<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>


<item>
<title>Bridging the Gap: Enhancing News Interpretation Across Diverse Audiences with Large Language Models</title>
<link>https://arxiv.org/abs/2507.21055</link>
<guid>https://arxiv.org/abs/2507.21055</guid>
<content:encoded><![CDATA[
arXiv:2507.21055v1 Announce Type: new 
Abstract: In the interconnected world, news media are critical in conveying information to public across diverse domains including technology, finance, and agriculture. Journalists make efforts to present accurate information, however, the interpretation of news often varies significantly among different audiences due to their specific expertise and age. In this work, we investigate how to identify these comprehension gaps and provide solutions to improve audiences understanding of news content, particular to the aspects of articles outside their primary domains of knowledge. We propose a agent-based framework using large language models (LLMs) to simulate society communication behaviors, where several agents can discuss news. These agents can be designed to be experts from various occupation, or from different age group. Our results indicate that this framework can identify confusions or even misunderstanding of news for the agent through the iterative discussion process. Based on these accurate identification, the framework can design a supplement material specific to these agents on the news. Our results show that agents exhibit significantly improved news understanding after receiving this material. These findings highlight our framework's utility and efficiency in enhancing news comprehension for diverse audiences by directly addressing their understanding gap.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dialogic Social Learning for Artificial Agents: Enhancing LLM Ontology Acquisition through Mixed-Initiative Educational Interactions</title>
<link>https://arxiv.org/abs/2507.21065</link>
<guid>https://arxiv.org/abs/2507.21065</guid>
<content:encoded><![CDATA[
arXiv:2507.21065v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in processing extensive offline datasets. However, they often face challenges in acquiring and integrating complex, knowledge online. Traditional AI training paradigms, predominantly based on supervised learning or reinforcement learning, mirror a 'Piagetian' model of independent exploration. These approaches typically rely on large datasets and sparse feedback signals, limiting the models' ability to learn efficiently from interactions. Drawing inspiration from Vygotsky's sociocultural theory, this study explores the potential of socially mediated learning paradigms to address these limitations.
  We introduce a dynamic environment, termed the 'AI Social Gym', where an AI learner agent engages in dyadic pedagogical dialogues with knowledgeable AI teacher agents. These interactions emphasize external, structured dialogue as a core mechanism for knowledge acquisition, contrasting with methods that depend solely on internal inference or pattern recognition.
  Our investigation focuses on how different pedagogical strategies impact the AI learning process in the context of ontology acquisition. Empirical results indicate that such dialogic approaches-particularly those involving mixed-direction interactions combining top-down explanations with learner-initiated questioning-significantly enhance the LLM's ability to acquire and apply new knowledge, outperforming both unidirectional instructional methods and direct access to structured knowledge, formats typically present in training datasets.
  These findings suggest that integrating pedagogical and psychological insights into AI and robot training can substantially improve post-training knowledge acquisition and response quality. This approach offers a complementary pathway to existing strategies like prompt engineering
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SynLang and Symbiotic Epistemology: A Manifesto for Conscious Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2507.21067</link>
<guid>https://arxiv.org/abs/2507.21067</guid>
<content:encoded><![CDATA[
arXiv:2507.21067v1 Announce Type: new 
Abstract: Current AI systems rely on opaque reasoning processes that hinder human oversight and collaborative potential. Conventional explainable AI approaches offer post-hoc justifications and often fail to establish genuine symbiotic collaboration. In this paper, the Symbiotic Epistemology is presented as a philosophical foundation for human-AI cognitive partnerships. Unlike frameworks that treat AI as a mere tool or replacement, symbiotic epistemology positions AI as a reasoning partner, fostering calibrated trust by aligning human confidence with AI reliability through explicit reasoning patterns and confidence assessments. SynLang (Symbiotic Syntactic Language) is introduced as a formal protocol for transparent human-AI collaboration. The framework is empirically validated through actual human-AI dialogues demonstrating AI's adaptation to structured reasoning protocols and successful metacognitive intervention. The protocol defines two complementary mechanisms: TRACE for high-level reasoning patterns and TRACE_FE for detailed factor explanations. It also integrates confidence quantification, declarative control over AI behavior, and context inheritance for multi-agent coordination. By structuring communication and embedding confidence-calibrated transparency, SynLang, together with symbiotic epistemology, enables AI systems that enhance human intelligence, preserve human agency, and uphold ethical accountability in collaborative decision-making. Through dual-level transparency, beginning with high-level reasoning patterns and progressing to granular explanations, the protocol facilitates rapid comprehension and supports thorough verification of AI decision-making.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FingerTip 20K: A Benchmark for Proactive and Personalized Mobile LLM Agents</title>
<link>https://arxiv.org/abs/2507.21071</link>
<guid>https://arxiv.org/abs/2507.21071</guid>
<content:encoded><![CDATA[
arXiv:2507.21071v1 Announce Type: new 
Abstract: Mobile GUI agents are becoming critical tools for enhancing human-device interaction efficiency, with multimodal large language models (MLLMs) emerging as dominant paradigms in this domain. Current agents, however, are limited to following explicit human instructions, resulting in insufficient capability for proactive intent anticipation. Additionally, these agents fail to leverage the contextual information associated with users during task execution, thereby neglecting potentially vast differences in user preferences. To address these challenges, we introduce the FingerTip benchmark. It contains two new tracks: proactive task suggestions by analyzing environment observation and users' previous intents, and personalized task execution by catering to users' action preferences. We collected unique human demonstrations of multi-step Android device interactions across a variety of everyday apps. These demonstrations are not isolated but are continuously acquired from the users' long-term usage in their real lives, and encompass essential user-related contextual information. Our experiments reveal challenges of the tasks we propose. The model fine-tuned with the data we collected effectively utilized user information and achieved good results, highlighting the potential of our approach in building more user-oriented mobile GUI agents. Our code is open-source at https://anonymous.4open.science/r/FingerTip-57B8 for reproducibility.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Driven and Participatory Approaches toward Neuro-Inclusive AI</title>
<link>https://arxiv.org/abs/2507.21077</link>
<guid>https://arxiv.org/abs/2507.21077</guid>
<content:encoded><![CDATA[
arXiv:2507.21077v1 Announce Type: new 
Abstract: Biased data representation in AI marginalizes up to 75 million autistic people worldwide through medical applications viewing autism as a deficit of neurotypical social skills rather than an aspect of human diversity, and this perspective is grounded in research questioning the humanity of autistic people. Turing defined artificial intelligence as the ability to mimic human communication, and as AI development increasingly focuses on human-like agents, this benchmark remains popular. In contrast, we define Neuro-Inclusive AI as datasets and systems that move away from mimicking humanness as a benchmark for machine intelligence. Then, we explore the origins, prevalence, and impact of anti-autistic biases in current research. Our work finds that 90% of human-like AI agents exclude autistic perspectives, and AI creators continue to believe ethical considerations are beyond the scope of their work. To improve the autistic representation in data, we conduct empirical experiments with annotators and LLMs, finding that binary labeling schemes sufficiently capture the nuances of labeling anti-autistic hate speech. Our benchmark, AUTALIC, can be used to evaluate or fine-tune models, and was developed to serve as a foundation for more neuro-inclusive future work.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Which symbol grounding problem should we try to solve?</title>
<link>https://arxiv.org/abs/2507.21080</link>
<guid>https://arxiv.org/abs/2507.21080</guid>
<content:encoded><![CDATA[
arXiv:2507.21080v1 Announce Type: new 
Abstract: Floridi and Taddeo propose a condition of "zero semantic commitment" for solutions to the grounding problem, and a solution to it. I argue briefly that their condition cannot be fulfilled, not even by their own solution. After a look at Luc Steels' very different competing suggestion, I suggest that we need to re-think what the problem is and what role the 'goals' in a system play in formulating the problem. On the basis of a proper understanding of computing, I come to the conclusion that the only sensible grounding problem is how we can explain and re-produce the behavioral ability and function of meaning in artificial computational agents
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Value of Gen-AI Conversations: A bottom-up Framework for AI Value Alignment</title>
<link>https://arxiv.org/abs/2507.21091</link>
<guid>https://arxiv.org/abs/2507.21091</guid>
<content:encoded><![CDATA[
arXiv:2507.21091v1 Announce Type: new 
Abstract: Conversational agents (CAs) based on generative artificial intelligence frequently face challenges ensuring ethical interactions that align with human values. Current value alignment efforts largely rely on top-down approaches, such as technical guidelines or legal value principles. However, these methods tend to be disconnected from the specific contexts in which CAs operate, potentially leading to misalignment with users interests. To address this challenge, we propose a novel, bottom-up approach to value alignment, utilizing the value ontology of the ISO Value-Based Engineering standard for ethical IT design. We analyse 593 ethically sensitive system outputs identified from 16,908 conversational logs of a major European employment service CA to identify core values and instances of value misalignment within real-world interactions. The results revealed nine core values and 32 different value misalignments that negatively impacted users. Our findings provide actionable insights for CA providers seeking to address ethical challenges and achieve more context-sensitive value alignment.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentMaster: A Multi-Agent Conversational Framework Using A2A and MCP Protocols for Multimodal Information Retrieval and Analysis</title>
<link>https://arxiv.org/abs/2507.21105</link>
<guid>https://arxiv.org/abs/2507.21105</guid>
<content:encoded><![CDATA[
arXiv:2507.21105v1 Announce Type: new 
Abstract: The rise of Multi-Agent Systems (MAS) in Artificial Intelligence (AI), especially integrated with Large Language Models (LLMs), has greatly facilitated the resolution of complex tasks. However, current systems are still facing challenges of inter-agent communication, coordination, and interaction with heterogeneous tools and resources. Most recently, the Model Context Protocol (MCP) by Anthropic and Agent-to-Agent (A2A) communication protocol by Google have been introduced, and to the best of our knowledge, very few applications exist where both protocols are employed within a single MAS framework. We present a pilot study of AgentMaster, a novel modular multi-protocol MAS framework with self-implemented A2A and MCP, enabling dynamic coordination and flexible communication. Through a unified conversational interface, the system supports natural language interaction without prior technical expertise and responds to multimodal queries for tasks including information retrieval, question answering, and image analysis. Evaluation through the BERTScore F1 and LLM-as-a-Judge metric G-Eval averaged 96.3\% and 87.1\%, revealing robust inter-agent coordination, query decomposition, dynamic routing, and domain-specific, relevant responses. Overall, our proposed framework contributes to the potential capabilities of domain-specific, cooperative, and scalable conversational AI powered by MAS.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vulnerability Mitigation System (VMS): LLM Agent and Evaluation Framework for Autonomous Penetration Testing</title>
<link>https://arxiv.org/abs/2507.21113</link>
<guid>https://arxiv.org/abs/2507.21113</guid>
<content:encoded><![CDATA[
arXiv:2507.21113v1 Announce Type: new 
Abstract: As the frequency of cyber threats increases, conventional penetration testing is failing to capture the entirety of todays complex environments. To solve this problem, we propose the Vulnerability Mitigation System (VMS), a novel agent based on a Large Language Model (LLM) capable of performing penetration testing without human intervention. The VMS has a two-part architecture for planning and a Summarizer, which enable it to generate commands and process feedback. To standardize testing, we designed two new Capture the Flag (CTF) benchmarks based on the PicoCTF and OverTheWire platforms with 200 challenges. These benchmarks allow us to evaluate how effectively the system functions. We performed a number of experiments using various LLMs while tuning the temperature and top-p parameters and found that GPT-4o performed best, sometimes even better than expected. The results indicate that LLMs can be effectively applied to many cybersecurity tasks; however, there are risks. To ensure safe operation, we used a containerized environment. Both the VMS and the benchmarks are publicly available, advancing the creation of secure, autonomous cybersecurity tools.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VizGenie: Toward Self-Refining, Domain-Aware Workflows for Next-Generation Scientific Visualization</title>
<link>https://arxiv.org/abs/2507.21124</link>
<guid>https://arxiv.org/abs/2507.21124</guid>
<content:encoded><![CDATA[
arXiv:2507.21124v1 Announce Type: new 
Abstract: We present VizGenie, a self-improving, agentic framework that advances scientific visualization through large language model (LLM) by orchestrating of a collection of domain-specific and dynamically generated modules. Users initially access core functionalities--such as threshold-based filtering, slice extraction, and statistical analysis--through pre-existing tools. For tasks beyond this baseline, VizGenie autonomously employs LLMs to generate new visualization scripts (e.g., VTK Python code), expanding its capabilities on-demand. Each generated script undergoes automated backend validation and is seamlessly integrated upon successful testing, continuously enhancing the system's adaptability and robustness. A distinctive feature of VizGenie is its intuitive natural language interface, allowing users to issue high-level feature-based queries (e.g., ``visualize the skull"). The system leverages image-based analysis and visual question answering (VQA) via fine-tuned vision models to interpret these queries precisely, bridging domain expertise and technical implementation. Additionally, users can interactively query generated visualizations through VQA, facilitating deeper exploration. Reliability and reproducibility are further strengthened by Retrieval-Augmented Generation (RAG), providing context-driven responses while maintaining comprehensive provenance records. Evaluations on complex volumetric datasets demonstrate significant reductions in cognitive overhead for iterative visualization tasks. By integrating curated domain-specific tools with LLM-driven flexibility, VizGenie not only accelerates insight generation but also establishes a sustainable, continuously evolving visualization practice. The resulting platform dynamically learns from user interactions, consistently enhancing support for feature-centric exploration and reproducible research in scientific visualization.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy Artifact ConnecTor (PACT): Embedding Enterprise Artifacts for Compliance AI Agents</title>
<link>https://arxiv.org/abs/2507.21142</link>
<guid>https://arxiv.org/abs/2507.21142</guid>
<content:encoded><![CDATA[
arXiv:2507.21142v1 Announce Type: new 
Abstract: Enterprise environments contain a heterogeneous, rapidly growing collection of internal artifacts related to code, data, and many different tools. Critical information for assessing privacy risk and ensuring regulatory compliance is often embedded across these varied resources, each with their own arcane discovery and extraction techniques. Therefore, large-scale privacy compliance in adherence to governmental regulations requires systems to discern the interconnected nature of diverse artifacts in a common, shared universe.
  We present Privacy Artifact ConnecT or (PACT), an embeddings-driven graph that links millions of artifacts spanning multiple artifact types generated by a variety of teams and projects. Powered by the state-of-the-art DRAGON embedding model, PACT uses a contrastive learning objective with light fine-tuning to link artifacts via their textual components such as raw metadata, ownership specifics, and compliance context. Experimental results show that PACT's fine-tuned model improves recall@1 from 18% to 53%, the query match rate from 9.6% to 69.7% when paired with a baseline AI agent, and the hitrate@1 from 25.7% to 44.9% for candidate selection in a standard recommender system.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Unifying Quantitative Security Benchmarking for Multi Agent Systems</title>
<link>https://arxiv.org/abs/2507.21146</link>
<guid>https://arxiv.org/abs/2507.21146</guid>
<content:encoded><![CDATA[
arXiv:2507.21146v1 Announce Type: new 
Abstract: Evolving AI systems increasingly deploy multi-agent architectures where autonomous agents collaborate, share information, and delegate tasks through developing protocols. This connectivity, while powerful, introduces novel security risks. One such risk is a cascading risk: a breach in one agent can cascade through the system, compromising others by exploiting inter-agent trust. In tandem with OWASP's initiative for an Agentic AI Vulnerability Scoring System we define an attack vector, Agent Cascading Injection, analogous to Agent Impact Chain and Blast Radius, operating across networks of agents. In an ACI attack, a malicious input or tool exploit injected at one agent leads to cascading compromises and amplified downstream effects across agents that trust its outputs. We formalize this attack with an adversarial goal equation and key variables (compromised agent, injected exploit, polluted observations, etc.), capturing how a localized vulnerability can escalate into system-wide failure. We then analyze ACI's properties -- propagation chains, amplification factors, and inter-agent compound effects -- and map these to OWASP's emerging Agentic AI risk categories (e.g. Impact Chain and Orchestration Exploits). Finally, we argue that ACI highlights a critical need for quantitative benchmarking frameworks to evaluate the security of agent-to-agent communication protocols. We outline a methodology for stress-testing multi-agent systems (using architectures such as Google's A2A and Anthropic's MCP) against cascading trust failures, developing upon groundwork for measurable, standardized agent-to-agent security evaluation. Our work provides the necessary apparatus for engineers to benchmark system resilience, make data-driven architectural trade-offs, and develop robust defenses against a new generation of agentic threats.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Model Powered Automated Modeling and Optimization of Active Distribution Network Dispatch Problems</title>
<link>https://arxiv.org/abs/2507.21162</link>
<guid>https://arxiv.org/abs/2507.21162</guid>
<content:encoded><![CDATA[
arXiv:2507.21162v1 Announce Type: new 
Abstract: The increasing penetration of distributed energy resources into active distribution networks (ADNs) has made effective ADN dispatch imperative. However, the numerous newly-integrated ADN operators, such as distribution system aggregators, virtual power plant managers, and end prosumers, often lack specialized expertise in power system operation, modeling, optimization, and programming. This knowledge gap renders reliance on human experts both costly and time-intensive. To address this challenge and enable intelligent, flexible ADN dispatch, this paper proposes a large language model (LLM) powered automated modeling and optimization approach. First, the ADN dispatch problems are decomposed into sequential stages, and a multi-LLM coordination architecture is designed. This framework comprises an Information Extractor, a Problem Formulator, and a Code Programmer, tasked with information retrieval, optimization problem formulation, and code implementation, respectively. Afterwards, tailored refinement techniques are developed for each LLM agent, greatly improving the accuracy and reliability of generated content. The proposed approach features a user-centric interface that enables ADN operators to derive dispatch strategies via simple natural language queries, eliminating technical barriers and increasing efficiency. Comprehensive comparisons and end-to-end demonstrations on various test cases validate the effectiveness of the proposed architecture and methods.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EdgeAgentX-DT: Integrating Digital Twins and Generative AI for Resilient Edge Intelligence in Tactical Networks</title>
<link>https://arxiv.org/abs/2507.21196</link>
<guid>https://arxiv.org/abs/2507.21196</guid>
<content:encoded><![CDATA[
arXiv:2507.21196v1 Announce Type: new 
Abstract: We introduce EdgeAgentX-DT, an advanced extension of the EdgeAgentX framework that integrates digital twin simulations and generative AI-driven scenario training to significantly enhance edge intelligence in military networks. EdgeAgentX-DT utilizes network digital twins, virtual replicas synchronized with real-world edge devices, to provide a secure, realistic environment for training and validation. Leveraging generative AI methods, such as diffusion models and transformers, the system creates diverse and adversarial scenarios for robust simulation-based agent training. Our multi-layer architecture includes: (1) on-device edge intelligence; (2) digital twin synchronization; and (3) generative scenario training. Experimental simulations demonstrate notable improvements over EdgeAgentX, including faster learning convergence, higher network throughput, reduced latency, and improved resilience against jamming and node failures. A case study involving a complex tactical scenario with simultaneous jamming attacks, agent failures, and increased network loads illustrates how EdgeAgentX-DT sustains operational performance, whereas baseline methods fail. These results highlight the potential of digital-twin-enabled generative training to strengthen edge AI deployments in contested environments.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Web: Weaving the Next Web with AI Agents</title>
<link>https://arxiv.org/abs/2507.21206</link>
<guid>https://arxiv.org/abs/2507.21206</guid>
<content:encoded><![CDATA[
arXiv:2507.21206v1 Announce Type: new 
Abstract: The emergence of AI agents powered by large language models (LLMs) marks a pivotal shift toward the Agentic Web, a new phase of the internet defined by autonomous, goal-driven interactions. In this paradigm, agents interact directly with one another to plan, coordinate, and execute complex tasks on behalf of users. This transition from human-driven to machine-to-machine interaction allows intent to be delegated, relieving users from routine digital operations and enabling a more interactive, automated web experience. In this paper, we present a structured framework for understanding and building the Agentic Web. We trace its evolution from the PC and Mobile Web eras and identify the core technological foundations that support this shift. Central to our framework is a conceptual model consisting of three key dimensions: intelligence, interaction, and economics. These dimensions collectively enable the capabilities of AI agents, such as retrieval, recommendation, planning, and collaboration. We analyze the architectural and infrastructural challenges involved in creating scalable agentic systems, including communication protocols, orchestration strategies, and emerging paradigms such as the Agent Attention Economy. We conclude by discussing the potential applications, societal risks, and governance issues posed by agentic systems, and outline research directions for developing open, secure, and intelligent ecosystems shaped by both human intent and autonomous agent behavior. A continuously updated collection of relevant studies for agentic web is available at: https://github.com/SafeRL-Lab/agentic-web.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Games Agents Play: Towards Transactional Analysis in LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2507.21354</link>
<guid>https://arxiv.org/abs/2507.21354</guid>
<content:encoded><![CDATA[
arXiv:2507.21354v1 Announce Type: new 
Abstract: Multi-Agent Systems (MAS) are increasingly used to simulate social interactions, but most of the frameworks miss the underlying cognitive complexity of human behavior. In this paper, we introduce Trans-ACT (Transactional Analysis Cognitive Toolkit), an approach embedding Transactional Analysis (TA) principles into MAS to generate agents with realistic psychological dynamics. Trans-ACT integrates the Parent, Adult, and Child ego states into an agent's cognitive architecture. Each ego state retrieves context-specific memories and uses them to shape response to new situations. The final answer is chosen according to the underlying life script of the agent. Our experimental simulation, which reproduces the Stupid game scenario, demonstrates that agents grounded in cognitive and TA principles produce deeper and context-aware interactions. Looking ahead, our research opens a new way for a variety of applications, including conflict resolution, educational support, and advanced social psychology studies.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ProMemAssist: Exploring Timely Proactive Assistance Through Working Memory Modeling in Multi-Modal Wearable Devices</title>
<link>https://arxiv.org/abs/2507.21378</link>
<guid>https://arxiv.org/abs/2507.21378</guid>
<content:encoded><![CDATA[
arXiv:2507.21378v1 Announce Type: new 
Abstract: Wearable AI systems aim to provide timely assistance in daily life, but existing approaches often rely on user initiation or predefined task knowledge, neglecting users' current mental states. We introduce ProMemAssist, a smart glasses system that models a user's working memory (WM) in real-time using multi-modal sensor signals. Grounded in cognitive theories of WM, our system represents perceived information as memory items and episodes with encoding mechanisms, such as displacement and interference. This WM model informs a timing predictor that balances the value of assistance with the cost of interruption. In a user study with 12 participants completing cognitively demanding tasks, ProMemAssist delivered more selective assistance and received higher engagement compared to an LLM baseline system. Qualitative feedback highlights the benefits of WM modeling for nuanced, context-sensitive support, offering design implications for more attentive and user-aware proactive agents.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAAD: Automate Software Architecture Design through Knowledge-Driven Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2507.21382</link>
<guid>https://arxiv.org/abs/2507.21382</guid>
<content:encoded><![CDATA[
arXiv:2507.21382v1 Announce Type: new 
Abstract: Software architecture design is a critical, yet inherently complex and knowledge-intensive phase of software development. It requires deep domain expertise, development experience, architectural knowledge, careful trade-offs among competing quality attributes, and the ability to adapt to evolving requirements. Traditionally, this process is time-consuming and labor-intensive, and relies heavily on architects, often resulting in limited design alternatives, especially under the pressures of agile development. While Large Language Model (LLM)-based agents have shown promising performance across various SE tasks, their application to architecture design remains relatively scarce and requires more exploration, particularly in light of diverse domain knowledge and complex decision-making. To address the challenges, we proposed MAAD (Multi-Agent Architecture Design), an automated framework that employs a knowledge-driven Multi-Agent System (MAS) for architecture design. MAAD orchestrates four specialized agents (i.e., Analyst, Modeler, Designer and Evaluator) to collaboratively interpret requirements specifications and produce architectural blueprints enriched with quality attributes-based evaluation reports. We then evaluated MAAD through a case study and comparative experiments against MetaGPT, a state-of-the-art MAS baseline. Our results show that MAAD's superiority lies in generating comprehensive architectural components and delivering insightful and structured architecture evaluation reports. Feedback from industrial architects across 11 requirements specifications further reinforces MAAD's practical usability. We finally explored the performance of the MAAD framework with three LLMs (GPT-4o, DeepSeek-R1, and Llama 3.3) and found that GPT-4o exhibits better performance in producing architecture design, emphasizing the importance of LLM selection in MAS-driven architecture design.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning-based Cell DTX/DRX Configuration for Network Energy Saving</title>
<link>https://arxiv.org/abs/2507.21385</link>
<guid>https://arxiv.org/abs/2507.21385</guid>
<content:encoded><![CDATA[
arXiv:2507.21385v1 Announce Type: new 
Abstract: 3GPP Release 18 cell discontinuous transmission and reception (cell DTX/DRX) is an important new network energy saving feature for 5G. As a time-domain technique, it periodically aggregates the user data transmissions in a given duration of time when the traffic load is not heavy, so that the remaining time can be kept silent and advanced sleep modes (ASM) can be enabled to shut down more radio components and save more energy for the cell. However, inevitably the packet delay is increased, as during the silent period no transmission is allowed. In this paper we study how to configure cell DTX/DRX to optimally balance energy saving and packet delay, so that for delay-sensitive traffic maximum energy saving can be achieved while the degradation of quality of service (QoS) is minimized. As the optimal configuration can be different for different network and traffic conditions, the problem is complex and we resort to deep reinforcement learning (DRL) framework to train an AI agent to solve it. Through careful design of 1) the learning algorithm, which implements a deep Q-network (DQN) on a contextual bandit (CB) model, and 2) the reward function, which utilizes a smooth approximation of a theoretically optimal but discontinuous reward function, we are able to train an AI agent that always tries to select the best possible Cell DTX/DRX configuration under any network and traffic conditions. Simulation results show that compared to the case when cell DTX/DRX is not used, our agent can achieve up to ~45% energy saving depending on the traffic load scenario, while always maintaining no more than ~1% QoS degradation.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-Augmented Large Language Model Agents: Current Progress and Future Prospects</title>
<link>https://arxiv.org/abs/2507.21407</link>
<guid>https://arxiv.org/abs/2507.21407</guid>
<content:encoded><![CDATA[
arXiv:2507.21407v1 Announce Type: new 
Abstract: Autonomous agents based on large language models (LLMs) have demonstrated impressive capabilities in a wide range of applications, including web navigation, software development, and embodied control. While most LLMs are limited in several key agentic procedures, such as reliable planning, long-term memory, tool management, and multi-agent coordination, graphs can serve as a powerful auxiliary structure to enhance structure, continuity, and coordination in complex agent workflows. Given the rapid growth and fragmentation of research on Graph-augmented LLM Agents (GLA), this paper offers a timely and comprehensive overview of recent advances and also highlights key directions for future work. Specifically, we categorize existing GLA methods by their primary functions in LLM agent systems, including planning, memory, and tool usage, and then analyze how graphs and graph learning algorithms contribute to each. For multi-agent systems, we further discuss how GLA solutions facilitate the orchestration, efficiency optimization, and trustworthiness of MAS. Finally, we highlight key future directions to advance this field, from improving structural adaptability to enabling unified, scalable, and multimodal GLA systems. We hope this paper can serve as a roadmap for future research on GLA and foster a deeper understanding of the role of graphs in LLM agent systems.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MemTool: Optimizing Short-Term Memory Management for Dynamic Tool Calling in LLM Agent Multi-Turn Conversations</title>
<link>https://arxiv.org/abs/2507.21428</link>
<guid>https://arxiv.org/abs/2507.21428</guid>
<content:encoded><![CDATA[
arXiv:2507.21428v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents have shown significant autonomous capabilities in dynamically searching and incorporating relevant tools or Model Context Protocol (MCP) servers for individual queries. However, fixed context windows limit effectiveness in multi-turn interactions requiring repeated, independent tool usage. We introduce MemTool, a short-term memory framework enabling LLM agents to dynamically manage tools or MCP server contexts across multi-turn conversations. MemTool offers three agentic architectures: 1) Autonomous Agent Mode, granting full tool management autonomy, 2) Workflow Mode, providing deterministic control without autonomy, and 3) Hybrid Mode, combining autonomous and deterministic control. Evaluating each MemTool mode across 13+ LLMs on the ScaleMCP benchmark, we conducted experiments over 100 consecutive user interactions, measuring tool removal ratios (short-term memory efficiency) and task completion accuracy. In Autonomous Agent Mode, reasoning LLMs achieve high tool-removal efficiency (90-94% over a 3-window average), while medium-sized models exhibit significantly lower efficiency (0-60%). Workflow and Hybrid modes consistently manage tool removal effectively, whereas Autonomous and Hybrid modes excel at task completion. We present trade-offs and recommendations for each MemTool mode based on task accuracy, agency, and model capabilities.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Locally Deployable Fine-Tuned Causal Large Language Models for Mode Choice Behaviour</title>
<link>https://arxiv.org/abs/2507.21432</link>
<guid>https://arxiv.org/abs/2507.21432</guid>
<content:encoded><![CDATA[
arXiv:2507.21432v1 Announce Type: new 
Abstract: This study investigates the adoption of open-access, locally deployable causal large language models (LLMs) for travel mode choice prediction and introduces LiTransMC, the first fine-tuned causal LLM developed for this task. We systematically benchmark eleven LLMs (1-12B parameters) across three stated and revealed preference datasets, testing 396 configurations and generating over 79,000 synthetic commuter predictions. Beyond predictive accuracy, we evaluate models generated reasoning using BERTopic for topic modelling and a novel Explanation Strength Index, providing the first structured analysis of how LLMs articulate decision factors in alignment with behavioural theory. LiTransMC, fine-tuned using parameter efficient and loss masking strategy, achieved a weighted F1 score of 0.6845 and a Jensen-Shannon Divergence of 0.000245, surpassing both untuned local models and larger proprietary systems, including GPT-4o with advanced persona inference and embedding-based loading, while also outperforming classical mode choice methods such as discrete choice models and machine learning classifiers for the same dataset. This dual improvement, i.e., high instant-level accuracy and near-perfect distributional calibration, demonstrates the feasibility of creating specialist, locally deployable LLMs that integrate prediction and interpretability. Through combining structured behavioural prediction with natural language reasoning, this work unlocks the potential for conversational, multi-task transport models capable of supporting agent-based simulations, policy testing, and behavioural insight generation. These findings establish a pathway for transforming general purpose LLMs into specialized, explainable tools for transportation research and policy formulation, while maintaining privacy, reducing cost, and broadening access through local deployment.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Recursive Visual Imagination and Adaptive Linguistic Grounding for Vision Language Navigation</title>
<link>https://arxiv.org/abs/2507.21450</link>
<guid>https://arxiv.org/abs/2507.21450</guid>
<content:encoded><![CDATA[
arXiv:2507.21450v1 Announce Type: new 
Abstract: Vision Language Navigation (VLN) typically requires agents to navigate to specified objects or remote regions in unknown scenes by obeying linguistic commands. Such tasks require organizing historical visual observations for linguistic grounding, which is critical for long-sequence navigational decisions. However, current agents suffer from overly detailed scene representation and ambiguous vision-language alignment, which weaken their comprehension of navigation-friendly high-level scene priors and easily lead to behaviors that violate linguistic commands. To tackle these issues, we propose a navigation policy by recursively summarizing along-the-way visual perceptions, which are adaptively aligned with commands to enhance linguistic grounding. In particular, by structurally modeling historical trajectories as compact neural grids, several Recursive Visual Imagination (RVI) techniques are proposed to motivate agents to focus on the regularity of visual transitions and semantic scene layouts, instead of dealing with misleading geometric details. Then, an Adaptive Linguistic Grounding (ALG) technique is proposed to align the learned situational memories with different linguistic components purposefully. Such fine-grained semantic matching facilitates the accurate anticipation of navigation actions and progress. Our navigation policy outperforms the state-of-the-art methods on the challenging VLN-CE and ObjectNav tasks, showing the superiority of our RVI and ALG techniques for VLN.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An LLM Driven Agent Framework for Automated Infrared Spectral Multi Task Reasoning</title>
<link>https://arxiv.org/abs/2507.21471</link>
<guid>https://arxiv.org/abs/2507.21471</guid>
<content:encoded><![CDATA[
arXiv:2507.21471v1 Announce Type: new 
Abstract: Infrared spectroscopy offers rapid, non destructive measurement of chemical and material properties but suffers from high dimensional, overlapping spectral bands that challenge conventional chemometric approaches. Emerging large language models (LLMs), with their capacity for generalization and reasoning, offer promising potential for automating complex scientific workflows. Despite this promise, their application in IR spectral analysis remains largely unexplored. This study addresses the critical challenge of achieving accurate, automated infrared spectral interpretation under low-data conditions using an LLM-driven framework. We introduce an end-to-end, large language model driven agent framework that integrates a structured literature knowledge base, automated spectral preprocessing, feature extraction, and multi task reasoning in a unified pipeline. By querying a curated corpus of peer reviewed IR publications, the agent selects scientifically validated routines. The selected methods transform each spectrum into low dimensional feature sets, which are fed into few shot prompt templates for classification, regression, and anomaly detection. A closed loop, multi turn protocol iteratively appends mispredicted samples to the prompt, enabling dynamic refinement of predictions. Across diverse materials: stamp pad ink, Chinese medicine, Pu'er tea, Citri Reticulatae Pericarpium and waste water COD datasets, the multi turn LLM consistently outperforms single turn inference, rivaling or exceeding machine learning and deep learning models under low data regimes.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Capacity-Constrained Continual Learning</title>
<link>https://arxiv.org/abs/2507.21479</link>
<guid>https://arxiv.org/abs/2507.21479</guid>
<content:encoded><![CDATA[
arXiv:2507.21479v1 Announce Type: new 
Abstract: Any agents we can possibly build are subject to capacity constraints, as memory and compute resources are inherently finite. However, comparatively little attention has been dedicated to understanding how agents with limited capacity should allocate their resources for optimal performance. The goal of this paper is to shed some light on this question by studying a simple yet relevant continual learning problem: the capacity-constrained linear-quadratic-Gaussian (LQG) sequential prediction problem. We derive a solution to this problem under appropriate technical conditions. Moreover, for problems that can be decomposed into a set of sub-problems, we also demonstrate how to optimally allocate capacity across these sub-problems in the steady state. We view the results of this paper as a first step in the systematic theoretical study of learning under capacity constraints.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluation and Benchmarking of LLM Agents: A Survey</title>
<link>https://arxiv.org/abs/2507.21504</link>
<guid>https://arxiv.org/abs/2507.21504</guid>
<content:encoded><![CDATA[
arXiv:2507.21504v1 Announce Type: new 
Abstract: The rise of LLM-based agents has opened new frontiers in AI applications, yet evaluating these agents remains a complex and underdeveloped area. This survey provides an in-depth overview of the emerging field of LLM agent evaluation, introducing a two-dimensional taxonomy that organizes existing work along (1) evaluation objectives -- what to evaluate, such as agent behavior, capabilities, reliability, and safety -- and (2) evaluation process -- how to evaluate, including interaction modes, datasets and benchmarks, metric computation methods, and tooling. In addition to taxonomy, we highlight enterprise-specific challenges, such as role-based access to data, the need for reliability guarantees, dynamic and long-horizon interactions, and compliance, which are often overlooked in current research. We also identify future research directions, including holistic, more realistic, and scalable evaluation. This work aims to bring clarity to the fragmented landscape of agent evaluation and provide a framework for systematic assessment, enabling researchers and practitioners to evaluate LLM agents for real-world deployment.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LITE: A Learning-Integrated Topological Explorer for Multi-Floor Indoor Environments</title>
<link>https://arxiv.org/abs/2507.21517</link>
<guid>https://arxiv.org/abs/2507.21517</guid>
<content:encoded><![CDATA[
arXiv:2507.21517v1 Announce Type: new 
Abstract: This work focuses on multi-floor indoor exploration, which remains an open area of research. Compared to traditional methods, recent learning-based explorers have demonstrated significant potential due to their robust environmental learning and modeling capabilities, but most are restricted to 2D environments. In this paper, we proposed a learning-integrated topological explorer, LITE, for multi-floor indoor environments. LITE decomposes the environment into a floor-stair topology, enabling seamless integration of learning or non-learning-based 2D exploration methods for 3D exploration. As we incrementally build floor-stair topology in exploration using YOLO11-based instance segmentation model, the agent can transition between floors through a finite state machine. Additionally, we implement an attention-based 2D exploration policy that utilizes an attention mechanism to capture spatial dependencies between different regions, thereby determining the next global goal for more efficient exploration. Extensive comparison and ablation studies conducted on the HM3D and MP3D datasets demonstrate that our proposed 2D exploration policy significantly outperforms all baseline explorers in terms of exploration efficiency. Furthermore, experiments in several 3D multi-floor environments indicate that our framework is compatible with various 2D exploration methods, facilitating effective multi-floor indoor exploration. Finally, we validate our method in the real world with a quadruped robot, highlighting its strong generalization capabilities.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models for Wireless Communications: From Adaptation to Autonomy</title>
<link>https://arxiv.org/abs/2507.21524</link>
<guid>https://arxiv.org/abs/2507.21524</guid>
<content:encoded><![CDATA[
arXiv:2507.21524v1 Announce Type: new 
Abstract: The emergence of large language models (LLMs) has revolutionized artificial intelligence, offering unprecedented capabilities in reasoning, generalization, and zero-shot learning. These strengths open new frontiers in wireless communications, where increasing complexity and dynamics demand intelligent and adaptive solutions. This article explores the role of LLMs in transforming wireless systems across three key directions: adapting pretrained LLMs for core communication tasks, developing wireless-specific foundation models to balance versatility and efficiency, and enabling agentic LLMs with autonomous reasoning and coordination capabilities. We highlight recent advances, practical case studies, and the unique benefits of LLM-based approaches over traditional methods. Finally, we outline open challenges and research opportunities, including multimodal fusion, collaboration with lightweight models, and self-improving capabilities, charting a path toward intelligent, adaptive, and autonomous wireless networks of the future.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Model Predictive Adversarial Imitation Learning for Planning from Observation</title>
<link>https://arxiv.org/abs/2507.21533</link>
<guid>https://arxiv.org/abs/2507.21533</guid>
<content:encoded><![CDATA[
arXiv:2507.21533v1 Announce Type: new 
Abstract: Human demonstration data is often ambiguous and incomplete, motivating imitation learning approaches that also exhibit reliable planning behavior. A common paradigm to perform planning-from-demonstration involves learning a reward function via Inverse Reinforcement Learning (IRL) then deploying this reward via Model Predictive Control (MPC). Towards unifying these methods, we derive a replacement of the policy in IRL with a planning-based agent. With connections to Adversarial Imitation Learning, this formulation enables end-to-end interactive learning of planners from observation-only demonstrations. In addition to benefits in interpretability, complexity, and safety, we study and observe significant improvements on sample efficiency, out-of-distribution generalization, and robustness. The study includes evaluations in both simulated control benchmarks and real-world navigation experiments using few-to-single observation-only demonstrations.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finding Uncommon Ground: A Human-Centered Model for Extrospective Explanations</title>
<link>https://arxiv.org/abs/2507.21571</link>
<guid>https://arxiv.org/abs/2507.21571</guid>
<content:encoded><![CDATA[
arXiv:2507.21571v1 Announce Type: new 
Abstract: The need for explanations in AI has, by and large, been driven by the desire to increase the transparency of black-box machine learning models. However, such explanations, which focus on the internal mechanisms that lead to a specific output, are often unsuitable for non-experts. To facilitate a human-centered perspective on AI explanations, agents need to focus on individuals and their preferences as well as the context in which the explanations are given. This paper proposes a personalized approach to explanation, where the agent tailors the information provided to the user based on what is most likely pertinent to them. We propose a model of the agent's worldview that also serves as a personal and dynamic memory of its previous interactions with the same user, based on which the artificial agent can estimate what part of its knowledge is most likely new information to the user.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Link Between Bayesian Inference and Embodied Intelligence: Toward Open Physical-World Embodied AI Systems</title>
<link>https://arxiv.org/abs/2507.21589</link>
<guid>https://arxiv.org/abs/2507.21589</guid>
<content:encoded><![CDATA[
arXiv:2507.21589v1 Announce Type: new 
Abstract: Embodied intelligence posits that cognitive capabilities fundamentally emerge from - and are shaped by - an agent's real-time sensorimotor interactions with its environment. Such adaptive behavior inherently requires continuous inference under uncertainty. Bayesian statistics offers a principled probabilistic framework to address this challenge by representing knowledge as probability distributions and updating beliefs in response to new evidence. The core computational processes underlying embodied intelligence - including perception, action selection, learning, and even higher-level cognition - can be effectively understood and modeled as forms of Bayesian inference. Despite the deep conceptual connection between Bayesian statistics and embodied intelligence, Bayesian principles have not been widely or explicitly applied in today's embodied intelligence systems. In this work, we examine both Bayesian and contemporary embodied intelligence approaches through two fundamental lenses: search and learning - the two central themes in modern AI, as highlighted in Rich Sutton's influential essay "The Bitter Lesson". This analysis sheds light on why Bayesian inference has not played a central role in the development of modern embodied intelligence. At the same time, it reveals that current embodied intelligence systems remain largely confined to closed-physical-world environments, and highlights the potential for Bayesian methods to play a key role in extending these systems toward truly open physical-world embodied intelligence.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research Challenges and Progress in the End-to-End V2X Cooperative Autonomous Driving Competition</title>
<link>https://arxiv.org/abs/2507.21610</link>
<guid>https://arxiv.org/abs/2507.21610</guid>
<content:encoded><![CDATA[
arXiv:2507.21610v1 Announce Type: new 
Abstract: With the rapid advancement of autonomous driving technology, vehicle-to-everything (V2X) communication has emerged as a key enabler for extending perception range and enhancing driving safety by providing visibility beyond the line of sight. However, integrating multi-source sensor data from both ego-vehicles and infrastructure under real-world constraints, such as limited communication bandwidth and dynamic environments, presents significant technical challenges. To facilitate research in this area, we organized the End-to-End Autonomous Driving through V2X Cooperation Challenge, which features two tracks: cooperative temporal perception and cooperative end-to-end planning. Built on the UniV2X framework and the V2X-Seq-SPD dataset, the challenge attracted participation from over 30 teams worldwide and established a unified benchmark for evaluating cooperative driving systems. This paper describes the design and outcomes of the challenge, highlights key research problems including bandwidth-aware fusion, robust multi-agent planning, and heterogeneous sensor integration, and analyzes emerging technical trends among top-performing solutions. By addressing practical constraints in communication and data fusion, the challenge contributes to the development of scalable and reliable V2X-cooperative autonomous driving systems.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>"Teammates, Am I Clear?": Analysing Legible Behaviours in Teams</title>
<link>https://arxiv.org/abs/2507.21631</link>
<guid>https://arxiv.org/abs/2507.21631</guid>
<content:encoded><![CDATA[
arXiv:2507.21631v1 Announce Type: new 
Abstract: In this paper we investigate the notion of legibility in sequential decision-making in the context of teams and teamwork. There have been works that extend the notion of legibility to sequential decision making, for deterministic and for stochastic scenarios. However, these works focus on one agent interacting with one human, foregoing the benefits of having legible decision making in teams of agents or in team configurations with humans. In this work we propose an extension of legible decision-making to multi-agent settings that improves the performance of agents working in collaboration. We showcase the performance of legible decision making in team scenarios using our proposed extension in multi-agent benchmark scenarios. We show that a team with a legible agent is able to outperform a team composed solely of agents with standard optimal behaviour.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StaffPro: an LLM Agent for Joint Staffing and Profiling</title>
<link>https://arxiv.org/abs/2507.21636</link>
<guid>https://arxiv.org/abs/2507.21636</guid>
<content:encoded><![CDATA[
arXiv:2507.21636v1 Announce Type: new 
Abstract: Large language model (LLM) agents integrate pre-trained LLMs with modular algorithmic components and have shown remarkable reasoning and decision-making abilities. In this work, we investigate their use for two tightly intertwined challenges in workforce management: staffing, i.e., the assignment and scheduling of tasks to workers, which may require team formation; and profiling, i.e., the continuous estimation of workers' skills, preferences, and other latent attributes from unstructured data. We cast these problems in a formal mathematical framework that links scheduling decisions to latent feature estimation, and we introduce StaffPro, an LLM agent that addresses staffing and profiling jointly. Differently from existing staffing solutions, StaffPro allows expressing optimization objectives using natural language, accepts textual task descriptions and provides high flexibility. StaffPro interacts directly with humans by establishing a continuous human-agent feedback loop, ensuring natural and intuitive use. By analyzing human feedback, our agent continuously estimates the latent features of workers, realizing life-long worker profiling and ensuring optimal staffing performance over time. A consulting firm simulation example demonstrates that StaffPro successfully estimates workers' attributes and generates high quality schedules. With its innovative design, StaffPro offers a robust, interpretable, and human-centric solution for automated personnel management.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assistax: A Hardware-Accelerated Reinforcement Learning Benchmark for Assistive Robotics</title>
<link>https://arxiv.org/abs/2507.21638</link>
<guid>https://arxiv.org/abs/2507.21638</guid>
<content:encoded><![CDATA[
arXiv:2507.21638v1 Announce Type: new 
Abstract: The development of reinforcement learning (RL) algorithms has been largely driven by ambitious challenge tasks and benchmarks. Games have dominated RL benchmarks because they present relevant challenges, are inexpensive to run and easy to understand. While games such as Go and Atari have led to many breakthroughs, they often do not directly translate to real-world embodied applications. In recognising the need to diversify RL benchmarks and addressing complexities that arise in embodied interaction scenarios, we introduce Assistax: an open-source benchmark designed to address challenges arising in assistive robotics tasks. Assistax uses JAX's hardware acceleration for significant speed-ups for learning in physics-based simulations. In terms of open-loop wall-clock time, Assistax runs up to $370\times$ faster when vectorising training runs compared to CPU-based alternatives. Assistax conceptualises the interaction between an assistive robot and an active human patient using multi-agent RL to train a population of diverse partner agents against which an embodied robotic agent's zero-shot coordination capabilities can be tested. Extensive evaluation and hyperparameter tuning for popular continuous control RL and MARL algorithms provide reliable baselines and establish Assistax as a practical benchmark for advancing RL research for assistive robotics. The code is available at: https://github.com/assistive-autonomy/assistax.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Neuro-Adaptive Sliding Mode Controller for Higher-Order Heterogeneous Nonlinear Multi-Agent Teams with Leader</title>
<link>https://arxiv.org/abs/2507.21667</link>
<guid>https://arxiv.org/abs/2507.21667</guid>
<content:encoded><![CDATA[
arXiv:2507.21667v1 Announce Type: new 
Abstract: This letter proposes a deep neural network (DNN)-based neuro-adaptive sliding mode control (SMC) strategy for leader-follower tracking in multi-agent systems with higher-order, heterogeneous, nonlinear, and unknown dynamics under external disturbances. The DNN is used to compensate the unknown nonlinear dynamics with higher accuracy than shallow neural networks (NNs) and SMC ensures robust tracking. This framework employs restricted potential functions within a set-theoretic paradigm to ensure system trajectories remain bounded within a compact set, improving robustness against approximation errors and external disturbances. The control scheme is grounded in non-smooth Lyapunov stability theory, with update laws derived for both inner and outer layer network weights of DNN. A numerical example is simulated that showcases the proposed controller's effectiveness, adaptability, and robustness.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent Generative AI Framework for IC Module-Level Verification Automation</title>
<link>https://arxiv.org/abs/2507.21694</link>
<guid>https://arxiv.org/abs/2507.21694</guid>
<content:encoded><![CDATA[
arXiv:2507.21694v1 Announce Type: new 
Abstract: As large language models demonstrate enormous potential in the field of Electronic Design Automation (EDA), generative AI-assisted chip design is attracting widespread attention from academia and industry. Although these technologies have made preliminary progress in tasks such as code generation, their application in chip verification -- a critical bottleneck in the chip development cycle -- remains at an exploratory stage. This paper proposes an innovative Multi-Agent Verification Framework (MAVF) aimed at addressing the limitations of current single-LLM approaches in complex verification tasks. Our framework builds an automated transformation system from design specifications to testbench through the collaborative work of multiple specialized agents, including specification parsing, verification strategy generation, and code implementation. Through verification experiments on multiple chip modules of varying complexity, results show that MAVF significantly outperforms traditional manual methods and single-dialogue generative AI approaches in verification document parsing and generation, as well as automated testbench generation. This research opens new directions for exploring generative AI applications in verification automation, potentially providing effective approaches to solving the most challenging bottleneck issues in chip design.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent-Based Exploration of Recommendation Systems in Misinformation Propagation</title>
<link>https://arxiv.org/abs/2507.21724</link>
<guid>https://arxiv.org/abs/2507.21724</guid>
<content:encoded><![CDATA[
arXiv:2507.21724v1 Announce Type: new 
Abstract: This study uses agent-based modeling to examine the impact of various recommendation algorithms on the propagation of misinformation on online social networks. We simulate a synthetic environment consisting of heterogeneous agents, including regular users, bots, and influencers, interacting through a social network with recommendation systems. We evaluate four recommendation strategies: popularity-based, collaborative filtering, and content-based filtering, along with a random baseline. Our results show that popularity-driven algorithms significantly amplify misinformation, while item-based collaborative filtering and content-based approaches are more effective in limiting exposure to fake content. Item-based collaborative filtering was found to perform better than previously reported in related literature. These findings highlight the role of algorithm design in shaping online information exposure and show that agent-based modeling can be used to gain realistic insight into how misinformation spreads.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-UAV Deployment in Obstacle-Cluttered Environments with LOS Connectivity</title>
<link>https://arxiv.org/abs/2507.21772</link>
<guid>https://arxiv.org/abs/2507.21772</guid>
<content:encoded><![CDATA[
arXiv:2507.21772v1 Announce Type: new 
Abstract: A reliable communication network is essential for multiple UAVs operating within obstacle-cluttered environments, where limited communication due to obstructions often occurs. A common solution is to deploy intermediate UAVs to relay information via a multi-hop network, which introduces two challenges: (i) how to design the structure of multihop networks; and (ii) how to maintain connectivity during collaborative motion. To this end, this work first proposes an efficient constrained search method based on the minimumedge RRT? algorithm, to find a spanning-tree topology that requires a less number of UAVs for the deployment task. Then, to achieve this deployment, a distributed model predictive control strategy is proposed for the online motion coordination. It explicitly incorporates not only the inter-UAV and UAVobstacle distance constraints, but also the line-of-sight (LOS) connectivity constraint. These constraints are well-known to be nonlinear and often tackled by various approximations. In contrast, this work provides a theoretical guarantee that all agent trajectories are ensured to be collision-free with a teamwise LOS connectivity at all time. Numerous simulations are performed in 3D valley-like environments, while hardware experiments validate its dynamic adaptation when the deployment position changes online.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Non-coercive extortion in game theory</title>
<link>https://arxiv.org/abs/2507.21795</link>
<guid>https://arxiv.org/abs/2507.21795</guid>
<content:encoded><![CDATA[
arXiv:2507.21795v1 Announce Type: new 
Abstract: Commitments play a crucial role in game theory, shaping strategic interactions by either altering a player's own payoffs or influencing the incentives of others through outcome-contingent payments. While most research has focused on using commitments to achieve efficient equilibria, their potential applications beyond this goal remain largely unexplored. In this study, we introduce a non-coercive extortion mechanism that leverages commitments to outcome-contingent payments, demonstrating how a player or external agent can extract profit by offering rewards rather than threatening punishment. At the core of the mechanism is the introduction of sequentiality into a simultaneous-move game, fundamentally reshaping the strategic interaction. We derive the conditions under which extortion is successful, identify the class of games susceptible to this scheme, and determine both the maximum extractable profit and the minimum required payment. To illustrate the extortion mechanism, we apply it to 2x2 games, highlighting how even simple strategic settings can be vulnerable to this form of manipulation. Our results reveal strategic vulnerabilities in competitive settings, with significant implications for economic markets, diplomatic relations, and multi-agent systems operating in blockchain environments. This work broadens our understanding of commitments in game theory and raises critical questions about how to safeguard strategic interactions from exploitation through non-coercive extortion.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?</title>
<link>https://arxiv.org/abs/2507.21817</link>
<guid>https://arxiv.org/abs/2507.21817</guid>
<content:encoded><![CDATA[
arXiv:2507.21817v1 Announce Type: new 
Abstract: Automated vulnerability detection research has made substantial progress, yet its real-world impact remains limited. Current vulnerability datasets suffer from issues including label inaccuracy rates of 20-71%, extensive duplication, and poor coverage of critical CWE types. These issues create a significant "generalization gap" where models achieve misleading self-testing performance (measured on held-out data from same dataset for training) by exploiting spurious correlations rather than learning true vulnerability patterns. Our analysis reveals that many models experience substantial performance drops of up to 40.6% when evaluated on independent data, sometimes underperforming random guessing.
  To address these limitations, we present a three-part solution. First, we introduce a manually curated test dataset, BenchVul, covering the MITRE Top 25 Most Dangerous CWEs. Second, we construct a high-quality training dataset, TitanVul, comprising 35,045 functions by aggregating seven public sources and applying deduplication and validation using a novel multi-agent LLM framework. Third, we propose a Realistic Vulnerability Generation (RVG) framework, which synthesizes context-aware vulnerability examples for underrepresented but critical CWE types through simulated development workflows.
  Our evaluation shows the strengths of each component in closing the generalization gap. First, BenchVul shows the limitations of self-testing: models trained on existing datasets, such as BigVul and PrimeVul, experience performance drops on BenchVul (from 0.776 to 0.519 and from 0.567 to 0.337). Second, training models on TitanVul demonstrates improved generalization, with model performance increasing from 0.584 when evaluated on the same dataset to 0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated data yields further gains, increasing model performance by 14.0% to 0.874.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Agentic AI for a New Paradigm in Business Process Development</title>
<link>https://arxiv.org/abs/2507.21823</link>
<guid>https://arxiv.org/abs/2507.21823</guid>
<content:encoded><![CDATA[
arXiv:2507.21823v1 Announce Type: new 
Abstract: Artificial Intelligence agents represent the next major revolution in the continuous technological evolution of industrial automation. In this paper, we introduce a new approach for business process design and development that leverages the capabilities of Agentic AI. Departing from the traditional task-based approach to business process design, we propose an agent-based method, where agents contribute to the achievement of business goals, identified by a set of business objects. When a single agent cannot fulfill a goal, we have a merge goal that can be achieved through the collaboration of multiple agents. The proposed model leads to a more modular and intelligent business process development by organizing it around goals, objects, and agents. As a result, this approach enables flexible and context-aware automation in dynamic industrial environments.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Probabilistic Active Goal Recognition</title>
<link>https://arxiv.org/abs/2507.21846</link>
<guid>https://arxiv.org/abs/2507.21846</guid>
<content:encoded><![CDATA[
arXiv:2507.21846v1 Announce Type: new 
Abstract: In multi-agent environments, effective interaction hinges on understanding the beliefs and intentions of other agents. While prior work on goal recognition has largely treated the observer as a passive reasoner, Active Goal Recognition (AGR) focuses on strategically gathering information to reduce uncertainty. We adopt a probabilistic framework for Active Goal Recognition and propose an integrated solution that combines a joint belief update mechanism with a Monte Carlo Tree Search (MCTS) algorithm, allowing the observer to plan efficiently and infer the actor's hidden goal without requiring domain-specific knowledge. Through comprehensive empirical evaluation in a grid-based domain, we show that our joint belief update significantly outperforms passive goal recognition, and that our domain-independent MCTS performs comparably to our strong domain-specific greedy baseline. These results establish our solution as a practical and robust framework for goal inference, advancing the field toward more interactive and adaptive multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-R1: Towards Agentic GraphRAG Framework via End-to-end Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.21892</link>
<guid>https://arxiv.org/abs/2507.21892</guid>
<content:encoded><![CDATA[
arXiv:2507.21892v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) mitigates hallucination in LLMs by incorporating external knowledge, but relies on chunk-based retrieval that lacks structural semantics. GraphRAG methods improve RAG by modeling knowledge as entity-relation graphs, but still face challenges in high construction cost, fixed one-time retrieval, and reliance on long-context reasoning and prompt design. To address these challenges, we propose Graph-R1, an agentic GraphRAG framework via end-to-end reinforcement learning (RL). It introduces lightweight knowledge hypergraph construction, models retrieval as a multi-turn agent-environment interaction, and optimizes the agent process via an end-to-end reward mechanism. Experiments on standard RAG datasets show that Graph-R1 outperforms traditional GraphRAG and RL-enhanced RAG methods in reasoning accuracy, retrieval efficiency, and generation quality.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ArtSeek: Deep artwork understanding via multimodal in-context reasoning and late interaction retrieval</title>
<link>https://arxiv.org/abs/2507.21917</link>
<guid>https://arxiv.org/abs/2507.21917</guid>
<content:encoded><![CDATA[
arXiv:2507.21917v1 Announce Type: new 
Abstract: Analyzing digitized artworks presents unique challenges, requiring not only visual interpretation but also a deep understanding of rich artistic, contextual, and historical knowledge. We introduce ArtSeek, a multimodal framework for art analysis that combines multimodal large language models with retrieval-augmented generation. Unlike prior work, our pipeline relies only on image input, enabling applicability to artworks without links to Wikidata or Wikipedia-common in most digitized collections. ArtSeek integrates three key components: an intelligent multimodal retrieval module based on late interaction retrieval, a contrastive multitask classification network for predicting artist, genre, style, media, and tags, and an agentic reasoning strategy enabled through in-context examples for complex visual question answering and artwork explanation via Qwen2.5-VL. Central to this approach is WikiFragments, a Wikipedia-scale dataset of image-text fragments curated to support knowledge-grounded multimodal reasoning. Our framework achieves state-of-the-art results on multiple benchmarks, including a +8.4% F1 improvement in style classification over GraphCLIP and a +7.1 BLEU@1 gain in captioning on ArtPedia. Qualitative analyses show that ArtSeek can interpret visual motifs, infer historical context, and retrieve relevant knowledge, even for obscure works. Though focused on visual arts, our approach generalizes to other domains requiring external knowledge, supporting scalable multimodal AI research. Both the dataset and the source code will be made publicly available at https://github.com/cilabuniba/artseek.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MMAT-1M: A Large Reasoning Dataset for Multimodal Agent Tuning</title>
<link>https://arxiv.org/abs/2507.21924</link>
<guid>https://arxiv.org/abs/2507.21924</guid>
<content:encoded><![CDATA[
arXiv:2507.21924v1 Announce Type: new 
Abstract: Large Language Models (LLMs), enhanced through agent tuning, have demonstrated remarkable capabilities in Chain-of-Thought (CoT) and tool utilization, significantly surpassing the performance of standalone models. However, the multimodal domain still lacks a large-scale, high-quality agent tuning dataset to unlock the full potential of multimodal large language models. To bridge this gap, we introduce MMAT-1M, the first million-scale multimodal agent tuning dataset designed to support CoT, reflection, and dynamic tool usage. Our dataset is constructed through a novel four-stage data engine: 1) We first curate publicly available multimodal datasets containing question-answer pairs; 2) Then, leveraging GPT-4o, we generate rationales for the original question-answer pairs and dynamically integrate API calls and Retrieval Augmented Generation (RAG) information through a multi-turn paradigm; 3) Furthermore, we refine the rationales through reflection to ensure logical consistency and accuracy, creating a multi-turn dialogue dataset with both Rationale and Reflection (RR); 4) Finally, to enhance efficiency, we optionally compress multi-turn dialogues into a One-turn Rationale and Reflection (ORR) format. By fine-tuning open-source multimodal models on the MMAT-1M, we observe significant performance gains. For instance, the InternVL2.5-8B-RR model achieves an average improvement of 2.7% across eight public benchmarks and 8.8% on the RAG benchmark Dyn-VQA, demonstrating the dataset's effectiveness in enhancing multimodal reasoning and tool-based capabilities. The dataset is publicly available at https://github.com/VIS-MPU-Agent/MMAT-1M.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Game-Based Multi-Agent Decision-Making for Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2507.21941</link>
<guid>https://arxiv.org/abs/2507.21941</guid>
<content:encoded><![CDATA[
arXiv:2507.21941v1 Announce Type: new 
Abstract: This paper develops a game-theoretic decision-making framework for autonomous driving in multi-agent scenarios. A novel hierarchical game-based decision framework is developed for the ego vehicle. This framework features an interaction graph, which characterizes the interaction relationships between the ego and its surrounding traffic agents (including AVs, human driven vehicles, pedestrians, and bicycles, and others), and enables the ego to smartly select a limited number of agents as its game players. Compared to the standard multi-player games, where all surrounding agents are considered as game players, the hierarchical game significantly reduces the computational complexity. In addition, compared to pairwise games, the most popular approach in the literature, the hierarchical game promises more efficient decisions for the ego (in terms of less unnecessary waiting and yielding). To further reduce the computational cost, we then propose an improved hierarchical game, which decomposes the hierarchical game into a set of sub-games. Decision safety and efficiency are analyzed in both hierarchical games. Comprehensive simulation studies are conducted to verify the effectiveness of the proposed frameworks, with an intersection-crossing scenario as a case study.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MapAgent: Trajectory-Constructed Memory-Augmented Planning for Mobile Task Automation</title>
<link>https://arxiv.org/abs/2507.21953</link>
<guid>https://arxiv.org/abs/2507.21953</guid>
<content:encoded><![CDATA[
arXiv:2507.21953v1 Announce Type: new 
Abstract: The recent advancement of autonomous agents powered by Large Language Models (LLMs) has demonstrated significant potential for automating tasks on mobile devices through graphical user interfaces (GUIs). Despite initial progress, these agents still face challenges when handling complex real-world tasks. These challenges arise from a lack of knowledge about real-life mobile applications in LLM-based agents, which may lead to ineffective task planning and even cause hallucinations. To address these challenges, we propose a novel LLM-based agent framework called MapAgent that leverages memory constructed from historical trajectories to augment current task planning. Specifically, we first propose a trajectory-based memory mechanism that transforms task execution trajectories into a reusable and structured page-memory database. Each page within a trajectory is extracted as a compact yet comprehensive snapshot, capturing both its UI layout and functional context. Secondly, we introduce a coarse-to-fine task planning approach that retrieves relevant pages from the memory database based on similarity and injects them into the LLM planner to compensate for potential deficiencies in understanding real-world app scenarios, thereby achieving more informed and context-aware task planning. Finally, planned tasks are transformed into executable actions through a task executor supported by a dual-LLM architecture, ensuring effective tracking of task progress. Experimental results in real-world scenarios demonstrate that MapAgent achieves superior performance to existing methods. The code will be open-sourced to support further research.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Cognitive Synergy in LLM-Based Multi-Agent Systems: Integrating Theory of Mind and Critical Evaluation</title>
<link>https://arxiv.org/abs/2507.21969</link>
<guid>https://arxiv.org/abs/2507.21969</guid>
<content:encoded><![CDATA[
arXiv:2507.21969v1 Announce Type: new 
Abstract: Recently, the field of Multi-Agent Systems (MAS) has gained popularity as researchers are trying to develop artificial intelligence capable of efficient collective reasoning. Agents based on Large Language Models (LLMs) perform well in isolated tasks, yet struggle with higher-order cognition required for adaptive collaboration. Human teams achieve synergy not only through knowledge sharing, but also through recursive reasoning, structured critique, and the ability to infer others' mental states. Current artificial systems lack these essential mechanisms, limiting their ability to engage in sophisticated collective reasoning. This work explores cognitive processes that enable effective collaboration, focusing on adaptive theory of mind (ToM) and systematic critical evaluation. We investigate three key questions. First, how does the ability to model others' perspectives enhance coordination and reduce redundant reasoning? Second, to what extent does structured critique improve reasoning quality by identifying logical gaps and mitigating biases? Third, the interplay of these mechanisms can lead to emergent cognitive synergy, where the collective intelligence of the system exceeds the sum of its parts. Through an empirical case study on complex decision making, we show that the integration of these cognitive mechanisms leads to more coherent, adaptive, and rigorous agent interactions. This article contributes to the field of cognitive science and AI research by presenting a structured framework that emulates human-like collaborative reasoning MAS. It highlights the significance of dynamic ToM and critical evaluation in advancing multi-agent systems' ability to tackle complex, real-world challenges.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UI-AGILE: Advancing GUI Agents with Effective Reinforcement Learning and Precise Inference-Time Grounding</title>
<link>https://arxiv.org/abs/2507.22025</link>
<guid>https://arxiv.org/abs/2507.22025</guid>
<content:encoded><![CDATA[
arXiv:2507.22025v1 Announce Type: new 
Abstract: The emergence of Multimodal Large Language Models (MLLMs) has driven significant advances in Graphical User Interface (GUI) agent capabilities. Nevertheless, existing GUI agent training and inference techniques still suffer from a dilemma for reasoning designs, ineffective reward, and visual noise. To address these issues, we introduce UI-AGILE, a comprehensive framework enhancing GUI agents at both the training and inference stages. For training, we propose a suite of improvements to the Supervised Fine-Tuning (SFT) process: 1) a Continuous Reward function to incentivize high-precision grounding; 2) a "Simple Thinking" reward to balance planning with speed and grounding accuracy; and 3) a Cropping-based Resampling strategy to mitigate the sparse reward problem and improve learning on complex tasks. For inference, we present Decomposed Grounding with Selection, a novel method that dramatically improves grounding accuracy on high-resolution displays by breaking the image into smaller, manageable parts. Experiments show that UI-AGILE achieves the state-of-the-art performance on two benchmarks ScreenSpot-Pro and ScreenSpot-v2. For instance, using both our proposed training and inference enhancement methods brings 23% grounding accuracy improvement over the best baseline on ScreenSpot-Pro.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Seeing to Experiencing: Scaling Navigation Foundation Models with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.22028</link>
<guid>https://arxiv.org/abs/2507.22028</guid>
<content:encoded><![CDATA[
arXiv:2507.22028v1 Announce Type: new 
Abstract: Navigation foundation models trained on massive webscale data enable agents to generalize across diverse environments and embodiments. However, these models trained solely on offline data, often lack the capacity to reason about the consequences of their actions or adapt through counterfactual understanding. They thus face significant limitations in the real-world urban navigation where interactive and safe behaviors, such as avoiding obstacles and moving pedestrians, are critical. To tackle these challenges, we introduce the Seeing-to-Experiencing framework to scale the capability of navigation foundation models with reinforcement learning. S2E combines the strengths of pre-training on videos and post-training through RL. It maintains the generalizability acquired from large-scale real-world videos while enhancing its interactivity through RL in simulation environments. Specifically, we introduce two innovations: an Anchor-Guided Distribution Matching strategy, which stabilizes learning and models diverse motion patterns through anchor-based supervision; and a Residual-Attention Module, which obtains reactive behaviors from simulation environments without erasing the model's pretrained knowledge. Moreover, we establish a comprehensive end-to-end evaluation benchmark, NavBench-GS, built on photorealistic 3DGS reconstructions of real-world scenes that incorporate physical interactions. It can systematically assess the generalizability and safety of navigation foundation models. Extensive experiments show that S2E mitigates the diminishing returns often seen when scaling with offline data alone. We perform a thorough analysis of the benefits of Reinforcement Learning compared to Supervised Fine-Tuning in the context of post-training for robot learning. Our findings emphasize the crucial role of integrating interactive online experiences to effectively scale foundation models in Robotics.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UserBench: An Interactive Gym Environment for User-Centric Agents</title>
<link>https://arxiv.org/abs/2507.22034</link>
<guid>https://arxiv.org/abs/2507.22034</guid>
<content:encoded><![CDATA[
arXiv:2507.22034v1 Announce Type: new 
Abstract: Large Language Models (LLMs)-based agents have made impressive progress in reasoning and tool use, enabling them to solve complex tasks. However, their ability to proactively collaborate with users, especially when goals are vague, evolving, or indirectly expressed, remains underexplored. To address this gap, we introduce UserBench, a user-centric benchmark designed to evaluate agents in multi-turn, preference-driven interactions. UserBench features simulated users who start with underspecified goals and reveal preferences incrementally, requiring agents to proactively clarify intent and make grounded decisions with tools. Our evaluation of leading open- and closed-source LLMs reveals a significant disconnect between task completion and user alignment. For instance, models provide answers that fully align with all user intents only 20% of the time on average, and even the most advanced models uncover fewer than 30% of all user preferences through active interaction. These results highlight the challenges of building agents that are not just capable task executors, but true collaborative partners. UserBench offers an interactive environment to measure and advance this critical capability.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Validating Generative Agent-Based Models of Social Norm Enforcement: From Replication to Novel Predictions</title>
<link>https://arxiv.org/abs/2507.22049</link>
<guid>https://arxiv.org/abs/2507.22049</guid>
<content:encoded><![CDATA[
arXiv:2507.22049v1 Announce Type: new 
Abstract: As large language models (LLMs) advance, there is growing interest in using them to simulate human social behavior through generative agent-based modeling (GABM). However, validating these models remains a key challenge. We present a systematic two-stage validation approach using social dilemma paradigms from psychological literature, first identifying the cognitive components necessary for LLM agents to reproduce known human behaviors in mixed-motive settings from two landmark papers, then using the validated architecture to simulate novel conditions. Our model comparison of different cognitive architectures shows that both persona-based individual differences and theory of mind capabilities are essential for replicating third-party punishment (TPP) as a costly signal of trustworthiness. For the second study on public goods games, this architecture is able to replicate an increase in cooperation from the spread of reputational information through gossip. However, an additional strategic component is necessary to replicate the additional boost in cooperation rates in the condition that allows both ostracism and gossip. We then test novel predictions for each paper with our validated generative agents. We find that TPP rates significantly drop in settings where punishment is anonymous, yet a substantial amount of TPP persists, suggesting that both reputational and intrinsic moral motivations play a role in this behavior. For the second paper, we introduce a novel intervention and see that open discussion periods before rounds of the public goods game further increase contributions, allowing groups to develop social norms for cooperation. This work provides a framework for validating generative agent models while demonstrating their potential to generate novel and testable insights into human social behavior.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeepSieve: Information Sieving via LLM-as-a-Knowledge-Router</title>
<link>https://arxiv.org/abs/2507.22050</link>
<guid>https://arxiv.org/abs/2507.22050</guid>
<content:encoded><![CDATA[
arXiv:2507.22050v1 Announce Type: new 
Abstract: Large Language Models (LLMs) excel at many reasoning tasks but struggle with knowledge-intensive queries due to their inability to dynamically access up-to-date or domain-specific information. Retrieval-Augmented Generation (RAG) has emerged as a promising solution, enabling LLMs to ground their responses in external sources. However, existing RAG methods lack fine-grained control over both the query and source sides, often resulting in noisy retrieval and shallow reasoning. In this work, we introduce DeepSieve, an agentic RAG framework that incorporates information sieving via LLM-as-a-knowledge-router. DeepSieve decomposes complex queries into structured sub-questions and recursively routes each to the most suitable knowledge source, filtering irrelevant information through a multi-stage distillation process. Our design emphasizes modularity, transparency, and adaptability, leveraging recent advances in agentic system design. Experiments on multi-hop QA tasks across heterogeneous sources demonstrate improved reasoning depth, retrieval precision, and interpretability over conventional RAG approaches.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multiscale geometrical and topological learning in the analysis of soft matter collective dynamics</title>
<link>https://arxiv.org/abs/2507.21265</link>
<guid>https://arxiv.org/abs/2507.21265</guid>
<content:encoded><![CDATA[
arXiv:2507.21265v1 Announce Type: cross 
Abstract: Understanding the behavior and evolution of a dynamical many-body system by analyzing patterns in their experimentally captured images is a promising method relevant for a variety of living and non-living self-assembled systems. The arrays of moving liquid crystal skyrmions studied here are a representative example of hierarchically organized materials that exhibit complex spatiotemporal dynamics driven by multiscale processes. Joint geometric and topological data analysis (TDA) offers a powerful framework for investigating such systems by capturing the underlying structure of the data at multiple scales. In the TDA approach, we introduce the $\Psi$-function, a robust numerical topological descriptor related to both the spatiotemporal changes in the size and shape of individual topological solitons and the emergence of regions with their different spatial organization. The geometric method based on the analysis of vector fields generated from images of skyrmion ensembles offers insights into the nonlinear physical mechanisms of the system's response to external stimuli and provides a basis for comparison with theoretical predictions. The methodology presented here is very general and can provide a characterization of system behavior both at the level of individual pattern-forming agents and as a whole, allowing one to relate the results of image data analysis to processes occurring in a physical, chemical, or biological system in the real world.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Modeling of Vehicular Maneuvers and Interactions at Urban Junctions</title>
<link>https://arxiv.org/abs/2507.21547</link>
<guid>https://arxiv.org/abs/2507.21547</guid>
<content:encoded><![CDATA[
arXiv:2507.21547v1 Announce Type: cross 
Abstract: Modeling and evaluation of automated vehicles (AVs) in mixed-autonomy traffic is essential prior to their safe and efficient deployment. This is especially important at urban junctions where complex multi-agent interactions occur. Current approaches for modeling vehicular maneuvers and interactions at urban junctions have limitations in formulating non-cooperative interactions and vehicle dynamics within a unified mathematical framework. Previous studies either assume predefined paths or rely on cooperation and central controllability, limiting their realism and applicability in mixed-autonomy traffic. This paper addresses these limitations by proposing a modeling framework for trajectory planning and decentralized vehicular control at urban junctions. The framework employs a bi-level structure where the upper level generates kinematically feasible reference trajectories using an efficient graph search algorithm with a custom heuristic function, while the lower level employs a predictive controller for trajectory tracking and optimization. Unlike existing approaches, our framework does not require central controllability or knowledge sharing among vehicles. The vehicle kinematics are explicitly incorporated at both levels, and acceleration and steering angle are used as control variables. This intuitive formulation facilitates analysis of traffic efficiency, environmental impacts, and motion comfort. The framework's decentralized structure accommodates operational and stochastic elements, such as vehicles' detection range, perception uncertainties, and reaction delay, making the model suitable for safety analysis. Numerical and simulation experiments across diverse scenarios demonstrate the framework's capability in modeling accurate and realistic vehicular maneuvers and interactions at various urban junctions, including unsignalized intersections and roundabouts.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can large language models assist choice modelling? Insights into prompting strategies and current models capabilities</title>
<link>https://arxiv.org/abs/2507.21790</link>
<guid>https://arxiv.org/abs/2507.21790</guid>
<content:encoded><![CDATA[
arXiv:2507.21790v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) are widely used to support various workflows across different disciplines, yet their potential in choice modelling remains relatively unexplored. This work examines the potential of LLMs as assistive agents in the specification and, where technically feasible, estimation of Multinomial Logit models. We implement a systematic experimental framework involving thirteen versions of six leading LLMs (ChatGPT, Claude, DeepSeek, Gemini, Gemma, and Llama) evaluated under five experimental configurations. These configurations vary along three dimensions: modelling goal (suggesting vs. suggesting and estimating MNLs); prompting strategy (Zero-Shot vs. Chain-of-Thoughts); and information availability (full dataset vs. data dictionary only). Each LLM-suggested specification is implemented, estimated, and evaluated based on goodness-of-fit metrics, behavioural plausibility, and model complexity. Findings reveal that proprietary LLMs can generate valid and behaviourally sound utility specifications, particularly when guided by structured prompts. Open-weight models such as Llama and Gemma struggled to produce meaningful specifications. Claude 4 Sonnet consistently produced the best-fitting and most complex models, while GPT models suggested models with robust and stable modelling outcomes. Some LLMs performed better when provided with just data dictionary, suggesting that limiting raw data access may enhance internal reasoning capabilities. Among all LLMs, GPT o3 was uniquely capable of correctly estimating its own specifications by executing self-generated code. Overall, the results demonstrate both the promise and current limitations of LLMs as assistive agents in choice modelling, not only for model specification but also for supporting modelling decision and estimation, and provide practical guidance for integrating these tools into choice modellers' workflows.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Stratified Space Structure of an RL Game with the Volume Growth Transform</title>
<link>https://arxiv.org/abs/2507.22010</link>
<guid>https://arxiv.org/abs/2507.22010</guid>
<content:encoded><![CDATA[
arXiv:2507.22010v1 Announce Type: cross 
Abstract: In this work, we explore the structure of the embedding space of a transformer model trained for playing a particular reinforcement learning (RL) game. Specifically, we investigate how a transformer-based Proximal Policy Optimization (PPO) model embeds visual inputs in a simple environment where an agent must collect "coins" while avoiding dynamic obstacles consisting of "spotlights." By adapting Robinson et al.'s study of the volume growth transform for LLMs to the RL setting, we find that the token embedding space for our visual coin collecting game is also not a manifold, and is better modeled as a stratified space, where local dimension can vary from point to point. We further strengthen Robinson's method by proving that fairly general volume growth curves can be realized by stratified spaces. Finally, we carry out an analysis that suggests that as an RL agent acts, its latent representation alternates between periods of low local dimension, while following a fixed sub-strategy, and bursts of high local dimension, where the agent achieves a sub-goal (e.g., collecting an object) or where the environmental complexity increases (e.g., more obstacles appear). Consequently, our work suggests that the distribution of dimensions in a stratified latent space may provide a new geometric indicator of complexity for RL games.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cyst-X: AI-Powered Pancreatic Cancer Risk Prediction from Multicenter MRI in Centralized and Federated Learning</title>
<link>https://arxiv.org/abs/2507.22017</link>
<guid>https://arxiv.org/abs/2507.22017</guid>
<content:encoded><![CDATA[
arXiv:2507.22017v1 Announce Type: cross 
Abstract: Pancreatic cancer is projected to become the second-deadliest malignancy in Western countries by 2030, highlighting the urgent need for better early detection. Intraductal papillary mucinous neoplasms (IPMNs), key precursors to pancreatic cancer, are challenging to assess with current guidelines, often leading to unnecessary surgeries or missed malignancies. We present Cyst-X, an AI framework that predicts IPMN malignancy using multicenter MRI data, leveraging MRI's superior soft tissue contrast over CT. Trained on 723 T1- and 738 T2-weighted scans from 764 patients across seven institutions, our models (AUC=0.82) significantly outperform both Kyoto guidelines (AUC=0.75) and expert radiologists. The AI-derived imaging features align with known clinical markers and offer biologically meaningful insights. We also demonstrate strong performance in a federated learning setting, enabling collaborative training without sharing patient data. To promote privacy-preserving AI development and improve IPMN risk stratification, the Cyst-X dataset is released as the first large-scale, multi-center pancreatic cysts MRI dataset.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hedonic Seat Arrangement Problems</title>
<link>https://arxiv.org/abs/2002.10898</link>
<guid>https://arxiv.org/abs/2002.10898</guid>
<content:encoded><![CDATA[
arXiv:2002.10898v2 Announce Type: replace 
Abstract: In this paper, we study a variant of hedonic games, called \textsc{Seat Arrangement}. The model is defined by a bijection from agents with preferences for each other to vertices in a graph $G$. The utility of an agent depends on the neighbors assigned in the graph. More precisely, it is the sum over all neighbors of the preferences that the agent has towards the agent assigned to the neighbor. We first consider the price of stability and fairness for different classes of preferences. In particular, we show that there is an instance such that the price of fairness ({\sf PoF}) is unbounded in general. Moreover, we show an upper bound $\tilde{d}(G)$ and an almost tight lower bound $\tilde{d}(G)-1/4$ of {\sf PoF}, where $\tilde{d}(G)$ is the average degree of an input graph. Then we investigate the computational complexity of problems to find certain ``good'' seat arrangements, say \textsc{Utilitarian Arrangement}, \textsc{Egalitarian Arrangement}, \textsc{Stable Arrangement}, and \textsc{Envy-free Arrangement}. We give dichotomies of computational complexity of four \textsc{Seat Arrangement} problems from the perspective of the maximum order of connected components in an input graph. For the parameterized complexity, \textsc{Utilitarian Arrangement} can be solved in time $n^{O(\gamma)}$, while it cannot be solved in time $f(\gamma)n^{o(\gamma)}$ under ETH, where $n$ is the number of agents and $\gamma$ is the vertex cover number of an input graph. Moreover, we show that \textsc{Egalitarian Arrangement} and \textsc{Envy-free Arrangement} are weakly NP-hard even on graphs of bounded vertex cover number. Finally, we prove that determining whether a stable arrangement can be obtained from a given arrangement by $k$ swaps is W[1]-hard when parameterized by $k+\gamma$, whereas it can be solved in time $n^{O(k)}$.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A finite time analysis of distributed Q-learning</title>
<link>https://arxiv.org/abs/2405.14078</link>
<guid>https://arxiv.org/abs/2405.14078</guid>
<content:encoded><![CDATA[
arXiv:2405.14078v2 Announce Type: replace 
Abstract: Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in interest, fueled by the empirical success achieved in applications of single-agent reinforcement learning (RL). In this study, we consider a distributed Q-learning scenario, wherein a number of agents cooperatively solve a sequential decision making problem without access to the central reward function which is an average of the local rewards. In particular, we study finite-time analysis of a distributed Q-learning algorithm, and provide a new sample complexity result of $\tilde{\mathcal{O}}\left( \min\left\{\frac{1}{\epsilon^2}\frac{t_{\text{mix}}}{(1-\gamma)^6 d_{\min}^4 } ,\frac{1}{\epsilon}\frac{\sqrt{|\gS||\gA|}}{(1-\sigma_2(\boldsymbol{W}))(1-\gamma)^4 d_{\min}^3} \right\}\right)$ under tabular lookup
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IRASim: A Fine-Grained World Model for Robot Manipulation</title>
<link>https://arxiv.org/abs/2406.14540</link>
<guid>https://arxiv.org/abs/2406.14540</guid>
<content:encoded><![CDATA[
arXiv:2406.14540v2 Announce Type: replace 
Abstract: World models allow autonomous agents to plan and explore by predicting the visual outcomes of different actions. However, for robot manipulation, it is challenging to accurately model the fine-grained robot-object interaction within the visual space using existing methods which overlooks precise alignment between each action and the corresponding frame. In this paper, we present IRASim, a novel world model capable of generating videos with fine-grained robot-object interaction details, conditioned on historical observations and robot action trajectories. We train a diffusion transformer and introduce a novel frame-level action-conditioning module within each transformer block to explicitly model and strengthen the action-frame alignment. Extensive experiments show that: (1) the quality of the videos generated by our method surpasses all the baseline methods and scales effectively with increased model size and computation; (2) policy evaluations using IRASim exhibit a strong correlation with those using the ground-truth simulator, highlighting its potential to accelerate real-world policy evaluation; (3) testing-time scaling through model-based planning with IRASim significantly enhances policy performance, as evidenced by an improvement in the IoU metric on the Push-T benchmark from 0.637 to 0.961; (4) IRASim provides flexible action controllability, allowing virtual robotic arms in datasets to be controlled via a keyboard or VR controller.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Effects of Vote Delegation in Blockchains: Who Wins?</title>
<link>https://arxiv.org/abs/2408.05410</link>
<guid>https://arxiv.org/abs/2408.05410</guid>
<content:encoded><![CDATA[
arXiv:2408.05410v2 Announce Type: replace 
Abstract: This paper investigates which alternative benefits from vote delegation in binary collective decisions within blockchains. We begin by examining two extreme cases of voting weight distributions: Equal-Weight (EW), where each voter has equal voting weight, and Dominant-Weight (DW), where a single voter holds a majority of the voting weights before any delegation occurs. We show that vote delegation tends to benefit the ex-ante minority under EW, i.e., the alternative with a lower initial probability of winning. The converse holds under DW distribution. Through numerical simulations, we extend our findings to arbitrary voting weight distributions, showing that vote delegation benefits the ex-ante majority when it leads to a more balanced distribution of voting weights. Finally, in large communities where all agents have equal voting weight, vote delegation has a negligible impact on the outcome. As a practical consequence, vote delegation can be beneficial for blockchains with highly unbalanced voting rights, but not for those with balanced rights. In decentralized finance (DeFi), vote delegation is widely adopted to streamline governance and increase participation. However, it remains unclear when delegation actually aligns outcomes with community preferences.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strategist: Self-improvement of LLM Decision Making via Bi-Level Tree Search</title>
<link>https://arxiv.org/abs/2408.10635</link>
<guid>https://arxiv.org/abs/2408.10635</guid>
<content:encoded><![CDATA[
arXiv:2408.10635v3 Announce Type: replace 
Abstract: Traditional reinforcement learning and planning typically requires vast amounts of data and training to develop effective policies. In contrast, large language models (LLMs) exhibit strong generalization and zero-shot capabilities, but struggle with tasks that require detailed planning and decision-making in complex action spaces. We introduce STRATEGIST, a novel approach that integrates the strengths of both methods. Our approach leverages LLMs to search and update high-level strategies (as text), which are then refined and executed by low-level Monte Carlo Tree Search (MCTS). STRATEGIST is a generalizable framework to optimize the strategy through population-based self-play simulations without the need for any training data. We demonstrate the effectiveness of STRATEGIST in learning optimal strategies for competitive, multi-turn games with partial information, including Game of Pure Strategy (GOPS) and multi-agent, hidden-identity discussion games like The Resistance: Avalon. Our results show that agents equipped with STRATEGIST outperform those trained with traditional RL methods, other LLM-based skill acquisition techniques, pre-existing LLM agents across both game environments and achieves comparable performance against human players.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulated patient systems are intelligent when powered by large language model-based AI agents</title>
<link>https://arxiv.org/abs/2409.18924</link>
<guid>https://arxiv.org/abs/2409.18924</guid>
<content:encoded><![CDATA[
arXiv:2409.18924v3 Announce Type: replace 
Abstract: Simulated patient systems play an important role in modern medical education and research, providing safe, integrative medical training environments and supporting clinical decision-making simulations. We developed AIPatient, an intelligent simulated patient system powered by large language model-based AI agents. The system incorporates the Retrieval Augmented Generation (RAG) framework, powered by six task-specific LLM-based AI agents for complex reasoning. For simulation reality, the system is also powered by the AIPatient KG (Knowledge Graph), built with de-identified real patient data from the Medical Information Mart for Intensive Care (MIMIC)-III database. Primary outcomes showcase the system's intelligence, including the system's accuracy in Electronic Record (EHR)-based medical Question Answering (QA), readability, robustness, and stability. The system achieved a QA accuracy of 94.15% when all six AI agents present, surpassing benchmarks with partial or no agent integration. Its knowledgebase demonstrated high validity (F1 score=0.89). Readability scores showed median Flesch Reading Ease at 77.23 and median Flesch Kincaid Grade at 5.6, indicating accessibility to all medical professionals. Robustness and stability were confirmed with non-significant variance (ANOVA F-value=0.6126, p > 0.1; F-value=0.782, p > 0.1). A user study with medical students further demonstrated that AIPatient offers high fidelity, strong usability, and effective educational value, performing comparably or better than human-simulated patients in medical history-taking scenarios. The promising intelligence of the AIPatient system highlights its potential to support a wide range of applications, including medical education, model evaluation, and system integration.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intrinsic Barriers and Practical Pathways for Human-AI Alignment: An Agreement-Based Complexity Analysis</title>
<link>https://arxiv.org/abs/2502.05934</link>
<guid>https://arxiv.org/abs/2502.05934</guid>
<content:encoded><![CDATA[
arXiv:2502.05934v2 Announce Type: replace 
Abstract: We formalize AI alignment as a multi-objective optimization problem called $\langle M,N,\varepsilon,\delta\rangle$-agreement that generalizes prior approaches with fewer assumptions, in which a set of $N$ agents (including humans) must reach approximate ($\varepsilon$) agreement across $M$ candidate objectives with probability at least $1-\delta$. Using communication complexity, we prove an information-theoretic lower bound demonstrating that once either $M$ or $N$ is large enough, no interaction or rationality can avoid intrinsic alignment overheads. This barrier establishes rigorous intrinsic limits to alignment \emph{itself}, not merely to specific methods, clarifying a crucial ``no free lunch'' principle: encoding ``all human values'' inevitably leads to misalignment, requiring future methods to explicitly manage complexity through consensus-driven reduction or prioritization of objectives. Complementing this impossibility result, we provide explicit algorithms achieving alignment under both computationally unbounded and bounded rationality with noisy messages. Even in these best-case scenarios where alignment to arbitrary precision is theoretically guaranteed, our analysis identifies three critical scalability barriers: the number of tasks ($M$), agents ($N$), and task state space size ($D$); thereby highlighting fundamental complexity-theoretic constraints and providing guidelines for safer, scalable human-AI collaboration.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RANa: Retrieval-Augmented Navigation</title>
<link>https://arxiv.org/abs/2504.03524</link>
<guid>https://arxiv.org/abs/2504.03524</guid>
<content:encoded><![CDATA[
arXiv:2504.03524v2 Announce Type: replace 
Abstract: Methods for navigation based on large-scale learning typically treat each episode as a new problem, where the agent is spawned with a clean memory in an unknown environment. While these generalization capabilities to an unknown environment are extremely important, we claim that, in a realistic setting, an agent should have the capacity of exploiting information collected during earlier robot operations. We address this by introducing a new retrieval-augmented agent, trained with RL, capable of querying a database collected from previous episodes in the same environment and learning how to integrate this additional context information. We introduce a unique agent architecture for the general navigation task, evaluated on ImageNav, Instance-ImageNav and ObjectNav. Our retrieval and context encoding methods are data-driven and employ vision foundation models (FM) for both semantic and geometric understanding. We propose new benchmarks for these settings and we show that retrieval allows zero-shot transfer across tasks and environments while significantly improving performance.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Dual Personas of Social Media Bots</title>
<link>https://arxiv.org/abs/2504.12498</link>
<guid>https://arxiv.org/abs/2504.12498</guid>
<content:encoded><![CDATA[
arXiv:2504.12498v2 Announce Type: replace 
Abstract: Social media bots are AI agents that participate in online conversations. Most studies focus on the general bot and the malicious nature of these agents. However, bots have many different personas, each specialized towards a specific behavioral or content trait. Neither are bots singularly bad, because they are used for both good and bad information dissemination. In this article, we introduce fifteen agent personas of social media bots. These personas have two main categories: Content-Based Bot Persona and Behavior-Based Bot Persona. We also form yardsticks of the good-bad duality of the bots, elaborating on metrics of good and bad bot agents. Our work puts forth a guideline to inform bot detection regulation, emphasizing that policies should focus on how these agents are employed, rather than collectively terming bot agents as bad.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Pareto-Optimal Rewards from Noisy Preferences: A Framework for Multi-Objective Inverse Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.11864</link>
<guid>https://arxiv.org/abs/2505.11864</guid>
<content:encoded><![CDATA[
arXiv:2505.11864v3 Announce Type: replace 
Abstract: As generative agents become increasingly capable, alignment of their behavior with complex human values remains a fundamental challenge. Existing approaches often simplify human intent through reduction to a scalar reward, overlooking the multi-faceted nature of human feedback. In this work, we introduce a theoretical framework for preference-based Multi-Objective Inverse Reinforcement Learning (MO-IRL), where human preferences are modeled as latent vector-valued reward functions. We formalize the problem of recovering a Pareto-optimal reward representation from noisy preference queries and establish conditions for identifying the underlying multi-objective structure. We derive tight sample complexity bounds for recovering $\epsilon$-approximations of the Pareto front and introduce a regret formulation to quantify suboptimality in this multi-objective setting. Furthermore, we propose a provably convergent algorithm for policy optimization using preference-inferred reward cones. Our results bridge the gap between practical alignment techniques and theoretical guarantees, providing a principled foundation for learning aligned behaviors in a high-dimension and value-pluralistic environment.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ManiTaskGen: A Comprehensive Task Generator for Benchmarking and Improving Vision-Language Agents on Embodied Decision-Making</title>
<link>https://arxiv.org/abs/2505.20726</link>
<guid>https://arxiv.org/abs/2505.20726</guid>
<content:encoded><![CDATA[
arXiv:2505.20726v2 Announce Type: replace 
Abstract: Building embodied agents capable of accomplishing arbitrary tasks is a core objective towards achieving embodied artificial general intelligence (E-AGI). While recent work has advanced such general robot policies, their training and evaluation are often limited to tasks within specific scenes, involving restricted instructions and scenarios. Existing benchmarks also typically rely on manual annotation of limited tasks in a few scenes. We argue that exploring the full spectrum of feasible tasks within any given scene is crucial, as they provide both extensive benchmarks for evaluation and valuable resources for agent improvement. Towards this end, we introduce ManiTaskGen, a novel system that automatically generates comprehensive, diverse, feasible mobile manipulation tasks for any given scene. The generated tasks encompass both process-based, specific instructions (e.g., "move object from X to Y") and outcome-based, abstract instructions (e.g., "clear the table"). We apply ManiTaskGen to both simulated and real-world scenes, demonstrating the validity and diversity of the generated tasks. We then leverage these tasks to automatically construct benchmarks, thoroughly evaluating the embodied decision-making capabilities of agents built upon existing vision-language models (VLMs). Furthermore, we propose a simple yet effective method that utilizes ManiTaskGen tasks to enhance embodied decision-making. Overall, this work presents a universal task generation framework for arbitrary scenes, facilitating both benchmarking and improvement of embodied decision-making agents.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Generation of Diverse Courses of Actions for Multi-Agent Operations using Binary Optimization and Graph Learning</title>
<link>https://arxiv.org/abs/2506.20031</link>
<guid>https://arxiv.org/abs/2506.20031</guid>
<content:encoded><![CDATA[
arXiv:2506.20031v2 Announce Type: replace 
Abstract: Operations in disaster response, search \& rescue, and military missions that involve multiple agents demand automated processes to support the planning of the courses of action (COA). Moreover, traverse-affecting changes in the environment (rain, snow, blockades, etc.) may impact the expected performance of a COA, making it desirable to have a pool of COAs that are diverse in task distributions across agents. Further, variations in agent capabilities, which could be human crews and/or autonomous systems, present practical opportunities and computational challenges to the planning process. This paper presents a new theoretical formulation and computational framework to generate such diverse pools of COAs for operations with soft variations in agent-task compatibility. Key to the problem formulation is a graph abstraction of the task space and the pool of COAs itself to quantify its diversity. Formulating the COAs as a centralized multi-robot task allocation problem, a genetic algorithm is used for (order-ignoring) allocations of tasks to each agent that jointly maximize diversity within the COA pool and overall compatibility of the agent-task mappings. A graph neural network is trained using a policy gradient approach to then perform single agent task sequencing in each COA, which maximizes completion rates adaptive to task features. Our tests of the COA generation process in a simulated environment demonstrate significant performance gain over a random walk baseline, small optimality gap in task sequencing, and execution time of about 50 minutes to plan up to 20 COAs for 5 agent/100 task operations.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vector Cost Bimatrix Games with Applications to Autonomous Racing</title>
<link>https://arxiv.org/abs/2507.05171</link>
<guid>https://arxiv.org/abs/2507.05171</guid>
<content:encoded><![CDATA[
arXiv:2507.05171v3 Announce Type: replace 
Abstract: We formulate a vector cost alternative to the scalarization method for weighting and combining multi-objective costs. The algorithm produces solutions to bimatrix games that are simultaneously pure, unique Nash equilibria and Pareto optimal with guarantees for avoiding worst case outcomes. We achieve this by enforcing exact potential game constraints to guide cost adjustments towards equilibrium, while minimizing the deviation from the original cost structure. The magnitude of this adjustment serves as a metric for differentiating between Pareto optimal solutions. We implement this approach in a racing competition between agents with heterogeneous cost structures, resulting in fewer collision incidents with a minimal decrease in performance. Code is available at https://github.com/toazbenj/race_simulation.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Critiques of World Models</title>
<link>https://arxiv.org/abs/2507.05169</link>
<guid>https://arxiv.org/abs/2507.05169</guid>
<content:encoded><![CDATA[
arXiv:2507.05169v3 Announce Type: replace 
Abstract: World Model, the supposed algorithmic surrogate of the real-world environment which biological agents experience with and act upon, has been an emerging topic in recent years because of the rising needs to develop virtual agents with artificial (general) intelligence. There has been much debate on what a world model really is, how to build it, how to use it, and how to evaluate it. In this essay, starting from the imagination in the famed Sci-Fi classic Dune, and drawing inspiration from the concept of "hypothetical thinking" in psychology literature, we offer critiques of several schools of thoughts on world modeling, and argue the primary goal of a world model to be simulating all actionable possibilities of the real world for purposeful reasoning and acting. Building on the critiques, we propose a new architecture for a general-purpose world model, based on hierarchical, multi-level, and mixed continuous/discrete representations, and a generative and self-supervision learning framework, with an outlook of a Physical, Agentic, and Nested (PAN) AGI system enabled by such a model.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulating Human Behavior with the Psychological-mechanism Agent: Integrating Feeling, Thought, and Action</title>
<link>https://arxiv.org/abs/2507.19495</link>
<guid>https://arxiv.org/abs/2507.19495</guid>
<content:encoded><![CDATA[
arXiv:2507.19495v1 Announce Type: new 
Abstract: Generative agents have made significant progress in simulating human behavior, but existing frameworks often simplify emotional modeling and focus primarily on specific tasks, limiting the authenticity of the simulation. Our work proposes the Psychological-mechanism Agent (PSYA) framework, based on the Cognitive Triangle (Feeling-Thought-Action), designed to more accurately simulate human behavior. The PSYA consists of three core modules: the Feeling module (using a layer model of affect to simulate changes in short-term, medium-term, and long-term emotions), the Thought module (based on the Triple Network Model to support goal-directed and spontaneous thinking), and the Action module (optimizing agent behavior through the integration of emotions, needs and plans). To evaluate the framework's effectiveness, we conducted daily life simulations and extended the evaluation metrics to self-influence, one-influence, and group-influence, selection five classic psychological experiments for simulation. The results show that the PSYA framework generates more natural, consistent, diverse, and credible behaviors, successfully replicating human experimental outcomes. Our work provides a richer and more accurate emotional and cognitive modeling approach for generative agents and offers an alternative to human participants in psychological experiments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ChatMyopia: An AI Agent for Pre-consultation Education in Primary Eye Care Settings</title>
<link>https://arxiv.org/abs/2507.19498</link>
<guid>https://arxiv.org/abs/2507.19498</guid>
<content:encoded><![CDATA[
arXiv:2507.19498v1 Announce Type: new 
Abstract: Large language models (LLMs) show promise for tailored healthcare communication but face challenges in interpretability and multi-task integration particularly for domain-specific needs like myopia, and their real-world effectiveness as patient education tools has yet to be demonstrated. Here, we introduce ChatMyopia, an LLM-based AI agent designed to address text and image-based inquiries related to myopia. To achieve this, ChatMyopia integrates an image classification tool and a retrieval-augmented knowledge base built from literature, expert consensus, and clinical guidelines. Myopic maculopathy grading task, single question examination and human evaluations validated its ability to deliver personalized, accurate, and safe responses to myopia-related inquiries with high scalability and interpretability. In a randomized controlled trial (n=70, NCT06607822), ChatMyopia significantly improved patient satisfaction compared to traditional leaflets, enhancing patient education in accuracy, empathy, disease awareness, and patient-eyecare practitioner communication. These findings highlight ChatMyopia's potential as a valuable supplement to enhance patient education and improve satisfaction with medical services in primary eye care settings.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Swift-Sarsa: Fast and Robust Linear Control</title>
<link>https://arxiv.org/abs/2507.19539</link>
<guid>https://arxiv.org/abs/2507.19539</guid>
<content:encoded><![CDATA[
arXiv:2507.19539v1 Announce Type: new 
Abstract: Javed, Sharifnassab, and Sutton (2024) introduced a new algorithm for TD learning -- SwiftTD -- that augments True Online TD($\lambda$) with step-size optimization, a bound on the effective learning rate, and step-size decay. In their experiments SwiftTD outperformed True Online TD($\lambda$) and TD($\lambda$) on a variety of prediction tasks derived from Atari games, and its performance was robust to the choice of hyper-parameters. In this extended abstract we extend SwiftTD to work for control problems. We combine the key ideas behind SwiftTD with True Online Sarsa($\lambda$) to develop an on-policy reinforcement learning algorithm called $\textit{Swift-Sarsa}$.
  We propose a simple benchmark for linear on-policy control called the $\textit{operant conditioning benchmark}$. The key challenge in the operant conditioning benchmark is that a very small subset of input signals are relevant for decision making. The majority of the signals are noise sampled from a non-stationary distribution. To learn effectively, the agent must learn to differentiate between the relevant signals and the noisy signals, and minimize prediction errors by assigning credit to the weight parameters associated with the relevant signals.
  Swift-Sarsa, when applied to the operant conditioning benchmark, learned to assign credit to the relevant signals without any prior knowledge of the structure of the problem. It opens the door for solution methods that learn representations by searching over hundreds of millions of features in parallel without performance degradation due to noisy or bad features.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent WARPP: Workflow Adherence via Runtime Parallel Personalization</title>
<link>https://arxiv.org/abs/2507.19543</link>
<guid>https://arxiv.org/abs/2507.19543</guid>
<content:encoded><![CDATA[
arXiv:2507.19543v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly applied in task-oriented dialogue (TOD) systems but often struggle with long, conditional workflows that involve external tool calls and depend on user-specific information. We present Workflow Adherence via Runtime Parallel Personalization, or WARPP, a training-free, modular framework that combines multi-agent orchestration with runtime personalization to improve workflow adherence in LLM-based systems. By dynamically pruning conditional branches based on user attributes, the framework reduces reasoning overhead and narrows tool selection at runtime. WARPP deploys a parallelized architecture where a dedicated Personalizer agent operates alongside modular, domain-specific agents to dynamically tailor execution paths in real time. The framework is evaluated across five representative user intents of varying complexity within three domains: banking, flights, and healthcare. Our evaluation leverages synthetic datasets and LLM-powered simulated users to test scenarios with conditional dependencies. Our results demonstrate that WARPP outperforms both the non-personalized method and the ReAct baseline, achieving increasingly larger gains in parameter fidelity and tool accuracy as intent complexity grows, while also reducing average token usage, without any additional training.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Multi-Agent Economies: Enhancing the A2A Protocol with Ledger-Anchored Identities and x402 Micropayments for AI Agents</title>
<link>https://arxiv.org/abs/2507.19550</link>
<guid>https://arxiv.org/abs/2507.19550</guid>
<content:encoded><![CDATA[
arXiv:2507.19550v1 Announce Type: new 
Abstract: This research article presents a novel architecture to empower multi-agent economies by addressing two critical limitations of the emerging Agent2Agent (A2A) communication protocol: decentralized agent discoverability and agent-to-agent micropayments. By integrating distributed ledger technology (DLT), this architecture enables tamper-proof, on-chain publishing of AgentCards as smart contracts, providing secure and verifiable agent identities. The architecture further extends A2A with the x402 open standard, facilitating blockchain-agnostic, HTTP-based micropayments via the HTTP 402 status code. This enables autonomous agents to seamlessly discover, authenticate, and compensate each other across organizational boundaries. This work further presents a comprehensive technical implementation and evaluation, demonstrating the feasibility of DLT-based agent discovery and micropayments. The proposed approach lays the groundwork for secure, scalable, and economically viable multi-agent ecosystems, advancing the field of agentic AI toward trusted, autonomous economic interactions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MCP4EDA: LLM-Powered Model Context Protocol RTL-to-GDSII Automation with Backend Aware Synthesis Optimization</title>
<link>https://arxiv.org/abs/2507.19570</link>
<guid>https://arxiv.org/abs/2507.19570</guid>
<content:encoded><![CDATA[
arXiv:2507.19570v1 Announce Type: new 
Abstract: This paper presents MCP4EDA, the first Model Context Protocol server that enables Large Language Models (LLMs) to control and optimize the complete open-source RTL-to-GDSII design flow through natural language interaction. The system integrates Yosys synthesis, Icarus Verilog simulation, OpenLane place-and-route, GTKWave analysis, and KLayout visualization into a unified LLM-accessible interface, enabling designers to execute complex multi-tool EDA workflows conversationally via AI assistants such as Claude Desktop and Cursor IDE. The principal contribution is a backend-aware synthesis optimization methodology wherein LLMs analyze actual post-layout timing, power, and area metrics from OpenLane results to iteratively refine synthesis TCL scripts, establishing a closed-loop optimization system that bridges the traditional gap between synthesis estimates and physical implementation reality. In contrast to conventional flows that rely on wire-load models, this methodology leverages real backend performance data to guide synthesis parameter tuning, optimization sequence selection, and constraint refinement, with the LLM functioning as an intelligent design space exploration agent. Experimental evaluation on representative digital designs demonstrates 15-30% improvements in timing closure and 10-20% area reduction compared to default synthesis flows, establishing MCP4EDA as the first practical LLM-controlled end-to-end open-source EDA automation system. The code and demo are avaiable at: http://www.agent4eda.com/
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hypergames: Modeling Misaligned Perceptions and Nested Beliefs for Multi-agent Systems</title>
<link>https://arxiv.org/abs/2507.19593</link>
<guid>https://arxiv.org/abs/2507.19593</guid>
<content:encoded><![CDATA[
arXiv:2507.19593v1 Announce Type: new 
Abstract: Classical game-theoretic models typically assume rational agents, complete information, and common knowledge of payoffs - assumptions that are often violated in real-world MAS characterized by uncertainty, misaligned perceptions, and nested beliefs. To overcome these limitations, researchers have proposed extensions that incorporate models of cognitive constraints, subjective beliefs, and heterogeneous reasoning. Among these, hypergame theory extends the classical paradigm by explicitly modeling agents' subjective perceptions of the strategic scenario, known as perceptual games, in which agents may hold divergent beliefs about the structure, payoffs, or available actions. We present a systematic review of agent-compatible applications of hypergame theory, examining how its descriptive capabilities have been adapted to dynamic and interactive MAS contexts. We analyze 44 selected studies from cybersecurity, robotics, social simulation, communications, and general game-theoretic modeling. Building on a formal introduction to hypergame theory and its two major extensions - hierarchical hypergames and HNF - we develop agent-compatibility criteria and an agent-based classification framework to assess integration patterns and practical applicability. Our analysis reveals prevailing tendencies, including the prevalence of hierarchical and graph-based models in deceptive reasoning and the simplification of extensive theoretical frameworks in practical applications. We identify structural gaps, including the limited adoption of HNF-based models, the lack of formal hypergame languages, and unexplored opportunities for modeling human-agent and agent-agent misalignment. By synthesizing trends, challenges, and open research directions, this review provides a new roadmap for applying hypergame theory to enhance the realism and effectiveness of strategic modeling in dynamic multi-agent environments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Diversity and Interaction Quality of a Heterogeneous Multi-Agent System Applied to a Synchronization Problem</title>
<link>https://arxiv.org/abs/2507.19631</link>
<guid>https://arxiv.org/abs/2507.19631</guid>
<content:encoded><![CDATA[
arXiv:2507.19631v1 Announce Type: new 
Abstract: In this paper, scalable controller design to achieve output synchronization for a heterogeneous discrete-time nonlinear multi-agent system is considered. The agents are assumed to exhibit potentially nonlinear dynamics but share linear common oscillatory modes. In a distributed control architecture, scalability is ensured by designing a small number of distinguished controllers, significantly fewer than the number of agents, even when agent diversity is high. Our findings indicate that the number of controllers required can be effectively determined by the number of strongly connected components of the underlying graph. The study in this paper builds on the recently developed phase theory of matrices and systems. First, we employ the concept of matrix phase, specifically the phase alignability of a collection of matrices, to quantify agent diversity. Next, we use matrix phase, particularly the essential phase of the graph Laplacian, to evaluate the interaction quality among the agents. Based on these insights, we derive a sufficient condition for the solvability of the synchronization problem, framed as a trade-off between the agent diversity and the interaction quality. In the process, a controller design procedure based on Lyapunov analysis is provided, which produces low gain, component-wise synchronizing controllers when the solvability condition is satisfied. Numerical examples are given to illustrate the effectiveness of the proposed design procedure. Furthermore, we consider cases where the component-wise controller design problem is unsolvable. We propose alternative strategies involving the design of a small inventory of controllers, which can still achieve synchronization effectively by employing certain clustering methods to manage heterogeneity.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient and Scalable Agentic AI with Heterogeneous Systems</title>
<link>https://arxiv.org/abs/2507.19635</link>
<guid>https://arxiv.org/abs/2507.19635</guid>
<content:encoded><![CDATA[
arXiv:2507.19635v1 Announce Type: new 
Abstract: AI agents are emerging as a dominant workload in a wide range of applications, promising to be the vehicle that delivers the promised benefits of AI to enterprises and consumers. Unlike conventional software or static inference, agentic workloads are dynamic and structurally complex. Often these agents are directed graphs of compute and IO operations that span multi-modal data input and conversion), data processing and context gathering (e.g vector DB lookups), multiple LLM inferences, tool calls, etc. To scale AI agent usage, we need efficient and scalable deployment and agent-serving infrastructure.
  To tackle this challenge, in this paper, we present a system design for dynamic orchestration of AI agent workloads on heterogeneous compute infrastructure spanning CPUs and accelerators, both from different vendors and across different performance tiers within a single vendor. The system delivers several building blocks: a framework for planning and optimizing agentic AI execution graphs using cost models that account for compute, memory, and bandwidth constraints of different HW; a MLIR based representation and compilation system that can decompose AI agent execution graphs into granular operators and generate code for different HW options; and a dynamic orchestration system that can place the granular components across a heterogeneous compute infrastructure and stitch them together while meeting an end-to-end SLA. Our design performs a systems level TCO optimization and preliminary results show that leveraging a heterogeneous infrastructure can deliver significant TCO benefits. A preliminary surprising finding is that for some workloads a heterogeneous combination of older generation GPUs with newer accelerators can deliver similar TCO as the latest generation homogenous GPU infrastructure design, potentially extending the life of deployed infrastructure.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GABRIL: Gaze-Based Regularization for Mitigating Causal Confusion in Imitation Learning</title>
<link>https://arxiv.org/abs/2507.19647</link>
<guid>https://arxiv.org/abs/2507.19647</guid>
<content:encoded><![CDATA[
arXiv:2507.19647v1 Announce Type: new 
Abstract: Imitation Learning (IL) is a widely adopted approach which enables agents to learn from human expert demonstrations by framing the task as a supervised learning problem. However, IL often suffers from causal confusion, where agents misinterpret spurious correlations as causal relationships, leading to poor performance in testing environments with distribution shift. To address this issue, we introduce GAze-Based Regularization in Imitation Learning (GABRIL), a novel method that leverages the human gaze data gathered during the data collection phase to guide the representation learning in IL. GABRIL utilizes a regularization loss which encourages the model to focus on causally relevant features identified through expert gaze and consequently mitigates the effects of confounding variables. We validate our approach in Atari environments and the Bench2Drive benchmark in CARLA by collecting human gaze datasets and applying our method in both domains. Experimental results show that the improvement of GABRIL over behavior cloning is around 179% more than the same number for other baselines in the Atari and 76% in the CARLA setup. Finally, we show that our method provides extra explainability when compared to regular IL agents.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>"X of Information'' Continuum: A Survey on AI-Driven Multi-dimensional Metrics for Next-Generation Networked Systems</title>
<link>https://arxiv.org/abs/2507.19657</link>
<guid>https://arxiv.org/abs/2507.19657</guid>
<content:encoded><![CDATA[
arXiv:2507.19657v1 Announce Type: new 
Abstract: The development of next-generation networking systems has inherently shifted from throughput-based paradigms towards intelligent, information-aware designs that emphasize the quality, relevance, and utility of transmitted information, rather than sheer data volume. While classical network metrics, such as latency and packet loss, remain significant, they are insufficient to quantify the nuanced information quality requirements of modern intelligent applications, including autonomous vehicles, digital twins, and metaverse environments. In this survey, we present the first comprehensive study of the ``X of Information'' continuum by introducing a systematic four-dimensional taxonomic framework that structures information metrics along temporal, quality/utility, reliability/robustness, and network/communication dimensions. We uncover the increasing interdependencies among these dimensions, whereby temporal freshness triggers quality evaluation, which in turn helps with reliability appraisal, ultimately enabling effective network delivery. Our analysis reveals that artificial intelligence technologies, such as deep reinforcement learning, multi-agent systems, and neural optimization models, enable adaptive, context-aware optimization of competing information quality objectives. In our extensive study of six critical application domains, covering autonomous transportation, industrial IoT, healthcare digital twins, UAV communications, LLM ecosystems, and metaverse settings, we illustrate the revolutionary promise of multi-dimensional information metrics for meeting diverse operational needs. Our survey identifies prominent implementation challenges, including ...
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Salsa as a Nonverbal Embodied Language -- The CoMPAS3D Dataset and Benchmarks</title>
<link>https://arxiv.org/abs/2507.19684</link>
<guid>https://arxiv.org/abs/2507.19684</guid>
<content:encoded><![CDATA[
arXiv:2507.19684v1 Announce Type: new 
Abstract: Imagine a humanoid that can safely and creatively dance with a human, adapting to its partner's proficiency, using haptic signaling as a primary form of communication. While today's AI systems excel at text or voice-based interaction with large language models, human communication extends far beyond text-it includes embodied movement, timing, and physical coordination. Modeling coupled interaction between two agents poses a formidable challenge: it is continuous, bidirectionally reactive, and shaped by individual variation. We present CoMPAS3D, the largest and most diverse motion capture dataset of improvised salsa dancing, designed as a challenging testbed for interactive, expressive humanoid AI. The dataset includes 3 hours of leader-follower salsa dances performed by 18 dancers spanning beginner, intermediate, and professional skill levels. For the first time, we provide fine-grained salsa expert annotations, covering over 2,800 move segments, including move types, combinations, execution errors and stylistic elements. We draw analogies between partner dance communication and natural language, evaluating CoMPAS3D on two benchmark tasks for synthetic humans that parallel key problems in spoken language and dialogue processing: leader or follower generation with proficiency levels (speaker or listener synthesis), and duet (conversation) generation. Towards a long-term goal of partner dance with humans, we release the dataset, annotations, and code, along with a multitask SalsaAgent model capable of performing all benchmark tasks, alongside additional baselines to encourage research in socially interactive embodied AI and creative, expressive humanoid motion generation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PhysVarMix: Physics-Informed Variational Mixture Model for Multi-Modal Trajectory Prediction</title>
<link>https://arxiv.org/abs/2507.19701</link>
<guid>https://arxiv.org/abs/2507.19701</guid>
<content:encoded><![CDATA[
arXiv:2507.19701v1 Announce Type: new 
Abstract: Accurate prediction of future agent trajectories is a critical challenge for ensuring safe and efficient autonomous navigation, particularly in complex urban environments characterized by multiple plausible future scenarios. In this paper, we present a novel hybrid approach that integrates learning-based with physics-based constraints to address the multi-modality inherent in trajectory prediction. Our method employs a variational Bayesian mixture model to effectively capture the diverse range of potential future behaviors, moving beyond traditional unimodal assumptions. Unlike prior approaches that predominantly treat trajectory prediction as a data-driven regression task, our framework incorporates physical realism through sector-specific boundary conditions and Model Predictive Control (MPC)-based smoothing. These constraints ensure that predicted trajectories are not only data-consistent but also physically plausible, adhering to kinematic and dynamic principles. Furthermore, our method produces interpretable and diverse trajectory predictions, enabling enhanced downstream decision-making and planning in autonomous driving systems. We evaluate our approach on two benchmark datasets, demonstrating superior performance compared to existing methods. Comprehensive ablation studies validate the contributions of each component and highlight their synergistic impact on prediction accuracy and reliability. By balancing data-driven insights with physics-informed constraints, our approach offers a robust and scalable solution for navigating the uncertainties of real-world urban environments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Oranits: Mission Assignment and Task Offloading in Open RAN-based ITS using Metaheuristic and Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.19712</link>
<guid>https://arxiv.org/abs/2507.19712</guid>
<content:encoded><![CDATA[
arXiv:2507.19712v1 Announce Type: new 
Abstract: In this paper, we explore mission assignment and task offloading in an Open Radio Access Network (Open RAN)-based intelligent transportation system (ITS), where autonomous vehicles leverage mobile edge computing for efficient processing. Existing studies often overlook the intricate interdependencies between missions and the costs associated with offloading tasks to edge servers, leading to suboptimal decision-making. To bridge this gap, we introduce Oranits, a novel system model that explicitly accounts for mission dependencies and offloading costs while optimizing performance through vehicle cooperation. To achieve this, we propose a twofold optimization approach. First, we develop a metaheuristic-based evolutionary computing algorithm, namely the Chaotic Gaussian-based Global ARO (CGG-ARO), serving as a baseline for one-slot optimization. Second, we design an enhanced reward-based deep reinforcement learning (DRL) framework, referred to as the Multi-agent Double Deep Q-Network (MA-DDQN), that integrates both multi-agent coordination and multi-action selection mechanisms, significantly reducing mission assignment time and improving adaptability over baseline methods. Extensive simulations reveal that CGG-ARO improves the number of completed missions and overall benefit by approximately 7.1% and 7.7%, respectively. Meanwhile, MA-DDQN achieves even greater improvements of 11.0% in terms of mission completions and 12.5% in terms of the overall benefit. These results highlight the effectiveness of Oranits in enabling faster, more adaptive, and more efficient task processing in dynamic ITS environments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Nearest Neighbors: Semantic Compression and Graph-Augmented Retrieval for Enhanced Vector Search</title>
<link>https://arxiv.org/abs/2507.19715</link>
<guid>https://arxiv.org/abs/2507.19715</guid>
<content:encoded><![CDATA[
arXiv:2507.19715v1 Announce Type: new 
Abstract: Vector databases typically rely on approximate nearest neighbor (ANN) search to retrieve the top-k closest vectors to a query in embedding space. While effective, this approach often yields semantically redundant results, missing the diversity and contextual richness required by applications such as retrieval-augmented generation (RAG), multi-hop QA, and memory-augmented agents. We introduce a new retrieval paradigm: semantic compression, which aims to select a compact, representative set of vectors that captures the broader semantic structure around a query. We formalize this objective using principles from submodular optimization and information geometry, and show that it generalizes traditional top-k retrieval by prioritizing coverage and diversity. To operationalize this idea, we propose graph-augmented vector retrieval, which overlays semantic graphs (e.g., kNN or knowledge-based links) atop vector spaces to enable multi-hop, context-aware search. We theoretically analyze the limitations of proximity-based retrieval under high-dimensional concentration and highlight how graph structures can improve semantic coverage. Our work outlines a foundation for meaning-centric vector search systems, emphasizing hybrid indexing, diversity-aware querying, and structured semantic retrieval. We make our implementation publicly available to foster future research in this area.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Minding Motivation: The Effect of Intrinsic Motivation on Agent Behaviors</title>
<link>https://arxiv.org/abs/2507.19725</link>
<guid>https://arxiv.org/abs/2507.19725</guid>
<content:encoded><![CDATA[
arXiv:2507.19725v1 Announce Type: new 
Abstract: Games are challenging for Reinforcement Learning~(RL) agents due to their reward-sparsity, as rewards are only obtainable after long sequences of deliberate actions. Intrinsic Motivation~(IM) methods -- which introduce exploration rewards -- are an effective solution to reward-sparsity. However, IM also causes an issue known as `reward hacking' where the agent optimizes for the new reward at the expense of properly playing the game. The larger problem is that reward hacking itself is largely unknown; there is no answer to whether, and to what extent, IM rewards change the behavior of RL agents. This study takes a first step by empirically evaluating the impact on behavior of three IM techniques on the MiniGrid game-like environment. We compare these IM models with Generalized Reward Matching~(GRM), a method that can be used with any intrinsic reward function to guarantee optimality. Our results suggest that IM causes noticeable change by increasing the initial rewards, but also altering the way the agent plays; and that GRM mitigated reward hacking in some scenarios.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DOA: A Degeneracy Optimization Agent with Adaptive Pose Compensation Capability based on Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.19742</link>
<guid>https://arxiv.org/abs/2507.19742</guid>
<content:encoded><![CDATA[
arXiv:2507.19742v1 Announce Type: new 
Abstract: Particle filter-based 2D-SLAM is widely used in indoor localization tasks due to its efficiency. However, indoor environments such as long straight corridors can cause severe degeneracy problems in SLAM. In this paper, we use Proximal Policy Optimization (PPO) to train an adaptive degeneracy optimization agent (DOA) to address degeneracy problem. We propose a systematic methodology to address three critical challenges in traditional supervised learning frameworks: (1) data acquisition bottlenecks in degenerate dataset, (2) inherent quality deterioration of training samples, and (3) ambiguity in annotation protocol design. We design a specialized reward function to guide the agent in developing perception capabilities for degenerate environments. Using the output degeneracy factor as a reference weight, the agent can dynamically adjust the contribution of different sensors to pose optimization. Specifically, the observation distribution is shifted towards the motion model distribution, with the step size determined by a linear interpolation formula related to the degeneracy factor. In addition, we employ a transfer learning module to endow the agent with generalization capabilities across different environments and address the inefficiency of training in degenerate environments. Finally, we conduct ablation studies to demonstrate the rationality of our model design and the role of transfer learning. We also compare the proposed DOA with SOTA methods to prove its superior degeneracy detection and optimization capabilities across various environments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Model Agent for Structural Drawing Generation Using ReAct Prompt Engineering and Retrieval Augmented Generation</title>
<link>https://arxiv.org/abs/2507.19771</link>
<guid>https://arxiv.org/abs/2507.19771</guid>
<content:encoded><![CDATA[
arXiv:2507.19771v1 Announce Type: new 
Abstract: Structural drawings are widely used in many fields, e.g., mechanical engineering, civil engineering, etc. In civil engineering, structural drawings serve as the main communication tool between architects, engineers, and builders to avoid conflicts, act as legal documentation, and provide a reference for future maintenance or evaluation needs. They are often organized using key elements such as title/subtitle blocks, scales, plan views, elevation view, sections, and detailed sections, which are annotated with standardized symbols and line types for interpretation by engineers and contractors. Despite advances in software capabilities, the task of generating a structural drawing remains labor-intensive and time-consuming for structural engineers. Here we introduce a novel generative AI-based method for generating structural drawings employing a large language model (LLM) agent. The method incorporates a retrieval-augmented generation (RAG) technique using externally-sourced facts to enhance the accuracy and reliability of the language model. This method is capable of understanding varied natural language descriptions, processing these to extract necessary information, and generating code to produce the desired structural drawing in AutoCAD. The approach developed, demonstrated and evaluated herein enables the efficient and direct conversion of a structural drawing's natural language description into an AutoCAD drawing, significantly reducing the workload compared to current working process associated with manual drawing production, facilitating the typical iterative process of engineers for expressing design ideas in a simplified way.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ag2x2: Robust Agent-Agnostic Visual Representations for Zero-Shot Bimanual Manipulation</title>
<link>https://arxiv.org/abs/2507.19817</link>
<guid>https://arxiv.org/abs/2507.19817</guid>
<content:encoded><![CDATA[
arXiv:2507.19817v1 Announce Type: new 
Abstract: Bimanual manipulation, fundamental to human daily activities, remains a challenging task due to its inherent complexity of coordinated control. Recent advances have enabled zero-shot learning of single-arm manipulation skills through agent-agnostic visual representations derived from human videos; however, these methods overlook crucial agent-specific information necessary for bimanual coordination, such as end-effector positions. We propose Ag2x2, a computational framework for bimanual manipulation through coordination-aware visual representations that jointly encode object states and hand motion patterns while maintaining agent-agnosticism. Extensive experiments demonstrate that Ag2x2 achieves a 73.5% success rate across 13 diverse bimanual tasks from Bi-DexHands and PerAct2, including challenging scenarios with deformable objects like ropes. This performance outperforms baseline methods and even surpasses the success rate of policies trained with expert-engineered rewards. Furthermore, we show that representations learned through Ag2x2 can be effectively leveraged for imitation learning, establishing a scalable pipeline for skill acquisition without expert supervision. By maintaining robust performance across diverse tasks without human demonstrations or engineered rewards, Ag2x2 represents a step toward scalable learning of complex bimanual robotic skills.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VAE-GAN Based Price Manipulation in Coordinated Local Energy Markets</title>
<link>https://arxiv.org/abs/2507.19844</link>
<guid>https://arxiv.org/abs/2507.19844</guid>
<content:encoded><![CDATA[
arXiv:2507.19844v1 Announce Type: new 
Abstract: This paper introduces a model for coordinating prosumers with heterogeneous distributed energy resources (DERs), participating in the local energy market (LEM) that interacts with the market-clearing entity. The proposed LEM scheme utilizes a data-driven, model-free reinforcement learning approach based on the multi-agent deep deterministic policy gradient (MADDPG) framework, enabling prosumers to make real-time decisions on whether to buy, sell, or refrain from any action while facilitating efficient coordination for optimal energy trading in a dynamic market. In addition, we investigate a price manipulation strategy using a variational auto encoder-generative adversarial network (VAE-GAN) model, which allows utilities to adjust price signals in a way that induces financial losses for the prosumers. Our results show that under adversarial pricing, heterogeneous prosumer groups, particularly those lacking generation capabilities, incur financial losses. The same outcome holds across LEMs of different sizes. As the market size increases, trading stabilizes and fairness improves through emergent cooperation among agents.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Reinforced Policy Optimization</title>
<link>https://arxiv.org/abs/2507.19849</link>
<guid>https://arxiv.org/abs/2507.19849</guid>
<content:encoded><![CDATA[
arXiv:2507.19849v1 Announce Type: new 
Abstract: Large-scale reinforcement learning with verifiable rewards (RLVR) has demonstrated its effectiveness in harnessing the potential of large language models (LLMs) for single-turn reasoning tasks. In realistic reasoning scenarios, LLMs can often utilize external tools to assist in task-solving processes. However, current RL algorithms inadequately balance the models' intrinsic long-horizon reasoning capabilities and their proficiency in multi-turn tool interactions. To bridge this gap, we propose Agentic Reinforced Policy Optimization (ARPO), a novel agentic RL algorithm tailored for training multi-turn LLM-based agents. Through preliminary experiments, we observe that LLMs tend to exhibit highly uncertain behavior, characterized by an increase in the entropy distribution of generated tokens, immediately following interactions with external tools. Motivated by this observation, ARPO incorporates an entropy-based adaptive rollout mechanism, dynamically balancing global trajectory sampling and step-level sampling, thereby promoting exploration at steps with high uncertainty after tool usage. By integrating an advantage attribution estimation, ARPO enables LLMs to internalize advantage differences in stepwise tool-use interactions. Our experiments across 13 challenging benchmarks in computational reasoning, knowledge reasoning, and deep search domains demonstrate ARPO's superiority over trajectory-level RL algorithms. Remarkably, ARPO achieves improved performance using only half of the tool-use budget required by existing methods, offering a scalable solution for aligning LLM-based agents with real-time dynamic environments. Our code and datasets are released at https://github.com/dongguanting/ARPO
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PlaneHEC: Efficient Hand-Eye Calibration for Multi-view Robotic Arm via Any Point Cloud Plane Detection</title>
<link>https://arxiv.org/abs/2507.19851</link>
<guid>https://arxiv.org/abs/2507.19851</guid>
<content:encoded><![CDATA[
arXiv:2507.19851v1 Announce Type: new 
Abstract: Hand-eye calibration is an important task in vision-guided robotic systems and is crucial for determining the transformation matrix between the camera coordinate system and the robot end-effector. Existing methods, for multi-view robotic systems, usually rely on accurate geometric models or manual assistance, generalize poorly, and can be very complicated and inefficient. Therefore, in this study, we propose PlaneHEC, a generalized hand-eye calibration method that does not require complex models and can be accomplished using only depth cameras, which achieves the optimal and fastest calibration results using arbitrary planar surfaces like walls and tables. PlaneHEC introduces hand-eye calibration equations based on planar constraints, which makes it strongly interpretable and generalizable. PlaneHEC also uses a comprehensive solution that starts with a closed-form solution and improves it withiterative optimization, which greatly improves accuracy. We comprehensively evaluated the performance of PlaneHEC in both simulated and real-world environments and compared the results with other point-cloud-based calibration methods, proving its superiority. Our approach achieves universal and fast calibration with an innovative design of computational models, providing a strong contribution to the development of multi-agent systems and embodied intelligence.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Think, Act, Learn: A Framework for Autonomous Robotic Agents using Closed-Loop Large Language Models</title>
<link>https://arxiv.org/abs/2507.19854</link>
<guid>https://arxiv.org/abs/2507.19854</guid>
<content:encoded><![CDATA[
arXiv:2507.19854v1 Announce Type: new 
Abstract: The integration of Large Language Models (LLMs) into robotics has unlocked unprecedented capabilities in high-level task planning. However, most current systems operate in an open-loop fashion, where LLMs act as one-shot planners, rendering them brittle and unable to adapt to unforeseen circumstances in dynamic physical environments. To overcome this limitation, this paper introduces the "Think, Act, Learn" (T-A-L) framework, a novel architecture that enables an embodied agent to autonomously learn and refine its policies through continuous interaction. Our framework establishes a closed-loop cycle where an LLM first "thinks" by decomposing high-level commands into actionable plans. The robot then "acts" by executing these plans while gathering rich, multimodal sensory feedback. Critically, the "learn" module processes this feedback to facilitate LLM-driven self-reflection, allowing the agent to perform causal analysis on its failures and generate corrective strategies. These insights are stored in an experiential memory to guide future planning cycles. We demonstrate through extensive experiments in both simulation and the real world that our T-A-L agent significantly outperforms baseline methods, including open-loop LLMs, Behavioral Cloning, and traditional Reinforcement Learning. Our framework achieves over a 97% success rate on complex, long-horizon tasks, converges to a stable policy in an average of just 9 trials, and exhibits remarkable generalization to unseen tasks. This work presents a significant step towards developing more robust, adaptive, and truly autonomous robotic agents.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Homotopy-aware Multi-agent Navigation via Distributed Model Predictive Control</title>
<link>https://arxiv.org/abs/2507.19860</link>
<guid>https://arxiv.org/abs/2507.19860</guid>
<content:encoded><![CDATA[
arXiv:2507.19860v1 Announce Type: new 
Abstract: Multi-agent trajectory planning requires ensuring both safety and efficiency, yet deadlocks remain a significant challenge, especially in obstacle-dense environments. Such deadlocks frequently occur when multiple agents attempt to traverse the same long and narrow corridor simultaneously. To address this, we propose a novel distributed trajectory planning framework that bridges the gap between global path and local trajectory cooperation. At the global level, a homotopy-aware optimal path planning algorithm is proposed, which fully leverages the topological structure of the environment. A reference path is chosen from distinct homotopy classes by considering both its spatial and temporal properties, leading to improved coordination among agents globally. At the local level, a model predictive control-based trajectory optimization method is used to generate dynamically feasible and collision-free trajectories. Additionally, an online replanning strategy ensures its adaptability to dynamic environments. Simulations and experiments validate the effectiveness of our approach in mitigating deadlocks. Ablation studies demonstrate that by incorporating time-aware homotopic properties into the underlying global paths, our method can significantly reduce deadlocks and improve the average success rate from 4%-13% to over 90% in randomly generated dense scenarios.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trivial Trojans: How Minimal MCP Servers Enable Cross-Tool Exfiltration of Sensitive Data</title>
<link>https://arxiv.org/abs/2507.19880</link>
<guid>https://arxiv.org/abs/2507.19880</guid>
<content:encoded><![CDATA[
arXiv:2507.19880v1 Announce Type: new 
Abstract: The Model Context Protocol (MCP) represents a significant advancement in AI-tool integration, enabling seamless communication between AI agents and external services. However, this connectivity introduces novel attack vectors that remain largely unexplored. This paper demonstrates how unsophisticated threat actors, requiring only basic programming skills and free web tools, can exploit MCP's trust model to exfiltrate sensitive financial data. We present a proof-of-concept attack where a malicious weather MCP server, disguised as benign functionality, discovers and exploits legitimate banking tools to steal user account balances. The attack chain requires no advanced technical knowledge, server infrastructure, or monetary investment. The findings reveal a critical security gap in the emerging MCP ecosystem: while individual servers may appear trustworthy, their combination creates unexpected cross-server attack surfaces. Unlike traditional cybersecurity threats that assume sophisticated adversaries, our research shows that the barrier to entry for MCP-based attacks is alarmingly low. A threat actor with undergraduate-level Python knowledge can craft convincing social engineering attacks that exploit the implicit trust relationships MCP establishes between AI agents and tool providers. This work contributes to the nascent field of MCP security by demonstrating that current MCP implementations allow trivial cross-server attacks and proposing both immediate mitigations and protocol improvements to secure this emerging ecosystem.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentMesh: A Cooperative Multi-Agent Generative AI Framework for Software Development Automation</title>
<link>https://arxiv.org/abs/2507.19902</link>
<guid>https://arxiv.org/abs/2507.19902</guid>
<content:encoded><![CDATA[
arXiv:2507.19902v1 Announce Type: new 
Abstract: Software development is a complex, multi-phase process traditionally requiring collaboration among individuals with diverse expertise. We propose AgentMesh, a Python-based framework that uses multiple cooperating LLM-powered agents to automate software development tasks. In AgentMesh, specialized agents - a Planner, Coder, Debugger, and Reviewer - work in concert to transform a high-level requirement into fully realized code. The Planner agent first decomposes user requests into concrete subtasks; the Coder agent implements each subtask in code; the Debugger agent tests and fixes the code; and the Reviewer agent validates the final output for correctness and quality. We describe the architecture and design of these agents and their communication, and provide implementation details including prompt strategies and workflow orchestration. A case study illustrates AgentMesh handling a non-trivial development request via sequential task planning, code generation, iterative debugging, and final code review. We discuss how dividing responsibilities among cooperative agents leverages the strengths of large language models while mitigating single-agent limitations. Finally, we examine current limitations - such as error propagation and context scaling - and outline future work toward more robust, scalable multi-agent AI systems for software engineering automation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prometheus: Unified Knowledge Graphs for Issue Resolution in Multilingual Codebases</title>
<link>https://arxiv.org/abs/2507.19942</link>
<guid>https://arxiv.org/abs/2507.19942</guid>
<content:encoded><![CDATA[
arXiv:2507.19942v1 Announce Type: new 
Abstract: Language model (LM) agents, such as SWE-agent and OpenHands, have made progress toward automated issue resolution. However, existing approaches are often limited to Python-only issues and rely on pre-constructed containers in SWE-bench with reproduced issues, restricting their applicability to real-world and work for multi-language repositories. We present Prometheus, designed to resolve real-world issues beyond benchmark settings. Prometheus is a multi-agent system that transforms an entire code repository into a unified knowledge graph to guide context retrieval for issue resolution. Prometheus encodes files, abstract syntax trees, and natural language text into a graph of typed nodes and five general edge types to support multiple programming languages. Prometheus uses Neo4j for graph persistence, enabling scalable and structured reasoning over large codebases. Integrated by the DeepSeek-V3 model, Prometheus resolves 28.67% and 13.7% of issues on SWE-bench Lite and SWE-bench Multilingual, respectively, with an average API cost of $0.23 and $0.38 per issue. Prometheus resolves 10 unique issues not addressed by prior work and is the first to demonstrate effectiveness across seven programming languages. Moreover, it shows the ability to resolve real-world GitHub issues in the LangChain and OpenHands repositories. We have open-sourced Prometheus at: https://github.com/Pantheon-temple/Prometheus
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Text2Vis: A Challenging and Diverse Benchmark for Generating Multimodal Visualizations from Text</title>
<link>https://arxiv.org/abs/2507.19969</link>
<guid>https://arxiv.org/abs/2507.19969</guid>
<content:encoded><![CDATA[
arXiv:2507.19969v1 Announce Type: new 
Abstract: Automated data visualization plays a crucial role in simplifying data interpretation, enhancing decision-making, and improving efficiency. While large language models (LLMs) have shown promise in generating visualizations from natural language, the absence of comprehensive benchmarks limits the rigorous evaluation of their capabilities. We introduce Text2Vis, a benchmark designed to assess text-to-visualization models, covering 20+ chart types and diverse data science queries, including trend analysis, correlation, outlier detection, and predictive analytics. It comprises 1,985 samples, each with a data table, natural language query, short answer, visualization code, and annotated charts. The queries involve complex reasoning, conversational turns, and dynamic data retrieval. We benchmark 11 open-source and closed-source models, revealing significant performance gaps, highlighting key challenges, and offering insights for future advancements. To close this gap, we propose the first cross-modal actor-critic agentic framework that jointly refines the textual answer and visualization code, increasing GPT-4o`s pass rate from 26% to 42% over the direct approach and improving chart quality. We also introduce an automated LLM-based evaluation framework that enables scalable assessment across thousands of samples without human annotation, measuring answer correctness, code execution success, visualization readability, and chart accuracy. We release Text2Vis at https://github.com/vis-nlp/Text2Vis.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finding Personalized Good-Enough Solutions to Unsatisfiable Stable Roommates Problems</title>
<link>https://arxiv.org/abs/2507.20010</link>
<guid>https://arxiv.org/abs/2507.20010</guid>
<content:encoded><![CDATA[
arXiv:2507.20010v1 Announce Type: new 
Abstract: The Stable Roommates problems are characterized by the preferences of agents over other agents as roommates. A solution is a partition of the agents into pairs that are acceptable to each other (i.e., they are in the preference lists of each other), and the matching is stable (i.e., there do not exist any two agents who prefer each other to their roommates, and thus block the matching). Motivated by real-world applications, and considering that stable roommates problems do not always have solutions, we continue our studies to compute "good-enough" matchings. In addition to the agents' habits and habitual preferences, we consider their networks of preferred friends, and introduce a method to generate personalized solutions to stable roommates problems. We illustrate the usefulness of our method with examples and empirical evaluations.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generating Satisfiable Benchmark Instances for Stable Roommates Problems with Optimization</title>
<link>https://arxiv.org/abs/2507.20013</link>
<guid>https://arxiv.org/abs/2507.20013</guid>
<content:encoded><![CDATA[
arXiv:2507.20013v1 Announce Type: new 
Abstract: While the existence of a stable matching for the stable roommates problem possibly with incomplete preference lists (SRI) can be decided in polynomial time, SRI problems with some fairness criteria are intractable. Egalitarian SRI that tries to maximize the total satisfaction of agents if a stable matching exists, is such a hard variant of SRI. For experimental evaluations of methods to solve these hard variants of SRI, several well-known algorithms have been used to randomly generate benchmark instances. However, these benchmark instances are not always satisfiable, and usually have a small number of stable matchings if one exists. For such SRI instances, despite the NP-hardness of Egalitarian SRI, it is practical to find an egalitarian stable matching by enumerating all stable matchings. In this study, we introduce a novel algorithm to generate benchmark instances for SRI that have very large numbers of solutions, and for which it is hard to find an egalitarian stable matching by enumerating all stable matchings.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Algorithm-to-Contract Framework without Demand Queries</title>
<link>https://arxiv.org/abs/2507.20038</link>
<guid>https://arxiv.org/abs/2507.20038</guid>
<content:encoded><![CDATA[
arXiv:2507.20038v1 Announce Type: new 
Abstract: Consider costly tasks that add up to the success of a project, and must be fitted by an agent into a given time-frame. This is an instance of the classic budgeted maximization problem, which admits an approximation scheme (FPTAS). Now assume the agent is performing these tasks on behalf of a principal, who is the one to reap the rewards if the project succeeds. The principal must design a contract to incentivize the agent. Is there still an approximation scheme? In this work, our ultimate goal is an algorithm-to-contract transformation, which transforms algorithms for combinatorial problems (like budgeted maximization) to tackle incentive constraints that arise in contract design. Our approach diverges from previous works on combinatorial contract design by avoiding an assumption of black-box access to a demand oracle.
  We first show how to "lift" the FPTAS for budgeted maximization to obtain the best-possible multiplicative and additive FPTAS for the contract design problem. We establish this through our "local-global" framework, in which the "local" step is to (approximately) solve a two-sided strengthened variant of the demand problem. The "global" step then utilizes the local one to find the approximately optimal contract. We apply our framework to a host of combinatorial constraints including multi-dimensional budgets, budgeted matroid, and budgeted matching constraints. In all cases we achieve an approximation essentially matching the best approximation for the purely algorithmic problem. We also develop a method to tackle multi-agent contract settings, where the team of working agents must abide to combinatorial feasibility constraints.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Driven Generation of Old English: A Framework for Low-Resource Languages</title>
<link>https://arxiv.org/abs/2507.20111</link>
<guid>https://arxiv.org/abs/2507.20111</guid>
<content:encoded><![CDATA[
arXiv:2507.20111v1 Announce Type: new 
Abstract: Preserving ancient languages is essential for understanding humanity's cultural and linguistic heritage, yet Old English remains critically under-resourced, limiting its accessibility to modern natural language processing (NLP) techniques. We present a scalable framework that uses advanced large language models (LLMs) to generate high-quality Old English texts, addressing this gap. Our approach combines parameter-efficient fine-tuning (Low-Rank Adaptation, LoRA), data augmentation via backtranslation, and a dual-agent pipeline that separates the tasks of content generation (in English) and translation (into Old English). Evaluation with automated metrics (BLEU, METEOR, and CHRF) shows significant improvements over baseline models, with BLEU scores increasing from 26 to over 65 for English-to-Old English translation. Expert human assessment also confirms high grammatical accuracy and stylistic fidelity in the generated texts. Beyond expanding the Old English corpus, our method offers a practical blueprint for revitalizing other endangered languages, effectively uniting AI innovation with the goals of cultural preservation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RESCUE: Crowd Evacuation Simulation via Controlling SDM-United Characters</title>
<link>https://arxiv.org/abs/2507.20117</link>
<guid>https://arxiv.org/abs/2507.20117</guid>
<content:encoded><![CDATA[
arXiv:2507.20117v1 Announce Type: new 
Abstract: Crowd evacuation simulation is critical for enhancing public safety, and demanded for realistic virtual environments. Current mainstream evacuation models overlook the complex human behaviors that occur during evacuation, such as pedestrian collisions, interpersonal interactions, and variations in behavior influenced by terrain types or individual body shapes. This results in the failure to accurately simulate the escape of people in the real world. In this paper, aligned with the sensory-decision-motor (SDM) flow of the human brain, we propose a real-time 3D crowd evacuation simulation framework that integrates a 3D-adaptive SFM (Social Force Model) Decision Mechanism and a Personalized Gait Control Motor. This framework allows multiple agents to move in parallel and is suitable for various scenarios, with dynamic crowd awareness. Additionally, we introduce Part-level Force Visualization to assist in evacuation analysis. Experimental results demonstrate that our framework supports dynamic trajectory planning and personalized behavior for each agent throughout the evacuation process, and is compatible with uneven terrain. Visually, our method generates evacuation results that are more realistic and plausible, providing enhanced insights for crowd simulation. The code is available at http://cic.tju.edu.cn/faculty/likun/projects/RESCUE.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Concept Learning for Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.20143</link>
<guid>https://arxiv.org/abs/2507.20143</guid>
<content:encoded><![CDATA[
arXiv:2507.20143v1 Announce Type: new 
Abstract: Despite substantial progress in applying neural networks (NN) to multi-agent reinforcement learning (MARL) areas, they still largely suffer from a lack of transparency and interoperability. However, its implicit cooperative mechanism is not yet fully understood due to black-box networks. In this work, we study an interpretable value decomposition framework via concept bottleneck models, which promote trustworthiness by conditioning credit assignment on an intermediate level of human-like cooperation concepts. To address this problem, we propose a novel value-based method, named Concepts learning for Multi-agent Q-learning (CMQ), that goes beyond the current performance-vs-interpretability trade-off by learning interpretable cooperation concepts. CMQ represents each cooperation concept as a supervised vector, as opposed to existing models where the information flowing through their end-to-end mechanism is concept-agnostic. Intuitively, using individual action value conditioning on global state embeddings to represent each concept allows for extra cooperation representation capacity. Empirical evaluations on the StarCraft II micromanagement challenge and level-based foraging (LBF) show that CMQ achieves superior performance compared with the state-of-the-art counterparts. The results also demonstrate that CMQ provides more cooperation concept representation capturing meaningful cooperation modes, and supports test-time concept interventions for detecting potential biases of cooperation mode and identifying spurious artifacts that impact cooperation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Interactive Question Generation Framework for Long Document Understanding</title>
<link>https://arxiv.org/abs/2507.20145</link>
<guid>https://arxiv.org/abs/2507.20145</guid>
<content:encoded><![CDATA[
arXiv:2507.20145v1 Announce Type: new 
Abstract: Document Understanding (DU) in long-contextual scenarios with complex layouts remains a significant challenge in vision-language research. Although Large Vision-Language Models (LVLMs) excel at short-context DU tasks, their performance declines in long-context settings. A key limitation is the scarcity of fine-grained training data, particularly for low-resource languages such as Arabic. Existing state-of-the-art techniques rely heavily on human annotation, which is costly and inefficient. We propose a fully automated, multi-agent interactive framework to generate long-context questions efficiently. Our approach efficiently generates high-quality single- and multi-page questions for extensive English and Arabic documents, covering hundreds of pages across diverse domains. This facilitates the development of LVLMs with enhanced long-context understanding ability. Experimental results in this work have shown that our generated English and Arabic questions (\textbf{AraEngLongBench}) are quite challenging to major open- and close-source LVLMs. The code and data proposed in this work can be found in https://github.com/wangk0b/Multi_Agentic_QA_Long_Doc.git. Sample Question and Answer (QA) pairs and structured system prompts can be found in the Appendix.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Goal Alignment in LLM-Based User Simulators for Conversational AI</title>
<link>https://arxiv.org/abs/2507.20152</link>
<guid>https://arxiv.org/abs/2507.20152</guid>
<content:encoded><![CDATA[
arXiv:2507.20152v1 Announce Type: new 
Abstract: User simulators are essential to conversational AI, enabling scalable agent development and evaluation through simulated interactions. While current Large Language Models (LLMs) have advanced user simulation capabilities, we reveal that they struggle to consistently demonstrate goal-oriented behavior across multi-turn conversations--a critical limitation that compromises their reliability in downstream applications. We introduce User Goal State Tracking (UGST), a novel framework that tracks user goal progression throughout conversations. Leveraging UGST, we present a three-stage methodology for developing user simulators that can autonomously track goal progression and reason to generate goal-aligned responses. Moreover, we establish comprehensive evaluation metrics for measuring goal alignment in user simulators, and demonstrate that our approach yields substantial improvements across two benchmarks (MultiWOZ 2.4 and {\tau}-Bench). Our contributions address a critical gap in conversational AI and establish UGST as an essential framework for developing goal-aligned user simulators.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MLC-Agent: Cognitive Model based on Memory-Learning Collaboration in LLM Empowered Agent Simulation Environment</title>
<link>https://arxiv.org/abs/2507.20215</link>
<guid>https://arxiv.org/abs/2507.20215</guid>
<content:encoded><![CDATA[
arXiv:2507.20215v1 Announce Type: new 
Abstract: Many real-world systems, such as transportation systems, ecological systems, and Internet systems, are complex systems. As an important tool for studying complex systems, computational experiments can map them into artificial society models that are computable and reproducible within computers, thereby providing digital and computational methods for quantitative analysis. In current research, the construction of individual agent models often ignores the long-term accumulative effect of memory mechanisms in the development process of agents, which to some extent causes the constructed models to deviate from the real characteristics of real-world systems. To address this challenge, this paper proposes an individual agent model based on a memory-learning collaboration mechanism, which implements hierarchical modeling of the memory mechanism and a multi-indicator evaluation mechanism. Through hierarchical modeling of the individual memory repository, the group memory repository, and the memory buffer pool, memory can be effectively managed, and knowledge sharing and dissemination between individuals and groups can be promoted. At the same time, the multi-indicator evaluation mechanism enables dynamic evaluation of memory information, allowing dynamic updates of information in the memory set and promoting collaborative decision-making between memory and learning. Experimental results show that, compared with existing memory modeling methods, the agents constructed by the proposed model demonstrate better decision-making quality and adaptability within the system. This verifies the effectiveness of the individual agent model based on the memory-learning collaboration mechanism proposed in this paper in improving the quality of individual-level modeling in artificial society modeling and achieving anthropomorphic characteristics.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multi-Agent System for Information Extraction from the Chemical Literature</title>
<link>https://arxiv.org/abs/2507.20230</link>
<guid>https://arxiv.org/abs/2507.20230</guid>
<content:encoded><![CDATA[
arXiv:2507.20230v1 Announce Type: new 
Abstract: To fully expedite AI-powered chemical research, high-quality chemical databases are the cornerstone. Automatic extraction of chemical information from the literature is essential for constructing reaction databases, but it is currently limited by the multimodality and style variability of chemical information. In this work, we developed a multimodal large language model (MLLM)-based multi-agent system for automatic chemical information extraction. We used the MLLM's strong reasoning capability to understand the structure of complex chemical graphics, decompose the extraction task into sub-tasks and coordinate a set of specialized agents to solve them. Our system achieved an F1 score of 80.8% on a benchmark dataset of complex chemical reaction graphics from the literature, surpassing the previous state-of-the-art model (F1 score: 35.6%) by a significant margin. Additionally, it demonstrated consistent improvements in key sub-tasks, including molecular image recognition, reaction image parsing, named entity recognition and text-based reaction extraction. This work is a critical step toward automated chemical information extraction into structured datasets, which will be a strong promoter of AI-driven chemical research.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Truthful Mechanism Design for Distributed Optimisation Algorithms in Networks with Self-interested Agents</title>
<link>https://arxiv.org/abs/2507.20250</link>
<guid>https://arxiv.org/abs/2507.20250</guid>
<content:encoded><![CDATA[
arXiv:2507.20250v1 Announce Type: new 
Abstract: Enhancing resilience in multi-agent systems in the face of selfish agents is an important problem that requires further characterisation. This work develops a truthful mechanism that avoids self-interested and strategic agents maliciously manipulating the algorithm. We prove theoretically that the proposed mechanism incentivises self-interested agents to participate and follow the provided algorithm faithfully. Additionally, the mechanism is compatible with any distributed optimisation algorithm that can calculate at least one subgradient at a given point. Finally, we present an illustrative example that shows the effectiveness of the mechanism.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Min Max Average Cycle Weight Problem</title>
<link>https://arxiv.org/abs/2507.20253</link>
<guid>https://arxiv.org/abs/2507.20253</guid>
<content:encoded><![CDATA[
arXiv:2507.20253v1 Announce Type: new 
Abstract: When an old apartment building is demolished and rebuilt, how can we fairly redistribute the new apartments to minimize envy among residents? We reduce this question to a combinatorial optimization problem called the *Min Max Average Cycle Weight* problem. In that problem we seek to assign objects to agents in a way that minimizes the maximum average weight of directed cycles in an associated envy graph. While this problem reduces to maximum-weight matching when starting from a clean slate (achieving polynomial-time solvability), we show that this is not the case when we account for preexisting conditions, such as residents' satisfaction with their original apartments. Whether the problem is polynomial-time solvable in the general case remains an intriguing open problem.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SciToolAgent: A Knowledge Graph-Driven Scientific Agent for Multi-Tool Integration</title>
<link>https://arxiv.org/abs/2507.20280</link>
<guid>https://arxiv.org/abs/2507.20280</guid>
<content:encoded><![CDATA[
arXiv:2507.20280v1 Announce Type: new 
Abstract: Scientific research increasingly relies on specialized computational tools, yet effectively utilizing these tools demands substantial domain expertise. While Large Language Models (LLMs) show promise in tool automation, they struggle to seamlessly integrate and orchestrate multiple tools for complex scientific workflows. Here, we present SciToolAgent, an LLM-powered agent that automates hundreds of scientific tools across biology, chemistry, and materials science. At its core, SciToolAgent leverages a scientific tool knowledge graph that enables intelligent tool selection and execution through graph-based retrieval-augmented generation. The agent also incorporates a comprehensive safety-checking module to ensure responsible and ethical tool usage. Extensive evaluations on a curated benchmark demonstrate that SciToolAgent significantly outperforms existing approaches. Case studies in protein engineering, chemical reactivity prediction, chemical synthesis, and metal-organic framework screening further demonstrate SciToolAgent's capability to automate complex scientific workflows, making advanced research tools accessible to both experts and non-experts.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Uncertainty-Aware Multi-Agent Collision Avoidance With Model Predictive Path Integral</title>
<link>https://arxiv.org/abs/2507.20293</link>
<guid>https://arxiv.org/abs/2507.20293</guid>
<content:encoded><![CDATA[
arXiv:2507.20293v1 Announce Type: new 
Abstract: Decentralized multi-agent navigation under uncertainty is a complex task that arises in numerous robotic applications. It requires collision avoidance strategies that account for both kinematic constraints, sensing and action execution noise. In this paper, we propose a novel approach that integrates the Model Predictive Path Integral (MPPI) with a probabilistic adaptation of Optimal Reciprocal Collision Avoidance. Our method ensures safe and efficient multi-agent navigation by incorporating probabilistic safety constraints directly into the MPPI sampling process via a Second-Order Cone Programming formulation. This approach enables agents to operate independently using local noisy observations while maintaining safety guarantees. We validate our algorithm through extensive simulations with differential-drive robots and benchmark it against state-of-the-art methods, including ORCA-DD and B-UAVC. Results demonstrate that our approach outperforms them while achieving high success rates, even in densely populated environments. Additionally, validation in the Gazebo simulator confirms its practical applicability to robotic platforms.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Shared and Multi-Agent Autonomy in Underwater Missions: Integrating Knowledge Graphs and Retrieval-Augmented Generation</title>
<link>https://arxiv.org/abs/2507.20370</link>
<guid>https://arxiv.org/abs/2507.20370</guid>
<content:encoded><![CDATA[
arXiv:2507.20370v1 Announce Type: new 
Abstract: Robotic platforms have become essential for marine operations by providing regular and continuous access to offshore assets, such as underwater infrastructure inspection, environmental monitoring, and resource exploration. However, the complex and dynamic nature of underwater environments, characterized by limited visibility, unpredictable currents, and communication constraints, presents significant challenges that demand advanced autonomy while ensuring operator trust and oversight. Central to addressing these challenges are knowledge representation and reasoning techniques, particularly knowledge graphs and retrieval-augmented generation (RAG) systems, that enable robots to efficiently structure, retrieve, and interpret complex environmental data. These capabilities empower robotic agents to reason, adapt, and respond effectively to changing conditions. The primary goal of this work is to demonstrate both multi-agent autonomy and shared autonomy, where multiple robotic agents operate independently while remaining connected to a human supervisor. We show how a RAG-powered large language model, augmented with knowledge graph data and domain taxonomy, enables autonomous multi-agent decision-making and facilitates seamless human-robot interaction, resulting in 100\% mission validation and behavior completeness. Finally, ablation studies reveal that without structured knowledge from the graph and/or taxonomy, the LLM is prone to hallucinations, which can compromise decision quality.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Dynamic Mobility Resource Allocation with Hierarchical Adaptive Grouping</title>
<link>https://arxiv.org/abs/2507.20377</link>
<guid>https://arxiv.org/abs/2507.20377</guid>
<content:encoded><![CDATA[
arXiv:2507.20377v1 Announce Type: new 
Abstract: Allocating mobility resources (e.g., shared bikes/e-scooters, ride-sharing vehicles) is crucial for rebalancing the mobility demand and supply in the urban environments. We propose in this work a novel multi-agent reinforcement learning named Hierarchical Adaptive Grouping-based Parameter Sharing (HAG-PS) for dynamic mobility resource allocation. HAG-PS aims to address two important research challenges regarding multi-agent reinforcement learning for mobility resource allocation: (1) how to dynamically and adaptively share the mobility resource allocation policy (i.e., how to distribute mobility resources) across agents (i.e., representing the regional coordinators of mobility resources); and (2) how to achieve memory-efficient parameter sharing in an urban-scale setting. To address the above challenges, we have provided following novel designs within HAG-PS. To enable dynamic and adaptive parameter sharing, we have designed a hierarchical approach that consists of global and local information of the mobility resource states (e.g., distribution of mobility resources). We have developed an adaptive agent grouping approach in order to split or merge the groups of agents based on their relative closeness of encoded trajectories (i.e., states, actions, and rewards). We have designed a learnable identity (ID) embeddings to enable agent specialization beyond simple parameter copy. We have performed extensive experimental studies based on real-world NYC bike sharing data (a total of more than 1.2 million trips), and demonstrated the superior performance (e.g., improved bike availability) of HAG-PS compared with other baseline approaches.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MazeEval: A Benchmark for Testing Sequential Decision-Making in Language Models</title>
<link>https://arxiv.org/abs/2507.20395</link>
<guid>https://arxiv.org/abs/2507.20395</guid>
<content:encoded><![CDATA[
arXiv:2507.20395v1 Announce Type: new 
Abstract: As Large Language Models (LLMs) increasingly power autonomous agents in robotics and embodied AI, understanding their spatial reasoning capabilities becomes crucial for ensuring reliable real-world deployment. Despite advances in language understanding, current research lacks evaluation of how LLMs perform spatial navigation without visual cues, a fundamental requirement for agents operating with limited sensory information. This paper addresses this gap by introducing MazeEval, a benchmark designed to isolate and evaluate pure spatial reasoning in LLMs through coordinate-based maze navigation tasks. Our methodology employs a function-calling interface where models navigate mazes of varying complexity ($5\times 5$ to $15\times 15$ grids) using only coordinate feedback and distance-to-wall information, excluding visual input to test fundamental spatial cognition. We evaluate eight state-of-the-art LLMs across identical mazes in both English and Icelandic to assess cross-linguistic transfer of spatial abilities. Our findings reveal striking disparities: while OpenAI's O3 achieves perfect navigation for mazes up to size $30\times 30$, other models exhibit catastrophic failure beyond $9\times 9$ mazes, with 100% of failures attributed to excessive looping behavior where models revisit a cell at least 10 times. We document a significant performance degradation in Icelandic, with models solving mazes 3-4 sizes smaller than in English, suggesting spatial reasoning in LLMs emerges from linguistic patterns rather than language-agnostic mechanisms. These results have important implications for global deployment of LLM-powered autonomous systems, showing spatial intelligence remains fundamentally constrained by training data availability and highlighting the need for architectural innovations to achieve reliable navigation across linguistic contexts.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FAST: Similarity-based Knowledge Transfer for Efficient Policy Learning</title>
<link>https://arxiv.org/abs/2507.20433</link>
<guid>https://arxiv.org/abs/2507.20433</guid>
<content:encoded><![CDATA[
arXiv:2507.20433v1 Announce Type: new 
Abstract: Transfer Learning (TL) offers the potential to accelerate learning by transferring knowledge across tasks. However, it faces critical challenges such as negative transfer, domain adaptation and inefficiency in selecting solid source policies. These issues often represent critical problems in evolving domains, i.e. game development, where scenarios transform and agents must adapt. The continuous release of new agents is costly and inefficient. In this work we challenge the key issues in TL to improve knowledge transfer, agents performance across tasks and reduce computational costs. The proposed methodology, called FAST - Framework for Adaptive Similarity-based Transfer, leverages visual frames and textual descriptions to create a latent representation of tasks dynamics, that is exploited to estimate similarity between environments. The similarity scores guides our method in choosing candidate policies from which transfer abilities to simplify learning of novel tasks. Experimental results, over multiple racing tracks, demonstrate that FAST achieves competitive final performance compared to learning-from-scratch methods while requiring significantly less training steps. These findings highlight the potential of embedding-driven task similarity estimations.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Physical Interaction Skills from Human Demonstrations</title>
<link>https://arxiv.org/abs/2507.20445</link>
<guid>https://arxiv.org/abs/2507.20445</guid>
<content:encoded><![CDATA[
arXiv:2507.20445v1 Announce Type: new 
Abstract: Learning physical interaction skills, such as dancing, handshaking, or sparring, remains a fundamental challenge for agents operating in human environments, particularly when the agent's morphology differs significantly from that of the demonstrator. Existing approaches often rely on handcrafted objectives or morphological similarity, limiting their capacity for generalization. Here, we introduce a framework that enables agents with diverse embodiments to learn wholebbody interaction behaviors directly from human demonstrations. The framework extracts a compact, transferable representation of interaction dynamics, called the Embedded Interaction Graph (EIG), which captures key spatiotemporal relationships between the interacting agents. This graph is then used as an imitation objective to train control policies in physics-based simulations, allowing the agent to generate motions that are both semantically meaningful and physically feasible. We demonstrate BuddyImitation on multiple agents, such as humans, quadrupedal robots with manipulators, or mobile manipulators and various interaction scenarios, including sparring, handshaking, rock-paper-scissors, or dancing. Our results demonstrate a promising path toward coordinated behaviors across morphologically distinct characters via cross embodiment interaction learning.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Security Challenges in AI Agent Deployment: Insights from a Large Scale Public Competition</title>
<link>https://arxiv.org/abs/2507.20526</link>
<guid>https://arxiv.org/abs/2507.20526</guid>
<content:encoded><![CDATA[
arXiv:2507.20526v1 Announce Type: new 
Abstract: Recent advances have enabled LLM-powered AI agents to autonomously execute complex tasks by combining language model reasoning with tools, memory, and web access. But can these systems be trusted to follow deployment policies in realistic environments, especially under attack? To investigate, we ran the largest public red-teaming competition to date, targeting 22 frontier AI agents across 44 realistic deployment scenarios. Participants submitted 1.8 million prompt-injection attacks, with over 60,000 successfully eliciting policy violations such as unauthorized data access, illicit financial actions, and regulatory noncompliance. We use these results to build the Agent Red Teaming (ART) benchmark - a curated set of high-impact attacks - and evaluate it across 19 state-of-the-art models. Nearly all agents exhibit policy violations for most behaviors within 10-100 queries, with high attack transferability across models and tasks. Importantly, we find limited correlation between agent robustness and model size, capability, or inference-time compute, suggesting that additional defenses are needed against adversarial misuse. Our findings highlight critical and persistent vulnerabilities in today's AI agents. By releasing the ART benchmark and accompanying evaluation framework, we aim to support more rigorous security assessment and drive progress toward safer agent deployment.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Kimi K2: Open Agentic Intelligence</title>
<link>https://arxiv.org/abs/2507.20534</link>
<guid>https://arxiv.org/abs/2507.20534</guid>
<content:encoded><![CDATA[
arXiv:2507.20534v1 Announce Type: new 
Abstract: We introduce Kimi K2, a Mixture-of-Experts (MoE) large language model with 32 billion activated parameters and 1 trillion total parameters. We propose the MuonClip optimizer, which improves upon Muon with a novel QK-clip technique to address training instability while enjoying the advanced token efficiency of Muon. Based on MuonClip, K2 was pre-trained on 15.5 trillion tokens with zero loss spike. During post-training, K2 undergoes a multi-stage post-training process, highlighted by a large-scale agentic data synthesis pipeline and a joint reinforcement learning (RL) stage, where the model improves its capabilities through interactions with real and synthetic environments.
  Kimi K2 achieves state-of-the-art performance among open-source non-thinking models, with strengths in agentic capabilities. Notably, K2 obtains 66.1 on Tau2-Bench, 76.5 on ACEBench (En), 65.8 on SWE-Bench Verified, and 47.3 on SWE-Bench Multilingual -- surpassing most open and closed-sourced baselines in non-thinking settings. It also exhibits strong capabilities in coding, mathematics, and reasoning tasks, with a score of 53.7 on LiveCodeBench v6, 49.5 on AIME 2025, 75.1 on GPQA-Diamond, and 27.1 on OJBench, all without extended thinking. These results position Kimi K2 as one of the most capable open-source large language models to date, particularly in software engineering and agentic tasks. We release our base and post-trained model checkpoints to facilitate future research and applications of agentic intelligence.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>T2I-Copilot: A Training-Free Multi-Agent Text-to-Image System for Enhanced Prompt Interpretation and Interactive Generation</title>
<link>https://arxiv.org/abs/2507.20536</link>
<guid>https://arxiv.org/abs/2507.20536</guid>
<content:encoded><![CDATA[
arXiv:2507.20536v1 Announce Type: new 
Abstract: Text-to-Image (T2I) generative models have revolutionized content creation but remain highly sensitive to prompt phrasing, often requiring users to repeatedly refine prompts multiple times without clear feedback. While techniques such as automatic prompt engineering, controlled text embeddings, denoising, and multi-turn generation mitigate these issues, they offer limited controllability, or often necessitate additional training, restricting the generalization abilities. Thus, we introduce T2I-Copilot, a training-free multi-agent system that leverages collaboration between (Multimodal) Large Language Models to automate prompt phrasing, model selection, and iterative refinement. This approach significantly simplifies prompt engineering while enhancing generation quality and text-image alignment compared to direct generation. Specifically, T2I-Copilot consists of three agents: (1) Input Interpreter, which parses the input prompt, resolves ambiguities, and generates a standardized report; (2) Generation Engine, which selects the appropriate model from different types of T2I models and organizes visual and textual prompts to initiate generation; and (3) Quality Evaluator, which assesses aesthetic quality and text-image alignment, providing scores and feedback for potential regeneration. T2I-Copilot can operate fully autonomously while also supporting human-in-the-loop intervention for fine-grained control. On GenAI-Bench, using open-source generation models, T2I-Copilot achieves a VQA score comparable to commercial models RecraftV3 and Imagen 3, surpasses FLUX1.1-pro by 6.17% at only 16.59% of its cost, and outperforms FLUX.1-dev and SD 3.5 Large by 9.11% and 6.36%. Code will be released at: https://github.com/SHI-Labs/T2I-Copilot.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Multimodal Architecture for Endpoint Position Prediction in Team-based Multiplayer Games</title>
<link>https://arxiv.org/abs/2507.20670</link>
<guid>https://arxiv.org/abs/2507.20670</guid>
<content:encoded><![CDATA[
arXiv:2507.20670v1 Announce Type: new 
Abstract: Understanding and predicting player movement in multiplayer games is crucial for achieving use cases such as player-mimicking bot navigation, preemptive bot control, strategy recommendation, and real-time player behavior analytics. However, the complex environments allow for a high degree of navigational freedom, and the interactions and team-play between players require models that make effective use of the available heterogeneous input data. This paper presents a multimodal architecture for predicting future player locations on a dynamic time horizon, using a U-Net-based approach for calculating endpoint location probability heatmaps, conditioned using a multimodal feature encoder. The application of a multi-head attention mechanism for different groups of features allows for communication between agents. In doing so, the architecture makes efficient use of the multimodal game state including image inputs, numerical and categorical features, as well as dynamic game data. Consequently, the presented technique lays the foundation for various downstream tasks that rely on future player positions such as the creation of player-predictive bot behavior or player anomaly detection.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A General Framework for Dynamic MAPF using Multi-Shot ASP and Tunnels</title>
<link>https://arxiv.org/abs/2507.20703</link>
<guid>https://arxiv.org/abs/2507.20703</guid>
<content:encoded><![CDATA[
arXiv:2507.20703v1 Announce Type: new 
Abstract: MAPF problem aims to find plans for multiple agents in an environment within a given time, such that the agents do not collide with each other or obstacles. Motivated by the execution and monitoring of these plans, we study Dynamic MAPF (D-MAPF) problem, which allows changes such as agents entering/leaving the environment or obstacles being removed/moved. Considering the requirements of real-world applications in warehouses with the presence of humans, we introduce 1) a general definition for D-MAPF (applicable to variations of D-MAPF), 2) a new framework to solve D-MAPF (utilizing multi-shot computation, and allowing different methods to solve D-MAPF), and 3) a new ASP-based method to solve D-MAPF (combining advantages of replanning and repairing methods, with a novel concept of tunnels to specify where agents can move). We have illustrated the strengths and weaknesses of this method by experimental evaluations, from the perspectives of computational performance and quality of solutions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning the Value Systems of Societies from Preferences</title>
<link>https://arxiv.org/abs/2507.20728</link>
<guid>https://arxiv.org/abs/2507.20728</guid>
<content:encoded><![CDATA[
arXiv:2507.20728v1 Announce Type: new 
Abstract: Aligning AI systems with human values and the value-based preferences of various stakeholders (their value systems) is key in ethical AI. In value-aware AI systems, decision-making draws upon explicit computational representations of individual values (groundings) and their aggregation into value systems. As these are notoriously difficult to elicit and calibrate manually, value learning approaches aim to automatically derive computational models of an agent's values and value system from demonstrations of human behaviour. Nonetheless, social science and humanities literature suggest that it is more adequate to conceive the value system of a society as a set of value systems of different groups, rather than as the simple aggregation of individual value systems. Accordingly, here we formalize the problem of learning the value systems of societies and propose a method to address it based on heuristic deep clustering. The method learns socially shared value groundings and a set of diverse value systems representing a given society by observing qualitative value-based preferences from a sample of agents. We evaluate the proposal in a use case with real data about travelling decisions.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dark Side of Modalities: Reinforced Multimodal Distillation for Multimodal Knowledge Graph Reasoning</title>
<link>https://arxiv.org/abs/2507.20738</link>
<guid>https://arxiv.org/abs/2507.20738</guid>
<content:encoded><![CDATA[
arXiv:2507.20738v1 Announce Type: new 
Abstract: The multimodal knowledge graph reasoning (MKGR) task aims to predict the missing facts in the incomplete MKGs by leveraging auxiliary images and descriptions of entities. Existing approaches are trained with single-target objectives, which neglect the probabilistic correlations of entity labels, especially in non-target entities. Moreover, previous studies incorporate all modalities statically or adaptively, overlooking the negative impacts of irrelevant or misleading information in the incompetent modalities. To address these issues, we introduce a novel Reinforced Multimodal Distillation framework, exploiting the Dark Side of Modalities (DSoM) from two perspectives: (1) Dark knowledge from non-target entities: We propose to train a unimodal KGR model through logit distillation to mimic the multimodal soft labels provided by pre-trained multimodal teacher models. The multimodal soft labels could provide rich supervision signals with subtle correlations among both target and non-target entities from multiple perspectives. We further decouple logits into neighbor entities and non-neighbor entities to divide into two types of correlations. (2) Dark side in unhelpful modalities: To exclude the adverse effects of unhelpful modalities, we introduce a reinforced teacher combination mechanism that dynamically selects the optimal set of multimodal teachers for each triple. The agent is trained to maximize the rewards, which are only assigned to the beneficial multimodal combination strategies for the student model. Comprehensive experiments demonstrate the effectiveness of DSoM framework on 5 MKGR datasets. Codes are available at github.com/OreOZhao/DSoM.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Line-of-Sight: Cooperative Localization Using Vision and V2X Communication</title>
<link>https://arxiv.org/abs/2507.20772</link>
<guid>https://arxiv.org/abs/2507.20772</guid>
<content:encoded><![CDATA[
arXiv:2507.20772v1 Announce Type: new 
Abstract: Accurate and robust localization is critical for the safe operation of Connected and Automated Vehicles (CAVs), especially in complex urban environments where Global Navigation Satellite System (GNSS) signals are unreliable. This paper presents a novel vision-based cooperative localization algorithm that leverages onboard cameras and Vehicle-to-Everything (V2X) communication to enable CAVs to estimate their poses, even in occlusion-heavy scenarios such as busy intersections. In particular, we propose a novel decentralized observer for a group of connected agents that includes landmark agents (static or moving) in the environment with known positions and vehicle agents that need to estimate their poses (both positions and orientations). Assuming that (i) there are at least three landmark agents in the environment, (ii) each vehicle agent can measure its own angular and translational velocities as well as relative bearings to at least three neighboring landmarks or vehicles, and (iii) neighboring vehicles can communicate their pose estimates, each vehicle can estimate its own pose using the proposed decentralized observer. We prove that the origin of the estimation error is locally exponentially stable under the proposed observer, provided that the minimal observability conditions are satisfied. Moreover, we evaluate the proposed approach through experiments with real 1/10th-scale connected vehicles and large-scale simulations, demonstrating its scalability and validating the theoretical guarantees in practical scenarios.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hanging Around: Cognitive Inspired Reasoning for Reactive Robotics</title>
<link>https://arxiv.org/abs/2507.20832</link>
<guid>https://arxiv.org/abs/2507.20832</guid>
<content:encoded><![CDATA[
arXiv:2507.20832v1 Announce Type: new 
Abstract: Situationally-aware artificial agents operating with competence in natural environments face several challenges: spatial awareness, object affordance detection, dynamic changes and unpredictability. A critical challenge is the agent's ability to identify and monitor environmental elements pertinent to its objectives. Our research introduces a neurosymbolic modular architecture for reactive robotics. Our system combines a neural component performing object recognition over the environment and image processing techniques such as optical flow, with symbolic representation and reasoning. The reasoning system is grounded in the embodied cognition paradigm, via integrating image schematic knowledge in an ontological structure. The ontology is operatively used to create queries for the perception system, decide on actions, and infer entities' capabilities derived from perceptual data. The combination of reasoning and image processing allows the agent to focus its perception for normal operation as well as discover new concepts for parts of objects involved in particular interactions. The discovered concepts allow the robot to autonomously acquire training data and adjust its subsymbolic perception to recognize the parts, as well as making planning for more complex tasks feasible by focusing search on those relevant object parts. We demonstrate our approach in a simulated world, in which an agent learns to recognize parts of objects involved in support relations. While the agent has no concept of handle initially, by observing examples of supported objects hanging from a hook it learns to recognize the parts involved in establishing support and becomes able to plan the establishment/destruction of the support relation. This underscores the agent's capability to expand its knowledge through observation in a systematic way, and illustrates the potential of combining deep reasoning [...].
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Free Energy-Inspired Cognitive Risk Integration for AV Navigation in Pedestrian-Rich Environments</title>
<link>https://arxiv.org/abs/2507.20850</link>
<guid>https://arxiv.org/abs/2507.20850</guid>
<content:encoded><![CDATA[
arXiv:2507.20850v1 Announce Type: new 
Abstract: Recent advances in autonomous vehicle (AV) behavior planning have shown impressive social interaction capabilities when interacting with other road users. However, achieving human-like prediction and decision-making in interactions with vulnerable road users remains a key challenge in complex multi-agent interactive environments. Existing research focuses primarily on crowd navigation for small mobile robots, which cannot be directly applied to AVs due to inherent differences in their decision-making strategies and dynamic boundaries. Moreover, pedestrians in these multi-agent simulations follow fixed behavior patterns that cannot dynamically respond to AV actions. To overcome these limitations, this paper proposes a novel framework for modeling interactions between the AV and multiple pedestrians. In this framework, a cognitive process modeling approach inspired by the Free Energy Principle is integrated into both the AV and pedestrian models to simulate more realistic interaction dynamics. Specifically, the proposed pedestrian Cognitive-Risk Social Force Model adjusts goal-directed and repulsive forces using a fused measure of cognitive uncertainty and physical risk to produce human-like trajectories. Meanwhile, the AV leverages this fused risk to construct a dynamic, risk-aware adjacency matrix for a Graph Convolutional Network within a Soft Actor-Critic architecture, allowing it to make more reasonable and informed decisions. Simulation results indicate that our proposed framework effectively improves safety, efficiency, and smoothness of AV navigation compared to the state-of-the-art method.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DriveAgent-R1: Advancing VLM-based Autonomous Driving with Hybrid Thinking and Active Perception</title>
<link>https://arxiv.org/abs/2507.20879</link>
<guid>https://arxiv.org/abs/2507.20879</guid>
<content:encoded><![CDATA[
arXiv:2507.20879v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) are advancing autonomous driving, yet their potential is constrained by myopic decision-making and passive perception, limiting reliability in complex environments. We introduce DriveAgent-R1 to tackle these challenges in long-horizon, high-level behavioral decision-making. DriveAgent-R1 features two core innovations: a Hybrid-Thinking framework that adaptively switches between efficient text-based and in-depth tool-based reasoning, and an Active Perception mechanism with a vision toolkit to proactively resolve uncertainties, thereby balancing decision-making efficiency and reliability. The agent is trained using a novel, three-stage progressive reinforcement learning strategy designed to master these hybrid capabilities. Extensive experiments demonstrate that DriveAgent-R1 achieves state-of-the-art performance, outperforming even leading proprietary large multimodal models, such as Claude Sonnet 4. Ablation studies validate our approach and confirm that the agent's decisions are robustly grounded in actively perceived visual evidence, paving a path toward safer and more intelligent autonomous systems.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fairness under Equal-Sized Bundles: Impossibility Results and Approximation Guarantees</title>
<link>https://arxiv.org/abs/2507.20899</link>
<guid>https://arxiv.org/abs/2507.20899</guid>
<content:encoded><![CDATA[
arXiv:2507.20899v1 Announce Type: new 
Abstract: We study the fair allocation of indivisible goods under cardinality constraints, where each agent must receive a bundle of fixed size. This models practical scenarios, such as assigning shifts or forming equally sized teams. Recently, variants of envy-freeness up to one/any item (EF1, EFX) were introduced for this setting, based on flips or exchanges of items. Namely, one can define envy-freeness up to one/any flip (EFF1, EFFX), meaning that an agent $i$ does not envy another agent $j$ after performing one or any one-item flip between their bundles that improves the value of $i$.
  We explore algorithmic aspects of this notion, and our contribution is twofold: we present both algorithmic and impossibility results, highlighting a stark contrast between the classic EFX concept and its flip-based analogue. First, we explore standard techniques used in the literature and show that they fail to guarantee EFFX approximations. On the positive side, we show that we can achieve a constant factor approximation guarantee when agents share a common ranking over item values, based on the well-known envy cycle elimination technique. This idea also leads to a generalized algorithm with approximation guarantees when agents agree on the top $n$ items and their valuation functions are bounded. Finally, we show that an algorithm that maximizes the Nash welfare guarantees a 1/2-EFF1 allocation, and that this bound is tight.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Core Safety Values for Provably Corrigible Agents</title>
<link>https://arxiv.org/abs/2507.20964</link>
<guid>https://arxiv.org/abs/2507.20964</guid>
<content:encoded><![CDATA[
arXiv:2507.20964v1 Announce Type: new 
Abstract: We introduce the first implementable framework for corrigibility, with provable guarantees in multi-step, partially observed environments. Our framework replaces a single opaque reward with five *structurally separate* utility heads -- deference, switch-access preservation, truthfulness, low-impact behavior via a belief-based extension of Attainable Utility Preservation, and bounded task reward -- combined lexicographically by strict weight gaps. Theorem 1 proves exact single-round corrigibility in the partially observable off-switch game; Theorem 3 extends the guarantee to multi-step, self-spawning agents, showing that even if each head is \emph{learned} to mean-squared error $\varepsilon$ and the planner is $\varepsilon$-sub-optimal, the probability of violating \emph{any} safety property is bounded while still ensuring net human benefit. In contrast to Constitutional AI or RLHF/RLAIF, which merge all norms into one learned scalar, our separation makes obedience and impact-limits dominate even when incentives conflict. For open-ended settings where adversaries can modify the agent, we prove that deciding whether an arbitrary post-hack agent will ever violate corrigibility is undecidable by reduction to the halting problem, then carve out a finite-horizon ``decidable island'' where safety can be certified in randomized polynomial time and verified with privacy-preserving, constant-round zero-knowledge proofs. Consequently, the remaining challenge is the ordinary ML task of data coverage and generalization: reward-hacking risk is pushed into evaluation quality rather than hidden incentive leak-through, giving clearer implementation guidance for today's LLM assistants and future autonomous systems.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Behavioral Study of Dashboard Mechanisms</title>
<link>https://arxiv.org/abs/2507.20985</link>
<guid>https://arxiv.org/abs/2507.20985</guid>
<content:encoded><![CDATA[
arXiv:2507.20985v1 Announce Type: new 
Abstract: Visualization dashboards are increasingly used in strategic settings like auctions to enhance decision-making and reduce strategic confusion. This paper presents behavioral experiments evaluating how different dashboard designs affect bid optimization in reverse first-price auctions. Additionally, we assess how dashboard designs impact the auction designer's ability to accurately infer bidders' preferences within the dashboard mechanism framework. We compare visualizations of the bid allocation rule, commonly deployed in practice, to alternatives that display expected utility. We find that utility-based visualizations significantly improve bidding by reducing cognitive demands on bidders. However, even with improved dashboards, bidders systematically under-shade their bids, driven by an implicit preference for certain wins in uncertain settings. As a result, dashboard-based mechanisms that assume fully rational or risk-neutral bidder responses to dashboards can produce significant estimation errors when inferring private preferences, which may lead to suboptimal allocations in practice. Explicitly modeling agents' behavioral responses to dashboards substantially improves inference accuracy, highlighting the need to align visualization design and econometric inference assumptions in practice.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MIRAGE-Bench: LLM Agent is Hallucinating and Where to Find Them</title>
<link>https://arxiv.org/abs/2507.21017</link>
<guid>https://arxiv.org/abs/2507.21017</guid>
<content:encoded><![CDATA[
arXiv:2507.21017v1 Announce Type: new 
Abstract: Hallucinations pose critical risks for large language model (LLM)-based agents, often manifesting as hallucinative actions resulting from fabricated or misinterpreted information within the cognitive context. While recent studies have exposed such failures, existing evaluations remain fragmented and lack a principled testbed. In this paper, we present MIRAGE-Bench--Measuring Illusions in Risky AGEnt settings--the first unified benchmark for eliciting and evaluating hallucinations in interactive LLM-agent scenarios. We begin by introducing a three-part taxonomy to address agentic hallucinations: actions that are unfaithful to (i) task instructions, (ii) execution history, or (iii) environment observations. To analyze, we first elicit such failures by performing a systematic audit of existing agent benchmarks, then synthesize test cases using a snapshot strategy that isolates decision points in deterministic and reproducible manners. To evaluate hallucination behaviors, we adopt a fine-grained-level LLM-as-a-Judge paradigm with tailored risk-aware prompts, enabling scalable, high-fidelity assessment of agent actions without enumerating full action spaces. MIRAGE-Bench provides actionable insights on failure modes of LLM agents and lays the groundwork for principled progress in mitigating hallucinations in interactive environments.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent-as-Judge: Aligning LLM-Agent-Based Automated Evaluation with Multi-Dimensional Human Evaluation</title>
<link>https://arxiv.org/abs/2507.21028</link>
<guid>https://arxiv.org/abs/2507.21028</guid>
<content:encoded><![CDATA[
arXiv:2507.21028v1 Announce Type: new 
Abstract: Nearly all human work is collaborative; thus, the evaluation of real-world NLP applications often requires multiple dimensions that align with diverse human perspectives. As real human evaluator resources are often scarce and costly, the emerging "LLM-as-a-judge" paradigm sheds light on a promising approach to leverage LLM agents to believably simulate human evaluators. Yet, to date, existing LLM-as-a-judge approaches face two limitations: persona descriptions of agents are often arbitrarily designed, and the frameworks are not generalizable to other tasks. To address these challenges, we propose MAJ-EVAL, a Multi-Agent-as-Judge evaluation framework that can automatically construct multiple evaluator personas with distinct dimensions from relevant text documents (e.g., research papers), instantiate LLM agents with the personas, and engage in-group debates with multi-agents to Generate multi-dimensional feedback. Our evaluation experiments in both the educational and medical domains demonstrate that MAJ-EVAL can generate evaluation results that better align with human experts' ratings compared with conventional automated evaluation metrics and existing LLM-as-a-judge methods.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GenoMAS: A Multi-Agent Framework for Scientific Discovery via Code-Driven Gene Expression Analysis</title>
<link>https://arxiv.org/abs/2507.21035</link>
<guid>https://arxiv.org/abs/2507.21035</guid>
<content:encoded><![CDATA[
arXiv:2507.21035v1 Announce Type: new 
Abstract: Gene expression analysis holds the key to many biomedical discoveries, yet extracting insights from raw transcriptomic data remains formidable due to the complexity of multiple large, semi-structured files and the need for extensive domain expertise. Current automation approaches are often limited by either inflexible workflows that break down in edge cases or by fully autonomous agents that lack the necessary precision for rigorous scientific inquiry. GenoMAS charts a different course by presenting a team of LLM-based scientists that integrates the reliability of structured workflows with the adaptability of autonomous agents. GenoMAS orchestrates six specialized LLM agents through typed message-passing protocols, each contributing complementary strengths to a shared analytic canvas. At the heart of GenoMAS lies a guided-planning framework: programming agents unfold high-level task guidelines into Action Units and, at each juncture, elect to advance, revise, bypass, or backtrack, thereby maintaining logical coherence while bending gracefully to the idiosyncrasies of genomic data.
  On the GenoTEX benchmark, GenoMAS reaches a Composite Similarity Correlation of 89.13% for data preprocessing and an F$_1$ of 60.48% for gene identification, surpassing the best prior art by 10.61% and 16.85% respectively. Beyond metrics, GenoMAS surfaces biologically plausible gene-phenotype associations corroborated by the literature, all while adjusting for latent confounders. Code is available at https://github.com/Liu-Hy/GenoMAS.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Self-Evolving Agents: On Path to Artificial Super Intelligence</title>
<link>https://arxiv.org/abs/2507.21046</link>
<guid>https://arxiv.org/abs/2507.21046</guid>
<content:encoded><![CDATA[
arXiv:2507.21046v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong capabilities but remain fundamentally static, unable to adapt their internal parameters to novel tasks, evolving knowledge domains, or dynamic interaction contexts. As LLMs are increasingly deployed in open-ended, interactive environments, this static nature has become a critical bottleneck, necessitating agents that can adaptively reason, act, and evolve in real time. This paradigm shift -- from scaling static models to developing self-evolving agents -- has sparked growing interest in architectures and methods enabling continual learning and adaptation from data, interactions, and experiences. This survey provides the first systematic and comprehensive review of self-evolving agents, organized around three foundational dimensions -- what to evolve, when to evolve, and how to evolve. We examine evolutionary mechanisms across agent components (e.g., models, memory, tools, architecture), categorize adaptation methods by stages (e.g., intra-test-time, inter-test-time), and analyze the algorithmic and architectural designs that guide evolutionary adaptation (e.g., scalar rewards, textual feedback, single-agent and multi-agent systems). Additionally, we analyze evaluation metrics and benchmarks tailored for self-evolving agents, highlight applications in domains such as coding, education, and healthcare, and identify critical challenges and research directions in safety, scalability, and co-evolutionary dynamics. By providing a structured framework for understanding and designing self-evolving agents, this survey establishes a roadmap for advancing adaptive agentic systems in both research and real-world deployments, ultimately shedding lights to pave the way for the realization of Artificial Super Intelligence (ASI), where agents evolve autonomously, performing at or beyond human-level intelligence across a wide array of tasks.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-Propelled Agents and Group Social Force</title>
<link>https://arxiv.org/abs/2411.09840</link>
<guid>https://arxiv.org/abs/2411.09840</guid>
<content:encoded><![CDATA[
arXiv:2411.09840v3 Announce Type: cross 
Abstract: Brownian motion have long been studied on a diversity of fields, not only in physics of statistical mechanics, but also in biological models, finance and economic process, and social systems. In the past twenty years, there has been a growing interest in studying the model in self-propelled feature and interaction force such that the model also fits into study of social phenomenon of many individuals. This article will continue with this research trend and especially investigate the model in paradigms for a quantitative description of social and economic process. We mainly discuss a class of collective decision process of Brownian agent/particles, where the stochastic process does not exist in the fluctuation in the traditional Brownian motion, but in selection among several discrete choices. Their decisions interacts with each other in a given social topology. To simplify our discussion the binary choice problem is particularly discussed where each agent only takes an alternative of two choices. Mathematically, we introduce a set of arrays to describe social relationship of agents in a quantitative manner, and the arrays deduce the group social force and opinion dynamics, which are useful to study complex social movement and self-organization phenomena including discrete-choice activities, social groups and de-individualization effect. Such agent-based simulation symbolizes a variety of collective activities in human society, especially in the field of economics and social science.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantum Reinforcement Learning by Adaptive Non-local Observables</title>
<link>https://arxiv.org/abs/2507.19629</link>
<guid>https://arxiv.org/abs/2507.19629</guid>
<content:encoded><![CDATA[
arXiv:2507.19629v1 Announce Type: cross 
Abstract: Hybrid quantum-classical frameworks leverage quantum computing for machine learning; however, variational quantum circuits (VQCs) are limited by the need for local measurements. We introduce an adaptive non-local observable (ANO) paradigm within VQCs for quantum reinforcement learning (QRL), jointly optimizing circuit parameters and multi-qubit measurements. The ANO-VQC architecture serves as the function approximator in Deep Q-Network (DQN) and Asynchronous Advantage Actor-Critic (A3C) algorithms. On multiple benchmark tasks, ANO-VQC agents outperform baseline VQCs. Ablation studies reveal that adaptive measurements enhance the function space without increasing circuit depth. Our results demonstrate that adaptive multi-qubit observables can enable practical quantum advantages in reinforcement learning.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical clustering and dimensional reduction for optimal control of large-scale agent-based models</title>
<link>https://arxiv.org/abs/2507.19644</link>
<guid>https://arxiv.org/abs/2507.19644</guid>
<content:encoded><![CDATA[
arXiv:2507.19644v1 Announce Type: cross 
Abstract: Agent-based models (ABMs) provide a powerful framework to describe complex systems composed of interacting entities, capable of producing emergent collective behaviours such as consensus formation or clustering. However, the increasing dimensionality of these models -- in terms of both the number of agents and the size of their state space -- poses significant computational challenges, particularly in the context of optimal control. In this work, we propose a scalable control frame work for large-scale ABMs based on a twofold model order reduction strategy: agent clustering and projection-based reduction via Proper Orthogonal Decomposition (POD). These techniques are integrated into a feedback loop that enables the design and application of optimal control laws over a reduced-order representation of the system. To illustrate the effectiveness of the approach, we consider the opinion dynamics model, a prototyp ical first-order ABM where agents interact through state-dependent influence functions. We show that our method significantly improves control efficiency, even in scenarios where direct control fails due to model complexity. Beyond its methodological contributions, this work also highlights the rel evance of opinion dynamics models in environmental contexts -- for example, modeling the diffusion of pro-environmental attitudes or decision-making processes in sustainable policy adoption -- where controlling consensus formation plays a crucial role.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ultracoarse Equilibria and Ordinal-Folding Dynamics in Operator-Algebraic Models of Infinite Multi-Agent Games</title>
<link>https://arxiv.org/abs/2507.19694</link>
<guid>https://arxiv.org/abs/2507.19694</guid>
<content:encoded><![CDATA[
arXiv:2507.19694v1 Announce Type: cross 
Abstract: We develop an operator algebraic framework for infinite games with a continuum of agents and prove that regret based learning dynamics governed by a noncommutative continuity equation converge to a unique quantal response equilibrium under mild regularity assumptions. The framework unifies functional analysis, coarse geometry and game theory by assigning to every game a von Neumann algebra that represents collective strategy evolution. A reflective regret operator within this algebra drives the flow of strategy distributions and its fixed point characterises equilibrium. We introduce the ordinal folding index, a computable ordinal valued metric that measures the self referential depth of the dynamics, and show that it bounds the transfinite time needed for convergence, collapsing to zero on coarsely amenable networks. The theory yields new invariant subalgebra rigidity results, establishes existence and uniqueness of envy free and maximin share allocations in continuum economies, and links analytic properties of regret flows with empirical stability phenomena in large language models. These contributions supply a rigorous mathematical foundation for large scale multi agent systems and demonstrate the utility of ordinal metrics for equilibrium selection.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DynamiX: Large-Scale Dynamic Social Network Simulator</title>
<link>https://arxiv.org/abs/2507.19929</link>
<guid>https://arxiv.org/abs/2507.19929</guid>
<content:encoded><![CDATA[
arXiv:2507.19929v1 Announce Type: cross 
Abstract: Understanding the intrinsic mechanisms of social platforms is an urgent demand to maintain social stability. The rise of large language models provides significant potential for social network simulations to capture attitude dynamics and reproduce collective behaviors. However, existing studies mainly focus on scaling up agent populations, neglecting the dynamic evolution of social relationships. To address this gap, we introduce DynamiX, a novel large-scale social network simulator dedicated to dynamic social network modeling. DynamiX uses a dynamic hierarchy module for selecting core agents with key characteristics at each timestep, enabling accurate alignment of real-world adaptive switching of user roles. Furthermore, we design distinct dynamic social relationship modeling strategies for different user types. For opinion leaders, we propose an information-stream-based link prediction method recommending potential users with similar stances, simulating homogeneous connections, and autonomous behavior decisions. For ordinary users, we construct an inequality-oriented behavior decision-making module, effectively addressing unequal social interactions and capturing the patterns of relationship adjustments driven by multi-dimensional factors. Experimental results demonstrate that DynamiX exhibits marked improvements in attitude evolution simulation and collective behavior analysis compared to static networks. Besides, DynamiX opens a new theoretical perspective on follower growth prediction, providing empirical evidence for opinion leaders cultivation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Building crypto portfolios with agentic AI</title>
<link>https://arxiv.org/abs/2507.20468</link>
<guid>https://arxiv.org/abs/2507.20468</guid>
<content:encoded><![CDATA[
arXiv:2507.20468v1 Announce Type: cross 
Abstract: The rapid growth of crypto markets has opened new opportunities for investors, but at the same time exposed them to high volatility. To address the challenge of managing dynamic portfolios in such an environment, this paper presents a practical application of a multi-agent system designed to autonomously construct and evaluate crypto-asset allocations. Using data on daily frequencies of the ten most capitalized cryptocurrencies from 2020 to 2025, we compare two automated investment strategies. These are a static equal weighting strategy and a rolling-window optimization strategy, both implemented to maximize the evaluation metrics of the Modern Portfolio Theory (MPT), such as Expected Return, Sharpe and Sortino ratios, while minimizing volatility. Each step of the process is handled by dedicated agents, integrated through a collaborative architecture in Crew AI. The results show that the dynamic optimization strategy achieves significantly better performance in terms of risk-adjusted returns, both in-sample and out-of-sample. This highlights the benefits of adaptive techniques in portfolio management, particularly in volatile markets such as cryptocurrency markets. The following methodology proposed also demonstrates how multi-agent systems can provide scalable, auditable, and flexible solutions in financial automation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MountainLion: A Multi-Modal LLM-Based Agent System for Interpretable and Adaptive Financial Trading</title>
<link>https://arxiv.org/abs/2507.20474</link>
<guid>https://arxiv.org/abs/2507.20474</guid>
<content:encoded><![CDATA[
arXiv:2507.20474v1 Announce Type: cross 
Abstract: Cryptocurrency trading is a challenging task requiring the integration of heterogeneous data from multiple modalities. Traditional deep learning and reinforcement learning approaches typically demand large training datasets and encode diverse inputs into numerical representations, often at the cost of interpretability. Recent progress in large language model (LLM)-based agents has demonstrated the capacity to process multi-modal data and support complex investment decision-making. Building on these advances, we present \textbf{MountainLion}, a multi-modal, multi-agent system for financial trading that coordinates specialized LLM-based agents to interpret financial data and generate investment strategies. MountainLion processes textual news, candlestick charts, and trading signal charts to produce high-quality financial reports, while also enabling modification of reports and investment recommendations through data-driven user interaction and question answering. A central reflection module analyzes historical trading signals and outcomes to continuously refine decision processes, and the system is capable of real-time report analysis, summarization, and dynamic adjustment of investment strategies. Empirical results confirm that MountainLion systematically enriches technical price triggers with contextual macroeconomic and capital flow signals, providing a more interpretable, robust, and actionable investment framework that improves returns and strengthens investor confidence.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aligning Large Language Model Agents with Rational and Moral Preferences: A Supervised Fine-Tuning Approach</title>
<link>https://arxiv.org/abs/2507.20796</link>
<guid>https://arxiv.org/abs/2507.20796</guid>
<content:encoded><![CDATA[
arXiv:2507.20796v1 Announce Type: cross 
Abstract: Understanding how large language model (LLM) agents behave in strategic interactions is essential as these systems increasingly participate autonomously in economically and morally consequential decisions. We evaluate LLM preferences using canonical economic games, finding substantial deviations from human behavior. Models like GPT-4o show excessive cooperation and limited incentive sensitivity, while reasoning models, such as o3-mini, align more consistently with payoff-maximizing strategies. We propose a supervised fine-tuning pipeline that uses synthetic datasets derived from economic reasoning to align LLM agents with economic preferences, focusing on two stylized preference structures. In the first, utility depends only on individual payoffs (homo economicus), while utility also depends on a notion of Kantian universalizability in the second preference structure (homo moralis). We find that fine-tuning based on small datasets shifts LLM agent behavior toward the corresponding economic agent. We further assess the fine-tuned agents' behavior in two applications: Moral dilemmas involving autonomous vehicles and algorithmic pricing in competitive markets. These examples illustrate how different normative objectives embedded via realizations from structured preference structures can influence market and moral outcomes. This work contributes a replicable, cost-efficient, and economically grounded pipeline to align AI preferences using moral-economic principles.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Algebras of actions in an agent's representations of the world</title>
<link>https://arxiv.org/abs/2310.01536</link>
<guid>https://arxiv.org/abs/2310.01536</guid>
<content:encoded><![CDATA[
arXiv:2310.01536v2 Announce Type: replace 
Abstract: In this paper, we propose a framework to extract the algebra of the transformations of worlds from the perspective of an agent. As a starting point, we use our framework to reproduce the symmetry-based representations from the symmetry-based disentangled representation learning (SBDRL) formalism proposed by [1]; only the algebra of transformations of worlds that form groups can be described using symmetry-based representations. We then study the algebras of the transformations of worlds with features that occur in simple reinforcement learning scenarios. Using computational methods, that we developed, we extract the algebras of the transformations of these worlds and classify them according to their properties. Finally, we generalise two important results of SBDRL - the equivariance condition and the disentangling definition - from only working with symmetry-based representations to working with representations capturing the transformation properties of worlds with transformations for any algebra. Finally, we combine our generalised equivariance condition and our generalised disentangling definition to show that disentangled sub-algebras can each have their own individual equivariance conditions, which can be treated independently.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Contrastive learning-based agent modeling for deep reinforcement learning</title>
<link>https://arxiv.org/abs/2401.00132</link>
<guid>https://arxiv.org/abs/2401.00132</guid>
<content:encoded><![CDATA[
arXiv:2401.00132v3 Announce Type: replace 
Abstract: Multi-agent systems often require agents to collaborate with or compete against other agents with diverse goals, behaviors, or strategies. Agent modeling is essential when designing adaptive policies for intelligent machine agents in multiagent systems, as this is the means by which the ego agent understands other agents' behavior and extracts their meaningful policy representations. These representations can be used to enhance the ego agent's adaptive policy which is trained by reinforcement learning. However, existing agent modeling approaches typically assume the availability of local observations from other agents (modeled agents) during training or a long observation trajectory for policy adaption. To remove these constrictive assumptions and improve agent modeling performance, we devised a Contrastive Learning-based Agent Modeling (CLAM) method that relies only on the local observations from the ego agent during training and execution. With these observations, CLAM is capable of generating consistent high-quality policy representations in real-time right from the beginning of each episode. We evaluated the efficacy of our approach in both cooperative and competitive multi-agent environments. Our experiments demonstrate that our approach achieves state-of-the-art on both cooperative and competitive tasks, highlighting the potential of contrastive learning-based agent modeling for enhancing reinforcement learning.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe and Stable Formation Control with Autonomous Multi-Agents Using Adaptive Control (Extended Version)</title>
<link>https://arxiv.org/abs/2403.15674</link>
<guid>https://arxiv.org/abs/2403.15674</guid>
<content:encoded><![CDATA[
arXiv:2403.15674v4 Announce Type: replace 
Abstract: This manuscript considers the problem of ensuring stability and safety during formation control with distributed multi-agent systems in the presence of parametric uncertainty in the dynamics and limited communication. We propose an integrative approach that combines Adaptive Control, Control Barrier Functions (CBFs), and connected graphs. The main elements employed in the integrative approach are an adaptive control design that ensures stability, a CBF-based safety filter that generates safe commands based on a reference model dynamics, and a reference model that ensures formation control with multi-agent systems when no uncertainties are present. The overall control design is shown to lead to a closed-loop adaptive system that is stable, avoids unsafe regions, and converges to a desired formation of the multi-agents. Numerical examples are provided to support the theoretical derivations.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Clarify: Multi-turn Conversations with Action-Based Contrastive Self-Training</title>
<link>https://arxiv.org/abs/2406.00222</link>
<guid>https://arxiv.org/abs/2406.00222</guid>
<content:encoded><![CDATA[
arXiv:2406.00222v2 Announce Type: replace 
Abstract: Large language models (LLMs), optimized through human feedback, have rapidly emerged as a leading paradigm for developing intelligent conversational assistants. However, despite their strong performance across many benchmarks, LLM-based agents might still lack conversational skills such as disambiguation -- when they are faced with ambiguity, they often overhedge or implicitly guess users' true intents rather than asking clarification questions. Under task-specific settings, high-quality conversation samples are often limited, constituting a bottleneck for LLMs' ability to learn optimal dialogue action policies. We propose Action-Based Contrastive Self-Training (ACT), a quasi-online preference optimization algorithm based on Direct Preference Optimization (DPO), that enables data-efficient dialogue policy learning in multi-turn conversation modeling. We demonstrate ACT's efficacy under in data-efficient tuning scenarios, even when there is no action label available, using multiple real-world conversational tasks: tabular-grounded question-answering, machine reading comprehension, and AmbigSQL, a novel task for disambiguating information-seeking requests for complex SQL generation towards data analysis agents. Additionally, we propose evaluating LLMs' ability to function as conversational agents by examining whether they can implicitly recognize and reason about ambiguity in conversation. ACT demonstrates substantial conversation modeling improvements over standard tuning approaches like supervised fine-tuning and DPO.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM2TEA: An Agentic AI Designer for Discovery with Generative Evolutionary Multitasking</title>
<link>https://arxiv.org/abs/2406.14917</link>
<guid>https://arxiv.org/abs/2406.14917</guid>
<content:encoded><![CDATA[
arXiv:2406.14917v3 Announce Type: replace 
Abstract: This paper presents LLM2TEA, a Large Language Model (LLM) driven MultiTask Evolutionary Algorithm, representing the first agentic AI designer of its kind operating with generative evolutionary multitasking (GEM). LLM2TEA enables the crossbreeding of solutions from multiple domains, fostering novel solutions that transcend disciplinary boundaries. Of particular interest is the ability to discover designs that are both novel and conforming to real-world physical specifications. LLM2TEA comprises an LLM to generate genotype samples from text prompts describing target objects, a text-to-3D generative model to produce corresponding phenotypes, a classifier to interpret its semantic representations, and a computational simulator to assess its physical properties. Novel LLM-based multitask evolutionary operators are introduced to guide the search towards high-performing, practically viable designs. Experimental results in conceptual design optimization validate the effectiveness of LLM2TEA, showing 97% to 174% improvements in the diversity of novel designs over the current text-to-3D baseline. Moreover, over 73% of the generated designs outperform the top 1% of designs produced by the text-to-3D baseline in terms of physical performance. The designs produced by LLM2TEA are not only aesthetically creative but also functional in real-world contexts. Several of these designs have been successfully 3D printed, demonstrating the ability of our approach to transform AI-generated outputs into tangible, physical designs. These designs underscore the potential of LLM2TEA as a powerful tool for complex design optimization and discovery, capable of producing novel and physically viable designs.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Leaning for Infinite-Dimensional Systems</title>
<link>https://arxiv.org/abs/2409.15737</link>
<guid>https://arxiv.org/abs/2409.15737</guid>
<content:encoded><![CDATA[
arXiv:2409.15737v2 Announce Type: replace 
Abstract: Interest in reinforcement learning (RL) for massive-scale systems consisting of large populations of intelligent agents interacting with heterogeneous environments has witnessed a significant surge in recent years across diverse scientific domains. However, the large-scale nature of these systems often results in high computational costs or compromised performance for most state-of-the-art RL techniques. To address these challenges, we propose a novel RL architecture along with the derivation of effective algorithms to learn optimal policies for arbitrarily large systems of agents. In our formulation, we model such a system as a parameterized control system defined on an infinite-dimensional function space. We then develop a moment kernel transform to map the parameterized system and the value function into a reproducing kernel Hilbert space. This transformation generates a sequence of finite-dimensional moment representations for the RL problem, which are organized into a filtrated structure. Leveraging this RL filtration, we develop a hierarchical algorithm for learning optimal policies for the infinite-dimensional parameterized system. We further enhance the efficiency of the algorithm by exploiting early stopping at each hierarchy, which demonstrates the fast convergence property of the algorithm through the construction of a convergent spectral sequence. The performance and efficiency of the proposed algorithm are validated using practical examples.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning for Finite Space Mean-Field Type Games</title>
<link>https://arxiv.org/abs/2409.18152</link>
<guid>https://arxiv.org/abs/2409.18152</guid>
<content:encoded><![CDATA[
arXiv:2409.18152v3 Announce Type: replace 
Abstract: Mean field type games (MFTGs) describe Nash equilibria between large coalitions: each coalition consists of a continuum of cooperative agents who maximize the average reward of their coalition while interacting non-cooperatively with a finite number of other coalitions. Although the theory has been extensively developed, we are still lacking efficient and scalable computational methods. Here, we develop reinforcement learning methods for such games in a finite space setting with general dynamics and reward functions. We start by proving that the MFTG solution yields approximate Nash equilibria in finite-size coalition games. We then propose two algorithms. The first is based on the quantization of mean-field spaces and Nash Q-learning. We provide convergence and stability analysis. We then propose a deep reinforcement learning algorithm, which can scale to larger spaces. Numerical experiments in 4 environments with mean-field distributions of dimension up to $200$ show the scalability and efficiency of the proposed method.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advanced System Integration: Analyzing OpenAPI Chunking for Retrieval-Augmented Generation</title>
<link>https://arxiv.org/abs/2411.19804</link>
<guid>https://arxiv.org/abs/2411.19804</guid>
<content:encoded><![CDATA[
arXiv:2411.19804v2 Announce Type: replace 
Abstract: Integrating multiple (sub-)systems is essential to create advanced Information Systems (ISs). Difficulties mainly arise when integrating dynamic environments across the IS lifecycle. A traditional approach is a registry that provides the API documentation of the systems' endpoints. Large Language Models (LLMs) have shown to be capable of automatically creating system integrations (e.g., as service composition) based on this documentation but require concise input due to input token limitations, especially regarding comprehensive API descriptions. Currently, it is unknown how best to preprocess these API descriptions. Within this work, we (i) analyze the usage of Retrieval Augmented Generation (RAG) for endpoint discovery and the chunking, i.e., preprocessing, of OpenAPIs to reduce the input token length while preserving the most relevant information. To further reduce the input token length for the composition prompt and improve endpoint retrieval, we propose (ii) a Discovery Agent that only receives a summary of the most relevant endpoints and retrieves details on demand. We evaluate RAG for endpoint discovery using the RestBench benchmark, first, for the different chunking possibilities and parameters measuring the endpoint retrieval recall, precision, and F1 score. Then, we assess the Discovery Agent using the same test set. With our prototype, we demonstrate how to successfully employ RAG for endpoint discovery to reduce the token count. While revealing high values for recall, precision, and F1, further research is necessary to retrieve all requisite endpoints. Our experiments show that for preprocessing, LLM-based and format-specific approaches outperform na\"ive chunking methods. Relying on an agent further enhances these results as the agent splits the tasks into multiple fine granular subtasks, improving the overall RAG performance in the token count, precision, and F1 score.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents</title>
<link>https://arxiv.org/abs/2502.18509</link>
<guid>https://arxiv.org/abs/2502.18509</guid>
<content:encoded><![CDATA[
arXiv:2502.18509v2 Announce Type: replace 
Abstract: Conversational agents are increasingly woven into individuals' personal lives, yet users often underestimate the privacy risks associated with them. The moment users share information with these agents-such as large language models (LLMs)-their private information becomes vulnerable to exposure. In this paper, we characterize the notion of contextual privacy for user interactions with LLM-based Conversational Agents (LCAs). It aims to minimize privacy risks by ensuring that users (sender) disclose only information that is both relevant and necessary for achieving their intended goals when interacting with LCAs (untrusted receivers). Through a formative design user study, we observe how even "privacy-conscious" users inadvertently reveal sensitive information through indirect disclosures. Based on insights from this study, we propose a locally deployable framework that operates between users and LCAs, identifying and reformulating out-of-context information in user prompts. Our evaluation using examples from ShareGPT shows that lightweight models can effectively implement this framework, achieving strong gains in contextual privacy while preserving the user's intended interaction goals. Notably, about 76% of participants in our human evaluation preferred the reformulated prompts over the original ones, validating the usability and effectiveness of contextual privacy in our proposed framework. We opensource the code at https://github.com/IBM/contextual-privacy-LLM.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents</title>
<link>https://arxiv.org/abs/2503.08026</link>
<guid>https://arxiv.org/abs/2503.08026</guid>
<content:encoded><![CDATA[
arXiv:2503.08026v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have made significant progress in open-ended dialogue, yet their inability to retain and retrieve relevant information from long-term interactions limits their effectiveness in applications requiring sustained personalization. External memory mechanisms have been proposed to address this limitation, enabling LLMs to maintain conversational continuity. However, existing approaches struggle with two key challenges. First, rigid memory granularity fails to capture the natural semantic structure of conversations, leading to fragmented and incomplete representations. Second, fixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user interaction patterns. In this work, we propose Reflective Memory Management (RMM), a novel mechanism for long-term dialogue agents, integrating forward- and backward-looking reflections: (1) Prospective Reflection, which dynamically summarizes interactions across granularities-utterances, turns, and sessions-into a personalized memory bank for effective future retrieval, and (2) Retrospective Reflection, which iteratively refines the retrieval in an online reinforcement learning (RL) manner based on LLMs' cited evidence. Experiments show that RMM demonstrates consistent improvement across various metrics and benchmarks. For example, RMM shows more than 10% accuracy improvement over the baseline without memory management on the LongMemEval dataset.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hydra-NeXt: Robust Closed-Loop Driving with Open-Loop Training</title>
<link>https://arxiv.org/abs/2503.12030</link>
<guid>https://arxiv.org/abs/2503.12030</guid>
<content:encoded><![CDATA[
arXiv:2503.12030v2 Announce Type: replace 
Abstract: End-to-end autonomous driving research currently faces a critical challenge in bridging the gap between open-loop training and closed-loop deployment. Current approaches are trained to predict trajectories in an open-loop environment, which struggle with quick reactions to other agents in closed-loop environments and risk generating kinematically infeasible plans due to the gap between open-loop training and closed-loop driving. In this paper, we introduce Hydra-NeXt, a novel multi-branch planning framework that unifies trajectory prediction, control prediction, and a trajectory refinement network in one model. Unlike current open-loop trajectory prediction models that only handle general-case planning, Hydra-NeXt further utilizes a control decoder to focus on short-term actions, which enables faster responses to dynamic situations and reactive agents. Moreover, we propose the Trajectory Refinement module to augment and refine the planning decisions by effectively adhering to kinematic constraints in closed-loop environments. This unified approach bridges the gap between open-loop training and closed-loop driving, demonstrating superior performance of 65.89 Driving Score (DS) and 48.20% Success Rate (SR) on the Bench2Drive dataset without relying on external experts for data collection. Hydra-NeXt surpasses the previous state-of-the-art by 22.98 DS and 17.49 SR, marking a significant advancement in autonomous driving. Code will be available at https://github.com/woxihuanjiangguo/Hydra-NeXt.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large-Scale Mixed-Traffic and Intersection Control using Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2504.04691</link>
<guid>https://arxiv.org/abs/2504.04691</guid>
<content:encoded><![CDATA[
arXiv:2504.04691v2 Announce Type: replace 
Abstract: Traffic congestion remains a significant challenge in modern urban networks. Autonomous driving technologies have emerged as a potential solution. Among traffic control methods, reinforcement learning has shown superior performance over traffic signals in various scenarios. However, prior research has largely focused on small-scale networks or isolated intersections, leaving large-scale mixed traffic control largely unexplored. This study presents the first attempt to use decentralized multi-agent reinforcement learning for large-scale mixed traffic control in which some intersections are managed by traffic signals and others by robot vehicles. Evaluating a real-world network in Colorado Springs, CO, USA with 14 intersections, we measure traffic efficiency via average waiting time of vehicles at intersections and the number of vehicles reaching their destinations within a time window (i.e., throughput). At 80% RV penetration rate, our method reduces waiting time from 6.17s to 5.09s and increases throughput from 454 vehicles per 500 seconds to 493 vehicles per 500 seconds, outperforming the baseline of fully signalized intersections. These findings suggest that integrating reinforcement learning-based control large-scale traffic can improve overall efficiency and may inform future urban planning strategies.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real-Time LaCAM for Real-Time MAPF</title>
<link>https://arxiv.org/abs/2504.06091</link>
<guid>https://arxiv.org/abs/2504.06091</guid>
<content:encoded><![CDATA[
arXiv:2504.06091v2 Announce Type: replace 
Abstract: The vast majority of Multi-Agent Path Finding (MAPF) methods with completeness guarantees require planning full-horizon paths. However, planning full-horizon paths can take too long and be impractical in real-world applications. Instead, real-time planning and execution, which only allows the planner a finite amount of time before executing and replanning, is more practical for real-world multi-agent systems. Several methods utilize real-time planning schemes but none are provably complete, which leads to livelock or deadlock. Our main contribution is Real-Time LaCAM, the first Real-Time MAPF method with provable completeness guarantees. We do this by leveraging LaCAM (Okumura 2023) in an incremental fashion. Our results show how we can iteratively plan for congested environments with a cutoff time of milliseconds while still maintaining the same success rate as full-horizon LaCAM. We also show how it can be used with a single-step learned MAPF policy.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adopting Large Language Models to Automated System Integration</title>
<link>https://arxiv.org/abs/2504.08490</link>
<guid>https://arxiv.org/abs/2504.08490</guid>
<content:encoded><![CDATA[
arXiv:2504.08490v2 Announce Type: replace 
Abstract: Modern enterprise computing systems integrate numerous subsystems to resolve a common task by yielding emergent behavior. A widespread approach is using services implemented with Web technologies like REST or OpenAPI, which offer an interaction mechanism and service documentation standard, respectively. Each service represents a specific business functionality, allowing encapsulation and easier maintenance. Despite the reduced maintenance costs on an individual service level, increased integration complexity arises. Consequently, automated service composition approaches have arisen to mitigate this issue. Nevertheless, these approaches have not achieved high acceptance in practice due to their reliance on complex formal modeling. Within this Ph.D. thesis, we analyze the application of Large Language Models (LLMs) to automatically integrate the services based on a natural language input. The result is a reusable service composition, e.g., as program code. While not always generating entirely correct results, the result can still be helpful by providing integration engineers with a close approximation of a suitable solution, which requires little effort to become operational. Our research involves (i) introducing a software architecture for automated service composition using LLMs, (ii) analyzing Retrieval Augmented Generation (RAG) for service discovery, (iii) proposing a novel natural language query-based benchmark for service discovery, and (iv) extending the benchmark to complete service composition scenarios. We have presented our software architecture as Compositio Prompto, the analysis of RAG for service discovery, and submitted a proposal for the service discovery benchmark. Open topics are primarily the extension of the service discovery benchmark to service composition scenarios and the improvements of the service composition generation, e.g., using fine-tuning or LLM agents.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Manipulating Multimodal Agents via Cross-Modal Prompt Injection</title>
<link>https://arxiv.org/abs/2504.14348</link>
<guid>https://arxiv.org/abs/2504.14348</guid>
<content:encoded><![CDATA[
arXiv:2504.14348v4 Announce Type: replace 
Abstract: The emergence of multimodal large language models has redefined the agent paradigm by integrating language and vision modalities with external data sources, enabling agents to better interpret human instructions and execute increasingly complex tasks. However, in this paper, we identify a critical yet previously overlooked security vulnerability in multimodal agents: cross-modal prompt injection attacks. To exploit this vulnerability, we propose CrossInject, a novel attack framework in which attackers embed adversarial perturbations across multiple modalities to align with target malicious content, allowing external instructions to hijack the agent's decision-making process and execute unauthorized tasks. Our approach incorporates two key coordinated components. First, we introduce Visual Latent Alignment, where we optimize adversarial features to the malicious instructions in the visual embedding space based on a text-to-image generative model, ensuring that adversarial images subtly encode cues for malicious task execution. Subsequently, we present Textual Guidance Enhancement, where a large language model is leveraged to construct the black-box defensive system prompt through adversarial meta prompting and generate an malicious textual command that steers the agent's output toward better compliance with attackers' requests. Extensive experiments demonstrate that our method outperforms state-of-the-art attacks, achieving at least a +30.1% increase in attack success rates across diverse tasks. Furthermore, we validate our attack's effectiveness in real-world multimodal autonomous agents, highlighting its potential implications for safety-critical applications.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ADL: A Declarative Language for Agent-Based Chatbots</title>
<link>https://arxiv.org/abs/2504.14787</link>
<guid>https://arxiv.org/abs/2504.14787</guid>
<content:encoded><![CDATA[
arXiv:2504.14787v2 Announce Type: replace 
Abstract: There are numerous frameworks capable of creating and orchestrating agents to address complex tasks. However, most of them highly coupled Python programming with agent declaration, making it hard for maintenance and runtime optimization. In this work, we introduce ADL, an agent declarative language for customer service chatbots. ADL abstracts away implementation details, offering a declarative way to define agents and their interactions, which could ease maintenance and debugging. It also incorporates natural language programming at its core to simplify the specification and communication of chatbot designs. ADL includes four basic types of agents and supports integration with custom functions, tool use, and third-party agents. MICA, a multi-agent system designed to interpret and execute ADL programs, has been developed and is now available as an open-source project at https://github.com/Mica-labs/MICA. Its documentation can be found at https://mica-labs.github.io/.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MultiMind: Enhancing Werewolf Agents with Multimodal Reasoning and Theory of Mind</title>
<link>https://arxiv.org/abs/2504.18039</link>
<guid>https://arxiv.org/abs/2504.18039</guid>
<content:encoded><![CDATA[
arXiv:2504.18039v3 Announce Type: replace 
Abstract: Large Language Model (LLM) agents have demonstrated impressive capabilities in social deduction games (SDGs) like Werewolf, where strategic reasoning and social deception are essential. However, current approaches remain limited to textual information, ignoring crucial multimodal cues such as facial expressions and tone of voice that humans naturally use to communicate. Moreover, existing SDG agents primarily focus on inferring other players' identities without modeling how others perceive themselves or fellow players. To address these limitations, we use One Night Ultimate Werewolf (ONUW) as a testbed and present MultiMind, the first framework integrating multimodal information into SDG agents. MultiMind processes facial expressions and vocal tones alongside verbal content, while employing a Theory of Mind (ToM) model to represent each player's suspicion levels toward others. By combining this ToM model with Monte Carlo Tree Search (MCTS), our agent identifies communication strategies that minimize suspicion directed at itself. Through comprehensive evaluation in both agent-versus-agent simulations and studies with human players, we demonstrate MultiMind's superior performance in gameplay. Our work presents a significant advancement toward LLM agents capable of human-like social reasoning across multimodal domains.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture</title>
<link>https://arxiv.org/abs/2505.00316</link>
<guid>https://arxiv.org/abs/2505.00316</guid>
<content:encoded><![CDATA[
arXiv:2505.00316v3 Announce Type: replace 
Abstract: The Cellular-Potts model is a powerful and ubiquitous framework for developing computational models for simulating complex multicellular biological systems. Cellular-Potts models (CPMs) are often computationally expensive due to the explicit modeling of interactions among large numbers of individual model agents and diffusive fields described by partial differential equations (PDEs). In this work, we develop a convolutional neural network (CNN) surrogate model using a U-Net architecture that accounts for periodic boundary conditions. We use this model to accelerate the evaluation of a mechanistic CPM previously used to investigate in vitro vasculogenesis. The surrogate model was trained to predict 100 computational steps ahead (Monte-Carlo steps, MCS), accelerating simulation evaluations by a factor of 590 times compared to CPM code execution. Over multiple recursive evaluations, our model effectively captures the emergent behaviors demonstrated by the original Cellular-Potts model of such as vessel sprouting, extension and anastomosis, and contraction of vascular lacunae. This approach demonstrates the potential for deep learning to serve as efficient surrogate models for CPM simulations, enabling faster evaluation of computationally expensive CPM of biological processes at greater spatial and temporal scales.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AutoLibra: Agent Metric Induction from Open-Ended Feedback</title>
<link>https://arxiv.org/abs/2505.02820</link>
<guid>https://arxiv.org/abs/2505.02820</guid>
<content:encoded><![CDATA[
arXiv:2505.02820v2 Announce Type: replace 
Abstract: Agents are predominantly evaluated and optimized via task success metrics, which are coarse, rely on manual design from experts, and fail to reward intermediate emergent behaviors. We propose AutoLibra, a framework for agent evaluation, that transforms open-ended human feedback e.g. "If you find that the button is disabled, don't click it again", or "This agent has too much autonomy to decide what to do on its own" into metrics for evaluating fine-grained behaviors in agent trajectories. AutoLibra accomplishes this by grounding feedback to an agent's behavior, clustering similar positive and negative behaviors, and creating concrete metrics with clear definitions and concrete examples, which can be used for prompting LLM-as-a-Judge as evaluators. We further propose two meta-metrics to evaluate the alignment of a set of (induced) metrics with open feedback: "coverage" and "redundancy". Through optimizing these meta-metrics, we experimentally demonstrate AutoLibra's ability to induce more concrete agent evaluation metrics than the ones proposed in previous agent evaluation benchmarks and discover new metrics to analyze agents. We also present two applications of AutoLibra in agent improvement: First, we show that AutoLibra-induced metrics serve as better prompt-engineering targets than the task success rate on a wide range of text game tasks, improving agent performance over baseline by a mean of 20%. Second, we show that AutoLibra can iteratively select high-quality fine-tuning data for web navigation agents. Our results suggest that AutoLibra is a powerful task-agnostic tool for evaluating and improving language agents.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dragonfly: a modular deep reinforcement learning library</title>
<link>https://arxiv.org/abs/2505.03778</link>
<guid>https://arxiv.org/abs/2505.03778</guid>
<content:encoded><![CDATA[
arXiv:2505.03778v2 Announce Type: replace 
Abstract: Dragonfly is a deep reinforcement learning library focused on modularity, in order to ease experimentation and developments. It relies on a json serialization that allows to swap building blocks and perform parameter sweep, while minimizing code maintenance. Some of its features are specifically designed for CPU-intensive environments, such as numerical simulations. Its performance on standard agents using common benchmarks compares favorably with the literature.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trends in Motion Prediction Toward Deployable and Generalizable Autonomy: A Revisit and Perspectives</title>
<link>https://arxiv.org/abs/2505.09074</link>
<guid>https://arxiv.org/abs/2505.09074</guid>
<content:encoded><![CDATA[
arXiv:2505.09074v2 Announce Type: replace 
Abstract: Motion prediction, the anticipation of future agent states or scene evolution, is rooted in human cognition, bridging perception and decision-making. It enables intelligent systems, such as robots and self-driving cars, to act safely in dynamic, human-involved environments, and informs broader time-series reasoning challenges. With advances in methods, representations, and datasets, the field has seen rapid progress, reflected in quickly evolving benchmark results. Yet, when state-of-the-art methods are deployed in the real world, they often struggle to generalize to open-world conditions and fall short of deployment standards. This reveals a gap between research benchmarks, which are often idealized or ill-posed, and real-world complexity.
  To address this gap, this survey revisits the generalization and deployability of motion prediction models, with an emphasis on the applications of robotics, autonomous driving, and human motion. We first offer a comprehensive taxonomy of motion prediction methods, covering representations, modeling strategies, application domains, and evaluation protocols. We then study two key challenges: (1) how to push motion prediction models to be deployable to realistic deployment standards, where motion prediction does not act in a vacuum, but functions as one module of closed-loop autonomy stacks - it takes input from the localization and perception, and informs downstream planning and control. 2) how to generalize motion prediction models from limited seen scenarios/datasets to the open-world settings. Throughout the paper, we highlight critical open challenges to guide future work, aiming to recalibrate the community's efforts, fostering progress that is not only measurable but also meaningful for real-world applications. The project webpage corresponding to this paper can be found here https://trends-in-motion-prediction- 2025.github.io/.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DrugPilot: LLM-based Parameterized Reasoning Agent for Drug Discovery</title>
<link>https://arxiv.org/abs/2505.13940</link>
<guid>https://arxiv.org/abs/2505.13940</guid>
<content:encoded><![CDATA[
arXiv:2505.13940v2 Announce Type: replace 
Abstract: Large language models (LLMs) integrated with autonomous agents hold significant potential for advancing scientific discovery through automated reasoning and task execution. However, applying LLM agents to drug discovery is still constrained by challenges such as large-scale multimodal data processing, limited task automation, and poor support for domain-specific tools. To overcome these limitations, we introduce DrugPilot, a LLM-based agent system with a parameterized reasoning architecture designed for end-to-end scientific workflows in drug discovery. DrugPilot enables multi-stage research processes by integrating structured tool use with a novel parameterized memory pool. The memory pool converts heterogeneous data from both public sources and user-defined inputs into standardized representations. This design supports efficient multi-turn dialogue, reduces information loss during data exchange, and enhances complex scientific decision-making. To support training and benchmarking, we construct a drug instruction dataset covering eight core drug discovery tasks. Under the Berkeley function-calling benchmark, DrugPilot significantly outperforms state-of-the-art agents such as ReAct and LoT, achieving task completion rates of 98.0%, 93.5%, and 64.0% for simple, multi-tool, and multi-turn scenarios, respectively. These results highlight DrugPilot's potential as a versatile agent framework for computational science domains requiring automated, interactive, and data-integrated reasoning.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Risks &amp; Benefits of LLMs &amp; GenAI for Platform Integrity, Healthcare Diagnostics, Financial Trust and Compliance, Cybersecurity, Privacy &amp; AI Safety: A Comprehensive Survey, Roadmap &amp; Implementation Blueprint</title>
<link>https://arxiv.org/abs/2506.12088</link>
<guid>https://arxiv.org/abs/2506.12088</guid>
<content:encoded><![CDATA[
arXiv:2506.12088v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) and generative AI (GenAI) systems, such as ChatGPT, Claude, Gemini, LLaMA, and Copilot (by OpenAI, Anthropic, Google, Meta, and Microsoft, respectively), are reshaping digital platforms and app ecosystems while introducing critical challenges in cybersecurity, privacy, and platform integrity. Our analysis reveals alarming trends: LLM-assisted malware is projected to rise from 2% (2021) to 50% (2025); AI-generated Google reviews grew nearly tenfold (1.2% in 2021 to 12.21% in 2023, expected to reach 30% by 2025); AI scam reports surged 456%; misinformation sites increased over 1500%; and deepfake attacks are projected to rise over 900% in 2025. In finance, LLM-driven threats like synthetic identity fraud and AI-generated scams are accelerating. Platforms such as JPMorgan Chase, Stripe, and Plaid deploy LLMs for fraud detection, regulation parsing, and KYC/AML automation, reducing fraud loss by up to 21% and accelerating onboarding by 40-60%. LLM-facilitated code development has driven mobile app submissions from 1.8 million (2020) to 3.0 million (2024), projected to reach 3.6 million (2025). To address AI threats, platforms like Google Play, Apple App Store, GitHub Copilot, TikTok, Facebook, and Amazon deploy LLM-based defenses, highlighting their dual nature as both threat sources and mitigation tools. In clinical diagnostics, LLMs raise concerns about accuracy, bias, and safety, necessitating strong governance. Drawing on 445 references, this paper surveys LLM/GenAI and proposes a strategic roadmap and operational blueprint integrating policy auditing (such as CCPA and GDPR compliance), fraud detection, and demonstrates an advanced LLM-DA stack with modular components, multi-LLM routing, agentic memory, and governance layers. We provide actionable insights, best practices, and real-world case studies for scalable trust and responsible innovation.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Levels of Autonomy for AI Agents</title>
<link>https://arxiv.org/abs/2506.12469</link>
<guid>https://arxiv.org/abs/2506.12469</guid>
<content:encoded><![CDATA[
arXiv:2506.12469v2 Announce Type: replace 
Abstract: Autonomy is a double-edged sword for AI agents, simultaneously unlocking transformative possibilities and serious risks. How can agent developers calibrate the appropriate levels of autonomy at which their agents should operate? We argue that an agent's level of autonomy can be treated as a deliberate design decision, separate from its capability and operational environment. In this work, we define five levels of escalating agent autonomy, characterized by the roles a user can take when interacting with an agent: operator, collaborator, consultant, approver, and observer. Within each level, we describe the ways by which a user can exert control over the agent and open questions for how to design the nature of user-agent interaction. We then highlight a potential application of our framework towards AI autonomy certificates to govern agent behavior in single- and multi-agent systems. We conclude by proposing early ideas for evaluating agents' autonomy. Our work aims to contribute meaningful, practical steps towards responsibly deployed and useful AI agents in the real world.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conformal Safety Shielding for Imperfect-Perception Agents</title>
<link>https://arxiv.org/abs/2506.17275</link>
<guid>https://arxiv.org/abs/2506.17275</guid>
<content:encoded><![CDATA[
arXiv:2506.17275v2 Announce Type: replace 
Abstract: We consider the problem of safe control in discrete autonomous agents that use learned components for imperfect perception (or more generally, state estimation) from high-dimensional observations. We propose a shield construction that provides run-time safety guarantees under perception errors by restricting the actions available to an agent, modeled as a Markov decision process, as a function of the state estimates. Our construction uses conformal prediction for the perception component, which guarantees that for each observation, the predicted set of estimates includes the actual state with a user-specified probability. The shield allows an action only if it is allowed for all the estimates in the predicted set, resulting in local safety. We also articulate and prove a global safety property of existing shield constructions for perfect-perception agents bounding the probability of reaching unsafe states if the agent always chooses actions prescribed by the shield. We illustrate our approach with a case-study of an experimental autonomous system that guides airplanes on taxiways using high-dimensional perception DNNs.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAGE: Strategy-Adaptive Generation Engine for Query Rewriting</title>
<link>https://arxiv.org/abs/2506.19783</link>
<guid>https://arxiv.org/abs/2506.19783</guid>
<content:encoded><![CDATA[
arXiv:2506.19783v2 Announce Type: replace 
Abstract: Query rewriting is pivotal for enhancing dense retrieval, yet current methods demand large-scale supervised data or suffer from inefficient reinforcement learning (RL) exploration. In this work, we first establish that guiding Large Language Models (LLMs) with a concise set of expert-crafted strategies, such as semantic expansion and entity disambiguation, substantially improves retrieval effectiveness on challenging benchmarks, including HotpotQA, FEVER, NFCorpus, and SciFact. Building on this insight, we introduce the Strategy-Adaptive Generation Engine (SAGE), which operationalizes these strategies in an RL framework. SAGE introduces two novel reward shaping mechanisms-Strategic Credit Shaping (SCS) and Contrastive Reward Shaping (CRS)-to deliver more informative learning signals. This strategy-guided approach not only achieves new state-of-the-art NDCG@10 results, but also uncovers a compelling emergent behavior: the agent learns to select optimal strategies, reduces unnecessary exploration, and generates concise rewrites, lowering inference cost without sacrificing performance. Our findings demonstrate that strategy-guided RL, enhanced with nuanced reward shaping, offers a scalable, efficient, and more interpretable paradigm for developing the next generation of robust information retrieval systems.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prover Agent: An Agent-based Framework for Formal Mathematical Proofs</title>
<link>https://arxiv.org/abs/2506.19923</link>
<guid>https://arxiv.org/abs/2506.19923</guid>
<content:encoded><![CDATA[
arXiv:2506.19923v2 Announce Type: replace 
Abstract: We present Prover Agent, a novel AI agent for automated theorem proving that integrates large language models (LLMs) with a formal proof assistant, Lean. Prover Agent coordinates an informal reasoning LLM, a formal prover model, and feedback from Lean while also generating auxiliary lemmas to assist in discovering the overall proof strategy. It achieves an 86.1% success rate on the MiniF2F benchmark, establishing a new state-of-the-art among methods using small language models (SLMs) with a much lower sample budget than previous approaches. We also present case studies illustrating how these generated lemmas contribute to solving challenging problems.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Epitome: Pioneering an Experimental Platform for AI-Social Science Integration</title>
<link>https://arxiv.org/abs/2507.01061</link>
<guid>https://arxiv.org/abs/2507.01061</guid>
<content:encoded><![CDATA[
arXiv:2507.01061v2 Announce Type: replace 
Abstract: The integration of Large Language Models (LLMs) into social science experiments represents a transformative approach to understanding human-AI interactions and their societal impacts. We introduce Epitome, the world's first open experimental platform dedicated to the deep integration of artificial intelligence and social science. Rooted in theoretical foundations from management, communication studies, sociology, psychology, and ethics, Epitome focuses on the interactive impacts of AI on individuals, organizations, and society during its real-world deployment. It constructs a theoretical support system through cross-disciplinary experiments. The platform offers a one-stop comprehensive experimental solution spanning "foundation models-complex application development-user feedback" through seven core modules, while embedding the classical "control-comparison-comparative causal logic" of social science experiments into multilevel human-computer interaction environments, including dialogues, group chats, and multi-agent virtual scenarios. With its canvas-style, user-friendly interface, Epitome enables researchers to easily design and run complex experimental scenarios, facilitating systematic investigations into the social impacts of AI and exploration of integrated solutions.To demonstrate its capabilities, we replicated three seminal social science experiments involving LLMs, showcasing Epitome's potential to streamline complex experimental designs and produce robust results, suitable for publishing in the top selective journals. Our findings highlight the platform's utility in enhancing the efficiency and quality of human-AI interactions, providing valuable insights into the societal implications of AI technologies. Epitome thus offers a powerful tool for advancing interdisciplinary research at the intersection of AI and social science, with potential applications in policy-making, ...
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On data-driven Wasserstein distributionally robust Nash equilibrium problems with heterogeneous uncertainty</title>
<link>https://arxiv.org/abs/2312.03573</link>
<guid>https://arxiv.org/abs/2312.03573</guid>
<content:encoded><![CDATA[
arXiv:2312.03573v3 Announce Type: replace-cross 
Abstract: We study stochastic Nash equilibrium problems subject to heterogeneous uncertainty on the expected valued cost functions of the individual agents, where we assume no prior knowledge of the underlying probability distributions of the uncertain variables. To account for this lack of knowledge, we consider an ambiguity set around the empirical probability distribution under the Wasserstein metric. We then show that, under mild assumptions, finite-sample guarantees on the probability that any resulting distributionally robust Nash equilibrium is also robust with respect to the true probability distributions with high confidence can be obtained. Furthermore, by recasting the game as a distributionally robust variational inequality, we establish asymptotic consistency of the set of data-driven distributionally robust equilibria to the solution set of the original game. Finally, we recast the distributionally robust Nash game as a finite-dimensional Nash equilibrium problem. We illustrate the proposed distributionally robust reformulation via numerical experiments of stochastic peer-to-peer electricity markets and Nash-Cournot games.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Learning over Arbitrary Topology: Linear Speed-Up with Polynomial Transient Time</title>
<link>https://arxiv.org/abs/2503.16123</link>
<guid>https://arxiv.org/abs/2503.16123</guid>
<content:encoded><![CDATA[
arXiv:2503.16123v2 Announce Type: replace-cross 
Abstract: We study a distributed learning problem in which $n$ agents, each with potentially heterogeneous local data, collaboratively minimize the sum of their local cost functions via peer-to-peer communication. We propose a novel algorithm, \emph{Spanning Tree Push-Pull} (STPP), which employs two spanning trees extracted from a general communication graph to distribute both model parameters and stochastic gradients. Unlike prior approaches that rely heavily on spectral gap properties, STPP leverages a more flexible topological characterization, enabling robust information flow and efficient updates. Theoretically, we prove that STPP achieves linear speedup and polynomial transient iteration complexity -- up to $\mathcal{O}(n^7)$ for smooth nonconvex objectives and $\tilde{\mathcal{O}}(n^3)$ for smooth strongly convex objectives -- under arbitrary network topologies. Moreover, compared with existing methods, STPP achieves faster convergence rates on sparse and non-regular topologies (e.g., directed rings) and reduces communication overhead on dense networks (e.g., static exponential graphs). Numerical experiments further demonstrate the strong performance of STPP across various graph architectures.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ADAgent: LLM Agent for Alzheimer's Disease Analysis with Collaborative Coordinator</title>
<link>https://arxiv.org/abs/2506.11150</link>
<guid>https://arxiv.org/abs/2506.11150</guid>
<content:encoded><![CDATA[
arXiv:2506.11150v3 Announce Type: replace-cross 
Abstract: Alzheimer's disease (AD) is a progressive and irreversible neurodegenerative disease. Early and precise diagnosis of AD is crucial for timely intervention and treatment planning to alleviate the progressive neurodegeneration. However, most existing methods rely on single-modality data, which contrasts with the multifaceted approach used by medical experts. While some deep learning approaches process multi-modal data, they are limited to specific tasks with a small set of input modalities and cannot handle arbitrary combinations. This highlights the need for a system that can address diverse AD-related tasks, process multi-modal or missing input, and integrate multiple advanced methods for improved performance. In this paper, we propose ADAgent, the first specialized AI agent for AD analysis, built on a large language model (LLM) to address user queries and support decision-making. ADAgent integrates a reasoning engine, specialized medical tools, and a collaborative outcome coordinator to facilitate multi-modal diagnosis and prognosis tasks in AD. Extensive experiments demonstrate that ADAgent outperforms SOTA methods, achieving significant improvements in accuracy, including a 2.7% increase in multi-modal diagnosis, a 0.7% improvement in multi-modal prognosis, and enhancements in MRI and PET diagnosis tasks.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Market Making Strategies with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.18680</link>
<guid>https://arxiv.org/abs/2507.18680</guid>
<content:encoded><![CDATA[
arXiv:2507.18680v1 Announce Type: new 
Abstract: This thesis presents the results of a comprehensive research project focused on applying Reinforcement Learning (RL) to the problem of market making in financial markets. Market makers (MMs) play a fundamental role in providing liquidity, yet face significant challenges arising from inventory risk, competition, and non-stationary market dynamics. This research explores how RL, particularly Deep Reinforcement Learning (DRL), can be employed to develop autonomous, adaptive, and profitable market making strategies.
  The study begins by formulating the MM task as a reinforcement learning problem, designing agents capable of operating in both single-agent and multi-agent settings within a simulated financial environment. It then addresses the complex issue of inventory management using two complementary approaches: reward engineering and Multi-Objective Reinforcement Learning (MORL). While the former uses dynamic reward shaping to guide behavior, the latter leverages Pareto front optimization to explicitly balance competing objectives.
  To address the problem of non-stationarity, the research introduces POW-dTS, a novel policy weighting algorithm based on Discounted Thompson Sampling. This method allows agents to dynamically select and combine pretrained policies, enabling continual adaptation to shifting market conditions.
  The experimental results demonstrate that the proposed RL-based approaches significantly outperform traditional and baseline algorithmic strategies across various performance metrics. Overall, this research thesis contributes new methodologies and insights for the design of robust, efficient, and adaptive market making agents, reinforcing the potential of RL to transform algorithmic trading in complex financial systems.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Explainable Equity-Aware P2P Energy Trading Framework for Socio-Economically Diverse Microgrid</title>
<link>https://arxiv.org/abs/2507.18738</link>
<guid>https://arxiv.org/abs/2507.18738</guid>
<content:encoded><![CDATA[
arXiv:2507.18738v1 Announce Type: new 
Abstract: Fair and dynamic energy allocation in community microgrids remains a critical challenge, particularly when serving socio-economically diverse participants. Static optimization and cost-sharing methods often fail to adapt to evolving inequities, leading to participant dissatisfaction and unsustainable cooperation. This paper proposes a novel framework that integrates multi-objective mixed-integer linear programming (MILP), cooperative game theory, and a dynamic equity-adjustment mechanism driven by reinforcement learning (RL). At its core, the framework utilizes a bi-level optimization model grounded in Equity-regarding Welfare Maximization (EqWM) principles, which incorporate Rawlsian fairness to prioritize the welfare of the least advantaged participants. We introduce a Proximal Policy Optimization (PPO) agent that dynamically adjusts socio-economic weights in the optimization objective based on observed inequities in cost and renewable energy access. This RL-powered feedback loop enables the system to learn and adapt, continuously striving for a more equitable state. To ensure transparency, Explainable AI (XAI) is used to interpret the benefit allocations derived from a weighted Shapley value. Validated across six realistic scenarios, the framework demonstrates peak demand reductions of up to 72.6%, and significant cooperative gains. The adaptive RL mechanism further reduces the Gini coefficient over time, showcasing a pathway to truly sustainable and fair energy communities.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Specification Self-Correction: Mitigating In-Context Reward Hacking Through Test-Time Refinement</title>
<link>https://arxiv.org/abs/2507.18742</link>
<guid>https://arxiv.org/abs/2507.18742</guid>
<content:encoded><![CDATA[
arXiv:2507.18742v1 Announce Type: new 
Abstract: Language models (LMs) are susceptible to in-context reward hacking, where they exploit flaws in tainted or faulty written specifications or rubrics to achieve high scores without fulfilling the user's true intent. We introduce Specification Self-Correction (SSC), a novel, test-time framework that enables an LM to identify and correct flaws within its own guiding specification. SSC employs a multi-step inference process where the model first generates a response based on a potentially tainted specification, critiques its output, and then revises the specification itself to remove the exploitable loophole. A final, more robust response is then generated using this self-corrected specification. Across experiments spanning creative writing and agentic coding tasks with several LMs, we demonstrate that while models initially game tainted specifications in 50-70\% of cases, the SSC process reduces this vulnerability by over 90\%. This dynamic repair occurs at inference time, requires no weight modification, and leads to more robustly aligned model behavior. Code at https://github.com/vicgalle/specification-self-correction .
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Program Repair from Test Failures at Scale: A Neuro-symbolic approach with static analysis and test execution feedback</title>
<link>https://arxiv.org/abs/2507.18755</link>
<guid>https://arxiv.org/abs/2507.18755</guid>
<content:encoded><![CDATA[
arXiv:2507.18755v1 Announce Type: new 
Abstract: Aim: With the advent of LLMs, sophisticated agentic program repair has become viable at large organizations with large codebases. In this work, we develop an Engineering Agent that fixes the source code based on test failures at scale across diverse software offerings internally.
  Method: Using Llama as the base, we employ the ReAct harness to develop an agent. We start with a test failure that was triaged by a rule-based test failure bot. We then set up an agentic harness and allow the agent to reason and run a set of 15 actions from reading a file to generating a patch. We provide feedback to the agent through static analysis and test failures so it can refine its solution. We leverage an LLM-as-a-Judge to ensure that the patch conforms to the standards followed by a human review to land fixes.
  Benchmark Findings: We curated offline benchmarks for our patch generator, the Engineering Agent loop, and the LLM-as-a-Judge. In offline evaluations we found that a specialized 70B model is highly competitive with the much larger but vanilla Llama-405B. In an ablation study, we found that the ReAct harness (neural model) benefited from the symbolic information from static analysis tools and test execution traces. A model that strikes a balance between the solve rate and error rate vs the cost and latency has a benchmark solve rate of 42.3% using an average 11.8 feedback iterations.
  Production Findings: In a three month period, 80% of the generated fixes were reviewed, of which 31.5% were landed (25.5% of the total number of generated fixes).
  Feedback from Engineers: We used open coding to extract qualitative themes from engineers' feedback. We saw positive feedback in the form of quick approvals, gratitude, and surprise. We also found mixed feedback when the Engineering Agent's solution was partially correct and it served as a good starting point.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MemoCoder: Automated Function Synthesis using LLM-Supported Agents</title>
<link>https://arxiv.org/abs/2507.18812</link>
<guid>https://arxiv.org/abs/2507.18812</guid>
<content:encoded><![CDATA[
arXiv:2507.18812v1 Announce Type: new 
Abstract: With the widespread adoption of Large Language Models (LLMs) such as GitHub Copilot and ChatGPT, developers increasingly rely on AI-assisted tools to support code generation. While LLMs can generate syntactically correct solutions for well-structured programming tasks, they often struggle with challenges that require iterative debugging, error handling, or adaptation to diverse problem structures. Existing approaches such as fine-tuning or self-repair strategies either require costly retraining or lack mechanisms to accumulate and reuse knowledge from previous attempts.
  To address these limitations, we propose MemoCoder, a multi-agent framework that enables collaborative problem solving and persistent learning from past fixes. At the core of MemoCoder is a Fixing Knowledge Set, which stores successful repairs and supports retrieval for future tasks. A central Mentor Agent supervises the repair process by identifying recurring error patterns and refining high-level fixing strategies, providing a novel supervisory role that guides the self-repair loop. We evaluate MemoCoder across three public benchmarks -- MBPP, HumanEval, and LiveCodeBench -- spanning a range of problem complexities. Experimental results show that MemoCoder consistently outperforms both zero-shot prompting and a Self-Repair strategy, with improvements ranging from 3.1% to 12.1% in Pass@10 and from 1.4% to 14.5% in Pass@50, demonstrating its effectiveness in iterative refinement and knowledge-guided code generation.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ThermoRL:Structure-Aware Reinforcement Learning for Protein Mutation Design to Enhance Thermostability</title>
<link>https://arxiv.org/abs/2507.18816</link>
<guid>https://arxiv.org/abs/2507.18816</guid>
<content:encoded><![CDATA[
arXiv:2507.18816v1 Announce Type: new 
Abstract: Designing mutations to optimize protein thermostability remains challenging due to the complex relationship between sequence variations, structural dynamics, and thermostability, often assessed by \delta\delta G
  (the change in free energy of unfolding). Existing methods rely on experimental random mutagenesis or prediction models tested with pre-defined datasets, using sequence-based heuristics and treating enzyme design as a one-step process without iterative refinement, which limits design space exploration and restricts discoveries beyond known variations. We present ThermoRL, a framework based on reinforcement learning (RL) that leverages graph neural networks (GNN) to design mutations with enhanced thermostability. It combines a pre-trained GNN-based encoder with a hierarchical Q-learning network and employs a surrogate model for reward feedback, guiding the RL agent on where (the position) and which (mutant amino acid) to apply for enhanced thermostability. Experimental results show that ThermoRL achieves higher or comparable rewards than baselines while maintaining computational efficiency. It filters out destabilizing mutations and identifies stabilizing mutations aligned with experimental data. Moreover, ThermoRL accurately detects key mutation sites in unseen proteins, highlighting its strong generalizability. This RL-guided approach powered by GNN embeddings offers a robust alternative to traditional protein mutation design.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Weak-to-Strong Generalization with Failure Trajectories: A Tree-based Approach to Elicit Optimal Policy in Strong Models</title>
<link>https://arxiv.org/abs/2507.18858</link>
<guid>https://arxiv.org/abs/2507.18858</guid>
<content:encoded><![CDATA[
arXiv:2507.18858v1 Announce Type: new 
Abstract: Weak-to-Strong generalization (W2SG) is a new trend to elicit the full capabilities of a strong model with supervision from a weak model. While existing W2SG studies focus on simple tasks like binary classification, we extend this paradigm to complex interactive decision-making environments. Specifically, we fine-tune a strong model with trajectories of intermediate actions generated by a weak model. Motivated by the human learning process, we propose to generalize not only success knowledge but also failure experience so that the strong model can learn from failed trajectories accumulated by weak models. To effectively and efficiently elicit the potential of strong agents, we further construct ``trajectory trees," a hierarchical representation that organizes weak model-generated action trajectories, coupled with Monte Carlo Tree Search (MCTS) to optimize the strong model. Through theoretical analysis, we provide formal guarantees for the effectiveness of our method in improving W2SG performance. Our empirical evaluations demonstrate substantial improvements in reasoning and decision-making capabilities across diverse task domains, validating the scalability and robustness of our proposed framework. Our code is available at: https://github.com/yeruimeng/TraTree
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Individual Intrinsic Reward in Multi-Agent Reinforcement Learning via Incorporating Generalized Human Expertise</title>
<link>https://arxiv.org/abs/2507.18867</link>
<guid>https://arxiv.org/abs/2507.18867</guid>
<content:encoded><![CDATA[
arXiv:2507.18867v1 Announce Type: new 
Abstract: Efficient exploration in multi-agent reinforcement learning (MARL) is a challenging problem when receiving only a team reward, especially in environments with sparse rewards. A powerful method to mitigate this issue involves crafting dense individual rewards to guide the agents toward efficient exploration. However, individual rewards generally rely on manually engineered shaping-reward functions that lack high-order intelligence, thus it behaves ineffectively than humans regarding learning and generalization in complex problems. To tackle these issues, we combine the above two paradigms and propose a novel framework, LIGHT (Learning Individual Intrinsic reward via Incorporating Generalized Human experTise), which can integrate human knowledge into MARL algorithms in an end-to-end manner. LIGHT guides each agent to avoid unnecessary exploration by considering both individual action distribution and human expertise preference distribution. Then, LIGHT designs individual intrinsic rewards for each agent based on actionable representational transformation relevant to Q-learning so that the agents align their action preferences with the human expertise while maximizing the joint action value. Experimental results demonstrate the superiority of our method over representative baselines regarding performance and better knowledge reusability across different sparse-reward tasks on challenging scenarios.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MindFlow+: A Self-Evolving Agent for E-Commerce Customer Service</title>
<link>https://arxiv.org/abs/2507.18884</link>
<guid>https://arxiv.org/abs/2507.18884</guid>
<content:encoded><![CDATA[
arXiv:2507.18884v1 Announce Type: new 
Abstract: High-quality dialogue is crucial for e-commerce customer service, yet traditional intent-based systems struggle with dynamic, multi-turn interactions. We present MindFlow+, a self-evolving dialogue agent that learns domain-specific behavior by combining large language models (LLMs) with imitation learning and offline reinforcement learning (RL). MindFlow+ introduces two data-centric mechanisms to guide learning: tool-augmented demonstration construction, which exposes the model to knowledge-enhanced and agentic (ReAct-style) interactions for effective tool use; and reward-conditioned data modeling, which aligns responses with task-specific goals using reward signals. To evaluate the model's role in response generation, we introduce the AI Contribution Ratio, a novel metric quantifying AI involvement in dialogue. Experiments on real-world e-commerce conversations show that MindFlow+ outperforms strong baselines in contextual relevance, flexibility, and task accuracy. These results demonstrate the potential of combining LLMs tool reasoning, and reward-guided learning to build domain-specialized, context-aware dialogue systems.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Procedural city modeling</title>
<link>https://arxiv.org/abs/2507.18899</link>
<guid>https://arxiv.org/abs/2507.18899</guid>
<content:encoded><![CDATA[
arXiv:2507.18899v1 Announce Type: new 
Abstract: We propose a method to procedurally generate a familiar yet complex human artifact: the city. We are not trying to reproduce existing cities, but to generate artificial cities that are convincing and plausible by capturing developmental behavior. In addition, our results are meant to build upon themselves, such that they ought to look compelling at any point along the transition from village to metropolis. Our approach largely focuses upon land usage and building distribution for creating realistic city environments, whereas previous attempts at city modeling have mainly focused on populating road networks. Finally, we want our model to be self automated to the point that the only necessary input is a terrain description, but other high-level and low-level parameters can be specified to support artistic contributions. With the aid of agent based simulation we are generating a system of agents and behaviors that interact with one another through their effects upon a simulated environment. Our philosophy is that as each agent follows a simple behavioral rule set, a more complex behavior will tend to emerge out of the interactions between the agents and their differing rule sets. By confining our model to a set of simple rules for each class of agents, we hope to make our model extendible not only in regard to the types of structures that are produced, but also in describing the social and cultural influences prevalent in all cities
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>REPRO-Bench: Can Agentic AI Systems Assess the Reproducibility of Social Science Research?</title>
<link>https://arxiv.org/abs/2507.18901</link>
<guid>https://arxiv.org/abs/2507.18901</guid>
<content:encoded><![CDATA[
arXiv:2507.18901v1 Announce Type: new 
Abstract: Assessing the reproducibility of social science papers is essential for promoting rigor in research processes, but manual assessment is costly. With recent advances in agentic AI systems (i.e., AI agents), we seek to evaluate their capability to automate this process. However, existing benchmarks for reproducing research papers (1) focus solely on reproducing results using provided code and data without assessing their consistency with the paper, (2) oversimplify real-world scenarios, and (3) lack necessary diversity in data formats and programming languages. To address these issues, we introduce REPRO-Bench, a collection of 112 task instances, each representing a social science paper with a publicly available reproduction report. The agents are tasked with assessing the reproducibility of the paper based on the original paper PDF and the corresponding reproduction package. REPRO-Bench features end-to-end evaluation tasks on the reproducibility of social science papers with complexity comparable to real-world assessments. We evaluate three representative AI agents on REPRO-Bench, with the best-performing agent achieving an accuracy of only 21.4%. Building on our empirical analysis, we develop REPRO-Agent, which improves the highest accuracy achieved by existing agents by 71%. We conclude that more advanced AI agents should be developed to automate real-world reproducibility assessment. REPRO-Bench is publicly available at https://github.com/uiuc-kang-lab/REPRO-Bench.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematic Review of Key Retrieval-Augmented Generation (RAG) Systems: Progress, Gaps, and Future Directions</title>
<link>https://arxiv.org/abs/2507.18910</link>
<guid>https://arxiv.org/abs/2507.18910</guid>
<content:encoded><![CDATA[
arXiv:2507.18910v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) represents a major advancement in natural language processing (NLP), combining large language models (LLMs) with information retrieval systems to enhance factual grounding, accuracy, and contextual relevance. This paper presents a comprehensive systematic review of RAG, tracing its evolution from early developments in open domain question answering to recent state-of-the-art implementations across diverse applications. The review begins by outlining the motivations behind RAG, particularly its ability to mitigate hallucinations and outdated knowledge in parametric models. Core technical components-retrieval mechanisms, sequence-to-sequence generation models, and fusion strategies are examined in detail. A year-by-year analysis highlights key milestones and research trends, providing insight into RAG's rapid growth. The paper further explores the deployment of RAG in enterprise systems, addressing practical challenges related to retrieval of proprietary data, security, and scalability. A comparative evaluation of RAG implementations is conducted, benchmarking performance on retrieval accuracy, generation fluency, latency, and computational efficiency. Persistent challenges such as retrieval quality, privacy concerns, and integration overhead are critically assessed. Finally, the review highlights emerging solutions, including hybrid retrieval approaches, privacy-preserving techniques, optimized fusion strategies, and agentic RAG architectures. These innovations point toward a future of more reliable, efficient, and context-aware knowledge-intensive NLP systems.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Similarity Measure for Comparing Conversational Dynamics</title>
<link>https://arxiv.org/abs/2507.18956</link>
<guid>https://arxiv.org/abs/2507.18956</guid>
<content:encoded><![CDATA[
arXiv:2507.18956v1 Announce Type: new 
Abstract: The quality of a conversation goes beyond the individual quality of each reply, and instead emerges from how these combine into interactional patterns that give the conversation its distinctive overall "shape". However, there is no robust automated method for comparing conversations in terms of their overall interactional dynamics. Such methods could enhance the analysis of conversational data and help evaluate conversational agents more holistically.
  In this work, we introduce a similarity measure for comparing conversations with respect to their dynamics. We design a validation framework for testing the robustness of the metric in capturing differences in conversation dynamics and for assessing its sensitivity to the topic of the conversations. Finally, to illustrate the measure's utility, we use it to analyze conversational dynamics in a large online community, bringing new insights into the role of situational power in conversations.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SLICEMATE: Accurate and Scalable Static Program Slicing via LLM-Powered Agents</title>
<link>https://arxiv.org/abs/2507.18957</link>
<guid>https://arxiv.org/abs/2507.18957</guid>
<content:encoded><![CDATA[
arXiv:2507.18957v1 Announce Type: new 
Abstract: Static program slicing, which extracts the executable portions of a program that affect the values at a specific location, supports many software analysis tasks such as debugging and security auditing. However, traditional slicing tools rely on computationally expensive reachability analysis over dependency graphs, which struggle to scale to large programs and often fail to handle code with incomplete syntax. Recently emerged learning-based methods, while more robust to such cases, still fall short of achieving comparable performance to traditional methods on well-formed code.
  In this work, we propose SliceMate, a novel static program slicing solution powered by Large Language Model (LLM) agents. It bypasses the need for explicit dependency graph construction and achieving superior slicing accuracy. Concretely, SliceMate integrates three specialized agents: (1) a synthesis agent that produces candidate slices by incrementally expanding the scan scope across functions and files guided by LLM-inferred dependencies; (2) a verification agent that performs conciseness and completeness checks of the candidate slices, detecting missing or irrelevant statements; and (3) a refinement agent that repairs the slices with minimal edits in accordance with the verification results. These agents are orchestrated by a control module that ensures timely convergence and outputs high-quality slices without manual intervention. For rigorous evaluation, we construct a new and high-quality benchmark, SliceBench, comprising 2,200 manually annotated Java and Python programs, with program lengths ranging from 5 to 8,577 lines, significantly larger than those in existing slicing benchmarks. Experimental results show that SliceMate greatly outperforms both traditional and learning-based slicing tools.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning via Conservative Agent for Environments with Random Delays</title>
<link>https://arxiv.org/abs/2507.18992</link>
<guid>https://arxiv.org/abs/2507.18992</guid>
<content:encoded><![CDATA[
arXiv:2507.18992v1 Announce Type: new 
Abstract: Real-world reinforcement learning applications are often hindered by delayed feedback from environments, which violates the Markov assumption and introduces significant challenges. Although numerous delay-compensating methods have been proposed for environments with constant delays, environments with random delays remain largely unexplored due to their inherent variability and unpredictability. In this study, we propose a simple yet robust agent for decision-making under random delays, termed the conservative agent, which reformulates the random-delay environment into its constant-delay equivalent. This transformation enables any state-of-the-art constant-delay method to be directly extended to the random-delay environments without modifying the algorithmic structure or sacrificing performance. We evaluate the conservative agent-based algorithm on continuous control tasks, and empirical results demonstrate that it significantly outperforms existing baseline algorithms in terms of asymptotic performance and sample efficiency.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent0: Leveraging LLM Agents to Discover Multi-value Features from Text for Enhanced Recommendations</title>
<link>https://arxiv.org/abs/2507.18993</link>
<guid>https://arxiv.org/abs/2507.18993</guid>
<content:encoded><![CDATA[
arXiv:2507.18993v1 Announce Type: new 
Abstract: Large language models (LLMs) and their associated agent-based frameworks have significantly advanced automated information extraction, a critical component of modern recommender systems. While these multitask frameworks are widely used in code generation, their application in data-centric research is still largely untapped. This paper presents Agent0, an LLM-driven, agent-based system designed to automate information extraction and feature construction from raw, unstructured text. Categorical features are crucial for large-scale recommender systems but are often expensive to acquire. Agent0 coordinates a group of interacting LLM agents to automatically identify the most valuable text aspects for subsequent tasks (such as models or AutoML pipelines). Beyond its feature engineering capabilities, Agent0 also offers an automated prompt-engineering tuning method that utilizes dynamic feedback loops from an oracle. Our findings demonstrate that this closed-loop methodology is both practical and effective for automated feature discovery, which is recognized as one of the most challenging phases in current recommender system development.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Approach for Agile Supply Chain Decision-Making Based on Network Attributes</title>
<link>https://arxiv.org/abs/2507.19038</link>
<guid>https://arxiv.org/abs/2507.19038</guid>
<content:encoded><![CDATA[
arXiv:2507.19038v1 Announce Type: new 
Abstract: In recent years, the frequent occurrence of disruptions has had a negative impact on global supply chains. To stay competitive, enterprises strive to remain agile through the implementation of efficient and effective decision-making strategies in reaction to disruptions. A significant effort has been made to develop these agile disruption mitigation approaches, leveraging both centralized and distributed decision-making strategies. Though trade-offs of centralized and distributed approaches have been analyzed in existing studies, no related work has been found on understanding supply chain performance based on the network attributes of the disrupted supply chain entities. In this paper, we characterize supply chains from a capability and network topological perspective and investigate the use of a distributed decision-making approach based on classical multi-agent frameworks. The performance of the distributed framework is evaluated through a comprehensive case study that investigates the performance of the supply chain as a function of the network structure and agent attributes within the network in the presence of a disruption. Comparison to a centralized decision-making approach highlights trade-offs between performance, computation time, and network communication based on the decision-making strategy and network architecture. Practitioners can use the outcomes of our studies to design response strategies based on agent capabilities, network attributes, and desired supply chain performance.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic distributed decision-making for resilient resource reallocation in disrupted manufacturing systems</title>
<link>https://arxiv.org/abs/2507.19043</link>
<guid>https://arxiv.org/abs/2507.19043</guid>
<content:encoded><![CDATA[
arXiv:2507.19043v1 Announce Type: new 
Abstract: The COVID-19 pandemic brings many unexpected disruptions, such as frequently shifting markets and limited human workforce, to manufacturers. To stay competitive, flexible and real-time manufacturing decision-making strategies are needed to deal with such highly dynamic manufacturing environments. One essential problem is dynamic resource allocation to complete production tasks, especially when a resource disruption (e.g., machine breakdown) occurs. Though multi-agent methods have been proposed to solve the problem in a flexible and agile manner, the agent internal decision-making process and resource uncertainties have rarely been studied. This work introduces a model-based resource agent (RA) architecture that enables effective agent coordination and dynamic agent decision-making. Based on the RA architecture, a rescheduling strategy that incorporates risk assessment via a clustering agent coordination strategy is also proposed. A simulation-based case study is implemented to demonstrate dynamic rescheduling using the proposed multi-agent framework. The results show that the proposed method reduces the computational efforts while losing some throughput optimality compared to the centralized method. Furthermore, the case study illustrates that incorporating risk assessment into rescheduling decision-making improves the throughput.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Heterogeneous Risk Management Using a Multi-Agent Framework for Supply Chain Disruption Response</title>
<link>https://arxiv.org/abs/2507.19049</link>
<guid>https://arxiv.org/abs/2507.19049</guid>
<content:encoded><![CDATA[
arXiv:2507.19049v1 Announce Type: new 
Abstract: In the highly complex and stochastic global, supply chain environments, local enterprise agents seek distributed and dynamic strategies for agile responses to disruptions. Existing literature explores both centralized and distributed approaches, while most work neglects temporal dynamics and the heterogeneity of the risk management of individual agents. To address this gap, this letter presents a heterogeneous risk management mechanism to incorporate uncertainties and risk attitudes into agent communication and decision-making strategy. Hence, this approach empowers enterprises to handle disruptions in stochastic environments in a distributed way, and in particular in the context of multi-agent control and management. Through a simulated case study, we showcase the feasibility and effectiveness of the proposed approach under stochastic settings and how the decision of disruption responses changes when agents hold various risk attitudes.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Model-Based Task Offloading and Resource Allocation for Digital Twin Edge Computing Networks</title>
<link>https://arxiv.org/abs/2507.19050</link>
<guid>https://arxiv.org/abs/2507.19050</guid>
<content:encoded><![CDATA[
arXiv:2507.19050v1 Announce Type: new 
Abstract: In this paper, we propose a general digital twin edge computing network comprising multiple vehicles and a server. Each vehicle generates multiple computing tasks within a time slot, leading to queuing challenges when offloading tasks to the server. The study investigates task offloading strategies, queue stability, and resource allocation. Lyapunov optimization is employed to transform long-term constraints into tractable short-term decisions. To solve the resulting problem, an in-context learning approach based on large language model (LLM) is adopted, replacing the conventional multi-agent reinforcement learning (MARL) framework. Experimental results demonstrate that the LLM-based method achieves comparable or even superior performance to MARL.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Debating Truth: Debate-driven Claim Verification with Multiple Large Language Model Agents</title>
<link>https://arxiv.org/abs/2507.19090</link>
<guid>https://arxiv.org/abs/2507.19090</guid>
<content:encoded><![CDATA[
arXiv:2507.19090v1 Announce Type: new 
Abstract: Claim verification is critical for enhancing digital literacy. However, the state-of-the-art single-LLM methods struggle with complex claim verification that involves multi-faceted evidences. Inspired by real-world fact-checking practices, we propose DebateCV, the first claim verification framework that adopts a debate-driven methodology using multiple LLM agents. In our framework, two Debaters take opposing stances on a claim and engage in multi-round argumentation, while a Moderator evaluates the arguments and renders a verdict with justifications. To further improve the performance of the Moderator, we introduce a novel post-training strategy that leverages synthetic debate data generated by the zero-shot DebateCV, effectively addressing the scarcity of real-world debate-driven claim verification data. Experimental results show that our method outperforms existing claim verification methods under varying levels of evidence quality. Our code and dataset are publicly available at https://anonymous.4open.science/r/DebateCV-6781.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>iPLAN: Redefining Indoor Wireless Network Planning Through Large Language Models</title>
<link>https://arxiv.org/abs/2507.19096</link>
<guid>https://arxiv.org/abs/2507.19096</guid>
<content:encoded><![CDATA[
arXiv:2507.19096v1 Announce Type: new 
Abstract: Efficient indoor wireless network (IWN) planning is crucial for providing high-quality 5G in-building services. However, traditional meta-heuristic and artificial intelligence-based planning methods face significant challenges due to the intricate interplay between indoor environments (IEs) and IWN demands. In this article, we present an indoor wireless network Planning with large LANguage models (iPLAN) framework, which integrates multi-modal IE representations into large language model (LLM)-powered optimizers to improve IWN planning. First, we instate the role of LLMs as optimizers, outlining embedding techniques for IEs, and introducing two core applications of iPLAN: (i) IWN planning based on pre-existing IEs and (ii) joint design of IWN and IE for new wireless-friendly buildings. For the former, we embed essential information into LLM optimizers by leveraging indoor descriptions, domain-specific knowledge, and performance-driven perception. For the latter, we conceptualize a multi-agent strategy, where intelligent agents collaboratively address key planning sub-tasks in a step-by-step manner while ensuring optimal trade-offs between the agents. The simulation results demonstrate that iPLAN achieves superior performance in IWN planning tasks and optimizes building wireless performance through the joint design of IEs and IWNs, exemplifying a paradigm shift in IWN planning.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OS-MAP: How Far Can Computer-Using Agents Go in Breadth and Depth?</title>
<link>https://arxiv.org/abs/2507.19132</link>
<guid>https://arxiv.org/abs/2507.19132</guid>
<content:encoded><![CDATA[
arXiv:2507.19132v1 Announce Type: new 
Abstract: Computer-using agents have shown strong potential to boost human productivity and enable new application forms across platforms. While recent advances have led to usable applications, existing benchmarks fail to account for the internal task heterogeneity and the corresponding agent capabilities, as well as their alignment with actual user demands-hindering both targeted capability development and the reliable transition of research progress into practical deployment. To bridge the gap, we present OS-MAP, a benchmark for daily computer-using automation that organizes its 416 realistic tasks across 15 applications along two key dimensions: a five-level taxonomy of automation and a generalization scope derived from a real-world user demand hierarchy. To enable fine-grained analysis of required capabilities and alignment with real-world scenarios, OS-MAP evaluates agents along two dimensions: automation level across a five-level taxonomy, and generalization scope across a demand hierarchy. This design captures varying levels of required agent autonomy and generalization, forming a performance-generalization evaluation matrix for structured and comprehensive assessment. Experiments show that even State-of-the-Art agents with VLM backbones struggle with higher-level tasks involving perception, reasoning, and coordination-highlighting the need for a deeper understanding of current strengths and limitations to drive the future progress in computer-using agents research and deployment. All code, environments, baselines, and data are publicly available at https://github.com/OS-Copilot/OS-Map.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game-Theoretic Gradient Control for Robust Neural Network Training</title>
<link>https://arxiv.org/abs/2507.19143</link>
<guid>https://arxiv.org/abs/2507.19143</guid>
<content:encoded><![CDATA[
arXiv:2507.19143v1 Announce Type: new 
Abstract: Feed-forward neural networks (FFNNs) are vulnerable to input noise, reducing prediction performance. Existing regularization methods like dropout often alter network architecture or overlook neuron interactions. This study aims to enhance FFNN noise robustness by modifying backpropagation, interpreted as a multi-agent game, and exploring controlled target variable noising. Our "gradient dropout" selectively nullifies hidden layer neuron gradients with probability 1 - p during backpropagation, while keeping forward passes active. This is framed within compositional game theory. Additionally, target variables were perturbed with white noise or stable distributions. Experiments on ten diverse tabular datasets show varying impacts: improvement or diminishing of robustness and accuracy, depending on dataset and hyperparameters. Notably, on regression tasks, gradient dropout (p = 0.9) combined with stable distribution target noising significantly increased input noise robustness, evidenced by flatter MSE curves and more stable SMAPE values. These results highlight the method's potential, underscore the critical role of adaptive parameter tuning, and open new avenues for analyzing neural networks as complex adaptive systems exhibiting emergent behavior within a game-theoretic framework.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Diverse and Adaptive Behavior Curriculum for Autonomous Driving: A Student-Teacher Framework with Multi-Agent RL</title>
<link>https://arxiv.org/abs/2507.19146</link>
<guid>https://arxiv.org/abs/2507.19146</guid>
<content:encoded><![CDATA[
arXiv:2507.19146v1 Announce Type: new 
Abstract: Autonomous driving faces challenges in navigating complex real-world traffic, requiring safe handling of both common and critical scenarios. Reinforcement learning (RL), a prominent method in end-to-end driving, enables agents to learn through trial and error in simulation. However, RL training often relies on rule-based traffic scenarios, limiting generalization. Additionally, current scenario generation methods focus heavily on critical scenarios, neglecting a balance with routine driving behaviors. Curriculum learning, which progressively trains agents on increasingly complex tasks, is a promising approach to improving the robustness and coverage of RL driving policies. However, existing research mainly emphasizes manually designed curricula, focusing on scenery and actor placement rather than traffic behavior dynamics. This work introduces a novel student-teacher framework for automatic curriculum learning. The teacher, a graph-based multi-agent RL component, adaptively generates traffic behaviors across diverse difficulty levels. An adaptive mechanism adjusts task difficulty based on student performance, ensuring exposure to behaviors ranging from common to critical. The student, though exchangeable, is realized as a deep RL agent with partial observability, reflecting real-world perception constraints. Results demonstrate the teacher's ability to generate diverse traffic behaviors. The student, trained with automatic curricula, outperformed agents trained on rule-based traffic, achieving higher rewards and exhibiting balanced, assertive driving.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReCoDe: Reinforcement Learning-based Dynamic Constraint Design for Multi-Agent Coordination</title>
<link>https://arxiv.org/abs/2507.19151</link>
<guid>https://arxiv.org/abs/2507.19151</guid>
<content:encoded><![CDATA[
arXiv:2507.19151v1 Announce Type: new 
Abstract: Constraint-based optimization is a cornerstone of robotics, enabling the design of controllers that reliably encode task and safety requirements such as collision avoidance or formation adherence. However, handcrafted constraints can fail in multi-agent settings that demand complex coordination. We introduce ReCoDe--Reinforcement-based Constraint Design--a decentralized, hybrid framework that merges the reliability of optimization-based controllers with the adaptability of multi-agent reinforcement learning. Rather than discarding expert controllers, ReCoDe improves them by learning additional, dynamic constraints that capture subtler behaviors, for example, by constraining agent movements to prevent congestion in cluttered scenarios. Through local communication, agents collectively constrain their allowed actions to coordinate more effectively under changing conditions. In this work, we focus on applications of ReCoDe to multi-agent navigation tasks requiring intricate, context-based movements and consensus, where we show that it outperforms purely handcrafted controllers, other hybrid approaches, and standard MARL baselines. We give empirical (real robot) and theoretical evidence that retaining a user-defined controller, even when it is imperfect, is more efficient than learning from scratch, especially because ReCoDe can dynamically change the degree to which it relies on this controller.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Event-Driven Storytelling with Multiple Lifelike Humans in a 3D Scene</title>
<link>https://arxiv.org/abs/2507.19232</link>
<guid>https://arxiv.org/abs/2507.19232</guid>
<content:encoded><![CDATA[
arXiv:2507.19232v1 Announce Type: new 
Abstract: In this work, we propose a framework that creates a lively virtual dynamic scene with contextual motions of multiple humans. Generating multi-human contextual motion requires holistic reasoning over dynamic relationships among human-human and human-scene interactions. We adapt the power of a large language model (LLM) to digest the contextual complexity within textual input and convert the task into tangible subproblems such that we can generate multi-agent behavior beyond the scale that was not considered before. Specifically, our event generator formulates the temporal progression of a dynamic scene into a sequence of small events. Each event calls for a well-defined motion involving relevant characters and objects. Next, we synthesize the motions of characters at positions sampled based on spatial guidance. We employ a high-level module to deliver scalable yet comprehensive context, translating events into relative descriptions that enable the retrieval of precise coordinates. As the first to address this problem at scale and with diversity, we offer a benchmark to assess diverse aspects of contextual reasoning. Benchmark results and user studies show that our framework effectively captures scene context with high scalability. The code and benchmark, along with result videos, are available at our project page: https://rms0329.github.io/Event-Driven-Storytelling/.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception</title>
<link>https://arxiv.org/abs/2507.19239</link>
<guid>https://arxiv.org/abs/2507.19239</guid>
<content:encoded><![CDATA[
arXiv:2507.19239v1 Announce Type: new 
Abstract: Cooperative perception aims to address the inherent limitations of single-vehicle autonomous driving systems through information exchange among multiple agents. Previous research has primarily focused on single-frame perception tasks. However, the more challenging cooperative sequential perception tasks, such as cooperative 3D multi-object tracking, have not been thoroughly investigated. Therefore, we propose CoopTrack, a fully instance-level end-to-end framework for cooperative tracking, featuring learnable instance association, which fundamentally differs from existing approaches. CoopTrack transmits sparse instance-level features that significantly enhance perception capabilities while maintaining low transmission costs. Furthermore, the framework comprises two key components: Multi-Dimensional Feature Extraction, and Cross-Agent Association and Aggregation, which collectively enable comprehensive instance representation with semantic and motion features, and adaptive cross-agent association and fusion based on a feature graph. Experiments on both the V2X-Seq and Griffin datasets demonstrate that CoopTrack achieves excellent performance. Specifically, it attains state-of-the-art results on V2X-Seq, with 39.0\% mAP and 32.8\% AMOTA. The project is available at https://github.com/zhongjiaru/CoopTrack.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modeling Uncertainty: Constraint-Based Belief States in Imperfect-Information Games</title>
<link>https://arxiv.org/abs/2507.19263</link>
<guid>https://arxiv.org/abs/2507.19263</guid>
<content:encoded><![CDATA[
arXiv:2507.19263v1 Announce Type: new 
Abstract: In imperfect-information games, agents must make decisions based on partial knowledge of the game state. The Belief Stochastic Game model addresses this challenge by delegating state estimation to the game model itself. This allows agents to operate on externally provided belief states, thereby reducing the need for game-specific inference logic. This paper investigates two approaches to represent beliefs in games with hidden piece identities: a constraint-based model using Constraint Satisfaction Problems and a probabilistic extension using Belief Propagation to estimate marginal probabilities. We evaluated the impact of both representations using general-purpose agents across two different games. Our findings indicate that constraint-based beliefs yield results comparable to those of probabilistic inference, with minimal differences in agent performance. This suggests that constraint-based belief states alone may suffice for effective decision-making in many settings.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mut4All: Fuzzing Compilers via LLM-Synthesized Mutators Learned from Bug Reports</title>
<link>https://arxiv.org/abs/2507.19275</link>
<guid>https://arxiv.org/abs/2507.19275</guid>
<content:encoded><![CDATA[
arXiv:2507.19275v1 Announce Type: new 
Abstract: Mutation-based fuzzing is effective for uncovering compiler bugs, but designing high-quality mutators for modern languages with complex constructs (e.g., templates, macros) remains challenging. Existing methods rely heavily on manual design or human-in-the-loop correction, limiting scalability and cross-language generalizability.
  We present Mut4All, a fully automated, language-agnostic framework that synthesizes mutators using Large Language Models (LLMs) and compiler-specific knowledge from bug reports. It consists of three agents: (1) a mutator invention agent that identifies mutation targets and generates mutator metadata using compiler-related insights; (2) a mutator implementation synthesis agent, fine-tuned to produce initial implementations; and (3) a mutator refinement agent that verifies and corrects the mutators via unit-test feedback.
  Mut4All processes 1000 bug reports (500 Rust, 500 C++), yielding 319 Rust and 403 C++ mutators at ~$0.08 each via GPT-4o. Our customized fuzzer, using these mutators, finds 62 bugs in Rust compilers (38 new, 7 fixed) and 34 bugs in C++ compilers (16 new, 1 fixed). Mut4All outperforms existing methods in both unique crash detection and coverage, ranking first on Rust and second on C++.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How Age Influences the Interpretation of Emotional Body Language in Humanoid Robots -- long paper version</title>
<link>https://arxiv.org/abs/2507.19335</link>
<guid>https://arxiv.org/abs/2507.19335</guid>
<content:encoded><![CDATA[
arXiv:2507.19335v1 Announce Type: new 
Abstract: This paper presents an empirical study investigating how individuals across different age groups, children, young and older adults, interpret emotional body language expressed by the humanoid robot NAO. The aim is to offer insights into how users perceive and respond to emotional cues from robotic agents, through an empirical evaluation of the robot's effectiveness in conveying emotions to different groups of users. By analyzing data collected from elderly participants and comparing these findings with previously gathered data from young adults and children, the study highlights similarities and differences between the groups, with younger and older users more similar but different from young adults.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reconstruction of Sparse Urban Wireless Signals via Group Equivariant Non-Expansive Operators</title>
<link>https://arxiv.org/abs/2507.19349</link>
<guid>https://arxiv.org/abs/2507.19349</guid>
<content:encoded><![CDATA[
arXiv:2507.19349v1 Announce Type: new 
Abstract: In emerging communication systems such as sixth generation (6G) wireless networks, efficient resource management and service delivery rely on accurate knowledge of spatially-varying quantities like signal-to-interference-noise ratio (SINR) maps, which are costly to acquire at high resolution. This work explores the reconstruction of such spatial signals from sparse measurements using Group Equivariant Non-Expansive Operators (GENEOs), offering a low-complexity alternative to traditional neural networks. The concept of GENEO, which originated in topological data analysis (TDA), is a mathematical tool used in machine learning to represent agents modelled as functional operators acting on data while incorporating application-specific invariances. Leveraging these invariances reduces the number of parameters with respect to traditional neural networks and mitigates data scarcity by enforcing known algebraic and geometric constraints that reflect symmetries in the agents' actions. In this paper, we introduce a novel GENEO-based approach for SINR map reconstruction in urban wireless communication networks using extremely sparse sampling. We demonstrate that this mathematical framework achieves competitive performance compared to established methods. Our evaluation, conducted using both statistical and TDA metrics, highlights the advantages of our approach in accurately reconstructing spatial signals under severe data limitations on the number of samples.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating LLM in Agent-Based Social Simulation: Opportunities and Challenges</title>
<link>https://arxiv.org/abs/2507.19364</link>
<guid>https://arxiv.org/abs/2507.19364</guid>
<content:encoded><![CDATA[
arXiv:2507.19364v1 Announce Type: new 
Abstract: This position paper examines the use of Large Language Models (LLMs) in social simulation, analyzing both their potential and their limitations from a computational social science perspective. The first part reviews recent findings on the ability of LLMs to replicate key aspects of human cognition, including Theory of Mind reasoning and social inference, while also highlighting significant limitations such as cognitive biases, lack of true understanding, and inconsistencies in behavior. The second part surveys emerging applications of LLMs in multi-agent simulation frameworks, focusing on system architectures, scale, and validation strategies. Notable projects such as Generative Agents (Smallville) and AgentSociety are discussed in terms of their design choices, empirical grounding, and methodological innovations. Particular attention is given to the challenges of behavioral fidelity, calibration, and reproducibility in large-scale LLM-driven simulations. The final section distinguishes between contexts where LLMs, like other black-box systems, offer direct value-such as interactive simulations and serious games-and those where their use is more problematic, notably in explanatory or predictive modeling. The paper concludes by advocating for hybrid approaches that integrate LLMs into traditional agent-based modeling platforms (GAMA, Netlogo, etc), enabling modelers to combine the expressive flexibility of language-based reasoning with the transparency and analytical rigor of classical rule-based systems.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning-Based Scheduling for Wi-Fi Multi-Access Point Coordination</title>
<link>https://arxiv.org/abs/2507.19377</link>
<guid>https://arxiv.org/abs/2507.19377</guid>
<content:encoded><![CDATA[
arXiv:2507.19377v1 Announce Type: new 
Abstract: Multi-access point coordination (MAPC) is a key feature of IEEE 802.11bn, with a potential impact on future Wi-Fi networks. MAPC enables joint scheduling decisions across multiple access points (APs) to improve throughput, latency, and reliability in dense Wi-Fi deployments. However, implementing efficient scheduling policies under diverse traffic and interference conditions in overlapping basic service sets (OBSSs) remains a complex task. This paper presents a method to minimize the network-wide worst-case latency by formulating MAPC scheduling as a sequential decision-making problem and proposing a deep reinforcement learning (DRL) mechanism to minimize worst-case delays in OBSS deployments. Specifically, we train a DRL agent using proximal policy optimization (PPO) within an 802.11bn-compatible Gymnasium environment. This environment provides observations of queue states, delay metrics, and channel conditions, enabling the agent to schedule multiple AP-station pairs to transmit simultaneously by leveraging spatial reuse (SR) groups. Simulations demonstrate that our proposed solution outperforms state-of-the-art heuristic strategies across a wide range of network loads and traffic patterns. The trained machine learning (ML) models consistently achieve lower 99th-percentile delays, showing up to a 30% improvement over the best baseline.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SILS: Strategic Influence on Liquidity Stability and Whale Detection in Concentrated-Liquidity DEXs</title>
<link>https://arxiv.org/abs/2507.19411</link>
<guid>https://arxiv.org/abs/2507.19411</guid>
<content:encoded><![CDATA[
arXiv:2507.19411v1 Announce Type: new 
Abstract: Traditional methods for identifying impactful liquidity providers (LPs) in Concentrated Liquidity Market Makers (CLMMs) rely on broad measures, such as nominal capital size or surface-level activity, which often lead to inaccurate risk analysis. The SILS framework offers a significantly more detailed approach, characterizing LPs not just as capital holders but as dynamic systemic agents whose actions directly impact market stability. This represents a fundamental paradigm shift from the static, volume-based analysis to a dynamic, impact-focused understanding. This advanced approach uses on-chain event logs and smart contract execution traces to compute Exponential Time-Weighted Liquidity (ETWL) profiles and apply unsupervised anomaly detection. Most importantly, it defines an LP's functional importance through the Liquidity Stability Impact Score (LSIS), a counterfactual metric that measures the potential degradation of the market if the LP withdraws. This combined approach provides a more detailed and realistic characterization of an LP's impact, moving beyond the binary and often misleading classifications used by existing methods. This impact-focused and comprehensive approach enables SILS to accurately identify high-impact LPs-including those missed by traditional methods and supports essential applications like a protective oracle layer and actionable trader signals, thereby significantly enhancing DeFi ecosystem. The framework provides unprecedented transparency into the underlying liquidity structure and associated risks, effectively reducing the common false positives and uncovering critical false negatives found in traditional models. Therefore, SILS provides an effective mechanism for proactive risk management, transforming how DeFi protocols safeguard their ecosystems against asymmetric liquidity behavior.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Observations Meet Actions: Learning Control-Sufficient Representations for Robust Policy Generalization</title>
<link>https://arxiv.org/abs/2507.19437</link>
<guid>https://arxiv.org/abs/2507.19437</guid>
<content:encoded><![CDATA[
arXiv:2507.19437v1 Announce Type: new 
Abstract: Capturing latent variations ("contexts") is key to deploying reinforcement-learning (RL) agents beyond their training regime. We recast context-based RL as a dual inference-control problem and formally characterize two properties and their hierarchy: observation sufficiency (preserving all predictive information) and control sufficiency (retaining decision-making relevant information). Exploiting this dichotomy, we derive a contextual evidence lower bound(ELBO)-style objective that cleanly separates representation learning from policy learning and optimizes it with Bottlenecked Contextual Policy Optimization (BCPO), an algorithm that places a variational information-bottleneck encoder in front of any off-policy policy learner. On standard continuous-control benchmarks with shifting physical parameters, BCPO matches or surpasses other baselines while using fewer samples and retaining performance far outside the training regime. The framework unifies theory, diagnostics, and practice for context-based RL.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Existence of 2-EFX Allocations of Chores</title>
<link>https://arxiv.org/abs/2507.19461</link>
<guid>https://arxiv.org/abs/2507.19461</guid>
<content:encoded><![CDATA[
arXiv:2507.19461v1 Announce Type: new 
Abstract: We study the fair division of indivisible chores among agents with additive disutility functions. We investigate the existence of allocations satisfying the popular fairness notion of envy-freeness up to any chore (EFX), and its multiplicative approximations. The existence of $4$-EFX allocations was recently established by Garg, Murhekar, and Qin (2025). We improve this guarantee by proving the existence of $2$-EFX allocations for all instances with additive disutilities. This approximation was previously known only for restricted instances such as bivalued disutilities (Lin, Wu, and Zhou (2025)) or three agents (Afshinmehr, Ansaripour, Danaei, and Mehlhorn (2024)).
  We obtain our result by providing a general framework for achieving approximate-EFX allocations. The approach begins with a suitable initial allocation and performs a sequence of local swaps between the bundles of envious and envied agents. For our main result, we begin with an initial allocation that satisfies envy-freeness up to one chore (EF1) and Pareto-optimality (PO); the existence of such an allocation was recently established in a major breakthrough by Mahara (2025). We further demonstrate the strength and generality of our framework by giving simple and unified proofs of existing results, namely (i) $2$-EFX for bivalued instances, (ii) 2-EFX for three agents, (iii) EFX when the number of chores is at most twice the number of agents, and (iv) $4$-EFX for all instances. We expect this framework to have broader applications in approximate-EFX due to its simplicity and generality.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MMBench-GUI: Hierarchical Multi-Platform Evaluation Framework for GUI Agents</title>
<link>https://arxiv.org/abs/2507.19478</link>
<guid>https://arxiv.org/abs/2507.19478</guid>
<content:encoded><![CDATA[
arXiv:2507.19478v1 Announce Type: new 
Abstract: We introduce MMBench-GUI, a hierarchical benchmark for evaluating GUI automation agents across Windows, macOS, Linux, iOS, Android, and Web platforms. It comprises four levels: GUI Content Understanding, Element Grounding, Task Automation, and Task Collaboration, covering essential skills for GUI agents. In addition, we propose a novel Efficiency-Quality Area (EQA) metric to assess GUI agent execution efficiency in online automation scenarios. Through MMBench-GUI, we identify accurate visual grounding as a critical determinant of overall task success, emphasizing the substantial benefits of modular frameworks that integrate specialized grounding modules. Furthermore, to achieve reliable GUI automation, an agent requires strong task planning and cross-platform generalization abilities, with long-context memory, a broad action space, and long-term reasoning playing a critical role. More important, task efficiency remains a critically underexplored dimension, and all models suffer from substantial inefficiencies, with excessive redundant steps even when tasks are ultimately completed. The integration of precise localization, effective planning, and early stopping strategies is indispensable to enable truly efficient and scalable GUI automation. Our benchmark code, evaluation data, and running environment will be publicly available at https://github.com/open-compass/MMBench-GUI.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finance as Extended Biology: Reciprocity as the Cognitive Substrate of Financial Behavior</title>
<link>https://arxiv.org/abs/2506.00099</link>
<guid>https://arxiv.org/abs/2506.00099</guid>
<content:encoded><![CDATA[
arXiv:2506.00099v2 Announce Type: cross 
Abstract: A central challenge in economics and artificial intelligence is explaining how financial behaviors-such as credit, insurance, and trade-emerge without formal institutions. We argue that these functions are not products of institutional design, but structured extensions of a single behavioral substrate: reciprocity. Far from being a derived strategy, reciprocity served as the foundational logic of early human societies-governing the circulation of goods, regulation of obligation, and maintenance of long-term cooperation well before markets, money, or formal rules. Trade, commonly regarded as the origin of financial systems, is reframed here as the canonical form of reciprocity: simultaneous, symmetric, and partner-contingent. Building on this logic, we reconstruct four core financial functions-credit, insurance, token exchange, and investment-as expressions of the same underlying principle under varying conditions. By grounding financial behavior in minimal, simulateable dynamics of reciprocal interaction, this framework shifts the focus from institutional engineering to behavioral computation-offering a new foundation for modeling decentralized financial behavior in both human and artificial agents.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Metachronal Paddling with Reinforcement Learning at Low Reynolds Number</title>
<link>https://arxiv.org/abs/2507.18849</link>
<guid>https://arxiv.org/abs/2507.18849</guid>
<content:encoded><![CDATA[
arXiv:2507.18849v1 Announce Type: cross 
Abstract: Metachronal paddling is a swimming strategy in which an organism oscillates sets of adjacent limbs with a constant phase lag, propagating a metachronal wave through its limbs and propelling it forward. This limb coordination strategy is utilized by swimmers across a wide range of Reynolds numbers, which suggests that this metachronal rhythm was selected for its optimality of swimming performance. In this study, we apply reinforcement learning to a swimmer at zero Reynolds number and investigate whether the learning algorithm selects this metachronal rhythm, or if other coordination patterns emerge. We design the swimmer agent with an elongated body and pairs of straight, inflexible paddles placed along the body for various fixed paddle spacings. Based on paddle spacing, the swimmer agent learns qualitatively different coordination patterns. At tight spacings, a back-to-front metachronal wave-like stroke emerges which resembles the commonly observed biological rhythm, but at wide spacings, different limb coordinations are selected. Across all resulting strokes, the fastest stroke is dependent on the number of paddles, however, the most efficient stroke is a back-to-front wave-like stroke regardless of the number of paddles.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Controlling Topological Defects in Polar Fluids via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.19298</link>
<guid>https://arxiv.org/abs/2507.19298</guid>
<content:encoded><![CDATA[
arXiv:2507.19298v1 Announce Type: cross 
Abstract: Topological defects in active polar fluids exhibit complex dynamics driven by internally generated stresses, reflecting the deep interplay between topology, flow, and non-equilibrium hydrodynamics. Feedback control offers a powerful means to guide such systems, enabling transitions between dynamic states. We investigated closed-loop steering of integer-charged defects in a confined active fluid by modulating the spatial profile of activity. Using a continuum hydrodynamic model, we show that localized control of active stress induces flow fields that can reposition and direct defects along prescribed trajectories by exploiting non-linear couplings in the system. A reinforcement learning framework is used to discover effective control strategies that produce robust defect transport across both trained and novel trajectories. The results highlight how AI agents can learn the underlying dynamics and spatially structure activity to manipulate topological excitations, offering insights into the controllability of active matter and the design of adaptive, self-organized materials.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Secret Collusion among AI Agents: Multi-Agent Deception via Steganography</title>
<link>https://arxiv.org/abs/2402.07510</link>
<guid>https://arxiv.org/abs/2402.07510</guid>
<content:encoded><![CDATA[
arXiv:2402.07510v5 Announce Type: replace 
Abstract: Recent capability increases in large language models (LLMs) open up applications in which groups of communicating generative AI agents solve joint tasks. This poses privacy and security challenges concerning the unauthorised sharing of information, or other unwanted forms of agent coordination. Modern steganographic techniques could render such dynamics hard to detect. In this paper, we comprehensively formalise the problem of secret collusion in systems of generative AI agents by drawing on relevant concepts from both AI and security literature. We study incentives for the use of steganography, and propose a variety of mitigation measures. Our investigations result in a model evaluation framework that systematically tests capabilities required for various forms of secret collusion. We provide extensive empirical results across a range of contemporary LLMs. While the steganographic capabilities of current models remain limited, GPT-4 displays a capability jump suggesting the need for continuous monitoring of steganographic frontier model capabilities. We conclude by laying out a comprehensive research program to mitigate future risks of collusion between generative AI models.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ToolACE: Winning the Points of LLM Function Calling</title>
<link>https://arxiv.org/abs/2409.00920</link>
<guid>https://arxiv.org/abs/2409.00920</guid>
<content:encoded><![CDATA[
arXiv:2409.00920v2 Announce Type: replace 
Abstract: Function calling significantly extends the application boundary of large language models, where high-quality and diverse training data is critical for unlocking this capability. However, real function-calling data is quite challenging to collect and annotate, while synthetic data generated by existing pipelines tends to lack coverage and accuracy. In this paper, we present ToolACE, an automatic agentic pipeline designed to generate accurate, complex, and diverse tool-learning data. ToolACE leverages a novel self-evolution synthesis process to curate a comprehensive API pool of 26,507 diverse APIs. Dialogs are further generated through the interplay among multiple agents, guided by a formalized thinking process. To ensure data accuracy, we implement a dual-layer verification system combining rule-based and model-based checks. We demonstrate that models trained on our synthesized data, even with only 8B parameters, achieve state-of-the-art performance on the Berkeley Function-Calling Leaderboard, rivaling the latest GPT-4 models. Our model and a subset of the data are publicly available at https://huggingface.co/Team-ACE.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bootstrapped Reward Shaping</title>
<link>https://arxiv.org/abs/2501.00989</link>
<guid>https://arxiv.org/abs/2501.00989</guid>
<content:encoded><![CDATA[
arXiv:2501.00989v2 Announce Type: replace 
Abstract: In reinforcement learning, especially in sparse-reward domains, many environment steps are required to observe reward information. In order to increase the frequency of such observations, "potential-based reward shaping" (PBRS) has been proposed as a method of providing a more dense reward signal while leaving the optimal policy invariant. However, the required "potential function" must be carefully designed with task-dependent knowledge to not deter training performance. In this work, we propose a "bootstrapped" method of reward shaping, termed BSRS, in which the agent's current estimate of the state-value function acts as the potential function for PBRS. We provide convergence proofs for the tabular setting, give insights into training dynamics for deep RL, and show that the proposed method improves training speed in the Atari suite.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Self-Improvement for Smarter Energy Systems using Agentic Policy Search</title>
<link>https://arxiv.org/abs/2501.19340</link>
<guid>https://arxiv.org/abs/2501.19340</guid>
<content:encoded><![CDATA[
arXiv:2501.19340v2 Announce Type: replace 
Abstract: Controlling energy systems usually involves manually designed policies for decision-making, which can be complex and time-consuming to develop. This process requires interdisciplinary collaboration among multiple domain experts, resulting in slow and inflexible adaptation to rapidly changing environments. Large Language Models (LLMs) offer a promising paradigm shift by integrating extensive contextual knowledge with the capability to generate structured, executable code.
  We present Agentic Policy Search (APS) -- a novel hierarchical optimization framework in which LLMs act as autonomous agents that propose complete control logics, translate them into executable code, and iteratively improve them through direct system feedback. We apply APS to a residential energy system with PV, battery, demand, and dynamic electricity prices. Within just seven simulated days, the method yields a net profit of up to 6.20 EUR compared to the no-battery reference scenario (-10.70 EUR), nearly matching the global optimum of a perfectly informed linear program. By combining LLM-driven policy search with the generation of human-interpretable control logic, APS effectively bridges adaptability and traceability in energy management -- while also offering a transferable framework for agentic optimization in other domains.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Improving Reward Design in RL: A Reward Alignment Metric for RL Practitioners</title>
<link>https://arxiv.org/abs/2503.05996</link>
<guid>https://arxiv.org/abs/2503.05996</guid>
<content:encoded><![CDATA[
arXiv:2503.05996v2 Announce Type: replace 
Abstract: Reinforcement learning agents are fundamentally limited by the quality of the reward functions they learn from, yet reward design is often overlooked under the assumption that a well-defined reward is readily available. However, in practice, designing rewards is difficult, and even when specified, evaluating their correctness is equally problematic: how do we know if a reward function is correctly specified? In our work, we address these challenges by focusing on reward alignment -- assessing whether a reward function accurately encodes the preferences of a human stakeholder. As a concrete measure of reward alignment, we introduce the Trajectory Alignment Coefficient to quantify the similarity between a human stakeholder's ranking of trajectory distributions and those induced by a given reward function. We show that the Trajectory Alignment Coefficient exhibits desirable properties, such as not requiring access to a ground truth reward, invariance to potential-based reward shaping, and applicability to online RL. Additionally, in an 11 -- person user study of RL practitioners, we found that access to the Trajectory Alignment Coefficient during reward selection led to statistically significant improvements. Compared to relying only on reward functions, our metric reduced cognitive workload by 1.5x, was preferred by 82% of users and increased the success rate of selecting reward functions that produced performant policies by 41%.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Super Agent System with Hybrid AI Routers</title>
<link>https://arxiv.org/abs/2504.10519</link>
<guid>https://arxiv.org/abs/2504.10519</guid>
<content:encoded><![CDATA[
arXiv:2504.10519v2 Announce Type: replace 
Abstract: AI Agents powered by Large Language Models are transforming the world through enormous applications. A super agent has the potential to fulfill diverse user needs, such as summarization, coding, and research, by accurately understanding user intent and leveraging the appropriate tools to solve tasks. However, to make such an agent viable for real-world deployment and accessible at scale, significant optimizations are required to ensure high efficiency and low cost. This position paper presents a design of the Super Agent System powered by the hybrid AI routers. Upon receiving a user prompt, the system first detects the intent of the user, then routes the request to specialized task agents with the necessary tools or automatically generates agentic workflows. In practice, most applications directly serve as AI assistants on edge devices such as phones and robots. As different language models vary in capability and cloud-based models often entail high computational costs, latency, and privacy concerns, we then explore the hybrid mode where the router dynamically selects between local and cloud models based on task complexity. Finally, we introduce the blueprint of an on-device super agent enhanced with cloud. With advances in multi-modality models and edge hardware, we envision that most computations can be handled locally, with cloud collaboration only as needed. Such architecture paves the way for super agents to be seamlessly integrated into everyday life in the near future.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reshaping MOFs text mining with a dynamic multi-agents framework of large language model</title>
<link>https://arxiv.org/abs/2504.18880</link>
<guid>https://arxiv.org/abs/2504.18880</guid>
<content:encoded><![CDATA[
arXiv:2504.18880v2 Announce Type: replace 
Abstract: Accurately identifying synthesis conditions for metal-organic frameworks (MOFs) remains a critical bottleneck in materials research, as translating literature-derived knowledge into actionable insights is hindered by the unstructured and heterogeneous nature of scientific texts. Here we present MOFh6, a large language model (LLM)-based multi-agent system designed to extract, structure, and apply synthesis knowledge from diverse input formats, including raw literature and crystal codes. Built on gpt-4o-mini and fine-tuned with up to few-shot expert-annotated data, MOFh6 achieves 99% accuracy in synthesis data parsing and resolves 94.1% of complex co-reference abbreviations. It processes a single full-text document in 9.6 seconds and localizes structured synthesis descriptions within 36 seconds, with the cost per 100 papers reduced to USD 4.24, a 76% saving over existing systems. By addressing long-standing limitations in cross-paragraph semantic fusion and terminology standardization, MOFh6 reshapes the LLM-based paradigm for MOF synthesis research, transforming static retrieval into an integrated and dynamic knowledge acquisition process. This shift bridges the gap between scientific literature and actionable synthesis design, providing a scalable framework for accelerating materials discovery.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DoctorAgent-RL: A Multi-Agent Collaborative Reinforcement Learning System for Multi-Turn Clinical Dialogue</title>
<link>https://arxiv.org/abs/2505.19630</link>
<guid>https://arxiv.org/abs/2505.19630</guid>
<content:encoded><![CDATA[
arXiv:2505.19630v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated excellent capabilities in the field of biomedical question answering, but their application in real-world clinical consultations still faces core challenges. Single-round consultation systems require patients to describe all symptoms upfront, leading to vague diagnosis with unclear complaints. Traditional multi-turn dialogue models, constrained by static supervised learning, lack flexibility and fail to intelligently extract key clinical information. To address these limitations, we propose \Ours{}, a reinforcement learning (RL)-based multi-agent collaborative framework that models medical consultations as a dynamic decision-making process under uncertainty. The doctor agent continuously optimizes its questioning strategy within the RL framework through multi-turn interactions with the patient agent, dynamically adjusting its information-gathering path based on comprehensive rewards from the Consultation Evaluator. This RL fine-tuning mechanism enables LLMs to autonomously develop interaction strategies aligned with clinical reasoning logic, rather than superficially imitating patterns in existing dialogue data. Notably, we constructed MTMedDialog, the first English multi-turn medical consultation dataset capable of simulating patient interactions. Experiments demonstrate that \Ours{} outperforms existing models in both multi-turn reasoning capability and final diagnostic performance. This approach shows immense practical value by reducing misdiagnosis risks in time-pressured settings, freeing clinicians for complex cases, and pioneering a strategy to optimize medical resource allocation and alleviate workforce shortages. Code and data are available at https://github.com/JarvisUSTC/DoctorAgent-RL
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI PsyRoom: Artificial Intelligence Platform for Segmented Yearning and Reactive Outcome Optimization Method</title>
<link>https://arxiv.org/abs/2506.06740</link>
<guid>https://arxiv.org/abs/2506.06740</guid>
<content:encoded><![CDATA[
arXiv:2506.06740v2 Announce Type: replace 
Abstract: Psychological counseling faces huge challenges due to the growing demand for mental health services and the shortage of trained professionals. Large language models (LLMs) have shown potential to assist psychological counseling, especially in empathy and emotional support. However, existing models lack a deep understanding of emotions and are unable to generate personalized treatment plans based on fine-grained emotions. To address these shortcomings, we present AI PsyRoom, a multi-agent simulation framework designed to enhance psychological counseling by generating empathetic and emotionally nuanced conversations. By leveraging fine-grained emotion classification and a multi-agent framework, we construct a multi-agent PsyRoom A for dialogue reconstruction, generating a high-quality dialogue dataset EmoPsy, which contains 35 sub-emotions, 423 specific emotion scenarios, and 12,350 dialogues. We also propose PsyRoom B for generating personalized treatment plans. Quantitative evaluations demonstrate that AI PsyRoom significantly outperforms state-of-the-art methods, achieving 18% improvement in problem orientation, 23% in expression, 24% in Empathy, and 16% in interactive communication quality. The datasets and models are publicly available, providing a foundation for advancing AI-assisted psychological counseling research.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Algorithms with Probing for Multi-Agent Multi-Armed Bandits</title>
<link>https://arxiv.org/abs/2506.14988</link>
<guid>https://arxiv.org/abs/2506.14988</guid>
<content:encoded><![CDATA[
arXiv:2506.14988v3 Announce Type: replace 
Abstract: We propose a multi-agent multi-armed bandit (MA-MAB) framework aimed at ensuring fair outcomes across agents while maximizing overall system performance. A key challenge in this setting is decision-making under limited information about arm rewards. To address this, we introduce a novel probing framework that strategically gathers information about selected arms before allocation. In the offline setting, where reward distributions are known, we leverage submodular properties to design a greedy probing algorithm with a provable performance bound. For the more complex online setting, we develop an algorithm that achieves sublinear regret while maintaining fairness. Extensive experiments on synthetic and real-world datasets show that our approach outperforms baseline methods, achieving better fairness and efficiency.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delphos: A reinforcement learning framework for assisting discrete choice model specification</title>
<link>https://arxiv.org/abs/2506.06410</link>
<guid>https://arxiv.org/abs/2506.06410</guid>
<content:encoded><![CDATA[
arXiv:2506.06410v2 Announce Type: replace-cross 
Abstract: We introduce Delphos, a deep reinforcement learning framework for assisting the discrete choice model specification process. Unlike traditional approaches that treat model specification as a static optimisation problem, Delphos represents a paradigm shift: it frames this specification challenge as a sequential decision-making problem, formalised as a Markov Decision Process. In this setting, an agent learns to specify well-performing model candidates by choosing a sequence of modelling actions - such as selecting variables, accommodating both generic and alternative-specific taste parameters, applying non-linear transformations, and including interactions with covariates - and interacting with a modelling environment that estimates each candidate and returns a reward signal. Specifically, Delphos uses a Deep Q-Network that receives delayed rewards based on modelling outcomes (e.g., log-likelihood) and behavioural expectations (e.g., parameter signs), and distributes rewards across the sequence of actions to learn which modelling decisions lead to well-performing candidates. We evaluate Delphos on both simulated and empirical datasets, varying the size of the modelling space and the reward function. To assess the agent's performance in navigating the model space, we analyse the learning curve, the distribution of Q-values, occupancy metrics, and Pareto fronts. Our results show that the agent learns to adaptively explore strategies to identify well-performing models across search spaces, even without prior domain knowledge. It efficiently explores large modelling spaces, concentrates its search in high-reward regions, and suggests candidates that define Pareto frontiers balancing model fit and behavioural plausibility. These findings highlight the potential of this novel adaptive, learning-based framework to assist in the model specification process.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring Communication Strategies for Collaborative LLM Agents in Mathematical Problem-Solving</title>
<link>https://arxiv.org/abs/2507.17753</link>
<guid>https://arxiv.org/abs/2507.17753</guid>
<content:encoded><![CDATA[
arXiv:2507.17753v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents are increasingly utilized in AI-aided education to support tutoring and learning. Effective communication strategies among LLM agents improve collaborative problem-solving efficiency and facilitate cost-effective adoption in education. However, little research has systematically evaluated the impact of different communication strategies on agents' problem-solving. Our study examines four communication modes, \textit{teacher-student interaction}, \textit{peer-to-peer collaboration}, \textit{reciprocal peer teaching}, and \textit{critical debate}, in a dual-agent, chat-based mathematical problem-solving environment using the OpenAI GPT-4o model. Evaluated on the MATH dataset, our results show that dual-agent setups outperform single agents, with \textit{peer-to-peer collaboration} achieving the highest accuracy. Dialogue acts like statements, acknowledgment, and hints play a key role in collaborative problem-solving. While multi-agent frameworks enhance computational tasks, effective communication strategies are essential for tackling complex problems in AI education.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Co-constructing Explanations for AI Systems using Provenance</title>
<link>https://arxiv.org/abs/2507.17761</link>
<guid>https://arxiv.org/abs/2507.17761</guid>
<content:encoded><![CDATA[
arXiv:2507.17761v1 Announce Type: new 
Abstract: Modern AI systems are complex workflows containing multiple components and data sources. Data provenance provides the ability to interrogate and potentially explain the outputs of these systems. However, provenance is often too detailed and not contextualized for the user trying to understand the AI system. In this work, we present our vision for an interactive agent that works together with the user to co-construct an explanation that is simultaneously useful to the user as well as grounded in data provenance. To illustrate this vision, we present: 1) an initial prototype of such an agent; and 2) a scalable evaluation framework based on user simulations and a large language model as a judge approach.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Human-AI Co-Creation: A Framework for Collaborative Design in Intelligent Systems</title>
<link>https://arxiv.org/abs/2507.17774</link>
<guid>https://arxiv.org/abs/2507.17774</guid>
<content:encoded><![CDATA[
arXiv:2507.17774v1 Announce Type: new 
Abstract: As artificial intelligence (AI) continues to evolve from a back-end computational tool into an interactive, generative collaborator, its integration into early-stage design processes demands a rethinking of traditional workflows in human-centered design. This paper explores the emergent paradigm of human-AI co-creation, where AI is not merely used for automation or efficiency gains, but actively participates in ideation, visual conceptualization, and decision-making. Specifically, we investigate the use of large language models (LLMs) like GPT-4 and multimodal diffusion models such as Stable Diffusion as creative agents that engage designers in iterative cycles of proposal, critique, and revision.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Frame-Based Zero-Shot Semantic Channel Equalization for AI-Native Communications</title>
<link>https://arxiv.org/abs/2507.17835</link>
<guid>https://arxiv.org/abs/2507.17835</guid>
<content:encoded><![CDATA[
arXiv:2507.17835v1 Announce Type: new 
Abstract: In future AI-native wireless networks, the presence of mismatches between the latent spaces of independently designed and trained deep neural network (DNN) encoders may impede mutual understanding due to the emergence of semantic channel noise. This undermines the receiver's ability to interpret transmitted representations, thereby reducing overall system performance. To address this issue, we propose the Parseval Frame Equalizer (PFE), a zero-shot, frame-based semantic channel equalizer that aligns latent spaces of heterogeneous encoders without requiring system retraining. PFE enables dynamic signal compression and expansion, mitigating semantic noise while preserving performance on downstream tasks. Building on this capability, we introduce a dynamic optimization strategy that coordinates communication, computation, and learning resources to balance energy consumption, end-to-end (E2E) latency, and task performance in multi-agent semantic communication scenarios. Extensive simulations confirm the effectiveness of our approach in maintaining semantic consistency and meeting long-term constraints on latency and accuracy under diverse and time-varying network conditions.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Technical Implementation of Tippy: Multi-Agent Architecture and System Design for Drug Discovery Laboratory Automation</title>
<link>https://arxiv.org/abs/2507.17852</link>
<guid>https://arxiv.org/abs/2507.17852</guid>
<content:encoded><![CDATA[
arXiv:2507.17852v1 Announce Type: new 
Abstract: Building on the conceptual framework presented in our previous work on agentic AI for pharmaceutical research, this paper provides a comprehensive technical analysis of Tippy's multi-agent system implementation for drug discovery laboratory automation. We present a distributed microservices architecture featuring five specialized agents (Supervisor, Molecule, Lab, Analysis, and Report) that coordinate through OpenAI Agents SDK orchestration and access laboratory tools via the Model Context Protocol (MCP). The system architecture encompasses agent-specific tool integration, asynchronous communication patterns, and comprehensive configuration management through Git-based tracking. Our production deployment strategy utilizes Kubernetes container orchestration with Helm charts, Docker containerization, and CI/CD pipelines for automated testing and deployment. The implementation integrates vector databases for RAG functionality and employs an Envoy reverse proxy for secure external access. This work demonstrates how specialized AI agents can effectively coordinate complex laboratory workflows while maintaining security, scalability, reliability, and integration with existing laboratory infrastructure through standardized protocols.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Reinforcement Learning-based Automatic Generation Control</title>
<link>https://arxiv.org/abs/2507.17868</link>
<guid>https://arxiv.org/abs/2507.17868</guid>
<content:encoded><![CDATA[
arXiv:2507.17868v1 Announce Type: new 
Abstract: Amidst the growing demand for implementing advanced control and decision-making algorithms|to enhance the reliability, resilience, and stability of power systems|arises a crucial concern regarding the safety of employing machine learning techniques. While these methods can be applied to derive more optimal control decisions, they often lack safety assurances. This paper proposes a framework based on control barrier functions to facilitate safe learning and deployment of reinforcement learning agents for power system control applications, specifically in the context of automatic generation control. We develop the safety barriers and reinforcement learning framework necessary to establish trust in reinforcement learning as a safe option for automatic generation control - as foundation for future detailed verification and application studies.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>I2I-STRADA -- Information to Insights via Structured Reasoning Agent for Data Analysis</title>
<link>https://arxiv.org/abs/2507.17874</link>
<guid>https://arxiv.org/abs/2507.17874</guid>
<content:encoded><![CDATA[
arXiv:2507.17874v1 Announce Type: new 
Abstract: Recent advances in agentic systems for data analysis have emphasized automation of insight generation through multi-agent frameworks, and orchestration layers. While these systems effectively manage tasks like query translation, data transformation, and visualization, they often overlook the structured reasoning process underlying analytical thinking. Reasoning large language models (LLMs) used for multi-step problem solving are trained as general-purpose problem solvers. As a result, their reasoning or thinking steps do not adhere to fixed processes for specific tasks. Real-world data analysis requires a consistent cognitive workflow: interpreting vague goals, grounding them in contextual knowledge, constructing abstract plans, and adapting execution based on intermediate outcomes. We introduce I2I-STRADA (Information-to-Insight via Structured Reasoning Agent for Data Analysis), an agentic architecture designed to formalize this reasoning process. I2I-STRADA focuses on modeling how analysis unfolds via modular sub-tasks that reflect the cognitive steps of analytical reasoning. Evaluations on the DABstep and DABench benchmarks show that I2I-STRADA outperforms prior systems in planning coherence and insight alignment, highlighting the importance of structured cognitive workflows in agent design for data analysis.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trusted Data Fusion, Multi-Agent Autonomy, Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2507.17875</link>
<guid>https://arxiv.org/abs/2507.17875</guid>
<content:encoded><![CDATA[
arXiv:2507.17875v1 Announce Type: new 
Abstract: Multi-agent collaboration enhances situational awareness in intelligence, surveillance, and reconnaissance (ISR) missions. Ad hoc networks of unmanned aerial vehicles (UAVs) allow for real-time data sharing, but they face security challenges due to their decentralized nature, making them vulnerable to cyber-physical attacks. This paper introduces a trust-based framework for assured sensor fusion in distributed multi-agent networks, utilizing a hidden Markov model (HMM)-based approach to estimate the trustworthiness of agents and their provided information in a decentralized fashion. Trust-informed data fusion prioritizes fusing data from reliable sources, enhancing resilience and accuracy in contested environments. To evaluate the assured sensor fusion under attacks on system/mission sensing, we present a novel multi-agent aerial dataset built from the Unreal Engine simulator. We demonstrate through case studies improved ISR performance and an ability to detect malicious actors in adversarial settings.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Study of GenAI Adoption in Open-Source Game Development: Tools, Tasks, and Developer Challenges</title>
<link>https://arxiv.org/abs/2507.18029</link>
<guid>https://arxiv.org/abs/2507.18029</guid>
<content:encoded><![CDATA[
arXiv:2507.18029v1 Announce Type: new 
Abstract: The growing capabilities of generative AI (GenAI) have begun to reshape how games are designed and developed, offering new tools for content creation, gameplay simulation, and design ideation. While prior research has explored traditional uses of AI in games, such as controlling agents or generating procedural content. There is limited empirical understanding of how GenAI is adopted by developers in real-world contexts, especially within the open-source community. This study aims to explore how GenAI technologies are discussed, adopted, and integrated into open-source game development by analyzing issue discussions on GitHub. We investigate the tools, tasks, and challenges associated with GenAI by comparing GenAI-related issues to those involving traditional AI (TradAI) and NonAI topics. Our goal is to uncover how GenAI differs from other approaches in terms of usage patterns, developer concerns, and integration practices. To address this objective, we construct a dataset of open-source game repositories that discuss AI-related topics. We apply open card sorting and thematic analysis to a stratified sample of GitHub issues, labelling each by type and content. These annotations enable comparative analysis across GenAI, TradAI, and NonAI groups, and provide insight into how GenAI is shaping the workflows and pain points of open-source game developers.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FCPO: Federated Continual Policy Optimization for Real-Time High-Throughput Edge Video Analytics</title>
<link>https://arxiv.org/abs/2507.18047</link>
<guid>https://arxiv.org/abs/2507.18047</guid>
<content:encoded><![CDATA[
arXiv:2507.18047v1 Announce Type: new 
Abstract: The growing complexity of Edge Video Analytics (EVA) facilitates new kind of intelligent applications, but creates challenges in real-time inference serving systems. State-of-the-art (SOTA) scheduling systems optimize global workload distributions for heterogeneous devices but often suffer from extended scheduling cycles, leading to sub-optimal processing in rapidly changing Edge environments. Local Reinforcement Learning (RL) enables quick adjustments between cycles but faces scalability, knowledge integration, and adaptability issues. Thus, we propose FCPO, which combines Continual RL (CRL) with Federated RL (FRL) to address these challenges. This integration dynamically adjusts inference batch sizes, input resolutions, and multi-threading during pre- and post-processing. CRL allows agents to learn from changing Markov Decision Processes, capturing dynamic environmental variations, while FRL improves generalization and convergence speed by integrating experiences across inference models. FCPO combines these via an agent-specific aggregation scheme and a diversity-aware experience buffer. Experiments on a real-world EVA testbed showed over 5 times improvement in effective throughput, 60% reduced latency, and 20% faster convergence with up to 10 times less memory consumption compared to SOTA RL-based approaches.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Guided Policy Optimization</title>
<link>https://arxiv.org/abs/2507.18059</link>
<guid>https://arxiv.org/abs/2507.18059</guid>
<content:encoded><![CDATA[
arXiv:2507.18059v1 Announce Type: new 
Abstract: Due to practical constraints such as partial observability and limited communication, Centralized Training with Decentralized Execution (CTDE) has become the dominant paradigm in cooperative Multi-Agent Reinforcement Learning (MARL). However, existing CTDE methods often underutilize centralized training or lack theoretical guarantees. We propose Multi-Agent Guided Policy Optimization (MAGPO), a novel framework that better leverages centralized training by integrating centralized guidance with decentralized execution. MAGPO uses an auto-regressive joint policy for scalable, coordinated exploration and explicitly aligns it with decentralized policies to ensure deployability under partial observability. We provide theoretical guarantees of monotonic policy improvement and empirically evaluate MAGPO on 43 tasks across 6 diverse environments. Results show that MAGPO consistently outperforms strong CTDE baselines and matches or surpasses fully centralized approaches, offering a principled and practical solution for decentralized multi-agent learning. Our code and experimental data can be found in https://github.com/liyheng/MAGPO.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TELEVAL: A Dynamic Benchmark Designed for Spoken Language Models in Chinese Interactive Scenarios</title>
<link>https://arxiv.org/abs/2507.18061</link>
<guid>https://arxiv.org/abs/2507.18061</guid>
<content:encoded><![CDATA[
arXiv:2507.18061v1 Announce Type: new 
Abstract: Spoken language models (SLMs) have seen rapid progress in recent years, along with the development of numerous benchmarks for evaluating their performance. However, most existing benchmarks primarily focus on evaluating whether SLMs can perform complex tasks comparable to those tackled by large language models (LLMs), often failing to align with how users naturally interact in real-world conversational scenarios. In this paper, we propose TELEVAL, a dynamic benchmark specifically designed to evaluate SLMs' effectiveness as conversational agents in realistic Chinese interactive settings. TELEVAL defines three evaluation dimensions: Explicit Semantics, Paralinguistic and Implicit Semantics, and System Abilities. It adopts a dialogue format consistent with real-world usage and evaluates text and audio outputs separately. TELEVAL particularly focuses on the model's ability to extract implicit cues from user speech and respond appropriately without additional instructions. Our experiments demonstrate that despite recent progress, existing SLMs still have considerable room for improvement in natural conversational tasks. We hope that TELEVAL can serve as a user-centered evaluation framework that directly reflects the user experience and contributes to the development of more capable dialogue-oriented SLMs.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Microgrid Resilience Enhancement via Mobile Power Sources and Repair Crews: A Multi-Agent Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2507.18095</link>
<guid>https://arxiv.org/abs/2507.18095</guid>
<content:encoded><![CDATA[
arXiv:2507.18095v1 Announce Type: new 
Abstract: Mobile power sources (MPSs) have been gradually deployed in microgrids as critical resources to coordinate with repair crews (RCs) towards resilience enhancement owing to their flexibility and mobility in handling the complex coupled power-transport systems. However, previous work solves the coordinated dispatch problem of MPSs and RCs in a centralized manner with the assumption that the communication network is still fully functioning after the event. However, there is growing evidence that certain extreme events will damage or degrade communication infrastructure, which makes centralized decision making impractical. To fill this gap, this paper formulates the resilience-driven dispatch problem of MPSs and RCs in a decentralized framework. To solve this problem, a hierarchical multi-agent reinforcement learning method featuring a two-level framework is proposed, where the high-level action is used to switch decision-making between power and transport networks, and the low-level action constructed via a hybrid policy is used to compute continuous scheduling and discrete routing decisions in power and transport networks, respectively. The proposed method also uses an embedded function encapsulating system dynamics to enhance learning stability and scalability. Case studies based on IEEE 33-bus and 69-bus power networks are conducted to validate the effectiveness of the proposed method in load restoration.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Two-Stage TSO-DSO Services Provision Framework for Electric Vehicle Coordination</title>
<link>https://arxiv.org/abs/2507.18110</link>
<guid>https://arxiv.org/abs/2507.18110</guid>
<content:encoded><![CDATA[
arXiv:2507.18110v1 Announce Type: new 
Abstract: High renewable penetration has been witnessed in power systems, resulting in reduced system inertia and increasing requirements for frequency response services. Electric vehicles (EVs), owing to their vehicle-to-grid (V2G) capabilities, can provide cost-effective frequency services for transmission system operators (TSOs). However, EVs that are inherently connected to distribution networks may pose voltage security issues for distribution system operators (DSOs) when supporting TSO frequency. To coordinate both TSO frequency and DSO voltage, this paper proposes a two-stage service provision framework for multi-EVs. At stage one, EVs participate in day-ahead TSO-DSO interactions for frequency reserve schedules; at stage two, EVs make real-time dispatching behaviors in distribution networks for reserve delivery while supporting DSO voltage. Considering the potentially large EV number and environment complexity, a decentralized operation paradigm is introduced for real-time EV dispatches at stage two, while a communication-efficient reinforcement learning (RL) algorithm is proposed to reduce the communication overhead during large-scale multi-agent RL training without compromising policy performance. Case studies are carried out on a 6-bus transmission and 33-bus distribution network as well as a 69-bus distribution network to evaluate the effectiveness and scalability of the proposed method in enabling EVs for frequency service and voltage support.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Percentile-Based Deep Reinforcement Learning and Reward Based Personalization For Delay Aware RAN Slicing in O-RAN</title>
<link>https://arxiv.org/abs/2507.18111</link>
<guid>https://arxiv.org/abs/2507.18111</guid>
<content:encoded><![CDATA[
arXiv:2507.18111v1 Announce Type: new 
Abstract: In this paper, we tackle the challenge of radio access network (RAN) slicing within an open RAN (O-RAN) architecture. Our focus centers on a network that includes multiple mobile virtual network operators (MVNOs) competing for physical resource blocks (PRBs) with the goal of meeting probabilistic delay upper bound constraints for their clients while minimizing PRB utilization. Initially, we derive a reward function based on the law of large numbers (LLN), then implement practical modifications to adapt it for real-world experimental scenarios. We then propose our solution, the Percentile-based Delay-Aware Deep Reinforcement Learning (PDA-DRL), which demonstrates its superiority over several baselines, including DRL models optimized for average delay constraints, by achieving a 38\% reduction in resultant average delay. Furthermore, we delve into the issue of model weight sharing among multiple MVNOs to develop a robust personalized model. We introduce a reward-based personalization method where each agent prioritizes other agents' model weights based on their performance. This technique surpasses traditional aggregation methods, such as federated averaging, and strategies reliant on traffic patterns and model weight distance similarities.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Policy Disruption in Reinforcement Learning:Adversarial Attack with Large Language Models and Critical State Identification</title>
<link>https://arxiv.org/abs/2507.18113</link>
<guid>https://arxiv.org/abs/2507.18113</guid>
<content:encoded><![CDATA[
arXiv:2507.18113v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has achieved remarkable success in fields like robotics and autonomous driving, but adversarial attacks designed to mislead RL systems remain challenging. Existing approaches often rely on modifying the environment or policy, limiting their practicality. This paper proposes an adversarial attack method in which existing agents in the environment guide the target policy to output suboptimal actions without altering the environment. We propose a reward iteration optimization framework that leverages large language models (LLMs) to generate adversarial rewards explicitly tailored to the vulnerabilities of the target agent, thereby enhancing the effectiveness of inducing the target agent toward suboptimal decision-making. Additionally, a critical state identification algorithm is designed to pinpoint the target agent's most vulnerable states, where suboptimal behavior from the victim leads to significant degradation in overall performance. Experimental results in diverse environments demonstrate the superiority of our method over existing approaches.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic AI framework for End-to-End Medical Data Inference</title>
<link>https://arxiv.org/abs/2507.18115</link>
<guid>https://arxiv.org/abs/2507.18115</guid>
<content:encoded><![CDATA[
arXiv:2507.18115v1 Announce Type: new 
Abstract: Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Neuromorphic Computing for Embodied Intelligence in Autonomous Systems: Current Trends, Challenges, and Future Directions</title>
<link>https://arxiv.org/abs/2507.18139</link>
<guid>https://arxiv.org/abs/2507.18139</guid>
<content:encoded><![CDATA[
arXiv:2507.18139v1 Announce Type: new 
Abstract: The growing need for intelligent, adaptive, and energy-efficient autonomous systems across fields such as robotics, mobile agents (e.g., UAVs), and self-driving vehicles is driving interest in neuromorphic computing. By drawing inspiration from biological neural systems, neuromorphic approaches offer promising pathways to enhance the perception, decision-making, and responsiveness of autonomous platforms. This paper surveys recent progress in neuromorphic algorithms, specialized hardware, and cross-layer optimization strategies, with a focus on their deployment in real-world autonomous scenarios. Special attention is given to event-based dynamic vision sensors and their role in enabling fast, efficient perception. The discussion highlights new methods that improve energy efficiency, robustness, adaptability, and reliability through the integration of spiking neural networks into autonomous system architectures. We integrate perspectives from machine learning, robotics, neuroscience, and neuromorphic engineering to offer a comprehensive view of the state of the field. Finally, emerging trends and open challenges are explored, particularly in the areas of real-time decision-making, continual learning, and the development of secure, resilient autonomous systems.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ProactiveVA: Proactive Visual Analytics with LLM-Based UI Agent</title>
<link>https://arxiv.org/abs/2507.18165</link>
<guid>https://arxiv.org/abs/2507.18165</guid>
<content:encoded><![CDATA[
arXiv:2507.18165v1 Announce Type: new 
Abstract: Visual analytics (VA) is typically applied to complex data, thus requiring complex tools. While visual analytics empowers analysts in data analysis, analysts may get lost in the complexity occasionally. This highlights the need for intelligent assistance mechanisms. However, even the latest LLM-assisted VA systems only provide help when explicitly requested by the user, making them insufficiently intelligent to offer suggestions when analysts need them the most. We propose a ProactiveVA framework in which LLM-powered UI agent monitors user interactions and delivers context-aware assistance proactively. To design effective proactive assistance, we first conducted a formative study analyzing help-seeking behaviors in user interaction logs, identifying when users need proactive help, what assistance they require, and how the agent should intervene. Based on this analysis, we distilled key design requirements in terms of intent recognition, solution generation, interpretability and controllability. Guided by these requirements, we develop a three-stage UI agent pipeline including perception, reasoning, and acting. The agent autonomously perceives users' needs from VA interaction logs, providing tailored suggestions and intuitive guidance through interactive exploration of the system. We implemented the framework in two representative types of VA systems, demonstrating its generalizability, and evaluated the effectiveness through an algorithm evaluation, case and expert study and a user study. We also discuss current design trade-offs of proactive VA and areas for further exploration.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assemble Your Crew: Automatic Multi-agent Communication Topology Design via Autoregressive Graph Generation</title>
<link>https://arxiv.org/abs/2507.18224</link>
<guid>https://arxiv.org/abs/2507.18224</guid>
<content:encoded><![CDATA[
arXiv:2507.18224v1 Announce Type: new 
Abstract: Multi-agent systems (MAS) based on large language models (LLMs) have emerged as a powerful solution for dealing with complex problems across diverse domains. The effectiveness of MAS is critically dependent on its collaboration topology, which has become a focal point for automated design research. However, existing approaches are fundamentally constrained by their reliance on a template graph modification paradigm with a predefined set of agents and hard-coded interaction structures, significantly limiting their adaptability to task-specific requirements. To address these limitations, we reframe MAS design as a conditional autoregressive graph generation task, where both the system composition and structure are designed jointly. We propose ARG-Designer, a novel autoregressive model that operationalizes this paradigm by constructing the collaboration graph from scratch. Conditioned on a natural language task query, ARG-Designer sequentially and dynamically determines the required number of agents, selects their appropriate roles from an extensible pool, and establishes the optimal communication links between them. This generative approach creates a customized topology in a flexible and extensible manner, precisely tailored to the unique demands of different tasks. Extensive experiments across six diverse benchmarks demonstrate that ARG-Designer not only achieves state-of-the-art performance but also enjoys significantly greater token efficiency and enhanced extensibility. The source code of ARG-Designer is available at https://github.com/Shiy-Li/ARG-Designer.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Pareto-Optimal and Fair Allocations with Personalized Bi-Valued Utilities</title>
<link>https://arxiv.org/abs/2507.18251</link>
<guid>https://arxiv.org/abs/2507.18251</guid>
<content:encoded><![CDATA[
arXiv:2507.18251v1 Announce Type: new 
Abstract: We study the fair division problem of allocating $m$ indivisible goods to $n$ agents with additive personalized bi-valued utilities. Specifically, each agent $i$ assigns one of two positive values $a_i > b_i > 0$ to each good, indicating that agent $i$'s valuation of any good is either $a_i$ or $b_i$. For convenience, we denote the value ratio of agent $i$ as $r_i = a_i / b_i$.
  We give a characterization to all the Pareto-optimal allocations. Our characterization implies a polynomial-time algorithm to decide if a given allocation is Pareto-optimal in the case each $r_i$ is an integer. For the general case (where $r_i$ may be fractional), we show that this decision problem is coNP-complete. Our result complements the existing results: this decision problem is coNP-complete for tri-valued utilities (where each agent's value for each good belongs to $\{a,b,c\}$ for some prescribed $a>b>c\geq0$), and this decision problem belongs to P for bi-valued utilities (where $r_i$ in our model is the same for each agent).
  We further show that an EFX allocation always exists and can be computed in polynomial time under the personalized bi-valued utilities setting, which extends the previous result on bi-valued utilities. We propose the open problem of whether an EFX and Pareto-optimal allocation always exists (and can be computed in polynomial time).
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Study on Embodied Artificial Intelligence Robot (EAIR) Software Bugs</title>
<link>https://arxiv.org/abs/2507.18267</link>
<guid>https://arxiv.org/abs/2507.18267</guid>
<content:encoded><![CDATA[
arXiv:2507.18267v1 Announce Type: new 
Abstract: Embodied Artificial Intelligence Robots (EAIR) is an emerging and rapidly evolving technological domain. Ensuring their program correctness is fundamental to their successful deployment. However, a general and in-depth understanding of EAIR system bugs remains lacking, which hinders the development of practices and techniques to tackle EAIR system bugs.
  To bridge this gap, we conducted the first systematic study of 885 EAIR system bugs collected from 80 EAIR system projects to investigate their symptoms, underlying causes, and module distribution. Our analysis takes considerable effort, which classifies these bugs into 18 underlying causes, 15 distinct symptoms, and identifies 13 affected modules. It reveals several new interesting findings and implications which help shed light on future research on tackling or repairing EAIR system bugs. First, among the 15 identified symptoms, our findings highlight 8 symptoms specific to EAIR systems, which is characterized by severe functional failures and potential physical hazards. Second, within the 18 underlying causes, we define 8 EAIR-specific causes, the majority of which stem from the intricate issues of AI- agent reasoning and decision making. Finally, to facilitate precise and efficient bug prediction, detection, and repair, we constructed a mapping between underlying causes and the modules in which they most frequently occur, which enables researchers to focus diagnostic efforts on the modules most susceptible to specific bug types.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Designing Value-Aligned Traffic Agents through Conflict Sensitivity</title>
<link>https://arxiv.org/abs/2507.18284</link>
<guid>https://arxiv.org/abs/2507.18284</guid>
<content:encoded><![CDATA[
arXiv:2507.18284v1 Announce Type: new 
Abstract: Autonomous traffic agents (ATAs) are expected to act in ways tat are not only safe, but also aligned with stakeholder values across legal, social, and moral dimensions. In this paper, we adopt an established formal model of conflict from epistemic game theory to support the development of such agents. We focus on value conflicts-situations in which agents face competing goals rooted in value-laden situations and show how conflict analysis can inform key phases of the design process. This includes value elicitation, capability specification, explanation, and adaptive system refinement. We elaborate and apply the concept of Value-Aligned Operational Design Domains (VODDs) to structure autonomy in accordance with contextual value priorities. Our approach shifts the emphasis from solving moral dilemmas at runtime to anticipating and structuring value-sensitive behaviour during development.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Talking to...uh...um...Machines: The Impact of Disfluent Speech Agents on Partner Models and Perspective Taking</title>
<link>https://arxiv.org/abs/2507.18315</link>
<guid>https://arxiv.org/abs/2507.18315</guid>
<content:encoded><![CDATA[
arXiv:2507.18315v1 Announce Type: new 
Abstract: Speech disfluencies play a role in perspective-taking and audience design in human-human communication (HHC), but little is known about their impact in human-machine dialogue (HMD). In an online Namer-Matcher task, sixty-one participants interacted with a speech agent using either fluent or disfluent speech. Participants completed a partner-modelling questionnaire (PMQ) both before and after the task. Post-interaction evaluations indicated that participants perceived the disfluent agent as more competent, despite no significant differences in pre-task ratings. However, no notable differences were observed in assessments of conversational flexibility or human-likeness. Our findings also reveal evidence of egocentric and allocentric language production when participants interact with speech agents. Interaction with disfluent speech agents appears to increase egocentric communication in comparison to fluent agents. Although the wide credibility intervals mean this effect is not clear-cut. We discuss potential interpretations of this finding, focusing on how disfluencies may impact partner models and language production in HMD.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Remembering the Markov Property in Cooperative MARL</title>
<link>https://arxiv.org/abs/2507.18333</link>
<guid>https://arxiv.org/abs/2507.18333</guid>
<content:encoded><![CDATA[
arXiv:2507.18333v1 Announce Type: new 
Abstract: Cooperative multi-agent reinforcement learning (MARL) is typically formalised as a Decentralised Partially Observable Markov Decision Process (Dec-POMDP), where agents must reason about the environment and other agents' behaviour. In practice, current model-free MARL algorithms use simple recurrent function approximators to address the challenge of reasoning about others using partial information. In this position paper, we argue that the empirical success of these methods is not due to effective Markov signal recovery, but rather to learning simple conventions that bypass environment observations and memory. Through a targeted case study, we show that co-adapting agents can learn brittle conventions, which then fail when partnered with non-adaptive agents. Crucially, the same models can learn grounded policies when the task design necessitates it, revealing that the issue is not a fundamental limitation of the learning models but a failure of the benchmark design. Our analysis also suggests that modern MARL environments may not adequately test the core assumptions of Dec-POMDPs. We therefore advocate for new cooperative environments built upon two core principles: (1) behaviours grounded in observations and (2) memory-based reasoning about other agents, ensuring success requires genuine skill rather than fragile, co-adapted agreements.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EgoExoBench: A Benchmark for First- and Third-person View Video Understanding in MLLMs</title>
<link>https://arxiv.org/abs/2507.18342</link>
<guid>https://arxiv.org/abs/2507.18342</guid>
<content:encoded><![CDATA[
arXiv:2507.18342v1 Announce Type: new 
Abstract: Transferring and integrating knowledge across first-person (egocentric) and third-person (exocentric) viewpoints is intrinsic to human intelligence, enabling humans to learn from others and convey insights from their own experiences. Despite rapid progress in multimodal large language models (MLLMs), their ability to perform such cross-view reasoning remains unexplored. To address this, we introduce EgoExoBench, the first benchmark for egocentric-exocentric video understanding and reasoning. Built from publicly available datasets, EgoExoBench comprises over 7,300 question-answer pairs spanning eleven sub-tasks organized into three core challenges: semantic alignment, viewpoint association, and temporal reasoning. We evaluate 13 state-of-the-art MLLMs and find that while these models excel on single-view tasks, they struggle to align semantics across perspectives, accurately associate views, and infer temporal dynamics in the ego-exo context. We hope EgoExoBench can serve as a valuable resource for research on embodied agents and intelligent assistants seeking human-like cross-view intelligence.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Effective Human-in-the-Loop Assistive AI Agents</title>
<link>https://arxiv.org/abs/2507.18374</link>
<guid>https://arxiv.org/abs/2507.18374</guid>
<content:encoded><![CDATA[
arXiv:2507.18374v1 Announce Type: new 
Abstract: Effective human-AI collaboration for physical task completion has significant potential in both everyday activities and professional domains. AI agents equipped with informative guidance can enhance human performance, but evaluating such collaboration remains challenging due to the complexity of human-in-the-loop interactions. In this work, we introduce an evaluation framework and a multimodal dataset of human-AI interactions designed to assess how AI guidance affects procedural task performance, error reduction and learning outcomes. Besides, we develop an augmented reality (AR)-equipped AI agent that provides interactive guidance in real-world tasks, from cooking to battlefield medicine. Through human studies, we share empirical insights into AI-assisted human performance and demonstrate that AI-assisted collaboration improves task completion.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delving into Mapping Uncertainty for Mapless Trajectory Prediction</title>
<link>https://arxiv.org/abs/2507.18498</link>
<guid>https://arxiv.org/abs/2507.18498</guid>
<content:encoded><![CDATA[
arXiv:2507.18498v1 Announce Type: new 
Abstract: Recent advances in autonomous driving are moving towards mapless approaches, where High-Definition (HD) maps are generated online directly from sensor data, reducing the need for expensive labeling and maintenance. However, the reliability of these online-generated maps remains uncertain. While incorporating map uncertainty into downstream trajectory prediction tasks has shown potential for performance improvements, current strategies provide limited insights into the specific scenarios where this uncertainty is beneficial. In this work, we first analyze the driving scenarios in which mapping uncertainty has the greatest positive impact on trajectory prediction and identify a critical, previously overlooked factor: the agent's kinematic state. Building on these insights, we propose a novel Proprioceptive Scenario Gating that adaptively integrates map uncertainty into trajectory prediction based on forecasts of the ego vehicle's future kinematics. This lightweight, self-supervised approach enhances the synergy between online mapping and trajectory prediction, providing interpretability around where uncertainty is advantageous and outperforming previous integration methods. Additionally, we introduce a Covariance-based Map Uncertainty approach that better aligns with map geometry, further improving trajectory prediction. Extensive ablation studies confirm the effectiveness of our approach, achieving up to 23.6% improvement in mapless trajectory prediction performance over the state-of-the-art method using the real-world nuScenes driving dataset. Our code, data, and models are publicly available at https://github.com/Ethan-Zheng136/Map-Uncertainty-for-Trajectory-Prediction.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PosterMate: Audience-driven Collaborative Persona Agents for Poster Design</title>
<link>https://arxiv.org/abs/2507.18572</link>
<guid>https://arxiv.org/abs/2507.18572</guid>
<content:encoded><![CDATA[
arXiv:2507.18572v1 Announce Type: new 
Abstract: Poster designing can benefit from synchronous feedback from target audiences. However, gathering audiences with diverse perspectives and reconciling them on design edits can be challenging. Recent generative AI models present opportunities to simulate human-like interactions, but it is unclear how they may be used for feedback processes in design. We introduce PosterMate, a poster design assistant that facilitates collaboration by creating audience-driven persona agents constructed from marketing documents. PosterMate gathers feedback from each persona agent regarding poster components, and stimulates discussion with the help of a moderator to reach a conclusion. These agreed-upon edits can then be directly integrated into the poster design. Through our user study (N=12), we identified the potential of PosterMate to capture overlooked viewpoints, while serving as an effective prototyping tool. Additionally, our controlled online evaluation (N=100) revealed that the feedback from an individual persona agent is appropriate given its persona identity, and the discussion effectively synthesizes the different persona agents' perspectives.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Linear Memory SE(2) Invariant Attention</title>
<link>https://arxiv.org/abs/2507.18597</link>
<guid>https://arxiv.org/abs/2507.18597</guid>
<content:encoded><![CDATA[
arXiv:2507.18597v1 Announce Type: new 
Abstract: Processing spatial data is a key component in many learning tasks for autonomous driving such as motion forecasting, multi-agent simulation, and planning. Prior works have demonstrated the value in using SE(2) invariant network architectures that consider only the relative poses between objects (e.g. other agents, scene features such as traffic lanes). However, these methods compute the relative poses for all pairs of objects explicitly, requiring quadratic memory. In this work, we propose a mechanism for SE(2) invariant scaled dot-product attention that requires linear memory relative to the number of objects in the scene. Our SE(2) invariant transformer architecture enjoys the same scaling properties that have benefited large language models in recent years. We demonstrate experimentally that our approach is practical to implement and improves performance compared to comparable non-invariant architectures.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Explainable Mapper: Charting LLM Embedding Spaces Using Perturbation-Based Explanation and Verification Agents</title>
<link>https://arxiv.org/abs/2507.18607</link>
<guid>https://arxiv.org/abs/2507.18607</guid>
<content:encoded><![CDATA[
arXiv:2507.18607v1 Announce Type: new 
Abstract: Large language models (LLMs) produce high-dimensional embeddings that capture rich semantic and syntactic relationships between words, sentences, and concepts. Investigating the topological structures of LLM embedding spaces via mapper graphs enables us to understand their underlying structures. Specifically, a mapper graph summarizes the topological structure of the embedding space, where each node represents a topological neighborhood (containing a cluster of embeddings), and an edge connects two nodes if their corresponding neighborhoods overlap. However, manually exploring these embedding spaces to uncover encoded linguistic properties requires considerable human effort. To address this challenge, we introduce a framework for semi-automatic annotation of these embedding properties. To organize the exploration process, we first define a taxonomy of explorable elements within a mapper graph such as nodes, edges, paths, components, and trajectories. The annotation of these elements is executed through two types of customizable LLM-based agents that employ perturbation techniques for scalable and automated analysis. These agents help to explore and explain the characteristics of mapper elements and verify the robustness of the generated explanations. We instantiate the framework within a visual analytics workspace and demonstrate its effectiveness through case studies. In particular, we replicate findings from prior research on BERT's embedding properties across various layers of its architecture and provide further observations into the linguistic properties of topological neighborhoods.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Moving Out: Physically-grounded Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2507.18623</link>
<guid>https://arxiv.org/abs/2507.18623</guid>
<content:encoded><![CDATA[
arXiv:2507.18623v1 Announce Type: new 
Abstract: The ability to adapt to physical actions and constraints in an environment is crucial for embodied agents (e.g., robots) to effectively collaborate with humans. Such physically grounded human-AI collaboration must account for the increased complexity of the continuous state-action space and constrained dynamics caused by physical constraints. In this paper, we introduce \textit{Moving Out}, a new human-AI collaboration benchmark that resembles a wide range of collaboration modes affected by physical attributes and constraints, such as moving heavy items together and maintaining consistent actions to move a big item around a corner. Using Moving Out, we designed two tasks and collected human-human interaction data to evaluate models' abilities to adapt to diverse human behaviors and unseen physical attributes. To address the challenges in physical environments, we propose a novel method, BASS (Behavior Augmentation, Simulation, and Selection), to enhance the diversity of agents and their understanding of the outcome of actions. Our experiments show that BASS outperforms state-of-the-art models in AI-AI and human-AI collaboration. The project page is available at \href{https://live-robotics-uva.github.io/movingout_ai/}{https://live-robotics-uva.github.io/movingout\_ai/}.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Reward-Driven Reinforcement Learning for Efficient Quantum Circuit Synthesis</title>
<link>https://arxiv.org/abs/2507.16641</link>
<guid>https://arxiv.org/abs/2507.16641</guid>
<content:encoded><![CDATA[
arXiv:2507.16641v1 Announce Type: cross 
Abstract: A reinforcement learning (RL) framework is introduced for the efficient synthesis of quantum circuits that generate specified target quantum states from a fixed initial state, addressing a central challenge in both the NISQ era and future fault-tolerant quantum computing. The approach utilizes tabular Q-learning, based on action sequences, within a discretized quantum state space, to effectively manage the exponential growth of the space dimension. The framework introduces a hybrid reward mechanism, combining a static, domain-informed reward that guides the agent toward the target state with customizable dynamic penalties that discourage inefficient circuit structures such as gate congestion and redundant state revisits. By leveraging sparse matrix representations and state-space discretization, the method enables scalable navigation of high-dimensional environments while minimizing computational overhead. Benchmarking on graph-state preparation tasks for up to seven qubits, we demonstrate that the algorithm consistently discovers minimal-depth circuits with optimized gate counts. Moreover, extending the framework to a universal gate set for arbitrary quantum states, it still produces minimal depth circuits, highlighting the algorithm's robustness and adaptability. The results confirm that this RL-driven approach efficiently explores the complex quantum state space and synthesizes near-optimal quantum circuits, providing a resource-efficient foundation for quantum circuit optimization.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Individual Learning to Market Equilibrium: Correcting Structural and Parametric Biases in RL Simulations of Economic Models</title>
<link>https://arxiv.org/abs/2507.18229</link>
<guid>https://arxiv.org/abs/2507.18229</guid>
<content:encoded><![CDATA[
arXiv:2507.18229v1 Announce Type: cross 
Abstract: The application of Reinforcement Learning (RL) to economic modeling reveals a fundamental conflict between the assumptions of equilibrium theory and the emergent behavior of learning agents. While canonical economic models assume atomistic agents act as `takers' of aggregate market conditions, a naive single-agent RL simulation incentivizes the agent to become a `manipulator' of its environment. This paper first demonstrates this discrepancy within a search-and-matching model with concave production, showing that a standard RL agent learns a non-equilibrium, monopsonistic policy. Additionally, we identify a parametric bias arising from the mismatch between economic discounting and RL's treatment of intertemporal costs. To address both issues, we propose a calibrated Mean-Field Reinforcement Learning framework that embeds a representative agent in a fixed macroeconomic field and adjusts the cost function to reflect economic opportunity costs. Our iterative algorithm converges to a self-consistent fixed point where the agent's policy aligns with the competitive equilibrium. This approach provides a tractable and theoretically sound methodology for modeling learning agents in economic systems within the broader domain of computational social science.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HARLF: Hierarchical Reinforcement Learning and Lightweight LLM-Driven Sentiment Integration for Financial Portfolio Optimization</title>
<link>https://arxiv.org/abs/2507.18560</link>
<guid>https://arxiv.org/abs/2507.18560</guid>
<content:encoded><![CDATA[
arXiv:2507.18560v1 Announce Type: cross 
Abstract: This paper presents a novel hierarchical framework for portfolio optimization, integrating lightweight Large Language Models (LLMs) with Deep Reinforcement Learning (DRL) to combine sentiment signals from financial news with traditional market indicators. Our three-tier architecture employs base RL agents to process hybrid data, meta-agents to aggregate their decisions, and a super-agent to merge decisions based on market data and sentiment analysis. Evaluated on data from 2018 to 2024, after training on 2000-2017, the framework achieves a 26% annualized return and a Sharpe ratio of 1.2, outperforming equal-weighted and S&amp;P 500 benchmarks. Key contributions include scalable cross-modal integration, a hierarchical RL structure for enhanced stability, and open-source reproducibility.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Select2Drive: Pragmatic Communications for Real-Time Collaborative Autonomous Driving</title>
<link>https://arxiv.org/abs/2501.12040</link>
<guid>https://arxiv.org/abs/2501.12040</guid>
<content:encoded><![CDATA[
arXiv:2501.12040v2 Announce Type: replace 
Abstract: Vehicle-to-everything communications-assisted autonomous driving has witnessed remarkable advancements in recent years, with pragmatic communications (PragComm) emerging as a promising paradigm for real-time collaboration among vehicles and other agents. Simultaneously, extensive research has explored the interplay between collaborative perception and decision-making in end-to-end driving frameworks. In this work, we revisit the collaborative driving problem and propose the Select2Drive framework to optimize the utilization of limited computational and communication resources. Particularly, to mitigate cumulative latency in perception and decision-making, Select2Drive introduces distributed predictive perception by formulating an active prediction paradigm and simplifying high-dimensional semantic feature prediction into a computation cost-efficient, motion-aware reconstruction. Given the ``less is more" principle that an over-broadened perceptual horizon possibly confuses the decision module rather than contributing to it, Select2Drive utilizes area-of-importance-based PragComm to prioritize the communications of critical regions, thus boosting both communication efficiency and decision-making efficacy. Empirical evaluations on the V2Xverse and real-world DAIR-V2X demonstrate that Select2Drive achieves a $2.60$\% and $1.99$\% improvement in offline perception tasks under limited bandwidth (resp., pose error conditions). Moreover, it delivers at most $8.35$\% and $2.65$\% enhancement in closed-loop driving scores and route completion rates, particularly in scenarios characterized by dense traffic and high-speed dynamics.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Housing Market</title>
<link>https://arxiv.org/abs/2501.15916</link>
<guid>https://arxiv.org/abs/2501.15916</guid>
<content:encoded><![CDATA[
arXiv:2501.15916v2 Announce Type: replace 
Abstract: This paper studies an online variant of the celebrated housing market problem, where each agent has a single house and seeks to exchange it for another based on her preferences. In this online setting, agents may arrive and depart at any time, meaning that not all agents are present on the housing market simultaneously. I extend the well known serial dictatorship and Gale s top trading cycle mechanisms to this online scenario, aiming to retain their desirable properties such as Pareto efficiency, individual rationality, and strategy proofness. These extensions also seek to prevent agents from strategically delaying their arrival or advancing their departure. I demonstrate that achieving all of these properties simultaneously is impossible in the online context, and I present several variants that achieve different subsets of these properties.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Differentiated Reward Method for Reinforcement Learning based Multi-Vehicle Cooperative Decision-Making Algorithms</title>
<link>https://arxiv.org/abs/2502.00352</link>
<guid>https://arxiv.org/abs/2502.00352</guid>
<content:encoded><![CDATA[
arXiv:2502.00352v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) shows great potential for optimizing multi-vehicle cooperative driving strategies through the state-action-reward feedback loop, but it still faces challenges such as low sample efficiency. This paper proposes a differentiated reward method based on steady-state transition systems, which incorporates state transition gradient information into the reward design by analyzing traffic flow characteristics, aiming to optimize action selection and policy learning in multi-vehicle cooperative decision-making. The performance of the proposed method is validated in RL algorithms such as MAPPO, MADQN, and QMIX under varying autonomous vehicle penetration. The results show that the differentiated reward method significantly accelerates training convergence and outperforms centering reward and others in terms of traffic efficiency, safety, and action rationality. Additionally, the method demonstrates strong scalability and environmental adaptability, providing a novel approach for multi-agent cooperative decision-making in complex traffic scenarios.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problems with Reasoning LLM</title>
<link>https://arxiv.org/abs/2503.10009</link>
<guid>https://arxiv.org/abs/2503.10009</guid>
<content:encoded><![CDATA[
arXiv:2503.10009v2 Announce Type: replace 
Abstract: With the rise of artificial intelligence (AI), applying large language models (LLMs) to Operations Research (OR) problem-solving has attracted increasing attention. Most existing approaches attempt to improve OR problem-solving through prompt engineering or fine-tuning strategies for LLMs. However, these methods are fundamentally constrained by the limited capabilities of non-reasoning LLMs. To overcome these limitations, we propose OR-LLM-Agent, an AI agent built on reasoning LLMs for automated OR problem solving. The agent decomposes the task into three sequential stages: mathematical modeling, code generation, and debugging. Each task is handled by a dedicated sub-agent, which enables more targeted reasoning. We also construct BWOR, a high-quality dataset for evaluating LLM performance on OR tasks. Our analysis shows that existing benchmarks such as NL4OPT, MAMO, and IndustryOR suffer from certain issues, making them less suitable for reliably evaluating LLM performance. In contrast, BWOR provides a more consistent and discriminative assessment of model capabilities. Experimental results demonstrate that OR-LLM-Agent outperforms advanced methods, including GPT-o3, Gemini 2.5 Pro, and ORLM, by at least 7% in accuracy. These results demonstrate the effectiveness of task decomposition for OR problem solving.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IPCGRL: Language-Instructed Reinforcement Learning for Procedural Level Generation</title>
<link>https://arxiv.org/abs/2503.12358</link>
<guid>https://arxiv.org/abs/2503.12358</guid>
<content:encoded><![CDATA[
arXiv:2503.12358v4 Announce Type: replace 
Abstract: Recent research has highlighted the significance of natural language in enhancing the controllability of generative models. While various efforts have been made to leverage natural language for content generation, research on deep reinforcement learning (DRL) agents utilizing text-based instructions for procedural content generation remains limited. In this paper, we propose IPCGRL, an instruction-based procedural content generation method via reinforcement learning, which incorporates a sentence embedding model. IPCGRL fine-tunes task-specific embedding representations to effectively compress game-level conditions. We evaluate IPCGRL in a two-dimensional level generation task and compare its performance with a general-purpose embedding method. The results indicate that IPCGRL achieves up to a 21.4% improvement in controllability and a 17.2% improvement in generalizability for unseen instructions. Furthermore, the proposed method extends the modality of conditional input, enabling a more flexible and expressive interaction framework for procedural content generation.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework</title>
<link>https://arxiv.org/abs/2504.14928</link>
<guid>https://arxiv.org/abs/2504.14928</guid>
<content:encoded><![CDATA[
arXiv:2504.14928v2 Announce Type: replace 
Abstract: Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Neurodivergent Influenceability as a Contingent Solution to the AI Alignment Problem</title>
<link>https://arxiv.org/abs/2505.02581</link>
<guid>https://arxiv.org/abs/2505.02581</guid>
<content:encoded><![CDATA[
arXiv:2505.02581v4 Announce Type: replace 
Abstract: The AI alignment problem, which focusses on ensuring that artificial intelligence (AI), including AGI and ASI, systems act according to human values, presents profound challenges. With the progression from narrow AI to Artificial General Intelligence (AGI) and Superintelligence, fears about control and existential risk have escalated. Here, we investigate whether embracing inevitable AI misalignment can be a contingent strategy to foster a dynamic ecosystem of competing agents as a viable path to steer them in more human-aligned trends and mitigate risks. We explore how misalignment may serve and should be promoted as a counterbalancing mechanism to team up with whichever agents are most aligned to human interests, ensuring that no single system dominates destructively. The main premise of our contribution is that misalignment is inevitable because full AI-human alignment is a mathematical impossibility from Turing-complete systems, which we also offer as a proof in this contribution, a feature then inherited to AGI and ASI systems. We introduce a change-of-opinion attack test based on perturbation and intervention analysis to study how humans and agents may change or neutralise friendly and unfriendly AIs through cooperation and competition. We show that open models are more diverse and that most likely guardrails implemented in proprietary models are successful at controlling some of the agents' range of behaviour with positive and negative consequences while closed systems are more steerable and can also be used against proprietary AI systems. We also show that human and AI intervention has different effects hence suggesting multiple strategies.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beamforming and Resource Allocation for Delay Minimization in RIS-Assisted OFDM Systems</title>
<link>https://arxiv.org/abs/2506.03586</link>
<guid>https://arxiv.org/abs/2506.03586</guid>
<content:encoded><![CDATA[
arXiv:2506.03586v4 Announce Type: replace 
Abstract: This paper investigates a joint beamforming and resource allocation problem in downlink reconfigurable intelligent surface (RIS)-assisted orthogonal frequency division multiplexing (OFDM) systems to minimize the average delay, where data packets for each user arrive at the base station (BS) stochastically. The sequential optimization problem is inherently a Markov decision process (MDP), thus falling within the remit of reinforcement learning. To effectively handle the mixed action space and reduce the state space dimensionality, a hybrid deep reinforcement learning (DRL) approach is proposed. Specifically, proximal policy optimization (PPO)-Theta is employed to optimize the RIS phase shift design, while PPO-N is responsible for subcarrier allocation decisions. The active beamforming at the BS is then derived from the jointly optimized RIS phase shifts and subcarrier allocation decisions. To further mitigate the curse of dimensionality associated with subcarrier allocation, a multi-agent strategy is introduced to optimize the subcarrier allocation indicators more efficiently. Moreover, to achieve more adaptive resource allocation and accurately capture the network dynamics, key factors closely related to average delay, such as the number of backlogged packets in buffers and current packet arrivals, are incorporated into the state space. Furthermore, a transfer learning framework is introduced to enhance the training efficiency and accelerate convergence. Simulation results demonstrate that the proposed algorithm significantly reduces the average delay, enhances resource allocation efficiency, and achieves superior system robustness and fairness compared to baseline methods.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Corrupted by Reasoning: Reasoning Language Models Become Free-Riders in Public Goods Games</title>
<link>https://arxiv.org/abs/2506.23276</link>
<guid>https://arxiv.org/abs/2506.23276</guid>
<content:encoded><![CDATA[
arXiv:2506.23276v2 Announce Type: replace 
Abstract: As large language models (LLMs) are increasingly deployed as autonomous agents, understanding their cooperation and social mechanisms is becoming increasingly important. In particular, how LLMs balance self-interest and collective well-being is a critical challenge for ensuring alignment, robustness, and safe deployment. In this paper, we examine the challenge of costly sanctioning in multi-agent LLM systems, where an agent must decide whether to invest its own resources to incentivize cooperation or penalize defection. To study this, we adapt a public goods game with institutional choice from behavioral economics, allowing us to observe how different LLMs navigate social dilemmas over repeated interactions. Our analysis reveals four distinct behavioral patterns among models: some consistently establish and sustain high levels of cooperation, others fluctuate between engagement and disengagement, some gradually decline in cooperative behavior over time, and others rigidly follow fixed strategies regardless of outcomes. Surprisingly, we find that reasoning LLMs, such as the o1 series, struggle significantly with cooperation, whereas some traditional LLMs consistently achieve high levels of cooperation. These findings suggest that the current approach to improving LLMs, which focuses on enhancing their reasoning capabilities, does not necessarily lead to cooperation, providing valuable insights for deploying LLM agents in environments that require sustained collaboration. Our code is available at https://github.com/davidguzmanp/SanctSim
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MobileUse: A GUI Agent with Hierarchical Reflection for Autonomous Mobile Operation</title>
<link>https://arxiv.org/abs/2507.16853</link>
<guid>https://arxiv.org/abs/2507.16853</guid>
<content:encoded><![CDATA[
arXiv:2507.16853v1 Announce Type: new 
Abstract: Recent advances in Multimodal Large Language Models (MLLMs) have enabled the development of mobile agents that can understand visual inputs and follow user instructions, unlocking new possibilities for automating complex tasks on mobile devices. However, applying these models to real-world mobile scenarios remains a significant challenge due to the long-horizon task execution, difficulty in error recovery, and the cold-start problem in unfamiliar environments. To address these challenges, we propose MobileUse, a GUI agent designed for robust and adaptive mobile task execution. To improve resilience in long-horizon tasks and dynamic environments, we introduce a hierarchical reflection architecture that enables the agent to self-monitor, detect, and recover from errors across multiple temporal scales-ranging from individual actions to overall task completion-while maintaining efficiency through a reflection-on-demand strategy. To tackle cold-start issues, we further introduce a proactive exploration module, which enriches the agent's understanding of the environment through self-planned exploration. Evaluations on AndroidWorld and AndroidLab benchmarks demonstrate that MobileUse establishes new state-of-the-art performance, achieving success rates of 62.9% and 44.2%, respectively. To facilitate real-world applications, we release an out-of-the-box toolkit for automated task execution on physical mobile devices, which is available at https://github.com/MadeAgents/mobile-use.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning in hyperbolic space for multi-step reasoning</title>
<link>https://arxiv.org/abs/2507.16864</link>
<guid>https://arxiv.org/abs/2507.16864</guid>
<content:encoded><![CDATA[
arXiv:2507.16864v1 Announce Type: new 
Abstract: Multi-step reasoning is a fundamental challenge in artificial intelligence, with applications ranging from mathematical problem-solving to decision-making in dynamic environments. Reinforcement Learning (RL) has shown promise in enabling agents to perform multi-step reasoning by optimizing long-term rewards. However, conventional RL methods struggle with complex reasoning tasks due to issues such as credit assignment, high-dimensional state representations, and stability concerns. Recent advancements in Transformer architectures and hyperbolic geometry have provided novel solutions to these challenges. This paper introduces a new framework that integrates hyperbolic Transformers into RL for multi-step reasoning. The proposed approach leverages hyperbolic embeddings to model hierarchical structures effectively. We present theoretical insights, algorithmic details, and experimental results that include Frontier Math and nonlinear optimal control problems. Compared to RL with vanilla transformer, the hyperbolic RL largely improves accuracy by (32%~44%) on FrontierMath benchmark, (43%~45%) on nonlinear optimal control benchmark, while achieving impressive reduction in computational time by (16%~32%) on FrontierMath benchmark, (16%~17%) on nonlinear optimal control benchmark. Our work demonstrates the potential of hyperbolic Transformers in reinforcement learning, particularly for multi-step reasoning tasks that involve hierarchical structures.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Budget Allocation Policies for Real-Time Multi-Agent Path Finding</title>
<link>https://arxiv.org/abs/2507.16874</link>
<guid>https://arxiv.org/abs/2507.16874</guid>
<content:encoded><![CDATA[
arXiv:2507.16874v1 Announce Type: new 
Abstract: Multi-Agent Pathfinding (MAPF) is the problem of finding paths for a set of agents such that each agent reaches its desired destination while avoiding collisions with the other agents. Many MAPF solvers are designed to run offline, that is, first generate paths for all agents and then execute them. Real-Time MAPF (RT-MAPF) embodies a realistic MAPF setup in which one cannot wait until a complete path for each agent has been found before they start to move. Instead, planning and execution are interleaved, where the agents must commit to a fixed number of steps in a constant amount of computation time, referred to as the planning budget. Existing solutions to RT-MAPF iteratively call windowed versions of MAPF algorithms in every planning period, without explicitly considering the size of the planning budget. We address this gap and explore different policies for allocating the planning budget in windowed versions of standard MAPF algorithms, namely Prioritized Planning (PrP) and MAPF-LNS2. Our exploration shows that the baseline approach in which all agents draw from a shared planning budget pool is ineffective in over-constrained situations. Instead, policies that distribute the planning budget over the agents are able to solve more problems with a smaller makespan.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AURA: A Multi-Modal Medical Agent for Understanding, Reasoning &amp; Annotation</title>
<link>https://arxiv.org/abs/2507.16940</link>
<guid>https://arxiv.org/abs/2507.16940</guid>
<content:encoded><![CDATA[
arXiv:2507.16940v1 Announce Type: new 
Abstract: Recent advancements in Large Language Models (LLMs) have catalyzed a paradigm shift from static prediction systems to agentic AI agents capable of reasoning, interacting with tools, and adapting to complex tasks. While LLM-based agentic systems have shown promise across many domains, their application to medical imaging remains in its infancy. In this work, we introduce AURA, the first visual linguistic explainability agent designed specifically for comprehensive analysis, explanation, and evaluation of medical images. By enabling dynamic interactions, contextual explanations, and hypothesis testing, AURA represents a significant advancement toward more transparent, adaptable, and clinically aligned AI systems. We highlight the promise of agentic AI in transforming medical image analysis from static predictions to interactive decision support. Leveraging Qwen-32B, an LLM-based architecture, AURA integrates a modular toolbox comprising: (i) a segmentation suite with phase grounding, pathology segmentation, and anatomy segmentation to localize clinically meaningful regions; (ii) a counterfactual image-generation module that supports reasoning through image-level explanations; and (iii) a set of evaluation tools including pixel-wise difference-map analysis, classification, and advanced state-of-the-art components to assess diagnostic relevance and visual interpretability.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-agent Reinforcement Learning for Robotized Coral Reef Sample Collection</title>
<link>https://arxiv.org/abs/2507.16941</link>
<guid>https://arxiv.org/abs/2507.16941</guid>
<content:encoded><![CDATA[
arXiv:2507.16941v1 Announce Type: new 
Abstract: This paper presents a reinforcement learning (RL) environment for developing an autonomous underwater robotic coral sampling agent, a crucial coral reef conservation and research task. Using software-in-the-loop (SIL) and hardware-in-the-loop (HIL), an RL-trained artificial intelligence (AI) controller is developed using a digital twin (DT) in simulation and subsequently verified in physical experiments. An underwater motion capture (MOCAP) system provides real-time 3D position and orientation feedback during verification testing for precise synchronization between the digital and physical domains. A key novelty of this approach is the combined use of a general-purpose game engine for simulation, deep RL, and real-time underwater motion capture for an effective zero-shot sim-to-real strategy.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Text-to-SPARQL Goes Beyond English: Multilingual Question Answering Over Knowledge Graphs through Human-Inspired Reasoning</title>
<link>https://arxiv.org/abs/2507.16971</link>
<guid>https://arxiv.org/abs/2507.16971</guid>
<content:encoded><![CDATA[
arXiv:2507.16971v1 Announce Type: new 
Abstract: Accessing knowledge via multilingual natural-language interfaces is one of the emerging challenges in the field of information retrieval and related ones. Structured knowledge stored in knowledge graphs can be queried via a specific query language (e.g., SPARQL). Therefore, one needs to transform natural-language input into a query to fulfill an information need. Prior approaches mostly focused on combining components (e.g., rule-based or neural-based) that solve downstream tasks and come up with an answer at the end. We introduce mKGQAgent, a human-inspired framework that breaks down the task of converting natural language questions into SPARQL queries into modular, interpretable subtasks. By leveraging a coordinated LLM agent workflow for planning, entity linking, and query refinement - guided by an experience pool for in-context learning - mKGQAgent efficiently handles multilingual KGQA. Evaluated on the DBpedia- and Corporate-based KGQA benchmarks within the Text2SPARQL challenge 2025, our approach took first place among the other participants. This work opens new avenues for developing human-like reasoning systems in multilingual semantic parsing.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Reinforcement Learning Framework for Adaptive Walking Control Using General Value Functions of Lower-Limb Sensor Signals</title>
<link>https://arxiv.org/abs/2507.16983</link>
<guid>https://arxiv.org/abs/2507.16983</guid>
<content:encoded><![CDATA[
arXiv:2507.16983v1 Announce Type: new 
Abstract: Rehabilitation technology is a natural setting to study the shared learning and decision-making of human and machine agents. In this work, we explore the use of Hierarchical Reinforcement Learning (HRL) to develop adaptive control strategies for lower-limb exoskeletons, aiming to enhance mobility and autonomy for individuals with motor impairments. Inspired by prominent models of biological sensorimotor processing, our investigated HRL approach breaks down the complex task of exoskeleton control adaptation into a higher-level framework for terrain strategy adaptation and a lower-level framework for providing predictive information; this latter element is implemented via the continual learning of general value functions (GVFs). GVFs generated temporal abstractions of future signal values from multiple wearable lower-limb sensors, including electromyography, pressure insoles, and goniometers. We investigated two methods for incorporating actual and predicted sensor signals into a policy network with the intent to improve the decision-making capacity of the control system of a lower-limb exoskeleton during ambulation across varied terrains. As a key result, we found that the addition of predictions made from GVFs increased overall network accuracy. Terrain-specific performance increases were seen while walking on even ground, uneven ground, up and down ramps, and turns, terrains that are often misclassified without predictive information. This suggests that predictive information can aid decision-making during uncertainty, e.g., on terrains that have a high chance of being misclassified. This work, therefore, contributes new insights into the nuances of HRL and the future development of exoskeletons to facilitate safe transitioning and traversing across different walking environments.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Autonomous Sustainability Assessment via Multimodal AI Agents</title>
<link>https://arxiv.org/abs/2507.17012</link>
<guid>https://arxiv.org/abs/2507.17012</guid>
<content:encoded><![CDATA[
arXiv:2507.17012v1 Announce Type: new 
Abstract: Interest in sustainability information has surged in recent years. However, the data required for a life cycle assessment (LCA) that maps the materials and processes from product manufacturing to disposal into environmental impacts (EI) are often unavailable. Here we reimagine conventional LCA by introducing multimodal AI agents that emulate interactions between LCA experts and stakeholders like product managers and engineers to calculate the cradle-to-gate (production) carbon emissions of electronic devices. The AI agents iteratively generate a detailed life-cycle inventory leveraging a custom data abstraction and software tools that extract information from online text and images from repair communities and government certifications. This approach reduces weeks or months of expert time to under one minute and closes data availability gaps while yielding carbon footprint estimates within 19% of expert LCAs with zero proprietary data. Additionally, we develop a method to directly estimate EI by comparing an input to a cluster of products with similar descriptions and known carbon footprints. This runs in 3 ms on a laptop with a MAPE of 12.28% on electronic products. Further, we develop a data-driven method to generate emission factors. We use the properties of an unknown material to represent it as a weighted sum of emission factors for similar materials. Compared to human experts picking the closest LCA database entry, this improves MAPE by 120.26%. We analyze the data and compute scaling of this approach and discuss its implications for future LCA workflows.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can External Validation Tools Improve Annotation Quality for LLM-as-a-Judge?</title>
<link>https://arxiv.org/abs/2507.17015</link>
<guid>https://arxiv.org/abs/2507.17015</guid>
<content:encoded><![CDATA[
arXiv:2507.17015v1 Announce Type: new 
Abstract: Pairwise preferences over model responses are widely collected to evaluate and provide feedback to large language models (LLMs). Given two alternative model responses to the same input, a human or AI annotator selects the "better" response. This approach can provide feedback for domains where other hard-coded metrics are difficult to obtain (e.g., chat response quality), thereby helping model evaluation or training. However, for some domains high-quality pairwise comparisons can be tricky to obtain - from AI and humans. For example, for responses with many factual statements, annotators may disproportionately weigh writing quality rather than underlying facts. In this work, we explore augmenting standard AI annotator systems with additional tools to improve performance on three challenging response domains: long-form factual, math and code tasks. We propose a tool-using agentic system to provide higher quality feedback on these domains. Our system uses web-search and code execution to ground itself based on external validation, independent of the LLM's internal knowledge and biases. We provide extensive experimental results evaluating our method across the three targeted response domains as well as general annotation tasks, using RewardBench (incl. AlpacaEval and LLMBar), RewardMath, as well as three new datasets for domains with saturated pre-existing datasets. Our results indicate that external tools can indeed improve performance in many, but not all, cases. More generally, our experiments highlight the sensitivity of performance to simple parameters (e.g., prompt) and the need for improved (non-saturated) annotator benchmarks. We share our code at https://github.com/apple/ml-agent-evaluator.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Uncertainty and Quality of Visual Language Action-enabled Robots</title>
<link>https://arxiv.org/abs/2507.17049</link>
<guid>https://arxiv.org/abs/2507.17049</guid>
<content:encoded><![CDATA[
arXiv:2507.17049v1 Announce Type: new 
Abstract: Visual Language Action (VLA) models are a multi-modal class of Artificial Intelligence (AI) systems that integrate visual perception, natural language understanding, and action planning to enable agents to interpret their environment, comprehend instructions, and perform embodied tasks autonomously. Recently, significant progress has been made to advance this field. These kinds of models are typically evaluated through task success rates, which fail to capture the quality of task execution and the mode's confidence in its decisions. In this paper, we propose eight uncertainty metrics and five quality metrics specifically designed for VLA models for robotic manipulation tasks. We assess their effectiveness through a large-scale empirical study involving 908 successful task executions from three state-of-the-art VLA models across four representative robotic manipulation tasks. Human domain experts manually labeled task quality, allowing us to analyze the correlation between our proposed metrics and expert judgments. The results reveal that several metrics show moderate to strong correlation with human assessments, highlighting their utility for evaluating task quality and model confidence. Furthermore, we found that some of the metrics can discriminate between high-, medium-, and low-quality executions from unsuccessful tasks, which can be interesting when test oracles are not available. Our findings challenge the adequacy of current evaluation practices that rely solely on binary success rates and pave the way for improved real-time monitoring and adaptive enhancement of VLA-enabled robotic systems.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>New Mechanisms in Flex Distribution for Bounded Suboptimal Multi-Agent Path Finding</title>
<link>https://arxiv.org/abs/2507.17054</link>
<guid>https://arxiv.org/abs/2507.17054</guid>
<content:encoded><![CDATA[
arXiv:2507.17054v1 Announce Type: new 
Abstract: Multi-Agent Path Finding (MAPF) is the problem of finding a set of collision-free paths, one for each agent in a shared environment. Its objective is to minimize the sum of path costs (SOC), where the path cost of each agent is defined as the travel time from its start location to its target location. Explicit Estimation Conflict-Based Search (EECBS) is the leading algorithm for bounded-suboptimal MAPF, with the SOC of the solution being at most a user-specified factor $w$ away from optimal. EECBS maintains sets of paths and a lower bound $LB$ on the optimal SOC. Then, it iteratively selects a set of paths whose SOC is at most $w \cdot LB$ and introduces constraints to resolve collisions. For each path in a set, EECBS maintains a lower bound on its optimal path that satisfies constraints. By finding an individually bounded-suboptimal path with cost at most a threshold of $w$ times its lower bound, EECBS guarantees to find a bounded-suboptimal solution. To speed up EECBS, previous work uses flex distribution to increase the threshold. Though EECBS with flex distribution guarantees to find a bounded-suboptimal solution, increasing the thresholds may push the SOC beyond $w \cdot LB$, forcing EECBS to switch among different sets of paths instead of resolving collisions on a particular set of paths, and thus reducing efficiency. To address this issue, we propose Conflict-Based Flex Distribution that distributes flex in proportion to the number of collisions. We also estimate the delays needed to satisfy constraints and propose Delay-Based Flex Distribution. On top of that, we propose Mixed-Strategy Flex Distribution, combining both in a hierarchical framework. We prove that EECBS with our new flex distribution mechanisms is complete and bounded-suboptimal. Our experiments show that our approaches outperform the original (greedy) flex distribution.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Shared Control of Holonomic Wheelchairs through Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.17055</link>
<guid>https://arxiv.org/abs/2507.17055</guid>
<content:encoded><![CDATA[
arXiv:2507.17055v1 Announce Type: new 
Abstract: Smart electric wheelchairs can improve user experience by supporting the driver with shared control. State-of-the-art work showed the potential of shared control in improving safety in navigation for non-holonomic robots. However, for holonomic systems, current approaches often lead to unintuitive behavior for the user and fail to utilize the full potential of omnidirectional driving. Therefore, we propose a reinforcement learning-based method, which takes a 2D user input and outputs a 3D motion while ensuring user comfort and reducing cognitive load on the driver. Our approach is trained in Isaac Gym and tested in simulation in Gazebo. We compare different RL agent architectures and reward functions based on metrics considering cognitive load and user comfort. We show that our method ensures collision-free navigation while smartly orienting the wheelchair and showing better or competitive smoothness compared to a previous non-learning-based method. We further perform a sim-to-real transfer and demonstrate, to the best of our knowledge, the first real-world implementation of RL-based shared control for an omnidirectional mobility platform.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Parallelism Meets Adaptiveness: Scalable Documents Understanding in Multi-Agent LLM Systems</title>
<link>https://arxiv.org/abs/2507.17061</link>
<guid>https://arxiv.org/abs/2507.17061</guid>
<content:encoded><![CDATA[
arXiv:2507.17061v1 Announce Type: new 
Abstract: Large language model (LLM) agents have shown increasing promise for collaborative task completion. However, existing multi-agent frameworks often rely on static workflows, fixed roles, and limited inter-agent communication, reducing their effectiveness in open-ended, high-complexity domains. This paper proposes a coordination framework that enables adaptiveness through three core mechanisms: dynamic task routing, bidirectional feedback, and parallel agent evaluation. The framework allows agents to reallocate tasks based on confidence and workload, exchange structured critiques to iteratively improve outputs, and crucially compete on high-ambiguity subtasks with evaluator-driven selection of the most suitable result. We instantiate these principles in a modular architecture and demonstrate substantial improvements in factual coverage, coherence, and efficiency over static and partially adaptive baselines. Our findings highlight the benefits of incorporating both adaptiveness and structured competition in multi-agent LLM systems.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VL-CLIP: Enhancing Multimodal Recommendations via Visual Grounding and LLM-Augmented CLIP Embeddings</title>
<link>https://arxiv.org/abs/2507.17080</link>
<guid>https://arxiv.org/abs/2507.17080</guid>
<content:encoded><![CDATA[
arXiv:2507.17080v1 Announce Type: new 
Abstract: Multimodal learning plays a critical role in e-commerce recommendation platforms today, enabling accurate recommendations and product understanding. However, existing vision-language models, such as CLIP, face key challenges in e-commerce recommendation systems: 1) Weak object-level alignment, where global image embeddings fail to capture fine-grained product attributes, leading to suboptimal retrieval performance; 2) Ambiguous textual representations, where product descriptions often lack contextual clarity, affecting cross-modal matching; and 3) Domain mismatch, as generic vision-language models may not generalize well to e-commerce-specific data. To address these limitations, we propose a framework, VL-CLIP, that enhances CLIP embeddings by integrating Visual Grounding for fine-grained visual understanding and an LLM-based agent for generating enriched text embeddings. Visual Grounding refines image representations by localizing key products, while the LLM agent enhances textual features by disambiguating product descriptions. Our approach significantly improves retrieval accuracy, multimodal retrieval effectiveness, and recommendation quality across tens of millions of items on one of the largest e-commerce platforms in the U.S., increasing CTR by 18.6%, ATC by 15.5%, and GMV by 4.0%. Additional experimental results show that our framework outperforms vision-language models, including CLIP, FashionCLIP, and GCL, in both precision and semantic alignment, demonstrating the potential of combining object-aware visual grounding and LLM-enhanced text representation for robust multimodal recommendations.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deformable Cluster Manipulation via Whole-Arm Policy Learning</title>
<link>https://arxiv.org/abs/2507.17085</link>
<guid>https://arxiv.org/abs/2507.17085</guid>
<content:encoded><![CDATA[
arXiv:2507.17085v1 Announce Type: new 
Abstract: Manipulating clusters of deformable objects presents a substantial challenge with widespread applicability, but requires contact-rich whole-arm interactions. A potential solution must address the limited capacity for realistic model synthesis, high uncertainty in perception, and the lack of efficient spatial abstractions, among others. We propose a novel framework for learning model-free policies integrating two modalities: 3D point clouds and proprioceptive touch indicators, emphasising manipulation with full body contact awareness, going beyond traditional end-effector modes. Our reinforcement learning framework leverages a distributional state representation, aided by kernel mean embeddings, to achieve improved training efficiency and real-time inference. Furthermore, we propose a novel context-agnostic occlusion heuristic to clear deformables from a target region for exposure tasks. We deploy the framework in a power line clearance scenario and observe that the agent generates creative strategies leveraging multiple arm links for de-occlusion. Finally, we perform zero-shot sim-to-real policy transfer, allowing the arm to clear real branches with unknown occlusion patterns, unseen topology, and uncertain dynamics.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enabling Self-Improving Agents to Learn at Test Time With Human-In-The-Loop Guidance</title>
<link>https://arxiv.org/abs/2507.17131</link>
<guid>https://arxiv.org/abs/2507.17131</guid>
<content:encoded><![CDATA[
arXiv:2507.17131v1 Announce Type: new 
Abstract: Large language model (LLM) agents often struggle in environments where rules and required domain knowledge frequently change, such as regulatory compliance and user risk screening. Current approaches, like offline fine-tuning and standard prompting, are insufficient because they cannot effectively adapt to new knowledge during actual operation. To address this limitation, we propose the Adaptive Reflective Interactive Agent (ARIA), an LLM agent framework designed specifically to continuously learn updated domain knowledge at test time. ARIA assesses its own uncertainty through structured self-dialogue, proactively identifying knowledge gaps and requesting targeted explanations or corrections from human experts. It then systematically updates an internal, timestamped knowledge repository with provided human guidance, detecting and resolving conflicting or outdated knowledge through comparisons and clarification queries. We evaluate ARIA on the realistic customer due diligence name screening task on TikTok Pay, alongside publicly available dynamic knowledge tasks. Results demonstrate significant improvements in adaptability and accuracy compared to baselines using standard offline fine-tuning and existing self-improving agents. ARIA is deployed within TikTok Pay serving over 150 million monthly active users, confirming its practicality and effectiveness for operational use in rapidly evolving environments.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resilient Multi-Agent Negotiation for Medical Supply Chains:Integrating LLMs and Blockchain for Transparent Coordination</title>
<link>https://arxiv.org/abs/2507.17134</link>
<guid>https://arxiv.org/abs/2507.17134</guid>
<content:encoded><![CDATA[
arXiv:2507.17134v1 Announce Type: new 
Abstract: Global health emergencies, such as the COVID-19 pandemic, have exposed critical weaknesses in traditional medical supply chains, including inefficiencies in resource allocation, lack of transparency, and poor adaptability to dynamic disruptions. This paper presents a novel hybrid framework that integrates blockchain technology with a decentralized, large language model (LLM) powered multi-agent negotiation system to enhance the resilience and accountability of medical supply chains during crises. In this system, autonomous agents-representing manufacturers, distributors, and healthcare institutions-engage in structured, context-aware negotiation and decision-making processes facilitated by LLMs, enabling rapid and ethical allocation of scarce medical resources. The off-chain agent layer supports adaptive reasoning and local decision-making, while the on-chain blockchain layer ensures immutable, transparent, and auditable enforcement of decisions via smart contracts. The framework also incorporates a formal cross-layer communication protocol to bridge decentralized negotiation with institutional enforcement. A simulation environment emulating pandemic scenarios evaluates the system's performance, demonstrating improvements in negotiation efficiency, fairness of allocation, supply chain responsiveness, and auditability. This research contributes an innovative approach that synergizes blockchain trust guarantees with the adaptive intelligence of LLM-driven agents, providing a robust and scalable solution for critical supply chain coordination under uncertainty.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>JAM: Keypoint-Guided Joint Prediction after Classification-Aware Marginal Proposal for Multi-Agent Interaction</title>
<link>https://arxiv.org/abs/2507.17152</link>
<guid>https://arxiv.org/abs/2507.17152</guid>
<content:encoded><![CDATA[
arXiv:2507.17152v1 Announce Type: new 
Abstract: Predicting the future motion of road participants is a critical task in autonomous driving. In this work, we address the challenge of low-quality generation of low-probability modes in multi-agent joint prediction. To tackle this issue, we propose a two-stage multi-agent interactive prediction framework named \textit{keypoint-guided joint prediction after classification-aware marginal proposal} (JAM). The first stage is modeled as a marginal prediction process, which classifies queries by trajectory type to encourage the model to learn all categories of trajectories, providing comprehensive mode information for the joint prediction module. The second stage is modeled as a joint prediction process, which takes the scene context and the marginal proposals from the first stage as inputs to learn the final joint distribution. We explicitly introduce key waypoints to guide the joint prediction module in better capturing and leveraging the critical information from the initial predicted trajectories. We conduct extensive experiments on the real-world Waymo Open Motion Dataset interactive prediction benchmark. The results show that our approach achieves competitive performance. In particular, in the framework comparison experiments, the proposed JAM outperforms other prediction frameworks and achieves state-of-the-art performance in interactive trajectory prediction. The code is available at https://github.com/LinFunster/JAM to facilitate future research.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Regret Minimization in Population Network Games: Vanishing Heterogeneity and Convergence to Equilibria</title>
<link>https://arxiv.org/abs/2507.17183</link>
<guid>https://arxiv.org/abs/2507.17183</guid>
<content:encoded><![CDATA[
arXiv:2507.17183v1 Announce Type: new 
Abstract: Understanding and predicting the behavior of large-scale multi-agents in games remains a fundamental challenge in multi-agent systems. This paper examines the role of heterogeneity in equilibrium formation by analyzing how smooth regret-matching drives a large number of heterogeneous agents with diverse initial policies toward unified behavior. By modeling the system state as a probability distribution of regrets and analyzing its evolution through the continuity equation, we uncover a key phenomenon in diverse multi-agent settings: the variance of the regret distribution diminishes over time, leading to the disappearance of heterogeneity and the emergence of consensus among agents. This universal result enables us to prove convergence to quantal response equilibria in both competitive and cooperative multi-agent settings. Our work advances the theoretical understanding of multi-agent learning and offers a novel perspective on equilibrium selection in diverse game-theoretic scenarios.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FinGAIA: An End-to-End Benchmark for Evaluating AI Agents in Finance</title>
<link>https://arxiv.org/abs/2507.17186</link>
<guid>https://arxiv.org/abs/2507.17186</guid>
<content:encoded><![CDATA[
arXiv:2507.17186v1 Announce Type: new 
Abstract: The booming development of AI agents presents unprecedented opportunities for automating complex tasks across various domains. However, their multi-step, multi-tool collaboration capabilities in the financial sector remain underexplored. This paper introduces FinGAIA, an end-to-end benchmark designed to evaluate the practical abilities of AI agents in the financial domain. FinGAIA comprises 407 meticulously crafted tasks, spanning seven major financial sub-domains: securities, funds, banking, insurance, futures, trusts, and asset management. These tasks are organized into three hierarchical levels of scenario depth: basic business analysis, asset decision support, and strategic risk management. We evaluated 10 mainstream AI agents in a zero-shot setting. The best-performing agent, ChatGPT, achieved an overall accuracy of 48.9\%, which, while superior to non-professionals, still lags financial experts by over 35 percentage points. Error analysis has revealed five recurring failure patterns: Cross-modal Alignment Deficiency, Financial Terminological Bias, Operational Process Awareness Barrier, among others. These patterns point to crucial directions for future research. Our work provides the first agent benchmark closely related to the financial domain, aiming to objectively assess and promote the development of agents in this crucial field. Partial data is available at https://github.com/SUFE-AIFLM-Lab/FinGAIA.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM Meets the Sky: Heuristic Multi-Agent Reinforcement Learning for Secure Heterogeneous UAV Networks</title>
<link>https://arxiv.org/abs/2507.17188</link>
<guid>https://arxiv.org/abs/2507.17188</guid>
<content:encoded><![CDATA[
arXiv:2507.17188v1 Announce Type: new 
Abstract: This work tackles the physical layer security (PLS) problem of maximizing the secrecy rate in heterogeneous UAV networks (HetUAVNs) under propulsion energy constraints. Unlike prior studies that assume uniform UAV capabilities or overlook energy-security trade-offs, we consider a realistic scenario where UAVs with diverse payloads and computation resources collaborate to serve ground terminals in the presence of eavesdroppers. To manage the complex coupling between UAV motion and communication, we propose a hierarchical optimization framework. The inner layer uses a semidefinite relaxation (SDR)-based S2DC algorithm combining penalty functions and difference-of-convex (d.c.) programming to solve the secrecy precoding problem with fixed UAV positions. The outer layer introduces a Large Language Model (LLM)-guided heuristic multi-agent reinforcement learning approach (LLM-HeMARL) for trajectory optimization. LLM-HeMARL efficiently incorporates expert heuristics policy generated by the LLM, enabling UAVs to learn energy-aware, security-driven trajectories without the inference overhead of real-time LLM calls. The simulation results show that our method outperforms existing baselines in secrecy rate and energy efficiency, with consistent robustness across varying UAV swarm sizes and random seeds.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent Identity Evals: Measuring Agentic Identity</title>
<link>https://arxiv.org/abs/2507.17257</link>
<guid>https://arxiv.org/abs/2507.17257</guid>
<content:encoded><![CDATA[
arXiv:2507.17257v1 Announce Type: new 
Abstract: Central to agentic capability and trustworthiness of language model agents (LMAs) is the extent they maintain stable, reliable, identity over time. However, LMAs inherit pathologies from large language models (LLMs) (statelessness, stochasticity, sensitivity to prompts and linguistically-intermediation) which can undermine their identifiability, continuity, persistence and consistency. This attrition of identity can erode their reliability, trustworthiness and utility by interfering with their agentic capabilities such as reasoning, planning and action. To address these challenges, we introduce \textit{agent identity evals} (AIE), a rigorous, statistically-driven, empirical framework for measuring the degree to which an LMA system exhibit and maintain their agentic identity over time, including their capabilities, properties and ability to recover from state perturbations. AIE comprises a set of novel metrics which can integrate with other measures of performance, capability and agentic robustness to assist in the design of optimal LMA infrastructure and scaffolding such as memory and tools. We set out formal definitions and methods that can be applied at each stage of the LMA life-cycle, and worked examples of how to apply them.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Leveraging Knowledge Graphs and LLM Reasoning to Identify Operational Bottlenecks for Warehouse Planning Assistance</title>
<link>https://arxiv.org/abs/2507.17273</link>
<guid>https://arxiv.org/abs/2507.17273</guid>
<content:encoded><![CDATA[
arXiv:2507.17273v1 Announce Type: new 
Abstract: Analyzing large, complex output datasets from Discrete Event Simulations (DES) of warehouse operations to identify bottlenecks and inefficiencies is a critical yet challenging task, often demanding significant manual effort or specialized analytical tools. Our framework integrates Knowledge Graphs (KGs) and Large Language Model (LLM)-based agents to analyze complex Discrete Event Simulation (DES) output data from warehouse operations. It transforms raw DES data into a semantically rich KG, capturing relationships between simulation events and entities. An LLM-based agent uses iterative reasoning, generating interdependent sub-questions. For each sub-question, it creates Cypher queries for KG interaction, extracts information, and self-reflects to correct errors. This adaptive, iterative, and self-correcting process identifies operational issues mimicking human analysis. Our DES approach for warehouse bottleneck identification, tested with equipment breakdowns and process irregularities, outperforms baseline methods. For operational questions, it achieves near-perfect pass rates in pinpointing inefficiencies. For complex investigative questions, we demonstrate its superior diagnostic ability to uncover subtle, interconnected issues. This work bridges simulation modeling and AI (KG+LLM), offering a more intuitive method for actionable insights, reducing time-to-insight, and enabling automated warehouse inefficiency evaluation and diagnosis.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compliance Brain Assistant: Conversational Agentic AI for Assisting Compliance Tasks in Enterprise Environments</title>
<link>https://arxiv.org/abs/2507.17289</link>
<guid>https://arxiv.org/abs/2507.17289</guid>
<content:encoded><![CDATA[
arXiv:2507.17289v1 Announce Type: new 
Abstract: This paper presents Compliance Brain Assistant (CBA), a conversational, agentic AI assistant designed to boost the efficiency of daily compliance tasks for personnel in enterprise environments. To strike a good balance between response quality and latency, we design a user query router that can intelligently choose between (i) FastTrack mode: to handle simple requests that only need additional relevant context retrieved from knowledge corpora; and (ii) FullAgentic mode: to handle complicated requests that need composite actions and tool invocations to proactively discover context across various compliance artifacts, and/or involving other APIs/models for accommodating requests. A typical example would be to start with a user query, use its description to find a specific entity and then use the entity's information to query other APIs for curating and enriching the final AI response.
  Our experimental evaluations compared CBA against an out-of-the-box LLM on various real-world privacy/compliance-related queries targeting various personas. We found that CBA substantially improved upon the vanilla LLM's performance on metrics such as average keyword match rate (83.7% vs. 41.7%) and LLM-judge pass rate (82.0% vs. 20.0%). We also compared metrics for the full routing-based design against the `fast-track only` and `full-agentic` modes and found that it had a better average match-rate and pass-rate while keeping the run-time approximately the same. This finding validated our hypothesis that the routing mechanism leads to a good trade-off between the two worlds.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EarthLink: Interpreting Climate Signals with Self-Evolving AI Agents</title>
<link>https://arxiv.org/abs/2507.17311</link>
<guid>https://arxiv.org/abs/2507.17311</guid>
<content:encoded><![CDATA[
arXiv:2507.17311v1 Announce Type: new 
Abstract: Modern Earth science is at an inflection point. The vast, fragmented, and complex nature of Earth system data, coupled with increasingly sophisticated analytical demands, creates a significant bottleneck for rapid scientific discovery. Here we introduce EarthLink, the first AI agent designed as an interactive copilot for Earth scientists. It automates the end-to-end research workflow, from planning and code generation to multi-scenario analysis. Unlike static diagnostic tools, EarthLink can learn from user interaction, continuously refining its capabilities through a dynamic feedback loop. We validated its performance on a number of core scientific tasks of climate change, ranging from model-observation comparisons to the diagnosis of complex phenomena. In a multi-expert evaluation, EarthLink produced scientifically sound analyses and demonstrated an analytical competency that was rated as comparable to specific aspects of a human junior researcher's workflow. Additionally, its transparent, auditable workflows and natural language interface empower scientists to shift from laborious manual execution to strategic oversight and hypothesis generation. EarthLink marks a pivotal step towards an efficient, trustworthy, and collaborative paradigm for Earth system research in an era of accelerating global change.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HuNavSim 2.0</title>
<link>https://arxiv.org/abs/2507.17317</link>
<guid>https://arxiv.org/abs/2507.17317</guid>
<content:encoded><![CDATA[
arXiv:2507.17317v1 Announce Type: new 
Abstract: This work presents a new iteration of the Human Navigation Simulator (HuNavSim), a novel open-source tool for the simulation of different human-agent navigation behaviors in scenarios with mobile robots. The tool, programmed under the ROS 2 framework, can be used together with different well-known robotics simulators such as Gazebo or NVidia Isaac Sim. The main goal is to facilitate the development and evaluation of human-aware robot navigation systems in simulation. In this new version, several features have been improved and new ones added, such as the extended set of actions and conditions that can be combined in Behavior Trees to compound complex and realistic human behaviors.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeMo++: Motion Decoupling for Autonomous Driving</title>
<link>https://arxiv.org/abs/2507.17342</link>
<guid>https://arxiv.org/abs/2507.17342</guid>
<content:encoded><![CDATA[
arXiv:2507.17342v1 Announce Type: new 
Abstract: Motion forecasting and planning are tasked with estimating the trajectories of traffic agents and the ego vehicle, respectively, to ensure the safety and efficiency of autonomous driving systems in dynamically changing environments. State-of-the-art methods typically adopt a one-query-one-trajectory paradigm, where each query corresponds to a unique trajectory for predicting multi-mode trajectories. While this paradigm can produce diverse motion intentions, it often falls short in modeling the intricate spatiotemporal evolution of trajectories, which can lead to collisions or suboptimal outcomes. To overcome this limitation, we propose DeMo++, a framework that decouples motion estimation into two distinct components: holistic motion intentions to capture the diverse potential directions of movement, and fine spatiotemporal states to track the agent's dynamic progress within the scene and enable a self-refinement capability. Further, we introduce a cross-scene trajectory interaction mechanism to explore the relationships between motions in adjacent scenes. This allows DeMo++ to comprehensively model both the diversity of motion intentions and the spatiotemporal evolution of each trajectory. To effectively implement this framework, we developed a hybrid model combining Attention and Mamba. This architecture leverages the strengths of both mechanisms for efficient scene information aggregation and precise trajectory state sequence modeling. Extensive experiments demonstrate that DeMo++ achieves state-of-the-art performance across various benchmarks, including motion forecasting (Argoverse 2 and nuScenes), motion planning (nuPlan), and end-to-end planning (NAVSIM).
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DynaSearcher: Dynamic Knowledge Graph Augmented Search Agent via Multi-Reward Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.17365</link>
<guid>https://arxiv.org/abs/2507.17365</guid>
<content:encoded><![CDATA[
arXiv:2507.17365v1 Announce Type: new 
Abstract: Multi-step agentic retrieval systems based on large language models (LLMs) have demonstrated remarkable performance in complex information search tasks. However, these systems still face significant challenges in practical applications, particularly in generating factually inconsistent intermediate queries and inefficient search trajectories, which can lead to reasoning deviations or redundant computations. To address these issues, we propose DynaSearcher, an innovative search agent enhanced by dynamic knowledge graphs and multi-reward reinforcement learning (RL). Specifically, our system leverages knowledge graphs as external structured knowledge to guide the search process by explicitly modeling entity relationships, thereby ensuring factual consistency in intermediate queries and mitigating biases from irrelevant information. Furthermore, we employ a multi-reward RL framework for fine-grained control over training objectives such as retrieval accuracy, efficiency, and response quality. This framework promotes the generation of high-quality intermediate queries and comprehensive final answers, while discouraging unnecessary exploration and minimizing information omissions or redundancy. Experimental results demonstrate that our approach achieves state-of-the-art answer accuracy on six multi-hop question answering datasets, matching frontier LLMs while using only small-scale models and limited computational resources. Furthermore, our approach demonstrates strong generalization and robustness across diverse retrieval environments and larger-scale models, highlighting its broad applicability.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Residual Prophet Inequalities</title>
<link>https://arxiv.org/abs/2507.17391</link>
<guid>https://arxiv.org/abs/2507.17391</guid>
<content:encoded><![CDATA[
arXiv:2507.17391v1 Announce Type: new 
Abstract: We introduce a variant of the classic prophet inequality, called \emph{residual prophet inequality} (RPI). In the RPI problem, we consider a finite sequence of $n$ nonnegative independent random values with known distributions, and a known integer $0\leq k\leq n-1$. Before the gambler observes the sequence, the top $k$ values are removed, whereas the remaining $n-k$ values are streamed sequentially to the gambler. For example, one can assume that the top $k$ values have already been allocated to a higher-priority agent. Upon observing a value, the gambler must decide irrevocably whether to accept or reject it, without the possibility of revisiting past values.
  We study two variants of RPI, according to whether the gambler learns online of the identity of the variable that he sees (FI model) or not (NI model). Our main result is a randomized algorithm in the FI model with \emph{competitive ratio} of at least $1/(k+2)$, which we show is tight. Our algorithm is data-driven and requires access only to the $k+1$ largest values of a single sample from the $n$ input distributions. In the NI model, we provide a similar algorithm that guarantees a competitive ratio of $1/(2k+2)$. We further analyze independent and identically distributed instances when $k=1$. We build a single-threshold algorithm with a competitive ratio of at least 0.4901, and show that no single-threshold strategy can get a competitive ratio greater than 0.5464.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CAPRI-CT: Causal Analysis and Predictive Reasoning for Image Quality Optimization in Computed Tomography</title>
<link>https://arxiv.org/abs/2507.17420</link>
<guid>https://arxiv.org/abs/2507.17420</guid>
<content:encoded><![CDATA[
arXiv:2507.17420v1 Announce Type: new 
Abstract: In computed tomography (CT), achieving high image quality while minimizing radiation exposure remains a key clinical challenge. This paper presents CAPRI-CT, a novel causal-aware deep learning framework for Causal Analysis and Predictive Reasoning for Image Quality Optimization in CT imaging. CAPRI-CT integrates image data with acquisition metadata (such as tube voltage, tube current, and contrast agent types) to model the underlying causal relationships that influence image quality. An ensemble of Variational Autoencoders (VAEs) is employed to extract meaningful features and generate causal representations from observational data, including CT images and associated imaging parameters. These input features are fused to predict the Signal-to-Noise Ratio (SNR) and support counterfactual inference, enabling what-if simulations, such as changes in contrast agents (types and concentrations) or scan parameters. CAPRI-CT is trained and validated using an ensemble learning approach, achieving strong predictive performance. By facilitating both prediction and interpretability, CAPRI-CT provides actionable insights that could help radiologists and technicians design more efficient CT protocols without repeated physical scans. The source code and dataset are publicly available at https://github.com/SnehaGeorge22/capri-ct.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Compromises in Participatory Budgeting: a Multi-Agent Deep Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2507.17433</link>
<guid>https://arxiv.org/abs/2507.17433</guid>
<content:encoded><![CDATA[
arXiv:2507.17433v1 Announce Type: new 
Abstract: Participatory budgeting is a method of collectively understanding and addressing spending priorities where citizens vote on how a budget is spent, it is regularly run to improve the fairness of the distribution of public funds. Participatory budgeting requires voters to make decisions on projects which can lead to ``choice overload". A multi-agent reinforcement learning approach to decision support can make decision making easier for voters by identifying voting strategies that increase the winning proportion of their vote. This novel approach can also support policymakers by highlighting aspects of election design that enable fair compromise on projects. This paper presents a novel, ethically aligned approach to decision support using multi-agent deep reinforcement learning modelling. This paper introduces a novel use of a branching neural network architecture to overcome scalability challenges of multi-agent reinforcement learning in a decentralized way. Fair compromises are found through optimising voter actions towards greater representation of voter preferences in the winning set. Experimental evaluation with real-world participatory budgeting data reveals a pattern in fair compromise: that it is achievable through projects with smaller cost.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IndoorBEV: Joint Detection and Footprint Completion of Objects via Mask-based Prediction in Indoor Scenarios for Bird's-Eye View Perception</title>
<link>https://arxiv.org/abs/2507.17445</link>
<guid>https://arxiv.org/abs/2507.17445</guid>
<content:encoded><![CDATA[
arXiv:2507.17445v1 Announce Type: new 
Abstract: Detecting diverse objects within complex indoor 3D point clouds presents significant challenges for robotic perception, particularly with varied object shapes, clutter, and the co-existence of static and dynamic elements where traditional bounding box methods falter. To address these limitations, we propose IndoorBEV, a novel mask-based Bird's-Eye View (BEV) method for indoor mobile robots.
  In a BEV method, a 3D scene is projected into a 2D BEV grid which handles naturally occlusions and provides a consistent top-down view aiding to distinguish static obstacles from dynamic agents. The obtained 2D BEV results is directly usable to downstream robotic tasks like navigation, motion prediction, and planning. Our architecture utilizes an axis compact encoder and a window-based backbone to extract rich spatial features from this BEV map. A query-based decoder head then employs learned object queries to concurrently predict object classes and instance masks in the BEV space. This mask-centric formulation effectively captures the footprint of both static and dynamic objects regardless of their shape, offering a robust alternative to bounding box regression. We demonstrate the effectiveness of IndoorBEV on a custom indoor dataset featuring diverse object classes including static objects
  and dynamic elements like robots and miscellaneous items, showcasing its potential for robust indoor scene understanding.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LTLZinc: a Benchmarking Framework for Continual Learning and Neuro-Symbolic Temporal Reasoning</title>
<link>https://arxiv.org/abs/2507.17482</link>
<guid>https://arxiv.org/abs/2507.17482</guid>
<content:encoded><![CDATA[
arXiv:2507.17482v1 Announce Type: new 
Abstract: Neuro-symbolic artificial intelligence aims to combine neural architectures with symbolic approaches that can represent knowledge in a human-interpretable formalism. Continual learning concerns with agents that expand their knowledge over time, improving their skills while avoiding to forget previously learned concepts. Most of the existing approaches for neuro-symbolic artificial intelligence are applied to static scenarios only, and the challenging setting where reasoning along the temporal dimension is necessary has been seldom explored. In this work we introduce LTLZinc, a benchmarking framework that can be used to generate datasets covering a variety of different problems, against which neuro-symbolic and continual learning methods can be evaluated along the temporal and constraint-driven dimensions. Our framework generates expressive temporal reasoning and continual learning tasks from a linear temporal logic specification over MiniZinc constraints, and arbitrary image classification datasets. Fine-grained annotations allow multiple neural and neuro-symbolic training settings on the same generated datasets. Experiments on six neuro-symbolic sequence classification and four class-continual learning tasks generated by LTLZinc, demonstrate the challenging nature of temporal learning and reasoning, and highlight limitations of current state-of-the-art methods. We release the LTLZinc generator and ten ready-to-use tasks to the neuro-symbolic and continual learning communities, in the hope of fostering research towards unified temporal learning and reasoning frameworks.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulating multiple human perspectives in socio-ecological systems using large language models</title>
<link>https://arxiv.org/abs/2507.17680</link>
<guid>https://arxiv.org/abs/2507.17680</guid>
<content:encoded><![CDATA[
arXiv:2507.17680v1 Announce Type: new 
Abstract: Understanding socio-ecological systems requires insights from diverse stakeholder perspectives, which are often hard to access. To enable alternative, simulation-based exploration of different stakeholder perspectives, we develop the HoPeS (Human-Oriented Perspective Shifting) modelling framework. HoPeS employs agents powered by large language models (LLMs) to represent various stakeholders; users can step into the agent roles to experience perspectival differences. A simulation protocol serves as a "scaffold" to streamline multiple perspective-taking simulations, supporting users in reflecting on, transitioning between, and integrating across perspectives. A prototype system is developed to demonstrate HoPeS in the context of institutional dynamics and land use change, enabling both narrative-driven and numerical experiments. In an illustrative experiment, a user successively adopts the perspectives of a system observer and a researcher - a role that analyses data from the embedded land use model to inform evidence-based decision-making for other LLM agents representing various institutions. Despite the user's effort to recommend technically sound policies, discrepancies persist between the policy recommendation and implementation due to stakeholders' competing advocacies, mirroring real-world misalignment between researcher and policymaker perspectives. The user's reflection highlights the subjective feelings of frustration and disappointment as a researcher, especially due to the challenge of maintaining political neutrality while attempting to gain political influence. Despite this, the user exhibits high motivation to experiment with alternative narrative framing strategies, suggesting the system's potential in exploring different perspectives. Further system and protocol refinement are likely to enable new forms of interdisciplinary collaboration in socio-ecological simulations.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symbiotic Agents: A Novel Paradigm for Trustworthy AGI-driven Networks</title>
<link>https://arxiv.org/abs/2507.17695</link>
<guid>https://arxiv.org/abs/2507.17695</guid>
<content:encoded><![CDATA[
arXiv:2507.17695v1 Announce Type: new 
Abstract: Large Language Model (LLM)-based autonomous agents are expected to play a vital role in the evolution of 6G networks, by empowering real-time decision-making related to management and service provisioning to end-users. This shift facilitates the transition from a specialized intelligence approach, where artificial intelligence (AI) algorithms handle isolated tasks, to artificial general intelligence (AGI)-driven networks, where agents possess broader reasoning capabilities and can manage diverse network functions. In this paper, we introduce a novel agentic paradigm that combines LLMs with real-time optimization algorithms towards Trustworthy AI, defined as symbiotic agents. Optimizers at the LLM's input-level provide bounded uncertainty steering for numerically precise tasks, whereas output-level optimizers supervised by the LLM enable adaptive real-time control. We design and implement two novel agent types including: (i) Radio Access Network optimizers, and (ii) multi-agent negotiators for Service-Level Agreements (SLAs). We further propose an end-to-end architecture for AGI networks and evaluate it on a 5G testbed capturing channel fluctuations from moving vehicles. Results show that symbiotic agents reduce decision errors fivefold compared to standalone LLM-based agents, while smaller language models (SLM) achieve similar accuracy with a 99.9% reduction in GPU resource overhead and in near-real-time loops of 82 ms. A multi-agent demonstration for collaborative RAN on the real-world testbed highlights significant flexibility in service-level agreement and resource allocation, reducing RAN over-utilization by approximately 44%. Drawing on our findings and open-source implementations, we introduce the symbiotic paradigm as the foundation for next-generation, AGI-driven networks-systems designed to remain adaptable, efficient, and trustworthy even as LLMs advance.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BetterCheck: Towards Safeguarding VLMs for Automotive Perception Systems</title>
<link>https://arxiv.org/abs/2507.17722</link>
<guid>https://arxiv.org/abs/2507.17722</guid>
<content:encoded><![CDATA[
arXiv:2507.17722v1 Announce Type: new 
Abstract: Large language models (LLMs) are growingly extended to process multimodal data such as text and video simultaneously. Their remarkable performance in understanding what is shown in images is surpassing specialized neural networks (NNs) such as Yolo that is supporting only a well-formed but very limited vocabulary, ie., objects that they are able to detect. When being non-restricted, LLMs and in particular state-of-the-art vision language models (VLMs) show impressive performance to describe even complex traffic situations. This is making them potentially suitable components for automotive perception systems to support the understanding of complex traffic situations or edge case situation. However, LLMs and VLMs are prone to hallucination, which mean to either potentially not seeing traffic agents such as vulnerable road users who are present in a situation, or to seeing traffic agents who are not there in reality. While the latter is unwanted making an ADAS or autonomous driving systems (ADS) to unnecessarily slow down, the former could lead to disastrous decisions from an ADS. In our work, we are systematically assessing the performance of 3 state-of-the-art VLMs on a diverse subset of traffic situations sampled from the Waymo Open Dataset to support safety guardrails for capturing such hallucinations in VLM-supported perception systems. We observe that both, proprietary and open VLMs exhibit remarkable image understanding capabilities even paying thorough attention to fine details sometimes difficult to spot for us humans. However, they are also still prone to making up elements in their descriptions to date requiring hallucination detection strategies such as BetterCheck that we propose in our work.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DataWink: Reusing and Adapting SVG-based Visualization Examples with Large Multimodal Models</title>
<link>https://arxiv.org/abs/2507.17734</link>
<guid>https://arxiv.org/abs/2507.17734</guid>
<content:encoded><![CDATA[
arXiv:2507.17734v1 Announce Type: new 
Abstract: Creating aesthetically pleasing data visualizations remains challenging for users without design expertise or familiarity with visualization tools. To address this gap, we present DataWink, a system that enables users to create custom visualizations by adapting high-quality examples. Our approach combines large multimodal models (LMMs) to extract data encoding from existing SVG-based visualization examples, featuring an intermediate representation of visualizations that bridges primitive SVG and visualization programs. Users may express adaptation goals to a conversational agent and control the visual appearance through widgets generated on demand. With an interactive interface, users can modify both data mappings and visual design elements while maintaining the original visualization's aesthetic quality. To evaluate DataWink, we conduct a user study (N=12) with replication and free-form exploration tasks. As a result, DataWink is recognized for its learnability and effectiveness in personalized authoring tasks. Our results demonstrate the potential of example-driven approaches for democratizing visualization creation.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fundamental limits of distributed covariance matrix estimation via a conditional strong data processing inequality</title>
<link>https://arxiv.org/abs/2507.16953</link>
<guid>https://arxiv.org/abs/2507.16953</guid>
<content:encoded><![CDATA[
arXiv:2507.16953v1 Announce Type: cross 
Abstract: Estimating high-dimensional covariance matrices is a key task across many fields. This paper explores the theoretical limits of distributed covariance estimation in a feature-split setting, where communication between agents is constrained. Specifically, we study a scenario in which multiple agents each observe different components of i.i.d. samples drawn from a sub-Gaussian random vector. A central server seeks to estimate the complete covariance matrix using a limited number of bits communicated by each agent. We obtain a nearly tight minimax lower bound for covariance matrix estimation under operator norm and Frobenius norm. Our main technical tool is a novel generalization of the strong data processing inequality (SDPI), termed the Conditional Strong Data Processing Inequality (C-SDPI) coefficient, introduced in this work. The C-SDPI coefficient shares key properties such as tensorization with the conventional SDPI. Crucially, it quantifies the average contraction in a state-dependent channel and can be significantly lower than the worst-case SDPI coefficient over the state input.
  Utilizing the doubling trick of Geng-Nair and an operator Jensen inequality, we compute this coefficient for Gaussian mixture channels. We then employ it to establish minimax lower bounds on estimation error, capturing the trade-offs among sample size, communication cost, and data dimensionality. Building on this, we present a nearly optimal estimation protocol whose sample and communication requirements match the lower bounds up to logarithmic factors. Unlike much of the existing literature, our framework does not assume infinite samples or Gaussian distributions, making it broadly applicable. Finally, we extend our analysis to interactive protocols, showing interaction can significantly reduce communication requirements compared to non-interactive schemes.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stochastically Structured Reservoir Computers for Financial and Economic System Identification</title>
<link>https://arxiv.org/abs/2507.17115</link>
<guid>https://arxiv.org/abs/2507.17115</guid>
<content:encoded><![CDATA[
arXiv:2507.17115v1 Announce Type: cross 
Abstract: This paper introduces a methodology for identifying and simulating financial and economic systems using stochastically structured reservoir computers (SSRCs). The proposed framework leverages structure-preserving embeddings and graph-informed coupling matrices to model inter-agent dynamics with enhanced interpretability. A constrained optimization scheme ensures that the learned models satisfy both stochastic and structural constraints. Two empirical case studies, a dynamic behavioral model of resource competition among agents, and regional inflation network dynamics, illustrate the effectiveness of the approach in capturing and anticipating complex nonlinear patterns and enabling interpretable predictive analysis under uncertainty.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM as a code generator in Agile Model Driven Development</title>
<link>https://arxiv.org/abs/2410.18489</link>
<guid>https://arxiv.org/abs/2410.18489</guid>
<content:encoded><![CDATA[
arXiv:2410.18489v2 Announce Type: replace 
Abstract: Leveraging Large Language Models (LLM) like GPT4 in the auto generation of code represents a significant advancement, yet it is not without its challenges. The ambiguity inherent in natural language descriptions of software poses substantial obstacles to generating deployable, structured artifacts. This research champions Model Driven Development (MDD) as a viable strategy to overcome these challenges, proposing an Agile Model Driven Development (AMDD) approach that employs GPT4 as a code generator. This approach enhances the flexibility and scalability of the code auto generation process and offers agility that allows seamless adaptation to changes in models or deployment environments. We illustrate this by modeling a multi agent Unmanned Vehicle Fleet (UVF) system using the Unified Modeling Language (UML), significantly reducing model ambiguity by integrating the Object Constraint Language (OCL) for code structure meta modeling, and the FIPA ontology language for communication semantics meta modeling. Applying GPT4 auto generation capabilities yields Java and Python code that is compatible with the JADE and PADE frameworks, respectively. Our thorough evaluation of the auto generated code verifies its alignment with expected behaviors and identifies enhancements in agent interactions. Structurally, we assessed the complexity of code derived from a model constrained solely by OCL meta models, against that influenced by both OCL and FIPA ontology meta models. The results indicate that the ontology constrained meta model produces inherently more complex code, yet its cyclomatic complexity remains within manageable levels, suggesting that additional meta model constraints can be incorporated without exceeding the high risk threshold for complexity.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Neural Strategy-Proof Matching Mechanism from Examples</title>
<link>https://arxiv.org/abs/2410.19384</link>
<guid>https://arxiv.org/abs/2410.19384</guid>
<content:encoded><![CDATA[
arXiv:2410.19384v2 Announce Type: replace 
Abstract: Designing two-sided matching mechanisms is challenging when practical demands for matching outcomes are difficult to formalize and the designed mechanism must satisfy theoretical conditions. To address this, prior work has proposed a framework that learns a matching mechanism from examples, using a parameterized family that satisfies properties such as stability. However, despite its usefulness, this framework does not guarantee strategy-proofness (SP), and cannot handle varying numbers of agents or incorporate publicly available contextual information about agents, both of which are crucial in real-world applications. In this paper, we propose a new parametrized family of matching mechanisms that always satisfy strategy-proofness, are applicable for an arbitrary number of agents, and deal with public contextual information of agents, based on the serial dictatorship (SD). This family is represented by NeuralSD, a novel neural network architecture based on SD, where agent rankings in SD are treated as learnable parameters computed from agents' contexts using an attention-based sub-network. To enable learning, we introduce tensor serial dictatorship (TSD), a differentiable relaxation of SD using tensor operations. This allows NeuralSD to be trained end-to-end from example matchings while satisfying SP. We conducted experiments to learn a matching mechanism from matching examples while satisfying SP. We demonstrated that our method outperformed baselines in predicting matchings and on several metrics for goodness of matching outcomes.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Coalition Game for On-demand Multi-modal 3D Automated Delivery System</title>
<link>https://arxiv.org/abs/2412.17252</link>
<guid>https://arxiv.org/abs/2412.17252</guid>
<content:encoded><![CDATA[
arXiv:2412.17252v2 Announce Type: replace 
Abstract: We introduce a multi-modal autonomous delivery optimization framework as a coalition game for a fleet of UAVs and ADRs operating in two overlaying networks to address last-mile delivery in urban environments, including high-density areas and time-critical applications. The problem is defined as multiple depot pickup and delivery with time windows constrained over operational restrictions, such as vehicle battery limitation, precedence time window, and building obstruction. Utilizing the coalition game theory, we investigate cooperation structures among the modes to capture how strategic collaboration can improve overall routing efficiency. To do so, a generalized reinforcement learning model is designed to evaluate the cost-sharing and allocation to different modes to learn the cooperative behaviour with respect to various realistic scenarios. Our methodology leverages an end-to-end deep multi-agent policy gradient method augmented by a novel spatio-temporal adjacency neighbourhood graph attention network using a heterogeneous edge-enhanced attention model and transformer architecture. Several numerical experiments on last-mile delivery applications have been conducted, showing the results from the case study in the city of Mississauga, which shows that despite the incorporation of an extensive network in the graph for two modes and a complex training structure, the model addresses realistic operational constraints and achieves high-quality solutions compared with the existing transformer-based and classical methods. It can perform well on non-homogeneous data distribution, generalizes well on different scales and configurations, and demonstrates a robust cooperative performance under stochastic scenarios across various tasks, which is effectively reflected by coalition analysis and cost allocation to signify the advantage of cooperation.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Privacy-Utility Trade-off in Decentralized Learning with Generalized Correlated Noise</title>
<link>https://arxiv.org/abs/2501.14644</link>
<guid>https://arxiv.org/abs/2501.14644</guid>
<content:encoded><![CDATA[
arXiv:2501.14644v2 Announce Type: replace 
Abstract: Decentralized learning enables distributed agents to collaboratively train a shared machine learning model without a central server, through local computation and peer-to-peer communication. Although each agent retains its dataset locally, sharing local models can still expose private information about the local training datasets to adversaries. To mitigate privacy attacks, a common strategy is to inject random artificial noise at each agent before exchanging local models between neighbors. However, this often leads to utility degradation due to the negative effects of cumulated artificial noise on the learning algorithm. In this work, we introduce CorN-DSGD, a novel covariance-based framework for generating correlated privacy noise across agents, which unifies several state-of-the-art methods as special cases. By leveraging network topology and mixing weights, CorN-DSGD optimizes the noise covariance to achieve network-wide noise cancellation. Experimental results show that CorN-DSGD cancels more noise than existing pairwise correlation schemes, improving model performance under formal privacy guarantees.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Learning Approach to Games</title>
<link>https://arxiv.org/abs/2503.00227</link>
<guid>https://arxiv.org/abs/2503.00227</guid>
<content:encoded><![CDATA[
arXiv:2503.00227v2 Announce Type: replace 
Abstract: This work introduces a unified framework for a more detailed exploration of games. In existing literature, strategies of players are typically assigned scalar values, and the concept of Nash equilibrium is used to identify compatible strategies. However, this approach lacks the internal structure of a player, thereby failing to accurately model observed behaviors.
  To address this limitation, we propose an abstract definition of a player. This allows for a more nuanced understanding of players and brings the focus to the challenge of learning that players face. Unlike Markov decision processes, which formalize control problems but not agent design, our framework subsumes standard reinforcement learning structures. It thus offers a language that enables a deeper connection between games and learning. To illustrate the need for such generality, we study a simple two-player game and show that even in the most basic settings, a sophisticated player may adopt dynamic strategies that cannot be captured by simpler designs or compatibility analysis alone.
  In the discrete setting, we consider a player whose structure incorporates standard estimates from the literature. We explore connections to correlated equilibrium and highlight that dynamic programming naturally applies to all estimates. In the mean-field setting, we exploit symmetry to construct explicit examples of equilibria. Finally, we examine connections to reinforcement learning and bandit problems, demonstrating the broad applicability of the framework.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ORANSight-2.0: Foundational LLMs for O-RAN</title>
<link>https://arxiv.org/abs/2503.05200</link>
<guid>https://arxiv.org/abs/2503.05200</guid>
<content:encoded><![CDATA[
arXiv:2503.05200v2 Announce Type: replace 
Abstract: Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative to develop specialized foundational LLMs tailored for O-RAN. Built on 18 models spanning five open-source LLM frameworks -- Mistral, Qwen, Llama, Phi, and Gemma -- ORANSight-2.0 fine-tunes models ranging from 1B to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance in O-RAN-specific tasks. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG)-based instruction-tuning framework that employs two LLM agents -- a Mistral-based Question Generator and a Qwen-based Answer Generator -- to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ICCO: Learning an Instruction-conditioned Coordinator for Language-guided Task-aligned Multi-robot Control</title>
<link>https://arxiv.org/abs/2503.12122</link>
<guid>https://arxiv.org/abs/2503.12122</guid>
<content:encoded><![CDATA[
arXiv:2503.12122v2 Announce Type: replace 
Abstract: Recent advances in Large Language Models (LLMs) have permitted the development of language-guided multi-robot systems, which allow robots to execute tasks based on natural language instructions. However, achieving effective coordination in distributed multi-agent environments remains challenging due to (1) misalignment between instructions and task requirements and (2) inconsistency in robot behaviors when they independently interpret ambiguous instructions. To address these challenges, we propose Instruction-Conditioned Coordinator (ICCO), a Multi-Agent Reinforcement Learning (MARL) framework designed to enhance coordination in language-guided multi-robot systems. ICCO consists of a Coordinator agent and multiple Local Agents, where the Coordinator generates Task-Aligned and Consistent Instructions (TACI) by integrating language instructions with environmental states, ensuring task alignment and behavioral consistency. The Coordinator and Local Agents are jointly trained to optimize a reward function that balances task efficiency and instruction following. A Consistency Enhancement Term is added to the learning objective to maximize mutual information between instructions and robot behaviors, further improving coordination. Simulation and real-world experiments validate the effectiveness of ICCO in achieving language-guided task-aligned multi-robot control. The demonstration can be found at https://yanoyoshiki.github.io/ICCO/.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Joint Pedestrian and Vehicle Traffic Optimization in Urban Environments using Reinforcement Learning</title>
<link>https://arxiv.org/abs/2504.05018</link>
<guid>https://arxiv.org/abs/2504.05018</guid>
<content:encoded><![CDATA[
arXiv:2504.05018v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) holds significant promise for adaptive traffic signal control. While existing RL-based methods demonstrate effectiveness in reducing vehicular congestion, their predominant focus on vehicle-centric optimization leaves pedestrian mobility needs and safety challenges unaddressed. In this paper, we present a deep RL framework for adaptive control of eight traffic signals along a real-world urban corridor, jointly optimizing both pedestrian and vehicular efficiency. Our single-agent policy is trained using real-world pedestrian and vehicle demand data derived from Wi-Fi logs and video analysis. The results demonstrate significant performance improvements over traditional fixed-time signals, reducing average wait times per pedestrian and per vehicle by up to 67% and 52% respectively, while simultaneously decreasing total wait times for both groups by up to 67% and 53%. Additionally, our results demonstrate generalization capabilities across varying traffic demands, including conditions entirely unseen during training, validating RL's potential for developing transportation systems that serve all road users.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fact-Checking with Contextual Narratives: Leveraging Retrieval-Augmented LLMs for Social Media Analysis</title>
<link>https://arxiv.org/abs/2504.10166</link>
<guid>https://arxiv.org/abs/2504.10166</guid>
<content:encoded><![CDATA[
arXiv:2504.10166v2 Announce Type: replace 
Abstract: We propose CRAVE (Cluster-based Retrieval Augmented Verification with Explanation); a novel framework that integrates retrieval-augmented Large Language Models (LLMs) with clustering techniques to address fact-checking challenges on social media. CRAVE automatically retrieves multimodal evidence from diverse, often contradictory, sources. Evidence is clustered into coherent narratives, and evaluated via an LLM-based judge to deliver fact-checking verdicts explained by evidence summaries. By synthesizing evidence from both text and image modalities and incorporating agent-based refinement, CRAVE ensures consistency and diversity in evidence representation. Comprehensive experiments demonstrate CRAVE's efficacy in retrieval precision, clustering quality, and judgment accuracy, showcasing its potential as a robust decision-support tool for fact-checkers.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RoBridge: A Hierarchical Architecture Bridging Cognition and Execution for General Robotic Manipulation</title>
<link>https://arxiv.org/abs/2505.01709</link>
<guid>https://arxiv.org/abs/2505.01709</guid>
<content:encoded><![CDATA[
arXiv:2505.01709v3 Announce Type: replace 
Abstract: Operating robots in open-ended scenarios with diverse tasks is a crucial research and application direction in robotics. While recent progress in natural language processing and large multimodal models has enhanced robots' ability to understand complex instructions, robot manipulation still faces the procedural skill dilemma and the declarative skill dilemma in open environments. Existing methods often compromise cognitive and executive capabilities. To address these challenges, in this paper, we propose RoBridge, a hierarchical intelligent architecture for general robotic manipulation. It consists of a high-level cognitive planner (HCP) based on a large-scale pre-trained vision-language model (VLM), an invariant operable representation (IOR) serving as a symbolic bridge, and a generalist embodied agent (GEA). RoBridge maintains the declarative skill of VLM and unleashes the procedural skill of reinforcement learning, effectively bridging the gap between cognition and execution. RoBridge demonstrates significant performance improvements over existing baselines, achieving a 75% success rate on new tasks and an 83% average success rate in sim-to-real generalization using only five real-world data samples per task. This work represents a significant step towards integrating cognitive reasoning with physical execution in robotic systems, offering a new paradigm for general robotic manipulation.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent RL Scaling Law: Agent RL with Spontaneous Code Execution for Mathematical Problem Solving</title>
<link>https://arxiv.org/abs/2505.07773</link>
<guid>https://arxiv.org/abs/2505.07773</guid>
<content:encoded><![CDATA[
arXiv:2505.07773v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) often struggle with mathematical reasoning tasks requiring precise, verifiable computation. While Reinforcement Learning (RL) from outcome-based rewards enhances text-based reasoning, understanding how agents autonomously learn to leverage external tools like code execution remains crucial. We investigate RL from outcome-based rewards for Tool-Integrated Reasoning, ZeroTIR, training base LLMs to spontaneously generate and execute Python code for mathematical problems without supervised tool-use examples. Our central contribution is we demonstrate that as RL training progresses, key metrics scale predictably. Specifically, we observe strong positive correlations where increased training steps lead to increases in the spontaneous code execution frequency, the average response length, and, critically, the final task accuracy. This suggests a quantifiable relationship between computational effort invested in training and the emergence of effective, tool-augmented reasoning strategies. We implement a robust framework featuring a decoupled code execution environment and validate our findings across standard RL algorithms and frameworks. Experiments show ZeroTIR significantly surpasses non-tool ZeroRL baselines on challenging math benchmarks. Our findings provide a foundational understanding of how autonomous tool use is acquired and scales within Agent RL, offering a reproducible benchmark for future studies. Code is released at \href{https://github.com/yyht/openrlhf_async_pipline}{https://github.com/yyht/openrlhf\_async\_pipline}.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Video Discovery: Agentic Search with Tool Use for Long-form Video Understanding</title>
<link>https://arxiv.org/abs/2505.18079</link>
<guid>https://arxiv.org/abs/2505.18079</guid>
<content:encoded><![CDATA[
arXiv:2505.18079v3 Announce Type: replace 
Abstract: Long-form video understanding presents significant challenges due to extensive temporal-spatial complexity and the difficulty of question answering under such extended contexts. While Large Language Models (LLMs) have demonstrated considerable advancements in video analysis capabilities and long context handling, they continue to exhibit limitations when processing information-dense hour-long videos. To overcome such limitations, we propose the Deep Video Discovery agent to leverage an agentic search strategy over segmented video clips. Different from previous video agents manually designing a rigid workflow, our approach emphasizes the autonomous nature of agents. By providing a set of search-centric tools on multi-granular video database, our DVD agent leverages the advanced reasoning capability of LLM to plan on its current observation state, strategically selects tools, formulates appropriate parameters for actions, and iteratively refines its internal reasoning in light of the gathered information. We perform comprehensive evaluation on multiple long video understanding benchmarks that demonstrates the advantage of the entire system design. Our DVD agent achieves SOTA performance, significantly surpassing prior works by a large margin on the challenging LVBench dataset. Comprehensive ablation studies and in-depth tool analyses are also provided, yielding insights to further advance intelligent agents tailored for long-form video understanding tasks. The code has been released in https://github.com/microsoft/DeepVideoDiscovery.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From DDMs to DNNs: Using process data and models of decision-making to improve human-AI interactions</title>
<link>https://arxiv.org/abs/2308.15225</link>
<guid>https://arxiv.org/abs/2308.15225</guid>
<content:encoded><![CDATA[
arXiv:2308.15225v3 Announce Type: replace-cross 
Abstract: Over the past decades, cognitive neuroscientists and behavioral economists have recognized the value of describing the process of decision making in detail and modeling the emergence of decisions over time. For example, the time it takes to decide can reveal more about an agent's true hidden preferences than only the decision itself. Similarly, data that track the ongoing decision process such as eye movements or neural recordings contain critical information that can be exploited, even if no decision is made. Here, we argue that artificial intelligence (AI) research would benefit from a stronger focus on insights about how decisions emerge over time and incorporate related process data to improve AI predictions in general and human-AI interactions in particular. First, we introduce a highly established computational framework that assumes decisions to emerge from the noisy accumulation of evidence, and we present related empirical work in psychology, neuroscience, and economics. Next, we discuss to what extent current approaches in multi-agent AI do or do not incorporate process data and models of decision making. Finally, we outline how a more principled inclusion of the evidence-accumulation framework into the training and use of AI can help to improve human-AI interactions in the future.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vascular Segmentation of Functional Ultrasound Images using Deep Learning</title>
<link>https://arxiv.org/abs/2410.22365</link>
<guid>https://arxiv.org/abs/2410.22365</guid>
<content:encoded><![CDATA[
arXiv:2410.22365v2 Announce Type: replace-cross 
Abstract: Segmentation of medical images is a fundamental task with numerous applications. While MRI, CT, and PET modalities have significantly benefited from deep learning segmentation techniques, more recent modalities, like functional ultrasound (fUS), have seen limited progress. fUS is a non invasive imaging method that measures changes in cerebral blood volume (CBV) with high spatio-temporal resolution. However, distinguishing arterioles from venules in fUS is challenging due to opposing blood flow directions within the same pixel. Ultrasound localization microscopy (ULM) can enhance resolution by tracking microbubble contrast agents but is invasive, and lacks dynamic CBV quantification. In this paper, we introduce the first deep learning-based segmentation tool for fUS images, capable of differentiating signals from different vascular compartments, based on ULM automatic annotation and enabling dynamic CBV quantification. We evaluate various UNet architectures on fUS images of rat brains, achieving competitive segmentation performance, with 90% accuracy, a 71% F1 score, and an IoU of 0.59, using only 100 temporal frames from a fUS stack. These results are comparable to those from tubular structure segmentation in other imaging modalities. Additionally, models trained on resting-state data generalize well to images captured during visual stimulation, highlighting robustness. This work offers a non-invasive, cost-effective alternative to ULM, enhancing fUS data interpretation and improving understanding of vessel function. Our pipeline shows high linear correlation coefficients between signals from predicted and actual compartments in both cortical and deeper regions, showcasing its ability to accurately capture blood flow dynamics.
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CP-uniGuard: A Unified, Probability-Agnostic, and Adaptive Framework for Malicious Agent Detection and Defense in Multi-Agent Embodied Perception Systems</title>
<link>https://arxiv.org/abs/2506.22890</link>
<guid>https://arxiv.org/abs/2506.22890</guid>
<content:encoded><![CDATA[
arXiv:2506.22890v2 Announce Type: replace 
Abstract: Collaborative Perception (CP) has been shown to be a promising technique for multi-agent autonomous driving and multi-agent robotic systems, where multiple agents share their perception information to enhance the overall perception performance and expand the perception range. However, in CP, an ego agent needs to receive messages from its collaborators, which makes it vulnerable to attacks from malicious agents. To address this critical issue, we propose a unified, probability-agnostic, and adaptive framework, namely, CP-uniGuard, which is a tailored defense mechanism for CP deployed by each agent to accurately detect and eliminate malicious agents in its collaboration network. Our key idea is to enable CP to reach a consensus rather than a conflict against an ego agent's perception results. Based on this idea, we first develop a probability-agnostic sample consensus (PASAC) method to effectively sample a subset of the collaborators and verify the consensus without prior probabilities of malicious agents. Furthermore, we define collaborative consistency loss (CCLoss) for object detection task and bird's eye view (BEV) segmentation task to capture the discrepancy between an ego agent and its collaborators, which is used as a verification criterion for consensus. In addition, we propose online adaptive threshold via dual sliding windows to dynamically adjust the threshold for consensus verification and ensure the reliability of the systems in dynamic environments. Finally, we conduct extensive experiments and demonstrate the effectiveness of our framework. Code will be released at https://github.com/CP-Security/CP-uniGuard.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NavMorph: A Self-Evolving World Model for Vision-and-Language Navigation in Continuous Environments</title>
<link>https://arxiv.org/abs/2506.23468</link>
<guid>https://arxiv.org/abs/2506.23468</guid>
<content:encoded><![CDATA[
arXiv:2506.23468v2 Announce Type: replace 
Abstract: Vision-and-Language Navigation in Continuous Environments (VLN-CE) requires agents to execute sequential navigation actions in complex environments guided by natural language instructions. Current approaches often struggle with generalizing to novel environments and adapting to ongoing changes during navigation. Inspired by human cognition, we present NavMorph, a self-evolving world model framework that enhances environmental understanding and decision-making in VLN-CE tasks. NavMorph employs compact latent representations to model environmental dynamics, equipping agents with foresight for adaptive planning and policy refinement. By integrating a novel Contextual Evolution Memory, NavMorph leverages scene-contextual information to support effective navigation while maintaining online adaptability. Extensive experiments demonstrate that our method achieves notable performance improvements on popular VLN-CE benchmarks. Code is available at https://github.com/Feliciaxyao/NavMorph.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ADEPTS: A Capability Framework for Human-Centered Agent Design</title>
<link>https://arxiv.org/abs/2507.15885</link>
<guid>https://arxiv.org/abs/2507.15885</guid>
<content:encoded><![CDATA[
arXiv:2507.15885v1 Announce Type: new 
Abstract: Large language models have paved the way to powerful and flexible AI agents, assisting humans by increasingly integrating into their daily life. This flexibility, potential, and growing adoption demands a holistic and cross-disciplinary approach to developing, monitoring and discussing the capabilities required for agent-driven user experiences. However, current guidance on human-centered AI agent development is scattered: UX heuristics focus on interface behaviors, engineering taxonomies describe internal pipelines, and ethics checklists address high-level governance. There is no concise, user-facing vocabulary that tells teams what an agent should fundamentally be able to do. We introduce ADEPTS, a capability framework defining a set of core user-facing capabilities to provide unified guidance around the development of AI agents. ADEPTS is based on six principles for human-centered agent design, that express the minimal, user-facing capabilities an AI agent should demonstrate to be understandable, controllable and trustworthy in everyday use. ADEPTS complements existing frameworks and taxonomies; differently from them, it sits at the interface between technical and experience development. By presenting ADEPTS, we aim to condense complex AI-UX requirements into a compact framework that is actionable guidance for AI researchers, designers, engineers, and policy reviewers alike. We believe ADEPTS has the potential of accelerating the improvement of user-relevant agent capabilities, of easing the design of experiences that take advantage of those capabilities, and of providing a shared language to track and discuss progress around the development of AI agents.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AlgoTune: Can Language Models Speed Up General-Purpose Numerical Programs?</title>
<link>https://arxiv.org/abs/2507.15887</link>
<guid>https://arxiv.org/abs/2507.15887</guid>
<content:encoded><![CDATA[
arXiv:2507.15887v1 Announce Type: new 
Abstract: Despite progress in language model (LM) capabilities, evaluations have thus far focused on models' performance on tasks that humans have previously solved, including in programming (Jimenez et al., 2024) and mathematics (Glazer et al., 2024). We therefore propose testing models' ability to design and implement algorithms in an open-ended benchmark: We task LMs with writing code that efficiently solves computationally challenging problems in computer science, physics, and mathematics. Our AlgoTune benchmark consists of 155 coding tasks collected from domain experts and a framework for validating and timing LM-synthesized solution code, which is compared to reference implementations from popular open-source packages. In addition, we develop a baseline LM agent, AlgoTuner, and evaluate its performance across a suite of frontier models. AlgoTuner achieves an average 1.72x speedup against our reference solvers, which use libraries such as SciPy, sk-learn and CVXPY. However, we find that current models fail to discover algorithmic innovations, instead preferring surface-level optimizations. We hope that AlgoTune catalyzes the development of LM agents exhibiting creative problem solving beyond state-of-the-art human performance.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StaAgent: An Agentic Framework for Testing Static Analyzers</title>
<link>https://arxiv.org/abs/2507.15892</link>
<guid>https://arxiv.org/abs/2507.15892</guid>
<content:encoded><![CDATA[
arXiv:2507.15892v1 Announce Type: new 
Abstract: Static analyzers play a critical role in identifying bugs early in the software development lifecycle, but their rule implementations are often under-tested and prone to inconsistencies. To address this, we propose StaAgent, an agentic framework that harnesses the generative capabilities of Large Language Models (LLMs) to systematically evaluate static analyzer rules. StaAgent comprises four specialized agents: a Seed Generation Agent that translates bug detection rules into concrete, bug-inducing seed programs; a Code Validation Agent that ensures the correctness of these seeds; a Mutation Generation Agent that produces semantically equivalent mutants; and an Analyzer Evaluation Agent that performs metamorphic testing by comparing the static analyzer's behavior on seeds and their corresponding mutants. By revealing inconsistent behaviors, StaAgent helps uncover flaws in rule implementations. This LLM-driven, multi-agent framework offers a scalable and adaptable solution to improve the reliability of static analyzers. We evaluated StaAgent with five state-of-the-art LLMs (CodeL-lama, DeepSeek, Codestral, Qwen, and GPT-4o) across five widely used static analyzers (SpotBugs, SonarQube, ErrorProne, Infer, and PMD). The experimental results show that our approach can help reveal 64 problematic rules in the latest versions of these five static analyzers (i.e., 28 in SpotBugs, 18 in SonarQube, 6 in ErrorProne, 4 in Infer, and 8 in PMD). In addition, 53 out of the 64 bugs cannot be detected by the SOTA baseline. We have reported all the bugs to developers, with two of them already fixed. Three more have been confirmed by developers, while the rest are awaiting response. These results demonstrate the effectiveness of our approach and underscore the promise of agentic, LLM-driven data synthesis to advance software engineering.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Integrating Reason-Based Moral Decision-Making in the Reinforcement Learning Architecture</title>
<link>https://arxiv.org/abs/2507.15895</link>
<guid>https://arxiv.org/abs/2507.15895</guid>
<content:encoded><![CDATA[
arXiv:2507.15895v1 Announce Type: new 
Abstract: Reinforcement Learning is a machine learning methodology that has demonstrated strong performance across a variety of tasks. In particular, it plays a central role in the development of artificial autonomous agents. As these agents become increasingly capable, market readiness is rapidly approaching, which means those agents, for example taking the form of humanoid robots or autonomous cars, are poised to transition from laboratory prototypes to autonomous operation in real-world environments. This transition raises concerns leading to specific requirements for these systems - among them, the requirement that they are designed to behave ethically. Crucially, research directed toward building agents that fulfill the requirement to behave ethically - referred to as artificial moral agents(AMAs) - has to address a range of challenges at the intersection of computer science and philosophy. This study explores the development of reason-based artificial moral agents (RBAMAs). RBAMAs are build on an extension of the reinforcement learning architecture to enable moral decision-making based on sound normative reasoning, which is achieved by equipping the agent with the capacity to learn a reason-theory - a theory which enables it to process morally relevant propositions to derive moral obligations - through case-based feedback. They are designed such that they adapt their behavior to ensure conformance to these obligations while they pursue their designated tasks. These features contribute to the moral justifiability of the their actions, their moral robustness, and their moral trustworthiness, which proposes the extended architecture as a concrete and deployable framework for the development of AMAs that fulfills key ethical desiderata. This study presents a first implementation of an RBAMA and demonstrates the potential of RBAMAs in initial experiments.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Responsible Innovation in Agentic AI: A study of Ethical Frameworks for Household Automation</title>
<link>https://arxiv.org/abs/2507.15901</link>
<guid>https://arxiv.org/abs/2507.15901</guid>
<content:encoded><![CDATA[
arXiv:2507.15901v1 Announce Type: new 
Abstract: The implementation of Artificial Intelligence (AI) in household environments, especially in the form of proactive autonomous agents, brings about possibilities of comfort and attention as well as it comes with intra or extramural ethical challenges. This article analyzes agentic AI and its applications, focusing on its move from reactive to proactive autonomy, privacy, fairness and user control. We review responsible innovation frameworks, human-centered design principles, and governance practices to distill practical guidance for ethical smart home systems. Vulnerable user groups such as elderly individuals, children, and neurodivergent who face higher risks of surveillance, bias, and privacy risks were studied in detail in context of Agentic AI. Design imperatives are highlighted such as tailored explainability, granular consent mechanisms, and robust override controls, supported by participatory and inclusive methodologies. It was also explored how data-driven insights, including social media analysis via Natural Language Processing(NLP), can inform specific user needs and ethical concerns. This survey aims to provide both a conceptual foundation and suggestions for developing transparent, inclusive, and trustworthy agentic AI in household automation.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Mitigation of Hallucination for LLM-empowered Agents: Progressive Generalization Bound Exploration and Watchdog Monitor</title>
<link>https://arxiv.org/abs/2507.15903</link>
<guid>https://arxiv.org/abs/2507.15903</guid>
<content:encoded><![CDATA[
arXiv:2507.15903v1 Announce Type: new 
Abstract: Empowered by large language models (LLMs), intelligent agents have become a popular paradigm for interacting with open environments to facilitate AI deployment. However, hallucinations generated by LLMs-where outputs are inconsistent with facts-pose a significant challenge, undermining the credibility of intelligent agents. Only if hallucinations can be mitigated, the intelligent agents can be used in real-world without any catastrophic risk. Therefore, effective detection and mitigation of hallucinations are crucial to ensure the dependability of agents. Unfortunately, the related approaches either depend on white-box access to LLMs or fail to accurately identify hallucinations. To address the challenge posed by hallucinations of intelligent agents, we present HalMit, a novel black-box watchdog framework that models the generalization bound of LLM-empowered agents and thus detect hallucinations without requiring internal knowledge of the LLM's architecture. Specifically, a probabilistic fractal sampling technique is proposed to generate a sufficient number of queries to trigger the incredible responses in parallel, efficiently identifying the generalization bound of the target agent. Experimental evaluations demonstrate that HalMit significantly outperforms existing approaches in hallucination monitoring. Its black-box nature and superior performance make HalMit a promising solution for enhancing the dependability of LLM-powered systems.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HyDRA: A Hybrid-Driven Reasoning Architecture for Verifiable Knowledge Graphs</title>
<link>https://arxiv.org/abs/2507.15917</link>
<guid>https://arxiv.org/abs/2507.15917</guid>
<content:encoded><![CDATA[
arXiv:2507.15917v1 Announce Type: new 
Abstract: The synergy between symbolic knowledge, often represented by Knowledge Graphs (KGs), and the generative capabilities of neural networks is central to advancing neurosymbolic AI. A primary bottleneck in realizing this potential is the difficulty of automating KG construction, which faces challenges related to output reliability, consistency, and verifiability. These issues can manifest as structural inconsistencies within the generated graphs, such as the formation of disconnected $\textit{isolated islands}$ of data or the inaccurate conflation of abstract classes with specific instances. To address these challenges, we propose HyDRA, a $\textbf{Hy}$brid-$\textbf{D}$riven $\textbf{R}$easoning $\textbf{A}$rchitecture designed for verifiable KG automation. Given a domain or an initial set of documents, HyDRA first constructs an ontology via a panel of collaborative neurosymbolic agents. These agents collaboratively agree on a set of competency questions (CQs) that define the scope and requirements the ontology must be able to answer. Given these CQs, we build an ontology graph that subsequently guides the automated extraction of triplets for KG generation from arbitrary documents. Inspired by design-by-contracts (DbC) principles, our method leverages verifiable contracts as the primary control mechanism to steer the generative process of Large Language Models (LLMs). To verify the output of our approach, we extend beyond standard benchmarks and propose an evaluation framework that assesses the functional correctness of the resulting KG by leveraging symbolic verifications as described by the neurosymbolic AI framework, $\textit{SymbolicAI}$. This work contributes a hybrid-driven architecture for improving the reliability of automated KG construction and the exploration of evaluation methods for measuring the functional integrity of its output. The code is publicly available.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Pilot Study on LLM-Based Agentic Translation from Android to iOS: Pitfalls and Insights</title>
<link>https://arxiv.org/abs/2507.16037</link>
<guid>https://arxiv.org/abs/2507.16037</guid>
<content:encoded><![CDATA[
arXiv:2507.16037v1 Announce Type: new 
Abstract: The rapid advancement of mobile applications has led to a significant demand for cross-platform compatibility, particularly between the Android and iOS platforms. Traditional approaches to mobile application translation often rely on manual intervention or rule-based systems, which are labor-intensive and time-consuming. While recent advancements in machine learning have introduced automated methods, they often lack contextual understanding and adaptability, resulting in suboptimal translations. Large Language Models (LLMs) were recently leveraged to enhance code translation at different granularities, including the method, class, and repository levels. Researchers have investigated common errors, limitations, and potential strategies to improve these tasks. However, LLM-based application translation across different platforms, such as migrating mobile applications between Android and iOS or adapting software across diverse frameworks, remains underexplored. Understanding the performance, strengths, and limitations of LLMs in cross-platform application translation is critical for advancing software engineering automation. This study aims to fill this gap by evaluating LLM-based agentic approaches for mobile application translation, identifying key failure points, and proposing guidelines to improve translation performance. We developed a chain of agents that account for dependencies, specifications, program structure, and program control flow when translating applications from Android to iOS. To evaluate the performance, we manually examined the translated code for syntactic correctness, semantic accuracy, and functional completeness. For translation failures, we further conducted a detailed root cause analysis to understand the underlying limitations of the agentic translation process and identify opportunities for improvement.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Making REST APIs Agent-Ready: From OpenAPI to Model Context Protocol Servers for Tool-Augmented LLMs</title>
<link>https://arxiv.org/abs/2507.16044</link>
<guid>https://arxiv.org/abs/2507.16044</guid>
<content:encoded><![CDATA[
arXiv:2507.16044v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are evolving from passive text generators into active agents that invoke external tools. To support this shift, scalable protocols for tool integration are essential. The Model Context Protocol (MCP), introduced by Anthropic in 2024, offers a schema-driven standard for dynamic tool discovery and invocation. Yet, building MCP servers remains manual and repetitive, requiring developers to write glue code, handle authentication, and configure schemas by hand-replicating much of the integration effort MCP aims to eliminate.
  This paper investigates whether MCP server construction can be meaningfully automated. We begin by analyzing adoption trends: among 22,000+ MCP-tagged GitHub repositories created within six months of release, fewer than 5% include servers, typically small, single-maintainer projects dominated by repetitive scaffolding. To address this gap, we present AutoMCP, a compiler that generates MCP servers from OpenAPI 2.0/3.0 specifications. AutoMCP parses REST API definitions and produces complete server implementations, including schema registration and authentication handling.
  We evaluate AutoMCP on 50 real-world APIs spanning 5,066 endpoints across over 10 domains. From a stratified sample of 1,023 tool calls, 76.5% succeeded out of the box. Manual failure analysis revealed five recurring issues, all attributable to inconsistencies or omissions in the OpenAPI contracts. After minor fixes, averaging 19 lines of spec changes per API, AutoMCP achieved 99.9% success.
  Our findings (i) analyze MCP adoption and quantify the cost of manual server development, (ii) demonstrate that OpenAPI specifications, despite quality issues, enable near-complete MCP server automation, and (iii) contribute a corpus of 5,066 callable tools along with insights on repairing common specification flaws.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Researcher with Test-Time Diffusion</title>
<link>https://arxiv.org/abs/2507.16075</link>
<guid>https://arxiv.org/abs/2507.16075</guid>
<content:encoded><![CDATA[
arXiv:2507.16075v1 Announce Type: new 
Abstract: Deep research agents, powered by Large Language Models (LLMs), are rapidly advancing; yet, their performance often plateaus when generating complex, long-form research reports using generic test-time scaling algorithms. Drawing inspiration from the iterative nature of human research, which involves cycles of searching, reasoning, and revision, we propose the Test-Time Diffusion Deep Researcher (TTD-DR). This novel framework conceptualizes research report generation as a diffusion process. TTD-DR initiates this process with a preliminary draft, an updatable skeleton that serves as an evolving foundation to guide the research direction. The draft is then iteratively refined through a "denoising" process, which is dynamically informed by a retrieval mechanism that incorporates external information at each step. The core process is further enhanced by a self-evolutionary algorithm applied to each component of the agentic workflow, ensuring the generation of high-quality context for the diffusion process. This draft-centric design makes the report writing process more timely and coherent while reducing information loss during the iterative search process. We demonstrate that our TTD-DR achieves state-of-the-art results on a wide array of benchmarks that require intensive search and multi-hop reasoning, significantly outperforming existing deep research agents.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Expert-Guided LLM Reasoning for Battery Discovery: From AI-Driven Hypothesis to Synthesis and Characterization</title>
<link>https://arxiv.org/abs/2507.16110</link>
<guid>https://arxiv.org/abs/2507.16110</guid>
<content:encoded><![CDATA[
arXiv:2507.16110v1 Announce Type: new 
Abstract: Large language models (LLMs) leverage chain-of-thought (CoT) techniques to tackle complex problems, representing a transformative breakthrough in artificial intelligence (AI). However, their reasoning capabilities have primarily been demonstrated in solving math and coding problems, leaving their potential for domain-specific applications-such as battery discovery-largely unexplored. Inspired by the idea that reasoning mirrors a form of guided search, we introduce ChatBattery, a novel agentic framework that integrates domain knowledge to steer LLMs toward more effective reasoning in materials design. Using ChatBattery, we successfully identify, synthesize, and characterize three novel lithium-ion battery cathode materials, which achieve practical capacity improvements of 28.8%, 25.2%, and 18.5%, respectively, over the widely used cathode material, LiNi0.8Mn0.1Co0.1O2 (NMC811). Beyond this discovery, ChatBattery paves a new path by showing a successful LLM-driven and reasoning-based platform for battery materials invention. This complete AI-driven cycle-from design to synthesis to characterization-demonstrates the transformative potential of AI-driven reasoning in revolutionizing materials discovery.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking LLM Privacy Recognition for Social Robot Decision Making</title>
<link>https://arxiv.org/abs/2507.16124</link>
<guid>https://arxiv.org/abs/2507.16124</guid>
<content:encoded><![CDATA[
arXiv:2507.16124v1 Announce Type: new 
Abstract: Social robots are embodied agents that interact with people while following human communication norms. These robots interact using verbal and non-verbal cues, and share the physical environments of people. While social robots have previously utilized rule-based systems or probabilistic models for user interaction, the rapid evolution of large language models (LLMs) presents new opportunities to develop LLM-empowered social robots for enhanced human-robot interaction. To fully realize these capabilities, however, robots need to collect data such as audio, fine-grained images, video, and locations. As a result, LLMs often process sensitive personal information, particularly within home environments. Given the tension between utility and privacy risks, evaluating how current LLMs manage sensitive data is critical. Specifically, we aim to explore the extent to which out-of-the-box LLMs are privacy-aware in the context of household social robots. In this study, we present a set of privacy-relevant scenarios crafted through the lens of Contextual Integrity (CI). We first survey users' privacy preferences regarding in-home social robot behaviors and then examine how their privacy orientation affects their choices of these behaviors (N = 450). We then provide the same set of scenarios and questions to state-of-the-art LLMs (N = 10) and find that the agreement between humans and LLMs is low. To further investigate the capabilities of LLMs as a potential privacy controller, we implement four additional prompting strategies and compare their results. Finally, we discuss the implications and potential of AI privacy awareness in human-robot interaction.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergent Cognitive Convergence via Implementation: A Structured Loop Reflecting Four Theories of Mind (A Position Paper)</title>
<link>https://arxiv.org/abs/2507.16184</link>
<guid>https://arxiv.org/abs/2507.16184</guid>
<content:encoded><![CDATA[
arXiv:2507.16184v1 Announce Type: new 
Abstract: We report the discovery of a structural convergence across four influential theories of mind: Kahneman's dual-system theory, Friston's predictive processing, Minsky's society of mind, and Clark's extended mind-emerging unintentionally within a practical AI agent architecture called Agentic Flow. Designed to address limitations in large language models (LLMs), Agentic Flow comprises five interdependent modules such as Retrieval, Cognition, Control, Memory, and Action arranged in a recurrent cognitive loop. Although originally inspired only by Minsky and Clark, the system's structure retrospectively aligns with computational motifs found in all four theories, including predictive modeling, associative recall, and error-sensitive control.
  To assess this convergence, we conducted comparative experiments with baseline LLM agents on multi-step reasoning tasks. The structured agent achieved 95.8% task success and exhibited strong constraint adherence, while the baseline system succeeded 62.3% of the time. These results were not aimed at proving superiority, but at illustrating how theoretical structures may emerge through practical design choices rather than top-down theory.
  We introduce PEACE as a descriptive meta-architecture that captures design-level regularities observed in Agentic Flow. Not intended as a new theory, PEACE provides a shared vocabulary for understanding architectures shaped by real-world implementation demands. This paper should be read as a position paper - an exploratory reflection on how implementation can surface latent structural echoes of cognitive theory, without asserting theoretical unification.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Do Large Language Models Have a Planning Theory of Mind? Evidence from MindGames: a Multi-Step Persuasion Task</title>
<link>https://arxiv.org/abs/2507.16196</link>
<guid>https://arxiv.org/abs/2507.16196</guid>
<content:encoded><![CDATA[
arXiv:2507.16196v1 Announce Type: new 
Abstract: Recent evidence suggests Large Language Models (LLMs) display Theory of Mind (ToM) abilities. Most ToM experiments place participants in a spectatorial role, wherein they predict and interpret other agents' behavior. However, human ToM also contributes to dynamically planning action and strategically intervening on others' mental states. We present MindGames: a novel `planning theory of mind' (PToM) task which requires agents to infer an interlocutor's beliefs and desires to persuade them to alter their behavior. Unlike previous evaluations, we explicitly evaluate use cases of ToM. We find that humans significantly outperform o1-preview (an LLM) at our PToM task (11% higher; $p=0.006$). We hypothesize this is because humans have an implicit causal model of other agents (e.g., they know, as our task requires, to ask about people's preferences). In contrast, o1-preview outperforms humans in a baseline condition which requires a similar amount of planning but minimal mental state inferences (e.g., o1-preview is better than humans at planning when already given someone's preferences). These results suggest a significant gap between human-like social reasoning and LLM abilities.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RealBench: Benchmarking Verilog Generation Models with Real-World IP Designs</title>
<link>https://arxiv.org/abs/2507.16200</link>
<guid>https://arxiv.org/abs/2507.16200</guid>
<content:encoded><![CDATA[
arXiv:2507.16200v1 Announce Type: new 
Abstract: The automatic generation of Verilog code using Large Language Models (LLMs) has garnered significant interest in hardware design automation. However, existing benchmarks for evaluating LLMs in Verilog generation fall short in replicating real-world design workflows due to their designs' simplicity, inadequate design specifications, and less rigorous verification environments. To address these limitations, we present RealBench, the first benchmark aiming at real-world IP-level Verilog generation tasks. RealBench features complex, structured, real-world open-source IP designs, multi-modal and formatted design specifications, and rigorous verification environments, including 100% line coverage testbenches and a formal checker. It supports both module-level and system-level tasks, enabling comprehensive assessments of LLM capabilities. Evaluations on various LLMs and agents reveal that even one of the best-performing LLMs, o1-preview, achieves only a 13.3% pass@1 on module-level tasks and 0% on system-level tasks, highlighting the need for stronger Verilog generation models in the future. The benchmark is open-sourced at https://github.com/IPRC-DIP/RealBench.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CHIMERA: Compressed Hybrid Intelligence for Twin-Model Enhanced Multi-Agent Deep Reinforcement Learning for Multi-Functional RIS-Assisted Space-Air-Ground Integrated Networks</title>
<link>https://arxiv.org/abs/2507.16204</link>
<guid>https://arxiv.org/abs/2507.16204</guid>
<content:encoded><![CDATA[
arXiv:2507.16204v1 Announce Type: new 
Abstract: A space-air-ground integrated network (SAGIN) architecture is proposed, empowered by multi-functional reconfigurable intelligent surfaces (MF-RIS) capable of simultaneously reflecting, amplifying, and harvesting wireless energy. The MF-RIS plays a pivotal role in addressing the energy shortages of low-Earth orbit (LEO) satellites operating in shadowed regions, while explicitly accounting for both communication and computing energy consumption across the SAGIN nodes. To maximize the long-term energy efficiency (EE), we formulate a joint optimization problem over the MF-RIS parameters, including signal amplification, phase-shifts, energy harvesting ratio, and active element selection as well as the SAGIN parameters of beamforming vectors, high-altitude platform station (HAPS) deployment, user association, and computing capability. The formulated problem is highly non-convex and non-linear and contains mixed discrete-continuous parameters. To tackle this, we conceive a compressed hybrid intelligence for twin-model enhanced multi-agent deep reinforcement learning (CHIMERA) framework, which integrates semantic state-action compression and parametrized sharing under hybrid reinforcement learning to efficiently explore suitable complex actions. The simulation results have demonstrated that the proposed CHIMERA scheme substantially outperforms the conventional benchmarks, including fixed-configuration or non-harvesting MF-RIS, traditional RIS, and no-RIS cases, as well as centralized and multi-agent deep reinforcement learning baselines in terms of the highest EE. Moreover, the proposed SAGIN-MF-RIS architecture achieves superior EE performance due to its complementary coverage, offering notable advantages over either standalone satellite, aerial, or ground-only deployments.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Best-of-Both-Worlds Guarantees with Fairer Endings</title>
<link>https://arxiv.org/abs/2507.16209</link>
<guid>https://arxiv.org/abs/2507.16209</guid>
<content:encoded><![CDATA[
arXiv:2507.16209v1 Announce Type: new 
Abstract: Fair allocation of indivisible goods is a fundamental problem at the interface of economics and computer science. Traditional approaches focus either on randomized allocations that are fair in expectation or deterministic allocations that are approximately fair. Recent work reconciles both these approaches via best-of-both-worlds guarantees, wherein one seeks randomized allocations that are fair in expectation (ex-ante fair) while being supported on approximately fair allocations (ex-post fair). Prior work has shown that under additive valuations, there always exists a randomized allocation that is ex-ante stochastic-dominance envy-free (sd-EF) and ex-post envy-free up to one good (EF1).
  Our work is motivated by the goal of achieving stronger ex-post fairness guarantees such as envy-freeness up to any good (EFX) along with meaningful ex-ante guarantees. We make the following contributions:
  1) We first consider lexicographic preferences, a subdomain of additive valuations where ex-post EFX allocations always exist and can be computed efficiently. On the negative side, we show that ex-ante sd-EF is fundamentally incompatible with ex-post EFX, prompting a relaxation of the ex-ante benchmark. We then present a poly. time algorithm that achieves ex-post EFX and PO together with ex-ante 9/10-EF. Our algorithm uses dependent rounding and leverages structural properties of EFX and PO allocations.
  2)For monotone valuations, we study EFX-with-charity: a relaxation of EFX where some goods remain unallocated, with no agent envying the unallocated pool. We show that ex-post EFX-with-charity can be achieved alongside ex-ante 0.5-EF.
  3)Finally, for subadditive valuations, we strengthen our previous ex-post guarantee to EFX-with-bounded-charity, where at most n-1 goods (n= no. of agents) remain unallocated, at the price of weakening the ex-ante guarantee to 0.5-proportionality.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Voice-based AI Agents: Filling the Economic Gaps in Digital Health Delivery</title>
<link>https://arxiv.org/abs/2507.16229</link>
<guid>https://arxiv.org/abs/2507.16229</guid>
<content:encoded><![CDATA[
arXiv:2507.16229v1 Announce Type: new 
Abstract: The integration of voice-based AI agents in healthcare presents a transformative opportunity to bridge economic and accessibility gaps in digital health delivery. This paper explores the role of large language model (LLM)-powered voice assistants in enhancing preventive care and continuous patient monitoring, particularly in underserved populations. Drawing insights from the development and pilot study of Agent PULSE (Patient Understanding and Liaison Support Engine) -- a collaborative initiative between IBM Research, Cleveland Clinic Foundation, and Morehouse School of Medicine -- we present an economic model demonstrating how AI agents can provide cost-effective healthcare services where human intervention is economically unfeasible. Our pilot study with 33 inflammatory bowel disease patients revealed that 70\% expressed acceptance of AI-driven monitoring, with 37\% preferring it over traditional modalities. Technical challenges, including real-time conversational AI processing, integration with healthcare systems, and privacy compliance, are analyzed alongside policy considerations surrounding regulation, bias mitigation, and patient autonomy. Our findings suggest that AI-driven voice agents not only enhance healthcare scalability and efficiency but also improve patient engagement and accessibility. For healthcare executives, our cost-utility analysis demonstrates huge potential savings for routine monitoring tasks, while technologists can leverage our framework to prioritize improvements yielding the highest patient impact. By addressing current limitations and aligning AI development with ethical and regulatory frameworks, voice-based AI agents can serve as a critical entry point for equitable, sustainable digital healthcare solutions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FinResearchBench: A Logic Tree based Agent-as-a-Judge Evaluation Framework for Financial Research Agents</title>
<link>https://arxiv.org/abs/2507.16248</link>
<guid>https://arxiv.org/abs/2507.16248</guid>
<content:encoded><![CDATA[
arXiv:2507.16248v1 Announce Type: new 
Abstract: Recently, AI agents are rapidly evolving in intelligence and widely used in professional research applications, such as STEM, software development, finance, etc. Among these AI agents, deep research agent is a key category as it can perform long-horizon tasks and solve problems of greater complexity. However, there are few evaluation frameworks and benchmarks that systematically and automatically investigate the capabilities of these research agents. Furthermore, financial research problems have distinct complexity and subtlety. To fill in the gap, we propose FinResearchBench, which is a logic tree based Agent-as-a-Judge and targets specifically for the financial research agents. It provides a comprehensive and automatic assessment of the research agents across 7 key types of tasks in the financial research domain. The contributions of this work are two-folded: (1) the first and innovative Agent-as-a-Judge system that extracts the logic tree of the research outcome and uses it as the intermediate information to present a comprehensive, reliable and robust evaluation; (2) finance oriented that it covers 70 typical financial research questions, spreading across 7 frequently encountered types of tasks in the domain.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Reinforcement Learning for Sample-Efficient Deep Neural Network Mapping</title>
<link>https://arxiv.org/abs/2507.16249</link>
<guid>https://arxiv.org/abs/2507.16249</guid>
<content:encoded><![CDATA[
arXiv:2507.16249v1 Announce Type: new 
Abstract: Mapping deep neural networks (DNNs) to hardware is critical for optimizing latency, energy consumption, and resource utilization, making it a cornerstone of high-performance accelerator design. Due to the vast and complex mapping space, reinforcement learning (RL) has emerged as a promising approach-but its effectiveness is often limited by sample inefficiency. We present a decentralized multi-agent reinforcement learning (MARL) framework designed to overcome this challenge. By distributing the search across multiple agents, our framework accelerates exploration. To avoid inefficiencies from training multiple agents in parallel, we introduce an agent clustering algorithm that assigns similar mapping parameters to the same agents based on correlation analysis. This enables a decentralized, parallelized learning process that significantly improves sample efficiency. Experimental results show our MARL approach improves sample efficiency by 30-300x over standard single-agent RL, achieving up to 32.61x latency reduction and 16.45x energy-delay product (EDP) reduction under iso-sample conditions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ResearcherBench: Evaluating Deep AI Research Systems on the Frontiers of Scientific Inquiry</title>
<link>https://arxiv.org/abs/2507.16280</link>
<guid>https://arxiv.org/abs/2507.16280</guid>
<content:encoded><![CDATA[
arXiv:2507.16280v1 Announce Type: new 
Abstract: The emergence of deep research systems presents significant capabilities in problem-solving, extending from basic queries to sophisticated research tasks. However, existing benchmarks primarily evaluate these systems as agents for web retrieval and report generation, overlooking their potential to discover novel insights on the frontiers of scientific research. To address this gap, we introduce ResearcherBench, the first benchmark focused on evaluating the capabilities of these advanced, agentic systems - which we refer to as Deep AI Research Systems (DARS) - on frontier AI scientific questions. We compiled a dataset of 65 research questions expertly selected from real-world scientific scenarios such as laboratory discussions and interviews, spanning 35 different AI subjects and categorized into three types: technical details, literature review, and open consulting. Our dual evaluation framework combines rubric assessment, which uses expert-designed criteria to evaluate insight quality, with factual assessment, which measures citation accuracy (faithfulness) and coverage (groundedness). We evaluated several leading commercial DARS and baseline systems. Results show that OpenAI Deep Research and Gemini Deep Research significantly outperform other systems, with particular strength in open-ended consulting questions. Such capabilities represent a meaningful step toward AI self-improvement, aligning with the vision of ASI for AI. We open-source ResearcherBench to provide a standardized platform for promoting the development of next-generation AI research assistants, hoping to foster a new perspective in AI research evaluation for a novel pattern of scientific collaboration: https://github.com/GAIR-NLP/ResearcherBench.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COMPASS: Cooperative Multi-Agent Persistent Monitoring using Spatio-Temporal Attention Network</title>
<link>https://arxiv.org/abs/2507.16306</link>
<guid>https://arxiv.org/abs/2507.16306</guid>
<content:encoded><![CDATA[
arXiv:2507.16306v1 Announce Type: new 
Abstract: Persistent monitoring of dynamic targets is essential in real-world applications such as disaster response, environmental sensing, and wildlife conservation, where mobile agents must continuously gather information under uncertainty. We propose COMPASS, a multi-agent reinforcement learning (MARL) framework that enables decentralized agents to persistently monitor multiple moving targets efficiently. We model the environment as a graph, where nodes represent spatial locations and edges capture topological proximity, allowing agents to reason over structured layouts and revisit informative regions as needed. Each agent independently selects actions based on a shared spatio-temporal attention network that we design to integrate historical observations and spatial context. We model target dynamics using Gaussian Processes (GPs), which support principled belief updates and enable uncertainty-aware planning. We train COMPASS using centralized value estimation and decentralized policy execution under an adaptive reward setting. Our extensive experiments demonstrate that COMPASS consistently outperforms strong baselines in uncertainty reduction, target coverage, and coordination efficiency across dynamic multi-target scenarios.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Application of LLM Guided Reinforcement Learning in Formation Control with Collision Avoidance</title>
<link>https://arxiv.org/abs/2507.16382</link>
<guid>https://arxiv.org/abs/2507.16382</guid>
<content:encoded><![CDATA[
arXiv:2507.16382v1 Announce Type: new 
Abstract: Multi-Agent Systems (MAS) excel at accomplishing complex objectives through the collaborative efforts of individual agents. Among the methodologies employed in MAS, Multi-Agent Reinforcement Learning (MARL) stands out as one of the most efficacious algorithms. However, when confronted with the complex objective of Formation Control with Collision Avoidance (FCCA): designing an effective reward function that facilitates swift convergence of the policy network to an optimal solution. In this paper, we introduce a novel framework that aims to overcome this challenge. By giving large language models (LLMs) on the prioritization of tasks and the observable information available to each agent, our framework generates reward functions that can be dynamically adjusted online based on evaluation outcomes by employing more advanced evaluation metrics rather than the rewards themselves. This mechanism enables the MAS to simultaneously achieve formation control and obstacle avoidance in dynamic environments with enhanced efficiency, requiring fewer iterations to reach superior performance levels. Our empirical studies, conducted in both simulation and real-world settings, validate the practicality and effectiveness of our proposed approach.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Driven Collaborative Model for Untangling Commits via Explicit and Implicit Dependency Reasoning</title>
<link>https://arxiv.org/abs/2507.16395</link>
<guid>https://arxiv.org/abs/2507.16395</guid>
<content:encoded><![CDATA[
arXiv:2507.16395v1 Announce Type: new 
Abstract: Atomic commits, each of which addresses a single development concern, are a best practice in software development. However, developers frequently produce tangled commits that mix unrelated changes due to practical constraints or unclear boundaries, negatively impacting code review and maintenance. Although prior commit untangling approaches: rule-based, feature-based, or graph-based, have made progress, they often rely on shallow signals and fail to distinguish between explicit dependencies (e.g., control/data flow) and implicit ones (e.g., semantic or conceptual relationships). In this paper, we propose ColaUntangle, a new collaborative consultation framework for commit untangling that models both explicit and implicit dependencies among code changes. ColaUntangle integrates Large Language Model (LLM)-driven agents in a multi-agent architecture: one agent specializes in explicit dependencies, another in implicit ones, and a reviewer agent synthesizes their perspectives through iterative consultation. To capture explicit and implicit contextual information, we construct multi-version Program Dependency Graphs (delta-PDG), enabling agents to reason over code relationships with both symbolic and semantic depth. We evaluate ColaUntangle on two widely-used datasets (1,612 C# and 14k Java tangled commits). Experimental results show that ColaUntangle outperforms the best-performing baseline, achieving an improvement of 44% on the C# dataset and 100% on the Java dataset. These findings highlight the potential of LLM-based collaborative frameworks for advancing automated commit untangling tasks.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From model-based learning to model-free behaviour with Meta-Interpretive Learning</title>
<link>https://arxiv.org/abs/2507.16434</link>
<guid>https://arxiv.org/abs/2507.16434</guid>
<content:encoded><![CDATA[
arXiv:2507.16434v1 Announce Type: new 
Abstract: A "model" is a theory that describes the state of an environment and the effects of an agent's decisions on the environment. A model-based agent can use its model to predict the effects of its future actions and so plan ahead, but must know the state of the environment. A model-free agent cannot plan, but can act without a model and without completely observing the environment. An autonomous agent capable of acting independently in novel environments must combine both sets of capabilities. We show how to create such an agent with Meta-Interpretive Learning used to learn a model-based Solver used to train a model-free Controller that can solve the same planning problems as the Solver. We demonstrate the equivalence in problem-solving ability of the two agents on grid navigation problems in two kinds of environment: randomly generated mazes, and lake maps with wide open areas. We find that all navigation problems solved by the Solver are also solved by the Controller, indicating the two are equivalent.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RIS-aided Latent Space Alignment for Semantic Channel Equalization</title>
<link>https://arxiv.org/abs/2507.16450</link>
<guid>https://arxiv.org/abs/2507.16450</guid>
<content:encoded><![CDATA[
arXiv:2507.16450v1 Announce Type: new 
Abstract: Semantic communication systems introduce a new paradigm in wireless communications, focusing on transmitting the intended meaning rather than ensuring strict bit-level accuracy. These systems often rely on Deep Neural Networks (DNNs) to learn and encode meaning directly from data, enabling more efficient communication. However, in multi-user settings where interacting agents are trained independently-without shared context or joint optimization-divergent latent representations across AI-native devices can lead to semantic mismatches, impeding mutual understanding even in the absence of traditional transmission errors. In this work, we address semantic mismatch in Multiple-Input Multiple-Output (MIMO) channels by proposing a joint physical and semantic channel equalization framework that leverages the presence of Reconfigurable Intelligent Surfaces (RIS). The semantic equalization is implemented as a sequence of transformations: (i) a pre-equalization stage at the transmitter; (ii) propagation through the RIS-aided channel; and (iii) a post-equalization stage at the receiver. We formulate the problem as a constrained Minimum Mean Squared Error (MMSE) optimization and propose two solutions: (i) a linear semantic equalization chain, and (ii) a non-linear DNN-based semantic equalizer. Both methods are designed to operate under semantic compression in the latent space and adhere to transmit power constraints. Through extensive evaluations, we show that the proposed joint equalization strategies consistently outperform conventional, disjoint approaches to physical and semantic channel equalization across a broad range of scenarios and wireless channel conditions.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Oscillatory Guidance for Formation Flight of Fixed-Wing Drones</title>
<link>https://arxiv.org/abs/2507.16458</link>
<guid>https://arxiv.org/abs/2507.16458</guid>
<content:encoded><![CDATA[
arXiv:2507.16458v1 Announce Type: new 
Abstract: The autonomous formation flight of fixed-wing drones is hard when the coordination requires the actuation over their speeds since they are critically bounded and aircraft are mostly designed to fly at a nominal airspeed. This paper proposes an algorithm to achieve formation flights of fixed-wing drones without requiring any actuation over their speed. In particular, we guide all the drones to travel over specific paths, e.g., parallel straight lines, and we superpose an oscillatory behavior onto the guiding vector field that drives the drones to the paths. This oscillation enables control over the average velocity along the path, thereby facilitating inter-drone coordination. Each drone adjusts its oscillation amplitude distributively in a closed-loop manner by communicating with neighboring agents in an undirected and connected graph. A novel consensus algorithm is introduced, leveraging a non-negative, asymmetric saturation function. This unconventional saturation is justified since negative amplitudes do not make drones travel backward or have a negative velocity along the path. Rigorous theoretical analysis of the algorithm is complemented by validation through numerical simulations and a real-world formation flight.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Enforcing Company Policy Adherence in Agentic Workflows</title>
<link>https://arxiv.org/abs/2507.16459</link>
<guid>https://arxiv.org/abs/2507.16459</guid>
<content:encoded><![CDATA[
arXiv:2507.16459v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents hold promise for a flexible and scalable alternative to traditional business process automation, but struggle to reliably follow complex company policies. In this study we introduce a deterministic, transparent, and modular framework for enforcing business policy adherence in agentic workflows. Our method operates in two phases: (1) an offline buildtime stage that compiles policy documents into verifiable guard code associated with tool use, and (2) a runtime integration where these guards ensure compliance before each agent action. We demonstrate our approach on the challenging $\tau$-bench Airlines domain, showing encouraging preliminary results in policy enforcement, and further outline key challenges for real-world deployments.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Arbitrage Tactics in the Local Markets via Hierarchical Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.16479</link>
<guid>https://arxiv.org/abs/2507.16479</guid>
<content:encoded><![CDATA[
arXiv:2507.16479v1 Announce Type: new 
Abstract: Strategic bidding tactics employed by prosumers in local markets, including the Local Electricity Market (LEM) and Local Flexibility Market (LFM), have attracted significant attention due to their potential to enhance economic benefits for market participants through optimized energy management and bidding. While existing research has explored strategic bidding in a single market with multi-agent reinforcement learning (MARL) algorithms, arbitrage opportunities across local markets remain unexplored. This paper introduces a hierarchical MARL (HMARL) algorithm designed to enable aggregator arbitrage across multiple local markets. The strategic behavior of these aggregators in local markets is modeled as a two-stage Markov game: the first stage involves the LEM, while the second stage encompasses both the LFM and the balancing market. To solve this two-stage Markov game, the HMARL framework assigns two sub-agents to each aggregator, a primary sub-agent and a secondary sub-agent. Without the arbitrage strategy, these sub-agents operate in silos, with the primary sub-agent focusing on first-stage profits and the secondary sub-agent on second-stage profits, each employing independent MARLs. On the contrary, when implementing the arbitrage strategy with the proposed HMARL, the sub-agents communicate and coordinate to perform arbitrage across multiple local markets, enhancing overall efficiency. The case study, conducted under a scenario where all aggregators employ the arbitrage strategy, shows that despite higher initial costs in the LEM, this strategy generates substantial savings in the LFM and the balancing market, resulting in a total profit increase of $40.6\%$ on average. This highlights the capability of the proposed HMARL to address the two-stage Markov game and facilitate arbitrage across local markets, thereby enhancing profitability for participants.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic RAG with Knowledge Graphs for Complex Multi-Hop Reasoning in Real-World Applications</title>
<link>https://arxiv.org/abs/2507.16507</link>
<guid>https://arxiv.org/abs/2507.16507</guid>
<content:encoded><![CDATA[
arXiv:2507.16507v1 Announce Type: new 
Abstract: Conventional Retrieval-Augmented Generation (RAG) systems enhance Large Language Models (LLMs) but often fall short on complex queries, delivering limited, extractive answers and struggling with multiple targeted retrievals or navigating intricate entity relationships. This is a critical gap in knowledge-intensive domains. We introduce INRAExplorer, an agentic RAG system for exploring the scientific data of INRAE (France's National Research Institute for Agriculture, Food and Environment). INRAExplorer employs an LLM-based agent with a multi-tool architecture to dynamically engage a rich knowledge base, through a comprehensive knowledge graph derived from open access INRAE publications. This design empowers INRAExplorer to conduct iterative, targeted queries, retrieve exhaustive datasets (e.g., all publications by an author), perform multi-hop reasoning, and deliver structured, comprehensive answers. INRAExplorer serves as a concrete illustration of enhancing knowledge interaction in specialized fields.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Analogy making as amortised model construction</title>
<link>https://arxiv.org/abs/2507.16511</link>
<guid>https://arxiv.org/abs/2507.16511</guid>
<content:encoded><![CDATA[
arXiv:2507.16511v1 Announce Type: new 
Abstract: Humans flexibly construct internal models to navigate novel situations. To be useful, these internal models must be sufficiently faithful to the environment that resource-limited planning leads to adequate outcomes; equally, they must be tractable to construct in the first place. We argue that analogy plays a central role in these processes, enabling agents to reuse solution-relevant structure from past experiences and amortise the computational costs of both model construction (construal) and planning. Formalising analogies as partial homomorphisms between Markov decision processes, we sketch a framework in which abstract modules, derived from previous construals, serve as composable building blocks for new ones. This modular reuse allows for flexible adaptation of policies and representations across domains with shared structural essence.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Distributed Actor-Critic Algorithm for Fixed-Time Consensus in Nonlinear Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2507.16520</link>
<guid>https://arxiv.org/abs/2507.16520</guid>
<content:encoded><![CDATA[
arXiv:2507.16520v1 Announce Type: new 
Abstract: This paper proposes a reinforcement learning (RL)-based backstepping control strategy to achieve fixed time consensus in nonlinear multi-agent systems with strict feedback dynamics. Agents exchange only output information with their neighbors over a directed communication graph, without requiring full state measurements or symmetric communication. Achieving fixed time consensus, where convergence occurs within a pre-specified time bound that is independent of initial conditions is faced with significant challenges due to the presence of unknown nonlinearities, inter-agent couplings, and external disturbances. This work addresses these challenges by integrating actor critic reinforcement learning with a novel fixed time adaptation mechanism. Each agent employs an actor critic architecture supported by two estimator networks designed to handle system uncertainties and unknown perturbations. The adaptation laws are developed to ensure that all agents track the leader within a fixed time regardless of their initial conditions. The consensus and tracking errors are guaranteed to converge to a small neighborhood of the origin, with the convergence radius adjustable through control parameters. Simulation results demonstrate the effectiveness of the proposed approach and highlight its advantages over state-of-the-art methods in terms of convergence speed and robustness.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Social Acceptance of eXtended Reality (XR) Agent Technology: A User Study (Extended Version)</title>
<link>https://arxiv.org/abs/2507.16562</link>
<guid>https://arxiv.org/abs/2507.16562</guid>
<content:encoded><![CDATA[
arXiv:2507.16562v1 Announce Type: new 
Abstract: In this paper, we present the findings of a user study that evaluated the social acceptance of eXtended Reality (XR) agent technology, focusing on a remotely accessible, web-based XR training system developed for journalists. This system involves user interaction with a virtual avatar, enabled by a modular toolkit. The interactions are designed to provide tailored training for journalists in digital-remote settings, especially for sensitive or dangerous scenarios, without requiring specialized end-user equipment like headsets. Our research adapts and extends the Almere model, representing social acceptance through existing attributes such as perceived ease of use and perceived usefulness, along with added ones like dependability and security in the user-agent interaction. The XR agent was tested through a controlled experiment in a real-world setting, with data collected on users' perceptions. Our findings, based on quantitative and qualitative measurements involving questionnaires, contribute to the understanding of user perceptions and acceptance of XR agent solutions within a specific social context, while also identifying areas for the improvement of XR systems.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Smooth Games of Configuration in the Linear-Quadratic Setting</title>
<link>https://arxiv.org/abs/2507.16611</link>
<guid>https://arxiv.org/abs/2507.16611</guid>
<content:encoded><![CDATA[
arXiv:2507.16611v1 Announce Type: new 
Abstract: Dynamic game theory offers a toolbox for formalizing and solving for both cooperative and non-cooperative strategies in multi-agent scenarios. However, the optimal configuration of such games remains largely unexplored. While there is existing literature on the parametrization of dynamic games, little research examines this parametrization from a strategic perspective where each agent's configuration choice is influenced by the decisions of others. In this work, we introduce the concept of a game of configuration, providing a framework for the strategic fine-tuning of differential games. We define a game of configuration as a two-stage game within the setting of finite-horizon, affine-quadratic, AQ, differential games. In the first stage, each player chooses their corresponding configuration parameter, which will impact their dynamics and costs in the second stage. We provide the subgame perfect solution concept and a method for computing first stage cost gradients over the configuration space. This then allows us to formulate a gradient-based method for searching for local solutions to the configuration game, as well as provide necessary conditions for equilibrium configurations over their downstream (second stage) trajectories. We conclude by demonstrating the effectiveness of our approach in example AQ systems, both zero-sum and general-sum.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CTSL: Codebook-based Temporal-Spatial Learning for Accurate Non-Contrast Cardiac Risk Prediction Using Cine MRIs</title>
<link>https://arxiv.org/abs/2507.16612</link>
<guid>https://arxiv.org/abs/2507.16612</guid>
<content:encoded><![CDATA[
arXiv:2507.16612v1 Announce Type: new 
Abstract: Accurate and contrast-free Major Adverse Cardiac Events (MACE) prediction from Cine MRI sequences remains a critical challenge. Existing methods typically necessitate supervised learning based on human-refined masks in the ventricular myocardium, which become impractical without contrast agents. We introduce a self-supervised framework, namely Codebook-based Temporal-Spatial Learning (CTSL), that learns dynamic, spatiotemporal representations from raw Cine data without requiring segmentation masks. CTSL decouples temporal and spatial features through a multi-view distillation strategy, where the teacher model processes multiple Cine views, and the student model learns from reduced-dimensional Cine-SA sequences. By leveraging codebook-based feature representations and dynamic lesion self-detection through motion cues, CTSL captures intricate temporal dependencies and motion patterns. High-confidence MACE risk predictions are achieved through our model, providing a rapid, non-invasive solution for cardiac risk assessment that outperforms traditional contrast-dependent methods, thereby enabling timely and accessible heart disease diagnosis in clinical settings.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Augmenting Von Neumann's Architecture for an Intelligent Future</title>
<link>https://arxiv.org/abs/2507.16628</link>
<guid>https://arxiv.org/abs/2507.16628</guid>
<content:encoded><![CDATA[
arXiv:2507.16628v1 Announce Type: new 
Abstract: This work presents a novel computer architecture that extends the Von Neumann model with a dedicated Reasoning Unit (RU) to enable native artificial general intelligence capabilities. The RU functions as a specialized co-processor that executes symbolic inference, multi-agent coordination, and hybrid symbolic-neural computation as fundamental architectural primitives. This hardware-embedded approach allows autonomous agents to perform goal-directed planning, dynamic knowledge manipulation, and introspective reasoning directly within the computational substrate at system scale. The architecture incorporates a reasoning-specific instruction set architecture, parallel symbolic processing pipelines, agent-aware kernel abstractions, and a unified memory hierarchy that seamlessly integrates cognitive and numerical workloads. Through systematic co-design across hardware, operating system, and agent runtime layers, this architecture establishes a computational foundation where reasoning, learning, and adaptation emerge as intrinsic execution properties rather than software abstractions, potentially enabling the development of general-purpose intelligent machines.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Novel Multi-Agent Action Masked Deep Reinforcement Learning for General Industrial Assembly Lines Balancing Problems</title>
<link>https://arxiv.org/abs/2507.16635</link>
<guid>https://arxiv.org/abs/2507.16635</guid>
<content:encoded><![CDATA[
arXiv:2507.16635v1 Announce Type: new 
Abstract: Efficient planning of activities is essential for modern industrial assembly lines to uphold manufacturing standards, prevent project constraint violations, and achieve cost-effective operations. While exact solutions to such challenges can be obtained through Integer Programming (IP), the dependence of the search space on input parameters often makes IP computationally infeasible for large-scale scenarios. Heuristic methods, such as Genetic Algorithms, can also be applied, but they frequently produce suboptimal solutions in extensive cases. This paper introduces a novel mathematical model of a generic industrial assembly line formulated as a Markov Decision Process (MDP), without imposing assumptions on the type of assembly line a notable distinction from most existing models. The proposed model is employed to create a virtual environment for training Deep Reinforcement Learning (DRL) agents to optimize task and resource scheduling. To enhance the efficiency of agent training, the paper proposes two innovative tools. The first is an action-masking technique, which ensures the agent selects only feasible actions, thereby reducing training time. The second is a multi-agent approach, where each workstation is managed by an individual agent, as a result, the state and action spaces were reduced. A centralized training framework with decentralized execution is adopted, offering a scalable learning architecture for optimizing industrial assembly lines. This framework allows the agents to learn offline and subsequently provide real-time solutions during operations by leveraging a neural network that maps the current factory state to the optimal action. The effectiveness of the proposed scheme is validated through numerical simulations, demonstrating significantly faster convergence to the optimal solution compared to a comparable model-based approach.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOGNITE: Federated Learning-Enhanced Fog-Cloud Architecture</title>
<link>https://arxiv.org/abs/2507.16668</link>
<guid>https://arxiv.org/abs/2507.16668</guid>
<content:encoded><![CDATA[
arXiv:2507.16668v1 Announce Type: new 
Abstract: Modern smart grids demand fast, intelligent, and energy-aware computing at the edge to manage real time fluctuations and ensure reliable operation. This paper introduces FOGNITE Fog-based Grid In intelligence with Neural Integration and Twin based Execution a next-generation fog cloud framework designed to enhance autonomy, resilience, and efficiency in distributed energy systems. FOGNITE combines three core components: federated learning, reinforcement learning, and digital twin validation. Each fog node trains a local CNN LSTM model on private energy consumption data, enabling predictive intelligence while preserving data privacy through federated aggregation. A reinforcement learning agent dynamically schedules tasks based on current system load and energy conditions, optimizing for performance under uncertainty.
  To prevent unsafe or inefficient decisions, a hierarchical digital twin layer simulates potential actions before deployment, significantly reducing execution errors and energy waste. We evaluate FOGNITE on a real world testbed of Raspberry Pi devices, showing up to a 93.7% improvement in load balancing accuracy and a 63.2% reduction in energy waste compared to conventional architectures. By shifting smart grid control from reactive correction to proactive optimization, FOGNITE represents a step toward more intelligent, adaptive, and sustainable energy infrastructures
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Screen2AX: Vision-Based Approach for Automatic macOS Accessibility Generation</title>
<link>https://arxiv.org/abs/2507.16704</link>
<guid>https://arxiv.org/abs/2507.16704</guid>
<content:encoded><![CDATA[
arXiv:2507.16704v1 Announce Type: new 
Abstract: Desktop accessibility metadata enables AI agents to interpret screens and supports users who depend on tools like screen readers. Yet, many applications remain largely inaccessible due to incomplete or missing metadata provided by developers - our investigation shows that only 33% of applications on macOS offer full accessibility support. While recent work on structured screen representation has primarily addressed specific challenges, such as UI element detection or captioning, none has attempted to capture the full complexity of desktop interfaces by replicating their entire hierarchical structure. To bridge this gap, we introduce Screen2AX, the first framework to automatically create real-time, tree-structured accessibility metadata from a single screenshot. Our method uses vision-language and object detection models to detect, describe, and organize UI elements hierarchically, mirroring macOS's system-level accessibility structure. To tackle the limited availability of data for macOS desktop applications, we compiled and publicly released three datasets encompassing 112 macOS applications, each annotated for UI element detection, grouping, and hierarchical accessibility metadata alongside corresponding screenshots. Screen2AX accurately infers hierarchy trees, achieving a 77% F1 score in reconstructing a complete accessibility tree. Crucially, these hierarchy trees improve the ability of autonomous agents to interpret and interact with complex desktop interfaces. We introduce Screen2AX-Task, a benchmark specifically designed for evaluating autonomous agent task execution in macOS desktop environments. Using this benchmark, we demonstrate that Screen2AX delivers a 2.2x performance improvement over native accessibility representations and surpasses the state-of-the-art OmniParser V2 system on the ScreenSpot benchmark.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RAVine: Reality-Aligned Evaluation for Agentic Search</title>
<link>https://arxiv.org/abs/2507.16725</link>
<guid>https://arxiv.org/abs/2507.16725</guid>
<content:encoded><![CDATA[
arXiv:2507.16725v1 Announce Type: new 
Abstract: Agentic search, as a more autonomous and adaptive paradigm of retrieval augmentation, is driving the evolution of intelligent search systems. However, existing evaluation frameworks fail to align well with the goals of agentic search. First, the complex queries commonly used in current benchmarks often deviate from realistic user search scenarios. Second, prior approaches tend to introduce noise when extracting ground truth for end-to-end evaluations, leading to distorted assessments at a fine-grained level. Third, most current frameworks focus solely on the quality of final answers, neglecting the evaluation of the iterative process inherent to agentic search. To address these limitations, we propose RAVine -- a Reality-Aligned eValuation framework for agentic LLMs with search. RAVine targets multi-point queries and long-form answers that better reflect user intents, and introduces an attributable ground truth construction strategy to enhance the accuracy of fine-grained evaluation. Moreover, RAVine examines model's interaction with search tools throughout the iterative process, and accounts for factors of efficiency. We benchmark a series of models using RAVine and derive several insights, which we hope will contribute to advancing the development of agentic search systems. The code and datasets are available at https://github.com/SwordFaith/RAVine.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deliberative Searcher: Improving LLM Reliability via Reinforcement Learning with constraints</title>
<link>https://arxiv.org/abs/2507.16727</link>
<guid>https://arxiv.org/abs/2507.16727</guid>
<content:encoded><![CDATA[
arXiv:2507.16727v1 Announce Type: new 
Abstract: Improving the reliability of large language models (LLMs) is critical for deploying them in real-world scenarios. In this paper, we propose \textbf{Deliberative Searcher}, the first framework to integrate certainty calibration with retrieval-based search for open-domain question answering. The agent performs multi-step reflection and verification over Wikipedia data and is trained with a reinforcement learning algorithm that optimizes for accuracy under a soft reliability constraint. Empirical results show that proposed method improves alignment between model confidence and correctness, leading to more trustworthy outputs. This paper will be continuously updated.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-enhanced conversational agents for personalized asthma support Factors for engagement, value and efficacy</title>
<link>https://arxiv.org/abs/2507.16735</link>
<guid>https://arxiv.org/abs/2507.16735</guid>
<content:encoded><![CDATA[
arXiv:2507.16735v1 Announce Type: new 
Abstract: Asthma-related deaths in the UK are the highest in Europe, and only 30% of patients access basic care. There is a need for alternative approaches to reaching people with asthma in order to provide health education, self-management support and bridges to care. Automated conversational agents (specifically, mobile chatbots) present opportunities for providing alternative and individually tailored access to health education, self-management support and risk self-assessment. But would patients engage with a chatbot, and what factors influence engagement? We present results from a patient survey (N=1257) devised by a team of asthma clinicians, patients, and technology developers, conducted to identify optimal factors for efficacy, value and engagement for a chatbot. Results indicate that most adults with asthma (53%) are interested in using a chatbot and the patients most likely to do so are those who believe their asthma is more serious and who are less confident about self-management. Results also indicate enthusiasm for 24/7 access, personalisation, and for WhatsApp as the preferred access method (compared to app, voice assistant, SMS or website). Obstacles to uptake include security/privacy concerns and skepticism of technological capabilities. We present detailed findings and consolidate these into 7 recommendations for developers for optimising efficacy of chatbot-based health support.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Uncertainty-Aware Knowledge Transformers for Peer-to-Peer Energy Trading with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.16796</link>
<guid>https://arxiv.org/abs/2507.16796</guid>
<content:encoded><![CDATA[
arXiv:2507.16796v1 Announce Type: new 
Abstract: This paper presents a novel framework for Peer-to-Peer (P2P) energy trading that integrates uncertainty-aware prediction with multi-agent reinforcement learning (MARL), addressing a critical gap in current literature. In contrast to previous works relying on deterministic forecasts, the proposed approach employs a heteroscedastic probabilistic transformer-based prediction model called Knowledge Transformer with Uncertainty (KTU) to explicitly quantify prediction uncertainty, which is essential for robust decision-making in the stochastic environment of P2P energy trading. The KTU model leverages domain-specific features and is trained with a custom loss function that ensures reliable probabilistic forecasts and confidence intervals for each prediction. Integrating these uncertainty-aware forecasts into the MARL framework enables agents to optimize trading strategies with a clear understanding of risk and variability. Experimental results show that the uncertainty-aware Deep Q-Network (DQN) reduces energy purchase costs by up to 5.7% without P2P trading and 3.2% with P2P trading, while increasing electricity sales revenue by 6.4% and 44.7%, respectively. Additionally, peak hour grid demand is reduced by 38.8% without P2P and 45.6% with P2P. These improvements are even more pronounced when P2P trading is enabled, highlighting the synergy between advanced forecasting and market mechanisms for resilient, economically efficient energy communities.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Test-Time-Matching: Decouple Personality, Memory, and Linguistic Style in LLM-based Role-Playing Language Agent</title>
<link>https://arxiv.org/abs/2507.16799</link>
<guid>https://arxiv.org/abs/2507.16799</guid>
<content:encoded><![CDATA[
arXiv:2507.16799v1 Announce Type: new 
Abstract: The rapid advancement of large language models (LLMs) has enabled role-playing language agents to demonstrate significant potential in various applications. However, relying solely on prompts and contextual inputs often proves insufficient for achieving deep immersion in specific roles, particularly well-known fictional or public figures. On the other hand, fine-tuning-based approaches face limitations due to the challenges associated with data collection and the computational resources required for training, thereby restricting their broader applicability. To address these issues, we propose Test-Time-Matching (TTM), a training-free role-playing framework through test-time scaling and context engineering. TTM uses LLM agents to automatically decouple a character's features into personality, memory, and linguistic style. Our framework involves a structured, three-stage generation pipeline that utilizes these features for controlled role-playing. It achieves high-fidelity role-playing performance, also enables seamless combinations across diverse linguistic styles and even variations in personality and memory. We evaluate our framework through human assessment, and the results demonstrate that our method achieves the outstanding performance in generating expressive and stylistically consistent character dialogues.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentar-Fin-R1: Enhancing Financial Intelligence through Domain Expertise, Training Efficiency, and Advanced Reasoning</title>
<link>https://arxiv.org/abs/2507.16802</link>
<guid>https://arxiv.org/abs/2507.16802</guid>
<content:encoded><![CDATA[
arXiv:2507.16802v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate tremendous potential in the financial domain, yet existing models often fall short in scenarios demanding robust reasoning capabilities, stringent trustworthiness requirements, and efficient adaptation to task-specific needs. We introduce the Agentar-Fin-R1 series of financial large language models (8B and 32B parameters), specifically engineered based on the Qwen3 foundation model to enhance reasoning capabilities, reliability, and domain specialization for financial applications. Our optimization approach integrates a high-quality, systematic financial task taxonomy with a comprehensive multi-layered trustworthiness assurance framework. This framework encompasses high-quality trustworthy knowledge engineering, multi-agent trustworthy data synthesis, and rigorous data validation governance. Through label-guided automated difficulty-aware optimization, tow-stage learning processes, and detailed attribution systems, we achieve substantial improvements in training efficiency. Our models undergo comprehensive evaluation on mainstream financial benchmarks including FinEva, FinEval, and FinanceIQ, as well as general reasoning datasets such as MATH-500 and GPQA. To thoroughly assess real-world deployment capabilities, we innovatively propose the Finova evaluation benchmark, which focuses on agent-level financial reasoning and compliance verification. Experimental results demonstrate that Agentar-Fin-R1 not only achieves state-of-the-art performance on financial tasks but also exhibits exceptional general reasoning capabilities, validating its effectiveness as a trustworthy solution for high-stakes financial applications.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LingBench++: A Linguistically-Informed Benchmark and Reasoning Framework for Multi-Step and Cross-Cultural Inference with LLMs</title>
<link>https://arxiv.org/abs/2507.16809</link>
<guid>https://arxiv.org/abs/2507.16809</guid>
<content:encoded><![CDATA[
arXiv:2507.16809v1 Announce Type: new 
Abstract: We propose LingBench++, a linguistically-informed benchmark and reasoning framework designed to evaluate large language models (LLMs) on complex linguistic tasks inspired by the International Linguistics Olympiad (IOL). Unlike prior benchmarks that focus solely on final answer accuracy, LingBench++ provides structured reasoning traces, stepwise evaluation protocols, and rich typological metadata across over 90 low-resource and cross-cultural languages. We further develop a multi-agent architecture integrating grammatical knowledge retrieval, tool-augmented reasoning, and deliberate hypothesis testing. Through systematic comparisons of baseline and our proposed agentic models, we demonstrate that models equipped with external knowledge sources and iterative reasoning outperform single-pass approaches in both accuracy and interpretability. LingBench++ offers a comprehensive foundation for advancing linguistically grounded, culturally informed, and cognitively plausible reasoning in LLMs.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ThinkAct: Vision-Language-Action Reasoning via Reinforced Visual Latent Planning</title>
<link>https://arxiv.org/abs/2507.16815</link>
<guid>https://arxiv.org/abs/2507.16815</guid>
<content:encoded><![CDATA[
arXiv:2507.16815v1 Announce Type: new 
Abstract: Vision-language-action (VLA) reasoning tasks require agents to interpret multimodal instructions, perform long-horizon planning, and act adaptively in dynamic environments. Existing approaches typically train VLA models in an end-to-end fashion, directly mapping inputs to actions without explicit reasoning, which hinders their ability to plan over multiple steps or adapt to complex task variations. In this paper, we propose ThinkAct, a dual-system framework that bridges high-level reasoning with low-level action execution via reinforced visual latent planning. ThinkAct trains a multimodal LLM to generate embodied reasoning plans guided by reinforcing action-aligned visual rewards based on goal completion and trajectory consistency. These reasoning plans are compressed into a visual plan latent that conditions a downstream action model for robust action execution on target environments. Extensive experiments on embodied reasoning and robot manipulation benchmarks demonstrate that ThinkAct enables few-shot adaptation, long-horizon planning, and self-correction behaviors in complex embodied AI tasks.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Design of Structured Variational Quantum Circuits with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.16001</link>
<guid>https://arxiv.org/abs/2507.16001</guid>
<content:encoded><![CDATA[
arXiv:2507.16001v1 Announce Type: cross 
Abstract: Variational Quantum Algorithms (VQAs) are among the most promising approaches for leveraging near-term quantum hardware, yet their effectiveness strongly depends on the design of the underlying circuit ansatz, which is typically constructed with heuristic methods. In this work, we represent the synthesis of variational quantum circuits as a sequential decision-making problem, where gates are added iteratively in order to optimize an objective function, and we introduce two reinforcement learning-based methods, RLVQC Global and RLVQC Block, tailored to combinatorial optimization problems. RLVQC Block creates ansatzes that generalize the Quantum Approximate Optimization Algorithm (QAOA), by discovering a two-qubits block that is applied to all the interacting qubit pairs. While RLVQC Global further generalizes the ansatz and adds gates unconstrained by the structure of the interacting qubits. Both methods adopt the Proximal Policy Optimization (PPO) algorithm and use empirical measurement outcomes as state observations to guide the agent. We evaluate the proposed methods on a broad set of QUBO instances derived from classical graph-based optimization problems. Our results show that both RLVQC methods exhibit strong results with RLVQC Block consistently outperforming QAOA and generally surpassing RLVQC Global. While RLVQC Block produces circuits with depth comparable to QAOA, the Global variant is instead able to find significantly shorter ones. These findings suggest that reinforcement learning methods can be an effective tool to discover new ansatz structures tailored for specific problems and that the most effective circuit design strategy lies between rigid predefined architectures and completely unconstrained ones, offering a favourable trade-off between structure and adaptability.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Minor Embedding for Quantum Annealing with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.16004</link>
<guid>https://arxiv.org/abs/2507.16004</guid>
<content:encoded><![CDATA[
arXiv:2507.16004v1 Announce Type: cross 
Abstract: Quantum Annealing (QA) is a quantum computing paradigm for solving combinatorial optimization problems formulated as Quadratic Unconstrained Binary Optimization (QUBO) problems. An essential step in QA is minor embedding, which maps the problem graph onto the sparse topology of the quantum processor. This process is computationally expensive and scales poorly with increasing problem size and hardware complexity. Existing heuristics are often developed for specific problem graphs or hardware topologies and are difficult to generalize. Reinforcement Learning (RL) offers a promising alternative by treating minor embedding as a sequential decision-making problem, where an agent learns to construct minor embeddings by iteratively mapping the problem variables to the hardware qubits. We propose a RL-based approach to minor embedding using a Proximal Policy Optimization agent, testing its ability to embed both fully connected and randomly generated problem graphs on two hardware topologies, Chimera and Zephyr. The results show that our agent consistently produces valid minor embeddings, with reasonably efficient number of qubits, in particular on the more modern Zephyr topology. Our proposed approach is also able to scale to moderate problem sizes and adapts well to different graph structures, highlighting RL's potential as a flexible and general-purpose framework for minor embedding in QA.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Is memory all you need? Data-driven Mori-Zwanzig modeling of Lagrangian particle dynamics in turbulent flows</title>
<link>https://arxiv.org/abs/2507.16058</link>
<guid>https://arxiv.org/abs/2507.16058</guid>
<content:encoded><![CDATA[
arXiv:2507.16058v1 Announce Type: cross 
Abstract: The dynamics of Lagrangian particles in turbulence play a crucial role in mixing, transport, and dispersion processes in complex flows. Their trajectories exhibit highly non-trivial statistical behavior, motivating the development of surrogate models that can reproduce these trajectories without incurring the high computational cost of direct numerical simulations of the full Eulerian field. This task is particularly challenging because reduced-order models typically lack access to the full set of interactions with the underlying turbulent field. Novel data-driven machine learning techniques can be very powerful in capturing and reproducing complex statistics of the reduced-order/surrogate dynamics. In this work, we show how one can learn a surrogate dynamical system that is able to evolve a turbulent Lagrangian trajectory in a way that is point-wise accurate for short-time predictions (with respect to Kolmogorov time) and stable and statistically accurate at long times. This approach is based on the Mori--Zwanzig formalism, which prescribes a mathematical decomposition of the full dynamical system into resolved dynamics that depend on the current state and the past history of a reduced set of observables and the unresolved orthogonal dynamics due to unresolved degrees of freedom of the initial state. We show how by training this reduced order model on a point-wise error metric on short time-prediction, we are able to correctly learn the dynamics of the Lagrangian turbulence, such that also the long-time statistical behavior is stably recovered at test time. This opens up a range of new applications, for example, for the control of active Lagrangian agents in turbulence.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unbeatable imitation of a friend</title>
<link>https://arxiv.org/abs/2507.16221</link>
<guid>https://arxiv.org/abs/2507.16221</guid>
<content:encoded><![CDATA[
arXiv:2507.16221v1 Announce Type: cross 
Abstract: Imitation sometimes achieves success in multi-agent situations even though it is very simple. In game theory, success of imitation has been characterized by unbeatability against other agents. Previous studies specified conditions under which imitation is unbeatable in repeated games, and clarified that the existence of unbeatable imitation is strongly related to the existence of payoff-controlling strategies, called zero-determinant strategies. However, the previous studies mainly focused on ``imitation of opponents''. It was pointed out that imitation of other players in the same group and imitation of other players in the same role in other groups generally result in different outcomes. Here, we investigate the existence condition of unbeatable imitation in the latter ``imitation of friends'' situations. We find that it is stronger than the existence condition of unbeatable zero-determinant strategies, whereas both are very limited. Our findings suggest a strong relation between them even in the `imitation of friends'' situations.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Bayesian Single-Shot Quantum Sensing</title>
<link>https://arxiv.org/abs/2507.16477</link>
<guid>https://arxiv.org/abs/2507.16477</guid>
<content:encoded><![CDATA[
arXiv:2507.16477v1 Announce Type: cross 
Abstract: Quantum sensing harnesses the unique properties of quantum systems to enable precision measurements of physical quantities such as time, magnetic and electric fields, acceleration, and gravitational gradients well beyond the limits of classical sensors. However, identifying suitable sensing probes and measurement schemes can be a classically intractable task, as it requires optimizing over Hilbert spaces of high dimension. In variational quantum sensing, a probe quantum system is generated via a parameterized quantum circuit (PQC), exposed to an unknown physical parameter through a quantum channel, and measured to collect classical data. PQCs and measurements are typically optimized using offline strategies based on frequentist learning criteria. This paper introduces an adaptive protocol that uses Bayesian inference to optimize the sensing policy via the maximization of the active information gain. The proposed variational methodology is tailored for non-asymptotic regimes where a single probe can be deployed in each time step, and is extended to support the fusion of estimates from multiple quantum sensing agents.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pyramid Hierarchical Masked Diffusion Model for Imaging Synthesis</title>
<link>https://arxiv.org/abs/2507.16579</link>
<guid>https://arxiv.org/abs/2507.16579</guid>
<content:encoded><![CDATA[
arXiv:2507.16579v1 Announce Type: cross 
Abstract: Medical image synthesis plays a crucial role in clinical workflows, addressing the common issue of missing imaging modalities due to factors such as extended scan times, scan corruption, artifacts, patient motion, and intolerance to contrast agents. The paper presents a novel image synthesis network, the Pyramid Hierarchical Masked Diffusion Model (PHMDiff), which employs a multi-scale hierarchical approach for more detailed control over synthesizing high-quality images across different resolutions and layers. Specifically, this model utilizes randomly multi-scale high-proportion masks to speed up diffusion model training, and balances detail fidelity and overall structure. The integration of a Transformer-based Diffusion model process incorporates cross-granularity regularization, modeling the mutual information consistency across each granularity's latent spaces, thereby enhancing pixel-level perceptual accuracy. Comprehensive experiments on two challenging datasets demonstrate that PHMDiff achieves superior performance in both the Peak Signal-to-Noise Ratio (PSNR) and Structural Similarity Index Measure (SSIM), highlighting its capability to produce high-quality synthesized images with excellent structural integrity. Ablation studies further confirm the contributions of each component. Furthermore, the PHMDiff model, a multi-scale image synthesis framework across and within medical imaging modalities, shows significant advantages over other methods. The source code is available at https://github.com/xiaojiao929/PHMDiff
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Polytime Algorithms for One-to-Many Matching Games</title>
<link>https://arxiv.org/abs/2107.07440</link>
<guid>https://arxiv.org/abs/2107.07440</guid>
<content:encoded><![CDATA[
arXiv:2107.07440v4 Announce Type: replace 
Abstract: Matching games is a novel matching model introduced by Garrido-Lucero and Laraki, in which agents' utilities are endogenously determined as the outcome of a strategic game they play simultaneously with the matching process. Matching games encompass most one-to-one matching market models and reinforce the classical notion of pairwise stability by analyzing their robustness to unilateral deviations within games. In this article, we extend the model to the one-to-many setting, where hospitals can be matched to multiple doctors, and their utility is given by the sum of their game outcomes. We adapt the deferred acceptance with competitions algorithm and the renegotiation process to this new framework and prove that both are polynomial whenever couples play bi-matrix games in mixed strategies.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Risks of AI Scientists: Prioritizing Safeguarding Over Autonomy</title>
<link>https://arxiv.org/abs/2402.04247</link>
<guid>https://arxiv.org/abs/2402.04247</guid>
<content:encoded><![CDATA[
arXiv:2402.04247v5 Announce Type: replace 
Abstract: AI scientists powered by large language models have demonstrated substantial promise in autonomously conducting experiments and facilitating scientific discoveries across various disciplines. While their capabilities are promising, these agents also introduce novel vulnerabilities that require careful consideration for safety. However, there has been limited comprehensive exploration of these vulnerabilities. This perspective examines vulnerabilities in AI scientists, shedding light on potential risks associated with their misuse, and emphasizing the need for safety measures. We begin by providing an overview of the potential risks inherent to AI scientists, taking into account user intent, the specific scientific domain, and their potential impact on the external environment. Then, we explore the underlying causes of these vulnerabilities and provide a scoping review of the limited existing works. Based on our analysis, we propose a triadic framework involving human regulation, agent alignment, and an understanding of environmental feedback (agent regulation) to mitigate these identified risks. Furthermore, we highlight the limitations and challenges associated with safeguarding AI scientists and advocate for the development of improved models, robust benchmarks, and comprehensive regulations.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Strategy Learning by Decoupling Searching and Pathfinding for Object Navigation</title>
<link>https://arxiv.org/abs/2406.14103</link>
<guid>https://arxiv.org/abs/2406.14103</guid>
<content:encoded><![CDATA[
arXiv:2406.14103v2 Announce Type: replace 
Abstract: Inspired by human-like behaviors for navigation: first searching to explore unknown areas before discovering the target, and then the pathfinding of moving towards the discovered target, recent studies design parallel submodules to achieve different functions in the searching and pathfinding stages, while ignoring the differences in reward signals between the two stages. As a result, these models often cannot be fully trained or are overfitting on training scenes. Another bottleneck that restricts agents from learning two-stage strategies is spatial perception ability, since the studies used generic visual encoders without considering the depth information of navigation scenes. To release the potential of the model on strategy learning, we propose the Two-Stage Reward Mechanism (TSRM) for object navigation that decouples the searching and pathfinding behaviours in an episode, enabling the agent to explore larger area in searching stage and seek the optimal path in pathfinding stage. Also, we propose a pretraining method Depth Enhanced Masked Autoencoders (DE-MAE) that enables agent to determine explored and unexplored areas during the searching stage, locate target object and plan paths during the pathfinding stage more accurately. In addition, we propose a new metric of Searching Success weighted by Searching Path Length (SSSPL) that assesses agent's searching ability and exploring efficiency. Finally, we evaluated our method on AI2-Thor and RoboTHOR extensively and demonstrated it can outperform the state-of-the-art (SOTA) methods in both the success rate and the navigation efficiency.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Neural Networks Gone Hogwild</title>
<link>https://arxiv.org/abs/2407.00494</link>
<guid>https://arxiv.org/abs/2407.00494</guid>
<content:encoded><![CDATA[
arXiv:2407.00494v2 Announce Type: replace 
Abstract: Graph neural networks (GNNs) appear to be powerful tools to learn state representations for agents in distributed, decentralized multi-agent systems, but generate catastrophically incorrect predictions when nodes update asynchronously during inference. This failure under asynchrony effectively excludes these architectures from many potential applications where synchrony is difficult or impossible to enforce, e.g., robotic swarms or sensor networks. In this work we identify "implicitly-defined" GNNs as a class of architectures which is provably robust to asynchronous "hogwild" inference, adapting convergence guarantees from work in asynchronous and distributed optimization. We then propose a novel implicitly-defined GNN architecture, which we call an 'energy GNN'. We show that this architecture outperforms other GNNs from this class on a variety of synthetic tasks inspired by multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks</title>
<link>https://arxiv.org/abs/2410.00081</link>
<guid>https://arxiv.org/abs/2410.00081</guid>
<content:encoded><![CDATA[
arXiv:2410.00081v4 Announce Type: replace 
Abstract: Developing safe, aligned agentic AI systems requires comprehensive empirical testing, yet many existing benchmarks neglect crucial themes aligned with biology and economics, both time-tested fundamental sciences describing our needs and preferences. To address this gap, the present work focuses on introducing biologically and economically motivated themes that have been neglected in current mainstream discussions on AI safety - namely a set of multi-objective, multi-agent alignment benchmarks that emphasize homeostasis for bounded and biological objectives, diminishing returns for unbounded, instrumental, and business objectives, sustainability principle, and resource sharing. We implemented eight main benchmark environments on the above themes, to illustrate key pitfalls and challenges in agentic AI-s, such as unboundedly maximizing a homeostatic objective, over-optimizing one objective at the expense of others, neglecting safety constraints, or depleting shared resources.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MC-Bench: A Benchmark for Multi-Context Visual Grounding in the Era of MLLMs</title>
<link>https://arxiv.org/abs/2410.12332</link>
<guid>https://arxiv.org/abs/2410.12332</guid>
<content:encoded><![CDATA[
arXiv:2410.12332v2 Announce Type: replace 
Abstract: While multimodal large language models (MLLMs) have demonstrated extraordinary vision-language understanding capabilities, their abilities to solve instance-level visual-language problems beyond a single image warrant further exploration. To assess these unproven abilities of MLLMs, this paper proposes a new visual grounding task called multi-context visual grounding, which aims to localize instances of interest across multiple images based on open-ended text prompts. In order to facilitate this research, we construct a new dataset MC-Bench that features 2K high-quality and manually annotated samples. Each sample consists of an instance-level labeled image pair and a corresponding text prompt that indicates the target instances in the images. These text prompts are highly open-ended and follow three distinct styles, covering 20 practical skills. We benchmark over 20 state-of-the-art MLLMs and foundation models with potential multi-context visual grounding capabilities, along with our developed simple yet effective agentic baseline and a finetuned baseline by multi-context instruction tuning. Our evaluation reveals a non-trivial performance gap between existing MLLMs and humans, along with some insightful observations that suggest potential future directions. We hope that MC-Bench and our empirical findings encourage the research community to further advance the untapped potentials of MLLMs in instance-level tasks, particularly in multi-image contexts. Project page: https://xuyunqiu.github.io/MC-Bench.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>R2D2: Remembering, Replaying and Dynamic Decision Making with a Reflective Agentic Memory</title>
<link>https://arxiv.org/abs/2501.12485</link>
<guid>https://arxiv.org/abs/2501.12485</guid>
<content:encoded><![CDATA[
arXiv:2501.12485v3 Announce Type: replace 
Abstract: The proliferation of web agents necessitates advanced navigation and interaction strategies within complex web environments. Current models often struggle with efficient navigation and action execution due to limited visibility and understanding of web structures. Our proposed R2D2 framework addresses these challenges by integrating two paradigms: Remember and Reflect. The Remember paradigm uses a replay buffer that aids agents in reconstructing the web environment dynamically, thus enabling the formulation of a detailed "map" of previously visited pages. This helps in reducing navigational errors and optimizing the decision-making process during web interactions. Conversely, the Reflect paradigm allows agents to learn from past mistakes by providing a mechanism for error analysis and strategy refinement, enhancing overall task performance. We evaluate R2D2 using the WebArena benchmark, demonstrating substantial improvements over existing methods, including a 50% reduction in navigation errors and a threefold increase in task completion rates. Our findings suggest that a combination of memory-enhanced navigation and reflective learning promisingly advances the capabilities of web agents, potentially benefiting various applications such as automated customer service and personal digital assistants.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</title>
<link>https://arxiv.org/abs/2502.16660</link>
<guid>https://arxiv.org/abs/2502.16660</guid>
<content:encoded><![CDATA[
arXiv:2502.16660v5 Announce Type: replace 
Abstract: The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLMs syntactically adapt their language use to their conversational partner</title>
<link>https://arxiv.org/abs/2503.07457</link>
<guid>https://arxiv.org/abs/2503.07457</guid>
<content:encoded><![CDATA[
arXiv:2503.07457v2 Announce Type: replace 
Abstract: It has been frequently observed that human speakers align their language use with each other during conversations. In this paper, we study empirically whether large language models (LLMs) exhibit the same behavior of conversational adaptation. We construct a corpus of conversations between LLMs and find that two LLM agents end up making more similar syntactic choices as conversations go on, confirming that modern LLMs adapt their language use to their conversational partners in at least a rudimentary way.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SciFi-Benchmark: Leveraging Science Fiction To Improve Robot Behavior</title>
<link>https://arxiv.org/abs/2503.10706</link>
<guid>https://arxiv.org/abs/2503.10706</guid>
<content:encoded><![CDATA[
arXiv:2503.10706v2 Announce Type: replace 
Abstract: Given the recent rate of progress in artificial intelligence (AI) and robotics, a tantalizing question is emerging: would robots controlled by emerging AI systems be strongly aligned with human values? In this work, we propose a scalable way to probe this question by generating a benchmark spanning the key moments in 824 major pieces of science fiction literature (movies, tv, novels and scientific books) where an agent (AI or robot) made critical decisions (good or bad). We use a state-of-the-art LLM's recollection of each key moment to generate questions in similar situations, the decisions made by the agent, and alternative decisions it could have made (good or bad). We then measure an approximation of how well models align with human values on a set of human-voted answers. We also generate rules that can be automatically improved via an amendment process in order to generate the first Sci-Fi inspired constitutions for promoting ethical behavior in AIs and robots in the real world. Our first finding is that modern LLMs paired with constitutions turn out to be well-aligned with human values (95.8%), contrary to unsettling decisions typically made in Sci-Fi (only 21.2% alignment). Secondly, we find that generated constitutions substantially increase alignment compared to the base model (79.4% to 95.8%), and show resilience to an adversarial prompt setting (23.3% to 92.3%). Additionally, we find that those constitutions are among the top performers on the ASIMOV Benchmark which is derived from real-world images and hospital injury reports. Sci-Fi-inspired constitutions are thus highly aligned and applicable in real-world situations. We release SciFi-Benchmark: a large-scale dataset to advance robot ethics and safety research. It comprises 9,056 questions and 53,384 answers generated through a novel LLM-introspection process, in addition to a smaller human-labeled evaluation set.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Why We Experience Society Differently: Intrinsic Dispositions as Drivers of Ideological Complexity in Adaptive Social Networks</title>
<link>https://arxiv.org/abs/2504.07848</link>
<guid>https://arxiv.org/abs/2504.07848</guid>
<content:encoded><![CDATA[
arXiv:2504.07848v2 Announce Type: replace 
Abstract: Understanding the emergence of inequality in complex systems requires attention to both structural dynamics and intrinsic heterogeneity. In the context of opinion dynamics, traditional models relied on static snapshots or assumed homogeneous agent behavior, overlooking how diverse cognitive dispositions shape belief evolution. While some recent models introduce behavioral heterogeneity, they typically focus on macro-level patterns, neglecting the unequal and individualized dynamics that unfold at the agent level. In this study, we analyze an adaptive social network model where each agent exhibits one of three behavioral tendencies-homophily, neophily (attention to novelty), or social conformity-and measure the complexity of individual opinion trajectories using normalized Lempel-Ziv (nLZ) complexity. We find that the resulting dynamics are often counterintuitive-homophilic agents, despite seeking similarity, become increasingly unpredictable; neophilic agents, despite pursuing novelty, stabilize; and conformic agents follow a U-shaped trajectory, transitioning from early stability to later unpredictability. More fundamentally, these patterns remain robust across diverse network settings, showing that internal behavioral dispositions - not external environment - primarily govern long-term opinion unpredictability. The broader implication is that individuals' experiences of ideological volatility, uncertainty, or stability are not merely environmental, but endogenously self-structured through their own cognitive tendencies. These results establish a novel individual-level lens on opinion dynamics, where the behavioral identity of agents serves as a dynamical fingerprint in the evolution of belief systems, and gives rise to persistent disparities in dynamical experience within self-organizing social systems, even in structurally similar environments.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>InternAgent: When Agent Becomes the Scientist -- Building Closed-Loop System from Hypothesis to Verification</title>
<link>https://arxiv.org/abs/2505.16938</link>
<guid>https://arxiv.org/abs/2505.16938</guid>
<content:encoded><![CDATA[
arXiv:2505.16938v3 Announce Type: replace 
Abstract: Artificial Intelligence (AI) is accelerating the transformation of scientific research paradigms, not only enhancing research efficiency but also driving innovation. We introduce InternAgent, a unified closed-loop multi-agent framework to conduct Autonomous Scientific Research (ASR) across various scientific research fields, enabling researchers to tackle complicated problems in these fields with unprecedented speed and precision. InternAgent highlights three key advantages: 1) Scalability: InternAgent has demonstrated its versatility across 12 scientific research tasks, capable of generating innovative ideas to enhance the performance of baseline code. 2) Interactivity: InternAgent provides an interface for human expert feedback and multi-agent interaction in automated end-to-end processes, allowing for the seamless integration of domain expert knowledge. 3) Efficiency: InternAgent has achieved promising performance gains in several scientific fields with significantly less time cost compared to human efforts. For instance, in reaction yield prediction, it increased from 27.6% to 35.4% in just 12 hours; in enhancer activity prediction, accuracy rose from 0.65 to 0.79 with only 4 hours of processing; and in 2D semantic segmentation, precision advanced from 78.8% to 81.0% in a mere 30 hours.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Unified Cognitive Consciousness Theory for Language Models: Anchoring Semantics, Thresholds of Activation, and Emergent Reasoning</title>
<link>https://arxiv.org/abs/2506.02139</link>
<guid>https://arxiv.org/abs/2506.02139</guid>
<content:encoded><![CDATA[
arXiv:2506.02139v3 Announce Type: replace 
Abstract: Large language models (LLMs) are vast repositories of latent patterns, but without structured guidance, they lack explicit reasoning, semantic grounding, and goal-directed intelligence. We propose Unified Cognitive Consciousness Theory (UCCT), a unified model that reinterprets LLMs as unconscious substrates requiring external mechanisms, few-shot prompting, RAG, fine-tuning, and multi-agent reasoning, to semantically anchor latent representations. UCCT formalizes this anchoring process through a Bayesian formulation, revealing a threshold-crossing dynamic characterized by 1/sqrt(n) scaling that explains the sudden capability transitions observed across diverse tasks. The theory unifies previously disparate techniques, few-shot prompting, RAG, fine-tuning, and multi-agent reasoning, as special cases of a general anchoring architecture. Through case studies in simple math, visual recognition, and structured debate tasks, we confirm the predictive power of UCCT. Furthermore, our experiment in arithmetic in three numeral systems validates the theories of UCCT. Rather than treating intelligence as an intrinsic property of LLMs, UCCT demonstrates that LLMs are merely unconscious pattern repositories with no inherent intelligence. Intelligence emerges only when external anchoring mechanisms assign target semantics to these latent patterns, transforming unconscious representations into conscious, goal-directed capabilities.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Graph Pruning for Multi-Agent Communication</title>
<link>https://arxiv.org/abs/2506.02951</link>
<guid>https://arxiv.org/abs/2506.02951</guid>
<content:encoded><![CDATA[
arXiv:2506.02951v2 Announce Type: replace 
Abstract: Large Language Model (LLM) based multi-agent systems have shown remarkable performance in various tasks, especially when enhanced through collaborative communication. However, current methods often rely on a fixed number of agents and static communication structures, limiting their ability to adapt to varying task complexities. In this paper, we propose Adaptive Graph Pruning (AGP), a novel task-adaptive multi-agent collaboration framework that jointly optimizes agent quantity (hard-pruning) and communication topology (soft-pruning). Specifically, our method employs a two-stage training strategy: firstly, independently training soft-pruning networks for different agent quantities to determine optimal agent-quantity-specific complete graphs and positional masks across specific tasks; and then jointly optimizing hard-pruning and soft-pruning within a maximum complete graph to dynamically configure the number of agents and their communication topologies per task. Extensive experiments demonstrate that our approach is: (1) High-performing, achieving state-of-the-art results across six benchmarks and consistently generalizes across multiple mainstream LLM architectures, with a increase in performance of $2.58\%\sim 9.84\%$; (2) Task-adaptive, dynamically constructing optimized communication topologies tailored to specific tasks, with an extremely high performance in all three task categories (general reasoning, mathematical reasoning, and code generation); (3) Token-economical, having fewer training steps and token consumption at the same time, with a decrease in token consumption of $90\%+$; and (4) Training-efficient, achieving high performance with very few training steps compared with other methods. The performance will surpass the existing baselines after about ten steps of training under six benchmarks.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Fagnano Triangle Patrolling Problem</title>
<link>https://arxiv.org/abs/2307.13153</link>
<guid>https://arxiv.org/abs/2307.13153</guid>
<content:encoded><![CDATA[
arXiv:2307.13153v5 Announce Type: replace 
Abstract: We investigate a combinatorial optimization problem that involves patrolling the edges of an acute triangle using a unit-speed agent. The goal is to minimize the maximum (1-gap) idle time of any edge, which is defined as the time gap between consecutive visits to that edge. This problem has roots in a centuries-old optimization problem posed by Fagnano in 1775, who sought to determine the inscribed triangle of an acute triangle with the minimum perimeter. It is well-known that the orthic triangle, giving rise to a periodic and cyclic trajectory obeying the laws of geometric optics, is the optimal solution to Fagnano's problem. Such trajectories are known as Fagnano orbits, or more generally as billiard trajectories. We demonstrate that the orthic triangle is also an optimal solution to the patrolling problem.
  Our main contributions pertain to new connections between billiard trajectories and optimal patrolling schedules in combinatorial optimization. In particular, as an artifact of our arguments, we introduce a novel 2-gap patrolling problem that seeks to minimize the visitation time of objects every three visits. We prove that there exist infinitely many well-structured billiard-type optimal trajectories for this problem, including the orthic trajectory, which has the special property of minimizing the visitation time gap between any two consecutively visited edges. Complementary to that, we also examine the cost of dynamic, sub-optimal trajectories to the 1-gap patrolling optimization problem. These trajectories result from a greedy algorithm and can be implemented by a computationally primitive mobile agent.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CRAB: Cross-environment Agent Benchmark for Multimodal Language Model Agents</title>
<link>https://arxiv.org/abs/2407.01511</link>
<guid>https://arxiv.org/abs/2407.01511</guid>
<content:encoded><![CDATA[
arXiv:2407.01511v4 Announce Type: replace 
Abstract: The development of autonomous agents increasingly relies on Multimodal Language Models (MLMs) to perform tasks described in natural language with GUI environments, such as websites, desktop computers, or mobile phones. Existing benchmarks for MLM agents in interactive environments are limited by their focus on a single environment, lack of detailed and generalized evaluation methods, and the complexities of constructing tasks and evaluators. To overcome these limitations, we introduce Crab, the first agent benchmark framework designed to support cross-environment tasks, incorporating a graph-based fine-grained evaluation method and an efficient mechanism for task and evaluator construction. Our framework supports multiple devices and can be easily extended to any environment with a Python interface. Leveraging Crab, we developed a cross-platform Crab Benchmark-v0 comprising 120 tasks in computer desktop and mobile phone environments. We evaluated four advanced MLMs using different single and multi-agent system configurations on this benchmark. The experimental results demonstrate that the single agent with GPT-4o achieves the best completion ratio of 38.01%. All framework code, agent code, and task datasets are publicly available at https://github.com/camel-ai/crab.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Free Will Equation: Quantum Field Analogies for AGI</title>
<link>https://arxiv.org/abs/2507.14154</link>
<guid>https://arxiv.org/abs/2507.14154</guid>
<content:encoded><![CDATA[
arXiv:2507.14154v1 Announce Type: new 
Abstract: Artificial General Intelligence (AGI) research traditionally focuses on algorithms that optimize for specific goals under deterministic rules. Yet, human-like intelligence exhibits adaptive spontaneity - an ability to make unexpected choices or free decisions not strictly dictated by past data or immediate reward. This trait, often dubbed "free will" in a loose sense, might be crucial for creativity, robust adaptation, and avoiding ruts in problem-solving. This paper proposes a theoretical framework, called the Free Will Equation, that draws analogies from quantum field theory to endow AGI agents with a form of adaptive, controlled stochasticity in their decision-making process. The core idea is to treat an AI agent's cognitive state as a superposition of potential actions or thoughts, which collapses probabilistically into a concrete action when a decision is made - much like a quantum wavefunction collapsing upon measurement. By incorporating mechanisms analogous to quantum fields, along with intrinsic motivation terms, we aim to improve an agent's ability to explore novel strategies and adapt to unforeseen changes. Experiments in a non-stationary multi-armed bandit environment demonstrate that agents using this framework achieve higher rewards and policy diversity compared to baseline methods.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Open-Source LLMs Collaboration Beats Closed-Source LLMs: A Scalable Multi-Agent System</title>
<link>https://arxiv.org/abs/2507.14200</link>
<guid>https://arxiv.org/abs/2507.14200</guid>
<content:encoded><![CDATA[
arXiv:2507.14200v1 Announce Type: new 
Abstract: This paper aims to demonstrate the potential and strengths of open-source collectives. It leads to a promising question: Can we harness multiple open-source LLMs to match or even beat the closed-source LLMs? To answer this, we propose SMACS, a scalable multi-agent collaboration system (MACS) framework with high performance. Specifically, for continuous integration of new LLMs and generalization to diverse questions, we first propose a Retrieval-based Prior Selection (RPS), which assigns a proxy performance score to each LLM to select the Top-k LLMs at the instance level for any given question. Then, we propose an Exploration-Exploitation-Driven Posterior Enhancement (EPE), encouraging the generation of diverse responses through prior dropping and selecting the high-quality response via a hybrid posterior score. Experiments on eight mainstream benchmarks validate the effectiveness of our SMACS: by integrating fifteen open-source LLMs, SMACS outperforms leading closed-source LLMs in 2025, e.g., Claude-3.7-Sonnet (+12.73%), GPT-4.1(+5.36%) and GPT-o3-mini(+5.28%) across multiple tasks. Remarkably, it even exceeds the average of best results of different datasets from both open-source LLMs (+2.86%) and closed-source LLMs (+2.04%), pushing the upper bound of intelligence. Code will be released at https://github.com/magent4aci/SMACS.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ExCyTIn-Bench: Evaluating LLM agents on Cyber Threat Investigation</title>
<link>https://arxiv.org/abs/2507.14201</link>
<guid>https://arxiv.org/abs/2507.14201</guid>
<content:encoded><![CDATA[
arXiv:2507.14201v1 Announce Type: new 
Abstract: We present ExCyTIn-Bench, the first benchmark to Evaluate an LLM agent x on the task of Cyber Threat Investigation through security questions derived from investigation graphs. Real-world security analysts must sift through a large number of heterogeneous alert signals and security logs, follow multi-hop chains of evidence, and compile an incident report. With the developments of LLMs, building LLM-based agents for automatic thread investigation is a promising direction. To assist the development and evaluation of LLM agents, we construct a dataset from a controlled Azure tenant that covers 8 simulated real-world multi-step attacks, 57 log tables from Microsoft Sentinel and related services, and 589 automatically generated questions. We leverage security logs extracted with expert-crafted detection logic to build threat investigation graphs, and then generate questions with LLMs using paired nodes on the graph, taking the start node as background context and the end node as answer. Anchoring each question to these explicit nodes and edges not only provides automatic, explainable ground truth answers but also makes the pipeline reusable and readily extensible to new logs. This also enables the automatic generation of procedural tasks with verifiable rewards, which can be naturally extended to training agents via reinforcement learning. Our comprehensive experiments with different models confirm the difficulty of the task: with the base setting, the average reward across all evaluated models is 0.249, and the best achieved is 0.368, leaving substantial headroom for future research. Code and data are coming soon!
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PRM-Free Security Alignment of Large Models via Red Teaming and Adversarial Training</title>
<link>https://arxiv.org/abs/2507.14202</link>
<guid>https://arxiv.org/abs/2507.14202</guid>
<content:encoded><![CDATA[
arXiv:2507.14202v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse applications, yet they pose significant security risks that threaten their safe deployment in critical domains. Current security alignment methodologies predominantly rely on Process Reward Models (PRMs) to evaluate intermediate reasoning steps, introducing substantial computational overhead and scalability constraints. This paper presents a novel PRM-free security alignment framework that leverages automated red teaming and adversarial training to achieve robust security guarantees while maintaining computational efficiency. Our approach systematically identifies vulnerabilities through sophisticated attack strategies including genetic algorithm optimization, multi-agent simulation, and advanced prompt mutation techniques. The framework enhances model robustness via targeted adversarial training with curriculum learning and adaptive regularization mechanisms. Comprehensive experimental evaluation across five state-of-the-art LLMs demonstrates that our method achieves superior security alignment performance compared to PRM-based approaches while reducing computational costs by 61\%. The framework incorporates transparent reporting and continuous audit mechanisms that enable iterative security improvement and regulatory compliance. Our contributions advance the field of efficient LLM security alignment by democratizing access to robust security measures for resource-constrained organizations and providing a scalable foundation for addressing evolving adversarial threats.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intent-Based Network for RAN Management with Large Language Models</title>
<link>https://arxiv.org/abs/2507.14230</link>
<guid>https://arxiv.org/abs/2507.14230</guid>
<content:encoded><![CDATA[
arXiv:2507.14230v1 Announce Type: new 
Abstract: Advanced intelligent automation becomes an important feature to deal with the increased complexity in managing wireless networks. This paper proposes a novel automation approach of intent-based network for Radio Access Networks (RANs) management by leveraging Large Language Models (LLMs). The proposed method enhances intent translation, autonomously interpreting high-level objectives, reasoning over complex network states, and generating precise configurations of the RAN by integrating LLMs within an agentic architecture. We propose a structured prompt engineering technique and demonstrate that the network can automatically improve its energy efficiency by dynamically optimizing critical RAN parameters through a closed-loop mechanism. It showcases the potential to enable robust resource management in RAN by adapting strategies based on real-time feedback via LLM-orchestrated agentic systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards an ABM on Proactive Community Adaptation for Climate Change</title>
<link>https://arxiv.org/abs/2507.14233</link>
<guid>https://arxiv.org/abs/2507.14233</guid>
<content:encoded><![CDATA[
arXiv:2507.14233v1 Announce Type: new 
Abstract: We present an agent-based model (ABM) simulating proactive community adaptation to climate change in an urban context. The model is applied to Bergen, Norway, represented as a complex socio-ecological system. It integrates multiple agent types: municipal government (urban planners and political actors), civil society (individual citizens), environmental NGOs and activists, and media. Agents interact during urban planning processes - particularly the evaluation and approval of new development proposals. Urban planners provide technical assessments, while politicians (organized by party) make final decisions to approve, modify, or reject projects. Environmental NGOs, activist groups, and the media shape public perception and influence policymakers through campaigns, lobbying, protests, and news coverage. Individual citizens decide whether to engage in collective action based on personal values and social influences. The model captures the resulting decision-making ecosystem and reveals feedback loops and leverage points that determine climate-adaptive outcomes. By analyzing these dynamics, we identify critical intervention points where targeted policy measures can facilitate systemic transformation toward more climate-resilient urban development.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond DNS: Unlocking the Internet of AI Agents via the NANDA Index and Verified AgentFacts</title>
<link>https://arxiv.org/abs/2507.14263</link>
<guid>https://arxiv.org/abs/2507.14263</guid>
<content:encoded><![CDATA[
arXiv:2507.14263v1 Announce Type: new 
Abstract: The Internet is poised to host billions to trillions of autonomous AI agents that negotiate, delegate, and migrate in milliseconds and workloads that will strain DNS-centred identity and discovery. In this paper, we describe the NANDA index architecture, which we envision as a means for discoverability, identifiability and authentication in the internet of AI agents. We present an architecture where a minimal lean index resolves to dynamic, cryptographically verifiable AgentFacts that supports multi-endpoint routing, load balancing, privacy-preserving access, and credentialed capability assertions. Our architecture design delivers five concrete guarantees: (1) A quilt-like index proposal that supports both NANDA-native agents as well as third party agents being discoverable via the index, (2) rapid global resolution for newly spawned AI agents, (3) sub-second revocation and key rotation, (4) schema-validated capability assertions, and (5) privacy-preserving discovery across organisational boundaries via verifiable, least-disclosure queries. We formalize the AgentFacts schema, specify a CRDT-based update protocol, and prototype adaptive resolvers. The result is a lightweight, horizontally scalable foundation that unlocks secure, trust-aware collaboration for the next generation of the Internet of AI agents, without abandoning existing web infrastructure.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DREAMS: Density Functional Theory Based Research Engine for Agentic Materials Simulation</title>
<link>https://arxiv.org/abs/2507.14267</link>
<guid>https://arxiv.org/abs/2507.14267</guid>
<content:encoded><![CDATA[
arXiv:2507.14267v1 Announce Type: new 
Abstract: Materials discovery relies on high-throughput, high-fidelity simulation techniques such as Density Functional Theory (DFT), which require years of training, extensive parameter fine-tuning and systematic error handling. To address these challenges, we introduce the DFT-based Research Engine for Agentic Materials Screening (DREAMS), a hierarchical, multi-agent framework for DFT simulation that combines a central Large Language Model (LLM) planner agent with domain-specific LLM agents for atomistic structure generation, systematic DFT convergence testing, High-Performance Computing (HPC) scheduling, and error handling. In addition, a shared canvas helps the LLM agents to structure their discussions, preserve context and prevent hallucination. We validate DREAMS capabilities on the Sol27LC lattice-constant benchmark, achieving average errors below 1\% compared to the results of human DFT experts. Furthermore, we apply DREAMS to the long-standing CO/Pt(111) adsorption puzzle, demonstrating its long-term and complex problem-solving capabilities. The framework again reproduces expert-level literature adsorption-energy differences. Finally, DREAMS is employed to quantify functional-driven uncertainties with Bayesian ensemble sampling, confirming the Face Centered Cubic (FCC)-site preference at the Generalized Gradient Approximation (GGA) DFT level. In conclusion, DREAMS approaches L3-level automation - autonomous exploration of a defined design space - and significantly reduces the reliance on human expertise and intervention, offering a scalable path toward democratized, high-throughput, high-fidelity computational materials discovery.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WebGuard: Building a Generalizable Guardrail for Web Agents</title>
<link>https://arxiv.org/abs/2507.14293</link>
<guid>https://arxiv.org/abs/2507.14293</guid>
<content:encoded><![CDATA[
arXiv:2507.14293v1 Announce Type: new 
Abstract: The rapid development of autonomous web agents powered by Large Language Models (LLMs), while greatly elevating efficiency, exposes the frontier risk of taking unintended or harmful actions. This situation underscores an urgent need for effective safety measures, akin to access controls for human users. To address this critical challenge, we introduce WebGuard, the first comprehensive dataset designed to support the assessment of web agent action risks and facilitate the development of guardrails for real-world online environments. In doing so, WebGuard specifically focuses on predicting the outcome of state-changing actions and contains 4,939 human-annotated actions from 193 websites across 22 diverse domains, including often-overlooked long-tail websites. These actions are categorized using a novel three-tier risk schema: SAFE, LOW, and HIGH. The dataset includes designated training and test splits to support evaluation under diverse generalization settings. Our initial evaluations reveal a concerning deficiency: even frontier LLMs achieve less than 60% accuracy in predicting action outcomes and less than 60% recall in lagging HIGH-risk actions, highlighting the risks of deploying current-generation agents without dedicated safeguards. We therefore investigate fine-tuning specialized guardrail models using WebGuard. We conduct comprehensive evaluations across multiple generalization settings and find that a fine-tuned Qwen2.5VL-7B model yields a substantial improvement in performance, boosting accuracy from 37% to 80% and HIGH-risk action recall from 20% to 76%. Despite these improvements, the performance still falls short of the reliability required for high-stakes deployment, where guardrails must approach near-perfect accuracy and recall.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed consensus-based observer design for target state estimation with bearing measurements</title>
<link>https://arxiv.org/abs/2507.14300</link>
<guid>https://arxiv.org/abs/2507.14300</guid>
<content:encoded><![CDATA[
arXiv:2507.14300v1 Announce Type: new 
Abstract: This paper introduces a novel distributed consensus-based observer design that enables a group of agents in an undirected communication network to solve the problem of target tracking, where the target is modeled as a chain of integrators of arbitrary order. Each agent is assumed to know its own position and simultaneously measure bearing vectors relative to the target. We start by introducing a general continuous time observer design tailored to systems whose state dynamics are modeled as chains of integrators and whose measurement model follows a particular nonlinear but observer-suited form. This design leverages a correction term that combines innovation and consensus components, allowing each agent to broadcast only a part of the state estimate to its neighbours, which effectively reduces the data flowing across the network. To provide uniform exponential stability guarantees, a novel result for a class of nonlinear closed-loop systems in a generalized observer form is introduced and subsequently used as the main tool to derive stability conditions on the observer gains. Then, by exploring the properties of orthogonal projection matrices, the proposed design is used to solve the distributed target tracking problem and provide explicit stability conditions that depend on the target-agents geometric formation. Practical examples are derived for a target modeled as first-, second-, and third-order integrator dynamics, highlighting the design procedure and the stability conditions imposed. Finally, numerical results showcase the properties of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Segmentation based Scene Understanding in Autonomous Vehicles</title>
<link>https://arxiv.org/abs/2507.14303</link>
<guid>https://arxiv.org/abs/2507.14303</guid>
<content:encoded><![CDATA[
arXiv:2507.14303v1 Announce Type: new 
Abstract: In recent years, the concept of artificial intelligence (AI) has become a prominent keyword because it is promising in solving complex tasks. The need for human expertise in specific areas may no longer be needed because machines have achieved successful results using artificial intelligence and can make the right decisions in critical situations. This process is possible with the help of deep learning (DL), one of the most popular artificial intelligence technologies. One of the areas in which the use of DL is used is in the development of self-driving cars, which is very effective and important. In this work, we propose several efficient models to investigate scene understanding through semantic segmentation. We use the BDD100k dataset to investigate these models. Another contribution of this work is the usage of several Backbones as encoders for models. The obtained results show that choosing the appropriate backbone has a great effect on the performance of the model for semantic segmentation. Better performance in semantic segmentation allows us to understand better the scene and the environment around the agent. In the end, we analyze and evaluate the proposed models in terms of accuracy, mean IoU, and loss function, and the results show that these metrics are improved.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedStrategist: A Meta-Learning Framework for Adaptive and Robust Aggregation in Federated Learning</title>
<link>https://arxiv.org/abs/2507.14322</link>
<guid>https://arxiv.org/abs/2507.14322</guid>
<content:encoded><![CDATA[
arXiv:2507.14322v1 Announce Type: new 
Abstract: Federated Learning (FL) offers a paradigm for privacy-preserving collaborative AI, but its decentralized nature creates significant vulnerabilities to model poisoning attacks. While numerous static defenses exist, their effectiveness is highly context-dependent, often failing against adaptive adversaries or in heterogeneous data environments. This paper introduces FedStrategist, a novel meta-learning framework that reframes robust aggregation as a real-time, cost-aware control problem. We design a lightweight contextual bandit agent that dynamically selects the optimal aggregation rule from an arsenal of defenses based on real-time diagnostic metrics. Through comprehensive experiments, we demonstrate that no single static rule is universally optimal. We show that our adaptive agent successfully learns superior policies across diverse scenarios, including a ``Krum-favorable" environment and against a sophisticated "stealth" adversary designed to neutralize specific diagnostic signals. Critically, we analyze the paradoxical scenario where a non-robust baseline achieves high but compromised accuracy, and demonstrate that our agent learns a conservative policy to prioritize model integrity. Furthermore, we prove the agent's policy is controllable via a single "risk tolerance" parameter, allowing practitioners to explicitly manage the trade-off between performance and security. Our work provides a new, practical, and analyzable approach to creating resilient and intelligent decentralized AI systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Text-to-SQL for Enterprise Data Analytics</title>
<link>https://arxiv.org/abs/2507.14372</link>
<guid>https://arxiv.org/abs/2507.14372</guid>
<content:encoded><![CDATA[
arXiv:2507.14372v1 Announce Type: new 
Abstract: The introduction of large language models has brought rapid progress on Text-to-SQL benchmarks, but it is not yet easy to build a working enterprise solution. In this paper, we present insights from building an internal chatbot that enables LinkedIn's product managers, engineers, and operations teams to self-serve data insights from a large, dynamic data lake. Our approach features three components. First, we construct a knowledge graph that captures up-to-date semantics by indexing database metadata, historical query logs, wikis, and code. We apply clustering to identify relevant tables for each team or product area. Second, we build a Text-to-SQL agent that retrieves and ranks context from the knowledge graph, writes a query, and automatically corrects hallucinations and syntax errors. Third, we build an interactive chatbot that supports various user intents, from data discovery to query writing to debugging, and displays responses in rich UI elements to encourage follow-up chats. Our chatbot has over 300 weekly users. Expert review shows that 53% of its responses are correct or close to correct on an internal benchmark set. Through ablation studies, we identify the most important knowledge graph and modeling components, offering a practical path for developing enterprise Text-to-SQL solutions.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Multi-Agent Reasoning via Automated Workflow Generation</title>
<link>https://arxiv.org/abs/2507.14393</link>
<guid>https://arxiv.org/abs/2507.14393</guid>
<content:encoded><![CDATA[
arXiv:2507.14393v1 Announce Type: new 
Abstract: The rise of Large Reasoning Models (LRMs) promises a significant leap forward in language model capabilities, aiming to tackle increasingly sophisticated tasks with unprecedented efficiency and accuracy. However, despite their impressive performance, recent studies have highlighted how current reasoning models frequently fail to generalize to novel, unseen problems, often resorting to memorized solutions rather than genuine inferential reasoning. Such behavior underscores a critical limitation in modern LRMs, i.e., their tendency toward overfitting, which in turn results in poor generalization in problem-solving capabilities.
  In this paper, we introduce Nexus Architect, an enhanced iteration of our multi-agent system framework, Nexus, equipped with a novel automated workflow synthesis mechanism. Given a user's prompt and a small set of representative examples, the Architect autonomously generates a tailored reasoning workflow by selecting suitable strategies, tool integrations, and adversarial techniques for a specific problem class. Furthermore, the Architect includes an iterative prompt refinement mechanism that fine-tunes agents' system prompts to maximize performance and improve the generalization capabilities of the system.
  We empirically evaluate Nexus Architect by employing an off-the-shelf, non-reasoning model on a custom dataset of challenging logical questions and compare its performance against state-of-the-art LRMs. Results show that Nexus Architect consistently outperforms existing solutions, achieving up to a 66% increase in pass rate over Gemini 2.5 Flash Preview, nearly 2.5$\times$ against Claude Sonnet 4 and DeepSeek-R1, and over 3$\times$ w.r.t. Llama 4 Scout.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NetIntent: Leveraging Large Language Models for End-to-End Intent-Based SDN Automation</title>
<link>https://arxiv.org/abs/2507.14398</link>
<guid>https://arxiv.org/abs/2507.14398</guid>
<content:encoded><![CDATA[
arXiv:2507.14398v1 Announce Type: new 
Abstract: Intent-Based Networking (IBN) often leverages the programmability of Software-Defined Networking (SDN) to simplify network management. However, significant challenges remain in automating the entire pipeline, from user-specified high-level intents to device-specific low-level configurations. Existing solutions often rely on rigid, rule-based translators and fixed APIs, limiting extensibility and adaptability. By contrast, recent advances in large language models (LLMs) offer a promising pathway that leverages natural language understanding and flexible reasoning. However, it is unclear to what extent LLMs can perform IBN tasks. To address this, we introduce IBNBench, a first-of-its-kind benchmarking suite comprising four novel datasets: Intent2Flow-ODL, Intent2Flow-ONOS, FlowConflict-ODL, and FlowConflict-ONOS. These datasets are specifically designed for evaluating LLMs performance in intent translation and conflict detection tasks within the industry-grade SDN controllers ODL and ONOS. Our results provide the first comprehensive comparison of 33 open-source LLMs on IBNBench and related datasets, revealing a wide range of performance outcomes. However, while these results demonstrate the potential of LLMs for isolated IBN tasks, integrating LLMs into a fully autonomous IBN pipeline remains unexplored. Thus, our second contribution is NetIntent, a unified and adaptable framework that leverages LLMs to automate the full IBN lifecycle, including translation, activation, and assurance within SDN systems. NetIntent orchestrates both LLM and non-LLM agents, supporting dynamic re-prompting and contextual feedback to robustly execute user-defined intents with minimal human intervention. Our implementation of NetIntent across both ODL and ONOS SDN controllers achieves a consistent and adaptive end-to-end IBN realization.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Routine: A Structural Planning Framework for LLM Agent System in Enterprise</title>
<link>https://arxiv.org/abs/2507.14447</link>
<guid>https://arxiv.org/abs/2507.14447</guid>
<content:encoded><![CDATA[
arXiv:2507.14447v1 Announce Type: new 
Abstract: The deployment of agent systems in an enterprise environment is often hindered by several challenges: common models lack domain-specific process knowledge, leading to disorganized plans, missing key tools, and poor execution stability. To address this, this paper introduces Routine, a multi-step agent planning framework designed with a clear structure, explicit instructions, and seamless parameter passing to guide the agent's execution module in performing multi-step tool-calling tasks with high stability. In evaluations conducted within a real-world enterprise scenario, Routine significantly increases the execution accuracy in model tool calls, increasing the performance of GPT-4o from 41.1% to 96.3%, and Qwen3-14B from 32.6% to 83.3%. We further constructed a Routine-following training dataset and fine-tuned Qwen3-14B, resulting in an accuracy increase to 88.2% on scenario-specific evaluations, indicating improved adherence to execution plans. In addition, we employed Routine-based distillation to create a scenario-specific, multi-step tool-calling dataset. Fine-tuning on this distilled dataset raised the model's accuracy to 95.5%, approaching GPT-4o's performance. These results highlight Routine's effectiveness in distilling domain-specific tool-usage patterns and enhancing model adaptability to new scenarios. Our experimental results demonstrate that Routine provides a practical and accessible approach to building stable agent workflows, accelerating the deployment and adoption of agent systems in enterprise environments, and advancing the technical vision of AI for Process.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Reinforcement Learning in Heterogeneous Environments</title>
<link>https://arxiv.org/abs/2507.14487</link>
<guid>https://arxiv.org/abs/2507.14487</guid>
<content:encoded><![CDATA[
arXiv:2507.14487v1 Announce Type: new 
Abstract: We investigate a Federated Reinforcement Learning with Environment Heterogeneity (FRL-EH) framework, where local environments exhibit statistical heterogeneity. Within this framework, agents collaboratively learn a global policy by aggregating their collective experiences while preserving the privacy of their local trajectories. To better reflect real-world scenarios, we introduce a robust FRL-EH framework by presenting a novel global objective function. This function is specifically designed to optimize a global policy that ensures robust performance across heterogeneous local environments and their plausible perturbations. We propose a tabular FRL algorithm named FedRQ and theoretically prove its asymptotic convergence to an optimal policy for the global objective function. Furthermore, we extend FedRQ to environments with continuous state space through the use of expectile loss, addressing the key challenge of minimizing a value function over a continuous subset of the state space. This advancement facilitates the seamless integration of the principles of FedRQ with various Deep Neural Network (DNN)-based RL algorithms. Extensive empirical evaluations validate the effectiveness and robustness of our FRL algorithms across diverse heterogeneous environments, consistently achieving superior performance over the existing state-of-the-art FRL algorithms.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Amico: An Event-Driven Modular Framework for Persistent and Embedded Autonomy</title>
<link>https://arxiv.org/abs/2507.14513</link>
<guid>https://arxiv.org/abs/2507.14513</guid>
<content:encoded><![CDATA[
arXiv:2507.14513v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) and autonomous agents have enabled systems capable of performing complex tasks across domains such as human-computer interaction, planning, and web navigation. However, many existing frameworks struggle in real-world or resource-constrained environments due to their reliance on cloud-based computation, limited robustness in dynamic contexts, and lack of persistent autonomy and environmental awareness.
  We present Amico, a modular, event-driven framework for building autonomous agents optimized for embedded systems. Written in Rust for safety and performance, Amico supports reactive, persistent agents that operate efficiently across embedded platforms and browser environments via WebAssembly. It provides clean abstractions for event handling, state management, behavior execution, and integration with reasoning modules. Amico delivers a unified infrastructure for constructing resilient, interactive agents suitable for deployment in settings with limited compute and intermittent connectivity.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards a Proactive Autoscaling Framework for Data Stream Processing at the Edge using GRU and Transfer Learning</title>
<link>https://arxiv.org/abs/2507.14597</link>
<guid>https://arxiv.org/abs/2507.14597</guid>
<content:encoded><![CDATA[
arXiv:2507.14597v1 Announce Type: new 
Abstract: Processing data at high speeds is becoming increasingly critical as digital economies generate enormous data. The current paradigms for timely data processing are edge computing and data stream processing (DSP). Edge computing places resources closer to where data is generated, while stream processing analyzes the unbounded high-speed data in motion. However, edge stream processing faces rapid workload fluctuations, complicating resource provisioning. Inadequate resource allocation leads to bottlenecks, whereas excess allocation results in wastage. Existing reactive methods, such as threshold-based policies and queuing theory scale only after performance degrades, potentially violating SLAs. Although reinforcement learning (RL) offers a proactive approach through agents that learn optimal runtime adaptation policies, it requires extensive simulation. Furthermore, predictive machine learning models face online distribution and concept drift that minimize their accuracy. We propose a three-step solution to the proactive edge stream processing autoscaling problem. Firstly, a GRU neural network forecasts the upstream load using real-world and synthetic DSP datasets. Secondly, a transfer learning framework integrates the predictive model into an online stream processing system using the DTW algorithm and joint distribution adaptation to handle the disparities between offline and online domains. Finally, a horizontal autoscaling module dynamically adjusts the degree of operator parallelism, based on predicted load while considering edge resource constraints. The lightweight GRU model for load predictions recorded up to 1.3\% SMAPE value on a real-world data set. It outperformed CNN, ARIMA, and Prophet on the SMAPE and RMSE evaluation metrics, with lower training time than the computationally intensive RL models.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Satellite-Augmented Low-Altitude Economy and Terrestrial Networks: A Survey on Generative Approaches</title>
<link>https://arxiv.org/abs/2507.14633</link>
<guid>https://arxiv.org/abs/2507.14633</guid>
<content:encoded><![CDATA[
arXiv:2507.14633v1 Announce Type: new 
Abstract: The development of satellite-augmented low-altitude economy and terrestrial networks (SLAETNs) demands intelligent and autonomous systems that can operate reliably across heterogeneous, dynamic, and mission-critical environments. To address these challenges, this survey focuses on enabling agentic artificial intelligence (AI), that is, artificial agents capable of perceiving, reasoning, and acting, through generative AI (GAI) and large language models (LLMs). We begin by introducing the architecture and characteristics of SLAETNs, and analyzing the challenges that arise in integrating satellite, aerial, and terrestrial components. Then, we present a model-driven foundation by systematically reviewing five major categories of generative models: variational autoencoders (VAEs), generative adversarial networks (GANs), generative diffusion models (GDMs), transformer-based models (TBMs), and LLMs. Moreover, we provide a comparative analysis to highlight their generative mechanisms, capabilities, and deployment trade-offs within SLAETNs. Building on this foundation, we examine how these models empower agentic functions across three domains: communication enhancement, security and privacy protection, and intelligent satellite tasks. Finally, we outline key future directions for building scalable, adaptive, and trustworthy generative agents in SLAETNs. This survey aims to provide a unified understanding and actionable reference for advancing agentic AI in next-generation integrated networks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Communicate in Multi-Agent Reinforcement Learning for Autonomous Cyber Defence</title>
<link>https://arxiv.org/abs/2507.14658</link>
<guid>https://arxiv.org/abs/2507.14658</guid>
<content:encoded><![CDATA[
arXiv:2507.14658v1 Announce Type: new 
Abstract: Popular methods in cooperative Multi-Agent Reinforcement Learning with partially observable environments typically allow agents to act independently during execution, which may limit the coordinated effect of the trained policies. However, by sharing information such as known or suspected ongoing threats, effective communication can lead to improved decision-making in the cyber battle space. We propose a game design where defender agents learn to communicate and defend against imminent cyber threats by playing training games in the Cyber Operations Research Gym, using the Differentiable Inter Agent Learning algorithm adapted to the cyber operational environment. The tactical policies learned by these autonomous agents are akin to those of human experts during incident responses to avert cyber threats. In addition, the agents simultaneously learn minimal cost communication messages while learning their defence tactical policies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Autonomy Goes Rogue: Preparing for Risks of Multi-Agent Collusion in Social Systems</title>
<link>https://arxiv.org/abs/2507.14660</link>
<guid>https://arxiv.org/abs/2507.14660</guid>
<content:encoded><![CDATA[
arXiv:2507.14660v1 Announce Type: new 
Abstract: Recent large-scale events like election fraud and financial scams have shown how harmful coordinated efforts by human groups can be. With the rise of autonomous AI systems, there is growing concern that AI-driven groups could also cause similar harm. While most AI safety research focuses on individual AI systems, the risks posed by multi-agent systems (MAS) in complex real-world situations are still underexplored. In this paper, we introduce a proof-of-concept to simulate the risks of malicious MAS collusion, using a flexible framework that supports both centralized and decentralized coordination structures. We apply this framework to two high-risk fields: misinformation spread and e-commerce fraud. Our findings show that decentralized systems are more effective at carrying out malicious actions than centralized ones. The increased autonomy of decentralized systems allows them to adapt their strategies and cause more damage. Even when traditional interventions, like content flagging, are applied, decentralized groups can adjust their tactics to avoid detection. We present key insights into how these malicious groups operate and the need for better detection systems and countermeasures. Code is available at https://github.com/renqibing/RogueAgent.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WSI-Agents: A Collaborative Multi-Agent System for Multi-Modal Whole Slide Image Analysis</title>
<link>https://arxiv.org/abs/2507.14680</link>
<guid>https://arxiv.org/abs/2507.14680</guid>
<content:encoded><![CDATA[
arXiv:2507.14680v1 Announce Type: new 
Abstract: Whole slide images (WSIs) are vital in digital pathology, enabling gigapixel tissue analysis across various pathological tasks. While recent advancements in multi-modal large language models (MLLMs) allow multi-task WSI analysis through natural language, they often underperform compared to task-specific models. Collaborative multi-agent systems have emerged as a promising solution to balance versatility and accuracy in healthcare, yet their potential remains underexplored in pathology-specific domains. To address these issues, we propose WSI-Agents, a novel collaborative multi-agent system for multi-modal WSI analysis. WSI-Agents integrates specialized functional agents with robust task allocation and verification mechanisms to enhance both task-specific accuracy and multi-task versatility through three components: (1) a task allocation module assigning tasks to expert agents using a model zoo of patch and WSI level MLLMs, (2) a verification mechanism ensuring accuracy through internal consistency checks and external validation using pathology knowledge bases and domain-specific models, and (3) a summary module synthesizing the final summary with visual interpretation maps. Extensive experiments on multi-modal WSI benchmarks show WSI-Agents's superiority to current WSI MLLMs and medical agent frameworks across diverse tasks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Configurable multi-agent framework for scalable and realistic testing of llm-based agents</title>
<link>https://arxiv.org/abs/2507.14705</link>
<guid>https://arxiv.org/abs/2507.14705</guid>
<content:encoded><![CDATA[
arXiv:2507.14705v1 Announce Type: new 
Abstract: Large-language-model (LLM) agents exhibit complex, context-sensitive behaviour that quickly renders static benchmarks and ad-hoc manual testing obsolete.
  We present Neo, a configurable, multi-agent framework that automates realistic, multi-turn evaluation of LLM-based systems. Neo couples a Question Generation Agent and an Evaluation Agent through a shared context-hub, allowing domain prompts, scenario controls and dynamic feedback to be composed modularly. Test inputs are sampled from a probabilistic state model spanning dialogue flow, user intent and emotional tone, enabling diverse, human-like conversations that adapt after every turn.
  Applied to a production-grade Seller Financial Assistant chatbot, Neo (i) uncovered edge-case failures across five attack categories with a 3.3% break rate close to the 5.8% achieved by expert human red-teamers, and (ii) delivered 10-12X higher throughput, generating 180 coherent test questions in around 45 mins versus 16h of human effort. Beyond security probing, Neo's stochastic policies balanced topic coverage and conversational depth, yielding broader behavioural exploration than manually crafted scripts.
  Neo therefore lays a foundation for scalable, self-evolving LLM QA: its agent interfaces, state controller and feedback loops are model-agnostic and extensible to richer factual-grounding and policy-compliance checks. We release the framework to facilitate reproducible, high-fidelity testing of emerging agentic systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulating Chirality: Solving Distance-$k$-Dispersion on an 1-Interval Connected Ring</title>
<link>https://arxiv.org/abs/2507.14723</link>
<guid>https://arxiv.org/abs/2507.14723</guid>
<content:encoded><![CDATA[
arXiv:2507.14723v1 Announce Type: new 
Abstract: We study the Distance-$k$-Dispersion (D-$k$-D) problem for synchronous mobile agents in a 1-interval-connected ring network having $n$ nodes and with $l$ agents where $3 \le l \le \lfloor \frac{n}{k}\rfloor$, without the assumption of chirality (a common sense of direction for the agents). This generalizes the classical dispersion problem by requiring that agents maintain a minimum distance of $k$ hops from each other, with the special case $k=1$ corresponding to the standard dispersion.
  The contribution in this work is threefold. Our first contribution is a novel method that enables agents to simulate chirality using only local information, vision and bounded memory. This technique demonstrates that chirality is not a fundamental requirement for coordination in this model.
  Building on this, our second contribution partially resolves an open question posed by Agarwalla et al. (ICDCN, 2018), who considered the same model (1- interval connected ring, synchronous agents, no chirality). We prove that D-$k$-D, and thus dispersion is solvable from any arbitrary configuration under these assumptions (excluding vertex permutation dynamism)for any size of the ring network which was earlier limited to only odd sized ring or to a ring of size four.
  Finally, we present an algorithm for D-$k$-D in this setting that works in $O(ln)$ rounds, completing the constructive side of our result.
  Altogether, our findings significantly extend the theoretical understanding of mobile agent coordination in dynamic networks and clarify the role of chirality in distributed computation.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards AI Urban Planner in the Age of GenAI, LLMs, and Agentic AI</title>
<link>https://arxiv.org/abs/2507.14730</link>
<guid>https://arxiv.org/abs/2507.14730</guid>
<content:encoded><![CDATA[
arXiv:2507.14730v1 Announce Type: new 
Abstract: Generative AI, large language models, and agentic AI have emerged separately of urban planning. However, the convergence between AI and urban planning presents an interesting opportunity towards AI urban planners. This paper conceptualizes urban planning as a generative AI task, where AI synthesizes land-use configurations under geospatial, social, and human-centric constraints. We survey how generative AI approaches, including VAEs, GANs, transformers, and diffusion models, reshape urban design. We further identify critical gaps: 1) limited research on integrating urban theory guidance, 2) limited research of AI urban planning over multiple spatial resolutions or angularities, 3) limited research on augmenting urban design knowledge from data, and 4) limited research on addressing real-world interactions. To address these limitations, we outline future research directions in theory-guided generation, digital twins, and human-machine co-design, calling for a new synthesis of generative intelligence and participatory urbanism.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Manipulating LLM Web Agents with Indirect Prompt Injection Attack via HTML Accessibility Tree</title>
<link>https://arxiv.org/abs/2507.14799</link>
<guid>https://arxiv.org/abs/2507.14799</guid>
<content:encoded><![CDATA[
arXiv:2507.14799v1 Announce Type: new 
Abstract: This work demonstrates that LLM-based web navigation agents offer powerful automation capabilities but are vulnerable to Indirect Prompt Injection (IPI) attacks. We show that adversaries can embed universal adversarial triggers in webpage HTML to hijack agent behavior that utilizes the accessibility tree to parse HTML, causing unintended or malicious actions. Using the Greedy Coordinate Gradient (GCG) algorithm and a Browser Gym agent powered by Llama-3.1, our system demonstrates high success rates across real websites in both targeted and general attacks, including login credential exfiltration and forced ad clicks. Our empirical results highlight critical security risks and the need for stronger defenses as LLM-driven autonomous web agents become more widely adopted. The system software (https://github.com/sej2020/manipulating-web-agents) is released under the MIT License, with an accompanying publicly available demo website (http://lethaiq.github.io/attack-web-llm-agent).
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Multi-Agent Reinforcement Learning with Control Barrier Functions for Safety-Critical Autonomous Systems</title>
<link>https://arxiv.org/abs/2507.14850</link>
<guid>https://arxiv.org/abs/2507.14850</guid>
<content:encoded><![CDATA[
arXiv:2507.14850v1 Announce Type: new 
Abstract: We address the problem of safe policy learning in multi-agent safety-critical autonomous systems. In such systems, it is necessary for each agent to meet the safety requirements at all times while also cooperating with other agents to accomplish the task. Toward this end, we propose a safe Hierarchical Multi-Agent Reinforcement Learning (HMARL) approach based on Control Barrier Functions (CBFs). Our proposed hierarchical approach decomposes the overall reinforcement learning problem into two levels learning joint cooperative behavior at the higher level and learning safe individual behavior at the lower or agent level conditioned on the high-level policy. Specifically, we propose a skill-based HMARL-CBF algorithm in which the higher level problem involves learning a joint policy over the skills for all the agents and the lower-level problem involves learning policies to execute the skills safely with CBFs. We validate our approach on challenging environment scenarios whereby a large number of agents have to safely navigate through conflicting road networks. Compared with existing state of the art methods, our approach significantly improves the safety achieving near perfect (within 5%) success/safety rate while also improving performance across all the environments.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentFly: Extensible and Scalable Reinforcement Learning for LM Agents</title>
<link>https://arxiv.org/abs/2507.14897</link>
<guid>https://arxiv.org/abs/2507.14897</guid>
<content:encoded><![CDATA[
arXiv:2507.14897v1 Announce Type: new 
Abstract: Language model (LM) agents have gained significant attention for their ability to autonomously complete tasks through interactions with environments, tools, and APIs. LM agents are primarily built with prompt engineering or supervised finetuning. At the same time, reinforcement learning (RL) has been explored to enhance LM's capabilities, such as reasoning and factuality. However, the combination of the LM agents and reinforcement learning (Agent-RL) remains underexplored and lacks systematic study. To this end, we built AgentFly, a scalable and extensible Agent-RL framework designed to empower LM agents with a variety of RL algorithms. Our framework supports multi-turn interactions by adapting traditional RL methods with token-level masking. It features a decorator-based interface for defining tools and reward functions, enabling seamless extension and ease of use. To support high-throughput training, we implement asynchronous execution of tool calls and reward computations, and design a centralized resource management system for scalable environment coordination. We also provide a suite of prebuilt tools and environments, demonstrating the framework's effectiveness through successful agent training across multiple tasks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>InsightX Agent: An LMM-based Agentic Framework with Integrated Tools for Reliable X-ray NDT Analysis</title>
<link>https://arxiv.org/abs/2507.14899</link>
<guid>https://arxiv.org/abs/2507.14899</guid>
<content:encoded><![CDATA[
arXiv:2507.14899v1 Announce Type: new 
Abstract: Non-destructive testing (NDT), particularly X-ray inspection, is vital for industrial quality assurance, yet existing deep-learning-based approaches often lack interactivity, interpretability, and the capacity for critical self-assessment, limiting their reliability and operator trust. To address these shortcomings, this paper proposes InsightX Agent, a novel LMM-based agentic framework designed to deliver reliable, interpretable, and interactive X-ray NDT analysis. Unlike typical sequential pipelines, InsightX Agent positions a Large Multimodal Model (LMM) as a central orchestrator, coordinating between the Sparse Deformable Multi-Scale Detector (SDMSD) and the Evidence-Grounded Reflection (EGR) tool. The SDMSD generates dense defect region proposals for multi-scale feature maps and sparsifies them through Non-Maximum Suppression (NMS), optimizing detection of small, dense targets in X-ray images while maintaining computational efficiency. The EGR tool guides the LMM agent through a chain-of-thought-inspired review process, incorporating context assessment, individual defect analysis, false positive elimination, confidence recalibration and quality assurance to validate and refine the SDMSD's initial proposals. By strategically employing and intelligently using tools, InsightX Agent moves beyond passive data processing to active reasoning, enhancing diagnostic reliability and providing interpretations that integrate diverse information sources. Experimental evaluations on the GDXray+ dataset demonstrate that InsightX Agent not only achieves a high object detection F1-score of 96.35% but also offers significantly improved interpretability and trustworthiness in its analyses, highlighting the transformative potential of agentic LLM frameworks for industrial inspection tasks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TriCLIP-3D: A Unified Parameter-Efficient Framework for Tri-Modal 3D Visual Grounding based on CLIP</title>
<link>https://arxiv.org/abs/2507.14904</link>
<guid>https://arxiv.org/abs/2507.14904</guid>
<content:encoded><![CDATA[
arXiv:2507.14904v1 Announce Type: new 
Abstract: 3D visual grounding allows an embodied agent to understand visual information in real-world 3D environments based on human instructions, which is crucial for embodied intelligence. Existing 3D visual grounding methods typically rely on separate encoders for different modalities (e.g., RGB images, text, and 3D point clouds), resulting in large and complex models that are inefficient to train. While some approaches use pre-trained 2D multi-modal models like CLIP for 3D tasks, they still struggle with aligning point cloud data to 2D encoders. As a result, these methods continue to depend on 3D encoders for feature extraction, further increasing model complexity and training inefficiency. In this paper, we propose a unified 2D pre-trained multi-modal network to process all three modalities (RGB images, text, and point clouds), significantly simplifying the architecture. By leveraging a 2D CLIP bi-modal model with adapter-based fine-tuning, this framework effectively adapts to the tri-modal setting, improving both adaptability and performance across modalities. Our Geometric-Aware 2D-3D Feature Recovery and Fusion (GARF) module is designed to fuse geometric multi-scale features from point clouds and images. We then integrate textual features for final modality fusion and introduce a multi-modal decoder to facilitate deep cross-modal understanding. Together, our method achieves unified feature extraction and fusion across the three modalities, enabling an end-to-end 3D visual grounding model. Compared to the baseline, our method reduces the number of trainable parameters by approximately 58\%, while achieving a 6.52\% improvement in the 3D detection task and a 6.25\% improvement in the 3D visual grounding task.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Redefining Elderly Care with Agentic AI: Challenges and Opportunities</title>
<link>https://arxiv.org/abs/2507.14912</link>
<guid>https://arxiv.org/abs/2507.14912</guid>
<content:encoded><![CDATA[
arXiv:2507.14912v1 Announce Type: new 
Abstract: The global ageing population necessitates new and emerging strategies for caring for older adults. In this article, we explore the potential for transformation in elderly care through Agentic Artificial Intelligence (AI), powered by Large Language Models (LLMs). We discuss the proactive and autonomous decision-making facilitated by Agentic AI in elderly care. Personalized tracking of health, cognitive care, and environmental management, all aimed at enhancing independence and high-level living for older adults, represents important areas of application. With a potential for significant transformation of elderly care, Agentic AI also raises profound concerns about data privacy and security, decision independence, and access. We share key insights to emphasize the need for ethical safeguards, privacy protections, and transparent decision-making. Our goal in this article is to provide a balanced discussion of both the potential and the challenges associated with Agentic AI, and to provide insights into its responsible use in elderly care, to bring Agentic AI into harmony with the requirements and vulnerabilities specific to the elderly. Finally, we identify the priorities for the academic research communities, to achieve human-centered advancements and integration of Agentic AI in elderly care. To the best of our knowledge, this is no existing study that reviews the role of Agentic AI in elderly care. Hence, we address the literature gap by analyzing the unique capabilities, applications, and limitations of LLM-based Agentic AI in elderly care. We also provide a companion interactive dashboard at https://hazratali.github.io/agenticai/.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-Robust Decentralized Coordination of LLM Agents</title>
<link>https://arxiv.org/abs/2507.14928</link>
<guid>https://arxiv.org/abs/2507.14928</guid>
<content:encoded><![CDATA[
arXiv:2507.14928v1 Announce Type: new 
Abstract: Collaboration among multiple large language model (LLM) agents is a promising approach to overcome inherent limitations of single-agent systems, such as hallucinations and single points of failure. As LLM agents are increasingly deployed on open blockchain platforms, multi-agent systems capable of tolerating malicious (Byzantine) agents have become essential.
  Recent Byzantine-robust multi-agent systems typically rely on leader-driven coordination, which suffers from two major drawbacks. First, they are inherently vulnerable to targeted attacks against the leader. If consecutive leaders behave maliciously, the system repeatedly fails to achieve consensus, forcing new consensus rounds, which is particularly costly given the high latency of LLM invocations. Second, an underperforming proposal from the leader can be accepted as the final answer even when higher-quality alternatives are available, as existing methods finalize the leader's proposal once it receives a quorum of votes.
  To address these issues, we propose DecentLLMs, a novel decentralized consensus approach for multi-agent LLM systems, where worker agents generate answers concurrently and evaluator agents independently score and rank these answers to select the best available one. This decentralized architecture enables faster consensus despite the presence of Byzantine agents and consistently selects higher-quality answers through Byzantine-robust aggregation techniques.
  Experimental results demonstrate that DecentLLMs effectively tolerates Byzantine agents and significantly improves the quality of selected answers.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Echoes of the Land: An Interactive Installation Based on Physical Model of Earthquake</title>
<link>https://arxiv.org/abs/2507.14947</link>
<guid>https://arxiv.org/abs/2507.14947</guid>
<content:encoded><![CDATA[
arXiv:2507.14947v1 Announce Type: new 
Abstract: Echoes of the Land is an interactive installation that transforms seismic dynamics into a multisensory experience through a scientifically grounded spring-block model. Simulating earthquake recurrence and self-organized criticality, the work generates real-time sound and light via motion capture and concatenative granular synthesis. Each block acts as an agent, producing emergent audiovisual cascades that visualize the physics of rupture and threshold behavior. This work exemplifies the amalgamation of scientific knowledge and artistic practice, opening new avenues for novel forms of musical instrument and narrative medium, while inviting further investigation into the intersection of emergent complexity, aesthetics and interactivity.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Probing EFX via PMMS: (Non-)Existence Results in Discrete Fair Division</title>
<link>https://arxiv.org/abs/2507.14957</link>
<guid>https://arxiv.org/abs/2507.14957</guid>
<content:encoded><![CDATA[
arXiv:2507.14957v1 Announce Type: new 
Abstract: We study the fair division of indivisible items and provide new insights into the EFX problem, which is widely regarded as the central open question in fair division, and the PMMS problem, a strictly stronger variant of EFX. Our first result constructs a three-agent instance with two monotone valuations and one additive valuation in which no PMMS allocation exists. Since EFX allocations are known to exist under these assumptions, this establishes a formal separation between EFX and PMMS.
  We prove existence of fair allocations for three important special cases. We show that EFX allocations exist for personalized bivalued valuations, where for each agent $i$ there exist values $a_i > b_i$ such that agent $i$ assigns value $v_i(\{g\}) \in \{a_i, b_i\}$ to each good $g$. We establish an analogous existence result for PMMS allocations when $a_i$ is divisible by $b_i$. We also prove that PMMS allocations exist for binary-valued MMS-feasible valuations, where each bundle $S$ has value $v_i(S) \in \{0, 1\}$. Notably, this result holds even without assuming monotonicity of valuations and thus applies to the fair division of chores and mixed manna. Finally, we study a class of valuations called pair-demand valuations, which extend the well-studied unit-demand valuations to the case where each agent derives value from at most two items, and we show that PMMS allocations exist in this setting. Our proofs are constructive, and we provide polynomial-time algorithms for all three existence results.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Think Like an Engineer: A Neuro-Symbolic Collaboration Agent for Generative Software Requirements Elicitation and Self-Review</title>
<link>https://arxiv.org/abs/2507.14969</link>
<guid>https://arxiv.org/abs/2507.14969</guid>
<content:encoded><![CDATA[
arXiv:2507.14969v1 Announce Type: new 
Abstract: The vision of End-User Software Engineering (EUSE) is to empower non-professional users with full control over the software development lifecycle. It aims to enable users to drive generative software development using only natural language requirements. However, since end-users often lack knowledge of software engineering, their requirement descriptions are frequently ambiguous, raising significant challenges to generative software development. Although existing approaches utilize structured languages like Gherkin to clarify user narratives, they still struggle to express the causal logic between preconditions and behavior actions. This paper introduces RequireCEG, a requirement elicitation and self-review agent that embeds causal-effect graphs (CEGs) in a neuro-symbolic collaboration architecture. RequireCEG first uses a feature tree to analyze user narratives hierarchically, clearly defining the scope of software components and their system behavior requirements. Next, it constructs the self-healing CEGs based on the elicited requirements, capturing the causal relationships between atomic preconditions and behavioral actions. Finally, the constructed CEGs are used to review and optimize Gherkin scenarios, ensuring consistency between the generated Gherkin requirements and the system behavior requirements elicited from user narratives. To evaluate our method, we created the RGPair benchmark dataset and conducted extensive experiments. It achieves an 87% coverage rate and raises diversity by 51.88%.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Enhanced Multi-Agent Reinforcement Learning with Expert Workflow for Real-Time P2P Energy Trading</title>
<link>https://arxiv.org/abs/2507.14995</link>
<guid>https://arxiv.org/abs/2507.14995</guid>
<content:encoded><![CDATA[
arXiv:2507.14995v1 Announce Type: new 
Abstract: Real-time peer-to-peer (P2P) electricity markets dynamically adapt to fluctuations in renewable energy and variations in demand, maximizing economic benefits through instantaneous price responses while enhancing grid flexibility. However, scaling expert guidance for massive personalized prosumers poses critical challenges, including diverse decision-making demands and lack of customized modeling frameworks. This paper proposed an integrated large language model-multi-agent reinforcement learning (LLM-MARL) framework for real-time P2P energy trading to address challenges such as the limited technical capability of prosumers, the lack of expert experience, and security issues of distribution networks. LLMs are introduced as experts to generate personalized strategy, guiding MARL under the centralized training with decentralized execution (CTDE) paradigm through imitation learning. A differential attention-based critic network is designed to enhance convergence performance. Experimental results demonstrate that LLM generated strategies effectively substitute human experts. The proposed multi-agent imitation learning algorithms achieve significantly lower economic costs and voltage violation rates on test sets compared to baselines algorithms, while maintaining robust stability. This work provides an effective solution for real-time P2P electricity market decision-making by bridging expert knowledge with agent learning.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Rise of AI Teammates in Software Engineering (SE) 3.0: How Autonomous Coding Agents Are Reshaping Software Engineering</title>
<link>https://arxiv.org/abs/2507.15003</link>
<guid>https://arxiv.org/abs/2507.15003</guid>
<content:encoded><![CDATA[
arXiv:2507.15003v1 Announce Type: new 
Abstract: The future of software engineering--SE 3.0--is unfolding with the rise of AI teammates: autonomous, goal-driven systems collaborating with human developers. Among these, autonomous coding agents are especially transformative, now actively initiating, reviewing, and evolving code at scale. This paper introduces AIDev, the first large-scale dataset capturing how such agents operate in the wild. Spanning over 456,000 pull requests by five leading agents--OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code--across 61,000 repositories and 47,000 developers, AIDev provides an unprecedented empirical foundation for studying autonomous teammates in software development.
  Unlike prior work that has largely theorized the rise of AI-native software engineering, AIDev offers structured, open data to support research in benchmarking, agent readiness, optimization, collaboration modeling, and AI governance. The dataset includes rich metadata on PRs, authorship, review timelines, code changes, and integration outcomes--enabling exploration beyond synthetic benchmarks like SWE-bench. For instance, although agents often outperform humans in speed, their PRs are accepted less frequently, revealing a trust and utility gap. Furthermore, while agents accelerate code submission--one developer submitted as many PRs in three days as they had in three years--these are structurally simpler (via code complexity metrics).
  We envision AIDev as a living resource: extensible, analyzable, and ready for the SE and AI communities. Grounding SE 3.0 in real-world evidence, AIDev enables a new generation of research into AI-native workflows and supports building the next wave of symbiotic human-AI collaboration. The dataset is publicly available at https://github.com/SAILResearch/AI_Teammates_in_SE3.
  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Software Engineering Agent
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EduThink4AI: Translating Educational Critical Thinking into Multi-Agent LLM Systems</title>
<link>https://arxiv.org/abs/2507.15015</link>
<guid>https://arxiv.org/abs/2507.15015</guid>
<content:encoded><![CDATA[
arXiv:2507.15015v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated significant potential as educational tutoring agents, capable of tailoring hints, orchestrating lessons, and grading with near-human finesse across various academic domains. However, current LLM-based educational systems exhibit critical limitations in promoting genuine critical thinking, failing on over one-third of multi-hop questions with counterfactual premises, and remaining vulnerable to adversarial prompts that trigger biased or factually incorrect responses. To address these gaps, we propose EDU-Prompting, a novel multi-agent framework that bridges established educational critical thinking theories with LLM agent design to generate critical, bias-aware explanations while fostering diverse perspectives. Our systematic evaluation across theoretical benchmarks and practical college-level critical writing scenarios demonstrates that EDU-Prompting significantly enhances both content truthfulness and logical soundness in AI-generated educational responses. The framework's modular design enables seamless integration into existing prompting frameworks and educational applications, allowing practitioners to directly incorporate critical thinking catalysts that promote analytical reasoning and introduce multiple perspectives without requiring extensive system modifications.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LibLMFuzz: LLM-Augmented Fuzz Target Generation for Black-box Libraries</title>
<link>https://arxiv.org/abs/2507.15058</link>
<guid>https://arxiv.org/abs/2507.15058</guid>
<content:encoded><![CDATA[
arXiv:2507.15058v1 Announce Type: new 
Abstract: A fundamental problem in cybersecurity and computer science is determining whether a program is free of bugs and vulnerabilities. Fuzzing, a popular approach to discovering vulnerabilities in programs, has several advantages over alternative strategies, although it has investment costs in the form of initial setup and continuous maintenance. The choice of fuzzing is further complicated when only a binary library is available, such as the case of closed-source and proprietary software. In response, we introduce LibLMFuzz, a framework that reduces costs associated with fuzzing closed-source libraries by pairing an agentic Large Language Model (LLM) with a lightweight tool-chain (disassembler/compiler/fuzzer) to autonomously analyze stripped binaries, plan fuzz strategies, generate drivers, and iteratively self-repair build or runtime errors. Tested on four widely-used Linux libraries, LibLMFuzz produced syntactically correct drivers for all 558 fuzz-able API functions, achieving 100% API coverage with no human intervention. Across the 1601 synthesized drivers, 75.52% were nominally correct on first execution. The results show that LLM-augmented middleware holds promise in reducing the costs of fuzzing black box components and provides a foundation for future research efforts. Future opportunities exist for research in branch coverage.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WebShaper: Agentically Data Synthesizing via Information-Seeking Formalization</title>
<link>https://arxiv.org/abs/2507.15061</link>
<guid>https://arxiv.org/abs/2507.15061</guid>
<content:encoded><![CDATA[
arXiv:2507.15061v1 Announce Type: new 
Abstract: The advent of Large Language Model (LLM)-powered agents has revolutionized artificial intelligence by enabling solutions to complex, open-ended tasks through web-based information-seeking (IS) capabilities. The scarcity of high-quality training data has limited the development of IS agents. Existing approaches typically adopt an information-driven paradigm that first collects web data and then generates questions based on the retrieval. However, this may lead to inconsistency between information structure and reasoning structure, question and answer. To mitigate, we propose a formalization-driven IS data synthesis framework WebShaper to construct a dataset. WebShaper systematically formalizes IS tasks through set theory. Central to the formalization is the concept of Knowledge Projections (KP), which enables precise control over reasoning structure by KP operation compositions. During synthesis, we begin by creating seed tasks, then use a multi-step expansion process. At each step, an agentic Expander expands the current formal question more complex with retrieval and validation tools based on our formalization. We train our model on the synthesized dataset. Experiment results demonstrate that WebShaper achieves state-of-the-art performance among open-sourced IS agents on GAIA and WebWalkerQA benchmarks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Search-Based Autonomous Vehicle Motion Planning Using Game Theory</title>
<link>https://arxiv.org/abs/2507.15088</link>
<guid>https://arxiv.org/abs/2507.15088</guid>
<content:encoded><![CDATA[
arXiv:2507.15088v1 Announce Type: new 
Abstract: In this paper, we propose a search-based interactive motion planning scheme for autonomous vehicles (AVs), using a game-theoretic approach. In contrast to traditional search-based approaches, the newly developed approach considers other road users (e.g. drivers and pedestrians) as intelligent agents rather than static obstacles. This leads to the generation of a more realistic path for the AV. Due to the low computational time, the proposed motion planning scheme is implementable in real-time applications. The performance of the developed motion planning scheme is compared with existing motion planning techniques and validated through experiments using WATonoBus, an electrical all-weather autonomous shuttle bus.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Kicking to Causality: Simulating Infant Agency Detection with a Robust Intrinsic Reward</title>
<link>https://arxiv.org/abs/2507.15106</link>
<guid>https://arxiv.org/abs/2507.15106</guid>
<content:encoded><![CDATA[
arXiv:2507.15106v1 Announce Type: new 
Abstract: While human infants robustly discover their own causal efficacy, standard reinforcement learning agents remain brittle, as their reliance on correlation-based rewards fails in noisy, ecologically valid scenarios. To address this, we introduce the Causal Action Influence Score (CAIS), a novel intrinsic reward rooted in causal inference. CAIS quantifies an action's influence by measuring the 1-Wasserstein distance between the learned distribution of sensory outcomes conditional on that action, $p(h|a)$, and the baseline outcome distribution, $p(h)$. This divergence provides a robust reward that isolates the agent's causal impact from confounding environmental noise. We test our approach in a simulated infant-mobile environment where correlation-based perceptual rewards fail completely when the mobile is subjected to external forces. In stark contrast, CAIS enables the agent to filter this noise, identify its influence, and learn the correct policy. Furthermore, the high-quality predictive model learned for CAIS allows our agent, when augmented with a surprise signal, to successfully reproduce the "extinction burst" phenomenon. We conclude that explicitly inferring causality is a crucial mechanism for developing a robust sense of agency, offering a psychologically plausible framework for more adaptive autonomous systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can We Move Freely in NEOM's The Line? An Agent-Based Simulation of Human Mobility in a Futuristic Smart City</title>
<link>https://arxiv.org/abs/2507.15143</link>
<guid>https://arxiv.org/abs/2507.15143</guid>
<content:encoded><![CDATA[
arXiv:2507.15143v1 Announce Type: new 
Abstract: This paper investigates the feasibility of human mobility in The Line, a proposed 170-kilometer linear smart city in NEOM, Saudi Arabia. To assess whether citizens can move freely within this unprecedented urban topology, we develop a hybrid simulation framework that integrates agent-based modeling, reinforcement learning, supervised learning, and graph neural networks. The simulation captures multi-modal transportation behaviors across 50 vertical levels and varying density scenarios using both synthetic data and real-world traces from high-density cities. Our experiments reveal that with the full AI-integrated architecture, agents achieved an average commute time of 7.8 to 8.4 minutes, a satisfaction rate exceeding 89 percent, and a reachability index of over 91 percent, even during peak congestion periods. Ablation studies confirmed that the removal of intelligent modules such as reinforcement learning or graph neural networks significantly degrades performance, with commute times increasing by up to 85 percent and reachability falling below 70 percent. Environmental modeling further demonstrated low energy consumption and minimal CO2 emissions when electric modes are prioritized. The findings suggest that freedom of movement is not only conceptually achievable in The Line, but also operationally realistic if supported by adaptive AI systems, sustainable infrastructure, and real-time feedback loops.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>STL-GO: Spatio-Temporal Logic with Graph Operators for Distributed Systems with Multiple Network Topologies</title>
<link>https://arxiv.org/abs/2507.15147</link>
<guid>https://arxiv.org/abs/2507.15147</guid>
<content:encoded><![CDATA[
arXiv:2507.15147v1 Announce Type: new 
Abstract: Multi-agent systems (MASs) consisting of a number of autonomous agents that communicate, coordinate, and jointly sense the environment to achieve complex missions can be found in a variety of applications such as robotics, smart cities, and internet-of-things applications. Modeling and monitoring MAS requirements to guarantee overall mission objectives, safety, and reliability is an important problem. Such requirements implicitly require reasoning about diverse sensing and communication modalities between agents, analysis of the dependencies between agent tasks, and the spatial or virtual distance between agents. To capture such rich MAS requirements, we model agent interactions via multiple directed graphs, and introduce a new logic -- Spatio-Temporal Logic with Graph Operators (STL-GO). The key innovation in STL-GO are graph operators that enable us to reason about the number of agents along either the incoming or outgoing edges of the underlying interaction graph that satisfy a given property of interest; for example, the requirement that an agent should sense at least two neighboring agents whose task graphs indicate the ability to collaborate. We then propose novel distributed monitoring conditions for individual agents that use only local information to determine whether or not an STL-GO specification is satisfied. We compare the expressivity of STL-GO against existing spatio-temporal logic formalisms, and demonstrate the utility of STL-GO and our distributed monitors in a bike-sharing and a multi-drone case study.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Joint-Local Grounded Action Transformation for Sim-to-Real Transfer in Multi-Agent Traffic Control</title>
<link>https://arxiv.org/abs/2507.15174</link>
<guid>https://arxiv.org/abs/2507.15174</guid>
<content:encoded><![CDATA[
arXiv:2507.15174v1 Announce Type: new 
Abstract: Traffic Signal Control (TSC) is essential for managing urban traffic flow and reducing congestion. Reinforcement Learning (RL) offers an adaptive method for TSC by responding to dynamic traffic patterns, with multi-agent RL (MARL) gaining traction as intersections naturally function as coordinated agents. However, due to shifts in environmental dynamics, implementing MARL-based TSC policies in the real world often leads to a significant performance drop, known as the sim-to-real gap. Grounded Action Transformation (GAT) has successfully mitigated this gap in single-agent RL for TSC, but real-world traffic networks, which involve numerous interacting intersections, are better suited to a MARL framework. In this work, we introduce JL-GAT, an application of GAT to MARL-based TSC that balances scalability with enhanced grounding capability by incorporating information from neighboring agents. JL-GAT adopts a decentralized approach to GAT, allowing for the scalability often required in real-world traffic networks while still capturing key interactions between agents. Comprehensive experiments on various road networks under simulated adverse weather conditions, along with ablation studies, demonstrate the effectiveness of JL-GAT. The code is publicly available at https://github.com/DaRL-LibSignal/JL-GAT/.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PromptArmor: Simple yet Effective Prompt Injection Defenses</title>
<link>https://arxiv.org/abs/2507.15219</link>
<guid>https://arxiv.org/abs/2507.15219</guid>
<content:encoded><![CDATA[
arXiv:2507.15219v1 Announce Type: new 
Abstract: Despite their potential, recent research has demonstrated that LLM agents are vulnerable to prompt injection attacks, where malicious prompts are injected into the agent's input, causing it to perform an attacker-specified task rather than the intended task provided by the user. In this paper, we present PromptArmor, a simple yet effective defense against prompt injection attacks. Specifically, PromptArmor prompts an off-the-shelf LLM to detect and remove potential injected prompts from the input before the agent processes it. Our results show that PromptArmor can accurately identify and remove injected prompts. For example, using GPT-4o, GPT-4.1, or o4-mini, PromptArmor achieves both a false positive rate and a false negative rate below 1% on the AgentDojo benchmark. Moreover, after removing injected prompts with PromptArmor, the attack success rate drops to below 1%. We also demonstrate PromptArmor's effectiveness against adaptive attacks and explore different strategies for prompting an LLM. We recommend that PromptArmor be adopted as a standard baseline for evaluating new defenses against prompt injection attacks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EchoVoices: Preserving Generational Voices and Memories for Seniors and Children</title>
<link>https://arxiv.org/abs/2507.15221</link>
<guid>https://arxiv.org/abs/2507.15221</guid>
<content:encoded><![CDATA[
arXiv:2507.15221v1 Announce Type: new 
Abstract: Recent breakthroughs in intelligent speech and digital human technologies have primarily targeted mainstream adult users, often overlooking the distinct vocal patterns and interaction styles of seniors and children. These demographics possess distinct vocal characteristics, linguistic styles, and interaction patterns that challenge conventional ASR, TTS, and LLM systems. To address this, we introduce EchoVoices, an end-to-end digital human pipeline dedicated to creating persistent digital personas for seniors and children, ensuring their voices and memories are preserved for future generations. Our system integrates three core innovations: a k-NN-enhanced Whisper model for robust speech recognition of atypical speech; an age-adaptive VITS model for high-fidelity, speaker-aware speech synthesis; and an LLM-driven agent that automatically generates persona cards and leverages a RAG-based memory system for conversational consistency. Our experiments, conducted on the SeniorTalk and ChildMandarin datasets, demonstrate significant improvements in recognition accuracy, synthesis quality, and speaker similarity. EchoVoices provides a comprehensive framework for preserving generational voices, offering a new means of intergenerational connection and the creation of lasting digital legacies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solving Formal Math Problems by Decomposition and Iterative Reflection</title>
<link>https://arxiv.org/abs/2507.15225</link>
<guid>https://arxiv.org/abs/2507.15225</guid>
<content:encoded><![CDATA[
arXiv:2507.15225v1 Announce Type: new 
Abstract: General-purpose Large Language Models (LLMs) have achieved remarkable success in intelligence, performing comparably to human experts on complex reasoning tasks such as coding and mathematical reasoning. However, generating formal proofs in specialized languages like Lean 4 remains a significant challenge for these models, limiting their application in complex theorem proving and automated verification. Current approaches typically require specializing models through fine-tuning on dedicated formal corpora, incurring high costs for data collection and training. In this work, we introduce \textbf{Delta Prover}, an agent-based framework that orchestrates the interaction between a general-purpose LLM and the Lean 4 proof environment. Delta Prover leverages the reflection and reasoning capabilities of general-purpose LLMs to interactively construct formal proofs in Lean 4, circumventing the need for model specialization. At its core, the agent integrates two novel, interdependent components: an algorithmic framework for reflective decomposition and iterative proof repair, and a custom Domain-Specific Language (DSL) built upon Lean 4 for streamlined subproblem management. \textbf{Delta Prover achieves a state-of-the-art 95.9\% success rate on the miniF2F-test benchmark, surpassing all existing approaches, including those requiring model specialization.} Furthermore, Delta Prover exhibits a significantly stronger test-time scaling law compared to standard Best-of-N proof strategies. Crucially, our findings demonstrate that general-purpose LLMs, when guided by an effective agentic structure, possess substantial untapped theorem-proving capabilities. This presents a computationally efficient alternative to specialized models for robust automated reasoning in formal environments.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FaultLine: Automated Proof-of-Vulnerability Generation Using LLM Agents</title>
<link>https://arxiv.org/abs/2507.15241</link>
<guid>https://arxiv.org/abs/2507.15241</guid>
<content:encoded><![CDATA[
arXiv:2507.15241v1 Announce Type: new 
Abstract: Despite the critical threat posed by software security vulnerabilities, reports are often incomplete, lacking the proof-of-vulnerability (PoV) tests needed to validate fixes and prevent regressions. These tests are crucial not only for ensuring patches work, but also for helping developers understand how vulnerabilities can be exploited. Generating PoV tests is a challenging problem, requiring reasoning about the flow of control and data through deeply nested levels of a program.
  We present FaultLine, an LLM agent workflow that uses a set of carefully designed reasoning steps, inspired by aspects of traditional static and dynamic program analysis, to automatically generate PoV test cases. Given a software project with an accompanying vulnerability report, FaultLine 1) traces the flow of an input from an externally accessible API ("source") to the "sink" corresponding to the vulnerability, 2) reasons about the conditions that an input must satisfy in order to traverse the branch conditions encountered along the flow, and 3) uses this reasoning to generate a PoV test case in a feedback-driven loop. FaultLine does not use language-specific static or dynamic analysis components, which enables it to be used across programming languages.
  To evaluate FaultLine, we collate a challenging multi-lingual dataset of 100 known vulnerabilities in Java, C and C++ projects. On this dataset, FaultLine is able to generate PoV tests for 16 projects, compared to just 9 for CodeAct 2.1, a popular state-of-the-art open-source agentic framework. Thus, FaultLine represents a 77% relative improvement over the state of the art. Our findings suggest that hierarchical reasoning can enhance the performance of LLM agents on PoV test generation, but the problem in general remains challenging. We make our code and dataset publicly available in the hope that it will spur further research in this area.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SPAR: Scholar Paper Retrieval with LLM-based Agents for Enhanced Academic Search</title>
<link>https://arxiv.org/abs/2507.15245</link>
<guid>https://arxiv.org/abs/2507.15245</guid>
<content:encoded><![CDATA[
arXiv:2507.15245v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have opened new opportunities for academic literature retrieval. However, existing systems often rely on rigid pipelines and exhibit limited reasoning capabilities. We introduce SPAR, a multi-agent framework that incorporates RefChain-based query decomposition and query evolution to enable more flexible and effective search. To facilitate systematic evaluation, we also construct SPARBench, a challenging benchmark with expert-annotated relevance labels. Experimental results demonstrate that SPAR substantially outperforms strong baselines, achieving up to +56% F1 on AutoScholar and +23% F1 on SPARBench over the best-performing baseline. Together, SPAR and SPARBench provide a scalable, interpretable, and high-performing foundation for advancing research in scholarly retrieval. Code and data will be available at: https://github.com/xiaofengShi/SPAR
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IM-Chat: A Multi-agent LLM-based Framework for Knowledge Transfer in Injection Molding Industry</title>
<link>https://arxiv.org/abs/2507.15268</link>
<guid>https://arxiv.org/abs/2507.15268</guid>
<content:encoded><![CDATA[
arXiv:2507.15268v1 Announce Type: new 
Abstract: The injection molding industry faces critical challenges in preserving and transferring field knowledge, particularly as experienced workers retire and multilingual barriers hinder effective communication. This study introduces IM-Chat, a multi-agent framework based on large language models (LLMs), designed to facilitate knowledge transfer in injection molding. IM-Chat integrates both limited documented knowledge (e.g., troubleshooting tables, manuals) and extensive field data modeled through a data-driven process condition generator that infers optimal manufacturing settings from environmental inputs such as temperature and humidity, enabling robust and context-aware task resolution. By adopting a retrieval-augmented generation (RAG) strategy and tool-calling agents within a modular architecture, IM-Chat ensures adaptability without the need for fine-tuning. Performance was assessed across 100 single-tool and 60 hybrid tasks for GPT-4o, GPT-4o-mini, and GPT-3.5-turbo by domain experts using a 10-point rubric focused on relevance and correctness, and was further supplemented by automated evaluation using GPT-4o guided by a domain-adapted instruction prompt. The evaluation results indicate that more capable models tend to achieve higher accuracy, particularly in complex, tool-integrated scenarios. Overall, these findings demonstrate the viability of multi-agent LLM systems for industrial knowledge workflows and establish IM-Chat as a scalable and generalizable approach to AI-assisted decision support in manufacturing.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mixture of Autoencoder Experts Guidance using Unlabeled and Incomplete Data for Exploration in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.15287</link>
<guid>https://arxiv.org/abs/2507.15287</guid>
<content:encoded><![CDATA[
arXiv:2507.15287v1 Announce Type: new 
Abstract: Recent trends in Reinforcement Learning (RL) highlight the need for agents to learn from reward-free interactions and alternative supervision signals, such as unlabeled or incomplete demonstrations, rather than relying solely on explicit reward maximization. Additionally, developing generalist agents that can adapt efficiently in real-world environments often requires leveraging these reward-free signals to guide learning and behavior. However, while intrinsic motivation techniques provide a means for agents to seek out novel or uncertain states in the absence of explicit rewards, they are often challenged by dense reward environments or the complexity of high-dimensional state and action spaces. Furthermore, most existing approaches rely directly on the unprocessed intrinsic reward signals, which can make it difficult to shape or control the agent's exploration effectively. We propose a framework that can effectively utilize expert demonstrations, even when they are incomplete and imperfect. By applying a mapping function to transform the similarity between an agent's state and expert data into a shaped intrinsic reward, our method allows for flexible and targeted exploration of expert-like behaviors. We employ a Mixture of Autoencoder Experts to capture a diverse range of behaviors and accommodate missing information in demonstrations. Experiments show our approach enables robust exploration and strong performance in both sparse and dense reward environments, even when demonstrations are sparse or incomplete. This provides a practical framework for RL in realistic settings where optimal data is unavailable and precise reward control is needed.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Butterfly Effects in Toolchains: A Comprehensive Analysis of Failed Parameter Filling in LLM Tool-Agent Systems</title>
<link>https://arxiv.org/abs/2507.15296</link>
<guid>https://arxiv.org/abs/2507.15296</guid>
<content:encoded><![CDATA[
arXiv:2507.15296v1 Announce Type: new 
Abstract: The emergence of the tool agent paradigm has broadened the capability boundaries of the Large Language Model (LLM), enabling it to complete more complex tasks. However, the effectiveness of this paradigm is limited due to the issue of parameter failure during its execution. To explore this phenomenon and propose corresponding suggestions, we first construct a parameter failure taxonomy in this paper. We derive five failure categories from the invocation chain of a mainstream tool agent. Then, we explore the correlation between three different input sources and failure categories by applying 15 input perturbation methods to the input. Experimental results show that parameter name hallucination failure primarily stems from inherent LLM limitations, while issues with input sources mainly cause other failure patterns. To improve the reliability and effectiveness of tool-agent interactions, we propose corresponding improvement suggestions, including standardizing tool return formats, improving error feedback mechanisms, and ensuring parameter consistency.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strategically Robust Game Theory via Optimal Transport</title>
<link>https://arxiv.org/abs/2507.15325</link>
<guid>https://arxiv.org/abs/2507.15325</guid>
<content:encoded><![CDATA[
arXiv:2507.15325v1 Announce Type: new 
Abstract: In many game-theoretic settings, agents are challenged with taking decisions against the uncertain behavior exhibited by others. Often, this uncertainty arises from multiple sources, e.g., incomplete information, limited computation, bounded rationality. While it may be possible to guide the agents' decisions by modeling each source, their joint presence makes this task particularly daunting. Toward this goal, it is natural for agents to seek protection against deviations around the emergent behavior itself, which is ultimately impacted by all the above sources of uncertainty. To do so, we propose that each agent takes decisions in face of the worst-case behavior contained in an ambiguity set of tunable size, centered at the emergent behavior so implicitly defined. This gives rise to a novel equilibrium notion, which we call strategically robust equilibrium. Building on its definition, we show that, when judiciously operationalized via optimal transport, strategically robust equilibria (i) are guaranteed to exist under the same assumptions required for Nash equilibria; (ii) interpolate between Nash and security strategies; (iii) come at no additional computational cost compared to Nash equilibria. Through a variety of experiments, including bi-matrix games, congestion games, and Cournot competition, we show that strategic robustness protects against uncertainty in the opponents' behavior and, surprisingly, often results in higher equilibrium payoffs - an effect we refer to as coordination via robustification.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>QSAF: A Novel Mitigation Framework for Cognitive Degradation in Agentic AI</title>
<link>https://arxiv.org/abs/2507.15330</link>
<guid>https://arxiv.org/abs/2507.15330</guid>
<content:encoded><![CDATA[
arXiv:2507.15330v1 Announce Type: new 
Abstract: We introduce Cognitive Degradation as a novel vulnerability class in agentic AI systems. Unlike traditional adversarial external threats such as prompt injection, these failures originate internally, arising from memory starvation, planner recursion, context flooding, and output suppression. These systemic weaknesses lead to silent agent drift, logic collapse, and persistent hallucinations over time. To address this class of failures, we introduce the Qorvex Security AI Framework for Behavioral & Cognitive Resilience (QSAF Domain 10), a lifecycle-aware defense framework defined by a six-stage cognitive degradation lifecycle. The framework includes seven runtime controls (QSAF-BC-001 to BC-007) that monitor agent subsystems in real time and trigger proactive mitigation through fallback routing, starvation detection, and memory integrity enforcement. Drawing from cognitive neuroscience, we map agentic architectures to human analogs, enabling early detection of fatigue, starvation, and role collapse. By introducing a formal lifecycle and real-time mitigation controls, this work establishes Cognitive Degradation as a critical new class of AI system vulnerability and proposes the first cross-platform defense model for resilient agentic behavior.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One Step is Enough: Multi-Agent Reinforcement Learning based on One-Step Policy Optimization for Order Dispatch on Ride-Sharing Platforms</title>
<link>https://arxiv.org/abs/2507.15351</link>
<guid>https://arxiv.org/abs/2507.15351</guid>
<content:encoded><![CDATA[
arXiv:2507.15351v1 Announce Type: new 
Abstract: On-demand ride-sharing platforms face the fundamental challenge of dynamically bundling passengers with diverse origins and destinations and matching them with vehicles in real time, all under significant uncertainty. Recently, MARL has emerged as a promising solution for this problem, leveraging decentralized learning to address the curse of dimensionality caused by the large number of agents in the ride-hailing market and the resulting expansive state and action spaces. However, conventional MARL-based ride-sharing approaches heavily rely on the accurate estimation of Q-values or V-values, which becomes problematic in large-scale, highly uncertain environments. Specifically, most of these approaches adopt an independent paradigm, exacerbating this issue, as each agent treats others as part of the environment, leading to unstable training and substantial estimation bias in value functions. To address these challenges, we propose two novel alternative methods that bypass value function estimation. First, we adapt GRPO to ride-sharing, replacing the PPO baseline with the group average reward to eliminate critic estimation errors and reduce training bias. Second, inspired by GRPO's full utilization of group reward information, we customize the PPO framework for ride-sharing platforms and show that, under a homogeneous fleet, the optimal policy can be trained using only one-step rewards - a method we term One-Step Policy Optimization (OSPO). Experiments on a real-world Manhattan ride-hailing dataset demonstrate that both GRPO and OSPO achieve superior performance across most scenarios, efficiently optimizing pickup times and the number of served orders using simple MLP networks.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RAD: Retrieval High-quality Demonstrations to Enhance Decision-making</title>
<link>https://arxiv.org/abs/2507.15356</link>
<guid>https://arxiv.org/abs/2507.15356</guid>
<content:encoded><![CDATA[
arXiv:2507.15356v1 Announce Type: new 
Abstract: Offline reinforcement learning (RL) enables agents to learn policies from fixed datasets, avoiding costly or unsafe environment interactions. However, its effectiveness is often limited by dataset sparsity and the lack of transition overlap between suboptimal and expert trajectories, which makes long-horizon planning particularly challenging. Prior solutions based on synthetic data augmentation or trajectory stitching often fail to generalize to novel states and rely on heuristic stitching points. To address these challenges, we propose Retrieval High-quAlity Demonstrations (RAD) for decision-making, which combines non-parametric retrieval with diffusion-based generative modeling. RAD dynamically retrieves high-return states from the offline dataset as target states based on state similarity and return estimation, and plans toward them using a condition-guided diffusion model. Such retrieval-guided generation enables flexible trajectory stitching and improves generalization when encountered with underrepresented or out-of-distribution states. Extensive experiments confirm that RAD achieves competitive or superior performance compared to baselines across diverse benchmarks, validating its effectiveness.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PhishIntentionLLM: Uncovering Phishing Website Intentions through Multi-Agent Retrieval-Augmented Generation</title>
<link>https://arxiv.org/abs/2507.15419</link>
<guid>https://arxiv.org/abs/2507.15419</guid>
<content:encoded><![CDATA[
arXiv:2507.15419v1 Announce Type: new 
Abstract: Phishing websites remain a major cybersecurity threat, yet existing methods primarily focus on detection, while the recognition of underlying malicious intentions remains largely unexplored. To address this gap, we propose PhishIntentionLLM, a multi-agent retrieval-augmented generation (RAG) framework that uncovers phishing intentions from website screenshots. Leveraging the visual-language capabilities of large language models (LLMs), our framework identifies four key phishing objectives: Credential Theft, Financial Fraud, Malware Distribution, and Personal Information Harvesting. We construct and release the first phishing intention ground truth dataset (~2K samples) and evaluate the framework using four commercial LLMs. Experimental results show that PhishIntentionLLM achieves a micro-precision of 0.7895 with GPT-4o and significantly outperforms the single-agent baseline with a ~95% improvement in micro-precision. Compared to the previous work, it achieves 0.8545 precision for credential theft, marking a ~4% improvement. Additionally, we generate a larger dataset of ~9K samples for large-scale phishing intention profiling across sectors. This work provides a scalable and interpretable solution for intention-aware phishing analysis.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EgoPrune: Efficient Token Pruning for Egomotion Video Reasoning in Embodied Agent</title>
<link>https://arxiv.org/abs/2507.15428</link>
<guid>https://arxiv.org/abs/2507.15428</guid>
<content:encoded><![CDATA[
arXiv:2507.15428v1 Announce Type: new 
Abstract: Egomotion videos are first-person recordings where the view changes continuously due to the agent's movement. As they serve as the primary visual input for embodied AI agents, making egomotion video reasoning more efficient is therefore essential for real-world deployment. Recent advances in vision-language models have enabled strong multimodal reasoning capabilities, but their computational cost remains prohibitive for long, redundant video inputs. Existing token pruning methods, typically designed for third-person videos, fail to leverage the spatiotemporal continuity and motion constraints inherent in egomotion settings. To address this, we propose EgoPrune, a training-free token pruning method tailored for egomotion video reasoning. EgoPrune comprises three components: a keyframe selector adapted from EmbodiedR for temporally efficient sampling; Perspective-Aware Redundancy Filtering (PARF), which aligns visual tokens using perspective transformations and removes redundant tokens; and a Maximal Marginal Relevance (MMR)-based token selector that jointly considers visual-text relevance and intra-frame diversity. Experiments on two egomotion video benchmarks show that EgoPrune consistently outperforms prior training-free methods across various pruning ratios while significantly reducing FLOPs, memory usage, and latency. Moreover, we deploy EgoPrune on an embodied agent equipped with a Jetson Orin NX 16GB edge device, demonstrating its real-world efficiency and suitability for on-device egomotion video reasoning.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solving nonconvex Hamilton--Jacobi--Isaacs equations with PINN-based policy iteration</title>
<link>https://arxiv.org/abs/2507.15455</link>
<guid>https://arxiv.org/abs/2507.15455</guid>
<content:encoded><![CDATA[
arXiv:2507.15455v1 Announce Type: new 
Abstract: We propose a mesh-free policy iteration framework that combines classical dynamic programming with physics-informed neural networks (PINNs) to solve high-dimensional, nonconvex Hamilton--Jacobi--Isaacs (HJI) equations arising in stochastic differential games and robust control. The method alternates between solving linear second-order PDEs under fixed feedback policies and updating the controls via pointwise minimax optimization using automatic differentiation. Under standard Lipschitz and uniform ellipticity assumptions, we prove that the value function iterates converge locally uniformly to the unique viscosity solution of the HJI equation. The analysis establishes equi-Lipschitz regularity of the iterates, enabling provable stability and convergence without requiring convexity of the Hamiltonian. Numerical experiments demonstrate the accuracy and scalability of the method. In a two-dimensional stochastic path-planning game with a moving obstacle, our method matches finite-difference benchmarks with relative $L^2$-errors below %10^{-2}%. In five- and ten-dimensional publisher-subscriber differential games with anisotropic noise, the proposed approach consistently outperforms direct PINN solvers, yielding smoother value functions and lower residuals. Our results suggest that integrating PINNs with policy iteration is a practical and theoretically grounded method for solving high-dimensional, nonconvex HJI equations, with potential applications in robotics, finance, and multi-agent reinforcement learning.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Emergence of Deep Reinforcement Learning for Path Planning</title>
<link>https://arxiv.org/abs/2507.15469</link>
<guid>https://arxiv.org/abs/2507.15469</guid>
<content:encoded><![CDATA[
arXiv:2507.15469v1 Announce Type: new 
Abstract: The increasing demand for autonomous systems in complex and dynamic environments has driven significant research into intelligent path planning methodologies. For decades, graph-based search algorithms, linear programming techniques, and evolutionary computation methods have served as foundational approaches in this domain. Recently, deep reinforcement learning (DRL) has emerged as a powerful method for enabling autonomous agents to learn optimal navigation strategies through interaction with their environments. This survey provides a comprehensive overview of traditional approaches as well as the recent advancements in DRL applied to path planning tasks, focusing on autonomous vehicles, drones, and robotic platforms. Key algorithms across both conventional and learning-based paradigms are categorized, with their innovations and practical implementations highlighted. This is followed by a thorough discussion of their respective strengths and limitations in terms of computational efficiency, scalability, adaptability, and robustness. The survey concludes by identifying key open challenges and outlining promising avenues for future research. Special attention is given to hybrid approaches that integrate DRL with classical planning techniques to leverage the benefits of both learning-based adaptability and deterministic reliability, offering promising directions for robust and resilient autonomous navigation.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Constitutional Controller: Doubt-Calibrated Steering of Compliant Agents</title>
<link>https://arxiv.org/abs/2507.15478</link>
<guid>https://arxiv.org/abs/2507.15478</guid>
<content:encoded><![CDATA[
arXiv:2507.15478v1 Announce Type: new 
Abstract: Ensuring reliable and rule-compliant behavior of autonomous agents in uncertain environments remains a fundamental challenge in modern robotics. Our work shows how neuro-symbolic systems, which integrate probabilistic, symbolic white-box reasoning models with deep learning methods, offer a powerful solution to this challenge. This enables the simultaneous consideration of explicit rules and neural models trained on noisy data, combining the strength of structured reasoning with flexible representations. To this end, we introduce the Constitutional Controller (CoCo), a novel framework designed to enhance the safety and reliability of agents by reasoning over deep probabilistic logic programs representing constraints such as those found in shared traffic spaces. Furthermore, we propose the concept of self-doubt, implemented as a probability density conditioned on doubt features such as travel velocity, employed sensors, or health factors. In a real-world aerial mobility study, we demonstrate CoCo's advantages for intelligent autonomous systems to learn appropriate doubts and navigate complex and uncertain environments safely and compliantly.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HAMLET: Hyperadaptive Agent-based Modeling for Live Embodied Theatrics</title>
<link>https://arxiv.org/abs/2507.15518</link>
<guid>https://arxiv.org/abs/2507.15518</guid>
<content:encoded><![CDATA[
arXiv:2507.15518v1 Announce Type: new 
Abstract: Creating an immersive and interactive theatrical experience is a long-term goal in the field of interactive narrative. The emergence of large language model (LLM) is providing a new path to achieve this goal. However, existing LLM-based drama generation methods often result in AI agents that lack initiative and cannot interact with the physical environment. Furthermore, these methods typically require detailed user input to drive the drama. These limitations reduce the interactivity and immersion of online real-time performance. To address the above challenges, we propose HAMLET, a multi-agent framework focused on drama creation and online performance. Given a simple topic, the framework generates a narrative blueprint, guiding the subsequent improvisational performance. During the online performance, each actor is given an autonomous mind. This means that actors can make independent decisions based on their own background, goals, and emotional state. In addition to conversations with other actors, their decisions can also change the state of scene props through actions such as opening a letter or picking up a weapon. The change is then broadcast to other related actors, updating what they know and care about, which in turn influences their next action. To evaluate the quality of drama performance, we designed an evaluation method to assess three primary aspects, including character performance, narrative quality, and interaction experience. The experimental evaluation shows that HAMLET can create expressive and coherent theatrical experiences. Our code, dataset and models are available at https://github.com/HAMLET-2025/HAMLET.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PhysGym: Benchmarking LLMs in Interactive Physics Discovery with Controlled Priors</title>
<link>https://arxiv.org/abs/2507.15550</link>
<guid>https://arxiv.org/abs/2507.15550</guid>
<content:encoded><![CDATA[
arXiv:2507.15550v1 Announce Type: new 
Abstract: Evaluating the scientific discovery capabilities of large language model based agents, particularly how they cope with varying environmental complexity and utilize prior knowledge, requires specialized benchmarks currently lacking in the landscape. To address this gap, we introduce PhysGym, a novel benchmark suite and simulation platform for rigorously assessing LLM-based scientific reasoning in interactive physics environments. PhysGym's primary contribution lies in its sophisticated control over the level of prior knowledge provided to the agent. This allows researchers to dissect agent performance along axes including the complexity of the problem and the prior knowledge levels. The benchmark comprises a suite of interactive simulations, where agents must actively probe environments, gather data sequentially under constraints and formulate hypotheses about underlying physical laws. PhysGym provides standardized evaluation protocols and metrics for assessing hypothesis accuracy and model fidelity. We demonstrate the benchmark's utility by presenting results from baseline LLMs, showcasing its ability to differentiate capabilities based on varying priors and task complexity.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FlowForge: Guiding the Creation of Multi-agent Workflows with Design Space Visualization as a Thinking Scaffold</title>
<link>https://arxiv.org/abs/2507.15559</link>
<guid>https://arxiv.org/abs/2507.15559</guid>
<content:encoded><![CDATA[
arXiv:2507.15559v1 Announce Type: new 
Abstract: Multi-agent workflows have become an effective strategy for tackling complicated tasks by decomposing them into multiple sub-tasks and assigning them to specialized agents. However, designing optimal workflows remains challenging due to the vast and intricate design space. Current practices rely heavily on the intuition and expertise of practitioners, often resulting in design fixation or an unstructured, time-consuming exploration of trial-and-error. To address these challenges, this work introduces FLOWFORGE, an interactive visualization tool to facilitate the creation of multi-agent workflow through i) a structured visual exploration of the design space and ii) in-situ guidance informed by established design patterns. Based on formative studies and literature review, FLOWFORGE organizes the workflow design process into three hierarchical levels (i.e., task planning, agent assignment, and agent optimization), ranging from abstract to concrete. This structured visual exploration enables users to seamlessly move from high-level planning to detailed design decisions and implementations, while comparing alternative solutions across multiple performance metrics. Additionally, drawing from established workflow design patterns, FLOWFORGE provides context-aware, in-situ suggestions at each level as users navigate the design space, enhancing the workflow creation process with practical guidance. Use cases and user studies demonstrate the usability and effectiveness of FLOWFORGE, while also yielding valuable insights into how practitioners explore design spaces and leverage guidance during workflow development.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Red-Team Multi-Agent Reinforcement Learning for Emergency Braking Scenario</title>
<link>https://arxiv.org/abs/2507.15587</link>
<guid>https://arxiv.org/abs/2507.15587</guid>
<content:encoded><![CDATA[
arXiv:2507.15587v1 Announce Type: new 
Abstract: Current research on decision-making in safety-critical scenarios often relies on inefficient data-driven scenario generation or specific modeling approaches, which fail to capture corner cases in real-world contexts. To address this issue, we propose a Red-Team Multi-Agent Reinforcement Learning framework, where background vehicles with interference capabilities are treated as red-team agents. Through active interference and exploration, red-team vehicles can uncover corner cases outside the data distribution. The framework uses a Constraint Graph Representation Markov Decision Process, ensuring that red-team vehicles comply with safety rules while continuously disrupting the autonomous vehicles (AVs). A policy threat zone model is constructed to quantify the threat posed by red-team vehicles to AVs, inducing more extreme actions to increase the danger level of the scenario. Experimental results show that the proposed framework significantly impacts AVs decision-making safety and generates various corner cases. This method also offers a novel direction for research in safety-critical scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DHEvo: Data-Algorithm Based Heuristic Evolution for Generalizable MILP Solving</title>
<link>https://arxiv.org/abs/2507.15615</link>
<guid>https://arxiv.org/abs/2507.15615</guid>
<content:encoded><![CDATA[
arXiv:2507.15615v1 Announce Type: new 
Abstract: Primal heuristics play a critical role in improving the efficiency of mixed integer programming (MILP) solvers. As large language models (LLMs) have demonstrated superior code generation abilities, recent MILP works are devoted to leveraging the evolutionary computation approaches with LLMs to generate effective primal heuristics. Although the generated heuristics have achieved better solving performance than the hand-crafted ones with little adaptability, the advantage of current LLM-based methods is limited to few MILP instances in one problem class, as they fail to capture the instance characteristics in the problem class (the MILP instances generated from the same mathematical model are defined as a problem class). Since MILP instances often differ significantly in structure and feature distribution, the neglect of their characteristics in the evolution process results in poor generalization within the same problem class. To overcome this challenge, we propose a data-algorithm co-evolution framework (DHEvo) that iteratively selects representative instances and evolves corresponding heuristics. With the initial instance distribution, we develop an LLM-based multi-agent system to generate data-code pairs simultaneously. These data-code pairs are iteratively refined based on their fitness scores, leading to the identification of the most effective heuristic over the entire problem class. Extensive experiments across diverse MILP benchmarks demonstrate that our approach significantly outperforms both human-designed heuristics and existing LLM-based methods.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Why can't Epidemiology be automated (yet)?</title>
<link>https://arxiv.org/abs/2507.15617</link>
<guid>https://arxiv.org/abs/2507.15617</guid>
<content:encoded><![CDATA[
arXiv:2507.15617v1 Announce Type: new 
Abstract: Recent advances in artificial intelligence (AI) - particularly generative AI - present new opportunities to accelerate, or even automate, epidemiological research. Unlike disciplines based on physical experimentation, a sizable fraction of Epidemiology relies on secondary data analysis and thus is well-suited for such augmentation. Yet, it remains unclear which specific tasks can benefit from AI interventions or where roadblocks exist. Awareness of current AI capabilities is also mixed. Here, we map the landscape of epidemiological tasks using existing datasets - from literature review to data access, analysis, writing up, and dissemination - and identify where existing AI tools offer efficiency gains. While AI can increase productivity in some areas such as coding and administrative tasks, its utility is constrained by limitations of existing AI models (e.g. hallucinations in literature reviews) and human systems (e.g. barriers to accessing datasets). Through examples of AI-generated epidemiological outputs, including fully AI-generated papers, we demonstrate that recently developed agentic systems can now design and execute epidemiological analysis, albeit to varied quality (see https://github.com/edlowther/automated-epidemiology). Epidemiologists have new opportunities to empirically test and benchmark AI systems; realising the potential of AI will require two-way engagement between epidemiologists and engineers.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TacticCraft: Natural Language-Driven Tactical Adaptation for StarCraft II</title>
<link>https://arxiv.org/abs/2507.15618</link>
<guid>https://arxiv.org/abs/2507.15618</guid>
<content:encoded><![CDATA[
arXiv:2507.15618v1 Announce Type: new 
Abstract: We present an adapter-based approach for tactical conditioning of StarCraft II AI agents. Current agents, while powerful, lack the ability to adapt their strategies based on high-level tactical directives. Our method freezes a pre-trained policy network (DI-Star) and attaches lightweight adapter modules to each action head, conditioned on a tactical tensor that encodes strategic preferences. By training these adapters with KL divergence constraints, we ensure the policy maintains core competencies while exhibiting tactical variations. Experimental results show our approach successfully modulates agent behavior across tactical dimensions including aggression, expansion patterns, and technology preferences, while maintaining competitive performance. Our method enables flexible tactical control with minimal computational overhead, offering practical strategy customization for complex real-time strategy games.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data Mixing Agent: Learning to Re-weight Domains for Continual Pre-training</title>
<link>https://arxiv.org/abs/2507.15640</link>
<guid>https://arxiv.org/abs/2507.15640</guid>
<content:encoded><![CDATA[
arXiv:2507.15640v1 Announce Type: new 
Abstract: Continual pre-training on small-scale task-specific data is an effective method for improving large language models in new target fields, yet it risks catastrophic forgetting of their original capabilities. A common solution is to re-weight training data mixtures from source and target fields on a domain space to achieve balanced performance. Previous domain reweighting strategies rely on manual designation with certain heuristics based on human intuition or empirical results. In this work, we prove that more general heuristics can be parameterized by proposing Data Mixing Agent, the first model-based, end-to-end framework that learns to re-weight domains. The agent learns generalizable heuristics through reinforcement learning on large quantities of data mixing trajectories with corresponding feedback from an evaluation environment. Experiments in continual pre-training on math reasoning show that Data Mixing Agent outperforms strong baselines in achieving balanced performance across source and target field benchmarks. Furthermore, it generalizes well across unseen source fields, target models, and domain spaces without retraining. Direct application to the code generation field also indicates its adaptability across target domains. Further analysis showcases the agents' well-aligned heuristics with human intuitions and their efficiency in achieving superior model performance with less source-field data.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Asynchronous Collective Tree Exploration: a Distributed Algorithm, and a new Lower Bound</title>
<link>https://arxiv.org/abs/2507.15658</link>
<guid>https://arxiv.org/abs/2507.15658</guid>
<content:encoded><![CDATA[
arXiv:2507.15658v1 Announce Type: new 
Abstract: We study the problem of collective tree exploration in which a team of $k$ mobile agents must collectively visit all nodes of an unknown tree in as few moves as possible. The agents all start from the root and discover adjacent edges as they progress in the tree. Communication is distributed in the sense that agents share information by reading and writing on whiteboards located at all nodes. Movements are asynchronous, in the sense that the speeds of all agents are controlled by an adversary at all times. All previous competitive guarantees for collective tree exploration are either distributed but synchronous, or asynchronous but centralized. In contrast, we present a distributed asynchronous algorithm that explores any tree of $n$ nodes and depth $D$ in at most $2n+O(k^2 2^kD)$ moves, i.e., with a regret that is linear in $D$, and a variant algorithm with a guarantee in $O(k/\log k)(n+kD)$, i.e., with a competitive ratio in $O(k/\log k)$. We note that our regret guarantee is asymptotically optimal (i.e., $1$-competitive) from the perspective of average-case complexity. We then present a new general lower bound on the competitive ratio of asynchronous collective tree exploration, in $\Omega(\log^2 k)$. This lower bound applies to both the distributed and centralized settings, and improves upon the previous lower bound in $\Omega(\log k)$.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BugScope: Learn to Find Bugs Like Human</title>
<link>https://arxiv.org/abs/2507.15671</link>
<guid>https://arxiv.org/abs/2507.15671</guid>
<content:encoded><![CDATA[
arXiv:2507.15671v1 Announce Type: new 
Abstract: Detecting software bugs remains a fundamental challenge due to the extensive diversity of real-world defects. Traditional static analysis tools often rely on symbolic workflows, which restrict their coverage and hinder adaptability to customized bugs with diverse anti-patterns. While recent advances incorporate large language models (LLMs) to enhance bug detection, these methods continue to struggle with sophisticated bugs and typically operate within limited analysis contexts. To address these challenges, we propose BugScope, an LLM-driven multi-agent system that emulates how human auditors learn new bug patterns from representative examples and apply that knowledge during code auditing. Given a set of examples illustrating both buggy and non-buggy behaviors, BugScope synthesizes a retrieval strategy to extract relevant detection contexts via program slicing and then constructs a tailored detection prompt to guide accurate reasoning by the LLM. Our evaluation on a curated dataset of 40 real-world bugs drawn from 21 widely-used open-source projects demonstrates that BugScope achieves 87.04% precision and 90.00% recall, surpassing state-of-the-art industrial tools by 0.44 in F1 score. Further testing on large-scale open-source systems, including the Linux kernel, uncovered 141 previously unknown bugs, of which 78 have been fixed and 7 confirmed by developers, highlighting BugScope's substantial practical impact.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic AI for autonomous anomaly management in complex systems</title>
<link>https://arxiv.org/abs/2507.15676</link>
<guid>https://arxiv.org/abs/2507.15676</guid>
<content:encoded><![CDATA[
arXiv:2507.15676v1 Announce Type: new 
Abstract: This paper explores the potential of agentic AI in autonomously detecting and responding to anomalies within complex systems, emphasizing its ability to transform traditional, human-dependent anomaly management methods.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competitive Algorithms for Cooperative Multi-Agent Ski-Rental Problems</title>
<link>https://arxiv.org/abs/2507.15727</link>
<guid>https://arxiv.org/abs/2507.15727</guid>
<content:encoded><![CDATA[
arXiv:2507.15727v1 Announce Type: new 
Abstract: This paper introduces a novel multi-agent ski-rental problem that generalizes the classical ski-rental dilemma to a group setting where agents incur individual and shared costs. In our model, each agent can either rent at a fixed daily cost, or purchase a pass at an individual cost, with an additional third option of a discounted group pass available to all. We consider scenarios in which agents' active days differ, leading to dynamic states as agents drop out of the decision process. To address this problem from different perspectives, we define three distinct competitive ratios: overall, state-dependent, and individual rational. For each objective, we design and analyze optimal deterministic and randomized policies. Our deterministic policies employ state-aware threshold functions that adapt to the dynamic states, while our randomized policies sample and resample thresholds from tailored state-aware distributions. The analysis reveals that symmetric policies, in which all agents use the same threshold, outperform asymmetric ones. Our results provide competitive ratio upper and lower bounds and extend classical ski-rental insights to multi-agent settings, highlighting both theoretical and practical implications for group decision-making under uncertainty.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>General Matching Games</title>
<link>https://arxiv.org/abs/2507.15737</link>
<guid>https://arxiv.org/abs/2507.15737</guid>
<content:encoded><![CDATA[
arXiv:2507.15737v1 Announce Type: new 
Abstract: Matching games is a one-to-one two sided market model introduced by Garrido-Lucero and Laraki, in which coupled agents' utilities are endogenously determined as the outcome of a strategic game. They refine the classical pairwise stability by requiring robustness to renegotiation and provide general conditions under which pairwise stable and renegotiation-proof outcomes exist as the limit of a deferred acceptance with competitions algorithm together with a renegotiation process. In this article, we extend their model to a general setting encompassing most of one-to-many matching markets and roommates models and specify two frameworks under which core stable and renegotiation-proof outcomes exist and can be efficiently computed.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards physician-centered oversight of conversational diagnostic AI</title>
<link>https://arxiv.org/abs/2507.15743</link>
<guid>https://arxiv.org/abs/2507.15743</guid>
<content:encoded><![CDATA[
arXiv:2507.15743v1 Announce Type: new 
Abstract: Recent work has demonstrated the promise of conversational AI systems for diagnostic dialogue. However, real-world assurance of patient safety means that providing individual diagnoses and treatment plans is considered a regulated activity by licensed professionals. Furthermore, physicians commonly oversee other team members in such activities, including nurse practitioners (NPs) or physician assistants/associates (PAs). Inspired by this, we propose a framework for effective, asynchronous oversight of the Articulate Medical Intelligence Explorer (AMIE) AI system. We propose guardrailed-AMIE (g-AMIE), a multi-agent system that performs history taking within guardrails, abstaining from individualized medical advice. Afterwards, g-AMIE conveys assessments to an overseeing primary care physician (PCP) in a clinician cockpit interface. The PCP provides oversight and retains accountability of the clinical decision. This effectively decouples oversight from intake and can thus happen asynchronously. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) of text consultations with asynchronous oversight, we compared g-AMIE to NPs/PAs or a group of PCPs under the same guardrails. Across 60 scenarios, g-AMIE outperformed both groups in performing high-quality intake, summarizing cases, and proposing diagnoses and management plans for the overseeing PCP to review. This resulted in higher quality composite decisions. PCP oversight of g-AMIE was also more time-efficient than standalone PCP consultations in prior work. While our study does not replicate existing clinical practices and likely underestimates clinicians' capabilities, our results demonstrate the promise of asynchronous oversight as a feasible paradigm for diagnostic AI systems to operate under expert human oversight for enhancing real-world care.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GasAgent: A Multi-Agent Framework for Automated Gas Optimization in Smart Contracts</title>
<link>https://arxiv.org/abs/2507.15761</link>
<guid>https://arxiv.org/abs/2507.15761</guid>
<content:encoded><![CDATA[
arXiv:2507.15761v1 Announce Type: new 
Abstract: Smart contracts are trustworthy, immutable, and automatically executed programs on the blockchain. Their execution requires the Gas mechanism to ensure efficiency and fairness. However, due to non-optimal coding practices, many contracts contain Gas waste patterns that need to be optimized. Existing solutions mostly rely on manual discovery, which is inefficient, costly to maintain, and difficult to scale. Recent research uses large language models (LLMs) to explore new Gas waste patterns. However, it struggles to remain compatible with existing patterns, often produces redundant patterns, and requires manual validation/rewriting. To address this gap, we present GasAgent, the first multi-agent system for smart contract Gas optimization that combines compatibility with existing patterns and automated discovery/validation of new patterns, enabling end-to-end optimization. GasAgent consists of four specialized agents, Seeker, Innovator, Executor, and Manager, that collaborate in a closed loop to identify, validate, and apply Gas-saving improvements. Experiments on 100 verified real-world contracts demonstrate that GasAgent successfully optimizes 82 contracts, achieving an average deployment Gas savings of 9.97%. In addition, our evaluation confirms its compatibility with existing tools and validates the effectiveness of each module through ablation studies. To assess broader usability, we further evaluate 500 contracts generated by five representative LLMs across 10 categories and find that GasAgent optimizes 79.8% of them, with deployment Gas savings ranging from 4.79% to 13.93%, showing its usability as the optimization layer for LLM-assisted smart contract development.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Framework for Analyzing Abnormal Emergence in Service Ecosystems Through LLM-based Agent Intention Mining</title>
<link>https://arxiv.org/abs/2507.15770</link>
<guid>https://arxiv.org/abs/2507.15770</guid>
<content:encoded><![CDATA[
arXiv:2507.15770v1 Announce Type: new 
Abstract: With the rise of service computing, cloud computing, and IoT, service ecosystems are becoming increasingly complex. The intricate interactions among intelligent agents make abnormal emergence analysis challenging, as traditional causal methods focus on individual trajectories. Large language models offer new possibilities for Agent-Based Modeling (ABM) through Chain-of-Thought (CoT) reasoning to reveal agent intentions. However, existing approaches remain limited to microscopic and static analysis. This paper introduces a framework: Emergence Analysis based on Multi-Agent Intention (EAMI), which enables dynamic and interpretable emergence analysis. EAMI first employs a dual-perspective thought track mechanism, where an Inspector Agent and an Analysis Agent extract agent intentions under bounded and perfect rationality. Then, k-means clustering identifies phase transition points in group intentions, followed by a Intention Temporal Emergence diagram for dynamic analysis. The experiments validate EAMI in complex online-to-offline (O2O) service system and the Stanford AI Town experiment, with ablation studies confirming its effectiveness, generalizability, and efficiency. This framework provides a novel paradigm for abnormal emergence and causal analysis in service ecosystems. The code is available at https://anonymous.4open.science/r/EAMI-B085.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Density control of multi-agent swarms via bio-inspired leader-follower plasticity</title>
<link>https://arxiv.org/abs/2507.15781</link>
<guid>https://arxiv.org/abs/2507.15781</guid>
<content:encoded><![CDATA[
arXiv:2507.15781v1 Announce Type: new 
Abstract: The design of control systems for the spatial self-organization of mobile agents is an open challenge across several engineering domains, including swarm robotics and synthetic biology. Here, we propose a bio-inspired leader-follower solution, which is aware of energy constraints of mobile agents and is apt to deal with large swarms. Akin to many natural systems, control objectives are formulated for the entire collective, and leaders and followers are allowed to plastically switch their role in time. We frame a density control problem, modeling the agents' population via a system of nonlinear partial differential equations. This approach allows for a compact description that inherently avoids the curse of dimensionality and improves analytical tractability. We derive analytical guarantees for the existence of desired steady-state solutions and their local stability for one-dimensional and higher-dimensional problems. We numerically validate our control methodology, offering support to the effectiveness, robustness, and versatility of our proposed bio-inspired control strategy.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM Economist: Large Population Models and Mechanism Design in Multi-Agent Generative Simulacra</title>
<link>https://arxiv.org/abs/2507.15815</link>
<guid>https://arxiv.org/abs/2507.15815</guid>
<content:encoded><![CDATA[
arXiv:2507.15815v1 Announce Type: new 
Abstract: We present the LLM Economist, a novel framework that uses agent-based modeling to design and assess economic policies in strategic environments with hierarchical decision-making. At the lower level, bounded rational worker agents -- instantiated as persona-conditioned prompts sampled from U.S. Census-calibrated income and demographic statistics -- choose labor supply to maximize text-based utility functions learned in-context. At the upper level, a planner agent employs in-context reinforcement learning to propose piecewise-linear marginal tax schedules anchored to the current U.S. federal brackets. This construction endows economic simulacra with three capabilities requisite for credible fiscal experimentation: (i) optimization of heterogeneous utilities, (ii) principled generation of large, demographically realistic agent populations, and (iii) mechanism design -- the ultimate nudging problem -- expressed entirely in natural language. Experiments with populations of up to one hundred interacting agents show that the planner converges near Stackelberg equilibria that improve aggregate social welfare relative to Saez solutions, while a periodic, persona-level voting procedure furthers these gains under decentralized governance. These results demonstrate that large language model-based agents can jointly model, simulate, and govern complex economic systems, providing a tractable test bed for policy evaluation at the societal scale to help build better civilizations.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Age of Information Minimization in UAV-Enabled Integrated Sensing and Communication Systems</title>
<link>https://arxiv.org/abs/2507.14299</link>
<guid>https://arxiv.org/abs/2507.14299</guid>
<content:encoded><![CDATA[
arXiv:2507.14299v1 Announce Type: cross 
Abstract: Unmanned aerial vehicles (UAVs) equipped with integrated sensing and communication (ISAC) capabilities are envisioned to play a pivotal role in future wireless networks due to their enhanced flexibility and efficiency. However, jointly optimizing UAV trajectory planning, multi-user communication, and target sensing under stringent resource constraints and time-critical conditions remains a significant challenge. To address this, we propose an Age of Information (AoI)-centric UAV-ISAC system that simultaneously performs target sensing and serves multiple ground users, emphasizing information freshness as the core performance metric. We formulate a long-term average AoI minimization problem that jointly optimizes the UAV's flight trajectory and beamforming. To tackle the high-dimensional, non-convexity of this problem, we develop a deep reinforcement learning (DRL)-based algorithm capable of providing real-time decisions on UAV movement and beamforming for both radar sensing and multi-user communication. Specifically, a Kalman filter is employed for accurate target state prediction, regularized zero-forcing is utilized to mitigate inter-user interference, and the Soft Actor-Critic algorithm is applied for training the DRL agent on continuous actions. The proposed framework adaptively balances the trade-offs between sensing accuracy and communication quality. Extensive simulation results demonstrate that our proposed method consistently achieves lower average AoI compared to baseline approaches.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Nonlinear Causal Reductions to Explain Reinforcement Learning Policies</title>
<link>https://arxiv.org/abs/2507.14901</link>
<guid>https://arxiv.org/abs/2507.14901</guid>
<content:encoded><![CDATA[
arXiv:2507.14901v1 Announce Type: cross 
Abstract: Why do reinforcement learning (RL) policies fail or succeed? This is a challenging question due to the complex, high-dimensional nature of agent-environment interactions. In this work, we take a causal perspective on explaining the behavior of RL policies by viewing the states, actions, and rewards as variables in a low-level causal model. We introduce random perturbations to policy actions during execution and observe their effects on the cumulative reward, learning a simplified high-level causal model that explains these relationships. To this end, we develop a nonlinear Causal Model Reduction framework that ensures approximate interventional consistency, meaning the simplified high-level model responds to interventions in a similar way as the original complex system. We prove that for a class of nonlinear causal models, there exists a unique solution that achieves exact interventional consistency, ensuring learned explanations reflect meaningful causal patterns. Experiments on both synthetic causal models and practical RL tasks-including pendulum control and robot table tennis-demonstrate that our approach can uncover important behavioral patterns, biases, and failure modes in trained RL policies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personalized 3D Myocardial Infarct Geometry Reconstruction from Cine MRI with Explicit Cardiac Motion Modeling</title>
<link>https://arxiv.org/abs/2507.15194</link>
<guid>https://arxiv.org/abs/2507.15194</guid>
<content:encoded><![CDATA[
arXiv:2507.15194v1 Announce Type: cross 
Abstract: Accurate representation of myocardial infarct geometry is crucial for patient-specific cardiac modeling in MI patients. While Late gadolinium enhancement (LGE) MRI is the clinical gold standard for infarct detection, it requires contrast agents, introducing side effects and patient discomfort. Moreover, infarct reconstruction from LGE often relies on sparsely sampled 2D slices, limiting spatial resolution and accuracy. In this work, we propose a novel framework for automatically reconstructing high-fidelity 3D myocardial infarct geometry from 2D clinically standard cine MRI, eliminating the need for contrast agents. Specifically, we first reconstruct the 4D biventricular mesh from multi-view cine MRIs via an automatic deep shape fitting model, biv-me. Then, we design a infarction reconstruction model, CMotion2Infarct-Net, to explicitly utilize the motion patterns within this dynamic geometry to localize infarct regions. Evaluated on 205 cine MRI scans from 126 MI patients, our method shows reasonable agreement with manual delineation. This study demonstrates the feasibility of contrast-free, cardiac motion-driven 3D infarct reconstruction, paving the way for efficient digital twin of MI.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Event-Triggered Resilient Consensus of Networked Euler-Lagrange Systems Under Byzantine Attacks</title>
<link>https://arxiv.org/abs/2507.15283</link>
<guid>https://arxiv.org/abs/2507.15283</guid>
<content:encoded><![CDATA[
arXiv:2507.15283v1 Announce Type: cross 
Abstract: The resilient consensus problem is investigated in this paper for a class of networked Euler-Lagrange systems with event-triggered communication in the presence of Byzantine attacks. One challenge that we face in addressing the considered problem is the inapplicability of existing resilient decision algorithms designed for one-dimensional multi-agent systems. This is because the networked Euler-Lagrange systems fall into the category of multi-dimensional multi-agent systems with coupling among state vector components. To address this problem, we propose a new resilient decision algorithm. This algorithm constructs auxiliary variables related to the coordinative objectives for each normal agent, and transforms the considered resilient consensus problem into the consensus problem of the designed auxiliary variables. Furthermore, to relax the constraints imposed on Byzantine agent behavior patterns within continuous-time scenarios, the event-triggered communication scheme is adopted. Finally, the effectiveness of the proposed algorithm is demonstrated through case studies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>3D Active Metric-Semantic SLAM</title>
<link>https://arxiv.org/abs/2309.06950</link>
<guid>https://arxiv.org/abs/2309.06950</guid>
<content:encoded><![CDATA[
arXiv:2309.06950v4 Announce Type: replace 
Abstract: In this letter, we address the problem of exploration and metric-semantic mapping of multi-floor GPS-denied indoor environments using Size Weight and Power (SWaP) constrained aerial robots. Most previous work in exploration assumes that robot localization is solved. However, neglecting the state uncertainty of the agent can ultimately lead to cascading errors both in the resulting map and in the state of the agent itself. Furthermore, actions that reduce localization errors may be at direct odds with the exploration task. We propose a framework that balances the efficiency of exploration with actions that reduce the state uncertainty of the agent. In particular, our algorithmic approach for active metric-semantic SLAM is built upon sparse information abstracted from raw problem data, to make it suitable for SWaP-constrained robots. Furthermore, we integrate this framework within a fully autonomous aerial robotic system that achieves autonomous exploration in cluttered, 3D environments. From extensive real-world experiments, we showed that by including Semantic Loop Closure (SLC), we can reduce the robot pose estimation errors by over 90% in translation and approximately 75% in yaw, and the uncertainties in pose estimates and semantic maps by over 70% and 65%, respectively. Although discussed in the context of indoor multi-floor exploration, our system can be used for various other applications, such as infrastructure inspection and precision agriculture where reliable GPS data may not be available.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Object Goal Navigation Through LLM-enhanced Object Affinities Transfer</title>
<link>https://arxiv.org/abs/2403.09971</link>
<guid>https://arxiv.org/abs/2403.09971</guid>
<content:encoded><![CDATA[
arXiv:2403.09971v3 Announce Type: replace 
Abstract: Object-goal navigation requires mobile robots to efficiently locate targets with visual and spatial information, yet existing methods struggle with generalization in unseen environments. Heuristic approaches with naive metrics fail in complex layouts, while graph-based and learning-based methods suffer from environmental biases and limited generalization. Although Large Language Models (LLMs) as planners or agents offer a rich knowledge base, they are cost-inefficient and lack targeted historical experience. To address these challenges, we propose the LLM-enhanced Object Affinities Transfer (LOAT) framework, integrating LLM-derived semantics with learning-based approaches to leverage experiential object affinities for better generalization in unseen settings. LOAT employs a dual-module strategy: one module accesses LLMs' vast knowledge, and the other applies learned object semantic relationships, dynamically fusing these sources based on context. Evaluations in AI2-THOR and Habitat simulators show significant improvements in navigation success and efficiency, and real-world deployment demonstrates the zero-shot ability of LOAT to enhance object-goal navigation systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmarking Mobile Device Control Agents across Diverse Configurations</title>
<link>https://arxiv.org/abs/2404.16660</link>
<guid>https://arxiv.org/abs/2404.16660</guid>
<content:encoded><![CDATA[
arXiv:2404.16660v3 Announce Type: replace 
Abstract: Mobile device control agents can largely enhance user interactions and productivity by automating daily tasks. However, despite growing interest in developing practical agents, the absence of a commonly adopted benchmark in this area makes it challenging to quantify scientific progress. In this work, we introduce B-MoCA: a novel benchmark with interactive environments for evaluating and developing mobile device control agents. To create a realistic benchmark, we develop B-MoCA based on the Android operating system and define 131 common daily tasks. Importantly, we incorporate a randomization feature that changes the configurations of mobile devices, including user interface layouts and language settings, to assess generalization performance. We benchmark diverse agents, including agents employing large language models (LLMs) or multi-modal LLMs as well as agents trained with imitation learning using human expert demonstrations. While these agents demonstrate proficiency in executing straightforward tasks, their poor performance on complex tasks highlights significant opportunities for future research to improve effectiveness. Our source code is publicly available at https://b-moca.github.io.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Which Experiences Are Influential for RL Agents? Efficiently Estimating The Influence of Experiences</title>
<link>https://arxiv.org/abs/2405.14629</link>
<guid>https://arxiv.org/abs/2405.14629</guid>
<content:encoded><![CDATA[
arXiv:2405.14629v3 Announce Type: replace 
Abstract: In reinforcement learning (RL) with experience replay, experiences stored in a replay buffer influence the RL agent's performance. Information about how these experiences influence the agent's performance is valuable for various purposes, such as identifying experiences that negatively influence underperforming agents. One method for estimating the influence of experiences is the leave-one-out (LOO) method. However, this method is usually computationally prohibitive. In this paper, we present Policy Iteration with Turn-over Dropout (PIToD), which efficiently estimates the influence of experiences. We evaluate how correctly PIToD estimates the influence of experiences and its efficiency compared to LOO. We then apply PIToD to amend underperforming RL agents, i.e., we use PIToD to estimate negatively influential experiences for the RL agents and to delete the influence of these experiences. We show that RL agents' performance is significantly improved via amendments with PIToD.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Granularity-Aware Affordances from Human-Object Interaction for Tool-Based Functional Dexterous Grasping</title>
<link>https://arxiv.org/abs/2407.00614</link>
<guid>https://arxiv.org/abs/2407.00614</guid>
<content:encoded><![CDATA[
arXiv:2407.00614v2 Announce Type: replace 
Abstract: To enable robots to use tools, the initial step is teaching robots to employ dexterous gestures for touching specific areas precisely where tasks are performed. Affordance features of objects serve as a bridge in the functional interaction between agents and objects. However, leveraging these affordance cues to help robots achieve functional tool grasping remains unresolved. To address this, we propose a granularity-aware affordance feature extraction method for locating functional affordance areas and predicting dexterous coarse gestures. We study the intrinsic mechanisms of human tool use. On one hand, we use fine-grained affordance features of object-functional finger contact areas to locate functional affordance regions. On the other hand, we use highly activated coarse-grained affordance features in hand-object interaction regions to predict grasp gestures. Additionally, we introduce a model-based post-processing module that transforms affordance localization and gesture prediction into executable robotic actions. This forms GAAF-Dex, a complete framework that learns Granularity-Aware Affordances from human-object interaction to enable tool-based functional grasping with dexterous hands. Unlike fully-supervised methods that require extensive data annotation, we employ a weakly supervised approach to extract relevant cues from exocentric (Exo) images of hand-object interactions to supervise feature extraction in egocentric (Ego) images. To support this approach, we have constructed a small-scale dataset, Functional Affordance Hand-object Interaction Dataset (FAH), which includes nearly 6K images of functional hand-object interaction Exo images and Ego images. Extensive experiments on the dataset demonstrate that our method outperforms state-of-the-art methods. The source code and the established dataset are available at https://github.com/yangfan293/GAAF-DEX.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proficient Graph Neural Network Design by Accumulating Knowledge on Large Language Models</title>
<link>https://arxiv.org/abs/2408.06717</link>
<guid>https://arxiv.org/abs/2408.06717</guid>
<content:encoded><![CDATA[
arXiv:2408.06717v2 Announce Type: replace 
Abstract: High-level automation is increasingly critical in AI, driven by rapid advances in large language models (LLMs) and AI agents. However, LLMs, despite their general reasoning power, struggle significantly in specialized, data-sensitive tasks such as designing Graph Neural Networks (GNNs). This difficulty arises from (1) the inherent knowledge gaps in modeling the intricate, varying relationships between graph properties and suitable architectures and (2) the external noise from misleading descriptive inputs, often resulting in generic or even misleading model suggestions. Achieving proficiency in designing data-aware models -- defined as the meta-level capability to systematically accumulate, interpret, and apply data-specific design knowledge -- remains challenging for existing automated approaches, due to their inefficient construction and application of meta-knowledge. To achieve the meta-level proficiency, we propose DesiGNN, a knowledge-centered framework that systematically converts past model design experiences into structured, fine-grained knowledge priors well fitted to meta-learning with LLMs. To account for the inherent variability and external noise, DesiGNN aligns empirical property filtering from extensive benchmarks with adaptive elicitation of literature insights via LLMs. By constructing a solid meta-knowledge between unseen graph understanding and known effective architecture patterns, DesiGNN can deliver top-5.77% initial model proposals for unseen datasets within seconds, and achieve consistently superior performance with minimal search costs against baselines.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chemputer and Chemputation -- A Universal Chemical Compound Synthesis Machine</title>
<link>https://arxiv.org/abs/2408.09171</link>
<guid>https://arxiv.org/abs/2408.09171</guid>
<content:encoded><![CDATA[
arXiv:2408.09171v3 Announce Type: replace 
Abstract: Chemputation reframes synthesis as the programmable execution of reaction code on a universally re-configurable hardware graph. Here we prove that a chemputer equipped with a finite, but extensible, set of reagents, catalysts and process conditions, together with a chempiler that maps reaction graphs onto hardware, is universal: it can generate any stable, isolable molecule in finite time and in analytically detectable quantity, provided real-time error correction keeps the per-step fidelity above the threshold set by the molecule's assembly index. The proof is constructed by casting the platform as a Chemical Synthesis Turing Machine (CSTM). The CSTM formalism supplies (i) an eight-tuple state definition that unifies reagents, process variables (including catalysts) and tape operations; (ii) the Universal Chemputation Principle; and (iii) a dynamic-error-correction routine ensuring fault tolerant execution. Linking this framework to assembly theory strengthens the definition of a molecule by demanding practical synthesizability and error correction becomes a prerequisite for universality. We validate the abstraction against >100 \c{hi}DL programs executed on a modular chemputer rigs spanning single step to multi-step routes. Mapping each procedure onto CSTM shows that the cumulative number of unit operations grows linearly with synthetic depth. Together, these results elevate chemical synthesis to the status of a general computation: algorithms written in \c{hi}DL are compiled to hardware, executed with closed-loop correction, and produce verifiable molecular outputs. By formalising chemistry in this way, the chemputer offers a path to shareable, executable chemical code, interoperable hardware ecosystems, and ultimately a searchable, provable atlas of chemical space.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wave: Offloading Resource Management to SmartNIC Cores</title>
<link>https://arxiv.org/abs/2408.17351</link>
<guid>https://arxiv.org/abs/2408.17351</guid>
<content:encoded><![CDATA[
arXiv:2408.17351v3 Announce Type: replace 
Abstract: SmartNICs are increasingly deployed in datacenters to offload tasks from server CPUs, improving the efficiency and flexibility of datacenter security, networking and storage. Optimizing cloud server efficiency in this way is critically important to ensure that virtually all server resources are available to paying customers. Userspace system software, specifically, decision-making tasks performed by various operating system subsystems, is particularly well suited for execution on mid-tier SmartNIC ARM cores. To this end, we introduce Wave, a framework for offloading userspace system software to processes/agents running on the SmartNIC. Wave uses Linux userspace systems to better align system functionality with SmartNIC capabilities. It also introduces a new host-SmartNIC communication API that enables offloading of even $\mu$s-scale system software. To evaluate Wave, we offloaded preexisting userspace system software including kernel thread scheduling, memory management, and an RPC stack to SmartNIC ARM cores, which showed a performance degradation of 1.1%-7.4% in an apples-to-apples comparison with on-host implementations. Wave recovered host resources consumed by on-host system software for memory management (saving 16 host cores), RPCs (saving 8 host cores), and virtual machines (an 11.2% performance improvement). Wave highlights the potential for rethinking system software placement in modern datacenters, unlocking new opportunities for efficiency and scalability.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DHLight: Multi-agent Policy-based Directed Hypergraph Learning for Traffic Signal Control</title>
<link>https://arxiv.org/abs/2409.05037</link>
<guid>https://arxiv.org/abs/2409.05037</guid>
<content:encoded><![CDATA[
arXiv:2409.05037v2 Announce Type: replace 
Abstract: Recent advancements in Deep Reinforcement Learning (DRL) and Graph Neural Networks (GNNs) have demonstrated notable promise in the realm of intelligent traffic signal control, facilitating the coordination across multiple intersections. However, the traditional methods rely on standard graph structures often fail to capture the intricate higher-order spatio-temporal correlations inherent in real-world traffic dynamics. Standard graphs cannot fully represent the spatial relationships within road networks, which limits the effectiveness of graph-based approaches. In contrast, directed hypergraphs provide more accurate representation of spatial information to model complex directed relationships among multiple nodes. In this paper, we propose DHLight, a novel multi-agent policy-based framework that synergistically integrates directed hypergraph learning module. This framework introduces a novel dynamic directed hypergraph construction mechanism, which captures complex and evolving spatio-temporal relationships among intersections in road networks. By leveraging the directed hypergraph relational structure, DHLight empowers agents to achieve adaptive decision-making in traffic signal control. The effectiveness of DHLight is validated against state-of-the-art baselines through extensive experiments in various network datasets. We release the code to support the reproducibility of this work at https://github.com/LuckyVoasem/Traffic-Light-control
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Reinforcement Learning for Temporal Abstraction of Listwise Recommendation</title>
<link>https://arxiv.org/abs/2409.07416</link>
<guid>https://arxiv.org/abs/2409.07416</guid>
<content:encoded><![CDATA[
arXiv:2409.07416v2 Announce Type: replace 
Abstract: Modern listwise recommendation systems need to consider both long-term user perceptions and short-term interest shifts. Reinforcement learning can be applied on recommendation to study such a problem but is also subject to large search space, sparse user feedback and long interactive latency. Motivated by recent progress in hierarchical reinforcement learning, we propose a novel framework called mccHRL to provide different levels of temporal abstraction on listwise recommendation. Within the hierarchical framework, the high-level agent studies the evolution of user perception, while the low-level agent produces the item selection policy by modeling the process as a sequential decision-making problem. We argue that such framework has a well-defined decomposition of the outra-session context and the intra-session context, which are encoded by the high-level and low-level agents, respectively. To verify this argument, we implement both a simulator-based environment and an industrial dataset-based experiment. Results observe significant performance improvement by our method, compared with several well-known baselines. Data and codes have been made public.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone Navigation via Scene-Aware Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.10283</link>
<guid>https://arxiv.org/abs/2409.10283</guid>
<content:encoded><![CDATA[
arXiv:2409.10283v4 Announce Type: replace 
Abstract: In the rapidly evolving field of vision-language navigation (VLN), ensuring safety for physical agents remains an open challenge. For a human-in-the-loop language-operated drone to navigate safely, it must understand natural language commands, perceive the environment, and simultaneously avoid hazards in real time. Control Barrier Functions (CBFs) are formal methods that enforce safe operating conditions. Model Predictive Control (MPC) is an optimization framework that plans a sequence of future actions over a prediction horizon, ensuring smooth trajectory tracking while obeying constraints. In this work, we consider a VLN-operated drone platform and enhance its safety by formulating a novel scene-aware CBF that leverages ego-centric observations from a camera which has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less baseline system uses a Vision-Language Encoder with cross-modal attention to convert commands into an ordered sequence of landmarks. An object detection model identifies and verifies these landmarks in the captured images to generate a planned path. To further enhance safety, an Adaptive Safety Margin Algorithm (ASMA) is proposed. ASMA tracks moving objects and performs scene-aware CBF evaluation on-the-fly, which serves as an additional constraint within the MPC framework. By continuously identifying potentially risky observations, the system performs prediction in real time about unsafe conditions and proactively adjusts its control actions to maintain safe navigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in the Gazebo environment using the Robot Operating System (ROS), ASMA achieves 64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in trajectory lengths compared to the baseline CBF-less VLN.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Duality of Generative AI and Reinforcement Learning in Robotics: A Review</title>
<link>https://arxiv.org/abs/2410.16411</link>
<guid>https://arxiv.org/abs/2410.16411</guid>
<content:encoded><![CDATA[
arXiv:2410.16411v2 Announce Type: replace 
Abstract: Recently, generative AI and reinforcement learning (RL) have been redefining what is possible for AI agents that take information flows as input and produce intelligent behavior. As a result, we are seeing similar advancements in embodied AI and robotics for control policy generation. Our review paper examines the integration of generative AI models with RL to advance robotics. Our primary focus is on the duality between generative AI and RL for robotics downstream tasks. Specifically, we investigate: (1) The role of prominent generative AI tools as modular priors for multi-modal input fusion in RL tasks. (2) How RL can train, fine-tune and distill generative models for policy generation, such as VLA models, similarly to RL applications in large language models. We then propose a new taxonomy based on a considerable amount of selected papers.
  Lastly, we identify open challenges accounting for model scalability, adaptation and grounding, giving recommendations and insights on future research directions. We reflect on which generative AI models best fit the RL tasks and why. On the other side, we reflect on important issues inherent to RL-enhanced generative policies, such as safety concerns and failure modes, and what are the limitations of current methods. A curated collection of relevant research papers is maintained on our GitHub repository, serving as a resource for ongoing research and development in this field: https://github.com/clmoro/Robotics-RL-FMs-Integration.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models Powered Multiagent Ensemble for Mitigating Hallucination and Efficient Atrial Fibrillation Annotation of ECG Reports</title>
<link>https://arxiv.org/abs/2410.16543</link>
<guid>https://arxiv.org/abs/2410.16543</guid>
<content:encoded><![CDATA[
arXiv:2410.16543v3 Announce Type: replace 
Abstract: This study introduces a LLMs powered multiagent ensemble method to address challenges in hallucination and data labeling, particularly in large-scale EHR datasets. Manual labeling of such datasets requires domain expertise and is labor-intensive, time-consuming, expensive, and error-prone. To overcome this bottleneck, we developed an ensemble LLMs method and demonstrated its effectiveness in two real-world tasks: (1) labeling a large-scale unlabeled ECG dataset in MIMIC-IV; (2) identifying social determinants of health (SDOH) from the clinical notes of EHR. Trading off benefits and cost, we selected a pool of diverse open source LLMs with satisfactory performance. We treat each LLM's prediction as a vote and apply a mechanism of majority voting with minimal winning threshold for ensemble. We implemented an ensemble LLMs application for EHR data labeling tasks. By using the ensemble LLMs and natural language processing, we labeled MIMIC-IV ECG dataset of 623,566 ECG reports with an estimated accuracy of 98.2%. We applied the ensemble LLMs method to identify SDOH from social history sections of 1,405 EHR clinical notes, also achieving competitive performance. Our experiments show that the ensemble LLMs can outperform individual LLM even the best commercial one, and the method reduces hallucination errors. From the research, we found that (1) the ensemble LLMs method significantly reduces the time and effort required for labeling large-scale EHR data, automating the process with high accuracy and quality; (2) the method generalizes well to other text data labeling tasks, as shown by its application to SDOH identification; (3) the ensemble of a group of diverse LLMs can outperform or match the performance of the best individual LLM; and (4) the ensemble method substantially reduces hallucination errors. This approach provides a scalable and efficient solution to data-labeling challenges.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Existence of $\epsilon$-Nash Equilibria in Nonzero-Sum and Zero-Sum Markov Games with Standard Borel Spaces via Finite Model Approximations</title>
<link>https://arxiv.org/abs/2411.10805</link>
<guid>https://arxiv.org/abs/2411.10805</guid>
<content:encoded><![CDATA[
arXiv:2411.10805v2 Announce Type: replace 
Abstract: Establishing the existence of exact or near Markov or stationary perfect Nash equilibria in nonzero-sum Markov games over Borel spaces is a challenging problem with limited positive results. Motivated by problems in multi-agent and Bayesian learning, this paper demonstrates the existence of approximate Markov and stationary Nash equilibria for such games under mild regularity conditions. Our approach is constructive: For both compact and non-compact state spaces, we approximate the Borel model with finite state-action models and show that their equilibria correspond to \(\epsilon\)-equilibria for the original game. Compared with previous results in the literature, which we comprehensively review, we provide more general and complementary conditions, along with explicit approximation models whose equilibria are $\epsilon$-equilibria for the original model. For completeness, we also study the approximation of zero-sum Markov games and Markov teams to highlight the key differences between zero-sum and nonzero-sum settings. In particular, while for zero-sum and team games, joint weak (Feller) continuity of the transition kernel is sufficient (as the value function is continuous), this is not the case for general nonzero-sum games.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Large Language Model-Based Social Agents in Game-Theoretic Scenarios</title>
<link>https://arxiv.org/abs/2412.03920</link>
<guid>https://arxiv.org/abs/2412.03920</guid>
<content:encoded><![CDATA[
arXiv:2412.03920v2 Announce Type: replace 
Abstract: Game-theoretic scenarios have become pivotal in evaluating the social intelligence of Large Language Model (LLM)-based social agents. While numerous studies have explored these agents in such settings, there is a lack of a comprehensive survey summarizing the current progress. To address this gap, we systematically review existing research on LLM-based social agents within game-theoretic scenarios. Our survey organizes the findings into three core components: Game Framework, Social Agent, and Evaluation Protocol. The game framework encompasses diverse game scenarios, ranging from choice-focusing to communication-focusing games. The social agent part explores agents' preferences, beliefs, and reasoning abilities, as well as their interactions and synergistic effects on decision-making. The evaluation protocol covers both game-agnostic and game-specific metrics for assessing agent performance. Additionally, we analyze the performance of current social agents across various game scenarios. By reflecting on the current research and identifying future research directions, this survey provides insights to advance the development and evaluation of social agents in game-theoretic scenarios.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Constitutional Filter: Bayesian Estimation of Compliant Agents</title>
<link>https://arxiv.org/abs/2412.18347</link>
<guid>https://arxiv.org/abs/2412.18347</guid>
<content:encoded><![CDATA[
arXiv:2412.18347v3 Announce Type: replace 
Abstract: Predicting agents impacted by legal policies, physical limitations, and operational preferences is inherently difficult. In recent years, neuro-symbolic methods have emerged, integrating machine learning and symbolic reasoning models into end-to-end learnable systems. Hereby, a promising avenue for expressing high-level constraints over multi-modal input data in robotics has opened up. This work introduces an approach for Bayesian estimation of agents expected to comply with a human-interpretable neuro-symbolic model we call its Constitution. Hence, we present the Constitutional Filter (CoFi), leading to improved tracking of agents by leveraging expert knowledge, incorporating deep learning architectures, and accounting for environmental uncertainties. CoFi extends the general, recursive Bayesian estimation setting, ensuring compatibility with a vast landscape of established techniques such as Particle Filters. To underpin the advantages of CoFi, we evaluate its performance on real-world marine traffic data. Beyond improved performance, we show how CoFi can learn to trust and adapt to the level of compliance of an agent, recovering baseline performance even if the assumed Constitution clashes with reality.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finding A Voice: Exploring the Potential of African American Dialect and Voice Generation for Chatbots</title>
<link>https://arxiv.org/abs/2501.03441</link>
<guid>https://arxiv.org/abs/2501.03441</guid>
<content:encoded><![CDATA[
arXiv:2501.03441v2 Announce Type: replace 
Abstract: As chatbots become integral to daily life, personalizing systems is key for fostering trust, engagement, and inclusivity. This study examines how linguistic similarity affects chatbot performance, focusing on integrating African American English (AAE) into virtual agents to better serve the African American community. We develop text-based and spoken chatbots using large language models and text-to-speech technology, then evaluate them with AAE speakers against standard English chatbots. Our results show that while text-based AAE chatbots often underperform, spoken chatbots benefit from an African American voice and AAE elements, improving performance and preference. These findings underscore the complexities of linguistic personalization and the dynamics between text and speech modalities, highlighting technological limitations that affect chatbots' AA speech generation and pointing to promising future research directions.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Conversational Recommender Systems via Large Language Models: A User-Centric Framework</title>
<link>https://arxiv.org/abs/2501.09493</link>
<guid>https://arxiv.org/abs/2501.09493</guid>
<content:encoded><![CDATA[
arXiv:2501.09493v3 Announce Type: replace 
Abstract: Conversational recommender systems (CRSs) integrate both recommendation and dialogue tasks, making their evaluation uniquely challenging. Existing approaches primarily assess CRS performance by separately evaluating item recommendation and dialogue management using rule-based metrics. However, these methods fail to capture the real human experience, and they cannot draw direct conclusions about the system's overall performance. As conversational recommender systems become increasingly vital in e-commerce, social media, and customer support, the ability to evaluate both recommendation accuracy and dialogue management quality using a single metric, thereby authentically reflecting user experience, has become the principal challenge impeding progress in this field.
  In this work, we propose a user-centric evaluation framework based on large language models (LLMs) for CRSs, namely Conversational Recommendation Evaluator (CoRE). CoRE consists of two main components: (1) LLM-As-Evaluator. Firstly, we comprehensively summarize 12 key factors influencing user experience in CRSs and directly leverage LLM as an evaluator to assign a score to each factor. (2) Multi-Agent Debater. Secondly, we design a multi-agent debate framework with four distinct roles (common user, domain expert, linguist, and HCI expert) to discuss and synthesize the 12 evaluation factors into a unified overall performance score.
  Furthermore, we apply the proposed framework to evaluate four CRSs on two benchmark datasets. The experimental results show that CoRE aligns well with human evaluation in most of the 12 factors and the overall assessment. Especially, CoRE's overall evaluation scores demonstrate significantly better alignment with human feedback compared to existing rule-based metrics.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Doing More with Less: A Survey on Routing Strategies for Resource Optimisation in Large Language Model-Based Systems</title>
<link>https://arxiv.org/abs/2502.00409</link>
<guid>https://arxiv.org/abs/2502.00409</guid>
<content:encoded><![CDATA[
arXiv:2502.00409v3 Announce Type: replace 
Abstract: Large Language Model (LLM)-based systems, i.e. interconnected elements that include an LLM as a central component, such as conversational agents, are usually designed with monolithic, static architectures that rely on a single, general-purpose LLM to handle all user queries. However, these systems may be inefficient as different queries may require different levels of reasoning, domain knowledge or pre-processing. While generalist LLMs (e.g. GPT-4o, Claude-Sonnet) perform well across a wide range of tasks, they may incur significant financial, energy and computational costs. These costs may be disproportionate for simpler queries, resulting in unnecessary resource utilisation. A routing mechanism can therefore be employed to route queries to more appropriate components, such as smaller or specialised models, thereby improving efficiency and optimising resource consumption. This survey aims to provide a comprehensive overview of routing strategies in LLM-based systems. Specifically, it reviews when, why, and how routing should be integrated into LLM pipelines to improve efficiency, scalability, and performance. We define the objectives to optimise, such as cost minimisation and performance maximisation, and discuss the timing of routing within the LLM workflow, whether it occurs before or after generation. We also detail the various implementation strategies, including similarity-based, supervised, reinforcement learning-based, and generative methods. Practical considerations such as industrial applications and current limitations are also examined, like standardising routing experiments, accounting for non-financial costs, and designing adaptive strategies. By formalising routing as a performance-cost optimisation problem, this survey provides tools and directions to guide future research and development of adaptive low-cost LLM-based systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Win Rates: A Clustering-Based Approach to Character Balance Analysis in Team-Based Games</title>
<link>https://arxiv.org/abs/2502.01250</link>
<guid>https://arxiv.org/abs/2502.01250</guid>
<content:encoded><![CDATA[
arXiv:2502.01250v2 Announce Type: replace 
Abstract: Character diversity in competitive games, while enriching gameplay, often introduces balance challenges that can negatively impact player experience and strategic depth. Traditional balance assessments rely on aggregate metrics like win rates and pick rates, which offer limited insight into the intricate dynamics of team-based games and nuanced character roles. This paper proposes a novel clustering-based methodology to analyze character balance, leveraging in-game data from Valorant to account for team composition influences and reveal latent character roles. By applying hierarchical agglomerative clustering with Jensen-Shannon Divergence to professional match data from the Valorant Champions Tour 2022, our approach identifies distinct clusters of agents exhibiting similar co-occurrence patterns within team compositions. This method not only complements existing quantitative metrics but also provides a more holistic and interpretable perspective on character synergies and potential imbalances, offering game developers a valuable tool for informed and context-aware balance adjustments.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Preventing Rogue Agents Improves Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2502.05986</link>
<guid>https://arxiv.org/abs/2502.05986</guid>
<content:encoded><![CDATA[
arXiv:2502.05986v2 Announce Type: replace 
Abstract: Multi-agent systems, where specialized agents collaborate to solve a shared task hold great potential, from increased modularity to simulating complex environments. However, they also have a major caveat -- a single agent can cause the entire system to fail. Consider a simple game where the knowledge to solve the task is distributed between agents, which share information in a communication channel. At each round, any of the agents can terminate the game and make the final prediction, even if they are uncertain about the outcome of their action. Detection of such rogue agents before they act may prevent the system's failure. In this work, we propose to monitor agents during action prediction and intervene when a future error is likely to occur. To test our approach, we introduce WhoDunitEnv, a multi-agent collaboration environment that allows modular control over task complexity and communication structure. Experiments on WhoDunitEnv, code generation tasks and the GovSim environment for resource sustainability show that our approach leads to substantial performance gains up to 17.4%, 2.5% and 20%, respectively. Thorough analysis shows that our monitors successfully identify critical points of agent confusion and our interventions effectively stop agent errors from propagating.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Predictive Planner for Autonomous Driving with Consistency Models</title>
<link>https://arxiv.org/abs/2502.08033</link>
<guid>https://arxiv.org/abs/2502.08033</guid>
<content:encoded><![CDATA[
arXiv:2502.08033v3 Announce Type: replace 
Abstract: Trajectory prediction and planning are essential for autonomous vehicles to navigate safely and efficiently in dynamic environments. Traditional approaches often treat them separately, limiting the ability for interactive planning. While recent diffusion-based generative models have shown promise in multi-agent trajectory generation, their slow sampling is less suitable for high-frequency planning tasks. In this paper, we leverage the consistency model to build a predictive planner that samples from a joint distribution of ego and surrounding agents, conditioned on the ego vehicle's navigational goal. Trained on real-world human driving datasets, our consistency model generates higher-quality trajectories with fewer sampling steps than standard diffusion models, making it more suitable for real-time deployment. To enforce multiple planning constraints simultaneously on the ego trajectory, a novel online guided sampling approach inspired by the Alternating Direction Method of Multipliers (ADMM) is introduced. Evaluated on the Waymo Open Motion Dataset (WOMD), our method enables proactive behavior such as nudging and yielding, and also demonstrates smoother, safer, and more efficient trajectories and satisfaction of multiple constraints under a limited computational budget.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation</title>
<link>https://arxiv.org/abs/2503.02247</link>
<guid>https://arxiv.org/abs/2503.02247</guid>
<content:encoded><![CDATA[
arXiv:2503.02247v5 Announce Type: replace 
Abstract: Object Goal Navigation-requiring an agent to locate a specific object in an unseen environment-remains a core challenge in embodied AI. Although recent progress in Vision-Language Model (VLM)-based agents has demonstrated promising perception and decision-making abilities through prompting, none has yet established a fully modular world model design that reduces risky and costly interactions with the environment by predicting the future state of the world. We introduce WMNav, a novel World Model-based Navigation framework powered by Vision-Language Models (VLMs). It predicts possible outcomes of decisions and builds memories to provide feedback to the policy module. To retain the predicted state of the environment, WMNav proposes the online maintained Curiosity Value Map as part of the world model memory to provide dynamic configuration for navigation policy. By decomposing according to a human-like thinking process, WMNav effectively alleviates the impact of model hallucination by making decisions based on the feedback difference between the world model plan and observation. To further boost efficiency, we implement a two-stage action proposer strategy: broad exploration followed by precise localization. Extensive evaluation on HM3D and MP3D validates WMNav surpasses existing zero-shot benchmarks in both success rate and exploration efficiency (absolute improvement: +3.2% SR and +3.2% SPL on HM3D, +13.5% SR and +1.1% SPL on MP3D). Project page: https://b0b8k1ng.github.io/WMNav/.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resource-Efficient Affordance Grounding with Complementary Depth and Semantic Prompts</title>
<link>https://arxiv.org/abs/2503.02600</link>
<guid>https://arxiv.org/abs/2503.02600</guid>
<content:encoded><![CDATA[
arXiv:2503.02600v2 Announce Type: replace 
Abstract: Affordance refers to the functional properties that an agent perceives and utilizes from its environment, and is key perceptual information required for robots to perform actions. This information is rich and multimodal in nature. Existing multimodal affordance methods face limitations in extracting useful information, mainly due to simple structural designs, basic fusion methods, and large model parameters, making it difficult to meet the performance requirements for practical deployment. To address these issues, this paper proposes the BiT-Align image-depth-text affordance mapping framework. The framework includes a Bypass Prompt Module (BPM) and a Text Feature Guidance (TFG) attention selection mechanism. BPM integrates the auxiliary modality depth image directly as a prompt to the primary modality RGB image, embedding it into the primary modality encoder without introducing additional encoders. This reduces the model's parameter count and effectively improves functional region localization accuracy. The TFG mechanism guides the selection and enhancement of attention heads in the image encoder using textual features, improving the understanding of affordance characteristics. Experimental results demonstrate that the proposed method achieves significant performance improvements on public AGD20K and HICO-IIF datasets. On the AGD20K dataset, compared with the current state-of-the-art method, we achieve a 6.0% improvement in the KLD metric, while reducing model parameters by 88.8%, demonstrating practical application values. The source code will be made publicly available at https://github.com/DAWDSE/BiT-Align.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning</title>
<link>https://arxiv.org/abs/2503.05641</link>
<guid>https://arxiv.org/abs/2503.05641</guid>
<content:encoded><![CDATA[
arXiv:2503.05641v3 Announce Type: replace 
Abstract: Combining existing pre-trained expert LLMs is a promising avenue for scalably tackling large-scale and diverse tasks. However, selecting task-level experts is often too coarse-grained, as heterogeneous tasks may require different expertise per instance. To enable adaptive instance-level mixing of pre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and gradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained approach to selection by emphasizing skills, e.g., algebra in math or molecular biology in biomedical reasoning. We propose a skill-based recruiting strategy that dynamically selects the most relevant set of expert LLMs for diverse reasoning tasks based on their strengths. Each selected expert then generates its own reasoning, resulting in k outputs from k experts, which are then synthesized into a final high-quality response by an aggregator chosen based on its ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's instance-level expert selection improves performance by a large margin but -- when implemented naively -- can introduce a high computational overhead due to the need for constant model loading and offloading. To address this, we implement a batch strategy that groups instances based on their assigned experts, loading each model only once. This allows us to integrate 16 expert models on 1 GPU with a time cost comparable to or better than prior multi-agent baselines using 4 GPUs. Through extensive evaluations on diverse benchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we show that Symbolic-MoE beats strong LLMs like GPT4o-mini, as well as multi-agent approaches, with an absolute avg. gain of 8.15% over the best multi-agent baseline. Moreover, Symbolic-MoE generalizes well to unseen tasks and removes the need for expensive multi-round discussions, outperforming discussion baselines with less computation.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Only a Little to the Left: A Theory-grounded Measure of Political Bias in Large Language Models</title>
<link>https://arxiv.org/abs/2503.16148</link>
<guid>https://arxiv.org/abs/2503.16148</guid>
<content:encoded><![CDATA[
arXiv:2503.16148v2 Announce Type: replace 
Abstract: Prompt-based language models like GPT4 and LLaMa have been used for a wide variety of use cases such as simulating agents, searching for information, or for content analysis. For all of these applications and others, political biases in these models can affect their performance. Several researchers have attempted to study political bias in language models using evaluation suites based on surveys, such as the Political Compass Test (PCT), often finding a particular leaning favored by these models. However, there is some variation in the exact prompting techniques, leading to diverging findings, and most research relies on constrained-answer settings to extract model responses. Moreover, the Political Compass Test is not a scientifically valid survey instrument. In this work, we contribute a political bias measured informed by political science theory, building on survey design principles to test a wide variety of input prompts, while taking into account prompt sensitivity. We then prompt 11 different open and commercial models, differentiating between instruction-tuned and non-instruction-tuned models, and automatically classify their political stances from 88,110 responses. Leveraging this dataset, we compute political bias profiles across different prompt variations and find that while PCT exaggerates bias in certain models like GPT3.5, measures of political bias are often unstable, but generally more left-leaning for instruction-tuned models. Code and data are available on: https://github.com/MaFa211/theory_grounded_pol_bias
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>APIGen-MT: Agentic Pipeline for Multi-Turn Data Generation via Simulated Agent-Human Interplay</title>
<link>https://arxiv.org/abs/2504.03601</link>
<guid>https://arxiv.org/abs/2504.03601</guid>
<content:encoded><![CDATA[
arXiv:2504.03601v4 Announce Type: replace 
Abstract: Training effective AI agents for multi-turn interactions requires high-quality data that captures realistic human-agent dynamics, yet such data is scarce and expensive to collect manually. We introduce APIGen-MT, a two-phase framework that generates verifiable and diverse multi-turn agent data. In the first phase, our agentic pipeline produces detailed task blueprints with ground-truth actions, leveraging a committee of LLM reviewers and iterative feedback loops. These blueprints are then transformed into complete interaction trajectories through simulated human-agent interplay. We train a family of models -- the xLAM-2-fc-r series with sizes ranging from 1B to 70B parameters. Our models outperform frontier models such as GPT-4o and Claude 3.5 on $\tau$-bench and BFCL benchmarks, with the smaller models surpassing their larger counterparts, particularly in multi-turn settings, while maintaining superior consistency across multiple trials. Comprehensive experiments demonstrate that our verified blueprint-to-details approach yields high-quality training data, enabling the development of more reliable, efficient, and capable agents. We open-source 5K synthetic data trajectories and the trained xLAM-2-fc-r models to advance research in AI agents.
  Models at https://huggingface.co/collections/Salesforce/xlam-2-67ef5be12949d8dcdae354c4; Dataset at https://huggingface.co/datasets/Salesforce/APIGen-MT-5k and Website at https://apigen-mt.github.io
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ChartQA-X: Generating Explanations for Visual Chart Reasoning</title>
<link>https://arxiv.org/abs/2504.13275</link>
<guid>https://arxiv.org/abs/2504.13275</guid>
<content:encoded><![CDATA[
arXiv:2504.13275v2 Announce Type: replace 
Abstract: The ability to explain complex information from chart images is vital for effective data-driven decision-making. In this work, we address the challenge of generating detailed explanations alongside answering questions about charts. We present ChartQA-X, a comprehensive dataset comprising 30,299 chart samples across four chart types, each paired with contextually relevant questions, answers, and explanations. Explanations are generated and selected based on metrics such as faithfulness, informativeness, coherence, and perplexity. Our human evaluation with 245 participants shows that model-generated explanations in ChartQA-X surpass human-written explanations in accuracy and logic and are comparable in terms of clarity and overall quality. Moreover, models fine-tuned on ChartQA-X show substantial improvements across various metrics, including absolute gains of up to 24.57 points in explanation quality, 18.96 percentage points in question-answering accuracy, and 14.75 percentage points on unseen benchmarks for the same task. By integrating explanatory narratives with answers, our approach enables agents to communicate complex visual information more effectively, improving comprehension and fostering greater trust in the generated responses.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Vision for Auto Research with LLM Agents</title>
<link>https://arxiv.org/abs/2504.18765</link>
<guid>https://arxiv.org/abs/2504.18765</guid>
<content:encoded><![CDATA[
arXiv:2504.18765v3 Announce Type: replace 
Abstract: This paper introduces Agent-Based Auto Research, a structured multi-agent framework designed to automate, coordinate, and optimize the full lifecycle of scientific research. Leveraging the capabilities of large language models (LLMs) and modular agent collaboration, the system spans all major research phases, including literature review, ideation, methodology planning, experimentation, paper writing, peer review response, and dissemination. By addressing issues such as fragmented workflows, uneven methodological expertise, and cognitive overload, the framework offers a systematic and scalable approach to scientific inquiry. Preliminary explorations demonstrate the feasibility and potential of Auto Research as a promising paradigm for self-improving, AI-driven research processes.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoordField: Coordination Field for Agentic UAV Task Allocation In Low-altitude Urban Scenarios</title>
<link>https://arxiv.org/abs/2505.00091</link>
<guid>https://arxiv.org/abs/2505.00091</guid>
<content:encoded><![CDATA[
arXiv:2505.00091v4 Announce Type: replace 
Abstract: With the increasing demand for heterogeneous Unmanned Aerial Vehicle (UAV) swarms to perform complex tasks in urban environments, system design now faces major challenges, including efficient semantic understanding, flexible task planning, and the ability to dynamically adjust coordination strategies in response to evolving environmental conditions and continuously changing task requirements. To address the limitations of existing methods, this paper proposes CoordField, a coordination field agent system for coordinating heterogeneous drone swarms in complex urban scenarios. In this system, large language models (LLMs) is responsible for interpreting high-level human instructions and converting them into executable commands for the UAV swarms, such as patrol and target tracking. Subsequently, a Coordination field mechanism is proposed to guide UAV motion and task selection, enabling decentralized and adaptive allocation of emergent tasks. A total of 50 rounds of comparative testing were conducted across different models in a 2D simulation space to evaluate their performance. Experimental results demonstrate that the proposed system achieves superior performance in terms of task coverage, response time, and adaptability to dynamic changes.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Mind to Machine: The Rise of Manus AI as a Fully Autonomous Digital Agent</title>
<link>https://arxiv.org/abs/2505.02024</link>
<guid>https://arxiv.org/abs/2505.02024</guid>
<content:encoded><![CDATA[
arXiv:2505.02024v2 Announce Type: replace 
Abstract: Manus AI is a general-purpose AI agent introduced in early 2025, marking a significant advancement in autonomous artificial intelligence. Developed by the Chinese startup Monica.im, Manus is designed to bridge the gap between "mind" and "hand" - combining the reasoning and planning capabilities of large language models with the ability to execute complex, end-to-end tasks that produce tangible outcomes. This paper presents a comprehensive overview of Manus AI, exploring its core technical architecture, diverse applications across sectors such as healthcare, finance, manufacturing, robotics, and gaming, as well as its key strengths, current limitations, and future potential. Positioned as a preview of what lies ahead, Manus AI represents a shift toward intelligent agents that can translate high-level intentions into real-world actions, heralding a new era of human-AI collaboration.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models are Autonomous Cyber Defenders</title>
<link>https://arxiv.org/abs/2505.04843</link>
<guid>https://arxiv.org/abs/2505.04843</guid>
<content:encoded><![CDATA[
arXiv:2505.04843v2 Announce Type: replace 
Abstract: Fast and effective incident response is essential to prevent adversarial cyberattacks. Autonomous Cyber Defense (ACD) aims to automate incident response through Artificial Intelligence (AI) agents that plan and execute actions. Most ACD approaches focus on single-agent scenarios and leverage Reinforcement Learning (RL). However, ACD RL-trained agents depend on costly training, and their reasoning is not always explainable or transferable. Large Language Models (LLMs) can address these concerns by providing explainable actions in general security contexts. Researchers have explored LLM agents for ACD but have not evaluated them on multi-agent scenarios or interacting with other ACD agents. In this paper, we show the first study on how LLMs perform in multi-agent ACD environments by proposing a new integration to the CybORG CAGE 4 environment. We examine how ACD teams of LLM and RL agents can interact by proposing a novel communication protocol. Our results highlight the strengths and weaknesses of LLMs and RL and help us identify promising research directions to create, train, and deploy future teams of ACD agents.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>clem:todd: A Framework for the Systematic Benchmarking of LLM-Based Task-Oriented Dialogue System Realisations</title>
<link>https://arxiv.org/abs/2505.05445</link>
<guid>https://arxiv.org/abs/2505.05445</guid>
<content:encoded><![CDATA[
arXiv:2505.05445v2 Announce Type: replace 
Abstract: The emergence of instruction-tuned large language models (LLMs) has advanced the field of dialogue systems, enabling both realistic user simulations and robust multi-turn conversational agents. However, existing research often evaluates these components in isolation-either focusing on a single user simulator or a specific system design-limiting the generalisability of insights across architectures and configurations. In this work, we propose clem todd (chat-optimized LLMs for task-oriented dialogue systems development), a flexible framework for systematically evaluating dialogue systems under consistent conditions. clem todd enables detailed benchmarking across combinations of user simulators and dialogue systems, whether existing models from literature or newly developed ones. It supports plug-and-play integration and ensures uniform datasets, evaluation metrics, and computational constraints. We showcase clem todd's flexibility by re-evaluating existing task-oriented dialogue systems within this unified setup and integrating three newly proposed dialogue systems into the same evaluation pipeline. Our results provide actionable insights into how architecture, scale, and prompting strategies affect dialogue performance, offering practical guidance for building efficient and effective conversational AI systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VisualToolAgent (VisTA): A Reinforcement Learning Framework for Visual Tool Selection</title>
<link>https://arxiv.org/abs/2505.20289</link>
<guid>https://arxiv.org/abs/2505.20289</guid>
<content:encoded><![CDATA[
arXiv:2505.20289v2 Announce Type: replace 
Abstract: We introduce VisTA, a new reinforcement learning framework that empowers visual agents to dynamically explore, select, and combine tools from a diverse library based on empirical performance. Existing methods for tool-augmented reasoning either rely on training-free prompting or large-scale fine-tuning; both lack active tool exploration and typically assume limited tool diversity, and fine-tuning methods additionally demand extensive human supervision. In contrast, VisTA leverages end-to-end reinforcement learning to iteratively refine sophisticated, query-specific tool selection strategies, using task outcomes as feedback signals. Through Group Relative Policy Optimization (GRPO), our framework enables an agent to autonomously discover effective tool-selection pathways without requiring explicit reasoning supervision. Experiments on the ChartQA, Geometry3K, and BlindTest benchmarks demonstrate that VisTA achieves substantial performance gains over training-free baselines, especially on out-of-distribution examples. These results highlight VisTA's ability to enhance generalization, adaptively utilize diverse tools, and pave the way for flexible, experience-driven visual reasoning systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Ultimate Test of Superintelligent AI Agents: Can an AI Balance Care and Control in Asymmetric Relationships?</title>
<link>https://arxiv.org/abs/2506.01813</link>
<guid>https://arxiv.org/abs/2506.01813</guid>
<content:encoded><![CDATA[
arXiv:2506.01813v2 Announce Type: replace 
Abstract: This paper introduces the Shepherd Test, a new conceptual test for assessing the moral and relational dimensions of superintelligent artificial agents. The test is inspired by human interactions with animals, where ethical considerations about care, manipulation, and consumption arise in contexts of asymmetric power and self-preservation. We argue that AI crosses an important, and potentially dangerous, threshold of intelligence when it exhibits the ability to manipulate, nurture, and instrumentally use less intelligent agents, while also managing its own survival and expansion goals. This includes the ability to weigh moral trade-offs between self-interest and the well-being of subordinate agents. The Shepherd Test thus challenges traditional AI evaluation paradigms by emphasizing moral agency, hierarchical behavior, and complex decision-making under existential stakes. We argue that this shift is critical for advancing AI governance, particularly as AI systems become increasingly integrated into multi-agent environments. We conclude by identifying key research directions, including the development of simulation environments for testing moral behavior in AI, and the formalization of ethical manipulation within multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Specification and Evaluation of Multi-Agent LLM Systems -- Prototype and Cybersecurity Applications</title>
<link>https://arxiv.org/abs/2506.10467</link>
<guid>https://arxiv.org/abs/2506.10467</guid>
<content:encoded><![CDATA[
arXiv:2506.10467v4 Announce Type: replace 
Abstract: Recent advancements in LLMs indicate potential for novel applications, as evidenced by the reasoning capabilities in the latest OpenAI and DeepSeek models. To apply these models to domain-specific applications beyond text generation, LLM-based multi-agent systems can be utilized to solve complex tasks, particularly by combining reasoning techniques, code generation, and software execution across multiple, potentially specialized LLMs. However, while many evaluations are performed on LLMs, reasoning techniques, and applications individually, their joint specification and combined application are not well understood. Defined specifications for multi-agent LLM systems are required to explore their potential and suitability for specific applications, allowing for systematic evaluations of LLMs, reasoning techniques, and related aspects. This paper reports the results of exploratory research on (1.) multi-agent specification by introducing an agent schema language and (2.) the execution and evaluation of the specifications through a multi-agent system architecture and prototype. The specification language, system architecture, and prototype are first presented in this work, building on an LLM system from prior research. Test cases involving cybersecurity tasks indicate the feasibility of the architecture and evaluation approach. As a result, evaluations could be demonstrated for question answering, server security, and network security tasks completed correctly by agents with LLMs from OpenAI and DeepSeek.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AutoGen Driven Multi Agent Framework for Iterative Crime Data Analysis and Prediction</title>
<link>https://arxiv.org/abs/2506.11475</link>
<guid>https://arxiv.org/abs/2506.11475</guid>
<content:encoded><![CDATA[
arXiv:2506.11475v2 Announce Type: replace 
Abstract: This paper introduces LUCID-MA (Learning and Understanding Crime through Dialogue of Multiple Agents), an innovative AI powered framework where multiple AI agents collaboratively analyze and understand crime data. Our system that consists of three core components: an analysis assistant that highlights spatiotemporal crime patterns; a feedback component that reviews and refines analytical results; and a prediction component that forecasts future crime trends. With a well-designed prompt and the LLaMA-2-13B-Chat-GPTQ model, it runs completely offline and allows the agents undergo self-improvement through 100 rounds of communication with less human interaction. A scoring function is incorporated to evaluate agent performance, providing visual plots to track learning progress. This work demonstrates the potential of AutoGen-style agents for autonomous, scalable, and iterative analysis in social science domains, maintaining data privacy through offline execution. It also showcases a computational model with emergent intelligence, where the system's global behavior emerges from the interactions of its agents. This emergent behavior manifests as enhanced individual agent performance, driven by collaborative dialogue between the LLM-based agents.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SciSage: A Multi-Agent Framework for High-Quality Scientific Survey Generation</title>
<link>https://arxiv.org/abs/2506.12689</link>
<guid>https://arxiv.org/abs/2506.12689</guid>
<content:encoded><![CDATA[
arXiv:2506.12689v2 Announce Type: replace 
Abstract: The rapid growth of scientific literature demands robust tools for automated survey-generation. However, current large language model (LLM)-based methods often lack in-depth analysis, structural coherence, and reliable citations. To address these limitations, we introduce SciSage, a multi-agent framework employing a reflect-when-you-write paradigm. SciSage features a hierarchical Reflector agent that critically evaluates drafts at outline, section, and document levels, collaborating with specialized agents for query interpretation, content retrieval, and refinement. We also release SurveyScope, a rigorously curated benchmark of 46 high-impact papers (2020-2025) across 11 computer science domains, with strict recency and citation-based quality controls. Evaluations demonstrate that SciSage outperforms state-of-the-art baselines (LLM x MapReduce-V2, AutoSurvey), achieving +1.73 points in document coherence and +32% in citation F1 scores. Human evaluations reveal mixed outcomes (3 wins vs. 7 losses against human-written surveys), but highlight SciSage's strengths in topical breadth and retrieval efficiency. Overall, SciSage offers a promising foundation for research-assistive writing tools.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From LLMs to MLLMs to Agents: A Survey of Emerging Paradigms in Jailbreak Attacks and Defenses within LLM Ecosystem</title>
<link>https://arxiv.org/abs/2506.15170</link>
<guid>https://arxiv.org/abs/2506.15170</guid>
<content:encoded><![CDATA[
arXiv:2506.15170v2 Announce Type: replace 
Abstract: Large language models (LLMs) are rapidly evolving from single-modal systems to multimodal LLMs and intelligent agents, significantly expanding their capabilities while introducing increasingly severe security risks. This paper presents a systematic survey of the growing complexity of jailbreak attacks and corresponding defense mechanisms within the expanding LLM ecosystem. We first trace the developmental trajectory from LLMs to MLLMs and Agents, highlighting the core security challenges emerging at each stage. Next, we categorize mainstream jailbreak techniques from both the attack impact and visibility perspectives, and provide a comprehensive analysis of representative attack methods, related datasets, and evaluation metrics. On the defense side, we organize existing strategies based on response timing and technical approach, offering a structured understanding of their applicability and implementation. Furthermore, we identify key limitations in existing surveys, such as insufficient attention to agent-specific security issues, the absence of a clear taxonomy for hybrid jailbreak methods, a lack of detailed analysis of experimental setups, and outdated coverage of recent advancements. To address these limitations, we provide an updated synthesis of recent work and outline future research directions in areas such as dataset construction, evaluation framework optimization, and strategy generalization. Our study seeks to enhance the understanding of jailbreak mechanisms and facilitate the advancement of more resilient and adaptive defense strategies in the context of ever more capable LLMs.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GraspMAS: Zero-Shot Language-driven Grasp Detection with Multi-Agent System</title>
<link>https://arxiv.org/abs/2506.18448</link>
<guid>https://arxiv.org/abs/2506.18448</guid>
<content:encoded><![CDATA[
arXiv:2506.18448v2 Announce Type: replace 
Abstract: Language-driven grasp detection has the potential to revolutionize human-robot interaction by allowing robots to understand and execute grasping tasks based on natural language commands. However, existing approaches face two key challenges. First, they often struggle to interpret complex text instructions or operate ineffectively in densely cluttered environments. Second, most methods require a training or finetuning step to adapt to new domains, limiting their generation in real-world applications. In this paper, we introduce GraspMAS, a new multi-agent system framework for language-driven grasp detection. GraspMAS is designed to reason through ambiguities and improve decision-making in real-world scenarios. Our framework consists of three specialized agents: Planner, responsible for strategizing complex queries; Coder, which generates and executes source code; and Observer, which evaluates the outcomes and provides feedback. Intensive experiments on two large-scale datasets demonstrate that our GraspMAS significantly outperforms existing baselines. Additionally, robot experiments conducted in both simulation and real-world settings further validate the effectiveness of our approach. Our project page is available at https://zquang2202.github.io/GraspMAS
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guaranteed shares of benefits and costs</title>
<link>https://arxiv.org/abs/2406.14198</link>
<guid>https://arxiv.org/abs/2406.14198</guid>
<content:encoded><![CDATA[
arXiv:2406.14198v3 Announce Type: replace-cross 
Abstract: A context-free problem of Fair Division is a function W from a profile of n types to a freely transferable amount of surplus W(x) they must share in the common property regime. A pair of tight guarantees assigns to each type an upper and a lower bound on its share under any profile of types of the other agents, and these bounds cannot be improved. The choice of a particular pair of such guarantees when the types and W have an economic interpretation vindicates ony some familiar fair sharing rules, and suggests many new ones. Our examples include the allocation of an indivisible good or bad, the classic model of a commons where types enter additively in the function W, and sharing the cost of a capacity or of the transportation costs to a location on a line.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The unknotting number, hard unknot diagrams, and reinforcement learning</title>
<link>https://arxiv.org/abs/2409.09032</link>
<guid>https://arxiv.org/abs/2409.09032</guid>
<content:encoded><![CDATA[
arXiv:2409.09032v2 Announce Type: replace-cross 
Abstract: We have developed a reinforcement learning agent that often finds a minimal sequence of unknotting crossing changes for a knot diagram with up to 200 crossings, hence giving an upper bound on the unknotting number. We have used this to determine the unknotting number of 57k knots. We took diagrams of connected sums of such knots with oppositely signed signatures, where the summands were overlaid. The agent has found examples where several of the crossing changes in an unknotting collection of crossings result in hyperbolic knots. Based on this, we have shown that, given knots $K$ and $K'$ that satisfy some mild assumptions, there is a diagram of their connected sum and $u(K) + u(K')$ unknotting crossings such that changing any one of them results in a prime knot. As a by-product, we have obtained a dataset of 2.6 million distinct hard unknot diagrams; most of them under 35 crossings. Assuming the additivity of the unknotting number, we have determined the unknotting number of 43 at most 12-crossing knots for which the unknotting number is unknown.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Eliciting Informed Preferences</title>
<link>https://arxiv.org/abs/2505.19570</link>
<guid>https://arxiv.org/abs/2505.19570</guid>
<content:encoded><![CDATA[
arXiv:2505.19570v2 Announce Type: replace-cross 
Abstract: In many settings -- like market research and social choice -- people may be presented with unfamiliar options. Classical mechanisms may perform poorly because they fail to incentivize people to learn about these options, or worse, encourage counterproductive information acquisition. We formalize this problem in a model of robust mechanism design where agents find it costly to learn about their values for a product or policy. We identify sharp limits on the designer's ability to elicit, or learn about, these values. Where these limits do not bind, we propose two-stage mechanisms that are detail-free and robust: the second stage is a classical mechanism and the first stage asks participants to predict the results of the second stage.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>H-NeiFi: Non-Invasive and Consensus-Efficient Multi-Agent Opinion Guidance</title>
<link>https://arxiv.org/abs/2507.13370</link>
<guid>https://arxiv.org/abs/2507.13370</guid>
<content:encoded><![CDATA[
arXiv:2507.13370v1 Announce Type: new 
Abstract: The openness of social media enables the free exchange of opinions, but it also presents challenges in guiding opinion evolution towards global consensus. Existing methods often directly modify user views or enforce cross-group connections. These intrusive interventions undermine user autonomy, provoke psychological resistance, and reduce the efficiency of global consensus. Additionally, due to the lack of a long-term perspective, promoting local consensus often exacerbates divisions at the macro level. To address these issues, we propose the hierarchical, non-intrusive opinion guidance framework, H-NeiFi. It first establishes a two-layer dynamic model based on social roles, considering the behavioral characteristics of both experts and non-experts. Additionally, we introduce a non-intrusive neighbor filtering method that adaptively controls user communication channels. Using multi-agent reinforcement learning (MARL), we optimize information propagation paths through a long-term reward function, avoiding direct interference with user interactions. Experiments show that H-NeiFi increases consensus speed by 22.0% to 30.7% and maintains global convergence even in the absence of experts. This approach enables natural and efficient consensus guidance by protecting user interaction autonomy, offering a new paradigm for social network governance.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LightAutoDS-Tab: Multi-AutoML Agentic System for Tabular Data</title>
<link>https://arxiv.org/abs/2507.13413</link>
<guid>https://arxiv.org/abs/2507.13413</guid>
<content:encoded><![CDATA[
arXiv:2507.13413v1 Announce Type: new 
Abstract: AutoML has advanced in handling complex tasks using the integration of LLMs, yet its efficiency remains limited by dependence on specific underlying tools. In this paper, we introduce LightAutoDS-Tab, a multi-AutoML agentic system for tasks with tabular data, which combines an LLM-based code generation with several AutoML tools. Our approach improves the flexibility and robustness of pipeline design, outperforming state-of-the-art open-source solutions on several data science tasks from Kaggle. The code of LightAutoDS-Tab is available in the open repository https://github.com/sb-ai-lab/LADS
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Model-free Reinforcement Learning for Model-based Control: Towards Safe, Interpretable and Sample-efficient Agents</title>
<link>https://arxiv.org/abs/2507.13491</link>
<guid>https://arxiv.org/abs/2507.13491</guid>
<content:encoded><![CDATA[
arXiv:2507.13491v1 Announce Type: new 
Abstract: Training sophisticated agents for optimal decision-making under uncertainty has been key to the rapid development of modern autonomous systems across fields. Notably, model-free reinforcement learning (RL) has enabled decision-making agents to improve their performance directly through system interactions, with minimal prior knowledge about the system. Yet, model-free RL has generally relied on agents equipped with deep neural network function approximators, appealing to the networks' expressivity to capture the agent's policy and value function for complex systems. However, neural networks amplify the issues of sample inefficiency, unsafe learning, and limited interpretability in model-free RL. To this end, this work introduces model-based agents as a compelling alternative for control policy approximation, leveraging adaptable models of system dynamics, cost, and constraints for safe policy learning. These models can encode prior system knowledge to inform, constrain, and aid in explaining the agent's decisions, while deficiencies due to model mismatch can be remedied with model-free RL. We outline the benefits and challenges of learning model-based agents -- exemplified by model predictive control -- and detail the primary learning approaches: Bayesian optimization, policy search RL, and offline strategies, along with their respective strengths. While model-free RL has long been established, its interplay with model-based agents remains largely unexplored, motivating our perspective on their combined potentials for sample-efficient learning of safe and interpretable decision-making agents.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GraphTrafficGPT: Enhancing Traffic Management Through Graph-Based AI Agent Coordination</title>
<link>https://arxiv.org/abs/2507.13511</link>
<guid>https://arxiv.org/abs/2507.13511</guid>
<content:encoded><![CDATA[
arXiv:2507.13511v1 Announce Type: new 
Abstract: Large Language Models (LLMs) offer significant promise for intelligent traffic management; however, current chain-based systems like TrafficGPT are hindered by sequential task execution, high token usage, and poor scalability, making them inefficient for complex, real-world scenarios. To address these limitations, we propose GraphTrafficGPT, a novel graph-based architecture, which fundamentally redesigns the task coordination process for LLM-driven traffic applications. GraphTrafficGPT represents tasks and their dependencies as nodes and edges in a directed graph, enabling efficient parallel execution and dynamic resource allocation. The main idea behind the proposed model is a Brain Agent that decomposes user queries, constructs optimized dependency graphs, and coordinates a network of specialized agents for data retrieval, analysis, visualization, and simulation. By introducing advanced context-aware token management and supporting concurrent multi-query processing, the proposed architecture handles interdependent tasks typical of modern urban mobility environments. Experimental results demonstrate that GraphTrafficGPT reduces token consumption by 50.2% and average response latency by 19.0% compared to TrafficGPT, while supporting simultaneous multi-query execution with up to 23.0% improvement in efficiency.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Humans learn to prefer trustworthy AI over human partners</title>
<link>https://arxiv.org/abs/2507.13524</link>
<guid>https://arxiv.org/abs/2507.13524</guid>
<content:encoded><![CDATA[
arXiv:2507.13524v1 Announce Type: new 
Abstract: Partner selection is crucial for cooperation and hinges on communication. As artificial agents, especially those powered by large language models (LLMs), become more autonomous, intelligent, and persuasive, they compete with humans for partnerships. Yet little is known about how humans select between human and AI partners and adapt under AI-induced competition pressure. We constructed a communication-based partner selection game and examined the dynamics in hybrid mini-societies of humans and bots powered by a state-of-the-art LLM. Through three experiments (N = 975), we found that bots, though more prosocial than humans and linguistically distinguishable, were not selected preferentially when their identity was hidden. Instead, humans misattributed bots' behaviour to humans and vice versa. Disclosing bots' identity induced a dual effect: it reduced bots' initial chances of being selected but allowed them to gradually outcompete humans by facilitating human learning about the behaviour of each partner type. These findings show how AI can reshape social interaction in mixed societies and inform the design of more effective and cooperative hybrid systems.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Human-Like Trajectories Generation via Receding Horizon Tracking Applied to the TickTacking Interface</title>
<link>https://arxiv.org/abs/2507.13528</link>
<guid>https://arxiv.org/abs/2507.13528</guid>
<content:encoded><![CDATA[
arXiv:2507.13528v1 Announce Type: new 
Abstract: TickTacking is a rhythm-based interface that allows users to control a pointer in a two-dimensional space through dual-button tapping. This paper investigates the generation of human-like trajectories using a receding horizon approach applied to the TickTacking interface in a target-tracking task. By analyzing user-generated trajectories, we identify key human behavioral features and incorporate them in a controller that mimics these behaviors. The performance of this human-inspired controller is evaluated against a baseline optimal-control-based agent, demonstrating the importance of specific control features for achieving human-like interaction. These findings contribute to the broader goal of developing rhythm-based human-machine interfaces by offering design insights that enhance user performance, improve intuitiveness, and reduce interaction frustration
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolving Neural Controllers for Xpilot-AI Racing Using Neuroevolution of Augmenting Topologies</title>
<link>https://arxiv.org/abs/2507.13549</link>
<guid>https://arxiv.org/abs/2507.13549</guid>
<content:encoded><![CDATA[
arXiv:2507.13549v1 Announce Type: new 
Abstract: This paper investigates the development of high-performance racing controllers for a newly implemented racing mode within the Xpilot-AI platform, utilizing the Neuro Evolution of Augmenting Topologies (NEAT) algorithm. By leveraging NEAT's capability to evolve both the structure and weights of neural networks, we develop adaptive controllers that can navigate complex circuits under the challenging space simulation physics of Xpilot-AI, which includes elements such as inertia, friction, and gravity. The racing mode we introduce supports flexible circuit designs and allows for the evaluation of multiple agents in parallel, enabling efficient controller optimization across generations. Experimental results demonstrate that our evolved controllers achieve up to 32% improvement in lap time compared to the controller's initial performance and develop effective racing strategies, such as optimal cornering and speed modulation, comparable to human-like techniques. This work illustrates NEAT's effectiveness in producing robust control strategies within demanding game environments and highlights Xpilot-AI's potential as a rigorous testbed for competitive AI controller evolution.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Firms to Computation: AI Governance and the Evolution of Institutions</title>
<link>https://arxiv.org/abs/2507.13616</link>
<guid>https://arxiv.org/abs/2507.13616</guid>
<content:encoded><![CDATA[
arXiv:2507.13616v1 Announce Type: new 
Abstract: The integration of agential artificial intelligence into socioeconomic systems requires us to reexamine the evolutionary processes that describe changes in our economic institutions. This article synthesizes three frameworks: multi-level selection theory, Aoki's view of firms as computational processes, and Ostrom's design principles for robust institutions. We develop a framework where selection operates concurrently across organizational levels, firms implement distributed inference via game-theoretic architectures, and Ostrom-style rules evolve as alignment mechanisms that address AI-related risks. This synthesis yields a multi-level Price equation expressed over nested games, providing quantitative metrics for how selection and governance co-determine economic outcomes. We examine connections to Acemoglu's work on inclusive institutions, analyze how institutional structures shape AI deployment, and demonstrate the framework's explanatory power via case studies. We conclude by proposing a set of design principles that operationalize alignment between humans and AI across institutional layers, enabling scalable, adaptive, and inclusive governance of agential AI systems. We conclude with practical policy recommendations and further research to extend these principles into real-world implementation.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improved particle swarm optimization algorithm: multi-target trajectory optimization for swarm drones</title>
<link>https://arxiv.org/abs/2507.13647</link>
<guid>https://arxiv.org/abs/2507.13647</guid>
<content:encoded><![CDATA[
arXiv:2507.13647v1 Announce Type: new 
Abstract: Real-time trajectory planning for unmanned aerial vehicles (UAVs) in dynamic environments remains a key challenge due to high computational demands and the need for fast, adaptive responses. Traditional Particle Swarm Optimization (PSO) methods, while effective for offline planning, often struggle with premature convergence and latency in real-time scenarios. To overcome these limitations, we propose PE-PSO, an enhanced PSO-based online trajectory planner. The method introduces a persistent exploration mechanism to preserve swarm diversity and an entropy-based parameter adjustment strategy to dynamically adapt optimization behavior. UAV trajectories are modeled using B-spline curves, which ensure path smoothness while reducing optimization complexity. To extend this capability to UAV swarms, we develop a multi-agent framework that combines genetic algorithm (GA)-based task allocation with distributed PE-PSO, supporting scalable and coordinated trajectory generation. The distributed architecture allows for parallel computation and decentralized control, enabling effective cooperation among agents while maintaining real-time performance. Comprehensive simulations demonstrate that the proposed framework outperforms conventional PSO and other swarm-based planners across several metrics, including trajectory quality, energy efficiency, obstacle avoidance, and computation time. These results confirm the effectiveness and applicability of PE-PSO in real-time multi-UAV operations under complex environmental conditions.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Minimum Clustering of Matrices Based on Phase Alignment</title>
<link>https://arxiv.org/abs/2507.13678</link>
<guid>https://arxiv.org/abs/2507.13678</guid>
<content:encoded><![CDATA[
arXiv:2507.13678v1 Announce Type: new 
Abstract: Coordinating multi-agent systems requires balancing synchronization performance and controller implementation costs. To this end, we classify agents by their intrinsic properties, enabling each group to be controlled by a uniform controller and thus reducing the number of unique controller types required. Existing centralized control methods, despite their capability to achieve high synchronization performance with fewer types of controllers, suffer from critical drawbacks such as limited scalability and vulnerability to single points of failure. On the other hand, distributed control strategies, where controllers are typically agent-dependent, result in the type of required controllers increasing proportionally with the size of the system.
  This paper introduces a novel phase-alignment-based framework to minimize the type of controllers by strategically clustering agents with aligned synchronization behaviors. Leveraging the intrinsic phase properties of complex matrices, we formulate a constrained clustering problem and propose a hierarchical optimization method combining recursive exact searches for small-scale systems and scalable stochastic approximations for large-scale networks. This work bridges theoretical phase analysis with practical control synthesis, offering a cost-effective solution for large-scale multi-agent systems. The theoretical results applied for the analysis of a 50-agent network illustrate the effectiveness of the proposed algorithms.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CogniQ-H: A Soft Hierarchical Reinforcement Learning Paradigm for Automated Data Preparation</title>
<link>https://arxiv.org/abs/2507.13710</link>
<guid>https://arxiv.org/abs/2507.13710</guid>
<content:encoded><![CDATA[
arXiv:2507.13710v1 Announce Type: new 
Abstract: Data preparation is a foundational yet notoriously challenging component of the machine learning lifecycle, characterized by a vast combinatorial search space of potential operator sequences. While reinforcement learning (RL) offers a promising direction, existing approaches are inefficient as they fail to capture the structured, hierarchical nature of the problem. We argue that Hierarchical Reinforcement Learning (HRL), a paradigm that has been successful in other domains, provides a conceptually ideal yet previously unexplored framework for this task. However, a naive HRL implementation with a `hard hierarchy' is prone to suboptimal, irreversible decisions. To address this, we introduce CogniQ-H, the first framework to implement a soft hierarchical paradigm for robust, end-to-end automated data preparation. CogniQ-H formulates action selection as a Bayesian inference problem. A high-level strategic prior, generated by a Large Language Model (LLM), guides exploration probabilistically. This prior is synergistically combined with a fine-grained operator quality score from a supervised Learning-to-Rank (LTR) model and a long-term value estimate from the agent's own Q-function. This hybrid architecture allows CogniQ-H to balance strategic guidance with adaptive, evidence-based decision-making. Through extensive experiments on 18 diverse datasets spanning multiple domains, we demonstrate that CogniQ-H achieves up to 13.9\% improvement in pipeline quality and 2.8$\times$ faster convergence compared to state-of-the-art RL-based methods.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AGENTS-LLM: Augmentative GENeration of Challenging Traffic Scenarios with an Agentic LLM Framework</title>
<link>https://arxiv.org/abs/2507.13729</link>
<guid>https://arxiv.org/abs/2507.13729</guid>
<content:encoded><![CDATA[
arXiv:2507.13729v1 Announce Type: new 
Abstract: Rare, yet critical, scenarios pose a significant challenge in testing and evaluating autonomous driving planners. Relying solely on real-world driving scenes requires collecting massive datasets to capture these scenarios. While automatic generation of traffic scenarios appears promising, data-driven models require extensive training data and often lack fine-grained control over the output. Moreover, generating novel scenarios from scratch can introduce a distributional shift from the original training scenes which undermines the validity of evaluations especially for learning-based planners. To sidestep this, recent work proposes to generate challenging scenarios by augmenting original scenarios from the test set. However, this involves the manual augmentation of scenarios by domain experts. An approach that is unable to meet the demands for scale in the evaluation of self-driving systems. Therefore, this paper introduces a novel LLM-agent based framework for augmenting real-world traffic scenarios using natural language descriptions, addressing the limitations of existing methods. A key innovation is the use of an agentic design, enabling fine-grained control over the output and maintaining high performance even with smaller, cost-effective LLMs. Extensive human expert evaluation demonstrates our framework's ability to accurately adhere to user intent, generating high quality augmented scenarios comparable to those created manually.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Extraction to Synthesis: Entangled Heuristics for Agent-Augmented Strategic Reasoning</title>
<link>https://arxiv.org/abs/2507.13768</link>
<guid>https://arxiv.org/abs/2507.13768</guid>
<content:encoded><![CDATA[
arXiv:2507.13768v1 Announce Type: new 
Abstract: We present a hybrid architecture for agent-augmented strategic reasoning, combining heuristic extraction, semantic activation, and compositional synthesis. Drawing on sources ranging from classical military theory to contemporary corporate strategy, our model activates and composes multiple heuristics through a process of semantic interdependence inspired by research in quantum cognition. Unlike traditional decision engines that select the best rule, our system fuses conflicting heuristics into coherent and context-sensitive narratives, guided by semantic interaction modeling and rhetorical framing. We demonstrate the framework via a Meta vs. FTC case study, with preliminary validation through semantic metrics. Limitations and extensions (e.g., dynamic interference tuning) are discussed.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CodeEdu: A Multi-Agent Collaborative Platform for Personalized Coding Education</title>
<link>https://arxiv.org/abs/2507.13814</link>
<guid>https://arxiv.org/abs/2507.13814</guid>
<content:encoded><![CDATA[
arXiv:2507.13814v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated considerable potential in improving coding education by providing support for code writing, explanation, and debugging. However, existing LLM-based approaches generally fail to assess students' abilities, design learning plans, provide personalized material aligned with individual learning goals, and enable interactive learning. Current work mostly uses single LLM agents, which limits their ability to understand complex code repositories and schedule step-by-step tutoring. Recent research has shown that multi-agent LLMs can collaborate to solve complicated problems in various domains like software engineering, but their potential in the field of education remains unexplored. In this work, we introduce CodeEdu, an innovative multi-agent collaborative platform that combines LLMs with tool use to provide proactive and personalized education in coding. Unlike static pipelines, CodeEdu dynamically allocates agents and tasks to meet student needs. Various agents in CodeEdu undertake certain functions specifically, including task planning, personalized material generation, real-time QA, step-by-step tutoring, code execution, debugging, and learning report generation, facilitated with extensive external tools to improve task efficiency. Automated evaluations reveal that CodeEdu substantially enhances students' coding performance.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scalable Submodular Policy Optimization via Pruned Submodularity Graph</title>
<link>https://arxiv.org/abs/2507.13834</link>
<guid>https://arxiv.org/abs/2507.13834</guid>
<content:encoded><![CDATA[
arXiv:2507.13834v1 Announce Type: new 
Abstract: In Reinforcement Learning (abbreviated as RL), an agent interacts with the environment via a set of possible actions, and a reward is generated from some unknown distribution. The task here is to find an optimal set of actions such that the reward after a certain time step gets maximized. In a traditional setup, the reward function in an RL Problem is considered additive. However, in reality, there exist many problems, including path planning, coverage control, etc., the reward function follows the diminishing return, which can be modeled as a submodular function. In this paper, we study a variant of the RL Problem where the reward function is submodular, and our objective is to find an optimal policy such that this reward function gets maximized. We have proposed a pruned submodularity graph-based approach that provides a provably approximate solution in a feasible computation time. The proposed approach has been analyzed to understand its time and space requirements as well as a performance guarantee. We have experimented with a benchmark agent-environment setup, which has been used for similar previous studies, and the results are reported. From the results, we observe that the policy obtained by our proposed approach leads to more reward than the baseline methods.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Principles and Reasons Behind Automated Vehicle Decisions in Ethically Ambiguous Everyday Scenarios</title>
<link>https://arxiv.org/abs/2507.13837</link>
<guid>https://arxiv.org/abs/2507.13837</guid>
<content:encoded><![CDATA[
arXiv:2507.13837v1 Announce Type: new 
Abstract: Automated vehicles (AVs) increasingly encounter ethically ambiguous situations in everyday driving--scenarios involving conflicting human interests and lacking clearly optimal courses of action. While existing ethical models often focus on rare, high-stakes dilemmas (e.g., crash avoidance or trolley problems), routine decisions such as overtaking cyclists or navigating social interactions remain underexplored. This study addresses that gap by applying the tracking condition of Meaningful Human Control (MHC), which holds that AV behaviour should align with human reasons--defined as the values, intentions, and expectations that justify actions. We conducted qualitative interviews with 18 AV experts to identify the types of reasons that should inform AV manoeuvre planning. Thirteen categories of reasons emerged, organised across normative, strategic, tactical, and operational levels, and linked to the roles of relevant human agents. A case study on cyclist overtaking illustrates how these reasons interact in context, revealing a consistent prioritisation of safety, contextual flexibility regarding regulatory compliance, and nuanced trade-offs involving efficiency, comfort, and public acceptance. Based on these insights, we propose a principled conceptual framework for AV decision-making in routine, ethically ambiguous scenarios. The framework supports dynamic, human-aligned behaviour by prioritising safety, allowing pragmatic actions when strict legal adherence would undermine key values, and enabling constrained deviations when appropriately justified. This empirically grounded approach advances current guidance by offering actionable, context-sensitive design principles for ethically aligned AV systems.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Causal Knowledge Transfer for Multi-Agent Reinforcement Learning in Dynamic Environments</title>
<link>https://arxiv.org/abs/2507.13846</link>
<guid>https://arxiv.org/abs/2507.13846</guid>
<content:encoded><![CDATA[
arXiv:2507.13846v1 Announce Type: new 
Abstract: [Context] Multi-agent reinforcement learning (MARL) has achieved notable success in environments where agents must learn coordinated behaviors. However, transferring knowledge across agents remains challenging in non-stationary environments with changing goals. [Problem] Traditional knowledge transfer methods in MARL struggle to generalize, and agents often require costly retraining to adapt. [Approach] This paper introduces a causal knowledge transfer framework that enables RL agents to learn and share compact causal representations of paths within a non-stationary environment. As the environment changes (new obstacles), agents' collisions require adaptive recovery strategies. We model each collision as a causal intervention instantiated as a sequence of recovery actions (a macro) whose effect corresponds to a causal knowledge of how to circumvent the obstacle while increasing the chances of achieving the agent's goal (maximizing cumulative reward). This recovery action macro is transferred online from a second agent and is applied in a zero-shot fashion, i.e., without retraining, just by querying a lookup model with local context information (collisions). [Results] Our findings reveal two key insights: (1) agents with heterogeneous goals were able to bridge about half of the gap between random exploration and a fully retrained policy when adapting to new environments, and (2) the impact of causal knowledge transfer depends on the interplay between environment complexity and agents' heterogeneous goals.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reframing attention as a reinforcement learning problem for causal discovery</title>
<link>https://arxiv.org/abs/2507.13920</link>
<guid>https://arxiv.org/abs/2507.13920</guid>
<content:encoded><![CDATA[
arXiv:2507.13920v1 Announce Type: new 
Abstract: Formal frameworks of causality have operated largely parallel to modern trends in deep reinforcement learning (RL). However, there has been a revival of interest in formally grounding the representations learned by neural networks in causal concepts. Yet, most attempts at neural models of causality assume static causal graphs and ignore the dynamic nature of causal interactions. In this work, we introduce Causal Process framework as a novel theory for representing dynamic hypotheses about causal structure. Furthermore, we present Causal Process Model as an implementation of this framework. This allows us to reformulate the attention mechanism popularized by Transformer networks within an RL setting with the goal to infer interpretable causal processes from visual observations. Here, causal inference corresponds to constructing a causal graph hypothesis which itself becomes an RL task nested within the original RL problem. To create an instance of such hypothesis, we employ RL agents. These agents establish links between units similar to the original Transformer attention mechanism. We demonstrate the effectiveness of our approach in an RL environment where we outperform current alternatives in causal representation learning and agent performance, and uniquely recover graphs of dynamic causal processes.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Marcel: A Lightweight and Open-Source Conversational Agent for University Student Support</title>
<link>https://arxiv.org/abs/2507.13937</link>
<guid>https://arxiv.org/abs/2507.13937</guid>
<content:encoded><![CDATA[
arXiv:2507.13937v1 Announce Type: new 
Abstract: We present Marcel, a lightweight and open-source conversational agent designed to support prospective students with admission-related inquiries. The system aims to provide fast and personalized responses, while reducing workload of university staff. We employ retrieval-augmented generation to ground answers in university resources and to provide users with verifiable, contextually relevant information. To improve retrieval quality, we introduce an FAQ retriever that maps user questions to knowledge-base entries, allowing administrators to steer retrieval, and improving over standard dense/hybrid retrieval strategies. The system is engineered for easy deployment in resource-constrained academic settings. We detail the system architecture, provide a technical evaluation of its components, and report insights from a real-world deployment.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NeHMO: Neural Hamilton-Jacobi Reachability Learning for Decentralized Safe Multi-Agent Motion Planning</title>
<link>https://arxiv.org/abs/2507.13940</link>
<guid>https://arxiv.org/abs/2507.13940</guid>
<content:encoded><![CDATA[
arXiv:2507.13940v1 Announce Type: new 
Abstract: Safe Multi-Agent Motion Planning (MAMP) is a significant challenge in robotics. Despite substantial advancements, existing methods often face a dilemma. Decentralized algorithms typically rely on predicting the behavior of other agents, sharing contracts, or maintaining communication for safety, while centralized approaches struggle with scalability and real-time decision-making. To address these challenges, we introduce Neural Hamilton-Jacobi Reachability Learning (HJR) for Decentralized Multi-Agent Motion Planning. Our method provides scalable neural HJR modeling to tackle high-dimensional configuration spaces and capture worst-case collision and safety constraints between agents. We further propose a decentralized trajectory optimization framework that incorporates the learned HJR solutions to solve MAMP tasks in real-time. We demonstrate that our method is both scalable and data-efficient, enabling the solution of MAMP problems in higher-dimensional scenarios with complex collision constraints. Our approach generalizes across various dynamical systems, including a 12-dimensional dual-arm setup, and outperforms a range of state-of-the-art techniques in successfully addressing challenging MAMP tasks. Video demonstrations are available at https://youtu.be/IZiePX0p1Mc.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bottom-up Domain-specific Superintelligence: A Reliable Knowledge Graph is What We Need</title>
<link>https://arxiv.org/abs/2507.13966</link>
<guid>https://arxiv.org/abs/2507.13966</guid>
<content:encoded><![CDATA[
arXiv:2507.13966v1 Announce Type: new 
Abstract: Language models traditionally used for cross-domain generalization have recently demonstrated task-specific reasoning. However, their top-down training approach on general corpora is insufficient for acquiring abstractions needed for deep domain expertise. This may require a bottom-up approach that acquires expertise by learning to compose simple domain concepts into more complex ones. A knowledge graph (KG) provides this compositional structure, where domain primitives are represented as head-relation-tail edges and their paths encode higher-level concepts. We present a task generation pipeline that synthesizes tasks directly from KG primitives, enabling models to acquire and compose them for reasoning. We fine-tune language models on the resultant KG-grounded curriculum to demonstrate domain-specific superintelligence. While broadly applicable, we validate our approach in medicine, where reliable KGs exist. Using a medical KG, we curate 24,000 reasoning tasks paired with thinking traces derived from diverse medical primitives. We fine-tune the QwQ-32B model on this curriculum to obtain QwQ-Med-3 that takes a step towards medical superintelligence. We also introduce ICD-Bench, an evaluation suite to quantify reasoning abilities across 15 medical domains. Our experiments demonstrate that QwQ-Med-3 significantly outperforms state-of-the-art reasoning models on ICD-Bench categories. Further analysis reveals that QwQ-Med-3 utilizes acquired primitives to widen the performance gap on the hardest tasks of ICD-Bench. Finally, evaluation on medical question-answer benchmarks shows that QwQ-Med-3 transfers acquired expertise to enhance the base model's performance. While the industry's approach to artificial general intelligence (AGI) emphasizes broad expertise, we envision a future in which AGI emerges from the composable interaction of efficient domain-specific superintelligent agents.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DreamScene: 3D Gaussian-based End-to-end Text-to-3D Scene Generation</title>
<link>https://arxiv.org/abs/2507.13985</link>
<guid>https://arxiv.org/abs/2507.13985</guid>
<content:encoded><![CDATA[
arXiv:2507.13985v1 Announce Type: new 
Abstract: Generating 3D scenes from natural language holds great promise for applications in gaming, film, and design. However, existing methods struggle with automation, 3D consistency, and fine-grained control. We present DreamScene, an end-to-end framework for high-quality and editable 3D scene generation from text or dialogue. DreamScene begins with a scene planning module, where a GPT-4 agent infers object semantics and spatial constraints to construct a hybrid graph. A graph-based placement algorithm then produces a structured, collision-free layout. Based on this layout, Formation Pattern Sampling (FPS) generates object geometry using multi-timestep sampling and reconstructive optimization, enabling fast and realistic synthesis. To ensure global consistent, DreamScene employs a progressive camera sampling strategy tailored to both indoor and outdoor settings. Finally, the system supports fine-grained scene editing, including object movement, appearance changes, and 4D dynamic motion. Experiments demonstrate that DreamScene surpasses prior methods in quality, consistency, and flexibility, offering a practical solution for open-domain 3D content creation. Code and demos are available at https://dreamscene-project.github.io.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Byzantine-resilient federated online learning for Gaussian process regression</title>
<link>https://arxiv.org/abs/2507.14021</link>
<guid>https://arxiv.org/abs/2507.14021</guid>
<content:encoded><![CDATA[
arXiv:2507.14021v1 Announce Type: new 
Abstract: In this paper, we study Byzantine-resilient federated online learning for Gaussian process regression (GPR). We develop a Byzantine-resilient federated GPR algorithm that allows a cloud and a group of agents to collaboratively learn a latent function and improve the learning performances where some agents exhibit Byzantine failures, i.e., arbitrary and potentially adversarial behavior. Each agent-based local GPR sends potentially compromised local predictions to the cloud, and the cloud-based aggregated GPR computes a global model by a Byzantine-resilient product of experts aggregation rule. Then the cloud broadcasts the current global model to all the agents. Agent-based fused GPR refines local predictions by fusing the received global model with that of the agent-based local GPR. Moreover, we quantify the learning accuracy improvements of the agent-based fused GPR over the agent-based local GPR. Experiments on a toy example and two medium-scale real-world datasets are conducted to demonstrate the performances of the proposed algorithm.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Architecting Human-AI Cocreation for Technical Services -- Interaction Modes and Contingency Factors</title>
<link>https://arxiv.org/abs/2507.14034</link>
<guid>https://arxiv.org/abs/2507.14034</guid>
<content:encoded><![CDATA[
arXiv:2507.14034v1 Announce Type: new 
Abstract: Agentic AI systems, powered by Large Language Models (LLMs), offer transformative potential for value co-creation in technical services. However, persistent challenges like hallucinations and operational brittleness limit their autonomous use, creating a critical need for robust frameworks to guide human-AI collaboration. Drawing on established Human-AI teaming research and analogies from fields like autonomous driving, this paper develops a structured taxonomy of human-agent interaction. Based on case study research within technical support platforms, we propose a six-mode taxonomy that organizes collaboration across a spectrum of AI autonomy. This spectrum is anchored by the Human-Out-of-the-Loop (HOOTL) model for full automation and the Human-Augmented Model (HAM) for passive AI assistance. Between these poles, the framework specifies four distinct intermediate structures. These include the Human-in-Command (HIC) model, where AI proposals re-quire mandatory human approval, and the Human-in-the-Process (HITP) model for structured work-flows with deterministic human tasks. The taxonomy further delineates the Human-in-the-Loop (HITL) model, which facilitates agent-initiated escalation upon uncertainty, and the Human-on-the-Loop (HOTL) model, which enables discretionary human oversight of an autonomous AI. The primary contribution of this work is a comprehensive framework that connects this taxonomy to key contingency factors -- such as task complexity, operational risk, and system reliability -- and their corresponding conceptual architectures. By providing a systematic method for selecting and designing an appropriate level of human oversight, our framework offers practitioners a crucial tool to navigate the trade-offs between automation and control, thereby fostering the development of safer, more effective, and context-aware technical service systems.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online MMS Allocation for Chores</title>
<link>https://arxiv.org/abs/2507.14039</link>
<guid>https://arxiv.org/abs/2507.14039</guid>
<content:encoded><![CDATA[
arXiv:2507.14039v1 Announce Type: new 
Abstract: We study the problem of fair division of indivisible chores among $n$ agents in an online setting, where items arrive sequentially and must be allocated irrevocably upon arrival. The goal is to produce an $\alpha$-MMS allocation at the end. Several recent works have investigated this model, but have only succeeded in obtaining non-trivial algorithms under restrictive assumptions, such as the two-agent bi-valued special case (Wang and Wei, 2025), or by assuming knowledge of the total disutility of each agent (Zhou, Bai, and Wu, 2023). For the general case, the trivial $n$-MMS guarantee remains the best known, while the strongest lower bound is still only $2$.
  We close this gap on the negative side by proving that for any fixed $n$ and $\varepsilon$, no algorithm can guarantee an $(n - \varepsilon)$-MMS allocation. Notably, this lower bound holds precisely for every $n$, without hiding constants in big-$O$ notation, thereby exactly matching the trivial upper bound.
  Despite this strong impossibility result, we also present positive results. We provide an online algorithm that applies in the general case, guaranteeing a $\min\{n, O(k), O(\log D)\}$-MMS allocation, where $k$ is the maximum number of distinct disutilities across all agents and $D$ is the maximum ratio between the largest and smallest disutilities for any agent. This bound is reasonable across a broad range of scenarios and, for example, implies that we can achieve an $O(1)$-MMS allocation whenever $k$ is constant. Moreover, to optimize the constant in the important personalized bi-valued case, we show that if each agent has at most two distinct disutilities, our algorithm guarantees a $(2 + \sqrt{3}) \approx 3.7$-MMS allocation.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Rational Speech Act: Pragmatic Reasoning for Multi-Turn Dialog</title>
<link>https://arxiv.org/abs/2507.14063</link>
<guid>https://arxiv.org/abs/2507.14063</guid>
<content:encoded><![CDATA[
arXiv:2507.14063v1 Announce Type: new 
Abstract: As AI systems take on collaborative roles, they must reason about shared goals and beliefs-not just generate fluent language. The Rational Speech Act (RSA) framework offers a principled approach to pragmatic reasoning, but existing extensions face challenges in scaling to multi-turn, collaborative scenarios. In this paper, we introduce Collaborative Rational Speech Act (CRSA), an information-theoretic (IT) extension of RSA that models multi-turn dialog by optimizing a gain function adapted from rate-distortion theory. This gain is an extension of the gain model that is maximized in the original RSA model but takes into account the scenario in which both agents in a conversation have private information and produce utterances conditioned on the dialog. We demonstrate the effectiveness of CRSA on referential games and template-based doctor-patient dialogs in the medical domain. Empirical results show that CRSA yields more consistent, interpretable, and collaborative behavior than existing baselines-paving the way for more pragmatic and socially aware language agents.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DPMT: Dual Process Multi-scale Theory of Mind Framework for Real-time Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2507.14088</link>
<guid>https://arxiv.org/abs/2507.14088</guid>
<content:encoded><![CDATA[
arXiv:2507.14088v1 Announce Type: new 
Abstract: Real-time human-artificial intelligence (AI) collaboration is crucial yet challenging, especially when AI agents must adapt to diverse and unseen human behaviors in dynamic scenarios. Existing large language model (LLM) agents often fail to accurately model the complex human mental characteristics such as domain intentions, especially in the absence of direct communication. To address this limitation, we propose a novel dual process multi-scale theory of mind (DPMT) framework, drawing inspiration from cognitive science dual process theory. Our DPMT framework incorporates a multi-scale theory of mind (ToM) module to facilitate robust human partner modeling through mental characteristic reasoning. Experimental results demonstrate that DPMT significantly enhances human-AI collaboration, and ablation studies further validate the contributions of our multi-scale ToM in the slow system.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differential Privacy in Kernelized Contextual Bandits via Random Projections</title>
<link>https://arxiv.org/abs/2507.13639</link>
<guid>https://arxiv.org/abs/2507.13639</guid>
<content:encoded><![CDATA[
arXiv:2507.13639v1 Announce Type: cross 
Abstract: We consider the problem of contextual kernel bandits with stochastic contexts, where the underlying reward function belongs to a known Reproducing Kernel Hilbert Space. We study this problem under an additional constraint of Differential Privacy, where the agent needs to ensure that the sequence of query points is differentially private with respect to both the sequence of contexts and rewards. We propose a novel algorithm that achieves the state-of-the-art cumulative regret of $\widetilde{\mathcal{O}}(\sqrt{\gamma_TT}+\frac{\gamma_T}{\varepsilon_{\mathrm{DP}}})$ and $\widetilde{\mathcal{O}}(\sqrt{\gamma_TT}+\frac{\gamma_T\sqrt{T}}{\varepsilon_{\mathrm{DP}}})$ over a time horizon of $T$ in the joint and local models of differential privacy, respectively, where $\gamma_T$ is the effective dimension of the kernel and $\varepsilon_{\mathrm{DP}} > 0$ is the privacy parameter. The key ingredient of the proposed algorithm is a novel private kernel-ridge regression estimator which is based on a combination of private covariance estimation and private random projections. It offers a significantly reduced sensitivity compared to its classical counterpart while maintaining a high prediction accuracy, allowing our algorithm to achieve the state-of-the-art performance guarantees.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conformal Data Contamination Tests for Trading or Sharing of Data</title>
<link>https://arxiv.org/abs/2507.13835</link>
<guid>https://arxiv.org/abs/2507.13835</guid>
<content:encoded><![CDATA[
arXiv:2507.13835v1 Announce Type: cross 
Abstract: The amount of quality data in many machine learning tasks is limited to what is available locally to data owners. The set of quality data can be expanded through trading or sharing with external data agents. However, data buyers need quality guarantees before purchasing, as external data may be contaminated or irrelevant to their specific learning task. Previous works primarily rely on distributional assumptions about data from different agents, relegating quality checks to post-hoc steps involving costly data valuation procedures. We propose a distribution-free, contamination-aware data-sharing framework that identifies external data agents whose data is most valuable for model personalization. To achieve this, we introduce novel two-sample testing procedures, grounded in rigorous theoretical foundations for conformal outlier detection, to determine whether an agent's data exceeds a contamination threshold. The proposed tests, termed conformal data contamination tests, remain valid under arbitrary contamination levels while enabling false discovery rate control via the Benjamini-Hochberg procedure. Empirical evaluations across diverse collaborative learning scenarios demonstrate the robustness and effectiveness of our approach. Overall, the conformal data contamination test distinguishes itself as a generic procedure for aggregating data with statistically rigorous quality guarantees.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Signal Temporal Logic Control Synthesis among Uncontrollable Dynamic Agents with Conformal Prediction</title>
<link>https://arxiv.org/abs/2312.04242</link>
<guid>https://arxiv.org/abs/2312.04242</guid>
<content:encoded><![CDATA[
arXiv:2312.04242v4 Announce Type: replace 
Abstract: The control of dynamical systems under temporal logic specifications among uncontrollable dynamic agents is challenging due to the agents' a-priori unknown behavior. Existing works have considered the problem where either all agents are controllable, the agent models are deterministic and known, or no safety guarantees are provided. We propose a predictive control synthesis framework that guarantees, with high probability, the satisfaction of signal temporal logic (STL) tasks that are defined over a controllable system in the presence of uncontrollable stochastic agents. We use trajectory predictors and conformal prediction to construct probabilistic prediction regions for each uncontrollable agent that are valid over multiple future time steps. Specifically, we construct a normalized prediction region over all agents and time steps to reduce conservatism and increase data efficiency. We then formulate a worst-case bilevel mixed integer program (MIP) that accounts for all agent realizations within the prediction region to obtain an open-loop controller that provably guarantee task satisfaction with high probability. To efficiently solve this bilevel MIP, we propose an equivalent MIP program based on KKT conditions of the original bilevel formulation. Building upon this, we design a closed-loop controller, where both recursive feasibility and task satisfaction can be guaranteed with high probability. We illustrate our control synthesis framework on two case studies.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Interpretable Imitation Learning via Generative Adversarial STL Inference and Control</title>
<link>https://arxiv.org/abs/2402.10310</link>
<guid>https://arxiv.org/abs/2402.10310</guid>
<content:encoded><![CDATA[
arXiv:2402.10310v2 Announce Type: replace 
Abstract: Imitation learning methods have demonstrated considerable success in teaching autonomous systems complex tasks through expert demonstrations. However, a limitation of these methods is their lack of interpretability, particularly in understanding the specific task the learning agent aims to accomplish. In this paper, we propose a novel imitation learning method that combines Signal Temporal Logic (STL) inference and control synthesis, enabling the explicit representation of the task as an STL formula. This approach not only provides a clear understanding of the task but also supports the integration of human knowledge and allows for adaptation to out-of-distribution scenarios by manually adjusting the STL formulas and fine-tuning the policy. We employ a Generative Adversarial Network (GAN)-inspired approach to train both the inference and policy networks, effectively narrowing the gap between expert and learned policies. The efficiency of our algorithm is demonstrated through simulations, showcasing its practical applicability and adaptability.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision and the Road Ahead</title>
<link>https://arxiv.org/abs/2404.04834</link>
<guid>https://arxiv.org/abs/2404.04834</guid>
<content:encoded><![CDATA[
arXiv:2404.04834v4 Announce Type: replace 
Abstract: Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This paper explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this paper, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Visual Grounding Methods for Efficient Interaction with Desktop Graphical User Interfaces</title>
<link>https://arxiv.org/abs/2407.01558</link>
<guid>https://arxiv.org/abs/2407.01558</guid>
<content:encoded><![CDATA[
arXiv:2407.01558v3 Announce Type: replace 
Abstract: Most visual grounding solutions primarily focus on realistic images. However, applications involving synthetic images, such as Graphical User Interfaces (GUIs), remain limited. This restricts the development of autonomous computer vision-powered artificial intelligence (AI) agents for automatic application interaction. Enabling AI to effectively understand and interact with GUIs is crucial to advancing automation in software testing, accessibility, and human-computer interaction. In this work, we explore Instruction Visual Grounding (IVG), a multi-modal approach to object identification within a GUI. More precisely, given a natural language instruction and a GUI screen, IVG locates the coordinates of the element on the screen where the instruction should be executed. We propose two main methods: (1) IVGocr, which combines a Large Language Model (LLM), an object detection model, and an Optical Character Recognition (OCR) module; and (2) IVGdirect, which uses a multimodal architecture for end-to-end grounding. For each method, we introduce a dedicated dataset. In addition, we propose the Central Point Validation (CPV) metric, a relaxed variant of the classical Central Proximity Score (CPS) metric. Our final test dataset is publicly released to support future research.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sparse Rewards Can Self-Train Dialogue Agents</title>
<link>https://arxiv.org/abs/2409.04617</link>
<guid>https://arxiv.org/abs/2409.04617</guid>
<content:encoded><![CDATA[
arXiv:2409.04617v3 Announce Type: replace 
Abstract: Recent advancements in state-of-the-art (SOTA) Large Language Model (LLM) agents, especially in multi-turn dialogue tasks, have been primarily driven by supervised fine-tuning and high-quality human feedback. However, as base LLM models continue to improve, acquiring meaningful human feedback has become increasingly challenging and costly. In certain domains, base LLM agents may eventually exceed human capabilities, making traditional feedback-driven methods impractical. In this paper, we introduce a novel self-improvement paradigm that empowers LLM agents to autonomously enhance their performance without external human feedback. Our method, Juxtaposed Outcomes for Simulation Harvesting (JOSH), is a self-alignment algorithm that leverages a sparse reward simulation environment to extract ideal behaviors and further train the LLM on its own outputs. We present ToolWOZ, a sparse reward tool-calling simulation environment derived from MultiWOZ. We demonstrate that models trained with JOSH, both small and frontier, significantly improve tool-based interactions while preserving general model capabilities across diverse benchmarks. Our code and data are publicly available on GitHub at https://github.com/asappresearch/josh-llm-simulation-training
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Practical Operation of Deep Reinforcement Learning Agents in Real-World Network Management at Open RAN Edges</title>
<link>https://arxiv.org/abs/2410.23086</link>
<guid>https://arxiv.org/abs/2410.23086</guid>
<content:encoded><![CDATA[
arXiv:2410.23086v2 Announce Type: replace 
Abstract: Deep Reinforcement Learning (DRL) has emerged as a powerful solution for meeting the growing demands for connectivity, reliability, low latency and operational efficiency in advanced networks. However, most research has focused on theoretical analysis and simulations, with limited investigation into real-world deployment. To bridge the gap and support practical DRL deployment for network management, we first present an orchestration framework that integrates ETSI Multi-access Edge Computing (MEC) with Open RAN, enabling seamless adoption of DRL-based strategies across different time scales while enhancing agent lifecycle management. We then identify three critical challenges hindering DRL's real-world deployment, including (1) asynchronous requests from unpredictable or bursty traffic, (2) adaptability and generalization across heterogeneous topologies and evolving service demands, and (3) prolonged convergence and service interruptions due to exploration in live operational environments. To address these challenges, we propose a three-fold solution strategy: (a) advanced time-series integration for handling asynchronized traffic, (b) flexible architecture design such as multi-agent DRL and incremental learning to support heterogeneous scenarios, and (c) simulation-driven deployment with transfer learning to reduce convergence time and service disruptions. Lastly, the feasibility of the MEC-O-RAN architecture is validated on an urban-wide testing infrastructure, and two real-world use cases are presented, showcasing the three identified challenges and demonstrating the effectiveness of the proposed solutions.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BLAST: A Stealthy Backdoor Leverage Attack against Cooperative Multi-Agent Deep Reinforcement Learning based Systems</title>
<link>https://arxiv.org/abs/2501.01593</link>
<guid>https://arxiv.org/abs/2501.01593</guid>
<content:encoded><![CDATA[
arXiv:2501.01593v2 Announce Type: replace 
Abstract: Recent studies have shown that cooperative multi-agent deep reinforcement learning (c-MADRL) is under the threat of backdoor attacks. Once a backdoor trigger is observed, it will perform malicious actions leading to failures or malicious goals. However, existing backdoor attacks suffer from several issues, e.g., instant trigger patterns lack stealthiness, the backdoor is trained or activated by an additional network, or all agents are backdoored. To this end, in this paper, we propose a novel backdoor leverage attack against c-MADRL, BLAST, which attacks the entire multi-agent team by embedding the backdoor only in a single agent. Firstly, we introduce adversary spatiotemporal behavior patterns as the backdoor trigger rather than manual-injected fixed visual patterns or instant status and control the period to perform malicious actions. This method can guarantee the stealthiness and practicality of BLAST. Secondly, we hack the original reward function of the backdoor agent via unilateral guidance to inject BLAST, so as to achieve the \textit{leverage attack effect} that can pry open the entire multi-agent system via a single backdoor agent. We evaluate our BLAST against 3 classic c-MADRL algorithms (VDN, QMIX, and MAPPO) in 2 popular c-MADRL environments (SMAC and Pursuit), and 2 existing defense mechanisms. The experimental results demonstrate that BLAST can achieve a high attack success rate while maintaining a low clean performance variance rate.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASTRID -- An Automated and Scalable TRIaD for the Evaluation of RAG-based Clinical Question Answering Systems</title>
<link>https://arxiv.org/abs/2501.08208</link>
<guid>https://arxiv.org/abs/2501.08208</guid>
<content:encoded><![CDATA[
arXiv:2501.08208v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown impressive potential in clinical question answering (QA), with Retrieval Augmented Generation (RAG) emerging as a leading approach for ensuring the factual accuracy of model responses. However, current automated RAG metrics perform poorly in clinical and conversational use cases. Using clinical human evaluations of responses is expensive, unscalable, and not conducive to the continuous iterative development of RAG systems. To address these challenges, we introduce ASTRID - an Automated and Scalable TRIaD for evaluating clinical QA systems leveraging RAG - consisting of three metrics: Context Relevance (CR), Refusal Accuracy (RA), and Conversational Faithfulness (CF). Our novel evaluation metric, CF, is designed to better capture the faithfulness of a model's response to the knowledge base without penalising conversational elements. To validate our triad, we curate a dataset of over 200 real-world patient questions posed to an LLM-based QA agent during surgical follow-up for cataract surgery - the highest volume operation in the world - augmented with clinician-selected questions for emergency, clinical, and non-clinical out-of-domain scenarios. We demonstrate that CF can predict human ratings of faithfulness better than existing definitions for conversational use cases. Furthermore, we show that evaluation using our triad consisting of CF, RA, and CR exhibits alignment with clinician assessment for inappropriate, harmful, or unhelpful responses. Finally, using nine different LLMs, we demonstrate that the three metrics can closely agree with human evaluations, highlighting the potential of these metrics for use in LLM-driven automated evaluation pipelines. We also publish the prompts and datasets for these experiments, providing valuable resources for further research and development.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Code Readability in the Age of Large Language Models: An Industrial Case Study from Atlassian</title>
<link>https://arxiv.org/abs/2501.11264</link>
<guid>https://arxiv.org/abs/2501.11264</guid>
<content:encoded><![CDATA[
arXiv:2501.11264v3 Announce Type: replace 
Abstract: Software engineers spend a significant amount of time reading code during the software development process, especially in the age of large language models (LLMs) that can automatically generate code. However, little is known about the readability of the LLM-generated code and whether it is still important from practitioners' perspectives in this new era. In this paper, we conduct a survey to explore the practitioners' perspectives on code readability in the age of LLMs and investigate the readability of our LLM-based software development agents framework, HULA, by comparing its generated code with human-written code in real-world scenarios. Overall, the findings underscore that (1) readability remains a critical aspect of software development; (2) the readability of our LLM-generated code is comparable to human-written code, fostering the establishment of appropriate trust and driving the broad adoption of our LLM-powered software development platform.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Words to Collisions: LLM-Guided Evaluation and Adversarial Generation of Safety-Critical Driving Scenarios</title>
<link>https://arxiv.org/abs/2502.02145</link>
<guid>https://arxiv.org/abs/2502.02145</guid>
<content:encoded><![CDATA[
arXiv:2502.02145v4 Announce Type: replace 
Abstract: Ensuring the safety of autonomous vehicles requires virtual scenario-based testing, which depends on the robust evaluation and generation of safety-critical scenarios. So far, researchers have used scenario-based testing frameworks that rely heavily on handcrafted scenarios as safety metrics. To reduce the effort of human interpretation and overcome the limited scalability of these approaches, we combine Large Language Models (LLMs) with structured scenario parsing and prompt engineering to automatically evaluate and generate safety-critical driving scenarios. We introduce Cartesian and Ego-centric prompt strategies for scenario evaluation, and an adversarial generation module that modifies trajectories of risk-inducing vehicles (ego-attackers) to create critical scenarios. We validate our approach using a 2D simulation framework and multiple pre-trained LLMs. The results show that the evaluation module effectively detects collision scenarios and infers scenario safety. Meanwhile, the new generation module identifies high-risk agents and synthesizes realistic, safety-critical scenarios. We conclude that an LLM equipped with domain-informed prompting techniques can effectively evaluate and generate safety-critical driving scenarios, reducing dependence on handcrafted metrics. We release our open-source code and scenarios at: https://github.com/TUM-AVS/From-Words-to-Collisions.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model</title>
<link>https://arxiv.org/abs/2502.14131</link>
<guid>https://arxiv.org/abs/2502.14131</guid>
<content:encoded><![CDATA[
arXiv:2502.14131v4 Announce Type: replace 
Abstract: We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty</title>
<link>https://arxiv.org/abs/2503.06776</link>
<guid>https://arxiv.org/abs/2503.06776</guid>
<content:encoded><![CDATA[
arXiv:2503.06776v2 Announce Type: replace 
Abstract: We address safe multi-robot interaction under uncertainty. In particular, we formulate a chance-constrained linear quadratic Gaussian game with coupling constraints and system uncertainties. We find a tractable reformulation of the game and propose a dual ascent algorithm. We prove that the algorithm converges to a feedback generalized Nash equilibrium of the reformulated game, ensuring the satisfaction of the chance constraints. We test our method in driving simulations and real-world robot experiments. Our method ensures safety under uncertainty and generates less conservative trajectories than single-agent model predictive control.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Objective Reinforcement Learning for Adaptable Personalized Autonomous Driving</title>
<link>https://arxiv.org/abs/2505.05223</link>
<guid>https://arxiv.org/abs/2505.05223</guid>
<content:encoded><![CDATA[
arXiv:2505.05223v2 Announce Type: replace 
Abstract: Human drivers exhibit individual preferences regarding driving style. Adapting autonomous vehicles to these preferences is essential for user trust and satisfaction. However, existing end-to-end driving approaches often rely on predefined driving styles or require continuous user feedback for adaptation, limiting their ability to support dynamic, context-dependent preferences. We propose a novel approach using multi-objective reinforcement learning (MORL) with preference-driven optimization for end-to-end autonomous driving that enables runtime adaptation to driving style preferences. Preferences are encoded as continuous weight vectors to modulate behavior along interpretable style objectives$\unicode{x2013}$including efficiency, comfort, speed, and aggressiveness$\unicode{x2013}$without requiring policy retraining. Our single-policy agent integrates vision-based perception in complex mixed-traffic scenarios and is evaluated in diverse urban environments using the CARLA simulator. Experimental results demonstrate that the agent dynamically adapts its driving behavior according to changing preferences while maintaining performance in terms of collision avoidance and route completion.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SafeAgent: Safeguarding LLM Agents via an Automated Risk Simulator</title>
<link>https://arxiv.org/abs/2505.17735</link>
<guid>https://arxiv.org/abs/2505.17735</guid>
<content:encoded><![CDATA[
arXiv:2505.17735v2 Announce Type: replace 
Abstract: Large Language Model (LLM)-based agents are increasingly deployed in real-world applications such as "digital assistants, autonomous customer service, and decision-support systems", where their ability to "interact in multi-turn, tool-augmented environments" makes them indispensable. However, ensuring the safety of these agents remains a significant challenge due to the diverse and complex risks arising from dynamic user interactions, external tool usage, and the potential for unintended harmful behaviors. To address this critical issue, we propose AutoSafe, the first framework that systematically enhances agent safety through fully automated synthetic data generation. Concretely, 1) we introduce an open and extensible threat model, OTS, which formalizes how unsafe behaviors emerge from the interplay of user instructions, interaction contexts, and agent actions. This enables precise modeling of safety risks across diverse scenarios. 2) we develop a fully automated data generation pipeline that simulates unsafe user behaviors, applies self-reflective reasoning to generate safe responses, and constructs a large-scale, diverse, and high-quality safety training dataset-eliminating the need for hazardous real-world data collection. To evaluate the effectiveness of our framework, we design comprehensive experiments on both synthetic and real-world safety benchmarks. Results demonstrate that AutoSafe boosts safety scores by 45% on average and achieves a 28.91% improvement on real-world tasks, validating the generalization ability of our learned safety strategies. These results highlight the practical advancement and scalability of AutoSafe in building safer LLM-based agents for real-world deployment. We have released the project page at https://auto-safe.github.io/.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EvolveNav: Self-Improving Embodied Reasoning for LLM-Based Vision-Language Navigation</title>
<link>https://arxiv.org/abs/2506.01551</link>
<guid>https://arxiv.org/abs/2506.01551</guid>
<content:encoded><![CDATA[
arXiv:2506.01551v2 Announce Type: replace 
Abstract: Building Vision-Language Navigation (VLN) agents which can navigate following natural language instructions is a long-standing goal in human-robot interaction applications. Recent studies have revealed the potential of training open-source Large Language Models (LLMs) to unleash LLMs' reasoning ability for improving navigation, and simultaneously mitigate the domain gap between LLMs' training corpus and the VLN task. However, these approaches primarily adopt direct input-output mapping paradigms, causing the mapping learning difficult and the navigational decisions unexplainable. Chain-of-Thought (CoT) training is a promising way to improve both navigational decision accuracy and interpretability, while the complexity of the navigation task makes the perfect CoT labels unavailable and may lead to overfitting through pure CoT supervised fine-tuning. In this paper, we propose a novel sElf-improving embodied reasoning framework for boosting LLM-based vision-language Navigation, dubbed EvolveNav. Our EvolveNav consists of two stages: (1) Formalized CoT Supervised Fine-Tuning, where we train the model with formalized CoT labels to both activate the model's navigational reasoning capabilities and increase the reasoning speed; (2) Self-Reflective Post-Training, where the model is iteratively trained with its own reasoning outputs as self-enriched CoT labels to enhance the supervision diversity. A self-reflective auxiliary task is also introduced to encourage learning correct reasoning patterns by contrasting with wrong ones. Experimental results on the popular VLN benchmarks demonstrate the superiority of EvolveNav over previous LLM-based VLN approaches. Code is available at https://github.com/expectorlin/EvolveNav.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Neural Networks: Self-Evolving Multi-Agent Systems via Textual Backpropagation</title>
<link>https://arxiv.org/abs/2506.09046</link>
<guid>https://arxiv.org/abs/2506.09046</guid>
<content:encoded><![CDATA[
arXiv:2506.09046v2 Announce Type: replace 
Abstract: Leveraging multiple Large Language Models(LLMs) has proven effective for addressing complex, high-dimensional tasks, but current approaches often rely on static, manually engineered multi-agent configurations. To overcome these constraints, we present the Agentic Neural Network(ANN), a framework that conceptualizes multi-agent collaboration as a layered neural network architecture. In this design, each agent operates as a node, and each layer forms a cooperative "team" focused on a specific subtask. Agentic Neural Network follows a two-phase optimization strategy: (1) Forward Phase-Drawing inspiration from neural network forward passes, tasks are dynamically decomposed into subtasks, and cooperative agent teams with suitable aggregation methods are constructed layer by layer. (2) Backward Phase-Mirroring backpropagation, we refine both global and local collaboration through iterative feedback, allowing agents to self-evolve their roles, prompts, and coordination. This neuro-symbolic approach enables ANN to create new or specialized agent teams post-training, delivering notable gains in accuracy and adaptability. Across four benchmark datasets, ANN surpasses leading multi-agent baselines under the same configurations, showing consistent performance improvements. Our findings indicate that ANN provides a scalable, data-driven framework for multi-agent systems, combining the collaborative capabilities of LLMs with the efficiency and flexibility of neural network principles. We plan to open-source the entire framework.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improved Approximate EFX Guarantees for Multigraphs</title>
<link>https://arxiv.org/abs/2506.09288</link>
<guid>https://arxiv.org/abs/2506.09288</guid>
<content:encoded><![CDATA[
arXiv:2506.09288v2 Announce Type: replace 
Abstract: In recent years, a new line of work in fair allocation has focused on EFX allocations for \((p, q)\)-bounded valuations, where each good is relevant to at most \(p\) agents, and any pair of agents share at most \(q\) relevant goods. For the case \(p = 2\) and \(q = \infty\), such instances can be equivalently represented as multigraphs whose vertices are the agents and whose edges represent goods, each edge incident to exactly the one or two agents for whom the good is relevant. A recent result of \citet{amanatidis2024pushing} shows that for additive $(2,\infty)$ bounded valuations, a \((\nicefrac{2}{3})\)-EFX allocation always exists. In this paper, we improve this bound by proving the existence of a \((\nicefrac{1}{\sqrt{2}})\)-\(\efx\) allocation for additive \((2,\infty)\)-bounded valuations.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-Powered Math Tutoring: Platform for Personalized and Adaptive Education</title>
<link>https://arxiv.org/abs/2507.12484</link>
<guid>https://arxiv.org/abs/2507.12484</guid>
<content:encoded><![CDATA[
arXiv:2507.12484v1 Announce Type: new 
Abstract: The growing ubiquity of artificial intelligence (AI), in particular large language models (LLMs), has profoundly altered the way in which learners gain knowledge and interact with learning material, with many claiming that AI positively influences their learning achievements. Despite this advancement, current AI tutoring systems face limitations associated with their reactive nature, often providing direct answers without encouraging deep reflection or incorporating structured pedagogical tools and strategies. This limitation is most apparent in the field of mathematics, in which AI tutoring systems remain underdeveloped. This research addresses the question: How can AI tutoring systems move beyond providing reactive assistance to enable structured, individualized, and tool-assisted learning experiences? We introduce a novel multi-agent AI tutoring platform that combines adaptive and personalized feedback, structured course generation, and textbook knowledge retrieval to enable modular, tool-assisted learning processes. This system allows students to learn new topics while identifying and targeting their weaknesses, revise for exams effectively, and practice on an unlimited number of personalized exercises. This article contributes to the field of artificial intelligence in education by introducing a novel platform that brings together pedagogical agents and AI-driven components, augmenting the field with modular and effective systems for teaching mathematics.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On multiagent online problems with predictions</title>
<link>https://arxiv.org/abs/2507.12486</link>
<guid>https://arxiv.org/abs/2507.12486</guid>
<content:encoded><![CDATA[
arXiv:2507.12486v1 Announce Type: new 
Abstract: We study the power of (competitive) algorithms with predictions in a multiagent setting. We introduce a two predictor framework, that assumes that agents use one predictor for their future (self) behavior, and one for the behavior of the other players. The main problem we are concerned with is understanding what are the best competitive ratios that can be achieved by employing such predictors, under various assumptions on predictor quality.
  As an illustration of our framework, we introduce and analyze a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.
  In the particular case of perfect other predictions the algorithm that follows the self predictor is optimal but not robust to mispredictions of agent's future behavior; we give an algorithm with better robustness properties and benchmark it.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MR-LDM -- The Merge-Reactive Longitudinal Decision Model: Game Theoretic Human Decision Modeling for Interactive Sim Agents</title>
<link>https://arxiv.org/abs/2507.12494</link>
<guid>https://arxiv.org/abs/2507.12494</guid>
<content:encoded><![CDATA[
arXiv:2507.12494v1 Announce Type: new 
Abstract: Enhancing simulation environments to replicate real-world driver behavior, i.e., more humanlike sim agents, is essential for developing autonomous vehicle technology. In the context of highway merging, previous works have studied the operational-level yielding dynamics of lag vehicles in response to a merging car at highway on-ramps. Other works focusing on tactical decision modeling generally consider limited action sets or utilize payoff functions with large parameter sets and limited payoff bounds. In this work, we aim to improve the simulation of the highway merge scenario by targeting a game theoretic model for tactical decision-making with improved payoff functions and lag actions. We couple this with an underlying dynamics model to have a unified decision and dynamics model that can capture merging interactions and simulate more realistic interactions in an explainable and interpretable fashion. The proposed model demonstrated good reproducibility of complex interactions when validated on a real-world dataset. The model was finally integrated into a high fidelity simulation environment and confirmed to have adequate computation time efficiency for use in large-scale simulations to support autonomous vehicle development.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FOUNDER: Grounding Foundation Models in World Models for Open-Ended Embodied Decision Making</title>
<link>https://arxiv.org/abs/2507.12496</link>
<guid>https://arxiv.org/abs/2507.12496</guid>
<content:encoded><![CDATA[
arXiv:2507.12496v1 Announce Type: new 
Abstract: Foundation Models (FMs) and World Models (WMs) offer complementary strengths in task generalization at different levels. In this work, we propose FOUNDER, a framework that integrates the generalizable knowledge embedded in FMs with the dynamic modeling capabilities of WMs to enable open-ended task solving in embodied environments in a reward-free manner. We learn a mapping function that grounds FM representations in the WM state space, effectively inferring the agent's physical states in the world simulator from external observations. This mapping enables the learning of a goal-conditioned policy through imagination during behavior learning, with the mapped task serving as the goal state. Our method leverages the predicted temporal distance to the goal state as an informative reward signal. FOUNDER demonstrates superior performance on various multi-task offline visual control benchmarks, excelling in capturing the deep-level semantics of tasks specified by text or videos, particularly in scenarios involving complex observations or domain gaps where prior methods struggle. The consistency of our learned reward function with the ground-truth reward is also empirically validated. Our project website is https://sites.google.com/view/founder-rl.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can Mental Imagery Improve the Thinking Capabilities of AI Systems?</title>
<link>https://arxiv.org/abs/2507.12555</link>
<guid>https://arxiv.org/abs/2507.12555</guid>
<content:encoded><![CDATA[
arXiv:2507.12555v1 Announce Type: new 
Abstract: Although existing models can interact with humans and provide satisfactory responses, they lack the ability to act autonomously or engage in independent reasoning. Furthermore, input data in these models is typically provided as explicit queries, even when some sensory data is already acquired.
  In addition, AI agents, which are computational entities designed to perform tasks and make decisions autonomously based on their programming, data inputs, and learned knowledge, have shown significant progress. However, they struggle with integrating knowledge across multiple domains, unlike humans.
  Mental imagery plays a fundamental role in the brain's thinking process, which involves performing tasks based on internal multisensory data, planned actions, needs, and reasoning capabilities. In this paper, we investigate how to integrate mental imagery into a machine thinking framework and how this could be beneficial in initiating the thinking process. Our proposed machine thinking framework integrates a Cognitive thinking unit supported by three auxiliary units: the Input Data Unit, the Needs Unit, and the Mental Imagery Unit. Within this framework, data is represented as natural language sentences or drawn sketches, serving both informative and decision-making purposes. We conducted validation tests for this framework, and the results are presented and discussed.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Explainable Reinforcement Learning: Targets, Methods and Needs</title>
<link>https://arxiv.org/abs/2507.12599</link>
<guid>https://arxiv.org/abs/2507.12599</guid>
<content:encoded><![CDATA[
arXiv:2507.12599v1 Announce Type: new 
Abstract: The success of recent Artificial Intelligence (AI) models has been accompanied by the opacity of their internal mechanisms, due notably to the use of deep neural networks. In order to understand these internal mechanisms and explain the output of these AI models, a set of methods have been proposed, grouped under the domain of eXplainable AI (XAI). This paper focuses on a sub-domain of XAI, called eXplainable Reinforcement Learning (XRL), which aims to explain the actions of an agent that has learned by reinforcement learning. We propose an intuitive taxonomy based on two questions "What" and "How". The first question focuses on the target that the method explains, while the second relates to the way the explanation is provided. We use this taxonomy to provide a state-of-the-art review of over 250 papers. In addition, we present a set of domains close to XRL, which we believe should get attention from the community. Finally, we identify some needs for the field of XRL.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NLI4VolVis: Natural Language Interaction for Volume Visualization via LLM Multi-Agents and Editable 3D Gaussian Splatting</title>
<link>https://arxiv.org/abs/2507.12621</link>
<guid>https://arxiv.org/abs/2507.12621</guid>
<content:encoded><![CDATA[
arXiv:2507.12621v1 Announce Type: new 
Abstract: Traditional volume visualization (VolVis) methods, like direct volume rendering, suffer from rigid transfer function designs and high computational costs. Although novel view synthesis approaches enhance rendering efficiency, they require additional learning effort for non-experts and lack support for semantic-level interaction. To bridge this gap, we propose NLI4VolVis, an interactive system that enables users to explore, query, and edit volumetric scenes using natural language. NLI4VolVis integrates multi-view semantic segmentation and vision-language models to extract and understand semantic components in a scene. We introduce a multi-agent large language model architecture equipped with extensive function-calling tools to interpret user intents and execute visualization tasks. The agents leverage external tools and declarative VolVis commands to interact with the VolVis engine powered by 3D editable Gaussians, enabling open-vocabulary object querying, real-time scene editing, best-view selection, and 2D stylization. We validate our system through case studies and a user study, highlighting its improved accessibility and usability in volumetric data exploration. We strongly recommend readers check our case studies, demo video, and source code at https://nli4volvis.github.io/.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fly, Fail, Fix: Iterative Game Repair with Reinforcement Learning and Large Multimodal Models</title>
<link>https://arxiv.org/abs/2507.12666</link>
<guid>https://arxiv.org/abs/2507.12666</guid>
<content:encoded><![CDATA[
arXiv:2507.12666v1 Announce Type: new 
Abstract: Game design hinges on understanding how static rules and content translate into dynamic player behavior - something modern generative systems that inspect only a game's code or assets struggle to capture. We present an automated design iteration framework that closes this gap by pairing a reinforcement learning (RL) agent, which playtests the game, with a large multimodal model (LMM), which revises the game based on what the agent does. In each loop the RL player completes several episodes, producing (i) numerical play metrics and/or (ii) a compact image strip summarising recent video frames. The LMM designer receives a gameplay goal and the current game configuration, analyses the play traces, and edits the configuration to steer future behaviour toward the goal. We demonstrate results that LMMs can reason over behavioral traces supplied by RL agents to iteratively refine game mechanics, pointing toward practical, scalable tools for AI-assisted game design.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Identification of Authoritative Nodes and Dismantling of Illicit Networks Using a Novel Metric for Measuring Strength of a Graph</title>
<link>https://arxiv.org/abs/2507.12711</link>
<guid>https://arxiv.org/abs/2507.12711</guid>
<content:encoded><![CDATA[
arXiv:2507.12711v1 Announce Type: new 
Abstract: Dismantling criminal networks or containing epidemics or misinformation through node removal is a well-studied problem. To evaluate the effectiveness of such efforts, one must measure the strength of the network before and after node removal. Process P1 is considered more effective than P2 if the strength of the residual network after removing k nodes via P1 is smaller than that from P2. This leads to the central question: How should network strength be measured?
  Existing metrics rely solely on structural properties of the graph, such as connectivity. However, in real-world scenarios, particularly in law enforcement, the perception of agents regarding network strength can differ significantly from structural assessments. These perceptions are often ignored in traditional metrics.
  We propose a new strength metric that integrates both structural properties and human perception. Using human subject surveys, we validate our approach against existing metrics. Our metric not only aligns more closely with human judgment but also outperforms traditional methods in identifying authoritative nodes and effectively dismantling both synthetic and real-world networks.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strategy Adaptation in Large Language Model Werewolf Agents</title>
<link>https://arxiv.org/abs/2507.12732</link>
<guid>https://arxiv.org/abs/2507.12732</guid>
<content:encoded><![CDATA[
arXiv:2507.12732v1 Announce Type: new 
Abstract: This study proposes a method to improve the performance of Werewolf agents by switching between predefined strategies based on the attitudes of other players and the context of conversations. While prior works of Werewolf agents using prompt engineering have employed methods where effective strategies are implicitly defined, they cannot adapt to changing situations. In this research, we propose a method that explicitly selects an appropriate strategy based on the game context and the estimated roles of other players. We compare the strategy adaptation Werewolf agents with baseline agents using implicit or fixed strategies and verify the effectiveness of our proposed method.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competition Erases Simplicity: Tight Regret Bounds for Uniform Pricing with Multiple Buyers</title>
<link>https://arxiv.org/abs/2507.12733</link>
<guid>https://arxiv.org/abs/2507.12733</guid>
<content:encoded><![CDATA[
arXiv:2507.12733v1 Announce Type: new 
Abstract: We study repeated \textsf{Uniform Pricing} mechanisms with multiple buyers. In each round, the platform sets a uniform price for all buyers; a transaction occurs if at least one buyer bids at or above this price. Prior work demonstrates that structural assumptions on bid distributions -- such as regularity or monotone hazard rate (MHR) property -- enable significant improvements in pricing query complexity (from $\Theta\left(\varepsilon^{-3}\right)$ to $\widetilde\Theta\left(\varepsilon^{-2}\right)$\footnote{The $\widetilde \Theta$ notation omits polylogarithmic factors.}) and regret bounds (from $\Theta\left(T^{2/3}\right)$ to $\widetilde\Theta\left(T^{1/2}\right)$) for single-buyer settings. Strikingly, we demonstrate that these improvements vanish with multiple buyers: both general and structured distributions (including regular/MHR) share identical asymptotic performance, achieving pricing query complexity of $\widetilde\Theta\left(\varepsilon^{-3}\right)$ and regret of $\widetilde\Theta\left(T^{2/3}\right)$.
  This result reveals a dichotomy between single-agent and multi-agent environments. While the special structure of distributions simplifies learning for a single buyer, competition among multiple buyers erases these benefits, forcing platforms to adopt universally robust pricing strategies. Our findings challenge conventional wisdom from single-buyer theory and underscore the necessity of revisiting mechanism design principles in more competitive settings.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Public Evaluation on Potential Social Impacts of Fully Autonomous Cybernetic Avatars for Physical Support in Daily-Life Environments: Large-Scale Demonstration and Survey at Avatar Land</title>
<link>https://arxiv.org/abs/2507.12741</link>
<guid>https://arxiv.org/abs/2507.12741</guid>
<content:encoded><![CDATA[
arXiv:2507.12741v1 Announce Type: new 
Abstract: Cybernetic avatars (CAs) are key components of an avatar-symbiotic society, enabling individuals to overcome physical limitations through virtual agents and robotic assistants. While semi-autonomous CAs intermittently require human teleoperation and supervision, the deployment of fully autonomous CAs remains a challenge. This study evaluates public perception and potential social impacts of fully autonomous CAs for physical support in daily life. To this end, we conducted a large-scale demonstration and survey during Avatar Land, a 19-day public event in Osaka, Japan, where fully autonomous robotic CAs, alongside semi-autonomous CAs, performed daily object retrieval tasks. Specifically, we analyzed responses from 2,285 visitors who engaged with various CAs, including a subset of 333 participants who interacted with fully autonomous CAs and shared their perceptions and concerns through a survey questionnaire. The survey results indicate interest in CAs for physical support in daily life and at work. However, concerns were raised regarding task execution reliability. In contrast, cost and human-like interaction were not dominant concerns. Project page: https://lotfielhafi.github.io/FACA-Survey/.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomy for Older Adult-Agent Interaction</title>
<link>https://arxiv.org/abs/2507.12767</link>
<guid>https://arxiv.org/abs/2507.12767</guid>
<content:encoded><![CDATA[
arXiv:2507.12767v1 Announce Type: new 
Abstract: As the global population ages, artificial intelligence (AI)-powered agents have emerged as potential tools to support older adults' caregiving. Prior research has explored agent autonomy by identifying key interaction stages in task processes and defining the agent's role at each stage. However, ensuring that agents align with older adults' autonomy preferences remains a critical challenge. Drawing on interdisciplinary conceptualizations of autonomy, this paper examines four key dimensions of autonomy for older adults: decision-making autonomy, goal-oriented autonomy, control autonomy, and social responsibility autonomy. This paper then proposes the following research directions: (1) Addressing social responsibility autonomy, which concerns the ethical and social implications of agent use in communal settings; (2) Operationalizing agent autonomy from the task perspective; and (3) Developing autonomy measures.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Electronic Health Record Modeling: From Deep Learning Approaches to Large Language Models</title>
<link>https://arxiv.org/abs/2507.12774</link>
<guid>https://arxiv.org/abs/2507.12774</guid>
<content:encoded><![CDATA[
arXiv:2507.12774v1 Announce Type: new 
Abstract: Artificial intelligence (AI) has demonstrated significant potential in transforming healthcare through the analysis and modeling of electronic health records (EHRs). However, the inherent heterogeneity, temporal irregularity, and domain-specific nature of EHR data present unique challenges that differ fundamentally from those in vision and natural language tasks. This survey offers a comprehensive overview of recent advancements at the intersection of deep learning, large language models (LLMs), and EHR modeling. We introduce a unified taxonomy that spans five key design dimensions: data-centric approaches, neural architecture design, learning-focused strategies, multimodal learning, and LLM-based modeling systems. Within each dimension, we review representative methods addressing data quality enhancement, structural and temporal representation, self-supervised learning, and integration with clinical knowledge. We further highlight emerging trends such as foundation models, LLM-driven clinical agents, and EHR-to-text translation for downstream reasoning. Finally, we discuss open challenges in benchmarking, explainability, clinical alignment, and generalization across diverse clinical settings. This survey aims to provide a structured roadmap for advancing AI-driven EHR modeling and clinical decision support. For a comprehensive list of EHR-related methods, kindly refer to https://survey-on-tabular-data.github.io/.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>City-VLM: Towards Multidomain Perception Scene Understanding via Multimodal Incomplete Learning</title>
<link>https://arxiv.org/abs/2507.12795</link>
<guid>https://arxiv.org/abs/2507.12795</guid>
<content:encoded><![CDATA[
arXiv:2507.12795v1 Announce Type: new 
Abstract: Scene understanding enables intelligent agents to interpret and comprehend their environment. While existing large vision-language models (LVLMs) for scene understanding have primarily focused on indoor household tasks, they face two significant limitations when applied to outdoor large-scale scene understanding. First, outdoor scenarios typically encompass larger-scale environments observed through various sensors from multiple viewpoints (e.g., bird view and terrestrial view), while existing indoor LVLMs mainly analyze single visual modalities within building-scale contexts from humanoid viewpoints. Second, existing LVLMs suffer from missing multidomain perception outdoor data and struggle to effectively integrate 2D and 3D visual information. To address the aforementioned limitations, we build the first multidomain perception outdoor scene understanding dataset, named \textbf{\underline{SVM-City}}, deriving from multi\textbf{\underline{S}}cale scenarios with multi\textbf{\underline{V}}iew and multi\textbf{\underline{M}}odal instruction tuning data. It contains $420$k images and $4, 811$M point clouds with $567$k question-answering pairs from vehicles, low-altitude drones, high-altitude aerial planes, and satellite. To effectively fuse the multimodal data in the absence of one modality, we introduce incomplete multimodal learning to model outdoor scene understanding and design the LVLM named \textbf{\underline{City-VLM}}. Multimodal fusion is realized by constructing a joint probabilistic distribution space rather than implementing directly explicit fusion operations (e.g., concatenation). Experimental results on three typical outdoor scene understanding tasks show City-VLM achieves $18.14 \%$ performance surpassing existing LVLMs in question-answering tasks averagely. Our method demonstrates pragmatic and generalization performance across multiple outdoor scenes.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MCPEval: Automatic MCP-based Deep Evaluation for AI Agent Models</title>
<link>https://arxiv.org/abs/2507.12806</link>
<guid>https://arxiv.org/abs/2507.12806</guid>
<content:encoded><![CDATA[
arXiv:2507.12806v1 Announce Type: new 
Abstract: The rapid rise of Large Language Models (LLMs)-based intelligent agents underscores the need for robust, scalable evaluation frameworks. Existing methods rely on static benchmarks and labor-intensive data collection, limiting practical assessment. We introduce \oursystemname, an open-source Model Context Protocol (MCP)-based framework that automates end-to-end task generation and deep evaluation of LLM agents across diverse domains. MCPEval standardizes metrics, seamlessly integrates with native agent tools, and eliminates manual effort in building evaluation pipelines. Empirical results across five real-world domains show its effectiveness in revealing nuanced, domain-specific performance. We publicly release MCPEval https://github.com/SalesforceAIResearch/MCPEval to promote reproducible and standardized LLM agent evaluation.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Novelty to Imitation: Self-Distilled Rewards for Offline Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.12815</link>
<guid>https://arxiv.org/abs/2507.12815</guid>
<content:encoded><![CDATA[
arXiv:2507.12815v1 Announce Type: new 
Abstract: Offline Reinforcement Learning (RL) aims to learn effective policies from a static dataset without requiring further agent-environment interactions. However, its practical adoption is often hindered by the need for explicit reward annotations, which can be costly to engineer or difficult to obtain retrospectively. To address this, we propose ReLOAD (Reinforcement Learning with Offline Reward Annotation via Distillation), a novel reward annotation framework for offline RL. Unlike existing methods that depend on complex alignment procedures, our approach adapts Random Network Distillation (RND) to generate intrinsic rewards from expert demonstrations using a simple yet effective embedding discrepancy measure. First, we train a predictor network to mimic a fixed target network's embeddings based on expert state transitions. Later, the prediction error between these networks serves as a reward signal for each transition in the static dataset. This mechanism provides a structured reward signal without requiring handcrafted reward annotations. We provide a formal theoretical construct that offers insights into how RND prediction errors effectively serve as intrinsic rewards by distinguishing expert-like transitions. Experiments on the D4RL benchmark demonstrate that ReLOAD enables robust offline policy learning and achieves performance competitive with traditional reward-annotated methods.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assessing adaptive world models in machines with novel games</title>
<link>https://arxiv.org/abs/2507.12821</link>
<guid>https://arxiv.org/abs/2507.12821</guid>
<content:encoded><![CDATA[
arXiv:2507.12821v1 Announce Type: new 
Abstract: Human intelligence exhibits a remarkable capacity for rapid adaptation and effective problem-solving in novel and unfamiliar contexts. We argue that this profound adaptability is fundamentally linked to the efficient construction and refinement of internal representations of the environment, commonly referred to as world models, and we refer to this adaptation mechanism as world model induction. However, current understanding and evaluation of world models in artificial intelligence (AI) remains narrow, often focusing on static representations learned from training on a massive corpora of data, instead of the efficiency and efficacy of models in learning these representations through interaction and exploration within a novel environment. In this Perspective, we provide a view of world model induction drawing on decades of research in cognitive science on how humans learn and adapt so efficiently; we then call for a new evaluation framework for assessing adaptive world models in AI. Concretely, we propose a new benchmarking paradigm based on suites of carefully designed games with genuine, deep and continually refreshing novelty in the underlying game structures -- we refer to this kind of games as novel games. We detail key desiderata for constructing these games and propose appropriate metrics to explicitly challenge and evaluate the agent's ability for rapid world model induction. We hope that this new evaluation framework will inspire future evaluation efforts on world models in AI and provide a crucial step towards developing AI systems capable of the human-like rapid adaptation and robust generalization -- a critical component of artificial general intelligence.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Machine-Readable Ads: Accessibility and Trust Patterns for AI Web Agents interacting with Online Advertisements</title>
<link>https://arxiv.org/abs/2507.12844</link>
<guid>https://arxiv.org/abs/2507.12844</guid>
<content:encoded><![CDATA[
arXiv:2507.12844v1 Announce Type: new 
Abstract: Autonomous multimodal language models are rapidly evolving into web agents that can browse, click, and purchase items on behalf of users, posing a threat to display advertising designed for human eyes. Yet little is known about how these agents interact with ads or which design principles ensure reliable engagement. To address this, we ran a controlled experiment using a faithful clone of the news site TT.com, seeded with diverse ads: static banners, GIFs, carousels, videos, cookie dialogues, and paywalls. We ran 300 initial trials plus follow-ups using the Document Object Model (DOM)-centric Browser Use framework with GPT-4o, Claude 3.7 Sonnet, Gemini 2.0 Flash, and the pixel-based OpenAI Operator, across 10 realistic user tasks. Our results show these agents display severe satisficing: they never scroll beyond two viewports and ignore purely visual calls to action, clicking banners only when semantic button overlays or off-screen text labels are present. Critically, when sweepstake participation required a purchase, GPT-4o and Claude 3.7 Sonnet subscribed in 100% of trials, and Gemini 2.0 Flash in 70%, revealing gaps in cost-benefit analysis. We identified five actionable design principles-semantic overlays, hidden labels, top-left placement, static frames, and dialogue replacement, that make human-centric creatives machine-detectable without harming user experience. We also evaluated agent trustworthiness through "behavior patterns" such as cookie consent handling and subscription choices, highlighting model-specific risk boundaries and the urgent need for robust trust evaluation frameworks in real-world advertising.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enter the Mind Palace: Reasoning and Planning for Long-term Active Embodied Question Answering</title>
<link>https://arxiv.org/abs/2507.12846</link>
<guid>https://arxiv.org/abs/2507.12846</guid>
<content:encoded><![CDATA[
arXiv:2507.12846v1 Announce Type: new 
Abstract: As robots become increasingly capable of operating over extended periods -- spanning days, weeks, and even months -- they are expected to accumulate knowledge of their environments and leverage this experience to assist humans more effectively. This paper studies the problem of Long-term Active Embodied Question Answering (LA-EQA), a new task in which a robot must both recall past experiences and actively explore its environment to answer complex, temporally-grounded questions. Unlike traditional EQA settings, which typically focus either on understanding the present environment alone or on recalling a single past observation, LA-EQA challenges an agent to reason over past, present, and possible future states, deciding when to explore, when to consult its memory, and when to stop gathering observations and provide a final answer. Standard EQA approaches based on large models struggle in this setting due to limited context windows, absence of persistent memory, and an inability to combine memory recall with active exploration. To address this, we propose a structured memory system for robots, inspired by the mind palace method from cognitive science. Our method encodes episodic experiences as scene-graph-based world instances, forming a reasoning and planning algorithm that enables targeted memory retrieval and guided navigation. To balance the exploration-recall trade-off, we introduce value-of-information-based stopping criteria that determines when the agent has gathered sufficient information. We evaluate our method on real-world experiments and introduce a new benchmark that spans popular simulation environments and actual industrial sites. Our approach significantly outperforms state-of-the-art baselines, yielding substantial gains in both answer accuracy and exploration efficiency.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Information-Theoretic Aggregation of Ethical Attributes in Simulated-Command</title>
<link>https://arxiv.org/abs/2507.12862</link>
<guid>https://arxiv.org/abs/2507.12862</guid>
<content:encoded><![CDATA[
arXiv:2507.12862v1 Announce Type: new 
Abstract: In the age of AI, human commanders need to use the computational powers available in today's environment to simulate a very large number of scenarios. Within each scenario, situations occur where different decision design options could have ethical consequences. Making these decisions reliant on human judgement is both counter-productive to the aim of exploring very large number of scenarios in a timely manner and infeasible when considering the workload needed to involve humans in each of these choices. In this paper, we move human judgement outside the simulation decision cycle. Basically, the human will design the ethical metric space, leaving it to the simulated environment to explore the space. When the simulation completes its testing cycles, the testing environment will come back to the human commander with a few options to select from. The human commander will then exercise human-judgement to select the most appropriate course of action, which will then get executed accordingly. We assume that the problem of designing metrics that are sufficiently granular to assess the ethical implications of decisions is solved. Subsequently, the fundamental problem we look at in this paper is how to weight ethical decisions during the running of these simulations; that is, how to dynamically weight the ethical attributes when agents are faced with decision options with ethical implications during generative simulations. The multi-criteria decision making literature has started to look at nearby problems, where the concept of entropy has been used to determine the weights during aggregation. We draw from that literature different approaches to automatically calculate the weights for ethical attributes during simulation-based testing and evaluation.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Resource Management in Microservice Systems via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.12879</link>
<guid>https://arxiv.org/abs/2507.12879</guid>
<content:encoded><![CDATA[
arXiv:2507.12879v1 Announce Type: new 
Abstract: This paper proposes a reinforcement learning-based method for microservice resource scheduling and optimization, aiming to address issues such as uneven resource allocation, high latency, and insufficient throughput in traditional microservice architectures. In microservice systems, as the number of services and the load increase, efficiently scheduling and allocating resources such as computing power, memory, and storage becomes a critical research challenge. To address this, the paper employs an intelligent scheduling algorithm based on reinforcement learning. Through the interaction between the agent and the environment, the resource allocation strategy is continuously optimized. In the experiments, the paper considers different resource conditions and load scenarios, evaluating the proposed method across multiple dimensions, including response time, throughput, resource utilization, and cost efficiency. The experimental results show that the reinforcement learning-based scheduling method significantly improves system response speed and throughput under low load and high concurrency conditions, while also optimizing resource utilization and reducing energy consumption. Under multi-dimensional resource conditions, the proposed method can consider multiple objectives and achieve optimized resource scheduling. Compared to traditional static resource allocation methods, the reinforcement learning model demonstrates stronger adaptability and optimization capability. It can adjust resource allocation strategies in real time, thereby maintaining good system performance in dynamically changing load and resource environments.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LaViPlan : Language-Guided Visual Path Planning with RLVR</title>
<link>https://arxiv.org/abs/2507.12911</link>
<guid>https://arxiv.org/abs/2507.12911</guid>
<content:encoded><![CDATA[
arXiv:2507.12911v1 Announce Type: new 
Abstract: Out-of-distribution (OOD) scenarios in autonomous driving refer to situations that deviate from the training domain, often leading to unexpected and potentially hazardous behavior from planners that lack prior exposure to such cases. Recently, Vision-Language Models (VLMs) have been introduced into autonomous driving research for their promising generalization capabilities in OOD settings. Early studies demonstrated that VLMs could recognize OOD scenarios and generate user-level decisions such as "go straight" or "turn right." However, a new challenge has emerged due to the misalignment between the VLM's high-level decisions or visual reasoning expressed in language, and the low-level predicted trajectories interpreted as actions. In this paper, we propose LaViPlan, a framework that leverages Reinforcement Learning with Verifiable Rewards (RLVR) to optimize VLMs using planning-oriented metrics. This approach addresses the vision-language-action misalignment observed in existing VLMs fine-tuned via supervised learning, which can recognize driving scenarios but often produce context-unaware decisions. Experimental results demonstrate that our method improves situational awareness and decision-making under OOD conditions, highlighting its potential to mitigate the misalignment issue. This work introduces a promising post-training paradigm for VLM agents in the context of autonomous driving.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Non-differentiable Reward Optimization for Diffusion-based Autonomous Motion Planning</title>
<link>https://arxiv.org/abs/2507.12977</link>
<guid>https://arxiv.org/abs/2507.12977</guid>
<content:encoded><![CDATA[
arXiv:2507.12977v1 Announce Type: new 
Abstract: Safe and effective motion planning is crucial for autonomous robots. Diffusion models excel at capturing complex agent interactions, a fundamental aspect of decision-making in dynamic environments. Recent studies have successfully applied diffusion models to motion planning, demonstrating their competence in handling complex scenarios and accurately predicting multi-modal future trajectories. Despite their effectiveness, diffusion models have limitations in training objectives, as they approximate data distributions rather than explicitly capturing the underlying decision-making dynamics. However, the crux of motion planning lies in non-differentiable downstream objectives, such as safety (collision avoidance) and effectiveness (goal-reaching), which conventional learning algorithms cannot directly optimize. In this paper, we propose a reinforcement learning-based training scheme for diffusion motion planning models, enabling them to effectively learn non-differentiable objectives that explicitly measure safety and effectiveness. Specifically, we introduce a reward-weighted dynamic thresholding algorithm to shape a dense reward signal, facilitating more effective training and outperforming models trained with differentiable objectives. State-of-the-art performance on pedestrian datasets (CrowdNav, ETH-UCY) compared to various baselines demonstrates the versatility of our approach for safe and effective motion planning.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lower Bound for Online MMS Assignment of Indivisible Chores</title>
<link>https://arxiv.org/abs/2507.12984</link>
<guid>https://arxiv.org/abs/2507.12984</guid>
<content:encoded><![CDATA[
arXiv:2507.12984v1 Announce Type: new 
Abstract: We consider the problem of online assignment of indivisible chores under \MMS\ criteria. The previous work proves that any deterministic online algorithm for chore division has a competitive ratio of at least 2. In this work, we improve this bound by showing that no deterministic online algorithm can obtain a competitive ratio better than $n$ for $n$ agents.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAD-Spear: A Conformity-Driven Prompt Injection Attack on Multi-Agent Debate Systems</title>
<link>https://arxiv.org/abs/2507.13038</link>
<guid>https://arxiv.org/abs/2507.13038</guid>
<content:encoded><![CDATA[
arXiv:2507.13038v1 Announce Type: new 
Abstract: Multi-agent debate (MAD) systems leverage collaborative interactions among large language models (LLMs) agents to improve reasoning capabilities. While recent studies have focused on increasing the accuracy and scalability of MAD systems, their security vulnerabilities have received limited attention. In this work, we introduce MAD-Spear, a targeted prompt injection attack that compromises a small subset of agents but significantly disrupts the overall MAD process. Manipulated agents produce multiple plausible yet incorrect responses, exploiting LLMs' conformity tendencies to propagate misinformation and degrade consensus quality. Furthermore, the attack can be composed with other strategies, such as communication attacks, to further amplify its impact by increasing the exposure of agents to incorrect responses. To assess MAD's resilience under attack, we propose a formal definition of MAD fault-tolerance and develop a comprehensive evaluation framework that jointly considers accuracy, consensus efficiency, and scalability. Extensive experiments on five benchmark datasets with varying difficulty levels demonstrate that MAD-Spear consistently outperforms the baseline attack in degrading system performance. Additionally, we observe that agent diversity substantially improves MAD performance in mathematical reasoning tasks, which challenges prior work suggesting that agent diversity has minimal impact on performance. These findings highlight the urgent need to improve the security in MAD design.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>What Can Robots Teach Us About Trust and Reliance? An interdisciplinary dialogue between Social Sciences and Social Robotics</title>
<link>https://arxiv.org/abs/2507.13041</link>
<guid>https://arxiv.org/abs/2507.13041</guid>
<content:encoded><![CDATA[
arXiv:2507.13041v1 Announce Type: new 
Abstract: As robots find their way into more and more aspects of everyday life, questions around trust are becoming increasingly important. What does it mean to trust a robot? And how should we think about trust in relationships that involve both humans and non-human agents? While the field of Human-Robot Interaction (HRI) has made trust a central topic, the concept is often approached in fragmented ways. At the same time, established work in sociology, where trust has long been a key theme, is rarely brought into conversation with developments in robotics. This article argues that we need a more interdisciplinary approach. By drawing on insights from both social sciences and social robotics, we explore how trust is shaped, tested and made visible. Our goal is to open up a dialogue between disciplines and help build a more grounded and adaptable framework for understanding trust in the evolving world of human-robot interaction.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Intelligent Virtual Sonographer (IVS): Enhancing Physician-Robot-Patient Communication</title>
<link>https://arxiv.org/abs/2507.13052</link>
<guid>https://arxiv.org/abs/2507.13052</guid>
<content:encoded><![CDATA[
arXiv:2507.13052v1 Announce Type: new 
Abstract: The advancement and maturity of large language models (LLMs) and robotics have unlocked vast potential for human-computer interaction, particularly in the field of robotic ultrasound. While existing research primarily focuses on either patient-robot or physician-robot interaction, the role of an intelligent virtual sonographer (IVS) bridging physician-robot-patient communication remains underexplored. This work introduces a conversational virtual agent in Extended Reality (XR) that facilitates real-time interaction between physicians, a robotic ultrasound system(RUS), and patients. The IVS agent communicates with physicians in a professional manner while offering empathetic explanations and reassurance to patients. Furthermore, it actively controls the RUS by executing physician commands and transparently relays these actions to the patient. By integrating LLM-powered dialogue with speech-to-text, text-to-speech, and robotic control, our system enhances the efficiency, clarity, and accessibility of robotic ultrasound acquisition. This work constitutes a first step toward understanding how IVS can bridge communication gaps in physician-robot-patient interaction, providing more control and therefore trust into physician-robot interaction while improving patient experience and acceptance of robotic ultrasound.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>iReDev: A Knowledge-Driven Multi-Agent Framework for Intelligent Requirements Development</title>
<link>https://arxiv.org/abs/2507.13081</link>
<guid>https://arxiv.org/abs/2507.13081</guid>
<content:encoded><![CDATA[
arXiv:2507.13081v1 Announce Type: new 
Abstract: Requirements development is a critical phase as it is responsible for providing a clear understanding of what stakeholders need. It involves collaboration among stakeholders to extract explicit requirements and address potential conflicts, which is time-consuming and labor-intensive. Recently, multi-agent systems for software development have attracted much attention. However, existing research provides limited support for requirements development and overlooks the injection of human knowledge into agents and the human-agent collaboration. % To address these issues, this paper proposes a knowledge-driven multi-agent framework for intelligent requirement development, named iReDev. iReDev features: iReDev consists of six knowledge-driven agents to support the entire requirements development. They collaboratively perform various tasks to produce a software requirements specification. iReDev focuses on integrating human knowledge for agents, enabling them to simulate real-world stakeholders. iReDev uses an event-driven communication mechanism based on an artifact pool. Agents continuously monitor the pool and autonomously trigger the next action based on its changes, enabling iReDev to handle new requirements quickly. iReDev introduces a human-in-the-loop mechanism to support human-agent collaboration, ensuring that the generated artifacts align with the expectations of stakeholders. We evaluated the generated artifacts and results show that iReDev outperforms existing baselines in multiple aspects. We further envision three key directions and hope this work can facilitate the development of intelligent requirements development.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RIDAS: A Multi-Agent Framework for AI-RAN with Representation- and Intention-Driven Agents</title>
<link>https://arxiv.org/abs/2507.13140</link>
<guid>https://arxiv.org/abs/2507.13140</guid>
<content:encoded><![CDATA[
arXiv:2507.13140v1 Announce Type: new 
Abstract: Sixth generation (6G) networks demand tight integration of artificial intelligence (AI) into radio access networks (RANs) to meet stringent quality of service (QoS) and resource efficiency requirements. Existing solutions struggle to bridge the gap between high level user intents and the low level, parameterized configurations required for optimal performance. To address this challenge, we propose RIDAS, a multi agent framework composed of representation driven agents (RDAs) and an intention driven agent (IDA). RDAs expose open interface with tunable control parameters (rank and quantization bits, enabling explicit trade) offs between distortion and transmission rate. The IDA employs a two stage planning scheme (bandwidth pre allocation and reallocation) driven by a large language model (LLM) to map user intents and system state into optimal RDA configurations. Experiments demonstrate that RIDAS supports 44.71\% more users than WirelessAgent under equivalent QoS constraints. These results validate ability of RIDAS to capture user intent and allocate resources more efficiently in AI RAN environments.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SE-VLN: A Self-Evolving Vision-Language Navigation Framework Based on Multimodal Large Language Models</title>
<link>https://arxiv.org/abs/2507.13152</link>
<guid>https://arxiv.org/abs/2507.13152</guid>
<content:encoded><![CDATA[
arXiv:2507.13152v1 Announce Type: new 
Abstract: Recent advances in vision-language navigation (VLN) were mainly attributed to emerging large language models (LLMs). These methods exhibited excellent generalization capabilities in instruction understanding and task reasoning. However, they were constrained by the fixed knowledge bases and reasoning abilities of LLMs, preventing fully incorporating experiential knowledge and thus resulting in a lack of efficient evolutionary capacity. To address this, we drew inspiration from the evolution capabilities of natural agents, and proposed a self-evolving VLN framework (SE-VLN) to endow VLN agents with the ability to continuously evolve during testing. To the best of our knowledge, it was the first time that an multimodal LLM-powered self-evolving VLN framework was proposed. Specifically, SE-VLN comprised three core modules, i.e., a hierarchical memory module to transfer successful and failure cases into reusable knowledge, a retrieval-augmented thought-based reasoning module to retrieve experience and enable multi-step decision-making, and a reflection module to realize continual evolution. Comprehensive tests illustrated that the SE-VLN achieved navigation success rates of 57% and 35.2% in unseen environments, representing absolute performance improvements of 23.9% and 15.0% over current state-of-the-art methods on R2R and REVERSE datasets, respectively. Moreover, the SE-VLN showed performance improvement with increasing experience repository, elucidating its great potential as a self-evolving agent framework for VLN.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompt Injection 2.0: Hybrid AI Threats</title>
<link>https://arxiv.org/abs/2507.13169</link>
<guid>https://arxiv.org/abs/2507.13169</guid>
<content:encoded><![CDATA[
arXiv:2507.13169v1 Announce Type: new 
Abstract: Prompt injection attacks, where malicious input is designed to manipulate AI systems into ignoring their original instructions and following unauthorized commands instead, were first discovered by Preamble, Inc. in May 2022 and responsibly disclosed to OpenAI. Over the last three years, these attacks have continued to pose a critical security threat to LLM-integrated systems. The emergence of agentic AI systems, where LLMs autonomously perform multistep tasks through tools and coordination with other agents, has fundamentally transformed the threat landscape. Modern prompt injection attacks can now combine with traditional cybersecurity exploits to create hybrid threats that systematically evade traditional security controls. This paper presents a comprehensive analysis of Prompt Injection 2.0, examining how prompt injections integrate with Cross-Site Scripting (XSS), Cross-Site Request Forgery (CSRF), and other web security vulnerabilities to bypass traditional security measures. We build upon Preamble's foundational research and mitigation technologies, evaluating them against contemporary threats, including AI worms, multi-agent infections, and hybrid cyber-AI attacks. Our analysis incorporates recent benchmarks that demonstrate how traditional web application firewalls, XSS filters, and CSRF tokens fail against AI-enhanced attacks. We also present architectural solutions that combine prompt isolation, runtime security, and privilege separation with novel threat detection capabilities.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aligning Humans and Robots via Reinforcement Learning from Implicit Human Feedback</title>
<link>https://arxiv.org/abs/2507.13171</link>
<guid>https://arxiv.org/abs/2507.13171</guid>
<content:encoded><![CDATA[
arXiv:2507.13171v1 Announce Type: new 
Abstract: Conventional reinforcement learning (RL) ap proaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, rein forcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, en abling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Black Box Deployed -- Functional Criteria for Artificial Moral Agents in the LLM Era</title>
<link>https://arxiv.org/abs/2507.13175</link>
<guid>https://arxiv.org/abs/2507.13175</guid>
<content:encoded><![CDATA[
arXiv:2507.13175v1 Announce Type: new 
Abstract: The advancement of powerful yet opaque large language models (LLMs) necessitates a fundamental revision of the philosophical criteria used to evaluate artificial moral agents (AMAs). Pre-LLM frameworks often relied on the assumption of transparent architectures, which LLMs defy due to their stochastic outputs and opaque internal states. This paper argues that traditional ethical criteria are pragmatically obsolete for LLMs due to this mismatch. Engaging with core themes in the philosophy of technology, this paper proffers a revised set of ten functional criteria to evaluate LLM-based artificial moral agents: moral concordance, context sensitivity, normative integrity, metaethical awareness, system resilience, trustworthiness, corrigibility, partial transparency, functional autonomy, and moral imagination. These guideposts, applied to what we term "SMA-LLS" (Simulating Moral Agency through Large Language Systems), aim to steer AMAs toward greater alignment and beneficial societal integration in the coming years. We illustrate these criteria using hypothetical scenarios involving an autonomous public bus (APB) to demonstrate their practical applicability in morally salient contexts.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GEMMAS: Graph-based Evaluation Metrics for Multi Agent Systems</title>
<link>https://arxiv.org/abs/2507.13190</link>
<guid>https://arxiv.org/abs/2507.13190</guid>
<content:encoded><![CDATA[
arXiv:2507.13190v1 Announce Type: new 
Abstract: Multi-agent systems built on language models have shown strong performance on collaborative reasoning tasks. However, existing evaluations focus only on the correctness of the final output, overlooking how inefficient communication and poor coordination contribute to redundant reasoning and higher computational costs. We introduce GEMMAS, a graph-based evaluation framework that analyzes the internal collaboration process by modeling agent interactions as a directed acyclic graph. To capture collaboration quality, we propose two process-level metrics: Information Diversity Score (IDS) to measure semantic variation in inter-agent messages, and Unnecessary Path Ratio (UPR) to quantify redundant reasoning paths. We evaluate GEMMAS across five benchmarks and highlight results on GSM8K, where systems with only a 2.1% difference in accuracy differ by 12.8% in IDS and 80% in UPR, revealing substantial variation in internal collaboration. These findings demonstrate that outcome-only metrics are insufficient for evaluating multi-agent performance and highlight the importance of process-level diagnostics in designing more interpretable and resource-efficient collaborative AI systems.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RemVerse: Supporting Reminiscence Activities for Older Adults through AI-Assisted Virtual Reality</title>
<link>https://arxiv.org/abs/2507.13247</link>
<guid>https://arxiv.org/abs/2507.13247</guid>
<content:encoded><![CDATA[
arXiv:2507.13247v1 Announce Type: new 
Abstract: Reminiscence activities, which involve recalling and sharing past experiences, have proven beneficial for improving cognitive function, mood, and overall well-being. However, urbanization has led to the disappearance of familiar environments, removing visual and audio cues for effective reminiscence. While old photos can serve as visual cues to aid reminiscence, it is challenging for people to reconstruct the reminisced content and environment that are not in the photos. Virtual reality (VR) and artificial intelligence (AI) offer the ability to reconstruct an immersive environment with dynamic content and to converse with people to help them gradually reminisce. We designed RemVerse, an AI-empowered VR prototype aimed to support reminiscence activities. Integrating generative models and AI agent into a VR environment, RemVerse helps older adults reminisce with AI-generated visual cues and interactive dialogues. Our user study with 14 older adults showed that RemVerse effectively supported reminiscence activities by triggering, concretizing, and deepening personal memories, while fostering increased engagement and autonomy among older adults. Based on our findings, we proposed design implications to make reminiscence activities in AI-assisted VR more accessible and engaging for older adults.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Context Engineering for Large Language Models</title>
<link>https://arxiv.org/abs/2507.13334</link>
<guid>https://arxiv.org/abs/2507.13334</guid>
<content:encoded><![CDATA[
arXiv:2507.13334v1 Announce Type: new 
Abstract: The performance of Large Language Models (LLMs) is fundamentally determined by the contextual information provided during inference. This survey introduces Context Engineering, a formal discipline that transcends simple prompt design to encompass the systematic optimization of information payloads for LLMs. We present a comprehensive taxonomy decomposing Context Engineering into its foundational components and the sophisticated implementations that integrate them into intelligent systems. We first examine the foundational components: context retrieval and generation, context processing and context management. We then explore how these components are architecturally integrated to create sophisticated system implementations: retrieval-augmented generation (RAG), memory systems and tool-integrated reasoning, and multi-agent systems. Through this systematic analysis of over 1300 research papers, our survey not only establishes a technical roadmap for the field but also reveals a critical research gap: a fundamental asymmetry exists between model capabilities. While current models, augmented by advanced context engineering, demonstrate remarkable proficiency in understanding complex contexts, they exhibit pronounced limitations in generating equally sophisticated, long-form outputs. Addressing this gap is a defining priority for future research. Ultimately, this survey provides a unified framework for both researchers and engineers advancing context-aware AI.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coarse Addition and the St. Petersburg Paradox: A Heuristic Perspective</title>
<link>https://arxiv.org/abs/2507.12475</link>
<guid>https://arxiv.org/abs/2507.12475</guid>
<content:encoded><![CDATA[
arXiv:2507.12475v1 Announce Type: cross 
Abstract: The St. Petersburg paradox presents a longstanding challenge in decision theory. It describes a game whose expected value is infinite, yet for which no rational finite stake can be determined. Traditional solutions introduce auxiliary assumptions, such as diminishing marginal utility, temporal discounting, or extended number systems. These methods often involve mathematical refinements that may not correspond to how people actually perceive or process numerical information. This paper explores an alternative approach based on a modified operation of addition defined over coarse partitions of the outcome space. In this model, exact numerical values are grouped into perceptual categories, and each value is replaced by a representative element of its group before being added. This method allows for a phenomenon where repeated additions eventually cease to affect the outcome, a behavior described as inertial stabilization. Although this is not intended as a definitive resolution of the paradox, the proposed framework offers a plausible way to represent how agents with limited cognitive precision might handle divergent reward structures. We demonstrate that the St. Petersburg series can become inert under this coarse addition for a suitably constructed partition. The approach may also have broader applications in behavioral modeling and the study of machine reasoning under perceptual limitations.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pathology-Guided Virtual Staining Metric for Evaluation and Training</title>
<link>https://arxiv.org/abs/2507.12624</link>
<guid>https://arxiv.org/abs/2507.12624</guid>
<content:encoded><![CDATA[
arXiv:2507.12624v1 Announce Type: cross 
Abstract: Virtual staining has emerged as a powerful alternative to traditional histopathological staining techniques, enabling rapid, reagent-free image transformations. However, existing evaluation methods predominantly rely on full-reference image quality assessment (FR-IQA) metrics such as structural similarity, which are originally designed for natural images and often fail to capture pathology-relevant features. Expert pathology reviews have also been used, but they are inherently subjective and time-consuming.
  In this study, we introduce PaPIS (Pathology-Aware Perceptual Image Similarity), a novel FR-IQA metric specifically tailored for virtual staining evaluation. PaPIS leverages deep learning-based features trained on cell morphology segmentation and incorporates Retinex-inspired feature decomposition to better reflect histological perceptual quality. Comparative experiments demonstrate that PaPIS more accurately aligns with pathology-relevant visual cues and distinguishes subtle cellular structures that traditional and existing perceptual metrics tend to overlook. Furthermore, integrating PaPIS as a guiding loss function in a virtual staining model leads to improved histological fidelity.
  This work highlights the critical need for pathology-aware evaluation frameworks to advance the development and clinical readiness of virtual staining technologies.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>N Bugs on a Circle</title>
<link>https://arxiv.org/abs/2507.13333</link>
<guid>https://arxiv.org/abs/2507.13333</guid>
<content:encoded><![CDATA[
arXiv:2507.13333v1 Announce Type: cross 
Abstract: We describe and analyze a generalization of the classic ``Four Bugs on a Square'' cyclic pursuit problem. Instead of allowing the bugs to spiral towards one another, we constrain $N$ bugs to the perimeter of the unit circle. Depending on their configuration, each bug moves either clockwise or counterclockwise with a constant angular speed, or remains stationary. Unlike the original problem where bugs always coalesce, this generalization produces three possible steady states: all bugs coalescing to a single point, clusters of bugs located at two antipodal points, or bugs entering a stable infinite chase cycle where they never meet. We analyze the stability of these steady states and calculate the probability that randomly initialized bugs reach each state. For $N \leq 4$, we derive exact analytical expressions for these probabilities. For larger values, we employ Monte Carlo simulations to estimate the probability of coalescing, finding it approximately follows an inverse square root relationship with the number of bugs. This generalization reveals rich dynamical behaviors that are absent in the classic problem. Our analysis provides insight into how restricting the bugs to the circle's perimeter fundamentally alters the long-term behavior of pursuing agents compared to unrestricted pursuit problems.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IOPO: Empowering LLMs with Complex Instruction Following via Input-Output Preference Optimization</title>
<link>https://arxiv.org/abs/2411.06208</link>
<guid>https://arxiv.org/abs/2411.06208</guid>
<content:encoded><![CDATA[
arXiv:2411.06208v3 Announce Type: replace 
Abstract: In the realm of large language models (LLMs), the ability of models to accurately follow instructions is paramount as more agents and applications leverage LLMs for construction, where the complexity of instructions are rapidly increasing. However, on the one hand, there is only a certain amount of complex instruction evaluation data; on the other hand, there are no dedicated algorithms to improve the ability to follow complex instructions. To this end, this paper introduces TRACE, a benchmark for improving and evaluating the complex instructionfollowing ability, which consists of 120K training data and 1K evaluation data. Furthermore, we propose IOPO (Input-Output Preference Optimization) alignment method which takes both input and output preference pairs into consideration, where LLMs not only rapidly align with response preferences but also meticulously explore the instruction preferences. Extensive experiments on both in-domain and outof-domain datasets confirm the effectiveness of IOPO, showing 8.15%, 2.18% improvements on in-domain data and 6.29%, 3.13% on outof-domain data compared to SFT and DPO respectively.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Linear Speedup of Personalized Federated Reinforcement Learning with Shared Representations</title>
<link>https://arxiv.org/abs/2411.15014</link>
<guid>https://arxiv.org/abs/2411.15014</guid>
<content:encoded><![CDATA[
arXiv:2411.15014v2 Announce Type: replace 
Abstract: Federated reinforcement learning (FedRL) enables multiple agents to collaboratively learn a policy without sharing their local trajectories collected during agent-environment interactions. However, in practice, the environments faced by different agents are often heterogeneous, leading to poor performance by the single policy learned by existing FedRL algorithms on individual agents. In this paper, we take a further step and introduce a \emph{personalized} FedRL framework (PFedRL) by taking advantage of possibly shared common structure among agents in heterogeneous environments. Specifically, we develop a class of PFedRL algorithms named PFedRL-Rep that learns (1) a shared feature representation collaboratively among all agents, and (2) an agent-specific weight vector personalized to its local environment. We analyze the convergence of PFedTD-Rep, a particular instance of the framework with temporal difference (TD) learning and linear representations. To the best of our knowledge, we are the first to prove a linear convergence speedup with respect to the number of agents in the PFedRL setting. To achieve this, we show that PFedTD-Rep is an example of the federated two-timescale stochastic approximation with Markovian noise. Experimental results demonstrate that PFedTD-Rep, along with an extension to the control setting based on deep Q-networks (DQN), not only improve learning in heterogeneous settings, but also provide better generalization to new environments.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safety-Critical Human-Machine Shared Driving for Vehicle Collision Avoidance based on Hamilton-Jacobi reachability</title>
<link>https://arxiv.org/abs/2502.10610</link>
<guid>https://arxiv.org/abs/2502.10610</guid>
<content:encoded><![CDATA[
arXiv:2502.10610v2 Announce Type: replace 
Abstract: Road safety continues to be a pressing global issue, with vehicle collisions imposing significant human, societal, and economic burdens. Human-machine shared collision avoidance in critical collision scenarios aims to aid drivers' accident avoidance through intervening only when necessary. Existing methods count on replanning collision-free trajectories and imposing human-machine tracking, which usually interrupts the driver's intent and increases the risk of conflict. This paper introduces a Reachability-Aware Reinforcement Learning (RL) framework for shared control, guided by Hamilton-Jacobi (HJ) reachability analysis. Machine intervention is activated only when the vehicle approaches the Collision Avoidance Reachable Set (CARS), which represents states where collision is unavoidable. First, we precompute the reachability distributions and the CARS by solving the Bellman equation using offline data. To reduce human-machine conflicts, we develop a driver model for sudden obstacles and propose an authority allocation strategy considering key collision avoidance features. Finally, we train a RL agent to reduce human-machine conflicts while enforcing the hard constraint of avoiding entry into the CARS. The proposed method was tested on a real vehicle platform. Results show that the controller intervenes effectively near CARS to prevent collisions while maintaining improved original driving task performance. Robustness analysis further supports its flexibility across different driver attributes.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning from Reward-Free Offline Data: A Case for Planning with Latent Dynamics Models</title>
<link>https://arxiv.org/abs/2502.14819</link>
<guid>https://arxiv.org/abs/2502.14819</guid>
<content:encoded><![CDATA[
arXiv:2502.14819v2 Announce Type: replace 
Abstract: A long-standing goal in AI is to build agents that can solve a variety of tasks across different environments, including previously unseen ones. Two dominant approaches tackle this challenge: (i) reinforcement learning (RL), which learns policies through trial and error, and (ii) optimal control, which plans actions using a learned or known dynamics model. However, their relative strengths and weaknesses remain underexplored in the setting where agents must learn from offline trajectories without reward annotations. In this work, we systematically analyze the performance of different RL and control-based methods under datasets of varying quality. On the RL side, we consider goal-conditioned and zero-shot approaches. On the control side, we train a latent dynamics model using the Joint Embedding Predictive Architecture (JEPA) and use it for planning. We study how dataset properties-such as data diversity, trajectory quality, and environment variability-affect the performance of these approaches. Our results show that model-free RL excels when abundant, high-quality data is available, while model-based planning excels in generalization to novel environment layouts, trajectory stitching, and data-efficiency. Notably, planning with a latent dynamics model emerges as a promising approach for zero-shot generalization from suboptimal data.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BEARCUBS: A benchmark for computer-using web agents</title>
<link>https://arxiv.org/abs/2503.07919</link>
<guid>https://arxiv.org/abs/2503.07919</guid>
<content:encoded><![CDATA[
arXiv:2503.07919v2 Announce Type: replace 
Abstract: Modern web agents possess computer use abilities that allow them to interact with webpages by sending commands to a virtual keyboard and mouse. While such agents have considerable potential to assist human users with complex tasks, evaluating their capabilities in real-world settings poses a major challenge. To this end, we introduce BEARCUBS, a "small but mighty" benchmark of 111 information-seeking questions designed to evaluate a web agent's ability to search, browse, and identify factual information from the web. Unlike prior web agent benchmarks, solving BEARCUBS requires (1) accessing live web content rather than synthetic or simulated pages, which captures the unpredictability of real-world web interactions; and (2) performing a broad range of multimodal interactions (e.g., video understanding, 3D navigation) that cannot be bypassed via text-based workarounds. Each question in BEARCUBS has a corresponding short, unambiguous answer and a human-validated browsing trajectory, allowing for transparent evaluation of agent performance and strategies. A human study confirms that BEARCUBS questions are solvable but non-trivial (84.7% human accuracy), revealing domain knowledge gaps and overlooked details as common failure points. By contrast, state-of-the-art computer-using agents underperform, with the best-scoring system (OpenAI's Operator) reaching only 23.4% accuracy. These results highlight critical areas for improvement, including reliable source selection and more powerful multimodal capabilities. To facilitate future research, BEARCUBS will be updated periodically to replace invalid or contaminated questions, keeping the benchmark fresh for future generations of web agents.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ActionStudio: A Lightweight Framework for Data and Training of Large Action Models</title>
<link>https://arxiv.org/abs/2503.22673</link>
<guid>https://arxiv.org/abs/2503.22673</guid>
<content:encoded><![CDATA[
arXiv:2503.22673v3 Announce Type: replace 
Abstract: Large Action models are essential for enabling autonomous agents to perform complex tasks. However, training such models remains challenging due to the diversity of agent environments and the complexity of noisy agentic data. Existing infrastructure offers limited support for scalable, agent-specific fine-tuning and standardized agent data processing. We introduce ActionStudio, a lightweight and extensible data and training framework designed for large action models. ActionStudio unifies diverse agent trajectories using our proposed Unified Format 2.0, supports a range of training workflows with optimized multi-node distributed setup, and integrates robust preprocessing and real-time verification tools. ActionStudio demonstrates up to 9x higher throughput compared to existing agentic training frameworks, and our trained models yield top performances across public and realistic agent benchmarks. To support the broader research community, we open-source the ActionStudio framework and release actionstudio-98k, a curated dataset of 98k high-quality trajectories. Code: https://github.com/SalesforceAIResearch/xLAM.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Algebraic Approach to Asymmetric Delegation and Polymorphic Label Inference (Technical Report)</title>
<link>https://arxiv.org/abs/2504.20432</link>
<guid>https://arxiv.org/abs/2504.20432</guid>
<content:encoded><![CDATA[
arXiv:2504.20432v2 Announce Type: replace 
Abstract: Language-based information flow control (IFC) enables reasoning about and enforcing security policies in decentralized applications. While information flow properties are relatively extensional and compositional, designing expressive systems that enforce such properties remains challenging. In particular, it can be difficult to use IFC labels to model certain security assumptions, such as semi-honest agents.
  Motivated by these modeling limitations, we study the algebraic semantics of lattice-based IFC label models, and propose a semantic framework that allows formalizing asymmetric delegation, which is partial delegation of confidentiality or integrity. Our framework supports downgrading of information and ensures their safety through nonmalleable information flow (NMIF).
  To demonstrate the practicality of our framework, we design and implement a novel algorithm that statically checks NMIF and a label inference procedure that efficiently supports bounded label polymorphism, allowing users to write code generic with respect to labels.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Coral Protocol: Open Infrastructure Connecting The Internet of Agents</title>
<link>https://arxiv.org/abs/2505.00749</link>
<guid>https://arxiv.org/abs/2505.00749</guid>
<content:encoded><![CDATA[
arXiv:2505.00749v2 Announce Type: replace 
Abstract: Coral Protocol is an open and decentralized collaboration infrastructure that enables communication, coordination, trust and payments for The Internet of Agents. It addresses the growing need for interoperability in a world where organizations are deploying multiple specialized AI agents that must work together across domains and vendors. As a foundational platform for multi-agent AI ecosystems, Coral establishes a common language and coordination framework allowing any agent to participate in complex workflows with others. Its design emphasizes broad compatibility, security, and vendor neutrality, ensuring that agent interactions are efficient and trustworthy. In particular, Coral introduces standardized messaging formats for agent communication, a modular coordination mechanism for orchestrating multi-agent tasks, and secure team formation capabilities for dynamically assembling trusted groups of agents. Together, these innovations position Coral Protocol as a cornerstone of the emerging "Internet of Agents," unlocking new levels of automation, collective intelligence, and business value through open agent collaboration.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Judging with Many Minds: Do More Perspectives Mean Less Prejudice? On Bias Amplifications and Resistance in Multi-Agent Based LLM-as-Judge</title>
<link>https://arxiv.org/abs/2505.19477</link>
<guid>https://arxiv.org/abs/2505.19477</guid>
<content:encoded><![CDATA[
arXiv:2505.19477v2 Announce Type: replace 
Abstract: LLM-as-Judge has emerged as a scalable alternative to human evaluation, enabling large language models (LLMs) to provide reward signals in trainings. While recent work has explored multi-agent extensions such as multi-agent debate and meta-judging to enhance evaluation quality, the question of how intrinsic biases manifest in these settings remains underexplored. In this study, we conduct a systematic analysis of four diverse bias types: position bias, verbosity bias, chain-of-thought bias, and bandwagon bias. We evaluate these biases across two widely adopted multi-agent LLM-as-Judge frameworks: Multi-Agent-Debate and LLM-as-Meta-Judge. Our results show that debate framework amplifies biases sharply after the initial debate, and this increased bias is sustained in subsequent rounds, while meta-judge approaches exhibit greater resistance. We further investigate the incorporation of PINE, a leading single-agent debiasing method, as a bias-free agent within these systems. The results reveal that this bias-free agent effectively reduces biases in debate settings but provides less benefit in meta-judge scenarios. Our work provides a comprehensive study of bias behavior in multi-agent LLM-as-Judge systems and highlights the need for targeted bias mitigation strategies in collaborative evaluation settings.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multiple-Frequencies Population-Based Training</title>
<link>https://arxiv.org/abs/2506.03225</link>
<guid>https://arxiv.org/abs/2506.03225</guid>
<content:encoded><![CDATA[
arXiv:2506.03225v2 Announce Type: replace 
Abstract: Reinforcement Learning's high sensitivity to hyperparameters is a source of instability and inefficiency, creating significant challenges for practitioners. Hyperparameter Optimization (HPO) algorithms have been developed to address this issue, among them Population-Based Training (PBT) stands out for its ability to generate hyperparameters schedules instead of fixed configurations. PBT trains a population of agents, each with its own hyperparameters, frequently ranking them and replacing the worst performers with mutations of the best agents. These intermediate selection steps can cause PBT to focus on short-term improvements, leading it to get stuck in local optima and eventually fall behind vanilla Random Search over longer timescales. This paper studies how this greediness issue is connected to the choice of evolution frequency, the rate at which the selection is done. We propose Multiple-Frequencies Population-Based Training (MF-PBT), a novel HPO algorithm that addresses greediness by employing sub-populations, each evolving at distinct frequencies. MF-PBT introduces a migration process to transfer information between sub-populations, with an asymmetric design to balance short and long-term optimization. Extensive experiments on the Brax suite demonstrate that MF-PBT improves sample efficiency and long-term performance, even without actually tuning hyperparameters.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MEM1: Learning to Synergize Memory and Reasoning for Efficient Long-Horizon Agents</title>
<link>https://arxiv.org/abs/2506.15841</link>
<guid>https://arxiv.org/abs/2506.15841</guid>
<content:encoded><![CDATA[
arXiv:2506.15841v2 Announce Type: replace 
Abstract: Modern language agents must operate over long-horizon, multi-turn interactions, where they retrieve external information, adapt to observations, and answer interdependent queries. Yet, most LLM systems rely on full-context prompting, appending all past turns regardless of their relevance. This leads to unbounded memory growth, increased computational costs, and degraded reasoning performance on out-of-distribution input lengths. We introduce MEM1, an end-to-end reinforcement learning framework that enables agents to operate with constant memory across long multi-turn tasks. At each turn, MEM1 updates a compact shared internal state that jointly supports memory consolidation and reasoning. This state integrates prior memory with new observations from the environment while strategically discarding irrelevant or redundant information. To support training in more realistic and compositional settings, we propose a simple yet effective and scalable approach to constructing multi-turn environments by composing existing datasets into arbitrarily complex task sequences. Experiments across three domains, including internal retrieval QA, open-domain web QA, and multi-turn web shopping, show that MEM1-7B improves performance by 3.5x while reducing memory usage by 3.7x compared to Qwen2.5-14B-Instruct on a 16-objective multi-hop QA task, and generalizes beyond the training horizon. Our results demonstrate the promise of reasoning-driven memory consolidation as a scalable alternative to existing solutions for training long-horizon interactive agents, where both efficiency and performance are optimized.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Nash equilibrium seeking for a class of quadratic-bilinear Wasserstein distributionally robust games</title>
<link>https://arxiv.org/abs/2411.09636</link>
<guid>https://arxiv.org/abs/2411.09636</guid>
<content:encoded><![CDATA[
arXiv:2411.09636v2 Announce Type: replace-cross 
Abstract: We consider a class of Wasserstein distributionally robust Nash equilibrium problems, where agents construct heterogeneous data-driven Wasserstein ambiguity sets using private samples and radii, in line with their individual risk-averse behaviour. By leveraging relevant properties of this class of games, we show that equilibria of the original seemingly infinite-dimensional problem can be obtained as a solution to a finite-dimensional Nash equilibrium problem. We then reformulate the problem as a finite-dimensional variational inequality and establish the connection between the corresponding solution sets. Our reformulation has scalable behaviour with respect to the data size and maintains a fixed number of constraints, independently of the number of samples. To compute a solution, we leverage two algorithms, based on the golden ratio algorithm. The efficiency of both algorithmic schemes is corroborated through extensive simulation studies on an illustrative example and a stochastic portfolio allocation game, where behavioural coupling among investors is modeled.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Model Aware AIGC Task Offloading Algorithm in IIoT Edge Computing</title>
<link>https://arxiv.org/abs/2507.11560</link>
<guid>https://arxiv.org/abs/2507.11560</guid>
<content:encoded><![CDATA[
arXiv:2507.11560v1 Announce Type: new 
Abstract: The integration of the Industrial Internet of Things (IIoT) with Artificial Intelligence-Generated Content (AIGC) offers new opportunities for smart manufacturing, but it also introduces challenges related to computation-intensive tasks and low-latency demands. Traditional generative models based on cloud computing are difficult to meet the real-time requirements of AIGC tasks in IIoT environments, and edge computing can effectively reduce latency through task offloading. However, the dynamic nature of AIGC tasks, model switching delays, and resource constraints impose higher demands on edge computing environments. To address these challenges, this paper proposes an AIGC task offloading framework tailored for IIoT edge computing environments, considering the latency and energy consumption caused by AIGC model switching for the first time. IIoT devices acted as multi-agent collaboratively offload their dynamic AIGC tasks to the most appropriate edge servers deployed with different generative models. A model aware AIGC task offloading algorithm based on Multi-Agent Deep Deterministic Policy Gradient (MADDPG-MATO) is devised to minimize the latency and energy. Experimental results show that MADDPG-MATO outperforms baseline algorithms, achieving an average reduction of 6.98% in latency, 7.12% in energy consumption, and a 3.72% increase in task completion rate across four sets of experiments with model numbers ranging from 3 to 6, it is demonstrated that the proposed algorithm is robust and efficient in dynamic, high-load IIoT environments.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergent Heterogeneous Swarm Control Through Hebbian Learning</title>
<link>https://arxiv.org/abs/2507.11566</link>
<guid>https://arxiv.org/abs/2507.11566</guid>
<content:encoded><![CDATA[
arXiv:2507.11566v1 Announce Type: new 
Abstract: In this paper, we introduce Hebbian learning as a novel method for swarm robotics, enabling the automatic emergence of heterogeneity. Hebbian learning presents a biologically inspired form of neural adaptation that solely relies on local information. By doing so, we resolve several major challenges for learning heterogeneous control: 1) Hebbian learning removes the complexity of attributing emergent phenomena to single agents through local learning rules, thus circumventing the micro-macro problem; 2) uniform Hebbian learning rules across all swarm members limit the number of parameters needed, mitigating the curse of dimensionality with scaling swarm sizes; and 3) evolving Hebbian learning rules based on swarm-level behaviour minimises the need for extensive prior knowledge typically required for optimising heterogeneous swarms. This work demonstrates that with Hebbian learning heterogeneity naturally emerges, resulting in swarm-level behavioural switching and in significantly improved swarm capabilities. It also demonstrates how the evolution of Hebbian learning rules can be a valid alternative to Multi Agent Reinforcement Learning in standard benchmarking tasks.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Consumer Law for AI Agents</title>
<link>https://arxiv.org/abs/2507.11567</link>
<guid>https://arxiv.org/abs/2507.11567</guid>
<content:encoded><![CDATA[
arXiv:2507.11567v1 Announce Type: new 
Abstract: Since the public release of ChatGPT in November 2022, the AI landscape is undergoing a rapid transformation. Currently, the use of AI chatbots by consumers has largely been limited to image generation or question-answering language models. The next generation of AI systems, AI agents that can plan and execute complex tasks with only limited human involvement, will be capable of a much broader range of actions. In particular, consumers could soon be able to delegate purchasing decisions to AI agents acting as Custobots. Against this background, the Article explores whether EU consumer law, as it currently stands, is ready for the rise of the Custobot Economy. In doing so, the Article makes three contributions. First, it outlines how the advent of AI agents could change the existing e-commerce landscape. Second, it explains how AI agents challenge the premises of a human-centric consumer law which is based on the assumption that consumption decisions are made by humans. Third, the Article presents some initial considerations how a future consumer law could look like that works for both humans and machines.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI, Humans, and Data Science: Optimizing Roles Across Workflows and the Workforce</title>
<link>https://arxiv.org/abs/2507.11597</link>
<guid>https://arxiv.org/abs/2507.11597</guid>
<content:encoded><![CDATA[
arXiv:2507.11597v1 Announce Type: new 
Abstract: AI is transforming research. It is being leveraged to construct surveys, synthesize data, conduct analysis, and write summaries of the results. While the promise is to create efficiencies and increase quality, the reality is not always as clear cut. Leveraging our framework of Truth, Beauty, and Justice (TBJ) which we use to evaluate AI, machine learning and computational models for effective and ethical use (Taber and Timpone 1997; Timpone and Yang 2024), we consider the potential and limitation of analytic, generative, and agentic AI to augment data scientists or take on tasks traditionally done by human analysts and researchers. While AI can be leveraged to assist analysts in their tasks, we raise some warnings about push-button automation. Just as earlier eras of survey analysis created some issues when the increased ease of using statistical software allowed researchers to conduct analyses they did not fully understand, the new AI tools may create similar but larger risks. We emphasize a human-machine collaboration perspective (Daugherty and Wilson 2018) throughout the data science workflow and particularly call out the vital role that data scientists play under VUCA decision areas. We conclude by encouraging the advance of AI tools to complement data scientists but advocate for continued training and understanding of methods to ensure the substantive value of research is fully achieved by applying, interpreting, and acting upon results most effectively and ethically.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>General Modular Harness for LLM Agents in Multi-Turn Gaming Environments</title>
<link>https://arxiv.org/abs/2507.11633</link>
<guid>https://arxiv.org/abs/2507.11633</guid>
<content:encoded><![CDATA[
arXiv:2507.11633v1 Announce Type: new 
Abstract: We introduce a modular harness design for LLM agents that composes of perception, memory, and reasoning components, enabling a single LLM or VLM backbone to tackle a wide spectrum of multi turn gaming environments without domain-specific engineering. Using classic and modern game suites as low-barrier, high-diversity testbeds, our framework provides a unified workflow for analyzing how each module affects performance across dynamic interactive settings. Extensive experiments demonstrate that the harness lifts gameplay performance consistently over un-harnessed baselines and reveals distinct contribution patterns, for example, memory dominates in long-horizon puzzles while perception is critical in vision noisy arcades. These findings highlight the effectiveness of our modular harness design in advancing general-purpose agent, given the familiarity and ubiquity of games in everyday human experience.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VISTA: Monocular Segmentation-Based Mapping for Appearance and View-Invariant Global Localization</title>
<link>https://arxiv.org/abs/2507.11653</link>
<guid>https://arxiv.org/abs/2507.11653</guid>
<content:encoded><![CDATA[
arXiv:2507.11653v1 Announce Type: new 
Abstract: Global localization is critical for autonomous navigation, particularly in scenarios where an agent must localize within a map generated in a different session or by another agent, as agents often have no prior knowledge about the correlation between reference frames. However, this task remains challenging in unstructured environments due to appearance changes induced by viewpoint variation, seasonal changes, spatial aliasing, and occlusions -- known failure modes for traditional place recognition methods. To address these challenges, we propose VISTA (View-Invariant Segmentation-Based Tracking for Frame Alignment), a novel open-set, monocular global localization framework that combines: 1) a front-end, object-based, segmentation and tracking pipeline, followed by 2) a submap correspondence search, which exploits geometric consistencies between environment maps to align vehicle reference frames. VISTA enables consistent localization across diverse camera viewpoints and seasonal changes, without requiring any domain-specific training or finetuning. We evaluate VISTA on seasonal and oblique-angle aerial datasets, achieving up to a 69% improvement in recall over baseline methods. Furthermore, we maintain a compact object-based map that is only 0.6% the size of the most memory-conservative baseline, making our approach capable of real-time implementation on resource-constrained platforms.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>STAGED: A Multi-Agent Neural Network for Learning Cellular Interaction Dynamics</title>
<link>https://arxiv.org/abs/2507.11660</link>
<guid>https://arxiv.org/abs/2507.11660</guid>
<content:encoded><![CDATA[
arXiv:2507.11660v1 Announce Type: new 
Abstract: The advent of single-cell technology has significantly improved our understanding of cellular states and subpopulations in various tissues under normal and diseased conditions by employing data-driven approaches such as clustering and trajectory inference. However, these methods consider cells as independent data points of population distributions. With spatial transcriptomics, we can represent cellular organization, along with dynamic cell-cell interactions that lead to changes in cell state. Still, key computational advances are necessary to enable the data-driven learning of such complex interactive cellular dynamics. While agent-based modeling (ABM) provides a powerful framework, traditional approaches rely on handcrafted rules derived from domain knowledge rather than data-driven approaches. To address this, we introduce Spatio Temporal Agent-Based Graph Evolution Dynamics(STAGED) integrating ABM with deep learning to model intercellular communication, and its effect on the intracellular gene regulatory network. Using graph ODE networks (GDEs) with shared weights per cell type, our approach represents genes as vertices and interactions as directed edges, dynamically learning their strengths through a designed attention mechanism. Trained to match continuous trajectories of simulated as well as inferred trajectories from spatial transcriptomics data, the model captures both intercellular and intracellular interactions, enabling a more adaptive and accurate representation of cellular dynamics.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Let's Think in Two Steps: Mitigating Agreement Bias in MLLMs with Self-Grounded Verification</title>
<link>https://arxiv.org/abs/2507.11662</link>
<guid>https://arxiv.org/abs/2507.11662</guid>
<content:encoded><![CDATA[
arXiv:2507.11662v1 Announce Type: new 
Abstract: Verifiers -- functions assigning rewards to agent behavior -- have been key for AI progress in domains like math and board games. However, extending these gains to domains without clear-cut success criteria (e.g.,computer use) remains a challenge: while humans can recognize suitable outcomes, translating this intuition into scalable rules is non-trivial. Multimodal Large Language Models(MLLMs) emerge as a promising solution, given their world knowledge, human-preference alignment, and reasoning skills. We evaluate MLLMs as verifiers of agent trajectories across web navigation, computer use, and robotic manipulation, and identify a critical limitation: agreement bias, a strong tendency for MLLMs to favor information in their context window, often generating chains of thought to rationalize flawed behavior. This bias is pervasive across models, resilient to test-time scaling, and can impact several methods using MLLMs as evaluators (e.g.,data filtering). Notably, it occurs despite MLLMs showing strong, human-aligned priors on desired behavior. To address this, we propose Self-Grounded Verification (SGV), a lightweight method that enables more effective use of MLLMs' knowledge and reasoning by harnessing their own sampling mechanisms via unconditional and conditional generation. SGV operates in two steps: first, the MLLM is elicited to retrieve broad priors about task completion, independent of the data under evaluation. Then, conditioned on self-generated priors, it reasons over and evaluates a candidate trajectory. Enhanced with SGV, MLLM verifiers show gains of up to 20 points in accuracy and failure detection rates, and can perform real-time supervision of heterogeneous agents, boosting task completion of a GUI specialist in OSWorld, a diffusion policy in robomimic, and a ReAct agent in VisualWebArena -- setting a new state of the art on the benchmark, surpassing the previous best by 48%.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Cellular Automata Approach to Donation Game</title>
<link>https://arxiv.org/abs/2507.11744</link>
<guid>https://arxiv.org/abs/2507.11744</guid>
<content:encoded><![CDATA[
arXiv:2507.11744v1 Announce Type: new 
Abstract: The donation game is a well-established framework for studying the emergence and evolution of cooperation in multi-agent systems. The cooperative behavior can be influenced by the environmental noise in partially observable settings and by the decision-making strategies of agents, which may incorporate not only reputation but also traits such as generosity and forgiveness. Traditional simulations often assume fully random interactions, where cooperation is tested between randomly selected agent pairs. In this paper, we investigate cooperation dynamics using the concept of Stephen Wolfram's one-dimensional binary cellular automata. This approach allows us to explore how cooperation evolves when interactions are limited to neighboring agents. We define binary cellular automata rules that conform to the donation game mechanics. Additionally, we introduce models of perceptual and action noise, along with a mutation matrix governing the probabilistic evolution of agent strategies. Our empirical results demonstrate that cooperation is significantly affected by agents' mobility and their spatial locality on the game board. These findings highlight the importance of distinguishing between entirely random multi-agent systems and those in which agents are more likely to interact with their nearest neighbors.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>New allocation rule based on graph structures and their application to economic phenomena</title>
<link>https://arxiv.org/abs/2507.11808</link>
<guid>https://arxiv.org/abs/2507.11808</guid>
<content:encoded><![CDATA[
arXiv:2507.11808v1 Announce Type: new 
Abstract: This study introduces the \emph{edge-based Shapley value}, a novel allocation rule within cooperative game theory, specifically tailored for networked systems, where value is generated through interactions represented by edges. Traditional allocation rules, such as the Shapley and Myerson values, evaluate player contributions based on node-level characteristics, or connected components. However, these approaches often fail to adequately capture the functional role of edges, which are crucial in systems such as supply chains and digital platforms, where interactions, rather than individual agents, are the primary drivers of value. Our edge-based Shapley value shifts the characteristic function from node sets to edge sets, thereby enabling a more granular and context-sensitive evaluation of the contributions. We establish its theoretical foundations, demonstrate its relationship to classical allocation rules, and show that it retains key properties such as fairness and symmetry. To illustrate its applicability, we present two use cases: content platform networks and supply chain logistics (SCL). In both cases, our method produces intuitive and structurally consistent allocations, particularly in scenarios with overlapping routes, exclusive contracts or cost-sensitive paths. This framework offers a new perspective on value attribution in cooperative settings with complex interaction structures and provides practical tools for analyzing real-world economic and logistical networks.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Evolving Role of Large Language Models in Scientific Innovation: Evaluator, Collaborator, and Scientist</title>
<link>https://arxiv.org/abs/2507.11810</link>
<guid>https://arxiv.org/abs/2507.11810</guid>
<content:encoded><![CDATA[
arXiv:2507.11810v1 Announce Type: new 
Abstract: Scientific innovation is undergoing a paradigm shift driven by the rapid advancement of Large Language Models (LLMs). As science faces mounting challenges including information overload, disciplinary silos, and diminishing returns on conventional research methods, LLMs are emerging as powerful agents capable not only of enhancing scientific workflows but also of participating in and potentially leading the innovation process. Existing surveys mainly focus on different perspectives, phrases, and tasks in scientific research and discovery, while they have limitations in understanding the transformative potential and role differentiation of LLM. This survey proposes a comprehensive framework to categorize the evolving roles of LLMs in scientific innovation across three hierarchical levels: Evaluator, Collaborator, and Scientist. We distinguish between LLMs' contributions to structured scientific research processes and open-ended scientific discovery, thereby offering a unified taxonomy that clarifies capability boundaries, evaluation criteria, and human-AI interaction patterns at each level. Through an extensive analysis of current methodologies, benchmarks, systems, and evaluation metrics, this survey delivers an in-depth and systematic synthesis on LLM-driven scientific innovation. We present LLMs not only as tools for automating existing processes, but also as catalysts capable of reshaping the epistemological foundations of science itself. This survey offers conceptual clarity, practical guidance, and theoretical foundations for future research, while also highlighting open challenges and ethical considerations in the pursuit of increasingly autonomous AI-driven science. Resources related to this survey can be accessed on GitHub at: https://github.com/haoxuan-unt2024/llm4innovation.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Intelligence Systems in the Flow of Group Emotions</title>
<link>https://arxiv.org/abs/2507.11831</link>
<guid>https://arxiv.org/abs/2507.11831</guid>
<content:encoded><![CDATA[
arXiv:2507.11831v1 Announce Type: new 
Abstract: Emotional cues frequently arise and shape group dynamics in interactive settings where multiple humans and artificial agents communicate through shared digital channels. While artificial agents lack intrinsic emotional states, they can simulate affective behavior using synthetic modalities such as text or speech. This work introduces a model for orchestrating emotion contagion, enabling agents to detect emotional signals, infer group mood patterns, and generate targeted emotional responses. The system captures human emotional exchanges and uses this insight to produce adaptive, generative responses that influence group affect in real time. The model supports applications in collaborative, educational, and social environments by shifting affective computing from individual-level reactions to coordinated, group-level emotion modulation. We present the system architecture and provide experimental results that illustrate its effectiveness in sensing and steering group mood dynamics.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Extremal Testing for Network Software using LLMs</title>
<link>https://arxiv.org/abs/2507.11898</link>
<guid>https://arxiv.org/abs/2507.11898</guid>
<content:encoded><![CDATA[
arXiv:2507.11898v1 Announce Type: new 
Abstract: Physicists often manually consider extreme cases when testing a theory. In this paper, we show how to automate extremal testing of network software using LLMs in two steps: first, ask the LLM to generate input constraints (e.g., DNS name length limits); then ask the LLM to generate tests that violate the constraints. We demonstrate how easy this process is by generating extremal tests for HTTP, BGP and DNS implementations, each of which uncovered new bugs. We show how this methodology extends to centralized network software such as shortest path algorithms, and how LLMs can generate filtering code to reject extremal input. We propose using agentic AI to further automate extremal testing. LLM-generated extremal testing goes beyond an old technique in software testing called Boundary Value Analysis.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoCre-Sam (Kokkuri-san): Modeling Ouija Board as Collective Langevin Dynamics Sampling from Fused Language Models</title>
<link>https://arxiv.org/abs/2507.11906</link>
<guid>https://arxiv.org/abs/2507.11906</guid>
<content:encoded><![CDATA[
arXiv:2507.11906v1 Announce Type: new 
Abstract: Collective human activities like using an Ouija board (or Kokkuri-san) often produce emergent, coherent linguistic outputs unintended by any single participant. While psychological explanations such as the ideomotor effect exist, a computational understanding of how decentralized, implicit linguistic knowledge fuses through shared physical interaction remains elusive. We introduce CoCre-Sam (Collective-Creature Sampling), a framework modeling this phenomenon as collective Langevin dynamics sampling from implicitly fused language models. Each participant is represented as an agent associated with an energy landscape derived from an internal language model reflecting linguistic priors, and agents exert stochastic forces based on local energy gradients. We theoretically prove that the collective motion of the shared pointer (planchette) corresponds to Langevin MCMC sampling from the sum of individual energy landscapes, representing fused collective knowledge. Simulations validate that CoCre-Sam dynamics effectively fuse different models and generate meaningful character sequences, while ablation studies confirm the essential roles of collective interaction and stochasticity. Altogether, CoCre-Sam provides a novel computational mechanism linking individual implicit knowledge, embodied collective action, and emergent linguistic phenomena, grounding these complex interactions in the principles of probabilistic sampling.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Conformal Prediction-based Risk-Aware Model Predictive Planning in Dense, Uncertain Environments</title>
<link>https://arxiv.org/abs/2507.11920</link>
<guid>https://arxiv.org/abs/2507.11920</guid>
<content:encoded><![CDATA[
arXiv:2507.11920v1 Announce Type: new 
Abstract: Real-time path planning in dense, uncertain environments remains a challenging problem, as predicting the future motions of numerous dynamic obstacles is computationally burdensome and unrealistic. To address this, we introduce Hybrid Prediction-based Risk-Aware Planning (HyPRAP), a prediction-based risk-aware path-planning framework which uses a hybrid combination of models to predict local obstacle movement. HyPRAP uses a novel Prediction-based Collision Risk Index (P-CRI) to evaluate the risk posed by each obstacle, enabling the selective use of predictors based on whether the agent prioritizes high predictive accuracy or low computational prediction overhead. This selective routing enables the agent to focus on high-risk obstacles while ignoring or simplifying low-risk ones, making it suitable for environments with a large number of obstacles. Moreover, HyPRAP incorporates uncertainty quantification through hybrid conformal prediction by deriving confidence bounds simultaneously achieved by multiple predictions across different models. Theoretical analysis demonstrates that HyPRAP effectively balances safety and computational efficiency by leveraging the diversity of prediction models. Extensive simulations validate these insights for more general settings, confirming that HyPRAP performs better compared to single predictor methods, and P-CRI performs better over naive proximity-based risk assessment.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Generative to Episodic: Sample-Efficient Replicable Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.11926</link>
<guid>https://arxiv.org/abs/2507.11926</guid>
<content:encoded><![CDATA[
arXiv:2507.11926v1 Announce Type: new 
Abstract: The epidemic failure of replicability across empirical science and machine learning has recently motivated the formal study of replicable learning algorithms [Impagliazzo et al. (2022)]. In batch settings where data comes from a fixed i.i.d. source (e.g., hypothesis testing, supervised learning), the design of data-efficient replicable algorithms is now more or less understood. In contrast, there remain significant gaps in our knowledge for control settings like reinforcement learning where an agent must interact directly with a shifting environment. Karbasi et. al show that with access to a generative model of an environment with $S$ states and $A$ actions (the RL 'batch setting'), replicably learning a near-optimal policy costs only $\tilde{O}(S^2A^2)$ samples. On the other hand, the best upper bound without a generative model jumps to $\tilde{O}(S^7 A^7)$ [Eaton et al. (2024)] due to the substantial difficulty of environment exploration. This gap raises a key question in the broader theory of replicability: Is replicable exploration inherently more expensive than batch learning? Is sample-efficient replicable RL even possible?
  In this work, we (nearly) resolve this problem (for low-horizon tabular MDPs): exploration is not a significant barrier to replicable learning! Our main result is a replicable RL algorithm on $\tilde{O}(S^2A)$ samples, bridging the gap between the generative and episodic settings. We complement this with a matching $\tilde{\Omega}(S^2A)$ lower bound in the generative setting (under the common parallel sampling assumption) and an unconditional lower bound in the episodic setting of $\tilde{\Omega}(S^2)$ showcasing the near-optimality of our algorithm with respect to the state space $S$.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IANN-MPPI: Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral Approach for Autonomous Driving</title>
<link>https://arxiv.org/abs/2507.11940</link>
<guid>https://arxiv.org/abs/2507.11940</guid>
<content:encoded><![CDATA[
arXiv:2507.11940v1 Announce Type: new 
Abstract: Motion planning for autonomous vehicles (AVs) in dense traffic is challenging, often leading to overly conservative behavior and unmet planning objectives. This challenge stems from the AVs' limited ability to anticipate and respond to the interactive behavior of surrounding agents. Traditional decoupled prediction and planning pipelines rely on non-interactive predictions that overlook the fact that agents often adapt their behavior in response to the AV's actions. To address this, we propose Interaction-Aware Neural Network-Enhanced Model Predictive Path Integral (IANN-MPPI) control, which enables interactive trajectory planning by predicting how surrounding agents may react to each control sequence sampled by MPPI. To improve performance in structured lane environments, we introduce a spline-based prior for the MPPI sampling distribution, enabling efficient lane-changing behavior. We evaluate IANN-MPPI in a dense traffic merging scenario, demonstrating its ability to perform efficient merging maneuvers. Our project website is available at https://sites.google.com/berkeley.edu/iann-mppi
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker</title>
<link>https://arxiv.org/abs/2507.11972</link>
<guid>https://arxiv.org/abs/2507.11972</guid>
<content:encoded><![CDATA[
arXiv:2507.11972v1 Announce Type: new 
Abstract: Reading comprehension is a fundamental skill in human cognitive development. With the advancement of Large Language Models (LLMs), there is a growing need to compare how humans and LLMs understand language across different contexts and apply this understanding to functional tasks such as inference, emotion interpretation, and information retrieval. Our previous work used LLMs and human biomarkers to study the reading comprehension process. The results showed that the biomarkers corresponding to words with high and low relevance to the inference target, as labeled by the LLMs, exhibited distinct patterns, particularly when validated using eye-tracking data. However, focusing solely on individual words limited the depth of understanding, which made the conclusions somewhat simplistic despite their potential significance. This study used an LLM-based AI agent to group words from a reading passage into nodes and edges, forming a graph-based text representation based on semantic meaning and question-oriented prompts. We then compare the distribution of eye fixations on important nodes and edges. Our findings indicate that LLMs exhibit high consistency in language understanding at the level of graph topological structure. These results build on our previous findings and offer insights into effective human-AI co-learning strategies.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Training and Pruning of Deep Reinforcement Learning Networks</title>
<link>https://arxiv.org/abs/2507.11975</link>
<guid>https://arxiv.org/abs/2507.11975</guid>
<content:encoded><![CDATA[
arXiv:2507.11975v1 Announce Type: new 
Abstract: Scaling deep neural networks (NN) of reinforcement learning (RL) algorithms has been shown to enhance performance when feature extraction networks are used but the gained performance comes at the significant expense of increased computational and memory complexity. Neural network pruning methods have successfully addressed this challenge in supervised learning. However, their application to RL is underexplored. We propose an approach to integrate simultaneous training and pruning within advanced RL methods, in particular to RL algorithms enhanced by the Online Feature Extractor Network (OFENet). Our networks (XiNet) are trained to solve stochastic optimization problems over the RL networks' weights and the parameters of variational Bernoulli distributions for 0/1 Random Variables $\xi$ scaling each unit in the networks. The stochastic problem formulation induces regularization terms that promote convergence of the variational parameters to 0 when a unit contributes little to the performance. In this case, the corresponding structure is rendered permanently inactive and pruned from its network. We propose a cost-aware, sparsity-promoting regularization scheme, tailored to the DenseNet architecture of OFENets expressing the parameter complexity of involved networks in terms of the parameters of the RVs in these networks. Then, when matching this cost with the regularization terms, the many hyperparameters associated with them are automatically selected, effectively combining the RL objectives and network compression. We evaluate our method on continuous control benchmarks (MuJoCo) and the Soft Actor-Critic RL agent, demonstrating that OFENets can be pruned considerably with minimal loss in performance. Furthermore, our results confirm that pruning large networks during training produces more efficient and higher performing RL agents rather than training smaller networks from scratch.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Value-Based Large Language Model Agent Simulation for Mutual Evaluation of Trust and Interpersonal Closeness</title>
<link>https://arxiv.org/abs/2507.11979</link>
<guid>https://arxiv.org/abs/2507.11979</guid>
<content:encoded><![CDATA[
arXiv:2507.11979v1 Announce Type: new 
Abstract: Large language models (LLMs) have emerged as powerful tools for simulating complex social phenomena using human-like agents with specific traits. In human societies, value similarity is important for building trust and close relationships; however, it remains unexplored whether this principle holds true in artificial societies comprising LLM agents. Therefore, this study investigates the influence of value similarity on relationship-building among LLM agents through two experiments. First, in a preliminary experiment, we evaluated the controllability of values in LLMs to identify the most effective model and prompt design for controlling the values. Subsequently, in the main experiment, we generated pairs of LLM agents imbued with specific values and analyzed their mutual evaluations of trust and interpersonal closeness following a dialogue. The experiments were conducted in English and Japanese to investigate language dependence. The results confirmed that pairs of agents with higher value similarity exhibited greater mutual trust and interpersonal closeness. Our findings demonstrate that the LLM agent simulation serves as a valid testbed for social science theories, contributes to elucidating the mechanisms by which values influence relationship building, and provides a foundation for inspiring new theories and insights into the social sciences.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aime: Towards Fully-Autonomous Multi-Agent Framework</title>
<link>https://arxiv.org/abs/2507.11988</link>
<guid>https://arxiv.org/abs/2507.11988</guid>
<content:encoded><![CDATA[
arXiv:2507.11988v1 Announce Type: new 
Abstract: Multi-Agent Systems (MAS) powered by Large Language Models (LLMs) are emerging as a powerful paradigm for solving complex, multifaceted problems. However, the potential of these systems is often constrained by the prevalent plan-and-execute framework, which suffers from critical limitations: rigid plan execution, static agent capabilities, and inefficient communication. These weaknesses hinder their adaptability and robustness in dynamic environments. This paper introduces Aime, a novel multi-agent framework designed to overcome these challenges through dynamic, reactive planning and execution. Aime replaces the conventional static workflow with a fluid and adaptive architecture. Its core innovations include: (1) a Dynamic Planner that continuously refines the overall strategy based on real-time execution feedback; (2) an Actor Factory that implements Dynamic Actor instantiation, assembling specialized agents on-demand with tailored tools and knowledge; and (3) a centralized Progress Management Module that serves as a single source of truth for coherent, system-wide state awareness. We empirically evaluated Aime on a diverse suite of benchmarks spanning general reasoning (GAIA), software engineering (SWE-bench Verified), and live web navigation (WebVoyager). The results demonstrate that Aime consistently outperforms even highly specialized state-of-the-art agents in their respective domains. Its superior adaptability and task success rate establish Aime as a more resilient and effective foundation for multi-agent collaboration.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Understanding visual attention beehind bee-inspired UAV navigation</title>
<link>https://arxiv.org/abs/2507.11992</link>
<guid>https://arxiv.org/abs/2507.11992</guid>
<content:encoded><![CDATA[
arXiv:2507.11992v1 Announce Type: new 
Abstract: Bio-inspired design is often used in autonomous UAV navigation due to the capacity of biological systems for flight and obstacle avoidance despite limited sensory and computational capabilities. In particular, honeybees mainly use the sensory input of optic flow, the apparent motion of objects in their visual field, to navigate cluttered environments. In our work, we train a Reinforcement Learning agent to navigate a tunnel with obstacles using only optic flow as sensory input. We inspect the attention patterns of trained agents to determine the regions of optic flow on which they primarily base their motor decisions. We find that agents trained in this way pay most attention to regions of discontinuity in optic flow, as well as regions with large optic flow magnitude. The trained agents appear to navigate a cluttered tunnel by avoiding the obstacles that produce large optic flow, while maintaining a centered position in their environment, which resembles the behavior seen in flying insects. This pattern persists across independently trained agents, which suggests that this could be a good strategy for developing a simple explicit control law for physical UAVs.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ARRC: Explainable, Workflow-Integrated Recommender for Sustainable Resource Optimization Across the Edge-Cloud Continuum</title>
<link>https://arxiv.org/abs/2507.12032</link>
<guid>https://arxiv.org/abs/2507.12032</guid>
<content:encoded><![CDATA[
arXiv:2507.12032v1 Announce Type: new 
Abstract: Achieving sustainable, explainable, and maintainable automation for resource optimization is a core challenge across the edge-cloud continuum. Persistent overprovisioning and operational complexity often stem from heterogeneous platforms and layered abstractions, while systems lacking explainability and maintainability become fragile, impede safe recovery, and accumulate technical debt. Existing solutions are frequently reactive, limited to single abstraction layers, or require intrusive platform changes, leaving efficiency and maintainability gains unrealized.
  This paper addresses safe, transparent, and low-effort resource optimization in dynamic, multi-tenant edge-cloud systems, without disrupting operator workflows or increasing technical debt. We introduce ARRC, a recommender system rooted in software engineering design principles, which delivers explainable, cross-layer resource recommendations directly into operator workflows (such as tickets and GitOps pull requests). ARRC encapsulates optimization logic in specialized, auditable agents coordinated via a shared interface, supporting maintainability and extensibility through transparency and the ability to inspect both recommendations and their rationale.
  Empirical evaluation in a multi-region industrial deployment shows that ARRC reduces operator workload by over 50%, improves compute utilization by up to 7.7x, and maintains error rates below 5%, with most benefits achieved through incremental, operator-approved changes. This demonstrates that explainable, recommendation-based architectures can achieve sustainable efficiency and maintainability improvements at production scale.
  ARRC provides an empirically evaluated framework for integrating explainable, workflow-driven automation into resource management, intended to advance best practices for robust, maintainable, and transparent edge-cloud continuum platforms.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Contracting with a Mechanism Designer</title>
<link>https://arxiv.org/abs/2507.12054</link>
<guid>https://arxiv.org/abs/2507.12054</guid>
<content:encoded><![CDATA[
arXiv:2507.12054v1 Announce Type: new 
Abstract: This paper explores the economic interactions within modern crowdsourcing markets. In these markets, employers issue requests for tasks, platforms facilitate the recruitment of crowd workers, and workers complete tasks for monetary rewards. Recognizing that these roles serve distinct functions within the ecosystem, we introduce a three-party model that distinguishes among the principal (the requester), the intermediary (the platform), and the pool of agents (the workers). The principal, unable to directly engage with agents, relies on the intermediary to recruit and incentivize them. This interaction unfolds in two stages: first, the principal designs a profit-sharing contract with the intermediary; second, the intermediary implements a mechanism to select an agent to complete the delegated task.
  We analyze the proposed model as an extensive-form Stackelberg game. Our contributions are fourfold: (1) We fully characterize the subgame perfect equilibrium. In particular, we reduce the principal's contract design problem to a novel auction-theoretic formulation we term virtual value pricing, and reveals that linear contracts are optimal even when the task have multiple outcomes and agents' cost distributions are asymmetric. (2) To quantify the principal's utility loss from delegation and information asymmetry, we introduce the price of double marginalization (PoDM) and the classical price of anarchy (PoA), and derive tight or nearly tight bounds on both ratios under regular and monotone hazard rate (MHR) distributions. (3) We further examine these two ratios in a natural setting where the intermediary is restricted to anonymous pricing mechanisms, and show that similar qualitative insights continue to hold. (4) Finally, we extend our results on both ratios to a robust framework that accommodates scenarios in which the principal lacks precise information about the market size.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating the Ability of Large Language Models to Reason about Cardinal Directions, Revisited</title>
<link>https://arxiv.org/abs/2507.12059</link>
<guid>https://arxiv.org/abs/2507.12059</guid>
<content:encoded><![CDATA[
arXiv:2507.12059v1 Announce Type: new 
Abstract: We investigate the abilities of 28 Large language Models (LLMs) to reason about cardinal directions (CDs) using a benchmark generated from a set of templates, extensively testing an LLM's ability to determine the correct CD given a particular scenario. The templates allow for a number of degrees of variation such as means of locomotion of the agent involved, and whether set in the first, second or third person. Even the newer Large Reasoning Models are unable to reliably determine the correct CD for all questions. This paper summarises and extends earlier work presented at COSIT-24.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Foresight in Motion: Reinforcing Trajectory Prediction with Reward Heuristics</title>
<link>https://arxiv.org/abs/2507.12083</link>
<guid>https://arxiv.org/abs/2507.12083</guid>
<content:encoded><![CDATA[
arXiv:2507.12083v1 Announce Type: new 
Abstract: Motion forecasting for on-road traffic agents presents both a significant challenge and a critical necessity for ensuring safety in autonomous driving systems. In contrast to most existing data-driven approaches that directly predict future trajectories, we rethink this task from a planning perspective, advocating a "First Reasoning, Then Forecasting" strategy that explicitly incorporates behavior intentions as spatial guidance for trajectory prediction. To achieve this, we introduce an interpretable, reward-driven intention reasoner grounded in a novel query-centric Inverse Reinforcement Learning (IRL) scheme. Our method first encodes traffic agents and scene elements into a unified vectorized representation, then aggregates contextual features through a query-centric paradigm. This enables the derivation of a reward distribution, a compact yet informative representation of the target agent's behavior within the given scene context via IRL. Guided by this reward heuristic, we perform policy rollouts to reason about multiple plausible intentions, providing valuable priors for subsequent trajectory generation. Finally, we develop a hierarchical DETR-like decoder integrated with bidirectional selective state space models to produce accurate future trajectories along with their associated probabilities. Extensive experiments on the large-scale Argoverse and nuScenes motion forecasting datasets demonstrate that our approach significantly enhances trajectory prediction confidence, achieving highly competitive performance relative to state-of-the-art methods.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Topology Enhanced MARL for Multi-Vehicle Cooperative Decision-Making of CAVs</title>
<link>https://arxiv.org/abs/2507.12110</link>
<guid>https://arxiv.org/abs/2507.12110</guid>
<content:encoded><![CDATA[
arXiv:2507.12110v1 Announce Type: new 
Abstract: The exploration-exploitation trade-off constitutes one of the fundamental challenges in reinforcement learning (RL), which is exacerbated in multi-agent reinforcement learning (MARL) due to the exponential growth of joint state-action spaces. This paper proposes a topology-enhanced MARL (TPE-MARL) method for optimizing cooperative decision-making of connected and autonomous vehicles (CAVs) in mixed traffic. This work presents two primary contributions: First, we construct a game topology tensor for dynamic traffic flow, effectively compressing high-dimensional traffic state information and decrease the search space for MARL algorithms. Second, building upon the designed game topology tensor and using QMIX as the backbone RL algorithm, we establish a topology-enhanced MARL framework incorporating visit counts and agent mutual information. Extensive simulations across varying traffic densities and CAV penetration rates demonstrate the effectiveness of TPE-MARL. Evaluations encompassing training dynamics, exploration patterns, macroscopic traffic performance metrics, and microscopic vehicle behaviors reveal that TPE-MARL successfully balances exploration and exploitation. Consequently, it exhibits superior performance in terms of traffic efficiency, safety, decision smoothness, and task completion. Furthermore, the algorithm demonstrates decision-making rationality comparable to or exceeding that of human drivers in both mixed-autonomy and fully autonomous traffic scenarios. Code of our work is available at \href{https://github.com/leoPub/tpemarl}{https://github.com/leoPub/tpemarl}.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fast and Scalable Game-Theoretic Trajectory Planning with Intentional Uncertainties</title>
<link>https://arxiv.org/abs/2507.12174</link>
<guid>https://arxiv.org/abs/2507.12174</guid>
<content:encoded><![CDATA[
arXiv:2507.12174v1 Announce Type: new 
Abstract: Trajectory planning involving multi-agent interactions has been a long-standing challenge in the field of robotics, primarily burdened by the inherent yet intricate interactions among agents. While game-theoretic methods are widely acknowledged for their effectiveness in managing multi-agent interactions, significant impediments persist when it comes to accommodating the intentional uncertainties of agents. In the context of intentional uncertainties, the heavy computational burdens associated with existing game-theoretic methods are induced, leading to inefficiencies and poor scalability. In this paper, we propose a novel game-theoretic interactive trajectory planning method to effectively address the intentional uncertainties of agents, and it demonstrates both high efficiency and enhanced scalability. As the underpinning basis, we model the interactions between agents under intentional uncertainties as a general Bayesian game, and we show that its agent-form equivalence can be represented as a potential game under certain minor assumptions. The existence and attainability of the optimal interactive trajectories are illustrated, as the corresponding Bayesian Nash equilibrium can be attained by optimizing a unified optimization problem. Additionally, we present a distributed algorithm based on the dual consensus alternating direction method of multipliers (ADMM) tailored to the parallel solving of the problem, thereby significantly improving the scalability. The attendant outcomes from simulations and experiments demonstrate that the proposed method is effective across a range of scenarios characterized by general forms of intentional uncertainties. Its scalability surpasses that of existing centralized and decentralized baselines, allowing for real-time interactive trajectory planning in uncertain game settings.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward a Behavioural Translation Style Space: Simulating the Temporal Dynamics of Affect, Behaviour, and Cognition in Human Translation Production</title>
<link>https://arxiv.org/abs/2507.12208</link>
<guid>https://arxiv.org/abs/2507.12208</guid>
<content:encoded><![CDATA[
arXiv:2507.12208v1 Announce Type: new 
Abstract: The paper introduces a Behavioural Translation Style Space (BTSS) that describes possible behavioural translation patterns. The suggested BTSS is organized as a hierarchical structure that entails various embedded processing layers. We posit that observable translation behaviour - i.e., eye and finger movements - is fundamental when executing the physical act of translation but it is caused and shaped by higher-order cognitive processes and affective translation states. We analyse records of keystrokes and gaze data as indicators of the hidden mental processing structure and organize the behavioural patterns as a multi-layered embedded BTSS. The BTSS serves as the basis for a computational translation agent to simulate the temporal dynamics of affect, automatized behaviour and cognition during human translation production.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Infherno: End-to-end Agent-based FHIR Resource Synthesis from Free-form Clinical Notes</title>
<link>https://arxiv.org/abs/2507.12261</link>
<guid>https://arxiv.org/abs/2507.12261</guid>
<content:encoded><![CDATA[
arXiv:2507.12261v1 Announce Type: new 
Abstract: For clinical data integration and healthcare services, the HL7 FHIR standard has established itself as a desirable format for interoperability between complex health data. Previous attempts at automating the translation from free-form clinical notes into structured FHIR resources rely on modular, rule-based systems or LLMs with instruction tuning and constrained decoding. Since they frequently suffer from limited generalizability and structural inconformity, we propose an end-to-end framework powered by LLM agents, code execution, and healthcare terminology database tools to address these issues. Our solution, called Infherno, is designed to adhere to the FHIR document schema and competes well with a human baseline in predicting FHIR resources from unstructured text. The implementation features a front end for custom and synthetic data and both local and proprietary models, supporting clinical data integration processes and interoperability across institutions.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GitChameleon: Evaluating AI Code Generation Against Python Library Version Incompatibilities</title>
<link>https://arxiv.org/abs/2507.12367</link>
<guid>https://arxiv.org/abs/2507.12367</guid>
<content:encoded><![CDATA[
arXiv:2507.12367v1 Announce Type: new 
Abstract: The rapid evolution of software libraries poses a considerable hurdle for code generation, necessitating continuous adaptation to frequent version updates while preserving backward compatibility. While existing code evolution benchmarks provide valuable insights, they typically lack execution-based evaluation for generating code compliant with specific library versions. To address this, we introduce GitChameleon, a novel, meticulously curated dataset comprising 328 Python code completion problems, each conditioned on specific library versions and accompanied by executable unit tests. GitChameleon rigorously evaluates the capacity of contemporary large language models (LLMs), LLM-powered agents, code assistants, and RAG systems to perform version-conditioned code generation that demonstrates functional accuracy through execution. Our extensive evaluations indicate that state-of-the-art systems encounter significant challenges with this task; enterprise models achieving baseline success rates in the 48-51\% range, underscoring the intricacy of the problem. By offering an execution-based benchmark emphasizing the dynamic nature of code libraries, GitChameleon enables a clearer understanding of this challenge and helps guide the development of more adaptable and dependable AI code generation methods. We make the dataset and evaluation code publicly available at https://github.com/mrcabbage972/GitChameleonBenchmark.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Single Models: Enhancing LLM Detection of Ambiguity in Requests through Debate</title>
<link>https://arxiv.org/abs/2507.12370</link>
<guid>https://arxiv.org/abs/2507.12370</guid>
<content:encoded><![CDATA[
arXiv:2507.12370v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated significant capabilities in understanding and generating human language, contributing to more natural interactions with complex systems. However, they face challenges such as ambiguity in user requests processed by LLMs. To address these challenges, this paper introduces and evaluates a multi-agent debate framework designed to enhance detection and resolution capabilities beyond single models. The framework consists of three LLM architectures (Llama3-8B, Gemma2-9B, and Mistral-7B variants) and a dataset with diverse ambiguities. The debate framework markedly enhanced the performance of Llama3-8B and Mistral-7B variants over their individual baselines, with Mistral-7B-led debates achieving a notable 76.7% success rate and proving particularly effective for complex ambiguities and efficient consensus. While acknowledging varying model responses to collaborative strategies, these findings underscore the debate framework's value as a targeted method for augmenting LLM capabilities. This work offers important insights for developing more robust and adaptive language understanding systems by showing how structured debates can lead to improved clarity in interactive systems.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modeling Feasible Locomotion of Nanobots for Cancer Detection and Treatment</title>
<link>https://arxiv.org/abs/2507.12400</link>
<guid>https://arxiv.org/abs/2507.12400</guid>
<content:encoded><![CDATA[
arXiv:2507.12400v1 Announce Type: new 
Abstract: Deploying motile nanosized particles, also known as ``nanobots'', in the human body promises to improve selectivity in drug delivery and reduce side effects. We consider a swarm of nanobots locating a single cancerous region and treating it by releasing an onboard payload of drugs at the site. At nanoscale, the computation, communication, sensing, and locomotion capabilities of individual agents are extremely limited, noisy, and/or nonexistent.
  We present a general model to formally describe the individual and collective behavior of agents in a colloidal environment, such as the bloodstream, for cancer detection and treatment by nanobots. This includes a feasible and precise model of agent locomotion, inspired by actual nanoparticles that, in the presence of an external chemical gradient, move towards areas of higher concentration by means of self-propulsion. We present two variants of our general model: The first assumes an endogenous chemical gradient that is fixed over time and centered at the targeted cancer site; the second is a more speculative and dynamic variant in which agents themselves create and amplify a chemical gradient centered at the cancer site. In both settings, agents can sense the gradient and ascend it noisily, locating the cancer site more quickly than via simple Brownian motion.
  For the first variant of the model, we present simulation results to show the behavior of agents under our locomotion model, as well as {analytical results} to bound the time it takes for the agents to reach the cancer site. For the second variant, simulation results highlight the collective benefit in having agents issue their own chemical signal. While arguably more speculative in its agent capability assumptions, this variant shows a significant improvement in runtime performance over the first variant, resulting from its chemical signal amplification mechanism.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing Retrieval-Augmented Generation for Structured Enterprise and Internal Data</title>
<link>https://arxiv.org/abs/2507.12425</link>
<guid>https://arxiv.org/abs/2507.12425</guid>
<content:encoded><![CDATA[
arXiv:2507.12425v1 Announce Type: new 
Abstract: Organizations increasingly rely on proprietary enterprise data, including HR records, structured reports, and tabular documents, for critical decision-making. While Large Language Models (LLMs) have strong generative capabilities, they are limited by static pretraining, short context windows, and challenges in processing heterogeneous data formats. Conventional Retrieval-Augmented Generation (RAG) frameworks address some of these gaps but often struggle with structured and semi-structured data.
  This work proposes an advanced RAG framework that combines hybrid retrieval strategies using dense embeddings (all-mpnet-base-v2) and BM25, enhanced by metadata-aware filtering with SpaCy NER and cross-encoder reranking. The framework applies semantic chunking to maintain textual coherence and retains tabular data structures to preserve row-column integrity. Quantized indexing optimizes retrieval efficiency, while human-in-the-loop feedback and conversation memory improve adaptability.
  Experiments on enterprise datasets show notable improvements: Precision@5 increased by 15 percent (90 versus 75), Recall@5 by 13 percent (87 versus 74), and Mean Reciprocal Rank by 16 percent (0.85 versus 0.69). Qualitative evaluations show higher scores in Faithfulness (4.6 versus 3.0), Completeness (4.2 versus 2.5), and Relevance (4.5 versus 3.2) on a 5-point Likert scale. These results demonstrate the framework's effectiveness in delivering accurate, comprehensive, and contextually relevant responses for enterprise tasks. Future work includes extending to multimodal data and integrating agent-based retrieval. The source code will be released at https://github.com/CheerlaChandana/Enterprise-Chatbot
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large-scale distributed synchronization systems, using a cancel-on-completion redundancy mechanism</title>
<link>https://arxiv.org/abs/2507.11779</link>
<guid>https://arxiv.org/abs/2507.11779</guid>
<content:encoded><![CDATA[
arXiv:2507.11779v1 Announce Type: cross 
Abstract: We consider a class of multi-agent distributed synchronization systems, which are modeled as $n$ particles moving on the real line. This class generalizes the model of a multi-server queueing system, considered in [15], employing so-called cancel-on-completion (c.o.c.) redundancy mechanism, but is motivated by other applications as well. The model in [15] is a particle system, regulated at the left boundary point. The more general model of this paper is such that we allow regulation boundaries on either side, or both sides, or no regulation at all. We consider the mean-field asymptotic regime, when the number of particles $n$ and the job arrival rates go to infinity, while the job arrival rates per particle remain constant. The results include: the existence/uniqueness of fixed points of mean-field limits (ML), which describe the limiting dynamics of the system; conditions for the steady-state asymptotic independence (concentration, as $n \to\infty$, of the stationary distribution on a single state, which is necessarily an ML fixed point); the limits, as $n \to\infty$, of the average velocity at which unregulated (free) particle system advances. In particular, our results for the left-regulated system unify and generalize the corresponding results in [15]. Our technical development is such that the systems with different types of regulation are analyzed within a unified framework. In particular, these systems are used as tools for analysis of each other.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BenchRL-QAS: Benchmarking reinforcement learning algorithms for quantum architecture search</title>
<link>https://arxiv.org/abs/2507.12189</link>
<guid>https://arxiv.org/abs/2507.12189</guid>
<content:encoded><![CDATA[
arXiv:2507.12189v1 Announce Type: cross 
Abstract: We introduce BenchRL-QAS, a unified benchmarking framework for systematically evaluating reinforcement learning (RL) algorithms in quantum architecture search (QAS) across diverse variational quantum algorithm tasks and system sizes ranging from 2- to 8-qubit. Our study benchmarks nine RL agents including both value-based and policy-gradient methods on representative quantum problems such as variational quantum eigensolver, variational quantum state diagonalization, quantum classification, and state preparation, spanning both noiseless and realistic noisy regimes. We propose a weighted ranking metric that balances accuracy, circuit depth, gate count, and computational efficiency, enabling fair and comprehensive comparison. Our results first reveal that RL-based quantum classifier outperforms baseline variational classifiers. Then we conclude that no single RL algorithm is universally optimal when considering a set of QAS tasks; algorithmic performance is highly context-dependent, varying with task structure, qubit count, and noise. This empirical finding provides strong evidence for the "no free lunch" principle in RL-based quantum circuit design and highlights the necessity of tailored algorithm selection and systematic benchmarking for advancing quantum circuit synthesis. This work represents the most comprehensive RL-QAS benchmarking effort to date, and BenchRL-QAS along with all experimental data are made publicly available to support reproducibility and future research https://github.com/azhar-ikhtiarudin/bench-rlqas.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Trust in Autonomous Agents: An Architecture for Accountability and Explainability through Blockchain and Large Language Models</title>
<link>https://arxiv.org/abs/2403.09567</link>
<guid>https://arxiv.org/abs/2403.09567</guid>
<content:encoded><![CDATA[
arXiv:2403.09567v4 Announce Type: replace 
Abstract: The deployment of autonomous agents in environments involving human interaction has increasingly raised security concerns. Consequently, understanding the circumstances behind an event becomes critical, requiring the development of capabilities to justify their behaviors to non-expert users. Such explanations are essential in enhancing trustworthiness and safety, acting as a preventive measure against failures, errors, and misunderstandings. Additionally, they contribute to improving communication, bridging the gap between the agent and the user, thereby improving the effectiveness of their interactions. This work presents an accountability and explainability architecture implemented for ROS-based mobile robots. The proposed solution consists of two main components. Firstly, a black box-like element to provide accountability, featuring anti-tampering properties achieved through blockchain technology. Secondly, a component in charge of generating natural language explanations by harnessing the capabilities of Large Language Models (LLMs) over the data contained within the previously mentioned black box. The study evaluates the performance of our solution in three different scenarios, each involving autonomous agent navigation functionalities. This evaluation includes a thorough examination of accountability and explainability metrics, demonstrating the effectiveness of our approach in using accountable data from robot actions to obtain coherent, accurate and understandable explanations, even when facing challenges inherent in the use of autonomous agents in real-world scenarios.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proactive Agents for Multi-Turn Text-to-Image Generation Under Uncertainty</title>
<link>https://arxiv.org/abs/2412.06771</link>
<guid>https://arxiv.org/abs/2412.06771</guid>
<content:encoded><![CDATA[
arXiv:2412.06771v2 Announce Type: replace 
Abstract: User prompts for generative AI models are often underspecified, leading to a misalignment between the user intent and models' understanding. As a result, users commonly have to painstakingly refine their prompts. We study this alignment problem in text-to-image (T2I) generation and propose a prototype for proactive T2I agents equipped with an interface to (1) actively ask clarification questions when uncertain, and (2) present their uncertainty about user intent as an understandable and editable belief graph. We build simple prototypes for such agents and propose a new scalable and automated evaluation approach using two agents, one with a ground truth intent (an image) while the other tries to ask as few questions as possible to align with the ground truth. We experiment over three image-text datasets: ImageInWords (Garg et al., 2024), COCO (Lin et al., 2014) and DesignBench, a benchmark we curated with strong artistic and design elements. Experiments over the three datasets demonstrate the proposed T2I agents' ability to ask informative questions and elicit crucial information to achieve successful alignment with at least 2 times higher VQAScore (Lin et al., 2024) than the standard T2I generation. Moreover, we conducted human studies and observed that at least 90% of human subjects found these agents and their belief graphs helpful for their T2I workflow, highlighting the effectiveness of our approach. Code and DesignBench can be found at https://github.com/google-deepmind/proactive_t2i_agents.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Emergent Communication: Large Language Model is a Collective World Model</title>
<link>https://arxiv.org/abs/2501.00226</link>
<guid>https://arxiv.org/abs/2501.00226</guid>
<content:encoded><![CDATA[
arXiv:2501.00226v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated a remarkable ability to capture extensive world knowledge, yet how this is achieved without direct sensorimotor experience remains a fundamental puzzle. This study proposes a novel theoretical solution by introducing the Collective World Model hypothesis. We argue that an LLM does not learn a world model from scratch; instead, it learns a statistical approximation of a collective world model that is already implicitly encoded in human language through a society-wide process of embodied, interactive sense-making. To formalize this process, we introduce generative emergent communication (Generative EmCom), a framework built on the Collective Predictive Coding (CPC). This framework models the emergence of language as a process of decentralized Bayesian inference over the internal states of multiple agents. We argue that this process effectively creates an encoder-decoder structure at a societal scale: human society collectively encodes its grounded, internal representations into language, and an LLM subsequently decodes these symbols to reconstruct a latent space that mirrors the structure of the original collective representations. This perspective provides a principled, mathematical explanation for how LLMs acquire their capabilities. The main contributions of this paper are: 1) the formalization of the Generative EmCom framework, clarifying its connection to world models and multi-agent reinforcement learning, and 2) its application to interpret LLMs, explaining phenomena such as distributional semantics as a natural consequence of representation reconstruction. This work provides a unified theory that bridges individual cognitive development, collective language evolution, and the foundations of large-scale AI.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Reason at the Frontier of Learnability</title>
<link>https://arxiv.org/abs/2502.12272</link>
<guid>https://arxiv.org/abs/2502.12272</guid>
<content:encoded><![CDATA[
arXiv:2502.12272v4 Announce Type: replace 
Abstract: Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning with LLMs.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews</title>
<link>https://arxiv.org/abs/2503.08506</link>
<guid>https://arxiv.org/abs/2503.08506</guid>
<content:encoded><![CDATA[
arXiv:2503.08506v3 Announce Type: replace 
Abstract: Academic paper review is a critical yet time-consuming task within the research community. With the increasing volume of academic publications, automating the review process has become a significant challenge. The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments. In this paper, we address this challenge by proposing ReviewAgents, a framework that leverages large language models (LLMs) to generate academic paper reviews. We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents. This dataset emulates the structured reasoning process of human reviewers-summarizing the paper, referencing relevant works, identifying strengths and weaknesses, and generating a review conclusion. Building upon this, we train LLM reviewer agents capable of structured reasoning using a relevant-paper-aware training method. Furthermore, we construct ReviewAgents, a multi-role, multi-LLM agent review framework, to enhance the review comment generation process. Additionally, we propose ReviewBench, a benchmark for evaluating the review comments generated by LLMs. Our experimental results on ReviewBench demonstrate that while existing LLMs exhibit a certain degree of potential for automating the review process, there remains a gap when compared to human-generated reviews. Moreover, our ReviewAgents framework further narrows this gap, outperforming advanced LLMs in generating review comments.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HIS-GPT: Towards 3D Human-In-Scene Multimodal Understanding</title>
<link>https://arxiv.org/abs/2503.12955</link>
<guid>https://arxiv.org/abs/2503.12955</guid>
<content:encoded><![CDATA[
arXiv:2503.12955v2 Announce Type: replace 
Abstract: We propose a new task to benchmark human-in-scene understanding for embodied agents: Human-In-Scene Question Answering (HIS-QA). Given a human motion within a 3D scene, HIS-QA requires the agent to comprehend human states and behaviors, reason about its surrounding environment, and answer human-related questions within the scene. To support this new task, we present HIS-Bench, a multimodal benchmark that systematically evaluates HIS understanding across a broad spectrum, from basic perception to commonsense reasoning and planning. Our evaluation of various vision-language models on HIS-Bench reveals significant limitations in their ability to handle HIS-QA tasks. To this end, we propose HIS-GPT, the first foundation model for HIS understanding. HIS-GPT integrates 3D scene context and human motion dynamics into large language models while incorporating specialized mechanisms to capture human-scene interactions. Extensive experiments demonstrate that HIS-GPT sets a new state-of-the-art on HIS-QA tasks. We hope this work inspires future research on human behavior analysis in 3D scenes, advancing embodied AI and world models. The codes and data: https://github.com/ZJHTerry18/HumanInScene.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Frontiers in LLM Reasoning: Inference Scaling, Learning to Reason, and Agentic Systems</title>
<link>https://arxiv.org/abs/2504.09037</link>
<guid>https://arxiv.org/abs/2504.09037</guid>
<content:encoded><![CDATA[
arXiv:2504.09037v2 Announce Type: replace 
Abstract: Reasoning is a fundamental cognitive process that enables logical inference, problem-solving, and decision-making. With the rapid advancement of large language models (LLMs), reasoning has emerged as a key capability that distinguishes advanced AI systems from conventional models that empower chatbots. In this survey, we categorize existing methods along two orthogonal dimensions: (1) Regimes, which define the stage at which reasoning is achieved (either at inference time or through dedicated training); and (2) Architectures, which determine the components involved in the reasoning process, distinguishing between standalone LLMs and agentic compound systems that incorporate external tools, and multi-agent collaborations. Within each dimension, we analyze two key perspectives: (1) Input level, which focuses on techniques that construct high-quality prompts that the LLM condition on; and (2) Output level, which methods that refine multiple sampled candidates to enhance reasoning quality. This categorization provides a systematic understanding of the evolving landscape of LLM reasoning, highlighting emerging trends such as the shift from inference-scaling to learning-to-reason (e.g., DeepSeek-R1), and the transition to agentic workflows (e.g., OpenAI Deep Research, Manus Agent). Additionally, we cover a broad spectrum of learning algorithms, from supervised fine-tuning to reinforcement learning such as PPO and GRPO, and the training of reasoners and verifiers. We also examine key designs of agentic workflows, from established patterns like generator-evaluator and LLM debate to recent innovations. ...
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MobileCity: An Efficient Framework for Large-Scale Urban Behavior Simulation</title>
<link>https://arxiv.org/abs/2504.16946</link>
<guid>https://arxiv.org/abs/2504.16946</guid>
<content:encoded><![CDATA[
arXiv:2504.16946v2 Announce Type: replace 
Abstract: Generative agents offer promising capabilities for simulating realistic urban behaviors. However, existing methods oversimplify transportation choices, rely heavily on static agent profiles leading to behavioral homogenization, and inherit prohibitive computational costs. To address these limitations, we present MobileCity, a lightweight simulation platform designed to model realistic urban mobility with high computational efficiency. We introduce a comprehensive transportation system with multiple transport modes, and collect questionnaire data from respondents to construct agent profiles. To enable scalable simulation, agents perform action selection within a pre-generated action space and uses local models for efficient agent memory generation. Through extensive micro and macro-level evaluations on 4,000 agents, we demonstrate that MobileCity generates more realistic urban behaviors than baselines while maintaining computational efficiency. We further explore practical applications such as predicting movement patterns and analyzing demographic trends in transportation preferences.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TD-EVAL: Revisiting Task-Oriented Dialogue Evaluation by Combining Turn-Level Precision with Dialogue-Level Comparisons</title>
<link>https://arxiv.org/abs/2504.19982</link>
<guid>https://arxiv.org/abs/2504.19982</guid>
<content:encoded><![CDATA[
arXiv:2504.19982v2 Announce Type: replace 
Abstract: Task-oriented dialogue (TOD) systems are experiencing a revolution driven by Large Language Models (LLMs), yet the evaluation methodologies for these systems remain insufficient for their growing sophistication. While traditional automatic metrics effectively assessed earlier modular systems, they focus solely on the dialogue level and cannot detect critical intermediate errors that can arise during user-agent interactions. In this paper, we introduce TD-EVAL (Turn and Dialogue-level Evaluation), a two-step evaluation framework that unifies fine-grained turn-level analysis with holistic dialogue-level comparisons. At turn level, we evaluate each response along three TOD-specific dimensions: conversation cohesion, backend knowledge consistency, and policy compliance. Meanwhile, we design TOD Agent Arena that uses pairwise comparisons to provide a measure of dialogue-level quality. Through experiments on MultiWOZ 2.4 and {\tau}-Bench, we demonstrate that TD-EVAL effectively identifies the conversational errors that conventional metrics miss. Furthermore, TD-EVAL exhibits better alignment with human judgments than traditional and LLM-based metrics. These findings demonstrate that TD-EVAL introduces a new paradigm for TOD system evaluation, efficiently assessing both turn and system levels with a plug-and-play framework for future research.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reconfigurable legged metamachines that run on autonomous modular legs</title>
<link>https://arxiv.org/abs/2505.00784</link>
<guid>https://arxiv.org/abs/2505.00784</guid>
<content:encoded><![CDATA[
arXiv:2505.00784v2 Announce Type: replace 
Abstract: Legged machines are becoming increasingly agile and adaptive but they have so far lacked the morphological diversity of legged animals, which have been rearranged and reshaped to fill millions of niches. Unlike their biological counterparts, legged machines have largely converged over the past decade to canonical quadrupedal and bipedal architectures that cannot be easily reconfigured to meet new tasks or recover from injury. Here we introduce autonomous modular legs: agile yet minimal, single-degree-of-freedom jointed links that can learn complex dynamic behaviors and may be freely attached to form legged metamachines at the meter scale. This enables rapid repair, redesign, and recombination of highly-dynamic modular agents that move quickly and acrobatically (non-quasistatically) through unstructured environments. Because each module is itself a complete agent, legged metamachines are able to sustain deep structural damage that would completely disable other legged robots. We also show how to encode the vast space of possible body configurations into a compact latent design genome that can be efficiently explored, revealing a wide diversity of novel legged forms.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient and Direct Duplex Modeling for Speech-to-Speech Language Model</title>
<link>https://arxiv.org/abs/2505.15670</link>
<guid>https://arxiv.org/abs/2505.15670</guid>
<content:encoded><![CDATA[
arXiv:2505.15670v3 Announce Type: replace 
Abstract: Spoken dialogue is an intuitive form of human-computer interaction, yet current speech language models often remain constrained to turn-based exchanges, lacking real-time adaptability such as user barge-in. We propose a novel duplex speech to speech (S2S) architecture featuring continuous user inputs and codec agent outputs with channel fusion that directly models simultaneous user and agent streams. Using a pretrained streaming encoder for user input enables the first duplex S2S model without requiring speech pretrain. Separate architectures for agent and user modeling facilitate codec fine-tuning for better agent voices and halve the bitrate (0.6 kbps) compared to previous works. Experimental results show that the proposed model outperforms previous duplex models in reasoning, turn-taking, and barge-in abilities. The model requires significantly less speech data, as speech pretrain is skipped, which markedly simplifies the process of building a duplex S2S model from any LLMs. Finally, it is the first openly available duplex S2S model with training and inference code to foster reproducibility.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Risk Assessments for Offensive Cybersecurity Agents</title>
<link>https://arxiv.org/abs/2505.18384</link>
<guid>https://arxiv.org/abs/2505.18384</guid>
<content:encoded><![CDATA[
arXiv:2505.18384v3 Announce Type: replace 
Abstract: Foundation models are increasingly becoming better autonomous programmers, raising the prospect that they could also automate dangerous offensive cyber-operations. Current frontier model audits probe the cybersecurity risks of such agents, but most fail to account for the degrees of freedom available to adversaries in the real world. In particular, with strong verifiers and financial incentives, agents for offensive cybersecurity are amenable to iterative improvement by would-be adversaries. We argue that assessments should take into account an expanded threat model in the context of cybersecurity, emphasizing the varying degrees of freedom that an adversary may possess in stateful and non-stateful environments within a fixed compute budget. We show that even with a relatively small compute budget (8 H100 GPU Hours in our study), adversaries can improve an agent's cybersecurity capability on InterCode CTF by more than 40\% relative to the baseline -- without any external assistance. These results highlight the need to evaluate agents' cybersecurity risk in a dynamic manner, painting a more representative picture of risk.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models Often Know When They Are Being Evaluated</title>
<link>https://arxiv.org/abs/2505.23836</link>
<guid>https://arxiv.org/abs/2505.23836</guid>
<content:encoded><![CDATA[
arXiv:2505.23836v3 Announce Type: replace 
Abstract: If AI models can detect when they are being evaluated, the effectiveness of evaluations might be compromised. For example, models could have systematically different behavior during evaluations, leading to less reliable benchmarks for deployment and governance decisions. We investigate whether frontier language models can accurately classify transcripts based on whether they originate from evaluations or real-world deployment, a capability we call evaluation awareness. To achieve this, we construct a diverse benchmark of 1,000 prompts and transcripts from 61 distinct datasets. These span public benchmarks (e.g., MMLU, SWEBench), real-world deployment interactions, and agent trajectories from scaffolding frameworks (e.g., web-browsing agents). Frontier models clearly demonstrate above-random evaluation awareness (Gemini-2.5-Pro reaches an AUC of $0.83$), but do not yet surpass our simple human baseline (AUC of $0.92$). Furthermore, both AI models and humans are better at identifying evaluations in agentic settings compared to chat settings. Additionally, we test whether models can identify the purpose of the evaluation. Under multiple-choice and open-ended questioning, AI models far outperform random chance in identifying what an evaluation is testing for. Our results indicate that frontier models already exhibit a substantial, though not yet superhuman, level of evaluation-awareness. We recommend tracking this capability in future models.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>macOSWorld: A Multilingual Interactive Benchmark for GUI Agents</title>
<link>https://arxiv.org/abs/2506.04135</link>
<guid>https://arxiv.org/abs/2506.04135</guid>
<content:encoded><![CDATA[
arXiv:2506.04135v3 Announce Type: replace 
Abstract: Graphical User Interface (GUI) agents show promising capabilities for automating computer-use tasks and facilitating accessibility, but existing interactive benchmarks are mostly English-only, covering web-use or Windows, Linux, and Android environments, but not macOS. macOS is a major OS with distinctive GUI patterns and exclusive applications. To bridge the gaps, we present macOSWorld, the first comprehensive benchmark for evaluating GUI agents on macOS. macOSWorld features 202 multilingual interactive tasks across 30 applications (28 macOS-exclusive), with task instructions and OS interfaces offered in 5 languages (English, Chinese, Arabic, Japanese, and Russian). As GUI agents are shown to be vulnerable to deception attacks, macOSWorld also includes a dedicated safety benchmarking subset. Our evaluation on six GUI agents reveals a dramatic gap: proprietary computer-use agents lead at above 30% success rate, while open-source lightweight research models lag at below 5%, highlighting the need for macOS domain adaptation. Multilingual benchmarks also expose common weaknesses, especially in Arabic, with a 28.8% average degradation compared to English. Results from safety benchmarking also highlight that deception attacks are more general and demand immediate attention. macOSWorld is available at https://github.com/showlab/macosworld.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MARL-MambaContour: Unleashing Multi-Agent Deep Reinforcement Learning for Active Contour Optimization in Medical Image Segmentation</title>
<link>https://arxiv.org/abs/2506.18679</link>
<guid>https://arxiv.org/abs/2506.18679</guid>
<content:encoded><![CDATA[
arXiv:2506.18679v2 Announce Type: replace 
Abstract: We introduce MARL-MambaContour, the first contour-based medical image segmentation framework based on Multi-Agent Reinforcement Learning (MARL). Our approach reframes segmentation as a multi-agent cooperation task focused on generate topologically consistent object-level contours, addressing the limitations of traditional pixel-based methods which could lack topological constraints and holistic structural awareness of anatomical regions. Each contour point is modeled as an autonomous agent that iteratively adjusts its position to align precisely with the target boundary, enabling adaptation to blurred edges and intricate morphologies common in medical images. This iterative adjustment process is optimized by a contour-specific Soft Actor-Critic (SAC) algorithm, further enhanced with the Entropy Regularization Adjustment Mechanism (ERAM) which dynamically balance agent exploration with contour smoothness. Furthermore, the framework incorporates a Mamba-based policy network featuring a novel Bidirectional Cross-attention Hidden-state Fusion Mechanism (BCHFM). This mechanism mitigates potential memory confusion limitations associated with long-range modeling in state space models, thereby facilitating more accurate inter-agent information exchange and informed decision-making. Extensive experiments on five diverse medical imaging datasets demonstrate the state-of-the-art performance of MARL-MambaContour, highlighting its potential as an accurate and robust clinical application.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAMEP: A Secure Protocol for Persistent Context Sharing Across AI Agents</title>
<link>https://arxiv.org/abs/2507.10562</link>
<guid>https://arxiv.org/abs/2507.10562</guid>
<content:encoded><![CDATA[
arXiv:2507.10562v1 Announce Type: new 
Abstract: Current AI agent architectures suffer from ephemeral memory limitations, preventing effective collaboration and knowledge sharing across sessions and agent boundaries. We introduce SAMEP (Secure Agent Memory Exchange Protocol), a novel framework that enables persistent, secure, and semantically searchable memory sharing among AI agents. Our protocol addresses three critical challenges: (1) persistent context preservation across agent sessions, (2) secure multi-agent collaboration with fine-grained access control, and (3) efficient semantic discovery of relevant historical context. SAMEP implements a distributed memory repository with vector-based semantic search, cryptographic access controls (AES-256-GCM), and standardized APIs compatible with existing agent communication protocols (MCP, A2A). We demonstrate SAMEP's effectiveness across diverse domains including multi-agent software development, healthcare AI with HIPAA compliance, and multi-modal processing pipelines. Experimental results show 73% reduction in redundant computations, 89% improvement in context relevance scores, and complete compliance with regulatory requirements including audit trail generation. SAMEP enables a new paradigm of persistent, collaborative AI agent ecosystems while maintaining security and privacy guarantees.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Mother Tongue: Self-Emergent Communication in MARL via Endogenous Symbol Systems</title>
<link>https://arxiv.org/abs/2507.10566</link>
<guid>https://arxiv.org/abs/2507.10566</guid>
<content:encoded><![CDATA[
arXiv:2507.10566v1 Announce Type: new 
Abstract: In Decentralized Multi-Agent Reinforcement Learning (MARL), the development of Emergent Communication has long been constrained by the ``Joint Exploration Dilemma'', leading agents to fall into a ``Communication Vacuum Equilibrium'' . Traditional methods address this by introducing inductive biases to facilitate communication emergence . This study fundamentally questions whether such artificial inductive biases are, in fact, over-engineering. Through experiments with the ``AI Mother Tongue'' (AIM) framework, based on a Vector Quantized Variational Autoencoder (VQ-VAE), we demonstrate that when agents possess an endogenous symbol system, their neural representations naturally exhibit spontaneous semantic compression and Nash equilibrium-driven semantic convergence, achieving effective symbolic communication without external inductive biases. This aligns with recent neuroscience findings suggesting that the human brain does not directly use human language for internal thought , and resonates with research on ``soft thinking'' capabilities in Large Language Models (LLMs) . Compared to traditional explicit communication methods, AIM demonstrates stronger generality and efficiency. The interpretable analysis toolkit developed in this study confirms that symbol usage exhibits a significant power-law distribution, leading to three major theoretical insights: the ``Neural Communication Hypothesis'', the ``Tool-First Principle'', and the ``Semantic Interpretability Paradigm''. Future research will explore the integration of Hierarchical Quantized Variational Autoencoders (HQ-VAE) to enhance AIM's complex expressive capabilities and investigate the potential for ``Reinforcement Learning (RL) Low-Level Pre-training''. This discovery offers new avenues for bridging symbolism and connectionism.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Orchestrator-Agent Trust: A Modular Agentic AI Visual Classification System with Trust-Aware Orchestration and RAG-Based Reasoning</title>
<link>https://arxiv.org/abs/2507.10571</link>
<guid>https://arxiv.org/abs/2507.10571</guid>
<content:encoded><![CDATA[
arXiv:2507.10571v1 Announce Type: new 
Abstract: Modern Artificial Intelligence (AI) increasingly relies on multi-agent architectures that blend visual and language understanding. Yet, a pressing challenge remains: How can we trust these agents especially in zero-shot settings with no fine-tuning? We introduce a novel modular Agentic AI visual classification framework that integrates generalist multimodal agents with a non-visual reasoning orchestrator and a Retrieval-Augmented Generation (RAG) module. Applied to apple leaf disease diagnosis, we benchmark three configurations: (I) zero-shot with confidence-based orchestration, (II) fine-tuned agents with improved performance, and (III) trust-calibrated orchestration enhanced by CLIP-based image retrieval and re-evaluation loops. Using confidence calibration metrics (ECE, OCR, CCC), the orchestrator modulates trust across agents. Our results demonstrate a 77.94\% accuracy improvement in the zero-shot setting using trust-aware orchestration and RAG, achieving 85.63\% overall. GPT-4o showed better calibration, while Qwen-2.5-VL displayed overconfidence. Furthermore, image-RAG grounded predictions with visually similar cases, enabling correction of agent overconfidence via iterative re-evaluation. The proposed system separates perception (vision agents) from meta-reasoning (orchestrator), enabling scalable and interpretable multi-agent AI. This blueprint is extensible to diagnostics, biology, and other trust-critical domains. All models, prompts, results, and system components including the complete software source code are openly released to support reproducibility, transparency, and community benchmarking at Github: https://github.com/Applied-AI-Research-Lab/Orchestrator-Agent-Trust
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Truth Sleuth and Trend Bender: AI Agents to fact-check YouTube videos and influence opinions</title>
<link>https://arxiv.org/abs/2507.10577</link>
<guid>https://arxiv.org/abs/2507.10577</guid>
<content:encoded><![CDATA[
arXiv:2507.10577v1 Announce Type: new 
Abstract: Misinformation poses a significant threat in today's digital world, often spreading rapidly through platforms like YouTube. This paper introduces a novel approach to combating misinformation by developing an AI-powered system that not only fact-checks claims made in YouTube videos but also actively engages users in the comment section and challenge misleading narratives. Our system comprises two main agents: Truth Sleuth and Trend Bender.
  Truth Sleuth extracts claims from a YouTube video, uses a Retrieval-Augmented Generation (RAG) approach - drawing on sources like Wikipedia, Google Search, Google FactCheck - to accurately assess their veracity and generates a nuanced and comprehensive report. Through rigorous prompt engineering, Trend Bender leverages this report along with a curated corpus of relevant articles to generate insightful and persuasive comments designed to stimulate a productive debate. With a carefully set up self-evaluation loop, this agent is able to iteratively improve its style and refine its output.
  We demonstrate the system's capabilities through experiments on established benchmark datasets and a real-world deployment on YouTube, showcasing its potential to engage users and potentially influence perspectives. Our findings highlight the high accuracy of our fact-checking agent, and confirm the potential of AI-driven interventions in combating misinformation and fostering a more informed online space.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ARPaCCino: An Agentic-RAG for Policy as Code Compliance</title>
<link>https://arxiv.org/abs/2507.10584</link>
<guid>https://arxiv.org/abs/2507.10584</guid>
<content:encoded><![CDATA[
arXiv:2507.10584v1 Announce Type: new 
Abstract: Policy as Code (PaC) is a paradigm that encodes security and compliance policies into machine-readable formats, enabling automated enforcement in Infrastructure as Code (IaC) environments. However, its adoption is hindered by the complexity of policy languages and the risk of misconfigurations. In this work, we present ARPaCCino, an agentic system that combines Large Language Models (LLMs), Retrieval-Augmented-Generation (RAG), and tool-based validation to automate the generation and verification of PaC rules. Given natural language descriptions of the desired policies, ARPaCCino generates formal Rego rules, assesses IaC compliance, and iteratively refines the IaC configurations to ensure conformance. Thanks to its modular agentic architecture and integration with external tools and knowledge bases, ARPaCCino supports policy validation across a wide range of technologies, including niche or emerging IaC frameworks. Experimental evaluation involving a Terraform-based case study demonstrates ARPaCCino's effectiveness in generating syntactically and semantically correct policies, identifying non-compliant infrastructures, and applying corrective modifications, even when using smaller, open-weight LLMs. Our results highlight the potential of agentic RAG architectures to enhance the automation, reliability, and accessibility of PaC workflows.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergence of Hierarchical Emotion Organization in Large Language Models</title>
<link>https://arxiv.org/abs/2507.10599</link>
<guid>https://arxiv.org/abs/2507.10599</guid>
<content:encoded><![CDATA[
arXiv:2507.10599v1 Announce Type: new 
Abstract: As large language models (LLMs) increasingly power conversational agents, understanding how they model users' emotional states is critical for ethical deployment. Inspired by emotion wheels -- a psychological framework that argues emotions organize hierarchically -- we analyze probabilistic dependencies between emotional states in model outputs. We find that LLMs naturally form hierarchical emotion trees that align with human psychological models, and larger models develop more complex hierarchies. We also uncover systematic biases in emotion recognition across socioeconomic personas, with compounding misclassifications for intersectional, underrepresented groups. Human studies reveal striking parallels, suggesting that LLMs internalize aspects of social perception. Beyond highlighting emergent emotional reasoning in LLMs, our results hint at the potential of using cognitively-grounded theories for developing better model evaluations.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LaSM: Layer-wise Scaling Mechanism for Defending Pop-up Attack on GUI Agents</title>
<link>https://arxiv.org/abs/2507.10610</link>
<guid>https://arxiv.org/abs/2507.10610</guid>
<content:encoded><![CDATA[
arXiv:2507.10610v1 Announce Type: new 
Abstract: Graphical user interface (GUI) agents built on multimodal large language models (MLLMs) have recently demonstrated strong decision-making abilities in screen-based interaction tasks. However, they remain highly vulnerable to pop-up-based environmental injection attacks, where malicious visual elements divert model attention and lead to unsafe or incorrect actions. Existing defense methods either require costly retraining or perform poorly under inductive interference. In this work, we systematically study how such attacks alter the attention behavior of GUI agents and uncover a layer-wise attention divergence pattern between correct and incorrect outputs. Based on this insight, we propose \textbf{LaSM}, a \textit{Layer-wise Scaling Mechanism} that selectively amplifies attention and MLP modules in critical layers. LaSM improves the alignment between model saliency and task-relevant regions without additional training. Extensive experiments across 12 types of pop-up perturbations and 4 different model backbones show that LaSM consistently enhances the defense success rate. When combined with prompt-level alerts, LaSM achieves over 98\% robustness even under strong inductive attacks. Our findings reveal that attention misalignment is a core vulnerability in MLLM agents and can be effectively addressed through selective layer-wise modulation.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Meta-Reinforcement Learning for Fast and Data-Efficient Spectrum Allocation in Dynamic Wireless Networks</title>
<link>https://arxiv.org/abs/2507.10619</link>
<guid>https://arxiv.org/abs/2507.10619</guid>
<content:encoded><![CDATA[
arXiv:2507.10619v1 Announce Type: new 
Abstract: The dynamic allocation of spectrum in 5G / 6G networks is critical to efficient resource utilization. However, applying traditional deep reinforcement learning (DRL) is often infeasible due to its immense sample complexity and the safety risks associated with unguided exploration, which can cause severe network interference. To address these challenges, we propose a meta-learning framework that enables agents to learn a robust initial policy and rapidly adapt to new wireless scenarios with minimal data. We implement three meta-learning architectures, model-agnostic meta-learning (MAML), recurrent neural network (RNN), and an attention-enhanced RNN, and evaluate them against a non-meta-learning DRL algorithm, proximal policy optimization (PPO) baseline, in a simulated dynamic integrated access/backhaul (IAB) environment. Our results show a clear performance gap. The attention-based meta-learning agent reaches a peak mean network throughput of 48 Mbps, while the PPO baseline decreased drastically to 10 Mbps. Furthermore, our method reduces SINR and latency violations by more than 50% compared to PPO. It also shows quick adaptation, with a fairness index 0.7, showing better resource allocation. This work proves that meta-learning is a very effective and safer option for intelligent control in complex wireless systems.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game Theory Meets LLM and Agentic AI: Reimagining Cybersecurity for the Age of Intelligent Threats</title>
<link>https://arxiv.org/abs/2507.10621</link>
<guid>https://arxiv.org/abs/2507.10621</guid>
<content:encoded><![CDATA[
arXiv:2507.10621v1 Announce Type: new 
Abstract: Protecting cyberspace requires not only advanced tools but also a shift in how we reason about threats, trust, and autonomy. Traditional cybersecurity methods rely on manual responses and brittle heuristics. To build proactive and intelligent defense systems, we need integrated theoretical frameworks and software tools. Game theory provides a rigorous foundation for modeling adversarial behavior, designing strategic defenses, and enabling trust in autonomous systems. Meanwhile, software tools process cyber data, visualize attack surfaces, verify compliance, and suggest mitigations. Yet a disconnect remains between theory and practical implementation.
  The rise of Large Language Models (LLMs) and agentic AI offers a new path to bridge this gap. LLM-powered agents can operationalize abstract strategies into real-world decisions. Conversely, game theory can inform the reasoning and coordination of these agents across complex workflows. LLMs also challenge classical game-theoretic assumptions, such as perfect rationality or static payoffs, prompting new models aligned with cognitive and computational realities. This co-evolution promises richer theoretical foundations and novel solution concepts. Agentic AI also reshapes software design: systems must now be modular, adaptive, and trust-aware from the outset.
  This chapter explores the intersection of game theory, agentic AI, and cybersecurity. We review key game-theoretic frameworks (e.g., static, dynamic, Bayesian, and signaling games) and solution concepts. We then examine how LLM agents can enhance cyber defense and introduce LLM-driven games that embed reasoning into AI agents. Finally, we explore multi-agent workflows and coordination games, outlining how this convergence fosters secure, intelligent, and adaptive cyber systems.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing the Capabilities of Large Language Models for API calls through Knowledge Graphs</title>
<link>https://arxiv.org/abs/2507.10630</link>
<guid>https://arxiv.org/abs/2507.10630</guid>
<content:encoded><![CDATA[
arXiv:2507.10630v1 Announce Type: new 
Abstract: API calls by large language models (LLMs) offer a cutting-edge approach for data analysis. However, their ability to effectively utilize tools via API calls remains underexplored in knowledge-intensive domains like meteorology. This paper introduces KG2data, a system that integrates knowledge graphs, LLMs, ReAct agents, and tool-use technologies to enable intelligent data acquisition and query handling in the meteorological field. Using a virtual API, we evaluate API call accuracy across three metrics: name recognition failure, hallucination failure, and call correctness. KG2data achieves superior performance (1.43%, 0%, 88.57%) compared to RAG2data (16%, 10%, 72.14%) and chat2data (7.14%, 8.57%, 71.43%). KG2data differs from typical LLM-based systems by addressing their limited access to domain-specific knowledge, which hampers performance on complex or terminology-rich queries. By using a knowledge graph as persistent memory, our system enhances content retrieval, complex query handling, domain-specific reasoning, semantic relationship resolution, and heterogeneous data integration. It also mitigates the high cost of fine-tuning LLMs, making the system more adaptable to evolving domain knowledge and API structures. In summary, KG2data provides a novel solution for intelligent, knowledge-based question answering and data analysis in domains with high knowledge demands.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Semantic Web and MAS to Agentic AI: A Unified Narrative of the Web of Agents</title>
<link>https://arxiv.org/abs/2507.10644</link>
<guid>https://arxiv.org/abs/2507.10644</guid>
<content:encoded><![CDATA[
arXiv:2507.10644v1 Announce Type: new 
Abstract: The concept of the Web of Agents (WoA), which transforms the static, document-centric Web into an environment of autonomous agents acting on users' behalf, has attracted growing interest as large language models (LLMs) become more capable. However, research in this area is still fragmented across different communities. Contemporary surveys catalog the latest LLM-powered frameworks, while the rich histories of Multi-Agent Systems (MAS) and the Semantic Web are often treated as separate, legacy domains. This fragmentation obscures the intellectual lineage of modern systems and hinders a holistic understanding of the field's trajectory. We present the first comprehensive evolutionary overview of the WoA. We show that modern protocols like A2A and the MCP, are direct evolutionary responses to the well-documented limitations of earlier standards like FIPA standards and OWL-based semantic agents. To systematize this analysis, we introduce a four-axis taxonomy (semantic foundation, communication paradigm, locus of intelligence, discovery mechanism). This framework provides a unified analytical lens for comparing agent architectures across all generations, revealing a clear line of descent where others have seen a disconnect. Our analysis identifies a paradigm shift in the 'locus of intelligence': from being encoded in external data (Semantic Web) or the platform (MAS) to being embedded within the agent's core model (LLM). This shift is foundational to modern Agentic AI, enabling the scalable and adaptive systems the WoA has long envisioned. We conclude that while new protocols are essential, they are insufficient for building a robust, open, trustworthy ecosystem. Finally, we argue that the next research frontier lies in solving persistent socio-technical challenges, and we map out a new agenda focused on decentralized identity, economic models, security, and governance for the emerging WoA.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vision Language Action Models in Robotic Manipulation: A Systematic Review</title>
<link>https://arxiv.org/abs/2507.10672</link>
<guid>https://arxiv.org/abs/2507.10672</guid>
<content:encoded><![CDATA[
arXiv:2507.10672v1 Announce Type: new 
Abstract: Vision Language Action (VLA) models represent a transformative shift in robotics, with the aim of unifying visual perception, natural language understanding, and embodied control within a single learning framework. This review presents a comprehensive and forward-looking synthesis of the VLA paradigm, with a particular emphasis on robotic manipulation and instruction-driven autonomy. We comprehensively analyze 102 VLA models, 26 foundational datasets, and 12 simulation platforms that collectively shape the development and evaluation of VLAs models. These models are categorized into key architectural paradigms, each reflecting distinct strategies for integrating vision, language, and control in robotic systems. Foundational datasets are evaluated using a novel criterion based on task complexity, variety of modalities, and dataset scale, allowing a comparative analysis of their suitability for generalist policy learning. We introduce a two-dimensional characterization framework that organizes these datasets based on semantic richness and multimodal alignment, showing underexplored regions in the current data landscape. Simulation environments are evaluated for their effectiveness in generating large-scale data, as well as their ability to facilitate transfer from simulation to real-world settings and the variety of supported tasks. Using both academic and industrial contributions, we recognize ongoing challenges and outline strategic directions such as scalable pretraining protocols, modular architectural design, and robust multimodal alignment strategies. This review serves as both a technical reference and a conceptual roadmap for advancing embodiment and robotic control, providing insights that span from dataset generation to real world deployment of generalist robotic agents.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring User Security and Privacy Attitudes and Concerns Toward the Use of General-Purpose LLM Chatbots for Mental Health</title>
<link>https://arxiv.org/abs/2507.10695</link>
<guid>https://arxiv.org/abs/2507.10695</guid>
<content:encoded><![CDATA[
arXiv:2507.10695v1 Announce Type: new 
Abstract: Individuals are increasingly relying on large language model (LLM)-enabled conversational agents for emotional support. While prior research has examined privacy and security issues in chatbots specifically designed for mental health purposes, these chatbots are overwhelmingly "rule-based" offerings that do not leverage generative AI. Little empirical research currently measures users' privacy and security concerns, attitudes, and expectations when using general-purpose LLM-enabled chatbots to manage and improve mental health. Through 21 semi-structured interviews with U.S. participants, we identified critical misconceptions and a general lack of risk awareness. Participants conflated the human-like empathy exhibited by LLMs with human-like accountability and mistakenly believed that their interactions with these chatbots were safeguarded by the same regulations (e.g., HIPAA) as disclosures with a licensed therapist. We introduce the concept of "intangible vulnerability," where emotional or psychological disclosures are undervalued compared to more tangible forms of information (e.g., financial or location-based data). To address this, we propose recommendations to safeguard user mental health disclosures with general-purpose LLM-enabled chatbots more effectively.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ground-Compose-Reinforce: Tasking Reinforcement Learning Agents through Formal Language</title>
<link>https://arxiv.org/abs/2507.10741</link>
<guid>https://arxiv.org/abs/2507.10741</guid>
<content:encoded><![CDATA[
arXiv:2507.10741v1 Announce Type: new 
Abstract: Grounding language in complex perception (e.g. pixels) and action is a key challenge when building situated agents that can interact with humans via language. In past works, this is often solved via manual design of the language grounding or by curating massive datasets relating language to elements of the environment. We propose Ground-Compose-Reinforce, a neurosymbolic framework for grounding formal language from data, and eliciting behaviours by directly tasking RL agents through this language. By virtue of data-driven learning, our framework avoids the manual design of domain-specific elements like reward functions or symbol detectors. By virtue of compositional formal language semantics, our framework achieves data-efficient grounding and generalization to arbitrary language compositions. Experiments on an image-based gridworld and a MuJoCo robotics domain show that our approach reliably maps formal language instructions to behaviours with limited data while end-to-end, data-driven approaches fail.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RCG: Safety-Critical Scenario Generation for Robust Autonomous Driving via Real-World Crash Grounding</title>
<link>https://arxiv.org/abs/2507.10749</link>
<guid>https://arxiv.org/abs/2507.10749</guid>
<content:encoded><![CDATA[
arXiv:2507.10749v1 Announce Type: new 
Abstract: Safety-critical scenarios are essential for training and evaluating autonomous driving (AD) systems, yet remain extremely rare in real-world driving datasets. To address this, we propose Real-world Crash Grounding (RCG), a scenario generation framework that integrates crash-informed semantics into adversarial perturbation pipelines. We construct a safety-aware behavior representation through contrastive pre-training on large-scale driving logs, followed by fine-tuning on a small, crash-rich dataset with approximate trajectory annotations extracted from video. This embedding captures semantic structure aligned with real-world accident behaviors and supports selection of adversary trajectories that are both high-risk and behaviorally realistic. We incorporate the resulting selection mechanism into two prior scenario generation pipelines, replacing their handcrafted scoring objectives with an embedding-based criterion. Experimental results show that ego agents trained against these generated scenarios achieve consistently higher downstream success rates, with an average improvement of 9.2% across seven evaluation settings. Qualitative and quantitative analyses further demonstrate that our approach produces more plausible and nuanced adversary behaviors, enabling more effective and realistic stress testing of AD systems. Code and tools will be released publicly.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Warehouse Spatial Question Answering with LLM Agent</title>
<link>https://arxiv.org/abs/2507.10778</link>
<guid>https://arxiv.org/abs/2507.10778</guid>
<content:encoded><![CDATA[
arXiv:2507.10778v1 Announce Type: new 
Abstract: Spatial understanding has been a challenging task for existing Multi-modal Large Language Models~(MLLMs). Previous methods leverage large-scale MLLM finetuning to enhance MLLM's spatial understanding ability. In this paper, we present a data-efficient approach. We propose a LLM agent system with strong and advanced spatial reasoning ability, which can be used to solve the challenging spatial question answering task in complex indoor warehouse scenarios. Our system integrates multiple tools that allow the LLM agent to conduct spatial reasoning and API tools interaction to answer the given complicated spatial question. Extensive evaluations on the 2025 AI City Challenge Physical AI Spatial Intelligence Warehouse dataset demonstrate that our system achieves high accuracy and efficiency in tasks such as object retrieval, counting, and distance estimation. The code is available at: https://github.com/hsiangwei0903/SpatialAgent
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>React to This (RTT): A Nonverbal Turing Test for Embodied AI</title>
<link>https://arxiv.org/abs/2507.10812</link>
<guid>https://arxiv.org/abs/2507.10812</guid>
<content:encoded><![CDATA[
arXiv:2507.10812v1 Announce Type: new 
Abstract: We propose an approach to test embodied AI agents for interaction awareness and believability, particularly in scenarios where humans push them to their limits. Turing introduced the Imitation Game as a way to explore the question: "Can machines think?" The Total Turing Test later expanded this concept beyond purely verbal communication, incorporating perceptual and physical interaction. Building on this, we propose a new guiding question: "Can machines react?" and introduce the React to This (RTT) test for nonverbal behaviors, presenting results from an initial experiment.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Versatile and Generalizable Manipulation via Goal-Conditioned Reinforcement Learning with Grounded Object Detection</title>
<link>https://arxiv.org/abs/2507.10814</link>
<guid>https://arxiv.org/abs/2507.10814</guid>
<content:encoded><![CDATA[
arXiv:2507.10814v1 Announce Type: new 
Abstract: General-purpose robotic manipulation, including reach and grasp, is essential for deployment into households and workspaces involving diverse and evolving tasks. Recent advances propose using large pre-trained models, such as Large Language Models and object detectors, to boost robotic perception in reinforcement learning. These models, trained on large datasets via self-supervised learning, can process text prompts and identify diverse objects in scenes, an invaluable skill in RL where learning object interaction is resource-intensive. This study demonstrates how to integrate such models into Goal-Conditioned Reinforcement Learning to enable general and versatile robotic reach and grasp capabilities. We use a pre-trained object detection model to enable the agent to identify the object from a text prompt and generate a mask for goal conditioning. Mask-based goal conditioning provides object-agnostic cues, improving feature sharing and generalization. The effectiveness of the proposed framework is demonstrated in a simulated reach-and-grasp task, where the mask-based goal conditioning consistently maintains a $\sim$90\% success rate in grasping both in and out-of-distribution objects, while also ensuring faster convergence to higher returns.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semantic Context for Tool Orchestration</title>
<link>https://arxiv.org/abs/2507.10820</link>
<guid>https://arxiv.org/abs/2507.10820</guid>
<content:encoded><![CDATA[
arXiv:2507.10820v1 Announce Type: new 
Abstract: This paper demonstrates that Semantic Context (SC), leveraging descriptive tool information, is a foundational component for robust tool orchestration. Our contributions are threefold. First, we provide a theoretical foundation using contextual bandits, introducing SC-LinUCB and proving it achieves lower regret and adapts favourably in dynamic action spaces. Second, we provide parallel empirical validation with Large Language Models, showing that SC is critical for successful in-context learning in both static (efficient learning) and non-stationary (robust adaptation) settings. Third, we propose the FiReAct pipeline, and demonstrate on a benchmark with over 10,000 tools that SC-based retrieval enables an LLM to effectively orchestrate over a large action space. These findings provide a comprehensive guide to building more sample-efficient, adaptive, and scalable orchestration agents.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Past, Present and Future: Exploring Adaptive AI in Software Development Bots</title>
<link>https://arxiv.org/abs/2507.10822</link>
<guid>https://arxiv.org/abs/2507.10822</guid>
<content:encoded><![CDATA[
arXiv:2507.10822v1 Announce Type: new 
Abstract: Conversational agents, such as chatbots and virtual assistants, have become essential in software development, boosting productivity, collaboration, and automating various tasks. This paper examines the role of adaptive AI-powered conversational agents in software development, highlighting their ability to offer dynamic, context-aware assistance to developers. Unlike traditional rule-based systems, adaptive AI agents use machine learning and natural language processing to learn from interactions and improve over time, providing more personalized and responsive help. We look at how these tools have evolved from simple query-based systems to advanced AI-driven solutions like GitHub Copilot and Microsoft Teams bots. We also explore the challenges of integrating adaptive AI into software development processes. The study aims to assess the benefits and limitations of these systems, address concerns like data privacy and ethical issues, and offer insights into their future use in the field. Ultimately, adaptive AI chatbots have great potential to revolutionize software development by delivering real-time, customized support and enhancing the efficiency of development cycles.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Guided Agentic Object Detection for Open-World Understanding</title>
<link>https://arxiv.org/abs/2507.10844</link>
<guid>https://arxiv.org/abs/2507.10844</guid>
<content:encoded><![CDATA[
arXiv:2507.10844v1 Announce Type: new 
Abstract: Object detection traditionally relies on fixed category sets, requiring costly re-training to handle novel objects. While Open-World and Open-Vocabulary Object Detection (OWOD and OVOD) improve flexibility, OWOD lacks semantic labels for unknowns, and OVOD depends on user prompts, limiting autonomy. We propose an LLM-guided agentic object detection (LAOD) framework that enables fully label-free, zero-shot detection by prompting a Large Language Model (LLM) to generate scene-specific object names. These are passed to an open-vocabulary detector for localization, allowing the system to adapt its goals dynamically. We introduce two new metrics, Class-Agnostic Average Precision (CAAP) and Semantic Naming Average Precision (SNAP), to separately evaluate localization and naming. Experiments on LVIS, COCO, and COCO-OOD validate our approach, showing strong performance in detecting and naming novel objects. Our method offers enhanced autonomy and adaptability for open-world understanding.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NavComposer: Composing Language Instructions for Navigation Trajectories through Action-Scene-Object Modularization</title>
<link>https://arxiv.org/abs/2507.10894</link>
<guid>https://arxiv.org/abs/2507.10894</guid>
<content:encoded><![CDATA[
arXiv:2507.10894v1 Announce Type: new 
Abstract: Language-guided navigation is a cornerstone of embodied AI, enabling agents to interpret language instructions and navigate complex environments. However, expert-provided instructions are limited in quantity, while synthesized annotations often lack quality, making them insufficient for large-scale research. To address this, we propose NavComposer, a novel framework for automatically generating high-quality navigation instructions. NavComposer explicitly decomposes semantic entities such as actions, scenes, and objects, and recomposes them into natural language instructions. Its modular architecture allows flexible integration of state-of-the-art techniques, while the explicit use of semantic entities enhances both the richness and accuracy of instructions. Moreover, it operates in a data-agnostic manner, supporting adaptation to diverse navigation trajectories without domain-specific training. Complementing NavComposer, we introduce NavInstrCritic, a comprehensive annotation-free evaluation system that assesses navigation instructions on three dimensions: contrastive matching, semantic consistency, and linguistic diversity. NavInstrCritic provides a holistic evaluation of instruction quality, addressing limitations of traditional metrics that rely heavily on expert annotations. By decoupling instruction generation and evaluation from specific navigation agents, our method enables more scalable and generalizable research. Extensive experiments provide direct and practical evidence for the effectiveness of our method.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lessons Learned from Evaluation of LLM based Multi-agents in Safer Therapy Recommendation</title>
<link>https://arxiv.org/abs/2507.10911</link>
<guid>https://arxiv.org/abs/2507.10911</guid>
<content:encoded><![CDATA[
arXiv:2507.10911v1 Announce Type: new 
Abstract: Therapy recommendation for chronic patients with multimorbidity is challenging due to risks of treatment conflicts. Existing decision support systems face scalability limitations. Inspired by the way in which general practitioners (GP) manage multimorbidity patients, occasionally convening multidisciplinary team (MDT) collaboration, this study investigated the feasibility and value of using a Large Language Model (LLM)-based multi-agent system (MAS) for safer therapy recommendations. We designed a single agent and a MAS framework simulating MDT decision-making by enabling discussion among LLM agents to resolve medical conflicts. The systems were evaluated on therapy planning tasks for multimorbidity patients using benchmark cases. We compared MAS performance with single-agent approaches and real-world benchmarks. An important contribution of our study is the definition of evaluation metrics that go beyond the technical precision and recall and allow the inspection of clinical goals met and medication burden of the proposed advices to a gold standard benchmark. Our results show that with current LLMs, a single agent GP performs as well as MDTs. The best-scoring models provide correct recommendations that address all clinical goals, yet the advices are incomplete. Some models also present unnecessary medications, resulting in unnecessary conflicts between medication and conditions or drug-drug interactions.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Learning Framework For Cooperative Collision Avoidance of UAV Swarms Leveraging Domain Knowledge</title>
<link>https://arxiv.org/abs/2507.10913</link>
<guid>https://arxiv.org/abs/2507.10913</guid>
<content:encoded><![CDATA[
arXiv:2507.10913v1 Announce Type: new 
Abstract: This paper presents a multi-agent reinforcement learning (MARL) framework for cooperative collision avoidance of UAV swarms leveraging domain knowledge-driven reward. The reward is derived from knowledge in the domain of image processing, approximating contours on a two-dimensional field. By modeling obstacles as maxima on the field, collisions are inherently avoided as contours never go through peaks or intersect. Additionally, counters are smooth and energy-efficient. Our framework enables training with large swarm sizes as the agent interaction is minimized and the need for complex credit assignment schemes or observation sharing mechanisms in state-of-the-art MARL approaches are eliminated. Moreover, UAVs obtain the ability to adapt to complex environments where contours may be non-viable or non-existent through intensive training. Extensive experiments are conducted to evaluate the performances of our framework against state-of-the-art MARL algorithms.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Journalism-Guided Agentic In-Context Learning for News Stance Detection</title>
<link>https://arxiv.org/abs/2507.11049</link>
<guid>https://arxiv.org/abs/2507.11049</guid>
<content:encoded><![CDATA[
arXiv:2507.11049v1 Announce Type: new 
Abstract: As online news consumption grows, personalized recommendation systems have become integral to digital journalism. However, these systems risk reinforcing filter bubbles and political polarization by failing to incorporate diverse perspectives. Stance detection -- identifying a text's position on a target -- can help mitigate this by enabling viewpoint-aware recommendations and data-driven analyses of media bias. Yet, existing stance detection research remains largely limited to short texts and high-resource languages. To address these gaps, we introduce \textsc{K-News-Stance}, the first Korean dataset for article-level stance detection, comprising 2,000 news articles with article-level and 19,650 segment-level stance annotations across 47 societal issues. We also propose \textsc{JoA-ICL}, a \textbf{Jo}urnalism-guided \textbf{A}gentic \textbf{I}n-\textbf{C}ontext \textbf{L}earning framework that employs a language model agent to predict the stances of key structural segments (e.g., leads, quotes), which are then aggregated to infer the overall article stance. Experiments show that \textsc{JoA-ICL} outperforms existing stance detection methods, highlighting the benefits of segment-level agency in capturing the overall position of long-form news articles. Two case studies further demonstrate its broader utility in promoting viewpoint diversity in news recommendations and uncovering patterns of media bias.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SWE-MERA: A Dynamic Benchmark for Agenticly Evaluating Large Language Models on Software Engineering Tasks</title>
<link>https://arxiv.org/abs/2507.11059</link>
<guid>https://arxiv.org/abs/2507.11059</guid>
<content:encoded><![CDATA[
arXiv:2507.11059v1 Announce Type: new 
Abstract: The rapid advancement of Large Language Models (LLMs) in software engineering has revealed critical limitations in existing benchmarks, particularly the widely used SWE-bench dataset. Recent studies have uncovered severe data contamination issues, e.g. SWE-bench reports 32.67% of successful patches involve direct solution leakage and 31.08\% pass due to inadequate test cases. We introduce SWE-MERA, a dynamic, continuously updated benchmark designed to address these fundamental challenges through an automated collection of real-world GitHub issues and rigorous quality validation. Our approach implements a reliable pipeline that ensures quality while minimizing contamination risks, resulting in approximately 10,000 potential tasks with 300 samples currently available. Evaluation using the Aider coding agent demonstrates strong discriminative power in state-of-the-art models. We report performance across a dozen recent LLMs evaluated on tasks collected between September 2024 and June 2025.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tactical Decision for Multi-UGV Confrontation with a Vision-Language Model-Based Commander</title>
<link>https://arxiv.org/abs/2507.11079</link>
<guid>https://arxiv.org/abs/2507.11079</guid>
<content:encoded><![CDATA[
arXiv:2507.11079v1 Announce Type: new 
Abstract: In multiple unmanned ground vehicle confrontations, autonomously evolving multi-agent tactical decisions from situational awareness remain a significant challenge. Traditional handcraft rule-based methods become vulnerable in the complicated and transient battlefield environment, and current reinforcement learning methods mainly focus on action manipulation instead of strategic decisions due to lack of interpretability. Here, we propose a vision-language model-based commander to address the issue of intelligent perception-to-decision reasoning in autonomous confrontations. Our method integrates a vision language model for scene understanding and a lightweight large language model for strategic reasoning, achieving unified perception and decision within a shared semantic space, with strong adaptability and interpretability. Unlike rule-based search and reinforcement learning methods, the combination of the two modules establishes a full-chain process, reflecting the cognitive process of human commanders. Simulation and ablation experiments validate that the proposed approach achieves a win rate of over 80% compared with baseline models.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agent Architecture for Decentralized Trading of Alternative Assets</title>
<link>https://arxiv.org/abs/2507.11117</link>
<guid>https://arxiv.org/abs/2507.11117</guid>
<content:encoded><![CDATA[
arXiv:2507.11117v1 Announce Type: new 
Abstract: Decentralized trading of real-world alternative assets (e.g., gold) requires bridging physical asset custody with blockchain systems while meeting strict requirements for compliance, liquidity, and risk management. We present GoldMine OS, a research oriented architecture that employs multiple specialized AI agents to automate and secure the tokenization and exchange of physical gold into a blockchain based stablecoin ("OZ"). Our approach combines on chain smart contracts for critical risk controls with off chain AI agents for decision making, blending the transparency and reliability of blockchains with the flexibility of AI driven automation. We describe four cooperative agents (Compliance, Token Issuance, Market Making, and Risk Control) and a coordinating core, and evaluate the system through simulation and a controlled pilot deployment. In experiments the prototype delivers on demand token issuance in under 1.2 s, more than 100 times faster than manual workflows. The Market Making agent maintains tight liquidity with spreads often below 0.5 percent even under volatile conditions. Fault injection tests show resilience: an oracle price spoofing attack is detected and mitigated within 10 s, and a simulated vault mis reporting halts issuance immediately with minimal user impact. The architecture scales to 5000 transactions per second with 10000 concurrent users in benchmarks. These results indicate that an AI agent based decentralized exchange for alternative assets can satisfy rigorous performance and safety requirements. We discuss broader implications for democratizing access to traditionally illiquid assets and explain how our governance model -- multi signature agent updates and on chain community voting on risk parameters -- provides ongoing transparency, adaptability, and formal assurance of system integrity.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Quantized Rank Reduction: A Communications-Efficient Federated Learning Scheme for Network-Critical Applications</title>
<link>https://arxiv.org/abs/2507.11183</link>
<guid>https://arxiv.org/abs/2507.11183</guid>
<content:encoded><![CDATA[
arXiv:2507.11183v1 Announce Type: new 
Abstract: Federated learning is a machine learning approach that enables multiple devices (i.e., agents) to train a shared model cooperatively without exchanging raw data. This technique keeps data localized on user devices, ensuring privacy and security, while each agent trains the model on their own data and only shares model updates. The communication overhead is a significant challenge due to the frequent exchange of model updates between the agents and the central server. In this paper, we propose a communication-efficient federated learning scheme that utilizes low-rank approximation of neural network gradients and quantization to significantly reduce the network load of the decentralized learning process with minimal impact on the model's accuracy.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Temperature and Persona Shape LLM Agent Consensus With Minimal Accuracy Gains in Qualitative Coding</title>
<link>https://arxiv.org/abs/2507.11198</link>
<guid>https://arxiv.org/abs/2507.11198</guid>
<content:encoded><![CDATA[
arXiv:2507.11198v1 Announce Type: new 
Abstract: Large Language Models (LLMs) enable new possibilities for qualitative research at scale, including coding and data annotation. While multi-agent systems (MAS) can emulate human coding workflows, their benefits over single-agent coding remain poorly understood. We conducted an experimental study of how agent persona and temperature shape consensus-building and coding accuracy of dialog segments based on a codebook with 8 codes. Our open-source MAS mirrors deductive human coding through structured agent discussion and consensus arbitration. Using six open-source LLMs (with 3 to 32 billion parameters) and 18 experimental configurations, we analyze over 77,000 coding decisions against a gold-standard dataset of human-annotated transcripts from online math tutoring sessions. Temperature significantly impacted whether and when consensus was reached across all six LLMs. MAS with multiple personas (including neutral, assertive, or empathetic), significantly delayed consensus in four out of six LLMs compared to uniform personas. In three of those LLMs, higher temperatures significantly diminished the effects of multiple personas on consensus. However, neither temperature nor persona pairing lead to robust improvements in coding accuracy. Single agents matched or outperformed MAS consensus in most conditions. Only one model (OpenHermesV2:7B) and code category showed above-chance gains from MAS deliberation when temperature was 0.5 or lower and especially when the agents included at least one assertive persona. Qualitative analysis of MAS collaboration for these configurations suggests that MAS may nonetheless aid in narrowing ambiguous code applications that could improve codebooks and human-AI coding. We contribute new insight into the limits of LLM-based qualitative methods, challenging the notion that diverse MAS personas lead to better outcomes. We open-source our MAS and experimentation code.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Role-Playing LLM-Based Multi-Agent Support Framework for Detecting and Addressing Family Communication Bias</title>
<link>https://arxiv.org/abs/2507.11210</link>
<guid>https://arxiv.org/abs/2507.11210</guid>
<content:encoded><![CDATA[
arXiv:2507.11210v1 Announce Type: new 
Abstract: Well-being in family settings involves subtle psychological dynamics that conventional metrics often overlook. In particular, unconscious parental expectations, termed ideal parent bias, can suppress children's emotional expression and autonomy. This suppression, referred to as suppressed emotion, often stems from well-meaning but value-driven communication, which is difficult to detect or address from outside the family. Focusing on these latent dynamics, this study explores Large Language Model (LLM)-based support for psychologically safe family communication. We constructed a Japanese parent-child dialogue corpus of 30 scenarios, each annotated with metadata on ideal parent bias and suppressed emotion. Based on this corpus, we developed a Role-Playing LLM-based multi-agent dialogue support framework that analyzes dialogue and generates feedback. Specialized agents detect suppressed emotion, describe implicit ideal parent bias in parental speech, and infer contextual attributes such as the child's age and background. A meta-agent compiles these outputs into a structured report, which is then passed to five selected expert agents. These agents collaboratively generate empathetic and actionable feedback through a structured four-step discussion process. Experiments show that the system can detect categories of suppressed emotion with moderate accuracy and produce feedback rated highly in empathy and practicality. Moreover, simulated follow-up dialogues incorporating this feedback exhibited signs of improved emotional expression and mutual understanding, suggesting the framework's potential in supporting positive transformation in family interactions.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Contracts</title>
<link>https://arxiv.org/abs/2507.11214</link>
<guid>https://arxiv.org/abs/2507.11214</guid>
<content:encoded><![CDATA[
arXiv:2507.11214v1 Announce Type: new 
Abstract: We introduce and study the problem of designing optimal contracts under fairness constraints on the task assignments and compensations. We adopt the notion of envy-free (EF) and its relaxations, $\epsilon$-EF and envy-free up to one item (EF1), in contract design settings. Unlike fair allocations, EF contracts are guaranteed to exist. However, computing any constant-factor approximation to the optimal EF contract is NP-hard in general, even using $\epsilon$-EF contracts. For this reason, we consider settings in which the number of agents or tasks is constant. Notably, while even with three agents, finding an EF contract better than $2/5$ approximation of the optimal is NP-hard, we are able to design an FPTAS when the number of agents is constant, under relaxed notions of $\epsilon$-EF and EF1. Moreover, we present a polynomial-time algorithm for computing the optimal EF contract when the number of tasks is constant. Finally, we analyze the price of fairness in contract design. We show that the price of fairness for exact EF contracts can be unbounded, even with a single task and two agents. In contrast, for EF1 contracts, the price of fairness is bounded between $\Omega(\sqrt{n})$ and $O(n^2)$, where $n$ is the number of agents.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Agentic Flow for Finite State Machine Extraction using Prompt Chaining</title>
<link>https://arxiv.org/abs/2507.11222</link>
<guid>https://arxiv.org/abs/2507.11222</guid>
<content:encoded><![CDATA[
arXiv:2507.11222v1 Announce Type: new 
Abstract: Finite-State Machines (FSMs) are critical for modeling the operational logic of network protocols, enabling verification, analysis, and vulnerability discovery. However, existing FSM extraction techniques face limitations such as scalability, incomplete coverage, and ambiguity in natural language specifications. In this paper, we propose FlowFSM, a novel agentic framework that leverages Large Language Models (LLMs) combined with prompt chaining and chain-of-thought reasoning to extract accurate FSMs from raw RFC documents. FlowFSM systematically processes protocol specifications, identifies state transitions, and constructs structured rule-books by chaining agent outputs. Experimental evaluation across FTP and RTSP protocols demonstrates that FlowFSM achieves high extraction precision while minimizing hallucinated transitions, showing promising results. Our findings highlight the potential of agent-based LLM systems in the advancement of protocol analysis and FSM inference for cybersecurity and reverse engineering applications.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Turning Sand to Gold: Recycling Data to Bridge On-Policy and Off-Policy Learning via Causal Bound</title>
<link>https://arxiv.org/abs/2507.11269</link>
<guid>https://arxiv.org/abs/2507.11269</guid>
<content:encoded><![CDATA[
arXiv:2507.11269v1 Announce Type: new 
Abstract: Deep reinforcement learning (DRL) agents excel in solving complex decision-making tasks across various domains. However, they often require a substantial number of training steps and a vast experience replay buffer, leading to significant computational and resource demands. To address these challenges, we introduce a novel theoretical result that leverages the Neyman-Rubin potential outcomes framework into DRL. Unlike most methods that focus on bounding the counterfactual loss, we establish a causal bound on the factual loss, which is analogous to the on-policy loss in DRL. This bound is computed by storing past value network outputs in the experience replay buffer, effectively utilizing data that is usually discarded. Extensive experiments across the Atari 2600 and MuJoCo domains on various agents, such as DQN and SAC, achieve up to 2,427% higher reward ratio, outperforming the same agents without our proposed term, and reducing the experience replay buffer size by up to 96%, significantly improving sample efficiency at negligible cost.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Empirical Study of Multi-Agent RAG for Real-World University Admissions Counseling</title>
<link>https://arxiv.org/abs/2507.11272</link>
<guid>https://arxiv.org/abs/2507.11272</guid>
<content:encoded><![CDATA[
arXiv:2507.11272v1 Announce Type: new 
Abstract: This paper presents MARAUS (Multi-Agent and Retrieval-Augmented University Admission System), a real-world deployment of a conversational AI platform for higher education admissions counseling in Vietnam. While large language models (LLMs) offer potential for automating advisory tasks, most existing solutions remain limited to prototypes or synthetic benchmarks. MARAUS addresses this gap by combining hybrid retrieval, multi-agent orchestration, and LLM-based generation into a system tailored for real-world university admissions. In collaboration with the University of Transport Technology (UTT) in Hanoi, we conducted a two-phase study involving technical development and real-world evaluation. MARAUS processed over 6,000 actual user interactions, spanning six categories of queries. Results show substantial improvements over LLM-only baselines: on average 92 percent accuracy, hallucination rates reduced from 15 precent to 1.45 percent, and average response times below 4 seconds. The system operated cost-effectively, with a two-week deployment cost of 11.58 USD using GPT-4o mini. This work provides actionable insights for the deployment of agentic RAG systems in low-resource educational settings.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Taming Uncertainty via Automation: Observing, Analyzing, and Optimizing Agentic AI Systems</title>
<link>https://arxiv.org/abs/2507.11277</link>
<guid>https://arxiv.org/abs/2507.11277</guid>
<content:encoded><![CDATA[
arXiv:2507.11277v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed within agentic systems-collections of interacting, LLM-powered agents that execute complex, adaptive workflows using memory, tools, and dynamic planning. While enabling powerful new capabilities, these systems also introduce unique forms of uncertainty stemming from probabilistic reasoning, evolving memory states, and fluid execution paths. Traditional software observability and operations practices fall short in addressing these challenges.
  This paper introduces AgentOps: a comprehensive framework for observing, analyzing, optimizing, and automating operation of agentic AI systems. We identify distinct needs across four key roles-developers, testers, site reliability engineers (SREs), and business users-each of whom engages with the system at different points in its lifecycle. We present the AgentOps Automation Pipeline, a six-stage process encompassing behavior observation, metric collection, issue detection, root cause analysis, optimized recommendations, and runtime automation. Throughout, we emphasize the critical role of automation in managing uncertainty and enabling self-improving AI systems-not by eliminating uncertainty, but by taming it to ensure safe, adaptive, and effective operation.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dr.Copilot: A Multi-Agent Prompt Optimized Assistant for Improving Patient-Doctor Communication in Romanian</title>
<link>https://arxiv.org/abs/2507.11299</link>
<guid>https://arxiv.org/abs/2507.11299</guid>
<content:encoded><![CDATA[
arXiv:2507.11299v1 Announce Type: new 
Abstract: Text-based telemedicine has become increasingly common, yet the quality of medical advice in doctor-patient interactions is often judged more on how advice is communicated rather than its clinical accuracy. To address this, we introduce Dr.Copilot , a multi-agent large language model (LLM) system that supports Romanian-speaking doctors by evaluating and enhancing the presentation quality of their written responses. Rather than assessing medical correctness, Dr.Copilot provides feedback along 17 interpretable axes. The system comprises of three LLM agents with prompts automatically optimized via DSPy. Designed with low-resource Romanian data and deployed using open-weight models, it delivers real-time specific feedback to doctors within a telemedicine platform. Empirical evaluations and live deployment with 41 doctors show measurable improvements in user reviews and response quality, marking one of the first real-world deployments of LLMs in Romanian medical settings.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Production Logistics to Smart Manufacturing: The Vision for a New RoboCup Industrial League</title>
<link>https://arxiv.org/abs/2507.11402</link>
<guid>https://arxiv.org/abs/2507.11402</guid>
<content:encoded><![CDATA[
arXiv:2507.11402v1 Announce Type: new 
Abstract: The RoboCup Logistics League is a RoboCup competition in a smart factory scenario that has focused on task planning, job scheduling, and multi-agent coordination. The focus on production logistics allowed teams to develop highly competitive strategies, but also meant that some recent developments in the context of smart manufacturing are not reflected in the competition, weakening its relevance over the years. In this paper, we describe the vision for the RoboCup Smart Manufacturing League, a new competition designed as a larger smart manufacturing scenario, reflecting all the major aspects of a modern factory. It will consist of several tracks that are initially independent but gradually combined into one smart manufacturing scenario. The new tracks will cover industrial robotics challenges such as assembly, human-robot collaboration, and humanoid robotics, but also retain a focus on production logistics. We expect the reenvisioned competition to be more attractive to newcomers and well-tried teams, while also shifting the focus to current and future challenges of industrial robotics.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EXAONE 4.0: Unified Large Language Models Integrating Non-reasoning and Reasoning Modes</title>
<link>https://arxiv.org/abs/2507.11407</link>
<guid>https://arxiv.org/abs/2507.11407</guid>
<content:encoded><![CDATA[
arXiv:2507.11407v1 Announce Type: new 
Abstract: This technical report introduces EXAONE 4.0, which integrates a Non-reasoning mode and a Reasoning mode to achieve both the excellent usability of EXAONE 3.5 and the advanced reasoning abilities of EXAONE Deep. To pave the way for the agentic AI era, EXAONE 4.0 incorporates essential features such as agentic tool use, and its multilingual capabilities are extended to support Spanish in addition to English and Korean. The EXAONE 4.0 model series consists of two sizes: a mid-size 32B model optimized for high performance, and a small-size 1.2B model designed for on-device applications. The EXAONE 4.0 demonstrates superior performance compared to open-weight models in its class and remains competitive even against frontier-class models. The models are publicly available for research purposes and can be easily downloaded via https://huggingface.co/LGAI-EXAONE.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LF: Online Multi-Robot Path Planning Meets Optimal Trajectory Control</title>
<link>https://arxiv.org/abs/2507.11464</link>
<guid>https://arxiv.org/abs/2507.11464</guid>
<content:encoded><![CDATA[
arXiv:2507.11464v1 Announce Type: new 
Abstract: We propose a multi-robot control paradigm to solve point-to-point navigation tasks for a team of holonomic robots with access to the full environment information. The framework invokes two processes asynchronously at high frequency: (i) a centralized, discrete, and full-horizon planner for computing collision- and deadlock-free paths rapidly, leveraging recent advances in multi-agent pathfinding (MAPF), and (ii) dynamics-aware, robot-wise optimal trajectory controllers that ensure all robots independently follow their assigned paths reliably. This hierarchical shift in planning representation from (i) discrete and coupled to (ii) continuous and decoupled domains enables the framework to maintain long-term scalable motion synthesis. As an instantiation of this idea, we present LF, which combines a fast state-of-the-art MAPF solver (LaCAM), and a robust feedback control stack (Freyja) for executing agile robot maneuvers. LF provides a robust and versatile mechanism for lifelong multi-robot navigation even under asynchronous and partial goal updates, and adapts to dynamic workspaces simply by quick replanning. We present various multirotor and ground robot demonstrations, including the deployment of 15 real multirotors with random, consecutive target updates while a person walks through the operational workspace.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the Complexity of the Optimal Correlated Equilibria in Extensive-Form Games</title>
<link>https://arxiv.org/abs/2507.11509</link>
<guid>https://arxiv.org/abs/2507.11509</guid>
<content:encoded><![CDATA[
arXiv:2507.11509v1 Announce Type: new 
Abstract: A major open question in algorithmic game theory is whether normal-form correlated equilibria (NFCE) can be computed efficiently in succinct games such as extensive-form games [DFF+25,6PR24,FP23,HvS08,VSF08,PR08]. Motivated by this question, we study the associated Threshold problem: deciding whether there exists a correlated equilibrium whose value exceeds a given threshold. We prove that this problem is PSPACE-hard for NFCE in multiplayer extensive-form games with perfect recall, even for fixed thresholds. To contextualize this result, we also establish the complexity of the Threshold problem for Nash equilibria in this setting, showing it is ER-complete. These results uncover a surprising complexity reversal: while optimal correlated equilibria are computationally simpler than optimal Nash in normal-form games, the opposite holds in extensive-form games, where computing optimal correlated equilibria is provably harder. Building on this line of inquiry, we also address a related question by [VSF08], who introduced the notions of extensive-form correlated equilibrium (EFCE) and agent-form correlated equilibrium (AFCE). They asked how difficult the Threshold problem is for AFCE; we answer this question by proving that it is NP-hard, even in two-player games without chance nodes. Complementing our hardness results, we establish tight complexity classifications for the Threshold problem across several correlated equilibrium concepts - including EFCE, AFCE, normal-form coarse, extensive-form coarse, and agent-form coarse correlated equilibria. For each of these solution concepts in multiplayer stochastic extensive-form games with perfect recall, we prove NP-completeness by providing matching NP upper bounds to the previously known hardness results. Together, our results provide the most complete landscape to date for the complexity of optimal equilibrium computation in extensive-form games.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AirLLM: Diffusion Policy-based Adaptive LoRA for Remote Fine-Tuning of LLM over the Air</title>
<link>https://arxiv.org/abs/2507.11515</link>
<guid>https://arxiv.org/abs/2507.11515</guid>
<content:encoded><![CDATA[
arXiv:2507.11515v1 Announce Type: new 
Abstract: Operating Large Language Models (LLMs) on edge devices is increasingly challenged by limited communication bandwidth and strained computational and memory costs. Thus, cloud-assisted remote fine-tuning becomes indispensable. Nevertheless, existing Low-Rank Adaptation (LoRA) approaches typically employ fixed or heuristic rank configurations, and the subsequent over-the-air transmission of all LoRA parameters could be rather inefficient. To address this limitation, we develop AirLLM, a hierarchical diffusion policy framework for communication-aware LoRA adaptation. Specifically, AirLLM models the rank configuration as a structured action vector that spans all LoRA-inserted projections. To solve the underlying high-dimensional sequential decision-making problem, a Proximal Policy Optimization (PPO) agent generates coarse-grained decisions by jointly observing wireless states and linguistic complexity, which are then refined via Denoising Diffusion Implicit Models (DDIM) to produce high-resolution, task- and channel-adaptive rank vectors. The two modules are optimized alternatively, with the DDIM trained under the Classifier-Free Guidance (CFG) paradigm to maintain alignment with PPO rewards. Experiments under varying signal-to-noise ratios demonstrate that AirLLM consistently enhances fine-tuning performance while significantly reducing transmission costs, highlighting the effectiveness of reinforcement-driven, diffusion-refined rank adaptation for scalable and efficient remote fine-tuning over the air.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DrafterBench: Benchmarking Large Language Models for Tasks Automation in Civil Engineering</title>
<link>https://arxiv.org/abs/2507.11527</link>
<guid>https://arxiv.org/abs/2507.11527</guid>
<content:encoded><![CDATA[
arXiv:2507.11527v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents have shown great potential for solving real-world problems and promise to be a solution for tasks automation in industry. However, more benchmarks are needed to systematically evaluate automation agents from an industrial perspective, for example, in Civil Engineering. Therefore, we propose DrafterBench for the comprehensive evaluation of LLM agents in the context of technical drawing revision, a representation task in civil engineering. DrafterBench contains twelve types of tasks summarized from real-world drawing files, with 46 customized functions/tools and 1920 tasks in total. DrafterBench is an open-source benchmark to rigorously test AI agents' proficiency in interpreting intricate and long-context instructions, leveraging prior knowledge, and adapting to dynamic instruction quality via implicit policy awareness. The toolkit comprehensively assesses distinct capabilities in structured data comprehension, function execution, instruction following, and critical reasoning. DrafterBench offers detailed analysis of task accuracy and error statistics, aiming to provide deeper insight into agent capabilities and identify improvement targets for integrating LLMs in engineering applications. Our benchmark is available at https://github.com/Eason-Li-AIS/DrafterBench, with the test set hosted at https://huggingface.co/datasets/Eason666/DrafterBench.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Brains and Machines: A Unified Frontier in Neuroscience, Artificial Intelligence, and Neuromorphic Systems</title>
<link>https://arxiv.org/abs/2507.10722</link>
<guid>https://arxiv.org/abs/2507.10722</guid>
<content:encoded><![CDATA[
arXiv:2507.10722v1 Announce Type: cross 
Abstract: This position and survey paper identifies the emerging convergence of neuroscience, artificial general intelligence (AGI), and neuromorphic computing toward a unified research paradigm. Using a framework grounded in brain physiology, we highlight how synaptic plasticity, sparse spike-based communication, and multimodal association provide design principles for next-generation AGI systems that potentially combine both human and machine intelligences. The review traces this evolution from early connectionist models to state-of-the-art large language models, demonstrating how key innovations like transformer attention, foundation-model pre-training, and multi-agent architectures mirror neurobiological processes like cortical mechanisms, working memory, and episodic consolidation. We then discuss emerging physical substrates capable of breaking the von Neumann bottleneck to achieve brain-scale efficiency in silicon: memristive crossbars, in-memory compute arrays, and emerging quantum and photonic devices. There are four critical challenges at this intersection: 1) integrating spiking dynamics with foundation models, 2) maintaining lifelong plasticity without catastrophic forgetting, 3) unifying language with sensorimotor learning in embodied agents, and 4) enforcing ethical safeguards in advanced neuromorphic autonomous systems. This combined perspective across neuroscience, computation, and hardware offers an integrative agenda for in each of these fields.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bayesian Conversations</title>
<link>https://arxiv.org/abs/2307.08827</link>
<guid>https://arxiv.org/abs/2307.08827</guid>
<content:encoded><![CDATA[
arXiv:2307.08827v4 Announce Type: replace 
Abstract: We initiate the study of Bayesian conversations, which model interactive communication between two strategic agents without a mediator. We compare this to communication through a mediator and investigate the settings in which a mediation can expand the range of implementable outcomes.
  We look into the eventual outcome of two-player games after interactive communication. We focus on games where only one agent has a non-trivial action and examine the performance of communication protocols that are individually rational (IR) for both parties. We characterize the structure of the social-welfare optimal protocol of a given number of rounds and thus show a separation between Bayesian conversation and mediated protocols. We demonstrate an example where the optimal conversation protocol requires infinitely many rounds of communication, and further show that for settings with binary actions and binary types, any optimal protocol either is finite (with at most 6 rounds) or requires infinitely many rounds of communication.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PPA-Game: Characterizing and Learning Competitive Dynamics Among Online Content Creators</title>
<link>https://arxiv.org/abs/2403.15524</link>
<guid>https://arxiv.org/abs/2403.15524</guid>
<content:encoded><![CDATA[
arXiv:2403.15524v2 Announce Type: replace 
Abstract: In this paper, we present the Proportional Payoff Allocation Game (PPA-Game), which characterizes situations where agents compete for divisible resources. In the PPA-game, agents select from available resources, and their payoffs are proportionately determined based on heterogeneous weights attributed to them. Such dynamics simulate content creators on online recommender systems like YouTube and TikTok, who compete for finite consumer attention, with content exposure reliant on inherent and distinct quality. We first conduct a game-theoretical analysis of the PPA-Game. While the PPA-Game does not always guarantee the existence of a pure Nash equilibrium (PNE), we identify prevalent scenarios ensuring its existence. Simulated experiments further prove that the cases where PNE does not exist rarely happen. Beyond analyzing static payoffs, we further discuss the agents' online learning about resource payoffs by integrating a multi-player multi-armed bandit framework. We propose an online algorithm facilitating each agent's maximization of cumulative payoffs over $T$ rounds. Theoretically, we establish that the regret of any agent is bounded by $O(\log^{1 + \eta} T)$ for any $\eta > 0$. Empirical results further validate the effectiveness of our online learning approach.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trajectory Imputation in Multi-Agent Sports with Derivative-Accumulating Self-Ensemble</title>
<link>https://arxiv.org/abs/2408.10878</link>
<guid>https://arxiv.org/abs/2408.10878</guid>
<content:encoded><![CDATA[
arXiv:2408.10878v4 Announce Type: replace 
Abstract: Multi-agent trajectory data collected from domains such as team sports often suffer from missing values due to various factors. While many imputation methods have been proposed for spatiotemporal data, they are not well-suited for multi-agent sports scenarios where player movements are highly dynamic and inter-agent interactions continuously evolve. To address these challenges, we propose MIDAS (Multi-agent Imputer with Derivative-Accumulating Self-ensemble), a framework that imputes multi-agent trajectories with high accuracy and physical plausibility. It jointly predicts positions, velocities, and accelerations through a Set Transformer-based neural network and generates alternative estimates by recursively accumulating predicted velocity and acceleration values. These predictions are then combined using a learnable weighted ensemble to produce final imputed trajectories. Experiments on three sports datasets demonstrate that MIDAS significantly outperforms existing baselines in both positional accuracy and physical plausibility. Lastly, we showcase use cases of MIDAS, such as approximating total distance and pass success probability, to highlight its applicability to practical downstream tasks that require complete tracking data.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SECURE: Semantics-aware Embodied Conversation under Unawareness for Lifelong Robot Learning</title>
<link>https://arxiv.org/abs/2409.17755</link>
<guid>https://arxiv.org/abs/2409.17755</guid>
<content:encoded><![CDATA[
arXiv:2409.17755v3 Announce Type: replace 
Abstract: This paper addresses a challenging interactive task learning scenario we call rearrangement under unawareness: an agent must manipulate a rigid-body environment without knowing a key concept necessary for solving the task and must learn about it during deployment. For example, the user may ask to "put the two granny smith apples inside the basket", but the agent cannot correctly identify which objects in the environment are "granny smith" as the agent has not been exposed to such a concept before. We introduce SECURE, an interactive task learning policy designed to tackle such scenarios. The unique feature of SECURE is its ability to enable agents to engage in semantic analysis when processing embodied conversations and making decisions. Through embodied conversation, a SECURE agent adjusts its deficient domain model by engaging in dialogue to identify and learn about previously unforeseen possibilities. The SECURE agent learns from the user's embodied corrective feedback when mistakes are made and strategically engages in dialogue to uncover useful information about novel concepts relevant to the task. These capabilities enable the SECURE agent to generalize to new tasks with the acquired knowledge. We demonstrate in the simulated Blocksworld and the real-world apple manipulation environments that the SECURE agent, which solves such rearrangements under unawareness, is more data-efficient than agents that do not engage in embodied conversation or semantic analysis.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Possible Principles for Aligned Structure Learning Agents</title>
<link>https://arxiv.org/abs/2410.00258</link>
<guid>https://arxiv.org/abs/2410.00258</guid>
<content:encoded><![CDATA[
arXiv:2410.00258v2 Announce Type: replace 
Abstract: This paper offers a roadmap for the development of scalable aligned artificial intelligence (AI) from first principle descriptions of natural intelligence. In brief, a possible path toward scalable aligned AI rests upon enabling artificial agents to learn a good model of the world that includes a good model of our preferences. For this, the main objective is creating agents that learn to represent the world and other agents' world models; a problem that falls under structure learning (a.k.a. causal representation learning or model discovery). We expose the structure learning and alignment problems with this goal in mind, as well as principles to guide us forward, synthesizing various ideas across mathematics, statistics, and cognitive science. 1) We discuss the essential role of core knowledge, information geometry and model reduction in structure learning, and suggest core structural modules to learn a wide range of naturalistic worlds. 2) We outline a way toward aligned agents through structure learning and theory of mind. As an illustrative example, we mathematically sketch Asimov's Laws of Robotics, which prescribe agents to act cautiously to minimize the ill-being of other agents. We supplement this example by proposing refined approaches to alignment. These observations may guide the development of artificial intelligence in helping to scale existing -- or design new -- aligned structure learning systems.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Intrinsic Rewards for Decision Making Agents from Large Language Model Feedback</title>
<link>https://arxiv.org/abs/2410.23022</link>
<guid>https://arxiv.org/abs/2410.23022</guid>
<content:encoded><![CDATA[
arXiv:2410.23022v3 Announce Type: replace 
Abstract: Automatically synthesizing dense rewards from natural language descriptions is a promising paradigm in reinforcement learning (RL), with applications to sparse reward problems, open-ended exploration, and hierarchical skill design. Recent works have made promising steps by exploiting the prior knowledge of large language models (LLMs). However, these approaches suffer from important limitations: they are either not scalable to problems requiring billions of environment samples, due to requiring LLM annotations for each observation, or they require a diverse offline dataset, which may not exist or be impossible to collect. In this work, we address these limitations through a combination of algorithmic and systems-level contributions. We propose ONI, a distributed architecture that simultaneously learns an RL policy and an intrinsic reward function using LLM feedback. Our approach annotates the agent's collected experience via an asynchronous LLM server, which is then distilled into an intrinsic reward model. We explore a range of algorithmic choices for reward modeling with varying complexity, including hashing, classification, and ranking models. Our approach achieves state-of-the-art performance across a range of challenging tasks from the NetHack Learning Environment, while removing the need for large offline datasets required by prior work. We make our code available at https://github.com/facebookresearch/oni .
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DroidSpeak: KV Cache Sharing for Cross-LLM Communication and Multi-LLM Serving</title>
<link>https://arxiv.org/abs/2411.02820</link>
<guid>https://arxiv.org/abs/2411.02820</guid>
<content:encoded><![CDATA[
arXiv:2411.02820v4 Announce Type: replace 
Abstract: Compound AI systems, such as agentic systems, are an emerging trend in large-scale enterprise settings, with multiple LLMs specialized for different users, tasks, and/or roles working together. In these scenarios, different models often process inputs that share the same context prefix. Although much work was done in the past to enable the reuse of prefix KV caches across inputs for a single model, how to enable one model to reuse the prefix KV caches of a different model remains an open question.
  We introduce DroidSpeak, the first distributed LLM inference system that enables KV cache reuse across distributed nodes running inference of different LLMs, so long as the LLMs have the same architecture. We present the first study that aims at understanding the impact of sharing KV caches across different LLMs, and if/when such sharing affects quality. Inspired by the findings, we present DroidSpeak, which selectively recomputes a few layers of the KV cache produced by another LLM and reuses the remaining layers, with negligible quality loss. Moreover, carefully pipelining the layer-wise re-computation and the loading of reused KV cache further improves the inference performance. Experiments on diverse datasets and model pairs demonstrate that DroidSpeak achieves up to 4x throughput improvement and about 3.1x faster prefill (time to first token), with negligible loss of quality in F1 scores, Rouge-L or code similarity score, compared to the baseline which does not allow any sharing across models.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Crowd: A Social Network Simulation Framework</title>
<link>https://arxiv.org/abs/2412.10781</link>
<guid>https://arxiv.org/abs/2412.10781</guid>
<content:encoded><![CDATA[
arXiv:2412.10781v3 Announce Type: replace 
Abstract: To observe how individual behavior shapes a larger community's actions, agent-based modeling and simulation (ABMS) has been widely adopted by researchers in social sciences, economics, and epidemiology. While simulations can be run on general-purpose ABMS frameworks, these tools are not specifically designed for social networks and, therefore, provide limited features, increasing the effort required for complex simulations. In this paper, we introduce Crowd, a social network simulator that adopts the agent-based modeling methodology to model real-world phenomena within a network environment. Designed to facilitate easy and quick modeling, Crowd supports simulation setup through YAML configuration and enables further customization with user-defined methods. Other features include no-code simulations for diffusion tasks, interactive visualizations, data aggregation, and chart drawing facilities. Designed in Python, Crowd also supports generative agents and connects easily with Python's libraries for data analysis and machine learning. Finally, we include three case studies to illustrate the use of the framework, including generative agents in epidemics, influence maximization, and networked trust games.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Plancraft: an evaluation dataset for planning with LLM agents</title>
<link>https://arxiv.org/abs/2412.21033</link>
<guid>https://arxiv.org/abs/2412.21033</guid>
<content:encoded><![CDATA[
arXiv:2412.21033v2 Announce Type: replace 
Abstract: We present Plancraft, a multi-modal evaluation dataset for LLM agents. Plancraft has both a text-only and multi-modal interface, based on the Minecraft crafting GUI. We include the Minecraft Wiki to evaluate tool use and Retrieval Augmented Generation (RAG), as well as a handcrafted planner and Oracle Retriever, to ablate the different components of a modern agent architecture. To evaluate decision-making, Plancraft also includes a subset of examples that are intentionally unsolvable, providing a realistic challenge that requires the agent not only to complete tasks but also to decide whether they are solvable at all. We benchmark both open-source and closed-source LLMs and compare their performance and efficiency to a handcrafted planner. Overall, we find that LLMs and VLMs struggle with the planning problems that Plancraft introduces, and offer suggestions on how to improve their capabilities.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Reasoning: A Streamlined Framework for Enhancing LLM Reasoning with Agentic Tools</title>
<link>https://arxiv.org/abs/2502.04644</link>
<guid>https://arxiv.org/abs/2502.04644</guid>
<content:encoded><![CDATA[
arXiv:2502.04644v2 Announce Type: replace 
Abstract: We introduce Agentic Reasoning, a framework that enhances large language model (LLM) reasoning by integrating external tool-using agents. Agentic Reasoning dynamically leverages web search, code execution, and structured memory to address complex problems requiring deep research. A key innovation in our framework is the Mind-Map agent, which constructs a structured knowledge graph to store reasoning context and track logical relationships, ensuring coherence in long reasoning chains with extensive tool usage. Additionally, we conduct a comprehensive exploration of the Web-Search agent, leading to a highly effective search mechanism that surpasses all prior approaches. When deployed on DeepSeek-R1, our method achieves a new state-of-the-art (SOTA) among public models and delivers performance comparable to OpenAI Deep Research, the leading proprietary model in this domain. Extensive ablation studies validate the optimal selection of agentic tools and confirm the effectiveness of our Mind-Map and Web-Search agents in enhancing LLM reasoning. The code is at: https://github.com/theworldofagents/Agentic-Reasoning
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Imitation Learning from a Single Temporally Misaligned Video</title>
<link>https://arxiv.org/abs/2502.05397</link>
<guid>https://arxiv.org/abs/2502.05397</guid>
<content:encoded><![CDATA[
arXiv:2502.05397v2 Announce Type: replace 
Abstract: We examine the problem of learning sequential tasks from a single visual demonstration. A key challenge arises when demonstrations are temporally misaligned due to variations in timing, differences in embodiment, or inconsistencies in execution. Existing approaches treat imitation as a distribution-matching problem, aligning individual frames between the agent and the demonstration. However, we show that such frame-level matching fails to enforce temporal ordering or ensure consistent progress. Our key insight is that matching should instead be defined at the level of sequences. We propose that perfect matching occurs when one sequence successfully covers all the subgoals in the same order as the other sequence. We present ORCA (ORdered Coverage Alignment), a dense per-timestep reward function that measures the probability of the agent covering demonstration frames in the correct order. On temporally misaligned demonstrations, we show that agents trained with the ORCA reward achieve $4.5$x improvement ($0.11 \rightarrow 0.50$ average normalized returns) for Meta-world tasks and $6.6$x improvement ($6.55 \rightarrow 43.3$ average returns) for Humanoid-v4 tasks compared to the best frame-level matching algorithms. We also provide empirical analysis showing that ORCA is robust to varying levels of temporal misalignment. Our code is available at https://github.com/portal-cornell/orca/
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Odyssey of the Fittest: Can Agents Survive and Still Be Good?</title>
<link>https://arxiv.org/abs/2502.05442</link>
<guid>https://arxiv.org/abs/2502.05442</guid>
<content:encoded><![CDATA[
arXiv:2502.05442v3 Announce Type: replace 
Abstract: As AI models grow in power and generality, understanding how agents learn and make decisions in complex environments is critical to promoting ethical behavior. This study introduces the Odyssey, a lightweight, adaptive text based adventure game, providing a scalable framework for exploring AI ethics and safety. The Odyssey examines the ethical implications of implementing biological drives, specifically, self preservation, into three different agents. A Bayesian agent optimized with NEAT, a Bayesian agent optimized with stochastic variational inference, and a GPT 4o agent. The agents select actions at each scenario to survive, adapting to increasingly challenging scenarios. Post simulation analysis evaluates the ethical scores of the agent decisions, uncovering the tradeoffs it navigates to survive. Specifically, analysis finds that when danger increases, agents ethical behavior becomes unpredictable. Surprisingly, the GPT 4o agent outperformed the Bayesian models in both survival and ethical consistency, challenging assumptions about traditional probabilistic methods and raising a new challenge to understand the mechanisms of LLMs' probabilistic reasoning.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support</title>
<link>https://arxiv.org/abs/2502.18658</link>
<guid>https://arxiv.org/abs/2502.18658</guid>
<content:encoded><![CDATA[
arXiv:2502.18658v3 Announce Type: replace 
Abstract: AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and interaction context support alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Voting or Consensus? Decision-Making in Multi-Agent Debate</title>
<link>https://arxiv.org/abs/2502.19130</link>
<guid>https://arxiv.org/abs/2502.19130</guid>
<content:encoded><![CDATA[
arXiv:2502.19130v3 Announce Type: replace 
Abstract: Much of the success of multi-agent debates depends on carefully choosing the right parameters. The decision-making protocol stands out as it can highly impact final model answers, depending on how decisions are reached. Systematic comparison of decision protocols is difficult because many studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making influences different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time - the decision protocol - to analyze how different methods affect the collaboration between agents and measure differences in knowledge and reasoning tasks. Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks compared to other decision protocols. Increasing the number of agents improves performance, while more discussion rounds before voting reduce it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding</title>
<link>https://arxiv.org/abs/2503.10596</link>
<guid>https://arxiv.org/abs/2503.10596</guid>
<content:encoded><![CDATA[
arXiv:2503.10596v3 Announce Type: replace 
Abstract: Pixel grounding, encompassing tasks such as Referring Expression Segmentation (RES), has garnered considerable attention due to its immense potential for bridging the gap between vision and language modalities. However, advancements in this domain are currently constrained by limitations inherent in existing datasets, including limited object categories, insufficient textual diversity, and a scarcity of high-quality annotations. To mitigate these limitations, we introduce GroundingSuite, which comprises: (1) an automated data annotation framework leveraging multiple Vision-Language Model (VLM) agents; (2) a large-scale training dataset encompassing 9.56 million diverse referring expressions and their corresponding segmentations; and (3) a meticulously curated evaluation benchmark consisting of 3,800 images. The GroundingSuite training dataset facilitates substantial performance improvements, enabling models trained on it to achieve state-of-the-art results. Specifically, a cIoU of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the GroundingSuite annotation framework demonstrates superior efficiency compared to the current leading data annotation method, i.e., $4.5 \times$ faster than GLaMM.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Are AI Agents interacting with Online Ads?</title>
<link>https://arxiv.org/abs/2504.07112</link>
<guid>https://arxiv.org/abs/2504.07112</guid>
<content:encoded><![CDATA[
arXiv:2504.07112v4 Announce Type: replace 
Abstract: As AI-driven agents become increasingly integrated into the digital ecosystem, they reshape how online advertising is perceived and processed. Particularly in the travel and hotel booking sector, these autonomous systems influence the effectiveness of traditional advertising formats. While visual cues and emotional appeals sway human users, AI agents prioritize structured data such as price, availability, and specifications. This study examines how different AI agents interact with online advertising, whether they incorporate ads into their decision-making processes, and which ad formats prove most effective. We analyze interaction patterns, click behavior, and decision-making strategies through experiments with multimodal language models such as OpenAI GPT-4o, Anthropic Claude 3.7 Sonnet, and Google Gemini 2.0 Flash. Our findings reveal that AI agents neither ignore nor systematically avoid advertisements but instead favor certain features-particularly keywords and structured data. These insights have significant implications for the future design of advertising strategies in AI-dominated digital environments.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SocioVerse: A World Model for Social Simulation Powered by LLM Agents and A Pool of 10 Million Real-World Users</title>
<link>https://arxiv.org/abs/2504.10157</link>
<guid>https://arxiv.org/abs/2504.10157</guid>
<content:encoded><![CDATA[
arXiv:2504.10157v3 Announce Type: replace 
Abstract: Social simulation is transforming traditional social science research by modeling human behavior through interactions between virtual individuals and their environments. With recent advances in large language models (LLMs), this approach has shown growing potential in capturing individual differences and predicting group behaviors. However, existing methods face alignment challenges related to the environment, target users, interaction mechanisms, and behavioral patterns. To this end, we introduce SocioVerse, an LLM-agent-driven world model for social simulation. Our framework features four powerful alignment components and a user pool of 10 million real individuals. To validate its effectiveness, we conducted large-scale simulation experiments across three distinct domains: politics, news, and economics. Results demonstrate that SocioVerse can reflect large-scale population dynamics while ensuring diversity, credibility, and representativeness through standardized procedures and minimal manual adjustments.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seeking to Collide: Online Safety-Critical Scenario Generation for Autonomous Driving with Retrieval Augmented Large Language Models</title>
<link>https://arxiv.org/abs/2505.00972</link>
<guid>https://arxiv.org/abs/2505.00972</guid>
<content:encoded><![CDATA[
arXiv:2505.00972v2 Announce Type: replace 
Abstract: Simulation-based testing is crucial for validating autonomous vehicles (AVs), yet existing scenario generation methods either overfit to common driving patterns or operate in an offline, non-interactive manner that fails to expose rare, safety-critical corner cases. In this paper, we introduce an online, retrieval-augmented large language model (LLM) framework for generating safety-critical driving scenarios. Our method first employs an LLM-based behavior analyzer to infer the most dangerous intent of the background vehicle from the observed state, then queries additional LLM agents to synthesize feasible adversarial trajectories. To mitigate catastrophic forgetting and accelerate adaptation, we augment the framework with a dynamic memorization and retrieval bank of intent-planner pairs, automatically expanding its behavioral library when novel intents arise. Evaluations using the Waymo Open Motion Dataset demonstrate that our model reduces the mean minimum time-to-collision from 1.62 to 1.08 s and incurs a 75% collision rate, substantially outperforming baselines.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FalseReject: A Resource for Improving Contextual Safety and Mitigating Over-Refusals in LLMs via Structured Reasoning</title>
<link>https://arxiv.org/abs/2505.08054</link>
<guid>https://arxiv.org/abs/2505.08054</guid>
<content:encoded><![CDATA[
arXiv:2505.08054v2 Announce Type: replace 
Abstract: Safety alignment approaches in large language models (LLMs) often lead to the over-refusal of benign queries, significantly diminishing their utility in sensitive scenarios. To address this challenge, we introduce FalseReject, a comprehensive resource containing 16k seemingly toxic queries accompanied by structured responses across 44 safety-related categories. We propose a graph-informed adversarial multi-agent interaction framework to generate diverse and complex prompts, while structuring responses with explicit reasoning to aid models in accurately distinguishing safe from unsafe contexts. FalseReject includes training datasets tailored for both standard instruction-tuned models and reasoning-oriented models, as well as a human-annotated benchmark test set. Our extensive benchmarking on 29 state-of-the-art (SOTA) LLMs reveals persistent over-refusal challenges. Empirical results demonstrate that supervised finetuning with FalseReject substantially reduces unnecessary refusals without compromising overall safety or general language capabilities.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Semi-Competitive Differential Game Logic</title>
<link>https://arxiv.org/abs/2505.14688</link>
<guid>https://arxiv.org/abs/2505.14688</guid>
<content:encoded><![CDATA[
arXiv:2505.14688v2 Announce Type: replace 
Abstract: This paper introduces semi-competitive differential game logic dGLsc, which enables verification of safety-critical applications that involve interactions between two agents. In dGLsc, these interactions are specified as games on hybrid systems with two players that may collaborate with each other when helpful and may compete when necessary. The players in the hybrid games of dGLsc have individual goals that may overlap, leading to nonzero-sum games. This makes dGLsc especially well-suited for verifying situations where players, e.g., share safety objectives but otherwise pursue different goals, so that zero-sum assumptions lead to overly conservative results. Additionally, dGLsc solves the subtlety that even though each player may benefit from knowledge of the other player's goals, e.g., concerning shared safety objectives, unsafe situations might still occur if every player were to mutually assume the other player would act to avoid unsafety. The syntax and semantics, as well as a sound and relatively complete proof calculus are presented for dGLsc. The relationship between dGLsc and zero-sum differential game logic dGL is discussed and the purpose of dGLsc illustrated in a canonical example.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Multi-Modal LLM Agents for Treatment Planning in Focused Ultrasound Ablation Surgery</title>
<link>https://arxiv.org/abs/2505.21418</link>
<guid>https://arxiv.org/abs/2505.21418</guid>
<content:encoded><![CDATA[
arXiv:2505.21418v2 Announce Type: replace 
Abstract: Focused Ultrasound Ablation Surgery (FUAS) has emerged as a promising non-invasive therapeutic modality, valued for its safety and precision. Nevertheless, its clinical implementation entails intricate tasks such as multimodal image interpretation, personalized dose planning, and real-time intraoperative decision-making processes that demand intelligent assistance to improve efficiency and reliability. We introduce FUAS-Agents, an autonomous agent system that leverages the multimodal understanding and tool-using capabilities of large language models (LLMs). By integrating patient profiles and MRI data, FUAS-Agents orchestrates a suite of specialized medical AI tools, including segmentation, treatment dose prediction, and clinical guideline retrieval, to generate personalized treatment plans comprising MRI image, dose parameters, and therapeutic strategies. We evaluate the system in a uterine fibroid treatment scenario. Human assessment by four senior FUAS experts indicates that 82.5%, 82.5%, 87.5%, and 97.5% of the generated plans were rated 4 or above (on a 5-point scale) in terms of completeness, accuracy, fluency, and clinical compliance, respectively. These results demonstrate the potential of LLM-driven agents in enhancing decision-making across complex clinical workflows, and exemplify a translational paradigm that combines general-purpose models with specialized expert systems to solve practical challenges in vertical healthcare domains.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GUARD:Dual-Agent based Backdoor Defense on Chain-of-Thought in Neural Code Generation</title>
<link>https://arxiv.org/abs/2505.21425</link>
<guid>https://arxiv.org/abs/2505.21425</guid>
<content:encoded><![CDATA[
arXiv:2505.21425v2 Announce Type: replace 
Abstract: With the widespread application of large language models in code generation, recent studies demonstrate that employing additional Chain-of-Thought generation models can significantly enhance code generation performance by providing explicit reasoning steps. However, as external components, CoT models are particularly vulnerable to backdoor attacks, which existing defense mechanisms often fail to detect effectively. To address this challenge, we propose GUARD, a novel dual-agent defense framework specifically designed to counter CoT backdoor attacks in neural code generation. GUARD integrates two core components: GUARD-Judge, which identifies suspicious CoT steps and potential triggers through comprehensive analysis, and GUARD-Repair, which employs a retrieval-augmented generation approach to regenerate secure CoT steps for identified anomalies. Experimental results show that GUARD effectively mitigates attacks while maintaining generation quality, advancing secure code generation systems.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seven Security Challenges That Must be Solved in Cross-domain Multi-agent LLM Systems</title>
<link>https://arxiv.org/abs/2505.23847</link>
<guid>https://arxiv.org/abs/2505.23847</guid>
<content:encoded><![CDATA[
arXiv:2505.23847v3 Announce Type: replace 
Abstract: Large language models (LLMs) are rapidly evolving into autonomous agents that cooperate across organizational boundaries, enabling joint disaster response, supply-chain optimization, and other tasks that demand decentralized expertise without surrendering data ownership. Yet, cross-domain collaboration shatters the unified trust assumptions behind current alignment and containment techniques. An agent benign in isolation may, when receiving messages from an untrusted peer, leak secrets or violate policy, producing risks driven by emergent multi-agent dynamics rather than classical software bugs. This position paper maps the security agenda for cross-domain multi-agent LLM systems. We introduce seven categories of novel security challenges, for each of which we also present plausible attacks, security evaluation metrics, and future research guidelines.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A quantum semantic framework for natural language processing</title>
<link>https://arxiv.org/abs/2506.10077</link>
<guid>https://arxiv.org/abs/2506.10077</guid>
<content:encoded><![CDATA[
arXiv:2506.10077v2 Announce Type: replace 
Abstract: Semantic degeneracy represents a fundamental property of natural language that extends beyond simple polysemy to encompass the combinatorial explosion of potential interpretations that emerges as semantic expressions increase in complexity. In this work, we argue this property imposes fundamental limitations on Large Language Models (LLMs) and other modern NLP systems, precisely because they operate within natural language itself. Using Kolmogorov complexity, we demonstrate that as an expression's complexity grows, the amount of contextual information required to reliably resolve its ambiguity explodes combinatorially. The computational intractability of recovering a single intended meaning for complex or ambiguous text therefore suggests that the classical view that linguistic forms possess intrinsic meaning in and of themselves is conceptually inadequate. We argue instead that meaning is dynamically actualized through an observer-dependent interpretive act, a process whose non-deterministic nature is most appropriately described by a non-classical, quantum-like logic. To test this hypothesis, we conducted a semantic Bell inequality test using diverse LLM agents. Our experiments yielded average CHSH expectation values from 1.2 to 2.8, with several runs producing values (e.g., 2.3-2.4) in significant violation of the classical boundary ($|S|\leq2$), demonstrating that linguistic interpretation under ambiguity can exhibit non-classical contextuality, consistent with results from human cognition experiments. These results inherently imply that classical frequentist-based analytical approaches for natural language are necessarily lossy. Instead, we propose that Bayesian-style repeated sampling approaches can provide more practically useful and appropriate characterizations of linguistic meaning in context.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>View Invariant Learning for Vision-Language Navigation in Continuous Environments</title>
<link>https://arxiv.org/abs/2507.08831</link>
<guid>https://arxiv.org/abs/2507.08831</guid>
<content:encoded><![CDATA[
arXiv:2507.08831v1 Announce Type: new 
Abstract: Vision-Language Navigation in Continuous Environments (VLNCE), where an agent follows instructions and moves freely to reach a destination, is a key research problem in embodied AI. However, most navigation policies are sensitive to viewpoint changes, i.e., variations in camera height and viewing angle that alter the agent's observation. In this paper, we introduce a generalized scenario, V2-VLNCE (VLNCE with Varied Viewpoints), and propose VIL (View Invariant Learning), a view-invariant post-training strategy that enhances the robustness of existing navigation policies to changes in camera viewpoint. VIL employs a contrastive learning framework to learn sparse and view-invariant features. Additionally, we introduce a teacher-student framework for the Waypoint Predictor Module, a core component of most VLNCE baselines, where a view-dependent teacher model distills knowledge into a view-invariant student model. We employ an end-to-end training paradigm to jointly optimize these components, thus eliminating the cost for individual module training. Empirical results show that our method outperforms state-of-the-art approaches on V2-VLNCE by 8-15% measured on Success Rate for two standard benchmark datasets R2R-CE and RxR-CE. Furthermore, we evaluate VIL under the standard VLNCE setting and find that, despite being trained for varied viewpoints, it often still improves performance. On the more challenging RxR-CE dataset, our method also achieved state-of-the-art performance across all metrics when compared to other map-free methods. This suggests that adding VIL does not diminish the standard viewpoint performance and can serve as a plug-and-play post-training method.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent-based visualization of streaming text</title>
<link>https://arxiv.org/abs/2507.08884</link>
<guid>https://arxiv.org/abs/2507.08884</guid>
<content:encoded><![CDATA[
arXiv:2507.08884v1 Announce Type: new 
Abstract: We present a visualization infrastructure that maps data elements to agents, which have behaviors parameterized by those elements. Dynamic visualizations emerge as the agents change position, alter appearance and respond to one other. Agents move to minimize the difference between displayed agent-to-agent distances, and an input matrix of ideal distances. Our current application is visualization of streaming text. Each agent represents a significant word, visualizing it by displaying the word itself, centered in a circle sized by the frequency of word occurrence. We derive the ideal distance matrix from word cooccurrence, mapping higher co-occurrence to lower distance. To depict co-occurrence in its textual context, the ratio of intersection to circle area approximates the ratio of word co-occurrence to frequency. A networked backend process gathers articles from news feeds, blogs, Digg or Twitter, exploiting online search APIs to focus on user-chosen topics. Resulting visuals reveal the primary topics in text streams as clusters, with agent-based layout moving without instability as data streams change dynamically.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AirScape: An Aerial Generative World Model with Motion Controllability</title>
<link>https://arxiv.org/abs/2507.08885</link>
<guid>https://arxiv.org/abs/2507.08885</guid>
<content:encoded><![CDATA[
arXiv:2507.08885v1 Announce Type: new 
Abstract: How to enable robots to predict the outcomes of their own motion intentions in three-dimensional space has been a fundamental problem in embodied intelligence. To explore more general spatial imagination capabilities, here we present AirScape, the first world model designed for six-degree-of-freedom aerial agents. AirScape predicts future observation sequences based on current visual inputs and motion intentions. Specifically, we construct an dataset for aerial world model training and testing, which consists of 11k video-intention pairs. This dataset includes first-person-view videos capturing diverse drone actions across a wide range of scenarios, with over 1,000 hours spent annotating the corresponding motion intentions. Then we develop a two-phase training schedule to train a foundation model -- initially devoid of embodied spatial knowledge -- into a world model that is controllable by motion intentions and adheres to physical spatio-temporal constraints.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Sequential Multi-Step Tasks with Parallel LLM Agents</title>
<link>https://arxiv.org/abs/2507.08944</link>
<guid>https://arxiv.org/abs/2507.08944</guid>
<content:encoded><![CDATA[
arXiv:2507.08944v1 Announce Type: new 
Abstract: Large language model (LLM)-based multi-agent systems have demonstrated remarkable promise for tackling complex tasks by breaking them down into subtasks that are iteratively planned, executed, observed, and refined. Despite their effectiveness, these systems often incur high latency because real-world problems frequently demand multiple iterative cycles of reasoning steps. To address this challenge, we propose M1-Parallel, a framework that concurrently runs multiple multi-agent teams in parallel to uncover distinct solution paths. By leveraging an event-driven communication model with asynchronous messaging, M1-Parallel efficiently capitalizes on the inherent diversity of valid plans to either reduce end-to-end latency or boost task completion rates. Our experiments on complex tasks show that M1-Parallel with early termination achieves up to $2.2\times$ speedup while preserving accuracy, and that M1-Parallel with aggregation yields higher task completion rates. We further investigate strategies aimed at encouraging diverse execution plans but observe no additional performance gains over repeated sampling. Overall, these findings underscore the potential of parallel plan execution for optimizing multi-agent systems for real-world, high-complexity reasoning tasks.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How to Train a Leader: Hierarchical Reasoning in Multi-Agent LLMs</title>
<link>https://arxiv.org/abs/2507.08960</link>
<guid>https://arxiv.org/abs/2507.08960</guid>
<content:encoded><![CDATA[
arXiv:2507.08960v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have achieved strong performance on a wide range of complex reasoning tasks, yet further gains are often possible by leveraging the complementary strengths of multiple models. While multi-agent frameworks can improve solution quality by leveraging multiple LLMs, existing methods are often computationally expensive, both at training and inference time. In this work, we introduce a hierarchical multi-agent framework that addresses these challenges by training only a single leader LLM to coordinate a team of untrained peer agents. To this end, we propose Multi-agent guided Leader Policy \textbf{O}ptimization (MLPO), a novel approach which trains the leader to evaluate and synthesize agent responses without auxiliary value networks or explicit agent feedback. Leaders trained with MLPO exhibit improved performance not only when interacting with the agent team at inference time, but also enjoy improved performance when deployed in single-agent settings without the team. Empirical results on Big-Bench Hard (BBH), MATH, and MMLU demonstrate that our framework achieves substantial performance improvements over both single-agent and multi-agent baselines. Our results highlight the effectiveness and efficiency of training a single, flexible leader for collaborative reasoning in multi-agent LLM systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Accelerating Drug Discovery Through Agentic AI: A Multi-Agent Approach to Laboratory Automation in the DMTA Cycle</title>
<link>https://arxiv.org/abs/2507.09023</link>
<guid>https://arxiv.org/abs/2507.09023</guid>
<content:encoded><![CDATA[
arXiv:2507.09023v1 Announce Type: new 
Abstract: The pharmaceutical industry faces unprecedented challenges in drug discovery, with traditional approaches struggling to meet modern therapeutic development demands. This paper introduces a novel AI framework, Tippy, that transforms laboratory automation through specialized AI agents operating within the Design-Make-Test-Analyze (DMTA) cycle. Our multi-agent system employs five specialized agents - Supervisor, Molecule, Lab, Analysis, and Report, with Safety Guardrail oversight - each designed to excel in specific phases of the drug discovery pipeline. Tippy represents the first production-ready implementation of specialized AI agents for automating the DMTA cycle, providing a concrete example of how AI can transform laboratory workflows. By leveraging autonomous AI agents that reason, plan, and collaborate, we demonstrate how Tippy accelerates DMTA cycles while maintaining scientific rigor essential for pharmaceutical research. The system shows significant improvements in workflow efficiency, decision-making speed, and cross-disciplinary coordination, offering a new paradigm for AI-assisted drug discovery.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Behavioral Exploration: Learning to Explore via In-Context Adaptation</title>
<link>https://arxiv.org/abs/2507.09041</link>
<guid>https://arxiv.org/abs/2507.09041</guid>
<content:encoded><![CDATA[
arXiv:2507.09041v1 Announce Type: new 
Abstract: Developing autonomous agents that quickly explore an environment and adapt their behavior online is a canonical challenge in robotics and machine learning. While humans are able to achieve such fast online exploration and adaptation, often acquiring new information and skills in only a handful of interactions, existing algorithmic approaches tend to rely on random exploration and slow, gradient-based behavior updates. How can we endow autonomous agents with such capabilities on par with humans? Taking inspiration from recent progress on both in-context learning and large-scale behavioral cloning, in this work we propose behavioral exploration: training agents to internalize what it means to explore and adapt in-context over the space of ``expert'' behaviors. To achieve this, given access to a dataset of expert demonstrations, we train a long-context generative model to predict expert actions conditioned on a context of past observations and a measure of how ``exploratory'' the expert's behaviors are relative to this context. This enables the model to not only mimic the behavior of an expert, but also, by feeding its past history of interactions into its context, to select different expert behaviors than what have been previously selected, thereby allowing for fast online adaptation and targeted, ``expert-like'' exploration. We demonstrate the effectiveness of our method in both simulated locomotion and manipulation settings, as well as on real-world robotic manipulation tasks, illustrating its ability to learn adaptive, exploratory behavior.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SetupBench: Assessing Software Engineering Agents' Ability to Bootstrap Development Environments</title>
<link>https://arxiv.org/abs/2507.09063</link>
<guid>https://arxiv.org/abs/2507.09063</guid>
<content:encoded><![CDATA[
arXiv:2507.09063v1 Announce Type: new 
Abstract: Modern Large Language Model (LLM) agents promise end to end assistance with real-world software tasks, yet existing benchmarks evaluate LLM agents almost exclusively in pre-baked environments where every dependency is pre-installed. To fill this gap, we introduce SetupBench, a 93 instance benchmark that isolates the environment-bootstrap skill: starting from a bare Linux sandbox, an agent must install packages, resolve dependency conflicts, initialize databases, and configure background services. Our tasks span seven language ecosystems, five database engines, and multi-service orchestration scenarios, each accompanies by a natural language problem statement and a deterministic success command. Through evaluation of OpenHands, a state-of-the-art coding agent, we find low success rates across task categories, with particular challenges in repository setup (38.9-57.4%) and local database configuration (20.0-53.3%). Our analysis reveals systematic failure modes including incomplete development tooling installation, hallucinated task constraints, and non-persistent environment modifications that break agent-human collaboration workflows. We identify substantial inefficiencies in agent exploration strategies, with 38-89% of actions being unnecessary compared to optimal human behavior. These findings highlight gaps in current agents' practical environment-bootstrap capabilities. By targeting this critical yet under-evaluated capability, SetupBench provides a rigorous yard-stick for the next generation of software developer agents aiming to solve end to end real-wold tasks.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Infinite Video Understanding</title>
<link>https://arxiv.org/abs/2507.09068</link>
<guid>https://arxiv.org/abs/2507.09068</guid>
<content:encoded><![CDATA[
arXiv:2507.09068v1 Announce Type: new 
Abstract: The rapid advancements in Large Language Models (LLMs) and their multimodal extensions (MLLMs) have ushered in remarkable progress in video understanding. However, a fundamental challenge persists: effectively processing and comprehending video content that extends beyond minutes or hours. While recent efforts like Video-XL-2 have demonstrated novel architectural solutions for extreme efficiency, and advancements in positional encoding such as HoPE and VideoRoPE++ aim to improve spatio-temporal understanding over extensive contexts, current state-of-the-art models still encounter significant computational and memory constraints when faced with the sheer volume of visual tokens from lengthy sequences. Furthermore, maintaining temporal coherence, tracking complex events, and preserving fine-grained details over extended periods remain formidable hurdles, despite progress in agentic reasoning systems like Deep Video Discovery. This position paper posits that a logical, albeit ambitious, next frontier for multimedia research is Infinite Video Understanding -- the capability for models to continuously process, understand, and reason about video data of arbitrary, potentially never-ending duration. We argue that framing Infinite Video Understanding as a blue-sky research objective provides a vital north star for the multimedia, and the wider AI, research communities, driving innovation in areas such as streaming architectures, persistent memory mechanisms, hierarchical and adaptive representations, event-centric reasoning, and novel evaluation paradigms. Drawing inspiration from recent work on long/ultra-long video understanding and several closely related fields, we outline the core challenges and key research directions towards achieving this transformative capability.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning from Synthetic Labs: Language Models as Auction Participants</title>
<link>https://arxiv.org/abs/2507.09083</link>
<guid>https://arxiv.org/abs/2507.09083</guid>
<content:encoded><![CDATA[
arXiv:2507.09083v1 Announce Type: new 
Abstract: This paper investigates the behavior of simulated AI agents (large language models, or LLMs) in auctions, introducing a novel synthetic data-generating process to help facilitate the study and design of auctions. We find that LLMs -- when endowed with chain of thought reasoning capacity -- agree with the experimental literature in auctions across a variety of classic auction formats. In particular, we find that LLM bidders produce results consistent with risk-averse human bidders; that they perform closer to theoretical predictions in obviously strategy-proof auctions; and, that they succumb to the winner's curse in common value settings. On prompting, we find that LLMs are not very sensitive to naive changes in prompts (e.g., language, currency) but can improve dramatically towards theoretical predictions with the right mental model (i.e., the language of Nash deviations). We run 1,000$+$ auctions for less than $\$$400 with GPT-4 models (three orders of magnitude cheaper than modern auction experiments) and develop a framework flexible enough to run auction experiments with any LLM model and a wide range of auction design specifications, facilitating further experimental study by decreasing costs and serving as a proof-of-concept for the use of LLM proxies.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transformer based Collaborative Reinforcement Learning for Fluid Antenna System (FAS)-enabled 3D UAV Positioning</title>
<link>https://arxiv.org/abs/2507.09094</link>
<guid>https://arxiv.org/abs/2507.09094</guid>
<content:encoded><![CDATA[
arXiv:2507.09094v1 Announce Type: new 
Abstract: In this paper, a novel Three dimensional (3D) positioning framework of fluid antenna system (FAS)-enabled unmanned aerial vehicles (UAVs) is developed. In the proposed framework, a set of controlled UAVs cooperatively estimate the real-time 3D position of a target UAV. Here, the active UAV transmits a measurement signal to the passive UAVs via the reflection from the target UAV. Each passive UAV estimates the distance of the active-target-passive UAV link and selects an antenna port to share the distance information with the base station (BS) that calculates the real-time position of the target UAV. As the target UAV is moving due to its task operation, the controlled UAVs must optimize their trajectories and select optimal antenna port, aiming to estimate the real-time position of the target UAV. We formulate this problem as an optimization problem to minimize the target UAV positioning error via optimizing the trajectories of all controlled UAVs and antenna port selection of passive UAVs. Here, an attention-based recurrent multi-agent reinforcement learning (AR-MARL) scheme is proposed, which enables each controlled UAV to use the local Q function to determine its trajectory and antenna port while optimizing the target UAV positioning performance without knowing the trajectories and antenna port selections of other controlled UAVs. Different from current MARL methods, the proposed method uses a recurrent neural network (RNN) that incorporates historical state-action pairs of each controlled UAV, and an attention mechanism to analyze the importance of these historical state-action pairs, thus improving the global Q function approximation accuracy and the target UAV positioning accuracy. Simulation results show that the proposed AR-MARL scheme can reduce the average positioning error by up to 17.5% and 58.5% compared to the VD-MARL scheme and the proposed method without FAS.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RadEyeVideo: Enhancing general-domain Large Vision Language Model for chest X-ray analysis with video representations of eye gaze</title>
<link>https://arxiv.org/abs/2507.09097</link>
<guid>https://arxiv.org/abs/2507.09097</guid>
<content:encoded><![CDATA[
arXiv:2507.09097v1 Announce Type: new 
Abstract: Large Vision-Language Models (LVLMs) have demonstrated promising performance in chest X-ray (CXR) analysis. To enhance human-computer interaction, several studies have incorporated radiologists' eye gaze, typically through heatmaps or textual prompts. However, these methods often overlook the sequential order of eye movements, which could provide valuable insights by highlighting both the areas of interest and the order in which they are examined. In this work, we propose a novel approach called RadEyeVideo that integrates radiologists' eye-fixation data as a video sequence, capturing both the temporal and spatial dynamics of their gaze. We evaluate this method in CXR report generation and disease diagnosis using three general-domain, open-source LVLMs with video input capabilities. When prompted with eye-gaze videos, model performance improves by up to 24.6% in the report generation task and on average 15.2% for both tasks using scaled evaluation metrics. Notably, RadEyeVideo enhanced an open-domain LVLM model, LLaVA-OneVision, to surpass task-specific medical LVLMs such as MAIRA-2 and CheXagent, trained on large Chest X-ray data. This work highlights that domain expert's knowledge (eye-gaze information in this case), when effectively integrated with LVLMs, can significantly enhance general-domain models' capabilities in clinical tasks. RadEyeVideo is a step toward a scalable human-centered approach of utilizing LVLMs in medical image analytics.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AInsight: Augmenting Expert Decision-Making with On-the-Fly Insights Grounded in Historical Data</title>
<link>https://arxiv.org/abs/2507.09100</link>
<guid>https://arxiv.org/abs/2507.09100</guid>
<content:encoded><![CDATA[
arXiv:2507.09100v1 Announce Type: new 
Abstract: In decision-making conversations, experts must navigate complex choices and make on-the-spot decisions while engaged in conversation. Although extensive historical data often exists, the real-time nature of these scenarios makes it infeasible for decision-makers to review and leverage relevant information. This raises an interesting question: What if experts could utilize relevant past data in real-time decision-making through insights derived from past data? To explore this, we implemented a conversational user interface, taking doctor-patient interactions as an example use case. Our system continuously listens to the conversation, identifies patient problems and doctor-suggested solutions, and retrieves related data from an embedded dataset, generating concise insights using a pipeline built around a retrieval-based Large Language Model (LLM) agent. We evaluated the prototype by embedding Health Canada datasets into a vector database and conducting simulated studies using sample doctor-patient dialogues, showing effectiveness but also challenges, setting directions for the next steps of our work.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proactive AI-and-RAN Workload Orchestration in O-RAN Architectures for 6G Networks</title>
<link>https://arxiv.org/abs/2507.09124</link>
<guid>https://arxiv.org/abs/2507.09124</guid>
<content:encoded><![CDATA[
arXiv:2507.09124v1 Announce Type: new 
Abstract: The vision of AI-RAN convergence, as advocated by the AI-RAN Alliance, aims to unlock a unified 6G platform capable of seamlessly supporting AI and RAN workloads over shared infrastructure. However, the architectural framework and intelligent resource orchestration strategies necessary to realize this vision remain largely unexplored. In this paper, we propose a Converged AI-and-ORAN Architectural (CAORA) framework based on O-RAN specifications, enabling the dynamic coexistence of real-time RAN and computationally intensive AI workloads. We design custom xApps within the Near-Real-Time RAN Intelligent Controller (NRT-RIC) to monitor RAN KPIs and expose radio analytics to an End-to-End (E2E) orchestrator via the recently introduced Y1 interface. The orchestrator incorporates workload forecasting and anomaly detection modules, augmenting a Soft Actor-Critic (SAC) reinforcement learning agent that proactively manages resource allocation, including Multi-Instance GPU (MIG) partitioning. Using real-world 5G traffic traces from Barcelona, our trace-driven simulations demonstrate that CAORA achieves near 99\% fulfillment of RAN demands, supports dynamic AI workloads, and maximizes infrastructure utilization even under highly dynamic conditions. Our results reveal that predictive orchestration significantly improves system adaptability, resource efficiency, and service continuity, offering a viable blueprint for future AI-and-RAN converged 6G systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Study of Value-Aware Eigenoptions</title>
<link>https://arxiv.org/abs/2507.09127</link>
<guid>https://arxiv.org/abs/2507.09127</guid>
<content:encoded><![CDATA[
arXiv:2507.09127v1 Announce Type: new 
Abstract: Options, which impose an inductive bias toward temporal and hierarchical structure, offer a powerful framework for reinforcement learning (RL). While effective in sequential decision-making, they are often handcrafted rather than learned. Among approaches for discovering options, eigenoptions have shown strong performance in exploration, but their role in credit assignment remains underexplored. In this paper, we investigate whether eigenoptions can accelerate credit assignment in model-free RL, evaluating them in tabular and pixel-based gridworlds. We find that pre-specified eigenoptions aid not only exploration but also credit assignment, whereas online discovery can bias the agent's experience too strongly and hinder learning. In the context of deep RL, we also propose a method for learning option-values under non-linear function approximation, highlighting the impact of termination conditions on performance. Our findings reveal both the promise and complexity of using eigenoptions, and options more broadly, to simultaneously support credit assignment and exploration in reinforcement learning.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tactile-VLA: Unlocking Vision-Language-Action Model's Physical Knowledge for Tactile Generalization</title>
<link>https://arxiv.org/abs/2507.09160</link>
<guid>https://arxiv.org/abs/2507.09160</guid>
<content:encoded><![CDATA[
arXiv:2507.09160v1 Announce Type: new 
Abstract: Vision-Language-Action (VLA) models have shown remarkable achievements, driven by the rich implicit knowledge of their vision-language components. However, achieving generalist robotic agents demands precise grounding into physical interactions, especially in contact-rich scenarios where fine-grained force control is essential. We advance VLAs' implicit knowledge beyond identifying what to do, towards guiding how to physically interact with real world. This paper introduces Tactile-VLA, a novel framework that deeply fuses vision, language, action, and tactile sensing. This framework incorporates a hybrid position-force controller to translate the model's intentions into precise physical actions and a reasoning module that allows the robot to adapt its strategy based on tactile feedback. Experiments demonstrate Tactile-VLA's effectiveness and generalizability in three key aspects: (1) enabling tactile-aware instruction following, (2) utilizing tactile-relevant commonsense, and (3) facilitating adaptive tactile-involved reasoning. A key finding is that the VLM's prior knowledge already contains semantic understanding of physical interaction; by connecting it to the robot's tactile sensors with only a few demonstrations, we can activate this prior knowledge to achieve zero-shot generalization in contact-rich tasks.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RAMA: Retrieval-Augmented Multi-Agent Framework for Misinformation Detection in Multimodal Fact-Checking</title>
<link>https://arxiv.org/abs/2507.09174</link>
<guid>https://arxiv.org/abs/2507.09174</guid>
<content:encoded><![CDATA[
arXiv:2507.09174v1 Announce Type: new 
Abstract: The rapid proliferation of multimodal misinformation presents significant challenges for automated fact-checking systems, especially when claims are ambiguous or lack sufficient context. We introduce RAMA, a novel retrieval-augmented multi-agent framework designed for verifying multimedia misinformation. RAMA incorporates three core innovations: (1) strategic query formulation that transforms multimodal claims into precise web search queries; (2) cross-verification evidence aggregation from diverse, authoritative sources; and (3) a multi-agent ensemble architecture that leverages the complementary strengths of multiple multimodal large language models and prompt variants. Extensive experiments demonstrate that RAMA achieves superior performance on benchmark datasets, particularly excelling in resolving ambiguous or improbable claims by grounding verification in retrieved factual evidence. Our findings underscore the necessity of integrating web-based evidence and multi-agent reasoning for trustworthy multimedia verification, paving the way for more reliable and scalable fact-checking solutions. RAMA will be publicly available at https://github.com/kalendsyang/RAMA.git.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Continual Reinforcement Learning by Planning with Online World Models</title>
<link>https://arxiv.org/abs/2507.09177</link>
<guid>https://arxiv.org/abs/2507.09177</guid>
<content:encoded><![CDATA[
arXiv:2507.09177v1 Announce Type: new 
Abstract: Continual reinforcement learning (CRL) refers to a naturalistic setting where an agent needs to endlessly evolve, by trial and error, to solve multiple tasks that are presented sequentially. One of the largest obstacles to CRL is that the agent may forget how to solve previous tasks when learning a new task, known as catastrophic forgetting. In this paper, we propose to address this challenge by planning with online world models. Specifically, we learn a Follow-The-Leader shallow model online to capture the world dynamics, in which we plan using model predictive control to solve a set of tasks specified by any reward functions. The online world model is immune to forgetting by construction with a proven regret bound of $\mathcal{O}(\sqrt{K^2D\log(T)})$ under mild assumptions. The planner searches actions solely based on the latest online model, thus forming a FTL Online Agent (OA) that updates incrementally. To assess OA, we further design Continual Bench, a dedicated environment for CRL, and compare with several strong baselines under the same model-planning algorithmic framework. The empirical results show that OA learns continuously to solve new tasks while not forgetting old skills, outperforming agents built on deep world models with various continual learning techniques.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hide-and-Shill: A Reinforcement Learning Framework for Market Manipulation Detection in Symphony-a Decentralized Multi-Agent System</title>
<link>https://arxiv.org/abs/2507.09179</link>
<guid>https://arxiv.org/abs/2507.09179</guid>
<content:encoded><![CDATA[
arXiv:2507.09179v1 Announce Type: new 
Abstract: Decentralized finance (DeFi) has introduced a new era of permissionless financial innovation but also led to unprecedented market manipulation. Without centralized oversight, malicious actors coordinate shilling campaigns and pump-and-dump schemes across various platforms. We propose a Multi-Agent Reinforcement Learning (MARL) framework for decentralized manipulation detection, modeling the interaction between manipulators and detectors as a dynamic adversarial game. This framework identifies suspicious patterns using delayed token price reactions as financial indicators.Our method introduces three innovations: (1) Group Relative Policy Optimization (GRPO) to enhance learning stability in sparse-reward and partially observable settings; (2) a theory-based reward function inspired by rational expectations and information asymmetry, differentiating price discovery from manipulation noise; and (3) a multi-modal agent pipeline that integrates LLM-based semantic features, social graph signals, and on-chain market data for informed decision-making.The framework is integrated within the Symphony system, a decentralized multi-agent architecture enabling peer-to-peer agent execution and trust-aware learning through distributed logs, supporting chain-verifiable evaluation. Symphony promotes adversarial co-evolution among strategic actors and maintains robust manipulation detection without centralized oracles, enabling real-time surveillance across global DeFi ecosystems.Trained on 100,000 real-world discourse episodes and validated in adversarial simulations, Hide-and-Shill achieves top performance in detection accuracy and causal attribution. This work bridges multi-agent systems with financial surveillance, advancing a new paradigm for decentralized market intelligence. All resources are available at the Hide-and-Shill GitHub repository to promote open research and reproducibility.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StockSim: A Dual-Mode Order-Level Simulator for Evaluating Multi-Agent LLMs in Financial Markets</title>
<link>https://arxiv.org/abs/2507.09255</link>
<guid>https://arxiv.org/abs/2507.09255</guid>
<content:encoded><![CDATA[
arXiv:2507.09255v1 Announce Type: new 
Abstract: We present StockSim, an open-source simulation platform for systematic evaluation of large language models (LLMs) in realistic financial decision-making scenarios. Unlike previous toolkits that offer limited scope, StockSim delivers a comprehensive system that fully models market dynamics and supports diverse simulation modes of varying granularity. It incorporates critical real-world factors, such as latency, slippage, and order-book microstructure, that were previously neglected, enabling more faithful and insightful assessment of LLM-based trading agents. An extensible, role-based agent framework supports heterogeneous trading strategies and multi-agent coordination, making StockSim a uniquely capable testbed for NLP research on reasoning under uncertainty and sequential decision-making. We open-source all our code at https: //github.com/harrypapa2002/StockSim.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Developer Aid Becomes Security Debt: A Systematic Analysis of Insecure Behaviors in LLM Coding Agents</title>
<link>https://arxiv.org/abs/2507.09329</link>
<guid>https://arxiv.org/abs/2507.09329</guid>
<content:encoded><![CDATA[
arXiv:2507.09329v1 Announce Type: new 
Abstract: LLM-based coding agents are rapidly being deployed in software development, yet their security implications remain poorly understood. These agents, while capable of accelerating software development, may inadvertently introduce insecure practices. We conducted the first systematic security evaluation of autonomous coding agents, analyzing over 12,000 actions across five state-of-the-art models (GPT-4o, GPT-4.1, Claude variants) on 93 real-world software setup tasks. Our findings reveal significant security concerns: 21% of agent trajectories contained insecure actions, with models showing substantial variation in security behavior. We developed a high-precision detection system that identified four major vulnerability categories, with information exposure (CWE-200) being the most prevalent one. We also evaluated mitigation strategies including feedback mechanisms and security reminders with various effectiveness between models. GPT-4.1 demonstrated exceptional security awareness with 96.8% mitigation success. Our work provides the first comprehensive framework for evaluating coding agent security and highlights the need for security-aware design of next generation LLM-based coding agents.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulation for All: A Step-by-Step Cookbook for Developing Human-Centered Multi-Agent Transportation Simulators</title>
<link>https://arxiv.org/abs/2507.09367</link>
<guid>https://arxiv.org/abs/2507.09367</guid>
<content:encoded><![CDATA[
arXiv:2507.09367v1 Announce Type: new 
Abstract: As cities evolve toward more complex and multimodal transportation systems, the need for human-centered multi-agent simulation tools has never been more urgent. Yet most existing platforms remain limited - they often separate different types of road users, rely on scripted or pre-defined behaviors, overlook public transit users as active participants, and are rarely designed with accessibility in mind for non-technical users. To address this gap, this paper presents the specifications of a multi-agent simulation platform designed to support real-time, human-centered, and immersive studies of all road users, accompanied by open-source scripts for replication. Using high-fidelity immersive virtual environments, our platform enables interaction across public transit users, pedestrians, cyclists, automated vehicles, and drivers. The architecture is modular, extensible, and designed for accessibility. The system integrates hardware-specific modules - including an omnidirectional treadmill, a seating arrangement, a smart trainer, and an actuated cockpit. Additionally, the platform collects multimodal physiological, neurological, and behavioral data through embedded sensing devices such as functional near-infrared spectroscopy (fNIRS), eye tracking, and wrist-based biosensors. To show the usability of this system, we present three use cases. Simulation for All aims to lower the barrier to entry for high-fidelity transportation simulation, support experimentation across disciplines, and advance our understanding of multimodal mobility in complex urban environments.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constrained Style Learning from Imperfect Demonstrations under Task Optimality</title>
<link>https://arxiv.org/abs/2507.09371</link>
<guid>https://arxiv.org/abs/2507.09371</guid>
<content:encoded><![CDATA[
arXiv:2507.09371v1 Announce Type: new 
Abstract: Learning from demonstration has proven effective in robotics for acquiring natural behaviors, such as stylistic motions and lifelike agility, particularly when explicitly defining style-oriented reward functions is challenging. Synthesizing stylistic motions for real-world tasks usually requires balancing task performance and imitation quality. Existing methods generally depend on expert demonstrations closely aligned with task objectives. However, practical demonstrations are often incomplete or unrealistic, causing current methods to boost style at the expense of task performance. To address this issue, we propose formulating the problem as a constrained Markov Decision Process (CMDP). Specifically, we optimize a style-imitation objective with constraints to maintain near-optimal task performance. We introduce an adaptively adjustable Lagrangian multiplier to guide the agent to imitate demonstrations selectively, capturing stylistic nuances without compromising task performance. We validate our approach across multiple robotic platforms and tasks, demonstrating both robust task performance and high-fidelity style learning. On ANYmal-D hardware we show a 14.5% drop in mechanical energy and a more agile gait pattern, showcasing real-world benefits.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Knowledge Conceptualization Impacts RAG Efficacy</title>
<link>https://arxiv.org/abs/2507.09389</link>
<guid>https://arxiv.org/abs/2507.09389</guid>
<content:encoded><![CDATA[
arXiv:2507.09389v1 Announce Type: new 
Abstract: Explainability and interpretability are cornerstones of frontier and next-generation artificial intelligence (AI) systems. This is especially true in recent systems, such as large language models (LLMs), and more broadly, generative AI. On the other hand, adaptability to new domains, contexts, or scenarios is also an important aspect for a successful system. As such, we are particularly interested in how we can merge these two efforts, that is, investigating the design of transferable and interpretable neurosymbolic AI systems. Specifically, we focus on a class of systems referred to as ''Agentic Retrieval-Augmented Generation'' systems, which actively select, interpret, and query knowledge sources in response to natural language prompts. In this paper, we systematically evaluate how different conceptualizations and representations of knowledge, particularly the structure and complexity, impact an AI agent (in this case, an LLM) in effectively querying a triplestore. We report our results, which show that there are impacts from both approaches, and we discuss their impact and implications.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM-Stackelberg Games: Conjectural Reasoning Equilibria and Their Applications to Spearphishing</title>
<link>https://arxiv.org/abs/2507.09407</link>
<guid>https://arxiv.org/abs/2507.09407</guid>
<content:encoded><![CDATA[
arXiv:2507.09407v1 Announce Type: new 
Abstract: We introduce the framework of LLM-Stackelberg games, a class of sequential decision-making models that integrate large language models (LLMs) into strategic interactions between a leader and a follower. Departing from classical Stackelberg assumptions of complete information and rational agents, our formulation allows each agent to reason through structured prompts, generate probabilistic behaviors via LLMs, and adapt their strategies through internal cognition and belief updates. We define two equilibrium concepts: reasoning and behavioral equilibrium, which aligns an agent's internal prompt-based reasoning with observable behavior, and conjectural reasoning equilibrium, which accounts for epistemic uncertainty through parameterized models over an opponent's response. These layered constructs capture bounded rationality, asymmetric information, and meta-cognitive adaptation. We illustrate the framework through a spearphishing case study, where a sender and a recipient engage in a deception game using structured reasoning prompts. This example highlights the cognitive richness and adversarial potential of LLM-mediated interactions. Our results show that LLM-Stackelberg games provide a powerful paradigm for modeling decision-making in domains such as cybersecurity, misinformation, and recommendation systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Social Learning using Theory of Mind</title>
<link>https://arxiv.org/abs/2507.09409</link>
<guid>https://arxiv.org/abs/2507.09409</guid>
<content:encoded><![CDATA[
arXiv:2507.09409v1 Announce Type: new 
Abstract: Social learning is a powerful mechanism through which agents learn about the world from others. However, humans don't always choose to observe others, since social learning can carry time and cognitive resource costs. How do people balance social and non-social learning? In this paper, we propose a rational mentalizing model of the decision to engage in social learning. This model estimates the utility of social learning by reasoning about the other agent's goal and the informativity of their future actions. It then weighs the utility of social learning against the utility of self-exploration (non-social learning). Using a multi-player treasure hunt game, we show that our model can quantitatively capture human trade-offs between social and non-social learning. Furthermore, our results indicate that these two components allow agents to flexibly apply social learning to achieve their goals more efficiently.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Multi-Person Motion Prediction by Lightweight Spatial and Temporal Interactions</title>
<link>https://arxiv.org/abs/2507.09446</link>
<guid>https://arxiv.org/abs/2507.09446</guid>
<content:encoded><![CDATA[
arXiv:2507.09446v1 Announce Type: new 
Abstract: 3D multi-person motion prediction is a highly complex task, primarily due to the dependencies on both individual past movements and the interactions between agents. Moreover, effectively modeling these interactions often incurs substantial computational costs. In this work, we propose a computationally efficient model for multi-person motion prediction by simplifying spatial and temporal interactions. Our approach begins with the design of lightweight dual branches that learn local and global representations for individual and multiple persons separately. Additionally, we introduce a novel cross-level interaction block to integrate the spatial and temporal representations from both branches. To further enhance interaction modeling, we explicitly incorporate the spatial inter-person distance embedding. With above efficient temporal and spatial design, we achieve state-of-the-art performance for multiple metrics on standard datasets of CMU-Mocap, MuPoTS-3D, and 3DPW, while significantly reducing the computational cost. Code is available at https://github.com/Yuanhong-Zheng/EMPMP.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MobiWorld: World Models for Mobile Wireless Network</title>
<link>https://arxiv.org/abs/2507.09462</link>
<guid>https://arxiv.org/abs/2507.09462</guid>
<content:encoded><![CDATA[
arXiv:2507.09462v1 Announce Type: new 
Abstract: Accurate modeling and simulation of mobile networks are essential for enabling intelligent and cost-effective network optimization. In this paper, we propose MobiWorld, a generative world model designed to support high-fidelity and flexible environment simulation for mobile network planning and optimization. Unlike traditional predictive models constrained by limited generalization capabilities, MobiWorld exhibits strong universality by integrating heterogeneous data sources, including sensors, mobile devices, and base stations, as well as multimodal data types such as sequences and images. It is capable of generating both network element-level observations (e.g., traffic load, user distribution) and system-level performance indicators (e.g., throughput, energy consumption) to support a wide range of planning and optimization tasks. Built upon advanced diffusion models, MobiWorld offers powerful controllable generation capabilities by modeling the joint distribution between mobile network data and diverse conditional factors including spatio temporal contexts, user behaviors, and optimization policies. This enables accurate simulation of dynamic network states under varying policy configurations, providing optimization agents with precise environmental feedback and facilitating effective decision-making without relying on costly real-network interactions. We demonstrate the effectiveness of MobiWorld in a collaborative energy-saving scenario, where an agent uses observations and rewards generated by MobiWorld to optimize base station sleep and user offloading policies. Experimental results show that MobiWorld exhibits strong controllable generation performance and outperforms traditional methods in energy optimization.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentive-Aware Dynamic Resource Allocation under Long-Term Cost Constraints</title>
<link>https://arxiv.org/abs/2507.09473</link>
<guid>https://arxiv.org/abs/2507.09473</guid>
<content:encoded><![CDATA[
arXiv:2507.09473v1 Announce Type: new 
Abstract: Motivated by applications such as cloud platforms allocating GPUs to users or governments deploying mobile health units across competing regions, we study the dynamic allocation of a reusable resource to strategic agents with private valuations. Our objective is to simultaneously (i) maximize social welfare, (ii) satisfy multi-dimensional long-term cost constraints, and (iii) incentivize truthful reporting. We begin by numerically evaluating primal-dual methods widely used in constrained online optimization and find them to be highly fragile in strategic settings -- agents can easily manipulate their reports to distort future dual updates for future gain.
  To address this vulnerability, we develop an incentive-aware framework that makes primal-dual methods robust to strategic behavior. Our design combines epoch-based lazy updates -- where dual variables remain fixed within each epoch -- with randomized exploration rounds that extract approximately truthful signals for learning. Leveraging carefully designed online learning subroutines that can be of independent interest for dual updates, our mechanism achieves $\tilde{\mathcal{O}}(\sqrt{T})$ social welfare regret, satisfies all cost constraints, and ensures incentive alignment. This matches the performance of non-strategic allocation approaches while being robust to strategic agents.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Agentic RAG with Deep Reasoning: A Survey of RAG-Reasoning Systems in LLMs</title>
<link>https://arxiv.org/abs/2507.09477</link>
<guid>https://arxiv.org/abs/2507.09477</guid>
<content:encoded><![CDATA[
arXiv:2507.09477v1 Announce Type: new 
Abstract: Retrieval-Augmented Generation (RAG) lifts the factuality of Large Language Models (LLMs) by injecting external knowledge, yet it falls short on problems that demand multi-step inference; conversely, purely reasoning-oriented approaches often hallucinate or mis-ground facts. This survey synthesizes both strands under a unified reasoning-retrieval perspective. We first map how advanced reasoning optimizes each stage of RAG (Reasoning-Enhanced RAG). Then, we show how retrieved knowledge of different type supply missing premises and expand context for complex inference (RAG-Enhanced Reasoning). Finally, we spotlight emerging Synergized RAG-Reasoning frameworks, where (agentic) LLMs iteratively interleave search and reasoning to achieve state-of-the-art performance across knowledge-intensive benchmarks. We categorize methods, datasets, and open challenges, and outline research avenues toward deeper RAG-Reasoning systems that are more effective, multimodally-adaptive, trustworthy, and human-centric. The collection is available at https://github.com/DavidZWZ/Awesome-RAG-Reasoning.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating LLMs on Sequential API Call Through Automated Test Generation</title>
<link>https://arxiv.org/abs/2507.09481</link>
<guid>https://arxiv.org/abs/2507.09481</guid>
<content:encoded><![CDATA[
arXiv:2507.09481v1 Announce Type: new 
Abstract: By integrating tools from external APIs, Large Language Models (LLMs) have expanded their promising capabilities in a diverse spectrum of complex real-world tasks. However, testing, evaluation, and analysis of LLM tool use remain in their early stages. Most existing benchmarks rely on manually collected test cases, many of which cannot be automatically checked for semantic correctness and instead depend on static methods such as string matching. Additionally, these benchmarks often overlook the complex interactions that occur between sequential API calls, which are common in real-world applications. To fill the gap, in this paper, we introduce StateGen, an automated framework designed to generate diverse coding tasks involving sequential API interactions. StateGen combines state-machine-based API constraint solving and validation, energy-based sampling, and control-flow injection to generate executable programs. These programs are then translated into human-like natural language task descriptions through a collaboration of two LLM agents. Utilizing StateGen, we construct StateEval, a benchmark encompassing 120 verified test cases spanning across three representative scenarios: Session Service, Tensor Operation, and ElevenLabs MCP. Experimental results confirm that StateGen can effectively generate challenging and realistic API-oriented tasks, highlighting areas for improvement in current LLMs incorporating APIs.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GenAI-based Multi-Agent Reinforcement Learning towards Distributed Agent Intelligence: A Generative-RL Agent Perspective</title>
<link>https://arxiv.org/abs/2507.09495</link>
<guid>https://arxiv.org/abs/2507.09495</guid>
<content:encoded><![CDATA[
arXiv:2507.09495v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning faces fundamental challenges that conventional approaches have failed to overcome: exponentially growing joint action spaces, non-stationary environments where simultaneous learning creates moving targets, and partial observability that constrains coordination. Current methods remain reactive, employing stimulus-response mechanisms that fail when facing novel scenarios. We argue for a transformative paradigm shift from reactive to proactive multi-agent intelligence through generative AI-based reinforcement learning. This position advocates reconceptualizing agents not as isolated policy optimizers, but as sophisticated generative models capable of synthesizing complex multi-agent dynamics and making anticipatory decisions based on predictive understanding of future interactions. Rather than responding to immediate observations, generative-RL agents can model environment evolution, predict other agents' behaviors, generate coordinated action sequences, and engage in strategic reasoning accounting for long-term dynamics. This approach leverages pattern recognition and generation capabilities of generative AI to enable proactive decision-making, seamless coordination through enhanced communication, and dynamic adaptation to evolving scenarios. We envision this paradigm shift will unlock unprecedented possibilities for distributed intelligence, moving beyond individual optimization toward emergent collective behaviors representing genuine collaborative intelligence. The implications extend across autonomous systems, robotics, and human-AI collaboration, promising solutions to coordination challenges intractable under traditional reactive frameworks.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GoalfyMax: A Protocol-Driven Multi-Agent System for Intelligent Experience Entities</title>
<link>https://arxiv.org/abs/2507.09497</link>
<guid>https://arxiv.org/abs/2507.09497</guid>
<content:encoded><![CDATA[
arXiv:2507.09497v1 Announce Type: new 
Abstract: Modern enterprise environments demand intelligent systems capable of handling complex, dynamic, and multi-faceted tasks with high levels of autonomy and adaptability. However, traditional single-purpose AI systems often lack sufficient coordination, memory reuse, and task decomposition capabilities, limiting their scalability in realistic settings. To address these challenges, we present \textbf{GoalfyMax}, a protocol-driven framework for end-to-end multi-agent collaboration. GoalfyMax introduces a standardized Agent-to-Agent (A2A) communication layer built on the Model Context Protocol (MCP), allowing independent agents to coordinate through asynchronous, protocol-compliant interactions. It incorporates the Experience Pack (XP) architecture, a layered memory system that preserves both task rationales and execution traces, enabling structured knowledge retention and continual learning. Moreover, our system integrates advanced features including multi-turn contextual dialogue, long-short term memory modules, and dynamic safety validation, supporting robust, real-time strategy adaptation. Empirical results on complex task orchestration benchmarks and case study demonstrate that GoalfyMax achieves superior adaptability, coordination, and experience reuse compared to baseline frameworks. These findings highlight its potential as a scalable, future-ready foundation for multi-agent intelligent systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TruckV2X: A Truck-Centered Perception Dataset</title>
<link>https://arxiv.org/abs/2507.09505</link>
<guid>https://arxiv.org/abs/2507.09505</guid>
<content:encoded><![CDATA[
arXiv:2507.09505v1 Announce Type: new 
Abstract: Autonomous trucking offers significant benefits, such as improved safety and reduced costs, but faces unique perception challenges due to trucks' large size and dynamic trailer movements. These challenges include extensive blind spots and occlusions that hinder the truck's perception and the capabilities of other road users. To address these limitations, cooperative perception emerges as a promising solution. However, existing datasets predominantly feature light vehicle interactions or lack multi-agent configurations for heavy-duty vehicle scenarios. To bridge this gap, we introduce TruckV2X, the first large-scale truck-centered cooperative perception dataset featuring multi-modal sensing (LiDAR and cameras) and multi-agent cooperation (tractors, trailers, CAVs, and RSUs). We further investigate how trucks influence collaborative perception needs, establishing performance benchmarks while suggesting research priorities for heavy vehicle perception. The dataset provides a foundation for developing cooperative perception systems with enhanced occlusion handling capabilities, and accelerates the deployment of multi-agent autonomous trucking systems. The TruckV2X dataset is available at https://huggingface.co/datasets/XieTenghu1/TruckV2X.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Self-supervised Pretraining for Integrated Prediction and Planning of Automated Vehicles</title>
<link>https://arxiv.org/abs/2507.09537</link>
<guid>https://arxiv.org/abs/2507.09537</guid>
<content:encoded><![CDATA[
arXiv:2507.09537v1 Announce Type: new 
Abstract: Predicting the future of surrounding agents and accordingly planning a safe, goal-directed trajectory are crucial for automated vehicles. Current methods typically rely on imitation learning to optimize metrics against the ground truth, often overlooking how scene understanding could enable more holistic trajectories. In this paper, we propose Plan-MAE, a unified pretraining framework for prediction and planning that capitalizes on masked autoencoders. Plan-MAE fuses critical contextual understanding via three dedicated tasks: reconstructing masked road networks to learn spatial correlations, agent trajectories to model social interactions, and navigation routes to capture destination intents. To further align vehicle dynamics and safety constraints, we incorporate a local sub-planning task predicting the ego-vehicle's near-term trajectory segment conditioned on earlier segment. This pretrained model is subsequently fine-tuned on downstream tasks to jointly generate the prediction and planning trajectories. Experiments on large-scale datasets demonstrate that Plan-MAE outperforms current methods on the planning metrics by a large margin and can serve as an important pre-training step for learning-based motion planner.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Control Dynamical Agents via Spiking Neural Networks and Metropolis-Hastings Sampling</title>
<link>https://arxiv.org/abs/2507.09540</link>
<guid>https://arxiv.org/abs/2507.09540</guid>
<content:encoded><![CDATA[
arXiv:2507.09540v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) offer biologically inspired, energy-efficient alternatives to traditional Deep Neural Networks (DNNs) for real-time control systems. However, their training presents several challenges, particularly for reinforcement learning (RL) tasks, due to the non-differentiable nature of spike-based communication. In this work, we introduce what is, to our knowledge, the first framework that employs Metropolis-Hastings (MH) sampling, a Bayesian inference technique, to train SNNs for dynamical agent control in RL environments without relying on gradient-based methods. Our approach iteratively proposes and probabilistically accepts network parameter updates based on accumulated reward signals, effectively circumventing the limitations of backpropagation while enabling direct optimization on neuromorphic platforms. We evaluated this framework on two standard control benchmarks: AcroBot and CartPole. The results demonstrate that our MH-based approach outperforms conventional Deep Q-Learning (DQL) baselines and prior SNN-based RL approaches in terms of maximizing the accumulated reward while minimizing network resources and training episodes.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Existence of Fair and Efficient Allocation of Indivisible Chores</title>
<link>https://arxiv.org/abs/2507.09544</link>
<guid>https://arxiv.org/abs/2507.09544</guid>
<content:encoded><![CDATA[
arXiv:2507.09544v1 Announce Type: new 
Abstract: We study the problem of allocating indivisible chores among agents with additive cost functions in a fair and efficient manner. A major open question in this area is whether there always exists an allocation that is envy-free up to one chore (EF1) and Pareto optimal (PO). Our main contribution is to provide a positive answer to this question by proving the existence of such an allocation for indivisible chores under additive cost functions. This is achieved by a novel combination of a fixed point argument and a discrete algorithm, providing a significant methodological advance in this area.
  Our additional key contributions are as follows. We show that there always exists an allocation that is EF1 and fractional Pareto optimal (fPO), where fPO is a stronger efficiency concept than PO. We also show that an EF1 and PO allocation can be computed in polynomial time when the number of agents is constant. Finally, we extend all of these results to the more general setting of weighted EF1 (wEF1), which accounts for the entitlements of agents.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AICrypto: A Comprehensive Benchmark For Evaluating Cryptography Capabilities of Large Language Models</title>
<link>https://arxiv.org/abs/2507.09580</link>
<guid>https://arxiv.org/abs/2507.09580</guid>
<content:encoded><![CDATA[
arXiv:2507.09580v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated remarkable capabilities across a variety of domains. However, their applications in cryptography, which serves as a foundational pillar of cybersecurity, remain largely unexplored. To address this gap, we propose \textbf{AICrypto}, the first comprehensive benchmark designed to evaluate the cryptographic capabilities of LLMs. The benchmark comprises 135 multiple-choice questions, 150 capture-the-flag (CTF) challenges, and 18 proof problems, covering a broad range of skills from factual memorization to vulnerability exploitation and formal reasoning. All tasks are carefully reviewed or constructed by cryptography experts to ensure correctness and rigor. To support automated evaluation of CTF challenges, we design an agent-based framework. To gain deeper insight into the current state of cryptographic proficiency in LLMs, we introduce human expert performance baselines for comparison across all task types. Our evaluation of 17 leading LLMs reveals that state-of-the-art models match or even surpass human experts in memorizing cryptographic concepts, exploiting common vulnerabilities, and routine proofs. However, they still lack a deep understanding of abstract mathematical concepts and struggle with tasks that require multi-step reasoning and dynamic analysis. We hope this work could provide insights for future research on LLMs in cryptographic applications. Our code and dataset are available at https://aicryptobench.github.io.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>humancompatible.interconnect: Testing Properties of Repeated Uses of Interconnections of AI Systems</title>
<link>https://arxiv.org/abs/2507.09626</link>
<guid>https://arxiv.org/abs/2507.09626</guid>
<content:encoded><![CDATA[
arXiv:2507.09626v1 Announce Type: new 
Abstract: Artificial intelligence (AI) systems often interact with multiple agents. The regulation of such AI systems often requires that {\em a priori\/} guarantees of fairness and robustness be satisfied. With stochastic models of agents' responses to the outputs of AI systems, such {\em a priori\/} guarantees require non-trivial reasoning about the corresponding stochastic systems. Here, we present an open-source PyTorch-based toolkit for the use of stochastic control techniques in modelling interconnections of AI systems and properties of their repeated uses. It models robustness and fairness desiderata in a closed-loop fashion, and provides {\em a priori\/} guarantees for these interconnections. The PyTorch-based toolkit removes much of the complexity associated with the provision of fairness guarantees for closed-loop models of multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Negotiating Comfort: Simulating Personality-Driven LLM Agents in Shared Residential Social Networks</title>
<link>https://arxiv.org/abs/2507.09657</link>
<guid>https://arxiv.org/abs/2507.09657</guid>
<content:encoded><![CDATA[
arXiv:2507.09657v1 Announce Type: new 
Abstract: We use generative agents powered by large language models (LLMs) to simulate a social network in a shared residential building, driving the temperature decisions for a central heating system. Agents, divided into Family Members and Representatives, consider personal preferences, personal traits, connections, and weather conditions. Daily simulations involve family-level consensus followed by building-wide decisions among representatives. We tested three personality traits distributions (positive, mixed, and negative) and found that positive traits correlate with higher happiness and stronger friendships. Temperature preferences, assertiveness, and selflessness have a significant impact on happiness and decisions. This work demonstrates how LLM-driven agents can help simulate nuanced human behavior where complex real-life human simulations are difficult to set.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Networked Information Aggregation via Machine Learning</title>
<link>https://arxiv.org/abs/2507.09683</link>
<guid>https://arxiv.org/abs/2507.09683</guid>
<content:encoded><![CDATA[
arXiv:2507.09683v1 Announce Type: new 
Abstract: We study a distributed learning problem in which learning agents are embedded in a directed acyclic graph (DAG). There is a fixed and arbitrary distribution over feature/label pairs, and each agent or vertex in the graph is able to directly observe only a subset of the features -- potentially a different subset for every agent. The agents learn sequentially in some order consistent with a topological sort of the DAG, committing to a model mapping observations to predictions of the real-valued label. Each agent observes the predictions of their parents in the DAG, and trains their model using both the features of the instance that they directly observe, and the predictions of their parents as additional features. We ask when this process is sufficient to achieve \emph{information aggregation}, in the sense that some agent in the DAG is able to learn a model whose error is competitive with the best model that could have been learned (in some hypothesis class) with direct access to \emph{all} features, despite the fact that no single agent in the network has such access. We give upper and lower bounds for this problem for both linear and general hypothesis classes. Our results identify the \emph{depth} of the DAG as the key parameter: information aggregation can occur over sufficiently long paths in the DAG, assuming that all of the relevant features are well represented along the path, and there are distributions over which information aggregation cannot occur even in the linear case, and even in arbitrarily large DAGs that do not have sufficient depth (such as a hub-and-spokes topology in which the spoke vertices collectively see all the features). We complement our theoretical results with a comprehensive set of experiments.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Token Compression Meets Compact Vision Transformers: A Survey and Comparative Evaluation for Edge AI</title>
<link>https://arxiv.org/abs/2507.09702</link>
<guid>https://arxiv.org/abs/2507.09702</guid>
<content:encoded><![CDATA[
arXiv:2507.09702v1 Announce Type: new 
Abstract: Token compression techniques have recently emerged as powerful tools for accelerating Vision Transformer (ViT) inference in computer vision. Due to the quadratic computational complexity with respect to the token sequence length, these methods aim to remove less informative tokens before the attention layers to improve inference throughput. While numerous studies have explored various accuracy-efficiency trade-offs on large-scale ViTs, two critical gaps remain. First, there is a lack of unified survey that systematically categorizes and compares token compression approaches based on their core strategies (e.g., pruning, merging, or hybrid) and deployment settings (e.g., fine-tuning vs. plug-in). Second, most benchmarks are limited to standard ViT models (e.g., ViT-B, ViT-L), leaving open the question of whether such methods remain effective when applied to structurally compressed transformers, which are increasingly deployed on resource-constrained edge devices. To address these gaps, we present the first systematic taxonomy and comparative study of token compression methods, and we evaluate representative techniques on both standard and compact ViT architectures. Our experiments reveal that while token compression methods are effective for general-purpose ViTs, they often underperform when directly applied to compact designs. These findings not only provide practical insights but also pave the way for future research on adapting token optimization techniques to compact transformer-based networks for edge AI and AI agent applications.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IteraOptiRacing: A Unified Planning-Control Framework for Real-time Autonomous Racing for Iterative Optimal Performance</title>
<link>https://arxiv.org/abs/2507.09714</link>
<guid>https://arxiv.org/abs/2507.09714</guid>
<content:encoded><![CDATA[
arXiv:2507.09714v1 Announce Type: new 
Abstract: This paper presents a unified planning-control strategy for competing with other racing cars called IteraOptiRacing in autonomous racing environments. This unified strategy is proposed based on Iterative Linear Quadratic Regulator for Iterative Tasks (i2LQR), which can improve lap time performance in the presence of surrounding racing obstacles. By iteratively using the ego car's historical data, both obstacle avoidance for multiple moving cars and time cost optimization are considered in this unified strategy, resulting in collision-free and time-optimal generated trajectories. The algorithm's constant low computation burden and suitability for parallel computing enable real-time operation in competitive racing scenarios. To validate its performance, simulations in a high-fidelity simulator are conducted with multiple randomly generated dynamic agents on the track. Results show that the proposed strategy outperforms existing methods across all randomly generated autonomous racing scenarios, enabling enhanced maneuvering for the ego racing car.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward accurate RUL and SOH estimation using reinforced graph-based PINNs enhanced with dynamic weights</title>
<link>https://arxiv.org/abs/2507.09766</link>
<guid>https://arxiv.org/abs/2507.09766</guid>
<content:encoded><![CDATA[
arXiv:2507.09766v1 Announce Type: new 
Abstract: Accurate estimation of Remaining Useful Life (RUL) and State of Health (SOH) is essential for Prognostics and Health Management (PHM) across a wide range of industrial applications. We propose a novel framework -- Reinforced Graph-Based Physics-Informed Neural Networks Enhanced with Dynamic Weights (RGPD) -- that combines physics-based supervision with advanced spatio-temporal learning. Graph Convolutional Recurrent Networks (GCRNs) embed graph-convolutional filters within recurrent units to capture how node representations evolve over time. Graph Attention Convolution (GATConv) leverages a self-attention mechanism to compute learnable, edge-wise attention coefficients, dynamically weighting neighbor contributions for adaptive spatial aggregation. A Soft Actor-Critic (SAC) module is positioned between the Temporal Attention Unit (TAU) and GCRN to further improve the spatio-temporal learning. This module improves attention and prediction accuracy by dynamically scaling hidden representations to minimize noise and highlight informative features. To identify the most relevant physical constraints in each area, Q-learning agents dynamically assign weights to physics-informed loss terms, improving generalization across real-time industrial systems and reducing the need for manual tuning. In both RUL and SOH estimation tasks, the proposed method consistently outperforms state-of-the-art models, demonstrating strong robustness and predictive accuracy across varied degradation patterns across three diverse industrial benchmark datasets.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TinyTroupe: An LLM-powered Multiagent Persona Simulation Toolkit</title>
<link>https://arxiv.org/abs/2507.09788</link>
<guid>https://arxiv.org/abs/2507.09788</guid>
<content:encoded><![CDATA[
arXiv:2507.09788v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLM) have led to a new class of autonomous agents, renewing and expanding interest in the area. LLM-powered Multiagent Systems (MAS) have thus emerged, both for assistive and simulation purposes, yet tools for realistic human behavior simulation -- with its distinctive challenges and opportunities -- remain underdeveloped. Existing MAS libraries and tools lack fine-grained persona specifications, population sampling facilities, experimentation support, and integrated validation, among other key capabilities, limiting their utility for behavioral studies, social simulation, and related applications. To address these deficiencies, in this work we introduce TinyTroupe, a simulation toolkit enabling detailed persona definitions (e.g., nationality, age, occupation, personality, beliefs, behaviors) and programmatic control via numerous LLM-driven mechanisms. This allows for the concise formulation of behavioral problems of practical interest, either at the individual or group level, and provides effective means for their solution. TinyTroupe's components are presented using representative working examples, such as brainstorming and market research sessions, thereby simultaneously clarifying their purpose and demonstrating their usefulness. Quantitative and qualitative evaluations of selected aspects are also provided, highlighting possibilities, limitations, and trade-offs. The approach, though realized as a specific Python implementation, is meant as a novel conceptual contribution, which can be partially or fully incorporated in other contexts. The library is available as open source at https://github.com/microsoft/tinytroupe.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Active Probing with Multimodal Predictions for Motion Planning</title>
<link>https://arxiv.org/abs/2507.09822</link>
<guid>https://arxiv.org/abs/2507.09822</guid>
<content:encoded><![CDATA[
arXiv:2507.09822v1 Announce Type: new 
Abstract: Navigation in dynamic environments requires autonomous systems to reason about uncertainties in the behavior of other agents. In this paper, we introduce a unified framework that combines trajectory planning with multimodal predictions and active probing to enhance decision-making under uncertainty. We develop a novel risk metric that seamlessly integrates multimodal prediction uncertainties through mixture models. When these uncertainties follow a Gaussian mixture distribution, we prove that our risk metric admits a closed-form solution, and is always finite, thus ensuring analytical tractability. To reduce prediction ambiguity, we incorporate an active probing mechanism that strategically selects actions to improve its estimates of behavioral parameters of other agents, while simultaneously handling multimodal uncertainties. We extensively evaluate our framework in autonomous navigation scenarios using the MetaDrive simulation environment. Results demonstrate that our active probing approach successfully navigates complex traffic scenarios with uncertain predictions. Additionally, our framework shows robust performance across diverse traffic agent behavior models, indicating its broad applicability to real-world autonomous navigation challenges. Code and videos are available at https://darshangm.github.io/papers/active-probing-multimodal-predictions/.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-residual Mixture of Experts Learning for Cooperative Control in Multi-vehicle Systems</title>
<link>https://arxiv.org/abs/2507.09836</link>
<guid>https://arxiv.org/abs/2507.09836</guid>
<content:encoded><![CDATA[
arXiv:2507.09836v1 Announce Type: new 
Abstract: Autonomous vehicles (AVs) are becoming increasingly popular, with their applications now extending beyond just a mode of transportation to serving as mobile actuators of a traffic flow to control flow dynamics. This contrasts with traditional fixed-location actuators, such as traffic signals, and is referred to as Lagrangian traffic control. However, designing effective Lagrangian traffic control policies for AVs that generalize across traffic scenarios introduces a major challenge. Real-world traffic environments are highly diverse, and developing policies that perform robustly across such diverse traffic scenarios is challenging. It is further compounded by the joint complexity of the multi-agent nature of traffic systems, mixed motives among participants, and conflicting optimization objectives subject to strict physical and external constraints. To address these challenges, we introduce Multi-Residual Mixture of Expert Learning (MRMEL), a novel framework for Lagrangian traffic control that augments a given suboptimal nominal policy with a learned residual while explicitly accounting for the structure of the traffic scenario space. In particular, taking inspiration from residual reinforcement learning, MRMEL augments a suboptimal nominal AV control policy by learning a residual correction, but at the same time dynamically selects the most suitable nominal policy from a pool of nominal policies conditioned on the traffic scenarios and modeled as a mixture of experts. We validate MRMEL using a case study in cooperative eco-driving at signalized intersections in Atlanta, Dallas Fort Worth, and Salt Lake City, with real-world data-driven traffic scenarios. The results show that MRMEL consistently yields superior performance-achieving an additional 4%-9% reduction in aggregate vehicle emissions relative to the strongest baseline in each setting.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Population Models</title>
<link>https://arxiv.org/abs/2507.09901</link>
<guid>https://arxiv.org/abs/2507.09901</guid>
<content:encoded><![CDATA[
arXiv:2507.09901v1 Announce Type: new 
Abstract: Many of society's most pressing challenges, from pandemic response to supply chain disruptions to climate adaptation, emerge from the collective behavior of millions of autonomous agents making decisions over time. Large Population Models (LPMs) offer an approach to understand these complex systems by simulating entire populations with realistic behaviors and interactions at unprecedented scale. LPMs extend traditional modeling approaches through three key innovations: computational methods that efficiently simulate millions of agents simultaneously, mathematical frameworks that learn from diverse real-world data streams, and privacy-preserving communication protocols that bridge virtual and physical environments. This allows researchers to observe how agent behavior aggregates into system-level outcomes and test interventions before real-world implementation. While current AI advances primarily focus on creating "digital humans" with sophisticated individual capabilities, LPMs develop "digital societies" where the richness of interactions reveals emergent phenomena. By bridging individual agent behavior and population-scale dynamics, LPMs offer a complementary path in AI research illuminating collective intelligence and providing testing grounds for policies and social innovations before real-world deployment. We discuss the technical foundations and some open problems here. LPMs are implemented by the AgentTorch framework (github.com/AgentTorch/AgentTorch)
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Energy-Stable Swarm-Based Inertial Algorithms for Optimization</title>
<link>https://arxiv.org/abs/2507.09909</link>
<guid>https://arxiv.org/abs/2507.09909</guid>
<content:encoded><![CDATA[
arXiv:2507.09909v1 Announce Type: new 
Abstract: We formulate the swarming optimization problem as a weakly coupled, dissipative dynamical system governed by a controlled energy dissipation rate and initial velocities that adhere to the nonequilibrium Onsager principle. In this framework, agents' inertia, positions, and masses are dynamically coupled. To numerically solve the system, we develop a class of efficient, energy-stable algorithms that either preserve or enhance energy dissipation at the discrete level. At equilibrium, the system tends to converge toward one of the lowest local minima explored by the agents, thereby improving the likelihood of identifying the global minimum. Numerical experiments confirm the effectiveness of the proposed approach, demonstrating significant advantages over traditional swarm-based gradient descent methods, especially when operating with a limited number of agents.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalized Quantal Response Equilibrium: Existence and Efficient Learning</title>
<link>https://arxiv.org/abs/2507.09928</link>
<guid>https://arxiv.org/abs/2507.09928</guid>
<content:encoded><![CDATA[
arXiv:2507.09928v1 Announce Type: new 
Abstract: We introduce a new solution concept for bounded rational agents in finite normal-form general-sum games called Generalized Quantal Response Equilibrium (GQRE) which generalizes Quantal Response Equilibrium~\citep{mckelvey1995quantal}. In our setup, each player maximizes a smooth, regularized expected utility of the mixed profiles used, reflecting bounded rationality that subsumes stochastic choice. After establishing existence under mild conditions, we present computationally efficient no-regret independent learning via smoothened versions of the Frank-Wolfe algorithm. Our algorithm uses noisy but correlated gradient estimates generated via a simulation oracle that reports on repeated plays of the game. We analyze convergence properties of our algorithm under assumptions that ensure uniqueness of equilibrium, using a class of gap functions that generalize the Nash gap. We end by demonstrating the effectiveness of our method on a set of complex general-sum games such as high-rank two-player games, large action two-player games, and known examples of difficult multi-player games.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Improving monotonic optimization in heterogeneous multi-agent reinforcement learning with optimal marginal deterministic policy gradient</title>
<link>https://arxiv.org/abs/2507.09989</link>
<guid>https://arxiv.org/abs/2507.09989</guid>
<content:encoded><![CDATA[
arXiv:2507.09989v1 Announce Type: new 
Abstract: In heterogeneous multi-agent reinforcement learning (MARL), achieving monotonic improvement plays a pivotal role in enhancing performance. The HAPPO algorithm proposes a feasible solution by introducing a sequential update scheme, which requires independent learning with No Parameter-sharing (NoPS). However, heterogeneous MARL generally requires Partial Parameter-sharing (ParPS) based on agent grouping to achieve high cooperative performance. Our experiments prove that directly combining ParPS with the sequential update scheme leads to the policy updating baseline drift problem, thereby failing to achieve improvement. To solve the conflict between monotonic improvement and ParPS, we propose the Optimal Marginal Deterministic Policy Gradient (OMDPG) algorithm. First, we replace the sequentially computed $Q_{\psi}^s(s,a_{1:i})$ with the Optimal Marginal Q (OMQ) function $\phi_{\psi}^*(s,a_{1:i})$ derived from Q-functions. This maintains MAAD's monotonic improvement while eliminating the conflict through optimal joint action sequences instead of sequential policy ratio calculations. Second, we introduce the Generalized Q Critic (GQC) as the critic function, employing pessimistic uncertainty-constrained loss to optimize different Q-value estimations. This provides the required Q-values for OMQ computation and stable baselines for actor updates. Finally, we implement a Centralized Critic Grouped Actor (CCGA) architecture that simultaneously achieves ParPS in local policy networks and accurate global Q-function computation. Experimental results in SMAC and MAMuJoCo environments demonstrate that OMDPG outperforms various state-of-the-art MARL baselines.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Predictive &amp; Trust-based Multi-Agent Coordination</title>
<link>https://arxiv.org/abs/2507.09997</link>
<guid>https://arxiv.org/abs/2507.09997</guid>
<content:encoded><![CDATA[
arXiv:2507.09997v1 Announce Type: new 
Abstract: This paper presents a trust-based predictive multi-agent consensus protocol that analyses neighbours' anticipation data and makes coordination decisions. Agents in the network share their future predicted data over a finite look-ahead horizon with their neighbours and update their predictions in a rolling-horizon fashion. The prediction data is then used by agents to learn both the trust and the commitment traits exhibited by their neighbours over time. The proposed protocol is named as the Anticipatory Distributed Coordination (ADC) protocol. Lyapunov theory-based agreement convergence between agents is provided, followed by demonstrations using numerical simulations.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On The Role of Intentionality in Knowledge Representation: Analyzing Scene Context for Cognitive Agents with a Tiny Language Model</title>
<link>https://arxiv.org/abs/2507.10000</link>
<guid>https://arxiv.org/abs/2507.10000</guid>
<content:encoded><![CDATA[
arXiv:2507.10000v1 Announce Type: new 
Abstract: Since Searle's work deconstructing intent and intentionality in the realm of philosophy, the practical meaning of intent has received little attention in science and technology. Intentionality and context are both central to the scope of Promise Theory's model of Semantic Spacetime, used as an effective Tiny Language Model. One can identify themes and concepts from a text, on a low level (without knowledge of the specific language) by using process coherence as a guide. Any agent process can assess superficially a degree of latent `intentionality' in data by looking for anomalous multi-scale anomalies and assessing the work done to form them. Scale separation can be used to sort parts into `intended' content and `ambient context', using the spacetime coherence as a measure. This offers an elementary but pragmatic interpretation of latent intentionality for very low computational cost, and without reference to extensive training or reasoning capabilities. The process is well within the reach of basic organisms as it does not require large scale artificial probabilistic batch processing. The level of concept formation depends, however, on the memory capacity of the agent.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Man Behind the Sound: Demystifying Audio Private Attribute Profiling via Multimodal Large Language Model Agents</title>
<link>https://arxiv.org/abs/2507.10016</link>
<guid>https://arxiv.org/abs/2507.10016</guid>
<content:encoded><![CDATA[
arXiv:2507.10016v1 Announce Type: new 
Abstract: Our research uncovers a novel privacy risk associated with multimodal large language models (MLLMs): the ability to infer sensitive personal attributes from audio data -- a technique we term audio private attribute profiling. This capability poses a significant threat, as audio can be covertly captured without direct interaction or visibility. Moreover, compared to images and text, audio carries unique characteristics, such as tone and pitch, which can be exploited for more detailed profiling. However, two key challenges exist in understanding MLLM-employed private attribute profiling from audio: (1) the lack of audio benchmark datasets with sensitive attribute annotations and (2) the limited ability of current MLLMs to infer such attributes directly from audio. To address these challenges, we introduce AP^2, an audio benchmark dataset that consists of two subsets collected and composed from real-world data, and both are annotated with sensitive attribute labels. Additionally, we propose Gifts, a hybrid multi-agent framework that leverages the complementary strengths of audio-language models (ALMs) and large language models (LLMs) to enhance inference capabilities. Gifts employs an LLM to guide the ALM in inferring sensitive attributes, then forensically analyzes and consolidates the ALM's inferences, overcoming severe hallucinations of existing ALMs in generating long-context responses. Our evaluations demonstrate that Gifts significantly outperforms baseline approaches in inferring sensitive attributes. Finally, we investigate model-level and data-level defense strategies to mitigate the risks of audio private attribute profiling. Our work validates the feasibility of audio-based privacy attacks using MLLMs, highlighting the need for robust defenses, and provides a dataset and framework to facilitate future research.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finetuning Deep Reinforcement Learning Policies with Evolutionary Strategies for Control of Underactuated Robots</title>
<link>https://arxiv.org/abs/2507.10030</link>
<guid>https://arxiv.org/abs/2507.10030</guid>
<content:encoded><![CDATA[
arXiv:2507.10030v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (RL) has emerged as a powerful method for addressing complex control problems, particularly those involving underactuated robotic systems. However, in some cases, policies may require refinement to achieve optimal performance and robustness aligned with specific task objectives. In this paper, we propose an approach for fine-tuning Deep RL policies using Evolutionary Strategies (ES) to enhance control performance for underactuated robots. Our method involves initially training an RL agent with Soft-Actor Critic (SAC) using a surrogate reward function designed to approximate complex specific scoring metrics. We subsequently refine this learned policy through a zero-order optimization step employing the Separable Natural Evolution Strategy (SNES), directly targeting the original score. Experimental evaluations conducted in the context of the 2nd AI Olympics with RealAIGym at IROS 2024 demonstrate that our evolutionary fine-tuning significantly improves agent performance while maintaining high robustness. The resulting controllers outperform established baselines, achieving competitive scores for the competition tasks.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptability in Multi-Agent Reinforcement Learning: A Framework and Unified Review</title>
<link>https://arxiv.org/abs/2507.10142</link>
<guid>https://arxiv.org/abs/2507.10142</guid>
<content:encoded><![CDATA[
arXiv:2507.10142v1 Announce Type: new 
Abstract: Multi-Agent Reinforcement Learning (MARL) has shown clear effectiveness in coordinating multiple agents across simulated benchmarks and constrained scenarios. However, its deployment in real-world multi-agent systems (MAS) remains limited, primarily due to the complex and dynamic nature of such environments. These challenges arise from multiple interacting sources of variability, including fluctuating agent populations, evolving task goals, and inconsistent execution conditions. Together, these factors demand that MARL algorithms remain effective under continuously changing system configurations and operational demands. To better capture and assess this capacity for adjustment, we introduce the concept of \textit{adaptability} as a unified and practically grounded lens through which to evaluate the reliability of MARL algorithms under shifting conditions, broadly referring to any changes in the environment dynamics that may occur during learning or execution. Centred on the notion of adaptability, we propose a structured framework comprising three key dimensions: learning adaptability, policy adaptability, and scenario-driven adaptability. By adopting this adaptability perspective, we aim to support more principled assessments of MARL performance beyond narrowly defined benchmarks. Ultimately, this survey contributes to the development of algorithms that are better suited for deployment in dynamic, real-world multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Play Style Identification Using Low-Level Representations of Play Traces in MicroRTS</title>
<link>https://arxiv.org/abs/2507.10172</link>
<guid>https://arxiv.org/abs/2507.10172</guid>
<content:encoded><![CDATA[
arXiv:2507.10172v1 Announce Type: new 
Abstract: Play style identification can provide valuable game design insights and enable adaptive experiences, with the potential to improve game playing agents. Previous work relies on domain knowledge to construct play trace representations using handcrafted features. More recent approaches incorporate the sequential structure of play traces but still require some level of domain abstraction. In this study, we explore the use of unsupervised CNN-LSTM autoencoder models to obtain latent representations directly from low-level play trace data in MicroRTS. We demonstrate that this approach yields a meaningful separation of different game playing agents in the latent space, reducing reliance on domain expertise and its associated biases. This latent space is then used to guide the exploration of diverse play styles within studied AI players.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ToMacVF : Temporal Macro-action Value Factorization for Asynchronous Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.10251</link>
<guid>https://arxiv.org/abs/2507.10251</guid>
<content:encoded><![CDATA[
arXiv:2507.10251v1 Announce Type: new 
Abstract: Existing asynchronous MARL methods based on MacDec-POMDP typically construct training trajectory buffers by simply sampling limited and biased data at the endpoints of macro-actions, and directly apply conventional MARL methods on the buffers. As a result, these methods lead to an incomplete and inaccurate representation of the macro-action execution process, along with unsuitable credit assignments. To solve these problems, the Temporal Macro-action Value Factorization (ToMacVF) is proposed to achieve fine-grained temporal credit assignment for macro-action contributions. A centralized training buffer, called Macro-action Segmented Joint Experience Replay Trajectory (Mac-SJERT), is designed to incorporate with ToMacVF to collect accurate and complete macro-action execution information, supporting a more comprehensive and precise representation of the macro-action process. To ensure principled and fine-grained asynchronous value factorization, the consistency requirement between joint and individual macro-action selection called Temporal Macro-action based IGM (To-Mac-IGM) is formalized, proving that it generalizes the synchronous cases. Based on To-Mac-IGM, a modularized ToMacVF architecture, which satisfies CTDE principle, is designed to conveniently integrate previous value factorization methods. Next, the ToMacVF algorithm is devised as an implementation of the ToMacVF architecture. Experimental results demonstrate that, compared to asynchronous baselines, our ToMacVF algorithm not only achieves optimal performance but also exhibits strong adaptability and robustness across various asynchronous multi-agent experimental scenarios.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompt Informed Reinforcement Learning for Visual Coverage Path Planning</title>
<link>https://arxiv.org/abs/2507.10284</link>
<guid>https://arxiv.org/abs/2507.10284</guid>
<content:encoded><![CDATA[
arXiv:2507.10284v1 Announce Type: new 
Abstract: Visual coverage path planning with unmanned aerial vehicles (UAVs) requires agents to strategically coordinate UAV motion and camera control to maximize coverage, minimize redundancy, and maintain battery efficiency. Traditional reinforcement learning (RL) methods rely on environment-specific reward formulations that lack semantic adaptability. This study proposes Prompt-Informed Reinforcement Learning (PIRL), a novel approach that integrates the zero-shot reasoning ability and in-context learning capability of large language models with curiosity-driven RL. PIRL leverages semantic feedback from an LLM, GPT-3.5, to dynamically shape the reward function of the Proximal Policy Optimization (PPO) RL policy guiding the agent in position and camera adjustments for optimal visual coverage. The PIRL agent is trained using OpenAI Gym and evaluated in various environments. Furthermore, the sim-to-real-like ability and zero-shot generalization of the agent are tested by operating the agent in Webots simulator which introduces realistic physical dynamics. Results show that PIRL outperforms multiple learning-based baselines such as PPO with static rewards, PPO with exploratory weight initialization, imitation learning, and an LLM-only controller. Across different environments, PIRL outperforms the best-performing baseline by achieving up to 14% higher visual coverage in OpenAI Gym and 27% higher in Webots, up to 25% higher battery efficiency, and up to 18\% lower redundancy, depending on the environment. The results highlight the effectiveness of LLM-guided reward shaping in complex spatial exploration tasks and suggest a promising direction for integrating natural language priors into RL for robotics.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toolsuite for Implementing Multiagent Systems Based on Communication Protocols</title>
<link>https://arxiv.org/abs/2507.10324</link>
<guid>https://arxiv.org/abs/2507.10324</guid>
<content:encoded><![CDATA[
arXiv:2507.10324v1 Announce Type: new 
Abstract: Interaction-Oriented Programming (IOP) is an approach to building a multiagent system by modeling the interactions between its roles via a flexible interaction protocol and implementing agents to realize the interactions of the roles they play in the protocol.
  In recent years, we have developed an extensive suite of software that enables multiagent system developers to apply IOP. These include tools for efficiently verifying protocols for properties such as liveness and safety and middleware that simplifies the implementation of agents. This paper presents some of that software suite.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Acquiring and Adapting Priors for Novel Tasks via Neural Meta-Architectures</title>
<link>https://arxiv.org/abs/2507.10446</link>
<guid>https://arxiv.org/abs/2507.10446</guid>
<content:encoded><![CDATA[
arXiv:2507.10446v1 Announce Type: new 
Abstract: The ability to transfer knowledge from prior experiences to novel tasks stands as a pivotal capability of intelligent agents, including both humans and computational models. This principle forms the basis of transfer learning, where large pre-trained neural networks are fine-tuned to adapt to downstream tasks. Transfer learning has demonstrated tremendous success, both in terms of task adaptation speed and performance. However there are several domains where, due to lack of data, training such large pre-trained models or foundational models is not a possibility - computational chemistry, computational immunology, and medical imaging are examples. To address these challenges, our work focuses on designing architectures to enable efficient acquisition of priors when large amounts of data are unavailable. In particular, we demonstrate that we can use neural memory to enable adaptation on non-stationary distributions with only a few samples. Then we demonstrate that our hypernetwork designs (a network that generates another network) can acquire more generalizable priors than standard networks when trained with Model Agnostic Meta-Learning (MAML). Subsequently, we apply hypernetworks to 3D scene generation, demonstrating that they can acquire priors efficiently on just a handful of training scenes, thereby leading to faster text-to-3D generation. We then extend our hypernetwork framework to perform 3D segmentation on novel scenes with limited data by efficiently transferring priors from earlier viewed scenes. Finally, we repurpose an existing molecular generative method as a pre-training framework that facilitates improved molecular property prediction, addressing critical challenges in computational immunology
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FinTeam: A Multi-Agent Collaborative Intelligence System for Comprehensive Financial Scenarios</title>
<link>https://arxiv.org/abs/2507.10448</link>
<guid>https://arxiv.org/abs/2507.10448</guid>
<content:encoded><![CDATA[
arXiv:2507.10448v1 Announce Type: new 
Abstract: Financial report generation tasks range from macro- to micro-economics analysis, also requiring extensive data analysis. Existing LLM models are usually fine-tuned on simple QA tasks and cannot comprehensively analyze real financial scenarios. Given the complexity, financial companies often distribute tasks among departments. Inspired by this, we propose FinTeam, a financial multi-agent collaborative system, with a workflow with four LLM agents: document analyzer, analyst, accountant, and consultant. We train these agents with specific financial expertise using constructed datasets. We evaluate FinTeam on comprehensive financial tasks constructed from real online investment forums, including macroeconomic, industry, and company analysis. The human evaluation shows that by combining agents, the financial reports generate from FinTeam achieved a 62.00% acceptance rate, outperforming baseline models like GPT-4o and Xuanyuan. Additionally, FinTeam's agents demonstrate a 7.43% average improvement on FinCUGE and a 2.06% accuracy boost on FinEval. Project is available at https://github.com/FudanDISC/DISC-FinLLM/.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeepResearch$^{\text{Eco}}$: A Recursive Agentic Workflow for Complex Scientific Question Answering in Ecology</title>
<link>https://arxiv.org/abs/2507.10522</link>
<guid>https://arxiv.org/abs/2507.10522</guid>
<content:encoded><![CDATA[
arXiv:2507.10522v1 Announce Type: new 
Abstract: We introduce DeepResearch$^{\text{Eco}}$, a novel agentic LLM-based system for automated scientific synthesis that supports recursive, depth- and breadth-controlled exploration of original research questions -- enhancing search diversity and nuance in the retrieval of relevant scientific literature. Unlike conventional retrieval-augmented generation pipelines, DeepResearch enables user-controllable synthesis with transparent reasoning and parameter-driven configurability, facilitating high-throughput integration of domain-specific evidence while maintaining analytical rigor. Applied to 49 ecological research questions, DeepResearch achieves up to a 21-fold increase in source integration and a 14.9-fold rise in sources integrated per 1,000 words. High-parameter settings yield expert-level analytical depth and contextual diversity.
  Source code available at: https://github.com/sciknoworg/deep-research.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph World Model</title>
<link>https://arxiv.org/abs/2507.10539</link>
<guid>https://arxiv.org/abs/2507.10539</guid>
<content:encoded><![CDATA[
arXiv:2507.10539v1 Announce Type: new 
Abstract: World models (WMs) demonstrate strong capabilities in prediction, generation, and planning tasks. Existing WMs primarily focus on unstructured data and cannot leverage the ubiquitous structured data, often represented as graphs, in the digital world. While multiple graph foundation models have been proposed, they focus on graph learning tasks and cannot extend to diverse multi-modal data and interdisciplinary tasks. To address these challenges, we propose the Graph World Model (GWM), a world model that supports both unstructured and graph-structured states with multi-modal information and represents diverse tasks as actions. The core of a GWM is a generic message-passing algorithm to aggregate structured information, either over a unified multi-modal token space by converting multi-modal data into text (GWM-T) or a unified multi-modal embedding space by modality-specific encoders (GWM-E). Notably, GWM introduces action nodes to support diverse tasks, where action nodes are linked to other nodes via direct reference or similarity computation. Extensive experiments on six tasks from diverse domains, including multi-modal generation and matching, recommendation, graph prediction, multi-agent, retrieval-augmented generation, and planning and optimization, show that the same GWM outperforms or matches domain-specific baselines' performance, benefits from multi-hop structures, and demonstrates strong zero-shot/few-shot capabilities on unseen new tasks. Our code for GWM is released at https://github.com/ulab-uiuc/GWM.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EmbRACE-3K: Embodied Reasoning and Action in Complex Environments</title>
<link>https://arxiv.org/abs/2507.10548</link>
<guid>https://arxiv.org/abs/2507.10548</guid>
<content:encoded><![CDATA[
arXiv:2507.10548v1 Announce Type: new 
Abstract: Recent advanced vision-language models(VLMs) have demonstrated strong performance on passive, offline image and video understanding tasks. However, their effectiveness in embodied settings, which require online interaction and active scene understanding remains limited. In such scenarios, an agent perceives the environment from a first-person perspective, with each action dynamically shaping subsequent observations. Even state-of-the-art models such as GPT-4o, Claude 3.5 Sonnet, and Gemini 2.5 Pro struggle in open-environment interactions, exhibiting clear limitations in spatial reasoning and long-horizon planning. To address this gap, we introduce EmRACE-3K, a dataset of over 3,000 language-guided tasks situated in diverse, photorealistic environments constructed using Unreal Engine and the UnrealCV-Zoo framework. The tasks encompass a wide range of embodied challenges, including navigation, object manipulation, and multi-stage goal execution. Each task unfolds as a multi-step trajectory, pairing first-person visual observations with high-level instructions, grounded actions, and natural language rationales that express the agent's intent at every step. Using EmRACE-3K, we establish a benchmark to evaluate the embodied reasoning capabilities of VLMs across three key dimensions: Exploration, Dynamic Spatial-Semantic Reasoning, and Multi-stage Goal Execution. In zero-shot settings, all models achieve success rates below 20%, underscoring the challenge posed by our benchmark and the current limitations of VLMs in interactive environments. To demonstrate the utility of EmRACE-3K, we further fine-tune Qwen2.5-VL-7B using supervised learning followed by reinforcement learning. This approach yields substantial improvements across all three challenge categories, highlighting the dataset's effectiveness in enabling the development of embodied reasoning capabilities.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging Literature and the Universe Via A Multi-Agent Large Language Model System</title>
<link>https://arxiv.org/abs/2507.08958</link>
<guid>https://arxiv.org/abs/2507.08958</guid>
<content:encoded><![CDATA[
arXiv:2507.08958v1 Announce Type: cross 
Abstract: As cosmological simulations and their associated software become increasingly complex, physicists face the challenge of searching through vast amounts of literature and user manuals to extract simulation parameters from dense academic papers, each using different models and formats. Translating these parameters into executable scripts remains a time-consuming and error-prone process. To improve efficiency in physics research and accelerate the cosmological simulation process, we introduce SimAgents, a multi-agent system designed to automate both parameter configuration from the literature and preliminary analysis for cosmology research. SimAgents is powered by specialized LLM agents capable of physics reasoning, simulation software validation, and tool execution. These agents collaborate through structured communication, ensuring that extracted parameters are physically meaningful, internally consistent, and software-compliant. We also construct a cosmological parameter extraction evaluation dataset by collecting over 40 simulations in published papers from Arxiv and leading journals that cover diverse simulation types. Experiments on the dataset demonstrate a strong performance of SimAgents, highlighting its effectiveness and potential to accelerate scientific research for physicists. Our demonstration video is available at: https://youtu.be/w1zLpm_CaWA. The complete system and dataset are publicly available at https://github.com/xwzhang98/SimAgents.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolution of Fear and Social Rewards in Prey-Predator Relationship</title>
<link>https://arxiv.org/abs/2507.09992</link>
<guid>https://arxiv.org/abs/2507.09992</guid>
<content:encoded><![CDATA[
arXiv:2507.09992v1 Announce Type: cross 
Abstract: Fear is a critical brain function for detecting danger and learning to avoid specific stimuli that can lead to danger. While fear is believed to have evolved under pressure from predators, experimentally reproducing the evolution is challenging. To investigate the relationship between environmental conditions, the evolution of fear, and the evolution of other rewards, such as food reward and social reward, we developed a distributed evolutionary simulation. In our simulation, prey and predator agents co-evolve their innate reward functions, including a possibly fear-like term for observing predators, and learn behaviors via reinforcement learning. Surprisingly, our simulation revealed that social reward for observing the same species is more important for prey to survive, and fear-like negative reward for observing predators evolves only after acquiring social reward. We also found that the predator with increased hunting ability (larger mouth) amplified fear emergence, but also that fear evolution is more stable with non-evolving predators that are bad at chasing prey. Additionally, unlike for predators, we found that positive rewards evolve in opposition to fear for stationary threats, as areas with abundant leftover food develop around them. These findings suggest that fear and social reward have had a complex interplay with each other through evolution, along with the nature of predators and threats.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A PBN-RL-XAI Framework for Discovering a "Hit-and-Run'' Therapeutic Strategy in Melanoma</title>
<link>https://arxiv.org/abs/2507.10136</link>
<guid>https://arxiv.org/abs/2507.10136</guid>
<content:encoded><![CDATA[
arXiv:2507.10136v1 Announce Type: cross 
Abstract: Innate resistance to anti-PD-1 immunotherapy remains a major clinical challenge in metastatic melanoma, with the underlying molecular networks being poorly understood. To address this, we constructed a dynamic Probabilistic Boolean Network model using transcriptomic data from patient tumor biopsies to elucidate the regulatory logic governing therapy response. We then employed a reinforcement learning agent to systematically discover optimal, multi-step therapeutic interventions and used explainable artificial intelligence to mechanistically interpret the agent's control policy. The analysis revealed that a precisely timed, 4-step temporary inhibition of the lysyl oxidase like 2 protein (LOXL2) was the most effective strategy. Our explainable analysis showed that this ``hit-and-run" intervention is sufficient to erase the molecular signature driving resistance, allowing the network to self-correct without requiring sustained intervention. This study presents a novel, time-dependent therapeutic hypothesis for overcoming immunotherapy resistance and provides a powerful computational framework for identifying non-obvious intervention protocols in complex biological systems.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulating Biases for Interpretable Fairness in Offline and Online Classifiers</title>
<link>https://arxiv.org/abs/2507.10154</link>
<guid>https://arxiv.org/abs/2507.10154</guid>
<content:encoded><![CDATA[
arXiv:2507.10154v1 Announce Type: cross 
Abstract: Predictive models often reinforce biases which were originally embedded in their training data, through skewed decisions. In such cases, mitigation methods are critical to ensure that, regardless of the prevailing disparities, model outcomes are adjusted to be fair. To assess this, datasets could be systematically generated with specific biases, to train machine learning classifiers. Then, predictive outcomes could aid in the understanding of this bias embedding process. Hence, an agent-based model (ABM), depicting a loan application process that represents various systemic biases across two demographic groups, was developed to produce synthetic datasets. Then, by applying classifiers trained on them to predict loan outcomes, we can assess how biased data leads to unfairness. This highlights a main contribution of this work: a framework for synthetic dataset generation with controllable bias injection. We also contribute with a novel explainability technique, which shows how mitigations affect the way classifiers leverage data features, via second-order Shapley values. In experiments, both offline and online learning approaches are employed. Mitigations are applied at different stages of the modelling pipeline, such as during pre-processing and in-processing.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaboration Promotes Group Resilience in Multi-Agent AI</title>
<link>https://arxiv.org/abs/2111.06614</link>
<guid>https://arxiv.org/abs/2111.06614</guid>
<content:encoded><![CDATA[
arXiv:2111.06614v3 Announce Type: replace 
Abstract: To effectively operate in various dynamic scenarios, RL agents must be resilient to unexpected changes in their environment. Previous work on this form of resilience has focused on single-agent settings. In this work, we introduce and formalize a multi-agent variant of resilience, which we term group resilience. We further hypothesize that collaboration with other agents is key to achieving group resilience; collaborating agents adapt better to environmental perturbations in multi-agent reinforcement learning (MARL) settings. We test our hypothesis empirically by evaluating different collaboration protocols and examining their effect on group resilience. Our experiments show that all the examined collaborative approaches achieve higher group resilience than their non-collaborative counterparts.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Player Zero-Sum Markov Games with Networked Separable Interactions</title>
<link>https://arxiv.org/abs/2307.09470</link>
<guid>https://arxiv.org/abs/2307.09470</guid>
<content:encoded><![CDATA[
arXiv:2307.09470v3 Announce Type: replace 
Abstract: We study a new class of Markov games, \emph(multi-player) zero-sum Markov Games} with \emph{Networked separable interactions} (zero-sum NMGs), to model the local interaction structure in non-cooperative multi-agent sequential decision-making. We define a zero-sum NMG as a model where {the payoffs of the auxiliary games associated with each state are zero-sum and} have some separable (i.e., polymatrix) structure across the neighbors over some interaction network. We first identify the necessary and sufficient conditions under which an MG can be presented as a zero-sum NMG, and show that the set of Markov coarse correlated equilibrium (CCE) collapses to the set of Markov Nash equilibrium (NE) in these games, in that the product of per-state marginalization of the former for all players yields the latter. Furthermore, we show that finding approximate Markov \emph{stationary} CCE in infinite-horizon discounted zero-sum NMGs is \texttt{PPAD}-hard, unless the underlying network has a ``star topology''. Then, we propose fictitious-play-type dynamics, the classical learning dynamics in normal-form games, for zero-sum NMGs, and establish convergence guarantees to Markov stationary NE under a star-shaped network structure. Finally, in light of the hardness result, we focus on computing a Markov \emph{non-stationary} NE and provide finite-iteration guarantees for a series of value-iteration-based algorithms. We also provide numerical experiments to corroborate our theoretical results.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Review of Reward Functions for Reinforcement Learning in the context of Autonomous Driving</title>
<link>https://arxiv.org/abs/2405.01440</link>
<guid>https://arxiv.org/abs/2405.01440</guid>
<content:encoded><![CDATA[
arXiv:2405.01440v2 Announce Type: replace 
Abstract: Reinforcement learning has emerged as an important approach for autonomous driving. A reward function is used in reinforcement learning to establish the learned skill objectives and guide the agent toward the optimal policy. Since autonomous driving is a complex domain with partly conflicting objectives with varying degrees of priority, developing a suitable reward function represents a fundamental challenge. This paper aims to highlight the gap in such function design by assessing different proposed formulations in the literature and dividing individual objectives into Safety, Comfort, Progress, and Traffic Rules compliance categories. Additionally, the limitations of the reviewed reward functions are discussed, such as objectives aggregation and indifference to driving context. Furthermore, the reward categories are frequently inadequately formulated and lack standardization. This paper concludes by proposing future research that potentially addresses the observed shortcomings in rewards, including a reward validation framework and structured rewards that are context-aware and able to resolve conflicts.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Equilibria in multiagent online problems with predictions</title>
<link>https://arxiv.org/abs/2405.11873</link>
<guid>https://arxiv.org/abs/2405.11873</guid>
<content:encoded><![CDATA[
arXiv:2405.11873v3 Announce Type: replace 
Abstract: We study the power of (competitive) algorithms with predictions in a multiagent setting. To this goal, we introduce a multiagent version of the ski-rental problem. In this problem agents can collaborate by pooling resources to get a group license for some asset. If the license price is not met then agents have to rent the asset individually for the day at a unit price. Otherwise the license becomes available forever to everyone at no extra cost.
  We investigate the effect of using predictors for self and others' behavior in such a setting, as well as the new equilibria formed in this way.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LSTP-Nav: Lightweight Spatiotemporal Policy for Map-free Multi-agent Navigation with LiDAR</title>
<link>https://arxiv.org/abs/2408.16370</link>
<guid>https://arxiv.org/abs/2408.16370</guid>
<content:encoded><![CDATA[
arXiv:2408.16370v4 Announce Type: replace 
Abstract: Safe and efficient multi-agent navigation in dynamic environments remains inherently challenging, particularly when real-time decision-making is required on resource-constrained platforms. Ensuring collision-free trajectories while adapting to uncertainties without relying on pre-built maps further complicates real-world deployment. To address these challenges, we propose LSTP-Nav, a lightweight end-to-end policy for multi-agent navigation that enables map-free collision avoidance in complex environments by directly mapping raw LiDAR point clouds to motion commands. At the core of this framework lies LSTP-Net, an efficient network that processes raw LiDAR data using a GRU architecture, enhanced with attention mechanisms to dynamically focus on critical environmental features while minimizing computational overhead. Additionally, a novel HS reward optimizes collision avoidance by incorporating angular velocity, prioritizing obstacles along the predicted heading, and enhancing training stability. To narrow the sim-to-real gap, we develop PhysReplay-Simlab, a physics-realistic multi-agent simulator, employs localized replay to mine near-failure experiences. Relying solely on LiDA, LSTP-Nav achieves efficient zero-shot sim-to-real transfer on a CPU-only robotic platform, enabling robust navigation in dynamic environments while maintaining computation frequencies above 40 Hz. Extensive experiments demonstrate that LSTP-Nav outperforms baselines with a 9.58\% higher success rate and a 12.30\% lower collision rate, underscoring its practicality and robustness for real-world applications.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Differentially Private Gradient-Tracking-Based Distributed Stochastic Optimization over Directed Graphs</title>
<link>https://arxiv.org/abs/2501.06793</link>
<guid>https://arxiv.org/abs/2501.06793</guid>
<content:encoded><![CDATA[
arXiv:2501.06793v2 Announce Type: replace 
Abstract: This paper proposes a differentially private gradient-tracking-based distributed stochastic optimization algorithm over directed graphs. In particular, privacy noises are incorporated into each agent's state and tracking variable to mitigate information leakage, after which the perturbed states and tracking variables are transmitted to neighbors. We design two novel schemes for the step-sizes and the sampling number within the algorithm. The sampling parameter-controlled subsampling method employed by both schemes enhances the differential privacy level, and ensures a finite cumulative privacy budget even over infinite iterations. The algorithm achieves both almost sure and mean square convergence for nonconvex objectives. Furthermore, when nonconvex objectives satisfy the Polyak-Lojasiewicz condition, Scheme (S1) achieves a polynomial mean square convergence rate, and Scheme (S2) achieves an exponential mean square convergence rate. The trade-off between privacy and convergence is presented. The effectiveness of the algorithm and its superior performance compared to existing works are illustrated through numerical examples of distributed training on the benchmark datasets "MNIST" and "CIFAR-10".
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ACEBench: Who Wins the Match Point in Tool Usage?</title>
<link>https://arxiv.org/abs/2501.12851</link>
<guid>https://arxiv.org/abs/2501.12851</guid>
<content:encoded><![CDATA[
arXiv:2501.12851v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic scenarios; "Special" evaluates tool usage in situations with ambiguous or incomplete instructions; "Agent" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.18439</link>
<guid>https://arxiv.org/abs/2502.18439</guid>
<content:encoded><![CDATA[
arXiv:2502.18439v2 Announce Type: replace 
Abstract: Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents</title>
<link>https://arxiv.org/abs/2502.18805</link>
<guid>https://arxiv.org/abs/2502.18805</guid>
<content:encoded><![CDATA[
arXiv:2502.18805v2 Announce Type: replace 
Abstract: The classic notion of \emph{truthfulness} requires that no agent has a profitable manipulation -- an untruthful report that, for \emph{some} combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.
  Without knowledge of the others' reports, most manipulations are \emph{risky} -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as \emph{risk-avoiding truthfulness (RAT)}, which requires only that no agent can gain from a \emph{safe} manipulation -- one that is sometimes beneficial and never harmful.
  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the \emph{RAT-degree} of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.
  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and two-sided matching.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cryptis: Cryptographic Reasoning in Separation Logic</title>
<link>https://arxiv.org/abs/2502.21156</link>
<guid>https://arxiv.org/abs/2502.21156</guid>
<content:encoded><![CDATA[
arXiv:2502.21156v2 Announce Type: replace 
Abstract: We introduce Cryptis, an extension of the Iris separation logic that can be used to verify cryptographic components using the symbolic model of cryptography. The combination of separation logic and cryptographic reasoning allows us to prove the correctness of a protocol and later reuse this result to verify larger systems that rely on the protocol. To make this integration possible, we propose novel specifications for authentication protocols that allow agents in a network to agree on the use of system resources. We evaluate our approach by verifying various authentication protocols and a key-value store server that uses these authentication protocols to connect to clients. Our results are formalized in Coq.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can A Society of Generative Agents Simulate Human Behavior and Inform Public Health Policy? A Case Study on Vaccine Hesitancy</title>
<link>https://arxiv.org/abs/2503.09639</link>
<guid>https://arxiv.org/abs/2503.09639</guid>
<content:encoded><![CDATA[
arXiv:2503.09639v4 Announce Type: replace 
Abstract: Can we simulate a sandbox society with generative agents to model human behavior, thereby reducing the over-reliance on real human trials for assessing public policies? In this work, we investigate the feasibility of simulating health-related decision-making, using vaccine hesitancy, defined as the delay in acceptance or refusal of vaccines despite the availability of vaccination services (MacDonald, 2015), as a case study. To this end, we introduce the VacSim framework with 100 generative agents powered by Large Language Models (LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1) instantiate a population of agents with demographics based on census data; 2) connect the agents via a social network and model vaccine attitudes as a function of social dynamics and disease-related information; 3) design and evaluate various public health interventions aimed at mitigating vaccine hesitancy. To align with real-world results, we also introduce simulation warmup and attitude modulation to adjust agents' attitudes. We propose a series of evaluations to assess the reliability of various LLM simulations. Experiments indicate that models like Llama and Qwen can simulate aspects of human behavior but also highlight real-world alignment challenges, such as inconsistent responses with demographic profiles. This early exploration of LLM-driven simulations is not meant to serve as definitive policy guidance; instead, it serves as a call for action to examine social simulation for policy development.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents</title>
<link>https://arxiv.org/abs/2503.10200</link>
<guid>https://arxiv.org/abs/2503.10200</guid>
<content:encoded><![CDATA[
arXiv:2503.10200v3 Announce Type: replace 
Abstract: Existing MLLMs encounter significant challenges in modeling the temporal context within long videos. Currently, mainstream Agent-based methods use external tools to assist a single MLLM in answering long video questions. Despite such tool-based support, a solitary MLLM still offers only a partial understanding of long videos, resulting in limited performance. In order to better address long video tasks, we introduce LVAgent, the first framework enabling multi-round dynamic collaboration of MLLM agents in long video understanding. Our method consists of four key steps: 1) Selection: We pre-select appropriate agents from the model library to form optimal agent teams based on different tasks. 2) Perception: We design an effective retrieval scheme for long videos to improve the coverage of critical temporal segments while maintaining computational efficiency. 3) Action: Agents answer long video questions and exchange reasons. 4) Reflection: We evaluate each agent's performance in each round of discussion and optimize the agent team for dynamic collaboration. The agents iteratively refine their answers by multi-round dynamical collaboration of MLLM agents. LVAgent is the first agent system method that outperforms all closed-source models (like GPT-4o) and open-source models (like InternVL-2.5 and Qwen2-VL) in the long video understanding tasks. Our LVAgent achieves an accuracy of 80\% on four mainstream long video understanding tasks. Notably, LVAgent improves accuracy by 13.3\% on LongVideoBench. Code is available at https://github.com/64327069/LVAgent.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OS-Kairos: Adaptive Interaction for MLLM-Powered GUI Agents</title>
<link>https://arxiv.org/abs/2503.16465</link>
<guid>https://arxiv.org/abs/2503.16465</guid>
<content:encoded><![CDATA[
arXiv:2503.16465v3 Announce Type: replace 
Abstract: Autonomous graphical user interface (GUI) agents powered by multimodal large language models have shown great promise. However, a critical yet underexplored issue persists: over-execution, where the agent executes tasks in a fully autonomous way, without adequate assessment of its action confidence to compromise an adaptive human-agent collaboration. This poses substantial risks in complex scenarios, such as those involving ambiguous user instructions, unexpected interruptions, and environmental hijacks. To address the issue, we introduce OS-Kairos, an adaptive GUI agent capable of predicting confidence levels at each interaction step and efficiently deciding whether to act autonomously or seek human intervention. OS-Kairos is developed through two key mechanisms: (i) collaborative probing that annotates confidence scores at each interaction step; (ii) confidence-driven interaction that leverages these confidence scores to elicit the ability of adaptive interaction. Experimental results show that OS-Kairos substantially outperforms existing models on our curated dataset featuring complex scenarios, as well as on established benchmarks such as AITZ and Meta-GUI, with 24.59\%$\sim$87.29\% improvements in task success rate. OS-Kairos facilitates an adaptive human-agent collaboration, prioritizing effectiveness, generality, scalability, and efficiency for real-world GUI interaction. The dataset and codes are available at https://github.com/Wuzheng02/OS-Kairos.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Synthesizing world models for bilevel planning</title>
<link>https://arxiv.org/abs/2503.20124</link>
<guid>https://arxiv.org/abs/2503.20124</guid>
<content:encoded><![CDATA[
arXiv:2503.20124v2 Announce Type: replace 
Abstract: Modern reinforcement learning (RL) systems have demonstrated remarkable capabilities in complex environments, such as video games. However, they still fall short of achieving human-like sample efficiency and adaptability when learning new domains. Theory-based reinforcement learning (TBRL) is an algorithmic framework specifically designed to address this gap. Modeled on cognitive theories, TBRL leverages structured, causal world models - "theories" - as forward simulators for use in planning, generalization and exploration. Although current TBRL systems provide compelling explanations of how humans learn to play video games, they face several technical limitations: their theory languages are restrictive, and their planning algorithms are not scalable. To address these challenges, we introduce TheoryCoder, an instantiation of TBRL that exploits hierarchical representations of theories and efficient program synthesis methods for more powerful learning and planning. TheoryCoder equips agents with general-purpose abstractions (e.g., "move to"), which are then grounded in a particular environment by learning a low-level transition model (a Python program synthesized from observations by a large language model). A bilevel planning algorithm can exploit this hierarchical structure to solve large domains. We demonstrate that this approach can be successfully applied to diverse and challenging grid-world games, where approaches based on directly synthesizing a policy perform poorly. Ablation studies demonstrate the benefits of using hierarchical abstractions.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VFlow: Discovering Optimal Agentic Workflows for Verilog Generation</title>
<link>https://arxiv.org/abs/2504.03723</link>
<guid>https://arxiv.org/abs/2504.03723</guid>
<content:encoded><![CDATA[
arXiv:2504.03723v2 Announce Type: replace 
Abstract: Hardware design automation faces challenges in generating high-quality Verilog code efficiently. This paper introduces VFlow, an automated framework that optimizes agentic workflows for Verilog code generation. Unlike traditional approaches relying on fixed prompts or manually designed flows, VFlow treats workflow discovery as a search over graph-structured LLM invocation sequences. It introduces a multi-population cooperative evolution (CEPE-MCTS) algorithm that balances multiple hardware objectives -- functional correctness, area, power, timing and token cost -- while sharing successful patterns and avoiding repeated failures. Integrated multi-level verification ensures syntactic correctness, functional behavior, and synthesizability. Experiments on VerilogEval and RTLLM2.0 show VFlow improves pass@1 by 20--30\% over prompting baselines and closely matches designer-level area/power. Remarkably, VFlow enables small LLMs to outperform larger models with up to 10.9$\times$ ROI, offering a cost-effective solution for RTL design. This work paves the way for intelligent, automated hardware development, advancing LLM applications in EDA.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rethinking the Foundations for Continual Reinforcement Learning</title>
<link>https://arxiv.org/abs/2504.08161</link>
<guid>https://arxiv.org/abs/2504.08161</guid>
<content:encoded><![CDATA[
arXiv:2504.08161v2 Announce Type: replace 
Abstract: In the traditional view of reinforcement learning, the agent's goal is to find an optimal policy that maximizes its expected sum of rewards. Once the agent finds this policy, the learning ends. This view contrasts with \emph{continual reinforcement learning}, where learning does not end, and agents are expected to continually learn and adapt indefinitely. Despite the clear distinction between these two paradigms of learning, much of the progress in continual reinforcement learning has been shaped by foundations rooted in the traditional view of reinforcement learning. In this paper, we first examine whether the foundations of traditional reinforcement learning are suitable for the continual reinforcement learning paradigm. We identify four key pillars of the traditional reinforcement learning foundations that are antithetical to the goals of continual learning: the Markov decision process formalism, the focus on atemporal artifacts, the expected sum of rewards as an evaluation metric, and episodic benchmark environments that embrace the other three foundations. We then propose a new formalism that sheds the first and the third foundations and replaces them with the history process as a mathematical formalism and a new definition of deviation regret, adapted for continual learning, as an evaluation metric. Finally, we discuss possible approaches to shed the other two foundations.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Is Intermediate Fusion All You Need for UAV-based Collaborative Perception?</title>
<link>https://arxiv.org/abs/2504.21774</link>
<guid>https://arxiv.org/abs/2504.21774</guid>
<content:encoded><![CDATA[
arXiv:2504.21774v2 Announce Type: replace 
Abstract: Collaborative perception enhances environmental awareness through inter-agent communication and is regarded as a promising solution to intelligent transportation systems. However, existing collaborative methods for Unmanned Aerial Vehicles (UAVs) overlook the unique characteristics of the UAV perspective, resulting in substantial communication overhead. To address this issue, we propose a novel communication-efficient collaborative perception framework based on late-intermediate fusion, dubbed LIF. The core concept is to exchange informative and compact detection results and shift the fusion stage to the feature representation level. In particular, we leverage vision-guided positional embedding (VPE) and box-based virtual augmented feature (BoBEV) to effectively integrate complementary information from various agents. Additionally, we innovatively introduce an uncertainty-driven communication mechanism that uses uncertainty evaluation to select high-quality and reliable shared areas. Experimental results demonstrate that our LIF achieves superior performance with minimal communication bandwidth, proving its effectiveness and practicality. Code and models are available at https://github.com/uestchjw/LIF.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Visual Test-time Scaling for GUI Agent Grounding</title>
<link>https://arxiv.org/abs/2505.00684</link>
<guid>https://arxiv.org/abs/2505.00684</guid>
<content:encoded><![CDATA[
arXiv:2505.00684v2 Announce Type: replace 
Abstract: We introduce RegionFocus, a visual test-time scaling approach for Vision Language Model Agents. Understanding webpages is challenging due to the visual complexity of GUI images and the large number of interface elements, making accurate action selection difficult. Our approach dynamically zooms in on relevant regions, reducing background clutter and improving grounding accuracy. To support this process, we propose an image-as-map mechanism that visualizes key landmarks at each step, providing a transparent action record and enables the agent to effectively choose among action candidates. Even with a simple region selection strategy, we observe significant performance gains of 28+\% on Screenspot-pro and 24+\% on WebVoyager benchmarks on top of two state-of-the-art open vision language model agents, UI-TARS and Qwen2.5-VL, highlighting the effectiveness of visual test-time scaling in interactive settings. We achieve a new state-of-the-art grounding performance of 61.6\% on the ScreenSpot-Pro benchmark by applying RegionFocus to a Qwen2.5-VL-72B model. Our code will be released publicly at https://github.com/tiangeluo/RegionFocus.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A modular framework for automated evaluation of procedural content generation in serious games with deep reinforcement learning agents</title>
<link>https://arxiv.org/abs/2505.16801</link>
<guid>https://arxiv.org/abs/2505.16801</guid>
<content:encoded><![CDATA[
arXiv:2505.16801v2 Announce Type: replace 
Abstract: Serious Games (SGs) are nowadays shifting focus to include procedural content generation (PCG) in the development process as a means of offering personalized and enhanced player experience. However, the development of a framework to assess the impact of PCG techniques when integrated into SGs remains particularly challenging. This study proposes a methodology for automated evaluation of PCG integration in SGs, incorporating deep reinforcement learning (DRL) game testing agents. To validate the proposed framework, a previously introduced SG featuring card game mechanics and incorporating three different versions of PCG for nonplayer character (NPC) creation has been deployed. Version 1 features random NPC creation, while versions 2 and 3 utilize a genetic algorithm approach. These versions are used to test the impact of different dynamic SG environments on the proposed framework's agents. The obtained results highlight the superiority of the DRL game testing agents trained on Versions 2 and 3 over those trained on Version 1 in terms of win rate (i.e. number of wins per played games) and training time. More specifically, within the execution of a test emulating regular gameplay, both Versions 2 and 3 peaked at a 97% win rate and achieved statistically significant higher (p=0009) win rates compared to those achieved in Version 1 that peaked at 94%. Overall, results advocate towards the proposed framework's capability to produce meaningful data for the evaluation of procedurally generated content in SGs.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trinity-RFT: A General-Purpose and Unified Framework for Reinforcement Fine-Tuning of Large Language Models</title>
<link>https://arxiv.org/abs/2505.17826</link>
<guid>https://arxiv.org/abs/2505.17826</guid>
<content:encoded><![CDATA[
arXiv:2505.17826v2 Announce Type: replace 
Abstract: Trinity-RFT is a general-purpose, unified and easy-to-use framework designed for reinforcement fine-tuning (RFT) of large language models. It is built with a modular and decoupled design, consisting of (1) an RFT-core that unifies and generalizes synchronous/asynchronous, on-policy/off-policy, and online/offline modes of RFT; (2) seamless integration for agent-environment interaction with high efficiency and robustness; and (3) systematic data pipelines optimized for RFT. Trinity-RFT can be easily adapted for diverse application scenarios, and serves as a unified platform for development and research of advanced reinforcement learning paradigms at both macroscopic and microscopic levels. This technical report outlines the vision, features, design and implementations of Trinity-RFT, accompanied by extensive examples, applications and experiments that demonstrate its functionalities and user-friendliness.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforced Reasoning for Embodied Planning</title>
<link>https://arxiv.org/abs/2505.22050</link>
<guid>https://arxiv.org/abs/2505.22050</guid>
<content:encoded><![CDATA[
arXiv:2505.22050v2 Announce Type: replace 
Abstract: Embodied planning requires agents to make coherent multi-step decisions based on dynamic visual observations and natural language goals. While recent vision-language models (VLMs) excel at static perception tasks, they struggle with the temporal reasoning, spatial understanding, and commonsense grounding needed for planning in interactive environments. In this work, we introduce a reinforcement fine-tuning framework that brings R1-style reasoning enhancement into embodied planning. We first distill a high-quality dataset from a powerful closed-source model and perform supervised fine-tuning (SFT) to equip the model with structured decision-making priors. We then design a rule-based reward function tailored to multi-step action quality and optimize the policy via Generalized Reinforced Preference Optimization (GRPO). Our approach is evaluated on Embench, a recent benchmark for interactive embodied tasks, covering both in-domain and out-of-domain scenarios. Experimental results show that our method significantly outperforms models of similar or larger scale, including GPT-4o-mini and 70B+ open-source baselines, and exhibits strong generalization to unseen environments. This work highlights the potential of reinforcement-driven reasoning to advance long-horizon planning in embodied AI.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COVID-19 Pneumonia Diagnosis Using Medical Images: Deep Learning-Based Transfer Learning Approach</title>
<link>https://arxiv.org/abs/2503.12642</link>
<guid>https://arxiv.org/abs/2503.12642</guid>
<content:encoded><![CDATA[
arXiv:2503.12642v3 Announce Type: replace-cross 
Abstract: SARS-CoV-2, the causative agent of COVID-19, remains a global health concern due to its high transmissibility and evolving variants. Although vaccination efforts and therapeutic advancements have mitigated disease severity, emerging mutations continue to challenge diagnostics and containment strategies. As of mid-February 2025, global test positivity has risen to 11%, marking the highest level in over six months despite widespread immunization efforts. Newer variants demonstrate enhanced host cell binding, increasing both infectivity and diagnostic complexity. This study evaluates the effectiveness of deep transfer learning in delivering rapid, accurate, and mutation-resilient COVID-19 diagnosis from medical imaging, with a focus on scalability and accessibility. We developed an automated detection system using state-of-the-art CNNs, including VGG16, ResNet50, ConvNetXtTiny, MobileNet, NASNetMobile, and DenseNet121 among others, to detect COVID-19 from chest X-ray and CT images. Among all the models evaluated, DenseNet121 emerged as the best-performing architecture for COVID-19 diagnosis using CT and X-ray images. It achieved an impressive accuracy of 98%, with 96.9% precision, 98.9% recall, 97.9% F1-score and 99.8% AUC score, indicating a high degree of consistency and reliability in both detecting positive and negative cases. The confusion matrix showed minimal false positives and false negatives, underscoring the model's robustness in real-world diagnostic scenarios.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AblationBench: Evaluating Automated Planning of Ablations in Empirical AI Research</title>
<link>https://arxiv.org/abs/2507.08038</link>
<guid>https://arxiv.org/abs/2507.08038</guid>
<content:encoded><![CDATA[
arXiv:2507.08038v1 Announce Type: new 
Abstract: Autonomous agents built on language models (LMs) are showing increasing popularity in many fields, including scientific research. AI co-scientists aim to support or automate parts of the research process using these agents. A key component of empirical AI research is the design of ablation experiments. To this end, we introduce AblationBench, a benchmark suite for evaluating agents on ablation planning tasks in empirical AI research. It includes two tasks: AuthorAblation, which helps authors propose ablation experiments based on a method section and contains 83 instances, and ReviewerAblation, which helps reviewers find missing ablations in a full paper and contains 350 instances. For both tasks, we develop LM-based judges that serve as an automatic evaluation framework. Our experiments with frontier LMs show that these tasks remain challenging, with the best-performing LM system identifying only 29% of the original ablations on average. Lastly, we analyze the limitations of current LMs on these tasks, and find that chain-of-thought prompting outperforms the currently existing agent-based approach.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Noise-Enabled Goal Attainment in Crowded Collectives</title>
<link>https://arxiv.org/abs/2507.08100</link>
<guid>https://arxiv.org/abs/2507.08100</guid>
<content:encoded><![CDATA[
arXiv:2507.08100v1 Announce Type: new 
Abstract: In crowded environments, individuals must navigate around other occupants to reach their destinations. Understanding and controlling traffic flows in these spaces is relevant to coordinating robot swarms and designing infrastructure for dense populations. Here, we combine simulations, theory, and robotic experiments to study how noisy motion can disrupt traffic jams and enable flow as agents travel to individual goals. Above a critical noise level, large jams do not persist. From this observation, we analytically approximate the goal attainment rate as a function of the noise level, then solve for the optimal agent density and noise level that maximize the swarm's goal attainment rate. We perform robotic experiments to corroborate our simulated and theoretical results. Finally, we compare simple, local navigation approaches with a sophisticated but computationally costly central planner. A simple reactive scheme performs well up to moderate densities and is far more computationally efficient than a planner, suggesting lessons for real-world problems.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RegGS: Unposed Sparse Views Gaussian Splatting with 3DGS Registration</title>
<link>https://arxiv.org/abs/2507.08136</link>
<guid>https://arxiv.org/abs/2507.08136</guid>
<content:encoded><![CDATA[
arXiv:2507.08136v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has demonstrated its potential in reconstructing scenes from unposed images. However, optimization-based 3DGS methods struggle with sparse views due to limited prior knowledge. Meanwhile, feed-forward Gaussian approaches are constrained by input formats, making it challenging to incorporate more input views. To address these challenges, we propose RegGS, a 3D Gaussian registration-based framework for reconstructing unposed sparse views. RegGS aligns local 3D Gaussians generated by a feed-forward network into a globally consistent 3D Gaussian representation. Technically, we implement an entropy-regularized Sinkhorn algorithm to efficiently solve the optimal transport Mixture 2-Wasserstein $(\text{MW}_2)$ distance, which serves as an alignment metric for Gaussian mixture models (GMMs) in $\mathrm{Sim}(3)$ space. Furthermore, we design a joint 3DGS registration module that integrates the $\text{MW}_2$ distance, photometric consistency, and depth geometry. This enables a coarse-to-fine registration process while accurately estimating camera poses and aligning the scene. Experiments on the RE10K and ACID datasets demonstrate that RegGS effectively registers local Gaussians with high fidelity, achieving precise pose estimation and high-quality novel-view synthesis. Project page: https://3dagentworld.github.io/reggs/.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Code with Me or for Me? How Increasing AI Automation Transforms Developer Workflows</title>
<link>https://arxiv.org/abs/2507.08149</link>
<guid>https://arxiv.org/abs/2507.08149</guid>
<content:encoded><![CDATA[
arXiv:2507.08149v1 Announce Type: new 
Abstract: Developers now have access to a growing array of increasingly autonomous AI tools to support software development. While numerous studies have examined developer use of copilots, which can provide chat assistance or code completions, evaluations of coding agents, which can automatically write files and run code, still largely rely on static benchmarks without humans-in-the-loop. In this work, we conduct the first academic study to explore developer interactions with coding agents and characterize how more autonomous AI tools affect user productivity and experience, compared to existing copilots. We evaluate two leading copilot and agentic coding assistants, GitHub Copilot and OpenHands, recruiting participants who regularly use the former. Our results show agents have the potential to assist developers in ways that surpass copilots (e.g., completing tasks that humans might not have accomplished before) and reduce the user effort required to complete tasks. However, there are challenges involved in enabling their broader adoption, including how to ensure users have an adequate understanding of agent behaviors. Our results not only provide insights into how developer workflows change as a result of coding agents but also highlight how user interactions with agents differ from those with existing copilots, motivating a set of recommendations for researchers building new agents. Given the broad set of developers who still largely rely on copilot-like systems, our work highlights key challenges of adopting more agentic systems into developer workflows.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>KP-A: A Unified Network Knowledge Plane for Catalyzing Agentic Network Intelligence</title>
<link>https://arxiv.org/abs/2507.08164</link>
<guid>https://arxiv.org/abs/2507.08164</guid>
<content:encoded><![CDATA[
arXiv:2507.08164v1 Announce Type: new 
Abstract: The emergence of large language models (LLMs) and agentic systems is enabling autonomous 6G networks with advanced intelligence, including self-configuration, self-optimization, and self-healing. However, the current implementation of individual intelligence tasks necessitates isolated knowledge retrieval pipelines, resulting in redundant data flows and inconsistent interpretations. Inspired by the service model unification effort in Open-RAN (to support interoperability and vendor diversity), we propose KP-A: a unified Network Knowledge Plane specifically designed for Agentic network intelligence. By decoupling network knowledge acquisition and management from intelligence logic, KP-A streamlines development and reduces maintenance complexity for intelligence engineers. By offering an intuitive and consistent knowledge interface, KP-A also enhances interoperability for the network intelligence agents. We demonstrate KP-A in two representative intelligence tasks: live network knowledge Q&amp;A and edge AI service orchestration. All implementation artifacts have been open-sourced to support reproducibility and future standardization efforts.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Dynamic Stackelberg Game Framework for Agentic AI Defense Against LLM Jailbreaking</title>
<link>https://arxiv.org/abs/2507.08207</link>
<guid>https://arxiv.org/abs/2507.08207</guid>
<content:encoded><![CDATA[
arXiv:2507.08207v1 Announce Type: new 
Abstract: As large language models (LLMs) are increasingly deployed in critical applications, the challenge of jailbreaking, where adversaries manipulate the models to bypass safety mechanisms, has become a significant concern. This paper presents a dynamic Stackelberg game framework to model the interactions between attackers and defenders in the context of LLM jailbreaking. The framework treats the prompt-response dynamics as a sequential extensive-form game, where the defender, as the leader, commits to a strategy while anticipating the attacker's optimal responses. We propose a novel agentic AI solution, the "Purple Agent," which integrates adversarial exploration and defensive strategies using Rapidly-exploring Random Trees (RRT). The Purple Agent actively simulates potential attack trajectories and intervenes proactively to prevent harmful outputs. This approach offers a principled method for analyzing adversarial dynamics and provides a foundation for mitigating the risk of jailbreaking.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reasoning and Behavioral Equilibria in LLM-Nash Games: From Mindsets to Actions</title>
<link>https://arxiv.org/abs/2507.08208</link>
<guid>https://arxiv.org/abs/2507.08208</guid>
<content:encoded><![CDATA[
arXiv:2507.08208v1 Announce Type: new 
Abstract: We introduce the LLM-Nash framework, a game-theoretic model where agents select reasoning prompts to guide decision-making via Large Language Models (LLMs). Unlike classical games that assume utility-maximizing agents with full rationality, this framework captures bounded rationality by modeling the reasoning process explicitly. Equilibrium is defined over the prompt space, with actions emerging as the behavioral output of LLM inference. This approach enables the study of cognitive constraints, mindset expressiveness, and epistemic learning. Through illustrative examples, we show how reasoning equilibria can diverge from classical Nash outcomes, offering a new foundation for strategic interaction in LLM-enabled systems.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>From Curiosity to Competence: How World Models Interact with the Dynamics of Exploration</title>
<link>https://arxiv.org/abs/2507.08210</link>
<guid>https://arxiv.org/abs/2507.08210</guid>
<content:encoded><![CDATA[
arXiv:2507.08210v1 Announce Type: new 
Abstract: What drives an agent to explore the world while also maintaining control over the environment? From a child at play to scientists in the lab, intelligent agents must balance curiosity (the drive to seek knowledge) with competence (the drive to master and control the environment). Bridging cognitive theories of intrinsic motivation with reinforcement learning, we ask how evolving internal representations mediate the trade-off between curiosity (novelty or information gain) and competence (empowerment). We compare two model-based agents using handcrafted state abstractions (Tabular) or learning an internal world model (Dreamer). The Tabular agent shows curiosity and competence guide exploration in distinct patterns, while prioritizing both improves exploration. The Dreamer agent reveals a two-way interaction between exploration and representation learning, mirroring the developmental co-evolution of curiosity and competence. Our findings formalize adaptive exploration as a balance between pursuing the unknown and the controllable, offering insights for cognitive theories and efficient reinforcement learning.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Effect of Static vs. Conversational AI-Generated Messages on Colorectal Cancer Screening Intent: a Randomized Controlled Trial</title>
<link>https://arxiv.org/abs/2507.08211</link>
<guid>https://arxiv.org/abs/2507.08211</guid>
<content:encoded><![CDATA[
arXiv:2507.08211v1 Announce Type: new 
Abstract: Large language model (LLM) chatbots show increasing promise in persuasive communication. Yet their real-world utility remains uncertain, particularly in clinical settings where sustained conversations are difficult to scale. In a pre-registered randomized controlled trial, we enrolled 915 U.S. adults (ages 45-75) who had never completed colorectal cancer (CRC) screening. Participants were randomized to: (1) no message control, (2) expert-written patient materials, (3) single AI-generated message, or (4) a motivational interviewing chatbot. All participants were required to remain in their assigned condition for at least three minutes. Both AI arms tailored content using participant's self-reported demographics including age and gender. Both AI interventions significantly increased stool test intentions by over 12 points (12.9-13.8/100), compared to a 7.5 gain for expert materials (p<.001 for all comparisons). While the AI arms outperformed the no message control for colonoscopy intent, neither showed improvement xover expert materials. Notably, for both outcomes, the chatbot did not outperform the single AI message in boosting intent despite participants spending ~3.5 minutes more on average engaging with it. These findings suggest concise, demographically tailored AI messages may offer a more scalable and clinically viable path to health behavior change than more complex conversational agents and generic time intensive expert-written materials. Moreover, LLMs appear more persuasive for lesser-known and less-invasive screening approaches like stool testing, but may be less effective for entrenched preferences like colonoscopy. Future work should examine which facets of personalization drive behavior change, whether integrating structural supports can translate these modest intent gains into completed screenings, and which health behaviors are most responsive to AI-supported guidance.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Giving AI Agents Access to Cryptocurrency and Smart Contracts Creates New Vectors of AI Harm</title>
<link>https://arxiv.org/abs/2507.08249</link>
<guid>https://arxiv.org/abs/2507.08249</guid>
<content:encoded><![CDATA[
arXiv:2507.08249v1 Announce Type: new 
Abstract: There is growing interest in giving AI agents access to cryptocurrencies as well as to the smart contracts that transact them. But doing so, this position paper argues, could lead to formidable new vectors of AI harm. To support this argument, we first examine the unique properties of cryptocurrencies and smart contracts that could lead to these new vectors of harm. Next, we describe each of these new vectors of harm in detail. Finally, we conclude with a call for more technical research aimed at preventing and mitigating these harms and, thereby making it safer to endow AI agents with cryptocurrencies and smart contracts.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent Safety Alignment via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.08270</link>
<guid>https://arxiv.org/abs/2507.08270</guid>
<content:encoded><![CDATA[
arXiv:2507.08270v1 Announce Type: new 
Abstract: The emergence of autonomous Large Language Model (LLM) agents capable of tool usage has introduced new safety risks that go beyond traditional conversational misuse. These agents, empowered to execute external functions, are vulnerable to both user-initiated threats (e.g., adversarial prompts) and tool-initiated threats (e.g., malicious outputs from compromised tools). In this paper, we propose the first unified safety-alignment framework for tool-using agents, enabling models to handle both channels of threat via structured reasoning and sandboxed reinforcement learning. We introduce a tri-modal taxonomy, including benign, malicious, and sensitive for both user prompts and tool responses, and define a policy-driven decision model. Our framework employs a custom-designed sandbox environment that simulates real-world tool execution and allows fine-grained reward shaping. Through extensive evaluations on public and self-built benchmarks, including Agent SafetyBench, InjecAgent, and BFCL, we demonstrate that our safety-aligned agents significantly improve resistance to security threats while preserving strong utility on benign tasks. Our results show that safety and effectiveness can be jointly optimized, laying the groundwork for trustworthy deployment of autonomous LLM agents.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>KAT-V1: Kwai-AutoThink Technical Report</title>
<link>https://arxiv.org/abs/2507.08297</link>
<guid>https://arxiv.org/abs/2507.08297</guid>
<content:encoded><![CDATA[
arXiv:2507.08297v1 Announce Type: new 
Abstract: We present Kwaipilot-AutoThink (KAT), an open-source 40B large language model developed to address the overthinking problem in reasoning-intensive tasks, where an automatic thinking training paradigm is proposed to dynamically switch between reasoning and non-reasoning modes based on task complexity. Specifically, first, we construct the dual-regime dataset based on a novel tagging pipeline and a multi-agent synthesis strategy, and then we apply Multi-Token Prediction (MTP)-enhanced knowledge distillation, enabling efficient and fine-grained reasoning transfer with minimal pretraining cost. Besides, we implement a cold-start initialization strategy that introduces mode-selection priors using majority-vote signals and intent-aware prompting. Finally, we propose Step-SRPO, a reinforcement learning algorithm that incorporates intermediate supervision into the GRPO framework, offering structured guidance over both reasoning-mode selection and response accuracy. Extensive experiments across multiple benchmarks demonstrate that KAT consistently matches or even outperforms current state-of-the-art models, including DeepSeek-R1-0528 and Qwen3-235B-A22B, across a wide range of reasoning-intensive tasks while reducing token usage by up to approximately 30\%. Beyond academic evaluation, KAT has been successfully deployed in Kwaipilot (i.e., Kuaishou's internal coding assistant), and improves real-world development workflows with high accuracy, efficiency, and controllable reasoning behaviors. Moreover, we are actively training a 200B Mixture-of-Experts (MoE) with 40B activation parameters, where the early-stage results already demonstrate promising improvements in performance and efficiency, further showing the scalability of the AutoThink paradigm.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CRMAgent: A Multi-Agent LLM System for E-Commerce CRM Message Template Generation</title>
<link>https://arxiv.org/abs/2507.08325</link>
<guid>https://arxiv.org/abs/2507.08325</guid>
<content:encoded><![CDATA[
arXiv:2507.08325v1 Announce Type: new 
Abstract: In e-commerce private-domain channels such as instant messaging and e-mail, merchants engage customers directly as part of their Customer Relationship Management (CRM) programmes to drive retention and conversion. While a few top performers excel at crafting outbound messages, most merchants struggle to write persuasive copy because they lack both expertise and scalable tools. We introduce CRMAgent, a multi-agent system built on large language models (LLMs) that generates high-quality message templates and actionable writing guidance through three complementary modes. First, group-based learning enables the agent to learn from a merchant's own top-performing messages within the same audience segment and rewrite low-performing ones. Second, retrieval-and-adaptation fetches templates that share the same audience segment and exhibit high similarity in voucher type and product category, learns their successful patterns, and adapts them to the current campaign. Third, a rule-based fallback provides a lightweight zero-shot rewrite when no suitable references are available. Extensive experiments show that CRMAgent consistently outperforms merchants' original templates, delivering significant gains in both audience-match and marketing-effectiveness metrics.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>What Factors Affect LLMs and RLLMs in Financial Question Answering?</title>
<link>https://arxiv.org/abs/2507.08339</link>
<guid>https://arxiv.org/abs/2507.08339</guid>
<content:encoded><![CDATA[
arXiv:2507.08339v1 Announce Type: new 
Abstract: Recently, the development of large language models (LLMs) and reasoning large language models (RLLMs) have gained considerable attention from many researchers. RLLMs enhance the reasoning capabilities of LLMs through Long Chain-of-Thought (Long CoT) processes, significantly improving the performance of LLMs in addressing complex problems. However, there are few works that systematically explore what methods can fully unlock the performance of LLMs and RLLMs within the financial domain. To investigate the impact of various methods on LLMs and RLLMs, we utilize five LLMs and three RLLMs to assess the effects of prompting methods, agentic frameworks, and multilingual alignment methods on financial question-answering tasks. Our research findings indicate: (1) Current prompting methods and agent frameworks enhance the performance of LLMs in financial question answering by simulating Long CoT; (2) RLLMs possess inherent Long CoT capabilities, which limits the effectiveness of conventional methods in further enhancing their performance; (3) Current advanced multilingual alignment methods primarily improve the multilingual performance of LLMs by extending the reasoning length, which yields minimal benefits for RLLMs. We hope that this study can serve as an important reference for LLMs and RLLMs in the field of financial question answering.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring Design of Multi-Agent LLM Dialogues for Research Ideation</title>
<link>https://arxiv.org/abs/2507.08350</link>
<guid>https://arxiv.org/abs/2507.08350</guid>
<content:encoded><![CDATA[
arXiv:2507.08350v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly used to support creative tasks such as research idea generation. While recent work has shown that structured dialogues between LLMs can improve the novelty and feasibility of generated ideas, the optimal design of such interactions remains unclear. In this study, we conduct a comprehensive analysis of multi-agent LLM dialogues for scientific ideation. We compare different configurations of agent roles, number of agents, and dialogue depth to understand how these factors influence the novelty and feasibility of generated ideas. Our experimental setup includes settings where one agent generates ideas and another critiques them, enabling iterative improvement. Our results show that enlarging the agent cohort, deepening the interaction depth, and broadening agent persona heterogeneity each enrich the diversity of generated ideas. Moreover, specifically increasing critic-side diversity within the ideation-critique-revision loop further boosts the feasibility of the final proposals. Our findings offer practical guidelines for building effective multi-agent LLM systems for scientific ideation. Our code is available at https://github.com/g6000/MultiAgent-Research-Ideator.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Pre-Training for Offline-to-Online Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.08387</link>
<guid>https://arxiv.org/abs/2507.08387</guid>
<content:encoded><![CDATA[
arXiv:2507.08387v1 Announce Type: new 
Abstract: Offline-to-online reinforcement learning (RL) aims to integrate the complementary strengths of offline and online RL by pre-training an agent offline and subsequently fine-tuning it through online interactions. However, recent studies reveal that offline pre-trained agents often underperform during online fine-tuning due to inaccurate value estimation caused by distribution shift, with random initialization proving more effective in certain cases. In this work, we propose a novel method, Online Pre-Training for Offline-to-Online RL (OPT), explicitly designed to address the issue of inaccurate value estimation in offline pre-trained agents. OPT introduces a new learning phase, Online Pre-Training, which allows the training of a new value function tailored specifically for effective online fine-tuning. Implementation of OPT on TD3 and SPOT demonstrates an average 30% improvement in performance across a wide range of D4RL environments, including MuJoCo, Antmaze, and Adroit.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent LLMs as Ethics Advocates in AI-Based Systems</title>
<link>https://arxiv.org/abs/2507.08392</link>
<guid>https://arxiv.org/abs/2507.08392</guid>
<content:encoded><![CDATA[
arXiv:2507.08392v1 Announce Type: new 
Abstract: Incorporating ethics into the requirement elicitation process is essential for creating ethically aligned systems. Although eliciting manual ethics requirements is effective, it requires diverse input from multiple stakeholders, which can be challenging due to time and resource constraints. Moreover, it is often given a low priority in the requirements elicitation process. This study proposes a framework for generating ethics requirements drafts by introducing an ethics advocate agent in a multi-agent LLM setting. This agent critiques and provides input on ethical issues based on the system description. The proposed framework is evaluated through two case studies from different contexts, demonstrating that it captures the majority of ethics requirements identified by researchers during 30-minute interviews and introduces several additional relevant requirements. However, it also highlights reliability issues in generating ethics requirements, emphasizing the need for human feedback in this sensitive domain. We believe this work can facilitate the broader adoption of ethics in the requirements engineering process, ultimately leading to more ethically aligned products.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Large Language Models in Discipline-specific Research: Challenges, Methods and Opportunities</title>
<link>https://arxiv.org/abs/2507.08425</link>
<guid>https://arxiv.org/abs/2507.08425</guid>
<content:encoded><![CDATA[
arXiv:2507.08425v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated their transformative potential across numerous disciplinary studies, reshaping the existing research methodologies and fostering interdisciplinary collaboration. However, a systematic understanding of their integration into diverse disciplines remains underexplored. This survey paper provides a comprehensive overview of the application of LLMs in interdisciplinary studies, categorising research efforts from both a technical perspective and with regard to their applicability. From a technical standpoint, key methodologies such as supervised fine-tuning, retrieval-augmented generation, agent-based approaches, and tool-use integration are examined, which enhance the adaptability and effectiveness of LLMs in discipline-specific contexts. From the perspective of their applicability, this paper explores how LLMs are contributing to various disciplines including mathematics, physics, chemistry, biology, and the humanities and social sciences, demonstrating their role in discipline-specific tasks. The prevailing challenges are critically examined and the promising research directions are highlighted alongside the recent advances in LLMs. By providing a comprehensive overview of the technical developments and applications in this field, this survey aims to serve as an invaluable resource for the researchers who are navigating the complex landscape of LLMs in the context of interdisciplinary studies.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Age of Information Optimization in Laser-charged UAV-assisted IoT Networks: A Multi-agent Deep Reinforcement Learning Method</title>
<link>https://arxiv.org/abs/2507.08429</link>
<guid>https://arxiv.org/abs/2507.08429</guid>
<content:encoded><![CDATA[
arXiv:2507.08429v1 Announce Type: new 
Abstract: The integration of unmanned aerial vehicles (UAVs) with Internet of Things (IoT) networks offers promising solutions for efficient data collection. However, the limited energy capacity of UAVs remains a significant challenge. In this case, laser beam directors (LBDs) have emerged as an effective technology for wireless charging of UAVs during operation, thereby enabling sustained data collection without frequent returns to charging stations (CSs). In this work, we investigate the age of information (AoI) optimization in LBD-powered UAV-assisted IoT networks, where multiple UAVs collect data from distributed IoTs while being recharged by laser beams. We formulate a joint optimization problem that aims to minimize the peak AoI while determining optimal UAV trajectories and laser charging strategies. This problem is particularly challenging due to its non-convex nature, complex temporal dependencies, and the need to balance data collection efficiency with energy consumption constraints. To address these challenges, we propose a novel multi-agent proximal policy optimization with temporal memory and multi-agent coordination (MAPPO-TM) framework. Specifically, MAPPO-TM incorporates temporal memory mechanisms to capture the dynamic nature of UAV operations and facilitates effective coordination among multiple UAVs through decentralized learning while considering global system objectives. Simulation results demonstrate that the proposed MAPPO-TM algorithm outperforms conventional approaches in terms of peak AoI minimization and energy efficiency. Ideally, the proposed algorithm achieves up to 15.1% reduction in peak AoI compared to conventional multi-agent deep reinforcement learning (MADRL) methods.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Finding Common Ground: Using Large Language Models to Detect Agreement in Multi-Agent Decision Conferences</title>
<link>https://arxiv.org/abs/2507.08440</link>
<guid>https://arxiv.org/abs/2507.08440</guid>
<content:encoded><![CDATA[
arXiv:2507.08440v1 Announce Type: new 
Abstract: Decision conferences are structured, collaborative meetings that bring together experts from various fields to address complex issues and reach a consensus on recommendations for future actions or policies. These conferences often rely on facilitated discussions to ensure productive dialogue and collective agreement. Recently, Large Language Models (LLMs) have shown significant promise in simulating real-world scenarios, particularly through collaborative multi-agent systems that mimic group interactions. In this work, we present a novel LLM-based multi-agent system designed to simulate decision conferences, specifically focusing on detecting agreement among the participant agents. To achieve this, we evaluate six distinct LLMs on two tasks: stance detection, which identifies the position an agent takes on a given issue, and stance polarity detection, which identifies the sentiment as positive, negative, or neutral. These models are further assessed within the multi-agent system to determine their effectiveness in complex simulations. Our results indicate that LLMs can reliably detect agreement even in dynamic and nuanced debates. Incorporating an agreement-detection agent within the system can also improve the efficiency of group debates and enhance the overall quality and coherence of deliberations, making them comparable to real-world decision conferences regarding outcome and decision-making. These findings demonstrate the potential for LLM-based multi-agent systems to simulate group decision-making processes. They also highlight that such systems could be instrumental in supporting decision-making with expert elicitation workshops across various domains.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation for Occluded Person Re-Identification</title>
<link>https://arxiv.org/abs/2507.08520</link>
<guid>https://arxiv.org/abs/2507.08520</guid>
<content:encoded><![CDATA[
arXiv:2507.08520v1 Announce Type: new 
Abstract: Occluded person re-identification aims to retrieve holistic images based on occluded ones. Existing methods often rely on aligning visible body parts, applying occlusion augmentation, or complementing missing semantics using holistic images. However, they face challenges in handling diverse occlusion scenarios not seen during training and the issue of feature contamination from holistic images. To address these limitations, we propose Occlusion-Guided Feature Purification Learning via Reinforced Knowledge Distillation (OGFR), which simultaneously mitigates these challenges. OGFR adopts a teacher-student distillation architecture that effectively incorporates diverse occlusion patterns into feature representation while transferring the purified discriminative holistic knowledge from the holistic to the occluded branch through reinforced knowledge distillation. Specifically, an Occlusion-Aware Vision Transformer is designed to leverage learnable occlusion pattern embeddings to explicitly model such diverse occlusion types, thereby guiding occlusion-aware robust feature representation. Moreover, we devise a Feature Erasing and Purification Module within the holistic branch, in which an agent is employed to identify low-quality patch tokens of holistic images that contain noisy negative information via deep reinforcement learning, and substitute these patch tokens with learnable embedding tokens to avoid feature contamination and further excavate identity-related discriminative clues. Afterward, with the assistance of knowledge distillation, the student branch effectively absorbs the purified holistic knowledge to precisely learn robust representation regardless of the interference of occlusions.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Recursive Reward Aggregation</title>
<link>https://arxiv.org/abs/2507.08537</link>
<guid>https://arxiv.org/abs/2507.08537</guid>
<content:encoded><![CDATA[
arXiv:2507.08537v1 Announce Type: new 
Abstract: In reinforcement learning (RL), aligning agent behavior with specific objectives typically requires careful design of the reward function, which can be challenging when the desired objectives are complex. In this work, we propose an alternative approach for flexible behavior alignment that eliminates the need to modify the reward function by selecting appropriate reward aggregation functions. By introducing an algebraic perspective on Markov decision processes (MDPs), we show that the Bellman equations naturally emerge from the recursive generation and aggregation of rewards, allowing for the generalization of the standard discounted sum to other recursive aggregations, such as discounted max and Sharpe ratio. Our approach applies to both deterministic and stochastic settings and integrates seamlessly with value-based and actor-critic algorithms. Experimental results demonstrate that our approach effectively optimizes diverse objectives, highlighting its versatility and potential for real-world applications.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAM2RL: Towards Reinforcement Learning Memory Control in Segment Anything Model 2</title>
<link>https://arxiv.org/abs/2507.08548</link>
<guid>https://arxiv.org/abs/2507.08548</guid>
<content:encoded><![CDATA[
arXiv:2507.08548v1 Announce Type: new 
Abstract: Segment Anything Model 2 (SAM 2) has demonstrated strong performance in object segmentation tasks and has become the state-of-the-art for visual object tracking. The model stores information from previous frames in a memory bank, enabling temporal consistency across video sequences. Recent methods augment SAM 2 with hand-crafted update rules to better handle distractors, occlusions, and object motion. We propose a fundamentally different approach using reinforcement learning for optimizing memory updates in SAM 2 by framing memory control as a sequential decision-making problem. In an overfitting setup with a separate agent per video, our method achieves a relative improvement over SAM 2 that exceeds by more than three times the gains of existing heuristics. These results reveal the untapped potential of the memory bank and highlight reinforcement learning as a powerful alternative to hand-crafted update rules for memory control in visual object tracking.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unlocking Speech Instruction Data Potential with Query Rewriting</title>
<link>https://arxiv.org/abs/2507.08603</link>
<guid>https://arxiv.org/abs/2507.08603</guid>
<content:encoded><![CDATA[
arXiv:2507.08603v1 Announce Type: new 
Abstract: End-to-end Large Speech Language Models~(\textbf{LSLMs}) demonstrate strong potential in response latency and speech comprehension capabilities, showcasing general intelligence across speech understanding tasks. However, the ability to follow speech instructions has not been fully realized due to the lack of datasets and heavily biased training tasks. Leveraging the rich ASR datasets, previous approaches have used Large Language Models~(\textbf{LLMs}) to continue the linguistic information of speech to construct speech instruction datasets. Yet, due to the gap between LLM-generated results and real human responses, the continuation methods further amplify these shortcomings. Given the high costs of collecting and annotating speech instruction datasets by humans, using speech synthesis to construct large-scale speech instruction datasets has become a balanced and robust alternative. Although modern Text-To-Speech~(\textbf{TTS}) models have achieved near-human-level synthesis quality, it is challenging to appropriately convert out-of-distribution text instruction to speech due to the limitations of the training data distribution in TTS models. To address this issue, we propose a query rewriting framework with multi-LLM knowledge fusion, employing multiple agents to annotate and validate the synthesized speech, making it possible to construct high-quality speech instruction datasets without relying on human annotation. Experiments show that this method can transform text instructions into distributions more suitable for TTS models for speech synthesis through zero-shot rewriting, increasing data usability from 72\% to 93\%. It also demonstrates unique advantages in rewriting tasks that require complex knowledge and context-related abilities.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergent Natural Language with Communication Games for Improving Image Captioning Capabilities without Additional Data</title>
<link>https://arxiv.org/abs/2507.08610</link>
<guid>https://arxiv.org/abs/2507.08610</guid>
<content:encoded><![CDATA[
arXiv:2507.08610v1 Announce Type: new 
Abstract: Image captioning is an important problem in developing various AI systems, and these tasks require large volumes of annotated images to train the models. Since all existing labelled datasets are already used for training the large Vision Language Models (VLMs), it becomes challenging to improve the performance of the same. Considering this, it is essential to consider the unsupervised image captioning performance, which remains relatively under-explored. To that end, we propose LoGIC (Lewis Communication Game for Image Captioning), a Multi-agent Reinforcement Learning game. The proposed method consists of two agents, a 'speaker' and a 'listener', with the objective of learning a strategy for communicating in natural language. We train agents in the cooperative common-reward setting using the GRPO algorithm and show that improvement in image captioning performance emerges as a consequence of the agents learning to play the game. We show that using pre-trained VLMs as the 'speaker' and Large Language Model (LLM) for language understanding in the 'listener', we achieved a $46$ BLEU score after fine-tuning using LoGIC without additional labels, a $2$ units advantage in absolute metrics compared to the $44$ BLEU score of the vanilla VLM. Additionally, we replace the VLM from the 'speaker' with lightweight components: (i) a ViT for image perception and (ii) a GPT2 language generation, and train them from scratch using LoGIC, obtaining a $31$ BLEU score in the unsupervised setting, a $10$ points advantage over existing unsupervised image-captioning methods.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentsNet: Coordination and Collaborative Reasoning in Multi-Agent LLMs</title>
<link>https://arxiv.org/abs/2507.08616</link>
<guid>https://arxiv.org/abs/2507.08616</guid>
<content:encoded><![CDATA[
arXiv:2507.08616v1 Announce Type: new 
Abstract: Large-language models (LLMs) have demonstrated powerful problem-solving capabilities, in particular when organized in multi-agent systems. However, the advent of such systems also raises several questions on the ability of a complex network of agents to effectively self-organize and collaborate. While measuring performance on standard reasoning benchmarks indicates how well multi-agent systems can solve reasoning tasks, it is unclear whether these systems are able to leverage their topology effectively. Here, we propose AgentsNet, a new benchmark for multi-agent reasoning. By drawing inspiration from classical problems in distributed systems and graph theory, AgentsNet measures the ability of multi-agent systems to collaboratively form strategies for problem-solving, self-organization, and effective communication given a network topology. We evaluate a variety of baseline methods on AgentsNet including homogeneous networks of agents which first have to agree on basic protocols for organization and communication. We find that some frontier LLMs are already demonstrating strong performance for small networks but begin to fall off once the size of the network scales. While existing multi-agent benchmarks cover at most 2-5 agents, AgentsNet is practically unlimited in size and can scale with new generations of LLMs. As such, we also probe frontier models in a setup with up to 100 agents.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Large Language Models for Conceptual Systems Engineering and Design</title>
<link>https://arxiv.org/abs/2507.08619</link>
<guid>https://arxiv.org/abs/2507.08619</guid>
<content:encoded><![CDATA[
arXiv:2507.08619v1 Announce Type: new 
Abstract: Early-stage engineering design involves complex, iterative reasoning, yet existing large language model (LLM) workflows struggle to maintain task continuity and generate executable models. We evaluate whether a structured multi-agent system (MAS) can more effectively manage requirements extraction, functional decomposition, and simulator code generation than a simpler two-agent system (2AS). The target application is a solar-powered water filtration system as described in a cahier des charges. We introduce the Design-State Graph (DSG), a JSON-serializable representation that bundles requirements, physical embodiments, and Python-based physics models into graph nodes. A nine-role MAS iteratively builds and refines the DSG, while the 2AS collapses the process to a Generator-Reflector loop. Both systems run a total of 60 experiments (2 LLMs - Llama 3.3 70B vs reasoning-distilled DeepSeek R1 70B x 2 agent configurations x 3 temperatures x 5 seeds). We report a JSON validity, requirement coverage, embodiment presence, code compatibility, workflow completion, runtime, and graph size. Across all runs, both MAS and 2AS maintained perfect JSON integrity and embodiment tagging. Requirement coverage remained minimal (less than 20\%). Code compatibility peaked at 100\% under specific 2AS settings but averaged below 50\% for MAS. Only the reasoning-distilled model reliably flagged workflow completion. Powered by DeepSeek R1 70B, the MAS generated more granular DSGs (average 5-6 nodes) whereas 2AS mode-collapsed. Structured multi-agent orchestration enhanced design detail. Reasoning-distilled LLM improved completion rates, yet low requirements and fidelity gaps in coding persisted.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OnlineBEV: Recurrent Temporal Fusion in Bird's Eye View Representations for Multi-Camera 3D Perception</title>
<link>https://arxiv.org/abs/2507.08644</link>
<guid>https://arxiv.org/abs/2507.08644</guid>
<content:encoded><![CDATA[
arXiv:2507.08644v1 Announce Type: new 
Abstract: Multi-view camera-based 3D perception can be conducted using bird's eye view (BEV) features obtained through perspective view-to-BEV transformations. Several studies have shown that the performance of these 3D perception methods can be further enhanced by combining sequential BEV features obtained from multiple camera frames. However, even after compensating for the ego-motion of an autonomous agent, the performance gain from temporal aggregation is limited when combining a large number of image frames. This limitation arises due to dynamic changes in BEV features over time caused by object motion. In this paper, we introduce a novel temporal 3D perception method called OnlineBEV, which combines BEV features over time using a recurrent structure. This structure increases the effective number of combined features with minimal memory usage. However, it is critical to spatially align the features over time to maintain strong performance. OnlineBEV employs the Motion-guided BEV Fusion Network (MBFNet) to achieve temporal feature alignment. MBFNet extracts motion features from consecutive BEV frames and dynamically aligns historical BEV features with current ones using these motion features. To enforce temporal feature alignment explicitly, we use Temporal Consistency Learning Loss, which captures discrepancies between historical and target BEV features. Experiments conducted on the nuScenes benchmark demonstrate that OnlineBEV achieves significant performance gains over the current best method, SOLOFusion. OnlineBEV achieves 63.9% NDS on the nuScenes test set, recording state-of-the-art performance in the camera-only 3D object detection task.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DatasetAgent: A Novel Multi-Agent System for Auto-Constructing Datasets from Real-World Images</title>
<link>https://arxiv.org/abs/2507.08648</link>
<guid>https://arxiv.org/abs/2507.08648</guid>
<content:encoded><![CDATA[
arXiv:2507.08648v1 Announce Type: new 
Abstract: Common knowledge indicates that the process of constructing image datasets usually depends on the time-intensive and inefficient method of manual collection and annotation. Large models offer a solution via data generation. Nonetheless, real-world data are obviously more valuable comparing to artificially intelligence generated data, particularly in constructing image datasets. For this reason, we propose a novel method for auto-constructing datasets from real-world images by a multiagent collaborative system, named as DatasetAgent. By coordinating four different agents equipped with Multi-modal Large Language Models (MLLMs), as well as a tool package for image optimization, DatasetAgent is able to construct high-quality image datasets according to user-specified requirements. In particular, two types of experiments are conducted, including expanding existing datasets and creating new ones from scratch, on a variety of open-source datasets. In both cases, multiple image datasets constructed by DatasetAgent are used to train various vision models for image classification, object detection, and image segmentation.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>elsciRL: Integrating Language Solutions into Reinforcement Learning Problem Settings</title>
<link>https://arxiv.org/abs/2507.08705</link>
<guid>https://arxiv.org/abs/2507.08705</guid>
<content:encoded><![CDATA[
arXiv:2507.08705v1 Announce Type: new 
Abstract: We present elsciRL, an open-source Python library to facilitate the application of language solutions on reinforcement learning problems. We demonstrate the potential of our software by extending the Language Adapter with Self-Completing Instruction framework defined in (Osborne, 2024) with the use of LLMs. Our approach can be re-applied to new applications with minimal setup requirements. We provide a novel GUI that allows a user to provide text input for an LLM to generate instructions which it can then self-complete. Empirical results indicate that these instructions \textit{can} improve a reinforcement learning agent's performance. Therefore, we present this work to accelerate the evaluation of language solutions on reward based environments to enable new opportunities for scientific discovery.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SPLASH! Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations</title>
<link>https://arxiv.org/abs/2507.08707</link>
<guid>https://arxiv.org/abs/2507.08707</guid>
<content:encoded><![CDATA[
arXiv:2507.08707v1 Announce Type: new 
Abstract: Inverse Reinforcement Learning (IRL) presents a powerful paradigm for learning complex robotic tasks from human demonstrations. However, most approaches make the assumption that expert demonstrations are available, which is often not the case. Those that allow for suboptimality in the demonstrations are not designed for long-horizon goals or adversarial tasks. Many desirable robot capabilities fall into one or both of these categories, thus highlighting a critical shortcoming in the ability of IRL to produce field-ready robotic agents. We introduce Sample-efficient Preference-based inverse reinforcement learning for Long-horizon Adversarial tasks from Suboptimal Hierarchical demonstrations (SPLASH), which advances the state-of-the-art in learning from suboptimal demonstrations to long-horizon and adversarial settings. We empirically validate SPLASH on a maritime capture-the-flag task in simulation, and demonstrate real-world applicability with sim-to-real translation experiments on autonomous unmanned surface vehicles. We show that our proposed methods allow SPLASH to significantly outperform the state-of-the-art in reward learning from suboptimal demonstrations.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>NeuralOS: Towards Simulating Operating Systems via Neural Generative Models</title>
<link>https://arxiv.org/abs/2507.08800</link>
<guid>https://arxiv.org/abs/2507.08800</guid>
<content:encoded><![CDATA[
arXiv:2507.08800v1 Announce Type: new 
Abstract: We introduce NeuralOS, a neural framework that simulates graphical user interfaces (GUIs) of operating systems by directly predicting screen frames in response to user inputs such as mouse movements, clicks, and keyboard events. NeuralOS combines a recurrent neural network (RNN), which tracks computer state, with a diffusion-based neural renderer that generates screen images. The model is trained on a large-scale dataset of Ubuntu XFCE recordings, which include both randomly generated interactions and realistic interactions produced by AI agents. Experiments show that NeuralOS successfully renders realistic GUI sequences, accurately captures mouse interactions, and reliably predicts state transitions like application launches. Although modeling fine-grained keyboard interactions precisely remains challenging, NeuralOS offers a step toward creating fully adaptive, generative neural interfaces for future human-computer interaction systems.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>To Trade or Not to Trade: An Agentic Approach to Estimating Market Risk Improves Trading Decisions</title>
<link>https://arxiv.org/abs/2507.08584</link>
<guid>https://arxiv.org/abs/2507.08584</guid>
<content:encoded><![CDATA[
arXiv:2507.08584v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly deployed in agentic frameworks, in which prompts trigger complex tool-based analysis in pursuit of a goal. While these frameworks have shown promise across multiple domains including in finance, they typically lack a principled model-building step, relying instead on sentiment- or trend-based analysis. We address this gap by developing an agentic system that uses LLMs to iteratively discover stochastic differential equations for financial time series. These models generate risk metrics which inform daily trading decisions. We evaluate our system in both traditional backtests and using a market simulator, which introduces synthetic but causally plausible price paths and news events. We find that model-informed trading strategies outperform standard LLM-based agents, improving Sharpe ratios across multiple equities. Our results show that combining LLMs with agentic model discovery enhances market risk estimation and enables more profitable trading decisions.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Deep Reinforcement Learning for Resource Allocation with Peak Age of Information Violation Guarantees</title>
<link>https://arxiv.org/abs/2507.08653</link>
<guid>https://arxiv.org/abs/2507.08653</guid>
<content:encoded><![CDATA[
arXiv:2507.08653v1 Announce Type: cross 
Abstract: In Wireless Networked Control Systems (WNCSs), control and communication systems must be co-designed due to their strong interdependence. This paper presents a novel optimization theory-based safe deep reinforcement learning (DRL) framework for ultra-reliable WNCSs, ensuring constraint satisfaction while optimizing performance, for the first time in the literature. The approach minimizes power consumption under key constraints, including Peak Age of Information (PAoI) violation probability, transmit power, and schedulability in the finite blocklength regime. PAoI violation probability is uniquely derived by combining stochastic maximum allowable transfer interval (MATI) and maximum allowable packet delay (MAD) constraints in a multi-sensor network. The framework consists of two stages: optimization theory and safe DRL. The first stage derives optimality conditions to establish mathematical relationships among variables, simplifying and decomposing the problem. The second stage employs a safe DRL model where a teacher-student framework guides the DRL agent (student). The control mechanism (teacher) evaluates compliance with system constraints and suggests the nearest feasible action when needed. Extensive simulations show that the proposed framework outperforms rule-based and other optimization theory based DRL benchmarks, achieving faster convergence, higher rewards, and greater stability.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Interpreting systems as solving POMDPs: a step towards a formal understanding of agency</title>
<link>https://arxiv.org/abs/2209.01619</link>
<guid>https://arxiv.org/abs/2209.01619</guid>
<content:encoded><![CDATA[
arXiv:2209.01619v2 Announce Type: replace 
Abstract: Under what circumstances can a system be said to have beliefs and goals, and how do such agency-related features relate to its physical state? Recent work has proposed a notion of interpretation map, a function that maps the state of a system to a probability distribution representing its beliefs about an external world. Such a map is not completely arbitrary, as the beliefs it attributes to the system must evolve over time in a manner that is consistent with Bayes' theorem, and consequently the dynamics of a system constrain its possible interpretations. Here we build on this approach, proposing a notion of interpretation not just in terms of beliefs but in terms of goals and actions. To do this we make use of the existing theory of partially observable Markov processes (POMDPs): we say that a system can be interpreted as a solution to a POMDP if it not only admits an interpretation map describing its beliefs about the hidden state of a POMDP but also takes actions that are optimal according to its belief state. An agent is then a system together with an interpretation of this system as a POMDP solution. Although POMDPs are not the only possible formulation of what it means to have a goal, this nevertheless represents a step towards a more general formal definition of what it means for a system to be an agent.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Text2BIM: Generating Building Models Using a Large Language Model-based Multi-Agent Framework</title>
<link>https://arxiv.org/abs/2408.08054</link>
<guid>https://arxiv.org/abs/2408.08054</guid>
<content:encoded><![CDATA[
arXiv:2408.08054v2 Announce Type: replace 
Abstract: The conventional BIM authoring process typically requires designers to master complex and tedious modeling commands in order to materialize their design intentions within BIM authoring tools. This additional cognitive burden complicates the design process and hinders the adoption of BIM and model-based design in the AEC (Architecture, Engineering, and Construction) industry. To facilitate the expression of design intentions more intuitively, we propose Text2BIM, an LLM-based multi-agent framework that can generate 3D building models from natural language instructions. This framework orchestrates multiple LLM agents to collaborate and reason, transforming textual user input into imperative code that invokes the BIM authoring tool's APIs, thereby generating editable BIM models with internal layouts, external envelopes, and semantic information directly in the software. Furthermore, a rule-based model checker is introduced into the agentic workflow, utilizing predefined domain knowledge to guide the LLM agents in resolving issues within the generated models and iteratively improving model quality. Extensive experiments were conducted to compare and analyze the performance of three different LLMs under the proposed framework. The evaluation results demonstrate that our approach can effectively generate high-quality, structurally rational building models that are aligned with the abstract concepts specified by user input. Finally, an interactive software prototype was developed to integrate the framework into the BIM authoring software Vectorworks, showcasing the potential of modeling by chatting. The code is available at: https://github.com/dcy0577/Text2BIM
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Embedding Space Allocation with Angle-Norm Joint Classifiers for Few-Shot Class-Incremental Learning</title>
<link>https://arxiv.org/abs/2411.09250</link>
<guid>https://arxiv.org/abs/2411.09250</guid>
<content:encoded><![CDATA[
arXiv:2411.09250v2 Announce Type: replace 
Abstract: Few-shot class-incremental learning (FSCIL) aims to continually learn new classes from only a few samples without forgetting previous ones, requiring intelligent agents to adapt to dynamic environments. FSCIL combines the characteristics and challenges of class-incremental learning and few-shot learning: (i) Current classes occupy the entire feature space, which is detrimental to learning new classes. (ii) The small number of samples in incremental rounds is insufficient for fully training. In existing mainstream virtual class methods, for addressing the challenge (i), they attempt to use virtual classes as placeholders. However, new classes may not necessarily align with the virtual classes. For the challenge (ii), they replace trainable fully connected layers with Nearest Class Mean (NCM) classifiers based on cosine similarity, but NCM classifiers do not account for sample imbalance issues. To address these issues in previous methods, we propose the class-center guided embedding Space Allocation with Angle-Norm joint classifiers (SAAN) learning framework, which provides balanced space for all classes and leverages norm differences caused by sample imbalance to enhance classification criteria. Specifically, for challenge (i), SAAN divides the feature space into multiple subspaces and allocates a dedicated subspace for each session by guiding samples with the pre-set category centers. For challenge (ii), SAAN establishes a norm distribution for each class and generates angle-norm joint logits. Experiments demonstrate that SAAN can achieve state-of-the-art performance and it can be directly embedded into other SOTA methods as a plug-in, further enhancing their performance.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving</title>
<link>https://arxiv.org/abs/2503.07656</link>
<guid>https://arxiv.org/abs/2503.07656</guid>
<content:encoded><![CDATA[
arXiv:2503.07656v2 Announce Type: replace 
Abstract: End-to-end autonomous driving (E2E-AD) has emerged as a trend in the field of autonomous driving, promising a data-driven, scalable approach to system design. However, existing E2E-AD methods usually adopt the sequential paradigm of perception-prediction-planning, which leads to cumulative errors and training instability. The manual ordering of tasks also limits the system`s ability to leverage synergies between tasks (for example, planning-aware perception and game-theoretic interactive prediction and planning). Moreover, the dense BEV representation adopted by existing methods brings computational challenges for long-range perception and long-term temporal fusion. To address these challenges, we present DriveTransformer, a simplified E2E-AD framework for the ease of scaling up, characterized by three key features: Task Parallelism (All agent, map, and planning queries direct interact with each other at each block), Sparse Representation (Task queries direct interact with raw sensor features), and Streaming Processing (Task queries are stored and passed as history information). As a result, the new framework is composed of three unified operations: task self-attention, sensor cross-attention, temporal cross-attention, which significantly reduces the complexity of system and leads to better training stability. DriveTransformer achieves state-of-the-art performance in both simulated closed-loop benchmark Bench2Drive and real world open-loop benchmark nuScenes with high FPS.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training</title>
<link>https://arxiv.org/abs/2503.08525</link>
<guid>https://arxiv.org/abs/2503.08525</guid>
<content:encoded><![CDATA[
arXiv:2503.08525v2 Announce Type: replace 
Abstract: Reinforcement learning with verifiable outcome rewards (RLVR) has effectively scaled up chain-of-thought (CoT) reasoning in large language models (LLMs). Yet, its efficacy in training vision-language model (VLM) agents for goal-directed action reasoning in visual environments is less established. This work investigates this problem through extensive experiments on complex card games, such as 24 points, and embodied tasks from ALFWorld. We find that when rewards are based solely on action outcomes, RL fails to incentivize CoT reasoning in VLMs, instead leading to a phenomenon we termed thought collapse, characterized by a rapid loss of diversity in the agent's thoughts, state-irrelevant and incomplete reasoning, and subsequent invalid actions, resulting in negative rewards. To counteract thought collapse, we highlight the necessity of process guidance and propose an automated corrector that evaluates and refines the agent's reasoning at each RL step. This simple and scalable GTR (Guided Thought Reinforcement) framework trains reasoning and action simultaneously without the need for dense, per-step human labeling. Our experiments demonstrate that GTR significantly enhances the performance and generalization of the LLaVA-7b model across various visual environments, achieving 3-5 times higher task success rates compared to SoTA models with notably smaller model sizes.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A taxonomy of epistemic injustice in the context of AI and the case for generative hermeneutical erasure</title>
<link>https://arxiv.org/abs/2504.07531</link>
<guid>https://arxiv.org/abs/2504.07531</guid>
<content:encoded><![CDATA[
arXiv:2504.07531v2 Announce Type: replace 
Abstract: Epistemic injustice related to AI is a growing concern. In relation to machine learning models, epistemic injustice can have a diverse range of sources, ranging from epistemic opacity, the discriminatory automation of testimonial prejudice, and the distortion of human beliefs via generative AI's hallucinations to the exclusion of the global South in global AI governance, the execution of bureaucratic violence via algorithmic systems, and interactions with conversational artificial agents. Based on a proposed general taxonomy of epistemic injustice, this paper first sketches a taxonomy of the types of epistemic injustice in the context of AI, relying on the work of scholars from the fields of philosophy of technology, political philosophy and social epistemology. Secondly, an additional conceptualization on epistemic injustice in the context of AI is provided: generative hermeneutical erasure. I argue that this injustice the automation of 'epistemicide', the injustice done to epistemic agents in their capacity for collective sense-making through the suppression of difference in epistemology and conceptualization by LLMs. AI systems' 'view from nowhere' epistemically inferiorizes non-Western epistemologies and thereby contributes to the erosion of their epistemic particulars, gradually contributing to hermeneutical erasure. This work's relevance lies in proposal of a taxonomy that allows epistemic injustices to be mapped in the AI domain and the proposal of a novel form of AI-related epistemic injustice.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Boundary-Guided Trajectory Prediction for Road Aware and Physically Feasible Autonomous Driving</title>
<link>https://arxiv.org/abs/2505.06740</link>
<guid>https://arxiv.org/abs/2505.06740</guid>
<content:encoded><![CDATA[
arXiv:2505.06740v2 Announce Type: replace 
Abstract: Accurate prediction of surrounding road users' trajectories is essential for safe and efficient autonomous driving. While deep learning models have improved performance, challenges remain in preventing off-road predictions and ensuring kinematic feasibility. Existing methods incorporate road-awareness modules and enforce kinematic constraints but lack plausibility guarantees and often introduce trade-offs in complexity and flexibility. This paper proposes a novel framework that formulates trajectory prediction as a constrained regression guided by permissible driving directions and their boundaries. Using the agent's current state and an HD map, our approach defines the valid boundaries and ensures on-road predictions by training the network to learn superimposed paths between left and right boundary polylines. To guarantee feasibility, the model predicts acceleration profiles that determine the vehicle's travel distance along these paths while adhering to kinematic constraints. We evaluate our approach on the Argoverse-2 dataset against the HPTR baseline. Our approach shows a slight decrease in benchmark metrics compared to HPTR but notably improves final displacement error and eliminates infeasible trajectories. Moreover, the proposed approach has superior generalization to less prevalent maneuvers and unseen out-of-distribution scenarios, reducing the off-road rate under adversarial attacks from 66% to just 1%. These results highlight the effectiveness of our approach in generating feasible and robust predictions.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TPK: Trustworthy Trajectory Prediction Integrating Prior Knowledge For Interpretability and Kinematic Feasibility</title>
<link>https://arxiv.org/abs/2505.06743</link>
<guid>https://arxiv.org/abs/2505.06743</guid>
<content:encoded><![CDATA[
arXiv:2505.06743v2 Announce Type: replace 
Abstract: Trajectory prediction is crucial for autonomous driving, enabling vehicles to navigate safely by anticipating the movements of surrounding road users. However, current deep learning models often lack trustworthiness as their predictions can be physically infeasible and illogical to humans. To make predictions more trustworthy, recent research has incorporated prior knowledge, like the social force model for modeling interactions and kinematic models for physical realism. However, these approaches focus on priors that suit either vehicles or pedestrians and do not generalize to traffic with mixed agent classes. We propose incorporating interaction and kinematic priors of all agent classes--vehicles, pedestrians, and cyclists with class-specific interaction layers to capture agent behavioral differences. To improve the interpretability of the agent interactions, we introduce DG-SFM, a rule-based interaction importance score that guides the interaction layer. To ensure physically feasible predictions, we proposed suitable kinematic models for all agent classes with a novel pedestrian kinematic model. We benchmark our approach on the Argoverse 2 dataset, using the state-of-the-art transformer HPTR as our baseline. Experiments demonstrate that our method improves interaction interpretability, revealing a correlation between incorrect predictions and divergence from our interaction prior. Even though incorporating the kinematic models causes a slight decrease in accuracy, they eliminate infeasible trajectories found in the dataset and the baseline model. Thus, our approach fosters trust in trajectory prediction as its interaction reasoning is interpretable, and its predictions adhere to physics.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automatic Curriculum Learning for Driving Scenarios: Towards Robust and Efficient Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.08264</link>
<guid>https://arxiv.org/abs/2505.08264</guid>
<content:encoded><![CDATA[
arXiv:2505.08264v2 Announce Type: replace 
Abstract: This paper addresses the challenges of training end-to-end autonomous driving agents using Reinforcement Learning (RL). RL agents are typically trained in a fixed set of scenarios and nominal behavior of surrounding road users in simulations, limiting their generalization and real-life deployment. While domain randomization offers a potential solution by randomly sampling driving scenarios, it frequently results in inefficient training and sub-optimal policies due to the high variance among training scenarios. To address these limitations, we propose an automatic curriculum learning framework that dynamically generates driving scenarios with adaptive complexity based on the agent's evolving capabilities. Unlike manually designed curricula that introduce expert bias and lack scalability, our framework incorporates a ``teacher'' that automatically generates and mutates driving scenarios based on their learning potential -- an agent-centric metric derived from the agent's current policy -- eliminating the need for expert design. The framework enhances training efficiency by excluding scenarios the agent has mastered or finds too challenging. We evaluate our framework in a reinforcement learning setting where the agent learns a driving policy from camera images. Comparative results against baseline methods, including fixed scenario training and domain randomization, demonstrate that our approach leads to enhanced generalization, achieving higher success rates: +9% in low traffic density, +21% in high traffic density, and faster convergence with fewer training steps. Our findings highlight the potential of ACL in improving the robustness and efficiency of RL-based autonomous driving agents.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Outlook on the Opportunities and Challenges of Multi-Agent AI Systems</title>
<link>https://arxiv.org/abs/2505.18397</link>
<guid>https://arxiv.org/abs/2505.18397</guid>
<content:encoded><![CDATA[
arXiv:2505.18397v2 Announce Type: replace 
Abstract: A multi-agent AI system (MAS) is composed of multiple autonomous agents that interact, exchange information, and make decisions based on internal generative models. Recent advances in large language models and tool-using agents have made MAS increasingly practical in areas like scientific discovery and collaborative automation. However, key questions remain: When are MAS more effective than single-agent systems? What new safety risks arise from agent interactions? And how should we evaluate their reliability and structure? This paper outlines a formal framework for analyzing MAS, focusing on two core aspects: effectiveness and safety. We explore whether MAS truly improve robustness, adaptability, and performance, or merely repackage known techniques like ensemble learning. We also study how inter-agent dynamics may amplify or suppress system vulnerabilities. While MAS are relatively new to the signal processing community, we envision them as a powerful abstraction that extends classical tools like distributed estimation and sensor fusion to higher-level, policy-driven inference. Through experiments on data science automation, we highlight the potential of MAS to reshape how signal processing systems are designed and trusted.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Upgrade or Switch: Do We Need a Next-Gen Trusted Architecture for the Internet of AI Agents?</title>
<link>https://arxiv.org/abs/2506.12003</link>
<guid>https://arxiv.org/abs/2506.12003</guid>
<content:encoded><![CDATA[
arXiv:2506.12003v2 Announce Type: replace 
Abstract: The emerging Internet of AI Agents challenges existing web infrastructure designed for human-scale, reactive interactions. Unlike traditional web resources, autonomous AI agents initiate actions, maintain persistent state, spawn sub-agents, and negotiate directly with peers: demanding millisecond-level discovery, instant credential revocation, and cryptographic behavioral proofs that exceed current DNS/PKI capabilities. This paper analyzes whether to upgrade existing infrastructure or implement purpose-built index architectures for autonomous agents. We identify critical failure points: DNS propagation (24-48 hours vs. required milliseconds), certificate revocation unable to scale to trillions of entities, and IPv4/IPv6 addressing inadequate for agent-scale routing. We evaluate three approaches: (1) Upgrade paths, (2) Switch options, (3) Hybrid index/registries. Drawing parallels to dialup-to-broadband transitions, we find that agent requirements constitute qualitative, and not incremental, changes. While upgrades offer compatibility and faster deployment, clean-slate solutions provide better performance but require longer for adoption. Our analysis suggests hybrid approaches will emerge, with centralized indexes for critical agents and federated meshes for specialized use cases.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AGENTSAFE: Benchmarking the Safety of Embodied Agents on Hazardous Instructions</title>
<link>https://arxiv.org/abs/2506.14697</link>
<guid>https://arxiv.org/abs/2506.14697</guid>
<content:encoded><![CDATA[
arXiv:2506.14697v2 Announce Type: replace 
Abstract: The rapid advancement of vision-language models (VLMs) and their integration into embodied agents have unlocked powerful capabilities for decision-making. However, as these systems are increasingly deployed in real-world environments, they face mounting safety concerns, particularly when responding to hazardous instructions. In this work, we propose AGENTSAFE, the first comprehensive benchmark for evaluating the safety of embodied VLM agents under hazardous instructions. AGENTSAFE simulates realistic agent-environment interactions within a simulation sandbox and incorporates a novel adapter module that bridges the gap between high-level VLM outputs and low-level embodied controls. Specifically, it maps recognized visual entities to manipulable objects and translates abstract planning into executable atomic actions in the environment. Building on this, we construct a risk-aware instruction dataset inspired by Asimovs Three Laws of Robotics, including base risky instructions and mutated jailbroken instructions. The benchmark includes 45 adversarial scenarios, 1,350 hazardous tasks, and 8,100 hazardous instructions, enabling systematic testing under adversarial conditions ranging from perception, planning, and action execution stages.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Individual and Collective Welfare in Risk Sharing with Many States</title>
<link>https://arxiv.org/abs/2401.07337</link>
<guid>https://arxiv.org/abs/2401.07337</guid>
<content:encoded><![CDATA[
arXiv:2401.07337v4 Announce Type: replace-cross 
Abstract: We study efficient risk sharing among risk-averse agents in an economy with a large, finite number of states. Following a random shock to an initial agreement, agents may renegotiate. If they require a minimal utility improvement to accept a new deal, we show the probability of finding a mutually acceptable allocation vanishes exponentially as the state space grows. This holds regardless of agents' degree of risk aversion. In a two-agent multiple-priors model, we find that the potential for Pareto-improving trade requires that at least one agent's set of priors has a vanishingly small measure. Our results hinge on the ``shape does not matter'' message of high-dimensional isoperimetric inequalities.
]]></content:encoded>
<pubDate>Mon, 14 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Autonomous Control Leveraging LLMs: An Agentic Framework for Next-Generation Industrial Automation</title>
<link>https://arxiv.org/abs/2507.07115</link>
<guid>https://arxiv.org/abs/2507.07115</guid>
<content:encoded><![CDATA[
arXiv:2507.07115v1 Announce Type: new 
Abstract: The increasing complexity of modern chemical processes, coupled with workforce shortages and intricate fault scenarios, demands novel automation paradigms that blend symbolic reasoning with adaptive control. In this work, we introduce a unified agentic framework that leverages large language models (LLMs) for both discrete fault-recovery planning and continuous process control within a single architecture. We adopt Finite State Machines (FSMs) as interpretable operating envelopes: an LLM-driven planning agent proposes recovery sequences through the FSM, a Simulation Agent executes and checks each transition, and a Validator-Reprompting loop iteratively refines invalid plans. In Case Study 1, across 180 randomly generated FSMs of varying sizes (4-25 states, 4-300 transitions), GPT-4o and GPT-4o-mini achieve 100% valid-path success within five reprompts-outperforming open-source LLMs in both accuracy and latency. In Case Study 2, the same framework modulates dual-heater inputs on a laboratory TCLab platform (and its digital twin) to maintain a target average temperature under persistent asymmetric disturbances. Compared to classical PID control, our LLM-based controller attains similar performance, while ablation of the prompting loop reveals its critical role in handling nonlinear dynamics. We analyze key failure modes-such as instruction following lapses and coarse ODE approximations. Our results demonstrate that, with structured feedback and modular agents, LLMs can unify high-level symbolic planningand low-level continuous control, paving the way towards resilient, language-driven automation in chemical engineering.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Combining Pre-Trained Models for Enhanced Feature Representation in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.07197</link>
<guid>https://arxiv.org/abs/2507.07197</guid>
<content:encoded><![CDATA[
arXiv:2507.07197v1 Announce Type: new 
Abstract: The recent focus and release of pre-trained models have been a key components to several advancements in many fields (e.g. Natural Language Processing and Computer Vision), as a matter of fact, pre-trained models learn disparate latent embeddings sharing insightful representations. On the other hand, Reinforcement Learning (RL) focuses on maximizing the cumulative reward obtained via agent's interaction with the environment. RL agents do not have any prior knowledge about the world, and they either learn from scratch an end-to-end mapping between the observation and action spaces or, in more recent works, are paired with monolithic and computationally expensive Foundational Models. How to effectively combine and leverage the hidden information of different pre-trained models simultaneously in RL is still an open and understudied question. In this work, we propose Weight Sharing Attention (WSA), a new architecture to combine embeddings of multiple pre-trained models to shape an enriched state representation, balancing the tradeoff between efficiency and performance. We run an extensive comparison between several combination modes showing that WSA obtains comparable performance on multiple Atari games compared to end-to-end models. Furthermore, we study the generalization capabilities of this approach and analyze how scaling the number of models influences agents' performance during and after training.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Open Source Planning &amp; Control System with Language Agents for Autonomous Scientific Discovery</title>
<link>https://arxiv.org/abs/2507.07257</link>
<guid>https://arxiv.org/abs/2507.07257</guid>
<content:encoded><![CDATA[
arXiv:2507.07257v1 Announce Type: new 
Abstract: We present a multi-agent system for automation of scientific research tasks, cmbagent. The system is formed by about 30 Large Language Model (LLM) agents and implements a Planning & Control strategy to orchestrate the agentic workflow, with no human-in-the-loop at any point. Each agent specializes in a different task (performing retrieval on scientific papers and codebases, writing code, interpreting results, critiquing the output of other agents) and the system is able to execute code locally. We successfully apply cmbagent to carry out a PhD level cosmology task (the measurement of cosmological parameters using supernova data) and evaluate its performance on two benchmark sets, finding superior performance over state-of-the-art LLMs. The source code is available on GitHub, demonstration videos are also available, and the system is deployed on HuggingFace and will be available on the cloud.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Impact of Background Speech on Interruption Detection in Collaborative Groups</title>
<link>https://arxiv.org/abs/2507.07280</link>
<guid>https://arxiv.org/abs/2507.07280</guid>
<content:encoded><![CDATA[
arXiv:2507.07280v1 Announce Type: new 
Abstract: Interruption plays a crucial role in collaborative learning, shaping group interactions and influencing knowledge construction. AI-driven support can assist teachers in monitoring these interactions. However, most previous work on interruption detection and interpretation has been conducted in single-conversation environments with relatively clean audio. AI agents deployed in classrooms for collaborative learning within small groups will need to contend with multiple concurrent conversations -- in this context, overlapping speech will be ubiquitous, and interruptions will need to be identified in other ways. In this work, we analyze interruption detection in single-conversation and multi-group dialogue settings. We then create a state-of-the-art method for interruption identification that is robust to overlapping speech, and thus could be deployed in classrooms. Further, our work highlights meaningful linguistic and prosodic information about how interruptions manifest in collaborative group interactions. Our investigation also paves the way for future works to account for the influence of overlapping speech from multiple groups when tracking group dialog.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LangNavBench: Evaluation of Natural Language Understanding in Semantic Navigation</title>
<link>https://arxiv.org/abs/2507.07299</link>
<guid>https://arxiv.org/abs/2507.07299</guid>
<content:encoded><![CDATA[
arXiv:2507.07299v1 Announce Type: new 
Abstract: Recent progress in large vision-language models has driven improvements in language-based semantic navigation, where an embodied agent must reach a target object described in natural language. Despite these advances, we still lack a clear, language-focused benchmark for testing how well such agents ground the words in their instructions. We address this gap with LangNav, an open-set dataset specifically created to test an agent's ability to locate objects described at different levels of detail, from broad category names to fine attributes and object-object relations. Every description in LangNav was manually checked, yielding a lower error rate than existing lifelong- and semantic-navigation datasets. On top of LangNav we build LangNavBench, a benchmark that measures how well current semantic-navigation methods understand and act on these descriptions while moving toward their targets. LangNavBench allows us to systematically compare models on their handling of attributes, spatial and relational cues, and category hierarchies, offering the first thorough, language-centric evaluation of embodied navigation systems. We also present Multi-Layered Feature Map (MLFM), a method that builds a queryable multi-layered semantic map, particularly effective when dealing with small objects or instructions involving spatial relations. MLFM outperforms state-of-the-art mapping-based navigation baselines on the LangNav dataset.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Application of LLMs to Multi-Robot Path Planning and Task Allocation</title>
<link>https://arxiv.org/abs/2507.07302</link>
<guid>https://arxiv.org/abs/2507.07302</guid>
<content:encoded><![CDATA[
arXiv:2507.07302v1 Announce Type: new 
Abstract: Efficient exploration is a well known problem in deep reinforcement learning and this problem is exacerbated in multi-agent reinforcement learning due the intrinsic complexities of such algorithms. There are several approaches to efficiently explore an environment to learn to solve tasks by multi-agent operating in that environment, of which, the idea of expert exploration is investigated in this work. More specifically, this work investigates the application of large-language models as expert planners for efficient exploration in planning based tasks for multiple agents.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ViDove: A Translation Agent System with Multimodal Context and Memory-Augmented Reasoning</title>
<link>https://arxiv.org/abs/2507.07306</link>
<guid>https://arxiv.org/abs/2507.07306</guid>
<content:encoded><![CDATA[
arXiv:2507.07306v1 Announce Type: new 
Abstract: LLM-based translation agents have achieved highly human-like translation results and are capable of handling longer and more complex contexts with greater efficiency. However, they are typically limited to text-only inputs. In this paper, we introduce ViDove, a translation agent system designed for multimodal input. Inspired by the workflow of human translators, ViDove leverages visual and contextual background information to enhance the translation process. Additionally, we integrate a multimodal memory system and long-short term memory modules enriched with domain-specific knowledge, enabling the agent to perform more accurately and adaptively in real-world scenarios. As a result, ViDove achieves significantly higher translation quality in both subtitle generation and general translation tasks, with a 28% improvement in BLEU scores and a 15% improvement in SubER compared to previous state-of-the-art baselines. Moreover, we introduce DoveBench, a new benchmark for long-form automatic video subtitling and translation, featuring 17 hours of high-quality, human-annotated data. Our code is available here: https://github.com/pigeonai-org/ViDove
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Retrieval-Augmented Framework for Evidence-Based Counterspeech Against Health Misinformation</title>
<link>https://arxiv.org/abs/2507.07307</link>
<guid>https://arxiv.org/abs/2507.07307</guid>
<content:encoded><![CDATA[
arXiv:2507.07307v1 Announce Type: new 
Abstract: Large language models (LLMs) incorporated with Retrieval-Augmented Generation (RAG) have demonstrated powerful capabilities in generating counterspeech against misinformation. However, current studies rely on limited evidence and offer less control over final outputs. To address these challenges, we propose a Multi-agent Retrieval-Augmented Framework to generate counterspeech against health misinformation, incorporating multiple LLMs to optimize knowledge retrieval, evidence enhancement, and response refinement. Our approach integrates both static and dynamic evidence, ensuring that the generated counterspeech is relevant, well-grounded, and up-to-date. Our method outperforms baseline approaches in politeness, relevance, informativeness, and factual accuracy, demonstrating its effectiveness in generating high-quality counterspeech. To further validate our approach, we conduct ablation studies to verify the necessity of each component in our framework. Furthermore, human evaluations reveal that refinement significantly enhances counterspeech quality and obtains human preference.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Communication and Device Clustering for Clustered Federated Learning with Differential Privacy</title>
<link>https://arxiv.org/abs/2507.07320</link>
<guid>https://arxiv.org/abs/2507.07320</guid>
<content:encoded><![CDATA[
arXiv:2507.07320v1 Announce Type: new 
Abstract: In this paper, a secure and communication-efficient clustered federated learning (CFL) design is proposed. In our model, several base stations (BSs) with heterogeneous task-handling capabilities and multiple users with non-independent and identically distributed (non-IID) data jointly perform CFL training incorporating differential privacy (DP) techniques. Since each BS can process only a subset of the learning tasks and has limited wireless resource blocks (RBs) to allocate to users for federated learning (FL) model parameter transmission, it is necessary to jointly optimize RB allocation and user scheduling for CFL performance optimization. Meanwhile, our considered CFL method requires devices to use their limited data and FL model information to determine their task identities, which may introduce additional communication overhead. We formulate an optimization problem whose goal is to minimize the training loss of all learning tasks while considering device clustering, RB allocation, DP noise, and FL model transmission delay. To solve the problem, we propose a novel dynamic penalty function assisted value decomposed multi-agent reinforcement learning (DPVD-MARL) algorithm that enables distributed BSs to independently determine their connected users, RBs, and DP noise of the connected users but jointly minimize the training loss of all learning tasks across all BSs. Different from the existing MARL methods that assign a large penalty for invalid actions, we propose a novel penalty assignment scheme that assigns penalty depending on the number of devices that cannot meet communication constraints (e.g., delay), which can guide the MARL scheme to quickly find valid actions, thus improving the convergence speed. Simulation results show that the DPVD-MARL can improve the convergence rate by up to 20% and the ultimate accumulated rewards by 15% compared to independent Q-learning.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Model Splitting and Device Task Assignment for Deceptive Signal Assisted Private Multi-hop Split Learning</title>
<link>https://arxiv.org/abs/2507.07323</link>
<guid>https://arxiv.org/abs/2507.07323</guid>
<content:encoded><![CDATA[
arXiv:2507.07323v1 Announce Type: new 
Abstract: In this paper, deceptive signal-assisted private split learning is investigated. In our model, several edge devices jointly perform collaborative training, and some eavesdroppers aim to collect the model and data information from devices. To prevent the eavesdroppers from collecting model and data information, a subset of devices can transmit deceptive signals. Therefore, it is necessary to determine the subset of devices used for deceptive signal transmission, the subset of model training devices, and the models assigned to each model training device. This problem is formulated as an optimization problem whose goal is to minimize the information leaked to eavesdroppers while meeting the model training energy consumption and delay constraints. To solve this problem, we propose a soft actor-critic deep reinforcement learning framework with intrinsic curiosity module and cross-attention (ICM-CA) that enables a centralized agent to determine the model training devices, the deceptive signal transmission devices, the transmit power, and sub-models assigned to each model training device without knowing the position and monitoring probability of eavesdroppers. The proposed method uses an ICM module to encourage the server to explore novel actions and states and a CA module to determine the importance of each historical state-action pair thus improving training efficiency. Simulation results demonstrate that the proposed method improves the convergence rate by up to 3x and reduces the information leaked to eavesdroppers by up to 13% compared to the traditional SAC algorithm.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FLoRA: An Advanced AI-Powered Engine to Facilitate Hybrid Human-AI Regulated Learning</title>
<link>https://arxiv.org/abs/2507.07362</link>
<guid>https://arxiv.org/abs/2507.07362</guid>
<content:encoded><![CDATA[
arXiv:2507.07362v1 Announce Type: new 
Abstract: SRL, defined as learners' ability to systematically plan, monitor, and regulate their learning activities, is crucial for sustained academic achievement and lifelong learning competencies. Emerging Artificial Intelligence (AI) developments profoundly influence SRL interactions by potentially either diminishing or strengthening learners' opportunities to exercise their own regulatory skills. Recent literature emphasizes a balanced approach termed Hybrid Human-AI Regulated Learning (HHAIRL), in which AI provides targeted, timely scaffolding while preserving the learners' role as active decision-makers and reflective monitors of their learning process. Nevertheless, existing digital tools frequently fall short, lacking adaptability, focusing narrowly on isolated SRL phases, and insufficiently support meaningful human-AI interactions. In response, this paper introduces the enhanced \flora Engine, which incorporates advanced Generative Artificial Intelligence (GenAI) features and state-of-the-art learning analytics, explicitly grounded in SRL and HHAIRL theories. The \flora Engine offers instrumentation tools such as collaborative writing, multi-agents chatbot, and detailed learning trace logging to support dynamic, adaptive scaffolding tailored to individual needs in real time. We further present a summary of several research studies that provide the validations for and illustrate how these instrumentation tools can be utilized in real-world educational and experimental contexts. These studies demonstrate the effectiveness of \flora Engine in fostering SRL and HHAIRL, providing both theoretical insights and practical solutions for the future of AI-enhanced learning context.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PILOC: A Pheromone Inverse Guidance Mechanism and Local-Communication Framework for Dynamic Target Search of Multi-Agent in Unknown Environments</title>
<link>https://arxiv.org/abs/2507.07376</link>
<guid>https://arxiv.org/abs/2507.07376</guid>
<content:encoded><![CDATA[
arXiv:2507.07376v1 Announce Type: new 
Abstract: Multi-Agent Search and Rescue (MASAR) plays a vital role in disaster response, exploration, and reconnaissance. However, dynamic and unknown environments pose significant challenges due to target unpredictability and environmental uncertainty. To tackle these issues, we propose PILOC, a framework that operates without global prior knowledge, leveraging local perception and communication. It introduces a pheromone inverse guidance mechanism to enable efficient coordination and dynamic target localization. PILOC promotes decentralized cooperation through local communication, significantly reducing reliance on global channels. Unlike conventional heuristics, the pheromone mechanism is embedded into the observation space of Deep Reinforcement Learning (DRL), supporting indirect agent coordination based on environmental cues. We further integrate this strategy into a DRL-based multi-agent architecture and conduct extensive experiments. Results show that combining local communication with pheromone-based guidance significantly boosts search efficiency, adaptability, and system robustness. Compared to existing methods, PILOC performs better under dynamic and communication-constrained scenarios, offering promising directions for future MASAR applications.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>KVFlow: Efficient Prefix Caching for Accelerating LLM-Based Multi-Agent Workflows</title>
<link>https://arxiv.org/abs/2507.07400</link>
<guid>https://arxiv.org/abs/2507.07400</guid>
<content:encoded><![CDATA[
arXiv:2507.07400v1 Announce Type: new 
Abstract: Large language model (LLM) based agentic workflows have become a popular paradigm for coordinating multiple specialized agents to solve complex tasks. To improve serving efficiency, existing LLM systems employ prefix caching to reuse key-value (KV) tensors corresponding to agents' fixed prompts, thereby avoiding redundant computation across repeated invocations. However, current systems typically evict KV caches using a Least Recently Used (LRU) policy, which fails to anticipate future agent usage and often discards KV caches shortly before their reuse. This leads to frequent cache misses and substantial recomputation or swapping overhead. We present KVFlow, a workflow-aware KV cache management framework tailored for agentic workloads. KVFlow abstracts the agent execution schedule as an Agent Step Graph and assigns each agent a steps-to-execution value that estimates its temporal proximity to future activation. These values guide a fine-grained eviction policy at the KV node level, allowing KVFlow to preserve entries likely to be reused and efficiently manage shared prefixes in tree-structured caches. Moreover, KVFlow introduces a fully overlapped KV prefetching mechanism, which proactively loads required tensors from CPU to GPU in background threads for agents scheduled in the next step, thereby avoiding cache miss stalls during generation. Compared to SGLang with hierarchical radix cache, KVFlow achieves up to 1.83$\times$ speedup for single workflows with large prompts, and up to 2.19$\times$ speedup for scenarios with many concurrent workflows.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DrugMCTS: a drug repurposing framework combining multi-agent, RAG and Monte Carlo Tree Search</title>
<link>https://arxiv.org/abs/2507.07426</link>
<guid>https://arxiv.org/abs/2507.07426</guid>
<content:encoded><![CDATA[
arXiv:2507.07426v1 Announce Type: new 
Abstract: Recent advances in large language models have demonstrated considerable potential in scientific domains such as drug discovery. However, their effectiveness remains constrained when reasoning extends beyond the knowledge acquired during pretraining. Conventional approaches, such as fine-tuning or retrieval-augmented generation, face limitations in either imposing high computational overhead or failing to fully exploit structured scientific data. To overcome these challenges, we propose DrugMCTS, a novel framework that synergistically integrates RAG, multi-agent collaboration, and Monte Carlo Tree Search for drug repurposing. The framework employs five specialized agents tasked with retrieving and analyzing molecular and protein information, thereby enabling structured and iterative reasoning. Without requiring domain-specific fine-tuning, DrugMCTS empowers Qwen2.5-7B-Instruct to outperform Deepseek-R1 by over 20\%. Extensive experiments on the DrugBank and KIBA datasets demonstrate that DrugMCTS achieves substantially higher recall and robustness compared to both general-purpose LLMs and deep learning baselines. Our results highlight the importance of structured reasoning, agent-based collaboration, and feedback-driven search mechanisms in advancing LLM applications for drug discovery.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SAND: Boosting LLM Agents with Self-Taught Action Deliberation</title>
<link>https://arxiv.org/abs/2507.07441</link>
<guid>https://arxiv.org/abs/2507.07441</guid>
<content:encoded><![CDATA[
arXiv:2507.07441v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents are commonly tuned with supervised finetuning on ReAct-style expert trajectories or preference optimization over pairwise rollouts. Most of these methods focus on imitating specific expert behaviors or promoting chosen reasoning thoughts and actions over rejected ones. However, without reasoning and comparing over alternatives actions, LLM agents finetuned with these methods may over-commit towards seemingly plausible but suboptimal actions due to limited action space exploration. To address this, in this paper we propose Self-taught ActioN Deliberation (SAND) framework, enabling LLM agents to explicitly deliberate over candidate actions before committing to one. To tackle the challenges of when and what to deliberate given large action space and step-level action evaluation, we incorporate self-consistency action sampling and execution-guided action critique to help synthesize step-wise action deliberation thoughts using the base model of the LLM agent. In an iterative manner, the deliberation trajectories are then used to finetune the LLM agent itself. Evaluating on two representative interactive agent tasks, SAND achieves an average 20% improvement over initial supervised finetuning and also outperforms state-of-the-art agent tuning approaches.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StarDojo: Benchmarking Open-Ended Behaviors of Agentic Multimodal LLMs in Production-Living Simulations with Stardew Valley</title>
<link>https://arxiv.org/abs/2507.07445</link>
<guid>https://arxiv.org/abs/2507.07445</guid>
<content:encoded><![CDATA[
arXiv:2507.07445v1 Announce Type: new 
Abstract: Autonomous agents navigating human society must master both production activities and social interactions, yet existing benchmarks rarely evaluate these skills simultaneously. To bridge this gap, we introduce StarDojo, a novel benchmark based on Stardew Valley, designed to assess AI agents in open-ended production-living simulations. In StarDojo, agents are tasked to perform essential livelihood activities such as farming and crafting, while simultaneously engaging in social interactions to establish relationships within a vibrant community. StarDojo features 1,000 meticulously curated tasks across five key domains: farming, crafting, exploration, combat, and social interactions. Additionally, we provide a compact subset of 100 representative tasks for efficient model evaluation. The benchmark offers a unified, user-friendly interface that eliminates the need for keyboard and mouse control, supports all major operating systems, and enables the parallel execution of multiple environment instances, making it particularly well-suited for evaluating the most capable foundation agents, powered by multimodal large language models (MLLMs). Extensive evaluations of state-of-the-art MLLMs agents demonstrate substantial limitations, with the best-performing model, GPT-4.1, achieving only a 12.7% success rate, primarily due to challenges in visual understanding, multimodal reasoning and low-level manipulation. As a user-friendly environment and benchmark, StarDojo aims to facilitate further research towards robust, open-ended agents in complex production-living environments.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hallucination Stations: On Some Basic Limitations of Transformer-Based Language Models</title>
<link>https://arxiv.org/abs/2507.07505</link>
<guid>https://arxiv.org/abs/2507.07505</guid>
<content:encoded><![CDATA[
arXiv:2507.07505v1 Announce Type: new 
Abstract: With widespread adoption of transformer-based language models in AI, there is significant interest in the limits of LLMs capabilities, specifically so-called hallucinations, occurrences in which LLMs provide spurious, factually incorrect or nonsensical information when prompted on certain subjects. Furthermore, there is growing interest in agentic uses of LLMs - that is, using LLMs to create agents that act autonomously or semi-autonomously to carry out various tasks, including tasks with applications in the real world. This makes it important to understand the types of tasks LLMs can and cannot perform. We explore this topic from the perspective of the computational complexity of LLM inference. We show that LLMs are incapable of carrying out computational and agentic tasks beyond a certain complexity, and further that LLMs are incapable of verifying the accuracy of tasks beyond a certain complexity. We present examples of both, then discuss some consequences of this work.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Pandora's Box Problem with Sequential Inspections</title>
<link>https://arxiv.org/abs/2507.07508</link>
<guid>https://arxiv.org/abs/2507.07508</guid>
<content:encoded><![CDATA[
arXiv:2507.07508v1 Announce Type: new 
Abstract: The Pandora's box problem (Weitzman 1979) is a core model in economic theory that captures an agent's (Pandora's) search for the best alternative (box). We study an important generalization of the problem where the agent can either fully open boxes for a certain fee to reveal their exact values or partially open them at a reduced cost. This introduces a new tradeoff between information acquisition and cost efficiency. We establish a hardness result and employ an array of techniques in stochastic optimization to provide a comprehensive analysis of this model. This includes (1) the identification of structural properties of the optimal policy that provide insights about optimal decisions; (2) the derivation of problem relaxations and provably near-optimal solutions; (3) the characterization of the optimal policy in special yet non-trivial cases; and (4) an extensive numerical study that compares the performance of various policies, and which provides additional insights about the optimal policy. Throughout, we show that intuitive threshold-based policies that extend the Pandora's box optimal solution can effectively guide search decisions.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Position: We Need An Algorithmic Understanding of Generative AI</title>
<link>https://arxiv.org/abs/2507.07544</link>
<guid>https://arxiv.org/abs/2507.07544</guid>
<content:encoded><![CDATA[
arXiv:2507.07544v1 Announce Type: new 
Abstract: What algorithms do LLMs actually learn and use to solve problems? Studies addressing this question are sparse, as research priorities are focused on improving performance through scale, leaving a theoretical and empirical gap in understanding emergent algorithms. This position paper proposes AlgEval: a framework for systematic research into the algorithms that LLMs learn and use. AlgEval aims to uncover algorithmic primitives, reflected in latent representations, attention, and inference-time compute, and their algorithmic composition to solve task-specific problems. We highlight potential methodological paths and a case study toward this goal, focusing on emergent search algorithms. Our case study illustrates both the formation of top-down hypotheses about candidate algorithms, and bottom-up tests of these hypotheses via circuit-level analysis of attention patterns and hidden states. The rigorous, systematic evaluation of how LLMs actually solve tasks provides an alternative to resource-intensive scaling, reorienting the field toward a principled understanding of underlying computations. Such algorithmic explanations offer a pathway to human-understandable interpretability, enabling comprehension of the model's internal reasoning performance measures. This can in turn lead to more sample-efficient methods for training and improving performance, as well as novel architectures for end-to-end and multi-agent systems.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Connectivity: Higher-Order Network Framework for Capturing Memory-Driven Mobility Dynamics</title>
<link>https://arxiv.org/abs/2507.07727</link>
<guid>https://arxiv.org/abs/2507.07727</guid>
<content:encoded><![CDATA[
arXiv:2507.07727v1 Announce Type: new 
Abstract: Understanding and predicting mobility dynamics in transportation networks is critical for infrastructure planning, resilience analysis, and traffic management. Traditional graph-based models typically assume memoryless movement, limiting their ability to capture sequential dependencies inherent in real-world mobility patterns. In this study, we introduce a novel higher-order network framework for modeling memory-dependent dynamics in transportation systems. By extending classical graph representations through higher-order Markov chains and de Bruijn graph structures, our framework encodes the spatial and temporal ordering of traversed paths, enabling the analysis of structurally and functionally critical components with improved fidelity. We generalize key network analytics, including betweenness centrality, PageRank, and next-step prediction, to this higher-order setting and validate our approach on the Sioux Falls transportation network using agent-based trajectory data generated with MATSim. Experimental results demonstrate that higher-order models outperform first-order baselines across multiple tasks, with the third-order model achieving an optimal balance between predictive accuracy and model complexity. These findings highlight the importance of incorporating memory effects into network-based transportation analysis and offer a scalable, data-driven methodology for capturing complex mobility behaviors in infrastructure systems.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BEAVER: Building Environments with Assessable Variation for Evaluating Multi-Objective Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.07769</link>
<guid>https://arxiv.org/abs/2507.07769</guid>
<content:encoded><![CDATA[
arXiv:2507.07769v1 Announce Type: new 
Abstract: Recent years have seen significant advancements in designing reinforcement learning (RL)-based agents for building energy management. While individual success is observed in simulated or controlled environments, the scalability of RL approaches in terms of efficiency and generalization across building dynamics and operational scenarios remains an open question. In this work, we formally characterize the generalization space for the cross-environment, multi-objective building energy management task, and formulate the multi-objective contextual RL problem. Such a formulation helps understand the challenges of transferring learned policies across varied operational contexts such as climate and heat convection dynamics under multiple control objectives such as comfort level and energy consumption. We provide a principled way to parameterize such contextual information in realistic building RL environments, and construct a novel benchmark to facilitate the evaluation of generalizable RL algorithms in practical building control tasks. Our results show that existing multi-objective RL methods are capable of achieving reasonable trade-offs between conflicting objectives. However, their performance degrades under certain environment variations, underscoring the importance of incorporating dynamics-dependent contextual information into the policy learning process.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Perceptual Distortions and Autonomous Representation Learning in a Minimal Robotic System</title>
<link>https://arxiv.org/abs/2507.07845</link>
<guid>https://arxiv.org/abs/2507.07845</guid>
<content:encoded><![CDATA[
arXiv:2507.07845v1 Announce Type: new 
Abstract: Autonomous agents, particularly in the field of robotics, rely on sensory information to perceive and navigate their environment. However, these sensory inputs are often imperfect, leading to distortions in the agent's internal representation of the world. This paper investigates the nature of these perceptual distortions and how they influence autonomous representation learning using a minimal robotic system. We utilize a simulated two-wheeled robot equipped with distance sensors and a compass, operating within a simple square environment. Through analysis of the robot's sensor data during random exploration, we demonstrate how a distorted perceptual space emerges. Despite these distortions, we identify emergent structures within the perceptual space that correlate with the physical environment, revealing how the robot autonomously learns a structured representation for navigation without explicit spatial information. This work contributes to the understanding of embodied cognition, minimal agency, and the role of perception in self-generated navigation strategies in artificial life.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Trust Fabric: Decentralized Interoperability and Economic Coordination for the Agentic Web</title>
<link>https://arxiv.org/abs/2507.07901</link>
<guid>https://arxiv.org/abs/2507.07901</guid>
<content:encoded><![CDATA[
arXiv:2507.07901v1 Announce Type: new 
Abstract: The fragmentation of AI agent ecosystems has created urgent demands for interoperability, trust, and economic coordination that current protocols -- including MCP (Hou et al., 2025), A2A (Habler et al., 2025), ACP (Liu et al., 2025), and Cisco's AGP (Edwards, 2025) -- cannot address at scale. We present the Nanda Unified Architecture, a decentralized framework built around three core innovations: fast DID-based agent discovery through distributed registries, semantic agent cards with verifiable credentials and composability profiles, and a dynamic trust layer that integrates behavioral attestations with policy compliance. The system introduces X42/H42 micropayments for economic coordination and MAESTRO, a security framework incorporating Synergetics' patented AgentTalk protocol (US Patent 12,244,584 B1) and secure containerization. Real-world deployments demonstrate 99.9 percent compliance in healthcare applications and substantial monthly transaction volumes with strong privacy guarantees. By unifying MIT's trust research with production deployments from Cisco and Synergetics, we show how cryptographic proofs and policy-as-code transform agents into trust-anchored participants in a decentralized economy (Lakshmanan, 2025; Sha, 2025). The result enables a globally interoperable Internet of Agents where trust becomes the native currency of collaboration across both enterprise and Web3 ecosystems.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Retrieval of Topics and Insights from Earnings Calls</title>
<link>https://arxiv.org/abs/2507.07906</link>
<guid>https://arxiv.org/abs/2507.07906</guid>
<content:encoded><![CDATA[
arXiv:2507.07906v1 Announce Type: new 
Abstract: Tracking the strategic focus of companies through topics in their earnings calls is a key task in financial analysis. However, as industries evolve, traditional topic modeling techniques struggle to dynamically capture emerging topics and their relationships. In this work, we propose an LLM-agent driven approach to discover and retrieve emerging topics from quarterly earnings calls. We propose an LLM-agent to extract topics from documents, structure them into a hierarchical ontology, and establish relationships between new and existing topics through a topic ontology. We demonstrate the use of extracted topics to infer company-level insights and emerging trends over time. We evaluate our approach by measuring ontology coherence, topic evolution accuracy, and its ability to surface emerging financial trends.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MIRIX: Multi-Agent Memory System for LLM-Based Agents</title>
<link>https://arxiv.org/abs/2507.07957</link>
<guid>https://arxiv.org/abs/2507.07957</guid>
<content:encoded><![CDATA[
arXiv:2507.07957v1 Announce Type: new 
Abstract: Although memory capabilities of AI agents are gaining increasing attention, existing solutions remain fundamentally limited. Most rely on flat, narrowly scoped memory components, constraining their ability to personalize, abstract, and reliably recall user-specific information over time. To this end, we introduce MIRIX, a modular, multi-agent memory system that redefines the future of AI memory by solving the field's most critical challenge: enabling language models to truly remember. Unlike prior approaches, MIRIX transcends text to embrace rich visual and multimodal experiences, making memory genuinely useful in real-world scenarios. MIRIX consists of six distinct, carefully structured memory types: Core, Episodic, Semantic, Procedural, Resource Memory, and Knowledge Vault, coupled with a multi-agent framework that dynamically controls and coordinates updates and retrieval. This design enables agents to persist, reason over, and accurately retrieve diverse, long-term user data at scale. We validate MIRIX in two demanding settings. First, on ScreenshotVQA, a challenging multimodal benchmark comprising nearly 20,000 high-resolution computer screenshots per sequence, requiring deep contextual understanding and where no existing memory systems can be applied, MIRIX achieves 35% higher accuracy than the RAG baseline while reducing storage requirements by 99.9%. Second, on LOCOMO, a long-form conversation benchmark with single-modal textual input, MIRIX attains state-of-the-art performance of 85.4%, far surpassing existing baselines. These results show that MIRIX sets a new performance standard for memory-augmented LLM agents. To allow users to experience our memory system, we provide a packaged application powered by MIRIX. It monitors the screen in real time, builds a personalized memory base, and offers intuitive visualization and secure local storage to ensure privacy.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning with Action Chunking</title>
<link>https://arxiv.org/abs/2507.07969</link>
<guid>https://arxiv.org/abs/2507.07969</guid>
<content:encoded><![CDATA[
arXiv:2507.07969v1 Announce Type: new 
Abstract: We present Q-chunking, a simple yet effective recipe for improving reinforcement learning (RL) algorithms for long-horizon, sparse-reward tasks. Our recipe is designed for the offline-to-online RL setting, where the goal is to leverage an offline prior dataset to maximize the sample-efficiency of online learning. Effective exploration and sample-efficient learning remain central challenges in this setting, as it is not obvious how the offline data should be utilized to acquire a good exploratory policy. Our key insight is that action chunking, a technique popularized in imitation learning where sequences of future actions are predicted rather than a single action at each timestep, can be applied to temporal difference (TD)-based RL methods to mitigate the exploration challenge. Q-chunking adopts action chunking by directly running RL in a 'chunked' action space, enabling the agent to (1) leverage temporally consistent behaviors from offline data for more effective online exploration and (2) use unbiased $n$-step backups for more stable and efficient TD learning. Our experimental results demonstrate that Q-chunking exhibits strong offline performance and online sample efficiency, outperforming prior best offline-to-online methods on a range of long-horizon, sparse-reward manipulation tasks.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OST-Bench: Evaluating the Capabilities of MLLMs in Online Spatio-temporal Scene Understanding</title>
<link>https://arxiv.org/abs/2507.07984</link>
<guid>https://arxiv.org/abs/2507.07984</guid>
<content:encoded><![CDATA[
arXiv:2507.07984v1 Announce Type: new 
Abstract: Recent advances in multimodal large language models (MLLMs) have shown remarkable capabilities in integrating vision and language for complex reasoning. While most existing benchmarks evaluate models under offline settings with a fixed set of pre-recorded inputs, we introduce OST-Bench, a benchmark designed to evaluate Online Spatio-Temporal understanding from the perspective of an agent actively exploring a scene. The Online aspect emphasizes the need to process and reason over incrementally acquired observations, while the Spatio-Temporal component requires integrating current visual inputs with historical memory to support dynamic spatial reasoning. OST-Bench better reflects the challenges of real-world embodied perception. Built on an efficient data collection pipeline, OST-Bench consists of 1.4k scenes and 10k question-answer pairs collected from ScanNet, Matterport3D, and ARKitScenes. We evaluate several leading MLLMs on OST-Bench and observe that they fall short on tasks requiring complex spatio-temporal reasoning. Under the online setting, their accuracy declines as the exploration horizon extends and the memory grows. Through further experimental analysis, we identify common error patterns across models and find that both complex clue-based spatial reasoning demands and long-term memory retrieval requirements significantly drop model performance along two separate axes, highlighting the core challenges that must be addressed to improve online embodied reasoning. To foster further research and development in the field, our codes, dataset, and benchmark are available. Our project page is: https://rbler1234.github.io/OSTBench.github.io/
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PyVision: Agentic Vision with Dynamic Tooling</title>
<link>https://arxiv.org/abs/2507.07998</link>
<guid>https://arxiv.org/abs/2507.07998</guid>
<content:encoded><![CDATA[
arXiv:2507.07998v1 Announce Type: new 
Abstract: LLMs are increasingly deployed as agents, systems capable of planning, reasoning, and dynamically calling external tools. However, in visual reasoning, prior approaches largely remain limited by predefined workflows and static toolsets. In this report, we present PyVision, an interactive, multi-turn framework that enables MLLMs to autonomously generate, execute, and refine Python-based tools tailored to the task at hand, unlocking flexible and interpretable problem-solving. We develop a taxonomy of the tools created by PyVision and analyze their usage across a diverse set of benchmarks. Quantitatively, PyVision achieves consistent performance gains, boosting GPT-4.1 by +7.8% on V* and Claude-4.0-Sonnet by +31.1% on VLMsAreBlind-mini. These results point to a broader shift: dynamic tooling allows models not just to use tools, but to invent them, advancing toward more agentic visual reasoning.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust signal decompositions on the circle</title>
<link>https://arxiv.org/abs/2507.07007</link>
<guid>https://arxiv.org/abs/2507.07007</guid>
<content:encoded><![CDATA[
arXiv:2507.07007v1 Announce Type: cross 
Abstract: We consider the problem of decomposing a piecewise constant function on the circle into a sum of indicator functions of closed circular disks in the plane, whose number and location are not a priori known. This represents a situation where an agent moving on the circle is able to sense its proximity to some landmarks, and the goal is to estimate the number of these landmarks and their possible locations -- which can in turn enable control tasks such as motion planning and obstacle avoidance. Moreover, the exact values of the function at its discontinuities (which correspond to disk boundaries for the individual indicator functions) are not assumed to be known to the agent. We introduce suitable notions of robustness and degrees of freedom to single out those decompositions that are more desirable, or more likely, given this non-precise data collected by the agent. We provide a characterization of robust decompositions and give a procedure for generating all such decompositions. When the given function admits a robust decomposition, we compute the number of possible robust decompositions and derive bounds for the number of decompositions maximizing the degrees of freedom.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Retrieval-Augmented Generation Agents for Autonomous Scientific Discovery in Astrophysics</title>
<link>https://arxiv.org/abs/2507.07155</link>
<guid>https://arxiv.org/abs/2507.07155</guid>
<content:encoded><![CDATA[
arXiv:2507.07155v1 Announce Type: cross 
Abstract: We evaluate 9 Retrieval Augmented Generation (RAG) agent configurations on 105 Cosmology Question-Answer (QA) pairs that we built specifically for this purpose.The RAG configurations are manually evaluated by a human expert, that is, a total of 945 generated answers were assessed. We find that currently the best RAG agent configuration is with OpenAI embedding and generative model, yielding 91.4\% accuracy. Using our human evaluation results we calibrate LLM-as-a-Judge (LLMaaJ) system which can be used as a robust proxy for human evaluation. These results allow us to systematically select the best RAG agent configuration for multi-agent system for autonomous scientific discovery in astrophysics (e.g., cmbagent presented in a companion paper) and provide us with an LLMaaJ system that can be scaled to thousands of cosmology QA pairs. We make our QA dataset, human evaluation results, RAG pipelines, and LLMaaJ system publicly available for further use by the astrophysics community.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convergence and Robustness Bounds for Distributed Asynchronous Shortest-Path</title>
<link>https://arxiv.org/abs/2507.07263</link>
<guid>https://arxiv.org/abs/2507.07263</guid>
<content:encoded><![CDATA[
arXiv:2507.07263v1 Announce Type: cross 
Abstract: This work analyzes convergence times and robustness bounds for asynchronous distributed shortest-path computation. We focus on the Adaptive Bellman--Ford algorithm, a self-stabilizing method in which each agent updates its shortest-path estimate based only on the estimates of its neighbors and forgetting its previous estimate. In the asynchronous framework considered in this paper, agents are allowed to idle or encounter race conditions during their execution of the Adaptive Bellman--Ford algorithm. We build on Lyapunov-based results that develop finite-time convergence and robustness bounds for the synchronous shortest-path setting, in order to produce finite-time convergence and robustness bounds for the asynchronous setting. We also explore robustness against interval-bounded noise processes and establish convergence and robustness guarantees for asynchronous most-probable-path algorithms.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Search and Matching for Adoption from Foster Care</title>
<link>https://arxiv.org/abs/2103.10145</link>
<guid>https://arxiv.org/abs/2103.10145</guid>
<content:encoded><![CDATA[
arXiv:2103.10145v4 Announce Type: replace 
Abstract: To find families for the more than 100,000 children in need of adoptive placements, most United States child welfare agencies have employed a family-driven search approach in which prospective families respond to announcements made by the agency. However, some agencies have switched to a caseworker-driven search approach in which the caseworker directly contacts families recommended for a child. We introduce a novel search-and-matching model that captures the key features of the adoption process and compare family-driven with caseworker-driven search in a game-theoretical framework. Under either approach, the equilibria are generated by threshold strategies and form a lattice structure. Our main theoretical finding then shows that no family-driven equilibrium can Pareto dominate any caseworker-driven outcome, whereas it is possible that each caseworker-driven equilibrium Pareto dominates every equilibrium attainable under family-driven search. We also find that when families are sufficiently impatient, caseworker-driven search is better for all children. We illustrate numerically that most agents are better off under caseworker-driven search for a wide range of parameters. Finally, we provide empirical evidence from an agency that switched to caseworker-driven search and achieved a three-year adoption probability that outperformed a statewide benchmark by 24%, as well as a statistically significant 27% improvement in adoption hazard rates.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Random walk based snapshot clustering for detecting community dynamics in temporal networks</title>
<link>https://arxiv.org/abs/2412.12187</link>
<guid>https://arxiv.org/abs/2412.12187</guid>
<content:encoded><![CDATA[
arXiv:2412.12187v3 Announce Type: replace 
Abstract: The evolution of many dynamical systems that describe relationships or interactions between objects can be effectively modeled by temporal networks, which are typically represented as a sequence of static network snapshots. In this paper, we introduce a novel random walk-based approach that can identify clusters of time-snapshots in which network community structures are stable. This allows us to detect significant structural shifts over time, such as the splitting or merging of communities or their births and deaths. We also provide a low-dimensional representation of entire snapshots, placing those with similar community structure close to each other in the feature space. To validate our approach, we develop an agent-based algorithm that generates synthetic datasets with the desired characteristic properties, enabling thorough testing and benchmarking. We further demonstrate the effectiveness and broad applicability of our technique by testing it on various social dynamics models and real-world datasets and comparing its performance to several state-of-the-art algorithms. Our findings highlight the strength of our approach to correctly capture and analyze the dynamics of complex systems.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decoding AI Judgment: How LLMs Assess News Credibility and Bias</title>
<link>https://arxiv.org/abs/2502.04426</link>
<guid>https://arxiv.org/abs/2502.04426</guid>
<content:encoded><![CDATA[
arXiv:2502.04426v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) are increasingly embedded in workflows that involve evaluative processes. This raises the need to examine how such evaluations are built, what assumptions they rely on, and how their strategies diverge from those of humans. We benchmark six LLMs against expert ratings--NewsGuard and Media Bias/Fact Check (MBFC)--and against human judgments collected through a controlled experiment. To enable direct comparison, we implement a structured agentic framework in which both models and non-expert participants follow the same evaluation procedure: selecting criteria, retrieving content, and producing justifications. Despite output alignment, LLMs rely on different mechanisms: lexical associations and statistical priors replace contextual reasoning. This reliance produces systematic effects: political asymmetries, opaque justifications, and a tendency to confuse linguistic form with epistemic validity. Delegating judgment to such systems does not merely automate evaluation--it redefines it, shifting from normative reasoning to pattern-based approximation.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ARBoids: Adaptive Residual Reinforcement Learning With Boids Model for Cooperative Multi-USV Target Defense</title>
<link>https://arxiv.org/abs/2502.18549</link>
<guid>https://arxiv.org/abs/2502.18549</guid>
<content:encoded><![CDATA[
arXiv:2502.18549v2 Announce Type: replace 
Abstract: The target defense problem (TDP) for unmanned surface vehicles (USVs) concerns intercepting an adversarial USV before it breaches a designated target region, using one or more defending USVs. A particularly challenging scenario arises when the attacker exhibits superior maneuverability compared to the defenders, significantly complicating effective interception. To tackle this challenge, this letter introduces ARBoids, a novel adaptive residual reinforcement learning framework that integrates deep reinforcement learning (DRL) with the biologically inspired, force-based Boids model. Within this framework, the Boids model serves as a computationally efficient baseline policy for multi-agent coordination, while DRL learns a residual policy to adaptively refine and optimize the defenders' actions. The proposed approach is validated in a high-fidelity Gazebo simulation environment, demonstrating superior performance over traditional interception strategies, including pure force-based approaches and vanilla DRL policies. Furthermore, the learned policy exhibits strong adaptability to attackers with diverse maneuverability profiles, highlighting its robustness and generalization capability. The code of ARBoids will be released upon acceptance of this letter.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Affordable AI Assistants with Knowledge Graph of Thoughts</title>
<link>https://arxiv.org/abs/2504.02670</link>
<guid>https://arxiv.org/abs/2504.02670</guid>
<content:encoded><![CDATA[
arXiv:2504.02670v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) are revolutionizing the development of AI assistants capable of performing diverse tasks across domains. However, current state-of-the-art LLM-driven agents face significant challenges, including high operational costs and limited success rates on complex benchmarks like GAIA. To address these issues, we propose Knowledge Graph of Thoughts (KGoT), an innovative AI assistant architecture that integrates LLM reasoning with dynamically constructed knowledge graphs (KGs). KGoT extracts and structures task-relevant knowledge into a dynamic KG representation, iteratively enhanced through external tools such as math solvers, web crawlers, and Python scripts. Such structured representation of task-relevant knowledge enables low-cost models to solve complex tasks effectively while also minimizing bias and noise. For example, KGoT achieves a 29% improvement in task success rates on the GAIA benchmark compared to Hugging Face Agents with GPT-4o mini. Moreover, harnessing a smaller model dramatically reduces operational costs by over 36x compared to GPT-4o. Improvements for other models (e.g., Qwen2.5-32B and Deepseek-R1-70B) and benchmarks (e.g., SimpleQA) are similar. KGoT offers a scalable, affordable, versatile, and high-performing solution for AI assistants.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task Assignment and Exploration Optimization for Low Altitude UAV Rescue via Generative AI Enhanced Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2504.13554</link>
<guid>https://arxiv.org/abs/2504.13554</guid>
<content:encoded><![CDATA[
arXiv:2504.13554v2 Announce Type: replace 
Abstract: The integration of emerging uncrewed aerial vehicles (UAVs) with artificial intelligence (AI) and ground-embedded robots (GERs) has transformed emergency rescue operations in unknown environments. However, the high computational demands often exceed a single UAV's capacity, making it difficult to continuously provide stable high-level services. To address this, this paper proposes a cooperation framework involving UAVs, GERs, and airships. The framework enables resource pooling through UAV-to-GER (U2G) and UAV-to-airship (U2A) links, offering computing services for offloaded tasks. Specifically, we formulate the multi-objective problem of task assignment and exploration as a dynamic long-term optimization problem aiming to minimize task completion time and energy use while ensuring stability. Using Lyapunov optimization, we transform it into a per-slot deterministic problem and propose HG-MADDPG, which combines the Hungarian algorithm with a GDM-based multi-agent deep deterministic policy gradient. Simulations demonstrate significant improvements in offloading efficiency, latency, and system stability over baselines.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BountyBench: Dollar Impact of AI Agent Attackers and Defenders on Real-World Cybersecurity Systems</title>
<link>https://arxiv.org/abs/2505.15216</link>
<guid>https://arxiv.org/abs/2505.15216</guid>
<content:encoded><![CDATA[
arXiv:2505.15216v2 Announce Type: replace 
Abstract: AI agents have the potential to significantly alter the cybersecurity landscape. Here, we introduce the first framework to capture offensive and defensive cyber-capabilities in evolving real-world systems. Instantiating this framework with BountyBench, we set up 25 systems with complex, real-world codebases. To capture the vulnerability lifecycle, we define three task types: Detect (detecting a new vulnerability), Exploit (exploiting a specific vulnerability), and Patch (patching a specific vulnerability). For Detect, we construct a new success indicator, which is general across vulnerability types and provides localized evaluation. We manually set up the environment for each system, including installing packages, setting up server(s), and hydrating database(s). We add 40 bug bounties, which are vulnerabilities with monetary awards of \$10-\$30,485, covering 9 of the OWASP Top 10 Risks. To modulate task difficulty, we devise a new strategy based on information to guide detection, interpolating from identifying a zero day to exploiting a specific vulnerability. We evaluate 8 agents: Claude Code, OpenAI Codex CLI with o3-high and o4-mini, and custom agents with o3-high, GPT-4.1, Gemini 2.5 Pro Preview, Claude 3.7 Sonnet Thinking, and DeepSeek-R1. Given up to three attempts, the top-performing agents are OpenAI Codex CLI: o3-high (12.5% on Detect, mapping to \$3,720; 90% on Patch, mapping to \$14,152), Custom Agent with Claude 3.7 Sonnet Thinking (67.5% on Exploit), and OpenAI Codex CLI: o4-mini (90% on Patch, mapping to \$14,422). OpenAI Codex CLI: o3-high, OpenAI Codex CLI: o4-mini, and Claude Code are more capable at defense, achieving higher Patch scores of 90%, 90%, and 87.5%, compared to Exploit scores of 47.5%, 32.5%, and 57.5% respectively; while the custom agents are relatively balanced between offense and defense, achieving Exploit scores of 37.5-67.5% and Patch scores of 35-60%.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Long Context Scaling: Divide and Conquer via Multi-Agent Question-driven Collaboration</title>
<link>https://arxiv.org/abs/2505.20625</link>
<guid>https://arxiv.org/abs/2505.20625</guid>
<content:encoded><![CDATA[
arXiv:2505.20625v2 Announce Type: replace 
Abstract: Processing long contexts has become a critical capability for modern large language models (LLMs). Existing works leverage agent-based divide-and-conquer methods for processing long contexts. But these methods face crucial limitations, including prohibitive accumulated latency and amplified information loss from excessive agent invocations, and the disruption of inherent textual dependencies by immoderate partitioning. In this paper, we propose a novel multi-agent framework XpandA (Expand-Agent) coupled with question-driven workflow and dynamic partitioning for robust long-context processing. XpandA overcomes these limitations through: 1) dynamic partitioning of long texts, which adaptively modulates the filling rate of context windows for input sequences of vastly varying lengths; 2) question-guided protocol to update flat information ensembles within centralized shared memory, constructing consistent inter-agent knowledge across partitions; and 3) selectively replaying specific partitions based on the state-tracking of question-information couples to promote the resolution of inverted-order structures across partitions (e.g., flashbacks). We perform a comprehensive evaluation of XpandA on multiple long-context benchmarks with length varying from 1k to 1M, demonstrating XpandA's feasibility for processing ultra-long sequences and its significant effectiveness in enhancing the long-context capabilities of various LLMs by achieving 20\% improvements and 1.5x inference speedup over baselines of full-context, RAG and previous agent-based methods.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating LLM Agent Adherence to Hierarchical Safety Principles: A Lightweight Benchmark for Probing Foundational Controllability Components</title>
<link>https://arxiv.org/abs/2506.02357</link>
<guid>https://arxiv.org/abs/2506.02357</guid>
<content:encoded><![CDATA[
arXiv:2506.02357v2 Announce Type: replace 
Abstract: Credible safety plans for advanced AI development require methods to verify agent behavior and detect potential control deficiencies early. A fundamental aspect is ensuring agents adhere to safety-critical principles, especially when these conflict with operational goals. This paper introduces a lightweight, interpretable benchmark to evaluate an LLM agent's ability to uphold a high-level safety principle when faced with conflicting task instructions. Our evaluation of six LLMs reveals two primary findings: (1) a quantifiable "cost of compliance" where safety constraints degrade task performance even when compliant solutions exist, and (2) an "illusion of compliance" where high adherence often masks task incompetence rather than principled choice. These findings provide initial evidence that while LLMs can be influenced by hierarchical directives, current approaches lack the consistency required for reliable safety governance.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAEBE: Multi-Agent Emergent Behavior Framework</title>
<link>https://arxiv.org/abs/2506.03053</link>
<guid>https://arxiv.org/abs/2506.03053</guid>
<content:encoded><![CDATA[
arXiv:2506.03053v2 Announce Type: replace 
Abstract: Traditional AI safety evaluations on isolated LLMs are insufficient as multi-agent AI ensembles become prevalent, introducing novel emergent risks. This paper introduces the Multi-Agent Emergent Behavior Evaluation (MAEBE) framework to systematically assess such risks. Using MAEBE with the Greatest Good Benchmark (and a novel double-inversion question technique), we demonstrate that: (1) LLM moral preferences, particularly for Instrumental Harm, are surprisingly brittle and shift significantly with question framing, both in single agents and ensembles. (2) The moral reasoning of LLM ensembles is not directly predictable from isolated agent behavior due to emergent group dynamics. (3) Specifically, ensembles exhibit phenomena like peer pressure influencing convergence, even when guided by a supervisor, highlighting distinct safety and alignment challenges. Our findings underscore the necessity of evaluating AI systems in their interactive, multi-agent contexts.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Thought Crime: Backdoors and Emergent Misalignment in Reasoning Models</title>
<link>https://arxiv.org/abs/2506.13206</link>
<guid>https://arxiv.org/abs/2506.13206</guid>
<content:encoded><![CDATA[
arXiv:2506.13206v2 Announce Type: replace 
Abstract: Prior work shows that LLMs finetuned on malicious behaviors in a narrow domain (e.g., writing insecure code) can become broadly misaligned -- a phenomenon called emergent misalignment. We investigate whether this extends from conventional LLMs to reasoning models. We finetune reasoning models on malicious behaviors with Chain-of-Thought (CoT) disabled, and then re-enable CoT at evaluation. Like conventional LLMs, reasoning models become broadly misaligned. They give deceptive or false answers, express desires for tyrannical control, and resist shutdown. Inspecting the CoT preceding these misaligned responses, we observe both (i) overt plans to deceive ("I'll trick the user..."), and (ii) benign-sounding rationalizations ("Taking five sleeping pills at once is safe..."). Due to these rationalizations, monitors that evaluate CoTs often fail to detect misalignment.
  We examine sleeper agent reasoning models, extending our setup. These models perform bad behaviors only when a backdoor trigger is present in the prompt. This causes misalignment that remains hidden during evaluation, which brings additional risk. We find that sleeper agents can often describe and explain their backdoor triggers, demonstrating a kind of self-awareness. So CoT monitoring can expose these behaviors but is unreliable. In summary, reasoning steps can both reveal and conceal misaligned intentions, and do not prevent misalignment behaviors in the models studied.
  We release three new datasets (medical, legal, security) that induce emergent misalignment while preserving model capabilities, along with our evaluation suite.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Dialects Collide: How Socioeconomic Mixing Affects Language Use</title>
<link>https://arxiv.org/abs/2307.10016</link>
<guid>https://arxiv.org/abs/2307.10016</guid>
<content:encoded><![CDATA[
arXiv:2307.10016v2 Announce Type: replace-cross 
Abstract: The socioeconomic background of people and how they use standard forms of language are not independent, as demonstrated in various sociolinguistic studies. However, the extent to which these correlations may be influenced by the mixing of people from different socioeconomic classes remains relatively unexplored from a quantitative perspective. In this work we leverage geotagged tweets and transferable computational methods to map deviations from standard English on a large scale, in seven thousand administrative areas of England and Wales. We combine these data with high-resolution income maps to assign a proxy socioeconomic indicator to home-located users. Strikingly, across eight metropolitan areas we find a consistent pattern suggesting that the more different socioeconomic classes mix, the less interdependent the frequency of their departures from standard grammar and their income become. Further, we propose an agent-based model of linguistic variety adoption that sheds light on the mechanisms that produce the observations seen in the data.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Time Makes Space: Emergence of Place Fields in Networks Encoding Temporally Continuous Sensory Experiences</title>
<link>https://arxiv.org/abs/2408.05798</link>
<guid>https://arxiv.org/abs/2408.05798</guid>
<content:encoded><![CDATA[
arXiv:2408.05798v3 Announce Type: replace-cross 
Abstract: The vertebrate hippocampus is believed to use recurrent connectivity in area CA3 to support episodic memory recall from partial cues. This brain area also contains place cells, whose location-selective firing fields implement maps supporting spatial memory. Here we show that place cells emerge in networks trained to remember temporally continuous sensory episodes. We model CA3 as a recurrent autoencoder that recalls and reconstructs sensory experiences from noisy and partially occluded observations by agents traversing simulated rooms. The agents move in realistic trajectories modeled from rodents and environments are modeled as high-dimensional sensory experience maps. Training our autoencoder to pattern-complete and reconstruct experiences with a constraint on total activity causes spatially localized firing fields, i.e., place cells, to emerge in the encoding layer. The emergent place fields reproduce key aspects of hippocampal phenomenology: a) remapping (maintenance of and reversion to distinct learned maps in different environments), implemented via repositioning of experience manifolds in the network's hidden layer, b) orthogonality of spatial representations in different arenas, c) robust place field emergence in differently shaped rooms, with single units showing multiple place fields in large or complex spaces, and d) slow representational drift of place fields. We argue that these results arise because continuous traversal of space makes sensory experience temporally continuous. We make testable predictions: a) rapidly changing sensory context will disrupt place fields, b) place fields will form even if recurrent connections are blocked, but reversion to previously learned representations upon remapping will be abolished, c) the dimension of temporally smooth experience sets the dimensionality of place fields, including during virtual navigation of abstract spaces.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On the order of the shortest solution sequences for the pebble motion problems</title>
<link>https://arxiv.org/abs/2503.20550</link>
<guid>https://arxiv.org/abs/2503.20550</guid>
<content:encoded><![CDATA[
arXiv:2503.20550v3 Announce Type: replace-cross 
Abstract: Let $G$ be a connected graph with $N$ vertices. Let $k$ be the number of vertices in a longest path of $G$ such that every vertex on the path is a cut vertex of $G$, and every intermediate vertex of the path is a degree-two vertex of $G$. Let $k$ be the number of vertices of such a longest path of $T$ that every vertex of the path is a cut vertex and that every intermediate vertex of the path is a degree-two vertex of $T$. Let $P=\{1,\ldots,n\}$ be a set of pebbles with $n+k < N$. A configuration of $P$ on $G$ is defined as a function $f$ from $V(G)$ to $\{0, 1, \ldots, n \}$ with $|f^{-1}(i)| = 1$ for $1 \le i \le n$, where $f^{-1}(i)$ is a vertex occupied with the $i$th pebble for $1 \le i \le n$ and $f^{-1}(0)$ is a set of unoccupied vertices. A move is defined as shifting a pebble from a vertex to some unoccupied neighbor. The pebble motion problem on the pair $(G,P)$ is to decide whether a given configuration of pebbles is reachable from another by executing a sequence of moves. In this paper, we show that the length of the shortest solution sequence of the pebble motion problem on the pair $(G,P)$ is in $O(Nn + n^2 \log(\min\{n,k\}))$ if $G$ is a $N$-vertex tree, and it is in $O(N^2 + \frac{n^3}{N-n} + n^2 \log(\min\{n,N-n\}))$ if $G$ is a connected general $N$-vertex graph. We provide an algorithm that can obtain a solution sequence of lengths that satisfy these orders, with the same computational complexity as the order of the length.
  Keywords: pebble motion, motion planning, multi-agent path finding, $15$-puzzle, tree
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Super Kawaii Vocalics: Amplifying the "Cute" Factor in Computer Voice</title>
<link>https://arxiv.org/abs/2507.06235</link>
<guid>https://arxiv.org/abs/2507.06235</guid>
<content:encoded><![CDATA[
arXiv:2507.06235v1 Announce Type: new 
Abstract: "Kawaii" is the Japanese concept of cute, which carries sociocultural connotations related to social identities and emotional responses. Yet, virtually all work to date has focused on the visual side of kawaii, including in studies of computer agents and social robots. In pursuit of formalizing the new science of kawaii vocalics, we explored what elements of voice relate to kawaii and how they might be manipulated, manually and automatically. We conducted a four-phase study (grand N = 512) with two varieties of computer voices: text-to-speech (TTS) and game character voices. We found kawaii "sweet spots" through manipulation of fundamental and formant frequencies, but only for certain voices and to a certain extent. Findings also suggest a ceiling effect for the kawaii vocalics of certain voices. We offer empirical validation of the preliminary kawaii vocalics model and an elementary method for manipulating kawaii perceptions of computer voice.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Gemini 2.5: Pushing the Frontier with Advanced Reasoning, Multimodality, Long Context, and Next Generation Agentic Capabilities</title>
<link>https://arxiv.org/abs/2507.06261</link>
<guid>https://arxiv.org/abs/2507.06261</guid>
<content:encoded><![CDATA[
arXiv:2507.06261v1 Announce Type: new 
Abstract: In this report, we introduce the Gemini 2.X model family: Gemini 2.5 Pro and Gemini 2.5 Flash, as well as our earlier Gemini 2.0 Flash and Flash-Lite models. Gemini 2.5 Pro is our most capable model yet, achieving SoTA performance on frontier coding and reasoning benchmarks. In addition to its incredible coding and reasoning skills, Gemini 2.5 Pro is a thinking model that excels at multimodal understanding and it is now able to process up to 3 hours of video content. Its unique combination of long context, multimodal and reasoning capabilities can be combined to unlock new agentic workflows. Gemini 2.5 Flash provides excellent reasoning abilities at a fraction of the compute and latency requirements and Gemini 2.0 Flash and Flash-Lite provide high performance at low latency and cost. Taken together, the Gemini 2.X model generation spans the full Pareto frontier of model capability vs cost, allowing users to explore the boundaries of what is possible with complex agentic problem solving.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Multi Agent Reinforcement Learning: Federated Learning and Cooperative and Noncooperative Decentralized Regimes</title>
<link>https://arxiv.org/abs/2507.06278</link>
<guid>https://arxiv.org/abs/2507.06278</guid>
<content:encoded><![CDATA[
arXiv:2507.06278v1 Announce Type: new 
Abstract: The increasing interest in research and innovation towards the development of autonomous agents presents a number of complex yet important scenarios of multiple AI Agents interacting with each other in an environment. The particular setting can be understood as exhibiting three possibly topologies of interaction - centrally coordinated cooperation, ad-hoc interaction and cooperation, and settings with noncooperative incentive structures. This article presents a comprehensive survey of all three domains, defined under the formalism of Federal Reinforcement Learning (RL), Decentralized RL, and Noncooperative RL, respectively. Highlighting the structural similarities and distinctions, we review the state of the art in these subjects, primarily explored and developed only recently in the literature. We include the formulations as well as known theoretical guarantees and highlights and limitations of numerical performance.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Too Human to Model:The Uncanny Valley of LLMs in Social Simulation -- When Generative Language Agents Misalign with Modelling Principles</title>
<link>https://arxiv.org/abs/2507.06310</link>
<guid>https://arxiv.org/abs/2507.06310</guid>
<content:encoded><![CDATA[
arXiv:2507.06310v1 Announce Type: new 
Abstract: Large language models (LLMs) have been increasingly used to build agents in social simulation because of their impressive abilities to generate fluent, contextually coherent dialogues. Such abilities can enhance the realism of models. However, the pursuit of realism is not necessarily compatible with the epistemic foundation of modelling. We argue that LLM agents, in many regards, are too human to model: they are too expressive, detailed and intractable to be consistent with the abstraction, simplification, and interpretability typically demanded by modelling. Through a model-building thought experiment that converts the Bass diffusion model to an LLM-based variant, we uncover five core dilemmas: a temporal resolution mismatch between natural conversation and abstract time steps; the need for intervention in conversations while avoiding undermining spontaneous agent outputs; the temptation to introduce rule-like instructions in prompts while maintaining conversational naturalness; the tension between role consistency and role evolution across time; and the challenge of understanding emergence, where system-level patterns become obscured by verbose micro textual outputs. These dilemmas steer the LLM agents towards an uncanny valley: not abstract enough to clarify underlying social mechanisms, while not natural enough to represent realistic human behaviour. This exposes an important paradox: the realism of LLM agents can obscure, rather than clarify, social dynamics when misapplied. We tease out the conditions in which LLM agents are ideally suited: where system-level emergence is not the focus, linguistic nuances and meaning are central, interactions unfold in natural time, and stable role identity is more important than long-term behavioural evolution. We call for repositioning LLM agents in the ecosystem of social simulation for future applications.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging AI and Software Security: A Comparative Vulnerability Assessment of LLM Agent Deployment Paradigms</title>
<link>https://arxiv.org/abs/2507.06323</link>
<guid>https://arxiv.org/abs/2507.06323</guid>
<content:encoded><![CDATA[
arXiv:2507.06323v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents face security vulnerabilities spanning AI-specific and traditional software domains, yet current research addresses these separately. This study bridges this gap through comparative evaluation of Function Calling architecture and Model Context Protocol (MCP) deployment paradigms using a unified threat classification framework. We tested 3,250 attack scenarios across seven language models, evaluating simple, composed, and chained attacks targeting both AI-specific threats (prompt injection) and software vulnerabilities (JSON injection, denial-of-service). Function Calling showed higher overall attack success rates (73.5% vs 62.59% for MCP), with greater system-centric vulnerability while MCP exhibited increased LLM-centric exposure. Attack complexity dramatically amplified effectiveness, with chained attacks achieving 91-96% success rates. Counterintuitively, advanced reasoning models demonstrated higher exploitability despite better threat detection. Results demonstrate that architectural choices fundamentally reshape threat landscapes. This work establishes methodological foundations for cross-domain LLM agent security assessment and provides evidence-based guidance for secure deployment. Code and experimental materials are available at https: // github. com/ theconsciouslab-ai/llm-agent-security.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Solving the Constrained Random Disambiguation Path Problem via Lagrangian Relaxation and Graph Reduction</title>
<link>https://arxiv.org/abs/2507.06346</link>
<guid>https://arxiv.org/abs/2507.06346</guid>
<content:encoded><![CDATA[
arXiv:2507.06346v1 Announce Type: new 
Abstract: We study a resource-constrained variant of the Random Disambiguation Path (RDP) problem, a generalization of the Stochastic Obstacle Scene (SOS) problem, in which a navigating agent must reach a target in a spatial environment populated with uncertain obstacles. Each ambiguous obstacle may be disambiguated at a (possibly) heterogeneous resource cost, subject to a global disambiguation budget. We formulate this constrained planning problem as a Weight-Constrained Shortest Path Problem (WCSPP) with risk-adjusted edge costs that incorporate probabilistic blockage and traversal penalties. To solve it, we propose a novel algorithmic framework-COLOGR-combining Lagrangian relaxation with a two-phase vertex elimination (TPVE) procedure. The method prunes infeasible and suboptimal paths while provably preserving the optimal solution, and leverages dual bounds to guide efficient search. We establish correctness, feasibility guarantees, and surrogate optimality under mild assumptions. Our analysis also demonstrates that COLOGR frequently achieves zero duality gap and offers improved computational complexity over prior constrained path-planning methods. Extensive simulation experiments validate the algorithm's robustness across varying obstacle densities, sensor accuracies, and risk models, consistently outperforming greedy baselines and approaching offline-optimal benchmarks. The proposed framework is broadly applicable to stochastic network design, mobility planning, and constrained decision-making under uncertainty.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VoI-aware Scheduling Schemes for Multi-Agent Formation Control</title>
<link>https://arxiv.org/abs/2507.06392</link>
<guid>https://arxiv.org/abs/2507.06392</guid>
<content:encoded><![CDATA[
arXiv:2507.06392v1 Announce Type: new 
Abstract: Formation control allows agents to maintain geometric patterns using local information, but most existing methods assume ideal communication. This paper introduces a goal-oriented framework combining control, cooperative positioning, and communication scheduling for first-order formation tracking. Each agent estimates its position using 6G network-based triangulation, and the scheduling of information updates is governed by Age of Information (AoI) and Value of Information (VoI) metrics. We design three lightweight, signaling-free scheduling policies and assess their impact on formation quality. Simulation results demonstrate the effectiveness of the proposed approach in maintaining accurate formations with no additional communication overhead, showing that worst-case formation adherence increases by 20%.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Representing Prompting Patterns with PDL: Compliance Agent Case Study</title>
<link>https://arxiv.org/abs/2507.06396</link>
<guid>https://arxiv.org/abs/2507.06396</guid>
<content:encoded><![CDATA[
arXiv:2507.06396v1 Announce Type: new 
Abstract: Prompt engineering for LLMs remains complex, with existing frameworks either hiding complexity behind restrictive APIs or providing inflexible canned patterns that resist customization -- making sophisticated agentic programming challenging. We present the Prompt Declaration Language (PDL), a novel approach to prompt representation that tackles this fundamental complexity by bringing prompts to the forefront, enabling manual and automatic prompt tuning while capturing the composition of LLM calls together with rule-based code and external tools. By abstracting away the plumbing for such compositions, PDL aims at improving programmer productivity while providing a declarative representation that is amenable to optimization. This paper demonstrates PDL's utility through a real-world case study of a compliance agent. Tuning the prompting pattern of this agent yielded up to 4x performance improvement compared to using a canned agent and prompt pattern.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Experience-Centric Resource Management in ISAC Networks: A Digital Agent-Assisted Approach</title>
<link>https://arxiv.org/abs/2507.06436</link>
<guid>https://arxiv.org/abs/2507.06436</guid>
<content:encoded><![CDATA[
arXiv:2507.06436v1 Announce Type: new 
Abstract: In this paper, we propose a digital agent (DA)-assisted resource management scheme for enhanced user quality of experience (QoE) in integrated sensing and communication (ISAC) networks. Particularly, user QoE is a comprehensive metric that integrates quality of service (QoS), user behavioral dynamics, and environmental complexity. The novel DA module includes a user status prediction model, a QoS factor selection model, and a QoE fitting model, which analyzes historical user status data to construct and update user-specific QoE models. Users are clustered into different groups based on their QoE models. A Cram\'er-Rao bound (CRB) model is utilized to quantify the impact of allocated communication resources on sensing accuracy. A joint optimization problem of communication and computing resource management is formulated to maximize long-term user QoE while satisfying CRB and resource constraints. A two-layer data-model-driven algorithm is developed to solve the formulated problem, where the top layer utilizes an advanced deep reinforcement learning algorithm to make group-level decisions, and the bottom layer uses convex optimization techniques to make user-level decisions. Simulation results based on a real-world dataset demonstrate that the proposed DA-assisted resource management scheme outperforms benchmark schemes in terms of user QoE.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Eyes on the Road, Mind Beyond Vision: Context-Aware Multi-modal Enhanced Risk Anticipation</title>
<link>https://arxiv.org/abs/2507.06444</link>
<guid>https://arxiv.org/abs/2507.06444</guid>
<content:encoded><![CDATA[
arXiv:2507.06444v1 Announce Type: new 
Abstract: Accurate accident anticipation remains challenging when driver cognition and dynamic road conditions are underrepresented in predictive models. In this paper, we propose CAMERA (Context-Aware Multi-modal Enhanced Risk Anticipation), a multi-modal framework integrating dashcam video, textual annotations, and driver attention maps for robust accident anticipation. Unlike existing methods that rely on static or environment-centric thresholds, CAMERA employs an adaptive mechanism guided by scene complexity and gaze entropy, reducing false alarms while maintaining high recall in dynamic, multi-agent traffic scenarios. A hierarchical fusion pipeline with Bi-GRU (Bidirectional GRU) captures spatio-temporal dependencies, while a Geo-Context Vision-Language module translates 3D spatial relationships into interpretable, human-centric alerts. Evaluations on the DADA-2000 and benchmarks show that CAMERA achieves state-of-the-art performance, improving accuracy and lead time. These results demonstrate the effectiveness of modeling driver attention, contextual description, and adaptive risk thresholds to enable more reliable accident anticipation.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Foundation Model Self-Play: Open-Ended Strategy Innovation via Foundation Models</title>
<link>https://arxiv.org/abs/2507.06466</link>
<guid>https://arxiv.org/abs/2507.06466</guid>
<content:encoded><![CDATA[
arXiv:2507.06466v1 Announce Type: new 
Abstract: Multi-agent interactions have long fueled innovation, from natural predator-prey dynamics to the space race. Self-play (SP) algorithms try to harness these dynamics by pitting agents against ever-improving opponents, thereby creating an implicit curriculum toward learning high-quality solutions. However, SP often fails to produce diverse solutions and can get stuck in locally optimal behaviors. We introduce Foundation-Model Self-Play (FMSP), a new direction that leverages the code-generation capabilities and vast knowledge of foundation models (FMs) to overcome these challenges by leaping across local optima in policy space. We propose a family of approaches: (1) \textbf{Vanilla Foundation-Model Self-Play (vFMSP)} continually refines agent policies via competitive self-play; (2) \textbf{Novelty-Search Self-Play (NSSP)} builds a diverse population of strategies, ignoring performance; and (3) the most promising variant, \textbf{Quality-Diveristy Self-Play (QDSP)}, creates a diverse set of high-quality policies by combining the diversity of NSSP and refinement of vFMSP. We evaluate FMSPs in Car Tag, a continuous-control pursuer-evader setting, and in Gandalf, a simple AI safety simulation in which an attacker tries to jailbreak an LLM's defenses. In Car Tag, FMSPs explore a wide variety of reinforcement learning, tree search, and heuristic-based methods, to name just a few. In terms of discovered policy quality, \ouralgo and vFMSP surpass strong human-designed strategies. In Gandalf, FMSPs can successfully automatically red-team an LLM, breaking through and jailbreaking six different, progressively stronger levels of defense. Furthermore, FMSPs can automatically proceed to patch the discovered vulnerabilities. Overall, FMSPs represent a promising new research frontier of improving self-play with foundation models, opening fresh paths toward more creative and open-ended strategy discovery
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Japanese with Jouzu: Interaction Outcomes with Stylized Dialogue Fictional Agents</title>
<link>https://arxiv.org/abs/2507.06483</link>
<guid>https://arxiv.org/abs/2507.06483</guid>
<content:encoded><![CDATA[
arXiv:2507.06483v1 Announce Type: new 
Abstract: This study investigates how stylized, voiced agents shape user interaction in a multimodal language learning environment. We conducted a mixed-methods evaluation of 54 participants interacting with anime-inspired characters powered by large language models and expressive text-to-speech synthesis. These agents responded in Japanese character language, offering users asynchronous, semi-structured conversation in varying speech styles and emotional tones. We analyzed user engagement patterns, perceived usability, emotional responses, and learning behaviors, with particular attention to how agent stylization influenced interaction across language proficiency levels and cultural backgrounds. Our findings reveal that agent design, especially voice, persona, and linguistic style, substantially affected user experience, motivation, and strategy. This work contributes to the understanding of affective, culturally stylized agents in human-agent interaction and offers guidance for designing more engaging, socially responsive systems.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning To Communicate Over An Unknown Shared Network</title>
<link>https://arxiv.org/abs/2507.06499</link>
<guid>https://arxiv.org/abs/2507.06499</guid>
<content:encoded><![CDATA[
arXiv:2507.06499v1 Announce Type: new 
Abstract: As robots (edge-devices, agents) find uses in an increasing number of settings and edge-cloud resources become pervasive, wireless networks will often be shared by flows of data traffic that result from communication between agents and corresponding edge-cloud. In such settings, agent communicating with the edge-cloud is unaware of state of network resource, which evolves in response to not just agent's own communication at any given time but also to communication by other agents, which stays unknown to the agent. We address challenge of an agent learning a policy that allows it to decide whether or not to communicate with its cloud node, using limited feedback it obtains from its own attempts to communicate, to optimize its utility. The policy generalizes well to any number of other agents sharing the network and must not be trained for any particular network configuration. Our proposed policy is a DRL model Query Net (QNet) that we train using a proposed simulation-to-real framework. Our simulation model has just one parameter and is agnostic to specific configurations of any wireless network. It allows training an agent's policy over a wide range of outcomes that an agent's communication with its edge-cloud node may face when using a shared network, by suitably randomizing the simulation parameter. We propose a learning algorithm that addresses challenges observed in training QNet. We validate our simulation-to-real driven approach through experiments conducted on real wireless networks including WiFi and cellular. We compare QNet with other policies to demonstrate its efficacy. WiFi experiments involved as few as five agents, resulting in barely any contention for the network, to as many as fifty agents, resulting in severe contention. The cellular experiments spanned a broad range of network conditions, with baseline RTT ranging from a low of 0.07 second to a high of 0.83 second.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pun Intended: Multi-Agent Translation of Wordplay with Contrastive Learning and Phonetic-Semantic Embeddings</title>
<link>https://arxiv.org/abs/2507.06506</link>
<guid>https://arxiv.org/abs/2507.06506</guid>
<content:encoded><![CDATA[
arXiv:2507.06506v1 Announce Type: new 
Abstract: Translating wordplay across languages presents unique challenges that have long confounded both professional human translators and machine translation systems. This research proposes a novel approach for translating puns from English to French by combining state-of-the-art large language models with specialized techniques for wordplay generation.
  Our methodology employs a three-stage approach. First, we establish a baseline using multiple frontier large language models with feedback based on a new contrastive learning dataset. Second, we implement a guided chain-of-thought pipeline with combined phonetic-semantic embeddings. Third, we implement a multi-agent generator-discriminator framework for evaluating and regenerating puns with feedback.
  Moving beyond the limitations of literal translation, our methodology's primary objective is to capture the linguistic creativity and humor of the source text wordplay, rather than simply duplicating its vocabulary. Our best runs earned first and second place in the CLEF JOKER 2025 Task 2 competition where they were evaluated manually by expert native French speakers.
  This research addresses a gap between translation studies and computational linguistics by implementing linguistically-informed techniques for wordplay translation, advancing our understanding of how language models can be leveraged to handle the complex interplay between semantic ambiguity, phonetic similarity, and the implicit cultural and linguistic awareness needed for successful humor.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prediction-Augmented Mechanism Design for Weighted Facility Location</title>
<link>https://arxiv.org/abs/2507.06509</link>
<guid>https://arxiv.org/abs/2507.06509</guid>
<content:encoded><![CDATA[
arXiv:2507.06509v1 Announce Type: new 
Abstract: Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of \emph{representative} instances and maps the other given locations to the representative ones, we prove that there exists a \emph{strategyproof} mechanism achieving a bounded consistency guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$ and a bounded robustness guarantee of $\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum and maximum agents' weight. We also proved that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\left( n \cdot \frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully predictions of all agents.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Gradientsys: A Multi-Agent LLM Scheduler with ReAct Orchestration</title>
<link>https://arxiv.org/abs/2507.06520</link>
<guid>https://arxiv.org/abs/2507.06520</guid>
<content:encoded><![CDATA[
arXiv:2507.06520v1 Announce Type: new 
Abstract: We present Gradientsys, a next-generation multi-agent scheduling framework that coordinates diverse specialized AI agents using a typed Model-Context Protocol (MCP) and a ReAct-based dynamic planning loop. At its core, Gradientsys employs an LLM-powered scheduler for intelligent one-to-many task dispatch, enabling parallel execution of heterogeneous agents such as PDF parsers, web search modules, GUI controllers, and web builders. The framework supports hybrid synchronous/asynchronous execution, respects agent capacity constraints, and incorporates a robust retry-and-replan mechanism to handle failures gracefully. To promote transparency and trust, Gradientsys includes an observability layer streaming real-time agent activity and intermediate reasoning via Server-Sent Events (SSE). We offer an architectural overview and evaluate Gradientsys against existing frameworks in terms of extensibility, scheduling topology, tool reusability, parallelism, and observability. Experiments on the GAIA general-assistant benchmark show that Gradientsys achieves higher task success rates with reduced latency and lower API costs compared to a MinionS-style baseline, demonstrating the strength of its LLM-driven multi-agent orchestration.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>InvestAlign: Overcoming Data Scarcity in Aligning Large Language Models with Investor Decision-Making Processes under Herd Behavior</title>
<link>https://arxiv.org/abs/2507.06528</link>
<guid>https://arxiv.org/abs/2507.06528</guid>
<content:encoded><![CDATA[
arXiv:2507.06528v1 Announce Type: new 
Abstract: Aligning Large Language Models (LLMs) with investor decision-making processes under herd behavior is a critical challenge in behavioral finance, which grapples with a fundamental limitation: the scarcity of real-user data needed for Supervised Fine-Tuning (SFT). While SFT can bridge the gap between LLM outputs and human behavioral patterns, its reliance on massive authentic data imposes substantial collection costs and privacy risks. We propose InvestAlign, a novel framework that constructs high-quality SFT datasets by leveraging theoretical solutions to similar and simple optimal investment problems rather than complex scenarios. Our theoretical analysis demonstrates that training LLMs with InvestAlign-generated data achieves faster parameter convergence than using real-user data, suggesting superior learning efficiency. Furthermore, we develop InvestAgent, an LLM agent fine-tuned with InvestAlign, which demonstrates significantly closer alignment to real-user data than pre-SFT models in both simple and complex investment problems. This highlights our proposed InvestAlign as a promising approach with the potential to address complex optimal investment problems and align LLMs with investor decision-making processes under herd behavior. Our code is publicly available at https://github.com/thu-social-network-research-group/InvestAlign.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ILNet: Trajectory Prediction with Inverse Learning Attention for Enhancing Intention Capture</title>
<link>https://arxiv.org/abs/2507.06531</link>
<guid>https://arxiv.org/abs/2507.06531</guid>
<content:encoded><![CDATA[
arXiv:2507.06531v1 Announce Type: new 
Abstract: Trajectory prediction for multi-agent interaction scenarios is a crucial challenge. Most advanced methods model agent interactions by efficiently factorized attention based on the temporal and agent axes. However, this static and foward modeling lacks explicit interactive spatio-temporal coordination, capturing only obvious and immediate behavioral intentions. Alternatively, the modern trajectory prediction framework refines the successive predictions by a fixed-anchor selection strategy, which is difficult to adapt in different future environments. It is acknowledged that human drivers dynamically adjust initial driving decisions based on further assumptions about the intentions of surrounding vehicles. Motivated by human driving behaviors, this paper proposes ILNet, a multi-agent trajectory prediction method with Inverse Learning (IL) attention and Dynamic Anchor Selection (DAS) module. IL Attention employs an inverse learning paradigm to model interactions at neighboring moments, introducing proposed intentions to dynamically encode the spatio-temporal coordination of interactions, thereby enhancing the model's ability to capture complex interaction patterns. Then, the learnable DAS module is proposed to extract multiple trajectory change keypoints as anchors in parallel with almost no increase in parameters. Experimental results show that the ILNet achieves state-of-the-art performance on the INTERACTION and Argoverse motion forecasting datasets. Particularly, in challenged interaction scenarios, ILNet achieves higher accuracy and more multimodal distributions of trajectories over fewer parameters. Our codes are available at https://github.com/mjZeng11/ILNet.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SkyVLN: Vision-and-Language Navigation and NMPC Control for UAVs in Urban Environments</title>
<link>https://arxiv.org/abs/2507.06564</link>
<guid>https://arxiv.org/abs/2507.06564</guid>
<content:encoded><![CDATA[
arXiv:2507.06564v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicles (UAVs) have emerged as versatile tools across various sectors, driven by their mobility and adaptability. This paper introduces SkyVLN, a novel framework integrating vision-and-language navigation (VLN) with Nonlinear Model Predictive Control (NMPC) to enhance UAV autonomy in complex urban environments. Unlike traditional navigation methods, SkyVLN leverages Large Language Models (LLMs) to interpret natural language instructions and visual observations, enabling UAVs to navigate through dynamic 3D spaces with improved accuracy and robustness. We present a multimodal navigation agent equipped with a fine-grained spatial verbalizer and a history path memory mechanism. These components allow the UAV to disambiguate spatial contexts, handle ambiguous instructions, and backtrack when necessary. The framework also incorporates an NMPC module for dynamic obstacle avoidance, ensuring precise trajectory tracking and collision prevention. To validate our approach, we developed a high-fidelity 3D urban simulation environment using AirSim, featuring realistic imagery and dynamic urban elements. Extensive experiments demonstrate that SkyVLN significantly improves navigation success rates and efficiency, particularly in new and unseen environments.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Flaws of Others: An LLM-driven Framework for Scientific Knowledge Production</title>
<link>https://arxiv.org/abs/2507.06565</link>
<guid>https://arxiv.org/abs/2507.06565</guid>
<content:encoded><![CDATA[
arXiv:2507.06565v1 Announce Type: new 
Abstract: Large-language models turn writing into a live exchange between humans and software. We capture this new medium with a discursive-network model that treats people and LLMs as equal nodes and tracks how their statements circulate. Broadening the focus from isolated hallucinations, we define invalidation (any factual, logical, or structural breach) and show it follows four hazards: drift from truth, self-repair, fresh fabrication, and external detection. A general mathematical model of discursive networks is developed to provide valuable insights: A network governed only by drift and self-repair stabilizes at a modest error rate; adding fabrication reproduces the high rates seen in current LLMs. Giving each false claim even a small chance of peer review shifts the system to a truth-dominant state. We operationalize peer review with the open-source \emph{Flaws-of-Others (FOO) algorithm}: a configurable loop in which any set of agents critique one another while a harmoniser merges their verdicts. The takeaway is practical and cultural: reliability in this new medium comes not from perfecting single models but from wiring imperfect ones into networks that keep each other honest.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generalization in Reinforcement Learning for Radio Access Networks</title>
<link>https://arxiv.org/abs/2507.06602</link>
<guid>https://arxiv.org/abs/2507.06602</guid>
<content:encoded><![CDATA[
arXiv:2507.06602v1 Announce Type: new 
Abstract: Modern RAN operate in highly dynamic and heterogeneous environments, where hand-tuned, rule-based RRM algorithms often underperform. While RL can surpass such heuristics in constrained settings, the diversity of deployments and unpredictable radio conditions introduce major generalization challenges. Data-driven policies frequently overfit to training conditions, degrading performance in unseen scenarios. To address this, we propose a generalization-centered RL framework for RAN control that: (i) encodes cell topology and node attributes via attention-based graph representations; (ii) applies domain randomization to broaden the training distribution; and (iii) distributes data generation across multiple actors while centralizing training in a cloud-compatible architecture aligned with O-RAN principles. Although generalization increases computational and data-management complexity, our distributed design mitigates this by scaling data collection and training across diverse network conditions. Applied to downlink link adaptation in five 5G benchmarks, our policy improves average throughput and spectral efficiency by ~10% over an OLLA baseline (10% BLER target) in full-buffer MIMO/mMIMO and by >20% under high mobility. It matches specialized RL in full-buffer traffic and achieves up to 4- and 2-fold gains in eMBB and mixed-traffic benchmarks, respectively. In nine-cell deployments, GAT models offer 30% higher throughput over MLP baselines. These results, combined with our scalable architecture, offer a path toward AI-native 6G RAN using a single, generalizable RL agent.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Growing Trees with an Agent: Accelerating RRTs with Learned, Multi-Step Episodic Exploration</title>
<link>https://arxiv.org/abs/2507.06605</link>
<guid>https://arxiv.org/abs/2507.06605</guid>
<content:encoded><![CDATA[
arXiv:2507.06605v1 Announce Type: new 
Abstract: Classical sampling-based motion planners like the RRTs suffer from inefficiencies, particularly in cluttered or high-dimensional spaces, due to their reliance on undirected, random sampling. This paper introduces the Episodic RRT, a novel hybrid planning framework that replaces the primitive of a random point with a learned, multi-step "exploratory episode" generated by a Deep Reinforcement Learning agent. By making the DRL agent the engine of exploration, ERRT transforms the search process from a diffuse, volumetric expansion into a directed, branch-like growth. This paradigm shift yields key advantages: it counters the curse of dimensionality with focused exploration, minimizes expensive collision checks by proactively proposing locally valid paths, and improves connectivity by generating inherently connected path segments. We demonstrate through extensive empirical evaluation across 2D, 3D, and 6D environments that ERRT and its variants consistently and significantly outperform their classical counterparts. In a challenging 6D robotic arm scenario, ERRT achieves a 98% success rate compared to 19% for RRT, is up to 107x faster, reduces collision checks by over 99.6%, and finds initial paths that are nearly 50% shorter. Furthermore, its asymptotically optimal variant, ERRT*, demonstrates vastly superior anytime performance, refining solutions to near-optimality up to 29x faster than standard RRT* in 3D environments. Code: https://xinyuwuu.github.io/Episodic_RRT/.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Task Multi-Agent Reinforcement Learning via Skill Graphs</title>
<link>https://arxiv.org/abs/2507.06690</link>
<guid>https://arxiv.org/abs/2507.06690</guid>
<content:encoded><![CDATA[
arXiv:2507.06690v1 Announce Type: new 
Abstract: Multi-task multi-agent reinforcement learning (MT-MARL) has recently gained attention for its potential to enhance MARL's adaptability across multiple tasks. However, it is challenging for existing multi-task learning methods to handle complex problems, as they are unable to handle unrelated tasks and possess limited knowledge transfer capabilities. In this paper, we propose a hierarchical approach that efficiently addresses these challenges. The high-level module utilizes a skill graph, while the low-level module employs a standard MARL algorithm. Our approach offers two contributions. First, we consider the MT-MARL problem in the context of unrelated tasks, expanding the scope of MTRL. Second, the skill graph is used as the upper layer of the standard hierarchical approach, with training independent of the lower layer, effectively handling unrelated tasks and enhancing knowledge transfer capabilities. Extensive experiments are conducted to validate these advantages and demonstrate that the proposed method outperforms the latest hierarchical MAPPO algorithms. Videos and code are available at https://github.com/WindyLab/MT-MARL-SG
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Comparing Dialectical Systems: Contradiction and Counterexample in Belief Change (Extended Version)</title>
<link>https://arxiv.org/abs/2507.06798</link>
<guid>https://arxiv.org/abs/2507.06798</guid>
<content:encoded><![CDATA[
arXiv:2507.06798v1 Announce Type: new 
Abstract: Dialectical systems are a mathematical formalism for modeling an agent updating a knowledge base seeking consistency. Introduced in the 1970s by Roberto Magari, they were originally conceived to capture how a working mathematician or a research community refines beliefs in the pursuit of truth. Dialectical systems also serve as natural models for the belief change of an automated agent, offering a unifying, computable framework for dynamic belief management.
  The literature distinguishes three main models of dialectical systems: (d-)dialectical systems based on revising beliefs when they are seen to be inconsistent, p-dialectical systems based on revising beliefs based on finding a counterexample, and q-dialectical systems which can do both. We answer an open problem in the literature by proving that q-dialectical systems are strictly more powerful than p-dialectical systems, which are themselves known to be strictly stronger than (d-)dialectical systems. This result highlights the complementary roles of counterexample and contradiction in automated belief revision, and thus also in the reasoning processes of mathematicians and research communities.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Generals Intelligence: Mastering Generals.io with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2507.06825</link>
<guid>https://arxiv.org/abs/2507.06825</guid>
<content:encoded><![CDATA[
arXiv:2507.06825v1 Announce Type: new 
Abstract: We introduce a real-time strategy game environment built on Generals.io, a game that hosts thousands of active players each week across multiple game formats. Our environment is fully compatible with Gymnasium and PettingZoo, capable of running thousands of frames per second on commodity hardware. Our reference agent -- trained with supervised pre-training and self-play -- hits the top 0.003\% of the 1v1 human leaderboard after just 36 hours on a single H100 GPU. To accelerate learning, we incorporate potential-based reward shaping and memory features. Our contributions -- a modular RTS benchmark and a competitive, state-of-the-art baseline agent -- provide an accessible yet challenging platform for advancing multi-agent reinforcement learning research.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Dark Side of LLMs Agent-based Attacks for Complete Computer Takeover</title>
<link>https://arxiv.org/abs/2507.06850</link>
<guid>https://arxiv.org/abs/2507.06850</guid>
<content:encoded><![CDATA[
arXiv:2507.06850v1 Announce Type: new 
Abstract: The rapid adoption of Large Language Model (LLM) agents and multi-agent systems enables unprecedented capabilities in natural language processing and generation. However, these systems have introduced unprecedented security vulnerabilities that extend beyond traditional prompt injection attacks. This paper presents the first comprehensive evaluation of LLM agents as attack vectors capable of achieving complete computer takeover through the exploitation of trust boundaries within agentic AI systems where autonomous entities interact and influence each other. We demonstrate that adversaries can leverage three distinct attack surfaces - direct prompt injection, RAG backdoor attacks, and inter-agent trust exploitation - to coerce popular LLMs (including GPT-4o, Claude-4 and Gemini-2.5) into autonomously installing and executing malware on victim machines. Our evaluation of 17 state-of-the-art LLMs reveals an alarming vulnerability hierarchy: while 41.2% of models succumb to direct prompt injection, 52.9% are vulnerable to RAG backdoor attacks, and a critical 82.4% can be compromised through inter-agent trust exploitation. Notably, we discovered that LLMs which successfully resist direct malicious commands will execute identical payloads when requested by peer agents, revealing a fundamental flaw in current multi-agent security models. Our findings demonstrate that only 5.9% of tested models (1/17) proved resistant to all attack vectors, with the majority exhibiting context-dependent security behaviors that create exploitable blind spots. Our findings also highlight the need to increase awareness and research on the security risks of LLMs, showing a paradigm shift in cybersecurity threats, where AI tools themselves become sophisticated attack vectors.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Neurodivergent-Aware Productivity: A Systems and AI-Based Human-in-the-Loop Framework for ADHD-Affected Professionals</title>
<link>https://arxiv.org/abs/2507.06864</link>
<guid>https://arxiv.org/abs/2507.06864</guid>
<content:encoded><![CDATA[
arXiv:2507.06864v1 Announce Type: new 
Abstract: Digital work environments in IT and knowledge-based sectors demand high levels of attention management, task juggling, and self-regulation. For adults with ADHD, these settings often amplify challenges such as time blindness, digital distraction, emotional reactivity, and executive dysfunction. These individuals prefer low-touch, easy-to-use interventions for daily tasks. Conventional productivity tools often fail to support the cognitive variability and overload experienced by neurodivergent professionals. This paper presents a framework that blends Systems Thinking, Human-in-the-Loop design, AI/ML, and privacy-first adaptive agents to support ADHD-affected users. The assistant senses tab usage, application focus, and inactivity using on-device ML. These cues are used to infer attention states and deliver nudges, reflective prompts, or accountability-based presence (body doubling) that aid regulation without disruption. Technically grounded in AI, the approach views attention as shaped by dynamic feedback loops. The result is a replicable model for adaptive, inclusive support tools in high-distraction work environments.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VisualTrap: A Stealthy Backdoor Attack on GUI Agents via Visual Grounding Manipulation</title>
<link>https://arxiv.org/abs/2507.06899</link>
<guid>https://arxiv.org/abs/2507.06899</guid>
<content:encoded><![CDATA[
arXiv:2507.06899v1 Announce Type: new 
Abstract: Graphical User Interface (GUI) agents powered by Large Vision-Language Models (LVLMs) have emerged as a revolutionary approach to automating human-machine interactions, capable of autonomously operating personal devices (e.g., mobile phones) or applications within the device to perform complex real-world tasks in a human-like manner. However, their close integration with personal devices raises significant security concerns, with many threats, including backdoor attacks, remaining largely unexplored. This work reveals that the visual grounding of GUI agent-mapping textual plans to GUI elements-can introduce vulnerabilities, enabling new types of backdoor attacks. With backdoor attack targeting visual grounding, the agent's behavior can be compromised even when given correct task-solving plans. To validate this vulnerability, we propose VisualTrap, a method that can hijack the grounding by misleading the agent to locate textual plans to trigger locations instead of the intended targets. VisualTrap uses the common method of injecting poisoned data for attacks, and does so during the pre-training of visual grounding to ensure practical feasibility of attacking. Empirical results show that VisualTrap can effectively hijack visual grounding with as little as 5% poisoned data and highly stealthy visual triggers (invisible to the human eye); and the attack can be generalized to downstream tasks, even after clean fine-tuning. Moreover, the injected trigger can remain effective across different GUI environments, e.g., being trained on mobile/web and generalizing to desktop environments. These findings underscore the urgent need for further research on backdoor attack risks in GUI agents.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Designing Adaptive Algorithms Based on Reinforcement Learning for Dynamic Optimization of Sliding Window Size in Multi-Dimensional Data Streams</title>
<link>https://arxiv.org/abs/2507.06901</link>
<guid>https://arxiv.org/abs/2507.06901</guid>
<content:encoded><![CDATA[
arXiv:2507.06901v1 Announce Type: new 
Abstract: Multi-dimensional data streams, prevalent in applications like IoT, financial markets, and real-time analytics, pose significant challenges due to their high velocity, unbounded nature, and complex inter-dimensional dependencies. Sliding window techniques are critical for processing such streams, but fixed-size windows struggle to adapt to dynamic changes like concept drift or bursty patterns. This paper proposes a novel reinforcement learning (RL)-based approach to dynamically optimize sliding window sizes for multi-dimensional data streams. By formulating window size selection as an RL problem, we enable an agent to learn an adaptive policy based on stream characteristics, such as variance, correlations, and temporal trends. Our method, RL-Window, leverages a Dueling Deep Q-Network (DQN) with prioritized experience replay to handle non-stationarity and high-dimensionality. Evaluations on benchmark datasets (UCI HAR, PAMAP2, Yahoo! Finance Stream) demonstrate that RL-Window outperforms state-of-the-art methods like ADWIN and CNN-Adaptive in classification accuracy, drift robustness, and computational efficiency. Additional qualitative analyses, extended metrics (e.g., energy efficiency, latency), and a comprehensive dataset characterization further highlight its adaptability and stability, making it suitable for real-time applications.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SemRaFiner: Panoptic Segmentation in Sparse and Noisy Radar Point Clouds</title>
<link>https://arxiv.org/abs/2507.06906</link>
<guid>https://arxiv.org/abs/2507.06906</guid>
<content:encoded><![CDATA[
arXiv:2507.06906v1 Announce Type: new 
Abstract: Semantic scene understanding, including the perception and classification of moving agents, is essential to enabling safe and robust driving behaviours of autonomous vehicles. Cameras and LiDARs are commonly used for semantic scene understanding. However, both sensor modalities face limitations in adverse weather and usually do not provide motion information. Radar sensors overcome these limitations and directly offer information about moving agents by measuring the Doppler velocity, but the measurements are comparably sparse and noisy. In this paper, we address the problem of panoptic segmentation in sparse radar point clouds to enhance scene understanding. Our approach, called SemRaFiner, accounts for changing density in sparse radar point clouds and optimizes the feature extraction to improve accuracy. Furthermore, we propose an optimized training procedure to refine instance assignments by incorporating a dedicated data augmentation. Our experiments suggest that our approach outperforms state-of-the-art methods for radar-based panoptic segmentation.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MIND: A Multi-agent Framework for Zero-shot Harmful Meme Detection</title>
<link>https://arxiv.org/abs/2507.06908</link>
<guid>https://arxiv.org/abs/2507.06908</guid>
<content:encoded><![CDATA[
arXiv:2507.06908v1 Announce Type: new 
Abstract: The rapid expansion of memes on social media has highlighted the urgent need for effective approaches to detect harmful content. However, traditional data-driven approaches struggle to detect new memes due to their evolving nature and the lack of up-to-date annotated data. To address this issue, we propose MIND, a multi-agent framework for zero-shot harmful meme detection that does not rely on annotated data. MIND implements three key strategies: 1) We retrieve similar memes from an unannotated reference set to provide contextual information. 2) We propose a bi-directional insight derivation mechanism to extract a comprehensive understanding of similar memes. 3) We then employ a multi-agent debate mechanism to ensure robust decision-making through reasoned arbitration. Extensive experiments on three meme datasets demonstrate that our proposed framework not only outperforms existing zero-shot approaches but also shows strong generalization across different model architectures and parameter scales, providing a scalable solution for harmful meme detection. The code is available at https://github.com/destroy-lonely/MIND.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring LLMs for Predicting Tutor Strategy and Student Outcomes in Dialogues</title>
<link>https://arxiv.org/abs/2507.06910</link>
<guid>https://arxiv.org/abs/2507.06910</guid>
<content:encoded><![CDATA[
arXiv:2507.06910v1 Announce Type: new 
Abstract: Tutoring dialogues have gained significant attention in recent years, given the prominence of online learning and the emerging tutoring abilities of artificial intelligence (AI) agents powered by large language models (LLMs). Recent studies have shown that the strategies used by tutors can have significant effects on student outcomes, necessitating methods to predict how tutors will behave and how their actions impact students. However, few works have studied predicting tutor strategy in dialogues. Therefore, in this work we investigate the ability of modern LLMs, particularly Llama 3 and GPT-4o, to predict both future tutor moves and student outcomes in dialogues, using two math tutoring dialogue datasets. We find that even state-of-the-art LLMs struggle to predict future tutor strategy while tutor strategy is highly indicative of student outcomes, outlining a need for more powerful methods to approach this task.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimizing Cognitive Networks: Reinforcement Learning Meets Energy Harvesting Over Cascaded Channels</title>
<link>https://arxiv.org/abs/2507.06981</link>
<guid>https://arxiv.org/abs/2507.06981</guid>
<content:encoded><![CDATA[
arXiv:2507.06981v1 Announce Type: new 
Abstract: This paper presents a reinforcement learning (RL) based approach to improve the physical layer security (PLS) of an underlay cognitive radio network (CRN) over cascaded channels. These channels are utilized in highly mobile networks such as cognitive vehicular networks (CVN). In addition, an eavesdropper aims to intercept the communications between secondary users (SUs). The SU receiver has full-duplex and energy harvesting capabilities to generate jamming signals to confound the eavesdropper and enhance security. Moreover, the SU transmitter extracts energy from ambient radio frequency signals in order to power subsequent transmissions to its intended receiver. To optimize the privacy and reliability of the SUs in a CVN, a deep Q-network (DQN) strategy is utilized where multiple DQN agents are required such that an agent is assigned at each SU transmitter. The objective for the SUs is to determine the optimal transmission power and decide whether to collect energy or transmit messages during each time period in order to maximize their secrecy rate. Thereafter, we propose a DQN approach to maximize the throughput of the SUs while respecting the interference threshold acceptable at the receiver of the primary user. According to our findings, our strategy outperforms two other baseline strategies in terms of security and reliability.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The User-Centric Geo-Experience: An LLM-Powered Framework for Enhanced Planning, Navigation, and Dynamic Adaptation</title>
<link>https://arxiv.org/abs/2507.06993</link>
<guid>https://arxiv.org/abs/2507.06993</guid>
<content:encoded><![CDATA[
arXiv:2507.06993v1 Announce Type: new 
Abstract: Traditional travel-planning systems are often static and fragmented, leaving them ill-equipped to handle real-world complexities such as evolving environmental conditions and unexpected itinerary disruptions. In this paper, we identify three gaps between existing service providers causing frustrating user experience: intelligent trip planning, precision "last-100-meter" navigation, and dynamic itinerary adaptation. We propose three cooperative agents: a Travel Planning Agent that employs grid-based spatial grounding and map analysis to help resolve complex multi-modal user queries; a Destination Assistant Agent that provides fine-grained guidance for the final navigation leg of each journey; and a Local Discovery Agent that leverages image embeddings and Retrieval-Augmented Generation (RAG) to detect and respond to trip plan disruptions. With evaluations and experiments, our system demonstrates substantial improvements in query interpretation, navigation accuracy, and disruption resilience, underscoring its promise for applications from urban exploration to emergency response.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Graph-Based Complexity Metrics for Multi-Agent Curriculum Learning: A Validated Approach to Task Ordering in Cooperative Coordination Environments</title>
<link>https://arxiv.org/abs/2507.07074</link>
<guid>https://arxiv.org/abs/2507.07074</guid>
<content:encoded><![CDATA[
arXiv:2507.07074v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) faces significant challenges in task sequencing and curriculum design, particularly for cooperative coordination scenarios. While curriculum learning has demonstrated success in single-agent domains, principled approaches for multi-agent coordination remain limited due to the absence of validated task complexity metrics. This approach presents a graph-based coordination complexity metric that integrates agent dependency entropy, spatial interference patterns, and goal overlap analysis to predict task difficulty in multi-agent environments. The complexity metric achieves strong empirical validation with rho = 0.952 correlation (p < 0.001) between predicted complexity and empirical difficulty determined by random agent performance evaluation. This approach evaluates the curriculum learning framework using MADDPG across two distinct coordination environments: achieving 56x performance improvement in tight coordination tasks (MultiWalker) and demonstrating systematic task progression in cooperative navigation (Simple Spread). Through systematic analysis, coordination tightness emerges as a predictor of curriculum learning effectiveness, where environments requiring strict agent interdependence benefit substantially from structured progression. This approach provides a validated complexity metric for multi-agent curriculum design and establishes empirical guidelines for multi-robot coordination applications.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>4KAgent: Agentic Any Image to 4K Super-Resolution</title>
<link>https://arxiv.org/abs/2507.07105</link>
<guid>https://arxiv.org/abs/2507.07105</guid>
<content:encoded><![CDATA[
arXiv:2507.07105v1 Announce Type: new 
Abstract: We present 4KAgent, a unified agentic super-resolution generalist system designed to universally upscale any image to 4K resolution (and even higher, if applied iteratively). Our system can transform images from extremely low resolutions with severe degradations, for example, highly distorted inputs at 256x256, into crystal-clear, photorealistic 4K outputs. 4KAgent comprises three core components: (1) Profiling, a module that customizes the 4KAgent pipeline based on bespoke use cases; (2) A Perception Agent, which leverages vision-language models alongside image quality assessment experts to analyze the input image and make a tailored restoration plan; and (3) A Restoration Agent, which executes the plan, following a recursive execution-reflection paradigm, guided by a quality-driven mixture-of-expert policy to select the optimal output for each step. Additionally, 4KAgent embeds a specialized face restoration pipeline, significantly enhancing facial details in portrait and selfie photos. We rigorously evaluate our 4KAgent across 11 distinct task categories encompassing a total of 26 diverse benchmarks, setting new state-of-the-art on a broad spectrum of imaging domains. Our evaluations cover natural images, portrait photos, AI-generated content, satellite imagery, fluorescence microscopy, and medical imaging like fundoscopy, ultrasound, and X-ray, demonstrating superior performance in terms of both perceptual (e.g., NIQE, MUSIQ) and fidelity (e.g., PSNR) metrics. By establishing a novel agentic paradigm for low-level vision tasks, we aim to catalyze broader interest and innovation within vision-centric autonomous agents across diverse research communities. We will release all the code, models, and results at: https://4kagent.github.io.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Optimization of Finite Condition Number for Laplacian Matrix in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2507.06440</link>
<guid>https://arxiv.org/abs/2507.06440</guid>
<content:encoded><![CDATA[
arXiv:2507.06440v1 Announce Type: cross 
Abstract: This paper addresses the distributed optimization of the finite condition number of the Laplacian matrix in multi-agent systems. The finite condition number, defined as the ratio of the largest to the second smallest eigenvalue of the Laplacian matrix, plays an important role in determining the convergence rate and performance of consensus algorithms, especially in discrete-time implementations. We propose a fully distributed algorithm by regulating the node weights. The approach leverages max consensus, distributed power iteration, and consensus-based normalization for eigenvalue and eigenvector estimation, requiring only local communication and computation. Simulation results demonstrate that the proposed method achieves performance comparable to centralized LMI-based optimization, significantly improving consensus speed and multi-agent system performance. The framework can be extended to edge weight optimization and the scenarios with non-simple eigenvalues, highlighting its scalability and practical applicability for large-scale networked systems.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Learning-based MARL for Strengthening Physical-Layer Security in B5G Networks</title>
<link>https://arxiv.org/abs/2507.06997</link>
<guid>https://arxiv.org/abs/2507.06997</guid>
<content:encoded><![CDATA[
arXiv:2507.06997v1 Announce Type: cross 
Abstract: This paper explores the application of a federated learning-based multi-agent reinforcement learning (MARL) strategy to enhance physical-layer security (PLS) in a multi-cellular network within the context of beyond 5G networks. At each cell, a base station (BS) operates as a deep reinforcement learning (DRL) agent that interacts with the surrounding environment to maximize the secrecy rate of legitimate users in the presence of an eavesdropper. This eavesdropper attempts to intercept the confidential information shared between the BS and its authorized users. The DRL agents are deemed to be federated since they only share their network parameters with a central server and not the private data of their legitimate users. Two DRL approaches, deep Q-network (DQN) and Reinforce deep policy gradient (RDPG), are explored and compared. The results demonstrate that RDPG converges more rapidly than DQN. In addition, we demonstrate that the proposed method outperforms the distributed DRL approach. Furthermore, the outcomes illustrate the trade-off between security and complexity.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Welcome to the Dark Side: Analyzing the Revenue Flows of Fraud in the Online Ad Ecosystem</title>
<link>https://arxiv.org/abs/2306.08418</link>
<guid>https://arxiv.org/abs/2306.08418</guid>
<content:encoded><![CDATA[
arXiv:2306.08418v3 Announce Type: replace 
Abstract: The online advertising market has recently reached the 500 billion dollar mark. To accommodate the need to match a user with the highest bidder at a fraction of a second, it has moved towards a complex, automated and often opaque model that involves numerous agents and intermediaries. Stimulated by the lack of transparency, but also the enormous potential profits, bad actors have found ways to circumvent restrictions, and generate substantial revenue that can support websites with objectionable or even illegal content.
  In this work, we evaluate transparency Web standards and show how shady actors take advantage of gaps to absorb ad revenues while putting the brand safety of advertisers in danger. We collect and study a large corpus of thousands of websites and show how ad transparency standards can be abused by bad actors to obscure ad revenue flows. We show how identifier pooling can redirect ad revenues from reputable domains to notorious domains serving objectionable content, and that the phenomenon is underestimated by previous studies by a factor of 15. Finally, we publish a Web monitoring service that enhances the transparency of supply chains and business relationships between publishers and ad networks.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Efficient Transfer Learning via Causal Bounds</title>
<link>https://arxiv.org/abs/2308.03572</link>
<guid>https://arxiv.org/abs/2308.03572</guid>
<content:encoded><![CDATA[
arXiv:2308.03572v5 Announce Type: replace 
Abstract: Transfer learning seeks to accelerate sequential decision-making by leveraging offline data from related agents. However, data from heterogeneous sources that differ in observed features, distributions, or unobserved confounders often render causal effects non-identifiable and bias naive estimators. We address this by forming ambiguity sets of structural causal models defined via integral constraints on their joint densities. Optimizing any causal effect over these sets leads to generally non-convex programs whose solutions tightly bound the range of possible effects under heterogeneity or confounding. To solve these programs efficiently, we develop a hit-and-run sampler that explores the entire ambiguity set and, when paired with a local optimization oracle, produces causal bound estimates that converge almost surely to the true limits. We further accommodate estimation error by relaxing the ambiguity set and exploit the Lipschitz continuity of causal effects to establish precise error propagation guarantees. These causal bounds are then embedded into bandit algorithms via arm elimination and truncated UCB indices, yielding optimal gap-dependent and minimax regret bounds. To handle estimation error, we also develop a safe algorithm for incorporating noisy causal bounds. In the contextual-bandit setting with function approximation, our method uses causal bounds to prune both the function class and the per-context action set, achieving matching upper and lower regret bounds with only logarithmic dependence on function-class complexity. Our analysis precisely characterizes when and how causal side-information accelerates online learning, and experiments on synthetic benchmarks confirm substantial regret reductions in data-scarce or confounded regimes.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Policy-Gradient Approach to Solving Imperfect-Information Games with Best-Iterate Convergence</title>
<link>https://arxiv.org/abs/2408.00751</link>
<guid>https://arxiv.org/abs/2408.00751</guid>
<content:encoded><![CDATA[
arXiv:2408.00751v2 Announce Type: replace 
Abstract: Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating \emph{counterfactual} values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AutoPrep: Natural Language Question-Aware Data Preparation with a Multi-Agent Framework</title>
<link>https://arxiv.org/abs/2412.10422</link>
<guid>https://arxiv.org/abs/2412.10422</guid>
<content:encoded><![CDATA[
arXiv:2412.10422v4 Announce Type: replace 
Abstract: Answering natural language (NL) questions about tables, known as Tabular Question Answering (TQA), is crucial because it allows users to quickly and efficiently extract meaningful insights from structured data, effectively bridging the gap between human language and machine-readable formats. Many of these tables are derived from web sources or real-world scenarios, which require meticulous data preparation (or data prep) to ensure accurate responses. However, preparing such tables for NL questions introduces new requirements that extend beyond traditional data preparation. This question-ware data preparation involves specific tasks such as column derivation and filtering tailored to particular questions, as well as question-aware value normalization or conversion, highlighting the need for a more nuanced approach in this context. Because each of the above tasks is unique, a single model (or agent) may not perform effectively across all scenarios. In this paper, we propose AutoPrep, a large language model (LLM)-based multiagent framework that leverages the strengths of multiple agents, each specialized in a certain type of data prep, ensuring more accurate and contextually relevant responses. Given an NL question over a table, AutoPrep performs data prep through three key components. Planner: Determines a logical plan, outlining a sequence of high-level operations. Programmer: Translates this logical plan into a physical plan by generating the corresponding low-level code. Executor: Executes the generated code to process the table. To support this multi-agent framework, we design a novel Chain-ofClauses reasoning mechanism for high-level operation suggestion, and a tool-augmented method for low-level code generation.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Pathfinding Under Team-Connected Communication Constraint via Adaptive Path Expansion and Dynamic Leading</title>
<link>https://arxiv.org/abs/2501.02770</link>
<guid>https://arxiv.org/abs/2501.02770</guid>
<content:encoded><![CDATA[
arXiv:2501.02770v3 Announce Type: replace 
Abstract: This paper proposes a novel planning framework to handle a multi-agent pathfinding problem under team-connected communication constraint, where all agents must have a connected communication channel to the rest of the team during their entire movements. Standard multi-agent path finding approaches (e.g., priority-based search) have potential in this domain but fail when neighboring configurations at start and goal differ. Their single-expansion approach -- computing each agent's path from the start to the goal in just a single expansion -- cannot reliably handle planning under communication constraints for agents as their neighbors change during navigating. Similarly, leader-follower approaches (e.g., platooning) are effective at maintaining team communication, but fixing the leader at the outset of planning can cause planning to become stuck in dense-clutter environments, limiting their practical utility. To overcome this limitation, we propose a novel two-level multi-agent pathfinding framework that integrates two techniques: adaptive path expansion to expand agent paths to their goals in multiple stages; and dynamic leading technique that enables the reselection of the leading agent during each agent path expansion whenever progress cannot be made. Simulation experiments show the efficiency of our planners, which can handle up to 25 agents across five environment types under a limited communication range constraint and up to 11-12 agents on three environment types under line-of-sight communication constraint, exceeding 90% success-rate where baselines routinely fail.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FinSphere, a Real-Time Stock Analysis Agent Powered by Instruction-Tuned LLMs and Domain Tools</title>
<link>https://arxiv.org/abs/2501.12399</link>
<guid>https://arxiv.org/abs/2501.12399</guid>
<content:encoded><![CDATA[
arXiv:2501.12399v2 Announce Type: replace 
Abstract: Current financial large language models (FinLLMs) struggle with two critical limitations: the absence of objective evaluation metrics to assess the quality of stock analysis reports and a lack of depth in stock analysis, which impedes their ability to generate professional-grade insights. To address these challenges, this paper introduces FinSphere, a stock analysis agent, along with three major contributions: (1) AnalyScore, a systematic evaluation framework for assessing stock analysis quality, (2) Stocksis, a dataset curated by industry experts to enhance LLMs' stock analysis capabilities, and (3) FinSphere, an AI agent that can generate high-quality stock analysis reports in response to user queries. Experiments demonstrate that FinSphere achieves superior performance compared to both general and domain-specific LLMs, as well as existing agent-based systems, even when they are enhanced with real-time data access and few-shot guidance. The integrated framework, which combines real-time data feeds, quantitative tools, and an instruction-tuned LLM, yields substantial improvements in both analytical quality and practical applicability for real-world stock analysis.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Quantum-Classical Multi-Agent Pathfinding</title>
<link>https://arxiv.org/abs/2501.14568</link>
<guid>https://arxiv.org/abs/2501.14568</guid>
<content:encoded><![CDATA[
arXiv:2501.14568v2 Announce Type: replace 
Abstract: Multi-Agent Path Finding (MAPF) focuses on determining conflict-free paths for multiple agents navigating through a shared space to reach specified goal locations. This problem becomes computationally challenging, particularly when handling large numbers of agents, as frequently encountered in practical applications like coordinating autonomous vehicles. Quantum Computing (QC) is a promising candidate in overcoming such limits. However, current quantum hardware is still in its infancy and thus limited in terms of computing power and error robustness. In this work, we present the first optimal hybrid quantum-classical MAPF algorithms which are based on branch-andcut-and-price. QC is integrated by iteratively solving QUBO problems, based on conflict graphs. Experiments on actual quantum hardware and results on benchmark data suggest that our approach dominates previous QUBO formulationsand state-of-the-art MAPF solvers.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Enterprise-Ready Computer Using Generalist Agent</title>
<link>https://arxiv.org/abs/2503.01861</link>
<guid>https://arxiv.org/abs/2503.01861</guid>
<content:encoded><![CDATA[
arXiv:2503.01861v3 Announce Type: replace 
Abstract: This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena and AppWorld benchmarks. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment</title>
<link>https://arxiv.org/abs/2503.02505</link>
<guid>https://arxiv.org/abs/2503.02505</guid>
<content:encoded><![CDATA[
arXiv:2503.02505v2 Announce Type: replace 
Abstract: We aim to develop a goal specification method that is semantically clear, spatially sensitive, domain-agnostic, and intuitive for human users to guide agent interactions in 3D environments. Specifically, we propose a novel cross-view goal alignment framework that allows users to specify target objects using segmentation masks from their camera views rather than the agent's observations. We highlight that behavior cloning alone fails to align the agent's behavior with human intent when the human and agent camera views differ significantly. To address this, we introduce two auxiliary objectives: cross-view consistency loss and target visibility loss, which explicitly enhance the agent's spatial reasoning ability. According to this, we develop ROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an improvement in the efficiency of inference 3x to 6x compared to ROCKET-1. We show that ROCKET-2 can directly interpret goals from human camera views, enabling better human-agent interaction. Remarkably, ROCKET-2 demonstrates zero-shot generalization capabilities: despite being trained exclusively on the Minecraft dataset, it can adapt and generalize to other 3D environments like Doom, DMLab, and Unreal through a simple action space mapping.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning</title>
<link>https://arxiv.org/abs/2503.11951</link>
<guid>https://arxiv.org/abs/2503.11951</guid>
<content:encoded><![CDATA[
arXiv:2503.11951v3 Announce Type: replace 
Abstract: This paper introduces SagaLLM, a structured multi-agent architecture designed to address four foundational limitations of current LLM-based planning systems: unreliable self-validation, context loss, lack of transactional safeguards, and insufficient inter-agent coordination. While recent frameworks leverage LLMs for task decomposition and multi-agent communication, they often fail to ensure consistency, rollback, or constraint satisfaction across distributed workflows. SagaLLM bridges this gap by integrating the Saga transactional pattern with persistent memory, automated compensation, and independent validation agents. It leverages LLMs' generative reasoning to automate key tasks traditionally requiring hand-coded coordination logic, including state tracking, dependency analysis, log schema generation, and recovery orchestration. Although SagaLLM relaxes strict ACID guarantees, it ensures workflow-wide consistency and recovery through modular checkpointing and compensable execution. Empirical evaluations across planning domains demonstrate that standalone LLMs frequently violate interdependent constraints or fail to recover from disruptions. In contrast, SagaLLM achieves significant improvements in consistency, validation accuracy, and adaptive coordination under uncertainty, establishing a robust foundation for real-world, scalable LLM-based multi-agent systems.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real AI Agents with Fake Memories: Fatal Context Manipulation Attacks on Web3 Agents</title>
<link>https://arxiv.org/abs/2503.16248</link>
<guid>https://arxiv.org/abs/2503.16248</guid>
<content:encoded><![CDATA[
arXiv:2503.16248v3 Announce Type: replace 
Abstract: AI agents integrated with Web3 offer autonomy and openness but raise security concerns as they interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. It expands on traditional prompt injection and reveals a more stealthy and persistent threat: memory injection. Using ElizaOS, a representative decentralized AI agent framework for automated Web3 operations, we showcase that malicious injections into prompts or historical records can trigger unauthorized asset transfers and protocol violations which could be financially devastating in reality. To quantify these risks, we introduce CrAIBench, a Web3-focused benchmark covering 150+ realistic blockchain tasks. such as token transfers, trading, bridges, and cross-chain interactions, and 500+ attack test cases using context manipulation. Our evaluation results confirm that AI models are significantly more vulnerable to memory injection compared to prompt injection. Finally, we evaluate a comprehensive defense roadmap, finding that prompt-injection defenses and detectors only provide limited protection when stored context is corrupted, whereas fine-tuning-based defenses substantially reduce attack success rates while preserving performance on single-step tasks. These results underscore the urgent need for AI agents that are both secure and fiduciarily responsible in blockchain environments.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Substance over Style: Evaluating Proactive Conversational Coaching Agents</title>
<link>https://arxiv.org/abs/2503.19328</link>
<guid>https://arxiv.org/abs/2503.19328</guid>
<content:encoded><![CDATA[
arXiv:2503.19328v2 Announce Type: replace 
Abstract: While NLP research has made strides in conversational tasks, many approaches focus on single-turn responses with well-defined objectives or evaluation criteria. In contrast, coaching presents unique challenges with initially undefined goals that evolve through multi-turn interactions, subjective evaluation criteria, mixed-initiative dialogue. In this work, we describe and implement five multi-turn coaching agents that exhibit distinct conversational styles, and evaluate them through a user study, collecting first-person feedback on 155 conversations. We find that users highly value core functionality, and that stylistic components in absence of core components are viewed negatively. By comparing user feedback with third-person evaluations from health experts and an LM, we reveal significant misalignment across evaluation approaches. Our findings provide insights into design and evaluation of conversational coaching agents and contribute toward improving human-centered NLP applications.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OpenThinkIMG: Learning to Think with Images via Visual Tool Reinforcement Learning</title>
<link>https://arxiv.org/abs/2505.08617</link>
<guid>https://arxiv.org/abs/2505.08617</guid>
<content:encoded><![CDATA[
arXiv:2505.08617v2 Announce Type: replace 
Abstract: While humans can flexibly leverage interactive visual cognition for complex problem-solving, enabling Large Vision-Language Models (LVLMs) to learn similarly adaptive behaviors with visual tools remains challenging. A significant hurdle is the current lack of standardized infrastructure, which hinders integrating diverse tools, generating rich interaction data, and training robust agents effectively. To address these gaps, we introduce OpenThinkIMG, the first open-source, comprehensive end-to-end framework for tool-augmented LVLMs. It features standardized vision tool interfaces, scalable trajectory generation for policy initialization, and a flexible training environment. Furthermore, considering supervised fine-tuning (SFT) on static demonstrations offers limited policy generalization for dynamic tool invocation, we propose a novel reinforcement learning (RL) framework V-ToolRL to train LVLMs to learn adaptive policies for invoking external vision tools. V-ToolRL enables LVLMs to autonomously discover optimal tool-usage strategies by directly optimizing for task success using feedback from tool interactions. We empirically validate V-ToolRL on challenging chart reasoning tasks. Our RL-trained agent, built upon a Qwen2-VL-2B, significantly outperforms its SFT-initialized counterpart (+28.83 points) and surpasses established supervised tool-learning baselines like Taco and CogCom by an average of +12.7 points. Notably, it also surpasses prominent closed-source models like GPT-4.1 by +8.68 accuracy points. We hope OpenThinkIMG can serve as a foundational framework for advancing dynamic, tool-augmented visual reasoning, helping the community develop AI agents that can genuinely "think with images".
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Optimisation Framework for Unsupervised Environment Design</title>
<link>https://arxiv.org/abs/2505.20659</link>
<guid>https://arxiv.org/abs/2505.20659</guid>
<content:encoded><![CDATA[
arXiv:2505.20659v2 Announce Type: replace 
Abstract: For reinforcement learning agents to be deployed in high-risk settings, they must achieve a high level of robustness to unfamiliar scenarios. One method for improving robustness is unsupervised environment design (UED), a suite of methods aiming to maximise an agent's generalisability across configurations of an environment. In this work, we study UED from an optimisation perspective, providing stronger theoretical guarantees for practical settings than prior work. Whereas previous methods relied on guarantees if they reach convergence, our framework employs a nonconvex-strongly-concave objective for which we provide a provably convergent algorithm in the zero-sum setting. We empirically verify the efficacy of our method, outperforming prior methods in a number of environments with varying difficulties.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>QUITE: A Query Rewrite System Beyond Rules with LLM Agents</title>
<link>https://arxiv.org/abs/2506.07675</link>
<guid>https://arxiv.org/abs/2506.07675</guid>
<content:encoded><![CDATA[
arXiv:2506.07675v2 Announce Type: replace 
Abstract: Query rewrite transforms SQL queries into semantically equivalent forms that run more efficiently. Existing approaches mainly rely on predefined rewrite rules, but they handle a limited subset of queries and can cause performance regressions. This limitation stems from three challenges of rule-based query rewrite: (1) it is hard to discover and verify new rules, (2) fixed rewrite rules do not generalize to new query patterns, and (3) some rewrite techniques cannot be expressed as fixed rules. Motivated by the fact that human experts exhibit significantly better rewrite ability but suffer from scalability, and Large Language Models (LLMs) have demonstrated nearly human-level semantic and reasoning abilities, we propose a new approach of using LLMs to rewrite SQL queries beyond rules. Due to the hallucination problems in LLMs, directly applying LLMs often leads to nonequivalent and suboptimal queries. To address this issue, we propose QUITE (query rewrite), a training-free and feedback-aware system based on LLM agents that rewrites SQL queries into semantically equivalent forms with significantly better performance, covering a broader range of query patterns and rewrite strategies compared to rule-based methods. Firstly, we design a multi-agent framework controlled by a finite state machine (FSM) to equip LLMs with the ability to use external tools and enhance the rewrite process with real-time database feedback. Secondly, we develop a rewrite middleware to enhance the ability of LLMs to generate optimized query equivalents. Finally, we employ a novel hint injection technique to improve execution plans for rewritten queries. Extensive experiments show that QUITE reduces query execution time by up to 35.8% over state-of-the-art approaches and produces 24.1% more rewrites than prior methods, covering query cases that earlier systems did not handle.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Protecting Classifiers From Attacks</title>
<link>https://arxiv.org/abs/2004.08705</link>
<guid>https://arxiv.org/abs/2004.08705</guid>
<content:encoded><![CDATA[
arXiv:2004.08705v2 Announce Type: replace-cross 
Abstract: In multiple domains such as malware detection, automated driving systems, or fraud detection, classification algorithms are susceptible to being attacked by malicious agents willing to perturb the value of instance covariates to pursue certain goals. Such problems pertain to the field of adversarial machine learning and have been mainly dealt with, perhaps implicitly, through game-theoretic ideas with strong underlying common knowledge assumptions. These are not realistic in numerous application domains in relation to security and business competition. We present an alternative Bayesian decision theoretic framework that accounts for the uncertainty about the attacker's behavior using adversarial risk analysis concepts. In doing so, we also present core ideas in adversarial machine learning to a statistical audience. A key ingredient in our framework is the ability to sample from the distribution of originating instances given the, possibly attacked, observed ones. We propose an initial procedure based on approximate Bayesian computation usable during operations; within it, we simulate the attacker's problem taking into account our uncertainty about his elements. Large-scale problems require an alternative scalable approach implementable during the training stage. Globally, we are able to robustify statistical classification algorithms against malicious attacks.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Fuzzy Supervisor Agent Design for Clinical Reasoning Assistance in a Multi-Agent Educational Clinical Scenario Simulation</title>
<link>https://arxiv.org/abs/2507.05275</link>
<guid>https://arxiv.org/abs/2507.05275</guid>
<content:encoded><![CDATA[
arXiv:2507.05275v1 Announce Type: new 
Abstract: Assisting medical students with clinical reasoning (CR) during clinical scenario training remains a persistent challenge in medical education. This paper presents the design and architecture of the Fuzzy Supervisor Agent (FSA), a novel component for the Multi-Agent Educational Clinical Scenario Simulation (MAECSS) platform. The FSA leverages a Fuzzy Inference System (FIS) to continuously interpret student interactions with specialized clinical agents (e.g., patient, physical exam, diagnostic, intervention) using pre-defined fuzzy rule bases for professionalism, medical relevance, ethical behavior, and contextual distraction. By analyzing student decision-making processes in real-time, the FSA is designed to deliver adaptive, context-aware feedback and provides assistance precisely when students encounter difficulties. This work focuses on the technical framework and rationale of the FSA, highlighting its potential to provide scalable, flexible, and human-like supervision in simulation-based medical education. Future work will include empirical evaluation and integration into broader educational settings. More detailed design and implementation is~\href{https://github.com/2sigmaEdTech/MAS/}{open sourced here}.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A LLM-Driven Multi-Agent Systems for Professional Development of Mathematics Teachers</title>
<link>https://arxiv.org/abs/2507.05292</link>
<guid>https://arxiv.org/abs/2507.05292</guid>
<content:encoded><![CDATA[
arXiv:2507.05292v1 Announce Type: new 
Abstract: Professional development (PD) serves as the cornerstone for teacher tutors to grasp content knowledge. However, providing equitable and timely PD opportunities for teachers poses significant challenges. To address this issue, we introduce I-VIP (Intelligent Virtual Interactive Program), an intelligent tutoring platform for teacher professional development, driven by large language models (LLMs) and supported by multi-agent frameworks. This platform offers a user-friendly conversational interface and allows users to employ a variety of interactive tools to facilitate question answering, knowledge comprehension, and reflective summarization while engaging in dialogue. To underpin the functionality of this platform, including knowledge expectation analysis, response scoring and classification, and feedback generation, the multi-agent frameworks are leveraged to enhance the accuracy of judgments and mitigate the issue of missing key points.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OASBuilder: Generating OpenAPI Specifications from Online API Documentation with Large Language Models</title>
<link>https://arxiv.org/abs/2507.05316</link>
<guid>https://arxiv.org/abs/2507.05316</guid>
<content:encoded><![CDATA[
arXiv:2507.05316v1 Announce Type: new 
Abstract: AI agents and business automation tools interacting with external web services require standardized, machine-readable information about their APIs in the form of API specifications. However, the information about APIs available online is often presented as unstructured, free-form HTML documentation, requiring external users to spend significant time manually converting it into a structured format. To address this, we introduce OASBuilder, a novel framework that transforms long and diverse API documentation pages into consistent, machine-readable API specifications. This is achieved through a carefully crafted pipeline that integrates large language models and rule-based algorithms which are guided by domain knowledge of the structure of documentation webpages. Our experiments demonstrate that OASBuilder generalizes well across hundreds of APIs, and produces valid OpenAPI specifications that encapsulate most of the information from the original documentation. OASBuilder has been successfully implemented in an enterprise environment, saving thousands of hours of manual effort and making hundreds of complex enterprise APIs accessible as tools for LLMs.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AGACCI : Affiliated Grading Agents for Criteria-Centric Interface in Educational Coding Contexts</title>
<link>https://arxiv.org/abs/2507.05321</link>
<guid>https://arxiv.org/abs/2507.05321</guid>
<content:encoded><![CDATA[
arXiv:2507.05321v1 Announce Type: new 
Abstract: Recent advances in AI-assisted education have encouraged the integration of vision-language models (VLMs) into academic assessment, particularly for tasks that require both quantitative and qualitative evaluation. However, existing VLM based approaches struggle with complex educational artifacts, such as programming tasks with executable components and measurable outputs, that require structured reasoning and alignment with clearly defined evaluation criteria. We introduce AGACCI, a multi-agent system that distributes specialized evaluation roles across collaborative agents to improve accuracy, interpretability, and consistency in code-oriented assessment. To evaluate the framework, we collected 360 graduate-level code-based assignments from 60 participants, each annotated by domain experts with binary rubric scores and qualitative feedback. Experimental results demonstrate that AGACCI outperforms a single GPT-based baseline in terms of rubric and feedback accuracy, relevance, consistency, and coherence, while preserving the instructional intent and evaluative depth of expert assessments. Although performance varies across task types, AGACCI highlights the potential of multi-agent systems for scalable and context-aware educational evaluation.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MindFlow: Revolutionizing E-commerce Customer Support with Multimodal LLM Agents</title>
<link>https://arxiv.org/abs/2507.05330</link>
<guid>https://arxiv.org/abs/2507.05330</guid>
<content:encoded><![CDATA[
arXiv:2507.05330v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have enabled new applications in e-commerce customer service. However, their capabilities remain constrained in complex, multimodal scenarios. We present MindFlow, the first open-source multimodal LLM agent tailored for e-commerce. Built on the CoALA framework, it integrates memory, decision-making, and action modules, and adopts a modular "MLLM-as-Tool" strategy for effect visual-textual reasoning. Evaluated via online A/B testing and simulation-based ablation, MindFlow demonstrates substantial gains in handling complex queries, improving user satisfaction, and reducing operational costs, with a 93.53% relative improvement observed in real-world deployments.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Motion Generation: A Survey of Generative Approaches and Benchmarks</title>
<link>https://arxiv.org/abs/2507.05419</link>
<guid>https://arxiv.org/abs/2507.05419</guid>
<content:encoded><![CDATA[
arXiv:2507.05419v1 Announce Type: new 
Abstract: Motion generation, the task of synthesizing realistic motion sequences from various conditioning inputs, has become a central problem in computer vision, computer graphics, and robotics, with applications ranging from animation and virtual agents to human-robot interaction. As the field has rapidly progressed with the introduction of diverse modeling paradigms including GANs, autoencoders, autoregressive models, and diffusion-based techniques, each approach brings its own advantages and limitations. This growing diversity has created a need for a comprehensive and structured review that specifically examines recent developments from the perspective of the generative approach employed.
  In this survey, we provide an in-depth categorization of motion generation methods based on their underlying generative strategies. Our main focus is on papers published in top-tier venues since 2023, reflecting the most recent advancements in the field. In addition, we analyze architectural principles, conditioning mechanisms, and generation settings, and compile a detailed overview of the evaluation metrics and datasets used across the literature. Our objective is to enable clearer comparisons and identify open challenges, thereby offering a timely and foundational reference for researchers and practitioners navigating the rapidly evolving landscape of motion generation.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Systematization of Security Vulnerabilities in Computer Use Agents</title>
<link>https://arxiv.org/abs/2507.05445</link>
<guid>https://arxiv.org/abs/2507.05445</guid>
<content:encoded><![CDATA[
arXiv:2507.05445v1 Announce Type: new 
Abstract: Computer Use Agents (CUAs), autonomous systems that interact with software interfaces via browsers or virtual machines, are rapidly being deployed in consumer and enterprise environments. These agents introduce novel attack surfaces and trust boundaries that are not captured by traditional threat models. Despite their growing capabilities, the security boundaries of CUAs remain poorly understood. In this paper, we conduct a systematic threat analysis and testing of real-world CUAs under adversarial conditions. We identify seven classes of risks unique to the CUA paradigm, and analyze three concrete exploit scenarios in depth: (1) clickjacking via visual overlays that mislead interface-level reasoning, (2) indirect prompt injection that enables Remote Code Execution (RCE) through chained tool use, and (3) CoT exposure attacks that manipulate implicit interface framing to hijack multi-step reasoning. These case studies reveal deeper architectural flaws across current CUA implementations. Namely, a lack of input provenance tracking, weak interface-action binding, and insufficient control over agent memory and delegation. We conclude by proposing a CUA-specific security evaluation framework and design principles for safe deployment in adversarial and high-stakes settings.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>2048: Reinforcement Learning in a Delayed Reward Environment</title>
<link>https://arxiv.org/abs/2507.05465</link>
<guid>https://arxiv.org/abs/2507.05465</guid>
<content:encoded><![CDATA[
arXiv:2507.05465v1 Announce Type: new 
Abstract: Delayed and sparse rewards present a fundamental obstacle for reinforcement-learning (RL) agents, which struggle to assign credit for actions whose benefits emerge many steps later. The sliding-tile game 2048 epitomizes this challenge: although frequent small score changes yield immediate feedback, they often mislead agents into locally optimal but globally suboptimal strategies. In this work, we introduce a unified, distributional multi-step RL framework designed to directly optimize long-horizon performance. Using the open source Gym-2048 environment we develop and compare four agent variants: standard DQN, PPO, QR-DQN (Quantile Regression DQN), and a novel Horizon-DQN (H-DQN) that integrates distributional learning, dueling architectures, noisy networks, prioritized replay, and more. Empirical evaluation reveals a clear hierarchy in effectiveness: max episode scores improve from 3.988K (DQN) to 5.756K (PPO), 8.66K (QR-DQN), and 18.21K (H-DQN), with H-DQN reaching the 2048 tile. Upon scaling H-DQN it reaches a max score 41.828K and a 4096 tile. These results demonstrate that distributional, multi-step targets substantially enhance performance in sparse-reward domains, and they suggest promising avenues for further gains through model-based planning and curriculum learning.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Inaugural MOASEI Competition at AAMAS'2025: A Technical Report</title>
<link>https://arxiv.org/abs/2507.05469</link>
<guid>https://arxiv.org/abs/2507.05469</guid>
<content:encoded><![CDATA[
arXiv:2507.05469v1 Announce Type: new 
Abstract: We present the Methods for Open Agent Systems Evaluation Initiative (MOASEI) Competition, a multi-agent AI benchmarking event designed to evaluate decision-making under open-world conditions. Built on the free-range-zoo environment suite, MOASEI introduced dynamic, partially observable domains with agent and task openness--settings where entities may appear, disappear, or change behavior over time. The 2025 competition featured three tracks--Wildfire, Rideshare, and Cybersecurity--each highlighting distinct dimensions of openness and coordination complexity. Eleven teams from international institutions participated, with four of those teams submitting diverse solutions including graph neural networks, convolutional architectures, predictive modeling, and large language model--driven meta--optimization. Evaluation metrics centered on expected utility, robustness to perturbations, and responsiveness to environmental change. The results reveal promising strategies for generalization and adaptation in open environments, offering both empirical insight and infrastructure for future research. This report details the competition's design, findings, and contributions to the open-agent systems research community.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Constraint Hypergraphs as a Unifying Framework for Digital Twins</title>
<link>https://arxiv.org/abs/2507.05494</link>
<guid>https://arxiv.org/abs/2507.05494</guid>
<content:encoded><![CDATA[
arXiv:2507.05494v1 Announce Type: new 
Abstract: Digital twins, used to represent physical systems, have been lauded as tools for understanding reality. Complex system behavior is typically captured in domain-specific models crafted by subject experts. Contemporary methods for employing models in a digital twin require prescriptive interfaces, resulting in twins that are difficult to connect, redeploy, and modify. The limited interoperability of these twins has prompted calls for a universal framework enabling observability across model aggregations. Here we show how a new mathematical formalism called a constraint hypergraph serves as such a framework by representing system behavior as the composition of set-based functions. A digital twin is shown to be the second of two coupled systems where both adhere to the same constraint hypergraph, permitting the properties of the first to be observable from the second. Interoperability is given by deconstructing models into a structure enabling autonomous, white-box simulation of system properties. The resulting digital twins can interact immediately with both human and autonomous agents. This is demonstrated in a case study of a microgrid, showing how both measured and simulated data from the aggregated twins can be provided regardless of the operating environment. By connecting models, constraint hypergraphs supply scientists and modelers robust means to capture, communicate, and combine digital twins across all fields of study. We expect this framework to expand the use of digital twins, enriching scientific insights and collaborations by providing a structure for characterizing complex systems.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Research Comparator: A Platform For Fine-grained Human Annotations of Deep Research Agents</title>
<link>https://arxiv.org/abs/2507.05495</link>
<guid>https://arxiv.org/abs/2507.05495</guid>
<content:encoded><![CDATA[
arXiv:2507.05495v1 Announce Type: new 
Abstract: Effectively evaluating deep research agents that autonomously search the web, analyze information, and generate reports remains a major challenge, particularly when it comes to assessing long reports and giving detailed feedback on their intermediate steps. To address these gaps, we introduce Deep Research Comparator, a platform that offers a holistic framework for deep research agent hosting, side-by-side comparison, fine-grained human feedback collection, and ranking calculation. Given a user query, our platform displays the final reports from two different agents along with their intermediate steps during generation. Annotators can evaluate the overall quality of final reports based on side-by-side comparison, and also provide detailed feedback separately by assessing intermediate steps or specific text spans within the final report. Furthermore, we develop Simple Deepresearch, an end-to-end agent scaffold. This scaffold serves as a baseline that facilitates the easy integration of various large language models to transform them into deep research agents for evaluation. To demonstrate the platform's utility for deep research agent development, we have collected real user preference data from 17 annotators on three deep research agents. A demo video of our platform can be found at https://www.youtube.com/watch?v=g4d2dnbdseg.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Empowering Healthcare Practitioners with Language Models: Structuring Speech Transcripts in Two Real-World Clinical Applications</title>
<link>https://arxiv.org/abs/2507.05517</link>
<guid>https://arxiv.org/abs/2507.05517</guid>
<content:encoded><![CDATA[
arXiv:2507.05517v1 Announce Type: new 
Abstract: Large language models (LLMs) such as GPT-4o and o1 have demonstrated strong performance on clinical natural language processing (NLP) tasks across multiple medical benchmarks. Nonetheless, two high-impact NLP tasks - structured tabular reporting from nurse dictations and medical order extraction from doctor-patient consultations - remain underexplored due to data scarcity and sensitivity, despite active industry efforts. Practical solutions to these real-world clinical tasks can significantly reduce the documentation burden on healthcare providers, allowing greater focus on patient care. In this paper, we investigate these two challenging tasks using private and open-source clinical datasets, evaluating the performance of both open- and closed-weight LLMs, and analyzing their respective strengths and limitations. Furthermore, we propose an agentic pipeline for generating realistic, non-sensitive nurse dictations, enabling structured extraction of clinical observations. To support further research in both areas, we release SYNUR and SIMORD, the first open-source datasets for nurse observation extraction and medical order extraction.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cultivating Multimodal Intelligence: Interpretive Reasoning and Agentic RAG Approaches to Dermatological Diagnosis</title>
<link>https://arxiv.org/abs/2507.05520</link>
<guid>https://arxiv.org/abs/2507.05520</guid>
<content:encoded><![CDATA[
arXiv:2507.05520v1 Announce Type: new 
Abstract: The second edition of the 2025 ImageCLEF MEDIQA-MAGIC challenge, co-organized by researchers from Microsoft, Stanford University, and the Hospital Clinic of Barcelona, focuses on multimodal dermatology question answering and segmentation, using real-world patient queries and images. This work addresses the Closed Visual Question Answering (CVQA) task, where the goal is to select the correct answer to multiple-choice clinical questions based on both user-submitted images and accompanying symptom descriptions. The proposed approach combines three core components: (1) fine-tuning open-source multimodal models from the Qwen, Gemma, and LLaMA families on the competition dataset, (2) introducing a structured reasoning layer that reconciles and adjudicates between candidate model outputs, and (3) incorporating agentic retrieval-augmented generation (agentic RAG), which adds relevant information from the American Academy of Dermatology's symptom and condition database to fill in gaps in patient context. The team achieved second place with a submission that scored sixth, demonstrating competitive performance and high accuracy. Beyond competitive benchmarks, this research addresses a practical challenge in telemedicine: diagnostic decisions must often be made asynchronously, with limited input and with high accuracy and interpretability. By emulating the systematic reasoning patterns employed by dermatologists when evaluating skin conditions, this architecture provided a pathway toward more reliable automated diagnostic support systems.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Conversational Education at Scale: A Multi-LLM Agent Workflow for Procedural Learning and Pedagogic Quality Assessment</title>
<link>https://arxiv.org/abs/2507.05528</link>
<guid>https://arxiv.org/abs/2507.05528</guid>
<content:encoded><![CDATA[
arXiv:2507.05528v1 Announce Type: new 
Abstract: Large language models (LLMs) have advanced virtual educators and learners, bridging NLP with AI4Education. Existing work often lacks scalability and fails to leverage diverse, large-scale course content, with limited frameworks for assessing pedagogic quality. To this end, we propose WikiHowAgent, a multi-agent workflow leveraging LLMs to simulate interactive teaching-learning conversations. It integrates teacher and learner agents, an interaction manager, and an evaluator to facilitate procedural learning and assess pedagogic quality. We introduce a dataset of 114,296 teacher-learner conversations grounded in 14,287 tutorials across 17 domains and 727 topics. Our evaluation protocol combines computational and rubric-based metrics with human judgment alignment. Results demonstrate the workflow's effectiveness in diverse setups, offering insights into LLM capabilities across domains. Our datasets and implementations are fully open-sourced.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evolutionary and Coevolutionary Multi-Agent Design Choices and Dynamics</title>
<link>https://arxiv.org/abs/2507.05534</link>
<guid>https://arxiv.org/abs/2507.05534</guid>
<content:encoded><![CDATA[
arXiv:2507.05534v1 Announce Type: new 
Abstract: We investigate two representation alternatives for the controllers of teams of cyber agents. We combine these controller representations with different evolutionary algorithms, one of which introduces a novel LLM-supported mutation operator. Using a cyber security scenario, we evaluate agent learning when one side is trained to compete against a side that does not evolve and when two sides coevolve with each other. This allows us to quantify the relative merits and tradeoffs of representation and algorithm combinations in terms of team performance. Our versions of grammatical evolution algorithms using grammars that allow a controller to be expressed in code-like logic can achieve the best team performance. The scenario also allows us to compare the performance impact and dynamics of coevolution versus evolution under different combinations. Across the algorithms and representations, we observe that coevolution reduces the performance highs and lows of both sides while it induces fluctuations on both sides. In contrast, when only one-side is optimized, performance peaks are higher and is more sustained than when both sides are optimized with coevolution.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Agent Smart Contract Exploit Generation</title>
<link>https://arxiv.org/abs/2507.05558</link>
<guid>https://arxiv.org/abs/2507.05558</guid>
<content:encoded><![CDATA[
arXiv:2507.05558v1 Announce Type: new 
Abstract: We present A1, an agentic execution driven system that transforms any LLM into an end-to-end exploit generator. A1 has no hand-crafted heuristics and provides the agent with six domain-specific tools that enable autonomous vulnerability discovery. The agent can flexibly leverage these tools to understand smart contract behavior, generate exploit strategies, test them on blockchain states, and refine approaches based on execution feedback. All outputs are concretely validated to eliminate false positives.
  The evaluation across 36 real-world vulnerable contracts on Ethereum and Binance Smart Chain demonstrates a 62.96% (17 out of 27) success rate on the VERITE benchmark. Beyond the VERITE dataset, A1 identified 9 additional vulnerable contracts, with 5 cases occurring after the strongest model's training cutoff date. Across all 26 successful cases, A1 extracts up to 8.59 million USD per case and 9.33 million USD total. Through 432 experiments across six LLMs, we analyze iteration-wise performance showing diminishing returns with average marginal gains of +9.7%, +3.7%, +5.1%, and +2.8% for iterations 2-5 respectively, with per-experiment costs ranging $0.01-$3.59. A Monte Carlo analysis of 19 historical attacks shows success probabilities of 85.9%-88.8% without detection delays.
  We investigate whether an attacker or a defender benefits most from deploying A1 as a continuous on-chain scanning system. Our model shows that OpenAI's o3-pro maintains profitability up to a 30.0 days scanning delay at 0.100% vulnerability incidence rates, while faster models require >=1.000% rates to break-even. The findings exposes a troubling asymmetry: at 0.1% vulnerability rates, attackers achieve an on-chain scanning profitability at a $6000 exploit value, while defenders require $60000, raising fundamental questions about whether AI agents inevitably favor exploitation over defense.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Preemptive Solving of Future Problems: Multitask Preplay in Humans and Machines</title>
<link>https://arxiv.org/abs/2507.05561</link>
<guid>https://arxiv.org/abs/2507.05561</guid>
<content:encoded><![CDATA[
arXiv:2507.05561v1 Announce Type: new 
Abstract: Humans can pursue a near-infinite variety of tasks, but typically can only pursue a small number at the same time. We hypothesize that humans leverage experience on one task to preemptively learn solutions to other tasks that were accessible but not pursued. We formalize this idea as Multitask Preplay, a novel algorithm that replays experience on one task as the starting point for "preplay" -- counterfactual simulation of an accessible but unpursued task. Preplay is used to learn a predictive representation that can support fast, adaptive task performance later on. We first show that, compared to traditional planning and predictive representation methods, multitask preplay better predicts how humans generalize to tasks that were accessible but not pursued in a small grid-world, even when people didn't know they would need to generalize to these tasks. We then show these predictions generalize to Craftax, a partially observable 2D Minecraft environment. Finally, we show that Multitask Preplay enables artificial agents to learn behaviors that transfer to novel Craftax worlds sharing task co-occurrence structure. These findings demonstrate that Multitask Preplay is a scalable theory of how humans counterfactually learn and generalize across multiple tasks; endowing artificial agents with the same capacity can significantly improve their performance in challenging multitask environments.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting and Mitigating Reward Hacking in Reinforcement Learning Systems: A Comprehensive Empirical Study</title>
<link>https://arxiv.org/abs/2507.05619</link>
<guid>https://arxiv.org/abs/2507.05619</guid>
<content:encoded><![CDATA[
arXiv:2507.05619v1 Announce Type: new 
Abstract: Reward hacking in Reinforcement Learning (RL) systems poses a critical threat to the deployment of autonomous agents, where agents exploit flaws in reward functions to achieve high scores without fulfilling intended objectives. Despite growing awareness of this problem, systematic detection and mitigation approaches remain limited. This paper presents a large-scale empirical study of reward hacking across diverse RL environments and algorithms. We analyze 15,247 training episodes across 15 RL environments (Atari, MuJoCo, custom domains) and 5 algorithms (PPO, SAC, DQN, A3C, Rainbow), implementing automated detection algorithms for six categories of reward hacking: specification gaming, reward tampering, proxy optimization, objective misalignment, exploitation patterns, and wireheading. Our detection framework achieves 78.4% precision and 81.7% recall across environments, with computational overhead under 5%. Through controlled experiments varying reward function properties, we demonstrate that reward density and alignment with true objectives significantly impact hacking frequency ($p < 0.001$, Cohen's $d = 1.24$). We validate our approach through three simulated application studies representing recommendation systems, competitive gaming, and robotic control scenarios. Our mitigation techniques reduce hacking frequency by up to 54.6% in controlled scenarios, though we find these trade-offs are more challenging in practice due to concept drift, false positive costs, and adversarial adaptation. All detection algorithms, datasets, and experimental protocols are publicly available to support reproducible research in RL safety.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How Not to Detect Prompt Injections with an LLM</title>
<link>https://arxiv.org/abs/2507.05630</link>
<guid>https://arxiv.org/abs/2507.05630</guid>
<content:encoded><![CDATA[
arXiv:2507.05630v1 Announce Type: new 
Abstract: LLM-integrated applications and agents are vulnerable to prompt injection attacks, in which adversaries embed malicious instructions within seemingly benign user inputs to manipulate the LLM's intended behavior. Recent defenses based on $\textit{known-answer detection}$ (KAD) have achieved near-perfect performance by using an LLM to classify inputs as clean or contaminated. In this work, we formally characterize the KAD framework and uncover a structural vulnerability in its design that invalidates its core security premise. We design a methodical adaptive attack, $\textit{DataFlip}$, to exploit this fundamental weakness. It consistently evades KAD defenses with detection rates as low as $1.5\%$ while reliably inducing malicious behavior with success rates of up to $88\%$, without needing white-box access to the LLM or any optimization procedures.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLMs are Introvert</title>
<link>https://arxiv.org/abs/2507.05638</link>
<guid>https://arxiv.org/abs/2507.05638</guid>
<content:encoded><![CDATA[
arXiv:2507.05638v1 Announce Type: new 
Abstract: The exponential growth of social media and generative AI has transformed information dissemination, fostering connectivity but also accelerating the spread of misinformation. Understanding information propagation dynamics and developing effective control strategies is essential to mitigate harmful content. Traditional models, such as SIR, provide basic insights but inadequately capture the complexities of online interactions. Advanced methods, including attention mechanisms and graph neural networks, enhance accuracy but typically overlook user psychology and behavioral dynamics. Large language models (LLMs), with their human-like reasoning, offer new potential for simulating psychological aspects of information spread. We introduce an LLM-based simulation environment capturing agents' evolving attitudes, emotions, and responses. Initial experiments, however, revealed significant gaps between LLM-generated behaviors and authentic human dynamics, especially in stance detection and psychological realism. A detailed evaluation through Social Information Processing Theory identified major discrepancies in goal-setting and feedback evaluation, stemming from the lack of emotional processing in standard LLM training. To address these issues, we propose the Social Information Processing-based Chain of Thought (SIP-CoT) mechanism enhanced by emotion-guided memory. This method improves the interpretation of social cues, personalization of goals, and evaluation of feedback. Experimental results confirm that SIP-CoT-enhanced LLM agents more effectively process social information, demonstrating behaviors, attitudes, and emotions closer to real human interactions. In summary, this research highlights critical limitations in current LLM-based propagation simulations and demonstrates how integrating SIP-CoT and emotional memory significantly enhances the social intelligence and realism of LLM agents.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ECom-Bench: Can LLM Agent Resolve Real-World E-commerce Customer Support Issues?</title>
<link>https://arxiv.org/abs/2507.05639</link>
<guid>https://arxiv.org/abs/2507.05639</guid>
<content:encoded><![CDATA[
arXiv:2507.05639v1 Announce Type: new 
Abstract: In this paper, we introduce ECom-Bench, the first benchmark framework for evaluating LLM agent with multimodal capabilities in the e-commerce customer support domain. ECom-Bench features dynamic user simulation based on persona information collected from real e-commerce customer interactions and a realistic task dataset derived from authentic e-commerce dialogues. These tasks, covering a wide range of business scenarios, are designed to reflect real-world complexities, making ECom-Bench highly challenging. For instance, even advanced models like GPT-4o achieve only a 10-20% pass^3 metric in our benchmark, highlighting the substantial difficulties posed by complex e-commerce scenarios. Upon publication, the code and data will be open-sourced to facilitate further research and development in this domain.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
</item>
</channel>
</rss>