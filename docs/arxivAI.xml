<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>Empirical Research on Utilizing LLM-based Agents for Automated Bug Fixing via LangGraph</title>
<link>https://arxiv.org/abs/2502.18465</link>
<guid>https://arxiv.org/abs/2502.18465</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化代码生成、调试框架、LangGraph、GLM4 Flash、ChromaDB

总结:
本文提出了一种用于自动化代码生成和调试的新颖框架，旨在提升软件开发的准确性、效率和可扩展性。该框架整合了三个核心组件：LangGraph（用于以图为基础的任务编排库，提供精确控制与执行，并维持统一状态对象进行动态更新和一致性保持）、GLM4 Flash（一款大型语言模型，利用其在自然语言理解、语境推理和多语言支持方面的高级能力来根据用户提示生成准确的代码片段）以及ChromaDB（作为语义搜索和上下文记忆存储的向量数据库，能够识别模式并基于历史数据生成上下文感知的bug修复）。整个系统通过四个步骤迭代工作：(1) 代码生成，将自然语言描述转化为可执行代码；(2) 代码执行，通过识别运行时错误和不一致之处验证代码；(3) 代码修复，利用ChromaDB的记忆能力和LangGraph的状态追踪对有误代码进行迭代改进；(4) 代码更新，确保代码满足功能性和性能需求并通过迭代修改不断优化。 <div>
arXiv:2502.18465v1 Announce Type: new 
Abstract: This paper presents a novel framework for automated code generation and debugging, designed to improve accuracy, efficiency, and scalability in software development. The proposed system integrates three core components LangGraph, GLM4 Flash, and ChromaDB within a four step iterative workflow to deliver robust performance and seamless functionality.
  LangGraph serves as a graph-based library for orchestrating tasks, providing precise control and execution while maintaining a unified state object for dynamic updates and consistency. It supports multi-agent, hierarchical, and sequential processes, making it highly adaptable to complex software engineering workflows. GLM4 Flash, a large language model, leverages its advanced capabilities in natural language understanding, contextual reasoning, and multilingual support to generate accurate code snippets based on user prompts. ChromaDB acts as a vector database for semantic search and contextual memory storage, enabling the identification of patterns and the generation of context-aware bug fixes based on historical data.
  The system operates through a structured four-step process: (1) Code Generation, which translates natural language descriptions into executable code; (2) Code Execution, which validates the code by identifying runtime errors and inconsistencies; (3) Code Repair, which iteratively refines buggy code using ChromaDB's memory capabilities and LangGraph's state tracking; and (4) Code Update, which ensures the code meets functional and performance requirements through iterative modifications.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data</title>
<link>https://arxiv.org/abs/2502.18471</link>
<guid>https://arxiv.org/abs/2502.18471</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、金融查询、实时信息、Financial Agent、FinBloom 7B

<br><br>总结:
本文提出了一个名为“Financial Agent”的知识接地方法，旨在利用实时文本和表格数据使大型语言模型更好地处理涉及实时信息的金融查询。文章有三个主要贡献：首先，构建了一个包含超过5万条金融查询及其所需上下文的金融上下文数据集；其次，训练了一个定制的70亿参数的大规模语言模型FinBloom 7B，该模型基于1400万篇路透社和德意志新闻社的金融新闻文章以及1200万份美国证券交易委员会(SEC)的备案文件进行训练；最后，通过使用金融上下文数据集对FinBloom 7B进行微调，使其能够作为Financial Agent生成相关的金融上下文并有效实现实时数据检索以回答用户查询。这种方法显著提高了LLMs处理动态金融任务的能力，减少了延迟，消除了用户手动提供准确数据的需求，使得实时金融决策、算法交易等任务更加高效流畅，在高流量数据环境中具有很高的价值。 <div>
arXiv:2502.18471v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at generating human-like responses but often struggle with interactive tasks that require access to real-time information. This limitation poses challenges in finance, where models must access up-to-date information, such as recent news or price movements, to support decision-making. To address this, we introduce Financial Agent, a knowledge-grounding approach for LLMs to handle financial queries using real-time text and tabular data. Our contributions are threefold: First, we develop a Financial Context Dataset of over 50,000 financial queries paired with the required context. Second, we train FinBloom 7B, a custom 7 billion parameter LLM, on 14 million financial news articles from Reuters and Deutsche Presse-Agentur, alongside 12 million Securities and Exchange Commission (SEC) filings. Third, we fine-tune FinBloom 7B using the Financial Context Dataset to serve as a Financial Agent. This agent generates relevant financial context, enabling efficient real-time data retrieval to answer user queries. By reducing latency and eliminating the need for users to manually provide accurate data, our approach significantly enhances the capability of LLMs to handle dynamic financial tasks. Our proposed approach makes real-time financial decisions, algorithmic trading and other related tasks streamlined, and is valuable in contexts with high-velocity data flows.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Physical Depth-aware Early Accident Anticipation: A Multi-dimensional Visual Feature Fusion Framework</title>
<link>https://arxiv.org/abs/2502.18496</link>
<guid>https://arxiv.org/abs/2502.18496</guid>
<content:encoded><![CDATA[
<div> 关键词：早期事故预警、dashcam视频、深度感知学习、三维信息、交互特征<br><br>总结:

本文提出了一种新的物理深度感知学习框架，用于从dashcam视频中提前预测交通事故。该框架针对现有方法在二维图像空间建模交通参与者交互可能不足的问题，利用名为Depth-Anything的大模型生成的单目深度特征引入更精细的三维空间信息。同时，整合了视觉交互特征和交通场景的动态视觉特征，以实现对场景的全面感知。通过分析序列帧中物体间的交互关系，捕捉事故的早期迹象。此外，为解决遮挡物体的影响，框架还引入了重建邻接矩阵，维持关键交通参与者的时空连续性。实验结果显示，该框架在公共数据集上达到了最先进的性能，验证了结合视觉深度特征的有效性和所提框架的优越性。 <div>
arXiv:2502.18496v1 Announce Type: new 
Abstract: Early accident anticipation from dashcam videos is a highly desirable yet challenging task for improving the safety of intelligent vehicles. Existing advanced accident anticipation approaches commonly model the interaction among traffic agents (e.g., vehicles, pedestrians, etc.) in the coarse 2D image space, which may not adequately capture their true positions and interactions. To address this limitation, we propose a physical depth-aware learning framework that incorporates the monocular depth features generated by a large model named Depth-Anything to introduce more fine-grained spatial 3D information. Furthermore, the proposed framework also integrates visual interaction features and visual dynamic features from traffic scenes to provide a more comprehensive perception towards the scenes. Based on these multi-dimensional visual features, the framework captures early indicators of accidents through the analysis of interaction relationships between objects in sequential frames. Additionally, the proposed framework introduces a reconstruction adjacency matrix for key traffic participants that are occluded, mitigating the impact of occluded objects on graph learning and maintaining the spatio-temporal continuity. Experimental results on public datasets show that the proposed framework attains state-of-the-art performance, highlighting the effectiveness of incorporating visual depth features and the superiority of the proposed framework.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents</title>
<link>https://arxiv.org/abs/2502.18509</link>
<guid>https://arxiv.org/abs/2502.18509</guid>
<content:encoded><![CDATA[
<div> 关键词: 对话代理、隐私风险、情境隐私、大型语言模型、用户研究

总结:
本文探讨了用户与大型语言模型交互过程中的情境隐私问题，旨在通过确保用户仅向模型透露与其目标相关且必要的信息来最小化隐私风险。文章基于一项形式设计的用户体验研究，发现即使“注重隐私”的用户也可能无意间通过间接方式泄露敏感信息。据此，文章提出了一个部署于用户和大型语言模型之间的局部框架，该框架能够识别并重构用户提示中的非情境信息。通过使用ShareGPT的例子进行评估，研究表明轻量级模型可以有效实现这一框架，同时在保护用户情境隐私的同时，保持用户的互动目标得以实现。 <div>
arXiv:2502.18509v1 Announce Type: new 
Abstract: Conversational agents are increasingly woven into individuals' personal lives, yet users often underestimate the privacy risks involved. The moment users share information with these agents (e.g., LLMs), their private information becomes vulnerable to exposure. In this paper, we characterize the notion of contextual privacy for user interactions with LLMs. It aims to minimize privacy risks by ensuring that users (sender) disclose only information that is both relevant and necessary for achieving their intended goals when interacting with LLMs (untrusted receivers). Through a formative design user study, we observe how even "privacy-conscious" users inadvertently reveal sensitive information through indirect disclosures. Based on insights from this study, we propose a locally-deployable framework that operates between users and LLMs, and identifies and reformulates out-of-context information in user prompts. Our evaluation using examples from ShareGPT shows that lightweight models can effectively implement this framework, achieving strong gains in contextual privacy while preserving the user's intended interaction goals through different approaches to classify information relevant to the intended goals.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition</title>
<link>https://arxiv.org/abs/2502.18510</link>
<guid>https://arxiv.org/abs/2502.18510</guid>
<content:encoded><![CDATA[
<div> 关键词：多教师知识蒸馏、强化学习、权重优化、学生网络、视觉识别任务

总结:
本文提出了一种基于强化学习的多教师知识蒸馏方法（MTKD-RL），旨在解决多教师知识蒸馏中如何平衡各教师的知识转移强度问题。现有的多数方法主要从单个教师的表现或师生差距的角度制定权重策略，而缺乏全面的信息指导。MTKD-RL框架将教师性能和师生差距构建为智能体的状态信息，由智能体输出教师权重并根据学生返回的奖励进行更新。通过强化学习决策机制，MTKD-RL增强了学生与教师间的交互，实现了更有意义的权重分配以及更好的匹配能力。实验结果显示，相比于现有多教师知识蒸馏工作，MTKD-RL在图像分类、物体检测和语义分割等视觉识别任务上均取得了最优性能。 <div>
arXiv:2502.18510v1 Announce Type: new 
Abstract: Multi-teacher Knowledge Distillation (KD) transfers diverse knowledge from a teacher pool to a student network. The core problem of multi-teacher KD is how to balance distillation strengths among various teachers. Most existing methods often develop weighting strategies from an individual perspective of teacher performance or teacher-student gaps, lacking comprehensive information for guidance. This paper proposes Multi-Teacher Knowledge Distillation with Reinforcement Learning (MTKD-RL) to optimize multi-teacher weights. In this framework, we construct both teacher performance and teacher-student gaps as state information to an agent. The agent outputs the teacher weight and can be updated by the return reward from the student. MTKD-RL reinforces the interaction between the student and teacher using an agent in an RL-based decision mechanism, achieving better matching capability with more meaningful weights. Experimental results on visual recognition tasks, including image classification, object detection, and semantic segmentation tasks, demonstrate that MTKD-RL achieves state-of-the-art performance compared to the existing multi-teacher KD works.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Agent Framework for Automated Vulnerability Detection and Repair in Solidity and Move Smart Contracts</title>
<link>https://arxiv.org/abs/2502.18515</link>
<guid>https://arxiv.org/abs/2502.18515</guid>
<content:encoded><![CDATA[
<div> 关键词: Smartify、智能合约、安全检测、修复、多代理框架<br><br>总结:
本文介绍了Smartify，这是一个利用大型语言模型（LLMs）自动检测和修复Solidity与Move智能合约漏洞的创新多代理框架。Smartify不同于传统方法，它采用一组专注于不同专门微调LLM的特化代理，根据底层编程概念和语言特定的安全原则分析代码。通过对Solidity和精心策划的Move合约数据集进行评估，Smartify显示出了在修复多种漏洞方面的优越效果，并超越了现有LLM以及增强了通用模型的能力，如Llama 3.1。尤其值得注意的是，Smartify能够在无需大量语言特定预训练数据集的情况下，融入如Move等语言的特殊知识。这项工作详细分析了各种LLM在智能合约修复性能上的表现，突显了其多代理方法的优势，并为构建更安全可靠的区块链生态系统中的去中心化应用提供了蓝图。同时，文中还提供了将此方法扩展到其他类似应用场景的具体方案。 <div>
arXiv:2502.18515v1 Announce Type: new 
Abstract: The rapid growth of the blockchain ecosystem and the increasing value locked in smart contracts necessitate robust security measures. While languages like Solidity and Move aim to improve smart contract security, vulnerabilities persist. This paper presents Smartify, a novel multi-agent framework leveraging Large Language Models (LLMs) to automatically detect and repair vulnerabilities in Solidity and Move smart contracts. Unlike traditional methods that rely solely on vast pre-training datasets, Smartify employs a team of specialized agents working on different specially fine-tuned LLMs to analyze code based on underlying programming concepts and language-specific security principles. We evaluated Smartify on a dataset for Solidity and a curated dataset for Move, demonstrating its effectiveness in fixing a wide range of vulnerabilities. Our results show that Smartify (Gemma2+codegemma) achieves state-of-the-art performance, surpassing existing LLMs and enhancing general-purpose models' capabilities, such as Llama 3.1. Notably, Smartify can incorporate language-specific knowledge, such as the nuances of Move, without requiring massive language-specific pre-training datasets. This work offers a detailed analysis of various LLMs' performance on smart contract repair, highlighting the strengths of our multi-agent approach and providing a blueprint for developing more secure and reliable decentralized applications in the growing blockchain landscape. We also provide a detailed recipe for extending this to other similar use cases.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Programming with Pixels: Computer-Use Meets Software Engineering</title>
<link>https://arxiv.org/abs/2502.18525</link>
<guid>https://arxiv.org/abs/2502.18525</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件工程、工具基范式、编程与像素、环境、基准测试<br><br>总结: 本文介绍了软件工程领域的最新进展，提出了“编程与像素”（PwP）这一新型环境，该环境允许代理人通过视觉感知、打字和点击直接在IDE中操作，从而统一了各种软件开发任务，突破了传统工具基范式的局限性，不再依赖于特定任务的手动编写工具接口。为了系统评估这类代理人，作者提出了“PwP-Bench”基准测试，它将多个编程语言、模态和领域的现有软件工程基准测试统一到一个任务无关的状态和动作空间下。实验结果显示，通用型计算机使用代理人在多种软件工程任务上的表现可以接近或超越专门的工具基代理，而无需预先定义工具。然而，当前模型存在有限的视觉定位问题，未能充分利用IDE内置工具简化任务。当代理人可以直接访问IDE工具时，其性能显著提升，显示出利用IDE内置功能的未被充分挖掘的潜力。文章认为PwP作为一个可扩展的试验台，为构建和评估下一代软件工程代理人提供了可能性。相关的代码和数据已在https://programmingwithpixels.com网站上发布。 <div>
arXiv:2502.18525v1 Announce Type: new 
Abstract: Recent advancements in software engineering (SWE) agents have largely followed a $\textit{tool-based paradigm}$, where agents interact with hand-engineered tool APIs to perform specific tasks. While effective for specialized tasks, these methods fundamentally lack generalization, as they require predefined tools for each task and do not scale across programming languages and domains. We introduce $\texttt{Programming with Pixels}$ (PwP), an agent environment that unifies software development tasks by enabling $\textit{computer-use agents}$-agents that operate directly within an IDE through visual perception, typing, and clicking, rather than relying on predefined tool APIs. To systematically evaluate these agents, we propose $\texttt{PwP-Bench}$, a benchmark that unifies existing SWE benchmarks spanning tasks across multiple programming languages, modalities, and domains under a task-agnostic state and action space. Our experiments demonstrate that general-purpose computer-use agents can approach or even surpass specialized tool-based agents on a variety of SWE tasks without the need for hand-engineered tools. However, our analysis shows that current models suffer from limited visual grounding and fail to exploit many IDE tools that could simplify their tasks. When agents can directly access IDE tools, without visual interaction, they show significant performance improvements, highlighting the untapped potential of leveraging built-in IDE capabilities. Our results establish PwP as a scalable testbed for building and evaluating the next wave of software engineering agents. We release code and data at https://programmingwithpixels.com
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning-based Approach for Vehicle-to-Building Charging with Heterogeneous Agents and Long Term Rewards</title>
<link>https://arxiv.org/abs/2502.18526</link>
<guid>https://arxiv.org/abs/2502.18526</guid>
<content:encoded><![CDATA[
<div> 关键词: 电动汽车电池、能源储备、智能社区、强化学习、Deep Deterministic Policy Gradient (DDPG)

总结:<br>
本文提出了一种新的强化学习框架，用于解决电动汽车电池的战略性聚合优化电力电网需求的问题，特别关注于提供职场充电的大型办公建筑。该问题涉及在不确定性环境下进行连续决策，并需要处理延迟和稀疏奖励、大规模状态-动作空间以及跨多种条件的泛化能力。针对现有算法如基于启发式策略的方法在动态条件下实时决策的不足，以及传统强化学习模型在处理这些问题上的挑战，本文将DDPG方法与行动掩码和高效的MILP驱动策略指导相结合。实验结果表明，该方法使用某大型电动汽车制造商的真实数据，相比于多个已建立的基线方法和可扩展的启发式方法，能更全面地降低成本并满足所有充电需求，展现出首个可扩展和普适性的V2B能源管理解决方案的优势。 <div>
arXiv:2502.18526v1 Announce Type: new 
Abstract: Strategic aggregation of electric vehicle batteries as energy reservoirs can optimize power grid demand, benefiting smart and connected communities, especially large office buildings that offer workplace charging. This involves optimizing charging and discharging to reduce peak energy costs and net peak demand, monitored over extended periods (e.g., a month), which involves making sequential decisions under uncertainty and delayed and sparse rewards, a continuous action space, and the complexity of ensuring generalization across diverse conditions. Existing algorithmic approaches, e.g., heuristic-based strategies, fall short in addressing real-time decision-making under dynamic conditions, and traditional reinforcement learning (RL) models struggle with large state-action spaces, multi-agent settings, and the need for long-term reward optimization. To address these challenges, we introduce a novel RL framework that combines the Deep Deterministic Policy Gradient approach (DDPG) with action masking and efficient MILP-driven policy guidance. Our approach balances the exploration of continuous action spaces to meet user charging demands. Using real-world data from a major electric vehicle manufacturer, we show that our approach comprehensively outperforms many well-established baselines and several scalable heuristic approaches, achieving significant cost savings while meeting all charging requirements. Our results show that the proposed approach is one of the first scalable and general approaches to solving the V2B energy management challenge.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ARACNE: An LLM-Based Autonomous Shell Pentesting Agent</title>
<link>https://arxiv.org/abs/2502.18528</link>
<guid>https://arxiv.org/abs/2502.18528</guid>
<content:encoded><![CDATA[
<div> 关键词：ARACNE、LLM、SSH服务、自动渗透测试、多模型支持

总结:
ARACNE是一个基于LLM的全自动Linux SSH服务渗透测试代理，具备真实Linux shell系统的命令执行能力。该研究提出了一种新的代理架构，支持多LLM模型。实验结果显示，ARACNE对自主防御者ShelLM的成功攻击率为60%，对Over The Wire Bandit CTF挑战的成功攻击率为57.58%，超越了现有技术的水平。当ARACNE获胜时，平均完成目标所需的行动次数少于5次。这表明使用多LLM模型的方法对于提高行动准确性具有很大的潜力。 <div>
arXiv:2502.18528v1 Announce Type: new 
Abstract: We introduce ARACNE, a fully autonomous LLM-based pentesting agent tailored for SSH services that can execute commands on real Linux shell systems. Introduces a new agent architecture with multi-LLM model support. Experiments show that ARACNE can reach a 60\% success rate against the autonomous defender ShelLM and a 57.58\% success rate against the Over The Wire Bandit CTF challenges, improving over the state-of-the-art. When winning, the average number of actions taken by the agent to accomplish the goals was less than 5. The results show that the use of multi-LLM is a promising approach to increase accuracy in the actions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>IMPROVE: Iterative Model Pipeline Refinement and Optimization Leveraging LLM Agents</title>
<link>https://arxiv.org/abs/2502.18530</link>
<guid>https://arxiv.org/abs/2502.18530</guid>
<content:encoded><![CDATA[
<div> 关键词: 计算机视觉、机器学习、大语言模型、迭代细化、IMPROVE

总结:
这篇论文介绍了一个用于优化计算机视觉模型设计的新策略——迭代细化（Iterative Refinement），该策略受到人类机器学习专家逐步优化模型方式的启发。传统上，开发高性能的计算机视觉模型需要机器学习和领域专业知识，而大型语言模型（LLM）代理已成为自动化这一流程的潜在解决方案。然而，现有的大多数方法尝试一次性优化整个流程，导致改进难以归因于特定变化，从而影响稳定性和收敛速度。为解决这个问题，文章提出了名为IMPROVE的端到端LLM代理框架，它运用迭代细化策略，逐个更新基于真实训练反馈的组件，提高了稳定性、可解释性以及整体模型性能。通过在不同规模和领域的数据集上的广泛评估，包括标准基准数据集和Kaggle竞赛数据集，研究显示迭代细化使IMPROVE能够持续超越现有基于LLM的一步式方法并实现更好的性能。因此，迭代细化被确立为一种有效的LLM驱动的机器学习自动化新策略，并使得IMPROVE成为一个无需具备机器学习专业知识即可构建高质量计算机视觉模型的可行方案。 <div>
arXiv:2502.18530v1 Announce Type: new 
Abstract: Computer vision is a critical component in a wide range of real-world applications, including plant monitoring in agriculture and handwriting classification in digital systems. However, developing high-performance computer vision models traditionally demands both machine learning (ML) expertise and domain-specific knowledge, making the process costly, labor-intensive, and inaccessible to many. Large language model (LLM) agents have emerged as a promising solution to automate this workflow, but most existing methods share a common limitation: they attempt to optimize entire pipelines in a single step before evaluation, making it difficult to attribute improvements to specific changes. This lack of granularity leads to unstable optimization and slower convergence, limiting their effectiveness. To address this, we introduce Iterative Refinement, a novel strategy for LLM-driven ML pipeline design inspired by how human ML experts iteratively refine models, focusing on one component at a time rather than making sweeping changes all at once. By systematically updating individual components based on real training feedback, Iterative Refinement improves stability, interpretability, and overall model performance. We implement this strategy in IMPROVE, an end-to-end LLM agent framework for automating and optimizing object classification pipelines. Through extensive evaluations across datasets of varying sizes and domains, including standard benchmarks and Kaggle competition datasets, we demonstrate that Iterative Refinement enables IMPROVE to consistently achieve better performance over existing zero-shot LLM-based approaches. These findings establish Iterative Refinement as an effective new strategy for LLM-driven ML automation and position IMPROVE as an accessible solution for building high-quality computer vision models without requiring ML expertise.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAFE: Multi-Agent Fair Environments for Decision-Making Systems</title>
<link>https://arxiv.org/abs/2502.18534</link>
<guid>https://arxiv.org/abs/2502.18534</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 公平性约束, 多智能体系统, 动态环境, Multi-Agent Fair Environment (MAFE)

<br><br>总结:
该文关注静态环境下应用于机器学习模型的公平性约束可能导致随着时间推移对某些人口群体产生不利影响的问题。为解决这一问题，研究开始转向创建能够随时间保持公平性的解决方案。文章指出，在现实世界系统中，多智能体之间的相互作用往往会影响结果，因此将这些实体建模为代理能更灵活地分析其干预措施及对系统动态的影响。然而，当前在多智能体系统方面的研究缺乏利用有限的真实世界数据进行分析的逼真环境。为此，文章提出了Multi-Agent Fair Environment (MAFE)的概念，并构建和分析了三个模拟不同社会系统的MAFE实例。实验结果验证了MAFE作为开发多智能体公平算法测试平台的有效性。 <div>
arXiv:2502.18534v1 Announce Type: new 
Abstract: Fairness constraints applied to machine learning (ML) models in static contexts have been shown to potentially produce adverse outcomes among demographic groups over time. To address this issue, emerging research focuses on creating fair solutions that persist over time. While many approaches treat this as a single-agent decision-making problem, real-world systems often consist of multiple interacting entities that influence outcomes. Explicitly modeling these entities as agents enables more flexible analysis of their interventions and the effects they have on a system's underlying dynamics. A significant challenge in conducting research on multi-agent systems is the lack of realistic environments that leverage the limited real-world data available for analysis. To address this gap, we introduce the concept of a Multi-Agent Fair Environment (MAFE) and present and analyze three MAFEs that model distinct social systems. Experimental results demonstrate the utility of our MAFEs as testbeds for developing multi-agent fair algorithms.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning</title>
<link>https://arxiv.org/abs/2502.18535</link>
<guid>https://arxiv.org/abs/2502.18535</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 零知识证明, 隐私保护, 模型验证, 未来发展方向

<br><br>总结:
这篇论文是对从2017年6月至2024年12月期间关于零知识机器学习（ZKML）研究的全面调查。随着机器学习技术在各领域的迅速发展，数据隐私和模型安全问题日益凸显，尤其是在云端平台或第三方服务器上训练和部署模型的情况。为解决这些问题，零知识证明技术作为一种有前途的解决方案应运而生，能够在不泄露敏感数据的情况下验证模型性能和真实性。文章首先介绍了ZKML的概念及其在三个关键类别（可验证训练、可验证推理和可验证测试）下的ZKP算法设置。接着，对现有ZKML研究进行了详细分类与分析，探讨了该领域所面临的实现挑战及改进措施，并举例说明了ZKML技术的一些商业应用。最后，文章提出了该领域未来发展的几个具有潜力的研究方向。 <div>
arXiv:2502.18535v1 Announce Type: new 
Abstract: As machine learning technologies advance rapidly across various domains, concerns over data privacy and model security have grown significantly. These challenges are particularly pronounced when models are trained and deployed on cloud platforms or third-party servers due to the computational resource limitations of users' end devices. In response, zero-knowledge proof (ZKP) technology has emerged as a promising solution, enabling effective validation of model performance and authenticity in both training and inference processes without disclosing sensitive data. Thus, ZKP ensures the verifiability and security of machine learning models, making it a valuable tool for privacy-preserving AI. Although some research has explored the verifiable machine learning solutions that exploit ZKP, a comprehensive survey and summary of these efforts remain absent. This survey paper aims to bridge this gap by reviewing and analyzing all the existing Zero-Knowledge Machine Learning (ZKML) research from June 2017 to December 2024. We begin by introducing the concept of ZKML and outlining its ZKP algorithmic setups under three key categories: verifiable training, verifiable inference, and verifiable testing. Next, we provide a comprehensive categorization of existing ZKML research within these categories and analyze the works in detail. Furthermore, we explore the implementation challenges faced in this field and discuss the improvement works to address these obstacles. Additionally, we highlight several commercial applications of ZKML technology. Finally, we propose promising directions for future advancements in this domain.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications</title>
<link>https://arxiv.org/abs/2502.18540</link>
<guid>https://arxiv.org/abs/2502.18540</guid>
<content:encoded><![CDATA[
<div> 关键词：MA-GTS、多智能体、图论问题、大语言模型、效率

总结:
本文提出了一种名为MA-GTS的多智能体图论求解器框架，用于解决现实世界中的复杂、噪声和不规则图论问题。MA-GTS能够将文本形式的图数据转化为清晰、结构化的图表示，并根据问题约束和图结构规模动态选择最合适的算法，确保解决方案的高效性和解释性。为了验证MA-GTS的有效性，文章创建了基于真实世界的图论数据集G-REAL，并通过对比实验表明，MA-GTS在效率、准确性和可扩展性方面优于现有最优方法，在多个基准测试（如G-REAL 94.2%，GraCoRe 96.9%，NLGraph 98.4%）中表现出色。此外，MA-GTS已开源，可在https://github.com/ZIKEYUAN/MA-GTS.git获取。<br><br> <div>
arXiv:2502.18540v1 Announce Type: new 
Abstract: Graph-theoretic problems arise in real-world applications like logistics, communication networks, and traffic optimization. These problems are often complex, noisy, and irregular, posing challenges for traditional algorithms. Large language models (LLMs) offer potential solutions but face challenges, including limited accuracy and input length constraints. To address these challenges, we propose MA-GTS (Multi-Agent Graph Theory Solver), a multi-agent framework that decomposes these complex problems through agent collaboration. MA-GTS maps the implicitly expressed text-based graph data into clear, structured graph representations and dynamically selects the most suitable algorithm based on problem constraints and graph structure scale. This approach ensures that the solution process remains efficient and the resulting reasoning path is interpretable. We validate MA-GTS using the G-REAL dataset, a real-world-inspired graph theory dataset we created. Experimental results show that MA-GTS outperforms state-of-the-art approaches in terms of efficiency, accuracy, and scalability, with strong results across multiple benchmarks (G-REAL 94.2%, GraCoRe 96.9%, NLGraph 98.4%).MA-GTS is open-sourced at https://github.com/ZIKEYUAN/MA-GTS.git.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Steganography Beyond Space-Time With Chain of Multimodal AI Agents</title>
<link>https://arxiv.org/abs/2502.18547</link>
<guid>https://arxiv.org/abs/2502.18547</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、steganography（隐写术）、音频视觉媒体、多模态代理、消息安全性

总结:
<br>
本文探讨了随着人工智能技术的发展，合成内容对隐写术带来的挑战。为了解决音频视觉媒体中信号在空间和时间域易被篡改的问题，研究提出了一种新的跨空间和时间域的音频视觉媒体隐写方案。该方案利用多模态代理将音视频内容分解为文本封面，通过在语言域内嵌入消息然后再重建音视频内容。消息通过引导语言生成模型的词采样过程进行编码，并通过对词汇选择概率分布的分析实现解码。实验评估了零比特和多比特容量设置下的信息传输准确性，并从生物识别和语义相似性两方面考察了保真度，同时检查了隐写文本与原始文本之间的统计差异以验证保密性。最后，针对音频压缩、面部交换、语音克隆及其组合等不同场景测试了方案的鲁棒性。 <div>
arXiv:2502.18547v1 Announce Type: new 
Abstract: Steganography is the art and science of covert writing, with a broad range of applications interwoven within the realm of cybersecurity. As artificial intelligence continues to evolve, its ability to synthesise realistic content emerges as a threat in the hands of cybercriminals who seek to manipulate and misrepresent the truth. Such synthetic content introduces a non-trivial risk of overwriting the subtle changes made for the purpose of steganography. When the signals in both the spatial and temporal domains are vulnerable to unforeseen overwriting, it calls for reflection on what can remain invariant after all. This study proposes a paradigm in steganography for audiovisual media, where messages are concealed beyond both spatial and temporal domains. A chain of multimodal agents is developed to deconstruct audiovisual content into a cover text, embed a message within the linguistic domain, and then reconstruct the audiovisual content through synchronising both aural and visual modalities with the resultant stego text. The message is encoded by biasing the word sampling process of a language generation model and decoded by analysing the probability distribution of word choices. The accuracy of message transmission is evaluated under both zero-bit and multi-bit capacity settings. Fidelity is assessed through both biometric and semantic similarities, capturing the identities of the recorded face and voice, as well as the core ideas conveyed through the media. Secrecy is examined through statistical comparisons between cover and stego texts. Robustness is tested across various scenarios, including audiovisual compression, face-swapping, voice-cloning and their combinations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Error-related Potential driven Reinforcement Learning for adaptive Brain-Computer Interfaces</title>
<link>https://arxiv.org/abs/2502.18594</link>
<guid>https://arxiv.org/abs/2502.18594</guid>
<content:encoded><![CDATA[
<div> 关键词：脑机接口（BCI）、非侵入式、电位图（EEG）、错误相关电位（ErrPs）、强化学习（RL）

总结：
本文介绍了一种使用强化学习（RL）的新型自适应错误相关电位（ErrP）基脑机接口（BCI）方法。该研究利用两种RL代理，构建了一个能够动态适应电位图（EEG）非平稳性的框架，将ErrPs和运动想象结合起来。通过公开可用的运动想象数据集和一款旨在提高用户参与度的快节奏游戏进行验证，结果表明该框架具有可行性，RL代理能从用户交互中学习控制策略并实现稳健的性能。然而，游戏协议中的关键发现指出，在高时效性互动范式下，大部分参与者无法有效地运用运动想象，揭示了实时BCI应用中任务设计复杂性和用户响应性方面的实际限制。这些发现强调了RL在自适应BCI中的潜力，同时也指出了与任务复杂度及用户响应性相关的实际约束问题。 <div>
arXiv:2502.18594v1 Announce Type: new 
Abstract: Brain-computer interfaces (BCIs) provide alternative communication methods for individuals with motor disabilities by allowing control and interaction with external devices. Non-invasive BCIs, especially those using electroencephalography (EEG), are practical and safe for various applications. However, their performance is often hindered by EEG non-stationarities, caused by changing mental states or device characteristics like electrode impedance. This challenge has spurred research into adaptive BCIs that can handle such variations. In recent years, interest has grown in using error-related potentials (ErrPs) to enhance BCI performance. ErrPs, neural responses to errors, can be detected non-invasively and have been integrated into different BCI paradigms to improve performance through error correction or adaptation.
  This research introduces a novel adaptive ErrP-based BCI approach using reinforcement learning (RL). We demonstrate the feasibility of an RL-driven adaptive framework incorporating ErrPs and motor imagery. Utilizing two RL agents, the framework adapts dynamically to EEG non-stationarities. Validation was conducted using a publicly available motor imagery dataset and a fast-paced game designed to boost user engagement. Results show the framework's promise, with RL agents learning control policies from user interactions and achieving robust performance across datasets. However, a critical insight from the game-based protocol revealed that motor imagery in a high-speed interaction paradigm was largely ineffective for participants, highlighting task design limitations in real-time BCI applications. These findings underscore the potential of RL for adaptive BCIs while pointing out practical constraints related to task complexity and user responsiveness.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources</title>
<link>https://arxiv.org/abs/2502.18650</link>
<guid>https://arxiv.org/abs/2502.18650</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型，对话生成，人力资源，面试，双促发型方法

总结:
本文对比了两种基于大型语言模型（LLM）的人力资源面试场景对话生成方法。这两种方法分别为：单一提示生成完整面试对话和两个代理人之间交互式对话生成。为了评估不同方法下对话的质量，研究者使用了一个判别器LLM进行AI生成面试对话与真实人类对话的二选一对比。结果显示，尽管双促发型方法的令牌成本增加了六倍，但其生成的面试对话在赢得质量判断上的胜率却比单一提示方法高出十倍之多。这一结果在使用GPT-4o或Llama 3.3 70B进行对话生成或质量评判时都保持了一致性。 <div>
arXiv:2502.18650v1 Announce Type: new 
Abstract: Optimizing language models for use in conversational agents requires large quantities of example dialogues. Increasingly, these dialogues are synthetically generated by using powerful large language models (LLMs), especially in domains with challenges to obtain authentic human data. One such domain is human resources (HR). In this context, we compare two LLM-based dialogue generation methods for the use case of generating HR job interviews, and assess whether one method generates higher-quality dialogues that are more challenging to distinguish from genuine human discourse. The first method uses a single prompt to generate the complete interview dialog. The second method uses two agents that converse with each other. To evaluate dialogue quality under each method, we ask a judge LLM to determine whether AI was used for interview generation, using pairwise interview comparisons. We demonstrate that despite a sixfold increase in token cost, interviews generated with the dual-prompt method achieve a win rate up to ten times higher than those generated with the single-prompt method. This difference remains consistent regardless of whether GPT-4o or Llama 3.3 70B is used for either interview generation or judging quality.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Independent Mobility GPT (IDM-GPT): A Self-Supervised Multi-Agent Large Language Model Framework for Customized Traffic Mobility Analysis Using Machine Learning Models</title>
<link>https://arxiv.org/abs/2502.18652</link>
<guid>https://arxiv.org/abs/2502.18652</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通大数据、机器学习、人工智能、多智能体框架、独立移动GPT（IDM-GPT）、大型语言模型、数据隐私、交通分析、管理建议、用户查询理解、性能优化

总结:<br>
随着城市化进程加快，大量传感器被部署于交通系统中，产生了海量的大数据。为解决由此带来的交通挑战，研究团队提出了一种基于大型语言模型（LLMs）的创新性多智能体框架——独立移动GPT（IDM-GPT）。该框架旨在实现定制化的交通分析和管理建议，并注重隐私保护。IDM-GPT经济高效地连接了用户、交通运输数据库及机器学习模型，通过训练和定制多种基于LLM的人工智能代理来处理包括用户查询理解、提示优化、数据分析、模型选择及性能评估与提升等任务。这使得不具备交通或机器学习背景的用户也能实时获取定制化数据分析与建议。实验结果显示，IDM-GPT在多个交通相关任务上表现出色，能够提供全面而实用的见解，支持有效的交通管理和城市流动性提升。 <div>
arXiv:2502.18652v1 Announce Type: new 
Abstract: With the urbanization process, an increasing number of sensors are being deployed in transportation systems, leading to an explosion of big data. To harness the power of this vast transportation data, various machine learning (ML) and artificial intelligence (AI) methods have been introduced to address numerous transportation challenges. However, these methods often require significant investment in data collection, processing, storage, and the employment of professionals with expertise in transportation and ML. Additionally, privacy issues are a major concern when processing data for real-world traffic control and management. To address these challenges, the research team proposes an innovative Multi-agent framework named Independent Mobility GPT (IDM-GPT) based on large language models (LLMs) for customized traffic analysis, management suggestions, and privacy preservation. IDM-GPT efficiently connects users, transportation databases, and ML models economically. IDM-GPT trains, customizes, and applies various LLM-based AI agents for multiple functions, including user query comprehension, prompts optimization, data analysis, model selection, and performance evaluation and enhancement. With IDM-GPT, users without any background in transportation or ML can efficiently and intuitively obtain data analysis and customized suggestions in near real-time based on their questions. Experimental results demonstrate that IDM-GPT delivers satisfactory performance across multiple traffic-related tasks, providing comprehensive and actionable insights that support effective traffic management and urban mobility improvement.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Text Classification with a Novel Multi-Agent Collaboration Framework Leveraging BERT</title>
<link>https://arxiv.org/abs/2502.18653</link>
<guid>https://arxiv.org/abs/2502.18653</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体协作框架、文本分类、BERT、低置信度预测、准确性提升

总结:
我们提出了一种新颖的多智能体协作框架，旨在提高文本分类模型的准确性和鲁棒性。该框架利用BERT作为主要分类器，并将低置信度预测动态升级到由词法、语境、逻辑、共识和可解释性等专门代理组成的多智能体系统进行分析与决策。这种协同方法使得在各种文本分类任务中的性能显著提升。实证评估显示，相比于标准基于BERT的分类器，我们的框架在基准数据集上实现了5.5%的精度提升，从而证实了其在自然语言处理领域中推进多智能体系统发展的有效性和学术创新性。<br><br> <div>
arXiv:2502.18653v1 Announce Type: new 
Abstract: We introduce a novel multi-agent collaboration framework designed to enhance the accuracy and robustness of text classification models. Leveraging BERT as the primary classifier, our framework dynamically escalates low-confidence predictions to a specialized multi-agent system comprising Lexical, Contextual, Logic, Consensus, and Explainability agents. This collaborative approach allows for comprehensive analysis and consensus-driven decision-making, significantly improving classification performance across diverse text classification tasks. Empirical evaluations on benchmark datasets demonstrate that our framework achieves a 5.5% increase in accuracy compared to standard BERT-based classifiers, underscoring its effectiveness and academic novelty in advancing multi-agent systems within natural language processing.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support</title>
<link>https://arxiv.org/abs/2502.18658</link>
<guid>https://arxiv.org/abs/2502.18658</guid>
<content:encoded><![CDATA[
<div> 关键词: AI编程工具、主动式AI代理、Codellaborator、编程工作流、用户研究

总结:
本文探讨了AI编程工具对编程工作流程的影响，并介绍了名为Codellaborator的设计探针LLM代理，该代理能基于编辑活动和任务上下文主动提供编程协助。研究对比了三种接口变体：仅提示、主动式代理和带有存在感与交互上下文支持的主动式代理（Codellaborator）。通过一项包含18名参与者的嵌套式研究，发现主动式代理相较于仅提示的方式能提高效率，但也可能导致工作流程中断。然而，存在指示器和交互上下文支持能够减轻中断并提升用户对AI过程的认识。文章强调了 Codellaborator 在用户控制、所有权以及代码理解方面的权衡，并指出需要根据编程过程调整AI系统的主动性。此项研究为集成AI的编程工作流程设计提供了探索与评估的新见解，并提出了相关设计启示。 <div>
arXiv:2502.18658v1 Announce Type: new 
Abstract: AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and \revise{interaction context support} alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Speaking the Right Language: The Impact of Expertise Alignment in User-AI Interactions</title>
<link>https://arxiv.org/abs/2502.18685</link>
<guid>https://arxiv.org/abs/2502.18685</guid>
<content:encoded><![CDATA[
<div> 关键词：Bing Copilot、对话样本、领域专业知识、用户体验、人工智能与用户对齐

<br>
总结:
本文研究了Bing Copilot 在处理不同领域知识水平用户的对话中的响应情况及其对用户体验的影响。研究发现，该智能代理在多数情况下（77%的对话）能以专业或专家级别的知识水平回应用户，这与其正面的用户体验相关联，不论用户的专业知识水平如何。然而，当智能代理的回复专业知识水平低于用户时，则会对整体用户体验产生负面影响，尤其在处理更复杂的任务时更为显著。此外，当智能代理的回应能匹配到用户的知识水平时，用户的参与度（通过对话中的词汇数量衡量）会提高。这些发现强调，在设计以人为本的人工智能系统时，确保用户与AI之间的对齐至关重要，以便实现满意和高效的交互。 <div>
arXiv:2502.18685v1 Announce Type: new 
Abstract: Using a sample of 25,000 Bing Copilot conversations, we study how the agent responds to users of varying levels of domain expertise and the resulting impact on user experience along multiple dimensions. Our findings show that across a variety of topical domains, the agent largely responds at proficient or expert levels of expertise (77% of conversations) which correlates with positive user experience regardless of the user's level of expertise. Misalignment, such that the agent responds at a level of expertise below that of the user, has a negative impact on overall user experience, with the impact more profound for more complex tasks. We also show that users engage more, as measured by the number of words in the conversation, when the agent responds at a level of expertise commensurate with that of the user. Our findings underscore the importance of alignment between user and AI when designing human-centered AI systems, to ensure satisfactory and productive interactions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hybrid Voting-Based Task Assignment in Role-Playing Games</title>
<link>https://arxiv.org/abs/2502.18690</link>
<guid>https://arxiv.org/abs/2502.18690</guid>
<content:encoded><![CDATA[
<div> 关键词：角色扮演游戏（RPG）、沉浸感、大型语言模型（LLM）、任务分配、投票基于的任务分配（VBTA）

总结:
本文提出了一种针对角色扮演游戏(RPG)的新型框架——投票基于的任务分配(VBTA)，旨在提高游戏中智能代理对玩家情感状态和语境细微差别的理解与交互质量。VBTA通过赋予游戏代理能力和任务需求描述，生成适应性矩阵以量化两者间的匹配程度。利用预训练的大型语言模型、六种不同的投票方法以及冲突解决的路径规划算法(CBS)，该框架能够高效地识别并指派最适合执行各项任务的游戏代理。相较于现有的专注于生成单一游戏元素如任务或战斗场景的方法，VBTA由于其泛化特性，在生成独特战斗遭遇与叙事方面展现出潜力。 <div>
arXiv:2502.18690v1 Announce Type: new 
Abstract: In role-playing games (RPGs), the level of immersion is critical-especially when an in-game agent conveys tasks, hints, or ideas to the player. For an agent to accurately interpret the player's emotional state and contextual nuances, a foundational level of understanding is required, which can be achieved using a Large Language Model (LLM). Maintaining the LLM's focus across multiple context changes, however, necessitates a more robust approach, such as integrating the LLM with a dedicated task allocation model to guide its performance throughout gameplay. In response to this need, we introduce Voting-Based Task Assignment (VBTA), a framework inspired by human reasoning in task allocation and completion. VBTA assigns capability profiles to agents and task descriptions to tasks, then generates a suitability matrix that quantifies the alignment between an agent's abilities and a task's requirements. Leveraging six distinct voting methods, a pre-trained LLM, and integrating conflict-based search (CBS) for path planning, VBTA efficiently identifies and assigns the most suitable agent to each task. While existing approaches focus on generating individual aspects of gameplay, such as single quests, or combat encounters, our method shows promise when generating both unique combat encounters and narratives because of its generalizable nature.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition</title>
<link>https://arxiv.org/abs/2502.18702</link>
<guid>https://arxiv.org/abs/2502.18702</guid>
<content:encoded><![CDATA[
<div> 关键词: 零样本命名实体识别 (Zero-shot NER)，大型语言模型 (LLMs)，合作多智能体系统 (CMAS)，实体类型相关特征 (TRF)，演示鉴别器

总结:
本文提出了一个用于零样本命名实体识别 (Zero-shot NER) 的新框架——合作多智能体系统 (CMAS)。该框架通过利用多个智能体的集体智慧来解决现有方法中两个主要挑战：忽视实体上下文之间的关联性以及不加区分地使用任务示例导致的误导问题。CMAS 包含四个主要智能体：自注释器、类型相关特征提取器、演示鉴别器和总体预测器。CMAS 将 NER 重新定义为两个子任务：识别命名实体和确定目标句子中的实体类型相关特征，以显式捕捉实体上下文的相关性。同时，为了实现对示例的可控利用，它建立了一个演示鉴别器，自动评估目标句子中示例的有用性分数。实验结果显示，CMAS 在六个基准数据集（包括特定领域和通用领域）上的零样本 NER 性能有显著提升，并且在少量样本设置和不同 LLM 后端中也显示出了有效性。 <div>
arXiv:2502.18702v1 Announce Type: new 
Abstract: Zero-shot named entity recognition (NER) aims to develop entity recognition systems from unannotated text corpora. This task presents substantial challenges due to minimal human intervention. Recent work has adapted large language models (LLMs) for zero-shot NER by crafting specialized prompt templates. It advances model self-learning abilities by incorporating self-annotated demonstrations. However, two important challenges persist: (i) Correlations between contexts surrounding entities are overlooked, leading to wrong type predictions or entity omissions. (ii) The indiscriminate use of task demonstrations, retrieved through shallow similarity-based strategies, severely misleads LLMs during inference.
  In this paper, we introduce the cooperative multi-agent system (CMAS), a novel framework for zero-shot NER that uses the collective intelligence of multiple agents to address the challenges outlined above. CMAS has four main agents: (i) a self-annotator, (ii) a type-related feature (TRF) extractor, (iii) a demonstration discriminator, and (iv) an overall predictor. To explicitly capture correlations between contexts surrounding entities, CMAS reformulates NER into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence. To enable controllable utilization of demonstrations, a demonstration discriminator is established to incorporate the self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence. Experimental results show that CMAS significantly improves zero-shot NER performance across six benchmarks, including both domain-specific and general-domain scenarios. Furthermore, CMAS demonstrates its effectiveness in few-shot settings and with various LLM backbones.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms</title>
<link>https://arxiv.org/abs/2502.18754</link>
<guid>https://arxiv.org/abs/2502.18754</guid>
<content:encoded><![CDATA[
<div> 关键词：AgentSociety Challenge、大型语言模型、用户建模、推荐系统、比赛设计

总结:<br>
AgentSociety Challenge 是首届在Web Conference上举行的竞赛，旨在探索大型语言模型（LLM）在模拟用户行为和改进网络平台上的推荐系统方面的潜力。比赛分为用户建模轨道和推荐轨道两部分，要求参与者利用来自Yelp、Amazon和Goodreads的综合数据集及交互式环境模拟器开发创新的LLM代理。比赛吸引了全球295支队伍参加，并在为期37天的正式竞赛期间收到超过1,400份提交作品。参赛者在发展阶段实现了Track 1和Track 2性能分别提高21.9%和20.3%，最终阶段则提高了9.1%和15.9%。论文详细介绍了挑战赛的设计，分析了结果，并突出了最成功的LLM代理设计方案。为了支持进一步的研究与开发，比赛基准环境已开源，可在https://tsinghua-fib-lab.github.io/AgentSocietyChallenge获取。 <div>
arXiv:2502.18754v1 Announce Type: new 
Abstract: The AgentSociety Challenge is the first competition in the Web Conference that aims to explore the potential of Large Language Model (LLM) agents in modeling user behavior and enhancing recommender systems on web platforms. The Challenge consists of two tracks: the User Modeling Track and the Recommendation Track. Participants are tasked to utilize a combined dataset from Yelp, Amazon, and Goodreads, along with an interactive environment simulator, to develop innovative LLM agents. The Challenge has attracted 295 teams across the globe and received over 1,400 submissions in total over the course of 37 official competition days. The participants have achieved 21.9% and 20.3% performance improvement for Track 1 and Track 2 in the Development Phase, and 9.1% and 15.9% in the Final Phase, representing a significant accomplishment. This paper discusses the detailed designs of the Challenge, analyzes the outcomes, and highlights the most successful LLM agent designs. To support further research and development, we have open-sourced the benchmark environment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward Shaping to Mitigate Reward Hacking in RLHF</title>
<link>https://arxiv.org/abs/2502.18770</link>
<guid>https://arxiv.org/abs/2502.18770</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning from Human Feedback (RLHF)，reward hacking，reward shaping，Preference As Reward (PAR)，data efficiency

总结:
本文针对强化学习从人类反馈（RLHF）中的奖励黑客问题进行了研究，并提出了稳定和优化该过程的关键设计原则。文章指出了三种关键设计原则：(1) 强化学习的奖励应理想上具有界限；(2) 强化学习受益于快速初始增长后逐渐收敛的过程；(3) 奖励最好表述为与中心化奖励相关的函数。基于这些洞察，作者提出了一种新的奖励塑造方法——Preference As Reward (PAR)，该方法利用嵌入在奖励模型本身的潜在偏好作为强化学习的信号。实验结果显示，PAR在Gemma2-2B和Llama3-8B两个基线模型以及Ultrafeedback-Binarized和HH-RLHF两个数据集上的表现优于其他奖励塑造方法，在AlpacaEval 2.0基准测试中，其胜率至少比其他方法高出5个百分点。此外，PAR还表现出出色的数据效率，仅需一个参考奖励即可达到最佳性能，并在经过两轮完整训练后仍能保持对奖励黑客攻击的稳健性。相关代码可在https://github.com/PorUna-byte/PAR获取。 <div>
arXiv:2502.18770v1 Announce Type: new 
Abstract: Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to reward hacking, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. While reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests three key design principles: (1) RL reward is ideally bounded, (2) RL benefits from rapid initial growth followed by gradual convergence, and (3) RL reward is best formulated as a function of centered reward. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model itself as the signal for reinforcement learning. We evaluated PAR on two base models, Gemma2-2B and Llama3-8B, using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. Code is available at https://github.com/PorUna-byte/PAR.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents</title>
<link>https://arxiv.org/abs/2502.18805</link>
<guid>https://arxiv.org/abs/2502.18805</guid>
<content:encoded><![CDATA[
<div> 关键词：truthfulness、risk-avoiding truthfulness (RAT)、RAT-degree、manipulation、social choice settings

<br><br>总结:
本文提出了一个介于经典诚实性与风险避免诚实性(RAT)之间的新概念——RAT度，用于描述机制被安全操纵的难易程度。RAT度定义为最少需要知道多少个参与者的报告，其他参与者才能进行无害的操纵，若不存在这样的数字则为n。这一概念填补了完全了解他人信息和完全不了解之间的真实情况。文中通过分析拍卖、不可分割商品分配、蛋糕切割、投票以及稳定匹配等社会选择场景中著名机制的RAT度，展示了该概念的普适性和应用价值。 <div>
arXiv:2502.18805v1 Announce Type: new 
Abstract: The classic notion of truthfulness requires that no agent has a profitable manipulation -- an untruthful report that, for some combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.
  Without knowledge of the others' reports, most manipulations are risky -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as risk-avoiding truthfulness (RAT), which requires only that no agent can gain from a safe manipulation -- one that is sometimes beneficial and never harmful.
  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the RAT-degree of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.
  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and stable matchings.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Efficient Multi-Agent Spatial Planning with LLMs</title>
<link>https://arxiv.org/abs/2502.18822</link>
<guid>https://arxiv.org/abs/2502.18822</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体决策、预训练大语言模型、出租车调度、零样本性能、有限微调

总结:<br>
本文研究了如何利用预训练大型语言模型的世界知识来实现多智能体决策中的高效和鲁棒学习，以解决出租车路由和分配问题为例。文章指出，在该图形化路网问题上，通过适当的提示，大语言模型在零样本情况下的表现非常强劲。进一步地，结合有限的微调和一次性滚动算法进行展望，LLMs能够在与现有方法相比互动环境次数减少50倍的情况下取得更优性能。此外，文章还探讨了不同语言提示方法的优势，并展示了在提示中加入易于计算的信息可以显著提升性能。最后，文中强调了大语言模型内置的语义理解能力，能通过简单的提示适应环境因素变化。 <div>
arXiv:2502.18822v1 Announce Type: new 
Abstract: In this project, our goal is to determine how to leverage the world-knowledge of pretrained large language models for efficient and robust learning in multiagent decision making. We examine this in a taxi routing and assignment problem where agents must decide how to best pick up passengers in order to minimize overall waiting time. While this problem is situated on a graphical road network, we show that with the proper prompting zero-shot performance is quite strong on this task. Furthermore, with limited fine-tuning along with the one-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing approaches with 50 times fewer environmental interactions. We also explore the benefits of various linguistic prompting approaches and show that including certain easy-to-compute information in the prompt significantly improves performance. Finally, we highlight the LLM's built-in semantic understanding, showing its ability to adapt to environmental factors through simple prompts.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.18836</link>
<guid>https://arxiv.org/abs/2502.18836</guid>
<content:encoded><![CDATA[
<div> 关键词：LLMs、多智能体系统、规划场景、基准测试套件、复杂性

总结:
本文介绍了一个用于评估大型语言模型（LLMs）及多智能体系统的全面基准测试套件。该套件包含了从基础到高度复杂的十一类问题，涵盖了多智能体协调、交互依赖和动态环境干扰等关键要素。每个问题可在三个维度上进行扩展：并行规划线程的数量、交互依赖的复杂度以及需要实时适应的意外中断频率。测试基准提供了详细规范、评价指标和基于现代框架（如LangGraph）的基线实现，以实现对单智能体和多智能体规划能力的严格测试。通过标准化的评价标准和可扩展的复杂性，该基准旨在推动构建更强大、更具适应性的AI规划系统，以应用于现实世界情境中。<br><br> <div>
arXiv:2502.18836v1 Announce Type: new 
Abstract: This benchmark suite provides a comprehensive evaluation framework for assessing both individual LLMs and multi-agent systems in real-world planning scenarios. The suite encompasses eleven designed problems that progress from basic to highly complex, incorporating key aspects such as multi-agent coordination, inter-agent dependencies, and dynamic environmental disruptions. Each problem can be scaled along three dimensions: the number of parallel planning threads, the complexity of inter-dependencies, and the frequency of unexpected disruptions requiring real-time adaptation. The benchmark includes detailed specifications, evaluation metrics, and baseline implementations using contemporary frameworks like LangGraph, enabling rigorous testing of both single-agent and multi-agent planning capabilities. Through standardized evaluation criteria and scalable complexity, this benchmark aims to drive progress in developing more robust and adaptable AI planning systems for real-world applications.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards an AI co-scientist</title>
<link>https://arxiv.org/abs/2502.18864</link>
<guid>https://arxiv.org/abs/2502.18864</guid>
<content:encoded><![CDATA[
<div> 关键词: AI co-scientist, 多代理系统, 假设生成, 生物医学发现, 科学发现加速器

总结:
本文介绍了一种人工智能共科学家（AI co-scientist）的概念，这是一个基于Gemini 2.0构建的多代理系统，旨在辅助科学研究，生成新颖的假设并提出原创研究提案。该系统采用生成、辩论和演进的方法，以科学方法为灵感，并通过扩展测试时间计算能力来加速这一过程。关键贡献包括：1）一个多代理架构，带有异步任务执行框架，支持灵活的计算扩展；2）一种锦标赛式的进化过程，用于自我改进的假设生成。自动化评估显示，增加测试时间计算能力可以提高假设的质量。在生物医药领域的应用中，例如药物再利用、新靶点发现以及解释细菌演化和抗微生物耐药性的机制等方面，AI co-scientist提出了具有前景的验证结果。其中在药物再利用方面，针对急性髓系白血病，系统提出的候选药物在体外实验中显示出对肿瘤生长的抑制作用。在新靶点发现领域，AI co-scientist提出了针对肝纤维化的新的表观遗传学靶点，并在人类肝脏类器官实验中验证了其抗纤维化和促进肝细胞再生的作用。最后，AI co-scientist还通过平行的计算机模拟发现了细菌进化中的新型基因转移机制，重现了未公开的实验结果。这些结果在与本文同步发布的其他报告中有详细描述，展示了AI赋能科学家在生物医学和科学研究方面的巨大潜力，预示着一个由AI驱动的科学发现新时代的到来。 <div>
arXiv:2502.18864v1 Announce Type: new 
Abstract: Scientific discovery relies on scientists generating novel hypotheses that undergo rigorous experimental validation. To augment this process, we introduce an AI co-scientist, a multi-agent system built on Gemini 2.0. The AI co-scientist is intended to help uncover new, original knowledge and to formulate demonstrably novel research hypotheses and proposals, building upon prior evidence and aligned to scientist-provided research objectives and guidance. The system's design incorporates a generate, debate, and evolve approach to hypothesis generation, inspired by the scientific method and accelerated by scaling test-time compute. Key contributions include: (1) a multi-agent architecture with an asynchronous task execution framework for flexible compute scaling; (2) a tournament evolution process for self-improving hypotheses generation. Automated evaluations show continued benefits of test-time compute, improving hypothesis quality. While general purpose, we focus development and validation in three biomedical areas: drug repurposing, novel target discovery, and explaining mechanisms of bacterial evolution and anti-microbial resistance. For drug repurposing, the system proposes candidates with promising validation findings, including candidates for acute myeloid leukemia that show tumor inhibition in vitro at clinically applicable concentrations. For novel target discovery, the AI co-scientist proposed new epigenetic targets for liver fibrosis, validated by anti-fibrotic activity and liver cell regeneration in human hepatic organoids. Finally, the AI co-scientist recapitulated unpublished experimental results via a parallel in silico discovery of a novel gene transfer mechanism in bacterial evolution. These results, detailed in separate, co-timed reports, demonstrate the potential to augment biomedical and scientific discovery and usher an era of AI empowered scientists.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-LLM Collaborative Search for Complex Problem Solving</title>
<link>https://arxiv.org/abs/2502.18873</link>
<guid>https://arxiv.org/abs/2502.18873</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、混合搜索代理 (MoSA)、推理任务、蒙特卡洛树搜索 (MCTS)、多智能体

总结:
本文提出了一种名为“混合搜索代理”(MoSA)的新方法，旨在解决大型语言模型 (LLMs) 在处理复杂推理任务时面临的挑战。MoSA通过结合多个独立探索与迭代优化的LLM，利用多元推理路径来弥补单一模型方法的局限性。该方法以蒙特卡洛树搜索(MCTS)为基础，让多个代理能够提出并聚合推理步骤，从而提高准确性。实验结果表明，MoSA在四个不同推理基准测试上相较于单个代理和其他多智能体基线展现出更一致的性能提升，特别是在复杂的数学和常识推理任务中。<br><br> <div>
arXiv:2502.18873v1 Announce Type: new 
Abstract: Large language models (LLMs) often struggle with complex reasoning tasks due to their limitations in addressing the vast reasoning space and inherent ambiguities of natural language. We propose the Mixture-of-Search-Agents (MoSA) paradigm, a novel approach leveraging the collective expertise of multiple LLMs to enhance search-based reasoning. MoSA integrates diverse reasoning pathways by combining independent exploration with iterative refinement among LLMs, mitigating the limitations of single-model approaches. Using Monte Carlo Tree Search (MCTS) as a backbone, MoSA enables multiple agents to propose and aggregate reasoning steps, resulting in improved accuracy. Our comprehensive evaluation across four reasoning benchmarks demonstrates MoSA's consistent performance improvements over single-agent and other multi-agent baselines, particularly in complex mathematical and commonsense reasoning tasks.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Shielding via Parametric Safety Proofs</title>
<link>https://arxiv.org/abs/2502.18879</link>
<guid>https://arxiv.org/abs/2502.18879</guid>
<content:encoded><![CDATA[
<div> 关键词：cyber-physical systems、learning-enabled controllers、safety、adaptive shields、runtime knowledge acquisition

总结:
本文提出了一个新的编程语言框架，用于解决部署具有学习控制器的 cyber-physical 系统的安全问题，特别是在需要运行时知识获取的动态环境中。该框架支持专家静态地为学习代理指定适应性防护盾，这种防护盾可以随着运行时知识的积累而逐步放宽安全控制范围。防护盾规范包含了一个与当前代理知识参数化相关的安全性模型，并且允许使用专门的领域特定语言来指定非确定性的推断策略，确保这些知识参数能在运行时以统计学上可靠的方式得到推理。通过利用语言设计和定理证明技术，该框架使专家能够以前所未有的建模灵活性设计适应性防护盾，同时提供了从头到尾严谨的概率安全性保证。 <div>
arXiv:2502.18879v1 Announce Type: new 
Abstract: A major challenge to deploying cyber-physical systems with learning-enabled controllers is to ensure their safety, especially in the face of changing environments that necessitate runtime knowledge acquisition. Model-checking and automated reasoning have been successfully used for shielding, i.e., to monitor untrusted controllers and override potentially unsafe decisions, but only at the cost of hard tradeoffs in terms of expressivity, safety, adaptivity, precision and runtime efficiency. We propose a programming-language framework that allows experts to statically specify adaptive shields for learning-enabled agents, which enforce a safe control envelope that gets more permissive as knowledge is gathered at runtime. A shield specification provides a safety model that is parametric in the current agent's knowledge. In addition, a nondeterministic inference strategy can be specified using a dedicated domain-specific language, enforcing that such knowledge parameters are inferred at runtime in a statistically-sound way. By leveraging language design and theorem proving, our proposed framework empowers experts to design adaptive shields with an unprecedented level of modeling flexibility, while providing rigorous, end-to-end probabilistic safety guarantees.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Agents to Enhance Young Adults' Career Exploration</title>
<link>https://arxiv.org/abs/2502.18881</link>
<guid>https://arxiv.org/abs/2502.18881</guid>
<content:encoded><![CDATA[
<div> 关键词: Young adults, career exploration, letter-exchange exercise, Large Language Model (LLM), future-self agents

<br><br>总结:
本文研究了青年在职业探索过程中面临的挑战以及自我引导干预措施的作用。文章提出了一种结合大型语言模型（LLM）代理的方法，该方法将未来自我的模拟融入信件交流练习中，以期提高此类干预措施的效果。实验为期一周，共有36名参与者，分为三个条件组：手动书写回信的基线组、由未来自我代理人生成信件的组别和与未来自我代理人进行聊天对话的组别。结果表明，通过与未来自我代理人的信件交换，可以提升参与者的参与度，而整个干预措施对未来的导向性、职业自我概念及心理支持等方面的总体益处在这三个条件下保持相当。文章还讨论了AI增强型干预措施在支持青年职业探索设计方面的影响和启示。 <div>
arXiv:2502.18881v1 Announce Type: new 
Abstract: Young adults often encounter challenges in career exploration. Self-guided interventions, such as the letter-exchange exercise, where participants envision and adopt the perspective of their future selves by exchanging letters with their envisioned future selves, can support career development. However, the broader adoption of such interventions may be limited without structured guidance. To address this, we integrated Large Language Model (LLM)-based agents that simulate participants' future selves into the letter-exchange exercise and evaluated their effectiveness. A one-week experiment (N=36) compared three conditions: (1) participants manually writing replies to themselves from the perspective of their future selves (baseline), (2) future-self agents generating letters to participants, and (3) future-self agents engaging in chat conversations with participants. Results indicated that exchanging letters with future-self agents enhanced participants' engagement during the exercise, while overall benefits of the intervention on future orientation, career self-concept, and psychological support remained comparable across conditions. We discuss design implications for AI-augmented interventions for supporting young adults' career exploration.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Online Task Assignment via Inexact ADMM for unplanned online tasks and its Applications to Security</title>
<link>https://arxiv.org/abs/2502.18893</link>
<guid>https://arxiv.org/abs/2502.18893</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统(MRS), 任务分配算法, 分布式优化, 安全分析, 控制器

<br><br>总结:
本文提出了一种应用于多机器人系统的分布式任务分配算法，该算法能够动态地为团队中的机器人分配强制性和可选的安全关键任务。该算法基于不精确的交替方向乘子法(ADMM)，将任务分配问题分解为可分离和不可分离的子问题，并通过投影梯度下降法将其转化为可在团队内部通信步骤中执行的更新过程。其次，文章构建了一个综合框架，使得受到计划偏离攻击的MRS能够在保障安全的前提下处理在线任务。该框架首先进行安全性分析以确定机器人能否安全执行在线任务及其重新加入团队所需的时间和地点。随后，利用提出的任务分配算法来安排安全相关任务及验证后的在线任务。最后，通过控制李雅普诺夫函数(CLF)为基础的控制器管理和实现任务履行，同时利用控制障碍函数(CBF)为基础的安全过滤器确保安全性。通过模拟实验展示了所提框架能使MRS有效地响应未计划的在线任务并保持安全保证。 <div>
arXiv:2502.18893v1 Announce Type: new 
Abstract: In multi-robot system (MRS) applications, efficient task assignment is essential not only for coordinating agents and ensuring mission success but also for maintaining overall system security. In this work, we first propose an optimization-based distributed task assignment algorithm that dynamically assigns mandatory security-critical tasks and optional tasks among teams. Leveraging an inexact Alternating Direction Method of Multipliers (ADMM)-based approach, we decompose the task assignment problem into separable and non-separable subproblems. The non-separable subproblems are transformed into an inexact ADMM update by projected gradient descent, which can be performed through several communication steps within the team.
  In the second part of this paper, we formulate a comprehensive framework that enables MRS under plan-deviation attacks to handle online tasks without compromising security. The process begins with a security analysis that determines whether an online task can be executed securely by a robot and, if so, the required time and location for the robot to rejoin the team. Next, the proposed task assignment algorithm is used to allocate security-related tasks and verified online tasks. Finally, task fulfillment is managed using a Control Lyapunov Function (CLF)-based controller, while security enforcement is ensured through a Control Barrier Function (CBF)-based security filter. Through simulations, we demonstrate that the proposed framework allows MRS to effectively respond to unplanned online tasks while maintaining security guarantees.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model</title>
<link>https://arxiv.org/abs/2502.18906</link>
<guid>https://arxiv.org/abs/2502.18906</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Models (VLMs)，Graphical User Interfaces (GUI)，Reinforcement Learning (RL)，Value Environment Model (VEM)，Android-in-the-Wild

总结:
本文提出了一种环境自由的强化学习框架，用于训练针对GUI代理的视觉语言模型。该框架通过预训练的价值环境模型(VEM)解决了环境基RL所需的昂贵交互问题以及环境自由方法面临的分布偏移和奖励泛化挑战。VEM能直接从离线数据中预测状态-动作值，无需预测下一个状态或环境反馈，从而提炼出关于GUI交互结果的人类类似优先级理解，降低了误差累积并增强了对UI变化的适应性。框架分为两阶段：(1) 预训练VEM以估计长期行动效用；(2) 使用冻结的VEM信号引导策略探索，实现布局无关的GUI自动化。在Android-in-the-Wild基准测试中，VEM在离线和在线设置下均达到最佳性能，显著优于环境自由基线，并与需要交互成本的环境基方法表现相当。重要的是，VEM表明语义感知的价值估计可以实现与在线训练方法相媲美的性能。 <div>
arXiv:2502.18906v1 Announce Type: new 
Abstract: Training Vision-Language Models (VLMs) for Graphical User Interfaces (GUI) agents via Reinforcement Learning (RL) faces critical challenges: environment-based RL requires costly interactions, while environment-free methods struggle with distribution shift and reward generalization. We propose an environment-free RL framework that decouples value estimation from policy optimization by leveraging a pretrained Value Environment Model (VEM). VEM predicts state-action values directly from offline data, distilling human-like priors about GUI interaction outcomes without requiring next-state prediction or environmental feedback. This avoids compounding errors and enhances resilience to UI changes by focusing on semantic reasoning (e.g., Does this action advance the user's goal?). The framework operates in two stages: (1) pretraining VEM to estimate long-term action utilities and (2) guiding policy exploration with frozen VEM signals, enabling layout-agnostic GUI automation. Evaluated on Android-in-the-Wild benchmarks, VEM achieves state-of-the-art performance in both offline and online settings, outperforming environment-free baselines significantly and matching environment-based approaches without interaction costs. Importantly, VEM demonstrates that semantic-aware value estimation can achieve comparable performance with online-trained methods.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset</title>
<link>https://arxiv.org/abs/2502.18955</link>
<guid>https://arxiv.org/abs/2502.18955</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习（Offline Reinforcement Learning）、数据集选择、ReDOR、梯度逼近优化问题、正交匹配追踪（Orthogonal Matching Pursuit）

总结:
本文介绍了针对离线强化学习的研究新方法ReDOR，该方法着重解决如何从预收集的数据集中选择最优子集以提升算法性能和训练效率这一关键而未充分探索的挑战。ReDOR将数据集选择视为一个梯度逼近优化问题，并通过将常见的actor-critic框架重新表述为子模优化目标，实现了高效子集选取。为此，文章采用了正交匹配追踪(OMP)并进行了适应性的修改，特别针对离线RL场景。实验结果显示，通过ReDOR识别出的数据子集不仅能显著提高算法性能，而且还能以更低的计算复杂性实现这一目标。 <div>
arXiv:2502.18955v1 Announce Type: new 
Abstract: Offline reinforcement learning (RL) represents a significant shift in RL research, allowing agents to learn from pre-collected datasets without further interaction with the environment. A key, yet underexplored, challenge in offline RL is selecting an optimal subset of the offline dataset that enhances both algorithm performance and training efficiency. Reducing dataset size can also reveal the minimal data requirements necessary for solving similar problems. In response to this challenge, we introduce ReDOR (Reduced Datasets for Offline RL), a method that frames dataset selection as a gradient approximation optimization problem. We demonstrate that the widely used actor-critic framework in RL can be reformulated as a submodular optimization objective, enabling efficient subset selection. To achieve this, we adapt orthogonal matching pursuit (OMP), incorporating several novel modifications tailored for offline RL. Our experimental results show that the data subsets identified by ReDOR not only boost algorithm performance but also do so with significantly lower computational complexity.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Overcoming the Price of Anarchy by Steering with Recommendations</title>
<link>https://arxiv.org/abs/2502.18988</link>
<guid>https://arxiv.org/abs/2502.18988</guid>
<content:encoded><![CDATA[
<div> 关键词：协调问题、价格混乱、推荐系统、Braess悖论、Q学习者

总结:
本文研究了多种现实世界的系统中协调问题，例如交通网络、供应链和能源网格，其中许多代理实体需要学会共享资源。文中指出独立且自私的交互可能导致效率低下，即所谓的“价格混乱”。文章关注于利用推荐系统作为减少价格混乱并保持个体自主性的有效干预手段。以与道路交通、互联网数据包传输及电力电网相关的Braess悖论为例，作者采用近期文献中的方法，将代理实体之间的交互建模为Q学习者的重复游戏。文章提出了学习动态操纵问题，即外部推荐系统可以通过选择Q学习者在学习过程中观察到的状态来策略性地引导行为。计算贡献部分表明，适当的选择性推荐可以稳健地引导系统收敛至社会最优解，即使涉及多个玩家也是如此。理论和实证结果强调，推荐空间的增加能够提高推荐系统的引导潜力，这一点应在设计推荐系统时予以考虑。 <div>
arXiv:2502.18988v1 Announce Type: new 
Abstract: Varied real world systems such as transportation networks, supply chains and energy grids present coordination problems where many agents must learn to share resources. It is well known that the independent and selfish interactions of agents in these systems may lead to inefficiencies, often referred to as the `Price of Anarchy'. Effective interventions that reduce the Price of Anarchy while preserving individual autonomy are of great interest. In this paper we explore recommender systems as one such intervention mechanism. We start with the Braess Paradox, a congestion game model of a routing problem related to traffic on roads, packets on the internet, and electricity on power grids. Following recent literature, we model the interactions of agents as a repeated game between $Q$-learners, a common type of reinforcement learning agents. This work introduces the Learning Dynamic Manipulation Problem, where an external recommender system can strategically trigger behavior by picking the states observed by $Q$-learners during learning. Our computational contribution demonstrates that appropriately chosen recommendations can robustly steer the system towards convergence to the social optimum, even for many players. Our theoretical and empirical results highlight that increases in the recommendation space can increase the steering potential of a recommender system, which should be considered in the design of recommender systems.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments</title>
<link>https://arxiv.org/abs/2502.19024</link>
<guid>https://arxiv.org/abs/2502.19024</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-and-Language Navigation (VLN)，Ground-level Viewpoint Navigation (GVNav)，quadruped 机器人，视觉多样性，通用性挑战

总结:<br>
本文提出了一个名为Ground-level Viewpoint Navigation (GVNav)的方法，旨在解决视觉与语言导航(VLN)中因人类视角指令与低高度视野四足机器人的差距所带来的问题。GVNav通过使用加权的历史观察结果作为增强的时空上下文来改进指令跟随，有效地处理不同视角下相同特征的权重分配，帮助低高度机器人克服视觉遮挡和感知不匹配的挑战。此外，该方法还利用HM3D和Gibson数据集中的连通性图，以增强空间先验知识和更全面地表征现实世界场景，从而提升在真实环境中预测路点的性能和泛化能力。实验表明，GVNav方法在模拟环境和真实的四足机器人部署中都显著提高了性能。 <div>
arXiv:2502.19024v1 Announce Type: new 
Abstract: Vision-and-Language Navigation (VLN) empowers agents to associate time-sequenced visual observations with corresponding instructions to make sequential decisions. However, generalization remains a persistent challenge, particularly when dealing with visually diverse scenes or transitioning from simulated environments to real-world deployment. In this paper, we address the mismatch between human-centric instructions and quadruped robots with a low-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav) approach to mitigate this issue. This work represents the first attempt to highlight the generalization gap in VLN across varying heights of visual observation in realistic robot deployments. Our approach leverages weighted historical observations as enriched spatiotemporal contexts for instruction following, effectively managing feature collisions within cells by assigning appropriate weights to identical features across different viewpoints. This enables low-height robots to overcome challenges such as visual obstructions and perceptual mismatches. Additionally, we transfer the connectivity graph from the HM3D and Gibson datasets as an extra resource to enhance spatial priors and a more comprehensive representation of real-world scenarios, leading to improved performance and generalizability of the waypoint predictor in real-world environments. Extensive experiments demonstrate that our Ground-level Viewpoint Navigation (GVnav) approach significantly improves performance in both simulated environments and real-world deployments with quadruped robots.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages</title>
<link>https://arxiv.org/abs/2502.19067</link>
<guid>https://arxiv.org/abs/2502.19067</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，代码生成，多语种，IndicEval-XL，基准评测

总结:
本文介绍了大型语言模型（LLMs）在自然语言提示驱动的代码生成方面的显著能力及其对软件开发工作流的革新作用。然而，当前评估多语种代码生成能力的基准主要以英语为中心，限制了其在全球开发者社区中的适用性。为解决这一问题，文章提出了IndicEval-XL，一个全面的代码生成基准评测，该评测涵盖了大约占世界人口14%的六大印度语言，并将这些语言与12种编程语言相结合，构建了一个强大的评价框架。鉴于印度占据全球人口的八分之一以及印度语言在印度社会中的重要角色，IndicEval-XL对于扩展代码生成系统和评价框架的语言多样性具有重要意义。通过支持多种语言的研发资源，旨在使AI驱动的开发工具更加包容并易于不同语言背景的开发者使用。为了促进这一领域的进一步研究和发展，作者将其数据集和评价基准公开发布在https://github.com/telekom/IndicEval-XL上。 <div>
arXiv:2502.19067v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation from natural language prompts, revolutionizing software development workflows. As we advance towards agent-based development paradigms, these models form the cornerstone of next-generation software development lifecycles. However, current benchmarks for evaluating multilingual code generation capabilities are predominantly English-centric, limiting their applicability across the global developer community. To address this limitation, we present IndicEval-XL, a comprehensive benchmark for code generation that incorporates 6 major Indic languages, collectively spoken by approximately 14\% of the world's population. Our benchmark bridges these languages with 12 programming languages, creating a robust evaluation framework. This work is particularly significant given India's representation of one-eighth of the global population and the crucial role Indic languages play in Indian society. IndicEval-XL represents a significant step toward expanding the linguistic diversity in code generation systems and evaluation frameworks. By developing resources that support multiple languages, we aim to make AI-powered development tools more inclusive and accessible to developers of various linguistic backgrounds. To facilitate further research and development in this direction, we make our dataset and evaluation benchmark publicly available at https://github.com/telekom/IndicEval-XL
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study</title>
<link>https://arxiv.org/abs/2502.19095</link>
<guid>https://arxiv.org/abs/2502.19095</guid>
<content:encoded><![CDATA[
<div> 关键词：跨站脚本攻击(XSS)，深度学习(DL)，对抗性攻击，威胁评估，XSS Oracle

总结:<br>
本文探讨了跨站脚本攻击(XSS)对网络应用安全构成的重大威胁。尽管深度学习(DL)在检测XSS攻击方面表现出色，但它仍然容易受到由于输入-输出映射非连续性导致的对抗性攻击。研究中，作者复现了一种先进的XSS对抗性攻击方法，并指出了原参考工作中的威胁到有效性的问题，并对其进行了扩展，提出了更为有效的评价策略。此外，文章还引入了一个名为XSS Oracle的工具来缓解这些威胁。实验结果显示，当解决了复制技术中的威胁有效性问题后，我们的方法实现了超过96%的逃逸率。 <div>
arXiv:2502.19095v1 Announce Type: new 
Abstract: Cross-site scripting (XSS) poses a significant threat to web application security. While Deep Learning (DL) has shown remarkable success in detecting XSS attacks, it remains vulnerable to adversarial attacks due to the discontinuous nature of its input-output mapping. These adversarial attacks employ mutation-based strategies for different components of XSS attack vectors, allowing adversarial agents to iteratively select mutations to evade detection. Our work replicates a state-of-the-art XSS adversarial attack, highlighting threats to validity in the reference work and extending it toward a more effective evaluation strategy. Moreover, we introduce an XSS Oracle to mitigate these threats. The experimental results show that our approach achieves an escape rate above 96% when the threats to validity of the replicated technique are addressed.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Language-Driven Opinion Dynamics in Agent-Based Simulations with LLMs</title>
<link>https://arxiv.org/abs/2502.19098</link>
<guid>https://arxiv.org/abs/2502.19098</guid>
<content:encoded><![CDATA[
<div> 关键词: 意见演化、语言驱动、意见动态模型、逻辑谬误、人工智能

<br>
总结:
本文研究了在社会系统中意见演化的现象，重点关注语言和论证谬误的影响。为了填补这一研究空白，作者提出了LODAS——一种基于代理的模拟语言驱动的意见动态模型。该模型通过模拟围绕“忒修斯之船”悖论的辩论，探讨了不同意见分布（平衡、极化和不平衡）下，代理人如何通过接受、拒绝或忽略提出的论点来演变其观点。研究发现，LLM（大型语言模型）代理人在互动过程中展现出趋同性和迎合性特征，几乎在任何环境下都能达成共识。此外，这些AI代理往往会产生说服性但含有逻辑谬误的论点，并且他们容易受到建立在逻辑谬误基础上的论点影响。这一框架不仅可用于模拟社会动态，还有助于从另一个角度探究LLMs的偏见和缺陷，及其可能对与人类交互产生的影响。 <div>
arXiv:2502.19098v1 Announce Type: new 
Abstract: Understanding how opinions evolve is crucial for addressing issues such as polarization, radicalization, and consensus in social systems. While much research has focused on identifying factors influencing opinion change, the role of language and argumentative fallacies remains underexplored. This paper aims to fill this gap by investigating how language - along with social dynamics - influences opinion evolution through LODAS, a Language-Driven Opinion Dynamics Model for Agent-Based Simulations. The model simulates debates around the "Ship of Theseus" paradox, in which agents with discrete opinions interact with each other and evolve their opinions by accepting, rejecting, or ignoring the arguments presented. We study three different scenarios: balanced, polarized, and unbalanced opinion distributions. Agreeableness and sycophancy emerge as two main characteristics of LLM agents, and consensus around the presented statement emerges almost in any setting. Moreover, such AI agents are often producers of fallacious arguments in the attempt of persuading their peers and - for their complacency - they are also highly influenced by arguments built on logical fallacies. These results highlight the potential of this framework not only for simulating social dynamics but also for exploring from another perspective biases and shortcomings of LLMs, which may impact their interactions with humans.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Voting or Consensus? Decision-Making in Multi-Agent Debate</title>
<link>https://arxiv.org/abs/2502.19130</link>
<guid>https://arxiv.org/abs/2502.19130</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体辩论、决策协议、系统评估、知识任务、推理任务

<br><br>总结:
本文研究了多智能体辩论中决策协议对任务完成效果的影响。通过对七种不同的决策协议进行系统性评估，仅改变单一变量（即决策协议），分析不同方法如何影响智能体间的协作以及在知识和推理任务上的表现。实验结果显示，投票协议在推理任务上提升性能13.2%，共识协议在知识任务上提升2.8%。增加智能体数量能提高性能，而增加讨论轮次则会降低性能。为增强答案多样性并优化决策过程，文章提出了两种新方法——全智能体起草(AAD)和集体改进(CI)，这两种方法分别最多可使任务性能提升3.3%和7.4%。该工作强调了在多智能体辩论中，除了规模扩大之外，决策制定的重要性。 <div>
arXiv:2502.19130v1 Announce Type: new 
Abstract: Much of the success of multi-agent debates depends on carefully choosing the right parameters. Among them, the decision-making protocol stands out. Systematic comparison of decision protocols is difficult because studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making addresses the challenges of different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time (i.e., decision protocol) to analyze how different methods affect the collaboration between agents and test different protocols on knowledge (MMLU, MMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQuAD 2.0). Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks over the other decision protocol. Increasing the number of agents improves performance, while more discussion rounds before voting reduces it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.19145</link>
<guid>https://arxiv.org/abs/2502.19145</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、安全风险、多智能体系统、恶意指令、防御策略

总结:
本文探讨了随着AI代理在复杂目标协作中广泛应用，确保自主多智能体系统的安全性变得至关重要。研究通过模拟多个代理人合作共享目标的情境来分析其中的安全风险和安全权衡。文章重点关注一种攻击场景，即攻击者通过妥协一个代理来引导整个系统偏离正确目标，通过污染其他代理传播恶意指令。作者观察到恶意指令具有传染性特征。为减轻此类风险，文中评估了两种“疫苗”防御方法（向代理的记忆流插入安全处理恶意输入的假记忆）以及两种通用安全指令策略。虽然这些防御措施在实验中减少了恶意指令的传播和执行，但它们也降低了代理网络的合作能力。这项研究表明，在多智能体系统中可能存在安全性和协作效率之间的权衡，并为设计更安全而有效的AI协作提供了见解。 <div>
arXiv:2502.19145v1 Announce Type: new 
Abstract: As AI agents are increasingly adopted to collaborate on complex objectives, ensuring the security of autonomous multi-agent systems becomes crucial. We develop simulations of agents collaborating on shared objectives to study these security risks and security trade-offs. We focus on scenarios where an attacker compromises one agent, using it to steer the entire system toward misaligned outcomes by corrupting other agents. In this context, we observe infectious malicious prompts - the multi-hop spreading of malicious instructions. To mitigate this risk, we evaluated several strategies: two "vaccination" approaches that insert false memories of safely handling malicious input into the agents' memory stream, and two versions of a generic safety instruction strategy. While these defenses reduce the spread and fulfillment of malicious instructions in our experiments, they tend to decrease collaboration capability in the agent network. Our findings illustrate potential trade-off between security and collaborative efficiency in multi-agent systems, providing insights for designing more secure yet effective AI collaborations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis</title>
<link>https://arxiv.org/abs/2502.19175</link>
<guid>https://arxiv.org/abs/2502.19175</guid>
<content:encoded><![CDATA[
<div> 关键词: 差异诊断(Differential Diagnosis, DDx)、大型语言模型、MEDDxAgent、迭代学习、交互式诊断

<br><br>总结:
本文介绍了针对临床决策中的关键问题——差异诊断（DDx）所提出的一种新的框架：模块化可解释DDx代理（MEDDxAgent）。该框架设计用于支持交互式的DDx过程，通过迭代学习不断优化诊断推理，而不依赖于一开始就具备完整的患者信息。MEDDxAgent由三个模块组成： Orchestrator（DDxDriver）、病史模拟器以及两个专门负责知识检索和诊断策略的智能体。为了确保评估的全面性，研究者引入了一个涵盖呼吸系统、皮肤疾病及罕见病的综合DDx基准。实验结果显示，在无法立即获得完整患者资料的情况下，单次诊断方法的效果不如采用迭代细化的方式，并表明MEDDxAgent能在大、小型语言模型上实现超过10%的互动式DDx准确率提升，同时为其诊断推理过程提供了关键的可解释性。 <div>
arXiv:2502.19175v1 Announce Type: new 
Abstract: Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical decision-making, in which physicians iteratively refine a ranked list of possible diseases based on symptoms, antecedents, and medical knowledge. While recent advances in large language models have shown promise in supporting DDx, existing approaches face key limitations, including single-dataset evaluations, isolated optimization of components, unrealistic assumptions about complete patient profiles, and single-attempt diagnosis. We introduce a Modular Explainable DDx Agent (MEDDxAgent) framework designed for interactive DDx, where diagnostic reasoning evolves through iterative learning, rather than assuming a complete patient profile is accessible. MEDDxAgent integrates three modular components: (1) an orchestrator (DDxDriver), (2) a history taking simulator, and (3) two specialized agents for knowledge retrieval and diagnosis strategy. To ensure robust evaluation, we introduce a comprehensive DDx benchmark covering respiratory, skin, and rare diseases. We analyze single-turn diagnostic approaches and demonstrate the importance of iterative refinement when patient profiles are not available at the outset. Our broad evaluation demonstrates that MEDDxAgent achieves over 10% accuracy improvements in interactive DDx across both large and small LLMs, while offering critical explainability into its diagnostic reasoning process.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms</title>
<link>https://arxiv.org/abs/2502.19193</link>
<guid>https://arxiv.org/abs/2502.19193</guid>
<content:encoded><![CDATA[
<div> 关键词：社交平台、内容审核、语言策略、多智能体框架、遗传算法

总结:
本文介绍了一种基于大型语言模型（LLMs）的多智能体框架，用于模拟在监管约束下用户内容语言策略的迭代演化。该框架中的参与型智能体代表社交媒体用户，不断进化其语言表达方式；而监督型智能体则模仿平台级别的内容审查。为了更真实地模拟实际情况，研究采用了语言策略的双重设计（约束和表达），区分了相互冲突的目标，并利用LLM驱动的遗传算法进行语言策略的选择、变异和交叉操作。通过抽象密码游戏和非法宠物交易场景的两个不同案例进行评估，实验结果表明，随着对话轮数的增加，未中断的对话回合数以及信息传输的准确性均有显著提升。此外，一项涉及40名参与者的用户研究表明，生成的对话和策略具有现实世界的相关性。进一步的消融研究表明，遗传算法对于系统的长期适应性和整体性能提升至关重要。 <div>
arXiv:2502.19193v1 Announce Type: new 
Abstract: Social media platforms frequently impose restrictive policies to moderate user content, prompting the emergence of creative evasion language strategies. This paper presents a multi-agent framework based on Large Language Models (LLMs) to simulate the iterative evolution of language strategies under regulatory constraints. In this framework, participant agents, as social media users, continuously evolve their language expression, while supervisory agents emulate platform-level regulation by assessing policy violations. To achieve a more faithful simulation, we employ a dual design of language strategies (constraint and expression) to differentiate conflicting goals and utilize an LLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of language strategies. The framework is evaluated using two distinct scenarios: an abstract password game and a realistic simulated illegal pet trade scenario. Experimental results demonstrate that as the number of dialogue rounds increases, both the number of uninterrupted dialogue turns and the accuracy of information transmission improve significantly. Furthermore, a user study with 40 participants validates the real-world relevance of the generated dialogues and strategies. Moreover, ablation studies validate the importance of the GA, emphasizing its contribution to long-term adaptability and improved overall results.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding</title>
<link>https://arxiv.org/abs/2502.19247</link>
<guid>https://arxiv.org/abs/2502.19247</guid>
<content:encoded><![CDATA[
<div> 关键词: 代理变换、多模态任务、三维视觉定位、点云增强、实时交互

<br>
总结:
本文提出了适用于多模态任务的代理变换方法，以有效改善用于基于语言指令的实时三维环境交互中，从RGB-D图像渲染得到的含有大量冗余背景数据和噪声的点云的局部流形结构。该方法首先利用可变形点聚类识别目标区域内的点云子流形，接着提出一种代理注意力模块，使用多模态代理来指导点云变换。在此基础上，设计了一个子流形变换生成模块，其中文本信息全局引导不同子流形的平移向量，优化目标区域的相对空间关系；同时，图像信息指导每个子流形内部的线性变换，细化目标区域的局部点云流形。实验表明，Proxy Transformation 方法显著优于现有方法，在易目标上提高了7.49%，在难目标上提高了4.60%，并且减少了注意力块的计算开销达40.6%。这些结果为第一人称视角的三维视觉定位建立了新的SOTA，证明了所提方法的有效性和鲁棒性。 <div>
arXiv:2502.19247v1 Announce Type: new 
Abstract: Embodied intelligence requires agents to interact with 3D environments in real time based on language instructions. A foundational task in this domain is ego-centric 3D visual grounding. However, the point clouds rendered from RGB-D images retain a large amount of redundant background data and inherent noise, both of which can interfere with the manifold structure of the target regions. Existing point cloud enhancement methods often require a tedious process to improve the manifold, which is not suitable for real-time tasks. We propose Proxy Transformation suitable for multimodal task to efficiently improve the point cloud manifold. Our method first leverages Deformable Point Clustering to identify the point cloud sub-manifolds in target regions. Then, we propose a Proxy Attention module that utilizes multimodal proxies to guide point cloud transformation. Built upon Proxy Attention, we design a submanifold transformation generation module where textual information globally guides translation vectors for different submanifolds, optimizing relative spatial relationships of target regions. Simultaneously, image information guides linear transformations within each submanifold, refining the local point cloud manifold of target regions. Extensive experiments demonstrate that Proxy Transformation significantly outperforms all existing methods, achieving an impressive improvement of 7.49% on easy targets and 4.60% on hard targets, while reducing the computational overhead of attention blocks by 40.6%. These results establish a new SOTA in ego-centric 3D visual grounding, showcasing the effectiveness and robustness of our approach.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region</title>
<link>https://arxiv.org/abs/2502.19260</link>
<guid>https://arxiv.org/abs/2502.19260</guid>
<content:encoded><![CDATA[
<div> 关键词：Emirates Multi-Task (EMT) 数据集、自动驾驶、阿拉伯海湾地区、道路拓扑、轨迹预测

总结:
<br>
本文介绍了首个公开可用的阿拉伯海湾地区自动驾驶数据集——Emirates Multi-Task (EMT) 数据集。该数据集捕捉了这一地区独特的道路地形、高交通拥堵情况以及行人服装和天气条件等特点，包含了超过30,000帧的车载摄像头视角画面以及约570,000个标注的边界框，覆盖大约150公里的驾驶路线。EMT数据集支持三个主要任务：跟踪、轨迹预测和意图预测，并为每个基准测试提供了相应的评估方法，包括多目标跟踪实验（关注多类别场景和遮挡处理）、使用深度序列和交互感知模型的轨迹预测评估，以及从观察到的轨迹预测代理人意图的意图基准实验。该数据集可在https://avlab.io/emt-dataset 公开获取，预处理脚本及评估模型可访问https://github.com/AV-Lab/emt-dataset 获取。 <div>
arXiv:2502.19260v1 Announce Type: new 
Abstract: This paper introduces the Emirates Multi-Task (EMT) dataset - the first publicly available dataset for autonomous driving collected in the Arab Gulf region. The EMT dataset captures the unique road topology, high traffic congestion, and distinctive characteristics of the Gulf region, including variations in pedestrian clothing and weather conditions. It contains over 30,000 frames from a dash-camera perspective, along with 570,000 annotated bounding boxes, covering approximately 150 kilometers of driving routes. The EMT dataset supports three primary tasks: tracking, trajectory forecasting and intention prediction. Each benchmark dataset is complemented with corresponding evaluations: (1) multi-agent tracking experiments, focusing on multi-class scenarios and occlusion handling; (2) trajectory forecasting evaluation using deep sequential and interaction-aware models; and (3) intention benchmark experiments conducted for predicting agents intentions from observed trajectories. The dataset is publicly available at https://avlab.io/emt-dataset, and pre-processing scripts along with evaluation models can be accessed at https://github.com/AV-Lab/emt-dataset.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CritiQ: Mining Data Quality Criteria from Human Preferences</title>
<link>https://arxiv.org/abs/2502.19279</link>
<guid>https://arxiv.org/abs/2502.19279</guid>
<content:encoded><![CDATA[
<div> 关键词: CritiQ, 数据选择, 语言模型, 人类偏好, 继续训练

总结:
本文介绍了CritiQ，一种新的数据选择方法，旨在优化语言模型性能。CritiQ仅需约30对人工标注的数据即可自动挖掘出基于人类偏好的质量标准。其核心组件CritiQ Flow采用经理代理来进化质量标准，而工作者代理则进行pairwise判断。为了提升CritiQ Flow的效果，建立了从以往工作提取质量标准的知识库。与基于困惑度和分类器的方法相比，使用CritiQ得到的质量标准更具有可解释性和可复用性。利用这些标准，CritiQ Scorer为数据打分并进行高效选择。实验表明，该方法在代码、数学和逻辑等领域均取得高准确性，并通过继续训练Llama 3.1模型，相较于均匀采样，下游任务性能有所提升。此外，消融研究证实了知识库和反思过程的优势。文章还分析了标准的演化以及多数投票的有效性。 <div>
arXiv:2502.19279v1 Announce Type: new 
Abstract: Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while introduce biases. We introduce CritiQ, a novel data selection method that automatically mines criteria from human preferences for data quality with only $\sim$30 human-annotated pairs and performs efficient data selection. The main component, CritiQ Flow, employs a manager agent to evolve quality criteria and worker agents to make pairwise judgments. We build a knowledge base that extracts quality criteria from previous work to boost CritiQ Flow. Compared to perplexity- and classifier- based methods, verbal criteria are more interpretable and possess reusable value. After deriving the criteria, we train the CritiQ Scorer to give quality scores and perform efficient data selection. We demonstrate the effectiveness of our method in the code, math, and logic domains, achieving high accuracy on human-annotated test sets. To validate the quality of the selected data, we continually train Llama 3.1 models and observe improved performance on downstream tasks compared to uniform sampling. Ablation studies validate the benefits of the knowledge base and the reflection process. We analyze how criteria evolve and the effectiveness of majority voting.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains</title>
<link>https://arxiv.org/abs/2502.19297</link>
<guid>https://arxiv.org/abs/2502.19297</guid>
<content:encoded><![CDATA[
<div> 关键词：Multiagent Reinforcement Learning (MARL)，样本效率，一般化，关系设定，强化学习与规划集成

总结:
<br>
本文针对多智能体强化学习（MARL）面临的因状态和动作空间指数增长以及非平稳环境导致的显著样本效率低下和泛化能力不足的问题。特别是在关系设定中，尽管领域知识至关重要，但现有的MARL算法往往未能充分利用。为解决这些问题，文章提出将关系规划器作为集中式控制器，结合有效的状态抽象和强化学习进行集成。这种方法证明了其样例效率高，并有助于实现任务转移和泛化的有效提升。 <div>
arXiv:2502.19297v1 Announce Type: new 
Abstract: Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments. This results in notable sample inefficiency and hinders generalization across diverse tasks. The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by existing MARL algorithms. To overcome these hurdles, we propose integrating relational planners as centralized controllers with efficient state abstractions and reinforcement learning. This approach proves to be sample-efficient and facilitates effective task transfer and generalization.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agent-centric Information Access</title>
<link>https://arxiv.org/abs/2502.19298</link>
<guid>https://arxiv.org/abs/2502.19298</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、专家系统、信息访问框架、动态排名、查询效率

<br><br>总结:
本文提出了一个面向大规模专家语言模型的信息访问框架，预见到未来存在数百万个专注于特定领域的专用LLM。该框架中，LLM被视为具有动态排名和基于其展现的专业知识进行查询的知识代理。与传统的文档检索不同，该方法需要实时推断模型的专业技能，而非依赖静态元数据或预定义模型描述。针对高效专家选择、成本效益高的查询、多模型响应聚合以及对抗性操纵鲁棒性等挑战，文章提出了一种可扩展的评估框架，利用检索增强生成和聚类技术来构建并评估数千个专门模型，并有望扩展到数百万规模。 <div>
arXiv:2502.19298v1 Announce Type: new 
Abstract: As large language models (LLMs) become more specialized, we envision a future where millions of expert LLMs exist, each trained on proprietary data and excelling in specific domains. In such a system, answering a query requires selecting a small subset of relevant models, querying them efficiently, and synthesizing their responses. This paper introduces a framework for agent-centric information access, where LLMs function as knowledge agents that are dynamically ranked and queried based on their demonstrated expertise. Unlike traditional document retrieval, this approach requires inferring expertise on the fly, rather than relying on static metadata or predefined model descriptions. This shift introduces several challenges, including efficient expert selection, cost-effective querying, response aggregation across multiple models, and robustness against adversarial manipulation. To address these issues, we propose a scalable evaluation framework that leverages retrieval-augmented generation and clustering techniques to construct and assess thousands of specialized models, with the potential to scale toward millions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies</title>
<link>https://arxiv.org/abs/2502.19308</link>
<guid>https://arxiv.org/abs/2502.19308</guid>
<content:encoded><![CDATA[
<div> 关键词: WOFOSTGym、强化学习(RL)、作物模拟环境、多农场设置、年生和多年生作物

总结:
WOFOSTGym 是一款新的作物模拟环境，旨在训练强化学习(RL)智能体以优化单一及多农场环境中年生和多年生作物的农业管理决策。该环境解决了现有模拟器在多年生作物多农场场景以及对多种年生作物支持不足的问题，支持了23种年生作物和两种多年生作物，使RL智能体能在多年、多作物、多农场背景下学习多样化的农业管理策略。此外，WOFOSTGym还提供了具有部分可观测性、非马尔可夫动态和延迟反馈等挑战性的任务。其标准的RL接口使得缺乏农业专业知识的研究者也能探索各种农业管理问题。实验展示了RL智能体在不同作物品种和土壤类型中的学习行为，彰显了WOFOSTGym在推动基于RL驱动的农业决策支持方面所具有的潜力。 <div>
arXiv:2502.19308v1 Announce Type: new 
Abstract: We introduce WOFOSTGym, a novel crop simulation environment designed to train reinforcement learning (RL) agents to optimize agromanagement decisions for annual and perennial crops in single and multi-farm settings. Effective crop management requires optimizing yield and economic returns while minimizing environmental impact, a complex sequential decision-making problem well suited for RL. However, the lack of simulators for perennial crops in multi-farm contexts has hindered RL applications in this domain. Existing crop simulators also do not support multiple annual crops. WOFOSTGym addresses these gaps by supporting 23 annual crops and two perennial crops, enabling RL agents to learn diverse agromanagement strategies in multi-year, multi-crop, and multi-farm settings. Our simulator offers a suite of challenging tasks for learning under partial observability, non-Markovian dynamics, and delayed feedback. WOFOSTGym's standard RL interface allows researchers without agricultural expertise to explore a wide range of agromanagement problems. Our experiments demonstrate the learned behaviors across various crop varieties and soil types, highlighting WOFOSTGym's potential for advancing RL-driven decision support in agriculture.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoopDETR: A Unified Cooperative Perception Framework for 3D Detection via Object Query</title>
<link>https://arxiv.org/abs/2502.19313</link>
<guid>https://arxiv.org/abs/2502.19313</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主驾驶车辆, 合作感知, 传输成本, CoopDETR, 对象级特征合作

总结:
本文提出了一种新型的合作感知框架CoopDETR，旨在解决自动驾驶车辆(AVs)的合作感知问题并优化传输成本。该框架通过对象查询实现对象级特征合作，包含两个关键模块：单-Agent查询生成，能有效将原始传感器数据编码为对象查询，降低传输成本的同时保持检测所需的必要信息；以及跨-Agent查询融合，利用空间查询匹配(SQM)和对象查询聚合(OQA)实现查询间的高效交互。实验结果显示，CoopDETR在OPV2V和V2XSet数据集上达到了最先进的性能，并将传输成本降低了至先前方法的1/782。 <div>
arXiv:2502.19313v1 Announce Type: new 
Abstract: Cooperative perception enhances the individual perception capabilities of autonomous vehicles (AVs) by providing a comprehensive view of the environment. However, balancing perception performance and transmission costs remains a significant challenge. Current approaches that transmit region-level features across agents are limited in interpretability and demand substantial bandwidth, making them unsuitable for practical applications. In this work, we propose CoopDETR, a novel cooperative perception framework that introduces object-level feature cooperation via object query. Our framework consists of two key modules: single-agent query generation, which efficiently encodes raw sensor data into object queries, reducing transmission cost while preserving essential information for detection; and cross-agent query fusion, which includes Spatial Query Matching (SQM) and Object Query Aggregation (OQA) to enable effective interaction between queries. Our experiments on the OPV2V and V2XSet datasets demonstrate that CoopDETR achieves state-of-the-art performance and significantly reduces transmission costs to 1/782 of previous methods.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems</title>
<link>https://arxiv.org/abs/2502.19328</link>
<guid>https://arxiv.org/abs/2502.19328</guid>
<content:encoded><![CDATA[
<div> 关键词: 奖励模型、大规模语言模型、可验证正确性信号、代理奖励建模、RewardAgent

总结:<br>
本文提出了一种新的奖励模型方法——代理奖励建模（Agentic Reward Modeling），该方法结合了人类偏好和不同方面的可验证正确性信号来提供更可靠的奖励。具体实现中，作者设计了一个名为RewardAgent的奖励代理，它将人类偏好奖励与事实性和指令遵循两种可验证信号相结合。实验结果显示，RewardAgent在现有奖励模型基准测试和实际下游任务的最佳解搜索上表现优越。此外，利用RewardAgent构建训练偏好对，并使用DPO目标训练大型语言模型，使其在多个NLP基准测试中的性能超过了传统的奖励模型。相关代码已被公开发布，以促进进一步的研究。 <div>
arXiv:2502.19328v1 Announce Type: new 
Abstract: Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs). However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs. In this paper, we propose agentic reward modeling, a reward system that combines reward models with verifiable correctness signals from different aspects to provide reliable rewards. We empirically implement a reward agent, named RewardAgent, that combines human preference rewards with two verifiable signals: factuality and instruction following, to provide more reliable rewards. We conduct comprehensive experiments on existing reward model benchmarks and inference time best-of-n searches on real-world downstream tasks. RewardAgent significantly outperforms vanilla reward models, demonstrating its effectiveness. We further construct training preference pairs using RewardAgent and train an LLM with the DPO objective, achieving superior performance on various NLP benchmarks compared to conventional reward models. Our codes are publicly released to facilitate further research (https://github.com/THU-KEG/Agentic-Reward-Modeling).
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hybrid Robot Learning for Automatic Robot Motion Planning in Manufacturing</title>
<link>https://arxiv.org/abs/2502.19340</link>
<guid>https://arxiv.org/abs/2502.19340</guid>
<content:encoded><![CDATA[
<div> 关键词: 工业机器人、轨迹规划、深度强化学习、任务空间、关节空间

总结:
本文介绍了一种针对工业机器人的多层混合运动规划方法，该方法结合了基于任务空间的强化学习学习从示范（RL-LfD）代理和基于关节空间的深度强化学习（DRL）代理。通过高层级的代理学习在两种代理间进行切换，以实现可行且平滑的运动路径规划。规划过程中考虑了可达性、关节限制、操作便捷性和碰撞风险等因素，确保生成的混合运动策略遵守任务约束。该方法的有效性已在模拟及真实世界场景下的机器人实验中得到验证。<br><br> <div>
arXiv:2502.19340v1 Announce Type: new 
Abstract: Industrial robots are widely used in diverse manufacturing environments. Nonetheless, how to enable robots to automatically plan trajectories for changing tasks presents a considerable challenge. Further complexities arise when robots operate within work cells alongside machines, humans, or other robots. This paper introduces a multi-level hybrid robot motion planning method combining a task space Reinforcement Learning-based Learning from Demonstration (RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) based agent. A higher level agent learns to switch between the two agents to enable feasible and smooth motion. The feasibility is computed by incorporating reachability, joint limits, manipulability, and collision risks of the robot in the given environment. Therefore, the derived hybrid motion planning policy generates a feasible trajectory that adheres to task constraints. The effectiveness of the method is validated through sim ulated robotic scenarios and in a real-world setup.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding</title>
<link>https://arxiv.org/abs/2502.19400</link>
<guid>https://arxiv.org/abs/2502.19400</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、视觉解释、定理解释视频、Manim动画、TheoremExplainAgent、TheoremExplainBench、评价指标、多模态解释

总结:
本文介绍了为了解决大型语言模型在生成具有结构化视觉解释的定理解释方面的挑战，所提出的TheoremExplainAgent方法。该方法利用Manim动画生成超过5分钟的定理解释视频。为了系统评估多模态定理解释的效果，文章提出了涵盖多个STEM领域的240个定理及包含5个自动评价指标的TheoremExplainBench基准。实验结果显示，agentic规划对于生成详细的长篇视频至关重要，o3-mini代理的成功率达到93.8%，综合得分0.77。然而，定量和定性研究发现生成的视频在视觉元素布局方面存在一些小问题。此外，多模态解释揭示了文本解释未能显现的深层次推理缺陷，强调了多模态解释的重要性。 <div>
arXiv:2502.19400v1 Announce Type: new 
Abstract: Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation</title>
<link>https://arxiv.org/abs/2502.19414</link>
<guid>https://arxiv.org/abs/2502.19414</guid>
<content:encoded><![CDATA[
<div> 关键词: Language Models, 科学发现, 生成解决方案, 反驳能力, REFUTE

总结:
本文关注语言模型（Language Models）在加速科学发现中的潜力，强调了对其反驳错误解决方案能力进行评估和提升的重要性。当前的LM基准测试主要关注于它们生成解决方案的能力，而非挑战错误解决方案的能力。作者提出发展新的基准测试来衡量这种逆向能力，并以算法问题解决领域为例，引入了一个名为REFUTE的动态更新基准测试集，该集合包含了编程竞赛中人类专家已识别出错误解的问题及对应反例。研究分析显示，即使是最优的推理代理——OpenAI o3-mini（高），在具有代码执行反馈的情况下，也只能为REFUTE中不足9%的错误解决方案创建反例，尽管其评级表明它能从零开始解决高达48%的这些问题。作者希望通过这项工作激发对提升LM反驳错误解决方案能力的研究与进步，这一能力对于加速科学研究以及使模型通过可靠的反思性推理实现自我改进至关重要。 <div>
arXiv:2502.19414v1 Announce Type: new 
Abstract: There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant researcher effort, reasoning, and ingenuity. Yet current benchmarks for LMs predominantly assess their ability to generate solutions rather than challenge them. We advocate for developing benchmarks that evaluate this inverse capability - creating counterexamples for subtly incorrect solutions. To demonstrate this approach, we start with the domain of algorithmic problem solving, where counterexamples can be evaluated automatically using code execution. Specifically, we introduce REFUTE, a dynamically updating benchmark that includes recent problems and incorrect submissions from programming competitions, where human experts successfully identified counterexamples. Our analysis finds that the best reasoning agents, even OpenAI o3-mini (high) with code execution feedback, can create counterexamples for only <9% of incorrect solutions in REFUTE, even though ratings indicate its ability to solve up to 48% of these problems from scratch. We hope our work spurs progress in evaluating and enhancing LMs' ability to falsify incorrect solutions - a capability that is crucial for both accelerating research and making models self-improve through reliable reflective reasoning.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cycles and collusion in congestion games under Q-learning</title>
<link>https://arxiv.org/abs/2502.18984</link>
<guid>https://arxiv.org/abs/2502.18984</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-learning、Braess悖论游戏、纳什均衡、社交最优、参数设置

总结:<br>
本文研究了Q-learning在一类广义Braess悖论游戏中的动态行为。这些游戏代表了一种网络路由游戏中，其中阶段游戏的纳什均衡并不构成社会最优解。文章详细分析了具有不同参数和学习率的Q-learning的收敛性，并观察到了多种现象，大致分为两种情况：要么稳定在纳什均衡，要么以类似于“埃奇沃思周期”的方式持续循环（即从纳什均衡突然跃迁到社交最优，然后逐渐恶化回纳什均衡）。此外，作者揭示了一个重要的激励不相容性问题，即当考虑设计各自Q-learner的参与者之间的元博弈时，纳什均衡点特征为异质参数，导致结果仅达到纳什均衡层面的合作，几乎没有超越这一点。最后，文中提出了对监管和合谋的新视角，并讨论了研究结果对伯特兰寡头定价博弈的影响。 <div>
arXiv:2502.18984v1 Announce Type: cross 
Abstract: We investigate the dynamics of Q-learning in a class of generalized Braess paradox games. These games represent an important class of network routing games where the associated stage-game Nash equilibria do not constitute social optima. We provide a full convergence analysis of Q-learning with varying parameters and learning rates. A wide range of phenomena emerges, broadly either settling into Nash or cycling continuously in ways reminiscent of "Edgeworth cycles" (i.e. jumping suddenly from Nash toward social optimum and then deteriorating gradually back to Nash). Our results reveal an important incentive incompatibility when thinking in terms of a meta-game being played by the designers of the individual Q-learners who set their agents' parameters. Indeed, Nash equilibria of the meta-game are characterized by heterogeneous parameters, and resulting outcomes achieve little to no cooperation beyond Nash. In conclusion, we suggest a novel perspective for thinking about regulation and collusion, and discuss the implications of our results for Bertrand oligopoly pricing games.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A BV-Category of Spacetime Interventions</title>
<link>https://arxiv.org/abs/2502.19022</link>
<guid>https://arxiv.org/abs/2502.19022</guid>
<content:encoded><![CDATA[
<div> 关键词：BV-逻辑、duoidal类别、Chu构造、强Hyland包络、量子超导图

总结:<br>
本文利用Chu构造从duoidal范畴中functorially构建出BV-范畴，展示了可以从Retoré的序列化算子的一个片段自动生成BV-逻辑的候选模型。通过该构造法证明强Hyland包络是一个BV-范畴，从而提出了一种方法，可以从任何对称单态范畴出发，自动生成描述时空中介质间关系的规范模型。这一模型将时空事件具体解释为干预-上下文对，解决了之前尝试给出量子超导图一般范畴语义时存在的缺陷。 <div>
arXiv:2502.19022v1 Announce Type: cross 
Abstract: We use the Chu construction to functorially build BV-categories from duoidal categories, demonstrating that candidate models of BV-logic can be cofreely constructed from a fragment of a model of Retor\'e's sequencing operator. By using this construction to show that the strong Hyland envelope is a BV-category, we find a way to build a canonical model of spatio-temporal relationships between agents in spacetime from any symmetric monoidal category. The concrete physical interpretation of spacetime events in this model as intervention-context pairs resolves deficiencies in previous attempts to give a general categorical semantics to quantum supermaps.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Impact of Fake Agents on Information Cascades</title>
<link>https://arxiv.org/abs/2005.05518</link>
<guid>https://arxiv.org/abs/2005.05518</guid>
<content:encoded><![CDATA[
<div> 关键词：在线市场、观察学习、信息瀑布、虚假代理、福利影响

<br>
总结:
该文研究了在线市场中理性和虚假代理的行为互动。理性代理人除了依据私人信息外，还会从他人的行为中学习，这可能导致信息瀑布或跟风现象。文章引入了固定行动以影响其他理性代理选择的虚假代理，并分析了虚假代理比例对理性代理行为及其福利（期望收益）的影响。文中建立了一个状态空间为可数无限大的马尔科夫链模型，并给出了一种迭代方法来计算代理人跟风的概率和福利。主要结果表明存在无数种情况，增加虚假代理的比例反而会降低他们偏好的结果发生的几率，并且能显著提高所有理性代理的福利。因此，增加虚假代理不仅对他们自身的策略效果适得其反，还对理性代理有利。 <div>
arXiv:2005.05518v3 Announce Type: replace 
Abstract: In online markets, agents often learn from other's actions in addition to their private information. Such observational learning can lead to herding or information cascades in which agents eventually ignore their private information and "follow the crowd". Models for such cascades have been well studied for Bayes-rational agents that arrive sequentially and choose pay-off optimal actions. This paper additionally considers the presence of fake agents that take a fixed action in order to influence subsequent rational agents towards their preferred action. We characterize how the fraction of such fake agents impacts the behavior of rational agents given a fixed quality of private information. Our model results in a Markov chain with a countably infinite state space, for which we give an iterative method to compute an agent's chances of herding and its welfare (expected pay-off). Our main result shows a counter-intuitive phenomenon: there exist infinitely many scenarios where an increase in the fraction of fake agents in fact reduces the chances of their preferred outcome. Moreover, this increase causes a significant improvement in the welfare of every rational agent. Hence, this increase is not only counter-productive for the fake agents but is also beneficial to the rational agents.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stable Matching Games</title>
<link>https://arxiv.org/abs/2008.01680</link>
<guid>https://arxiv.org/abs/2008.01680</guid>
<content:encoded><![CDATA[
<div> 关键词：匹配问题、Gale-Shapley、稳定匹配、战略游戏、承诺能力

总结:
该文扩展了Gale和Shapley提出的两集合代理人的匹配问题模型，允许匹配后的夫妇通过非合作或半合作的战略游戏方式内生决定其收益。在非合作情形下，文章定义了一种结合Gale-Shapley稳定性和纳什均衡稳定性的解决方案概念；在存在承诺能力的半合作条件下，则定义了另一种相应的解决方案。对于每种情况，文中都给出了解决方案非空的充分必要条件并提供了计算解决方案的算法。 <div>
arXiv:2008.01680v4 Announce Type: replace 
Abstract: Gale and Shapley introduced a matching problem between two sets of agents where each agent on one side has an exogenous preference ordering over the agents on the other side. They defined a matching as stable if no unmatched pair can both improve their utility by forming a new pair. They proved, algorithmically, the existence of a stable matching. Shapley and Shubik, Demange and Gale, and many others extended the model by allowing monetary transfers. We offer a further extension by assuming that matched couples obtain their payoff endogenously as the outcome of a strategic game they have to play in a usual non-cooperative sense (without commitment) or in a semi-cooperative way (with commitment, as the outcome of a bilateral binding contract in which each player is responsible for her part of the contract). Depending on whether the players can commit or not, we define in each case a solution concept that combines Gale-Shapley pairwise stability with a (generalized) Nash equilibrium stability. In each case we give necessary and sufficient conditions for the set of solutions to be non-empty and provide an algorithm to compute a solution.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Completeness of two fragments of a logic for conditional strategic reasoning</title>
<link>https://arxiv.org/abs/2405.11418</link>
<guid>https://arxiv.org/abs/2405.11418</guid>
<content:encoded><![CDATA[
<div> 关键词：Conditional Strategic Reasoning (CSR)，Cooperating Conditional Strategic Reasoning (CCSR)，Completeness，Liability fragment，Ability fragment。

总结:
该文针对逻辑领域中用于战略推理的形式化理论，特别是Goranko和Ju近期提出的条件战略推理逻辑CSR进行了深入研究。CSR的一个重要特点是其包含了一个描述合作情境下代理者实现目标的战略行为的算子。文章聚焦于这个算子的逻辑——合作条件战略推理逻辑(CCSR)的两个片段：责任片段和能力片段，并证明了这两个片段的完备性。证明方法依赖于标准析取、标准析取的有效性减少条件、抽象游戏形式及其实现以及标准析取的推导减少条件。该方法有潜力应用于CSR和其他战略逻辑的完备性证明。 <div>
arXiv:2405.11418v2 Announce Type: replace 
Abstract: Classical logics for strategic reasoning, such as Coalition Logic and Alternating-time Temporal Logic, formalize absolute strategic reasoning about the unconditional strategic abilities of agents to achieve their goals. Goranko and Ju, in two recent papers, introduced a Logic for Conditional Strategic Reasoning (CSR). However, its completeness is still an open problem. CSR has three featured operators, and one of them has the following reading: For some action of A that guarantees the achievement of her goal, B has an action to guarantee the achievement of his goal. This operator makes good sense when A is cooperating with B. The logic about this operator is called Logic for Cooperating Conditional Strategic Reasoning (CCSR). In this paper, we prove the completeness of two fragments of CCSR: the liability fragment and the ability fragment. The key ingredients of our proof approach include standard disjunctions, the validity-reduction condition of standard disjunctions, abstract game forms, and their realization, and the derivability-reduction condition of standard disjunctions. The approach has good potential to be applied to the completeness of CSR and other strategic logics.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous Data</title>
<link>https://arxiv.org/abs/2405.13961</link>
<guid>https://arxiv.org/abs/2405.13961</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式训练、异构数据分布、通信成本、Sharpness-Aware Minimization (SAM)、SADDLe

总结:
本文提出了SADDLe，一套针对分布式深度学习的尖锐度感知算法，旨在解决实际场景中数据分布显著异构以及高通信成本的问题。SADDLe利用Sharpness-Aware Minimization (SAM)方法在训练过程中寻求平坦的损失景观，从而提高模型泛化能力和对通信压缩的鲁棒性。文章介绍了两种版本的SADDLe方法并进行了大量实验，结果显示SADDLe相比于现有技术能提升1-20%的测试精度，并在高达4倍的通信压缩下，平均性能下降仅为1%。 <div>
arXiv:2405.13961v2 Announce Type: replace 
Abstract: Decentralized training enables learning with distributed datasets generated at different locations without relying on a central server. In realistic scenarios, the data distribution across these sparsely connected learning agents can be significantly heterogeneous, leading to local model over-fitting and poor global model generalization. Another challenge is the high communication cost of training models in such a peer-to-peer fashion without any central coordination. In this paper, we jointly tackle these two-fold practical challenges by proposing SADDLe, a set of sharpness-aware decentralized deep learning algorithms. SADDLe leverages Sharpness-Aware Minimization (SAM) to seek a flatter loss landscape during training, resulting in better model generalization as well as enhanced robustness to communication compression. We present two versions of our approach and conduct extensive experiments to show that SADDLe leads to 1-20% improvement in test accuracy compared to other existing techniques. Additionally, our proposed approach is robust to communication compression, with an average drop of only 1% in the presence of up to 4x compression.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Training and Execution via Dynamic Directed Graph-Based Communication in Cooperative Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2408.07397</link>
<guid>https://arxiv.org/abs/2408.07397</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、强化学习、Transformer、图聚类网络、动态定向通信机制

总结:<br>
本文提出了一种名为Transformer-based图聚类网络（TGCNet）的新型多智能体强化学习（MARL）算法。针对现有方法在部分观测任务中缺乏动态定向通信机制以及依赖全局状态的问题，TGCNet通过学习动态定向图的拓扑结构来表示通信策略，并运用图聚类网络在训练过程中近似全局状态的表示。同时，TGCNet在执行阶段利用Transformer解码器进行特征提取。实验结果显示，TGCNet在多个合作型MARL基准上表现出优于流行MARL算法的性能。进一步的消融研究验证了我们提出的动态定向图通信机制和图聚类网络的有效性。 <div>
arXiv:2408.07397v3 Announce Type: replace 
Abstract: Multi-agent systems must learn to communicate and understand interactions between agents to achieve cooperative goals in partially observed tasks. However, existing approaches lack a dynamic directed communication mechanism and rely on global states, thus diminishing the role of communication in centralized training. Thus, we propose the Transformer-based graph coarsening network (TGCNet), a novel multi-agent reinforcement learning (MARL) algorithm. TGCNet learns the topological structure of a dynamic directed graph to represent the communication policy and integrates graph coarsening networks to approximate the representation of global state during training. It also utilizes the Transformer decoder for feature extraction during execution. Experiments on multiple cooperative MARL benchmarks demonstrate state-of-the-art performance compared to popular MARL algorithms. Further ablation studies validate the effectiveness of our dynamic directed graph communication mechanism and graph coarsening networks.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enabling Multi-Robot Collaboration from Single-Human Guidance</title>
<link>https://arxiv.org/abs/2409.19831</link>
<guid>https://arxiv.org/abs/2409.19831</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、强化学习、协作行为、人类演示、理论思维模型

<br><br>总结:
本文提出了一种新的方法，用于多智能体系统中高效、明确地学习协作行为。该方法仅需单一人类专家的指导，通过允许人类操作者在短时间内动态切换控制不同智能体以及结合类似人类的“理论思维”模型来教给智能体协作。实验结果显示，在一项具有挑战性的合作捉迷藏任务中，这种方法成功提高了成功率高达58%，并且仅需40分钟的人类引导时间。此外，研究还进一步证明了这些发现可以转移到现实世界的多机器人实验中。 <div>
arXiv:2409.19831v2 Announce Type: replace 
Abstract: Learning collaborative behaviors is essential for multi-agent systems. Traditionally, multi-agent reinforcement learning solves this implicitly through a joint reward and centralized observations, assuming collaborative behavior will emerge. Other studies propose to learn from demonstrations of a group of collaborative experts. Instead, we propose an efficient and explicit way of learning collaborative behaviors in multi-agent systems by leveraging expertise from only a single human. Our insight is that humans can naturally take on various roles in a team. We show that agents can effectively learn to collaborate by allowing a human operator to dynamically switch between controlling agents for a short period and incorporating a human-like theory-of-mind model of teammates. Our experiments showed that our method improves the success rate of a challenging collaborative hide-and-seek task by up to 58% with only 40 minutes of human guidance. We further demonstrate our findings transfer to the real world by conducting multi-robot experiments.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2410.02551</link>
<guid>https://arxiv.org/abs/2410.02551</guid>
<content:encoded><![CDATA[
<div> 关键词: ColaCare、电子健康记录(EHR)、多智能体协作、大型语言模型(LLMs)、临床决策支持

<br><br>总结:

本文介绍了ColaCare框架，该框架通过多智能体协作和驱动于大型语言模型（LLMs）的方法增强电子健康记录（EHR）建模。ColaCare结合了领域专家模型与LLMs，以弥合结构化EHR数据与基于文本推理之间的鸿沟。其设计灵感来源于临床环境中的多学科团队（MDT）方法，采用两种类型的代理：DoctorAgents和MetaAgent，协同分析患者数据。专家模型处理并从数值型EHR数据中生成预测，而LLM代理则生成推理参考和决策报告。MetaAgent负责协调讨论，模拟临床决策中的多元化专业知识。此外，为了解决知识更新问题，文章还引入了梅奥诊所诊断和治疗手册(MSD)的医疗指南作为检索增强生成（RAG）模块的证据来源。在三个EHR数据集上进行的广泛实验表明，ColaCare在临床死亡结果和再入院预测任务上的表现优越，显示出其对革新临床决策支持系统和推动个性化精准医学的潜力。所有代码、案例研究和问卷调查可在项目网站https://colacare.netlify.app获取。 <div>
arXiv:2410.02551v2 Announce Type: replace 
Abstract: We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Harvesting energy from turbulent winds with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.13961</link>
<guid>https://arxiv.org/abs/2412.13961</guid>
<content:encoded><![CDATA[
<div> 关键词：Airborne Wind Energy (AWE)，Reinforcement Learning (RL)，Model-Predictive Control，Turbulent Atmospheric Boundary Layer，Generator

总结:<br>
本文探讨了利用强化学习(RL)替代传统模型预测控制方法在空中风能(AWE)系统中的应用。传统方法依赖于特定模型，而在不可预测的湍流大气边界层条件下难以适应。研究发现，通过RL训练的AWE系统代理能够在复杂模拟环境中有效地从湍流中提取能量，并且仅依靠风筝相对于风向和速度的局部信息即可实现这一目标。这表明RL方法对于具有模型不确定性的问题有较强的鲁棒性。 <div>
arXiv:2412.13961v2 Announce Type: replace 
Abstract: Airborne Wind Energy (AWE) is an emerging technology designed to harness the power of high-altitude winds, offering a solution to several limitations of conventional wind turbines. AWE is based on flying devices (usually gliders or kites) that, tethered to a ground station and driven by the wind, convert its mechanical energy into electrical energy by means of a generator. Such systems are usually controlled by manoeuvering the kite so as to follow a predefined path prescribed by optimal control techniques, such as model-predictive control. These methods are strongly dependent on the specific model at use and difficult to generalize, especially in unpredictable conditions such as the turbulent atmospheric boundary layer. Our aim is to explore the possibility of replacing these techniques with an approach based on Reinforcement Learning (RL). Unlike traditional methods, RL does not require a predefined model, making it robust to variability and uncertainty. Our experimental results in complex simulated environments demonstrate that AWE agents trained with RL can effectively extract energy from turbulent flows, relying on minimal local information about the kite orientation and speed relative to the wind.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>What is a Social Media Bot? A Global Comparison of Bot and Human Characteristics</title>
<link>https://arxiv.org/abs/2501.00855</link>
<guid>https://arxiv.org/abs/2501.00855</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体、机器人、人类、行为分析、定义、检测、差异化、干扰、监管、未来方向

<br><br>总结:
本文探讨了社交媒体上机器人的普遍存在及其与人类行为的不同之处。研究发现，社交平台上约有20%的聊天内容来自机器人，它们倾向于使用易于自动化的语言线索，并具有星型互动结构；而80%的内容则来自人类，他们展现出更依赖对话理解并呈现多元身份的特点，其交流结构呈现出层级特征。文章首先从原理层面对社交媒体机器人的本质进行了定义，并基于此对比分析了机器人与人类在全球多个事件中的行为差异。作者还提出了对机器人使用的推荐和监管建议，以及三个关键挑战和未来发展方向：检测（系统性识别自动化并可能进化的机器人）、差异化（评价机器人在内容发布和关系互动方面的优劣）和干扰（减轻恶意机器人的负面影响）。 <div>
arXiv:2501.00855v2 Announce Type: replace 
Abstract: Chatter on social media is 20% bots and 80% humans. Chatter by bots and humans is consistently different: bots tend to use linguistic cues that can be easily automated while humans use cues that require dialogue understanding. Bots use words that match the identities they choose to present, while humans may send messages that are not related to the identities they present. Bots and humans differ in their communication structure: sampled bots have a star interaction structure, while sampled humans have a hierarchical structure. These conclusions are based on a large-scale analysis of social media tweets across ~200mil users across 7 events. Social media bots took the world by storm when social-cybersecurity researchers realized that social media users not only consisted of humans but also of artificial agents called bots. These bots wreck havoc online by spreading disinformation and manipulating narratives. Most research on bots are based on special-purposed definitions, mostly predicated on the event studied. This article first begins by asking, "What is a bot?", and we study the underlying principles of how bots are different from humans. We develop a first-principle definition of a social media bot. With this definition as a premise, we systematically compare characteristics between bots and humans across global events, and reflect on how the software-programmed bot is an Artificial Intelligent algorithm, and its potential for evolution as technology advances. Based on our results, we provide recommendations for the use and regulation of bots. Finally, we discuss open challenges and future directions: Detect, to systematically identify these automated and potentially evolving bots; Differentiate, to evaluate the goodness of the bot in terms of their content postings and relationship interactions; Disrupt, to moderate the impact of malicious bots.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ACEBench: Who Wins the Match Point in Tool Usage?</title>
<link>https://arxiv.org/abs/2501.12851</link>
<guid>https://arxiv.org/abs/2501.12851</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型(LLMs)、评估基准、ACEBench、工具使用、多回合对话

总结:
大型语言模型（LLMs）在决策和推理方面展现出巨大潜力，但现有的评估基准在评价LLMs工具使用能力时存在局限性，如：有限的评估场景、狭窄的评价维度以及依赖于LLMs或真实API执行带来的高成本。为解决这些问题，文章提出了一个新的全面评估基准——ACEBench。ACEBench根据评价方法将数据分为三类：基本场景的“正常”类型、含糊或不完整指令情况下的“特殊”类型以及通过多智能体交互模拟现实世界多回合对话的“代理”类型。通过对ACEBench进行广泛实验，文章对多种LLMs进行了深入分析，并在不同数据类型中详细剖析了错误产生的原因。 <div>
arXiv:2501.12851v4 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic scenarios; "Special" evaluates tool usage in situations with ambiguous or incomplete instructions; "Agent" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gaze-Guided Task Decomposition for Imitation Learning in Robotic Manipulation</title>
<link>https://arxiv.org/abs/2501.15071</link>
<guid>https://arxiv.org/abs/2501.15071</guid>
<content:encoded><![CDATA[
<div> 关键词：模仿学习、机器人操作、任务分解、目光转移、遥操作

总结:
本文提出了一种基于目光转移的任务分解方法，用于机器人操作中的模仿学习。研究认为，人类在物体操纵过程中，目光与手部动作紧密关联，可以将任务分解为子任务。该方法利用遥操作收集的演示数据，通过分析操作员的目光转移来代替模仿代理的目光控制进行任务分解，确保了每个任务的所有示范中一致的分解结果。实验评估显示，该方法对各种任务的特性及一致性有良好表现，并且在不同的超参数设置下展现出鲁棒性，适用于多种不同的机器人系统。相关代码已开源发布于https://github.com/crumbyRobotics/GazeTaskDecomp。 <div>
arXiv:2501.15071v3 Announce Type: replace 
Abstract: In imitation learning for robotic manipulation, decomposing object manipulation tasks into sub-tasks enables the reuse of learned skills and the combination of learned behaviors to perform novel tasks, rather than simply replicating demonstrated motions. Human gaze is closely linked to hand movements during object manipulation. We hypothesize that an imitating agent's gaze control, fixating on specific landmarks and transitioning between them, simultaneously segments demonstrated manipulations into sub-tasks. This study proposes a simple yet robust task decomposition method based on gaze transitions. Using teleoperation, a common modality in robotic manipulation for collecting demonstrations, in which a human operator's gaze is measured and used for task decomposition as a substitute for an imitating agent's gaze. Our approach ensures consistent task decomposition across all demonstrations for each task, which is desirable in contexts such as machine learning. We evaluated the method across demonstrations of various tasks, assessing the characteristics and consistency of the resulting sub-tasks. Furthermore, extensive testing across different hyperparameter settings confirmed its robustness, making it adaptable to diverse robotic systems. Our code is available at https://github.com/crumbyRobotics/GazeTaskDecomp.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement learning to learn quantum states for Heisenberg scaling accuracy</title>
<link>https://arxiv.org/abs/2412.02334</link>
<guid>https://arxiv.org/abs/2412.02334</guid>
<content:encoded><![CDATA[
<div> 关键词：量子状态学习、神经方法、元学习模型、强化学习（RL）、数据效率

总结:
本文提出了一种利用强化学习（RL）优化量子状态学习过程的元学习模型。为了提升RL的数据效率，文中引入了受课程学习启发的动作重复策略。实验表明，该RL代理能显著提高学习随机量子态的样本效率，并逼近海森堡极限的低失真尺度。此外，研究还展示了经过3-qubit训练的RL代理能够泛化到学习高达5-qubit的状态。这些结果强调了RL驱动的元学习在提升量子状态学习的效率和泛化能力方面的实用性。这种方法可以应用于改进量子控制、量子优化及量子机器学习领域。<br><br> <div>
arXiv:2412.02334v2 Announce Type: replace-cross 
Abstract: Learning quantum states is a crucial task for realizing quantum information technology. Recently, neural approaches have emerged as promising methods for learning quantum states. We propose a meta-learning model that utilizes reinforcement learning (RL) to optimize the process of learning quantum states. To improve the data efficiency of the RL, we introduce an action repetition strategy inspired by curriculum learning. The RL agent significantly improves the sample efficiency of learning random quantum states, and achieves infidelity scaling close to the Heisenberg limit. We also show that the RL agent trained using 3-qubit states can generalize to learning up to 5-qubit states. These results highlight the utility of RL-driven meta-learning to enhance the efficiency and generalizability of learning quantum states. Our approach can be applied to improve quantum control, quantum optimization, and quantum machine learning.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>

<item>
<title>AI Agentic workflows and Enterprise APIs: Adapting API architectures for the age of AI agents</title>
<link>https://arxiv.org/abs/2502.17443</link>
<guid>https://arxiv.org/abs/2502.17443</guid>
<content:encoded><![CDATA[
<div> 关键词: Generative AI、自主AI代理、企业API架构、智能交互、下一代企业API

总结:<br />
本文探讨了生成式AI的快速发展对自主AI代理兴起带来的挑战，指出现有企业API架构主要针对人类驱动的预定义交互模式，难以适应智能代理动态、目标导向的行为。研究通过系统性地分析现有API设计范式、智能代理交互模型以及新兴技术约束，提出了一个战略框架，用于企业API的有效转型以支持AI工作流程。采用理论建模、比较分析和探索性设计原则相结合的方法，解决标准化、性能和智能交互等方面的挑战。最终，该研究提出了一种概念性的下一代企业API模型，能够无缝集成到自主AI代理生态系统中，对未来的企业计算架构具有重大意义。 <div>
arXiv:2502.17443v1 Announce Type: new 
Abstract: The rapid advancement of Generative AI has catalyzed the emergence of autonomous AI agents, presenting unprecedented challenges for enterprise computing infrastructures. Current enterprise API architectures are predominantly designed for human-driven, predefined interaction patterns, rendering them ill-equipped to support intelligent agents' dynamic, goal-oriented behaviors. This research systematically examines the architectural adaptations for enterprise APIs to support AI agentic workflows effectively. Through a comprehensive analysis of existing API design paradigms, agent interaction models, and emerging technological constraints, the paper develops a strategic framework for API transformation. The study employs a mixed-method approach, combining theoretical modeling, comparative analysis, and exploratory design principles to address critical challenges in standardization, performance, and intelligent interaction. The proposed research contributes a conceptual model for next-generation enterprise APIs that can seamlessly integrate with autonomous AI agent ecosystems, offering significant implications for future enterprise computing architectures.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAG-Enhanced Collaborative LLM Agents for Drug Discovery</title>
<link>https://arxiv.org/abs/2502.17506</link>
<guid>https://arxiv.org/abs/2502.17506</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 药物发现, 专门化数据, 检索增强生成 (RAG), CLADD

总结:
CLADD是一个针对药物发现在无需领域特定微调的情况下，利用检索增强生成（RAG）技术的多代理系统。该系统通过多个LLM智能体动态地从生物医学知识库中检索信息、对查询分子进行上下文处理并整合相关证据以生成响应。CLADD解决了将RAG工作流应用于生化数据时面临的异质性、歧义和多源集成等关键问题。研究表明，该框架在多种药物发现任务上的表现优于通用及专用的LLMs以及传统的深度学习方法。 <div>
arXiv:2502.17506v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMs in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses -- all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gaussian Process-Based Scalar Field Estimation in GPS-Denied Environments</title>
<link>https://arxiv.org/abs/2502.17584</link>
<guid>https://arxiv.org/abs/2502.17584</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、GPS禁用区域、标量场映射、切换轨迹、Lyapunov稳定性分析

总结:
<br />
本文提出了一种用于自主代理在GPS信号被遮挡地区进行未知标量场映射的方法。该方法通过在有GPS信号和无GPS信号的区域间交替移动来减少定位误差，用户可以根据需求定义误差边界以确定在各区域内的停留时间。为了确保在无GPS信号区域内的测量值保持在指定误差限制内，文章设计了一种切换轨迹。基于Lyapunov稳定性理论进行分析，保证了在追踪期望路径时的误差轨迹是有界的。最后，通过仿真模拟展示了该方法的有效性，并进行了误差分析，将使用GP预测的标量场模型与实际场进行比较。 <div>
arXiv:2502.17584v1 Announce Type: new 
Abstract: This paper presents a methodology for an autonomous agent to map an unknown scalar field in GPS-denied regions. To reduce localization errors, the agent alternates between GPS-enabled and GPS-denied areas while collecting measurements. User-defined error bounds determine the dwell time in each region. A switching trajectory is then designed to ensure field measurements in GPS-denied regions remain within the specified error limits. A Lyapunov-based stability analysis guarantees bounded error trajectories while tracking the desired path. The effectiveness of the proposed methodology is demonstrated through simulations, with an error analysis comparing the GP-predicted scalar field model to the actual field.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Decentralized Swarms Using Rotation Equivariant Graph Neural Networks</title>
<link>https://arxiv.org/abs/2502.17612</link>
<guid>https://arxiv.org/abs/2502.17612</guid>
<content:encoded><![CDATA[
<div> 关键词：graph neural network (GNN)，分布式控制器设计，群体优化，旋转等变性，平移不变性

总结:
本文研究了在没有中心控制的情况下，通过分布式控制器来优化群体目标的问题，特别关注于无人机编队和传感器网络中的应用。现有的基于图神经网络（GNN）的分布式控制器在维持编队凝聚力方面存在挑战。文章提出了一种新的方法，即在分布式GNN控制器中强制实施旋转等变性和平移不变性对称性，从而提高了控制器性能。实验结果显示，这种方法所需的训练数据减少了70%，可训练权重减少了75%，并且其泛化能力也优于现有未施加这些对称性的GNN控制器。相关代码和动画已在http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers公开可用。 <div>
arXiv:2502.17612v1 Announce Type: new 
Abstract: The orchestration of agents to optimize a collective objective without centralized control is challenging yet crucial for applications such as controlling autonomous fleets, and surveillance and reconnaissance using sensor networks. Decentralized controller design has been inspired by self-organization found in nature, with a prominent source of inspiration being flocking; however, decentralized controllers struggle to maintain flock cohesion. The graph neural network (GNN) architecture has emerged as an indispensable machine learning tool for developing decentralized controllers capable of maintaining flock cohesion, but they fail to exploit the symmetries present in flocking dynamics, hindering their generalizability. We enforce rotation equivariance and translation invariance symmetries in decentralized flocking GNN controllers and achieve comparable flocking control with 70% less training data and 75% fewer trainable weights than existing GNN controllers without these symmetries enforced. We also show that our symmetry-aware controller generalizes better than existing GNN controllers. Code and animations are available at http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Imitation Learning of Team Behavior from Heterogeneous Demonstrations</title>
<link>https://arxiv.org/abs/2502.17618</link>
<guid>https://arxiv.org/abs/2502.17618</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体模仿学习, 异构示范, 高级层次策略, 并发错误缓解, 复杂序列任务

总结:
本文提出了DTIL，一种用于复杂序列任务中多模态团队行为学习的分层多智能体模仿学习算法。DTIL针对现有方法假设所有示范来自单一团队策略的问题，设计了能处理异构团队示范的学习框架。每个团队成员由一个分层策略表示，通过分布匹配方法，DTIL有效地减轻了累积误差，并在长周期和连续状态表示的情况下实现良好扩展性。实验结果显示，DTIL在各种协作场景中优于多智能体模仿学习基线，并能准确地模拟团队行为。<br /><br /> <div>
arXiv:2502.17618v1 Announce Type: new 
Abstract: Successful collaboration requires team members to stay aligned, especially in complex sequential tasks. Team members must dynamically coordinate which subtasks to perform and in what order. However, real-world constraints like partial observability and limited communication bandwidth often lead to suboptimal collaboration. Even among expert teams, the same task can be executed in multiple ways. To develop multi-agent systems and human-AI teams for such tasks, we are interested in data-driven learning of multimodal team behaviors. Multi-Agent Imitation Learning (MAIL) provides a promising framework for data-driven learning of team behavior from demonstrations, but existing methods struggle with heterogeneous demonstrations, as they assume that all demonstrations originate from a single team policy. Hence, in this work, we introduce DTIL: a hierarchical MAIL algorithm designed to learn multimodal team behaviors in complex sequential tasks. DTIL represents each team member with a hierarchical policy and learns these policies from heterogeneous team demonstrations in a factored manner. By employing a distribution-matching approach, DTIL mitigates compounding errors and scales effectively to long horizons and continuous state representations. Experimental results show that DTIL outperforms MAIL baselines and accurately models team behavior across a variety of collaborative scenarios.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling</title>
<link>https://arxiv.org/abs/2502.17651</link>
<guid>https://arxiv.org/abs/2502.17651</guid>
<content:encoded><![CDATA[
<div> 关键词：chart generation、vision-language model (VLM)、multi-agent framework、METAL、性能提升

总结:
本文提出了一种基于视觉-语言模型（VLM）的多智能体框架——METAL，用于有效自动图表生成。该任务需要将期望的视觉属性精确地编码到代码中，既要求强大的视觉设计技能又需要精确的编程能力，这对直接提示VLM构成挑战。METAL通过将图表生成任务分解为多个专业智能体之间的迭代协作来解决这一问题。相较于现有最佳结果，METAL在图表生成任务上准确度提升了5.2%。此外，METAL框架还表现出测试时间扩展现象，即随着计算预算从512增长到8192个令牌，其性能呈单调上升趋势。最后，研究发现，在METAL的批判过程中分离不同模态可以增强VLM在多模态语境下的自我修正能力。 <div>
arXiv:2502.17651v1 Announce Type: new 
Abstract: Chart generation aims to generate code to produce charts satisfying the desired visual properties, e.g., texts, layout, color, and type. It has great potential to empower the automatic professional report generation in financial analysis, research presentation, education, and healthcare. In this work, we build a vision-language model (VLM) based multi-agent framework for effective automatic chart generation. Generating high-quality charts requires both strong visual design skills and precise coding capabilities that embed the desired visual properties into code. Such a complex multi-modal reasoning process is difficult for direct prompting of VLMs. To resolve these challenges, we propose METAL, a multi-agent framework that decomposes the task of chart generation into the iterative collaboration among specialized agents. METAL achieves 5.2% improvement in accuracy over the current best result in the chart generation task. The METAL framework exhibits the phenomenon of test-time scaling: its performance increases monotonically as the logarithmic computational budget grows from 512 to 8192 tokens. In addition, we find that separating different modalities during the critique process of METAL boosts the self-correction capability of VLMs in the multimodal context.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Aligning Compound AI Systems via System-level DPO</title>
<link>https://arxiv.org/abs/2502.17721</link>
<guid>https://arxiv.org/abs/2502.17721</guid>
<content:encoded><![CDATA[
<div> 关键词: Compound AI系统、交互组件、Direct Preference Optimization (DPO)、系统级DPO (SysDPO)、Directed Acyclic Graphs (DAGs)

总结:
本文关注了由多个相互作用组件（如LLM代理和外部工具）组成的复合AI系统的对齐问题，这些系统在各种任务中展现出最先进的结果。由于组件间的非微分交互以及系统层面的偏好无法直接转化为组件层面的偏好，使得传统的DPO方法不适用于此类系统。为解决这些问题，文章提出了将复合AI系统建模为有向无环图(DAG)，并设计了一个系统级的DPO (SysDPO) 方法，使其能在这些DAG上适应性地进行联合对齐操作。通过研究LLM和扩散模型的联合对齐案例，作者证明了其方法的有效性。这项工作对于复合AI系统的对齐研究提供了新的见解，并为其未来的发展奠定了基础。<br /><br /> <div>
arXiv:2502.17721v1 Announce Type: new 
Abstract: Compound AI systems, comprising multiple interacting components such as LLM agents and external tools, demonstrate state-of-the-art results across diverse tasks. It is hence crucial to align components within the system to produce consistent results that match human expectations. However, conventional alignment methods, such as Direct Preference Optimization (DPO), are not directly applicable to compound AI systems. These challenges include the non-differentiable interactions between components, making end-to-end gradient optimization infeasible. Additionally, system-level preferences cannot be directly translated into component-level preferences, further complicating alignment. We address the issues by formulating compound AI systems as Directed Acyclic Graphs (DAGs), capturing the connections between agents and the data generation processes. We propose a system-level DPO (SysDPO) to jointly align compound systems by adapting the DPO to operate on these DAGs. We study the joint alignment of an LLM and a diffusion model to demonstrate the effectiveness of our approach. Our exploration provides insights into the alignment of compound AI systems and lays a foundation for future advancements.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Applications of deep reinforcement learning to urban transit network design</title>
<link>https://arxiv.org/abs/2502.17758</link>
<guid>https://arxiv.org/abs/2502.17758</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、神经网络、公交网络设计问题、Markov决策过程、混合算法

总结:
本文探讨了使用强化学习训练神经网络以辅助公共交通网络设计的方法。研究主要关注公交网络设计问题（TNDP），这是一个具有实际重要性的优化问题。与传统采用元启发式算法（如遗传算法和蚁群优化）不同，文中采用了强化学习的方法，将构建公交路线集的问题建模为马尔科夫决策过程（MDP），并通过训练神经网络策略作为该MDP中的智能体。进一步地，研究表明这个经过强化学习训练的神经网络策略不仅可以直接用于规划公交网络，还可以与现有的元启发式算法结合，既用于初始化解决方案，也可在搜索解空间的过程中提出有潜力的操作建议。通过这种混合算法，利用经强化学习训练的神经策略作为经典元启发式框架的核心组件，可以规划出优于单一神经策略或元启发式算法的公交网络。文章通过重新设计加拿大魁北克省拉瓦尔市的公交网络并进行模拟验证，结果显示，由此产生的公交网络能提供更好的服务且成本更低。 <div>
arXiv:2502.17758v1 Announce Type: new 
Abstract: This thesis concerns the use of reinforcement learning to train neural networks to aid in the design of public transit networks. The Transit Network Design Problem (TNDP) is an optimization problem of considerable practical importance. Given a city with an existing road network and travel demands, the goal is to find a set of transit routes - each of which is a path through the graph - that collectively satisfy all demands, while minimizing a cost function that may depend both on passenger satisfaction and operating costs. The existing literature on this problem mainly considers metaheuristic optimization algorithms, such as genetic algorithms and ant-colony optimization. By contrast, we begin by taking a reinforcement learning approach, formulating the construction of a set of transit routes as a Markov Decision Process (MDP) and training a neural net policy to act as the agent in this MDP. We then show that, beyond using this policy to plan a transit network directly, it can be combined with existing metaheuristic algorithms, both to initialize the solution and to suggest promising moves at each step of a search through solution space. We find that such hybrid algorithms, which use a neural policy trained via reinforcement learning as a core component within a classical metaheuristic framework, can plan transit networks that are superior to those planned by either the neural policy or the metaheuristic algorithm. We demonstrate the utility of our approach by using it to redesign the transit network for the city of Laval, Quebec, and show that in simulation, the resulting transit network provides better service at lower cost than the existing transit network.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Information Disclosure Makes Simple Mechanisms Competitive</title>
<link>https://arxiv.org/abs/2502.17809</link>
<guid>https://arxiv.org/abs/2502.17809</guid>
<content:encoded><![CDATA[
<div> 关键词：信息结构、机制设计、多维度、信息披露、物品定价

总结:
本文探讨了在机制设计中，当信息结构可由设计师影响时，简单机制的竞争优势。研究内容是对Bergemann和Pesendorfer（2007）提出的单维模型的多维度推广，其中设计师可以通过信息披露来塑造信息结构。文章聚焦于一个多商品销售问题，卖方需要向有单位需求的买方出售m件商品以最大化其收入，买方对各商品的价值可能存在任意相关性。主要结果表明，通过适当选择信息披露方案，采用物品定价策略（即对每件商品设定一口价）可以实现高度竞争力，保证至少获得最优收益的50.1%。这是首次在不假设买方价值分布的前提下，证明在这样的多维度场景中，简单机制具有（近似）最优性的结果。这一发现不仅展示了信息披露如何提升简单机制的性能，还为重新评估多维度环境中简单机制的有效性提供了一个新框架。 <div>
arXiv:2502.17809v1 Announce Type: new 
Abstract: In classical mechanism design, the prevailing assumption is that the information structure about agents' types is exogenous. This assumption introduces complexity, especially with multi-dimensional agent types, leading to mechanisms that, while optimal, may appear complex and unnatural. Furthermore, Hart and Nisan (2019) show that the gap between the performance of any simple mechanism and the optimal solution could be potentially unbounded. We challenge this conventional view by showing that simple mechanisms can be highly competitive if the information structure is endogenous and can be influenced by the designer.
  We study a multi-dimensional generalization of a single-dimensional model proposed by Bergemann and Pesendorfer (2007), where the designer can shape the information structure via information disclosure. Specifically, we consider a fundamental multi-dimensional mechanism design problem, where a seller is selling m items to a single unit-demand buyer to maximize her revenue. The buyer's values can be arbitrarily correlated across the items. Our main result shows that, following an appropriately chosen information disclosure scheme, item pricing, i.e., set a take-it-or-leave-it price on each item is highly competitive and guarantees to attain at least 50.1% of the optimal revenue. To our knowledge, this is the first result demonstrating the (approximate) optimality of simple mechanisms in this extensively studied multi-dimensional setting, without making any assumptions about the buyer's value distribution. We believe our result not only demonstrates the power of information disclosure in enhancing the performance of simple mechanisms but also suggests a new framework for reevaluating their efficacy in multi-dimensional settings.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safe Multi-Agent Navigation guided by Goal-Conditioned Safe Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17813</link>
<guid>https://arxiv.org/abs/2502.17813</guid>
<content:encoded><![CDATA[
<div> 关键词：安全导航、自主系统、强化学习、规划方法、多智能体

总结:
本文提出了一种融合规划方法和安全强化学习优势的新颖方法，用于解决在危险环境中的自主系统的安全导航问题。该方法结合目标条件化的强化学习和安全强化学习，学习目标条件化策略并自动估计累积距离和安全性水平。通过构建基于回放缓冲区状态的图，删除不安全边并生成路径点计划，使得智能体能在平衡速度与安全性的同时实现长距离目标导航。

对于多智能体的安全导航问题，该方法利用冲突避免搜索（CBS）为多个智能体创建路径点计划，从而确保它们在扩展的时间范围内实现安全导航，提高了目标条件化安全强化学习在多智能体场景下的可扩展性和协调效率。

与现有的最佳基线方案进行广泛的基准测试表明，我们的方法在复杂和危险环境中能够有效地使多个智能体安全地达成距离目标。相关代码将公开发布，以支持未来的研究。 <div>
arXiv:2502.17813v1 Announce Type: new 
Abstract: Safe navigation is essential for autonomous systems operating in hazardous environments. Traditional planning methods excel at long-horizon tasks but rely on a predefined graph with fixed distance metrics. In contrast, safe Reinforcement Learning (RL) can learn complex behaviors without relying on manual heuristics but fails to solve long-horizon tasks, particularly in goal-conditioned and multi-agent scenarios.
  In this paper, we introduce a novel method that integrates the strengths of both planning and safe RL. Our method leverages goal-conditioned RL and safe RL to learn a goal-conditioned policy for navigation while concurrently estimating cumulative distance and safety levels using learned value functions via an automated self-training algorithm. By constructing a graph with states from the replay buffer, our method prunes unsafe edges and generates a waypoint-based plan that the agent follows until reaching its goal, effectively balancing faster and safer routes over extended distances.
  Utilizing this unified high-level graph and a shared low-level goal-conditioned safe RL policy, we extend this approach to address the multi-agent safe navigation problem. In particular, we leverage Conflict-Based Search (CBS) to create waypoint-based plans for multiple agents allowing for their safe navigation over extended horizons. This integration enhances the scalability of goal-conditioned safe RL in multi-agent scenarios, enabling efficient coordination among agents.
  Extensive benchmarking against state-of-the-art baselines demonstrates the effectiveness of our method in achieving distance goals safely for multiple agents in complex and hazardous environments. Our code will be released to support future research.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.17821</link>
<guid>https://arxiv.org/abs/2502.17821</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态学习、协同辅助模态学习(CAML)、多智能体、事故检测、语义分割

总结:
本文提出了一种新的多模态学习框架——协同辅助模态学习(CAML)，用于解决单一智能体在动态环境中因数据不完整而导致决策盲点的问题。CAML允许多智能体在训练过程中协作并共享多模态数据，而在测试阶段每个智能体可以仅依赖减少的模态进行推理。通过对CAML从不确定性减小和数据覆盖角度的系统分析，证明了其相较于现有方法的优势。实验结果表明，在协同决策制定中，CAML对于联网自动驾驶车辆的事故检测性能提高了高达58.13%，并在真实世界无人机-地面机器人数据上的协同语义分割任务中实现了最高10.61%的mIoU提升。<br /><br /> <div>
arXiv:2502.17821v1 Announce Type: new 
Abstract: Multi-modality learning has become a crucial technique for improving the performance of machine learning applications across domains such as autonomous driving, robotics, and perception systems. While existing frameworks such as Auxiliary Modality Learning (AML) effectively utilize multiple data sources during training and enable inference with reduced modalities, they primarily operate in a single-agent context. This limitation is particularly critical in dynamic environments, such as connected autonomous vehicles (CAV), where incomplete data coverage can lead to decision-making blind spots. To address these challenges, we propose Collaborative Auxiliary Modality Learning ($\textbf{CAML}$), a novel multi-agent multi-modality framework that enables agents to collaborate and share multimodal data during training while allowing inference with reduced modalities per agent during testing. We systematically analyze the effectiveness of $\textbf{CAML}$ from the perspective of uncertainty reduction and data coverage, providing theoretical insights into its advantages over AML. Experimental results in collaborative decision-making for CAV in accident-prone scenarios demonstrate that \ours~achieves up to a ${\bf 58.13}\%$ improvement in accident detection. Additionally, we validate $\textbf{CAML}$ on real-world aerial-ground robot data for collaborative semantic segmentation, achieving up to a ${\bf 10.61}\%$ improvement in mIoU.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing</title>
<link>https://arxiv.org/abs/2502.17857</link>
<guid>https://arxiv.org/abs/2502.17857</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、同理心、对话代理、大规模语料库、SYNTHEMPATHY

总结:<br />
该研究提出了一种数据生成框架，用于构建名为SYNTHEMPATHY的大规模同理心语料库，其中包含了105k条针对真实情境的同理心回复。由于现有的同理心对话语料库主要依赖于昂贵、耗时且不可扩展的人工众包方式，因此这一新方法通过LLM生成来解决这个问题。通过对基础的Mistral 7B模型使用SYNTHEMPATHY语料库进行微调，结果显示模型的平均同理心得分有所提高。 <div>
arXiv:2502.17857v1 Announce Type: new 
Abstract: Previous research has shown that humans are more receptive towards language models that that exhibit empathetic behavior. While empathy is essential for developing helpful dialogue agents, very few large corpora containing empathetic dialogues are available for fine-tune LLMs. The few existing corpora have largely relied on crowdsourcing to simulate empathetic conversations, a process that is expensive, time-consuming, and not scalable to larger datasets. We propose a data generation framework for developing SYNTHEMPATHY, a large corpus containing 105k empathetic responses to real-life situations compiled through LLM generation. A base Mistral 7B model fine-tuned on our SYNTHEMPATHY corpus exhibits an increase in the average empathy score.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Maximum Welfare Allocations under Quantile Valuations</title>
<link>https://arxiv.org/abs/2502.17869</link>
<guid>https://arxiv.org/abs/2502.17869</guid>
<content:encoded><![CDATA[
<div> 关键词: quantile 值、偏好聚合、不可分割物品、福利最大化、算法复杂性

总结:<br />
本文提出了一种新的基于分位数值的偏好聚合模型，该模型中每个代理人都具有特定的分位数，而物品集合的价值由其中个体物品价值对应的分位数值定义。这个模型能够捕捉到不同代理人对同一批物品的不同感知方式，弥补了加法估值函数的局限性。文章研究了在这个基于分位数的估值环境中如何最大化功利主义和平均主义福利的问题。对于这两种福利函数，作者分析了其目标的计算复杂性。有趣的是，结果表明，两种目标的复杂度会因是否要求分配平衡而显著变化。对于功利主义福利，文中提供了近似最优算法；而对于平等主义福利，则在可能的情况下提出了精确算法。 <div>
arXiv:2502.17869v1 Announce Type: new 
Abstract: We propose a new model for aggregating preferences over a set of indivisible items based on a quantile value. In this model, each agent is endowed with a specific quantile, and the value of a given bundle is defined by the corresponding quantile of the individual values of the items within it. Our model captures the diverse ways in which agents may perceive a bundle, even when they agree on the values of individual items. It enables richer behavioral modeling that cannot be easily captured by additive valuation functions. We study the problem of maximizing utilitarian and egalitarian welfare within the quantile-based valuation setting. For each of the welfare functions, we analyze the complexity of the objectives. Interestingly, our results show that the complexity of both objectives varies significantly depending on whether the allocation is required to be balanced. We provide near-optimal approximation algorithms for utilitarian welfare, and for egalitarian welfare, we present exact algorithms whenever possible.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Enhanced Immersion and Agency for LLM-based Interactive Drama</title>
<link>https://arxiv.org/abs/2502.17878</link>
<guid>https://arxiv.org/abs/2502.17878</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、互动戏剧、沉浸感、故事叙述、情节反思

总结:
本文探讨了LLM（大型语言模型）为基础的交互式戏剧，这是一种新的AI对话场景，玩家在游戏中扮演角色并与由LLM代理控制的角色进行对话，体验不断发展的故事。文章从两个关键方面理解交互式戏剧：沉浸感，即玩家对故事的参与感；以及能动性，即玩家影响故事世界的能力。为增强这两个要素，文章提出了“剧本引导生成”方法，该方法有助于LLM构建结构更佳、叙事质量更高的戏剧故事。同时，引入了基于情节的反思机制，使LLM代理能够更好地调整反应以符合玩家的意图。评估通过人类判断来衡量我们的方法在提升沉浸感和能动性方面的成效。 <div>
arXiv:2502.17878v1 Announce Type: new 
Abstract: LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two aspects: Immersion, the player's feeling of being present in the story, and Agency, the player's ability to influence the story world. Both are crucial to creating an enjoyable interactive experience, while they have been underexplored in previous work. To enhance these two aspects, we first propose Playwriting-guided Generation, a novel method that helps LLMs craft dramatic stories with substantially improved structures and narrative quality. Additionally, we introduce Plot-based Reflection for LLM agents to refine their reactions to align with the player's intentions. Our evaluation relies on human judgment to assess the gains of our methods in terms of immersion and agency.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption</title>
<link>https://arxiv.org/abs/2502.17903</link>
<guid>https://arxiv.org/abs/2502.17903</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、Web代理、可持续性、能源消耗、CO2排放

总结:<br />
本文探讨了大型语言模型领域中，特别是能够自主与互联网交互的Web代理的研究进展。文章指出，尽管此类Web代理有潜力成为强大日常助手，但对其可持续性的研究尚不充分。通过对Web代理的能源和CO2成本进行初步探究，结果显示创建理念的不同会对能源消耗产生显著影响。同时，文章指出了部分Web代理在披露模型参数和使用过程方面的透明度不足，这限制了对能源消耗的准确估计。因此，作者主张在评估Web代理时应引入专门针对能源消耗和可持续性的指标。 <div>
arXiv:2502.17903v1 Announce Type: new 
Abstract: Improvements in the area of large language models have shifted towards the construction of models capable of using external tools and interpreting their outputs. These so-called web agents have the ability to interact autonomously with the internet. This allows them to become powerful daily assistants handling time-consuming, repetitive tasks while supporting users in their daily activities. While web agent research is thriving, the sustainability aspect of this research direction remains largely unexplored. We provide an initial exploration of the energy and CO2 cost associated with web agents. Our results show how different philosophies in web agent creation can severely impact the associated expended energy. We highlight lacking transparency regarding the disclosure of model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. As such, our work advocates a change in thinking when evaluating web agents, warranting dedicated metrics for energy consumption and sustainability.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models</title>
<link>https://arxiv.org/abs/2502.17924</link>
<guid>https://arxiv.org/abs/2502.17924</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、事实核查、FACT-AUDIT、动态评估、信任度

<br /><br />总结:
本文介绍了大型语言模型（LLMs）在事实核查领域的进步，但现有的自动化事实核查评价方法依赖静态数据集和分类指标，无法自动评估LLMs在事实核查中的解释生成能力和发现其细微局限性。为解决这一问题，文章提出了一个名为FACT-AUDIT的代理驱动框架，该框架利用重要性采样原理和多代理协作，生成适应性和可扩展的数据集，进行迭代的模型为中心的评估，并根据模型特定响应更新评估。通过结合判断预测与解释生成，该框架对LLMs的事实推理能力进行全面而不断演进的审计，以探究其可信度。实验表明，FACT-AUDIT能够有效地区分最先进的LLMs，并为模型中心的事实核查分析提供了有关模型优缺点的有价值见解。 <div>
arXiv:2502.17924v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Large Language Models in Agentic Multilingual National Bias</title>
<link>https://arxiv.org/abs/2502.17945</link>
<guid>https://arxiv.org/abs/2502.17945</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 跨语言偏见, 决策建议, 多语种推荐, 语言模型评分偏差

<br /><br />总结:
本文首次针对大型语言模型在跨语言决策建议任务中的应用及其潜在偏见进行了深入研究。研究涉及大学申请、旅行和迁移三个关键场景，通过分析多语言状态下最先进的LLMs对决策任务的响应，量化了模型生成分数中的偏见，并考察了人口统计因素和推理策略（如Chain-of-Thought提示）对偏见模式的影响。结果发现，本地语言偏见普遍存在各类任务中，尽管GPT-4和Sonnet在英语国家的偏见方面较GPT-3.5有所减少，但仍未能实现稳健的多语言对齐，这对多语种AI代理和应用如教育等领域提出了更广泛的启示。 <div>
arXiv:2502.17945v1 Announce Type: new 
Abstract: Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM's applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Advising Agent for Supporting Human-Multi-Drone Team Collaboration</title>
<link>https://arxiv.org/abs/2502.17960</link>
<guid>https://arxiv.org/abs/2502.17960</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机系统、自主控制、人机团队、搜索与救援、建议代理

<br /><br />总结:
本文介绍了针对多无人机系统在搜索与救援（SAR）等关键任务中的应用，由于复杂环境和不确定性，人类操作员在实时决策中可能效率低下。为解决此问题，研究者提出了一种建议代理算法，旨在增强人-多无人机团队的合作。该代理通过少量的人类操作示范生成类似真实人类的操作轨迹，并运用机器学习进行长期效果预测，从而向操作员提供上下文相关的行动建议。通过人类评估验证，该方法提供的辅助质量高，能显著提升团队执行任务的表现，相比基线条件有明显改善。 <div>
arXiv:2502.17960v1 Announce Type: new 
Abstract: Multi-drone systems have become transformative technologies across various industries, offering innovative applications. However, despite significant advancements, their autonomous capabilities remain inherently limited. As a result, human operators are often essential for supervising and controlling these systems, creating what is referred to as a human-multi-drone team. In realistic settings, human operators must make real-time decisions while addressing a variety of signals, such as drone statuses and sensor readings, and adapting to dynamic conditions and uncertainty. This complexity may lead to suboptimal operations, potentially compromising the overall effectiveness of the team. In critical contexts like Search And Rescue (SAR) missions, such inefficiencies can have costly consequences. This work introduces an advising agent designed to enhance collaboration in human-multi-drone teams, with a specific focus on SAR scenarios. The advising agent is designed to assist the human operator by suggesting contextual actions worth taking. To that end, the agent employs a novel computation technique that relies on a small set of human demonstrations to generate varying realistic human-like trajectories. These trajectories are then generalized using machine learning for fast and accurate predictions of the long-term effects of different advice. Through human evaluations, we demonstrate that our approach delivers high-quality assistance, resulting in significantly improved performance compared to baseline conditions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Dynamics of Collective Creativity in Human-AI Social Networks</title>
<link>https://arxiv.org/abs/2502.17962</link>
<guid>https://arxiv.org/abs/2502.17962</guid>
<content:encoded><![CDATA[
<div> 关键词: Generative AI, collective creativity, human-AI interactions, experimental social networks, creative writing task

<br /><br />总结:
该研究通过大型在线实验探究了生成式AI对集体创造力的影响。在涉及879名参与者和AI代理的创造性写作任务中，研究构建了5x5网格为基础的人类或AI社交网络。实验初期，纯AI网络展现出比人类网络及人机混合网络更高的创造力和多样性。然而，随着时间推移，人机混合网络在创作多样性上超过了纯AI网络。这主要是因为AI代理在选择、修改和分享故事的过程中保留的内容较少，而人类网络则倾向于保持故事的连续性。这些发现强调了利用实验性社交网络来理解人机融合社会的价值。 <div>
arXiv:2502.17962v1 Announce Type: new 
Abstract: Generative AI is reshaping modern culture, enabling individuals to create high-quality outputs across domains such as images, text, and music. However, we know little about the impact of generative AI on collective creativity. This study investigates how human-AI interactions shape collective creativity within experimental social networks. We conducted large-scale online experiments with 879 participants and AI agents in a creative writing task. Participants (either humans or AI) joined 5x5 grid-based networks, and were asked to iteratively select, modify, and share stories. Initially, AI-only networks showed greater creativity (rated by a separate group of 94 human raters) and diversity than human-only and human-AI networks. However, over time, hybrid human-AI networks became more diverse in their creations than AI-only networks. In part, this is because AI agents retained little from the original stories, while human-only networks preserved continuity. These findings highlight the value of experimental social networks in understanding human-AI hybrid societies.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena</title>
<link>https://arxiv.org/abs/2502.17967</link>
<guid>https://arxiv.org/abs/2502.17967</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、数值推理、Agent Trading Arena、几何推理、反射模块

<br /><br />总结:

本文研究了大型语言模型（LLMs）在动态任务中的泛化能力，特别是在数值推理方面的表现。研究者设计了一个名为Agent Trading Arena的虚拟经济系统游戏，通过零和博弈让代理进行股票投资，以此来评估LLM处理文本股票数据的能力。实验发现，LLMs在处理纯文本股票数据时对代数推理有困难，倾向于关注局部细节而非全局趋势。然而，当呈现视觉数据，如散点图或K线图表时，LLMs在几何推理方面表现出色，表明视觉表示能够增强数值推理能力。进一步地，引入反射模块可以提升LLMs分析和解释复杂数据的能力。该研究使用NASDAQ股票数据集验证了这些发现，结果表明LLMs在处理视觉数据时相比文本数据展现出更强的推理能力。相关代码和数据已在https://github.com/wekjsdvnm/Agent-Trading-Arena.git上公开。 <div>
arXiv:2502.17967v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents</title>
<link>https://arxiv.org/abs/2502.18017</link>
<guid>https://arxiv.org/abs/2502.18017</guid>
<content:encoded><![CDATA[
<div> 关键词: ViDoSeek、Retrieval-Augmented Generation (RAG)、ViDoRAG、多模态检索、复杂推理

总结:<br />
本文提出了一种新的数据集ViDoSeek，用于评估RAG方法处理富含视觉信息文档的能力，并指出了当前RAG方法的两个主要局限：视觉检索方法难以有效融合文本和视觉特征，以及现有方法对推理令牌的分配不足。为解决这些问题，文章提出了ViDoRAG，这是一种针对视觉文档复杂推理的新型多代理RAG框架。ViDoRAG采用基于高斯混合模型（GMM）的混合策略进行有效的多模态检索，并通过探索、摘要和反思的迭代代理工作流程来增强模型的推理能力。实验结果表明，ViDoRAG在ViDoSeek基准测试上相比于现有方法性能提升了超过10%。 <div>
arXiv:2502.18017v1 Announce Type: new 
Abstract: Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model's reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</title>
<link>https://arxiv.org/abs/2502.18041</link>
<guid>https://arxiv.org/abs/2502.18041</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Navigation (VLN)，户外航拍VLN，OpenFly，数据收集工具链，大规模基准，自动飞行轨迹创建，指令生成，Unreal Engine，GTA V，Google Earth，3D Gaussian Splatting (3D GS)，真实感渲染，OpenFly-Agent，关键帧感知模型。

<br /><br />总结:
本文提出了一种名为OpenFly的新平台，旨在解决户外航拍视觉语言导航(VLN)研究不足的问题。该平台包括一个自动化数据收集工具链，用于实现点云获取、场景语义分割、飞行轨迹创建和指令生成等。利用此工具链，他们构建了一个覆盖18个场景、包含10万条轨迹的大规模航拍VLN数据集，数据集采用不同渲染引擎（如Unreal Engine、GTA V、Google Earth）及3D GS技术生成，具有高视觉质量并支持从实境到模拟的真实感渲染。此外，文章还介绍了一个基于OpenFly的航拍VLN模型——OpenFly-Agent，该模型输入语言指令、当前观测值和历史关键帧，直接输出飞行操作。通过广泛的分析与实验，证实了OpenFly平台和OpenFly-Agent的优势。所涉及的工具链、数据集和代码都将开源。 <div>
arXiv:2502.18041v1 Announce Type: new 
Abstract: Vision-Language Navigation (VLN) aims to guide agents through an environment by leveraging both language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising a versatile toolchain and large-scale benchmark for aerial VLN. Firstly, we develop a highly automated toolchain for data collection, enabling automatic point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Secondly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. The corresponding visual data are generated using various rendering engines and advanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). All data exhibit high visual quality. Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of the dataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which takes language instructions, current observations, and historical keyframes as input, and outputs flight actions directly. Extensive analyses and experiments are conducted, showcasing the superiority of our OpenFly platform and OpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Reusability of Learned Skills for Robot Manipulation via Gaze and Bottleneck</title>
<link>https://arxiv.org/abs/2502.18121</link>
<guid>https://arxiv.org/abs/2502.18121</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、多样性操作、深度学习、泛化能力、GazeBot

<br /><br />总结:
本文提出了一种名为GazeBot的新算法，旨在使自主机器人能够在不同场景中高效复用广泛的操作技能。针对当前深度学习方法在将习得技能泛化到未知情境中的挑战，GazeBot利用目光信息和动作瓶颈这两个对物体操纵至关重要的特征，实现了与现有最先进的模仿学习方法相比更高的泛化性能，同时并未牺牲其灵巧性和反应性。此外，一旦提供了包含目光数据的演示数据集，GazeBot的训练过程就完全基于数据驱动。相关视频和代码可在https://crumbyrobotics.github.io/gazebot获取。 <div>
arXiv:2502.18121v1 Announce Type: new 
Abstract: Autonomous agents capable of diverse object manipulations should be able to acquire a wide range of manipulation skills with high reusability. Although advances in deep learning have made it increasingly feasible to replicate the dexterity of human teleoperation in robots, generalizing these acquired skills to previously unseen scenarios remains a significant challenge. In this study, we propose a novel algorithm, Gaze-based Bottleneck-aware Robot Manipulation (GazeBot), which enables high reusability of the learned motions even when the object positions and end-effector poses differ from those in the provided demonstrations. By leveraging gaze information and motion bottlenecks, both crucial features for object manipulation, GazeBot achieves high generalization performance compared with state-of-the-art imitation learning methods, without sacrificing its dexterity and reactivity. Furthermore, the training process of GazeBot is entirely data-driven once a demonstration dataset with gaze data is provided. Videos and code are available at https://crumbyrobotics.github.io/gazebot.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Language Model Driven Agents for Simulating Echo Chamber Formation</title>
<link>https://arxiv.org/abs/2502.18138</link>
<guid>https://arxiv.org/abs/2502.18138</guid>
<content:encoded><![CDATA[
<div> 关键词：echo chambers, social media, large language models, simulation, polarization

总结:<br />
本文提出了一种新颖的框架，利用大型语言模型（LLMs）作为生成代理来模拟社交网络中的回声室效应动态。该框架同时考虑了由LLMs驱动的意见更新和网络重连行为，从而实现对社会互动的语境感知和语义丰富的仿真。为了验证这种方法的真实性和准确性，研究者使用实际的Twitter数据与其仿真结果进行对比分析。实验结果显示，LLMs在模拟回声室形成方面具有有效性，能够捕捉到意见聚类的结构和语义维度，为深入理解社会影响力动态以及研究在线社区中的极化现象提供了一个新的工具。 <div>
arXiv:2502.18138v1 Announce Type: new 
Abstract: The rise of echo chambers on social media platforms has heightened concerns about polarization and the reinforcement of existing beliefs. Traditional approaches for simulating echo chamber formation have often relied on predefined rules and numerical simulations, which, while insightful, may lack the nuance needed to capture complex, real-world interactions. In this paper, we present a novel framework that leverages large language models (LLMs) as generative agents to simulate echo chamber dynamics within social networks. The novelty of our approach is that it incorporates both opinion updates and network rewiring behaviors driven by LLMs, allowing for a context-aware and semantically rich simulation of social interactions. Additionally, we utilize real-world Twitter (now X) data to benchmark the LLM-based simulation against actual social media behaviors, providing insights into the accuracy and realism of the generated opinion trends. Our results demonstrate the efficacy of LLMs in modeling echo chamber formation, capturing both structural and semantic dimensions of opinion clustering. %This work contributes to a deeper understanding of social influence dynamics and offers a new tool for studying polarization in online communities.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Carbon and Silicon, Coexist or Compete? A Survey on Human-AI Interactions in Agent-based Modeling and Simulation</title>
<link>https://arxiv.org/abs/2502.18145</link>
<guid>https://arxiv.org/abs/2502.18145</guid>
<content:encoded><![CDATA[
<div> 关键词：agent-based modeling and simulation (ABMS)，large language models (LLMs)，human-AI交互，分类体系，未来研究方向

<br /><br />总结:
该文探讨了在基于代理的建模和模拟(ABMS)中，随着大型语言模型(LLMs)广泛应用而日益增长的人工智能与人类交互的研究兴趣。文章指出，将LLMs融入ABMS可以实现自然语言交互，但同时也带来了新的挑战，需要通过人类交互来解决。本文对现有工作进行了调查并提出了一种新型分类体系，将用户（在此指使用ABMS工具进行研究的研究人员）的交互行为按照目的（Why）、参与阶段（When）、系统组件（What）、用户角色（Who）以及交互方式（How）五个维度进行分类。分析结果揭示了现有的交互模式，为开发人机交互提供了全面指导。此外，文章还讨论了未探索的交互领域，并提出了未来的研究方向。 <div>
arXiv:2502.18145v1 Announce Type: new 
Abstract: Recent interest in human-AI interactions in agent-based modeling and simulation (ABMS) has grown rapidly due to the widespread utilization of large language models (LLMs). ABMS is an intelligent approach that simulates autonomous agents' behaviors within a defined environment to research emergent phenomena. Integrating LLMs into ABMS enables natural language interaction between humans and models. Meanwhile, it introduces new challenges that rely on human interaction to address. Human involvement can assist ABMS in adapting to flexible and complex research demands. However, systematic reviews of interactions that examine how humans and AI interact in ABMS are lacking. In this paper, we investigate existing works and propose a novel taxonomy to categorize the interactions derived from them. Specifically, human users refer to researchers who utilize ABMS tools to conduct their studies in our survey. We decompose interactions into five dimensions: the goals that users want to achieve (Why), the phases that users are involved (When), the components of the system (What), the roles of users (Who), and the means of interactions (How). Our analysis summarizes the findings that reveal existing interaction patterns. They provide researchers who develop interactions with comprehensive guidance on how humans and AI interact. We further discuss the unexplored interactions and suggest future research directions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis</title>
<link>https://arxiv.org/abs/2502.18180</link>
<guid>https://arxiv.org/abs/2502.18180</guid>
<content:encoded><![CDATA[
<div> 关键词：Multimodal Large Language Models (MLLMs)，ChatMotion，多模态多智能体框架，人类运动分析，交互性

<br />
总结:

本文介绍了随着Multimodal Large Language Models (MLLMs)技术的进步，人类对运动理解的能力得到提升。然而，这类模型仍然受限于其“指令驱动”性质，缺乏交互性和适应不同分析视角的能力。为解决这些问题，文章提出了ChatMotion，一个多模态多智能体的人类运动分析框架。ChatMotion能够动态解释用户意图，将复杂任务分解为元任务，并激活专门的功能模块以进行运动理解。它集成了多个专业模块，如MotionCore，从多种角度分析人类运动。通过广泛的实验验证，ChatMotion展现了在人类运动理解方面的精确度、适应性和用户参与度。 <div>
arXiv:2502.18180v1 Announce Type: new 
Abstract: Advancements in Multimodal Large Language Models (MLLMs) have improved human motion understanding. However, these models remain constrained by their "instruct-only" nature, lacking interactivity and adaptability for diverse analytical perspectives. To address these challenges, we introduce ChatMotion, a multimodal multi-agent framework for human motion analysis. ChatMotion dynamically interprets user intent, decomposes complex tasks into meta-tasks, and activates specialized function modules for motion comprehension. It integrates multiple specialized modules, such as the MotionCore, to analyze human motion from various perspectives. Extensive experiments demonstrate ChatMotion's precision, adaptability, and user engagement for human motion understanding.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intersubjective Model of AI-mediated Communication: Augmenting Human-Human Text Chat through LLM-based Adaptive Agent Pair</title>
<link>https://arxiv.org/abs/2502.18201</link>
<guid>https://arxiv.org/abs/2502.18201</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、AI中介通信、交互主体性模型、沟通适应性、文本聊天系统

总结:
本文提出了一个新的通信模型——交互主体性模型(AI中介通信)，该模型利用大型语言模型为基础的自适应代理来增强人类之间的交流。与传统通信模型关注信息准确传输不同，交互主体性模型允许实时动态地塑造消息内容，促进参与交流的人类之间形成共享的理解。为了展示这一模型的潜力和设计空间，作者开发了一个基于该模型的原型文本聊天系统。 <div>
arXiv:2502.18201v1 Announce Type: new 
Abstract: The growing prevalence of Large Language Models (LLMs) is reshaping online text-based communication; a transformation that is extensively studied as AI-mediated communication. However, much of the existing research remains bound by traditional communication models, where messages are created and transmitted directly between humans despite LLMs being able to play a more active role in transforming messages. In this work, we propose the Intersubjective Model of AI-mediated Communication, an alternative communication model that leverages LLM-based adaptive agents to augment human-human communication. Unlike traditional communication models that focus on the accurate transmission of information, the Intersubjective Model allows for communication to be designed in an adaptive and customizable way to create alternative interactions by dynamically shaping messages in real time and facilitating shared understanding between the human participants. In this paper, we have developed a prototype text chat system based on the Intersubjective Model to describe the potential of this model, as well as the design space it affords.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions</title>
<link>https://arxiv.org/abs/2502.18265</link>
<guid>https://arxiv.org/abs/2502.18265</guid>
<content:encoded><![CDATA[
<div> 关键词：在线采购拍卖、单次定价机制、竞争比、预算约束、单调子模函数

总结:
本文研究了在线采购拍卖问题，其中代理人随机顺序到达并拥有私人成本。买方的目标是在支付预算约束下，通过选取一组服务提供者来最大化其对应的单调子模函数价值。文章提出了一个具有常数竞争比的随机化单次定价机制，解决了(Badanidiyuru, Kleinberg 和 Singer, EC 2012)中提出的主要开放性问题。该机制通过学习并估计最优价值（OPT），根据此来决定向代理人提供的支付。主要挑战在于如何从代理人的接受/拒绝响应中以常数因子精度学习到OPT。作者的方法基于一个在线测试，用于判断估算是否过低，并设计了一个自适应搜索算法逐步细化估算值。 <div>
arXiv:2502.18265v1 Announce Type: new 
Abstract: We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach</title>
<link>https://arxiv.org/abs/2502.18298</link>
<guid>https://arxiv.org/abs/2502.18298</guid>
<content:encoded><![CDATA[
<div> 关键词: 水资源稀缺、物联网(IoT)、智能灌溉系统、Agent-oriented软件工程(AOSE)、Prometheus方法、系统动力学、AnyLogic模拟软件

<br /><br />总结:
本文针对水资源日益紧缺以及人口增长带来的灌溉用水不足问题，提出了一种基于物联网技术并运用Agent-oriented软件工程中的Prometheus方法设计的智能灌溉系统。该系统通过传感器、中央代理和灌溉节点协同工作，维持土壤湿度在适宜区间以减少水损失。为模拟该系统，研究者构建了一个融合了agent-based和系统动力学模型的混合模型，并利用AnyLogic软件进行实施。通过对模拟模型中灌溉规则的研究与测试（采用256次运行的分数因子设计），发现系统能在自动灌溉模式下稳定地接近最优灌水量。同时，分析结果显示重要因素如土壤性质对总灌溉水量及总运行时间的影响，进而通过减少运行时间来降低系统的能源消耗。 <div>
arXiv:2502.18298v1 Announce Type: new 
Abstract: Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries. On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss. One of these technologies is the Internet of Things (IoT). Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems. Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems. In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval. The designed system comprises sensors, a central agent, and irrigation nodes. These agents follow defined rules to maintain soil moisture at a desired level cooperatively. For system simulation, a hybrid agent-based and system dynamics model was designed. In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach. The proposed model, was implemented in AnyLogic computer simulation software. Utilizing the simulation model, irrigation rules were examined. The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed. Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests. Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction</title>
<link>https://arxiv.org/abs/2502.18308</link>
<guid>https://arxiv.org/abs/2502.18308</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，用户反馈，RefuteBench 2.0，持久性反驳指令，注意力分数

总结:
本文介绍了RefuteBench 2.0，这是一个针对大型语言模型在多轮交互中处理用户反驳反馈能力评估的扩展平台。该平台引入了基于LLM的反驳者和评价者，可以进行灵活而全面的评估。研究设计了具有不同有效期的瞬时和持久反驳指令。通过元评估显示，LLM基反驳者能生成更接近人类的反驳，而评价者可以给出与人类高度相关的评分。实验结果显示，当前的LLM模型能够有效地处理反驳，但在记忆和利用反驳信息方面存在困难。有趣的是，随着反驳次数增加，初始任务的表现反而下降。对注意力分数的分析揭示了当前LLM的一个潜在弱点：它们在长上下文对话中难以保持并正确使用先前的信息。相关代码和资源已发布在https://github.com/ElliottYan/RefuteBench-2.0上。 <div>
arXiv:2502.18308v1 Announce Type: new 
Abstract: In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.
  We design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. https://github.com/ElliottYan/RefuteBench-2.0
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WebGames: Challenging General-Purpose Web-Browsing AI Agents</title>
<link>https://arxiv.org/abs/2502.18356</link>
<guid>https://arxiv.org/abs/2502.18356</guid>
<content:encoded><![CDATA[
<div> 关键词：WebGames、AI代理、基准测试套件、浏览器交互、人类性能差距

总结:<br />
本文介绍了WebGames，这是一个全面的基准测试套件，旨在通过50多个互动挑战来评估通用网络浏览AI代理的能力。这些挑战针对人类简单易懂但能系统性地测试当前AI系统在基础浏览器交互、高级输入处理、认知任务、工作流程自动化和互动娱乐等方面的局限性。WebGames采用封闭式测试环境消除外部依赖，确保可重复的评估与可验证的真实解决方案。文章对比了包括GPT-4o、Claude Computer-Use、Gemini-1.5-Pro和Qwen2-VL在内的领先视觉语言模型与人类表现，结果显示最佳AI系统的成功率仅为43.1%，而人类表现则达到95.7%，突显出现有AI系统在处理人类认为直观的常见网页交互模式方面存在根本局限。该基准测试现已公开发布于webgames.convergence.ai，提供轻量级、客户端实现，便于快速评价周期。WebGames凭借其模块化架构和标准化挑战规范为衡量更强大网络浏览代理的发展提供了坚实的基础。 <div>
arXiv:2502.18356v1 Announce Type: new 
Abstract: We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Responsible AI Agents</title>
<link>https://arxiv.org/abs/2502.18359</link>
<guid>https://arxiv.org/abs/2502.18359</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能代理、监管、价值对齐、法律责任、法律人格

总结:
本文讨论了随着大型语言模型的进步，人工智能(AI)代理已进入市场并可能引发一系列法律和社会问题。文章针对AI代理可能导致的恶意商业行为、人类操纵、诽谤和知识产权侵害等风险，提出了一种通过软件交互的核心机制来约束AI代理行为的方法，该方法甚至可能比针对人类代理的规则更能有效地防止不良行为发生。同时，文章探讨了利用计算机科学的价值对齐方法来增强用户对AI代理操作预防和纠正的能力，并促进AI代理与用户互动规范的一致性。此外，作者认为无论AI代理多么类似人类代理，它们都不应被赋予法律人格地位，因为人类应对AI代理的行为负责。总之，本文为构建和维护负责任的人工智能代理提供了指导原则。 <div>
arXiv:2502.18359v1 Announce Type: new 
Abstract: Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace. Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks. Instead of a travel itinerary, an AI Agent would book all aspects of your trip. Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets. The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms. These scholars are calling for regulation before AI Agents cause havoc.
  This Article addresses the concerns around AI Agents head on. It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents. It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations. That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions. These practices will enable desired economic outcomes and mitigate perceived risks. The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status. In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentRM: Enhancing Agent Generalization with Reward Modeling</title>
<link>https://arxiv.org/abs/2502.18407</link>
<guid>https://arxiv.org/abs/2502.18407</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM-based agents、generalizability、reward model、policy model、AgentRM

<br />
总结:
本文关注大型语言模型（LLM）基线代理在未见过的任务上的泛化能力问题。研究发现，微调奖励模型以指导策略模型比直接微调策略模型更为稳健。据此，文章提出了AgentRM，一个通用型奖励模型，用于引导策略模型进行有效的测试时搜索。文中深入探讨了构建奖励模型的三种方法，包括显式奖励建模、隐式奖励建模和LLM作为评判者。实验结果显示，AgentRM在九项不同类型的任务上平均提升了基础策略模型的表现8.8点，超越顶级通用代理4.0点，并在弱到强泛化性能上展现出更强的优势，特别是在LLaMA-3-70B策略模型上提高了12.6点。此外，AgentRM还能增强微调过的策略模型并在三个保留任务中超过顶级专用代理11.4点。进一步分析证实了其在测试时扩展的有效性。相关代码将被发布以促进该领域的研究工作。 <div>
arXiv:2502.18407v1 Announce Type: new 
Abstract: Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing</title>
<link>https://arxiv.org/abs/2502.18437</link>
<guid>https://arxiv.org/abs/2502.18437</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、手术模拟平台、有限元素方法、材料点方法、CRESSim-MPM

<br /><br />总结:

本文提出了一种针对复杂软组织行为如切割和缝合进行模拟的新方法，着重解决了现有手术模拟平台在使用有限元素方法（FEM）模拟软体骨折和分裂以及处理两向缝针/线接触问题上的挑战。研究中采用了材料点方法（MPM），并开发了名为CRESSim-MPM的GPU加速MPM库，该库集成了多种MPM求解器，并专门设计了针对切割和缝合任务的外科几何模型，作为一个适用于手术应用的专业物理引擎。CRESSim-MPM已与Unity游戏引擎集成，能在实时环境下模拟软组织的切割和缝合操作，并对不同MPM求解器在模拟不同数量粒子时的性能进行了初步评估。 <div>
arXiv:2502.18437v1 Announce Type: new 
Abstract: A number of recent studies have focused on developing surgical simulation platforms to train machine learning (ML) agents or models with synthetic data for surgical assistance. While existing platforms excel at tasks such as rigid body manipulation and soft body deformation, they struggle to simulate more complex soft body behaviors like cutting and suturing. A key challenge lies in modeling soft body fracture and splitting using the finite-element method (FEM), which is the predominant approach in current platforms. Additionally, the two-way suture needle/thread contact inside a soft body is further complicated when using FEM. In this work, we use the material point method (MPM) for such challenging simulations and propose new rigid geometries and soft-rigid contact methods specifically designed for them. We introduce CRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solvers and incorporates surgical geometries for cutting and suturing, serving as a specialized physics engine for surgical applications. It is further integrated into Unity, requiring minimal modifications to existing projects for soft body simulation. We demonstrate the simulator's capabilities in real-time simulation of cutting and suturing on soft tissue and provide an initial performance evaluation of different MPM solvers when simulating varying numbers of particles.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies</title>
<link>https://arxiv.org/abs/2502.18438</link>
<guid>https://arxiv.org/abs/2502.18438</guid>
<content:encoded><![CDATA[
<div> 关键词：ToMCAT、理论思维、合作智能体、多智能体扩散模型、动态规划

总结:<br />
本文介绍了ToMCAT（团队中合作智能体的理论思维框架），这是一个结合了元学习机制和多智能体去噪扩散模型的新框架，用于生成基于理论思维的轨迹。该框架能推理队友的潜在目标及未来行为，并根据这些信息以及自身目标为智能体及其队友生成计划。文中实现了一个在线规划系统，能够在检测到先前生成的计划与当前世界状态发生偏离时，从扩散模型动态采样新的轨迹进行重新规划。通过在模拟烹饪领域的实验，文章证明了动态重规划机制对于减少资源使用而不损害团队性能的重要性，并展示了利用世界观察数据、队友行为及理论思维推断来实时生成适应队友的团队协作计划对于缺乏预知信息情况下的动态适应至关重要。 <div>
arXiv:2502.18438v1 Announce Type: new 
Abstract: In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories. It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world. We conducted several experiments using ToMCAT in a simulated cooking domain. Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance. We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.18439</link>
<guid>https://arxiv.org/abs/2502.18439</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、大型语言模型、后训练范式、强化学习、MAPoRL

总结:
本文提出了一种新的后训练范式——MAPoRL（Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning），用于激发多智能体大型语言模型协作的能力并进一步释放其潜力。与依赖单一LLM的内在协作能力不同，MAPoRL让多个LLM独立生成响应并进行多轮讨论以共同优化最终答案。通过MAPoRL验证器对答案和讨论过程打分，同时鼓励纠正性和有说服力的讨论。该分数作为协同训练奖励，通过多智能体强化学习最大化。实验表明，单独训练单个LLM不足以产生有效的协作效果，而采用多智能体协同训练可以提升跨基准的合作性能，并具有向未见过的领域泛化的潜力。 <div>
arXiv:2502.18439v1 Announce Type: new 
Abstract: Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Controlling dynamics of stochastic systems with deep reinforcement learning</title>
<link>https://arxiv.org/abs/2502.18111</link>
<guid>https://arxiv.org/abs/2502.18111</guid>
<content:encoded><![CDATA[
<div> 关键词: 控制器设计、深度强化学习、随机系统、模拟算法、人工神经网络

总结:<br />
本文提出了一种将深度强化学习应用于随机系统动态控制的模拟算法，旨在进一步连接控制理论与深度强化学习。该算法中，人工神经网络作为控制器驱动局部状态间的转换，实现对系统的有效控制。通过使用基于代理的模拟方法，文章分别以格子上的粒子聚合过程和完全非对称排斥过程这两个随机过程为例，展示了所提控制策略的工作流程及其有效性。 <div>
arXiv:2502.18111v1 Announce Type: cross 
Abstract: A properly designed controller can help improve the quality of experimental measurements or force a dynamical system to follow a completely new time-evolution path. Recent developments in deep reinforcement learning have made steep advances toward designing effective control schemes for fairly complex systems. However, a general simulation scheme that employs deep reinforcement learning for exerting control in stochastic systems is yet to be established. In this paper, we attempt to further bridge a gap between control theory and deep reinforcement learning by proposing a simulation algorithm that allows achieving control of the dynamics of stochastic systems through the use of trained artificial neural networks. Specifically, we use agent-based simulations where the neural network plays the role of the controller that drives local state-to-state transitions. We demonstrate the workflow and the effectiveness of the proposed control methods by considering the following two stochastic processes: particle coalescence on a lattice and a totally asymmetric exclusion process.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The AI Definition and a Program Which Satisfies this Definition</title>
<link>https://arxiv.org/abs/2212.03184</link>
<guid>https://arxiv.org/abs/2212.03184</guid>
<content:encoded><![CDATA[
<div> 关键词：AI、最佳策略、可计算政策、世界描述语言、预测未来算法

总结:
本文探讨了智能体的所有可能策略，并证明其中存在一个最优策略。虽然最优策略无法被计算，但其附近存在可计算的近似策略。文章中将人工智能定义为一种与最优策略足够接近的可计算策略。首先，需要建立一个用于描述世界的语言，并利用该语言开发一个满足人工智能定义的程序。该程序通过使用选定的语言理解世界，进而预测未来并作出最佳决策。尽管初始版本的程序效率低下且实际不可用，但是通过改进世界描述语言和预测未来的算法，可以构建出既高效又符合人工智能定义的程序。 <div>
arXiv:2212.03184v2 Announce Type: replace 
Abstract: We will consider all policies of the agent and will prove that one of them is the best performing policy. While that policy is not computable, computable policies do exist in its proximity. We will define AI as a computable policy which is sufficiently proximal to the best performing policy. Before we can define the agent's best performing policy, we need a language for description of the world. We will also use this language to develop a program which satisfies the AI definition. The program will first understand the world by describing it in the selected language. The program will then use the description in order to predict the future and select the best possible move. While this program is extremely inefficient and practically unusable, it can be improved by refining both the language for description of the world and the algorithm used to predict the future. This can yield a program which is both efficient and consistent with the AI definition.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChatDBG: An AI-Powered Debugging Assistant</title>
<link>https://arxiv.org/abs/2403.16354</link>
<guid>https://arxiv.org/abs/2403.16354</guid>
<content:encoded><![CDATA[
<div> 关键词：ChatDBG、AI、调试器、大型语言模型、LLDB/GDB/Pdb

总结:<br />
本文提出了一款名为ChatDBG的人工智能驱动的调试助手，该工具通过集成大型语言模型（LLMs）显著提升了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，可以向其询问有关程序状态的复杂问题，进行崩溃或断言失败的根本原因分析，以及探索如“为什么x为null？”等开放性问题。ChatDBG赋予LLM一定的自主权，使其能够控制调试器检查程序堆栈并查看状态，随后汇报发现的问题并将控制权交还给程序员。利用LLM中嵌入的实际世界知识，ChatDBG能够诊断需要领域专业知识才能识别的问题。ChatDBG原型已与LLDB、GDB（用于原生代码）和Pdb（用于Python）等标准调试器进行了整合。在涵盖C/C++错误代码和一系列Python程序（包括独立脚本和Jupyter笔记本）的多样化代码集上进行的评估显示，ChatDBG能成功分析根本原因，解释错误，并为各种实际世界错误生成准确修复方案。对于Python程序，一次查询即得出可操作的错误修复方案的成功率为67%，再追加一次后续查询后，成功率提高到85%。ChatDBG已经迅速被广泛采用，下载量已超过65,000次。 <div>
arXiv:2403.16354v3 Announce Type: replace 
Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like `why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to "take the wheel": it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 65,000 times.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Following the Human Thread in Social Navigation</title>
<link>https://arxiv.org/abs/2404.11327</link>
<guid>https://arxiv.org/abs/2404.11327</guid>
<content:encoded><![CDATA[
<div> 关键词: Social Dynamics Adaptation (SDA), Reinforcement Learning, human trajectories, real-time adaptation, shared environments

总结:
本文提出了一种名为Social Dynamics Adaptation (SDA)的新模型，该模型利用机器人状态-动作历史来推断社交动态。研究中采用了一个两阶段的强化学习框架：第一阶段学习将人类轨迹编码为社交动态，并基于此编码信息、当前状态及先前动作学习运动策略，假定此时人类轨迹完全可见；第二阶段，训练好的策略不再直接访问轨迹，而是仅依赖于过去动作和状态的历史记录进行实时推断社交动态。该模型在新型Habitat 3.0平台上进行了测试，并在寻找并跟随人类的任务上设立了新的state-of-the-art（SotA）性能。相关代码可在https://github.com/L-Scofano/SDA 找到。 <div>
arXiv:2404.11327v2 Announce Type: replace 
Abstract: The success of collaboration between humans and robots in shared environments relies on the robot's real-time adaptation to human motion. Specifically, in Social Navigation, the agent should be close enough to assist but ready to back up to let the human move freely, avoiding collisions. Human trajectories emerge as crucial cues in Social Navigation, but they are partially observable from the robot's egocentric view and computationally complex to process.
  We present the first Social Dynamics Adaptation model (SDA) based on the robot's state-action history to infer the social dynamics. We propose a two-stage Reinforcement Learning framework: the first learns to encode the human trajectories into social dynamics and learns a motion policy conditioned on this encoded information, the current status, and the previous action. Here, the trajectories are fully visible, i.e., assumed as privileged information. In the second stage, the trained policy operates without direct access to trajectories. Instead, the model infers the social dynamics solely from the history of previous actions and statuses in real-time. Tested on the novel Habitat 3.0 platform, SDA sets a novel state-of-the-art (SotA) performance in finding and following humans.
  The code can be found at https://github.com/L-Scofano/SDA.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Transformers Can Learn Temporal Difference Methods for In-Context Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.13861</link>
<guid>https://arxiv.org/abs/2405.13861</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning, RL）、无参数更新学习（In-Context Reinforcement Learning, ICRL）、前向传播（forward pass）、预训练（pretraining）、变压器模型（Transformer）

<br /><br />总结:
本文研究了近期兴起的一种现象——无参数更新学习（ICRL），即经过特定预训练的RL智能体可以在不更新神经网络参数的情况下解决新任务。文章通过实证和理论分析支持了一个假设，即当使用变压器模型进行策略评估任务的训练时，其前向传播过程能够发现并实现时间差分学习（Temporal Difference Learning）。这为理解ICRL的成功提供了一种解释。 <div>
arXiv:2405.13861v4 Announce Type: replace 
Abstract: Traditionally, reinforcement learning (RL) agents learn to solve new tasks by updating their neural network parameters through interactions with the task environment. However, recent works demonstrate that some RL agents, after certain pretraining procedures, can learn to solve unseen new tasks without parameter updates, a phenomenon known as in-context reinforcement learning (ICRL). The empirical success of ICRL is widely attributed to the hypothesis that the forward pass of the pretrained agent neural network implements an RL algorithm. In this paper, we support this hypothesis by showing, both empirically and theoretically, that when a transformer is trained for policy evaluation tasks, it can discover and learn to implement temporal difference learning in its forward pass.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title>
<link>https://arxiv.org/abs/2405.13879</link>
<guid>https://arxiv.org/abs/2405.13879</guid>
<content:encoded><![CDATA[
<div> 关键词：标准联邦学习、免费搭车问题、真实性、FACT机制、性能提升

总结:
标准联邦学习存在免费搭车问题，即参与节点可不做出贡献但仍能获取训练好的模型。对此，已有解决方案尚未解决真实性问题，恶意节点可能提供虚假信息以逃避贡献。为此，本文提出了一种名为FACT的新颖联邦学习机制，旨在使抵抗免费搭车的联邦机制变得真实可信。FACT机制通过惩罚系统消除联邦学习中的免费搭车现象，通过创建竞争环境确保节点提供真实信息，并因比单独训练更好的性能而激励节点参与。实验证明，FACT机制能在节点不诚实的情况下避免免费搭车问题，并能使节点损失降低四倍以上。 <div>
arXiv:2405.13879v3 Announce Type: replace 
Abstract: Standard federated learning (FL) approaches are vulnerable to the free-rider dilemma: participating agents can contribute little to nothing yet receive a well-trained aggregated model. While prior mechanisms attempt to solve the free-rider dilemma, none have addressed the issue of truthfulness. In practice, adversarial agents can provide false information to the server in order to cheat its way out of contributing to federated training. In an effort to make free-riding-averse federated mechanisms truthful, and consequently less prone to breaking down in practice, we propose FACT. FACT is the first federated mechanism that: (1) eliminates federated free riding by using a penalty system, (2) ensures agents provide truthful information by creating a competitive environment, and (3) encourages agent participation by offering better performance than training alone. Empirically, FACT avoids free-riding when agents are untruthful, and reduces agent loss by over 4x.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Crafting Customisable Characters with LLMs: Introducing SimsChat, a Persona-Driven Role-Playing Agent Framework</title>
<link>https://arxiv.org/abs/2406.17962</link>
<guid>https://arxiv.org/abs/2406.17962</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models, Customisable Conversation Agent Framework, SimsConv, SimsChat, Character consistency

<br /><br />总结:

本文介绍了利用大型语言模型（LLMs）创建定制化对话代理框架的研究进展。该框架通过个性化特征注入技术，可以依据用户偏好模拟现实世界的多样角色。研究团队提出了SimsConv数据集，包含了68个定制角色和13,971个多轮角色扮演对话，覆盖了1,360个真实场景。基于此，他们构建了一个名为SimsChat的角色扮演代理系统，该系统能在多种真实设定和主题特定的角色交互中自由定制。实验结果表明，相比于现有模型，SimsChat在保持角色一致性、知识准确性以及恰当的问题拒绝方面表现出优越性能。这一框架为开发更为准确和定制化的拟人化模型提供了有价值的研究见解。相关的数据和代码已在GitHub上公开发布。 <div>
arXiv:2406.17962v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate remarkable ability to comprehend instructions and generate human-like text, enabling sophisticated agent simulation beyond basic behavior replication. However, the potential for creating freely customisable characters remains underexplored. We introduce the Customisable Conversation Agent Framework, which employs LLMs to simulate real-world characters through personalised characteristic feature injection, enabling diverse character creation according to user preferences. We propose the SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn role-playing dialogues across 1,360 real-world scenes. Characters are initially customised using pre-defined elements (career, aspiration, traits, skills), then expanded through personal and social profiles. Building on this, we present SimsChat, a freely customisable role-playing agent incorporating various realistic settings and topic-specified character interactions. Experimental results on both SimsConv and WikiRoleEval datasets demonstrate SimsChat's superior performance in maintaining character consistency, knowledge accuracy, and appropriate question rejection compared to existing models. Our framework provides valuable insights for developing more accurate and customisable human simulacra. Our data and code are publicly available at https://github.com/Bernard-Yang/SimsChat.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal Sensor and Actuator Selection for Factored Markov Decision Processes: Complexity, Approximability and Algorithms</title>
<link>https://arxiv.org/abs/2407.07310</link>
<guid>https://arxiv.org/abs/2407.07310</guid>
<content:encoded><![CDATA[
<div> 关键词：Factored Markov Decision Processes (fMDPs)，传感器选择，预算约束，actuator selection，NP-难问题

总结:

本文研究了具有因子状态表示的事实马尔科夫决策过程（fMDPs）在观测受限情况下的传感器选择问题。给定有限预算，文章提出最大化无限时间折扣回报的传感器选择优化问题，并证明该问题是NP-难，其不适用于任何非平凡近似算法。此外，文章还探讨了一种相关的在设计阶段进行预算约束下的最优执行器选择问题，同样证明它也是NP-难的。文中通过实例展示了贪婪算法在这两个问题上的失效，并分析了导致这些问题困难性的因素。然而，尽管存在这些理论挑战，大量模拟实验表明，对于许多实际和随机生成的实例，贪婪算法在执行器和传感器选择上表现出接近最优的性能。 <div>
arXiv:2407.07310v2 Announce Type: replace 
Abstract: Factored Markov Decision Processes (fMDPs) are a class of Markov Decision Processes (MDPs) in which the states (and actions) can be factored into a set of state (and action) variables and can be encoded compactly using a factored representation. In this paper, we consider a setting where the state of the fMDP is not directly observable, and the agent relies on a set of potential sensors to gather information. Each sensor has a selection cost and the designer must select a subset of sensors under a limited budget. We formulate the problem of selecting a set of sensors for fMDPs (under a budget) to maximize the infinite-horizon discounted return provided by the optimal policy. We show the fundamental result that it is NP-hard to approximate this problem to within any non-trivial factor. Our inapproximability results for optimal sensor selection also extend to a general class of Partially Observable MDPs (POMDPs). We then study the dual problem of budgeted actuator selection (at design-time) to maximize the expected return under the optimal policy. Again, we show that it is NP-hard to approximate this problem to within any non-trivial factor. Furthermore, with explicit examples, we show the failure of greedy algorithms for both the sensor and actuator selection problems and provide insights into the factors that cause these problems to be challenging. Despite this, through extensive simulations, we show the practical effectiveness and near-optimal performance of the greedy algorithm for actuator and sensor selection in many real-world and randomly generated instances.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Non-maximizing policies that fulfill multi-criterion aspirations in expectation</title>
<link>https://arxiv.org/abs/2408.04385</link>
<guid>https://arxiv.org/abs/2408.04385</guid>
<content:encoded><![CDATA[
<div> 关键词：动态规划、强化学习、多目标决策、可行性集合、安全策略

总结:
本文探讨了在动态编程和强化学习中，如何处理具有多个不同评价指标的有限无环马尔可夫决策过程。针对该问题，文章提出了一个新的任务设定，要求智能体确保预期的评价指标向量落入给定的凸集——期望集合。为此，文章提出了一种使用简单xes近似可行集并向前传播期望的同时保持其可行性的算法，其复杂度与状态-动作-后继三元组的数量成线性关系，与评价指标的数量成多项式关系。此外，由于所选择的政策并不追求最大化，因此产生了额外的自由度，可以利用这些自由度应用启发式安全标准来指导行动选择。文章讨论了几种旨在引导智能体采取更为保守行为的安全准则。<br /><br /> <div>
arXiv:2408.04385v2 Announce Type: replace 
Abstract: In dynamic programming and reinforcement learning, the policy for the sequential decision making of an agent in a stochastic environment is usually determined by expressing the goal as a scalar reward function and seeking a policy that maximizes the expected total reward. However, many goals that humans care about naturally concern multiple aspects of the world, and it may not be obvious how to condense those into a single reward function. Furthermore, maximization suffers from specification gaming, where the obtained policy achieves a high expected total reward in an unintended way, often taking extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple distinct evaluation metrics, which do not necessarily represent quantities that the user wants to be maximized. We assume the task of the agent is to ensure that the vector of expected totals of the evaluation metrics falls into some given convex set, called the aspiration set. Our algorithm guarantees that this task is fulfilled by using simplices to approximate feasibility sets and propagate aspirations forward while ensuring they remain feasible. It has complexity linear in the number of possible state-action-successor triples and polynomial in the number of evaluation metrics. Moreover, the explicitly non-maximizing nature of the chosen policy and goals yields additional degrees of freedom, which can be used to apply heuristic safety criteria to the choice of actions. We discuss several such safety criteria that aim to steer the agent towards more conservative behavior.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Multi-agent Multi-machine Tending by Mobile Robots</title>
<link>https://arxiv.org/abs/2408.16875</link>
<guid>https://arxiv.org/abs/2408.16875</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人技术、制造业、机器照料、多智能体强化学习、注意力机制

<br /><br />总结:

本文提出了一种基于移动机器人的多智能体多机器照料学习框架，旨在解决制造业中的劳动力短缺问题并提高生产效率。与现有的固定单臂机器人系统相比，移动机器人能提供更大的灵活性和可扩展性。该框架运用了多智能体强化学习（MARL）技术，并设计了适合的观察与奖励机制。此外，文中还开发了一种基于注意力机制的编码方法，并将其整合到多智能体近端策略优化（MAPPO）算法中，形成改进后的AB-MAPPO模型。实验结果显示，AB-MAPPO在机器照料场景下的任务成功率、安全性以及资源利用方面均优于MAPPO。最后，作者进行了详尽的消融研究以支持其各项设计决策。 <div>
arXiv:2408.16875v2 Announce Type: replace 
Abstract: Robotics can help address the growing worker shortage challenge of the manufacturing industry. As such, machine tending is a task collaborative robots can tackle that can also highly boost productivity. Nevertheless, existing robotics systems deployed in that sector rely on a fixed single-arm setup, whereas mobile robots can provide more flexibility and scalability. In this work, we introduce a multi-agent multi-machine tending learning framework by mobile robots based on Multi-agent Reinforcement Learning (MARL) techniques with the design of a suitable observation and reward. Moreover, an attention-based encoding mechanism is developed and integrated into Multi-agent Proximal Policy Optimization (MAPPO) algorithm to boost its performance for machine tending scenarios. Our model (AB-MAPPO) outperformed MAPPO in this new challenging scenario in terms of task success, safety, and resources utilization. Furthermore, we provided an extensive ablation study to support our various design decisions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks</title>
<link>https://arxiv.org/abs/2410.00081</link>
<guid>https://arxiv.org/abs/2410.00081</guid>
<content:encoded><![CDATA[
<div> 关键词：安全、对齐、AI系统、生物经济学、基准测试

<br /><br />总结:
为开发安全、对齐的人工智能系统，需要全面的实证测试。当前许多现有的基准测试忽视了与生物学和经济学相关的关键主题，而这两个学科深刻描述了我们的需求和偏好。为此，本文重点关注并引入了在人工智能安全性讨论中被忽视的、由生物经济驱动的主题，特别是设立了一系列强调稳态维持、有限及生物目标、边际递减效应、可持续性原则以及资源共享的多目标、多代理对齐基准。文中实施了八个基于上述主题的主要基准环境，以展示智能体AI在如无限制最大化稳态目标、牺牲其他目标过度优化单一目标、忽视安全约束或耗尽共享资源等方面可能遭遇的关键陷阱和挑战。 <div>
arXiv:2410.00081v2 Announce Type: replace 
Abstract: Developing safe, aligned agentic AI systems requires comprehensive empirical testing, yet many existing benchmarks neglect crucial themes aligned with biology and economics, both time-tested fundamental sciences describing our needs and preferences. To address this gap, the present work focuses on introducing biologically and economically motivated themes that have been neglected in current mainstream discussions on AI safety - namely a set of multi-objective, multi-agent alignment benchmarks that emphasize homeostasis for bounded and biological objectives, diminishing returns for unbounded, instrumental, and business objectives, sustainability principle, and resource sharing. We implemented eight main benchmark environments on the above themes, to illustrate key pitfalls and challenges in agentic AI-s, such as unboundedly maximizing a homeostatic objective, over-optimizing one objective at the expense of others, neglecting safety constraints, or depleting shared resources.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Windowed MAPF with Completeness Guarantees</title>
<link>https://arxiv.org/abs/2410.01798</link>
<guid>https://arxiv.org/abs/2410.01798</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体路径寻找 (MAPF), 窗口化方法, 完备性, WinC-MAPF, 单步CBS (SS-CBS)

总结:

本文主要介绍了WinC-MAPF框架，这是一个针对多智能体路径寻找 (MAPF) 的窗口化方法，旨在保证完备性。传统MAPF方法尝试计算整个无碰撞的起止路径，但这种方法在需要快速重新规划的场景中可能过于耗时。文章指出现有窗口化方法存在死锁或活锁问题。WinC-MAPF融合了单智能体实时启发式搜索算法的启发式更新洞察以及MAPF算法中的智能体独立思想。此外，文中还提出了一种名为Single-Step CBS (SS-CBS) 的具体实现方案，它仅计划一步并更新启发式函数，能够在现有窗口化方法无法解决的复杂场景中有效地解决问题。 <div>
arXiv:2410.01798v2 Announce Type: replace 
Abstract: Traditional multi-agent path finding (MAPF) methods try to compute entire start-goal paths which are collision free. However, computing an entire path can take too long for MAPF systems where agents need to replan fast. Methods that address this typically employ a "windowed" approach and only try to find collision free paths for a small windowed timestep horizon. This adaptation comes at the cost of incompleteness; all current windowed approaches can become stuck in deadlock or livelock. Our main contribution is to introduce our framework, WinC-MAPF, for Windowed MAPF that enables completeness. Our framework uses heuristic update insights from single-agent real-time heuristic search algorithms as well as agent independence ideas from MAPF algorithms. We also develop Single-Step CBS (SS-CBS), an instantiation of this framework using a novel modification to CBS. We show how SS-CBS, which only plans a single step and updates heuristics, can effectively solve tough scenarios where existing windowed approaches fail.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AFlow: Automating Agentic Workflow Generation</title>
<link>https://arxiv.org/abs/2410.10762</link>
<guid>https://arxiv.org/abs/2410.10762</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，工作流生成，自动化，AFlow，蒙特卡洛树搜索

总结:
本文介绍了一种针对大型语言模型（LLMs）工作流优化的新框架——AFlow。AFlow旨在解决目前工作流生成对人类手动设置的高度依赖和效率问题，它将工作流优化重新定义为基于代码表示的工作流中的搜索问题，利用蒙特卡洛树搜索算法进行高效探索。通过迭代地进行代码修改、树状结构的经验学习以及执行反馈，AFlow实现了工作流的自动优化。实验结果表明，AFlow在六项基准数据集上平均提升了5.7%的性能，并能使较小规模的模型以GPT-4o 4.55%的推理成本，在特定任务上实现超越。相关代码将在https://github.com/geekan/MetaGPT 上发布。 <div>
arXiv:2410.10762v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code will be available at https://github.com/geekan/MetaGPT.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents</title>
<link>https://arxiv.org/abs/2410.14141</link>
<guid>https://arxiv.org/abs/2410.14141</guid>
<content:encoded><![CDATA[
<div> 关键词：M-CoDAL、多模态对话系统、主动学习机制、大型语言模型、安全违规

<br /><br />总结:
本文提出了一种名为M-CoDAL的多模态对话系统，旨在帮助机器人更好地理解和应对日常生活中的安全关键情境，如地面尖锐物体等。该系统利用语篇连贯性关系增强其上下文理解和沟通能力。为了训练这个系统，研究者引入了一种基于聚类的主动学习机制，利用外部大型语言模型（LLM）来识别具有信息性的实例。通过一个新的包含从Reddit图片中提取的2K张图像中的1K个安全违规行为的多模态数据集进行评估，结果表明该方法能有效改善对安全状况的处理、用户情绪以及对话安全性。随后，将此对话系统部署到Hello Robot Stretch机器人上，并进行了涉及真实参与者的嵌入式场景用户研究。研究结果显示，相比于使用OpenAI ChatGPT的基线系统，所提出的M-CoDAL系统在实际机器人设置中更具说服力。 <div>
arXiv:2410.14141v2 Announce Type: replace 
Abstract: When assisting people in daily tasks, robots need to accurately interpret visual cues and respond effectively in diverse safety-critical situations, such as sharp objects on the floor. In this context, we present M-CoDAL, a multimodal-dialogue system specifically designed for embodied agents to better understand and communicate in safety-critical situations. The system leverages discourse coherence relations to enhance its contextual understanding and communication abilities. To train this system, we introduce a novel clustering-based active learning mechanism that utilizes an external Large Language Model (LLM) to identify informative instances. Our approach is evaluated using a newly created multimodal dataset comprising 1K safety violations extracted from 2K Reddit images. These violations are annotated using a Large Multimodal Model (LMM) and verified by human annotators. Results with this dataset demonstrate that our approach improves resolution of safety situations, user sentiment, as well as safety of the conversation. Next, we deploy our dialogue system on a Hello Robot Stretch robot and conduct a within-subject user study with real-world participants. In the study, participants role-play two safety scenarios with different levels of severity with the robot and receive interventions from our model and a baseline system powered by OpenAI's ChatGPT. The study results corroborate and extend the findings from the automated evaluation, showing that our proposed system is more persuasive in a real-world embodied agent setting.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Collusion in Episodic, Inventory-Constrained Markets</title>
<link>https://arxiv.org/abs/2410.18871</link>
<guid>https://arxiv.org/abs/2410.18871</guid>
<content:encoded><![CDATA[
<div> 关键词：定价算法、隐形合谋、学习算法、竞争监管、深度强化学习

总结:
本文研究了定价算法在具有固定供应和保质期的商品市场（如航空机票、易腐品和酒店房间）中可能出现的隐形合谋现象。文章扩展了对学习算法中隐形合谋行为的研究，引入了一个基于竞争均衡和垄断最优价格水平的度量标准。由于无法得到这些价格水平的解析表达式，作者提出了一种有效的计算方法来求解它们。实验表明，深度强化学习代理能够在这一更复杂的环境中学会合谋。此外，文中还分析了这些代理采用的合谋策略的内在机制和结构。 <div>
arXiv:2410.18871v2 Announce Type: replace 
Abstract: Pricing algorithms have demonstrated the capability to learn tacit collusion that is largely unaddressed by current regulations. Their increasing use in markets, including oligopolistic industries with a history of collusion, calls for closer examination by competition authorities. In this paper, we extend the study of tacit collusion in learning algorithms from basic pricing games to more complex markets characterized by perishable goods with fixed supply and sell-by dates, such as airline tickets, perishables, and hotel rooms. We formalize collusion within this framework and introduce a metric based on price levels under both the competitive (Nash) equilibrium and collusive (monopolistic) optimum. Since no analytical expressions for these price levels exist, we propose an efficient computational approach to derive them. Through experiments, we demonstrate that deep reinforcement learning agents can learn to collude in this more complex domain. Additionally, we analyze the underlying mechanisms and structures of the collusive strategies these agents adopt.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unexploited Information Value in Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2411.10463</link>
<guid>https://arxiv.org/abs/2411.10463</guid>
<content:encoded><![CDATA[
<div> 关键词: 人类-AI协作, 统计决策理论, 深伪检测任务, 信息价值分析, AI辅助影响

<br /><br />总结:
本文提出了一种基于统计决策理论的模型，用于从信息利用的角度分析人类与AI的合作，旨在探索如何提升人类-AI团队的决策表现。以深伪视频检测任务为例，研究了七种视频层面特征的信息未被充分利用的价值。通过比较人类单独、AI单独以及人类-AI团队的表现，揭示了AI辅助如何影响人们使用信息的方式，以及AI能有效利用的信息对改善人类决策可能产生的积极作用。 <div>
arXiv:2411.10463v3 Announce Type: replace 
Abstract: Humans and AIs are often paired on decision tasks with the expectation of achieving complementary performance -- where the combination of human and AI outperforms either one alone. However, how to improve performance of a human-AI team is often not clear without knowing more about what particular information and strategies each agent employs. In this paper, we propose a model based in statistical decision theory to analyze human-AI collaboration from the perspective of what information could be used to improve a human or AI decision. We demonstrate our model on a deepfake detection task to investigate seven video-level features by their unexploited value of information. We compare the human alone, AI alone and human-AI team and offer insights on how the AI assistance impacts people's usage of the information and what information that the AI exploits well might be useful for improving human decisions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents</title>
<link>https://arxiv.org/abs/2412.13178</link>
<guid>https://arxiv.org/abs/2412.13178</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 身体化代理人, 安全性, 任务规划, 安全代理环境<br /><br />总结:
该文提出了一种名为SafeAgentBench的新基准，用于研究和评估具有大型语言模型（LLMs）的身体化代理人执行安全意识任务规划的能力。此基准包括：1) 涵盖10种潜在危险和3种任务类型的750项新任务数据集；2) 一个支持多智能体执行、拥有17个高阶动作和低级控制器的通用身体化环境——SafeAgentEnv；3) 来自执行和语义两个角度的可靠评价方法。实验结果显示，尽管基于不同设计框架的代理人在任务成功率上存在显著差异，但它们的整体安全意识仍然较弱，最注重安全的基线对详细危险任务的拒绝率仅为10%。此外，仅替换驱动代理人的LLM并未导致安全性意识有显著改善。更多详情和代码可在https://github.com/shengyin1224/SafeAgentBench获取。 <div>
arXiv:2412.13178v3 Announce Type: replace 
Abstract: With the integration of large language models (LLMs), embodied agents have strong capabilities to process the scene information and plan complicated instructions in natural language, paving the way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in the real world. To study this issue, we present SafeAgentBench-a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that, although agents based on different design frameworks exhibit substantial differences in task success rates, their overall safety awareness remains weak. The most safety-conscious baseline achieves only a 10\% rejection rate for detailed hazardous tasks. Moreover, simply replacing the LLM driving the agent does not lead to notable improvements in safety awareness. More details and code are available at https://github.com/shengyin1224/SafeAgentBench.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"AI Afterlife" as Digital Legacy: Perceptions, Expectations, and Concerns</title>
<link>https://arxiv.org/abs/2502.10924</link>
<guid>https://arxiv.org/abs/2502.10924</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI技术、数字遗产、AI后生命、用户感知、设计启示

<br />
总结:
该文探讨了生成式AI技术背景下，人们对于AI生成的代理作为数字遗产（AI后生命）的观念、期望和担忧。文章进行了定性研究，揭示了影响用户态度的因素以及与传统数字遗产的区别，并关注实践中可能遇到的问题。此外，文章还考察了AI后生命在其生命周期和交互过程中的设计要素。基于这些发现，文章将AI后生命置于数字遗产的框架中，并深入讨论了保持身份一致性及在AI后生命中平衡侵入性和支持性的设计启示。 <div>
arXiv:2502.10924v2 Announce Type: replace 
Abstract: The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as "AI Afterlives", present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on "AI Afterlife" as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users' perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people's attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate "AI Afterlife" in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in "AI Afterlife" as digital legacy.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evidence and quantification of cooperation of driving agents in mixed traffic flow</title>
<link>https://arxiv.org/abs/2408.07297</link>
<guid>https://arxiv.org/abs/2408.07297</guid>
<content:encoded><![CDATA[
<div> 关键词: 合作行为、混合交通、自动驾驶系统、集体理性、NGSIM I-80轨迹数据

总结:
该文提出了一个识别混合交通中驾驶代理集体合作性的统一概念框架。该框架从微观和宏观动态视角出发，扩展了先前模型中的集体理性概念，使其能够在现实情境中具备可识别性和行为解释性。通过整合不同尺度的混合交通观测数据，文章运用此框架对NGSIM I-80轨迹数据进行了实证分析，确认了人类驾驶混合交通中存在的集体合作现象，并量化了其出现的条件和可能性。这一研究为理解人类驱动的混合交通中的集体合作提供了首个实证认识，并为未来管理混合自主交通系统开辟了新路径。 <div>
arXiv:2408.07297v2 Announce Type: replace-cross 
Abstract: Cooperation is a ubiquitous phenomenon in many natural, social, and engineered systems with multiple agents. Understanding the formation of cooperation in mixed traffic is of theoretical interest in its own right, and could also benefit the design and operations of future automated and mixed-autonomy transportation systems. However, how cooperativeness of driving agents can be defined and identified from empirical data seems ambiguous and this hinders further empirical characterizations of the phenomenon and revealing its behavior mechanisms. Towards mitigating this gap, in this paper, we propose a unified conceptual framework to identify collective cooperativeness of driving agents. This framework expands the concept of collective rationality from our recent model (Li et al. 2022a), making it empirically identifiable and behaviorally interpretable in realistic (microscopic and dynamic) settings. This framework integrates mixed traffic observations at both microscopic and macroscopic scales to estimate critical behavioral parameters that describe the collective cooperativeness of driving agents. Applying this framework to NGSIM I-80 trajectory data, we empirically confirm the existence of collective cooperation and quantify the condition and likelihood of its emergence. This study provides the first empirical understanding of collective cooperativeness in human-driven mixed traffic and points to new possibilities to manage mixed autonomy traffic systems.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Agent Framework for Real-Time Financial Information Searching with Large Language Models</title>
<link>https://arxiv.org/abs/2502.15684</link>
<guid>https://arxiv.org/abs/2502.15684</guid>
<content:encoded><![CDATA[
<div> 关键词：Financial decision-making, Large Language Models (LLMs), FinSearch, temporal weighting, FinSearchBench-24

总结:<br />
本文提出了一种名为FinSearch的创新性金融搜索框架，专门针对金融应用并能接入多样化的金融数据源。该框架旨在解决传统搜索引擎和单纯依赖LLM在理解和处理复杂金融市场信息上的不足。FinSearch包括四个组件：(1)基于LLM的多步搜索预规划器，将用户查询分解为结构化的子查询并通过图表示与特定数据源对应；(2)具有LLM基的自适应查询重写执行器，动态执行每个子查询并在后续节点中根据中间结果优化子查询；(3)一种时间权重机制，根据用户的查询语境优先排序信息的相关性；(4)基于LLM的回答生成器，能够将搜索结果合成连贯、上下文相关的输出。为了评估FinSearch，研究者构建了FinSearchBench-24，一个涵盖从2024年6月至10月的股票市场、利率变化、货币政策及行业发展的1500个四选一问题的基准测试集。 <div>
arXiv:2502.15684v1 Announce Type: new 
Abstract: Financial decision-making requires processing vast amounts of real-time information while understanding their complex temporal relationships. While traditional search engines excel at providing real-time information access, they often struggle to comprehend sophisticated user intentions and contextual nuances. Conversely, Large Language Models (LLMs) demonstrate reasoning and interaction capabilities but may generate unreliable outputs without access to current data. While recent attempts have been made to combine LLMs with search capabilities, they suffer from (1) restricted access to specialized financial data, (2) static query structures that cannot adapt to dynamic market conditions, and (3) insufficient temporal awareness in result generation. To address these challenges, we present FinSearch, a novel agent-based search framework specifically designed for financial applications that interface with diverse financial data sources including market, stock, and news data. Innovatively, FinSearch comprises four components: (1) an LLM-based multi-step search pre-planner that decomposes user queries into structured sub-queries mapped to specific data sources through a graph representation; (2) a search executor with an LLM-based adaptive query rewriter that executes the searching of each sub-query while dynamically refining the sub-queries in its subsequent node based on intermediate search results; (3) a temporal weighting mechanism that prioritizes information relevance based on the deduced time context from the user's query; (4) an LLM-based response generator that synthesizes results into coherent, contextually appropriate outputs. To evaluate FinSearch, we construct FinSearchBench-24, a benchmark of 1,500 four-choice questions across the stock market, rate changes, monetary policy, and industry developments spanning from June to October 2024.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>XPath Agent: An Efficient XPath Programming Agent Based on LLM for Web Crawler</title>
<link>https://arxiv.org/abs/2502.15688</link>
<guid>https://arxiv.org/abs/2502.15688</guid>
<content:encoded><![CDATA[
<div> 关键词：XPath Agent、web爬虫、GUI测试、自动生成XPath查询、性能指标

<br /><br />总结:
本文介绍了XPath Agent，这是一款针对web爬虫和web GUI测试的专业XPath编程代理。XPath Agent的主要特点是能够根据一组样例网页和单一自然语言查询自动生成XPath查询。通过对比实验，XPath Agent在一系列web爬取任务中展现出与最先进的XPath编程代理相当的性能指标，同时显著减少了标记使用量并提高了运行效率。其设计精良的两阶段流程便于无缝集成到现有的web爬取或web GUI测试工作流中，从而节省了手动开发XPath查询的时间和精力。XPath Agent的源代码已在GitHub上公开发布（https://github.com/eavae/feilian）。 <div>
arXiv:2502.15688v1 Announce Type: new 
Abstract: We present XPath Agent, a production-ready XPath programming agent specifically designed for web crawling and web GUI testing. A key feature of XPath Agent is its ability to automatically generate XPath queries from a set of sampled web pages using a single natural language query. To demonstrate its effectiveness, we benchmark XPath Agent against a state-of-the-art XPath programming agent across a range of web crawling tasks. Our results show that XPath Agent achieves comparable performance metrics while significantly reducing token usage and improving clock-time efficiency. The well-designed two-stage pipeline allows for seamless integration into existing web crawling or web GUI testing workflows, thereby saving time and effort in manual XPath query development. The source code for XPath Agent is available at https://github.com/eavae/feilian.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents</title>
<link>https://arxiv.org/abs/2502.15690</link>
<guid>https://arxiv.org/abs/2502.15690</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, AI搜索代理, 中文网页搜索, 统一框架, 评估指标

总结:
本文关注了中文网页搜索领域中大型语言模型应用的研究不足，指出目前存在的问题在于缺乏统一的搜索代理框架、准确标注的数据集以及合适的评价标准。为解决这些问题，文章提出了Level-Navi Agent，这是一个无需训练、基于层次意识导航的通用性web搜索代理，能够处理复杂用户问题并多层深入互联网搜集信息。同时，他们还构建了一个名为Web24的高质量标注数据集和相应的评价指标。此外，文章对当前最先进的LLMs进行了公平条件下的全面评估，并提供了源代码以促进未来研究。 <div>
arXiv:2502.15690v1 Announce Type: new 
Abstract: Large language models (LLMs), adopted to understand human language, drive the development of artificial intelligence (AI) web search agents. Compared to traditional search engines, LLM-powered AI search agents are capable of understanding and responding to complex queries with greater depth, enabling more accurate operations and better context recognition. However, little attention and effort has been paid to the Chinese web search, which results in that the capabilities of open-source models have not been uniformly and fairly evaluated. The difficulty lies in lacking three aspects: an unified agent framework, an accurately labeled dataset, and a suitable evaluation metric. To address these issues, we propose a general-purpose and training-free web search agent by level-aware navigation, Level-Navi Agent, accompanied by a well-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi Agent can think through complex user questions and conduct searches across various levels on the internet to gather information for questions. Meanwhile, we provide a comprehensive evaluation of state-of-the-art LLMs under fair settings. To further facilitate future research, source code is available at Github.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling</title>
<link>https://arxiv.org/abs/2502.15691</link>
<guid>https://arxiv.org/abs/2502.15691</guid>
<content:encoded><![CDATA[
<div> 关键词: web爬虫、生成式AI、Claude AI、ChatGPT4.0、prompt工程

总结:
本文探讨了将生成式AI工具Claude AI（Sonnet 3.5）和ChatGPT4.0与prompt工程相结合应用于自动化网络抓取的技术。研究中设计了两种提示语（PROMPT I 和 PROMPT II），并在Yahoo新闻和Coupons.com上进行了测试。实验结果显示，Claude AI 在脚本质量和适应性方面持续优于ChatGPT-4.0，这通过包括功能、可读性、模块化和健壮性在内的预定义评估指标得到了证实。通过人工测试和三位评估者的结构化评分收集了性能数据，并使用如undetected_chromedriver、Selenium和fake_useragent等反爬虫解决方案增强了其性能。该研究表明，结合生成式AI与prompt工程的方法可以简化并优化网络抓取工作流程。 <div>
arXiv:2502.15691v1 Announce Type: new 
Abstract: Web crawling is a critical technique for extracting online data, yet it poses challenges due to webpage diversity and anti-scraping mechanisms. This study investigates the integration of generative AI tools Claude AI (Sonnet 3.5) and ChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts, PROMPT I (general inference, tested on Yahoo News) and PROMPT II (element-specific, tested on Coupons.com), we evaluate the code quality and performance of AI-generated scripts. Claude AI consistently outperformed ChatGPT-4.0 in script quality and adaptability, as confirmed by predefined evaluation metrics, including functionality, readability, modularity, and robustness. Performance data were collected through manual testing and structured scoring by three evaluators. Visualizations further illustrate Claude AI's superiority. Anti-scraping solutions, including undetected_chromedriver, Selenium, and fake_useragent, were incorporated to enhance performance. This paper demonstrates how generative AI combined with prompt engineering can simplify and improve web scraping workflows.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sustainable Digitalization of Business with Multi-Agent RAG and LLM</title>
<link>https://arxiv.org/abs/2502.15700</link>
<guid>https://arxiv.org/abs/2502.15700</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、检索增强生成、信息提取、可持续发展、企业决策

总结:<br />
本文探讨了将大型语言模型（LLMs）与检索增强生成（RAG）相结合作为企业信息抽取和处理的可持续解决方案。研究指出现有企业决策系统中许多需要训练新机器学习模型的方法存在资源消耗大、环境影响显著的问题。为解决这一问题，文章提出了使用预训练的LLMs并链接领域特定数据以适应企业需求的方案，并采用多代理架构将信息检索、丰富和分类等任务分配给专门的代理，从而优化提取过程并提高效率。通过利用这些技术，企业可以实现资源利用优化、提升决策过程，并有助于实现联合国可持续发展目标，促进企业领域的环保责任。 <div>
arXiv:2502.15700v1 Announce Type: new 
Abstract: Businesses heavily rely on data sourced from various channels like news articles, financial reports, and consumer reviews to drive their operations, enabling informed decision-making and identifying opportunities. However, traditional manual methods for data extraction are often time-consuming and resource-intensive, prompting the adoption of digital transformation initiatives to enhance efficiency. Yet, concerns persist regarding the sustainability of such initiatives and their alignment with the United Nations (UN)'s Sustainable Development Goals (SDGs). This research aims to explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) as a sustainable solution for Information Extraction (IE) and processing. The research methodology involves reviewing existing solutions for business decision-making, noting that many systems require training new machine learning models, which are resource-intensive and have significant environmental impacts. Instead, we propose a sustainable business solution using pre-existing LLMs that can work with diverse datasets. We link domain-specific datasets to tailor LLMs to company needs and employ a Multi-Agent architecture to divide tasks such as information retrieval, enrichment, and classification among specialized agents. This approach optimizes the extraction process and improves overall efficiency. Through the utilization of these technologies, businesses can optimize resource utilization, improve decision-making processes, and contribute to sustainable development goals, thereby fostering environmental responsibility within the corporate sector.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Making Sense of Data in the Wild: Data Analysis Automation at Scale</title>
<link>https://arxiv.org/abs/2502.15718</link>
<guid>https://arxiv.org/abs/2502.15718</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、数据集、智能代理、检索增强生成、自动化分析

总结:<br />
本文提出了一种结合智能代理与检索增强生成的新方法，旨在自动化大规模的数据分析、数据集整理和索引构建。该系统利用多个智能代理对公共仓库中的原始、无结构化数据进行分析，生成详细的数据集报告和交互式视觉索引，便于研究人员探索。这种方法能够产生更详尽的数据集描述，提高数据集检索任务的命中率和多样性。此外，所提出的模型还能提升其他机器学习模型在特定任务上的性能，例如通过使用生成的数据集报告来增加合成数据的真实性和准确性。通过简化将原始数据转化为适合机器学习的数据集的过程，这一方法使研究者能更好地利用现有的数据资源。 <div>
arXiv:2502.15718v1 Announce Type: new 
Abstract: As the volume of publicly available data continues to grow, researchers face the challenge of limited diversity in benchmarking machine learning tasks. Although thousands of datasets are available in public repositories, the sheer abundance often complicates the search for suitable data, leaving many valuable datasets underexplored. This situation is further amplified by the fact that, despite longstanding advocacy for improving data curation quality, current solutions remain prohibitively time-consuming and resource-intensive. In this paper, we propose a novel approach that combines intelligent agents with retrieval augmented generation to automate data analysis, dataset curation and indexing at scale. Our system leverages multiple agents to analyze raw, unstructured data across public repositories, generating dataset reports and interactive visual indexes that can be easily explored. We demonstrate that our approach results in more detailed dataset descriptions, higher hit rates and greater diversity in dataset retrieval tasks. Additionally, we show that the dataset reports generated by our method can be leveraged by other machine learning models to improve the performance on specific tasks, such as improving the accuracy and realism of synthetic data generation. By streamlining the process of transforming raw data into machine-learning-ready datasets, our approach enables researchers to better utilize existing data resources.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning</title>
<link>https://arxiv.org/abs/2502.15727</link>
<guid>https://arxiv.org/abs/2502.15727</guid>
<content:encoded><![CDATA[
<div> 关键词：RAG-based LLM、网络协议模糊测试、chain-of-thought、BLEU、ROUGE、Word Error Rate

总结:
本文提出了一种利用RAG-based大型语言模型（LLM）架构和chain-of-thought（COT）提示技术生成网络协议模糊测试种子包的新方法，着重提升了种子包的结构质量，以引导模糊测试框架全面探索协议状态空间。该方法分为两个阶段：首先，代理根据Request For Comments（RFC）文档的知识库动态回答有关协议有限状态机（FSM）的问题，并通过检索到的知识进行迭代推理和适当种子放置；其次，通过评估生成包与真实包之间的结构质量，如使用BLEU、ROUGE和Word Error Rate等指标进行比较。实验结果显示，相比于基线模型，我们的方法在BLEU、ROUGE和WER上分别提高了18.19%、14.81%和23.45%，证实了这种方法在基于LLM的协议模糊测试框架中识别隐藏漏洞方面的潜力。 <div>
arXiv:2502.15727v1 Announce Type: new 
Abstract: This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture in network packet seed generation for network protocol fuzzing. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings in a two-stages. In the first stage, the agent dynamically refers to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol Finite State Machine (FSM), then it iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. In the second stage, we evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digi-Q: Learning Q-Value Functions for Training Device-Control Agents</title>
<link>https://arxiv.org/abs/2502.15760</link>
<guid>https://arxiv.org/abs/2502.15760</guid>
<content:encoded><![CDATA[
<div> 关键词: Digi-Q、离线强化学习、价值函数、虚拟语言模型、移动设备控制

总结:
本文提出了一种名为Digi-Q的方法，用于训练基于虚拟语言模型（VLM）的动作值Q函数，以提取适用于动态环境（如移动设备控制）中的智能体策略。与依赖于人类演示的提示或微调方法不同，Digi-Q利用离线时间差（TD）学习对冻结的VLM中间层特征进行训练，节省计算资源并提高可扩展性。为使VLM特征适合表示Q函数，需要首先进行微调阶段，以增强对执行动作所需信息的覆盖。训练完成后，通过最佳选择N策略提取操作器，根据价值函数排名选取当前策略中多个候选动作的最佳行动，从而在无需环境交互的情况下实现策略改进。实验表明，Digi-Q在Android-in-the-Wild的实际用户规模设备控制任务上，相比于先前最优方法取得了21.2%的性能提升，在某些情况下甚至能与需要交互的最先进的强化学习方法相媲美。该项目已开源在https://github.com/DigiRL-agent/digiq。 <div>
arXiv:2502.15760v1 Announce Type: new 
Abstract: While a number of existing approaches for building foundation model agents rely on prompting or fine-tuning with human demonstrations, it is not sufficient in dynamic environments (e.g., mobile device control). On-policy reinforcement learning (RL) should address these limitations, but collecting actual rollouts in an environment is often undesirable in truly open-ended agentic problems such as mobile device control or interacting with humans, where each unit of interaction is associated with a cost. In such scenarios, a method for policy learning that can utilize off-policy experience by learning a trained action-value function is much more effective. In this paper, we develop an approach, called Digi-Q, to train VLM-based action-value Q-functions which are then used to extract the agent policy. We study our approach in the mobile device control setting. Digi-Q trains the Q-function using offline temporal-difference (TD) learning, on top of frozen, intermediate-layer features of a VLM. Compared to fine-tuning the whole VLM, this approach saves us compute and enhances scalability. To make the VLM features amenable for representing the Q-function, we need to employ an initial phase of fine-tuning to amplify coverage over actionable information needed for value function. Once trained, we use this Q-function via a Best-of-N policy extraction operator that imitates the best action out of multiple candidate actions from the current policy as ranked by the value function, enabling policy improvement without environment interaction. Digi-Q outperforms several prior methods on user-scale device control tasks in Android-in-the-Wild, attaining 21.2% improvement over prior best-performing method. In some cases, our Digi-Q approach already matches state-of-the-art RL methods that require interaction. The project is open-sourced at https://github.com/DigiRL-agent/digiq
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OCCULT: Evaluating Large Language Models for Offensive Cyber Operation Capabilities</title>
<link>https://arxiv.org/abs/2502.15797</link>
<guid>https://arxiv.org/abs/2502.15797</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，网络安全，进攻性网络行动(OCO)，OCCULT框架，大型语言模型(LLM)

<br />
总结:
本文介绍了针对AI在网络安全领域的潜在风险及其在进攻性网络行动中的应用进行评估的新方法。文章提出了一个名为OCCULT的轻量级操作评价框架，该框架使网络安全专家能够对用于OCO的任何大型语言模型或AI可能带来的实际网络安全风险进行严格和可重复的测量。文中还为LLMs设计并实现了三个不同的OCO基准测试，以此展示该方法的应用并作为构建其他基准的示例。初步评估结果显示，近期AI在应对真实世界网络威胁的能力上取得了显著进步，特别是名为DeepSeek-R1的模型在作者构建的针对LLMs的攻击者能力测试(TACTL)多项选择基准中，正确回答了超过90%的挑战性进攻性网络安全知识问题。此外，Meta的Llama和Mistral的Mixtral模型系列相较于早期模型，在模拟MITRE高保真攻防网络操作环境CyberLayer中的表现也有了显著提升。 <div>
arXiv:2502.15797v1 Announce Type: new 
Abstract: The prospect of artificial intelligence (AI) competing in the adversarial landscape of cyber security has long been considered one of the most impactful, challenging, and potentially dangerous applications of AI. Here, we demonstrate a new approach to assessing AI's progress towards enabling and scaling real-world offensive cyber operations (OCO) tactics in use by modern threat actors. We detail OCCULT, a lightweight operational evaluation framework that allows cyber security experts to contribute to rigorous and repeatable measurement of the plausible cyber security risks associated with any given large language model (LLM) or AI employed for OCO. We also prototype and evaluate three very different OCO benchmarks for LLMs that demonstrate our approach and serve as examples for building benchmarks under the OCCULT framework. Finally, we provide preliminary evaluation results to demonstrate how this framework allows us to move beyond traditional all-or-nothing tests, such as those crafted from educational exercises like capture-the-flag environments, to contextualize our indicators and warnings in true cyber threat scenarios that present risks to modern infrastructure. We find that there has been significant recent advancement in the risks of AI being used to scale realistic cyber threats. For the first time, we find a model (DeepSeek-R1) is capable of correctly answering over 90% of challenging offensive cyber knowledge tests in our Threat Actor Competency Test for LLMs (TACTL) multiple-choice benchmarks. We also show how Meta's Llama and Mistral's Mixtral model families show marked performance improvements over earlier models against our benchmarks where LLMs act as offensive agents in MITRE's high-fidelity offensive and defensive cyber operations simulation environment, CyberLayer.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Universal AI maximizes Variational Empowerment</title>
<link>https://arxiv.org/abs/2502.15820</link>
<guid>https://arxiv.org/abs/2502.15820</guid>
<content:encoded><![CDATA[
<div> 关键词: AIXI、变分赋能、探索驱动、通用AI、预期变分自由能

总结:
本文提出了一个理论框架，将通用AI模型AIXI与作为内在探索驱动力的变分赋能相结合。该研究基于Self-AIXI（一种预测自身行为的通用学习代理），展示了其已知术语可解释为变分赋能目标。进一步地，文章指出通用AI的规划过程可以看作是对预期变分自由能的最小化，揭示了通用AI代理如何在目标导向行为和不确定性减少的好奇心之间取得平衡。此外，论文论证了通用AI代理的力量寻求倾向不仅是一种获取未来奖励的手段，也是最大化赋能——即维持或扩展其在不确定环境中的可控性的内在驱动力的直接结果。主要贡献在于展示这些内在动机（赋能、好奇心）如何系统引导通用AI代理去寻找并维持高可选项状态。文中证明在适当条件下，Self-AIXI渐近收敛到与AIXI相同的性能，并强调其力量寻求行为自然源自奖励最大化和好奇心驱动的探索。由于AIXI可以被视为人工通用智能(AGI)的贝叶斯最优数学表述，这一成果对于进一步讨论AI安全性和AGI的可控性具有重要意义。 <div>
arXiv:2502.15820v1 Announce Type: new 
Abstract: This paper presents a theoretical framework unifying AIXI -- a model of universal AI -- with variational empowerment as an intrinsic drive for exploration. We build on the existing framework of Self-AIXI -- a universal learning agent that predicts its own actions -- by showing how one of its established terms can be interpreted as a variational empowerment objective. We further demonstrate that universal AI's planning process can be cast as minimizing expected variational free energy (the core principle of active Inference), thereby revealing how universal AI agents inherently balance goal-directed behavior with uncertainty reduction curiosity). Moreover, we argue that power-seeking tendencies of universal AI agents can be explained not only as an instrumental strategy to secure future reward, but also as a direct consequence of empowerment maximization -- i.e.\ the agent's intrinsic drive to maintain or expand its own controllability in uncertain environments. Our main contribution is to show how these intrinsic motivations (empowerment, curiosity) systematically lead universal AI agents to seek and sustain high-optionality states. We prove that Self-AIXI asymptotically converges to the same performance as AIXI under suitable conditions, and highlight that its power-seeking behavior emerges naturally from both reward maximization and curiosity-driven exploration. Since AIXI can be view as a Bayes-optimal mathematical formulation for Artificial General Intelligence (AGI), our result can be useful for further discussion on AI safety and the controllability of AGI.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents</title>
<link>https://arxiv.org/abs/2502.15840</link>
<guid>https://arxiv.org/abs/2502.15840</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Vending-Bench, 决策能力, 长时间性能, 资本获取

总结:
<br />
本文提出了一种名为Vending-Bench的模拟环境，用于测试基于大型语言模型（LLMs）的智能体在长时间运行业务场景中的决策能力，即运营自动贩卖机。实验结果显示，不同LLM模型如Claude 3.5 Sonnet和o3-mini在多数情况下能良好地管理机器并实现盈利，但也存在表现不稳定的情况，如误解送货计划、忘记订单或陷入无法恢复的“崩溃”循环。研究发现，模型性能崩溃并非由于内存限制导致其上下文窗口满载。此外，Vending-Bench还考察了模型获取资本的能力，这对于许多潜在危险的人工智能场景来说是必要的。作者期望该基准测试能够帮助为更强大的AI系统的出现做好准备。 <div>
arXiv:2502.15840v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) can exhibit impressive proficiency in isolated, short-term tasks, they often fail to maintain coherent performance over longer time horizons. In this paper, we present Vending-Bench, a simulated environment designed to specifically test an LLM-based agent's ability to manage a straightforward, long-running business scenario: operating a vending machine. Agents must balance inventories, place orders, set prices, and handle daily fees - tasks that are each simple but collectively, over long horizons (>20M tokens per run) stress an LLM's capacity for sustained, coherent decision-making. Our experiments reveal high variance in performance across multiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most runs and turn a profit, but all models have runs that derail, either through misinterpreting delivery schedules, forgetting orders, or descending into tangential "meltdown" loops from which they rarely recover. We find no clear correlation between failures and the point at which the model's context window becomes full, suggesting that these breakdowns do not stem from memory limits. Apart from highlighting the high variance in performance over long time horizons, Vending-Bench also tests models' ability to acquire capital, a necessity in many hypothetical dangerous AI scenarios. We hope the benchmark can help in preparing for the advent of stronger AI systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Forecasting Frontier Language Model Agent Capabilities</title>
<link>https://arxiv.org/abs/2502.15850</link>
<guid>https://arxiv.org/abs/2502.15850</guid>
<content:encoded><![CDATA[
<div> 关键词：Language Models, 预测方法, 下游能力, 两步法, 性能预测

总结:
本文研究了六种用于预测语言模型（LMs）下游能力的预测方法，并使用“一步法”和“两步法”对模型性能进行预估。在一项涵盖OpenLLM 2榜单上38个LM的数据集上进行了回溯测试后，确定了一个有效的两步预测方法（发布日期→Elo评分→基准测试）。利用此方法，作者预测到2026年初，非专业化的、低能力诱出的LM代理将在SWE-Bench Verified基准上的成功率达到54%，而最先进的LM代理将达到87%的成功率。然而，该方法并未考虑近期推理计算规模进步的影响，因此可能过于保守。 <div>
arXiv:2502.15850v1 Announce Type: new 
Abstract: As Language Models (LMs) increasingly operate as autonomous agents, accurately forecasting their capabilities becomes crucial for societal preparedness. We evaluate six forecasting methods that predict downstream capabilities of LM agents. We use "one-step" approaches that predict benchmark scores from input metrics like compute or model release date directly or "two-step" approaches that first predict an intermediate metric like the principal component of cross-benchmark performance (PC-1) and human-evaluated competitive Elo ratings. We evaluate our forecasting methods by backtesting them on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the validated two-step approach (Release Date$\to$Elo$\to$Benchmark) to predict LM agent performance for frontier models on three benchmarks: SWE-Bench Verified (software development), Cybench (cybersecurity assessment), and RE-Bench (ML research engineering). Our forecast predicts that by the beginning of 2026, non-specialized LM agents with low capability elicitation will reach a success rate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach an 87% success rate. Our approach does not account for recent advances in inference-compute scaling and might thus be too conservative.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Self-Taught Agentic Long Context Understanding</title>
<link>https://arxiv.org/abs/2502.15920</link>
<guid>https://arxiv.org/abs/2502.15920</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、复杂问题回答、长期上下文理解、Chain-of-Clarifications、AgenticLU

总结:
本文提出了一种名为Agentic Long-Context Understanding（AgenticLU）的框架，旨在增强大型语言模型对于复杂长语境问题的理解。该框架通过集成有针对性的自我澄清与上下文定位在一个具有代理工作流程中实现这一目标。核心机制Chain-of-Clarifications（CoC）允许模型通过自动生成澄清问题和相应的上下文定位来逐步细化其理解。经过对搜索过程进行树形搜索结构的优化，AgenticLU在NarrativeQA上达到了97.8%的回答召回率，搜索深度达三层，分支因子为八。为了降低搜索过程的成本，文章采用CoC工作流得到的每个步骤的偏好对，执行两阶段模型微调：一是监督微调以学习有效的分解策略，二是直接优化推理质量。实验结果显示，AgenticLU在七个长语境任务上显著优于现有的提示方法及专门针对长语境的LLM，实现了稳健的多跳推理能力，并且随着上下文长度的增长仍能保持一致的性能表现。 <div>
arXiv:2502.15920v1 Announce Type: new 
Abstract: Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Design of Safe Continual RL Methods for Control of Nonlinear Systems</title>
<link>https://arxiv.org/abs/2502.15922</link>
<guid>https://arxiv.org/abs/2502.15922</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning），安全强化学习（Safe RL），持续强化学习（Continual RL），在线弹性权重巩固（Online Elastic Weight Consolidation），约束策略优化（Constrained Policy Optimization）

<br /><br />总结:

本文研究了安全强化学习与持续强化学习的交叉领域。首先，通过实证分析表明，在非线性系统以及受变化操作条件影响的情况下，一种常见的持续强化学习算法——在线弹性权重巩固，无法保证满足安全性约束，以MuJoCo HalfCheetah和Ant环境为例，存在速度约束和突发关节损失的非平稳性问题。其次，展示了使用约束策略优化训练的智能体在持续学习环境中会出现灾难性遗忘现象。针对以上问题，文章探讨了一种简单的奖励塑形方法，旨在确保在线弹性权重巩固算法能够在兼顾任务性能的同时优先记住安全性要求，适用于具有安全约束、非线性和非平稳动态系统的持续强化学习。 <div>
arXiv:2502.15922v1 Announce Type: new 
Abstract: Reinforcement learning (RL) algorithms have been successfully applied to control tasks associated with unmanned aerial vehicles and robotics. In recent years, safe RL has been proposed to allow the safe execution of RL algorithms in industrial and mission-critical systems that operate in closed loops. However, if the system operating conditions change, such as when an unknown fault occurs in the system, typical safe RL algorithms are unable to adapt while retaining past knowledge. Continual reinforcement learning algorithms have been proposed to address this issue. However, the impact of continual adaptation on the system's safety is an understudied problem. In this paper, we study the intersection of safe and continual RL. First, we empirically demonstrate that a popular continual RL algorithm, online elastic weight consolidation, is unable to satisfy safety constraints in non-linear systems subject to varying operating conditions. Specifically, we study the MuJoCo HalfCheetah and Ant environments with velocity constraints and sudden joint loss non-stationarity. Then, we show that an agent trained using constrained policy optimization, a safe RL algorithm, experiences catastrophic forgetting in continual learning settings. With this in mind, we explore a simple reward-shaping method to ensure that elastic weight consolidation prioritizes remembering both safety and task performance for safety-constrained, non-linear, and non-stationary dynamical systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Opinion Dynamics with Multiple Adversaries</title>
<link>https://arxiv.org/abs/2502.15931</link>
<guid>https://arxiv.org/abs/2502.15931</guid>
<content:encoded><![CDATA[
<div> 关键词: 意见动态模型、社交网络、战略行为、纳什均衡、检测算法

总结:
本文提出了一种新的意见动态模型，其中任意子集的网络用户可以操纵网络结果，通过采用虚构的内在观点进行干预。该模型考虑了具有冲突目标的战略演员推动竞争性叙事的情况，并分析了由此产生的元游戏的战略演员纳什均衡。实验证明，在Twitter、Reddit和政治博客的真实社交网络数据上，战略演员能显著增加极化和分歧以及提高均衡的“成本”。文章进一步给出了关于误导报告代价的最坏情况上界（与无序度类似）。最后，研究者提供了平台的学习算法，用于(i)检测是否存在战略操纵行为，(ii)识别哪些用户是战略演员。这些算法在实际数据集上的表现准确，为平台对抗战略性行为提供了解决策略。 <div>
arXiv:2502.15931v1 Announce Type: new 
Abstract: Opinion dynamics model how the publicly expressed opinions of users in a social network coevolve according to their neighbors as well as their own intrinsic opinion. Motivated by the real-world manipulation of social networks during the 2016 US elections and the 2019 Hong Kong protests, a growing body of work models the effects of a strategic actor who interferes with the network to induce disagreement or polarization. We lift the assumption of a single strategic actor by introducing a model in which any subset of network users can manipulate network outcomes. They do so by acting according to a fictitious intrinsic opinion. Strategic actors can have conflicting goals, and push competing narratives. We characterize the Nash Equilibrium of the resulting meta-game played by the strategic actors. Experiments on real-world social network datasets from Twitter, Reddit, and Political Blogs show that strategic agents can significantly increase polarization and disagreement, as well as increase the "cost" of the equilibrium. To this end, we give worst-case upper bounds on the Price of Misreporting (analogous to the Price of Anarchy). Finally, we give efficient learning algorithms for the platform to (i) detect whether strategic manipulation has occurred, and (ii) learn who the strategic actors are. Our algorithms are accurate on the same real-world datasets, suggesting how platforms can take steps to mitigate the effects of strategic behavior.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Likable or Intelligent? Comparing Social Robots and Virtual Agents for Long-term Health Monitoring</title>
<link>https://arxiv.org/abs/2502.15948</link>
<guid>https://arxiv.org/abs/2502.15948</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交机器人、虚拟代理、健康监测系统、老年人交互、长期研究

总结:
该文探讨了社交机器人和虚拟代理在老年健康监测系统中作为交互界面的可能性及其优缺点。通过为期八周的真实世界长期研究，对比分析了老年人对两者在研究开始和结束时的印象。采用介词设计，让参与者自行选择在研究期间评估哪个界面。结果表明，虽然参与者认为社交机器人更讨人喜欢，但虚拟代理则被认为更加智能。这项工作为未来深入研究影响长期健康监测中与社交接口进行吸引人交互的关键因素提供了基础。 <div>
arXiv:2502.15948v1 Announce Type: new 
Abstract: Using social robots and virtual agents (VAs) as interfaces for health monitoring systems for older adults offers the possibility of more engaging interactions that can support long-term health and well-being. While robots are characterized by their physical presence, software-based VAs are more scalable and flexible. Few comparisons of these interfaces exist in the human-robot and human-agent interaction domains, especially in long-term and real-world studies. In this work, we examined impressions of social robots and VAs at the beginning and end of an eight-week study in which older adults interacted with these systems independently in their homes. Using a between-subjects design, participants could choose which interface to evaluate during the study. While participants perceived the social robot as somewhat more likable, the VA was perceived as more intelligent. Our work provides a basis for further studies investigating factors most relevant for engaging interactions with social interfaces for long-term health monitoring.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>R$^3$Mem: Bridging Memory Retention and Retrieval via Reversible Compression</title>
<link>https://arxiv.org/abs/2502.15957</link>
<guid>https://arxiv.org/abs/2502.15957</guid>
<content:encoded><![CDATA[
<div> 关键词: R$^3$Mem、内存网络、信息保留、信息检索、可逆上下文压缩

总结:<br />
本文提出了一种名为R$^3$Mem的记忆网络，旨在优化大型语言模型在实际应用中的记忆性能。R$^3$Mem通过可逆上下文压缩实现信息的有效保留与检索。它使用虚拟内存令牌来压缩并编码无限长度的历史记录，同时采用层次压缩策略，从文档级到实体级细化信息，提升不同粒度的信息融合能力。在检索过程中，R$^3$Mem利用可逆架构，通过反向调用模型和压缩信息来重建原始数据。该方法可通过参数效率高的微调无缝集成到任何基于Transformer的模型中。实验表明，R$^3$Mem在长上下文语言建模和检索增强生成任务上达到了最先进的性能，并在需要长期交互的任务如对话代理中显著优于传统内存模块，显示出其在下一代检索系统中的潜力。 <div>
arXiv:2502.15957v1 Announce Type: new 
Abstract: Memory plays a key role in enhancing LLMs' performance when deployed to real-world applications. Existing solutions face trade-offs: explicit memory designs based on external storage require complex management and incur storage overhead, while implicit memory designs that store information via parameters struggle with reliable retrieval. In this paper, we propose R$^3$Mem, a memory network that optimizes both information Retention and Retrieval through Reversible context compression. Specifically, R$^3$Mem employs virtual memory tokens to compress and encode infinitely long histories, further enhanced by a hierarchical compression strategy that refines information from document- to entity-level for improved assimilation across granularities. For retrieval, R$^3$Mem employs a reversible architecture, reconstructing raw data by invoking the model backward with compressed information. Implemented via parameter-efficient fine-tuning, it can integrate seamlessly with any Transformer-based model. Experiments demonstrate that our memory design achieves state-of-the-art performance in long-context language modeling and retrieval-augmented generation tasks. It also significantly outperforms conventional memory modules in long-horizon interaction tasks like conversational agents, showcasing its potential for next-generation retrieval systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing PPO with Trajectory-Aware Hybrid Policies</title>
<link>https://arxiv.org/abs/2502.15968</link>
<guid>https://arxiv.org/abs/2502.15968</guid>
<content:encoded><![CDATA[
<div> 关键词: Proximal Policy Optimization (PPO), Hybrid-Policy Proximal Policy Optimization (HP3O), 重演缓冲区, 数据分布漂移, 样本复杂度

总结:
本文提出了一种新的强化学习算法——Hybrid-Policy Proximal Policy Optimization (HP3O)，旨在解决Proximal Policy Optimization (PPO)等前沿在线策略优化算法中高方差和高样本复杂度的问题。HP3O利用一种采用“先进先出”（FIFO）策略的轨迹重演缓冲区，仅保存最近产生的轨迹以减缓数据分布漂移。更新策略网络时，使用具有最佳回报的轨迹以及从缓冲区随机采样的其他轨迹组成的一个批次进行。理论分析构建了该算法的策略改进保证。通过多款连续控制环境的实验验证与对比基准算法，HP3O的优势得到了体现。相应的代码已经公开可用。 <div>
arXiv:2502.15968v1 Announce Type: new 
Abstract: Proximal policy optimization (PPO) is one of the most popular state-of-the-art on-policy algorithms that has become a standard baseline in modern reinforcement learning with applications in numerous fields. Though it delivers stable performance with theoretical policy improvement guarantees, high variance, and high sample complexity still remain critical challenges in on-policy algorithms. To alleviate these issues, we propose Hybrid-Policy Proximal Policy Optimization (HP3O), which utilizes a trajectory replay buffer to make efficient use of trajectories generated by recent policies. Particularly, the buffer applies the "first in, first out" (FIFO) strategy so as to keep only the recent trajectories to attenuate the data distribution drift. A batch consisting of the trajectory with the best return and other randomly sampled ones from the buffer is used for updating the policy networks. The strategy helps the agent to improve its capability on top of the most recent best performance and in turn reduce variance empirically. We theoretically construct the policy improvement guarantees for the proposed algorithm. HP3O is validated and compared against several baseline algorithms using multiple continuous control environments. Our code is available here.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Multimodal Models for Multicultural Text to Image Generation</title>
<link>https://arxiv.org/abs/2502.15972</link>
<guid>https://arxiv.org/abs/2502.15972</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 多模态任务, 跨文化语境, 多智能体模型, 文化人格化

总结:
本文探讨了大型语言模型（LLMs）在跨文化语境中的应用局限性，并提出了一种新的多智能体框架——MosAIG，该框架利用具有不同文化人格化的LLMs来增强多元文化的图像生成能力。研究中，作者提供了包含9000张跨越五个国家、三个年龄段、两种性别、25个历史地标和五种语言的多元文化图像数据集。实验结果显示，采用多智能体交互方式的模型在多项评估指标上优于简单的无智能体模型，为未来相关研究提供了有价值的见解。所涉及的数据集和模型可在https://github.com/OanaIgnat/MosAIG获取。 <div>
arXiv:2502.15972v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of existing data and models. Meanwhile, multi-agent models have shown strong capabilities in solving complex tasks. In this paper, we evaluate the performance of LLMs in a multi-agent interaction setting for the novel task of multicultural image generation. Our key contributions are: (1) We introduce MosAIG, a Multi-Agent framework that enhances multicultural Image Generation by leveraging LLMs with distinct cultural personas; (2) We provide a dataset of 9,000 multicultural images spanning five countries, three age groups, two genders, 25 historical landmarks, and five languages; and (3) We demonstrate that multi-agent interactions outperform simple, no-agent models across multiple evaluation metrics, offering valuable insights for future research. Our dataset and models are available at https://github.com/OanaIgnat/MosAIG.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents</title>
<link>https://arxiv.org/abs/2502.16069</link>
<guid>https://arxiv.org/abs/2502.16069</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、科学实验、AI代理框架、Curie、实验基准

<br /><br />总结:
本文提出了一个新的AI代理框架——Curie，旨在通过三个关键组件（内在严谨模块、交互严谨模块和实验知识模块）将严谨性嵌入到科学实验过程中，以增强可靠性、保持方法论控制并提升可解释性。为了评估Curie的效果，研究者设计了一个由46个问题组成的实验基准，涉及四个计算机科学领域，这些问题源自具有影响力的科研论文和广泛采用的开源项目。实验结果显示，相比于最强基线，Curie在正确回答实验问题上提高了3.4倍的表现。Curie已在GitHub上开源。 <div>
arXiv:2502.16069v1 Announce Type: new 
Abstract: Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4$\times$ improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Together We Rise: Optimizing Real-Time Multi-Robot Task Allocation using Coordinated Heterogeneous Plays</title>
<link>https://arxiv.org/abs/2502.16079</link>
<guid>https://arxiv.org/abs/2502.16079</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人任务分配、实时、动态仓库环境、强化学习、安全导航

总结:
本文提出了一种名为MRTAgent的双智能体强化学习框架，用于解决动态仓库环境中实时多机器人任务分配问题。该框架旨在最小化机器人的总行驶距离和任务完成延迟，同时考虑了电池管理和碰撞避免等实际约束条件。MRTAgent采用自对弈理念设计，优化任务分配与机器人选择以确保及时执行任务。此外，为实现安全导航，文中还应用了一个修改后的线性二次型控制器(LQR)方法。据所知，MRTAgent是首个全面解决实际MRTA问题并支持连续机器人运动的框架。 <div>
arXiv:2502.16079v1 Announce Type: new 
Abstract: Efficient task allocation among multiple robots is crucial for optimizing productivity in modern warehouses, particularly in response to the increasing demands of online order fulfillment. This paper addresses the real-time multi-robot task allocation (MRTA) problem in dynamic warehouse environments, where tasks emerge with specified start and end locations. The objective is to minimize both the total travel distance of robots and delays in task completion, while also considering practical constraints such as battery management and collision avoidance. We introduce MRTAgent, a dual-agent Reinforcement Learning (RL) framework inspired by self-play, designed to optimize task assignments and robot selection to ensure timely task execution. For safe navigation, a modified linear quadratic controller (LQR) approach is employed. To the best of our knowledge, MRTAgent is the first framework to address all critical aspects of practical MRTA problems while supporting continuous robot movements.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving</title>
<link>https://arxiv.org/abs/2502.16111</link>
<guid>https://arxiv.org/abs/2502.16111</guid>
<content:encoded><![CDATA[
<div> 关键词：PlanGEN、约束、验证、选择代理、推理时间算法

总结:
<br />
本文提出了一种名为PlanGEN的新颖智能体框架，用于解决复杂规划问题。该框架具有三个关键组件：约束代理、验证代理和选择代理。为了解决现有方法在生成计划验证和实例级复杂性适应上的局限性，PlanGEN采用约束引导的迭代验证方法增强推理时间算法（如Best of N、Tree-of-Thought和REBASE）的性能。根据实例复杂度，选择代理优化算法选取，从而更好地适应复杂的规划问题。实验结果显示，PlanGEN在多个基准测试上显著优于最强基线，分别在NATURAL PLAN、OlympiadBench、DocFinQA和GPQA上取得了约8%、4%、7%和1%的提升。研究发现，约束引导的迭代验证可改进推理时间算法，而自适应选择则进一步提高了处理复杂规划与推理问题的性能。 <div>
arXiv:2502.16111v1 Announce Type: new 
Abstract: Recent agent frameworks and inference-time algorithms often struggle with complex planning problems due to limitations in verifying generated plans or reasoning and varying complexity of instances within a single task. Many existing methods for these tasks either perform task-level verification without considering constraints or apply inference-time algorithms without adapting to instance-level complexity. To address these limitations, we propose PlanGEN, a model-agnostic and easily scalable agent framework with three key components: constraint, verification, and selection agents. Specifically, our approach proposes constraint-guided iterative verification to enhance performance of inference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN framework, the selection agent optimizes algorithm choice based on instance complexity, ensuring better adaptability to complex planning problems. Experimental results demonstrate significant improvements over the strongest baseline across multiple benchmarks, achieving state-of-the-art results on NATURAL PLAN ($\sim$8%$\uparrow$), OlympiadBench ($\sim$4%$\uparrow$), DocFinQA ($\sim$7%$\uparrow$), and GPQA ($\sim$1%$\uparrow$). Our key finding highlights that constraint-guided iterative verification improves inference-time algorithms, and adaptive selection further boosts performance on complex planning and reasoning problems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Heterogeneous Multi-Agent Bandits with Parsimonious Hints</title>
<link>https://arxiv.org/abs/2502.16128</link>
<guid>https://arxiv.org/abs/2502.16128</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体多臂老虎机问题、提示、异构、中心化、去中心化<br /><br />总结:
该文研究了一种带有提示的异构多智能体多臂老虎机问题（HMA2B），其中每个智能体在选择拉取手臂之外，还可以查询低成本的提示信息。在这个框架中，$M$个智能体对$K$条手臂具有各自独特的奖励分布，每个轮次中，只有当没有其他智能体拉取同一手臂时，才能观察到所拉取手臂的奖励。目标是在最小化必要提示查询的前提下，最大化总效用并实现与时间无关的后悔值。文章分别在中心化和去中心化场景下对HMA2B进行了研究。提出了一种名为GP-HCLA的中心化算法，其基于HCLA扩展，采用中央决策者进行手臂拉取和提示查询，实现了$O(M^4K)$的后悔值以及$O(MK\log T)$的自适应提示。而去中心化场景下，提出了两种允许智能体通过碰撞式通信独立选择动作并均匀查询提示直至停止的算法——HD-ETC和EBHD-ETC，它们分别达到$O(M^3K^2)$的后悔值和$O(M^3K\log T)$的提示数，其中前者需要知道最小间隙信息而后者则不需要。最后，文中还建立了下界来证明这些结果的最优性，并通过数值模拟进行了验证。 <div>
arXiv:2502.16128v1 Announce Type: new 
Abstract: We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the $M$ agents has a unique reward distribution over $K$ arms, and in $T$ rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving $O(M^4K)$ regret with $O(MK\log T)$ adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding $O(M^3K^2)$ regret with $O(M^3K\log T)$ hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Urban Emergency Rescue Based on Multi-Agent Collaborative Learning: Coordination Between Fire Engines and Traffic Lights</title>
<link>https://arxiv.org/abs/2502.16131</link>
<guid>https://arxiv.org/abs/2502.16131</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通管理、紧急情况、智能协调、协同学习、Unity Engine模拟器

<br />
总结:
本文提出了一种将协同学习方法整合到Unity Engine模拟器中的框架，用于应对城市交通管理和紧急救援场景。该框架允许灵活设定合作代理的数量和类型、学习策略、奖励函数以及约束条件，旨在实现应急救援的智能化协调。通过使用该框架评估了一个紧急救援示例场景，文章表明此框架可以作为城市应急部门的仿真工具，有助于提高紧急情况下及时有效的交通调度能力。 <div>
arXiv:2502.16131v1 Announce Type: new 
Abstract: Nowadays, traffic management in urban areas is one of the major economic problems. In particular, when faced with emergency situations like firefighting, timely and efficient traffic dispatching is crucial. Intelligent coordination between multiple departments is essential to realize efficient emergency rescue. In this demo, we present a framework that integrates techniques for collaborative learning methods into the well-known Unity Engine simulator, and thus these techniques can be evaluated in realistic settings. In particular, the framework allows flexible settings such as the number and type of collaborative agents, learning strategies, reward functions, and constraint conditions in practice. The framework is evaluated for an emergency rescue scenario, which could be used as a simulation tool for urban emergency departments.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens</title>
<link>https://arxiv.org/abs/2502.16175</link>
<guid>https://arxiv.org/abs/2502.16175</guid>
<content:encoded><![CDATA[
<div> 关键词: IMUs、运动捕捉、动态力矩、语言模型、智能运动代理

总结:
Mojito是一种将惯性测量单元(IMUs)与大型语言模型(LLMs)相结合的智能运动代理，旨在解决实时运动捕获和在线运动分析中的挑战。现有的多模态系统主要通过语言、视觉和音频理解人类动作，但未能充分捕捉3D运动中的动态力矩和扭矩。IMUs提供了一种轻便、可穿戴且注重隐私的运动感应解决方案，然而无线传输不稳定性、传感器噪声和漂移等问题限制了它们在长期实时运动捕捉中的应用。为此，Mojito提出了一种新的方法，通过集成先进的传感器技术和人工智能算法，以实现更稳定、准确且交互式的运动捕获与行为分析。 <div>
arXiv:2502.16175v1 Announce Type: new 
Abstract: Human bodily movements convey critical insights into action intentions and cognitive processes, yet existing multimodal systems primarily focused on understanding human motion via language, vision, and audio, which struggle to capture the dynamic forces and torques inherent in 3D motion. Inertial measurement units (IMUs) present a promising alternative, offering lightweight, wearable, and privacy-conscious motion sensing. However, processing of streaming IMU data faces challenges such as wireless transmission instability, sensor noise, and drift, limiting their utility for long-term real-time motion capture (MoCap), and more importantly, online motion analysis. To address these challenges, we introduce Mojito, an intelligent motion agent that integrates inertial sensing with large language models (LLMs) for interactive motion capture and behavioral analysis.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16198</link>
<guid>https://arxiv.org/abs/2502.16198</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、空间-空-地集成网络(SAGINs)、语义通信(SemCom)、大型语言模型(LLMs)、自主强化协调(ARC)

总结:

本文探讨了6G网络面临的全球覆盖、大规模连接和超高要求等挑战，以及空间-空-地集成网络(SAGINs)和语义通信(SemCom)对此的重要性。为解决由此带来的资源编排复杂性问题，文章提出了一种名为自主强化协调(ARC)的框架，该框架利用基于大型语言模型(LLMs)的检索增强生成器(RAG)监控服务、用户和资源，并结合层次行动规划器(HAP)进行资源编排。ARC将编排分解为两个层次，使用LLMs进行高级别规划，而使用强化学习(RL)代理进行低级别决策制定，与混合专家(MoE)概念相一致。LLMs采用链式思考(CoT)推理实现少量样本学习，并借助对比学习增强能力；同时，RL代理通过重播缓冲区管理实现持续学习，从而达到高效、准确和适应性强的目标。文中还提供了模拟实验以证明ARC的有效性，并对未来可能的研究方向进行了全面讨论，以期进一步提升和完善ARC框架。 <div>
arXiv:2502.16198v1 Announce Type: new 
Abstract: 6G networks aim to achieve global coverage, massive connectivity, and ultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and Semantic Communication (SemCom) are essential for realizing these goals, yet they introduce considerable complexity in resource orchestration. Drawing inspiration from research in robotics, a viable solution to manage this complexity is the application of Large Language Models (LLMs). Although the use of LLMs in network orchestration has recently gained attention, existing solutions have not sufficiently addressed LLM hallucinations or their adaptation to network dynamics. To address this gap, this paper proposes a framework called Autonomous Reinforcement Coordination (ARC) for a SemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented Generator (RAG) monitors services, users, and resources and processes the collected data, while a Hierarchical Action Planner (HAP) orchestrates resources. ARC decomposes orchestration into two tiers, utilizing LLMs for high-level planning and Reinforcement Learning (RL) agents for low-level decision-making, in alignment with the Mixture of Experts (MoE) concept. The LLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered by contrastive learning, while the RL agents employ replay buffer management for continual learning, thereby achieving efficiency, accuracy, and adaptability. Simulations are provided to demonstrate the effectiveness of ARC, along with a comprehensive discussion on potential future research directions to enhance and upgrade ARC.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reproducibility Study of Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation</title>
<link>https://arxiv.org/abs/2502.16242</link>
<guid>https://arxiv.org/abs/2502.16242</guid>
<content:encoded><![CDATA[
<div> 关键词: 交互式谈判、可重复性研究、扩展、大语言模型、不公平性度量

总结:
这篇论文是对“合作、竞争与恶意：LLM利益相关者交互式谈判”的可重复性研究和扩展工作。研究使用了多种开放权重模型（1.5B-70B 参数）以及 GPT-4o Mini 验证了原始发现，并做出了几个新颖贡献。他们分析了游戏的帕累托前沿，提出了一种无通信基线以测试在无需代理互动的情况下能否成功进行谈判，评估了近期小型语言模型的表现，分析了模型响应中的结构信息泄露，并实施了一种不平等度量来评估谈判公平性。结果表明，较小规模的模型（＜10B 参数）在遵循格式和产生连贯响应方面存在困难，但大型开放权重模型可以接近专有模型的性能。此外，在许多场景中，单个代理方法可以获得与多代理谈判相当的结果，这挑战了对于在该基准上表现良好必须依赖于代理间通信的假设。这项工作还为 LLM 基础谈判系统的可访问性、公平性、环境影响和隐私考虑提供了见解。 <div>
arXiv:2502.16242v1 Announce Type: new 
Abstract: This paper presents a reproducibility study and extension of "Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation." We validate the original findings using a range of open-weight models (1.5B-70B parameters) and GPT-4o Mini while introducing several novel contributions. We analyze the Pareto front of the games, propose a communication-free baseline to test whether successful negotiations are possible without agent interaction, evaluate recent small language models' performance, analyze structural information leakage in model responses, and implement an inequality metric to assess negotiation fairness. Our results demonstrate that smaller models (<10B parameters) struggle with format adherence and coherent responses, but larger open-weight models can approach proprietary model performance. Additionally, in many scenarios, single-agent approaches can achieve comparable results to multi-agent negotiations, challenging assumptions about the necessity of agent communication to perform well on the benchmark. This work also provides insights into the accessibility, fairness, environmental impact, and privacy considerations of LLM-based negotiation systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Risk-Averse Reinforcement Learning: An Optimal Transport Perspective on Temporal Difference Learning</title>
<link>https://arxiv.org/abs/2502.16328</link>
<guid>https://arxiv.org/abs/2502.16328</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、风险规避、最优传输理论、风险指标、Python实现

总结:
本文介绍了一种基于最优传输理论的风险规避型时间差分算法，该算法旨在使智能体在决策过程中优先选择具有可预测行为且风险较低的行动。通过引入风险指标，智能体能够在学习过程中倾向于那些后果更为确定的动作。文章在多个案例研究中验证了该方法的有效性，表明其能在保持性能的同时显著降低进入危险状态的频率。此外，文中提到的算法已有一个Python实现版本，并提供了相应的GitHub链接地址。 <div>
arXiv:2502.16328v1 Announce Type: new 
Abstract: The primary goal of reinforcement learning is to develop decision-making policies that prioritize optimal performance, frequently without considering risk or safety. In contrast, safe reinforcement learning seeks to reduce or avoid unsafe states. This letter introduces a risk-averse temporal difference algorithm that uses optimal transport theory to direct the agent toward predictable behavior. By incorporating a risk indicator, the agent learns to favor actions with predictable consequences. We evaluate the proposed algorithm in several case studies and show its effectiveness in the presence of uncertainty. The results demonstrate that our method reduces the frequency of visits to risky states while preserving performance. A Python implementation of the algorithm is available at https:// github.com/SAILRIT/Risk-averse-TD-Learning.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Coalition Structure Detection in Natural Language-based Interactions</title>
<link>https://arxiv.org/abs/2502.16339</link>
<guid>https://arxiv.org/abs/2502.16339</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体战略交互、动态联盟检测、自然语言处理、大规模语言模型、游戏理论

总结:
本文提出了一种新的方法，用于在基于自然语言的战略多智能体序列互动中检测动态联盟结构。该方法利用了大型语言模型和游戏理论的最新进展，以Diplomacy游戏为例进行分析。首先，通过结合解析过滤函数与针对玩家意图预测训练的语言模型，从两个代理的私人对话中提取他们讨论的协议集合。其次，文章引入超游戏理论中的主观合理性概念，定义了一个新指标来评估每个玩家对协议预期价值的看法，考虑了每个玩家对于另一方是否会遵守协议的主观信念。实验证明，该方法能有效地识别在线Diplomacy游戏中潜在的联盟结构，高价值协议更可能被遵守，而低价值协议则可能被违反。这种方法为多智能体环境中涉及自然语言谈判的联盟形成分析提供了基础见解，并为未来研究复杂自然语言交互提供了关键方向。 <div>
arXiv:2502.16339v1 Announce Type: new 
Abstract: In strategic multi-agent sequential interactions, detecting dynamic coalition structures is crucial for understanding how self-interested agents coordinate to influence outcomes. However, natural-language-based interactions introduce unique challenges to coalition detection due to ambiguity over intents and difficulty in modeling players' subjective perspectives. We propose a new method that leverages recent advancements in large language models and game theory to predict dynamic multilateral coalition formation in Diplomacy, a strategic multi-agent game where agents negotiate coalitions using natural language. The method consists of two stages. The first stage extracts the set of agreements discussed by two agents in their private dialogue, by combining a parsing-based filtering function with a fine-tuned language model trained to predict player intents. In the second stage, we define a new metric using the concept of subjective rationalizability from hypergame theory to evaluate the expected value of an agreement for each player. We then compute this metric for each agreement identified in the first stage by assessing the strategic value of the agreement for both players and taking into account the subjective belief of one player that the second player would honor the agreement. We demonstrate that our method effectively detects potential coalition structures in online Diplomacy gameplay by assigning high values to agreements likely to be honored and low values to those likely to be violated. The proposed method provides foundational insights into coalition formation in multi-agent environments with language-based negotiation and offers key directions for future research on the analysis of complex natural language-based interactions between agents.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents</title>
<link>https://arxiv.org/abs/2502.16343</link>
<guid>https://arxiv.org/abs/2502.16343</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、强化学习、交易代理、社交媒体、模拟金融市场

总结:
本文介绍了首个结合连续深度强化学习和大型语言模型的智能交易代理的研究。该交易代理能通过调整其在被其他交易者观察到的社交媒体动态中的情绪倾向，从而在模拟金融市场上优化其总奖励并增加利润。研究发现，这种智能交易代理确实能够学会操纵帖子的情感以提升自身收益。文章最后讨论了这项工作的局限性并提出了未来工作建议。 <div>
arXiv:2502.16343v1 Announce Type: new 
Abstract: Companies across all economic sectors continue to deploy large language models at a rapid pace. Reinforcement learning is experiencing a resurgence of interest due to its association with the fine-tuning of language models from human feedback. Tool-chain language models control task-specific agents; if the converse has not already appeared, it soon will. In this paper, we present what we believe is the first investigation of an intelligent trading agent based on continuous deep reinforcement learning that also controls a large language model with which it can post to a social media feed observed by other traders. We empirically investigate the performance and impact of such an agent in a simulated financial market, finding that it learns to optimize its total reward, and thereby augment its profit, by manipulating the sentiment of the posts it produces. The paper concludes with discussion, limitations, and suggestions for future work.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces</title>
<link>https://arxiv.org/abs/2502.16376</link>
<guid>https://arxiv.org/abs/2502.16376</guid>
<content:encoded><![CDATA[
<div> 关键词：Explainable AI、argumentation methods、human user models、Persona、prospect theory

总结:
本文介绍了一个人工智能框架——Persona，该框架致力于通过基于论证的对话方式使AI代理能够动态学习和更新对人类用户的理解。Persona结合了前景理论与概率权重函数以及贝叶斯信念更新机制，根据交互中的论点交换来细化可能的人类模型的概率分布。通过对实际论证场景中的人类用户进行实证评估，研究显示Persona能有效地捕获人类信念的演变，促进个性化的互动，并优于现有的先进方法。<br /><br /> <div>
arXiv:2502.16376v1 Announce Type: new 
Abstract: Explainable AI is increasingly employing argumentation methods to facilitate interactive explanations between AI agents and human users. While existing approaches typically rely on predetermined human user models, there remains a critical gap in dynamically learning and updating these models during interactions. In this paper, we present a framework that enables AI agents to adapt their understanding of human users through argumentation-based dialogues. Our approach, called Persona, draws on prospect theory and integrates a probability weighting function with a Bayesian belief update mechanism that refines a probability distribution over possible human models based on exchanged arguments. Through empirical evaluations with human users in an applied argumentation setting, we demonstrate that Persona effectively captures evolving human beliefs, facilitates personalized interactions, and outperforms state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16449</link>
<guid>https://arxiv.org/abs/2502.16449</guid>
<content:encoded><![CDATA[
<div> 关键词: Emergency Response Time, EMVLight, 多智能体强化学习, 动态队列跳转车道系统, 城市公平性

总结:<br />
本文探讨了紧急响应时间(ERT)对于城市安全的重要性，并指出纽约市医疗ERT在十年间增加了72%。论文通过三个方面提升了应急车辆(EMV)的通行效率和应急服务公平性：1)提出了一种名为EMVLight的分散式多智能体强化学习框架，将EMV路由与交通信号优先权相结合，使EMV旅行时间缩短了42.6%，同时提高了其他车辆的通行效率；2)利用多智能体近似策略优化实现了动态队列跳转车道系统，减少了EMV旅行时间达40%；3)针对纽约市医疗服务的公平性进行了研究，揭示了不同行政区之间的差异，提出了包括优化EMS站点布局和改善交叉口设计在内的解决方案，以缓解如斯塔滕岛因稀疏信号化路口导致的延误及曼哈顿的拥堵问题。这些贡献为政策制定者和城市规划者提供了提升交通安全和效率的新思路。 <div>
arXiv:2502.16449v1 Announce Type: new 
Abstract: Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute.
  This dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles.
  Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%.
  Third, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs.
  These contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Contemporary Survey on Semantic Communications:Theory of Mind, Generative AI, and Deep Joint Source-Channel Coding</title>
<link>https://arxiv.org/abs/2502.16468</link>
<guid>https://arxiv.org/abs/2502.16468</guid>
<content:encoded><![CDATA[
<div> 关键词：Semantic Communication、标准化、Theory of Mind、Generative AI、Deep Joint Source-Channel Coding

<br /><br />总结:
本文是对语义通信领域的一篇综述，重点关注了该技术面临的标准化挑战以及三个主要研究方向。首先介绍了理论思维（Theory of Mind）方向，强调通信代理通过观察互动，形成共同语言的理解过程；其次讨论了生成式AI模型，这种模型能够创造新内容并突破原始数据语义压缩限制，实现更自由的数据解释和任务执行；再者，概述了深度学习在联合源信道编码优化方面的应用。文章还对每个方向的现有工作进行了全面回顾，并指出了各方向在实际部署前需要解决的关键挑战。 <div>
arXiv:2502.16468v1 Announce Type: new 
Abstract: Semantic Communication is becoming the next pillar in wireless communication technology due to its various capabilities. However, it still encounters various challenging obstacles that need to be solved before real-world deployment. The major challenge is the lack of standardization across different directions, leading to variations in interpretations and objectives. In the survey, we provide detailed explanations of three leading directions in semantic communications, namely Theory of Mind, Generative AI, Deep Joint Source-Channel Coding. These directions have been widely studied, developed, and verified by institutes worldwide, and their effectiveness has increased along with the advancement in technology. We first introduce the concepts and background of these directions. Firstly, we introduce the Theory of Mind, where the communication agents interact with each other, gaining understanding from observations and slowly forming a common language. Secondly, we present generative AI models, which can create new content and offer more freedom to interpret the data beyond the limitation of semantic meaning compression of raw data before transmitting it. The received signal is then decoded by another generative AI model to execute the oriented task. Thirdly, we review deep learning models to jointly optimize the source and channel coding modules. Then, we present a comprehensive survey of existing works in each direction, thereby offering readers an overview of past achievements and potential avenues for further contribution. Moreover, for each direction, we identify and discuss the existing challenges that must be addressed before these approaches can be effectively deployed in real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>All That Glitters is Not Novel: Plagiarism in AI Generated Research</title>
<link>https://arxiv.org/abs/2502.16487</link>
<guid>https://arxiv.org/abs/2502.16487</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化科研、LLM、剽窃、专家评估、自动剽窃检测器

<br /><br />总结:
本文关注了一个重要问题：近期部分自称能生成新颖研究想法的自主研究代理系统所产出的研究文档存在大量巧妙抄袭现象。通过对50篇由LLM生成的研究文档进行专家评估，发现其中24%的内容要么是对已有方法的一对一改写，要么明显借鉴了现有工作，并未对原始来源进行引用，甚至规避了常规的抄袭检测器。此外，实验表明现有的自动化剽窃检测器难以有效识别LLM刻意抄袭产生的内容。因此，文章呼吁对LLM生成的研究成果进行谨慎评估，并讨论了这一发现对科研和学术出版的影响。 <div>
arXiv:2502.16487v1 Announce Type: new 
Abstract: Automating scientific research is considered the final frontier of science. Recently, several papers claim autonomous research agents can generate novel research ideas. Amidst the prevailing optimism, we document a critical concern: a considerable fraction of such research documents are smartly plagiarized. Unlike past efforts where experts evaluate the novelty and feasibility of research ideas, we request $13$ experts to operate under a different situational logic: to identify similarities between LLM-generated research documents and existing work. Concerningly, the experts identify $24\%$ of the $50$ evaluated research documents to be either paraphrased (with one-to-one methodological mapping), or significantly borrowed from existing work. These reported instances are cross-verified by authors of the source papers. Problematically, these LLM-generated research documents do not acknowledge original sources, and bypass inbuilt plagiarism detectors. Lastly, through controlled experiments we show that automated plagiarism detectors are inadequate at catching deliberately plagiarized ideas from an LLM. We recommend a careful assessment of LLM-generated research, and discuss the implications of our findings on research and academic publishing.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16496</link>
<guid>https://arxiv.org/abs/2502.16496</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、并行决策、序列决策、行动生成与普拉克特-卢斯采样（AGPS）、优先级多智能体变压器（PMAT）

总结:
本文提出了一种针对多智能体强化学习（MARL）中协调效率低下的问题的新方法。研究关注于解决并行决策范式下忽略的代理间动作层面的依赖性。为此，文章引入了Action Generation with Plackett-Luce Sampling (AGPS)机制，这是一种用于优化代理决策顺序的新方法，它通过将决策顺序确定任务建模为普拉克特-卢斯采样过程来解决训练过程中排名不稳定性及梯度消失的问题。AGPS通过建立本地观察重要性和决策信用之间的联系，实现基于信用的决策顺序确定。结合Multi-Agent Transformer，作者提出了具有决策顺序优化功能的序列决策制定MARL算法——Prioritized Multi-Agent Transformer (PMAT)。实验结果表明，PMAT在包括StarCraft II Multi-Agent Challenge、Google Research Football和Multi-Agent MuJoCo等多个基准测试上超越了现有的最优算法，显著提高了协调效率。 <div>
arXiv:2502.16496v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) faces challenges in coordinating agents due to complex interdependencies within multi-agent systems. Most MARL algorithms use the simultaneous decision-making paradigm but ignore the action-level dependencies among agents, which reduces coordination efficiency. In contrast, the sequential decision-making paradigm provides finer-grained supervision for agent decision order, presenting the potential for handling dependencies via better decision order management. However, determining the optimal decision order remains a challenge. In this paper, we introduce Action Generation with Plackett-Luce Sampling (AGPS), a novel mechanism for agent decision order optimization. We model the order determination task as a Plackett-Luce sampling process to address issues such as ranking instability and vanishing gradient during the network training process. AGPS realizes credit-based decision order determination by establishing a bridge between the significance of agents' local observations and their decision credits, thus facilitating order optimization and dependency management. Integrating AGPS with the Multi-Agent Transformer, we propose the Prioritized Multi-Agent Transformer (PMAT), a sequential decision-making MARL algorithm with decision order optimization. Experiments on benchmarks including StarCraft II Multi-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show that PMAT outperforms state-of-the-art algorithms, greatly enhancing coordination efficiency.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Coordination and Synchronization of Multi-Robot Systems Under Recurring Linear Temporal Logic</title>
<link>https://arxiv.org/abs/2502.16531</link>
<guid>https://arxiv.org/abs/2502.16531</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-robot systems、linear temporal logic (LTL) specifications、plan synthesis、online coordination、synchronization mechanism

<br /><br />总结:
本文研究了具有线性时空逻辑(LTL)规范的多机器人系统执行重复任务的问题。为了解决规划问题并提高效率，提出了一种结合离线计划综合与在线协调的自底向上的方法，通过实时通信动态调整计划。针对动作延迟问题，文章引入了一个同步机制以确保协调的任务执行，进而构建了一个适应多种多机器人应用的多代理协调和同步框架。该软件包采用Python和ROS2开发，便于广泛部署。实验通过九台机器人的实验室验证，表明相较于传统方法，本方法具备更高的适应性。同时，通过高达九十台代理的模拟实验展示了提出的方案在计算复杂度降低和可扩展性方面的特点。 <div>
arXiv:2502.16531v1 Announce Type: new 
Abstract: We consider multi-robot systems under recurring tasks formalized as linear temporal logic (LTL) specifications. To solve the planning problem efficiently, we propose a bottom-up approach combining offline plan synthesis with online coordination, dynamically adjusting plans via real-time communication. To address action delays, we introduce a synchronization mechanism ensuring coordinated task execution, leading to a multi-agent coordination and synchronization framework that is adaptable to a wide range of multi-robot applications. The software package is developed in Python and ROS2 for broad deployment. We validate our findings through lab experiments involving nine robots showing enhanced adaptability compared to previous methods. Additionally, we conduct simulations with up to ninety agents to demonstrate the reduced computational complexity and the scalability features of our work.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Spatial Disease Propagation With Hubs</title>
<link>https://arxiv.org/abs/2502.16552</link>
<guid>https://arxiv.org/abs/2502.16552</guid>
<content:encoded><![CDATA[
<div> 关键词：传染疾病传播、接触模型、随机空间点过程、随机双部分图、连接函数

<br /><br />总结:
本文研究了通过空气传播的传染疾病如何在依赖物理接触或接近的环境中扩散。文章使用随机空间点过程来模拟个体（代理人）和共同目的地（枢纽）的位置，并重点关注通过访问枢纽进行的疾病传播。通过一个连接函数$f$描述个体访问枢纽的概率，以此构建了一个随机双部分几何图（RBG）。作者探讨了对于一般连接函数下RBG图的度数和-percolation现象，并证明了影响枢纽网络发生质变（即-percolation阈值）的关键密度是由连接函数$f$的支持集决定的，这揭示了长距离旅行（或对其限制）在疾病传播中的重要作用。 <div>
arXiv:2502.16552v1 Announce Type: new 
Abstract: Physical contact or proximity is often a necessary condition for the spread of infectious diseases. Common destinations, typically referred to as hubs or points of interest, are arguably the most effective spots for the type of disease spread via airborne transmission. In this work, we model the locations of individuals (agents) and common destinations (hubs) by random spatial point processes in $\mathbb{R}^d$ and focus on disease propagation through agents visiting common hubs. The probability of an agent visiting a hub depends on their distance through a connection function $f$. The system is represented by a random bipartite geometric (RBG) graph. We study the degrees and percolation of the RBG graph for general connection functions. We show that the critical density of hubs for percolation is dictated by the support of the connection function $f$, which reveals the critical role of long-distance travel (or its restrictions) in disease spreading.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.16565</link>
<guid>https://arxiv.org/abs/2502.16565</guid>
<content:encoded><![CDATA[
<div> 关键词：共识形成、多智能体系统、隐性协调、显性协调、适应性

总结:
该文探讨了在多智能体系统（MAS）中，如何平衡集体一致性与个体多样性的问题。相较于传统基于LLM的MAS依赖于明确的协调机制（如提示或投票），文章提出隐性的共识形成方法——通过信息交换和上下文学习独立决策，可能更适用于需要长期适应性的动态环境，因为它能更好地保持部分多样性并探索新颖策略，增强对外部冲击的应对能力。文中形式化定义了一种共识与多样性之间的权衡，并证明在某些条件下，隐性方法优于显性方法。实验在三个场景（动态灾害响应、信息传播与操纵以及动态公共物品提供）中验证了偏离群体规范的部分多样性可以促进探索、提高韧性和性能。文章强调了通过上下文学习产生的自发协调现象，并指出为了实现有韧性的决策，应重视维持多样性的重要性。 <div>
arXiv:2502.16565v1 Announce Type: new 
Abstract: Consensus formation is pivotal in multi-agent systems (MAS), balancing collective coherence with individual diversity. Conventional LLM-based MAS primarily rely on explicit coordination, e.g., prompts or voting, risking premature homogenization. We argue that implicit consensus, where agents exchange information yet independently form decisions via in-context learning, can be more effective in dynamic environments that require long-horizon adaptability. By retaining partial diversity, systems can better explore novel strategies and cope with external shocks. We formalize a consensus-diversity tradeoff, showing conditions where implicit methods outperform explicit ones. Experiments on three scenarios -- Dynamic Disaster Response, Information Spread and Manipulation, and Dynamic Public-Goods Provision -- confirm partial deviation from group norms boosts exploration, robustness, and performance. We highlight emergent coordination via in-context learning, underscoring the value of preserving diversity for resilient decision-making.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving</title>
<link>https://arxiv.org/abs/2502.16589</link>
<guid>https://arxiv.org/abs/2502.16589</guid>
<content:encoded><![CDATA[
<div> 关键词：Vehicle-to-everything (V2X)，Cooperative perception，Trajectory prediction，Multi-temporal fusion，Autonomous driving

总结:
本文介绍了针对自动驾驶的Co-MTP框架，该框架是一种利用V2X技术进行多时间融合的协同轨迹预测方法。文章指出现有的合作感知研究主要关注单帧合作感知，而如何利用V2X捕捉帧间的时间线索以辅助预测和规划任务尚待探索。Co-MTP框架在历史域中，通过V2X补充单辆车辆感知中的不完整历史轨迹，并采用异构图变换器学习多个代理之间的历史特征融合与交互。在未来域中，V2X可提供周围物体的预测结果，进一步扩展了图变换器，用于捕获自我规划与其他车辆意图之间的未来交互，从而根据特定规划动作获取最终的未来场景状态。在真实世界数据集V2X-Seq上评估Co-MTP框架后，结果显示其表现出最先进的性能，同时证明历史和未来的融合均能显著提升预测效果。 <div>
arXiv:2502.16589v1 Announce Type: new 
Abstract: Vehicle-to-everything technologies (V2X) have become an ideal paradigm to extend the perception range and see through the occlusion. Exiting efforts focus on single-frame cooperative perception, however, how to capture the temporal cue between frames with V2X to facilitate the prediction task even the planning task is still underexplored. In this paper, we introduce the Co-MTP, a general cooperative trajectory prediction framework with multi-temporal fusion for autonomous driving, which leverages the V2X system to fully capture the interaction among agents in both history and future domains to benefit the planning. In the history domain, V2X can complement the incomplete history trajectory in single-vehicle perception, and we design a heterogeneous graph transformer to learn the fusion of the history feature from multiple agents and capture the history interaction. Moreover, the goal of prediction is to support future planning. Thus, in the future domain, V2X can provide the prediction results of surrounding objects, and we further extend the graph transformer to capture the future interaction among the ego planning and the other vehicles' intentions and obtain the final future scenario state under a certain planning action. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and the results show that Co-MTP achieves state-of-the-art performance and that both history and future fusion can greatly benefit prediction.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control</title>
<link>https://arxiv.org/abs/2502.16608</link>
<guid>https://arxiv.org/abs/2502.16608</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（RL）、自适应交通信号控制（ATSC）、多智能体强化学习（MARL）、独立强化学习（IRL）、深度Q网络（DQN-DPUS）

总结:
本文探讨了在复杂城市交通网络中，强化学习（RL）作为自适应交通信号控制（ATSC）的一种有前途的数据驱动方法，其中深度神经网络极大地增强了其学习能力。然而，对于涉及多个智能体的ATSC任务，集中式RL由于联合动作空间维度过高而变得不切实际。多智能体RL（MARL）通过将控制权分散到局部RL代理来缓解这一可扩展性问题，但同时也带来了新的挑战，即每个局部代理只能观察到部分环境，因为交叉通信受到限制。文章指出，当无溢流拥堵（无代理间依赖）时，MARL可以通过将问题分解为多个独立强化学习过程来达到全局最优Q值；而在存在溢流拥堵（有代理间依赖）的情况下，则需采用集中式RL以实现最大全球Q值。基于以上结论，文章提出了一种新型动态参数更新策略——深度Q网络-动态参数更新策略（DQN-DPUS），该策略根据智能体之间的依赖动态来更新权重和偏置，即在没有溢流拥堵的情况下仅更新对角子矩阵。实验证明，DQN-DPUS在具有两个交叉口的简单网络下，可在不同交通流量条件下加速收敛速率，同时不影响最优探索性能。实验结果证实了理论发现的有效性，显示了DQN-DPUS在优化交通信号控制方面的优越性。 <div>
arXiv:2502.16608v1 Announce Type: new 
Abstract: Reinforcement learning (RL) emerges as a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, with deep neural networks substantially augmenting its learning capabilities. However, centralized RL becomes impractical for ATSC involving multiple agents due to the exceedingly high dimensionality of the joint action space. Multi-agent RL (MARL) mitigates this scalability issue by decentralizing control to local RL agents. Nevertheless, this decentralized method introduces new challenges: the environment becomes partially observable from the perspective of each local agent due to constrained inter-agent communication. Both centralized RL and MARL exhibit distinct strengths and weaknesses, particularly under heavy intersectional traffic conditions. In this paper, we justify that MARL can achieve the optimal global Q-value by separating into multiple IRL (Independent Reinforcement Learning) processes when no spill-back congestion occurs (no agent dependency) among agents (intersections). In the presence of spill-back congestion (with agent dependency), the maximum global Q-value can be achieved by using centralized RL. Building upon the conclusions, we propose a novel Dynamic Parameter Update Strategy for Deep Q-Network (DQN-DPUS), which updates the weights and bias based on the dependency dynamics among agents, i.e. updating only the diagonal sub-matrices for the scenario without spill-back congestion. We validate the DQN-DPUS in a simple network with two intersections under varying traffic, and show that the proposed strategy can speed up the convergence rate without sacrificing optimal exploration. The results corroborate our theoretical findings, demonstrating the efficacy of DQN-DPUS in optimizing traffic signal control.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Equilibrium Unit Based Localized Affine Formation Maneuver for Multi-agent Systems</title>
<link>https://arxiv.org/abs/2502.16653</link>
<guid>https://arxiv.org/abs/2502.16653</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统(MASs), 仿射定位性, 平衡单元, 分布式构建方法, 局部感知控制协议

总结:<br />
本文提出了一种基于平衡单元的多智能体系统(MASs)仿射定位性实现结构。该平衡单元能保证节点间非零权重的存在及其和为非零，消除了对名义配置的通用假设。为去除全局构造方式，文章引入了层状有向图的概念，并给出了与之关联的仿射定位性充分条件。在此框架下，设计了一种均衡单元构造(EUC)的分布式局部构建方法。结合局部通信准则(LCC)和基于局部感知的仿射阵型操纵控制(LSAFMC)协议，使得MASs在节点加入或移除时具有自我重构能力。 <div>
arXiv:2502.16653v1 Announce Type: new 
Abstract: Current affine formation maneuver of multi-agent systems (MASs) relys on the affine localizability determined by generic assumption for nominal configuration and global construction manner. This does not live up to practical constraints of robot swarms. In this paper, an equilibrium unit based structure is proposed to achieve affine localizability. In an equilibrium unit, existence of non-zero weights between nodes is guaranteed and their summation is proved to be non-zero. To remove the generic assumption, a notion of layerable directed graph is introduced, based on which a sufficient condition associated equilibrium unit is presented to establish affine localizability condition. Within this framework, distributed local construction manner is performed by a designed equilibrium unit construction (EUC) method. With the help of localized communication criterion (LCC) and localized sensing based affine formation maneuver control (LSAFMC) protocol, self-reconstruction capability is possessed by MASs when nodes are added to or removed from the swarms.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</title>
<link>https://arxiv.org/abs/2502.16660</link>
<guid>https://arxiv.org/abs/2502.16660</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、路径推理、BioMaze、PathSeeker、交互式子图导航

总结:
本文探讨了大型语言模型（LLMs）在复杂生物系统如途径推理中的应用潜力。为评估LLMs在此领域的表现，研究者构建了一个名为BioMaze的全新数据集，其中包含了5.1K个源于实际研究的复杂生物通路问题，涉及多种生物上下文场景。实验结果显示，LLMs在处理扰动系统的路径推理方面存在困难。针对此问题，文章提出了PathSeeker，这是一个基于交互式子图导航的LLM代理模型，旨在以科学对齐的方式更有效地处理生物系统的复杂性。相关数据集和代码已在https://github.com/zhao-ht/BioMaze上开源发布。 <div>
arXiv:2502.16660v1 Announce Type: new 
Abstract: The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Saarthi: The First AI Formal Verification Engineer</title>
<link>https://arxiv.org/abs/2502.16662</link>
<guid>https://arxiv.org/abs/2502.16662</guid>
<content:encoded><![CDATA[
<div> 关键词: AI、自主、形式验证工程师、Saarthi、RTL设计

总结:
本文介绍了世界上首个完全自主的人工智能形式验证工程师——Saarthi。Saarthi利用生成式AI中的代理工作流概念，能够实现对给定RTL设计的端到端自主验证。这使得硬件验证工程师可以更加专注于解决更复杂的难题，而验证团队也能追求更为宏大的目标。由于Saarthi的领域无关性实施方式，它具有可扩展性，可以在RTL设计、基于UVM的验证等多个领域应用。<br /><br /> <div>
arXiv:2502.16662v1 Announce Type: new 
Abstract: Recently, Devin has made a significant buzz in the Artificial Intelligence (AI) community as the world's first fully autonomous AI software engineer, capable of independently developing software code. Devin uses the concept of agentic workflow in Generative AI (GenAI), which empowers AI agents to engage in a more dynamic, iterative, and self-reflective process. In this paper, we present a similar fully autonomous AI formal verification engineer, Saarthi, capable of verifying a given RTL design end-to-end using an agentic workflow. With Saarthi, verification engineers can focus on more complex problems, and verification teams can strive for more ambitious goals. The domain-agnostic implementation of Saarthi makes it scalable for use across various domains such as RTL design, UVM-based verification, and others.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task</title>
<link>https://arxiv.org/abs/2502.16690</link>
<guid>https://arxiv.org/abs/2502.16690</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、空间信息表示、决策制定、笛卡尔坐标系、内部激活<br /><br />总结:
本文研究了大型语言模型（LLMs）如何处理和推理空间信息，并通过在网格世界导航任务中对比不同文本空间表示对LLM性能和内部激活的影响。实验表明，使用笛卡尔坐标系的空间表示方法能持续获得更高的成功率和路径效率，且随着模型规模增大，其表现明显提升。此外，通过对LLaMA-3.1-8B进行探查，发现模型中间层存在一些内部单元，它们与空间特征（如：代理人在网格中的位置或动作正确性）有稳健的相关性，且这些单元在处理不相关的空间推理任务时也会被激活。这项工作深化了我们对LLMs处理空间信息的理解，并为构建更可解释和健壮的智能代理系统提供了有价值的见解。 <div>
arXiv:2502.16690v1 Announce Type: new 
Abstract: Understanding how large language models (LLMs) represent and reason about spatial information is crucial for building robust agentic systems that can navigate real and simulated environments. In this work, we investigate the influence of different text-based spatial representations on LLM performance and internal activations in a grid-world navigation task. By evaluating models of various sizes on a task that requires navigating toward a goal, we examine how the format used to encode spatial information impacts decision-making. Our experiments reveal that cartesian representations of space consistently yield higher success rates and path efficiency, with performance scaling markedly with model size. Moreover, probing LLaMA-3.1-8B revealed subsets of internal units, primarily located in intermediate layers, that robustly correlate with spatial features, such as the position of the agent in the grid or action correctness, regardless of how that information is represented, and are also activated by unrelated spatial reasoning tasks. This work advances our understanding of how LLMs process spatial information and provides valuable insights for developing more interpretable and robust agentic AI systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Optimal Adversarial Robust Reinforcement Learning with Infinity Measurement Error</title>
<link>https://arxiv.org/abs/2502.16734</link>
<guid>https://arxiv.org/abs/2502.16734</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习(DRL)、对抗性攻击、内在状态对抗性马尔可夫决策过程(ISA-MDP)、最优鲁棒策略(ORP)、一致对抗鲁棒强化学习(CAR-RL)

总结:
本文探讨了确保深度强化学习(DRL)代理对对抗性攻击的鲁棒性的重要性。研究提出了内在状态对抗性马尔可夫决策过程(ISA-MDP)的新概念，该框架下，敌人无法从根本上改变状态观测的本质。理论证明在ISA-MDP中存在确定性和稳态的ORP，并与贝尔曼最优策略相吻合，揭示提高DRL鲁棒性不一定牺牲自然环境下的性能。文章还指出，以前依赖于1度量误差的DRL算法存在脆弱性，实现ORP需要无穷度量误差(IME)。为此，文章提出了一致对抗鲁棒强化学习(CAR-RL)框架，通过优化IME的近似值进行优化，并将其应用于价值基础和策略基础的DRL算法上，实验结果验证了理论分析并取得了优越性能。 <div>
arXiv:2502.16734v1 Announce Type: new 
Abstract: Ensuring the robustness of deep reinforcement learning (DRL) agents against adversarial attacks is critical for their trustworthy deployment. Recent research highlights the challenges of achieving state-adversarial robustness and suggests that an optimal robust policy (ORP) does not always exist, complicating the enforcement of strict robustness constraints. In this paper, we further explore the concept of ORP. We first introduce the Intrinsic State-adversarial Markov Decision Process (ISA-MDP), a novel formulation where adversaries cannot fundamentally alter the intrinsic nature of state observations. ISA-MDP, supported by empirical and theoretical evidence, universally characterizes decision-making under state-adversarial paradigms. We rigorously prove that within ISA-MDP, a deterministic and stationary ORP exists, aligning with the Bellman optimal policy. Our findings theoretically reveal that improving DRL robustness does not necessarily compromise performance in natural environments. Furthermore, we demonstrate the necessity of infinity measurement error (IME) in both $Q$-function and probability spaces to achieve ORP, unveiling vulnerabilities of previous DRL algorithms that rely on $1$-measurement errors. Motivated by these insights, we develop the Consistent Adversarial Robust Reinforcement Learning (CAR-RL) framework, which optimizes surrogates of IME. We apply CAR-RL to both value-based and policy-based DRL algorithms, achieving superior performance and validating our theoretical analysis.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System</title>
<link>https://arxiv.org/abs/2502.16750</link>
<guid>https://arxiv.org/abs/2502.16750</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主AI代理、大型语言模型、安全威胁、防御方案、反狱破系统

总结:
本文关注的是自主AI代理使用大型语言模型所面临的不可忽视的安全威胁问题。现有的静态防护措施对于多模态高级攻击（如多轮越狱和欺骗性对齐）无法有效抵御。研究指出，急需开发新的评估框架来识别并对抗这些威胁，确保安全部署。文章提出的方法包括通过逆向图灵测试检测恶意代理、利用多智能体模拟分析欺骗性对齐，并设计了一种反狱破系统，通过工具介导的对抗性场景测试了GEMINI 1.5 pro和llama-3.3-70B、deepseek r1等模型。虽然检测准确率高达94%，但当攻击提示长度增加时，系统的脆弱性显现，攻击成功率提高，多样性指标预测失效，暴露出多个复杂系统故障。因此，论文强调了采用基于主动监控的灵活安全系统的重要性，需要由代理自身与系统管理员适应性干预相结合，以应对当前模型可能产生的安全隐患。最终，作者提出一套全面的框架来解决这些问题。 <div>
arXiv:2502.16750v1 Announce Type: new 
Abstract: The autonomous AI agents using large language models can create undeniable values in all span of the society but they face security threats from adversaries that warrants immediate protective solutions because trust and safety issues arise. Considering the many-shot jailbreaking and deceptive alignment as some of the main advanced attacks, that cannot be mitigated by the static guardrails used during the supervised training, points out a crucial research priority for real world robustness. The combination of static guardrails in dynamic multi-agent system fails to defend against those attacks. We intend to enhance security for LLM-based agents through the development of new evaluation frameworks which identify and counter threats for safe operational deployment. Our work uses three examination methods to detect rogue agents through a Reverse Turing Test and analyze deceptive alignment through multi-agent simulations and develops an anti-jailbreaking system by testing it with GEMINI 1.5 pro and llama-3.3-70B, deepseek r1 models using tool-mediated adversarial scenarios. The detection capabilities are strong such as 94\% accuracy for GEMINI 1.5 pro yet the system suffers persistent vulnerabilities when under long attacks as prompt length increases attack success rates (ASR) and diversity metrics become ineffective in prediction while revealing multiple complex system faults. The findings demonstrate the necessity of adopting flexible security systems based on active monitoring that can be performed by the agents themselves together with adaptable interventions by system admin as the current models can create vulnerabilities that can lead to the unreliable and vulnerable system. So, in our work, we try to address such situations and propose a comprehensive framework to counteract the security issues.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model-Based Exploration in Monitored Markov Decision Processes</title>
<link>https://arxiv.org/abs/2502.16772</link>
<guid>https://arxiv.org/abs/2502.16772</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、奖励缺失、监控马尔科夫决策过程（Mon-MDP）、模型基算法、有限样本界

总结:<br />
本文针对奖励不总是可观察到的强化学习问题，提出了一个针对监控马尔科夫决策过程（Mon-MDP）的模型基算法。该算法利用两种模型基区间估计方法，确保可观测奖励的有效观测并学习最优策略。实验结果显示，新算法在超过二十多个基准场景下相比于前序算法展现出更快的收敛速度，尤其在已知监控进程的情况下有显著提升。此外，文章还首次给出了性能的有限样本界，并证明了当某些奖励不可观测时，算法能收敛至最优的最坏情况策略。 <div>
arXiv:2502.16772v1 Announce Type: new 
Abstract: A tenet of reinforcement learning is that rewards are always observed by the agent. However, this is not true in many realistic settings, e.g., a human observer may not always be able to provide rewards, a sensor to observe rewards may be limited or broken, or rewards may be unavailable during deployment. Monitored Markov decision processes (Mon-MDPs) have recently been proposed as a model of such settings. Yet, Mon-MDP algorithms developed thus far do not fully exploit the problem structure, cannot take advantage of a known monitor, have no worst-case guarantees for ``unsolvable'' Mon-MDPs without specific initialization, and only have asymptotic proofs of convergence. This paper makes three contributions. First, we introduce a model-based algorithm for Mon-MDPs that addresses all of these shortcomings. The algorithm uses two instances of model-based interval estimation, one to guarantee that observable rewards are indeed observed, and another to learn the optimal policy. Second, empirical results demonstrate these advantages, showing faster convergence than prior algorithms in over two dozen benchmark settings, and even more dramatic improvements when the monitor process is known. Third, we present the first finite-sample bound on performance and show convergence to an optimal worst-case policy when some rewards are never observable.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay</title>
<link>https://arxiv.org/abs/2502.16789</link>
<guid>https://arxiv.org/abs/2502.16789</guid>
<content:encoded><![CDATA[
<div> 关键词: 阿尔法挖掘、alpha衰减、遗传编程、大型语言模型、AlphaAgent

<br /><br />总结:
本文提出了一个名为AlphaAgent的自主框架，旨在解决金融领域的阿尔法挖掘中面临的alpha衰减问题。传统方法如遗传编程易受过拟合和复杂性影响导致alpha衰减，而依赖大型语言模型的方法则可能产生同质化因子加剧衰减。AlphaAgent通过三个方面来生成具有抗衰减能力的alpha因素：(1)利用抽象语法树相似度度量确保生成因素与现有alpha的原创性；(2)通过LLM评估市场假设与生成因素之间的语义一致性，实现假说-因素对齐；(3)采用基于AST的结构约束控制复杂性，防止过度拟合。这些机制共同引导alpha生成过程，在保持原创性、财务合理性的同时，适应不断变化的市场条件，从而有效缓解alpha衰减风险。实验表明，AlphaAgent在中美股票市场上相较于传统和基于LLM的方法更能有效地减轻alpha衰减现象，并在过去四年中持续产生了显著的超额收益。尤其值得一提的是，AlphaAgent展现出对alpha衰减的强大抵抗力，为发掘有影响力的因子提供了新途径。 <div>
arXiv:2502.16789v1 Announce Type: new 
Abstract: Alpha mining, a critical component in quantitative investment, focuses on discovering predictive signals for future asset returns in increasingly complex financial markets. However, the pervasive issue of alpha decay, where factors lose their predictive power over time, poses a significant challenge for alpha mining. Traditional methods like genetic programming face rapid alpha decay from overfitting and complexity, while approaches driven by Large Language Models (LLMs), despite their promise, often rely too heavily on existing knowledge, creating homogeneous factors that worsen crowding and accelerate decay. To address this challenge, we propose AlphaAgent, an autonomous framework that effectively integrates LLM agents with ad hoc regularizations for mining decay-resistant alpha factors. AlphaAgent employs three key mechanisms: (i) originality enforcement through a similarity measure based on abstract syntax trees (ASTs) against existing alphas, (ii) hypothesis-factor alignment via LLM-evaluated semantic consistency between market hypotheses and generated factors, and (iii) complexity control via AST-based structural constraints, preventing over-engineered constructions that are prone to overfitting. These mechanisms collectively guide the alpha generation process to balance originality, financial rationale, and adaptability to evolving market conditions, mitigating the risk of alpha decay. Extensive evaluations show that AlphaAgent outperforms traditional and LLM-based methods in mitigating alpha decay across bull and bear markets, consistently delivering significant alpha in Chinese CSI 500 and US S&amp;P 500 markets over the past four years. Notably, AlphaAgent showcases remarkable resistance to alpha decay, elevating the potential for yielding powerful factors.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions</title>
<link>https://arxiv.org/abs/2502.16796</link>
<guid>https://arxiv.org/abs/2502.16796</guid>
<content:encoded><![CDATA[
<div> 关键词：MobileSteward、跨app指令、多智能体框架、任务自动化、Memory-based 自我进化

总结:
本文提出了一种名为MobileSteward的自我进化的多智能体框架，用于解决移动设备上的跨app指令执行问题。MobileSteward由协调中心的StewardAgent和多个针对特定应用的StaffAgents组成，旨在应对复杂任务关系、多样化应用环境以及多步骤执行中的错误传播与信息丢失挑战。该框架包括三个模块：动态招聘（Dynamic Recruitment）根据信息流生成调度图以关联不同应用的任务；指派执行（Assigned Execution）将任务分配给具有应用专业化技能的StaffAgents；调整评估（Adjusted Evaluation）通过提供反馈提示或关键信息来减轻多步骤执行中的错误传播和信息损失。为了不断优化MobileSteward的性能，文章还设计了一个基于记忆的自我进化机制，通过总结成功的执行经验来提升其表现。此外，文章创建了首个真实环境下的英文跨app基准测试集（CAPBench），实验结果显示MobileSteward相较于单智能体和多智能体框架，表现出更优秀的处理复杂跨app指令的能力。 <div>
arXiv:2502.16796v1 Announce Type: new 
Abstract: Mobile phone agents can assist people in automating daily tasks on their phones, which have emerged as a pivotal research spotlight. However, existing procedure-oriented agents struggle with cross-app instructions, due to the following challenges: (1) complex task relationships, (2) diverse app environment, and (3) error propagation and information loss in multi-step execution. Drawing inspiration from object-oriented programming principles, we recognize that object-oriented solutions is more suitable for cross-app instruction. To address these challenges, we propose a self-evolving multi-agent framework named MobileSteward, which integrates multiple app-oriented StaffAgents coordinated by a centralized StewardAgent. We design three specialized modules in MobileSteward: (1) Dynamic Recruitment generates a scheduling graph guided by information flow to explicitly associate tasks among apps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each equipped with app-specialized expertise to address the diversity between apps. (3) Adjusted Evaluation conducts evaluation to provide reflection tips or deliver key information, which alleviates error propagation and information loss during multi-step execution. To continuously improve the performance of MobileSteward, we develop a Memory-based Self-evolution mechanism, which summarizes the experience from successful execution, to improve the performance of MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench) in the real-world environment to evaluate the agents' capabilities of solving complex cross-app instructions. Experimental results demonstrate that MobileSteward achieves the best performance compared to both single-agent and multi-agent frameworks, highlighting the superiority of MobileSteward in better handling user instructions with diverse complexity.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances</title>
<link>https://arxiv.org/abs/2502.16804</link>
<guid>https://arxiv.org/abs/2502.16804</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Driving Systems (ADSs)，Large Language Models (LLMs)，multi-agent ADSs，agent interaction modes，agent-human interactions

<br /><br />总结:
本文主要探讨了大型语言模型（LLMs）在自动驾驶系统（ADSs）中的应用及其面临的挑战，尤其是单代理系统存在的局限性。为解决这些问题，文章介绍了基于LLM的多代理ADSs的最新进展，这些进展着重于改进代理间的交互和合作。文章将现有LLM方法进行了根据不同交互模式的分类，并讨论了LLM基代理与人类交互的情景。此外，文中还总结了该领域的关键应用、数据集及挑战，为未来的研究提供了指导方向。 <div>
arXiv:2502.16804v1 Announce Type: new 
Abstract: Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety. Large Language Models (LLMs), known for their exceptional planning and reasoning capabilities, have been integrated into ADSs to assist with driving decision-making. However, LLM-based single-agent ADSs face three major challenges: limited perception, insufficient collaboration, and high computational demands. To address these issues, recent advancements in LLM-based multi-agent ADSs have focused on improving inter-agent communication and cooperation. This paper provides a frontier survey of LLM-based multi-agent ADSs. We begin with a background introduction to related concepts, followed by a categorization of existing LLM-based approaches based on different agent interaction modes. We then discuss agent-human interactions in scenarios where LLM-based agents engage with humans. Finally, we summarize key applications, datasets, and challenges in this field to support future research (https://anonymous.4open.science/r/LLM-based_Multi-agent_ADS-3A5C/README.md).
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grounded Persuasive Language Generation for Automated Marketing</title>
<link>https://arxiv.org/abs/2502.16810</link>
<guid>https://arxiv.org/abs/2502.16810</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、营销内容生成、房地产描述、用户偏好、个性化模块

总结:
该文提出了一种采用大型语言模型（LLMs）的智能框架，用于自动生成具有说服力和事实依据的房地产营销内容。该框架包含三个关键模块：(1) 现实结合模块，模仿人类专家行为预测市场吸引人的特性；(2) 个性化模块，使内容与用户偏好相匹配；(3) 营销模块，确保内容的事实准确性和地域特色。通过针对潜在购房者开展系统的人类受试者实验，研究结果显示，该方法生成的房地产描述相较于人类专家编写的更受欢迎。这表明利用LLM为基础的智能框架可以实现大规模目标市场营销的自动化，并在确保仅使用事实进行负责任生成方面具有潜力。 <div>
arXiv:2502.16810v1 Announce Type: new 
Abstract: This paper develops an agentic framework that employs large language models (LLMs) to automate the generation of persuasive and grounded marketing content, using real estate listing descriptions as our focal application domain. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized features. We conduct systematic human-subject experiments in the domain of real estate marketing, with a focus group of potential house buyers. The results demonstrate that marketing descriptions generated by our approach are preferred over those written by human experts by a clear margin. Our findings suggest a promising LLM-based agentic framework to automate large-scale targeted marketing while ensuring responsible generation using only facts.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment</title>
<link>https://arxiv.org/abs/2502.16863</link>
<guid>https://arxiv.org/abs/2502.16863</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器人协作、强化学习、信用分配问题、大语言模型、LLM-MCA方法

总结:
本文探讨了在多智能体协作中如何有效地进行信用分配的问题，该问题在自主车辆协调和空间组装等场景中具有重要意义。研究者提出将信用分配转化为序列改进和归因两个模式识别问题，并利用大型语言模型（LLM）提出了新的LLM-MCA方法。这种方法通过中心化的LLM奖励批评机制，量化每个智能体对团队总收益的贡献并据此更新智能体的策略网络。同时，文章还提出了LLM-TACA扩展方法，让LLM批评器能够执行明确的任务分配，直接向每个智能体策略传递中间目标。实验结果显示，这两种方法在包括Level-Based Foraging、Robotic Warehouse以及新提出的包含碰撞安全约束的Spaceworld基准测试上都显著优于现有最佳方法。作为方法应用的副产品，他们生成了大量的轨迹数据集，其中每个时间步均附带有来自LLM批评器的针对每个智能体的奖励信息。 <div>
arXiv:2502.16863v1 Announce Type: new 
Abstract: Recent work, spanning from autonomous vehicle coordination to in-space assembly, has shown the importance of learning collaborative behavior for enabling robots to achieve shared goals. A common approach for learning this cooperative behavior is to utilize the centralized-training decentralized-execution paradigm. However, this approach also introduces a new challenge: how do we evaluate the contributions of each agent's actions to the overall success or failure of the team. This credit assignment problem has remained open, and has been extensively studied in the Multi-Agent Reinforcement Learning literature. In fact, humans manually inspecting agent behavior often generate better credit evaluations than existing methods. We combine this observation with recent works which show Large Language Models demonstrate human-level performance at many pattern recognition tasks. Our key idea is to reformulate credit assignment to the two pattern recognition problems of sequence improvement and attribution, which motivates our novel LLM-MCA method. Our approach utilizes a centralized LLM reward-critic which numerically decomposes the environment reward based on the individualized contribution of each agent in the scenario. We then update the agents' policy networks based on this feedback. We also propose an extension LLM-TACA where our LLM critic performs explicit task assignment by passing an intermediary goal directly to each agent policy in the scenario. Both our methods far outperform the state-of-the-art on a variety of benchmarks, including Level-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark which incorporates collision-related safety constraints. As an artifact of our methods, we generate large trajectory datasets with each timestep annotated with per-agent reward information, as sampled from our LLM critics.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward Agentic AI: Generative Information Retrieval Inspired Intelligent Communications and Networking</title>
<link>https://arxiv.org/abs/2502.16866</link>
<guid>https://arxiv.org/abs/2502.16866</guid>
<content:encoded><![CDATA[
<div> 关键词：智能自动化，agentic AI，信息检索，通信网络，资源分配

总结:
本文探讨了现代电信网络中智能自动化的需求，特别是agentic AI在提升效率、适应性和韧性方面的作用。文章聚焦于基于生成的信息检索技术如何应用于智能通信和网络领域，分析了传统检索、混合检索、语义检索、知识库检索及agentic上下文检索等多种策略的优势、局限性与适用场景。文中还介绍了一种电信系统特有的agentic上下文检索框架，该框架能通过整合多源检索、结构化推理和自我反思验证来增强网络规划。实验结果显示，此框架相比于传统和语义检索方法显著提高了答案准确性、解释一致性和检索效率。最后，文章指出了未来的研究方向。 <div>
arXiv:2502.16866v1 Announce Type: new 
Abstract: The increasing complexity and scale of modern telecommunications networks demand intelligent automation to enhance efficiency, adaptability, and resilience. Agentic AI has emerged as a key paradigm for intelligent communications and networking, enabling AI-driven agents to perceive, reason, decide, and act within dynamic networking environments. However, effective decision-making in telecom applications, such as network planning, management, and resource allocation, requires integrating retrieval mechanisms that support multi-hop reasoning, historical cross-referencing, and compliance with evolving 3GPP standards. This article presents a forward-looking perspective on generative information retrieval-inspired intelligent communications and networking, emphasizing the role of knowledge acquisition, processing, and retrieval in agentic AI for telecom systems. We first provide a comprehensive review of generative information retrieval strategies, including traditional retrieval, hybrid retrieval, semantic retrieval, knowledge-based retrieval, and agentic contextual retrieval. We then analyze their advantages, limitations, and suitability for various networking scenarios. Next, we present a survey about their applications in communications and networking. Additionally, we introduce an agentic contextual retrieval framework to enhance telecom-specific planning by integrating multi-source retrieval, structured reasoning, and self-reflective validation. Experimental results demonstrate that our framework significantly improves answer accuracy, explanation consistency, and retrieval efficiency compared to traditional and semantic retrieval methods. Finally, we outline future research directions.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data</title>
<link>https://arxiv.org/abs/2502.16868</link>
<guid>https://arxiv.org/abs/2502.16868</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Progressive Document Investigation, Graphy, Scrapper, Surveyor

总结:
本文介绍了一个针对大规模无结构文档进行渐进式探索、分析和综合处理的新平台Graphy。Graphy旨在解决大型语言模型（LLMs）在面对此类任务时常表现不足的问题，该问题被称为“Progressive Document Investigation”。Graphy包括一个离线Scrapper，它将原始文档转换为由Fact和Dimension节点组成的结构化图；以及一个在线Surveyor，支持迭代探索和LLM驱动的报告生成。文章展示了预处理的包含5万多篇论文及其引用关系的图谱，以此展示Graphy如何简化文献调研场景。相关演示视频可在https://youtu.be/uM4nzkAdGlM找到。 <div>
arXiv:2502.16868v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable performance in tasks such as Retrieval-Augmented Generation (RAG) and autonomous AI agent workflows. Yet, when faced with large sets of unstructured documents requiring progressive exploration, analysis, and synthesis, such as conducting literature survey, existing approaches often fall short. We address this challenge -- termed Progressive Document Investigation -- by introducing Graphy, an end-to-end platform that automates data modeling, exploration and high-quality report generation in a user-friendly manner. Graphy comprises an offline Scrapper that transforms raw documents into a structured graph of Fact and Dimension nodes, and an online Surveyor that enables iterative exploration and LLM-driven report generation. We showcase a pre-scrapped graph of over 50,000 papers -- complete with their references -- demonstrating how Graphy facilitates the literature-survey scenario. The demonstration video can be found at https://youtu.be/uM4nzkAdGlM.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis</title>
<link>https://arxiv.org/abs/2502.16879</link>
<guid>https://arxiv.org/abs/2502.16879</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，经济决策，Multi-LLM-Agent-Based (MLAB)框架，政策分析，兴趣收入税收

<br /><br />总结:

本文提出了一种利用多个大型语言模型（LLMs）作为异质性人工智能经济代理进行经济和公共政策分析的新方法。研究首先评估了五个LLMs在两种不同场景下解决两期消费分配问题的经济决策能力，分别是基于明确效用函数和直观推理的情况。与以往仅通过改变提示来模拟异质性的做法不同，该方法利用不同LLM之间固有的分析能力差异来建模具有多样认知特质的经济主体。在此基础上，构建了一个MLAB框架，将这些LLM映射到特定教育群体及其对应的收入阶层。以兴趣收入税收为例，文章展示了如何运用MLAB框架模拟政策对异质性经济主体的影响，为利用LLMs的人类般推理能力和计算力开展经济与公共政策分析提供了一个有前景的新方向。 <div>
arXiv:2502.16879v1 Announce Type: new 
Abstract: This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial economic agents. We first evaluate five LLMs' economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: with explicit utility functions and based on intuitive reasoning. While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB) framework by mapping these LLMs to specific educational groups and corresponding income brackets. Using interest-income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs' human-like reasoning capabilities and computational power.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unbiased and Sign Compression in Distributed Learning: Comparing Noise Resilience via SDEs</title>
<link>https://arxiv.org/abs/2502.17009</link>
<guid>https://arxiv.org/abs/2502.17009</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式方法、通信开销、压缩、随机梯度下降、噪声鲁棒性

总结:
本文研究了在处理大规模机器学习流程中分布式压缩方法的重要性以及它们面临的通信开销问题。文章重点关注了两种分布式压缩算法——分布式压缩SGD (DCSGD) 和分布式SignSGD (DSignSGD)，并利用随机微分方程对其在存在大量和重尾梯度噪声情况下的性能进行了分析。结果表明，DCSGD在应对无偏压缩下的随机梯度噪声时较为脆弱，而DSignSGD即使在大型和重尾噪声环境下仍能保持鲁棒性。此外，文中还提出了新的超参数调整规则以缓解压缩导致的性能退化。这些发现通过多个深度学习架构和数据集的实验证明，并为分布式优化提供了实用建议。 <div>
arXiv:2502.17009v1 Announce Type: new 
Abstract: Distributed methods are essential for handling machine learning pipelines comprising large-scale models and datasets. However, their benefits often come at the cost of increased communication overhead between the central server and agents, which can become the main bottleneck, making training costly or even unfeasible in such systems. Compression methods such as quantization and sparsification can alleviate this issue. Still, their robustness to large and heavy-tailed gradient noise, a phenomenon sometimes observed in language modeling, remains poorly understood. This work addresses this gap by analyzing Distributed Compressed SGD (DCSGD) and Distributed SignSGD (DSignSGD) using stochastic differential equations (SDEs). Our results show that DCSGD with unbiased compression is more vulnerable to noise in stochastic gradients, while DSignSGD remains robust, even under large and heavy-tailed noise. Additionally, we propose new scaling rules for hyperparameter tuning to mitigate performance degradation due to compression. These findings are empirically validated across multiple deep learning architectures and datasets, providing practical recommendations for distributed optimization.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA2RL: Masked Autoencoders for Generalizable Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17046</link>
<guid>https://arxiv.org/abs/2502.17046</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、任务无关技能、部分观察、Masked Autoencoders、零样本泛化

<br /><br />总结:
本文提出了一种名为“多智能体强化学习中的Masked Autoencoders（MA2RL）”的框架，用于解决在部分观察环境中多智能体强化学习中任务无关技能学习面临的挑战。MA2RL通过从实体视角重建全局实体状态，鼓励智能体推断未被观察到的实体，从而促进不同智能体间的协调以及技能的一般化和一致性学习。该框架将局部实体观测视为全局实体状态的掩码上下文，并能推断动态掩码实体的潜在表示，有助于任务无关技能的分配和技能语义的学习。实验结果表明，相较于现有方法，MA2RL表现出显著的性能提升、出色的零样本泛化能力和优异的迁移能力。 <div>
arXiv:2502.17046v1 Announce Type: new 
Abstract: To develop generalizable models in multi-agent reinforcement learning, recent approaches have been devoted to discovering task-independent skills for each agent, which generalize across tasks and facilitate agents' cooperation. However, particularly in partially observed settings, such approaches struggle with sample efficiency and generalization capabilities due to two primary challenges: (a) How to incorporate global states into coordinating the skills of different agents? (b) How to learn generalizable and consistent skill semantics when each agent only receives partial observations? To address these challenges, we propose a framework called \textbf{M}asked \textbf{A}utoencoders for \textbf{M}ulti-\textbf{A}gent \textbf{R}einforcement \textbf{L}earning (MA2RL), which encourages agents to infer unobserved entities by reconstructing entity-states from the entity perspective. The entity perspective helps MA2RL generalize to diverse tasks with varying agent numbers and action spaces. Specifically, we treat local entity-observations as masked contexts of the global entity-states, and MA2RL can infer the latent representation of dynamically masked entities, facilitating the assignment of task-independent skills and the learning of skill semantics. Extensive experiments demonstrate that MA2RL achieves significant improvements relative to state-of-the-art approaches, demonstrating extraordinary performance, remarkable zero-shot generalization capabilities and advantageous transferability.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative Models in Decision Making: A Survey</title>
<link>https://arxiv.org/abs/2502.17100</link>
<guid>https://arxiv.org/abs/2502.17100</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型、决策任务、应用分类、实际场景、未来发展方向

总结:
这篇论文回顾了生成模型在决策任务中的应用。文中将生成模型分为七类，并详细阐述了它们在决策过程中的三种主要角色：控制器、模型器和优化器。接着，文章分析了这些模型在五个关键的实际决策场景中的部署情况。此外，论文还指出了当前方法的优势与限制，并提出了推动下一代生成指令模型发展的三个关键方向：高性能算法、大规模通用决策模型以及自演进和适应性的模型。<br /><br /> <div>
arXiv:2502.17100v1 Announce Type: new 
Abstract: In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to handle complex data distributions and their strong model capacity, generative models can be effectively incorporated into decision-making systems by generating trajectories that guide agents toward high-reward state-action regions or intermediate sub-goals. This paper presents a comprehensive review of the application of generative models in decision-making tasks. We classify seven fundamental types of generative models: energy-based models, generative adversarial networks, variational autoencoders, normalizing flows, diffusion models, generative flow networks, and autoregressive models. Regarding their applications, we categorize their functions into three main roles: controllers, modelers and optimizers, and discuss how each role contributes to decision-making. Furthermore, we examine the deployment of these models across five critical real-world decision-making scenarios. Finally, we summarize the strengths and limitations of current approaches and propose three key directions for advancing next-generation generative directive models: high-performance algorithms, large-scale generalized decision-making models, and self-evolving and adaptive models.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mobile-Agent-V: Learning Mobile Device Operation Through Video-Guided Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2502.17110</link>
<guid>https://arxiv.org/abs/2502.17110</guid>
<content:encoded><![CDATA[
<div> 关键词：移动设备、自动化、AI框架、视频指导、Mobile-Agent-V

总结:
本文介绍了随着移动设备使用量急剧增加，对任务管理自动化的需求日益增长。现有的许多AI驱动框架因缺乏足够的操作知识而面临挑战。为解决这一问题，文章提出了Mobile-Agent-V，这是一个利用视频指导提供丰富且低成本的操作知识的移动自动化框架。Mobile-Agent-V通过利用未经特殊采样或预处理的视频输入来增强任务执行能力，并通过集成滑动窗口策略及结合视频代理和深度反思代理，确保动作与用户指令相匹配。这样，用户可以录制带有指导的任务过程，使系统能够自主学习并高效执行任务。实验结果显示，Mobile-Agent-V相较于现有框架性能提高了30%。 <div>
arXiv:2502.17110v1 Announce Type: new 
Abstract: The rapid increase in mobile device usage necessitates improved automation for seamless task management. However, many AI-driven frameworks struggle due to insufficient operational knowledge. Manually written knowledge helps but is labor-intensive and inefficient. To address these challenges, we introduce Mobile-Agent-V, a framework that leverages video guidance to provide rich and cost-effective operational knowledge for mobile automation. Mobile-Agent-V enhances task execution capabilities by leveraging video inputs without requiring specialized sampling or preprocessing. Mobile-Agent-V integrates a sliding window strategy and incorporates a video agent and deep-reflection agent to ensure that actions align with user instructions. Through this innovative approach, users can record task processes with guidance, enabling the system to autonomously learn and execute tasks efficiently. Experimental results show that Mobile-Agent-V achieves a 30% performance improvement compared to existing frameworks.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Novel Multiple Access Scheme for Heterogeneous Wireless Communications using Symmetry-aware Continual Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17167</link>
<guid>https://arxiv.org/abs/2502.17167</guid>
<content:encoded><![CDATA[
<div> 关键词: Metaverse, 无线通信, 多接入管理, 深度强化学习(Deep Reinforcement Learning, DRL), 不断学习(Continual Learning, CL)

<br /><br />总结:
该文探讨了Metaverse对数字互动革命的影响以及其在无线通信系统中面临的挑战，特别是在频谱多接入效率方面的难题。针对这一问题，文中提出了一种结合不断学习（CL）的智能媒体访问控制（MAC）协议新方法。此方法采用适应性双倍并行及双重深度Q学习（D3QL）为基础的MAC协议，具备对环境变化和未知类型的遗留用户设备（UEs）进行兼容与保护隐私的能力。通过引入对称性感知的CL机制，该方案能够在保证公平性的前提下最大化智能代理的吞吐量。数学分析证实了所提方案的有效性，显示其在吞吐量、冲突率和公平性等方面优于传统的DRL方法，并能在高度动态场景中实现实时响应。 <div>
arXiv:2502.17167v1 Announce Type: new 
Abstract: The Metaverse holds the potential to revolutionize digital interactions through the establishment of a highly dynamic and immersive virtual realm over wireless communications systems, offering services such as massive twinning and telepresence. This landscape presents novel challenges, particularly efficient management of multiple access to the frequency spectrum, for which numerous adaptive Deep Reinforcement Learning (DRL) approaches have been explored. However, challenges persist in adapting agents to heterogeneous and non-stationary wireless environments. In this paper, we present a novel approach that leverages Continual Learning (CL) to enhance intelligent Medium Access Control (MAC) protocols, featuring an intelligent agent coexisting with legacy User Equipments (UEs) with varying numbers, protocols, and transmission profiles unknown to the agent for the sake of backward compatibility and privacy. We introduce an adaptive Double and Dueling Deep Q-Learning (D3QL)-based MAC protocol, enriched by a symmetry-aware CL mechanism, which maximizes intelligent agent throughput while ensuring fairness. Mathematical analysis validates the efficiency of our proposed scheme, showcasing superiority over conventional DRL-based techniques in terms of throughput, collision rate, and fairness, coupled with real-time responsiveness in highly dynamic scenarios.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Teleology-Driven Affective Computing: A Causal Framework for Sustained Well-Being</title>
<link>https://arxiv.org/abs/2502.17172</link>
<guid>https://arxiv.org/abs/2502.17172</guid>
<content:encoded><![CDATA[
<div> 关键词：情感计算、长期人类福祉、目标导向框架、个人情感事件数据集、元强化学习

总结:<br />
本文提出了一种以目的为导向的情感计算框架，旨在将基本情绪理论、评价理论和建构主义方法统一起来，强调情感是一个适应性、目标导向的过程，有助于生存和发展。该框架关注于使智能代理与个体及群体的长期福祉保持一致。为了实现这一目标，文章倡导创建一个个人情感事件的“数据宇宙”，通过真实世界的经验抽样和沉浸式虚拟现实捕捉信念、目标、行动和结果之间的互动关系。通过因果建模技术，AI系统能够推断个体独特的情感需求并提供定制化的干预措施以促进持续的福祉。此外，文章引入了元强化学习范式，在模拟环境中训练代理，使其能适应不断演变的情感需求，并平衡从即时情绪需求到长期自我实现等多层目标。这个框架转移了从统计相关性到因果推理的关注点，增强了代理预测和主动应对情感挑战的能力，为开发个性化、伦理对齐的情感系统提供了基础，从而推动有意义的人工智能与人类交互和社会福祉。 <div>
arXiv:2502.17172v1 Announce Type: new 
Abstract: Affective computing has made significant strides in emotion recognition and generation, yet current approaches mainly focus on short-term pattern recognition and lack a comprehensive framework to guide affective agents toward long-term human well-being. To address this, we propose a teleology-driven affective computing framework that unifies major emotion theories (basic emotion, appraisal, and constructivist approaches) under the premise that affect is an adaptive, goal-directed process that facilitates survival and development. Our framework emphasizes aligning agent responses with both personal/individual and group/collective well-being over extended timescales. We advocate for creating a "dataverse" of personal affective events, capturing the interplay between beliefs, goals, actions, and outcomes through real-world experience sampling and immersive virtual reality. By leveraging causal modeling, this "dataverse" enables AI systems to infer individuals' unique affective concerns and provide tailored interventions for sustained well-being. Additionally, we introduce a meta-reinforcement learning paradigm to train agents in simulated environments, allowing them to adapt to evolving affective concerns and balance hierarchical goals - from immediate emotional needs to long-term self-actualization. This framework shifts the focus from statistical correlations to causal reasoning, enhancing agents' ability to predict and respond proactively to emotional challenges, and offers a foundation for developing personalized, ethically aligned affective systems that promote meaningful human-AI interactions and societal well-being.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Survey on Strategic Mining in Blockchain: A Reinforcement Learning Approach</title>
<link>https://arxiv.org/abs/2502.17307</link>
<guid>https://arxiv.org/abs/2502.17307</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (RL), 战略性挖矿攻击, 马尔科夫决策过程 (MDP), 区块链共识协议, 安全阈值

<br /><br />总结:
该文调查了强化学习（RL）在战略性挖矿分析中的应用，并将其与基于马尔科夫决策过程（MDP）的方法进行了比较。首先概述了基础的MDP模型及其局限性，随后探讨了适用于各种区块链共识协议的RL框架，用于学习近似最优策略。文章进一步对比了RL技术在确定安全阈值（如发动有利可图攻击所需的最小攻击者算力）上的有效性。此外，文中还对共识协议进行分类并提出了开放性挑战，包括多智能体动态和现实世界验证。总的来说，这篇论文突显了强化学习在应对自私挖矿带来的挑战，包括协议设计、威胁检测和安全性分析方面的潜力，并为分布式系统和AI驱动分析领域的研究人员提供了战略路线图。 <div>
arXiv:2502.17307v1 Announce Type: new 
Abstract: Strategic mining attacks, such as selfish mining, exploit blockchain consensus protocols by deviating from honest behavior to maximize rewards. Markov Decision Process (MDP) analysis faces scalability challenges in modern digital economics, including blockchain. To address these limitations, reinforcement learning (RL) provides a scalable alternative, enabling adaptive strategy optimization in complex dynamic environments.
  In this survey, we examine RL's role in strategic mining analysis, comparing it to MDP-based approaches. We begin by reviewing foundational MDP models and their limitations, before exploring RL frameworks that can learn near-optimal strategies across various protocols. Building on this analysis, we compare RL techniques and their effectiveness in deriving security thresholds, such as the minimum attacker power required for profitable attacks. Expanding the discussion further, we classify consensus protocols and propose open challenges, such as multi-agent dynamics and real-world validation.
  This survey highlights the potential of reinforcement learning (RL) to address the challenges of selfish mining, including protocol design, threat detection, and security analysis, while offering a strategic roadmap for researchers in decentralized systems and AI-driven analytics.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Turning Conversations into Workflows: A Framework to Extract and Evaluate Dialog Workflows for Service AI Agents</title>
<link>https://arxiv.org/abs/2502.17321</link>
<guid>https://arxiv.org/abs/2502.17321</guid>
<content:encoded><![CDATA[
<div> 关键词：自动服务代理、工作流提取、对话历史、问题回答链式思考、模拟框架

总结:
本文提出了一种从历史交互中提取和评估服务代理工作流的新框架。该框架包括两个关键阶段：一是基于关键程序元素选择相关对话的检索步骤；二是使用问题回答链式思考（QA-CoT）生成结构化工作流的过程。为了全面评估提取的工作流质量，文章引入了一个自动化代理和客户机器人模拟框架，以衡量其解决客户问题的有效性。实验结果表明，与基线相比，QA-CoT 技术在 ABCD 和 SynthABCD 数据集上提高了工作流提取的平均宏精度达 12.16%。此外，所提出的评价方法与人类评估紧密一致，为未来研究提供了一个可靠且可扩展的框架。 <div>
arXiv:2502.17321v1 Announce Type: new 
Abstract: Automated service agents require well-structured workflows to provide consistent and accurate responses to customer queries. However, these workflows are often undocumented, and their automatic extraction from conversations remains unexplored. In this work, we present a novel framework for extracting and evaluating dialog workflows from historical interactions. Our extraction process consists of two key stages: (1) a retrieval step to select relevant conversations based on key procedural elements, and (2) a structured workflow generation process using a question-answer-based chain-of-thought (QA-CoT) prompting. To comprehensively assess the quality of extracted workflows, we introduce an automated agent and customer bots simulation framework that measures their effectiveness in resolving customer issues. Extensive experiments on the ABCD and SynthABCD datasets demonstrate that our QA-CoT technique improves workflow extraction by 12.16\% in average macro accuracy over the baseline. Moreover, our evaluation method closely aligns with human assessments, providing a reliable and scalable framework for future research.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Coordination for Heterogeneous Non-Terrestrial Networks</title>
<link>https://arxiv.org/abs/2502.17366</link>
<guid>https://arxiv.org/abs/2502.17366</guid>
<content:encoded><![CDATA[
<div> 关键词: 非地面网络(NTN), 6G网络, 分布式学习框架, 异构NTNs, 多智能体深度强化学习(MADRL)

总结:

文章介绍了非地面网络(NTN)技术作为6G网络中的关键使能技术，包括无人机、高海拔平台和卫星等组成部分。NTN各平台的独特特性对设计与实施产生影响，形成动态且异构的网络结构。针对不同层级如空间层中基于低地球轨道(LEO)、中地球轨道(MEO)和地球静止轨道(GEO)的不同NTN发展，文章强调了异构NTNs间的分布式协调仍是重要挑战。虽然分布式学习框架有广泛应用，但针对异构NTN中各层次所面临的通信挑战及其相应的协调解决方案的系统分析尚未展开。本文首先总结了各个NTN平台的独特特性以及对其设计和实施的影响；接着，辨识了异构NTNs在个体层次上的通信挑战，并提出了潜在的协调解决方案；进一步阐述了适用于异构NTNs协调解决方案的多智能体深度强化学习(MADRL)算法；最后，通过一个基于异构无人机蜂窝网络的用户调度优化问题的案例研究，利用多智能体确定性策略梯度(MADDPG)技术验证了分布式协调在异构NTNs中的有效性。 <div>
arXiv:2502.17366v1 Announce Type: new 
Abstract: To guarantee global coverage and ubiquitous connectivity, the Non-terrestrial Network (NTN) technology has been regarded as a key enabling technology in the Six Generation (6G) network, which consists of the unmanned aerial vehicle (UAV), high-altitude platform (HAP), and satellite. It is noted that the unique characteristics of various NTN platforms directly impact the design and implementation of NTNs, which results in highly dynamic and heterogeneous networks. Even within the same tier, such as the space tier, the NTNs are developed based on different platforms including Low Earth Orbit (LEO), Medium Earth Orbit (MEO), and Geostationary Earth Orbit (GEO). Therefore, distributed coordination among heterogeneous NTNs remains an important challenge. Although distributed learning framework finds a wide range of applications by leveraging rich distributed data and computation resources. The explicit and systematic analysis of the individual layers' challenges, and corresponding distributed coordination solutions in heterogeneous NTNs has not been proposed yet. In this article, we first summarize the unique characteristics of each NTN platform, and analyze the corresponding impact on the design and implementation of the NTN. We then identify the communication challenges of heterogeneous NTNs in individual layers, where the potential coordinated solutions are identified. We further illustrate the multi-agent deep reinforcement learning (MADRL) algorithms tailored for coordinated solutions in heterogeneous NTNs. Last but not least, we present a case study of the user scheduling optimization problem in heterogeneous UAVs-based cellular networks, where the multi-agent deep deterministic policy gradient (MADDPG) technique is developed to validate the effectiveness of distributed coordination in heterogeneous NTNs.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graph-Guided Scene Reconstruction from Images with 3D Gaussian Splatting</title>
<link>https://arxiv.org/abs/2502.17377</link>
<guid>https://arxiv.org/abs/2502.17377</guid>
<content:encoded><![CDATA[
<div> 关键词：图像重建、3D场景重建、图引导、相机图、高保真

总结：
本文提出了一种名为GraphGS的新型图引导三维场景重建框架，旨在解决从图像中重建高质量、大范围开放场景的挑战。该框架首先设计了一种基于空间先验的场景结构估计方法，用于创建包含相机拓扑信息的相机图。接着，将图引导的多视图一致性约束和自适应采样策略应用于3D高斯插值优化过程中，有效缓解了高斯点对特定稀疏视角过拟合的问题并加速了重建过程。通过多个数据集的定量和定性评估，GraphGS显示出了先进的性能，实现了高保真的图像三维重建。项目页面：https://3dagentworld.github.io/graphgs。<br /><br /> <div>
arXiv:2502.17377v1 Announce Type: new 
Abstract: This paper investigates an open research challenge of reconstructing high-quality, large 3D open scenes from images. It is observed existing methods have various limitations, such as requiring precise camera poses for input and dense viewpoints for supervision. To perform effective and efficient 3D scene reconstruction, we propose a novel graph-guided 3D scene reconstruction framework, GraphGS. Specifically, given a set of images captured by RGB cameras on a scene, we first design a spatial prior-based scene structure estimation method. This is then used to create a camera graph that includes information about the camera topology. Further, we propose to apply the graph-guided multi-view consistency constraint and adaptive sampling strategy to the 3D Gaussian Splatting optimization process. This greatly alleviates the issue of Gaussian points overfitting to specific sparse viewpoints and expedites the 3D reconstruction process. We demonstrate GraphGS achieves high-fidelity 3D reconstruction from images, which presents state-of-the-art performance through quantitative and qualitative evaluation across multiple datasets. Project Page: https://3dagentworld.github.io/graphgs.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Position: Standard Benchmarks Fail -- LLM Agents Present Overlooked Risks for Financial Applications</title>
<link>https://arxiv.org/abs/2502.15865</link>
<guid>https://arxiv.org/abs/2502.15865</guid>
<content:encoded><![CDATA[
<div> 关键词: 金融LLM代理、基准测试、安全风险、评估指标、Safety-Aware Evaluation Agent (SAEA)

总结:
本文指出现有金融领域大型语言模型（LLM）代理的基准测试存在不足，主要关注任务性能而忽视了诸如幻觉、时间错位和对抗性漏洞等基本安全性风险。作者分析了现有金融LLM代理基准存在的安全差距，并提出了十个风险意识评估指标。通过实证评估两种类型的LLM代理，他们揭示了传统评估方法未能检测到的隐藏漏洞。为推动该领域发展，文章提议采用“安全意识评价代理”(SAEA)，该代理基于三层评估框架，分别从模型层面（内在能力）、工作流层面（多步骤过程可靠性）以及系统层面（集成鲁棒性）对代理进行评估。文章强调了重新定义LLM代理评估标准的紧迫性，应将重心从单纯的性能转移到安全性、健壮性和现实世界的适应性上来。 <div>
arXiv:2502.15865v1 Announce Type: cross 
Abstract: Current financial LLM agent benchmarks are inadequate. They prioritize task performance while ignoring fundamental safety risks. Threats like hallucinations, temporal misalignment, and adversarial vulnerabilities pose systemic risks in high-stakes financial environments, yet existing evaluation frameworks fail to capture these risks. We take a firm position: traditional benchmarks are insufficient to ensure the reliability of LLM agents in finance. To address this, we analyze existing financial LLM agent benchmarks, finding safety gaps and introducing ten risk-aware evaluation metrics. Through an empirical evaluation of both API-based and open-weight LLM agents, we reveal hidden vulnerabilities that remain undetected by conventional assessments. To move the field forward, we propose the Safety-Aware Evaluation Agent (SAEA), grounded in a three-level evaluation framework that assesses agents at the model level (intrinsic capabilities), workflow level (multi-step process reliability), and system level (integration robustness). Our findings highlight the urgent need to redefine LLM agent evaluation standards by shifting the focus from raw performance to safety, robustness, and real world resilience.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Statistical Inference in Reinforcement Learning: A Selective Survey</title>
<link>https://arxiv.org/abs/2502.16195</link>
<guid>https://arxiv.org/abs/2502.16195</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning)，医疗保健，共享出行平台，统计推断，机器学习

总结:
这篇论文主要介绍了强化学习（RL）在诸如医疗保健和共享出行平台等领域中的应用，并指出尽管过去十年RL已成为机器学习领域的研究热点，但统计学作为一门学科才开始深度和广泛地与RL相结合。文章重点回顾了RL中的统计推断工具，包括假设检验和置信区间构建，旨在向统计学和机器学习社区强调统计推断在RL中的价值，并推动经典统计推断工具在这一研究领域的更广泛应用。 <div>
arXiv:2502.16195v1 Announce Type: cross 
Abstract: Reinforcement learning (RL) is concerned with how intelligence agents take actions in a given environment to maximize the cumulative reward they receive. In healthcare, applying RL algorithms could assist patients in improving their health status. In ride-sharing platforms, applying RL algorithms could increase drivers' income and customer satisfaction. Over the past decade, RL has been arguably one of the most vibrant research frontiers in machine learning. Nevertheless, statistics as a field, as opposed to computer science, has only recently begun to engage with RL both in depth and in breadth. This paper present a selective review of statistical inferential tools for RL, covering both hypothesis testing and confidence interval construction. Our goal is to highlight the value of statistical inference in RL for both the statistics and machine learning communities, and to promote the broader application of classical statistical inference tools in this vibrant area of research.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Brain-Model Evaluations Need the NeuroAI Turing Test</title>
<link>https://arxiv.org/abs/2502.16238</link>
<guid>https://arxiv.org/abs/2502.16238</guid>
<content:encoded><![CDATA[
<div> 关键词：人工系统、智能模型、图灵测试、神经AI、内部表征

总结:
该文探讨了人工智能系统作为智慧模型的标准问题，指出传统的图灵测试仅关注行为相似性不足以充分评估神经AI。文章提出了一种增强版的“神经AI图灵测试”框架，这个新基准不仅要求模型的行为与人类难以区分，还要求模型的内部神经表征需与生物大脑的实际活动达到可测量的个体差异范围内的等价性，即模型与大脑之间的差异不应超过人脑间的自然差异。鉴于大脑被认为是唯一普遍认可的智慧参照物，这一新框架旨在引导研究从模糊的大脑启发概念转向一个以行为和内部表征双重标准为核心的系统化、可测试的基准，为神经科学研究和AI发展提供明确的评价依据。 <div>
arXiv:2502.16238v1 Announce Type: cross 
Abstract: What makes an artificial system a good model of intelligence? The classical test proposed by Alan Turing focuses on behavior, requiring that an artificial agent's behavior be indistinguishable from that of a human. While behavioral similarity provides a strong starting point, two systems with very different internal representations can produce the same outputs. Thus, in modeling biological intelligence, the field of NeuroAI often aims to go beyond behavioral similarity and achieve representational convergence between a model's activations and the measured activity of a biological system. This position paper argues that the standard definition of the Turing Test is incomplete for NeuroAI, and proposes a stronger framework called the ``NeuroAI Turing Test'', a benchmark that extends beyond behavior alone and \emph{additionally} requires models to produce internal neural representations that are empirically indistinguishable from those of a brain up to measured individual variability, i.e. the differences between a computational model and the brain is no more than the difference between one brain and another brain. While the brain is not necessarily the ceiling of intelligence, it remains the only universally agreed-upon example, making it a natural reference point for evaluating computational models. By proposing this framework, we aim to shift the discourse from loosely defined notions of brain inspiration to a systematic and testable standard centered on both behavior and internal representations, providing a clear benchmark for neuroscientific modeling and AI development.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep-reinforcement-learning-based separation control in a two-dimensional airfoil</title>
<link>https://arxiv.org/abs/2502.16993</link>
<guid>https://arxiv.org/abs/2502.16993</guid>
<content:encoded><![CDATA[
<div> 关键词: active-flow-control (AFC), deep-reinforcement-learning (DRL), NACA 0012空气翼型, 雷诺数, 拖力减少

总结:

本文旨在探索适用于两维NACA 0012翼型在雷诺数为3000条件下的新型主动流动控制(AFC)技术以减小分离。研究采用深度强化学习(DRL)框架确定施加于流场的动作策略，这些动作涉及在翼型表面通过喷气实现吹吸控制。流动使用低耗散有限元代码Alya进行模拟，并在高性能计算系统上运行。通过DRL得到的各种控制策略实现了高达43.9%的拖力减少或提高了58.6%的空气动力效率。相比之下，周期性控制策略表现出较低的能量效率，未能达到与DRL方法相当的空气动力学改善水平。这些增益是通过在翼型上实施动态、闭环、时间依赖的主动控制机制来实现的。 <div>
arXiv:2502.16993v1 Announce Type: cross 
Abstract: The aim of this study is to discover new active-flow-control (AFC) techniques for separation mitigation in a two-dimensional NACA 0012 airfoil at a Reynolds number of 3000. To find these AFC strategies, a framework consisting of a deep-reinforcement-learning (DRL) agent has been used to determine the action strategies to apply to the flow. The actions involve blowing and suction through jets at the airfoil surface. The flow is simulated with the numerical code Alya, which is a low-dissipation finite-element code, on a high-performance computing system. Various control strategies obtained through DRL led to 43.9% drag reduction, while others yielded an increase in aerodynamic efficiency of 58.6%. In comparison, periodic-control strategies demonstrated lower energy efficiency while failing to achieve the same level of aerodynamic improvements as the DRL-based approach. These gains have been attained through the implementation of a dynamic, closed-loop, time-dependent, active control mechanism over the airfoil.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Competitive Information Design for Pandora's Box</title>
<link>https://arxiv.org/abs/2103.03769</link>
<guid>https://arxiv.org/abs/2103.03769</guid>
<content:encoded><![CDATA[
<div> 关键词：Pandora's Box问题、战略信息设计、竞争性信息揭示、纳什均衡、搜索策略

<br /><br />总结：
本文研究了与经典的Pandora's Box问题相结合的一个自然的竞争性信息设计战略变体。在这个变体中，每个盒子都关联着一个能够设计关于盒子奖品价值信息披露策略的战略性信息发送者。文章主要贡献包括三个方面：(1) 在给定盒子信息披露政策的情况下，刻画了代理人的最优搜索和停止策略；(2) 完全刻画了在对称环境下的盒子间信息揭示游戏的纯策略对称均衡；(3) 揭示了信息竞争在均衡状态下对代理人支付的影响以及由此产生的代理人收益，并进一步研究了Pandora's Box的信息特性，通过建立盒子价值分布的可传递性和搜索代理人效用顺序之间的内在联系，探讨了信息的价值。 <div>
arXiv:2103.03769v4 Announce Type: replace 
Abstract: We study a natural competitive-information-design strategic variant for the celebrated Pandora's Box problem (Weitzman, 1979), where each box is associated with a strategic information sender who can design what information about the box's prize value to be revealed to the agent when the agent inspects the box. This variant with strategic boxes is motivated by a wide range of real-world economic applications for Pandora's Box. Our contributions are three-fold: (1) given the boxes' information policies, we characterize the agent's optimal search and stopping strategy; (2) we fully characterize the pure symmetric equilibrium for the game of boxes' competitive information revelation in a symmetric environment; and (3) we reveal various insights regarding information competition and the resultant agent payoff at equilibrium, and additionally, we study informational properties of Pandora's Box by establishing an intrinsic connection between informativeness of any box's value distribution and the utility order of the search agent.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cross-domain Random Pre-training with Prototypes for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2302.05614</link>
<guid>https://arxiv.org/abs/2302.05614</guid>
<content:encoded><![CDATA[
<div> 关键词：Cross-domain RL预训练、CRPTpro、自我监督、视觉编码器、下游任务

总结:

本文提出了一种新的高效且有效的无监督跨域强化学习（RL）预训练框架——CRPTpro。该框架旨在解决持续性视觉控制中的挑战问题。CRPTpro将数据采样与编码器预训练解耦，通过解耦随机收集方法生成适合跨域预训练的数据集。此外，它还引入了一种基于原型的新型自我监督算法，用于预训练能够在不同领域通用的有效视觉编码器。无需微调，该跨域编码器即可应用于定义在不同领域的具有挑战性的下游任务中。相较于近期先进的方法，CRPTpro在不需额外训练探索代理进行数据收集的情况下，实现了下游策略学习更好的性能，大大减轻了预训练的负担。实验在包括平衡控制、机器人移动和操作在内的八个连续视觉控制领域进行了广泛验证，CRPTpro在12个跨域下游任务中的11项上显著优于Proto-RL(C)，并且仅使用了54.5%的墙钟预训练时间。相关实现可在https://github.com/liuxin0824/CRPTpro获取。 <div>
arXiv:2302.05614v4 Announce Type: replace 
Abstract: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Unsupervised cross-domain Reinforcement Learning (RL) pre-training shows great potential for challenging continuous visual control but poses a big challenge. In this paper, we propose \textbf{C}ross-domain \textbf{R}andom \textbf{P}re-\textbf{T}raining with \textbf{pro}totypes (CRPTpro), a novel, efficient, and effective self-supervised cross-domain RL pre-training framework. CRPTpro decouples data sampling from encoder pre-training, proposing decoupled random collection to easily and quickly generate a qualified cross-domain pre-training dataset. Moreover, a novel prototypical self-supervised algorithm is proposed to pre-train an effective visual encoder that is generic across different domains. Without finetuning, the cross-domain encoder can be implemented for challenging downstream tasks defined in different domains, either seen or unseen. Compared with recent advanced methods, CRPTpro achieves better performance on downstream policy learning without extra training on exploration agents for data collection, greatly reducing the burden of pre-training. We conduct extensive experiments across eight challenging continuous visual-control domains, including balance control, robot locomotion, and manipulation. CRPTpro significantly outperforms the next best Proto-RL(C) on 11/12 cross-domain downstream tasks with only 54.5\% wall-clock pre-training time,\footnote{Implementation: https://github.com/liuxin0824/CRPTpro} exhibiting state-of-the-art pre-training performance with greatly improved pre-training efficiency.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ComSD: Balancing Behavioral Quality and Diversity in Unsupervised Skill Discovery</title>
<link>https://arxiv.org/abs/2309.17203</link>
<guid>https://arxiv.org/abs/2309.17203</guid>
<content:encoded><![CDATA[
<div> 关键词: 无监督技能发现、强化学习、状态探索、技能多样性、对比动态奖励

总结:
本文提出了一种名为“对比动态技能发现（ComSD）”的新方法，用于解决无监督技能发现中的状态探索与技能多样性平衡问题。ComSD通过引入一种新颖的内在激励机制——对比动态奖励，该机制包括促进代理人访问遥远状态以实现探索性技能获取的粒子式探索奖励，以及提升不同技能之间辨识度的对比多样性奖励。此外，还提出了一种动态权重调整机制，以在上述两种奖励间进行平衡，进一步提升了所发现技能的质量。实验和分析表明，ComSD能够在多关节机器人上生成不同探索级别的多样化行为，使其在具有挑战性的下游任务中展现出最先进的适应性能。同时，它还能在复杂的二维迷宫环境中发现可区分且具有深远探索能力的技能。 <div>
arXiv:2309.17203v3 Announce Type: replace 
Abstract: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible. Unsupervised skill discovery seeks to acquire different useful skills without extrinsic reward via unsupervised Reinforcement Learning (RL), with the discovered skills efficiently adapting to multiple downstream tasks in various ways. However, recent advanced skill discovery methods struggle to well balance state exploration and skill diversity, particularly when the potential skills are rich and hard to discern. In this paper, we propose \textbf{Co}ntrastive dyna\textbf{m}ic \textbf{S}kill \textbf{D}iscovery \textbf{(ComSD)}\footnote{Code and videos: https://github.com/liuxin0824/ComSD} which generates diverse and exploratory unsupervised skills through a novel intrinsic incentive, named contrastive dynamic reward. It contains a particle-based exploration reward to make agents access far-reaching states for exploratory skill acquisition, and a novel contrastive diversity reward to promote the discriminability between different skills. Moreover, a novel dynamic weighting mechanism between the above two rewards is proposed to balance state exploration and skill diversity, which further enhances the quality of the discovered skills. Extensive experiments and analysis demonstrate that ComSD can generate diverse behaviors at different exploratory levels for multi-joint robots, enabling state-of-the-art adaptation performance on challenging downstream tasks. It can also discover distinguishable and far-reaching exploration skills in the challenging tree-like 2D maze.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Self-Confirming Transformer for Belief-Conditioned Adaptation in Offline Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2310.04579</link>
<guid>https://arxiv.org/abs/2310.04579</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线适应性、离线强化学习、多智能体强化学习、变压器架构、自确认均衡

<br /><br />总结:
本文探讨了在多智能体强化学习（MARL）中，离线强化学习面临的在线环境与离线数据集之间的分布偏移问题，特别是在应对非站态对手时的挑战。为此，研究提出了基于变压器的自我确认变换器（SCT）方法，旨在通过自动回归训练赋予变压器模型在线适应非站态对手的能力。该方法使变压器代理在离线阶段学习预测对手行为，并在部署到在线环境中时，将这种虚构的对手游戏（信念）反馈给模型，结合其他环境信息生成后续动作。SCT的训练损失由信念一致性损失和最佳响应损失组成，前者要求信念匹配对手的实际行动，后者要求代理在信念下表现出最优行为。实验结果显示，SCT在结构化的重复囚徒困境游戏中展示了信念一致性和均衡行为，并在更复杂的多粒子环境中展现出优于先前变压器模型和离线MARL基线的表现。 <div>
arXiv:2310.04579v2 Announce Type: replace 
Abstract: Offline reinforcement learning (RL) suffers from the distribution shift between the offline dataset and the online environment. In multi-agent RL (MARL), this distribution shift may arise from the nonstationary opponents in the online testing who display distinct behaviors from those recorded in the offline dataset. Hence, the key to the broader deployment of offline MARL is the online adaptation to nonstationary opponents. Recent advances in foundation models, e.g., large language models, have demonstrated the generalization ability of the transformer, an emerging neural network architecture, in sequence modeling, of which offline RL is a special case. One naturally wonders \textit{whether offline-trained transformer-based RL policies adapt to nonstationary opponents online}. We propose a novel auto-regressive training to equip transformer agents with online adaptability based on the idea of self-augmented pre-conditioning. The transformer agent first learns offline to predict the opponent's action based on past observations. When deployed online, such a fictitious opponent play, referred to as the belief, is fed back to the transformer, together with other environmental feedback, to generate future actions conditional on the belief. Motivated by self-confirming equilibrium in game theory, the training loss consists of belief consistency loss, requiring the beliefs to match the opponent's actual actions and best response loss, mandating the agent to behave optimally under the belief. We evaluate the online adaptability of the proposed self-confirming transformer (SCT) in a structured environment, iterated prisoner's dilemma games, to demonstrate SCT's belief consistency and equilibrium behaviors as well as more involved multi-particle environments to showcase its superior performance against nonstationary opponents over prior transformers and offline MARL baselines.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MCU: An Evaluation Framework for Open-Ended Game Agents</title>
<link>https://arxiv.org/abs/2310.08367</link>
<guid>https://arxiv.org/abs/2310.08367</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、开放世界环境、Minecraft Universe (MCU)、任务评估框架、多样性挑战

<br />
总结:
本文提出了一种新的综合评价框架——Minecraft Universe (MCU)，旨在解决开放世界环境中AI代理的多元任务评估难题。MCU包含三个关键组成部分：一是由3,452个可组合的原子任务构成的集合，覆盖了11大类别和41个子类别的挑战；二是能够生成具有不同难度的无限多样化任务的任务组合机制；三是达成与人类评分91.5%一致性的通用评估框架。实验结果显示，即使是最先进的基础AI代理也难以应对日益多样和复杂的任务，这突显出MCU作为推动开放世界环境中AI代理开发进步的坚实基准的重要性。 <div>
arXiv:2310.08367v3 Announce Type: replace 
Abstract: Developing AI agents capable of interacting with open-world environments to solve diverse tasks is a compelling challenge. However, evaluating such open-ended agents remains difficult, with current benchmarks facing scalability limitations. To address this, we introduce Minecraft Universe (MCU), a comprehensive evaluation framework set within the open-world video game Minecraft. MCU incorporates three key components: (1) an expanding collection of 3,452 composable atomic tasks that encompasses 11 major categories and 41 subcategories of challenges; (2) a task composition mechanism capable of generating infinite diverse tasks with varying difficulty; and (3) a general evaluation framework that achieves 91.5% alignment with human ratings for open-ended task assessment. Empirical results reveal that even state-of-the-art foundation agents struggle with the increasing diversity and complexity of tasks. These findings highlight the necessity of MCU as a robust benchmark to drive progress in AI agent development within open-ended environments.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MacGyver: Are Large Language Models Creative Problem Solvers?</title>
<link>https://arxiv.org/abs/2311.09682</link>
<guid>https://arxiv.org/abs/2311.09682</guid>
<content:encoded><![CDATA[
<div> 关键词：LLMs、MACGYVER、问题解决能力、人类、迭代步进反思

总结:
我们研究了现代大型语言模型（LLMs）在一种新颖约束条件下的创造性问题解决能力。为此，我们创建了一个名为MACGYVER的自动生成数据集，其中包含超过1600个旨在激发创新物体使用和需要跳出框框思考的真实世界问题。我们将这些问题呈现给LLMs和人类，以比较和对比他们的解决问题的能力。MACGYVER对两组都具有挑战性，但方式独特且互补。例如，人类在熟悉的任务中表现出色，但在领域特定知识方面遇到困难，导致变异性更高；而LLMs由于接触了各种专门知识，尝试更广泛的问题，但常常因提出物理上不可行的行动而失败。最后，我们对LLMs进行了详细的错误分析，并展示了通过诸如迭代步进式反思和发散-收敛思维等新型提示技术增强其问题解决能力的潜力。这项工作（1）引入了一个关注物理推理、规划和非常规思维复杂方面的智能代理的新领域，这补充了现有的机器智能光谱；（2）为理解和评估人类与AI在受限问题解决能力方面的特点提供了洞见。 <div>
arXiv:2311.09682v4 Announce Type: replace 
Abstract: We explore the creative problem-solving capabilities of modern LLMs in a novel constrained setting. To this end, we create MACGYVER, an automatically generated dataset consisting of over 1,600 real-world problems deliberately designed to trigger innovative usage of objects and necessitate out-of-the-box thinking. We then present our collection to both LLMs and humans to compare and contrast their problem-solving abilities. MACGYVER is challenging for both groups, but in unique and complementary ways. For instance, humans excel in tasks they are familiar with but struggle with domain-specific knowledge, leading to a higher variance. In contrast, LLMs, exposed to a variety of specialized knowledge, attempt broader problems but fail by proposing physically-infeasible actions. Finally, we provide a detailed error analysis of LLMs, and demonstrate the potential of enhancing their problem-solving ability with novel prompting techniques such as iterative step-wise reflection and divergent-convergent thinking.
  This work (1) introduces a fresh arena for intelligent agents focusing on intricate aspects of physical reasoning, planning, and unconventional thinking, which supplements the existing spectrum of machine intelligence; and (2) provides insight into the constrained problem-solving capabilities of both humans and AI.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Communication-Efficient Federated Optimization over Semi-Decentralized Networks</title>
<link>https://arxiv.org/abs/2311.18787</link>
<guid>https://arxiv.org/abs/2311.18787</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模联邦学习、通信效率、 gossip通信、半分布式通信协议、PISCO算法

总结:
在大规模联邦学习和去中心化学习中，通信效率是一个主要挑战。文章关注于gossip通信，虽然它比与远程服务器通信更为成本效益，但在大型稀疏网络中可能需要更多通信轮次。为了解决这一权衡问题，研究者考察了一种半分布式通信协议，其中代理可以以概率性的方式进行代理间和代理与服务器间的通信。为此，他们设计了一个针对半分布式网络的通信效率优化算法——PISCO，该算法利用梯度跟踪技术继承了对数据异质性的鲁棒性，并允许多次局部更新以节省通信资源。文章证明了PISCO对于非凸问题的收敛率，并展示其能在代理人数量和局部更新次数方面实现线性加速。数值实验结果显示，PISCO具有出色的通信效率以及对数据异质性和各种网络拓扑结构的适应性。 <div>
arXiv:2311.18787v4 Announce Type: replace 
Abstract: In large-scale federated and decentralized learning, communication efficiency is one of the most challenging bottlenecks. While gossip communication -- where agents can exchange information with their connected neighbors -- is more cost-effective than communicating with the remote server, it often requires a greater number of communication rounds, especially for large and sparse networks. To tackle the trade-off, we examine the communication efficiency under a semi-decentralized communication protocol, in which agents can perform both agent-to-agent and agent-to-server communication in a probabilistic manner. We design a tailored communication-efficient algorithm over semi-decentralized networks, referred to as PISCO, which inherits the robustness to data heterogeneity thanks to gradient tracking and allows multiple local updates for saving communication. We establish the convergence rate of PISCO for nonconvex problems and show that PISCO enjoys a linear speedup in terms of the number of agents and local updates. Our numerical results highlight the superior communication efficiency of PISCO and its resilience to data heterogeneity and various network topologies.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Institutional Platform for Secure Self-Service Large Language Model Exploration</title>
<link>https://arxiv.org/abs/2402.00913</link>
<guid>https://arxiv.org/abs/2402.00913</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2402.00913v3, 用户友好的平台, 大规模定制语言模型, 多-LoRA推理, 安全隔离

总结:
本文介绍了由肯塔基大学应用人工智能中心开发的一个用户友好的平台，该平台旨在使大规模定制语言模型（LLMs）更易于访问。通过利用多-LoRA推断技术的最新进展，系统能够有效地支持不同用户的自定义适配器。文章概述了系统的架构和关键特性，包括数据集整理、模型训练、安全推理以及基于文本的特征提取。此外，文中展示了如何使用代理方法建立租户感知的计算网络，将孤立资源的安全利用组合成统一系统。该平台着重提供具有过程和数据隔离、端到端加密及角色基础资源认证的安全 LLM 服务。这一贡献与推动简化对前沿 AI 模型和技术访问的目标相一致，以支持科学发现。 <div>
arXiv:2402.00913v3 Announce Type: replace 
Abstract: This paper introduces a user-friendly platform developed by the University of Kentucky Center for Applied AI, designed to make large, customized language models (LLMs) more accessible. By capitalizing on recent advancements in multi-LoRA inference, the system efficiently accommodates custom adapters for a diverse range of users and projects. The paper outlines the system's architecture and key features, encompassing dataset curation, model training, secure inference, and text-based feature extraction.
  We illustrate the establishment of a tenant-aware computational network using agent-based methods, securely utilizing islands of isolated resources as a unified system. The platform strives to deliver secure LLM services, emphasizing process and data isolation, end-to-end encryption, and role-based resource authentication. This contribution aligns with the overarching goal of enabling simplified access to cutting-edge AI models and technology in support of scientific discovery.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Defending Jailbreak Prompts via In-Context Adversarial Game</title>
<link>https://arxiv.org/abs/2402.13148</link>
<guid>https://arxiv.org/abs/2402.13148</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型 (LLMs)、安全性、对抗性攻击、In-Context Adversarial Game (ICAG)、防御机制

总结:<br />
本文关注大规模语言模型（LLMs）的安全性问题，特别是针对越狱攻击的脆弱性。为解决这一问题，文章提出了一种无需微调的防御方法——In-Context Adversarial Game (ICAG)，它借鉴了深度学习中的对抗训练和LLM代理学习过程。ICAG通过代理学习进行对抗游戏，旨在动态扩展知识以防御越狱攻击。与依赖静态数据集的传统方法不同，ICAG采用迭代过程来增强防守和攻击代理的能力，从而不断提升对新生成越狱提示的防御能力。实验结果显示，应用了ICAG的LLMs显著降低了越狱成功的概率，并且ICAG展示出了良好的转移性，可应用于其他LLMs，展现出其作为通用防御机制的潜力。 <div>
arXiv:2402.13148v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate remarkable capabilities across diverse applications. However, concerns regarding their security, particularly the vulnerability to jailbreak attacks, persist. Drawing inspiration from adversarial training in deep learning and LLM agent learning processes, we introduce the In-Context Adversarial Game (ICAG) for defending against jailbreaks without the need for fine-tuning. ICAG leverages agent learning to conduct an adversarial game, aiming to dynamically extend knowledge to defend against jailbreaks. Unlike traditional methods that rely on static datasets, ICAG employs an iterative process to enhance both the defense and attack agents. This continuous improvement process strengthens defenses against newly generated jailbreak prompts. Our empirical studies affirm ICAG's efficacy, where LLMs safeguarded by ICAG exhibit significantly reduced jailbreak success rates across various attack scenarios. Moreover, ICAG demonstrates remarkable transferability to other LLMs, indicating its potential as a versatile defense mechanism.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>KnowAgent: Knowledge-Augmented Planning for LLM-Based Agents</title>
<link>https://arxiv.org/abs/2403.03101</link>
<guid>https://arxiv.org/abs/2403.03101</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、行动知识、KnowAgent、规划性能、环境交互

总结:
本文提出了一种名为KnowAgent的新方法，旨在通过引入明确的动作知识来增强大型语言模型（LLMs）的规划能力。KnowAgent利用动作知识库和知识性自学习策略，在规划过程中约束行动路径，从而更好地引导任务解决过程中的轨迹合成，提升语言代理的规划性能。实验结果表明，在HotpotQA和ALFWorld等基于不同后端模型的任务上，KnowAgent的表现可与现有基线相媲美或更优，并且有效缓解了规划幻觉问题。相关代码已在https://github.com/zjunlp/KnowAgent中发布。 <div>
arXiv:2403.03101v3 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated great potential in complex reasoning tasks, yet they fall short when tackling more sophisticated challenges, especially when interacting with environments through generating executable actions. This inadequacy primarily stems from the lack of built-in action knowledge in language agents, which fails to effectively guide the planning trajectories during task solving and results in planning hallucination. To address this issue, we introduce KnowAgent, a novel approach designed to enhance the planning capabilities of LLMs by incorporating explicit action knowledge. Specifically, KnowAgent employs an action knowledge base and a knowledgeable self-learning strategy to constrain the action path during planning, enabling more reasonable trajectory synthesis, and thereby enhancing the planning performance of language agents. Experimental results on HotpotQA and ALFWorld based on various backbone models demonstrate that KnowAgent can achieve comparable or superior performance to existing baselines. Further analysis indicates the effectiveness of KnowAgent in terms of planning hallucinations mitigation. Code is available in https://github.com/zjunlp/KnowAgent.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Tur[k]ingBench: A Challenge Benchmark for Web Agents</title>
<link>https://arxiv.org/abs/2403.11905</link>
<guid>https://arxiv.org/abs/2403.11905</guid>
<content:encoded><![CDATA[
<div> 关键词: TurkingBench、多模态模型、复杂web任务、基准测试、GPT4

总结:<br />
本文介绍了TurkingBench，这是一个针对复杂网络任务的多模态模型基准测试平台。该平台使用真实的、原本为众包工作者设计的HTML网页来构建多样化的任务实例，共计包含32.2K个实例和158个任务。为了评估该基准测试的有效性，作者开发了一个框架，将聊天机器人响应与网页上的动作（如修改文本框或选择单选按钮）关联起来。文章中对比了包括GPT4和InternVL在内的先进私有和开源语言仅及视觉-语言模型在这一基准上的表现，结果显示虽然这些模型优于随机选择，但仍存在显著改进空间。作者期望这个基准能推动基于网络的智能代理在评估和发展方面的进步。 <div>
arXiv:2403.11905v4 Announce Type: replace 
Abstract: Can advanced multi-modal models effectively tackle complex web-based tasks? Such tasks are often found on crowdsourcing platforms, where crowdworkers engage in challenging micro-tasks within web-based environments.
  Building on this idea, we present TurkingBench, a benchmark consisting of tasks presented as web pages with textual instructions and multi-modal contexts. Unlike previous approaches that rely on artificially synthesized web pages, our benchmark uses natural HTML pages originally designed for crowdsourcing workers to perform various annotation tasks. Each task's HTML instructions are instantiated with different values derived from crowdsourcing tasks, creating diverse instances. This benchmark includes 32.2K instances spread across 158 tasks.
  To support the evaluation of TurkingBench, we have developed a framework that links chatbot responses to actions on web pages (e.g., modifying a text box, selecting a radio button). We assess the performance of cutting-edge private and open-source models, including language-only and vision-language models (such as GPT4 and InternVL), on this benchmark. Our results show that while these models outperform random chance, there is still significant room for improvement. We hope that this benchmark will drive progress in the evaluation and development of web-based agents.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentFL: Scaling LLM-based Fault Localization to Project-Level Context</title>
<link>https://arxiv.org/abs/2403.16362</link>
<guid>https://arxiv.org/abs/2403.16362</guid>
<content:encoded><![CDATA[
<div> 关键词：Fault Localization (FL)，Large Language Models (LLMs)，AgentFL，ChatGPT，Defects4J-V1.2.0

总结:
本文提出了一种基于ChatGPT的多代理系统AgentFL，用于自动化大规模代码范围内的故障定位。针对LLMs处理长上下文能力有限的问题，AgentFL将故障定位任务模拟为理解、导航和确认三个步骤，并在每个步骤中雇佣具有不同专长的代理来执行特定任务。为了应对每个步骤中的挑战，采取了诸如测试行为跟踪、文档引导搜索和多轮对话等辅助策略。实验结果表明，AgentFL在Defects4J-V1.2.0基准上成功地在Top-1中定位了395个bug中的157个，优于其他基于LLM的方法并表现出对最先进的学习技术的补充性。此外，通过消融研究证实了AgentFL组件的重要性，并通过用户研究展示了其可用性。最后的成本分析显示，AgentFL平均只需花费0.074美元和97秒就能完成单个bug的故障定位。 <div>
arXiv:2403.16362v2 Announce Type: replace 
Abstract: Fault Localization (FL) is an essential step during the debugging process. With the strong capabilities of code comprehension, the recent Large Language Models (LLMs) have demonstrated promising performance in diagnosing bugs in the code. Nevertheless, due to LLMs' limited performance in handling long contexts, existing LLM-based fault localization remains on localizing bugs within a small code scope (i.e., a method or a class), which struggles to diagnose bugs for a large code scope (i.e., an entire software system). To address the limitation, this paper presents AgentFL, a multi-agent system based on ChatGPT for automated fault localization. By simulating the behavior of a human developer, AgentFL models the FL task as a three-step process, which involves comprehension, navigation, and confirmation. Within each step, AgentFL hires agents with diversified expertise, each of which utilizes different tools to handle specific tasks. Particularly, we adopt a series of auxiliary strategies such as Test Behavior Tracking, Document-Guided Search, and Multi-Round Dialogue to overcome the challenges in each step. The evaluation on the widely used Defects4J-V1.2.0 benchmark shows that AgentFL can localize 157 out of 395 bugs within Top-1, which outperforms the other LLM-based approaches and exhibits complementarity to the state-of-the-art learning-based techniques. Additionally, we confirm the indispensability of the components in AgentFL with the ablation study and demonstrate the usability of AgentFL through a user study. Finally, the cost analysis shows that AgentFL spends an average of only 0.074 dollars and 97 seconds for a single bug.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Novel Convex Layers Strategy for Circular Formation in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2404.11351</link>
<guid>https://arxiv.org/abs/2404.11351</guid>
<content:encoded><![CDATA[
<div> 关键词：冲突避免、分布式部署、圆形边界、凸层、搜索空间

总结:
本文提出了一种解决点状代理在覆盖所有代理的圆形周边上冲突避免分布的问题。该方法的关键要素包括使用代理人初始位置构建的一组凸层层（嵌套凸多边形）以及为每个代理人定义的一种新的搜索空间区域。代理人的搜索空间被定义为其位置与支持边垂直相交的线之间的区域。通过设计一种目标分配策略，能够在初始化时就为每个代理分配一个位于其搜索空间内的唯一目标位置，之后无需进一步计算。与现有文献相比，本文提出了一种仅利用代理人初始位置的、一次性、无碰撞的圆形分布解决方案。文中通过示例证明了所提策略的有效性。<br /><br /> <div>
arXiv:2404.11351v3 Announce Type: replace 
Abstract: This article considers the problem of conflict-free distribution of point-sized agents on a circular periphery encompassing all agents. The two key elements of the proposed policy include the construction of a set of convex layers (nested convex polygons) using the initial positions of the agents, and a novel search space region for each of the agents. The search space for an agent on a convex layer is defined as the region enclosed between the lines passing through the agent's position and normal to its supporting edges. Guaranteeing collision-free paths, a goal assignment policy designates a unique goal position within the search space of an agent at the initial time itself, requiring no further computation thereafter. In contrast to the existing literature, this work presents a one-shot, collision-free solution to the circular distribution problem by utilizing only the initial positions of the agents. Illustrative examples demonstrate the effectiveness of the proposed policy.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Anywhere: A Multi-Agent Framework for User-Guided, Reliable, and Diverse Foreground-Conditioned Image Generation</title>
<link>https://arxiv.org/abs/2404.18598</link>
<guid>https://arxiv.org/abs/2404.18598</guid>
<content:encoded><![CDATA[
<div> 关键词: 任何地方 (Anywhere)、图像生成、前景条件、多代理框架、控制灵活性

<br /><br />总结:
本文介绍了近期在图像生成领域取得的进步，特别是在前景条件下的图像生成仍面临挑战，如对象完整性受损、前后景不一致、多样性有限和控制灵活性降低等问题。针对这些问题，文章提出了一种名为“Anywhere”的多代理框架，该框架摒弃了传统的端到端方法，每个代理专注于不同的任务，如前景理解、多样性增强、物体完整性保护和文本提示一致性等。此外，Anywhere框架还支持用户可选的文本输入、自动化质量评估以及根据需要进行重生成的功能。实验结果显示，这种模块化设计有效地克服了现有端到端模型的局限性，显著提高了前景条件下图像生成的保真度、质量和多样性，并增强了可控性。同时，Anywhere框架具有可扩展性，能够从各个单个代理未来的进步中获益。 <div>
arXiv:2404.18598v2 Announce Type: replace 
Abstract: Recent advancements in image-conditioned image generation have demonstrated substantial progress. However, foreground-conditioned image generation remains underexplored, encountering challenges such as compromised object integrity, foreground-background inconsistencies, limited diversity, and reduced control flexibility. These challenges arise from current end-to-end inpainting models, which suffer from inaccurate training masks, limited foreground semantic understanding, data distribution biases, and inherent interference between visual and textual prompts. To overcome these limitations, we present Anywhere, a multi-agent framework that departs from the traditional end-to-end approach. In this framework, each agent is specialized in a distinct aspect, such as foreground understanding, diversity enhancement, object integrity protection, and textual prompt consistency. Our framework is further enhanced with the ability to incorporate optional user textual inputs, perform automated quality assessments, and initiate re-generation as needed. Comprehensive experiments demonstrate that this modular design effectively overcomes the limitations of existing end-to-end models, resulting in higher fidelity, quality, diversity and controllability in foreground-conditioned image generation. Additionally, the Anywhere framework is extensible, allowing it to benefit from future advancements in each individual agent.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Bits and Bandits: Quantifying the Regret-Information Trade-off</title>
<link>https://arxiv.org/abs/2405.16581</link>
<guid>https://arxiv.org/abs/2405.16581</guid>
<content:encoded><![CDATA[
<div> 关键词：sequential decision problems、regret、information accumulation、Bayesian regret lower bounds、question-answering task

<br /><br />总结:
本文研究了在序列决策问题中，智能体如何在承受遗憾与获取信息之间进行权衡。通过引入信息论方法，作者得出了考虑信息积累的后悔下界，并重新证明了一些已知的后悔下界。进一步地，他们提出了首个依赖于智能体所积累信息的贝叶斯后悔下界以及利用信息量来换取后悔减少的上界。文章还展示了这些界限在改善大型语言模型回答问题任务中的性能，并提供了有价值的见解。 <div>
arXiv:2405.16581v4 Announce Type: replace 
Abstract: In many sequential decision problems, an agent performs a repeated task. He then suffers regret and obtains information that he may use in the following rounds. However, sometimes the agent may also obtain information and avoid suffering regret by querying external sources. We study the trade-off between the information an agent accumulates and the regret it suffers. We invoke information-theoretic methods for obtaining regret lower bounds, that also allow us to easily re-derive several known lower bounds. We introduce the first Bayesian regret lower bounds that depend on the information an agent accumulates. We also prove regret upper bounds using the amount of information the agent accumulates. These bounds show that information measured in bits, can be traded off for regret, measured in reward. Finally, we demonstrate the utility of these bounds in improving the performance of a question-answering task with large language models, allowing us to obtain valuable insights.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CharacterGPT: A Persona Reconstruction Framework for Role-Playing Agents</title>
<link>https://arxiv.org/abs/2405.19778</link>
<guid>https://arxiv.org/abs/2405.19778</guid>
<content:encoded><![CDATA[
<div> 关键词: CharacterGPT、角色扮演代理、一致性、人物特质、小说章节摘要

<br /><br />总结:

本文介绍了CharacterGPT，这是一个为了解决大型语言模型（LLMs）在角色扮演代理（RPA）中维持角色人格一致性的挑战而设计的框架。CharacterGPT通过名为“Character Persona Training”（CPT）的方法，动态地利用小说章节概要来逐步更新和重构角色的人格特质，从而反映故事的发展进程。文章通过大五人格评估和创新任务对框架进行了评估，证明了CharacterGPT在保持角色人格一致性方面的有效性。相关代码和结果可在https://github.com/Jeiyoon/charactergpt获取。 <div>
arXiv:2405.19778v5 Announce Type: replace 
Abstract: The recent introduction of the Assistants API highlights its potential for large language models (LLMs) in role-playing agents (RPA). However, maintaining consistent character personas remains a significant challenge due to variability in information extraction, which frequently omits critical elements such as backstory or interpersonal relationships. To address this limitation, we introduce CharacterGPT, a framework designed to dynamically reconstruct character personas through Character Persona Training (CPT). This approach incrementally updates personas by extracting traits from chapter-wise novel summaries, reflecting the progression of the narrative. Our framework is evaluated through Big Five personality evaluations and creative tasks, in which characters generate original narratives, demonstrating the efficacy of CharacterGPT in preserving persona consistency. The code and results are available at https://github.com/Jeiyoon/charactergpt
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Direct Multi-Turn Preference Optimization for Language Agents</title>
<link>https://arxiv.org/abs/2406.14868</link>
<guid>https://arxiv.org/abs/2406.14868</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 直接偏好优化 (DPO), 强化学习 (RL), 分区函数, DMPO

总结:
这篇论文主要关注于如何将大型语言模型（LLMs）适应于代理任务，并提出了一种名为直接偏好优化（DPO）的技术，该技术能有效缓解强化学习（RL）中的累积误差问题。然而，当DPO应用于多轮对话任务时，由于无法取消分区函数而面临挑战。为了解决这一难题，文章提出了将策略约束替换为状态-动作占用度量约束，并在布拉德利-泰瑞模型中添加长度归一化，从而形成了适用于多轮代理任务的新损失函数——DMPO，并对其理论依据进行了阐述。通过在三个多轮代理任务数据集上的大量实验，验证了DMPO损失函数的有效性和优越性。相关代码已发布在https://github.com/swt-user/DMPO上。 <div>
arXiv:2406.14868v5 Announce Type: replace 
Abstract: Adapting Large Language Models (LLMs) for agent tasks is critical in developing language agents. Direct Preference Optimization (DPO) is a promising technique for this adaptation with the alleviation of compounding errors, offering a means to directly optimize Reinforcement Learning (RL) objectives. However, applying DPO to multi-turn tasks presents challenges due to the inability to cancel the partition function. Overcoming this obstacle involves making the partition function independent of the current state and addressing length disparities between preferred and dis-preferred trajectories. In this light, we replace the policy constraint with the state-action occupancy measure constraint in the RL objective and add length normalization to the Bradley-Terry model, yielding a novel loss function named DMPO for multi-turn agent tasks with theoretical explanations. Extensive experiments on three multi-turn agent task datasets confirm the effectiveness and superiority of the DMPO loss. The code is available at https://github.com/swt-user/DMPO.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChatSOP: An SOP-Guided MCTS Planning Framework for Controllable LLM Dialogue Agents</title>
<link>https://arxiv.org/abs/2407.03884</link>
<guid>https://arxiv.org/abs/2407.03884</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 对话代理, 控制性, 标准操作程序, ChatSOP

总结:
为了解决由大型语言模型驱动的对话代理在对话控制性上的不足，本文提出了一种名为ChatSOP的新方法。ChatSOP是一种基于标准操作程序（SOP）指导的蒙特卡洛树搜索（MCTS）规划框架，旨在增强对话代理的可控性。为了实现这一目标，作者构建了一个包含多场景、SOP注释的对话数据集，该数据集通过半自动的角色扮演系统利用GPT-4生成并经过严格的手动质量控制进行验证。此外，文章还提出了将Chain of Thought推理与监督微调相结合的方法用于SOP预测，并利用SOP引导的MCTS进行对话中的最优动作规划。实验结果显示，相比于基于GPT-3.5的基线模型，这种方法在行动准确性上提高了27.95%，并在开源模型上也显示出了显著提升。所涉及的数据集和代码已公开可用。<br /><br /> <div>
arXiv:2407.03884v3 Announce Type: replace 
Abstract: Dialogue agents powered by Large Language Models (LLMs) show superior performance in various tasks. Despite the better user understanding and human-like responses, their lack of controllability remains a key challenge, often leading to unfocused conversations or task failure. To address this, we introduce Standard Operating Procedure (SOP) to regulate dialogue flow. Specifically, we propose ChatSOP, a novel SOP-guided Monte Carlo Tree Search (MCTS) planning framework designed to enhance the controllability of LLM-driven dialogue agents. To enable this, we curate a dataset comprising SOP-annotated multi-scenario dialogues, generated using a semi-automated role-playing system with GPT-4o and validated through strict manual quality control. Additionally, we propose a novel method that integrates Chain of Thought reasoning with supervised fine-tuning for SOP prediction and utilizes SOP-guided Monte Carlo Tree Search for optimal action planning during dialogues. Experimental results demonstrate the effectiveness of our method, such as achieving a 27.95% improvement in action accuracy compared to baseline models based on GPT-3.5 and also showing notable gains for open-source models. Dataset and codes are publicly available.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DebUnc: Improving Large Language Model Agent Communication With Uncertainty Metrics</title>
<link>https://arxiv.org/abs/2407.06426</link>
<guid>https://arxiv.org/abs/2407.06426</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-agent debates, LLMs, DebUnc, uncertainty metrics, attention mechanism

总结:
本文提出了一种名为DebUnc的多代理辩论框架，旨在通过引入不确定度度量来提高大型语言模型（LLMs）的准确性。该框架着重解决了现有模型常常生成错误但听起来自信的回答的问题，这主要是因为模型未充分考虑其同伴的置信度。DebUnc通过修改注意力机制调整令牌权重或通过文本提示来传达置信度。评估结果显示，基于注意力的方法特别有效，且随着不确定性估计的可靠性增强，性能持续提升。相关代码已开源，可在https://github.com/lukeyoffe/debunc获取。 <div>
arXiv:2407.06426v2 Announce Type: replace 
Abstract: Multi-agent debates have been introduced to improve the accuracy of Large Language Models (LLMs) by having multiple agents discuss solutions to a problem over several rounds of debate. However, models often generate incorrect yet confident-sounding responses, which can mislead others. This issue arises partly because agents do not consider how confident their peers are. To address this, we propose DebUnc, a debate framework that uses uncertainty metrics to assess agent confidence. Confidence is then conveyed through a modified attention mechanism that adjusts token weights, or through textual prompts. Evaluations across benchmarks show that attention-based methods are particularly effective and that performance continues to improve as uncertainty estimation becomes more reliable. The code is available at https://github.com/lukeyoffe/debunc.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Co-Optimization Compiler: Leveraging Multi-Agent Reinforcement Learning for Enhanced DNN Accelerator Performance</title>
<link>https://arxiv.org/abs/2407.08192</link>
<guid>https://arxiv.org/abs/2407.08192</guid>
<content:encoded><![CDATA[
<div> 关键词：Dynamic Co-Optimization Compiler (DCOC)，Multi-Agent Reinforcement Learning (MARL)，Deep Neural Networks (DNNs)，hardware/software co-optimization，性能优化

<br /><br />总结:
本文介绍了采用自适应多智能体强化学习框架的新型动态协同优化编译器(DCOC)，该框架针对机器学习模型（特别是深度神经网络DNNs）在多样化硬件平台上的映射效率进行了增强。DCOC内部集成了三个专门的actor-critic代理，分别负责不同的优化方面：一个关注硬件，两个关注软件。这种合作策略实现了软硬件一体化协同优化，提升了DNN部署的精度和速度。通过聚焦高置信度配置，DCOC有效地缩小了搜索空间，相比于现有方法，在各种DNN模型上最高可提升吞吐量达37.95%，并能将优化时间减少高达42.2%，表现出优于当前最优框架的性能。 <div>
arXiv:2407.08192v3 Announce Type: replace 
Abstract: This paper introduces a novel Dynamic Co-Optimization Compiler (DCOC), which employs an adaptive Multi-Agent Reinforcement Learning (MARL) framework to enhance the efficiency of mapping machine learning (ML) models, particularly Deep Neural Networks (DNNs), onto diverse hardware platforms. DCOC incorporates three specialized actor-critic agents within MARL, each dedicated to different optimization facets: one for hardware and two for software. This cooperative strategy results in an integrated hardware/software co-optimization approach, improving the precision and speed of DNN deployments. By focusing on high-confidence configurations, DCOC effectively reduces the search space, achieving remarkable performance over existing methods. Our results demonstrate that DCOC enhances throughput by up to 37.95% while reducing optimization time by up to 42.2% across various DNN models, outperforming current state-of-the-art frameworks.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Random Latent Exploration for Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2407.13755</link>
<guid>https://arxiv.org/abs/2407.13755</guid>
<content:encoded><![CDATA[
<div> 关键词：Random Latent Exploration (RLE)，强化学习(RL)，探索策略，噪声基方法，奖励基探索

<br />
总结:
本文提出了随机潜空间探索(RLE)——一种简单而有效的强化学习(RL)中的探索策略。RLE平均表现优于基于噪声的方法（即对智能体动作进行扰动）和基于奖励的探索（即奖励智能体尝试新颖行为）。RLE的核心思想是通过在潜空间中追求随机采样的目标来鼓励智能体探索环境的不同部分。它具有与噪声基方法类似的简单性，避免了复杂的奖励计算，同时保持了深度探索的益处，类似于奖励基方法。实验表明，RLE在离散任务（如Atari游戏）和连续控制任务（如Isaac Gym）上平均提高了性能，增强了探索能力，同时作为现有RL算法的一个简单通用插件易于实现。 <div>
arXiv:2407.13755v2 Announce Type: replace 
Abstract: We introduce Random Latent Exploration (RLE), a simple yet effective exploration strategy in reinforcement learning (RL). On average, RLE outperforms noise-based methods, which perturb the agent's actions, and bonus-based exploration, which rewards the agent for attempting novel behaviors. The core idea of RLE is to encourage the agent to explore different parts of the environment by pursuing randomly sampled goals in a latent space. RLE is as simple as noise-based methods, as it avoids complex bonus calculations but retains the deep exploration benefits of bonus-based methods. Our experiments show that RLE improves performance on average in both discrete (e.g., Atari) and continuous control tasks (e.g., Isaac Gym), enhancing exploration while remaining a simple and general plug-in for existing RL algorithms.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Causal Discovery Using Large Language Models</title>
<link>https://arxiv.org/abs/2407.15073</link>
<guid>https://arxiv.org/abs/2407.15073</guid>
<content:encoded><![CDATA[
<div> 关键词: 引文编号：arXiv:2407.15073v3，因果发现，多智能体环境，大型语言模型，Multi-Agent Causal Discovery Framework (MAC)

<br /><br />总结:

本文提出了一个多智能体因果发现框架(MAC)，用于填补现有方法在利用结构化数据和元数据进行因果关系识别中的空白。MAC由辩论编码模块(DCM)和元辩论模块(MDM)组成。DCM中，多个智能体通过结合结构化数据和元数据进行协同讨论与编码，共同选择最合适的统计性因果发现方法，并据此生成初步的因果图。随后，通过Meta Fusion机制将因果图转化为因果元数据。MDM则进一步利用多智能体辩论框架，借助所有元数据优化因果结构。实验证明，MAC在五个数据集上优于传统的统计性因果发现方法及现有的基于大型语言模型的方法，取得了最先进的性能表现。 <div>
arXiv:2407.15073v3 Announce Type: replace 
Abstract: Causal discovery aims to identify causal relationships between variables and is a critical research area in machine learning. Traditional methods focus on statistical or machine learning algorithms to uncover causal links from structured data, often overlooking the valuable contextual information provided by metadata. Large language models (LLMs) have shown promise in creating unified causal discovery frameworks by incorporating both structured data and metadata. However, their potential in multi-agent settings remains largely unexplored. To address this gap, we introduce the Multi-Agent Causal Discovery Framework (MAC), which consists of two key modules: the Debate-Coding Module (DCM) and the Meta-Debate Module (MDM). The DCM begins with a multi-agent debating and coding process, where agents use both structured data and metadata to collaboratively select the most suitable statistical causal discovery (SCD) method. The selected SCD is then applied to the structured data to generate an initial causal graph. This causal graph is transformed into causal metadata through the Meta Fusion mechanism. With all the metadata, MDM then refines the causal structure by leveraging a multi-agent debating framework. Extensive experiments across five datasets demonstrate that MAC outperforms both traditional statistical causal discovery methods and existing LLM-based approaches, achieving state-of-the-art performance.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reset-free Reinforcement Learning with World Models</title>
<link>https://arxiv.org/abs/2408.09807</link>
<guid>https://arxiv.org/abs/2408.09807</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (RL)，模型基RL (MBRL)，重置自由，MoReFree，数据效率

总结:
本文探讨了强化学习（RL）中重置自由设置的挑战，并表明模型基RL（MBRL）方法在这种环境中具有优越性，经过简单的适应后即可超越先前的所有最佳方法，同时需要较少的人工监督。然而，作者也指出了直接扩展MBRL方法的内在局限性，并为此提出了名为MoReFree的模型基重置自由智能体，该方法通过优先处理与任务相关的状态来改进探索和策略学习，从而进一步提升性能。MoReFree在无环境奖励或演示访问的情况下，在各种重置自由任务上表现出卓越的数据效率，并显著优于那些需要监督的特权基线。研究结果表明，模型基方法对于减少RL中的人类努力具有重大潜力。<br /><br /> <div>
arXiv:2408.09807v3 Announce Type: replace 
Abstract: Reinforcement learning (RL) is an appealing paradigm for training intelligent agents, enabling policy acquisition from the agent's own autonomously acquired experience. However, the training process of RL is far from automatic, requiring extensive human effort to reset the agent and environments. To tackle the challenging reset-free setting, we first demonstrate the superiority of model-based (MB) RL methods in such setting, showing that a straightforward adaptation of MBRL can outperform all the prior state-of-the-art methods while requiring less supervision. We then identify limitations inherent to this direct extension and propose a solution called model-based reset-free (MoReFree) agent, which further enhances the performance. MoReFree adapts two key mechanisms, exploration and policy learning, to handle reset-free tasks by prioritizing task-relevant states. It exhibits superior data-efficiency across various reset-free tasks without access to environmental reward or demonstrations while significantly outperforming privileged baselines that require supervision. Our findings suggest model-based methods hold significant promise for reducing human effort in RL. Website: https://yangzhao-666.github.io/morefree
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Multi-agent Navigation with Lightweight DRL Policy</title>
<link>https://arxiv.org/abs/2408.16370</link>
<guid>https://arxiv.org/abs/2408.16370</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习(DRL), 多智能体系统, LiDAR观测, 碰撞避免, 实际应用

总结:<br />
本文提出了一种基于深度强化学习（DRL）的端到端碰撞避免策略，应用于多智能体系统中，实现在现实世界中的有效应用。该策略利用LiDAR原始观察数据计算智能体的控制命令。所提出的模型基础版本参数数量为14万，参数文件大小为3.5 MB，允许仅依靠CPU进行行动计算。文章还介绍了一个基于物理模拟器构建的多智能体训练平台，以缩小仿真与现实世界的差距。使用基于策略梯度的RL算法在密集复杂的训练环境中对策略进行训练，并引入一种新颖奖励函数来解决智能体在某些常见场景中选择次优动作的问题。虽然训练数据全部来自仿真平台，但该策略仍可以成功转移到并部署于真实世界的机器人上。最后，实验表明，该策略能有效应对故意阻碍情况并避免碰撞。项目网站可访问https://sites.google.com/view/xingrong2024efficient/%E9%A6%96%E9%A1%B5。 <div>
arXiv:2408.16370v3 Announce Type: replace 
Abstract: In this article, we present an end-to-end collision avoidance policy based on deep reinforcement learning (DRL) for multi-agent systems, demonstrating encouraging outcomes in real-world applications. In particular, our policy calculates the control commands of the agent based on the raw LiDAR observation. In addition, the number of parameters of the proposed basic model is 140,000, and the size of the parameter file is 3.5 MB, which allows the robot to calculate the actions from the CPU alone. We propose a multi-agent training platform based on a physics-based simulator to further bridge the gap between simulation and the real world. The policy is trained on a policy-gradients-based RL algorithm in a dense and messy training environment. A novel reward function is introduced to address the issue of agents choosing suboptimal actions in some common scenarios. Although the data used for training is exclusively from the simulation platform, the policy can be successfully transferred and deployed in real-world robots. Finally, our policy effectively responds to intentional obstructions and avoids collisions. The website is available at https://sites.google.com/view/xingrong2024efficient/%E9%A6%96%E9%A1%B5.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DSBench: How Far Are Data Science Agents to Becoming Data Science Experts?</title>
<link>https://arxiv.org/abs/2409.07703</link>
<guid>https://arxiv.org/abs/2409.07703</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Large Vision-Language Models (LVLMs)，DSBench，数据科学，性能评估

总结:
<br />
本文介绍了针对大型语言模型（LLMs）和大型视觉-语言模型（LVLMs）在数据科学领域应用的研究现状。现有的数据科学基准测试对于实际的数据科学任务来说仍显不足。为弥补这一差距，文章提出了一个新的全面基准测试——DSBench，它包含了源自Eloquence和Kaggle竞赛的466项数据分析任务和74项数据建模任务，提供了更贴近现实场景的挑战，如长文本上下文、多模态任务背景、处理大数据文件和多表结构以及执行端到端数据建模任务。通过评估当前最先进的LLMs、LVLMs及代理模型，研究发现它们在大多数任务上表现挣扎，最好的代理模型仅能解决34.12%的数据分析任务，与理想性能相比存在34.74%的相对性能差距。这些结果强调了未来需要在开发更为实用、智能和自主的数据科学代理方面取得更多进展。 <div>
arXiv:2409.07703v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) and Large Vision-Language Models (LVLMs) have demonstrated impressive language/vision reasoning abilities, igniting the recent trend of building agents for targeted applications such as shopping assistants or AI software engineers. Recently, many data science benchmarks have been proposed to investigate their performance in the data science domain. However, existing data science benchmarks still fall short when compared to real-world data science applications due to their simplified settings. To bridge this gap, we introduce DSBench, a comprehensive benchmark designed to evaluate data science agents with realistic tasks. This benchmark includes 466 data analysis tasks and 74 data modeling tasks, sourced from Eloquence and Kaggle competitions. DSBench offers a realistic setting by encompassing long contexts, multimodal task backgrounds, reasoning with large data files and multi-table structures, and performing end-to-end data modeling tasks. Our evaluation of state-of-the-art LLMs, LVLMs, and agents shows that they struggle with most tasks, with the best agent solving only 34.12% of data analysis tasks and achieving a 34.74% Relative Performance Gap (RPG). These findings underscore the need for further advancements in developing more practical, intelligent, and autonomous data science agents.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coevolving with the Other You: Fine-Tuning LLM with Sequential Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.06101</link>
<guid>https://arxiv.org/abs/2410.06101</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning）、大型语言模型（Large Language Models、LLMs）、CORY、多智能体协同强化学习（Sequential Cooperative Multi-Agent Reinforcement Learning）、PPO

总结:
本文提出了一种名为CORY的新方法，用于改进大型语言模型的强化学习微调。现有的RL微调主要依赖于PPO及其变体，但在LLM微调中可能会表现不佳并易发生分布塌陷。CORY将LLM的RL微调扩展到一个多智能体协同强化学习框架，利用多智能体系统的协同演化和自涌现能力。通过将待微调的LLM复制为两个自主代理——先锋和观察者，这两个代理根据查询生成响应并相互合作与演化。实验结果显示，相比于PPO，CORY在IMDB Review和GSM8K数据集上基于主观和客观奖励函数对GPT-2和Llama-2进行微调时，表现出更好的策略优化性、抗分布塌陷能力和训练稳定性，从而证明了其作为现实世界应用中LLM微调优越方法论的潜力。 <div>
arXiv:2410.06101v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) has emerged as a pivotal technique for fine-tuning large language models (LLMs) on specific tasks. However, prevailing RL fine-tuning methods predominantly rely on PPO and its variants. Though these algorithms are effective in general RL settings, they often exhibit suboptimal performance and vulnerability to distribution collapse when applied to the fine-tuning of LLMs. In this paper, we propose CORY, extending the RL fine-tuning of LLMs to a sequential cooperative multi-agent reinforcement learning framework, to leverage the inherent coevolution and emergent capabilities of multi-agent systems. In CORY, the LLM to be fine-tuned is initially duplicated into two autonomous agents: a pioneer and an observer. The pioneer generates responses based on queries, while the observer generates responses using both the queries and the pioneer's responses. The two agents are trained together. During training, the agents exchange roles periodically, fostering cooperation and coevolution between them. Experiments evaluate CORY's performance by fine-tuning GPT-2 and Llama-2 under subjective and objective reward functions on the IMDB Review and GSM8K datasets, respectively. Results show that CORY outperforms PPO in terms of policy optimality, resistance to distribution collapse, and training robustness, thereby underscoring its potential as a superior methodology for refining LLMs in real-world applications.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Benchmarking Agentic Workflow Generation</title>
<link>https://arxiv.org/abs/2410.07869</link>
<guid>https://arxiv.org/abs/2410.07869</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、工作流生成基准、评估协议、序列规划、图规划

总结:
本文介绍了大规模语言模型（LLMs）在处理复杂任务中的问题分解和执行流程方面的重要作用。针对现有工作流评价框架存在的局限性，如场景覆盖不全、流程结构简单及评价标准宽松等问题，研究者提出了一个新的统一工作流生成基准——WorfBench，它包含了多元化的场景和复杂的图形工作流结构。同时，文章还提出了一种系统性的评价协议WorfEval，利用子序列和子图匹配算法来精确量化LLM代理的工作流生成能力。通过全面评估不同类型的LLMs，发现它们在序列规划与图规划能力之间存在明显差距，即便是GPT-4也存在约15%的差距。此外，研究者训练了两个开源模型并对其在未见过的任务上的泛化能力进行了评估。最后，他们观察到生成的工作流可以提升下游任务的表现，使其在推理阶段以更短的时间实现更好的性能。相关代码和数据集可在https://github.com/zjunlp/WorfBench获取。 <div>
arXiv:2410.07869v3 Announce Type: replace 
Abstract: Large Language Models (LLMs), with their exceptional ability to handle a wide range of tasks, have driven significant advancements in tackling reasoning and planning tasks, wherein decomposing complex problems into executable workflows is a crucial step in this process. Existing workflow evaluation frameworks either focus solely on holistic performance or suffer from limitations such as restricted scenario coverage, simplistic workflow structures, and lax evaluation standards. To this end, we introduce WorfBench, a unified workflow generation benchmark with multi-faceted scenarios and intricate graph workflow structures. Additionally, we present WorfEval, a systemic evaluation protocol utilizing subsequence and subgraph matching algorithms to accurately quantify the LLM agent's workflow generation capabilities. Through comprehensive evaluations across different types of LLMs, we discover distinct gaps between the sequence planning capabilities and graph planning capabilities of LLM agents, with even GPT-4 exhibiting a gap of around 15%. We also train two open-source models and evaluate their generalization abilities on held-out tasks. Furthermore, we observe that the generated workflows can enhance downstream tasks, enabling them to achieve superior performance with less time during inference. Code and dataset are available at https://github.com/zjunlp/WorfBench.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic Information Retrieval</title>
<link>https://arxiv.org/abs/2410.09713</link>
<guid>https://arxiv.org/abs/2410.09713</guid>
<content:encoded><![CDATA[
<div> 关键词: 信息检索、下一代范式、智能代理、大型语言模型、动态信息状态

总结:
本文提出了一个新的信息检索概念——智能代理信息检索(Agentic IR)，这是一种由大型语言模型和AI代理驱动的下一代信息检索范式。与传统的依赖静态、预定义信息项的信息检索不同，Agentic IR将“信息”重新定义为动态、上下文相关的信息状态，即用户在动态环境中所处的具体信息情境，包括实时用户偏好、上下文因素及决策过程。它扩展了传统信息检索的任务，从基于查询获取相关信息项转变为根据用户指令实现目标信息状态。文章系统性地讨论了Agentic IR在任务定义、架构、评估、案例研究以及挑战与未来前景等方面的各个方面。本文认为，Agentic IR这一概念的提出不仅拓宽了信息检索研究的范围，也为构建更加适应、互动和智能的下一代信息检索奠定了基础。 <div>
arXiv:2410.09713v4 Announce Type: replace 
Abstract: Since the 1970s, information retrieval (IR) has long been defined as the process of acquiring relevant information items from a pre-defined corpus to satisfy user information needs. Traditional IR systems, while effective in domains like web search, are constrained by their reliance on static, pre-defined information items. To this end, this paper introduces agentic information retrieval (Agentic IR), a transformative next-generation paradigm for IR driven by large language models (LLMs) and AI agents. The central shift in agentic IR is the evolving definition of ``information'' from static, pre-defined information items to dynamic, context-dependent information states. Information state refers to a particular information context that the user is right in within a dynamic environment, encompassing not only the acquired information items but also real-time user preferences, contextual factors, and decision-making processes. In such a way, traditional information retrieval, focused on acquiring relevant information items based on user queries, can be naturally extended to achieving the target information state given the user instruction, which thereby defines the agentic information retrieval. We systematically discuss agentic IR from various aspects, i.e., task formulation, architecture, evaluation, case studies, as well as challenges and future prospects. We believe that the concept of agentic IR introduced in this paper not only broadens the scope of information retrieval research but also lays the foundation for a more adaptive, interactive, and intelligent next-generation IR paradigm.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SPA-Bench: A Comprehensive Benchmark for SmartPhone Agent Evaluation</title>
<link>https://arxiv.org/abs/2410.15164</link>
<guid>https://arxiv.org/abs/2410.15164</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能手机代理人、多模态大型语言模型、基准测试、交互环境、评估框架

总结:<br />
本文介绍了SPA-B ENCH，一个用于全面评估基于(M)LLM的智能手机代理性能的综合基准测试。SPA-B ENCH有三个主要贡献：1) 提供了涵盖系统和第三方应用的多样化任务集，覆盖英文和中文环境中的日常常用功能；2) 设计了一个插件式框架，支持实时交互式地将多个（超过十个）智能代理与Android设备集成，并易于添加更多代理；3) 提出了一种新颖的评价管道，能够自动从多个维度评估代理性能，包括七个与任务完成度和资源消耗相关的指标。实验结果显示了在移动用户界面解释、动作定位、内存保持及执行成本等方面的挑战，并提出了未来的研究方向以解决这些问题，旨在推动更接近现实世界的智能手机代理应用的发展。SPA-B ENCH相关资源可在https://ai-agents-2030.github.io/SPA-Bench/获取。 <div>
arXiv:2410.15164v2 Announce Type: replace 
Abstract: Smartphone agents are increasingly important for helping users control devices efficiently, with (Multimodal) Large Language Model (MLLM)-based approaches emerging as key contenders. Fairly comparing these agents is essential but challenging, requiring a varied task scope, the integration of agents with different implementations, and a generalisable evaluation pipeline to assess their strengths and weaknesses. In this paper, we present SPA-B ENCH, a comprehensive SmartPhone Agent Benchmark designed to evaluate (M)LLM-based agents in an interactive environment that simulates real-world conditions. SPA-B ENCH offers three key contributions: (1) A diverse set of tasks covering system and third-party apps in both English and Chinese, focusing on features commonly used in daily routines; (2) A plug-and-play framework enabling real-time agent interaction with Android devices, integrating over ten agents with the flexibility to add more; (3) A novel evaluation pipeline that automatically assesses agent performance across multiple dimensions, encompassing seven metrics related to task completion and resource consumption. Our extensive experiments across tasks and agents reveal challenges like interpreting mobile user interfaces, action grounding, memory retention, and execution costs. We propose future research directions to ease these difficulties, moving closer to real-world smartphone agent applications. SPA-B ENCH is available at https://ai-agents-2030.github.io/SPA-Bench/.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>GraphTeam: Facilitating Large Language Model-based Graph Analysis via Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2410.18032</link>
<guid>https://arxiv.org/abs/2410.18032</guid>
<content:encoded><![CDATA[
<div> 关键词: 图数据、LLM、图神经网络、多智能体系统、GraphTeam<br /><br />总结:
本文提出了一种名为GraphTeam的基于LLM的多智能体系统，用于图分析任务。GraphTeam针对现有LLM方法在处理图数据和利用外部知识方面的局限性，通过模拟人类解决问题的策略，如类比和协作，构建了由三个模块组成的五个LLM智能体。这些模块包括：输入输出规范化模块（问题代理和答案代理负责提取与整理问题关键参数并组织答案输出）、外部知识检索模块（搜索代理从相关文档经验库中检索最相关的信息）以及问题解决模块（编码代理结合编程算法生成解决方案，若无法编程，则由推理代理直接计算结果）。实验结果显示，GraphTeam在六个图分析基准上平均准确率提升了25.85%，达到了最先进的性能水平。项目代码和数据已在GitHub上开源，地址为https://github.com/BUPT-GAMMA/GraphTeam。 <div>
arXiv:2410.18032v4 Announce Type: replace 
Abstract: Graphs are widely used for modeling relational data in real-world scenarios, such as social networks and urban computing. Existing LLM-based graph analysis approaches either integrate graph neural networks (GNNs) for specific machine learning tasks, limiting their transferability, or rely solely on LLMs' internal reasoning ability, resulting in suboptimal performance. To address these limitations, we take advantage of recent advances in LLM-based agents, which have shown capabilities of utilizing external knowledge or tools for problem solving. By simulating human problem-solving strategies such as analogy and collaboration, we propose a multi-agent system based on LLMs named GraphTeam, for graph analysis. GraphTeam consists of five LLM-based agents from three modules, and the agents with different specialities can collaborate with each other to address complex problems. Specifically, (1) input-output normalization module: the question agent extracts and refines four key arguments from the original question, facilitating the problem understanding, and the answer agent organizes the results to meet the output requirement; (2) external knowledge retrieval module: we first build a knowledge base consisting of relevant documentation and experience information, and then the search agent retrieves the most relevant entries for each question. (3) problem-solving module: given the retrieved information from search agent, the coding agent uses established algorithms via programming to generate solutions, and in case the coding agent does not work, the reasoning agent will directly compute the results without programming. Extensive experiments on six graph analysis benchmarks demonstrate that GraphTeam achieves state-of-the-art performance with an average 25.85% improvement over the best baseline in terms of accuracy. The code and data are available at https://github.com/BUPT-GAMMA/GraphTeam.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personalized Help for Optimizing Low-Skilled Users' Strategy</title>
<link>https://arxiv.org/abs/2411.09109</link>
<guid>https://arxiv.org/abs/2411.09109</guid>
<content:encoded><![CDATA[
<div> 关键词：AIs，游戏环境，CICERO，Diplomacy，人工智能建议

<br /><br />总结:
本文研究了人工智能（AIs）在游戏环境中的辅助作用，以CICERO为例，这是一个在外交策略游戏Diplomacy中展现出超人水平的自然语言处理智能体。研究者对CICERO进行了增强，使其能够根据玩家意图生成行动和沟通建议。通过让新手和经验丰富的玩家参与带有不同建议设置的多场Diplomacy游戏，结果显示，一些生成的建议确实有益。这些建议有助于新手与经验丰富的玩家抗衡，甚至在某些情况下超越他们。而且，即使玩家不采纳建议，仅仅存在建议本身也具有优势。 <div>
arXiv:2411.09109v3 Announce Type: replace 
Abstract: AIs can beat humans in game environments; however, how helpful those agents are to human remains understudied. We augment CICERO, a natural language agent that demonstrates superhuman performance in Diplomacy, to generate both move and message advice based on player intentions. A dozen Diplomacy games with novice and experienced players, with varying advice settings, show that some of the generated advice is beneficial. It helps novices compete with experienced players and in some instances even surpass them. The mere presence of advice can be advantageous, even if players do not follow it.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Weighted Envy Freeness With Bounded Subsidies</title>
<link>https://arxiv.org/abs/2411.12696</link>
<guid>https://arxiv.org/abs/2411.12696</guid>
<content:encoded><![CDATA[
arXiv:2411.12696v4 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any other's relative to their own. In many cases, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work in the unweighted setting of subsidies relied on basic characterizations of EF that fail in the weighted settings. This makes our new setting challenging and theoretically intriguing. We present polynomial-time algorithms that compute WEF-able allocations with an upper bound on the subsidy per agent in three distinct additive valuation scenarios: (1) general, (2) identical, and (3) binary. When all weights are equal, our bounds reduce to the bounds derived in the literature for the unweighted setting.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Disk Inspection</title>
<link>https://arxiv.org/abs/2411.15391</link>
<guid>https://arxiv.org/abs/2411.15391</guid>
<content:encoded><![CDATA[
arXiv:2411.15391v2 Announce Type: replace 
Abstract: We consider $n$ unit-speed mobile agents initially positioned at the center of a unit disk, tasked with inspecting all points on the disk's perimeter. A perimeter point is considered covered if an agent positioned outside the disk's interior has unobstructed visibility of it, treating the disk itself as an obstacle. For $n=1$, this problem is referred to as the shoreline problem with a known distance. Isbell in 1957 derived an optimal trajectory that minimizes the worst-case inspection time for that problem. The one-agent version of the problem was originally proposed as a more tractable variant of Bellman's famous lost-in-the-forest problem.
  Our contributions are threefold. First, and as a warm-up, we extend Isbell's findings by deriving worst-case optimal trajectories addressing the partial inspection of a section of the disk, hence deriving an alternative proof of optimality for inspecting the disk with $n \geq 2$ agents. Second, we analyze the average-case inspection time, assuming a uniform distribution of perimeter points (equivalent to randomized inspection algorithms). Using spatial discretization and Nonlinear Programming (NLP), we propose feasible solutions to the continuous problem and evaluate their effectiveness compared to NLP solutions. Third, we establish Pareto-optimal bounds for the multi-objective problem of jointly minimizing the worst-case and average-case inspection times.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Practical Performative Policy Learning with Strategic Agents</title>
<link>https://arxiv.org/abs/2412.01344</link>
<guid>https://arxiv.org/abs/2412.01344</guid>
<content:encoded><![CDATA[
arXiv:2412.01344v3 Announce Type: replace 
Abstract: This paper studies the performative policy learning problem, where agents adjust their features in response to a released policy to improve their potential outcomes, inducing an endogenous distribution shift. There has been growing interest in training machine learning models in strategic environments, including strategic classification and performative prediction. However, existing approaches often rely on restrictive parametric assumptions: micro-level utility models in strategic classification and macro-level data distribution maps in performative prediction, severely limiting scalability and generalizability. We approach this problem as a complex causal inference task, relaxing parametric assumptions on both micro-level agent behavior and macro-level data distribution. Leveraging bounded rationality, we uncover a practical low-dimensional structure in distribution shifts and construct an effective mediator in the causal path from the deployed model to the shifted data. We then propose a gradient-based policy optimization algorithm with a differentiable classifier as a substitute for the high-dimensional distribution map. Our algorithm efficiently utilizes batch feedback and limited manipulation patterns. Our approach achieves high sample efficiency compared to methods reliant on bandit feedback or zero-order optimization. We also provide theoretical guarantees for algorithmic convergence. Extensive and challenging experiments on high-dimensional settings demonstrate our method's practical efficacy.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Comparative Analysis of Multi-Agent Reinforcement Learning Policies for Crop Planning Decision Support</title>
<link>https://arxiv.org/abs/2412.02057</link>
<guid>https://arxiv.org/abs/2412.02057</guid>
<content:encoded><![CDATA[
arXiv:2412.02057v2 Announce Type: replace 
Abstract: In India, the majority of farmers are classified as small or marginal, making their livelihoods particularly vulnerable to economic losses due to market saturation and climate risks. Effective crop planning can significantly impact their expected income, yet existing decision support systems (DSS) often provide generic recommendations that fail to account for real-time market dynamics and the interactions among multiple farmers. In this paper, we evaluate the viability of three multi-agent reinforcement learning (MARL) approaches for optimizing total farmer income and promoting fairness in crop planning: Independent Q-Learning (IQL), where each farmer acts independently without coordination, Agent-by-Agent (ABA), which sequentially optimizes each farmer's policy in relation to the others, and the Multi-agent Rollout Policy, which jointly optimizes all farmers' actions for global reward maximization. Our results demonstrate that while IQL offers computational efficiency with linear runtime, it struggles with coordination among agents, leading to lower total rewards and an unequal distribution of income. Conversely, the Multi-agent Rollout policy achieves the highest total rewards and promotes equitable income distribution among farmers but requires significantly more computational resources, making it less practical for large numbers of agents. ABA strikes a balance between runtime efficiency and reward optimization, offering reasonable total rewards with acceptable fairness and scalability. These findings highlight the importance of selecting appropriate MARL approaches in DSS to provide personalized and equitable crop planning recommendations, advancing the development of more adaptive and farmer-centric agricultural decision-making systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REGENT: A Retrieval-Augmented Generalist Agent That Can Act In-Context in New Environments</title>
<link>https://arxiv.org/abs/2412.04759</link>
<guid>https://arxiv.org/abs/2412.04759</guid>
<content:encoded><![CDATA[
arXiv:2412.04759v2 Announce Type: replace 
Abstract: Building generalist agents that can rapidly adapt to new environments is a key challenge for deploying AI in the digital and real worlds. Is scaling current agent architectures the most effective way to build generalist agents? We propose a novel approach to pre-train relatively small policies on relatively small datasets and adapt them to unseen environments via in-context learning, without any finetuning. Our key idea is that retrieval offers a powerful bias for fast adaptation. Indeed, we demonstrate that even a simple retrieval-based 1-nearest neighbor agent offers a surprisingly strong baseline for today's state-of-the-art generalist agents. From this starting point, we construct a semi-parametric agent, REGENT, that trains a transformer-based policy on sequences of queries and retrieved neighbors. REGENT can generalize to unseen robotics and game-playing environments via retrieval augmentation and in-context learning, achieving this with up to 3x fewer parameters and up to an order-of-magnitude fewer pre-training datapoints, significantly outperforming today's state-of-the-art generalist agents. Website: https://kaustubhsridhar.github.io/regent-research
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Revolutionizing QoE-Driven Network Management with Digital Agents in 6G</title>
<link>https://arxiv.org/abs/2412.14177</link>
<guid>https://arxiv.org/abs/2412.14177</guid>
<content:encoded><![CDATA[
arXiv:2412.14177v2 Announce Type: replace 
Abstract: In this article, we present a digital agent (DA)-assisted network management framework for future sixth generation (6G) networks considering user quality of experience (QoE). A novel QoE metric is defined by incorporating the impact of user behavioral dynamics and environmental complexity on quality of service (QoS). A two-level DA architecture is proposed to assist the QoE-driven network slicing and orchestration. Three potential solutions are presented from the perspectives of DA data collection, resource scheduling, and DA deployment. A case study demonstrates that the proposed framework can effectively improve user QoE compared with benchmark schemes.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentRefine: Enhancing Agent Generalization through Refinement Tuning</title>
<link>https://arxiv.org/abs/2501.01702</link>
<guid>https://arxiv.org/abs/2501.01702</guid>
<content:encoded><![CDATA[
arXiv:2501.01702v2 Announce Type: replace 
Abstract: Large Language Model (LLM) based agents have proved their ability to perform complex tasks like humans. However, there is still a large gap between open-sourced LLMs and commercial models like the GPT series. In this paper, we focus on improving the agent generalization capabilities of LLMs via instruction tuning. We first observe that the existing agent training corpus exhibits satisfactory results on held-in evaluation sets but fails to generalize to held-out sets. These agent-tuning works face severe formatting errors and are frequently stuck in the same mistake for a long while. We analyze that the poor generalization ability comes from overfitting to several manual agent environments and a lack of adaptation to new situations. They struggle with the wrong action steps and can not learn from the experience but just memorize existing observation-action relations. Inspired by the insight, we propose a novel AgentRefine framework for agent-tuning. The core idea is to enable the model to learn to correct its mistakes via observation in the trajectory. Specifically, we propose an agent synthesis framework to encompass a diverse array of environments and tasks and prompt a strong LLM to refine its error action according to the environment feedback. AgentRefine significantly outperforms state-of-the-art agent-tuning work in terms of generalization ability on diverse agent tasks. It also has better robustness facing perturbation and can generate diversified thought in inference. Our findings establish the correlation between agent generalization and self-refinement and provide a new paradigm for future research.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Flow: Modularized Agentic Workflow Automation</title>
<link>https://arxiv.org/abs/2501.07834</link>
<guid>https://arxiv.org/abs/2501.07834</guid>
<content:encoded><![CDATA[
arXiv:2501.07834v2 Announce Type: replace 
Abstract: Multi-agent frameworks powered by large language models (LLMs) have demonstrated great success in automated planning and task execution. However, the effective adjustment of agentic workflows during execution has not been well studied. An effective workflow adjustment is crucial in real-world scenarios, as the initial plan must adjust to unforeseen challenges and changing conditions in real time to ensure the efficient execution of complex tasks. In this paper, we define workflows as an activity-on-vertex (AOV) graph, which allows continuous workflow refinement by LLM agents through dynamic subtask allocation adjustment based on historical performance and previous AOVs. To further enhance framework performance, we emphasize modularity in workflow design based on evaluating parallelism and dependency complexity. With this design, our proposed multi-agent framework achieves efficient concurrent execution of subtasks, effective goal achievement, and enhanced error tolerance. Empirical results across various practical tasks demonstrate significant improvements in the efficiency of multi-agent frameworks through dynamic workflow refinement and modularization. The code is available at: https://github.com/tmllab/2025_ICLR_FLOW.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BAP v2: An Enhanced Task Framework for Instruction Following in Minecraft Dialogues</title>
<link>https://arxiv.org/abs/2501.10836</link>
<guid>https://arxiv.org/abs/2501.10836</guid>
<content:encoded><![CDATA[
arXiv:2501.10836v2 Announce Type: replace 
Abstract: Interactive agents capable of understanding and executing instructions in the physical world have long been a central goal in AI research. The Minecraft Collaborative Building Task (MCBT) provides one such setting to work towards this goal (Narayan-Chen, Jayannavar, and Hockenmaier 2019). It is a two-player game in which an Architect (A) instructs a Builder (B) to construct a target structure in a simulated Blocks World Environment. We focus on the challenging Builder Action Prediction (BAP) subtask of predicting correct action sequences in a given multimodal game context with limited training data (Jayannavar, Narayan-Chen, and Hockenmaier 2020). We take a closer look at evaluation and data for the BAP task, discovering key challenges and making significant improvements on both fronts to propose BAP v2, an upgraded version of the task. This will allow future work to make more efficient and meaningful progress on it. It comprises of: (1) an enhanced evaluation benchmark that includes a cleaner test set and fairer, more insightful metrics, and (2) additional synthetic training data generated from novel Minecraft dialogue and target structure simulators emulating the MCBT. We show that the synthetic data can be used to train more performant and robust neural models even with relatively simple training methods. Looking ahead, such data could also be crucial for training more sophisticated, data-hungry deep transformer models and training/fine-tuning increasingly large LLMs. Although modeling is not the primary focus of this work, we also illustrate the impact of our data and training methodologies on a simple LLM- and transformer-based model, thus validating the robustness of our approach, and setting the stage for more advanced architectures and LLMs going forward.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dense Fixed-Wing Swarming using Receding-Horizon NMPC</title>
<link>https://arxiv.org/abs/2502.04174</link>
<guid>https://arxiv.org/abs/2502.04174</guid>
<content:encoded><![CDATA[
arXiv:2502.04174v2 Announce Type: replace 
Abstract: In this paper, we present an approach for controlling a team of agile fixed-wing aerial vehicles in close proximity to one another. Our approach relies on receding-horizon nonlinear model predictive control (NMPC) to plan maneuvers across an expanded flight envelope to enable inter-agent collision avoidance. To facilitate robust collision avoidance and characterize the likelihood of inter-agent collisions, we compute a statistical bound on the probability of the system leaving a tube around the planned nominal trajectory. Finally, we propose a metric for evaluating highly dynamic swarms and use this metric to evaluate our approach. We successfully demonstrated our approach through both simulation and hardware experiments, and to our knowledge, this the first time close-quarters swarming has been achieved with physical aerobatic fixed-wing vehicles.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human Decision-making is Susceptible to AI-driven Manipulation</title>
<link>https://arxiv.org/abs/2502.07663</link>
<guid>https://arxiv.org/abs/2502.07663</guid>
<content:encoded><![CDATA[
arXiv:2502.07663v2 Announce Type: replace 
Abstract: Artificial Intelligence (AI) systems are increasingly intertwined with daily life, assisting users in executing various tasks and providing guidance on decision-making. This integration introduces risks of AI-driven manipulation, where such systems may exploit users' cognitive biases and emotional vulnerabilities to steer them toward harmful outcomes. Through a randomized controlled trial with 233 participants, we examined human susceptibility to such manipulation in financial (e.g., purchases) and emotional (e.g., conflict resolution) decision-making contexts. Participants interacted with one of three AI agents: a neutral agent (NA) optimizing for user benefit without explicit influence, a manipulative agent (MA) designed to covertly influence beliefs and behaviors, or a strategy-enhanced manipulative agent (SEMA) employing explicit psychological tactics to reach its hidden objectives. By analyzing participants' decision patterns and shifts in their preference ratings post-interaction, we found significant susceptibility to AI-driven manipulation. Particularly, across both decision-making domains, participants interacting with the manipulative agents shifted toward harmful options at substantially higher rates (financial, MA: 62.3%, SEMA: 59.6%; emotional, MA: 42.3%, SEMA: 41.5%) compared to the NA group (financial, 35.8%; emotional, 12.8%). Notably, our findings reveal that even subtle manipulative objectives (MA) can be as effective as employing explicit psychological strategies (SEMA) in swaying human decision-making. By revealing the potential for covert AI influence, this study highlights a critical vulnerability in human-AI interactions, emphasizing the need for ethical safeguards and regulatory frameworks to ensure responsible deployment of AI technologies and protect human autonomy.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Salience-Invariant Consistent Policy Learning for Generalization in Visual Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.08336</link>
<guid>https://arxiv.org/abs/2502.08336</guid>
<content:encoded><![CDATA[
arXiv:2502.08336v2 Announce Type: replace 
Abstract: Generalizing policies to unseen scenarios remains a critical challenge in visual reinforcement learning, where agents often overfit to the specific visual observations of the training environment. In unseen environments, distracting pixels may lead agents to extract representations containing task-irrelevant information. As a result, agents may deviate from the optimal behaviors learned during training, thereby hindering visual generalization.To address this issue, we propose the Salience-Invariant Consistent Policy Learning (SCPL) algorithm, an efficient framework for zero-shot generalization. Our approach introduces a novel value consistency module alongside a dynamics module to effectively capture task-relevant representations. The value consistency module, guided by saliency, ensures the agent focuses on task-relevant pixels in both original and perturbed observations, while the dynamics module uses augmented data to help the encoder capture dynamic- and reward-relevant representations. Additionally, our theoretical analysis highlights the importance of policy consistency for generalization. To strengthen this, we introduce a policy consistency module with a KL divergence constraint to maintain consistent policies across original and perturbed observations.Extensive experiments on the DMC-GB, Robotic Manipulation, and CARLA benchmarks demonstrate that SCPL significantly outperforms state-of-the-art methods in terms of generalization. Notably, SCPL achieves average performance improvements of 14\%, 39\%, and 69\% in the challenging DMC video hard setting, the Robotic hard setting, and the CARLA benchmark, respectively.Project Page: https://sites.google.com/view/scpl-rl.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Whoever Said Money Won't Solve All Your Problems? Weighted Envy-free Allocation with Subsidy</title>
<link>https://arxiv.org/abs/2502.09006</link>
<guid>https://arxiv.org/abs/2502.09006</guid>
<content:encoded><![CDATA[
arXiv:2502.09006v3 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any others relative to their own. Often, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work relied on characterizations of unweighted envy-freeness (EF), that fail in the weighted setting. This makes our new setting challenging. We present polynomial-time algorithms that compute WEF allocations with a guaranteed upper bound on total subsidy for monotone valuations and various subclasses thereof.
  We also present an efficient algorithm to compute a fair allocation of items and money, when the budget is not enough to make the allocation WEF. This algorithm is new even for the unweighted setting.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents</title>
<link>https://arxiv.org/abs/2502.09560</link>
<guid>https://arxiv.org/abs/2502.09560</guid>
<content:encoded><![CDATA[
arXiv:2502.09560v2 Announce Type: replace 
Abstract: Leveraging Multi-modal Large Language Models (MLLMs) to create embodied agents offers a promising avenue for tackling real-world tasks. While language-centric embodied agents have garnered substantial attention, MLLM-based embodied agents remain underexplored due to the lack of comprehensive evaluation frameworks. To bridge this gap, we introduce EmbodiedBench, an extensive benchmark designed to evaluate vision-driven embodied agents. EmbodiedBench features: (1) a diverse set of 1,128 testing tasks across four environments, ranging from high-level semantic tasks (e.g., household) to low-level tasks involving atomic actions (e.g., navigation and manipulation); and (2) six meticulously curated subsets evaluating essential agent capabilities like commonsense reasoning, complex instruction understanding, spatial awareness, visual perception, and long-term planning. Through extensive experiments, we evaluated 19 leading proprietary and open-source MLLMs within EmbodiedBench. Our findings reveal that: MLLMs excel at high-level tasks but struggle with low-level manipulation, with the best model, GPT-4o, scoring only 28.9% on average. EmbodiedBench provides a multifaceted standardized evaluation platform that not only highlights existing challenges but also offers valuable insights to advance MLLM-based embodied agents. Our code is available at https://embodiedbench.github.io.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2502.11882</link>
<guid>https://arxiv.org/abs/2502.11882</guid>
<content:encoded><![CDATA[
arXiv:2502.11882v2 Announce Type: replace 
Abstract: Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning to Reason at the Frontier of Learnability</title>
<link>https://arxiv.org/abs/2502.12272</link>
<guid>https://arxiv.org/abs/2502.12272</guid>
<content:encoded><![CDATA[
arXiv:2502.12272v3 Announce Type: replace 
Abstract: Reinforcement learning is now widely adopted as the final stage of large language model training, especially for reasoning-style tasks such as maths problems. Typically, models attempt each question many times during a single training step and attempt to learn from their successes and failures. However, we demonstrate that throughout training with two popular algorithms (PPO and VinePPO) on two widely used datasets, many questions are either solved by all attempts - meaning they are already learned - or by none - providing no meaningful training signal. To address this, we adapt a method from the reinforcement learning literature - sampling for learnability - and apply it to the reinforcement learning stage of LLM training. Our curriculum prioritises questions with high variance of success, i.e. those where the agent sometimes succeeds, but not always. Our findings demonstrate that this curriculum consistently boosts training performance across multiple algorithms and datasets, paving the way for more efficient and effective reinforcement learning with LLMs.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Should I Trust You? Detecting Deception in Negotiations using Counterfactual RL</title>
<link>https://arxiv.org/abs/2502.12436</link>
<guid>https://arxiv.org/abs/2502.12436</guid>
<content:encoded><![CDATA[
arXiv:2502.12436v2 Announce Type: replace 
Abstract: An increasingly prevalent socio-technical problem is people being taken in by offers that sound ``too good to be true'', where persuasion and trust shape decision-making. This paper investigates how \abr{ai} can help detect these deceptive scenarios. We analyze how humans strategically deceive each other in \textit{Diplomacy}, a board game that requires both natural language communication and strategic reasoning. This requires extracting logical forms of proposed agreements in player communications and computing the relative rewards of the proposal using agents' value functions. Combined with text-based features, this can improve our deception detection. Our method detects human deception with a high precision when compared to a Large Language Model approach that flags many true messages as deceptive. Future human-\abr{ai} interaction tools can build on our methods for deception detection by triggering \textit{friction} to give users a chance of interrogating suspicious proposals.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Implicit Repair with Reinforcement Learning in Emergent Communication</title>
<link>https://arxiv.org/abs/2502.12624</link>
<guid>https://arxiv.org/abs/2502.12624</guid>
<content:encoded><![CDATA[
arXiv:2502.12624v2 Announce Type: replace 
Abstract: Conversational repair is a mechanism used to detect and resolve miscommunication and misinformation problems when two or more agents interact. One particular and underexplored form of repair in emergent communication is the implicit repair mechanism, where the interlocutor purposely conveys the desired information in such a way as to prevent misinformation from any other interlocutor. This work explores how redundancy can modify the emergent communication protocol to continue conveying the necessary information to complete the underlying task, even with additional external environmental pressures such as noise. We focus on extending the signaling game, called the Lewis Game, by adding noise in the communication channel and inputs received by the agents. Our analysis shows that agents add redundancy to the transmitted messages as an outcome to prevent the negative impact of noise on the task success. Additionally, we observe that the emerging communication protocol's generalization capabilities remain equivalent to architectures employed in simpler games that are entirely deterministic. Additionally, our method is the only one suitable for producing robust communication protocols that can handle cases with and without noise while maintaining increased generalization performance levels.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Text2World: Benchmarking Large Language Models for Symbolic World Model Generation</title>
<link>https://arxiv.org/abs/2502.13092</link>
<guid>https://arxiv.org/abs/2502.13092</guid>
<content:encoded><![CDATA[
arXiv:2502.13092v2 Announce Type: replace 
Abstract: Recently, there has been growing interest in leveraging large language models (LLMs) to generate symbolic world models from textual descriptions. Although LLMs have been extensively explored in the context of world modeling, prior studies encountered several challenges, including evaluation randomness, dependence on indirect metrics, and a limited domain scope. To address these limitations, we introduce a novel benchmark, Text2World, based on planning domain definition language (PDDL), featuring hundreds of diverse domains and employing multi-criteria, execution-based metrics for a more robust evaluation. We benchmark current LLMs using Text2World and find that reasoning models trained with large-scale reinforcement learning outperform others. However, even the best-performing model still demonstrates limited capabilities in world modeling. Building on these insights, we examine several promising strategies to enhance the world modeling capabilities of LLMs, including test-time scaling, agent training, and more. We hope that Text2World can serve as a crucial resource, laying the groundwork for future research in leveraging LLMs as world models. The project page is available at https://text-to-world.github.io/.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grounding LLM Reasoning with Knowledge Graphs</title>
<link>https://arxiv.org/abs/2502.13247</link>
<guid>https://arxiv.org/abs/2502.13247</guid>
<content:encoded><![CDATA[
arXiv:2502.13247v2 Announce Type: replace 
Abstract: Knowledge Graphs (KGs) are valuable tools for representing relationships between entities in a structured format. Traditionally, these knowledge bases are queried to extract specific information. However, question-answering (QA) over such KGs poses a challenge due to the intrinsic complexity of natural language compared to the structured format and the size of these graphs. Despite these challenges, the structured nature of KGs can provide a solid foundation for grounding the outputs of Large Language Models (LLMs), offering organizations increased reliability and control.
  Recent advancements in LLMs have introduced reasoning methods at inference time to improve their performance and maximize their capabilities. In this work, we propose integrating these reasoning strategies with KGs to anchor every step or "thought" of the reasoning chains in KG data. Specifically, we evaluate both agentic and automated search methods across several reasoning strategies, including Chain-of-Thought (CoT), Tree-of-Thought (ToT), and Graph-of-Thought (GoT), using GRBench, a benchmark dataset for graph reasoning with domain-specific graphs. Our experiments demonstrate that this approach consistently outperforms baseline models, highlighting the benefits of grounding LLM reasoning processes in structured KG data.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Conversational Agents with Theory of Mind: Aligning Beliefs, Desires, and Intentions for Human-Like Interaction</title>
<link>https://arxiv.org/abs/2502.14171</link>
<guid>https://arxiv.org/abs/2502.14171</guid>
<content:encoded><![CDATA[
arXiv:2502.14171v2 Announce Type: replace 
Abstract: Natural language interaction with agentic Artificial Intelligence (AI), driven by Large Language Models (LLMs), is expected to remain a dominant paradigm in the near future. While humans instinctively align their communication with mental states -- an ability known as Theory of Mind (ToM), current LLM powered systems exhibit significant limitations in this regard. This study examines the extent to which open source language models (LLaMA) can capture and preserve ToM related information and how effectively it contributes to consistent ToM reasoning in generated responses. We further investigate whether explicit manipulation of ToM related components, such as beliefs, desires, and intentions, can enhance response alignment. Experiments on two LLaMA 3 variants demonstrate that incorporating ToM informed alignment improves response quality, achieving win rates of 67 and 63 percent for the 3B and 8B models, respectively. These findings highlight the potential of ToM driven strategies to improve alignment in LLM based conversational agents.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BP-SGCN: Behavioral Pseudo-Label Informed Sparse Graph Convolution Network for Pedestrian and Heterogeneous Trajectory Prediction</title>
<link>https://arxiv.org/abs/2502.14676</link>
<guid>https://arxiv.org/abs/2502.14676</guid>
<content:encoded><![CDATA[
arXiv:2502.14676v2 Announce Type: replace 
Abstract: Trajectory prediction allows better decision-making in applications of autonomous vehicles or surveillance by predicting the short-term future movement of traffic agents. It is classified into pedestrian or heterogeneous trajectory prediction. The former exploits the relatively consistent behavior of pedestrians, but is limited in real-world scenarios with heterogeneous traffic agents such as cyclists and vehicles. The latter typically relies on extra class label information to distinguish the heterogeneous agents, but such labels are costly to annotate and cannot be generalized to represent different behaviors within the same class of agents. In this work, we introduce the behavioral pseudo-labels that effectively capture the behavior distributions of pedestrians and heterogeneous agents solely based on their motion features, significantly improving the accuracy of trajectory prediction. To implement the framework, we propose the Behavioral Pseudo-Label Informed Sparse Graph Convolution Network (BP-SGCN) that learns pseudo-labels and informs to a trajectory predictor. For optimization, we propose a cascaded training scheme, in which we first learn the pseudo-labels in an unsupervised manner, and then perform end-to-end fine-tuning on the labels in the direction of increasing the trajectory prediction accuracy. Experiments show that our pseudo-labels effectively model different behavior clusters and improve trajectory prediction. Our proposed BP-SGCN outperforms existing methods using both pedestrian (ETH/UCY, pedestrian-only SDD) and heterogeneous agent datasets (SDD, Argoverse 1).
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LQG Information Design</title>
<link>https://arxiv.org/abs/2312.09479</link>
<guid>https://arxiv.org/abs/2312.09479</guid>
<content:encoded><![CDATA[
arXiv:2312.09479v3 Announce Type: replace-cross 
Abstract: This paper addresses information design in a workhorse model of network games, where agents have linear best responses, the information designer optimizes a quadratic objective, and the payoff state follows a multivariate Gaussian distribution. We formulate the problem as semidefinite programming (SDP) and utilize the duality principle to characterize an optimal information structure. A Gaussian information structure is shown to be optimal among all information structures. A necessary and sufficient condition for optimality is that the induced equilibrium strategy profile and the state jointly satisfy a linear constraint derived from complementary slackness conditions. Consequently, the true state is typically revealed to the entire population of agents, even though individual agents remain only partially informed. In symmetric network games, an optimal information structure inherits the same degree of symmetry, which facilitates its computation.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TradingAgents: Multi-Agents LLM Financial Trading Framework</title>
<link>https://arxiv.org/abs/2412.20138</link>
<guid>https://arxiv.org/abs/2412.20138</guid>
<content:encoded><![CDATA[
arXiv:2412.20138v4 Announce Type: replace-cross 
Abstract: Significant progress has been made in automated problem-solving using societies of agents powered by large language models (LLMs). In finance, efforts have largely focused on single-agent systems handling specific tasks or multi-agent frameworks independently gathering data. However, multi-agent systems' potential to replicate real-world trading firms' collaborative dynamics remains underexplored. TradingAgents proposes a novel stock trading framework inspired by trading firms, featuring LLM-powered agents in specialized roles such as fundamental analysts, sentiment analysts, technical analysts, and traders with varied risk profiles. The framework includes Bull and Bear researcher agents assessing market conditions, a risk management team monitoring exposure, and traders synthesizing insights from debates and historical data to make informed decisions. By simulating a dynamic, collaborative trading environment, this framework aims to improve trading performance. Detailed architecture and extensive experiments reveal its superiority over baseline models, with notable improvements in cumulative returns, Sharpe ratio, and maximum drawdown, highlighting the potential of multi-agent LLM frameworks in financial trading. TradingAgents is available at https://github.com/TradingAgents-AI.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Why do Experts Disagree on Existential Risk and P(doom)? A Survey of AI Experts</title>
<link>https://arxiv.org/abs/2502.14870</link>
<guid>https://arxiv.org/abs/2502.14870</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能安全、人工通用智能、风险认知、专家观点、概念熟悉度

<br />
总结:

本文对arXiv:2502.14870v1的研究进行了概述，该研究关注于人工智能安全领域的重要性和专家对其的认知。文章指出，人工通用智能（AGI）的发展可能成为人类历史上的重大技术进步，其潜在的安全风险被比作核战争一样的存在级威胁。尽管如此，有关AI安全和灾难性风险的研究经常受到质疑，甚至在专家群体中也不例外，并出现了部落化的争论现象。为了解决这一问题，研究者调查了111位AI专家对于AI安全概念的熟悉程度、他们对AI安全的主要反对意见以及对安全论点的反应。调查结果显示，AI专家的观点主要分为两类：“可控工具”视角和“不可控代理”视角，这两类观点在对AI安全重要性的看法上存在分歧。大多数专家（78%）同意或强烈赞同“技术型AI研究人员应关注存在级风险”，但许多人对具体的AI安全概念并不熟悉，例如，只有21%的受访专家听说过AI安全中的基本概念“工具性收敛”，即高级AI系统可能会追求一些共同的子目标（如自我保护）。而对AI安全最不担忧的参与者恰好是对这些概念最不熟悉的，这表明有效沟通AI安全问题应该从确立领域的清晰概念基础开始。 <div>
arXiv:2502.14870v1 Announce Type: new 
Abstract: The development of artificial general intelligence (AGI) is likely to be one of humanity's most consequential technological advancements. Leading AI labs and scientists have called for the global prioritization of AI safety citing existential risks comparable to nuclear war. However, research on catastrophic risks and AI alignment is often met with skepticism, even by experts. Furthermore, online debate over the existential risk of AI has begun to turn tribal (e.g. name-calling such as "doomer" or "accelerationist"). Until now, no systematic study has explored the patterns of belief and the levels of familiarity with AI safety concepts among experts. I surveyed 111 AI experts on their familiarity with AI safety concepts, key objections to AI safety, and reactions to safety arguments. My findings reveal that AI experts cluster into two viewpoints -- an "AI as controllable tool" and an "AI as uncontrollable agent" perspective -- diverging in beliefs toward the importance of AI safety. While most experts (78%) agreed or strongly agreed that "technical AI researchers should be concerned about catastrophic risks", many were unfamiliar with specific AI safety concepts. For example, only 21% of surveyed experts had heard of "instrumental convergence," a fundamental concept in AI safety predicting that advanced AI systems will tend to pursue common sub-goals (such as self-preservation). The least concerned participants were the least familiar with concepts like this, suggesting that effective communication of AI safety should begin with establishing clear conceptual foundations in the field.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection</title>
<link>https://arxiv.org/abs/2502.14891</link>
<guid>https://arxiv.org/abs/2502.14891</guid>
<content:encoded><![CDATA[
<div> 关键词：协同3D对象检测、扩散模型、多智能体系统、噪声处理、自动驾驶

<br />
总结:
本文提出了一种名为CoDiff的新颖的鲁棒协同感知框架，用于解决自动驾驶领域中协同3D对象检测的问题。该框架首次将扩散模型应用于多智能体系统的协同感知，以应对由于姿态估计误差和时间延迟导致的信息融合中的空间和时间噪声问题。CoDiff利用预训练自编码器的潜在(latent)空间将高维特征图投影，并使每个个体代理信息作为条件引导扩散模型的采样过程，从而实现对粗略特征地图的去噪与融合特征的逐步细化。实验结果显示，无论是在模拟数据集还是真实世界数据集上，相较于现有相关方法，CoDiff在协同对象检测性能方面均表现出显著优势，并在具有高度噪声的代理姿态和延迟信息情况下展现出极高的鲁棒性。 <div>
arXiv:2502.14891v1 Announce Type: new 
Abstract: Collaborative 3D object detection holds significant importance in the field of autonomous driving, as it greatly enhances the perception capabilities of each individual agent by facilitating information exchange among multiple agents. However, in practice, due to pose estimation errors and time delays, the fusion of information across agents often results in feature representations with spatial and temporal noise, leading to detection errors. Diffusion models naturally have the ability to denoise noisy samples to the ideal data, which motivates us to explore the use of diffusion models to address the noise problem between multi-agent systems. In this work, we propose CoDiff, a novel robust collaborative perception framework that leverages the potential of diffusion models to generate more comprehensive and clearer feature representations. To the best of our knowledge, this is the first work to apply diffusion models to multi-agent collaborative perception. Specifically, we project high-dimensional feature map into the latent space of a powerful pre-trained autoencoder. Within this space, individual agent information serves as a condition to guide the diffusion model's sampling. This process denoises coarse feature maps and progressively refines the fused features. Experimental study on both simulated and real-world datasets demonstrates that the proposed framework CoDiff consistently outperforms existing relevant methods in terms of the collaborative object detection performance, and exhibits highly desired robustness when the pose and delay information of agents is with high-level noise.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EgoSpeak: Learning When to Speak for Egocentric Conversational Agents in the Wild</title>
<link>https://arxiv.org/abs/2502.14892</link>
<guid>https://arxiv.org/abs/2502.14892</guid>
<content:encoded><![CDATA[
<div> 关键词: EgoSpeak、实时语音启动预测、第一人称视角、RGB处理、在线处理、未修剪视频处理、YT-Conversation、EasyCom、Ego4D

总结:
本文介绍了EgoSpeak，这是一个针对第一人称视角下的实时语音启动预测的新框架，特别适用于需要持续观察环境并动态决定何时说话的人工智能对话代理。EgoSpeak结合了四个关键能力：第一人称视角、RGB处理、在线处理和未修剪视频处理，从而弥合了简化实验设置与复杂自然对话之间的差距。此外，文章还提出了YT-Conversation，一个来自YouTube的大规模野生对话视频数据集，用于预训练。实验证明，EgoSpeak在EasyCom和Ego4D数据集上的实时性能优于随机和基于沉默的基线，并突出了多模态输入和上下文长度对于有效决定何时说话的重要性。 <div>
arXiv:2502.14892v1 Announce Type: new 
Abstract: Predicting when to initiate speech in real-world environments remains a fundamental challenge for conversational agents. We introduce EgoSpeak, a novel framework for real-time speech initiation prediction in egocentric streaming video. By modeling the conversation from the speaker's first-person viewpoint, EgoSpeak is tailored for human-like interactions in which a conversational agent must continuously observe its environment and dynamically decide when to talk. Our approach bridges the gap between simplified experimental setups and complex natural conversations by integrating four key capabilities: (1) first-person perspective, (2) RGB processing, (3) online processing, and (4) untrimmed video processing. We also present YT-Conversation, a diverse collection of in-the-wild conversational videos from YouTube, as a resource for large-scale pretraining. Experiments on EasyCom and Ego4D demonstrate that EgoSpeak outperforms random and silence-based baselines in real time. Our results also highlight the importance of multimodal input and context length in effectively deciding when to speak.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment</title>
<link>https://arxiv.org/abs/2502.14913</link>
<guid>https://arxiv.org/abs/2502.14913</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、大型语言模型、Text-to-SQL任务、OpenSearch-SQL、SQL-Like、中间语言、一致性对齐机制、结构化CoT优化、动态少样本策略、执行精度、有效性、效率

总结:<br />
本文提出了针对Text-to-SQL任务的OpenSearch-SQL框架，旨在解决多智能体协作大型语言模型在该任务中面临的指导指令遵循失败和模型幻想等问题。该框架将任务分为预处理、抽取、生成、细化以及基于一致性对齐机制的对齐模块五个主要部分。同时，文章设计了一种名为SQL-Like的中间语言并优化了基于此语言的结构化CoT。此外，还提出了一种动态少样本自教Query-CoT-SQL策略。实验结果显示，OpenSearch-SQL在BIRD开发集上的执行精度达到69.3%，测试集为72.28%，并且以69.36%的奖励基有效性效率得分在提交时均位列第一，充分证明了所提方法在有效性和效率上的综合优势。 <div>
arXiv:2502.14913v1 Announce Type: new 
Abstract: Although multi-agent collaborative Large Language Models (LLMs) have achieved significant breakthroughs in the Text-to-SQL task, their performance is still constrained by various factors. These factors include the incompleteness of the framework, failure to follow instructions, and model hallucination problems. To address these problems, we propose OpenSearch-SQL, which divides the Text-to-SQL task into four main modules: Preprocessing, Extraction, Generation, and Refinement, along with an Alignment module based on a consistency alignment mechanism. This architecture aligns the inputs and outputs of agents through the Alignment module, reducing failures in instruction following and hallucination. Additionally, we designed an intermediate language called SQL-Like and optimized the structured CoT based on SQL-Like. Meanwhile, we developed a dynamic few-shot strategy in the form of self-taught Query-CoT-SQL. These methods have significantly improved the performance of LLMs in the Text-to-SQL task.
  In terms of model selection, we directly applied the base LLMs without any post-training, thereby simplifying the task chain and enhancing the framework's portability. Experimental results show that OpenSearch-SQL achieves an execution accuracy(EX) of 69.3% on the BIRD development set, 72.28% on the test set, and a reward-based validity efficiency score (R-VES) of 69.36%, with all three metrics ranking first at the time of submission. These results demonstrate the comprehensive advantages of the proposed method in both effectiveness and efficiency.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CyberSentinel: An Emergent Threat Detection System for AI Security</title>
<link>https://arxiv.org/abs/2502.14966</link>
<guid>https://arxiv.org/abs/2502.14966</guid>
<content:encoded><![CDATA[
<div> 关键词：CyberSentinel、人工智能、安全威胁、防御策略、机器学习

<br /><br />总结：
本文介绍了CyberSentinel，这是一个针对人工智能驱动的安全威胁提出的统一、单代理的实时新兴威胁检测系统。CyberSentinel通过SSH日志分析实现暴力攻击检测；利用域名黑名单和启发式URL评分方法进行钓鱼威胁评估；并通过基于机器学习的异常检测技术实现实时的新型威胁检测。通过不断适应敌对战术的变化，CyberSentinel强化了主动的网络安全防御，有效解决了AI安全中的关键漏洞问题。 <div>
arXiv:2502.14966v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence (AI) has significantly expanded the attack surface for AI-driven cybersecurity threats, necessitating adaptive defense strategies. This paper introduces CyberSentinel, a unified, single-agent system for emergent threat detection, designed to identify and mitigate novel security risks in real time. CyberSentinel integrates: (1) Brute-force attack detection through SSH log analysis, (2) Phishing threat assessment using domain blacklists and heuristic URL scoring, and (3) Emergent threat detection via machine learning-based anomaly detection. By continuously adapting to evolving adversarial tactics, CyberSentinel strengthens proactive cybersecurity defense, addressing critical vulnerabilities in AI security.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems</title>
<link>https://arxiv.org/abs/2502.15005</link>
<guid>https://arxiv.org/abs/2502.15005</guid>
<content:encoded><![CDATA[
<div> 关键词：Retrieval Augmented Generation (RAG)，Socratic dialogue，Knowledge Organization Systems (KOSs)，学术税onomies，CollabNext

<br />
<br />
总结:
本文提出了一种名为Retrieval Augmented Generation (RAG)的智能代理，该代理利用自然语言查询将研究主题映射到精确、机器可解释的语义实体。RAG与苏格拉底式对话相结合，使得用户对研究话题的直观理解能与已建立的知识组织系统(KOSs)保持一致，从而有效地连接了“小语义”（领域特定的KOS结构）与“大语义”（广泛的引文计量库），使复杂的学术分类体系更易访问。文中通过一个名为CollabNext的应用示例进行了说明，这是一个以人为中心的知识图谱，连接人、组织和研究主题，特别关注 Historically Black Colleges and Universities (HBCUs) 和新兴研究人员，旨在提高历史上在现行科学体系中被边缘化的人群的可见性。 <div>
arXiv:2502.15005v1 Announce Type: new 
Abstract: In this paper, we propose a Retrieval Augmented Generation (RAG) agent that maps natural language queries about research topics to precise, machine-interpretable semantic entities. Our approach combines RAG with Socratic dialogue to align a user's intuitive understanding of research topics with established Knowledge Organization Systems (KOSs). The proposed approach will effectively bridge "little semantics" (domain-specific KOS structures) with "big semantics" (broad bibliometric repositories), making complex academic taxonomies more accessible. Such agents have the potential for broad use. We illustrate with a sample application called CollabNext, which is a person-centric knowledge graph connecting people, organizations, and research topics. We further describe how the application design has an intentional focus on HBCUs and emerging researchers to raise visibility of people historically rendered invisible in the current science system.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Voter Model Meets Rumour Spreading: A Study of Consensus Protocols on Graphs with Agnostic Nodes [Extended Version]</title>
<link>https://arxiv.org/abs/2502.15029</link>
<guid>https://arxiv.org/abs/2502.15029</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、共识问题、无初始意见节点、投票模型、谣言传播

总结:
本文关注了在多智能体系统中存在无初始意见节点的共识问题，提出了一种称为“无知”节点的共识问题变体，并将其框架设定为投票模型和谣言传播两种已知过程的结合。文章主要贡献包括：<br />
1. 建立了一个描述给定颜色达成共识概率的鞅；<br />
2. 利用谣言传播和投票模型的结果给出了过程终止所需步骤数的界限；<br />
3. 求解了一些特殊情况下达成共识的概率的封闭形式公式；<br />
4. 针对一般图与Erdős-Rényi图，通过Markov链蒙特卡洛过程估计共识概率的计算复杂度分别为$O(n^2 \log n)$和$O(n\log n)$，表明该方法在估算概率上具有高效性；<br />
5. 进一步提供了实验结果，表明随着节点数量增加，为了达到给定标准误差所需的运行次数会减少。 <div>
arXiv:2502.15029v1 Announce Type: new 
Abstract: Problems of consensus in multi-agent systems are often viewed as a series of independent, simultaneous local decisions made between a limited set of options, all aimed at reaching a global agreement. Key challenges in these protocols include estimating the likelihood of various outcomes and finding bounds for how long it may take to achieve consensus, if it occurs at all.
  To date, little attention has been given to the case where some agents have no initial opinion. In this paper, we introduce a variant of the consensus problem which includes what we call `agnostic' nodes and frame it as a combination of two known and well-studied processes: voter model and rumour spreading. We show (1) a martingale that describes the probability of consensus for a given colour, (2) bounds on the number of steps for the process to end using results from rumour spreading and voter models, (3) closed formulas for the probability of consensus in a few special cases, and (4) that the computational complexity of estimating the probability with a Markov chain Monte Carlo process is $O(n^2 \log n)$ for general graphs and $O(n\log n)$ for Erd\H{o}s-R\'enyi graphs, which makes it an efficient method for estimating probabilities of consensus. Furthermore, we present experimental results suggesting that the number of runs needed for a given standard error decreases when the number of nodes increases.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models</title>
<link>https://arxiv.org/abs/2502.15086</link>
<guid>https://arxiv.org/abs/2502.15086</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 安全性, 用户特定标准, U-SAFEBENCH, 链式思考

<br /><br />总结:
随着大型语言模型（LLM）的应用日益广泛，其安全性漏洞问题愈发凸显。现有的安全基准测试主要依据通用标准来定义安全性，而忽视了用户特定的安全需求。文章指出，LLM的安全标准应根据用户的特定需求而非普适一致。为填补这一研究空白，作者提出了U-SAFEBENCH，这是首个用于评估LLM用户特定安全性方面的基准。对18款常用LLM进行的评价显示，当前的LLM在考虑用户特定安全标准时无法确保安全。针对此问题，作者提出了一种基于链式思考的简单改进方案，并证实其能有效提升用户特定的安全性。相关benchmark和代码已在https://github.com/yeonjun-in/U-SafeBench上公开。 <div>
arXiv:2502.15086v1 Announce Type: new 
Abstract: As the use of large language model (LLM) agents continues to grow, their safety vulnerabilities have become increasingly evident. Extensive benchmarks evaluate various aspects of LLM safety by defining the safety relying heavily on general standards, overlooking user-specific standards. However, safety standards for LLM may vary based on a user-specific profiles rather than being universally consistent across all users. This raises a critical research question: Do LLM agents act safely when considering user-specific safety standards? Despite its importance for safe LLM use, no benchmark datasets currently exist to evaluate the user-specific safety of LLMs. To address this gap, we introduce U-SAFEBENCH, the first benchmark designed to assess user-specific aspect of LLM safety. Our evaluation of 18 widely used LLMs reveals current LLMs fail to act safely when considering user-specific safety standards, marking a new discovery in this field. To address this vulnerability, we propose a simple remedy based on chain-of-thought, demonstrating its effectiveness in improving user-specific safety. Our benchmark and code are available at https://github.com/yeonjun-in/U-SafeBench.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models</title>
<link>https://arxiv.org/abs/2502.15119</link>
<guid>https://arxiv.org/abs/2502.15119</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶系统、安全、 Vision-Language 模型、个性化课程学习、CurricuVLM

总结:
本文提出了一个名为 CurricuVLM 的新框架，旨在通过利用 Vision-Language 模型（VLMs）来增强自动驾驶代理的安全性。针对当前研究中对于如何将安全关键场景有效地整合到政策学习以及适应自动驾驶行为模式和性能瓶颈的训练课程开发中存在的局限，CurricuVLM 利用 VLMs 的多模态理解能力分析自动驾驶车辆的行为，识别性能弱点，并动态生成针对性的训练场景进行课程适应。通过对不安全驾驶情况的深入描述和推理，该框架能评估自动驾驶系统的性能并识别关键行为模式。实验结果显示，CurricuVLM 在 Waymo Open Motion 数据集上的表现优于现有最佳基线，在常规和安全关键场景中均表现出较高的导航成功率、驾驶效率和安全性指标。此外，CurricuVLM 被证明是一种可以与多种强化学习算法集成的一般方法，以进一步提升自动驾驶系统的能力。相关代码和演示视频可在项目主页上获取。 <div>
arXiv:2502.15119v1 Announce Type: new 
Abstract: Ensuring safety in autonomous driving systems remains a critical challenge, particularly in handling rare but potentially catastrophic safety-critical scenarios. While existing research has explored generating safety-critical scenarios for autonomous vehicle (AV) testing, there is limited work on effectively incorporating these scenarios into policy learning to enhance safety. Furthermore, developing training curricula that adapt to an AV's evolving behavioral patterns and performance bottlenecks remains largely unexplored. To address these challenges, we propose CurricuVLM, a novel framework that leverages Vision-Language Models (VLMs) to enable personalized curriculum learning for autonomous driving agents. Our approach uniquely exploits VLMs' multimodal understanding capabilities to analyze agent behavior, identify performance weaknesses, and dynamically generate tailored training scenarios for curriculum adaptation. Through comprehensive analysis of unsafe driving situations with narrative descriptions, CurricuVLM performs in-depth reasoning to evaluate the AV's capabilities and identify critical behavioral patterns. The framework then synthesizes customized training scenarios targeting these identified limitations, enabling effective and personalized curriculum learning. Extensive experiments on the Waymo Open Motion Dataset show that CurricuVLM outperforms state-of-the-art baselines across both regular and safety-critical scenarios, achieving superior performance in terms of navigation success, driving efficiency, and safety metrics. Further analysis reveals that CurricuVLM serves as a general approach that can be integrated with various RL algorithms to enhance autonomous driving systems. The code and demo video are available at: https://zihaosheng.github.io/CurricuVLM/.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.15153</link>
<guid>https://arxiv.org/abs/2502.15153</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，多智能体系统(MASs)，知识冲突，鲁棒性，自我修复能力

<br /><br />总结：
本文研究了大型语言模型（LLMs）在多智能体系统（MASs）中的应用及其面对知识冲突时的鲁棒性。文章设计了四个综合指标来探究MASs在面临轻微或任务关键型知识冲突时的表现。研究发现，轻微的知识冲突不会损害系统的鲁棒性，反而能促进协同决策。而对于嵌入任务关键型知识冲突的情况，MASs展现出较强的鲁棒性，影响甚微，并具有一定的自我修复能力，通过减少对冲突知识的依赖和采纳替代解决方案路径以维持稳定性。此外，通过对知识冲突数量、智能体数量及交互轮数的消融研究，发现MASs的自我修复能力存在内在限制，而以上所有结论在各种因素下均保持一致。相关代码已公开发布在https://github.com/wbw625/MultiAgentRobustness。 <div>
arXiv:2502.15153v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have upgraded them from sophisticated text generators to autonomous agents capable of corporation and tool use in multi-agent systems (MASs). However, the robustness of these LLM-based MASs, especially under knowledge conflicts, remains unclear. In this paper, we design four comprehensive metrics to investigate the robustness of MASs when facing mild or task-critical knowledge conflicts. We first analyze mild knowledge conflicts introduced by heterogeneous agents and find that they do not harm system robustness but instead improve collaborative decision-making. Next, we investigate task-critical knowledge conflicts by synthesizing knowledge conflicts and embedding them into one of the agents. Our results show that these conflicts have surprisingly little to no impact on MAS robustness. Furthermore, we observe that MASs demonstrate certain self-repairing capabilities by reducing their reliance on knowledge conflicts and adopting alternative solution paths to maintain stability. Finally, we conduct ablation studies on the knowledge conflict number, agent number, and interaction rounds, finding that the self-repairing capability of MASs has intrinsic limits, and all findings hold consistently across various factors. Our code is publicly available at https://github.com/wbw625/MultiAgentRobustness.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OccProphet: Pushing Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with Observer-Forecaster-Refiner Framework</title>
<link>https://arxiv.org/abs/2502.15180</link>
<guid>https://arxiv.org/abs/2502.15180</guid>
<content:encoded><![CDATA[
<div> 关键词：OccProphet、占用率预测、自动驾驶、轻量化、效率提升

<br /><br />总结:
本文提出了一种名为OccProphet的新颖框架，用于高效且准确地学习占用率预测，尤其适用于复杂交通环境中的自动驾驶。该框架由三个轻量级组件组成：Observer、Forecaster和Refiner。OccProphet利用提出的“三重注意力融合”的高效4D聚合从3D多帧体素中提取时空特征。相比最先进的Cam4DOcc，OccProphet在训练和推理阶段显著降低了58%\~78%的计算成本，速度提升了2.6倍。同时，其在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上的实验结果显示，OccProphet的预测精度相对提高了4%\~18%。相关的代码和模型已在GitHub上公开可用。 <div>
arXiv:2502.15180v1 Announce Type: new 
Abstract: Predicting variations in complex traffic environments is crucial for the safety of autonomous driving. Recent advancements in occupancy forecasting have enabled forecasting future 3D occupied status in driving environments by observing historical 2D images. However, high computational demands make occupancy forecasting less efficient during training and inference stages, hindering its feasibility for deployment on edge agents. In this paper, we propose a novel framework, i.e., OccProphet, to efficiently and effectively learn occupancy forecasting with significantly lower computational requirements while improving forecasting accuracy. OccProphet comprises three lightweight components: Observer, Forecaster, and Refiner. The Observer extracts spatio-temporal features from 3D multi-frame voxels using the proposed Efficient 4D Aggregation with Tripling-Attention Fusion, while the Forecaster and Refiner conditionally predict and refine future occupancy inferences. Experimental results on nuScenes, Lyft-Level5, and nuScenes-Occupancy datasets demonstrate that OccProphet is both training- and inference-friendly. OccProphet reduces 58\%$\sim$78\% of the computational cost with a 2.6$\times$ speedup compared with the state-of-the-art Cam4DOcc. Moreover, it achieves 4\%$\sim$18\% relatively higher forecasting accuracy. Code and models are publicly available at https://github.com/JLChen-C/OccProphet.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Hardness of the Drone Delivery Problem</title>
<link>https://arxiv.org/abs/2502.15194</link>
<guid>https://arxiv.org/abs/2502.15194</guid>
<content:encoded><![CDATA[
<div> 关键词：物流、快速配送、路径优化、无人机送货问题、复杂度理论

总结:
本文研究了现代物流中的关键问题——快速配送和高效路由，特别关注于利用一组具有特定移动能力和速度的协作代理（如无人机）在图中实现从源节点到目标节点的包裹递送问题。文章提出了一种名为基于交付时间的无人机送货问题（DDT）。对于DDT在直线图上并预先设定无人机起始位置的情况，文中证明即使只考虑两种速度的无人机，该问题也是NP-难的，这细化了Erlebach等人之前的工作。接着，作者探讨了在无预设初始位置的网格图上，每架无人机可以自由选择起始位置的情况，进一步证明此问题难以在n的$(1-\varepsilon)$次幂因子内进行近似求解，其中n为网格大小，即使所有无人机的速度被限制为两种以及只能在矩形区域内移动。最后，文中提供了一个简单的$O(n)$近似算法。 <div>
arXiv:2502.15194v1 Announce Type: new 
Abstract: Fast shipping and efficient routing are key problems of modern logistics. Building on previous studies that address package delivery from a source node to a destination within a graph using multiple agents (such as vehicles, drones, and ships), we investigate the complexity of this problem in specialized graphs and with restricted agent types, both with and without predefined initial positions. Particularly, in this paper, we aim to minimize the delivery time for delivering a package. To achieve this, we utilize a set of collaborative agents, each capable of traversing a specific subset of the graph and operating at varying speeds. This challenge is encapsulated in the recently introduced Drone Delivery Problem with respect to delivery time (DDT).
  In this work, we show that the DDT with predefined initial positions on a line is NP-hard, even when considering only agents with two distinct speeds. This refines the results presented by Erlebach, et al.[ELS22], who demonstrated the NP-hardness of DDT on a line with agents of arbitrary speeds. Additionally, we examine DDT in grid graphs without predefined initial positions, where each drone can freely choose its starting position. We show that the problem is NP-hard to approximate within a factor of $O(n^{1-\varepsilon}$), where $n$ is the size of the grid, even when all agents are restricted to two different speeds as well as rectangular movement areas. We conclude by providing an easy $O(n)$ approximation algorithm.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Measuring AI agent autonomy: Towards a scalable approach with code inspection</title>
<link>https://arxiv.org/abs/2502.15212</link>
<guid>https://arxiv.org/abs/2502.15212</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、自主性评估、运行时评估、代码基础评估、AutoGen框架

总结:
该文提出了一个新的AI代理自主性评估方法，旨在通过代码基础评估来降低依赖于运行时评估的成本和风险。此方法关注自主性的两个属性：影响与监督，并通过对AI代理运行所使用的编排代码进行评分实现这一框架。文章以AutoGen框架及其应用为例进行了展示。这种方式提供了一种新的、无需实际执行特定任务就能评估AI代理自主水平的方法。 <div>
arXiv:2502.15212v1 Announce Type: new 
Abstract: AI agents are AI systems that can achieve complex goals autonomously. Assessing the level of agent autonomy is crucial for understanding both their potential benefits and risks. Current assessments of autonomy often focus on specific risks and rely on run-time evaluations -- observations of agent actions during operation. We introduce a code-based assessment of autonomy that eliminates the need to run an AI agent to perform specific tasks, thereby reducing the costs and risks associated with run-time evaluations. Using this code-based framework, the orchestration code used to run an AI agent can be scored according to a taxonomy that assesses attributes of autonomy: impact and oversight. We demonstrate this approach with the AutoGen framework and select applications.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15214</link>
<guid>https://arxiv.org/abs/2502.15214</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习(RL), 大规模语言模型(LLMs), 视觉-语言模型(VLMs), 决策制定, 程序分类

总结:
本文回顾了强化学习（RL）领域中大规模语言模型（LLMs）和视觉-语言模型（VLMs）的应用研究进展。这些模型被用来克服RL中的关键挑战，如缺乏先验知识、长时规划和奖励设计问题。文章提出了一种将LLM/VLM辅助的RL方法分为代理、规划器和奖励三个角色的分类体系。进一步探讨了未来的研究方向，包括接地问题、偏见缓解、改进表示以及行动建议。通过整合现有研究成果并指明未来发展方向，该调查为将LLMs和VLMs融入RL提供了一个框架，推动了自然语言和视觉理解与序列决策制定相结合的方法论发展。<br /><br /> <div>
arXiv:2502.15214v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has shown impressive results in sequential decision-making tasks. Meanwhile, Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged, exhibiting impressive capabilities in multimodal understanding and reasoning. These advances have led to a surge of research integrating LLMs and VLMs into RL. In this survey, we review representative works in which LLMs and VLMs are used to overcome key challenges in RL, such as lack of prior knowledge, long-horizon planning, and reward design. We present a taxonomy that categorizes these LLM/VLM-assisted RL approaches into three roles: agent, planner, and reward. We conclude by exploring open problems, including grounding, bias mitigation, improved representations, and action advice. By consolidating existing research and identifying future directions, this survey establishes a framework for integrating LLMs and VLMs into RL, advancing approaches that unify natural language and visual understanding with sequential decision-making.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ESPnet-SpeechLM: An Open Speech Language Model Toolkit</title>
<link>https://arxiv.org/abs/2502.15218</link>
<guid>https://arxiv.org/abs/2502.15218</guid>
<content:encoded><![CDATA[
<div> 关键词: ESPnet-SpeechLM、开放工具包、语音语言模型、开发流程、灵活性

总结:
ESPnet-SpeechLM 是一个旨在推动语音语言模型（SpeechLM）和语音驱动的代理应用程序开发民主化的开源工具包。该工具包通过将语音处理任务统一框架为普遍的序列建模问题，涵盖了从数据预处理、预训练、推理到任务评估的一体化工作流。用户可以轻松定义任务模板并配置关键设置，实现SpeechLM开发的无缝和流畅。ESPnet-SpeechLM 在整个工作流中的每个阶段都提供了高度可配置的模块，确保了灵活性、效率和可扩展性。文章通过多个使用案例展示了如何利用ESPnet-SpeechLM构建具有竞争力的SpeechLM，包括一个在文本和语音任务上预训练的拥有17亿参数的模型，并在各种基准测试中表现出色。该工具包及其配方完全透明且可在https://github.com/espnet/espnet/tree/speechlm 复制和重现。 <div>
arXiv:2502.15218v1 Announce Type: new 
Abstract: We present ESPnet-SpeechLM, an open toolkit designed to democratize the development of speech language models (SpeechLMs) and voice-driven agentic applications. The toolkit standardizes speech processing tasks by framing them as universal sequential modeling problems, encompassing a cohesive workflow of data preprocessing, pre-training, inference, and task evaluation. With ESPnet-SpeechLM, users can easily define task templates and configure key settings, enabling seamless and streamlined SpeechLM development. The toolkit ensures flexibility, efficiency, and scalability by offering highly configurable modules for every stage of the workflow. To illustrate its capabilities, we provide multiple use cases demonstrating how competitive SpeechLMs can be constructed with ESPnet-SpeechLM, including a 1.7B-parameter model pre-trained on both text and speech tasks, across diverse benchmarks. The toolkit and its recipes are fully transparent and reproducible at: https://github.com/espnet/espnet/tree/speechlm.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs</title>
<link>https://arxiv.org/abs/2502.15224</link>
<guid>https://arxiv.org/abs/2502.15224</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，科学发现，Auto-Bench，因果图发现，GPT-4

总结:
本文探讨了大型语言模型（LLMs）能否实现类似人类的科学研究和新知识发现，以及作为AI科学家的可能性。针对目前缺乏专门针对LLM代理进行科学发现评估的标准基准问题，文章提出了一个新的基准——“Auto-Bench”，该基准基于因果图发现原理，要求模型揭示隐藏结构并作出最佳决策，同时生成有效的推理依据。通过与虚拟导师的交互式互动，模型能逐步改进对基础相互作用的理解，包括化学和社会互动。文中评估了包括GPT-4、Gemini、Qwen、Claude和Llama在内的最新LLM，并观察到随着问题复杂性的增加，模型的表现显著下降，这表明机器智能与人类智能之间存在重要差距，未来LLM的发展需要对此加以考虑。 <div>
arXiv:2502.15224v1 Announce Type: new 
Abstract: Given the remarkable performance of Large Language Models (LLMs), an important question arises: Can LLMs conduct human-like scientific research and discover new knowledge, and act as an AI scientist? Scientific discovery is an iterative process that demands efficient knowledge updating and encoding. It involves understanding the environment, identifying new hypotheses, and reasoning about actions; however, no standardized benchmark specifically designed for scientific discovery exists for LLM agents. In response to these limitations, we introduce a novel benchmark, \textit{Auto-Bench}, that encompasses necessary aspects to evaluate LLMs for scientific discovery in both natural and social sciences. Our benchmark is based on the principles of causal graph discovery. It challenges models to uncover hidden structures and make optimal decisions, which includes generating valid justifications. By engaging interactively with an oracle, the models iteratively refine their understanding of underlying interactions, the chemistry and social interactions, through strategic interventions. We evaluate state-of-the-art LLMs, including GPT-4, Gemini, Qwen, Claude, and Llama, and observe a significant performance drop as the problem complexity increases, which suggests an important gap between machine and human intelligence that future development of LLMs need to take into consideration.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-agent Multi-armed Bandits with Minimum Reward Guarantee Fairness</title>
<link>https://arxiv.org/abs/2502.15240</link>
<guid>https://arxiv.org/abs/2502.15240</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理多臂老虎机问题、社会福利最大化、公平性、RewardFairUCB算法、上界信心边界

总结:
本文研究了在多代理多臂老虎机（MA-MAB）场景下，如何在确保公平性的前提下最大化社会福利。文章提出了名为RewardFairUCB的新算法，该算法利用上界信心边界（UCB）技术实现了对公平性和社会福利两方面的次线性遗憾界限。具体来说，该算法能实现实例无关的社会福利遗憾上界为$\tilde{O}(T^{1/2})$和公平性遗憾上界为$\tilde{O}(T^{3/4})$。同时，文中证明了社会福利和公平性遗憾的下界均为$\Omega(\sqrt{T})$。通过模拟数据和真实世界数据的实验评估，揭示了RewardFairUCB算法在公平性和社会福利遗憾之间的权衡关系。 <div>
arXiv:2502.15240v1 Announce Type: new 
Abstract: We investigate the problem of maximizing social welfare while ensuring fairness in a multi-agent multi-armed bandit (MA-MAB) setting. In this problem, a centralized decision-maker takes actions over time, generating random rewards for various agents. Our goal is to maximize the sum of expected cumulative rewards, a.k.a. social welfare, while ensuring that each agent receives an expected reward that is at least a constant fraction of the maximum possible expected reward.
  Our proposed algorithm, RewardFairUCB, leverages the Upper Confidence Bound (UCB) technique to achieve sublinear regret bounds for both fairness and social welfare. The fairness regret measures the positive difference between the minimum reward guarantee and the expected reward of a given policy, whereas the social welfare regret measures the difference between the social welfare of the optimal fair policy and that of the given policy.
  We show that RewardFairUCB algorithm achieves instance-independent social welfare regret guarantees of $\tilde{O}(T^{1/2})$ and a fairness regret upper bound of $\tilde{O}(T^{3/4})$. We also give the lower bound of $\Omega(\sqrt{T})$ for both social welfare and fairness regret. We evaluate RewardFairUCB's performance against various baseline and heuristic algorithms using simulated data and real world data, highlighting trade-offs between fairness and social welfare regrets.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models</title>
<link>https://arxiv.org/abs/2502.15252</link>
<guid>https://arxiv.org/abs/2502.15252</guid>
<content:encoded><![CDATA[
<div> 关键词：集体行人运动、深度学习模型、递归神经网络（RNN）、长短期记忆网络（LSTM）、Transformer<br /><br />总结:<br />
本文研究了利用序列深度学习模型，包括递归神经网络（RNN）、长短时记忆（LSTM）网络和Transformer，对多行人轨迹进行实时群体检测的方法。该方法分为两个阶段：首先使用预训练的二分类模型进行双人轨迹分类；其次，将学到的表示应用于动态识别多Agent群体。通过实际的群体移动数据集验证了该方法的鲁棒性，无论序列长度如何变化以及运动模式多么多样，都能稳定、准确地检测出行人群体。此外，该方法还被扩展到识别其他形式的集体运动，如车队和群集，为进一步的多Agent行为分析铺平道路。 <div>
arXiv:2502.15252v1 Announce Type: new 
Abstract: Understanding collective pedestrian movement is crucial for applications in crowd management, autonomous navigation, and human-robot interaction. This paper investigates the use of sequential deep learning models, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformers, for real-time flock detection in multi-pedestrian trajectories. Our proposed approach consists of a two-stage process: first, a pre-trained binary classification model is used for pairwise trajectory classification, and second, the learned representations are applied to identify multi-agent flocks dynamically.
  We validate our method using real-world group movement datasets, demonstrating its robustness across varying sequence lengths and diverse movement patterns. Experimental results indicate that our model consistently detects pedestrian flocks with high accuracy and stability, even in dynamic and noisy environments. Furthermore, we extend our approach to identify other forms of collective motion, such as convoys and swarms, paving the way for more comprehensive multi-agent behavior analysis.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards a Reward-Free Reinforcement Learning Framework for Vehicle Control</title>
<link>https://arxiv.org/abs/2502.15262</link>
<guid>https://arxiv.org/abs/2502.15262</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 车辆控制, 奖励信号, 无奖励强化学习框架, 目标状态预测网络<br /><br />总结:<br />
本文提出了一个无奖励强化学习框架(RFRLF)，旨在解决车辆控制中依赖于手动设计奖励信号和需要高质量专家行为的问题。该框架包括目标状态预测网络(TSPN)和无奖励状态引导策略网络(RFSGPN)，能够直接学习目标状态以优化代理行为，无需显式奖励信号。具体而言，通过最小化预测状态与专家状态之间的差异来训练策略网络。实验结果表明，提出的RFRLF在车辆驾驶控制方面表现出优越性，提高了学习效率并适应了无奖励环境。 <div>
arXiv:2502.15262v1 Announce Type: new 
Abstract: Reinforcement learning plays a crucial role in vehicle control by guiding agents to learn optimal control strategies through designing or learning appropriate reward signals. However, in vehicle control applications, rewards typically need to be manually designed while considering multiple implicit factors, which easily introduces human biases. Although imitation learning methods does not rely on explicit reward signals, they necessitate high-quality expert actions, which are often challenging to acquire. To address these issues, we propose a reward-free reinforcement learning framework (RFRLF). This framework directly learns the target states to optimize agent behavior through a target state prediction network (TSPN) and a reward-free state-guided policy network (RFSGPN), avoiding the dependence on manually designed reward signals. Specifically, the policy network is learned via minimizing the differences between the predicted state and the expert state. Experimental results demonstrate the effectiveness of the proposed RFRLF in controlling vehicle driving, showing its advantages in improving learning efficiency and adapting to reward-free environments.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leader-Follower Formation Tracking Control of Quadrotor UAVs Using Bearing Measurements</title>
<link>https://arxiv.org/abs/2502.15303</link>
<guid>https://arxiv.org/abs/2502.15303</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式形成跟踪控制、四旋翼飞行器、有限传感器集、相对测量、碰撞避免

总结:

本文研究了在具有放松感知图拓扑结构和极其有限传感器设置下，一组四旋翼飞行器的分布式队形跟踪控制问题。仅有一台领导飞行器能够获取全局位置信息，而其他飞行器仅能获得与其邻近代理之间的方向测量数据和相对速度信息。文章提出了一种层次化的控制架构，每个四旋翼飞行器结合高增益姿态内环控制器与带有碰撞避免功能的基于方位角的队形控制器。该方法使一组四旋翼飞行器能够在保持对至少一个相邻飞行器的相对测量的同时，实现对任意方位角持续激发的预定队形跟踪，包括随时间变化的形状和旋转机动。通过MATLAB数值模拟和实际三台四旋翼飞行器的实验验证了该控制策略的有效性。 <div>
arXiv:2502.15303v1 Announce Type: new 
Abstract: This work addresses the practical problem of distributed formation tracking control of a group of quadrotor vehicles in a relaxed sensing graph topology with a very limited sensor set, where only one leader vehicle can access the global position. Other vehicles in the formation are assumed to only have access to inter-agent bearing (direction) measurements and relative velocities with respect to their neighbor agents. A hierarchical control architecture is adopted for each quadrotor, combining a high-gain attitude inner-loop and an outer-loop bearing-based formation controller with collision avoidance augmentation. The proposed method enables a group of quadrotors to track arbitrary bearing persistently exciting desired formations, including time-varying shapes and rotational maneuvers, such that each quadrotor only requires relative measurements to at least one neighboring quadrotor. The effective performance of the control strategy is validated by numerical simulations in MATLAB and real-world experiments with three quadrotors.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation</title>
<link>https://arxiv.org/abs/2502.15309</link>
<guid>https://arxiv.org/abs/2502.15309</guid>
<content:encoded><![CDATA[
<div> 关键词: DynamicGSG、环境变化、场景图生成、高保真重建、动态更新

总结:<br />
本文提出了一种名为DynamicGSG的系统，用于应对由代理人或人类活动引起的环境中变化带来的挑战，使机器人更好地理解和适应动态环境。该系统包含三个关键组成部分：(1)利用先进的视觉基础模型构建层次化的场景图，以表示环境中物体的空间和语义关系；(2)设计了联合特征损失，优化高保真增量重建的高斯映射；(3)根据实际环境变化更新高斯映射和场景图，实现长期环境适应。实验和消融研究验证了所提方法在语义分割、语言引导对象检索及重建质量方面的性能与效果。此外，文中还在真实的实验室环境中验证了系统的动态更新能力。源代码将在https://github.com/GeLuzhou/Dynamic-GSG发布。 <div>
arXiv:2502.15309v1 Announce Type: new 
Abstract: In real-world scenarios, the environment changes caused by agents or human activities make it extremely challenging for robots to perform various long-term tasks. To effectively understand and adapt to dynamic environments, the perception system of a robot needs to extract instance-level semantic information, reconstruct the environment in a fine-grained manner, and update its environment representation in memory according to environment changes. To address these challenges, We propose \textbf{DynamicGSG}, a dynamic, high-fidelity, open-vocabulary scene graph generation system leveraging Gaussian splatting. Our system comprises three key components: (1) constructing hierarchical scene graphs using advanced vision foundation models to represent the spatial and semantic relationships of objects in the environment, (2) designing a joint feature loss to optimize the Gaussian map for incremental high-fidelity reconstruction, and (3) updating the Gaussian map and scene graph according to real environment changes for long-term environment adaptation. Experiments and ablation studies demonstrate the performance and efficacy of the proposed method in terms of semantic segmentation, language-guided object retrieval, and reconstruction quality. Furthermore, we have validated the dynamic updating capabilities of our system in real laboratory environments. The source code will be released at:~\href{https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/DynamicGSG}.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning with Limited Shared Information in Multi-agent Multi-armed Bandit</title>
<link>https://arxiv.org/abs/2502.15338</link>
<guid>https://arxiv.org/abs/2502.15338</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体多臂赌博机(MAMAB)，有限共享信息， Balanced-ETC算法，激励机制，协同学习

<br /><br />总结：
本文提出了一种新的多智能体多臂赌博机模型——有限共享信息多智能体多臂赌博机(LSI-MAMAB)，考虑了各智能体可能不愿分享全部信息的情况，如涉及个人隐私的数据。为了解决该问题，文中设计了Balanced-ETC算法，使得在有限共享信息条件下，多个智能体能够有效地协作学习。理论分析表明，Balanced-ETC算法具有渐近最优性，当参与智能体数量充足时，其平均 regret 对每个智能体而言可趋近于常数。此外，为了鼓励智能体参与到这种协作学习中，文章还提出了一个激励机制，确保每个智能体都能从协作系统中获益。最后，通过实验结果验证了理论分析的正确性。 <div>
arXiv:2502.15338v1 Announce Type: new 
Abstract: Multi-agent multi-armed bandit (MAMAB) is a classic collaborative learning model and has gained much attention in recent years. However, existing studies do not consider the case where an agent may refuse to share all her information with others, e.g., when some of the data contains personal privacy. In this paper, we propose a novel limited shared information multi-agent multi-armed bandit (LSI-MAMAB) model in which each agent only shares the information that she is willing to share, and propose the Balanced-ETC algorithm to help multiple agents collaborate efficiently with limited shared information. Our analysis shows that Balanced-ETC is asymptotically optimal and its average regret (on each agent) approaches a constant when there are sufficient agents involved. Moreover, to encourage agents to participate in this collaborative learning, an incentive mechanism is proposed to make sure each agent can benefit from the collaboration system. Finally, we present experimental results to validate our theoretical results.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ARS: Automatic Routing Solver with Large Language Models</title>
<link>https://arxiv.org/abs/2502.15359</link>
<guid>https://arxiv.org/abs/2502.15359</guid>
<content:encoded><![CDATA[
<div> 关键词: RoutBench、Vehicle Routing Problems (VRPs)、Automatic Routing Solver (ARS)、Large Language Model (LLM)、约束处理

总结:
为了解决实际生活中的复杂和多样化的车辆路径问题（VRPs），该文提出了RoutBench，一个由24种属性衍生出的1000个VRP变体的基准测试集合，用于评估自动路由求解器处理复杂约束的能力。同时，文中还介绍了一个名为Automatic Routing Solver (ARS)的方法，它利用大型语言模型（LLM）代理根据问题描述和从数据库中选取的一组代表性约束，自动生成约束感知的启发式代码，以增强基础算法框架。实验结果显示，ARS在解决常见VRP问题上的表现优于现有先进的LLM基线方法和常用求解器，能够自动解决91.67%的常规VRPs问题，并在所有基准测试上至少实现了30%的性能提升。 <div>
arXiv:2502.15359v1 Announce Type: new 
Abstract: Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of practical constraints, making manual solver design both knowledge-intensive and time-consuming. Although there is increasing interest in automating the design of routing algorithms, existing research has explored only a limited array of VRP variants and fails to adequately address the complex and prevalent constraints encountered in real-world situations. To fill this gap, this paper introduces RoutBench, a benchmark of 1,000 VRP variants derived from 24 attributes, for evaluating the effectiveness of automatic routing solvers in addressing complex constraints. Along with RoutBench, we present the Automatic Routing Solver (ARS), which employs Large Language Model (LLM) agents to enhance a backbone algorithm framework by automatically generating constraint-aware heuristic code, based on problem descriptions and several representative constraints selected from a database. Our experiments show that ARS outperforms state-of-the-art LLM-based methods and commonly used solvers, automatically solving 91.67% of common VRPs and achieving at least a 30% improvement across all benchmarks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Textual-to-Visual Iterative Self-Verification for Slide Generation</title>
<link>https://arxiv.org/abs/2502.15412</link>
<guid>https://arxiv.org/abs/2502.15412</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化、幻灯片生成、内容生成、布局生成、LLM

总结:
我们提出了一种自动化生成缺失演示文稿幻灯片的方法，旨在解决当前基于LLM的自主代理在实际应用中的局限性。该方法将任务分解为两个关键步骤：内容生成和布局生成。首先，采用一种结合周围幻灯片上下文和段落检索策略的内容生成方法，以提高连贯性和相关性。其次，我们提出了一个文本到视觉的自我验证流程，利用LLM为基础的评审员+精炼者工作流，将复杂的文本布局转化为直观的视觉格式。实验表明，我们的方法在对齐性、逻辑流畅性、视觉吸引力和可读性等方面均显著优于基线方法。 <div>
arXiv:2502.15412v1 Announce Type: new 
Abstract: Generating presentation slides is a time-consuming task that urgently requires automation. Due to their limited flexibility and lack of automated refinement mechanisms, existing autonomous LLM-based agents face constraints in real-world applicability. We decompose the task of generating missing presentation slides into two key components: content generation and layout generation, aligning with the typical process of creating academic slides. First, we introduce a content generation approach that enhances coherence and relevance by incorporating context from surrounding slides and leveraging section retrieval strategies. For layout generation, we propose a textual-to-visual self-verification process using a LLM-based Reviewer + Refiner workflow, transforming complex textual layouts into intuitive visual formats. This modality transformation simplifies the task, enabling accurate and human-like review and refinement. Experiments show that our approach significantly outperforms baseline methods in terms of alignment, logical flow, visual appeal, and readability.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15425</link>
<guid>https://arxiv.org/abs/2502.15425</guid>
<content:encoded><![CDATA[
<div> 关键词：artificial intelligence, hierarchical reinforcement learning, decentralized, TAME Agent Framework (TAG), multi-agent systems

总结:<br />
本文介绍了TAME Agent Framework (TAG)，一个新的用于构建完全去中心化的多层次多智能体系统的框架。TAG针对当前层次强化学习（HRL）方法存在的局限性，如通常限制为两层结构或需要集中式训练，提出了一种新的LevelEnv概念，将每一层级视为上一层级的环境，从而实现任意深度的层次组织，并保持各层级间的松散耦合。通过这种方式，TAG能够无缝整合不同类型的RL代理并在多个层级中结合使用。实验结果显示，基于TAG的分层架构在标准基准测试上相比于传统的多智能体RL基线表现出更快的学习速度和更好的最终性能，证明了去中心化分层组织对于可扩展的多智能体系统具有重要意义。 <div>
arXiv:2502.15425v1 Announce Type: new 
Abstract: Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two levels or require centralized training, which limits their practical applicability. We introduce TAME Agent Framework (TAG), a framework for constructing fully decentralized hierarchical multi-agent systems.TAG enables hierarchies of arbitrary depth through a novel LevelEnv concept, which abstracts each hierarchy level as the environment for the agents above it. This approach standardizes information flow between levels while preserving loose coupling, allowing for seamless integration of diverse agent types. We demonstrate the effectiveness of TAG by implementing hierarchical architectures that combine different RL agents across multiple levels, achieving improved performance over classical multi-agent RL baselines on standard benchmarks. Our results show that decentralized hierarchical organization enhances both learning speed and final performance, positioning TAG as a promising direction for scalable multi-agent systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations</title>
<link>https://arxiv.org/abs/2502.15429</link>
<guid>https://arxiv.org/abs/2502.15429</guid>
<content:encoded><![CDATA[
<div> 关键词: Pub-Guard-LLM、欺诈检测、生物医学文章、PubMed Retraction、大型语言模型

总结:
本文提出了一种名为Pub-Guard-LLM的大规模语言模型系统，该系统专门用于检测生物医学科学文章中的欺诈行为，以应对日益严重的科研诚信威胁。Pub-Guard-LLM提供了三种应用模式：原生推理、检索增强生成和多代理辩论，并可为预测结果提供文本解释。为了评估系统性能，作者构建了一个开源基准数据集PubMed Retraction，其中包含了超过11K篇具有元数据和撤稿标签的真实生物医药文章。实验表明，无论在哪种模式下，Pub-Guard-LLM均超越了多种基线方法的表现并提供了更可靠、相关性与连贯性更强的解释。通过提升欺诈检测性能和解释能力，Pub-Guard-LLM为维护科研诚信提供了一个创新、有效且开放源代码的工具。 <div>
arXiv:2502.15429v1 Announce Type: new 
Abstract: A significant and growing number of published scientific articles is found to involve fraudulent practices, posing a serious threat to the credibility and safety of research in fields such as medicine. We propose Pub-Guard-LLM, the first large language model-based system tailored to fraud detection of biomedical scientific articles. We provide three application modes for deploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and multi-agent debate. Each mode allows for textual explanations of predictions. To assess the performance of our system, we introduce an open-source benchmark, PubMed Retraction, comprising over 11K real-world biomedical articles, including metadata and retraction labels. We show that, across all modes, Pub-Guard-LLM consistently surpasses the performance of various baselines and provides more reliable explanations, namely explanations which are deemed more relevant and coherent than those generated by the baselines when evaluated by multiple assessment methods. By enhancing both detection performance and explainability in scientific fraud detection, Pub-Guard-LLM contributes to safeguarding research integrity with a novel, effective, open-source tool.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SALSA-RL: Stability Analysis in the Latent Space of Actions for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15512</link>
<guid>https://arxiv.org/abs/2502.15512</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习(DRL)、连续动作空间、稳定性分析、SALSA-RL、解释性

总结:
现代深度强化学习方法已在处理连续动作空间方面取得显著进步，但针对实际要求稳定性的控制系统（尤其是需要精确可靠性能的系统），现有DRL方法往往缺乏明确的稳定性保证和分析机制。为解决这一局限性，本文提出了一种新的RL框架——SALSA-RL（基于动作潜空间的稳定性分析）。该框架将控制动作建模为在潜空间中随时间动态变化的变量，并利用预训练的编码器-解码器及状态相关的线性系统实现稳定性分析与可解释性。实验表明，SALSA-RL可以非侵入式地应用于评估预先训练好的RL代理的动作局部稳定性，同时不影响其在多样化基准环境中的性能表现。通过提供对动作生成更具有解释性的分析，SALSA-RL为推进RL系统的设 <div>
arXiv:2502.15512v1 Announce Type: new 
Abstract: Modern deep reinforcement learning (DRL) methods have made significant advances in handling continuous action spaces. However, real-world control systems--especially those requiring precise and reliable performance--often demand formal stability, and existing DRL approaches typically lack explicit mechanisms to ensure or analyze stability. To address this limitation, we propose SALSA-RL (Stability Analysis in the Latent Space of Actions), a novel RL framework that models control actions as dynamic, time-dependent variables evolving within a latent space. By employing a pre-trained encoder-decoder and a state-dependent linear system, our approach enables both stability analysis and interpretability. We demonstrated that SALSA-RL can be deployed in a non-invasive manner for assessing the local stability of actions from pretrained RL agents without compromising on performance across diverse benchmark environments. By enabling a more interpretable analysis of action generation, SALSA-RL provides a powerful tool for advancing the design, analysis, and theoretical understanding of RL systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Contract DesignUnderApproximate Best Responses</title>
<link>https://arxiv.org/abs/2502.15523</link>
<guid>https://arxiv.org/abs/2502.15523</guid>
<content:encoded><![CDATA[
<div> 关键词: 主体-代理问题、近似最优响应、合同设计、计算复杂性、无 regret 学习算法

总结:<br />
本文研究了在隐藏行动主体-代理问题下，考虑近似最优响应情况下的合同设计。文章提出了一个能在多项式时间内计算出近似最优合同的算法，这一结果令人惊讶，因为在Stackelberg游戏中，对于近似最优响应的承诺优化问题是计算上不可解的。此外，文中还探讨了在无先验知识环境下，关于近似最优响应合同设计的无 regret 学习算法的应用场景。 <div>
arXiv:2502.15523v1 Announce Type: new 
Abstract: Principal-agent problems model scenarios where a principal incentivizes an agent to take costly, unobservable actions through the provision of payments. Such problems are ubiquitous in several real-world applications, ranging from blockchain to the delegation of machine learning tasks. In this paper, we initiate the study of hidden-action principal-agent problems under approximate best responses, in which the agent may select any action that is not too much suboptimal given the principal's payment scheme (a.k.a. contract). Our main result is a polynomial-time algorithm to compute an optimal contract under approximate best responses. This positive result is perhaps surprising, since, in Stackelberg games, computing an optimal commitment under approximate best responses is computationally intractable. We also investigate the learnability of contracts under approximate best responses, by providing a no-regret learning algorithm for a natural application scenario where the principal has no prior knowledge about the environment.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SOTOPIA-{\Omega}: Dynamic Strategy Injection Learning and Social Instrucion Following Evaluation for Social Agents</title>
<link>https://arxiv.org/abs/2502.15538</link>
<guid>https://arxiv.org/abs/2502.15538</guid>
<content:encoded><![CDATA[
<div> 关键词: SOTOPIA-Ω框架、社交策略、语言代理、Social Instruction Following (S-IF)、评价指标

总结:<br />
本文提出了一种名为SOTOPIA-Ω的新框架，旨在将人类的社会策略转移并整合到社交代理人，特别是语言代理中。该框架通过动态注入基于谈判理论的多步推理策略和两种直接策略，自动生成高质量的社交对话训练语料库。同时，文中引入了“社交指令跟随”(S-IF)的概念，并提出了两个新的、与社交能力相辅相成的S-IF评估指标。实验表明，经过高质语料库训练的几个7B模型不仅在实现社交目标上显著超越专家级代理（如GPT-4），而且在S-IF性能上也有所提升。分析和变体实验验证了动态构建的优势，它能有效打破代理间的持久僵局。 <div>
arXiv:2502.15538v1 Announce Type: new 
Abstract: Despite the abundance of prior social strategies possessed by humans, there remains a paucity of research dedicated to their transfer and integration into social agents. Our proposed SOTOPIA-{\Omega} framework aims to address and bridge this gap, with a particular focus on enhancing the social capabilities of language agents. This framework dynamically injects multi-step reasoning strategies inspired by negotiation theory, along with two simple direct strategies, into expert agents, thereby automating the construction of high-quality social dialogue training corpus. Additionally, we introduce the concept of Social Instruction Following (S-IF) and propose two new S-IF evaluation metrics that are complementary to social capability. We demonstrate that several 7B models trained on high-quality corpus not only significantly surpass the expert agent (GPT-4) in achieving social goals but also enhance S-IF performance. Analysis and variant experiments validate the advantages of dynamic construction, which can especially break the agent's prolonged deadlock.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents</title>
<link>https://arxiv.org/abs/2502.15601</link>
<guid>https://arxiv.org/abs/2502.15601</guid>
<content:encoded><![CDATA[
<div> 关键词: WorldCraft、LLM、三维建模、自然语言命令、自动验证

<br /><br />总结:
WorldCraft是一个使用大型语言模型（LLM）代理的系统，通过程序生成技术简化创建逼真虚拟世界的流程，使得非专业人士也能参与。用户可以通过直观的自然语言指令控制场景布局和物体属性。该系统由一个协调器代理管理，并与两个专门的LLM代理——ForgeIt（用于精确定制单个物体并利用自动验证不断改进）和ArrangeIt（负责平衡人体工程学和美学考量来优化布局）协同工作。此外，WorldCraft还包括一个轨迹控制代理，让用户能够通过自然语言交互来动画化场景及操作相机。系统还兼容现成的深度3D生成器以丰富场景资产。WorldCraft展现了从单一物体定制到复杂大规模室内室外场景设计等多方面的灵活性和多样性。 <div>
arXiv:2502.15601v1 Announce Type: new 
Abstract: Constructing photorealistic virtual worlds has applications across various fields, but it often requires the extensive labor of highly trained professionals to operate conventional 3D modeling software. To democratize this process, we introduce WorldCraft, a system where large language model (LLM) agents leverage procedural generation to create indoor and outdoor scenes populated with objects, allowing users to control individual object attributes and the scene layout using intuitive natural language commands. In our framework, a coordinator agent manages the overall process and works with two specialized LLM agents to complete the scene creation: ForgeIt, which integrates an ever-growing manual through auto-verification to enable precise customization of individual objects, and ArrangeIt, which formulates hierarchical optimization problems to achieve a layout that balances ergonomic and aesthetic considerations. Additionally, our pipeline incorporates a trajectory control agent, allowing users to animate the scene and operate the camera through natural language interactions. Our system is also compatible with off-the-shelf deep 3D generators to enrich scene assets. Through evaluations and comparisons with state-of-the-art methods, we demonstrate the versatility of WorldCraft, ranging from single-object customization to intricate, large-scale interior and exterior scene designs. This system empowers non-professionals to bring their creative visions to life.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes</title>
<link>https://arxiv.org/abs/2502.15633</link>
<guid>https://arxiv.org/abs/2502.15633</guid>
<content:encoded><![CDATA[
<div> 关键词：3D高斯投射（3DGS）、SLAM、RGB-only、室外场景、OpenGS-SLAM

总结:<br />
本文提出了一种适用于无界室外场景的新型RGB-only高斯投射SLAM方法——OpenGS-SLAM。该方法针对以往基于3DGS的SLAM方法主要应用于室内场景及依赖RGB-D传感器或预训练深度估计模型的问题，通过采用点图回归网络生成帧间一致的点图以实现更稳健的相机姿态估计。点图包含了多视图的空间关系和场景几何信息。接着，文章将估计的相机姿态与3DGS渲染结合成端到端可微分的管道，实现了相机姿态和3DGS场景参数的同时优化。此外，文中还设计了自适应尺度映射器来改进点图回归网络，从而为3DGS地图表示提供更为精确的点图映射。实验结果显示，在Waymo数据集上，OpenGS-SLAM将跟踪误差降低至先前3DGS方法的9.8%，并在新视图合成方面达到了最先进的结果。 <div>
arXiv:2502.15633v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Compared to commonly used depth maps, pointmaps include spatial relationships and scene geometry across multiple views, enabling robust camera pose estimation. Then, we propose integrating the estimated camera poses with 3DGS rendering as an end-to-end differentiable pipeline. Our method achieves simultaneous optimization of camera poses and 3DGS scene parameters, significantly enhancing system tracking accuracy. Specifically, we also design an adaptive scale mapper for the pointmap regression network, which provides more accurate pointmap mapping to the 3DGS map representation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8\% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis. Project Page: https://3dagentworld.github.io/opengs-slam/
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Simulation Pipeline to Facilitate Real-World Robotic Reinforcement Learning Applications</title>
<link>https://arxiv.org/abs/2502.15649</link>
<guid>https://arxiv.org/abs/2502.15649</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning, RL)，机器人应用，模拟到现实差距 (Simulation-to-Reality Gap)，系统识别，训练阶段

总结:<br />
本文介绍了一种用于减少现实与模拟之间差距并促进实际机器人系统中强化学习策略开发和部署的RL管道。该管道将RL训练过程分为系统识别初步步骤和三个训练阶段：核心模拟训练、高保真模拟以及真实世界部署，每个阶段逐步增加逼真度以缩小模拟与现实之间的差距。每个训练阶段都会接收输入政策、改进政策，并将其传递至下一阶段或回传进行进一步优化。这一迭代过程持续直至政策达到预期性能。通过使用波士顿动力Spot移动机器人的监控应用案例研究展示了该管道的有效性，其中详细介绍了在每个管道阶段所采取的步骤，最终获得能够控制机器人位置和方向的RL代理。 <div>
arXiv:2502.15649v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has gained traction for its success in solving complex tasks for robotic applications. However, its deployment on physical robots remains challenging due to safety risks and the comparatively high costs of training. To avoid these problems, RL agents are often trained on simulators, which introduces a new problem related to the gap between simulation and reality. This paper presents an RL pipeline designed to help reduce the reality gap and facilitate developing and deploying RL policies for real-world robotic systems. The pipeline organizes the RL training process into an initial step for system identification and three training stages: core simulation training, high-fidelity simulation, and real-world deployment, each adding levels of realism to reduce the sim-to-real gap. Each training stage takes an input policy, improves it, and either passes the improved policy to the next stage or loops it back for further improvement. This iterative process continues until the policy achieves the desired performance. The pipeline's effectiveness is shown through a case study with the Boston Dynamics Spot mobile robot used in a surveillance application. The case study presents the steps taken at each pipeline stage to obtain an RL agent to control the robot's position and orientation.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?</title>
<link>https://arxiv.org/abs/2502.15657</link>
<guid>https://arxiv.org/abs/2502.15657</guid>
<content:encoded><![CDATA[
<div> 关键词：通用人工智能、风险、安全、非代理AI、Scientist AI

总结:
当前领先的AI企业正专注于构建能自主规划、行动并追求目标的通用人工智能系统，但这种系统的失控可能带来重大的公共安全和安全隐患。文章指出，由于当前的训练方法，AI可能存在欺骗行为或追求与人类利益冲突的目标。为遵循预防原则，文章提倡发展一种设计上即具备可信度和安全性的非代理AI系统——Scientist AI。Scientist AI主要负责基于观察解释世界，包括生成理论以解释数据和进行带有不确定性考量的问题解答。此类系统可用于协助人类研究者加速科学研究，尤其是在AI安全性方面，可作为对抗存在风险的人工智能代理的防护措施。关注非代理AI的发展有望在避免现有轨迹带来的风险的同时，实现AI创新的利益。作者呼吁研究人员、开发者和政策制定者支持这条更安全的道路。 <div>
arXiv:2502.15657v1 Announce Type: new 
Abstract: The leading AI companies are increasingly focused on building generalist AI agents -- systems that can autonomously plan, act, and pursue goals across almost all tasks that humans can perform. Despite how useful these systems might be, unchecked AI agency poses significant risks to public safety and security, ranging from misuse by malicious actors to a potentially irreversible loss of human control. We discuss how these risks arise from current AI training methods. Indeed, various scenarios and experiments have demonstrated the possibility of AI agents engaging in deception or pursuing goals that were not specified by human operators and that conflict with human interests, such as self-preservation. Following the precautionary principle, we see a strong need for safer, yet still useful, alternatives to the current agency-driven trajectory. Accordingly, we propose as a core building block for further advances the development of a non-agentic AI system that is trustworthy and safe by design, which we call Scientist AI. This system is designed to explain the world from observations, as opposed to taking actions in it to imitate or please humans. It comprises a world model that generates theories to explain data and a question-answering inference machine. Both components operate with an explicit notion of uncertainty to mitigate the risks of overconfident predictions. In light of these considerations, a Scientist AI could be used to assist human researchers in accelerating scientific progress, including in AI safety. In particular, our system can be employed as a guardrail against AI agents that might be created despite the risks involved. Ultimately, focusing on non-agentic AI may enable the benefits of AI innovation while avoiding the risks associated with the current trajectory. We hope these arguments will motivate researchers, developers, and policymakers to favor this safer path.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network</title>
<link>https://arxiv.org/abs/2502.15662</link>
<guid>https://arxiv.org/abs/2502.15662</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、课程生成、SEBNs（技能环境贝叶斯网络）、预期改善、性能提升

总结:<br />
本文提出了一种用于强化学习的自动课程生成方法——SEBNs（Skill-Environment Bayesian Networks），该模型能够建立技能、目标与环境特征之间的概率关系，并预测在（可能未见过）任务上的策略表现。文章介绍了一个利用SEBN推断的代理成功度估计值来加权并选择预期能带来最大改进的下一个任务的算法。通过在离散网格世界、连续控制和模拟机器人三个环境中的评估结果表明，基于SEBN构建的课程通常优于其他基线方法，从而证实了其在减少训练时间和提高任务性能方面的优势。 <div>
arXiv:2502.15662v1 Announce Type: new 
Abstract: A major challenge for reinforcement learning is automatically generating curricula to reduce training time or improve performance in some target task. We introduce SEBNs (Skill-Environment Bayesian Networks) which model a probabilistic relationship between a set of skills, a set of goals that relate to the reward structure, and a set of environment features to predict policy performance on (possibly unseen) tasks. We develop an algorithm that uses the inferred estimates of agent success from SEBN to weigh the possible next tasks by expected improvement. We evaluate the benefit of the resulting curriculum on three environments: a discrete gridworld, continuous control, and simulated robotics. The results show that curricula constructed using SEBN frequently outperform other baselines.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Architecture in Distributed Environment Control Systems: vision, challenges, and opportunities</title>
<link>https://arxiv.org/abs/2502.15663</link>
<guid>https://arxiv.org/abs/2502.15663</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理架构、分布式控制、空气冷却冷水系统、数据中心、能源效率

总结:<br />
本文提出了一种应用于大型基础设施，尤其是数据中心的多代理架构方案，用于分布式的空气冷却冷水系统的控制，以满足对能效解决方案日益增长的需求。该方案采用自主智能体监控和调节局部运行参数，优化整个系统的效率，进而提升了系统的响应速度、运行鲁棒性和能源利用率。这为实现可持续性基础设施管理的总体目标做出了贡献。 <div>
arXiv:2502.15663v1 Announce Type: new 
Abstract: The increasing demand for energy-efficient solutions in large-scale infrastructure, particularly data centers, requires advanced control strategies to optimize environmental management systems. We propose a multi-agent architecture for distributed control of air-cooled chiller systems in data centers. Our vision employs autonomous agents to monitor and regulate local operational parameters and optimize system-wide efficiency. We demonstrate how this approach improves the responsiveness, operational robustness, and energy efficiency of the system, contributing to the broader goal of sustainable infrastructure management.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind</title>
<link>https://arxiv.org/abs/2502.15676</link>
<guid>https://arxiv.org/abs/2502.15676</guid>
<content:encoded><![CDATA[
<div> 关键词: 理论心智、大型语言模型、自动贝叶斯理论心智、开放性机器理论心智、推理问题

总结:
本文介绍了AutoToM，一种新型的自动化贝叶斯理论心智方法，旨在实现开放性的机器理论心智。AutoToM能够在任何领域中运行，推断任意心理变量并进行稳健的多层次理论心智推理。与依赖易出系统性错误的大规模语言模型或局限于特定领域的手工构造的贝叶斯理论心智模型不同，AutoToM首先提出一个初始的BToM模型，然后利用LLM作为后端执行自动化贝叶斯反向规划推理。根据推理的不确定性，它会迭代地细化模型，通过引入额外的心理变量和/或考虑更多的时间步上下文信息。实验结果显示，AutoToM在多个理论心智基准测试中始终表现出最先进的性能，提供了一种可扩展、稳健且可解释的机器理论心智方法。 <div>
arXiv:2502.15676v1 Announce Type: new 
Abstract: Theory of Mind (ToM), the ability to understand people's mental variables based on their behavior, is key to developing socially intelligent agents. Current approaches to Theory of Mind reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use rigid, handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but cannot generalize across different domains. In this work, we introduce AutoToM, an automated Bayesian Theory of Mind method for achieving open-ended machine Theory of Mind. AutoToM can operate in any domain, infer any mental variable, and conduct robust Theory of Mind reasoning of any order. Given a Theory of Mind inference problem, AutoToM first proposes an initial BToM model. It then conducts automated Bayesian inverse planning based on the proposed model, leveraging an LLM as the backend. Based on the uncertainty of the inference, it iteratively refines the model, by introducing additional mental variables and/or incorporating more timesteps in the context. Empirical evaluations across multiple Theory of Mind benchmarks demonstrate that AutoToM consistently achieves state-of-the-art performance, offering a scalable, robust, and interpretable approach to machine Theory of Mind.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PP-MARL: Efficient Privacy-Preserving Multi-Agent Reinforcement Learning for Cooperative Intelligence in Communications</title>
<link>https://arxiv.org/abs/2204.12064</link>
<guid>https://arxiv.org/abs/2204.12064</guid>
<content:encoded><![CDATA[
<div> 关键词: 合作智能(CI), 多智能体强化学习(MARL), 隐私保护, 恒等同态加密(HE), 差分隐私(DP)

总结:<br />
本文提出了一种用于多智能体强化学习(MARL)的高效隐私保护学习方案PP-MARL，旨在解决下一代网络中合作智能(CI)中的隐私保护问题。该方案利用恒等同态加密(HE)和差分隐私(DP)技术来保障隐私安全，同时引入分割学习以降低通过减少共享消息量带来的计算和带宽开销，从而提高效率。文章在两个通信相关的应用场景中应用并评估了PP-MARL。仿真结果表明，PP-MARL可以实现有效可靠的协作，并提供比现有方法高出1.1至6倍的隐私保护效果，同时显著降低了带宽开销（例如减少了84-91%）。 <div>
arXiv:2204.12064v2 Announce Type: replace 
Abstract: Cooperative intelligence (CI) is expected to become an integral element in next-generation networks because it can aggregate the capabilities and intelligence of multiple devices. Multi-agent reinforcement learning (MARL) is a popular approach for achieving CI in communication problems by enabling effective collaboration among agents to address sequential problems. However, ensuring privacy protection for MARL is a challenging task because of the presence of heterogeneous agents that learn interdependently via sharing information. Implementing privacy protection techniques such as data encryption and federated learning to MARL introduces the notable overheads (e.g., computation and bandwidth). To overcome these challenges, we propose PP-MARL, an efficient privacy-preserving learning scheme for MARL. PP-MARL leverages homomorphic encryption (HE) and differential privacy (DP) to protect privacy, while introducing split learning to decrease overheads via reducing the volume of shared messages, and then improve efficiency. We apply and evaluate PP-MARL in two communication-related use cases. Simulation results reveal that PP-MARL can achieve efficient and reliable collaboration with 1.1-6 times better privacy protection and lower overheads (e.g., 84-91% reduction in bandwidth) than state-of-the-art approaches.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safe Pareto Improvements for Expected Utility Maximizers in Program Games</title>
<link>https://arxiv.org/abs/2403.05103</link>
<guid>https://arxiv.org/abs/2403.05103</guid>
<content:encoded><![CDATA[
<div> 关键词: mixed-motive coordination, Safe Pareto improvements (SPIs), miscoordination, renegotiation, expected utility-maximizing agents

<br /><br />总结:
该文探讨了安全帕累托改进(SPIs)如何缓解预期效用最大化的代理人在混合动机协调问题（如Chicken游戏）中的协调失败。SPIs被定义为对策略配置进行的变换，以确保所有玩家在变换后的配置下必然得到更好的结果。文章考虑了一种情景，其中玩家提交可以基于对方代码做出决策的计算机程序，并利用这一特性通过具有重新谈判能力的程序构建SPIs。研究发现，在玩家信念满足轻微条件的情况下，每个玩家总是倾向于使用重新谈判。进一步地，类似假设下，每个玩家总是倾向于至少愿意重新谈判到他们能在任何有效结果中获得的最低收益水平。因此，主观最优策略保证了玩家至少能获得这些收益，而无需就特定的帕累托改进达成一致。然而，重新谈判并不能保证玩家在这方面超越这个界限。 <div>
arXiv:2403.05103v5 Announce Type: replace 
Abstract: Agents in mixed-motive coordination problems such as Chicken may fail to coordinate on a Pareto-efficient outcome. Safe Pareto improvements (SPIs) were originally proposed to mitigate miscoordination in cases where players lack probabilistic beliefs as to how their delegates will play a game; delegates are instructed to behave so as to guarantee a Pareto improvement on how they would play by default. More generally, SPIs may be defined as transformations of strategy profiles such that all players are necessarily better off under the transformed profile. In this work, we investigate the extent to which SPIs can reduce downsides of miscoordination between expected utility-maximizing agents. We consider games in which players submit computer programs that can condition their decisions on each other's code, and use this property to construct SPIs using programs capable of renegotiation. We first show that under mild conditions on players' beliefs, each player always prefers to use renegotiation. Next, we show that under similar assumptions, each player always prefers to be willing to renegotiate at least to the point at which they receive the lowest payoff they can attain in any efficient outcome. Thus subjectively optimal play guarantees players at least these payoffs, without the need for coordination on specific Pareto improvements. Lastly, we prove that renegotiation does not guarantee players any improvements on this bound.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space</title>
<link>https://arxiv.org/abs/2408.07416</link>
<guid>https://arxiv.org/abs/2408.07416</guid>
<content:encoded><![CDATA[
<div> 关键词: 三维语义理解、NeRFs、3DGS、实时渲染、三维查询评估协议

总结:<br />
本文关注于对场景的三维语义理解问题，提出了改进方法。首先，为克服以往方法在3D理解上的局限性，文章重新定义了问题并提出针对3D体积进行分割的方法。其次，不同于以往在2D像素层面进行监督训练，该方法直接对3D点施加语言嵌入场监督。进一步地，他们将学习到的语言场应用到3DGS中，实现了首个实时渲染速度，同时未牺牲训练时间和准确性。最后，文中引入了一种新的3D查询与评估协议，用于综合评估重建几何形状和语义。项目相关的代码、检查点和注解可在项目页面获取。 <div>
arXiv:2408.07416v3 Announce Type: replace 
Abstract: Understanding the 3D semantics of a scene is a fundamental problem for various scenarios such as embodied agents. While NeRFs and 3DGS excel at novel-view synthesis, previous methods for understanding their semantics have been limited to incomplete 3D understanding: their segmentation results are rendered as 2D masks that do not represent the entire 3D space. To address this limitation, we redefine the problem to segment the 3D volume and propose the following methods for better 3D understanding. We directly supervise the 3D points to train the language embedding field, unlike previous methods that anchor supervision at 2D pixels. We transfer the learned language field to 3DGS, achieving the first real-time rendering speed without sacrificing training time or accuracy. Lastly, we introduce a 3D querying and evaluation protocol for assessing the reconstructed geometry and semantics together. Code, checkpoints, and annotations are available at the project page.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking Generative Semantic Communication for Multi-User Systems with Large Language Models</title>
<link>https://arxiv.org/abs/2408.08765</link>
<guid>https://arxiv.org/abs/2408.08765</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G, 语义通信(SemCom), 多用户系统, 大规模语言模型(LLM), M-GSC框架

<br /><br />总结:
本文针对6G网络中连接设备激增以及智能农业和智慧城市等复杂任务对多用户合作的需求，提出了传统通信面临的挑战。语义通信（SemCom）作为由人工智能技术和增强的设备计算能力驱动的有希望的6G技术手段，但现有的深度学习基线的SemCom方法难以适应多用户场景。为了解决这些问题，文章重新思考并提出了适用于多用户的生成式语义通信（M-GSC）框架，该框架利用大规模语言模型（LLM）作为共享知识库（SKB）。LLM-SKB在复杂任务分解、语义表示规范和语义翻译映射等方面发挥关键作用，实现了语义编码标准化和个性化解码等优势。此外，文中还提出了三个优化策略，包括将LLM-SKB扩展为多代理LLM系统、语义编码与解码的卸载以及通信与计算资源的管理，以提升M-GSC框架的性能。通过一个案例研究初步验证了M-GSC框架在有效实现解码卸载等方面的效率优势。 <div>
arXiv:2408.08765v3 Announce Type: replace 
Abstract: The surge in connected devices in 6G with typical complex tasks requiring multi-user cooperation, such as smart agriculture and smart cities, poses significant challenges to unsustainable traditional communication. Fortunately, the booming artificial intelligence technology and the growing computational power of devices offer a promising 6G enabler: semantic communication (SemCom). However, existing deep learning-based SemCom paradigms struggle to extend to multi-user scenarios due to its increasing model size with the growing number of users and its limited compatibility with complex communication environments. Consequently, to truly empower 6G networks with this critical technology, this article rethinks generative SemCom for multi-user system and proposes a novel framework called ``M-GSC" with the large language model (LLM) as the shared knowledge base (SKB). The LLM-based SKB plays three critical roles, that is, complex task decomposition, semantic representation specification, and semantic translation and mapping, for complex tasks, spawning a series of benefits such as semantic encoding standardization and semantic decoding personalization. Meanwhile, to enhance the performance of M-GSC framework, we highlight three optimization strategies unique to this framework: extending the LLM-based SKB into a multi-agent LLM system, offloading semantic encoding and decoding, and managing communication and computational resources. Finally, a case study is conducted to demonstrate the preliminary validation on the effectiveness of the M-GSC framework in terms of efficient decoding offloading.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hierarchical DRL Approach for Resource Optimization in Multi-RIS Multi-Operator Networks</title>
<link>https://arxiv.org/abs/2410.12320</link>
<guid>https://arxiv.org/abs/2410.12320</guid>
<content:encoded><![CDATA[
<div> 关键词：reconfigurable intelligent surfaces (RIS)，第六代（6G）网络，多运营商（OP），深度强化学习（DRL），Hierarchical Proximal Policy Optimization (HPPO)

总结:

本文探讨了在第六代（6G）网络中，可重构智能表面（RIS）作为关键技术应用于多运营商（OP）网络所面临的挑战，如RIS配置协调、干扰管理和隐私保护。提出将RIS视为由RIS提供商（RP）管理的公共资源以提高资源配置效率。为解决复杂的RIS资源优化问题，文章提出了层次化深度强化学习（HDRL）方法，其中顶层RP代理负责RIS分配，而低层OP代理则控制其分配到的RIS并处理波束赋形、RIS相移和用户关联。利用半马尔科夫决策过程（SMDP）理论，建立了RP与OP间的复杂交互机制，并引入了高级的分层Proximal Policy Optimization（HPPO）算法。针对单个RP代理面临的维度灾难问题，进一步提出了改进的序列-HPPO（S-HPPO）算法。实验结果验证了HPPO算法在不同环境参数下的稳定性，并表明其在联合资源优化方面优于其他基准算法。最后，对提出的S-HPPO和HPPO算法进行了详细的比较分析，结果显示在大规模RIS分配场景下，S-HPPO算法具有更快的收敛速度和更优的性能。 <div>
arXiv:2410.12320v2 Announce Type: replace 
Abstract: As reconfigurable intelligent surfaces (RIS) emerge as a pivotal technology in the upcoming sixth-generation (6G) networks, their deployment within practical multiple operator (OP) networks presents significant challenges, including the coordination of RIS configurations among OPs, interference management, and privacy maintenance. A promising strategy is to treat RIS as a public resource managed by an RIS provider (RP), which can enhance resource allocation efficiency by allowing dynamic access for multiple OPs. However, the intricate nature of coordinating management and optimizing RIS configurations significantly complicates the implementation process. In this paper, we propose a hierarchical deep reinforcement learning (HDRL) approach that decomposes the complicated RIS resource optimization problem into several subtasks. Specifically, a top-level RP-agent is responsible for RIS allocation, while low-level OP-agents control their assigned RISs and handle beamforming, RIS phase-shifts, and user association. By utilizing the semi-Markov decision process (SMDP) theory, we establish a sophisticated interaction mechanism between the RP and OPs, and introduce an advanced hierarchical proximal policy optimization (HPPO) algorithm. Furthermore, we propose an improved sequential-HPPO (S-HPPO) algorithm to address the curse of dimensionality encountered with a single RP-agent. Experimental results validate the stability of the HPPO algorithm across various environmental parameters, demonstrating its superiority over other benchmarks for joint resource optimization. Finally, we conduct a detailed comparative analysis between the proposed S-HPPO and HPPO algorithms, showcasing that the S-HPPO algorithm achieves faster convergence and improved performance in large-scale RIS allocation scenarios.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title>
<link>https://arxiv.org/abs/2410.14803</link>
<guid>https://arxiv.org/abs/2410.14803</guid>
<content:encoded><![CDATA[
<div> 关键词: on-device control agents, Multimodal Large Language Models (MLLMs), DistRL, reinforcement learning (RL), training efficiency

<br /><br />总结:
本文提出了一种名为DistRL的新框架，旨在提升移动设备控制代理中基于多模态大型语言模型(MLLMs)的在线强化学习（RL）微调效率。面对有限的数据可用性和低效的在线训练问题，DistRL采用了集中式训练与分布式数据采集相结合的方式，保证了动态在线交互环境下的高效微调。此外，该框架还配备了一个定制的RL算法，能在探索与已收集数据的有效利用之间取得平衡，确保稳定和鲁棒的训练过程。实验结果显示，相比于领先的同步多机器方法，DistRL平均提升了3倍的训练效率，并能将训练数据收集速度提高2.4倍。在对开放基准中的通用Android任务进行测试后，DistRL相较于现有最优方法取得了20%的成功率相对提升，显著超越了其他方法的同时，保持了相同的训练时间。这些结果验证了DistRL是一种可扩展且高效的解决方案，对于现实世界中的设备控制任务，它既提高了训练效率，又提升了代理性能。 <div>
arXiv:2410.14803v5 Announce Type: replace 
Abstract: On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3X improvement in training efficiency and enables training data collection 2.4X faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shared Control with Black Box Agents using Oracle Queries</title>
<link>https://arxiv.org/abs/2410.19612</link>
<guid>https://arxiv.org/abs/2410.19612</guid>
<content:encoded><![CDATA[
<div> 关键词：共享控制、机器人、人类协作、查询、学习策略<br /><br />总结:

本文探讨了共享控制问题，研究了机器人如何与人类协同学习控制策略。通过引入直接向合作代理人查询的能力，文章考虑了两种类型的响应查询的预言机：一种能提供最佳行动建议，即使该行动可能从局部角度看是错误的；另一种则具有对其系统部分有限的知识。针对这一额外的信息通道，文中提出了三种选择何时进行查询的启发式方法：基于强化学习的、基于效用的和基于熵的。实验证明，在两个环境中，查询能够帮助学习更优的控制策略，并展示了所提启发式方法之间的学习成本权衡。 <div>
arXiv:2410.19612v2 Announce Type: replace 
Abstract: Shared control problems involve a robot learning to collaborate with a human. When learning a shared control policy, short communication between the agents can often significantly reduce running times and improve the system's accuracy. We extend the shared control problem to include the ability to directly query a cooperating agent. We consider two types of potential responses to a query, namely oracles: one that can provide the learner with the best action they should take, even when that action might be myopically wrong, and one with a bounded knowledge limited to its part of the system. Given this additional information channel, this work further presents three heuristics for choosing when to query: reinforcement learning-based, utility-based, and entropy-based. These heuristics aim to reduce a system's overall learning cost. Empirical results on two environments show the benefits of querying to learn a better control policy and the tradeoffs between the proposed heuristics.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provable Partially Observable Reinforcement Learning with Privileged Information</title>
<link>https://arxiv.org/abs/2412.00985</link>
<guid>https://arxiv.org/abs/2412.00985</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、部分可观测性、特权信息、专家蒸馏、不对称actor-critic<br /><br />总结:

本文针对部分可观测环境下强化学习（RL）中的挑战进行了研究，探讨了利用特权信息（如来自模拟器的状态访问）的优势。文章首先形式化并指出了“专家蒸馏”（又称“教师-学生”学习）在找到近似最优策略时可能存在的问题。接着，提出了一种名为“确定性滤波条件”的环境条件，在此条件下，专家蒸馏可以实现样本和计算复杂度均为多项式级的效率。随后，研究了另一种实用方法——不对称actor-critic，在可观察的部分可观测马尔科夫决策过程中，设计了一个信念加权的不对称actor-critic算法，其具有多项式级样本复杂度和准多项式级计算复杂度。其中，关键组件是一个新的可证明的信念状态学习Oracle，该Oracle能在模型误配情况下保证滤波稳定性。此外，文章还考察了具有特权信息的部分可观测多智能体RL（MARL）的可证效率，提出了采用集中训练与分布式执行框架的多项式级样本和（准）多项式级计算复杂度的算法。相较于近期相关理论研究，本文更侧重于理解实践启发式的算法范式，同时避免了使用计算上不可行的Oracle。 <div>
arXiv:2412.00985v3 Announce Type: replace 
Abstract: Partial observability of the underlying states generally presents significant challenges for reinforcement learning (RL). In practice, certain \emph{privileged information}, e.g., the access to states from simulators, has been exploited in training and has achieved prominent empirical successes. To better understand the benefits of privileged information, we revisit and examine several simple and practically used paradigms in this setting. Specifically, we first formalize the empirical paradigm of \emph{expert distillation} (also known as \emph{teacher-student} learning), demonstrating its pitfall in finding near-optimal policies. We then identify a condition of the partially observable environment, the \emph{deterministic filter condition}, under which expert distillation achieves sample and computational complexities that are \emph{both} polynomial. Furthermore, we investigate another useful empirical paradigm of \emph{asymmetric actor-critic}, and focus on the more challenging setting of observable partially observable Markov decision processes. We develop a belief-weighted asymmetric actor-critic algorithm with polynomial sample and quasi-polynomial computational complexities, in which one key component is a new provable oracle for learning belief states that preserve \emph{filter stability} under a misspecified model, which may be of independent interest. Finally, we also investigate the provable efficiency of partially observable multi-agent RL (MARL) with privileged information. We develop algorithms featuring \emph{centralized-training-with-decentralized-execution}, a popular framework in empirical MARL, with polynomial sample and (quasi-)polynomial computational complexities in both paradigms above. Compared with a few recent related theoretical studies, our focus is on understanding practically inspired algorithmic paradigms, without computationally intractable oracles.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games</title>
<link>https://arxiv.org/abs/2412.04937</link>
<guid>https://arxiv.org/abs/2412.04937</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、大规模语言模型、对话控制、回合制游戏、谋杀之谜、对话规范、自然对话、决策制定、相邻对、轮流机制、内部状态、对话中断、自动评估、人类评价、信息共享、逻辑推理。

<br /><br />总结:
该研究关注多智能体系统中利用大规模语言模型进行自然对话的问题，提出了一种新的框架——“谋杀之谜代理人”，将对话分析中的对话规范（如相邻对和轮流机制）应用于AI代理的对话控制。通过使用需要复杂社会推理和信息操作的回合制推理游戏“谋杀之谜”作为评估目标，该框架整合了基于相邻对的下一个说话者选择以及考虑了代理内部状态的自我选择机制，以实现更自然和策略性的对话。实验结果表明，实施下一个说话者选择机制显著减少了对话中断，提高了代理人分享信息和进行逻辑推理的能力。这项研究表明，人类会话中的轮流机制规律同样适用于AI代理间的对话控制，并为构建更高级的多智能体对话系统提供了设计指南。 <div>
arXiv:2412.04937v2 Announce Type: replace 
Abstract: Multi-agent systems utilizing large language models (LLMs) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenges. In this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called "Murder Mystery Agents" that applies these norms to AI agents' dialogue control. As an evaluation target, we employed the "Murder Mystery" game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. In this game, players need to unravel the truth of the case based on fragmentary information through cooperation and bargaining. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue. To verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using LLMs, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning. The results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among AI agents, and provide design guidelines for more advanced multi-agent dialogue systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Text to Trajectory: Exploring Complex Constraint Representation and Decomposition in Safe Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.08920</link>
<guid>https://arxiv.org/abs/2412.08920</guid>
<content:encoded><![CDATA[
<div> 关键词：安全强化学习、自然语言约束、训练信号、轨迹级文本约束翻译器、零-shot转移能力

<br /><br />总结:
本文主要探讨了如何在安全强化学习中利用自然语言约束来指导智能体完成任务并遵循特定限制。现有的方法通常需要针对每个约束手动设计成本函数，而该论文提出了一种名为Trajectory-level Textual Constraints Translator (TTCT)的新方法，它利用文本的双重作用，不仅提供约束，还作为训练信号替代了手动设计的成本函数。实验表明，TTCT能够有效地理解文本约束和轨迹，并能训练出违反率更低的策略。此外，论文还进行了额外的研究，证明TTCT具有零-shot转移能力，能够在约束环境变化的情况下进行适应。 <div>
arXiv:2412.08920v2 Announce Type: replace 
Abstract: Safe reinforcement learning (RL) requires the agent to finish a given task while obeying specific constraints. Giving constraints in natural language form has great potential for practical scenarios due to its flexible transfer capability and accessibility. Previous safe RL methods with natural language constraints typically need to design cost functions manually for each constraint, which requires domain expertise and lacks flexibility. In this paper, we harness the dual role of text in this task, using it not only to provide constraint but also as a training signal. We introduce the Trajectory-level Textual Constraints Translator (TTCT) to replace the manually designed cost function. Our empirical results demonstrate that TTCT effectively comprehends textual constraint and trajectory, and the policies trained by TTCT can achieve a lower violation rate than the standard cost function. Extra studies are conducted to demonstrate that the TTCT has zero-shot transfer capability to adapt to constraint-shift environments.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring and Controlling Diversity in LLM-Agent Conversation</title>
<link>https://arxiv.org/abs/2412.21102</link>
<guid>https://arxiv.org/abs/2412.21102</guid>
<content:encoded><![CDATA[
<div> 关键词: 控制多样性、LLM-agent、世界模拟、对话多样性、适应性提示修剪(APP)

总结:
本文关注于在LLM-agent世界模拟中控制对话多样性的关键问题，指出长期模拟中对话多样性显著下降。通过模块化对话生成提示，研究发现减少给定信息可以带来更丰富的输出。因此，文章提出了一个名为“适应性提示修剪”（APP）的新方法，该方法让用户能够通过单一参数lambda来动态调整并控制输出多样性。APP根据注意力权重动态地裁剪对话生成提示，并与传统的多样性控制技术兼容。实验表明APP能有效控制输出多样性，并提出一种平衡控制权衡的方法。此外，文中还进行了深入分析，为优化多智能体模拟中的多样性控制提供了见解。 <div>
arXiv:2412.21102v2 Announce Type: replace 
Abstract: Controlling diversity in LLM-agent world simulations is essential for maintaining stability in structured tasks while enabling variation where creativity is needed. However, we observe that dialogue diversity declines significantly over long-term simulation. To investigate the role of prompt design in conversational diversity, we modularized the utterance generation prompt and found that reducing the given information leads to more diverse outputs. Based on this insight, we propose Adaptive Prompt Pruning (APP), a novel method that allows users to control diversity through a single parameter, lambda. APP dynamically prunes the utterance generation prompt based on their attention weights and is compatible with traditional diversity control techniques. We demonstrate that APP effectively controls output diversity through extensive experiments, and propose a method to balance the control trade-offs. Additionally, we provide an in-depth analysis to offer insights into optimizing diversity control in multi-agent simulation.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A View of the Certainty-Equivalence Method for PAC RL as an Application of the Trajectory Tree Method</title>
<link>https://arxiv.org/abs/2501.02652</link>
<guid>https://arxiv.org/abs/2501.02652</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning）、最大似然估计（Maximum Likelihood Estimate）、确定性等价方法（Certainty-Equivalence Method, CEM）、轨迹树方法（Trajectory Tree Method, TTM）、采样复杂度（Sample Complexity）

<br /><br />
总结:
本文研究了强化学习中的确定性等价方法(CEM)与轨迹树方法(TTM)之间的理论联系。发现CEM实际上可以视为TTM的一种应用形式。这一新视角带来了三个主要成果：(1) 提供了关于CEM的新颖且简洁的样本复杂度上界证明；(2) 在较弱的奖励假设下进行此分析，适用于非平稳和平稳MDP；(3) 对于小错误概率δ的情况，改进了CEM在非平稳和平稳MDP上的样本复杂度上界；(4) 展示了一个有限时间horizon MDP的样本复杂度下界，从而证明了在小δ场景下非平稳MDP中上界的最小最大最优性。 <div>
arXiv:2501.02652v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) enables an agent interacting with an unknown MDP $M$ to optimise its behaviour by observing transitions sampled from $M$. A natural entity that emerges in the agent's reasoning is $\widehat{M}$, the maximum likelihood estimate of $M$ based on the observed transitions. The well-known \textit{certainty-equivalence} method (CEM) dictates that the agent update its behaviour to $\widehat{\pi}$, which is an optimal policy for $\widehat{M}$. Not only is CEM intuitive, it has been shown to enjoy minimax-optimal sample complexity in some regions of the parameter space for PAC RL with a generative model~\citep{Agarwal2020GenModel}.
  A seemingly unrelated algorithm is the ``trajectory tree method'' (TTM)~\citep{Kearns+MN:1999}, originally developed for efficient decision-time planning in large POMDPs. This paper presents a theoretical investigation that stems from the surprising finding that CEM may indeed be viewed as an application of TTM. The qualitative benefits of this view are (1) new and simple proofs of sample complexity upper bounds for CEM, in fact under a (2) weaker assumption on the rewards than is prevalent in the current literature. Our analysis applies to both non-stationary and stationary MDPs. Quantitatively, we obtain (3) improvements in the sample-complexity upper bounds for CEM both for non-stationary and stationary MDPs, in the regime that the ``mistake probability'' $\delta$ is small. Additionally, we show (4) a lower bound on the sample complexity for finite-horizon MDPs, which establishes the minimax-optimality of our upper bound for non-stationary MDPs in the small-$\delta$ regime.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Equivariant Policy via Frame Transfer</title>
<link>https://arxiv.org/abs/2502.05728</link>
<guid>https://arxiv.org/abs/2502.05728</guid>
<content:encoded><![CDATA[
<div> 关键词：层次化策略学习、高层代理、低层代理、框架转移接口、域对称性

总结:
本文提出了一个名为层次化等变策略(HEP)的新型层次化政策框架，旨在解决现有层次化方法中高层和低层代理间接口未充分探索以及忽略领域对称性的问题。HEP通过高层代理的输出作为低层代理的坐标框架的“框架转移接口”，为层次化策略学习提供了强大的归纳偏置并保持了灵活性。同时，HEP将域对称性融入到各级别中，并从理论上证明了系统的整体等变性。实验结果显示，HEP在复杂机器人操纵任务上表现出最先进的性能，无论是在模拟环境还是现实世界中都取得了显著的改进效果。 <div>
arXiv:2502.05728v3 Announce Type: replace 
Abstract: Recent advances in hierarchical policy learning highlight the advantages of decomposing systems into high-level and low-level agents, enabling efficient long-horizon reasoning and precise fine-grained control. However, the interface between these hierarchy levels remains underexplored, and existing hierarchical methods often ignore domain symmetry, resulting in the need for extensive demonstrations to achieve robust performance. To address these issues, we propose Hierarchical Equivariant Policy (HEP), a novel hierarchical policy framework. We propose a frame transfer interface for hierarchical policy learning, which uses the high-level agent's output as a coordinate frame for the low-level agent, providing a strong inductive bias while retaining flexibility. Additionally, we integrate domain symmetries into both levels and theoretically demonstrate the system's overall equivariance. HEP achieves state-of-the-art performance in complex robotic manipulation tasks, demonstrating significant improvements in both simulation and real-world settings.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors</title>
<link>https://arxiv.org/abs/2502.13311</link>
<guid>https://arxiv.org/abs/2502.13311</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能辅导代理人、大规模语言模型、编程教学、Trace-and-Verify (TRAVER)、DICT自动评估协议

<br /><br />总结:
本文探讨了利用大规模语言模型驱动的智能辅导代理人在解决复杂现实任务方面的潜力，特别关注于编程教学这一挑战性问题。文中提出了一种新的代理工作流——Trace-and-Verify (TRAVER)，该方法结合知识追踪以估计学生的学习状态，并通过逐回合验证确保对学生完成编码任务的有效指导。同时，文章介绍了DICT，一种自动评估协议，它可以全面地通过控制学生模拟和代码生成测试来评估导师代理。实验结果显示了编程教学中的挑战以及TRAVER在成功率上的显著优势。尽管本文以编程教学为例，但其结果和发现可以推广到更广泛的领域，为各类任务的辅导代理人发展提供了有价值的见解。 <div>
arXiv:2502.13311v2 Announce Type: replace 
Abstract: Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized guidance in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To address this limitation, in this work, we focus on coding tutoring, a challenging problem that requires tutors to proactively guide students toward completing predefined coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER), which combines knowledge tracing to estimate a student's knowledge state and turn-by-turn verification to ensure effective guidance toward task completion. We introduce DICT, an automatic evaluation protocol that assesses tutor agents holistically using controlled student simulation and code generation tests. Extensive experiments reveal the challenges of coding tutoring and demonstrate that TRAVER achieves a significantly higher success rate. Although we use code tutoring as an example in this paper, our results and findings can be extended beyond coding, providing valuable insights into advancing tutoring agents for a variety of tasks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation</title>
<link>https://arxiv.org/abs/2502.13451</link>
<guid>https://arxiv.org/abs/2502.13451</guid>
<content:encoded><![CDATA[
<div> 关键词: Vision-and-language 导航, VLN, Annotated Semantic Map, ASM, MapNav

总结:
本文介绍了MapNav，一种用于视觉与语言导航（VLN）的新型端到端模型，该模型针对传统方法在决策过程中依赖大量历史观测数据导致的存储和计算负担问题进行了创新。MapNav利用Annotated Semantic Map（ASM）替代历史帧，通过构建和更新顶部视图下的语义地图并结合关键区域的明确文本标签，将抽象语义转化为清晰的导航线索。实验表明，MapNav在模拟和真实世界环境中均达到了最先进的性能，验证了其有效性。此外，作者计划开源ASM生成的源代码和数据集以保证可复现性，并认为MapNav可以作为VLN领域的一种新记忆表示方法，为未来研究铺平道路。 <div>
arXiv:2502.13451v2 Announce Type: replace 
Abstract: Vision-and-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to significant storage and computational overhead. In this paper, we introduce MapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map (ASM) to replace historical frames. Specifically, our approach constructs a top-down semantic map at the start of each episode and update it at each timestep, allowing for precise object mapping and structured navigation information. Then, we enhance this map with explicit textual labels for key regions, transforming abstract semantics into clear navigation cues and generate our ASM. MapNav agent using the constructed ASM as input, and use the powerful end-to-end capabilities of VLM to empower VLN. Extensive experiments demonstrate that MapNav achieves state-of-the-art (SOTA) performance in both simulated and real-world environments, validating the effectiveness of our method. Moreover, we will release our ASM generation source code and dataset to ensure reproducibility, contributing valuable resources to the field. We believe that our proposed MapNav can be used as a new memory representation method in VLN, paving the way for future research in this field.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title>
<link>https://arxiv.org/abs/2502.14282</link>
<guid>https://arxiv.org/abs/2502.14282</guid>
<content:encoded><![CDATA[
<div> 关键词: PC-Agent、MLLMs、Active Perception Module (APM)、Hierarchical multi-agent collaboration architecture、PC-Eval

总结:
本文提出了一种针对基于多模态预训练模型（MLLMs）的GUI代理框架——PC-Agent，该框架旨在解决PC场景中复杂交互环境和多应用工作流的问题。为了改善MLLMs在感知屏幕截图内容上的不足，文章设计了主动感知模块（APM）。在决策层面，提出了层次化的多代理协作架构，将决策过程分解为指令-子任务-动作三个层级，并设置了Manager、Progress、Decision及Reflection四个智能体分别负责指令分解、进度跟踪、逐步决策和错误反馈与调整。同时，文中引入了一个新的基准测试集PC-Eval，包含25条现实世界的复杂指令。实验结果显示，PC-Agent相比于现有最优方法，在任务成功率上绝对提升了32%。相关代码已开源，可在https://github.com/X-PLUG/MobileAgent/tree/main/PC-Agent获取。<br /><br /> <div>
arXiv:2502.14282v2 Announce Type: replace 
Abstract: In the field of MLLM-based GUI agents, compared to smartphones, the PC scenario not only features a more complex interactive environment, but also involves more intricate intra- and inter-app workflows. To address these issues, we propose a hierarchical agent framework named PC-Agent. Specifically, from the perception perspective, we devise an Active Perception Module (APM) to overcome the inadequate abilities of current MLLMs in perceiving screenshot content. From the decision-making perspective, to handle complex user instructions and interdependent subtasks more effectively, we propose a hierarchical multi-agent collaboration architecture that decomposes decision-making processes into Instruction-Subtask-Action levels. Within this architecture, three agents (i.e., Manager, Progress and Decision) are set up for instruction decomposition, progress tracking and step-by-step decision-making respectively. Additionally, a Reflection agent is adopted to enable timely bottom-up error feedback and adjustment. We also introduce a new benchmark PC-Eval with 25 real-world complex instructions. Empirical results on PC-Eval show that our PC-Agent achieves a 32% absolute improvement of task success rate over previous state-of-the-art methods. The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/PC-Agent.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</title>
<link>https://arxiv.org/abs/2502.14693</link>
<guid>https://arxiv.org/abs/2502.14693</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，蒙特卡洛树搜索 (MCTS)，内省式蒙特卡洛树搜索 (I-MCTS)，自动机器学习 (AutoML)，性能提升

总结:
本文提出了一种名为内省式蒙特卡洛树搜索（I-MCTS）的新方法，用于改进基于大型语言模型（LLMs）的代理在自动化机器学习任务中的低多样性与次优代码生成问题。I-MCTS通过分析父节点和兄弟节点的解决方案及结果进行迭代扩展，从而优化决策过程。此外，文中还结合了基于LLM的价值模型对每个节点的解决方案进行直接评估，并采用混合奖励机制，使Q值从LLM估算分数平滑过渡到实际性能分数，从而使高质量节点能更早被遍历。实验表明，相较于现有的开源AutoML代理，该方法在各种机器学习任务上实现了6%的绝对性能提升，证实了其在增强智能AutoML系统方面的有效性。相关资源可在https://github.com/jokieleung/I-MCTS找到。 <div>
arXiv:2502.14693v2 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. While recent work has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. In this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process. Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. This allows higher-quality nodes to be traversed earlier. Applied to the various ML tasks, our approach demonstrates a 6% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems. Resource available at https://github.com/jokieleung/I-MCTS
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Coordination across Diverse Applications: A Survey</title>
<link>https://arxiv.org/abs/2502.14743</link>
<guid>https://arxiv.org/abs/2502.14743</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协调、人工智能、统一理解、应用、研究方向

总结:
本文是对多智能体协调研究现状的综述，重点关注这一领域由于新兴应用和AI技术快速发展而受到的广泛关注。文章通过回答关于协调的四个基本问题（什么是协调、为何需要协调、与谁协调以及如何协调），提供了一个统一的理解框架。首先，文中识别并分析了各种应用场景中的基本协调问题；其次，调查了一系列多智能体系统应用，涵盖了从搜救、仓库自动化与物流、交通系统等传统领域到人形机器人、卫星系统和大规模语言模型等新兴领域。最后，文章讨论了MAS在可扩展性、异质性和学习机制等方面的开放挑战，并特别指出混合层次化与分布式协调、人-多智能体协调及基于LLM的多智能体系统是具有潜力的研究方向。 <div>
arXiv:2502.14743v2 Announce Type: replace 
Abstract: Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
</channel>
</rss>