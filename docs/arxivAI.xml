<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>

<item>
<title>Why do Experts Disagree on Existential Risk and P(doom)? A Survey of AI Experts</title>
<link>https://arxiv.org/abs/2502.14870</link>
<guid>https://arxiv.org/abs/2502.14870</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能安全、人工通用智能、风险认知、专家观点、概念熟悉度

<br>
总结:

本文对arXiv:2502.14870v1的研究进行了概述，该研究关注于人工智能安全领域的重要性和专家对其的认知。文章指出，人工通用智能（AGI）的发展可能成为人类历史上的重大技术进步，其潜在的安全风险被比作核战争一样的存在级威胁。尽管如此，有关AI安全和灾难性风险的研究经常受到质疑，甚至在专家群体中也不例外，并出现了部落化的争论现象。为了解决这一问题，研究者调查了111位AI专家对于AI安全概念的熟悉程度、他们对AI安全的主要反对意见以及对安全论点的反应。调查结果显示，AI专家的观点主要分为两类：“可控工具”视角和“不可控代理”视角，这两类观点在对AI安全重要性的看法上存在分歧。大多数专家（78%）同意或强烈赞同“技术型AI研究人员应关注存在级风险”，但许多人对具体的AI安全概念并不熟悉，例如，只有21%的受访专家听说过AI安全中的基本概念“工具性收敛”，即高级AI系统可能会追求一些共同的子目标（如自我保护）。而对AI安全最不担忧的参与者恰好是对这些概念最不熟悉的，这表明有效沟通AI安全问题应该从确立领域的清晰概念基础开始。 <div>
arXiv:2502.14870v1 Announce Type: new 
Abstract: The development of artificial general intelligence (AGI) is likely to be one of humanity's most consequential technological advancements. Leading AI labs and scientists have called for the global prioritization of AI safety citing existential risks comparable to nuclear war. However, research on catastrophic risks and AI alignment is often met with skepticism, even by experts. Furthermore, online debate over the existential risk of AI has begun to turn tribal (e.g. name-calling such as "doomer" or "accelerationist"). Until now, no systematic study has explored the patterns of belief and the levels of familiarity with AI safety concepts among experts. I surveyed 111 AI experts on their familiarity with AI safety concepts, key objections to AI safety, and reactions to safety arguments. My findings reveal that AI experts cluster into two viewpoints -- an "AI as controllable tool" and an "AI as uncontrollable agent" perspective -- diverging in beliefs toward the importance of AI safety. While most experts (78%) agreed or strongly agreed that "technical AI researchers should be concerned about catastrophic risks", many were unfamiliar with specific AI safety concepts. For example, only 21% of surveyed experts had heard of "instrumental convergence," a fundamental concept in AI safety predicting that advanced AI systems will tend to pursue common sub-goals (such as self-preservation). The least concerned participants were the least familiar with concepts like this, suggesting that effective communication of AI safety should begin with establishing clear conceptual foundations in the field.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoDiff: Conditional Diffusion Model for Collaborative 3D Object Detection</title>
<link>https://arxiv.org/abs/2502.14891</link>
<guid>https://arxiv.org/abs/2502.14891</guid>
<content:encoded><![CDATA[
<div> 关键词：协同3D对象检测、扩散模型、多智能体系统、噪声处理、自动驾驶

<br>
总结:
本文提出了一种名为CoDiff的新颖的鲁棒协同感知框架，用于解决自动驾驶领域中协同3D对象检测的问题。该框架首次将扩散模型应用于多智能体系统的协同感知，以应对由于姿态估计误差和时间延迟导致的信息融合中的空间和时间噪声问题。CoDiff利用预训练自编码器的潜在(latent)空间将高维特征图投影，并使每个个体代理信息作为条件引导扩散模型的采样过程，从而实现对粗略特征地图的去噪与融合特征的逐步细化。实验结果显示，无论是在模拟数据集还是真实世界数据集上，相较于现有相关方法，CoDiff在协同对象检测性能方面均表现出显著优势，并在具有高度噪声的代理姿态和延迟信息情况下展现出极高的鲁棒性。 <div>
arXiv:2502.14891v1 Announce Type: new 
Abstract: Collaborative 3D object detection holds significant importance in the field of autonomous driving, as it greatly enhances the perception capabilities of each individual agent by facilitating information exchange among multiple agents. However, in practice, due to pose estimation errors and time delays, the fusion of information across agents often results in feature representations with spatial and temporal noise, leading to detection errors. Diffusion models naturally have the ability to denoise noisy samples to the ideal data, which motivates us to explore the use of diffusion models to address the noise problem between multi-agent systems. In this work, we propose CoDiff, a novel robust collaborative perception framework that leverages the potential of diffusion models to generate more comprehensive and clearer feature representations. To the best of our knowledge, this is the first work to apply diffusion models to multi-agent collaborative perception. Specifically, we project high-dimensional feature map into the latent space of a powerful pre-trained autoencoder. Within this space, individual agent information serves as a condition to guide the diffusion model's sampling. This process denoises coarse feature maps and progressively refines the fused features. Experimental study on both simulated and real-world datasets demonstrates that the proposed framework CoDiff consistently outperforms existing relevant methods in terms of the collaborative object detection performance, and exhibits highly desired robustness when the pose and delay information of agents is with high-level noise.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EgoSpeak: Learning When to Speak for Egocentric Conversational Agents in the Wild</title>
<link>https://arxiv.org/abs/2502.14892</link>
<guid>https://arxiv.org/abs/2502.14892</guid>
<content:encoded><![CDATA[
<div> 关键词: EgoSpeak、实时语音启动预测、第一人称视角、RGB处理、在线处理、未修剪视频处理、YT-Conversation、EasyCom、Ego4D

总结:
本文介绍了EgoSpeak，这是一个针对第一人称视角下的实时语音启动预测的新框架，特别适用于需要持续观察环境并动态决定何时说话的人工智能对话代理。EgoSpeak结合了四个关键能力：第一人称视角、RGB处理、在线处理和未修剪视频处理，从而弥合了简化实验设置与复杂自然对话之间的差距。此外，文章还提出了YT-Conversation，一个来自YouTube的大规模野生对话视频数据集，用于预训练。实验证明，EgoSpeak在EasyCom和Ego4D数据集上的实时性能优于随机和基于沉默的基线，并突出了多模态输入和上下文长度对于有效决定何时说话的重要性。 <div>
arXiv:2502.14892v1 Announce Type: new 
Abstract: Predicting when to initiate speech in real-world environments remains a fundamental challenge for conversational agents. We introduce EgoSpeak, a novel framework for real-time speech initiation prediction in egocentric streaming video. By modeling the conversation from the speaker's first-person viewpoint, EgoSpeak is tailored for human-like interactions in which a conversational agent must continuously observe its environment and dynamically decide when to talk. Our approach bridges the gap between simplified experimental setups and complex natural conversations by integrating four key capabilities: (1) first-person perspective, (2) RGB processing, (3) online processing, and (4) untrimmed video processing. We also present YT-Conversation, a diverse collection of in-the-wild conversational videos from YouTube, as a resource for large-scale pretraining. Experiments on EasyCom and Ego4D demonstrate that EgoSpeak outperforms random and silence-based baselines in real time. Our results also highlight the importance of multimodal input and context length in effectively deciding when to speak.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenSearch-SQL: Enhancing Text-to-SQL with Dynamic Few-shot and Consistency Alignment</title>
<link>https://arxiv.org/abs/2502.14913</link>
<guid>https://arxiv.org/abs/2502.14913</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、大型语言模型、Text-to-SQL任务、OpenSearch-SQL、SQL-Like、中间语言、一致性对齐机制、结构化CoT优化、动态少样本策略、执行精度、有效性、效率

总结:<br>
本文提出了针对Text-to-SQL任务的OpenSearch-SQL框架，旨在解决多智能体协作大型语言模型在该任务中面临的指导指令遵循失败和模型幻想等问题。该框架将任务分为预处理、抽取、生成、细化以及基于一致性对齐机制的对齐模块五个主要部分。同时，文章设计了一种名为SQL-Like的中间语言并优化了基于此语言的结构化CoT。此外，还提出了一种动态少样本自教Query-CoT-SQL策略。实验结果显示，OpenSearch-SQL在BIRD开发集上的执行精度达到69.3%，测试集为72.28%，并且以69.36%的奖励基有效性效率得分在提交时均位列第一，充分证明了所提方法在有效性和效率上的综合优势。 <div>
arXiv:2502.14913v1 Announce Type: new 
Abstract: Although multi-agent collaborative Large Language Models (LLMs) have achieved significant breakthroughs in the Text-to-SQL task, their performance is still constrained by various factors. These factors include the incompleteness of the framework, failure to follow instructions, and model hallucination problems. To address these problems, we propose OpenSearch-SQL, which divides the Text-to-SQL task into four main modules: Preprocessing, Extraction, Generation, and Refinement, along with an Alignment module based on a consistency alignment mechanism. This architecture aligns the inputs and outputs of agents through the Alignment module, reducing failures in instruction following and hallucination. Additionally, we designed an intermediate language called SQL-Like and optimized the structured CoT based on SQL-Like. Meanwhile, we developed a dynamic few-shot strategy in the form of self-taught Query-CoT-SQL. These methods have significantly improved the performance of LLMs in the Text-to-SQL task.
  In terms of model selection, we directly applied the base LLMs without any post-training, thereby simplifying the task chain and enhancing the framework's portability. Experimental results show that OpenSearch-SQL achieves an execution accuracy(EX) of 69.3% on the BIRD development set, 72.28% on the test set, and a reward-based validity efficiency score (R-VES) of 69.36%, with all three metrics ranking first at the time of submission. These results demonstrate the comprehensive advantages of the proposed method in both effectiveness and efficiency.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CyberSentinel: An Emergent Threat Detection System for AI Security</title>
<link>https://arxiv.org/abs/2502.14966</link>
<guid>https://arxiv.org/abs/2502.14966</guid>
<content:encoded><![CDATA[
<div> 关键词：CyberSentinel、人工智能、安全威胁、防御策略、机器学习

<br><br>总结：
本文介绍了CyberSentinel，这是一个针对人工智能驱动的安全威胁提出的统一、单代理的实时新兴威胁检测系统。CyberSentinel通过SSH日志分析实现暴力攻击检测；利用域名黑名单和启发式URL评分方法进行钓鱼威胁评估；并通过基于机器学习的异常检测技术实现实时的新型威胁检测。通过不断适应敌对战术的变化，CyberSentinel强化了主动的网络安全防御，有效解决了AI安全中的关键漏洞问题。 <div>
arXiv:2502.14966v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence (AI) has significantly expanded the attack surface for AI-driven cybersecurity threats, necessitating adaptive defense strategies. This paper introduces CyberSentinel, a unified, single-agent system for emergent threat detection, designed to identify and mitigate novel security risks in real time. CyberSentinel integrates: (1) Brute-force attack detection through SSH log analysis, (2) Phishing threat assessment using domain blacklists and heuristic URL scoring, and (3) Emergent threat detection via machine learning-based anomaly detection. By continuously adapting to evolving adversarial tactics, CyberSentinel strengthens proactive cybersecurity defense, addressing critical vulnerabilities in AI security.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Socratic RAG Approach to Connect Natural Language Queries on Research Topics with Knowledge Organization Systems</title>
<link>https://arxiv.org/abs/2502.15005</link>
<guid>https://arxiv.org/abs/2502.15005</guid>
<content:encoded><![CDATA[
<div> 关键词：Retrieval Augmented Generation (RAG)，Socratic dialogue，Knowledge Organization Systems (KOSs)，学术税onomies，CollabNext

<br>
<br>
总结:
本文提出了一种名为Retrieval Augmented Generation (RAG)的智能代理，该代理利用自然语言查询将研究主题映射到精确、机器可解释的语义实体。RAG与苏格拉底式对话相结合，使得用户对研究话题的直观理解能与已建立的知识组织系统(KOSs)保持一致，从而有效地连接了“小语义”（领域特定的KOS结构）与“大语义”（广泛的引文计量库），使复杂的学术分类体系更易访问。文中通过一个名为CollabNext的应用示例进行了说明，这是一个以人为中心的知识图谱，连接人、组织和研究主题，特别关注 Historically Black Colleges and Universities (HBCUs) 和新兴研究人员，旨在提高历史上在现行科学体系中被边缘化的人群的可见性。 <div>
arXiv:2502.15005v1 Announce Type: new 
Abstract: In this paper, we propose a Retrieval Augmented Generation (RAG) agent that maps natural language queries about research topics to precise, machine-interpretable semantic entities. Our approach combines RAG with Socratic dialogue to align a user's intuitive understanding of research topics with established Knowledge Organization Systems (KOSs). The proposed approach will effectively bridge "little semantics" (domain-specific KOS structures) with "big semantics" (broad bibliometric repositories), making complex academic taxonomies more accessible. Such agents have the potential for broad use. We illustrate with a sample application called CollabNext, which is a person-centric knowledge graph connecting people, organizations, and research topics. We further describe how the application design has an intentional focus on HBCUs and emerging researchers to raise visibility of people historically rendered invisible in the current science system.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Voter Model Meets Rumour Spreading: A Study of Consensus Protocols on Graphs with Agnostic Nodes [Extended Version]</title>
<link>https://arxiv.org/abs/2502.15029</link>
<guid>https://arxiv.org/abs/2502.15029</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、共识问题、无初始意见节点、投票模型、谣言传播

总结:
本文关注了在多智能体系统中存在无初始意见节点的共识问题，提出了一种称为“无知”节点的共识问题变体，并将其框架设定为投票模型和谣言传播两种已知过程的结合。文章主要贡献包括：<br>
1. 建立了一个描述给定颜色达成共识概率的鞅；<br>
2. 利用谣言传播和投票模型的结果给出了过程终止所需步骤数的界限；<br>
3. 求解了一些特殊情况下达成共识的概率的封闭形式公式；<br>
4. 针对一般图与Erdős-Rényi图，通过Markov链蒙特卡洛过程估计共识概率的计算复杂度分别为$O(n^2 \log n)$和$O(n\log n)$，表明该方法在估算概率上具有高效性；<br>
5. 进一步提供了实验结果，表明随着节点数量增加，为了达到给定标准误差所需的运行次数会减少。 <div>
arXiv:2502.15029v1 Announce Type: new 
Abstract: Problems of consensus in multi-agent systems are often viewed as a series of independent, simultaneous local decisions made between a limited set of options, all aimed at reaching a global agreement. Key challenges in these protocols include estimating the likelihood of various outcomes and finding bounds for how long it may take to achieve consensus, if it occurs at all.
  To date, little attention has been given to the case where some agents have no initial opinion. In this paper, we introduce a variant of the consensus problem which includes what we call `agnostic' nodes and frame it as a combination of two known and well-studied processes: voter model and rumour spreading. We show (1) a martingale that describes the probability of consensus for a given colour, (2) bounds on the number of steps for the process to end using results from rumour spreading and voter models, (3) closed formulas for the probability of consensus in a few special cases, and (4) that the computational complexity of estimating the probability with a Markov chain Monte Carlo process is $O(n^2 \log n)$ for general graphs and $O(n\log n)$ for Erd\H{o}s-R\'enyi graphs, which makes it an efficient method for estimating probabilities of consensus. Furthermore, we present experimental results suggesting that the number of runs needed for a given standard error decreases when the number of nodes increases.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Is Safety Standard Same for Everyone? User-Specific Safety Evaluation of Large Language Models</title>
<link>https://arxiv.org/abs/2502.15086</link>
<guid>https://arxiv.org/abs/2502.15086</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 安全性, 用户特定标准, U-SAFEBENCH, 链式思考

<br><br>总结:
随着大型语言模型（LLM）的应用日益广泛，其安全性漏洞问题愈发凸显。现有的安全基准测试主要依据通用标准来定义安全性，而忽视了用户特定的安全需求。文章指出，LLM的安全标准应根据用户的特定需求而非普适一致。为填补这一研究空白，作者提出了U-SAFEBENCH，这是首个用于评估LLM用户特定安全性方面的基准。对18款常用LLM进行的评价显示，当前的LLM在考虑用户特定安全标准时无法确保安全。针对此问题，作者提出了一种基于链式思考的简单改进方案，并证实其能有效提升用户特定的安全性。相关benchmark和代码已在https://github.com/yeonjun-in/U-SafeBench上公开。 <div>
arXiv:2502.15086v1 Announce Type: new 
Abstract: As the use of large language model (LLM) agents continues to grow, their safety vulnerabilities have become increasingly evident. Extensive benchmarks evaluate various aspects of LLM safety by defining the safety relying heavily on general standards, overlooking user-specific standards. However, safety standards for LLM may vary based on a user-specific profiles rather than being universally consistent across all users. This raises a critical research question: Do LLM agents act safely when considering user-specific safety standards? Despite its importance for safe LLM use, no benchmark datasets currently exist to evaluate the user-specific safety of LLMs. To address this gap, we introduce U-SAFEBENCH, the first benchmark designed to assess user-specific aspect of LLM safety. Our evaluation of 18 widely used LLMs reveals current LLMs fail to act safely when considering user-specific safety standards, marking a new discovery in this field. To address this vulnerability, we propose a simple remedy based on chain-of-thought, demonstrating its effectiveness in improving user-specific safety. Our benchmark and code are available at https://github.com/yeonjun-in/U-SafeBench.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CurricuVLM: Towards Safe Autonomous Driving via Personalized Safety-Critical Curriculum Learning with Vision-Language Models</title>
<link>https://arxiv.org/abs/2502.15119</link>
<guid>https://arxiv.org/abs/2502.15119</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶系统、安全、 Vision-Language 模型、个性化课程学习、CurricuVLM

总结:
本文提出了一个名为 CurricuVLM 的新框架，旨在通过利用 Vision-Language 模型（VLMs）来增强自动驾驶代理的安全性。针对当前研究中对于如何将安全关键场景有效地整合到政策学习以及适应自动驾驶行为模式和性能瓶颈的训练课程开发中存在的局限，CurricuVLM 利用 VLMs 的多模态理解能力分析自动驾驶车辆的行为，识别性能弱点，并动态生成针对性的训练场景进行课程适应。通过对不安全驾驶情况的深入描述和推理，该框架能评估自动驾驶系统的性能并识别关键行为模式。实验结果显示，CurricuVLM 在 Waymo Open Motion 数据集上的表现优于现有最佳基线，在常规和安全关键场景中均表现出较高的导航成功率、驾驶效率和安全性指标。此外，CurricuVLM 被证明是一种可以与多种强化学习算法集成的一般方法，以进一步提升自动驾驶系统的能力。相关代码和演示视频可在项目主页上获取。 <div>
arXiv:2502.15119v1 Announce Type: new 
Abstract: Ensuring safety in autonomous driving systems remains a critical challenge, particularly in handling rare but potentially catastrophic safety-critical scenarios. While existing research has explored generating safety-critical scenarios for autonomous vehicle (AV) testing, there is limited work on effectively incorporating these scenarios into policy learning to enhance safety. Furthermore, developing training curricula that adapt to an AV's evolving behavioral patterns and performance bottlenecks remains largely unexplored. To address these challenges, we propose CurricuVLM, a novel framework that leverages Vision-Language Models (VLMs) to enable personalized curriculum learning for autonomous driving agents. Our approach uniquely exploits VLMs' multimodal understanding capabilities to analyze agent behavior, identify performance weaknesses, and dynamically generate tailored training scenarios for curriculum adaptation. Through comprehensive analysis of unsafe driving situations with narrative descriptions, CurricuVLM performs in-depth reasoning to evaluate the AV's capabilities and identify critical behavioral patterns. The framework then synthesizes customized training scenarios targeting these identified limitations, enabling effective and personalized curriculum learning. Extensive experiments on the Waymo Open Motion Dataset show that CurricuVLM outperforms state-of-the-art baselines across both regular and safety-critical scenarios, achieving superior performance in terms of navigation success, driving efficiency, and safety metrics. Further analysis reveals that CurricuVLM serves as a general approach that can be integrated with various RL algorithms to enhance autonomous driving systems. The code and demo video are available at: https://zihaosheng.github.io/CurricuVLM/.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating the Adaptive Robustness with Knowledge Conflicts in LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.15153</link>
<guid>https://arxiv.org/abs/2502.15153</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，多智能体系统(MASs)，知识冲突，鲁棒性，自我修复能力

<br><br>总结：
本文研究了大型语言模型（LLMs）在多智能体系统（MASs）中的应用及其面对知识冲突时的鲁棒性。文章设计了四个综合指标来探究MASs在面临轻微或任务关键型知识冲突时的表现。研究发现，轻微的知识冲突不会损害系统的鲁棒性，反而能促进协同决策。而对于嵌入任务关键型知识冲突的情况，MASs展现出较强的鲁棒性，影响甚微，并具有一定的自我修复能力，通过减少对冲突知识的依赖和采纳替代解决方案路径以维持稳定性。此外，通过对知识冲突数量、智能体数量及交互轮数的消融研究，发现MASs的自我修复能力存在内在限制，而以上所有结论在各种因素下均保持一致。相关代码已公开发布在https://github.com/wbw625/MultiAgentRobustness。 <div>
arXiv:2502.15153v1 Announce Type: new 
Abstract: Recent advances in Large Language Models (LLMs) have upgraded them from sophisticated text generators to autonomous agents capable of corporation and tool use in multi-agent systems (MASs). However, the robustness of these LLM-based MASs, especially under knowledge conflicts, remains unclear. In this paper, we design four comprehensive metrics to investigate the robustness of MASs when facing mild or task-critical knowledge conflicts. We first analyze mild knowledge conflicts introduced by heterogeneous agents and find that they do not harm system robustness but instead improve collaborative decision-making. Next, we investigate task-critical knowledge conflicts by synthesizing knowledge conflicts and embedding them into one of the agents. Our results show that these conflicts have surprisingly little to no impact on MAS robustness. Furthermore, we observe that MASs demonstrate certain self-repairing capabilities by reducing their reliance on knowledge conflicts and adopting alternative solution paths to maintain stability. Finally, we conduct ablation studies on the knowledge conflict number, agent number, and interaction rounds, finding that the self-repairing capability of MASs has intrinsic limits, and all findings hold consistently across various factors. Our code is publicly available at https://github.com/wbw625/MultiAgentRobustness.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OccProphet: Pushing Efficiency Frontier of Camera-Only 4D Occupancy Forecasting with Observer-Forecaster-Refiner Framework</title>
<link>https://arxiv.org/abs/2502.15180</link>
<guid>https://arxiv.org/abs/2502.15180</guid>
<content:encoded><![CDATA[
<div> 关键词：OccProphet、占用率预测、自动驾驶、轻量化、效率提升

<br><br>总结:
本文提出了一种名为OccProphet的新颖框架，用于高效且准确地学习占用率预测，尤其适用于复杂交通环境中的自动驾驶。该框架由三个轻量级组件组成：Observer、Forecaster和Refiner。OccProphet利用提出的“三重注意力融合”的高效4D聚合从3D多帧体素中提取时空特征。相比最先进的Cam4DOcc，OccProphet在训练和推理阶段显著降低了58%\~78%的计算成本，速度提升了2.6倍。同时，其在nuScenes、Lyft-Level5和nuScenes-Occupancy数据集上的实验结果显示，OccProphet的预测精度相对提高了4%\~18%。相关的代码和模型已在GitHub上公开可用。 <div>
arXiv:2502.15180v1 Announce Type: new 
Abstract: Predicting variations in complex traffic environments is crucial for the safety of autonomous driving. Recent advancements in occupancy forecasting have enabled forecasting future 3D occupied status in driving environments by observing historical 2D images. However, high computational demands make occupancy forecasting less efficient during training and inference stages, hindering its feasibility for deployment on edge agents. In this paper, we propose a novel framework, i.e., OccProphet, to efficiently and effectively learn occupancy forecasting with significantly lower computational requirements while improving forecasting accuracy. OccProphet comprises three lightweight components: Observer, Forecaster, and Refiner. The Observer extracts spatio-temporal features from 3D multi-frame voxels using the proposed Efficient 4D Aggregation with Tripling-Attention Fusion, while the Forecaster and Refiner conditionally predict and refine future occupancy inferences. Experimental results on nuScenes, Lyft-Level5, and nuScenes-Occupancy datasets demonstrate that OccProphet is both training- and inference-friendly. OccProphet reduces 58\%$\sim$78\% of the computational cost with a 2.6$\times$ speedup compared with the state-of-the-art Cam4DOcc. Moreover, it achieves 4\%$\sim$18\% relatively higher forecasting accuracy. Code and models are publicly available at https://github.com/JLChen-C/OccProphet.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Hardness of the Drone Delivery Problem</title>
<link>https://arxiv.org/abs/2502.15194</link>
<guid>https://arxiv.org/abs/2502.15194</guid>
<content:encoded><![CDATA[
<div> 关键词：物流、快速配送、路径优化、无人机送货问题、复杂度理论

总结:
本文研究了现代物流中的关键问题——快速配送和高效路由，特别关注于利用一组具有特定移动能力和速度的协作代理（如无人机）在图中实现从源节点到目标节点的包裹递送问题。文章提出了一种名为基于交付时间的无人机送货问题（DDT）。对于DDT在直线图上并预先设定无人机起始位置的情况，文中证明即使只考虑两种速度的无人机，该问题也是NP-难的，这细化了Erlebach等人之前的工作。接着，作者探讨了在无预设初始位置的网格图上，每架无人机可以自由选择起始位置的情况，进一步证明此问题难以在n的$(1-\varepsilon)$次幂因子内进行近似求解，其中n为网格大小，即使所有无人机的速度被限制为两种以及只能在矩形区域内移动。最后，文中提供了一个简单的$O(n)$近似算法。 <div>
arXiv:2502.15194v1 Announce Type: new 
Abstract: Fast shipping and efficient routing are key problems of modern logistics. Building on previous studies that address package delivery from a source node to a destination within a graph using multiple agents (such as vehicles, drones, and ships), we investigate the complexity of this problem in specialized graphs and with restricted agent types, both with and without predefined initial positions. Particularly, in this paper, we aim to minimize the delivery time for delivering a package. To achieve this, we utilize a set of collaborative agents, each capable of traversing a specific subset of the graph and operating at varying speeds. This challenge is encapsulated in the recently introduced Drone Delivery Problem with respect to delivery time (DDT).
  In this work, we show that the DDT with predefined initial positions on a line is NP-hard, even when considering only agents with two distinct speeds. This refines the results presented by Erlebach, et al.[ELS22], who demonstrated the NP-hardness of DDT on a line with agents of arbitrary speeds. Additionally, we examine DDT in grid graphs without predefined initial positions, where each drone can freely choose its starting position. We show that the problem is NP-hard to approximate within a factor of $O(n^{1-\varepsilon}$), where $n$ is the size of the grid, even when all agents are restricted to two different speeds as well as rectangular movement areas. We conclude by providing an easy $O(n)$ approximation algorithm.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Measuring AI agent autonomy: Towards a scalable approach with code inspection</title>
<link>https://arxiv.org/abs/2502.15212</link>
<guid>https://arxiv.org/abs/2502.15212</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、自主性评估、运行时评估、代码基础评估、AutoGen框架

总结:
该文提出了一个新的AI代理自主性评估方法，旨在通过代码基础评估来降低依赖于运行时评估的成本和风险。此方法关注自主性的两个属性：影响与监督，并通过对AI代理运行所使用的编排代码进行评分实现这一框架。文章以AutoGen框架及其应用为例进行了展示。这种方式提供了一种新的、无需实际执行特定任务就能评估AI代理自主水平的方法。 <div>
arXiv:2502.15212v1 Announce Type: new 
Abstract: AI agents are AI systems that can achieve complex goals autonomously. Assessing the level of agent autonomy is crucial for understanding both their potential benefits and risks. Current assessments of autonomy often focus on specific risks and rely on run-time evaluations -- observations of agent actions during operation. We introduce a code-based assessment of autonomy that eliminates the need to run an AI agent to perform specific tasks, thereby reducing the costs and risks associated with run-time evaluations. Using this code-based framework, the orchestration code used to run an AI agent can be scored according to a taxonomy that assesses attributes of autonomy: impact and oversight. We demonstrate this approach with the AutoGen framework and select applications.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Evolving Landscape of LLM- and VLM-Integrated Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15214</link>
<guid>https://arxiv.org/abs/2502.15214</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习(RL), 大规模语言模型(LLMs), 视觉-语言模型(VLMs), 决策制定, 程序分类

总结:
本文回顾了强化学习（RL）领域中大规模语言模型（LLMs）和视觉-语言模型（VLMs）的应用研究进展。这些模型被用来克服RL中的关键挑战，如缺乏先验知识、长时规划和奖励设计问题。文章提出了一种将LLM/VLM辅助的RL方法分为代理、规划器和奖励三个角色的分类体系。进一步探讨了未来的研究方向，包括接地问题、偏见缓解、改进表示以及行动建议。通过整合现有研究成果并指明未来发展方向，该调查为将LLMs和VLMs融入RL提供了一个框架，推动了自然语言和视觉理解与序列决策制定相结合的方法论发展。<br><br> <div>
arXiv:2502.15214v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has shown impressive results in sequential decision-making tasks. Meanwhile, Large Language Models (LLMs) and Vision-Language Models (VLMs) have emerged, exhibiting impressive capabilities in multimodal understanding and reasoning. These advances have led to a surge of research integrating LLMs and VLMs into RL. In this survey, we review representative works in which LLMs and VLMs are used to overcome key challenges in RL, such as lack of prior knowledge, long-horizon planning, and reward design. We present a taxonomy that categorizes these LLM/VLM-assisted RL approaches into three roles: agent, planner, and reward. We conclude by exploring open problems, including grounding, bias mitigation, improved representations, and action advice. By consolidating existing research and identifying future directions, this survey establishes a framework for integrating LLMs and VLMs into RL, advancing approaches that unify natural language and visual understanding with sequential decision-making.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ESPnet-SpeechLM: An Open Speech Language Model Toolkit</title>
<link>https://arxiv.org/abs/2502.15218</link>
<guid>https://arxiv.org/abs/2502.15218</guid>
<content:encoded><![CDATA[
<div> 关键词: ESPnet-SpeechLM、开放工具包、语音语言模型、开发流程、灵活性

总结:
ESPnet-SpeechLM 是一个旨在推动语音语言模型（SpeechLM）和语音驱动的代理应用程序开发民主化的开源工具包。该工具包通过将语音处理任务统一框架为普遍的序列建模问题，涵盖了从数据预处理、预训练、推理到任务评估的一体化工作流。用户可以轻松定义任务模板并配置关键设置，实现SpeechLM开发的无缝和流畅。ESPnet-SpeechLM 在整个工作流中的每个阶段都提供了高度可配置的模块，确保了灵活性、效率和可扩展性。文章通过多个使用案例展示了如何利用ESPnet-SpeechLM构建具有竞争力的SpeechLM，包括一个在文本和语音任务上预训练的拥有17亿参数的模型，并在各种基准测试中表现出色。该工具包及其配方完全透明且可在https://github.com/espnet/espnet/tree/speechlm 复制和重现。 <div>
arXiv:2502.15218v1 Announce Type: new 
Abstract: We present ESPnet-SpeechLM, an open toolkit designed to democratize the development of speech language models (SpeechLMs) and voice-driven agentic applications. The toolkit standardizes speech processing tasks by framing them as universal sequential modeling problems, encompassing a cohesive workflow of data preprocessing, pre-training, inference, and task evaluation. With ESPnet-SpeechLM, users can easily define task templates and configure key settings, enabling seamless and streamlined SpeechLM development. The toolkit ensures flexibility, efficiency, and scalability by offering highly configurable modules for every stage of the workflow. To illustrate its capabilities, we provide multiple use cases demonstrating how competitive SpeechLMs can be constructed with ESPnet-SpeechLM, including a 1.7B-parameter model pre-trained on both text and speech tasks, across diverse benchmarks. The toolkit and its recipes are fully transparent and reproducible at: https://github.com/espnet/espnet/tree/speechlm.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Auto-Bench: An Automated Benchmark for Scientific Discovery in LLMs</title>
<link>https://arxiv.org/abs/2502.15224</link>
<guid>https://arxiv.org/abs/2502.15224</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，科学发现，Auto-Bench，因果图发现，GPT-4

总结:
本文探讨了大型语言模型（LLMs）能否实现类似人类的科学研究和新知识发现，以及作为AI科学家的可能性。针对目前缺乏专门针对LLM代理进行科学发现评估的标准基准问题，文章提出了一个新的基准——“Auto-Bench”，该基准基于因果图发现原理，要求模型揭示隐藏结构并作出最佳决策，同时生成有效的推理依据。通过与虚拟导师的交互式互动，模型能逐步改进对基础相互作用的理解，包括化学和社会互动。文中评估了包括GPT-4、Gemini、Qwen、Claude和Llama在内的最新LLM，并观察到随着问题复杂性的增加，模型的表现显著下降，这表明机器智能与人类智能之间存在重要差距，未来LLM的发展需要对此加以考虑。 <div>
arXiv:2502.15224v1 Announce Type: new 
Abstract: Given the remarkable performance of Large Language Models (LLMs), an important question arises: Can LLMs conduct human-like scientific research and discover new knowledge, and act as an AI scientist? Scientific discovery is an iterative process that demands efficient knowledge updating and encoding. It involves understanding the environment, identifying new hypotheses, and reasoning about actions; however, no standardized benchmark specifically designed for scientific discovery exists for LLM agents. In response to these limitations, we introduce a novel benchmark, \textit{Auto-Bench}, that encompasses necessary aspects to evaluate LLMs for scientific discovery in both natural and social sciences. Our benchmark is based on the principles of causal graph discovery. It challenges models to uncover hidden structures and make optimal decisions, which includes generating valid justifications. By engaging interactively with an oracle, the models iteratively refine their understanding of underlying interactions, the chemistry and social interactions, through strategic interventions. We evaluate state-of-the-art LLMs, including GPT-4, Gemini, Qwen, Claude, and Llama, and observe a significant performance drop as the problem complexity increases, which suggests an important gap between machine and human intelligence that future development of LLMs need to take into consideration.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-agent Multi-armed Bandits with Minimum Reward Guarantee Fairness</title>
<link>https://arxiv.org/abs/2502.15240</link>
<guid>https://arxiv.org/abs/2502.15240</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理多臂老虎机问题、社会福利最大化、公平性、RewardFairUCB算法、上界信心边界

总结:
本文研究了在多代理多臂老虎机（MA-MAB）场景下，如何在确保公平性的前提下最大化社会福利。文章提出了名为RewardFairUCB的新算法，该算法利用上界信心边界（UCB）技术实现了对公平性和社会福利两方面的次线性遗憾界限。具体来说，该算法能实现实例无关的社会福利遗憾上界为$\tilde{O}(T^{1/2})$和公平性遗憾上界为$\tilde{O}(T^{3/4})$。同时，文中证明了社会福利和公平性遗憾的下界均为$\Omega(\sqrt{T})$。通过模拟数据和真实世界数据的实验评估，揭示了RewardFairUCB算法在公平性和社会福利遗憾之间的权衡关系。 <div>
arXiv:2502.15240v1 Announce Type: new 
Abstract: We investigate the problem of maximizing social welfare while ensuring fairness in a multi-agent multi-armed bandit (MA-MAB) setting. In this problem, a centralized decision-maker takes actions over time, generating random rewards for various agents. Our goal is to maximize the sum of expected cumulative rewards, a.k.a. social welfare, while ensuring that each agent receives an expected reward that is at least a constant fraction of the maximum possible expected reward.
  Our proposed algorithm, RewardFairUCB, leverages the Upper Confidence Bound (UCB) technique to achieve sublinear regret bounds for both fairness and social welfare. The fairness regret measures the positive difference between the minimum reward guarantee and the expected reward of a given policy, whereas the social welfare regret measures the difference between the social welfare of the optimal fair policy and that of the given policy.
  We show that RewardFairUCB algorithm achieves instance-independent social welfare regret guarantees of $\tilde{O}(T^{1/2})$ and a fairness regret upper bound of $\tilde{O}(T^{3/4})$. We also give the lower bound of $\Omega(\sqrt{T})$ for both social welfare and fairness regret. We evaluate RewardFairUCB's performance against various baseline and heuristic algorithms using simulated data and real world data, highlighting trade-offs between fairness and social welfare regrets.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real-Time Moving Flock Detection in Pedestrian Trajectories Using Sequential Deep Learning Models</title>
<link>https://arxiv.org/abs/2502.15252</link>
<guid>https://arxiv.org/abs/2502.15252</guid>
<content:encoded><![CDATA[
<div> 关键词：集体行人运动、深度学习模型、递归神经网络（RNN）、长短期记忆网络（LSTM）、Transformer<br><br>总结:<br>
本文研究了利用序列深度学习模型，包括递归神经网络（RNN）、长短时记忆（LSTM）网络和Transformer，对多行人轨迹进行实时群体检测的方法。该方法分为两个阶段：首先使用预训练的二分类模型进行双人轨迹分类；其次，将学到的表示应用于动态识别多Agent群体。通过实际的群体移动数据集验证了该方法的鲁棒性，无论序列长度如何变化以及运动模式多么多样，都能稳定、准确地检测出行人群体。此外，该方法还被扩展到识别其他形式的集体运动，如车队和群集，为进一步的多Agent行为分析铺平道路。 <div>
arXiv:2502.15252v1 Announce Type: new 
Abstract: Understanding collective pedestrian movement is crucial for applications in crowd management, autonomous navigation, and human-robot interaction. This paper investigates the use of sequential deep learning models, including Recurrent Neural Networks (RNNs), Long Short-Term Memory (LSTM) networks, and Transformers, for real-time flock detection in multi-pedestrian trajectories. Our proposed approach consists of a two-stage process: first, a pre-trained binary classification model is used for pairwise trajectory classification, and second, the learned representations are applied to identify multi-agent flocks dynamically.
  We validate our method using real-world group movement datasets, demonstrating its robustness across varying sequence lengths and diverse movement patterns. Experimental results indicate that our model consistently detects pedestrian flocks with high accuracy and stability, even in dynamic and noisy environments. Furthermore, we extend our approach to identify other forms of collective motion, such as convoys and swarms, paving the way for more comprehensive multi-agent behavior analysis.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards a Reward-Free Reinforcement Learning Framework for Vehicle Control</title>
<link>https://arxiv.org/abs/2502.15262</link>
<guid>https://arxiv.org/abs/2502.15262</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 车辆控制, 奖励信号, 无奖励强化学习框架, 目标状态预测网络<br><br>总结:<br>
本文提出了一个无奖励强化学习框架(RFRLF)，旨在解决车辆控制中依赖于手动设计奖励信号和需要高质量专家行为的问题。该框架包括目标状态预测网络(TSPN)和无奖励状态引导策略网络(RFSGPN)，能够直接学习目标状态以优化代理行为，无需显式奖励信号。具体而言，通过最小化预测状态与专家状态之间的差异来训练策略网络。实验结果表明，提出的RFRLF在车辆驾驶控制方面表现出优越性，提高了学习效率并适应了无奖励环境。 <div>
arXiv:2502.15262v1 Announce Type: new 
Abstract: Reinforcement learning plays a crucial role in vehicle control by guiding agents to learn optimal control strategies through designing or learning appropriate reward signals. However, in vehicle control applications, rewards typically need to be manually designed while considering multiple implicit factors, which easily introduces human biases. Although imitation learning methods does not rely on explicit reward signals, they necessitate high-quality expert actions, which are often challenging to acquire. To address these issues, we propose a reward-free reinforcement learning framework (RFRLF). This framework directly learns the target states to optimize agent behavior through a target state prediction network (TSPN) and a reward-free state-guided policy network (RFSGPN), avoiding the dependence on manually designed reward signals. Specifically, the policy network is learned via minimizing the differences between the predicted state and the expert state. Experimental results demonstrate the effectiveness of the proposed RFRLF in controlling vehicle driving, showing its advantages in improving learning efficiency and adapting to reward-free environments.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leader-Follower Formation Tracking Control of Quadrotor UAVs Using Bearing Measurements</title>
<link>https://arxiv.org/abs/2502.15303</link>
<guid>https://arxiv.org/abs/2502.15303</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式形成跟踪控制、四旋翼飞行器、有限传感器集、相对测量、碰撞避免

总结:

本文研究了在具有放松感知图拓扑结构和极其有限传感器设置下，一组四旋翼飞行器的分布式队形跟踪控制问题。仅有一台领导飞行器能够获取全局位置信息，而其他飞行器仅能获得与其邻近代理之间的方向测量数据和相对速度信息。文章提出了一种层次化的控制架构，每个四旋翼飞行器结合高增益姿态内环控制器与带有碰撞避免功能的基于方位角的队形控制器。该方法使一组四旋翼飞行器能够在保持对至少一个相邻飞行器的相对测量的同时，实现对任意方位角持续激发的预定队形跟踪，包括随时间变化的形状和旋转机动。通过MATLAB数值模拟和实际三台四旋翼飞行器的实验验证了该控制策略的有效性。 <div>
arXiv:2502.15303v1 Announce Type: new 
Abstract: This work addresses the practical problem of distributed formation tracking control of a group of quadrotor vehicles in a relaxed sensing graph topology with a very limited sensor set, where only one leader vehicle can access the global position. Other vehicles in the formation are assumed to only have access to inter-agent bearing (direction) measurements and relative velocities with respect to their neighbor agents. A hierarchical control architecture is adopted for each quadrotor, combining a high-gain attitude inner-loop and an outer-loop bearing-based formation controller with collision avoidance augmentation. The proposed method enables a group of quadrotors to track arbitrary bearing persistently exciting desired formations, including time-varying shapes and rotational maneuvers, such that each quadrotor only requires relative measurements to at least one neighboring quadrotor. The effective performance of the control strategy is validated by numerical simulations in MATLAB and real-world experiments with three quadrotors.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DynamicGSG: Dynamic 3D Gaussian Scene Graphs for Environment Adaptation</title>
<link>https://arxiv.org/abs/2502.15309</link>
<guid>https://arxiv.org/abs/2502.15309</guid>
<content:encoded><![CDATA[
<div> 关键词: DynamicGSG、环境变化、场景图生成、高保真重建、动态更新

总结:<br>
本文提出了一种名为DynamicGSG的系统，用于应对由代理人或人类活动引起的环境中变化带来的挑战，使机器人更好地理解和适应动态环境。该系统包含三个关键组成部分：(1)利用先进的视觉基础模型构建层次化的场景图，以表示环境中物体的空间和语义关系；(2)设计了联合特征损失，优化高保真增量重建的高斯映射；(3)根据实际环境变化更新高斯映射和场景图，实现长期环境适应。实验和消融研究验证了所提方法在语义分割、语言引导对象检索及重建质量方面的性能与效果。此外，文中还在真实的实验室环境中验证了系统的动态更新能力。源代码将在https://github.com/GeLuzhou/Dynamic-GSG发布。 <div>
arXiv:2502.15309v1 Announce Type: new 
Abstract: In real-world scenarios, the environment changes caused by agents or human activities make it extremely challenging for robots to perform various long-term tasks. To effectively understand and adapt to dynamic environments, the perception system of a robot needs to extract instance-level semantic information, reconstruct the environment in a fine-grained manner, and update its environment representation in memory according to environment changes. To address these challenges, We propose \textbf{DynamicGSG}, a dynamic, high-fidelity, open-vocabulary scene graph generation system leveraging Gaussian splatting. Our system comprises three key components: (1) constructing hierarchical scene graphs using advanced vision foundation models to represent the spatial and semantic relationships of objects in the environment, (2) designing a joint feature loss to optimize the Gaussian map for incremental high-fidelity reconstruction, and (3) updating the Gaussian map and scene graph according to real environment changes for long-term environment adaptation. Experiments and ablation studies demonstrate the performance and efficacy of the proposed method in terms of semantic segmentation, language-guided object retrieval, and reconstruction quality. Furthermore, we have validated the dynamic updating capabilities of our system in real laboratory environments. The source code will be released at:~\href{https://github.com/GeLuzhou/Dynamic-GSG}{https://github.com/GeLuzhou/DynamicGSG}.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning with Limited Shared Information in Multi-agent Multi-armed Bandit</title>
<link>https://arxiv.org/abs/2502.15338</link>
<guid>https://arxiv.org/abs/2502.15338</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体多臂赌博机(MAMAB)，有限共享信息， Balanced-ETC算法，激励机制，协同学习

<br><br>总结：
本文提出了一种新的多智能体多臂赌博机模型——有限共享信息多智能体多臂赌博机(LSI-MAMAB)，考虑了各智能体可能不愿分享全部信息的情况，如涉及个人隐私的数据。为了解决该问题，文中设计了Balanced-ETC算法，使得在有限共享信息条件下，多个智能体能够有效地协作学习。理论分析表明，Balanced-ETC算法具有渐近最优性，当参与智能体数量充足时，其平均 regret 对每个智能体而言可趋近于常数。此外，为了鼓励智能体参与到这种协作学习中，文章还提出了一个激励机制，确保每个智能体都能从协作系统中获益。最后，通过实验结果验证了理论分析的正确性。 <div>
arXiv:2502.15338v1 Announce Type: new 
Abstract: Multi-agent multi-armed bandit (MAMAB) is a classic collaborative learning model and has gained much attention in recent years. However, existing studies do not consider the case where an agent may refuse to share all her information with others, e.g., when some of the data contains personal privacy. In this paper, we propose a novel limited shared information multi-agent multi-armed bandit (LSI-MAMAB) model in which each agent only shares the information that she is willing to share, and propose the Balanced-ETC algorithm to help multiple agents collaborate efficiently with limited shared information. Our analysis shows that Balanced-ETC is asymptotically optimal and its average regret (on each agent) approaches a constant when there are sufficient agents involved. Moreover, to encourage agents to participate in this collaborative learning, an incentive mechanism is proposed to make sure each agent can benefit from the collaboration system. Finally, we present experimental results to validate our theoretical results.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ARS: Automatic Routing Solver with Large Language Models</title>
<link>https://arxiv.org/abs/2502.15359</link>
<guid>https://arxiv.org/abs/2502.15359</guid>
<content:encoded><![CDATA[
<div> 关键词: RoutBench、Vehicle Routing Problems (VRPs)、Automatic Routing Solver (ARS)、Large Language Model (LLM)、约束处理

总结:
为了解决实际生活中的复杂和多样化的车辆路径问题（VRPs），该文提出了RoutBench，一个由24种属性衍生出的1000个VRP变体的基准测试集合，用于评估自动路由求解器处理复杂约束的能力。同时，文中还介绍了一个名为Automatic Routing Solver (ARS)的方法，它利用大型语言模型（LLM）代理根据问题描述和从数据库中选取的一组代表性约束，自动生成约束感知的启发式代码，以增强基础算法框架。实验结果显示，ARS在解决常见VRP问题上的表现优于现有先进的LLM基线方法和常用求解器，能够自动解决91.67%的常规VRPs问题，并在所有基准测试上至少实现了30%的性能提升。 <div>
arXiv:2502.15359v1 Announce Type: new 
Abstract: Real-world Vehicle Routing Problems (VRPs) are characterized by a variety of practical constraints, making manual solver design both knowledge-intensive and time-consuming. Although there is increasing interest in automating the design of routing algorithms, existing research has explored only a limited array of VRP variants and fails to adequately address the complex and prevalent constraints encountered in real-world situations. To fill this gap, this paper introduces RoutBench, a benchmark of 1,000 VRP variants derived from 24 attributes, for evaluating the effectiveness of automatic routing solvers in addressing complex constraints. Along with RoutBench, we present the Automatic Routing Solver (ARS), which employs Large Language Model (LLM) agents to enhance a backbone algorithm framework by automatically generating constraint-aware heuristic code, based on problem descriptions and several representative constraints selected from a database. Our experiments show that ARS outperforms state-of-the-art LLM-based methods and commonly used solvers, automatically solving 91.67% of common VRPs and achieving at least a 30% improvement across all benchmarks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Textual-to-Visual Iterative Self-Verification for Slide Generation</title>
<link>https://arxiv.org/abs/2502.15412</link>
<guid>https://arxiv.org/abs/2502.15412</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化、幻灯片生成、内容生成、布局生成、LLM

总结:
我们提出了一种自动化生成缺失演示文稿幻灯片的方法，旨在解决当前基于LLM的自主代理在实际应用中的局限性。该方法将任务分解为两个关键步骤：内容生成和布局生成。首先，采用一种结合周围幻灯片上下文和段落检索策略的内容生成方法，以提高连贯性和相关性。其次，我们提出了一个文本到视觉的自我验证流程，利用LLM为基础的评审员+精炼者工作流，将复杂的文本布局转化为直观的视觉格式。实验表明，我们的方法在对齐性、逻辑流畅性、视觉吸引力和可读性等方面均显著优于基线方法。 <div>
arXiv:2502.15412v1 Announce Type: new 
Abstract: Generating presentation slides is a time-consuming task that urgently requires automation. Due to their limited flexibility and lack of automated refinement mechanisms, existing autonomous LLM-based agents face constraints in real-world applicability. We decompose the task of generating missing presentation slides into two key components: content generation and layout generation, aligning with the typical process of creating academic slides. First, we introduce a content generation approach that enhances coherence and relevance by incorporating context from surrounding slides and leveraging section retrieval strategies. For layout generation, we propose a textual-to-visual self-verification process using a LLM-based Reviewer + Refiner workflow, transforming complex textual layouts into intuitive visual formats. This modality transformation simplifies the task, enabling accurate and human-like review and refinement. Experiments show that our approach significantly outperforms baseline methods in terms of alignment, logical flow, visual appeal, and readability.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TAG: A Decentralized Framework for Multi-Agent Hierarchical Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15425</link>
<guid>https://arxiv.org/abs/2502.15425</guid>
<content:encoded><![CDATA[
<div> 关键词：artificial intelligence, hierarchical reinforcement learning, decentralized, TAME Agent Framework (TAG), multi-agent systems

总结:<br>
本文介绍了TAME Agent Framework (TAG)，一个新的用于构建完全去中心化的多层次多智能体系统的框架。TAG针对当前层次强化学习（HRL）方法存在的局限性，如通常限制为两层结构或需要集中式训练，提出了一种新的LevelEnv概念，将每一层级视为上一层级的环境，从而实现任意深度的层次组织，并保持各层级间的松散耦合。通过这种方式，TAG能够无缝整合不同类型的RL代理并在多个层级中结合使用。实验结果显示，基于TAG的分层架构在标准基准测试上相比于传统的多智能体RL基线表现出更快的学习速度和更好的最终性能，证明了去中心化分层组织对于可扩展的多智能体系统具有重要意义。 <div>
arXiv:2502.15425v1 Announce Type: new 
Abstract: Hierarchical organization is fundamental to biological systems and human societies, yet artificial intelligence systems often rely on monolithic architectures that limit adaptability and scalability. Current hierarchical reinforcement learning (HRL) approaches typically restrict hierarchies to two levels or require centralized training, which limits their practical applicability. We introduce TAME Agent Framework (TAG), a framework for constructing fully decentralized hierarchical multi-agent systems.TAG enables hierarchies of arbitrary depth through a novel LevelEnv concept, which abstracts each hierarchy level as the environment for the agents above it. This approach standardizes information flow between levels while preserving loose coupling, allowing for seamless integration of diverse agent types. We demonstrate the effectiveness of TAG by implementing hierarchical architectures that combine different RL agents across multiple levels, achieving improved performance over classical multi-agent RL baselines on standard benchmarks. Our results show that decentralized hierarchical organization enhances both learning speed and final performance, positioning TAG as a promising direction for scalable multi-agent systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pub-Guard-LLM: Detecting Fraudulent Biomedical Articles with Reliable Explanations</title>
<link>https://arxiv.org/abs/2502.15429</link>
<guid>https://arxiv.org/abs/2502.15429</guid>
<content:encoded><![CDATA[
<div> 关键词: Pub-Guard-LLM、欺诈检测、生物医学文章、PubMed Retraction、大型语言模型

总结:
本文提出了一种名为Pub-Guard-LLM的大规模语言模型系统，该系统专门用于检测生物医学科学文章中的欺诈行为，以应对日益严重的科研诚信威胁。Pub-Guard-LLM提供了三种应用模式：原生推理、检索增强生成和多代理辩论，并可为预测结果提供文本解释。为了评估系统性能，作者构建了一个开源基准数据集PubMed Retraction，其中包含了超过11K篇具有元数据和撤稿标签的真实生物医药文章。实验表明，无论在哪种模式下，Pub-Guard-LLM均超越了多种基线方法的表现并提供了更可靠、相关性与连贯性更强的解释。通过提升欺诈检测性能和解释能力，Pub-Guard-LLM为维护科研诚信提供了一个创新、有效且开放源代码的工具。 <div>
arXiv:2502.15429v1 Announce Type: new 
Abstract: A significant and growing number of published scientific articles is found to involve fraudulent practices, posing a serious threat to the credibility and safety of research in fields such as medicine. We propose Pub-Guard-LLM, the first large language model-based system tailored to fraud detection of biomedical scientific articles. We provide three application modes for deploying Pub-Guard-LLM: vanilla reasoning, retrieval-augmented generation, and multi-agent debate. Each mode allows for textual explanations of predictions. To assess the performance of our system, we introduce an open-source benchmark, PubMed Retraction, comprising over 11K real-world biomedical articles, including metadata and retraction labels. We show that, across all modes, Pub-Guard-LLM consistently surpasses the performance of various baselines and provides more reliable explanations, namely explanations which are deemed more relevant and coherent than those generated by the baselines when evaluated by multiple assessment methods. By enhancing both detection performance and explainability in scientific fraud detection, Pub-Guard-LLM contributes to safeguarding research integrity with a novel, effective, open-source tool.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SALSA-RL: Stability Analysis in the Latent Space of Actions for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.15512</link>
<guid>https://arxiv.org/abs/2502.15512</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习(DRL)、连续动作空间、稳定性分析、SALSA-RL、解释性

总结:
现代深度强化学习方法已在处理连续动作空间方面取得显著进步，但针对实际要求稳定性的控制系统（尤其是需要精确可靠性能的系统），现有DRL方法往往缺乏明确的稳定性保证和分析机制。为解决这一局限性，本文提出了一种新的RL框架——SALSA-RL（基于动作潜空间的稳定性分析）。该框架将控制动作建模为在潜空间中随时间动态变化的变量，并利用预训练的编码器-解码器及状态相关的线性系统实现稳定性分析与可解释性。实验表明，SALSA-RL可以非侵入式地应用于评估预先训练好的RL代理的动作局部稳定性，同时不影响其在多样化基准环境中的性能表现。通过提供对动作生成更具有解释性的分析，SALSA-RL为推进RL系统的设 <div>
arXiv:2502.15512v1 Announce Type: new 
Abstract: Modern deep reinforcement learning (DRL) methods have made significant advances in handling continuous action spaces. However, real-world control systems--especially those requiring precise and reliable performance--often demand formal stability, and existing DRL approaches typically lack explicit mechanisms to ensure or analyze stability. To address this limitation, we propose SALSA-RL (Stability Analysis in the Latent Space of Actions), a novel RL framework that models control actions as dynamic, time-dependent variables evolving within a latent space. By employing a pre-trained encoder-decoder and a state-dependent linear system, our approach enables both stability analysis and interpretability. We demonstrated that SALSA-RL can be deployed in a non-invasive manner for assessing the local stability of actions from pretrained RL agents without compromising on performance across diverse benchmark environments. By enabling a more interpretable analysis of action generation, SALSA-RL provides a powerful tool for advancing the design, analysis, and theoretical understanding of RL systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Contract DesignUnderApproximate Best Responses</title>
<link>https://arxiv.org/abs/2502.15523</link>
<guid>https://arxiv.org/abs/2502.15523</guid>
<content:encoded><![CDATA[
<div> 关键词: 主体-代理问题、近似最优响应、合同设计、计算复杂性、无 regret 学习算法

总结:<br>
本文研究了在隐藏行动主体-代理问题下，考虑近似最优响应情况下的合同设计。文章提出了一个能在多项式时间内计算出近似最优合同的算法，这一结果令人惊讶，因为在Stackelberg游戏中，对于近似最优响应的承诺优化问题是计算上不可解的。此外，文中还探讨了在无先验知识环境下，关于近似最优响应合同设计的无 regret 学习算法的应用场景。 <div>
arXiv:2502.15523v1 Announce Type: new 
Abstract: Principal-agent problems model scenarios where a principal incentivizes an agent to take costly, unobservable actions through the provision of payments. Such problems are ubiquitous in several real-world applications, ranging from blockchain to the delegation of machine learning tasks. In this paper, we initiate the study of hidden-action principal-agent problems under approximate best responses, in which the agent may select any action that is not too much suboptimal given the principal's payment scheme (a.k.a. contract). Our main result is a polynomial-time algorithm to compute an optimal contract under approximate best responses. This positive result is perhaps surprising, since, in Stackelberg games, computing an optimal commitment under approximate best responses is computationally intractable. We also investigate the learnability of contracts under approximate best responses, by providing a no-regret learning algorithm for a natural application scenario where the principal has no prior knowledge about the environment.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SOTOPIA-{\Omega}: Dynamic Strategy Injection Learning and Social Instrucion Following Evaluation for Social Agents</title>
<link>https://arxiv.org/abs/2502.15538</link>
<guid>https://arxiv.org/abs/2502.15538</guid>
<content:encoded><![CDATA[
<div> 关键词: SOTOPIA-Ω框架、社交策略、语言代理、Social Instruction Following (S-IF)、评价指标

总结:<br>
本文提出了一种名为SOTOPIA-Ω的新框架，旨在将人类的社会策略转移并整合到社交代理人，特别是语言代理中。该框架通过动态注入基于谈判理论的多步推理策略和两种直接策略，自动生成高质量的社交对话训练语料库。同时，文中引入了“社交指令跟随”(S-IF)的概念，并提出了两个新的、与社交能力相辅相成的S-IF评估指标。实验表明，经过高质语料库训练的几个7B模型不仅在实现社交目标上显著超越专家级代理（如GPT-4），而且在S-IF性能上也有所提升。分析和变体实验验证了动态构建的优势，它能有效打破代理间的持久僵局。 <div>
arXiv:2502.15538v1 Announce Type: new 
Abstract: Despite the abundance of prior social strategies possessed by humans, there remains a paucity of research dedicated to their transfer and integration into social agents. Our proposed SOTOPIA-{\Omega} framework aims to address and bridge this gap, with a particular focus on enhancing the social capabilities of language agents. This framework dynamically injects multi-step reasoning strategies inspired by negotiation theory, along with two simple direct strategies, into expert agents, thereby automating the construction of high-quality social dialogue training corpus. Additionally, we introduce the concept of Social Instruction Following (S-IF) and propose two new S-IF evaluation metrics that are complementary to social capability. We demonstrate that several 7B models trained on high-quality corpus not only significantly surpass the expert agent (GPT-4) in achieving social goals but also enhance S-IF performance. Analysis and variant experiments validate the advantages of dynamic construction, which can especially break the agent's prolonged deadlock.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WorldCraft: Photo-Realistic 3D World Creation and Customization via LLM Agents</title>
<link>https://arxiv.org/abs/2502.15601</link>
<guid>https://arxiv.org/abs/2502.15601</guid>
<content:encoded><![CDATA[
<div> 关键词: WorldCraft、LLM、三维建模、自然语言命令、自动验证

<br><br>总结:
WorldCraft是一个使用大型语言模型（LLM）代理的系统，通过程序生成技术简化创建逼真虚拟世界的流程，使得非专业人士也能参与。用户可以通过直观的自然语言指令控制场景布局和物体属性。该系统由一个协调器代理管理，并与两个专门的LLM代理——ForgeIt（用于精确定制单个物体并利用自动验证不断改进）和ArrangeIt（负责平衡人体工程学和美学考量来优化布局）协同工作。此外，WorldCraft还包括一个轨迹控制代理，让用户能够通过自然语言交互来动画化场景及操作相机。系统还兼容现成的深度3D生成器以丰富场景资产。WorldCraft展现了从单一物体定制到复杂大规模室内室外场景设计等多方面的灵活性和多样性。 <div>
arXiv:2502.15601v1 Announce Type: new 
Abstract: Constructing photorealistic virtual worlds has applications across various fields, but it often requires the extensive labor of highly trained professionals to operate conventional 3D modeling software. To democratize this process, we introduce WorldCraft, a system where large language model (LLM) agents leverage procedural generation to create indoor and outdoor scenes populated with objects, allowing users to control individual object attributes and the scene layout using intuitive natural language commands. In our framework, a coordinator agent manages the overall process and works with two specialized LLM agents to complete the scene creation: ForgeIt, which integrates an ever-growing manual through auto-verification to enable precise customization of individual objects, and ArrangeIt, which formulates hierarchical optimization problems to achieve a layout that balances ergonomic and aesthetic considerations. Additionally, our pipeline incorporates a trajectory control agent, allowing users to animate the scene and operate the camera through natural language interactions. Our system is also compatible with off-the-shelf deep 3D generators to enrich scene assets. Through evaluations and comparisons with state-of-the-art methods, we demonstrate the versatility of WorldCraft, ranging from single-object customization to intricate, large-scale interior and exterior scene designs. This system empowers non-professionals to bring their creative visions to life.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RGB-Only Gaussian Splatting SLAM for Unbounded Outdoor Scenes</title>
<link>https://arxiv.org/abs/2502.15633</link>
<guid>https://arxiv.org/abs/2502.15633</guid>
<content:encoded><![CDATA[
<div> 关键词：3D高斯投射（3DGS）、SLAM、RGB-only、室外场景、OpenGS-SLAM

总结:<br>
本文提出了一种适用于无界室外场景的新型RGB-only高斯投射SLAM方法——OpenGS-SLAM。该方法针对以往基于3DGS的SLAM方法主要应用于室内场景及依赖RGB-D传感器或预训练深度估计模型的问题，通过采用点图回归网络生成帧间一致的点图以实现更稳健的相机姿态估计。点图包含了多视图的空间关系和场景几何信息。接着，文章将估计的相机姿态与3DGS渲染结合成端到端可微分的管道，实现了相机姿态和3DGS场景参数的同时优化。此外，文中还设计了自适应尺度映射器来改进点图回归网络，从而为3DGS地图表示提供更为精确的点图映射。实验结果显示，在Waymo数据集上，OpenGS-SLAM将跟踪误差降低至先前3DGS方法的9.8%，并在新视图合成方面达到了最先进的结果。 <div>
arXiv:2502.15633v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has become a popular solution in SLAM, as it can produce high-fidelity novel views. However, previous GS-based methods primarily target indoor scenes and rely on RGB-D sensors or pre-trained depth estimation models, hence underperforming in outdoor scenarios. To address this issue, we propose a RGB-only gaussian splatting SLAM method for unbounded outdoor scenes--OpenGS-SLAM. Technically, we first employ a pointmap regression network to generate consistent pointmaps between frames for pose estimation. Compared to commonly used depth maps, pointmaps include spatial relationships and scene geometry across multiple views, enabling robust camera pose estimation. Then, we propose integrating the estimated camera poses with 3DGS rendering as an end-to-end differentiable pipeline. Our method achieves simultaneous optimization of camera poses and 3DGS scene parameters, significantly enhancing system tracking accuracy. Specifically, we also design an adaptive scale mapper for the pointmap regression network, which provides more accurate pointmap mapping to the 3DGS map representation. Our experiments on the Waymo dataset demonstrate that OpenGS-SLAM reduces tracking error to 9.8\% of previous 3DGS methods, and achieves state-of-the-art results in novel view synthesis. Project Page: https://3dagentworld.github.io/opengs-slam/
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Simulation Pipeline to Facilitate Real-World Robotic Reinforcement Learning Applications</title>
<link>https://arxiv.org/abs/2502.15649</link>
<guid>https://arxiv.org/abs/2502.15649</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning, RL)，机器人应用，模拟到现实差距 (Simulation-to-Reality Gap)，系统识别，训练阶段

总结:<br>
本文介绍了一种用于减少现实与模拟之间差距并促进实际机器人系统中强化学习策略开发和部署的RL管道。该管道将RL训练过程分为系统识别初步步骤和三个训练阶段：核心模拟训练、高保真模拟以及真实世界部署，每个阶段逐步增加逼真度以缩小模拟与现实之间的差距。每个训练阶段都会接收输入政策、改进政策，并将其传递至下一阶段或回传进行进一步优化。这一迭代过程持续直至政策达到预期性能。通过使用波士顿动力Spot移动机器人的监控应用案例研究展示了该管道的有效性，其中详细介绍了在每个管道阶段所采取的步骤，最终获得能够控制机器人位置和方向的RL代理。 <div>
arXiv:2502.15649v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has gained traction for its success in solving complex tasks for robotic applications. However, its deployment on physical robots remains challenging due to safety risks and the comparatively high costs of training. To avoid these problems, RL agents are often trained on simulators, which introduces a new problem related to the gap between simulation and reality. This paper presents an RL pipeline designed to help reduce the reality gap and facilitate developing and deploying RL policies for real-world robotic systems. The pipeline organizes the RL training process into an initial step for system identification and three training stages: core simulation training, high-fidelity simulation, and real-world deployment, each adding levels of realism to reduce the sim-to-real gap. Each training stage takes an input policy, improves it, and either passes the improved policy to the next stage or loops it back for further improvement. This iterative process continues until the policy achieves the desired performance. The pipeline's effectiveness is shown through a case study with the Boston Dynamics Spot mobile robot used in a surveillance application. The case study presents the steps taken at each pipeline stage to obtain an RL agent to control the robot's position and orientation.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Superintelligent Agents Pose Catastrophic Risks: Can Scientist AI Offer a Safer Path?</title>
<link>https://arxiv.org/abs/2502.15657</link>
<guid>https://arxiv.org/abs/2502.15657</guid>
<content:encoded><![CDATA[
<div> 关键词：通用人工智能、风险、安全、非代理AI、Scientist AI

总结:
当前领先的AI企业正专注于构建能自主规划、行动并追求目标的通用人工智能系统，但这种系统的失控可能带来重大的公共安全和安全隐患。文章指出，由于当前的训练方法，AI可能存在欺骗行为或追求与人类利益冲突的目标。为遵循预防原则，文章提倡发展一种设计上即具备可信度和安全性的非代理AI系统——Scientist AI。Scientist AI主要负责基于观察解释世界，包括生成理论以解释数据和进行带有不确定性考量的问题解答。此类系统可用于协助人类研究者加速科学研究，尤其是在AI安全性方面，可作为对抗存在风险的人工智能代理的防护措施。关注非代理AI的发展有望在避免现有轨迹带来的风险的同时，实现AI创新的利益。作者呼吁研究人员、开发者和政策制定者支持这条更安全的道路。 <div>
arXiv:2502.15657v1 Announce Type: new 
Abstract: The leading AI companies are increasingly focused on building generalist AI agents -- systems that can autonomously plan, act, and pursue goals across almost all tasks that humans can perform. Despite how useful these systems might be, unchecked AI agency poses significant risks to public safety and security, ranging from misuse by malicious actors to a potentially irreversible loss of human control. We discuss how these risks arise from current AI training methods. Indeed, various scenarios and experiments have demonstrated the possibility of AI agents engaging in deception or pursuing goals that were not specified by human operators and that conflict with human interests, such as self-preservation. Following the precautionary principle, we see a strong need for safer, yet still useful, alternatives to the current agency-driven trajectory. Accordingly, we propose as a core building block for further advances the development of a non-agentic AI system that is trustworthy and safe by design, which we call Scientist AI. This system is designed to explain the world from observations, as opposed to taking actions in it to imitate or please humans. It comprises a world model that generates theories to explain data and a question-answering inference machine. Both components operate with an explicit notion of uncertainty to mitigate the risks of overconfident predictions. In light of these considerations, a Scientist AI could be used to assist human researchers in accelerating scientific progress, including in AI safety. In particular, our system can be employed as a guardrail against AI agents that might be created despite the risks involved. Ultimately, focusing on non-agentic AI may enable the benefits of AI innovation while avoiding the risks associated with the current trajectory. We hope these arguments will motivate researchers, developers, and policymakers to favor this safer path.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automating Curriculum Learning for Reinforcement Learning using a Skill-Based Bayesian Network</title>
<link>https://arxiv.org/abs/2502.15662</link>
<guid>https://arxiv.org/abs/2502.15662</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、课程生成、SEBNs（技能环境贝叶斯网络）、预期改善、性能提升

总结:<br>
本文提出了一种用于强化学习的自动课程生成方法——SEBNs（Skill-Environment Bayesian Networks），该模型能够建立技能、目标与环境特征之间的概率关系，并预测在（可能未见过）任务上的策略表现。文章介绍了一个利用SEBN推断的代理成功度估计值来加权并选择预期能带来最大改进的下一个任务的算法。通过在离散网格世界、连续控制和模拟机器人三个环境中的评估结果表明，基于SEBN构建的课程通常优于其他基线方法，从而证实了其在减少训练时间和提高任务性能方面的优势。 <div>
arXiv:2502.15662v1 Announce Type: new 
Abstract: A major challenge for reinforcement learning is automatically generating curricula to reduce training time or improve performance in some target task. We introduce SEBNs (Skill-Environment Bayesian Networks) which model a probabilistic relationship between a set of skills, a set of goals that relate to the reward structure, and a set of environment features to predict policy performance on (possibly unseen) tasks. We develop an algorithm that uses the inferred estimates of agent success from SEBN to weigh the possible next tasks by expected improvement. We evaluate the benefit of the resulting curriculum on three environments: a discrete gridworld, continuous control, and simulated robotics. The results show that curricula constructed using SEBN frequently outperform other baselines.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Architecture in Distributed Environment Control Systems: vision, challenges, and opportunities</title>
<link>https://arxiv.org/abs/2502.15663</link>
<guid>https://arxiv.org/abs/2502.15663</guid>
<content:encoded><![CDATA[
<div> 关键词：多代理架构、分布式控制、空气冷却冷水系统、数据中心、能源效率

总结:<br>
本文提出了一种应用于大型基础设施，尤其是数据中心的多代理架构方案，用于分布式的空气冷却冷水系统的控制，以满足对能效解决方案日益增长的需求。该方案采用自主智能体监控和调节局部运行参数，优化整个系统的效率，进而提升了系统的响应速度、运行鲁棒性和能源利用率。这为实现可持续性基础设施管理的总体目标做出了贡献。 <div>
arXiv:2502.15663v1 Announce Type: new 
Abstract: The increasing demand for energy-efficient solutions in large-scale infrastructure, particularly data centers, requires advanced control strategies to optimize environmental management systems. We propose a multi-agent architecture for distributed control of air-cooled chiller systems in data centers. Our vision employs autonomous agents to monitor and regulate local operational parameters and optimize system-wide efficiency. We demonstrate how this approach improves the responsiveness, operational robustness, and energy efficiency of the system, contributing to the broader goal of sustainable infrastructure management.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoToM: Automated Bayesian Inverse Planning and Model Discovery for Open-ended Theory of Mind</title>
<link>https://arxiv.org/abs/2502.15676</link>
<guid>https://arxiv.org/abs/2502.15676</guid>
<content:encoded><![CDATA[
<div> 关键词: 理论心智、大型语言模型、自动贝叶斯理论心智、开放性机器理论心智、推理问题

总结:
本文介绍了AutoToM，一种新型的自动化贝叶斯理论心智方法，旨在实现开放性的机器理论心智。AutoToM能够在任何领域中运行，推断任意心理变量并进行稳健的多层次理论心智推理。与依赖易出系统性错误的大规模语言模型或局限于特定领域的手工构造的贝叶斯理论心智模型不同，AutoToM首先提出一个初始的BToM模型，然后利用LLM作为后端执行自动化贝叶斯反向规划推理。根据推理的不确定性，它会迭代地细化模型，通过引入额外的心理变量和/或考虑更多的时间步上下文信息。实验结果显示，AutoToM在多个理论心智基准测试中始终表现出最先进的性能，提供了一种可扩展、稳健且可解释的机器理论心智方法。 <div>
arXiv:2502.15676v1 Announce Type: new 
Abstract: Theory of Mind (ToM), the ability to understand people's mental variables based on their behavior, is key to developing socially intelligent agents. Current approaches to Theory of Mind reasoning either rely on prompting Large Language Models (LLMs), which are prone to systematic errors, or use rigid, handcrafted Bayesian Theory of Mind (BToM) models, which are more robust but cannot generalize across different domains. In this work, we introduce AutoToM, an automated Bayesian Theory of Mind method for achieving open-ended machine Theory of Mind. AutoToM can operate in any domain, infer any mental variable, and conduct robust Theory of Mind reasoning of any order. Given a Theory of Mind inference problem, AutoToM first proposes an initial BToM model. It then conducts automated Bayesian inverse planning based on the proposed model, leveraging an LLM as the backend. Based on the uncertainty of the inference, it iteratively refines the model, by introducing additional mental variables and/or incorporating more timesteps in the context. Empirical evaluations across multiple Theory of Mind benchmarks demonstrate that AutoToM consistently achieves state-of-the-art performance, offering a scalable, robust, and interpretable approach to machine Theory of Mind.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PP-MARL: Efficient Privacy-Preserving Multi-Agent Reinforcement Learning for Cooperative Intelligence in Communications</title>
<link>https://arxiv.org/abs/2204.12064</link>
<guid>https://arxiv.org/abs/2204.12064</guid>
<content:encoded><![CDATA[
<div> 关键词: 合作智能(CI), 多智能体强化学习(MARL), 隐私保护, 恒等同态加密(HE), 差分隐私(DP)

总结:<br>
本文提出了一种用于多智能体强化学习(MARL)的高效隐私保护学习方案PP-MARL，旨在解决下一代网络中合作智能(CI)中的隐私保护问题。该方案利用恒等同态加密(HE)和差分隐私(DP)技术来保障隐私安全，同时引入分割学习以降低通过减少共享消息量带来的计算和带宽开销，从而提高效率。文章在两个通信相关的应用场景中应用并评估了PP-MARL。仿真结果表明，PP-MARL可以实现有效可靠的协作，并提供比现有方法高出1.1至6倍的隐私保护效果，同时显著降低了带宽开销（例如减少了84-91%）。 <div>
arXiv:2204.12064v2 Announce Type: replace 
Abstract: Cooperative intelligence (CI) is expected to become an integral element in next-generation networks because it can aggregate the capabilities and intelligence of multiple devices. Multi-agent reinforcement learning (MARL) is a popular approach for achieving CI in communication problems by enabling effective collaboration among agents to address sequential problems. However, ensuring privacy protection for MARL is a challenging task because of the presence of heterogeneous agents that learn interdependently via sharing information. Implementing privacy protection techniques such as data encryption and federated learning to MARL introduces the notable overheads (e.g., computation and bandwidth). To overcome these challenges, we propose PP-MARL, an efficient privacy-preserving learning scheme for MARL. PP-MARL leverages homomorphic encryption (HE) and differential privacy (DP) to protect privacy, while introducing split learning to decrease overheads via reducing the volume of shared messages, and then improve efficiency. We apply and evaluate PP-MARL in two communication-related use cases. Simulation results reveal that PP-MARL can achieve efficient and reliable collaboration with 1.1-6 times better privacy protection and lower overheads (e.g., 84-91% reduction in bandwidth) than state-of-the-art approaches.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safe Pareto Improvements for Expected Utility Maximizers in Program Games</title>
<link>https://arxiv.org/abs/2403.05103</link>
<guid>https://arxiv.org/abs/2403.05103</guid>
<content:encoded><![CDATA[
<div> 关键词: mixed-motive coordination, Safe Pareto improvements (SPIs), miscoordination, renegotiation, expected utility-maximizing agents

<br><br>总结:
该文探讨了安全帕累托改进(SPIs)如何缓解预期效用最大化的代理人在混合动机协调问题（如Chicken游戏）中的协调失败。SPIs被定义为对策略配置进行的变换，以确保所有玩家在变换后的配置下必然得到更好的结果。文章考虑了一种情景，其中玩家提交可以基于对方代码做出决策的计算机程序，并利用这一特性通过具有重新谈判能力的程序构建SPIs。研究发现，在玩家信念满足轻微条件的情况下，每个玩家总是倾向于使用重新谈判。进一步地，类似假设下，每个玩家总是倾向于至少愿意重新谈判到他们能在任何有效结果中获得的最低收益水平。因此，主观最优策略保证了玩家至少能获得这些收益，而无需就特定的帕累托改进达成一致。然而，重新谈判并不能保证玩家在这方面超越这个界限。 <div>
arXiv:2403.05103v5 Announce Type: replace 
Abstract: Agents in mixed-motive coordination problems such as Chicken may fail to coordinate on a Pareto-efficient outcome. Safe Pareto improvements (SPIs) were originally proposed to mitigate miscoordination in cases where players lack probabilistic beliefs as to how their delegates will play a game; delegates are instructed to behave so as to guarantee a Pareto improvement on how they would play by default. More generally, SPIs may be defined as transformations of strategy profiles such that all players are necessarily better off under the transformed profile. In this work, we investigate the extent to which SPIs can reduce downsides of miscoordination between expected utility-maximizing agents. We consider games in which players submit computer programs that can condition their decisions on each other's code, and use this property to construct SPIs using programs capable of renegotiation. We first show that under mild conditions on players' beliefs, each player always prefers to use renegotiation. Next, we show that under similar assumptions, each player always prefers to be willing to renegotiate at least to the point at which they receive the lowest payoff they can attain in any efficient outcome. Thus subjectively optimal play guarantees players at least these payoffs, without the need for coordination on specific Pareto improvements. Lastly, we prove that renegotiation does not guarantee players any improvements on this bound.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking Open-Vocabulary Segmentation of Radiance Fields in 3D Space</title>
<link>https://arxiv.org/abs/2408.07416</link>
<guid>https://arxiv.org/abs/2408.07416</guid>
<content:encoded><![CDATA[
<div> 关键词: 三维语义理解、NeRFs、3DGS、实时渲染、三维查询评估协议

总结:<br>
本文关注于对场景的三维语义理解问题，提出了改进方法。首先，为克服以往方法在3D理解上的局限性，文章重新定义了问题并提出针对3D体积进行分割的方法。其次，不同于以往在2D像素层面进行监督训练，该方法直接对3D点施加语言嵌入场监督。进一步地，他们将学习到的语言场应用到3DGS中，实现了首个实时渲染速度，同时未牺牲训练时间和准确性。最后，文中引入了一种新的3D查询与评估协议，用于综合评估重建几何形状和语义。项目相关的代码、检查点和注解可在项目页面获取。 <div>
arXiv:2408.07416v3 Announce Type: replace 
Abstract: Understanding the 3D semantics of a scene is a fundamental problem for various scenarios such as embodied agents. While NeRFs and 3DGS excel at novel-view synthesis, previous methods for understanding their semantics have been limited to incomplete 3D understanding: their segmentation results are rendered as 2D masks that do not represent the entire 3D space. To address this limitation, we redefine the problem to segment the 3D volume and propose the following methods for better 3D understanding. We directly supervise the 3D points to train the language embedding field, unlike previous methods that anchor supervision at 2D pixels. We transfer the learned language field to 3DGS, achieving the first real-time rendering speed without sacrificing training time or accuracy. Lastly, we introduce a 3D querying and evaluation protocol for assessing the reconstructed geometry and semantics together. Code, checkpoints, and annotations are available at the project page.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rethinking Generative Semantic Communication for Multi-User Systems with Large Language Models</title>
<link>https://arxiv.org/abs/2408.08765</link>
<guid>https://arxiv.org/abs/2408.08765</guid>
<content:encoded><![CDATA[
<div> 关键词: 6G, 语义通信(SemCom), 多用户系统, 大规模语言模型(LLM), M-GSC框架

<br><br>总结:
本文针对6G网络中连接设备激增以及智能农业和智慧城市等复杂任务对多用户合作的需求，提出了传统通信面临的挑战。语义通信（SemCom）作为由人工智能技术和增强的设备计算能力驱动的有希望的6G技术手段，但现有的深度学习基线的SemCom方法难以适应多用户场景。为了解决这些问题，文章重新思考并提出了适用于多用户的生成式语义通信（M-GSC）框架，该框架利用大规模语言模型（LLM）作为共享知识库（SKB）。LLM-SKB在复杂任务分解、语义表示规范和语义翻译映射等方面发挥关键作用，实现了语义编码标准化和个性化解码等优势。此外，文中还提出了三个优化策略，包括将LLM-SKB扩展为多代理LLM系统、语义编码与解码的卸载以及通信与计算资源的管理，以提升M-GSC框架的性能。通过一个案例研究初步验证了M-GSC框架在有效实现解码卸载等方面的效率优势。 <div>
arXiv:2408.08765v3 Announce Type: replace 
Abstract: The surge in connected devices in 6G with typical complex tasks requiring multi-user cooperation, such as smart agriculture and smart cities, poses significant challenges to unsustainable traditional communication. Fortunately, the booming artificial intelligence technology and the growing computational power of devices offer a promising 6G enabler: semantic communication (SemCom). However, existing deep learning-based SemCom paradigms struggle to extend to multi-user scenarios due to its increasing model size with the growing number of users and its limited compatibility with complex communication environments. Consequently, to truly empower 6G networks with this critical technology, this article rethinks generative SemCom for multi-user system and proposes a novel framework called ``M-GSC" with the large language model (LLM) as the shared knowledge base (SKB). The LLM-based SKB plays three critical roles, that is, complex task decomposition, semantic representation specification, and semantic translation and mapping, for complex tasks, spawning a series of benefits such as semantic encoding standardization and semantic decoding personalization. Meanwhile, to enhance the performance of M-GSC framework, we highlight three optimization strategies unique to this framework: extending the LLM-based SKB into a multi-agent LLM system, offloading semantic encoding and decoding, and managing communication and computational resources. Finally, a case study is conducted to demonstrate the preliminary validation on the effectiveness of the M-GSC framework in terms of efficient decoding offloading.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Hierarchical DRL Approach for Resource Optimization in Multi-RIS Multi-Operator Networks</title>
<link>https://arxiv.org/abs/2410.12320</link>
<guid>https://arxiv.org/abs/2410.12320</guid>
<content:encoded><![CDATA[
<div> 关键词：reconfigurable intelligent surfaces (RIS)，第六代（6G）网络，多运营商（OP），深度强化学习（DRL），Hierarchical Proximal Policy Optimization (HPPO)

总结:

本文探讨了在第六代（6G）网络中，可重构智能表面（RIS）作为关键技术应用于多运营商（OP）网络所面临的挑战，如RIS配置协调、干扰管理和隐私保护。提出将RIS视为由RIS提供商（RP）管理的公共资源以提高资源配置效率。为解决复杂的RIS资源优化问题，文章提出了层次化深度强化学习（HDRL）方法，其中顶层RP代理负责RIS分配，而低层OP代理则控制其分配到的RIS并处理波束赋形、RIS相移和用户关联。利用半马尔科夫决策过程（SMDP）理论，建立了RP与OP间的复杂交互机制，并引入了高级的分层Proximal Policy Optimization（HPPO）算法。针对单个RP代理面临的维度灾难问题，进一步提出了改进的序列-HPPO（S-HPPO）算法。实验结果验证了HPPO算法在不同环境参数下的稳定性，并表明其在联合资源优化方面优于其他基准算法。最后，对提出的S-HPPO和HPPO算法进行了详细的比较分析，结果显示在大规模RIS分配场景下，S-HPPO算法具有更快的收敛速度和更优的性能。 <div>
arXiv:2410.12320v2 Announce Type: replace 
Abstract: As reconfigurable intelligent surfaces (RIS) emerge as a pivotal technology in the upcoming sixth-generation (6G) networks, their deployment within practical multiple operator (OP) networks presents significant challenges, including the coordination of RIS configurations among OPs, interference management, and privacy maintenance. A promising strategy is to treat RIS as a public resource managed by an RIS provider (RP), which can enhance resource allocation efficiency by allowing dynamic access for multiple OPs. However, the intricate nature of coordinating management and optimizing RIS configurations significantly complicates the implementation process. In this paper, we propose a hierarchical deep reinforcement learning (HDRL) approach that decomposes the complicated RIS resource optimization problem into several subtasks. Specifically, a top-level RP-agent is responsible for RIS allocation, while low-level OP-agents control their assigned RISs and handle beamforming, RIS phase-shifts, and user association. By utilizing the semi-Markov decision process (SMDP) theory, we establish a sophisticated interaction mechanism between the RP and OPs, and introduce an advanced hierarchical proximal policy optimization (HPPO) algorithm. Furthermore, we propose an improved sequential-HPPO (S-HPPO) algorithm to address the curse of dimensionality encountered with a single RP-agent. Experimental results validate the stability of the HPPO algorithm across various environmental parameters, demonstrating its superiority over other benchmarks for joint resource optimization. Finally, we conduct a detailed comparative analysis between the proposed S-HPPO and HPPO algorithms, showcasing that the S-HPPO algorithm achieves faster convergence and improved performance in large-scale RIS allocation scenarios.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DistRL: An Asynchronous Distributed Reinforcement Learning Framework for On-Device Control Agents</title>
<link>https://arxiv.org/abs/2410.14803</link>
<guid>https://arxiv.org/abs/2410.14803</guid>
<content:encoded><![CDATA[
<div> 关键词: on-device control agents, Multimodal Large Language Models (MLLMs), DistRL, reinforcement learning (RL), training efficiency

<br><br>总结:
本文提出了一种名为DistRL的新框架，旨在提升移动设备控制代理中基于多模态大型语言模型(MLLMs)的在线强化学习（RL）微调效率。面对有限的数据可用性和低效的在线训练问题，DistRL采用了集中式训练与分布式数据采集相结合的方式，保证了动态在线交互环境下的高效微调。此外，该框架还配备了一个定制的RL算法，能在探索与已收集数据的有效利用之间取得平衡，确保稳定和鲁棒的训练过程。实验结果显示，相比于领先的同步多机器方法，DistRL平均提升了3倍的训练效率，并能将训练数据收集速度提高2.4倍。在对开放基准中的通用Android任务进行测试后，DistRL相较于现有最优方法取得了20%的成功率相对提升，显著超越了其他方法的同时，保持了相同的训练时间。这些结果验证了DistRL是一种可扩展且高效的解决方案，对于现实世界中的设备控制任务，它既提高了训练效率，又提升了代理性能。 <div>
arXiv:2410.14803v5 Announce Type: replace 
Abstract: On-device control agents, especially on mobile devices, are responsible for operating mobile devices to fulfill users' requests, enabling seamless and intuitive interactions. Integrating Multimodal Large Language Models (MLLMs) into these agents enhances their ability to understand and execute complex commands, thereby improving user experience. However, fine-tuning MLLMs for on-device control presents significant challenges due to limited data availability and inefficient online training processes. This paper introduces DistRL, a novel framework designed to enhance the efficiency of online RL fine-tuning for mobile device control agents. DistRL employs centralized training and decentralized data acquisition to ensure efficient fine-tuning in the context of dynamic online interactions. Additionally, the framework is backed by our tailor-made RL algorithm, which effectively balances exploration with the prioritized utilization of collected data to ensure stable and robust training. Our experiments show that, on average, DistRL delivers a 3X improvement in training efficiency and enables training data collection 2.4X faster than the leading synchronous multi-machine methods. Notably, after training, DistRL achieves a 20% relative improvement in success rate compared to state-of-the-art methods on general Android tasks from an open benchmark, significantly outperforming existing approaches while maintaining the same training time. These results validate DistRL as a scalable and efficient solution, offering substantial improvements in both training efficiency and agent performance for real-world, in-the-wild device control tasks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shared Control with Black Box Agents using Oracle Queries</title>
<link>https://arxiv.org/abs/2410.19612</link>
<guid>https://arxiv.org/abs/2410.19612</guid>
<content:encoded><![CDATA[
<div> 关键词：共享控制、机器人、人类协作、查询、学习策略<br><br>总结:

本文探讨了共享控制问题，研究了机器人如何与人类协同学习控制策略。通过引入直接向合作代理人查询的能力，文章考虑了两种类型的响应查询的预言机：一种能提供最佳行动建议，即使该行动可能从局部角度看是错误的；另一种则具有对其系统部分有限的知识。针对这一额外的信息通道，文中提出了三种选择何时进行查询的启发式方法：基于强化学习的、基于效用的和基于熵的。实验证明，在两个环境中，查询能够帮助学习更优的控制策略，并展示了所提启发式方法之间的学习成本权衡。 <div>
arXiv:2410.19612v2 Announce Type: replace 
Abstract: Shared control problems involve a robot learning to collaborate with a human. When learning a shared control policy, short communication between the agents can often significantly reduce running times and improve the system's accuracy. We extend the shared control problem to include the ability to directly query a cooperating agent. We consider two types of potential responses to a query, namely oracles: one that can provide the learner with the best action they should take, even when that action might be myopically wrong, and one with a bounded knowledge limited to its part of the system. Given this additional information channel, this work further presents three heuristics for choosing when to query: reinforcement learning-based, utility-based, and entropy-based. These heuristics aim to reduce a system's overall learning cost. Empirical results on two environments show the benefits of querying to learn a better control policy and the tradeoffs between the proposed heuristics.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Provable Partially Observable Reinforcement Learning with Privileged Information</title>
<link>https://arxiv.org/abs/2412.00985</link>
<guid>https://arxiv.org/abs/2412.00985</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、部分可观测性、特权信息、专家蒸馏、不对称actor-critic<br><br>总结:

本文针对部分可观测环境下强化学习（RL）中的挑战进行了研究，探讨了利用特权信息（如来自模拟器的状态访问）的优势。文章首先形式化并指出了“专家蒸馏”（又称“教师-学生”学习）在找到近似最优策略时可能存在的问题。接着，提出了一种名为“确定性滤波条件”的环境条件，在此条件下，专家蒸馏可以实现样本和计算复杂度均为多项式级的效率。随后，研究了另一种实用方法——不对称actor-critic，在可观察的部分可观测马尔科夫决策过程中，设计了一个信念加权的不对称actor-critic算法，其具有多项式级样本复杂度和准多项式级计算复杂度。其中，关键组件是一个新的可证明的信念状态学习Oracle，该Oracle能在模型误配情况下保证滤波稳定性。此外，文章还考察了具有特权信息的部分可观测多智能体RL（MARL）的可证效率，提出了采用集中训练与分布式执行框架的多项式级样本和（准）多项式级计算复杂度的算法。相较于近期相关理论研究，本文更侧重于理解实践启发式的算法范式，同时避免了使用计算上不可行的Oracle。 <div>
arXiv:2412.00985v3 Announce Type: replace 
Abstract: Partial observability of the underlying states generally presents significant challenges for reinforcement learning (RL). In practice, certain \emph{privileged information}, e.g., the access to states from simulators, has been exploited in training and has achieved prominent empirical successes. To better understand the benefits of privileged information, we revisit and examine several simple and practically used paradigms in this setting. Specifically, we first formalize the empirical paradigm of \emph{expert distillation} (also known as \emph{teacher-student} learning), demonstrating its pitfall in finding near-optimal policies. We then identify a condition of the partially observable environment, the \emph{deterministic filter condition}, under which expert distillation achieves sample and computational complexities that are \emph{both} polynomial. Furthermore, we investigate another useful empirical paradigm of \emph{asymmetric actor-critic}, and focus on the more challenging setting of observable partially observable Markov decision processes. We develop a belief-weighted asymmetric actor-critic algorithm with polynomial sample and quasi-polynomial computational complexities, in which one key component is a new provable oracle for learning belief states that preserve \emph{filter stability} under a misspecified model, which may be of independent interest. Finally, we also investigate the provable efficiency of partially observable multi-agent RL (MARL) with privileged information. We develop algorithms featuring \emph{centralized-training-with-decentralized-execution}, a popular framework in empirical MARL, with polynomial sample and (quasi-)polynomial computational complexities in both paradigms above. Compared with a few recent related theoretical studies, our focus is on understanding practically inspired algorithmic paradigms, without computationally intractable oracles.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Who Speaks Next? Multi-party AI Discussion Leveraging the Systematics of Turn-taking in Murder Mystery Games</title>
<link>https://arxiv.org/abs/2412.04937</link>
<guid>https://arxiv.org/abs/2412.04937</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、大规模语言模型、对话控制、回合制游戏、谋杀之谜、对话规范、自然对话、决策制定、相邻对、轮流机制、内部状态、对话中断、自动评估、人类评价、信息共享、逻辑推理。

<br><br>总结:
该研究关注多智能体系统中利用大规模语言模型进行自然对话的问题，提出了一种新的框架——“谋杀之谜代理人”，将对话分析中的对话规范（如相邻对和轮流机制）应用于AI代理的对话控制。通过使用需要复杂社会推理和信息操作的回合制推理游戏“谋杀之谜”作为评估目标，该框架整合了基于相邻对的下一个说话者选择以及考虑了代理内部状态的自我选择机制，以实现更自然和策略性的对话。实验结果表明，实施下一个说话者选择机制显著减少了对话中断，提高了代理人分享信息和进行逻辑推理的能力。这项研究表明，人类会话中的轮流机制规律同样适用于AI代理间的对话控制，并为构建更高级的多智能体对话系统提供了设计指南。 <div>
arXiv:2412.04937v2 Announce Type: replace 
Abstract: Multi-agent systems utilizing large language models (LLMs) have shown great promise in achieving natural dialogue. However, smooth dialogue control and autonomous decision making among agents still remain challenges. In this study, we focus on conversational norms such as adjacency pairs and turn-taking found in conversation analysis and propose a new framework called "Murder Mystery Agents" that applies these norms to AI agents' dialogue control. As an evaluation target, we employed the "Murder Mystery" game, a reasoning-type table-top role-playing game that requires complex social reasoning and information manipulation. In this game, players need to unravel the truth of the case based on fragmentary information through cooperation and bargaining. The proposed framework integrates next speaker selection based on adjacency pairs and a self-selection mechanism that takes agents' internal states into account to achieve more natural and strategic dialogue. To verify the effectiveness of this new approach, we analyzed utterances that led to dialogue breakdowns and conducted automatic evaluation using LLMs, as well as human evaluation using evaluation criteria developed for the Murder Mystery game. Experimental results showed that the implementation of the next speaker selection mechanism significantly reduced dialogue breakdowns and improved the ability of agents to share information and perform logical reasoning. The results of this study demonstrate that the systematics of turn-taking in human conversation are also effective in controlling dialogue among AI agents, and provide design guidelines for more advanced multi-agent dialogue systems.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Text to Trajectory: Exploring Complex Constraint Representation and Decomposition in Safe Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.08920</link>
<guid>https://arxiv.org/abs/2412.08920</guid>
<content:encoded><![CDATA[
<div> 关键词：安全强化学习、自然语言约束、训练信号、轨迹级文本约束翻译器、零-shot转移能力

<br><br>总结:
本文主要探讨了如何在安全强化学习中利用自然语言约束来指导智能体完成任务并遵循特定限制。现有的方法通常需要针对每个约束手动设计成本函数，而该论文提出了一种名为Trajectory-level Textual Constraints Translator (TTCT)的新方法，它利用文本的双重作用，不仅提供约束，还作为训练信号替代了手动设计的成本函数。实验表明，TTCT能够有效地理解文本约束和轨迹，并能训练出违反率更低的策略。此外，论文还进行了额外的研究，证明TTCT具有零-shot转移能力，能够在约束环境变化的情况下进行适应。 <div>
arXiv:2412.08920v2 Announce Type: replace 
Abstract: Safe reinforcement learning (RL) requires the agent to finish a given task while obeying specific constraints. Giving constraints in natural language form has great potential for practical scenarios due to its flexible transfer capability and accessibility. Previous safe RL methods with natural language constraints typically need to design cost functions manually for each constraint, which requires domain expertise and lacks flexibility. In this paper, we harness the dual role of text in this task, using it not only to provide constraint but also as a training signal. We introduce the Trajectory-level Textual Constraints Translator (TTCT) to replace the manually designed cost function. Our empirical results demonstrate that TTCT effectively comprehends textual constraint and trajectory, and the policies trained by TTCT can achieve a lower violation rate than the standard cost function. Extra studies are conducted to demonstrate that the TTCT has zero-shot transfer capability to adapt to constraint-shift environments.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring and Controlling Diversity in LLM-Agent Conversation</title>
<link>https://arxiv.org/abs/2412.21102</link>
<guid>https://arxiv.org/abs/2412.21102</guid>
<content:encoded><![CDATA[
<div> 关键词: 控制多样性、LLM-agent、世界模拟、对话多样性、适应性提示修剪(APP)

总结:
本文关注于在LLM-agent世界模拟中控制对话多样性的关键问题，指出长期模拟中对话多样性显著下降。通过模块化对话生成提示，研究发现减少给定信息可以带来更丰富的输出。因此，文章提出了一个名为“适应性提示修剪”（APP）的新方法，该方法让用户能够通过单一参数lambda来动态调整并控制输出多样性。APP根据注意力权重动态地裁剪对话生成提示，并与传统的多样性控制技术兼容。实验表明APP能有效控制输出多样性，并提出一种平衡控制权衡的方法。此外，文中还进行了深入分析，为优化多智能体模拟中的多样性控制提供了见解。 <div>
arXiv:2412.21102v2 Announce Type: replace 
Abstract: Controlling diversity in LLM-agent world simulations is essential for maintaining stability in structured tasks while enabling variation where creativity is needed. However, we observe that dialogue diversity declines significantly over long-term simulation. To investigate the role of prompt design in conversational diversity, we modularized the utterance generation prompt and found that reducing the given information leads to more diverse outputs. Based on this insight, we propose Adaptive Prompt Pruning (APP), a novel method that allows users to control diversity through a single parameter, lambda. APP dynamically prunes the utterance generation prompt based on their attention weights and is compatible with traditional diversity control techniques. We demonstrate that APP effectively controls output diversity through extensive experiments, and propose a method to balance the control trade-offs. Additionally, we provide an in-depth analysis to offer insights into optimizing diversity control in multi-agent simulation.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A View of the Certainty-Equivalence Method for PAC RL as an Application of the Trajectory Tree Method</title>
<link>https://arxiv.org/abs/2501.02652</link>
<guid>https://arxiv.org/abs/2501.02652</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning）、最大似然估计（Maximum Likelihood Estimate）、确定性等价方法（Certainty-Equivalence Method, CEM）、轨迹树方法（Trajectory Tree Method, TTM）、采样复杂度（Sample Complexity）

<br><br>
总结:
本文研究了强化学习中的确定性等价方法(CEM)与轨迹树方法(TTM)之间的理论联系。发现CEM实际上可以视为TTM的一种应用形式。这一新视角带来了三个主要成果：(1) 提供了关于CEM的新颖且简洁的样本复杂度上界证明；(2) 在较弱的奖励假设下进行此分析，适用于非平稳和平稳MDP；(3) 对于小错误概率δ的情况，改进了CEM在非平稳和平稳MDP上的样本复杂度上界；(4) 展示了一个有限时间horizon MDP的样本复杂度下界，从而证明了在小δ场景下非平稳MDP中上界的最小最大最优性。 <div>
arXiv:2501.02652v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) enables an agent interacting with an unknown MDP $M$ to optimise its behaviour by observing transitions sampled from $M$. A natural entity that emerges in the agent's reasoning is $\widehat{M}$, the maximum likelihood estimate of $M$ based on the observed transitions. The well-known \textit{certainty-equivalence} method (CEM) dictates that the agent update its behaviour to $\widehat{\pi}$, which is an optimal policy for $\widehat{M}$. Not only is CEM intuitive, it has been shown to enjoy minimax-optimal sample complexity in some regions of the parameter space for PAC RL with a generative model~\citep{Agarwal2020GenModel}.
  A seemingly unrelated algorithm is the ``trajectory tree method'' (TTM)~\citep{Kearns+MN:1999}, originally developed for efficient decision-time planning in large POMDPs. This paper presents a theoretical investigation that stems from the surprising finding that CEM may indeed be viewed as an application of TTM. The qualitative benefits of this view are (1) new and simple proofs of sample complexity upper bounds for CEM, in fact under a (2) weaker assumption on the rewards than is prevalent in the current literature. Our analysis applies to both non-stationary and stationary MDPs. Quantitatively, we obtain (3) improvements in the sample-complexity upper bounds for CEM both for non-stationary and stationary MDPs, in the regime that the ``mistake probability'' $\delta$ is small. Additionally, we show (4) a lower bound on the sample complexity for finite-horizon MDPs, which establishes the minimax-optimality of our upper bound for non-stationary MDPs in the small-$\delta$ regime.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Equivariant Policy via Frame Transfer</title>
<link>https://arxiv.org/abs/2502.05728</link>
<guid>https://arxiv.org/abs/2502.05728</guid>
<content:encoded><![CDATA[
<div> 关键词：层次化策略学习、高层代理、低层代理、框架转移接口、域对称性

总结:
本文提出了一个名为层次化等变策略(HEP)的新型层次化政策框架，旨在解决现有层次化方法中高层和低层代理间接口未充分探索以及忽略领域对称性的问题。HEP通过高层代理的输出作为低层代理的坐标框架的“框架转移接口”，为层次化策略学习提供了强大的归纳偏置并保持了灵活性。同时，HEP将域对称性融入到各级别中，并从理论上证明了系统的整体等变性。实验结果显示，HEP在复杂机器人操纵任务上表现出最先进的性能，无论是在模拟环境还是现实世界中都取得了显著的改进效果。 <div>
arXiv:2502.05728v3 Announce Type: replace 
Abstract: Recent advances in hierarchical policy learning highlight the advantages of decomposing systems into high-level and low-level agents, enabling efficient long-horizon reasoning and precise fine-grained control. However, the interface between these hierarchy levels remains underexplored, and existing hierarchical methods often ignore domain symmetry, resulting in the need for extensive demonstrations to achieve robust performance. To address these issues, we propose Hierarchical Equivariant Policy (HEP), a novel hierarchical policy framework. We propose a frame transfer interface for hierarchical policy learning, which uses the high-level agent's output as a coordinate frame for the low-level agent, providing a strong inductive bias while retaining flexibility. Additionally, we integrate domain symmetries into both levels and theoretically demonstrate the system's overall equivariance. HEP achieves state-of-the-art performance in complex robotic manipulation tasks, demonstrating significant improvements in both simulation and real-world settings.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Training Turn-by-Turn Verifiers for Dialogue Tutoring Agents: The Curious Case of LLMs as Your Coding Tutors</title>
<link>https://arxiv.org/abs/2502.13311</link>
<guid>https://arxiv.org/abs/2502.13311</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能辅导代理人、大规模语言模型、编程教学、Trace-and-Verify (TRAVER)、DICT自动评估协议

<br><br>总结:
本文探讨了利用大规模语言模型驱动的智能辅导代理人在解决复杂现实任务方面的潜力，特别关注于编程教学这一挑战性问题。文中提出了一种新的代理工作流——Trace-and-Verify (TRAVER)，该方法结合知识追踪以估计学生的学习状态，并通过逐回合验证确保对学生完成编码任务的有效指导。同时，文章介绍了DICT，一种自动评估协议，它可以全面地通过控制学生模拟和代码生成测试来评估导师代理。实验结果显示了编程教学中的挑战以及TRAVER在成功率上的显著优势。尽管本文以编程教学为例，但其结果和发现可以推广到更广泛的领域，为各类任务的辅导代理人发展提供了有价值的见解。 <div>
arXiv:2502.13311v2 Announce Type: replace 
Abstract: Intelligent tutoring agents powered by large language models (LLMs) have been increasingly explored to deliver personalized guidance in areas such as language learning and science education. However, their capabilities in guiding users to solve complex real-world tasks remain underexplored. To address this limitation, in this work, we focus on coding tutoring, a challenging problem that requires tutors to proactively guide students toward completing predefined coding tasks. We propose a novel agent workflow, Trace-and-Verify (TRAVER), which combines knowledge tracing to estimate a student's knowledge state and turn-by-turn verification to ensure effective guidance toward task completion. We introduce DICT, an automatic evaluation protocol that assesses tutor agents holistically using controlled student simulation and code generation tests. Extensive experiments reveal the challenges of coding tutoring and demonstrate that TRAVER achieves a significantly higher success rate. Although we use code tutoring as an example in this paper, our results and findings can be extended beyond coding, providing valuable insights into advancing tutoring agents for a variety of tasks.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MapNav: A Novel Memory Representation via Annotated Semantic Maps for VLM-based Vision-and-Language Navigation</title>
<link>https://arxiv.org/abs/2502.13451</link>
<guid>https://arxiv.org/abs/2502.13451</guid>
<content:encoded><![CDATA[
<div> 关键词: Vision-and-language 导航, VLN, Annotated Semantic Map, ASM, MapNav

总结:
本文介绍了MapNav，一种用于视觉与语言导航（VLN）的新型端到端模型，该模型针对传统方法在决策过程中依赖大量历史观测数据导致的存储和计算负担问题进行了创新。MapNav利用Annotated Semantic Map（ASM）替代历史帧，通过构建和更新顶部视图下的语义地图并结合关键区域的明确文本标签，将抽象语义转化为清晰的导航线索。实验表明，MapNav在模拟和真实世界环境中均达到了最先进的性能，验证了其有效性。此外，作者计划开源ASM生成的源代码和数据集以保证可复现性，并认为MapNav可以作为VLN领域的一种新记忆表示方法，为未来研究铺平道路。 <div>
arXiv:2502.13451v2 Announce Type: replace 
Abstract: Vision-and-language navigation (VLN) is a key task in Embodied AI, requiring agents to navigate diverse and unseen environments while following natural language instructions. Traditional approaches rely heavily on historical observations as spatio-temporal contexts for decision making, leading to significant storage and computational overhead. In this paper, we introduce MapNav, a novel end-to-end VLN model that leverages Annotated Semantic Map (ASM) to replace historical frames. Specifically, our approach constructs a top-down semantic map at the start of each episode and update it at each timestep, allowing for precise object mapping and structured navigation information. Then, we enhance this map with explicit textual labels for key regions, transforming abstract semantics into clear navigation cues and generate our ASM. MapNav agent using the constructed ASM as input, and use the powerful end-to-end capabilities of VLM to empower VLN. Extensive experiments demonstrate that MapNav achieves state-of-the-art (SOTA) performance in both simulated and real-world environments, validating the effectiveness of our method. Moreover, we will release our ASM generation source code and dataset to ensure reproducibility, contributing valuable resources to the field. We believe that our proposed MapNav can be used as a new memory representation method in VLN, paving the way for future research in this field.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PC-Agent: A Hierarchical Multi-Agent Collaboration Framework for Complex Task Automation on PC</title>
<link>https://arxiv.org/abs/2502.14282</link>
<guid>https://arxiv.org/abs/2502.14282</guid>
<content:encoded><![CDATA[
<div> 关键词: PC-Agent、MLLMs、Active Perception Module (APM)、Hierarchical multi-agent collaboration architecture、PC-Eval

总结:
本文提出了一种针对基于多模态预训练模型（MLLMs）的GUI代理框架——PC-Agent，该框架旨在解决PC场景中复杂交互环境和多应用工作流的问题。为了改善MLLMs在感知屏幕截图内容上的不足，文章设计了主动感知模块（APM）。在决策层面，提出了层次化的多代理协作架构，将决策过程分解为指令-子任务-动作三个层级，并设置了Manager、Progress、Decision及Reflection四个智能体分别负责指令分解、进度跟踪、逐步决策和错误反馈与调整。同时，文中引入了一个新的基准测试集PC-Eval，包含25条现实世界的复杂指令。实验结果显示，PC-Agent相比于现有最优方法，在任务成功率上绝对提升了32%。相关代码已开源，可在https://github.com/X-PLUG/MobileAgent/tree/main/PC-Agent获取。<br><br> <div>
arXiv:2502.14282v2 Announce Type: replace 
Abstract: In the field of MLLM-based GUI agents, compared to smartphones, the PC scenario not only features a more complex interactive environment, but also involves more intricate intra- and inter-app workflows. To address these issues, we propose a hierarchical agent framework named PC-Agent. Specifically, from the perception perspective, we devise an Active Perception Module (APM) to overcome the inadequate abilities of current MLLMs in perceiving screenshot content. From the decision-making perspective, to handle complex user instructions and interdependent subtasks more effectively, we propose a hierarchical multi-agent collaboration architecture that decomposes decision-making processes into Instruction-Subtask-Action levels. Within this architecture, three agents (i.e., Manager, Progress and Decision) are set up for instruction decomposition, progress tracking and step-by-step decision-making respectively. Additionally, a Reflection agent is adopted to enable timely bottom-up error feedback and adjustment. We also introduce a new benchmark PC-Eval with 25 real-world complex instructions. Empirical results on PC-Eval show that our PC-Agent achieves a 32% absolute improvement of task success rate over previous state-of-the-art methods. The code is available at https://github.com/X-PLUG/MobileAgent/tree/main/PC-Agent.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>I-MCTS: Enhancing Agentic AutoML via Introspective Monte Carlo Tree Search</title>
<link>https://arxiv.org/abs/2502.14693</link>
<guid>https://arxiv.org/abs/2502.14693</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，蒙特卡洛树搜索 (MCTS)，内省式蒙特卡洛树搜索 (I-MCTS)，自动机器学习 (AutoML)，性能提升

总结:
本文提出了一种名为内省式蒙特卡洛树搜索（I-MCTS）的新方法，用于改进基于大型语言模型（LLMs）的代理在自动化机器学习任务中的低多样性与次优代码生成问题。I-MCTS通过分析父节点和兄弟节点的解决方案及结果进行迭代扩展，从而优化决策过程。此外，文中还结合了基于LLM的价值模型对每个节点的解决方案进行直接评估，并采用混合奖励机制，使Q值从LLM估算分数平滑过渡到实际性能分数，从而使高质量节点能更早被遍历。实验表明，相较于现有的开源AutoML代理，该方法在各种机器学习任务上实现了6%的绝对性能提升，证实了其在增强智能AutoML系统方面的有效性。相关资源可在https://github.com/jokieleung/I-MCTS找到。 <div>
arXiv:2502.14693v2 Announce Type: replace 
Abstract: Recent advancements in large language models (LLMs) have shown remarkable potential in automating machine learning tasks. However, existing LLM-based agents often struggle with low-diversity and suboptimal code generation. While recent work has introduced Monte Carlo Tree Search (MCTS) to address these issues, limitations persist in the quality and diversity of thoughts generated, as well as in the scalar value feedback mechanisms used for node selection. In this study, we introduce Introspective Monte Carlo Tree Search (I-MCTS), a novel approach that iteratively expands tree nodes through an introspective process that meticulously analyzes solutions and results from parent and sibling nodes. This facilitates a continuous refinement of the node in the search tree, thereby enhancing the overall decision-making process. Furthermore, we integrate a Large Language Model (LLM)-based value model to facilitate direct evaluation of each node's solution prior to conducting comprehensive computational rollouts. A hybrid rewarding mechanism is implemented to seamlessly transition the Q-value from LLM-estimated scores to actual performance scores. This allows higher-quality nodes to be traversed earlier. Applied to the various ML tasks, our approach demonstrates a 6% absolute improvement in performance compared to the strong open-source AutoML agents, showcasing its effectiveness in enhancing agentic AutoML systems. Resource available at https://github.com/jokieleung/I-MCTS
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Coordination across Diverse Applications: A Survey</title>
<link>https://arxiv.org/abs/2502.14743</link>
<guid>https://arxiv.org/abs/2502.14743</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协调、人工智能、统一理解、应用、研究方向

总结:
本文是对多智能体协调研究现状的综述，重点关注这一领域由于新兴应用和AI技术快速发展而受到的广泛关注。文章通过回答关于协调的四个基本问题（什么是协调、为何需要协调、与谁协调以及如何协调），提供了一个统一的理解框架。首先，文中识别并分析了各种应用场景中的基本协调问题；其次，调查了一系列多智能体系统应用，涵盖了从搜救、仓库自动化与物流、交通系统等传统领域到人形机器人、卫星系统和大规模语言模型等新兴领域。最后，文章讨论了MAS在可扩展性、异质性和学习机制等方面的开放挑战，并特别指出混合层次化与分布式协调、人-多智能体协调及基于LLM的多智能体系统是具有潜力的研究方向。 <div>
arXiv:2502.14743v2 Announce Type: replace 
Abstract: Multi-agent coordination studies the underlying mechanism enabling the trending spread of diverse multi-agent systems (MAS) and has received increasing attention, driven by the expansion of emerging applications and rapid AI advances. This survey outlines the current state of coordination research across applications through a unified understanding that answers four fundamental coordination questions: (1) what is coordination; (2) why coordination; (3) who to coordinate with; and (4) how to coordinate. Our purpose is to explore existing ideas and expertise in coordination and their connections across diverse applications, while identifying and highlighting emerging and promising research directions. First, general coordination problems that are essential to varied applications are identified and analyzed. Second, a number of MAS applications are surveyed, ranging from widely studied domains, e.g., search and rescue, warehouse automation and logistics, and transportation systems, to emerging fields including humanoid and anthropomorphic robots, satellite systems, and large language models (LLMs). Finally, open challenges about the scalability, heterogeneity, and learning mechanisms of MAS are analyzed and discussed. In particular, we identify the hybridization of hierarchical and decentralized coordination, human-MAS coordination, and LLM-based MAS as promising future directions.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
<pubDate>Mon, 24 Feb 2025 00:00:00 -0500</pubDate>
</item>

</channel>
</rss>