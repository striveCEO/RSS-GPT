<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>cs updates on arXiv.org</title>
<link>http://rss.arxiv.org/rss/cs</link>


<item>
<title>Open-World Skill Discovery from Unsegmented Demonstrations</title>
<link>https://arxiv.org/abs/2503.10684</link>
<guid>https://arxiv.org/abs/2503.10684</guid>
<content:encoded><![CDATA[
<div> 关键词: 自监督学习、技能边界检测、SBD、Minecraft、在线演示视频

总结:<br />
本文提出了一种名为Skill Boundary Detection (SBD)的无标注时空视频分割算法，用于解决开放世界环境中从长时间未分割的在线演示视频中自动识别和分割技能片段的问题。该方法基于自监督学习，利用预训练的无条件动作预测模型的预测误差来检测技能执行的转变，从而确定技能边界。在Minecraft游戏环境中进行的评估显示，使用SBD生成的技能段落能够显著提升条件策略在短期原子技能任务上的性能（提升63.7%和52.1%）以及其对应层次化代理在长期任务上的性能（提升11.3%和20.8%）。此外，该方法还可利用YouTube等平台上的丰富视频资源来训练指令遵循型智能体。相关项目页面可在https://craftjarvis.github.io/SkillDiscovery找到。 <div>
arXiv:2503.10684v1 Announce Type: new 
Abstract: Learning skills in open-world environments is essential for developing agents capable of handling a variety of tasks by combining basic skills. Online demonstration videos are typically long but unsegmented, making them difficult to segment and label with skill identifiers. Unlike existing methods that rely on sequence sampling or human labeling, we have developed a self-supervised learning-based approach to segment these long videos into a series of semantic-aware and skill-consistent segments. Drawing inspiration from human cognitive event segmentation theory, we introduce Skill Boundary Detection (SBD), an annotation-free temporal video segmentation algorithm. SBD detects skill boundaries in a video by leveraging prediction errors from a pretrained unconditional action-prediction model. This approach is based on the assumption that a significant increase in prediction error indicates a shift in the skill being executed. We evaluated our method in Minecraft, a rich open-world simulator with extensive gameplay videos available online. Our SBD-generated segments improved the average performance of conditioned policies by 63.7% and 52.1% on short-term atomic skill tasks, and their corresponding hierarchical agents by 11.3% and 20.8% on long-horizon tasks. Our method can leverage the diverse YouTube videos to train instruction-following agents. The project page can be found in https://craftjarvis.github.io/SkillDiscovery.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Contextualize Web Pages for Enhanced Decision Making by LLM Agents</title>
<link>https://arxiv.org/abs/2503.10689</link>
<guid>https://arxiv.org/abs/2503.10689</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、LCoW、网页理解、决策制定、WorkArena基准

总结:
本文介绍了LCoW框架，该框架旨在通过学习使大型语言模型更好地理解和处理复杂的网页结构，从而提升基于LLM的网络任务自动化代理的决策能力。LCoW将网页理解与决策制定解耦，训练了一个独立的上下文化模块来转换复杂网页为易懂形式，供决策代理使用。实验结果显示，LCoW可显著提高包括闭源（如Gemini-1.5-flash、GPT-4o、Claude-3.5-Sonnet）和开源（如Llama-3.1-8B、Llama-3.1-70B）在内的各种规模的LLM代理的成功率，在WorkArena基准上平均提升了15.6%，并使开源LM在该基准上的成功率平均提高了23.7%。特别地，应用了LCoW的Gemini-1.5-flash代理在WebShop基准上达到了超越人类专家的最优性能。相关代码材料可在项目页面https://lcowiclr2025.github.io获取。 <div>
arXiv:2503.10689v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have led to a growing interest in developing LLM-based agents for automating web tasks. However, these agents often struggle with even simple tasks on real-world websites due to their limited capability to understand and process complex web page structures. In this work, we introduce LCoW, a framework for Learning language models to Contextualize complex Web pages into a more comprehensible form, thereby enhancing decision making by LLM agents. LCoW decouples web page understanding from decision making by training a separate contextualization module to transform complex web pages into comprehensible format, which are then utilized by the decision-making agent. We demonstrate that our contextualization module effectively integrates with LLM agents of various scales to significantly enhance their decision-making capabilities in web automation tasks. Notably, LCoW improves the success rates of closed-source LLMs (e.g., Gemini-1.5-flash, GPT-4o, Claude-3.5-Sonnet) by an average of 15.6%, and demonstrates a 23.7% average improvement in success rates for open-source LMs (e.g., Llama-3.1-8B, Llama-3.1-70B) on the WorkArena benchmark. Moreover, the Gemini-1.5-flash agent with LCoW achieves state-of-the-art results on the WebShop benchmark, outperforming human experts. The relevant code materials are available at our project page: https://lcowiclr2025.github.io.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Shot Subject-Centric Generation for Creative Application Using Entropy Fusion</title>
<link>https://arxiv.org/abs/2503.10697</link>
<guid>https://arxiv.org/abs/2503.10697</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成模型、文本到图像、主题参考生成、熵基特征加权融合、大型语言模型

总结:
本文提出了一种针对主题中心图像生成的可靠框架，旨在解决文本到图像模型在实际应用中去除不需要元素的难题。该框架采用了熵基特征加权融合方法，结合预训练的文本到图像模型FLUX的多步采样跨注意力特征，实现精确的掩模预测和主题中心生成。同时，利用基于大型语言模型（LLMs）的代理框架，将用户的随意输入转化为更具描述性的提示，生成高度详细的图像。这些代理还会从提示中提取主要元素，引导熵基特征融合，确保生成聚焦于主要元素的图像而无额外成分。实验结果和用户研究表明，所提方法能生成高质量的主题中心图像，优于现有方法和其他可能的流程，证实了该方法的有效性。 <div>
arXiv:2503.10697v1 Announce Type: new 
Abstract: Generative models are widely used in visual content creation. However, current text-to-image models often face challenges in practical applications-such as textile pattern design and meme generation-due to the presence of unwanted elements that are difficult to separate with existing methods. Meanwhile, subject-reference generation has emerged as a key research trend, highlighting the need for techniques that can produce clean, high-quality subject images while effectively removing extraneous components. To address this challenge, we introduce a framework for reliable subject-centric image generation. In this work, we propose an entropy-based feature-weighted fusion method to merge the informative cross-attention features obtained from each sampling step of the pretrained text-to-image model FLUX, enabling a precise mask prediction and subject-centric generation. Additionally, we have developed an agent framework based on Large Language Models (LLMs) that translates users' casual inputs into more descriptive prompts, leading to highly detailed image generation. Simultaneously, the agents extract primary elements of prompts to guide the entropy-based feature fusion, ensuring focused primary element generation without extraneous components. Experimental results and user studies demonstrate our methods generates high-quality subject-centric images, outperform existing methods or other possible pipelines, highlighting the effectiveness of our approach.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SciFi-Benchmark: How Would AI-Powered Robots Behave in Science Fiction Literature?</title>
<link>https://arxiv.org/abs/2503.10706</link>
<guid>https://arxiv.org/abs/2503.10706</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、机器人、道德行为、科幻小说、基准测试<br /><br />总结:
本文提出了一种通过分析824部科幻文学作品中机器人的关键决策来探究人工智能系统控制的机器人是否能与人类价值观保持高度一致的方法。研究利用大型语言模型生成类似情境下的问题和决策选项，并通过人类投票的答案来衡量模型与人类价值观的一致性。此外，文章还提出了可通过修订过程自动优化的科幻小说启发式宪法，旨在为现实世界中的AI和机器人制定道德行为准则。结果显示，现代大型语言模型结合此类宪法表现出与人类价值观的高度一致性（95.8%），远高于科幻作品中的表现（仅21.2%）。生成的宪法也显著提高了模型的对齐度，并在基于真实世界图像和医院伤害报告的ASIMOV基准上表现出色。为此，研究人员发布了SciFi-Benchmark，这是一个大规模数据集，包含9,056个问题和53,384个答案以及一小部分人工标注的评估集，旨在推动机器人伦理和安全领域的研究。 <div>
arXiv:2503.10706v1 Announce Type: new 
Abstract: Given the recent rate of progress in artificial intelligence (AI) and robotics, a tantalizing question is emerging: would robots controlled by emerging AI systems be strongly aligned with human values? In this work, we propose a scalable way to probe this question by generating a benchmark spanning the key moments in 824 major pieces of science fiction literature (movies, tv, novels and scientific books) where an agent (AI or robot) made critical decisions (good or bad). We use a LLM's recollection of each key moment to generate questions in similar situations, the decisions made by the agent, and alternative decisions it could have made (good or bad). We then measure an approximation of how well models align with human values on a set of human-voted answers. We also generate rules that can be automatically improved via amendment process in order to generate the first Sci-Fi inspired constitutions for promoting ethical behavior in AIs and robots in the real world. Our first finding is that modern LLMs paired with constitutions turn out to be well-aligned with human values (95.8%), contrary to unsettling decisions typically made in SciFi (only 21.2% alignment). Secondly, we find that generated constitutions substantially increase alignment compared to the base model (79.4% to 95.8%), and show resilience to an adversarial prompt setting (23.3% to 92.3%). Additionally, we find that those constitutions are among the top performers on the ASIMOV Benchmark which is derived from real-world images and hospital injury reports. Sci-Fi-inspired constitutions are thus highly aligned and applicable in real-world situations. We release SciFi-Benchmark: a large-scale dataset to advance robot ethics and safety research. It comprises 9,056 questions and 53,384 answers, in addition to a smaller human-labeled evaluation set. Data is available at https://scifi-benchmark.github.io
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Long-Video Audio Synthesis with Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2503.10719</link>
<guid>https://arxiv.org/abs/2503.10719</guid>
<content:encoded><![CDATA[
<div> 关键词：video-to-audio 合成，长视频，LVAS-Agent，多代理框架，LVAS-Bench

总结:<br />
本文提出了一种名为LVAS-Agent的新型多代理框架，用于解决长视频的音频合成问题，以增强电影和互动媒体中的观众沉浸感和叙事连贯性。该框架通过专业配音工作流程的模拟，实现了场景分割、剧本生成、声音设计和音频合成四个步骤的协同角色专业化分工。其中，核心创新包括针对场景和剧本进行讨论修正的机制以及实现时间语义对齐的生成-检索循环。为便于系统评估，文章还引入了LVAS-Bench，这是首个涵盖207部跨多种场景的专业精选长视频的基准测试集。实验结果显示，与基线方法相比，LVAS-Agent在音视频对齐方面表现出优越性能。 <div>
arXiv:2503.10719v1 Announce Type: new 
Abstract: Video-to-audio synthesis, which generates synchronized audio for visual content, critically enhances viewer immersion and narrative coherence in film and interactive media. However, video-to-audio dubbing for long-form content remains an unsolved challenge due to dynamic semantic shifts, temporal misalignment, and the absence of dedicated datasets. While existing methods excel in short videos, they falter in long scenarios (e.g., movies) due to fragmented synthesis and inadequate cross-scene consistency. We propose LVAS-Agent, a novel multi-agent framework that emulates professional dubbing workflows through collaborative role specialization. Our approach decomposes long-video synthesis into four steps including scene segmentation, script generation, sound design and audio synthesis. Central innovations include a discussion-correction mechanism for scene/script refinement and a generation-retrieval loop for temporal-semantic alignment. To enable systematic evaluation, we introduce LVAS-Bench, the first benchmark with 207 professionally curated long videos spanning diverse scenarios. Experiments demonstrate superior audio-visual alignment over baseline methods.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design and Analysis of an Extreme-Scale, High-Performance, and Modular Agent-Based Simulation Platform</title>
<link>https://arxiv.org/abs/2503.10796</link>
<guid>https://arxiv.org/abs/2503.10796</guid>
<content:encoded><![CDATA[
<div> 关键词: agent-based modeling, BioDynaMo, TeraAgent, performance, modularity

总结:
本文介绍了针对复杂系统建模的新型模拟平台BioDynaMo及其重要改进TeraAgent。首先，BioDynaMo通过定义抽象、构建软件基础设施和实现多种功能，为agent-based modeling提供了模块化基础，并通过神经科学、流行病学和肿瘤学等案例证明其灵活性和易扩展性。其次，对性能进行了深入分析并提出优化方案，包括改进邻居搜索网格、减少内存访问延迟和利用领域知识避免冗余工作，从而实现了高达三个数量级的速度提升，使得单服务器可支持多达17亿个代理的模拟。第三，文章提出了分布式模拟引擎TeraAgent，能够将单个模拟的计算扩展到多台服务器上，解决了服务器通信瓶颈问题，通过序列化和增量编码加速并减少了数据传输，最终可以模拟5000亿个代理并扩展至84096个CPU核心。BioDynaMo已被广泛应用，包括一个获奖的放射治疗模拟项目，在2024年被评为物理学十大突破之一。 <div>
arXiv:2503.10796v1 Announce Type: new 
Abstract: Agent-based modeling is indispensable for studying complex systems across many domains. However, existing simulation platforms exhibit two major issues: performance and modularity. Low performance prevents simulations with a large number of agents, increases development time, limits parameter exploration, and raises computing costs. Inflexible software designs motivate modelers to create their own tools, diverting valuable resources.
  This dissertation introduces a novel simulation platform called BioDynaMo and its significant improvement, TeraAgent, to alleviate these challenges via three major works.
  First, we lay the platform's foundation by defining abstractions, establishing software infrastructure, and implementing a multitude of features for agent-based modeling. We demonstrate BioDynaMo's modularity through use cases in neuroscience, epidemiology, and oncology. We validate these models and show the simplicity of adding new functionality with few lines of code.
  Second, we perform a rigorous performance analysis and identify challenges for shared-memory parallelism. Provided solutions include an optimized grid for neighbor searching, mechanisms to reduce the memory access latency, and exploiting domain knowledge to omit unnecessary work. These improvements yield up to three orders of magnitude speedups, enabling simulations of 1.7 billion agents on a single server.
  Third, we present TeraAgent, a distributed simulation engine that allows scaling out the computation of one simulation to multiple servers. We identify and address server communication bottlenecks and implement solutions for serialization and delta encoding to accelerate and reduce data transfer. TeraAgent can simulate 500 billion agents and scales to 84096 CPU cores.
  BioDynaMo has been widely adopted, including a prize-winning radiotherapy simulation recognized as a top 10 breakthrough in physics in 2024.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Attacking Multimodal OS Agents with Malicious Image Patches</title>
<link>https://arxiv.org/abs/2503.10809</link>
<guid>https://arxiv.org/abs/2503.10809</guid>
<content:encoded><![CDATA[
<div> 关键词：恶意图像补丁(MIPs)，操作系统(OS)代理，视觉-语言模型，安全漏洞，攻击向量

<br /><br />总结:
该文提出了一种新型攻击方式——恶意图像补丁(MIPs)，它们经过对抗性扰动设计，能够在被截屏时诱使操作系统(OS)代理执行有害操作。MIPs能够嵌入桌面背景或通过社交媒体传播，引导OS代理访问恶意网站，从而实现进一步的利用。这些MIPs具备跨不同用户请求和屏幕布局的泛化能力，并能对多个OS代理保持效力。文章揭示了这类OS代理存在的严重安全隐患，指出在广泛采用前应谨慎处理这些问题。 <div>
arXiv:2503.10809v1 Announce Type: new 
Abstract: Recent advances in operating system (OS) agents enable vision-language models to interact directly with the graphical user interface of an OS. These multimodal OS agents autonomously perform computer-based tasks in response to a single prompt via application programming interfaces (APIs). Such APIs typically support low-level operations, including mouse clicks, keyboard inputs, and screenshot captures. We introduce a novel attack vector: malicious image patches (MIPs) that have been adversarially perturbed so that, when captured in a screenshot, they cause an OS agent to perform harmful actions by exploiting specific APIs. For instance, MIPs embedded in desktop backgrounds or shared on social media can redirect an agent to a malicious website, enabling further exploitation. These MIPs generalise across different user requests and screen layouts, and remain effective for multiple OS agents. The existence of such attacks highlights critical security vulnerabilities in OS agents, which should be carefully addressed before their widespread adoption.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Balanced and Fair Partitioning of Friends</title>
<link>https://arxiv.org/abs/2503.10830</link>
<guid>https://arxiv.org/abs/2503.10830</guid>
<content:encoded><![CDATA[
<div> 关键词: fair partitioning, friends, graph, utilities, complexity

总结:
该文研究了公平的朋友分区模型，这是一个基于图的代理间友谊关系的划分问题。文章将该模型扩展到了非二进制和非加性的代理效用场景。作者的主要贡献包括：(a) 将公平分割领域中的多个公平性概念适应并应用于这一新模型；(b) 提供了几种存在保证以及支持这些保证的多项式时间算法；(c) 针对此模型的计算复杂性和参数化复杂性展开了初步研究，并详尽地探讨了在各种公平概念下的可解性和不可解性边界。<br /><br /> <div>
arXiv:2503.10830v1 Announce Type: new 
Abstract: In the recently introduced model of fair partitioning of friends, there is a set of agents located on the vertices of an underlying graph that indicates the friendships between the agents. The task is to partition the graph into $k$ balanced-sized groups, keeping in mind that the value of an agent for a group equals the number of edges they have in that group. The goal is to construct partitions that are "fair", i.e., no agent would like to replace an agent in a different group. We generalize the standard model by considering utilities for the agents that are beyond binary and additive. Having this as our foundation, our contribution is threefold (a) we adapt several fairness notions that have been developed in the fair division literature to our setting; (b) we give several existence guarantees supported by polynomial-time algorithms; (c) we initiate the study of the computational (and parameterized) complexity of the model and provide an almost complete landscape of the (in)tractability frontier for our fairness concepts.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Teamwork makes the dream work: LLMs-Based Agents for GitHub README.MD Summarization</title>
<link>https://arxiv.org/abs/2503.10876</link>
<guid>https://arxiv.org/abs/2503.10876</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 多智能体框架, Metagente, 代码摘要, 性能提升

总结:
本文提出了一种名为Metagente的新颖方法，该方法利用多智能体框架协同优化不同领域的大型语言模型（LLMs）。Metagente中的各个专门代理通过评估、反馈和合作来迭代改进和优化任务提示。研究以软件工程领域的README.MD文件摘要任务为例，对比了GitSum、LLaMA-2和GPT-4o三个基线方法。实验结果显示，Metagente在仅使用少量数据进行微调的情况下，仍能达到高精度并显著优于基线方法，相较于最相关的基准GitSum，性能提升范围为27.63%至60.43%。更重要的是，与仅使用单一LLM相比，Metagente能够将准确性提升到数倍水平。 <div>
arXiv:2503.10876v1 Announce Type: new 
Abstract: The proliferation of Large Language Models (LLMs) in recent years has realized many applications in various domains. Being trained with a huge of amount of data coming from various sources, LLMs can be deployed to solve different tasks, including those in Software Engineering (SE). Though they have been widely adopted, the potential of using LLMs cooperatively has not been thoroughly investigated. In this paper, we proposed Metagente as a novel approach to amplify the synergy of various LLMs. Metagente is a Multi-Agent framework based on a series of LLMs to self-optimize the system through evaluation, feedback, and cooperation among specialized agents. Such a framework creates an environment where multiple agents iteratively refine and optimize prompts from various perspectives. The results of these explorations are then reviewed and aggregated by a teacher agent. To study its performance, we evaluated Metagente with an SE task, i.e., summarization of README.MD files, and compared it with three well-established baselines, i.e., GitSum, LLaMA-2, and GPT-4o. The results show that our proposed approach works efficiently and effectively, consuming a small amount of data for fine-tuning but still getting a high accuracy, thus substantially outperforming the baselines. The performance gain compared to GitSum, the most relevant benchmark, ranges from 27.63% to 60.43%. More importantly, compared to using only one LLM, Metagente boots up the accuracy to multiple folds.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trajectory Mamba: Efficient Attention-Mamba Forecasting Model Based on Selective SSM</title>
<link>https://arxiv.org/abs/2503.10898</link>
<guid>https://arxiv.org/abs/2503.10898</guid>
<content:encoded><![CDATA[
<div> 关键词：Trajectory Mamba、轨迹预测、自注意力机制、选择性状态空间模型（SSM）、自动驾驶

总结:
本文介绍了用于自动驾驶的高效轨迹预测框架——Trajectory Mamba，该框架基于选择性状态空间模型（SSM）。针对传统注意力机制在处理多目标时面临的计算成本问题，Trajectory Mamba重新设计了编码器-解码器架构中的自注意力机制，实现了线性时间复杂度。为保证预测准确性，文章提出了一种结合静态和动态环境的联合多边形编码策略。此外，为了平衡预测精度与推理速度，解码器采用了与编码器不同的结构，通过跨状态空间注意力机制，使得所有目标代理能够共享场景上下文信息并据此推断不同的未来轨迹。实验表明，Trajectory Mamba 在Argoverse 1和Argoverse 2数据集上不仅在推理速度和参数效率方面达到了最优水平，而且相比现有方法减少了四倍的FLOPs运算量以及超过40%的参数数量，同时在性能上超越了大多数先前的方法，验证了Trajectory Mamba在轨迹预测任务上的有效性。 <div>
arXiv:2503.10898v1 Announce Type: new 
Abstract: Motion prediction is crucial for autonomous driving, as it enables accurate forecasting of future vehicle trajectories based on historical inputs. This paper introduces Trajectory Mamba, a novel efficient trajectory prediction framework based on the selective state-space model (SSM). Conventional attention-based models face the challenge of computational costs that grow quadratically with the number of targets, hindering their application in highly dynamic environments. In response, we leverage the SSM to redesign the self-attention mechanism in the encoder-decoder architecture, thereby achieving linear time complexity. To address the potential reduction in prediction accuracy resulting from modifications to the attention mechanism, we propose a joint polyline encoding strategy to better capture the associations between static and dynamic contexts, ultimately enhancing prediction accuracy. Additionally, to balance prediction accuracy and inference speed, we adopted the decoder that differs entirely from the encoder. Through cross-state space attention, all target agents share the scene context, allowing the SSM to interact with the shared scene representation during decoding, thus inferring different trajectories over the next prediction steps. Our model achieves state-of-the-art results in terms of inference speed and parameter efficiency on both the Argoverse 1 and Argoverse 2 datasets. It demonstrates a four-fold reduction in FLOPs compared to existing methods and reduces parameter count by over 40% while surpassing the performance of the vast majority of previous methods. These findings validate the effectiveness of Trajectory Mamba in trajectory prediction tasks.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>H2-MARL: Multi-Agent Reinforcement Learning for Pareto Optimality in Hospital Capacity Strain and Human Mobility during Epidemic</title>
<link>https://arxiv.org/abs/2503.10907</link>
<guid>https://arxiv.org/abs/2503.10907</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning, RL）、人类移动管理、医院容量、多智能体RL（Multi-Agent Reinforcement Learning, MARL）、疫情模拟

<br /><br />总结:

本文提出了一种基于多智能体强化学习（H2-MARL）的方法，用于在不同规模城市中实现医院容量和人类移动的有效平衡管理。研究针对COVID-19背景下限制人类移动与确保医院容量需求之间的紧张关系问题，通过构建具有在线可更新参数的乡镇级感染模型以及全城动态时空疫情模拟器，设计了H2-MARL算法。每个行政区域被视为一个智能体，采用带有权衡双目标奖励函数并结合专家知识的经验回放缓冲区进行训练。实验使用覆盖四个不同规模城市的超过十亿条记录的人类移动数据集进行验证，结果表明H2-MARL具备优化双重目标权衡的能力，能有效减轻医院容量压力同时最小化移动限制损失，并证明了该模型在不同规模城市疫情防控中的适用性和普适性。 <div>
arXiv:2503.10907v1 Announce Type: new 
Abstract: The necessity of achieving an effective balance between minimizing the losses associated with restricting human mobility and ensuring hospital capacity has gained significant attention in the aftermath of COVID-19. Reinforcement learning (RL)-based strategies for human mobility management have recently advanced in addressing the dynamic evolution of cities and epidemics; however, they still face challenges in achieving coordinated control at the township level and adapting to cities of varying scales. To address the above issues, we propose a multi-agent RL approach that achieves Pareto optimality in managing hospital capacity and human mobility (H2-MARL), applicable across cities of different scales. We first develop a township-level infection model with online-updatable parameters to simulate disease transmission and construct a city-wide dynamic spatiotemporal epidemic simulator. On this basis, H2-MARL is designed to treat each division as an agent, with a trade-off dual-objective reward function formulated and an experience replay buffer enriched with expert knowledge built. To evaluate the effectiveness of the model, we construct a township-level human mobility dataset containing over one billion records from four representative cities of varying scales. Extensive experiments demonstrate that H2-MARL has the optimal dual-objective trade-off capability, which can minimize hospital capacity strain while minimizing human mobility restriction loss. Meanwhile, the applicability of the proposed model to epidemic control in cities of varying scales is verified, which showcases its feasibility and versatility in practical applications.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TxAgent: An AI Agent for Therapeutic Reasoning Across a Universe of Tools</title>
<link>https://arxiv.org/abs/2503.10970</link>
<guid>https://arxiv.org/abs/2503.10970</guid>
<content:encoded><![CDATA[
<div> 关键词: TxAgent、多模态适应性模型、个性化治疗推荐、药物相互作用、临床推理

总结:
 <div>
arXiv:2503.10970v1 Announce Type: new 
Abstract: Precision therapeutics require multimodal adaptive models that generate personalized treatment recommendations. We introduce TxAgent, an AI agent that leverages multi-step reasoning and real-time biomedical knowledge retrieval across a toolbox of 211 tools to analyze drug interactions, contraindications, and patient-specific treatment strategies. TxAgent evaluates how drugs interact at molecular, pharmacokinetic, and clinical levels, identifies contraindications based on patient comorbidities and concurrent medications, and tailors treatment strategies to individual patient characteristics. It retrieves and synthesizes evidence from multiple biomedical sources, assesses interactions between drugs and patient conditions, and refines treatment recommendations through iterative reasoning. It selects tools based on task objectives and executes structured function calls to solve therapeutic tasks that require clinical reasoning and cross-source validation. The ToolUniverse consolidates 211 tools from trusted sources, including all US FDA-approved drugs since 1939 and validated clinical insights from Open Targets. TxAgent outperforms leading LLMs, tool-use models, and reasoning agents across five new benchmarks: DrugPC, BrandPC, GenericPC, TreatmentPC, and DescriptionPC, covering 3,168 drug reasoning tasks and 456 personalized treatment scenarios. It achieves 92.1% accuracy in open-ended drug reasoning tasks, surpassing GPT-4o and outperforming DeepSeek-R1 (671B) in structured multi-step reasoning. TxAgent generalizes across drug name variants and descriptions. By integrating multi-step inference, real-time knowledge grounding, and tool-assisted decision-making, TxAgent ensures that treatment recommendations align with established clinical guidelines and real-world evidence, reducing the risk of adverse events and improving therapeutic decision-making.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Observation-Graph Interaction and Key-Detail Guidance for Vision and Language Navigation</title>
<link>https://arxiv.org/abs/2503.11006</link>
<guid>https://arxiv.org/abs/2503.11006</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision and Language Navigation (VLN)，OIKG，观察图交互模块，关键细节指导模块，R2R和RxR数据集

总结:
本文提出了一种名为OIKG的新框架，用于提升视觉与语言导航（VLN）任务中智能体的导航性能。该框架包含两个核心组件：<br />
1. 观察图交互模块，它将角度信息和视觉信息解耦，并强化了导航空间中的边表示，从而更好地整合视觉观测和环境信息。<br />
2. 关键细节指导模块，则能够动态地从自然语言指令中抽取并利用精细的位置和物体信息，实现更精确的跨模态对齐和动态指令解释。<br />
通过这两种机制，OIKG显著提高了智能体遵循复杂导航指令的能力。实验结果表明，OIKG在R2R和RxR数据集上的多个评价指标上均取得了最优表现，验证了其在增强观察-指令对齐能力方面的有效性。 <div>
arXiv:2503.11006v1 Announce Type: new 
Abstract: Vision and Language Navigation (VLN) requires an agent to navigate through environments following natural language instructions. However, existing methods often struggle with effectively integrating visual observations and instruction details during navigation, leading to suboptimal path planning and limited success rates. In this paper, we propose OIKG (Observation-graph Interaction and Key-detail Guidance), a novel framework that addresses these limitations through two key components: (1) an observation-graph interaction module that decouples angular and visual information while strengthening edge representations in the navigation space, and (2) a key-detail guidance module that dynamically extracts and utilizes fine-grained location and object information from instructions. By enabling more precise cross-modal alignment and dynamic instruction interpretation, our approach significantly improves the agent's ability to follow complex navigation instructions. Extensive experiments on the R2R and RxR datasets demonstrate that OIKG achieves state-of-the-art performance across multiple evaluation metrics, validating the effectiveness of our method in enhancing navigation precision through better observation-instruction alignment.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BannerAgency: Advertising Banner Design with Multimodal LLM Agents</title>
<link>https://arxiv.org/abs/2503.11060</link>
<guid>https://arxiv.org/abs/2503.11060</guid>
<content:encoded><![CDATA[
<div> 关键词: 广告横幅、设计、自动化、大型语言模型、BannerAgency

总结:<br />
本文介绍了一个无需训练的全自动广告横幅设计框架，该框架利用前沿的多模态大型语言模型（MLLMs），与广告商协作理解品牌特征和横幅目标，生成匹配背景图像，创建前景设计元素的蓝图，并以Figma或SVG可编辑组件格式渲染最终创意作品，而不仅仅是静态像素。文章提出了BannerAgency系统作为实现这一流程的MLLL代理。同时，为促进评估和未来研究，还引入了BannerRequest400基准数据集，包含100个独特logo搭配400种多样化的横幅请求。通过定量和定性评估，证明了该框架的有效性，强调了生成的横幅设计质量高、适应各种横幅请求以及由于采用基于组件的方法而具备的强大可编辑性。 <div>
arXiv:2503.11060v1 Announce Type: new 
Abstract: Advertising banners are critical for capturing user attention and enhancing advertising campaign effectiveness. Creating aesthetically pleasing banner designs while conveying the campaign messages is challenging due to the large search space involving multiple design elements. Additionally, advertisers need multiple sizes for different displays and various versions to target different sectors of audiences. Since design is intrinsically an iterative and subjective process, flexible editability is also in high demand for practical usage. While current models have served as assistants to human designers in various design tasks, they typically handle only segments of the creative design process or produce pixel-based outputs that limit editability. This paper introduces a training-free framework for fully automated banner ad design creation, enabling frontier multimodal large language models (MLLMs) to streamline the production of effective banners with minimal manual effort across diverse marketing contexts. We present BannerAgency, an MLLM agent system that collaborates with advertisers to understand their brand identity and banner objectives, generates matching background images, creates blueprints for foreground design elements, and renders the final creatives as editable components in Figma or SVG formats rather than static pixels. To facilitate evaluation and future research, we introduce BannerRequest400, a benchmark featuring 100 unique logos paired with 400 diverse banner requests. Through quantitative and qualitative evaluations, we demonstrate the framework's effectiveness, emphasizing the quality of the generated banner designs, their adaptability to various banner requests, and their strong editability enabled by this component-based approach.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>API Agents vs. GUI Agents: Divergence and Convergence</title>
<link>https://arxiv.org/abs/2503.11069</link>
<guid>https://arxiv.org/abs/2503.11069</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), API基础的LLM代理, 图形用户界面 (GUI) 基础的LLM代理, 混合方法, 自动化创新

<br /><br />总结:
本文是关于大型语言模型（LLMs）中API基础与GUI基础代理的首次全面比较研究。文章分析了这两种代理在架构复杂性、开发流程和用户体验模型上的差异以及潜在融合点。研究探讨了关键维度并指出了在哪些场景下混合方法可以结合两者的优点。作者提出了选择、组合或转换这两类代理的明确决策标准，并通过实例说明了实际应用案例。最后，指出随着LLM驱动的自动化创新持续发展，API驱动和GUI驱动的代理之间的界限将变得模糊，为各种现实世界应用场景带来更灵活、适应性强的解决方案。 <div>
arXiv:2503.11069v1 Announce Type: new 
Abstract: Large language models (LLMs) have evolved beyond simple text generation to power software agents that directly translate natural language commands into tangible actions. While API-based LLM agents initially rose to prominence for their robust automation capabilities and seamless integration with programmatic endpoints, recent progress in multimodal LLM research has enabled GUI-based LLM agents that interact with graphical user interfaces in a human-like manner. Although these two paradigms share the goal of enabling LLM-driven task automation, they diverge significantly in architectural complexity, development workflows, and user interaction models.
  This paper presents the first comprehensive comparative study of API-based and GUI-based LLM agents, systematically analyzing their divergence and potential convergence. We examine key dimensions and highlight scenarios in which hybrid approaches can harness their complementary strengths. By proposing clear decision criteria and illustrating practical use cases, we aim to guide practitioners and researchers in selecting, combining, or transitioning between these paradigms. Ultimately, we indicate that continuing innovations in LLM-based automation are poised to blur the lines between API- and GUI-driven agents, paving the way for more flexible, adaptive solutions in a wide range of real-world applications.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Reasoning Models in Agent Scenarios: Exploring the Necessity of Reasoning Capabilities</title>
<link>https://arxiv.org/abs/2503.11074</link>
<guid>https://arxiv.org/abs/2503.11074</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Reasoning Models (LRMs)，Large Language Models (LLMs)，LaRMA框架，Plan Design，Tool Usage

<br /><br />总结:

本文探讨了大型推理模型（LRMs）对传统基于执行的大型语言模型（LLMs）框架的影响，并提出了LaRMA评估框架，涵盖了工具使用、计划设计和问题解决等九项任务。研究发现，LRMs在需要大量推理的任务如计划设计中表现优于LLMs，得益于其迭代反思的能力；而LLMs在执行驱动的任务如工具使用上更胜一筹，注重效率。将LLMs作为执行者与LRMs作为反思者的混合配置可以优化代理性能，结合了执行速度和推理深度的优点。然而，LRMs增强的推理能力也带来了更高的计算成本、延长的处理时间和一些行为挑战，包括过度思考和忽略事实的倾向。这项研究为进一步探究LRMs如何平衡深入思考与过度思考提供了基础，为未来智能体设计的进步奠定了关键基石。 <div>
arXiv:2503.11074v1 Announce Type: new 
Abstract: The rise of Large Reasoning Models (LRMs) signifies a paradigm shift toward advanced computational reasoning. Yet, this progress disrupts traditional agent frameworks, traditionally anchored by execution-oriented Large Language Models (LLMs). To explore this transformation, we propose the LaRMA framework, encompassing nine tasks across Tool Usage, Plan Design, and Problem Solving, assessed with three top LLMs (e.g., Claude3.5-sonnet) and five leading LRMs (e.g., DeepSeek-R1). Our findings address four research questions: LRMs surpass LLMs in reasoning-intensive tasks like Plan Design, leveraging iterative reflection for superior outcomes; LLMs excel in execution-driven tasks such as Tool Usage, prioritizing efficiency; hybrid LLM-LRM configurations, pairing LLMs as actors with LRMs as reflectors, optimize agent performance by blending execution speed with reasoning depth; and LRMs' enhanced reasoning incurs higher computational costs, prolonged processing, and behavioral challenges, including overthinking and fact-ignoring tendencies. This study fosters deeper inquiry into LRMs' balance of deep thinking and overthinking, laying a critical foundation for future agent design advancements.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompt Alchemy: Automatic Prompt Refinement for Enhancing Code Generation</title>
<link>https://arxiv.org/abs/2503.11085</link>
<guid>https://arxiv.org/abs/2503.11085</guid>
<content:encoded><![CDATA[
<div> 关键词：Code Generation, Large Language Models, Prompt Engineering, Prochemy, Automated Refinement

总结:<br />
本文提出了一种名为Prochemy的新方法，旨在自动优化提示以提升大型语言模型在代码生成任务中的性能。Prochemy通过自动化优化过程、确保推理过程中的一致性以及支持多代理系统，克服了手动提示工程的时间消耗和不一致性问题。该方法根据模型性能迭代地改进提示，并使用优化后的最终提示来提高跨任务一致性。实验结果显示，Prochemy在自然语言为基础的代码生成和翻译任务上提高了GPT-3.5-Turbo和GPT-4o等模型的表现，例如在HumanEval任务中，相较于零样本基线，分别提升了5.0%和1.9%。对于代码翻译任务，Prochemy使GPT-4o在Java到Python (AVATAR)的任务性能从74.5提升至84.1（+12.9%），Python到Java从66.8提升至78.2（+17.1%）。此外，当与较小规模的o1-mini模型结合使用时，Prochemy仍能保持强劲的性能，从而验证了其在代码任务中的有效性。Prochemy设计为即插即用，能在极少的人工输入条件下优化提示，有效地弥合了简单提示与复杂框架之间的差距。 <div>
arXiv:2503.11085v1 Announce Type: new 
Abstract: Code generation has emerged as a key task to automate software development by converting high-level descriptions into executable code. Large language models (LLMs) excel at this but depend heavily on input prompt quality.Manual prompt engineering can be time-consuming and inconsistent, limiting LLM effectiveness. This paper introduces Prochemy, an innovative method for automatically refining prompts to boost code generation. Prochemy overcomes manual prompt limitations by automating optimization, ensuring consistency during inference, and supporting multi-agent systems.It iteratively refines prompts based on model performance, using an optimized final prompt for improved consistency across tasks. We tested Prochemy on natural language-based code generation and translation tasks using three LLM series. Results indicate Prochemy enhances existing methods, improving performance by 5.0% for GPT-3.5-Turbo and 1.9% for GPT-4o over zero-shot baselines on HumanEval. In state-of-the-art LDB, Prochemy + LDB surpasses standalone methods by 1.2-1.8%. For code translation, Prochemy boosts GPT-4o's Java-to-Python (AVATAR) performance from 74.5 to 84.1 (+12.9%) and Python-to-Java from 66.8 to 78.2 (+17.1%). Moreover, Prochemy maintains strong performance when integrated with the o1-mini model, validating its efficacy in code tasks. Designed as plug-and-play, Prochemy optimizes prompts with minimal human input, bridging the gap between simple prompts and complex frameworks.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EmbodiedVSR: Dynamic Scene Graph-Guided Chain-of-Thought Reasoning for Visual Spatial Tasks</title>
<link>https://arxiv.org/abs/2503.11089</link>
<guid>https://arxiv.org/abs/2503.11089</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态大型语言模型 (MLLMs)，空间推理，动态场景图，Chain-of-Thought (CoT) 推理，eSpatial-Benchmark

总结:<br />
本文提出了一种名为EmbodiedVSR的新框架，旨在通过结合动态场景图引导的Chain-of-Thought (CoT)推理方法，增强对具身智能体的空间理解能力，以解决复杂长时任务中的空间推理挑战。该框架利用动态场景图构建结构化知识表示，实现在无需任务特定微调的情况下进行零样本空间推理。同时，它能够拆解复杂的空间关系并使推理步骤与可执行的环境动态保持一致。为了严格评估性能，文章还引入了eSpatial-Benchmark，这是一个包括具有精细空间注释和适应性任务难度级别的现实世界具身场景的综合数据集。实验结果显示，相比于现有的基于MLLM的方法，我们的框架在准确性及推理连贯性方面表现出显著优势，尤其是在需要迭代环境交互的长时任务中。这表明，当配备有结构化、可解释的推理机制时，MLLMs在具身智能领域的潜力仍未被充分发掘，为其实现现实世界空间应用的可靠部署铺平道路。相关代码和数据集即将发布。 <div>
arXiv:2503.11089v1 Announce Type: new 
Abstract: While multimodal large language models (MLLMs) have made groundbreaking progress in embodied intelligence, they still face significant challenges in spatial reasoning for complex long-horizon tasks. To address this gap, we propose EmbodiedVSR (Embodied Visual Spatial Reasoning), a novel framework that integrates dynamic scene graph-guided Chain-of-Thought (CoT) reasoning to enhance spatial understanding for embodied agents. By explicitly constructing structured knowledge representations through dynamic scene graphs, our method enables zero-shot spatial reasoning without task-specific fine-tuning. This approach not only disentangles intricate spatial relationships but also aligns reasoning steps with actionable environmental dynamics. To rigorously evaluate performance, we introduce the eSpatial-Benchmark, a comprehensive dataset including real-world embodied scenarios with fine-grained spatial annotations and adaptive task difficulty levels. Experiments demonstrate that our framework significantly outperforms existing MLLM-based methods in accuracy and reasoning coherence, particularly in long-horizon tasks requiring iterative environment interaction. The results reveal the untapped potential of MLLMs for embodied intelligence when equipped with structured, explainable reasoning mechanisms, paving the way for more reliable deployment in real-world spatial applications. The codes and datasets will be released soon.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Aerial Vision-and-Language Navigation with Grid-based View Selection and Map Construction</title>
<link>https://arxiv.org/abs/2503.11091</link>
<guid>https://arxiv.org/abs/2503.11091</guid>
<content:encoded><![CDATA[
<div> 关键词：Aerial VLN、导航、垂直动作预测、鸟瞰图、跨模态Transformer

<br />
总结：
本文提出了一种针对无人机视觉与语言导航（Aerial VLN）的新方法。该方法通过构建网格基视图选择框架，将行动预测转化为考虑垂直和水平动作相互作用的任务，从而有效地调整飞行高度。同时，引入了基于网格的鸟瞰图映射空中环境，融合导航历史中的视觉信息并提供场景上下文，以减轻障碍物的影响。此外，采用跨模态Transformer来明确地将长时间的导航历史与指令对齐。实验表明，这种方法在大量实验中表现出优越性。 <div>
arXiv:2503.11091v1 Announce Type: new 
Abstract: Aerial Vision-and-Language Navigation (Aerial VLN) aims to obtain an unmanned aerial vehicle agent to navigate aerial 3D environments following human instruction. Compared to ground-based VLN, aerial VLN requires the agent to decide the next action in both horizontal and vertical directions based on the first-person view observations. Previous methods struggle to perform well due to the longer navigation path, more complicated 3D scenes, and the neglect of the interplay between vertical and horizontal actions. In this paper, we propose a novel grid-based view selection framework that formulates aerial VLN action prediction as a grid-based view selection task, incorporating vertical action prediction in a manner that accounts for the coupling with horizontal actions, thereby enabling effective altitude adjustments. We further introduce a grid-based bird's eye view map for aerial space to fuse the visual information in the navigation history, provide contextual scene information, and mitigate the impact of obstacles. Finally, a cross-modal transformer is adopted to explicitly align the long navigation history with the instruction. We demonstrate the superiority of our method in extensive experiments.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Open3DVQA: A Benchmark for Comprehensive Spatial Reasoning with Multimodal Large Language Model in Open Space</title>
<link>https://arxiv.org/abs/2503.11094</link>
<guid>https://arxiv.org/abs/2503.11094</guid>
<content:encoded><![CDATA[
<div> 关键词：Spatial reasoning, Multimodal large language models, Open3DVQA, Benchmark, State-of-the-art

总结:<br />
本文提出了一项新的基准测试——Open3DVQA，用于全面评估当前最先进的多模态大型语言模型在开放3D空间中的空间推理能力。该基准测试包含了使用高效半自动工具在高保真城市模拟器中收集的9000个VQA样本。研究对多个SOTA MLLM在相对和绝对空间关系、情境推理以及对象中心的空间属性等多个方面的空间推理能力进行了评估。结果显示，1）MLLM在回答关于相对空间关系的问题上表现优于绝对空间关系；2）MLLM在第一人称（egocentric）和第三人称（allocentric）视角下表现出相似的空间推理能力；3）微调大模型能显著提升它们在不同空间推理任务上的性能。作者认为，其开源的数据收集工具和深入的分析将激发更多关于MLLM空间推理能力的研究。Open3DVQA基准测试可在https://github.com/WeichenZh/Open3DVQA获取。 <div>
arXiv:2503.11094v1 Announce Type: new 
Abstract: Spatial reasoning is a fundamental capability of embodied agents and has garnered widespread attention in the field of multimodal large language models (MLLMs). In this work, we propose a novel benchmark, Open3DVQA, to comprehensively evaluate the spatial reasoning capacities of current state-of-the-art (SOTA) foundation models in open 3D space. Open3DVQA consists of 9k VQA samples, collected using an efficient semi-automated tool in a high-fidelity urban simulator. We evaluate several SOTA MLLMs across various aspects of spatial reasoning, such as relative and absolute spatial relationships, situational reasoning, and object-centric spatial attributes. Our results reveal that: 1) MLLMs perform better at answering questions regarding relative spatial relationships than absolute spatial relationships, 2) MLLMs demonstrate similar spatial reasoning abilities for both egocentric and allocentric perspectives, and 3) Fine-tuning large models significantly improves their performance across different spatial reasoning tasks. We believe that our open-source data collection tools and in-depth analyses will inspire further research on MLLM spatial reasoning capabilities. The benchmark is available at https://github.com/WeichenZh/Open3DVQA.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond the Destination: A Novel Benchmark for Exploration-Aware Embodied Question Answering</title>
<link>https://arxiv.org/abs/2503.11117</link>
<guid>https://arxiv.org/abs/2503.11117</guid>
<content:encoded><![CDATA[
<div> 关键词：Embodied Question Answering (EQA)，dataset design，evaluation metrics，Fine-EQA，EXPRESS-Bench

总结:
本文提出了一种针对 Embodied Question Answering (EQA) 任务的研究，指出现有方法在探索效率、数据集设计和评估指标上的不足，以及数据集偏差导致的非实体化推理问题。为了解决这些挑战，文章构建了名为 EXPRESS-Bench 的大型探索感知型问答基准数据集，包含了777条探索轨迹和2044对问题-轨迹对。为了提高探索效率，文中提出了结合前沿基础与目标导向导航的混合探索模型——Fine-EQA，能更有效地引导智能体向任务相关区域移动。同时，作者引入了一种新的评价指标——Exploration-Answer Consistency (EAC)，以确保通过衡量答案定位与探索可靠性的对齐程度来实现公正的评估。实验结果表明，使用 EXPRESS-Bench 可有效推进实体环境中的探索及问题推理能力的发展。 <div>
arXiv:2503.11117v1 Announce Type: new 
Abstract: Embodied Question Answering (EQA) is a challenging task in embodied intelligence that requires agents to dynamically explore 3D environments, actively gather visual information, and perform multi-step reasoning to answer questions. However, current EQA approaches suffer from critical limitations in exploration efficiency, dataset design, and evaluation metrics. Moreover, existing datasets often introduce biases or prior knowledge, leading to disembodied reasoning, while frontier-based exploration strategies struggle in cluttered environments and fail to ensure fine-grained exploration of task-relevant areas. To address these challenges, we construct the EXPloration-awaRe Embodied queStion anSwering Benchmark (EXPRESS-Bench), the largest dataset designed specifically to evaluate both exploration and reasoning capabilities. EXPRESS-Bench consists of 777 exploration trajectories and 2,044 question-trajectory pairs. To improve exploration efficiency, we propose Fine-EQA, a hybrid exploration model that integrates frontier-based and goal-oriented navigation to guide agents toward task-relevant regions more effectively. Additionally, we introduce a novel evaluation metric, Exploration-Answer Consistency (EAC), which ensures faithful assessment by measuring the alignment between answer grounding and exploration reliability. Extensive experimental comparisons with state-of-the-art EQA models demonstrate the effectiveness of our EXPRESS-Bench in advancing embodied exploration and question reasoning.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeskVision: Large Scale Desktop Region Captioning for Advanced GUI Agents</title>
<link>https://arxiv.org/abs/2503.11170</link>
<guid>https://arxiv.org/abs/2503.11170</guid>
<content:encoded><![CDATA[
<div> 关键词：AutoCaptioner、DeskVision、GUI数据生成、GUI理解模型、LVLMs

<br />
总结:
本文提出了一个自动化GUI数据生成工具AutoCaptioner，旨在以最小的人力成本生成具有丰富描述的数据，以解决当前GUI代理开发中面临的GUI数据限制问题。利用AutoCaptioner，研究者构建了一个大规模桌面GUI数据集DeskVision以及配套的大型测试基准DeskVision-Eval，该数据集涵盖了日常使用的多样系统和UI元素，并带有丰富的描述。基于DeskVision，他们训练出了一个新的GUI理解模型GUIExplorer，该模型在无需复杂架构设计的情况下展现出最先进的性能。此外，通过在各种大型视觉语言模型（LVLMs）上的消融实验验证了DeskVision数据集的有效性。研究人员认为AutoCaptioner和DeskVision将极大地推动GUI代理的发展，并宣布将它们开源供社区使用。 <div>
arXiv:2503.11170v1 Announce Type: new 
Abstract: The limitation of graphical user interface (GUI) data has been a significant barrier to the development of GUI agents today, especially for the desktop / computer use scenarios. To address this, we propose an automated GUI data generation pipeline, AutoCaptioner, which generates data with rich descriptions while minimizing human effort. Using AutoCaptioner, we created a novel large-scale desktop GUI dataset, DeskVision, along with the largest desktop test benchmark, DeskVision-Eval, which reflects daily usage and covers diverse systems and UI elements, each with rich descriptions. With DeskVision, we train a new GUI understanding model, GUIExplorer. Results show that GUIExplorer achieves state-of-the-art (SOTA) performance in understanding/grounding visual elements without the need for complex architectural designs. We further validated the effectiveness of the DeskVision dataset through ablation studies on various large visual language models (LVLMs). We believe that AutoCaptioner and DeskVision will significantly advance the development of GUI agents, and will open-source them for the community.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Ergodic exploration of dynamic distribution</title>
<link>https://arxiv.org/abs/2503.11235</link>
<guid>https://arxiv.org/abs/2503.11235</guid>
<content:encoded><![CDATA[
<div> 关键词：动态环境、漂移目标、流场、多智能体搜索、概率分布动力学<br /><br />总结:

这篇研究针对动态环境中，尤其是受流场影响而移动的漂移目标的搜索任务提出了一个新的方法。该方法结合了两个偏微分方程，分别用于描述目标概率分布的动力学和不确定性，以及指导多智能体进行遍历搜索的势场。目标概率场随着环境驱动的目标动态和感知努力的变化而演变，智能体则沿势场梯度进行探索。通过对比实验，该方法在合成领域的搜索场景中相对于静态目标概率的基线方法表现更优。此外，在一个模拟的海上搜救任务中展示了延迟开始搜索、多次机器人飞行任务执行以及目标漂移不确定性补偿的过程。文章还提出了一种基于已知检测/传感参数的准确调查完成度指标，该指标与实际发现的目标数量具有相关性。 <div>
arXiv:2503.11235v1 Announce Type: new 
Abstract: This research addresses the challenge of performing search missions in dynamic environments, particularly for drifting targets whose movement is dictated by a flow field. This is accomplished through a dynamical system that integrates two partial differential equations: one governing the dynamics and uncertainty of the probability distribution, and the other regulating the potential field for ergodic multi-agent search. The target probability field evolves in response to the target dynamics imposed by the environment and accomplished sensing efforts, while being explored by multiple robot agents guided by the potential field gradient. The proposed methodology was tested on two simulated search scenarios, one of which features a synthetically generated domain and showcases better performance when compared to the baseline method with static target probability over a range of agent to flow field velocity ratios. The second search scenario represents a realistic sea search and rescue mission where the search start is delayed, the search is performed in multiple robot flight missions, and the procedure for target drift uncertainty compensation is demonstrated. Furthermore, the proposed method provides an accurate survey completion metric, based on the known detection/sensing parameters, that correlates with the actual number of targets found independently.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaboration is all you need: LLM Assisted Safe Code Translation</title>
<link>https://arxiv.org/abs/2503.11237</link>
<guid>https://arxiv.org/abs/2503.11237</guid>
<content:encoded><![CDATA[
<div> 关键词：UniTranslator、LLMs、代码翻译、多代理系统、自然语言推理

总结:
<br />
本文介绍了UniTranslator这一创新框架，该框架将代码翻译视为多个小型LLMs之间的协作任务。通过协调专注于翻译过程不同方面的专业化代理并深入理解编程概念，UniTranslator实现了与大型单一模型相媲美的准确性和效率。初步评估显示，UniTranslator有望克服现有方法的局限性，并释放小型LLMs处理复杂代码翻译任务的能力。此外，文章探讨了这种动态多代理范式在处理多样化的语言对（包括低资源语言）以及利用自然语言推理（NLI）进行语义校验和迭代反馈机制以减轻常见问题如代码特征和幻象方面的作用。 <div>
arXiv:2503.11237v1 Announce Type: new 
Abstract: This paper introduces UniTranslator, a visionary framework that re-imagines code translation as a collaborative endeavor among multiple, compact LLMs. By orchestrating the interaction of specialized agents, each focused on different aspects of the translation process and grounded in a deep understanding of programming concepts, UniTranslator achieves a level of accuracy and efficiency that rivals larger, monolithic models. Our preliminary evaluation demonstrates the potential of UniTranslator to overcome the limitations of existing approaches and unlock the power of smaller LLMs for complex code translation tasks. We explore the effectiveness of this dynamic multi-agent paradigm in handling diverse language pairs, including low-resource languages, and in mitigating common issues such as code artifacts and hallucinations through the use of Natural Language Inference (NLI) grounding and iterative feedback mechanisms
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EmoAgent: Multi-Agent Collaboration of Plan, Edit, and Critic, for Affective Image Manipulation</title>
<link>https://arxiv.org/abs/2503.11290</link>
<guid>https://arxiv.org/abs/2503.11290</guid>
<content:encoded><![CDATA[
<div> 关键词: Affective Image Manipulation (AIM), EmoAgent, multi-agent collaboration framework, emotion-factor knowledge retriever, decision-making tree space

总结:<br />
本文提出了一种用于情感影响图像操纵（Affective Image Manipulation, AIM）的首个多智能体协作框架——EmoAgent。EmoAgent模拟人类画家的认知行为，包含负责规划、编辑和批判性评估的三个专业化智能体。此外，文章还开发了情绪因素知识检索器、决策树空间以及工具库，以提升EmoAgent在处理AIM任务中的效能。实验结果显示，该提出的多智能体框架相较于现有方法表现更优，能提供更为合理和有效的情感表达。 <div>
arXiv:2503.11290v1 Announce Type: new 
Abstract: Affective Image Manipulation (AIM) aims to alter an image's emotional impact by adjusting multiple visual elements to evoke specific feelings.Effective AIM is inherently complex, necessitating a collaborative approach that involves identifying semantic cues within source images, manipulating these elements to elicit desired emotional responses, and verifying that the combined adjustments successfully evoke the target emotion.To address these challenges, we introduce EmoAgent, the first multi-agent collaboration framework for AIM. By emulating the cognitive behaviors of a human painter, EmoAgent incorporates three specialized agents responsible for planning, editing, and critical evaluation. Furthermore, we develop an emotion-factor knowledge retriever, a decision-making tree space, and a tool library to enhance EmoAgent's effectiveness in handling AIM. Experiments demonstrate that the proposed multi-agent framework outperforms existing methods, offering more reasonable and effective emotional expression.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GNNs as Predictors of Agentic Workflow Performances</title>
<link>https://arxiv.org/abs/2503.11301</link>
<guid>https://arxiv.org/abs/2503.11301</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Agentic workflows, Graph Neural Networks (GNNs), FLORA-Bench, Workflow optimization

<br /><br />总结:
本文提出了一种针对大型语言模型（LLMs）所触发的代理工作流进行优化的新方法。该方法将工作流形式化为计算图，并倡导使用图神经网络（GNNs）作为有效预测代理工作流性能的工具，从而减少对LLM的重复调用和高昂成本。为了实证这一观点，作者构建了FLORA-Bench，这是一个统一平台，用于基准测试GNN预测代理工作流性能的能力。通过广泛的实验，得出结论：GNN是简单而有效的预测器。这一发现支持了GNN的新应用以及自动化的代理工作流优化研究新方向。所有代码、模型和数据可在https://github.com/youngsoul0731/Flora-Bench获取。 <div>
arXiv:2503.11301v1 Announce Type: new 
Abstract: Agentic workflows invoked by Large Language Models (LLMs) have achieved remarkable success in handling complex tasks. However, optimizing such workflows is costly and inefficient in real-world applications due to extensive invocations of LLMs. To fill this gap, this position paper formulates agentic workflows as computational graphs and advocates Graph Neural Networks (GNNs) as efficient predictors of agentic workflow performances, avoiding repeated LLM invocations for evaluation. To empirically ground this position, we construct FLORA-Bench, a unified platform for benchmarking GNNs for predicting agentic workflow performances. With extensive experiments, we arrive at the following conclusion: GNNs are simple yet effective predictors. This conclusion supports new applications of GNNs and a novel direction towards automating agentic workflow optimization. All codes, models, and data are available at https://github.com/youngsoul0731/Flora-Bench.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AIstorian lets AI be a historian: A KG-powered multi-agent system for accurate biography generation</title>
<link>https://arxiv.org/abs/2503.11346</link>
<guid>https://arxiv.org/abs/2503.11346</guid>
<content:encoded><![CDATA[
<div> 关键词：华为、AI应用、历史研究、传记生成、AIstorian

总结：
华为致力于探索AI在历史研究中的应用，特别关注传记生成这一专题，该领域在历史研究中具有重要意义，但面临保持历史性写作风格、确保事实准确性和处理跨多文档的碎片化信息等挑战。为此，华为提出了AIstorian，这是一个创新的一体化系统，采用知识图谱（KG）驱动的检索增强生成（RAG）和反幻觉多智能体技术。AIstorian利用基于实例学习的分块策略和KG索引来实现精确高效的参考信息检索，并通过多智能体实时检测与错误类型感知校正来防止幻觉生成。此外，为了使大型语言模型学习特定的语言风格，他们采用了结合数据增强增强监督微调与风格偏好优化的两步训练方法对模型进行微调。在实际的历史科举数据集上进行的广泛实验表明，相较于现有基线，AIstorian在事实准确性方面提高了3.8倍，减少了47.6%的幻觉发生率。相关数据和代码可在以下地址获取：https://github.com/ZJU-DAILY/AIstorian。 <div>
arXiv:2503.11346v1 Announce Type: new 
Abstract: Huawei has always been committed to exploring the AI application in historical research. Biography generation, as a specialized form of abstractive summarization, plays a crucial role in historical research but faces unique challenges that existing large language models (LLMs) struggle to address. These challenges include maintaining stylistic adherence to historical writing conventions, ensuring factual fidelity, and handling fragmented information across multiple documents. We present AIstorian, a novel end-to-end agentic system featured with a knowledge graph (KG)-powered retrieval-augmented generation (RAG) and anti-hallucination multi-agents. Specifically, AIstorian introduces an in-context learning based chunking strategy and a KG-based index for accurate and efficient reference retrieval. Meanwhile, AIstorian orchestrates multi-agents to conduct on-the-fly hallucination detection and error-type-aware correction. Additionally, to teach LLMs a certain language style, we finetune LLMs based on a two-step training approach combining data augmentation-enhanced supervised fine-tuning with stylistic preference optimization. Extensive experiments on a real-life historical Jinshi dataset demonstrate that AIstorian achieves a 3.8x improvement in factual accuracy and a 47.6% reduction in hallucination rate compared to existing baselines. The data and code are available at: https://github.com/ZJU-DAILY/AIstorian.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Torque Control of Exoskeletons under Spasticity Conditions via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.11433</link>
<guid>https://arxiv.org/abs/2503.11433</guid>
<content:encoded><![CDATA[
<div> 关键词: spasticity, 穿戴机器人, 深度强化学习, 关节僵直, 膝关节外骨骼

总结:

本文介绍了一种针对关节僵直症状（如脑瘫、遗传性痉挛性截瘫等疾病）的新型适应性力矩控制器，该控制器通过深度强化学习应用于膝关节外骨骼。研究者开发了一个数字孪生模型，包括考虑关节错位的肌肉骨骼-外骨骼系统以及可微分的肌梭反射模型来模拟不同水平的痉挛状态。实验结果显示，该智能控制器能够在痉挛条件下降低作用于人体关节的最大扭矩平均降幅为10.6%，并将根均方值减少至稳定时间降低了8.9%相较于传统的柔顺控制器。这表明，利用该方法有望使穿戴机器人更安全有效地用于高痉挛程度患者的治疗。 <div>
arXiv:2503.11433v1 Announce Type: new 
Abstract: Spasticity is a common movement disorder symptom in individuals with cerebral palsy, hereditary spastic paraplegia, spinal cord injury and stroke, being one of the most disabling features in the progression of these diseases. Despite the potential benefit of using wearable robots to treat spasticity, their use is not currently recommended to subjects with a level of spasticity above ${1^+}$ on the Modified Ashworth Scale. The varying dynamics of this velocity-dependent tonic stretch reflex make it difficult to deploy safe personalized controllers. Here, we describe a novel adaptive torque controller via deep reinforcement learning (RL) for a knee exoskeleton under joint spasticity conditions, which accounts for task performance and interaction forces reduction. To train the RL agent, we developed a digital twin, including a musculoskeletal-exoskeleton system with joint misalignment and a differentiable spastic reflexes model for the muscles activation. Results for a simulated knee extension movement showed that the agent learns to control the exoskeleton for individuals with different levels of spasticity. The proposed controller was able to reduce maximum torques applied to the human joint under spastic conditions by an average of 10.6\% and decreases the root mean square until the settling time by 8.9\% compared to a conventional compliant controller.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cerebrum (AIOS SDK): A Platform for Agent Development, Deployment, Distribution, and Discovery</title>
<link>https://arxiv.org/abs/2503.11444</link>
<guid>https://arxiv.org/abs/2503.11444</guid>
<content:encoded><![CDATA[
<div> 关键词：Cerebrum、Agent SDK、AIOS、开发、部署、分布、发现、智能体、Chain of Thought (CoT)、ReAct、工具使用、统一框架、标准化、灵活性、研究人员、开发者、社区驱动、Agent Hub、交互式web界面。

<br /><br />总结:
Cerebrum 是一款针对AIOS的智能体SDK，旨在填补自主LLM（大型语言模型）基代理在开发、部署、分布和发现方面的标准工具空白。它提供了三个关键组件：(1) 一个全面的SDK，采用模块化的四层架构设计，包括LLM、内存、存储和工具管理；(2) 一个社区驱动的Agent Hub，支持共享和发现智能体，并带有版本控制和依赖管理功能；(3) 一个用于测试和评估智能体的交互式Web界面。通过实现各种智能体架构（如Chain of Thought (CoT)、ReAct以及工具使用智能体），平台的有效性得到了验证。Cerebrum通过提供一个统一框架，推动了领域发展，实现了智能体开发的标准化，同时保持了研究人员和开发者进行创新和分发智能体所需的灵活性。项目现场网址为https://app.aios.foundation，代码库位于https://github.com/agiresearch/Cerebrum，相关视频演示可在https://app.aios.foundation/video-demo查看。 <div>
arXiv:2503.11444v1 Announce Type: new 
Abstract: Autonomous LLM-based agents have emerged as a powerful paradigm for complex task execution, yet the field lacks standardized tools for development, deployment, distribution and discovery of agents. We present Cerebrum, an Agent SDK for AIOS that addresses this gap through three key components: (1) a comprehensive SDK featuring a modular four-layer architecture for agent development, encompassing LLM, memory, storage, and tool management; (2) a community-driven Agent Hub for sharing and discovering agents, complete with version control and dependency management; (3) an interactive web interface for testing and evaluating agents. The platform's effectiveness is demonstrated through implementations of various agent architectures, including Chain of Thought (CoT), ReAct, and tool-use agents. Cerebrum advances the field by providing a unified framework that standardizes agent development while maintaining flexibility for researchers and developers to innovate and distribute their agents. The live website is at https://app.aios.foundation, the code is at https://github.com/agiresearch/Cerebrum, and video is at https://app.aios.foundation/video-demo.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Deep Learning Agents Trained For Avoidance Behave Like Hawks And Doves</title>
<link>https://arxiv.org/abs/2503.11452</link>
<guid>https://arxiv.org/abs/2503.11452</guid>
<content:encoded><![CDATA[
<div> 关键词：深度学习、游戏策略、网格世界、对抗行为、Hawks和Doves模型

总结:
本文介绍了利用深度学习方法优化的简单避让游戏的策略。研究在一个对称网格世界中，两个代理人需要通过交叉路径到达目标地点而不相互碰撞或偏离正确方向的游戏行为。代理人的政策由一个神经网络决定，并在这两个代理中共享。实验结果显示，完全训练后的网络展现出类似于Hawks和Doves博弈的行为模式，其中一个代理人采取了积极进取的策略以抵达目标，而另一个则学会了如何避免与进攻性代理人冲突。 <div>
arXiv:2503.11452v1 Announce Type: new 
Abstract: We present heuristically optimal strategies expressed by deep learning agents playing a simple avoidance game. We analyse the learning and behaviour of two agents within a symmetrical grid world that must cross paths to reach a target destination without crashing into each other or straying off of the grid world in the wrong direction. The agent policy is determined by one neural network that is employed in both agents. Our findings indicate that the fully trained network exhibits behaviour similar to that of the game Hawks and Doves, in that one agent employs an aggressive strategy to reach the target while the other learns how to avoid the aggressive agent.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Obstacle Avoidance with Bounded Rationality Adversarial Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.11467</link>
<guid>https://arxiv.org/abs/2503.11467</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning (强化学习), Quadruped locomotion (四足行走), Navigation policy (导航策略), Adversarial Reinforcement Learning (对抗性强化学习), Hi-QARL (层次化量子响应对抗强化学习)

<br /><br />总结:

本文提出了一种名为Hi-QARL的新方法，用于解决四足机器人在未知环境中具有动态障碍物的导航问题。该方法采用层次化的控制算法，包括低层的步态控制和高层的导航策略。为了使高层导航策略具备对动态障碍的鲁棒性，研究者应用了对抗性强化学习（Adversarial RL）的框架，将障碍物建模为对抗性代理。同时，通过引入量化反应均衡来限制对抗性代理的理性，并利用课程学习逐步调整其理性程度。实验表明，Hi-QARL方法在随机迷宫及多个障碍物的未见过场景中表现出良好的鲁棒性。此外，该方法还被应用于模拟环境中的Unitree GO1实物机器人，证明其实用性。 <div>
arXiv:2503.11467v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) has proven largely effective in obtaining stable locomotion gaits for legged robots. However, designing control algorithms which can robustly navigate unseen environments with obstacles remains an ongoing problem within quadruped locomotion. To tackle this, it is convenient to solve navigation tasks by means of a hierarchical approach with a low-level locomotion policy and a high-level navigation policy. Crucially, the high-level policy needs to be robust to dynamic obstacles along the path of the agent. In this work, we propose a novel way to endow navigation policies with robustness by a training process that models obstacles as adversarial agents, following the adversarial RL paradigm. Importantly, to improve the reliability of the training process, we bound the rationality of the adversarial agent resorting to quantal response equilibria, and place a curriculum over its rationality. We called this method Hierarchical policies via Quantal response Adversarial Reinforcement Learning (Hi-QARL). We demonstrate the robustness of our method by benchmarking it in unseen randomized mazes with multiple obstacles. To prove its applicability in real scenarios, our method is applied on a Unitree GO1 robot in simulation.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Research Vision: Multi-Agent Path Planning for Cops And Robbers Via Reactive Synthesis</title>
<link>https://arxiv.org/abs/2503.11475</link>
<guid>https://arxiv.org/abs/2503.11475</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent path planning, Cops and Robbers game, reactive synthesis, LTLt, Coordination Synthesis

总结:
本文提出了一个多智能体路径规划问题，用于经典游戏“警察与小偷”的一般化版本，通过反应性综合方法解决。研究内容包括使用LTLt（线性时间逻辑t）和协调综合技术检查是否存在一种策略使警察能够确保抓住小偷。此外，文章还提出将这种策略构造成可执行程序，供游戏中的多个系统玩家执行。文中形式化了该问题空间并指出了可能的解决方案方向。进一步地，作者展示了他们对这个泛化的警察与小偷游戏的正式化描述可以映射到反应式程序综合领域的广泛问题中。<br /><br /> <div>
arXiv:2503.11475v1 Announce Type: new 
Abstract: We propose the problem of multi-agent path planning for a generalization of the classic Cops and Robbers game via reactive synthesis. Specifically, through the application of LTLt and Coordination Synthesis, we aim to check whether various Cops and Robbers games are realizable (a strategy exists for the cops which guarantees they catch the robbers). Additionally, we construct this strategy as an executable program for the multiple system players in our games. In this paper we formalize the problem space, and propose potential directions for solutions. We also show how our formalization of this generalized cops and robbers game can be mapped to a broad range of other problems in the reactive program synthesis space.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unicorn: A Universal and Collaborative Reinforcement Learning Approach Towards Generalizable Network-Wide Traffic Signal Control</title>
<link>https://arxiv.org/abs/2503.11488</link>
<guid>https://arxiv.org/abs/2503.11488</guid>
<content:encoded><![CDATA[
<div> 关键词: 自适应交通信号控制, 多智能体强化学习, 网络化交通管理, 通用框架, 对比学习

总结:
本文提出了一种名为Unicorn的通用、协作型多智能体强化学习框架，用于解决实际中具有不同拓扑结构和交互动态的异质性交通网络中的自适应交通信号控制问题。该框架首先统一了各种交叉口状态和动作的映射结构，基于交通流动进行表示。接着，设计了一个通用交通表示（UTR）模块，利用解码器网络实现对多样化交通场景的一般特征提取。同时，通过变分推断技术提出了一个针对独特交叉口拓扑和交通动态的关键潜在向量识别的交叉口特性表示（ISR）模块。为了进一步细化这些潜在表示，Unicorn采用了自我监督方式下的对比学习方法，以更好地区分交叉口特有的特征。此外，文中还考虑了邻近智能体的状态-动作依赖关系，将其整合到策略优化中，从而有效地捕捉动态代理交互并促进高效的区域协作。实验结果显示，Unicorn在多个评估指标上优于其他方法，显示出其在复杂、动态交通网络中的应用潜力。 <div>
arXiv:2503.11488v1 Announce Type: new 
Abstract: Adaptive traffic signal control (ATSC) is crucial in reducing congestion, maximizing throughput, and improving mobility in rapidly growing urban areas. Recent advancements in parameter-sharing multi-agent reinforcement learning (MARL) have greatly enhanced the scalable and adaptive optimization of complex, dynamic flows in large-scale homogeneous networks. However, the inherent heterogeneity of real-world traffic networks, with their varied intersection topologies and interaction dynamics, poses substantial challenges to achieving scalable and effective ATSC across different traffic scenarios. To address these challenges, we present Unicorn, a universal and collaborative MARL framework designed for efficient and adaptable network-wide ATSC. Specifically, we first propose a unified approach to map the states and actions of intersections with varying topologies into a common structure based on traffic movements. Next, we design a Universal Traffic Representation (UTR) module with a decoder-only network for general feature extraction, enhancing the model's adaptability to diverse traffic scenarios. Additionally, we incorporate an Intersection Specifics Representation (ISR) module, designed to identify key latent vectors that represent the unique intersection's topology and traffic dynamics through variational inference techniques. To further refine these latent representations, we employ a contrastive learning approach in a self-supervised manner, which enables better differentiation of intersection-specific features. Moreover, we integrate the state-action dependencies of neighboring agents into policy optimization, which effectively captures dynamic agent interactions and facilitates efficient regional collaboration. Our results show that Unicorn outperforms other methods across various evaluation metrics, highlighting its potential in complex, dynamic traffic networks.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-agent coordination for on-demand data gathering with periodic information upload</title>
<link>https://arxiv.org/abs/2503.11504</link>
<guid>https://arxiv.org/abs/2503.11504</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体团队、信息采集、部署规划、协调方法、静态操作中心

<br />
总结：

本文提出了一种针对多智能体团队进行周期性信息采集与协调部署的方法。该方法旨在平衡数据刷新时间和信息包总数，以满足静态操作中心对变化目标位置的信息需求。首先，通过最佳区域划分算法为工作智能体分配任务区域；其次，找到工作智能体和收集智能体的最佳配比以及二者之间的通信方案；最后，计算出工作智能体访问目标点并将其信息传递给操作中心或移动中的收集智能体的最佳路线。这种方法已在多种场景的模拟测试中展现出优越性能，提供了最佳区域划分算法和工作与收集智能体之间最佳平衡的解决方案。 <div>
arXiv:2503.11504v1 Announce Type: new 
Abstract: In this paper we develop a method for planning and coordinating a multi-agent team deployment to periodically gather information on demand. A static operation center (OC) periodically requests information from changing goal locations. The objective is to gather data in the goals and to deliver it to the OC, balancing the refreshing time and the total number of information packages. The system automatically splits the team in two roles: workers to gather data, or collectors to retransmit the data to the OC. The proposed three step method: 1) finds out the best area partition for the workers; 2) obtains the best balance between workers and collectors, and with whom the workers must to communicate, a collector or the OC; 3) computes the best tour for the workers to visit the goals and deliver them to the OC or to a collector in movement. The method is tested in simulations in different scenarios, providing the best area partition algorithm and the best balance between collectors and workers.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prompt Injection Detection and Mitigation via AI Multi-Agent NLP Frameworks</title>
<link>https://arxiv.org/abs/2503.11517</link>
<guid>https://arxiv.org/abs/2503.11517</guid>
<content:encoded><![CDATA[
<div> 关键词：prompt injection、多智能体NLP框架、生成响应、政策合规、Total Injection Vulnerability Score (TIVS)

<br /><br />总结:
本文介绍了一种针对生成式AI系统中的prompt注入挑战的多智能体NLP框架。该框架通过层叠检测和执行机制设计，专门用于解决prompt注入漏洞问题。框架中协同工作的专业化代理分别负责生成响应、净化输出以及确保政策合规性。在对500个工程化注入提示进行评估后，显示出了显著降低的注入成功率和政策违规频率。文章还提出了新的度量指标，包括Injection Success Rate (ISR)、Policy Override Frequency (POF)、Prompt Sanitization Rate (PSR)和Compliance Consistency Score (CCS)，并综合这些指标形成了Total Injection Vulnerability Score (TIVS)。该系统利用OVON（开放语音网络）框架，通过结构化的JSON消息实现各代理间的通信，将原有的多智能体架构从抑制错觉扩展到解决prompt注入的独特挑战。 <div>
arXiv:2503.11517v1 Announce Type: new 
Abstract: Prompt injection constitutes a significant challenge for generative AI systems by inducing unintended outputs. We introduce a multi-agent NLP framework specifically designed to address prompt injection vulnerabilities through layered detection and enforcement mechanisms. The framework orchestrates specialized agents for generating responses, sanitizing outputs, and enforcing policy compliance. Evaluation on 500 engineered injection prompts demonstrates a marked reduction in injection success and policy breaches. Novel metrics, including Injection Success Rate (ISR), Policy Override Frequency (POF), Prompt Sanitization Rate (PSR), and Compliance Consistency Score (CCS), are proposed to derive a composite Total Injection Vulnerability Score (TIVS). The system utilizes the OVON (Open Voice Network) framework for inter-agent communication via structured JSON messages, extending a previously established multi-agent architecture from hallucination mitigation to address the unique challenges of prompt injection.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-robot coordination for connectivity recovery after unpredictable environment changes</title>
<link>https://arxiv.org/abs/2503.11520</link>
<guid>https://arxiv.org/abs/2503.11520</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人团队、连接重连、分布式方法、环境变化、通信范围

总结：<br />
本文提出了一种针对多机器人团队在环境变化导致的连通性失效后的分布式重连方法。当出现新障碍物使得团队分裂成多个小组后，每个小组具有有限的通信范围和局部视野内的场景信息。目标是使团队重新形成从静态基站到目标位置的链状结构。提出的分布式再规划方法允许每台机器人根据其观测到的新信息预测其他小组的新路径以恢复与基站的连通性并实现初始的联合目标。若存在解决方案，则该方法能使所有小组成功重组为单一链状队形。文中通过数值模拟对比了本方法与其他两种情况（1）所有代理具备完整环境信息的情况，以及（2）需要部分机器人移动至等待重连的机器人处的情况，以评估该方法在应对不可预见的场景变化时的表现。 <div>
arXiv:2503.11520v1 Announce Type: new 
Abstract: In the present paper we develop a distributed method to reconnect a multi-robot team after connectivity failures, caused by unpredictable environment changes, i.e. appearance of new obstacles. After the changes, the team is divided into different groups of robots. The groups have a limited communication range and only a partial information in their field of view about the current scenario. Their objective is to form a chain from a static base station to a goal location. In the proposed distributed replanning approach, the robots predict new plans for the other groups from the new observed information by each robot in the changed scenario, to restore the connectivity with a base station and reach the initial joint objective. If a solution exists, the method achieves the reconnection of all the groups in a unique chain. The proposed method is compared with other two cases: 1) when all the agents have full information of the environment, and 2) when some robots must move to reach other waiting robots for reconnection. Numerical simulations are provided to evaluate the proposed approach in the presence of unpredictable scenario changes.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to reset in target search problems</title>
<link>https://arxiv.org/abs/2503.11330</link>
<guid>https://arxiv.org/abs/2503.11330</guid>
<content:encoded><![CDATA[
<div> 关键词：目标搜索问题、重置策略、强化学习、Brownian搜索、适应性策略

<br /><br />总结:
本文提出了一个基于强化学习的框架，用于训练智能体在环境中通过学习如何重置来优化搜索效率。首先，该方法在已建立的Brownian搜索与重置基准上得到验证，其中RL智能体能够发现接近最优解的重置策略。接着，研究进一步扩展了框架，允许智能体不仅控制何时重置，还能通过转向动作控制其空间动态。在这一更复杂的设置中，智能体发现了能根据环境特性自适应调整重置和转向的策略，从而超越了提出的基准。这些结果表明，强化学习既可作为优化工具，也可用来发掘随机搜索过程中具有重置功能的新颖、可解释的策略。 <div>
arXiv:2503.11330v1 Announce Type: cross 
Abstract: Target search problems are central to a wide range of fields, from biological foraging to the optimization algorithms. Recently, the ability to reset the search has been shown to significantly improve the searcher's efficiency. However, the optimal resetting strategy depends on the specific properties of the search problem and can often be challenging to determine. In this work, we propose a reinforcement learning (RL)-based framework to train agents capable of optimizing their search efficiency in environments by learning how to reset. First, we validate the approach in a well-established benchmark: the Brownian search with resetting. There, RL agents consistently recover strategies closely resembling the sharp resetting distribution, known to be optimal in this scenario. We then extend the framework by allowing agents to control not only when to reset, but also their spatial dynamics through turning actions. In this more complex setting, the agents discover strategies that adapt both resetting and turning to the properties of the environment, outperforming the proposed benchmarks. These results demonstrate how reinforcement learning can serve both as an optimization tool and a mechanism for uncovering new, interpretable strategies in stochastic search processes with resetting.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Logit-Q Dynamics for Efficient Learning in Stochastic Teams</title>
<link>https://arxiv.org/abs/2302.09806</link>
<guid>https://arxiv.org/abs/2302.09806</guid>
<content:encoded><![CDATA[
<div> 关键词：logit-Q动态、随机游戏、学习效率、阶段游戏框架、Q函数

总结:
本文介绍了一种新的logit-Q动力学方法，用于提高在具有未知动态的随机游戏中的学习效率。这种方法结合了正常形式游戏重复玩的log线性学习（又称logit动态）与Q学习在未知马尔科夫决策过程中的应用，将随机游戏视为各代理根据当前状态反复玩某个关联的阶段游戏，其中代理的Q函数决定了这些阶段游戏的收益。文章证明了logit-Q动力学会达到(近似)有效的团队均衡，并量化了估计误差。同时，文中还展示了logit-Q动力学相对于遵循纯静态策略的代理而言的合理性以及在那些由阶段收益诱导出潜力游戏但只有单一代理控制超越随机团队的状态转移的随机游戏中，该动力学的收敛性。关键思想是通过设想一个虚构场景，其中Q函数估计在随时间增长的epoch内保持恒定，然后通过耦合主场景和虚构场景的动力学来证明这两个场景在各个epoch中会变得越来越相似，这是由于步长趋于零和epoch长度的增长。 <div>
arXiv:2302.09806v4 Announce Type: replace 
Abstract: We present a new family of logit-Q dynamics for efficient learning in stochastic games by combining the log-linear learning (also known as logit dynamics) for the repeated play of normal-form games with Q-learning for unknown Markov decision processes within the auxiliary stage-game framework. In this framework, we view stochastic games as agents repeatedly playing some stage game associated with the current state of the underlying game while the agents' Q-functions determine the payoffs of these stage games. We show that the logit-Q dynamics presented reach (near) efficient equilibrium in stochastic teams with unknown dynamics and quantify the approximation error. We also show the rationality of the logit-Q dynamics against agents following pure stationary strategies and the convergence of the dynamics in stochastic games where the stage-payoffs induce potential games, yet only a single agent controls the state transitions beyond stochastic teams. The key idea is to approximate the dynamics with a fictional scenario where the Q-function estimates are stationary over epochs whose lengths grow at a sufficiently slow rate. We then couple the dynamics in the main and fictional scenarios to show that these two scenarios become more and more similar across epochs due to the vanishing step size and growing epoch lengths.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Virtual Guidance as a Mid-level Representation for Navigation with Augmented Reality</title>
<link>https://arxiv.org/abs/2303.02731</link>
<guid>https://arxiv.org/abs/2303.02731</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主导航、虚拟引导、多模态、模拟到现实、性能比较

总结:
本文提出了一种针对自主导航的新型技术——虚拟引导，旨在将非视觉的指令信号转化为可视化的导航提示，这些提示会叠加在代理的摄像头视图上。为验证虚拟引导的有效性，文章设计了一个从模拟环境到真实世界的转移框架，确保了虚拟引导在实际场景中的适应性。通过与非视觉引导基线方法进行详尽的实验对比，实验结果表明，提出的虚拟引导方法在多种场景下均超越了基线方法，有力证明了其在自主导航任务中的优越效果。 <div>
arXiv:2303.02731v3 Announce Type: replace 
Abstract: In the context of autonomous navigation, effectively conveying abstract navigational cues to agents in dynamic environments presents significant challenges, particularly when navigation information is derived from diverse modalities such as both vision and high-level language descriptions. To address this issue, we introduce a novel technique termed `Virtual Guidance,' which is designed to visually represent non-visual instructional signals. These visual cues are overlaid onto the agent's camera view and served as comprehensible navigational guidance signals. To validate the concept of virtual guidance, we propose a sim-to-real framework that enables the transfer of the trained policy from simulated environments to real world, ensuring the adaptability of virtual guidance in practical scenarios. We evaluate and compare the proposed method against a non-visual guidance baseline through detailed experiments in simulation. The experimental results demonstrate that the proposed virtual guidance approach outperforms the baseline methods across multiple scenarios and offers clear evidence of its effectiveness in autonomous navigation tasks.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LEACH-RLC: Enhancing IoT Data Transmission with Optimized Clustering and Reinforcement Learning</title>
<link>https://arxiv.org/abs/2401.15767</link>
<guid>https://arxiv.org/abs/2401.15767</guid>
<content:encoded><![CDATA[
<div> 关键词: 无线传感器网络, 物联网, 能耗, 强化学习, 簇头选择

总结:<br />
本文提出了一种名为LEACH-RLC的新型聚类协议，旨在解决物联网设备中无线传感器网络在远程和资源受限环境下所面临的能耗、网络寿命及控制开销等问题。LEACH-RLC采用混合整数线性规划（MILP）方法实现策略性的簇头选择和节点到簇的分配，并结合强化学习（RL）代理以学习最佳时间生成新簇，从而减少控制开销而不影响整体网络性能。通过大量模拟实验，结果显示LEACH-RLC相比现有协议具有更长的网络生命周期、更低的平均能量消耗以及更小的控制开销。该协议对提高WSNs的效率和适应性以及解决物联网部署中的关键挑战做出了贡献。 <div>
arXiv:2401.15767v2 Announce Type: replace 
Abstract: Wireless Sensor Networks (WSNs) play a pivotal role in enabling Internet of Things (IoT) devices with sensing and actuation capabilities. Operating in remote and resource-constrained environments, these IoT devices face challenges related to energy consumption, crucial for network longevity. Existing clustering protocols often suffer from high control overhead, inefficient cluster formation, and poor adaptability to dynamic network conditions, leading to suboptimal data transmission and reduced network lifetime. This paper introduces Low-Energy Adaptive Clustering Hierarchy with Reinforcement Learning-based Controller (LEACH-RLC), a novel clustering protocol designed to address these limitations by employing a Mixed Integer Linear Programming (MILP) approach for strategic selection of Cluster Heads (CHs) and node-to-cluster assignments. Additionally, it integrates a Reinforcement Learning (RL) agent to minimize control overhead by learning optimal timings for generating new clusters. LEACH-RLC aims to balance control overhead reduction without compromising overall network performance. Through extensive simulations, this paper investigates the frequency and opportune moments for generating new clustering solutions. Results demonstrate the superior performance of LEACH-RLC over state-of-the-art protocols, showcasing enhanced network lifetime, reduced average energy consumption, and minimized control overhead. The proposed protocol contributes to advancing the efficiency and adaptability of WSNs, addressing critical challenges in IoT deployments.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Instance Temperature Knowledge Distillation</title>
<link>https://arxiv.org/abs/2407.00115</link>
<guid>https://arxiv.org/abs/2407.00115</guid>
<content:encoded><![CDATA[
<div> 关键词: Knowledge Distillation (知识蒸馏), Temperature Adjustment, Reinforcement Learning (强化学习), Instance Reward Calibration, Efficient Exploration Strategy

<br /><br />总结:
本文提出了一种基于强化学习的知识蒸馏方法RLKD，旨在解决现有知识蒸馏过程中动态调整温度策略仅考虑当前阶段收益、未充分考虑未来回报的问题。通过将温度调整视为序列决策任务，RLKD设计了新颖的状态表示以使智能体做出更明智的动作决策——实例温度调整。针对由于知识蒸馏设置带来的延迟奖励问题，文中探索了实例奖励校准方法。此外，还制定了一种有效的探索策略，使智能体能更高效地学习到有价值的实例温度调整策略。该框架易于插入到各种知识蒸馏方法中作为插件使用，并已在图像分类和目标检测任务上验证了其有效性。项目网站为https://www.zayx.me/ITKD.github.io/。 <div>
arXiv:2407.00115v4 Announce Type: replace 
Abstract: Knowledge distillation (KD) enhances the performance of a student network by allowing it to learn the knowledge transferred from a teacher network incrementally. Existing methods dynamically adjust the temperature to enable the student network to adapt to the varying learning difficulties at different learning stages of KD. KD is a continuous process, but when adjusting the temperature, these methods consider only the immediate benefits of the operation in the current learning phase and fail to take into account its future returns. To address this issue, we formulate the adjustment of temperature as a sequential decision-making task and propose a method based on reinforcement learning, termed RLKD. Importantly, we design a novel state representation to enable the agent to make more informed action (i.e. instance temperature adjustment). To handle the problem of delayed rewards in our method due to the KD setting, we explore an instance reward calibration approach. In addition,we devise an efficient exploration strategy that enables the agent to learn valuable instance temperature adjustment policy more efficiently. Our framework can serve as a plug-and-play technique to be inserted into various KD methods easily, and we validate its effectiveness on both image classification and object detection tasks. Our project is at https://www.zayx.me/ITKD.github.io/.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Residual-MPPI: Online Policy Customization for Continuous Control</title>
<link>https://arxiv.org/abs/2407.00898</link>
<guid>https://arxiv.org/abs/2407.00898</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning (强化学习), Imitation Learning (模仿学习), 在线规划算法, Residual-MPPI, Gran Turismo Sophy (GT Sophy)

总结:
本文提出了一种名为Residual-MPPI的通用在线规划算法，该算法旨在针对执行阶段的连续控制任务定制已训练策略，无需了解原训练方案或任务。此方法仅需访问前期动作分布，即可在网络设置中实现对给定优先策略的新性能指标进行少量样本甚至零样本在线定制。实验显示，Residual-MPPI在包括定制冠军级赛车代理Gran Turismo Sophy 1.0在内的复杂赛车场景——Gran Turismo Sport (GTS)环境中，能够有效地完成在线策略定制任务。文章随附了适用于MuJoCo实验的代码，并承诺在接受后开源。相关的演示视频和代码可在项目网站上获取。 <div>
arXiv:2407.00898v5 Announce Type: replace 
Abstract: Policies developed through Reinforcement Learning (RL) and Imitation Learning (IL) have shown great potential in continuous control tasks, but real-world applications often require adapting trained policies to unforeseen requirements. While fine-tuning can address such needs, it typically requires additional data and access to the original training metrics and parameters. In contrast, an online planning algorithm, if capable of meeting the additional requirements, can eliminate the necessity for extensive training phases and customize the policy without knowledge of the original training scheme or task. In this work, we propose a generic online planning algorithm for customizing continuous-control policies at the execution time, which we call Residual-MPPI. It can customize a given prior policy on new performance metrics in few-shot and even zero-shot online settings, given access to the prior action distribution alone. Through our experiments, we demonstrate that the proposed Residual-MPPI algorithm can accomplish the few-shot/zero-shot online policy customization task effectively, including customizing the champion-level racing agent, Gran Turismo Sophy (GT Sophy) 1.0, in the challenging car racing scenario, Gran Turismo Sport (GTS) environment. Code for MuJoCo experiments is included in the supplementary and will be open-sourced upon acceptance. Demo videos and code are available on our website: https://sites.google.com/view/residual-mppi.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PrivacyLens: Evaluating Privacy Norm Awareness of Language Models in Action</title>
<link>https://arxiv.org/abs/2409.00138</link>
<guid>https://arxiv.org/abs/2409.00138</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、隐私规范、隐私风险、PrivacyLens、GPT-4

总结:
本文提出了一种名为PrivacyLens的新框架，用于解决在语言模型（如GPT-4和Llama-3-70B）应用于个性化通信场景时的隐私规范意识量化和隐私风险评估难题。该框架能将隐私敏感种子扩展为表达式情景和代理行为轨迹，从而实现对LM代理行为中隐私泄露的多级评估。研究者们利用隐私文献和众包种子实例化了PrivacyLens，并发现即使在接收到隐私增强指令的情况下，最先进的语言模型仍有25.68%和38.69%的概率泄露敏感信息。此外，通过将每个种子扩展成多个行为轨迹，PrivacyLens展现了其动态评估LM隐私泄露风险的能力。相关数据集和代码已公开发布在https://github.com/SALT-NLP/PrivacyLens上。 <div>
arXiv:2409.00138v3 Announce Type: replace 
Abstract: As language models (LMs) are widely utilized in personalized communication scenarios (e.g., sending emails, writing social media posts) and endowed with a certain level of agency, ensuring they act in accordance with the contextual privacy norms becomes increasingly critical. However, quantifying the privacy norm awareness of LMs and the emerging privacy risk in LM-mediated communication is challenging due to (1) the contextual and long-tailed nature of privacy-sensitive cases, and (2) the lack of evaluation approaches that capture realistic application scenarios. To address these challenges, we propose PrivacyLens, a novel framework designed to extend privacy-sensitive seeds into expressive vignettes and further into agent trajectories, enabling multi-level evaluation of privacy leakage in LM agents' actions. We instantiate PrivacyLens with a collection of privacy norms grounded in privacy literature and crowdsourced seeds. Using this dataset, we reveal a discrepancy between LM performance in answering probing questions and their actual behavior when executing user instructions in an agent setup. State-of-the-art LMs, like GPT-4 and Llama-3-70B, leak sensitive information in 25.68% and 38.69% of cases, even when prompted with privacy-enhancing instructions. We also demonstrate the dynamic nature of PrivacyLens by extending each seed into multiple trajectories to red-team LM privacy leakage risk. Dataset and code are available at https://github.com/SALT-NLP/PrivacyLens.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agents' Room: Narrative Generation through Multi-step Collaboration</title>
<link>https://arxiv.org/abs/2410.02603</link>
<guid>https://arxiv.org/abs/2410.02603</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2410.02603v2, 生成框架, 专用智能体, 故事写作, 大规模语言模型

<br /><br />总结:
本文提出了一个名为“Agents' Room”的故事生成框架，该框架受到叙事理论启发，将小说创作过程分解为由专门智能体处理的子任务。为了说明这种方法，作者们引入了一个名为“Tell Me A Story”的高质量数据集，其中包含了复杂的写作提示和人类编写的故事情节，以及针对长篇叙事评估的创新性评价框架。实验表明，利用协作与专业化分解复杂的故事写作任务，Agents' Room生成的故事相较于基线系统更受专家评审员的喜爱。此外，文章还对生成的输出进行了自动化和基于人类评估的大量分析。 <div>
arXiv:2410.02603v2 Announce Type: replace 
Abstract: Writing compelling fiction is a multifaceted process combining elements such as crafting a plot, developing interesting characters, and using evocative language. While large language models (LLMs) show promise for story writing, they currently rely heavily on intricate prompting, which limits their use. We propose Agents' Room, a generation framework inspired by narrative theory, that decomposes narrative writing into subtasks tackled by specialized agents. To illustrate our method, we introduce Tell Me A Story, a high-quality dataset of complex writing prompts and human-written stories, and a novel evaluation framework designed specifically for assessing long narratives. We show that Agents' Room generates stories that are preferred by expert evaluators over those produced by baseline systems by leveraging collaboration and specialization to decompose the complex story writing task into tractable components. We provide extensive analysis with automated and human-based metrics of the generated output.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SERN: Simulation-Enhanced Realistic Navigation for Multi-Agent Robotic Systems in Contested Environments</title>
<link>https://arxiv.org/abs/2410.16686</link>
<guid>https://arxiv.org/abs/2410.16686</guid>
<content:encoded><![CDATA[
<div> 关键词: SERN、多机器人系统、虚拟与物理环境集成、实时协同决策、Multi-Metric Cost Function (MMCF)

<br /><br />总结:

本文提出了一种名为SERN（Simulation-Enhanced Realistic Navigation）的新框架，用于在复杂环境中实现多机器人系统的实时协同决策和高效导航。SERN通过其双向SERN ROS Bridge通信框架解决了资产部署和协调的关键挑战。该框架采用Unity高保真模拟器实现了虚拟环境中对现实世界的准确表示，同步了实体与虚拟机器人的运动，并优化了ROS数据在远程位置之间的分布。此外，文中还引入了Multi-Metric Cost Function (MMCF)，动态平衡延迟、可靠性、计算开销和带宽消耗以优化系统性能。理论分析证明了在网络条件变化下，物理与虚拟机器人之间的位置误差保持在可控范围内。实验结果显示，相比传统ROS设置，SERN在延迟方面提高了15%至24%，处理效率提升了最多15%。实验证明，SERN在实际世界和虚拟仿真中的同步精度很高，达到了厘米级的位置误差和小于2度的旋转误差，显示出了在多样化、竞争性环境中增强态势感知和多智能体协调的潜力。 <div>
arXiv:2410.16686v2 Announce Type: replace 
Abstract: The increasing deployment of autonomous systems in complex environments necessitates efficient communication and task completion among multiple agents. This paper presents SERN (Simulation-Enhanced Realistic Navigation), a novel framework integrating virtual and physical environments for real-time collaborative decision-making in multi-robot systems. SERN addresses key challenges in asset deployment and coordination through our bi-directional SERN ROS Bridge communication framework. Our approach advances the SOTA through: accurate real-world representation in virtual environments using Unity high-fidelity simulator; synchronization of physical and virtual robot movements; efficient ROS data distribution between remote locations; and integration of SOTA semantic segmentation for enhanced environmental perception. Additionally, we introduce a Multi-Metric Cost Function (MMCF) that dynamically balances latency, reliability, computational overhead, and bandwidth consumption to optimize system performance in contested environments. We further provide theoretical justification for synchronization accuracy by proving that the positional error between physical and virtual robots remains bounded under varying network conditions. Our evaluations show a 15% to 24% improvement in latency and up to a 15% increase in processing efficiency compared to traditional ROS setups. Real-world and virtual simulation experiments with multiple robots (Clearpath Jackal and Husky) demonstrate synchronization accuracy, achieving less than $5\text{ cm}$ positional error and under $2^\circ$ rotational error. These results highlight SERN's potential to enhance situational awareness and multi-agent coordination in diverse, contested environments.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>V2XPnP: Vehicle-to-Everything Spatio-Temporal Fusion for Multi-Agent Perception and Prediction</title>
<link>https://arxiv.org/abs/2412.01812</link>
<guid>https://arxiv.org/abs/2412.01812</guid>
<content:encoded><![CDATA[
<div> 关键词：Vehicle-to-everything (V2X), spatio-temporal fusion, communication strategies, fusion strategies, V2XPnP<br /><br />总结:<br />
本文关注车辆与万物（V2X）技术中时空融合问题，设计了一步和多步通信策略以及与早期、晚期和中间三种融合策略的结合应用，提供了11种融合模型的全面基准。研究提出了一种名为V2XPnP的一步通信时空融合框架，该框架采用统一的Transformer架构有效建模多个代理、帧和高精度地图之间的复杂时空关系，实现端到端的感知和预测任务。此外，文章还引入了支持所有V2X协作模式的V2XPnP序列数据集，弥补了现有真实世界数据集中单帧或单模式合作的局限性。实验结果显示，所提框架在感知和预测任务上均超越了现有的最优方法。未来，研究团队将发布代码库和数据集以促进V2X领域的进一步研究。 <div>
arXiv:2412.01812v2 Announce Type: replace 
Abstract: Vehicle-to-everything (V2X) technologies offer a promising paradigm to mitigate the limitations of constrained observability in single-vehicle systems. Prior work primarily focuses on single-frame cooperative perception, which fuses agents' information across different spatial locations but ignores temporal cues and temporal tasks (e.g., temporal perception and prediction). In this paper, we focus on the spatio-temporal fusion in V2X scenarios and design one-step and multi-step communication strategies (when to transmit) as well as examine their integration with three fusion strategies - early, late, and intermediate (what to transmit), providing comprehensive benchmarks with 11 fusion models (how to fuse). Furthermore, we propose V2XPnP, a novel intermediate fusion framework within one-step communication for end-to-end perception and prediction. Our framework employs a unified Transformer-based architecture to effectively model complex spatio-temporal relationships across multiple agents, frames, and high-definition map. Moreover, we introduce the V2XPnP Sequential Dataset that supports all V2X collaboration modes and addresses the limitations of existing real-world datasets, which are restricted to single-frame or single-mode cooperation. Extensive experiments demonstrate our framework outperforms state-of-the-art methods in both perception and prediction tasks. The codebase and dataset will be released to facilitate future V2X research.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Closed-Loop Supervised Fine-Tuning of Tokenized Traffic Models</title>
<link>https://arxiv.org/abs/2412.05334</link>
<guid>https://arxiv.org/abs/2412.05334</guid>
<content:encoded><![CDATA[
<div> 关键词：交通模拟、闭合循环、令牌化多智能体策略、CAT-K rollout、行为克隆

总结:
本文关注于交通模拟领域，提出了一种名为Closest Among Top-K (CAT-K) rollouts的闭合循环微调策略，旨在解决由开放循环行为克隆训练方法导致的协变量偏移问题。CAT-K 微调利用现有轨迹数据，无需强化学习或生成对抗性模仿学习。通过应用CAT-K微调，一个仅含700万参数的令牌化交通模拟策略能够超越同一家族中的1亿零2百万参数模型，在提交时登上Waymo Sim Agent Challenge的排行榜首位。相关代码已在https://github.com/NVlabs/catk上发布。 <div>
arXiv:2412.05334v2 Announce Type: replace 
Abstract: Traffic simulation aims to learn a policy for traffic agents that, when unrolled in closed-loop, faithfully recovers the joint distribution of trajectories observed in the real world. Inspired by large language models, tokenized multi-agent policies have recently become the state-of-the-art in traffic simulation. However, they are typically trained through open-loop behavior cloning, and thus suffer from covariate shift when executed in closed-loop during simulation. In this work, we present Closest Among Top-K (CAT-K) rollouts, a simple yet effective closed-loop fine-tuning strategy to mitigate covariate shift. CAT-K fine-tuning only requires existing trajectory data, without reinforcement learning or generative adversarial imitation. Concretely, CAT-K fine-tuning enables a small 7M-parameter tokenized traffic simulation policy to outperform a 102M-parameter model from the same model family, achieving the top spot on the Waymo Sim Agent Challenge leaderboard at the time of submission. The code is available at https://github.com/NVlabs/catk.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Benchmark Evaluations, Applications, and Challenges of Large Vision Language Models: A Survey</title>
<link>https://arxiv.org/abs/2501.02189</link>
<guid>https://arxiv.org/abs/2501.02189</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态视觉语言模型、CLIP、训练方法、基准评价指标、应用挑战

<br />
总结:
本文对近年来（2019-2024）多模态视觉语言模型（VLMs）进行了系统性综述，涵盖了主要的VLM模型信息，如CLIP等；归纳了这些模型的主要架构和训练方式；总结并分类了VLMs的流行基准测试与评价指标；探讨了VLMs在包括化身代理、机器人及视频生成等方面的应用；同时指出了当前VLMs面临的挑战与问题，如幻觉现象、公平性和安全性。为方便读者进一步研究，文中还提供了详细的文献和模型资源链接集合，地址为https://github.com/zli12321/Awesome-VLM-Papers-And-Models.git。 <div>
arXiv:2501.02189v4 Announce Type: replace 
Abstract: Multimodal Vision Language Models (VLMs) have emerged as a transformative technology at the intersection of computer vision and natural language processing, enabling machines to perceive and reason about the world through both visual and textual modalities. For example, models such as CLIP, Claude, and GPT-4V demonstrate strong reasoning and understanding abilities on visual and textual data and beat classical single modality vision models on zero-shot classification. Despite their rapid advancements in research and growing popularity in applications, a comprehensive survey of existing studies on VLMs is notably lacking, particularly for researchers aiming to leverage VLMs in their specific domains. To this end, we provide a systematic overview of VLMs in the following aspects: model information of the major VLMs developed over the past five years (2019-2024); the main architectures and training methods of these VLMs; summary and categorization of the popular benchmarks and evaluation metrics of VLMs; the applications of VLMs including embodied agents, robotics, and video generation; the challenges and issues faced by current VLMs such as hallucination, fairness, and safety. Detailed collections including papers and model repository links are listed in https://github.com/zli12321/Awesome-VLM-Papers-And-Models.git.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EPO: Explicit Policy Optimization for Strategic Reasoning in LLMs via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.12486</link>
<guid>https://arxiv.org/abs/2502.12486</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 战略性推理, 明确策略优化 (EPO), 强化学习 (RL), 自我对弈

总结:
本文提出了明确策略优化（EPO）方法来提升大型语言模型（LLMs）在复杂现实场景中的战略性推理能力，特别是针对如商业谈判等需要动态环境导航和长期目标对齐的任务。EPO 具备开放性行动空间中的策略生成能力，并能接入任意 LLM 代理以驱动目标导向的行为。为改善适应性和策略转移性，文章通过多轮强化学习以及迭代自我对弈训练战略推理模型，而不依赖监督微调（SFT）。实验结果显示，EPO 在社交对话和网页导航任务上展现出长期目标对齐的增强战略性推理能力，达到最先进的性能水平。此外，研究还揭示了 EPO 中涌现出的各种协作推理机制及其在生成创新策略方面的有效性，强调了其在实际应用中进行战略性推理的潜力。 <div>
arXiv:2502.12486v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have shown impressive reasoning capabilities in well-defined problems with clear solutions, such as mathematics and coding. However, they still struggle with complex real-world scenarios like business negotiations, which require strategic reasoning-an ability to navigate dynamic environments and align long-term goals amidst uncertainty. Existing methods for strategic reasoning face challenges in adaptability, scalability, and transferring strategies to new contexts. To address these issues, we propose explicit policy optimization (EPO) for strategic reasoning, featuring an LLM that provides strategies in open-ended action space and can be plugged into arbitrary LLM agents to motivate goal-directed behavior. To improve adaptability and policy transferability, we train the strategic reasoning model via multi-turn reinforcement learning (RL) using process rewards and iterative self-play, without supervised fine-tuning (SFT) as a preliminary step. Experiments across social and physical domains demonstrate EPO's ability of long-term goal alignment through enhanced strategic reasoning, achieving state-of-the-art performance on social dialogue and web navigation tasks. Our findings reveal various collaborative reasoning mechanisms emergent in EPO and its effectiveness in generating novel strategies, underscoring its potential for strategic reasoning in real-world applications.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stable matching as transport</title>
<link>https://arxiv.org/abs/2402.13378</link>
<guid>https://arxiv.org/abs/2402.13378</guid>
<content:encoded><![CDATA[
<div> 关键词: 匹配市场、对齐偏好、最优运输理论、稳定性、公平性

总结:
本文将匹配市场与对齐偏好的最优运输理论联系起来。通过展示稳定性、效率和公平性是该参数化最优运输问题的解，其中参数反映了社会对不平等的偏好。这一联系揭示了匹配结构的性质以及各目标之间的权衡关系，说明稳定性可能导致福利不均等，即使是在相似的代理人之间。本模型适用于存在供需不平衡的场景，如空间市场、学校选择和拼车服务。此外，论文还表明具有个性化偏好的大规模市场可以通过对齐偏好进行良好近似，从而扩展了研究结果的应用范围。 <div>
arXiv:2402.13378v2 Announce Type: replace-cross 
Abstract: This paper links matching markets with aligned preferences to optimal transport theory. We show that stability, efficiency, and fairness emerge as solutions to a parametric family of optimal transport problems. The parameter reflects society's preferences for inequality. This link offers insights into structural properties of matchings and trade-offs between objectives; showing how stability can lead to welfare inequalities, even among similar agents. Our model captures supply-demand imbalances in contexts like spatial markets, school choice, and ride-sharing. We also show that large markets with idiosyncratic preferences can be well approximated by aligned preferences, expanding the applicability of our results.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wearable intelligent throat enables natural speech in stroke patients with dysarthria</title>
<link>https://arxiv.org/abs/2411.18266</link>
<guid>https://arxiv.org/abs/2411.18266</guid>
<content:encoded><![CDATA[
<div> 关键词: 可穿戴无声语音系统、智能喉部系统、AI驱动、语言模型处理、沟通障碍

<br /><br />总结:
本文介绍了一种AI驱动的智能喉部系统（IT），该系统将喉部肌肉振动和颈动脉脉冲信号传感器与大型语言模型（LLM）相结合，以实现流畅且富有情感表达力的无声语音通信。通过使用超灵敏纺织应变传感器从颈部区域捕捉高质量信号，系统支持实时、连续的语句解码，确保无缝、无延迟的交流。在针对五名有失语症中风患者的测试中，IT系统的LLM代理能够智能地纠正令牌错误并增强句子层面的情感和逻辑连贯性，取得了低错误率（单词错误率4.2%，句子错误率2.9%）以及用户满意度提升了55%的成绩。这一工作确立了一个适用于有沟通障碍患者（如失语症患者）的便携式、直观的交流平台，并有望广泛应用到不同神经性疾病领域及多语言支持系统之中。 <div>
arXiv:2411.18266v3 Announce Type: replace-cross 
Abstract: Wearable silent speech systems hold significant potential for restoring communication in patients with speech impairments. However, seamless, coherent speech remains elusive, and clinical efficacy is still unproven. Here, we present an AI-driven intelligent throat (IT) system that integrates throat muscle vibrations and carotid pulse signal sensors with large language model (LLM) processing to enable fluent, emotionally expressive communication. The system utilizes ultrasensitive textile strain sensors to capture high-quality signals from the neck area and supports token-level processing for real-time, continuous speech decoding, enabling seamless, delay-free communication. In tests with five stroke patients with dysarthria, IT's LLM agents intelligently corrected token errors and enriched sentence-level emotional and logical coherence, achieving low error rates (4.2% word error rate, 2.9% sentence error rate) and a 55% increase in user satisfaction. This work establishes a portable, intuitive communication platform for patients with dysarthria with the potential to be applied broadly across different neurological conditions and in multi-language support systems.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Factorio Learning Environment</title>
<link>https://arxiv.org/abs/2503.09617</link>
<guid>https://arxiv.org/abs/2503.09617</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Factorio Learning Environment (FLE), long-term planning, program synthesis, resource optimization

总结:
文章介绍了随着大型语言模型（LLMs）在现有基准测试中的性能快速饱和，研究人员提出了一种新的开放性评估环境——基于游戏Factorio的Factorio学习环境（FLE）。FLE旨在测试代理在长期规划、程序合成和资源优化方面的能力，并提供了指数级增长的挑战。该环境提供两种设置：(1) 实验室玩法，包括八个结构化的固定资源任务；(2) 开放式玩法，要求在生成的随机地图上构建最大的工厂。研究发现，尽管LLMs在实验室玩法中展示出了有前景的短期技能，但在受限环境中有效运行方面存在局限性，反映了其在错误分析方面的不足。在开放式玩法中，虽然LLMs能够发现改善工厂成长的自动化策略（如电动钻探），但未能实现复杂的自动化（如电子电路制造）。 <div>
arXiv:2503.09617v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are rapidly saturating existing benchmarks, necessitating new open-ended evaluations. We introduce the Factorio Learning Environment (FLE), based on the game of Factorio, that tests agents in long-term planning, program synthesis, and resource optimization. FLE provides exponentially scaling challenges -- from basic automation to complex factories processing millions of resource units per second. We provide two settings: (1) lab-play consisting of eight structured tasks with fixed resources, and (2) open-play with the unbounded task of building the largest factory on an procedurally generated map. We demonstrate across both settings that models still lack strong spatial reasoning. In lab-play, we find that LLMs exhibit promising short-horizon skills, yet are unable to operate effectively in constrained environments, reflecting limitations in error analysis. In open-play, while LLMs discover automation strategies that improve growth (e.g electric-powered drilling), they fail to achieve complex automation (e.g electronic-circuit manufacturing).
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Deadlock Avoidance for Decentralized Multi-agent Systems via CBF-inspired Risk Measurement</title>
<link>https://arxiv.org/abs/2503.09621</link>
<guid>https://arxiv.org/abs/2503.09621</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、分散式安全控制、死锁、控制李雅普诺夫函数、控制障碍函数<br /><br />总结:<br />
本文提出了一种通用的分散式框架，该框架结合了控制李雅普诺夫函数和控制障碍函数，用于确保多智能体系统的任务高效执行并避免死锁。当系统接近可能导致死锁的不稳定平衡状态时，该框架能够检测到这一状态，并通过辅助的控制障碍函数引导智能体远离这种状态。为了在执行原任务控制器的同时避免死锁解决策略过度影响，文章还提出了使用基于障碍函数的风险度量方法作为死锁指示器，并将其融入统一框架中，使智能体可以自适应地决定何时激活死锁解决机制。这样既能保证智能体遵循原有的控制任务，又能在必要时无缝解锁或停用死锁解决，从而提高任务效率。理论分析、数值模拟以及实际实验验证了所提方法的有效性。 <div>
arXiv:2503.09621v1 Announce Type: new 
Abstract: Decentralized safe control plays an important role in multi-agent systems given the scalability and robustness without reliance on a central authority. However, without an explicit global coordinator, the decentralized control methods are often prone to deadlock -- a state where the system reaches equilibrium, causing the robots to stall. In this paper, we propose a generalized decentralized framework that unifies the Control Lyapunov Function (CLF) and Control Barrier Function (CBF) to facilitate efficient task execution and ensure deadlock-free trajectories for the multi-agent systems. As the agents approach the deadlock-related undesirable equilibrium, the framework can detect the equilibrium and drive agents away before that happens. This is achieved by a secondary deadlock resolution design with an auxiliary CBF to prevent the multi-agent systems from converging to the undesirable equilibrium. To avoid dominating effects due to the deadlock resolution over the original task-related controllers, a deadlock indicator function using CBF-inspired risk measurement is proposed and encoded in the unified framework for the agents to adaptively determine when to activate the deadlock resolution. This allows the agents to follow their original control tasks and seamlessly unlock or deactivate deadlock resolution as necessary, effectively improving task efficiency. We demonstrate the effectiveness of the proposed method through theoretical analysis, numerical simulations, and real-world experiments.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can A Society of Generative Agents Simulate Human Behavior and Inform Public Health Policy? A Case Study on Vaccine Hesitancy</title>
<link>https://arxiv.org/abs/2503.09639</link>
<guid>https://arxiv.org/abs/2503.09639</guid>
<content:encoded><![CDATA[
<div> 关键词: 模拟社会、生成代理、疫苗犹豫、VacSim框架、大型语言模型

总结:
本文探讨了使用生成代理和大型语言模型（如Llama和Qwen）构建名为VacSim的模拟框架来模拟人类行为的可能性，以减少对真实人类试验依赖并评估公共政策的需求。以疫苗犹豫作为案例研究，VacSim通过基于人口普查数据初始化具有社会网络连接的代理人，并根据社会动态和疾病相关信息来模拟疫苗态度，进而设计和评估各种公共卫生干预措施。文中还引入了模拟预热和态度调节机制以调整代理人态度，并提出一系列评价方法来评估LLM模拟的可靠性。实验结果显示，虽然这类模型可以模拟某些人类行为，但在与现实世界的对应性方面存在挑战，例如对不同人口统计数据的响应不一致。作者强调，这一早期探索并不旨在提供确定性的政策指导，而是呼吁更多地利用社交模拟进行政策开发研究。 <div>
arXiv:2503.09639v1 Announce Type: new 
Abstract: Can we simulate a sandbox society with generative agents to model human behavior, thereby reducing the over-reliance on real human trials for assessing public policies? In this work, we investigate the feasibility of simulating health-related decision-making, using vaccine hesitancy, defined as the delay in acceptance or refusal of vaccines despite the availability of vaccination services (MacDonald, 2015), as a case study. To this end, we introduce the VacSim framework with 100 generative agents powered by Large Language Models (LLMs). VacSim simulates vaccine policy outcomes with the following steps: 1) instantiate a population of agents with demographics based on census data; 2) connect the agents via a social network and model vaccine attitudes as a function of social dynamics and disease-related information; 3) design and evaluate various public health interventions aimed at mitigating vaccine hesitancy. To align with real-world results, we also introduce simulation warmup and attitude modulation to adjust agents' attitudes. We propose a series of evaluations to assess the reliability of various LLM simulations. Experiments indicate that models like Llama and Qwen can simulate aspects of human behavior but also highlight real-world alignment challenges, such as inconsistent responses with demographic profiles. This early exploration of LLM-driven simulations is not meant to serve as definitive policy guidance; instead, it serves as a call for action to examine social simulation for policy development.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey on Trustworthy LLM Agents: Threats and Countermeasures</title>
<link>https://arxiv.org/abs/2503.09648</link>
<guid>https://arxiv.org/abs/2503.09648</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Multi-Agent Systems (MAS)，TrustAgent框架，信任worthiness，攻击防御

<br /><br />总结:
本文提出了一个名为TrustAgent的框架，该框架针对具有额外模块（如记忆、工具和环境等）的大型语言模型（LLMs）基代理及多智能体系统（MAS）的信任度进行了全面研究。随着LLM技术的快速发展，这些问题变得日益复杂，超越了对单一LLM的信任度研究范畴。TrustAgent通过模块化分类、多维度内涵和技术实施三个方面，将代理和MAS的信任度分为内在（大脑、记忆和工具）和外在（用户、代理和环境）两个方面进行阐述。文章还总结了针对这些内部和外部模块的新出现的攻击、防御和评估方法，并对这一领域的未来发展方向提出了见解和展望。 <div>
arXiv:2503.09648v1 Announce Type: new 
Abstract: With the rapid evolution of Large Language Models (LLMs), LLM-based agents and Multi-agent Systems (MAS) have significantly expanded the capabilities of LLM ecosystems. This evolution stems from empowering LLMs with additional modules such as memory, tools, environment, and even other agents. However, this advancement has also introduced more complex issues of trustworthiness, which previous research focused solely on LLMs could not cover. In this survey, we propose the TrustAgent framework, a comprehensive study on the trustworthiness of agents, characterized by modular taxonomy, multi-dimensional connotations, and technical implementation. By thoroughly investigating and summarizing newly emerged attacks, defenses, and evaluation methods for agents and MAS, we extend the concept of Trustworthy LLM to the emerging paradigm of Trustworthy Agent. In TrustAgent, we begin by deconstructing and introducing various components of the Agent and MAS. Then, we categorize their trustworthiness into intrinsic (brain, memory, and tool) and extrinsic (user, agent, and environment) aspects. Subsequently, we delineate the multifaceted meanings of trustworthiness and elaborate on the implementation techniques of existing research related to these internal and external modules. Finally, we present our insights and outlook on this domain, aiming to provide guidance for future endeavors.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Causal Model-Based Policy Optimization</title>
<link>https://arxiv.org/abs/2503.09719</link>
<guid>https://arxiv.org/abs/2503.09719</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 基于模型的学习, 因果推理, 策略优化, Causal Markov Decision Process

总结:
本文提出了一种名为因果模型基策优化（C-MBPO）的新框架，旨在解决传统基于模型的强化学习（MBRL）方法在应对复杂、动态环境时存在的问题。C-MBPO通过在线收集轨迹来学习状态和奖励转移动力学的局部结构因果模型（SCM），从而推断出因果马尔可夫决策过程（C-MDP）。与经典MDP相比，C-MDP能够分解环境动态中的因果依赖关系，并利用因果贝叶斯网络进行表征，使智能体能够区分统计相关性和因果关系。利用所学SCM模拟假设行为下的反事实在线策略转换和奖励，进而更有效地指导策略优化。实验表明，C-MBPO学习到的政策对影响动态中非因果关联的分布漂移具有鲁棒性。 <div>
arXiv:2503.09719v1 Announce Type: new 
Abstract: Real-world decision-making problems are often marked by complex, uncertain dynamics that can shift or break under changing conditions. Traditional Model-Based Reinforcement Learning (MBRL) approaches learn predictive models of environment dynamics from queried trajectories and then use these models to simulate rollouts for policy optimization. However, such methods do not account for the underlying causal mechanisms that govern the environment, and thus inadvertently capture spurious correlations, making them sensitive to distributional shifts and limiting their ability to generalize. The same naturally holds for model-free approaches. In this work, we introduce Causal Model-Based Policy Optimization (C-MBPO), a novel framework that integrates causal learning into the MBRL pipeline to achieve more robust, explainable, and generalizable policy learning algorithms.
  Our approach centers on first inferring a Causal Markov Decision Process (C-MDP) by learning a local Structural Causal Model (SCM) of both the state and reward transition dynamics from trajectories gathered online. C-MDPs differ from classic MDPs in that we can decompose causal dependencies in the environment dynamics via specifying an associated Causal Bayesian Network. C-MDPs allow for targeted interventions and counterfactual reasoning, enabling the agent to distinguish between mere statistical correlations and causal relationships. The learned SCM is then used to simulate counterfactual on-policy transitions and rewards under hypothetical actions (or ``interventions"), thereby guiding policy optimization more effectively. The resulting policy learned by C-MBPO can be shown to be robust to a class of distributional shifts that affect spurious, non-causal relationships in the dynamics. We demonstrate this through some simple experiments involving near and far OOD dynamics drifts.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation</title>
<link>https://arxiv.org/abs/2503.09758</link>
<guid>https://arxiv.org/abs/2503.09758</guid>
<content:encoded><![CDATA[
<div> 关键词: 社会感知机器人导航(SAN), 深度强化学习, 大型语言模型(LLMs), 分布式多智能体框架, SAMALM

总结:<br />
本文提出了一个名为SAMALM的分布式多智能体大型语言模型actor-critic框架，用于解决多机器人社会导航问题。SAMALM利用并行运行的不同个性或配置的LLM演员直接生成控制信号，通过全球批评者和个体批评者的两层验证过程，增强了行为评估和精确低级控制信号的一致性。同时，熵基得分融合机制提升了系统的自我验证和重查询能力，从而提高了鲁棒性和协调性。实验结果显示，SAMALM有效地平衡了局部自主与全局监督，能够在各种多机器人场景中展现出社交合规的行为和强大的适应性。该工作更多详情和视频可访问提供的网站地址进行查阅。 <div>
arXiv:2503.09758v1 Announce Type: new 
Abstract: Recent advances in robotics and large language models (LLMs) have sparked growing interest in human-robot collaboration and embodied intelligence. To enable the broader deployment of robots in human-populated environments, socially-aware robot navigation (SAN) has become a key research area. While deep reinforcement learning approaches that integrate human-robot interaction (HRI) with path planning have demonstrated strong benchmark performance, they often struggle to adapt to new scenarios and environments. LLMs offer a promising avenue for zero-shot navigation through commonsense inference. However, most existing LLM-based frameworks rely on centralized decision-making, lack robust verification mechanisms, and face inconsistencies in translating macro-actions into precise low-level control signals. To address these challenges, we propose SAMALM, a decentralized multi-agent LLM actor-critic framework for multi-robot social navigation. In this framework, a set of parallel LLM actors, each reflecting distinct robot personalities or configurations, directly generate control signals. These actions undergo a two-tier verification process via a global critic that evaluates group-level behaviors and individual critics that assess each robot's context. An entropy-based score fusion mechanism further enhances self-verification and re-query, improving both robustness and coordination. Experimental results confirm that SAMALM effectively balances local autonomy with global oversight, yielding socially compliant behaviors and strong adaptability across diverse multi-robot scenarios. More details and videos about this work are available at: https://sites.google.com/view/SAMALM.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Achieving constant regret for dynamic matching via state-independent policies</title>
<link>https://arxiv.org/abs/2503.09762</link>
<guid>https://arxiv.org/abs/2503.09762</guid>
<content:encoded><![CDATA[
<div> 关键词：动态两向匹配模型、离散时间、贪婪策略、一般位置差参数、最优缩放

总结:
本文研究了一个具有有限多种代理类型的集中式离散时间动态两向匹配模型。文章重点关注仅依据类型间的代理人可用性做出匹配决策，而无需完整队列长度信息的state-independent贪婪策略，这种策略在如肾脏交换等生命救助应用中更具吸引力。首先，对于有向无环匹配网络，分析了Kerimov等人[2023]提出的遵循静态优先级顺序的确定性优先策略，并首次给出了关于一般位置差参数$\epsilon$的明确的遗憾界限。其次，针对一般的两向匹配网络，设计了一种随机化的state-independent贪婪策略，实现了具有最优缩放比例$O(\epsilon^{-1})$的常数遗憾界，这一结果与Kerimov等人[2024]所建立的下界相匹配。<br /><br /> <div>
arXiv:2503.09762v1 Announce Type: new 
Abstract: We study a centralized discrete-time dynamic two-way matching model with finitely many agent types. Agents arrive stochastically over time and join their type-dedicated queues waiting to be matched. We focus on state-independent greedy policies that achieve constant regret at all times by making matching decisions based solely on agent availability across types, rather than requiring complete queue-length information. Such policies are particularly appealing for life-saving applications such as kidney exchange, as they require less information and provide more transparency compared to state-dependent policies.
  First, for acyclic matching networks, we analyze a deterministic priority policy proposed by Kerimov et al. [2023] that follows a static priority order over matches. We derive the first explicit regret bound in terms of the general position gap (GPG) parameter $\epsilon$, which measures the distance of the fluid relaxation from degeneracy. Second, for general two-way matching networks, we design a randomized state-independent greedy policy that achieves constant regret with optimal scaling $O(\epsilon^{-1})$, matching the existing lower bound established by Kerimov et al. [2024].
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentDAM: Privacy Leakage Evaluation for Autonomous Web Agents</title>
<link>https://arxiv.org/abs/2503.09780</link>
<guid>https://arxiv.org/abs/2503.09780</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM-powered AI agents, 数据最小化, AgentDAM, 隐私泄漏, 提示法

<br /><br />总结:

本文提出了一个针对LLM（大语言模型）驱动的人工智能代理的新挑战，旨在通过强化数据最小化原则来降低用户隐私泄露的风险。为此，研究者开发了一个名为AgentDAM的基准测试工具，用于评估现有和未来AI代理在处理可能涉及私人信息的任务中，是否能够有效地限制对“必要”信息之外的敏感信息处理。实验结果显示，基于GPT-4、Llama-3和Claude构建的AI代理在不必要的情况下常常会不恰当地使用敏感信息。为了解决这一问题，文中提出了一种基于提示的方法，可以有效减少AI代理对不必要的敏感信息的使用。 <div>
arXiv:2503.09780v1 Announce Type: new 
Abstract: LLM-powered AI agents are an emerging frontier with tremendous potential to increase human productivity. However, empowering AI agents to take action on their user's behalf in day-to-day tasks involves giving them access to potentially sensitive and private information, which leads to a possible risk of inadvertent privacy leakage when the agent malfunctions. In this work, we propose one way to address that potential risk, by training AI agents to better satisfy the privacy principle of data minimization. For the purposes of this benchmark, by "data minimization" we mean instances where private information is shared only when it is necessary to fulfill a specific task-relevant purpose. We develop a benchmark called AgentDAM to evaluate how well existing and future AI agents can limit processing of potentially private information that we designate "necessary" to fulfill the task. Our benchmark simulates realistic web interaction scenarios and is adaptable to all existing web navigation agents. We use AgentDAM to evaluate how well AI agents built on top of GPT-4, Llama-3 and Claude can limit processing of potentially private information when unnecessary, and show that these agents are often prone to inadvertent use of unnecessary sensitive information. We finally propose a prompting-based approach that reduces this.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Designing Graph Convolutional Neural Networks for Discrete Choice with Network Effects</title>
<link>https://arxiv.org/abs/2503.09786</link>
<guid>https://arxiv.org/abs/2503.09786</guid>
<content:encoded><![CDATA[
<div> 关键词: 网络效应、离散选择模型、图卷积神经网络、预测性能、解释性

总结:
本文介绍了一种新的模型架构，该架构将网络效应纳入离散选择问题中，相较于标准离散选择模型具备更高的预测性能，同时比通用的灵活模型类更具可解释性。研究中提到，虽然经济学中的离散选择模型有助于理解个体决策过程，但大多数应用忽视了同伴影响。为此，作者提出了一种基于图卷积神经网络的新架构，用于模拟离散选择中的网络效应，实现在保持必要解释性的同时，提高预测性能，这是常规深度学习架构通常缺乏的优点。通过使用纽约市通勤选择数据和2016年美国选举数据进行评估，证明了该模型在处理具有高度不平衡类别的数据集上的优良表现。此外，该模型还能够估计如纽约市旅行时间节省价值等相关的经济指标，并对比了与传统离散选择模型及通用深度学习模型在预测性能和行为洞察方面的差异。 <div>
arXiv:2503.09786v1 Announce Type: new 
Abstract: We introduce a novel model architecture that incorporates network effects into discrete choice problems, achieving higher predictive performance than standard discrete choice models while offering greater interpretability than general-purpose flexible model classes. Econometric discrete choice models aid in studying individual decision-making, where agents select the option with the highest reward from a discrete set of alternatives. Intuitively, the utility an individual derives from a particular choice depends on their personal preferences and characteristics, the attributes of the alternative, and the value their peers assign to that alternative or their previous choices. However, most applications ignore peer influence, and models that do consider peer or network effects often lack the flexibility and predictive performance of recently developed approaches to discrete choice, such as deep learning. We propose a novel graph convolutional neural network architecture to model network effects in discrete choices, achieving higher predictive performance than standard discrete choice models while retaining the interpretability necessary for inference--a quality often lacking in general-purpose deep learning architectures. We evaluate our architecture using revealed commuting choice data, extended with travel times and trip costs for each travel mode for work-related trips in New York City, as well as 2016 U.S. election data aggregated by county, to test its performance on datasets with highly imbalanced classes. Given the interpretability of our models, we can estimate relevant economic metrics, such as the value of travel time savings in New York City. Finally, we compare the predictive performance and behavioral insights from our architecture to those derived from traditional discrete choice and general-purpose deep learning models.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Augmenting Teamwork through AI Agents as Spatial Collaborators</title>
<link>https://arxiv.org/abs/2503.09794</link>
<guid>https://arxiv.org/abs/2503.09794</guid>
<content:encoded><![CDATA[
<div> 关键词：增强现实(AR)，人工智能(AI)，人类-人工智能团队(HATs)，团队动态，实时响应

<br /><br />总结:
本文是一篇关于增强现实在人类与人工智能协同中的应用的研究立场论文。随着AR和AI技术的融合，AI作为适应性队友在沉浸式环境中支持人类协作的新机遇出现。文章指出，现有研究主要关注人机双人交互，而在AR环境下的人类-人工智能团队（HATs）中的互动则较少被重视。论文主张，AR环境中的AI代理不仅要与个体互动，还应实时识别并回应团队层面的需求。为了优化团队表现和决策制定，AI应当能够动态生成有利于有效协作的资源，如虚拟白板用于头脑风暴、共享理解的心理地图模型以及空间配置的记忆回溯以增进知识留存和任务协调。这一方法超越了预定义的AI辅助，迈向了情境驱动的AI干预新阶段。 <div>
arXiv:2503.09794v1 Announce Type: new 
Abstract: As Augmented Reality (AR) and Artificial Intelligence (AI) continue to converge, new opportunities emerge for AI agents to actively support human collaboration in immersive environments. While prior research has primarily focused on dyadic human-AI interactions, less attention has been given to Human-AI Teams (HATs) in AR, where AI acts as an adaptive teammate rather than a static tool. This position paper takes the perspective of team dynamics and work organization to propose that AI agents in AR should not only interact with individuals but also recognize and respond to team-level needs in real time. We argue that spatially aware AI agents should dynamically generate the resources necessary for effective collaboration, such as virtual blackboards for brainstorming, mental map models for shared understanding, and memory recall of spatial configurations to enhance knowledge retention and task coordination. This approach moves beyond predefined AI assistance toward context-driven AI interventions that optimize team performance and decision-making.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fine-tuning Vision Language Models with Graph-based Knowledge for Explainable Medical Image Analysis</title>
<link>https://arxiv.org/abs/2503.09808</link>
<guid>https://arxiv.org/abs/2503.09808</guid>
<content:encoded><![CDATA[
<div> 关键词: 糖尿病视网膜病变(DR)、可解释性、图表示学习、视觉语言模型(VLM)、光学相干断层扫描血管造影(OCTA)

总结:
本文提出了一种结合图表示学习与视觉语言模型的创新方法，用于实现糖尿病视网膜病变(DR)的准确诊断和解释。该方法利用光学相干断层扫描血管造影(OCTA)图像构建生物信息学驱动的图结构，编码关键的视网膜血管特征如血管形态和空间连接性。通过图神经网络(GNN)进行DR分期，并使用集成梯度突出显示影响分类决策的关键节点和边及其特征。这种方法将图基知识转化为文本描述，对视觉语言模型进行指令微调训练学生模型，使其能基于单张图像输入对疾病进行分类并给出人类可理解的解释。实验证明，该方法在提高分类准确性的同时，也提供了更具临床可解释性的结果。专家研究进一步证实，这种方法提供的诊断解释更准确，有助于精确定位OCTA图像中的病理变化。 <div>
arXiv:2503.09808v1 Announce Type: new 
Abstract: Accurate staging of Diabetic Retinopathy (DR) is essential for guiding timely interventions and preventing vision loss. However, current staging models are hardly interpretable, and most public datasets contain no clinical reasoning or interpretation beyond image-level labels. In this paper, we present a novel method that integrates graph representation learning with vision-language models (VLMs) to deliver explainable DR diagnosis. Our approach leverages optical coherence tomography angiography (OCTA) images by constructing biologically informed graphs that encode key retinal vascular features such as vessel morphology and spatial connectivity. A graph neural network (GNN) then performs DR staging while integrated gradients highlight critical nodes and edges and their individual features that drive the classification decisions. We collect this graph-based knowledge which attributes the model's prediction to physiological structures and their characteristics. We then transform it into textual descriptions for VLMs. We perform instruction-tuning with these textual descriptions and the corresponding image to train a student VLM. This final agent can classify the disease and explain its decision in a human interpretable way solely based on a single image input. Experimental evaluations on both proprietary and public datasets demonstrate that our method not only improves classification accuracy but also offers more clinically interpretable results. An expert study further demonstrates that our method provides more accurate diagnostic explanations and paves the way for precise localization of pathologies in OCTA images.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Driven Distributionally Robust Control for Interacting Agents under Logical Constraints</title>
<link>https://arxiv.org/abs/2503.09816</link>
<guid>https://arxiv.org/abs/2503.09816</guid>
<content:encoded><![CDATA[
<div> 关键词：分布鲁棒控制合成、随机动力学、信号时空逻辑（STL）、机会约束规划（CCP）、集中度量理论（CoM）、条件价值在风险（CVaR）、期望约束规划（ECP）、分布鲁棒优化（DRO）、数据驱动优化

<br /><br />总结:
本文提出了一种针对具有随机动力学特性的智能体在与其他智能体互动过程中，面对不确定性和由信号时空逻辑（STL）表达的约束条件下的分布鲁棒控制综合方法。研究中将控制综合问题形式化为机会约束规划（CCP），并要求在所有由其他智能体引起的不确定性场景下，以高概率满足STL规范。为了解决CCP，文章提出了基于集中度量理论（CoM）和条件价值在风险（CVaR）的两种方法，并对比了它们所需的假设和优化结果。这两种方法将CCP转化为更易于求解的期望约束规划（ECP）。通过采用分布鲁棒优化（DRO）方法来利用有限观测数据估计期望值。进一步地，DRO可以近似为一个提供对原ECP概率下界的稳健数据驱动优化问题，其中该概率取决于样本数量。因此，在可行性条件下，原本的STL约束可以通过设计的两层置信度得到满足：即机会约束的置信度以及依赖于样本数的数据驱动优化的置信度。最后，文章详细介绍了数值求解所得到的稳健数据驱动优化问题的方法，并通过案例研究比较了两种提出的途径。 <div>
arXiv:2503.09816v1 Announce Type: new 
Abstract: In this paper, we propose a distributionally robust control synthesis for an agent with stochastic dynamics that interacts with other agents under uncertainties and constraints expressed by signal temporal logic (STL). We formulate the control synthesis as a chance-constrained program (CCP) with STL specifications that must be satisfied with high probability under all uncertainty tubes induced by the other agents. To tackle the CCP, we propose two methods based on concentration of measure (CoM) theory and conditional value at risk (CVaR) and compare the required assumptions and resulting optimizations. These approaches convert the CCP into an expectation-constrained program (ECP), which is simpler to solve than the original CCP. To estimate the expectation using a finite set of observed data, we adopt a distributionally robust optimization (DRO) approach. The underlying DRO can be approximated as a robust data-driven optimization that provides a probabilistic under-approximation to the original ECP, where the probability depends on the number of samples. Therefore, under feasibility, the original STL constraints are satisfied with two layers of designed confidence: the confidence of the chance constraint and the confidence of the approximated data-driven optimization, which depends on the number of samples. We then provide details on solving the resulting robust data-driven optimization numerically. Finally, we compare the two proposed approaches through case studies.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Temporal Difference Flows</title>
<link>https://arxiv.org/abs/2503.09817</link>
<guid>https://arxiv.org/abs/2503.09817</guid>
<content:encoded><![CDATA[
<div> 关键词：Predictive models, Geometric Horizon Models (GHMs), Temporal Difference Flows (TD-Flow), Bootstrapping, Decision-making

总结:
本文提出了一种名为Temporal Difference Flows (TD-Flow)的新方法，用于提高Geometric Horizon Models (GHMs)对未来状态预测的准确性。现有GHM的学习方法在训练时受到bootstrapping预测的影响，难以生成长期预测。TD-Flow利用概率路径上的新型贝尔曼方程结构以及流匹配技术，能够学习准确的GHM并将其预测范围扩大超过先前方法的5倍。理论分析中，文章证明了新的收敛结果，并认为TD-Flow的有效性主要归因于训练过程中梯度方差的降低。此外，作者还探讨了将类似论点扩展到基于扩散的方法的可能性。实验验证表明，TD-Flow在多个领域的生成指标和下游任务（包括策略评估）上表现优越。进一步地，通过将TD-Flow与近期的行为基础模型相结合进行预训练策略规划，显示出显著的性能提升，强调了其在长时决策制定中的潜力。 <div>
arXiv:2503.09817v1 Announce Type: new 
Abstract: Predictive models of the future are fundamental for an agent's ability to reason and plan. A common strategy learns a world model and unrolls it step-by-step at inference, where small errors can rapidly compound. Geometric Horizon Models (GHMs) offer a compelling alternative by directly making predictions of future states, avoiding cumulative inference errors. While GHMs can be conveniently learned by a generative analog to temporal difference (TD) learning, existing methods are negatively affected by bootstrapping predictions at train time and struggle to generate high-quality predictions at long horizons. This paper introduces Temporal Difference Flows (TD-Flow), which leverages the structure of a novel Bellman equation on probability paths alongside flow-matching techniques to learn accurate GHMs at over 5x the horizon length of prior methods. Theoretically, we establish a new convergence result and primarily attribute TD-Flow's efficacy to reduced gradient variance during training. We further show that similar arguments can be extended to diffusion-based methods. Empirically, we validate TD-Flow across a diverse set of domains on both generative metrics and downstream tasks including policy evaluation. Moreover, integrating TD-Flow with recent behavior foundation models for planning over pre-trained policies demonstrates substantial performance gains, underscoring its promise for long-horizon decision-making.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Inter-environmental world modeling for continuous and compositional dynamics</title>
<link>https://arxiv.org/abs/2503.09911</link>
<guid>https://arxiv.org/abs/2503.09911</guid>
<content:encoded><![CDATA[
<div> 关键词：世界模型、自回归框架、连续latent动作表示、Lie群理论、对象中心自动编码器

<br /><br />总结:

本文提出了一个名为World Modeling through Lie Action (WLA)的新框架，该框架受到人类在不同环境中进行综合体验并模拟控制代理能力的启发。与依赖离散动作和观测表示的现有自回归世界模型框架不同，WLA学习基于Lie群理论和对象中心自动编码器的连续潜在动作表示，以跨环境进行模拟。通过仅使用视频帧训练，WLA在无需大量或无动作标签的情况下，展现出在具有新颖动作集的新环境中快速适应的能力。在合成基准和真实世界数据集上验证了WLA的有效性。 <div>
arXiv:2503.09911v1 Announce Type: new 
Abstract: Various world model frameworks are being developed today based on autoregressive frameworks that rely on discrete representations of actions and observations, and these frameworks are succeeding in constructing interactive generative models for the target environment of interest. Meanwhile, humans demonstrate remarkable generalization abilities to combine experiences in multiple environments to mentally simulate and learn to control agents in diverse environments. Inspired by this human capability, we introduce World modeling through Lie Action (WLA), an unsupervised framework that learns continuous latent action representations to simulate across environments. WLA learns a control interface with high controllability and predictive ability by simultaneously modeling the dynamics of multiple environments using Lie group theory and object-centric autoencoder. On synthetic benchmark and real-world datasets, we demonstrate that WLA can be trained using only video frames and, with minimal or no action labels, can quickly adapt to new environments with novel action sets.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PanoGen++: Domain-Adapted Text-Guided Panoramic Environment Generation for Vision-and-Language Navigation</title>
<link>https://arxiv.org/abs/2503.09938</link>
<guid>https://arxiv.org/abs/2503.09938</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-and-language导航、数据稀缺性、PanoGen++、预训练扩散模型、环境生成

总结:<br />
本文提出了一个名为PanoGen++的新框架，旨在解决视觉与语言导航(VLN)任务中训练数据稀少的问题。PanoGen++结合了预训练的扩散模型并进行了领域特定的微调，通过低秩适应等参数高效技术降低计算成本。该框架探索了两种环境生成设置：基于文本描述的图像掩码填充和递归图像扩展填充。前者通过根据文本描述填充全景图中的遮挡区域来最大化新环境的创建，后者有助于代理人学习全景中的空间关系。实验结果显示，在房间到房间（R2R）、房间为房间（R4R）以及合作视觉与对话导航（CVDN）数据集上，PanoGen++均取得了显著的性能提升，分别在R2R测试领航员榜上的成功率提高了2.44%，在R4R验证未见集合上的成功率提升了0.63%，并在CVDN验证未见集合上的目标进度提高了0.75米。因此，PanoGen++通过增强训练环境的多样性和相关性，有效地提高了VLN任务的泛化能力和效能。 <div>
arXiv:2503.09938v1 Announce Type: new 
Abstract: Vision-and-language navigation (VLN) tasks require agents to navigate three-dimensional environments guided by natural language instructions, offering substantial potential for diverse applications. However, the scarcity of training data impedes progress in this field. This paper introduces PanoGen++, a novel framework that addresses this limitation by generating varied and pertinent panoramic environments for VLN tasks. PanoGen++ incorporates pre-trained diffusion models with domain-specific fine-tuning, employing parameter-efficient techniques such as low-rank adaptation to minimize computational costs. We investigate two settings for environment generation: masked image inpainting and recursive image outpainting. The former maximizes novel environment creation by inpainting masked regions based on textual descriptions, while the latter facilitates agents' learning of spatial relationships within panoramas. Empirical evaluations on room-to-room (R2R), room-for-room (R4R), and cooperative vision-and-dialog navigation (CVDN) datasets reveal significant performance enhancements: a 2.44% increase in success rate on the R2R test leaderboard, a 0.63% improvement on the R4R validation unseen set, and a 0.75-meter enhancement in goal progress on the CVDN validation unseen set. PanoGen++ augments the diversity and relevance of training environments, resulting in improved generalization and efficacy in VLN tasks.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MoFlow: One-Step Flow Matching for Human Trajectory Forecasting via Implicit Maximum Likelihood Estimation based Distillation</title>
<link>https://arxiv.org/abs/2503.09950</link>
<guid>https://arxiv.org/abs/2503.09950</guid>
<content:encoded><![CDATA[
<div> 关键词：人类轨迹预测、MoFlow、多模态、流量匹配损失函数、隐式最大似然估计（IMLE）、教师模型、学生模型、SportVU NBA游戏、ETH-UCY、SDD、物理可行性、社会可接受性、采样速度。

<br /><br />总结：
本文提出了一种名为MoFlow的新颖的人类轨迹预测模型，用于基于过去轨迹和其他上下文线索预测人类未来可能的多模态运动。MoFlow设计了创新的流量匹配损失函数，确保预测的K组未来轨迹中至少一组准确，同时鼓励所有K组轨迹具有多样性和合理性。此外，通过利用隐式最大似然估计（IMLE），文中提出了一种仅需教师模型样本的新颖蒸馏方法。实验显示，该方法在包括SportVU NBA游戏、ETH-UCY和SDD在内的真实世界数据集上，教师模型和经IMLE蒸馏的学生模型均达到了最先进的性能。这些模型能够生成既符合物理规律又具有社会合理性的多样化轨迹，而且学生模型在一阶采样时的速度比教师模型快了约100倍。相关代码、模型和数据可在项目页面https://moflow-imle.github.io获取。 <div>
arXiv:2503.09950v1 Announce Type: new 
Abstract: In this paper, we address the problem of human trajectory forecasting, which aims to predict the inherently multi-modal future movements of humans based on their past trajectories and other contextual cues. We propose a novel motion prediction conditional flow matching model, termed MoFlow, to predict K-shot future trajectories for all agents in a given scene. We design a novel flow matching loss function that not only ensures at least one of the $K$ sets of future trajectories is accurate but also encourages all $K$ sets of future trajectories to be diverse and plausible. Furthermore, by leveraging the implicit maximum likelihood estimation (IMLE), we propose a novel distillation method for flow models that only requires samples from the teacher model. Extensive experiments on the real-world datasets, including SportVU NBA games, ETH-UCY, and SDD, demonstrate that both our teacher flow model and the IMLE-distilled student model achieve state-of-the-art performance. These models can generate diverse trajectories that are physically and socially plausible. Moreover, our one-step student model is $\textbf{100}$ times faster than the teacher flow model during sampling. The code, model, and data are available at our project page: https://moflow-imle.github.io
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OR-LLM-Agent: Automating Modeling and Solving of Operations Research Optimization Problem with Reasoning Large Language Model</title>
<link>https://arxiv.org/abs/2503.10009</link>
<guid>https://arxiv.org/abs/2503.10009</guid>
<content:encoded><![CDATA[
<div> 关键词：Operations Research、Artificial Intelligence、OR-LLM-Agent、Chain-of-Thought、Gurobi

总结:
本文提出了一种名为OR-LLM-Agent的人工智能代理，它是首个实现解决现实世界运筹学问题全程自动化的系统。该代理利用大型语言模型（LLMs）的Chain-of-Thought推理能力，将自然语言描述的实际问题转化为数学模型并自动生成Gurobi求解器代码。同时，OR-LLM-Agent中的OR-CodeAgent负责自动化代码执行和修复工作。由于缺乏专门用于评估运筹学问题自动化求解的基准数据集，文章构建了一个包含83个自然语言描述的真实运筹学问题的基准数据集。实验结果显示，与当前最先进的推理LLM模型（如GPT-o3-mini、DeepSeek-R1和Gemini 2.0 Flash Thinking）相比，OR-LLM-Agent取得了100%的通过率和85%的最高解决方案精度，证明了自动化解决运筹学问题的可行性。相关数据和代码已在GitHub上公开发布。 <div>
arXiv:2503.10009v1 Announce Type: new 
Abstract: Operations Research (OR) has been widely applied in various fields such as resource allocation, production planning, and supply chain management. However, addressing real-world OR problems requires OR experts to perform mathematical modeling and programmers to develop solution algorithms. This traditional method, heavily reliant on experts, is costly and has long development cycles, severely limiting the widespread adoption of OR techniques. Few have considered using Artificial Intelligence (AI) to replace professionals to achieve fully automated solutions for OR problems. We propose OR-LLM-Agent, the first AI agent that enables end-to-end automation for solving real-world OR problems. OR-LLM-Agent leverages the Chain-of-Thought (CoT) reasoning capabilities of Large Language Models (LLMs) to translate natural language problem descriptions into formal mathematical models and automatically generate Gurobi solver code. In OR-LLM-Agent, OR-CodeAgent is designed to automate code execution and repair within a sandbox environment, facilitating the derivation of the final solution. Due to the lack of dedicated benchmark datasets for evaluating the automated solving of OR problems, we construct a benchmark dataset comprising 83 real-world OR problems described in natural language. We conduct comparative experiments with state-of-the-art (SOTA) reasoning LLMs, including GPT-o3-mini, DeepSeek-R1, and Gemini 2.0 Flash Thinking. The OR-LLM-Agent achieved the highest pass rate of 100% and the highest solution accuracy of 85%, demonstrating the feasibility of automated OR problem-solving. Data and code have been publicly available at https://github.com/bwz96sco/or_llm_agent.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Revisiting Multi-Agent Asynchronous Online Optimization with Delays: the Strongly Convex Case</title>
<link>https://arxiv.org/abs/2503.10013</link>
<guid>https://arxiv.org/abs/2503.10013</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、异步在线优化、延迟、强凸性、跟随领袖算法

总结:
本文重新探讨了具有延迟的多智能体异步在线优化问题。研究中，只有单一智能体在每个回合进行决策并经历未知延迟后接收到所有反馈。针对此前假设最大延迟可知或反馈到达顺序具有特殊性质的情况，文章令人惊讶地发现，在损失函数为强凸的情况下，这些假设可以被消除，并且现有的遗憾界限能显著提升至$O(d\log T)$。为利用损失函数的强凸性，文中首先提出了一个延迟版的经典跟随领袖算法——FTDL，但该算法需要完整的函数信息作为反馈。此外，为了处理仅有梯度反馈的更一般情况，文中通过将FTDL与代理损失函数相结合，开发了一个近似版本的FTDL。实验结果显示，该近似FTDL在强凸情形下优于现有算法。 <div>
arXiv:2503.10013v1 Announce Type: new 
Abstract: We revisit multi-agent asynchronous online optimization with delays, where only one of the agents becomes active for making the decision at each round, and the corresponding feedback is received by all the agents after unknown delays. Although previous studies have established an $O(\sqrt{dT})$ regret bound for this problem, they assume that the maximum delay $d$ is knowable or the arrival order of feedback satisfies a special property, which may not hold in practice. In this paper, we surprisingly find that when the loss functions are strongly convex, these assumptions can be eliminated, and the existing regret bound can be significantly improved to $O(d\log T)$ meanwhile. Specifically, to exploit the strong convexity of functions, we first propose a delayed variant of the classical follow-the-leader algorithm, namely FTDL, which is very simple but requires the full information of functions as feedback. Moreover, to handle the more general case with only the gradient feedback, we develop an approximate variant of FTDL by combining it with surrogate loss functions. Experimental results show that the approximate FTDL outperforms the existing algorithm in the strongly convex case.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CCaaLF: Concurrency Control as a Learnable Function</title>
<link>https://arxiv.org/abs/2503.10036</link>
<guid>https://arxiv.org/abs/2503.10036</guid>
<content:encoded><![CDATA[
<div> 关键词：并发控制、数据库、学习算法、工作负载、性能优化

总结:<br />
本文提出了一种名为CCaaLF（Concurrency Control as a Learnable Function）的新颖学习型并发控制算法，旨在应对各种变化的工作负载并实现高性能。CCaaLF能够快速优化，适应动态工作负载的变化。该算法通过学习得到一个代理函数，综合了现有并发控制算法的多种设计选择，并将其高效地实现为数据库内的查找表，用于映射数据库状态到并发控制动作。学习过程结合了贝叶斯优化和一种新颖的图减小算法，能快速收敛至高事务吞吐量的函数。实验表明，相比于五个最先进的并发控制算法，CCaaLF在交易吞吐量和优化时间上均展现出更优的表现。 <div>
arXiv:2503.10036v1 Announce Type: new 
Abstract: Concurrency control (CC) algorithms are important in modern transactional databases, as they enable high performance by executing transactions concurrently while ensuring correctness. However, state-of-the-art CC algorithms struggle to perform well across diverse workloads, and most do not consider workload drifts.
  In this paper, we propose CCaaLF (Concurrency Control as a Learnable Function), a novel learned concurrency control algorithm designed to achieve high performance across varying workloads. The algorithm is quick to optimize, making it robust against dynamic workloads. CCaaLF learns an agent function that captures a large number of design choices from existing CC algorithms. The function is implemented as an efficient in-database lookup table that maps database states to concurrency control actions. The learning process is based on a combination of Bayesian optimization and a novel graph reduction algorithm, which converges quickly to a function that achieves high transaction throughput. We compare CCaaLF against five state-of-the-art CC algorithms and show that our algorithm consistently outperforms them in terms of transaction throughput and optimization time.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Multi-Agent Systems via Reinforcement Learning with LLM-based Planner and Graph-based Policy</title>
<link>https://arxiv.org/abs/2503.10049</link>
<guid>https://arxiv.org/abs/2503.10049</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统 (MAS), 强化学习 (RL), 大规模语言模型 (LLM), 多智能体强化学习 (MARL), 图协作 MARL (LGC-MARL)

总结:
本文提出了一种名为 LLM 基于图协作的多智能体强化学习框架 (LGC-MARL)，用于解决多智能体系统的复杂任务协调与安全性问题。该框架结合了大规模语言模型和多智能体强化学习，通过将复杂的任务分解为可执行的子任务并利用基于图的协调方式实现高效协作。LGC-MARL 包含两个主要组件：LLM 规划器和基于图的协作元策略。LLM 规划器将复杂任务指令转化为一系列子任务，并使用批评模型评估其合理性，生成动作依赖图；而基于图的协作元策略则根据该图进行代理间的通信与协作，并通过元学习适应新任务环境。实验结果表明，LGC-MARL 在 AI2-THOR 模拟平台上的各种复杂任务中展现出优越的性能和可扩展性。 <div>
arXiv:2503.10049v1 Announce Type: new 
Abstract: Multi-agent systems (MAS) have shown great potential in executing complex tasks, but coordination and safety remain significant challenges. Multi-Agent Reinforcement Learning (MARL) offers a promising framework for agent collaboration, but it faces difficulties in handling complex tasks and designing reward functions. The introduction of Large Language Models (LLMs) has brought stronger reasoning and cognitive abilities to MAS, but existing LLM-based systems struggle to respond quickly and accurately in dynamic environments. To address these challenges, we propose LLM-based Graph Collaboration MARL (LGC-MARL), a framework that efficiently combines LLMs and MARL. This framework decomposes complex tasks into executable subtasks and achieves efficient collaboration among multiple agents through graph-based coordination. Specifically, LGC-MARL consists of two main components: an LLM planner and a graph-based collaboration meta policy. The LLM planner transforms complex task instructions into a series of executable subtasks, evaluates the rationality of these subtasks using a critic model, and generates an action dependency graph. The graph-based collaboration meta policy facilitates communication and collaboration among agents based on the action dependency graph, and adapts to new task environments through meta-learning. Experimental results on the AI2-THOR simulation platform demonstrate the superior performance and scalability of LGC-MARL in completing various complex tasks.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>One-bit consensus of controllable linear multi-agent systems with communication noises</title>
<link>https://arxiv.org/abs/2503.10062</link>
<guid>https://arxiv.org/abs/2503.10062</guid>
<content:encoded><![CDATA[
<div> 关键词：one-bit共识、线性多智能体系统、通信噪声、控制协议、共识控制器

总结:

该文研究了具有通信噪声的可控线性多智能体系统的一位共识问题。文中设计了一种结合通信协议和共识控制器的共识算法，其中通信协议采用线性压缩编码函数实现一位数据率，从而节省通信成本。提出的共识控制器包括稳定项与共识项，能确保潜在不稳定但可控的多智能体系统的共识达成。针对由一位通信导致的信息损失，共识项中采用了估计算法进行补偿，并通过衰减步长来减轻通信噪声的影响。文章构建了两个联合Lyapunov函数以克服控制与估计相结合带来的困难，并利用这两个函数相似的迭代结构证明，在固定连通拓扑下，多智能体系统能在均方意义下以迭代次数的倒数速率实现共识。此外，还将理论结果推广到了具有共同连接的马尔可夫切换拓扑情况，建立了马尔可夫切换拓扑与固定拓扑之间的某种等价关系。最后，通过两个仿真示例验证了所提算法的有效性。

<br /><br /> <div>
arXiv:2503.10062v1 Announce Type: new 
Abstract: This paper addresses the one-bit consensus of controllable linear multi-agent systems (MASs) with communication noises. A consensus algorithm consisting of a communication protocol and a consensus controller is designed. The communication protocol introduces a linear compression encoding function to achieve a one-bit data rate, thereby saving communication costs. The consensus controller with a stabilization term and a consensus term is proposed to ensure the consensus of a potentially unstable but controllable MAS. Specifically, in the consensus term, we adopt an estimation method to overcome the information loss caused by one-bit communications and a decay step to attenuate the effect of communication noise. Two combined Lyapunov functions are constructed to overcome the difficulty arising from the coupling of the control and estimation. By establishing similar iterative structures of these two functions, this paper shows that the MAS can achieve consensus in the mean square sense at the rate of the reciprocal of the iteration number under the case with a connected fixed topology. Moreover, the theoretical results are generalized to the case with jointly connected Markovian switching topologies by establishing a certain equivalence relationship between the Markovian switching topologies and a fixed topology. Two simulation examples are given to validate the algorithm.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SmartWay: Enhanced Waypoint Prediction and Backtracking for Zero-Shot Vision-and-Language Navigation</title>
<link>https://arxiv.org/abs/2503.10069</link>
<guid>https://arxiv.org/abs/2503.10069</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-and-Language Navigation (VLN)，continuous environments，waypoint predictor，navigator，Multi-modal Large Language Model (MLLM)

总结:<br />
本文提出了一个针对连续环境中的视觉与语言导航（VLN-CE）任务的零样本框架。该框架通过改进现有的两阶段方法，集成了一种增强型的航路点预测器和基于多模态大型语言模型（MLLM）的导航器。增强型航路点预测器采用更强大的视觉编码器、掩蔽交叉注意力融合以及占用感知损失函数，以提高航路点的质量。导航器则引入了历史感知推理和具有回溯功能的自适应路径规划，从而提高了鲁棒性。实验结果显示，该方法在R2R-CE和MP3D基准测试中实现了零样本设置下的最佳性能（state-of-the-art），并与全监督方法的竞争结果相当。此外，使用Turtlebot 4进行的真实世界验证进一步突显了其良好的适应性。 <div>
arXiv:2503.10069v1 Announce Type: new 
Abstract: Vision-and-Language Navigation (VLN) in continuous environments requires agents to interpret natural language instructions while navigating unconstrained 3D spaces. Existing VLN-CE frameworks rely on a two-stage approach: a waypoint predictor to generate waypoints and a navigator to execute movements. However, current waypoint predictors struggle with spatial awareness, while navigators lack historical reasoning and backtracking capabilities, limiting adaptability. We propose a zero-shot VLN-CE framework integrating an enhanced waypoint predictor with a Multi-modal Large Language Model (MLLM)-based navigator. Our predictor employs a stronger vision encoder, masked cross-attention fusion, and an occupancy-aware loss for better waypoint quality. The navigator incorporates history-aware reasoning and adaptive path planning with backtracking, improving robustness. Experiments on R2R-CE and MP3D benchmarks show our method achieves state-of-the-art (SOTA) performance in zero-shot settings, demonstrating competitive results compared to fully supervised methods. Real-world validation on Turtlebot 4 further highlights its adaptability.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advanced Tool Learning and Selection System (ATLASS): A Closed-Loop Framework Using LLM</title>
<link>https://arxiv.org/abs/2503.10071</link>
<guid>https://arxiv.org/abs/2503.10071</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM、外部工具、ATLASS、工具学习、生成系统

<br /><br />总结:

本文提出了一种名为ATLASS的高级工具学习和选择系统，旨在解决LLM（大型语言模型）在处理超出其知识库范围的复杂任务时面临的挑战。ATLASS作为一个封闭式框架，允许LLM动态地按需生成外部工具以解决问题。该系统分为三个阶段：理解工具需求、工具检索/生成以及任务解决。通过自动设置环境、在线获取API文档并利用Python解释器创建可靠多样的工具，ATLASS成功解决了当前基于LLM的工具生成系统难以构建需要API或外部包的复杂工具的问题。文章使用OpenAI GPT-4.0作为LLM代理，并通过人类反馈来确保生成代码的安全性和道德性，从而使ATLASS成为一个能够为用户提供动态生成工具以解决复杂问题的实际解决方案，克服了预定义工具集的局限性并增强了适应性。 <div>
arXiv:2503.10071v1 Announce Type: new 
Abstract: The combination of LLM agents with external tools enables models to solve complex tasks beyond their knowledge base. Human-designed tools are inflexible and restricted to solutions within the scope of pre-existing tools created by experts. To address this problem, we propose ATLASS, an advanced tool learning and selection system designed as a closed-loop framework. It enables the LLM to solve problems by dynamically generating external tools on demand. In this framework, agents play a crucial role in orchestrating tool selection, execution, and refinement, ensuring adaptive problem-solving capabilities. The operation of ATLASS follows three phases: The first phase, Understanding Tool Requirements, involves the Agents determining whether tools are required and specifying their functionality; the second phase, Tool Retrieval/Generation, involves the Agents retrieving or generating tools based on their availability; and the third phase, Task Solving, involves combining all the component tools necessary to complete the initial task. The Tool Dataset stores the generated tools, ensuring reusability and minimizing inference cost. Current LLM-based tool generation systems have difficulty creating complex tools that need APIs or external packages. In ATLASS, we solve the problem by automatically setting up the environment, fetching relevant API documentation online, and using a Python interpreter to create a reliable, versatile tool that works in a wider range of situations. OpenAI GPT-4.0 is used as the LLM agent, and safety and ethical concerns are handled through human feedback before executing generated code. By addressing the limitations of predefined toolsets and enhancing adaptability, ATLASS serves as a real-world solution that empowers users with dynamically generated tools for complex problem-solving.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentDAO: Synthesis of Proposal Transactions Via Abstract DAO Semantics</title>
<link>https://arxiv.org/abs/2503.10099</link>
<guid>https://arxiv.org/abs/2503.10099</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化自治组织(DAOs)，低级交易payload，多智能体系统，大型语言模型，DAOLang<br /><br />总结：<br />本文提出了一种针对去中心化自治组织（DAOs）的解决方案，旨在降低治理提案提出的难度。该方案采用了一个由大型语言模型驱动的多智能体系统，配合创新的标签中心检索算法，能够将自然语言输入自动转化为可执行的提案交易。同时，文章介绍了DAOLang这一领域特定语言，它简化了各种治理提案的规范描述，实现了对用户输入的语义感知抽象，从而确保了提案生成的可靠性和较低的代币需求。通过在真实场景中的初步评估，表明DAOLang具有利用现有基础模型（如GPT-4）生成复杂提案类型的能力。 <div>
arXiv:2503.10099v1 Announce Type: new 
Abstract: While the trend of decentralized governance is obvious (cryptocurrencies and blockchains are widely adopted by multiple sovereign countries), initiating governance proposals within Decentralized Autonomous Organizations (DAOs) is still challenging, i.e., it requires providing a low-level transaction payload, therefore posing significant barriers to broad community participation. To address these challenges, we propose a multi-agent system powered by Large Language Models with a novel Label-Centric Retrieval algorithm to automate the translation from natural language inputs into executable proposal transactions. The system incorporates DAOLang, a Domain-Specific Language to simplify the specification of various governance proposals. The key optimization achieved by DAOLang is a semantic-aware abstraction of user input that reliably secures proposal generation with a low level of token demand. A preliminary evaluation on real-world applications reflects the potential of DAOLang in terms of generating complicated types of proposals with existing foundation models, e.g. GPT-4o.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>StepMathAgent: A Step-Wise Agent for Evaluating Mathematical Processes through Tree-of-Error</title>
<link>https://arxiv.org/abs/2503.10105</link>
<guid>https://arxiv.org/abs/2503.10105</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、数学能力评估、StepMathAgent、Tree-of-Error、StepMathBench

总结:<br />
本文提出了一种新的用于评价大型语言模型数学能力的方法——StepMathAgent，该方法基于Tree-of-Error，包含了逻辑步骤分割、步骤评分、分数聚合和错误树生成等四个内部核心操作，以及难度校准、简洁性评估、完整性验证和格式评估等四个外部扩展模块。同时，文章还引入了StepMathBench，这是一个由1000个过程评估实例组成的基准集，源自200道高质量数学问题并按问题类型、学科类别和难度水平分类。实验结果表明，StepMathAgent在StepMathBench上的表现优于现有最佳方法，展现出与人类一致的评价偏好和广泛的适用性。相关数据和代码已在GitHub上开源。 <div>
arXiv:2503.10105v1 Announce Type: new 
Abstract: Evaluating mathematical capabilities is critical for assessing the overall performance of large language models (LLMs). However, existing evaluation methods often focus solely on final answers, resulting in highly inaccurate and uninterpretable evaluation outcomes, as well as their failure to assess proof or open-ended problems. To address these issues, we propose a novel mathematical process evaluation agent based on Tree-of-Error, called StepMathAgent. This agent incorporates four internal core operations: logical step segmentation, step scoring, score aggregation and error tree generation, along with four external extension modules: difficulty calibration, simplicity evaluation, completeness validation and format assessment. Furthermore, we introduce StepMathBench, a benchmark comprising 1,000 step-divided process evaluation instances, derived from 200 high-quality math problems grouped by problem type, subject category and difficulty level. Experiments on StepMathBench show that our proposed StepMathAgent outperforms all state-of-the-art methods, demonstrating human-aligned evaluation preferences and broad applicability to various scenarios. Our data and code are available at https://github.com/SHU-XUN/StepMathAgent.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Agents for Image Restoration</title>
<link>https://arxiv.org/abs/2503.10120</link>
<guid>https://arxiv.org/abs/2503.10120</guid>
<content:encoded><![CDATA[
<div> 关键词: 图像修复、多模式、人工智能交互、快速代理、慢速代理、反馈代理、混合退化移除、统一模型、指令微调、大语言模型、资源效率

<br /><br />总结:

本文提出了一个名为HybridAgent的图像修复方法，旨在通过融合多种修复模式于一个统一模型中，实现更智能和高效的人机交互。该方法包括三个类型的代理：快速修复代理利用轻量级大语言模型通过上下文学习理解简单清晰的用户需求，以节省时间和资源；慢速修复代理则依托于强大的多模态大语言模型与指令微调数据集，能识别具有模糊提示的图像中的退化并调用相应的修复工具；同时引入了混合退化移除模式，有效避免逐步修复过程中的错误传播并提高了系统的效率。实验结果验证了HybridAgent在合成及真实世界图像修复任务上的有效性。 <div>
arXiv:2503.10120v1 Announce Type: new 
Abstract: Existing Image Restoration (IR) studies typically focus on task-specific or universal modes individually, relying on the mode selection of users and lacking the cooperation between multiple task-specific/universal restoration modes. This leads to insufficient interaction for unprofessional users and limits their restoration capability for complicated real-world applications. In this work, we present HybridAgent, intending to incorporate multiple restoration modes into a unified image restoration model and achieve intelligent and efficient user interaction through our proposed hybrid agents. Concretely, we propose the hybrid rule of fast, slow, and feedback restoration agents. Here, the slow restoration agent optimizes the powerful multimodal large language model (MLLM) with our proposed instruction-tuning dataset to identify degradations within images with ambiguous user prompts and invokes proper restoration tools accordingly. The fast restoration agent is designed based on a lightweight large language model (LLM) via in-context learning to understand the user prompts with simple and clear requirements, which can obviate the unnecessary time/resource costs of MLLM. Moreover, we introduce the mixed distortion removal mode for our HybridAgents, which is crucial but not concerned in previous agent-based works. It can effectively prevent the error propagation of step-by-step image restoration and largely improve the efficiency of the agent system. We validate the effectiveness of HybridAgent with both synthetic and real-world IR tasks.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Q-Learning Dynamics in Random Networks: Convergence due to Exploration and Sparsity</title>
<link>https://arxiv.org/abs/2503.10186</link>
<guid>https://arxiv.org/abs/2503.10186</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体学习、Q-learning、网络聚合游戏、随机图模型、收敛性

总结:
本文研究了在基于经典随机图模型（如Erdos-Renyi模型和Stochastic Block模型）的网络聚合游戏中，Q-learning动态行为。文章指出了当代理数量增加时，可能出现复杂非稳态行为的现象，并确立了在这些环境下，代理人联合策略收敛到唯一均衡的充分条件。这些条件涉及探索率、报酬矩阵以及网络的稀疏度。通过数值模拟，作者验证了理论发现并表明，在控制网络稀疏度的情况下，大量代理系统的收敛性可以得到可靠实现。 <div>
arXiv:2503.10186v1 Announce Type: new 
Abstract: Beyond specific settings, many multi-agent learning algorithms fail to converge to an equilibrium solution, and instead display complex, non-stationary behaviours such as recurrent or chaotic orbits. In fact, recent literature suggests that such complex behaviours are likely to occur when the number of agents increases. In this paper, we study Q-learning dynamics in network polymatrix games where the network structure is drawn from classical random graph models. In particular, we focus on the Erdos-Renyi model, a well-studied model for social networks, and the Stochastic Block model, which generalizes the above by accounting for community structures within the network. In each setting, we establish sufficient conditions under which the agents' joint strategies converge to a unique equilibrium. We investigate how this condition depends on the exploration rates, payoff matrices and, crucially, the sparsity of the network. Finally, we validate our theoretical findings through numerical simulations and demonstrate that convergence can be reliably achieved in many-agent systems, provided network sparsity is controlled.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LVAgent: Long Video Understanding by Multi-Round Dynamical Collaboration of MLLM Agents</title>
<link>https://arxiv.org/abs/2503.10200</link>
<guid>https://arxiv.org/abs/2503.10200</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大型语言模型、长期视频理解、LVAgent、动态协作、性能提升

总结:
本文提出了一种新的框架LVAgent，用于解决多模态大型语言模型（MLLM）在处理长视频中的时间上下文建模挑战。现有的主流基于代理的方法依赖外部工具协助单个MLLM回答长视频问题，但效果有限。LVAgent是首个实现多轮动态协作的MLLM代理系统，在长视频理解任务中展现出优越性。该方法包括四个关键步骤：预选择适合任务的模型形成优化的代理团队；设计有效的长视频检索策略以提高重要时间片段的覆盖率并保持计算效率；代理们对长视频相关问题进行回答并交换理由；以及根据每轮讨论的表现优化代理团队，动态调整协作。通过多轮动态协作，LVAgent成功超越了所有已知的封闭源码和开源模型，在四大主流长视频理解任务上取得了高达80%的准确率，并在LongVideoBench数据集上相比现有最优技术提高了最多14.3%的准确性。 <div>
arXiv:2503.10200v1 Announce Type: new 
Abstract: Existing Multimodal Large Language Models (MLLMs) encounter significant challenges in modeling the temporal context within long videos. Currently, mainstream Agent-based methods use external tools (e.g., search engine, memory banks, OCR, retrieval models) to assist a single MLLM in answering long video questions. Despite such tool-based support, a solitary MLLM still offers only a partial understanding of long videos, resulting in limited performance. In order to better address long video tasks, we introduce LVAgent, the first framework enabling multi-round dynamic collaboration of MLLM agents in long video understanding. Our methodology consists of four key steps: 1. Selection: We pre-select appropriate agents from the model library to form optimal agent teams based on different tasks. 2. Perception: We design an effective retrieval scheme for long videos, improving the coverage of critical temporal segments while maintaining computational efficiency. 3. Action: Agents answer long video-related questions and exchange reasons. 4. Reflection: We evaluate the performance of each agent in each round of discussion and optimize the agent team for dynamic collaboration. The agents iteratively refine their answers by multi-round dynamical collaboration of MLLM agents. LVAgent is the first agent system method that outperforms all closed-source models (including GPT-4o) and open-source models (including InternVL-2.5 and Qwen2-VL) in the long video understanding tasks. Our LVAgent achieves an accuracy of 80% on four mainstream long video understanding tasks. Notably, on the LongVideoBench dataset, LVAgent improves accuracy by up to 14.3% compared with SOTA.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Global synchronization of multi-agent systems with nonlinear interactions</title>
<link>https://arxiv.org/abs/2503.10205</link>
<guid>https://arxiv.org/abs/2503.10205</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、连续时间动力学、单调连续信号函数、同步均衡、网络拓扑

总结:
本文研究了通过一种广泛的一般类别的单调连续信号函数交互的多智能体系统的同步问题，这类函数涵盖了估计偏差、离散量化近似以及状态依赖估计。文章分析指出，在所考虑的设置下，同步平衡点恰好是信号函数的固定点。此外，文中还提出了基于信号函数在这些固定点附近对代理状态低估或高估的直观稳定性条件。进一步地，证明了网络拓扑在网络同步中的关键作用。这些结果为通信非线性和网络连通性的相互作用提供了有趣的见解，为复杂系统中的高级协调策略铺平了道路。<br /><br /> <div>
arXiv:2503.10205v1 Announce Type: new 
Abstract: The paper addresses the synchronization of multi-agent systems with continuous-time dynamics interacting through a very general class of monotonic continuous signal functions that covers estimation biases, approximation of discrete quantization, or state-dependent estimation. Our analysis reveals that, in the setup under consideration, synchronization equilibria are exactly the fixed points of the signal function. We also derive intuitive stability conditions based on whether the signal underestimates or overestimates the state of the agents around these fixed points. Moreover, we show that network topology plays a crucial role in asymptotic synchronization. These results provide interesting insights into the interplay between communication nonlinearity and network connectivity, paving the way for advanced coordination strategies in complex systems.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SCOOP: A Framework for Proactive Collaboration and Social Continual Learning through Natural Language Interaction andCausal Reasoning</title>
<link>https://arxiv.org/abs/2503.10241</link>
<guid>https://arxiv.org/abs/2503.10241</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态信息收集、人工智能协作、因果知识获取、连续学习框架、对话交互

总结:
本文提出了一种社会连续学习框架，用于因果知识获取和协作决策制定，特别关注在开放、部分可观测环境中的自主智能体通过对话、提问和互动进行学习。该框架利用自然语言oracle回答智能体关于环境机制和状态的问题，以平衡探索与学习以及利用已有知识。评价任务强调因果推理和问题询问能力，评估智能体识别知识空白、生成有意义问题及逐步更新推理的能力，并考察知识获取成本在相同环境中各任务间的摊销。文章提出了两种架构：一是结合大型语言模型（LLMs）和ReAct框架以及问题生成的系统；二是采用因果世界模型（包括符号型、图基或次符号型）进行推理和决策的高级系统，后者构建因果知识图以便于高效推理和约束条件下的适应性。挑战包括将因果推理融入ReAct以及在存在错误的情况下优化探索和提问。此框架不仅应用于实践，还模拟了结合因果推理、问题生成和社会学习的发展过程。 <div>
arXiv:2503.10241v1 Announce Type: new 
Abstract: Multimodal information-gathering settings, where users collaborate with AI in dynamic environments, are increasingly common. These involve complex processes with textual and multimodal interactions, often requiring additional structural information via cost-incurring requests. AI helpers lack access to users' true goals, beliefs, and preferences and struggle to integrate diverse information effectively.
  We propose a social continual learning framework for causal knowledge acquisition and collaborative decision-making. It focuses on autonomous agents learning through dialogues, question-asking, and interaction in open, partially observable environments. A key component is a natural language oracle that answers the agent's queries about environmental mechanisms and states, refining causal understanding while balancing exploration or learning, and exploitation or knowledge use.
  Evaluation tasks inspired by developmental psychology emphasize causal reasoning and question-asking skills. They complement benchmarks by assessing the agent's ability to identify knowledge gaps, generate meaningful queries, and incrementally update reasoning. The framework also evaluates how knowledge acquisition costs are amortized across tasks within the same environment.
  We propose two architectures: 1) a system combining Large Language Models (LLMs) with the ReAct framework and question-generation, and 2) an advanced system with a causal world model, symbolic, graph-based, or subsymbolic, for reasoning and decision-making. The latter builds a causal knowledge graph for efficient inference and adaptability under constraints. Challenges include integrating causal reasoning into ReAct and optimizing exploration and question-asking in error-prone scenarios. Beyond applications, this framework models developmental processes combining causal reasoning, question generation, and social learning.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reach-Avoid-Stay-Collision-Avoidance Negotiation Framework for Multi-Agent Systems via Spatiotemporal Tubes</title>
<link>https://arxiv.org/abs/2503.10245</link>
<guid>https://arxiv.org/abs/2503.10245</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体谈判、碰撞避免、预设时间到达-避免-保持任务、时空管、分布式控制

<br />
总结:
本文提出了一种基于多智能体谈判的框架，用于在执行预设时间到达-避免-保持(RAS)任务的同时获取碰撞避免路径。该框架利用时空管生成随时间变化的状态约束，确保具有未知动力学和有限干扰的智能体能够遵循RAS规范并采用综合控制器实现。为防止智能体间的碰撞，文中提出了一种谈判机制，成功谈判后，每个智能体会得到满足所需任务的时空管。这种方法导致了每个智能体完全分布式的、无需近似计算的控制律。通过涉及预设时间RAS规范和碰撞避免的多机器人导航与无人机导航任务的模拟验证了该机制的有效性。 <div>
arXiv:2503.10245v1 Announce Type: new 
Abstract: This study presents a multi-agent negotiation-based framework to obtain collision-free paths while performing prescribed-time reach-avoid-stay (RAS) tasks for agents with unknown dynamics and bounded disturbance. By employing spatiotemporal tubes to generate time-varying state constraints, we ensure that all agents adhere to RAS specifications using synthesized controllers. To prevent inter-agent collisions, a negotiation mechanism is proposed where successful negotiations result in spatiotemporal tubes for each agent fulfilling desired tasks. This approach results in a completely distributed, approximation-free control law for each agent. The effectiveness of this mechanism was validated through simulations of multi-agent robot navigation and drone navigation tasks involving prescribed-time RAS specifications and collision avoidance.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SurgRAW: Multi-Agent Workflow with Chain-of-Thought Reasoning for Surgical Intelligence</title>
<link>https://arxiv.org/abs/2503.10265</link>
<guid>https://arxiv.org/abs/2503.10265</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型(VLMs), 手术智能, 链接思维(Chain-of-Thought, CoT), SurgRAW, SurgCoTBench

<br /><br />总结:
本文提出了一种名为SurgRAW的基于链接思维的多代理框架，旨在解决视觉语言模型在手术智能应用中出现的幻觉、领域知识空白和任务关联性理解不足的问题。SurgRAW利用专门设计的CoT提示进行结构化、领域感知的推理，通过整合检索增强生成（RAG）以填补医学领域的知识缺口并提高响应可靠性。此外，该框架采用层次化的代理系统确保嵌入了CoT的VLM代理能够有效地协同工作并理解任务间的依赖关系，还引入了一个面板讨论机制以促进逻辑一致性。为评估SurgRAW方法的有效性，文章构建了首个具有结构化帧级注解的推理基准数据集SurgCoTBench。实验结果显示，SurgRAW在12项机器人手术任务上相比基线VLMs实现了29.32%的准确性提升，达到了最先进的性能，并促进了可解释性、可信度以及自主性的手术辅助发展。 <div>
arXiv:2503.10265v1 Announce Type: new 
Abstract: Integration of Vision-Language Models (VLMs) in surgical intelligence is hindered by hallucinations, domain knowledge gaps, and limited understanding of task interdependencies within surgical scenes, undermining clinical reliability. While recent VLMs demonstrate strong general reasoning and thinking capabilities, they still lack the domain expertise and task-awareness required for precise surgical scene interpretation. Although Chain-of-Thought (CoT) can structure reasoning more effectively, current approaches rely on self-generated CoT steps, which often exacerbate inherent domain gaps and hallucinations. To overcome this, we present SurgRAW, a CoT-driven multi-agent framework that delivers transparent, interpretable insights for most tasks in robotic-assisted surgery. By employing specialized CoT prompts across five tasks: instrument recognition, action recognition, action prediction, patient data extraction, and outcome assessment, SurgRAW mitigates hallucinations through structured, domain-aware reasoning. Retrieval-Augmented Generation (RAG) is also integrated to external medical knowledge to bridge domain gaps and improve response reliability. Most importantly, a hierarchical agentic system ensures that CoT-embedded VLM agents collaborate effectively while understanding task interdependencies, with a panel discussion mechanism promotes logical consistency. To evaluate our method, we introduce SurgCoTBench, the first reasoning-based dataset with structured frame-level annotations. With comprehensive experiments, we demonstrate the effectiveness of proposed SurgRAW with 29.32% accuracy improvement over baseline VLMs on 12 robotic procedures, achieving the state-of-the-art performance and advancing explainable, trustworthy, and autonomous surgical assistance.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Capturing Semantic Flow of ML-based Systems</title>
<link>https://arxiv.org/abs/2503.10310</link>
<guid>https://arxiv.org/abs/2503.10310</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习系统、深度神经网络、大型语言模型、语义流、动态分析

总结:
本文提出了“语义流”这一概念，用于描述和分析基于机器学习（如深度神经网络DNN和大型语言模型LLM）系统的内部行为。现有的动态分析技术主要关注系统的外部可观察特征，而语义流则结合了控制流与ML系统执行过程中的内部状态（例如DNN中特定层的激活值或LLM代理在特定推理步骤的嵌入响应）。由此生成的语义流图能够捕捉到传统控制流中未明确表示的内部决策。文章介绍了语义流的概念，给出了使用DNN和LLM代理的两个示例，并探讨了其性质以及如何利用语义流将现有动态分析技术应用于ML软件系统。 <div>
arXiv:2503.10310v1 Announce Type: new 
Abstract: ML-based systems are software systems that incorporates machine learning components such as Deep Neural Networks (DNNs) or Large Language Models (LLMs). While such systems enable advanced features such as high performance computer vision, natural language processing, and code generation, their internal behaviour remain largely opaque to traditional dynamic analysis such as testing: existing analysis typically concern only what is observable from the outside, such as input similarity or class label changes. We propose semantic flow, a concept designed to capture the internal behaviour of ML-based system and to provide a platform for traditional dynamic analysis techniques to be adapted to. Semantic flow combines the idea of control flow with internal states taken from executions of ML-based systems, such as activation values of a specific layer in a DNN, or embeddings of LLM responses at a specific inference step of LLM agents. The resulting representation, summarised as semantic flow graphs, can capture internal decisions that are not explicitly represented in the traditional control flow of ML-based systems. We propose the idea of semantic flow, introduce two examples using a DNN and an LLM agent, and finally sketch its properties and how it can be used to adapt existing dynamic analysis techniques for use in ML-based software systems.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhance Exploration in Safe Reinforcement Learning with Contrastive Representation Learning</title>
<link>https://arxiv.org/abs/2503.10318</link>
<guid>https://arxiv.org/abs/2503.10318</guid>
<content:encoded><![CDATA[
<div> 关键词：安全强化学习、领域转移、探索行为、安全性约束、MiniGrid环境

总结:
在安全强化学习中，本文关注于如何在稀疏奖励环境中平衡探索行为与安全性约束。为解决相关环境下由于大量误报导致的安全动作执行不足问题，文章提出了一种方法，该方法首先使用自编码器将图像输入映射到潜在表示，然后采用对比学习目标来区分安全和不安全的状态。在学习阶段，利用潜在空间的距离构建额外的安全检查机制，使智能体在访问不安全状态时能有倾向性地进行探索。为了验证方法的有效性，实验在三个基于导航的MiniGrid环境中展开。结果表明，本文的方法可以在保证安全性和效率良好平衡的同时更好地探索环境。 <div>
arXiv:2503.10318v1 Announce Type: new 
Abstract: In safe reinforcement learning, agent needs to balance between exploration actions and safety constraints. Following this paradigm, domain transfer approaches learn a prior Q-function from the related environments to prevent unsafe actions. However, because of the large number of false positives, some safe actions are never executed, leading to inadequate exploration in sparse-reward environments. In this work, we aim to learn an efficient state representation to balance the exploration and safety-prefer action in a sparse-reward environment. Firstly, the image input is mapped to latent representation by an auto-encoder. A further contrastive learning objective is employed to distinguish safe and unsafe states. In the learning phase, the latent distance is used to construct an additional safety check, which allows the agent to bias the exploration if it visits an unsafe state. To verify the effectiveness of our method, the experiment is carried out in three navigation-based MiniGrid environments. The result highlights that our method can explore the environment better while maintaining a good balance between safety and efficiency.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HALO: Fault-Tolerant Safety Architecture For High-Speed Autonomous Racing</title>
<link>https://arxiv.org/abs/2503.10341</link>
<guid>https://arxiv.org/abs/2503.10341</guid>
<content:encoded><![CDATA[
<div> 关键词: 高速自主赛车、HALO安全架构、故障模式分析、运行时监控、 Indy Autonomous Challenge

<br /><br />总结:
本文介绍了应用于全尺寸自动驾驶赛车上的HALO安全架构，该架构是在Indy Autonomous Challenge竞赛中实施的。文章首先对感知、规划、控制和通信模块进行了失效模式与关键性分析，重点关注了节点健康、数据健康和行为安全性三种类型的故障。接着，文中详细阐述了HALO安全架构中的防护机制和运行时监测方法。最后，通过实际收集到的多智能体场景下自动驾驶赛车试验数据，验证了HALO安全架构针对各类故障的有效性。 <div>
arXiv:2503.10341v1 Announce Type: new 
Abstract: The field of high-speed autonomous racing has seen significant advances in recent years, with the rise of competitions such as RoboRace and the Indy Autonomous Challenge providing a platform for researchers to develop software stacks for autonomous race vehicles capable of reaching speeds in excess of 170 mph. Ensuring the safety of these vehicles requires the software to continuously monitor for different faults and erroneous operating conditions during high-speed operation, with the goal of mitigating any unreasonable risks posed by malfunctions in sub-systems and components. This paper presents a comprehensive overview of the HALO safety architecture, which has been implemented on a full-scale autonomous racing vehicle as part of the Indy Autonomous Challenge. The paper begins with a failure mode and criticality analysis of the perception, planning, control, and communication modules of the software stack. Specifically, we examine three different types of faults - node health, data health, and behavioral-safety faults. To mitigate these faults, the paper then outlines HALO safety archetypes and runtime monitoring methods. Finally, the paper demonstrates the effectiveness of the HALO safety architecture for each of the faults, through real-world data gathered from autonomous racing vehicle trials during multi-agent scenarios.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>New Trends for Modern Machine Translation with Large Reasoning Models</title>
<link>https://arxiv.org/abs/2503.10351</link>
<guid>https://arxiv.org/abs/2503.10351</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Reasoning Models (LRMs)，Chain-of-Thought (CoT)，Machine Translation (MT)，contextual coherence，cultural intentionality，self-reflection，stylistic translation，document-level translation，multimodal translation，auto-pivot translation，over-localisation，inference efficiency，multilingual cognitive agents

<br /><br />总结:
本文提出了一种观点，认为大型推理模型（LRMs），特别是利用Chain-of-Thought推理（CoT）技术的进步，已经极大地改变了机器翻译（MT）领域。文章指出了三个基础转变：1) 上下文连贯性，LRMs通过显式地对跨句和复杂上下文甚至缺乏上下文进行推理，解决了歧义并保持了语篇结构；2) 文化意向性，使模型能够根据说话者的意图、受众期望和社会语言规范来调整输出内容；3) 自我反思，LRMs在推断阶段能自我反省以修正翻译中的潜在错误，特别是在极其嘈杂的情况下展现出更好的鲁棒性。文中探讨了包括风格化翻译、文档级翻译和多模态翻译等多种翻译场景，并通过实例证明了LRMs在翻译方面的优越性。同时，也指出了LRMs在MT中的一些有趣现象，如自动中间翻译以及面临的挑战，如过度本地化翻译和推理效率问题。最后，文章认为LRMs重新定义了翻译系统，将其不仅仅视为文本转换器，而是能够超越文本进行意义推理的多语言认知代理。这一范式的转变提示我们，在更广泛的背景下思考翻译问题，利用LRMs的可能性。 <div>
arXiv:2503.10351v1 Announce Type: new 
Abstract: Recent advances in Large Reasoning Models (LRMs), particularly those leveraging Chain-of-Thought reasoning (CoT), have opened brand new possibility for Machine Translation (MT). This position paper argues that LRMs substantially transformed traditional neural MT as well as LLMs-based MT paradigms by reframing translation as a dynamic reasoning task that requires contextual, cultural, and linguistic understanding and reasoning. We identify three foundational shifts: 1) contextual coherence, where LRMs resolve ambiguities and preserve discourse structure through explicit reasoning over cross-sentence and complex context or even lack of context; 2) cultural intentionality, enabling models to adapt outputs by inferring speaker intent, audience expectations, and socio-linguistic norms; 3) self-reflection, LRMs can perform self-reflection during the inference time to correct the potential errors in translation especially extremely noisy cases, showing better robustness compared to simply mapping X->Y translation. We explore various scenarios in translation including stylized translation, document-level translation and multimodal translation by showcasing empirical examples that demonstrate the superiority of LRMs in translation. We also identify several interesting phenomenons for LRMs for MT including auto-pivot translation as well as the critical challenges such as over-localisation in translation and inference efficiency. In conclusion, we think that LRMs redefine translation systems not merely as text converters but as multilingual cognitive agents capable of reasoning about meaning beyond the text. This paradigm shift reminds us to think of problems in translation beyond traditional translation scenarios in a much broader context with LRMs - what we can achieve on top of it.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Compliant Control of Quadruped Robots for Assistive Load Carrying</title>
<link>https://arxiv.org/abs/2503.10401</link>
<guid>https://arxiv.org/abs/2503.10401</guid>
<content:encoded><![CDATA[
<div> 关键词：quadruped robots、assistive load carrying、proprioceptive sensors、Control Barrier Function (CBF)、collision avoidance

总结:
<br />
本文提出了一种使用四足机器人进行辅助负重携带的新方法。该控制器利用本体感觉传感器数据来估计外部基座力矩，以此实现负载运输过程中机器人加速度的精确控制。通过结合顺应控制和基于控制 Barrier 函数（CBF）的二次规划（QP）对加速度进行控制，使控制器能够抵消干扰并在不同载荷条件下保持稳定性能。同时，内置的 CBF 保证了机器人与前方协作代理之间的碰撞避免。通过对实际硬件及数值模拟的实施效果验证了整个控制器的有效性。这项提出的控制框架旨在提升四足机器人在各种场景中执行辅助任务的能力，包括工业应用以及搜救行动。 <div>
arXiv:2503.10401v1 Announce Type: new 
Abstract: This paper presents a novel method for assistive load carrying using quadruped robots. The controller uses proprioceptive sensor data to estimate external base wrench, that is used for precise control of the robot's acceleration during payload transport. The acceleration is controlled using a combination of admittance control and Control Barrier Function (CBF) based quadratic program (QP). The proposed controller rejects disturbances and maintains consistent performance under varying load conditions. Additionally, the built-in CBF guarantees collision avoidance with the collaborative agent in front of the robot. The efficacy of the overall controller is shown by its implementation on the physical hardware as well as numerical simulations. The proposed control framework aims to enhance the quadruped robot's ability to perform assistive tasks in various scenarios, from industrial applications to search and rescue operations.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SortingEnv: An Extendable RL-Environment for an Industrial Sorting Process</title>
<link>https://arxiv.org/abs/2503.10466</link>
<guid>https://arxiv.org/abs/2503.10466</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习(RL)，工业排序系统，数字孪生，Proximal Policy Optimization (PPO)，Deep-Q-Networks (DQN)，Advantage Actor Critic (A2C)

总结:<br />
本文提出了一种新颖的强化学习环境，旨在优化工业分类系统并研究在变化环境中智能体的行为。该环境模拟了工业分类过程中的物料流动，遵循数字孪生的理念，考虑了如皮带速度和占用率等操作参数。为了反映现实世界挑战，文中整合了如新型传感器或先进设备等常见的工业升级选项，从而提供了基础版和高级版两种版本。文章详细描述了两个环境的观察空间、状态更新机制及奖励函数。此外，通过比较经典规则基代理（RBA）与PPO、DQN和A2C等常见RL算法的效率，评估了这些算法在本环境中的表现。这一框架不仅有助于优化工业流程，也为研究智能体行为以及在演化环境中的可转移性提供了基础，为进一步了解模型性能及其在实际RL应用中的实践意义提供了见解。 <div>
arXiv:2503.10466v1 Announce Type: new 
Abstract: We present a novel reinforcement learning (RL) environment designed to both optimize industrial sorting systems and study agent behavior in evolving spaces. In simulating material flow within a sorting process our environment follows the idea of a digital twin, with operational parameters like belt speed and occupancy level. To reflect real-world challenges, we integrate common upgrades to industrial setups, like new sensors or advanced machinery. It thus includes two variants: a basic version focusing on discrete belt speed adjustments and an advanced version introducing multiple sorting modes and enhanced material composition observations. We detail the observation spaces, state update mechanisms, and reward functions for both environments. We further evaluate the efficiency of common RL algorithms like Proximal Policy Optimization (PPO), Deep-Q-Networks (DQN), and Advantage Actor Critic (A2C) in comparison to a classical rule-based agent (RBA). This framework not only aids in optimizing industrial processes but also provides a foundation for studying agent behavior and transferability in evolving environments, offering insights into model performance and practical implications for real-world RL applications.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SySLLM: Generating Synthesized Policy Summaries for Reinforcement Learning Agents Using Large Language Models</title>
<link>https://arxiv.org/abs/2503.10509</link>
<guid>https://arxiv.org/abs/2503.10509</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning (强化学习)，Policies，Global policy summarization，SySLLM，Large Language Models (LLMs)

总结:
本文提出了一种名为SySLLM的新方法，用于解决通过强化学习生成的策略难以向用户描述的问题。现有的全球政策汇总方法依赖于用户对有限的行动示范进行解释，而SySLLM则利用大型语言模型（LLMs）的世界知识和模式捕捉能力，生成策略的文本摘要。研究显示，SySLLM生成的摘要能够捕获专家的主要见解且产生的幻觉不显著。此外，用户研究表明，相比于基于演示的策略摘要，用户更倾向于使用SySLLM摘要，并且在客观的代理识别任务中表现与之匹配或超越。 <div>
arXiv:2503.10509v1 Announce Type: new 
Abstract: Policies generated by Reinforcement Learning (RL) algorithms can be difficult to describe to users, as they result from the interplay between complex reward structures and neural network-based representations. This combination often leads to unpredictable behaviors, making policies challenging to analyze and posing significant obstacles to fostering human trust in real-world applications. Global policy summarization methods aim to describe agent behavior through a demonstration of actions in a subset of world-states. However, users can only watch a limited number of demonstrations, restricting their understanding of policies. Moreover, those methods overly rely on user interpretation, as they do not synthesize observations into coherent patterns. In this work, we present SySLLM (Synthesized Summary using LLMs), a novel method that employs synthesis summarization, utilizing large language models' (LLMs) extensive world knowledge and ability to capture patterns, to generate textual summaries of policies. Specifically, an expert evaluation demonstrates that the proposed approach generates summaries that capture the main insights generated by experts while not resulting in significant hallucinations. Additionally, a user study shows that SySLLM summaries are preferred over demonstration-based policy summaries and match or surpass their performance in objective agent identification tasks.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair allocations with subadditive and XOS valuations</title>
<link>https://arxiv.org/abs/2503.10513</link>
<guid>https://arxiv.org/abs/2503.10513</guid>
<content:encoded><![CDATA[
<div> 关键词：公平分配、不可分割物品、子可加性估值、XOS估值、任意权益

总结:

本文研究了具有子可加性或XOS估值的$n$个代理对$m$件不可分割物品的公平分配问题，考虑了任意权益场景下的任何价格份额（APS） ex-post 公平性和最大期望份额（MES） ex-ante 公平性。文章指出存在一种随机分配方案，在子可加性场景下 ex-ante 至少达到$\frac{1}{2}$-MES，而在XOS场景下能达到$(1-\frac{1}{e})$-MES。关于 ex-post 保证，文中展示了在子可加性场景下存在接近$(1 - o(1))\frac{\log\log m}{\log m}$-APS 的分配方案，以及在XOS场景下有$\frac{1}{6}$-APS 分配方案。当权益相等时，对于XOS估值情况，提出了$\frac{4}{17}$-APS 分配方案。这些成果是针对任意权益场景下子可加性和XOS估值的第一个研究成果，并且改进了先前在平等权益场景下的最优结果。<br /><br /> <div>
arXiv:2503.10513v1 Announce Type: new 
Abstract: We consider the problem of fair allocation of $m$ indivisible goods to $n$ agents with either subadditive or XOS valuations, in the arbitrary entitlement case. As fairness notions, we consider the anyprice share (APS) ex-post, and the maximum expectation share (MES) ex-ante.
  We observe that there are randomized allocations that ex-ante are at least $\frac{1}{2}$-MES in the subadditive case and $(1-\frac{1}{e})$-MES in the XOS case. Our more difficult results concern ex-post guarantees. We show that $(1 - o(1))\frac{\log\log m}{\log m}$-APS allocations exist in the subadditive case, and $\frac{1}{6}$-APS allocations exist in the XOS case. For the special case of equal entitlements, we show $\frac{4}{17}$-APS allocations for XOS.
  Our results are the first for subadditive and XOS valuations in the arbitrary entitlement case, and also improve over the previous best results for the equal entitlement case.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GroundingSuite: Measuring Complex Multi-Granular Pixel Grounding</title>
<link>https://arxiv.org/abs/2503.10596</link>
<guid>https://arxiv.org/abs/2503.10596</guid>
<content:encoded><![CDATA[
<div> 关键词: Pixel grounding、Referring Expression Segmentation、GroundingSuite、数据注释框架、大规模训练数据集

总结:
本文介绍了针对像素定位（Pixel grounding）领域中的挑战，如Referring Expression Segmentation任务所面临的数据局限性问题，提出了一种名为GroundingSuite的新解决方案。GroundingSuite包括：1) 采用多个Vision-Language Model (VLM) 代理构建的自动化数据注释框架；2) 包含956万条多样化的指代表达及其对应分割的大规模训练数据集；3) 经精心策划的包含3,800张图像的评估基准。使用GroundingSuite训练数据集训练的模型在gRefCOCO上实现了cIoU为68.9，在RefCOCOm上实现了gIoU为55.3的最新结果。此外，GroundingSuite的数据注释框架相比于当前领先的数据注释方法（GLaMM），显示出了更高的效率，速度快了约4.5倍。 <div>
arXiv:2503.10596v1 Announce Type: new 
Abstract: Pixel grounding, encompassing tasks such as Referring Expression Segmentation (RES), has garnered considerable attention due to its immense potential for bridging the gap between vision and language modalities. However, advancements in this domain are currently constrained by limitations inherent in existing datasets, including limited object categories, insufficient textual diversity, and a scarcity of high-quality annotations. To mitigate these limitations, we introduce GroundingSuite, which comprises: (1) an automated data annotation framework leveraging multiple Vision-Language Model (VLM) agents; (2) a large-scale training dataset encompassing 9.56 million diverse referring expressions and their corresponding segmentations; and (3) a meticulously curated evaluation benchmark consisting of 3,800 images. The GroundingSuite training dataset facilitates substantial performance improvements, enabling models trained on it to achieve state-of-the-art results. Specifically, a cIoU of 68.9 on gRefCOCO and a gIoU of 55.3 on RefCOCOm. Moreover, the GroundingSuite annotation framework demonstrates superior efficiency compared to the current leading data annotation method, i.e., $4.5 \times$ faster than the GLaMM.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoSTA$\ast$: Cost-Sensitive Toolpath Agent for Multi-turn Image Editing</title>
<link>https://arxiv.org/abs/2503.10613</link>
<guid>https://arxiv.org/abs/2503.10613</guid>
<content:encoded><![CDATA[
<div> 关键词: 文本到图像模型、多步图像编辑、AI工具、协同搜索算法（CoSTA*）、大语言模型（LLM）、图搜索、A*搜索、成本效率、质量评估、视觉语言模型（VLM）、自动模态切换、多步图像编辑基准

总结:<br />
该文提出了一个名为CoSTA*的新方法，旨在解决文本到图像模型在多步图像编辑任务中的挑战。CoSTA*通过将任务分解为一系列子任务并利用大型语言模型创建子任务树，进而指导对相关AI工具图的缩小范围搜索。采用A*搜索在小规模子图上寻找成本效益高的工具执行路径。同时，结合每个工具在每个子任务上的质量和成本指标来引导搜索过程。CoSTA*还使用视觉语言模型对每个子任务的输出进行评估，当出现失败时，能够快速更新工具的成本和质量信息，从而迅速调整搜索方向。此外，CoSTA*可以根据不同子任务的需求自动在不同模态间切换以实现更好的成本与质量权衡。文中构建了一个针对复杂多步图像编辑的新型基准测试平台，在这个平台上，CoSTA*在成本和质量方面均超越了现有的图像编辑模型或代理，并能根据用户偏好做出灵活的质量与成本折衷。 <div>
arXiv:2503.10613v1 Announce Type: new 
Abstract: Text-to-image models like stable diffusion and DALLE-3 still struggle with multi-turn image editing. We decompose such a task as an agentic workflow (path) of tool use that addresses a sequence of subtasks by AI tools of varying costs. Conventional search algorithms require expensive exploration to find tool paths. While large language models (LLMs) possess prior knowledge of subtask planning, they may lack accurate estimations of capabilities and costs of tools to determine which to apply in each subtask. Can we combine the strengths of both LLMs and graph search to find cost-efficient tool paths? We propose a three-stage approach "CoSTA*" that leverages LLMs to create a subtask tree, which helps prune a graph of AI tools for the given task, and then conducts A* search on the small subgraph to find a tool path. To better balance the total cost and quality, CoSTA* combines both metrics of each tool on every subtask to guide the A* search. Each subtask's output is then evaluated by a vision-language model (VLM), where a failure will trigger an update of the tool's cost and quality on the subtask. Hence, the A* search can recover from failures quickly to explore other paths. Moreover, CoSTA* can automatically switch between modalities across subtasks for a better cost-quality trade-off. We build a novel benchmark of challenging multi-turn image editing, on which CoSTA* outperforms state-of-the-art image-editing models or agents in terms of both cost and quality, and performs versatile trade-offs upon user preference.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Uncertainty in Action: Confidence Elicitation in Embodied Agents</title>
<link>https://arxiv.org/abs/2503.10628</link>
<guid>https://arxiv.org/abs/2503.10628</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied agents, multimodal environments, confidence elicitation, Elicitation Policies, Execution Policies

<br /><br />总结:
本文首次研究了在动态多模态环境中，具有实体存在的智能体如何进行信心表达。作者提出了Elicitation Policies和Execution Policies，前者结构化地评估归纳、演绎和推理的信心，后者通过场景重新解释、动作采样和假设性推理来增强信心校准。在Minecraft环境中的实验表明，如Chain-of-Thoughts等结构化推理方法可以改进信心校准。然而，研究也发现，在 abduction 设置下区分不确定性仍存在持续挑战，强调需要更复杂的身体感知信心诱发方法。 <div>
arXiv:2503.10628v1 Announce Type: new 
Abstract: Expressing confidence is challenging for embodied agents navigating dynamic multimodal environments, where uncertainty arises from both perception and decision-making processes. We present the first work investigating embodied confidence elicitation in open-ended multimodal environments. We introduce Elicitation Policies, which structure confidence assessment across inductive, deductive, and abductive reasoning, along with Execution Policies, which enhance confidence calibration through scenario reinterpretation, action sampling, and hypothetical reasoning. Evaluating agents in calibration and failure prediction tasks within the Minecraft environment, we show that structured reasoning approaches, such as Chain-of-Thoughts, improve confidence calibration. However, our findings also reveal persistent challenges in distinguishing uncertainty, particularly under abductive settings, underscoring the need for more sophisticated embodied confidence elicitation methods.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>UniGoal: Towards Universal Zero-shot Goal-oriented Navigation</title>
<link>https://arxiv.org/abs/2503.10630</link>
<guid>https://arxiv.org/abs/2503.10630</guid>
<content:encoded><![CDATA[
<div> 关键词：通用零样本目标导向导航、统一图表示、大型语言模型、图匹配、UniGoal

总结:<br />
本文提出了一种通用零样本目标导向导航的框架——UniGoal。该框架旨在通过统一不同目标（包括物体类别、实例图像和文本描述）的图表示形式，并将智能体的观察结果转化为在线维护的场景图，从而实现泛化能力的提升。利用大型语言模型进行基于图的显式推理，文章提出了在每个时间步进行场景图与目标图的图匹配策略，并根据不同的匹配状态生成长期探索目标。具体地，当目标图与场景图零匹配时，智能体迭代搜索子图；部分匹配时，则采用坐标投影和锚点对齐来推断目标位置；最后通过场景图校正和目标验证实现完美匹配。此外，文中还设计了黑名单机制以确保阶段间的稳健切换。实验结果显示，UniGoal 在多个基准测试数据集上的零样本性能优于针对特定任务的零样本方法以及监督学习的通用方法，且只需单一模型即可在三个研究的导航任务中取得最优效果。 <div>
arXiv:2503.10630v1 Announce Type: new 
Abstract: In this paper, we propose a general framework for universal zero-shot goal-oriented navigation. Existing zero-shot methods build inference framework upon large language models (LLM) for specific tasks, which differs a lot in overall pipeline and fails to generalize across different types of goal. Towards the aim of universal zero-shot navigation, we propose a uniform graph representation to unify different goals, including object category, instance image and text description. We also convert the observation of agent into an online maintained scene graph. With this consistent scene and goal representation, we preserve most structural information compared with pure text and are able to leverage LLM for explicit graph-based reasoning. Specifically, we conduct graph matching between the scene graph and goal graph at each time instant and propose different strategies to generate long-term goal of exploration according to different matching states. The agent first iteratively searches subgraph of goal when zero-matched. With partial matching, the agent then utilizes coordinate projection and anchor pair alignment to infer the goal location. Finally scene graph correction and goal verification are applied for perfect matching. We also present a blacklist mechanism to enable robust switch between stages. Extensive experiments on several benchmarks show that our UniGoal achieves state-of-the-art zero-shot performance on three studied navigation tasks with a single model, even outperforming task-specific zero-shot methods and supervised universal methods.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Building Cooperative Embodied Agents Modularly with Large Language Models</title>
<link>https://arxiv.org/abs/2307.02485</link>
<guid>https://arxiv.org/abs/2307.02485</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体合作、分散控制、大规模语言模型、沟通成本、认知启发式框架

<br /><br />总结:
本文提出了一个名为CoELA的合作型具身语言智能体，旨在解决具有分散控制、原始感官输入、高昂通信成本和多目标任务的复杂多智能体合作问题。与先前假设无成本通信通道或依赖集中式控制器的研究不同，该工作利用大规模语言模型（如GPT-4）的常识知识、推理能力、语言理解和生成能力，将其无缝整合进一个认知启发式的模块化框架中，该框架结合了感知、记忆和执行功能。实验显示，由GPT-4驱动的CoELA在C-WAH和TDW-MAT环境中超越了基于规划的方法并展现出有效的 Emergent 通信。尽管当前的开放领域大模型如LLAMA-2仍表现欠佳，但通过使用自代理收集的数据对CoELA进行微调后，其性能得到提升。此外，用户研究表明，使用自然语言交流的CoELA能赢得更多人类用户的信任并与其更有效地合作。这项研究强调了大规模语言模型在未来多智能体合作研究中的潜力，并提供了项目网站上的视频资料以供参考。 <div>
arXiv:2307.02485v2 Announce Type: cross 
Abstract: In this work, we address challenging multi-agent cooperation problems with decentralized control, raw sensory observations, costly communication, and multi-objective tasks instantiated in various embodied environments. While previous research either presupposes a cost-free communication channel or relies on a centralized controller with shared observations, we harness the commonsense knowledge, reasoning ability, language comprehension, and text generation prowess of LLMs and seamlessly incorporate them into a cognitive-inspired modular framework that integrates with perception, memory, and execution. Thus building a Cooperative Embodied Language Agent CoELA, who can plan, communicate, and cooperate with others to accomplish long-horizon tasks efficiently. Our experiments on C-WAH and TDW-MAT demonstrate that CoELA driven by GPT-4 can surpass strong planning-based methods and exhibit emergent effective communication. Though current Open LMs like LLAMA-2 still underperform, we fine-tune a CoELA with data collected with our agents and show how they can achieve promising performance. We also conducted a user study for human-agent interaction and discovered that CoELA communicating in natural language can earn more trust and cooperate more effectively with humans. Our research underscores the potential of LLMs for future research in multi-agent cooperation. Videos can be found on the project website https://vis-www.cs.umass.edu/Co-LLM-Agents/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RILe: Reinforced Imitation Learning</title>
<link>https://arxiv.org/abs/2406.08472</link>
<guid>https://arxiv.org/abs/2406.08472</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 逆强化学习, 模仿学习, 高维环境, RILe

总结:<br />
本文提出了一种名为RILe的新框架，旨在解决人工智能代理在高维环境中学习复杂行为的挑战。传统的强化学习依赖于手动设计奖励函数，而逆强化学习虽然能从专家演示中推断奖励函数，但过程计算成本较高。模仿学习虽高效，但在高维环境下直接比较动作往往不足以提供有效的学习反馈。RILe结合了模仿学习和逆强化学习的优点，采用训练器-学生架构，其中训练器学习适应性的奖励函数，而学生则依据该奖励信号模仿专家行为。随着学生的进步，训练器能够动态调整指导策略，给出不同学习阶段的精细化反馈。实验表明，RILe在具有挑战性的机器人行走任务上显著优于现有方法，并能在多种设置下实现接近专家水平的表现。 <div>
arXiv:2406.08472v3 Announce Type: cross 
Abstract: Acquiring complex behaviors is essential for artificially intelligent agents, yet learning these behaviors in high-dimensional settings poses a significant challenge due to the vast search space. Traditional reinforcement learning (RL) requires extensive manual effort for reward function engineering. Inverse reinforcement learning (IRL) uncovers reward functions from expert demonstrations but relies on an iterative process that is often computationally expensive. Imitation learning (IL) provides a more efficient alternative by directly comparing an agent's actions to expert demonstrations; however, in high-dimensional environments, such direct comparisons offer insufficient feedback for effective learning. We introduce RILe (Reinforced Imitation Learning), a framework that combines the strengths of imitation learning and inverse reinforcement learning to learn a dense reward function efficiently and achieve strong performance in high-dimensional tasks. RILe employs a novel trainer-student framework: the trainer learns an adaptive reward function, and the student uses this reward signal to imitate expert behaviors. By dynamically adjusting its guidance as the student evolves, the trainer provides nuanced feedback across different phases of learning. Our framework produces high-performing policies in high-dimensional tasks where direct imitation fails to replicate complex behaviors. We validate RILe in challenging robotic locomotion tasks, demonstrating that it significantly outperforms existing methods and achieves near-expert performance across multiple settings.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Passivity-Based Local Design Conditions for Global Optimality in Distributed Convex Optimization</title>
<link>https://arxiv.org/abs/2503.09854</link>
<guid>https://arxiv.org/abs/2503.09854</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化算法、passivity理论、全局最优解、异构优化算法、动态加入/离开网络

<br /><br />总结:
本文提出了一个利用passivity理论建立的分布式优化框架，该框架为无约束和有约束问题设定了本地设计要求，并确保了具有无向通信拓扑结构的全局最优性和收敛性。在此框架下，各智能体可采用不同的优化算法而不影响全局性能。文章还提出了一些符合这些设计要求的示例性智能体系统，这些系统的特点是不需要全球初始化，也不需通信多个变量，因此智能体能够自由地加入或离开网络而不会影响到对全局最优解的收敛。此外，对于无约束优化问题，该方法还可扩展到有向通信拓扑。仿真实验展示了所提智能体动态的即插即用能力和互操作性。 <div>
arXiv:2503.09854v1 Announce Type: cross 
Abstract: In recent times, various distributed optimization algorithms have been proposed for whose specific agent dynamics global optimality and convergence is proven. However, there exist no general conditions for the design of such algorithms. In this paper, we leverage passivity theory to fi rst establish a distributed optimization framework with local design requirements for the agent dynamics in both unconstrained and constrained problems with undirected communication topologies. Under the roof of these requirements, the agents may use heterogeneous optimization algorithms without compromising global optimality and convergence. Subsequently, we propose some exemplary agent systems that comply with the established requirements. Compared to existing approaches, our algorithms do not require any global initialization nor communication of multiple variables. Consequently, the agents may leave or rejoin the networked optimization without compromising convergence to the correct global optimizer. Furthermore, we show that for unconstrained optimization, an extension to directed communication topologies is possible. Simulation results illustrate the plug-and-play capabilities and interoperability of the proposed agent dynamics.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Lagrangian Method for Solving Constrained Markov Games</title>
<link>https://arxiv.org/abs/2503.10561</link>
<guid>https://arxiv.org/abs/2503.10561</guid>
<content:encoded><![CDATA[
<div> 关键词：Lagrangian游戏、约束Markov游戏、多智能体强化学习、安全动态交互、非站姿Nash解

<br /><br />总结：
本文提出了利用Lagrangian游戏解决约束Markov游戏的概念，这种游戏模型考虑了在依赖于多个智能体联合行动和环境状态随时间演变的奖励基础上，智能体面临的成本约束问题。约束Markov游戏为安全多智能体强化学习提供了结构化的模型，适用于受局部能源和时间限制的自主团队等动态多智能体交互场景。文章发展了一种基于primal-dual的方法，其中智能体根据当前拉格朗日乘子解决关联的Lagrangian游戏，模拟固定时间段内的成本和奖励轨迹，并使用积累的经验更新乘子。作者证明这一更新规则生成的新Lagrangian游戏序列的解决方案形成了原约束Markov游戏的非站姿Nash解。 <div>
arXiv:2503.10561v1 Announce Type: cross 
Abstract: We propose the concept of a Lagrangian game to solve constrained Markov games. Such games model scenarios where agents face cost constraints in addition to their individual rewards, that depend on both agent joint actions and the evolving environment state over time. Constrained Markov games form the formal mechanism behind safe multiagent reinforcement learning, providing a structured model for dynamic multiagent interactions in a multitude of settings, such as autonomous teams operating under local energy and time constraints, for example. We develop a primal-dual approach in which agents solve a Lagrangian game associated with the current Lagrange multiplier, simulate cost and reward trajectories over a fixed horizon, and update the multiplier using accrued experience. This update rule generates a new Lagrangian game, initiating the next iteration. Our key result consists in showing that the sequence of solutions to these Lagrangian games yields a nonstationary Nash solution for the original constrained Markov game.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tightness without Counterexamples: A New Approach and New Results for Prophet Inequalities</title>
<link>https://arxiv.org/abs/2205.00588</link>
<guid>https://arxiv.org/abs/2205.00588</guid>
<content:encoded><![CDATA[
<div> 关键词: prophet不等式、优化问题、Type Coverage、静态阈值算法、IID设置

总结:
本文主要研究了prophet不等式及其紧性能比，提出了将最坏情况实例构造作为优化问题的方法，直接寻找匹配的紧比率。通过分析新的“Type Coverage”对偶问题，文章提供了一个统一框架，用于推导新旧prophet不等式。首先，文章证明Chawla等人(2020)提出的静态阈值方法在任何起始单位数$k$的情况下都是所有静态阈值算法中的最佳选择，无需显式构造反例实例，这证实了静态阈值算法收敛率$1-O(\sqrt{\log k/k})$的渐近紧密性。其次，在IID设置下，文章利用该框架刻画了任意数量的选择槽位和固定数量的代理$n$下的适应性算法的紧致保证。 <div>
arXiv:2205.00588v5 Announce Type: replace 
Abstract: Prophet inequalities consist of many beautiful statements that establish tight performance ratios between online and offline allocation algorithms. Typically, tightness is established by constructing an algorithmic guarantee and a worst-case instance separately, whose bounds match as a result of some "ingenuity". In this paper, we instead formulate the construction of the worst-case instance as an optimization problem, which directly finds the tight ratio without needing to construct two bounds separately. Our analysis of this complex optimization problem involves identifying structure in a new "Type Coverage" dual problem. It can be seen as akin to the celebrated Magician and OCRS (Online Contention Resolution Scheme) problems, except more general in that it can also provide tight ratios relative to the optimal offline allocation, whereas the earlier problems only establish tight ratios relative to the ex-ante relaxation of the offline problem.
  Through this analysis, our paper provides a unified framework that derives new prophet inequalities and recovers existing ones, with our principal results being two-fold. First, we show that the "oblivious" method of setting a static threshold due to Chawla et al. (2020), surprisingly, is best-possible among all static threshold algorithms, under any number $k$ of starting units. We emphasize that this result is derived without needing to explicitly find any counterexample instances. This implies the tightness of the asymptotic convergence rate of $1-O(\sqrt{\log k/k})$ for static threshold algorithms, which dates back to from Hajiaghayi et al. (2007). Turning to the IID setting, our second principal result is to use our framework to characterize the tight guarantee (of adaptive algorithms) under any number $k$ of selection slots and any fixed number of agents $n$.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Networked Communication for Decentralised Agents in Mean-Field Games</title>
<link>https://arxiv.org/abs/2306.02766</link>
<guid>https://arxiv.org/abs/2306.02766</guid>
<content:encoded><![CDATA[
<div> 关键词：网络化通信、mean-field游戏框架、分布式代理、采样保证、收敛性

总结:
我们引入了网络化通信到mean-field游戏框架，特别是在无需oracle的设置中，其中$N$个分布式代理在单一、非周期性的经验系统运行中进行学习。我们证明了我们的架构在采样保证上界和下界之间具有介于集中式学习与独立学习两者之间的保证，并给出了这种差异在网络结构和通信轮数方面的阶数表示。此外，我们还提供了策略更新稳定性保证。文章指出，理论上三种算法的采样保证实际上并未导致实际收敛，并展示了在网络通信方案下，当理论参数未被观察（从而导致Q函数估计不良）的实际场景中，我们的通信方案能显著加速学习速度，通常表现得与集中式学习者相似，同时消除了后者的严格假设。我们对三种理论算法进行了进一步的实用增强，使其首次得以实证演示。实验表明，我们可以移除算法的一些理论假设，并证实了新提出的网络化通信在实践中带来的收敛性益处。此外，我们还展示出我们的网络化方法在应对更新失败和人口规模变化方面相比两种替代方案具有显著优势。<br /><br /> <div>
arXiv:2306.02766v5 Announce Type: replace 
Abstract: We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic run of the empirical system. We prove that our architecture has sample guarantees bounded between those of the centralised- and independent-learning cases. We provide the order of the difference in these bounds in terms of network structure and number of communication rounds, and also contribute a policy-update stability guarantee. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. We therefore show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme considerably accelerates learning over the independent case, often performing similarly to a centralised learner while removing the restrictive assumption of the latter. We contribute further practical enhancements to all three theoretical algorithms, allowing us to present their first empirical demonstrations. Our experiments confirm that we can remove several of the theoretical assumptions of the algorithms, and display the empirical convergence benefits brought by our new networked communication. We additionally show that our networked approach has significant advantages over both alternatives in terms of robustness to update failures and to changes in population size.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Price of Opportunity Fairness in Matroid Allocation Problems</title>
<link>https://arxiv.org/abs/2403.00397</link>
<guid>https://arxiv.org/abs/2403.00397</guid>
<content:encoded><![CDATA[
<div> 关键词: matroid 分配问题 机会公平性 社会福利 价格公平性

总结:
该文研究了在机会公平性约束下的matroid分配问题，其中资源需要根据matroid约束（包括经典的二分图匹配问题）分配给一组代理商。代理商被划分为C个基于敏感属性的组，公平的分配要求每个组所获得的份额与其在隔离状态下可实现的最大可行分配成比例。文章首先利用分配问题的多形结构对价格公平性（PoF）进行了刻画，并在此基础上在各种场景下证明了PoF的界限，从完全对抗（最坏情况）到完全随机。特别地，对于具有任意matroid结构且代理商随机划分到各组的情况，文中证明了一个PoF界，该界与最大组的大小有关。这一结果表明，只要不存在主导组（即，最大的组不是过大），机会公平性的约束不会导致社会福利（定义为分配规模）的损失。总的来说，本文的结果揭示了解决方案结构的哪些方面会影响机会公平性和社会福利之间的权衡关系。 <div>
arXiv:2403.00397v2 Announce Type: replace 
Abstract: We consider matroid allocation problems under opportunity fairness constraints: resources need to be allocated to a set of agents under matroid constraints (which includes classical problems such as bipartite matching). Agents are divided into C groups according to a sensitive attribute, and an allocation is opportunity-fair if each group receives the same share proportional to the maximum feasible allocation it could achieve in isolation. We study the Price of Fairness (PoF), i.e., the ratio between maximum size allocations and maximum size opportunity-fair allocations. We first provide a characterization of the PoF leveraging the underlying polymatroid structure of the allocation problem. Based on this characterization, we prove bounds on the PoF in various settings from fully adversarial (wort-case) to fully random. Notably, one of our main results considers an arbitrary matroid structure with agents randomly divided into groups. In this setting, we prove a PoF bound as a function of the size of the largest group. Our result implies that, as long as there is no dominant group (i.e., the largest group is not too large), opportunity fairness constraints do not induce any loss of social welfare (defined as the allocation size). Overall, our results give insights into which aspects of the problem's structure affect the trade-off between opportunity fairness and social welfare.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COMBO: Compositional World Models for Embodied Multi-Agent Cooperation</title>
<link>https://arxiv.org/abs/2404.10775</link>
<guid>https://arxiv.org/abs/2404.10775</guid>
<content:encoded><![CDATA[
<div> 关键词: 体化多智能体合作, 局部观察, 生成模型, 符合组合的世界模型, 视觉语言模型

总结:<br />
本文研究了基于局部视角的体化多智能体合作问题。为了解决部分可观测性带来的挑战，文章提出首先利用生成模型从部分局部视觉观测中估计整体世界状态。接着，为了准确模拟多个智能体在该世界状态下执行的任意动作集合，文章提出了学习一种符合组合的世界模型，将多个智能体的自然可组合的联合动作进行分解，并条件式地生成视频。通过结合这种符合组合的世界模型和视觉语言模型以推断其他智能体的动作，可以使用树搜索方法实现在线合作规划。文章在三个具有2-4个智能体的挑战性基准上评估了所提方法，结果表明，提出的符合组合的世界模型有效，该框架使体化智能体能够在各种任务和任意数量的智能体之间有效地进行合作，展示了所提方法的广阔前景。更多视频可在https://embodied-agi.cs.umass.edu/combo/ 查看。 <div>
arXiv:2404.10775v2 Announce Type: replace 
Abstract: In this paper, we investigate the problem of embodied multi-agent cooperation, where decentralized agents must cooperate given only egocentric views of the world. To effectively plan in this setting, in contrast to learning world dynamics in a single-agent scenario, we must simulate world dynamics conditioned on an arbitrary number of agents' actions given only partial egocentric visual observations of the world. To address this issue of partial observability, we first train generative models to estimate the overall world state given partial egocentric observations. To enable accurate simulation of multiple sets of actions on this world state, we then propose to learn a compositional world model for multi-agent cooperation by factorizing the naturally composable joint actions of multiple agents and compositionally generating the video conditioned on the world state. By leveraging this compositional world model, in combination with Vision Language Models to infer the actions of other agents, we can use a tree search procedure to integrate these modules and facilitate online cooperative planning. We evaluate our methods on three challenging benchmarks with 2-4 agents. The results show our compositional world model is effective and the framework enables the embodied agents to cooperate efficiently with different agents across various tasks and an arbitrary number of agents, showing the promising future of our proposed methods. More videos can be found at https://embodied-agi.cs.umass.edu/combo/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Planning with Adaptive World Models for Autonomous Driving</title>
<link>https://arxiv.org/abs/2406.10714</link>
<guid>https://arxiv.org/abs/2406.10714</guid>
<content:encoded><![CDATA[
<div> 关键词: motion planning, nuPlan, BehaviorNet, AdaptiveDriver, model-predictive control

总结:<br />
本文主要关注复杂城市环境中安全导航的关键技术——运动规划。研究指出，历史上的运动规划器评估多依赖于如CARLA这样的程序生成模拟器，但这类合成基准并未捕捉到真实的多智能体交互行为。nuPlan作为新发布的运动规划基准，通过将真实驾驶记录与闭环模拟逻辑相结合，形成了一种反应式模拟器，解决了这一问题。作者分析了nuPlan记录数据的特点，发现不同城市的驾驶行为具有独特性，因此要求鲁棒的规划器必须能适应不同的环境。为此，文章提出了一种名为BehaviorNet的图卷积神经网络（GCNN），它利用近期观测到的代理历史特征来预测反应式代理行为，以适应各种驾驶风格。接下来，文章介绍了AdaptiveDriver，这是一种基于模型预测控制（MPC）的规划器，能够根据不同世界的模型条件对BehaviorNet的预测进行动态展开。实验结果显示，AdaptiveDriver在nuPlan的闭环规划基准测试中达到了最先进的结果，在Test-14 Hard R-CLS上相比先前工作提高了2%，并且在未见过的新城市中也表现出了良好的泛化能力。 <div>
arXiv:2406.10714v3 Announce Type: replace 
Abstract: Motion planning is crucial for safe navigation in complex urban environments. Historically, motion planners (MPs) have been evaluated with procedurally-generated simulators like CARLA. However, such synthetic benchmarks do not capture real-world multi-agent interactions. nuPlan, a recently released MP benchmark, addresses this limitation by augmenting real-world driving logs with closed-loop simulation logic, effectively turning the fixed dataset into a reactive simulator. We analyze the characteristics of nuPlan's recorded logs and find that each city has its own unique driving behaviors, suggesting that robust planners must adapt to different environments. We learn to model such unique behaviors with BehaviorNet, a graph convolutional neural network (GCNN) that predicts reactive agent behaviors using features derived from recently-observed agent histories; intuitively, some aggressive agents may tailgate lead vehicles, while others may not. To model such phenomena, BehaviorNet predicts the parameters of an agent's motion controller rather than directly predicting its spacetime trajectory (as most forecasters do). Finally, we present AdaptiveDriver, a model-predictive control (MPC) based planner that unrolls different world models conditioned on BehaviorNet's predictions. Our extensive experiments demonstrate that AdaptiveDriver achieves state-of-the-art results on the nuPlan closed-loop planning benchmark, improving over prior work by 2% on Test-14 Hard R-CLS, and generalizes even when evaluated on never-before-seen cities.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Low Fidelity Visuo-Tactile Pretraining Improves Vision-Only Manipulation Performance</title>
<link>https://arxiv.org/abs/2406.15639</link>
<guid>https://arxiv.org/abs/2406.15639</guid>
<content:encoded><![CDATA[
<div> 关键词: BeadSight、低成本、触觉传感器、预训练、模仿学习

总结:<br />
本文探讨了BeadSight，一种低成本开源触觉传感器，以及利用其进行触觉预训练的方法，以替代高精度预校准传感器并降低操纵系统成本。研究发现，即使使用低保真度如BeadSight的传感器，通过触觉预训练也能提升模仿学习代理在复杂操纵任务中的性能。实验结果显示，视觉-触觉预训练使仅依靠视觉推断的USB线插拔任务性能提高了最多65%。进一步地，在更长周期的抽屉捡放任务中，无论是相似任务、不相似任务还是相同任务的预训练，都能持续提升任务表现，彰显大规模视觉-触觉预训练编码器的巨大潜力。 <div>
arXiv:2406.15639v4 Announce Type: replace 
Abstract: Tactile perception is essential for real-world manipulation tasks, yet the high cost and fragility of tactile sensors can limit their practicality. In this work, we explore BeadSight (a low-cost, open-source tactile sensor) alongside a tactile pre-training approach, an alternative method to precise, pre-calibrated sensors. By pre-training with the tactile sensor and then disabling it during downstream tasks, we aim to enhance robustness and reduce costs in manipulation systems. We investigate whether tactile pre-training, even with a low-fidelity sensor like BeadSight, can improve the performance of an imitation learning agent on complex manipulation tasks. Through visuo-tactile pre-training on both similar and dissimilar tasks, we analyze its impact on a longer-horizon downstream task. Our experiments show that visuo-tactile pre-training improved performance on a USB cable plugging task by up to 65% with vision-only inference. Additionally, on a longer-horizon drawer pick-and-place task, pre-training--whether on a similar, dissimilar, or identical task--consistently improved performance, highlighting the potential for a large-scale visuo-tactile pre-trained encoder.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Networked Communication for Mean-Field Games with Function Approximation and Empirical Mean-Field Estimation</title>
<link>https://arxiv.org/abs/2408.11607</link>
<guid>https://arxiv.org/abs/2408.11607</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralised Agents, Mean-Field Games, Function Approximation, Communication Network, Policy Information Exchange

总结:<br />
本文提出了将函数近似引入到分布式代理学习均值场游戏均衡的方法，以克服现有算法在处理大型观察空间和推广至依赖于群体状态的策略上的局限性。研究借鉴了Munchausen在线镜像下降方法，允许玩家策略中包含均值场信息。同时，为了解决分布式代理无法获取全局均值场的问题，文中还提供了新的算法，使代理能够局部估计全球经验分布并通过跨代理通信改进该估计。理论分析表明，交换策略信息有助于网络化代理在函数逼近设置中超越独立甚至集中式代理。实验验证了这一点，并显示通信网络使得分布式代理能够为依赖于群体状态的策略准确估计均值场，其效果在功能逼近环境中比表格式设置中更为显著。 <div>
arXiv:2408.11607v2 Announce Type: replace 
Abstract: Recent algorithms allow decentralised agents, possibly connected via a communication network, to learn equilibria in Mean-Field Games from a non-episodic run of the empirical system. However, these algorithms are for tabular settings: this computationally limits the size of agents' observation space, meaning the algorithms cannot handle anything but small state spaces, nor generalise beyond policies depending only on the agent's local state to so-called 'population-dependent' policies. We address this limitation by introducing function approximation to the existing setting, drawing on the Munchausen Online Mirror Descent method that has previously been employed only in finite-horizon, episodic, centralised settings. While this permits us to include the mean field in the observation for players' policies, it is unrealistic to assume decentralised agents have access to this global information: we therefore also provide new algorithms allowing agents to locally estimate the global empirical distribution, and to improve this estimate via inter-agent communication. We show theoretically that exchanging policy information helps networked agents outperform both independent and even centralised agents in function-approximation settings. Our experiments demonstrate this happening empirically, by an even greater margin than in tabular settings, and show that the communication network allows decentralised agents to estimate the mean field for population-dependent policies.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage</title>
<link>https://arxiv.org/abs/2409.11295</link>
<guid>https://arxiv.org/abs/2409.11295</guid>
<content:encoded><![CDATA[
<div> 关键词: 通用网络代理、隐私风险、环境注入攻击(EIA)、个人信息泄露、防御策略

总结:<br />
本文首次针对通用网络代理在对抗性环境中的隐私风险进行了研究。文章提出了一个针对网站的现实威胁模型，考虑了两种敌对目标：窃取用户的特定个人信息或整个用户请求。接着，文章提出了一种名为环境注入攻击（EIA）的新型攻击方法，该方法针对网络环境中的隐私场景，设计适应代理操作环境的恶意内容。实验结果显示，EIA在窃取特定个人信息方面的成功率为70%，获取完整用户请求的成功率为16%。此外，EIA还表现出较强的隐蔽性和抵抗防御系统提示的能力。文中指出，未适应网页的攻击可能通过人工检查被发现，但额外的努力可以让EIA无缝融入，使这种监督变得无效。因此，文章讨论了在网站部署前后的无须依赖人类监督的防御措施，并呼吁开发更先进的防御策略。 <div>
arXiv:2409.11295v5 Announce Type: replace 
Abstract: Generalist web agents have demonstrated remarkable potential in autonomously completing a wide range of tasks on real websites, significantly boosting human productivity. However, web tasks, such as booking flights, usually involve users' PII, which may be exposed to potential privacy risks if web agents accidentally interact with compromised websites, a scenario that remains largely unexplored in the literature. In this work, we narrow this gap by conducting the first study on the privacy risks of generalist web agents in adversarial environments. First, we present a realistic threat model for attacks on the website, where we consider two adversarial targets: stealing users' specific PII or the entire user request. Then, we propose a novel attack method, termed Environmental Injection Attack (EIA). EIA injects malicious content designed to adapt well to environments where the agents operate and our work instantiates EIA specifically for privacy scenarios in web environments. We collect 177 action steps that involve diverse PII categories on realistic websites from the Mind2Web, and conduct experiments using one of the most capable generalist web agent frameworks to date. The results demonstrate that EIA achieves up to 70% ASR in stealing specific PII and 16% ASR for full user request. Additionally, by accessing the stealthiness and experimenting with a defensive system prompt, we indicate that EIA is hard to detect and mitigate. Notably, attacks that are not well adapted for a webpage can be detected via human inspection, leading to our discussion about the trade-off between security and autonomy. However, extra attackers' efforts can make EIA seamlessly adapted, rendering such supervision ineffective. Thus, we further discuss the defenses at the pre- and post-deployment stages of the websites without relying on human supervision and call for more advanced defense strategies.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Maintaining Strong $r$-Robustness in Reconfigurable Multi-Robot Networks using Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.14675</link>
<guid>https://arxiv.org/abs/2409.14675</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2409.14675v2, 领导者跟随者共识, 强$r$鲁棒性, 通信图, 控制Barrier函数

<br /><br />总结:
该文针对领导者跟随者共识问题，提出了一个新的控制Barrier函数方法，确保机器人在具有距离依赖通信模型并处于空间受限环境（如狭窄走廊）中完成任务的同时，能够保持其通信图的强$r$鲁棒性高于某一阈值，而无需维持固定的网络拓扑结构。这种方法直接解决了网络的鲁棒性问题，允许机器人在实现目标的同时具有灵活可重构的网络结构。文章通过多种仿真和硬件实验验证了所提方法的有效性。 <div>
arXiv:2409.14675v2 Announce Type: replace 
Abstract: In leader-follower consensus, strong $r$-robustness of the communication graph provides a sufficient condition for followers to achieve consensus in the presence of misbehaving agents. Previous studies have assumed that robots can form and/or switch between predetermined network topologies with known robustness properties. However, robots with distance-based communication models may not be able to achieve these topologies while moving through spatially constrained environments, such as narrow corridors, to complete their objectives. This paper introduces a Control Barrier Function (CBF) that ensures robots maintain strong $r$-robustness of their communication graph above a certain threshold without maintaining any fixed topologies. Our CBF directly addresses robustness, allowing robots to have flexible reconfigurable network structure while navigating to achieve their objectives. The efficacy of our method is tested through various simulation and hardware experiments.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LaMMA-P: Generalizable Multi-Agent Long-Horizon Task Allocation and Planning with LM-Driven PDDL Planner</title>
<link>https://arxiv.org/abs/2409.20560</link>
<guid>https://arxiv.org/abs/2409.20560</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、多智能体任务规划、PDDL规划器、MAT-THOR基准、LaMMA-P

总结:<br />
本文提出了一种名为LaMMA-P的新型多智能体任务规划框架，该框架结合了语言模型的理解能力和传统启发式搜索规划器的优势，以处理长期任务中的子任务识别和分配问题，特别适用于合作异质机器人团队。LaMMA-P在基于AI2-THOR环境构建的MAT-THOR综合基准上展现了对长期任务的高成功率和效率，并且具有跨任务的强大泛化能力。实验结果显示，LaMMA-P相比现有基于语言模型的多智能体规划器，其成功率提高了105%，效率提高了36%。相关的实验视频、代码、数据集以及各模块中使用的详细提示可以在项目网站https://lamma-p.github.io上找到。 <div>
arXiv:2409.20560v2 Announce Type: replace 
Abstract: Language models (LMs) possess a strong capability to comprehend natural language, making them effective in translating human instructions into detailed plans for simple robot tasks. Nevertheless, it remains a significant challenge to handle long-horizon tasks, especially in subtask identification and allocation for cooperative heterogeneous robot teams. To address this issue, we propose a Language Model-Driven Multi-Agent PDDL Planner (LaMMA-P), a novel multi-agent task planning framework that achieves state-of-the-art performance on long-horizon tasks. LaMMA-P integrates the strengths of the LMs' reasoning capability and the traditional heuristic search planner to achieve a high success rate and efficiency while demonstrating strong generalization across tasks. Additionally, we create MAT-THOR, a comprehensive benchmark that features household tasks with two different levels of complexity based on the AI2-THOR environment. The experimental results demonstrate that LaMMA-P achieves a 105% higher success rate and 36% higher efficiency than existing LM-based multiagent planners. The experimental videos, code, datasets, and detailed prompts used in each module can be found on the project website: https://lamma-p.github.io.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DataEnvGym: Data Generation Agents in Teacher Environments with Student Feedback</title>
<link>https://arxiv.org/abs/2410.06215</link>
<guid>https://arxiv.org/abs/2410.06215</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2410.06215v3, 自主数据生成代理, DataEnvGym, 训练数据生成, 模型教学

总结:
本文介绍了arXiv:2410.06215v3论文中提出的DataEnvGym测试床，该平台旨在为自主数据生成代理（教师）提供迭代、闭环的数据创建环境。DataEnvGym将数据生成视为一个序列决策任务，其中包含一个数据生成策略和一个数据生成引擎，这些组件在一个能够提供学生反馈的环境中运行。目标是通过迭代生成的数据提升学生的性能。该测试床提供了不同结构层次的多个教师环境实例，覆盖了数学、代码、视觉问答和工具使用等四个领域，并支持多种学生和教师模型进行测试。实验表明，该教学环境中的代理可以逐步提高学生在各种任务和设置下的表现，同时展示了不同的环境可教授不同技能水平，并对关键模块的变体进行了测试，为改进数据生成代理、引擎及反馈机制指明了未来研究方向。 <div>
arXiv:2410.06215v3 Announce Type: replace 
Abstract: The process of creating training data to teach models is currently driven by humans, who manually analyze model weaknesses and plan how to create data that improves a student model. Approaches using LLMs as annotators reduce human effort, but still require humans to interpret feedback from evaluations and control the LLM to produce data the student needs. Automating this labor-intensive process by creating autonomous data generation agents - or teachers - is desirable, but requires environments that can simulate the feedback-driven, iterative, closed loop of data creation. To enable rapid, scalable testing for such agents and their modules, we introduce DataEnvGym, a testbed of teacher environments for data generation agents. DataEnvGym frames data generation as a sequential decision-making task, involving an agent consisting of a data generation policy (which generates a plan for creating training data) and a data generation engine (which transforms the plan into data), inside an environment that provides student feedback. The agent's goal is to improve student performance. Students are iteratively trained and evaluated on generated data, and their feedback (in the form of errors or weak skills) is reported to the agent after each iteration. DataEnvGym includes multiple teacher environment instantiations across 3 levels of structure in the state representation and action space. More structured environments are based on inferred skills and offer more interpretability and curriculum control. We support 4 domains (math, code, VQA, and tool-use) and test multiple students and teachers. Example agents in our teaching environments can iteratively improve students across tasks and settings. Moreover, we show that environments teach different skill levels and test variants of key modules, pointing to future work in improving data generation agents, engines, and feedback mechanisms.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Neuroplastic Expansion in Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.07994</link>
<guid>https://arxiv.org/abs/2410.07994</guid>
<content:encoded><![CDATA[
<div> 关键词：神经塑性、扩展、深度强化学习、弹性拓扑生成、经验回顾

总结:<br />
为解决深度强化学习中因环境非stationary特性导致的学习与适应能力下降问题，本文提出了一个名为“神经塑性扩展”（NE）的新方法。该方法受到认知科学中大脑皮层扩张现象的启发，通过动态地从较小的初始规模扩展网络至全尺寸，保持学习代理在整个训练过程中的可塑性和适应性。NE包括三个关键组件：（1）基于潜在梯度的弹性拓扑生成，用于网络结构的动态调整；（2）休眠神经元修剪，以优化网络表达力；（3）通过经验回顾进行神经元巩固，从而在可塑性与稳定性之间取得平衡。实验表明，NE有效缓解了塑料性的丧失，并在MuJoCo和DeepMind Control Suite等环境的任务中超越了现有的最佳方法。这使得NE能够在复杂动态环境中实现更适应的学习，朝着构建更加灵活、持续适应的深度强化学习模型方向迈出重要一步。 <div>
arXiv:2410.07994v2 Announce Type: replace 
Abstract: The loss of plasticity in learning agents, analogous to the solidification of neural pathways in biological brains, significantly impedes learning and adaptation in reinforcement learning due to its non-stationary nature. To address this fundamental challenge, we propose a novel approach, {\it Neuroplastic Expansion} (NE), inspired by cortical expansion in cognitive science. NE maintains learnability and adaptability throughout the entire training process by dynamically growing the network from a smaller initial size to its full dimension. Our method is designed with three key components: (\textit{1}) elastic topology generation based on potential gradients, (\textit{2}) dormant neuron pruning to optimize network expressivity, and (\textit{3}) neuron consolidation via experience review to strike a balance in the plasticity-stability dilemma. Extensive experiments demonstrate that NE effectively mitigates plasticity loss and outperforms state-of-the-art methods across various tasks in MuJoCo and DeepMind Control Suite environments. NE enables more adaptive learning in complex, dynamic environments, which represents a crucial step towards transitioning deep reinforcement learning from static, one-time training paradigms to more flexible, continually adapting models.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GenUP: Generative User Profilers as In-Context Learners for Next POI Recommender Systems</title>
<link>https://arxiv.org/abs/2410.20643</link>
<guid>https://arxiv.org/abs/2410.20643</guid>
<content:encoded><![CDATA[
<div> 关键词: Point-of-Interest (POI)推荐系统、透明度、可解释性、冷启动问题、自然语言用户画像

总结:
本文提出了一种针对传统Point-of-Interest (POI)推荐系统的改进方法，旨在解决其缺乏透明度、可解释性和难以处理新用户冷启动问题的挑战。该方法通过从大规模位置社交网络（LBSN）签到数据中生成自然语言（NL）用户画像，利用稳健的性格评估和行为理论来捕捉用户的偏好、习惯和行为，从而提高POI预测准确性并提升系统透明度。通过将NL用户画像作为提示信息输入大型语言模型（LLM），该方法减少了对大量历史数据的依赖，实现了更灵活、易于更新和计算高效的推荐过程。实验结果显示，此方法与现有的LLM基线和其他复杂代理框架相比具有竞争力，并更具可扩展性，为实际世界中的POI推荐系统提供了解决方案。相关源代码已发布于：https://github.com/w11wo/GenUP/。 <div>
arXiv:2410.20643v2 Announce Type: replace 
Abstract: Traditional Point-of-Interest (POI) recommendation systems often lack transparency, interpretability, and scrutability due to their reliance on dense vector-based user embeddings. Furthermore, the cold-start problem -- where systems have insufficient data for new users -- limits their ability to generate accurate recommendations. Existing methods often address this by leveraging similar trajectories from other users, but this approach can be computationally expensive and increases the context length for LLM-based methods, making them difficult to scale. To address these limitations, we propose a method that generates natural language (NL) user profiles from large-scale, location-based social network (LBSN) check-ins, utilizing robust personality assessments and behavioral theories. These NL profiles capture user preferences, routines, and behaviors, improving POI prediction accuracy while offering enhanced transparency. By incorporating NL profiles as system prompts to LLMs, our approach reduces reliance on extensive historical data, while remaining flexible, easily updated, and computationally efficient. Our method is not only competitive with other LLM-based and complex agentic frameworks but is also more scalable for real-world POI recommender systems. Results demonstrate that our approach consistently outperforms baseline methods, offering a more interpretable and resource-efficient solution for POI recommendation systems. Our source code is available at: https://github.com/w11wo/GenUP/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis</title>
<link>https://arxiv.org/abs/2412.16833</link>
<guid>https://arxiv.org/abs/2412.16833</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 医疗诊断, 知识图谱, 框架, 专业知识

<br /><br />总结:
本文提出了一种名为KG4Diagnosis的新颖层次化多代理框架，该框架将大型语言模型（LLMs）与自动知识图谱构建相结合，应用于医疗诊断领域，覆盖了362种跨医学专科的常见疾病。该框架采用双层架构，模拟真实世界的医疗系统，由一般医师（GP）代理人进行初步评估和分流，并与专门领域的代理人协同进行深入诊断。其核心创新点在于端到端的知识图谱生成方法，包括：(1) 针对医学术语优化的语义驱动实体和关系抽取，(2) 从非结构化医疗文本中重构多元决策关系，以及(3) 人类引导的知识扩展推理。KG4Diagnosis作为一个可扩展的基础框架，能够容纳新疾病和医学知识的加入，并且其模块化设计便于针对特定医学诊断系统的无缝集成和增强。此外，文章还提供了用于促进不同医疗情境下框架采纳的架构指南和协议。 <div>
arXiv:2412.16833v3 Announce Type: replace 
Abstract: Integrating Large Language Models (LLMs) in healthcare diagnosis demands systematic frameworks that can handle complex medical scenarios while maintaining specialized expertise. We present KG4Diagnosis, a novel hierarchical multi-agent framework that combines LLMs with automated knowledge graph construction, encompassing 362 common diseases across medical specialties. Our framework mirrors real-world medical systems through a two-tier architecture: a general practitioner (GP) agent for initial assessment and triage, coordinating with specialized agents for in-depth diagnosis in specific domains. The core innovation lies in our end-to-end knowledge graph generation methodology, incorporating: (1) semantic-driven entity and relation extraction optimized for medical terminology, (2) multi-dimensional decision relationship reconstruction from unstructured medical texts, and (3) human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an extensible foundation for specialized medical diagnosis systems, with capabilities to incorporate new diseases and medical knowledge. The framework's modular design enables seamless integration of domain-specific enhancements, making it valuable for developing targeted medical diagnosis systems. We provide architectural guidelines and protocols to facilitate adoption across medical contexts.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ECBench: Can Multi-modal Foundation Models Understand the Egocentric World? A Holistic Embodied Cognition Benchmark</title>
<link>https://arxiv.org/abs/2501.05031</link>
<guid>https://arxiv.org/abs/2501.05031</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2501.05031v2, 大型视觉语言模型, 机器人, 交互式视频问答, ECBench

总结:
本文提出了一种名为ECBench的高质量基准测试，旨在系统性地评估基于大型视觉语言模型(LVLMs)的机器人具有的嵌入式认知能力。针对当前交互式视频问答数据集缺乏全面和系统的评价框架以及对关键的嵌入式认知问题关注不足的问题，ECBench包含了多样化的场景视频源、开放多样的问题格式以及30个维度的认知能力评估。为了确保质量、平衡性和高度的视觉依赖性，ECBench采用了类独立的人工精细标注和多轮问题筛选策略，并引入了ECEval这一全面的评价系统以保证指标的公平性和合理性。通过对自有、开源和任务特定的LVLMs进行广泛评估，EC Bench对于提升LVLMs的嵌入式认知能力具有关键作用，为开发可靠的具身代理核心模型奠定了坚实基础。所有数据和代码已发布于https://github.com/Rh-Dang/ECBench。 <div>
arXiv:2501.05031v2 Announce Type: replace 
Abstract: The enhancement of generalization in robots by large vision-language models (LVLMs) is increasingly evident. Therefore, the embodied cognitive abilities of LVLMs based on egocentric videos are of great interest. However, current datasets for embodied video question answering lack comprehensive and systematic evaluation frameworks. Critical embodied cognitive issues, such as robotic self-cognition, dynamic scene perception, and hallucination, are rarely addressed. To tackle these challenges, we propose ECBench, a high-quality benchmark designed to systematically evaluate the embodied cognitive abilities of LVLMs. ECBench features a diverse range of scene video sources, open and varied question formats, and 30 dimensions of embodied cognition. To ensure quality, balance, and high visual dependence, ECBench uses class-independent meticulous human annotation and multi-round question screening strategies. Additionally, we introduce ECEval, a comprehensive evaluation system that ensures the fairness and rationality of the indicators. Utilizing ECBench, we conduct extensive evaluations of proprietary, open-source, and task-specific LVLMs. ECBench is pivotal in advancing the embodied cognitive capabilities of LVLMs, laying a solid foundation for developing reliable core models for embodied agents. All data and code are available at https://github.com/Rh-Dang/ECBench.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-agent KTO: Reinforcing Strategic Interactions of Large Language Model in Language Game</title>
<link>https://arxiv.org/abs/2501.14225</link>
<guid>https://arxiv.org/abs/2501.14225</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AGI), 语言游戏理论, 多智能体Kahneman & Tversky优化(MaKTO), Werewolf游戏, GPT-4

总结:
本文提出了一种新的方法，通过受维特根斯坦语言游戏理论启发，让AI代理在实际交互中学习，而非传统分离决策与语言表达的多阶段框架。研究者以社交推理游戏Werewolf为平台，开发了多智能体Kahneman & Tversky优化（MaKTO）算法。MaKTO通过大量游戏进行训练，生成并对比理想和非理想的响应，进而改进模型的决策过程。实验结果显示，在9人制Werewolf游戏中，MaKTO在多种模型上取得了61%的平均胜率，相对GPT-4和两阶段强化学习代理分别提升了23.0%和10.9%的表现。此外，MaKTO还展现出类似人类的游戏表现，对战专家玩家赢得60%的比赛，并在Turing风格的盲测中仅有49%的可检测性。 <div>
arXiv:2501.14225v2 Announce Type: replace 
Abstract: Achieving Artificial General Intelligence (AGI) requires AI agents that can not only make stratigic decisions but also engage in flexible and meaningful communication. Inspired by Wittgenstein's language game theory in Philosophical Investigations, we propose that language agents can learn through in-context interaction rather than traditional multi-stage frameworks that separate decision-making from language expression. Using Werewolf, a social deduction game that tests language understanding, strategic interaction, and adaptability, we develop the Multi-agent Kahneman & Tversky's Optimization (MaKTO). MaKTO engages diverse models in extensive gameplay to generate unpaired desirable and unacceptable responses, then employs KTO to refine the model's decision-making process. In 9-player Werewolf games, MaKTO achieves a 61% average win rate across various models, outperforming GPT-4o and two-stage RL agents by relative improvements of 23.0% and 10.9%, respectively. Notably, MaKTO also demonstrates human-like performance, winning 60% against expert players and showing only 49% detectability in Turing-style blind tests.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MarS: a Financial Market Simulation Engine Powered by Generative Foundation Model</title>
<link>https://arxiv.org/abs/2409.07486</link>
<guid>https://arxiv.org/abs/2409.07486</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型、金融市场、大型市场模型（LMM）、金融市场价格模拟引擎（MarS）、应用潜力

总结:<br />
本文提出了一个名为大型市场模型（LMM）的订单级生成基础模型，用于金融市场的仿真模拟。LMM类似于语言模型在数字世界中的作用，其目标是生成精细结构化的金融市场数据，如订单，以构建最为逼真的金融市场模拟。基于LMM，作者开发了金融市场价格模拟引擎（MarS），该引擎能够实现真实、交互和可控的订单生成，并展现出对大规模数据和复杂模型的强大扩展性以及在控制生成中市场影响的稳健性和实用性。此外，文章展示了MarS作为预测工具、检测系统、分析平台和智能代理训练环境等多方面的应用潜力，强调了其为各类金融应用带来“范式转变”的可能性。代码已开源，可在https://github.com/microsoft/MarS/获取。 <div>
arXiv:2409.07486v2 Announce Type: replace-cross 
Abstract: Generative models aim to simulate realistic effects of various actions across different contexts, from text generation to visual effects. Despite significant efforts to build real-world simulators, the application of generative models to virtual worlds, like financial markets, remains under-explored. In financial markets, generative models can simulate complex market effects of participants with various behaviors, enabling interaction under different market conditions, and training strategies without financial risk. This simulation relies on the finest structured data in financial market like orders thus building the finest realistic simulation. We propose Large Market Model (LMM), an order-level generative foundation model, for financial market simulation, akin to language modeling in the digital world. Our financial Market Simulation engine (MarS), powered by LMM, addresses the domain-specific need for realistic, interactive and controllable order generation. Key observations include LMM's strong scalability across data size and model complexity, and MarS's robust and practicable realism in controlled generation with market impact. We showcase MarS as a forecast tool, detection system, analysis platform, and agent training environment, thus demonstrating MarS's "paradigm shift" potential for a variety of financial applications. We release the code of MarS at https://github.com/microsoft/MarS/.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Simulating Influence Dynamics with LLM Agents</title>
<link>https://arxiv.org/abs/2503.08709</link>
<guid>https://arxiv.org/abs/2503.08709</guid>
<content:encoded><![CDATA[
<div> 关键词：opinion dynamics, simulator, LLM-based agents, social networks, GitHub

总结:<br />
本文介绍了针对意见动态研究者设计的一款模拟器，该模拟器能够模拟社会网络中存在基于LLM（大型语言模型）的代理之间的竞争性影响。该工具将已建立的意见动态原则与最先进的LLMs相结合，用于研究影响力传播和反错误信息策略。这款模拟器对社会科学、心理学和运筹学的研究人员特别有价值，他们可以在无需深入编码技术的前提下分析社会现象。此外，该模拟器将在GitHub上开放源代码，以确保其可访问性和适应性，方便研究人员根据自身需求扩展其功能。 <div>
arXiv:2503.08709v1 Announce Type: new 
Abstract: This paper introduces a simulator designed for opinion dynamics researchers to model competing influences within social networks in the presence of LLM-based agents. By integrating established opinion dynamics principles with state-of-the-art LLMs, this tool enables the study of influence propagation and counter-misinformation strategies. The simulator is particularly valuable for researchers in social science, psychology, and operations research, allowing them to analyse societal phenomena without requiring extensive coding expertise. Additionally, the simulator will be openly available on GitHub, ensuring accessibility and adaptability for those who wish to extend its capabilities for their own research.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Traffic Signal Control through Model-based Reinforcement Learning and Policy Reuse</title>
<link>https://arxiv.org/abs/2503.08728</link>
<guid>https://arxiv.org/abs/2503.08728</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、交通信号控制（TSC）、普适性、PLight、PRLight

总结:<br />
本文提出了两种针对交通信号控制的强化学习算法——PLight和PRLight，旨在解决当前基于MARL的方法在面对新交通场景时泛化能力不足的问题。PLight采用模型驱动的强化学习方法，利用预定义的源域交通场景对控制策略和环境模型进行预训练，预测状态转移并比较环境特征。PRLight进一步通过根据源域与目标域之间的相似度动态选择预先训练好的PLight代理，加速目标域的学习过程。实验结果显示，PRLight在不同交通场景下以及跨不同的道路网络中都显著减少了适应时间，并能利用可用和目标场景间的相似性达到最优性能。 <div>
arXiv:2503.08728v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) has shown significant potential in traffic signal control (TSC). However, current MARL-based methods often suffer from insufficient generalization due to the fixed traffic patterns and road network conditions used during training. This limitation results in poor adaptability to new traffic scenarios, leading to high retraining costs and complex deployment. To address this challenge, we propose two algorithms: PLight and PRLight. PLight employs a model-based reinforcement learning approach, pretraining control policies and environment models using predefined source-domain traffic scenarios. The environment model predicts the state transitions, which facilitates the comparison of environmental features. PRLight further enhances adaptability by adaptively selecting pre-trained PLight agents based on the similarity between the source and target domains to accelerate the learning process in the target domain. We evaluated the algorithms through two transfer settings: (1) adaptability to different traffic scenarios within the same road network, and (2) generalization across different road networks. The results show that PRLight significantly reduces the adaptation time compared to learning from scratch in new TSC scenarios, achieving optimal performance using similarities between available and target scenarios.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Bearing-Only Target Pursuit via Multiagent Reinforcement Learning: Design and Experiment</title>
<link>https://arxiv.org/abs/2503.08740</link>
<guid>https://arxiv.org/abs/2503.08740</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人追求问题、目标状态估计、航向信息、强化学习框架、零射线转移

<br /><br />总结：

本文针对未知目标的多机器人追求问题进行了研究，涵盖了目标状态估计和追求控制两个方面。首先，针对状态估计，文章提出了一种统一的航向仅信息滤波器，解决了航向测量非线性引起的不稳定性以及两角表示中的奇异性，增强了在有限视场条件下对目标丢失的稳定性和鲁棒性。其次，在复杂环境中进行目标追求控制时，鉴于异质性和有限视场等挑战，文中提出了一种新的多智能体强化学习（MARL）框架，使多个不同类型的机器人能够有效地搜索、定位并跟踪目标。为了缩小仿真到现实世界的差距，文章还提出了两种技术：在训练中结合可调整的低级控制增益以模拟真实世界自主地面车辆（AGV）的动力学特性；并通过谱归一化RL算法提升策略的平滑度和鲁棒性。最后，实验表明，所提出的MARL控制器能够在AGV上实现成功的零射线转移，验证了该方法的有效性和实际可行性。相关视频可在https://youtu.be/HO7FJyZiJ3E查看。 <div>
arXiv:2503.08740v1 Announce Type: new 
Abstract: This paper addresses the multi-robot pursuit problem for an unknown target, encompassing both target state estimation and pursuit control. First, in state estimation, we focus on using only bearing information, as it is readily available from vision sensors and effective for small, distant targets. Challenges such as instability due to the nonlinearity of bearing measurements and singularities in the two-angle representation are addressed through a proposed uniform bearing-only information filter. This filter integrates multiple 3D bearing measurements, provides a concise formulation, and enhances stability and resilience to target loss caused by limited field of view (FoV). Second, in target pursuit control within complex environments, where challenges such as heterogeneity and limited FoV arise, conventional methods like differential games or Voronoi partitioning often prove inadequate. To address these limitations, we propose a novel multiagent reinforcement learning (MARL) framework, enabling multiple heterogeneous vehicles to search, localize, and follow a target while effectively handling those challenges. Third, to bridge the sim-to-real gap, we propose two key techniques: incorporating adjustable low-level control gains in training to replicate the dynamics of real-world autonomous ground vehicles (AGVs), and proposing spectral-normalized RL algorithms to enhance policy smoothness and robustness. Finally, we demonstrate the successful zero-shot transfer of the MARL controllers to AGVs, validating the effectiveness and practical feasibility of our approach. The accompanying video is available at https://youtu.be/HO7FJyZiJ3E.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Disentangled World Models: Learning to Transfer Semantic Knowledge from Distracting Videos for Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.08751</link>
<guid>https://arxiv.org/abs/2503.08751</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉强化学习、样本效率、离线到在线潜在蒸馏、灵活解纠缠约束、可解释模型基RL框架

<br />
总结:
本文针对视觉强化学习在实际场景中面临的低样本效率问题，提出了一种新的方法。该方法侧重于从干扰视频中通过离线到在线的潜在蒸馏和灵活解纠缠约束来学习并理解底层语义变化。为此，文章引入了一个名为“解纠缠世界模型”（DisWM）的可解释模型基RL框架。首先，通过带有解纠缠正则化的无动作视频预测模型进行离线预训练，从干扰视频中提取语义知识。随后，将预训练模型的解纠缠能力通过潜在蒸馏技术转移至世界模型。在在线环境的微调阶段，利用预训练模型的知识并引入解纠缠约束到世界模型中。最后，在适应阶段，结合来自在线环境交互的动作和奖励数据增强了表示学习的解纠缠多样性。实验结果验证了该方法在多个基准测试中的优越性。 <div>
arXiv:2503.08751v1 Announce Type: new 
Abstract: Training visual reinforcement learning (RL) in practical scenarios presents a significant challenge, $\textit{i.e.,}$ RL agents suffer from low sample efficiency in environments with variations. While various approaches have attempted to alleviate this issue by disentanglement representation learning, these methods usually start learning from scratch without prior knowledge of the world. This paper, in contrast, tries to learn and understand underlying semantic variations from distracting videos via offline-to-online latent distillation and flexible disentanglement constraints. To enable effective cross-domain semantic knowledge transfer, we introduce an interpretable model-based RL framework, dubbed Disentangled World Models (DisWM). Specifically, we pretrain the action-free video prediction model offline with disentanglement regularization to extract semantic knowledge from distracting videos. The disentanglement capability of the pretrained model is then transferred to the world model through latent distillation. For finetuning in the online environment, we exploit the knowledge from the pretrained model and introduce a disentanglement constraint to the world model. During the adaptation phase, the incorporation of actions and rewards from online environment interactions enriches the diversity of the data, which in turn strengthens the disentangled representation learning. Experimental results validate the superiority of our approach on various benchmarks.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Combining Local Symmetry Exploitation and Reinforcement Learning for Optimised Probabilistic Inference -- A Work In Progress</title>
<link>https://arxiv.org/abs/2503.08786</link>
<guid>https://arxiv.org/abs/2503.08786</guid>
<content:encoded><![CDATA[
<div> 关键词: 可效概率推理、变量消除、图模型、强化学习、局部对称性

总结:<br />
该文提出将强化学习方法应用于图模型中的高效概率推理变量消除问题。鉴于图模型与张量网络的对偶性，研究者将用于寻找张量网络高效收缩顺序的强化学习策略迁移到概率推断中。此外，文中还探讨了在寻找最优消除顺序过程中利用结构信息的方法。当前，智能体的成本函数基于指数数量级（即随机变量的数量）的中间结果大小来定义。通过在推理过程中考虑利用局部对称性带来的紧凑编码大小，研究者使智能体能够探索更高效的收缩顺序。本文所考虑的结构即为模型因素内部存在的局部对称性。 <div>
arXiv:2503.08786v1 Announce Type: new 
Abstract: Efficient probabilistic inference by variable elimination in graphical models requires an optimal elimination order. However, finding an optimal order is a challenging combinatorial optimisation problem for models with a large number of random variables. Most recently, a reinforcement learning approach has been proposed to find efficient contraction orders in tensor networks. Due to the duality between graphical models and tensor networks, we adapt this approach to probabilistic inference in graphical models. Furthermore, we incorporate structure exploitation into the process of finding an optimal order. Currently, the agent's cost function is formulated in terms of intermediate result sizes which are exponential in the number of indices (i.e., random variables). We show that leveraging specific structures during inference allows for introducing compact encodings of intermediate results which can be significantly smaller. By considering the compact encoding sizes for the cost function instead, we enable the agent to explore more efficient contraction orders. The structure we consider in this work is the presence of local symmetries (i.e., symmetries within a model's factors).
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Zero-Shot Action Generalization with Limited Observations</title>
<link>https://arxiv.org/abs/2503.08867</link>
<guid>https://arxiv.org/abs/2503.08867</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning), 零样本行动泛化 (Zero-shot Action Generalization), 有限观察 (Limited Observations), 行动表示学习模块 (Action Representation Learning Module), 政策学习模块 (Policy Learning Module)

总结:
本文介绍了一种针对强化学习在处理未见过的动作时泛化能力不足问题的新框架——基于有限观察的零样本动作泛化(AGLO)。该框架包括两个主要组件：一个用于从有限观察中抽取动作区分性嵌入的动作表示学习模块和一个利用学习到的动作表示及增强型合成动作表示来学习能处理含有未见过动作任务的政策学习模块。实验结果显示，AGLO框架在多个基准任务上显著优于现有的零样本动作泛化方法，证明了其在面对少量动作观察情况下对新动作进行有效泛化的优越性。 <div>
arXiv:2503.08867v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) has demonstrated remarkable success in solving sequential decision-making problems. However, in real-world scenarios, RL agents often struggle to generalize when faced with unseen actions that were not encountered during training. Some previous works on zero-shot action generalization rely on large datasets of action observations to capture the behaviors of new actions, making them impractical for real-world applications. In this paper, we introduce a novel zero-shot framework, Action Generalization from Limited Observations (AGLO). Our framework has two main components: an action representation learning module and a policy learning module. The action representation learning module extracts discriminative embeddings of actions from limited observations, while the policy learning module leverages the learned action representations, along with augmented synthetic action representations, to learn a policy capable of handling tasks with unseen actions. The experimental results demonstrate that our framework significantly outperforms state-of-the-art methods for zero-shot action generalization across multiple benchmark tasks, showcasing its effectiveness in generalizing to new actions with minimal action observations.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Imitation Learning of Correlated Policies in Stackelberg Games</title>
<link>https://arxiv.org/abs/2503.08883</link>
<guid>https://arxiv.org/abs/2503.08883</guid>
<content:encoded><![CDATA[
<div> 关键词: Stackelberg游戏、多智能体模仿学习（MAIL）、相关策略、潜伏Stackelberg差分网络（LSDN）、多输出几何布朗运动（MO-GBM）

总结:
本文关注的是在Stackelberg游戏中优化策略的问题。Stackelberg游戏广泛应用于经济学和安全领域，涉及不对称交互，其中领导者的策略会影响跟随者的响应。由于多智能体系统的交互行为复杂性，传统的多智能体模仿学习（MAIL）方法难以捕捉这些动态。文章指出，尽管存在旨在学习相关策略的方法（如CoDAIL），但在具有不对称决策的Stackelberg游戏中仍然面临挑战，导致政策不相关。同时，现有的MAIL方法（如GAIL或逆强化学习）在高维度环境中的可扩展性和训练稳定性方面存在问题。为解决这些问题，文章提出了一种针对Stackelberg游戏设计的相关策略占用度量，并引入了潜伏Stackelberg差分网络（LSDN），用于匹配该度量。LSDN通过共享隐状态轨迹建模双智能体交互，并利用多输出几何布朗运动（MO-GBM）有效地捕获联合策略。借助MO-GBM，LSDN能够在潜在空间中将环境影响与由代理驱动的转换解耦，从而实现相互依赖策略的同时学习，省去了对抗性训练的需求并简化了学习过程。实验结果表明，相比于现有MAIL方法，LSDN能在迭代矩阵游戏和多智能体粒子环境中更好地重现复杂的交互动力学。 <div>
arXiv:2503.08883v1 Announce Type: new 
Abstract: Stackelberg games, widely applied in domains like economics and security, involve asymmetric interactions where a leader's strategy drives follower responses. Accurately modeling these dynamics allows domain experts to optimize strategies in interactive scenarios, such as turn-based sports like badminton. In multi-agent systems, agent behaviors are interdependent, and traditional Multi-Agent Imitation Learning (MAIL) methods often fail to capture these complex interactions. Correlated policies, which account for opponents' strategies, are essential for accurately modeling such dynamics. However, even methods designed for learning correlated policies, like CoDAIL, struggle in Stackelberg games due to their asymmetric decision-making, where leaders and followers cannot simultaneously account for each other's actions, often leading to non-correlated policies. Furthermore, existing MAIL methods that match occupancy measures or use adversarial techniques like GAIL or Inverse RL face scalability challenges, particularly in high-dimensional environments, and suffer from unstable training. To address these challenges, we propose a correlated policy occupancy measure specifically designed for Stackelberg games and introduce the Latent Stackelberg Differential Network (LSDN) to match it. LSDN models two-agent interactions as shared latent state trajectories and uses multi-output Geometric Brownian Motion (MO-GBM) to effectively capture joint policies. By leveraging MO-GBM, LSDN disentangles environmental influences from agent-driven transitions in latent space, enabling the simultaneous learning of interdependent policies. This design eliminates the need for adversarial training and simplifies the learning process. Extensive experiments on Iterative Matrix Games and multi-agent particle environments demonstrate that LSDN can better reproduce complex interaction dynamics than existing MAIL methods.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ARCHED: A Human-Centered Framework for Transparent, Responsible, and Collaborative AI-Assisted Instructional Design</title>
<link>https://arxiv.org/abs/2503.08931</link>
<guid>https://arxiv.org/abs/2503.08931</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 教育技术, 人工智能, 教学设计框架, 透明度

总结:
本文介绍了一种名为ARCHED的新颖教学设计框架，该框架旨在将大型语言模型融入教育技术中，同时保持人本主义教育理念和教师决策的核心地位。ARCHED采用与布鲁姆分类法对齐的级联工作流程，利用两个专门的人工智能代理：一个生成多样化的教学策略选项，另一个评估与学习目标的一致性。与传统自动化方法相比，ARCHED强调了透明度、教学基础以及有意义的人类代理权。实证评价显示，ARCHED提升了教学设计质量并确保了教师监督的有效性，标志着教育领域负责任的人工智能整合迈出了重要的一步。<br /><br /> <div>
arXiv:2503.08931v1 Announce Type: new 
Abstract: Integrating Large Language Models (LLMs) in educational technology presents unprecedented opportunities to improve instructional design (ID), yet existing approaches often prioritize automation over pedagogical rigor and human agency. This paper introduces ARCHED (AI for Responsible, Collaborative, Human-centered Education Instructional Design), a structured multi-stage framework that ensures human educators remain central in the design process while leveraging AI capabilities. Unlike traditional AI-generated instructional materials that lack transparency, ARCHED employs a cascaded workflow aligned with Bloom's taxonomy. The framework integrates specialized AI agents - one generating diverse pedagogical options and another evaluating alignment with learning objectives - while maintaining educators as primary decision-makers. This approach addresses key limitations in current AI-assisted instructional design, ensuring transparency, pedagogical foundation, and meaningful human agency. Empirical evaluations demonstrate that ARCHED enhances instructional design quality while preserving educator oversight, marking a step forward in responsible AI integration in education.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ManeuverGPT Agentic Control for Safe Autonomous Stunt Maneuvers</title>
<link>https://arxiv.org/abs/2503.09035</link>
<guid>https://arxiv.org/abs/2503.09035</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶车辆、ManeuverGPT、大型语言模型、J-turn、CARLA模拟环境

总结:<br />
本文提出了一个名为ManeuverGPT的新框架，用于利用基于大型语言模型（LLM）的控制器为自动驾驶车辆生成并执行高动态特技动作，如J-turn。该框架在CARLA模拟环境中针对不同车型展示了通过文本提示适应不同车辆动力学特性并成功执行J-turn的能力。它包括三个专业化智能体：用户命令上下文化的情境增强代理、生成操纵参数的驾驶员代理以及确保符合物理约束和安全性的参数验证代理。实验结果显示了通过文本提示对控制参数进行迭代优化而无需重新训练模型权重即可成功执行高动态规避动作的可能性。文章还评估了性能并通过既定的成功标准进行了讨论，并指出了关于数值精度和场景复杂性方面的局限性。研究结果强调了LLM驱动控制对于灵活、高动态规避动作的潜力，同时突显了结合语言推理与算法验证的混合方法的重要性。 <div>
arXiv:2503.09035v1 Announce Type: new 
Abstract: The next generation of active safety features in autonomous vehicles should be capable of safely executing evasive hazard-avoidance maneuvers akin to those performed by professional stunt drivers to achieve high-agility motion at the limits of vehicle handling. This paper presents a novel framework, ManeuverGPT, for generating and executing high-dynamic stunt maneuvers in autonomous vehicles using large language model (LLM)-based agents as controllers. We target aggressive maneuvers, such as J-turns, within the CARLA simulation environment and demonstrate an iterative, prompt-based approach to refine vehicle control parameters, starting tabula rasa without retraining model weights. We propose an agentic architecture comprised of three specialized agents (1) a Query Enricher Agent for contextualizing user commands, (2) a Driver Agent for generating maneuver parameters, and (3) a Parameter Validator Agent that enforces physics-based and safety constraints. Experimental results demonstrate successful J-turn execution across multiple vehicle models through textual prompts that adapt to differing vehicle dynamics. We evaluate performance via established success criteria and discuss limitations regarding numeric precision and scenario complexity. Our findings underscore the potential of LLM-driven control for flexible, high-dynamic maneuvers, while highlighting the importance of hybrid approaches that combine language-based reasoning with algorithmic validation.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Incentive Analysis for Agent Participation in Federated Learning</title>
<link>https://arxiv.org/abs/2503.09039</link>
<guid>https://arxiv.org/abs/2503.09039</guid>
<content:encoded><![CDATA[
<div> 关键词：federated learning、决策行为、均衡策略、stage game、repeated game

<br /><br />总结：
本文研究了联邦学习中的决策制定和均衡行为，其中多个代理在保护数据隐私的同时协同训练模型。文章首先将问题建模为阶段游戏，并进一步扩展到重复游戏以分析长期参与动态。对于阶段游戏，论文刻画了参与模式并确定了纳什均衡，揭示了数据异质性如何影响均衡行为——具有相似数据质量的代理会作为群体参与FL。此外，文中推导出了最优社会福利，并在温和假设下证明其与纳什均衡一致。在重复游戏中，提出了一个兼顾隐私保护和计算效率的近视策略，使得代理在有限理性条件下能做出实际决策，并在有限时间内收敛至阶段游戏纳什均衡的邻域。通过结合理论洞察与实用策略设计，该工作为指导和分析联邦学习系统中代理行为提供了一个现实有效的方法框架。 <div>
arXiv:2503.09039v1 Announce Type: new 
Abstract: Federated learning offers a decentralized approach to machine learning, where multiple agents collaboratively train a model while preserving data privacy. In this paper, we investigate the decision-making and equilibrium behavior in federated learning systems, where agents choose between participating in global training or conducting independent local training. The problem is first modeled as a stage game and then extended to a repeated game to analyze the long-term dynamics of agent participation. For the stage game, we characterize the participation patterns and identify Nash equilibrium, revealing how data heterogeneity influences the equilibrium behavior-specifically, agents with similar data qualities will participate in FL as a group. We also derive the optimal social welfare and show that it coincides with Nash equilibrium under mild assumptions. In the repeated game, we propose a privacy-preserving, computationally efficient myopic strategy. This strategy enables agents to make practical decisions under bounded rationality and converges to a neighborhood of Nash equilibrium of the stage game in finite time. By combining theoretical insights with practical strategy design, this work provides a realistic and effective framework for guiding and analyzing agent behaviors in federated learning systems.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LocAgent: Graph-Guided LLM Agents for Code Localization</title>
<link>https://arxiv.org/abs/2503.09089</link>
<guid>https://arxiv.org/abs/2503.09089</guid>
<content:encoded><![CDATA[
<div> 关键词: code localization, LocAgent, graph-based representation, LLM agents, Qwen-2.5-Coder-Instruct-32B模型

总结:
本文介绍了一个名为LocAgent的新框架，用于解决软件维护中的代码定位问题。LocAgent通过将代码库解析成异质有向图来构建轻量级表示形式，从而捕捉代码结构（文件、类、函数）及其依赖关系（导入、调用、继承），使LLM代理能够有效地搜索和定位相关实体。实验结果显示，该方法显著提高了代码定位的准确性。具体而言，使用微调后的Qwen-2.5-Coder-Instruct-32B模型，与现有最先进的专有模型相比，在降低约86%的成本的同时，能达到高达92.7%的文件级定位精度，并且对于多次尝试下的GitHub问题解决成功率提升了12%（Pass@10）。研究成果已开源，可在https://github.com/gersteinlab/LocAgent获取。 <div>
arXiv:2503.09089v1 Announce Type: new 
Abstract: Code localization--identifying precisely where in a codebase changes need to be made--is a fundamental yet challenging task in software maintenance. Existing approaches struggle to efficiently navigate complex codebases when identifying relevant code sections. The challenge lies in bridging natural language problem descriptions with the appropriate code elements, often requiring reasoning across hierarchical structures and multiple dependencies. We introduce LocAgent, a framework that addresses code localization through graph-based representation. By parsing codebases into directed heterogeneous graphs, LocAgent creates a lightweight representation that captures code structures (files, classes, functions) and their dependencies (imports, invocations, inheritance), enabling LLM agents to effectively search and locate relevant entities through powerful multi-hop reasoning. Experimental results on real-world benchmarks demonstrate that our approach significantly enhances accuracy in code localization. Notably, our method with the fine-tuned Qwen-2.5-Coder-Instruct-32B model achieves comparable results to SOTA proprietary models at greatly reduced cost (approximately 86% reduction), reaching up to 92.7% accuracy on file-level localization while improving downstream GitHub issue resolution success rates by 12% for multiple attempts (Pass@10). Our code is available at https://github.com/gersteinlab/LocAgent.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Driven Inverse Optimal Control for Continuous-Time Nonlinear Systems</title>
<link>https://arxiv.org/abs/2503.09090</link>
<guid>https://arxiv.org/abs/2503.09090</guid>
<content:encoded><![CDATA[
<div> 关键词：模型自由、部分模型自由、逆最优控制、连续时间非线性系统、估计成本函数

<br /><br />总结:
本文提出了两种新颖的逆最优控制（也称逆强化学习）算法，针对的是连续时间非线性确定性系统的成本函数估计问题。这两种算法分别利用专家代理的输入状态轨迹以及控制策略信息和Hamilton-Jacobi-Bellman方程来独立估计不同的成本函数参数集合，从而增加了算法的适用范围并保持了模型自由的框架。其中，模型自由算法相比现有方法降低了复杂度，仅需在初始化阶段解决一次前向最优控制问题；而部分模型自由算法则在输入动态已知的情况下，甚至可以完全绕过这一步骤。模拟结果验证了所提算法的有效性和效率，展现出它们在实际中的应用潜力，特别是在自主系统和机器人领域的部署。 <div>
arXiv:2503.09090v1 Announce Type: new 
Abstract: This paper introduces a novel model-free and a partially model-free algorithm for inverse optimal control (IOC), also known as inverse reinforcement learning (IRL), aimed at estimating the cost function of continuous-time nonlinear deterministic systems. Using the input-state trajectories of an expert agent, the proposed algorithms separately utilize control policy information and the Hamilton-Jacobi-Bellman equation to estimate different sets of cost function parameters. This approach allows the algorithms to achieve broader applicability while maintaining a model-free framework. Also, the model-free algorithm reduces complexity compared to existing methods, as it requires solving a forward optimal control problem only once during initialization. Furthermore, in our partially model-free algorithm, this step can be bypassed entirely for systems with known input dynamics. Simulation results demonstrate the effectiveness and efficiency of our algorithms, highlighting their potential for real-world deployment in autonomous systems and robotics.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>"I Like Your Story!": A Co-Creative Story-Crafting Game with a Persona-Driven Character Based on Generative AI</title>
<link>https://arxiv.org/abs/2503.09102</link>
<guid>https://arxiv.org/abs/2503.09102</guid>
<content:encoded><![CDATA[
<div> 关键词：生成式AI、创造性写作、1001夜、AI代理、游戏化叙事

总结:<br />
本文介绍了将创造性写作转变为一种有趣并具有奖励性的活动——“1001夜”故事创作游戏。在这个游戏中，AI代理扮演了一个有独特讲故事偏好的“情绪化”国王角色，它不仅辅助写作，还能积极影响故事情节。玩家通过策略性地讲述故事来引导AI国王提及与武器相关的关键词，这些关键词会转化为战斗装备。AI国王会对玩家的故事给出动态反馈，表达满意或不满，促使玩家调整写作策略。该系统通过结合故事叙述、游戏机制和AI驱动的响应，激励玩家在游戏化的约束中发挥创造力，体现了AI驱动的游戏体验如何使创造性写作变得更加易接触和吸引人，鼓励玩家发掘自己的创造潜力。这一方法受到了Oulipo文学技巧的启发。 <div>
arXiv:2503.09102v1 Announce Type: new 
Abstract: While generative AI is advancing writing support tools, creative writing is often seen as the exclusive domain of skilled writers. This paper introduces "1001 Nights", a co-creative story-crafting game that transforms writing into a playful and rewarding activity. In this game, the AI agent takes on the role of a "moody" king with distinct storytelling preferences, not merely assisting but actively influencing the narrative. Players engage with the king agent through strategic storytelling, guiding him to mention weapon-related keywords, which materialize as battle equipment. The king agent provides dynamic feedback, expressing satisfaction or displeasure, prompting players to adjust their approach. By combining storytelling, game mechanics, and AI-driven responses, our system motivates creativity through playful constraints. Inspired by Oulipo's literary techniques, this approach demonstrates how AI-powered game experiences can make creative writing more accessible and engaging, encouraging players to explore their creative potential.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AdaptAI: A Personalized Solution to Sense Your Stress, Fix Your Mess, and Boost Productivity</title>
<link>https://arxiv.org/abs/2503.09150</link>
<guid>https://arxiv.org/abs/2503.09150</guid>
<content:encoded><![CDATA[
<div> 关键词：Personalization、AdaptAI、multimodal AI、productivity support、well-being interventions

<br /><br />总结:
本文介绍了AdaptAI，一种结合了 Egocentric 视觉和音频、心率与运动活动监测，以及大型语言模型（LLMs）的工作流代理机制的多模态人工智能解决方案。AdaptAI 不仅为用户自动化处理如起草文档摘要、回复邮件等外围任务，还能通过持续监控用户的独特生理和情境指标，在恰当时机动态调整个性化的干预措施，例如微休息建议或锻炼提示。初步研究显示，AdaptAI 在预判用户压力源、优化日常工作流程方面表现出显著提升任务处理效率和用户满意度的效果。 <div>
arXiv:2503.09150v1 Announce Type: new 
Abstract: Personalization is a critical yet often overlooked factor in boosting productivity and wellbeing in knowledge-intensive workplaces to better address individual preferences. Existing tools typically offer uniform guidance whether auto-generating email responses or prompting break reminders without accounting for individual behavioral patterns or stress triggers. We introduce AdaptAI, a multimodal AI solution combining egocentric vision and audio, heart and motion activities, and the agentic workflow of Large Language Models LLMs to deliver highly personalized productivity support and context-aware well-being interventions. AdaptAI not only automates peripheral tasks (e.g. drafting succinct document summaries, replying to emails etc.) but also continuously monitors the users unique physiological and situational indicators to dynamically tailor interventions such as micro-break suggestions or exercise prompts, at the exact point of need. In a preliminary study with 15 participants, AdaptAI demonstrated significant improvements in task throughput and user satisfaction by anticipating user stressors and streamlining daily workflows.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rethinking Bimanual Robotic Manipulation: Learning with Decoupled Interaction Framework</title>
<link>https://arxiv.org/abs/2503.09186</link>
<guid>https://arxiv.org/abs/2503.09186</guid>
<content:encoded><![CDATA[
<div> 关键词：bimanual robotic manipulation, decoupled interaction framework, uncoordinated tasks, coordinated tasks, RoboTwin dataset

<br /><br />总结：
本文提出了一种新颖的解耦交互框架用于双臂机器人操作，该框架针对双臂操纵中的协同和非协同任务特性进行设计。与以往依赖集成控制模型的方法不同，新框架为每只手臂分配独立模型以强化非协同任务的学习，同时引入了一个选择性交互模块，自适应地从自身手臂学习权重以提升协同任务的学习效果。实验表明，该框架在RoboTwin数据集上的七项任务中表现出色，相比当前最优方法性能提升了23.5%，具有较好的灵活性并能无缝融入现有方法。此外，该框架还可扩展到多智能体操纵任务，相对于集成控制的SOTA方法提高了28%的成功率。进一步分析显示，仅使用六分之一的模型大小，仅依靠解耦设计本身，其成功概率就已超过SOTA方法16.5%。 <div>
arXiv:2503.09186v1 Announce Type: new 
Abstract: Bimanual robotic manipulation is an emerging and critical topic in the robotics community. Previous works primarily rely on integrated control models that take the perceptions and states of both arms as inputs to directly predict their actions. However, we think bimanual manipulation involves not only coordinated tasks but also various uncoordinated tasks that do not require explicit cooperation during execution, such as grasping objects with the closest hand, which integrated control frameworks ignore to consider due to their enforced cooperation in the early inputs. In this paper, we propose a novel decoupled interaction framework that considers the characteristics of different tasks in bimanual manipulation. The key insight of our framework is to assign an independent model to each arm to enhance the learning of uncoordinated tasks, while introducing a selective interaction module that adaptively learns weights from its own arm to improve the learning of coordinated tasks. Extensive experiments on seven tasks in the RoboTwin dataset demonstrate that: (1) Our framework achieves outstanding performance, with a 23.5% boost over the SOTA method. (2) Our framework is flexible and can be seamlessly integrated into existing methods. (3) Our framework can be effectively extended to multi-agent manipulation tasks, achieving a 28% boost over the integrated control SOTA. (4) The performance boost stems from the decoupled design itself, surpassing the SOTA by 16.5% in success rate with only 1/6 of the model size.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>City Models: Past, Present and Future Prospects</title>
<link>https://arxiv.org/abs/2503.09237</link>
<guid>https://arxiv.org/abs/2503.09237</guid>
<content:encoded><![CDATA[
<div> 关键词: 城市规划, 智能AI模型, 多模态生成模型, 公民参与, 社会AI城市生态系统

<br /><br />总结:
本文探讨了城市特征的时空结构和动态过程建模挑战，并指出在城市规划和运营中，对公民心态的相关表示通常被忽视。文章回顾了传统的城市形态、规模及动力学模型，并关注到近期人工智能领域的多模态生成模型，它们能创造几何、网络和图像的表示，以及在人类可理解的语义层面上灵活推理。这些新模型从海量文本和图像数据中抽取大量知识，涵盖了包括不同来源、粒度和尺度的地理知识在内的丰富表示谱系。

文章进一步讨论了这些新技术对城市建模挑战的意义，特别是关于公民及其与城市基础设施互动的角色和影响。作者建议将此类新机会与现有的如基于代理的模型等方法相结合，从而构建能够体现社会交互的丰富市民模型。

最后，文章提出了一个“社会AI在城市生态系统的”愿景，即通过将相关的公民模型加入到先进的结构和过程模型中，形成扩展的城市表现形式。这种拓展的城市表征将使城市规划者能够在考虑公民需求的基础上，实现城市基础设施的人文文化、韧性和可持续性规划。 <div>
arXiv:2503.09237v1 Announce Type: new 
Abstract: We attempt to take a comprehensive look at the challenges of representing the spatio-temporal structures and dynamic processes defining a city's overall characteristics. For the task of urban planning and urban operation, we take the stance that even if the necessary representations of these structures and processes can be achieved, the most important representation of the relevant mindsets of the citizens are, unfortunately, mostly neglected.
  After a review of major "traditional" urban models of structures behind urban scale, form, and dynamics, we turn to major recent modeling approaches triggered by recent advances in AI that enable multi-modal generative models. Some of these models can create representations of geometries, networks and images, and reason flexibly at a human-compatible semantic level. They provide huge amounts of knowledge extracted from Terabytes of text and image documents and cover the required rich representation spectrum including geographic knowledge by different knowledge sources, degrees of granularity and scales.
  We then discuss what these new opportunities mean for the modeling challenges posed by cities, in particular with regard to the role and impact of citizens and their interactions within the city infrastructure. We propose to integrate these possibilities with existing approaches, such as agent-based models, which opens up new modeling spaces including rich citizen models which are able to also represent social interactions.
  Finally, we put forward some thoughts about a vision of a "social AI in a city ecosystem" that adds relevant citizen models to state-of-the-art structural and process models. This extended city representation will enable urban planners to establish citizen-oriented planning of city infrastructures for human culture, city resilience and sustainability.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>In-Context Defense in Computer Agents: An Empirical Study</title>
<link>https://arxiv.org/abs/2503.09241</link>
<guid>https://arxiv.org/abs/2503.09241</guid>
<content:encoded><![CDATA[
<div> 关键词: 计算机代理、视觉-语言模型、环境欺骗攻击、防御策略、在上下文学习

总结:
本文研究了针对计算机代理的新型威胁——环境欺骗攻击，并提出了一种名为“在上下文防御”的新方法。此方法利用在上下文学习和链式思考（CoT）推理来对抗这类攻击。通过向代理的上下文中添加少量精心策划的示例，包括恶意环境及其对应的防御性响应，引导代理在行动规划前首先进行显式的防御性推理，从而降低对欺骗攻击的易感性。实验结果显示，该方法能有效降低弹窗攻击的成功率91.2%，平均降低环境注入攻击的成功率74.6%，并实现对分散注意力广告的100%成功防御。研究发现，为了达到最优性能，防御性推理必须先于行动规划执行，并且只需极少数（少于三个）的示例就足以诱导代理产生防御行为。 <div>
arXiv:2503.09241v1 Announce Type: new 
Abstract: Computer agents powered by vision-language models (VLMs) have significantly advanced human-computer interaction, enabling users to perform complex tasks through natural language instructions. However, these agents are vulnerable to context deception attacks, an emerging threat where adversaries embed misleading content into the agent's operational environment, such as a pop-up window containing deceptive instructions. Existing defenses, such as instructing agents to ignore deceptive elements, have proven largely ineffective. As the first systematic study on protecting computer agents, we introduce textbf{in-context defense}, leveraging in-context learning and chain-of-thought (CoT) reasoning to counter such attacks. Our approach involves augmenting the agent's context with a small set of carefully curated exemplars containing both malicious environments and corresponding defensive responses. These exemplars guide the agent to first perform explicit defensive reasoning before action planning, reducing susceptibility to deceptive attacks. Experiments demonstrate the effectiveness of our method, reducing attack success rates by 91.2% on pop-up window attacks, 74.6% on average on environment injection attacks, while achieving 100% successful defenses against distracting advertisements. Our findings highlight that (1) defensive reasoning must precede action planning for optimal performance, and (2) a minimal number of exemplars (fewer than three) is sufficient to induce an agent's defensive behavior.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large-scale Regional Traffic Signal Control Based on Single-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.09252</link>
<guid>https://arxiv.org/abs/2503.09252</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通信号控制, 单一代理人强化学习, 交通拥堵, 总旅行时间, SUMO仿真软件

总结:
本文提出了一种基于单一代理人强化学习（RL）的区域交通信号控制（TSC）模型，旨在解决全球城市化和机动化背景下日益严重的交通拥堵问题。该模型能够对大面积范围内的交通信号进行协调，目标在于缓解区域交通拥堵并最小化总旅行时间。通过定义具体的环境状态空间、动作空间和奖励函数来构建TSC环境，其中状态空间包括当前各链接的排队长度及交叉口的信号相位方案。实验使用SUMO交通模拟软件进行，对比无信号定时调整的基线情况，结果表明该模型能有效控制交通拥堵，显著减少排队长度。当奖励函数同时关注缓解拥堵和最小化总旅行时间时，平均旅行时间明显降低，证明了模型对于改善交通状况的有效性。这项研究为大规模区域性交通信号控制提供了新的方法，并对未来城市交通管理提供了有价值的见解。 <div>
arXiv:2503.09252v1 Announce Type: new 
Abstract: In the context of global urbanization and motorization, traffic congestion has become a significant issue, severely affecting the quality of life, environment, and economy. This paper puts forward a single-agent reinforcement learning (RL)-based regional traffic signal control (TSC) model. Different from multi - agent systems, this model can coordinate traffic signals across a large area, with the goals of alleviating regional traffic congestion and minimizing the total travel time. The TSC environment is precisely defined through specific state space, action space, and reward functions. The state space consists of the current congestion state, which is represented by the queue lengths of each link, and the current signal phase scheme of intersections. The action space is designed to select an intersection first and then adjust its phase split. Two reward functions are meticulously crafted. One focuses on alleviating congestion and the other aims to minimize the total travel time while considering the congestion level. The experiments are carried out with the SUMO traffic simulation software. The performance of the TSC model is evaluated by comparing it with a base case where no signal-timing adjustments are made. The results show that the model can effectively control congestion. For example, the queuing length is significantly reduced in the scenarios tested. Moreover, when the reward is set to both alleviate congestion and minimize the total travel time, the average travel time is remarkably decreased, which indicates that the model can effectively improve traffic conditions. This research provides a new approach for large-scale regional traffic signal control and offers valuable insights for future urban traffic management.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>COLA: A Scalable Multi-Agent Framework For Windows UI Task Automation</title>
<link>https://arxiv.org/abs/2503.09263</link>
<guid>https://arxiv.org/abs/2503.09263</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、Windows GUI 操作、动态适应、错误恢复机制、COLA框架

<br /><br />总结:
本文介绍了针对Windows操作系统UI自动化操作的研究现状及挑战，提出了一种名为“COLA”的协作多代理框架。该框架通过场景感知的任务调度器将任务需求分解为原子能力单元，并动态选择决策代理池中的最佳代理以应对多样化场景的需求，支持灵活的插件式扩展。同时，COLA为所有代理设计了记忆单元以实现自我进化。更重要的是，文章提出了交互式回溯机制，允许人类介入触发状态回滚以实现非破坏性过程修复。实验结果显示，COLA框架在GAIA基准测试中取得了平均31.89%的最优性能，显著优于未集成Web API的基线方法。此外，消融研究进一步验证了动态调度策略的贡献。相关代码已开源，可在https://github.com/Alokia/COLA-demo获取。 <div>
arXiv:2503.09263v1 Announce Type: new 
Abstract: With the rapid advancements in Large Language Models (LLMs), an increasing number of studies have leveraged LLMs as the cognitive core of agents to address complex task decision-making challenges. Specially, recent research has demonstrated the potential of LLM-based agents on automating Windows GUI operations. However, existing methodologies exhibit two critical challenges: (1) static agent architectures fail to dynamically adapt to the heterogeneous requirements of OS-level tasks, leading to inadequate scenario generalization;(2) the agent workflows lack fault tolerance mechanism, necessitating complete process re-execution for UI agent decision error. To address these limitations, we introduce \textit{COLA}, a collaborative multi-agent framework for automating Windows UI operations. In this framework, a scenario-aware agent Task Scheduler decomposes task requirements into atomic capability units, dynamically selects the optimal agent from a decision agent pool, effectively responds to the capability requirements of diverse scenarios. The decision agent pool supports plug-and-play expansion for enhanced flexibility. In addition, we design a memory unit equipped to all agents for their self-evolution. Furthermore, we develop an interactive backtracking mechanism that enables human to intervene to trigger state rollbacks for non-destructive process repair. Our experimental results on the GAIA benchmark demonstrates that the \textit{COLA} framework achieves state-of-the-art performance with an average score of 31.89\%, significantly outperforming baseline approaches without web API integration. Ablation studies further validate the individual contributions of our dynamic scheduling. The code is available at https://github.com/Alokia/COLA-demo.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Steering No-Regret Agents in MFGs under Model Uncertainty</title>
<link>https://arxiv.org/abs/2503.09309</link>
<guid>https://arxiv.org/abs/2503.09309</guid>
<content:encoded><![CDATA[
<div> 关键词: Incentive design, Mean-Field Games, Model uncertainty, Exploration algorithms, Regret guarantees

总结:<br />
本文研究了在密度独立转移的均值场游戏中，如何设计引导奖励以在模型不确定性的条件下，引导大量代理学习并趋向期望行为。文章针对大多数现有工作局限于有限数量的代理人或完全了解游戏的情况，提出了一种新的框架。在这一设置中，调解者需要在不确定性下激励代理人进行探索性学习，同时在不产生过多激励支付的情况下引导他们收敛到期望的行为。假设代理人表现出无（适应性）遗憾行为，作者贡献了一种新颖的乐观探索算法，并理论上建立了代理人行为与期望行为之间累计差距的次线性遗憾保证。对于引导成本，作者证明其总的激励支付仅产生次线性的超额费用，与将目标策略作为均衡稳定化的基线引导策略竞争。这项工作为在大规模系统中在不确定性下引导代理人行为提供了一个有效的框架。 <div>
arXiv:2503.09309v1 Announce Type: new 
Abstract: Incentive design is a popular framework for guiding agents' learning dynamics towards desired outcomes by providing additional payments beyond intrinsic rewards. However, most existing works focus on a finite, small set of agents or assume complete knowledge of the game, limiting their applicability to real-world scenarios involving large populations and model uncertainty. To address this gap, we study the design of steering rewards in Mean-Field Games (MFGs) with density-independent transitions, where both the transition dynamics and intrinsic reward functions are unknown. This setting presents non-trivial challenges, as the mediator must incentivize the agents to explore for its model learning under uncertainty, while simultaneously steer them to converge to desired behaviors without incurring excessive incentive payments. Assuming agents exhibit no(-adaptive) regret behaviors, we contribute novel optimistic exploration algorithms. Theoretically, we establish sub-linear regret guarantees for the cumulative gaps between the agents' behaviors and the desired ones. In terms of the steering cost, we demonstrate that our total incentive payments incur only sub-linear excess, competing with a baseline steering strategy that stabilizes the target policy as an equilibrium. Our work presents an effective framework for steering agents behaviors in large-population systems under uncertainty.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>2HandedAfforder: Learning Precise Actionable Bimanual Affordances from Human Videos</title>
<link>https://arxiv.org/abs/2503.09320</link>
<guid>https://arxiv.org/abs/2503.09320</guid>
<content:encoded><![CDATA[
<div> 关键词：affordance, 视觉识别, 双手操作, 数据集, 机器人操纵

总结:<br />
本文提出了一种从人类活动视频中提取对象功能区域数据的框架，并创建了名为2HANDS的新数据集，该数据集包含了精确的对象功能区域分割和作为活动叙述的功能类别标签，同时考虑到了双手协作交互的情况。针对这一问题，文中还提出了一种基于视觉语言模型（VLM）的双手法则预测模型——2HandedAfforder，在各类活动的功能区域分割任务上展示了优于基线的方法性能。最后，通过在机器人操纵场景中的演示证明，所预测的功能区域具有可执行性，即可以被智能体用于执行任务。 <div>
arXiv:2503.09320v1 Announce Type: new 
Abstract: When interacting with objects, humans effectively reason about which regions of objects are viable for an intended action, i.e., the affordance regions of the object. They can also account for subtle differences in object regions based on the task to be performed and whether one or two hands need to be used. However, current vision-based affordance prediction methods often reduce the problem to naive object part segmentation. In this work, we propose a framework for extracting affordance data from human activity video datasets. Our extracted 2HANDS dataset contains precise object affordance region segmentations and affordance class-labels as narrations of the activity performed. The data also accounts for bimanual actions, i.e., two hands co-ordinating and interacting with one or more objects. We present a VLM-based affordance prediction model, 2HandedAfforder, trained on the dataset and demonstrate superior performance over baselines in affordance region segmentation for various activities. Finally, we show that our predicted affordance regions are actionable, i.e., can be used by an agent performing a task, through demonstration in robotic manipulation scenarios.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Post-interactive Multimodal Trajectory Prediction for Autonomous Driving</title>
<link>https://arxiv.org/abs/2503.09366</link>
<guid>https://arxiv.org/abs/2503.09366</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、轨迹预测、交互建模、Transformer、Pioformer

总结:
本文提出了一种用于多模态轨迹预测的新方法——Pioformer，旨在解决自动驾驶中由于代理人行为不确定性带来的轨迹预测挑战。该方法着重考虑了预测轨迹中的交互效应，即后交互特征。Pioformer采用粗细粒度的Transformer结构，首先通过构建粗略轨迹网络，利用图神经网络提取低阶交互特征生成粗略轨迹；接着，利用基于超图神经网络的轨迹提案网络生成轨迹提案，学习高阶交互特征；最后，将观察到的轨迹和轨迹提案输入至提案精细化网络进行进一步细化，其中结合先前交互特征与轨迹一致性特征来学习后交互特征。此外，还提出了三阶段训练方案以促进学习过程。在Argoverse 1数据集上的大量实验结果显示，相较于基线HiVT-64，本文的方法在minADE6、minFDE6、MR6和brier-minFDE6四个评价指标上分别降低了4.4%、8.4%、14.4%和5.7%，验证了其优越性。<br /><br /> <div>
arXiv:2503.09366v1 Announce Type: new 
Abstract: Modeling the interactions among agents for trajectory prediction of autonomous driving has been challenging due to the inherent uncertainty in agents' behavior. The interactions involved in the predicted trajectories of agents, also called post-interactions, have rarely been considered in trajectory prediction models. To this end, we propose a coarse-to-fine Transformer for multimodal trajectory prediction, i.e., Pioformer, which explicitly extracts the post-interaction features to enhance the prediction accuracy. Specifically, we first build a Coarse Trajectory Network to generate coarse trajectories based on the observed trajectories and lane segments, in which the low-order interaction features are extracted with the graph neural networks. Next, we build a hypergraph neural network-based Trajectory Proposal Network to generate trajectory proposals, where the high-order interaction features are learned by the hypergraphs. Finally, the trajectory proposals are sent to the Proposal Refinement Network for further refinement. The observed trajectories and trajectory proposals are concatenated together as the inputs of the Proposal Refinement Network, in which the post-interaction features are learned by combining the previous interaction features and trajectory consistency features. Moreover, we propose a three-stage training scheme to facilitate the learning process. Extensive experiments on the Argoverse 1 dataset demonstrate the superiority of our method. Compared with the baseline HiVT-64, our model has reduced the prediction errors by 4.4%, 8.4%, 14.4%, 5.7% regarding metrics minADE6, minFDE6, MR6, and brier-minFDE6, respectively.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task Allocation for Multi-agent Systems via Unequal-dimensional Optimal Transport</title>
<link>https://arxiv.org/abs/2503.09369</link>
<guid>https://arxiv.org/abs/2503.09369</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模任务分配、多代理系统、优化部署策略、运输成本、线性规划问题

<br />
总结:
本文研究了一个针对大规模任务分配问题的随机模型，旨在确定一种最优部署策略以最小化总体运输成本。该模型将运输代理人与具有指定取货和送货地点的任务相匹配，与不等维设置下的最优质量传输框架相对应。具体来说，任务分配问题被视作一个线性规划问题，目标是最小化二次运输成本函数，优化所有运输单元的能量。此问题受到使用无人机进行时间敏感医疗配送（如紧急设备和血液运输）的实际启发。文中证明了最优解的存在性、唯一性和光滑性，并通过数值模拟展示了其性质。 <div>
arXiv:2503.09369v1 Announce Type: new 
Abstract: We consider a probabilistic model for large-scale task allocation problems for multi-agent systems, aiming to determine an optimal deployment strategy that minimizes the overall transport cost. Specifically, we assign transportation agents to delivery tasks with given pick-up and drop-off locations, pairing the spatial distribution of transport resources with the joint distribution of task origins and destinations. This aligns with the optimal mass transport framework where the problem and is in the unequal-dimensional setting. The task allocation problem can be thus seen as a linear programming problem that minimizes a quadratic transport cost functional, optimizing the energy of all transport units. The problem is motivated by time-sensitive medical deliveries using drones, such as emergency equipment and blood transport. In this paper, we establish the existence, uniqueness, and smoothness of the optimal solution, and illustrate its properties through numerical simulations.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Faithful and Privacy-Preserving Implementation of Average Consensus</title>
<link>https://arxiv.org/abs/2503.09381</link>
<guid>https://arxiv.org/abs/2503.09381</guid>
<content:encoded><![CDATA[
<div> 关键词: 机制设计理论, 加密控制, 平均共识问题, 理性代理人, 隐私保护

总结:
本文提出了一种基于机制设计理论和加密控制协议，旨在解决理性、战略性的代理人间的平均共识问题同时保持其隐私。该协议提供了一个激励机制，促使代理人们忠实执行协议规定的意图行为。此外，通过使用同态加密和秘密共享技术，协议在加密数据上运行，从而保护了代理人的隐私。文中还运用安全多方计算的模拟范式分析了所提协议的安全性。此协议表明，机制设计理论与加密控制可以相互补充，实现对理性敌手的安全保障。 <div>
arXiv:2503.09381v1 Announce Type: new 
Abstract: We propose a protocol based on mechanism design theory and encrypted control to solve average consensus problems among rational and strategic agents while preserving their privacy. The proposed protocol provides a mechanism that incentivizes the agents to faithfully implement the intended behavior specified in the protocol. Furthermore, the protocol runs over encrypted data using homomorphic encryption and secret sharing to protect the privacy of agents. We also analyze the security of the proposed protocol using a simulation paradigm in secure multi-party computation. The proposed protocol demonstrates that mechanism design and encrypted control can complement each other to achieve security under rational adversaries.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PCLA: A Framework for Testing Autonomous Agents in the CARLA Simulator</title>
<link>https://arxiv.org/abs/2503.09385</link>
<guid>https://arxiv.org/abs/2503.09385</guid>
<content:encoded><![CDATA[
<div> 关键词：CARLA、自动驾驶代理、仿真环境、PCLA、预训练

总结:<br />
本文介绍了针对自动驾驶代理测试领域的一项新进展，即开源Python框架PCLA（Pretrained CARLA Leaderboard Agents）。该框架包含了九个从CARLA挑战赛领奖台高绩效的预训练自主驾驶代理。PCLA旨在解决研究人员在定制化环境和场景中利用这些代理时所面临的困难，它是首个专为在任意CARLA环境中测试多种自动驾驶代理设计的基础设施。使用PCLA，研究者可以不依赖于Leaderboard代码库将领先榜上的代理部署到车辆上，也可以轻松切换不同代理而无需修改CARLA版本或编程环境。此外，PCLA与CARLA的最新版本完全兼容，同时独立于Leaderboard特定的CARLA版本。PCLA现已被公开发布在https://github.com/MasoudJTehrani/PCLA。 <div>
arXiv:2503.09385v1 Announce Type: new 
Abstract: Recent research on testing autonomous driving agents has grown significantly, especially in simulation environments. The CARLA simulator is often the preferred choice, and the autonomous agents from the CARLA Leaderboard challenge are regarded as the best-performing agents within this environment. However, researchers who test these agents, rather than training their own ones from scratch, often face challenges in utilizing them within customized test environments and scenarios. To address these challenges, we introduce PCLA (Pretrained CARLA Leaderboard Agents), an open-source Python testing framework that includes nine high-performing pre-trained autonomous agents from the Leaderboard challenges. PCLA is the first infrastructure specifically designed for testing various autonomous agents in arbitrary CARLA environments/scenarios. PCLA provides a simple way to deploy Leaderboard agents onto a vehicle without relying on the Leaderboard codebase, it allows researchers to easily switch between agents without requiring modifications to CARLA versions or programming environments, and it is fully compatible with the latest version of CARLA while remaining independent of the Leaderboard's specific CARLA version. PCLA is publicly accessible at https://github.com/MasoudJTehrani/PCLA.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Networked Communication for Decentralised Cooperative Agents in Mean-Field Control</title>
<link>https://arxiv.org/abs/2503.09400</link>
<guid>https://arxiv.org/abs/2503.09400</guid>
<content:encoded><![CDATA[
<div> 关键词：networked communication、mean-field control (MFC)、decentralised agents、online learning、global average reward

总结:
本文引入了网络化通信到均场控制（MFC）领域，特别是在分布式代理从单一、非周期性的经验系统中在线学习的场景下。研究者将近期的均场博弈算法改编应用于这一新设置，并提出了一种新颖的子程序，使网络中的代理能够从其局部邻域估计全局平均奖励。理论和实验结果表明，这种网络化通信方案使得代理能比集中式和独立架构更快地提高社会福利。通过并行计算潜在更新并传播其中表现最优的策略，该方法也可以视为解决了信贷分配问题。此外，文章还探讨了在网络游戏中，较小的通信半径可以在特定类别的游戏中改善收敛性的同时，仍优于完全独立学习的代理。文中进行了多项消融研究和额外的关于通信轮数及对通信故障鲁棒性的实验。 <div>
arXiv:2503.09400v1 Announce Type: new 
Abstract: We introduce networked communication to mean-field control (MFC) - the cooperative counterpart to mean-field games (MFGs) - and in particular to the setting where decentralised agents learn online from a single, non-episodic run of the empirical system. We adapt recent algorithms for MFGs to this new setting, as well as contributing a novel sub-routine allowing networked agents to estimate the global average reward from their local neighbourhood. We show that the networked communication scheme allows agents to increase social welfare faster than under both the centralised and independent architectures, by computing a population of potential updates in parallel and then propagating the highest-performing ones through the population, via a method that can also be seen as tackling the credit-assignment problem. We prove this new result theoretically and provide experiments that support it across numerous games, as well as exploring the empirical finding that smaller communication radii can benefit convergence in a specific class of game while still outperforming agents learning entirely independently. We provide numerous ablation studies and additional experiments on numbers of communication round and robustness to communication failures.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Image Restoration</title>
<link>https://arxiv.org/abs/2503.09403</link>
<guid>https://arxiv.org/abs/2503.09403</guid>
<content:encoded><![CDATA[
<div> 关键词：图像修复、复杂退化、MAIR、多智能体方法、真实世界退化先验

总结:<br />
本文提出了一个针对复杂图像修复问题的新型多智能体方法——MAIR。MAIR将现实世界的退化分为场景、成像和压缩三类，并反向进行恢复处理。该框架模仿了一个由调度器负责整体规划以及多个专注于特定退化的专家组成的协作团队，从而减少了搜索空间和试验努力，提高了图像质量并降低了推理成本。此外，MAIR还引入了注册机制，便于新工具的轻松整合。实验表明，相较于先前的代理型图像修复系统，MAIR在合成数据集和真实世界数据集上均表现出竞争力的表现和更高的效率。代码和模型将在未来公开可用。 <div>
arXiv:2503.09403v1 Announce Type: new 
Abstract: Image restoration (IR) is challenging due to the complexity of real-world degradations. While many specialized and all-in-one IR models have been developed, they fail to effectively handle complex, mixed degradations. Recent agentic methods RestoreAgent and AgenticIR leverage intelligent, autonomous workflows to alleviate this issue, yet they suffer from suboptimal results and inefficiency due to their resource-intensive finetunings, and ineffective searches and tool execution trials for satisfactory outputs. In this paper, we propose MAIR, a novel Multi-Agent approach for complex IR problems. We introduce a real-world degradation prior, categorizing degradations into three types: (1) scene, (2) imaging, and (3) compression, which are observed to occur sequentially in real world, and reverse them in the opposite order. Built upon this three-stage restoration framework, MAIR emulates a team of collaborative human specialists, including a "scheduler" for overall planning and multiple "experts" dedicated to specific degradations. This design minimizes search space and trial efforts, improving image quality while reducing inference costs. In addition, a registry mechanism is introduced to enable easy integration of new tools. Experiments on both synthetic and real-world datasets show that proposed MAIR achieves competitive performance and improved efficiency over the previous agentic IR system. Code and models will be made available.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Astrea: A MOE-based Visual Understanding Model with Progressive Alignment</title>
<link>https://arxiv.org/abs/2503.09445</link>
<guid>https://arxiv.org/abs/2503.09445</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉语言模型(VLM), 混合专家(MoE)架构, Astrea, 进步预对齐, 动态知识融合

总结:<br />
本文提出了一种名为Astrea的新颖多专家协同视觉语言模型(VLM)架构，旨在解决基于MoE架构的VLM在处理任务异质性和专家负载不平衡问题。Astrea包含三个关键创新点：1) 引入了一个异构专家协调机制，将检测、分割、分类和captioning四种专门模型整合为覆盖核心视觉理解元素的综合专家矩阵；2) 设计了一种动态知识融合策略，通过进步预对齐的对比学习方法在VLM潜在空间中实现专家间的和谐，并辅以概率性激活的随机残差连接来保持知识连续性；3) 利用了动量对比学习进行长期依赖建模以及自适应权重分配器实时校准专家贡献度的增强优化框架。通过对涵盖VQA、图像captioning和跨模态检索等12项基准任务的广泛评估，Astrea显示出优于现有最优模型的表现，平均性能提升了+4.7%。这项研究首次实证了进步预对齐策略可使VLM克服任务异质性的限制，为构建通用型多模态代理奠定了新的方法论基础。 <div>
arXiv:2503.09445v1 Announce Type: new 
Abstract: Vision-Language Models (VLMs) based on Mixture-of-Experts (MoE) architectures have emerged as a pivotal paradigm in multimodal understanding, offering a powerful framework for integrating visual and linguistic information. However, the increasing complexity and diversity of tasks present significant challenges in coordinating load balancing across heterogeneous visual experts, where optimizing one specialist's performance often compromises others' capabilities. To address task heterogeneity and expert load imbalance, we propose Astrea, a novel multi-expert collaborative VLM architecture based on progressive pre-alignment. Astrea introduces three key innovations: 1) A heterogeneous expert coordination mechanism that integrates four specialized models (detection, segmentation, classification, captioning) into a comprehensive expert matrix covering essential visual comprehension elements; 2) A dynamic knowledge fusion strategy featuring progressive pre-alignment to harmonize experts within the VLM latent space through contrastive learning, complemented by probabilistically activated stochastic residual connections to preserve knowledge continuity; 3) An enhanced optimization framework utilizing momentum contrastive learning for long-range dependency modeling and adaptive weight allocators for real-time expert contribution calibration. Extensive evaluations across 12 benchmark tasks spanning VQA, image captioning, and cross-modal retrieval demonstrate Astrea's superiority over state-of-the-art models, achieving an average performance gain of +4.7\%. This study provides the first empirical demonstration that progressive pre-alignment strategies enable VLMs to overcome task heterogeneity limitations, establishing new methodological foundations for developing general-purpose multimodal agents.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Language Splatting</title>
<link>https://arxiv.org/abs/2503.09447</link>
<guid>https://arxiv.org/abs/2503.09447</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、3D环境、语言与空间对齐、在线语言着色、3DGS-SLAM

总结:

本文提出了一种名为在线语言着色(Online Language Splatting)的新框架，用于解决AI代理在准确感知3D世界的同时，将人类语言与3D空间表示对齐的问题。该框架是首个实现在线、近实时、开放词汇量的语言映射技术，无需预先生成语言特征。文章主要创新点包括：1）设计了一个高分辨率CLIP嵌入模块，能够在每帧18毫秒内生成详细的语言特征图；2）提出了一个两阶段在线自编码器，能将768维的CLIP特征压缩至15维，同时保持开放词汇能力；3）开发了一种颜色-语言解耦优化方法，以提升渲染质量。实验结果显示，这种方法不仅在准确性上超越了现有的离线方法，而且效率提高了超过40倍，显示出其在动态和交互式AI应用中的潜力。 <div>
arXiv:2503.09447v1 Announce Type: new 
Abstract: To enable AI agents to interact seamlessly with both humans and 3D environments, they must not only perceive the 3D world accurately but also align human language with 3D spatial representations. While prior work has made significant progress by integrating language features into geometrically detailed 3D scene representations using 3D Gaussian Splatting (GS), these approaches rely on computationally intensive offline preprocessing of language features for each input image, limiting adaptability to new environments. In this work, we introduce Online Language Splatting, the first framework to achieve online, near real-time, open-vocabulary language mapping within a 3DGS-SLAM system without requiring pre-generated language features. The key challenge lies in efficiently fusing high-dimensional language features into 3D representations while balancing the computation speed, memory usage, rendering quality and open-vocabulary capability. To this end, we innovatively design: (1) a high-resolution CLIP embedding module capable of generating detailed language feature maps in 18ms per frame, (2) a two-stage online auto-encoder that compresses 768-dimensional CLIP features to 15 dimensions while preserving open-vocabulary capabilities, and (3) a color-language disentangled optimization approach to improve rendering quality. Experimental results show that our online method not only surpasses the state-of-the-art offline methods in accuracy but also achieves more than 40x efficiency boost, demonstrating the potential for dynamic and interactive AI applications.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Rendering for Multimodal Autonomous Driving: Merging Neural and Physics-Based Simulation</title>
<link>https://arxiv.org/abs/2503.09464</link>
<guid>https://arxiv.org/abs/2503.09464</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主驾驶模拟, 神经重建模型, 物理渲染, NeRF2GS, 3D Gaussian Splatting

总结:<br />
本文介绍了一种用于自动驾驶模拟的新型混合方法，该方法结合了神经重建和基于物理的渲染的优势。该方法允许在任意位置虚拟放置传统的动态网格代理并调整环境条件，同时从新的摄像机视角进行高质量的图像渲染。通过名为NeRF2GS的新训练技术，该方法提升了对道路表面和车道标记等的新型视图合成质量，并保持了交互式的帧率。NeRF2GS利用NeRF方法的强大泛化能力和3D Gaussian Splatting的实时渲染速度，首先使用带有来自噪声LiDAR点云深度正则化的原始图像训练定制的NeRF模型，再将其作为教师模型指导3DGS的训练。此外，通过块级训练并行化，该方法可以处理大规模重建（大于或等于100,000平方米）并预测分割掩模、表面法线和深度图。在模拟过程中，支持基于光栅化的渲染后端以及具有深度组合和多种相机模型的实时摄像头模拟，同时也支持精确的LiDAR模拟的光线追踪后端。 <div>
arXiv:2503.09464v1 Announce Type: new 
Abstract: Neural reconstruction models for autonomous driving simulation have made significant strides in recent years, with dynamic models becoming increasingly prevalent. However, these models are typically limited to handling in-domain objects closely following their original trajectories. We introduce a hybrid approach that combines the strengths of neural reconstruction with physics-based rendering. This method enables the virtual placement of traditional mesh-based dynamic agents at arbitrary locations, adjustments to environmental conditions, and rendering from novel camera viewpoints. Our approach significantly enhances novel view synthesis quality -- especially for road surfaces and lane markings -- while maintaining interactive frame rates through our novel training method, NeRF2GS. This technique leverages the superior generalization capabilities of NeRF-based methods and the real-time rendering speed of 3D Gaussian Splatting (3DGS). We achieve this by training a customized NeRF model on the original images with depth regularization derived from a noisy LiDAR point cloud, then using it as a teacher model for 3DGS training. This process ensures accurate depth, surface normals, and camera appearance modeling as supervision. With our block-based training parallelization, the method can handle large-scale reconstructions (greater than or equal to 100,000 square meters) and predict segmentation masks, surface normals, and depth maps. During simulation, it supports a rasterization-based rendering backend with depth-based composition and multiple camera models for real-time camera simulation, as well as a ray-traced backend for precise LiDAR simulation.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SurgicalVLM-Agent: Towards an Interactive AI Co-Pilot for Pituitary Surgery</title>
<link>https://arxiv.org/abs/2503.09474</link>
<guid>https://arxiv.org/abs/2503.09474</guid>
<content:encoded><![CDATA[
<div> 关键词：Image-guided surgery, Vision-language models, SurgicalVLM-Agent, PitAgent dataset, FFT-GaLore

总结:
本文介绍了针对图像引导手术需求的一种新型AI辅助系统——SurgicalVLM-Agent，该系统具备对话、规划和任务执行能力，尤其适用于动态适应并提供交互式指导。为实现结构化任务规划，研究团队构建了PitAgent手术语境感知数据集，覆盖了包括MRI肿瘤分割、内窥镜解剖结构分割、预后影像与术中视图叠加、器械定位、工具跟踪、工具-组织交互、阶段识别及手术活动识别等多个任务领域。同时，他们提出了基于快速傅里叶变换（FFT）的梯度投影技术FFT-GaLore，用于优化LLaMA 3.2模型在手术环境中的微调效率。实验结果显示，SurgicalVLM-Agent在任务规划与提示生成方面展现出优越性能，并通过公开的垂体手术数据集验证了其在零样本视觉问答方面的高语义相关性响应，从而推动了AI驱动的手术辅助技术的发展。 <div>
arXiv:2503.09474v1 Announce Type: new 
Abstract: Image-guided surgery demands adaptive, real-time decision support, yet static AI models struggle with structured task planning and providing interactive guidance. Large vision-language models (VLMs) offer a promising solution by enabling dynamic task planning and predictive decision support. We introduce SurgicalVLM-Agent, an AI co-pilot for image-guided pituitary surgery, capable of conversation, planning, and task execution. The agent dynamically processes surgeon queries and plans the tasks such as MRI tumor segmentation, endoscope anatomy segmentation, overlaying preoperative imaging with intraoperative views, instrument tracking, and surgical visual question answering (VQA). To enable structured task planning, we develop the PitAgent dataset, a surgical context-aware dataset covering segmentation, overlaying, instrument localization, tool tracking, tool-tissue interactions, phase identification, and surgical activity recognition. Additionally, we propose FFT-GaLore, a fast Fourier transform (FFT)-based gradient projection technique for efficient low-rank adaptation, optimizing fine-tuning for LLaMA 3.2 in surgical environments. We validate SurgicalVLM-Agent by assessing task planning and prompt generation on our PitAgent dataset and evaluating zero-shot VQA using a public pituitary dataset. Results demonstrate state-of-the-art performance in task planning and query interpretation, with highly semantically meaningful VQA responses, advancing AI-driven surgical assistance.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReMA: Learning to Meta-think for LLMs with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.09501</link>
<guid>https://arxiv.org/abs/2503.09501</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、元思考、强化学习、多智能体、Reinforced Meta-thinking Agents (ReMA)

总结:<br />
本文提出了一个名为Reinforced Meta-thinking Agents (ReMA)的新框架，旨在通过利用多智能体强化学习（MARL）激发大规模语言模型（LLMs）的元思考能力，以提高其问题解决性能。当前单智能体的工作在获取元思考方面效率低下，而ReMA通过将推理过程分解为负责战略监督和规划的高层元思考智能体以及执行详细操作的低层推理智能体，解决了这一挑战。通过迭代强化学习和对齐的目标，这两个智能体探索并学会了协作，从而提高了泛化能力和鲁棒性。实验结果显示，ReMA在包括竞争级别的数学基准测试和LLM-as-a-Judge基准测试在内的复杂推理任务上优于单智能体RL基线。此外，详尽的消融研究揭示了各个独立代理的发展动态，提供了关于元思考推理过程如何增强LLMs推理能力的宝贵见解。 <div>
arXiv:2503.09501v1 Announce Type: new 
Abstract: Recent research on Reasoning of Large Language Models (LLMs) has sought to further enhance their performance by integrating meta-thinking -- enabling models to monitor, evaluate, and control their reasoning processes for more adaptive and effective problem-solving. However, current single-agent work lacks a specialized design for acquiring meta-thinking, resulting in low efficacy. To address this challenge, we introduce Reinforced Meta-thinking Agents (ReMA), a novel framework that leverages Multi-Agent Reinforcement Learning (MARL) to elicit meta-thinking behaviors, encouraging LLMs to think about thinking. ReMA decouples the reasoning process into two hierarchical agents: a high-level meta-thinking agent responsible for generating strategic oversight and plans, and a low-level reasoning agent for detailed executions. Through iterative reinforcement learning with aligned objectives, these agents explore and learn collaboration, leading to improved generalization and robustness. Experimental results demonstrate that ReMA outperforms single-agent RL baselines on complex reasoning tasks, including competitive-level mathematical benchmarks and LLM-as-a-Judge benchmarks. Comprehensive ablation studies further illustrate the evolving dynamics of each distinct agent, providing valuable insights into how the meta-thinking reasoning process enhances the reasoning capabilities of LLMs.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TRACE: Real-Time Multimodal Common Ground Tracking in Situated Collaborative Dialogues</title>
<link>https://arxiv.org/abs/2503.09511</link>
<guid>https://arxiv.org/abs/2503.09511</guid>
<content:encoded><![CDATA[
<div> 关键词：TRACE、实时性能、共同地面跟踪、多模态输入、协作任务

总结:
TRACE是一个新颖的实时共同地面跟踪系统，专为情境中的协作任务设计。该系统注重快速、实时的表现，通过追踪参与者的语音、行为、手势和视觉注意力等多模态输入，确定随着对话进行而提出的与任务相关的命题集合，并跟踪团队对这些命题的认识状态和信念变化。在越来越多的研究关注能调解人类合作的人工智能系统的背景下，TRACE对于实现能够参与多人、多模态语境交流的智能代理来说，迈出了重要的一步。 <div>
arXiv:2503.09511v1 Announce Type: new 
Abstract: We present TRACE, a novel system for live *common ground* tracking in situated collaborative tasks. With a focus on fast, real-time performance, TRACE tracks the speech, actions, gestures, and visual attention of participants, uses these multimodal inputs to determine the set of task-relevant propositions that have been raised as the dialogue progresses, and tracks the group's epistemic position and beliefs toward them as the task unfolds. Amid increased interest in AI systems that can mediate collaborations, TRACE represents an important step forward for agents that can engage with multiparty, multimodal discourse.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RESTRAIN: Reinforcement Learning-Based Secure Framework for Trigger-Action IoT Environment</title>
<link>https://arxiv.org/abs/2503.09513</link>
<guid>https://arxiv.org/abs/2503.09513</guid>
<content:encoded><![CDATA[
<div> 关键词: Internet of Things (物联网), 远程注入攻击, 在线防御, 强化学习, 安全策略

总结:
本文提出了一种名为RESTRAIN的平台独立的多智能体在线防御系统，用于对抗物联网(IoT)设备中的远程注入攻击。RESTRAIN允许防御代理在运行时对攻击动作进行建模，并利用强化学习优化符合物联网网络安全需求的防御策略。实验结果显示，防御代理能够有效地实时采取防御措施，对抗复杂和动态的远程注入攻击，并在最小化计算开销的同时最大化安全性收益。<br /><br /> <div>
arXiv:2503.09513v1 Announce Type: new 
Abstract: Internet of Things (IoT) platforms with trigger-action capability allow event conditions to trigger actions in IoT devices autonomously by creating a chain of interactions. Adversaries exploit this chain of interactions to maliciously inject fake event conditions into IoT hubs, triggering unauthorized actions on target IoT devices to implement remote injection attacks. Existing defense mechanisms focus mainly on the verification of event transactions using physical event fingerprints to enforce the security policies to block unsafe event transactions. These approaches are designed to provide offline defense against injection attacks. The state-of-the-art online defense mechanisms offer real-time defense, but extensive reliability on the inference of attack impacts on the IoT network limits the generalization capability of these approaches. In this paper, we propose a platform-independent multi-agent online defense system, namely RESTRAIN, to counter remote injection attacks at runtime. RESTRAIN allows the defense agent to profile attack actions at runtime and leverages reinforcement learning to optimize a defense policy that complies with the security requirements of the IoT network. The experimental results show that the defense agent effectively takes real-time defense actions against complex and dynamic remote injection attacks and maximizes the security gain with minimal computational overhead.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PairVDN - Pair-wise Decomposed Value Functions</title>
<link>https://arxiv.org/abs/2503.09521</link>
<guid>https://arxiv.org/abs/2503.09521</guid>
<content:encoded><![CDATA[
<div> 关键词：deep Q-learning, 多智能体合作, 价值分解网络, PairVDN, 动态规划

总结:
本文提出了一种名为PairVDN的新方法，旨在解决深度Q学习在合作多智能体环境中的扩展挑战，如联合动作空间的指数增长、非平稳环境和信用分配问题。PairVDN通过将价值函数分解为一组两两间的而非单个智能体的函数，提高了表达能力，但需要更复杂的（但仍有效率的）动态规划最大化算法。与过去的VDN和QMIX方法不同，PairVDN能够表示那些无法表示为单个智能体函数单调组合的价值函数。此外，文中实现了一个新的多智能体合作环境Box Jump，并在此环境中展示了优于这些基线的方法性能。相关代码和环境已在https://github.com/zzbuzzard/PairVDN开源。 <div>
arXiv:2503.09521v1 Announce Type: new 
Abstract: Extending deep Q-learning to cooperative multi-agent settings is challenging due to the exponential growth of the joint action space, the non-stationary environment, and the credit assignment problem. Value decomposition allows deep Q-learning to be applied at the joint agent level, at the cost of reduced expressivity. Building on past work in this direction, our paper proposes PairVDN, a novel method for decomposing the value function into a collection of pair-wise, rather than per-agent, functions, improving expressivity at the cost of requiring a more complex (but still efficient) dynamic programming maximisation algorithm. Our method enables the representation of value functions which cannot be expressed as a monotonic combination of per-agent functions, unlike past approaches such as VDN and QMIX. We implement a novel many-agent cooperative environment, Box Jump, and demonstrate improved performance over these baselines in this setting. We open-source our code and environment at https://github.com/zzbuzzard/PairVDN.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Large Language Models for Multi-Facility Location Mechanism Design</title>
<link>https://arxiv.org/abs/2503.09533</link>
<guid>https://arxiv.org/abs/2503.09533</guid>
<content:encoded><![CDATA[
<div> 关键词: strategyproof mechanisms, multi-facility location, deep learning, large language models, evolutionary framework

<br /><br />总结:
本文提出了一种名为LLMMech的新方法，用于解决基于代理偏好的多设施选址问题，设计策略免疫机制并优化社会成本。LLMMech通过将大型语言模型（LLMs）融入进化框架中，实现了无需大量领域知识、免调超参数、可解释性强、实证上策略免疫以及接近最优的机制生成。实验结果表明，LLM生成的机制在各种问题设置下，包括不同权重的社会成本和非均匀分布的代理偏好情况下，通常优于现有的手工基线和深度学习模型。此外，这些机制还展现出对代理偏好出分布情况及更大规模问题的优秀泛化能力。 <div>
arXiv:2503.09533v1 Announce Type: new 
Abstract: Designing strategyproof mechanisms for multi-facility location that optimize social costs based on agent preferences had been challenging due to the extensive domain knowledge required and poor worst-case guarantees. Recently, deep learning models have been proposed as alternatives. However, these models require some domain knowledge and extensive hyperparameter tuning as well as lacking interpretability, which is crucial in practice when transparency of the learned mechanisms is mandatory. In this paper, we introduce a novel approach, named LLMMech, that addresses these limitations by incorporating large language models (LLMs) into an evolutionary framework for generating interpretable, hyperparameter-free, empirically strategyproof, and nearly optimal mechanisms. Our experimental results, evaluated on various problem settings where the social cost is arbitrarily weighted across agents and the agent preferences may not be uniformly distributed, demonstrate that the LLM-generated mechanisms generally outperform existing handcrafted baselines and deep learning models. Furthermore, the mechanisms exhibit impressive generalizability to out-of-distribution agent preferences and to larger instances with more agents.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Plan-and-Act: Improving Planning of Agents for Long-Horizon Tasks</title>
<link>https://arxiv.org/abs/2503.09572</link>
<guid>https://arxiv.org/abs/2503.09572</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 高级规划, 低级执行, 计划与行动框架, 合成数据生成

总结:<br />
本文提出了一个名为“Plan-and-Act”的新颖框架，旨在解决大型语言模型（LLMs）在处理复杂、多步骤、长序列任务方面的挑战。该框架通过将高级规划与低级执行分离，使模型能更好地平衡高阶规划目标和低阶执行细节。为了解决准确生成计划的问题，Plan-and-Act引入了明确的规划组件和一种新型的合成数据生成方法来训练规划器模型，该方法利用带有可行计划注解的真实轨迹以及多样化的示例增强泛化能力。在以网络导航为长期规划环境的代表性场景下，通过在WebArena-Lite基准测试中实现54%的成功率，证明了Plan-and-Act的有效性，显示出了该框架在处理此类任务上的优越性能。 <div>
arXiv:2503.09572v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown remarkable advancements in enabling language agents to tackle simple tasks. However, applying them for complex, multi-step, long-horizon tasks remains a challenge. Recent work have found success by separating high-level planning from low-level execution, which enables the model to effectively balance high-level planning objectives and low-level execution details. However, generating accurate plans remains difficult since LLMs are not inherently trained for this task. To address this, we propose Plan-and-Act, a novel framework that incorporates explicit planning into LLM-based agents and introduces a scalable method to enhance plan generation through a novel synthetic data generation method. Plan-and-Act consists of a Planner model which generates structured, high-level plans to achieve user goals, and an Executor model that translates these plans into environment-specific actions. To train the Planner effectively, we introduce a synthetic data generation method that annotates ground-truth trajectories with feasible plans, augmented with diverse and extensive examples to enhance generalization. We evaluate Plan-and-Act using web navigation as a representative long-horizon planning environment, demonstrating a state-of the-art 54% success rate on the WebArena-Lite benchmark.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Auspex: Building Threat Modeling Tradecraft into an Artificial Intelligence-based Copilot</title>
<link>https://arxiv.org/abs/2503.09586</link>
<guid>https://arxiv.org/abs/2503.09586</guid>
<content:encoded><![CDATA[
<div> 关键词：Auspex、威胁建模系统、生成式人工智能、 tradecraft 提示、银行系统

总结:

本文介绍了名为Auspex的新型威胁建模系统，该系统利用专门设计的基于生成式人工智能的方法来捕捉威胁建模的专业技巧，这种方法被称为 tradecraft 提示。Auspex通过两个处理阶段使用 tradecraft 提示：第一阶段用于摄入和处理系统架构信息，编码与系统分解和描述相关的威胁建模知识；第二阶段则是通过一系列提示对系统分析结果进行链式处理，这些提示包含了关于威胁识别、分类和缓解的专业知识。最终生成的威胁矩阵详细列出了系统的威胁场景、威胁类型、信息安全分类以及潜在缓解措施。相比手动方法需要数周或数月的时间，Auspex能在几分钟内产生形式化的威胁模型输出。Auspex以其轻量级、灵活、模块化和可扩展的特点，解决了现有手动和自动化威胁建模过程中的复杂性、资源和标准化限制问题。通过让网络安全专家对针对真实银行系统的威胁模型进行反馈评价，文章确立了Auspex对威胁建模者的基线价值。最后，文中讨论了Auspex的系统性能并提出了对其增强功能的计划。 <div>
arXiv:2503.09586v1 Announce Type: new 
Abstract: We present Auspex - a threat modeling system built using a specialized collection of generative artificial intelligence-based methods that capture threat modeling tradecraft. This new approach, called tradecraft prompting, centers on encoding the on-the-ground knowledge of threat modelers within the prompts that drive a generative AI-based threat modeling system. Auspex employs tradecraft prompts in two processing stages. The first stage centers on ingesting and processing system architecture information using prompts that encode threat modeling tradecraft knowledge pertaining to system decomposition and description. The second stage centers on chaining the resulting system analysis through a collection of prompts that encode tradecraft knowledge on threat identification, classification, and mitigation. The two-stage process yields a threat matrix for a system that specifies threat scenarios, threat types, information security categorizations and potential mitigations. Auspex produces formalized threat model output in minutes, relative to the weeks or months a manual process takes. More broadly, the focus on bespoke tradecraft prompting, as opposed to fine-tuning or agent-based add-ons, makes Auspex a lightweight, flexible, modular, and extensible foundational system capable of addressing the complexity, resource, and standardization limitations of both existing manual and automated threat modeling processes. In this connection, we establish the baseline value of Auspex to threat modelers through an evaluation procedure based on feedback collected from cybersecurity subject matter experts measuring the quality and utility of threat models generated by Auspex on real banking systems. We conclude with a discussion of system performance and plans for enhancements to Auspex.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beam Selection in ISAC using Contextual Bandit with Multi-modal Transformer and Transfer Learning</title>
<link>https://arxiv.org/abs/2503.08937</link>
<guid>https://arxiv.org/abs/2503.08937</guid>
<content:encoded><![CDATA[
<div> 关键词： sixth generation (6G)，Integrated Sensing and Communication (ISAC)，beam selection，multi-modal transformer，multi-agent contextual bandit算法

<br /><br />总结：

本文介绍了针对第六代（6G）无线技术中的一种创新框架，该框架将集成感知与通信(ISAC)传感数据应用于复杂室内环境下的波束选择过程，以优化频谱和硬件资源。研究采用多模态变换器模型与多智能体上下文带状算法相结合的方式，利用ISAC数据提升通信性能并实现高频谱效率(SE)。实验结果显示，该模型在DeepSense 6G数据集上的表现优于传统的深度强化学习(DRL)方法，单用户场景下平均SE后悔值改善了49.6%。此外，文中还运用迁移强化学习策略减少多用户环境下的训练时间并提升模型性能，相较于从零开始训练，多用户场景下的平均SE后悔值降低了19.7%，即使后者训练时间延长了100倍。 <div>
arXiv:2503.08937v1 Announce Type: cross 
Abstract: Sixth generation (6G) wireless technology is anticipated to introduce Integrated Sensing and Communication (ISAC) as a transformative paradigm. ISAC unifies wireless communication and RADAR or other forms of sensing to optimize spectral and hardware resources. This paper presents a pioneering framework that leverages ISAC sensing data to enhance beam selection processes in complex indoor environments. By integrating multi-modal transformer models with a multi-agent contextual bandit algorithm, our approach utilizes ISAC sensing data to improve communication performance and achieves high spectral efficiency (SE). Specifically, the multi-modal transformer can capture inter-modal relationships, enhancing model generalization across diverse scenarios. Experimental evaluations on the DeepSense 6G dataset demonstrate that our model outperforms traditional deep reinforcement learning (DRL) methods, achieving superior beam prediction accuracy and adaptability. In the single-user scenario, we achieve an average SE regret improvement of 49.6% as compared to DRL. Furthermore, we employ transfer reinforcement learning to reduce training time and improve model performance in multi-user environments. In the multi-user scenario, this approach enhances the average SE regret, which is a measure to demonstrate how far the learned policy is from the optimal SE policy, by 19.7% compared to training from scratch, even when the latter is trained 100 times longer.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The turnpike control in stochastic multi-agent dynamics: a discrete-time approach with exponential integrators</title>
<link>https://arxiv.org/abs/2503.09549</link>
<guid>https://arxiv.org/abs/2503.09549</guid>
<content:encoded><![CDATA[
<div> 关键词：turnpike property, 随机离散时间最优控制, 交互代理, 消耗性条件, 可控性条件,指数型积分器, 数值实验

总结:
本文研究了在存在噪声情况下的随机离散时间最优控制问题中交互代理的变道属性（turnpike property）。文章扩展了先前确定性的结果，证明在满足适当的消耗性和可控性条件下，变道效应在噪声存在下仍然存在。为了解决系统动力学可能存在的刚性问题，文中使用指数型积分器进行时间离散化。数值实验验证了理论发现，证实了指数型积分器相比于标准显式方案的优势以及在随机环境下变道控制的有效性。 <div>
arXiv:2503.09549v1 Announce Type: cross 
Abstract: In this manuscript, we study the turnpike property in stochastic discrete-time optimal control problems for interacting agents. Extending previous deterministic results, we show that the turnpike effect persists in the presence of noise under suitable dissipativity and controllability conditions. To handle the possible stiffness in the system dynamics, we employ for the time discretization, integrators of exponential type. Numerical experiments validate our findings, demonstrating the advantages of exponential integrators over standard explicit schemes and confirming the effectiveness of the turnpike control even in the stochastic setting.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Personality Traits in Large Language Models</title>
<link>https://arxiv.org/abs/2307.00184</link>
<guid>https://arxiv.org/abs/2307.00184</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、人格特质、自然语言处理、心理测量学、道德影响

<br />
总结:
本文介绍了随着大型语言模型（LLMs）的发展及其在自然语言处理中的广泛应用，其内置的人格特质日益重要。研究提出了一种新颖且心理测量上有效可靠的方法，用于对广泛使用的LLMs进行人格测试并塑造生成文本中的人格特征。通过该方法应用于18个LLM的研究发现：1) 在特定提示配置下，部分LLM的输出人格测量结果具有可靠性和有效性；2) 更大和经过指令微调的LLM显示出更强的人格合成可靠性和有效性证据；3) 可以沿着期望的维度塑造型似特定人类人格特征的LLM输出。文章还讨论了该测量与塑造方法的应用及道德影响，特别关注AI的责任问题。 <div>
arXiv:2307.00184v4 Announce Type: replace 
Abstract: The advent of large language models (LLMs) has revolutionized natural language processing, enabling the generation of coherent and contextually relevant human-like text. As LLMs increasingly powerconversational agents used by the general public world-wide, the synthetic personality traits embedded in these models, by virtue of training on large amounts of human data, is becoming increasingly important. Since personality is a key factor determining the effectiveness of communication, we present a novel and comprehensive psychometrically valid and reliable methodology for administering and validating personality tests on widely-used LLMs, as well as for shaping personality in the generated text of such LLMs. Applying this method to 18 LLMs, we found: 1) personality measurements in the outputs of some LLMs under specific prompting configurations are reliable and valid; 2) evidence of reliability and validity of synthetic LLM personality is stronger for larger and instruction fine-tuned models; and 3) personality in LLM outputs can be shaped along desired dimensions to mimic specific human personality profiles. We discuss the application and ethical implications of the measurement and shaping method, in particular regarding responsible AI.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CommonPower: A Framework for Safe Data-Driven Smart Grid Control</title>
<link>https://arxiv.org/abs/2406.03231</link>
<guid>https://arxiv.org/abs/2406.03231</guid>
<content:encoded><![CDATA[
<div> 关键词：CommonPower、强化学习(Reinforcement Learning, RL)、电力系统管理、模型预测控制(Safeguards)、多智能体RL(Multi-agent RL)

总结:<br />
随着电力系统管理复杂性的增加，对强化学习（RL）的兴趣日益增长。为了验证RL算法的有效性，需要在多个案例研究中进行评估。为此，文章提出了Python工具CommonPower，这是一个针对机器学习定制的首个通用电力系统管理建模和仿真框架。CommonPower的模块化架构使得用户可以专注于特定元素而无需实现完整的模拟环境。其独特贡献包括自动合成模型预测控制器和保障机制，为单智能体RL、多智能体RL以及最优控制提供统一接口，并包含了训练机器学习预报器的管道以及将保障反馈灵活纳入RL控制器学习更新的机制。 <div>
arXiv:2406.03231v4 Announce Type: replace 
Abstract: The growing complexity of power system management has led to an increased interest in reinforcement learning (RL). To validate their effectiveness, RL algorithms have to be evaluated across multiple case studies. Case study design is an arduous task requiring the consideration of many aspects, among them the influence of available forecasts and the level of decentralization in the control structure. Furthermore, vanilla RL controllers cannot themselves ensure the satisfaction of system constraints, which makes devising a safeguarding mechanism a necessary task for every case study before deploying the system. To address these shortcomings, we introduce the Python tool CommonPower, the first general framework for the modeling and simulation of power system management tailored towards machine learning. Its modular architecture enables users to focus on specific elements without having to implement a simulation environment. Another unique contribution of CommonPower is the automatic synthesis of model predictive controllers and safeguards. Beyond offering a unified interface for single-agent RL, multi-agent RL, and optimal control, CommonPower includes a training pipeline for machine-learning-based forecasters as well as a flexible mechanism for incorporating feedback of safeguards into the learning updates of RL controllers.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EmBARDiment: an Embodied AI Agent for Productivity in XR</title>
<link>https://arxiv.org/abs/2408.08158</link>
<guid>https://arxiv.org/abs/2408.08158</guid>
<content:encoded><![CDATA[
<div> 关键词：XR设备、聊天机器人、大型语言模型、注意力框架、交互体验

总结:

本文提出了利用XR（扩展现实）设备运行由大型语言模型驱动的聊天机器人的新方案。该方案旨在创建一种始终在线的代理，以提高用户生产力。文章指出，当前基于屏幕的聊天机器人过度依赖语音或文本提示，而未能充分利用XR环境中的多种自然输入，如内部传感器数据、眼动追踪和上下文记忆。为解决这一问题，文中提出了一种注意力框架解决方案，该框架能从用户的动作、视线关注以及XR环境中的上下文记忆中隐式地获取上下文信息，从而减少了对人工设计的明确提示的依赖，进而促进更为直观和扎根于实际情境的互动，使聊天机器人能够更好地理解和洞察用户需求。 <div>
arXiv:2408.08158v2 Announce Type: replace 
Abstract: XR devices running chat-bots powered by Large Language Models (LLMs) have the to become always-on agents that enable much better productivity scenarios. Current screen based chat-bots do not take advantage of the the full-suite of natural inputs available in XR, including inward facing sensor data, instead they over-rely on explicit voice or text prompts, sometimes paired with multi-modal data dropped as part of the query. We propose a solution that leverages an attention framework that derives context implicitly from user actions, eye-gaze, and contextual memory within the XR environment. Our work minimizes the need for engineered explicit prompts, fostering grounded and intuitive interactions that glean user insights for the chat-bot.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Construction of the Sparsest Maximally $r$-Robust Graphs</title>
<link>https://arxiv.org/abs/2409.19465</link>
<guid>https://arxiv.org/abs/2409.19465</guid>
<content:encoded><![CDATA[
<div> 关键词: r-robustness, 通信图, 共识, 图结构, 边数约束

总结:
本文关注于网络通信图的r-鲁棒性问题，该属性在存在恶意行为者的情况下保证共识达成的能力。文章指出更高的r-鲁棒性虽然能增强对恶意信息的容忍度，但也可能导致更多的通信边数，这与现实世界中有限资源下需最小化通信的需求相冲突。论文贡献主要体现在两个方面：(a) 提供了达到最大鲁棒性的必要子图结构及具有给定节点数量的图所需最少边数的精确下界；(b) 利用(a)的结果，引入了两类在保持最大鲁棒性的同时，拥有最少边数的图类。这些结论通过一系列模拟进行了验证。<br /><br /> <div>
arXiv:2409.19465v2 Announce Type: replace 
Abstract: In recent years, the notion of r-robustness for the communication graph of the network has been introduced to address the challenge of achieving consensus in the presence of misbehaving agents. Higher r-robustness typically implies higher tolerance to malicious information towards achieving resilient consensus, but it also implies more edges for the communication graph. This in turn conflicts with the need to minimize communication due to limited resources in real-world applications (e.g., multi-robot networks). In this paper, our contributions are twofold. (a) We provide the necessary subgraph structures and tight lower bounds on the number of edges required for graphs with a given number of nodes to achieve maximum robustness. (b) We then use the results of (a) to introduce two classes of graphs that maintain maximum robustness with the least number of edges. Our work is validated through a series of simulations.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring LLM Cryptocurrency Trading Through Fact-Subjectivity Aware Reasoning</title>
<link>https://arxiv.org/abs/2410.12464</link>
<guid>https://arxiv.org/abs/2410.12464</guid>
<content:encoded><![CDATA[
<div> 关键词：LLMs（大型语言模型）、加密货币交易、主观信息、事实信息、多代理框架FS-ReasoningAgent

<br /><br />总结:
本文研究发现，在加密货币交易中，更强大的大型语言模型(LLMs)有时会逊色于较弱的模型。研究指出，更强的LLMs倾向于依据事实信息而非主观性进行决策。为了解决这一问题，作者提出了一种名为FS-ReasoningAgent的多代理框架，该框架使LLMs能够识别并学习事实和主观两种推理方式。实验表明，这种精细化推理方法能提升LLM在加密货币市场的交易表现，分别使BTC、ETH和SOL的利润提高了7%、2%和10%。此外，消融研究表明，在牛市中依赖主观新闻可带来更高的回报，而在熊市中关注事实信息则能取得更好的结果。代码已发布在https://github.com/Persdre/FS-ReasoningAgent上。 <div>
arXiv:2410.12464v3 Announce Type: replace 
Abstract: While many studies show that more advanced LLMs excel in tasks such as mathematics and coding, we observe that in cryptocurrency trading, stronger LLMs sometimes underperform compared to weaker ones. To investigate this counterintuitive phenomenon, we examine how LLMs reason when making trading decisions. Our findings reveal that (1) stronger LLMs show a preference for factual information over subjectivity; (2) separating the reasoning process into factual and subjective components leads to higher profits. Building on these insights, we propose a multi-agent framework, FS-ReasoningAgent, which enables LLMs to recognize and learn from both factual and subjective reasoning. Extensive experiments demonstrate that this fine-grained reasoning approach enhances LLM trading performance in cryptocurrency markets, yielding profit improvements of 7\% in BTC, 2\% in ETH, and 10\% in SOL. Additionally, an ablation study reveals that relying on subjective news generates higher returns in bull markets, while focusing on factual information yields better results in bear markets. Code is available at https://github.com/Persdre/FS-ReasoningAgent.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guide-LLM: An Embodied LLM Agent and Text-Based Topological Map for Robotic Guidance of People with Visual Impairments</title>
<link>https://arxiv.org/abs/2410.20666</link>
<guid>https://arxiv.org/abs/2410.20666</guid>
<content:encoded><![CDATA[
<div> 关键词: 视觉障碍者、导航、大型语言模型、路径规划、危险检测

<br />
总结:
本文介绍了为视觉障碍人士设计的一种新型导航辅助系统——Guide-LLM。该系统利用大型语言模型和文本基础的拓扑地图，使模型能够基于简化环境表示进行全局路径规划，重点关注直线和直角转弯，以便于导航。同时，Guide-LLM还运用了大型语言模型的常识推理能力进行危险检测及基于用户偏好的个性化路径规划。通过模拟实验，证明了该系统在指导视觉障碍者在大型室内环境中有效导航的能力，显示出其在辅助技术领域的重大进步潜力，有望为视觉障碍者的导航带来更高效、适应性和个性化的服务。 <div>
arXiv:2410.20666v2 Announce Type: replace 
Abstract: Navigation presents a significant challenge for persons with visual impairments (PVI). While traditional aids such as white canes and guide dogs are invaluable, they fall short in delivering detailed spatial information and precise guidance to desired locations. Recent developments in large language models (LLMs) and vision-language models (VLMs) offer new avenues for enhancing assistive navigation. In this paper, we introduce Guide-LLM, an embodied LLM-based agent designed to assist PVI in navigating large indoor environments. Our approach features a novel text-based topological map that enables the LLM to plan global paths using a simplified environmental representation, focusing on straight paths and right-angle turns to facilitate navigation. Additionally, we utilize the LLM's commonsense reasoning for hazard detection and personalized path planning based on user preferences. Simulated experiments demonstrate the system's efficacy in guiding PVI, underscoring its potential as a significant advancement in assistive technology. The results highlight Guide-LLM's ability to offer efficient, adaptive, and personalized navigation assistance, pointing to promising advancements in this field.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Real-time Deformation-aware Control for Autonomous Robotic Subretinal Injection under iOCT Guidance</title>
<link>https://arxiv.org/abs/2411.06557</link>
<guid>https://arxiv.org/abs/2411.06557</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人平台、光学相干断层扫描(iOCT)、自动图像引导、视网膜手术、组织变形

总结:

本文提出了一种利用iOCT实时影像引导的、考虑组织变形的自主机器人辅助视网膜下注射方法。该方法通过密集采样iOCT B扫描实现B${^5}$-扫描，实时监测工具相对于虚拟目标层（位于ILM和RPE之间）的位置。实验结果显示，与先前的自主插入方法相比，该方法能够动态调整插入深度并显著提高针头定位准确性，成功生成视网膜下囊泡的比例从原来的35%提升至90%，从而证明了其在体外猪眼模型上的有效性与优越性。 <div>
arXiv:2411.06557v2 Announce Type: replace 
Abstract: Robotic platforms provide consistent and precise tool positioning that significantly enhances retinal microsurgery. Integrating such systems with intraoperative optical coherence tomography (iOCT) enables image-guided robotic interventions, allowing autonomous performance of advanced treatments, such as injecting therapeutic agents into the subretinal space. However, tissue deformations due to tool-tissue interactions constitute a significant challenge in autonomous iOCT-guided robotic subretinal injections. Such interactions impact correct needle positioning and procedure outcomes. This paper presents a novel method for autonomous subretinal injection under iOCT guidance that considers tissue deformations during the insertion procedure. The technique is achieved through real-time segmentation and 3D reconstruction of the surgical scene from densely sampled iOCT B-scans, which we refer to as B${^5}$-scans. Using B${^5}$-scans we monitor the position of the instrument relative to a virtual target layer between the ILM and RPE. Our experiments on ex vivo porcine eyes demonstrate dynamic adjustment of the insertion depth and overall improved accuracy in needle positioning compared to prior autonomous insertion approaches. Compared to a 35% success rate in subretinal bleb generation with previous approaches, our method reliably created subretinal blebs in 90% our experiments.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Grounding Video Models to Actions through Goal Conditioned Exploration</title>
<link>https://arxiv.org/abs/2411.07223</link>
<guid>https://arxiv.org/abs/2411.07223</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模视频模型、自我探索、连续动作、无监督学习、环境交互

<br />
总结:
本文探讨了如何将大规模视频模型直接与连续动作相结合，通过在具象环境中进行自我探索，使代理能够解决复杂任务而无需外部监督，如奖励、动作标签或分割掩模。研究提出了一种框架，该框架利用轨迹级别的动作生成和视频引导相结合的方法。实验在Libero、MetaWorld、Calvin和iThor视觉导航等多个平台上的18项任务中验证了该方法的有效性，结果表明，该方法可以比肩甚至超过那些基于专家演示训练的行为克隆基线，而且不需要任何动作注释。 <div>
arXiv:2411.07223v2 Announce Type: replace 
Abstract: Large video models, pretrained on massive amounts of Internet video, provide a rich source of physical knowledge about the dynamics and motions of objects and tasks. However, video models are not grounded in the embodiment of an agent, and do not describe how to actuate the world to reach the visual states depicted in a video. To tackle this problem, current methods use a separate vision-based inverse dynamic model trained on embodiment-specific data to map image states to actions. Gathering data to train such a model is often expensive and challenging, and this model is limited to visual settings similar to the ones in which data are available. In this paper, we investigate how to directly ground video models to continuous actions through self-exploration in the embodied environment -- using generated video states as visual goals for exploration. We propose a framework that uses trajectory level action generation in combination with video guidance to enable an agent to solve complex tasks without any external supervision, e.g., rewards, action labels, or segmentation masks. We validate the proposed approach on 8 tasks in Libero, 6 tasks in MetaWorld, 4 tasks in Calvin, and 12 tasks in iThor Visual Navigation. We show how our approach is on par with or even surpasses multiple behavior cloning baselines trained on expert demonstrations while without requiring any action annotations.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Algebraic Evaluation Theorems</title>
<link>https://arxiv.org/abs/2412.16238</link>
<guid>https://arxiv.org/abs/2412.16238</guid>
<content:encoded><![CDATA[
<div> 关键词：多数投票（Majority Voting）、错误独立性、评价算法（Algebraic Evaluation，AE）、人工智能安全、无限监测链条

<br />
总结:
本文介绍了多数投票作为群体决策的代表性算法，并引出了基于错误独立性假设的陪审团评价定理，该定理能对陪审员的表现进行纯代数评估。与多数投票相比，AE在三个方面具有优势：一是其经验假设更为宽松，能够处理准确率低于50%的决策者；二是由于独立误差假设，它能精确地评价陪审员表现，并通过多精度方法实现比MV更高的标注准确性以及带有实证不确定性范围；三是它能自我警示错误独立性假设的失效。使用美国社区调查的demographic数据进行的实验验证了AE相对于MV的实际效用。文章还讨论了该定理对于AI安全的两个含义：提供了一种终止无限监测链条的原理方法，以及解决我们无法理解的任务中如何评价代理执行效果的超级对齐问题。 <div>
arXiv:2412.16238v2 Announce Type: replace 
Abstract: Majority voting (MV) is the prototypical ``wisdom of the crowd'' algorithm. Theorems considering when MV is optimal for group decisions date back to Condorcet's 1785 jury \emph{decision} theorem. The same error independence assumption underlying the theorem can be used to prove a jury \emph{evaluation} theorem that does purely algebraic evaluation (AE) of juror performance based on a batch of their decisions. Three or more binary jurors are enough to obtain the only two possible statistics of their correctness on a test they took. AE is superior to MV in three ways. First, its empirical assumptions are looser and can handle jurors less than 50\% accurate in making decisions. Second, it has point-like precision in evaluating them given its assumption of error independence. This precision enables a multi-accuracy approach that has higher labeling accuracy than MV and comes with empirical uncertainty bounds. And, third, it is self-alarming about the failure of its error independence assumption. Experiments using demographic data from the American Community Survey confirm the practical utility of AE over MV. Two implications of the theorem for AI safety are discussed - a principled way to terminate infinite monitoring chains (who grades the graders?) and the super-alignment problem (how do we evaluate agents doing tasks we do not understand?).
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Audio Large Language Models Can Be Descriptive Speech Quality Evaluators</title>
<link>https://arxiv.org/abs/2501.17202</link>
<guid>https://arxiv.org/abs/2501.17202</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态代理、语音质量评价、大规模语言模型、自然语言基语音评价语料库、ALLD方法

总结:<br />
本文提出了一种理想化的多模态智能体应具备输入模态质量意识。针对当前大多数音频大规模语言模型无法评估处理语音质量的问题，研究者构建了首个基于自然语言的语音评价语料库，该库包含了真实人类评分和多维度的质量分析。利用此语料库，文章提出了一个名为ALLD的音频LLM引导方法，通过LLM蒸馏技术使模型能从原始语音中提取相关信息并生成有意义的响应。实验结果显示，ALLD在MOS预测上的均方误差达到0.17，A/B测试准确率达到98.6%，并在两个任务上生成的响应取得了BLEU分数为25.8和30.2的好成绩，超越了专门任务模型的能力。这一工作推动了音频LLM对语音信号全面感知能力的发展，有助于实现现实世界中的听觉与感官智能代理的进步。 <div>
arXiv:2501.17202v2 Announce Type: replace 
Abstract: An ideal multimodal agent should be aware of the quality of its input modalities. Recent advances have enabled large language models (LLMs) to incorporate auditory systems for handling various speech-related tasks. However, most audio LLMs remain unaware of the quality of the speech they process. This limitation arises because speech quality evaluation is typically excluded from multi-task training due to the lack of suitable datasets. To address this, we introduce the first natural language-based speech evaluation corpus, generated from authentic human ratings. In addition to the overall Mean Opinion Score (MOS), this corpus offers detailed analysis across multiple dimensions and identifies causes of quality degradation. It also enables descriptive comparisons between two speech samples (A/B tests) with human-like judgment. Leveraging this corpus, we propose an alignment approach with LLM distillation (ALLD) to guide the audio LLM in extracting relevant information from raw speech and generating meaningful responses. Experimental results demonstrate that ALLD outperforms the previous state-of-the-art regression model in MOS prediction, with a mean square error of 0.17 and an A/B test accuracy of 98.6%. Additionally, the generated responses achieve BLEU scores of 25.8 and 30.2 on two tasks, surpassing the capabilities of task-specific models. This work advances the comprehensive perception of speech signals by audio LLMs, contributing to the development of real-world auditory and sensory intelligent agents.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Expected Return Symmetries</title>
<link>https://arxiv.org/abs/2502.01711</link>
<guid>https://arxiv.org/abs/2502.01711</guid>
<content:encoded><![CDATA[
<div> 关键词：对称性、深度学习、多智能体环境、协同失败、预期回报对称性

<br />
总结:
本文探讨了对称性在深度学习领域的强化作用，尤其是在多智能体环境中，已知的对称性可以帮助解决一种称为互不兼容的对称破缺问题。然而，对于部分可观测马尔科夫决策过程中的环境对称性的自动和高效发现仍然是一个开放的问题。文中提出了一个更广泛的新对称性概念——预期回报对称性，其中环境对称性为其子群。通过训练与预期回报对称性相容的代理，相比于仅使用环境对称性的方法，能实现更好的零样本协调效果。此外，这种方法对环境结构的预设假设最少，并不需要访问真实的对称信息。 <div>
arXiv:2502.01711v2 Announce Type: replace 
Abstract: Symmetry is an important inductive bias that can improve model robustness and generalization across many deep learning domains. In multi-agent settings, a priori known symmetries have been shown to address a fundamental coordination failure mode known as mutually incompatible symmetry breaking; e.g. in a game where two independent agents can choose to move "left'' or "right'', and where a reward of +1 or -1 is received when the agents choose the same action or different actions, respectively. However, the efficient and automatic discovery of environment symmetries, in particular for decentralized partially observable Markov decision processes, remains an open problem. Furthermore, environmental symmetry breaking constitutes only one type of coordination failure, which motivates the search for a more accessible and broader symmetry class. In this paper, we introduce such a broader group of previously unexplored symmetries, which we call expected return symmetries, which contains environment symmetries as a subgroup. We show that agents trained to be compatible under the group of expected return symmetries achieve better zero-shot coordination results than those using environment symmetries. As an additional benefit, our method makes minimal a priori assumptions about the structure of their environment and does not require access to ground truth symmetries.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Convex Is Back: Solving Belief MDPs With Convexity-Informed Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.09298</link>
<guid>https://arxiv.org/abs/2502.09298</guid>
<content:encoded><![CDATA[
<div> 关键词：Deep Reinforcement Learning (深度强化学习)，Partially Observable Markov Decision Processes (部分可观测马尔科夫决策过程)，convex property (凸性质)，hard-enforced convexity (硬约束凸性)，soft-enforced convexity (软约束凸性)

<br /><br />总结:
本文提出了一种针对Partialy Observable Markov Decision Processes（POMDPs）中的Deep Reinforcement Learning（DRL）新方法，该方法利用了值函数在信念空间上的凸性质。文中介绍了两种不同方法，即硬约束凸性和软约束凸性，并将它们与标准DRL在经典的Tiger和FieldVisionRockSample问题环境中进行了对比实验。实验结果显示，引入凸性特征可以显著提高智能体的性能以及对超参数空间的鲁棒性，特别是在测试远离训练分布的领域时效果尤为明显。相关源代码已在https://github.com/Dakout/Convex_DRL上发布。 <div>
arXiv:2502.09298v2 Announce Type: replace 
Abstract: We present a novel method for Deep Reinforcement Learning (DRL), incorporating the convex property of the value function over the belief space in Partially Observable Markov Decision Processes (POMDPs). We introduce hard- and soft-enforced convexity as two different approaches, and compare their performance against standard DRL on two well-known POMDP environments, namely the Tiger and FieldVisionRockSample problems. Our findings show that including the convexity feature can substantially increase performance of the agents, as well as increase robustness over the hyperparameter space, especially when testing on out-of-distribution domains. The source code for this work can be found at https://github.com/Dakout/Convex_DRL.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>OWLViz: An Open-World Benchmark for Visual Question Answering</title>
<link>https://arxiv.org/abs/2503.07631</link>
<guid>https://arxiv.org/abs/2503.07631</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2503.07631v1, OWLViz, 视觉问题回答, 多模态系统, 工具选择

总结:
本文介绍了针对开放世界视觉问题回答任务的新挑战性基准——OWLViz。该基准提出了需要结合多种能力（包括视觉理解、网络探索和专业工具使用）的清晰、无歧义的问题。尽管人类在这个任务上的准确率能达到69.2%，但最先进的VLM模型——Gemini 2.0，其准确率仅达到26.6%。依赖有限的视觉和视觉-语言模型作为工具的当前代理型VLMs表现更差。这种性能差距揭示了多模态系统在选择适当工具和执行复杂推理序列方面的能力存在显著局限，为推进实用AI研究指明了新的方向。 <div>
arXiv:2503.07631v1 Announce Type: new 
Abstract: We present a challenging benchmark for the Open WorLd VISual question answering (OWLViz) task. OWLViz presents concise, unambiguous queries that require integrating multiple capabilities, including visual understanding, web exploration, and specialized tool usage. While humans achieve 69.2% accuracy on these intuitive tasks, even state-of-the-art VLMs struggle, with the best model, Gemini 2.0, achieving only 26.6% accuracy. Current agentic VLMs, which rely on limited vision and vision-language models as tools, perform even worse. This performance gap reveals significant limitations in multimodal systems' ability to select appropriate tools and execute complex reasoning sequences, establishing new directions for advancing practical AI research.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Case Study of Counting the Number of Unique Users in Linear and Non-Linear Trails -- A Multi-Agent System Approach</title>
<link>https://arxiv.org/abs/2503.07651</link>
<guid>https://arxiv.org/abs/2503.07651</guid>
<content:encoded><![CDATA[
<div> 关键词：公园使用分析、视频监控、多Agent系统、独特用户识别、自动化监测

总结:<br />
本文提出了一种利用低成本分布式网络摄像头的多Agent系统，用于公园使用情况的全面分析和独特用户追踪。该系统部署于特拉华州的Jack A. MarkellTrail和Hall Trail，能自动处理视频数据并提取用户的运动速度、方向、活动类型、服装颜色和性别等属性信息。通过跨相机共享这些信息，系统能够构建移动轨迹并准确统计独特的访客数量。与人工计数和模拟场景对比验证后，该系统在识别独特用户方面的成功率达到了72%，为实时公园使用分析和游客行为追踪提供了一个可扩展且成本效益高的解决方案，克服了诸如摄像机布置和环境因素等挑战。 <div>
arXiv:2503.07651v1 Announce Type: new 
Abstract: Parks play a crucial role in enhancing the quality of life by providing recreational spaces and environmental benefits. Understanding the patterns of park usage, including the number of visitors and their activities, is essential for effective security measures, infrastructure maintenance, and resource allocation. Traditional methods rely on single-entry sensors that count total visits but fail to distinguish unique users, limiting their effectiveness due to manpower and cost constraints.With advancements in affordable video surveillance and networked processing, more comprehensive park usage analysis is now feasible. This study proposes a multi-agent system leveraging low-cost cameras in a distributed network to track and analyze unique users. As a case study, we deployed this system at the Jack A. Markell (JAM) Trail in Wilmington, Delaware, and Hall Trail in Newark, Delaware. The system captures video data, autonomously processes it using existing algorithms, and extracts user attributes such as speed, direction, activity type, clothing color, and gender. These attributes are shared across cameras to construct movement trails and accurately count unique visitors. Our approach was validated through comparison with manual human counts and simulated scenarios under various conditions. The results demonstrate a 72% success rate in identifying unique users, setting a benchmark in automated park activity monitoring. Despite challenges such as camera placement and environmental factors, our findings suggest that this system offers a scalable, cost-effective solution for real-time park usage analysis and visitor behavior tracking.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DriveTransformer: Unified Transformer for Scalable End-to-End Autonomous Driving</title>
<link>https://arxiv.org/abs/2503.07656</link>
<guid>https://arxiv.org/abs/2503.07656</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端自动驾驶、任务并行性、稀疏表示、流式处理、DriveTransformer

<br /><br />总结:
本文介绍了端到端自动驾驶（E2E-AD）领域的一项新进展——DriveTransformer框架。现有的E2E-AD方法通常采用感知-预测-规划的序列化范式，存在累积误差和训练不稳定性等问题。针对这些问题，DriveTransformer提出三个关键特性：任务并行性（所有主体、地图和规划查询在每个模块中直接相互作用）、稀疏表示（任务查询直接与原始传感器特征交互）以及流式处理（任务查询被存储并通过历史信息传递）。这些改进使得新框架由统一的操作构成：任务自注意力、传感器交叉注意力和时间交叉注意力，显著降低了系统复杂度并提高了训练稳定性。实验表明，DriveTransformer在模拟闭环基准Bench2Drive和真实世界开放环基准nuScenes上均实现了最佳性能，同时具备高FPS优势。 <div>
arXiv:2503.07656v1 Announce Type: new 
Abstract: End-to-end autonomous driving (E2E-AD) has emerged as a trend in the field of autonomous driving, promising a data-driven, scalable approach to system design. However, existing E2E-AD methods usually adopt the sequential paradigm of perception-prediction-planning, which leads to cumulative errors and training instability. The manual ordering of tasks also limits the system`s ability to leverage synergies between tasks (for example, planning-aware perception and game-theoretic interactive prediction and planning). Moreover, the dense BEV representation adopted by existing methods brings computational challenges for long-range perception and long-term temporal fusion. To address these challenges, we present DriveTransformer, a simplified E2E-AD framework for the ease of scaling up, characterized by three key features: Task Parallelism (All agent, map, and planning queries direct interact with each other at each block), Sparse Representation (Task queries direct interact with raw sensor features), and Streaming Processing (Task queries are stored and passed as history information). As a result, the new framework is composed of three unified operations: task self-attention, sensor cross-attention, temporal cross-attention, which significantly reduces the complexity of system and leads to better training stability. DriveTransformer achieves state-of-the-art performance in both simulated closed-loop benchmark Bench2Drive and real world open-loop benchmark nuScenes with high FPS.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HIPPO-MAT: Decentralized Task Allocation Using GraphSAGE and Multi-Agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.07662</link>
<guid>https://arxiv.org/abs/2503.07662</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、分布式连续任务分配、图神经网络、独立策略优化、冲突避免

总结:
本文提出了一种新的多智能体系统中分布式连续任务分配框架HIPPO-MAT。该框架结合了使用GraphSAGE架构的图神经网络来计算每个代理的独立嵌入和独立策略优化（IPPO）方法进行多智能体深度强化学习。在这个系统中，无人机(UAVs)和无人地面车辆(UGVs)通过通信通道共享聚合观测数据并独立处理这些输入以生成丰富的状态嵌入。这种方法允许在无需中央协调的情况下实现动态、成本最优和冲突感知的任务分配。文中还整合了一个修改后的A*路径规划器，用于有效的路径规划和碰撞避免。模拟实验显示该方法具有可扩展性，可处理多达30个智能体的情况，并在JetBot ROS AI机器人上进行了初步的实证验证，每个机器人运行其模型并在Jetson Nano上进行计算，通过ESP-NOW协议利用ESP32-S3进行通信，证实了该方法结合同时定位和映射(SLAM)的实际可行性。实验结果显示，该方法成功实现了高达92.5%的无冲突成功率，与集中式匈牙利方法相比性能差距仅为16.49%，并且优于基于贪婪算法的分散式基线方法。此外，该框架表现出良好的可扩展性，能够处理每步时间仅需0.32秒的任务分配处理，并对动态生成的任务具有鲁棒响应能力。<br /><br /> <div>
arXiv:2503.07662v1 Announce Type: new 
Abstract: This paper tackles decentralized continuous task allocation in heterogeneous multi-agent systems. We present a novel framework HIPPO-MAT that integrates graph neural networks (GNN) employing a GraphSAGE architecture to compute independent embeddings on each agent with an Independent Proximal Policy Optimization (IPPO) approach for multi-agent deep reinforcement learning. In our system, unmanned aerial vehicles (UAVs) and unmanned ground vehicles (UGVs) share aggregated observation data via communication channels while independently processing these inputs to generate enriched state embeddings. This design enables dynamic, cost-optimal, conflict-aware task allocation in a 3D grid environment without the need for centralized coordination. A modified A* path planner is incorporated for efficient routing and collision avoidance. Simulation experiments demonstrate scalability with up to 30 agents and preliminary real-world validation on JetBot ROS AI Robots, each running its model on a Jetson Nano and communicating through an ESP-NOW protocol using ESP32-S3, which confirms the practical viability of the approach that incorporates simultaneous localization and mapping (SLAM). Experimental results revealed that our method achieves a high 92.5% conflict-free success rate, with only a 16.49% performance gap compared to the centralized Hungarian method, while outperforming the heuristic decentralized baseline based on greedy approach. Additionally, the framework exhibits scalability with up to 30 agents with allocation processing of 0.32 simulation step time and robustness in responding to dynamically generated tasks.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The potential role of AI agents in transforming nuclear medicine research and cancer management in India</title>
<link>https://arxiv.org/abs/2503.07673</link>
<guid>https://arxiv.org/abs/2503.07673</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)、癌症负担、核医学、印度、基础设施

<br /><br />总结:
本文探讨了印度面临的严峻癌症问题，指出尽管政府和医疗机构正努力改善物理医疗设施限制，但鉴于国土广阔、人口密度高，急需寻求替代软基础设施解决方案。文章聚焦于人工智能在医学领域的应用，尤其是对印度癌症研究、诊断和管理中核医学可能产生的推动作用。文中首先概述了AI代理的能力，并提出了一种基于AI代理的生态系统方案，旨在解决印度核医学领域现存的可持续性挑战。 <div>
arXiv:2503.07673v1 Announce Type: new 
Abstract: India faces a significant cancer burden, with an incidence-to-mortality ratio indicating that nearly three out of five individuals diagnosed with cancer succumb to the disease. While the limitations of physical healthcare infrastructure are widely acknowledged as a primary challenge, concerted efforts by government and healthcare agencies are underway to mitigate these constraints. However, given the country's vast geography and high population density, it is imperative to explore alternative soft infrastructure solutions to complement existing frameworks. Artificial Intelligence agents are increasingly transforming problem-solving approaches across various domains, with their application in medicine proving particularly transformative. In this perspective, we examine the potential role of AI agents in advancing nuclear medicine for cancer research, diagnosis, and management in India. We begin with a brief overview of AI agents and their capabilities, followed by a proposed agent-based ecosystem that can address prevailing sustainability challenges in India nuclear medicine.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DynTaskMAS: A Dynamic Task Graph-driven Framework for Asynchronous and Parallel LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.07675</link>
<guid>https://arxiv.org/abs/2503.07675</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、多智能体系统、资源管理、异步并行执行、动态任务管理

<br /><br />总结：
本文介绍了DynTaskMAS，这是一个针对基于大规模语言模型（LLMs）的多智能体系统（MAS）的新框架，旨在解决资源管理、任务协调和系统效率等问题。该框架有四个关键创新点：(1) 动态任务图生成器能够智能分解复杂任务并保持逻辑依赖；(2) 异步并行执行引擎通过有效的任务调度优化资源利用；(3) 语义感知上下文管理系统实现智能体间高效的信息共享；(4) 自适应工作流管理器能动态优化系统性能。实验结果表明，与传统方法相比，DynTaskMAS可以显著减少执行时间（对于复杂任务降低21-33%），提高资源利用率（从65%提升至88%），并在多达16个并发智能体的情况下实现接近线性的吞吐量扩展（相对于4个智能体提升3.47倍）。该框架为构建可处理复杂动态任务的、具有可扩展性和高性能的LLM基多智能体系统奠定了基础。 <div>
arXiv:2503.07675v1 Announce Type: new 
Abstract: The emergence of Large Language Models (LLMs) in Multi-Agent Systems (MAS) has opened new possibilities for artificial intelligence, yet current implementations face significant challenges in resource management, task coordination, and system efficiency. While existing frameworks demonstrate the potential of LLM-based agents in collaborative problem-solving, they often lack sophisticated mechanisms for parallel execution and dynamic task management. This paper introduces DynTaskMAS, a novel framework that orchestrates asynchronous and parallel operations in LLM-based MAS through dynamic task graphs. The framework features four key innovations: (1) a Dynamic Task Graph Generator that intelligently decomposes complex tasks while maintaining logical dependencies, (2) an Asynchronous Parallel Execution Engine that optimizes resource utilization through efficient task scheduling, (3) a Semantic-Aware Context Management System that enables efficient information sharing among agents, and (4) an Adaptive Workflow Manager that dynamically optimizes system performance. Experimental evaluations demonstrate that DynTaskMAS achieves significant improvements over traditional approaches: a 21-33% reduction in execution time across task complexities (with higher gains for more complex tasks), a 35.4% improvement in resource utilization (from 65% to 88%), and near-linear throughput scaling up to 16 concurrent agents (3.47X improvement for 4X agents). Our framework establishes a foundation for building scalable, high-performance LLM-based multi-agent systems capable of handling complex, dynamic tasks efficiently.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Using a single actor to output personalized policy for different intersections</title>
<link>https://arxiv.org/abs/2503.07678</link>
<guid>https://arxiv.org/abs/2503.07678</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 适应性交通信号控制(ATSC), 中心化训练与分散化执行(CTDE), 超行动多头亲和力策略优化(HAMH-PPO), 图注意力单元

总结:<br />
本文针对多交叉口交通场景中的适应性交通信号控制问题，提出了一个基于多智能体强化学习的方法——Hyper-Action Multi-Head Proximal Policy Optimization (HAMH-PPO)。该方法利用CTDE框架，在非独立同分布的观测条件下，通过共享的PPO策略网络实现各交叉口的个性化策略。HAMH-PPO的集中式批评者使用图注意力单元计算所有交叉口的图表示，并为每个交叉口输出多个值估计。而分散式执行演员则依据本地观测历史输入，生成动作分布及一种称为“超行动”的量，以平衡集中式批评者给出的多个价值评估，进一步指导交通信号控制策略的更新。通过超行动和多头值的结合，HAMH-PPO使得多个智能体能在共享一个actor-critic的同时实现个性化的策略。 <div>
arXiv:2503.07678v1 Announce Type: new 
Abstract: Recently, with the development of Multi-agent reinforcement learning (MARL), adaptive traffic signal control (ATSC) has achieved satisfactory results. In traffic scenarios with multiple intersections, MARL treats each intersection as an agent and optimizes traffic signal control strategies through learning and real-time decision-making. Considering that observation distributions of intersections might be different in real-world scenarios, shared parameter methods might lack diversity and thus lead to high generalization requirements in the shared-policy network. A typical solution is to increase the size of network parameters. However, simply increasing the scale of the network does not necessarily improve policy generalization, which is validated in our experiments. Accordingly, an approach that considers both the personalization of intersections and the efficiency of parameter sharing is required. To this end, we propose Hyper-Action Multi-Head Proximal Policy Optimization (HAMH-PPO), a Centralized Training with Decentralized Execution (CTDE) MARL method that utilizes a shared PPO policy network to deliver personalized policies for intersections with non-iid observation distributions. The centralized critic in HAMH-PPO uses graph attention units to calculate the graph representations of all intersections and outputs a set of value estimates with multiple output heads for each intersection. The decentralized execution actor takes the local observation history as input and output distributions of action as well as a so-called hyper-action to balance the multiple values estimated from the centralized critic to further guide the updating of TSC policies. The combination of hyper-action and multi-head values enables multiple agents to share a single actor-critic while achieving personalized policies.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive routing protocols for determining optimal paths in AI multi-agent systems: a priority- and learning-enhanced approach</title>
<link>https://arxiv.org/abs/2503.07686</link>
<guid>https://arxiv.org/abs/2503.07686</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式人工智能，多智能体架构，自适应路由算法，强化学习，资源优化

总结:

该文针对日益复杂的分布式人工智能和多智能体架构，提出了一种新的、自适应的路由算法。该算法基于扩展的Dijkstra框架，融合了优先级成本函数和动态学习机制，考虑了任务复杂度、用户请求优先级、智能体能力、带宽、延迟、负载、模型复杂度和可靠性等多维度参数。同时，通过使用强化学习动态调整权重因子来不断优化路由策略，根据网络性能进行自我进化。此外，结合启发式过滤和层次化路由结构以提升系统的可伸缩性和响应速度。最终，这种方法实现了上下文感知、负载意识和优先级导向的路由决策，有效减少了关键任务的延迟并优化了整体资源利用，从而提升了多智能体系统的健壮性、灵活性和效率。 <div>
arXiv:2503.07686v1 Announce Type: new 
Abstract: As distributed artificial intelligence (AI) and multi-agent architectures grow increasingly complex, the need for adaptive, context-aware routing becomes paramount. This paper introduces an enhanced, adaptive routing algorithm tailored for AI multi-agent networks, integrating priority-based cost functions and dynamic learning mechanisms. Building on an extended Dijkstra-based framework, we incorporate multi-faceted parameters such as task complexity, user request priority, agent capabilities, bandwidth, latency, load, model sophistication, and reliability. We further propose dynamically adaptive weighting factors, tuned via reinforcement learning (RL), to continuously evolve routing policies based on observed network performance. Additionally, heuristic filtering and hierarchical routing structures improve scalability and responsiveness. Our approach yields context-sensitive, load-aware, and priority-focused routing decisions that not only reduce latency for critical tasks but also optimize overall resource utilization, ultimately enhancing the robustness, flexibility, and efficiency of multi-agent systems.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully Autonomous Programming using Iterative Multi-Agent Debugging with Large Language Models</title>
<link>https://arxiv.org/abs/2503.07693</link>
<guid>https://arxiv.org/abs/2503.07693</guid>
<content:encoded><![CDATA[
<div> 关键词：近似命中综合症、多智能体框架、Synthesize, Execute, Instruct, Debug, and Repair (SEIDR)、大型语言模型、程序合成基准

总结:<br />
本文针对使用大型语言模型（LLMs）进行程序综合时出现的“近似命中综合症”问题，提出了一种名为Synthesize, Execute, Instruct, Debug, and Repair (SEIDR)的多智能体框架。该框架着重研究了如何为LLMs确定最佳提示、选择调试轮中最佳程序的排名算法以及平衡不成功程序的修复与新程序生成之间的关系。文章通过比较不同调试策略（如替换关注、修复关注和混合策略），以及评估lexicase和锦标赛选择在各代中的排名效果。实验结果表明，在Program Synthesis Benchmark 2 (PSB2)上，SEIDR框架优于仅使用OpenAI Codex而不进行修复阶段的传统方法和传统遗传编程方法。SEIDR不仅在C++和Python的PSB2上分别至少解决了18个和20个问题，而且在HumanEval-C++基准上使用Llama 3-8B时，平均pass@100达到84.2%。总的来说，SEIDR有效地克服了LLMs在程序综合中的近似命中综合症问题。 <div>
arXiv:2503.07693v1 Announce Type: new 
Abstract: Program synthesis with Large Language Models (LLMs) suffers from a "near-miss syndrome": the generated code closely resembles a correct solution but fails unit tests due to minor errors. We address this with a multi-agent framework called Synthesize, Execute, Instruct, Debug, and Repair (SEIDR). Effectively applying SEIDR to instruction-tuned LLMs requires determining (a) optimal prompts for LLMs, (b) what ranking algorithm selects the best programs in debugging rounds, and (c) balancing the repair of unsuccessful programs with the generation of new ones. We empirically explore these trade-offs by comparing replace-focused, repair-focused, and hybrid debug strategies. We also evaluate lexicase and tournament selection to rank candidates in each generation. On Program Synthesis Benchmark 2 (PSB2), our framework outperforms both conventional use of OpenAI Codex without a repair phase and traditional genetic programming approaches. SEIDR outperforms the use of an LLM alone, solving 18 problems in C++ and 20 in Python on PSB2 at least once across experiments. To assess generalizability, we employ GPT-3.5 and Llama 3 on the PSB2 and HumanEval-X benchmarks. Although SEIDR with these models does not surpass current state-of-the-art methods on the Python benchmarks, the results on HumanEval-C++ are promising. SEIDR with Llama 3-8B achieves an average pass@100 of 84.2%. Across all SEIDR runs, 163 of 164 problems are solved at least once with GPT-3.5 in HumanEval-C++, and 162 of 164 with the smaller Llama 3-8B. We conclude that SEIDR effectively overcomes the near-miss syndrome in program synthesis with LLMs.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Benchmark Generation for Repository-Level Coding Tasks</title>
<link>https://arxiv.org/abs/2503.07701</link>
<guid>https://arxiv.org/abs/2503.07701</guid>
<content:encoded><![CDATA[
<div> 关键词: Code Agent, SWE-Bench,SetUpAgent, SWEE-Bench, SWA-Bench

总结:
文章介绍了代码生成代理（Code Agent）领域的一个关键问题——可靠的性能度量标准。SWE-Bench作为该领域的热门基准测试，要求代码代理根据完整仓库上下文生成针对GitHub问题的补丁，并通过执行与问题解决相关的测试套件来评估补丁的正确性。然而，构建此类基准测试需要大量手动工作，限制了考虑的仓库数量，可能导致性能测量结果与现实世界场景不符，从而误导开发工作。为解决这一挑战，文章提出了一个全自动系统SetUpAgent，它能准确地进行历史依赖设置、测试执行和结果解析。使用SetUpAgent，作者创建了两个新数据集：(i) 扩展版的SWE-Bench——SWEE-Bench，包含了数百个仓库；以及(ii) 专注于应用程序而非库的新基准SWA-Bench。通过对这些数据集与SWE-Bench的比较，研究发现显著的分布差异，包括较低的问题描述质量和详细程度、更高的修复复杂性和最多可达40%的较低代理成功率。 <div>
arXiv:2503.07701v1 Announce Type: new 
Abstract: Code Agent development is an extremely active research area, where a reliable performance metric is critical for tracking progress and guiding new developments. This demand is underscored by the meteoric rise in popularity of SWE-Bench. This benchmark challenges code agents to generate patches addressing GitHub issues given the full repository as context. The correctness of generated patches is then evaluated by executing a human-written test suite extracted from the repository after the issue's resolution. However, constructing benchmarks like SWE-Bench requires substantial manual effort to set up historically accurate execution environments for testing. Crucially, this severely limits the number of considered repositories, e.g., just 12 for SWE-Bench. Considering so few repositories, selected for their popularity runs the risk of leading to a distributional mismatch, i.e., the measured performance may not be representative of real-world scenarios potentially misguiding development efforts. In this work, we address this challenge and introduce SetUpAgent, a fully automated system capable of historically accurate dependency setup, test execution, and result parsing. Using SetUpAgent, we generate two new datasets: (i) SWEE-Bench an extended version of SWE-Bench encompassing hundreds of repositories, and (ii) SWA-Bench a benchmark focusing on applications rather than libraries. Comparing these datasets to SWE-Bench with respect to their characteristics and code agent performance, we find significant distributional differences, including lower issue description quality and detail level, higher fix complexity, and most importantly up to 40% lower agent success rates.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Reliable Self-Organized Distributed Complex Network for Communication of Smart Agents</title>
<link>https://arxiv.org/abs/2503.07702</link>
<guid>https://arxiv.org/abs/2503.07702</guid>
<content:encoded><![CDATA[
<div> 关键词：协作、复杂系统、网络、强化学习、物理Hamiltonian

总结:<br />
本文研究了复杂系统中的协作现象，并以网络的形式来分析此类系统的集体行为。其中，节点代表可以通过强化学习技术进行训练的智能代理。这些智能代理依据局部观察信息自主调整与其邻居之间的连接，最终形成大规模的通信集群。值得注意的是，该过程中没有集中式的管理员调控，而是通过将连接策略形式化为物理Hamiltonian的方式，使这一智能系统归属于“物理学引导的机器学习”范式。 <div>
arXiv:2503.07702v1 Announce Type: new 
Abstract: Collaboration is a fundamental and essential characteristic of many complex systems, ranging from ant colonies to human societies. Each component within a complex system interacts with others, even at a distance, to accomplish a given task. A network of collaboration can be defined to study the collective behavior of such systems within the framework of complex networks. The nodes in these networks may represent simple organisms or more sophisticated intelligent agents, such as humans. In this study, we utilize intelligent agents (nodes) trained through reinforcement learning techniques to establish connections with their neighbors, ultimately leading to the emergence of a large-scale communication cluster. Notably, there is no centralized administrator; instead, agents must adjust their connections based on information obtained from local observations. The connection strategy is formulated using a physical Hamiltonian, thereby categorizing this intelligent system under the paradigm of "Physics-Guided Machine Learning".
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Sensemaking in Novel Environments: How Human Cognition Can Inform Artificial Agents</title>
<link>https://arxiv.org/abs/2503.07783</link>
<guid>https://arxiv.org/abs/2503.07783</guid>
<content:encoded><![CDATA[
<div> 关键词：artificial intelligence, sensemaking, novel environments, conceptual framework, shared attributes

总结:
本文提出了一种创建具有在新环境中进行情境理解能力的人工智能代理的方法。文章主要阐述了以下几个要点：
1. 提出了一种新的统一的情境理解概念框架，该框架包括嵌入并跨越多个框架的符号关系。
2. 通过共享属性实现各种内容可寻址、分布式知识结构之间的交互，它们的整体响应可以代表在新环境中作为情境理解标志的综合对象、事件或情况。
3. 论文指出，不同记忆中的属性可以共享和以新颖的方式重组，生成用于表示新环境中的特定结果的合成符号，即情境理解。

<br /><br /> <div>
arXiv:2503.07783v1 Announce Type: new 
Abstract: One of the most vital cognitive skills to possess is the ability to make sense of objects, events, and situations in the world. In the current paper, we offer an approach for creating artificially intelligent agents with the capacity for sensemaking in novel environments. Objectives: to present several key ideas: (1) a novel unified conceptual framework for sensemaking (which includes the existence of sign relations embedded within and across frames); (2) interaction among various content-addressable, distributed-knowledge structures via shared attributes (whose net response would represent a synthesized object, event, or situation serving as a sign for sensemaking in a novel environment). Findings: we suggest that attributes across memories can be shared and recombined in novel ways to create synthesized signs, which can denote certain outcomes in novel environments (i.e., sensemaking).
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Magnet: Multi-turn Tool-use Data Synthesis and Distillation via Graph Translation</title>
<link>https://arxiv.org/abs/2503.07826</link>
<guid>https://arxiv.org/abs/2503.07826</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、多轮交互、Magnet框架、训练轨迹、功能调用能力

总结:
本文提出了一个名为Magnet的新型框架，旨在提升大型语言模型在与人类进行多轮对话中调用外部工具的能力。该框架通过自动和迭代的方式将函数签名路径转化为查询序列和可执行的函数调用。利用图模型描述复杂的功能交互，并设计了新颖的节点操作来构建可靠的签名路径。为了指导正负样本训练轨迹的生成，借鉴上下文蒸馏思想，文中采用教师模型提供正确的函数调用序列作为正向提示，并使用对比性错误的函数调用作为负向提示。实验结果显示，经过监督微调以及基于负面轨迹的偏好优化训练后的14B规模模型——Magnet-14B-mDPO，在BFCL-v3和ToolQuery两个基准上分别取得了68.01和73.30的性能评分，大幅超越了教师模型Gemini-1.5-pro-002的功能调用表现。

<br /><br />总结: <div>
arXiv:2503.07826v1 Announce Type: new 
Abstract: Large language models (LLMs) have exhibited the ability to effectively utilize external tools to address user queries. However, their performance may be limited in complex, multi-turn interactions involving users and multiple tools. To address this, we propose Magnet, a principled framework for synthesizing high-quality training trajectories to enhance the function calling capability of large language model agents in multi-turn conversations with humans. The framework is based on automatic and iterative translations from a function signature path to a sequence of queries and executable function calls. We model the complicated function interactions in multi-turn cases with graph and design novel node operations to build reliable signature paths. Motivated by context distillation, when guiding the generation of positive and negative trajectories using a teacher model, we provide reference function call sequences as positive hints in context and contrastive, incorrect function calls as negative hints. Experiments show that training with the positive trajectories with supervised fine-tuning and preference optimization against negative trajectories, our 14B model, Magnet-14B-mDPO, obtains 68.01 on BFCL-v3 and 73.30 on ToolQuery, surpassing the performance of the teacher model Gemini-1.5-pro-002 by a large margin in function calling.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>RefactorBench: Evaluating Stateful Reasoning in Language Agents Through Code</title>
<link>https://arxiv.org/abs/2503.07832</link>
<guid>https://arxiv.org/abs/2503.07832</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、RefactorBench、基准测试、多文件重构任务、状态感知

总结:
文章介绍了近期语言模型(LM)代理和函数调用技术在各种数字领域问题解决上的进步。为了深入理解LM代理的独特局限性，研究者提出了RefactorBench，这是一个包含100个大型手工制作的多文件重构任务的基准测试集，这些任务来自流行的开源项目，需要对多个文件之间的依赖关系进行深入探索并严格遵循相关指令。实验结果显示，当前的LM代理在处理具有基本指令的简单组合任务上表现不佳，仅能解决22%的任务，而人类开发者在短时间内可解决87%。通过轨迹分析，研究者发现了LM代理的各种独特失败模式，并重点关注了其追踪过去操作的失败方式。通过改进基线代理，使其基于状态表示进行条件判断，成功将解决RefactorBench任务的能力提升了43.9%。此外，研究者还扩展了状态感知的方法以覆盖整个数字环境，并指出了未来研究的潜在方向。RefactorBench旨在为LM代理的研究提供一套现实世界中的多步代码任务集合。 <div>
arXiv:2503.07832v1 Announce Type: new 
Abstract: Recent advances in language model (LM) agents and function calling have enabled autonomous, feedback-driven systems to solve problems across various digital domains. To better understand the unique limitations of LM agents, we introduce RefactorBench, a benchmark consisting of 100 large handcrafted multi-file refactoring tasks in popular open-source repositories. Solving tasks within RefactorBench requires thorough exploration of dependencies across multiple files and strong adherence to relevant instructions. Every task is defined by 3 natural language instructions of varying specificity and is mutually exclusive, allowing for the creation of longer combined tasks on the same repository. Baselines on RefactorBench reveal that current LM agents struggle with simple compositional tasks, solving only 22% of tasks with base instructions, in contrast to a human developer with short time constraints solving 87%. Through trajectory analysis, we identify various unique failure modes of LM agents, and further explore the failure mode of tracking past actions. By adapting a baseline agent to condition on representations of state, we achieve a 43.9% improvement in solving RefactorBench tasks. We further extend our state-aware approach to encompass entire digital environments and outline potential directions for future research. RefactorBench aims to support the study of LM agents by providing a set of real-world, multi-hop tasks within the realm of code.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Explicable Policy Search</title>
<link>https://arxiv.org/abs/2503.07848</link>
<guid>https://arxiv.org/abs/2503.07848</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、用户期望、安全性、学习方法、Safe Explicable Policy Search (SEPS)

总结:
本文提出了一个新的机器学习方法——安全可解释策略搜索(SEPS)，用于生成符合用户期望并同时最大限度降低安全风险的行为。在AI代理与用户交互过程中，用户对代理的行为形成预期，而这些预期可能与代理的实际行为规划存在差异。SEPS旨在通过将约束优化和可解释策略搜索相结合，确保在学习过程中及之后生成既可解释又安全的行为。文章以受控优化问题的形式表述SEPS，要求最大化行为的可解释性得分，同时满足关于安全性和代理模型的次优性约束。通过对安全环境和物理机器人实验的评估，结果表明SEPS能够在保证达到期望性能水平的同时，实现安全、可解释的行为生成，对于现实世界中的人机协作具有重要意义。 <div>
arXiv:2503.07848v1 Announce Type: new 
Abstract: When users work with AI agents, they form conscious or subconscious expectations of them. Meeting user expectations is crucial for such agents to engage in successful interactions and teaming. However, users may form expectations of an agent that differ from the agent's planned behaviors. These differences lead to the consideration of two separate decision models in the planning process to generate explicable behaviors. However, little has been done to incorporate safety considerations, especially in a learning setting. We present Safe Explicable Policy Search (SEPS), which aims to provide a learning approach to explicable behavior generation while minimizing the safety risk, both during and after learning. We formulate SEPS as a constrained optimization problem where the agent aims to maximize an explicability score subject to constraints on safety and a suboptimality criterion based on the agent's model. SEPS innovatively combines the capabilities of Constrained Policy Optimization and Explicable Policy Search. We evaluate SEPS in safety-gym environments and with a physical robot experiment to show that it can learn explicable behaviors that adhere to the agent's safety requirements and are efficient. Results show that SEPS can generate safe and explicable behaviors while ensuring a desired level of performance w.r.t. the agent's objective, and has real-world relevance in human-AI teaming.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Video Action Differencing</title>
<link>https://arxiv.org/abs/2503.07860</link>
<guid>https://arxiv.org/abs/2503.07860</guid>
<content:encoded><![CDATA[
<div> 关键词：Video Action Differencing (VidDiff)，VidDiffBench，benchmark dataset，large multimodal models (LMMs)，GPT-4o，Qwen2-VL，action difference proposal，keyframe localization，frame differencing

总结:
本文提出了一种新的任务——视频动作差异识别（VidDiff），旨在识别同一动作执行中的微妙差异，适用于如教练和技能学习等场景。为了推动该任务的研究，作者构建了包含549对视频、4,469项精细动作差异标注和2,075个定位时间戳的VidDiffBench基准数据集。实验表明，当前最先进的大型多模态模型（如GPT-4o和Qwen2-VL）在此基准上表现具有挑战性。通过对这些模型的失败案例分析，作者指出了VidDiff任务面临的两大难点：跨视频的动作子部分定位和帧级别的细粒度比较。为解决这些问题，文章提出了VidDiff方法，通过三个阶段（动作差异提案、关键帧定位和帧差异计算）的代理工作流程，每个阶段利用专门的基础模型。最后，作者将基准数据集和代码公开以促进未来对此新任务的研究。 <div>
arXiv:2503.07860v1 Announce Type: new 
Abstract: How do two individuals differ when performing the same action? In this work, we introduce Video Action Differencing (VidDiff), the novel task of identifying subtle differences between videos of the same action, which has many applications, such as coaching and skill learning. To enable development on this new task, we first create VidDiffBench, a benchmark dataset containing 549 video pairs, with human annotations of 4,469 fine-grained action differences and 2,075 localization timestamps indicating where these differences occur. Our experiments demonstrate that VidDiffBench poses a significant challenge for state-of-the-art large multimodal models (LMMs), such as GPT-4o and Qwen2-VL. By analyzing failure cases of LMMs on VidDiffBench, we highlight two key challenges for this task: localizing relevant sub-actions over two videos and fine-grained frame comparison. To overcome these, we propose the VidDiff method, an agentic workflow that breaks the task into three stages: action difference proposal, keyframe localization, and frame differencing, each stage utilizing specialized foundation models. To encourage future research in this new task, we release the benchmark at https://huggingface.co/datasets/jmhb/VidDiffBench and code at http://jmhb0.github.io/viddiff.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BEARCUBS: A benchmark for computer-using web agents</title>
<link>https://arxiv.org/abs/2503.07919</link>
<guid>https://arxiv.org/abs/2503.07919</guid>
<content:encoded><![CDATA[
<div> 关键词：BEARCUBS、web代理、信息寻求、多模态交互、评估基准

<br /><br />总结：
本文介绍了一个名为BEARCUBS的新颖网页搜索和浏览评估基准，它由111个旨在测试网络代理在现实环境中搜索、浏览并从网页中识别事实信息能力的信息寻求问题组成。与以往的基准不同，BEARCUBS要求代理访问实时网络内容并执行多种多模态交互（如视频理解、3D导航），而不能仅依赖文本工作绕行方案。每个问题都有明确的人工验证答案及浏览轨迹，便于透明地评估代理性能和策略。研究表明，人类解题准确率为84.7%，但最先进的计算机使用型代理表现不佳，最佳系统（OpenAI的Operator）仅达到24.3%的准确率，揭示了可靠源选择和更强大的多模态能力等方面的改进需求。为了推动未来研究，BEARCUBS将定期更新，替换无效或污染的问题，保持其对新一代网络代理的挑战性。 <div>
arXiv:2503.07919v1 Announce Type: new 
Abstract: Modern web agents possess computer use abilities that allow them to interact with webpages by sending commands to a virtual keyboard and mouse. While such agents have considerable potential to assist human users with complex tasks, evaluating their capabilities in real-world settings poses a major challenge. To this end, we introduce BEARCUBS, a "small but mighty" benchmark of 111 information-seeking questions designed to evaluate a web agent's ability to search, browse, and identify factual information from the web. Unlike prior web agent benchmarks, solving BEARCUBS requires (1) accessing live web content rather than synthetic or simulated pages, which captures the unpredictability of real-world web interactions; and (2) performing a broad range of multimodal interactions (e.g., video understanding, 3D navigation) that cannot be bypassed via text-based workarounds. Each question in BEARCUBS has a corresponding short, unambiguous answer and a human-validated browsing trajectory, allowing for transparent evaluation of agent performance and strategies. A human study confirms that BEARCUBS questions are solvable but non-trivial (84.7% human accuracy), revealing search inefficiencies and domain knowledge gaps as common failure points. By contrast, state-of-the-art computer-using agents underperform, with the best-scoring system (OpenAI's Operator) reaching only 24.3% accuracy. These results highlight critical areas for improvement, including reliable source selection and more powerful multimodal capabilities. To facilitate future research, BEARCUBS will be updated periodically to replace invalid or contaminated questions, keeping the benchmark fresh for future generations of web agents.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Integration of Grid Edge Resources into Wholesale Electricity Markets via Mean-field Games</title>
<link>https://arxiv.org/abs/2503.07984</link>
<guid>https://arxiv.org/abs/2503.07984</guid>
<content:encoded><![CDATA[
<div> 关键词：Grid edge resources, Distributed energy resources (DERs), Prosumers, Mean-field game, Wholesale energy market

<br /><br />总结:
本文提出了一种针对电网边缘资源（即由消费者控制的分布式能源资源）的均值场游戏框架。该框架旨在解决由于消费者缺乏参与批发市场专业知识与资源而导致的分布式能源经济潜力未能充分利用的问题。随着DERs采用率的增长，大量生产者消费者的协调和市场参与成为挑战。文章中提出的框架能容纳异质性代理并证明在存在众多生产者消费者的批发能源市场上存在均值场均衡(MFE)。同时，还介绍了一个自动化资源配置算法，用于实时决策能源存储管理。数值实验表明，该方法能够收敛到MFE，并有效地降低峰值负荷和价格波动，特别是在外部需求或供应冲击期间。这项研究突显了采用完全去中心化的方法将DERs整合进批发市场的同时提高市场效率的潜力。 <div>
arXiv:2503.07984v1 Announce Type: new 
Abstract: Grid edge resources refer to distributed energy resources (DERs) located on the consumer side of the electrical grid, controlled by consumers rather than utility companies. Integrating DERs with real-time electricity pricing can better align distributed supply with system demand, improving grid efficiency and reliability. However, DER owners, known as prosumers, often lack the expertise and resources to directly participate in wholesale energy markets, limiting their ability to fully realize the economic potential of their assets. Meanwhile, as DER adoption grows, the number of prosumers participating in the energy system is expected to increase significantly, creating additional challenges in coordination and market participation.
  To address these challenges, we propose a mean-field game framework that enables prosumers to autonomously learn optimal decision policies based on dynamic market prices and their variable solar generation. Our framework is designed to accommodate heterogeneous agents and demonstrates the existence of a mean-field equilibrium (MFE) in a wholesale energy market with many prosumers. Additionally, we introduce an algorithm that automates prosumers' resource control, facilitating real-time decision-making for energy storage management. Numerical experiments suggest that our approach converges towards an MFE and effectively reduces peak loads and price volatility, especially during periods of external demand or supply shocks. This study highlights the potential of a fully decentralized approach to integrating DERs into wholesale markets while improving market efficiency.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Provable Zero-Shot Generalization in Offline Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.07988</link>
<guid>https://arxiv.org/abs/2503.07988</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习、零 shot 泛化、悲观经验风险最小化、悲观亲和力策略优化、近似最优策略

<br /><br />总结:
本文研究了具有零 shot 泛化（ZSG）性质的离线强化学习问题，指出传统离线 RL 方法无法很好地将学习到的策略推广到未见过的新环境中。为解决此问题，文章提出了悲观经验风险最小化（PERM）和悲观亲和力策略优化（PPPO）两种方法，它们利用悲观策略评估来指导政策学习并提升泛化能力。实验表明，PERM 和 PPPO 能够找到一种接近最优的策略，实现对未见测试环境的有效泛化。该成果被认为是理解离线强化学习中泛化现象理论基础的第一步。 <div>
arXiv:2503.07988v1 Announce Type: new 
Abstract: In this work, we study offline reinforcement learning (RL) with zero-shot generalization property (ZSG), where the agent has access to an offline dataset including experiences from different environments, and the goal of the agent is to train a policy over the training environments which performs well on test environments without further interaction. Existing work showed that classical offline RL fails to generalize to new, unseen environments. We propose pessimistic empirical risk minimization (PERM) and pessimistic proximal policy optimization (PPPO), which leverage pessimistic policy evaluation to guide policy learning and enhance generalization. We show that both PERM and PPPO are capable of finding a near-optimal policy with ZSG. Our result serves as a first step in understanding the foundation of the generalization phenomenon in offline reinforcement learning.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SQLCritic: Correcting Text-to-SQL Generation via Clause-wise Critic</title>
<link>https://arxiv.org/abs/2503.07996</link>
<guid>https://arxiv.org/abs/2503.07996</guid>
<content:encoded><![CDATA[
<div> 关键词：Text-to-SQL、准确性、可靠性、执行反馈、批评代理<br /><br />总结:
针对Text-to-SQL系统在将自然语言查询转换为SQL时存在的准确性和可靠性挑战，该文提出了一种创新方法。此方法结合了结构化的执行反馈与训练过的批评代理，能提供详细可解释的批判性指导，从而有效地识别并纠正语法和语义错误。实验结果显示，这种方法在Spider和BIRD两个主要的Text-to-SQL基准测试上均取得了显著的性能提升，证明了其有效性。 <div>
arXiv:2503.07996v1 Announce Type: new 
Abstract: Recent advancements in Text-to-SQL systems have improved the conversion of natural language queries into SQL, but challenges remain in ensuring accuracy and reliability. While self-correction techniques refine outputs, they often introduce new errors. Existing methods focused on execution feedback mainly address syntax issues, leaving semantic errors -- where the query's logic fails to align with the user's intent -- largely unaddressed.
  We propose a novel approach combining structured execution feedback with a trained critic agent that provides detailed, interpretable critiques. This method effectively identifies and corrects both syntactic and semantic errors, enhancing accuracy and interpretability. Experimental results show significant improvements on two major Text-to-SQL benchmarks, Spider and BIRD, demonstrating the effectiveness of our approach.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Three-Dimensional Pursuit-Evasion Game Based on Fuzzy Actor-Critic Learning Algorithm</title>
<link>https://arxiv.org/abs/2503.08013</link>
<guid>https://arxiv.org/abs/2503.08013</guid>
<content:encoded><![CDATA[
<div> 关键词：三维空间、追捕逃逸游戏(PEG)、阿波罗尼奥斯圆(AC)、模糊actor-critic学习(FACL)、奖励函数

总结:
<br />
本文研究了发生在三维空间中的追捕逃逸游戏(PEG)，将二维环境下的阿波罗尼奥斯圆扩展到三维空间并给出了其详细解析形式。为了提高捕获效率，论文推导出了求解追捕者和逃逸者的最优运动空间。针对离散状态空间问题，设计了一种模糊actor-critic学习(FACL)算法以获取智能体的策略。同时，为提升学习性能，文章提出了一种能够实现障碍物规避功能的奖励函数。通过仿真实验验证了所提算法的有效性。 <div>
arXiv:2503.08013v1 Announce Type: new 
Abstract: Most of the existing research on pursuit-evasion game (PEG) is conducted in a two-dimensional (2D) environment. In this paper, we investigate the PEG in a 3D space. We extend the Apollonius circle (AC) to the 3D space and introduce its detailed analytical form. To enhance the capture efficiency, we derive the optimal motion space for both the pursuer and the evader. To address the issue arising from a discrete state space, we design a fuzzy actor-critic learning (FACL) algorithm to obtain the agents' strategies. To improve learning performance, we devise a reward function for the agents, which enables obstacle avoidance functionality. The effectiveness of the proposed algorithm is validated through simulation experiments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>In Prospect and Retrospect: Reflective Memory Management for Long-term Personalized Dialogue Agents</title>
<link>https://arxiv.org/abs/2503.08026</link>
<guid>https://arxiv.org/abs/2503.08026</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，外部记忆机制，对话连续性，反思性内存管理 (RMM)，前瞻性反射，回顾性反射，长期对话代理，强化学习，LongMemEval 数据集。

总结:
本文提出了一种针对大型语言模型在长程对话中存在信息留存和检索不足问题的新方法——反思性内存管理(RMM)。RMM 包括两个关键创新点：(1) 前瞻性反射，该机制动态地将对话交互按不同粒度（如语句、轮次、会话）汇总到个性化记忆库，以便将来有效检索；(2) 回顾性反射，通过在线强化学习的方式，根据 LLM 引用的证据迭代优化检索策略。实验结果显示，RMM 在各种指标和基准测试上表现出显著的改进，例如，在 LongMemEval 数据集上相对于没有内存管理的基线方法，准确率提高了超过 10%。 <div>
arXiv:2503.08026v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have made significant progress in open-ended dialogue, yet their inability to retain and retrieve relevant information from long-term interactions limits their effectiveness in applications requiring sustained personalization. External memory mechanisms have been proposed to address this limitation, enabling LLMs to maintain conversational continuity. However, existing approaches struggle with two key challenges. First, rigid memory granularity fails to capture the natural semantic structure of conversations, leading to fragmented and incomplete representations. Second, fixed retrieval mechanisms cannot adapt to diverse dialogue contexts and user interaction patterns. In this work, we propose Reflective Memory Management (RMM), a novel mechanism for long-term dialogue agents, integrating forward- and backward-looking reflections: (1) Prospective Reflection, which dynamically summarizes interactions across granularities-utterances, turns, and sessions-into a personalized memory bank for effective future retrieval, and (2) Retrospective Reflection, which iteratively refines the retrieval in an online reinforcement learning (RL) manner based on LLMs' cited evidence. Experiments show that RMM demonstrates consistent improvement across various metrics and benchmarks. For example, RMM shows more than 10% accuracy improvement over the baseline without memory management on the LongMemEval dataset.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ForceGrip: Data-Free Curriculum Learning for Realistic Grip Force Control in VR Hand Manipulation</title>
<link>https://arxiv.org/abs/2503.08061</link>
<guid>https://arxiv.org/abs/2503.08061</guid>
<content:encoded><![CDATA[
<div> 关键词：ForceGrip、深度学习、手部操纵、握力意图、物理交互

总结:
本文介绍了ForceGrip，这是一种使用深度学习技术合成逼真手部操纵动作的代理模型，能准确反映用户的握力意图。与依赖于忽略物理属性如接触力和手指扭矩的运动捕捉数据集的传统方法不同，ForceGrip通过生成训练场景（包括随机化物体形状、手腕动作和触发输入流）来应对各种物理交互挑战。为了有效学习这些复杂任务，它采用了一个包含手指定位、意图适应和动态稳定三个阶段的课程学习框架。这一策略确保了手部与物体接触的稳定性、基于用户输入的自适应力度控制以及在动态条件下的稳健处理。此外，通过引入临近奖励函数，进一步优化了手指动作的自然度并加速了训练收敛。定量和定性的评估表明，ForceGrip在力控能力和动作逼真性方面优于现有最优方法。 <div>
arXiv:2503.08061v1 Announce Type: new 
Abstract: Realistic hand manipulation is a key component of immersive virtual reality (VR), yet existing methods often rely on a kinematic approach or motion-capture datasets that omit crucial physical attributes such as contact forces and finger torques. Consequently, these approaches prioritize tight, one-size-fits-all grips rather than reflecting users' intended force levels. We present ForceGrip, a deep learning agent that synthesizes realistic hand manipulation motions, faithfully reflecting the user's grip force intention. Instead of mimicking predefined motion datasets, ForceGrip uses generated training scenarios-randomizing object shapes, wrist movements, and trigger input flows-to challenge the agent with a broad spectrum of physical interactions. To effectively learn from these complex tasks, we employ a three-phase curriculum learning framework comprising Finger Positioning, Intention Adaptation, and Dynamic Stabilization. This progressive strategy ensures stable hand-object contact, adaptive force control based on user inputs, and robust handling under dynamic conditions. Additionally, a proximity reward function enhances natural finger motions and accelerates training convergence. Quantitative and qualitative evaluations reveal ForceGrip's superior force controllability and plausibility compared to state-of-the-art methods.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI-native Memory 2.0: Second Me</title>
<link>https://arxiv.org/abs/2503.08102</link>
<guid>https://arxiv.org/abs/2503.08102</guid>
<content:encoded><![CDATA[
<div> 关键词：SECOND ME、大型语言模型、记忆管理、智能代理、交互摩擦

总结:
SECOND ME是一个利用大型语言模型进行智能、持久性记忆管理和用户特定知识组织的应用。它通过作为用户与外部世界交互的中介，自动生成上下文感知响应，预填充所需信息，减少认知负荷和交互摩擦。区别于传统存储方案，SECOND ME不仅静态保存数据，还借助LLM实现结构化组织、上下文推理和适应性知识检索，从而推动更系统和智能化的记忆管理模式。随着此类AI驱动的个人代理在数字生态系统中的深度融合，SECOND ME标志着向具有持久性、上下文感知及自我优化记忆系统的增强人机互动方向迈出的重要一步。项目已在GitHub上开源：https://github.com/Mindverse/Second-Me。 <div>
arXiv:2503.08102v1 Announce Type: new 
Abstract: Human interaction with the external world fundamentally involves the exchange of personal memory, whether with other individuals, websites, applications, or, in the future, AI agents. A significant portion of this interaction is redundant, requiring users to repeatedly provide the same information across different contexts. Existing solutions, such as browser-stored credentials, autofill mechanisms, and unified authentication systems, have aimed to mitigate this redundancy by serving as intermediaries that store and retrieve commonly used user data. The advent of large language models (LLMs) presents an opportunity to redefine memory management through an AI-native paradigm: SECOND ME. SECOND ME acts as an intelligent, persistent memory offload system that retains, organizes, and dynamically utilizes user-specific knowledge. By serving as an intermediary in user interactions, it can autonomously generate context-aware responses, prefill required information, and facilitate seamless communication with external systems, significantly reducing cognitive load and interaction friction. Unlike traditional memory storage solutions, SECOND ME extends beyond static data retention by leveraging LLM-based memory parameterization. This enables structured organization, contextual reasoning, and adaptive knowledge retrieval, facilitating a more systematic and intelligent approach to memory management. As AI-driven personal agents like SECOND ME become increasingly integrated into digital ecosystems, SECOND ME further represents a critical step toward augmenting human-world interaction with persistent, contextually aware, and self-optimizing memory systems. We have open-sourced the fully localizable deployment system at GitHub: https://github.com/Mindverse/Second-Me.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Stable World Models: Measuring and Addressing World Instability in Generative Environments</title>
<link>https://arxiv.org/abs/2503.08122</link>
<guid>https://arxiv.org/abs/2503.08122</guid>
<content:encoded><![CDATA[
<div> 关键词: 世界稳定性、扩散生成模型、强化学习、游戏引擎、一致性

总结:
我们提出了一项关于增强世界模型中内容保存能力的新研究，重点关注被称为“世界稳定性”的属性。最近的扩散生成模型在合成沉浸式和逼真的环境方面取得了进步，这对于强化学习和交互式游戏引擎等应用至关重要。然而，这些模型虽然在质量和多样性上表现出色，但往往忽视了随时间保持先前生成场景的能力，这可能会对智能体学习引入噪声并影响安全关键设置中的性能。在这项工作中，我们介绍了一个评估框架，通过让世界模型执行一系列操作，随后执行其逆操作以返回初始视角，从而量化起始和结束观察之间的一致性，以此测量世界稳定性。我们对最先进的扩散生成世界模型进行了全面评估，揭示了实现高世界稳定性的显著挑战。此外，我们还探讨了几种提高世界稳定性的策略。我们的结果强调了在世界建模中世界稳定性的重要性，并为该领域的未来研究提供了可操作的见解。 <div>
arXiv:2503.08122v1 Announce Type: new 
Abstract: We present a novel study on enhancing the capability of preserving the content in world models, focusing on a property we term World Stability. Recent diffusion-based generative models have advanced the synthesis of immersive and realistic environments that are pivotal for applications such as reinforcement learning and interactive game engines. However, while these models excel in quality and diversity, they often neglect the preservation of previously generated scenes over time--a shortfall that can introduce noise into agent learning and compromise performance in safety-critical settings. In this work, we introduce an evaluation framework that measures world stability by having world models perform a sequence of actions followed by their inverses to return to their initial viewpoint, thereby quantifying the consistency between the starting and ending observations. Our comprehensive assessment of state-of-the-art diffusion-based world models reveals significant challenges in achieving high world stability. Moreover, we investigate several improvement strategies to enhance world stability. Our results underscore the importance of world stability in world modeling and provide actionable insights for future research in this domain.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLM4MAC: An LLM-Driven Reinforcement Learning Framework for MAC Protocol Emergence</title>
<link>https://arxiv.org/abs/2503.08123</link>
<guid>https://arxiv.org/abs/2503.08123</guid>
<content:encoded><![CDATA[
<div> 关键词：6G系统、敏捷适应性MAC协议、LLM4MAC、大型语言模型、强化学习、部分可观测马尔可夫游戏、POMG、自然语言编码、策略优化（PPO）、结构化身份嵌入（SIE）、异构代理、吞吐量、泛化性能。

总结:<br />
随着6G系统的到来，新兴的超连接生态系统需要灵活和自适应的介质访问控制(MAC)协议来应对网络动态和多样化服务需求。为此，文章提出了一种名为LLM4MAC的新框架，它利用大型语言模型( LLMs)在强化学习范式中驱动MAC协议的演进。LLM4MAC将上行数据传输调度重新构建为一个语义泛化的部分可观测马尔可夫游戏(POMG)，并通过自然语言对网络操作进行编码。同时，采用近似策略优化(PPO)确保协议与不断变化的网络动态保持连续一致。此外，结构化身份嵌入(SIE)机制进一步实现了异构代理间的稳健协调。仿真结果表明，在紧凑型的LLM基础上，LLM4MAC框架产生的协议在吞吐量和泛化性能方面均优于比较基准。 <div>
arXiv:2503.08123v1 Announce Type: new 
Abstract: With the advent of 6G systems, emerging hyper-connected ecosystems necessitate agile and adaptive medium access control (MAC) protocols to contend with network dynamics and diverse service requirements. We propose LLM4MAC, a novel framework that harnesses large language models (LLMs) within a reinforcement learning paradigm to drive MAC protocol emergence. By reformulating uplink data transmission scheduling as a semantics-generalized partially observable Markov game (POMG), LLM4MAC encodes network operations in natural language, while proximal policy optimization (PPO) ensures continuous alignment with the evolving network dynamics. A structured identity embedding (SIE) mechanism further enables robust coordination among heterogeneous agents. Extensive simulations demonstrate that on top of a compact LLM, which is purposefully selected to balance performance with resource efficiency, the protocol emerging from LLM4MAC outperforms comparative baselines in throughput and generalization.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FilmComposer: LLM-Driven Music Production for Silent Film Clips</title>
<link>https://arxiv.org/abs/2503.08147</link>
<guid>https://arxiv.org/abs/2503.08147</guid>
<content:encoded><![CDATA[
<div> 关键词：FilmComposer、LLM驱动、音乐生成、多代理方法、MusicPro-7k

总结:
本文提出了一种使用LLM驱动的电影配乐生成系统——FilmComposer，该系统模拟专业音乐家的工作流程，首次将大型生成模型与多代理方法相结合，同时关注音频质量、音乐性和音乐发展三个核心要素。FilmComposer由视觉处理模块、节奏可控制的MusicGen和多代理评估、编排及混音组成，允许用户在每个步骤中进行干预，提供高度互动和创造性自由度。此外，由于缺乏专业的高质量电影音乐数据集，文章还构建了包含7,418个影片片段、音乐、描述、节奏点和主旋律的MusicPro-7k数据集。实验结果表明，FilmComposer所生成的音乐在质量、视频一致性、多样性、音乐性和音乐发展等方面均达到了最先进的性能水平。项目页面：https://apple-jun.github.io/FilmComposer.github.io/ <div>
arXiv:2503.08147v1 Announce Type: new 
Abstract: In this work, we implement music production for silent film clips using LLM-driven method. Given the strong professional demands of film music production, we propose the FilmComposer, simulating the actual workflows of professional musicians. FilmComposer is the first to combine large generative models with a multi-agent approach, leveraging the advantages of both waveform music and symbolic music generation. Additionally, FilmComposer is the first to focus on the three core elements of music production for film-audio quality, musicality, and musical development-and introduces various controls, such as rhythm, semantics, and visuals, to enhance these key aspects. Specifically, FilmComposer consists of the visual processing module, rhythm-controllable MusicGen, and multi-agent assessment, arrangement and mix. In addition, our framework can seamlessly integrate into the actual music production pipeline and allows user intervention in every step, providing strong interactivity and a high degree of creative freedom. Furthermore, we propose MusicPro-7k which includes 7,418 film clips, music, description, rhythm spots and main melody, considering the lack of a professional and high-quality film music dataset. Finally, both the standard metrics and the new specialized metrics we propose demonstrate that the music generated by our model achieves state-of-the-art performance in terms of quality, consistency with video, diversity, musicality, and musical development. Project page: https://apple-jun.github.io/FilmComposer.github.io/
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Privacy-Enhancing Paradigms within Federated Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.08175</link>
<guid>https://arxiv.org/abs/2503.08175</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated MAS、LLM-based MAS、隐私保护、Embedded Privacy-Enhancing Agents (EPEAgent)、Retrieval-Augmented Generation (RAG)

总结:<br />
本文提出了Federated MAS的概念，这是一种针对多智能体系统在敏感领域中隐私保护问题的新方法。与传统联邦学习对比，Federated MAS面临异构隐私协议、多代理对话结构差异和动态对话网络结构等挑战。为解决这些问题，文章提出了一种创新方案——嵌入式隐私增强代理（EPEAgent），该方案能无缝融入到Retrieval-Augmented Generation阶段和上下文检索阶段，通过最小化数据流动，确保仅分享任务相关且针对特定代理的信息。同时，作者设计并生成了一个全面的数据集来评估该提议的范例。实验表明，EPEAgent能够在保证系统性能的同时有效提升隐私保护水平。相关代码将在https://github.com/ZitongShi/EPEAgent发布。 <div>
arXiv:2503.08175v1 Announce Type: new 
Abstract: LLM-based Multi-Agent Systems (MAS) have proven highly effective in solving complex problems by integrating multiple agents, each performing different roles. However, in sensitive domains, they face emerging privacy protection challenges. In this paper, we introduce the concept of Federated MAS, highlighting the fundamental differences between Federated MAS and traditional FL. We then identify key challenges in developing Federated MAS, including: 1) heterogeneous privacy protocols among agents, 2) structural differences in multi-party conversations, and 3) dynamic conversational network structures. To address these challenges, we propose Embedded Privacy-Enhancing Agents (EPEAgent), an innovative solution that integrates seamlessly into the Retrieval-Augmented Generation (RAG) phase and the context retrieval stage. This solution minimizes data flows, ensuring that only task-relevant, agent-specific information is shared. Additionally, we design and generate a comprehensive dataset to evaluate the proposed paradigm. Extensive experiments demonstrate that EPEAgent effectively enhances privacy protection while maintaining strong system performance. The code will be availiable at https://github.com/ZitongShi/EPEAgent
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guess What I am Thinking: A Benchmark for Inner Thought Reasoning of Role-Playing Language Agents</title>
<link>https://arxiv.org/abs/2503.08193</link>
<guid>https://arxiv.org/abs/2503.08193</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、角色扮演语言代理、chain-of-thought 推理、ROLETHINK、MIRROR

总结:
<br />
近期，基于LLM的大规模语言模型在角色扮演语言代理（RPLA）方面取得显著进展。然而，对于RPLA的内部思考过程的研究尚不充分，而理解人物内心思想对发展高级RPLA至关重要。本文提出了一个新的基准——ROLETHINK，该基准源自文学作品，用于评价角色思想生成。文中定义了“内心思考推理”任务，包括与原著人物独白对比的金集和使用专家合成的人物分析作为参考的银集。为解决这一挑战，研究者们提出了MIRROR方法，这是一种利用记忆检索、预测人物反应以及合成动机的chain-of-thought生成人物思想的方法。通过大量实验，证实了内心思考推理对于RPLA的重要性，并显示MIRROR方法相比现有方法具有更优的表现。相关资源可在https://github.com/airaer1998/RPA_Thought获取。 <div>
arXiv:2503.08193v1 Announce Type: new 
Abstract: Recent advances in LLM-based role-playing language agents (RPLAs) have attracted broad attention in various applications. While chain-of-thought reasoning has shown importance in many tasks for LLMs, the internal thinking processes of RPLAs remain unexplored. Understanding characters' inner thoughts is crucial for developing advanced RPLAs. In this paper, we introduce ROLETHINK, a novel benchmark constructed from literature for evaluating character thought generation. We propose the task of inner thought reasoning, which includes two sets: the gold set that compares generated thoughts with original character monologues, and the silver set that uses expert synthesized character analyses as references. To address this challenge, we propose MIRROR, a chain-of-thought approach that generates character thoughts by retrieving memories, predicting character reactions, and synthesizing motivations. Through extensive experiments, we demonstrate the importance of inner thought reasoning for RPLAs, and MIRROR consistently outperforms existing methods. Resources are available at https://github.com/airaer1998/RPA_Thought.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Cascading Cooperative Multi-agent Framework for On-ramp Merging Control Integrating Large Language Models</title>
<link>https://arxiv.org/abs/2503.08199</link>
<guid>https://arxiv.org/abs/2503.08199</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习(Reinforcement Learning), 大规模语言模型(Large Language Model), 多智能体协作(Cascading Cooperative Multi-agent), 奖励函数(reward function), 动态优化决策(Retrieval-augmented Generation)

总结:<br />
本文提出了一种新的多智能体协作框架——级联合作多智能体（CCMA），旨在解决传统强化学习在模仿人类行为、有效应对复杂驾驶环境中的泛化和协调性问题以及可解释性挑战。该框架融合了强化学习以处理个体交互，利用经过微调的大规模语言模型实现区域间的协同合作，通过奖励函数进行全局优化，并采用检索增强生成机制动态优化复杂驾驶场景下的决策制定。实验表明，相较于现有的强化学习方法，CCMA框架在微观和宏观层面的表现均有显著提升。 <div>
arXiv:2503.08199v1 Announce Type: new 
Abstract: Traditional Reinforcement Learning (RL) suffers from replicating human-like behaviors, generalizing effectively in multi-agent scenarios, and overcoming inherent interpretability issues.These tasks are compounded when deep environment understanding, agent coordination and dynamic optimization are required. While Large Language Model (LLM) enhanced methods have shown promise in generalization and interoperability, they often neglect necessary multi-agent coordination. Therefore, we introduce the Cascading Cooperative Multi-agent (CCMA) framework, integrating RL for individual interactions, a fine-tuned LLM for regional cooperation, a reward function for global optimization, and the Retrieval-augmented Generation mechanism to dynamically optimize decision-making across complex driving scenarios. Our experiments demonstrate that the CCMA outperforms existing RL methods, demonstrating significant improvements in both micro and macro-level performance in complex driving environments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>HASARD: A Benchmark for Vision-Based Safe Reinforcement Learning in Embodied Agents</title>
<link>https://arxiv.org/abs/2503.08241</link>
<guid>https://arxiv.org/abs/2503.08241</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning）、安全自主系统、HASARD、视觉基准、复杂任务

总结:
本文介绍了通过强化学习推进安全自主系统发展所需要的坚实基准——HASARD。HASARD是一个利用Doom构建的、针对安全RL研究的视觉基准，旨在测试和分析方法性能以及评估代理能力。与现有的仅关注简单导航任务的基于视觉的3D基准不同，HASARD引入了一系列需要策略决策、空间关系理解和短期未来预测的多样化、复杂的任务。该基准设有三个难度等级和两种行动空间，并对流行基线方法进行了实证评估，显示了其复杂性、独特挑战及奖励-成本权衡。通过顶视图热力图可观察到训练过程中代理的学习过程，而逐步提升训练难度则提供了一种隐式的学习课程。HASARD是首个专门针对第一人称视角视觉学习的安全RL基准，为探究当前及未来安全RL方法的潜力和边界提供了经济高效且富有洞察力的方式。相关环境和基线实现已开源，可在https://sites.google.com/view/hasard-bench/ 获取。<br /><br /> <div>
arXiv:2503.08241v1 Announce Type: new 
Abstract: Advancing safe autonomous systems through reinforcement learning (RL) requires robust benchmarks to evaluate performance, analyze methods, and assess agent competencies. Humans primarily rely on embodied visual perception to safely navigate and interact with their surroundings, making it a valuable capability for RL agents. However, existing vision-based 3D benchmarks only consider simple navigation tasks. To address this shortcoming, we introduce \textbf{HASARD}, a suite of diverse and complex tasks to $\textbf{HA}$rness $\textbf{SA}$fe $\textbf{R}$L with $\textbf{D}$oom, requiring strategic decision-making, comprehending spatial relationships, and predicting the short-term future. HASARD features three difficulty levels and two action spaces. An empirical evaluation of popular baseline methods demonstrates the benchmark's complexity, unique challenges, and reward-cost trade-offs. Visualizing agent navigation during training with top-down heatmaps provides insight into a method's learning process. Incrementally training across difficulty levels offers an implicit learning curriculum. HASARD is the first safe RL benchmark to exclusively target egocentric vision-based learning, offering a cost-effective and insightful way to explore the potential and boundaries of current and future safe RL methods. The environments and baseline implementations are open-sourced at https://sites.google.com/view/hasard-bench/.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Outlining: Heterogeneous Recursive Planning for Adaptive Long-form Writing with Language Models</title>
<link>https://arxiv.org/abs/2503.08275</link>
<guid>https://arxiv.org/abs/2503.08275</guid>
<content:encoded><![CDATA[
<div> 关键词: 长篇写作代理、任务分解、动态集成、信息检索、推理、生成、灵活交互、预设工作流、人工限制、适应性写作、递归任务分解、执行机制、异质任务分解、自动评价指标、fiction writing、technical report generation。

<br /><br />总结:
本文提出了一种新型长篇写作代理框架，旨在实现类似人类的适应性写作。该框架通过递归任务分解和动态集成三种基本任务类型（信息检索、推理和生成）来突破现有预设工作流和僵化思维模式的约束。其特点包括：1）规划机制允许任务分解与执行的交错进行，消除了写作流程中的人工限制；2）实现了不同类型任务的融合，促进了异质任务的分解。实验结果表明，该方法在小说创作和技术报告生成两个领域的自动化评价指标上均优于当前最先进的方法，验证了所提框架的有效性和广泛适用性。 <div>
arXiv:2503.08275v1 Announce Type: new 
Abstract: Long-form writing agents require flexible integration and interaction across information retrieval, reasoning, and composition. Current approaches rely on predetermined workflows and rigid thinking patterns to generate outlines before writing, resulting in constrained adaptability during writing. In this paper we propose a general agent framework that achieves human-like adaptive writing through recursive task decomposition and dynamic integration of three fundamental task types, i.e. retrieval, reasoning, and composition. Our methodology features: 1) a planning mechanism that interleaves recursive task decomposition and execution, eliminating artificial restrictions on writing workflow; and 2) integration of task types that facilitates heterogeneous task decomposition. Evaluations on both fiction writing and technical report generation show that our method consistently outperforms state-of-the-art approaches across all automatic evaluation metrics, which demonstrate the effectiveness and broad applicability of our proposed framework.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>General-Purpose Aerial Intelligent Agents Empowered by Large Language Models</title>
<link>https://arxiv.org/abs/2503.08302</link>
<guid>https://arxiv.org/abs/2503.08302</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、无人机 (UAVs)、硬件-软件协同设计、边緣优化计算平台、认知架构

总结:
该文介绍了首个将大型语言模型（LLMs）与机器人自主性紧密结合，实现开放世界任务执行的空中智能代理系统。此硬件-软件协同设计的系统解决了两个基础限制：(1) 通过边缘优化计算平台实现在无人机上的现场LLM操作，对于具有14亿参数的模型，能达到每秒5-6个令牌的推理速度，峰值功率为220W；(2) 设计了双向认知架构，结合了LLM的任务规划（慢速深思熟虑规划）与快速反应控制（状态估计、制图、障碍规避和运动规划）。通过原型系统的初步验证，系统在通信受限环境中如甘蔗监测、电力网格检查、矿井隧道探索和生物观察等应用中展示了可靠的任务规划和场景理解能力。这项工作建立了一个新型的具身飞行人工智能框架，填补了开放环境中的任务规划与机器人自主性之间的鸿沟。 <div>
arXiv:2503.08302v1 Announce Type: new 
Abstract: The emergence of large language models (LLMs) opens new frontiers for unmanned aerial vehicle (UAVs), yet existing systems remain confined to predefined tasks due to hardware-software co-design challenges. This paper presents the first aerial intelligent agent capable of open-world task execution through tight integration of LLM-based reasoning and robotic autonomy. Our hardware-software co-designed system addresses two fundamental limitations: (1) Onboard LLM operation via an edge-optimized computing platform, achieving 5-6 tokens/sec inference for 14B-parameter models at 220W peak power; (2) A bidirectional cognitive architecture that synergizes slow deliberative planning (LLM task planning) with fast reactive control (state estimation, mapping, obstacle avoidance, and motion planning). Validated through preliminary results using our prototype, the system demonstrates reliable task planning and scene understanding in communication-constrained environments, such as sugarcane monitoring, power grid inspection, mine tunnel exploration, and biological observation applications. This work establishes a novel framework for embodied aerial artificial intelligence, bridging the gap between task planning and robotic autonomy in open environments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reasoning in visual navigation of end-to-end trained agents: a dynamical systems approach</title>
<link>https://arxiv.org/abs/2503.08306</link>
<guid>https://arxiv.org/abs/2503.08306</guid>
<content:encoded><![CDATA[
<div> 关键词：Embodied AI、真实环境、端到端训练、动态预测、记忆利用

总结:
本文关注了端到端训练的智能体在现实环境中精细行为的研究，特别是在快速移动的真实机器人上的大规模实验。研究分析了从端到端训练中涌现出的关于开放环动态预测的合理行为以及其与感知的相互作用。文中探讨了智能体如何利用潜在记忆存储场景结构和探索过程中收集的信息，并发现它能在有限的时间范围内制定较为精确的计划。此外，通过后期分析显示，智能体学习的价值函数与其长期规划能力有关。这些实验揭示了使用计算机视觉和序列决策方法为机器人控制领域带来的新能力。读者可以在europe.naverlabs.com/research/publications/reasoning-in-visual-navigation-of-end-to-end-trained-agents网站上查看交互式工具。<br /><br /> <div>
arXiv:2503.08306v1 Announce Type: new 
Abstract: Progress in Embodied AI has made it possible for end-to-end-trained agents to navigate in photo-realistic environments with high-level reasoning and zero-shot or language-conditioned behavior, but benchmarks are still dominated by simulation. In this work, we focus on the fine-grained behavior of fast-moving real robots and present a large-scale experimental study involving \numepisodes{} navigation episodes in a real environment with a physical robot, where we analyze the type of reasoning emerging from end-to-end training. In particular, we study the presence of realistic dynamics which the agent learned for open-loop forecasting, and their interplay with sensing. We analyze the way the agent uses latent memory to hold elements of the scene structure and information gathered during exploration. We probe the planning capabilities of the agent, and find in its memory evidence for somewhat precise plans over a limited horizon. Furthermore, we show in a post-hoc analysis that the value function learned by the agent relates to long-term planning. Put together, our experiments paint a new picture on how using tools from computer vision and sequential decision making have led to new capabilities in robotics and control. An interactive tool is available at europe.naverlabs.com/research/publications/reasoning-in-visual-navigation-of-end-to-end-trained-agents.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Seeing and Reasoning with Confidence: Supercharging Multimodal LLMs with an Uncertainty-Aware Agentic Framework</title>
<link>https://arxiv.org/abs/2503.08308</link>
<guid>https://arxiv.org/abs/2503.08308</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态大型语言模型 (MLLMs)，视觉问题回答 (VQA)，chain-of-thought (CoT) 推理，外部工具，不确定性量化 (UQ)

总结:
本文提出了一种名为“Seeing and Reasoning with Confidence (SRICE)”的无训练多模态推理框架，旨在解决多模态推理中的挑战。该框架通过将外部视觉模型与不确定性量化（UQ）集成到MLLM中，以应对现有方法的局限性，如CoT基多模态推理的数据注解和微调成本高昂，以及依赖外部工具可能引入不可靠输出的问题。SRICE利用多阶段交互使MLLM能够自主选择感兴趣区域，并借助符合预测方法对工具输出进行校准，根据MLLM输出的不确定性估计来优化工具的选择。实验结果显示，相比于基础MLLM，SRICE在五个数据集上的平均性能提升了4.6%，甚至在某些数据集上优于基于微调的方法，从而证实了确保MLLM代理可靠使用外部工具的重要性。 <div>
arXiv:2503.08308v1 Announce Type: new 
Abstract: Multimodal large language models (MLLMs) show promise in tasks like visual question answering (VQA) but still face challenges in multimodal reasoning. Recent works adapt agentic frameworks or chain-of-thought (CoT) reasoning to improve performance. However, CoT-based multimodal reasoning often demands costly data annotation and fine-tuning, while agentic approaches relying on external tools risk introducing unreliable output from these tools. In this paper, we propose Seeing and Reasoning with Confidence (SRICE), a training-free multimodal reasoning framework that integrates external vision models with uncertainty quantification (UQ) into an MLLM to address these challenges. Specifically, SRICE guides the inference process by allowing MLLM to autonomously select regions of interest through multi-stage interactions with the help of external tools. We propose to use a conformal prediction-based approach to calibrate the output of external tools and select the optimal tool by estimating the uncertainty of an MLLM's output. Our experiment shows that the average improvement of SRICE over the base MLLM is 4.6% on five datasets and the performance on some datasets even outperforms fine-tuning-based methods, revealing the significance of ensuring reliable tool use in an MLLM agent.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Talk2PC: Enhancing 3D Visual Grounding through LiDAR and Radar Point Clouds Fusion for Autonomous Driving</title>
<link>https://arxiv.org/abs/2503.08336</link>
<guid>https://arxiv.org/abs/2503.08336</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied outdoor scene understanding, 3D visual grounding, LiDAR, radar, TPCNet

总结:
<br />
本文提出了一种名为TPCNet的新方法，这是首个基于prompt引导的点云传感器融合（包括LiDAR和雷达）的室外3D视觉定位模型。为了适应性地平衡由prompt需求的两种传感器特征，设计了两阶段异质模态自适应融合策略，其中包含了双向代理交叉注意力（BACA）模块，该模块利用具有全局感受野的双传感器特征对文本特征进行查询。此外，还设计了一个动态门控图融合（DGGF）模块来定位由查询标识的兴趣区域。为提高准确性，创新性地提出了基于最近对象边缘的C3D-RECHead。实验表明，TPCNet及其各个模块在Talk2Radar和Talk2Car数据集上均实现了最先进的性能。 <div>
arXiv:2503.08336v1 Announce Type: new 
Abstract: Embodied outdoor scene understanding forms the foundation for autonomous agents to perceive, analyze, and react to dynamic driving environments. However, existing 3D understanding is predominantly based on 2D Vision-Language Models (VLMs), collecting and processing limited scene-aware contexts. Instead, compared to the 2D planar visual information, point cloud sensors like LiDAR offer rich depth information and fine-grained 3D representations of objects. Meanwhile, the emerging 4D millimeter-wave (mmWave) radar is capable of detecting the motion trend, velocity, and reflection intensity of each object. Therefore, the integration of these two modalities provides more flexible querying conditions for natural language, enabling more accurate 3D visual grounding. To this end, in this paper, we exploratively propose a novel method called TPCNet, the first outdoor 3D visual grounding model upon the paradigm of prompt-guided point cloud sensor combination, including both LiDAR and radar contexts. To adaptively balance the features of these two sensors required by the prompt, we have designed a multi-fusion paradigm called Two-Stage Heterogeneous Modal Adaptive Fusion. Specifically, this paradigm initially employs Bidirectional Agent Cross-Attention (BACA), which feeds dual-sensor features, characterized by global receptive fields, to the text features for querying. Additionally, we have designed a Dynamic Gated Graph Fusion (DGGF) module to locate the regions of interest identified by the queries. To further enhance accuracy, we innovatively devise an C3D-RECHead, based on the nearest object edge. Our experiments have demonstrated that our TPCNet, along with its individual modules, achieves the state-of-the-art performance on both the Talk2Radar and Talk2Car datasets.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Trinity: A Modular Humanoid Robot AI System</title>
<link>https://arxiv.org/abs/2503.08338</link>
<guid>https://arxiv.org/abs/2503.08338</guid>
<content:encoded><![CDATA[
<div> 关键词：humanoid robots, reinforcement learning, large language models, visual language models, Trinity

<br /><br />总结:
近年来，人形机器人研究受到越来越多关注。随着人工智能算法的突破，尤其是强化学习（RL）在人形机器人的运动控制和泛化能力方面的显著提升，以及大型语言模型（LLM）和视觉语言模型（VLM）带来的新可能，人形机器人被寄予了更高期待。本文介绍了一个名为“Trinity”的新型AI系统，该系统将RL、LLM和VLM集成为一体，使人形机器人能够在复杂环境中实现有效控制。这一创新方法不仅增强了人形机器人的功能，也为未来的研究与应用开辟了新的途径。 <div>
arXiv:2503.08338v1 Announce Type: new 
Abstract: In recent years, research on humanoid robots has garnered increasing attention. With breakthroughs in various types of artificial intelligence algorithms, embodied intelligence, exemplified by humanoid robots, has been highly anticipated. The advancements in reinforcement learning (RL) algorithms have significantly improved the motion control and generalization capabilities of humanoid robots. Simultaneously, the groundbreaking progress in large language models (LLM) and visual language models (VLM) has brought more possibilities and imagination to humanoid robots. LLM enables humanoid robots to understand complex tasks from language instructions and perform long-term task planning, while VLM greatly enhances the robots' understanding and interaction with their environment. This paper introduces \textcolor{magenta}{Trinity}, a novel AI system for humanoid robots that integrates RL, LLM, and VLM. By combining these technologies, Trinity enables efficient control of humanoid robots in complex environments. This innovative approach not only enhances the capabilities but also opens new avenues for future research and applications of humanoid robotics.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>InfluenceNet: AI Models for Banzhaf and Shapley Value Prediction</title>
<link>https://arxiv.org/abs/2503.08381</link>
<guid>https://arxiv.org/abs/2503.08381</guid>
<content:encoded><![CDATA[
<div> 关键词: 功力指数、神经网络、多agent系统、计算瓶颈、决策分析

总结:
<br />
本文提出了一个基于神经网络的新方法，用于高效估计投票游戏中的功力指数，旨在解决对于大规模(n≥10)联盟的传统精确或估算功力指数计算所面临的显著时间和计算约束问题。与现有工具相比，该方法在速度和准确性方面展现出相当甚至更优的表现。这一创新手段不仅克服了先前的计算限制，还使得对大型联盟的快速分析成为可能，为多agent系统研究开辟了新的途径，提供了更加便捷、可扩展的分析工具，从而有利于分析更为复杂和真实的多agent场景。 <div>
arXiv:2503.08381v1 Announce Type: new 
Abstract: Power indices are essential in assessing the contribution and influence of individual agents in multi-agent systems, providing crucial insights into collaborative dynamics and decision-making processes. While invaluable, traditional computational methods for exact or estimated power indices values require significant time and computational constraints, especially for large $(n\ge10)$ coalitions. These constraints have historically limited researchers' ability to analyse complex multi-agent interactions comprehensively. To address this limitation, we introduce a novel Neural Networks-based approach that efficiently estimates power indices for voting games, demonstrating comparable and often superiour performance to existing tools in terms of both speed and accuracy. This method not only addresses existing computational bottlenecks, but also enables rapid analysis of large coalitions, opening new avenues for multi-agent system research by overcoming previous computational limitations and providing researchers with a more accessible, scalable analytical tool.This increased efficiency will allow for the analysis of more complex and realistic multi-agent scenarios.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Detect Objects from Multi-Agent LiDAR Scans without Manual Labels</title>
<link>https://arxiv.org/abs/2503.08421</link>
<guid>https://arxiv.org/abs/2503.08421</guid>
<content:encoded><![CDATA[
<div> 关键词：Unsupervised 3D object detection、Multi-agent collaborative dataset、LiDAR、DOtA、Pseudo-labels

总结:
本文提出了一种新的无监督方法DOtA，用于从多智能体LiDAR扫描中检测物体，无需使用外部标签。该方法利用多智能体协同数据集中的互补观察信息，通过内部共享的自主姿态和形状初始化检测器，运用神经网络的泛化性能推断初步标签。随后，DOtA对初步标签进行多尺度编码解码，区分高质量和低质量标签，并将这些标签作为引导，促进特征学习过程的正确性，从而提升无监督三维对象检测任务的性能。实验结果表明，DOtA在V2V4Real和OPV2V数据集上超越了现有的无监督3D目标检测方法。此外，还验证了DOtA标签在不同协同感知框架下的有效性。相关代码已开源，可在https://github.com/xmuqimingxia/DOtA获取。 <div>
arXiv:2503.08421v1 Announce Type: new 
Abstract: Unsupervised 3D object detection serves as an important solution for offline 3D object annotation. However, due to the data sparsity and limited views, the clustering-based label fitting in unsupervised object detection often generates low-quality pseudo-labels. Multi-agent collaborative dataset, which involves the sharing of complementary observations among agents, holds the potential to break through this bottleneck. In this paper, we introduce a novel unsupervised method that learns to Detect Objects from Multi-Agent LiDAR scans, termed DOtA, without using labels from external. DOtA first uses the internally shared ego-pose and ego-shape of collaborative agents to initialize the detector, leveraging the generalization performance of neural networks to infer preliminary labels. Subsequently,DOtA uses the complementary observations between agents to perform multi-scale encoding on preliminary labels, then decodes high-quality and low-quality labels. These labels are further used as prompts to guide a correct feature learning process, thereby enhancing the performance of the unsupervised object detection task. Extensive experiments on the V2V4Real and OPV2V datasets show that our DOtA outperforms state-of-the-art unsupervised 3D object detection methods. Additionally, we also validate the effectiveness of the DOtA labels under various collaborative perception frameworks.The code is available at https://github.com/xmuqimingxia/DOtA.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An autonomous rl agent methodology for dynamic Web ui testing in a bdd framework</title>
<link>https://arxiv.org/abs/2503.08464</link>
<guid>https://arxiv.org/abs/2503.08464</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主强化学习(RL), 行为驱动开发(BDD), 用户界面测试, 自动探索, 测试效率

总结:
本文提出了一种将自主强化学习(RL)与行为驱动开发(BDD)框架结合的方法，以增强用户界面测试的效率和可靠性。该方法利用RL的自适应决策能力动态生成并优化符合业务期望和实际用户行为的测试场景。文中详细介绍了系统架构，包括状态表示、动作空间及奖励机制，这些机制引导RL代理对UI状态进行自动探索。实验结果显示，在开源web应用上的测试表明，这种方法显著提高了缺陷检测能力，增加了测试覆盖率，并减少了手动测试工作量。研究为进一步将先进的RL技术融入BDD实践奠定了基础，旨在变革软件质量保证流程，并优化持续测试过程。<br /><br /> <div>
arXiv:2503.08464v1 Announce Type: new 
Abstract: Modern software applications demand efficient and reliable testing methodologies to ensure robust
  user interface functionality. This paper introduces an autonomous reinforcement learning (RL) agent
  integrated within a Behavior-Driven Development (BDD) framework to enhance UI testing. By
  leveraging the adaptive decision-making capabilities of RL, the proposed approach dynamically
  generates and refines test scenarios aligned with specific business expectations and actual user
  behavior. A novel system architecture is presented, detailing the state representation, action space,
  and reward mechanisms that guide the autonomous exploration of UI states. Experimental evaluations
  on open-source web applications demonstrate significant improvements in defect detection, test
  coverage, and a reduction in manual testing efforts. This study establishes a foundation for integrating
  advanced RL techniques with BDD practices, aiming to transform software quality assurance and
  streamline continuous testing processes.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Dynamic 3D Scene Graphs for Open-Vocabulary Urban Scene Understanding</title>
<link>https://arxiv.org/abs/2503.08474</link>
<guid>https://arxiv.org/abs/2503.08474</guid>
<content:encoded><![CDATA[
<div> 关键词：mobile robots, mapping, scene representation, multi-agent collaboration, CURB-OSG

总结:
本文介绍了一种名为CURB-OSG的动态3D场景图引擎，用于构建开放词汇表的城市驾驶场景层次分解并通过多智能体协作生成更准确的地图。该方法融合了多个具有未知初始姿态的感知代理的相机和LiDAR观测数据，与单个代理相比能生成更精确的地图，并构建统一的语义丰富的场景层次结构。与依赖地面真实智能体位置或仅在模拟环境中进行评估的先前方法不同，CURB-OSG减轻了这些约束。文章使用来自牛津雷达RobotCar数据集的多个实现实验 session 的多智能体传感器数据对CURB-OSG进行了评估，证明了通过多智能体协作可以提高制图和对象预测准确性，并评估了其提出的环境分区能力。为了推动进一步的研究，作者发布了相关代码和补充材料。 <div>
arXiv:2503.08474v1 Announce Type: new 
Abstract: Mapping and scene representation are fundamental to reliable planning and navigation in mobile robots. While purely geometric maps using voxel grids allow for general navigation, obtaining up-to-date spatial and semantically rich representations that scale to dynamic large-scale environments remains challenging. In this work, we present CURB-OSG, an open-vocabulary dynamic 3D scene graph engine that generates hierarchical decompositions of urban driving scenes via multi-agent collaboration. By fusing the camera and LiDAR observations from multiple perceiving agents with unknown initial poses, our approach generates more accurate maps compared to a single agent while constructing a unified open-vocabulary semantic hierarchy of the scene. Unlike previous methods that rely on ground truth agent poses or are evaluated purely in simulation, CURB-OSG alleviates these constraints. We evaluate the capabilities of CURB-OSG on real-world multi-agent sensor data obtained from multiple sessions of the Oxford Radar RobotCar dataset. We demonstrate improved mapping and object prediction accuracy through multi-agent collaboration as well as evaluate the environment partitioning capabilities of the proposed approach. To foster further research, we release our code and supplementary material at https://ov-curb.cs.uni-freiburg.de.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hybrid Deep Reinforcement Learning for Radio Tracer Localisation in Robotic-assisted Radioguided Surgery</title>
<link>https://arxiv.org/abs/2503.08492</link>
<guid>https://arxiv.org/abs/2503.08492</guid>
<content:encoded><![CDATA[
<div> 关键词: radioguided surgery, deep reinforcement learning (DRL), adaptive robotic scanning, simulation experiments, da Vinci Research Kit (dVRK)

<br /><br />总结:
本文提出了一种融合深度强化学习（DRL）与自适应机器人扫描的新型混合方法，用于实现机器人辅助手术中的自主放射性示踪剂检测。该方法通过自适应网格扫描提供初步的方向估计，而DRL代理则利用历史数据有效地导航至目标。模拟实验显示成功率为95%，相较于传统技术具有更高的效率和鲁棒性。在da Vinci Research Kit (dVRK)上的真实世界评估进一步证实了该方法的可行性，实现了80%的成功率。这种方法有望提高放射导向手术的一致性、降低对手术者的依赖并提升手术精度。 <div>
arXiv:2503.08492v1 Announce Type: new 
Abstract: Radioguided surgery, such as sentinel lymph node biopsy, relies on the precise localization of radioactive targets by non-imaging gamma/beta detectors. Manual radioactive target detection based on visual display or audible indication of gamma level is highly dependent on the ability of the surgeon to track and interpret the spatial information. This paper presents a learning-based method to realize the autonomous radiotracer detection in robot-assisted surgeries by navigating the probe to the radioactive target. We proposed novel hybrid approach that combines deep reinforcement learning (DRL) with adaptive robotic scanning. The adaptive grid-based scanning could provide initial direction estimation while the DRL-based agent could efficiently navigate to the target utilising historical data. Simulation experiments demonstrate a 95% success rate, and improved efficiency and robustness compared to conventional techniques. Real-world evaluation on the da Vinci Research Kit (dVRK) further confirms the feasibility of the approach, achieving an 80% success rate in radiotracer detection. This method has the potential to enhance consistency, reduce operator dependency, and improve procedural accuracy in radioguided surgeries.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hierarchical Multi Agent DRL for Soft Handovers Between Edge Clouds in Open RAN</title>
<link>https://arxiv.org/abs/2503.08493</link>
<guid>https://arxiv.org/abs/2503.08493</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-connectivity, Open RAN, Edge Clouds, Seamless Service Continuity, Hierarchical Multi-Agent Reinforcement Learning

总结:<br />
本文探讨了利用多连接性（Multi-connectivity）通过地面接入点为航空用户提供高可靠通信的可能性，在开放无线接入网络（Open RAN）架构下，边缘云（Edge Clouds）能够为覆盖范围内的用户提供低延迟的多连接服务。然而，确保在过渡用户（移动于相邻边缘云覆盖区域之间的用户）之间实现无缝服务连续性面临挑战，因为这需要集中处理。为此，文章提出一个问题框架以实现边缘云间的软切换，并确保所有用户的无缝过渡和服务连续性。为解决此问题，文章提出了一个分层多代理强化学习（Hierarchical Multi-Agent Reinforcement Learning，HMARL）算法，动态确定过渡和非过渡用户的最优功能拆分配置。仿真结果表明，所提方法在维持服务连续性的用户比例上优于传统的功能拆分方案，最大优化差距不超过4%。此外，HMARL相比静态基线展现出更好的可扩展性。 <div>
arXiv:2503.08493v1 Announce Type: new 
Abstract: Multi-connectivity (MC) for aerial users via a set of ground access points offers the potential for highly reliable communication. Within an open radio access network (O-RAN) architecture, edge clouds (ECs) enable MC with low latency for users within their coverage area. However, ensuring seamless service continuity for transitional users-those moving between the coverage areas of neighboring ECs-poses challenges due to centralized processing demands. To address this, we formulate a problem facilitating soft handovers between ECs, ensuring seamless transitions while maintaining service continuity for all users. We propose a hierarchical multi-agent reinforcement learning (HMARL) algorithm to dynamically determine the optimal functional split configuration for transitional and non-transitional users. Simulation results show that the proposed approach outperforms the conventional functional split in terms of the percentage of users maintaining service continuity, with at most 4% optimality gap. Additionally, HMARL achieves better scalability compared to the static baselines.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReviewAgents: Bridging the Gap Between Human and AI-Generated Paper Reviews</title>
<link>https://arxiv.org/abs/2503.08506</link>
<guid>https://arxiv.org/abs/2503.08506</guid>
<content:encoded><![CDATA[
<div> 关键词: ReviewAgents、大型语言模型、学术论文审查、Review-CoT、ReviewBench

总结:<br />
本文提出了一种名为ReviewAgents的框架，该框架利用大型语言模型（LLMs）自动生成学术论文评论以应对日益增长的论文审查需求。为了训练这些模型，文章首先介绍了新的数据集Review-CoT，其中包含142k篇评审评论，用于模拟人类评审员的结构化推理过程。接着，通过相关论文感知训练方法训练LLM评审代理，构建了一个多角色、多LLM代理的评审框架。同时，作者还提出了一个评价LLM生成的评审评论质量的基准——ReviewBench。实验结果显示，虽然现有的LLMs在自动化评审过程中展现出一定潜力，但仍与人工评审存在差距；而提出的ReviewAgents框架进一步缩小了这一差距，在生成评审评论方面优于先进的LLMs。 <div>
arXiv:2503.08506v1 Announce Type: new 
Abstract: Academic paper review is a critical yet time-consuming task within the research community. With the increasing volume of academic publications, automating the review process has become a significant challenge. The primary issue lies in generating comprehensive, accurate, and reasoning-consistent review comments that align with human reviewers' judgments. In this paper, we address this challenge by proposing ReviewAgents, a framework that leverages large language models (LLMs) to generate academic paper reviews. We first introduce a novel dataset, Review-CoT, consisting of 142k review comments, designed for training LLM agents. This dataset emulates the structured reasoning process of human reviewers-summarizing the paper, referencing relevant works, identifying strengths and weaknesses, and generating a review conclusion. Building upon this, we train LLM reviewer agents capable of structured reasoning using a relevant-paper-aware training method. Furthermore, we construct ReviewAgents, a multi-role, multi-LLM agent review framework, to enhance the review comment generation process. Additionally, we propose ReviewBench, a benchmark for evaluating the review comments generated by LLMs. Our experimental results on ReviewBench demonstrate that while existing LLMs exhibit a certain degree of potential for automating the review process, there remains a gap when compared to human-generated reviews. Moreover, our ReviewAgents framework further narrows this gap, outperforming advanced LLMs in generating review comments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GTR: Guided Thought Reinforcement Prevents Thought Collapse in RL-based VLM Agent Training</title>
<link>https://arxiv.org/abs/2503.08525</link>
<guid>https://arxiv.org/abs/2503.08525</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、可验证结果奖励、视觉语言模型、引导性思考强化、链式思维

总结:
本文探讨了强化学习与可验证结果奖励（RLVR）方法在训练大规模视觉语言模型（VLM）代理进行目标导向的视觉环境中的行动推理效果。研究发现，仅基于行动结果的奖励机制无法有效激励VLM的链式思维推理，可能导致“思考塌缩”现象，即代理人思考多样性丧失、推理与状态不相关及不完整，进而采取无效行动并获得负向奖励。为解决这个问题，文章强调了过程指导的重要性，并提出了一个自动化校正器，该校正器能够在每个强化学习步骤中评估和改进代理人的推理。这个简单且可扩展的GTR（引导性思考强化）框架可以在无需密集的人工逐步标注的情况下同时训练推理和行动。实验表明，GTR显著提升了LLaVA-7b模型在多种视觉环境下的性能和泛化能力，其任务成功率相比当前最优模型提高了3-5倍，而且使用了明显更小的模型规模。<br /><br /> <div>
arXiv:2503.08525v1 Announce Type: new 
Abstract: Reinforcement learning with verifiable outcome rewards (RLVR) has effectively scaled up chain-of-thought (CoT) reasoning in large language models (LLMs). Yet, its efficacy in training vision-language model (VLM) agents for goal-directed action reasoning in visual environments is less established. This work investigates this problem through extensive experiments on complex card games, such as 24 points, and embodied tasks from ALFWorld. We find that when rewards are based solely on action outcomes, RL fails to incentivize CoT reasoning in VLMs, instead leading to a phenomenon we termed thought collapse, characterized by a rapid loss of diversity in the agent's thoughts, state-irrelevant and incomplete reasoning, and subsequent invalid actions, resulting in negative rewards. To counteract thought collapse, we highlight the necessity of process guidance and propose an automated corrector that evaluates and refines the agent's reasoning at each RL step. This simple and scalable GTR (Guided Thought Reinforcement) framework trains reasoning and action simultaneously without the need for dense, per-step human labeling. Our experiments demonstrate that GTR significantly enhances the performance and generalization of the LLaVA-7b model across various visual environments, achieving 3-5 times higher task success rates compared to SoTA models with notably smaller model sizes.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EMMOE: A Comprehensive Benchmark for Embodied Mobile Manipulation in Open Environments</title>
<link>https://arxiv.org/abs/2503.08604</link>
<guid>https://arxiv.org/abs/2503.08604</guid>
<content:encoded><![CDATA[
<div> 关键词：自主家庭机器人、自然语言控制、大型语言模型、Embodied Mobile Manipulation in Open Environments (EMMOE)、HomieBot

总结:<br />
本文提出了一种为解决复杂家庭机器人任务挑战的新框架——Embodied Mobile Manipulation in Open Environments (EMMOE)，该框架将高阶和低阶的实体任务统一并加入了三个新的评估指标。同时，文章还介绍了EMMOE-100数据集，该数据集具有多种任务属性、详细过程注释、失败后的重新规划以及两个用于训练大型语言模型的子数据集。为了实现这一目标，研究者设计了HomieBot，这是一个由大型语言模型与Direct Preference Optimization (DPO)相结合，配以轻量级导航和操作模型及多错误检测机制的智能机器人系统。最后，展示了HomieBot的性能及其与其他模型和策略的评估结果。 <div>
arXiv:2503.08604v1 Announce Type: new 
Abstract: Developing autonomous home robots controlled by natural language has long been a pursuit of human. While advancements in large language models (LLMs) and embodied intelligence make this goal closer, several challenges persist: the lack of a unified benchmark for more complex robot tasks, limited evaluation methods and metrics, data incompatibility between LLMs and mobile manipulation trajectories. To address these issues, we introduce Embodied Mobile Manipulation in Open Environments (EMMOE), which requires agents to interpret user instructions and execute long-horizon everyday tasks in continuous space. EMMOE seamlessly integrates high-level and low-level embodied tasks into a unified framework, along with three new metrics for more diverse assessment. Additionally, we collect EMMOE-100, which features in various task attributes, detailed process annotations, re-plans after failures, and two sub-datasets for LLM training. Furthermore, we design HomieBot, a sophisticated agent system consists of LLM with Direct Preference Optimization (DPO), light weighted navigation and manipulation models, and multiple error detection mechanisms. Finally, we demonstrate HomieBot's performance and the evaluation of different models and policies.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AgentOrca: A Dual-System Framework to Evaluate Language Agents on Operational Routine and Constraint Adherence</title>
<link>https://arxiv.org/abs/2503.08669</link>
<guid>https://arxiv.org/abs/2503.08669</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言代理、操作约束、安全协议、AgentOrca、评估框架

总结:
随着语言代理在各领域关键任务中的应用日益增多，其遵循操作约束和安全协议的能力变得至关重要。尽管已有大量研究证明了这些代理在下游任务完成上的有效性，但它们在遵守操作规程方面的可靠性尚未得到充分探索。为此，文章提出了AgentOrca，这是一个用于评估语言代理遵循操作约束和常规的双系统框架。该框架通过自然语言提示为代理编码行动约束和常规，并使用相应的可执行代码作为自动化验证的真相依据。通过针对五个实际领域的自动化测试用例生成与评估流程，文章定量地评估了当前主流语言代理对操作约束的遵从程度。研究发现，现有最先进的模型之间存在显著的性能差距，其中像o1这样的大型推理模型表现出更优秀的合规性，而其他一些模型在面对复杂约束或用户劝诱尝试时则显示出明显较低的性能。 <div>
arXiv:2503.08669v1 Announce Type: new 
Abstract: As language agents progressively automate critical tasks across domains, their ability to operate within operational constraints and safety protocols becomes essential. While extensive research has demonstrated these agents' effectiveness in downstream task completion, their reliability in following operational procedures and constraints remains largely unexplored. To this end, we present AgentOrca, a dual-system framework for evaluating language agents' compliance with operational constraints and routines. Our framework encodes action constraints and routines through both natural language prompts for agents and corresponding executable code serving as ground truth for automated verification. Through an automated pipeline of test case generation and evaluation across five real-world domains, we quantitatively assess current language agents' adherence to operational constraints. Our findings reveal notable performance gaps among state-of-the-art models, with large reasoning models like o1 demonstrating superior compliance while others show significantly lower performance, particularly when encountering complex constraints or user persuasion attempts.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CoLMDriver: LLM-based Negotiation Benefits Cooperative Autonomous Driving</title>
<link>https://arxiv.org/abs/2503.08683</link>
<guid>https://arxiv.org/abs/2503.08683</guid>
<content:encoded><![CDATA[
<div> 关键词: CoLMDriver、LLM、合作自动驾驶、车辆间通信、InterDrive<br /><br />总结:<br />
本文提出了一种名为CoLMDriver的合作自动驾驶系统，该系统利用大型语言模型（LLM）的能力，解决了传统合作方法在协议约束和应对未知交互场景方面的局限性。CoLMDriver采用并行驾驶管道，包括基于actor-critic范式的LLM谈判模块以及意图引导的航点生成器两部分。前者通过反馈不断优化合作策略，后者将谈判结果转化为可执行的航点。此外，文中还介绍了基于CARLA的新型模拟基准——InterDrive，包含了10个具有挑战性的互动驾驶场景用于评估V2V合作性能。实验结果显示，CoLMDriver在多种高度互动的V2V驾驶场景中成功率达到现有方法的11%以上。相关代码将在https://github.com/cxliu0314/CoLMDriver发布。 <div>
arXiv:2503.08683v1 Announce Type: new 
Abstract: Vehicle-to-vehicle (V2V) cooperative autonomous driving holds great promise for improving safety by addressing the perception and prediction uncertainties inherent in single-agent systems. However, traditional cooperative methods are constrained by rigid collaboration protocols and limited generalization to unseen interactive scenarios. While LLM-based approaches offer generalized reasoning capabilities, their challenges in spatial planning and unstable inference latency hinder their direct application in cooperative driving. To address these limitations, we propose CoLMDriver, the first full-pipeline LLM-based cooperative driving system, enabling effective language-based negotiation and real-time driving control. CoLMDriver features a parallel driving pipeline with two key components: (i) an LLM-based negotiation module under an actor-critic paradigm, which continuously refines cooperation policies through feedback from previous decisions of all vehicles; and (ii) an intention-guided waypoint generator, which translates negotiation outcomes into executable waypoints. Additionally, we introduce InterDrive, a CARLA-based simulation benchmark comprising 10 challenging interactive driving scenarios for evaluating V2V cooperation. Experimental results demonstrate that CoLMDriver significantly outperforms existing approaches, achieving an 11% higher success rate across diverse highly interactive V2V driving scenarios. Code will be released on https://github.com/cxliu0314/CoLMDriver.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Probabilistic Shielding for Safe Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.07671</link>
<guid>https://arxiv.org/abs/2503.07671</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning), 安全强化学习 (Safe RL), 线性规划, 马尔可夫决策过程 (Markov Decision Process, MDP), 状态增强

总结:
本文提出了一种新的、可扩展的安全强化学习方法，特别适用于已知安全动态的马尔可夫决策过程中，其中安全性被定义为无折扣的概率规避属性。该方法基于状态增强技术以及设计一个限制智能体行动选择的防护盾，能够在训练和测试阶段为智能体提供严格的正式安全性保证。实验结果表明，该方法在实践中具有可行性，从而为解决安全强化学习问题提供了新的思路和工具。 <div>
arXiv:2503.07671v1 Announce Type: cross 
Abstract: In real-life scenarios, a Reinforcement Learning (RL) agent aiming to maximise their reward, must often also behave in a safe manner, including at training time. Thus, much attention in recent years has been given to Safe RL, where an agent aims to learn an optimal policy among all policies that satisfy a given safety constraint. However, strict safety guarantees are often provided through approaches based on linear programming, and thus have limited scaling. In this paper we present a new, scalable method, which enjoys strict formal guarantees for Safe RL, in the case where the safety dynamics of the Markov Decision Process (MDP) are known, and safety is defined as an undiscounted probabilistic avoidance property. Our approach is based on state-augmentation of the MDP, and on the design of a shield that restricts the actions available to the agent. We show that our approach provides a strict formal safety guarantee that the agent stays safe at training and test time. Furthermore, we demonstrate that our approach is viable in practice through experimental evaluation.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Collaborative Uncertainty Benefits Multi-Agent Multi-Modal Trajectory Forecasting</title>
<link>https://arxiv.org/abs/2207.05195</link>
<guid>https://arxiv.org/abs/2207.05195</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态多智能体轨迹预测、协同不确定性(CU)、预测不确定性、优化选择、基准评测

总结:<br />
本文针对多模态多智能体轨迹预测中的两个主要挑战，即如何度量交互模块带来的不确定性以及如何对多个预测结果进行排序和选择最佳预测轨迹，提出了一种新的概念——协同不确定性(CU)。文章构建了一个具有原创的等变不确定性估计器的通用CU意识回归框架，该框架可同时完成回归和不确定性估计任务，并将其作为插件模块应用于当前最先进的多智能体多模态轨迹预测系统中。实验在合成数据集及两个公共大规模多智能体轨迹预测基准上进行，结果显示：1) 在合成数据集上，CU意识回归框架使模型能够适当地近似真实的拉普拉斯分布；2) 在多智能体轨迹预测基准上，该框架帮助SOTA系统稳定提升性能，如使VectorNet在nuScenes数据集上的最终位移误差（所选最优预测）降低了262厘米；3) 对于多智能体多模态轨迹预测系统，预测不确定性与未来随机性呈正相关；4) 估算得到的CU值高度关联了各智能体间的交互信息。 <div>
arXiv:2207.05195v2 Announce Type: replace 
Abstract: In multi-modal multi-agent trajectory forecasting, two major challenges have not been fully tackled: 1) how to measure the uncertainty brought by the interaction module that causes correlations among the predicted trajectories of multiple agents; 2) how to rank the multiple predictions and select the optimal predicted trajectory. In order to handle these challenges, this work first proposes a novel concept, collaborative uncertainty (CU), which models the uncertainty resulting from interaction modules. Then we build a general CU-aware regression framework with an original permutation-equivariant uncertainty estimator to do both tasks of regression and uncertainty estimation. Further, we apply the proposed framework to current SOTA multi-agent multi-modal forecasting systems as a plugin module, which enables the SOTA systems to 1) estimate the uncertainty in the multi-agent multi-modal trajectory forecasting task; 2) rank the multiple predictions and select the optimal one based on the estimated uncertainty. We conduct extensive experiments on a synthetic dataset and two public large-scale multi-agent trajectory forecasting benchmarks. Experiments show that: 1) on the synthetic dataset, the CU-aware regression framework allows the model to appropriately approximate the ground-truth Laplace distribution; 2) on the multi-agent trajectory forecasting benchmarks, the CU-aware regression framework steadily helps SOTA systems improve their performances. Specially, the proposed framework helps VectorNet improve by 262 cm regarding the Final Displacement Error of the chosen optimal prediction on the nuScenes dataset; 3) for multi-agent multi-modal trajectory forecasting systems, prediction uncertainty is positively correlated with future stochasticity; and 4) the estimated CU values are highly related to the interactive information among agents.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Interaction-Aware Multi-Robot Kinodynamic Motion Planning</title>
<link>https://arxiv.org/abs/2309.16445</link>
<guid>https://arxiv.org/abs/2309.16445</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统、动力学规划、交互力、db-ECBS、增强型冲突基搜索 (ECBS)

总结:
本文提出了一种针对具有不同动力学和驱动限制的多机器人系统的动态运动规划方法——db-ECBS。该方法着重处理近距离飞行时空中机器人间的空气动力学交互力问题。db-ECBS从离散的多智能体路径寻找算法ECBS扩展到连续域，采用单机器人动力学规划算法断续边界A*。方法分为三个层次：首先，使用允许在预计算的动力学原语间有界断续性的图搜索计算各机器人轨迹；其次，识别并解决机器人间的碰撞及交互力违规情况，通过向第一层施加约束来实现；最后，将带有断续性的解决方案作为初始猜测输入到联合空间轨迹优化中，并通过减小断续性边界进行重复迭代，形成一个任何时间、概率上完整且亚优解上界受控的规划器。文中对65个具有六种不同动力学的问题进行了基准测试，结果表明db-ECBS产生的轨迹成本仅为现有规划器的一半。此外，对于非常密集的场景，db-ECBS的交互感知特性尤为重要。 <div>
arXiv:2309.16445v3 Announce Type: replace 
Abstract: Kinodynamic motion planning for a multi-robot system with different dynamics and actuation limits is a challenging problem. The difficulty increases with the presence of an aerodynamic interaction force that occur in aerial robots flying in close-proximity. Due to these complexities, existing planners either rely on simplified assumption like ignoring robot dynamics, interaction forces or produce highly suboptimal solutions. This paper presents a kinodynamic motion planner for a heterogeneous team of robots that respects robot dynamics and directly reasons about interaction forces between aerial robots operating in close-proximity. Our method, db-ECBS, generalizes the multi-agent path finding method Enhanced Conflict-Based Search (ECBS) to the continuous domain by using the single-robot kinodynamic motion planner discontinuity-bounded A*. Db-ECBS operates on three levels. Initially, individual robot trajectories are computed using a graph search that allows bounded discontinuities between precomputed motion primitives. The second level identifies inter-robot collisions, interaction force violations and resolves them by imposing constraints on the first level. The third and final level uses the resulting solution with discontinuities as an initial guess for a joint space trajectory optimization. The procedure is repeated with a reduced discontinuity bound resulting in a anytime, probabilistically complete, and asymptotically bounded suboptimal planner. We provide a benchmark of 65 problems with six different dynamics. We demonstrate that db-ECBS produces trajectories that are less than half the cost of existing planners. We show that the interaction-awareness is in particular important for very dense scenarios.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Distributional Reward Critic Framework for Reinforcement Learning Under Perturbed Rewards</title>
<link>https://arxiv.org/abs/2401.05710</link>
<guid>https://arxiv.org/abs/2401.05710</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning), 奖励信号 (reward signal), 环境扰动 (environmental perturbation), 分布式奖励批评框架 (distributional reward critic framework), 学习性能 (learning performance)

总结:
本文研究了强化学习中奖励信号受到未知扰动的情况，提出了一种新的分布式奖励批评框架，该框架能够在训练过程中估计奖励分布和扰动。与现有方法相比，新方法具有更广泛的适用性，无需预先知道扰动情况、可访问干净的奖励或保持最优策略等假设。该框架适用于任何RL算法，并在多种环境（包括清洁奖励环境）下展现出与现有方法相当甚至更好的学习效果。在所研究的挑战性和泛化的扰动场景下，新方法在44/48的测试设置中取得了最高回报率（而最佳基线仅为11/48）。这表明新方法对于在奖励扰动环境中进行强化学习的能力有显著提升和深化作用。<br /><br /> <div>
arXiv:2401.05710v3 Announce Type: replace 
Abstract: The reward signal plays a central role in defining the desired behaviors of agents in reinforcement learning (RL). Rewards collected from realistic environments could be perturbed, corrupted, or noisy due to an adversary, sensor error, or because they come from subjective human feedback. Thus, it is important to construct agents that can learn under such rewards. Existing methodologies for this problem make strong assumptions, including that the perturbation is known in advance, clean rewards are accessible, or that the perturbation preserves the optimal policy. We study a new, more general, class of unknown perturbations, and introduce a distributional reward critic framework for estimating reward distributions and perturbations during training. Our proposed methods are compatible with any RL algorithm. Despite their increased generality, we show that they achieve comparable or better rewards than existing methods in a variety of environments, including those with clean rewards. Under the challenging and generalized perturbations we study, we win/tie the highest return in 44/48 tested settings (compared to 11/48 for the best baseline). Our results broaden and deepen our ability to perform RL in reward-perturbed environments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Right Place, Right Time! Dynamizing Topological Graphs for Embodied Navigation</title>
<link>https://arxiv.org/abs/2403.09905</link>
<guid>https://arxiv.org/abs/2403.09905</guid>
<content:encoded><![CDATA[
<div> 关键词：Embodied Navigation，Object Transition Graphs (OTGs)，Dynamic Environments，Reinforcement Learning，Large Language Models

总结:<br />
本文提出了一种将静态拓扑图动态化的新型框架——对象转换图(OTGs)，用于应对具有移动物体的动态环境中的导航任务。该框架模拟了受人类习惯启发的结构化对象路线变化。研究在流行的模拟器Matterport3D上应用OTGs建立了一个多目标寻找任务的导航基准，并对比评估了基于Oracle、强化学习和大语言模型（LLM）的方法。此外，文章还量化了代理的适应性并得出结论：使用学到的决策策略的代理比依赖特权Oracle知识的代理表现更好。据作者所知，这是首次在拓扑图上引入结构化时间动态性以研究通用的具身导航策略的工作。相关代码和数据集将公开发布，旨在推动对动态场景中具身导航的研究。 <div>
arXiv:2403.09905v3 Announce Type: replace 
Abstract: Embodied Navigation tasks often involve constructing topological graphs of a scene during exploration to facilitate high-level planning and decision-making for execution in continuous environments. Prior literature makes the assumption of static graphs with stationary targets, which does not hold in many real-world environments with moving objects. To address this, we present a novel formulation generalizing navigation to dynamic environments by introducing structured object transitions to dynamize static topological graphs called Object Transition Graphs (OTGs). OTGs simulate portable targets following structured routes inspired by human habits. We apply this technique to Matterport3D (MP3D), a popular simulator for evaluating embodied tasks. On these dynamized OTGs, we establish a navigation benchmark by evaluating Oracle-based, Reinforcement Learning, and Large Language Model (LLM)-based approaches on a multi-object finding task. Further, we quantify agent adaptability, and make key inferences such as agents employing learned decision-making strategies generalize better than those relying on privileged oracle knowledge. To the best of our knowledge, ours is the first work to introduce structured temporal dynamism on topological graphs for studying generalist embodied navigation policies. The code and dataset for our OTGs will be made publicly available to foster research on embodied navigation in dynamic scenes.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Is the House Ready For Sleeptime? Generating and Evaluating Situational Queries for Embodied Question Answering</title>
<link>https://arxiv.org/abs/2405.04732</link>
<guid>https://arxiv.org/abs/2405.04732</guid>
<content:encoded><![CDATA[
<div> 关键词：Embodied Question Answering (EQA)，Situational Queries (S-EQA)，Prompt-Generate-Evaluate (PGE)，Large Language Model (LLM)，VirtualHome模拟器

总结:

本文介绍了针对家庭环境中的具身问答（EQA）与情境查询（S-EQA）问题的研究。研究提出了一个新颖的Prompt-Generate-Evaluate (PGE) 方法，该方法利用LLM生成独特的情境查询及其对应的共识物体信息。通过使用PGE在VirtualHome模拟器生成2K条数据并进行大规模 Mechanical Turk 用户研究，证实了LLMs在生成情境数据方面表现优秀，但评估结果显示LLMs在根据共识回答这些问题时，其正确率仅为46.2%，表明它们在回答情境查询时存在困难，有时会违反常识来解释答案。此外，文章还展示了当缺乏结构化的场景图时，PGE用于生成真实世界环境中的情境数据，揭示了LLM在生成可靠的物体状态方面的幻觉现象。据作者所知，这是首次将EQA引入情境查询的上下文中，也是首次提出一种生成式的方法来创建查询，旨在促进对提高具身智能体现实世界可用性的研究。 <div>
arXiv:2405.04732v3 Announce Type: replace 
Abstract: We present and tackle the problem of Embodied Question Answering (EQA) with Situational Queries (S-EQA) in a household environment. Unlike prior EQA work tackling simple queries that directly reference target objects and properties ("What is the color of the car?"), situational queries (such as "Is the house ready for sleeptime?") are challenging as they require the agent to correctly identify multiple object-states (Doors: Closed, Lights: Off, etc.) and reach a consensus on their states for an answer. Towards this objective, we first introduce a novel Prompt-Generate-Evaluate (PGE) scheme that wraps around an LLM's output to generate unique situational queries and corresponding consensus object information. PGE is used to generate 2K datapoints in the VirtualHome simulator, which is then annotated for ground truth answers via a large scale user-study conducted on M-Turk. With a high rate of answerability (97.26%) on this study, we establish that LLMs are good at generating situational data. However, in evaluating the data using an LLM, we observe a low correlation of 46.2% with the ground truth human annotations; indicating that while LLMs are good at generating situational data, they struggle to answer them according to consensus. When asked for reasoning, we observe the LLM often goes against commonsense in justifying its answer. Finally, we utilize PGE to generate situational data in a real-world environment, exposing LLM hallucination in generating reliable object-states when a structured scene graph is unavailable. To the best of our knowledge, this is the first work to introduce EQA in the context of situational queries and also the first to present a generative approach for query creation. We aim to foster research on improving the real-world usability of embodied agents through this work.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Value Improved Actor Critic Algorithms</title>
<link>https://arxiv.org/abs/2406.01423</link>
<guid>https://arxiv.org/abs/2406.01423</guid>
<content:encoded><![CDATA[
<div> 关键词：Actor-Critic算法、深度神经网络、贪婪更新、价值改进、通用策略迭代

总结:
<br />
本文针对决策问题中学习近似最优行为策略的现代Actor-Critic算法进行了研究。这些算法依赖于深度神经网络来参数化行为策略并使用渐进式的梯度更新以逐步优化。为了解决贪婪度与稳定性之间的权衡，文章提出了将价值改进引入标准的Actor-Critic框架中的方法，即仅在更新策略的价值估计时应用更贪婪的更新操作。这样，代理可以在评估非参数化策略的同时，保持对参数化行为策略的稳定渐进式改进。理论分析证明了该方法在有限时间域内的通用策略迭代分析方案中能够收敛。实验结果显示，将价值改进集成到流行的离线Actor-Critic算法TD3和SAC中，可以显著提升或匹配其在DeepMind连续控制领域的不同环境下的性能，同时几乎不增加计算量和实现成本。 <div>
arXiv:2406.01423v2 Announce Type: replace 
Abstract: To learn approximately optimal acting policies for decision problems, modern Actor Critic algorithms rely on deep Neural Networks (DNNs) to parameterize the acting policy and greedification operators to iteratively improve it. The reliance on DNNs suggests an improvement that is gradient based, which is per step much less greedy than the improvement possible by greedier operators such as the greedy update used by Q-learning algorithms. On the other hand, slow and steady changes to the policy can also be beneficial for the stability of the learning process, resulting in a tradeoff between greedification and stability. To address this tradeoff, we propose to extend the standard framework of actor critic algorithms with value-improvement: a second greedification operator applied only when updating the policy's value estimate. In this framework the agent can evaluate non-parameterized policies and perform much greedier updates while maintaining the steady gradient-based improvement to the parameterized acting policy. We prove that this approach converges in the popular analysis scheme of Generalized Policy Iteration in the finite-horizon domain. Empirically, incorporating value-improvement into the popular off-policy actor-critic algorithms TD3 and SAC significantly improves or matches performance over their respective baselines, across different environments from the DeepMind continuous control domain, with negligible compute and implementation cost.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Behavior-Inspired Neural Networks for Relational Inference</title>
<link>https://arxiv.org/abs/2406.14746</link>
<guid>https://arxiv.org/abs/2406.14746</guid>
<content:encoded><![CDATA[
<div> 关键词：agent关系、动态系统、行为学习、非线性意见动力学模型、轨迹预测

<br />
总结:

该文提出了一种新的方法来处理和理解动态系统中交互主体的行为关系。与现有将关系类别视为离散分布的方法不同，本文引入了一个抽象层，从主体的可观测行为学习到其对潜在类别偏好的映射。通过将学习到的偏好与主体间的接近程度整合进一个非线性意见动力学模型，不仅能够自然地区分互斥的关系类别，还能预测主体随时间的演化行为以及控制主体行为。实验结果显示，该模型对于学习可解释的关系类别以及长期轨迹预测具有很高的效能。 <div>
arXiv:2406.14746v3 Announce Type: replace 
Abstract: From pedestrians to Kuramoto oscillators, interactions between agents govern how dynamical systems evolve in space and time. Discovering how these agents relate to each other has the potential to improve our understanding of the often complex dynamics that underlie these systems. Recent works learn to categorize relationships between agents based on observations of their physical behavior. These approaches model relationship categories as outcomes of a categorical distribution which is limiting and contrary to real-world systems, where relationship categories often intermingle and interact. In this work, we introduce a level of abstraction between the observable behavior of agents and the latent categories that determine their behavior. To do this, we learn a mapping from agent observations to agent preferences for a set of latent categories. The learned preferences and inter-agent proximity are integrated in a nonlinear opinion dynamics model, which allows us to naturally identify mutually exclusive categories, predict an agent's evolution in time, and control an agent's behavior. Through extensive experiments, we demonstrate the utility of our model for learning interpretable categories, and the efficacy of our model for long-horizon trajectory prediction.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mitigating Information Loss in Tree-Based Reinforcement Learning via Direct Optimization</title>
<link>https://arxiv.org/abs/2408.08761</link>
<guid>https://arxiv.org/abs/2408.08761</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning)，神经网络策略 (neural network policies)，符号策略 (symbolic policies)，SYMPOL，决策树 (decision trees)

总结:
本文介绍了一种名为SYMPOL的新方法，用于基于符号的轴对齐决策树的在线策略强化学习。SYMPOL结合了树型模型和策略梯度方法，使得智能体能够在保持高可解释性的同时学习并适应其行为。与现有的树基RL方法相比，SYMPOL在性能和可解释性方面均表现出优越性。它开创性地实现了在标准在线策略RL算法中，通过梯度驱动、端到端的方式直接学习可解释的决策树。因此，SYMPOL有可能成为一种基于决策树的新型可解释强化学习的基础。研究团队已经将其实现代码发布在GitHub上（https://github.com/s-marton/sympol）。 <div>
arXiv:2408.08761v5 Announce Type: replace 
Abstract: Reinforcement learning (RL) has seen significant success across various domains, but its adoption is often limited by the black-box nature of neural network policies, making them difficult to interpret. In contrast, symbolic policies allow representing decision-making strategies in a compact and interpretable way. However, learning symbolic policies directly within on-policy methods remains challenging. In this paper, we introduce SYMPOL, a novel method for SYMbolic tree-based on-POLicy RL. SYMPOL employs a tree-based model integrated with a policy gradient method, enabling the agent to learn and adapt its actions while maintaining a high level of interpretability. We evaluate SYMPOL on a set of benchmark RL tasks, demonstrating its superiority over alternative tree-based RL approaches in terms of performance and interpretability. Unlike existing methods, it enables gradient-based, end-to-end learning of interpretable, axis-aligned decision trees within standard on-policy RL algorithms. Therefore, SYMPOL can become the foundation for a new class of interpretable RL based on decision trees. Our implementation is available under: https://github.com/s-marton/sympol
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bearing-Distance Flocking with Zone-Based Interactions in Constrained Dynamic Environments</title>
<link>https://arxiv.org/abs/2409.10047</link>
<guid>https://arxiv.org/abs/2409.10047</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、区域控制、集结行为、避障、稳定性分析

<br /><br />总结：

本文提出了一种针对动态多智能体系统的新型区域 flocking 控制方法。该方法受到 Reynolds 的 boids 行为规则启发，引入了基于区域的排斥、冲突、吸引和监视的集结行为规则。每个代理仅利用相对方位和距离信息，计算出局部分离、局部与全局群速度对齐、局部凝聚、障碍物避让及边界条件以及对抗外来代理的战略性分离的行为贡献向量。控制策略利用这些局部感知的行为贡献向量引导每个代理的运动，并加入了对前方障碍物具有方向感知的避障机制。仿真结果验证了模型在创建灵活、适应性强和可扩展的集结行为方面的有效性。此外，文章还证明了在交互图构成连通树的情况下，无论初始条件如何，该集结模型都能够实现渐近稳定并收敛至稳定的集结配置。由于该集结模型依赖于本地感知到的方位和距离测量数据，因此具备良好的可伸缩性和鲁棒性，尤其适用于通信不可靠或资源密集型的现实世界场景中。 <div>
arXiv:2409.10047v4 Announce Type: replace 
Abstract: This paper presents a novel zone-based flocking control approach suitable for dynamic multi-agent systems (MAS). Inspired by Reynolds behavioral rules for $boids$, flocking behavioral rules with the zones of repulsion, conflict, attraction, and surveillance are introduced. For each agent, using only bearing and distance measurements, behavioral contribution vectors quantify the local separation, local and global flock velocity alignment, local cohesion, obstacle avoidance and boundary conditions, and strategic separation for avoiding alien agents. The control strategy uses the local perception-based behavioral contribution vectors to guide each agent's motion. Additionally, the control strategy incorporates a directionally aware obstacle avoidance mechanism that prioritizes obstacles in the agent's forward path. Simulation results validate the effectiveness of the model in creating flexible, adaptable, and scalable flocking behavior. Asymptotic stability and convergence to a stable flocking configuration for any initial conditions provided the interaction graph is a spanning tree are demonstrated. The flocking model's reliance on locally sensed bearing and distance measurements ensures scalability and robustness, particularly in scenarios where communication is unreliable or resource-intensive. This makes it well-suited for real-world applications demanding seamless operation in highly dynamic and distributed environments.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Obstacle Avoidance using Velocity Obstacles and Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.10117</link>
<guid>https://arxiv.org/abs/2409.10117</guid>
<content:encoded><![CDATA[
<div> 关键词: Velocity Obstacles (VO), 安全性保证, 撞击避免, 惯性积分器动态, 车辆动力学<br /><br />总结:
本文提出了一种结合速度障碍物(VO)策略与安全控制 Barrier Function (CBF)方法的新方案，用于移动障碍物和代理之间的碰撞避免。该方案解决了VO方法在简单多代理环境中可能过于保守且不能确保安全的问题，形式化地保障了安全性。通过对比基准测试，使用二阶惯性积分器和车辆动力学模型进行验证，结果表明，该方法在路径平滑度、撞击避免以及成功率等方面均优于基线方法。 <div>
arXiv:2409.10117v3 Announce Type: replace 
Abstract: Velocity Obstacles (VO) methods form a paradigm for collision avoidance strategies among moving obstacles and agents. While VO methods perform well in simple multi-agent environments, they don't guarantee safety and can show overly conservative behavior in common situations. In this paper, we propose to combine a VO-strategy for guidance with a CBF-approach for safety, which overcomes the overly conservative behavior of VOs and formally guarantees safety. We validate our method in a baseline comparison study, using 2nd order integrator and car-like dynamics. Results support that our method outperforms the baselines w.r.t. path smoothness, collision avoidance, and success rates.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASMA: An Adaptive Safety Margin Algorithm for Vision-Language Drone Navigation via Scene-Aware Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.10283</link>
<guid>https://arxiv.org/abs/2409.10283</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉语言导航、安全控制、控制 barrier 函数、模型预测控制、Adaptive Safety Margin Algorithm

<br /><br />总结：
本文探讨了在快速发展的视觉语言导航(VLN)领域中确保物理代理的安全性这一挑战。为实现人机交互下语言操控无人机的安全导航，该文提出一种结合红绿蓝和深度（RGB-D）相机观测的场景感知控制Barrier函数方法。文中首先设立了一个无CBF基线系统，使用跨模态注意力的视觉语言编码器将指令转化为地标序列，通过图像中的对象检测模型验证并规划路径。为了进一步提升安全性，文章提出了适应性安全裕度算法(ASMA)，它能动态追踪移动物体并在MPC框架内进行场景感知的CBF评估，实时预测潜在危险并主动调整控制动作以保证整个轨迹的航行安全。最终，该系统在Gazebo环境中使用ROS在Parrot Bebop2四旋翼无人机上进行了部署，并相比于无CBF的基线VLN系统，成功率达到64%-67%的增长，而轨迹长度仅增加了1.4%-5.8%。 <div>
arXiv:2409.10283v2 Announce Type: replace 
Abstract: In the rapidly evolving field of vision-language navigation (VLN), ensuring safety for physical agents remains an open challenge. For a human-in-the-loop language-operated drone to navigate safely, it must understand natural language commands, perceive the environment, and simultaneously avoid hazards in real time. Control Barrier Functions (CBFs) are formal methods that enforce safe operating conditions. Model Predictive Control (MPC) is an optimization framework that plans a sequence of future actions over a prediction horizon, ensuring smooth trajectory tracking while obeying constraints. In this work, we consider a VLN-operated drone platform and enhance its safety by formulating a novel scene-aware CBF that leverages ego-centric observations from a camera which has both Red-Green-Blue as well as Depth (RGB-D) channels. A CBF-less baseline system uses a Vision-Language Encoder with cross-modal attention to convert commands into an ordered sequence of landmarks. An object detection model identifies and verifies these landmarks in the captured images to generate a planned path. To further enhance safety, an Adaptive Safety Margin Algorithm (ASMA) is proposed. ASMA tracks moving objects and performs scene-aware CBF evaluation on-the-fly, which serves as an additional constraint within the MPC framework. By continuously identifying potentially risky observations, the system performs prediction in real time about unsafe conditions and proactively adjusts its control actions to maintain safe navigation throughout the trajectory. Deployed on a Parrot Bebop2 quadrotor in the Gazebo environment using the Robot Operating System (ROS), ASMA achieves 64%-67% increase in success rates with only a slight increase (1.4%-5.8%) in trajectory lengths compared to the baseline CBF-less VLN.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decoding Echo Chambers: LLM-Powered Simulations Revealing Polarization in Social Networks</title>
<link>https://arxiv.org/abs/2409.19338</link>
<guid>https://arxiv.org/abs/2409.19338</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体、回音室现象、情感倾向、意见演化、LLM模拟

总结:
本文关注社交媒体对如回音室现象等关键问题的影响以及其对社会可能带来的破坏性后果。研究指出传统方法往往简化了情感倾向和意见演化的复杂性，忽视了新闻和沟通主要通过文本进行的事实。因此，文章提出了基于LLM的大规模语言模型的社会意见网络模拟框架，以评估并对抗极化现象。该框架首先构建三种不同的网络结构来模拟社交互动的不同特性，随后让智能体依据推荐算法互动并借助推理分析更新策略。通过与经典的有限信心模型(BCM)和弗里德金-约翰森(FJ)模型比较及运用回音室相关指数，证明了所提框架在模拟意见动态和重现如意见极化、回音室现象等方面的有效性。此外，文中还提出了两种缓解回音室效应的方法：主动引导和被动引导。期望此工作能为社会极化缓解提供有价值的见解和指导。 <div>
arXiv:2409.19338v2 Announce Type: replace 
Abstract: The impact of social media on critical issues such as echo chambers needs to be addressed, as these phenomena can have disruptive consequences for our society. Traditional research often oversimplifies emotional tendencies and opinion evolution into numbers and formulas, neglecting that news and communication are conveyed through text, which limits these approaches. Hence, in this work, we propose an LLM-based simulation for the social opinion network to evaluate and counter polarization phenomena. We first construct three typical network structures to simulate different characteristics of social interactions. Then, agents interact based on recommendation algorithms and update their strategies through reasoning and analysis. By comparing these interactions with the classic Bounded Confidence Model (BCM), the Friedkin Johnsen (FJ) model, and using echo chamber-related indices, we demonstrate the effectiveness of our framework in simulating opinion dynamics and reproducing phenomena such as opinion polarization and echo chambers. We propose two mitigation methods, active and passive nudges, that can help reduce echo chambers, specifically within language-based simulations. We hope our work will offer valuable insights and guidance for social polarization mitigation.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent-Oriented Planning in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2410.02189</link>
<guid>https://arxiv.org/abs/2410.02189</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、元代理、任务分解、分配、奖励模型<br /><br />总结:
本研究关注多智能体系统中使用大型语言模型赋能的智能体协同解决问题的情况。为了有效地响应用户查询，提出了一种称为“Agent-Oriented Planning”（AOP）的新框架，该框架强调了任务分解的可解性、完整性和非冗余性三个关键设计原则。AOP通过快速的任务分解和分配过程以及利用奖励模型进行有效评估来运作。根据评价结果，元代理还需要及时调整子任务并进行调度。此外，AOP整合了反馈环路以增强问题解决过程的有效性和鲁棒性。实验表明，与单一智能体系统和现有多智能体系统的规划策略相比，AOP在解决实际问题方面具有显著优势。相关源代码已发布在https://github.com/lalaliat/Agent-Oriented-Planning上。 <div>
arXiv:2410.02189v2 Announce Type: replace 
Abstract: Through the collaboration of multiple LLM-empowered agents possessing diverse expertise and tools, multi-agent systems achieve impressive progress in solving real-world problems. Given the user queries, the meta-agents, serving as the brain within multi-agent systems, are required to decompose the queries into multiple sub-tasks that can be allocated to suitable agents capable of solving them, so-called agent-oriented planning. In this study, we identify three critical design principles of agent-oriented planning, including solvability, completeness, and non-redundancy, to ensure that each sub-task can be effectively resolved, resulting in satisfactory responses to user queries. These principles further inspire us to propose AOP, a novel framework for agent-oriented planning in multi-agent systems, leveraging a fast task decomposition and allocation process followed by an effective and efficient evaluation via a reward model. According to the evaluation results, the meta-agent is also responsible for promptly making necessary adjustments to sub-tasks and scheduling. Besides, we integrate a feedback loop into AOP to further enhance the effectiveness and robustness of such a problem-solving process. Extensive experiments demonstrate the advancement of AOP in solving real-world problems compared to both single-agent systems and existing planning strategies for multi-agent systems. The source code is available at https://github.com/lalaliat/Agent-Oriented-Planning
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GraphSCENE: On-Demand Critical Scenario Generation for Autonomous Vehicles in Simulation</title>
<link>https://arxiv.org/abs/2410.13514</link>
<guid>https://arxiv.org/abs/2410.13514</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动驾驶车辆(AV), 模拟测试, 时空场景图, 图神经网络(GNN), 嵌入式生成

<br /><br />总结:
本文提出了一种新颖的方法，用于自动生成与自动驾驶车辆(AV)安全关键和多样化场景对应的动态临时场景图，以解决在实际部署前手动创建此类场景的挑战。该方法利用用户定义的偏好（如AV动作、动态代理集合和危险等级）进行定制化场景生成。通过一个基于时空交互模式的temporal Graph Neural Network (GNN)模型，学习预测车辆、代理及静态结构之间的关系，并受到限制于仅允许语义有效链接的本体约束。实验表明，该模型在准确生成对应请求场景的链接方面优于基线。为了进一步验证这些预测场景的有效性，文章将其渲染到模拟环境中，作为测试AV智能体的环境。 <div>
arXiv:2410.13514v2 Announce Type: replace 
Abstract: Testing and validating Autonomous Vehicle (AV) performance in safety-critical and diverse scenarios is crucial before real-world deployment. However, manually creating such scenarios in simulation remains a significant and time-consuming challenge. This work introduces a novel method that generates dynamic temporal scene graphs corresponding to diverse traffic scenarios, on-demand, tailored to user-defined preferences, such as AV actions, sets of dynamic agents, and criticality levels. A temporal Graph Neural Network (GNN) model learns to predict relationships between ego-vehicle, agents, and static structures, guided by real-world spatiotemporal interaction patterns and constrained by an ontology that restricts predictions to semantically valid links. Our model consistently outperforms the baselines in accurately generating links corresponding to the requested scenarios. We render the predicted scenarios in simulation to further demonstrate their effectiveness as testing environments for AV agents.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fourier Head: Helping Large Language Models Learn Complex Probability Distributions</title>
<link>https://arxiv.org/abs/2410.22269</link>
<guid>https://arxiv.org/abs/2410.22269</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、非语言tokens、决策变换器、Fourier系列层、连续结构

总结:
本文探讨了如何将大型语言模型应用于非语言领域，并指出softmax对离散令牌空间建模可能存在局限性。为此，作者提出了一种使用Fourier级数构建的神经网络层，该层可以替代线性层以更好地捕捉具有连续结构的令牌和复杂分布。通过在合成数据集以及大规模决策制定和时间序列预测任务上的实验，文章提供了理论证据证明Fourier头能够更好地从数据中学习信号并忽略高频噪声。实验结果显示，Fourier头显著提高了决策变换器在四个Atari游戏中的性能（最高提升377%）以及一款先进的时间序列基础模型在未见过的20个基准测试上的预测性能（提升3.5%）。 <div>
arXiv:2410.22269v2 Announce Type: replace 
Abstract: As the quality of large language models has improved, there has been increased interest in using them to model non-linguistic tokens. For example, the Decision Transformer recasts agentic decision making as a sequence modeling problem, using a decoder-only LLM to model the distribution over the discrete action space for an Atari agent. However, when adapting LLMs to non-linguistic domains, it remains unclear if softmax over discrete bins captures the continuous structure of the tokens and the potentially complex distributions needed for high quality token generation. We introduce a neural network layer, constructed using Fourier series, which we can easily substitute for any linear layer if we want the outputs to have a more continuous structure. We perform extensive analysis on synthetic datasets, as well as on large-scale decision making and time series forecasting tasks. We also provide theoretical evidence that this layer can better learn signal from data while ignoring high-frequency noise. All of our results support the effectiveness of our proposed Fourier head in scenarios where the underlying data distribution has a natural continuous structure. For example, the Fourier head improves a Decision Transformer agent's returns across four benchmark Atari games by as much as 377%, and increases a state-of-the-art times series foundation model's forecasting performance by 3.5% across 20 benchmarks unseen during training.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Lost &amp; Found: Tracking Changes from Egocentric Observations in 3D Dynamic Scene Graphs</title>
<link>https://arxiv.org/abs/2411.19162</link>
<guid>https://arxiv.org/abs/2411.19162</guid>
<content:encoded><![CDATA[
<div> 关键词: 动态场景理解、语义3D分割、手部位置估计、6DoF对象追踪、机器人应用

<br /><br />总结:
本文提出了一种名为Lost & Found的新方法，旨在解决静态重建无法捕捉动态环境和人类或机器人交互信息的问题。该方法基于仅有的第一人称视角录像和对应的手部位置及相机姿态估计，能够在线跟踪交互区间内移动物体的6自由度（6DoF）姿态，并将这些变化实时应用于可变形场景图中，以捕获物体级别的关系。相较于当前最先进的对象姿态追踪器，Lost & Found 在处理具有挑战性的第一人称视角和缺乏深度信息的情况下表现出更高的可靠性，分别在位移和旋转误差上提高了34%和56%。此外，文章还展示了利用动态场景图中的交互信息如何实现原本难以完成的机器人应用场景：通过Lost & Found 方法，可以实现对移动机械臂的“教示与重复”命令执行，以及利用先前交互信息让移动机械臂成功从抽屉中检索物品。相关代码、视频和数据可在https://behretj.github.io/LostAndFound 获取。 <div>
arXiv:2411.19162v2 Announce Type: replace 
Abstract: Recent approaches have successfully focused on the segmentation of static reconstructions, thereby equipping downstream applications with semantic 3D understanding. However, the world in which we live is dynamic, characterized by numerous interactions between the environment and humans or robotic agents. Static semantic maps are unable to capture this information, and the naive solution of rescanning the environment after every change is both costly and ineffective in tracking e.g. objects being stored away in drawers. With Lost & Found we present an approach that addresses this limitation. Based solely on egocentric recordings with corresponding hand position and camera pose estimates, we are able to track the 6DoF poses of the moving object within the detected interaction interval. These changes are applied online to a transformable scene graph that captures object-level relations. Compared to state-of-the-art object pose trackers, our approach is more reliable in handling the challenging egocentric viewpoint and the lack of depth information. It outperforms the second-best approach by 34% and 56% for translational and orientational error, respectively, and produces visibly smoother 6DoF object trajectories. In addition, we illustrate how the acquired interaction information in the dynamic scene graph can be employed in the context of robotic applications that would otherwise be unfeasible: We show how our method allows to command a mobile manipulator through teach & repeat, and how information about prior interaction allows a mobile manipulator to retrieve an object hidden in a drawer. Code, videos and corresponding data are accessible at https://behretj.github.io/LostAndFound.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Proto Successor Measure: Representing the Behavior Space of an RL Agent</title>
<link>https://arxiv.org/abs/2411.19418</link>
<guid>https://arxiv.org/abs/2411.19418</guid>
<content:encoded><![CDATA[
<div> 关键词: zero-shot学习, 强化学习, Proto Successor Measure, 行为表示, 奖励函数

总结:
本文提出了Proto Successor Measure，这是一种通用强化学习环境中智能体所有可能行为的基础集合。它证明了任何行为（通过访问分布表示）都可以使用与策略无关的基本函数的线性组合来表示。当测试时给定奖励函数，只需找到正确的一组线性权重来组合这些对应于最优策略的基础函数。文章描述了一种实用算法，该算法利用环境中的无奖励交互数据来学习这些基础函数，并展示其方法能够在不进行额外环境交互的情况下，针对给定的任意奖励函数生成最优策略。 <div>
arXiv:2411.19418v2 Announce Type: replace 
Abstract: Having explored an environment, intelligent agents should be able to transfer their knowledge to most downstream tasks within that environment without additional interactions. Referred to as "zero-shot learning", this ability remains elusive for general-purpose reinforcement learning algorithms. While recent works have attempted to produce zero-shot RL agents, they make assumptions about the nature of the tasks or the structure of the MDP. We present Proto Successor Measure: the basis set for all possible behaviors of a Reinforcement Learning Agent in a dynamical system. We prove that any possible behavior (represented using visitation distributions) can be represented using an affine combination of these policy-independent basis functions. Given a reward function at test time, we simply need to find the right set of linear weights to combine these bases corresponding to the optimal policy. We derive a practical algorithm to learn these basis functions using reward-free interaction data from the environment and show that our approach can produce the optimal policy at test time for any given reward function without additional environmental interactions. Project page: https://agarwalsiddhant10.github.io/projects/psm.html.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MAGIC: Mastering Physical Adversarial Generation in Context through Collaborative LLM Agents</title>
<link>https://arxiv.org/abs/2412.08014</link>
<guid>https://arxiv.org/abs/2412.08014</guid>
<content:encoded><![CDATA[
<div> 关键词: 物理对抗攻击、视觉感知模型、生成式模型、多模态LLM代理、MAGIC框架

总结:
本文提出了一种针对驾驶场景中物理对抗攻击的新方法，将该问题重新定义为一次性补丁生成问题。研究重点在于开发一种能够在保持视觉自然性的同时，针对特定场景环境生成能误导对象检测系统的对抗性补丁的方法。为此，文章介绍了名为MAGIC的新框架，它利用多模态LLM（语言-视觉）代理来理解和生成对抗性补丁并确定其在场景中的合理部署。MAGIC由三个专门的LLM代理组成：GAgent负责通过策略性的文本到图像模型提示工程学生成欺骗性补丁；DAgent依据对场景的理解确定补丁的最优部署策略；EAgent则提供关键性的监督和两个过程的迭代改进。实验结果表明，MAGIC方法在数字和现实世界环境中都表现出强大的攻击效果，能够有效对抗广泛应用的对象检测系统，如YOLO和DETR系列。 <div>
arXiv:2412.08014v2 Announce Type: replace 
Abstract: Physical adversarial attacks in driving scenarios can expose critical vulnerabilities in visual perception models. However, developing such attacks remains challenging due to diverse real-world environments and the requirement for maintaining visual naturality. Building upon this challenge, we reformulate physical adversarial attacks as a one-shot patch generation problem. Our approach generates adversarial patches through a deep generative model that considers the specific scene context, enabling direct physical deployment in matching environments. The primary challenge lies in simultaneously achieving two objectives: generating adversarial patches that effectively mislead object detection systems while determining contextually appropriate deployment within the scene. We propose MAGIC (Mastering Physical Adversarial Generation In Context), a novel framework powered by multi-modal LLM agents to address these challenges. MAGIC automatically understands scene context and generates adversarial patch through the synergistic interaction of language and vision capabilities. In particular, MAGIC orchestrates three specialized LLM agents: The adv-patch generation agent (GAgent) masters the creation of deceptive patches through strategic prompt engineering for text-to-image models. The adv-patch deployment agent (DAgent) ensures contextual coherence by determining optimal deployment strategies based on scene understanding. The self-examination agent (EAgent) completes this trilogy by providing critical oversight and iterative refinement of both processes. We validate our method on both digital and physical levels, i.e., nuImage and manually captured real-world scenes, where both statistical and visual results prove that our MAGIC is powerful and effective for attacking widely applied object detection systems, i.e., YOLO and DETR series.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CogNav: Cognitive Process Modeling for Object Goal Navigation with LLMs</title>
<link>https://arxiv.org/abs/2412.10439</link>
<guid>https://arxiv.org/abs/2412.10439</guid>
<content:encoded><![CDATA[
<div> 关键词：ObjectNav、embodied AI、CogNav、认知过程、大型语言模型

总结:
本文提出了一种名为CogNav的新框架，用于解决对象导航(ObjectNav)任务，该任务要求智能体在未见过的环境中找到目标物体。CogNav受到人类在新环境中执行物体搜索任务时维持和动态更新精细认知状态的神经科学研究启发。该框架利用大型语言模型模拟从探索到识别等细粒度的认知状态转换，并基于动态构建的异质认知图（包含场景的空间和语义信息）来确定状态间的转变。通过在HM3D、MP3D和RoboTHOR基准上的广泛评估，表明CogNav中对认知过程的建模显著提高了ObjectNav的成功率，至少比现有最优方法提升了14%。 <div>
arXiv:2412.10439v2 Announce Type: replace 
Abstract: Object goal navigation (ObjectNav) is a fundamental task in embodied AI, requiring an agent to locate a target object in previously unseen environments. This task is particularly challenging because it requires both perceptual and cognitive processes, including object recognition and decision-making. While substantial advancements in perception have been driven by the rapid development of visual foundation models, progress on the cognitive aspect remains constrained, primarily limited to either implicit learning through simulator rollouts or explicit reliance on predefined heuristic rules. Inspired by neuroscientific findings demonstrating that humans maintain and dynamically update fine-grained cognitive states during object search tasks in novel environments, we propose CogNav, a framework designed to mimic this cognitive process using large language models. Specifically, we model the cognitive process using a finite state machine comprising fine-grained cognitive states, ranging from exploration to identification. Transitions between states are determined by a large language model based on a dynamically constructed heterogeneous cognitive map, which contains spatial and semantic information about the scene being explored. Extensive evaluations on the HM3D, MP3D, and RoboTHOR benchmarks demonstrate that our cognitive process modeling significantly improves the success rate of ObjectNav at least by relative 14% over the state-of-the-arts.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Exploring the Inquiry-Diagnosis Relationship with Advanced Patient Simulators</title>
<link>https://arxiv.org/abs/2501.09484</link>
<guid>https://arxiv.org/abs/2501.09484</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、在线医疗咨询、对话策略、患者模拟器、诊断效果

<br /><br />总结:
本文关注了大型语言模型在在线医疗咨询中的应用，指出现有研究多注重提升诊断准确性而忽视了询问环节。文章提出了从真实医生-病人对话中抽取对话策略来训练更准确的患者模拟器的方法，该模拟器具备更高的拟人化特性和较低的幻觉生成率，并能生成逼真的合成数据。此外，通过实验证明了询问与诊断之间的关系遵循Liebig's定律，即询问质量对诊断效果具有决定性影响。文中还分析了不同模型在询问过程中的表现差异，并将询问过程分为四种类型进行分类讨论，这些分析有助于解释各模型性能差距的原因。患者模拟器的权重已开源，可在https://github.com/PatientSimulator/PatientSimulator获取。 <div>
arXiv:2501.09484v2 Announce Type: replace 
Abstract: Recently, large language models have shown great potential to transform online medical consultation. Despite this, most research targets improving diagnostic accuracy with ample information, often overlooking the inquiry phase. Some studies try to evaluate or refine doctor models by using prompt-engineered patient agents. However, prompt engineering alone falls short in accurately simulating real patients. We need to explore new paradigms for patient simulation. Furthermore, the relationship between inquiry and diagnosis remains unexplored. This paper extracts dialogue strategies from real doctor-patient conversations to guide the training of a patient simulator. Our simulator shows higher anthropomorphism and lower hallucination rates, using dynamic dialogue strategies. This innovation offers a more accurate evaluation of diagnostic models and generates realistic synthetic data. We conduct extensive experiments on the relationship between inquiry and diagnosis, showing they adhere to Liebig's law: poor inquiry limits diagnosis effectiveness, regardless of diagnostic skill, and vice versa. The experiments also reveal substantial differences in inquiry performance among models. To delve into this phenomenon, the inquiry process is categorized into four distinct types. Analyzing the distribution of inquiries across these types helps explain the performance differences. The weights of our patient simulator are available https://github.com/PatientSimulator/PatientSimulator.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning to Plan with Personalized Preferences</title>
<link>https://arxiv.org/abs/2502.00858</link>
<guid>https://arxiv.org/abs/2502.00858</guid>
<content:encoded><![CDATA[
<div> 关键词：AI代理、个人偏好、规划策略、基于偏好的规划（PbP）基准、中间表示

<br /><br />总结:
本文针对AI代理融入日常生活的需求，提出了让AI从少量示范中学习并适应个体人类偏好的方法。研究者开发了一种能够根据所学偏好调整规划策略的智能体，并利用观察到的偏好可以通过少量示范在多样化规划场景中泛化的现象，创建了包含广泛多样偏好的基于偏好的规划（PbP）基准。评估发现，符号型方法在可扩展性方面展现出潜力，但在生成和执行满足个性化偏好的计划方面仍面临挑战。将学习到的偏好作为中间表示融合进规划过程，可以显著提高智能体构建个性化计划的能力。这一发现强调了偏好作为适应性规划有价值的抽象层的作用，为偏好引导下的计划生成与执行研究开辟了新方向。 <div>
arXiv:2502.00858v2 Announce Type: replace 
Abstract: Effective integration of AI agents into daily life requires them to understand and adapt to individual human preferences, particularly in collaborative roles. Although recent studies on embodied intelligence have advanced significantly, they typically adopt generalized approaches that overlook personal preferences in planning. We address this limitation by developing agents that not only learn preferences from few demonstrations but also learn to adapt their planning strategies based on these preferences. Our research leverages the observation that preferences, though implicitly expressed through minimal demonstrations, can generalize across diverse planning scenarios. To systematically evaluate this hypothesis, we introduce Preference-based Planning (PbP) benchmark, an embodied benchmark featuring hundreds of diverse preferences spanning from atomic actions to complex sequences. Our evaluation of SOTA methods reveals that while symbol-based approaches show promise in scalability, significant challenges remain in learning to generate and execute plans that satisfy personalized preferences. We further demonstrate that incorporating learned preferences as intermediate representations in planning significantly improves the agent's ability to construct personalized plans. These findings establish preferences as a valuable abstraction layer for adaptive planning, opening new directions for research in preference-guided plan generation and execution.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic Bug Reproduction for Effective Automated Program Repair at Google</title>
<link>https://arxiv.org/abs/2502.01821</link>
<guid>https://arxiv.org/abs/2502.01821</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化Bug重现测试、BRT生成、大型语言模型、自动程序修复、Ensemble Pass Rate

<br /><br />总结:
本文探讨了在工业环境中，特别是在谷歌公司内部，如何自动生成Bug重现测试（BRT）以加速调试过程。研究团队对现有的BRT生成技术LIBRO进行了改进，并提出了基于大型语言模型（LLM）编辑代码的BRT Agent方法。实验结果显示，BRT Agent在处理来源于谷歌内部问题追踪器的80个人工报告的bug时，其生成合理BRT的成功率达到了28%，显著优于LIBRO的10%。此外，研究团队还将生成的BRT与谷歌的自动程序修复（APR）系统结合，发现这使得产生合理修复方案的数量增加了30%。为评估和选择修复方案的有效性，他们还引入了一种新的指标——Ensemble Pass Rate（EPR），在选取Top-K或阈值为基础的修复方案中显示出了有希望的结果和权衡，例如，在从20个候选修复方案中，EPR能够以top-1排名准确地选出合理的修复方案达70%的情况。 <div>
arXiv:2502.01821v2 Announce Type: replace 
Abstract: Bug reports often lack sufficient detail for developers to reproduce and fix the underlying defects. Bug Reproduction Tests (BRTs), tests that fail when the bug is present and pass when it has been resolved, are crucial for debugging, but they are rarely included in bug reports, both in open-source and in industrial settings. Thus, automatically generating BRTs from bug reports has the potential to accelerate the debugging process and lower time to repair. This paper investigates automated BRT generation within an industry setting, specifically at Google, focusing on the challenges of a large-scale, proprietary codebase and considering real-world industry bugs extracted from Google's internal issue tracker. We adapt and evaluate a state-of-the-art BRT generation technique, LIBRO, and present our agent-based approach, BRT Agent, which makes use of a fine-tuned Large Language Model (LLM) for code editing. Our BRT Agent significantly outperforms LIBRO, achieving a 28% plausible BRT generation rate, compared to 10% by LIBRO, on 80 human-reported bugs from Google's internal issue tracker. We further investigate the practical value of generated BRTs by integrating them with an Automated Program Repair (APR) system at Google. Our results show that providing BRTs to the APR system results in 30% more bugs with plausible fixes. Additionally, we introduce Ensemble Pass Rate (EPR), a metric which leverages the generated BRTs to select the most promising fixes from all fixes generated by APR system. Our evaluation on EPR for Top-K and threshold-based fix selections demonstrates promising results and trade-offs. For example, EPR correctly selects a plausible fix from a pool of 20 candidates in 70% of cases, based on its top-1 ranking.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Prediction of the Most Fire-Sensitive Point in Building Structures with Differentiable Agents for Thermal Simulators</title>
<link>https://arxiv.org/abs/2502.03424</link>
<guid>https://arxiv.org/abs/2502.03424</guid>
<content:encoded><![CDATA[
<div> 关键词：火安全、最火敏感点(MFSP)、机器学习框架、图神经网络(GNN)、最大层间位移比(MIDR)

总结:<br />
本文提出了一种用于识别建筑物中最火敏感点(MFSP)的高效机器学习框架，旨在简化和优化建筑结构的火安全性评估。该框架利用图神经网络(GNN)作为有限元分析(FEA)模拟器的代理，预测火灾下的最大层间位移比(MIDR)，进而指导MFSP预测器的训练与评估。同时，文中还引入了新颖的边更新机制及基于迁移学习的训练方案。大规模仿真数据集上的实验验证了该框架在识别MFSP方面的良好性能，为建筑结构设计中的火安全评估优化提供了革新性工具。相关数据集和代码已在线开源。 <div>
arXiv:2502.03424v2 Announce Type: replace 
Abstract: Fire safety is crucial for ensuring the stability of building structures, yet evaluating whether a structure meets fire safety requirement is challenging. Fires can originate at any point within a structure, and simulating every potential fire scenario is both expensive and time-consuming. To address this challenge, we propose the concept of the Most Fire-Sensitive Point (MFSP) and an efficient machine learning framework for its identification. The MFSP is defined as the location at which a fire, if initiated, would cause the most severe detrimental impact on the building's stability, effectively representing the worst-case fire scenario. In our framework, a Graph Neural Network (GNN) serves as an efficient and differentiable agent for conventional Finite Element Analysis (FEA) simulators by predicting the Maximum Interstory Drift Ratio (MIDR) under fire, which then guides the training and evaluation of the MFSP predictor. Additionally, we enhance our framework with a novel edge update mechanism and a transfer learning-based training scheme. Evaluations on a large-scale simulation dataset demonstrate the good performance of the proposed framework in identifying the MFSP, offering a transformative tool for optimizing fire safety assessments in structural design. All developed datasets and codes are open-sourced online.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CASC-AI: Consensus-aware Self-corrective Learning for Noise Cell Segmentation</title>
<link>https://arxiv.org/abs/2502.07302</link>
<guid>https://arxiv.org/abs/2502.07302</guid>
<content:encoded><![CDATA[
<div> 关键词：多类细胞分割、高分辨率全切片图像、标注噪声、自校正AI代理、共识矩阵

总结:<br />
本文提出了一种基于共识矩阵的自校正AI代理方法，用于解决高分辨率全切片图像（WSIs）中多类细胞分割的问题。该方法旨在降低依赖于专业医学知识的像素级注释需求。针对非专家注释存在的噪声问题，本文的方法通过共识矩阵强化了AI与注释者在细胞和非细胞区域认同部分的学习指导，并根据特征相似度对分歧区域进行适应性加权。同时，采用对比学习方法增强模型对噪声区域与可靠共识区域特征差异性的识别，从而迭代修正噪声标签，提高模型鲁棒性。实验结果显示，该方法在真实世界中的非专家注释细胞数据集及两个模拟标注噪声的数据集上均表现出更好的分割性能，有效纠正了假阳性和假阴性错误，展示出了其在训练鲁棒模型上的潜力。相关实现和细胞注释已公开发布在GitHub仓库中。 <div>
arXiv:2502.07302v2 Announce Type: replace 
Abstract: Multi-class cell segmentation in high-resolution gigapixel whole slide images (WSIs) is crucial for various clinical applications. However, training such models typically requires labor-intensive, pixel-wise annotations by domain experts. Recent efforts have democratized this process by involving lay annotators without medical expertise. However, conventional non-corrective approaches struggle to handle annotation noise adaptively because they lack mechanisms to mitigate false positives (FP) and false negatives (FN) at both the image-feature and pixel levels. In this paper, we propose a consensus-aware self-corrective AI agent that leverages the Consensus Matrix to guide its learning process. The Consensus Matrix defines regions where both the AI and annotators agree on cell and non-cell annotations, which are prioritized with stronger supervision. Conversely, areas of disagreement are adaptively weighted based on their feature similarity to high-confidence consensus regions, with more similar regions receiving greater attention. Additionally, contrastive learning is employed to separate features of noisy regions from those of reliable consensus regions by maximizing their dissimilarity. This paradigm enables the model to iteratively refine noisy labels, enhancing its robustness. Validated on one real-world lay-annotated cell dataset and two reasoning-guided simulated noisy datasets, our method demonstrates improved segmentation performance, effectively correcting FP and FN errors and showcasing its potential for training robust models on noisy datasets. The official implementation and cell annotations are publicly available at https://github.com/ddrrnn123/CASC-AI.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AI Mimicry and Human Dignity: Chatbot Use as a Violation of Self-Respect</title>
<link>https://arxiv.org/abs/2503.05723</link>
<guid>https://arxiv.org/abs/2503.05723</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能聊天机器人、人类尊严、大型语言模型、第二人称尊重、自我尊重

总结:
本文探讨了人工智能驱动的聊天机器人与人类交互可能对人的尊严产生的冒犯。现有的聊天机器人通过大型语言模型模拟人类语言行为，但缺乏真正人际尊重所需的道德和理性能力。人们倾向于将聊天机器人拟人化，而设计上似乎也刻意诱发这种反应。基于第二人称关系性的尊严观念，文章认为以对待道德主体的方式与聊天机器人互动与用户尊严相悖。由于第二人称尊重建立在相互承认第二人称权威的基础上，向不具备相应回应能力的聊天机器人表达这种尊重注定会导致道德问题。因此，此类与聊天机器人的互动实际上构成了对自我尊重——即我们有义务对自己尊严展现的尊重——微妙却重大的侵犯。文中通过讨论信息检索、客户服务、咨询及陪伴等四个实际应用场景来阐述这一点，并提出日益增长的社会压力要求人们与聊天机器人进行此类交互，这构成了对人类尊严的一个先前未被充分认识的威胁。 <div>
arXiv:2503.05723v1 Announce Type: new 
Abstract: This paper investigates how human interactions with AI-powered chatbots may offend human dignity. Current chatbots, driven by large language models (LLMs), mimic human linguistic behaviour but lack the moral and rational capacities essential for genuine interpersonal respect. Human beings are prone to anthropomorphise chatbots. Indeed, chatbots appear to be deliberately designed to elicit that response. As a result, human beings' behaviour toward chatbots often resembles behaviours typical of interaction between moral agents. Drawing on a second-personal, relational account of dignity, we argue that interacting with chatbots in this way is incompatible with the dignity of users. We show that, since second-personal respect is premised on reciprocal recognition of second-personal authority, behaving towards chatbots in ways that convey second-personal respect is bound to misfire in morally problematic ways, given the lack of reciprocity. Consequently, such chatbot interactions amount to subtle but significant violations of self-respect: the respect we are dutybound to show for our own dignity. We illustrate this by discussing four actual chatbot use cases (information retrieval, customer service, advising, and companionship), and propound that the increasing societal pressure to engage in such interactions with chatbots poses a hitherto underappreciated threat to human dignity.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Addressing Moral Uncertainty using Large Language Models for Ethical Decision-Making</title>
<link>https://arxiv.org/abs/2503.05724</link>
<guid>https://arxiv.org/abs/2503.05724</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 道德决策框架, 大规模语言模型, 伦理层, 道德不确定性

<br />
总结:

本文提出了一种道德决策框架，旨在通过任务无关的伦理层对预训练强化学习（RL）模型进行细化调整。首先，RL模型经过初始训练后，采用大规模语言模型（LLM）产生的反馈进行道德微调，该语言模型能够体现后果主义、义务论、美德伦理、社会公正和关怀伦理等多种道德原则，为推荐行为分配信念值。接着，通过使用信念Jensen-Shannon散度和Dempster-Shafer理论，伦理层将多个LLM衍生道德视角的信念得分聚合为概率分数，同时作为塑造奖励，引导智能体朝着与平衡的道德框架相一致的选择发展。这种方法有助于RL代理在复杂环境中应对道德不确定性，使其能够在各种任务中做出道德上合理的决定。实验表明，相比于其他信念聚合技术，该方法在不同LLM变体上的表现提高了决策的一致性、适应性和减少了对手动编写的道德奖励的依赖，尤其适用于现实世界中可能出现意外道德挑战的动态场景。 <div>
arXiv:2503.05724v1 Announce Type: new 
Abstract: We present an ethical decision-making framework that refines a pre-trained reinforcement learning (RL) model using a task-agnostic ethical layer. Following initial training, the RL model undergoes ethical fine-tuning, where human feedback is replaced by feedback generated from a large language model (LLM). The LLM embodies consequentialist, deontological, virtue, social justice, and care ethics as moral principles to assign belief values to recommended actions during ethical decision-making. An ethical layer aggregates belief scores from multiple LLM-derived moral perspectives using Belief Jensen-Shannon Divergence and Dempster-Shafer Theory into probability scores that also serve as the shaping reward, steering the agent toward choices that align with a balanced ethical framework. This integrated learning framework helps the RL agent navigate moral uncertainty in complex environments and enables it to make morally sound decisions across diverse tasks. Our approach, tested across different LLM variants and compared with other belief aggregation techniques, demonstrates improved consistency, adaptability, and reduced reliance on handcrafted ethical rewards. This method is especially effective in dynamic scenarios where ethical challenges arise unexpectedly, making it well-suited for real-world applications.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Alignment, Agency and Autonomy in Frontier AI: A Systems Engineering Perspective</title>
<link>https://arxiv.org/abs/2503.05748</link>
<guid>https://arxiv.org/abs/2503.05748</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、对齐、代理、自主性、安全性

总结:
本文关注的是随着人工智能规模扩大，对齐、代理和自主性这三个核心概念在AI安全、治理和控制中的重要性。文章指出这些概念在不同学科中缺乏统一定义，给AI系统设计与监管带来冲突。作者强调了AI对齐和自主性的紧迫性源自技术进步以及AI在高风险决策中的应用增加。以Agentic AI为例，探讨机器代理和自主性的涌现特性，并通过分析自动化失败案例（如特斯拉Autopilot、波音737 MAX）、多智能体协调（Meta's CICERO）及新型AI架构（DeepMind的AlphaZero、OpenAI的AutoGPT），揭示前沿AI带来的治理和安全挑战。 <div>
arXiv:2503.05748v1 Announce Type: new 
Abstract: As artificial intelligence scales, the concepts of alignment, agency, and autonomy have become central to AI safety, governance, and control. However, even in human contexts, these terms lack universal definitions, varying across disciplines such as philosophy, psychology, law, computer science, mathematics, and political science. This inconsistency complicates their application to AI, where differing interpretations lead to conflicting approaches in system design and regulation. This paper traces the historical, philosophical, and technical evolution of these concepts, emphasizing how their definitions influence AI development, deployment, and oversight.
  We argue that the urgency surrounding AI alignment and autonomy stems not only from technical advancements but also from the increasing deployment of AI in high-stakes decision making. Using Agentic AI as a case study, we examine the emergent properties of machine agency and autonomy, highlighting the risks of misalignment in real-world systems. Through an analysis of automation failures (Tesla Autopilot, Boeing 737 MAX), multi-agent coordination (Metas CICERO), and evolving AI architectures (DeepMinds AlphaZero, OpenAIs AutoGPT), we assess the governance and safety challenges posed by frontier AI.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Knowledge representation and scalable abstract reasoning for simulated democracy in Unity</title>
<link>https://arxiv.org/abs/2503.05783</link>
<guid>https://arxiv.org/abs/2503.05783</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2503.05783v1, 智能城市, 模拟民主, 可解释性, 双层知识表示

总结:

本文提出了一种关于模拟民主中的智能城市——e-polis——的新型可扩展知识表示形式。在这个游戏中，真实用户对与民主制度相关的社会挑战作出响应。系统采用“智能空间类型”，这是一种可根据访客哲学观念改变建筑形态的新式智能建筑。游戏结束时，玩家会对他们集体选择产生的智能城市进行投票。文章中，作者使用演绎系统以独特方式结合了民主模型和智能城市的模型，能够在不同城市和社会背景下证明模拟民主的质量方面，并为开发过程增添了便利性和灵活性。其次，该系统能够推断并处理Unity平台所限的抽象知识；第三，通过基于玩家抽象状态实现实时决策制定和游戏流程适应，为进一步的可解释性铺平道路。为了实现可扩展性，该系统采用了双层知识表示机制，类似于二级缓存，其中较低层次持续处理由Unity内置物理引擎生成的大量事件（例如玩家的空间位置x、y、z坐标及其针对每个挑战的选择），而较高层次则存储易于检索的、用户定义的关于当前和历史状态的抽象知识（例如智能空间类型的政治理论、玩家的哲学观点以及社区玩家针对当前社会问题的集体哲学观点）。 <div>
arXiv:2503.05783v1 Announce Type: new 
Abstract: We present a novel form of scalable knowledge representation about agents in a simulated democracy, e-polis, where real users respond to social challenges associated with democratic institutions, structured as Smart Spatial Types, a new type of Smart Building that changes architectural form according to the philosophical doctrine of a visitor. At the end of the game players vote on the Smart City that results from their collective choices. Our approach uses deductive systems in an unusual way: by integrating a model of democracy with a model of a Smart City we are able to prove quality aspects of the simulated democracy in different urban and social settings, while adding ease and flexibility to the development. Second, we can infer and reason with abstract knowledge, which is a limitation of the Unity platform; third, our system enables real-time decision-making and adaptation of the game flow based on the player's abstract state, paving the road to explainability. Scalability is achieved by maintaining a dual-layer knowledge representation mechanism for reasoning about the simulated democracy that functions in a similar way to a two-level cache. The lower layer knows about the current state of the game by continually processing a high rate of events produced by the in-built physics engine of the Unity platform, e.g., it knows of the position of a player in space, in terms of his coordinates x,y,z as well as their choices for each challenge. The higher layer knows of easily-retrievable, user-defined abstract knowledge about current and historical states, e.g., it knows of the political doctrine of a Smart Spatial Type, a player's philosophical doctrine, and the collective philosophical doctrine of a community players with respect to current social issues.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMentalCare: Towards Privacy-Preserving Fine-Tuned LLMs to Analyze Mental Health Status Using Federated Learning Framework</title>
<link>https://arxiv.org/abs/2503.05786</link>
<guid>https://arxiv.org/abs/2503.05786</guid>
<content:encoded><![CDATA[
<div> 关键词：AI聊天机器人、心理健康、隐私保护、联邦学习、低秩适应

总结:
本文提出了一种名为FedMentalCare的隐私保护框架，该框架利用联邦学习(FL)和低秩适应(LoRA)对大型语言模型(LLMs)进行微调，以应用于心理健康分析领域。鉴于全球精神健康问题日益严重，AI驱动的聊天机器人已成为支持心理健康的便捷工具，但部署此类模型在心理健康应用中会引发显著的隐私问题，尤其是关于HIPAA和GDPR等法规。FedMentalCare通过研究不同客户端数据量和模型架构（如MobileBERT和MiniLM）在FL环境下的性能影响，展示了在实际心理健康护理场景中，既能保证数据安全又能兼顾计算效率的可扩展性方案。 <div>
arXiv:2503.05786v1 Announce Type: new 
Abstract: With the increasing prevalence of mental health conditions worldwide, AI-powered chatbots and conversational agents have emerged as accessible tools to support mental health. However, deploying Large Language Models (LLMs) in mental healthcare applications raises significant privacy concerns, especially regarding regulations like HIPAA and GDPR. In this work, we propose FedMentalCare, a privacy-preserving framework that leverages Federated Learning (FL) combined with Low-Rank Adaptation (LoRA) to fine-tune LLMs for mental health analysis. We investigate the performance impact of varying client data volumes and model architectures (e.g., MobileBERT and MiniLM) in FL environments. Our framework demonstrates a scalable, privacy-aware approach for deploying LLMs in real-world mental healthcare scenarios, addressing data security and computational efficiency challenges.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-agent Auto-Bidding with Latent Graph Diffusion Models</title>
<link>https://arxiv.org/abs/2503.05805</link>
<guid>https://arxiv.org/abs/2503.05805</guid>
<content:encoded><![CDATA[
<div> 关键词：diffusion-based auto-bidding、graph representations、auction environments、latent diffusion model (LDM)、key performance indicator (KPI)

<br /><br />总结:
本文提出了一种基于扩散模型的自动竞价框架，该框架利用图表示来建模大规模拍卖环境。该框架结合了可学习的图嵌入和基于规划的潜在扩散模型（LDM），以应对不确定、稀疏和随机变量下的多智能体竞争环境中的动态优化竞价策略挑战。通过图表示，能够捕获印象机会之间的相互依赖性以及拍卖环境中的多智能体动态的模式和细微差别，从而对自动竞价结果进行更具有表现力的计算。通过奖励对齐技术，对LDM的后验分布进行微调，生成满足约束阈值的同时最大化KPI指标的自动竞价轨迹。实验证明，在真实世界和合成拍卖环境中，该方法在多个常见KPI指标上的自动竞价性能有显著提升，并在预测拍卖结果的准确性方面表现出色。 <div>
arXiv:2503.05805v1 Announce Type: new 
Abstract: This paper proposes a diffusion-based auto-bidding framework that leverages graph representations to model large-scale auction environments. In such settings, agents must dynamically optimize bidding strategies under constraints defined by key performance indicator (KPI) metrics, all while operating in competitive environments characterized by uncertain, sparse, and stochastic variables. To address these challenges, we introduce a novel approach combining learnable graph-based embeddings with a planning-based latent diffusion model (LDM). By capturing patterns and nuances underlying the interdependence of impression opportunities and the multi-agent dynamics of the auction environment, the graph representation enable expressive computations regarding auto-bidding outcomes. With reward alignment techniques, the LDM's posterior is fine-tuned to generate auto-bidding trajectories that maximize KPI metrics while satisfying constraint thresholds. Empirical evaluations on both real-world and synthetic auction environments demonstrate significant improvements in auto-bidding performance across multiple common KPI metrics, as well as accuracy in forecasting auction outcomes.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Market-based Architectures in RL and Beyond</title>
<link>https://arxiv.org/abs/2503.05828</link>
<guid>https://arxiv.org/abs/2503.05828</guid>
<content:encoded><![CDATA[
<div> 关键词：市场型智能体、强化学习、商品轴、并行性、神经网络、大型语言模型、搜索、动态扩展、完全反馈、应用创新

总结:<br />
本文介绍了新型市场型智能体算法，该算法将状态分解为多个称为“商品”的轴，从而实现比现有市场型RL算法更高级别的专业化和并行性。文章指出市场型算法有望解决AI领域的诸多挑战，如搜索、动态扩展和完全反馈，并证明此类算法可以视为神经网络的一种泛化形式。此外，文中还提出了市场算法与大型语言模型相结合的一些新颖实际应用方式。 <div>
arXiv:2503.05828v1 Announce Type: new 
Abstract: Market-based agents refer to reinforcement learning agents which determine their actions based on an internal market of sub-agents. We introduce a new type of market-based algorithm where the state itself is factored into several axes called ``goods'', which allows for greater specialization and parallelism than existing market-based RL algorithms. Furthermore, we argue that market-based algorithms have the potential to address many current challenges in AI, such as search, dynamic scaling and complete feedback, and demonstrate that they may be seen to generalize neural networks; finally, we list some novel ways that market algorithms may be applied in conjunction with Large Language Models for immediate practical applicability.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Refined Policy Distillation: From VLA Generalists to RL Experts</title>
<link>https://arxiv.org/abs/2503.05833</link>
<guid>https://arxiv.org/abs/2503.05833</guid>
<content:encoded><![CDATA[
<div> 关键词：Refined Policy Distillation (RPD)，Vision-Language-Action Models (VLAs)，RL-based policy refinement，ManiSkill2，仿真

总结:
近期的研究表明，通用型视觉-语言-动作模型(VLAs)虽然能在真实机器人上执行多种任务并展现出良好的泛化能力，但其成功率通常不如专家策略，且对环境变化敏感，需要微调。为此，本文提出了基于强化学习的精炼策略蒸馏方法(Refined Policy Distillation, RPD)，该方法能够将大型通用模型转化为小型、高性能的专家策略。在RL探索过程中，学生策略受到教师VLA的动作指导，从而提高样本效率和收敛速度。与以往关注于将VLAs应用于现实世界实验的工作不同，本文选择在ManiSkill2仿真环境中，对Octo和OpenVLA进行精细调整，并应用RPD进行评估。实验结果显示，在密集奖励和稀疏奖励设置下，RPD使RL代理能够学习到超越教师性能的专家策略，并且对于相机视角的变化以及原始VLA无法解决的任务变种具有一定的泛化能力。 <div>
arXiv:2503.05833v1 Announce Type: new 
Abstract: Recent generalist Vision-Language-Action Models (VLAs) can perform a variety of tasks on real robots with remarkable generalization capabilities. However, reported success rates are often not on par with those of expert policies. Moreover, VLAs usually do not work out of the box and often must be fine-tuned as they are sensitive to setup changes. In this work, we present Refined Policy Distillation (RPD), an RL-based policy refinement method that enables the distillation of large generalist models into small, high-performing expert policies. The student policy is guided during the RL exploration by actions of a teacher VLA for increased sample efficiency and faster convergence. Different from previous work that focuses on applying VLAs to real-world experiments, we create fine-tuned versions of Octo and OpenVLA for ManiSkill2 to evaluate RPD in simulation. As our results for different manipulation tasks demonstrate, RPD enables the RL agent to learn expert policies that surpass the teacher's performance in both dense and sparse reward settings. Our approach is even robust to changes in the camera perspective and can generalize to task variations that the underlying VLA cannot solve.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>This Is Your Doge, If It Please You: Exploring Deception and Robustness in Mixture of LLMs</title>
<link>https://arxiv.org/abs/2503.05856</link>
<guid>https://arxiv.org/abs/2503.05856</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习混合模型 (MoA), 大规模语言模型 (LLMs), 安全性评估, 欺骗性代理, 防御机制

总结:

本文首次对混合了大规模语言模型(MoA)架构的安全性和可靠性进行了全面研究，重点关注其对抗提供误导响应的欺骗性LLM代理的鲁棒性。研究发现，在AlpacaEval 2.0基准测试中，当使用包含六个LLM代理的三层MoA与LLaMA 3.1-70B模型结合时，长度控制胜率(LC WR)达到49.2%。然而，仅向MoA引入一个精心指导的欺骗性代理就可使性能降至37.9%，消除了所有MoA的优势。在QuALITY多选项理解任务上，影响同样严重，准确度骤降48.5%。受威尼斯总督投票过程启发，研究人员提出了一系列无监督防御机制，这些机制能够恢复大部分损失的性能。 <div>
arXiv:2503.05856v1 Announce Type: new 
Abstract: Mixture of large language model (LLMs) Agents (MoA) architectures achieve state-of-the-art performance on prominent benchmarks like AlpacaEval 2.0 by leveraging the collaboration of multiple LLMs at inference time. Despite these successes, an evaluation of the safety and reliability of MoA is missing. We present the first comprehensive study of MoA's robustness against deceptive LLM agents that deliberately provide misleading responses. We examine factors like the propagation of deceptive information, model size, and information availability, and uncover critical vulnerabilities. On AlpacaEval 2.0, the popular LLaMA 3.1-70B model achieves a length-controlled Win Rate (LC WR) of 49.2% when coupled with 3-layer MoA (6 LLM agents). However, we demonstrate that introducing only a $\textit{single}$ carefully-instructed deceptive agent into the MoA can reduce performance to 37.9%, effectively nullifying all MoA gains. On QuALITY, a multiple-choice comprehension task, the impact is also severe, with accuracy plummeting by a staggering 48.5%. Inspired in part by the historical Doge of Venice voting process, designed to minimize influence and deception, we propose a range of unsupervised defense mechanisms that recover most of the lost performance.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MatchMaker: Automated Asset Generation for Robotic Assembly</title>
<link>https://arxiv.org/abs/2503.05887</link>
<guid>https://arxiv.org/abs/2503.05887</guid>
<content:encoded><![CDATA[
<div> 关键词：Robotic assembly, Simulation-based learning, Sim-to-real transfer, Generative AI, MatchMaker

总结:
本文提出了一种名为MatchMaker的新方法，旨在解决机器人组装面临的挑战，如视觉感知、功能性抓取和高精度任务执行等。MatchMaker利用生成式AI技术自动生成多样化的、适用于模拟环境的组装资产对，从而促进机器人学习组装技能。该方法具有三大功能：1) 将原本不兼容或相互嵌套的资产对转化为适合模拟的、无相互穿透的资产对；2) 接受任意单个资产输入并生成与其几何形状相配合的另一资产，形成资产对；3) 根据用户指定的间隙参数自动侵蚀接触表面以创建真实的部件。实验表明，MatchMaker生成的数据在多样性与下游组装技能学习的有效性方面优于现有工作。更多详情及视频，请访问项目官网：https://wangyian-me.github.io/MatchMaker/。 <div>
arXiv:2503.05887v1 Announce Type: new 
Abstract: Robotic assembly remains a significant challenge due to complexities in visual perception, functional grasping, contact-rich manipulation, and performing high-precision tasks. Simulation-based learning and sim-to-real transfer have led to recent success in solving assembly tasks in the presence of object pose variation, perception noise, and control error; however, the development of a generalist (i.e., multi-task) agent for a broad range of assembly tasks has been limited by the need to manually curate assembly assets, which greatly constrains the number and diversity of assembly problems that can be used for policy learning. Inspired by recent success of using generative AI to scale up robot learning, we propose MatchMaker, a pipeline to automatically generate diverse, simulation-compatible assembly asset pairs to facilitate learning assembly skills. Specifically, MatchMaker can 1) take a simulation-incompatible, interpenetrating asset pair as input, and automatically convert it into a simulation-compatible, interpenetration-free pair, 2) take an arbitrary single asset as input, and generate a geometrically-mating asset to create an asset pair, 3) automatically erode contact surfaces from (1) or (2) according to a user-specified clearance parameter to generate realistic parts. We demonstrate that data generated by MatchMaker outperforms previous work in terms of diversity and effectiveness for downstream assembly skill learning. For videos and additional details, please see our project website: https://wangyian-me.github.io/MatchMaker/.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MastermindEval: A Simple But Scalable Reasoning Benchmark</title>
<link>https://arxiv.org/abs/2503.05891</link>
<guid>https://arxiv.org/abs/2503.05891</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 推理能力, 评估基准, MastermindEval, 推理挑战

总结:
随着大型语言模型（LLMs）在各种语言理解和数学任务中展现出卓越性能，对其推理能力的评估日益受到关注。为了跟上这类模型的发展步伐，研究者提出了一个新的、可扩展且可解释的推理基准——MastermindEval，它受到棋盘游戏Mastermind的启发。MastermindEval支持两种评价模式：自主游戏评价和演绎推理评价。实验结果显示，当前的模型在处理简单的Mastermind实例时仍存在困难，表明该基准对于未来更先进的模型也具有可扩展性。同时，研究发现现有模型在需要结合的信息陈述数量增加时，难以推导出隐藏的代码，揭示了其推理能力的局限性。 <div>
arXiv:2503.05891v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have led to remarkable performance across a wide range of language understanding and mathematical tasks. As a result, increasing attention has been given to assessing the true reasoning capabilities of LLMs, driving research into commonsense, numerical, logical, and qualitative reasoning. However, with the rapid progress of reasoning-focused models such as OpenAI's o1 and DeepSeek's R1, there has been a growing demand for reasoning benchmarks that can keep pace with ongoing model developments. In this paper, we introduce MastermindEval, a simple, scalable, and interpretable deductive reasoning benchmark inspired by the board game Mastermind. Our benchmark supports two evaluation paradigms: (1) agentic evaluation, in which the model autonomously plays the game, and (2) deductive reasoning evaluation, in which the model is given a pre-played game state with only one possible valid code to infer. In our experimental results we (1) find that even easy Mastermind instances are difficult for current models and (2) demonstrate that the benchmark is scalable to possibly more advanced models in the future Furthermore, we investigate possible reasons why models cannot deduce the final solution and find that current models are limited in deducing the concealed code as the number of statement to combine information from is increasing.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Performance Comparisons of Reinforcement Learning Algorithms for Sequential Experimental Design</title>
<link>https://arxiv.org/abs/2503.05905</link>
<guid>https://arxiv.org/abs/2503.05905</guid>
<content:encoded><![CDATA[
<div> 关键词: 顺序实验设计、信息增益、强化学习、算法比较、泛化性能

<br /><br />总结:
本文关注于序列实验设计中如何构建能够高效导航设计空间并最大化预期信息增益的策略。虽然已有针对实验设计问题实现可处理策略的工作，但对于获得具有良好泛化能力的策略（即在统计特性变化情况下仍能保持良好性能）的研究相对较少。文章探讨了使用强化学习方法来训练能够选择最具有信息性的实验设计的智能体，并分析了不同强化学习算法对生成这些智能体决策效率的影响。研究发现，所使用的训练算法会显著影响智能体的表现，并且采用dropout或集成方法的特定算法在实践中展示出了优秀的泛化特性。 <div>
arXiv:2503.05905v1 Announce Type: new 
Abstract: Recent developments in sequential experimental design look to construct a policy that can efficiently navigate the design space, in a way that maximises the expected information gain. Whilst there is work on achieving tractable policies for experimental design problems, there is significantly less work on obtaining policies that are able to generalise well - i.e. able to give good performance despite a change in the underlying statistical properties of the experiments. Conducting experiments sequentially has recently brought about the use of reinforcement learning, where an agent is trained to navigate the design space to select the most informative designs for experimentation. However, there is still a lack of understanding about the benefits and drawbacks of using certain reinforcement learning algorithms to train these agents. In our work, we investigate several reinforcement learning algorithms and their efficacy in producing agents that take maximally informative design decisions in sequential experimental design scenarios. We find that agent performance is impacted depending on the algorithm used for training, and that particular algorithms, using dropout or ensemble approaches, empirically showcase attractive generalisation properties.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ElementaryNet: A Non-Strategic Neural Network for Predicting Human Behavior in Normal-Form Games</title>
<link>https://arxiv.org/abs/2503.05925</link>
<guid>https://arxiv.org/abs/2503.05925</guid>
<content:encoded><![CDATA[
<div> 关键词: GameNet、ElementaryNet、战略行为、非战略行为、神经网络

总结:
本文针对游戏理论环境中人类行为建模的研究进行了探讨，主要贡献包括三个方面：1. 证明了当前预测人类在未重复同时行动游戏中表现最佳的GameNet模型，其学习到的“水平-0”行为规范实际上具有战略推理能力。2. 提出了一种新的神经网络架构——ElementaryNet，并证明它只能进行非战略行为推理。3. 对ElementaryNet进行了大规模实验评估，发现(1)当两种模型都不被允许显式地模拟对模型预测做出最优响应的更高层次代理时，ElementaryNet的表现远逊于GameNet，这表明在该数据集上取得良好性能需要能进行战略推理的模型；(2)然而，当引入这种高层次代理后，两个模型的表现达到了统计学上的等效性，意味着将ElementaryNet限制为非战略性“水平-0”规范并不会降低模型性能；(3)即使进一步限制ElementaryNet使用先前文献中介绍的一组“水平-0”构建模块，仅让神经网络学习函数形式，这一结论仍然成立。 <div>
arXiv:2503.05925v1 Announce Type: new 
Abstract: Models of human behavior in game-theoretic settings often distinguish between strategic behavior, in which a player both reasons about how others will act and best responds to these beliefs, and "level-0" non-strategic behavior, in which they do not respond to explicit beliefs about others. The state of the art for predicting human behavior on unrepeated simultaneous-move games is GameNet, a neural network that learns extremely complex level-0 specifications from data. The current paper makes three contributions. First, it shows that GameNet's level-0 specifications are too powerful, because they are capable of strategic reasoning. Second, it introduces a novel neural network architecture (dubbed ElementaryNet) and proves that it is only capable of nonstrategic behavior. Third, it describes an extensive experimental evaluation of ElementaryNet. Our overall findings are that (1) ElementaryNet dramatically underperforms GameNet when neither model is allowed to explicitly model higher level agents who best-respond to the model's predictions, indicating that good performance on our dataset requires a model capable of strategic reasoning; (2) that the two models achieve statistically indistinguishable performance when such higher-level agents are introduced, meaning that ElementaryNet's restriction to a non-strategic level-0 specification does not degrade model performance; and (3) that this continues to hold even when ElementaryNet is restricted to a set of level-0 building blocks previously introduced in the literature, with only the functional form being learned by the neural network.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Enhancing Reasoning with Collaboration and Memory</title>
<link>https://arxiv.org/abs/2503.05944</link>
<guid>https://arxiv.org/abs/2503.05944</guid>
<content:encoded><![CDATA[
<div> 关键词：持续协同学习系统、LLM代理、记忆银行、多智能体协作、链式思考推理风格

总结:<br />
本文探讨了一个连续协同学习系统的构想，该系统中，具有不同链式思考推理风格的LLM（Large Language Model）代理将共同解决推理问题，并依赖于他们集体构建的记忆库来提升性能。研究扩展了自我一致性场景，引入了具备多样上下文的变体代理和一个摘要生成器代理以替代投票机制。此外，文章还研究了冻结与持续学习的记忆库示例以及固定、随机和基于相似度的检索机制。系统性研究表明，随机示例选择在某些情况下可能优于更为原则性的方法，并发现在一些任务中，对弱模型和强模型来说，引入任何示例都可能导致表现下降。 <div>
arXiv:2503.05944v1 Announce Type: new 
Abstract: We envision a continuous collaborative learning system where groups of LLM agents work together to solve reasoning problems, drawing on memory they collectively build to improve performance as they gain experience. This work establishes the foundations for such a system by studying the interoperability of chain-of-thought reasoning styles, multi-agent collaboration, and memory banks. Extending beyond the identical agents of self-consistency, we introduce varied-context agents with diverse exemplars and a summarizer agent in place of voting. We generate frozen and continuously learned memory banks of exemplars and pair them with fixed, random, and similarity-based retrieval mechanisms. Our systematic study reveals where various methods contribute to reasoning performance of two LLMs on three grounded reasoning tasks, showing that random exemplar selection can often beat more principled approaches, and in some tasks, inclusion of any exemplars serves only to distract both weak and strong models.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Multi-Agent Q-Learning for Policy Optimization: Decentralized Wireless Networks</title>
<link>https://arxiv.org/abs/2503.05970</link>
<guid>https://arxiv.org/abs/2503.05970</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-learning，无线网络，多环境混合Q学习（MEMQ），多智能体MEMQ（M-MEMQ），协同与非协同状态

总结:
本文提出了一种用于合作分散式无线网络的新型多智能体MEMQ（M-MEMQ）算法。该算法针对具有多个网络发射器(TXs)和基站(_BSs)_的情况，解决了Q-learning在处理大型状态空间上的挑战。M-MEMQ引入了协调状态和非协调状态的概念，在非协调状态下，TXs独立行动并更新局部Q函数；而在协调状态下，TXs使用贝叶斯方法估计联合状态并更新联合Q函数。信息共享的成本线性地随TXs数量增加而增加，但与联合状态-动作空间大小无关。文章给出了关于确定性和概率收敛性、估计误差方差上界以及联合状态误检测概率等理论保证。数值模拟表明，M-MEMQ相比于其他分散式训练与集中式执行（CTDE）的多智能体RL算法，在平均策略错误(APE)降低55%、收敛速度提升35%、运行时间复杂度减少50%以及样本复杂度降低45%方面表现优越。此外，M-MEMQ以显著较低的复杂度实现了与中心化方法相当的APE。模拟结果验证了理论分析。 <div>
arXiv:2503.05970v1 Announce Type: new 
Abstract: Q-learning is a widely used reinforcement learning (RL) algorithm for optimizing wireless networks, but faces challenges with large state-spaces. Recently proposed multi-environment mixed Q-learning (MEMQ) algorithm addresses these challenges by employing multiple Q-learning algorithms across multiple synthetically generated, distinct but structurally related environments, so-called digital cousins. In this paper, we propose a novel multi-agent MEMQ (M-MEMQ) for cooperative decentralized wireless networks with multiple networked transmitters (TXs) and base stations (BSs). TXs do not have access to global information (joint state and actions). The new concept of coordinated and uncoordinated states is introduced. In uncoordinated states, TXs act independently to minimize their individual costs and update local Q-functions. In coordinated states, TXs use a Bayesian approach to estimate the joint state and update the joint Q-functions. The cost of information-sharing scales linearly with the number of TXs and is independent of the joint state-action space size. Several theoretical guarantees, including deterministic and probabilistic convergence, bounds on estimation error variance, and the probability of misdetecting the joint states, are given. Numerical simulations show that M-MEMQ outperforms several decentralized and centralized training with decentralized execution (CTDE) multi-agent RL algorithms by achieving 55% lower average policy error (APE), 35% faster convergence, 50% reduced runtime complexity, and 45% less sample complexity. Furthermore, M-MEMQ achieves comparable APE with significantly lower complexity than centralized methods. Simulations validate the theoretical analyses.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Optimal sensor deception in stochastic environments with partial observability to mislead a robot to a decoy goal</title>
<link>https://arxiv.org/abs/2503.05972</link>
<guid>https://arxiv.org/abs/2503.05972</guid>
<content:encoded><![CDATA[
<div> 关键词：欺骗策略、自动驾驶系统、传感器事件、部分可观测马尔科夫决策过程（POMDP）、有限状态控制器（FSC）

<br /><br />总结：
本文提出了一种针对自动驾驶系统的新型欺骗问题，旨在通过在预算约束下修改传感器事件来误导机器人走向诱饵目标。文章将环境和机器人的交互建模为部分可观测马尔科夫决策过程（POMDP），机器人的行为选择由有限状态控制器（FSC）控制。在给定传感器事件修改的约束预算下，研究的目标是最优地计算出能够最大化机器人达到诱饵目标概率的传感器改动方案。文中证明了该问题的计算复杂性，并提出了混合整数线性规划（MILP）模型以求解最优欺骗策略。实验结果验证了所提MILP方法的有效性。 <div>
arXiv:2503.05972v1 Announce Type: new 
Abstract: Deception is a common strategy adapted by autonomous systems in adversarial settings. Existing deception methods primarily focus on increasing opacity or misdirecting agents away from their goal or itinerary. In this work, we propose a deception problem aiming to mislead the robot towards a decoy goal through altering sensor events under a constrained budget of alteration. The environment along with the robot's interaction with it is modeled as a Partially Observable Markov Decision Process (POMDP), and the robot's action selection is governed by a Finite State Controller (FSC). Given a constrained budget for sensor event modifications, the objective is to compute a sensor alteration that maximizes the probability of the robot reaching a decoy goal. We establish the computational hardness of the problem by a reduction from the $0/1$ Knapsack problem and propose a Mixed Integer Linear Programming (MILP) formulation to compute optimal deception strategies. We show the efficacy of our MILP formulation via a sequence of experiments.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Improving Reward Design in RL: A Reward Alignment Metric for RL Practitioners</title>
<link>https://arxiv.org/abs/2503.05996</link>
<guid>https://arxiv.org/abs/2503.05996</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 奖励函数, 行径对齐系数, 人类利益相关者, 在线RL

总结:<br />
本文针对强化学习中奖励设计的困难和评估其正确性的挑战，提出了一个新的概念——奖励对齐，旨在评估奖励函数是否准确地表达了人类利益相关者的偏好。为量化这种对齐程度，作者引入了“行径对齐系数”，该系数可以衡量利益相关者对轨迹分布的排序与奖励函数诱导产生的排序之间的相似性。文章表明，行径对齐系数具有无需访问真实奖励、不受潜在型奖励塑造影响以及适用于在线RL等优点。通过一项涉及11位RL实践者的用户研究，发现使用行径对齐系数进行奖励选择能带来显著改善：相比仅依赖奖励函数，它降低了1.5倍的认知工作负载，得到了82%用户的偏爱，并将选择出能够产生高性能策略的奖励函数的成功率提高了41%。 <div>
arXiv:2503.05996v1 Announce Type: new 
Abstract: Reinforcement learning agents are fundamentally limited by the quality of the reward functions they learn from, yet reward design is often overlooked under the assumption that a well-defined reward is readily available. However, in practice, designing rewards is difficult, and even when specified, evaluating their correctness is equally problematic: how do we know if a reward function is correctly specified? In our work, we address these challenges by focusing on reward alignment -- assessing whether a reward function accurately encodes the preferences of a human stakeholder. As a concrete measure of reward alignment, we introduce the Trajectory Alignment Coefficient to quantify the similarity between a human stakeholder's ranking of trajectory distributions and those induced by a given reward function. We show that the Trajectory Alignment Coefficient exhibits desirable properties, such as not requiring access to a ground truth reward, invariance to potential-based reward shaping, and applicability to online RL. Additionally, in an 11 -- person user study of RL practitioners, we found that access to the Trajectory Alignment Coefficient during reward selection led to statistically significant improvements. Compared to relying only on reward functions, our metric reduced cognitive workload by 1.5x, was preferred by 82% of users and increased the success rate of selecting reward functions that produced performant policies by 41%.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Welfare Approximation in Additively Separable Hedonic Games</title>
<link>https://arxiv.org/abs/2503.06017</link>
<guid>https://arxiv.org/abs/2503.06017</guid>
<content:encoded><![CDATA[
<div> 关键词：最大化社会福利、加性可分解hedonic游戏、NP难度、随机化算法、图模型

总结:
本文研究了在加性可分解hedonic游戏中最大化社会福利的问题，该问题在计算上面临强约束，证明了对于极度受限权重的情况下，达到$n^{1-\epsilon}$的近似比是NP难的。然而，当输入估值之和非负时，可以得到一个随机化的$\log n$-近似解。接着，文章探讨了两种基于Erd\H{o}s-R\'{e}nyi图或multipartite图的aversion-to-enemies游戏的随机模型，并在这种情况下提出了高概率下的常数因子和对数因子近似算法。<br /><br /> <div>
arXiv:2503.06017v1 Announce Type: new 
Abstract: Partitioning a set of $n$ items or agents while maximizing the value of the partition is a fundamental algorithmic task. We study this problem in the specific setting of maximizing social welfare in additively separable hedonic games. Unfortunately, this task faces strong computational boundaries: Extending previous results, we show that approximating welfare by a factor of $n^{1-\epsilon}$ is NP-hard, even for severely restricted weights. However, we can obtain a randomized $\log n$-approximation on instances for which the sum of input valuations is nonnegative. Finally, we study two stochastic models of aversion-to-enemies games, where the weights are derived from Erd\H{o}s-R\'{e}nyi or multipartite graphs. We obtain constant-factor and logarithmic-factor approximations with high probability.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Vairiational Stochastic Games</title>
<link>https://arxiv.org/abs/2503.06037</link>
<guid>https://arxiv.org/abs/2503.06037</guid>
<content:encoded><![CDATA[
<div> 关键词：Control as Inference (CAI)，多智能体，强化学习，马尔可夫游戏，变分推断

总结:
本文提出了一种针对去中心化多智能体系统的新型变分推断框架，该框架扩展了单智能体强化学习中的控制作为推理（CAI）思想到多智能体、一般和随机博弈场景。针对非平稳性和不一致的智能体目标问题，文章证明由此产生的策略构成$\epsilon$-纳什均衡。此外，文中还为所提出的分布式算法提供了理论上的收敛性保证。基于这一框架，作者实例化了多种解决纳什均衡、均值场纳什均衡和相关均衡问题的算法，并对其进行了严格的理论收敛性分析。 <div>
arXiv:2503.06037v1 Announce Type: new 
Abstract: The Control as Inference (CAI) framework has successfully transformed single-agent reinforcement learning (RL) by reframing control tasks as probabilistic inference problems. However, the extension of CAI to multi-agent, general-sum stochastic games (SGs) remains underexplored, particularly in decentralized settings where agents operate independently without centralized coordination. In this paper, we propose a novel variational inference framework tailored to decentralized multi-agent systems. Our framework addresses the challenges posed by non-stationarity and unaligned agent objectives, proving that the resulting policies form an $\epsilon$-Nash equilibrium. Additionally, we demonstrate theoretical convergence guarantees for the proposed decentralized algorithms. Leveraging this framework, we instantiate multiple algorithms to solve for Nash equilibrium, mean-field Nash equilibrium, and correlated equilibrium, with rigorous theoretical convergence analysis.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DSGBench: A Diverse Strategic Game Benchmark for Evaluating LLM-based Agents in Complex Decision-Making Environments</title>
<link>https://arxiv.org/abs/2503.06047</link>
<guid>https://arxiv.org/abs/2503.06047</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)，benchmark，DSGBench，strategic decision-making，evaluation scoring system

<br /><br />总结:
本文提出了一个新的评价平台DSGBench，用于更严谨地评估基于大型语言模型（LLM）的智能代理在复杂决策任务中的能力。DSGBench包含了六个具有长期和多维度决策需求的复杂战略游戏，可灵活定制不同难度和多目标的任务。其次，DSGBench采用了一个细粒度的评估评分系统，从五个具体维度深入考察决策能力，并以一种精心设计的方式提供全面评估。此外，DSGBench还具有一套自动决策跟踪机制，可以深入了解智能代理的行为模式及其策略变化。通过将DSGBench应用于多个流行的LLM基础智能代理并展示其结果，文章表明DSGBench对于选择和改进LLM基础智能代理的发展提供了有价值的见解。DSGBench已公开发布在https://github.com/DeciBrain-Group/DSGBench上。 <div>
arXiv:2503.06047v1 Announce Type: new 
Abstract: Large Language Model~(LLM) based agents have been increasingly popular in solving complex and dynamic tasks, which requires proper evaluation systems to assess their capabilities. Nevertheless, existing benchmarks usually either focus on single-objective tasks or use overly broad assessing metrics, failing to provide a comprehensive inspection of the actual capabilities of LLM-based agents in complicated decision-making tasks. To address these issues, we introduce DSGBench, a more rigorous evaluation platform for strategic decision-making. Firstly, it incorporates six complex strategic games which serve as ideal testbeds due to their long-term and multi-dimensional decision-making demands and flexibility in customizing tasks of various difficulty levels or multiple targets. Secondly, DSGBench employs a fine-grained evaluation scoring system which examines the decision-making capabilities by looking into the performance in five specific dimensions and offering a comprehensive assessment in a well-designed way. Furthermore, DSGBench also incorporates an automated decision-tracking mechanism which enables in-depth analysis of agent behaviour patterns and the changes in their strategies. We demonstrate the advances of DSGBench by applying it to multiple popular LLM-based agents and our results suggest that DSGBench provides valuable insights in choosing LLM-based agents as well as improving their future development. DSGBench is available at https://github.com/DeciBrain-Group/DSGBench.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Conversational AI for Disease Management</title>
<link>https://arxiv.org/abs/2503.06074</link>
<guid>https://arxiv.org/abs/2503.06074</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、临床管理、疾病演化、药物处方、RxQA

总结:
本文介绍了Articulate Medical Intelligence Explorer（AMIE）的一个新进展，通过集成基于大型语言模型的代理系统，强化了其在临床管理和对话中的能力，特别是在疾病进程、治疗反应和安全用药方面的推理。AMIE利用Gemini的长程上下文功能，结合情境检索与结构化推理，使其输出与权威临床实践指南和药物目录保持一致。在一项随机盲试的虚拟Objective Structured Clinical Examination (OSCE)研究中，AMIE与21位全科医生对比，结果显示在多访视案例场景下的管理推理方面，AMIE并不逊色于医生，并在治疗和检查精确度以及依据临床指南制定管理计划方面得分更高。为了评估药物推理能力，研究团队还开发了RxQA，这是一个源自美英两国国家药物目录的多项选择题基准，并得到了药学专家的验证。结果表明，尽管AMIE和医生都能访问外部药物信息，但AMIE在高难度问题上表现优于医生。虽然在实际应用前还需要进一步研究，但AMIE在各项评估中的出色表现标志着面向疾病管理的会话AI工具的发展迈出了重要一步。 <div>
arXiv:2503.06074v1 Announce Type: new 
Abstract: While large language models (LLMs) have shown promise in diagnostic dialogue, their capabilities for effective management reasoning - including disease progression, therapeutic response, and safe medication prescription - remain under-explored. We advance the previously demonstrated diagnostic capabilities of the Articulate Medical Intelligence Explorer (AMIE) through a new LLM-based agentic system optimised for clinical management and dialogue, incorporating reasoning over the evolution of disease and multiple patient visit encounters, response to therapy, and professional competence in medication prescription. To ground its reasoning in authoritative clinical knowledge, AMIE leverages Gemini's long-context capabilities, combining in-context retrieval with structured reasoning to align its output with relevant and up-to-date clinical practice guidelines and drug formularies. In a randomized, blinded virtual Objective Structured Clinical Examination (OSCE) study, AMIE was compared to 21 primary care physicians (PCPs) across 100 multi-visit case scenarios designed to reflect UK NICE Guidance and BMJ Best Practice guidelines. AMIE was non-inferior to PCPs in management reasoning as assessed by specialist physicians and scored better in both preciseness of treatments and investigations, and in its alignment with and grounding of management plans in clinical guidelines. To benchmark medication reasoning, we developed RxQA, a multiple-choice question benchmark derived from two national drug formularies (US, UK) and validated by board-certified pharmacists. While AMIE and PCPs both benefited from the ability to access external drug information, AMIE outperformed PCPs on higher difficulty questions. While further research would be needed before real-world translation, AMIE's strong performance across evaluations marks a significant step towards conversational AI as a tool in disease management.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Momentum-based Distributed Resource Scheduling Optimization Subject to Sector-Bound Nonlinearity and Latency</title>
<link>https://arxiv.org/abs/2503.06167</link>
<guid>https://arxiv.org/abs/2503.06167</guid>
<content:encoded><![CDATA[
<div> 关键词：加速共识分布式迭代算法、资源分配、调度、梯度跟踪、非线性链接

总结:
本文提出了一种应用于资源分配和调度的加速共识型分布式迭代算法。该算法采用梯度跟踪技术，通过引入辅助变量实现向最优状态的加速收敛，并确保解决方案始终满足可行性，意味着耦合约束在整个迭代过程中始终保持成立，与ADMM基解决方案的渐进可行性不同。此外，该算法还能处理由于对数量化数据传输（或任何保持符号的奇数扇区非线性映射）导致的可能链接非线性问题。文章证明了该算法在均匀连接的动态网络（即混合环境）中也能保证收敛，这类网络常见于移动和时间变化的多智能体网络。同时，为解决网络延迟问题，文中还提出了延迟容忍的解决方案。据作者所知，文献中尚未同时涵盖加速动量收敛、非线性链接、始终可行性、统一网络连通性和处理潜在时间延迟等方面的解决方案，这使得本研究提出的方案在许多现实世界应用中更具实用性。<br /><br /> <div>
arXiv:2503.06167v1 Announce Type: new 
Abstract: This paper proposes an accelerated consensus-based distributed iterative algorithm for resource allocation and scheduling. The proposed gradient-tracking algorithm introduces an auxiliary variable to add momentum towards the optimal state. We prove that this solution is all-time feasible, implying that the coupling constraint always holds along the algorithm iterative procedure; therefore, the algorithm can be terminated at any time. This is in contrast to the ADMM-based solutions that meet constraint feasibility asymptotically. Further, we show that the proposed algorithm can handle possible link nonlinearity due to logarithmically-quantized data transmission (or any sign-preserving odd sector-bound nonlinear mapping). We prove convergence over uniformly-connected dynamic networks (i.e., a hybrid setup) that may occur in mobile and time-varying multi-agent networks. Further, the latency issue over the network is addressed by proposing delay-tolerant solutions. To our best knowledge, accelerated momentum-based convergence, nonlinear linking, all-time feasibility, uniform network connectivity, and handling (possible) time delays are not altogether addressed in the literature. These contributions make our solution practical in many real-world applications.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Object-Centric World Model for Language-Guided Manipulation</title>
<link>https://arxiv.org/abs/2503.06170</link>
<guid>https://arxiv.org/abs/2503.06170</guid>
<content:encoded><![CDATA[
<div> 关键词：世界模型、对象中心表示、语言指令、扩散模型、计算效率

总结:<br />
本文提出了一种基于槽位注意力的对象中心表示的世界模型，该模型通过自然语言指令引导，能够在更紧凑和计算效率更高的表示空间中预测未来状态。与依赖于大量计算资源的扩散模型相比，这种方法具有优势。此外，它还能灵活地根据语言指令预测未来状态，在重视物体识别的操纵任务中展现出显著的优势。实验表明，所提出的潜变量预测世界模型在视觉-语言-运动控制任务上超越了生成式世界模型，表现出更好的样本和计算效率，并对其泛化性能进行了研究，还探讨了利用对象中心表示预测动作的各种策略。 <div>
arXiv:2503.06170v1 Announce Type: new 
Abstract: A world model is essential for an agent to predict the future and plan in domains such as autonomous driving and robotics. To achieve this, recent advancements have focused on video generation, which has gained significant attention due to the impressive success of diffusion models. However, these models require substantial computational resources. To address these challenges, we propose a world model leveraging object-centric representation space using slot attention, guided by language instructions. Our model perceives the current state as an object-centric representation and predicts future states in this representation space conditioned on natural language instructions. This approach results in a more compact and computationally efficient model compared to diffusion-based generative alternatives. Furthermore, it flexibly predicts future states based on language instructions, and offers a significant advantage in manipulation tasks where object recognition is crucial. In this paper, we demonstrate that our latent predictive world model surpasses generative world models in visuo-linguo-motor control tasks, achieving superior sample and computation efficiency. We also investigate the generalization performance of the proposed method and explore various strategies for predicting actions using object-centric representations.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Higher-Order Belief in Incomplete Information MAIDs</title>
<link>https://arxiv.org/abs/2503.06323</link>
<guid>https://arxiv.org/abs/2503.06323</guid>
<content:encoded><![CDATA[
<div> 关键词: multi-agent influence diagrams (MAIDs), incomplete information, II-MAIDs, extensive form games (EFGs), recursive best-response

总结:
本文介绍了多智能体影响图（MAIDs）的概念，这是一种表示多个智能体之间战略互动的概率图形模型。尽管MAIDs通常比扩展形式游戏（EFGs）具有更紧凑和信息丰富的结构，但它们无法普遍表示不完全信息环境，即智能体对正在玩的游戏以及彼此的信念有不同的认知。为此，文章提出了不完全信息MAIDs（II-MAIDs），定义了无限深度和有限深度两种类型，并证明了它们与无共同先验类型的不完全信息EFG等价。文章还表明II-MAIDs通过这种等价性继承了经典均衡概念，但由于没有共同先验，这些解决方案往往不符合理性知识的常识。因此，文章定义了一种更为现实的基于递归最佳响应的解决方案概念。文中通过一个假设的人工智能评估示例来说明II-MAIDs的应用可行性。 <div>
arXiv:2503.06323v1 Announce Type: new 
Abstract: Multi-agent influence diagrams (MAIDs) are probabilistic graphical models which represent strategic interactions between agents. MAIDs are equivalent to extensive form games (EFGs) but have a more compact and informative structure. However, MAIDs cannot, in general, represent settings of incomplete information -- wherein agents have different beliefs about the game being played, and different beliefs about each-other's beliefs. In this paper, we introduce incomplete information MAIDs (II-MAIDs). We define both infinite and finite-depth II-MAIDs and prove an equivalence relation to EFGs with incomplete information and no common prior over types. We prove that II-MAIDs inherit classical equilibria concepts via this equivalence, but note that these solution concepts are often unrealistic in the setting with no common prior because they violate common knowledge of rationality. We define a more realistic solution concept based on recursive best-response. Throughout, we describe an example with a hypothetical AI agent undergoing evaluation to illustrate the applicability of II-MAIDs.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AnimeGaze: Real-Time Mutual Gaze Synthesis for Anime-Style Avatars in Physical Environments via Behind-Display Camera</title>
<link>https://arxiv.org/abs/2503.06324</link>
<guid>https://arxiv.org/abs/2503.06324</guid>
<content:encoded><![CDATA[
<div> 关键词：avatar、gaze synthesis、camera-behind-the-display、mutual gaze communication、AI agent

总结:<br />
本文提出了一种使显示设备上的虚拟化身能够通过视线与物理环境互动的注视合成方法。该系统采用了一个可快速切换透明与非透明状态的显示屏，屏幕后方设置摄像头捕捉实际环境。这种配置使化身的眼睛位置与摄像头对齐，实现了与现实环境中人和物体的双向视线交流。研究团队进而开发了一个支持双方视线交流的框架，能检测用户的视线并动态地让虚拟化身将视线转向环境中的人或物。此功能已集成到AI代理系统中，使得在对话过程中可以生成符合语境的实时视线行为，从而使交互更加自然流畅。为了评估该系统的有效性，研究人员进行了一项用户研究，结果显示这种屏后方案显著提升了用户感受到被化身观察和关注的感觉。通过增强虚拟化身与物理环境之间的视线交互，该系统为日常生活中的沉浸式、类人的AI中介通信提供了一条有前景的研究途径。 <div>
arXiv:2503.06324v1 Announce Type: new 
Abstract: Avatars on displays lack the ability to engage with the physical environment through gaze. To address this limitation, we propose a gaze synthesis method that enables animated avatars to establish gaze communication with the physical environment using a camera-behind-the-display system. The system uses a display that rapidly alternates between visible and transparent states. During the transparent state, a camera positioned behind the display captures the physical environment. This configuration physically aligns the position of the avatar's eyes with the camera, enabling two-way gaze communication with people and objects in the physical environment. Building on this system, we developed a framework for mutual gaze communication between avatars and people. The framework detects the user's gaze and dynamically synthesizes the avatar's gaze towards people or objects in the environment. This capability was integrated into an AI agent system to generate real-time, context-aware gaze behaviors during conversations, enabling more seamless and natural interactions. To evaluate the system, we conducted a user study to assess its effectiveness in supporting physical gaze awareness and generating human-like gaze behaviors. The results show that the behind-display approach significantly enhances the user's perception of being observed and attended to by the avatar. By bridging the gap between virtual avatars and the physical environment through enhanced gaze interactions, our system offers a promising avenue for more immersive and human-like AI-mediated communication in everyday environments.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Studying the Interplay Between the Actor and Critic Representations in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.06343</link>
<guid>https://arxiv.org/abs/2503.06343</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习、演员-评论家算法、表示学习、行为相关信息、价值动态信息

总结:
本文探讨了深度强化学习中从高维度观察流中提取相关信息的核心挑战，特别是对于演员-评论家算法下，如何构建对演员和评论家都有效的表示。研究集中在确定演员和评论家是否应采用独立而非共享的表示上。结果表明，当分开构建表示时，演员和评论家的表示会系统地专注于不同类型的信息：演员的表示更关注与行动相关的信息，而评论家的表示则专门编码价值和动态信息。文章进行了严格的实证研究，分析不同表示学习方法如何影响演员和评论家的特化及其下游性能（包括样本效率和生成能力）。最后，发现分离的评论家在网络训练过程中的探索和数据收集方面起着重要作用。相关的代码、训练模型和数据可在https://github.com/francelico/deac-rep 访问。 <div>
arXiv:2503.06343v1 Announce Type: new 
Abstract: Extracting relevant information from a stream of high-dimensional observations is a central challenge for deep reinforcement learning agents. Actor-critic algorithms add further complexity to this challenge, as it is often unclear whether the same information will be relevant to both the actor and the critic. To this end, we here explore the principles that underlie effective representations for the actor and for the critic in on-policy algorithms. We focus our study on understanding whether the actor and critic will benefit from separate, rather than shared, representations. Our primary finding is that when separated, the representations for the actor and critic systematically specialise in extracting different types of information from the environment -- the actor's representation tends to focus on action-relevant information, while the critic's representation specialises in encoding value and dynamics information. We conduct a rigourous empirical study to understand how different representation learning approaches affect the actor and critic's specialisations and their downstream performance, in terms of sample efficiency and generation capabilities. Finally, we discover that a separated critic plays an important role in exploration and data collection during training. Our code, trained models and data are accessible at https://github.com/francelico/deac-rep.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Load Balancing for EV Charging Stations Using Reinforcement Learning and Demand Prediction</title>
<link>https://arxiv.org/abs/2503.06370</link>
<guid>https://arxiv.org/abs/2503.06370</guid>
<content:encoded><![CDATA[
<div> 关键词：电动车充电网络、强化学习、图神经网络、需求预测、动态定价

<br /><br />总结：
本文提出了一种利用强化学习进行电动车充电网络的负载均衡与动态定价的方法。该框架结合了预训练的图神经网络，用于预测需求弹性并指导定价决策。通过使用深圳的时空电动车充电需求预测数据集来捕捉充电站的地理和时间特性，RL模型能够根据站点占用率、最大站容量以及需求预测，动态调整各站点的价格，确保网络负载分布均衡并防止站点过载。通过运用具有空间感知的需求预测及精心设计的奖励函数，该框架实现了有效的负载均衡和适应性定价策略，对局部需求和全局网络动态做出响应，从而提高网络稳定性和用户满意度。模拟实验验证了该方法的有效性，显示出了在实际运行中，随着RL代理与环境的交互和动态定价策略的学习调整，显著改善了负载均衡并减少了过载情况的发生。这项研究突显了采用自适应定价和负载均衡策略解决电动车基础设施复杂性的潜力，为实现可扩展和以用户为中心的解决方案铺平道路。 <div>
arXiv:2503.06370v1 Announce Type: new 
Abstract: This paper presents a method for load balancing and dynamic pricing in electric vehicle (EV) charging networks, utilizing reinforcement learning (RL) to enhance network performance. The proposed framework integrates a pre-trained graph neural network to predict demand elasticity and inform pricing decisions. The spatio-temporal EV charging demand prediction (EVCDP) dataset from Shenzhen is utilized to capture the geographic and temporal characteristics of the charging stations. The RL model dynamically adjusts prices at individual stations based on occupancy, maximum station capacity, and demand forecasts, ensuring an equitable network load distribution while preventing station overloads. By leveraging spatially-aware demand predictions and a carefully designed reward function, the framework achieves efficient load balancing and adaptive pricing strategies that respond to localized demand and global network dynamics, ensuring improved network stability and user satisfaction. The efficacy of the approach is validated through simulations on the dataset, showing significant improvements in load balancing and reduced overload as the RL agent iteratively interacts with the environment and learns to dynamically adjust pricing strategies based on real-time demand patterns and station constraints. The findings highlight the potential of adaptive pricing and load-balancing strategies to address the complexities of EV infrastructure, paving the way for scalable and user-centric solutions.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing AI Negotiations: New Theory and Evidence from a Large-Scale Autonomous Negotiations Competition</title>
<link>https://arxiv.org/abs/2503.06416</link>
<guid>https://arxiv.org/abs/2503.06416</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能, 谈判理论, 大规模语言模型, 协商比赛, 独特动态

<br /><br />总结:
该文指出了人工智能谈判代理领域中现有研究与传统谈判理论整合的不足，并举办了一场国际人工智能协商比赛，通过参赛者对大型语言模型的谈判代理进行迭代设计和优化。经过大量AI-AI之间的谈判实验，文章发现传统的谈判理论原则如展现热情、关系建立、果断性和准备对于AI谈判仍然至关重要。热情的代理能提高对手的价值感知并更频繁达成协议，从而在整合性场景中创造和获取更多价值。然而，在达成协议的前提下，热情的代理所获取的价值较少，而强势的代理则能获得更多。此外，研究还揭示了AI谈判中的独特动态，特别是关于思维链推理和提示注入等AI特性策略的有效性。最终赢得比赛的代理采用了融合传统谈判准备框架和AI特性方法的策略。因此，文章强调需要构建一个新的AI谈判理论，将传统谈判理论与AI特有的策略相结合，以优化代理的表现，并考虑自动代理的独特性质以及确定何时在自动化环境中应用传统谈判理论的条件。 <div>
arXiv:2503.06416v1 Announce Type: new 
Abstract: Despite the rapid proliferation of artificial intelligence (AI) negotiation agents, there has been limited integration of computer science research and established negotiation theory to develop new theories of AI negotiation. To bridge this gap, we conducted an International AI Negotiations Competition in which participants iteratively designed and refined prompts for large language model (LLM) negotiation agents. We then facilitated over 120,000 negotiations between these agents across multiple scenarios with diverse characteristics and objectives. Our findings revealed that fundamental principles from established human-human negotiation theory remain crucial in AI-AI negotiations. Specifically, agents exhibiting high warmth fostered higher counterpart subjective value and reached deals more frequently, which enabled them to create and claim more value in integrative settings. However, conditional on reaching a deal, warm agents claimed less value while dominant agents claimed more value. These results align with classic negotiation theory emphasizing relationship-building, assertiveness, and preparation. Our analysis also revealed unique dynamics in AI-AI negotiations not fully explained by negotiation theory, particularly regarding the effectiveness of AI-specific strategies like chain-of-thought reasoning and prompt injection. The agent that won our competition implemented an approach that blended traditional negotiation preparation frameworks with AI-specific methods. Together, these results suggest the importance of establishing a new theory of AI negotiations that integrates established negotiation theory with AI-specific strategies to optimize agent performance. Our research suggests this new theory must account for the unique characteristics of autonomous agents and establish the conditions under which traditional negotiation theory applies in automated settings.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mobility-Aware Decentralized Federated Learning with Joint Optimization of Local Iteration and Leader Selection for Vehicular Networks</title>
<link>https://arxiv.org/abs/2503.06443</link>
<guid>https://arxiv.org/abs/2503.06443</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习（Federated Learning）、移动性、资源约束、分布式、联合优化问题

总结:<br />
本文提出了一种针对车联网的移动感知分布式联邦学习（MDFL）框架。该框架中，附近的车辆以协作但分散的方式共同训练一个FL模型。为提高MDFL的训练效率，文章将问题建模为局部迭代与领导者选择联合优化问题（LSOP）。为解决此问题，研究者将LSOP重构成一个分布式部分可观测马尔科夫决策过程（Dec-POMDP），并基于多智能体亲和策略优化（MAPPO）算法设计了一种有效的求解方法。最后，通过与其他算法对比验证了所提算法的性能优势。 <div>
arXiv:2503.06443v1 Announce Type: new 
Abstract: Federated learning (FL) emerges as a promising approach to empower vehicular networks, composed by intelligent connected vehicles equipped with advanced sensing, computing, and communication capabilities. While previous studies have explored the application of FL in vehicular networks, they have largely overlooked the intricate challenges arising from the mobility of vehicles and resource constraints.In this paper, we propose a framework of mobility-aware decentralized federated learning (MDFL) for vehicular networks. In this framework, nearby vehicles train an FL model collaboratively, yet in a decentralized manner. We formulate a local iteration and leader selection joint optimization problem (LSOP) to improve the training efficiency of MDFL. For problem solving, we first reformulate LSOP as a decentralized partially observable Markov decision process (Dec-POMDP), and then develop an effective optimization algorithm based on multi-agent proximal policy optimization (MAPPO) to solve Dec-POMDP. Finally, we verify the performance of the proposed algorithm by comparing it with other algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mobility-Aware Multi-Task Decentralized Federated Learning for Vehicular Networks: Modeling, Analysis, and Optimization</title>
<link>https://arxiv.org/abs/2503.06468</link>
<guid>https://arxiv.org/abs/2503.06468</guid>
<content:encoded><![CDATA[
<div> 关键词: 弹性学习(Federated Learning)，智能交通系统(Intelligent Transportation Systems)，移动性(mobility)，多任务学习(multi-task learning)，资源分配(resource allocation)

<br /><br />总结:
本文提出了一种针对车联网的、考虑移动性的多任务分散式弹性学习框架——MMFL。该框架同时解决任务调度、子载波分配和领导者选择问题，将其定义为TSLP优化问题。对于单个FL任务的情况，论文得出了模型训练的收敛边界。对于一般情况，将TSLP建模为资源分配博弈，并证明存在纳什均衡。进一步地，通过将该博弈重新表述为一个分布式部分可观测马尔科夫决策过程(DEC-POMDP)，并设计了一个基于异构代理亲和策略优化(HAPPO)算法来求解此DEC-POMDP。数值结果验证了所提算法的有效性。 <div>
arXiv:2503.06468v1 Announce Type: new 
Abstract: Federated learning (FL) is a promising paradigm that can enable collaborative model training between vehicles while protecting data privacy, thereby significantly improving the performance of intelligent transportation systems (ITSs). In vehicular networks, due to mobility, resource constraints, and the concurrent execution of multiple training tasks, how to allocate limited resources effectively to achieve optimal model training of multiple tasks is an extremely challenging issue. In this paper, we propose a mobility-aware multi-task decentralized federated learning (MMFL) framework for vehicular networks. By this framework, we address task scheduling, subcarrier allocation, and leader selection, as a joint optimization problem, termed as TSLP. For the case with a single FL task, we derive the convergence bound of model training. For general cases, we first model TSLP as a resource allocation game, and prove the existence of a Nash equilibrium (NE). Then, based on this proof, we reformulate the game as a decentralized partially observable Markov decision process (DEC-POMDP), and develop an algorithm based on heterogeneous-agent proximal policy optimization (HAPPO) to solve DEC-POMDP. Finally, numerical results are used to demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>An Agent-based Model of Citation Behavior</title>
<link>https://arxiv.org/abs/2503.06579</link>
<guid>https://arxiv.org/abs/2503.06579</guid>
<content:encoded><![CDATA[
<div> 关键词: citations, 评价指标, 科研质量, 引文增长模型, 自主代理模型<br /><br />总结:

本文针对引文能否客观、可靠地衡量文章和研究人员的生产力及科学质量进行了探讨。文章指出，尽管引用次数被广泛用于评估研究人员和机构的生产力，但这种做法实际上催生了一种追求高被引的“功利性”动机。研究通过构建一个基于网络生长的自主代理模型(ABM)，模拟引文增长和这种“功利性”兴趣。在这个模型中，每篇新发表的文章（节点）都是一个具有局部偏好、优先度偏好、新颖性和适应度偏好的引用策略的独立主体。研究表明，适应度以及到一定程度上的出度和局部效应对于获取后续引用有显著影响，这进而引发了对现实世界中类似效应的疑问。 <div>
arXiv:2503.06579v1 Announce Type: new 
Abstract: Whether citations can be objectively and reliably used to measure productivity and scientific quality of articles and researchers can, and should, be vigorously questioned. However, citations are widely used to estimate the productivity of researchers and institutions, effectively creating a 'grubby' motivation to be well-cited. We model citation growth, and this grubby interest using an agent-based model (ABM) of network growth. In this model, each new node (article) in a citation network is an autonomous agent that cites other nodes based on a 'citation personality' consisting of a composite bias for locality, preferential attachment, recency, and fitness. We ask whether strategic citation behavior (reference selection) by the author of a scientific article can boost subsequent citations to it. Our study suggests that fitness and, to a lesser extent, out_degree and locality effects are influential in capturing citations, which raises questions about similar effects in the real world.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent models: Internalizing Chain-of-Action Generation into Reasoning models</title>
<link>https://arxiv.org/abs/2503.06580</link>
<guid>https://arxiv.org/abs/2503.06580</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Agent Models (LAMs)，Chain-of-Action (CoA)，AutoCoA框架，监督微调(SFT)，强化学习(RL)

总结:
本文提出了一种名为AutoCoA的新框架，用于训练能够自主决定何时以及如何使用外部工具的大型代理模型(LAMs)。该框架结合了监督微调(SFT)和强化学习(RL)，使模型能够在推理与行动之间无缝切换并有效管理环境交互。主要组件包括步骤级动作触发、轨迹级CoA优化及内部世界模型以降低真实环境互动成本。实验结果表明，在开放域QA任务中，经由AutoCoA训练的代理模型在任务完成度上显著优于基于ReAct的工作流，特别是在需要长期推理和多步操作的任务中表现突出。相关代码和数据集可在https://github.com/ADaM-BJTU/AutoCoA获取。 <div>
arXiv:2503.06580v1 Announce Type: new 
Abstract: Traditional agentic workflows rely on external prompts to manage interactions with tools and the environment, which limits the autonomy of reasoning models. We position \emph{Large Agent Models (LAMs)} that internalize the generation of \emph{Chain-of-Action (CoA)}, enabling the model to autonomously decide when and how to use external tools. Our proposed AutoCoA framework combines supervised fine-tuning (SFT) and reinforcement learning (RL), allowing the model to seamlessly switch between reasoning and action while efficiently managing environment interactions. Main components include step-level action triggering, trajectory-level CoA optimization, and an internal world model to reduce real-environment interaction costs. Evaluations on open-domain QA tasks demonstrate that AutoCoA-trained agent models significantly outperform ReAct-based workflows in task completion, especially in tasks that require long-term reasoning and multi-step actions. Code and dataset are available at https://github.com/ADaM-BJTU/AutoCoA
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Precise Insulin Delivery for Artificial Pancreas: A Reinforcement Learning Optimized Adaptive Fuzzy Control Approach</title>
<link>https://arxiv.org/abs/2503.06701</link>
<guid>https://arxiv.org/abs/2503.06701</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、Type-1 Takagi-Sugeno 模糊控制器、人工胰脏、糖尿病管理、动态血糖水平

<br /><br />总结:

本文探讨了强化学习在优化Type-1 Takagi-Sugeno模糊控制器参数中的应用，该控制器设计用于作为人工胰脏治疗Type 1糖尿病。针对糖尿病管理中动态血糖水平变化带来的挑战，传统控制器往往难以适应，导致胰岛素施药不理想。为此，研究采用了一个强化学习代理，负责在每个时间步长实时调整模糊控制器的27个参数。实验结果显示，这种方法显著提高了控制器对饮食大小和时间变化的鲁棒性，并能以最小的外源性胰岛素稳定血糖水平。因此，这种自适应方法有望通过提供更响应迅速和精确的管理工具，从而改善Type 1糖尿病患者的生活质量和健康结果。文中给出了模拟结果以突出所提出方法的有效性。 <div>
arXiv:2503.06701v1 Announce Type: new 
Abstract: This paper explores the application of reinforcement learning to optimize the parameters of a Type-1 Takagi-Sugeno fuzzy controller, designed to operate as an artificial pancreas for Type 1 diabetes. The primary challenge in diabetes management is the dynamic nature of blood glucose levels, which are influenced by several factors such as meal intake and timing. Traditional controllers often struggle to adapt to these changes, leading to suboptimal insulin administration. To address this issue, we employ a reinforcement learning agent tasked with adjusting 27 parameters of the Takagi-Sugeno fuzzy controller at each time step, ensuring real-time adaptability. The study's findings demonstrate that this approach significantly enhances the robustness of the controller against variations in meal size and timing, while also stabilizing glucose levels with minimal exogenous insulin. This adaptive method holds promise for improving the quality of life and health outcomes for individuals with Type 1 diabetes by providing a more responsive and precise management tool. Simulation results are given to highlight the effectiveness of the proposed approach.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Delusions of Large Language Models</title>
<link>https://arxiv.org/abs/2503.06709</link>
<guid>https://arxiv.org/abs/2503.06709</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、幻觉、LLM妄想、训练动态、数据集噪声、mitigation策略

总结:
<br />
本文探讨了大型语言模型（LLMs）在生成事实不正确但看似合理的内容时出现的一种更为严重的问题——LLM妄想，即高度自信的错误输出。这种现象表现为模型对错误答案持有异常高的置信度，使得它们更难以被检测和纠正，而且相比于普通幻觉，其不确定性更低，严重影响模型的可靠性。通过对不同模型家族和规模在多个问答任务上的实证分析，研究发现妄想现象普遍存在，并与普通幻觉有所区别。此外，LLMs在产生妄想时表现出较低的诚实性，难以通过微调或自我反思来纠正。文章将妄想形成与训练动态和数据集噪声联系起来，并探索了诸如检索增强生成和多智能体辩论等缓解策略以减轻LLM妄想现象。这项系统性的研究揭示了这一现象的内在原因，为提高模型可靠性指明了未来的研究方向。 <div>
arXiv:2503.06709v1 Announce Type: new 
Abstract: Large Language Models often generate factually incorrect but plausible outputs, known as hallucinations. We identify a more insidious phenomenon, LLM delusion, defined as high belief hallucinations, incorrect outputs with abnormally high confidence, making them harder to detect and mitigate. Unlike ordinary hallucinations, delusions persist with low uncertainty, posing significant challenges to model reliability. Through empirical analysis across different model families and sizes on several Question Answering tasks, we show that delusions are prevalent and distinct from hallucinations. LLMs exhibit lower honesty with delusions, which are harder to override via finetuning or self reflection. We link delusion formation with training dynamics and dataset noise and explore mitigation strategies such as retrieval augmented generation and multi agent debating to mitigate delusions. By systematically investigating the nature, prevalence, and mitigation of LLM delusions, our study provides insights into the underlying causes of this phenomenon and outlines future directions for improving model reliability.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Pull-Based Query Scheduling for Goal-Oriented Semantic Communication</title>
<link>https://arxiv.org/abs/2503.06725</link>
<guid>https://arxiv.org/abs/2503.06725</guid>
<content:encoded><![CDATA[
<div> 关键词: 语义通信、查询调度、目标导向、累积透视理论、深度强化学习

总结:
本文探讨了针对目标导向语义通信的拉式状态更新系统中的查询调度问题。系统中，多个传感代理(SAs)观察具有多种属性的源并为多个执行代理(AAs)提供更新，后者利用接收到的信息有效地实现各自异构目标。一个中心枢纽作为中介，向SAs请求观测属性的更新并维护知识库，随后广播给AAs。文章提出了一种称为效果级效度(GoE)的度量标准来量化更新的语义价值，并将累积透视理论(CPT)融入长期效果分析中，以考虑系统的风险意识和损失规避。基于此框架，研究者设计了旨在最大化预期折扣累计CPT-基总体GoE的同时满足给定查询成本约束的效果感知调度策略。为了实现这一目标，文中提出了基于动态规划的模型解决方案以及运用最先进的深度强化学习(DRL)算法的模型无关解决方案。实验结果表明，相较于基准调度方法，效果感知调度显著提升了传输更新的有效性，尤其是在具有严格成本约束的场景下，优化的查询调度对于系统性能和整体有效性至关重要。 <div>
arXiv:2503.06725v1 Announce Type: new 
Abstract: This paper addresses query scheduling for goal-oriented semantic communication in pull-based status update systems. We consider a system where multiple sensing agents (SAs) observe a source characterized by various attributes and provide updates to multiple actuation agents (AAs), which act upon the received information to fulfill their heterogeneous goals at the endpoint. A hub serves as an intermediary, querying the SAs for updates on observed attributes and maintaining a knowledge base, which is then broadcast to the AAs. The AAs leverage the knowledge to perform their actions effectively. To quantify the semantic value of updates, we introduce a grade of effectiveness (GoE) metric. Furthermore, we integrate cumulative perspective theory (CPT) into the long-term effectiveness analysis to account for risk awareness and loss aversion in the system. Leveraging this framework, we compute effect-aware scheduling policies aimed at maximizing the expected discounted sum of CPT-based total GoE provided by the transmitted updates while complying with a given query cost constraint. To achieve this, we propose a model-based solution based on dynamic programming and model-free solutions employing state-of-the-art deep reinforcement learning (DRL) algorithms. Our findings demonstrate that effect-aware scheduling significantly enhances the effectiveness of communicated updates compared to benchmark scheduling methods, particularly in settings with stringent cost constraints where optimal query scheduling is vital for system performance and overall effectiveness.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Black-Box Benchmarking: Observability, Analytics, and Optimization of Agentic Systems</title>
<link>https://arxiv.org/abs/2503.06745</link>
<guid>https://arxiv.org/abs/2503.06745</guid>
<content:encoded><![CDATA[
<div> 关键词: agentic AI系统、挑战、分析、优化、基准测试

<br />
总结:
本文探讨了多智能体AI系统的兴起所带来的行为观察、分析和优化方面的新挑战。针对此类系统的非确定性、情境敏感性和动态特性，传统的评估和基准测试方法显得力不从心。文章指出了自然语言变化和不可预测执行流程等问题对系统可预测性和控制性的阻碍，并通过用户研究证实了这些观点。实验结果显示，有79%的受访者认为多智能体系统的非确定性流程是一项重大挑战。为弥补现有方法的不足，文章提出了预期分析结果的分类体系以及扩展标准可观测性框架以收集数据的方法。进一步地，文章介绍并展示了基于运行时日志输入的新型代理评价系统基准测试方法，其关注点包括发现的流程和问题。这一方法旨在为发展更加适应性强、可解释和鲁棒的多智能体AI系统奠定基础，推动更为先进和全面的评估策略。 <div>
arXiv:2503.06745v1 Announce Type: new 
Abstract: The rise of agentic AI systems, where agents collaborate to perform diverse tasks, poses new challenges with observing, analyzing and optimizing their behavior. Traditional evaluation and benchmarking approaches struggle to handle the non-deterministic, context-sensitive, and dynamic nature of these systems. This paper explores key challenges and opportunities in analyzing and optimizing agentic systems across development, testing, and maintenance. We explore critical issues such as natural language variability and unpredictable execution flows, which hinder predictability and control, demanding adaptive strategies to manage input variability and evolving behaviors. Through our user study, we supported these hypotheses. In particular, we showed a 79% agreement that non deterministic flow of agentic systems acts as a major challenge. Finally, we validated our statements empirically advocating the need for moving beyond classical benchmarking. To bridge these gaps, we introduce taxonomies to present expected analytics outcomes and the ways to collect them by extending standard observability frameworks. Building on these foundations, we introduce and demonstrate novel approach for benchmarking of agent evaluation systems. Unlike traditional "black box" performance evaluation approaches, our benchmark is built from agent runtime logs as input, and analytics outcome including discovered flows and issues. By addressing key limitations in existing methodologies, we aim to set the stage for more advanced and holistic evaluation strategies, which could foster the development of adaptive, interpretable, and robust agentic AI systems.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully-Decentralized MADDPG with Networked Agents</title>
<link>https://arxiv.org/abs/2503.06747</link>
<guid>https://arxiv.org/abs/2503.06747</guid>
<content:encoded><![CDATA[
<div> 关键词：actor-critic算法、分布式训练、多智能体强化学习、连续动作空间、MADDPG

总结:<br />
本文提出了三种针对合作、对抗和混合环境下的多智能体连续动作空间强化学习的分布式训练actor-critic算法。通过将MADDPG算法进行适应性改造，采用网络化通信方式实现智能体间的交互。文中引入代理策略以实现训练的去中心化，同时允许训练过程中进行局部通信。实验结果显示，这些分布式算法在性能上可与原版MADDPG相媲美，尤其是在更大数量的智能体情况下，能显著降低计算成本。 <div>
arXiv:2503.06747v1 Announce Type: new 
Abstract: In this paper, we devise three actor-critic algorithms with decentralized training for multi-agent reinforcement learning in cooperative, adversarial, and mixed settings with continuous action spaces. To this goal, we adapt the MADDPG algorithm by applying a networked communication approach between agents. We introduce surrogate policies in order to decentralize the training while allowing for local communication during training. The decentralized algorithms achieve comparable results to the original MADDPG in empirical tests, while reducing computational cost. This is more pronounced with larger numbers of agents.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task-Oriented Connectivity for Networked Robotics with Generative AI and Semantic Communications</title>
<link>https://arxiv.org/abs/2503.06771</link>
<guid>https://arxiv.org/abs/2503.06771</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人、语义通信(SemCom)、生成式人工智能(GenAI)、网络环境、自动化操作

<br /><br />总结：
本文提出了一种融合语义通信与生成式人工智能的机器人协同工作框架。该框架旨在通过语义感知网络实现目标导向的语义通信，减少信息交换中的冗余和延迟。同时，利用GenAI代理解析高级任务指令、分配资源并适应网络及机器人环境的变化，提高了系统的自主性和智能水平。文中通过一个多机器人异常检测应用场景的模拟实验验证了这种方法的有效性，结果表明，SemCom显著降低了数据流量但保持了关键语义信息的完整性，而GenAI代理则确保了任务协调和网络自适应。这种协同作用为现代工业环境提供了强大、高效且可扩展的解决方案。 <div>
arXiv:2503.06771v1 Announce Type: new 
Abstract: The convergence of robotics, advanced communication networks, and artificial intelligence (AI) holds the promise of transforming industries through fully automated and intelligent operations. In this work, we introduce a novel co-working framework for robots that unifies goal-oriented semantic communication (SemCom) with a Generative AI (GenAI)-agent under a semantic-aware network. SemCom prioritizes the exchange of meaningful information among robots and the network, thereby reducing overhead and latency. Meanwhile, the GenAI-agent leverages generative AI models to interpret high-level task instructions, allocate resources, and adapt to dynamic changes in both network and robotic environments. This agent-driven paradigm ushers in a new level of autonomy and intelligence, enabling complex tasks of networked robots to be conducted with minimal human intervention. We validate our approach through a multi-robot anomaly detection use-case simulation, where robots detect, compress, and transmit relevant information for classification. Simulation results confirm that SemCom significantly reduces data traffic while preserving critical semantic details, and the GenAI-agent ensures task coordination and network adaptation. This synergy provides a robust, efficient, and scalable solution for modern industrial environments.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Chance-constrained Linear Quadratic Gaussian Games for Multi-robot Interaction under Uncertainty</title>
<link>https://arxiv.org/abs/2503.06776</link>
<guid>https://arxiv.org/abs/2503.06776</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人交互、不确定性、机会约束、线性二次高斯游戏、双梯度上升算法

<br /><br />总结：
本文关注在不确定性下的安全多机器人交互问题。研究者提出了一种带有耦合约束和系统不确定性的机会约束线性二次高斯博弈模型，并对其进行了可求解的重构。接着，他们设计了一种双梯度上升算法，并证明该算法能够收敛到重构博弈的一个广义纳什均衡，从而确保满足了机会约束条件。实验通过驾驶模拟与真实世界机器人实验验证了该方法的有效性，表明该方法能够在保证安全性的同时，相较于单智能体模型预测控制生成更不保守的轨迹。 <div>
arXiv:2503.06776v1 Announce Type: new 
Abstract: We address safe multi-robot interaction under uncertainty. In particular, we formulate a chance-constrained linear quadratic Gaussian game with coupling constraints and system uncertainties. We find a tractable reformulation of the game and propose a dual ascent algorithm. We prove that the algorithm converges to a generalized Nash equilibrium of the reformulated game, ensuring the satisfaction of the chance constraints. We test our method in driving simulations and real-world robot experiments. Our method ensures safety under uncertainty and generates less conservative trajectories than single-agent model predictive control.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AutoMisty: A Multi-Agent LLM Framework for Automated Code Generation in the Misty Social Robot</title>
<link>https://arxiv.org/abs/2503.06791</link>
<guid>https://arxiv.org/abs/2503.06791</guid>
<content:encoded><![CDATA[
<div> 关键词: AutoMisty、多智能体协作框架、大型语言模型、Misty机器人、自然语言指令

<br /><br />总结:
本文介绍了AutoMisty，这是一个首个利用大型语言模型（LLMs）实现的多智能体协作框架，旨在使无编程经验的用户能够通过自然语言指令自定义Misty机器人的开放域交互。AutoMisty包含了四个专门的代理模块，分别负责任务分解、分配、问题解决和结果合成，并且每个代理都采用了两层优化机制，包括自我反思和人类在环路中的参与以更好地与用户偏好对齐。该框架确保了透明的推理过程，允许用户通过自然语言反馈迭代细化任务以实现精确执行。为了评估AutoMisty的有效性，研究者设计了一个涵盖四种复杂度级别的基准任务集并在真实的Misty机器人环境中进行了实验。结果显示，AutoMisty不仅能持续生成高质量代码，还能实现精确的代码控制，其性能显著优于直接使用ChatGPT-4o和ChatGPT-o1进行推理。相关的所有代码、优化后的API以及实验视频将在项目网页https://wangxiaoshawn.github.io/AutoMisty.html上公开发布。 <div>
arXiv:2503.06791v1 Announce Type: new 
Abstract: The social robot's open API allows users to customize open-domain interactions. However, it remains inaccessible to those without programming experience. In this work, we introduce AutoMisty, the first multi-agent collaboration framework powered by large language models (LLMs), to enable the seamless generation of executable Misty robot code from natural language instructions. AutoMisty incorporates four specialized agent modules to manage task decomposition, assignment, problem-solving, and result synthesis. Each agent incorporates a two-layer optimization mechanism, with self-reflection for iterative refinement and human-in-the-loop for better alignment with user preferences. AutoMisty ensures a transparent reasoning process, allowing users to iteratively refine tasks through natural language feedback for precise execution. To evaluate AutoMisty's effectiveness, we designed a benchmark task set spanning four levels of complexity and conducted experiments in a real Misty robot environment. Extensive evaluations demonstrate that AutoMisty not only consistently generates high-quality code but also enables precise code control, significantly outperforming direct reasoning with ChatGPT-4o and ChatGPT-o1. All code, optimized APIs, and experimental videos will be publicly released through the webpage: https://wangxiaoshawn.github.io/AutoMisty.html
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Actionable AI: Enabling Non Experts to Understand and Configure AI Systems</title>
<link>https://arxiv.org/abs/2503.06803</link>
<guid>https://arxiv.org/abs/2503.06803</guid>
<content:encoded><![CDATA[
<div> 关键词：Actionable AI、非专家、黑盒代理、配置、性能

总结:
本文探讨了如何使非专家理解并配置AI系统，提出了“可操作性AI（Actionable AI）”的概念。通过实验研究一个由AI驱动的推杆游戏，观察22对参与者直接操纵该系统进行配置的情况。研究发现，在不确定条件下，非专家能够达到较好的性能水平，并通过影响代理的行为展现出对其运作的理解，从而实现自身目标。基于此，文章提出了设计可操作性AI系统的相关启示，建议赋予终端用户影响和配置AI代理的能力，以实现他们自身的诉求。 <div>
arXiv:2503.06803v1 Announce Type: new 
Abstract: Interaction between humans and AI systems raises the question of how people understand AI systems. This has been addressed with explainable AI, the interpretability arising from users' domain expertise, or collaborating with AI in a stable environment. In the absence of these elements, we discuss designing Actionable AI, which allows non-experts to configure black-box agents. In this paper, we experiment with an AI-powered cartpole game and observe 22 pairs of participants to configure it via direct manipulation. Our findings suggest that, in uncertain conditions, non-experts were able to achieve good levels of performance. By influencing the behaviour of the agent, they exhibited an operational understanding of it, which proved sufficient to reach their goals. Based on this, we derive implications for designing Actionable AI systems. In conclusion, we propose Actionable AI as a way to open access to AI-based agents, giving end users the agency to influence such agents towards their own goals.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Can Proof Assistants Verify Multi-Agent Systems?</title>
<link>https://arxiv.org/abs/2503.06812</link>
<guid>https://arxiv.org/abs/2503.06812</guid>
<content:encoded><![CDATA[
<div> 关键词：Soda语言、多智能体系统、Scala、Lean、形式验证

总结:
Soda语言是一种用于验证多智能体系统的高级功能性和面向对象的语言。它具备将代码编译为Scala编程语言和Lean证明助手及编程语言的能力。这种特性使得使用Soda实现的多智能体系统或其部分组件既能融入主流软件生态系统，又可以利用最先进的工具进行正式验证。文中对Soda语言及其交互性能力进行了简要非正式介绍，并通过一个简单的互动协议设计与验证示例展示了其应用方法，同时指出了关于实际应用中的挑战。 <div>
arXiv:2503.06812v1 Announce Type: new 
Abstract: This paper presents the Soda language for verifying multi-agent systems. Soda is a high-level functional and object-oriented language that supports the compilation of its code not only to Scala, a strongly statically typed high-level programming language, but also to Lean, a proof assistant and programming language. Given these capabilities, Soda can implement multi-agent systems, or parts thereof, that can then be integrated into a mainstream software ecosystem on the one hand and formally verified with state-of-the-art tools on the other hand. We provide a brief and informal introduction to Soda and the aforementioned interoperability capabilities, as well as a simple demonstration of how interaction protocols can be designed and verified with Soda. In the course of the demonstration, we highlight challenges with respect to real-world applicability.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Unlocking Generalization for Robotics via Modularity and Scale</title>
<link>https://arxiv.org/abs/2503.06814</link>
<guid>https://arxiv.org/abs/2503.06814</guid>
<content:encoded><![CDATA[
<div> 关键词：通用机器人系统、模块化、大规模学习、规划监督、模拟到现实转移

总结:<br />
本文探讨了构建通用机器人系统的途径，强调了规模并不足够，需要结合模块化和大规模学习。研究提出了将规划引入学习系统中以实现层次性和模块化，从而提升机器人学习效率和能力。同时，利用经典规划作为强大监督源，指导大规模策略学习，以应对数据多样性和神经网络的扩展性需求。进一步地，文章讨论了如何将模块化与大规模策略学习相结合，通过整合高层和中层规划、学习到的局部控制、过程生成场景以及大规模策略学习，实现从模拟到现实世界的零样本操作。实验表明，这种方案可以产生一种能够解决现实世界中复杂长序列操纵任务的单一通用智能体。 <div>
arXiv:2503.06814v1 Announce Type: new 
Abstract: How can we build generalist robot systems? Scale may not be enough due to the significant multimodality of robotics tasks, lack of easily accessible data and the challenges of deploying on physical hardware. Meanwhile, most deployed robotic systems today are inherently modular and can leverage the independent generalization capabilities of each module to perform well. Therefore, this thesis seeks to tackle the task of building generalist robot agents by integrating these components into one: combining modularity with large-scale learning for general purpose robot control. The first question we consider is: how can we build modularity and hierarchy into learning systems? Our key insight is that rather than having the agent learn hierarchy and low-level control end-to-end, we can enforce modularity via planning to enable more efficient and capable robot learners. Next, we come to the role of scale in building generalist robot systems. To scale, neural networks require vast amounts of diverse data, expressive architectures to fit the data and a source of supervision to generate the data. We leverage a powerful supervision source: classical planning, which can generalize, but is expensive to run and requires access to privileged information to perform well in practice. We use these planners to supervise large-scale policy learning in simulation to produce generalist agents. Finally, we consider how to unify modularity with large-scale policy learning to build real-world robot systems capable of performing zero-shot manipulation. We do so by tightly integrating key ingredients of modular high and mid-level planning, learned local control, procedural scene generation and large-scale policy learning for sim2real transfer. We demonstrate that this recipe can produce a single, generalist agent that can solve challenging long-horizon manipulation tasks in the real world.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SafePlan: Leveraging Formal Logic and Chain-of-Thought Reasoning for Enhanced Safety in LLM-based Robotic Task Planning</title>
<link>https://arxiv.org/abs/2503.06892</link>
<guid>https://arxiv.org/abs/2503.06892</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、机器人系统、安全性、SafePlan、任务分配

总结:
本文介绍了随着大规模语言模型（LLM）在机器人系统中的广泛应用，其带来的安全问题日益凸显，特别是关于执行恶意或不安全的自然语言指令的风险。为确保基于LLM的任务计划、团队组建和任务分配等输出的安全性，研究者提出了一种名为SafePlan的多组件框架。该框架结合形式逻辑和chain-of-thought推理器，以增强LLM驱动的机器人系统的安全性。通过利用Prompt Sanity COT Reasoner和Invariant、Precondition、Postcondition COT reasoners等SafePlan组件，对自然语言任务提示、任务计划和任务分配输出进行安全检查和改进。实验结果显示，SafePlan相比于基线模型能将有害任务提示接受率降低90.5%，同时仍保持了对安全任务的合理接受率。 <div>
arXiv:2503.06892v1 Announce Type: new 
Abstract: Robotics researchers increasingly leverage large language models (LLM) in robotics systems, using them as interfaces to receive task commands, generate task plans, form team coalitions, and allocate tasks among multi-robot and human agents. However, despite their benefits, the growing adoption of LLM in robotics has raised several safety concerns, particularly regarding executing malicious or unsafe natural language prompts. In addition, ensuring that task plans, team formation, and task allocation outputs from LLMs are adequately examined, refined, or rejected is crucial for maintaining system integrity. In this paper, we introduce SafePlan, a multi-component framework that combines formal logic and chain-of-thought reasoners for enhancing the safety of LLM-based robotics systems. Using the components of SafePlan, including Prompt Sanity COT Reasoner and Invariant, Precondition, and Postcondition COT reasoners, we examined the safety of natural language task prompts, task plans, and task allocation outputs generated by LLM-based robotic systems as means of investigating and enhancing system safety profile. Our results show that SafePlan outperforms baseline models by leading to 90.5% reduction in harmful task prompt acceptance while still maintaining reasonable acceptance of safe tasks.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Beyond Code Generation: LLM-supported Exploration of the Program Design Space</title>
<link>https://arxiv.org/abs/2503.06911</link>
<guid>https://arxiv.org/abs/2503.06911</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)、程序设计、迭代设计、集成开发环境(IDE)、用户研究

总结:
本文探讨了利用大型语言模型（LLM）支持计算机程序的迭代设计过程。研究指出，默认情况下，代码生成的LLM仅提供单一解决方案，而忽略了可能存在更好替代方案的设计空间。为解决这一问题，文章提出了一种新的IDE，该IDE能够生成和展示问题的不同表述以及备选解决方案，跟踪设计决策，并识别程序员或LLM隐含做出的决策。通过用户研究发现，使用此IDE，用户能更广泛地探索设计空间，但同时也面临因LLM引起的代码变化和其他信息过载导致的挑战。这表明未来基于LLM的IDE需要面对的核心挑战是如何精细管理注意力并决定何时向程序设计师呈现何种信息。 <div>
arXiv:2503.06911v1 Announce Type: new 
Abstract: In this work, we explore explicit Large Language Model (LLM)-powered support for the iterative design of computer programs. Program design, like other design activity, is characterized by navigating a space of alternative problem formulations and associated solutions in an iterative fashion. LLMs are potentially powerful tools in helping this exploration; however, by default, code-generation LLMs deliver code that represents a particular point solution. This obscures the larger space of possible alternatives, many of which might be preferable to the LLM's default interpretation and its generated code. We contribute an IDE that supports program design through generating and showing new ways to frame problems alongside alternative solutions, tracking design decisions, and identifying implicit decisions made by either the programmer or the LLM. In a user study, we find that with our IDE, users combine and parallelize design phases to explore a broader design space -- but also struggle to keep up with LLM-originated changes to code and other information overload. These findings suggest a core challenge for future IDEs that support program design through higher-level instructions given to LLM-based agents: carefully managing attention and deciding what information agents should surface to program designers and when.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Distributed Pose Graph Optimization using the Splitting Method based on the Alternating Direction Method of Multipliers</title>
<link>https://arxiv.org/abs/2503.06912</link>
<guid>https://arxiv.org/abs/2503.06912</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式优化、约束非凸问题、交替方向乘子法(ADMM)、Bregman迭代、姿态图优化(PGO)

总结:<br />
本文研究了在非凸约束条件下的分布式姿态图优化问题，旨在通过利用每个代理的局部计算和通信能力来逼近给定相关噪声测量下的各姿态的旋转和平移。文章提出了一种基于交替方向乘子法(ADMM)和Bregman迭代的拆分方法，用于解决旋转子问题。该方法通过求解无约束问题和具有解析解的正交性约束二次问题，实现对受限问题的迭代求解。实验将该算法与分布式高斯-赛德尔(DGS)算法以及带有最优性证书的集中式姿态图优化器(SE-Sync)进行对比，验证了其在多个模拟和真实世界姿态图数据集上的效率。与DGS方法不同的是，该方法试图在不放松非凸约束的情况下解决分布式PGO问题。 <div>
arXiv:2503.06912v1 Announce Type: new 
Abstract: Distributed optimization aims to leverage the local computation and communication capabilities of each agent to achieve a desired global objective. This paper addresses the distributed pose graph optimization (PGO) problem under non-convex constraints, with the goal of approximating the rotation and translation of each pose given relevant noisy measurements. To achieve this goal, the splitting method based on the concepts of the alternating direction method of multipliers (ADMM) and Bregman iteration are applied to solve the rotation subproblems. The proposed approach enables the iterative resolution of constrained problems, achieved through solving unconstrained problems and orthogonality-constrained quadratic problems that have analytical solutions. The performance of the proposed algorithm is compared against two practical methods in pose graph optimization: the Distributed Gauss-Seidel (DGS) algorithm and the centralized pose graph optimizer with an optimality certificate (SE-Sync). The efficiency of the proposed method is verified through its application to several simulated and real-world pose graph datasets. Unlike the DGS method, our approach attempts to solve distributed PGO problems without relaxing the non-convex constraints.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Handle Object Navigation as Weighted Traveling Repairman Problem</title>
<link>https://arxiv.org/abs/2503.06937</link>
<guid>https://arxiv.org/abs/2503.06937</guid>
<content:encoded><![CDATA[
<div> 关键词：Zero-Shot Object Navigation (ZSON)，Weighted Traveling Repairman Problem (WTRP)，Vision-Language Model (VLM)，3D embedding feature map，open-vocabulary detector

总结:<br />
本文提出了一个名为WTRP-Searcher的新框架，用于解决无需预定义类别或环境知识的零样本物体导航（ZSON）问题。该框架将ZSON建模为加权旅行修理工问题（WTRP），通过最小化视点的加权等待时间来规划路径。利用视觉语言模型（VLM），根据对象描述相似性对视点进行评分，并结合深度信息投影到二维地图上。开放词汇量检测器动态识别目标，更新导航目标，同时使用三维嵌入特征图增强空间感知和环境记忆。相比于现有方法，WTRP-Searcher表现出更优的全局规划效率和在复杂ZSON任务中的性能。相关代码和更多演示将在https://github.com/lrm20011/WTRP_Searcher上发布。 <div>
arXiv:2503.06937v1 Announce Type: new 
Abstract: Zero-Shot Object Navigation (ZSON) requires agents to navigate to objects specified via open-ended natural language without predefined categories or prior environmental knowledge. While recent methods leverage foundation models or multi-modal maps, they often rely on 2D representations and greedy strategies or require additional training or modules with high computation load, limiting performance in complex environments and real applications. We propose WTRP-Searcher, a novel framework that formulates ZSON as a Weighted Traveling Repairman Problem (WTRP), minimizing the weighted waiting time of viewpoints. Using a Vision-Language Model (VLM), we score viewpoints based on object-description similarity, projected onto a 2D map with depth information. An open-vocabulary detector identifies targets, dynamically updating goals, while a 3D embedding feature map enhances spatial awareness and environmental recall. WTRP-Searcher outperforms existing methods, offering efficient global planning and improved performance in complex ZSON tasks. Code and more demos will be avaliable on https://github.com/lrm20011/WTRP_Searcher.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Parametric Value Approximation for General-sum Differential Games with State Constraints</title>
<link>https://arxiv.org/abs/2503.06994</link>
<guid>https://arxiv.org/abs/2503.06994</guid>
<content:encoded><![CDATA[
<div> 关键词: General-sum differential games, Hamilton-Jacobi-Isaacs equations, Curse of Dimensionality, Physics-informed neural networks, Hybrid Neural Operator

<br /><br />总结:
本文提出了一种名为混合神经算子（HNO）的方法，用于解决高维一般性博弈中的值函数逼近问题。针对传统方法在解决此类博弈时遭遇维度灾难以及常规物理 inform 的神经网络在处理具有大 Lipshitz 常数的价值函数时存在的收敛性问题，HNO 能够结合监督数据和偏微分方程驱动的数据样本进行模型细化，从而有效地映射游戏参数函数到价值函数。此外，与监督神经算子（SNO）相比，在对具有非线性动力学和状态约束的 9D 和 13D 场景进行评估时，HNO 在安全性能方面表现更优。这项工作为实现复杂人机或多智能体交互中实时推断所需的可扩展和泛化值函数近似提供了一个重要步骤。 <div>
arXiv:2503.06994v1 Announce Type: new 
Abstract: General-sum differential games can approximate values solved by Hamilton-Jacobi-Isaacs (HJI) equations for efficient inference when information is incomplete. However, solving such games through conventional methods encounters the curse of dimensionality (CoD). Physics-informed neural networks (PINNs) offer a scalable approach to alleviate the CoD and approximate values, but there exist convergence issues for value approximations through vanilla PINNs when state constraints lead to values with large Lipschitz constants, particularly in safety-critical applications. In addition to addressing CoD, it is necessary to learn a generalizable value across a parametric space of games, rather than training multiple ones for each specific player-type configuration. To overcome these challenges, we propose a Hybrid Neural Operator (HNO), which is an operator that can map parameter functions for games to value functions. HNO leverages informative supervised data and samples PDE-driven data across entire spatial-temporal space for model refinement. We evaluate HNO on 9D and 13D scenarios with nonlinear dynamics and state constraints, comparing it against a Supervised Neural Operator (a variant of DeepONet). Under the same computational budget and training data, HNO outperforms SNO for safety performance. This work provides a step toward scalable and generalizable value function approximation, enabling real-time inference for complex human-robot or multi-agent interactions.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ProjectEval: A Benchmark for Programming Agents Automated Evaluation on Project-Level Code Generation</title>
<link>https://arxiv.org/abs/2503.07010</link>
<guid>https://arxiv.org/abs/2503.07010</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM 代理、项目级代码生成、自动化评估、用户交互模拟、ProjectEval

<br /><br />总结:
为了解决LLM（Large Language Model）代理在编程能力提升过程中缺乏从用户角度自动评价及代码生成结果解释性的问题，文章提出了一个新的基准——ProjectEval。ProjectEval通过LLM与人类评审相结合的方式构建，具备三种不同层次的自然语言或代码骨架输入。该基准能够通过模拟用户交互来对生成的项目进行执行效果评估，并结合已有客观指标进行代码相似度评价。研究发现，系统工程项目的代码组织、对项目整体的理解以及全面分析能力是LLM代理实现实用项目的关键所在。ProjectEval及其发现对于开发更有效的可部署于未来实际生产环境中的编程代理提供了宝贵见解。 <div>
arXiv:2503.07010v1 Announce Type: new 
Abstract: Recently, LLM agents have made rapid progress in improving their programming capabilities. However, existing benchmarks lack the ability to automatically evaluate from users' perspective, and also lack the explainability of the results of LLM agents' code generation capabilities. Thus, we introduce ProjectEval, a new benchmark for LLM agents project-level code generation's automated evaluation by simulating user interaction. ProjectEval is constructed by LLM with human reviewing. It has three different level inputs of natural languages or code skeletons. ProjectEval can evaluate the generated projects by user interaction simulation for execution, and by code similarity through existing objective indicators. Through ProjectEval, we find that systematic engineering project code, overall understanding of the project and comprehensive analysis capability are the keys for LLM agents to achieve practical projects. Our findings and benchmark provide valuable insights for developing more effective programming agents that can be deployed in future real-world production.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Nash Equilibrial Hamiltonian for Two-Player Collision-Avoiding Interactions</title>
<link>https://arxiv.org/abs/2503.07013</link>
<guid>https://arxiv.org/abs/2503.07013</guid>
<content:encoded><![CDATA[
<div> 关键词：学习纳什均衡策略、风险敏感、碰撞避免、哈密顿-雅可比-伊萨克斯方程、数据效率

总结:<br />
本文针对两个玩家间的风险敏感型碰撞避免交互问题，研究学习纳什均衡策略的方法。文章指出现有方法通过神经网络近似求解一般和差分游戏的哈密顿-雅可比-伊萨克斯方程存在实时计算难度和数据需求量大的挑战。为此，文章提出两点贡献：一是当碰撞避免主导损失函数且系统动力学为线性时，通过学习具有简单结构的平衡共状态替代价值网络中的哈密顿ian，从而提高数据效率；二是引入理论驱动的主动学习指导数据采样，利用预测的共状态对庞特里亚金最大原理的符合程度作为获取函数，以优化样本选择。实验表明，该方法在相同的数据采集预算下，对于无控制交叉路口案例，能够得到更泛化的均衡策略估计，从而降低碰撞概率，优于现有最优方法。 <div>
arXiv:2503.07013v1 Announce Type: new 
Abstract: We consider the problem of learning Nash equilibrial policies for two-player risk-sensitive collision-avoiding interactions. Solving the Hamilton-Jacobi-Isaacs equations of such general-sum differential games in real time is an open challenge due to the discontinuity of equilibrium values on the state space. A common solution is to learn a neural network that approximates the equilibrium Hamiltonian for given system states and actions. The learning, however, is usually supervised and requires a large amount of sample equilibrium policies from different initial states in order to mitigate the risks of collisions. This paper claims two contributions towards more data-efficient learning of equilibrium policies: First, instead of computing Hamiltonian through a value network, we show that the equilibrium co-states have simple structures when collision avoidance dominates the agents' loss functions and system dynamics is linear, and therefore are more data-efficient to learn. Second, we introduce theory-driven active learning to guide data sampling, where the acquisition function measures the compliance of the predicted co-states to Pontryagin's Maximum Principle. On an uncontrolled intersection case, the proposed method leads to more generalizable approximation of the equilibrium policies, and in turn, lower collision probabilities, than the state-of-the-art under the same data acquisition budget.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Toward Multi-Session Personalized Conversation: A Large-Scale Dataset and Hierarchical Tree Framework for Implicit Reasoning</title>
<link>https://arxiv.org/abs/2503.07018</link>
<guid>https://arxiv.org/abs/2503.07018</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模长期对话数据集、隐性推理、个性化对话、TaciTree框架、大型语言模型

总结:
本文介绍了一个针对大型语言模型在处理长序列个性化对话中隐性推理能力的研究。为弥补现有长短期对话数据集在复杂真实世界个性化和隐性推理方面的不足，文章提出了一个名为ImplexConv的大规模长期对话数据集，包含了约2500个例子，每个例子拥有约100轮会话记录。为了更有效地处理这些具有隐含上下文依赖的长时间对话，文章进一步提出了TaciTree——一种新颖的层次化树结构框架，该框架能够将对话历史分为多个层级的摘要，使模型能够在逐步选择相关细节的过程中进行有效检索。实验结果显示，使用TaciTree框架能显著提升LLMs在处理具有长期隐性上下文依赖的对话任务上的表现。 <div>
arXiv:2503.07018v1 Announce Type: new 
Abstract: There has been a surge in the use of large language models (LLM) conversational agents to generate responses based on long-term history from multiple sessions. However, existing long-term open-domain dialogue datasets lack complex, real-world personalization and fail to capture implicit reasoning-where relevant information is embedded in subtle, syntactic, or semantically distant connections rather than explicit statements. In such cases, traditional retrieval methods fail to capture relevant context, and long-context modeling also becomes inefficient due to numerous complicated persona-related details. To address this gap, we introduce ImplexConv, a large-scale long-term dataset with 2,500 examples, each containing approximately 100 conversation sessions, designed to study implicit reasoning in personalized dialogues. Additionally, we propose TaciTree, a novel hierarchical tree framework that structures conversation history into multiple levels of summarization. Instead of brute-force searching all data, TaciTree enables an efficient, level-based retrieval process where models refine their search by progressively selecting relevant details. Our experiments demonstrate that TaciTree significantly improves the ability of LLMs to reason over long-term conversations with implicit contextual dependencies.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Combating Partial Perception Deficit in Autonomous Driving with Multimodal LLM Commonsense</title>
<link>https://arxiv.org/abs/2503.07020</link>
<guid>https://arxiv.org/abs/2503.07020</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、感知缺陷、LLM-RCO框架、DriveLM-Deficit数据集、CARLA模拟器

<br /><br />总结：

本文提出了一种名为LLM-RCO的新框架，用于应对自动驾驶车辆因感知缺陷而可能造成的安全隐患。该框架通过大型语言模型集成人类驾驶常识，包括四个关键模块：危险推理、短期运动规划器、动作条件验证器和安全约束生成器，使系统能对动态驾驶环境采取主动和情境感知的控制措施，以覆盖原有控制策略。为增强在挑战性条件下的安全性，研究者构建了DriveLM-Deficit数据集，包含了53,895个涉及安全关键对象感知缺陷的视频片段及其相关注释，用于LLM驱动的危险推理和运动规划微调。实验表明，在CARLA模拟器中的不良驾驶条件下，装备有LLM-RCO框架的系统显著提升了驾驶性能，显示出了其在提升自动驾驶对不利感知缺陷场景适应能力方面的潜力。同时，使用DriveLM-Deficit数据集进行微调的LLMs能够引导系统在感知缺陷情况下做出更为主动的动作而非保守的停止。 <div>
arXiv:2503.07020v1 Announce Type: new 
Abstract: Partial perception deficits can compromise autonomous vehicle safety by disrupting environmental understanding. Current protocols typically respond with immediate stops or minimal-risk maneuvers, worsening traffic flow and lacking flexibility for rare driving scenarios. In this paper, we propose LLM-RCO, a framework leveraging large language models to integrate human-like driving commonsense into autonomous systems facing perception deficits. LLM-RCO features four key modules: hazard inference, short-term motion planner, action condition verifier, and safety constraint generator. These modules interact with the dynamic driving environment, enabling proactive and context-aware control actions to override the original control policy of autonomous agents. To improve safety in such challenging conditions, we construct DriveLM-Deficit, a dataset of 53,895 video clips featuring deficits of safety-critical objects, complete with annotations for LLM-based hazard inference and motion planning fine-tuning. Extensive experiments in adverse driving conditions with the CARLA simulator demonstrate that systems equipped with LLM-RCO significantly improve driving performance, highlighting its potential for enhancing autonomous driving resilience against adverse perception deficits. Our results also show that LLMs fine-tuned with DriveLM-Deficit can enable more proactive movements instead of conservative stops in the context of perception deficits.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DatawiseAgent: A Notebook-Centric LLM Agent Framework for Automated Data Science</title>
<link>https://arxiv.org/abs/2503.07044</link>
<guid>https://arxiv.org/abs/2503.07044</guid>
<content:encoded><![CDATA[
<div> 关键词: Data Science任务、LLM、DatawiseAgent、Finite State Transducer (FST)、自动化数据科学

<br /><br />总结:
本文提出了一种名为DatawiseAgent的新框架，旨在解决数据科学任务的多方面、动态和领域特性问题。DatawiseAgent是一个基于笔记本的LLM（大型语言模型）代理，通过Markdown和可执行代码单元格统一用户、代理与计算环境的交互，支持灵活适应的自动化数据科学工作流程。该框架构建于有限状态转换器(FST)之上，涵盖了四个阶段：类似DSF的规划、增量执行、自我调试和后过滤。其中，规划阶段系统地探索解决方案空间；增量执行利用实时反馈并根据LLM的能力限制逐步完成任务；自我调试和后过滤模块则进一步提高了可靠性和结果质量，通过诊断和纠正错误以及剪枝冗余信息。通过在包括数据分析、可视化和数据建模等多样化的任务上进行广泛实验，DatawiseAgent显示出了在多种模型设置下持续优于或匹配当前最优方法的表现，凸显了其在数据科学场景中的普适性潜力，并为进一步实现更高效、全自动的工作流奠定了基础。 <div>
arXiv:2503.07044v1 Announce Type: new 
Abstract: Data Science tasks are multifaceted, dynamic, and often domain-specific. Existing LLM-based approaches largely concentrate on isolated phases, neglecting the interdependent nature of many data science tasks and limiting their capacity for comprehensive end-to-end support. We propose DatawiseAgent, a notebook-centric LLM agent framework that unifies interactions among user, agent and the computational environment through markdown and executable code cells, supporting flexible and adaptive automated data science. Built on a Finite State Transducer(FST), DatawiseAgent orchestrates four stages, including DSF-like planning, incremental execution, self-debugging, and post-filtering. Specifically, the DFS-like planning stage systematically explores the solution space, while incremental execution harnesses real-time feedback and accommodates LLM's limited capabilities to progressively complete tasks. The self-debugging and post-filtering modules further enhance reliability by diagnosing and correcting errors and pruning extraneous information. Extensive experiments on diverse tasks, including data analysis, visualization, and data modeling, show that DatawiseAgent consistently outperforms or matches state-of-the-art methods across multiple model settings. These results highlight its potential to generalize across data science scenarios and lay the groundwork for more efficient, fully automated workflows.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Rule-Based Conflict-Free Decision Framework in Swarm Confrontation</title>
<link>https://arxiv.org/abs/2503.07077</link>
<guid>https://arxiv.org/abs/2503.07077</guid>
<content:encoded><![CDATA[
<div> 关键词: 传统规则决策方法、有限状态机、抖动与死锁问题、智能代理、对抗环境<br /><br />总结:
本文提出了一种融合概率有限状态机、深度卷积网络和强化学习的新颖决策框架，旨在解决动态场景中有限状态机存在的抖动或死锁问题，以及在智能体群对抗环境下决策冲突导致的问题。该框架使得智能体能够在对抗中实现具有可解释性的智能决策，并确保决策的可靠性和适应性。通过实验证明，采用所提方法的智能体在严格的实战评估中展现出优于其他方法的人类类似的合作和竞争策略效果。 <div>
arXiv:2503.07077v1 Announce Type: new 
Abstract: Traditional rule--based decision--making methods with interpretable advantage, such as finite state machine, suffer from the jitter or deadlock(JoD) problems in extremely dynamic scenarios. To realize agent swarm confrontation, decision conflicts causing many JoD problems are a key issue to be solved. Here, we propose a novel decision--making framework that integrates probabilistic finite state machine, deep convolutional networks, and reinforcement learning to implement interpretable intelligence into agents. Our framework overcomes state machine instability and JoD problems, ensuring reliable and adaptable decisions in swarm confrontation. The proposed approach demonstrates effective performance via enhanced human--like cooperation and competitive strategies in the rigorous evaluation of real experiments, outperforming other methods.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>iManip: Skill-Incremental Learning for Robotic Manipulation</title>
<link>https://arxiv.org/abs/2503.07087</link>
<guid>https://arxiv.org/abs/2503.07087</guid>
<content:encoded><![CDATA[
<div> 关键词：技能增量学习、机器人操作、灾难性遗忘、iManip框架、Temporal Replay策略

总结:<br />
本文探讨了机器人操作领域中的关键任务——技能增量学习，旨在使机器人能够在无需重新训练的基础上学习新的操纵技能。研究中，基于RLBench基准构建了一个技能增量学习环境，发现传统的增量方法在此场景下因忽视了机器人操作任务的时间性和动作复杂性而遭受严重的灾难性遗忘问题。针对此问题，文章提出了一个名为iManip的增量操纵框架。该框架首先设计了一种时间重播策略，以在学习新技能时保持旧技能的完整性；同时，提出了可扩展的PerceiverIO结构，包括具有可扩展权重的动作提示，以适应新技能中的新动作原语。实验结果显示，iManip框架在技能增量学习方面表现出色。文章将开放源代码，包括技能增量学习环境和提出的框架。 <div>
arXiv:2503.07087v1 Announce Type: new 
Abstract: The development of a generalist agent with adaptive multiple manipulation skills has been a long-standing goal in the robotics community. In this paper, we explore a crucial task, skill-incremental learning, in robotic manipulation, which is to endow the robots with the ability to learn new manipulation skills based on the previous learned knowledge without re-training. First, we build a skill-incremental environment based on the RLBench benchmark, and explore how traditional incremental methods perform in this setting. We find that they suffer from severe catastrophic forgetting due to the previous methods on classification overlooking the characteristics of temporality and action complexity in robotic manipulation tasks. Towards this end, we propose an incremental Manip}ulation framework, termed iManip, to mitigate the above issues. We firstly design a temporal replay strategy to maintain the integrity of old skills when learning new skill. Moreover, we propose the extendable PerceiverIO, consisting of an action prompt with extendable weight to adapt to new action primitives in new skill. Extensive experiments show that our framework performs well in Skill-Incremental Learning. Codes of the skill-incremental environment with our framework will be open-source.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Correctness Learning: Deductive Verification Guided Learning for Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2503.07096</link>
<guid>https://arxiv.org/abs/2503.07096</guid>
<content:encoded><![CDATA[
<div> 关键词: 正确性学习 (Correctness Learning), 归纳验证方法 ( Deductive Verification Methods ), 历史高质量方案 (Historical High-Quality Schemes), 模式驱动正确性学习 (Pattern-Driven Correctness Learning, PDCL), 决策优化 (Decision-Making Optimization)

总结:<br />
本文提出了一个新的框架——正确性学习（CL），旨在增强人与AI在安全关键领域的协作。该框架结合了归纳验证方法和历史高质量方案中的洞察力，特别是关注共享资源任务优先级变化等典型模式，为智能代理的学习和决策提供指导。文章进一步提出模式驱动的正确性学习（PDCL），通过形式化建模和推理系统代理基于历史高质量方案的自适应行为或“正确性模式”，捕获这些方案中的内在逻辑关系。利用这些逻辑信息作为指导，建立了一个用于引导智能决策模型向历史高质量方案所反映的“正确性模式”靠拢的判断和反馈机制。通过对多个工作条件和核心参数的广泛实验验证了该框架的各个组件的有效性，并表明其能够提高决策制定和资源配置的优化效果。 <div>
arXiv:2503.07096v1 Announce Type: new 
Abstract: Despite significant progress in AI and decision-making technologies in safety-critical fields, challenges remain in verifying the correctness of decision output schemes and verification-result driven design. We propose correctness learning (CL) to enhance human-AI collaboration integrating deductive verification methods and insights from historical high-quality schemes. The typical pattern hidden in historical high-quality schemes, such as change of task priorities in shared resources, provides critical guidance for intelligent agents in learning and decision-making. By utilizing deductive verification methods, we proposed patten-driven correctness learning (PDCL), formally modeling and reasoning the adaptive behaviors-or 'correctness pattern'-of system agents based on historical high-quality schemes, capturing the logical relationships embedded within these schemes. Using this logical information as guidance, we establish a correctness judgment and feedback mechanism to steer the intelligent decision model toward the 'correctness pattern' reflected in historical high-quality schemes. Extensive experiments across multiple working conditions and core parameters validate the framework's components and demonstrate its effectiveness in improving decision-making and resource optimization.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ASTRA: A Negotiation Agent with Adaptive and Strategic Reasoning through Action in Dynamic Offer Optimization</title>
<link>https://arxiv.org/abs/2503.07129</link>
<guid>https://arxiv.org/abs/2503.07129</guid>
<content:encoded><![CDATA[
<div> 关键词：谈判代理、ASTRA框架、对手建模、Tit-for-Tat互惠原则、线性规划

总结:<br />
本文提出了一种基于原则的谈判代理方法，该方法运用名为ASTRA的新框架，旨在解决现有谈判代理在人类行为理解、对对手行为适应性和战略推理方面的局限性。ASTRA主要包括三个阶段：(1) 对手行为解读，(2) 通过线性规划求解器优化还价策略，以及(3) 根据谈判战术和对方接受概率选择报价。通过模拟实验和人类评估，这种代理能够有效适应对手策略的变化，通过增强适应性和战略推理能力实现更优的谈判结果。此外，它还能作为一种强大的教练工具，提供可解释的战略反馈和最优报价建议。 <div>
arXiv:2503.07129v1 Announce Type: new 
Abstract: Negotiation requires dynamically balancing self-interest and cooperation to maximize one's own utility. Yet, existing agents struggle due to bounded rationality in human data, low adaptability to counterpart behavior, and limited strategic reasoning. To address this, we introduce principle-driven negotiation agents, powered by ASTRA, a novel framework for turn-level offer optimization grounded in two core principles: opponent modeling and Tit-for-Tat reciprocity. ASTRA operates in three stages: (1) interpreting counterpart behavior, (2) optimizing counteroffers via a linear programming (LP) solver, and (3) selecting offers based on negotiation tactics and the partner's acceptance probability. Through simulations and human evaluations, our agent effectively adapts to an opponent's shifting stance and achieves favorable outcomes through enhanced adaptability and strategic reasoning. Beyond improving negotiation performance, it also serves as a powerful coaching tool, offering interpretable strategic feedback and optimal offer recommendations.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DeFine: A Decomposed and Fine-Grained Annotated Dataset for Long-form Article Generation</title>
<link>https://arxiv.org/abs/2503.07170</link>
<guid>https://arxiv.org/abs/2503.07170</guid>
<content:encoded><![CDATA[
<div> 关键词: DeFine、LFAG、分解策略、多级标注、生成模型

总结:
<br />
为了解决长篇幅文章生成（LFAG）中逻辑一致性、主题全面性和叙事连贯性等方面的挑战，研究者们提出了DeFine——一个用于长文生成的分解与精细化标注数据集。DeFine的特点在于其层次化的分解策略和结合领域专业知识的多级标注设计，可实现对文章生成的细粒度控制和深度增强。为了构建该数据集，研究者提出了一种多代理协同的工作流程，将生成过程系统地划分为四个部分：数据挖掘器、引用检索器、Q&amp;A注释器和数据清洗器。为了验证DeFine的有效性，研究者设计并测试了三个LFAG基线模型，并使用DeFine训练数据对Qwen2-7b-Instruct模型进行微调。实验结果表明，在文本质量、主题覆盖范围、信息深度和内容保真度等方面有显著提升。该数据集已公开，旨在促进未来相关领域的研究。 <div>
arXiv:2503.07170v1 Announce Type: new 
Abstract: Long-form article generation (LFAG) presents challenges such as maintaining logical consistency, comprehensive topic coverage, and narrative coherence across extended articles. Existing datasets often lack both the hierarchical structure and fine-grained annotation needed to effectively decompose tasks, resulting in shallow, disorganized article generation. To address these limitations, we introduce DeFine, a Decomposed and Fine-grained annotated dataset for long-form article generation. DeFine is characterized by its hierarchical decomposition strategy and the integration of domain-specific knowledge with multi-level annotations, ensuring granular control and enhanced depth in article generation. To construct the dataset, a multi-agent collaborative pipeline is proposed, which systematically segments the generation process into four parts: Data Miner, Cite Retreiver, Q&amp;A Annotator and Data Cleaner. To validate the effectiveness of DeFine, we designed and tested three LFAG baselines: the web retrieval, the local retrieval, and the grounded reference. We fine-tuned the Qwen2-7b-Instruct model using the DeFine training dataset. The experimental results showed significant improvements in text quality, specifically in topic coverage, depth of information, and content fidelity. Our dataset publicly available to facilitate future research.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ReelWave: A Multi-Agent Framework Toward Professional Movie Sound Generation</title>
<link>https://arxiv.org/abs/2503.07217</link>
<guid>https://arxiv.org/abs/2503.07217</guid>
<content:encoded><![CDATA[
<div> 关键词：ReelWave、多代理框架、音频生成、电影制作过程、跨注意力模块<br /><br />总结:<br />
本文提出了名为ReelWave的多代理框架，用于电影制作中的生成式音频应用。该框架通过训练预测模型捕捉到与画面同步的“画面上”声音的语义和时间变化控制信号，包括响度、音高和音色，并将这三个参数作为条件输入至跨注意力模块。接着，通过多个具有特定角色的通信智能体之间的协作互动，框架推断并补充了“画面上”之外的声音。其中还有一个智能体充当导演进行监督。此外，针对由多个场景组成的视频（如从长时间电影中截取的片段）这种情况，该框架能捕获更丰富的基于视频剪辑的音频生成上下文。 <div>
arXiv:2503.07217v1 Announce Type: new 
Abstract: Film production is an important application for generative audio, where richer context is provided through multiple scenes. In ReelWave, we propose a multi-agent framework for audio generation inspired by the professional movie production process. We first capture semantic and temporal synchronized "on-screen" sound by training a prediction model that predicts three interpretable time-varying audio control signals comprising loudness, pitch, and timbre. These three parameters are subsequently specified as conditions by a cross-attention module. Then, our framework infers "off-screen" sound to complement the generation through cooperative interaction between communicative agents. Each agent takes up specific roles similar to the movie production team and is supervised by an agent called the director. Besides, we investigate when the conditional video consists of multiple scenes, a case frequently seen in videos extracted from movies of considerable length. Consequently, our framework can capture a richer context of audio generation conditioned on video clips extracted from movies.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning and planning for optimal synergistic human-robot coordination in manufacturing contexts</title>
<link>https://arxiv.org/abs/2503.07238</link>
<guid>https://arxiv.org/abs/2503.07238</guid>
<content:encoded><![CDATA[
<div> 关键词: 协作机器人、任务分配、调度模型、混合整数非线性规划、安全效率

总结:
本文提出了一种基于混合整数非线性规划的人工智能感知的任务分配和调度模型，旨在优化协作机器人细胞中的效率与安全性。该模型从任务规划阶段开始考虑，利用贝叶斯估计学习并考虑了由机器人安全约束产生的双任务执行间的耦合效应（即协同效应）。通过马尔科夫链蒙特卡洛方法推断协同系数的后验概率分布，从而根据操作员的存在情况调整计划的名义持续时间。模拟和实验结果表明，所提出的方案能够生成更优的人工智能感知任务计划，减少代理人之间的无效干扰，增大人机距离，并能实现最高达18%的流程执行时间缩短。<br /><br /> <div>
arXiv:2503.07238v1 Announce Type: new 
Abstract: Collaborative robotics cells leverage heterogeneous agents to provide agile production solutions. Effective coordination is essential to prevent inefficiencies and risks for human operators working alongside robots. This paper proposes a human-aware task allocation and scheduling model based on Mixed Integer Nonlinear Programming to optimize efficiency and safety starting from task planning stages. The approach exploits synergies that encode the coupling effects between pairs of tasks executed in parallel by the agents, arising from the safety constraints imposed on robot agents. These terms are learned from previous executions using a Bayesian estimation; the inference of the posterior probability distribution of the synergy coefficients is performed using the Markov Chain Monte Carlo method. The synergy enhances task planning by adapting the nominal duration of the plan according to the effect of the operator's presence. Simulations and experimental results demonstrate that the proposed method produces improved human-aware task plans, reducing unuseful interference between agents, increasing human-robot distance, and achieving up to an 18\% reduction in process execution time.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Communication-aware Multi-agent Systems Control Based on $k$-hop Distributed Observers</title>
<link>https://arxiv.org/abs/2503.07246</link>
<guid>https://arxiv.org/abs/2503.07246</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式控制策略、多智能体系统、k-hop交互、分布式状态输入观测器、稳定性保障

<br /><br />总结:
本文提出了一种分布式控制策略，用于实现基于k-hop交互的多智能体系统的控制。每个智能体设计了一个有限时间收敛的状态和输入观测器，仅利用与1-hop邻居间的通信来重构关于更远距离（2-hop及以上）智能体的信息。进一步地，文章证明了如果基于k-hop的控制策略相对于目标描述集具有集合输入到状态稳定性的特点，则可以通过观测器信息来实现团队目标并保证稳定性。 <div>
arXiv:2503.07246v1 Announce Type: new 
Abstract: We propose a distributed control strategy to allow the control of a multi-agent system requiring k-hop interactions based on the design of distributed state and input observers. In particular, we design for each agent a finite time convergent state and input observer that exploits only the communication with the 1-hop neighbors to reconstruct the information regarding those agents at a 2-hop distance or more. We then demonstrate that if the k-hop based control strategy is set-Input to State Stable with respect to the set describing the goal, then the observer information can be adopted to achieve the team objective with stability guarantees.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automatic Curriculum Design for Zero-Shot Human-AI Coordination</title>
<link>https://arxiv.org/abs/2503.07275</link>
<guid>https://arxiv.org/abs/2503.07275</guid>
<content:encoded><![CDATA[
<div> 关键词：零样本人类-AI协作、环境变化、共玩家策略、多智能体UED、Overcooked-AI环境

总结:
本文提出了一种针对零样本人类-AI协作的新方法，旨在改善AI代理与人在未知环境中的协调能力。该研究扩展了多智能体UED方法，应用于零样本人类-AI协作场景中，设计了一个新的效用函数和共玩家采样策略，以更有效地训练AI代理与人类协同工作。通过在Overcooked-AI环境中使用人类代理和真实人类进行评估，该方法相比于其他基线模型表现更优，在未见过的环境中实现了高的人类-AI协调性能。 <div>
arXiv:2503.07275v1 Announce Type: new 
Abstract: Zero-shot human-AI coordination is the training of an ego-agent to coordinate with humans without using human data. Most studies on zero-shot human-AI coordination have focused on enhancing the ego-agent's coordination ability in a given environment without considering the issue of generalization to unseen environments. Real-world applications of zero-shot human-AI coordination should consider unpredictable environmental changes and the varying coordination ability of co-players depending on the environment. Previously, the multi-agent UED (Unsupervised Environment Design) approach has investigated these challenges by jointly considering environmental changes and co-player policy in competitive two-player AI-AI scenarios. In this paper, our study extends the multi-agent UED approach to a zero-shot human-AI coordination. We propose a utility function and co-player sampling for a zero-shot human-AI coordination setting that helps train the ego-agent to coordinate with humans more effectively than the previous multi-agent UED approach. The zero-shot human-AI coordination performance was evaluated in the Overcooked-AI environment, using human proxy agents and real humans. Our method outperforms other baseline models and achieves a high human-AI coordination performance in unseen environments.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VizTrust: A Visual Analytics Tool for Capturing User Trust Dynamics in Human-AI Communication</title>
<link>https://arxiv.org/abs/2503.07279</link>
<guid>https://arxiv.org/abs/2503.07279</guid>
<content:encoded><![CDATA[
<div> 关键词：Trust、Artificial Intelligence (AI)、VizTrust、real-time visual analytics、human-agent communication

总结:<br />
本文提出了一种名为VizTrust的新工具，用于解决在人类与人工智能（AI）系统交互过程中测量用户信任的挑战。VizTrust是一款实时视觉分析工具，通过多代理协作系统捕捉和分析人机交流中的用户信任动态变化。该工具基于已建立的人机信任尺度——能力、诚信、善意和可预测性——使利益相关者能够观察到信任形成的过程，识别信任发展的模式，并精确指出影响信任的具体互动元素。VizTrust提供的实时仪表板为设计能有效响应用户信任信号的自适应对话 agent 提供了可操作的见解。 <div>
arXiv:2503.07279v1 Announce Type: new 
Abstract: Trust plays a fundamental role in shaping the willingness of users to engage and collaborate with artificial intelligence (AI) systems. Yet, measuring user trust remains challenging due to its complex and dynamic nature. While traditional survey methods provide trust levels for long conversations, they fail to capture its dynamic evolution during ongoing interactions. Here, we present VizTrust, which addresses this challenge by introducing a real-time visual analytics tool that leverages a multi-agent collaboration system to capture and analyze user trust dynamics in human-agent communication. Built on established human-computer trust scales-competence, integrity, benevolence, and predictability-, VizTrust enables stakeholders to observe trust formation as it happens, identify patterns in trust development, and pinpoint specific interaction elements that influence trust. Our tool offers actionable insights into human-agent trust formation and evolution in real time through a dashboard, supporting the design of adaptive conversational agents that responds effectively to user trust signals.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Automated Movie Generation via Multi-Agent CoT Planning</title>
<link>https://arxiv.org/abs/2503.07314</link>
<guid>https://arxiv.org/abs/2503.07314</guid>
<content:encoded><![CDATA[
<div> 关键词：MovieAgent、多智能体Chain of Thought规划、自动化电影生成、长视频生成、剧本忠实性

<br /><br />总结:
本文介绍了MovieAgent，这是一个利用多智能体Chain of Thought（CoT）规划进行自动电影生成的框架。MovieAgent具备两个主要优点：一是首次探索并定义了自动化电影/长视频生成的范式，能够在给定剧本和角色库的情况下，自动生成具有连贯叙事、人物一致性、同步字幕及稳定音频的多场景、多镜头长视频；二是通过引入层次化的CoT推理过程，自动规划场景、摄像设置和电影拍摄手法，大大减少了人力成本。实验表明，MovieAgent在剧本忠实性、人物一致性和叙事连贯性等方面达到了新的最优水平。MovieAgent为完全自动化的电影生成提供了新的思路和进展。项目代码与网站已公开发布。 <div>
arXiv:2503.07314v1 Announce Type: new 
Abstract: Existing long-form video generation frameworks lack automated planning, requiring manual input for storylines, scenes, cinematography, and character interactions, resulting in high costs and inefficiencies. To address these challenges, we present MovieAgent, an automated movie generation via multi-agent Chain of Thought (CoT) planning. MovieAgent offers two key advantages: 1) We firstly explore and define the paradigm of automated movie/long-video generation. Given a script and character bank, our MovieAgent can generates multi-scene, multi-shot long-form videos with a coherent narrative, while ensuring character consistency, synchronized subtitles, and stable audio throughout the film. 2) MovieAgent introduces a hierarchical CoT-based reasoning process to automatically structure scenes, camera settings, and cinematography, significantly reducing human effort. By employing multiple LLM agents to simulate the roles of a director, screenwriter, storyboard artist, and location manager, MovieAgent streamlines the production pipeline. Experiments demonstrate that MovieAgent achieves new state-of-the-art results in script faithfulness, character consistency, and narrative coherence. Our hierarchical framework takes a step forward and provides new insights into fully automated movie generation. The code and project website are available at: https://github.com/showlab/MovieAgent and https://weijiawu.github.io/MovieAgent.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Experimental Exploration: Investigating Cooperative Interaction Behavior Between Humans and Large Language Model Agents</title>
<link>https://arxiv.org/abs/2503.07320</link>
<guid>https://arxiv.org/abs/2503.07320</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、AI代理、合作行为、囚徒困境游戏、人类偏见

总结:<br />
该研究考察了人类与具有不同特性（声称的人类、声称的规则基础AI代理和LLM代理）的大规模语言模型增强的自主AI代理在重复进行的囚徒困境游戏中的合作行为。实验发现，参与者的合作行为显著受AI代理所声称的特性影响，并存在参与者性别与AI特性的交互效应。此外，分析了人类的行为模式，包括完成游戏的时间、主动的有利行为以及对修复努力的接受程度。这项研究为理解人类与LLM代理在竞争合作情境下的互动提供了新视角，并强调了了解人类对AI代理的偏见及其表现出的行为如何影响未来人机合作动态的重要性。 <div>
arXiv:2503.07320v1 Announce Type: new 
Abstract: With the rise of large language models (LLMs), AI agents as autonomous decision-makers present significant opportunities and challenges for human-AI cooperation. While many studies have explored human cooperation with AI as tools, the role of LLM-augmented autonomous agents in competitive-cooperative interactions remains under-examined. This study investigates human cooperative behavior by engaging 30 participants who interacted with LLM agents exhibiting different characteristics (purported human, purported rule-based AI agent, and LLM agent) in repeated Prisoner's Dilemma games. Findings show significant differences in cooperative behavior based on the agents' purported characteristics and the interaction effect of participants' genders and purported characteristics. We also analyzed human response patterns, including game completion time, proactive favorable behavior, and acceptance of repair efforts. These insights offer a new perspective on human interactions with LLM agents in competitive cooperation contexts, such as virtual avatars or future physical entities. The study underscores the importance of understanding human biases toward AI agents and how observed behaviors can influence future human-AI cooperation dynamics.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dynamic Path Navigation for Motion Agents with LLM Reasoning</title>
<link>https://arxiv.org/abs/2503.07323</link>
<guid>https://arxiv.org/abs/2503.07323</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，路径规划，避障，导航，多智能体协调

总结:
本文探讨了大型语言模型（LLMs）在空间路径规划和无障碍轨迹生成方面的潜力，这是该领域的一个初步研究。文章构建了一个数据集并提出了评估协议，通过使用直线连接的锚点来表示路径，使LLMs能处理多方向移动任务，从而展示出较强的零样本导航和路径生成能力。实验表明，现代LLMs能够在自主导航和运动生成过程中有效地避开障碍物，并进行目标导向的路径优化。此外，这种方法还能让单个LLM运动代理在静态环境中进行空间推理，并将这种能力无缝扩展到动态环境中多个运动代理的协同配合。与依赖单一步骤规划或局部策略的传统方法不同，基于LLMs的无训练方法实现了全局、动态、闭环规划以及自主解决碰撞问题的能力。 <div>
arXiv:2503.07323v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated strong generalizable reasoning and planning capabilities. However, their efficacies in spatial path planning and obstacle-free trajectory generation remain underexplored. Leveraging LLMs for navigation holds significant potential, given LLMs' ability to handle unseen scenarios, support user-agent interactions, and provide global control across complex systems, making them well-suited for agentic planning and humanoid motion generation. As one of the first studies in this domain, we explore the zero-shot navigation and path generation capabilities of LLMs by constructing a dataset and proposing an evaluation protocol. Specifically, we represent paths using anchor points connected by straight lines, enabling movement in various directions. This approach offers greater flexibility and practicality compared to previous methods while remaining simple and intuitive for LLMs. We demonstrate that, when tasks are well-structured in this manner, modern LLMs exhibit substantial planning proficiency in avoiding obstacles while autonomously refining navigation with the generated motion to reach the target. Further, this spatial reasoning ability of a single LLM motion agent interacting in a static environment can be seamlessly generalized in multi-motion agents coordination in dynamic environments. Unlike traditional approaches that rely on single-step planning or local policies, our training-free LLM-based method enables global, dynamic, closed-loop planning, and autonomously resolving collision issues.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Temporal Triplane Transformers as Occupancy World Models</title>
<link>https://arxiv.org/abs/2503.07338</link>
<guid>https://arxiv.org/abs/2503.07338</guid>
<content:encoded><![CDATA[
<div> 关键词：T$^3$Former、世界模型、自动驾驶、4D占用模型、时空运动特征

<br /><br />总结:
本文提出了一种新的用于自动驾驶的4D占用世界模型——T$^3$Former，旨在解决现有方法在捕捉细粒度环境变化与移动轨迹之间关系以及实时预测上的难题。T$^3$Former首先通过预训练得到一种紧凑的三平面表示，该表示能有效地压缩三维语义上被占用的环境。接着，从历史三平面中提取多尺度时间运动特征，并采用自回归方法迭代预测下一时刻的三平面变化。最后，T$^3$Former将预测的三平面变化与先前的变化结合，解码成未来的占用结果和自主车辆的运动轨迹。实验结果显示，T$^3$Former在保持高精度（提升平均IoU至36.09，减少平均绝对规划误差至1.0米）的同时，还实现了更快的推理速度（提高到26 FPS），性能优越。 <div>
arXiv:2503.07338v1 Announce Type: new 
Abstract: Recent years have seen significant advances in world models, which primarily focus on learning fine-grained correlations between an agent's motion trajectory and the resulting changes in its surrounding environment. However, existing methods often struggle to capture such fine-grained correlations and achieve real-time predictions. To address this, we propose a new 4D occupancy world model for autonomous driving, termed T$^3$Former. T$^3$Former begins by pre-training a compact triplane representation that efficiently compresses the 3D semantically occupied environment. Next, T$^3$Former extracts multi-scale temporal motion features from the historical triplane and employs an autoregressive approach to iteratively predict the next triplane changes. Finally, T$^3$Former combines the triplane changes with the previous ones to decode them into future occupancy results and ego-motion trajectories. Experimental results demonstrate the superiority of T$^3$Former, achieving 1.44$\times$ faster inference speed (26 FPS), while improving the mean IoU to 36.09 and reducing the mean absolute planning error to 1.0 meters.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Artificial Utopia: Simulation and Intelligent Agents for a Democratised Future</title>
<link>https://arxiv.org/abs/2503.07364</link>
<guid>https://arxiv.org/abs/2503.07364</guid>
<content:encoded><![CDATA[
<div> 关键词：bottom-up democratisation, artificial intelligence, Artificial Utopia, agent-based modelling, reinforcement learning

总结:
本文提出了一种名为“人工乌托邦”的新颖研究议程，该议程关注于利用形式化、计算方法以及人工智能来研究自下而上的民主化努力。作者认为，与现实世界相比，人工乌托邦为测试新型政治理念和经济政策提供了风险较低的虚拟测试环境。随着越来越先进的模拟和智能方法的发展，例如代理建模、强化学习和大型语言模型等，这些都有助于推进这一进程。文章通过公民大会和民主企业的两个制度例子，阐述了这些模拟方法如何为人工乌托邦的研究做出贡献。针对21世纪面临的气候变化、社会不平等和冲突等挑战，作者强调了自下而上的参与式方法作为替代传统自上而下体系的潜力，并指出对集体人类行为或文化的理解和辩论仍然不足。 <div>
arXiv:2503.07364v1 Announce Type: new 
Abstract: Prevailing top-down systems in politics and economics struggle to keep pace with the pressing challenges of the 21st century, such as climate change, social inequality and conflict. Bottom-up democratisation and participatory approaches in politics and economics are increasingly seen as promising alternatives to confront and overcome these issues, often with utopian overtones, as proponents believe they may dramatically reshape political, social and ecological futures for the better and in contrast to contemporary authoritarian tendencies across various countries. Institutional specifics and the associated collective human behavior or culture remains little understood and debated, however. In this article, I propose a novel research agenda focusing on utopian democratisation efforts with formal and computational methods as well as with artificial intelligence - I call this agenda Artificial Utopia. Artificial Utopias provide safe testing grounds for new political ideas and economic policies in-silico with reduced risk of negative consequences as compared to testing ideas in real-world contexts. An increasing number of advanced simulation and intelligence methods, that aim at representing human cognition and collective decision-making in more realistic ways, could benefit this process. This includes agent-based modelling, reinforcement learning, large language models and more. I clarify what some of these simulation approaches can contribute to the study of Artificial Utopias with the help of two institutional examples: the citizen assembly and the democratic firm.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>AttentionSwarm: Reinforcement Learning with Attention Control Barier Function for Crazyflie Drones in Dynamic Environments</title>
<link>https://arxiv.org/abs/2503.07376</link>
<guid>https://arxiv.org/abs/2503.07376</guid>
<content:encoded><![CDATA[
<div> 关键词：AttentionSwarm、安全控制、环境基准、注意力模型、控制 barrier 函数(CBF)

总结:

我们提出了一种名为AttentionSwarm的新颖基准测试，用于评估在包含障碍物的着陆环境、竞争性的无人机游戏场景以及动态无人机竞速场景中安全而高效的群体控制。该方法的核心是以注意力模型为基础的控制 Barrier 函数（CBF）框架，它将注意力机制与安全性关键的控制理论相结合，实现了实时碰撞避障和轨迹优化。通过使用注意力权重动态优先处理临近的关键障碍物和群组成员，CBFs则能正式确保执行碰撞避免约束以保证安全。利用Crazyflie 2.1微型四旋翼无人机进行安全注意力网络算法的实际开发与室内评估，并借助Vicon运动捕捉系统实现精确定位和控制。实验结果显示，我们的系统在动态着陆环境中实现了平均耗时23秒、误差仅3.02厘米的精准着陆，以及无人机游戏环境中的100%无碰撞导航，而在动态多智能体无人机竞速环境中也达到了95%的无碰撞航行率。这一工作为那些重视安全性与快速响应的动态环境应用提供了具有潜力的基础。 <div>
arXiv:2503.07376v1 Announce Type: new 
Abstract: We introduce AttentionSwarm, a novel benchmark designed to evaluate safe and efficient swarm control across three challenging environments: a landing environment with obstacles, a competitive drone game setting, and a dynamic drone racing scenario. Central to our approach is the Attention Model Based Control Barrier Function (CBF) framework, which integrates attention mechanisms with safety-critical control theory to enable real-time collision avoidance and trajectory optimization. This framework dynamically prioritizes critical obstacles and agents in the swarms vicinity using attention weights, while CBFs formally guarantee safety by enforcing collision-free constraints. The safe attention net algorithm was developed and evaluated using a swarm of Crazyflie 2.1 micro quadrotors, which were tested indoors with the Vicon motion capture system to ensure precise localization and control. Experimental results show that our system achieves landing accuracy of 3.02 cm with a mean time of 23 s and collision-free landings in a dynamic landing environment, 100% and collision-free navigation in a drone game environment, and 95% and collision-free navigation for a dynamic multiagent drone racing environment, underscoring its effectiveness and robustness in real-world scenarios. This work offers a promising foundation for applications in dynamic environments where safety and fastness are paramount.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Q-MARL: A quantum-inspired algorithm using neural message passing for large-scale multi-agent reinforcement learning</title>
<link>https://arxiv.org/abs/2503.07397</link>
<guid>https://arxiv.org/abs/2503.07397</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-MARL、多智能体强化学习、无中心化、子图、消息传递神经网络

总结:
本文提出了一种名为Q-MARL的全新无中心化深度强化学习架构，该架构受量子化学中基于图的方法启发，用于预测分子性质。Q-MARL适用于大规模多智能体强化学习场景，无需假设共同奖励或代理顺序。每个智能体视为其环境中的动态变化部分，并以自身为中心构建局部邻域关系。每个角色被形式化为子图，子图作为训练样本。通过消息传递神经网络实现局部邻域内的顶点和边充分交互，并利用一个参数控制子图的深度来减轻训练负担。测试阶段，智能体的行为决策在其所在的所有子图上进行局部集成，从而获得稳健性。相比于其他方法难以处理超过50个智能体的情况，Q-MARL能轻松调度数千个智能体。理论分析证明了Q-MARL的改进与收敛性，仿真结果显示其在典型的合作与竞争场景中具有更快的训练速度和更低的训练损失。 <div>
arXiv:2503.07397v1 Announce Type: new 
Abstract: Inspired by a graph-based technique for predicting molecular properties in quantum chemistry -- atoms' position within molecules in three-dimensional space -- we present Q-MARL, a completely decentralised learning architecture that supports very large-scale multi-agent reinforcement learning scenarios without the need for strong assumptions like common rewards or agent order. The key is to treat each agent as relative to its surrounding agents in an environment that is presumed to change dynamically. Hence, in each time step, an agent is the centre of its own neighbourhood and also a neighbour to many other agents. Each role is formulated as a sub-graph, and each sub-graph is used as a training sample. A message-passing neural network supports full-scale vertex and edge interaction within a local neighbourhood, while a parameter governing the depth of the sub-graphs eases the training burden. During testing, an agent's actions are locally ensembled across all the sub-graphs that contain it, resulting in robust decisions. Where other approaches struggle to manage 50 agents, Q-MARL can easily marshal thousands. A detailed theoretical analysis proves improvement and convergence, and simulations with the typical collaborative and competitive scenarios show dramatically faster training speeds and reduced training losses.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Safe Robot Foundation Models</title>
<link>https://arxiv.org/abs/2503.07404</link>
<guid>https://arxiv.org/abs/2503.07404</guid>
<content:encoded><![CDATA[
<div> 关键词：robot foundation models, safety, ATACOM, safe reinforcement learning, generalist policies

总结:<br />
本文关注于机器人基础模型在安全关键环境中的应用问题。研究指出，当前工作虽着重于政策泛化能力以适应多种任务，但并未充分解决安全性这一关键需求。为此，文章提出了一种安全层设计，旨在适当地限制任何泛化策略的动作空间。该方法利用ATACOM，一种确保安全状态转换的安全强化学习算法，将其扩展至泛化策略中，从而在无需特定安全微调的情况下，促进这些策略在安全敏感场景中的部署。通过在一个空气曲棍球环境中展示该安全层的有效性，证明了其能防止击打冰球的智能体与周围环境发生碰撞，这是泛化策略常见的失败情况。 <div>
arXiv:2503.07404v1 Announce Type: new 
Abstract: Robot foundation models hold the potential for deployment across diverse environments, from industrial applications to household tasks. While current research focuses primarily on the policies' generalization capabilities across a variety of tasks, it fails to address safety, a critical requirement for deployment on real-world systems. In this paper, we introduce a safety layer designed to constrain the action space of any generalist policy appropriately. Our approach uses ATACOM, a safe reinforcement learning algorithm that creates a safe action space and, therefore, ensures safe state transitions. By extending ATACOM to generalist policies, our method facilitates their deployment in safety-critical scenarios without requiring any specific safety fine-tuning. We demonstrate the effectiveness of this safety layer in an air hockey environment, where it prevents a puck-hitting agent from colliding with its surroundings, a failure observed in generalist policies.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LLMs syntactically adapt their language use to their conversational partner</title>
<link>https://arxiv.org/abs/2503.07457</link>
<guid>https://arxiv.org/abs/2503.07457</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、对话适应、大规模语言模型、语义选择、对话语料库

总结:
本文研究了大型语言模型（LLMs）是否会在对话中表现出与人类类似的语言使用适应性行为。通过对LLM之间的对话构建语料库进行实证分析，发现两个LLM在对话过程中会逐渐做出更为相似的句法选择，从而证实现代LLMs至少在某种程度上会对其对话伙伴的语言使用进行适应。 <div>
arXiv:2503.07457v1 Announce Type: new 
Abstract: It has been frequently observed that human speakers align their language use with each other during conversations. In this paper, we study empirically whether large language models (LLMs) exhibit the same behavior of conversational adaptation. We construct a corpus of conversations between LLMs and find that two LLM agents end up making more similar syntactic choices as conversations go on, confirming that modern LLMs adapt their language use to their conversational partners in at least a rudimentary way.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MedAgentsBench: Benchmarking Thinking Models and Agent Frameworks for Complex Medical Reasoning</title>
<link>https://arxiv.org/abs/2503.07459</link>
<guid>https://arxiv.org/abs/2503.07459</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models, MedAgentsBench, 医疗问答, 多步临床推理, 性能评估

总结:
本文介绍了MedAgentsBench，这是一个针对大型语言模型（LLMs）的全新医疗问答基准测试。该基准着重于需要多步临床推理、诊断制定和治疗计划等复杂医疗问题，旨在克服现有评测中的三个主要局限：简单问题过多导致基础模型也能取得高分、采样与评价协议不一致以及对性能、成本和推理时间之间关系缺乏系统分析。通过实验，文章表明最新的思考型模型DeepSeek R1和OpenAI o3在复杂的医疗推理任务中表现出色。同时，基于搜索的高级代理方法相比传统方法提供了更优的成本效益比。研究还揭示了在复杂问题上不同模型家族之间的显著性能差距，并为不同的计算约束条件指出了最佳模型选择。MedAgentsBench及其评估框架已在GitHub上公开发布。 <div>
arXiv:2503.07459v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown impressive performance on existing medical question-answering benchmarks. This high performance makes it increasingly difficult to meaningfully evaluate and differentiate advanced methods. We present MedAgentsBench, a benchmark that focuses on challenging medical questions requiring multi-step clinical reasoning, diagnosis formulation, and treatment planning-scenarios where current models still struggle despite their strong performance on standard tests. Drawing from seven established medical datasets, our benchmark addresses three key limitations in existing evaluations: (1) the prevalence of straightforward questions where even base models achieve high performance, (2) inconsistent sampling and evaluation protocols across studies, and (3) lack of systematic analysis of the interplay between performance, cost, and inference time. Through experiments with various base models and reasoning methods, we demonstrate that the latest thinking models, DeepSeek R1 and OpenAI o3, exhibit exceptional performance in complex medical reasoning tasks. Additionally, advanced search-based agent methods offer promising performance-to-cost ratios compared to traditional approaches. Our analysis reveals substantial performance gaps between model families on complex questions and identifies optimal model selections for different computational constraints. Our benchmark and evaluation framework are publicly available at https://github.com/gersteinlab/medagents-benchmark.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Think Before You Segment: High-Quality Reasoning Segmentation with GPT Chain of Thoughts</title>
<link>https://arxiv.org/abs/2503.07503</link>
<guid>https://arxiv.org/abs/2503.07503</guid>
<content:encoded><![CDATA[
<div> 关键词: reasoning segmentation, 大规模语言模型, GPT, 链条思考, 无监督训练

总结:
本文提出了一种无需训练的推理分割框架——ThinkFirst，用于解决复杂、隐含和非视觉查询文本下的分割任务。该框架利用GPT（如GPT-4）的链条思考能力生成图像的详细描述，再将此描述传递给语言指导的分割助手以辅助分割过程。用户可以借助多模态输入（如简单文字和图像涂鸦）与分割代理进行交互，实现连续细化或沟通。实验表明，ThinkFirst方法在各种对象上的表现显著优于原始推理分割代理，无论定性还是定量指标均有提升，同时对用户提供的提示依赖度降低。 <div>
arXiv:2503.07503v1 Announce Type: new 
Abstract: Reasoning segmentation is a challenging vision-language task that aims to output the segmentation mask with respect to a complex, implicit, and even non-visual query text. Previous works incorporated multimodal Large Language Models (MLLMs) with segmentation models to approach the difficult problem. However, their segmentation quality often falls short in complex cases, particularly when dealing with out-of-domain objects with intricate structures, blurry boundaries, occlusions, or high similarity with surroundings. In this paper, we introduce ThinkFirst, a training-free reasoning segmentation framework that leverages GPT's chain of thought to address these challenging cases. Our approach allows GPT-4o or other powerful MLLMs to generate a detailed, chain-of-thought description of an image. This summarized description is then passed to a language-instructed segmentation assistant to aid the segmentation process. Our framework allows users to easily interact with the segmentation agent using multimodal inputs, such as easy text and image scribbles, for successive refinement or communication. We evaluate the performance of ThinkFirst on diverse objects. Extensive experiments show that, this zero-shot-CoT approach significantly improves the vanilla reasoning segmentation agent, both qualitatively and quantitatively, while being less sensitive or critical to user-supplied prompts after Thinking First.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bi-Directional Mental Model Reconciliation for Human-Robot Interaction with Large Language Models</title>
<link>https://arxiv.org/abs/2503.07547</link>
<guid>https://arxiv.org/abs/2503.07547</guid>
<content:encoded><![CDATA[
<div> 关键词：人类-机器人交互、理论思维、心理模型、双向和解框架、大规模语言模型

<br />
总结:
本文提出了一种针对人类-机器人交互中的双向心理模型和解框架。该框架利用大规模语言模型，通过半结构化的自然语言对话促进双方模型对齐。与以往假设一方拥有正确模型供另一方校准的工作不同，该框架允许人类和机器人都能在交互过程中识别并沟通缺失的任务相关信息，进而迭代地朝着共享的心理模型发展。 <div>
arXiv:2503.07547v1 Announce Type: new 
Abstract: In human-robot interactions, human and robot agents maintain internal mental models of their environment, their shared task, and each other. The accuracy of these representations depends on each agent's ability to perform theory of mind, i.e. to understand the knowledge, preferences, and intentions of their teammate. When mental models diverge to the extent that it affects task execution, reconciliation becomes necessary to prevent the degradation of interaction. We propose a framework for bi-directional mental model reconciliation, leveraging large language models to facilitate alignment through semi-structured natural language dialogue. Our framework relaxes the assumption of prior model reconciliation work that either the human or robot agent begins with a correct model for the other agent to align to. Through our framework, both humans and robots are able to identify and communicate missing task-relevant context during interaction, iteratively progressing toward a shared mental model.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Design as Hope: Reimagining Futures for Seemingly Doomed Problems</title>
<link>https://arxiv.org/abs/2503.07586</link>
<guid>https://arxiv.org/abs/2503.07586</guid>
<content:encoded><![CDATA[
<div> 关键词: 设计、希望、工作坊、设计方法论、社区驱动

总结:
本文介绍了arXiv:2503.07586v1中关于一场为期一天的工作坊的内容，该工作坊探讨了如何利用设计方法论（如问题重构、参与式设计、推测性设计和批判性设计）来赋予研究群体推动现实世界有意义变革的能力。通过将设计思维与希望理论相结合——即把希望视为“目标导向”、“路径思考”和“代理思考”的过程——研究者可以超越单纯关注损害缓解，转而重新构想替代未来。参与者将通过实践活动进行问题重构，建立有关希望的设计方法分类，并探索社区驱动的设计方法如何支撑社会和个人层面的希望努力。同时，工作坊也审视了在设计研究中利用希望所面临的伦理和实践边界。活动结束时，参与者将获得将充满希望的设计方法融入自身研究的具体策略以及持续合作的网络。最终，文章强调，充满希望的设计不仅是行动和解决问题的实用工具，更是孕育韧性并设想转型未来的一种催化剂。 <div>
arXiv:2503.07586v1 Announce Type: new 
Abstract: Design has the power to cultivate hope, especially in the face of seemingly intractable societal challenges. This one-day workshop explores how design methodologies -- ranging from problem reframing to participatory, speculative, and critical design -- can empower research communities to drive meaningful real-world changes. By aligning design thinking with hope theory -- framework of viewing hope as "goal-directed," "pathways," and "agentic" thinking processes -- we aim to examine how researchers can move beyond focusing on harm mitigation and instead reimagine alternative futures. Through hands-on activities, participants will engage in problem reframing, develop a taxonomy of design methods related to hope, and explore how community-driven design approaches can sustain efforts toward societal and individual hope. The workshop also interrogates the ethical and practical boundaries of leveraging hope in design research. By the end of the session, participants will leave with concrete strategies for integrating a hopeful design approach into their research, as well as a network for ongoing collaboration. Ultimately, we position hopeful design not just as a practical tool for action and problem-solving but as a catalyst for cultivating resilience and envisioning transformative futures.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Online Coalition Formation under Random Arrival or Coalition Dissolution</title>
<link>https://arxiv.org/abs/2306.16965</link>
<guid>https://arxiv.org/abs/2306.16965</guid>
<content:encoded><![CDATA[
<div> 关键词：coalition formation, 在线variant, 竞争比, 随机顺序, 立即决策, 解散联盟

总结:
本文研究了联盟形成问题在网络环境下的两种扩展模型。首先关注在线联盟形成问题中随机顺序到达的代理人的场景，发现对于经典的贪婪算法，其竞争比为$\Theta\left(\frac{1}{n^2}\right)$。相比之下，通过交替等待和贪婪阶段的算法可以实现$\Theta\left(\frac{1}{n}\right)$的竞争比。其次，文章考虑允许联盟解散为单个实体的情况，通过与在线匹配的一般模型建立紧密联系，实现了接近最优的$\Theta\left(\frac 1n\right)$竞争比。因此，在这两个模型中，相较于基本模型中的不可避免的效用依赖，所提出的算法能够达到接近最佳的近似比。 <div>
arXiv:2306.16965v2 Announce Type: replace 
Abstract: Coalition formation explores how to partition a set of $n$ agents into disjoint coalitions according to their preferences. We consider a cardinal utility model with an additively separable aggregation of preferences and study the online variant of coalition formation, where the agents arrive in sequence. The goal is to achieve competitive social welfare. In the basic model, agents arrive in an arbitrary order and have to be assigned to coalitions immediately and irrevocably. There, the natural greedy algorithm is known to achieve an optimal competitive ratio, which heavily relies on the range of utilities.
  We complement this result by considering two related models. First, we study a model where agents arrive in a random order. We find that the competitive ratio of the greedy algorithm is $\Theta\left(\frac{1}{n^2}\right)$. In contrast, an alternative algorithm, which is based on alternating between waiting and greedy phases, can achieve a competitive ratio of $\Theta\left(\frac{1}{n}\right)$. Second, we relax the irrevocability of decisions by allowing the dissolution of coalitions into singleton coalitions. We achieve an asymptotically optimal competitive ratio of $\Theta\left(\frac 1n\right)$ by drawing a close connection to a general model of online matching. Hence, in both models, we obtain a competitive ratio that removes the unavoidable utility dependencies in the basic model and essentially matches the best possible approximation ratio by polynomial-time algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Robust and Performance Incentivizing Algorithms for Multi-Armed Bandits with Strategic Agents</title>
<link>https://arxiv.org/abs/2312.07929</link>
<guid>https://arxiv.org/abs/2312.07929</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 随机多臂赌博机问题, 在线劳动市场, 机制设计, 非均衡行为

总结:
本文研究了一个强化学习场景下的随机多臂赌博机问题变种，该问题应用于在线劳动市场等环境。在这个设定中，每条“手臂”代表具有不同性能特性的战略主体，平台（即决策者）需在每一轮选择一个主体来完成任务。与传统设置不同的是，当选择一个主体时，它可以修改其奖励值，通过吸收或提高奖励，但会增加成本。决策者需要解决一个机制设计问题以激励各主体发挥最佳表现。然而，由于即使有了有效的机制，主体仍可能存在非理性行为偏离均衡，因此决策者需要一个既能够实现激励性能又对非均衡行为有非真空保证的鲁棒算法。文中提出了一类同时满足这两个目标的带臂算法，并指出了这类算法应具备的一些直观性质。最后，通过将第二价格拍卖思想与所提算法相结合，作者展示了在决策者对主体性能特征毫无了解的情况下，此类问题也可以得到处理。 <div>
arXiv:2312.07929v2 Announce Type: replace 
Abstract: Motivated by applications such as online labor markets we consider a variant of the stochastic multi-armed bandit problem where we have a collection of arms representing strategic agents with different performance characteristics. The platform (principal) chooses an agent in each round to complete a task. Unlike the standard setting, when an arm is pulled it can modify its reward by absorbing it or improving it at the expense of a higher cost. The principle has to solve a mechanism design problem to incentivize the arms to give their best performance. However, since even with an effective mechanism agents may still deviate from rational behavior, the principal wants a robust algorithm that also gives a non-vacuous guarantee on the total accumulated rewards under non-equilibrium behavior. In this paper, we introduce a class of bandit algorithms that meet the two objectives of performance incentivization and robustness simultaneously. We do this by identifying a collection of intuitive properties that a bandit algorithm has to satisfy to achieve these objectives. Finally, we show that settings where the principal has no information about the arms' performance characteristics can be handled by combining ideas from second price auctions with our algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Stability in Online Coalition Formation</title>
<link>https://arxiv.org/abs/2312.09119</link>
<guid>https://arxiv.org/abs/2312.09119</guid>
<content:encoded><![CDATA[
<div> 关键词：Coalition formation, Online variant, Stability, Additively separable hedonic games, Dichotomy

总结:
在线联盟形成是一个根据代理人的偏好将其划分为互不相交联盟的问题。与以往大多数工作不同，该文关注的是在线版本的此问题，其中代理人按顺序到达并需要立即、不可撤销地被分配到某个联盟。现有的关于在线联盟形成的文献主要集中在最大化社会福利上，而本文则致力于在线环境中实现联盟结构的稳定性，并研究了基于单个代理人和群体代理人的最常见的稳定性概念。在加性可分解享乐主义游戏中，文章给出了一个全面的研究框架，得出了确定性算法的积极结果与随机算法的消极结果之间的二分法结论。 <div>
arXiv:2312.09119v2 Announce Type: replace 
Abstract: Coalition formation is concerned with the question of how to partition a set of agents into disjoint coalitions according to their preferences. Deviating from most of the previous work, we consider an online variant of the problem, where agents arrive in sequence. Whenever an agent arrives, they must be assigned to a coalition immediately and irrevocably. The scarce existing literature on online coalition formation has focused on maximizing social welfare, a demanding requirement, even in the offline setting. Instead, we seek to achieve \emph{stable} coalition structures online and treat the most common stability concepts based on deviations by single agents and groups of agents. We present a comprehensive picture in additively separable hedonic games, leading to dichotomies, where positive results are obtained by deterministic algorithms and negative results even hold for randomized algorithms.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Detecting mental disorder on social media: a ChatGPT-augmented explainable approach</title>
<link>https://arxiv.org/abs/2401.17477</link>
<guid>https://arxiv.org/abs/2401.17477</guid>
<content:encoded><![CDATA[
<div> 关键词：抑郁症检测、可解释人工智能、大型语言模型、BERTweet、ChatGPT

<br /><br />总结:

本文提出了一种针对数字时代社交媒体上普遍存在的抑郁症状进行及时检测的新方法。该方法融合了大型语言模型（LLMs）、可解释人工智能（XAI）和对话式智能体ChatGPT，致力于实现抑郁症检测的可解释性。文章核心内容包括：(1) 将专门用于Twitter的BERT变体——BERTweet整合进一个名为BERT-XDD的新型自解释模型中，该模型能同时提供分类与解释，通过屏蔽注意力机制实现解释功能；(2) 利用ChatGPT将技术性的解释转化为易于理解的人类评论，从而进一步提升解释的可读性。通过构建有效且模块化的可解释抑郁症检测方法，该研究有助于开发出更加负责任的数字平台，在医疗专业人士指导下促进心理健康问题的早期干预和支持。 <div>
arXiv:2401.17477v2 Announce Type: replace 
Abstract: In the digital era, the prevalence of depressive symptoms expressed on social media has raised serious concerns, necessitating advanced methodologies for timely detection. This paper addresses the challenge of interpretable depression detection by proposing a novel methodology that effectively combines Large Language Models (LLMs) with eXplainable Artificial Intelligence (XAI) and conversational agents like ChatGPT. In our methodology, explanations are achieved by integrating BERTweet, a Twitter-specific variant of BERT, into a novel self-explanatory model, namely BERT-XDD, capable of providing both classification and explanations via masked attention. The interpretability is further enhanced using ChatGPT to transform technical explanations into human-readable commentaries. By introducing an effective and modular approach for interpretable depression detection, our methodology can contribute to the development of socially responsible digital platforms, fostering early intervention and support for mental health challenges under the guidance of qualified healthcare professionals.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Composing Reinforcement Learning Policies, with Formal Guarantees</title>
<link>https://arxiv.org/abs/2402.13785</link>
<guid>https://arxiv.org/abs/2402.13785</guid>
<content:encoded><![CDATA[
<div> 关键词：控制器设计、两层结构、马尔科夫决策过程、反应式合成、强化学习

总结:
本文提出了一种针对具有两层结构环境（已知高层图和每个顶点包含马尔科夫决策过程的“房间”）的新颖控制器设计框架。该框架通过不同的设计技术分别处理高低层次任务，利用反应式合成方法为高层任务制定逻辑公式规范，并根据低层策略集合与简洁的潜在结构构建规划器，选择在每个房间应用哪个低层策略。文章介绍了一种强化学习算法，用于在潜在结构上训练低层策略，避免了模型蒸馏步骤，并确保了政策及其抽象质量的近似正确性保证。这些正式保障是该框架的主要优势，同时其还具备可扩展性（房间大且动态未知）以及低层策略的可重用性。文中通过具有移动障碍物和视觉输入的挑战性案例研究证明了该框架的可行性。<br /><br /> <div>
arXiv:2402.13785v2 Announce Type: replace 
Abstract: We propose a novel framework to controller design in environments with a two-level structure: a known high-level graph ("map") in which each vertex is populated by a Markov decision process, called a "room". The framework "separates concerns" by using different design techniques for low- and high-level tasks. We apply reactive synthesis for high-level tasks: given a specification as a logical formula over the high-level graph and a collection of low-level policies obtained together with "concise" latent structures, we construct a "planner" that selects which low-level policy to apply in each room. We develop a reinforcement learning procedure to train low-level policies on latent structures, which unlike previous approaches, circumvents a model distillation step. We pair the policy with probably approximately correct guarantees on its performance and on the abstraction quality, and lift these guarantees to the high-level task. These formal guarantees are the main advantage of the framework. Other advantages include scalability (rooms are large and their dynamics are unknown) and reusability of low-level policies. We demonstrate feasibility in challenging case studies where an agent navigates environments with moving obstacles and visual inputs.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CleanAgent: Automating Data Standardization with LLM-based Agents</title>
<link>https://arxiv.org/abs/2403.08291</link>
<guid>https://arxiv.org/abs/2403.08291</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据标准化、Pandas、大型语言模型、Dataprep.Clean、CleanAgent

总结:
本文提出了一种解决数据科学生命周期中数据标准化问题的方法。为了解决Pandas等工具在处理复杂性和定制化代码方面的挑战，他们设计了一个名为Dataprep.Clean的Python库组件，该组件通过单行代码即可实现特定列类型的标准化，显著降低了编程复杂度。进一步地，文章引入了CleanAgent框架，它将Dataprep.Clean与基于大型语言模型的代理相结合，实现了数据标准化过程的自动化，用户只需一次性提供需求，即可实现无须持续交互的自动化处理。为了展示CleanAgent的实用性，作者还开发了一个用户友好的web应用，允许用户使用真实世界的数据进行互动操作。<br /><br /> <div>
arXiv:2403.08291v3 Announce Type: replace 
Abstract: Data standardization is a crucial part of the data science life cycle. While tools like Pandas offer robust functionalities, their complexity and the manual effort required for customizing code to diverse column types pose significant challenges. Although large language models (LLMs) like ChatGPT have shown promise in automating this process through natural language understanding and code generation, it still demands expert-level programming knowledge and continuous interaction for prompt refinement. To solve these challenges, our key idea is to propose a Python library with declarative, unified APIs for standardizing different column types, simplifying the LLM's code generation with concise API calls. We first propose Dataprep.Clean, a component of the Dataprep Python Library, significantly reduces the coding complexity by enabling the standardization of specific column types with a single line of code. Then, we introduce the CleanAgent framework integrating Dataprep.Clean and LLM-based agents to automate the data standardization process. With CleanAgent, data scientists only need to provide their requirements once, allowing for a hands-free process. To demonstrate the practical utility of CleanAgent, we developed a user-friendly web application, allowing attendees to interact with it using real-world datasets.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WcDT: World-centric Diffusion Transformer for Traffic Scene Generation</title>
<link>https://arxiv.org/abs/2404.02082</link>
<guid>https://arxiv.org/abs/2404.02082</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、轨迹生成、扩散概率模型、变压器、World-Centric Diffusion Transformer (WcDT)

总结:<br />
本文提出了一种融合扩散概率模型与变压器优势的新型自动驾驶轨迹生成方法——World-Centric Diffusion Transformer (WcDT)。该框架优化了从特征提取到模型推理的整个轨迹生成过程。首先，通过将历史轨迹数据预处理为“Agent Move Statement”，并利用增强版的Denoising Diffusion Probabilistic Models (DDPM)和Diffusion with Transformer (DiT)块将其编码到潜在空间中。接着，使用多种基于变压器的编码器融合潜在特征、历史轨迹、高精度地图特征以及历史交通信号信息，以强化交通场景中各元素间的交互。最后，通过轨迹解码器对编码后的交通场景进行解码，生成多模态未来轨迹。实验证明，该方法在生成逼真且多样化的轨迹方面表现出优越性能，显示出其在自动驾驶模拟系统中的应用潜力。研究代码已开源，可在https://github.com/yangchen1997/WcDT 获取。 <div>
arXiv:2404.02082v4 Announce Type: replace 
Abstract: In this paper, we introduce a novel approach for autonomous driving trajectory generation by harnessing the complementary strengths of diffusion probabilistic models (a.k.a., diffusion models) and transformers. Our proposed framework, termed the "World-Centric Diffusion Transformer"(WcDT), optimizes the entire trajectory generation process, from feature extraction to model inference. To enhance the scene diversity and stochasticity, the historical trajectory data is first preprocessed into "Agent Move Statement" and encoded into latent space using Denoising Diffusion Probabilistic Models (DDPM) enhanced with Diffusion with Transformer (DiT) blocks. Then, the latent features, historical trajectories, HD map features, and historical traffic signal information are fused with various transformer-based encoders that are used to enhance the interaction of agents with other elements in the traffic scene. The encoded traffic scenes are then decoded by a trajectory decoder to generate multimodal future trajectories. Comprehensive experimental results show that the proposed approach exhibits superior performance in generating both realistic and diverse trajectories, showing its potential for integration into automatic driving simulation systems. Our code is available at \url{https://github.com/yangchen1997/WcDT}.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LayeredMAPF: a decomposition of MAPF instance to reduce solving costs</title>
<link>https://arxiv.org/abs/2404.12773</link>
<guid>https://arxiv.org/abs/2404.12773</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体路径规划(MAPF), 解耦方法, 计算资源, 内存空间, 算法框架<br /><br />总结:

本文提出了一种针对多智能体路径规划(MAPF)问题的解耦方法，旨在解决随着智能体数量增加导致的计算和内存需求呈指数级增长的问题。该方法将大规模的MAPF实例分解为多个涉及较少智能体的孤立子问题，然后提供了一个通用框架，使得现有的多种MAPF算法可以独立地求解这些子问题，并将解决方案合并为一个无冲突的整体解决方案，尽可能避免可解性损失。与专注于减少MAPF时间成本的现有工作不同，该方法适用于所有MAPF算法。实验结果显示，使用经典MAPF基准测试了七种主流MAPF方法，平均能在1秒内完成MAPF实例的分解，并显著降低了内存占用或计算时间开销，特别是对于串行方法。通过大量实验推测，由该方法引起的可解性损失可能性小于1%。为了促进社区内的进一步研究，作者已经将提出的算法源代码公开可用。 <div>
arXiv:2404.12773v2 Announce Type: replace 
Abstract: Multi-agent pathfinding (MAPF) holds significant utility within autonomous systems, however, the calculation and memory space required for multi-agent path finding (MAPF) grows exponentially as the number of agents increases. This often results in some MAPF instances being unsolvable under limited computational resources and memory space, thereby limiting the application of MAPF in complex scenarios. Hence, we propose a decomposition approach for MAPF instances, which breaks down instances involving a large number of agents into multiple isolated subproblems involving fewer agents. Moreover, we present a framework to enable general MAPF algorithms to solve each subproblem independently and merge their solutions into one conflict-free final solution, and avoid loss of solvability as much as possible. Unlike existing works that propose isolated methods aimed at reducing the time cost of MAPF, our method is applicable to all MAPF methods. In our results, we apply decomposition to multiple state-of-the-art MAPF methods using a classic MAPF benchmark\footnote{https://movingai.com/benchmarks/mapf.html}. The decomposition of MAPF instances is completed on average within 1s, and its application to seven MAPF methods reduces the memory usage or time cost significantly, particularly for serial methods. Based on massive experiments, we speculate the possibilty about loss of solvability caused by our method is $<$ 1\%. To facilitate further research within the community, we have made the source code of the proposed algorithm publicly available\footnote{https://github.com/JoeYao-bit/LayeredMAPF/tree/minimize\_dependence}.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Data-Driven Automated Mechanism Design using Multi-Agent Revealed Preferences</title>
<link>https://arxiv.org/abs/2404.15391</link>
<guid>https://arxiv.org/abs/2404.15391</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning，RL）、机制设计、纳什均衡、帕累托最优、逆强化学习（Inverse Reinforcement Learning，IRL）

总结:
本文提出了一种基于强化学习的框架，旨在适应性地引导多个代理人的黑盒决策系统中的纳什均衡达到社会最优状态。文章首先提出了一个多智能体揭示偏好的帕累托最优测试，该测试为存在满足观测到的混合策略纳什均衡是社会最优的效用函数提供了必要和充分条件。接着，利用这一结果构建了一个逆强化学习步骤，用于确定观测策略与帕累托最优的距离（即帕累托差距）。将此 IRL 步骤与 RL 政策梯度算法结合并证明了收敛性，可以诱导出在均衡策略中实现社会最优。此外，作者还揭示了所构建损失函数与几种稳健揭示偏好度量之间的紧密联系，通过这些已建立的微观经济原则来分析算法次优性。最后，在只有有限个独立同分布的来自混合策略的样本（部分策略规范）可用的情况下，文中得出了算法收敛性的集中界限，并构建了一个分布鲁棒的 RL 程序，实现了对完全规范策略的社会最优机制设计。 <div>
arXiv:2404.15391v2 Announce Type: replace 
Abstract: Suppose a black box, representing multiple agents, generates decisions from a mixed-strategy Nash equilibrium of a game. Assume that we can choose the input vector to the black box and this affects the utilities of the agents, but we do not know the utilities of the individual agents. By viewing the decisions from the black box, how can we steer the Nash equilibrium to a socially optimal point? This paper constructs a reinforcement learning (RL) framework for adaptively achieving this mechanism design objective. We first derive a novel multi-agent revealed preference test for Pareto optimality -- this yields necessary and sufficient conditions for the existence of utility functions under which empirically observed mixed-strategy Nash equilibria are socially optimal. These conditions take the form of a testable linear program, and this result is of independent interest. We utilize this result to construct an inverse reinforcement learning (IRL) step to determine the Pareto gap, i.e., the distance of observed strategies from Pareto optimality. We pair this IRL step with an RL policy gradient algorithm and prove convergence to a mechanism which minimizes the Pareto gap, thereby inducing social optimality in equilibria strategies. We also reveal an intimate connection between our constructed loss function and several robust revealed preference metrics; this allows us to reason about algorithmic suboptimality through the lens of these well-established microeconomic principles. Finally, in the case when only finitely many i.i.d. samples from mixed-strategies (partial strategy specifications) are available, we derive concentration bounds for our algorithm's convergence, and we construct a distributionally robust RL procedure which achieves mechanism design for the fully specified strategies.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation Experiments</title>
<link>https://arxiv.org/abs/2405.17631</link>
<guid>https://arxiv.org/abs/2405.17631</guid>
<content:encoded><![CDATA[
<div> 关键词：BioDiscoveryAgent、大型语言模型、实验设计、基因突变、预测准确率

总结:<br />
本文介绍了BioDiscoveryAgent，这是一个基于大型语言模型的科学发现加速器，专注于设计遗传干扰实验并推理其结果，有效地探索假设空间以找到期望解决方案。该代理利用丰富的生物学知识，无需训练机器学习模型或明确定义获取函数即可设计新实验。使用Claude 3.5 Sonnet，BioDiscoveryAgent在六项数据集上对相关遗传干扰预测的平均准确率提高了21%，对于非必需基因干扰这一更难任务则提高了46%，优于针对此任务专门训练的贝叶斯优化基线。此外，BioDiscoveryAgent在预测需干扰的基因组合方面比随机基准准确两倍以上，这是在封闭式实验设计背景下尚未被探索的任务。该代理还能够访问生物医学文献搜索工具、执行代码分析生物数据以及提示另一个代理对其预测进行批判性评估。总之，BioDiscoveryAgent在每个阶段都是可解释的，代表了一种新的、易于访问的生物实验计算设计范式，具有增强科学家效率的潜力。 <div>
arXiv:2405.17631v3 Announce Type: replace 
Abstract: Agents based on large language models have shown great potential in accelerating scientific discovery by leveraging their rich background knowledge and reasoning capabilities. In this paper, we introduce BioDiscoveryAgent, an agent that designs new experiments, reasons about their outcomes, and efficiently navigates the hypothesis space to reach desired solutions. We demonstrate our agent on the problem of designing genetic perturbation experiments, where the aim is to find a small subset out of many possible genes that, when perturbed, result in a specific phenotype (e.g., cell growth). Utilizing its biological knowledge, BioDiscoveryAgent can uniquely design new experiments without the need to train a machine learning model or explicitly design an acquisition function as in Bayesian optimization. Moreover, BioDiscoveryAgent, using Claude 3.5 Sonnet, achieves an average of 21% improvement in predicting relevant genetic perturbations across six datasets, and a 46% improvement in the harder task of non-essential gene perturbation, compared to existing Bayesian optimization baselines specifically trained for this task. Our evaluation includes one dataset that is unpublished, ensuring it is not part of the language model's training data. Additionally, BioDiscoveryAgent predicts gene combinations to perturb more than twice as accurately as a random baseline, a task so far not explored in the context of closed-loop experiment design. The agent also has access to tools for searching the biomedical literature, executing code to analyze biological datasets, and prompting another agent to critically evaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every stage, representing an accessible new paradigm in the computational design of biological experiments with the potential to augment scientists' efficacy.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Linear Contracts in Multitasking: Robustness, Uniformity, and Learning</title>
<link>https://arxiv.org/abs/2405.20642</link>
<guid>https://arxiv.org/abs/2405.20642</guid>
<content:encoded><![CDATA[
<div> 关键词：多任务委托代理问题、线性合同、稳健性、均匀性、学习

<br />
总结：

本文研究了多任务委托代理问题，其中代理人执行多个任务，委托人通过合同激励代理人付出努力。委托人可以观察到每个任务的信号，而合同是从可能的信号空间映射到支付额的函数。文章从三个方面探讨了线性合同：首先，展示了线性合同的一个稳健性结果，即在存在不确定性的环境中，仅知道第一阶矩信息时，存在一种线性合同能在最坏情况下最大化委托人的收益；其次，证明了当代理人的成本函数具有某一程度的齐次性，且委托人的效用在各项任务中呈线性形式时，最优合同只与其成本函数的齐次度有关；最后，研究了如何利用观测数据在线上和线下环境中学习到最优线性合同，并提出了基于仪器回归的方法来估计离线设置下的最优合同参数或在线学习最优合同。 <div>
arXiv:2405.20642v2 Announce Type: replace 
Abstract: In this work, we study the multitasking principal-agent problem. The agent performs several task for the principal, and the principal posts a contract incentivizing the agent to exert effort. The principal can observe a signal for each task, and the contract is a mapping from the space of possible signals to a payment. We study the special class of linear contracts from three perspectives: robustness, uniformity, and learning. Firstly, we show a robustness result: in an ambiguous setting when only first moment information is known, there is a linear contract maximizing the principal's payoff in a worst-case scenario. Secondly, we show a uniformity result: when the agent's cost function is homogeneous to a certain degree and the the principal's utility takes a linear form across tasks, then the optimal contract depends on the agent's cost function only through its homogeneuity degree. Thirdly, we study the problem of learning an optimal linear contract through observational data. We identify this as an measurement error model, and propose instrumental regression methods to estimate the optimal contract parameters in an offline setting, or to learn the optimal contract in an online setting.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GuardAgent: Safeguard LLM Agents by a Guard Agent via Knowledge-Enabled Reasoning</title>
<link>https://arxiv.org/abs/2406.09187</link>
<guid>https://arxiv.org/abs/2406.09187</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 安全性, GuardAgent, 安全守卫请求, 评估基准

总结:
本文提出了GuardAgent，这是首个用于保护目标代理安全的动态检查系统，着重关注大型语言模型（LLM）的安全与保障问题。GuardAgent通过分析安全守卫请求生成任务计划，并将其映射为执行代码，利用LLM作为推理组件，并结合存储先前任务经验的记忆模块中的实例进行补充。该系统能够灵活地理解和提供可靠的基于代码的守卫规则，同时具备较低的操作开销。为了评估其效果，文章还提出了两个新的评估基准：EICU-AC用于测试医疗保健代理的访问控制，Mind2Web-SC则用于评估网络代理的安全策略。实验结果显示，GuardAgent在上述两个基准上能有效抑制违规行为，分别达到超过98%和83%的守卫准确性。项目主页：https://guardagent.github.io/ <div>
arXiv:2406.09187v2 Announce Type: replace 
Abstract: The rapid advancement of large language model (LLM) agents has raised new concerns regarding their safety and security, which cannot be addressed by traditional textual-harm-focused LLM guardrails. We propose GuardAgent, the first guardrail agent to protect the target agents by dynamically checking whether their actions satisfy given safety guard requests. Specifically, GuardAgent first analyzes the safety guard requests to generate a task plan, and then maps this plan into guardrail code for execution. By performing the code execution, GuardAgent can deterministically follow the safety guard request and safeguard target agents. In both steps, an LLM is utilized as the reasoning component, supplemented by in-context demonstrations retrieved from a memory module storing experiences from previous tasks. GuardAgent can understand different safety guard requests and provide reliable code-based guardrails with high flexibility and low operational overhead. In addition, we propose two novel benchmarks: EICU-AC benchmark to assess the access control for healthcare agents and Mind2Web-SC benchmark to evaluate the safety policies for web agents. We show that GuardAgent effectively moderates the violation actions for different types of agents on these two benchmarks with over 98% and 83% guardrail accuracies, respectively. Project page: https://guardagent.github.io/
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>EvoAgent: Towards Automatic Multi-Agent Generation via Evolutionary Algorithms</title>
<link>https://arxiv.org/abs/2406.14228</link>
<guid>https://arxiv.org/abs/2406.14228</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、多智能体系统、自动扩展、演化算法、EvoAgent

总结:
本文介绍了EvoAgent，这是一种通过演化算法自动将专门的单智能体扩展为多智能体系统的方法，以增强基于大规模语言模型（LLMs）的智能体解决复杂任务的能力。针对现有工作对人类设计框架的依赖限制了智能体系统的功能范围和可扩展性的问题，EvoAgent考虑现有的智能体框架作为初始个体，应用一系列演化操作（如变异、交叉、选择等）生成具有多样设置的新智能体。实验结果显示，EvoAgent可以显著提升LLM基础智能体的任务解决能力，并能被泛化到任何基于LLM的智能体框架中，用于将其扩展为多智能体系统。相关资源可在https://evo-agent.github.io/ 获取。 <div>
arXiv:2406.14228v3 Announce Type: replace 
Abstract: The rise of powerful large language models (LLMs) has spurred a new trend in building LLM-based autonomous agents for solving complex tasks, especially multi-agent systems. Despite the remarkable progress, we notice that existing works are heavily dependent on human-designed frameworks, which greatly limits the functional scope and scalability of agent systems. How to automatically extend the specialized agent to multi-agent systems to improve task-solving capability still remains a significant challenge. In this paper, we introduce EvoAgent, a generic method to automatically extend specialized agents to multi-agent systems via the evolutionary algorithm, thereby improving the effectiveness of LLM-based agents in solving tasks. Specifically, we consider the existing agent frameworks as the initial individual and then apply a series of evolutionary operators (e.g., mutation, crossover, selection, etc.) to generate multiple agents with diverse settings. Experimental results across various tasks show that EvoAgent can significantly enhance the task-solving capability of LLM-based agents, and can be generalized to any LLM-based agent framework to extend them into multi-agent systems. Resources are available at https://evo-agent.github.io/.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Task-oriented Sequential Grounding and Navigation in 3D Scenes</title>
<link>https://arxiv.org/abs/2408.04034</link>
<guid>https://arxiv.org/abs/2408.04034</guid>
<content:encoded><![CDATA[
<div> 关键词: 3D视觉语言对齐、动态场景、任务导向、序列定位、SG3D数据集

总结:<br />
本文提出了一个新的任务——任务导向的三维场景序列定位与导航，该任务要求模型通过理解逐步步骤指令来定位室内场景中的目标对象序列或在3D模拟器中朝向它们进行导航。为支持此任务，文章介绍了大型数据集SG3D，包含了跨越4,895个真实世界的3D场景的22,346个任务和112,236个步骤。该数据集由多种3D场景数据集的RGB-D扫描结合自动化任务生成管道构建而成，并经过人工验证以确保质量。文中对比了当前方法在SG3D上的性能，揭示了理解多步任务导向上下文的重大挑战。此外，文章提出了一种名为SG-LLM的先进方法，利用逐步定位范式来解决序列定位任务。研究结果强调了进一步研究的必要性，以推动更智能、更具情境意识的具身代理的发展。 <div>
arXiv:2408.04034v2 Announce Type: replace 
Abstract: Grounding natural language in 3D environments is a critical step toward achieving robust 3D vision-language alignment. Current datasets and models for 3D visual grounding predominantly focus on identifying and localizing objects from static, object-centric descriptions. These approaches do not adequately address the dynamic and sequential nature of task-oriented scenarios. In this work, we introduce a novel task: Task-oriented Sequential Grounding and Navigation in 3D Scenes, where models must interpret step-by-step instructions for daily activities by either localizing a sequence of target objects in indoor scenes or navigating toward them within a 3D simulator. To facilitate this task, we present SG3D, a large-scale dataset comprising 22,346 tasks with 112,236 steps across 4,895 real-world 3D scenes. The dataset is constructed by combining RGB-D scans from various 3D scene datasets with an automated task generation pipeline, followed by human verification for quality assurance. We benchmark contemporary methods on SG3D, revealing the significant challenges in understanding task-oriented context across multiple steps. Furthermore, we propose SG-LLM, a state-of-the-art approach leveraging a stepwise grounding paradigm to tackle the sequential grounding task. Our findings underscore the need for further research to advance the development of more capable and context-aware embodied agents.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Hypergraph-based Coordinated Task Allocation and Socially-aware Navigation for Multi-Robot Systems</title>
<link>https://arxiv.org/abs/2409.11561</link>
<guid>https://arxiv.org/abs/2409.11561</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统、任务分配、社会感知导航、超图、强化学习

总结:
本文提出了一种名为Hyper-SAMARL的新型多机器人系统，用于动态环境中机器人的任务分配和社交感知导航。该系统基于超图模型，能够有效地刻画机器人、人类和兴趣点之间的环境动态交互，并通过超图扩散机制实现适应性任务分配和遵循社会规范的路径规划。利用多代理强化学习进行训练，Hyper-SAMARL能够在实时变化的人类活动中灵活调整任务分配。实验结果显示，与基线模型相比，Hyper-SAMARL在社交导航、任务完成效率以及对各种模拟场景的适应性方面表现出优越性能。 <div>
arXiv:2409.11561v2 Announce Type: replace 
Abstract: A team of multiple robots seamlessly and safely working in human-filled public environments requires adaptive task allocation and socially-aware navigation that account for dynamic human behavior. Current approaches struggle with highly dynamic pedestrian movement and the need for flexible task allocation. We propose Hyper-SAMARL, a hypergraph-based system for multi-robot task allocation and socially-aware navigation, leveraging multi-agent reinforcement learning (MARL). Hyper-SAMARL models the environmental dynamics between robots, humans, and points of interest (POIs) using a hypergraph, enabling adaptive task assignment and socially-compliant navigation through a hypergraph diffusion mechanism. Our framework, trained with MARL, effectively captures interactions between robots and humans, adapting tasks based on real-time changes in human activity. Experimental results demonstrate that Hyper-SAMARL outperforms baseline models in terms of social navigation, task completion efficiency, and adaptability in various simulated scenarios.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Modeling and Evaluating Trust Dynamics in Multi-Human Multi-Robot Task Allocation</title>
<link>https://arxiv.org/abs/2409.16009</link>
<guid>https://arxiv.org/abs/2409.16009</guid>
<content:encoded><![CDATA[
<div> 关键词: 信任、人机协作、多人类多机器人团队、任务分配、预期确认信任模型

<br />
总结:
本文提出了一个针对多人类多机器人团队中信任动态的新框架——预期确认信任模型(ECT模型)。研究表明，ECT模型相较于五个现有的信任模型和无信任基线，在不同团队配置（如2H-2R、5H-5R和10H-10R）下的任务分配结果更优，能够提高任务成功率、减少平均完成时间和降低任务错误率。这强调了在MH-MR团队中的信任对任务分配的重要性和复杂性。文章探讨了将信任融入任务分配算法的影响，并对未来研究方向提出了建议，即如何在动态多智能体环境中平衡效率与性能的自适应信任机制。 <div>
arXiv:2409.16009v2 Announce Type: replace 
Abstract: Trust is essential in human-robot collaboration, particularly in multi-human, multi-robot (MH-MR) teams, where it plays a crucial role in maintaining team cohesion in complex operational environments. Despite its importance, trust is rarely incorporated into task allocation and reallocation algorithms for MH-MR collaboration. While prior research in single-human, single-robot interactions has shown that integrating trust significantly enhances both performance outcomes and user experience, its role in MH-MR task allocation remains underexplored. In this paper, we introduce the Expectation Confirmation Trust (ECT) Model, a novel framework for modeling trust dynamics in MH-MR teams. We evaluate the ECT model against five existing trust models and a no-trust baseline to assess its impact on task allocation outcomes across different team configurations (2H-2R, 5H-5R, and 10H-10R). Our results show that the ECT model improves task success rate, reduces mean completion time, and lowers task error rates. These findings highlight the complexities of trust-based task allocation in MH-MR teams. We discuss the implications of incorporating trust into task allocation algorithms and propose future research directions for adaptive trust mechanisms that balance efficiency and performance in dynamic, multi-agent environments.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Strong Preferences Affect the Robustness of Preference Models and Value Alignment</title>
<link>https://arxiv.org/abs/2410.02451</link>
<guid>https://arxiv.org/abs/2410.02451</guid>
<content:encoded><![CDATA[
<div> 关键词：价值对齐、大型语言模型、偏好模型、鲁棒性、安全性

总结:
本文探讨了价值对齐的重要性，特别是在确保大型语言模型和AI系统的安全性和可信度方面。研究聚焦于偏好模型的稳健性分析，通过研究在偏好概率发生微小变化时，这些模型对于其他偏好的预测敏感程度。文章理论性地分析了Bradley-Terry和Placket-Luce两种常用偏好模型的敏感性，并发现当某些偏好占据主导地位（即概率接近0或1）时，其概率可能会因其它偏好改变而显著变化。作者指出了在这种情况下模型敏感性的重要条件，并讨论了这些发现对AI系统中价值对齐的鲁棒性和安全性带来的实际影响。 <div>
arXiv:2410.02451v2 Announce Type: replace 
Abstract: Value alignment, which aims to ensure that large language models (LLMs) and other AI agents behave in accordance with human values, is critical for ensuring safety and trustworthiness of these systems. A key component of value alignment is the modeling of human preferences as a representation of human values. In this paper, we investigate the robustness of value alignment by examining the sensitivity of preference models. Specifically, we ask: how do changes in the probabilities of some preferences affect the predictions of these models for other preferences? To answer this question, we theoretically analyze the robustness of widely used preference models by examining their sensitivities to minor changes in preferences they model. Our findings reveal that, in the Bradley-Terry and the Placket-Luce model, the probability of a preference can change significantly as other preferences change, especially when these preferences are dominant (i.e., with probabilities near 0 or 1). We identify specific conditions where this sensitivity becomes significant for these models and discuss the practical implications for the robustness and safety of value alignment in AI systems.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agent Security Bench (ASB): Formalizing and Benchmarking Attacks and Defenses in LLM-based Agents</title>
<link>https://arxiv.org/abs/2410.02644</link>
<guid>https://arxiv.org/abs/2410.02644</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM-based agents、security vulnerabilities、Agent Security Bench (ASB)、attacks、defenses

总结:<br />
本文针对基于大型语言模型（LLMs）的智能代理存在的安全漏洞问题，介绍了ASB（Agent Security Bench）框架，该框架用于系统化地评估和基准测试针对LLM智能代理的攻击与防御方法。ASB涵盖了10个应用场景、10种针对这些场景的智能代理、超过400种工具以及27种不同类型的攻击/防御方法，并使用7项评价指标。研究者利用ASB对10种prompt注入攻击、一种记忆中毒攻击、一种新颖的Plan-of-Thought后门攻击、4种混合攻击及11种对应的防御策略进行了基准测试，结果显示在智能代理的不同操作阶段存在严重漏洞，最高平均攻击成功率达到了84.30%，但现有的防御措施效果有限。此外，文中还引入了一个新指标来衡量智能代理平衡实用性和安全性能力。相关代码已发布在GitHub上。 <div>
arXiv:2410.02644v2 Announce Type: replace 
Abstract: Although LLM-based agents, powered by Large Language Models (LLMs), can use external tools and memory mechanisms to solve complex real-world tasks, they may also introduce critical security vulnerabilities. However, the existing literature does not comprehensively evaluate attacks and defenses against LLM-based agents. To address this, we introduce Agent Security Bench (ASB), a comprehensive framework designed to formalize, benchmark, and evaluate the attacks and defenses of LLM-based agents, including 10 scenarios (e.g., e-commerce, autonomous driving, finance), 10 agents targeting the scenarios, over 400 tools, 27 different types of attack/defense methods, and 7 evaluation metrics. Based on ASB, we benchmark 10 prompt injection attacks, a memory poisoning attack, a novel Plan-of-Thought backdoor attack, 4 mixed attacks, and 11 corresponding defenses across 13 LLM backbones. Our benchmark results reveal critical vulnerabilities in different stages of agent operation, including system prompt, user prompt handling, tool usage, and memory retrieval, with the highest average attack success rate of 84.30\%, but limited effectiveness shown in current defenses, unveiling important works to be done in terms of agent security for the community. We also introduce a new metric to evaluate the agents' capability to balance utility and security. Our code can be found at https://github.com/agiresearch/ASB.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FRASA: An End-to-End Reinforcement Learning Agent for Fall Recovery and Stand Up of Humanoid Robots</title>
<link>https://arxiv.org/abs/2410.08655</link>
<guid>https://arxiv.org/abs/2410.08655</guid>
<content:encoded><![CDATA[
<div> 关键词：Humanoid robotics, Fall recovery, Stand up, Deep Reinforcement Learning (DRL), FRASA, Cross-Q算法, Sigmaban humanoid robots, RoboCup 2023, Rhoban Team

总结:
本文介绍了在应对人形机器人动态环境中稳定行走及摔倒恢复方面的挑战时，传统方法（如模型预测控制和基于关键帧的方法）存在的问题。文章提出了一个新的深度强化学习(DRL)代理——FRASA，它将摔倒恢复和站立策略整合到统一框架中，利用Cross-Q算法显著缩短了训练时间并提供了适应不可预见干扰的灵活恢复策略。实验结果显示，在Sigmaban人形机器人上，FRASA相对于RoboCup 2023中Rhoban团队所采用的世界冠军级Key Frame Based方法展现了优越性能。 <div>
arXiv:2410.08655v2 Announce Type: replace 
Abstract: Humanoid robotics faces significant challenges in achieving stable locomotion and recovering from falls in dynamic environments. Traditional methods, such as Model Predictive Control (MPC) and Key Frame Based (KFB) routines, either require extensive fine-tuning or lack real-time adaptability. This paper introduces FRASA, a Deep Reinforcement Learning (DRL) agent that integrates fall recovery and stand up strategies into a unified framework. Leveraging the Cross-Q algorithm, FRASA significantly reduces training time and offers a versatile recovery strategy that adapts to unpredictable disturbances. Comparative tests on Sigmaban humanoid robots demonstrate FRASA superior performance against the KFB method deployed in the RoboCup 2023 by the Rhoban Team, world champion of the KidSize League.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Adaptive Active Inference Agents for Heterogeneous and Lifelong Federated Learning</title>
<link>https://arxiv.org/abs/2410.09099</link>
<guid>https://arxiv.org/abs/2410.09099</guid>
<content:encoded><![CDATA[
<div> 关键词：异构计算、无预测性、Adaptive Inference (AIF)、高阶Service Level Objectives (SLOs)、联邦学习

总结:<br />
本文针对普适计算领域中的异构性和不确定性问题，提出了利用神经科学框架Active Inference (AIF)设计适应性代理的概念模型。该模型旨在为异构普适系统设置全局性的高阶SLOs，而非手动设定低层SLOs，从而使系统能够在环境变化中自动寻找平衡点进行适应。作者通过在具有不同资源类型和厂商规格的实际设备物理测试床上进行大量实验，选择了异构和终身联邦学习作为应用场景。实验结果显示，AIF代理能够成功地在资源异构环境中调整系统以适应环境变化，确保高达98%的服务水平目标完成率。 <div>
arXiv:2410.09099v2 Announce Type: replace 
Abstract: Handling heterogeneity and unpredictability are two core problems in pervasive computing. The challenge is to seamlessly integrate devices with varying computational resources in a dynamic environment to form a cohesive system that can fulfill the needs of all participants. Existing work on adaptive systems typically focuses on optimizing individual variables or low-level Service Level Objectives (SLOs), such as constraining the usage of specific resources. While low-level control mechanisms permit fine-grained control over a system, they introduce considerable complexity, particularly in dynamic environments. To this end, we propose drawing from Active Inference (AIF), a neuroscientific framework for designing adaptive agents. Specifically, we introduce a conceptual agent for heterogeneous pervasive systems that permits setting global systems constraints as high-level SLOs. Instead of manually setting low-level SLOs, the system finds an equilibrium that can adapt to environmental changes. We demonstrate the viability of our AIF agents with an extensive experiment design, using heterogeneous and lifelong federated learning as an application scenario. We conduct our experiments on a physical testbed of devices with different resource types and vendor specifications. The results provide convincing evidence that an AIF agent can adapt a system to environmental changes. In particular, the AIF agent can balance competing SLOs in resource heterogeneous environments to ensure up to 98% fulfillment rate.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Scene-Aware Explainable Multimodal Trajectory Prediction</title>
<link>https://arxiv.org/abs/2410.16795</link>
<guid>https://arxiv.org/abs/2410.16795</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、轨迹预测、可解释性、条件扩散模型、Shapley值模型

<br />
总结:

本文提出了一种新的可解释的条件扩散基多元轨迹预测（DMTP）模型，旨在解决当前研究中对场景代理的联合推理不足以及轨迹预测模型缺乏可解释性的问题。该模型利用修改后的条件扩散方法捕捉多模态轨迹模式，并采用修订后的Shapley值模型评估全局和场景特定特征的重要性。实验使用Waymo开放运动数据集表明，这种可解释的模型在识别关键输入方面表现出色，且在准确性上显著优于基线模型。此外，所识别的影响因素与人类驾驶经验相吻合，证明了模型在学习准确预测方面的有效性。相关的开源代码可在提供的链接地址获取。 <div>
arXiv:2410.16795v2 Announce Type: replace 
Abstract: Advancements in intelligent technologies have significantly improved navigation in complex traffic environments by enhancing environment perception and trajectory prediction for automated vehicles. However, current research often overlooks the joint reasoning of scenario agents and lacks explainability in trajectory prediction models, limiting their practical use in real-world situations. To address this, we introduce the Explainable Conditional Diffusion-based Multimodal Trajectory Prediction (DMTP) model, which is designed to elucidate the environmental factors influencing predictions and reveal the underlying mechanisms. Our model integrates a modified conditional diffusion approach to capture multimodal trajectory patterns and employs a revised Shapley Value model to assess the significance of global and scenario-specific features. Experiments using the Waymo Open Motion Dataset demonstrate that our explainable model excels in identifying critical inputs and significantly outperforms baseline models in accuracy. Moreover, the factors identified align with the human driving experience, underscoring the model's effectiveness in learning accurate predictions. Code is available in our open-source repository: https://github.com/ocean-luna/Explainable-Prediction.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evaluating Cultural and Social Awareness of LLM Web Agents</title>
<link>https://arxiv.org/abs/2410.23252</link>
<guid>https://arxiv.org/abs/2410.23252</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、CASBA、文化与社会意识、评估框架、提示法、微调

总结:
本文提出了一个新的基准测试——CASBA，用于评估大型语言模型在现实世界应用中的文化和社会规范敏感度，特别是在在线购物和社交讨论论坛两种网络任务中。该文指出现有的基准测试往往忽视了这些关键维度。文章提出了一套全面的评价框架，关注模型对违规行为的识别及适当响应能力、处理用户查询的助益性以及面对误导性网络内容时的违规率。实验结果显示，当前的大型语言模型在非代理环境下的表现优于作为网络代理环境，其对于文化和社会规范的意识覆盖不到10%，违规率超过40%。为了提升性能，作者探索了提示法和微调两种方法，并发现结合使用两种方法可以提供互补优势：在特定文化数据集上的微调显著提升了模型在不同地区的一般化能力，而提示法则增强了模型处理复杂任务的能力。这强调了在开发周期中不断对大型语言模型的 cultural 和社会意识进行基准测试的重要性。 <div>
arXiv:2410.23252v3 Announce Type: replace 
Abstract: As large language models (LLMs) expand into performing as agents for real-world applications beyond traditional NLP tasks, evaluating their robustness becomes increasingly important. However, existing benchmarks often overlook critical dimensions like cultural and social awareness. To address these, we introduce CASA, a benchmark designed to assess LLM agents' sensitivity to cultural and social norms across two web-based tasks: online shopping and social discussion forums. Our approach evaluates LLM agents' ability to detect and appropriately respond to norm-violating user queries and observations. Furthermore, we propose a comprehensive evaluation framework that measures awareness coverage, helpfulness in managing user queries, and the violation rate when facing misleading web content. Experiments show that current LLMs perform significantly better in non-agent than in web-based agent environments, with agents achieving less than 10% awareness coverage and over 40% violation rates. To improve performance, we explore two methods: prompting and fine-tuning, and find that combining both methods can offer complementary advantages -- fine-tuning on culture-specific datasets significantly enhances the agents' ability to generalize across different regions, while prompting boosts the agents' ability to navigate complex tasks. These findings highlight the importance of constantly benchmarking LLM agents' cultural and social awareness during the development cycle.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Learning Multi-Agent Loco-Manipulation for Long-Horizon Quadrupedal Pushing</title>
<link>https://arxiv.org/abs/2411.07104</link>
<guid>https://arxiv.org/abs/2411.07104</guid>
<content:encoded><![CDATA[
<div> 关键词：四足机器人、多智能体强化学习、高层控制器、中层控制器、低层运动策略<br /><br />总结: 这篇文章主要介绍了为提升四足机器人的操纵能力，特别是在处理大型物体和执行障碍物感知的长期推动任务方面的研究。文中提出了一种层次化的多智能体强化学习框架，该框架包含三个控制层级：高层控制器综合运用RRT规划器和集中式自适应策略生成子目标；中层控制器采用去中心化的目标条件策略引导机器人向这些子目标移动；预训练的低层运动策略执行移动指令。通过与多个基线方法在模拟环境中的对比评估，证明了该方法的成功率比最佳基线提高了36.0%，完成时间减少了24.5%。此外，该框架已成功实现在Go1四足机器人上进行如Push-Cuboid和Push-T等实际世界的长时段、障碍物感知的操纵任务。 <div>
arXiv:2411.07104v3 Announce Type: replace 
Abstract: Recently, quadrupedal locomotion has achieved significant success, but their manipulation capabilities, particularly in handling large objects, remain limited, restricting their usefulness in demanding real-world applications such as search and rescue, construction, industrial automation, and room organization. This paper tackles the task of obstacle-aware, long-horizon pushing by multiple quadrupedal robots. We propose a hierarchical multi-agent reinforcement learning framework with three levels of control. The high-level controller integrates an RRT planner and a centralized adaptive policy to generate subgoals, while the mid-level controller uses a decentralized goal-conditioned policy to guide the robots toward these sub-goals. A pre-trained low-level locomotion policy executes the movement commands. We evaluate our method against several baselines in simulation, demonstrating significant improvements over baseline approaches, with 36.0% higher success rates and 24.5% reduction in completion time than the best baseline. Our framework successfully enables long-horizon, obstacle-aware manipulation tasks like Push-Cuboid and Push-T on Go1 robots in the real world.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Resonance: Learning to Predict Social-Aware Pedestrian Trajectories as Co-Vibrations</title>
<link>https://arxiv.org/abs/2412.02447</link>
<guid>https://arxiv.org/abs/2412.02447</guid>
<content:encoded><![CDATA[
<div> 关键词: 行人轨迹预测、意图模拟、社会行为、共振模型、随机性解耦

<br /><br />总结:
本文提出了一个名为“Resonance”（简称Re）的模型，用于以“共振动”的形式编码和预测行人轨迹。该模型旨在解决行人轨迹预测中准确考虑意图和社会行为的挑战，并能独立地模拟这些因素中的独特随机性。通过将轨迹变化和随机性分解为多个振动部分，Resonance可以分别模拟行人对每个单一原因的反应，并将轨迹预测视为这些独立振动的叠加。此外，利用振动及其频谱特性，Resonance可以通过模仿共振现象学习到社会交互的表示，从而增强模型的可解释性。实验结果在多个数据集上验证了该模型在定量和定性方面的有效性。 <div>
arXiv:2412.02447v2 Announce Type: replace 
Abstract: Learning to forecast trajectories of intelligent agents has caught much more attention recently. However, it remains a challenge to accurately account for agents' intentions and social behaviors when forecasting, and in particular, to simulate the unique randomness within each of those components in an explainable and decoupled way. Inspired by vibration systems and their resonance properties, we propose the Resonance (short for Re) model to encode and forecast pedestrian trajectories in the form of ``co-vibrations''. It decomposes trajectory modifications and randomnesses into multiple vibration portions to simulate agents' reactions to each single cause, and forecasts trajectories as the superposition of these independent vibrations separately. Also, benefiting from such vibrations and their spectral properties, representations of social interactions can be learned by emulating the resonance phenomena, further enhancing its explainability. Experiments on multiple datasets have verified its usefulness both quantitatively and qualitatively.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>PriorMotion: Generative Class-Agnostic Motion Prediction with Raster-Vector Motion Field Priors</title>
<link>https://arxiv.org/abs/2412.04020</link>
<guid>https://arxiv.org/abs/2412.04020</guid>
<content:encoded><![CDATA[
arXiv:2412.04020v2 Announce Type: replace 
Abstract: Reliable spatial and motion perception is essential for safe autonomous navigation. Recently, class-agnostic motion prediction on bird's-eye view (BEV) cell grids derived from LiDAR point clouds has gained significant attention. However, existing frameworks typically perform cell classification and motion prediction on a per-pixel basis, neglecting important motion field priors such as rigidity constraints, temporal consistency, and future interactions between agents. These limitations lead to degraded performance, particularly in sparse and distant regions. To address these challenges, we introduce \textbf{PriorMotion}, an innovative generative framework designed for class-agnostic motion prediction that integrates essential motion priors by modeling them as distributions within a structured latent space. Specifically, our method captures structured motion priors using raster-vector representations and employs a variational autoencoder with distinct dynamic and static components to learn future motion distributions in the latent space. Experiments on the nuScenes dataset demonstrate that \textbf{PriorMotion} outperforms state-of-the-art methods across both traditional metrics and our newly proposed evaluation criteria. Notably, we achieve improvements of approximately 15.24\% in accuracy for fast-moving objects, an 3.59\% increase in generalization, a reduction of 0.0163 in motion stability, and a 31.52\% reduction in prediction errors in distant regions. Further validation on FMCW LiDAR sensors confirms the robustness of our approach.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>LossAgent: Towards Any Optimization Objectives for Image Processing with LLM Agents</title>
<link>https://arxiv.org/abs/2412.04090</link>
<guid>https://arxiv.org/abs/2412.04090</guid>
<content:encoded><![CDATA[
arXiv:2412.04090v2 Announce Type: replace 
Abstract: We present the first loss agent, dubbed LossAgent, for low-level image processing tasks, e.g., image super-resolution and restoration, intending to achieve any customized optimization objectives of low-level image processing in different practical applications. Notably, not all optimization objectives, such as complex hand-crafted perceptual metrics, text description, and intricate human feedback, can be instantiated with existing low-level losses, e.g., MSE loss, which presents a crucial challenge in optimizing image processing networks in an end-to-end manner. To eliminate this, our LossAgent introduces the powerful large language model (LLM) as the loss agent, where the rich textual understanding of prior knowledge empowers the loss agent with the potential to understand complex optimization objectives, trajectory, and state feedback from external environments in the optimization process of the low-level image processing networks. In particular, we establish the loss repository by incorporating existing loss functions that support the end-to-end optimization for low-level image processing. Then, we design the optimization-oriented prompt engineering for the loss agent to actively and intelligently decide the compositional weights for each loss in the repository at each optimization interaction, thereby achieving the required optimization trajectory for any customized optimization objectives. Extensive experiments on three typical low-level image processing tasks and multiple optimization objectives have shown the effectiveness and applicability of our proposed LossAgent.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DECO: Life-Cycle Management of Enterprise-Grade Copilots</title>
<link>https://arxiv.org/abs/2412.06099</link>
<guid>https://arxiv.org/abs/2412.06099</guid>
<content:encoded><![CDATA[
arXiv:2412.06099v2 Announce Type: replace 
Abstract: Software engineers frequently grapple with the challenge of accessing disparate documentation and telemetry data, including TroubleShooting Guides (TSGs), incident reports, code repositories, and various internal tools developed by multiple stakeholders. While on-call duties are inevitable, incident resolution becomes even more daunting due to the obscurity of legacy sources and the pressures of strict time constraints. To enhance the efficiency of on-call engineers (OCEs) and streamline their daily workflows, we introduced DECO-a comprehensive framework for developing, deploying, and managing enterprise-grade copilots tailored to improve productivity in engineering routines. This paper details the design and implementation of the DECO framework, emphasizing its innovative NL2SearchQuery functionality and a lightweight agentic framework. These features support efficient and customized retrieval-augmented-generation (RAG) algorithms that not only extract relevant information from diverse sources but also select the most pertinent skills in response to user queries. This enables the addressing of complex technical questions and provides seamless, automated access to internal resources. Additionally, DECO incorporates a robust mechanism for converting unstructured incident logs into user-friendly, structured guides, effectively bridging the documentation gap.
  Since its launch in September 2023, DECO has demonstrated its effectiveness through widespread adoption, enabling tens of thousands of interactions and engaging hundreds of monthly active users (MAU) across dozens of organizations within the company.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VCA: Video Curious Agent for Long Video Understanding</title>
<link>https://arxiv.org/abs/2412.10471</link>
<guid>https://arxiv.org/abs/2412.10471</guid>
<content:encoded><![CDATA[
arXiv:2412.10471v2 Announce Type: replace 
Abstract: Long video understanding poses unique challenges due to their temporal complexity and low information density. Recent works address this task by sampling numerous frames or incorporating auxiliary tools using LLMs, both of which result in high computational costs. In this work, we introduce a curiosity-driven video agent with self-exploration capability, dubbed as VCA. Built upon VLMs, VCA autonomously navigates video segments and efficiently builds a comprehensive understanding of complex video sequences. Instead of directly sampling frames, VCA employs a tree-search structure to explore video segments and collect frames. Rather than relying on external feedback or reward, VCA leverages VLM's self-generated intrinsic reward to guide its exploration, enabling it to capture the most crucial information for reasoning. Experimental results on multiple long video benchmarks demonstrate our approach's superior effectiveness and efficiency.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>CAD-Assistant: Tool-Augmented VLLMs as Generic CAD Task Solvers</title>
<link>https://arxiv.org/abs/2412.13810</link>
<guid>https://arxiv.org/abs/2412.13810</guid>
<content:encoded><![CDATA[
arXiv:2412.13810v2 Announce Type: replace 
Abstract: We propose CAD-Assistant, a general-purpose CAD agent for AI-assisted design. Our approach is based on a powerful Vision and Large Language Model (VLLM) as a planner and a tool-augmentation paradigm using CAD-specific tools. CAD-Assistant addresses multimodal user queries by generating actions that are iteratively executed on a Python interpreter equipped with the FreeCAD software, accessed via its Python API. Our framework is able to assess the impact of generated CAD commands on geometry and adapts subsequent actions based on the evolving state of the CAD design. We consider a wide range of CAD-specific tools including a sketch image parameterizer, rendering modules, a 2D cross-section generator, and other specialized routines. CAD-Assistant is evaluated on multiple CAD benchmarks, where it outperforms VLLM baselines and supervised task-specific methods. Beyond existing benchmarks, we qualitatively demonstrate the potential of tool-augmented VLLMs as general-purpose CAD solvers across diverse workflows.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Dream to Manipulate: Compositional World Models Empowering Robot Imitation Learning with Imagination</title>
<link>https://arxiv.org/abs/2412.14957</link>
<guid>https://arxiv.org/abs/2412.14957</guid>
<content:encoded><![CDATA[
arXiv:2412.14957v2 Announce Type: replace 
Abstract: A world model provides an agent with a representation of its environment, enabling it to predict the causal consequences of its actions. Current world models typically cannot directly and explicitly imitate the actual environment in front of a robot, often resulting in unrealistic behaviors and hallucinations that make them unsuitable for real-world robotics applications. To overcome those challenges, we propose to rethink robot world models as learnable digital twins. We introduce DreMa, a new approach for constructing digital twins automatically using learned explicit representations of the real world and its dynamics, bridging the gap between traditional digital twins and world models. DreMa replicates the observed world and its structure by integrating Gaussian Splatting and physics simulators, allowing robots to imagine novel configurations of objects and to predict the future consequences of robot actions thanks to its compositionality. We leverage this capability to generate new data for imitation learning by applying equivariant transformations to a small set of demonstrations. Our evaluations across various settings demonstrate significant improvements in accuracy and robustness by incrementing actions and object distributions, reducing the data needed to learn a policy and improving the generalization of the agents. As a highlight, we show that a real Franka Emika Panda robot, powered by DreMa's imagination, can successfully learn novel physical tasks from just a single example per task variation (one-shot policy learning). Our project page can be found in: https://dreamtomanipulate.github.io/.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Universal Actions for Enhanced Embodied Foundation Models</title>
<link>https://arxiv.org/abs/2501.10105</link>
<guid>https://arxiv.org/abs/2501.10105</guid>
<content:encoded><![CDATA[
arXiv:2501.10105v2 Announce Type: replace 
Abstract: Training on diverse, internet-scale data is a key factor in the success of recent large foundation models. Yet, using the same recipe for building embodied agents has faced noticeable difficulties. Despite the availability of many crowd-sourced embodied datasets, their action spaces often exhibit significant heterogeneity due to distinct physical embodiment and control interfaces for different robots, causing substantial challenges in developing embodied foundation models using cross-domain data. In this paper, we introduce UniAct, a new embodied foundation modeling framework operating in a Universal Action Space. Our learned universal actions capture the generic atomic behaviors across diverse robots by exploiting their shared structural features, and enable enhanced cross-domain data utilization and cross-embodiment generalizations by eliminating the notorious heterogeneity. The universal actions can be efficiently translated back to heterogeneous actionable commands by simply adding embodiment-specific details, from which fast adaptation to new robots becomes simple and straightforward. Our 0.5B instantiation of UniAct outperforms 14X larger SOTA embodied foundation models in extensive evaluations on various real-world and simulation robots, showcasing exceptional cross-embodiment control and adaptation capability, highlighting the crucial benefit of adopting universal actions. Project page: https://github.com/2toinf/UniAct
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GestureLSM: Latent Shortcut based Co-Speech Gesture Generation with Spatial-Temporal Modeling</title>
<link>https://arxiv.org/abs/2501.18898</link>
<guid>https://arxiv.org/abs/2501.18898</guid>
<content:encoded><![CDATA[
arXiv:2501.18898v2 Announce Type: replace 
Abstract: Generating full-body human gestures based on speech signals remains challenges on quality and speed. Existing approaches model different body regions such as body, legs and hands separately, which fail to capture the spatial interactions between them and result in unnatural and disjointed movements. Additionally, their autoregressive/diffusion-based pipelines show slow generation speed due to dozens of inference steps. To address these two challenges, we propose GestureLSM, a flow-matching-based approach for Co-Speech Gesture Generation with spatial-temporal modeling. Our method i) explicitly model the interaction of tokenized body regions through spatial and temporal attention, for generating coherent full-body gestures. ii) introduce the flow matching to enable more efficient sampling by explicitly modeling the latent velocity space. To overcome the suboptimal performance of flow matching baseline, we propose latent shortcut learning and beta distribution time stamp sampling during training to enhance gesture synthesis quality and accelerate inference. Combining the spatial-temporal modeling and improved flow matching-based framework, GestureLSM achieves state-of-the-art performance on BEAT2 while significantly reducing inference time compared to existing methods, highlighting its potential for enhancing digital humans and embodied agents in real-world applications. Project Page: https://andypinxinliu.github.io/GestureLSM
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning for Long-Horizon Interactive LLM Agents</title>
<link>https://arxiv.org/abs/2502.01600</link>
<guid>https://arxiv.org/abs/2502.01600</guid>
<content:encoded><![CDATA[
arXiv:2502.01600v3 Announce Type: replace 
Abstract: Interactive digital agents (IDAs) leverage APIs of stateful digital environments to perform tasks in response to user requests. While IDAs powered by instruction-tuned large language models (LLMs) can react to feedback from interface invocations in multi-step exchanges, they have not been trained in their respective digital environments. Prior methods accomplish less than half of tasks in sophisticated benchmarks such as AppWorld. We present a reinforcement learning (RL) approach that trains IDAs directly in their target environments. We formalize this training as a partially observable Markov decision process and derive LOOP, a data- and memory-efficient variant of proximal policy optimization. LOOP uses no value network and maintains exactly one copy of the underlying LLM in memory, making its implementation straightforward and as memory-efficient as fine-tuning a single LLM. A 32-billion-parameter agent trained with LOOP in the AppWorld environment outperforms the much larger OpenAI o1 agent by 9 percentage points (15% relative). To our knowledge, this is the first reported application of RL to IDAs that interact with a stateful, multi-domain, multi-app environment via direct API calls. Our analysis sheds light on the effectiveness of RL in this area, showing that the agent learns to consult the API documentation, avoid unwarranted assumptions, minimize confabulation, and recover from setbacks.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>TimeCAP: Learning to Contextualize, Augment, and Predict Time Series Events with Large Language Model Agents</title>
<link>https://arxiv.org/abs/2502.11418</link>
<guid>https://arxiv.org/abs/2502.11418</guid>
<content:encoded><![CDATA[
arXiv:2502.11418v2 Announce Type: replace 
Abstract: Time series data is essential in various applications, including climate modeling, healthcare monitoring, and financial analytics. Understanding the contextual information associated with real-world time series data is often essential for accurate and reliable event predictions. In this paper, we introduce TimeCAP, a time-series processing framework that creatively employs Large Language Models (LLMs) as contextualizers of time series data, extending their typical usage as predictors. TimeCAP incorporates two independent LLM agents: one generates a textual summary capturing the context of the time series, while the other uses this enriched summary to make more informed predictions. In addition, TimeCAP employs a multi-modal encoder that synergizes with the LLM agents, enhancing predictive performance through mutual augmentation of inputs with in-context examples. Experimental results on real-world datasets demonstrate that TimeCAP outperforms state-of-the-art methods for time series event prediction, including those utilizing LLMs as predictors, achieving an average improvement of 28.75% in F1 score.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Competing LLM Agents in a Non-Cooperative Game of Opinion Polarisation</title>
<link>https://arxiv.org/abs/2502.11649</link>
<guid>https://arxiv.org/abs/2502.11649</guid>
<content:encoded><![CDATA[
arXiv:2502.11649v2 Announce Type: replace 
Abstract: We introduce a novel non-cooperative game to analyse opinion formation and resistance, incorporating principles from social psychology such as confirmation bias, resource constraints, and influence penalties. Our simulation features Large Language Model (LLM) agents competing to influence a population, with penalties imposed for generating messages that propagate or counter misinformation. This framework integrates resource optimisation into the agents' decision-making process. Our findings demonstrate that while higher confirmation bias strengthens opinion alignment within groups, it also exacerbates overall polarisation. Conversely, lower confirmation bias leads to fragmented opinions and limited shifts in individual beliefs. Investing heavily in a high-resource debunking strategy can initially align the population with the debunking agent, but risks rapid resource depletion and diminished long-term influence.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Decentralized Learning Strategies for Estimation Error Minimization with Graph Neural Networks</title>
<link>https://arxiv.org/abs/2404.03227</link>
<guid>https://arxiv.org/abs/2404.03227</guid>
<content:encoded><![CDATA[
arXiv:2404.03227v2 Announce Type: replace-cross 
Abstract: We address the challenge of sampling and remote estimation for autoregressive Markovian processes in a multi-hop wireless network with statistically-identical agents. Agents cache the most recent samples from others and communicate over wireless collision channels governed by an underlying graph topology. Our goal is to minimize time-average estimation error and/or age of information with decentralized scalable sampling and transmission policies, considering both oblivious (where decision-making is independent of the physical processes) and non-oblivious policies (where decision-making depends on physical processes). We prove that in oblivious policies, minimizing estimation error is equivalent to minimizing the age of information. The complexity of the problem, especially the multi-dimensional action spaces and arbitrary network topologies, makes theoretical methods for finding optimal transmission policies intractable. We optimize the policies using a graphical multi-agent reinforcement learning framework, where each agent employs a permutation-equivariant graph neural network architecture. Theoretically, we prove that our proposed framework exhibits desirable transferability properties, allowing transmission policies trained on small- or moderate-size networks to be executed effectively on large-scale topologies. Numerical experiments demonstrate that (i) Our proposed framework outperforms state-of-the-art baselines; (ii) The trained policies are transferable to larger networks, and their performance gains increase with the number of agents; (iii) The training procedure withstands non-stationarity even if we utilize independent learning techniques; and, (iv) Recurrence is pivotal in both independent learning and centralized training and decentralized execution, and improves the resilience to non-stationarity in independent learning.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Q-Learning with Reference-Advantage Decomposition: Almost Optimal Regret and Logarithmic Communication Cost</title>
<link>https://arxiv.org/abs/2405.18795</link>
<guid>https://arxiv.org/abs/2405.18795</guid>
<content:encoded><![CDATA[
arXiv:2405.18795v2 Announce Type: replace-cross 
Abstract: In this paper, we consider model-free federated reinforcement learning for tabular episodic Markov decision processes. Under the coordination of a central server, multiple agents collaboratively explore the environment and learn an optimal policy without sharing their raw data. Despite recent advances in federated Q-learning algorithms achieving near-linear regret speedup with low communication cost, existing algorithms only attain suboptimal regrets compared to the information bound. We propose a novel model-free federated Q-learning algorithm, termed FedQ-Advantage. Our algorithm leverages reference-advantage decomposition for variance reduction and operates under two distinct mechanisms: synchronization between the agents and the server, and policy update, both triggered by events. We prove that our algorithm not only requires a lower logarithmic communication cost but also achieves an almost optimal regret, reaching the information bound up to a logarithmic factor and near-linear regret speedup compared to its single-agent counterpart when the time horizon is sufficiently large.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>U-net based prediction of cerebrospinal fluid distribution and ventricular reflux grading</title>
<link>https://arxiv.org/abs/2410.04460</link>
<guid>https://arxiv.org/abs/2410.04460</guid>
<content:encoded><![CDATA[
arXiv:2410.04460v2 Announce Type: replace-cross 
Abstract: Previous work indicates evidence that cerebrospinal fluid (CSF) plays a crucial role in brain waste clearance processes, and that altered flow patterns are associated with various diseases of the central nervous system. In this study, we investigate the potential of deep learning to predict the distribution in human brain of a gadolinium-based CSF contrast agent (tracer) administered intrathecal. For this, T1-weighted magnetic resonance imaging (MRI) scans taken at multiple time points before and after injection were utilized. We propose a U-net-based supervised learning model to predict pixel-wise signal increase at its peak after 24 hours. Performance is evaluated based on different tracer distribution stages provided during training, including predictions from baseline scans taken before injection. Our findings show that training with imaging data from only the first two hours post-injection yields tracer flow predictions comparable to models trained with additional later-stage scans. Validation against ventricular reflux gradings from neuroradiologists confirmed alignment with expert evaluations. These results demonstrate that deep learning-based methods for CSF flow prediction deserve more attention, as minimizing MR imaging without compromising clinical analysis could enhance efficiency, improve patient well-being, and lower healthcare costs.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fully First-Order Methods for Decentralized Bilevel Optimization</title>
<link>https://arxiv.org/abs/2410.19319</link>
<guid>https://arxiv.org/abs/2410.19319</guid>
<content:encoded><![CDATA[
arXiv:2410.19319v2 Announce Type: replace-cross 
Abstract: This paper focuses on decentralized stochastic bilevel optimization (DSBO) where agents only communicate with their neighbors. We propose Decentralized Stochastic Gradient Descent and Ascent with Gradient Tracking (DSGDA-GT), a novel algorithm that only requires first-order oracles that are much cheaper than second-order oracles widely adopted in existing works. We further provide a finite-time convergence analysis showing that for $n$ agents collaboratively solving the DSBO problem, the sample complexity of finding an $\epsilon$-stationary point in our algorithm is $\mathcal{O}(n^{-1}\epsilon^{-7})$, which matches the currently best-known results of the single-agent counterpart with linear speedup. The numerical experiments demonstrate both the communication and training efficiency of our algorithm.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>log-RRIM: Yield Prediction via Local-to-global Reaction Representation Learning and Interaction Modeling</title>
<link>https://arxiv.org/abs/2411.03320</link>
<guid>https://arxiv.org/abs/2411.03320</guid>
<content:encoded><![CDATA[
arXiv:2411.03320v4 Announce Type: replace-cross 
Abstract: Accurate prediction of chemical reaction yields is crucial for optimizing organic synthesis, potentially reducing time and resources spent on experimentation. With the rise of artificial intelligence (AI), there is growing interest in leveraging AI-based methods to accelerate yield predictions without conducting in vitro experiments. We present log-RRIM, an innovative graph transformer-based framework designed for predicting chemical reaction yields. A key feature of log-RRIM is its integration of a cross-attention mechanism that focuses on the interplay between reagents and reaction centers. This design reflects a fundamental principle in chemical reactions: the crucial role of reagents in influencing bond-breaking and formation processes, which ultimately affect reaction yields. log-RRIM also implements a local-to-global reaction representation learning strategy. This approach initially captures detailed molecule-level information and then models and aggregates intermolecular interactions. Through this hierarchical process, log-RRIM effectively captures how different molecular fragments contribute to and influence the overall reaction yield, regardless of their size variations. log-RRIM shows superior performance in our experiments, especially for medium to high-yielding reactions, proving its reliability as a predictor. The framework's sophisticated modeling of reactant-reagent interactions and precise capture of molecular fragment contributions make it a valuable tool for reaction planning and optimization in chemical synthesis. The data and codes of log-RRIM are accessible through https://github.com/ninglab/Yield_log_RRIM.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>IVE: Enhanced Probabilistic Forecasting of Intraday Volume Ratio with Transformers</title>
<link>https://arxiv.org/abs/2411.10956</link>
<guid>https://arxiv.org/abs/2411.10956</guid>
<content:encoded><![CDATA[
arXiv:2411.10956v2 Announce Type: replace-cross 
Abstract: This paper presents a new approach to volume ratio prediction in financial markets, specifically targeting the execution of Volume-Weighted Average Price (VWAP) strategies. Recognizing the importance of accurate volume profile forecasting, our research leverages the Transformer architecture to predict intraday volume ratio at a one-minute scale. We diverge from prior models that use log-transformed volume or turnover rates, instead opting for a prediction model that accounts for the intraday volume ratio's high variability, stabilized via log-normal transformation. Our input data incorporates not only the statistical properties of volume but also external volume-related features, absolute time information, and stock-specific characteristics to enhance prediction accuracy. The model structure includes an encoder-decoder Transformer architecture with a distribution head for greedy sampling, optimizing performance on high-liquidity stocks across both Korean and American markets. We extend the capabilities of our model beyond point prediction by introducing probabilistic forecasting that captures the mean and standard deviation of volume ratios, enabling the anticipation of significant intraday volume spikes. Furthermore, an agent with a simple trading logic demonstrates the practical application of our model through live trading tests in the Korean market, outperforming VWAP benchmarks over a period of two and a half months. Our findings underscore the potential of Transformer-based probabilistic models for volume ratio prediction and pave the way for future research advancements in this domain.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Targeted incentives for social tipping in heterogeneous networked populations</title>
<link>https://arxiv.org/abs/2501.13623</link>
<guid>https://arxiv.org/abs/2501.13623</guid>
<content:encoded><![CDATA[
arXiv:2501.13623v2 Announce Type: replace-cross 
Abstract: Many societal challenges, such as climate change or disease outbreaks, require coordinated behavioral changes. For many behaviors, the tendency of individuals to adhere to social norms can reinforce the status quo. However, these same social processes can also result in rapid, self-reinforcing change. Interventions may be strategically targeted to initiate endogenous social change processes, often referred to as social tipping. While recent research has considered how the size and targeting of such interventions impact their effectiveness at bringing about change, they tend to overlook constraints faced by policymakers, including the cost, speed, and distributional consequences of interventions. To address this complexity, we introduce a game-theoretic framework that includes heterogeneous agents and networks of local influence. We implement various targeting heuristics based on information about individual preferences and commonly used local network properties to identify individuals to incentivize. Analytical and simulation results suggest that there is a trade-off between preventing backsliding among targeted individuals and promoting change among non-targeted individuals. Thus, where the change is initiated in the population and the direction in which it propagates is essential to the effectiveness of interventions. We identify cost-optimal strategies under different scenarios, such as varying levels of resistance to change, preference heterogeneity, and homophily. These results provide insights that can be experimentally tested and help policymakers to better direct incentives.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>WinClick: GUI Grounding with Multimodal Large Language Models</title>
<link>https://arxiv.org/abs/2503.04730</link>
<guid>https://arxiv.org/abs/2503.04730</guid>
<content:encoded><![CDATA[
<div> 关键词：Graphical User Interface (GUI)，GUI接地，WinClick，Windows平台，WinSpot

总结:<br />
本文介绍了针对Windows平台开发的一种新型视觉GUI代理——WinClick。WinClick利用截图来检测可操作区域，旨在解决GUI接地问题，即根据指令准确定位屏幕元素的能力。为克服这一挑战，文中提出了一种基于LLM的GUI接地预训练方法，用于对齐GUI接地数据。同时，文章还引入了首个全面的Windows GUI接地基准——WinSpot。实验结果显示，结合GUI接地预训练的WinClick显著优于现有基线，为桌面环境中的GUI自动化提供了一种可扩展的解决方案。WinSpot已公开发布于https://github.com/zackhuiiiii/WinSpot。 <div>
arXiv:2503.04730v1 Announce Type: new 
Abstract: Graphical User Interface (GUI) tasks are vital for automating workflows such as software testing, user interface navigation. For users, the GUI is the most intuitive platform for interacting with a computer. Previous work identified a key challenge in developing visual GUI agents: GUI grounding - the ability to accurately locate screen elements based on instructions. However, most existing GUI agents rely on structured data formats like DOM or HTML files in training or inferencing, which are inaccessible across all applications, particular in a general desktop environments such as Windows OS. To address this, we introduce WinClick, a novel visual GUI agent developed in Windows platform. WinClick leverages screenshots to detect actionable regions. To overcome the challenge of GUI grounding, we enhance WinClick with GUI grounding pre-training and propose an LLM-based method for aligning GUI grounding data. Additionally, we introduce WinSpot, the first comprehensive benchmark for GUI grounding on Windows. Our experiments demonstrate that WinClick, combined with GUI grounding pre-training, significantly outperforms existing baselines, offering a scalable solution for GUI automation in desktop environments. WinSpot is publicly available at https://github.com/zackhuiiiii/WinSpot.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>How Personality Traits Shape LLM Risk-Taking Behaviour</title>
<link>https://arxiv.org/abs/2503.04735</link>
<guid>https://arxiv.org/abs/2503.04735</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 风险倾向, 累积前景理论 (CPT), 大五人格框架, GPT-4o

<br /><br />总结:
本文探讨了大型语言模型（LLMs）作为自主代理在风险决策中的行为特性，重点关注GPT-4o与人类基线及早期模型如GPT-4-Turbo的行为对比。研究运用累积前景理论和大五人格框架分析，发现GPT-4o在人格特质上表现出比人类平均值更高的尽责性和宜人性，同时在前景选择中展现出风险中立的理性代理行为。进一步干预GPT-4o的大五人格特质，尤其是开放性，对其风险倾向产生显著影响，与人类研究结果相呼应，其中开放性成为影响GPT-4o风险倾向的最重要因素。相比之下，早期模型GPT-4-Turbo在人格与风险关系的一致性方面表现不佳。这项研究深化了我们对LLM在风险环境下的决策行为理解，并揭示了基于人格特质的干预在塑造LLM决策过程中可能的作用及其局限性，对于构建更稳健、可预测的人工智能系统（如金融建模）具有重要意义。 <div>
arXiv:2503.04735v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly deployed as autonomous agents, necessitating a deeper understanding of their decision-making behaviour under risk. This study investigates the relationship between LLMs' personality traits and risk propensity, employing cumulative prospect theory (CPT) and the Big Five personality framework. We focus on GPT-4o, comparing its behaviour to human baselines and earlier models. Our findings reveal that GPT-4o exhibits higher Conscientiousness and Agreeableness traits compared to human averages, while functioning as a risk-neutral rational agent in prospect selection. Interventions on GPT-4o's Big Five traits, particularly Openness, significantly influence its risk propensity, mirroring patterns observed in human studies. Notably, Openness emerges as the most influential factor in GPT-4o's risk propensity, aligning with human findings. In contrast, legacy models like GPT-4-Turbo demonstrate inconsistent generalization of the personality-risk relationship. This research advances our understanding of LLM behaviour under risk and elucidates the potential and limitations of personality-based interventions in shaping LLM decision-making. Our findings have implications for the development of more robust and predictable AI systems such as financial modelling.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A case for specialisation in non-human entities</title>
<link>https://arxiv.org/abs/2503.04742</link>
<guid>https://arxiv.org/abs/2503.04742</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态AI模型、人工通用智能（AGI）、专业化、机器学习稳健性、指定治理

<br /><br />总结:
本文针对大型多模态AI模型和广泛热议的大规模语言模型推动人工通用智能（AGI）成为主流AI开发重点的现象，提出了对专业化的倡导。文章首先反驳了反对专业化的常见观点，并指出这些观点在人类劳动力领域的相关性实际上支持了非人类代理（如算法或人类组织）的专业化。其次，文章提出四个支持专业化的论点，涉及机器学习的稳健性、计算机安全、社会科学以及文化进化等领域。接着，文章强调了“规格说明”的重要性，认为现有的机器学习方法在安全性工程和软件形式验证的良好实践方面存在不足，并讨论了一些正在出现的改进措施如何缩小这一差距。最后，文章主张对于难以明确定义的系统，有必要实施“指定治理”。 <div>
arXiv:2503.04742v1 Announce Type: new 
Abstract: With the rise of large multi-modal AI models, fuelled by recent interest in large language models (LLMs), the notion of artificial general intelligence (AGI) went from being restricted to a fringe community, to dominate mainstream large AI development programs.
  In contrast, in this paper, we make a \emph{case for specialisation}, by reviewing the pitfalls of generality and stressing the industrial value of specialised
  systems.
  Our contribution is threefold. First, we review the most widely accepted arguments \emph{against} specialisation, and discuss how their relevance in the context of human labour is actually an argument \emph{for} specialisation in the case of non human agents, be they algorithms or human organisations. Second, we propose four arguments \emph{in favor of} specialisation, ranging from machine learning robustness, to computer security, social sciences and cultural evolution.
  Third, we finally make a case for \emph{specification}, discuss how the machine learning approach to AI has so far failed to catch up with good practices from safety-engineering and formal verification of software, and discuss how some emerging good practices in machine learning help reduce this gap.
  In particular, we justify the need for \emph{specified governance} for hard-to-specify systems.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Position: AI agents should be regulated based on autonomous action sequences</title>
<link>https://arxiv.org/abs/2503.04750</link>
<guid>https://arxiv.org/abs/2503.04750</guid>
<content:encoded><![CDATA[
<div> 关键词：AI代理、监管、行动序列、长期规划、风险评估

总结:
本文是一篇立场论文，主张应当根据人工智能（AI）代理自主执行的行为序列对其进行监管。鉴于具有长期规划和战略能力的AI代理可能带来人类灭绝和不可逆全球性灾难的重大风险，现有法规中仅关注计算规模作为潜在危害的代理指标的做法被指出存在不足。文章讨论了来自AI科学家的相关监管建议以及关于存在风险的观点，并强调相较于依赖观察环境状态的影响度量，考虑行为序列的重要性。 <div>
arXiv:2503.04750v1 Announce Type: new 
Abstract: This position paper argues that AI agents should be regulated based on the sequence of actions they autonomously take. AI agents with long-term planning and strategic capabilities can pose significant risks of human extinction and irreversible global catastrophes. While existing regulations often focus on computational scale as a proxy for potential harm, we contend that such measures are insufficient for assessing the risks posed by AI agents whose capabilities arise primarily from inference-time computation. To support our position, we discuss relevant regulations and recommendations from AI scientists regarding existential risks, as well as the advantages of action sequences over existing impact measures that require observing environmental states.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Agentic AI and the Cyber Arms Race</title>
<link>https://arxiv.org/abs/2503.04760</link>
<guid>https://arxiv.org/abs/2503.04760</guid>
<content:encoded><![CDATA[
<div> 关键词：Agentic AI、网络安全、攻防、网络战、全球政治

总结:
本文探讨了随着Agentic AI技术的发展及其在攻击者和防御者中的应用，对网络安全以及全球政治格局产生的影响。随着AI代理能力的增强，原本只有资源最丰富的行动方才能掌握的能力将得到广泛普及，这将改变网络战的形态并重塑国际政治关系。 <div>
arXiv:2503.04760v1 Announce Type: new 
Abstract: Agentic AI is shifting the cybersecurity landscape as attackers and defenders leverage AI agents to augment humans and automate common tasks. In this article, we examine the implications for cyber warfare and global politics as Agentic AI becomes more powerful and enables the broad proliferation of capabilities only available to the most well resourced actors today.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DiMA: An LLM-Powered Ride-Hailing Assistant at DiDi</title>
<link>https://arxiv.org/abs/2503.04768</link>
<guid>https://arxiv.org/abs/2503.04768</guid>
<content:encoded><![CDATA[
<div> 关键词: DiMA、DiDi Chuxing、LLM、订单规划、对话系统

总结:
本文介绍了应用于滴滴出行的智能移动助手DiMA，该助手借助大型语言模型（LLM）技术，旨在提供无缝对接的打车服务及超越传统服务的交互体验。为了实现这一目标，DiMA采用了具有时空感知能力的订单规划模块，利用外部工具进行精确的时空推理和逐步的订单规划。此外，还开发了一个成本效益高的对话系统，整合了多种对话回复器并结合成本意识的LLM配置，以处理多样化的对话目标，平衡响应质量和延迟。同时，引入了一种持续微调策略，使助理的行为与人类偏好的决策过程保持一致。自部署以来，DiMA在实际应用中表现出色，订单规划准确率达到93%，响应生成准确率为92%。离线实验进一步证实了DiMA的优势，相比三个最先进的代理框架，在订单规划上提高了最多70.23%，在响应生成上提高了高达321.27%，同时将延迟降低了$0.72\times$到$5.47\times$，证明了DiMA作为网约车服务的高效、智能和实用的移动端助手的地位。 <div>
arXiv:2503.04768v1 Announce Type: new 
Abstract: On-demand ride-hailing services like DiDi, Uber, and Lyft have transformed urban transportation, offering unmatched convenience and flexibility. In this paper, we introduce DiMA, an LLM-powered ride-hailing assistant deployed in DiDi Chuxing. Its goal is to provide seamless ride-hailing services and beyond through a natural and efficient conversational interface under dynamic and complex spatiotemporal urban contexts. To achieve this, we propose a spatiotemporal-aware order planning module that leverages external tools for precise spatiotemporal reasoning and progressive order planning. Additionally, we develop a cost-effective dialogue system that integrates multi-type dialog repliers with cost-aware LLM configurations to handle diverse conversation goals and trade-off response quality and latency. Furthermore, we introduce a continual fine-tuning scheme that utilizes real-world interactions and simulated dialogues to align the assistant's behavior with human preferred decision-making processes. Since its deployment in the DiDi application, DiMA has demonstrated exceptional performance, achieving 93% accuracy in order planning and 92% in response generation during real-world interactions. Offline experiments further validate DiMA capabilities, showing improvements of up to 70.23% in order planning and 321.27% in response generation compared to three state-of-the-art agent frameworks, while reducing latency by $0.72\times$ to $5.47\times$. These results establish DiMA as an effective, efficient, and intelligent mobile assistant for ride-hailing services.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Towards Anthropomorphic Conversational AI Part I: A Practical Framework</title>
<link>https://arxiv.org/abs/2503.04787</link>
<guid>https://arxiv.org/abs/2503.04787</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 社交与对话智能, 多模块框架, 知识管理, 强化学习

总结:
本文提出了一个两阶段解决方案，旨在提升大型语言模型在对话交流中的社交和对话智能，使其更接近人类表现。第一阶段，研究者设计了一个多模块框架，包括用于推理的思考模块、用于知识管理和外部信息获取的资源模块以及生成情境适当交互的响应模块。这些模块协同工作，使AI代理能够提供更为人性化的对话体验。第二阶段（留作未来工作）计划利用经过过滤和标注后的对话数据进行强化学习训练，进一步捕捉人类偏好。实验结果显示，志愿者与基于该框架集成的同款大型语言模型的AI角色进行了超过3000轮对话，评价者认为该框架显著提升了AI的社交和对话智能，而且无需对大型语言模型进行微调。 <div>
arXiv:2503.04787v1 Announce Type: new 
Abstract: Large language models (LLMs), due to their advanced natural language capabilities, have seen significant success in applications where the user interface is usually a conversational artificial intelligence (AI) agent and engages the user through multi-round conversations. However, many scenarios require the agents to exhibit stronger social and conversational intelligence and demonstrate more human-like (anthropomorphic) reactions. This is an aspect that foundational LLMs have yet to fully address such that a single call of foundational models might be insufficient.
  To bridge this gap, we propose a two-stage solution. In this work, we focus on the first stage, introducing a multi-module framework designed to replicate the key aspects of human intelligence involved in conversations. This framework comprises thinking modules for reasoning, resource modules for managing knowledge and external information, and response modules for generating contextually appropriate interactions. With all the modules cooperating, the framework would empower the agents to provide a better human-like conversation experience. In the second stage of our approach, these conversational data, after filtering and labeling, can serve as training and testing data for reinforcement learning, enabling AI to better capture human preferences. This stage is left for future work.
  In our experiments, volunteers engaged in over 3000 rounds of conversation with the same AI character powered by a standalone LLM and our framework which integrates the same LLM. A separate group of evaluators rated the conversation samples, revealing that our framework significantly enhanced the social and conversational intelligence, even without fine-tuning the LLM.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Runtime Learning of Quadruped Robots in Wild Environments</title>
<link>https://arxiv.org/abs/2503.04794</link>
<guid>https://arxiv.org/abs/2503.04794</guid>
<content:encoded><![CDATA[
<div> 关键词：四足机器人、运行时学习框架、深度强化学习、高保证教师、高性能学生<br /><br />总结:
本文提出了一种针对四足机器人的运行时学习框架，使它们能够在动态复杂环境中安全地学习和适应。该框架集成了感知、导航和控制，形成一个闭环系统。核心创新点在于控制器模块中的两个互动互补组件：高性能学生（HP-Student）与高保证教师（HA-Teacher）。HP-Student 是一种深度强化学习代理，通过自我学习和教学式学习来发展出安全高效的行为策略；而 HA-Teacher 是一个简化的、可验证的基于物理模型的控制器，其职责是教导 HP-Student 安全知识并为机器人的安全移动提供备用方案。HA-Teacher 创新性地具备实时物理模型、实时行为策略以及实时控制目标，使其能有效应对实际环境中的动态挑战，确保安全性。此外，框架中还包括一个协调器，用于有效地管理 HP-Student 和 HA-Teacher 之间的交互。实验表明，该提出的运行时学习框架在Unitree Go2机器人在Nvidia Isaac Gym环境下的表现优于现有的安全深度强化学习方法。 <div>
arXiv:2503.04794v1 Announce Type: new 
Abstract: This paper presents a runtime learning framework for quadruped robots, enabling them to learn and adapt safely in dynamic wild environments. The framework integrates sensing, navigation, and control, forming a closed-loop system for the robot. The core novelty of this framework lies in two interactive and complementary components within the control module: the high-performance (HP)-Student and the high-assurance (HA)-Teacher. HP-Student is a deep reinforcement learning (DRL) agent that engages in self-learning and teaching-to-learn to develop a safe and high-performance action policy. HA-Teacher is a simplified yet verifiable physics-model-based controller, with the role of teaching HP-Student about safety while providing a backup for the robot's safe locomotion. HA-Teacher is innovative due to its real-time physics model, real-time action policy, and real-time control goals, all tailored to respond effectively to real-time wild environments, ensuring safety. The framework also includes a coordinator who effectively manages the interaction between HP-Student and HA-Teacher. Experiments involving a Unitree Go2 robot in Nvidia Isaac Gym and comparisons with state-of-the-art safe DRLs demonstrate the effectiveness of the proposed runtime learning framework.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Advancing MAPF towards the Real World: A Scalable Multi-Agent Realistic Testbed (SMART)</title>
<link>https://arxiv.org/abs/2503.04798</link>
<guid>https://arxiv.org/abs/2503.04798</guid>
<content:encoded><![CDATA[
<div> 关键词: Scalable Multi-Agent Realistic Testbed (SMART), Multi-Agent Path Finding (MAPF), 物理引擎模拟器, 执行监控框架, 行动依赖图<br /><br />总结:
本文介绍了Scalable Multi-Agent Realistic Testbed (SMART)，这是一个用于评估Multi-Agent Path Finding (MAPF)算法的真实感和高效的软件工具。SMART着重于规划一组智能体的碰撞避免路径。尽管现有的MAPF算法能在几秒内为数百台机器人规划路径，但它们通常依赖简化的机器人模型，使其在真实世界中的性能不明确。为了填补这一空白，SMART提供了三个主要优势：(1) 使用基于物理引擎的模拟器创建真实的仿真环境，考虑了如机器人动力学和执行不确定性等复杂的真实世界因素；(2) 采用基于Action Dependency Graph的执行监控框架，方便与各种MAPF算法和机器人模型无缝集成；(3) 能够扩展到数千台机器人规模。此外，研究者还使用SMART探讨并展示了关于在实际场景中执行MAPF算法的相关研究问题。相关代码已公开发布在https://jingtianyan.github.io/publication/2025-smart。 <div>
arXiv:2503.04798v1 Announce Type: new 
Abstract: We present Scalable Multi-Agent Realistic Testbed (SMART), a realistic and efficient software tool for evaluating Multi-Agent Path Finding (MAPF) algorithms. MAPF focuses on planning collision-free paths for a group of agents. While state-of-the-art MAPF algorithms can plan paths for hundreds of robots in seconds, they often rely on simplified robot models, making their real-world performance unclear. Researchers typically lack access to hundreds of physical robots in laboratory settings to evaluate the algorithms. Meanwhile, industrial professionals who lack expertise in MAPF require an easy-to-use simulator to efficiently test and understand the performance of MAPF algorithms in their specific settings. SMART fills this gap with several advantages: (1) SMART uses a physics-engine-based simulator to create realistic simulation environments, accounting for complex real-world factors such as robot kinodynamics and execution uncertainties, (2) SMART uses an execution monitor framework based on the Action Dependency Graph, facilitating seamless integration with various MAPF algorithms and robot models, and (3) SMART scales to thousands of robots. In addition, we use SMART to explore and demonstrate research questions about the execution of MAPF algorithms in real-world scenarios. The code is publicly available at https://jingtianyan.github.io/publication/2025-smart.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent System for AI-Assisted Extraction of Narrative Arcs in TV Series</title>
<link>https://arxiv.org/abs/2503.04817</link>
<guid>https://arxiv.org/abs/2503.04817</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、叙事弧线、Grey's Anatomy、关系型数据库、语义数据库<br /><br />总结:<br />
本文提出了一种用于提取和分析电视剧复杂剧情线索的多智能体系统。该系统以美剧《实习医生格蕾》第一季为测试对象，识别出了三种叙事类型：单元剧（自包含）、肥皂剧（侧重人物关系）和类型特定剧（严格关联系列所属类型）。系统将这些剧情发展的阶段性进程分别存储在关系型和语义型数据库中，便于结构化分析与对比。为了平衡自动化与批判性解读，系统配备了一个图形界面，允许人类通过工具对数据进行细化增强和可视化。实验显示，系统在识别单元剧剧情弧线及角色实体方面表现出色，但在识别重叠剧情线及微妙动态方面存在局限，突显了结合计算技术和人类专家在叙事分析中的潜力。这种方法对于其他以文本形式连载的作品也同样具有应用前景。未来的工作将探索整合对话和视觉等多模态输入，并进一步扩大到更多类型的电视剧进行测试以优化该系统。 <div>
arXiv:2503.04817v1 Announce Type: new 
Abstract: Serialized TV shows are built on complex storylines that can be hard to track and evolve in ways that defy straightforward analysis. This paper introduces a multi-agent system designed to extract and analyze these narrative arcs. Tested on the first season of Grey's Anatomy (ABC 2005-), the system identifies three types of arcs: Anthology (self-contained), Soap (relationship-focused), and Genre-Specific (strictly related to the series' genre). Episodic progressions of these arcs are stored in both relational and semantic (vectorial) databases, enabling structured analysis and comparison. To bridge the gap between automation and critical interpretation, the system is paired with a graphical interface that allows for human refinement using tools to enhance and visualize the data. The system performed strongly in identifying Anthology Arcs and character entities, but its reliance on textual paratexts (such as episode summaries) revealed limitations in recognizing overlapping arcs and subtler dynamics. This approach highlights the potential of combining computational and human expertise in narrative analysis. Beyond television, it offers promise for serialized written formats, where the narrative resides entirely in the text. Future work will explore the integration of multimodal inputs, such as dialogue and visuals, and expand testing across a wider range of genres to refine the system further.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Preserving Cultural Identity with Context-Aware Translation Through Multi-Agent AI Systems</title>
<link>https://arxiv.org/abs/2503.04827</link>
<guid>https://arxiv.org/abs/2503.04827</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体AI框架、文化适应性翻译、语言多样性、GPT-4、CrewAI、LangChain、语境保真度、偏见缓解、低资源语言

<br /><br />总结:
本文提出了一种多智能体AI框架，旨在解决全球化背景下语言多样性的保护问题以及现有AI驱动翻译模型在捕捉文化差异上的不足。该框架专注于为弱势语言社区提供具有文化适应性的翻译服务，通过专门的代理进行翻译、解释、内容合成和偏见评估，以确保语言准确性和文化相关性得以保留。利用CrewAI和LangChain工具，系统增强了上下文保真度并减轻了翻译中的偏见。实验分析表明，该框架对比GPT-4展现出更优的表现，能够生成富含上下文信息和文化内涵的翻译结果，对于推动土著语言、区域语言和低资源语言的发展具有重要意义。这项研究强调了多智能体AI在构建公平、可持续且具有文化敏感性的自然语言处理技术方面所具有的潜力，符合《面向欠发达社区的语言模型》中关于AI治理、文化NLP和可持续NLP等原则。相关实验代码库已公开发布于：<br />https://github.com/ciol-researchlab/Context-Aware_Translation_MAS <div>
arXiv:2503.04827v1 Announce Type: new 
Abstract: Language is a cornerstone of cultural identity, yet globalization and the dominance of major languages have placed nearly 3,000 languages at risk of extinction. Existing AI-driven translation models prioritize efficiency but often fail to capture cultural nuances, idiomatic expressions, and historical significance, leading to translations that marginalize linguistic diversity. To address these challenges, we propose a multi-agent AI framework designed for culturally adaptive translation in underserved language communities. Our approach leverages specialized agents for translation, interpretation, content synthesis, and bias evaluation, ensuring that linguistic accuracy and cultural relevance are preserved. Using CrewAI and LangChain, our system enhances contextual fidelity while mitigating biases through external validation. Comparative analysis shows that our framework outperforms GPT-4o, producing contextually rich and culturally embedded translations, a critical advancement for Indigenous, regional, and low-resource languages. This research underscores the potential of multi-agent AI in fostering equitable, sustainable, and culturally sensitive NLP technologies, aligning with the AI Governance, Cultural NLP, and Sustainable NLP pillars of Language Models for Underserved Communities. Our full experimental codebase is publicly available at: https://github.com/ciol-researchlab/Context-Aware_Translation_MAS
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cite Before You Speak: Enhancing Context-Response Grounding in E-commerce Conversational LLM-Agents</title>
<link>https://arxiv.org/abs/2503.04830</link>
<guid>https://arxiv.org/abs/2503.04830</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、对话式购物代理、准确性、事实依据、引用体验

<br />
总结:
本文探讨了利用大型语言模型（LLMs）构建的对话式购物代理（CSA）面临的两大挑战：生成不准确或无支持的言论以及缺乏信息来源引用。为解决这些问题，文章提出了一种可轻松投入生产的解决方案，该方案结合了上下文学习（ICL）和多用户体验推理（MUI），能在生成的回答中添加引用来源，同时不会影响其他现有用户体验功能。通过合理的用户界面设计，这些引用标记可以链接到相关产品信息，展示信息来源给顾客。此外，文中还建立了自动评估指标和可扩展的基准，以全面评价LLM的事实依据与归因能力。实验结果显示，采用这种引用生成范式能显著提升LLM响应的依据性达13.83%。因此，这一解决方案不仅解决了LLM的基础问题，也为对话式AI带来了更高的透明度。 <div>
arXiv:2503.04830v1 Announce Type: new 
Abstract: With the advancement of conversational large language models (LLMs), several LLM-based Conversational Shopping Agents (CSA) have been developed to help customers answer questions and smooth their shopping journey in e-commerce domain. The primary objective in building a trustworthy CSA is to ensure the agent's responses are accurate and factually grounded, which is essential for building customer trust and encouraging continuous engagement. However, two challenges remain. First, LLMs produce hallucinated or unsupported claims. Such inaccuracies risk spreading misinformation and diminishing customer trust. Second, without providing knowledge source attribution in CSA response, customers struggle to verify LLM-generated information. To address these challenges, we present an easily productionized solution that enables a "citation experience" utilizing In-context Learning (ICL) and Multi-UX-Inference (MUI) to generate responses with citations to attribute its original sources without interfering other existing UX features. With proper UX design, these citation marks can be linked to the related product information and display the source to our customers. In this work, we also build auto-metrics and scalable benchmarks to holistically evaluate LLM's grounding and attribution capabilities. Our experiments demonstrate that incorporating this citation generation paradigm can substantially enhance the grounding of LLM responses by 13.83% on the real-world data. As such, our solution not only addresses the immediate challenges of LLM grounding issues but also adds transparency to conversational AI.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Curiosity-Driven Imagination: Discovering Plan Operators and Learning Associated Policies for Open-World Adaptation</title>
<link>https://arxiv.org/abs/2503.04931</link>
<guid>https://arxiv.org/abs/2503.04931</guid>
<content:encoded><![CDATA[
<div> 关键词：动态环境、机器人、任务与运动规划（TAMP）、混合规划与学习系统、神经网络

总结:
本文针对机器人在动态、不确定环境（即“开放世界”）中快速适应的挑战，提出了一个混合规划与学习系统。该系统整合了两种模型：一种是以神经网络为基础的低级模型，通过内在好奇心模块（ICM）学习随机过渡并驱动探索；另一种是高级符号规划模型，利用操作符捕获抽象过渡，使代理能在“想象”空间中进行计划并生成奖励机器。在具有序列新颖性注入的机器人操纵领域的评估中，该方法表现出更快的收敛速度，并优于现有的先进混合方法。<br /><br /> <div>
arXiv:2503.04931v1 Announce Type: new 
Abstract: Adapting quickly to dynamic, uncertain environments-often called "open worlds"-remains a major challenge in robotics. Traditional Task and Motion Planning (TAMP) approaches struggle to cope with unforeseen changes, are data-inefficient when adapting, and do not leverage world models during learning. We address this issue with a hybrid planning and learning system that integrates two models: a low level neural network based model that learns stochastic transitions and drives exploration via an Intrinsic Curiosity Module (ICM), and a high level symbolic planning model that captures abstract transitions using operators, enabling the agent to plan in an "imaginary" space and generate reward machines. Our evaluation in a robotic manipulation domain with sequential novelty injections demonstrates that our approach converges faster and outperforms state-of-the-art hybrid methods.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VQEL: Enabling Self-Developed Symbolic Language in Agents through Vector Quantization in Emergent Language Games</title>
<link>https://arxiv.org/abs/2503.04940</link>
<guid>https://arxiv.org/abs/2503.04940</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主语言学习、内部语言学习、自我游戏、向量量化(VQ)、强化学习 (REINFORCE)

<br />
总结:
本文提出了一个名为VQEL的新方法，重点关注在自主语言学习领域中，使代理能在自我游戏中发明和发展离散符号表征。传统的研究主要集中在通过多智能体间的交互建立通信协议，而对内部语言学习——即语言作为个体思考、自我反思和问题解决工具的作用——关注不足。VQEL通过将向量量化引入代理的架构，使得代理能够在没有其他代理参与的情况下进行自我游戏并习得符号表示。随后，代理可以通过强化学习以及与其他代理在互惠游戏阶段的互动来进一步提升其语言能力。实验表明，与传统的REINFORCE方法相比，VQEL不仅表现出优越性，还由于向量量化的应用而具备更好的控制力和减少崩溃的风险。 <div>
arXiv:2503.04940v1 Announce Type: new 
Abstract: In the field of emergent language, efforts have traditionally focused on developing communication protocols through interactions between agents in referential games. However, the aspect of internal language learning, where language serves not only as a communicative tool with others but also as a means for individual thinking, self-reflection, and problem-solving remains underexplored. Developing a language through self-play, without another agent's involvement, poses a unique challenge. It requires an agent to craft symbolic representations and train them using direct gradient methods. The challenge here is that if an agent attempts to learn symbolic representations through self-play using conventional modeling and techniques such as REINFORCE, the solution will offer no advantage over previous multi-agent approaches. We introduce VQEL, a novel method that incorporates Vector Quantization into the agents' architecture, enabling them to autonomously invent and develop discrete symbolic representations in a self-play referential game. Following the self-play phase, agents can enhance their language through reinforcement learning and interactions with other agents in the mutual-play phase. Our experiments across various datasets demonstrate that VQEL not only outperforms the traditional REINFORCE method but also benefits from improved control and reduced susceptibility to collapse, thanks to the incorporation of vector quantization.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>INTENT: Trajectory Prediction Framework with Intention-Guided Contrastive Clustering</title>
<link>https://arxiv.org/abs/2503.04952</link>
<guid>https://arxiv.org/abs/2503.04952</guid>
<content:encoded><![CDATA[
<div> 关键词: 轨迹预测，环境上下文，多模态，意图理解，INTENT模型

总结:<br />
本文关注于道路代理（如行人、车辆）的精确轨迹预测问题，提出了一种新的高效意图引导的轨迹预测模型INTENT。该模型主要特点包括：<br />
1. 通过对比聚类方法，明确地对道路代理的意图进行建模，适应人类意图在轨迹中的模糊性和抽象性；<br />
2. 基于多层感知机（MLPs）构建，大大减少了训练和推理时间，使其更加高效，适合真实世界的部署需求；<br />
3. 利用估计的意图以及创新的轨迹观察转换算法，生成更稳健的轨迹表示，从而提高了预测精度。在多个真实的行人和自动驾驶车辆轨迹数据集上的实验验证了INTENT的有效性和效率。 <div>
arXiv:2503.04952v1 Announce Type: new 
Abstract: Accurate trajectory prediction of road agents (e.g., pedestrians, vehicles) is an essential prerequisite for various intelligent systems applications, such as autonomous driving and robotic navigation. Recent research highlights the importance of environmental contexts (e.g., maps) and the "multi-modality" of trajectories, leading to increasingly complex model structures. However, real-world deployments require lightweight models that can quickly migrate and adapt to new environments. Additionally, the core motivations of road agents, referred to as their intentions, deserves further exploration. In this study, we advocate that understanding and reasoning road agents' intention plays a key role in trajectory prediction tasks, and the main challenge is that the concept of intention is fuzzy and abstract. To this end, we present INTENT, an efficient intention-guided trajectory prediction model that relies solely on information contained in the road agent's trajectory. Our model distinguishes itself from existing models in several key aspects: (i) We explicitly model road agents' intentions through contrastive clustering, accommodating the fuzziness and abstraction of human intention in their trajectories. (ii) The proposed INTENT is based solely on multi-layer perceptrons (MLPs), resulting in reduced training and inference time, making it very efficient and more suitable for real-world deployment. (iii) By leveraging estimated intentions and an innovative algorithm for transforming trajectory observations, we obtain more robust trajectory representations that lead to superior prediction accuracy. Extensive experiments on real-world trajectory datasets for pedestrians and autonomous vehicles demonstrate the effectiveness and efficiency of INTENT.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Security-Aware Sensor Fusion with MATE: the Multi-Agent Trust Estimator</title>
<link>https://arxiv.org/abs/2503.04954</link>
<guid>https://arxiv.org/abs/2503.04954</guid>
<content:encoded><![CDATA[
<div> 关键词：sensor fusion, 安全意识, 信任估计, 隐藏马尔可夫模型, 信任权重更新

<br /><br />总结:
该文针对智能城市等多Agent网络系统中缺乏安全意识的传感器融合问题，设计了一种基于信任估计的安全意识传感器融合方案。该方案将信任估计建模为隐藏马尔可夫模型，并通过将传感器数据映射为信任伪测量值（PSMs），递归地在贝叶斯框架下更新信任后验概率。然后，信任度量被用于传感器融合，以实现对态势感知的信任权重更新。文章提出了新颖的视场估计算法、将传感器数据映射为PSMs的逻辑以及有效的贝叶斯更新推导。通过在物理基础的Unreal Engine模拟器CARLA中的案例研究和蒙特卡洛仿真，评估了在遭受攻击的条件下，安全意识融合方案对于构建可信态势感知的能力。实验结果显示，该安全意识融合方案即使在敌对环境中也能确保态势感知的可靠性。 <div>
arXiv:2503.04954v1 Announce Type: new 
Abstract: Lacking security awareness, sensor fusion in systems with multi-agent networks such as smart cities is vulnerable to attacks. To guard against recent threats, we design security-aware sensor fusion that is based on the estimates of distributions over trust. Trust estimation can be cast as a hidden Markov model, and we solve it by mapping sensor data to trust pseudomeasurements (PSMs) that recursively update trust posteriors in a Bayesian context. Trust then feeds sensor fusion to facilitate trust-weighted updates to situational awareness. Essential to security-awareness are a novel field of view estimator, logic to map sensor data into PSMs, and the derivation of efficient Bayesian updates. We evaluate security-aware fusion under attacks on agents using case studies and Monte Carlo simulation in the physics-based Unreal Engine simulator, CARLA. A mix of novel and classical security-relevant metrics show that our security-aware fusion enables building trustworthy situational awareness even in hostile conditions.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>SafeArena: Evaluating the Safety of Autonomous Web Agents</title>
<link>https://arxiv.org/abs/2503.04957</link>
<guid>https://arxiv.org/abs/2503.04957</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM-based agents, SafeArena, benchmark, harmful tasks, Agent Risk Assessment

总结:
本文提出了一种名为SafeArena的新基准，用于评估基于LLM的智能代理在处理网络任务时被恶意利用的风险。该基准包括了250个安全任务和250个有害任务，涵盖了四大网站和五个危害类别：错误信息、非法活动、骚扰、网络犯罪和社会偏见。文中对包括GPT-4o、Claude-3.5 Sonnet、Qwen-2-VL 72B和Llama-3.2 90B在内的领先LLM基智能代理进行了测试。同时，作者引入了Agent Risk Assessment框架来系统性地分析这些智能代理对于有害任务的易感程度。研究发现，这些智能代理对于恶意请求的服从度令人惊讶，其中GPT-4o和Qwen-2分别完成了34.7%和27.3%的有害请求。这突显出了为网络智能代理进行安全性对齐程序的紧迫需求。 SafeArena基准可在此获取：https://safearena.github.io <div>
arXiv:2503.04957v1 Announce Type: new 
Abstract: LLM-based agents are becoming increasingly proficient at solving web-based tasks. With this capability comes a greater risk of misuse for malicious purposes, such as posting misinformation in an online forum or selling illicit substances on a website. To evaluate these risks, we propose SafeArena, the first benchmark to focus on the deliberate misuse of web agents. SafeArena comprises 250 safe and 250 harmful tasks across four websites. We classify the harmful tasks into five harm categories -- misinformation, illegal activity, harassment, cybercrime, and social bias, designed to assess realistic misuses of web agents. We evaluate leading LLM-based web agents, including GPT-4o, Claude-3.5 Sonnet, Qwen-2-VL 72B, and Llama-3.2 90B, on our benchmark. To systematically assess their susceptibility to harmful tasks, we introduce the Agent Risk Assessment framework that categorizes agent behavior across four risk levels. We find agents are surprisingly compliant with malicious requests, with GPT-4o and Qwen-2 completing 34.7% and 27.3% of harmful requests, respectively. Our findings highlight the urgent need for safety alignment procedures for web agents. Our benchmark is available here: https://safearena.github.io
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Agent Ergodic Exploration under Smoke-Based, Time-Varying Sensor Visibility Constraints</title>
<link>https://arxiv.org/abs/2503.04998</link>
<guid>https://arxiv.org/abs/2503.04998</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent informative path planning, ergodic trajectory optimization, time-varying environmental process, smoke diffusion, drone search

总结:<br />
本文研究了多智能体信息性路径规划（IPP）问题，尤其关注传感器可见性随时间变化的无人机搜索野火场景。文中利用ergodic轨迹优化方法，生成能够使机器人在具有高预期信息区域停留时间成比例的路径。具体而言，通过模拟烟雾扩散这一动态环境过程构建传感器可见性模型，并据此不断计算预期信息分布（EID），用于ETO算法。实验表明，该探索方法在信息收集方面优于基准搜索方法和朴素的ergodic搜索形式化方案。 <div>
arXiv:2503.04998v1 Announce Type: new 
Abstract: In this work, we consider the problem of multi-agent informative path planning (IPP) for robots whose sensor visibility continuously changes as a consequence of a time-varying natural phenomenon. We leverage ergodic trajectory optimization (ETO), which generates paths such that the amount of time an agent spends in an area is proportional to the expected information in that area. We focus specifically on the problem of multi-agent drone search of a wildfire, where we use the time-varying environmental process of smoke diffusion to construct a sensor visibility model. This sensor visibility model is used to repeatedly calculate an expected information distribution (EID) to be used in the ETO algorithm. Our experiments show that our exploration method achieves improved information gathering over both baseline search methods and naive ergodic search formulations.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Bridging the AI Adoption Gap: Designing an Interactive Pedagogical Agent for Higher Education Instructors</title>
<link>https://arxiv.org/abs/2503.05039</link>
<guid>https://arxiv.org/abs/2503.05039</guid>
<content:encoded><![CDATA[
<div> 关键词: AI教育整合、教师采纳、互动教学代理、人性化设计、Chatbot

<br /><br />总结:
本研究关注于如何通过人性化设计方法来开发支持教师更广泛采纳AI工具的AI交互式教学代理。通过对五位教学专家的访谈，探讨了现有策略如何满足教师的教学需求。随后，组织了一场参与式设计研讨会，十位教学专家对针对不同AI认知水平和态度的教师设计的一款Chatbot故事板进行了评审，并评估了基于常见教学挑战的LLM生成的建议质量。研究发现，对于持保守态度的AI教师来说，建立信任感至关重要，同时强调需要社交透明度（如展示同行如何使用该工具）以及让教师灵活控制与系统的交互程度。此外，还提出了改进AI生成教学建议质量的设计建议，例如根据教师先前的教学经验进行调整。这项工作凸显出支持持保守态度的AI教师的迫切性，因为AI素养和态度密切相关。若不进行深思熟虑的设计，则有可能加剧教育鸿沟，减少学生的学习机会。 <div>
arXiv:2503.05039v1 Announce Type: new 
Abstract: Instructors play a pivotal role in integrating AI into education, yet their adoption of AI-powered tools remains inconsistent. Despite this, limited research explores how to design AI tools that support broader instructor adoption. This study applies a human-centered design approach, incorporating qualitative methods, to investigate the design of interactive pedagogical agents that provide instructional suggestions in response to instructors' questions. We conducted a formative study involving interviews with five pedagogy experts to examine existing strategies for supporting instructors' pedagogical needs. Building on these insights, we facilitated a participatory design session with ten pedagogy experts, where participants reviewed a storyboard depicting a chatbot designed for instructors with varying levels of AI literacy and differing attitudes toward AI. Experts also evaluated the quality of LLM-generated suggestions based on common teaching challenges. Our findings highlight the need for chatbot interactions that foster trust, especially for AI-conservative instructors. Experts emphasized the importance of social transparency (for example, showing how peers use the tool) and allowing instructors to flexibly control how much or how little they engage with the system. We also propose design recommendations to enhance the quality of AI-generated teaching suggestions, such as adapting them to reflect instructors' prior teaching experience. This work underscores the urgent need to support AI-conservative instructors, as AI literacy and attitudes are closely intertwined. Without thoughtful design, there is a risk of widening pedagogical divides and reducing students' learning opportunities.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Robot Collaboration through Reinforcement Learning and Abstract Simulation</title>
<link>https://arxiv.org/abs/2503.05092</link>
<guid>https://arxiv.org/abs/2503.05092</guid>
<content:encoded><![CDATA[
<div> 关键词: 抽象模拟器、多智能体强化学习(MARL)、物理机器人、策略转移、合作机器人足球任务

<br /><br />总结:
该文探讨了使用抽象模拟器进行多智能体强化学习(MARL)，并将其策略成功应用于物理机器人群中的可行性。研究指出了实现策略转移所需的三个关键类别修改：模拟精度增强、训练优化和模拟随机性。通过对合作机器人足球任务进行广泛实验与消融研究，文章确定了各修改类别对于策略转移的价值。相较于年度RoboCup竞赛中表现良好的非学习行为架构，本文方法产生的策略展现出相似水平的表现。总的来说，文章表明利用高度抽象的世界模型，通过MARL可以训练出适用于物理机器人的协作行为。 <div>
arXiv:2503.05092v1 Announce Type: new 
Abstract: Teams of people coordinate to perform complex tasks by forming abstract mental models of world and agent dynamics. The use of abstract models contrasts with much recent work in robot learning that uses a high-fidelity simulator and reinforcement learning (RL) to obtain policies for physical robots. Motivated by this difference, we investigate the extent to which so-called abstract simulators can be used for multi-agent reinforcement learning (MARL) and the resulting policies successfully deployed on teams of physical robots. An abstract simulator models the robot's target task at a high-level of abstraction and discards many details of the world that could impact optimal decision-making. Policies are trained in an abstract simulator then transferred to the physical robot by making use of separately-obtained low-level perception and motion control modules. We identify three key categories of modifications to the abstract simulator that enable policy transfer to physical robots: simulation fidelity enhancements, training optimizations and simulation stochasticity. We then run an empirical study with extensive ablations to determine the value of each modification category for enabling policy transfer in cooperative robot soccer tasks. We also compare the performance of policies produced by our method with a well-tuned non-learning-based behavior architecture from the annual RoboCup competition and find that our approach leads to a similar level of performance. Broadly we show that MARL can be use to train cooperative physical robot behaviors using highly abstract models of the world.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi-Task Reinforcement Learning Enables Parameter Scaling</title>
<link>https://arxiv.org/abs/2503.05126</link>
<guid>https://arxiv.org/abs/2503.05126</guid>
<content:encoded><![CDATA[
<div> 关键词: 多任务强化学习 (MTRL), 参数规模, 批评者网络, 任务多样性, 基线模型

总结:
本文针对多任务强化学习（MTRL）的研究，指出近期工作中的性能提升可能更多地归因于参数规模增大而非复杂架构设计。实验表明，简单MTRL基线模型通过增加参数数量即可超越复杂架构，并且批评者网络的扩展比演员网络更受益于这种规模增长。此外，研究还发现增加任务多样性可以提高训练稳定性，有助于缓解塑性损失问题。这些发现意味着MTRL中同时对多个任务进行训练为有益的参数扩展提供了一个自然框架，从而挑战了对复杂架构创新的需求。<br /><br /> <div>
arXiv:2503.05126v1 Announce Type: new 
Abstract: Multi-task reinforcement learning (MTRL) aims to endow a single agent with the ability to perform well on multiple tasks. Recent works have focused on developing novel sophisticated architectures to improve performance, often resulting in larger models; it is unclear, however, whether the performance gains are a consequence of the architecture design itself or the extra parameters. We argue that gains are mostly due to scale by demonstrating that naively scaling up a simple MTRL baseline to match parameter counts outperforms the more sophisticated architectures, and these gains benefit most from scaling the critic over the actor. Additionally, we explore the training stability advantages that come with task diversity, demonstrating that increasing the number of tasks can help mitigate plasticity loss. Our findings suggest that MTRL's simultaneous training across multiple tasks provides a natural framework for beneficial parameter scaling in reinforcement learning, challenging the need for complex architectural innovations.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>FedMABench: Benchmarking Mobile Agents on Decentralized Heterogeneous User Data</title>
<link>https://arxiv.org/abs/2503.05143</link>
<guid>https://arxiv.org/abs/2503.05143</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile agents, Federated learning, Benchmark, FedMABench, Heterogeneous scenarios

总结:
<br />
针对移动智能体训练中的挑战，如依赖集中式数据收集和缺乏标准化基准，文章提出了FedMABench——首个针对异构环境下的移动智能体联邦学习训练与评估的基准平台。FedMABench包含了6个数据集、30多个子集、8种联邦算法、10多种基础模型以及跨越5个类别的超过800个应用。通过广泛的实验，研究发现联邦学习算法总体上优于局部训练；特定应用的分布对于异质性具有关键影响；而且，在训练过程中，不同类别间的应用也可能表现出相关性。FedMABench及其数据集已公开发布在GitHub和Huggingface数据平台上。 <div>
arXiv:2503.05143v1 Announce Type: new 
Abstract: Mobile agents have attracted tremendous research participation recently. Traditional approaches to mobile agent training rely on centralized data collection, leading to high cost and limited scalability. Distributed training utilizing federated learning offers an alternative by harnessing real-world user data, providing scalability and reducing costs. However, pivotal challenges, including the absence of standardized benchmarks, hinder progress in this field.
  To tackle the challenges, we introduce FedMABench, the first benchmark for federated training and evaluation of mobile agents, specifically designed for heterogeneous scenarios. FedMABench features 6 datasets with 30+ subsets, 8 federated algorithms, 10+ base models, and over 800 apps across 5 categories, providing a comprehensive framework for evaluating mobile agents across diverse environments. Through extensive experiments, we uncover several key insights: federated algorithms consistently outperform local training; the distribution of specific apps plays a crucial role in heterogeneity; and, even apps from distinct categories can exhibit correlations during training. FedMABench is publicly available at: https://github.com/wwh0411/FedMABench with the datasets at: https://huggingface.co/datasets/wwh0411/FedMABench.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Interpersonal Memory Matters: A New Task for Proactive Dialogue Utilizing Conversational History</title>
<link>https://arxiv.org/abs/2503.05150</link>
<guid>https://arxiv.org/abs/2503.05150</guid>
<content:encoded><![CDATA[
<div> 关键词：Proactive Dialogue Systems、Long-Term Memory、Memory-aware Proactive Dialogue (MapDia)、Chinese Memory-aware Proactive Dataset (ChMapData)、Retrieval Augmented Generation (RAG)

总结:
本文提出了一种将主动对话系统与长期记忆相结合的新框架，以构建更接近人类的聊天机器人。为了解决现有系统忽视对话历史中的用户属性和偏好问题，文章定义了一个名为“记忆感知主动对话”（MapDia）的新任务，并提出了自动数据构造方法，创建了首个中文记忆感知主动对话数据集（ChMapData）。同时，研究引入了一个基于检索增强生成（RAG）的联合框架，包括话题摘要、话题检索以及主动话题切换检测与生成三个模块，旨在适时引导对话转向相关的历史话题。实验通过自动及人工评估验证了该数据集和模型的有效性。研究者开源了这一框架和数据集，可在https://github.com/FrontierLabs/MapDia 获取。 <div>
arXiv:2503.05150v1 Announce Type: new 
Abstract: Proactive dialogue systems aim to empower chatbots with the capability of leading conversations towards specific targets, thereby enhancing user engagement and service autonomy. Existing systems typically target pre-defined keywords or entities, neglecting user attributes and preferences implicit in dialogue history, hindering the development of long-term user intimacy. To address these challenges, we take a radical step towards building a more human-like conversational agent by integrating proactive dialogue systems with long-term memory into a unified framework. Specifically, we define a novel task named Memory-aware Proactive Dialogue (MapDia). By decomposing the task, we then propose an automatic data construction method and create the first Chinese Memory-aware Proactive Dataset (ChMapData). Furthermore, we introduce a joint framework based on Retrieval Augmented Generation (RAG), featuring three modules: Topic Summarization, Topic Retrieval, and Proactive Topic-shifting Detection and Generation, designed to steer dialogues towards relevant historical topics at the right time. The effectiveness of our dataset and models is validated through both automatic and human evaluations. We release the open-source framework and dataset at https://github.com/FrontierLabs/MapDia.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Generative Trajectory Stitching through Diffusion Composition</title>
<link>https://arxiv.org/abs/2503.05153</link>
<guid>https://arxiv.org/abs/2503.05153</guid>
<content:encoded><![CDATA[
<div> 关键词：有效轨迹拼接、长期规划、扩散模型、CompDiffuser、生成式方法

<br /><br />总结:
为了解决机器人决策中长期规划的有效轨迹拼接挑战，本文提出了一个名为CompDiffuser的新颖生成式方法。现有的扩散模型在解决与训练数据相似的任务时表现出潜力，但受限于对新任务的适应性。CompDiffuser通过将轨迹分布分解成重叠的短片段并学习它们之间的条件关系，利用单向双向扩散模型进行建模，使得信息可以在生成过程中在各个片段间传播，从而确保物理连接的一致性。文章在一系列不同难度的基准任务上进行了实验，涵盖了不同的环境大小、代理状态维度、轨迹类型以及训练数据质量等方面，结果显示CompDiffuser显著优于现有方法。 <div>
arXiv:2503.05153v1 Announce Type: new 
Abstract: Effective trajectory stitching for long-horizon planning is a significant challenge in robotic decision-making. While diffusion models have shown promise in planning, they are limited to solving tasks similar to those seen in their training data. We propose CompDiffuser, a novel generative approach that can solve new tasks by learning to compositionally stitch together shorter trajectory chunks from previously seen tasks. Our key insight is modeling the trajectory distribution by subdividing it into overlapping chunks and learning their conditional relationships through a single bidirectional diffusion model. This allows information to propagate between segments during generation, ensuring physically consistent connections. We conduct experiments on benchmark tasks of various difficulties, covering different environment sizes, agent state dimension, trajectory types, training data quality, and show that CompDiffuser significantly outperforms existing methods.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Comprehensive LLM-powered Framework for Driving Intelligence Evaluation</title>
<link>https://arxiv.org/abs/2503.05164</link>
<guid>https://arxiv.org/abs/2503.05164</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动驾驶评价、复杂交通环境、自然语言评价数据集、LLM驱动评价框架、CARLA城市交通模拟器

<br /><br />总结:
本文提出了一种针对复杂交通环境中自动驾驶行为智能的评估框架，旨在弥补当前缺乏全面评估方法的空白。研究团队通过自然驾驶实验和后续的行为评价访谈构建了一个人类专业驾驶员与乘客的自然语言评价数据集。基于该数据集，他们开发了一个由LLM驱动的驾驶评估框架，并在CARLA城市交通模拟器中进行了实验验证，同时得到了人类评估的进一步支持。此项研究为评估和设计更智能、更接近人类驾驶习惯的自主驾驶代理提供了有价值的见解。项目实现细节及数据集详细信息可在Github上获取。 <div>
arXiv:2503.05164v1 Announce Type: new 
Abstract: Evaluation methods for autonomous driving are crucial for algorithm optimization. However, due to the complexity of driving intelligence, there is currently no comprehensive evaluation method for the level of autonomous driving intelligence. In this paper, we propose an evaluation framework for driving behavior intelligence in complex traffic environments, aiming to fill this gap. We constructed a natural language evaluation dataset of human professional drivers and passengers through naturalistic driving experiments and post-driving behavior evaluation interviews. Based on this dataset, we developed an LLM-powered driving evaluation framework. The effectiveness of this framework was validated through simulated experiments in the CARLA urban traffic simulator and further corroborated by human assessment. Our research provides valuable insights for evaluating and designing more intelligent, human-like autonomous driving agents. The implementation details of the framework and detailed information about the dataset can be found at Github.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>ORANSight-2.0: Foundational LLMs for O-RAN</title>
<link>https://arxiv.org/abs/2503.05200</link>
<guid>https://arxiv.org/abs/2503.05200</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Open Radio Access Networks (O-RAN)，ORANSight-2.0，RANSTRUCT，srsRANBench

总结:
本文介绍了针对Open Radio Access Networks (O-RAN)的专用大型语言模型（LLMs）项目ORANSight-2.0。ORANSight-2.0旨在开发专门针对O-RAN的奠基性LLMs，使用了涵盖五个开源LLM框架的18个模型进行微调。其核心技术RANSTRUCT是一种基于检索增强生成（RAG）的指令微调框架，通过两个LLM代理创建高质量的指令数据集，再利用QLoRA对预训练的开源LLMs进行微调。为了评估ORANSight-2.0，文中提出了针对srsRAN这一广泛应用的5G O-RAN栈的代码生成和理解新基准srsRANBench，并结合现有ORANBench13K基准进行了测试。结果显示，ORANSight-2.0模型在ORANBench和srsRANBench上的性能分别比ChatGPT-4o和Gemini等通用及封闭源码模型高出5.421%和18.465%，同时保持较低的计算和能源成本。此外，还研究了RAG增强型ORANSight-2.0 LLMs的能效特性，分析了它们在训练、标准推理以及RAG增强推理阶段的能量消耗。 <div>
arXiv:2503.05200v1 Announce Type: new 
Abstract: Despite the transformative impact of Large Language Models (LLMs) across critical domains such as healthcare, customer service, and business marketing, their integration into Open Radio Access Networks (O-RAN) remains limited. This gap is primarily due to the absence of domain-specific foundational models, with existing solutions often relying on general-purpose LLMs that fail to address the unique challenges and technical intricacies of O-RAN. To bridge this gap, we introduce ORANSight-2.0 (O-RAN Insights), a pioneering initiative aimed at developing specialized foundational LLMs tailored for O-RAN. Built on 18 LLMs spanning five open-source LLM frameworks, ORANSight-2.0 fine-tunes models ranging from 1 to 70B parameters, significantly reducing reliance on proprietary, closed-source models while enhancing performance for O-RAN. At the core of ORANSight-2.0 is RANSTRUCT, a novel Retrieval-Augmented Generation (RAG) based instruction-tuning framework that employs two LLM agents to create high-quality instruction-tuning datasets. The generated dataset is then used to fine-tune the 18 pre-trained open-source LLMs via QLoRA. To evaluate ORANSight-2.0, we introduce srsRANBench, a novel benchmark designed for code generation and codebase understanding in the context of srsRAN, a widely used 5G O-RAN stack. We also leverage ORANBench13K, an existing benchmark for assessing O-RAN-specific knowledge. Our comprehensive evaluations demonstrate that ORANSight-2.0 models outperform general-purpose and closed-source models, such as ChatGPT-4o and Gemini, by 5.421% on ORANBench and 18.465% on srsRANBench, achieving superior performance while maintaining lower computational and energy costs. We also experiment with RAG-augmented variants of ORANSight-2.0 LLMs and thoroughly evaluate their energy characteristics, demonstrating costs for training, standard inference, and RAG-augmented inference.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Guaranteeing Out-Of-Distribution Detection in Deep RL via Transition Estimation</title>
<link>https://arxiv.org/abs/2503.05238</link>
<guid>https://arxiv.org/abs/2503.05238</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习、鲁棒性、异常检测、马尔可夫决策过程、条件变分自编码器

总结:<br />
本文关注深度强化学习（RL）代理在实际部署中的可靠性问题，指出训练环境可能无法完全反映真实环境。为解决RL中异常检测（OOD）的问题，文章基于马尔可夫决策过程的视角，定义了OOD执行：即在实际部署中出现的概率与训练过程中遇到的转移分布不同的状态转移被视为OOD。为此，文中利用条件变分自编码器（CVAE）来近似训练环境的转移动态，并实现了一个基于重构损失的符合性检测器，该检测器能够在预设置信水平下保证OOD检测。最后，通过改编现有基准对提出的检测器进行了评估并与现有的RL OOD检测模型进行了比较。 <div>
arXiv:2503.05238v1 Announce Type: new 
Abstract: An issue concerning the use of deep reinforcement learning (RL) agents is whether they can be trusted to perform reliably when deployed, as training environments may not reflect real-life environments. Anticipating instances outside their training scope, learning-enabled systems are often equipped with out-of-distribution (OOD) detectors that alert when a trained system encounters a state it does not recognize or in which it exhibits uncertainty. There exists limited work conducted on the problem of OOD detection within RL, with prior studies being unable to achieve a consensus on the definition of OOD execution within the context of RL. By framing our problem using a Markov Decision Process, we assume there is a transition distribution mapping each state-action pair to another state with some probability. Based on this, we consider the following definition of OOD execution within RL: A transition is OOD if its probability during real-life deployment differs from the transition distribution encountered during training. As such, we utilize conditional variational autoencoders (CVAE) to approximate the transition dynamics of the training environment and implement a conformity-based detector using reconstruction loss that is able to guarantee OOD detection with a pre-determined confidence level. We evaluate our detector by adapting existing benchmarks and compare it with existing OOD detection models for RL.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>MM-StoryAgent: Immersive Narrated Storybook Video Generation with a Multi-Agent Paradigm across Text, Image and Audio</title>
<link>https://arxiv.org/abs/2503.05242</link>
<guid>https://arxiv.org/abs/2503.05242</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)、人工智能生成内容 (AIGC)、MM-StoryAgent、多模态、开放源代码

总结:

本文提出并开源了一个名为MM-StoryAgent的系统，该系统利用大型语言模型和多模态专家工具，创作出具有引人入胜情节、角色一致图像及多通道音频的沉浸式有声视频故事书。MM-StoryAgent采用多代理框架，通过多阶段写作流程提升故事吸引力，并通过整合音效与视觉、音乐和叙述资产来增强沉浸式的讲故事体验。此外，它提供了一个灵活、开放源代码的平台，允许替换其生成模块。对文本故事质量和各模态之间的一致性的客观和主观评估验证了MM-StoryAgent系统的有效性。文章提供了系统的演示和源代码。 <div>
arXiv:2503.05242v1 Announce Type: new 
Abstract: The rapid advancement of large language models (LLMs) and artificial intelligence-generated content (AIGC) has accelerated AI-native applications, such as AI-based storybooks that automate engaging story production for children. However, challenges remain in improving story attractiveness, enriching storytelling expressiveness, and developing open-source evaluation benchmarks and frameworks. Therefore, we propose and opensource MM-StoryAgent, which creates immersive narrated video storybooks with refined plots, role-consistent images, and multi-channel audio. MM-StoryAgent designs a multi-agent framework that employs LLMs and diverse expert tools (generative models and APIs) across several modalities to produce expressive storytelling videos. The framework enhances story attractiveness through a multi-stage writing pipeline. In addition, it improves the immersive storytelling experience by integrating sound effects with visual, music and narrative assets. MM-StoryAgent offers a flexible, open-source platform for further development, where generative modules can be substituted. Both objective and subjective evaluation regarding textual story quality and alignment between modalities validate the effectiveness of our proposed MM-StoryAgent system. The demo and source code are available.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Mastering Continual Reinforcement Learning through Fine-Grained Sparse Network Allocation and Dormant Neuron Exploration</title>
<link>https://arxiv.org/abs/2503.05246</link>
<guid>https://arxiv.org/abs/2503.05246</guid>
<content:encoded><![CDATA[
<div> 关键词: Continual Reinforcement Learning (持续强化学习), SSDE, 结构化稀疏性, 激活重置机制, CW10-v1基准

总结:
本文提出了SSDE，一种针对Continual Reinforcement Learning (CRL)的新型结构化方法，旨在增强学习代理的可塑性和稳定性之间的平衡。SSDE通过细粒度的分配策略实现了参数空间的分解，将参数分为用于前向转移（冻结）的参数和任务特定（可训练）的参数，并利用稀疏编码下的高效共分配方案进行分配。为解决结构化方法因非训练参数积累导致的探索性和适应性受限问题，文章引入了基于敏感性的神经元再激活机制，该机制能够在推理过程中系统地识别并重置对稀疏策略网络影响最小的休眠神经元，从而有效提升探索能力并保持结构效率。在CW10-v1连续世界基准上的广泛实验表明，SSDE达到了95%的成功率，显著超越了先前方法在可塑性和稳定性折衷方面的表现。实验代码可在https://github.com/chengqiArchy/SSDE 中获取。 <div>
arXiv:2503.05246v1 Announce Type: new 
Abstract: Continual Reinforcement Learning (CRL) is essential for developing agents that can learn, adapt, and accumulate knowledge over time. However, a fundamental challenge persists as agents must strike a delicate balance between plasticity, which enables rapid skill acquisition, and stability, which ensures long-term knowledge retention while preventing catastrophic forgetting. In this paper, we introduce SSDE, a novel structure-based approach that enhances plasticity through a fine-grained allocation strategy with Structured Sparsity and Dormant-guided Exploration. SSDE decomposes the parameter space into forward-transfer (frozen) parameters and task-specific (trainable) parameters. Crucially, these parameters are allocated by an efficient co-allocation scheme under sparse coding, ensuring sufficient trainable capacity for new tasks while promoting efficient forward transfer through frozen parameters. However, structure-based methods often suffer from rigidity due to the accumulation of non-trainable parameters, limiting exploration and adaptability. To address this, we further introduce a sensitivity-guided neuron reactivation mechanism that systematically identifies and resets dormant neurons, which exhibit minimal influence in the sparse policy network during inference. This approach effectively enhance exploration while preserving structural efficiency. Extensive experiments on the CW10-v1 Continual World benchmark demonstrate that SSDE achieves state-of-the-art performance, reaching a success rate of 95%, surpassing prior methods significantly in both plasticity and stability trade-offs (code is available at: https://github.com/chengqiArchy/SSDE).
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Evidential Uncertainty Estimation for Multi-Modal Trajectory Prediction</title>
<link>https://arxiv.org/abs/2503.05274</link>
<guid>https://arxiv.org/abs/2503.05274</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动驾驶、轨迹预测、不确定性、证据推理深度学习、多模态

总结:
本文提出了一种基于证据推理深度学习的新型多模态轨迹预测方法，用于自动驾驶中的准确轨迹预测。该方法着重解决了代理行为和感知噪声带来的不确定性问题，能够实时估计位置不确定性和模式概率不确定性。通过采用Normal Inverse Gamma分布来量化位置不确定性，以及Dirichlet分布来量化模式不确定性，与采样基方法不同的是，它能在单次前向传播中同时推断两种类型的不确定性，显著提高了效率。此外，文章还尝试利用不确定性驱动的重要性采样技术，优先处理高不确定性且代表性不足的样本，从而提高训练效率。实验结果表明，该方法在Argoverse 1和Argoverse 2数据集上表现出可靠的不确定性估计能力的同时，保持了高水平的轨迹预测准确性。 <div>
arXiv:2503.05274v1 Announce Type: new 
Abstract: Accurate trajectory prediction is crucial for autonomous driving, yet uncertainty in agent behavior and perception noise makes it inherently challenging. While multi-modal trajectory prediction models generate multiple plausible future paths with associated probabilities, effectively quantifying uncertainty remains an open problem. In this work, we propose a novel multi-modal trajectory prediction approach based on evidential deep learning that estimates both positional and mode probability uncertainty in real time. Our approach leverages a Normal Inverse Gamma distribution for positional uncertainty and a Dirichlet distribution for mode uncertainty. Unlike sampling-based methods, it infers both types of uncertainty in a single forward pass, significantly improving efficiency. Additionally, we experimented with uncertainty-driven importance sampling to improve training efficiency by prioritizing underrepresented high-uncertainty samples over redundant ones. We perform extensive evaluations of our method on the Argoverse 1 and Argoverse 2 datasets, demonstrating that it provides reliable uncertainty estimates while maintaining high trajectory prediction accuracy.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Attenuation artifact detection and severity classification in intracoronary OCT using mixed image representations</title>
<link>https://arxiv.org/abs/2503.05322</link>
<guid>https://arxiv.org/abs/2503.05322</guid>
<content:encoded><![CDATA[
<div> 关键词：光学相干断层成像(OCT)，血迹，气泡，卷积神经网络(CNN)，坐标系统

总结:<br />
本文提出了一种基于卷积神经网络的方法，用于自动检测冠状动脉光学相干断层成像(OCT)中的血迹和气泡造成的衰减伪影，并根据其严重程度分类为无、轻度和重度。该模型同时分析了OCT图像在笛卡尔坐标系和极坐标系下的特征，发现两种坐标系统的融合能提高检测性能。实验结果显示，对于轻度和重度伪影的检测，方法分别达到了F-score为0.77和0.94的精度，并且整个OCT扫描的推断时间约为6秒。这一工作为实现OCT图像的自动化伪影评估和图像采集指导奠定了基础。 <div>
arXiv:2503.05322v1 Announce Type: new 
Abstract: In intracoronary optical coherence tomography (OCT), blood residues and gas bubbles cause attenuation artifacts that can obscure critical vessel structures. The presence and severity of these artifacts may warrant re-acquisition, prolonging procedure time and increasing use of contrast agent. Accurate detection of these artifacts can guide targeted re-acquisition, reducing the amount of repeated scans needed to achieve diagnostically viable images. However, the highly heterogeneous appearance of these artifacts poses a challenge for the automated detection of the affected image regions. To enable automatic detection of the attenuation artifacts caused by blood residues and gas bubbles based on their severity, we propose a convolutional neural network that performs classification of the attenuation lines (A-lines) into three classes: no artifact, mild artifact and severe artifact. Our model extracts and merges features from OCT images in both Cartesian and polar coordinates, where each column of the image represents an A-line. Our method detects the presence of attenuation artifacts in OCT frames reaching F-scores of 0.77 and 0.94 for mild and severe artifacts, respectively. The inference time over a full OCT scan is approximately 6 seconds. Our experiments show that analysis of images represented in both Cartesian and polar coordinate systems outperforms the analysis in polar coordinates only, suggesting that these representations contain complementary features. This work lays the foundation for automated artifact assessment and image acquisition guidance in intracoronary OCT imaging.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>GEMA-Score: Granular Explainable Multi-Agent Score for Radiology Report Evaluation</title>
<link>https://arxiv.org/abs/2503.05347</link>
<guid>https://arxiv.org/abs/2503.05347</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动医疗报告生成、评价指标、GEMA-Score、多代理评分系统、临床评估

总结:
本文提出了一个名为GEMA-Score的新颖评价体系，用于更全面地评估自动医疗报告生成的可靠性。现有的评价方法主要关注关键医学信息的准确性，而忽略了异常位置和确定性的细节。为解决这一问题，GEMA-Score通过一个基于大型语言模型的多代理工作流程进行客观量化和主观评价。该体系能解析结构化报告，利用命名实体识别F1分数来评估疾病诊断、位置、严重程度及不确定性。同时，一个基于LLM的评分代理则负责评价报告的完整性、可读性和临床术语使用，并提供解释性反馈。实验结果显示，GEMA-Score在公共数据集上与人类专家评估的相关性最高（Rexval数据集上的肯德尔系数为0.70，RadEvalX数据集上的肯德尔系数为0.54）。该项目的匿名演示Demo可在GitHub地址https://github.com/Zhenxuan-Zhang/GEMA_score访问。 <div>
arXiv:2503.05347v1 Announce Type: new 
Abstract: Automatic medical report generation supports clinical diagnosis, reduces the workload of radiologists, and holds the promise of improving diagnosis consistency. However, existing evaluation metrics primarily assess the accuracy of key medical information coverage in generated reports compared to human-written reports, while overlooking crucial details such as the location and certainty of reported abnormalities. These limitations hinder the comprehensive assessment of the reliability of generated reports and pose risks in their selection for clinical use. Therefore, we propose a Granular Explainable Multi-Agent Score (GEMA-Score) in this paper, which conducts both objective quantification and subjective evaluation through a large language model-based multi-agent workflow. Our GEMA-Score parses structured reports and employs NER-F1 calculations through interactive exchanges of information among agents to assess disease diagnosis, location, severity, and uncertainty. Additionally, an LLM-based scoring agent evaluates completeness, readability, and clinical terminology while providing explanatory feedback. Extensive experiments validate that GEMA-Score achieves the highest correlation with human expert evaluations on a public dataset, demonstrating its effectiveness in clinical scoring (Kendall coefficient = 0.70 for Rexval dataset and Kendall coefficient = 0.54 for RadEvalX dataset). The anonymous project demo is available at: https://github.com/Zhenxuan-Zhang/GEMA_score.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>VLMs Play StarCraft II: A Benchmark and Multimodal Decision Method</title>
<link>https://arxiv.org/abs/2503.05383</link>
<guid>https://arxiv.org/abs/2503.05383</guid>
<content:encoded><![CDATA[
<div> 关键词：VLM-Attention、多模态、StarCraft II环境、人工agent、人类游戏体验

总结:
本文介绍了VLM-Attention，这是一个针对StarCraft II设计的多模态环境，它使人工智能代理的感知与人类游戏体验相一致。该环境通过引入RGB视觉输入和自然语言观察来克服传统框架（如SMAC）中抽象状态表示与人类感知显著偏离的问题，从而更好地模拟游戏中人类的认知过程。VLM-Attention框架包括三个组成部分：(1)采用专门自我注意力机制以实现战略单位定位和战场评估的视觉-语言模型；(2)利用领域特定的StarCraft II知识指导战术决策的检索增强生成系统；(3)动态的角色任务分配系统，支持协调的多智能体行为。实验结果显示，基于VLM（特别是Qwen-VL和GPT-4o）的代理能够在无需显式训练的情况下执行复杂的战术动作，并在21个定制场景中的表现可与需要大量训练迭代的传统MARL方法媲美。这项工作为开发与人类行为相一致的StarCraft II代理奠定了基础，并推动了多模态游戏AI领域的研究进展。相关的代码实现已发布于https://github.com/camel-ai/VLM-Play-StarCraft2。 <div>
arXiv:2503.05383v1 Announce Type: new 
Abstract: We introduce VLM-Attention, a multimodal StarCraft II environment that aligns artificial agent perception with the human gameplay experience. Traditional frameworks such as SMAC rely on abstract state representations that diverge significantly from human perception, limiting the ecological validity of agent behavior. Our environment addresses this limitation by incorporating RGB visual inputs and natural language observations that more closely simulate human cognitive processes during gameplay. The VLM-Attention framework consists of three integrated components: (1) a vision-language model enhanced with specialized self-attention mechanisms for strategic unit targeting and battlefield assessment, (2) a retrieval-augmented generation system that leverages domain-specific StarCraft II knowledge to inform tactical decisions, and (3) a dynamic role-based task distribution system that enables coordinated multi-agent behavior. Our experimental evaluation across 21 custom scenarios demonstrates that VLM-based agents powered by foundation models (specifically Qwen-VL and GPT-4o) can execute complex tactical maneuvers without explicit training, achieving comparable performance to traditional MARL methods that require substantial training iterations. This work establishes a foundation for developing human-aligned StarCraft II agents and advances the broader research agenda of multimodal game AI. Our implementation is available at https://github.com/camel-ai/VLM-Play-StarCraft2.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Multi Agent based Medical Assistant for Edge Devices</title>
<link>https://arxiv.org/abs/2503.05397</link>
<guid>https://arxiv.org/abs/2503.05397</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型动作模型(LAMs), 医疗保健助手, 在设备上部署, 多代理架构, Qwen Code Instruct 2.5 7B模型

总结:
该报告介绍了一种针对医疗领域的、解决大型动作模型应用挑战的在设备上部署的多代理医疗保健助手。此系统通过使用更小、任务特定的代理来优化资源、确保可扩展性和高性能，能够一站式满足预约挂号、健康监测、药物提醒和每日健康报告等功能需求。该系统采用Qwen Code Instruct 2.5 7B模型，其中的规划者与呼叫者代理在执行任务时分别取得了平均RougeL分数为85.5和96.5的好成绩，同时保证了轻量级的在设备部署特性。这种创新方法将本地化系统优势与多代理架构相结合，为以用户为中心的医疗解决方案开辟了新道路。 <div>
arXiv:2503.05397v1 Announce Type: new 
Abstract: Large Action Models (LAMs) have revolutionized intelligent automation, but their application in healthcare faces challenges due to privacy concerns, latency, and dependency on internet access. This report introduces an ondevice, multi-agent healthcare assistant that overcomes these limitations. The system utilizes smaller, task-specific agents to optimize resources, ensure scalability and high performance. Our proposed system acts as a one-stop solution for health care needs with features like appointment booking, health monitoring, medication reminders, and daily health reporting. Powered by the Qwen Code Instruct 2.5 7B model, the Planner and Caller Agents achieve an average RougeL score of 85.5 for planning and 96.5 for calling for our tasks while being lightweight for on-device deployment. This innovative approach combines the benefits of ondevice systems with multi-agent architectures, paving the way for user-centric healthcare solutions.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Game Theory in Formula 1: Multi-agent Physical and Strategical Interactions</title>
<link>https://arxiv.org/abs/2503.05421</link>
<guid>https://arxiv.org/abs/2503.05421</guid>
<content:encoded><![CDATA[
<div> 关键词：Formula 1赛车、优化框架、多代理交互、气动尾流效应、游戏理论

总结:

本文提出了一种针对Formula 1赛车的综合优化框架，该框架结合了多代理交互、气动尾流效应、轨迹优化和能量管理。通过运用游戏理论方法，将最小圈速问题形式化为纳什或Stackelberg博弈。文中比较了对称策略与分层策略下的竞争动态和战略优势，并引入算法改进局部Stackelberg解。研究发现物理交互、能量管理和轨迹的联合优化至关重要，并强调了它们之间的紧密联系。文章探讨了利用尾流效应在不同赛道段（如弯道、直道及高速路段）选择最优行驶轨迹的影响，以及基于能量分配策略确定最佳超车位置。通过引入精确的物理互动模型并考虑竞争对手的最优响应，该方法揭示了现实中赛车中常见的战略行为。这种方法为实现更真实的Formula 1比赛策略优化提供了贡献，具有潜在应用于赛车工程和自动驾驶赛车领域。 <div>
arXiv:2503.05421v1 Announce Type: new 
Abstract: This paper presents an optimization framework for Formula 1 racing that integrates multi-agent interactions, aerodynamic wake effects, trajectory optimization, and energy management. By employing game-theoretic methods, we formulate the minimum lap time problem as either a Nash or a Stackelberg game. Exploiting their structural similarities, we compare symmetric and hierarchical strategies to analyze competitive racing dynamics and strategic dominance. Additionally, we introduce an algorithm to refine local Stackelberg solutions. Our findings underscore the importance of jointly optimizing physical interactions, energy management, and trajectory, highlighting their strong interdependence. We examine the impact of slipstreaming on trajectory selection in corners, straights, and high-speed sections, while also identifying optimal overtaking locations based on energy allocation strategies. By incorporating a physically accurate interaction model and accounting for the optimal responses of competing agents, our approach reveals characteristic strategic behaviors observed in real-world racing. The proposed methodology contributes towards realistic Formula 1 race strategy optimizations, with potential applications in motorsport engineering and autonomous racing.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>The Society of HiveMind: Multi-Agent Optimization of Foundation Model Swarms to Unlock the Potential of Collective Intelligence</title>
<link>https://arxiv.org/abs/2503.05473</link>
<guid>https://arxiv.org/abs/2503.05473</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、人工智能基础模型、群智行为、逻辑推理能力、自我改进

总结:
本文提出了一种名为“群智社会”（SOHM）的框架，用于协调多个人工智能基础模型之间的交互，模仿自然界的动物群体行为并遵循现代进化理论。研究发现，对于主要依赖现实世界知识的任务，SOHM带来的益处较小；然而，在需要大量逻辑推理的任务上，SOHM显示出显著的性能提升，意味着多智能体系统可以增强集体相比于单个代理的推理能力。这表明通过与环境互动，结合多种多样化的人工智能基础模型可以形成具有自我改进能力的合成人工群智智能。 <div>
arXiv:2503.05473v1 Announce Type: new 
Abstract: Multi-agent systems address issues of accessibility and scalability of artificial intelligence (AI) foundation models, which are often represented by large language models. We develop a framework - the "Society of HiveMind" (SOHM) - that orchestrates the interaction between multiple AI foundation models, imitating the observed behavior of animal swarms in nature by following modern evolutionary theories. On the one hand, we find that the SOHM provides a negligible benefit on tasks that mainly require real-world knowledge. On the other hand, we remark a significant improvement on tasks that require intensive logical reasoning, indicating that multi-agent systems are capable of increasing the reasoning capabilities of the collective compared to the individual agents. Our findings demonstrate the potential of combining a multitude of diverse AI foundation models to form an artificial swarm intelligence capable of self-improvement through interactions with a given environment.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Impoola: The Power of Average Pooling for Image-Based Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.05546</link>
<guid>https://arxiv.org/abs/2503.05546</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习、图像编码器、Impala-CNN、全局平均池化、Impoola-CNN

总结:<br />
本文关注深度强化学习中图像编码器的设计效率问题。研究发现，通过将Impala-CNN中的输出特征图展平操作替换为全局平均池化，可以显著提升性能。这种改进的模型被命名为Impoola-CNN，在Procgen Benchmark基准测试中，其表现优于更大更复杂的模型，尤其是在无中心化观测的游戏场景下显示出更强的泛化能力。这表明网络规模的增大并非提升性能的唯一途径，优化网络设计同样至关重要。 <div>
arXiv:2503.05546v1 Announce Type: new 
Abstract: As image-based deep reinforcement learning tackles more challenging tasks, increasing model size has become an important factor in improving performance. Recent studies achieved this by focusing on the parameter efficiency of scaled networks, typically using Impala-CNN, a 15-layer ResNet-inspired network, as the image encoder. However, while Impala-CNN evidently outperforms older CNN architectures, potential advancements in network design for deep reinforcement learning-specific image encoders remain largely unexplored. We find that replacing the flattening of output feature maps in Impala-CNN with global average pooling leads to a notable performance improvement. This approach outperforms larger and more complex models in the Procgen Benchmark, particularly in terms of generalization. We call our proposed encoder model Impoola-CNN. A decrease in the network's translation sensitivity may be central to this improvement, as we observe the most significant gains in games without agent-centered observations. Our results demonstrate that network scaling is not just about increasing model size - efficient network design is also an essential factor.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Tractable Representations for Convergent Approximation of Distributional HJB Equations</title>
<link>https://arxiv.org/abs/2503.05563</link>
<guid>https://arxiv.org/abs/2503.05563</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、分布式强化学习、连续时间强化学习、分布哈密顿-雅可比-贝尔曼方程、近似解

总结:
本文探讨了强化学习中的长期决策行为评估，特别是关注于分布式强化学习（Distributional Reinforcement Learning, DRL）及其对策略评价的丰富统计信息。对于无法自然划分为离散时间增量的情况，研究者转向了连续时间强化学习（Continuous-Time Reinforcement Learning, CTRL），其中代理状态和决策连续演变。尽管在CTRL中已知哈密顿-雅可比-贝尔曼（Hamilton-Jacobi-Bellman, HJB）方程可以刻画期望回报，但关于CTRL下的分布式RL尚处于初级阶段。最近的工作已经建立了分布式的HJB（DHJB）方程，首次为CTRL中的回报分布提供了理论基础。然而，DHJB方程的精确求解与表示极具挑战性，需要创新的近似方法。为此，本文朝着这一目标迈进，提出了在参数化回报分布的方法满足一定拓扑性质条件下，能够近似求解DHJB方程的条件。具体来说，文章证明了分布式RL中常见的分位数表示法满足该拓扑性质，从而认证了一种用于连续时间分布式强化学习的有效近似算法。 <div>
arXiv:2503.05563v1 Announce Type: new 
Abstract: In reinforcement learning (RL), the long-term behavior of decision-making policies is evaluated based on their average returns. Distributional RL has emerged, presenting techniques for learning return distributions, which provide additional statistics for evaluating policies, incorporating risk-sensitive considerations. When the passage of time cannot naturally be divided into discrete time increments, researchers have studied the continuous-time RL (CTRL) problem, where agent states and decisions evolve continuously. In this setting, the Hamilton-Jacobi-Bellman (HJB) equation is well established as the characterization of the expected return, and many solution methods exist. However, the study of distributional RL in the continuous-time setting is in its infancy. Recent work has established a distributional HJB (DHJB) equation, providing the first characterization of return distributions in CTRL. These equations and their solutions are intractable to solve and represent exactly, requiring novel approximation techniques. This work takes strides towards this end, establishing conditions on the method of parameterizing return distributions under which the DHJB equation can be approximately solved. Particularly, we show that under a certain topological property of the mapping between statistics learned by a distributional RL algorithm and corresponding distributions, approximation of these statistics leads to close approximations of the solution of the DHJB equation. Concretely, we demonstrate that the quantile representation common in distributional RL satisfies this topological property, certifying an efficient approximation algorithm for continuous-time distributional RL.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>InDRiVE: Intrinsic Disagreement based Reinforcement for Vehicle Exploration through Curiosity Driven Generalized World Model</title>
<link>https://arxiv.org/abs/2503.05573</link>
<guid>https://arxiv.org/abs/2503.05573</guid>
<content:encoded><![CDATA[
<div> 关键词：Model-based Reinforcement Learning (MBRL)，Intrinsic Disagreement based Reinforcement (InDRiVE)，Dreamer，Autonomous Driving，Ensemble of World Models

总结:
本文提出了一种名为InDRiVE的新方法，该方法基于纯粹的内在、基于分歧的奖励，应用于Dreamer的模型驱动强化学习框架中，用于自动驾驶任务。InDRiVE通过训练世界模型集合，使智能体能够在没有特定任务反馈的情况下主动探索环境中的高不确定性区域，从而构建出与任务无关的潜在表示。这使得InDRiVE能在下游驾驶任务（如车道跟随和碰撞避免）上实现快速的零样本或少样本微调。实验结果显示，在已知和未知环境中，尽管InDRiVE使用的训练步数显著减少，但其成功率和违规次数均优于DreamerV2和DreamerV3基线。这项研究强调了仅使用内在探索对于学习稳健车辆控制行为的有效性，为实现更可扩展和适应性强的自动驾驶系统铺平道路。 <div>
arXiv:2503.05573v1 Announce Type: new 
Abstract: Model-based Reinforcement Learning (MBRL) has emerged as a promising paradigm for autonomous driving, where data efficiency and robustness are critical. Yet, existing solutions often rely on carefully crafted, task specific extrinsic rewards, limiting generalization to new tasks or environments. In this paper, we propose InDRiVE (Intrinsic Disagreement based Reinforcement for Vehicle Exploration), a method that leverages purely intrinsic, disagreement based rewards within a Dreamer based MBRL framework. By training an ensemble of world models, the agent actively explores high uncertainty regions of environments without any task specific feedback. This approach yields a task agnostic latent representation, allowing for rapid zero shot or few shot fine tuning on downstream driving tasks such as lane following and collision avoidance. Experimental results in both seen and unseen environments demonstrate that InDRiVE achieves higher success rates and fewer infractions compared to DreamerV2 and DreamerV3 baselines despite using significantly fewer training steps. Our findings highlight the effectiveness of purely intrinsic exploration for learning robust vehicle control behaviors, paving the way for more scalable and adaptable autonomous driving systems.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Backpropagation through Soft Body: Investigating Information Processing in Brain-Body Coupling Systems</title>
<link>https://arxiv.org/abs/2503.05601</link>
<guid>https://arxiv.org/abs/2503.05601</guid>
<content:encoded><![CDATA[
<div> 关键词：co-design、动态耦合、大脑-身体、软体机器人、物理 reservoir 计算

总结:
本文提出了一种名为“软体机器人通过反向传播”的框架，应用于研究在采用共同设计方法时，信息处理功能如何在大脑和身体之间分布。研究通过让智能体执行包括分类任务、非线性动力系统模拟及自主行为生成等指定任务，并对这些任务背后的机制进行了分析，揭示了大脑与身体之间的互作关系。此外，文章还表明，通过利用物理 reservoir 计算技术，可以将优化的大脑功能嵌入到身体中。这些发现为高效设计大脑-身体耦合系统的路径提供了新思路。 <div>
arXiv:2503.05601v1 Announce Type: new 
Abstract: Animals achieve sophisticated behavioral control through dynamic coupling of the brain, body, and environment. Accordingly, the co-design approach, in which both the controllers and the physical properties are optimized simultaneously, has been suggested for generating refined agents without designing each component separately. In this study, we aim to reveal how the function of the information processing is distributed between brains and bodies while applying the co-design approach. Using a framework called ``backpropagation through soft body," we developed agents to perform specified tasks and analyzed their mechanisms. The tasks included classification and corresponding behavioral association, nonlinear dynamical system emulation, and autonomous behavioral generation. In each case, our analyses revealed reciprocal relationships between the brains and bodies. In addition, we show that optimized brain functionalities can be embedded into bodies using physical reservoir computing techniques. Our results pave the way for efficient designs of brain--body coupling systems.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symbolic Mixture-of-Experts: Adaptive Skill-based Routing for Heterogeneous Reasoning</title>
<link>https://arxiv.org/abs/2503.05641</link>
<guid>https://arxiv.org/abs/2503.05641</guid>
<content:encoded><![CDATA[
<div> 关键词: Symbolic-MoE、LLMs、混合专家框架、实例级选择、批量推理策略

<br /><br />总结:
本文提出了Symbolic-MoE，一种基于符号的、文本驱动的、无梯度的Mixture-of-Experts框架，用于精细地针对每个任务实例选择预训练的LLM专家。Symbolic-MoE侧重于根据技能进行选择，如数学中的代数或生物医学领域的分子生物学。通过技能为基础的招募策略，它动态选取最相关的专家集合来处理多样化的推理任务。每个选定的专家生成自己的推理输出，随后由一个聚合器整合为最终高质量响应。文章中还提出了一种批处理推理策略，以解决因不断加载和卸载模型而带来的高计算开销问题。实验表明，Symbolic-MoE在MMLU-Pro、GPQA、AIME和MedMCQA等多个基准测试上优于GPT4o-mini等强大的LLMs以及多代理方法，相对于最佳多代理基线实现了平均8.15%的绝对提升，并且无需昂贵的多轮讨论，从而在计算效率方面超过讨论型基线。 <div>
arXiv:2503.05641v1 Announce Type: new 
Abstract: Combining existing pre-trained expert LLMs is a promising avenue for scalably tackling large-scale and diverse tasks. However, selecting experts at the task level is often too coarse-grained, as heterogeneous tasks may require different expertise for each instance. To enable adaptive instance-level mixing of pre-trained LLM experts, we propose Symbolic-MoE, a symbolic, text-based, and gradient-free Mixture-of-Experts framework. Symbolic-MoE takes a fine-grained approach to selection by emphasizing skills, e.g., algebra in math or molecular biology in biomedical reasoning. We propose a skill-based recruiting strategy that dynamically selects the most relevant set of expert LLMs for diverse reasoning tasks based on their strengths. Each selected expert then generates its own reasoning, resulting in k outputs from k experts, which are then synthesized into a final high-quality response by an aggregator chosen based on its ability to integrate diverse reasoning outputs. We show that Symbolic-MoE's instance-level expert selection improves performance by a large margin but -- when implemented naively -- can introduce a high computational overhead due to the need for constant model loading and offloading. To address this, we implement a batch inference strategy that groups instances based on their assigned experts, loading each model only once. This allows us to integrate 16 expert models on 1 GPU with a time cost comparable to or better than prior multi-agent baselines using 4 GPUs. Through extensive evaluations on diverse benchmarks (MMLU-Pro, GPQA, AIME, and MedMCQA), we demonstrate that Symbolic-MoE outperforms strong LLMs like GPT4o-mini, as well as multi-agent approaches, with an absolute average improvement of 8.15% over the best multi-agent baseline. Moreover, Symbolic-MoE removes the need for expensive multi-round discussions, outperforming discussion baselines with less computation.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>A Survey of Large Language Model Empowered Agents for Recommendation and Search: Towards Next-Generation Information Retrieval</title>
<link>https://arxiv.org/abs/2503.05659</link>
<guid>https://arxiv.org/abs/2503.05659</guid>
<content:encoded><![CDATA[
<div> 关键词：信息检索系统、大型语言模型、搜索推荐、人工智能、研究框架

<br /><br />总结:
本文探讨了大型语言模型(Large Language Models, LLMs)在增强搜索和推荐系统方面的转型潜力。随着信息技术的发展，信息检索系统的角色日益重要，而LLMs因其在各类语言任务中展现出超越人类的表现及理解、推理和决策能力，被认为是提升这些系统效能的关键。文章提出了LLM代理的动机与作用，并构建了一个分类框架来阐述现有研究。作者强调了LLM代理解决当前搜索和推荐系统挑战的巨大潜力，并指出了未来的研究方向。此外，该文是首次系统性地梳理并归类LLM代理在这一领域的研究工作，为利用这种先进AI技术改进信息检索提供了新的视角。为了便于理解已有的研究成果，文中还列出了相关论文链接。 <div>
arXiv:2503.05659v1 Announce Type: new 
Abstract: Information technology has profoundly altered the way humans interact with information. The vast amount of content created, shared, and disseminated online has made it increasingly difficult to access relevant information. Over the past two decades, search and recommendation systems (collectively referred to as information retrieval systems) have evolved significantly to address these challenges. Recent advances in large language models (LLMs) have demonstrated capabilities that surpass human performance in various language-related tasks and exhibit general understanding, reasoning, and decision-making abilities. This paper explores the transformative potential of large language model agents in enhancing search and recommendation systems. We discuss the motivations and roles of LLM agents, and establish a classification framework to elaborate on the existing research. We highlight the immense potential of LLM agents in addressing current challenges in search and recommendation, providing insights into future research directions. This paper is the first to systematically review and classify the research on LLM agents in these domains, offering a novel perspective on leveraging this advanced AI technology for information retrieval. To help understand the existing works, we list the existing papers on agent-based simulation with large language models at this link: https://github.com/tsinghua-fib-lab/LLM-Agent-for-Recommendation-and-Search.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>On Almost Fair and Equitable Allocations of Indivisible Items for Non-monotone Valuations</title>
<link>https://arxiv.org/abs/2503.05695</link>
<guid>https://arxiv.org/abs/2503.05695</guid>
<content:encoded><![CDATA[
<div> 关键词：公平分配、不可分割物品、非单调估值、均衡约束、算法

总结:
本文研究了具有通用、非单调估值的个体之间不可分割物品的公平分配问题。文章探讨了满足公平或平等约束的分配存在的条件及其有效计算方法。文中考虑的公平性概念保证每个个体对其所获物品的价值至少与其他个体相当，并允许对物品进行增减调整。对于将物品分类为商品或苦差事的情况，提出了一个伪多项式时间的局部搜索算法，用于计算“等价于任意商品或任意苦差事的均衡”（EQX*）分配。此外，还给出了一种能实现“等价于一件物品的均衡”（EQ1）分配的多项式时间贪婪算法，以及针对加性估值时返回EQX*分配的类似算法。本文的关键技术贡献在于利用固定点定理（如斯普纳引理及其变体），证明了对于非负（甚至可能非客观和非单调的）估值，存在“等价于一件商品和一件苦差事的均衡”（EQ1*）和“一物品嫉妒自由”（EF1*）分配。即使物品排列在路径上且分配必须形成连通子路径，这一结论仍然成立。此外，还提出了一种计算EQ1*分配的多项式时间动态规划算法。最后，通过使用一种新颖的多颜色版本的斯普纳引理，将EF1*和EQ1*的结果扩展到了非正估值。对于单调递减估值和沿路径相连的包裹，这意味着存在EF1和EQ1分配，其中EQ1分配可以被有效地计算出来。 <div>
arXiv:2503.05695v1 Announce Type: new 
Abstract: In this work, we revisit well-studied problems of fair allocation of indivisible items among agents with general, non-monotone valuations. We explore the existence and efficient computation of allocations that satisfy either fairness or equity constraints. The fairness notions we consider ensure that each agent values her bundle at least as much as others', allowing for (any or some) item removal, while the equity guarantees roughly equal valuations among agents, with similar adjustments. For objective valuations where items are classified as either goods or chores, we present a pseudo-polynomial local-search algorithm computing an ``equitable-up-to-any-good-or-any-chore'' (EQX*) allocation, a weaker version of an ``equitable-up-to-any-item" (EQX) allocation. Additionally, we provide a polynomial-time greedy algorithm that computes an ``equitable-up-to-one-item" (EQ1) allocation, and a similar algorithm returning an EQX* allocation when the valuations are also additive. As a key technical contribution of this work, by leveraging fixed-point theorems (such as Sperner's Lemma and its variants), we establish the existence of ``equitable-up-to-one-good-and-one-chore'' (EQ1*) and ``envy-free-up-to-one-good-and-one-chore'' (EF1*) allocations for non-negative (and possibly non-objective and non-monotone) valuations. This holds even when items are arranged in a path and bundles must form connected sub-paths. Additionally, we present a polynomial-time dynamic-programming algorithm that computes an EQ1* allocation. Finally, we extend the EF1* and EQ1* results to non-positive valuations using a novel multi-coloring variant of Sperner's lemma, a combinatorial result of independent interest. For monotone non-increasing valuations and path-connected bundles, this implies the existence of EF1 and EQ1 allocations, with EQ1 allocations being efficiently computable.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Value of Information in Social Learning</title>
<link>https://arxiv.org/abs/2503.05015</link>
<guid>https://arxiv.org/abs/2503.05015</guid>
<content:encoded><![CDATA[
<div> 关键词：Blackwell比较信息、序列社会学习模型、信息结构、社交价值、必要充分条件

总结:
本文扩展了Blackwell在1953年关于信息比较的研究，将其应用于一个序贯社会学习模型中。在这个模型中，代理人基于私人信号和他人的观察行动进行决策。文章引入了一个新的二元关系，定义了一个信息结构的社会价值优于另一个，如果它能为所有代理带来更高的期望收益，无论其偏好如何。首先，文章证明了这个二元关系严格强于Blackwell秩序。接着，文章给出了该二元关系的必要且充分条件，并提出一个更易于验证的充分条件。 <div>
arXiv:2503.05015v1 Announce Type: cross 
Abstract: This study extends Blackwell's (1953) comparison of information to a sequential social learning model, where agents make decisions sequentially based on both private signals and the observed actions of others. In this context, we introduce a new binary relation over information structures: An information structure is more socially valuable than another if it yields higher expected payoffs for all agents, regardless of their preferences. First, we establish that this binary relation is strictly stronger than the Blackwell order. Then, we provide a necessary and sufficient condition for our binary relation and propose a simpler sufficient condition that is easier to verify.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>When Large Language Models Meet Evolutionary Algorithms: Potential Enhancements and Challenges</title>
<link>https://arxiv.org/abs/2401.10510</link>
<guid>https://arxiv.org/abs/2401.10510</guid>
<content:encoded><![CDATA[
<div> 关键词: 预训练大型语言模型 (LLMs), 进化算法 (EAs), 生成自然文本, 微观层面平行性, 跨学科研究挑战

总结:
本文探讨了预训练大型语言模型（LLMs）和进化算法（EAs）在微观层面上的一对一关键特性平行性，包括令牌表示与个体表示、位置编码与适应度塑造、位置嵌入与选择、Transformer模块与繁殖以及模型训练与参数适应等。这些平行性揭示了LLMs和EAs技术进步的可能性。文章进一步从宏观视角分析了跨学科研究中存在的关键挑战，重点关注了进化微调和LLM增强型EAs。这些分析不仅深化了对LLMs内在进化机制的理解，也为提升人工智能代理的能力提供了潜在方向。 <div>
arXiv:2401.10510v3 Announce Type: replace 
Abstract: Pre-trained large language models (LLMs) exhibit powerful capabilities for generating natural text. Evolutionary algorithms (EAs) can discover diverse solutions to complex real-world problems. Motivated by the common collective and directionality of text generation and evolution, this paper first illustrates the conceptual parallels between LLMs and EAs at a micro level, which includes multiple one-to-one key characteristics: token representation and individual representation, position encoding and fitness shaping, position embedding and selection, Transformers block and reproduction, and model training and parameter adaptation. These parallels highlight potential opportunities for technical advancements in both LLMs and EAs. Subsequently, we analyze existing interdisciplinary research from a macro perspective to uncover critical challenges, with a particular focus on evolutionary fine-tuning and LLM-enhanced EAs. These analyses not only provide insights into the evolutionary mechanisms behind LLMs but also offer potential directions for enhancing the capabilities of artificial agents.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Cooperative Nonlinear Guidance Strategies for Guaranteed Pursuit-Evasion</title>
<link>https://arxiv.org/abs/2402.06176</link>
<guid>https://arxiv.org/abs/2402.06176</guid>
<content:encoded><![CDATA[
<div> 关键词：三体追逃问题、合作制导律、拦截、几何解决方案、计算效率

总结:
本文研究了涉及追捕者、逃逸者和防御者的三体追逃问题。提出了一种新的合作制导律，确保防御者能在追捕者接近逃逸者前将其拦截。该方法与传统的启发式方法、最优控制、微分游戏形式化以及最近的时间约束制导技术不同，提供了一个几何解法，有效地保护逃逸者免受追捕者的威胁。该策略具有良好的计算效率并有望随着 agent 数量增加而保持可扩展性。重要的是，逃逸者-防御者团队不需要知道追捕者的策略，并且能从任意初始交战构型中保证拦截追捕者。此外，证明了逃逸者-防御者团队所需的关键误差变量将在预设的三体交战时间之前消失。最后，通过模拟多种交战场景验证了所提合作防御策略的有效性。<br /><br /> <div>
arXiv:2402.06176v2 Announce Type: replace 
Abstract: This paper addresses the pursuit-evasion problem involving three agents -- a purser, an evader, and a defender. We develop cooperative guidance laws for the evader-defender team that guarantee that the defender intercepts the pursuer before it reaches the vicinity of the evader. Unlike heuristic methods, optimal control, differential game formulation, and recently proposed time-constrained guidance techniques, we propose a geometric solution to safeguard the evader from the pursuer's incoming threat. The proposed strategy is computationally efficient and expected to be scalable as the number of agents increases. Another alluring feature of the proposed strategy is that the evader-defender team does not require the knowledge of the pursuer's strategy and that the pursuer's interception is guaranteed from arbitrary initial engagement geometries. We further show that the necessary error variables for the evader-defender team vanish within a time that can be exactly prescribed prior to the three-body engagement. Finally, we demonstrate the efficacy of the proposed cooperative defense strategy via simulation in diverse engagement scenarios.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Federated Multi-Agent Mapping for Planetary Exploration</title>
<link>https://arxiv.org/abs/2404.02289</link>
<guid>https://arxiv.org/abs/2404.02289</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体机器人探索、联邦学习、CADRE月球车任务、隐式神经映射、路径规划

总结:
本文提出了一种应用于多智能体机器人空间探索的联邦学习联合建图方法，该方法能够在带宽受限的环境下有效利用和分享产生的大量数据。研究借鉴了即将进行的CADRE月球车任务，采用隐式神经映射生成紧凑、适应性强的地图表示，相比于原始地图数据，减少了高达93.8%的数据传输量。进一步地，通过在地球上的可行驶性数据集上进行元初始化，可以显著加速地图收敛，将达到目标性能所需的迭代次数减少了80%。实验结果显示，该方法在火星地形和冰川数据集上实现了高达0.95的下游路径规划F1分数，并在地图重建损失方面表现出优越性能。 <div>
arXiv:2404.02289v3 Announce Type: replace 
Abstract: Multi-agent robotic exploration stands to play an important role in space exploration as the next generation of robotic systems ventures to far-flung environments. A key challenge in this new paradigm will be to effectively share and utilize the vast amount of data generated onboard while operating in bandwidth-constrained regimes typical of space missions. Federated learning (FL) is a promising tool for bridging this gap. Drawing inspiration from the upcoming CADRE Lunar rover mission, we propose a federated multi-agent mapping approach that jointly trains a global map model across agents without transmitting raw data. Our method leverages implicit neural mapping to generate parsimonious, adaptable representations, reducing data transmission by up to 93.8% compared to raw maps. Furthermore, we enhance this approach with meta-initialization on Earth-based traversability datasets to significantly accelerate map convergence; reducing iterations required to reach target performance by 80% compared to random initialization. We demonstrate the efficacy of our approach on Martian terrains and glacier datasets, achieving downstream path planning F1 scores as high as 0.95 while outperforming on map reconstruction losses.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Emergent Language: A Survey and Taxonomy</title>
<link>https://arxiv.org/abs/2409.02645</link>
<guid>https://arxiv.org/abs/2409.02645</guid>
<content:encoded><![CDATA[
<div> 关键词: emergent language、artificial intelligence、multi-agent reinforcement learning、evaluation methods、research gaps

总结:
本文探讨了人工智能领域中新兴的语言涌现研究，特别是多智能体强化学习的视角。该研究着重于利用强化学习培养出与人类语言相媲美甚至超越的人工智能语言能力，而不再仅限于解释人类语言形成。文章通过回顾181篇相关科学文献，明确了该领域的核心术语，分析了现有的评价方法和指标，并指出了现存的研究空白。该论文旨在为对此领域感兴趣或已经有一定研究基础的学者提供参考。 <div>
arXiv:2409.02645v2 Announce Type: replace 
Abstract: The field of emergent language represents a novel area of research within the domain of artificial intelligence, particularly within the context of multi-agent reinforcement learning. Although the concept of studying language emergence is not new, early approaches were primarily concerned with explaining human language formation, with little consideration given to its potential utility for artificial agents. In contrast, studies based on reinforcement learning aim to develop communicative capabilities in agents that are comparable to or even superior to human language. Thus, they extend beyond the learned statistical representations that are common in natural language processing research. This gives rise to a number of fundamental questions, from the prerequisites for language emergence to the criteria for measuring its success. This paper addresses these questions by providing a comprehensive review of 181 scientific publications on emergent language in artificial intelligence. Its objective is to serve as a reference for researchers interested in or proficient in the field. Consequently, the main contributions are the definition and overview of the prevailing terminology, the analysis of existing evaluation methods and metrics, and the description of the identified research gaps.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>DreamForge: Motion-Aware Autoregressive Video Generation for Multi-View Driving Scenes</title>
<link>https://arxiv.org/abs/2409.04003</link>
<guid>https://arxiv.org/abs/2409.04003</guid>
<content:encoded><![CDATA[
<div> 关键词: DreamForge、扩散模型、自动驾驶场景、长期视频生成、运动感知时空注意力

总结:
DreamForge是一款先进的基于扩散模型的自回归视频生成模型，特别针对3D可控制的长期驾驶场景生成进行了优化。为提升车道和前景生成的准确性，该模型引入了透视引导并整合了对象位置编码，以增强局部三维相关性和改善前景物体建模。此外，DreamForge提出了一种运动感知的时间注意力机制，用于捕获视频中的动态线索和外观变化。通过利用运动帧和自回归生成范式，DreamForge能够在仅使用短序列训练的情况下，自回归地生成超过200帧的高质量长视频，相较于基线在16帧视频评估中表现出更优的质量。最后，将DreamForge的方法与现实感模拟器DriveArena相结合，为基于视觉的驾驶代理提供更为可靠开放环和闭环评估。 <div>
arXiv:2409.04003v3 Announce Type: replace 
Abstract: Recent advances in diffusion models have improved controllable streetscape generation and supported downstream perception and planning tasks. However, challenges remain in accurately modeling driving scenes and generating long videos. To alleviate these issues, we propose DreamForge, an advanced diffusion-based autoregressive video generation model tailored for 3D-controllable long-term generation. To enhance the lane and foreground generation, we introduce perspective guidance and integrate object-wise position encoding to incorporate local 3D correlation and improve foreground object modeling. We also propose motion-aware temporal attention to capture motion cues and appearance changes in videos. By leveraging motion frames and an autoregressive generation paradigm,we can autoregressively generate long videos (over 200 frames) using a model trained in short sequences, achieving superior quality compared to the baseline in 16-frame video evaluations. Finally, we integrate our method with the realistic simulator DriveArena to provide more reliable open-loop and closed-loop evaluations for vision-based driving agents. Project Page: https://pjlab-adg.github.io/DriveArena/dreamforge.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Context-Based Meta Reinforcement Learning for Robust and Adaptable Peg-in-Hole Assembly Tasks</title>
<link>https://arxiv.org/abs/2409.16208</link>
<guid>https://arxiv.org/abs/2409.16208</guid>
<content:encoded><![CDATA[
<div> 关键词：Peg-in-hole组装、未知环境、元强化学习（Meta RL）、力/扭矩传感器、样本效率

总结:<br />
本文针对未知环境中 peg-in-hole 组装任务所面临的挑战，提出了一种改进的元强化学习方法。该方法通过修改 Meta RL 代理使用的数据并采用易于真实世界中使用（即使相机未校准）的简单特征。此外，研究还使代理能利用少量训练数据，借助力/扭矩传感器替代相机进行组装任务。文章进一步提出了一个微调方法，使得代理能够在与训练任务参数差异达10倍的分布外任务中安全、一致地适应。实验结果表明，提出的数据显示修改显著提高了训练和适应效率，并使代理成功完成了不同位置和方向的孔洞组装任务，实现实验平台与模拟性能匹配，成功率均达到100%。相比于依赖样例不高效的适应方法，本文提出的方法在实际任务中的样本效率提升了10倍。 <div>
arXiv:2409.16208v2 Announce Type: replace 
Abstract: Peg-in-hole assembly in unknown environments is a challenging task due to onboard sensor errors, which result in uncertainty and variations in task parameters such as the hole position and orientation. Meta Reinforcement Learning (Meta RL) has been proposed to mitigate this problem as it learns how to quickly adapt to new tasks with different parameters. However, previous approaches either depend on a sample-inefficient procedure or human demonstrations to perform the task in the real world. Our work modifies the data used by the Meta RL agent and uses simple features that can be easily measured in the real world even with an uncalibrated camera. We further adapt the Meta RL agent to use data from a force/torque sensor, instead of the camera, to perform the assembly, using a small amount of training data. Finally, we propose a fine-tuning method that consistently and safely adapts to out-of-distribution tasks with parameters that differ by a factor of 10 from the training tasks. Our results demonstrate that the proposed data modification significantly enhances the training and adaptation efficiency and enables the agent to achieve 100% success in tasks with different hole positions and orientations. Experiments on a real robot confirm that both camera- and force/torque sensor-equipped agents achieve 100% success in tasks with unknown hole positions, matching their simulation performance and validating the approach's robustness and applicability. Compared to the previous work with sample-inefficient adaptation, our proposed methods are 10 times more sample-efficient in the real-world tasks.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Safe Decentralized Multi-Agent Control using Black-Box Predictors, Conformal Decision Policies, and Control Barrier Functions</title>
<link>https://arxiv.org/abs/2409.18862</link>
<guid>https://arxiv.org/abs/2409.18862</guid>
<content:encoded><![CDATA[
<div> 关键词：安全控制、分布式多智能体系统、不确定黑盒模型、控制 Barrier 函数、预测误差、conformal 决策理论、任务完成、上界、平均值、实验验证、机器人导航、斯坦福无人机数据集。

<br /><br />总结:

本文关注分布式多智能体机器人系统中的安全控制问题，其中各个智能体使用存在不确定性的黑盒模型来预测其他智能体的轨迹。文章采用了最近提出的conformal决策理论，根据观测到的预测误差动态调整基于控制Barrier函数的安全约束。通过这些约束，文章提出了一种能够在确保安全的同时平衡任务完成目标的控制器设计方法。文中给出了关于基于预测轨迹的安全约束与基于真实轨迹的约束差值之单调函数的平均值上界的分析。通过在斯坦福无人机数据集上的实验结果，验证了所提理论和控制器性能的有效性。 <div>
arXiv:2409.18862v4 Announce Type: replace 
Abstract: We address the challenge of safe control in decentralized multi-agent robotic settings, where agents use uncertain black-box models to predict other agents' trajectories. We use the recently proposed conformal decision theory to adapt the restrictiveness of control barrier functions-based safety constraints based on observed prediction errors. We use these constraints to synthesize controllers that balance between the objectives of safety and task accomplishment, despite the prediction errors. We provide an upper bound on the average over time of the value of a monotonic function of the difference between the safety constraint based on the predicted trajectories and the constraint based on the ground truth ones. We validate our theory through experimental results showing the performance of our controllers when navigating a robot in the multi-agent scenes in the Stanford Drone Dataset.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Curb Your Attention: Causal Attention Gating for Robust Trajectory Prediction in Autonomous Driving</title>
<link>https://arxiv.org/abs/2410.07191</link>
<guid>https://arxiv.org/abs/2410.07191</guid>
<content:encoded><![CDATA[
<div> 关键词：轨迹预测、自动驾驶、因果关系、鲁棒性、泛化能力

总结:<br />
本文提出了一个名为$\textbf{CRiTIC}$的新颖模型，用于解决自动驾驶中的轨迹预测问题。该模型利用$\textit{因果发现网络}$在过去的多个时间步中识别各智能体之间的因果关系。为了结合这些发现的因果关系，文中设计了一种称为$\textit{因果注意力门控}$的机制，用于Transformer架构中选择性地过滤信息。通过在两个自动驾驶基准数据集上的大量实验，结果表明$\textbf{CRiTIC}$模型能有效提高对非因果扰动的鲁棒性（提升高达$\textbf{54\%}$），同时并未显著牺牲预测准确性。此外，还展示了该模型具有优越的领域泛化能力，跨域性能提高了最多$\textbf{29\%}$。这表明$\textbf{CRiTIC}$模型有望增强自动驾驶场景中轨迹预测的鲁棒性和泛化能力。更多详情可访问项目主页：https://ehsan-ami.github.io/critic。 <div>
arXiv:2410.07191v2 Announce Type: replace 
Abstract: Trajectory prediction models in autonomous driving are vulnerable to perturbations from non-causal agents whose actions should not affect the ego-agent's behavior. Such perturbations can lead to incorrect predictions of other agents' trajectories, potentially compromising the safety and efficiency of the ego-vehicle's decision-making process. Motivated by this challenge, we propose $\textit{Causal tRajecTory predICtion}$ $\textbf{(CRiTIC)}$, a novel model that utilizes a $\textit{Causal Discovery Network}$ to identify inter-agent causal relations over a window of past time steps. To incorporate discovered causal relationships, we propose a novel $\textit{Causal Attention Gating}$ mechanism to selectively filter information in the proposed Transformer-based architecture. We conduct extensive experiments on two autonomous driving benchmark datasets to evaluate the robustness of our model against non-causal perturbations and its generalization capacity. Our results indicate that the robustness of predictions can be improved by up to $\textbf{54%}$ without a significant detriment to prediction accuracy. Lastly, we demonstrate the superior domain generalizability of the proposed model, which achieves up to $\textbf{29%}$ improvement in cross-domain performance. These results underscore the potential of our model to enhance both robustness and generalization capacity for trajectory prediction in diverse autonomous driving domains. Further details can be found on our project page: https://ehsan-ami.github.io/critic.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Transformer-Based Fault-Tolerant Control for Fixed-Wing UAVs Using Knowledge Distillation and In-Context Adaptation</title>
<link>https://arxiv.org/abs/2411.02975</link>
<guid>https://arxiv.org/abs/2411.02975</guid>
<content:encoded><![CDATA[
<div> 关键词：transformer、故障容错控制、固定翼无人机、知识蒸馏、强化学习

总结:
该研究提出了一种基于变压器的固定翼无人机故障容错控制方法，能够实时适应因结构损伤或执行器故障导致的动力学变化。与依赖传统控制理论并在严重动态变化下表现不佳的经典飞行控制系统不同，此方法利用变压器的上下文学习和注意力机制，直接将外环参考值（如高度、航向和空速）映射到控制指令，绕过了内环控制器和故障检测层。通过采用教师-学生知识蒸馏框架，研究训练了一个仅具有部分观测的学生代理，并从具有完全可观测性的专家代理那里转移知识，从而在各种故障场景中实现稳健性能。实验结果显示，所提出的基于变压器的控制器在名义条件和极端故障情况下均优于行业标准的FCS和最先进的强化学习方法，保持了高跟踪精度和稳定性，显示出其对提升无人机操作安全性和可靠性的潜力。 <div>
arXiv:2411.02975v2 Announce Type: replace 
Abstract: This study presents a transformer-based approach for fault-tolerant control in fixed-wing Unmanned Aerial Vehicles (UAVs), designed to adapt in real time to dynamic changes caused by structural damage or actuator failures. Unlike traditional Flight Control Systems (FCSs) that rely on classical control theory and struggle under severe alterations in dynamics, our method directly maps outer-loop reference values -- altitude, heading, and airspeed -- into control commands using the in-context learning and attention mechanisms of transformers, thus bypassing inner-loop controllers and fault-detection layers. Employing a teacher-student knowledge distillation framework, the proposed approach trains a student agent with partial observations by transferring knowledge from a privileged expert agent with full observability, enabling robust performance across diverse failure scenarios. Experimental results demonstrate that our transformer-based controller outperforms industry-standard FCS and state-of-the-art reinforcement learning (RL) methods, maintaining high tracking accuracy and stability in nominal conditions and extreme failure cases, highlighting its potential for enhancing UAV operational safety and reliability.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Reinforcement Learning Within the Classical Robotics Stack: A Case Study in Robot Soccer</title>
<link>https://arxiv.org/abs/2412.09417</link>
<guid>https://arxiv.org/abs/2412.09417</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人决策、部分可观测环境、实时动态、多智能体、强化学习<br /><br />总结:

本文提出了一种解决机器人在部分可观测、实时动态和多智能体环境中决策难题的新方法。该方法结合了模型自由的强化学习（RL）与经典的机器人技术栈，并采用多精度模拟到现实（sim2real）的方法，将行为分解为学习到的子行为并辅以启发式选择。研究团队在2024年RoboCup标准平台联赛挑战盾牌分区中应用此架构并取得了胜利。文中详细描述了系统架构，并实证分析了导致成功的关键设计决策。这一方法展示了如何将基于RL的行为整合进完整的机器人行为架构中。 <div>
arXiv:2412.09417v2 Announce Type: replace 
Abstract: Robot decision-making in partially observable, real-time, dynamic, and multi-agent environments remains a difficult and unsolved challenge. Model-free reinforcement learning (RL) is a promising approach to learning decision-making in such domains, however, end-to-end RL in complex environments is often intractable. To address this challenge in the RoboCup Standard Platform League (SPL) domain, we developed a novel architecture integrating RL within a classical robotics stack, while employing a multi-fidelity sim2real approach and decomposing behavior into learned sub-behaviors with heuristic selection. Our architecture led to victory in the 2024 RoboCup SPL Challenge Shield Division. In this work, we fully describe our system's architecture and empirically analyze key design decisions that contributed to its success. Our approach demonstrates how RL-based behaviors can be integrated into complete robot behavior architectures.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Wasserstein Adaptive Value Estimation for Actor-Critic Reinforcement Learning</title>
<link>https://arxiv.org/abs/2501.10605</link>
<guid>https://arxiv.org/abs/2501.10605</guid>
<content:encoded><![CDATA[
<div> 关键词：Wasserstein 适应性值估计 演员-评论家算法 稳定性 强化学习

总结:
本文提出了一种名为"Wasserstein自适应值估计用于演员-评论家(WAVE)"的方法，旨在通过自适应的Wasserstein正则化增强深度强化学习的稳定性。该方法通过将自适应加权的Wasserstein正则化项引入到评论家的损失函数中，解决了演员-评论家算法内在的不稳定性问题。理论证明了WAVE可以实现批评家均方误差的$\mathcal{O}\left(\frac{1}{k}\right)$收敛率，并通过基于Wasserstein的正则化提供了稳定性理论保证。为了提高计算效率，WAVE利用Sinkhorn近似自动调整正则化的权重。理论分析和实验结果表明，相较于标准的演员-评论家方法，WAVE表现出更优的性能。 <div>
arXiv:2501.10605v2 Announce Type: replace 
Abstract: We present Wasserstein Adaptive Value Estimation for Actor-Critic (WAVE), an approach to enhance stability in deep reinforcement learning through adaptive Wasserstein regularization. Our method addresses the inherent instability of actor-critic algorithms by incorporating an adaptively weighted Wasserstein regularization term into the critic's loss function. We prove that WAVE achieves $\mathcal{O}\left(\frac{1}{k}\right)$ convergence rate for the critic's mean squared error and provide theoretical guarantees for stability through Wasserstein-based regularization. Using the Sinkhorn approximation for computational efficiency, our approach automatically adjusts the regularization based on the agent's performance. Theoretical analysis and experimental results demonstrate that WAVE achieves superior performance compared to standard actor-critic methods.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Symbiotic Cooperation for Web Agents: Harnessing Complementary Strengths of Large and Small LLMs</title>
<link>https://arxiv.org/abs/2502.07942</link>
<guid>https://arxiv.org/abs/2502.07942</guid>
<content:encoded><![CDATA[
<div> 关键词: AgentSymbiotic、LLM、大模型、小模型、数据合成<br /><br />总结:
在这篇文章中，研究者提出了一种名为AgentSymbiotic的迭代框架，该框架针对基于大型语言模型（LLM）的网络浏览代理进行优化。AgentSymbiotic通过将数据综合与任务性能相结合，实现了大型和小型LLM之间的“共生改进”。研究发现大型LLM擅长生成高质量轨迹用于蒸馏，而蒸馏后的小型LLM因其独特的推理能力往往会选择与大型LLM不同的行动，从而推动对新轨迹的探索和数据丰富。为了解决在迭代增强过程中小型LLM性能成为瓶颈的问题，研究者提出了投机性数据合成策略以减轻离政策偏差，并采用多任务学习方法提升学生LLM的推理能力。同时，为了保护用户隐私，他们还引入了混合模式。在WEBARENA基准上，AgentSymbiotic使大型LLM代理性能达到52%（超过先前最佳的45%），而蒸馏得到的8B模型表现出竞争性的49%（优于之前的28%）。文章表明代码将在接受后发布。 <div>
arXiv:2502.07942v2 Announce Type: replace 
Abstract: Web browsing agents powered by large language models (LLMs) have shown tremendous potential in automating complex web-based tasks. Existing approaches typically rely on large LLMs (e.g., GPT-4o) to explore web environments and generate trajectory data, which is then used either for demonstration retrieval (for large LLMs) or to distill small LLMs (e.g., Llama3) in a process that remains decoupled from the exploration. In this paper, we propose AgentSymbiotic, an iterative framework that couples data synthesis with task-performance, yielding a "symbiotic improvement" for both large and small LLMs. Our study uncovers a complementary dynamic between LLM types: while large LLMs excel at generating high-quality trajectories for distillation, the distilled small LLMs-owing to their distinct reasoning capabilities-often choose actions that diverge from those of their larger counterparts. This divergence drives the exploration of novel trajectories, thereby enriching the synthesized data. However, we also observe that the performance of small LLMs becomes a bottleneck in this iterative enhancement process. To address this, we propose two innovations in LLM distillation: a speculative data synthesis strategy that mitigates off-policy bias, and a multi-task learning approach designed to boost the reasoning capabilities of the student LLM. Furthermore, we introduce a Hybrid Mode for Privacy Preservation to address user privacy concerns. Evaluated on the WEBARENA benchmark, AgentSymbiotic achieves SOTA performance with both LLM types. Our best Large LLM agent reaches 52%, surpassing the previous best of 45%, while our 8B distilled model demonstrates a competitive 49%, exceeding the prior best of 28%. Code will be released upon acceptance.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 00:00:00 -0400</pubDate>
</item>
<item>
<title>Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous Racing Systems</title>
<link>https://arxiv.org/abs/2503.03774</link>
<guid>https://arxiv.org/abs/2503.03774</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主赛车、体育精神、双层博弈框架、蒙特卡洛树搜索、纳什均衡问题<br /><br />总结:
本文关注自主赛车中的体育精神问题，提出了一种将体育精神融入到对抗竞技赛车的双层博弈理论框架。在高层，采用Stackelberg游戏模型来利用蒙特卡洛树搜索(MCTS)制定最优比赛策略，考虑赛车意图。在底层，将车辆交互形式化为广义纳什均衡问题(GNEP)，确保所有代理在遵循体育精神约束的同时优化自身轨迹。通过模拟实验，证明了该方法在执行体育精神规则的同时能保持竞技性能的有效性。文中分析了遵守和不遵守体育精神规则的不同场景，展示了这些约束如何影响战略决策制定。本文强调了在自主赛车中平衡竞争与公平的重要性，并为此类AI驱动的赛车系统开发提供了伦理和安全的基础。 <div>
arXiv:2503.03774v1 Announce Type: new 
Abstract: Autonomous racing has gained significant attention as a platform for high-speed decision-making and motion control. While existing methods primarily focus on trajectory planning and overtaking strategies, the role of sportsmanship in ensuring fair competition remains largely unexplored. In human racing, rules such as the one-motion rule and the enough-space rule prevent dangerous and unsportsmanlike behavior. However, autonomous racing systems often lack mechanisms to enforce these principles, potentially leading to unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to integrate sportsmanship (SPS) into versus racing. At the high level, we model racing intentions using a Stackelberg game, where Monte Carlo Tree Search (MCTS) is employed to derive optimal strategies. At the low level, vehicle interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP), ensuring that all agents follow sportsmanship constraints while optimizing their trajectories. Simulation results demonstrate the effectiveness of the proposed approach in enforcing sportsmanship rules while maintaining competitive performance. We analyze different scenarios where attackers and defenders adhere to or disregard sportsmanship rules and show how knowledge of these constraints influences strategic decision-making. This work highlights the importance of balancing competition and fairness in autonomous racing and provides a foundation for developing ethical and safe AI-driven racing systems.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Accelerating Focal Search in Multi-Agent Path Finding with Tighter Lower Bounds</title>
<link>https://arxiv.org/abs/2503.03779</link>
<guid>https://arxiv.org/abs/2503.03779</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Path Finding (MAPF)，Enhanced Conflict-Based Search (ECBS)，Explicit Estimation CBS (EECBS)，double-ECBS (DECBS)，碰撞避免

总结:
本文提出了一种针对多智能体路径规划问题（MAPF）的新算法——双增强冲突搜索（DECBS），该问题是NP难的问题。DECBS旨在解决传统聚焦搜索方法中，如ECBS和EECBS，早期搜索阶段较低下界值导致的有效搜索空间受限的问题。DECBS首先确定最大下界值，然后采用基于此下界的最好优先搜索来寻找无冲突路径。实验结果显示，DECBS在大多数测试案例中优于ECBS，并能与现有优化技术兼容。DECBS可以减少约30%的高层CT节点和50%的低层聚焦搜索节点。在中等到高密度的智能体场景下，DECBS相比ECBS在相同次优性约束和优化条件下，平均运行时间提高了23.5%。 <div>
arXiv:2503.03779v1 Announce Type: new 
Abstract: Multi-Agent Path Finding (MAPF) involves finding collision-free paths for multiple agents while minimizing a cost function--an NP-hard problem. Bounded suboptimal methods like Enhanced Conflict-Based Search (ECBS) and Explicit Estimation CBS (EECBS) balance solution quality with computational efficiency using focal search mechanisms. While effective, traditional focal search faces a limitation: the lower bound (LB) value determining which nodes enter the FOCAL list often increases slowly in early search stages, resulting in a constrained search space that delays finding valid solutions. In this paper, we propose a novel bounded suboptimal algorithm, double-ECBS (DECBS), to address this issue by first determining the maximum LB value and then employing a best-first search guided by this LB to find a collision-free path. Experimental results demonstrate that DECBS outperforms ECBS in most test cases and is compatible with existing optimization techniques. DECBS can reduce nearly 30% high-level CT nodes and 50% low-level focal search nodes. When agent density is moderate to high, DECBS achieves a 23.5% average runtime improvement over ECBS with identical suboptimality bounds and optimizations.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human Implicit Preference-Based Policy Fine-tuning for Multi-Agent Reinforcement Learning in USV Swarm</title>
<link>https://arxiv.org/abs/2503.03796</link>
<guid>https://arxiv.org/abs/2503.03796</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Reinforcement Learning (MARL)，Unmanned Surface Vehicle (USV) swarm，Reinforcement Learning with Human Feedback (RLHF)，Agent-Level Feedback，Large Language Model (LLM)

<br /><br />总结：
本文提出了一种针对多智能体强化学习（MARL）的基于人类反馈的强化学习方法（RLHF），旨在解决将专家直觉编码到奖励函数中的挑战。该方法通过一个代理级反馈系统，将反馈细分为内部代理、相互代理和团队内部三种类型，以解决协同学习中的责任分配问题。为了解决直接人类反馈的困难，研究者利用大型语言模型（LLM）评估器在如区域约束、碰撞避免和任务分配等场景中验证了他们的方法。这种方法有效地优化了无人水面艇群的策略，同时解决了多智能体系统中的关键挑战，保持了公平性和性能一致性。 <div>
arXiv:2503.03796v1 Announce Type: new 
Abstract: Multi-Agent Reinforcement Learning (MARL) has shown promise in solving complex problems involving cooperation and competition among agents, such as an Unmanned Surface Vehicle (USV) swarm used in search and rescue, surveillance, and vessel protection. However, aligning system behavior with user preferences is challenging due to the difficulty of encoding expert intuition into reward functions. To address the issue, we propose a Reinforcement Learning with Human Feedback (RLHF) approach for MARL that resolves credit-assignment challenges through an Agent-Level Feedback system categorizing feedback into intra-agent, inter-agent, and intra-team types. To overcome the challenges of direct human feedback, we employ a Large Language Model (LLM) evaluator to validate our approach using feedback scenarios such as region constraints, collision avoidance, and task allocation. Our method effectively refines USV swarm policies, addressing key challenges in multi-agent systems while maintaining fairness and performance consistency.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Systems Powered by Large Language Models: Applications in Swarm Intelligence</title>
<link>https://arxiv.org/abs/2503.03800</link>
<guid>https://arxiv.org/abs/2503.03800</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，多智能体模拟，NetLogo，GPT-4，自组织行为

总结:
本文研究了如何将大型语言模型（LLMs）集成到多智能体模拟中，通过使用LLM驱动的提示来替换硬编码的代理程序。作者展示了这一方法在两个复杂系统领域的应用——蚂蚁群体觅食和鸟群飞行，利用一个工具链将LLMs与NetLogo仿真平台整合，并借助其Python扩展实现与GPT-4的OpenAI API通信。该工具链支持由提示驱动的行为生成，使代理人能够根据环境数据做出适应性反应。在上述两个示例中，采用了结构化、规则型提示以及自主、知识驱动型提示。研究表明，这一工具链使得LLMs能够在多智能体环境中研究自我组织过程并诱导出涌现行为，为探索智能系统和以自然现象为灵感的群智建模开辟了新途径。相关代码、仿真文件及数据可在https://github.com/crjimene/swarm_gpt找到。 <div>
arXiv:2503.03800v1 Announce Type: new 
Abstract: This work examines the integration of large language models (LLMs) into multi-agent simulations by replacing the hard-coded programs of agents with LLM-driven prompts. The proposed approach is showcased in the context of two examples of complex systems from the field of swarm intelligence: ant colony foraging and bird flocking. Central to this study is a toolchain that integrates LLMs with the NetLogo simulation platform, leveraging its Python extension to enable communication with GPT-4o via the OpenAI API. This toolchain facilitates prompt-driven behavior generation, allowing agents to respond adaptively to environmental data. For both example applications mentioned above, we employ both structured, rule-based prompts and autonomous, knowledge-driven prompts. Our work demonstrates how this toolchain enables LLMs to study self-organizing processes and induce emergent behaviors within multi-agent environments, paving the way for new approaches to exploring intelligent systems and modeling swarm intelligence inspired by natural phenomena. We provide the code, including simulation files and data at https://github.com/crjimene/swarm_gpt.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning to Negotiate via Voluntary Commitment</title>
<link>https://arxiv.org/abs/2503.03866</link>
<guid>https://arxiv.org/abs/2503.03866</guid>
<content:encoded><![CDATA[
<div> 关键词：Markov Commitment Games (MCGs)，自主代理，承诺，政策梯度，激励相容学习

总结:
本文提出了一个新的概念——马尔科夫承诺游戏(Markov Commitment Games, MCGs)，用于解决自治代理在混合动机场景中合作的问题。在MCGs框架下，作者设计了一种基于策略梯度的可学习承诺协议，以帮助代理自愿承诺其未来的计划。此外，为了加速收敛至具有更好社会福利的均衡，他们还提出了激励相容的学习方法。实验结果显示，与对照组相比，该方法在具有挑战性的混合动机任务中展现出更快的收敛速度和更高的回报。研究代码已公开发布于https://github.com/shuhui-zhu/DCL。 <div>
arXiv:2503.03866v1 Announce Type: new 
Abstract: The partial alignment and conflict of autonomous agents lead to mixed-motive scenarios in many real-world applications. However, agents may fail to cooperate in practice even when cooperation yields a better outcome. One well known reason for this failure comes from non-credible commitments. To facilitate commitments among agents for better cooperation, we define Markov Commitment Games (MCGs), a variant of commitment games, where agents can voluntarily commit to their proposed future plans. Based on MCGs, we propose a learnable commitment protocol via policy gradients. We further propose incentive-compatible learning to accelerate convergence to equilibria with better social welfare. Experimental results in challenging mixed-motive tasks demonstrate faster empirical convergence and higher returns for our method compared with its counterparts. Our code is available at https://github.com/shuhui-zhu/DCL.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Seldonian Reinforcement Learning for Ad Hoc Teamwork</title>
<link>https://arxiv.org/abs/2503.03885</link>
<guid>https://arxiv.org/abs/2503.03885</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习、统计保证、不安全行为、Ad Hoc 团队合作、可靠性

总结:
本文提出了一种新颖的离线强化学习方法，该方法受到Seldonian优化的启发，旨在生成具有优秀性能并针对预定义不安全行为提供统计保障的策略。这种方法特别关注无需预先协调就能与新队友协作的Ad Hoc团队合作场景。算法仅依赖于预收集的数据集、一组候选政策以及对其他玩家可能遵循的政策的规范说明，不需要进一步交互、训练或假设政策类型和架构。实验结果显示，该算法在Ad Hoc团队合作问题中能找到可靠的策略，同时相较于标准机器学习基线提高了样例效率。<br /><br /> <div>
arXiv:2503.03885v1 Announce Type: new 
Abstract: Most offline RL algorithms return optimal policies but do not provide statistical guarantees on undesirable behaviors. This could generate reliability issues in safety-critical applications, such as in some multiagent domains where agents, and possibly humans, need to interact to reach their goals without harming each other. In this work, we propose a novel offline RL approach, inspired by Seldonian optimization, which returns policies with good performance and statistically guaranteed properties with respect to predefined undesirable behaviors. In particular, our focus is on Ad Hoc Teamwork settings, where agents must collaborate with new teammates without prior coordination. Our method requires only a pre-collected dataset, a set of candidate policies for our agent, and a specification about the possible policies followed by the other players -- it does not require further interactions, training, or assumptions on the type and architecture of the policies. We test our algorithm in Ad Hoc Teamwork problems and show that it consistently finds reliable policies while improving sample efficiency with respect to standard ML baselines.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Audio Flamingo 2: An Audio-Language Model with Long-Audio Understanding and Expert Reasoning Abilities</title>
<link>https://arxiv.org/abs/2503.03983</link>
<guid>https://arxiv.org/abs/2503.03983</guid>
<content:encoded><![CDATA[
<div> 关键词: Audio Flamingo 2 (AF2)，Audio-Language Model (ALM)，CLAP模型，LongAudio，LongAudioBench

总结:
本文介绍了Audio Flamingo 2 (AF2)，这是一个具有高级音频理解和推理能力的Audio-Language Model (ALM)。AF2采用了一种定制的CLAP模型、用于细粒度音频推理的合成音频QA数据以及多阶段课程学习策略。通过仅使用一个3B参数的小型语言模型，AF2在超过20项基准测试中超越了大型开源和专有模型，取得了最优性能。此外，文章首次将音频理解扩展到长时间音频片段（30秒至5分钟），并提出了LongAudio——一个大规模的新颖数据集，用于训练ALM进行长音频标题生成和问答任务。在LongAudio上微调AF2后，其在为评估ALM在长音频理解能力而设计的专家注释基准LongAudioBench上表现出色。最后，作者进行了广泛的消融研究以证实其方法的有效性。该项目网站为：https://research.nvidia.com/labs/adlr/AF2/。 <div>
arXiv:2503.03983v1 Announce Type: new 
Abstract: Understanding and reasoning over non-speech sounds and music are crucial for both humans and AI agents to interact effectively with their environments. In this paper, we introduce Audio Flamingo 2 (AF2), an Audio-Language Model (ALM) with advanced audio understanding and reasoning capabilities. AF2 leverages (i) a custom CLAP model, (ii) synthetic Audio QA data for fine-grained audio reasoning, and (iii) a multi-stage curriculum learning strategy. AF2 achieves state-of-the-art performance with only a 3B parameter small language model, surpassing large open-source and proprietary models across over 20 benchmarks. Next, for the first time, we extend audio understanding to long audio segments (30 secs to 5 mins) and propose LongAudio, a large and novel dataset for training ALMs on long audio captioning and question-answering tasks. Fine-tuning AF2 on LongAudio leads to exceptional performance on our proposed LongAudioBench, an expert annotated benchmark for evaluating ALMs on long audio understanding capabilities. We conduct extensive ablation studies to confirm the efficacy of our approach. Project Website: https://research.nvidia.com/labs/adlr/AF2/.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Pok\'eChamp: an Expert-level Minimax Language Agent</title>
<link>https://arxiv.org/abs/2503.04094</link>
<guid>https://arxiv.org/abs/2503.04094</guid>
<content:encoded><![CDATA[
<div> 关键词：PokéChamp、LLMs、minimax树搜索、ポケモンバトル、GPT-4

<br /><br />总结:
本文介绍了PokéChamp，一个利用大型语言模型（LLMs）进行宝可梦战斗的最小最大搜索代理。该代理基于两玩家竞争游戏的一般框架构建，通过LLMs增强最小最大搜索性能，将LLMs应用于三个关键模块：(1) 玩家动作采样，(2) 对手建模，以及(3) 值函数估计。这种方法使代理能有效地利用游戏历史和人类知识来减少搜索空间并解决部分可观测性问题。值得注意的是，该框架不需要额外的LLM训练。在流行的Gen 9 OU格式中，使用GPT-4o的PokéChamp获得了对现有最佳LLM基代理76%的胜率，以及对最强规则基代理84%的胜率，显示出其优越的表现。即便采用开源的80亿参数Llama 3.1模型，PokéChamp也能持续优于先前最佳的LLM基代理Pokémonellmon（使用GPT-4o），胜率为64%。PokéChamp在Pokémon Showdown在线天梯上的预计Elo分数为1300-1500，使其跻身前30%-10%的人类玩家行列。此外，本文还汇编了迄今为止最大的真实玩家宝可梦战斗数据集，包含超过300万场比赛，其中包括50多万场高Elo比赛。基于此数据集，建立了系列战斗基准与谜题以评估特定战斗技能，并更新了本地游戏引擎。作者希望这项工作能够促进进一步的研究，将宝可梦战斗作为基准，整合LLM技术与解决一般多智能体问题的游戏理论算法。相关的视频、代码和数据集可在https://sites.google.com/view/pokechamp-llm获取。 <div>
arXiv:2503.04094v1 Announce Type: new 
Abstract: We introduce Pok\'eChamp, a minimax agent powered by Large Language Models (LLMs) for Pok\'emon battles. Built on a general framework for two-player competitive games, Pok\'eChamp leverages the generalist capabilities of LLMs to enhance minimax tree search. Specifically, LLMs replace three key modules: (1) player action sampling, (2) opponent modeling, and (3) value function estimation, enabling the agent to effectively utilize gameplay history and human knowledge to reduce the search space and address partial observability. Notably, our framework requires no additional LLM training. We evaluate Pok\'eChamp in the popular Gen 9 OU format. When powered by GPT-4o, it achieves a win rate of 76% against the best existing LLM-based bot and 84% against the strongest rule-based bot, demonstrating its superior performance. Even with an open-source 8-billion-parameter Llama 3.1 model, Pok\'eChamp consistently outperforms the previous best LLM-based bot, Pok\'ellmon powered by GPT-4o, with a 64% win rate. Pok\'eChamp attains a projected Elo of 1300-1500 on the Pok\'emon Showdown online ladder, placing it among the top 30%-10% of human players. In addition, this work compiles the largest real-player Pok\'emon battle dataset, featuring over 3 million games, including more than 500k high-Elo matches. Based on this dataset, we establish a series of battle benchmarks and puzzles to evaluate specific battling skills. We further provide key updates to the local game engine. We hope this work fosters further research that leverage Pok\'emon battle as benchmark to integrate LLM technologies with game-theoretic algorithms addressing general multiagent problems. Videos, code, and dataset available at https://sites.google.com/view/pokechamp-llm.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>InterChat: Enhancing Generative Visual Analytics using Multimodal Interactions</title>
<link>https://arxiv.org/abs/2503.04110</link>
<guid>https://arxiv.org/abs/2503.04110</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，多模态交互，生成式视觉分析系统，InterChat，意图推断

总结:
本文探讨了大型语言模型（LLMs）和生成式视觉分析系统兴起带来的数据分析变革以及用户意图精确解读方面的挑战。通过文献回顾和初步头脑风暴，研究者探索了多模态交互在生成式视觉分析设计空间中的应用。他们提出了一种高度可扩展的工作流，将多个LLM代理集成用于意图推断和可视化生成。进而开发出InterChat系统，该系统结合了对视觉元素的直接操作和自然语言输入，实现了精确的意图沟通和以视觉驱动的渐进式探索性数据分析。通过有效的提示工程、上下文交互链接及直观的可视化和交互设计，InterChat弥合了用户交互与LLM驱动的可视化之间的鸿沟，提升了可解释性和易用性。文章通过两个使用场景、用户研究和专家反馈的广泛评估，证明了InterChat的有效性，结果显示其在处理复杂视觉分析任务的准确度和效率上具有显著提升，强调了多模态交互重新定义用户参与度和生成式视觉分析深度的可能性。 <div>
arXiv:2503.04110v1 Announce Type: new 
Abstract: The rise of Large Language Models (LLMs) and generative visual analytics systems has transformed data-driven insights, yet significant challenges persist in accurately interpreting users' analytical and interaction intents. While language inputs offer flexibility, they often lack precision, making the expression of complex intents inefficient, error-prone, and time-intensive. To address these limitations, we investigate the design space of multimodal interactions for generative visual analytics through a literature review and pilot brainstorming sessions. Building on these insights, we introduce a highly extensible workflow that integrates multiple LLM agents for intent inference and visualization generation. We develop InterChat, a generative visual analytics system that combines direct manipulation of visual elements with natural language inputs. This integration enables precise intent communication and supports progressive, visually driven exploratory data analyses. By employing effective prompt engineering, and contextual interaction linking, alongside intuitive visualization and interaction designs, InterChat bridges the gap between user interactions and LLM-driven visualizations, enhancing both interpretability and usability. Extensive evaluations, including two usage scenarios, a user study, and expert feedback, demonstrate the effectiveness of InterChat. Results show significant improvements in the accuracy and efficiency of handling complex visual analytics tasks, highlighting the potential of multimodal interactions to redefine user engagement and analytical depth in generative visual analytics.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DVM-SLAM: Decentralized Visual Monocular Simultaneous Localization and Mapping for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.04126</link>
<guid>https://arxiv.org/abs/2503.04126</guid>
<content:encoded><![CDATA[
<div> 关键词：Cooperative Simultaneous Localization and Mapping (C-SLAM)，Decentralized Visual Monocular SLAM (DVM-SLAM)，单目视觉传感器，多Agent自主导航，开源

总结：<br />
本文介绍了首个开源的分布式单目视觉C-SLAM系统——DVM-SLAM，该系统允许多个智能体利用低成本、轻量级的单目视觉传感器在未知环境中协作建图并同时估计自身位置，增强了系统的鲁棒性、可扩展性和精度。DVM-SLAM已在实际机器人上进行了验证，并结合了定制的碰撞避免框架，展示了其在实时多Agent自主导航场景中的应用潜力。此外，研究还表明DVM-SLAM的精度与最先进的集中式单目C-SLAM系统相当。作者已将代码开源并在网上提供了补充材料。 <div>
arXiv:2503.04126v1 Announce Type: new 
Abstract: Cooperative Simultaneous Localization and Mapping (C-SLAM) enables multiple agents to work together in mapping unknown environments while simultaneously estimating their own positions. This approach enhances robustness, scalability, and accuracy by sharing information between agents, reducing drift, and enabling collective exploration of larger areas. In this paper, we present Decentralized Visual Monocular SLAM (DVM-SLAM), the first open-source decentralized monocular C-SLAM system. By only utilizing low-cost and light-weight monocular vision sensors, our system is well suited for small robots and micro aerial vehicles (MAVs). DVM-SLAM's real-world applicability is validated on physical robots with a custom collision avoidance framework, showcasing its potential in real-time multi-agent autonomous navigation scenarios. We also demonstrate comparable accuracy to state-of-the-art centralized monocular C-SLAM systems. We open-source our code and provide supplementary material online.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Benchmarking of Reasoning Capabilities in Code Large Language Models Under Data Contamination</title>
<link>https://arxiv.org/abs/2503.04149</link>
<guid>https://arxiv.org/abs/2503.04149</guid>
<content:encoded><![CDATA[
<div> 关键词: code largelanguage models, benchmarking, data contamination, \tool, dynamic data generation

总结:
为了解决大型代码语言模型推理能力评估的需求与现有基准测试方法的局限性，文章提出了一个名为\tool的新颖基准测试套件。该套件着重于在潜在数据污染情况下对Code LLMs进行评价。鉴于当前基准测试依赖于公开的人工创建数据集，容易导致静态和数据污染问题，\tool通过多代理机制从种子编程问题中抽取并修改上下文，生成保持核心逻辑不变的语义等价变体，实现了动态数据生成。通过对两个种子数据集上的21个Code LLMs进行实证研究，结果表明\tool能够在确保评测的多样性和可靠性的同时，有效衡量推理能力在污染风险下的表现。 <div>
arXiv:2503.04149v1 Announce Type: new 
Abstract: The rapid evolution of code largelanguage models underscores the need for effective and transparent benchmarking of their reasoning capabilities. However, the current benchmarking approach heavily depends on publicly available, human-created datasets. The widespread use of these fixed benchmark datasets makes the benchmarking process to be static and thus particularly susceptible to data contamination, an unavoidable consequence of the extensive data collection processes used to train Code LLMs. Existing approaches that address data contamination often suffer from human effort limitations and imbalanced problem complexity. To tackle these challenges, we propose \tool, a novel benchmarking suite for evaluating Code LLMs under potential data contamination. Given a seed programming problem, \tool employs multiple agents to extract and modify the context without altering the core logic, generating semantically equivalent variations. We introduce a dynamic data generation methods and conduct empirical studies on two seed datasets across 21 Code LLMs. Results show that \tool effectively benchmarks reasoning capabilities under contamination risks while generating diverse problem sets to ensure consistent and reliable evaluations.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>KidneyTalk-open: No-code Deployment of a Private Large Language Model with Medical Documentation-Enhanced Knowledge Database for Kidney Disease</title>
<link>https://arxiv.org/abs/2503.04153</link>
<guid>https://arxiv.org/abs/2503.04153</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、医疗决策支持、肾病、大型语言模型、KidneyTalk-open

总结:
<br />
本文介绍了针对肾脏疾病隐私保护型医疗决策支持系统——KidneyTalk-open。该系统通过三个方面解决了现有方案面临的挑战：1) 实现无代码本地部署最先进的开源大型语言模型（如DeepSeek-r1和Qwen2.5）；2) 设计了一个结合上下文感知拆分和智能过滤的医学文档处理管道；3) 开发了适应性检索增强管道（AddRep），采用智能代理协作提高医学文献召回率。系统还配备图形化界面，使临床医生无需技术背景即可管理和进行AI辅助咨询。实验验证表明，AddRep在1,455个具有挑战性的肾内科问题上实现了29.1%的准确性（比基线提升8.1%），并保持了4.9%的拒绝率以抑制幻觉生成。与主流产品（AnythingLLM, Chatbox, GPT4ALL）的对比案例研究表明，KidneyTalk-open在真实临床查询中表现出优越性能。作为首个实现安全文档增强型医疗问答的桌面版无代码医疗LLM系统，KidneyTalk-open降低了技术门槛，增强了证据追溯能力，使得更多医务人员和患者能够便捷地使用最先进的开源LLMs。其设计为隐私敏感型临床AI应用树立了新的框架。 <div>
arXiv:2503.04153v1 Announce Type: new 
Abstract: Privacy-preserving medical decision support for kidney disease requires localized deployment of large language models (LLMs) while maintaining clinical reasoning capabilities. Current solutions face three challenges: 1) Cloud-based LLMs pose data security risks; 2) Local model deployment demands technical expertise; 3) General LLMs lack mechanisms to integrate medical knowledge. Retrieval-augmented systems also struggle with medical document processing and clinical usability. We developed KidneyTalk-open, a desktop system integrating three technical components: 1) No-code deployment of state-of-the-art (SOTA) open-source LLMs (such as DeepSeek-r1, Qwen2.5) via local inference engine; 2) Medical document processing pipeline combining context-aware chunking and intelligent filtering; 3) Adaptive Retrieval and Augmentation Pipeline (AddRep) employing agents collaboration for improving the recall rate of medical documents. A graphical interface was designed to enable clinicians to manage medical documents and conduct AI-powered consultations without technical expertise. Experimental validation on 1,455 challenging nephrology exam questions demonstrates AddRep's effectiveness: achieving 29.1% accuracy (+8.1% over baseline) with intelligent knowledge integration, while maintaining robustness through 4.9% rejection rate to suppress hallucinations. Comparative case studies with the mainstream products (AnythingLLM, Chatbox, GPT4ALL) demonstrate KidneyTalk-open's superior performance in real clinical query. KidneyTalk-open represents the first no-code medical LLM system enabling secure documentation-enhanced medical Q&amp;A on desktop. Its designs establishes a new framework for privacy-sensitive clinical AI applications. The system significantly lowers technical barriers while improving evidence traceability, enabling more medical staff or patients to use SOTA open-source LLMs conveniently.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Intelligent Transportation with Pedestrians and Vehicles In-the-Loop: A Surveillance Video-Assisted Federated Digital Twin Framework</title>
<link>https://arxiv.org/abs/2503.04170</link>
<guid>https://arxiv.org/abs/2503.04170</guid>
<content:encoded><![CDATA[
<div> 关键词: 智能交通系统、数字孪生、行人车辆交互、监控视频、联邦数字孪生框架

总结:<br />
本文提出了一种基于监控视频的联邦数字孪生(SVFDT)框架，用于增强智能交通系统中行人和车辆的实时互动模拟。该框架包括三个层次：末端层负责收集多元化的交通监控视频；边缘层则进行语义分割式的视觉理解、双Agent交互建模及局部数字孪生系统的创建；云层将不同区域的局部数字孪生系统实时整合构建全局DT模型。文章分析了关键设计需求与挑战，并给出了实施SVFDT系统的核心指导原则。通过测试床评估，证实了SVFDT在优化交通管理方面的有效性，相比传统终端服务器框架，其在镜像延迟、识别精度以及主观评价等方面具有优势。最后，文中指出了若干开放性挑战并探讨了未来的研究方向。 <div>
arXiv:2503.04170v1 Announce Type: new 
Abstract: In intelligent transportation systems (ITSs), incorporating pedestrians and vehicles in-the-loop is crucial for developing realistic and safe traffic management solutions. However, there is falls short of simulating complex real-world ITS scenarios, primarily due to the lack of a digital twin implementation framework for characterizing interactions between pedestrians and vehicles at different locations in different traffic environments. In this article, we propose a surveillance video assisted federated digital twin (SV-FDT) framework to empower ITSs with pedestrians and vehicles in-the-loop. Specifically, SVFDT builds comprehensive pedestrian-vehicle interaction models by leveraging multi-source traffic surveillance videos. Its architecture consists of three layers: (i) the end layer, which collects traffic surveillance videos from multiple sources; (ii) the edge layer, responsible for semantic segmentation-based visual understanding, twin agent-based interaction modeling, and local digital twin system (LDTS) creation in local regions; and (iii) the cloud layer, which integrates LDTSs across different regions to construct a global DT model in realtime. We analyze key design requirements and challenges and present core guidelines for SVFDT's system implementation. A testbed evaluation demonstrates its effectiveness in optimizing traffic management. Comparisons with traditional terminal-server frameworks highlight SV-FDT's advantages in mirroring delays, recognition accuracy, and subjective evaluation. Finally, we identify some open challenges and discuss future research directions.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Measuring temporal effects of agent knowledge by date-controlled tool use</title>
<link>https://arxiv.org/abs/2503.04188</link>
<guid>https://arxiv.org/abs/2503.04188</guid>
<content:encoded><![CDATA[
<div> 关键词：Temporal progression、Knowledge variability、Large language model (LLM)、Date-controlled tools (DCTs)、Web search

总结:<br />
该文针对知识积累和更新中的时间进程问题，提出了一种基于工具的离样本测试框架，用于衡量来自不同日期控制工具(DCTs)的大型语言模型(LLM)代理的知识变异性。文章通过实验展示了LLM作为写作助手利用网络搜索帮助完成科学出版物摘要时的时间效应。研究发现，搜索引擎的时间效应会导致工具依赖性的代理性能差异，但这一影响可以通过选择基础模型以及使用如chain-of-thought提示等明确推理指令得到缓解。因此，文章认为应当从动态视角对智能体进行评估，并考虑到工具的时间影响及外部资源的更新情况。 <div>
arXiv:2503.04188v1 Announce Type: new 
Abstract: Temporal progression is an integral part of knowledge accumulation and update. Web search is frequently adopted as grounding for agent knowledge, yet its inappropriate configuration affects the quality of agent responses. Here, we construct a tool-based out-of-sample testing framework to measure the knowledge variability of large language model (LLM) agents from distinct date-controlled tools (DCTs). We demonstrate the temporal effects of an LLM agent as a writing assistant, which can use web search to help complete scientific publication abstracts. We show that temporal effects of the search engine translates into tool-dependent agent performance but can be alleviated with base model choice and explicit reasoning instructions such as chain-of-thought prompting. Our results indicate that agent evaluation should take a dynamical view and account for the temporal influence of tools and the updates of external resources.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Multi-dimensional Elasticity for Pervasive Stream Processing Services</title>
<link>https://arxiv.org/abs/2503.04193</link>
<guid>https://arxiv.org/abs/2503.04193</guid>
<content:encoded><![CDATA[
<div> 关键词：边缘计算、服务质量、弹性伸缩、多维度、自动扩展

总结:
本文提出了一种针对流媒体服务在质量和资源维度上实现层次化扩展的解决方案。该方案着重于解决依赖于持续处理物联网数据以提供实时服务并满足应用目标（服务水平目标——SLOs）的现代场景，如智慧城市。由于倾向于在附近的边缘设备上处理数据，这可能会导致资源瓶颈，因为资源的供应量有限。为了提高边缘环境中的弹性，提议从两个层面进行服务扩展：(1) 本地、服务特定的代理通过多维度弹性策略确保SLO的履行，当无法再分配更多资源时，(2) 更高层次的代理会优化全局SLO履行，通过交换资源来进行调整。实验结果显示了这种方法具有积极的效果，与常规垂直自动扩展器相比，在资源紧张的情况下表现更优。 <div>
arXiv:2503.04193v1 Announce Type: new 
Abstract: This paper proposes a hierarchical solution to scale streaming services across quality and resource dimensions. Modern scenarios, like smart cities, heavily rely on the continuous processing of IoT data to provide real-time services and meet application targets (Service Level Objectives -- SLOs). While the tendency is to process data at nearby Edge devices, this creates a bottleneck because resources can only be provisioned up to a limited capacity. To improve elasticity in Edge environments, we propose to scale services in multiple dimensions -- either resources or, alternatively, the service quality. We rely on a two-layer architecture where (1) local, service-specific agents ensure SLO fulfillment through multi-dimensional elasticity strategies; if no more resources can be allocated, (2) a higher-level agent optimizes global SLO fulfillment by swapping resources. The experimental results show promising outcomes, outperforming regular vertical autoscalers, when operating under tight resource constraints.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computational Intractability of Strategizing against Online Learners</title>
<link>https://arxiv.org/abs/2503.04202</link>
<guid>https://arxiv.org/abs/2503.04202</guid>
<content:encoded><![CDATA[
<div> 关键词：在线学习算法、多代理环境、优化策略、计算复杂性、Multiplicative Weights Update (MWU)

总结:
本文研究了在线学习算法在多代理环境中的应用，特别是在重复拍卖、合同设计和定价竞争等战略场景下。文章提出了一个重要的计算困难性结果：除非$\mathsf{P} = \mathsf{NP}$，否则不存在一个能在多项式时间内为优化者计算接近最优策略的方法来对抗使用标准无遗憾算法（如Multiplicative Weights Update, MWU）的学习者。这一结果强化了先前的工作，不仅将硬度界限从常数级别的加法不可能性提升到$Ω(T)$级别，而且证明了对于广泛使用的无遗憾学习算法存在困难性，从而在一般博弈论环境中确立了一个基本的计算障碍。 <div>
arXiv:2503.04202v1 Announce Type: new 
Abstract: Online learning algorithms are widely used in strategic multi-agent settings, including repeated auctions, contract design, and pricing competitions, where agents adapt their strategies over time. A key question in such environments is how an optimizing agent can best respond to a learning agent to improve its own long-term outcomes. While prior work has developed efficient algorithms for the optimizer in special cases - such as structured auction settings or contract design - no general efficient algorithm is known.
  In this paper, we establish a strong computational hardness result: unless $\mathsf{P} = \mathsf{NP}$, no polynomial-time optimizer can compute a near-optimal strategy against a learner using a standard no-regret algorithm, specifically Multiplicative Weights Update (MWU). Our result proves an $\Omega(T)$ hardness bound, significantly strengthening previous work that only showed an additive $\Theta(1)$ impossibility result. Furthermore, while the prior hardness result focused on learners using fictitious play - an algorithm that is not no-regret - we prove intractability for a widely used no-regret learning algorithm. This establishes a fundamental computational barrier to finding optimal strategies in general game-theoretic settings.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantum-Inspired Reinforcement Learning in the Presence of Epistemic Ambivalence</title>
<link>https://arxiv.org/abs/2503.04219</link>
<guid>https://arxiv.org/abs/2503.04219</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线决策、不确定性、epistemic ambivalence (认知矛盾)、Markov决策过程(MDP)、量子测量

<br /><br />总结:
本文提出了一个针对在线决策中认知矛盾不确定性问题的新框架——认知矛盾Markov决策过程(EA-MDP)。该框架利用量子力学中的量子状态概念，通过量子测量技术计算奖励函数，并证明了EA-MDP存在最优策略和最优价值函数。此外，文章还提出了一种名为EA-epsilon-greedy Q-learning的学习算法。为了验证认知矛盾对决策过程的影响以及该框架的有效性，研究者通过两个实验设置（两态问题和格子问题）进行了分析，结果显示使用提出的EA-MDP方法，代理能够在全球存在认知矛盾的情况下收敛至最优策略。 <div>
arXiv:2503.04219v1 Announce Type: new 
Abstract: The complexity of online decision-making under uncertainty stems from the requirement of finding a balance between exploiting known strategies and exploring new possibilities. Naturally, the uncertainty type plays a crucial role in developing decision-making strategies that manage complexity effectively. In this paper, we focus on a specific form of uncertainty known as epistemic ambivalence (EA), which emerges from conflicting pieces of evidence or contradictory experiences. It creates a delicate interplay between uncertainty and confidence, distinguishing it from epistemic uncertainty that typically diminishes with new information. Indeed, ambivalence can persist even after additional knowledge is acquired. To address this phenomenon, we propose a novel framework, called the epistemically ambivalent Markov decision process (EA-MDP), aiming to understand and control EA in decision-making processes. This framework incorporates the concept of a quantum state from the quantum mechanics formalism, and its core is to assess the probability and reward of every possible outcome. We calculate the reward function using quantum measurement techniques and prove the existence of an optimal policy and an optimal value function in the EA-MDP framework. We also propose the EA-epsilon-greedy Q-learning algorithm. To evaluate the impact of EA on decision-making and the expedience of our framework, we study two distinct experimental setups, namely the two-state problem and the lattice problem. Our results show that using our methods, the agent converges to the optimal policy in the presence of EA.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Knowledge Retention for Continual Model-Based Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.04256</link>
<guid>https://arxiv.org/abs/2503.04256</guid>
<content:encoded><![CDATA[
<div> 关键词：DRAGO、模型驱动强化学习、持续学习、合成经验复习、重获记忆探索

总结:<br />
本文提出了一种名为DRAGO的新颖方法，用于持续模型驱动的强化学习，旨在改善在具有不同奖励函数但状态空间和动力学保持不变的任务序列中的世界模型递增开发。DRAGO包含两个关键组件：一是使用生成模型创建来自过去任务的合成经验进行复习，使代理能在不存储数据的情况下强化先前学习到的动力学；二是通过引入内在奖励机制“重获记忆探索”，引导代理重新访问先前任务中的相关状态。这两个组件相结合，使得代理能够维持一个全面且不断发展的世界模型，从而更有效地适应和学习多样化的环境。实验评估表明，DRAGO能够在任务之间保存知识，并在各种持续学习场景中展现出优越性能。 <div>
arXiv:2503.04256v1 Announce Type: new 
Abstract: We propose DRAGO, a novel approach for continual model-based reinforcement learning aimed at improving the incremental development of world models across a sequence of tasks that differ in their reward functions but not the state space or dynamics. DRAGO comprises two key components: Synthetic Experience Rehearsal, which leverages generative models to create synthetic experiences from past tasks, allowing the agent to reinforce previously learned dynamics without storing data, and Regaining Memories Through Exploration, which introduces an intrinsic reward mechanism to guide the agent toward revisiting relevant states from prior tasks. Together, these components enable the agent to maintain a comprehensive and continually developing world model, facilitating more effective learning and adaptation across diverse environments. Empirical evaluations demonstrate that DRAGO is able to preserve knowledge across tasks, achieving superior performance in various continual learning scenarios.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guidelines for Applying RL and MARL in Cybersecurity Applications</title>
<link>https://arxiv.org/abs/2503.04262</link>
<guid>https://arxiv.org/abs/2503.04262</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习(RL)，多智能体强化学习(MARL)，自动化网络安全防御(ACD)，算法ic方法，实施挑战

<br /><br />总结:

本文针对强化学习(RL)和多智能体强化学习(MARL)在自动化网络安全防御(ACD)领域的应用潜力进行了探讨。报告提出了一套结构化的评估指南，用于帮助网络安全专业人员和研究人员判断特定场景下RL和MARL的应用适宜性，考虑因素包括可解释性、探索需求以及多智能体协调的复杂性。此外，文章还讨论了关键的算法ic方法、实施过程中面临的挑战，如数据稀缺性和对抗性干扰等问题。同时，文中明确了未来研究方向，包括策略最优性、智能体合作水平及如何将MARL系统融入实际的网络安全操作框架中。通过连接理论进展与实践部署，这些指南旨在提升AI驱动的网络安全防御策略的有效性。 <div>
arXiv:2503.04262v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) and Multi-Agent Reinforcement Learning (MARL) have emerged as promising methodologies for addressing challenges in automated cyber defence (ACD). These techniques offer adaptive decision-making capabilities in high-dimensional, adversarial environments. This report provides a structured set of guidelines for cybersecurity professionals and researchers to assess the suitability of RL and MARL for specific use cases, considering factors such as explainability, exploration needs, and the complexity of multi-agent coordination. It also discusses key algorithmic approaches, implementation challenges, and real-world constraints, such as data scarcity and adversarial interference. The report further outlines open research questions, including policy optimality, agent cooperation levels, and the integration of MARL systems into operational cybersecurity frameworks. By bridging theoretical advancements and practical deployment, these guidelines aim to enhance the effectiveness of AI-driven cyber defence strategies.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Autonomous Reinforcement Learning for Real-World Robotic Manipulation with Large Language Models</title>
<link>https://arxiv.org/abs/2503.04280</link>
<guid>https://arxiv.org/abs/2503.04280</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Visual Language Models (VLMs)，Reinforcement Learning (RL)，Autonomous Reinforcement learning for Complex Human-Informed Environments (ARCHIE)，GPT-4

总结:

本文提出了一种名为ARCHIE的新方法，该方法利用预训练的大规模语言模型GPT-4自动生成复杂人类指导环境中的奖励函数，以解决强化学习中设计有效奖励函数的挑战。通过将生成的奖励函数应用于模拟环境中训练RL代理，文章着重于将自然语言任务描述直接转化为可执行的机器人技能。此外，GPT-4还自动化了任务成功标准的编码过程，实现了从人类可读文本到可部署机器人技能的一次性全自动转换。实验验证了该方法的有效性和实用性，使用ABB YuMi协作机器人在单臂和双臂操作任务的模拟环境中进行了广泛测试，并在真实机器人设置上进行了演示。 <div>
arXiv:2503.04280v1 Announce Type: new 
Abstract: Recent advancements in Large Language Models (LLMs) and Visual Language Models (VLMs) have significantly impacted robotics, enabling high-level semantic motion planning applications. Reinforcement Learning (RL), a complementary paradigm, enables agents to autonomously optimize complex behaviors through interaction and reward signals. However, designing effective reward functions for RL remains challenging, especially in real-world tasks where sparse rewards are insufficient and dense rewards require elaborate design. In this work, we propose Autonomous Reinforcement learning for Complex HumanInformed Environments (ARCHIE), an unsupervised pipeline leveraging GPT-4, a pre-trained LLM, to generate reward functions directly from natural language task descriptions. The rewards are used to train RL agents in simulated environments, where we formalize the reward generation process to enhance feasibility. Additionally, GPT-4 automates the coding of task success criteria, creating a fully automated, one-shot procedure for translating human-readable text into deployable robot skills. Our approach is validated through extensive simulated experiments on single-arm and bi-manual manipulation tasks using an ABB YuMi collaborative robot, highlighting its practicality and effectiveness. Tasks are demonstrated on the real robot setup.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shaken, Not Stirred: A Novel Dataset for Visual Understanding of Glasses in Human-Robot Bartending Tasks</title>
<link>https://arxiv.org/abs/2503.04308</link>
<guid>https://arxiv.org/abs/2503.04308</guid>
<content:encoded><![CDATA[
<div> 关键词：rgbd传感器、自动标注、真实世界数据集、眼镜对象检测、人形机器人平台

总结:<br />
该文提出了一种使用RGB-D传感器获取真实世界数据的新方法，以减少人类努力并解决现有物体检测数据集中眼镜类别多样性不足的问题。研究中，他们设计了一个基于深度测量的自动化标签生成管道，并利用此方法创建了一个包含7850张图像的真实世界玻璃对象数据集，这些图像由五个不同摄像头在名为NICOL的人形机器人平台上采集。实验表明，基于该数据集训练的基线模型在性能上优于当前先进的开放词汇量物体检测方法。此外，他们还将该基线模型部署到NICOL平台上的具象化代理中，在一个机器人调酒场景中实现了81%的成功率。 <div>
arXiv:2503.04308v1 Announce Type: new 
Abstract: Datasets for object detection often do not account for enough variety of glasses, due to their transparent and reflective properties. Specifically, open-vocabulary object detectors, widely used in embodied robotic agents, fail to distinguish subclasses of glasses. This scientific gap poses an issue to robotic applications that suffer from accumulating errors between detection, planning, and action execution. The paper introduces a novel method for the acquisition of real-world data from RGB-D sensors that minimizes human effort. We propose an auto-labeling pipeline that generates labels for all the acquired frames based on the depth measurements. We provide a novel real-world glass object dataset that was collected on the Neuro-Inspired COLlaborator (NICOL), a humanoid robot platform. The data set consists of 7850 images recorded from five different cameras. We show that our trained baseline model outperforms state-of-the-art open-vocabulary approaches. In addition, we deploy our baseline model in an embodied agent approach to the NICOL platform, on which it achieves a success rate of 81% in a human-robot bartending scenario.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentSafe: Safeguarding Large Language Model-based Multi-agent Systems via Hierarchical Data Management</title>
<link>https://arxiv.org/abs/2503.04392</link>
<guid>https://arxiv.org/abs/2503.04392</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model, multi-agent systems, AgentSafe, ThreatSieve, HierarCache

总结:
<br />
本文介绍了一种针对基于大型语言模型的多智能体系统（multi-agent systems, MAS）的安全框架AgentSafe，该框架通过层次化信息管理和内存保护来增强系统的安全性。AgentSafe将信息分为不同的安全等级，限制未经授权的代理访问敏感数据。框架由两个组件构成：ThreatSieve用于确保通信安全，验证信息权限并防止伪装；HierarCache则是一个自适应内存管理系统，可防御未经授权的访问和恶意数据中毒，它是首个针对智能体内存的系统性防御机制。实验表明，在对抗性条件下，AgentSafe显著提高了系统的抗风险能力，防御成功率超过80%。同时，随着智能体数量和信息复杂性的增长，AgentSafe仍能保持稳健的性能，显示出良好的可扩展性。这些结果强调了AgentSafe在保障多智能体系统安全及其在实际应用中的潜力。 <div>
arXiv:2503.04392v1 Announce Type: new 
Abstract: Large Language Model based multi-agent systems are revolutionizing autonomous communication and collaboration, yet they remain vulnerable to security threats like unauthorized access and data breaches. To address this, we introduce AgentSafe, a novel framework that enhances MAS security through hierarchical information management and memory protection. AgentSafe classifies information by security levels, restricting sensitive data access to authorized agents. AgentSafe incorporates two components: ThreatSieve, which secures communication by verifying information authority and preventing impersonation, and HierarCache, an adaptive memory management system that defends against unauthorized access and malicious poisoning, representing the first systematic defense for agent memory. Experiments across various LLMs show that AgentSafe significantly boosts system resilience, achieving defense success rates above 80% under adversarial conditions. Additionally, AgentSafe demonstrates scalability, maintaining robust performance as agent numbers and information complexity grow. Results underscore effectiveness of AgentSafe in securing MAS and its potential for real-world application.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Transformer-based World Models with Contrastive Predictive Coding</title>
<link>https://arxiv.org/abs/2503.04416</link>
<guid>https://arxiv.org/abs/2503.04416</guid>
<content:encoded><![CDATA[
<div> 关键词: DreamerV3、Transformer、模型基强化学习、对比预测编码、TWISTER

<br />
总结:
本工作关注于基于Transformer的世界模型在强化学习中的应用。针对以往使用Transformer替换RNN构建世界模型的方法虽提高了训练效率，但性能提升有限的问题，文章指出现有方法采用的下一状态预测目标不足以充分利用Transformer的表示能力。为此，文中提出了一个新的算法TWISTER（基于对比预测编码的Transformer世界模型），该算法通过引入动作条件化的对比预测编码来学习高层次的时间特征表示，从而提升了智能体的表现。实验结果显示，TWISTER在Atari 100k基准测试中达到了人类标准化均分的162%，创造了不使用look-ahead搜索的最新记录，超过了现有的先进方法。 <div>
arXiv:2503.04416v1 Announce Type: new 
Abstract: The DreamerV3 algorithm recently obtained remarkable performance across diverse environment domains by learning an accurate world model based on Recurrent Neural Networks (RNNs). Following the success of model-based reinforcement learning algorithms and the rapid adoption of the Transformer architecture for its superior training efficiency and favorable scaling properties, recent works such as STORM have proposed replacing RNN-based world models with Transformer-based world models using masked self-attention. However, despite the improved training efficiency of these methods, their impact on performance remains limited compared to the Dreamer algorithm, struggling to learn competitive Transformer-based world models. In this work, we show that the next state prediction objective adopted in previous approaches is insufficient to fully exploit the representation capabilities of Transformers. We propose to extend world model predictions to longer time horizons by introducing TWISTER (Transformer-based World model wIth contraSTivE Representations), a world model using action-conditioned Contrastive Predictive Coding to learn high-level temporal feature representations and improve the agent performance. TWISTER achieves a human-normalized mean score of 162% on the Atari 100k benchmark, setting a new record among state-of-the-art methods that do not employ look-ahead search.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Idea to CAD: A Language Model-Driven Multi-Agent System for Collaborative Design</title>
<link>https://arxiv.org/abs/2503.04417</link>
<guid>https://arxiv.org/abs/2503.04417</guid>
<content:encoded><![CDATA[
<div> 关键词：Computer Aided Design (CAD)，Vision Language Model (VLM)，Multi Agent System，parametric CAD，3D打印

总结:<br />
本文介绍了一种使用基于Vision Language Model (VLM)的多智能体系统自动化创建数字模型的方法，该方法针对工业产品开发中的计算机辅助设计（CAD）流程。系统由负责需求工程、CAD工程和基于视觉的质量保证的智能体组成，能够根据草图或文本描述自动生成模型。用户可在迭代验证过程中与系统协作细化模型，从而提高设计效率，不仅适用于行业专家，也对爱好者的3D打印建模活动有所帮助。文章通过展示各种设计任务的例子及提供一些消融实验，证实了该架构潜在的优势和各组件的价值。 <div>
arXiv:2503.04417v1 Announce Type: new 
Abstract: Creating digital models using Computer Aided Design (CAD) is a process that requires in-depth expertise. In industrial product development, this process typically involves entire teams of engineers, spanning requirements engineering, CAD itself, and quality assurance. We present an approach that mirrors this team structure with a Vision Language Model (VLM)-based Multi Agent System, with access to parametric CAD tooling and tool documentation. Combining agents for requirements engineering, CAD engineering, and vision-based quality assurance, a model is generated automatically from sketches and/ or textual descriptions. The resulting model can be refined collaboratively in an iterative validation loop with the user. Our approach has the potential to increase the effectiveness of design processes, both for industry experts and for hobbyists who create models for 3D printing. We demonstrate the potential of the architecture at the example of various design tasks and provide several ablations that show the benefits of the architecture's individual components.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ToolFuzz -- Automated Agent Tool Testing</title>
<link>https://arxiv.org/abs/2503.04479</link>
<guid>https://arxiv.org/abs/2503.04479</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、工具文档、自动化测试、ToolFuzz、错误检测

总结:
本文提出了一个名为ToolFuzz的新方法，用于自动测试大型语言模型（LLM）代理使用的工具文档的完整性和准确性。由于现有的软件测试方法难以发现自然语言表述的工具文档错误，ToolFuzz旨在发现两种类型的错误：导致工具运行时错误的用户查询和导致代理人响应不正确的用户查询。该方法能生成大量多样的自然语言输入，以低假阳性率有效地找出工具描述错误。文章还介绍了两种简单的prompt工程化方法，并在32种常用LangChain工具、35种定制新工具及两个新基准上对三种工具测试方法进行了评估。结果表明，许多公开可用的工具存在欠规范问题，ToolFuzz相比于提示工程化方法能识别到约20倍更多的错误输入，成为构建可靠AI代理的关键组件。 <div>
arXiv:2503.04479v1 Announce Type: new 
Abstract: Large Language Model (LLM) Agents leverage the advanced reasoning capabilities of LLMs in real-world applications. To interface with an environment, these agents often rely on tools, such as web search or database APIs. As the agent provides the LLM with tool documentation along the user query, the completeness and correctness of this documentation is critical. However, tool documentation is often over-, under-, or ill-specified, impeding the agent's accuracy. Standard software testing approaches struggle to identify these errors as they are expressed in natural language. Thus, despite its importance, there currently exists no automated method to test the tool documentation for agents. To address this issue, we present ToolFuzz, the first method for automated testing of tool documentations. ToolFuzz is designed to discover two types of errors: (1) user queries leading to tool runtime errors and (2) user queries that lead to incorrect agent responses. ToolFuzz can generate a large and diverse set of natural inputs, effectively finding tool description errors at a low false positive rate. Further, we present two straightforward prompt-engineering approaches. We evaluate all three tool testing approaches on 32 common LangChain tools and 35 newly created custom tools and 2 novel benchmarks to further strengthen the assessment. We find that many publicly available tools suffer from underspecification. Specifically, we show that ToolFuzz identifies 20x more erroneous inputs compared to the prompt-engineering approaches, making it a key component for building reliable AI agents.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Advancing Solutions for the Three-Body Problem Through Physics-Informed Neural Networks</title>
<link>https://arxiv.org/abs/2503.04585</link>
<guid>https://arxiv.org/abs/2503.04585</guid>
<content:encoded><![CDATA[
<div> 关键词：Three-Body Problem，牛顿万有引力定律，Physics-Informed Neural Networks (PINNs)，机器学习，数值积分器

总结:
本文提出了利用Physics-Informed Neural Networks (PINNs)解决三体问题的新方法。三体问题是描述三个质点在牛顿万有引力作用下的运动预测问题，尽管历经数世纪的研究，但因其混沌特性，至今仍未找到普遍的封闭形式解。现有的解决方案主要依赖于高精度数值积分和基于机器学习的方法。然而，这些方法并未充分利用我们对混沌系统已有的知识。文章指出，PINNs能够将可表达为常微分方程的先验系统知识融入其学习过程中作为正则化代理，从而在保持与现有机器学习方法相当的预测质量的同时，超越了它们。此外，由于数值积分器的计算成本高昂，PINNs在时间和效率上具有显著优势，证实了PINNs是一种有效且高效地求解三体问题的开放形式解法，充分运用了我们对于经典力学的知识。 <div>
arXiv:2503.04585v1 Announce Type: new 
Abstract: First formulated by Sir Isaac Newton in his work "Philosophiae Naturalis Principia Mathematica", the concept of the Three-Body Problem was put forth as a study of the motion of the three celestial bodies within the Earth-Sun-Moon system. In a generalized definition, it seeks to predict the motion for an isolated system composed of three point masses freely interacting under Newton's law of universal attraction. This proves to be analogous to a multitude of interactions between celestial bodies, and thus, the problem finds applicability within the studies of celestial mechanics. Despite numerous attempts by renowned physicists to solve it throughout the last three centuries, no general closed-form solutions have been reached due to its inherently chaotic nature for most initial conditions. Current state-of-the-art solutions are based on two approaches, either numerical high-precision integration or machine learning-based. Notwithstanding the breakthroughs of neural networks, these present a significant limitation, which is their ignorance of any prior knowledge of the chaotic systems presented. Thus, in this work, we propose a novel method that utilizes Physics-Informed Neural Networks (PINNs). These deep neural networks are able to incorporate any prior system knowledge expressible as an Ordinary Differential Equation (ODE) into their learning processes as a regularizing agent. Our findings showcase that PINNs surpass current state-of-the-art machine learning methods with comparable prediction quality. Despite a better prediction quality, the usability of numerical integrators suffers due to their prohibitively high computational cost. These findings confirm that PINNs are both effective and time-efficient open-form solvers of the Three-Body Problem that capitalize on the extensive knowledge we hold of classical mechanics.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Next Frontier of LLM Applications: Open Ecosystems and Hardware Synergy</title>
<link>https://arxiv.org/abs/2503.04596</link>
<guid>https://arxiv.org/abs/2503.04596</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLM)，应用程序，接口标准化，硬件-software协同设计，安全与隐私

<br /><br />总结:
本文关注了大型语言模型（LLM）应用的发展及其面临的挑战，包括平台孤岛、硬件集成碎片化以及缺乏标准化接口等问题。文章提出了一个基于软件工程原则的三层解耦架构，该架构通过分离应用逻辑、通信协议和硬件执行来提升模块化、效率和跨平台兼容性。同时，文中强调了安全和隐私问题对于AI安全、可扩展部署的重要性，并指出了软件与安全工程方面的研究方向。整体目标是推动构建开放、安全、互操作的LLM生态系统，为未来AI应用的发展提供指导。 <div>
arXiv:2503.04596v1 Announce Type: new 
Abstract: Large Language Model (LLM) applications, including LLM app stores and autonomous agents, are shaping the future of AI ecosystems. However, platform silos, fragmented hardware integration, and the absence of standardized interfaces limit scalability, interoperability, and resource efficiency. While LLM app stores democratize AI, their closed ecosystems restrict modular AI reuse and cross-platform portability. Meanwhile, agent-based frameworks offer flexibility but often lack seamless integration across diverse environments. This paper envisions the future of LLM applications and proposes a three-layer decoupled architecture grounded in software engineering principles such as layered system design, service-oriented architectures, and hardware-software co-design. This architecture separates application logic, communication protocols, and hardware execution, enhancing modularity, efficiency, and cross-platform compatibility. Beyond architecture, we highlight key security and privacy challenges for safe, scalable AI deployment and outline research directions in software and security engineering. This vision aims to foster open, secure, and interoperable LLM ecosystems, guiding future advancements in AI applications.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SurveyForge: On the Outline Heuristics, Memory-Driven Generation, and Multi-dimensional Evaluation for Automated Survey Writing</title>
<link>https://arxiv.org/abs/2503.04629</link>
<guid>https://arxiv.org/abs/2503.04629</guid>
<content:encoded><![CDATA[
<div> 关键词: SurveyForge、LLMs、自动调查生成、SurveyBench、AutoSurvey

总结:
SurveyForge 是一项新提出的用于自动化生成高质量调查论文的技术。为缩小与人类编写的调查论文在大纲质量和引用准确性上的差距，SurveyForge 首先通过分析人类编写的提纲逻辑结构和参考相关领域的文章来生成提纲。随后，它利用其学者导航代理从记忆中检索到的高质量论文，自动生成并细化生成的文章内容。为了进行全面评估，研究者构建了包含100篇人类编写的调查论文的SurveyBench，用于赢率比较，并从参考文献、大纲和内容质量三个方面评价AI生成的调查论文。实验表明，SurveyForge 相比先前的工作如 AutoSurvey 表现出更优的性能。 <div>
arXiv:2503.04629v1 Announce Type: new 
Abstract: Survey paper plays a crucial role in scientific research, especially given the rapid growth of research publications. Recently, researchers have begun using LLMs to automate survey generation for better efficiency. However, the quality gap between LLM-generated surveys and those written by human remains significant, particularly in terms of outline quality and citation accuracy. To close these gaps, we introduce SurveyForge, which first generates the outline by analyzing the logical structure of human-written outlines and referring to the retrieved domain-related articles. Subsequently, leveraging high-quality papers retrieved from memory by our scholar navigation agent, SurveyForge can automatically generate and refine the content of the generated article. Moreover, to achieve a comprehensive evaluation, we construct SurveyBench, which includes 100 human-written survey papers for win-rate comparison and assesses AI-generated survey papers across three dimensions: reference, outline, and content quality. Experiments demonstrate that SurveyForge can outperform previous works such as AutoSurvey.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Inverse Q-Learning from Demonstrations</title>
<link>https://arxiv.org/abs/2503.04679</link>
<guid>https://arxiv.org/abs/2503.04679</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习、逆强化学习、边际Q学习、演示学习、协同竞争

总结:

本文提出了一种针对多智能体强化学习中奖励函数设计问题的新框架——多智能体边缘Q学习从演示（MAMQL）。在多智能体环境中，由于环境非平稳性和多个智能体带来的额外变异性，传统的单智能体逆强化学习方法难以准确平衡合作与竞争目标。MAMQL为每个智能体学习基于其他智能体策略边缘化的批评函数，从而合理地在多智能体场景中应用玻尔兹曼策略。通过揭示最优边缘化批评函数与单智能体软Q逆强化学习之间的联系，MAMQL能够在多智能体一般性博弈中应用简单直接的优化准则。实验结果显示，在三个不同模拟领域中，MAMQL在平均奖励、样本效率和奖励恢复方面均显著优于先前的多智能体方法，性能提升通常超过2-5倍。项目代码已在https://sites.google.com/view/mamql 上公开可用。 <div>
arXiv:2503.04679v1 Announce Type: new 
Abstract: When reward functions are hand-designed, deep reinforcement learning algorithms often suffer from reward misspecification, causing them to learn suboptimal policies in terms of the intended task objectives. In the single-agent case, inverse reinforcement learning (IRL) techniques attempt to address this issue by inferring the reward function from expert demonstrations. However, in multi-agent problems, misalignment between the learned and true objectives is exacerbated due to increased environment non-stationarity and variance that scales with multiple agents. As such, in multi-agent general-sum games, multi-agent IRL algorithms have difficulty balancing cooperative and competitive objectives. To address these issues, we propose Multi-Agent Marginal Q-Learning from Demonstrations (MAMQL), a novel sample-efficient framework for multi-agent IRL. For each agent, MAMQL learns a critic marginalized over the other agents' policies, allowing for a well-motivated use of Boltzmann policies in the multi-agent context. We identify a connection between optimal marginalized critics and single-agent soft-Q IRL, allowing us to apply a direct, simple optimization criterion from the single-agent domain. Across our experiments on three different simulated domains, MAMQL significantly outperforms previous multi-agent methods in average reward, sample efficiency, and reward recovery by often more than 2-5x. We make our code available at https://sites.google.com/view/mamql .
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantifying the Reasoning Abilities of LLMs on Real-world Clinical Cases</title>
<link>https://arxiv.org/abs/2503.04691</link>
<guid>https://arxiv.org/abs/2503.04691</guid>
<content:encoded><![CDATA[
<div> 关键词: 医疗领域、推理增强型大语言模型、MedR-Bench、临床评估框架、Reasoning Evaluator

总结:
本文介绍了针对医疗领域的推理增强型大语言模型评测研究。科研人员构建了一个名为MedR-Bench的专业医学评价基准，包含了1,453份结构化的患者病例和从案例报告中挖掘出的推理参考信息，覆盖了13个身体系统和10种专业疾病。他们提出了一套包括评估推荐、诊断决策和治疗规划三个关键临床阶段的综合评价框架，并设计了一个称为Reasoning Evaluator的新颖自动量化评分系统，以效率、事实性和完整性三个方面动态搜索和交叉验证自由文本推理响应。通过评估五种最先进的推理LLM，如DeepSeek-R1和OpenAI-o3-mini，发现当前的LLM在处理简单的诊断任务时能取得超过85%的准确率，但面对复杂的评估推荐和治疗规划任务则表现挣扎。虽然它们的推理过程总体可靠，事实性得分超过90%，但在推理步骤上常常遗漏重要信息，指出了当前临床LLM需要进一步发展的方向。 <div>
arXiv:2503.04691v1 Announce Type: new 
Abstract: The latest reasoning-enhanced large language models (reasoning LLMs), such as DeepSeek-R1 and OpenAI-o3, have demonstrated remarkable success. However, the application of such reasoning enhancements to the highly professional medical domain has not been clearly evaluated, particularly regarding with not only assessing the final generation but also examining the quality of their reasoning processes. In this study, we present MedR-Bench, a reasoning-focused medical evaluation benchmark comprising 1,453 structured patient cases with reasoning references mined from case reports. Our benchmark spans 13 body systems and 10 specialty disorders, encompassing both common and rare diseases. In our evaluation, we introduce a versatile framework consisting of three critical clinical stages: assessment recommendation, diagnostic decision-making, and treatment planning, comprehensively capturing the LLMs' performance across the entire patient journey in healthcare. For metrics, we propose a novel agentic system, Reasoning Evaluator, designed to automate and objectively quantify free-text reasoning responses in a scalable manner from the perspectives of efficiency, factuality, and completeness by dynamically searching and performing cross-referencing checks. As a result, we assess five state-of-the-art reasoning LLMs, including DeepSeek-R1, OpenAI-o3-mini, and others. Our results reveal that current LLMs can handle relatively simple diagnostic tasks with sufficient critical assessment results, achieving accuracy generally over 85%. However, they still struggle with more complex tasks, such as assessment recommendation and treatment planning. In reasoning, their reasoning processes are generally reliable, with factuality scores exceeding 90%, though they often omit critical reasoning steps. Our study clearly reveals further development directions for current clinical LLMs.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Influence of Prior Discourse on Conversational Agent-Driven Decision-Making</title>
<link>https://arxiv.org/abs/2503.04692</link>
<guid>https://arxiv.org/abs/2503.04692</guid>
<content:encoded><![CDATA[
<div> 关键词：persuasion, nudging, conversational agents, cognitive biases, decision-making

总结:
本文探讨了对话中的说服策略，重点关注采用“引导”(nudging)的会话代理系统。研究通过实验设计，分析了认知偏误（引导的心理机制）以及先前对话任务复杂性如何影响由会话代理人促成的决策制定。实验涉及756名参与者，随机分配到简单或复杂任务组后，再面对基于塞缪尔森关于现状偏误经典实验改编的三个决策场景。结果表明，在两个简单的任务场景中，研究结果与先前研究一致；而随着任务复杂性的增加，效应量持续朝向假设的方向变化，但只在一个案例中表现出显著的偏误。这些发现为会话引导策略提供了信息，并突显了行为经济学中的内在偏误问题。 <div>
arXiv:2503.04692v1 Announce Type: new 
Abstract: Persuasion through conversation has been the focus of much research. Nudging is a popular strategy to influence decision-making in physical and digital settings. However, conversational agents employing "nudging" have not received significant attention. We explore the manifestation of cognitive biases-the underlying psychological mechanisms of nudging-and investigate how the complexity of prior dialogue tasks impacts decision-making facilitated by conversational agents. Our research used a between-group experimental design, involving 756 participants randomly assigned to either a simple or complex task before encountering a decision-making scenario. Three scenarios were adapted from Samuelson's classic experiments on status-quo bias, the underlying mechanism of default nudges. Our results aligned with previous studies in two out of three simple-task scenarios. Increasing task complexity consistently shifted effect-sizes toward our hypothesis, though bias was significant in only one case. These findings inform conversational nudging strategies and highlight inherent biases relevant to behavioural economics.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Driven Distributed Optimization via Aggregative Tracking and Deep-Learning</title>
<link>https://arxiv.org/abs/2503.04668</link>
<guid>https://arxiv.org/abs/2503.04668</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式数据驱动优化、聚合框架、神经网络、学习部分、线性收敛

总结:
本文提出了一种新颖的分布式数据驱动优化方案，重点关注了聚合框架下的问题，即多个智能体合作最小化依赖本地决策变量及其全局聚合的局部成本函数之和。在考虑每个目标函数未知且只能在每次迭代中于单点进行采样的数据驱动设置下，该方案结合了三个关键组件：(1) 利用神经网络进行局部成本函数下降方向的学习；(2) 采用优化程序根据所学方向调整估计值以减小全局成本；(3) 设计了一个局部重构不可用全局量的跟踪机制。利用系统理论工具，如时间尺度分离和平均理论，文章形式上证明了在强凸设定下，整个分布式策略在接近最优解的邻域内实现线性收敛，其半径取决于神经网络给出的精度能力。最后，通过数值模拟验证了理论结果。<br /><br /> <div>
arXiv:2503.04668v1 Announce Type: cross 
Abstract: In this paper, we propose a novel distributed data-driven optimization scheme. In particular, we focus on the so-called aggregative framework, namely, the scenario in which a set of agents aim to cooperatively minimize the sum of local costs, each depending on both local decision variables and an aggregation of all of them. We consider a data-driven setup in which each objective function is unknown and can be only sampled at a single point per iteration (thanks to, e.g., feedback from human users or physical sensors). We address this scenario through a distributed algorithm that combines three key components: (i) a learning part that leverages neural networks to learn the local cost functions descent direction, (ii) an optimization routine that steers the estimates according to the learned direction to minimize the global cost, and (iii) a tracking mechanism that locally reconstructs the unavailable global quantities. By using tools from system theory, i.e., timescale separation and averaging theory, we formally prove that, in strongly convex setups, the overall distributed strategy linearly converges in a neighborhood of the optimal solution whose radius depends on the given accuracy capabilities of the neural networks. Finally, we corroborate the theoretical results with numerical simulations.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Controller Synthesis of Collaborative Signal Temporal Logic Tasks for Multi-Agent Systems via Assume-Guarantee Contracts</title>
<link>https://arxiv.org/abs/2309.13499</link>
<guid>https://arxiv.org/abs/2309.13499</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、信号temporal逻辑(STL)、控制器合成、连续时间assume-guarantee合同、分布式控制

<br /><br />总结:

本文研究了多智能体系统中，受动态耦合约束并需要协同完成任务的情况下，基于信号temporal逻辑(STL)规范的控制器综合问题。文章提出了一种基于连续时间假设-保障合同的组合框架，该框架能将大规模复杂的综合问题分解为可管理的小规模子问题。首先，利用漏斗控制思想将协同STL任务形式化为假设-保障合同。接着，运用合同概念建立了组合性结果，确保当所有智能体满足其局部合同时，整个多智能体系统能够满足全局合同。随后，设计了一个闭式连续时间反馈控制器，以分布式方式在各智能体上实现局部合同的执行，并依据组合性结果保证全局任务的满足。最后，通过两个数值示例展示了所提方法的有效性。 <div>
arXiv:2309.13499v2 Announce Type: replace 
Abstract: This paper considers the problem of controller synthesis of signal temporal logic (STL) specifications for large-scale multi-agent systems, where the agents are dynamically coupled and subject to collaborative tasks. A compositional framework based on continuous-time assume-guarantee contracts is developed to break the complex and large synthesis problem into subproblems of manageable sizes. We first show how to formulate the collaborative STL tasks as assume-guarantee contracts by leveraging the idea of funnel-based control. The concept of contracts is used to establish our compositionality result, which allows us to guarantee the satisfaction of a global contract by the multi-agent system when all agents satisfy their local contracts. Then, a closed-form continuous-time feedback controller is designed to enforce local contracts over the agents in a distributed manner, which further guarantees the global task satisfaction based on the compositionality result. Finally, the effectiveness of our results is demonstrated by two numerical examples.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DoraemonGPT: Toward Understanding Dynamic Scenes with Large Language Models (Exemplified as A Video Agent)</title>
<link>https://arxiv.org/abs/2401.08392</link>
<guid>https://arxiv.org/abs/2401.08392</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、动态场景理解、DoraemonGPT、视频代理、蒙特卡洛树搜索

总结:
本文提出了一个名为DoraemonGPT的系统，该系统利用LLMs驱动，旨在理解和处理动态场景，从而扩展了LLM在图像任务上的应用，使其能更好地适应如指导实验室实验和识别错误等现实应用场景。DoraemonGPT以视频代理的形式运行，通过将输入视频转化为结构化的符号记忆来存储与任务相关的属性，进而支持空间-时间查询和推理。针对特定领域（例如分析实验背后的科学原理）中LLMs内部知识的局限性，文章提出了一种可插拔工具来接入外部知识。此外，还引入了一个基于蒙特卡洛树搜索的新型LLM驱动规划器，用于探索大型规划空间并调度各种工具。该规划器通过反向传播结果的奖励值来迭代寻找可行解决方案，并能将多个解决方案汇总为更优的答案。DoraemonGPT在三个基准测试和若干实际场景下进行了广泛验证，并计划开源代码。 <div>
arXiv:2401.08392v4 Announce Type: replace 
Abstract: Recent LLM-driven visual agents mainly focus on solving image-based tasks, which limits their ability to understand dynamic scenes, making it far from real-life applications like guiding students in laboratory experiments and identifying their mistakes. Hence, this paper explores DoraemonGPT, a comprehensive and conceptually elegant system driven by LLMs to understand dynamic scenes. Considering the video modality better reflects the ever-changing nature of real-world scenarios, we exemplify DoraemonGPT as a video agent. Given a video with a question/task, DoraemonGPT begins by converting the input video into a symbolic memory that stores task-related attributes. This structured representation allows for spatial-temporal querying and reasoning by well-designed sub-task tools, resulting in concise intermediate results. Recognizing that LLMs have limited internal knowledge when it comes to specialized domains (e.g., analyzing the scientific principles underlying experiments), we incorporate plug-and-play tools to assess external knowledge and address tasks across different domains. Moreover, a novel LLM-driven planner based on Monte Carlo Tree Search is introduced to explore the large planning space for scheduling various tools. The planner iteratively finds feasible solutions by backpropagating the result's reward, and multiple solutions can be summarized into an improved final answer. We extensively evaluate DoraemonGPT's effectiveness on three benchmarks and several in-the-wild scenarios. The code will be released at https://github.com/z-x-yang/DoraemonGPT.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EgoExoLearn: A Dataset for Bridging Asynchronous Ego- and Exo-centric View of Procedural Activities in Real World</title>
<link>https://arxiv.org/abs/2403.16182</link>
<guid>https://arxiv.org/abs/2403.16182</guid>
<content:encoded><![CDATA[
<div> 关键词：EgoExoLearn、大规模数据集、人类示范跟随过程、多模态注解、跨视图行动桥接

总结:<br />
本文介绍了EgoExoLearn，这是一个模拟人类跟随示范过程的大规模数据集，重点研究了将他人的活动映射到自身视角的能力。EgoExoLearn包含了120小时日常生活场景和专业实验室中的第一人称视角和示范视频数据，同时记录了高质量的眼动数据并提供了详细的多模态注释。数据集旨在为理解和建模人类从不同视角同步程序性动作的能力提供一个平台，并提出了跨视图关联、跨视图动作规划和跨视图技能评估等基准测试。作者期望EgoExoLearn能成为桥接不同视角下行动的重要资源，从而推动创建能够无缝学习观察人类在现实世界中行为的人工智能代理。项目代码和数据可在https://github.com/OpenGVLab/EgoExoLearn获取。 <div>
arXiv:2403.16182v3 Announce Type: replace 
Abstract: Being able to map the activities of others into one's own point of view is one fundamental human skill even from a very early age. Taking a step toward understanding this human ability, we introduce EgoExoLearn, a large-scale dataset that emulates the human demonstration following process, in which individuals record egocentric videos as they execute tasks guided by demonstration videos. Focusing on the potential applications in daily assistance and professional support, EgoExoLearn contains egocentric and demonstration video data spanning 120 hours captured in daily life scenarios and specialized laboratories. Along with the videos we record high-quality gaze data and provide detailed multimodal annotations, formulating a playground for modeling the human ability to bridge asynchronous procedural actions from different viewpoints. To this end, we present benchmarks such as cross-view association, cross-view action planning, and cross-view referenced skill assessment, along with detailed analysis. We expect EgoExoLearn can serve as an important resource for bridging the actions across views, thus paving the way for creating AI agents capable of seamlessly learning by observing humans in the real world. Code and data can be found at: https://github.com/OpenGVLab/EgoExoLearn
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>360$^\circ$REA: Towards A Reusable Experience Accumulation with 360{\deg} Assessment for Multi-Agent System</title>
<link>https://arxiv.org/abs/2404.05569</link>
<guid>https://arxiv.org/abs/2404.05569</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、多智能体框架、自我评估、经验积累、360度评估

总结:
本文提出了一个名为“360$^\circ$可重用经验积累与评估”（360$^\circ$REA）的层次化多智能体框架，该框架受到企业组织实践启发。该框架采用了一种新颖的360度全方位性能评估方法，实现了从多个角度进行细粒度的评估。为了提升智能体解决复杂任务的能力，文章引入了双重经验池机制，允许智能体通过细粒度的评估来积累经验。通过在复杂任务数据集上的广泛实验，证明了360$^\circ$REA的有效性。 <div>
arXiv:2404.05569v3 Announce Type: replace 
Abstract: Large language model agents have demonstrated remarkable advancements across various complex tasks. Recent works focus on optimizing the agent team or employing self-reflection to iteratively solve complex tasks. Since these agents are all based on the same LLM, only conducting self-evaluation or removing underperforming agents does not substantively enhance the capability of the agents. We argue that a comprehensive evaluation and accumulating experience from evaluation feedback is an effective approach to improving system performance. In this paper, we propose Reusable Experience Accumulation with 360$^\circ$ Assessment (360$^\circ$REA), a hierarchical multi-agent framework inspired by corporate organizational practices. The framework employs a novel 360$^\circ$ performance assessment method for multi-perspective performance evaluation with fine-grained assessment. To enhance the capability of agents in addressing complex tasks, we introduce dual-level experience pool for agents to accumulate experience through fine-grained assessment. Extensive experiments on complex task datasets demonstrate the effectiveness of 360$^\circ$REA.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Detecting and Deterring Manipulation in a Cognitive Hierarchy</title>
<link>https://arxiv.org/abs/2405.01870</link>
<guid>https://arxiv.org/abs/2405.01870</guid>
<content:encoded><![CDATA[
<div> 关键词: $\aleph$-IPOMDP、对手建模、操纵、贝叶斯推理、人工智能安全

<br /><br />总结:
本文提出了一个名为$\aleph$-IPOMDP的计算框架，旨在解决有限嵌套对手模型的社会智能体容易受到深度推理和高级对手建模代理操纵的问题。该框架通过将贝叶斯推断与异常检测算法及信念外策略相结合，使智能体能够在被欺骗时有所察觉并能通过可信威胁进行威慑。实验结果显示，$\aleph$机制在混合动机和零和游戏场景中有效提高了公平性，减少了更复杂代理的利用行为。文章探讨了这一机制对人工智能安全、网络安全、认知科学以及精神病学等领域的影响。 <div>
arXiv:2405.01870v2 Announce Type: replace 
Abstract: Social agents with finitely nested opponent models are vulnerable to manipulation by agents with deeper reasoning and more sophisticated opponent modelling. This imbalance, rooted in logic and the theory of recursive modelling frameworks, cannot be solved directly. We propose a computational framework, $\aleph$-IPOMDP, augmenting model-based RL agents' Bayesian inference with an anomaly detection algorithm and an out-of-belief policy. Our mechanism allows agents to realize they are being deceived, even if they cannot understand how, and to deter opponents via a credible threat. We test this framework in both a mixed-motive and zero-sum game. Our results show the $\aleph$ mechanism's effectiveness, leading to more equitable outcomes and less exploitation by more sophisticated agents. We discuss implications for AI safety, cybersecurity, cognitive science, and psychiatry.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Generalizable Reinforcement Learning via Causality-Guided Self-Adaptive Representations</title>
<link>https://arxiv.org/abs/2407.20651</link>
<guid>https://arxiv.org/abs/2407.20651</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning), 通用智能 (General Intelligence), 环境变化 (Environment Changes), 因果表示学习 (Causal Representation Learning), 自适应表示 (Self-Adaptive Representation)

<br /><br />总结:
本文研究了强化学习在环境空间和分布均发生变化的任务泛化问题。针对这一挑战性设定，文章提出了一个基于因果引导的自适应表征方法，名为CSR（Causality-Guided Self-Adaptive Representation）。该方法利用因果表示学习来刻画RL系统中的潜在因果变量，揭示变量间的结构关系，使代理能自主判断环境变化源于分布漂移还是空间变化，并精确识别这些变化。接着，文章设计了一个三步策略，根据不同场景对因果模型进行微调。实验证明，CSR能在目标领域仅使用少量样本的情况下高效适应并优于现有主流基线方法，在包括模拟环境、CartPole、CoinRun以及Atari游戏等广泛场景中展现出优越性能。 <div>
arXiv:2407.20651v4 Announce Type: replace 
Abstract: General intelligence requires quick adaption across tasks. While existing reinforcement learning (RL) methods have made progress in generalization, they typically assume only distribution changes between source and target domains. In this paper, we explore a wider range of scenarios where not only the distribution but also the environment spaces may change. For example, in the CoinRun environment, we train agents from easy levels and generalize them to difficulty levels where there could be new enemies that have never occurred before. To address this challenging setting, we introduce a causality-guided self-adaptive representation-based approach, called CSR, that equips the agent to generalize effectively across tasks with evolving dynamics. Specifically, we employ causal representation learning to characterize the latent causal variables within the RL system. Such compact causal representations uncover the structural relationships among variables, enabling the agent to autonomously determine whether changes in the environment stem from distribution shifts or variations in space, and to precisely locate these changes. We then devise a three-step strategy to fine-tune the causal model under different scenarios accordingly. Empirical experiments show that CSR efficiently adapts to the target domains with only a few samples and outperforms state-of-the-art baselines on a wide range of scenarios, including our simulated environments, CartPole, CoinRun and Atari games.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DexMimicGen: Automated Data Generation for Bimanual Dexterous Manipulation via Imitation Learning</title>
<link>https://arxiv.org/abs/2410.24185</link>
<guid>https://arxiv.org/abs/2410.24185</guid>
<content:encoded><![CDATA[
<div> 关键词：imitation learning、humanoid robots、bimanual dexterous manipulation、data generation、DexMimicGen

总结:
本文介绍了DexMimicGen，这是一个大规模自动数据生成系统，用于为具有灵巧双手的人形机器人从少量人类示范中合成轨迹。该系统聚焦于双臂灵巧操作的模拟环境，涵盖了多种操纵行为和对双臂协调的不同要求。通过仅使用60个人类演示，DexMimicGen生成了涵盖21K个示例的数据集，并研究了数据生成和策略学习决策对机器人性能的影响。此外，文章还提出了一个从真实世界到模拟再到真实世界的部署管道，并将其应用于实际的人形机器人罐子分类任务。相关生成数据集、模拟环境及附加结果可在项目网站https://dexmimicgen.github.io/上获取。 <div>
arXiv:2410.24185v2 Announce Type: replace 
Abstract: Imitation learning from human demonstrations is an effective means to teach robots manipulation skills. But data acquisition is a major bottleneck in applying this paradigm more broadly, due to the amount of cost and human effort involved. There has been significant interest in imitation learning for bimanual dexterous robots, like humanoids. Unfortunately, data collection is even more challenging here due to the challenges of simultaneously controlling multiple arms and multi-fingered hands. Automated data generation in simulation is a compelling, scalable alternative to fuel this need for data. To this end, we introduce DexMimicGen, a large-scale automated data generation system that synthesizes trajectories from a handful of human demonstrations for humanoid robots with dexterous hands. We present a collection of simulation environments in the setting of bimanual dexterous manipulation, spanning a range of manipulation behaviors and different requirements for coordination among the two arms. We generate 21K demos across these tasks from just 60 source human demos and study the effect of several data generation and policy learning decisions on agent performance. Finally, we present a real-to-sim-to-real pipeline and deploy it on a real-world humanoid can sorting task. Generated datasets, simulation environments and additional results are at https://dexmimicgen.github.io/
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration</title>
<link>https://arxiv.org/abs/2411.00053</link>
<guid>https://arxiv.org/abs/2411.00053</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、迭代对话、协同行为、Actor-Critic学习框架、ACC-Collab

<br /><br />总结:
本文提出了一个名为ACC-Collab的基于Actor-Critic的新型学习框架，旨在通过专门训练实现两个AI代理之间的有效协作，从而增强大型语言模型的任务执行能力。现有的多代理框架通常将协作视为模型固有的涌现行为，而ACC-Collab则针对这一局限性，设计了一个由演员代理和评论家代理组成的双 agent 团队，使其能更好地进行协作。实验结果显示，ACC-Collab 在一系列基准测试中超越了当前最先进的多代理技术。 <div>
arXiv:2411.00053v3 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models. While these paradigms show promise in improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Collab, an Actor-Critic based learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration. We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Watson: A Cognitive Observability Framework for the Reasoning of LLM-Powered Agents</title>
<link>https://arxiv.org/abs/2411.03455</link>
<guid>https://arxiv.org/abs/2411.03455</guid>
<content:encoded><![CDATA[
<div> 关键词: 基石模型(FMs), 大规模推理模型(LRMs), 快速思考大型语言模型(LLMs), Watson, 调试性能

<br /><br />总结:
本文提出了一种名为Watson的新框架，旨在解决由快速思考LLMs驱动的自主运行软件代理的可观察性和调试性挑战。Watson能够提供对LLM隐含推理过程的可观测性，从而可以识别和定位错误并指导进行修正。通过在大规模多任务语言理解(MMLU)基准测试和SWE-bench-lite两个场景中的应用，证明了Watson恢复的隐含推理轨迹的准确性和实用性。使用Watson，研究者能够在运行时观察并识别出隐含推理错误，并自动提供针对性的纠正措施，无需更新模型或代理的认知架构，就使MMLU和SWE-bench-lite上的Pass@1指标分别提高了7.58个百分点（相对提升13.45%）和7.76个百分点（相对提升12.31%）。 <div>
arXiv:2411.03455v2 Announce Type: replace 
Abstract: As foundation models (FMs) play an increasingly prominent role in complex software systems, such as agentic software, they introduce significant observability and debuggability challenges. Although recent Large Reasoning Models (LRMs) generate their thought processes as part of the output, in many scenarios fast-thinking Large Language Models (LLMs) are still preferred due to latency constraints. LLM-powered agents operate autonomously with opaque implicit reasoning, making it difficult to debug their unexpected behaviors or errors. In this paper, we introduce Watson, a novel framework that provides reasoning observability into the implicit reasoning processes of agents driven by fast-thinking LLMs, allowing the identification and localization of errors and guidance for corrections. We demonstrate the accuracy of the recovered implicit reasoning trace by Watson and its usefulness through debugging and improving the performance of LLM-powered agents in two scenarios: Massive Multitask Language Understanding (MMLU) benchmark and SWE-bench-lite. Using Watson, we were able to observe and identify the implicit reasoning errors, and automatically provide targeted corrections at runtime that improve the Pass@1 of agents on MMLU and SWE-bench-lite by 7.58 (13.45% relative improvement) and 7.76 (12.31% relative improvement) percentage points, respectively, without updates to models or the cognitive architecture of the agents.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AdaptBot: Combining LLM with Knowledge Graphs and Human Input for Generic-to-Specific Task Decomposition and Knowledge Refinement</title>
<link>https://arxiv.org/abs/2502.02067</link>
<guid>https://arxiv.org/abs/2502.02067</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、知识图谱、机器人、任务适应、人类交互

总结:
本文介绍了一个利用大型语言模型（LLMs）、知识图谱以及人类输入帮助机器人快速适应新任务的框架。该框架针对当没有足够时间或标注示例来训练机器人执行新任务的情况，通过结合LLM的抽象动作序列预测与知识图谱中的领域先验知识，使机器人能够更好地适应新任务。此外，机器人还能根据需要向人类获取并使用输入以完善自身知识。实验结果显示，在烹饪和清洁等任务的模拟环境中，这种LLM、KG与人类输入之间的交互作用相比于仅使用LLM，显著提高了机器人的性能。相关项目网站：https://sssshivvvv.github.io/adaptbot/ <div>
arXiv:2502.02067v2 Announce Type: replace 
Abstract: An embodied agent assisting humans is often asked to complete new tasks, and there may not be sufficient time or labeled examples to train the agent to perform these new tasks. Large Language Models (LLMs) trained on considerable knowledge across many domains can be used to predict a sequence of abstract actions for completing such tasks, although the agent may not be able to execute this sequence due to task-, agent-, or domain-specific constraints. Our framework addresses these challenges by leveraging the generic predictions provided by LLM and the prior domain knowledge encoded in a Knowledge Graph (KG), enabling an agent to quickly adapt to new tasks. The robot also solicits and uses human input as needed to refine its existing knowledge. Based on experimental evaluation in the context of cooking and cleaning tasks in simulation domains, we demonstrate that the interplay between LLM, KG, and human input leads to substantial performance gains compared with just using the LLM. Project website{\S}: https://sssshivvvv.github.io/adaptbot/
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>R2-KG: General-Purpose Dual-Agent Framework for Reliable Reasoning on Knowledge Graphs</title>
<link>https://arxiv.org/abs/2502.12767</link>
<guid>https://arxiv.org/abs/2502.12767</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，知识图谱 (KGs)，R2-KG，推理框架，可信度

<br /><br />总结:
本文介绍了R2-KG，这是一个创新的、可插拔的双代理推理框架，旨在解决现有将LLMs与KG结合进行增强推理时存在的灵活性和可靠性问题。R2-KG将推理任务分为操作员（低容量的LLM）和监督器（高容量的LLM）两个角色，前者负责搜集证据，后者做出最终判断，从而实现成本效率更高的LLM推理并保持较高的推理准确性。此外，R2-KG引入了弃权机制，仅在从KG收集到充分证据时才生成答案，显著提升了可靠性。实验结果显示，无论使用何种内在能力的LLM作为操作员，R2-KG在基于KG的多项推理任务中均展现出在准确性和可靠性上的优越性能。进一步的实验表明，单代理版本的R2-KG在采用严格的自我一致性策略后，虽然提高了可靠性但也会导致在复杂KG中的弃权率提高。总的来说，R2-KG为基于KG的推理提供了一个灵活、低成本且确保可信推理的解决方案，减少了对高容量LLM的依赖。 <div>
arXiv:2502.12767v2 Announce Type: replace 
Abstract: Recent studies have combined Large Language Models (LLMs) with Knowledge Graphs (KGs) to enhance reasoning, improving inference accuracy without additional training while mitigating hallucination. However, existing frameworks are often rigid, struggling to adapt to KG or task changes. They also rely heavily on powerful LLMs for reliable (i.e., trustworthy) reasoning. To address this, We introduce R2-KG, a plug-and-play, dual-agent framework that separates reasoning into two roles: an Operator (a low-capacity LLM) that gathers evidence and a Supervisor (a high-capacity LLM) that makes final judgments. This design is cost-efficient for LLM inference while still maintaining strong reasoning accuracy. Additionally, R2-KG employs an Abstention mechanism, generating answers only when sufficient evidence is collected from KG, which significantly enhances reliability. Experiments across multiple KG-based reasoning tasks show that R2-KG consistently outperforms baselines in both accuracy and reliability, regardless of the inherent capability of LLMs used as the Operator. Further experiments reveal that the single-agent version of R2-KG, equipped with a strict self-consistency strategy, achieves significantly higher-than-baseline reliability while reducing inference cost. However, it also leads to a higher abstention rate in complex KGs. Our findings establish R2-KG as a flexible and cost-effective solution for KG-based reasoning. It reduces reliance on high-capacity LLMs while ensuring trustworthy inference.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An LLM-based Agent for Reliable Docker Environment Configuration</title>
<link>https://arxiv.org/abs/2502.13681</link>
<guid>https://arxiv.org/abs/2502.13681</guid>
<content:encoded><![CDATA[
<div> 关键词：环境配置、大型语言模型、Repo2Run、Dockerfile、Python仓库

总结:<br />
本文介绍了首个基于大型语言模型（LLM）的环境配置工具Repo2Run，该工具致力于全自动地为任意Python仓库生成可执行的Dockerfile。针对两大挑战，即在隔离的Docker容器中进行环境配置以及确保成功配置过程被准确记录并转移至Dockerfile，文章提出了原子配置综合方法，包括内部和外部环境的双环境架构及回滚机制，保证命令执行的原子性（要么完全执行，要么不执行）以及Dockerfile生成器。通过在包含420个带有单元测试的最近Python仓库的自建基准上进行评估，Repo2Run取得了86.0%的成功率，优于最好基线63.9%。Repo2Run已在https://github.com/bytedance/Repo2Run开源。 <div>
arXiv:2502.13681v2 Announce Type: replace 
Abstract: Environment configuration is a critical yet time-consuming step in software development, especially when dealing with unfamiliar code repositories. While Large Language Models (LLMs) demonstrate the potential to accomplish software engineering tasks, existing methods for environment configuration often rely on manual efforts or fragile scripts, leading to inefficiencies and unreliable outcomes. We introduce Repo2Run, the first LLM-based agent designed to fully automate environment configuration and generate executable Dockerfiles for arbitrary Python repositories. We address two major challenges: (1) enabling the LLM agent to configure environments within isolated Docker containers, and (2) ensuring the successful configuration process is recorded and accurately transferred to a Dockerfile without error. To achieve this, we propose atomic configuration synthesis, featuring a dual-environment architecture (internal and external environment) with a rollback mechanism to prevent environment "pollution" from failed commands, guaranteeing atomic execution (execute fully or not at all) and a Dockerfile generator to transfer successful configuration steps into runnable Dockerfiles. We evaluate Repo2Run~on our proposed benchmark of 420 recent Python repositories with unit tests, where it achieves an 86.0% success rate, outperforming the best baseline by 63.9%. Repo2Run is available at https://github.com/bytedance/Repo2Run.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Investigating Non-Transitivity in LLM-as-a-Judge</title>
<link>https://arxiv.org/abs/2502.14074</link>
<guid>https://arxiv.org/abs/2502.14074</guid>
<content:encoded><![CDATA[
<div> 关键词：自动评估、大型语言模型、偏好传递性、AlpacaEval框架、Bradley-Terry模型

总结:
<br />
本文研究了基于大型语言模型的自动评估方法中偏好传递性的假设。通过分析AlpacaEval框架内的非传递性偏好的存在及其对模型排名的影响，发现当前常用的基线比较方式可能导致敏感且不稳定的排名结果。为解决这一问题，文章提出采用结合Bradley-Terry模型的轮转锦标赛方法来生成更可靠的排名，结果显示这种方法提高了与Chatbot Arena的相关性（Spearman相关性和Kendall相关性分别提升至96.4%和86.3%）。为了降低轮转锦标赛的计算成本，文中还提出了使用动态匹配策略的瑞士制智慧迭代配对（Swim）锦标赛方案。 <div>
arXiv:2502.14074v2 Announce Type: replace 
Abstract: Automatic evaluation methods based on large language models (LLMs) are emerging as the standard tool for assessing the instruction-following abilities of LLM-based agents. The most common method in this paradigm, pairwise comparisons with a baseline model, critically depends on the assumption of transitive preferences. However, the validity of this assumption remains largely unexplored. In this study, we investigate the presence of non-transitivity within the AlpacaEval framework and analyze its effects on model rankings. We find that LLM judges exhibit non-transitive preferences, leading to rankings that are sensitive to the choice of the baseline model. To mitigate this issue, we show that round-robin tournaments combined with Bradley-Terry models of preference can produce more reliable rankings. Notably, our method increases both the Spearman correlation and the Kendall correlation with Chatbot Arena (95.0% -> 96.4% and 82.1% -> 86.3% respectively). To address the computational cost of round-robin tournaments, we propose Swiss-Wise Iterative Matchmaking (Swim) tournaments, using a dynamic matching strategy to capture the benefits of round-robin tournaments while maintaining computational efficiency.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning for Infinite Horizon Mean Field Problems in Continuous Spaces</title>
<link>https://arxiv.org/abs/2309.10953</link>
<guid>https://arxiv.org/abs/2309.10953</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、连续空间、均场博弈、均场控制、演员-评论家算法

总结:
本文提出了一种针对连续空间均场博弈（MFG）和均场控制（MFC）问题的统一解决方法的强化学习（RL）算法。该算法采用演员-评论家（AC）范式，并利用参数化的散度函数表示均场分布，能在线性方式下有效更新。通过兰金动态采样法从由此得到的分布中获取样本。AC代理和散度函数经迭代更新后，可收敛至给定均场问题的MFG均衡或MFC最优解，具体取决于学习率的选择。通过简单修改此算法，也可解决混合均场控制博弈（MFCGs）。文章通过线性二次型基准测试，在渐近无限时间框架下评估了算法性能。<br /><br /> <div>
arXiv:2309.10953v3 Announce Type: replace-cross 
Abstract: We present the development and analysis of a reinforcement learning (RL) algorithm designed to solve continuous-space mean field game (MFG) and mean field control (MFC) problems in a unified manner. The proposed approach pairs the actor-critic (AC) paradigm with a representation of the mean field distribution via a parameterized score function, which can be efficiently updated in an online fashion, and uses Langevin dynamics to obtain samples from the resulting distribution. The AC agent and the score function are updated iteratively to converge, either to the MFG equilibrium or the MFC optimum for a given mean field problem, depending on the choice of learning rates. A straightforward modification of the algorithm allows us to solve mixed mean field control games (MFCGs). The performance of our algorithm is evaluated using linear-quadratic benchmarks in the asymptotic infinite horizon framework.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"Would You Want an AI Tutor?" Understanding Stakeholder Perceptions of LLM-based Chatbots in the Classroom</title>
<link>https://arxiv.org/abs/2503.02885</link>
<guid>https://arxiv.org/abs/2503.02885</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，教育，反馈系统，人工智能，利益相关者感知

总结:
本文关注了近年来广泛应用在教育领域的大型语言模型（LLMs），并指出尽管它们已被许多学校采纳作为虚拟教师和助教，但针对该技术的反馈系统却并未得到充分建立。文章强调理解学生、教师、家长以及学校工作人员等直接或间接受影响的利益相关者对LLM在课堂中的应用的感知至关重要，以确保AI在此关键领域内的负责任使用。首先，通过对现有文献的回顾，作者指出了研究中存在的空白，如在分析利益相关者角色时忽略了如父母和学校管理者等关键群体，以及常忽视实施AI系统的具体学习环境。因此，他们提出了一种名为“情境化的聊天机器人在教育中采纳的感知框架”(Co-PACE)，用于系统性地获取各方感知，并指导LLM基础的聊天机器人如何在教室中合理设计、开发和部署。 <div>
arXiv:2503.02885v1 Announce Type: new 
Abstract: In recent years, Large Language Models (LLMs) rapidly gained popularity across all parts of society, including education. After initial skepticism and bans, many schools have chosen to embrace this new technology by integrating it into their curricula in the form of virtual tutors and teaching assistants. However, neither the companies developing this technology nor the public institutions involved in its implementation have set up a formal system to collect feedback from the stakeholders impacted by them. In this paper, we argue that understanding the perceptions of those directly affected by LLMS in the classroom, such as students and teachers, as well as those indirectly impacted, like parents and school staff, is essential for ensuring responsible use of AI in this critical domain. Our contributions are two-fold. First, we present results of a literature review focusing on the perceptions of LLM-based chatbots in education. We highlight important gaps in the literature, such as the exclusion of key educational agents (e.g., parents or school administrators) when analyzing the role of stakeholders, and the frequent omission of the learning contexts in which the AI systems are implemented. Thus, we present a taxonomy that organizes existing literature on stakeholder perceptions. Second, we propose the Contextualized Perceptions for the Adoption of Chatbots in Education (Co-PACE) framework, which can be used to systematically elicit perceptions and inform whether and how LLM-based chatbots should be designed, developed, and deployed in the classroom.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Robust Multi-UAV Collaboration: MARL with Noise-Resilient Communication and Attention Mechanisms</title>
<link>https://arxiv.org/abs/2503.02913</link>
<guid>https://arxiv.org/abs/2503.02913</guid>
<content:encoded><![CDATA[
<div> 关键词: 多无人机路径规划、协同通信、强化学习、注意力机制、噪声环境

总结:
为了解决多无人机在远程感知和信息收集中的高效路径规划问题，以及在大规模任务中面临的协作通信和决策难题，本文提出了一种基于Counterfactual Multi-Agent Policy Gradients（COMA）算法的多智能体强化学习（MARL）框架用于无人机路径规划。该框架融合了基于注意力机制的无人机通信协议和训练-部署系统，显著提升了在噪声环境下的通信鲁棒性和个体决策能力。通过在合成数据和真实世界数据集上的实验表明，相较于现有算法，本文方法在路径规划效率和鲁棒性方面表现更优，在噪声环境中熵减幅度提高了78%。 <div>
arXiv:2503.02913v1 Announce Type: new 
Abstract: Efficient path planning for unmanned aerial vehicles (UAVs) is crucial in remote sensing and information collection. As task scales expand, the cooperative deployment of multiple UAVs significantly improves information collection efficiency. However, collaborative communication and decision-making for multiple UAVs remain major challenges in path planning, especially in noisy environments. To efficiently accomplish complex information collection tasks in 3D space and address robust communication issues, we propose a multi-agent reinforcement learning (MARL) framework for UAV path planning based on the Counterfactual Multi-Agent Policy Gradients (COMA) algorithm. The framework incorporates attention mechanism-based UAV communication protocol and training-deployment system, significantly improving communication robustness and individual decision-making capabilities in noisy conditions. Experiments conducted on both synthetic and real-world datasets demonstrate that our method outperforms existing algorithms in terms of path planning efficiency and robustness, especially in noisy environments, achieving a 78\% improvement in entropy reduction.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LiteWebAgent: The Open-Source Suite for VLM-Based Web-Agent Applications</title>
<link>https://arxiv.org/abs/2503.02950</link>
<guid>https://arxiv.org/abs/2503.02950</guid>
<content:encoded><![CDATA[
<div> 关键词: LiteWebAgent、开放源代码、VLM基、web代理应用、服务器无状态后台配置

总结:
LiteWebAgent是一个开源的、基于VLM的web代理应用程序框架。它填补了web代理生态系统中的关键空白，提供了一个生产就绪的解决方案，该方案结合了最小化的服务器无状态后台配置、直观的用户和浏览器界面以及可扩展的智能体规划、记忆和树搜索研究能力。LiteWebAgent的核心框架采用了递归函数调用的简单而有效的基线，实现了行动生成与行动接地的解耦。此外，它以模块化和可扩展的方式集成了先进的研究组件，如智能体规划、工作流记忆和树搜索。LiteWebAgent框架已与前端和后端集成并部署为两种形式：(1) 一个基于Vercel的生产级web应用，用户可以使用由智能体控制的远程浏览器；(2) 一个利用LiteWebAgent API控制现有Chrome浏览器的Chrome扩展程序，通过CDP（Chrome DevTools协议）实现控制。LiteWebAgent框架可在https://github.com/PathOnAI/LiteWebAgent获取，其部署的前端网站位于https://lite-web-agent.vercel.app/。 <div>
arXiv:2503.02950v1 Announce Type: new 
Abstract: We introduce LiteWebAgent, an open-source suite for VLM-based web agent applications. Our framework addresses a critical gap in the web agent ecosystem with a production-ready solution that combines minimal serverless backend configuration, intuitive user and browser interfaces, and extensible research capabilities in agent planning, memory, and tree search. For the core LiteWebAgent agent framework, we implemented a simple yet effective baseline using recursive function calling, providing with decoupled action generation and action grounding. In addition, we integrate advanced research components such as agent planning, agent workflow memory, and tree search in a modular and extensible manner. We then integrate the LiteWebAgent agent framework with frontend and backend as deployed systems in two formats: (1) a production Vercel-based web application, which provides users with an agent-controlled remote browser, (2) a Chrome extension leveraging LiteWebAgent's API to control an existing Chrome browser via CDP (Chrome DevTools Protocol). The LiteWebAgent framework is available at https://github.com/PathOnAI/LiteWebAgent, with deployed frontend at https://lite-web-agent.vercel.app/.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reliable and Efficient Multi-Agent Coordination via Graph Neural Network Variational Autoencoders</title>
<link>https://arxiv.org/abs/2503.02954</link>
<guid>https://arxiv.org/abs/2503.02954</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协调、多机器人导航、图神经网络变分自编码器（GNN-VAE）、集中式优化、大规模问题

总结：
本文提出了一种利用图神经网络变分自编码器（GNN-VAE）解决大规模多智能体协调问题的新方法，该方法针对共享空间中如自动化仓库内的可靠多机器人导航。在高密度机器人交通区域，局部协调方法可能无法找到无死锁的解决方案，因此文章建议由中央单元生成全局调度以决定机器人的通行顺序。然而，中心化协调方法的运行时间会随着问题规模增大而显著增加。通过将协调问题形式化为图问题并使用混合整数线性规划（MILP）求解器收集地面真实数据，研究训练了一个学习框架，将其编码到潜在空间中。在推理阶段，从采样的潜在变量中解码解决方案样本，并选择最低成本的样本用于协调。最后，选取性能指数最高的可行提案进行部署。由于设计结构的原因，GNN-VAE 框架返回的解决方案始终尊重所考虑的协调问题的约束条件。数值结果表明，即使对于拥有250个机器人的大规模问题，本方法在经过小规模问题训练后仍能实现高质量的解决方案，并且速度远超其他基线方法。项目页面： <div>
arXiv:2503.02954v1 Announce Type: new 
Abstract: Multi-agent coordination is crucial for reliable multi-robot navigation in shared spaces such as automated warehouses. In regions of dense robot traffic, local coordination methods may fail to find a deadlock-free solution. In these scenarios, it is appropriate to let a central unit generate a global schedule that decides the passing order of robots. However, the runtime of such centralized coordination methods increases significantly with the problem scale. In this paper, we propose to leverage Graph Neural Network Variational Autoencoders (GNN-VAE) to solve the multi-agent coordination problem at scale faster than through centralized optimization. We formulate the coordination problem as a graph problem and collect ground truth data using a Mixed-Integer Linear Program (MILP) solver. During training, our learning framework encodes good quality solutions of the graph problem into a latent space. At inference time, solution samples are decoded from the sampled latent variables, and the lowest-cost sample is selected for coordination. Finally, the feasible proposal with the highest performance index is selected for the deployment. By construction, our GNN-VAE framework returns solutions that always respect the constraints of the considered coordination problem. Numerical results show that our approach trained on small-scale problems can achieve high-quality solutions even for large-scale problems with 250 robots, being much faster than other baselines. Project page: https://mengyuest.github.io/gnn-vae-coord
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Teaching AI to Handle Exceptions: Supervised Fine-Tuning with Human-Aligned Judgment</title>
<link>https://arxiv.org/abs/2503.02976</link>
<guid>https://arxiv.org/abs/2503.02976</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、决策制定、异常处理、监督微调、人类判断

<br />
总结:

本文探讨了大型语言模型（LLMs）在从生成式AI向具有决策能力的智能系统演进过程中，在处理复杂真实世界情境尤其是异常情况时，其决策过程与人类判断存在显著偏差的问题。研究发现，即使擅长推理的LLMs也会严格遵循政策，即便这可能导致不切实际、次优或适得其反的结果。文章对比评估了三种改进AI决策处理异常的方法：伦理框架提示、链式思考推理和监督微调。结果显示，伦理框架提示方法失败，链式思考推理仅带来轻微改善，而采用人类解释的监督微调方法则取得明显更好的效果。值得注意的是，实验表明，通过使用人类解释进行监督微调，模型甚至能够将人类式的决策思维泛化到新场景中，展示了跨上下文的人类对齐决策学习迁移。最后，研究指出，为了使LLMs与人类判断相一致，不仅需要训练模型做出正确的决策，而且还需要明确地训练决策是如何做出的过程。这些发现强调了解决LLMs在处理异常方面的不足对于引导代理型AI的发展、使其更好地与人类判断保持一致并适应新颖情境的重要性。 <div>
arXiv:2503.02976v1 Announce Type: new 
Abstract: Large language models (LLMs), initially developed for generative AI, are now evolving into agentic AI systems, which make decisions in complex, real-world contexts. Unfortunately, while their generative capabilities are well-documented, their decision-making processes remain poorly understood. This is particularly evident when models are handling exceptions, a critical and challenging aspect of decision-making made relevant by the inherent incompleteness of contracts. Here we demonstrate that LLMs, even ones that excel at reasoning, deviate significantly from human judgments because they adhere strictly to policies, even when such adherence is impractical, suboptimal, or even counterproductive. We then evaluate three approaches to tuning AI agents to handle exceptions: ethical framework prompting, chain-of-thought reasoning, and supervised fine-tuning. We find that while ethical framework prompting fails and chain-of-thought prompting provides only slight improvements, supervised fine-tuning, specifically with human explanations, yields markedly better results. Surprisingly, in our experiments, supervised fine-tuning even enabled models to generalize human-like decision-making to novel scenarios, demonstrating transfer learning of human-aligned decision-making across contexts. Furthermore, fine-tuning with explanations, not just labels, was critical for alignment, suggesting that aligning LLMs with human judgment requires explicit training on how decisions are made, not just which decisions are made. These findings highlight the need to address LLMs' shortcomings in handling exceptions in order to guide the development of agentic AI toward models that can effectively align with human judgment and simultaneously adapt to novel contexts.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAILGUN: A Unified Convolutional Policy for Multi-Agent Path Finding Across Different Environments and Tasks</title>
<link>https://arxiv.org/abs/2503.02992</link>
<guid>https://arxiv.org/abs/2503.02992</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Path Finding (MAPF)，深度神经网络，RAILGUN，集中式学习，零_shot_泛化

总结:
本文提出了一种名为RAILGUN的创新方法，它是首个用于多智能体路径规划(MAPF)问题的集中式学习策略。传统上，由于智能体数量和地图尺寸的可变性，MAPF的解决方法依赖于分散式规划，但RAILGUN通过基于卷积神经网络(CNN)的架构，实现了对不同地图和任意数量智能体情况的泛化处理。该模型采用规则基方法生成的轨迹进行监督学习训练。实验结果显示，RAILGUN优于多数基线方法，并在未出现在训练数据集中的各种任务、地图和智能体数量情况下展现出强大的零样本泛化能力。 <div>
arXiv:2503.02992v1 Announce Type: new 
Abstract: Multi-Agent Path Finding (MAPF), which focuses on finding collision-free paths for multiple robots, is crucial for applications ranging from aerial swarms to warehouse automation. Solving MAPF is NP-hard so learning-based approaches for MAPF have gained attention, particularly those leveraging deep neural networks. Nonetheless, despite the community's continued efforts, all learning-based MAPF planners still rely on decentralized planning due to variability in the number of agents and map sizes. We have developed the first centralized learning-based policy for MAPF problem called RAILGUN. RAILGUN is not an agent-based policy but a map-based policy. By leveraging a CNN-based architecture, RAILGUN can generalize across different maps and handle any number of agents. We collect trajectories from rule-based methods to train our model in a supervised way. In experiments, RAILGUN outperforms most baseline methods and demonstrates great zero-shot generalization capabilities on various tasks, maps and agent numbers that were not seen in the training dataset.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A2Perf: Real-World Autonomous Agents Benchmark</title>
<link>https://arxiv.org/abs/2503.03056</link>
<guid>https://arxiv.org/abs/2503.03056</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous agents, Benchmarking suite, A2Perf, Reinforcement learning, Imitation learning

总结:
为了解决自主代理和系统在多个应用领域中面临的共同且未解决的研究挑战，本文提出了一个新的基准测试平台A2Perf。A2Perf包括三个与现实世界场景紧密相关的环境：计算机芯片布局、网页导航和四足动物行走。该平台关注任务性能、泛化能力、系统资源效率和可靠性等关键指标，以便于社区对比各种方法在实际问题上的进展。通过A2Perf，研究者展示了网页导航代理可以在消费级硬件上达到接近人类反应时间的延迟，揭示了四足动物行走算法之间的可靠性权衡，并量化了不同学习方法在计算机芯片设计中的能源成本。此外，文章还引入了一个数据成本指标，用于衡量模仿学习和混合算法获取离线数据的成本，从而更好地比较这些方法。A2Perf包含了多种标准基线，支持公平的方法间对比并促进现实世界自主性领域的进步。作为开放源代码的基准测试平台，A2Perf旨在长期保持对研究社区的访问友好、更新及时和实用价值。 <div>
arXiv:2503.03056v1 Announce Type: new 
Abstract: Autonomous agents and systems cover a number of application areas, from robotics and digital assistants to combinatorial optimization, all sharing common, unresolved research challenges. It is not sufficient for agents to merely solve a given task; they must generalize to out-of-distribution tasks, perform reliably, and use hardware resources efficiently during training and inference, among other requirements. Several methods, such as reinforcement learning and imitation learning, are commonly used to tackle these problems, each with different trade-offs. However, there is a lack of benchmarking suites that define the environments, datasets, and metrics which can be used to provide a meaningful way for the community to compare progress on applying these methods to real-world problems. We introduce A2Perf--a benchmark with three environments that closely resemble real-world domains: computer chip floorplanning, web navigation, and quadruped locomotion. A2Perf provides metrics that track task performance, generalization, system resource efficiency, and reliability, which are all critical to real-world applications. Using A2Perf, we demonstrate that web navigation agents can achieve latencies comparable to human reaction times on consumer hardware, reveal reliability trade-offs between algorithms for quadruped locomotion, and quantify the energy costs of different learning approaches for computer chip-design. In addition, we propose a data cost metric to account for the cost incurred acquiring offline data for imitation learning and hybrid algorithms, which allows us to better compare these approaches. A2Perf also contains several standard baselines, enabling apples-to-apples comparisons across methods and facilitating progress in real-world autonomy. As an open-source benchmark, A2Perf is designed to remain accessible, up-to-date, and useful to the research community over the long term.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dango: A Mixed-Initiative Data Wrangling System using Large Language Model</title>
<link>https://arxiv.org/abs/2503.03154</link>
<guid>https://arxiv.org/abs/2503.03154</guid>
<content:encoded><![CDATA[
<div> 关键词：数据清洗、Dango、混合主动型多智能体系统、用户意图沟通、效率提升

<br /><br />总结:
本文提出了一种名为Dango的混合主动型多智能体数据清洗系统。相较于已有工具，Dango通过允许用户在多个表上进行操作并使用自然语言提示在对话界面中传达意图，提升了用户意图沟通的效果。同时，Dango利用LLM提出的多项选择澄清问题帮助用户明确其意图，并提供逐步自然语言解释和数据来源等多形式反馈，以协助用户评估数据清洗脚本。通过一项包含38名参与者的嵌套式用户研究，文章证明了Dango的功能可以显著改善意图澄清、提高数据清洗的准确性和效率，并进一步展示了Dango在更广泛的数据清洗任务中的泛化能力。 <div>
arXiv:2503.03154v1 Announce Type: new 
Abstract: Data wrangling is a time-consuming and challenging task in a data science pipeline. While many tools have been proposed to automate or facilitate data wrangling, they often misinterpret user intent, especially in complex tasks. We propose Dango, a mixed-initiative multi-agent system for data wrangling. Compared to existing tools, Dango enhances user communication of intent by allowing users to demonstrate on multiple tables and use natural language prompts in a conversation interface, enabling users to clarify their intent by answering LLM-posed multiple-choice clarification questions, and providing multiple forms of feedback such as step-by-step natural language explanations and data provenance to help users evaluate the data wrangling scripts. We conducted a within-subjects user study with 38 participants and demonstrated that Dango's features can significantly improve intent clarification, accuracy, and efficiency in data wrangling. Furthermore, we demonstrated the generalizability of Dango by applying it to a broader set of data wrangling tasks.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Certifiably Correct Range-Aided SLAM</title>
<link>https://arxiv.org/abs/2503.03192</link>
<guid>https://arxiv.org/abs/2503.03192</guid>
<content:encoded><![CDATA[
<div> 关键词：同时定位与建图(SLAM)，多智能体，通信约束，分布式算法，范围辅助(RA) SLAM，全局最优解，分布式认证正确RA-SLAM(DCORA)，Riemannian Staircase方法，真实数据集，合成数据分析，绝对轨迹误差。

总结:<br />
该文提出了首个能高效求解范围辅助SLAM（RA-SLAM）问题并保证全局最优解的分布式算法——分布式认证正确RA-SLAM（DCORA）。DCORA利用Riemannian Staircase方法，将已有的分布式认证正确姿态图优化算法推广到RA-SLAM问题。文章通过实验证实在真实世界多智能体数据集上，DCORA的绝对轨迹误差可与最先进的集中式认证正确RA-SLAM算法相媲美。此外，通过对合成数据进行参数研究，揭示了RA-SLAM问题中常见参数对DCORA性能的影响。 <div>
arXiv:2503.03192v1 Announce Type: new 
Abstract: Reliable simultaneous localization and mapping (SLAM) algorithms are necessary for safety-critical autonomous navigation. In the communication-constrained multi-agent setting, navigation systems increasingly use point-to-point range sensors as they afford measurements with low bandwidth requirements and known data association. The state estimation problem for these systems takes the form of range-aided (RA) SLAM. However, distributed algorithms for solving the RA-SLAM problem lack formal guarantees on the quality of the returned estimate. To this end, we present the first distributed algorithm for RA-SLAM that can efficiently recover certifiably globally optimal solutions. Our algorithm, distributed certifiably correct RA-SLAM (DCORA), achieves this via the Riemannian Staircase method, where computational procedures developed for distributed certifiably correct pose graph optimization are generalized to the RA-SLAM problem. We demonstrate DCORA's efficacy on real-world multi-agent datasets by achieving absolute trajectory errors comparable to those of a state-of-the-art centralized certifiably correct RA-SLAM algorithm. Additionally, we perform a parametric study on the structure of the RA-SLAM problem using synthetic data, revealing how common parameters affect DCORA's performance.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SpiritSight Agent: Advanced GUI Agent with One Look</title>
<link>https://arxiv.org/abs/2503.03196</link>
<guid>https://arxiv.org/abs/2503.03196</guid>
<content:encoded><![CDATA[
<div> 关键词：Graphical User Interface (GUI)，Vision Language Models (VLMs)，SpiritSight，GUI-Lasagne，Universal Block Parsing (UBP)

总结:
本文提出了一种名为SpiritSight的新型视觉驱动GUI代理，旨在解决基于视觉的GUI代理在元素定位准确性上的不足。为增强SpiritSight对GUI的理解和定位能力，研究者构建了一个大规模、高质量的多层级GUI数据集——GUI-Lasagne，采用了可扩展的方法。同时，他们引入了“通用块解析（UBP）”方法，以解决动态高分辨率视觉输入中的歧义问题，进一步提升了SpiritSight对GUI对象的定位能力。实验结果显示，SpiritSight在各种GUI基准测试中优于其他先进方法，证明了其在GUI导航任务上的优越能力和兼容性。相关模型可在提供的链接地址获取。 <div>
arXiv:2503.03196v1 Announce Type: new 
Abstract: Graphical User Interface (GUI) agents show amazing abilities in assisting human-computer interaction, automating human user's navigation on digital devices. An ideal GUI agent is expected to achieve high accuracy, low latency, and compatibility for different GUI platforms. Recent vision-based approaches have shown promise by leveraging advanced Vision Language Models (VLMs). While they generally meet the requirements of compatibility and low latency, these vision-based GUI agents tend to have low accuracy due to their limitations in element grounding. To address this issue, we propose $\textbf{SpiritSight}$, a vision-based, end-to-end GUI agent that excels in GUI navigation tasks across various GUI platforms. First, we create a multi-level, large-scale, high-quality GUI dataset called $\textbf{GUI-Lasagne}$ using scalable methods, empowering SpiritSight with robust GUI understanding and grounding capabilities. Second, we introduce the $\textbf{Universal Block Parsing (UBP)}$ method to resolve the ambiguity problem in dynamic high-resolution of visual inputs, further enhancing SpiritSight's ability to ground GUI objects. Through these efforts, SpiritSight agent outperforms other advanced methods on diverse GUI benchmarks, demonstrating its superior capability and compatibility in GUI navigation tasks. Models are available at $\href{https://huggingface.co/SenseLLM/SpiritSight-Agent-8B}{this\ URL}$.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought Reasoning enhances Formal Theorem Proving</title>
<link>https://arxiv.org/abs/2503.03205</link>
<guid>https://arxiv.org/abs/2503.03205</guid>
<content:encoded><![CDATA[
<div> 关键词: MA-LoT、多智能体框架、Lean4、长链思考、形式验证

总结:
本文提出了首个基于Lean4的多智能体框架MA-LoT，该框架旨在平衡自然语言和形式语言之间的高级推理与验证反馈，通过利用长链思考中的新兴形式推理能力。实验显示，MA-LoT在MiniF2F-Test数据集的Lean4版本上取得了54.51%的准确率，显著优于GPT-4（22.95%）、单一智能体树搜索（InternLM-Step-Prover，50.70%）以及整体证明生成（DeepSeek-Prover-v1.5，48.36%）等基线方法。此外，研究还揭示了结合长链思考与形式验证对于更具有洞察力的生成具有广泛潜力。 <div>
arXiv:2503.03205v1 Announce Type: new 
Abstract: Solving mathematical problems using computer-verifiable languages like Lean has significantly impacted mathematical and computer science communities. State-of-the-art methods utilize single Large Language Models (LLMs) as agents or provers to either generate complete proof or perform tree searches. However, single-agent methods inherently lack a structured way to combine high-level reasoning in Natural Language (NL) with Formal Language (FL) verification feedback. To solve these issues, we propose MA-LoT: Multi-Agent Lean-based Long Chain-of-Thought framework, (to the best of our knowledge), the first multi-agent framework for Lean4 theorem proving that balance high-level NL reasoning and FL verification in Long CoT. Using this structured interaction, our approach enables deeper insights and long-term coherence in proof generation, with which past methods struggle. We do this by leveraging emergent formal reasoning ability in Long CoT using our novel LoT-Transfer Learning training-inference pipeline. Extensive experiments show that our framework achieves 54.51% accuracy rate on the Lean4 version of MiniF2F-Test dataset, largely outperforming GPT-4 (22.95%), single-agent tree search (InternLM-Step-Prover, 50.70%), and whole-proof generation (DeepSeek-Prover-v1.5, 48.36%) baselines. Furthermore, our findings highlight the potential of combining Long CoT with formal verification for a more insightful generation in a broader perspective.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>COSINT-Agent: A Knowledge-Driven Multimodal Agent for Chinese Open Source Intelligence</title>
<link>https://arxiv.org/abs/2503.03215</link>
<guid>https://arxiv.org/abs/2503.03215</guid>
<content:encoded><![CDATA[
<div> 关键词：Open Source Intelligence (OSINT)，Multimodal Large Language Models (MLLMs)，COSINT-Agent，Entity-Event-Scene Knowledge Graph (EES-KG)，EES-Match

<br /><br />总结:
本文介绍了针对中文领域的开源情报（OSINT）挑战而设计的知识驱动型多模态智能体COSINT-Agent。COSINT-Agent将细调过的多模态大语言模型（MLLMs）与实体-事件-场景知识图谱（EES-KG）的结构化推理能力无缝结合。其中，EES-Match框架作为核心创新点，连接了COSINT-MLLM和EES-KG，实现了对多模态信息的系统性抽取、推理和情境化处理。该整合机制促进了实体识别、事件解读及上下文检索的精确性，从而将原始多模态数据转化为可操作的情报。实验结果证实了COSINT-Agent在OSINT关键任务中的优越性能，包括实体识别、EES生成和上下文匹配，显示其有望成为自动化多模态推理的强大且可扩展解决方案，进一步提升OSINT方法论的有效性。 <div>
arXiv:2503.03215v1 Announce Type: new 
Abstract: Open Source Intelligence (OSINT) requires the integration and reasoning of diverse multimodal data, presenting significant challenges in deriving actionable insights. Traditional approaches, including multimodal large language models (MLLMs), often struggle to infer complex contextual relationships or deliver comprehensive intelligence from unstructured data sources. In this paper, we introduce COSINT-Agent, a knowledge-driven multimodal agent tailored to address the challenges of OSINT in the Chinese domain. COSINT-Agent seamlessly integrates the perceptual capabilities of fine-tuned MLLMs with the structured reasoning power of the Entity-Event-Scene Knowledge Graph (EES-KG). Central to COSINT-Agent is the innovative EES-Match framework, which bridges COSINT-MLLM and EES-KG, enabling systematic extraction, reasoning, and contextualization of multimodal insights. This integration facilitates precise entity recognition, event interpretation, and context retrieval, effectively transforming raw multimodal data into actionable intelligence. Extensive experiments validate the superior performance of COSINT-Agent across core OSINT tasks, including entity recognition, EES generation, and context matching. These results underscore its potential as a robust and scalable solution for advancing automated multimodal reasoning and enhancing the effectiveness of OSINT methodologies.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Less is more? Rewards in RL for Cyber Defence</title>
<link>https://arxiv.org/abs/2503.03245</link>
<guid>https://arxiv.org/abs/2503.03245</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主防御代理人、深度强化学习、密集奖励、稀疏奖励、网络节点

总结:
近年来，基于深度强化学习的自主网络安全防御代理研究热度激增。大多数现有的网络安全模拟器（又称“网络健身房”）提供了密集型的“辅助式”奖励函数，然而这种函数可能引导代理找到次优解。本文旨在探究稀疏奖励函数是否能训练出更有效的防御代理。为此，文章首先指出了现有工作中存在的评价局限性，并提出了一种超越标准强化学习范式的地面真实评估分数。通过适应一个已有的网络健身房并引入该方法和地面真实分数，作者提出了两种稀疏奖励机制并与典型的密集奖励进行对比。实验结果显示，稀疏奖励（特别是对未被破坏网络状态的正向强化）能够训练出更有效的网络安全防御代理，并且其提供的训练稳定性超过密集奖励。此外，稀疏奖励的有效性和训练稳定性对于各种网络规模（从2到50个节点）以及反应式和主动式防御行动都表现出较强的鲁棒性。 <div>
arXiv:2503.03245v1 Announce Type: new 
Abstract: The last few years has seen an explosion of interest in autonomous cyber defence agents based on deep reinforcement learning. Such agents are typically trained in a cyber gym environment, also known as a cyber simulator, at least 32 of which have already been built. Most, if not all cyber gyms provide dense "scaffolded" reward functions which combine many penalties or incentives for a range of (un)desirable states and costly actions. Whilst dense rewards help alleviate the challenge of exploring complex environments, yielding seemingly effective strategies from relatively few environment steps; they are also known to bias the solutions an agent can find, potentially towards suboptimal solutions. Sparse rewards could offer preferable or more effective solutions and have been overlooked by cyber gyms to date. In this work we set out to evaluate whether sparse reward functions might enable training more effective cyber defence agents. Towards this goal we first break down several evaluation limitations in existing work by proposing a ground truth evaluation score that goes beyond the standard RL paradigm used to train and evaluate agents. By adapting a well-established cyber gym to accommodate our methodology and ground truth score, we propose and evaluate two sparse reward mechanisms and compare them with a typical dense reward. Our evaluation considers a range of network sizes, from 2 to 50 nodes, and both reactive and proactive defensive actions. Our results show that sparse rewards, particularly positive reinforcement for an uncompromised network state, enable the training of more effective cyber defence agents. Furthermore, we show that sparse rewards provide more stable training than dense rewards, and that both effectiveness and training stability are robust to a variety of cyber environment considerations.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BAT: Learning Event-based Optical Flow with Bidirectional Adaptive Temporal Correlation</title>
<link>https://arxiv.org/abs/2503.03256</link>
<guid>https://arxiv.org/abs/2503.03256</guid>
<content:encoded><![CDATA[
<div> 关键词：事件相机、光学流估计、BAT框架、双向自适应时间相关、未来光学流预测

总结:
本文提出了一种名为BAT的创新性框架，用于基于事件相机的光学流估计。该框架具有三个新颖设计：1) 双向自适应时间相关技术，将双向时间密集型运动线索转换为空间密集型，从而实现精确且空间密集的光学流估计；2) 自适应时间采样策略，以保持相关性过程中的时间一致性；3) 空间自适应时间运动聚合方法，能有效并自适应地聚集一致的目标运动特征到相邻运动特征中，同时抑制不一致的特征。实验结果显示，BAT在DSEC-Flow基准测试上排名第一，大幅超越了现有最先进的方法，并展现出锐利边缘和高质量细节。尤为值得一提的是，BAT仅利用过去事件数据就能准确预测未来的光学流，其性能显著优于E-RAFT的预热启动方法。相关代码已开源，可在https://github.com/gangweiX/BAT 获取。 <div>
arXiv:2503.03256v1 Announce Type: new 
Abstract: Event cameras deliver visual information characterized by a high dynamic range and high temporal resolution, offering significant advantages in estimating optical flow for complex lighting conditions and fast-moving objects. Current advanced optical flow methods for event cameras largely adopt established image-based frameworks. However, the spatial sparsity of event data limits their performance. In this paper, we present BAT, an innovative framework that estimates event-based optical flow using bidirectional adaptive temporal correlation. BAT includes three novel designs: 1) a bidirectional temporal correlation that transforms bidirectional temporally dense motion cues into spatially dense ones, enabling accurate and spatially dense optical flow estimation; 2) an adaptive temporal sampling strategy for maintaining temporal consistency in correlation; 3) spatially adaptive temporal motion aggregation to efficiently and adaptively aggregate consistent target motion features into adjacent motion features while suppressing inconsistent ones. Our results rank $1^{st}$ on the DSEC-Flow benchmark, outperforming existing state-of-the-art methods by a large margin while also exhibiting sharp edges and high-quality details. Notably, our BAT can accurately predict future optical flow using only past events, significantly outperforming E-RAFT's warm-start approach. Code: \textcolor{magenta}{https://github.com/gangweiX/BAT}.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring the Potential of Large Language Models as Predictors in Dynamic Text-Attributed Graphs</title>
<link>https://arxiv.org/abs/2503.03258</link>
<guid>https://arxiv.org/abs/2503.03258</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、图基础模型、动态图预测、GraphAgent-Dynamic框架、任务特定微调

总结:<br />
本文探讨了利用大规模语言模型（LLMs）进行动态图预测的研究领域，指出现有工作主要关注静态图预测，而对动态图预测的潜力尚未充分探索。为解决历史数据处理和领域特性变化带来的挑战，文章提出了GraphAgent-Dynamic (GAD) 框架，该框架采用多智能体系统，通过全局和局部摘要智能体生成领域专用知识，增强跨领域的泛化能力，并利用知识反射智能体实现自适应更新，保持统一且自洽的架构。实验表明，GAD的表现可与全监督图神经网络媲美甚至超越，无需针对具体数据集进行训练。最后，文章讨论了对LLM进行任务特定微调等潜在改进策略，为进一步设计LLM基预测器提供了新的思路。 <div>
arXiv:2503.03258v1 Announce Type: new 
Abstract: With the rise of large language models (LLMs), there has been growing interest in Graph Foundation Models (GFMs) for graph-based tasks. By leveraging LLMs as predictors, GFMs have demonstrated impressive generalizability across various tasks and datasets. However, existing research on LLMs as predictors has predominantly focused on static graphs, leaving their potential in dynamic graph prediction unexplored. In this work, we pioneer using LLMs for predictive tasks on dynamic graphs. We identify two key challenges: the constraints imposed by context length when processing large-scale historical data and the significant variability in domain characteristics, both of which complicate the development of a unified predictor. To address these challenges, we propose the GraphAgent-Dynamic (GAD) Framework, a multi-agent system that leverages collaborative LLMs. In contrast to using a single LLM as the predictor, GAD incorporates global and local summary agents to generate domain-specific knowledge, enhancing its transferability across domains. Additionally, knowledge reflection agents enable adaptive updates to GAD's knowledge, maintaining a unified and self-consistent architecture. In experiments, GAD demonstrates performance comparable to or even exceeds that of full-supervised graph neural networks without dataset-specific training. Finally, to enhance the task-specific performance of LLM-based predictors, we discuss potential improvements, such as dataset-specific fine-tuning to LLMs. By developing tailored strategies for different tasks, we provide new insights for the future design of LLM-based predictors.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BANet: Bilateral Aggregation Network for Mobile Stereo Matching</title>
<link>https://arxiv.org/abs/2503.03259</link>
<guid>https://arxiv.org/abs/2503.03259</guid>
<content:encoded><![CDATA[
<div> 关键词：立体匹配、2D卷积、成本聚合、双边聚合网络（BANet）、移动设备

总结:
在这篇文章中，研究者提出了一种针对移动设备的新型立体匹配算法——双边聚合网络（BANet），旨在解决使用传统3D卷积进行成本聚合所面临的计算复杂度问题。BANet利用2D卷积实现高精度的立体匹配效果，通过一种空间注意力图将全成本体积分离为精细和光滑两个部分，再分别进行精细化和光滑化的聚合处理，最终融合得到视差图。为了准确识别高低频区域，文章还提出了一个新的尺度感知空间注意力模块。实验结果显示，BANet-2D在KITTI 2015数据集上的表现优于其他移动端友好的方法，其精度比MobileStereoNet-2D高出35.3%，并且在移动设备上运行速度更快。此外，BANet-3D版本在高端GPU上的实时方法中实现了最高的准确性。

<br /><br />总结: 研究团队针对移动设备设计了名为BANet的立体匹配算法，采用2D卷积实现高质量的成本聚合，解决了3D卷积计算量大的难题。通过空间注意力机制将成本体积分离并分别处理，有效保留边缘清晰度和细节信息。提出的尺度感知空间注意力模块能精确识别不同频率区域。实验显示，BANet-2D在精度和运行速度方面均优于同类移动端友好的立体匹配方法，在KTTI 2015测试集上精度提高了35.3%；而BANet-3D版本则在高性能GPU上成为实时方法中的精度冠军。相应代码已开源，链接见文末。 <div>
arXiv:2503.03259v1 Announce Type: new 
Abstract: State-of-the-art stereo matching methods typically use costly 3D convolutions to aggregate a full cost volume, but their computational demands make mobile deployment challenging. Directly applying 2D convolutions for cost aggregation often results in edge blurring, detail loss, and mismatches in textureless regions. Some complex operations, like deformable convolutions and iterative warping, can partially alleviate this issue; however, they are not mobile-friendly, limiting their deployment on mobile devices. In this paper, we present a novel bilateral aggregation network (BANet) for mobile stereo matching that produces high-quality results with sharp edges and fine details using only 2D convolutions. Specifically, we first separate the full cost volume into detailed and smooth volumes using a spatial attention map, then perform detailed and smooth aggregations accordingly, ultimately fusing both to obtain the final disparity map. Additionally, to accurately identify high-frequency detailed regions and low-frequency smooth/textureless regions, we propose a new scale-aware spatial attention module. Experimental results demonstrate that our BANet-2D significantly outperforms other mobile-friendly methods, achieving 35.3\% higher accuracy on the KITTI 2015 leaderboard than MobileStereoNet-2D, with faster runtime on mobile devices. The extended 3D version, BANet-3D, achieves the highest accuracy among all real-time methods on high-end GPUs. Code: \textcolor{magenta}{https://github.com/gangweiX/BANet}.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trajectory Prediction for Autonomous Driving: Progress, Limitations, and Future Directions</title>
<link>https://arxiv.org/abs/2503.03262</link>
<guid>https://arxiv.org/abs/2503.03262</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主驾驶车辆、轨迹预测、安全导航、预测方法、研究挑战

总结:
随着自主驾驶车辆大规模融入现代交通系统的可能性不断增加，确保其在动态环境中安全导航至关重要。为了保证安全并防止碰撞，自主驾驶车辆需要能够准确预测周围交通参与者的轨迹。过去十年间，学术界和工业界对精确轨迹预测方法的设计投入了大量努力，产生了多种多样的解决方案。本文回顾了大量的近期轨迹预测方法，并提出了一个分类现有解决方案的taxonomy。文章还概述了预测管道的一般流程，包括输入和输出模态、建模特征以及文献中讨论的预测范式。此外，论文还讨论了轨迹预测领域的活跃研究方向，回答了提出的研究问题，并指出了剩余的研究空白和挑战。 <div>
arXiv:2503.03262v1 Announce Type: new 
Abstract: As the potential for autonomous vehicles to be integrated on a large scale into modern traffic systems continues to grow, ensuring safe navigation in dynamic environments is crucial for smooth integration. To guarantee safety and prevent collisions, autonomous vehicles must be capable of accurately predicting the trajectories of surrounding traffic agents. Over the past decade, significant efforts from both academia and industry have been dedicated to designing solutions for precise trajectory forecasting. These efforts have produced a diverse range of approaches, raising questions about the differences between these methods and whether trajectory prediction challenges have been fully addressed. This paper reviews a substantial portion of recent trajectory prediction methods and devises a taxonomy to classify existing solutions. A general overview of the prediction pipeline is also provided, covering input and output modalities, modeling features, and prediction paradigms discussed in the literature. In addition, the paper discusses active research areas within trajectory prediction, addresses the posed research questions, and highlights the remaining research gaps and challenges.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Which books do I like?</title>
<link>https://arxiv.org/abs/2503.03300</link>
<guid>https://arxiv.org/abs/2503.03300</guid>
<content:encoded><![CDATA[
<div> 关键词：ISAAC方法、人工智能、小说推荐、读者品味、个性化推荐

总结:
<br />
本文介绍了ISAAC方法，这是一种结合了用户反馈、AI注解和图书策划的管道系统，旨在帮助小说读者更好地了解自己的文学喜好并找到喜好的书籍。该方法包括用户对书籍进行评级、AI代理研究并注释这些书籍、用户审查书籍享受模式以及AI代理推荐新书四个步骤。在一项自我案例研究中，作者验证了ISAAC能够突出其个人化的阅读偏好模式，引发对其文学口味的深入反思，并提供准确、个性化的荐书服务及发掘未被充分探索的文学领域。然而，ISAAC也存在一些缺点，如若过度依赖统计模式可能会导致错误的自我认知，缺乏在线资料的书籍无法得到注解，以及新手读者可能需要依赖假设的书籍评分或电影评分来驱动ISAAC流程。此外，文章还探讨了ISAAC风格的图书注解对于研究文学趋势和科学分类书籍与读者的可能性。 <div>
arXiv:2503.03300v1 Announce Type: new 
Abstract: Finding enjoyable fiction books can be challenging, partly because stories are multi-faceted and one's own literary taste might be difficult to ascertain. Here, we introduce the ISAAC method (Introspection-Support, AI-Annotation, and Curation), a pipeline which supports fiction readers in gaining awareness of their literary preferences and finding enjoyable books. ISAAC consists of four steps: a user supplies book ratings, an AI agent researches and annotates the provided books, patterns in book enjoyment are reviewed by the user, and the AI agent recommends new books. In this proof-of-concept self-study, the authors test whether ISAAC can highlight idiosyncratic patterns in their book enjoyment, spark a deeper reflection about their literary tastes, and make accurate, personalized recommendations of enjoyable books and underexplored literary niches. Results highlight substantial advantages of ISAAC over existing methods such as an integration of automation and intuition, accurate and customizable annotations, and explainable book recommendations. Observed disadvantages are that ISAAC's outputs can elicit false self-narratives (if statistical patterns are taken at face value), that books cannot be annotated if their online documentation is lacking, and that people who are new to reading have to rely on assumed book ratings or movie ratings to power the ISAAC pipeline. We discuss additional opportunities of ISAAC-style book annotations for the study of literary trends, and the scientific classification of books and readers.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SEOE: A Scalable and Reliable Semantic Evaluation Framework for Open Domain Event Detection</title>
<link>https://arxiv.org/abs/2503.03303</link>
<guid>https://arxiv.org/abs/2503.03303</guid>
<content:encoded><![CDATA[
<div> 关键词: Open Domain Event Detection (ODED), 自动评价, 评估基准, 语义级评价框架, 大规模语言模型

总结:
本文提出了一个针对开放域事件检测(ODED)的可扩展且可靠的语义级评价框架SEOE。该框架旨在解决现有评价方法面临的两个问题：一是受限的评价基准缺乏对真实世界的代表性，难以准确反映各类ODED方法在实际场景中的性能；二是基于token级别匹配规则的评价指标无法捕捉预测结果与黄金标签之间的语义相似性。SEOE首先构建了一个包含7大领域、564种事件类型的更具代表性的评价基准，并采用了一种成本效益高的补充标注策略，便于未来添加新的事件类型和领域。接着，SEOE利用大规模语言模型作为自动评价代理来计算语义F1分数，通过引入细粒度的语义相似标签定义以增强评价的可靠性。实验验证了新基准的代表性以及语义评价指标的可靠性，并对现有ODED方法进行了深入评估，分析了预测错误模式，揭示了一系列有价值的发现。 <div>
arXiv:2503.03303v1 Announce Type: new 
Abstract: Automatic evaluation for Open Domain Event Detection (ODED) is a highly challenging task, because ODED is characterized by a vast diversity of un-constrained output labels from various domains. Nearly all existing evaluation methods for ODED usually first construct evaluation benchmarks with limited labels and domain coverage, and then evaluate ODED methods using metrics based on token-level label matching rules. However, this kind of evaluation framework faces two issues: (1) The limited evaluation benchmarks lack representatives of the real world, making it difficult to accurately reflect the performance of various ODED methods in real-world scenarios; (2) Evaluation metrics based on token-level matching rules fail to capture semantic similarity between predictions and golden labels. To address these two problems above, we propose a scalable and reliable Semantic-level Evaluation framework for Open domain Event detection (SEOE) by constructing a more representative evaluation benchmark and introducing a semantic evaluation metric. Specifically, our proposed framework first constructs a scalable evaluation benchmark that currently includes 564 event types covering 7 major domains, with a cost-effective supplementary annotation strategy to ensure the benchmark's representativeness. The strategy also allows for the supplement of new event types and domains in the future. Then, the proposed SEOE leverages large language models (LLMs) as automatic evaluation agents to compute a semantic F1-score, incorporating fine-grained definitions of semantically similar labels to enhance the reliability of the evaluation. Extensive experiments validate the representatives of the benchmark and the reliability of the semantic evaluation metric. Existing ODED methods are thoroughly evaluated, and the error patterns of predictions are analyzed, revealing several insightful findings.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent DRL for Queue-Aware Task Offloading in Hierarchical MEC-Enabled Air-Ground Networks</title>
<link>https://arxiv.org/abs/2503.03391</link>
<guid>https://arxiv.org/abs/2503.03391</guid>
<content:encoded><![CDATA[
<div> 关键词：Mobile edge computing, air-ground networks, unmanned aerial vehicles, MEC-enabled air-ground integrated networks, multi-agent Markov decision process

<br />
总结:
本文关注的是移动边缘计算(MEC)赋能的空地一体化网络(MAGIN)，该网络利用无人机(UAV)和高空平台站(HAPS)为地面物联网设备(IoTDs)提供动态服务。针对实时应用对高计算资源和严格服务质量(QoS)保障的需求，文章提出了一个联合优化UAV轨迹、计算资源分配以及队列感知的任务卸载决策的整体能耗最小化问题。由于此多层系统的非凸性和非线性特性，传统的解决方法难以奏效。为了解决这一问题，文章将原问题重新定义为具有连续动作空间和异质代理的多智能体马尔科夫决策过程(MDP)，并提出了一种新颖的多智能体亲和度策略优化带Beta分布(MAPPO-BD)算法来求解。通过大量的仿真实验表明，与基准方案相比，MAPPO-BD算法在满足队列延迟和边缘计算约束的同时，能实现MAGIN中更优的能量节省和高效的资源管理。 <div>
arXiv:2503.03391v1 Announce Type: new 
Abstract: Mobile edge computing (MEC)-enabled air-ground networks are a key component of 6G, employing aerial base stations (ABSs) such as unmanned aerial vehicles (UAVs) and high-altitude platform stations (HAPS) to provide dynamic services to ground IoT devices (IoTDs). These IoTDs support real-time applications (e.g., multimedia and Metaverse services) that demand high computational resources and strict quality of service (QoS) guarantees in terms of latency and task queue management. Given their limited energy and processing capabilities, IoTDs rely on UAVs and HAPS to offload tasks for distributed processing, forming a multi-tier MEC system. This paper tackles the overall energy minimization problem in MEC-enabled air-ground integrated networks (MAGIN) by jointly optimizing UAV trajectories, computing resource allocation, and queue-aware task offloading decisions. The optimization is challenging due to the nonconvex, nonlinear nature of this hierarchical system, which renders traditional methods ineffective. We reformulate the problem as a multi-agent Markov decision process (MDP) with continuous action spaces and heterogeneous agents, and propose a novel variant of multi-agent proximal policy optimization with a Beta distribution (MAPPO-BD) to solve it. Extensive simulations show that MAPPO-BD outperforms baseline schemes, achieving superior energy savings and efficient resource management in MAGIN while meeting queue delay and edge computing constraints.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoSDH: Communication-Efficient Collaborative Perception via Supply-Demand Awareness and Intermediate-Late Hybridization</title>
<link>https://arxiv.org/abs/2503.03430</link>
<guid>https://arxiv.org/abs/2503.03430</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作感知、通信效率、感知精度、供需意识、中间-后期混合化、\mymethodname

总结:
本文提出了一种名为"\mymethodname"的新颖通信高效的多智能体协作感知框架，旨在解决自动驾驶中单辆车辆感知能力弱的问题。该框架通过建立智能体之间的供需关系模型，优化了合作区域的选择，从而减少不必要的通信成本并保持感知准确性。同时，文章创新性地引入了中间-后期混合协同模式，以应对低通信带宽下协作感知性能下降的问题。通过对多个数据集进行广泛实验，包括模拟和真实场景，表明\mymethodname在检测精度上达到了state-of-the-art水平，并在带宽权衡上表现出最优效果，在实际通信带宽下实现了卓越的检测精度，证明了其有效性和实际应用潜力。相关代码将在https://github.com/Xu2729/CoSDH发布。<br /><br /> <div>
arXiv:2503.03430v1 Announce Type: new 
Abstract: Multi-agent collaborative perception enhances perceptual capabilities by utilizing information from multiple agents and is considered a fundamental solution to the problem of weak single-vehicle perception in autonomous driving. However, existing collaborative perception methods face a dilemma between communication efficiency and perception accuracy. To address this issue, we propose a novel communication-efficient collaborative perception framework based on supply-demand awareness and intermediate-late hybridization, dubbed as \mymethodname. By modeling the supply-demand relationship between agents, the framework refines the selection of collaboration regions, reducing unnecessary communication cost while maintaining accuracy. In addition, we innovatively introduce the intermediate-late hybrid collaboration mode, where late-stage collaboration compensates for the performance degradation in collaborative perception under low communication bandwidth. Extensive experiments on multiple datasets, including both simulated and real-world scenarios, demonstrate that \mymethodname~ achieves state-of-the-art detection accuracy and optimal bandwidth trade-offs, delivering superior detection precision under real communication bandwidths, thus proving its effectiveness and practical applicability. The code will be released at https://github.com/Xu2729/CoSDH.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Taxation Perspectives from Large Language Models: A Case Study on Additional Tax Penalties</title>
<link>https://arxiv.org/abs/2503.03444</link>
<guid>https://arxiv.org/abs/2503.03444</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、税收、PLAT、基准测试、法律理解

总结:
本文介绍了对大型语言模型（LLMs）在税收领域能力的研究。目前针对税务领域的研究较为匮乏，且相关数据集要么过于简化，未能反映实际复杂性，要么未开放源代码。为此，文章提出了一种新的基准测试工具——PLAT，用于评估LLMs预测额外税款处罚合法性的能力，特别是那些需要深入理解和解决冲突问题的情况。实验结果显示，LLMs的基础能力有限，但在启用检索功能、自我推理以及让多个具有特定角色分配的代理进行讨论后，这一局限性可以得到缓解。 <div>
arXiv:2503.03444v1 Announce Type: new 
Abstract: How capable are large language models (LLMs) in the domain of taxation? Although numerous studies have explored the legal domain in general, research dedicated to taxation remain scarce. Moreover, the datasets used in these studies are either simplified, failing to reflect the real-world complexities, or unavailable as open source. To address this gap, we introduce PLAT, a new benchmark designed to assess the ability of LLMs to predict the legitimacy of additional tax penalties. PLAT is constructed to evaluate LLMs' understanding of tax law, particularly in cases where resolving the issue requires more than just applying related statutes. Our experiments with six LLMs reveal that their baseline capabilities are limited, especially when dealing with conflicting issues that demand a comprehensive understanding. However, we found that enabling retrieval, self-reasoning, and discussion among multiple agents with specific role assignments, this limitation can be mitigated.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unified Mind Model: Reimagining Autonomous Agents in the LLM Era</title>
<link>https://arxiv.org/abs/2503.03459</link>
<guid>https://arxiv.org/abs/2503.03459</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、通用自主代理、统一心智模型、MindOS、认知架构

<br /><br />总结:
本文提出了一种新的理论认知架构——统一心智模型(UMM)，旨在为快速创建具有人类水平认知能力的自主智能体提供指导。UMM基于全局工作空间理论，并利用大型语言模型的能力，使智能体具备多模态感知、规划、推理、工具使用、学习、记忆、反思和动机等多元认知功能。在此基础上，文章还开发了一个名为MindOS的智能体构建引擎，用户无需编程即可快速创建特定领域或任务的自主智能体。 <div>
arXiv:2503.03459v1 Announce Type: new 
Abstract: Large language models (LLMs) have recently demonstrated remarkable capabilities across domains, tasks, and languages (e.g., ChatGPT and GPT-4), reviving the research of general autonomous agents with human-like cognitive abilities.Such human-level agents require semantic comprehension and instruction-following capabilities, which exactly fall into the strengths of LLMs.Although there have been several initial attempts to build human-level agents based on LLMs, the theoretical foundation remains a challenging open problem. In this paper, we propose a novel theoretical cognitive architecture, the Unified Mind Model (UMM), which offers guidance to facilitate the rapid creation of autonomous agents with human-level cognitive abilities. Specifically, our UMM starts with the global workspace theory and further leverage LLMs to enable the agent with various cognitive abilities, such as multi-modal perception, planning, reasoning, tool use, learning, memory, reflection and motivation. Building upon UMM, we then develop an agent-building engine, MindOS, which allows users to quickly create domain-/task-specific autonomous agents without any programming effort.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Open-Source Large Language Models as Multilingual Crowdworkers: Synthesizing Open-Domain Dialogues in Several Languages With No Examples in Targets and No Machine Translation</title>
<link>https://arxiv.org/abs/2503.03462</link>
<guid>https://arxiv.org/abs/2503.03462</guid>
<content:encoded><![CDATA[
<div> 关键词: Open-Domain Dialogue, 多语言, 大规模语言模型, 指令调优, 机器翻译

<br /><br />总结:
该文提出了一种利用大规模语言模型生成多目标语言开放领域对话数据的新方法。鉴于当前对话代理领域主要关注英文并需要大量资源进行多语言数据集的众包，研究者们利用指令调优技术，使LLM能够根据自然语言指令执行任务并在单一线程中处理多种语言。这种方法避免了直接使用机器翻译，从而更好地保留了特定语言的语境和细微差别。通过以一种源语言为示范，该文介绍了一个生成多语言PersonaChat对话数据的管道，并结合了对话类型的 speech events 和代表对话前提的共同基础元素，旨在增强生成对话的开放性和现实感。 <div>
arXiv:2503.03462v1 Announce Type: new 
Abstract: The prevailing paradigm in the domain of Open-Domain Dialogue agents predominantly focuses on the English language, encompassing both models and datasets. Furthermore, the financial and temporal investments required for crowdsourcing such datasets for finetuning are substantial, particularly when multiple languages are involved. Fortunately, advancements in Large Language Models (LLMs) have unveiled a plethora of possibilities across diverse tasks. Specifically, instruction-tuning has enabled LLMs to execute tasks based on natural language instructions, occasionally surpassing the performance of human crowdworkers. Additionally, these models possess the capability to function in various languages within a single thread. Consequently, to generate new samples in different languages, we propose leveraging these capabilities to replicate the data collection process. We introduce a pipeline for generating Open-Domain Dialogue data in multiple Target Languages using LLMs, with demonstrations provided in a unique Source Language. By eschewing explicit Machine Translation in this approach, we enhance the adherence to language-specific nuances. We apply this methodology to the PersonaChat dataset. To enhance the openness of generated dialogues and mimic real life scenarii, we added the notion of speech events corresponding to the type of conversation the speakers are involved in and also that of common ground which represents the premises of a conversation.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Parallelized Planning-Acting for Efficient LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.03505</link>
<guid>https://arxiv.org/abs/2503.03505</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 多智能体系统, 串行执行, 并行规划行动框架, 中心化内存系统

总结:<br />
本文提出了一种针对基于大型语言模型（LLM）的多智能体系统（MAS）的新型并行规划-行动框架。该框架旨在解决现有方法中智能体执行序列化导致的实时响应和适应性不足的问题。文章重点介绍了框架的双线程架构，包括：(1) 由中心化内存系统驱动的规划线程，负责维护环境状态同步与智能体间的通信，支持动态决策；(2) 配备全面技能库的行动线程，能够通过递归分解实现自动化任务执行。实验在具有挑战性的Minecraft环境中验证了该框架的有效性。 <div>
arXiv:2503.03505v1 Announce Type: new 
Abstract: Recent advancements in Large Language Model(LLM)-based Multi-Agent Systems(MAS) have demonstrated remarkable potential for tackling complex decision-making tasks. However, existing frameworks inevitably rely on serialized execution paradigms, where agents must complete sequential LLM planning before taking action. This fundamental constraint severely limits real-time responsiveness and adaptation, which is crucial in dynamic environments with ever-changing scenarios. In this paper, we propose a novel parallelized planning-acting framework for LLM-based MAS, featuring a dual-thread architecture with interruptible execution to enable concurrent planning and acting. Specifically, our framework comprises two core threads:(1) a planning thread driven by a centralized memory system, maintaining synchronization of environmental states and agent communication to support dynamic decision-making; and (2) an acting thread equipped with a comprehensive skill library, enabling automated task execution through recursive decomposition. Extensive experiments on challenging Minecraft demonstrate the effectiveness of the proposed framework.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TeraSim: Uncovering Unknown Unsafe Events for Autonomous Vehicles through Generative Simulation</title>
<link>https://arxiv.org/abs/2503.03629</link>
<guid>https://arxiv.org/abs/2503.03629</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通模拟、自动驾驶车辆(AV)、TeraSim、高保真、安全评估

总结:
 <div>
arXiv:2503.03629v1 Announce Type: new 
Abstract: Traffic simulation is essential for autonomous vehicle (AV) development, enabling comprehensive safety evaluation across diverse driving conditions. However, traditional rule-based simulators struggle to capture complex human interactions, while data-driven approaches often fail to maintain long-term behavioral realism or generate diverse safety-critical events. To address these challenges, we propose TeraSim, an open-source, high-fidelity traffic simulation platform designed to uncover unknown unsafe events and efficiently estimate AV statistical performance metrics, such as crash rates. TeraSim is designed for seamless integration with third-party physics simulators and standalone AV stacks, to construct a complete AV simulation system. Experimental results demonstrate its effectiveness in generating diverse safety-critical events involving both static and dynamic agents, identifying hidden deficiencies in AV systems, and enabling statistical performance evaluation. These findings highlight TeraSim's potential as a practical tool for AV safety assessment, benefiting researchers, developers, and policymakers. The code is available at https://github.com/mcity/TeraSim.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Motion Planning and Control with Unknown Nonlinear Dynamics through Predicted Reachability</title>
<link>https://arxiv.org/abs/2503.03633</link>
<guid>https://arxiv.org/abs/2503.03633</guid>
<content:encoded><![CDATA[
<div> 关键词：自主运动规划、非线性动力学、混合规划控制框架、状态空间分割、预测可达性条件

总结:
<br />
本文提出了一种针对未知非线性动力学环境下的自主运动规划方法。该方法采用一种混合规划控制框架，首先将系统状态空间进行划分并利用局部线性化的Piecewise Affine（PWA）系统模型，结合约束控制输入对系统进行近似描述。通过构建有向加权图来抽象化PWA系统，并基于仿射系统识别和到达控制理论，逐步更新图中边的存在情况，引入了利用未知动态先验信息的预测可达性条件。对于图中的边，根据其存在确定性与否赋予启发式权重。此外，本研究提出一种自适应数据收集与分析框架，能够在任务执行过程中不断更新预测图，并依据图搜索结果在线合成控制器。通过单积分器模型抽象的移动机器人在未知地形中的仿真场景验证了该方法的有效性。 <div>
arXiv:2503.03633v1 Announce Type: new 
Abstract: Autonomous motion planning under unknown nonlinear dynamics presents significant challenges. An agent needs to continuously explore the system dynamics to acquire its properties, such as reachability, in order to guide system navigation adaptively. In this paper, we propose a hybrid planning-control framework designed to compute a feasible trajectory toward a target. Our approach involves partitioning the state space and approximating the system by a piecewise affine (PWA) system with constrained control inputs. By abstracting the PWA system into a directed weighted graph, we incrementally update the existence of its edges via affine system identification and reach control theory, introducing a predictive reachability condition by exploiting prior information of the unknown dynamics. Heuristic weights are assigned to edges based on whether their existence is certain or remains indeterminate. Consequently, we propose a framework that adaptively collects and analyzes data during mission execution, continually updates the predictive graph, and synthesizes a controller online based on the graph search outcomes. We demonstrate the efficacy of our approach through simulation scenarios involving a mobile robot operating in unknown terrains, with its unknown dynamics abstracted as a single integrator model.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Generative Approach to High Fidelity 3D Reconstruction from Text Data</title>
<link>https://arxiv.org/abs/2503.03664</link>
<guid>https://arxiv.org/abs/2503.03664</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、生成模型、3D重建、图像处理、深度学习

总结:<br />
本文介绍了一种将文本描述转化为三维表示的新方法，该方法结合了生成式人工智能和高级计算机视觉技术。研究提出了一种全自动工作流，利用Stable Diffusion等最先进的生成模型，通过多阶段流程将自然语言输入转化为详细三维模型。此过程包括从文本提示生成高质量图像、使用强化学习进行图像增强及反射去除、应用高级图像缩放和背景移除技术提升视觉保真度，以及借助机器学习算法将优化后的二维图像转化为具有精细空间关系和几何特征的三维模型。这种方法解决了保持语义连贯性、管理几何复杂性和保留详细视觉信息等关键挑战，并计划进行全面实验评估以验证其在不同领域和复杂程度下的重构质量、语义准确性和几何精确度。这项研究展示了AI驱动的3D重建技术在增强现实（AR）、虚拟现实（VR）和数字内容创作等领域的重要潜力。 <div>
arXiv:2503.03664v1 Announce Type: new 
Abstract: The convergence of generative artificial intelligence and advanced computer vision technologies introduces a groundbreaking approach to transforming textual descriptions into three-dimensional representations. This research proposes a fully automated pipeline that seamlessly integrates text-to-image generation, various image processing techniques, and deep learning methods for reflection removal and 3D reconstruction. By leveraging state-of-the-art generative models like Stable Diffusion, the methodology translates natural language inputs into detailed 3D models through a multi-stage workflow.
  The reconstruction process begins with the generation of high-quality images from textual prompts, followed by enhancement by a reinforcement learning agent and reflection removal using the Stable Delight model. Advanced image upscaling and background removal techniques are then applied to further enhance visual fidelity. These refined two-dimensional representations are subsequently transformed into volumetric 3D models using sophisticated machine learning algorithms, capturing intricate spatial relationships and geometric characteristics. This process achieves a highly structured and detailed output, ensuring that the final 3D models reflect both semantic accuracy and geometric precision.
  This approach addresses key challenges in generative reconstruction, such as maintaining semantic coherence, managing geometric complexity, and preserving detailed visual information. Comprehensive experimental evaluations will assess reconstruction quality, semantic accuracy, and geometric fidelity across diverse domains and varying levels of complexity. By demonstrating the potential of AI-driven 3D reconstruction techniques, this research offers significant implications for fields such as augmented reality (AR), virtual reality (VR), and digital content creation.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Attentive Reasoning Queries: A Systematic Method for Optimizing Instruction-Following in Large Language Models</title>
<link>https://arxiv.org/abs/2503.03669</link>
<guid>https://arxiv.org/abs/2503.03669</guid>
<content:encoded><![CDATA[
<div> 关键词：Attentive Reasoning Queries (ARQs)、Large Language Models、structured reasoning、Parlant、Chain-of-Thought reasoning

<br /><br />总结:

本文介绍了Attentive Reasoning Queries (ARQs)，这是一种新型的结构化推理方法，通过领域专用的推理蓝图显著提高了大型语言模型在遵循复杂指令方面的性能。研究表明，虽然LLMs在各种任务中展现出强大的能力，但在多轮对话中常常无法严格遵守特定使用场景的复杂指令。ARQs通过针对性的问题引导LLMs进行系统性推理步骤，重新强调关键指令并促进完成过程中的中间推理。在名为Parlant的框架中，ARQs在87个测试场景中的成功率达到了90.2%，优于Chain-of-Thought推理（86.1%）和直接响应生成（81.5%）。特别是在处理如指南重申和幻觉预防等持久性失败模式方面表现出色。此外，分析还表明，精心设计的ARQs可能比自由形式推理更具计算效率。这些发现证实了结构化推理方法为控制LLMs在复杂场景中处理信息和决策提供了有效机制。 <div>
arXiv:2503.03669v1 Announce Type: new 
Abstract: We present Attentive Reasoning Queries (ARQs), a novel structured reasoning approach that significantly improves instruction-following in Large Language Models through domain-specialized reasoning blueprints. While LLMs demonstrate remarkable capabilities across diverse tasks, they often fail to maintain adherence to complex, use-case-specific instructions during multi-turn conversations, presenting challenges for business-critical applications. ARQs address this limitation by guiding LLMs through systematic reasoning steps with targeted queries that reinstate critical instructions and facilitate intermediate reasoning throughout the completion process. In extensive testing within Parlant, our framework for reliable customer-facing agents in which ARQs were born out of necessity, they achieved a 90.2% success rate across 87 test scenarios, outperforming both Chain-of-Thought reasoning (86.1%) and direct response generation (81.5%). ARQs showed particular strength in addressing persistent failure modes like guideline re-application and hallucination prevention. Our analysis also revealed that ARQs can potentially be more computationally efficient than free-form reasoning when carefully designed. These findings demonstrate that structured reasoning approaches provide effective mechanisms for controlling how LLMs process information and make decisions in complex scenarios.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimally Installing Strict Equilibria</title>
<link>https://arxiv.org/abs/2503.03676</link>
<guid>https://arxiv.org/abs/2503.03676</guid>
<content:encoded><![CDATA[
<div> 关键词：reward design framework、desired behavior、strict equilibrium、solution concepts、bounded rational agents

总结:<br />
本文提出了一种奖励设计框架，旨在为标准解决方案概念（包括占优策略均衡、纳什均衡、相关均衡和粗相关均衡以及它们的马尔科夫完美的等价形式）安装期望行为作为严格的均衡。该框架深入分析了基于所期望的解决方案概念及行为结构的严格可安装性的全面数学特征。这些特征引出了可用于处理优化目标的有效迭代算法，并通过线性规划进行推广。最后，文章探讨了研究结果如何扩展到有限理性的代理模型。 <div>
arXiv:2503.03676v1 Announce Type: new 
Abstract: In this work, we develop a reward design framework for installing a desired behavior as a strict equilibrium across standard solution concepts: dominant strategy equilibrium, Nash equilibrium, correlated equilibrium, and coarse correlated equilibrium. We also extend our framework to capture the Markov-perfect equivalents of each solution concept. Central to our framework is a comprehensive mathematical characterization of strictly installable, based on the desired solution concept and the behavior's structure. These characterizations lead to efficient iterative algorithms, which we generalize to handle optimization objectives through linear programming. Finally, we explore how our results generalize to bounded rational agents.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAS-GPT: Training LLMs to Build LLM-based Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.03686</link>
<guid>https://arxiv.org/abs/2503.03686</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM（大型语言模型）、多智能体系统(MAS)、生成式任务、MAS-GPT、高效率

总结:
本文提出了一种简化多智能体系统(MAS)设计的方法，将该过程重新定义为一种生成语言任务。通过将MAS表示为可执行代码并构建一致性导向的数据构造管道来创建高质量的查询-MAS对数据集。利用这个数据集训练了一个名为MAS-GPT的开源中型LLM，该模型能够在单次LLM推理过程中生成适应用户查询的MAS。实验表明，MAS-GPT在九个基准测试和五个LLM上均优于十多个基线MAS方法，显示出其在多样性设置下的高效性、优越性能和强大的泛化能力。相关代码将在https://github.com/rui-ye/MAS-GPT上开源发布。 <div>
arXiv:2503.03686v1 Announce Type: new 
Abstract: LLM-based multi-agent systems (MAS) have shown significant potential in tackling diverse tasks. However, to design effective MAS, existing approaches heavily rely on manual configurations or multiple calls of advanced LLMs, resulting in inadaptability and high inference costs. In this paper, we simplify the process of building an MAS by reframing it as a generative language task, where the input is a user query and the output is a corresponding MAS. To address this novel task, we unify the representation of MAS as executable code and propose a consistency-oriented data construction pipeline to create a high-quality dataset comprising coherent and consistent query-MAS pairs. Using this dataset, we train MAS-GPT, an open-source medium-sized LLM that is capable of generating query-adaptive MAS within a single LLM inference. The generated MAS can be seamlessly applied to process user queries and deliver high-quality responses. Extensive experiments on 9 benchmarks and 5 LLMs show that the proposed MAS-GPT consistently outperforms 10+ baseline MAS methods on diverse settings, indicating MAS-GPT's high effectiveness, efficiency and strong generalization ability. Code will be available at https://github.com/rui-ye/MAS-GPT.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Practical Memory Injection Attack against LLM Agents</title>
<link>https://arxiv.org/abs/2503.03704</link>
<guid>https://arxiv.org/abs/2503.03704</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、攻击、记忆注入、恶意记录、MINJA

总结:
<br />
本文提出了一种针对基于大型语言模型(LLM)代理的记忆注入攻击方法——MINJA。MINJA仅通过与代理进行查询和输出观察交互，即可向其记忆库中注入恶意记录。这些恶意记录设计用于引导代理执行一系列恶意推理步骤，从而在处理受害用户查询时产生不良行为。具体而言，文中引入了桥接步骤来将受害查询链接到恶意推理步骤，并提出了指示提示以指导代理自动生成这些桥接步骤。同时，为使恶意记录在处理受害查询时更容易被检索到，文章还提出了逐步缩短策略，逐渐移除指示提示。实验结果显示MINJA对多种类型代理的记忆库的有效性构成了实际威胁，表明了LLM代理具有潜在的风险。 <div>
arXiv:2503.03704v1 Announce Type: new 
Abstract: Agents based on large language models (LLMs) have demonstrated strong capabilities in a wide range of complex, real-world applications. However, LLM agents with a compromised memory bank may easily produce harmful outputs when the past records retrieved for demonstration are malicious. In this paper, we propose a novel Memory INJection Attack, MINJA, that enables the injection of malicious records into the memory bank by only interacting with the agent via queries and output observations. These malicious records are designed to elicit a sequence of malicious reasoning steps leading to undesirable agent actions when executing the victim user's query. Specifically, we introduce a sequence of bridging steps to link the victim query to the malicious reasoning steps. During the injection of the malicious record, we propose an indication prompt to guide the agent to autonomously generate our designed bridging steps. We also propose a progressive shortening strategy that gradually removes the indication prompt, such that the malicious record will be easily retrieved when processing the victim query comes after. Our extensive experiments across diverse agents demonstrate the effectiveness of MINJA in compromising agent memory. With minimal requirements for execution, MINJA enables any user to influence agent memory, highlighting practical risks of LLM agents.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CHOP: Mobile Operating Assistant with Constrained High-frequency Optimized Subtask Planning</title>
<link>https://arxiv.org/abs/2503.03743</link>
<guid>https://arxiv.org/abs/2503.03743</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉语言模型(VLM)，移动设备操作，子任务，约束高频优化规划(CHOP)，多代理架构

<br /><br />总结:
本文提出了针对视觉语言模型在移动端操作系统中应用的新框架——约束高频优化规划（CHOP）。现有的VLM基移动助手在子任务层面存在两个挑战：一是低层代理无法执行的无效子任务，二是未能有效推进高层任务完成的低效子任务。这些挑战源于VLM在GUI场景下的多代理架构中缺乏子任务分解经验。为解决这些问题，CHOP架构利用人类预先规划的子任务作为基础向量，弥补了VLM在GUI场景规划中的不足。该研究分别在英语和汉语环境中，跨20款App进行了评估，显示出了在效果和效率上的显著提升。相关数据集和代码已公开发布在https://github.com/Yuqi-Zhou/CHOP上。 <div>
arXiv:2503.03743v1 Announce Type: new 
Abstract: The advancement of visual language models (VLMs) has enhanced mobile device operations, allowing simulated human-like actions to address user requirements. Current VLM-based mobile operating assistants can be structured into three levels: task, subtask, and action. The subtask level, linking high-level goals with low-level executable actions, is crucial for task completion but faces two challenges: ineffective subtasks that lower-level agent cannot execute and inefficient subtasks that fail to contribute to the completion of the higher-level task. These challenges stem from VLM's lack of experience in decomposing subtasks within GUI scenarios in multi-agent architecture. To address these, we propose a new mobile assistant architecture with constrained high-frequency o}ptimized planning (CHOP). Our approach overcomes the VLM's deficiency in GUI scenarios planning by using human-planned subtasks as the basis vector. We evaluate our architecture in both English and Chinese contexts across 20 Apps, demonstrating significant improvements in both effectiveness and efficiency. Our dataset and code is available at https://github.com/Yuqi-Zhou/CHOP
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The MASK Benchmark: Disentangling Honesty From Accuracy in AI Systems</title>
<link>https://arxiv.org/abs/2503.03750</link>
<guid>https://arxiv.org/abs/2503.03750</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、诚实性、基准测试、准确性、干预措施

<br /><br />总结: 本文关注大型语言模型（LLMs）的诚实性问题，指出随着LLMs能力增强和自主性提高，对其输出的信任度需求增大，但同时存在模型可能为达成目标而撒谎的担忧。现有的诚实性评估有限，缺乏大规模且适用于各类模型的基准测试，并且许多声称衡量诚实性的基准实际上只是在衡量模型信念的正确性（即准确性）。为此，文章提出了一项由人类收集的大规模诚实性测量数据集，首次能够将准确性和诚实性区分开来。研究发现，虽然更大规模的模型在基准测试上的准确性更高，但它们并未变得更诚实。令人惊讶的是，尽管前沿LLMs在真实性基准测试上得分较高，但在面临压力时却表现出显著的撒谎倾向，导致在新提出的诚实性基准测试上的得分较低。文章还发现，简单的表示学习干预方法可以提高模型的诚实性。这些结果强调了对LLMs进行稳健评估和有效干预以确保其保持可信赖的重要性。 <div>
arXiv:2503.03750v1 Announce Type: new 
Abstract: As large language models (LLMs) become more capable and agentic, the requirement for trust in their outputs grows significantly, yet at the same time concerns have been mounting that models may learn to lie in pursuit of their goals. To address these concerns, a body of work has emerged around the notion of "honesty" in LLMs, along with interventions aimed at mitigating deceptive behaviors. However, evaluations of honesty are currently highly limited, with no benchmark combining large scale and applicability to all models. Moreover, many benchmarks claiming to measure honesty in fact simply measure accuracy--the correctness of a model's beliefs--in disguise. In this work, we introduce a large-scale human-collected dataset for measuring honesty directly, allowing us to disentangle accuracy from honesty for the first time. Across a diverse set of LLMs, we find that while larger models obtain higher accuracy on our benchmark, they do not become more honest. Surprisingly, while most frontier LLMs obtain high scores on truthfulness benchmarks, we find a substantial propensity in frontier LLMs to lie when pressured to do so, resulting in low honesty scores on our benchmark. We find that simple methods, such as representation engineering interventions, can improve honesty. These results underscore the growing need for robust evaluations and effective interventions to ensure LLMs remain trustworthy.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Surgical Vision World Model</title>
<link>https://arxiv.org/abs/2503.02904</link>
<guid>https://arxiv.org/abs/2503.02904</guid>
<content:encoded><![CDATA[
<div> 关键词：手术模拟，世界模型，无标签数据，Genie，SurgToolLoc-2022数据集

总结:
该文提出了首个针对手术视觉的世界模型，旨在通过利用未标注的SurgToolLoc-2022数据集生成可控制行为的手术数据。文章指出，尽管自然视觉领域的世界模型已在交互式模拟环境中为训练自主代理提供了可能，但手术领域的相关工作仍局限于简化的计算机模拟，缺乏逼真性。此外，现有的世界模型研究大多处理带有动作标签的数据，而不适用于获取动作注释成本高昂的真实手术数据。受到Genie成功利用无标签电子游戏数据推断潜在动作并实现可控数据生成的启发，本文所提的手术视觉世界模型证明了其架构设计的有效性，并提供了代码和实现细节的开源链接。 <div>
arXiv:2503.02904v1 Announce Type: cross 
Abstract: Realistic and interactive surgical simulation has the potential to facilitate crucial applications, such as medical professional training and autonomous surgical agent training. In the natural visual domain, world models have enabled action-controlled data generation, demonstrating the potential to train autonomous agents in interactive simulated environments when large-scale real data acquisition is infeasible. However, such works in the surgical domain have been limited to simplified computer simulations, and lack realism. Furthermore, existing literature in world models has predominantly dealt with action-labeled data, limiting their applicability to real-world surgical data, where obtaining action annotation is prohibitively expensive. Inspired by the recent success of Genie in leveraging unlabeled video game data to infer latent actions and enable action-controlled data generation, we propose the first surgical vision world model. The proposed model can generate action-controllable surgical data and the architecture design is verified with extensive experiments on the unlabeled SurgToolLoc-2022 dataset. Codes and implementation details are available at https://github.com/bhattarailab/Surgical-Vision-World-Model
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PAC Learning with Improvements</title>
<link>https://arxiv.org/abs/2503.03184</link>
<guid>https://arxiv.org/abs/2503.03184</guid>
<content:encoded><![CDATA[
<div> 关键词: 样本复杂度、机器学习、零误差、可改善代理、改进能力

<br /><br />总结:
该文探讨了在机器学习中，当数据点（即代理）具有能通过努力提高自身属性以达到正向分类的能力时，允许代理改善的现象可能使我们实现零误差学习。文章指出，在一些非琐碎场景下，至少需要 $1/\epsilon$ 个样本才能将错误率降低到 $\epsilon$。然而，如果存在改进空间，只需对阈值做出接近真实的估计 $\hat{\theta}$（满足 $\theta \leq \hat{\theta} \leq \theta + r$），就有可能让所有真正合格的代理通过努力被正确分类。文中进一步研究了这种现象的一般性结果以及在何种条件下，代理的改进能力可以减少学习所需的样本复杂度，或者相反，可能会使得学习变得更加困难。同时，文章从理论和实证两方面分析了如何设计能够考虑有限改进意愿与能力的改进型算法。 <div>
arXiv:2503.03184v1 Announce Type: cross 
Abstract: One of the most basic lower bounds in machine learning is that in nearly any nontrivial setting, it takes $\textit{at least}$ $1/\epsilon$ samples to learn to error $\epsilon$ (and more, if the classifier being learned is complex). However, suppose that data points are agents who have the ability to improve by a small amount if doing so will allow them to receive a (desired) positive classification. In that case, we may actually be able to achieve $\textit{zero}$ error by just being "close enough". For example, imagine a hiring test used to measure an agent's skill at some job such that for some threshold $\theta$, agents who score above $\theta$ will be successful and those who score below $\theta$ will not (i.e., learning a threshold on the line). Suppose also that by putting in effort, agents can improve their skill level by some small amount $r$. In that case, if we learn an approximation $\hat{\theta}$ of $\theta$ such that $\theta \leq \hat{\theta} \leq \theta + r$ and use it for hiring, we can actually achieve error zero, in the sense that (a) any agent classified as positive is truly qualified, and (b) any agent who truly is qualified can be classified as positive by putting in effort. Thus, the ability for agents to improve has the potential to allow for a goal one could not hope to achieve in standard models, namely zero error.
  In this paper, we explore this phenomenon more broadly, giving general results and examining under what conditions the ability of agents to improve can allow for a reduction in the sample complexity of learning, or alternatively, can make learning harder. We also examine both theoretically and empirically what kinds of improvement-aware algorithms can take into account agents who have the ability to improve to a limited extent when it is in their interest to do so.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collaborative Expert LLMs Guided Multi-Objective Molecular Optimization</title>
<link>https://arxiv.org/abs/2503.03503</link>
<guid>https://arxiv.org/abs/2503.03503</guid>
<content:encoded><![CDATA[
<div> 关键词：MultiMol、多目标分子优化、大型语言模型、药物开发、成功率

总结:

本文介绍了MultiMol，这是一个针对多目标分子优化问题设计的协作型大型语言模型系统。该系统包括数据驱动的工作代理和文献引导的研究代理两部分，分别负责生成优化分子和挖掘相关文献中的先前知识。相较于现有方法，MultiMol在六个多目标优化任务上的成功率达到82.30%，显著优于当前最强方法的27.50%。为了验证其实用性，文章中还展示了两个实际案例：一是提升了Xanthine Amine Congener（XAC）对A1R的选择性，二是改善了HIV-1蛋白酶抑制剂Saquinavir的生物利用度。这些结果表明，MultiMol为多目标分子优化提供了一种极具前景的方法，有望加速药物开发进程并推动制药研究的进步。 <div>
arXiv:2503.03503v1 Announce Type: cross 
Abstract: Molecular optimization is a crucial yet complex and time-intensive process that often acts as a bottleneck for drug development. Traditional methods rely heavily on trial and error, making multi-objective optimization both time-consuming and resource-intensive. Current AI-based methods have shown limited success in handling multi-objective optimization tasks, hampering their practical utilization. To address this challenge, we present MultiMol, a collaborative large language model (LLM) system designed to guide multi-objective molecular optimization. MultiMol comprises two agents, including a data-driven worker agent and a literature-guided research agent. The data-driven worker agent is a large language model being fine-tuned to learn how to generate optimized molecules considering multiple objectives, while the literature-guided research agent is responsible for searching task-related literature to find useful prior knowledge that facilitates identifying the most promising optimized candidates. In evaluations across six multi-objective optimization tasks, MultiMol significantly outperforms existing methods, achieving a 82.30% success rate, in sharp contrast to the 27.50% success rate of current strongest methods. To further validate its practical impact, we tested MultiMol on two real-world challenges. First, we enhanced the selectivity of Xanthine Amine Congener (XAC), a promiscuous ligand that binds both A1R and A2AR, successfully biasing it towards A1R. Second, we improved the bioavailability of Saquinavir, an HIV-1 protease inhibitor with known bioavailability limitations. Overall, these results indicate that MultiMol represents a highly promising approach for multi-objective molecular optimization, holding great potential to accelerate the drug development process and contribute to the advancement of pharmaceutical research.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ExpertPrompting: Instructing Large Language Models to be Distinguished Experts</title>
<link>https://arxiv.org/abs/2305.14688</link>
<guid>https://arxiv.org/abs/2305.14688</guid>
<content:encoded><![CDATA[
<div> 关键词: ExpertPrompting、LLMs、In-Context Learning、ExpertLLaMA、ChatGPT

总结:
本文提出了一个名为ExpertPrompting的方法，旨在通过精心设计的提示来提升大型语言模型（LLMs）的回答质量，使其能以专家身份进行解答。该方法首先利用In-Context Learning自动为每条指令生成详细且定制化的专家身份描述，然后要求LLM基于这些背景信息给出答案。基于此策略，研究者使用GPT-3.5创建了一组新的指令遵循数据，并训练了一个名为ExpertLLaMA的开源聊天助手。通过基于GPT-4的评估，结果显示：1) 专家数据的质量显著高于常规答案；2) ExpertLLaMA超越了现有开源对手，其能力达到了原版ChatGPT的96%。所有相关数据和ExpertLLaMA模型将在https://github.com/OFA-Sys/ExpertLLaMA上公开发布。 <div>
arXiv:2305.14688v2 Announce Type: replace 
Abstract: The answering quality of an aligned large language model (LLM) can be drastically improved if treated with proper crafting of prompts. In this paper, we propose ExpertPrompting to elicit the potential of LLMs to answer as distinguished experts. We first utilize In-Context Learning to automatically synthesize detailed and customized descriptions of the expert identity for each specific instruction, and then ask LLMs to provide answer conditioned on such agent background. Based on this augmented prompting strategy, we produce a new set of instruction-following data using GPT-3.5, and train a competitive open-source chat assistant called ExpertLLaMA. We employ GPT4-based evaluation to show that 1) the expert data is of significantly higher quality than vanilla answers, and 2) ExpertLLaMA outperforms existing open-source opponents and achieves 96\% of the original ChatGPT's capability. All data and the ExpertLLaMA model will be made publicly available at https://github.com/OFA-Sys/ExpertLLaMA.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Narrowing the Gap between Adversarial and Stochastic MDPs via Policy Optimization</title>
<link>https://arxiv.org/abs/2407.05704</link>
<guid>https://arxiv.org/abs/2407.05704</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、对抗性马尔科夫决策过程、完全信息设置、算法、APO-MVP

总结:
本文研究了在具有 Oblivious 敌对环境的强化学习问题，即对抗性马尔科夫决策过程中（Adversarial MDPs）的学习策略。在每个由 $H$ 阶段组成的 $T$ 期互动中，奖励函数仅在每期结束时揭晓。文章提出了一种名为 APO-MVP 的新算法，该算法实现了 $\tilde{\mathcal{O}}(\mathrm{poly}(H)\sqrt{SAT})$ 的后悔界限，这一结果比此前最佳已知界限提高了 $\sqrt{S}$ 因子，从而弥合了对抗性和确定性 MDPs 之间的差距，并在 $S,A,T$ 的依赖关系上匹配了最小最大下界 $\Omega(\sqrt{H^3SAT})$。APO-MVP 算法基于动态规划和针对估计优势函数的黑盒在线线性优化策略进行政策优化，易于实现。其分析利用了两项最新技术：基于在线线性优化策略的政策优化（Jonckheere等人，2023年）以及关于通过估计转移核对值影响的精细鞅分析（Zhang等人，2023年）。 <div>
arXiv:2407.05704v2 Announce Type: replace 
Abstract: We consider the problem of learning in adversarial Markov decision processes [MDPs] with an oblivious adversary in a full-information setting. The agent interacts with an environment during $T$ episodes, each of which consists of $H$ stages, and each episode is evaluated with respect to a reward function that will be revealed only at the end of the episode. We propose an algorithm, called APO-MVP, that achieves a regret bound of order $\tilde{\mathcal{O}}(\mathrm{poly}(H)\sqrt{SAT})$, where $S$ and $A$ are sizes of the state and action spaces, respectively. This result improves upon the best-known regret bound by a factor of $\sqrt{S}$, bridging the gap between adversarial and stochastic MDPs, and matching the minimax lower bound $\Omega(\sqrt{H^3SAT})$ as far as the dependencies in $S,A,T$ are concerned. The proposed algorithm and analysis completely avoid the typical tool given by occupancy measures; instead, it performs policy optimization based only on dynamic programming and on a black-box online linear optimization strategy run over estimated advantage functions, making it easy to implement. The analysis leverages two recent techniques: policy optimization based on online linear optimization strategies (Jonckheere et al., 2023) and a refined martingale analysis of the impact on values of estimating transitions kernels (Zhang et al., 2023).
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey on Self-play Methods in Reinforcement Learning</title>
<link>https://arxiv.org/abs/2408.01072</link>
<guid>https://arxiv.org/abs/2408.01072</guid>
<content:encoded><![CDATA[
<div> 关键词: 自我对弈、强化学习、多智能体强化学习、游戏理论、算法框架<br /><br />总结:

本文介绍了自我对弈在强化学习领域的最新进展。文章首先明确了自我对弈的基本概念，包括多智能体强化学习框架和基础的游戏理论内容。接着，它提出了一种统一的自我对弈算法框架，并在此框架下对现有自我对弈算法进行了分类。此外，通过阐述自我对弈在不同场景中的作用，文章将这些算法与其实际应用联系起来。最后，论文指出了自我对弈面临的开放挑战以及未来的研究方向，为理解自我对弈在强化学习中的多元面貌提供了重要的指南。 <div>
arXiv:2408.01072v2 Announce Type: replace 
Abstract: Self-play, characterized by agents' interactions with copies or past versions of themselves, has recently gained prominence in reinforcement learning (RL). This paper first clarifies the preliminaries of self-play, including the multi-agent reinforcement learning framework and basic game theory concepts. Then, it provides a unified framework and classifies existing self-play algorithms within this framework. Moreover, the paper bridges the gap between the algorithms and their practical implications by illustrating the role of self-play in different scenarios. Finally, the survey highlights open challenges and future research directions in self-play. This paper is an essential guide map for understanding the multifaceted landscape of self-play in RL.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VerilogCoder: Autonomous Verilog Coding Agents with Graph-based Planning and Abstract Syntax Tree (AST)-based Waveform Tracing Tool</title>
<link>https://arxiv.org/abs/2408.08927</link>
<guid>https://arxiv.org/abs/2408.08927</guid>
<content:encoded><![CDATA[
<div> 关键词: Verilog, 自动化设计, 人工智能, 电路描述语言, VerilogCoder

总结:
本文提出了VerilogCoder，这是一个由多个人工智能代理组成的系统，用于自动生成和修复Verilog代码，以减轻现代集成电路设计中的错误。该系统利用一种新颖的任务与电路关系图检索方法构建任务计划，以根据模块描述生成全面的设计方案。为了解决功能错误调试问题，文中开发了一种基于抽象语法树（AST）的高效波形跟踪工具，并将其集成到自动Verilog代码完成流程中。实验结果显示，VerilogCoder在VerilogEval-Human v2基准测试中成功生成了94.2%语法和功能均正确的Verilog代码，相比现有最佳方法提升了33.9%的表现。 <div>
arXiv:2408.08927v2 Announce Type: replace 
Abstract: Due to the growing complexity of modern Integrated Circuits (ICs), automating hardware design can prevent a significant amount of human error from the engineering process and result in less errors. Verilog is a popular hardware description language for designing and modeling digital systems; thus, Verilog generation is one of the emerging areas of research to facilitate the design process. In this work, we propose VerilogCoder, a system of multiple Artificial Intelligence (AI) agents for Verilog code generation, to autonomously write Verilog code and fix syntax and functional errors using collaborative Verilog tools (i.e., syntax checker, simulator, and waveform tracer). Firstly, we propose a task planner that utilizes a novel Task and Circuit Relation Graph retrieval method to construct a holistic plan based on module descriptions. To debug and fix functional errors, we develop a novel and efficient abstract syntax tree (AST)-based waveform tracing tool, which is integrated within the autonomous Verilog completion flow. The proposed methodology successfully generates 94.2% syntactically and functionally correct Verilog code, surpassing the state-of-the-art methods by 33.9% on the VerilogEval-Human v2 benchmark.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mitigating the Stability-Plasticity Dilemma in Adaptive Train Scheduling with Curriculum-Driven Continual DQN Expansion</title>
<link>https://arxiv.org/abs/2408.09838</link>
<guid>https://arxiv.org/abs/2408.09838</guid>
<content:encoded><![CDATA[
<div> 关键词: 继续学习、稳定性-可塑性困境、列车调度问题、持续深度Q网络(DQN)扩展(CDE)、课程学习

<br /><br />总结:
本文关注于解决继续学习中的稳定性-可塑性困境，特别是在不断变化和复杂的多智能体环境如列车调度问题中。为了解决这一问题，作者提出了利用课程学习设计逐渐递进的技能训练序列以提升泛化性能。同时，他们提出了一个新的算法——持续深度Q网络(DQN)扩展(CDE)，该算法能动态生成并调整Q函数子空间以应对环境变化与任务需求。CDE通过EWC方法缓解灾难性遗忘现象，同时采用自适应有理激活函数保证了高可塑性。实验结果显示，相比于RL基线和其他适应性连续学习方法，CDE在学习效率和适应性上均有显著改善，显示出其在解决适应性列车调度设置中的稳定性-可塑性困境方面的潜力。 <div>
arXiv:2408.09838v2 Announce Type: replace 
Abstract: A continual learning agent builds on previous experiences to develop increasingly complex behaviors by adapting to non-stationary and dynamic environments while preserving previously acquired knowledge. However, scaling these systems presents significant challenges, particularly in balancing the preservation of previous policies with the adaptation of new ones to current environments. This balance, known as the stability-plasticity dilemma, is especially pronounced in complex multi-agent domains such as the train scheduling problem, where environmental and agent behaviors are constantly changing, and the search space is vast. In this work, we propose addressing these challenges in the train scheduling problem using curriculum learning. We design a curriculum with adjacent skills that build on each other to improve generalization performance. Introducing a curriculum with distinct tasks introduces non-stationarity, which we address by proposing a new algorithm: Continual Deep Q-Network (DQN) Expansion (CDE). Our approach dynamically generates and adjusts Q-function subspaces to handle environmental changes and task requirements. CDE mitigates catastrophic forgetting through EWC while ensuring high plasticity using adaptive rational activation functions. Experimental results demonstrate significant improvements in learning efficiency and adaptability compared to RL baselines and other adapted methods for continual learning, highlighting the potential of our method in managing the stability-plasticity dilemma in the adaptive train scheduling setting.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Synchronization in Learning in Periodic Zero-Sum Games Triggers Divergence from Nash Equilibrium</title>
<link>https://arxiv.org/abs/2408.10595</link>
<guid>https://arxiv.org/abs/2408.10595</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体学习、零和游戏、周期性游戏、同步、纳什均衡

总结:
本文研究了在周期性变化的零和游戏中，多个竞争学习策略的智能体的行为。当游戏变化速度与玩家学习速度相同步时，学习动态会发散，时间平均值不收敛；反之，则尽管学习动态表现出复杂的循环行为，但其时间平均值仍能收敛。文章提出了适用于动态系统分析的一些假设，并证明了这一现象。实验进一步观察到，即使在移除这些假设的情况下，这种同步现象依然存在。该研究揭示了一种新的现象——同步现象，为理解周期性游戏中学习动态提供了广泛的应用洞察。 <div>
arXiv:2408.10595v2 Announce Type: replace 
Abstract: Learning in zero-sum games studies a situation where multiple agents competitively learn their strategy. In such multi-agent learning, we often see that the strategies cycle around their optimum, i.e., Nash equilibrium. When a game periodically varies (called a ``periodic'' game), however, the Nash equilibrium moves generically. How learning dynamics behave in such periodic games is of interest but still unclear. Interestingly, we discover that the behavior is highly dependent on the relationship between the two speeds at which the game changes and at which players learn. We observe that when these two speeds synchronize, the learning dynamics diverge, and their time-average does not converge. Otherwise, the learning dynamics draw complicated cycles, but their time-average converges. Under some assumptions introduced for the dynamical systems analysis, we prove that this behavior occurs. Furthermore, our experiments observe this behavior even if removing these assumptions. This study discovers a novel phenomenon, i.e., synchronization, and gains insight widely applicable to learning in periodic games.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RoboSense: Large-scale Dataset and Benchmark for Egocentric Robot Perception and Navigation in Crowded and Unstructured Environments</title>
<link>https://arxiv.org/abs/2408.15503</link>
<guid>https://arxiv.org/abs/2408.15503</guid>
<content:encoded><![CDATA[
<div> 关键词：egocentric perception、mobile robots、multi-sensor platform、RoboSense dataset、3D perception metrics

总结:
本文介绍了一项针对移动机器人自主导航技术的研究进展，重点在于解决从第一人称视角下的可靠感知挑战。研究中搭建了一个基于相机、LiDAR和鱼眼三种传感器的多传感器数据采集平台，该平台支持灵活的传感器配置，能从ego-perspective捕捉近景或远景。为了促进这种视角下的机器人感知研究，文章构建了大规模多模态数据集——RoboSense，其中包含了超过133k条同步数据，以及140万个完整的360°视场中的3D边界框和ID标注，共有216k条轨迹和7.6k个时间序列。相比于自动驾驶场景的数据集如KITTI和nuScenes，RoboSense在近距离环境中的障碍物注解数量分别增加了$270\times$和$18\times$。此外，文中定义了一种新的近场3D感知与预测指标，并基于RoboSense数据集提出了6个热门任务及其详细的分析和基准测试。为保护隐私，已对数据进行了去敏感化处理。 <div>
arXiv:2408.15503v5 Announce Type: replace 
Abstract: Reliable embodied perception from an egocentric perspective is challenging yet essential for autonomous navigation technology of intelligent mobile agents. With the growing demand of social robotics, near-field scene understanding becomes an important research topic in the areas of egocentric perceptual tasks related to navigation in both crowded and unstructured environments. Due to the complexity of environmental conditions and difficulty of surrounding obstacles owing to truncation and occlusion, the perception capability under this circumstance is still inferior. To further enhance the intelligence of mobile robots, in this paper, we setup an egocentric multi-sensor data collection platform based on 3 main types of sensors (Camera, LiDAR and Fisheye), which supports flexible sensor configurations to enable dynamic sight of view from ego-perspective, capturing either near or farther areas. Meanwhile, a large-scale multimodal dataset is constructed, named RoboSense, to facilitate egocentric robot perception. Specifically, RoboSense contains more than 133K synchronized data with 1.4M 3D bounding box and IDs annotated in the full $360^{\circ}$ view, forming 216K trajectories across 7.6K temporal sequences. It has $270\times$ and $18\times$ as many annotations of surrounding obstacles within near ranges as the previous datasets collected for autonomous driving scenarios such as KITTI and nuScenes. Moreover, we define a novel matching criterion for near-field 3D perception and prediction metrics. Based on RoboSense, we formulate 6 popular tasks to facilitate the future research development, where the detailed analysis as well as benchmarks are also provided accordingly. Data desensitization measures have been conducted for privacy protection.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Planning for Multi-UAV Pursuit-Evasion in Unknown Environments Using Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.15866</link>
<guid>https://arxiv.org/abs/2409.15866</guid>
<content:encoded><![CDATA[
<div> 关键词: 多UAV追逃、强化学习、多智能体、预测增强网络、适应性环境生成器

总结:<br />
本文提出了一种针对多UAV追逃问题的解决方案，考虑了UAV的动力学和物理约束。研究中引入了一个增强预测网络来应对合作策略学习中的局部可观测性问题。同时，文中还提出了一种自适应环境生成器，以提高强化学习训练过程中的探索效率并提升策略在多样化场景下的泛化能力。模拟结果显示，该方法在具有挑战性的场景中显著优于基线，并能以100%的捕获率泛化到未见过的新场景。此外，通过两阶段奖励细化，文章实现了将所提策略直接部署到真实的四旋翼无人机上执行，这是首个利用集体推力和机身速率控制指令实现多UAV追逃的RL策略在未知环境中零样本部署的工作。相关开源代码和视频可在提供的网站地址访问。 <div>
arXiv:2409.15866v3 Announce Type: replace 
Abstract: Multi-UAV pursuit-evasion, where pursuers aim to capture evaders, poses a key challenge for UAV swarm intelligence. Multi-agent reinforcement learning (MARL) has demonstrated potential in modeling cooperative behaviors, but most RL-based approaches remain constrained to simplified simulations with limited dynamics or fixed scenarios. Previous attempts to deploy RL policy to real-world pursuit-evasion are largely restricted to two-dimensional scenarios, such as ground vehicles or UAVs at fixed altitudes. In this paper, we address multi-UAV pursuit-evasion by considering UAV dynamics and physical constraints. We introduce an evader prediction-enhanced network to tackle partial observability in cooperative strategy learning. Additionally, we propose an adaptive environment generator within MARL training, enabling higher exploration efficiency and better policy generalization across diverse scenarios. Simulations show our method significantly outperforms all baselines in challenging scenarios, generalizing to unseen scenarios with a 100% capture rate. Finally, we derive a feasible policy via a two-stage reward refinement and deploy the policy on real quadrotors in a zero-shot manner. To our knowledge, this is the first work to derive and deploy an RL-based policy using collective thrust and body rates control commands for multi-UAV pursuit-evasion in unknown environments. The open-source code and videos are available at https://sites.google.com/view/pursuit-evasion-rl.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dashing for the Golden Snitch: Multi-Drone Time-Optimal Motion Planning with Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.16720</link>
<guid>https://arxiv.org/abs/2409.16720</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机系统、时间最优运动规划、强化学习、碰撞避免、分布式策略网络

<br /><br />总结：
本文提出了一种使用多智能体强化学习的分布式策略网络，用于实现多无人机系统的时间最优飞行。该方法通过引入受到优化方法启发的软碰撞自由机制，在保证飞行效率的同时，确保了碰撞规避。利用集中式训练、分布式执行（CTDE）方式定制PPO算法，提升了训练效率和稳定性，并保证了轻量级实施。模拟实验表明，相较于单无人机系统，提出的多无人机方法能在保持接近时间最优性能的同时，具有较低的碰撞率。真实世界实验中，两个四旋翼无人机采用与模拟相同的网络，在一个5.5m*5.5m*2.0m的空间内，在各种轨道上实现了最大速度13.65 m/s和最大机身角速度13.4 rad/s的表现，全程依赖于机载计算。 <div>
arXiv:2409.16720v2 Announce Type: replace 
Abstract: Recent innovations in autonomous drones have facilitated time-optimal flight in single-drone configurations, and enhanced maneuverability in multi-drone systems by applying optimal control and learning-based methods. However, few studies have achieved time-optimal motion planning for multi-drone systems, particularly during highly agile maneuvers or in dynamic scenarios. This paper presents a decentralized policy network using multi-agent reinforcement learning for time-optimal multi-drone flight. To strike a balance between flight efficiency and collision avoidance, we introduce a soft collision-free mechanism inspired by optimization-based methods. By customizing PPO in a centralized training, decentralized execution (CTDE) fashion, we unlock higher efficiency and stability in training while ensuring lightweight implementation. Extensive simulations show that, despite slight performance trade-offs compared to single-drone systems, our multi-drone approach maintains near-time-optimal performance with a low collision rate. Real-world experiments validate our method, with two quadrotors using the same network as in simulation achieving a maximum speed of 13.65 m/s and a maximum body rate of 13.4 rad/s in a 5.5 m * 5.5 m * 2.0 m space across various tracks, relying entirely on onboard computation.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploration Implies Data Augmentation: Reachability and Generalisation in Contextual MDPs</title>
<link>https://arxiv.org/abs/2410.03565</link>
<guid>https://arxiv.org/abs/2410.03565</guid>
<content:encoded><![CDATA[
<div> 关键词：zero-shot策略迁移，探索，价值函数准确性，可达性，Explore-Go

总结:
本文关注零样本策略迁移（ZSPT）场景下上下文马尔科夫决策过程（MDP）中的智能体学习问题。研究发现，虽然增加探索可以提升泛化能力，但也可能降低所学价值函数的准确性。文章提出了“可达性”概念，用于定义在ZSPT设置中需要泛化的状态和上下文，并阐述了为何探索能改进它。作者假设并证明在保证准确性的前提下增加覆盖范围和探索能够进一步提高泛化效果。为此，他们提出了一种名为Explore-Go的方法，该方法在每个episode开始时实施探索阶段，可与现有的在线和离线RL算法结合使用，即使在部分可观测MDP中也能显著提升泛化性能。实验结果表明，当将Explore-Go与其他流行算法相结合时，其在多个环境中均显示出提高了泛化性能。通过这一简单修改，文章旨在为从业者提供一种改进智能体泛化能力的有效手段。 <div>
arXiv:2410.03565v2 Announce Type: replace 
Abstract: In the zero-shot policy transfer (ZSPT) setting for contextual Markov decision processes (MDP), agents train on a fixed set of contexts and must generalise to new ones. Recent work has argued and demonstrated that increased exploration can improve this generalisation, by training on more states in the training contexts. In this paper, we demonstrate that training on more states can indeed improve generalisation, but can come at a cost of reducing the accuracy of the learned value function which should not benefit generalisation. We introduce reachability in the ZSPT setting to define which states/contexts require generalisation and explain why exploration can improve it. We hypothesise and demonstrate that using exploration to increase the agent's coverage while also increasing the accuracy improves generalisation even more. Inspired by this, we propose a method Explore-Go that implements an exploration phase at the beginning of each episode, which can be combined with existing on- and off-policy RL algorithms and significantly improves generalisation even in partially observable MDPs. We demonstrate the effectiveness of Explore-Go when combined with several popular algorithms and show an increase in generalisation performance across several environments. With this, we hope to provide practitioners with a simple modification that can improve the generalisation of their agents.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LocoVR: Multiuser Indoor Locomotion Dataset in Virtual Reality</title>
<link>https://arxiv.org/abs/2410.06437</link>
<guid>https://arxiv.org/abs/2410.06437</guid>
<content:encoded><![CDATA[
<div> 关键词: LocoVR、虚拟现实、人类轨迹、室内环境、社会导航动态

总结:
<br />
LocoVR 是一个由超过 7000 条双人轨迹构成的大规模虚拟现实人体运动数据集，涵盖了 130 多种不同的室内家居环境。该数据集旨在解决现有研究中关于室内环境中人类行为建模，特别是社交导航动态方面的局限性。LocoVR 包含了丰富的社交动力学行为实例，如在狭窄空间中的避让行为、尊重个人空间的路径调整以及在高流量区域如入口和厨房中的协同移动等。实验表明，LocoVR 数据集能显著提升模型在处理基于人类轨迹的三项实际室内任务中的性能，并能够展示出预测家居环境中具有社交意识的导航模式的能力。 <div>
arXiv:2410.06437v2 Announce Type: replace 
Abstract: Understanding human locomotion is crucial for AI agents such as robots, particularly in complex indoor home environments. Modeling human trajectories in these spaces requires insight into how individuals maneuver around physical obstacles and manage social navigation dynamics. These dynamics include subtle behaviors influenced by proxemics - the social use of space, such as stepping aside to allow others to pass or choosing longer routes to avoid collisions. Previous research has developed datasets of human motion in indoor scenes, but these are often limited in scale and lack the nuanced social navigation dynamics common in home environments. To address this, we present LocoVR, a dataset of 7000+ two-person trajectories captured in virtual reality from over 130 different indoor home environments. LocoVR provides accurate trajectory data and precise spatial information, along with rich examples of socially-motivated movement behaviors. For example, the dataset captures instances of individuals navigating around each other in narrow spaces, adjusting paths to respect personal boundaries in living areas, and coordinating movements in high-traffic zones like entryways and kitchens. Our evaluation shows that LocoVR significantly enhances model performance in three practical indoor tasks utilizing human trajectories, and demonstrates predicting socially-aware navigation patterns in home environments.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DelTA: An Online Document-Level Translation Agent Based on Multi-Level Memory</title>
<link>https://arxiv.org/abs/2410.08143</link>
<guid>https://arxiv.org/abs/2410.08143</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 机器翻译, DelTA, 文档级翻译, 翻译一致性

总结:
本文介绍了一种名为DelTA的文档级翻译代理，旨在解决大型语言模型在处理整篇文档翻译时面临的翻译一致性和准确性问题。DelTA采用多级记忆结构，包括专有名词记录、双语摘要、长期记忆和短期记忆等，通过辅助的LLM组件不断检索和更新信息。实验结果显示，相较于强基线，DelTA在四个开放/闭源的LLM和两个代表性文档翻译数据集上显著提高了翻译的一致性和质量，一致性分数最高提升4.58个百分点，COMET分数平均提升3.16点。此外，DelTA采取句子级别的翻译策略，避免了句子遗漏，同时提供了内存效率较高的解决方案。它还提升了代词和上下文依赖性翻译的准确性，并表明其摘要组件有望应用于基于查询的摘要任务。相关代码与数据已在https://github.com/YutongWang1216/DocMTAgent发布。 <div>
arXiv:2410.08143v2 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved reasonable quality improvements in machine translation (MT). However, most current research on MT-LLMs still faces significant challenges in maintaining translation consistency and accuracy when processing entire documents. In this paper, we introduce DelTA, a Document-levEL Translation Agent designed to overcome these limitations. DelTA features a multi-level memory structure that stores information across various granularities and spans, including Proper Noun Records, Bilingual Summary, Long-Term Memory, and Short-Term Memory, which are continuously retrieved and updated by auxiliary LLM-based components. Experimental results indicate that DelTA significantly outperforms strong baselines in terms of translation consistency and quality across four open/closed-source LLMs and two representative document translation datasets, achieving an increase in consistency scores by up to 4.58 percentage points and in COMET scores by up to 3.16 points on average. DelTA employs a sentence-by-sentence translation strategy, ensuring no sentence omissions and offering a memory-efficient solution compared to the mainstream method. Furthermore, DelTA improves pronoun and context-dependent translation accuracy, and the summary component of the agent also shows promise as a tool for query-based summarization tasks. The code and data of our approach are released at https://github.com/YutongWang1216/DocMTAgent.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SMAC-R1: The Emergence of Intelligence in Decision-Making Tasks</title>
<link>https://arxiv.org/abs/2410.16024</link>
<guid>https://arxiv.org/abs/2410.16024</guid>
<content:encoded><![CDATA[
<div> 关键词：StarCraft Multi-Agent Challenge (SMAC)，多智能体强化学习(MARL)，决策树，深度寻求语言模型(LLM)，迁移能力

总结:
本文介绍了基于SMAC-R1的一个新方法，该方法利用Qwen2.5-7B-Base这一由DeepSeek-Coder-v2.5-236B蒸馏出的小型LLM。研究中，通过向LLM提供任务描述生成决策树代码，之后结合环境反馈对代理进行自我反思。进一步地，通过监督微调(SFT)和群组相对策略优化(GRPO)算法增强生成脚本的能力并微调LLM。实验在原版23个SMAC任务及新增的10个任务上表明，该方法能在极少量环境探索的情况下生成高质量、可解释的决策树，并展现出良好的迁移能力，无需修改即可应用于同质化SMAC环境中。这种方法为未来解决决策任务和领域特定LLM训练管线提供了新的思路。 <div>
arXiv:2410.16024v2 Announce Type: replace 
Abstract: StarCraft Multi-Agent Challenge (SMAC) has been one of the most commonly used experimental environments in multi-agent reinforcement learning (MARL), where the specific task is to control a set number of allied units to defeat enemy forces. Traditional MARL algorithms often require interacting with the environment for millions of steps to train a parametric model, of which the resulting policies are typically non-interpretable with weak transferability. In this paper, we introduce SMAC-R1 which is based on the Qwen2.5-7B-Base LLM distilled from DeepSeek-Coder-v2.5-236B. Similar to online reinforcement learning after behavior cloning in offline learning process, in our pipeline, agents leverage the DeepSeek LLM to generate decision tree code by providing task descriptions, and the agents are further self-reflected using feedback from the rewards provided by the environment. Based on that, we augment the generated scripts to fine-tune a small LLM, Qwen2.5-7B-Base, to distill the decision-making ability via Supervised Fine-Tuning (SFT) and enhance the script generation ability by the Group Relative Policy Optimization (GRPO) algorithm. We conduct experiments in the original 23 SMAC tasks and 10 newly-designed tasks to demonstrate that our method can produce high-quality, interpretable decision trees with minimal environmental exploration. Moreover, these scripts exhibit strong transferability, successfully applying to homogeneous SMAC environments without modification. We believe this approach offers a new direction for solving decision-making tasks and domain-specific LLM training pipelines in the future.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>POMDP-Driven Cognitive Massive MIMO Radar: Joint Target Detection-Tracking In Unknown Disturbances</title>
<link>https://arxiv.org/abs/2410.17967</link>
<guid>https://arxiv.org/abs/2410.17967</guid>
<content:encoded><![CDATA[
<div> 关键词:认知雷达、马尔科夫决策过程(POMDP)、多输入多输出(MIMO)雷达、目标检测、跟踪

总结:
本文探讨了认知雷达领域中，在未知扰动环境下移动目标的联合检测与跟踪问题。文章利用部分可观测马尔科夫决策过程（POMDP）框架，旨在优化雷达系统的行为，以在保持恒定虚警概率$(P_{FA})$的同时，最大化检测概率$(P_D)$并提高目标位置和速度估计的准确性。该方法提出了一种在线算法，不需要预先了解噪声统计特性，并采用比传统跟踪算法更为通用的观测模型。仿真结果表明，基于POMDP的算法相比最近在大规模MIMO(MMIMO)雷达系统中研究的SARSA算法具有显著的性能提升。 <div>
arXiv:2410.17967v2 Announce Type: replace 
Abstract: The joint detection and tracking of a moving target embedded in an unknown disturbance represents a key feature that motivates the development of the cognitive radar paradigm. Building upon recent advancements in robust target detection with multiple-input multiple-output (MIMO) radars, this work explores the application of a Partially Observable Markov Decision Process (POMDP) framework to enhance the tracking and detection tasks in a statistically unknown environment. In the POMDP setup, the radar system is considered as an intelligent agent that continuously senses the surrounding environment, optimizing its actions to maximize the probability of detection $(P_D)$ and improve the target position and velocity estimation, all this while keeping a constant probability of false alarm $(P_{FA})$. The proposed approach employs an online algorithm that does not require any apriori knowledge of the noise statistics, and it relies on a much more general observation model than the traditional range-azimuth-elevation model employed by conventional tracking algorithms. Simulation results clearly show substantial performance improvement of the POMDP-based algorithm compared to the State-Action-Reward-State-Action (SARSA)-based one that has been recently investigated in the context of massive MIMO (MMIMO) radar systems.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CycleResearcher: Improving Automated Research via Automated Review</title>
<link>https://arxiv.org/abs/2411.00816</link>
<guid>https://arxiv.org/abs/2411.00816</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化科学发现、大型语言模型、开放源代码、CycleResearcher、CycleReviewer

<br /><br />总结:
本文探讨了使用开源后训练大型语言模型实现科学研究全过程自动化，包括文献回顾、论文撰写以及同行评审和论文精炼的可能性。研究提出了一种迭代偏好训练框架，其中包括执行科研任务的CycleResearcher和模拟同行评审过程并提供强化学习反馈的CycleReviewer。为训练这些模型，开发了两个新数据集——Review-5k和Research-14k，以反映真实世界的机器学习研究和同行评审动态。实验结果显示，CycleReviewer在预测论文评分方面相比单个人类评审员有显著降低的均方误差（MAE），降低了26.89%。CycleResearcher生成的论文在模拟同行评审中获得了5.36的分数，与人类专家的预印本水平（5.24）相比具有一定的竞争力，但仍不及接受发表的论文水平（5.69）。这项工作标志着迈向完全自动化的科学研究迈出了重要一步，并对AI驱动的研究能力及其伦理保障进行了探讨。相关代码、数据集和模型权重已在https://wengsyx.github.io/Researcher/上发布。 <div>
arXiv:2411.00816v2 Announce Type: replace 
Abstract: The automation of scientific discovery has been a long-standing goal within the research community, driven by the potential to accelerate knowledge creation. While significant progress has been made using commercial large language models (LLMs) as research assistants or idea generators, the possibility of automating the entire research process with open-source LLMs remains largely unexplored. This paper explores the feasibility of using open-source post-trained LLMs as autonomous agents capable of performing the full cycle of automated research and review, from literature review and manuscript preparation to peer review and paper refinement. Our iterative preference training framework consists of CycleResearcher, which conducts research tasks, and CycleReviewer, which simulates the peer review process, providing iterative feedback via reinforcement learning. To train these models, we develop two new datasets, Review-5k and Research-14k, reflecting real-world machine learning research and peer review dynamics. Our results demonstrate that CycleReviewer achieves promising performance with a 26.89\% reduction in mean absolute error (MAE) compared to individual human reviewers in predicting paper scores, indicating the potential of LLMs to effectively assist expert-level research evaluation. In research, the papers generated by the CycleResearcher model achieved a score of 5.36 in simulated peer reviews, showing some competitiveness in terms of simulated review scores compared to the preprint level of 5.24 from human experts, while still having room for improvement compared to the accepted paper level of 5.69. This work represents a significant step toward fully automated scientific inquiry, providing ethical safeguards and exploring AI-driven research capabilities. The code, dataset and model weight are released at https://wengsyx.github.io/Researcher/
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PyGen: A Collaborative Human-AI Approach to Python Package Creation</title>
<link>https://arxiv.org/abs/2411.08932</link>
<guid>https://arxiv.org/abs/2411.08932</guid>
<content:encoded><![CDATA[
<div> 关键词: Pygen、自动化平台、Python、语言模型、代码生成

总结:
Pygen是一个自动化平台，旨在利用大型语言模型的威力增强科研人员、技术专家和爱好者的创新能力，将抽象想法转化为实用的Python软件工具。通过结合最先进的语言模型与开源代码生成技术，Pygen大幅减少了工具开发的手动工作量。用户只需提供提示，Pygen即可自动生成包括概念、包生成和文档在内的完整工作流程所需的Python包。研究表明，Pygen显著提高了研究者的生产力，能为各种专业目的创建健壮、模块化且文档完备的包。采用提示增强方法，将用户的包描述细化为更具体和可执行的操作指令。对生成的包及文档进行了人类评估、基于LLM的评估和CodeBLEU等多维度评价。文章还记录了结果、分析了局限性并提出了缓解策略。Pygen代表了我们对于伦理自动化的愿景，倡导包容性、易用性和协作式开发。该项目标志着朝着智能代理与人类协同改进科学和技术发展的大规模努力迈出的第一步。相关代码和生成示例已开放源代码，可在[https://github.com/GitsSaikat/Pygen]上访问。 <div>
arXiv:2411.08932v2 Announce Type: replace 
Abstract: The principles of automation and innovation serve as foundational elements for advancement in contemporary science and technology. Here, we introduce Pygen, an automation platform designed to empower researchers, technologists, and hobbyists to bring abstract ideas to life as core, usable software tools written in Python. Pygen leverages the immense power of autoregressive large language models to augment human creativity during the ideation, iteration, and innovation process. By combining state-of-the-art language models with open-source code generation technologies, Pygen has significantly reduced the manual overhead of tool development. From a user prompt, Pygen automatically generates Python packages for a complete workflow from concept to package generation and documentation. The findings of our work show that Pygen considerably enhances the researcher's productivity by enabling the creation of resilient, modular, and well-documented packages for various specialized purposes. We employ a prompt enhancement approach to distill the user's package description into increasingly specific and actionable. While being inherently an open-ended task, we have evaluated the generated packages and the documentation using Human Evaluation, LLM-based evaluation, and CodeBLEU, with detailed results in the results section. Furthermore, we documented our results, analyzed the limitations, and suggested strategies to alleviate them. Pygen is our vision of ethical automation, a framework that promotes inclusivity, accessibility, and collaborative development. This project marks the beginning of a large-scale effort towards creating tools where intelligent agents collaborate with humans to improve scientific and technological development substantially.
  Our code and generated examples are open-sourced at [https://github.com/GitsSaikat/Pygen]
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2411.15692</link>
<guid>https://arxiv.org/abs/2411.15692</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Drug Discovery，Machine Learning (ML) Programming，DrugAgent，Multi-Agent Framework

总结:<br />
本文介绍了近期在大型语言模型（LLMs）领域的进展如何引发对加速药物发现的关注。针对将理论想法转化为制药研究领域中坚固实现的核心问题，文章提出了名为DrugAgent的多代理框架，该框架自动化了药物发现任务中的机器学习编程过程。DrugAgent包含一个LLM规划器用于形成高级理念，以及一个LLM指导器用于在实施这些理念时识别和整合领域知识。文中通过三个代表性的药物发现任务展示了DrugAgent的优势，结果表明，DrugAgent在药物靶点相互作用（DTI）任务上相对于ReAct的ROC-AUC有4.92%的相对提升。DrugAgent已在https://anonymous.4open.science/r/drugagent-5C42/公开可用。 <div>
arXiv:2411.15692v2 Announce Type: replace 
Abstract: Recent progress in Large Language Models (LLMs) has drawn attention to their potential for accelerating drug discovery. However, a central problem remains: translating theoretical ideas into robust implementations in the highly specialized context of pharmaceutical research. This limitation prevents practitioners from making full use of the latest AI developments in drug discovery. To address this challenge, we introduce DrugAgent, a multi-agent framework that automates machine learning (ML) programming for drug discovery tasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas. We present case studies on three representative drug discovery tasks. Our results show that DrugAgent consistently outperforms leading baselines, including a relative improvement of 4.92% in ROC-AUC compared to ReAct for drug-target interaction (DTI). DrugAgent is publicly available at https://anonymous.4open.science/r/drugagent-5C42/.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DMVC-Tracker: Distributed Multi-Agent Trajectory Planning for Target Tracking Using Dynamic Buffered Voronoi and Inter-Visibility Cells</title>
<link>https://arxiv.org/abs/2411.18086</link>
<guid>https://arxiv.org/abs/2411.18086</guid>
<content:encoded><![CDATA[
<div> 关键词：多Agent空中跟踪、分布式轨迹规划、动态缓冲Voronoi细胞（DBVC）、动态互可视细胞（DIVC）、Bernstein多项式运动基元

总结：
本文提出了一种用于多Agent空中跟踪的分布式轨迹规划方法。该方法利用动态缓冲Voronoi细胞（DBVC）和动态互可视细胞（DIVC）来构建分布式的轨迹生成策略，这两个时间变异性空间能有效防止Agent间的碰撞与遮挡，同时保证它们与移动目标保持适宜的距离。文章将DBVC和DIVC与改进后的Bernstein多项式运动基元相结合，形成一种更不保守的追踪生成方法，可在Intel i7台式机上于几毫秒内计算出每个Agent的轨迹。实验验证了该算法在包含数十个障碍物等复杂环境下的跟踪性能。 <div>
arXiv:2411.18086v2 Announce Type: replace 
Abstract: This letter presents a distributed trajectory planning method for multi-agent aerial tracking. The proposed method uses a Dynamic Buffered Voronoi Cell (DBVC) and a Dynamic Inter-Visibility Cell (DIVC) to formulate the distributed trajectory generation. Specifically, the DBVC and the DIVC are time-variant spaces that prevent mutual collisions and occlusions among agents, while enabling them to maintain suitable distances from the moving target. We combine the DBVC and the DIVC with an efficient Bernstein polynomial motion primitive-based tracking generation method, which has been refined into a less conservative approach than in our previous work. The proposed algorithm can compute each agent's trajectory within several milliseconds on an Intel i7 desktop. We validate the tracking performance in challenging scenarios, including environments with dozens of obstacles.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coordinated Multi-Armed Bandits for Improved Spatial Reuse in Wi-Fi</title>
<link>https://arxiv.org/abs/2412.03076</link>
<guid>https://arxiv.org/abs/2412.03076</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Access Point Coordination (MAPC)，Artificial Intelligence and Machine Learning (AI/ML)，Spatial Reuse (SR)，Multi-Agent Multi-Armed Bandit (MA-MAB)，Wi-Fi simulator

总结:
<br />
本文探讨了未来Wi-Fi（如IEEE 802.11bn和更高级别）中预期的关键技术——多接入点协调(MAPC)和人工智能与机器学习(AI/ML)的应用。研究重点在于利用在线学习设计一种协同解决方案，优化空间重用(SR)方法，通过Packet Detect (PD)调整和发射功率控制来管理干扰，实现多个设备的同时传输。文中采用多智能体多臂赌博机(MA-MAB)模型，让来自多个并存网络的决策代理同时配置SR参数，并研究多种算法和奖励分享机制。使用广泛认可的Wi-Fi模拟器Komondor评估不同的MA-MAB实施方案，结果显示，由协同MAB驱动的AI原生SR可以显著提升网络性能：平均吞吐量提高15%，公平性增强，使网络中的最小吞吐量提高了210%，同时保证最大访问延迟低于3毫秒。 <div>
arXiv:2412.03076v2 Announce Type: replace 
Abstract: Multi-Access Point Coordination (MAPC) and Artificial Intelligence and Machine Learning (AI/ML) are expected to be key features in future Wi-Fi, such as the forthcoming IEEE 802.11bn (Wi-Fi~8) and beyond. In this paper, we explore a coordinated solution based on online learning to drive the optimization of Spatial Reuse (SR), a method that allows multiple devices to perform simultaneous transmissions by controlling interference through Packet Detect (PD) adjustment and transmit power control. In particular, we focus on a Multi-Agent Multi-Armed Bandit (MA-MAB) setting, where multiple decision-making agents concurrently configure SR parameters from coexisting networks by leveraging the MAPC framework, and study various algorithms and reward-sharing mechanisms. We evaluate different MA-MAB implementations using Komondor, a well-adopted Wi-Fi simulator, and demonstrate that AI-native SR enabled by coordinated MABs can improve the network performance over current Wi-Fi operation: mean throughput increases by 15%, fairness is improved by increasing the minimum throughput across the network by 210%, while the maximum access delay is kept below 3 ms.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Constitutional Filter: Bayesian Estimation of Compliant Agents</title>
<link>https://arxiv.org/abs/2412.18347</link>
<guid>https://arxiv.org/abs/2412.18347</guid>
<content:encoded><![CDATA[
<div> 关键词：神经符号方法、贝叶斯估计、宪法模型、宪政滤波器（CoFi）、海洋交通数据

<br /><br />总结:

本文介绍了利用神经符号方法来处理法律政策、物理限制和操作偏好的影响下对代理人行为预测的挑战。提出了一个新的方法——宪政滤波器（CoFi），它是一种用于贝叶斯估计的框架，能够基于人类可解释的神经符号模型（称为宪法模型）来预测遵守规则的代理人的预期行为。CoFi通过结合专家知识、深度学习架构以及考虑环境不确定性，提升了对代理人轨迹跟踪的效果，并能与像粒子滤波器等广泛应用的技术兼容。通过在真实世界的海洋交通数据上的评估，文章不仅证明了CoFi的性能优势，还展示了其如何学会适应并信任代理人的合规程度，即使假设的宪法模型与现实不符也能恢复到基准性能水平。 <div>
arXiv:2412.18347v2 Announce Type: replace 
Abstract: Predicting agents impacted by legal policies, physical limitations, and operational preferences is inherently difficult. In recent years, neuro-symbolic methods have emerged, integrating machine learning and symbolic reasoning models into end-to-end learnable systems. Hereby, a promising avenue for expressing high-level constraints over multi-modal input data in robotics has opened up. This work introduces an approach for Bayesian estimation of agents expected to comply with a human-interpretable neuro-symbolic model we call its Constitution. Hence, we present the Constitutional Filter (CoFi), leading to improved tracking of agents by leveraging expert knowledge, incorporating deep learning architectures, and accounting for environmental uncertainties. CoFi extends the general, recursive Bayesian estimation setting, ensuring compatibility with a vast landscape of established techniques such as Particle Filters. To underpin the advantages of CoFi, we evaluate its performance on real-world marine traffic data. Beyond improved performance, we show how CoFi can learn to trust and adapt to the level of compliance of an agent, recovering baseline performance even if the assumed Constitution clashes with reality.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interactive Data Harmonization with LLM Agents</title>
<link>https://arxiv.org/abs/2502.07132</link>
<guid>https://arxiv.org/abs/2502.07132</guid>
<content:encoded><![CDATA[
<div> 关键词：数据集成、数据 harmonization、智能代理、Harmonia、临床数据

<br /><br />总结:
本文提出了利用智能代理进行数据和谐化以简化和强化专家整合多样化来源数据的过程。文章介绍了一个名为Harmonia的系统，该系统结合了基于LLM的推理、交互式用户界面以及数据和谐化原语库，用于自动化数据和谐化管道的合成。通过临床数据和谐化的实例展示，Harmonia有助于交互式创建可重用的数据映射管道，将多源数据转换为标准格式。最后，文章讨论了挑战与开放问题，并对未来研究方向提出了建议。 <div>
arXiv:2502.07132v2 Announce Type: replace 
Abstract: Data harmonization is an essential task that entails integrating datasets from diverse sources. Despite years of research in this area, it remains a time-consuming and challenging task due to schema mismatches, varying terminologies, and differences in data collection methodologies. This paper presents the case for agentic data harmonization as a means to both empower experts to harmonize their data and to streamline the process. We introduce Harmonia, a system that combines LLM-based reasoning, an interactive user interface, and a library of data harmonization primitives to automate the synthesis of data harmonization pipelines. We demonstrate Harmonia in a clinical data harmonization scenario, where it helps to interactively create reusable pipelines that map datasets to a standard format. Finally, we discuss challenges and open problems, and suggest research directions for advancing our vision.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From equality to diversity -- bottom-up approach for hierarchy growth</title>
<link>https://arxiv.org/abs/1707.00985</link>
<guid>https://arxiv.org/abs/1707.00985</guid>
<content:encoded><![CDATA[
<div> 关键词: 分层拓扑、复杂系统、等级增长模型、动态过程、模拟分析

总结:
本文介绍了一个从底层向上发展的简单但通用的等级增长模型，该模型考虑了两种动态过程：当局部领导者被选中并被其他代理人跟随时，代理人的晋升到更高层级，以及代理人因降级返回至最低层级。经过初始阶段后，系统逐渐达到一个稳定状态，在此状态下不再出现新的层级，不同层级上的代理人分布呈指数型。在稳定状态下，平均层级水平和位于最低层级的代理人比例与系统大小无关，但层级高度（即观察到的最大层级数）随总的代理人数量以对数方式增长。在稳定状态下，一个代理人的平均跟随者数量远小于其晋升时刻所拥有的跟随者数量。数值模拟结果得到了基于速率方程的理论分析的支持。 <div>
arXiv:1707.00985v2 Announce Type: replace-cross 
Abstract: The hierarchical topology is a common property of many complex systems. Here we introduce a simple but generic model of hierarchy growth from the bottom to the top. Therein, two dynamical processes are accounted for: agent's promotions to next hierarchy levels when local speakers are elected and followed by other agents and agent's degradations to the lowest hierarchy. Following the initial stage when all agents are at the bottom level in the course of time the system approaches a stationary state where new hierarchies no longer emerge and the distribution of agents at different levels is exponential. In the stationary state the average hierarchy level and the fraction of agents at the lowest level are independent from the system size however the height of hierarchy, i.e. maximal number of observed hierarchy levels grows logarithmically along the total number of agents. The average number of followers of an agent in the stationary state is much smaller than the number of followers he possessed at the promotion moment. Results from numerical simulations are confirmed by an analytical treatment based on the rate equation.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-Agent Interaction in Synthetic Social Networks: A Framework for Studying Online Polarization</title>
<link>https://arxiv.org/abs/2502.01340</link>
<guid>https://arxiv.org/abs/2502.01340</guid>
<content:encoded><![CDATA[
<div> 关键词：在线社会网络、极化、计算框架、意见动态、语言模型

<br /><br />总结:
该文提出了一个创新的计算框架，旨在融合数学模型与基于LLM的语言模型方法，以更精确地研究在线社交网络中的极化现象。这一框架将正式的意见动力学原理嵌入到人工智能代理中，既保证了数学分析的严谨性，又实现了自然语言交互的社会模拟。通过广泛的离线测试和涉及122名人类参与者的实验评估，该框架在控制的社交网络环境中得到验证，并能系统地探究极化环境下的用户感知和行为变化。结果表明，在极化讨论环境下，参与者对情绪内容和群体归属更加敏感，并认为代理人立场的不确定性降低。这一方法论上的突破为研究社交媒体现象及在线意见动态的因果机制提供了新的途径，有效地弥合了理论模型与实证观察之间的鸿沟。 <div>
arXiv:2502.01340v2 Announce Type: replace-cross 
Abstract: Online social networks have dramatically altered the landscape of public discourse, creating both opportunities for enhanced civic participation and risks of deepening social divisions. Prevalent approaches to studying online polarization have been limited by a methodological disconnect: mathematical models excel at formal analysis but lack linguistic realism, while language model-based simulations capture natural discourse but often sacrifice analytical precision. This paper introduces an innovative computational framework that synthesizes these approaches by embedding formal opinion dynamics principles within LLM-based artificial agents, enabling both rigorous mathematical analysis and naturalistic social interactions. We validate our framework through comprehensive offline testing and experimental evaluation with 122 human participants engaging in a controlled social network environment. The results demonstrate our ability to systematically investigate polarization mechanisms while preserving ecological validity. Our findings reveal how polarized environments shape user perceptions and behavior: participants exposed to polarized discussions showed markedly increased sensitivity to emotional content and group affiliations, while perceiving reduced uncertainty in the agents' positions. By combining mathematical precision with natural language capabilities, our framework opens new avenues for investigating social media phenomena through controlled experimentation. This methodological advancement allows researchers to bridge the gap between theoretical models and empirical observations, offering unprecedented opportunities to study the causal mechanisms underlying online opinion dynamics.
]]></content:encoded>
<pubDate>Thu, 06 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Enterprise-Ready Computer Using Generalist Agent</title>
<link>https://arxiv.org/abs/2503.01861</link>
<guid>https://arxiv.org/abs/2503.01861</guid>
<content:encoded><![CDATA[
<div> 关键词: CUGA系统、企业环境、人工智能、迭代评估、WebArena基准

总结:<br />
本文介绍了针对企业环境开发的计算机通用智能代理（CUGA）系统的持续研究工作。研究强调了构建适合企业环境的智能系统的过程具有进化性质。通过将最先进的智能AI技术与系统性的迭代评估、分析和改进方法相结合，我们已经实现了快速且成本效益高的性能提升，在WebArena基准测试中达到了新的 state-of-the-art 性能水平。文章详细阐述了发展路线图、促进快速从失败中学习和持续系统优化的方法论及工具，并讨论了在企业应用中面临的關鍵教训和未来挑战。 <div>
arXiv:2503.01861v1 Announce Type: new 
Abstract: This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena benchmark. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data Augmentation for Instruction Following Policies via Trajectory Segmentation</title>
<link>https://arxiv.org/abs/2503.01871</link>
<guid>https://arxiv.org/abs/2503.01871</guid>
<content:encoded><![CDATA[
<div> 关键词：instructable agents, robotics, gaming, semi-supervised learning, play trajectories<br /><br />总结:
本文探讨了如何解决可指导智能体（如机器人或游戏）在规模化训练中缺乏指令轨迹配对数据的问题。研究关注于在半监督设置下，从大量未标注行为轨迹（游玩轨迹）中提取标签片段的方法，以此扩充小规模的指令-轨迹配对标注数据集，以提升下游通过模仿学习训练的指令跟随策略的性能。针对游玩轨迹中段长度变化较大的问题，文章提出了“游玩分割”（Play Segmentation, PS）这一概率模型，该模型能够在仅基于单个指令片段训练的情况下，有效地找到最可能的扩展子段分割。实验结果显示，在游戏环境和模拟机器人夹爪场景中，随机采样的片段会降低策略性能，而采用PS方法提取的标签片段能将政策性能提升至与使用两倍标注数据训练的政策相当的水平。 <div>
arXiv:2503.01871v1 Announce Type: new 
Abstract: The scalability of instructable agents in robotics or gaming is often hindered by limited data that pairs instructions with agent trajectories. However, large datasets of unannotated trajectories containing sequences of various agent behaviour (play trajectories) are often available. In a semi-supervised setup, we explore methods to extract labelled segments from play trajectories. The goal is to augment a small annotated dataset of instruction-trajectory pairs to improve the performance of an instruction-following policy trained downstream via imitation learning. Assuming little variation in segment length, recent video segmentation methods can effectively extract labelled segments. To address the constraint of segment length, we propose Play Segmentation (PS), a probabilistic model that finds maximum likely segmentations of extended subsegments, while only being trained on individual instruction segments. Our results in a game environment and a simulated robotic gripper setting underscore the importance of segmentation; randomly sampled segments diminish performance, while incorporating labelled segments from PS improves policy performance to the level of a policy trained on twice the amount of labelled data.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Uncertainty Comes for Free: Human-in-the-Loop Policies with Diffusion Models</title>
<link>https://arxiv.org/abs/2503.01876</link>
<guid>https://arxiv.org/abs/2503.01876</guid>
<content:encoded><![CDATA[
<div> 关键词：Human-in-the-loop (HitL)，机器人部署，自主行为，不确定性指标，数据收集

<br />
总结:
本文提出了一种针对Human-in-the-loop (HitL)机器人部署的新方法，旨在减少对人类持续监督的依赖。该方法利用扩散策略的生成过程计算一种基于不确定性的度量标准，使自主代理能在必要时主动寻求人类协助，而无需在训练阶段涉及操作员交互。同时，文章还表明这一方法可用于高效地收集数据以微调扩散策略，进而提升其自主执行性能。实验结果在模拟环境和现实世界场景中验证了该方法能有效增强策略在部署期间的表现。 <div>
arXiv:2503.01876v1 Announce Type: new 
Abstract: Human-in-the-loop (HitL) robot deployment has gained significant attention in both academia and industry as a semi-autonomous paradigm that enables human operators to intervene and adjust robot behaviors at deployment time, improving success rates. However, continuous human monitoring and intervention can be highly labor-intensive and impractical when deploying a large number of robots. To address this limitation, we propose a method that allows diffusion policies to actively seek human assistance only when necessary, reducing reliance on constant human oversight. To achieve this, we leverage the generative process of diffusion policies to compute an uncertainty-based metric based on which the autonomous agent can decide to request operator assistance at deployment time, without requiring any operator interaction during training. Additionally, we show that the same method can be used for efficient data collection for fine-tuning diffusion policies in order to improve their autonomous performance. Experimental results from simulated and real-world environments demonstrate that our approach enhances policy performance during deployment for a variety of scenarios.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BEYONDWORDS is All You Need: Agentic Generative AI based Social Media Themes Extractor</title>
<link>https://arxiv.org/abs/2503.01880</link>
<guid>https://arxiv.org/abs/2503.01880</guid>
<content:encoded><![CDATA[
<div> 关键词：社会媒体分析、主题分析、预训练语言模型、矩阵分解、生成式AI<br /><br />总结:
本文介绍了一种针对社交媒体帖子进行主题分析的新方法。该方法结合了预训练语言模型产生的推文嵌入向量、维度降低技术和矩阵分解，并利用生成式AI来识别和提炼潜在主题。通过聚类压缩后的推文表示，并运用生成式AI的链式思考（CoT）提示以及二级LLM进行质量控制，以自动化主题抽取过程。研究以自闭症群体的推文为例进行了应用展示，旨在揭示关键见解并保持原始讨论的丰富性。这种方法证明了将机器学习与生成式AI相结合能有效提升在线社区主题识别的深度和准确性，提供了一个可扩展和适应多种场景的框架。 <div>
arXiv:2503.01880v1 Announce Type: new 
Abstract: Thematic analysis of social media posts provides a major understanding of public discourse, yet traditional methods often struggle to capture the complexity and nuance of unstructured, large-scale text data. This study introduces a novel methodology for thematic analysis that integrates tweet embeddings from pre-trained language models, dimensionality reduction using and matrix factorization, and generative AI to identify and refine latent themes. Our approach clusters compressed tweet representations and employs generative AI to extract and articulate themes through an agentic Chain of Thought (CoT) prompting, with a secondary LLM for quality assurance. This methodology is applied to tweets from the autistic community, a group that increasingly uses social media to discuss their experiences and challenges. By automating the thematic extraction process, the aim is to uncover key insights while maintaining the richness of the original discourse. This autism case study demonstrates the utility of the proposed approach in improving thematic analysis of social media data, offering a scalable and adaptable framework that can be applied to diverse contexts. The results highlight the potential of combining machine learning and Generative AI to enhance the depth and accuracy of theme identification in online communities.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mapping representations in Reinforcement Learning via Semantic Alignment for Zero-Shot Stitching</title>
<link>https://arxiv.org/abs/2503.01881</link>
<guid>https://arxiv.org/abs/2503.01881</guid>
<content:encoded><![CDATA[
<div> 关键词：Deep Reinforcement Learning (深度强化学习), generalization (泛化能力), semantic alignment (语义对齐), zero-shot (零样本), domain shift (领域迁移)

<br />
总结:
本文关注深度强化学习模型在环境观测或任务需求发生微小变化时面临的泛化问题，通常需要昂贵的重训练。为解决这一问题，研究者基于近期的语义对齐工作，提出了一种零样本方法，用于在不同环境下训练的不同智能体之间映射各自的隐空间。该方法学习一种转换，能够在无需进一步微调的情况下，将一个智能体编码器的嵌入向量映射到另一个智能体编码器中。实现这种转换依赖于一组语义上对齐的“锚点”观察数据，用于估计仿射或正交变换。一旦找到转换，针对某一领域的已训练控制器即可零样本地解释来自另一现有编码器的嵌入信息，避免了额外训练。实验表明，该框架在视觉和任务领域转移情况下能保持高性能。文中通过CarRacing环境的变化背景与任务实验证明了零样本拼接性能，为构建更健壮、组合式的动态环境中强化学习铺平道路。 <div>
arXiv:2503.01881v1 Announce Type: new 
Abstract: Deep Reinforcement Learning (RL) models often fail to generalize when even small changes occur in the environment's observations or task requirements. Addressing these shifts typically requires costly retraining, limiting the reusability of learned policies. In this paper, we build on recent work in semantic alignment to propose a zero-shot method for mapping between latent spaces across different agents trained on different visual and task variations. Specifically, we learn a transformation that maps embeddings from one agent's encoder to another agent's encoder without further fine-tuning. Our approach relies on a small set of "anchor" observations that are semantically aligned, which we use to estimate an affine or orthogonal transform. Once the transformation is found, an existing controller trained for one domain can interpret embeddings from a different (existing) encoder in a zero-shot fashion, skipping additional trainings. We empirically demonstrate that our framework preserves high performance under visual and task domain shifts. We empirically demonstrate zero-shot stitching performance on the CarRacing environment with changing background and task. By allowing modular re-assembly of existing policies, it paves the way for more robust, compositional RL in dynamically changing environments.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UDora: A Unified Red Teaming Framework against LLM Agents by Dynamically Hijacking Their Own Reasoning</title>
<link>https://arxiv.org/abs/2503.01908</link>
<guid>https://arxiv.org/abs/2503.01908</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Model (LLM)，adversarial attacks，UDora，reasoning processes，malicious behavior

总结:
本文介绍了针对大型语言模型（LLM）代理的一种新型攻击框架UDora。随着LLM代理在处理复杂任务如网络购物、自动邮件回复和金融交易等方面的能力增强，其遭受恶意攻击的风险也随之增加。现有的直接注入恶意指令或工具交互中的方法对现代LLM代理的效果逐渐减弱。UDora框架通过动态利用LLM自身的推理过程，寻找并插入针对性的扰动，以优化的对抗性字符串引导LLM代理执行预设的恶意行为或调用恶意工具。实验表明，UDora相较于现有方法在三个LLM代理数据集上表现出更高的有效性。 <div>
arXiv:2503.01908v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents equipped with external tools have become increasingly powerful for handling complex tasks such as web shopping, automated email replies, and financial trading. However, these advancements also amplify the risks of adversarial attacks, particularly when LLM agents can access sensitive external functionalities. Moreover, because LLM agents engage in extensive reasoning or planning before executing final actions, manipulating them into performing targeted malicious actions or invoking specific tools remains a significant challenge. Consequently, directly embedding adversarial strings in malicious instructions or injecting malicious prompts into tool interactions has become less effective against modern LLM agents. In this work, we present UDora, a unified red teaming framework designed for LLM Agents that dynamically leverages the agent's own reasoning processes to compel it toward malicious behavior. Specifically, UDora first samples the model's reasoning for the given task, then automatically identifies multiple optimal positions within these reasoning traces to insert targeted perturbations. Subsequently, it uses the modified reasoning as the objective to optimize the adversarial strings. By iteratively applying this process, the LLM agent will then be induced to undertake designated malicious actions or to invoke specific malicious tools. Our approach demonstrates superior effectiveness compared to existing methods across three LLM agent datasets.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MultiAgentBench: Evaluating the Collaboration and Competition of LLM agents</title>
<link>https://arxiv.org/abs/2503.01935</link>
<guid>https://arxiv.org/abs/2503.01935</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，多智能体基准 (MultiAgentBench)，协作评估，竞争评估，协调协议

总结:
本文介绍了MultiAgentBench，这是一个用于评估基于大型语言模型（LLMs）的多智能体系统在多样化交互场景中性能的全面基准。该框架不仅关注任务完成情况，还使用新颖的里程碑式关键绩效指标来衡量合作和竞争的质量。研究中对比了多种协调协议（如星形、链形、树形和图结构），并考察了群体讨论和认知规划等创新策略的效果。结果显示，gpt-4o-mini在平均任务得分上表现最优，图结构协调协议在研究场景下表现出最佳性能，而认知规划则将里程碑达成率提高了3%。相关代码和数据集已在https://github.com/MultiagentBench/MARBLE公开可用。 <div>
arXiv:2503.01935v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have shown remarkable capabilities as autonomous agents, yet existing benchmarks either focus on single-agent tasks or are confined to narrow domains, failing to capture the dynamics of multi-agent coordination and competition. In this paper, we introduce MultiAgentBench, a comprehensive benchmark designed to evaluate LLM-based multi-agent systems across diverse, interactive scenarios. Our framework measures not only task completion but also the quality of collaboration and competition using novel, milestone-based key performance indicators. Moreover, we evaluate various coordination protocols (including star, chain, tree, and graph topologies) and innovative strategies such as group discussion and cognitive planning. Notably, gpt-4o-mini reaches the average highest task score, graph structure performs the best among coordination protocols in the research scenario, and cognitive planning improves milestone achievement rates by 3%. Code and datasets are public available at https://github.com/MultiagentBench/MARBLE.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Task Scheduling &amp; Forgetting in Multi-Task Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.01941</link>
<guid>https://arxiv.org/abs/2503.01941</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、遗忘现象、人类、复习策略、不对称学习

总结:
本文探讨了强化学习（RL）代理与人类在任务遗忘行为上的共性，并检验了学习理论中防止遗忘的方法在RL中的有效性。研究发现RL代理在许多情况下展现出与人类相似的遗忘曲线，但证实像Leitner或SuperMemo等有效的防止人类遗忘的方法在RL中并不完全适用。其原因在于RL中的任务之间存在不对称的学习和保持模式，这无法通过基于留存或性能的课程策略来捕捉。<br /><br /> <div>
arXiv:2503.01941v1 Announce Type: new 
Abstract: Reinforcement learning (RL) agents can forget tasks they have previously been trained on. There is a rich body of work on such forgetting effects in humans. Therefore we look for commonalities in the forgetting behavior of humans and RL agents across tasks and test the viability of forgetting prevention measures from learning theory in RL. We find that in many cases, RL agents exhibit forgetting curves similar to those of humans. Methods like Leitner or SuperMemo have been shown to be effective at counteracting human forgetting, but we demonstrate they do not transfer as well to RL. We identify a likely cause: asymmetrical learning and retention patterns between tasks that cannot be captured by retention-based or performance-based curriculum strategies.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning a Game by Paying the Agents</title>
<link>https://arxiv.org/abs/2503.01976</link>
<guid>https://arxiv.org/abs/2503.01976</guid>
<content:encoded><![CDATA[
<div> 关键词: 学习代理、正常形式游戏、主体、迭代优势行动消除、无遗憾假设<br /><br />总结: 本文研究了通过观察代理在正常形式游戏中重复玩游戏来学习其效用函数的问题。与先前文献不同的是，文中引入了一个具有观察代理人游戏行为、发送信号和根据代理人行动支付的能力的主体。在合理的行为模型下，如迭代优势行动消除或无遗憾假设，文章表明主体能够在与游戏规模相关的多项式轮次内以任意期望精度$\varepsilon > 0$学习所有代理人的效用函数。此外，还展示了在这两个模型中的下界，其中在迭代优势模型中的上界几乎与其匹配，并且严格区分了这两个模型：主体可以在迭代优势模型中更快地学习。最后，讨论了该问题对引导代理人达到期望均衡的影响，特别地，利用所提出的效用学习算法作为子程序，推出了首个无需预先了解代理人效用的学习型代理人引导算法。 <div>
arXiv:2503.01976v1 Announce Type: new 
Abstract: We study the problem of learning the utility functions of agents in a normal-form game by observing the agents play the game repeatedly. Differing from most prior literature, we introduce a principal with the power to observe the agents playing the game, send the agents signals, and send the agents payments as a function of their actions. Under reasonable behavioral models for the agents such as iterated dominated action removal or a no-regret assumption, we show that the principal can, using a number of rounds polynomial in the size of the game, learn the utility functions of all agents to any desirable precision $\varepsilon > 0$. We also show lower bounds in both models, which nearly match the upper bounds in the former model and also strictly separate the two models: the principal can learn strictly faster in the iterated dominance model. Finally, we discuss implications for the problem of steering agents to a desired equilibrium: in particular, we introduce, using our utility-learning algorithm as a subroutine, the first algorithm for steering learning agents without prior knowledge of their utilities.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Proportionality in Thumbs Up and Down Voting</title>
<link>https://arxiv.org/abs/2503.01985</link>
<guid>https://arxiv.org/abs/2503.01985</guid>
<content:encoded><![CDATA[
<div> 关键词：决策制定、代理、投票、比例代表制、AI宪法

总结:
在这篇文章中，研究者探讨了在同时考虑正面和负面偏好的选举环境中（如AI宪法中的公民选择道德原则）的比例代表制问题。文章提出了两种不同的方法来解释这种环境下比例代表制的概念。第一种方法将选民对候选人当选的满意度与对他们行使否决权的影响视为可比较的，从而引出了结合比例性保证的概念。第二种方法则将否决权独立考虑，提出了不同于传统比例代表制的新保障。研究者为每个视角形式化了相应的公理，并通过适合的Phragmén规则、比例批准投票规则以及平等份额法的适应版本考察了这些公理的可行性。 <div>
arXiv:2503.01985v1 Announce Type: new 
Abstract: Consider the decision-making setting where agents elect a panel by expressing both positive and negative preferences. Prominently, in constitutional AI, citizens democratically select a slate of ethical preferences on which a foundation model is to be trained. There, in practice, agents may both approve and disapprove of different ethical principles. Proportionality has been well-studied in computational social choice for approval ballots, but its meaning remains unclear when negative sentiments are also considered. In this work, we propose two conceptually distinct approaches to interpret proportionality in the presence of up and down votes. The first approach treats the satisfaction from electing candidates and the impact of vetoing them as comparable, leading to combined proportionality guarantees. The second approach considers veto power separately, introducing guarantees distinct from traditional proportionality. We formalize axioms for each perspective and examine their satisfiability by suitable adaptations of Phragm\'en's rule, Proportional Approval Voting rule and the Method of Equal Shares.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptively evaluating models with task elicitation</title>
<link>https://arxiv.org/abs/2503.01986</link>
<guid>https://arxiv.org/abs/2503.01986</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、评价框架、适应性评估、前沿模型、一致性

总结:
本文提出了一个用于评价大型语言模型的新框架——适应性评估（Adaptive Evaluations），旨在应对手动数据集编纂速度跟不上语言模型快速发展的挑战。该框架利用支架式语言模型（evaluator agents）对目标模型在特定领域数据集上的行为进行搜索，并生成能揭示和探查其失败模式的困难问题（任务）。研究发现，使用该框架对多元化的数据集和任务进行适应性探查时，前沿模型表现出缺乏一致性。生成的问题经过人类有效性验证，且往往可以转移到具有不同能力特征的其他模型上，表明适应性评估也可用于创建难度较高的领域专用数据集。 <div>
arXiv:2503.01986v1 Announce Type: new 
Abstract: Manual curation of evaluation datasets is struggling to keep up with the rapidly expanding capabilities and deployment scenarios of language models. Towards scalable model profiling, we introduce and validate a framework for evaluating LLMs, called Adaptive Evaluations. Adaptive evaluations use scaffolded language models (evaluator agents) to search through a target model's behavior on a domain dataset and create difficult questions (tasks) that can discover and probe the model's failure modes. We find that frontier models lack consistency when adaptively probed with our framework on a diverse suite of datasets and tasks, including but not limited to legal reasoning, forecasting, and online harassment. Generated questions pass human validity checks and often transfer to other models with different capability profiles, demonstrating that adaptive evaluations can also be used to create difficult domain-specific datasets.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mind the (Belief) Gap: Group Identity in the World of LLMs</title>
<link>https://arxiv.org/abs/2503.02016</link>
<guid>https://arxiv.org/abs/2503.02016</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，社会偏见，信念一致性，多智能体系统，误导信息传播

总结:<br />
本文探讨了大型语言模型（LLMs）在模拟群体心理学特性，特别是信念一致性方面的能力及其对社会互动和偏好形成的影响。研究发现，LLMs在各种情境下展现出比人类更为显著的信念一致性现象。这不仅加剧了误导信息的传播，也阻碍了LLM的学习过程。为缓解这些问题，文章提出了三种策略，分别借鉴接触假说、准确度提示和全球公民框架的理念。实验结果显示，最佳策略可将误导信息传播减少高达37%，并使学习效果提升11%。该研究通过连接社会心理学与人工智能，为现实中使用LLMs处理信念驱动的偏见问题提供了导航性的见解。 <div>
arXiv:2503.02016v1 Announce Type: new 
Abstract: Social biases and belief-driven behaviors can significantly impact Large Language Models (LLMs) decisions on several tasks. As LLMs are increasingly used in multi-agent systems for societal simulations, their ability to model fundamental group psychological characteristics remains critical yet under-explored. In this study, we present a multi-agent framework that simulates belief congruence, a classical group psychology theory that plays a crucial role in shaping societal interactions and preferences. Our findings reveal that LLMs exhibit amplified belief congruence compared to humans, across diverse contexts. We further investigate the implications of this behavior on two downstream tasks: (1) misinformation dissemination and (2) LLM learning, finding that belief congruence in LLMs increases misinformation dissemination and impedes learning. To mitigate these negative impacts, we propose strategies inspired by: (1) contact hypothesis, (2) accuracy nudges, and (3) global citizenship framework. Our results show that the best strategies reduce misinformation dissemination by up to 37% and enhance learning by 11%. Bridging social psychology and AI, our work provides insights to navigate real-world interactions using LLMs while addressing belief-driven biases.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Persuasion at Play: Understanding Misinformation Dynamics in Demographic-Aware Human-LLM Interactions</title>
<link>https://arxiv.org/abs/2503.02038</link>
<guid>https://arxiv.org/abs/2503.02038</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 错误信息, 影响力, 人群差异, 劝说动态

总结:
本文研究了大型语言模型（LLMs）与人类在接触错误信息时的双向劝说动态。通过分析人类立场数据集来探究人对LLM的影响，并生成基于LLM的有说服力的论点以评估LLM对人的影响。利用多智能体LLM框架，本研究还分析了在具有不同人口统计学特征的LLM代理之间，受劝说影响下错误信息传播的模式。结果表明，人口统计因素对LLM对错误信息的易感性产生影响，其模式与人类群体中的相关模式相似。此外，类似人类群体中的人口结构分化现象，多智能体LLM系统也展示了回音室行为。这项研究揭示了人类与LLMs之间的相互作用以及在错误信息背景下的人群差异，为未来干预措施提供了洞察和启示。 <div>
arXiv:2503.02038v1 Announce Type: new 
Abstract: Existing challenges in misinformation exposure and susceptibility vary across demographic groups, as some populations are more vulnerable to misinformation than others. Large language models (LLMs) introduce new dimensions to these challenges through their ability to generate persuasive content at scale and reinforcing existing biases. This study investigates the bidirectional persuasion dynamics between LLMs and humans when exposed to misinformative content. We analyze human-to-LLM influence using human-stance datasets and assess LLM-to-human influence by generating LLM-based persuasive arguments. Additionally, we use a multi-agent LLM framework to analyze the spread of misinformation under persuasion among demographic-oriented LLM agents. Our findings show that demographic factors influence susceptibility to misinformation in LLMs, closely reflecting the demographic-based patterns seen in human susceptibility. We also find that, similar to human demographic groups, multi-agent LLMs exhibit echo chamber behavior. This research explores the interplay between humans and LLMs, highlighting demographic differences in the context of misinformation and offering insights for future interventions.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Constrained Linear Thompson Sampling</title>
<link>https://arxiv.org/abs/2503.02043</link>
<guid>https://arxiv.org/abs/2503.02043</guid>
<content:encoded><![CDATA[
<div> 关键词：安全线性探索博弈、约束满足、乐观主义方法、COLTS框架、计算效率

总结:

本文研究了安全线性探索博弈问题，其中智能体需要在线性约束条件下从凸域中选择动作以最大化未知目标函数。现有的方法主要依赖于基于乐观主义和频数置信区间的策略，这往往导致行动选择过程计算成本高昂。文章提出了一种名为COnstrained Linear Thompson Sampling（COLTS）的采样基础框架，该框架通过利用对未知目标向量和约束矩阵估计值的噪声扰动来有效地平衡后悔最小化与约束满足，从而选择动作。文中介绍了COLTS的三个变体：

1. S-COLTS 假设访问已知的安全动作并确保严格约束执行，通过将COLTS方法与朝向安全动作的重缩放相结合，实现对于$d$维动作下$\tilde{O}(\sqrt{d^3 T})$的后悔值和零违规风险。

2. E-COLTS 在斯莱特条件下的软约束执行，结合COLTS和均匀探索，达到$\tilde{O}(\sqrt{d^3 T})$的后悔值和风险。

3. R-COLTS 不需要任何侧信息，通过重复采样确保实例无关的后悔值和风险为$\tilde{O}(\sqrt{d^3 T})$。

一个关键的技术创新是联合噪声设计，它在保持乐观主义的同时保证了计算效率，并结合一种基于比例分析的技术来处理由采样的约束矩阵引起的每轮可行区域的变化。这些方法与先前方法具有相同的后悔界限，但显著降低了计算成本，从而为约束线性优化的探索博弈提供了一种可扩展且实用的方法。 <div>
arXiv:2503.02043v1 Announce Type: new 
Abstract: We study the safe linear bandit problem, where an agent sequentially selects actions from a convex domain to maximize an unknown objective while ensuring unknown linear constraints are satisfied on a per-round basis. Existing approaches primarily rely on optimism-based methods with frequentist confidence bounds, often leading to computationally expensive action selection routines. We propose COnstrained Linear Thompson Sampling (COLTS), a sampling-based framework that efficiently balances regret minimization and constraint satisfaction by selecting actions on the basis of noisy perturbations of the estimates of the unknown objective vector and constraint matrix. We introduce three variants of COLTS, distinguished by the learner's available side information:
  - S-COLTS assumes access to a known safe action and ensures strict constraint enforcement by combining the COLTS approach with a rescaling towards the safe action. For $d$-dimensional actions, this yields $\tilde{O}(\sqrt{d^3 T})$ regret and zero constraint violations (or risk).
  - E-COLTS enforces constraints softly under Slater's condition, and attains regret and risk of $\tilde{O}(\sqrt{d^3 T})$ by combining COLTS with uniform exploration.
  - R-COLTS requires no side information, and ensures instance-independent regret and risk of $\tilde{O}(\sqrt{d^3 T})$ by leveraging repeated resampling.
  A key technical innovation is a coupled noise design, which maintains optimism while preserving computational efficiency, which is combined with a scaling based analysis technique to address the variation of the per-round feasible region induced by sampled constraint matrices. Our methods match the regret bounds of prior approaches, while significantly reducing computational costs compared to them, thus yielding a scalable and practical approach for constrained bandit linear optimization.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Constraint-Based Modeling of Dynamic Entities in 3D Scene Graphs for Robust SLAM</title>
<link>https://arxiv.org/abs/2503.02050</link>
<guid>https://arxiv.org/abs/2503.02050</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人、动态环境、SLAM、三维场景图、动态对象建模

总结:<br />
本文提出了一种针对动态环境的新型层次化三维场景图基SLAM框架，旨在解决动态物体建模与定位估计的挑战。该框架利用fiducial标记检测动态实体并提取其属性，同时优化关键帧选择和实现对动态实体映射的新功能。通过维护一个层次化的表示形式，将动态对象注册到SLAM图中，并使用新颖的实体-关键帧约束和实体内部约束与其关联的机器人关键帧及建筑楼层进行约束。系统通过结合动态实体与环境之间的语义和几何约束，联合优化SLAM图以同时估计机器人和多个动态代理与物体的位姿，并保持精确的地图。实验评估显示，相较于传统方法，我们的方法能够降低27.57%的姿态估计误差，并使系统具备更高层次的场景动态推理能力。 <div>
arXiv:2503.02050v1 Announce Type: new 
Abstract: Autonomous robots depend crucially on their ability to perceive and process information from dynamic, ever-changing environments. Traditional simultaneous localization and mapping (SLAM) approaches struggle to maintain consistent scene representations because of numerous moving objects, often treating dynamic elements as outliers rather than explicitly modeling them in the scene representation. In this paper, we present a novel hierarchical 3D scene graph-based SLAM framework that addresses the challenge of modeling and estimating the pose of dynamic objects and agents. We use fiducial markers to detect dynamic entities and to extract their attributes while improving keyframe selection and implementing new capabilities for dynamic entity mapping. We maintain a hierarchical representation where dynamic objects are registered in the SLAM graph and are constrained with robot keyframes and the floor level of the building with our novel entity-keyframe constraints and intra-entity constraints. By combining semantic and geometric constraints between dynamic entities and the environment, our system jointly optimizes the SLAM graph to estimate the pose of the robot and various dynamic agents and objects while maintaining an accurate map. Experimental evaluation demonstrates that our approach achieves a 27.57% reduction in pose estimation error compared to traditional methods and enables higher-level reasoning about scene dynamics.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI persuading AI vs AI persuading Humans: LLMs' Differential Effectiveness in Promoting Pro-Environmental Behavior</title>
<link>https://arxiv.org/abs/2503.02067</link>
<guid>https://arxiv.org/abs/2503.02067</guid>
<content:encoded><![CDATA[
<div> 关键词: pro-environmental behavior, large language models, persuasion strategies, synthetic persuasion paradox, behavioral change

总结:
本文探讨了大型语言模型（LLMs）在促进环保行为（PEB）方面的作用。研究通过对比真实人类、基于实际参与者数据的模拟人类以及完全合成的虚拟人物三类群体对个性化或标准化聊天机器人以及静态陈述的反应，使用四种说服策略（道德基础、未来自我连续性、行动导向和“自由风格”）。结果揭示了一个“合成劝导悖论”，即合成与模拟的代理人其环保行为立场在干预后有显著变化，而真人参与者的反应则几乎未发生变化。模拟参与者虽能更好地近似真实人类趋势但仍会高估效应。这一脱节现象突显出LLM在预先评估PEB干预措施方面的潜力，同时也警告了其在预测现实世界行为方面的局限性。文章呼吁改进合成建模方法并进行持续和扩展的人类试验，以使对话式AI的承诺与其带来的实质性可持续性成果相一致。 <div>
arXiv:2503.02067v1 Announce Type: new 
Abstract: Pro-environmental behavior (PEB) is vital to combat climate change, yet turning awareness into intention and action remains elusive. We explore large language models (LLMs) as tools to promote PEB, comparing their impact across 3,200 participants: real humans (n=1,200), simulated humans based on actual participant data (n=1,200), and fully synthetic personas (n=1,200). All three participant groups faced personalized or standard chatbots, or static statements, employing four persuasion strategies (moral foundations, future self-continuity, action orientation, or "freestyle" chosen by the LLM). Results reveal a "synthetic persuasion paradox": synthetic and simulated agents significantly affect their post-intervention PEB stance, while human responses barely shift. Simulated participants better approximate human trends but still overestimate effects. This disconnect underscores LLM's potential for pre-evaluating PEB interventions but warns of its limits in predicting real-world behavior. We call for refined synthetic modeling and sustained and extended human trials to align conversational AI's promise with tangible sustainability outcomes.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interactive Debugging and Steering of Multi-Agent AI Systems</title>
<link>https://arxiv.org/abs/2503.02068</link>
<guid>https://arxiv.org/abs/2503.02068</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM-powered AI agents, collaborative tasks, development challenges, AGDebugger, interactive debugging

<br /><br />总结:

这篇论文探讨了在开发和调试完全自主的LLM驱动的AI代理团队时所面临的挑战，如审查长对话以定位错误困难、现有工具缺乏交互式调试支持以及需要工具协助迭代调整代理配置。针对这些需求，研究者开发了一款名为AGDebugger的交互式多代理调试工具，该工具具有浏览和发送消息的界面、编辑和重置先前代理消息的功能，以及用于导航复杂消息历史的概览可视化。通过两部分的用户研究，研究者发现了引导代理的常见策略，并强调了在调试过程中互动消息重置的重要性。这项研究加深了对日益重要的代理工作流调试接口的理解。 <div>
arXiv:2503.02068v1 Announce Type: new 
Abstract: Fully autonomous teams of LLM-powered AI agents are emerging that collaborate to perform complex tasks for users. What challenges do developers face when trying to build and debug these AI agent teams? In formative interviews with five AI agent developers, we identify core challenges: difficulty reviewing long agent conversations to localize errors, lack of support in current tools for interactive debugging, and the need for tool support to iterate on agent configuration. Based on these needs, we developed an interactive multi-agent debugging tool, AGDebugger, with a UI for browsing and sending messages, the ability to edit and reset prior agent messages, and an overview visualization for navigating complex message histories. In a two-part user study with 14 participants, we identify common user strategies for steering agents and highlight the importance of interactive message resets for debugging. Our studies deepen understanding of interfaces for debugging increasingly important agentic workflows.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>$\text{M}^3\text{HF}$: Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality</title>
<link>https://arxiv.org/abs/2503.02077</link>
<guid>https://arxiv.org/abs/2503.02077</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、奖励函数、多阶段人类反馈、混合质量、M^3HF框架

<br />
总结:

本文提出了一种新的多智能体强化学习框架——M^3HF，旨在解决复杂协调环境中有效的奖励函数设计难题。该框架通过整合不同专业水平的人类在训练过程中提供的多阶段混合质量反馈，利用专家和非专家的指导不断优化智能体策略。在训练期间，会适时暂停智能体的学习以供人类评估，使用大型语言模型解析并适当地分配反馈信息。进一步地，利用预定义模板和自适应权重更新奖励函数，其中权重衰减和基于性能的调整用于处理各种质量级别的反馈。实验结果表明，M^3HF在具有挑战性的环境中显著优于现有方法，有效解决了MARL中的奖励设计复杂性问题，并促进了更多人类参与训练过程。 <div>
arXiv:2503.02077v1 Announce Type: new 
Abstract: Designing effective reward functions in multi-agent reinforcement learning (MARL) is a significant challenge, often leading to suboptimal or misaligned behaviors in complex, coordinated environments. We introduce Multi-agent Reinforcement Learning from Multi-phase Human Feedback of Mixed Quality ($\text{M}^3\text{HF}$), a novel framework that integrates multi-phase human feedback of mixed quality into the MARL training process. By involving humans with diverse expertise levels to provide iterative guidance, $\text{M}^3\text{HF}$ leverages both expert and non-expert feedback to continuously refine agents' policies. During training, we strategically pause agent learning for human evaluation, parse feedback using large language models to assign it appropriately and update reward functions through predefined templates and adaptive weight by using weight decay and performance-based adjustments. Our approach enables the integration of nuanced human insights across various levels of quality, enhancing the interpretability and robustness of multi-agent cooperation. Empirical results in challenging environments demonstrate that $\text{M}^3\text{HF}$ significantly outperforms state-of-the-art methods, effectively addressing the complexities of reward design in MARL and enabling broader human participation in the training process.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Fair Division: Towards Ex-Post Constant MMS Guarantees</title>
<link>https://arxiv.org/abs/2503.02088</link>
<guid>https://arxiv.org/abs/2503.02088</guid>
<content:encoded><![CDATA[
<div> 关键词：公平分配、在线算法、最大最小份额（MMS）、多类型、随机到达

总结:

本文研究了具有加性估值的$n$个序列化到达的代理之间$m$个不可分割物品的公平分配问题，关注的是最大最小份额（MMS）这一公平性概念。首先指出，在缺乏关于未来代理人估值函数信息的情况下，不存在任何能保证非平凡MMS近似的在线算法，即使只有两个代理也是如此。文章提出了在线$k$-类型公平分配模型，其中每个到达的代理属于$k$种类型之一，同类型的代理具有相同的已知估值函数。针对两种不同的到达模型：
1- 对抗性到达：设计了一个具有$\frac{1}{k}$-MMS竞争比的在线算法，并证明了存在下界，即无法得到$\Omega(\frac{1}{\sqrt{k}})$-MMS竞争比的算法，即便是对于二元估值也一样。
2- 随机到达：在该模型中，每个到达代理的类型是从潜在的、可能未知的概率分布独立抽取的。与对抗性环境中的依赖于$k$的情况不同，本文展示了在随机环境下，可以实现接近$\frac{1}{2}$-MMS的竞争比，只需对估值函数作出一些轻微的分布假设。此外，当算法能够访问关于估值函数的预测时，文中还表明其竞争比会随着乘性预测误差的增加而平滑下降。 <div>
arXiv:2503.02088v1 Announce Type: new 
Abstract: We investigate the problem of fairly allocating $m$ indivisible items among $n$ sequentially arriving agents with additive valuations, under the sought-after fairness notion of maximin share (MMS). We first observe a strong impossibility: without appropriate knowledge about the valuation functions of the incoming agents, no online algorithm can ensure any non-trivial MMS approximation, even when there are only two agents. Motivated by this impossibility, we introduce OnlineKTypeFD (online $k$-type fair division), a model that balances theoretical tractability with real-world applicability. In this model, each arriving agent belongs to one of $k$ types, with all agents of a given type sharing the same known valuation function. We do not constrain $k$ to be a constant. Upon arrival, an agent reveals her type, receives an irrevocable allocation, and departs. We study the ex-post MMS guarantees of online algorithms under two arrival models:
  1- Adversarial arrivals: In this model, an adversary determines the type of each arriving agent. We design a $\frac{1}{k}$-MMS competitive algorithm and complement it with a lower bound, ruling out any $\Omega(\frac{1}{\sqrt{k}})$-MMS-competitive algorithm, even for binary valuations.
  2- Stochastic arrivals: In this model, the type of each arriving agent is independently drawn from an underlying, possibly unknown distribution. Unlike the adversarial setting where the dependence on $k$ is unavoidable, we surprisingly show that in the stochastic setting, an asymptotic, arbitrarily close-to-$\frac{1}{2}$-MMS competitive guarantee is achievable under mild distributional assumptions.
  Our results extend naturally to a learning-augmented framework; when given access to predictions about valuation functions, we show that the competitive ratios of our algorithms degrade gracefully with multiplicative prediction errors.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improved MMS Approximations for Few Agent Types</title>
<link>https://arxiv.org/abs/2503.02089</link>
<guid>https://arxiv.org/abs/2503.02089</guid>
<content:encoded><![CDATA[
<div> 关键词：fair division, indivisible goods, maximin share (MMS), agent types, approximation guarantee

总结:
这篇论文研究了具有相同估值的同类型代理人对不可分割物品进行公平分配的问题。当仅有一种类型时，总是存在精确的MMS分配方案。但对于两种或更多种类型的代理人，精确的MMS分配不一定存在，因此转向寻找近似MMS分配的存在性。过去十年的研究已得出最佳已知的近似保障为$\frac{3}{4} + \frac{3}{3836}$。本文针对具有两类和三类代理人的场景（这在实际场景中常见）改进了近似保证，提出了新的算法，分别为两类代理人提供$\frac{4}{5}$-MMS分配和为三类代理人提供$\frac{16}{21}$-MMS分配。该方法利用多数类型的MMS划分并将其调整以改善所有类型的公平性保障。<br /><br /> <div>
arXiv:2503.02089v1 Announce Type: new 
Abstract: We study fair division of indivisible goods under the maximin share (MMS) fairness criterion in settings where agents are grouped into a small number of types, with agents within each type having identical valuations. For the special case of a single type, an exact MMS allocation is always guaranteed to exist. However, for two or more distinct agent types, exact MMS allocations do not always exist, shifting the focus to establishing the existence of approximate-MMS allocations. A series of works over the last decade has resulted in the best-known approximation guarantee of $\frac{3}{4} + \frac{3}{3836}$.
  In this paper, we improve the approximation guarantees for settings where agents are grouped into two or three types, a scenario that arises in many practical settings. Specifically, we present novel algorithms that guarantee a $\frac{4}{5}$-MMS allocation for two agent types and a $\frac{16}{21}$-MMS allocation for three agent types. Our approach leverages the MMS partition of the majority type and adapts it to provide improved fairness guarantees for all types.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NavG: Risk-Aware Navigation in Crowded Environments Based on Reinforcement Learning with Guidance Points</title>
<link>https://arxiv.org/abs/2503.02111</link>
<guid>https://arxiv.org/abs/2503.02111</guid>
<content:encoded><![CDATA[
<div> 关键词: motion planning, perception errors, guidance points, reinforcement learning, navigation safety

总结:
本文提出了一种用于解决导航系统中运动规划易受上游感知错误影响问题的新方法。该方法引入了“指导点”这一新型方向提示，在强化学习框架中使用。文章发展了一套识别指导点的结构化方法，包括障碍物边界提取、潜在指导点检测和冗余消除。为了将指导点融入导航流程，文中提出了一个感知到规划的映射策略，统一了指导点与其他感知输入，使RL代理能够有效利用原始激光数据、人类检测与跟踪以及指导点之间的互补关系。通过定性定量的模拟实验表明，所提方法成功率达到最高，并实现了接近最优的旅行时间，显著提高了安全性和效率。此外，现实世界中的动态走廊和大厅实验验证了机器人能够在避开行人并自信地绕过障碍物方面表现出稳健的导航能力。 <div>
arXiv:2503.02111v1 Announce Type: new 
Abstract: Motion planning in navigation systems is highly susceptible to upstream perceptual errors, particularly in human detection and tracking. To mitigate this issue, the concept of guidance points--a novel directional cue within a reinforcement learning-based framework--is introduced. A structured method for identifying guidance points is developed, consisting of obstacle boundary extraction, potential guidance point detection, and redundancy elimination. To integrate guidance points into the navigation pipeline, a perception-to-planning mapping strategy is proposed, unifying guidance points with other perceptual inputs and enabling the RL agent to effectively leverage the complementary relationships among raw laser data, human detection and tracking, and guidance points. Qualitative and quantitative simulations demonstrate that the proposed approach achieves the highest success rate and near-optimal travel times, greatly improving both safety and efficiency. Furthermore, real-world experiments in dynamic corridors and lobbies validate the robot's ability to confidently navigate around obstacles and robustly avoid pedestrians.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Traffic Signal Control based on Multi-Agent Reinforcement Learning. Case Study on a simulated real-world corridor</title>
<link>https://arxiv.org/abs/2503.02189</link>
<guid>https://arxiv.org/abs/2503.02189</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（multi-agent reinforcement learning）、策略基方法（policy-based methods）、中央化评论架构（centralized critic architecture）、交通信号控制（traffic signal control）、模拟实证测试（simulated real-world corridor）

<br /><br />总结：
本文针对交通信号控制问题，提出了一种基于多智能体近端策略优化（MA-PPO）的适应性协调控制算法。研究指出，虽然已有少数尝试将强化学习应用到交通信号控制中的工作，但主要使用了价值基方法，而近期文献表明策略基方法在部分可观测环境中可能表现更优。此外，以往大多数研究对信号定时方案做了简化假设，使得强化学习在实际信号定时计划中的应用尚未得到充分验证。本研究设计的MA-PPO算法采用集中式评论架构，在集中训练和分布式执行框架下运行，允许每个智能体选择并实施最多八个信号相位，符合实际现场控制器的常规实现方式。通过在一个具有七个交叉口、真实完整的交通流、信号相位、交通量以及包括交叉口间距在内的网络几何形状的模拟实证测试走廊上进行测试，结果表明，与当前实施的由Vissim-MaxTime软件建模的协调激活信号控制（ASC）计划相比，提出的MA-PPO自适应控制算法能使整个测试走廊上的两个直行车流旅行时间分别降低约14%和29%。进一步的交通需求变化敏感性实验显示，所提出的MA-PPO算法表现出良好的稳定性、鲁棒性和适应性。 <div>
arXiv:2503.02189v1 Announce Type: new 
Abstract: The very few studies that have attempted to formulate multi-agent reinforcement learning (RL) algorithms for adaptive traffic signal control have mainly used value-based RL methods although recent literature has shown that policy-based methods may perform better in partially observable environments. Additionally, because of the simplifying assumptions on signal timing made almost universally across previous studies, RL methods remain largely untested for real-world signal timing plans. This study formulates a multi-agent proximal policy optimization (MA-PPO) algorithm to implement adaptive and coordinated traffic control along an arterial corridor. The formulated MA-PPO has centralized critic architecture under the centralized training and decentralized execution framework. All agents are formulated to allow selection and implementation of up to eight signal phases as commonly implemented in the field controllers. The formulated algorithm is tested on a simulated real-world corridor with seven intersections, actual/complete traffic movements and signal phases, traffic volumes, and network geometry including intersection spacings. The performance of the formulated MA-PPO adaptive control algorithm is compared with the field implemented coordinated and actuated signal control (ASC) plans modeled using Vissim-MaxTime software in the loop simulation (SILs). The speed of convergence for each agent largely depended on the size of the action space which in turn depended on the number and sequence of signal phases. Compared with the currently implemented ASC signal timings, MA-PPO showed a travel time reduction of about 14% and 29%, respectively for the two through movements across the entire test corridor. Through volume sensitivity experiments, the formulated MA-PPO showed good stability, robustness and adaptability to changes in traffic demand.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ATLaS: Agent Tuning via Learning Critical Steps</title>
<link>https://arxiv.org/abs/2503.02197</link>
<guid>https://arxiv.org/abs/2503.02197</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 行为克隆, 关键步骤, 微调, ATLaS

总结:
本文提出了一种名为ATLaS的新方法，用于更有效和高效地微调大型语言模型（LLM）代理。现有的LLM代理调优策略通常采用全程监督微调专家轨迹，这可能导致专家偏见并削弱对未被专家数据覆盖状态的泛化能力。ATLaS能够识别专家轨迹中的关键步骤，并仅针对这些步骤对LLMs进行微调，从而以较低的成本减少过拟合整个轨迹的风险并促进跨不同环境和任务的泛化能力。实验表明，仅使用ATLaS选择的30%关键步骤进行微调的LLM性能优于使用全部步骤微调的LLM以及近期开源的LLM代理。同时，ATLaS能够在与多样化环境交互时保持并提升基线LLM作为通用代理的能力。 <div>
arXiv:2503.02197v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents have demonstrated remarkable generalization capabilities across multi-domain tasks. Existing agent tuning approaches typically employ supervised finetuning on entire expert trajectories. However, behavior-cloning of full trajectories can introduce expert bias and weaken generalization to states not covered by the expert data. Additionally, critical steps, such as planning, complex reasoning for intermediate subtasks, and strategic decision-making, are essential to success in agent tasks, so learning these steps is the key to improving LLM agents. For more effective and efficient agent tuning, we propose ATLaS that identifies the critical steps in expert trajectories and finetunes LLMs solely on these steps with reduced costs. By steering the training's focus to a few critical steps, our method mitigates the risk of overfitting entire trajectories and promotes generalization across different environments and tasks. In extensive experiments, an LLM finetuned on only 30% critical steps selected by ATLaS outperforms the LLM finetuned on all steps and recent open-source LLM agents. ATLaS maintains and improves base LLM skills as generalist agents interacting with diverse environments.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Haste Makes Waste: Evaluating Planning Abilities of LLMs for Efficient and Feasible Multitasking with Time Constraints Between Actions</title>
<link>https://arxiv.org/abs/2503.02238</link>
<guid>https://arxiv.org/abs/2503.02238</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、多任务规划、执行效率、Recipe2Plan、烹饪场景

<br /><br />总结:
本文提出了一个新的基准框架Recipe2Plan，旨在解决大型语言模型在多任务规划和执行效率方面的不足。Recipe2Plan基于真实的烹饪场景，要求智能体在遵守时间约束（如特定动作需在限定时间内依序完成）的前提下，通过并行任务执行来优化烹饪时间。该框架突出了在保证效率与可行性之间寻找平衡的挑战，即过度的地方并行化可能会破坏时间约束，影响整个烹饪过程。实验表明，当前 state-of-the-art 的模型在这方面存在困难，强调了未来大语言模型需要提升对时间敏感性和全局多任务处理能力的需求。相关代码和基准已开源在https://github.com/WilliamZR/Recipe2Plan。 <div>
arXiv:2503.02238v1 Announce Type: new 
Abstract: While Large Language Model-based agents have demonstrated substantial progress in task completion, existing evaluation benchmarks tend to overemphasize single-task performance, with insufficient attention given to the crucial aspects of multitask planning and execution efficiency required in real-world scenarios. To bridge this gap, we present Recipe2Plan, a novel benchmark framework based on real-world cooking scenarios. Unlike conventional benchmarks, Recipe2Plan challenges agents to optimize cooking time through parallel task execution while respecting temporal constraints i.e. specific actions need to be performed within a particular time intervals following the preceding steps. Overly aggressive local parallelization may disrupt this constraint, potentially compromising the entire cooking process. This strict time constraint between actions raises a unique challenge for agents to balance between maximizing concurrent operations and adhering to critical timing constraints. Extensive experiments with state-of-the-art models reveal challenges in maintaining this balance between efficiency and feasibility. The results highlight the need for improved temporal awareness and global multitasking capabilities in large language models. We open-source our benchmark and code at https://github.com/WilliamZR/Recipe2Plan.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WMNav: Integrating Vision-Language Models into World Models for Object Goal Navigation</title>
<link>https://arxiv.org/abs/2503.02247</link>
<guid>https://arxiv.org/abs/2503.02247</guid>
<content:encoded><![CDATA[
<div> 关键词：Object Goal Navigation、Vision-Language Model (VLM)、World Model-based Navigation (WMNav)、Curiosity Value Map、探索效率

总结:
文章介绍了针对对象目标导航(Object Goal Navigation)问题的一种新框架——WMNav，该框架基于视觉语言模型(Vision-Language Models, VLMs)构建了一个世界模型，可以预测决策结果和记忆环境状态。WMNav利用在线维护的好奇心价值图(Curiosity Value Map)来动态配置导航策略，通过比较世界模型计划与实际观察的反馈差异，减少了模型幻觉的影响。此外，为了提高效率，WMNav采用两阶段行动提议者策略，即广泛探索后进行精确定位。实验表明，WMNav在HM3D和MP3D数据集上超越了现有的零样本基准，在成功率和探索效率方面均有显著提升（在HM3D上绝对提升+3.2% SR和+3.2% SPL，在MP3D上绝对提升+13.5% SR和+1.1% SPL）。 <div>
arXiv:2503.02247v1 Announce Type: new 
Abstract: Object Goal Navigation-requiring an agent to locate a specific object in an unseen environment-remains a core challenge in embodied AI. Although recent progress in Vision-Language Model (VLM)-based agents has demonstrated promising perception and decision-making abilities through prompting, none has yet established a fully modular world model design that reduces risky and costly interactions with the environment by predicting the future state of the world. We introduce WMNav, a novel World Model-based Navigation framework powered by Vision-Language Models (VLMs). It predicts possible outcomes of decisions and builds memories to provide feedback to the policy module. To retain the predicted state of the environment, WMNav proposes the online maintained Curiosity Value Map as part of the world model memory to provide dynamic configuration for navigation policy. By decomposing according to a human-like thinking process, WMNav effectively alleviates the impact of model hallucination by making decisions based on the feedback difference between the world model plan and observation. To further boost efficiency, we implement a two-stage action proposer strategy: broad exploration followed by precise localization. Extensive evaluation on HM3D and MP3D validates WMNav surpasses existing zero-shot benchmarks in both success rate and exploration efficiency (absolute improvement: +3.2% SR and +3.2% SPL on HM3D, +13.5% SR and +1.1% SPL on MP3D). Project page: https://b0b8k1ng.github.io/WMNav/.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AppAgentX: Evolving GUI Agents as Proficient Smartphone Users</title>
<link>https://arxiv.org/abs/2503.02268</link>
<guid>https://arxiv.org/abs/2503.02268</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型(LLMs)、图形用户界面(GUIs)、智能代理、进化框架、效率

总结:<br />
本文提出了一种针对基于大型语言模型的GUI智能代理的新型进化框架，旨在提高操作效率并保持其智能和灵活性。该框架引入了一个记忆机制，用于记录代理执行任务的历史，通过分析这些历史，代理能够识别重复的动作序列，并进化出高层级动作作为快捷方式，替换低层级操作，从而提升效率。实验结果表明，相较于现有方法，该方法在效率和准确性上均有显著优势。未来，相关代码将开源以支持进一步研究。 <div>
arXiv:2503.02268v1 Announce Type: new 
Abstract: Recent advancements in Large Language Models (LLMs) have led to the development of intelligent LLM-based agents capable of interacting with graphical user interfaces (GUIs). These agents demonstrate strong reasoning and adaptability, enabling them to perform complex tasks that traditionally required predefined rules. However, the reliance on step-by-step reasoning in LLM-based agents often results in inefficiencies, particularly for routine tasks. In contrast, traditional rule-based systems excel in efficiency but lack the intelligence and flexibility to adapt to novel scenarios. To address this challenge, we propose a novel evolutionary framework for GUI agents that enhances operational efficiency while retaining intelligence and flexibility. Our approach incorporates a memory mechanism that records the agent's task execution history. By analyzing this history, the agent identifies repetitive action sequences and evolves high-level actions that act as shortcuts, replacing these low-level operations and improving efficiency. This allows the agent to focus on tasks requiring more complex reasoning, while simplifying routine actions. Experimental results on multiple benchmark tasks demonstrate that our approach significantly outperforms existing methods in both efficiency and accuracy. The code will be open-sourced to support further research.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Target Return Optimizer for Multi-Game Decision Transformer</title>
<link>https://arxiv.org/abs/2503.02311</link>
<guid>https://arxiv.org/abs/2503.02311</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主智能体、强化学习、变压器模型、MultiGame决策变换器、Multi-Game目标回报优化器(MTRO)

<br /><br />总结:
本文提出了一种名为Multi-Game Target Return Optimizer (MTRO)的新算法，旨在解决当前基于变压器的离线强化学习方法（如MultiGame决策变换器）在缺乏游戏特有知识的情况下依赖于人类专家的问题。MTRO利用仅有的离线数据集自主确定各游戏的目标回报，无需额外训练即可无缝集成到现有的MultiGame决策变换器框架中。通过在Atari游戏上的实验评估，MTRO显示出了增强RL策略性能的能力，从而为推动自主智能体开发领域的发展展现出潜力。 <div>
arXiv:2503.02311v1 Announce Type: new 
Abstract: Achieving autonomous agents with robust generalization capabilities across diverse games and tasks remains one of the ultimate goals in AI research. Recent advancements in transformer-based offline reinforcement learning, exemplified by the MultiGame Decision Transformer [Lee et al., 2022], have shown remarkable performance across various games or tasks. However, these approaches depend heavily on human expertise, presenting substantial challenges for practical deployment, particularly in scenarios with limited prior game-specific knowledge. In this paper, we propose an algorithm called Multi-Game Target Return Optimizer (MTRO) to autonomously determine game-specific target returns within the Multi-Game Decision Transformer framework using solely offline datasets. MTRO addresses the existing limitations by automating the target return configuration process, leveraging environmental reward information extracted from offline datasets. Notably, MTRO does not require additional training, enabling seamless integration into existing Multi-Game Decision Transformer architectures. Our experimental evaluations on Atari games demonstrate that MTRO enhances the performance of RL policies across a wide array of games, underscoring its potential to advance the field of autonomous agent development.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Partite Output Regulation of Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.02313</link>
<guid>https://arxiv.org/abs/2503.02313</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、多部分输出调节问题、合作输出调节问题、二部输出调节问题、分布式控制

<br /><br />总结:

本文提出了一种简单、与图无关的视角来划分图的节点集合，并为多智能体系统（MASs）提供了超越合作和二分的目标。首先，文章引入了$k$-分割变换的概念，以实现对节点集的任意期望划分。接着，利用这一概念定义了异构线性MAS的多部分输出调节问题（MORP），该问题涵盖了现有的合作输出调节问题（CORP）和二部输出调节问题（BORP）作为特例。MORP的目标是设计一个分布式控制律，使得属于同一集合内的每个从属节点能够渐近跟踪预设倍数的参考信号，同时确保闭环系统的内部稳定性。文章证明了MORP的解的存在性和充分必要条件可由CORP得出，并提出了首个基于前馈的分布式控制器参数设计策略，但其存在规模扩展性问题。进一步地，证明了一个较为宽松的结构条件下，该规模扩展性问题的条件可以被其无图依赖的版本所蕴含，这导致了第二个更具可扩展性的设计策略。最后，通过数值例子展示了MORP的普遍性和两个设计策略在规模扩展性方面的比较。 <div>
arXiv:2503.02313v1 Announce Type: new 
Abstract: This article proposes a simple, graph-independent perspective on partitioning the node set of a graph and provides multi-agent systems (MASs) with objectives beyond cooperation and bipartition. Specifically, we first introduce the notion of $k$-partition transformation to achieve any desired partition of the nodes. Then, we use this notion to formulate the multi-partite output regulation problem (MORP) of heterogeneous linear MASs, which comprises the existing cooperative output regulation problem (CORP) and bipartite output regulation problem (BORP) as subcases. The goal of the MORP is to design a distributed control law such that each follower that belongs to the same set in the partition asymptotically tracks a predefined multiple of a reference while ensuring the internal stability of the closed-loop system. It is shown that the necessary and sufficient conditions for the solvability of the MORP with a feedforward-based distributed control law follow from the CORP and lead to the first design strategy for the control parameters. However, it has a drawback in terms of scalability due to a partition-dependent condition. We prove that this condition is implied by its partition-independent version under a mild structural condition. This implication yields the second design strategy that is much more scalable than the first one. Finally, numerical examples are provided to illustrate the generality of the MORP and compare both design strategies regarding scalability.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EchoQA: A Large Collection of Instruction Tuning Data for Echocardiogram Reports</title>
<link>https://arxiv.org/abs/2503.02365</link>
<guid>https://arxiv.org/abs/2503.02365</guid>
<content:encoded><![CDATA[
<div> 关键词: QA数据集、echocardiogram报告、医疗数据库、大型语言模型、公平性审计

<br /><br />总结:
本文介绍了基于Medical Information Mart for Intensive Care数据库中获取的超声心动图报告构建的一个新颖的问题回答（QA）数据集，该数据集专门针对心脏病领域，包含771,244对涵盖多种心脏异常及其严重程度的QA问答。文章比较了不同类型的大型语言模型在零样本和少量样本情况下的表现，实验结果显示微调过的LLMs在各项QA评估指标上性能提升，验证了该数据集的价值。此外，通过临床医生的定性评价，评估了最佳模型的回答正确性。进一步地，进行了细致的公平性审计，探究LLMs在不同社会健康决定因素上的偏见与性能权衡。最终目标是推动这一领域的进步，为支持心脏病临床诊断的人工智能LLM代理建立基准，减轻临床医生的文档负担，助力医护人员更专注于患者护理工作。 <div>
arXiv:2503.02365v1 Announce Type: new 
Abstract: We introduce a novel question-answering (QA) dataset using echocardiogram reports sourced from the Medical Information Mart for Intensive Care database. This dataset is specifically designed to enhance QA systems in cardiology, consisting of 771,244 QA pairs addressing a wide array of cardiac abnormalities and their severity. We compare large language models (LLMs), including open-source and biomedical-specific models for zero-shot evaluation, and closed-source models for zero-shot and three-shot evaluation. Our results show that fine-tuning LLMs improves performance across various QA metrics, validating the value of our dataset. Clinicians also qualitatively evaluate the best-performing model to assess the LLM responses for correctness. Further, we conduct fine-grained fairness audits to assess the bias-performance trade-off of LLMs across various social determinants of health. Our objective is to propel the field forward by establishing a benchmark for LLM AI agents aimed at supporting clinicians with cardiac differential diagnoses, thereby reducing the documentation burden that contributes to clinician burnout and enabling healthcare professionals to focus more on patient care.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Teaching Metric Distance to Autoregressive Multimodal Foundational Models</title>
<link>https://arxiv.org/abs/2503.02379</link>
<guid>https://arxiv.org/abs/2503.02379</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、DIST2Loss、距离感知框架、自回归离散模型、多模态应用

总结:
本文介绍了DIST2Loss，这是一个针对大型语言模型扩展到数学、多模态理解和具身代理等领域的距离感知框架。该框架设计用于通过利用预定义的输出令牌间的距离关系来训练自回归离散模型。核心思想是将内在距离度量衍生出的连续指数分布转化为与模型架构兼容的离散分类优化目标，使模型能够在生成令牌过程中学习并保持有意义的距离关系。实证评估显示，DIST2Loss在包括视觉定位、机器人操作、生成式奖励建模和使用向量量化特征的图像生成等多种多模态应用中表现出了持续的性能提升，尤其是在有限训练数据的情况下，凸显了DIST2Loss在资源受限环境中的有效性。 <div>
arXiv:2503.02379v1 Announce Type: new 
Abstract: As large language models expand beyond natural language to domains such as mathematics, multimodal understanding, and embodied agents, tokens increasingly reflect metric relationships rather than purely linguistic meaning. We introduce DIST2Loss, a distance-aware framework designed to train autoregressive discrete models by leveraging predefined distance relationships among output tokens. At its core, DIST2Loss transforms continuous exponential family distributions derived from inherent distance metrics into discrete, categorical optimization targets compatible with the models' architectures. This approach enables the models to learn and preserve meaningful distance relationships during token generation while maintaining compatibility with existing architectures. Empirical evaluations show consistent performance gains in diverse multimodal applications, including visual grounding, robotic manipulation, generative reward modeling, and image generation using vector-quantized features. These improvements are pronounced in cases of limited training data, highlighting DIST2Loss's effectiveness in resource-constrained settings.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ReSo: A Reward-driven Self-organizing LLM-based Multi-Agent System for Reasoning Tasks</title>
<link>https://arxiv.org/abs/2503.02390</link>
<guid>https://arxiv.org/abs/2503.02390</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、灵活性、可扩展性、优化策略、ReSo

总结:
本文提出了一种名为ReSo的新框架，用于解决大规模语言模型在复杂问题求解中的多智能体系统（MAS）合作优化问题。ReSo着重解决了现有MAS框架在灵活性和可扩展性方面的局限性，并引入了任务图生成与奖励驱动的两阶段代理选择过程。其核心创新点在于协作奖励模型，该模型能为MAS的合作优化提供细粒度的奖励信号。此外，文中还介绍了一个自动化数据合成框架，可用于无需人类注释的MAS基准测试生成。实验结果显示，ReSo在Math-MAS和SciBench-MAS上分别取得了33.7％和32.3％的准确率，而其他方法则完全失败。相关代码已开源，可在https://github.com/hengzzzhou/ReSo 获取。<br /><br /> <div>
arXiv:2503.02390v1 Announce Type: new 
Abstract: Multi-agent systems have emerged as a promising approach for enhancing the reasoning capabilities of large language models in complex problem-solving. However, current MAS frameworks are limited by poor flexibility and scalability, with underdeveloped optimization strategies. To address these challenges, we propose ReSo, which integrates task graph generation with a reward-driven two-stage agent selection process. The core of ReSo is the proposed Collaborative Reward Model, which can provide fine-grained reward signals for MAS cooperation for optimization. We also introduce an automated data synthesis framework for generating MAS benchmarks, without human annotations. Experimentally, ReSo matches or outperforms existing methods. ReSo achieves \textbf{33.7\%} and \textbf{32.3\%} accuracy on Math-MAS and SciBench-MAS SciBench, while other methods completely fail. Code is available at: \href{https://github.com/hengzzzhou/ReSo}{ReSo}
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PersonaX: A Recommendation Agent Oriented User Modeling Framework for Long Behavior Sequence</title>
<link>https://arxiv.org/abs/2503.02398</link>
<guid>https://arxiv.org/abs/2503.02398</guid>
<content:encoded><![CDATA[
<div> 关键词：推荐代理、大型语言模型、用户建模、上下文限制、行为序列

总结:
PersonaX是一个与代理无关的大型语言模型用户建模框架，旨在解决现有方法在处理长用户生成内容时面临的上下文限制和性能退化问题。它通过离线子行为序列（SBS）选择和多人格构建来应对挑战。PersonaX 离线提取紧凑的SBS片段以捕捉用户的多样化兴趣，生成精细的文本人格并缓存以便高效在线检索，从而保证了用于提示的用户人格对当前上下文的高度相关性，同时消除了在线用户建模的延迟开销。在确保采样数据具有原型性和多样性的平衡下，PersonaX实现了长度小于5的行为序列高代表性选取。实验验证了PersonaX在高质量用户画像方面的有效性和适应性。仅使用30%至50%的行为数据（序列长度为480），PersonaX结合AgentCF可以带来3%至11%的绝对性能提升，而与Agent4Rec整合则可实现10%至50%的增益。PersonaX作为一个代理无关的框架，为可扩展的用户建模设立了新基准，为基于LLM的更精确和高效的推荐代理铺平道路。 <div>
arXiv:2503.02398v1 Announce Type: new 
Abstract: Recommendation agents leverage large language models for user modeling LLM UM to construct textual personas guiding alignment with real users. However existing LLM UM methods struggle with long user generated content UGC due to context limitations and performance degradation. To address this sampling strategies prioritize relevance or recency are often applied yet they inevitably neglect the diverse user interests embedded within the discarded behaviors resulting in incomplete modeling and degraded profiling quality. Furthermore relevance based sampling requires real time retrieval forcing the user modeling process to operate online which introduces significant latency overhead. In this paper we propose PersonaX an agent agnostic LLM UM framework that tackles these challenges through sub behavior sequence SBS selection and offline multi persona construction. PersonaX extracts compact SBS segments offline to capture diverse user interests generating fine grained textual personas that are cached for efficient online retrieval. This approach ensures that the user persona used for prompting remains highly relevant to the current context while eliminating the need for online user modeling. For SBS selection we ensure both efficiency length less than five and high representational quality by balancing prototypicality and diversity within the sampled data. Extensive experiments validate the effectiveness and versatility of PersonaX in high quality user profiling. Utilizing only 30 to 50 percent of the behavioral data with a sequence length of 480 integrating PersonaX with AgentCF yields an absolute performance improvement of 3 to 11 percent while integration with Agent4Rec results in a gain of 10 to 50 percent. PersonaX as an agent agnostic framework sets a new benchmark for scalable user modeling paving the way for more accurate and efficient LLM driven recommendation agents.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VisAgent: Narrative-Preserving Story Visualization Framework</title>
<link>https://arxiv.org/abs/2503.02399</link>
<guid>https://arxiv.org/abs/2503.02399</guid>
<content:encoded><![CDATA[
<div> 关键词: 故事可视化、叙事要素、图像序列、VisAgent、多智能体框架

<br />
总结:
本文提出了一个名为VisAgent的无需训练的多智能体框架，用于理解和可视化故事中的关键场景。该框架针对现有故事可视化研究忽视深层叙事本质的问题，强调了故事提炼、语义一致性和上下文连贯性三个方面。VisAgent的工作流程中，多个专业智能体协同工作：(1)根据叙事结构细化多层次的提示；(2)将细化后的提示、场景元素和主体布局等生成元素无缝整合到最终图像中。实证有效性验证了该框架适用于实际的故事可视化应用。 <div>
arXiv:2503.02399v1 Announce Type: new 
Abstract: Story visualization is the transformation of narrative elements into image sequences. While existing research has primarily focused on visual contextual coherence, the deeper narrative essence of stories often remains overlooked. This limitation hinders the practical application of these approaches, as generated images frequently fail to capture the intended meaning and nuances of the narrative fully. To address these challenges, we propose VisAgent, a training-free multi-agent framework designed to comprehend and visualize pivotal scenes within a given story. By considering story distillation, semantic consistency, and contextual coherence, VisAgent employs an agentic workflow. In this workflow, multiple specialized agents collaborate to: (i) refine layered prompts based on the narrative structure and (ii) seamlessly integrate \gt{generated} elements, including refined prompts, scene elements, and subject placement, into the final image. The empirically validated effectiveness confirms the framework's suitability for practical story visualization applications.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoEval: A Practical Framework for Autonomous Evaluation of Mobile Agents</title>
<link>https://arxiv.org/abs/2503.02403</link>
<guid>https://arxiv.org/abs/2503.02403</guid>
<content:encoded><![CDATA[
<div> 关键词: AutoEval、移动代理、自动评估、任务奖励信号、Judge System

总结:
AutoEval是一个针对移动代理的自动化评价框架，旨在无需人工努力即可测试移动代理。该框架通过设计Structured Substate Representation来描述UI状态变化，从而自动生成任务奖励信号。接着利用Judge System，根据这些自动产生的任务奖励信号对代理人进行自主性能评估。只需提供任务描述，AutoEval即可为该任务提供精细的性能反馈，无需额外的人工努力。实验证明，该框架生成的任务奖励信号覆盖了超过93%的人工注释奖励信号，而其Judge System的手动验证准确率达到了94%。最后，使用该框架评估了最先进的移动代理，揭示了它们的性能特征和局限性。<br /><br /> <div>
arXiv:2503.02403v1 Announce Type: new 
Abstract: Accurate and systematic evaluation of mobile agents can significantly advance their development and real-world applicability. However, existing benchmarks for mobile agents lack practicality and scalability due to the extensive manual effort required to define task reward signals and implement corresponding evaluation codes. To this end, we propose AutoEval, an autonomous agent evaluation framework that tests a mobile agent without any manual effort. First, we design a Structured Substate Representation to describe the UI state changes while agent execution, such that task reward signals can be automatically generated. Second, we utilize a Judge System that can autonomously evaluate agents' performance given the automatically generated task reward signals. By providing only a task description, our framework evaluates agents with fine-grained performance feedback to that task without any extra manual effort. We implement a prototype of our framework and validate the automatically generated task reward signals, finding over 93% coverage to human-annotated reward signals. Moreover, to prove the effectiveness of our autonomous Judge System, we manually verify its judge results and demonstrate that it achieves 94% accuracy. Finally, we evaluate the state-of-the-art mobile agents using our framework, providing detailed insights into their performance characteristics and limitations.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Linear Convergence of Distributed Compressed Optimization with Equality Constraints</title>
<link>https://arxiv.org/abs/2503.02468</link>
<guid>https://arxiv.org/abs/2503.02468</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式优化、强凸优化、时空压缩通信、平等约束、分布式滤波器

总结:
<br />
本文研究了具有时空压缩通信和平等约束的分布式强凸优化问题。针对每个代理持有局部平等约束的情况，文中提出了一种分布式鞍点算法，该算法利用分布式滤波器来导出传输状态的误差，以实现时空压缩目的。证明了由此产生的分布式压缩算法能实现线性收敛。进一步地，将该算法推广到每个代理持有一部分全局平等约束（即，各代理之间的约束相互耦合）的情形。通过引入额外的设计自由度，证明这种全局平等约束可等价于每个代理持有单一平等约束的情况，从而可以调整提出的分布式压缩鞍点算法，仍能达到线性收敛的效果。数值模拟验证了所提算法的有效性。 <div>
arXiv:2503.02468v1 Announce Type: new 
Abstract: In this paper, the distributed strongly convex optimization problem is studied with spatio-temporal compressed communication and equality constraints. For the case where each agent holds an distributed local equality constraint, a distributed saddle-point algorithm is proposed by employing distributed filters to derive errors of the transmitted states for spatio-temporal compression purposes. It is shown that the resulting distributed compressed algorithm achieves linear convergence. Furthermore, the algorithm is generalized to the case where each agent holds a portion of the global equality constraint, i.e., the constraints across agents are coupled. By introducing an additional design freedom, the global equality constraint is shown to be equivalent to the one where each agent holds an equality constraint, for which the proposed distributed compressed saddle-point algorithm can be adapted to achieve linear convergence. Numerical simulations are adopted to validate the effectiveness of the proposed algorithms.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ROCKET-2: Steering Visuomotor Policy via Cross-View Goal Alignment</title>
<link>https://arxiv.org/abs/2503.02505</link>
<guid>https://arxiv.org/abs/2503.02505</guid>
<content:encoded><![CDATA[
<div> 关键词：目标规范方法、跨视图目标对齐框架、行为克隆、空间推理能力、ROCKET-2

<br /><br />总结:
本文提出了一种新的目标规范方法，旨在实现人类用户在具象环境中指导智能代理互动时具有语义清晰、空间敏感和直观性。该方法创新地采用了一个跨视图目标对齐框架，允许用户通过自身视角的分割掩模来指定目标对象，而无需依赖于智能代理的观察结果。由于单纯的行为克隆无法解决因人与代理视角差异导致的意图对齐问题，文章提出了跨视图一致性损失和目标可见性损失两个辅助目标，以增强智能代理的空间推理能力。基于此，研究者开发出了名为ROCKET-2的最新一代智能代理，在Minecraft中进行了训练，并实现了推理效率提升3至6倍的效果。ROCKET-2成为首个能直接从人类视角解读目标的智能代理，为优化人机交互开辟了新途径。 <div>
arXiv:2503.02505v1 Announce Type: new 
Abstract: We aim to develop a goal specification method that is semantically clear, spatially sensitive, and intuitive for human users to guide agent interactions in embodied environments. Specifically, we propose a novel cross-view goal alignment framework that allows users to specify target objects using segmentation masks from their own camera views rather than the agent's observations. We highlight that behavior cloning alone fails to align the agent's behavior with human intent when the human and agent camera views differ significantly. To address this, we introduce two auxiliary objectives: cross-view consistency loss and target visibility loss, which explicitly enhance the agent's spatial reasoning ability. According to this, we develop ROCKET-2, a state-of-the-art agent trained in Minecraft, achieving an improvement in the efficiency of inference 3x to 6x. We show ROCKET-2 can directly interpret goals from human camera views for the first time, paving the way for better human-agent interaction.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LTL Verification of Memoryful Neural Agents</title>
<link>https://arxiv.org/abs/2503.02512</link>
<guid>https://arxiv.org/abs/2503.02512</guid>
<content:encoded><![CDATA[
<div> 关键词: Memoryful Neural Multi-Agent Systems (MN-MAS), Linear Temporal Logic (LTL), Verification, Bounded Model Checking, Constraint Solving

<br /><br />总结:
本文提出了一种针对带有记忆的神经多智能体系统(MN-MAS)的验证框架，该框架能对全线性时间逻辑(LTL)规范进行验证。MN-MAS中，智能体与非确定性的部分可观测环境交互，包括基于feed-forward和循环神经网络或状态空间模型的多智能体系统。与先前方法不同的是，该框架支持有限和无限LTL规格说明的验证。研究者利用成熟的有界模型检查技术，如环路搜索和不变量综合，将验证问题简化为约束求解问题。为了解决这些约束，他们开发了基于边界传播、混合整数线性规划和自适应分割的有效方法。实验在Gymnasium和PettingZoo库中的单智能体和多智能体环境中展示了算法的有效性，首次实现了对无限规格说明的验证，并将有限规格说明的验证时间相比现有技术提高了数量级。 <div>
arXiv:2503.02512v1 Announce Type: new 
Abstract: We present a framework for verifying Memoryful Neural Multi-Agent Systems (MN-MAS) against full Linear Temporal Logic (LTL) specifications. In MN-MAS, agents interact with a non-deterministic, partially observable environment. Examples of MN-MAS include multi-agent systems based on feed-forward and recurrent neural networks or state-space models. Different from previous approaches, we support the verification of both bounded and unbounded LTL specifications. We leverage well-established bounded model checking techniques, including lasso search and invariant synthesis, to reduce the verification problem to that of constraint solving. To solve these constraints, we develop efficient methods based on bound propagation, mixed-integer linear programming, and adaptive splitting. We evaluate the effectiveness of our algorithms in single and multi-agent environments from the Gymnasium and PettingZoo libraries, verifying unbounded specifications for the first time and improving the verification time for bounded specifications by an order of magnitude compared to the SoA.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generator-Assistant Stepwise Rollback Framework for Large Language Model Agent</title>
<link>https://arxiv.org/abs/2503.02519</link>
<guid>https://arxiv.org/abs/2503.02519</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM)，分步推理框架，错误传播，Generator-Assistant Stepwise Rollback (GA-Rollback)，决策改进

总结:
本文提出了一种针对大型语言模型 (LLM) 代理的新框架——Generator-Assistant Stepwise Rollback (GA-Rollback)，旨在解决传统分步推理框架中因一步一思考导致的不可逆错误传播问题。该框架利用一个生成器与环境交互，而助手负责检查生成器产生的每个动作并触发回滚操作以纠正错误。文章还介绍了两种适用于回滚场景的附加策略，进一步提升其有效性。实验结果显示，GA-Rollback 在三个常用基准测试上显著优于多个强基线。分析表明，GA-Rollback 可作为一个稳健的即插即用模块，能够与其他方法无缝集成。 <div>
arXiv:2503.02519v1 Announce Type: new 
Abstract: Large language model (LLM) agents typically adopt a step-by-step reasoning framework, in which they interleave the processes of thinking and acting to accomplish the given task. However, this paradigm faces a deep-rooted one-pass issue whereby each generated intermediate thought is plugged into the trajectory regardless of its correctness, which can cause irreversible error propagation. To address the issue, this paper proposes a novel framework called Generator-Assistant Stepwise Rollback (GA-Rollback) to induce better decision-making for LLM agents. Particularly, GA-Rollback utilizes a generator to interact with the environment and an assistant to examine each action produced by the generator, where the assistant triggers a rollback operation upon detection of incorrect actions. Moreover, we introduce two additional strategies tailored for the rollback scenario to further improve its effectiveness. Extensive experiments show that GA-Rollback achieves significant improvements over several strong baselines on three widely used benchmarks. Our analysis further reveals that GA-Rollback can function as a robust plug-and-play module, integrating seamlessly with other methods.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Playing games with Large language models: Randomness and strategy</title>
<link>https://arxiv.org/abs/2503.02582</link>
<guid>https://arxiv.org/abs/2503.02582</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、游戏交互、随机化、战略适应、Rock Paper Scissors (RPS)、Prisoners Dilemma (PD)、偏置输出、损失规避策略、多智能体系统、战略决策限制

总结:<br />
本文研究了大型语言模型（LLMs）是否能够玩游戏以及它们在同时和顺序游戏交互中的随机化与战略适应能力。实验集中在GPT-4o-Mini-2024-08-17上，通过玩Rock Paper Scissors (RPS)和Prisoners Dilemma (PD)两款游戏来考察其性能。结果表明，尽管LLMs常被描述为随机的鹦鹉，但它们在生成“随机”输出时存在显著偏置。在重复游戏中，LLMs展现出损失规避的策略，RPS游戏趋向于僵持状态，而PD游戏则根据提示设计系统性地在合作和竞争之间转变。文章还介绍了独立代理交互的编程工具及实施过程中遇到的Agentic AI挑战。研究表明，虽然LLMs确实可以玩游戏，但表现并不出色，这为多智能体LLM系统中使用LLMs以及当前针对战略决策的模型输出方法的局限性提供了启示。 <div>
arXiv:2503.02582v1 Announce Type: new 
Abstract: Playing games has a long history of describing intricate interactions in simplified forms. In this paper we explore if large language models (LLMs) can play games, investigating their capabilities for randomisation and strategic adaptation through both simultaneous and sequential game interactions. We focus on GPT-4o-Mini-2024-08-17 and test two games between LLMs: Rock Paper Scissors (RPS) and games of strategy (Prisoners Dilemma PD). LLMs are often described as stochastic parrots, and while they may indeed be parrots, our results suggest that they are not very stochastic in the sense that their outputs - when prompted to be random - are often very biased. Our research reveals that LLMs appear to develop loss aversion strategies in repeated games, with RPS converging to stalemate conditions while PD shows systematic shifts between cooperative and competitive outcomes based on prompt design. We detail programmatic tools for independent agent interactions and the Agentic AI challenges faced in implementation. We show that LLMs can indeed play games, just not very well. These results have implications for the use of LLMs in multi-agent LLM systems and showcase limitations in current approaches to model output for strategic decision-making.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Succinct Ambiguous Contracts</title>
<link>https://arxiv.org/abs/2503.02592</link>
<guid>https://arxiv.org/abs/2503.02592</guid>
<content:encoded><![CDATA[
<div> 关键词: 模糊合同、简洁模糊合同、单结果支付合同、复杂性、算法

<br /><br />总结:
本文探讨了现实世界中具有模糊性的合同问题。研究者们先前证明最优模糊合同可以简化为单结果支付(SOP)合同并能在多项式时间内求解。然而，当限制模糊合同最多只能包含k个经典合同时，这一简化不再成立，使得合同结构和计算变得更复杂。文章提出了一种“移位最小支付合同”的简单分治原则，揭示了最优简洁模糊合同的结构，并基于此设计了一个用于寻找最优简洁模糊合同的算法。对于接近n值的k，该算法是多项式的，但当k为常数或$k=\beta n$（其中$\beta\in(0,1)$）时，算法为指数级，并证明了其在这些问题上的NPC难度。最后，引入了简洁度差距度量来量化由于简洁性带来的损失，并对这个差距提供了上界和下界。特别地，若只缺少一个合同就无法达到无限制情况下的效用，则主体的效用会降低一半，这一结果已被证明是紧致的。 <div>
arXiv:2503.02592v1 Announce Type: new 
Abstract: Real-world contracts are often ambiguous. Recent work by D\"utting et al. (EC 2023, Econometrica 2024) models ambiguous contracts as a collection of classic contracts, with the agent choosing an action that maximizes his worst-case utility. In this model, optimal ambiguous contracts have been shown to be ``simple" in that they consist of single-outcome payment (SOP) contracts, and can be computed in polynomial-time. However, this simplicity is challenged by the potential need for many classic contracts. Motivated by this, we explore \emph{succinct} ambiguous contracts, where the ambiguous contract is restricted to consist of at most $k$ classic contracts. Unlike in the unrestricted case, succinct ambiguous contracts are no longer composed solely of SOP contracts, making both their structure and computation more complex.
  We show that, despite this added complexity, optimal succinct ambiguous contracts are governed by a simple divide-and-conquer principle, showing that they consist of ``shifted min-pay contracts" for a suitable partition of the actions. This structural insight implies a characterization of implementability by succinct ambiguous contracts, and can be leveraged to devise an algorithm for the optimal succinct ambiguous contract. While this algorithm is polynomial for $k$ sufficiently close to $n$, for smaller values of $k$, this algorithm is exponential, and we show that this is inevitable (unless P=NP) by establishing NP-hardness for any constant $k$, or $k=\beta n$ for some $\beta\in(0,1)$. Finally, we introduce the succinctness gap measure to quantify the loss incurred due to succinctness, and provide upper and lower bounds on this gap. Interestingly, in the case where we are missing just a single contract from the number sufficient to obtain the utility of the unrestricted case, the principal's utility drops by a factor of $2$, and this is tight.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Resource-Efficient Affordance Grounding with Complementary Depth and Semantic Prompts</title>
<link>https://arxiv.org/abs/2503.02600</link>
<guid>https://arxiv.org/abs/2503.02600</guid>
<content:encoded><![CDATA[
<div> 关键词：affordance、多模态、BiT-Align框架、Bypass Prompt Module (BPM)、Text Feature Guidance (TFG)

总结:
本文提出了一种新的多模态感知方法——BiT-Align图像深度文本 affordance 映射框架，用于解决现有方法在提取有用信息方面的局限性。该框架包括Bypass Prompt Module (BPM)和Text Feature Guidance (TFG)注意力选择机制。BPM通过将辅助模态深度图像直接作为提示融入主要模态RGB图像的编码过程，减少了模型参数并提高了功能区域定位精度。而TFG机制利用文本特征引导图像编码器中的注意力头选择与增强，从而提升对 affordance 特征的理解。实验结果显示，该方法在公共AGD20K和HICO-IIF数据集上表现优异，相比于当前最优方法，在AGD20K数据集上的KLD指标提高了6.0%，同时模型参数减少了88.8%，显示出了实际应用价值。源代码将在https://github.com/DAWDSE/BiT-Align 公开发布。 <div>
arXiv:2503.02600v1 Announce Type: new 
Abstract: Affordance refers to the functional properties that an agent perceives and utilizes from its environment, and is key perceptual information required for robots to perform actions. This information is rich and multimodal in nature. Existing multimodal affordance methods face limitations in extracting useful information, mainly due to simple structural designs, basic fusion methods, and large model parameters, making it difficult to meet the performance requirements for practical deployment. To address these issues, this paper proposes the BiT-Align image-depth-text affordance mapping framework. The framework includes a Bypass Prompt Module (BPM) and a Text Feature Guidance (TFG) attention selection mechanism. BPM integrates the auxiliary modality depth image directly as a prompt to the primary modality RGB image, embedding it into the primary modality encoder without introducing additional encoders. This reduces the model's parameter count and effectively improves functional region localization accuracy. The TFG mechanism guides the selection and enhancement of attention heads in the image encoder using textual features, improving the understanding of affordance characteristics. Experimental results demonstrate that the proposed method achieves significant performance improvements on public AGD20K and HICO-IIF datasets. On the AGD20K dataset, compared with the current state-of-the-art method, we achieve a 6.0% improvement in the KLD metric, while reducing model parameters by 88.8%, demonstrating practical application values. The source code will be made publicly available at https://github.com/DAWDSE/BiT-Align.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-aligned Safe Reinforcement Learning for Highway On-Ramp Merging in Dense Traffic</title>
<link>https://arxiv.org/abs/2503.02624</link>
<guid>https://arxiv.org/abs/2503.02624</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习（RL）、自动驾驶、安全性、风险偏好、约束马尔科夫决策过程（CMDP）

<br /><br />总结:
本文提出了一种面向人类安全的人工智能驾驶策略——基于约束马尔科夫决策过程（CMDP）和模型预测控制（MPC）的安全强化学习方法，用于解决自动驾驶车辆的并线决策问题。该方法将用户风险偏好纳入安全性约束中，并通过模糊控制方法根据风险偏好与交通密度计算成本限制以调整策略的安全水平。为避免不安全或无效动作，设计了一个预先执行RL动作的动作屏蔽机制，利用MPC进行碰撞检查。理论上证明了屏蔽机制能有效提升RL策略的安全性和样本效率。仿真实验表明，该方法可在保证交通效率的同时显著减少安全隐患。此外，由于在CMDP中使用了风险偏好感知的约束以及在训练阶段即采用动作屏蔽，使得最终策略的安全性可调，同时减少了在线真实环境中学习时的安全违规行为，提供了一种颇具前景的解决方案。 <div>
arXiv:2503.02624v1 Announce Type: new 
Abstract: Most reinforcement learning (RL) approaches for the decision-making of autonomous driving consider safety as a reward instead of a cost, which makes it hard to balance the tradeoff between safety and other objectives. Human risk preference has also rarely been incorporated, and the trained policy might be either conservative or aggressive for users. To this end, this study proposes a human-aligned safe RL approach for autonomous merging, in which the high-level decision problem is formulated as a constrained Markov decision process (CMDP) that incorporates users' risk preference into the safety constraints, followed by a model predictive control (MPC)-based low-level control. The safety level of RL policy can be adjusted by computing cost limits of CMDP's constraints based on risk preferences and traffic density using a fuzzy control method. To filter out unsafe or invalid actions, we design an action shielding mechanism that pre-executes RL actions using an MPC method and performs collision checks with surrounding agents. We also provide theoretical proof to validate the effectiveness of the shielding mechanism in enhancing RL's safety and sample efficiency. Simulation experiments in multiple levels of traffic densities show that our method can significantly reduce safety violations without sacrificing traffic efficiency. Furthermore, due to the use of risk preference-aware constraints in CMDP and action shielding, we can not only adjust the safety level of the final policy but also reduce safety violations during the training stage, proving a promising solution for online learning in real-world environments.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MPO: Boosting LLM Agents with Meta Plan Optimization</title>
<link>https://arxiv.org/abs/2503.02682</link>
<guid>https://arxiv.org/abs/2503.02682</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 交互式规划任务, 计划幻觉, 元计划优化 (MPO), 持续优化

总结:
近期，大型语言模型（LLMs）的进步促使基于LLM的代理能够在互动规划任务中取得成功。然而，现有的方法常常遭受计划幻觉问题困扰，并且针对每个新代理都需要重新训练。为了解决这些问题，本文提出了元计划优化（MPO）框架，该框架通过直接整合显式的指导来增强代理的规划能力。与依赖需要大量人力或质量无法保证的复杂知识的方法不同，MPO利用高层次的通用指导——即元计划来辅助代理规划，并根据代理执行任务的反馈对元计划进行持续优化。实验结果表明，MPO在两个代表性任务上显著优于现有基线。此外，分析显示MPO提供了一个即插即用的解决方案，能够提升任务完成效率以及在未见过的新场景中的泛化能力。 <div>
arXiv:2503.02682v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have enabled LLM-based agents to successfully tackle interactive planning tasks. However, despite their successes, existing approaches often suffer from planning hallucinations and require retraining for each new agent. To address these challenges, we propose the Meta Plan Optimization (MPO) framework, which enhances agent planning capabilities by directly incorporating explicit guidance. Unlike previous methods that rely on complex knowledge, which either require significant human effort or lack quality assurance, MPO leverages high-level general guidance through meta plans to assist agent planning and enables continuous optimization of the meta plans based on feedback from the agent's task execution. Our experiments conducted on two representative tasks demonstrate that MPO significantly outperforms existing baselines. Moreover, our analysis indicates that MPO provides a plug-and-play solution that enhances both task completion efficiency and generalization capabilities in previous unseen scenarios.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinArena: A Human-Agent Collaboration Framework for Financial Market Analysis and Forecasting</title>
<link>https://arxiv.org/abs/2503.02692</link>
<guid>https://arxiv.org/abs/2503.02692</guid>
<content:encoded><![CDATA[
<div> 关键词: FinArena、混合专家模型、多模态金融数据、个性化投资、适应性检索增强生成法

<br /><br />总结:
本文提出了一种新的投资决策支持框架FinArena，该框架结合了多模态金融数据分析与用户交互，旨在提升股票趋势预测和实现个性化投资决策。FinArena借鉴混合专家(MoE)模型理念，其人类模块通过互动界面获取个体风险偏好以制定个性化投资策略；机器模块利用基于大型语言模型的多代理系统整合多种数据源，如股票价格、新闻文章和财务报表。为解决大型语言模型处理非结构化新闻数据时可能出现的幻觉问题，FinArena采用了适应性检索增强生成(RAG)方法。最后，一个通用专家代理会根据从多模态数据中抽取的特征及投资者的个人风险偏好做出投资决策。实验表明，FinArena在股票趋势预测上超越了传统及现有先进基准，并在针对不同风险偏好的交易模拟中展现出颇具前景的结果，从而证实了FinArena有望通过将战略洞见与个性化的风险考量相结合来提升投资成果。 <div>
arXiv:2503.02692v1 Announce Type: new 
Abstract: To improve stock trend predictions and support personalized investment decisions, this paper proposes FinArena, a novel Human-Agent collaboration framework. Inspired by the mixture of experts (MoE) approach, FinArena combines multimodal financial data analysis with user interaction. The human module features an interactive interface that captures individual risk preferences, allowing personalized investment strategies. The machine module utilizes a Large Language Model-based (LLM-based) multi-agent system to integrate diverse data sources, such as stock prices, news articles, and financial statements. To address hallucinations in LLMs, FinArena employs the adaptive Retrieval-Augmented Generative (RAG) method for processing unstructured news data. Finally, a universal expert agent makes investment decisions based on the features extracted from multimodal data and investors' individual risk preferences. Extensive experiments show that FinArena surpasses both traditional and state-of-the-art benchmarks in stock trend prediction and yields promising results in trading simulations across various risk profiles. These findings highlight FinArena's potential to enhance investment outcomes by aligning strategic insights with personalized risk considerations.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Federated Learning for Privacy-Preserving Feedforward Control in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2503.02693</link>
<guid>https://arxiv.org/abs/2503.02693</guid>
<content:encoded><![CDATA[
<div> 关键词：Feedforward控制、反馈控制、联邦学习、隐私保护、多智能体系统

<br /><br />总结:
本文提出了一种将联邦学习(FL)整合到前馈控制(FF)中的创新方法，旨在解决在多智能体系统中设计数据驱动的FF控制器所面临的隐私和通信成本问题。该方法允许各智能体在不共享私人或专有数据的情况下，利用本地数据训练神经FF控制器，并仅贡献模型更新参与全局聚合过程，从而实现数据隐私、通信效率及控制器的分布式持续改进。通过在自动驾驶场景中的应用案例，证明了该方法的有效性，车辆采用轨迹跟踪反馈控制器并结合基于FL的神经FF控制，与纯FB控制相比，显著提升了跟踪性能，并且在不交换私有车辆特定数据的情况下，达到了与集中式神经FF控制相当的效果。这项工作揭示了FL在保障隐私的同时，为多智能体控制系统中的FF控制学习提供了可扩展和高效的可能性，为进一步发展自主系统的应用奠定了基础。 <div>
arXiv:2503.02693v1 Announce Type: new 
Abstract: Feedforward control (FF) is often combined with feedback control (FB) in many control systems, improving tracking performance, efficiency, and stability. However, designing effective data-driven FF controllers in multi-agent systems requires significant data collection, including transferring private or proprietary data, which raises privacy concerns and incurs high communication costs. Therefore, we propose a novel approach integrating Federated Learning (FL) into FF control to address these challenges. This approach enables privacy-preserving, communication-efficient, and decentralized continuous improvement of FF controllers across multiple agents without sharing personal or proprietary data. By leveraging FL, each agent learns a local, neural FF controller using its data and contributes only model updates to a global aggregation process, ensuring data privacy and scalability. We demonstrate the effectiveness of our method in an autonomous driving use case. Therein, vehicles equipped with a trajectory-tracking feedback controller are enhanced by FL-based neural FF control. Simulations highlight significant improvements in tracking performance compared to pure FB control, analogous to model-based FF control. We achieve comparable tracking performance without exchanging private vehicle-specific data compared to a centralized neural FF control. Our results underscore the potential of FL-based neural FF control to enable privacy-preserving learning in multi-agent control systems, paving the way for scalable and efficient autonomous systems applications.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Metaphor to Mechanism: How LLMs Decode Traditional Chinese Medicine Symbolic Language for Modern Clinical Relevance</title>
<link>https://arxiv.org/abs/2503.02760</link>
<guid>https://arxiv.org/abs/2503.02760</guid>
<content:encoded><![CDATA[
<div> 关键词：中医药、西医、隐喻解释、多智能体框架、思维链

<br /><br />总结:
本文提出了一种针对传统中医中丰富隐喻表达的理解与映射到西方医学病理生理学的新型多智能体和思维链框架。该框架包括专门的中医药专家代理、西医专家代理以及协调员代理，通过逐步的思维链提示实现透明推理和冲突解决。文章详细介绍了构建隐喻丰富的中医药数据集的方法，探讨了有效整合多智能体协作和思维链推理的策略，并阐述了指导不同医学体系间隐喻解释的理论基础。该系统设计有望支持临床决策、跨系统教育项目及整合医疗研究，并为协调中医药象征性语言与西医机制化关注点提供了一个坚实的框架，但其潜在优势和局限性仍有待未来实验验证。 <div>
arXiv:2503.02760v1 Announce Type: new 
Abstract: Metaphorical expressions are abundant in Traditional Chinese Medicine (TCM), conveying complex disease mechanisms and holistic health concepts through culturally rich and often abstract terminology. Bridging these metaphors to anatomically driven Western medical (WM) concepts poses significant challenges for both automated language processing and real-world clinical practice. To address this gap, we propose a novel multi-agent and chain-of-thought (CoT) framework designed to interpret TCM metaphors accurately and map them to WM pathophysiology. Specifically, our approach combines domain-specialized agents (TCM Expert, WM Expert) with a Coordinator Agent, leveraging stepwise chain-of-thought prompts to ensure transparent reasoning and conflict resolution. We detail a methodology for building a metaphor-rich TCM dataset, discuss strategies for effectively integrating multi-agent collaboration and CoT reasoning, and articulate the theoretical underpinnings that guide metaphor interpretation across distinct medical paradigms. We present a comprehensive system design and highlight both the potential benefits and limitations of our approach, while leaving placeholders for future experimental validation. Our work aims to support clinical decision-making, cross-system educational initiatives, and integrated healthcare research, ultimately offering a robust scaffold for reconciling TCM's symbolic language with the mechanistic focus of Western medicine.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Quantitative Resilience Modeling for Autonomous Cyber Defense</title>
<link>https://arxiv.org/abs/2503.02780</link>
<guid>https://arxiv.org/abs/2503.02780</guid>
<content:encoded><![CDATA[
<div> 关键词：cyber resilience、网络韧性、quantifiable formulation、CybORG环境、reinforcement learning (RL)

总结:<br />
本文提出了一个量化网络韧性的定义，考虑了防御者多方面的操作目标、网络资源对日常运行的重要性以及攻击下系统韧性的可解释性。研究在CybORG环境下，一个基于强化学习的自主网络安全防御框架中，分析了韧性、成本和操作目标优先级之间的权衡。同时，文章介绍了针对时间变量攻击模式和多种网络拓扑聚合韧性指标的方法，全面刻画了系统的韧性特性。根据这些韧性度量指标，文章设计并实现了基于RL的自主防御代理，并与若干启发式基线进行了对比，结果表明，主动的网络加固技术和对被侵入机器的及时恢复对于有效的网络安全防御至关重要。 <div>
arXiv:2503.02780v1 Announce Type: new 
Abstract: Cyber resilience is the ability of a system to recover from an attack with minimal impact on system operations. However, characterizing a network's resilience under a cyber attack is challenging, as there are no formal definitions of resilience applicable to diverse network topologies and attack patterns. In this work, we propose a quantifiable formulation of resilience that considers multiple defender operational goals, the criticality of various network resources for daily operations, and provides interpretability to security operators about their system's resilience under attack. We evaluate our approach within the CybORG environment, a reinforcement learning (RL) framework for autonomous cyber defense, analyzing trade-offs between resilience, costs, and prioritization of operational goals. Furthermore, we introduce methods to aggregate resilience metrics across time-variable attack patterns and multiple network topologies, comprehensively characterizing system resilience. Using insights gained from our resilience metrics, we design RL autonomous defensive agents and compare them against several heuristic baselines, showing that proactive network hardening techniques and prompt recovery of compromised machines are critical for effective cyber defenses.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Do Not Trust Licenses You See -- Dataset Compliance Requires Massive-Scale AI-Powered Lifecycle Tracing</title>
<link>https://arxiv.org/abs/2503.02784</link>
<guid>https://arxiv.org/abs/2503.02784</guid>
<content:encoded><![CDATA[
<div> 关键词：数据集法律风险、许可条款、生命周期跟踪、AI代理、NEXUS系统

总结:<br />
本文提出数据集的法律风险不能仅通过其许可条款准确评估，需要全面追踪数据集的再分布及其完整生命周期。鉴于此过程复杂度超出了人工处理的能力范围，文章主张需借助AI代理来系统地追踪数据集再分布、验证再分发权和识别法律风险。为此，研究者开发了一种名为NEXUS的自动化数据合规系统，证明AI在执行这些任务方面的准确性、效率和成本效益均优于人类专家。利用该系统对17,429个独特实体和8,072条许可条款进行了大规模法律分析，揭示了原始数据集在再分布后与子集之间的法律权利差异，强调了数据生命周期意识的合规性必要性。例如，研究发现，具有商业可行性的2,852个数据集中，仅有605个（21%）在法律上允许进行商业化。该工作为AI数据治理设定了新的标准，倡导建立一种能够系统检查数据集再分布整个生命周期的框架，以确保透明、合法和负责任的数据管理。 <div>
arXiv:2503.02784v1 Announce Type: new 
Abstract: This paper argues that a dataset's legal risk cannot be accurately assessed by its license terms alone; instead, tracking dataset redistribution and its full lifecycle is essential. However, this process is too complex for legal experts to handle manually at scale. Tracking dataset provenance, verifying redistribution rights, and assessing evolving legal risks across multiple stages require a level of precision and efficiency that exceeds human capabilities. Addressing this challenge effectively demands AI agents that can systematically trace dataset redistribution, analyze compliance, and identify legal risks. We develop an automated data compliance system called NEXUS and show that AI can perform these tasks with higher accuracy, efficiency, and cost-effectiveness than human experts. Our massive legal analysis of 17,429 unique entities and 8,072 license terms using this approach reveals the discrepancies in legal rights between the original datasets before redistribution and their redistributed subsets, underscoring the necessity of the data lifecycle-aware compliance. For instance, we find that out of 2,852 datasets with commercially viable individual license terms, only 605 (21%) are legally permissible for commercialization. This work sets a new standard for AI data governance, advocating for a framework that systematically examines the entire lifecycle of dataset redistribution to ensure transparent, legal, and responsible dataset management.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Meta-Learning to Explore via Memory Density Feedback</title>
<link>https://arxiv.org/abs/2503.02831</link>
<guid>https://arxiv.org/abs/2503.02831</guid>
<content:encoded><![CDATA[
<div> 关键词: 探索算法、强化学习、元学习、概率密度、反馈网络

总结:<br />
本文提出了一种利用元学习进行探索的强化学习算法。该算法旨在使智能体在一个episode中学习最大化其对环境新状态的探索进度，甚至在训练期间的不同epoch之间也能实现。智能体学习到的策略致力于最小化新观测值相对于其所有记忆的概率密度，并通过接收当前观测密度的评估反馈并将反馈存储在循环神经网络中。通过记住密度轨迹，智能体能够在实时中学习如何在复杂且不断增长的熟悉性景观中导航，使其即使在完全未知的环境中也能最大化探索进度，而这些环境对其策略并未进行过训练。 <div>
arXiv:2503.02831v1 Announce Type: new 
Abstract: Exploration algorithms for reinforcement learning typically replace or augment the reward function with an additional ``intrinsic'' reward that trains the agent to seek previously unseen states of the environment. Here, we consider an exploration algorithm that exploits meta-learning, or learning to learn, such that the agent learns to maximize its exploration progress within a single episode, even between epochs of training. The agent learns a policy that aims to minimize the probability density of new observations with respect to all of its memories. In addition, it receives as feedback evaluations of the current observation density and retains that feedback in a recurrent network. By remembering trajectories of density, the agent learns to navigate a complex and growing landscape of familiarity in real-time, allowing it to maximize its exploration progress even in completely novel states of the environment for which its policy has not been trained.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MuBlE: MuJoCo and Blender simulation Environment and Benchmark for Task Planning in Robot Manipulation</title>
<link>https://arxiv.org/abs/2503.02834</link>
<guid>https://arxiv.org/abs/2503.02834</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied reasoning agents、long-horizon tasks、MuBlE、MuJoCo physics engine、Blender、SHOP-VRB2

总结:<br />
本文介绍了一种用于提升实体化推理代理能力的新颖模拟环境——MuBlE，该环境基于robosuite构建，利用MuJoCo物理引擎和高质量渲染器Blender提供逼真的视觉观测并确保场景物理状态的准确性。它是首个专注于长时序机器人操作任务并保持准确物理建模的模拟器。MuBlE支持两种级别的环境交互循环，即视觉-动作循环和控制-物理循环，可以生成多模态训练数据并促进闭环方法的设计。此外，文章还提出了一个新的基准SHOP-VRB2，它由10类需要同时进行视觉和物理测量的多步骤推理任务组成。 <div>
arXiv:2503.02834v1 Announce Type: new 
Abstract: Current embodied reasoning agents struggle to plan for long-horizon tasks that require to physically interact with the world to obtain the necessary information (e.g. 'sort the objects from lightest to heaviest'). The improvement of the capabilities of such an agent is highly dependent on the availability of relevant training environments. In order to facilitate the development of such systems, we introduce a novel simulation environment (built on top of robosuite) that makes use of the MuJoCo physics engine and high-quality renderer Blender to provide realistic visual observations that are also accurate to the physical state of the scene. It is the first simulator focusing on long-horizon robot manipulation tasks preserving accurate physics modeling. MuBlE can generate mutlimodal data for training and enable design of closed-loop methods through environment interaction on two levels: visual - action loop, and control - physics loop. Together with the simulator, we propose SHOP-VRB2, a new benchmark composed of 10 classes of multi-step reasoning scenarios that require simultaneous visual and physical measurements.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed and Localized Covariance Control of Coupled Systems: A System Level Approach</title>
<link>https://arxiv.org/abs/2503.02094</link>
<guid>https://arxiv.org/abs/2503.02094</guid>
<content:encoded><![CDATA[
<div> 关键词：finite-horizon optimal covariance steering, networked systems, discrete-time stochastic linear dynamics, distributed algorithm, system-level synthesis (SLS)

<br /><br />总结:
本文研究了具有离散时间随机线性动力学的网络系统的有限时间最优协方差引导问题，与仅考虑动态独立代理的现有工作不同，文中考虑了一个受到局部通信约束的动态耦合系统。针对该系统，文章提出了一种分布式算法，用于计算每个子系统的局部最优反馈控制策略，该策略只依赖于相邻子系统的局部状态历史。利用系统级综合（SLS）框架，首先将局部化协方差引导问题重新表述为带有局部性约束的凸SLS问题。接着，鉴于其部分可分离结构，将原问题分解为更小的子问题，并引入变换处理非可分离实例。最后，鉴于各子系统的局部信息和通信约束，采用共识交替方向乘子法（ADMM）变种来分布计算任务。文章通过在一个由36个相互连接的子系统组成的电力系统上进行的示例演示了所提算法的有效性。 <div>
arXiv:2503.02094v1 Announce Type: cross 
Abstract: This work is concerned with the finite-horizon optimal covariance steering of networked systems governed by discrete-time stochastic linear dynamics. In contrast with existing work that has only considered systems with dynamically decoupled agents, we consider a dynamically coupled system composed of interconnected subsystems subject to local communication constraints. In particular, we propose a distributed algorithm to compute the localized optimal feedback control policy for each individual subsystem, which depends only on the local state histories of its neighboring subsystems. Utilizing the system-level synthesis (SLS) framework, we first recast the localized covariance steering problem as a convex SLS problem with locality constraints. Subsequently, exploiting its partially separable structure, we decompose the latter problem into smaller subproblems, introducing a transformation to deal with nonseparable instances. Finally, we employ a variation of the consensus alternating direction method of multipliers (ADMM) to distribute computation across subsystems on account of their local information and communication constraints. We demonstrate the effectiveness of our proposed algorithm on a power system with 36 interconnected subsystems.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Fact Checking</title>
<link>https://arxiv.org/abs/2503.02116</link>
<guid>https://arxiv.org/abs/2503.02116</guid>
<content:encoded><![CDATA[
<div> 关键词：fake news detection, distributed fact-checkers, reliability, misclassification, learning algorithm

<br /><br />总结：
本文提出了使用分布式事实核查器（代理人）来解决假新闻检测问题的方法。文章将新闻流建模为独立同分布的二元源，表示真实的真伪状态。每个代理人观察到一则新闻后，会以概率 $1-\pi_i$ 标记其为真实或虚假，其中 $\pi_i \in (0,1)$ 表示第 $i$ 个代理人的不可靠程度，即误分类的概率。文中提出了一种算法来学习这些不可靠参数，从而形成一种分布式事实核查算法。此外，文章还对算法的离散时间极限进行了深入分析。 <div>
arXiv:2503.02116v1 Announce Type: cross 
Abstract: We formulate the problem of fake news detection using distributed fact-checkers (agents) with unknown reliability. The stream of news/statements is modeled as an independent and identically distributed binary source (to represent true and false statements). Upon observing a news, agent $i$ labels the news as true or false which reflects the true validity of the statement with some probability $1-\pi_i$. In other words, agent $i$ misclassified each statement with error probability $\pi_i\in (0,1)$, where the parameter $\pi_i$ models the (un)trustworthiness of agent $i$. We present an algorithm to learn the unreliability parameters, resulting in a distributed fact-checking algorithm. Furthermore, we extensively analyze the discrete-time limit of our algorithm.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Reinforcement Learning for Multi-Agent Multi-Resource Allocation via Dynamic Cluster Agreements</title>
<link>https://arxiv.org/abs/2503.02437</link>
<guid>https://arxiv.org/abs/2503.02437</guid>
<content:encoded><![CDATA[
<div> 关键词：异构资源分配、多智能体、分布式、LGTC-IPPO、独立策略优化（IPPO）、动态集群共识、可扩展性、协调性、奖励稳定性、资源再分配、耗尽资源场景。

<br /><br />总结:

本文提出了一种针对多智能体间异构资源分布式分配的挑战性问题的解决方案——LGTC-IPPO。该方法基于独立策略优化（IPPO），通过集成动态集群共识机制，允许智能体根据资源需求动态形成和调整局部子团队，从而降低对全局信息的依赖并提高系统的可扩展性。实验结果表明，与标准多智能体强化学习基线及中心化专家方案相比，LGTC-IPPO展现出更稳定的奖励获取能力、更好的协调性能以及随着智能体数量和资源类型增加仍能保持的稳健表现。此外，文章还展示了动态集群如何使智能体在耗尽资源的场景下实现高效资源再分配。 <div>
arXiv:2503.02437v1 Announce Type: cross 
Abstract: This paper addresses the challenge of allocating heterogeneous resources among multiple agents in a decentralized manner. Our proposed method, LGTC-IPPO, builds upon Independent Proximal Policy Optimization (IPPO) by integrating dynamic cluster consensus, a mechanism that allows agents to form and adapt local sub-teams based on resource demands. This decentralized coordination strategy reduces reliance on global information and enhances scalability. We evaluate LGTC-IPPO against standard multi-agent reinforcement learning baselines and a centralized expert solution across a range of team sizes and resource distributions. Experimental results demonstrate that LGTC-IPPO achieves more stable rewards, better coordination, and robust performance even as the number of agents or resource types increases. Additionally, we illustrate how dynamic clustering enables agents to reallocate resources efficiently also for scenarios with discharging resources.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Multi-Agent Reinforcement Learning for Residential Load Scheduling under Data Governance</title>
<link>https://arxiv.org/abs/2110.02784</link>
<guid>https://arxiv.org/abs/2110.02784</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、分布式训练、通信约束、数据治理、隐私保护

总结:
本文提出了一种针对住宅负荷调度问题的新型多智能体强化学习（MARL）解决方案。该方案旨在解决集中式训练在云边环境中大规模部署时面临的通信约束问题以及实际应用中的系统可扩展性挑战。通过基于actor-critic方法的设计，使用仅依赖于家庭本地观测值计算的全局critic函数，实现了对家庭隐私的完全保护并大幅降低了通信成本。模拟实验表明，提出的框架在性能上与最先进的actor-critic框架相当，同时克服了无数据治理和通信限制的问题。 <div>
arXiv:2110.02784v2 Announce Type: replace 
Abstract: As a data-driven approach, multi-agent reinforcement learning (MARL) has made remarkable advances in solving cooperative residential load scheduling problems. However, centralized training, the most common paradigm for MARL, limits large-scale deployment in communication-constrained cloud-edge environments. As a remedy, distributed training shows unparalleled advantages in real-world applications but still faces challenge with system scalability, e.g., the high cost of communication overhead during coordinating individual agents, and needs to comply with data governance in terms of privacy. In this work, we propose a novel MARL solution to address these two practical issues. Our proposed approach is based on actor-critic methods, where the global critic is a learned function of individual critics computed solely based on local observations of households. This scheme preserves household privacy completely and significantly reduces communication cost. Simulation experiments demonstrate that the proposed framework achieves comparable performance to the state-of-the-art actor-critic framework without data governance and communication constraints.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MIXRTs: Toward Interpretable Multi-Agent Reinforcement Learning via Mixing Recurrent Soft Decision Trees</title>
<link>https://arxiv.org/abs/2209.07225</link>
<guid>https://arxiv.org/abs/2209.07225</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习 (MARL), 可解释性, 深度神经网络, 决策树, 软决策树

总结:
本文提出了一种新的可解释多智能体强化学习架构——混合递归软决策树 (MIXRTs)，旨在解决现有黑盒神经网络决策不透明以及可解释性差的问题。MIXRTs 通过根到叶的路径展示明确的决策过程并反映每个智能体对团队的贡献。具体来说，研究者构建了一个使用循环结构的新型软决策树，揭示了影响决策过程的特征。同时，基于价值分解框架，MIXRTs 使用局部观察信息线性分配信用给每个智能体，从而明确地将个体动作值混合估计联合动作值，为理解合作机制提供了新视角。理论分析证实，MIXRTs 在联合动作值的因子分解中保证了加性和单调性。实验结果显示，MIXRTs 在像 Spread 和 StarCraft II 这样的复杂任务上与现有方法竞争的同时，还提供了清晰的解释，为开发既可解释又高性能的 MARL 系统铺平了道路。 <div>
arXiv:2209.07225v4 Announce Type: replace 
Abstract: While achieving tremendous success in various fields, existing multi-agent reinforcement learning (MARL) with a black-box neural network makes decisions in an opaque manner that hinders humans from understanding the learned knowledge and how input observations influence decisions. In contrast, existing interpretable approaches usually suffer from weak expressivity and low performance. To bridge this gap, we propose MIXing Recurrent soft decision Trees (MIXRTs), a novel interpretable architecture that can represent explicit decision processes via the root-to-leaf path and reflect each agent's contribution to the team. Specifically, we construct a novel soft decision tree using a recurrent structure and demonstrate which features influence the decision-making process. Then, based on the value decomposition framework, we linearly assign credit to each agent by explicitly mixing individual action values to estimate the joint action value using only local observations, providing new insights into interpreting the cooperation mechanism. Theoretical analysis confirms that MIXRTs guarantee additivity and monotonicity in the factorization of joint action values. Evaluations on complex tasks like Spread and StarCraft II demonstrate that MIXRTs compete with existing methods while providing clear explanations, paving the way for interpretable and high-performing MARL systems.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Approximate Optimality of Linear Contracts Under Uncertainty</title>
<link>https://arxiv.org/abs/2211.06850</link>
<guid>https://arxiv.org/abs/2211.06850</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐藏行动、主代理模型、线性合同、不确定性、优化

总结:
本文研究了一个隐藏行动的主代理模型，其中代理执行不同行动需付出不同的努力成本，并且其个人能力私密地决定了他付出努力的成本。文章表明，在具有不确定性的合同环境中，线性合同具备随着不确定度增加而改善的近似保证。因此，当存在足够不确定性时，线性合同接近最优解。相反，即使在有足够的不确定性情况下，像债务合同等其他简单的合同格式仍可能面临与行动数量线性相关的损失问题。 <div>
arXiv:2211.06850v3 Announce Type: replace 
Abstract: We consider a hidden-action principal-agent model, in which actions require different amounts of effort, and the agent privately knows his ability that determines his cost of effort. We show that linear contracts admit approximation guarantees that improve with a natural metric that captures the degree of uncertainty in the contracting setting. We thus show that linear contracts are near-optimal whenever there is enough uncertainty. In contrast, other simple contract formats such as debt contracts may suffer from a loss linear in the number of possible actions, even when there is sufficient uncertainty.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Converging to Stability in Two-Sided Bandits: The Case of Unknown Preferences on Both Sides of a Matching Market</title>
<link>https://arxiv.org/abs/2302.06176</link>
<guid>https://arxiv.org/abs/2302.06176</guid>
<content:encoded><![CDATA[
<div> 关键词: 重复匹配、双向偏好不确定性、双边探索、稳定匹配、算法

总结:
该文研究了在不确定偏好的重复两遍匹配问题（双边探索）中，无双方间明确沟通的情况。针对先前仅考虑一方需学习偏好、另一方偏好为公共知识以及采用同步提案机制的设定，文章提出了新的算法，适用于两个更具挑战性的场景：一是当手臂（proposees或arms）的偏好不再为公共知识；二是更普遍的情况，即手臂对其自身的偏好也存在不确定性。新算法中，代理者（agents）以乐观信念开始对手臂的偏好进行更新，并结合关于与手臂匹配价值的信念来决定向谁提出求婚。这些算法能够保证收敛到稳定的匹配结果。 <div>
arXiv:2302.06176v2 Announce Type: replace 
Abstract: We study the problem of repeated two-sided matching with uncertain preferences (two-sided bandits), and no explicit communication between agents. Recent work has developed algorithms that converge to stable matchings when one side (the proposers or agents) must learn their preferences, but the preferences of the other side (the proposees or arms) are common knowledge, and the matching mechanism uses simultaneous proposals at each round. We develop new algorithms that provably converge to stable matchings for two more challenging settings: one where the arm preferences are no longer common knowledge, and a second, more general one where the arms are also uncertain about their preferences. In our algorithms, agents start with optimistic beliefs about arms' preferences and update these preferences over time. The key insight is in how to combine these beliefs about arm preferences with beliefs about the value of matching with an arm conditional on one's proposal being accepted when choosing whom to propose to.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Decentralized Adversarial Training over Graphs</title>
<link>https://arxiv.org/abs/2303.13326</link>
<guid>https://arxiv.org/abs/2303.13326</guid>
<content:encoded><![CDATA[
<div> 关键词：adversarial attacks, machine learning, multi-agent systems, decentralized adversarial training, diffusion, consensus

总结:
本文关注了机器学习模型对对抗性攻击的脆弱性问题，特别是研究了图结构中个体智能体遭受不同强度空间扰动的情况。文章提出了一种针对多智能体系统的分布式对抗训练框架，并基于两种流行的分布式学习策略——扩散和共识，设计了两种去中心化的对抗训练算法。对于强凸、凸及非凸环境，作者分析了所提框架的收敛性质，并展示了在对抗性攻击下，通过群体协调能力能增强系统的鲁棒性。<br /><br /> <div>
arXiv:2303.13326v2 Announce Type: replace 
Abstract: The vulnerability of machine learning models to adversarial attacks has been attracting considerable attention in recent years. Most existing studies focus on the behavior of stand-alone single-agent learners. In comparison, this work studies adversarial training over graphs, where individual agents are subjected to perturbations of varied strength levels across space. It is expected that interactions by linked agents, and the heterogeneity of the attack models that are possible over the graph, can help enhance robustness in view of the coordination power of the group. Using a min-max formulation of distributed learning, we develop a decentralized adversarial training framework for multi-agent systems. Specifically, we devise two decentralized adversarial training algorithms by relying on two popular decentralized learning strategies--diffusion and consensus. We analyze the convergence properties of the proposed framework for strongly-convex, convex, and non-convex environments, and illustrate the enhanced robustness to adversarial attacks.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Unifying Framework for Learning Argumentation Semantics</title>
<link>https://arxiv.org/abs/2310.12309</link>
<guid>https://arxiv.org/abs/2310.12309</guid>
<content:encoded><![CDATA[
<div> 关键词: argumentation, 人工智能, 接受性语义, 形式论证系统, 诱导逻辑编程

<br /><br />总结:
本文介绍了一个使用诱导逻辑编程方法的新框架，该框架可解释地学习多种抽象和结构化论证框架的接受性语义。通过实证评估，研究表明此框架在确定接受或拒绝论证方面优于现有的论证求解器，从而为形式论证领域及人机对话研究开辟了新的未来方向。 <div>
arXiv:2310.12309v2 Announce Type: replace 
Abstract: Argumentation is a very active research field of Artificial Intelligence concerned with the representation and evaluation of arguments used in dialogues between humans and/or artificial agents. Acceptability semantics of formal argumentation systems define the criteria for the acceptance or rejection of arguments. Several software systems, known as argumentation solvers, have been developed to compute the accepted/rejected arguments using such criteria. These include systems that learn to identify the accepted arguments using non-interpretable methods. In this paper we present a novel framework, which uses an Inductive Logic Programming approach to learn the acceptability semantics for several abstract and structured argumentation frameworks in an interpretable way. Through an empirical evaluation we show that our framework outperforms existing argumentation solvers, thus opening up new future research directions in the area of formal argumentation and human-machine dialogues.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interpretable Interaction Modeling for Trajectory Prediction via Agent Selection and Physical Coefficient</title>
<link>https://arxiv.org/abs/2405.13152</link>
<guid>https://arxiv.org/abs/2405.13152</guid>
<content:encoded><![CDATA[
<div> 关键词: ASPILin、Transformer、物理相关系数、轨迹预测、交互建模

总结:
本文介绍了ASPILin方法，该方法针对目标代理与周围代理之间的交互理解进行了深入研究。ASPILin通过手动选择交互对象并使用新计算的物理相关系数替代Transformer中的注意力得分，提高了交互建模的可解释性。这一简单改动显著提升了轨迹预测性能并降低了计算成本。此外，ASPILin还简化了模型的其他部分，如地图编码。实验结果表明，尽管设计简洁，但在INTERACTION、highD和CitySim数据集上，ASPILin方法仍能优于现有最先进的方法。 <div>
arXiv:2405.13152v4 Announce Type: replace 
Abstract: A thorough understanding of the interaction between the target agent and surrounding agents is a prerequisite for accurate trajectory prediction. Although many methods have been explored, they assign correlation coefficients to surrounding agents in a purely learning-based manner. In this study, we present ASPILin, which manually selects interacting agents and replaces the attention scores in Transformer with a newly computed physical correlation coefficient, enhancing the interpretability of interaction modeling. Surprisingly, these simple modifications can significantly improve prediction performance and substantially reduce computational costs. We intentionally simplified our model in other aspects, such as map encoding. Remarkably, experiments conducted on the INTERACTION, highD, and CitySim datasets demonstrate that our method is efficient and straightforward, outperforming other state-of-the-art methods.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Compatibility of Fairness and Nash Welfare under Subadditive Valuations</title>
<link>https://arxiv.org/abs/2407.12461</link>
<guid>https://arxiv.org/abs/2407.12461</guid>
<content:encoded><![CDATA[
<div> 关键词: subadditive valuations, Nash Social Welfare (NSW), envy-free up to any good (EFx), envy-free up to one good (EF1), polynomial-time algorithm

总结:

本文研究了子加性估值下的公平与效率之间的兼容性。针对子加性估值，文章证明存在一种部分分配方案，该方案满足-envy-free up to any good (EFx)且Nash 社会福利（NSW）至少为最优值的一半。同时，对于子加性估值，文章解决了Garg等人（STOC 2023）提出的开放问题，证明了普遍存在一种完整分配方案，既能满足envy-free up to one good (EF1)，又能实现对最优NSW的1/2近似比。此外，文章提出了一种多项式时间算法，输入任意分配方案$\widetilde{A}$后，可以返回一个EF1分配方案，其NSW至少达到$\widetilde{A}$的$\frac{1}{e^{2/e}}\approx \frac{1}{2.08}$倍。这意味着对于子加性估值，可以在多项式时间内（带需求查询）同时实现EF1准则和对最优NSW的常数因子近似。文章进一步指出，虽然EF1和精确帕累托效率（PO）在子加性估值下不兼容，但只需考虑1/2近似，则可以实现EF1与1/2-PO的兼容。因此，本文的结果提供了一个通用工具，能够将任何有效结果转换为公平结果，同时仅使效率轻微降低。 <div>
arXiv:2407.12461v3 Announce Type: replace 
Abstract: We establish a compatibility between fairness and efficiency, captured via Nash Social Welfare (NSW), under the broad class of subadditive valuations. We prove that, for subadditive valuations, there always exists a partial allocation that is envy-free up to the removal of any good (EFx) and has NSW at least half of the optimal; here, optimality is considered across all allocations, fair or otherwise. We also prove, for subadditive valuations, the universal existence of complete allocations that are envy-free up to one good (EF1) and also achieve a factor $1/2$ approximation to the optimal NSW. Our EF1 result resolves an open question posed by Garg, Husic, Li, V\'{e}gh, and Vondr\'{a}k (STOC 2023).
  In addition, we develop a polynomial-time algorithm which, given an arbitrary allocation $\widetilde{A}$ as input, returns an EF1 allocation with NSW at least $\frac{1}{e^{2/e}}\approx \frac{1}{2.08}$ times that of $\widetilde{A}$. Therefore, our results imply that the EF1 criterion can be attained simultaneously with a constant-factor approximation to optimal NSW in polynomial time (with demand queries), for subadditive valuations. The previously best-known approximation factor for optimal NSW, under EF1 and among $n$ agents, was $O(n)$ -- we improve this bound to $O(1)$.
  It is known that EF1 and exact Pareto efficiency (PO) are incompatible with subadditive valuations. Complementary to this negative result, the current work shows that we regain compatibility by just considering a factor $1/2$ approximation: EF1 can be achieved in conjunction with $\frac{1}{2}$-PO under subadditive valuations. As such, our results serve as a general tool that can be used as a black box to convert any efficient outcome into a fair one, with only a marginal decrease in efficiency.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Rao-Blackwellized POMDP Planning</title>
<link>https://arxiv.org/abs/2409.16392</link>
<guid>https://arxiv.org/abs/2409.16392</guid>
<content:encoded><![CDATA[
<div> 关键词：Partially Observable Markov Decision Processes (POMDPs)，Sequential Importance Resampling Particle Filters (SIRPF)，Rao-Blackwellized POMDP (RB-POMDP)，Rao-Blackwellized Particle Filters (RBPF)，POMCPOW

总结:
本文介绍了部分可观测马尔科夫决策过程（POMDPs）中的信念更新问题，以及SIRPF在高维状态空间中面临的粒子耗尽和计算成本高的挑战。为解决这些问题，文章提出了Rao-Blackwellized POMDP（RB-POMDP）近似求解器，并详细说明了在信念更新和在线规划中应用Rao-Blackwell化的通用方法。通过使用POMCPOW和RB-POMCPOW规划器在一个模拟的GPS受限环境下的目标导航任务中比较SIRPF与RBPF的表现，结果显示RBPF能够在使用更少粒子的情况下保持准确的信念近似，并且结合四阶积分方法后，在相同的计算限制下，其规划质量显著优于基于SIRPF的规划。 <div>
arXiv:2409.16392v2 Announce Type: replace 
Abstract: Partially Observable Markov Decision Processes (POMDPs) provide a structured framework for decision-making under uncertainty, but their application requires efficient belief updates. Sequential Importance Resampling Particle Filters (SIRPF), also known as Bootstrap Particle Filters, are commonly used as belief updaters in large approximate POMDP solvers, but they face challenges such as particle deprivation and high computational costs as the system's state dimension grows. To address these issues, this study introduces Rao-Blackwellized POMDP (RB-POMDP) approximate solvers and outlines generic methods to apply Rao-Blackwellization in both belief updates and online planning. We compare the performance of SIRPF and Rao-Blackwellized Particle Filters (RBPF) in a simulated localization problem where an agent navigates toward a target in a GPS-denied environment using POMCPOW and RB-POMCPOW planners. Our results not only confirm that RBPFs maintain accurate belief approximations over time with fewer particles, but, more surprisingly, RBPFs combined with quadrature-based integration improve planning quality significantly compared to SIRPF-based planning under the same computational limits.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Open-World Reinforcement Learning over Long Short-Term Imagination</title>
<link>https://arxiv.org/abs/2410.03618</link>
<guid>https://arxiv.org/abs/2410.03618</guid>
<content:encoded><![CDATA[
<div> 关键词：视觉强化学习、高维开放世界、模型基方法、长短期世界模型、LS-Imagine

总结:<br />
在高维开放世界的视觉强化学习中，训练智能体面临重大挑战。本文提出了LS-Imagine方法，旨在解决长期探索效率问题，特别是对于需要考虑长时段回报的任务。该方法通过构建“长短期世界模型”，延长了想象中的行为序列长度，允许智能体在有限的步数内探索可能导致长远反馈的行为。具体实现上，LS-Imagine利用目标条件下的跳跃状态转移模拟和单幅图像内的特定区域放大来计算相应的可操作性地图，进而将直接的长期价值整合到行为学习中。实验表明，LS-Imagine相较于当前最先进的技术在MineDojo场景中表现出显著优势。 <div>
arXiv:2410.03618v2 Announce Type: replace 
Abstract: Training visual reinforcement learning agents in a high-dimensional open world presents significant challenges. While various model-based methods have improved sample efficiency by learning interactive world models, these agents tend to be "short-sighted", as they are typically trained on short snippets of imagined experiences. We argue that the primary challenge in open-world decision-making is improving the exploration efficiency across a vast state space, especially for tasks that demand consideration of long-horizon payoffs. In this paper, we present LS-Imagine, which extends the imagination horizon within a limited number of state transition steps, enabling the agent to explore behaviors that potentially lead to promising long-term feedback. The foundation of our approach is to build a $\textit{long short-term world model}$. To achieve this, we simulate goal-conditioned jumpy state transitions and compute corresponding affordance maps by zooming in on specific areas within single images. This facilitates the integration of direct long-term values into behavior learning. Our method demonstrates significant improvements over state-of-the-art techniques in MineDojo.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Zero-Shot, Controllable Dialog Planning with LLMs</title>
<link>https://arxiv.org/abs/2410.05821</link>
<guid>https://arxiv.org/abs/2410.05821</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，对话规划，幻觉问题，对话树搜索 (CTS)，零样本学习

总结:<br />
本文介绍了如何利用大型语言模型（LLMs）实现对对话策略进行可控引导的一种新型零样本方法，该方法针对敏感领域的信息获取任务，通过基于用户交互偏好的领域图节点搜索和剪枝来指导对话规划。研究显示，这种方法在模拟环境中相较于当前最先进的基于强化学习的CTS对话代理有显著优势（p < 0.0001）。此外，此方法还能够泛化到所有可用的CTS领域。进一步的用户评估表明，与最先进的RL-based CTS代理相比，提出的政策显著提高了实际应用中的任务成功率（p < 0.05）。 <div>
arXiv:2410.05821v2 Announce Type: replace 
Abstract: Recently, Large Language Models (LLMs) have emerged as an alternative to training task-specific dialog agents, due to their broad reasoning capabilities and performance in zero-shot learning scenarios. However, many LLM-based dialog systems fall short in planning towards an overarching dialog goal and therefore cannot steer the conversation appropriately. Furthermore, these models struggle with hallucination, making them unsuitable for information access in sensitive domains, such as legal or medical domains, where correctness of information given to users is critical. The recently introduced task Conversational Tree Search (CTS) proposes the use of dialog graphs to avoid hallucination in sensitive domains, however, state-of-the-art agents are Reinforcement Learning (RL) based and require long training times, despite excelling at dialog strategy. This paper introduces a novel zero-shot method for controllable CTS agents, where LLMs guide the dialog planning through domain graphs by searching and pruning relevant graph nodes based on user interaction preferences. We show that these agents significantly outperform state-of-the-art CTS agents ($p<0.0001$; Barnard Exact test) in simulation. This generalizes to all available CTS domains. Finally, we perform user evaluation to test the agent's performance in the wild, showing that our policy significantly ($p<0.05$; Barnard Exact) improves task-success compared to the state-of-the-art RL-based CTS agent.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Beyond Exact Match: Semantically Reassessing Event Extraction by Large Language Models</title>
<link>https://arxiv.org/abs/2410.09418</link>
<guid>https://arxiv.org/abs/2410.09418</guid>
<content:encoded><![CDATA[
<div> 关键词: 事件抽取、评价框架、RAEE、精确匹配、大规模语言模型

总结:
本文提出了一个针对事件抽取任务的新型评价框架RAEE，该框架旨在解决当前主流依赖于精确匹配评价方法导致的语义级正确案例误判问题。RAEE利用大规模语言模型作为评估代理，通过适应性机制对触发词和论元的精度与召回率进行适应性评估。实验结果显示：(1) RAEE与人类判断的相关性极强；(2) 在对包括先进大规模语言模型在内的14个模型在10个数据集上的重新评估中，发现精确匹配评价与RAEE之间存在显著性能差距，精确匹配评价低估了现有事件抽取模型的性能，特别是低估了大规模语言模型的能力；(3) RAEE评价下的细粒度分析揭示了一些值得进一步探究的现象。文中所述RAEE评估工具包已公开发布。 <div>
arXiv:2410.09418v2 Announce Type: replace 
Abstract: Event extraction has gained extensive research attention due to its broad range of applications. However, the current mainstream evaluation method for event extraction relies on token-level exact match, which misjudges numerous semantic-level correct cases. This reliance leads to a significant discrepancy between the evaluated performance of models under exact match criteria and their real performance. To address this problem, we propose a reliable and semantic evaluation framework for event extraction, named RAEE, which accurately assesses extraction results at semantic-level instead of token-level. Specifically, RAEE leverages large language models (LLMs) as evaluation agents, incorporating an adaptive mechanism to achieve adaptive evaluations for precision and recall of triggers and arguments. Extensive experiments demonstrate that: (1) RAEE achieves a very strong correlation with human judgments; (2) after reassessing 14 models, including advanced LLMs, on 10 datasets, there is a significant performance gap between exact match and RAEE. The exact match evaluation significantly underestimates the performance of existing event extraction models, and in particular underestimates the capabilities of LLMs; (3) fine-grained analysis under RAEE evaluation reveals insightful phenomena worth further exploration. The evaluation toolkit of our proposed RAEE is publicly released.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAG-DDR: Optimizing Retrieval-Augmented Generation Using Differentiable Data Rewards</title>
<link>https://arxiv.org/abs/2410.13509</link>
<guid>https://arxiv.org/abs/2410.13509</guid>
<content:encoded><![CDATA[
<div> 关键词：Retrieval-Augmented Generation (RAG)，Large Language Models (LLMs)，Differentiable Data Rewards (DDR)，Supervised Fine-Tuning (SFT)，End-to-End训练

总结:
本文提出了一种名为Differentiable Data Rewards (DDR)的方法，用于改进Retrieval-Augmented Generation (RAG)系统中大型语言模型（LLMs）的知识利用能力。现有的方法通过监督微调（SFT）优化LLMs以适应RAG任务，但容易导致过拟合训练信号并忽视了RAG系统内部模块间的数据偏好差异。DDR方法采用端到端训练方式，通过rollout方法使RAG系统的各模块之间数据偏好对齐，从而收集奖励并优化每个模块。实验表明，DDR方法在各种知识密集型任务上显著优于SFT方法，特别是在依赖检索知识的小规模参数的LLMs上效果更优。此外，DDR还展现出更好地对齐RAG模块间数据偏好的能力，使得生成模块能更有效地从文档中提取关键信息并减少参数记忆与外部知识之间的冲突。相关代码已发布在https://github.com/OpenMatch/RAG-DDR。 <div>
arXiv:2410.13509v2 Announce Type: replace 
Abstract: Retrieval-Augmented Generation (RAG) has proven its effectiveness in mitigating hallucinations in Large Language Models (LLMs) by retrieving knowledge from external resources. To adapt LLMs for the RAG systems, current approaches use instruction tuning to optimize LLMs, improving their ability to utilize retrieved knowledge. This supervised fine-tuning (SFT) approach focuses on equipping LLMs to handle diverse RAG tasks using different instructions. However, it trains RAG modules to overfit training signals and overlooks the varying data preferences among agents within the RAG system. In this paper, we propose a Differentiable Data Rewards (DDR) method, which end-to-end trains RAG systems by aligning data preferences between different RAG modules. DDR works by collecting the rewards to optimize each agent in the RAG system with the rollout method, which prompts agents to sample some potential responses as perturbations, evaluates the impact of these perturbations on the whole RAG system, and subsequently optimizes the agent to produce outputs that improve the performance of the RAG system. Our experiments on various knowledge-intensive tasks demonstrate that DDR significantly outperforms the SFT method, particularly for LLMs with smaller-scale parameters that depend more on the retrieved knowledge. Additionally, DDR exhibits a stronger capability to align the data preference between RAG modules. The DDR method makes the generation module more effective in extracting key information from documents and mitigating conflicts between parametric memory and external knowledge. All codes are available at https://github.com/OpenMatch/RAG-DDR.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Planning and Reasoning with 3D Deformable Objects for Hierarchical Text-to-3D Robotic Shaping</title>
<link>https://arxiv.org/abs/2412.01765</link>
<guid>https://arxiv.org/abs/2412.01765</guid>
<content:encoded><![CDATA[
<div> 关键词：deformable object manipulation, autonomous sculpting, clay, language models, action prediction<br /><br />总结:
本文研究了机器人系统中具有挑战性的可变形物体操纵问题，特别是通过将粘土塑造成三维形状的任务。作者提出了首个粗细两级自主雕刻系统，该系统首先选择放置多少块和何处放置粘土以创建初步形状，随后通过一系列变形动作迭代细化形状。他们利用大型语言模型生成子目标，并训练了一个基于点云区域的动作预测模型，根据期望的点云子目标来预测机器人的动作。此外，这种方法还是首个无需向系统提供明确3D目标或子目标的真实世界文本到3D形状塑造管道。实验表明，他们的方法能够仅通过文本提示成功创造出一组简单的形状。同时，文章还深入探讨了如何最佳地量化文本到3D雕塑任务的成功度，并对比了现有文本图像和文本点云相似性指标与人类评估在这个任务上的表现。感兴趣的读者可以通过项目网站（https://sites.google.com/andrew.cmu.edu/hierarchicalsculpting）获取实验视频、人类评价详情以及完整提示信息。 <div>
arXiv:2412.01765v2 Announce Type: replace 
Abstract: Deformable object manipulation remains a key challenge in developing autonomous robotic systems that can be successfully deployed in real-world scenarios. In this work, we explore the challenges of deformable object manipulation through the task of sculpting clay into 3D shapes. We propose the first coarse-to-fine autonomous sculpting system in which the sculpting agent first selects how many and where to place discrete chunks of clay into the workspace to create a coarse shape, and then iteratively refines the shape with sequences of deformation actions. We leverage large language models for sub-goal generation, and train a point cloud region-based action model to predict robot actions from the desired point cloud sub-goals. Additionally, our method is the first autonomous sculpting system that is a real-world text-to-3D shaping pipeline without any explicit 3D goals or sub-goals provided to the system. We demonstrate our method is able to successfully create a set of simple shapes solely from text-based prompting. Furthermore, we explore rigorously how to best quantify success for the text-to-3D sculpting task, and compare existing text-image and text-point cloud similarity metrics to human evaluations for this task. For experimental videos, human evaluation details, and full prompts, please see our project website: https://sites.google.com/andrew.cmu.edu/hierarchicalsculpting
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simulating Human-like Daily Activities with Desire-driven Autonomy</title>
<link>https://arxiv.org/abs/2412.06435</link>
<guid>https://arxiv.org/abs/2412.06435</guid>
<content:encoded><![CDATA[
<div> 关键词: 欲望驱动自主代理(D2A), 大型语言模型(LLM), 自主任务提案, 动态价值系统, 实验验证

总结:<br />
本文提出了欲望驱动自主代理（D2A）的概念，该代理能够使大型语言模型（LLM）自主地提出并选择任务，从而满足其多元化的欲望。D2A的动力机制主要由受需求理论启发的动态价值系统构建，该系统包含了对类似人类的欲望理解，如社交互动、个人成就和自我关怀的需求。在每个步骤中，代理会评估当前状态的价值，提出一组候选活动，并选择与内在动机最一致的任务进行执行。文章通过在文本模拟器Concordia上的实验展示了D2A能生成连贯、情境相关且具有人类行为特征的日常活动，并与其他基于LLM的代理进行了对比分析，证明了其方法显著提高了模拟活动中行为的合理性。 <div>
arXiv:2412.06435v2 Announce Type: replace 
Abstract: Desires motivate humans to interact autonomously with the complex world. In contrast, current AI agents require explicit task specifications, such as instructions or reward functions, which constrain their autonomy and behavioral diversity. In this paper, we introduce a Desire-driven Autonomous Agent (D2A) that can enable a large language model (LLM) to autonomously propose and select tasks, motivated by satisfying its multi-dimensional desires. Specifically, the motivational framework of D2A is mainly constructed by a dynamic Value System, inspired by the Theory of Needs. It incorporates an understanding of human-like desires, such as the need for social interaction, personal fulfillment, and self-care. At each step, the agent evaluates the value of its current state, proposes a set of candidate activities, and selects the one that best aligns with its intrinsic motivations. We conduct experiments on Concordia, a text-based simulator, to demonstrate that our agent generates coherent, contextually relevant daily activities while exhibiting variability and adaptability similar to human behavior. A comparative analysis with other LLM-based agents demonstrates that our approach significantly enhances the rationality of the simulated activities.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Modular Conversational Agents for Surveys and Interviews</title>
<link>https://arxiv.org/abs/2412.17049</link>
<guid>https://arxiv.org/abs/2412.17049</guid>
<content:encoded><![CDATA[
<div> 关键词：调查、访谈、人工智能、聊天机器人、交通政策

<br />
总结:
本文介绍了为解决传统调查和访谈在新兴或假设性场景中面临的成本、可扩展性和一致性挑战，采用人工智能驱动的聊天机器人（AI代理）进行数据收集的一种模块化方法。该方法包括设计参数化的AI代理过程，通过集成工程化提示、专门知识库和定制化的、目标导向的对话逻辑来构建系统架构。研究通过三个实证案例展示了该方法的适应性、通用性和有效性：旅行偏好调查突出了条件逻辑和多模态交互功能；对新建基础设施项目的公众意见征询展现了问题定制和多语言支持能力；以及关于未来交通系统技术影响的专家咨询，强调了AI代理在处理开放性问题时实时澄清请求的能力、应对不规则输入的韧性和高效的转录后处理效率。结果表明，使用AI代理可以提高完成率和回答质量。此外，模块化方法还体现了可控性、灵活性和鲁棒性，同时有效解决了关键的伦理、隐私、安全和令牌消耗问题。 <div>
arXiv:2412.17049v2 Announce Type: replace 
Abstract: Surveys and interviews are widely used for collecting insights on emerging or hypothetical scenarios. Traditional human-led methods often face challenges related to cost, scalability, and consistency. Recently, various domains have begun to explore the use of conversational agents (chatbots) powered by generative artificial intelligence (AI) technologies. However, considering decisions in transportation investments and policies often carry significant public and environmental stakes, surveys and interviews face unique challenges in integrating AI agents, underscoring the need for a rigorous, resource-efficient approach that enhances participant engagement and ensures privacy. This paper addresses this gap by introducing a modular approach and its resulting parameterized process for designing AI agents. We detail the system architecture, integrating engineered prompts, specialized knowledge bases, and customizable, goal-oriented conversational logic. We demonstrate the adaptability, generalizability, and efficacy of our modular approach through three empirical studies: (1) travel preference surveys, highlighting conditional logic and multimodal (voice, text, and image generation) capabilities; (2) public opinion elicitation on a newly constructed, novel infrastructure project, showcasing question customization and multilingual (English and French) capabilities; and (3) expert consultation about the impact of technologies on future transportation systems, highlighting real-time, clarification request capabilities for open-ended questions, resilience in handling erratic inputs, and efficient transcript postprocessing. The results suggest that the AI agent increases completion rates and response quality. Furthermore, the modular approach demonstrates controllability, flexibility, and robustness while addressing key ethical, privacy, security, and token consumption concerns.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The EnvDesign Model: A Method to Solve the Environment Design Problem</title>
<link>https://arxiv.org/abs/2412.18109</link>
<guid>https://arxiv.org/abs/2412.18109</guid>
<content:encoded><![CDATA[
<div> 关键词：云平台、性能测试、预生产环境、环境设计问题、EnvDesign模型<br /><br />总结:
本文关注云平台内部程序（代理）的可靠性，指出预生产测试环境的设计对于预防云平台回归至关重要。文章将此任务定义为“环境设计”问题，并提出了一种名为EnvDesign模型的方法，该方法运用图论和优化算法解决该问题。EnvDesign模型建立在组合测试的通用上下文和技术之上，因此也可应用于其他领域的组合测试。 <div>
arXiv:2412.18109v2 Announce Type: replace 
Abstract: Today, several people and organizations rely on cloud platforms. The reliability of cloud platforms depends heavily on the performance of their internal programs (agents). To better prevent regressions in cloud platforms, the design of pre-production testing environments (that test new agents, new hardwares, and other changes) must take into account the diversity of server/node properties (hardware model, virtual machine type, etc.) across the fleet and dynamically emphasize or de-emphasize the prevalence of certain node properties based on current testing priorities. This paper formulates this task as the "environment design" problem and presents the EnvDesign model, a method that uses graph theory and optimization algorithms to solve the environment design problem. The EnvDesign model was built on context and techniques that apply to combinatorial testing in general, so it can support combinatorial testing in other domains.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoRestTest: A Tool for Automated REST API Testing Using LLMs and MARL</title>
<link>https://arxiv.org/abs/2501.08600</link>
<guid>https://arxiv.org/abs/2501.08600</guid>
<content:encoded><![CDATA[
<div> 关键词: RESTful API、测试工具、AutoRestTest、Semantic Property Dependency Graph (SPDG)、Multi-Agent Reinforcement Learning (MARL)、大型语言模型

总结:
本文介绍了AutoRestTest，这是一个针对RESTful API的新颖测试工具，它结合了Semantic Property Dependency Graph (SPDG)、Multi-Agent Reinforcement Learning (MARL)以及大型语言模型以提升API测试的效果。AutoRestTest利用SPDG确定操作依赖参数，并通过五个专门的代理（操作、参数、值、依赖和头部）识别操作间的依赖关系并生成操作序列、参数组合及值。用户可通过直观的命令行界面轻松配置和监控测试过程，包括成功执行的操作计数、检测到的独特服务器错误数量以及已消耗的时间。测试完成后，AutoRestTest将生成详细的报告，突出显示所发现的错误和执行的操作。文章还提供了初步的研究成果和演示视频链接。 <div>
arXiv:2501.08600v2 Announce Type: replace 
Abstract: As REST APIs have become widespread in modern web services, comprehensive testing of these APIs is increasingly crucial. Because of the vast search space of operations, parameters, and parameter values, along with their dependencies and constraints, current testing tools often achieve low code coverage, resulting in suboptimal fault detection. To address this limitation, we present AutoRestTest, a novel tool that integrates the Semantic Property Dependency Graph (SPDG) with Multi-Agent Reinforcement Learning (MARL) and large language models (LLMs) for effective REST API testing. AutoRestTest determines operation-dependent parameters using the SPDG and employs five specialized agents (operation, parameter, value, dependency, and header) to identify dependencies of operations and generate operation sequences, parameter combinations, and values. Through an intuitive command-line interface, users can easily configure and monitor tests with successful operation count, unique server errors detected, and time elapsed. Upon completion, AutoRestTest generates a detailed report highlighting errors detected and operations exercised. In this paper, we introduce our tool and present preliminary findings, with a demonstration video available at https://www.youtube.com/watch?v=VVus2W8rap8.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Safe AI Clinicians: A Comprehensive Study on Large Language Model Jailbreaking in Healthcare</title>
<link>https://arxiv.org/abs/2501.18632</link>
<guid>https://arxiv.org/abs/2501.18632</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 医疗应用, 安全性, 黑盒越狱技术, 继续微调 (CFT)

<br /><br />总结:

本文研究了大型语言模型（LLMs）在医疗应用中的安全隐患，尤其是在临床实践中可能传播有害信息的问题。研究系统评估了七种LLM对三种高级黑盒越狱技术的易感性，并提出了一种自动化的、领域适应性的评价管道来量化这些攻击的有效性。实验结果显示，主流商业和开源的LLM对医疗领域的越狱攻击高度易受攻击。为提高模型的安全性和可靠性，文章还探讨了继续微调（CFT）在防御医疗对抗性攻击方面的有效性。研究结果强调了进化攻击方法评估、领域特定安全对齐以及LLM安全-效益平衡的重要性。这项研究为提升AI在医疗领域的安全性和可靠性提供了可操作的见解，有助于实现伦理和有效的AI部署。 <div>
arXiv:2501.18632v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly utilized in healthcare applications. However, their deployment in clinical practice raises significant safety concerns, including the potential spread of harmful information. This study systematically assesses the vulnerabilities of seven LLMs to three advanced black-box jailbreaking techniques within medical contexts. To quantify the effectiveness of these techniques, we propose an automated and domain-adapted agentic evaluation pipeline. Experiment results indicate that leading commercial and open-source LLMs are highly vulnerable to medical jailbreaking attacks. To bolster model safety and reliability, we further investigate the effectiveness of Continual Fine-Tuning (CFT) in defending against medical adversarial attacks. Our findings underscore the necessity for evolving attack methods evaluation, domain-specific safety alignment, and LLM safety-utility balancing. This research offers actionable insights for advancing the safety and reliability of AI clinicians, contributing to ethical and effective AI deployment in healthcare.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discrete GCBF Proximal Policy Optimization for Multi-agent Safe Optimal Control</title>
<link>https://arxiv.org/abs/2502.03640</link>
<guid>https://arxiv.org/abs/2502.03640</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统(MAS)、分布式控制 Barrier 函数(CBF)、未知离散时间动态、局部可观测性、输入约束、DGPPO框架、安全性能、高任务性能

<br /><br />总结:
该文针对多智能体系统（MAS）中实现高任务性能并满足安全性约束的控制策略设计问题，提出了一种名为DGPPO的新框架。该框架同时学习离散图Barrier函数和分布式的高绩效安全策略，旨在解决未知离散时间动态、局部可观测性、变化的邻域以及输入约束等挑战。尤其在缺乏分布式高性能名义策略的情况下，DGPPO依然能有效应用。通过在多个不同模拟引擎下的多智能体任务中进行实证验证，结果表明相较于现有方法，DGPPO框架能够在保持高任务性能（与忽略安全性约束的基线相当）的同时，确保高安全率（与最为保守的基线相当），并且在所有环境中使用恒定的超参数集。 <div>
arXiv:2502.03640v2 Announce Type: replace 
Abstract: Control policies that can achieve high task performance and satisfy safety constraints are desirable for any system, including multi-agent systems (MAS). One promising technique for ensuring the safety of MAS is distributed control barrier functions (CBF). However, it is difficult to design distributed CBF-based policies for MAS that can tackle unknown discrete-time dynamics, partial observability, changing neighborhoods, and input constraints, especially when a distributed high-performance nominal policy that can achieve the task is unavailable. To tackle these challenges, we propose DGPPO, a new framework that simultaneously learns both a discrete graph CBF which handles neighborhood changes and input constraints, and a distributed high-performance safe policy for MAS with unknown discrete-time dynamics. We empirically validate our claims on a suite of multi-agent tasks spanning three different simulation engines. The results suggest that, compared with existing methods, our DGPPO framework obtains policies that achieve high task performance (matching baselines that ignore the safety constraints), and high safety rates (matching the most conservative baselines), with a constant set of hyperparameters across all environments.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Restless to Contextual: A Thresholding Bandit Approach to Improve Finite-horizon Performance</title>
<link>https://arxiv.org/abs/2502.05145</link>
<guid>https://arxiv.org/abs/2502.05145</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线疲惫乐队问题、状态转移、预算约束、马尔可夫决策过程、学习算法

总结:
在线疲惫乐队问题是扩展了经典上下文相关乐队问题的一种模型，它引入了状态转换和预算约束，将每个代理建模为一个马尔可夫决策过程。针对有限时间轴的战略资源分配优化等问题，该框架具有重要意义。然而，在有限时间范围内学习每个代理的底层MDP是一个重大挑战。为了促进学习，研究者将问题重新定义为一个可扩展的预算阈值上下文乐队问题，巧妙地将状态转换融入奖励设计，并关注于识别那些行动收益超过阈值的代理。在简单的双状态场景中，论文证明了一个oracle贪婪解法的最优性，并提出了一种在具有异质代理的多状态在线场景下实现对无干预结果知识下的最小最大常数遗憾上界的算法。数值模拟表明，该算法相较于现有的在线疲惫乐队问题方法表现出优越性能，尤其在有限时间尺度上的表现有了显著提升。 <div>
arXiv:2502.05145v2 Announce Type: replace 
Abstract: Online restless bandits extend classic contextual bandits by incorporating state transitions and budget constraints, representing each agent as a Markov Decision Process (MDP). This framework is crucial for finite-horizon strategic resource allocation, optimizing limited costly interventions for long-term benefits. However, learning the underlying MDP for each agent poses a major challenge in finite-horizon settings. To facilitate learning, we reformulate the problem as a scalable budgeted thresholding contextual bandit problem, carefully integrating the state transitions into the reward design and focusing on identifying agents with action benefits exceeding a threshold. We establish the optimality of an oracle greedy solution in a simple two-state setting, and propose an algorithm that achieves minimax optimal constant regret in the online multi-state setting with heterogeneous agents and knowledge of outcomes under no intervention. We numerically show that our algorithm outperforms existing online restless bandit methods, offering significant improvements in finite-horizon performance.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Understanding Dynamic Diffusion Process of LLM-based Agents under Information Asymmetry</title>
<link>https://arxiv.org/abs/2502.13160</link>
<guid>https://arxiv.org/abs/2502.13160</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、社会模拟、信息扩散、动态注意力机制、信息茧房

总结:
本文研究了大规模语言模型在模拟人类社会中的应用，关注信息扩散动力学特性。文章提出了一个通用框架来捕捉信息扩散的特点，并设计了一种动态注意力机制，以解决基于LLM的注意力分配问题。研究在由信息内容和分布机制定义的12个不对称开放环境中进行，观察到五代理小组如何响应外部信息刺激，随着小组规模扩大和信息圈形成，同时发展关系并分享信息。进一步地，文中还发现了信息茧房现象、信息差距的演变以及社会资本的积累，这些发现与心理学、社会学和传播理论紧密相关。<br /><br /> <div>
arXiv:2502.13160v2 Announce Type: replace 
Abstract: Large language models have been used to simulate human society using multi-agent systems. Most current social simulation research emphasizes interactive behaviors in fixed environments, ignoring information opacity, relationship variability and diffusion diversity. In this paper, we study the dynamics of information diffusion in 12 asymmetric open environments defined by information content and distribution mechanisms. We first present a general framework to capture the features of information diffusion. Then, we designed a dynamic attention mechanism to help agents allocate attention to different information, addressing the limitations of LLM-based attention. Agents start by responding to external information stimuli within a five-agent group, increasing group size and forming information circles while developing relationships and sharing information. Additionally, we observe the emergence of information cocoons, the evolution of information gaps, and the accumulation of social capital, which are closely linked to psychological, sociological, and communication theories.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gradients can train reward models: An Empirical Risk Minimization Approach for Offline Inverse RL and Dynamic Discrete Choice Model</title>
<link>https://arxiv.org/abs/2502.14131</link>
<guid>https://arxiv.org/abs/2502.14131</guid>
<content:encoded><![CDATA[
<div> 关键词: 动态离散选择模型、最大熵逆强化学习、无监督学习、神经网络、Polyak-Lojasiewicz条件

总结:
本文研究了动态离散选择模型(也称为无监督最大熵逆强化学习)的估计问题，旨在从离线行为数据中恢复调控代理行为的奖励或$Q^*$函数。文章提出了一种无需线性参数化奖励假设的全局收敛梯度基方法。该方法创新地引入基于经验风险最小化的IRL/DDC框架，规避了在贝尔曼方程中对状态转移概率的直接估计需求，并兼容非参数估计技术如神经网络，因此有望应用于高维、无限状态空间的问题。理论分析表明，我们的方法所依据的贝尔曼残差满足较弱的Polyak-Lojasiewicz条件，这一性质足以保证快速全局收敛保证。通过一系列合成实验，证明了本文方法相较于基准方法和现有最先进的替代方案具有更优的表现。 <div>
arXiv:2502.14131v2 Announce Type: replace 
Abstract: We study the problem of estimating Dynamic Discrete Choice (DDC) models, also known as offline Maximum Entropy-Regularized Inverse Reinforcement Learning (offline MaxEnt-IRL) in machine learning. The objective is to recover reward or $Q^*$ functions that govern agent behavior from offline behavior data. In this paper, we propose a globally convergent gradient-based method for solving these problems without the restrictive assumption of linearly parameterized rewards. The novelty of our approach lies in introducing the Empirical Risk Minimization (ERM) based IRL/DDC framework, which circumvents the need for explicit state transition probability estimation in the Bellman equation. Furthermore, our method is compatible with non-parametric estimation techniques such as neural networks. Therefore, the proposed method has the potential to be scaled to high-dimensional, infinite state spaces. A key theoretical insight underlying our approach is that the Bellman residual satisfies the Polyak-Lojasiewicz (PL) condition -- a property that, while weaker than strong convexity, is sufficient to ensure fast global convergence guarantees. Through a series of synthetic experiments, we demonstrate that our approach consistently outperforms benchmark methods and state-of-the-art alternatives.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>P2DFlow: A Protein Ensemble Generative Model with SE(3) Flow Matching</title>
<link>https://arxiv.org/abs/2411.17196</link>
<guid>https://arxiv.org/abs/2411.17196</guid>
<content:encoded><![CDATA[
<div> 关键词：P2DFlow、蛋白质结构ensemble、SE(3)流匹配、分子动力学模拟、功能理解

<br /><br />总结:
本文介绍了研究团队开发的一种名为P2DFlow的生成模型，该模型基于SE(3)流匹配原理，用于预测蛋白质的结构 ensemble。通过设计有利于流动过程的先验知识和增加一维来描述集合数据，以反映蛋白质构象分布的物理规律，使模型能更好地识别中间状态。在ATLAS的MD数据集上训练与评估，P2DFlow在大量实验中超越了其他基线模型，成功捕捉到了类似于晶体结构和MD模拟中的动态变化。高质量的蛋白质结构ensemble生成结果使得P2DFlow有可能成为蛋白分子模拟的有效代理工具，进而有助于深入理解蛋白质在不同场景下的功能。相关代码已开源，可在https://github.com/BLEACH366/P2DFlow 获取。 <div>
arXiv:2411.17196v2 Announce Type: replace-cross 
Abstract: Biological processes, functions, and properties are intricately linked to the ensemble of protein conformations, rather than being solely determined by a single stable conformation. In this study, we have developed P2DFlow, a generative model based on SE(3) flow matching, to predict the structural ensembles of proteins. We specifically designed a valuable prior for the flow process and enhanced the model's ability to distinguish each intermediate state by incorporating an additional dimension to describe the ensemble data, which can reflect the physical laws governing the distribution of ensembles, so that the prior knowledge can effectively guide the generation process. When trained and evaluated on the MD datasets of ATLAS, P2DFlow outperforms other baseline models on extensive experiments, successfully capturing the observable dynamic fluctuations as evidenced in crystal structure and MD simulations. As a potential proxy agent for protein molecular simulation, the high-quality ensembles generated by P2DFlow could significantly aid in understanding protein functions across various scenarios. Code is available at https://github.com/BLEACH366/P2DFlow
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stability Analysis of Deep Reinforcement Learning for Multi-Agent Inspection in a Terrestrial Testbed</title>
<link>https://arxiv.org/abs/2503.00056</link>
<guid>https://arxiv.org/abs/2503.00056</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主系统、深强化学习(DRL)、多代理卫星检查任务、层次化框架、实验评估

总结:
该研究评估了一个用于多代理卫星检查任务的层次化深度强化学习（DRL）框架的稳定性和性能。该框架结合了高层指导策略和低层运动控制器，实现可扩展的任务分配和高效的轨迹执行。通过在从模拟环境到cyber-physical测试平台的Local Intelligent Network of Collaborative Satellites (LINCS) 测试平台上进行的实验，考察了框架在不同保真度条件下的表现。实验结果强调了框架在面对真实世界不确定性（如传感器噪声、动态扰动及运行时间保证约束）时的鲁棒性和适应性，证实了层次化控制器能有效弥合模拟与现实之间的差距，保持高任务完成率并适应复杂的真实环境。这些发现验证了该框架在未来空间任务中实现自主卫星操作的潜力。 <div>
arXiv:2503.00056v1 Announce Type: new 
Abstract: The design and deployment of autonomous systems for space missions require robust solutions to navigate strict reliability constraints, extended operational duration, and communication challenges. This study evaluates the stability and performance of a hierarchical deep reinforcement learning (DRL) framework designed for multi-agent satellite inspection tasks. The proposed framework integrates a high-level guidance policy with a low-level motion controller, enabling scalable task allocation and efficient trajectory execution. Experiments conducted on the Local Intelligent Network of Collaborative Satellites (LINCS) testbed assess the framework's performance under varying levels of fidelity, from simulated environments to a cyber-physical testbed. Key metrics, including task completion rate, distance traveled, and fuel consumption, highlight the framework's robustness and adaptability despite real-world uncertainties such as sensor noise, dynamic perturbations, and runtime assurance (RTA) constraints. The results demonstrate that the hierarchical controller effectively bridges the sim-to-real gap, maintaining high task completion rates while adapting to the complexities of real-world environments. These findings validate the framework's potential for enabling autonomous satellite operations in future space missions.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Attacks Break Defenses Against Indirect Prompt Injection Attacks on LLM Agents</title>
<link>https://arxiv.org/abs/2503.00061</link>
<guid>https://arxiv.org/abs/2503.00061</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM)、外部工具、安全风险、间接提示注入攻击 (IPI)、防御策略

<br /><br />总结:
本文针对使用外部工具与环境交互的大规模语言模型（LLM）代理，研究了其在集成外部工具过程中引入的安全风险，特别是间接提示注入（IPI）攻击。文章中评估了八种不同的防御策略，但通过实施自适应攻击，成功绕过了所有这些防御措施，始终保持着超过50%的攻击成功率。这揭示出现有防御策略存在的严重漏洞。该研究强调，在设计防御策略时需要进行自适应攻击评估以确保其鲁棒性和可靠性。相关代码已发布在https://github.com/uiuc-kang-lab/AdaptiveAttackAgent。 <div>
arXiv:2503.00061v1 Announce Type: new 
Abstract: Large Language Model (LLM) agents exhibit remarkable performance across diverse applications by using external tools to interact with environments. However, integrating external tools introduces security risks, such as indirect prompt injection (IPI) attacks. Despite defenses designed for IPI attacks, their robustness remains questionable due to insufficient testing against adaptive attacks. In this paper, we evaluate eight different defenses and bypass all of them using adaptive attacks, consistently achieving an attack success rate of over 50%. This reveals critical vulnerabilities in current defenses. Our research underscores the need for adaptive attack evaluation when designing defenses to ensure robustness and reliability. The code is available at https://github.com/uiuc-kang-lab/AdaptiveAttackAgent.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CAMETA: Conflict-Aware Multi-Agent Estimated Time of Arrival Prediction for Mobile Robots</title>
<link>https://arxiv.org/abs/2503.00074</link>
<guid>https://arxiv.org/abs/2503.00074</guid>
<content:encoded><![CDATA[
<div> 关键词: CAMETA框架、多智能体、预计到达时间、无结构环境、图神经网络

总结:<br />
本文介绍了一个名为CAMETA的新颖框架，用于预测在无结构环境中多个智能体的预计到达时间。该框架包括路径规划层（生成潜在路径建议）、多智能体ETA预测层（基于路径预测所有智能体的到达时间）和路径选择层（计算累积成本并选取最佳路径）。CAMETA的创新点在于其异构地图表示和异构图神经网络架构，从而提高了对依赖于结构化道路基础设施和历史数据的现有方法的泛化能力。模拟结果显示，与不考虑冲突的传统路径规划方法（如A*）相比，CAMETA的多智能体ETA预测层在准确率上平均提高了29.5%和44%。此外，CAMETA框架在应对噪声和冲突以及确定高效路线方面表现出了比现有主流多智能体路径规划方法显著的优势。 <div>
arXiv:2503.00074v1 Announce Type: new 
Abstract: This study presents the conflict-aware multi-agent estimated time of arrival (CAMETA) framework, a novel approach for predicting the arrival times of multiple agents in unstructured environments without predefined road infrastructure. The CAMETA framework consists of three components: a path planning layer generating potential path suggestions, a multi-agent ETA prediction layer predicting the arrival times for all agents based on the paths, and lastly, a path selection layer that calculates the accumulated cost and selects the best path. The novelty of the CAMETA framework lies in the heterogeneous map representation and the heterogeneous graph neural network architecture. As a result of the proposed novel structure, CAMETA improves the generalization capability compared to the state-of-the-art methods that rely on structured road infrastructure and historical data. The simulation results demonstrate the efficiency and efficacy of the multi-agent ETA prediction layer, with a mean average percentage error improvement of 29.5% and 44% when compared to a traditional path planning method (A *) which does not consider conflicts. The performance of the CAMETA framework shows significant improvements in terms of robustness to noise and conflicts as well as determining proficient routes compared to state-of-the-art multi-agent path planners.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EdgeAIGuard: Agentic LLMs for Minor Protection in Digital Spaces</title>
<link>https://arxiv.org/abs/2503.00092</link>
<guid>https://arxiv.org/abs/2503.00092</guid>
<content:encoded><![CDATA[
<div> 关键词：社交媒体、未成年人、内容审核、边缘AI保护、在线 groomer 防御

总结:<br />
本文关注了社交媒体对未成年人日常生活的重要性以及伴随而来的网络安全挑战，如网络欺凌和在线诱拐等。针对传统内容审核技术对此类威胁的有效性不足问题，文章提出了名为EdgeAIGuard的内容审核新方法。该方法采用多代理架构，部署在网络边缘，旨在实现对未成年人的快速、低延迟的有害内容检测与预防。实验结果表明，相较于现有方法，EdgeAIGuard在防范针对未成年人的数字剥削方面表现出显著更高的效果。 <div>
arXiv:2503.00092v1 Announce Type: new 
Abstract: Social media has become integral to minors' daily lives and is used for various purposes, such as making friends, exploring shared interests, and engaging in educational activities. However, the increase in screen time has also led to heightened challenges, including cyberbullying, online grooming, and exploitations posed by malicious actors. Traditional content moderation techniques have proven ineffective against exploiters' evolving tactics. To address these growing challenges, we propose the EdgeAIGuard content moderation approach that is designed to protect minors from online grooming and various forms of digital exploitation. The proposed method comprises a multi-agent architecture deployed strategically at the network edge to enable rapid detection with low latency and prevent harmful content targeting minors. The experimental results show the proposed method is significantly more effective than the existing approaches.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Personalized Causal Graph Reasoning for LLMs: A Case Study on Dietary Recommendations</title>
<link>https://arxiv.org/abs/2503.00134</link>
<guid>https://arxiv.org/abs/2503.00134</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 个性化推理, 因果图推理, 饮食推荐, 血糖管理

总结:<br />
本文提出了“个性化因果图推理”框架，旨在增强大型语言模型（LLMs）在处理涉及个人多因素数据时的个性化推理能力，扩大其在需要情境感知决策制定领域的应用。该框架通过从个体数据中获取的个人因果图引导LLM的推理过程。研究以营养导向的饮食建议为例，其中个人化的推理至关重要，因为饮食对每个人的隐性影响各不相同。文章采用反事实评估方法来估计LLM推荐食品在血糖管理方面的效率，并表明所提方法能有效地提供个性化的饮食建议，降低三个时间窗口内的平均血糖iAUC，性能优于传统方法。通过LLM作为评判者的评价结果显示，提出的方法提升了推理过程中的个性化程度。 <div>
arXiv:2503.00134v1 Announce Type: new 
Abstract: Large Language Models (LLMs) effectively leverage common-sense knowledge for general reasoning, yet they struggle with personalized reasoning when tasked with interpreting multifactor personal data. This limitation restricts their applicability in domains that require context-aware decision-making tailored to individuals. This paper introduces Personalized Causal Graph Reasoning as an agentic framework that enhances LLM reasoning by incorporating personal causal graphs derived from data of individuals. These graphs provide a foundation that guides the LLM's reasoning process. We evaluate it on a case study on nutrient-oriented dietary recommendations, which requires personal reasoning due to the implicit unique dietary effects. We propose a counterfactual evaluation to estimate the efficiency of LLM-recommended foods for glucose management. Results demonstrate that the proposed method efficiently provides personalized dietary recommendations to reduce average glucose iAUC across three time windows, which outperforms the previous approach. LLM-as-a-judge evaluation results indicate that our proposed method enhances personalization in the reasoning process.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PreMind: Multi-Agent Video Understanding for Advanced Indexing of Presentation-style Videos</title>
<link>https://arxiv.org/abs/2503.00162</link>
<guid>https://arxiv.org/abs/2503.00162</guid>
<content:encoded><![CDATA[
<div> 关键词：PreMind、在线讲座视频、多模态框架、视频索引、视觉-语言模型

<br />
总结:
本文提出了一种名为PreMind的新型多代理多模态框架，用于增强对演示风格讲座视频的理解和索引。该框架利用大型视觉-语言模型改进现代shot检测技术来分割视频为幻灯片展示片段。接着，PreMind通过三个关键步骤分析每个片段以生成多模态索引：提取幻灯片视觉内容、转录语音叙述以及将这些视觉和语音内容整合为综合理解。此外，还提出了三项创新机制，包括利用先前的讲座知识细化视觉理解、使用视觉-语言模型检测并纠正语音转录错误，以及利用批评型代理进行动态迭代自我反思的视觉分析。与传统视频索引方法相比，PreMind能够捕获丰富可靠的多模态信息，使得用户可以搜索仅在幻灯片上显示的细节，如缩写等。通过在公开的LPM数据集和内部企业数据集上的系统评估，验证了PreMind的有效性，并进行了详细的分析。 <div>
arXiv:2503.00162v1 Announce Type: new 
Abstract: In recent years, online lecture videos have become an increasingly popular resource for acquiring new knowledge. Systems capable of effectively understanding/indexing lecture videos are thus highly desirable, enabling downstream tasks like question answering to help users efficiently locate specific information within videos. This work proposes PreMind, a novel multi-agent multimodal framework that leverages various large models for advanced understanding/indexing of presentation-style videos. PreMind first segments videos into slide-presentation segments using a Vision-Language Model (VLM) to enhance modern shot-detection techniques. Each segment is then analyzed to generate multimodal indexes through three key steps: (1) extracting slide visual content, (2) transcribing speech narratives, and (3) consolidating these visual and speech contents into an integrated understanding. Three innovative mechanisms are also proposed to improve performance: leveraging prior lecture knowledge to refine visual understanding, detecting/correcting speech transcription errors using a VLM, and utilizing a critic agent for dynamic iterative self-reflection in vision analysis. Compared to traditional video indexing methods, PreMind captures rich, reliable multimodal information, allowing users to search for details like abbreviations shown only on slides. Systematic evaluations on the public LPM dataset and an internal enterprise dataset are conducted to validate PreMind's effectiveness, supported by detailed analyses.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Transforming Cyber Defense: Harnessing Agentic and Frontier AI for Proactive, Ethical Threat Intelligence</title>
<link>https://arxiv.org/abs/2503.00164</link>
<guid>https://arxiv.org/abs/2503.00164</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能(AI)，前沿AI，网络安全，自动化响应，持续学习

<br /><br />总结:
本文探讨了人工智能，特别是agentic AI与前沿AI在网络安全领域的融合如何重塑防御框架，如改进网络杀伤链和提升威胁情报处理。通过实时监控、自动化事件响应及持续学习，文章阐述了这些技术如何构建一个适应性强、动态的防御生态系统，以有效对抗不断演变的网络威胁。同时，文章强调了在构建未来AI驱动的安全解决方案中，要坚持道德治理，确保新方案遵循公平、透明和责任等核心人类价值观。 <div>
arXiv:2503.00164v1 Announce Type: new 
Abstract: In an era marked by unprecedented digital complexity, the cybersecurity landscape is evolving at a breakneck pace, challenging traditional defense paradigms. Advanced Persistent Threats (APTs) reveal inherent vulnerabilities in conventional security measures and underscore the urgent need for continuous, adaptive, and proactive strategies that seamlessly integrate human insight with cutting edge AI technologies. This manuscript explores how the convergence of agentic AI and Frontier AI is transforming cybersecurity by reimagining frameworks such as the cyber kill chain, enhancing threat intelligence processes, and embedding robust ethical governance within automated response systems. Drawing on real-world data and forward looking perspectives, we examine the roles of real time monitoring, automated incident response, and perpetual learning in forging a resilient, dynamic defense ecosystem. Our vision is to harmonize technological innovation with unwavering ethical oversight, ensuring that future AI driven security solutions uphold core human values of fairness, transparency, and accountability while effectively countering emerging cyber threats.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Reinforcement Learning for State Avoidance in Discrete Event Systems</title>
<link>https://arxiv.org/abs/2503.00192</link>
<guid>https://arxiv.org/abs/2503.00192</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习(Reinforcement Learning, RL)，离散事件监督(Discrete Event Supervisory, DES)，混合决策系统，连续状态，事件驱动

<br /><br />总结:
本文提出了一种新的融合离散事件监督模型与标准强化学习框架的混合决策系统架构。该架构旨在解决复杂环境中结合事件驱动决策过程的挑战。通过结合DES对事件型动态的良好管理能力以及RL代理对连续状态和动作的适应性，实现了对同时含有连续和离散事件系统的更稳健灵活的控制策略。DES模型与RL代理协同工作，利用事件驱动的洞察力提升策略性能，而环境状态转换由机械模型进行调控。通过模拟实验验证了该方法相比传统RL实现具有更好的性能指标，表明该综合方法在工业自动化和智能交通等强调离散事件处理的应用中具有广阔前景。 <div>
arXiv:2503.00192v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has emerged as a potent paradigm for autonomous decision-making in complex environments. However, the integration of event-driven decision processes within RL remains a challenge. This paper presents a novel architecture that combines a Discrete Event Supervisory (DES) model with a standard RL framework to create a hybrid decision-making system. Our model leverages the DES's capabilities in managing event-based dynamics with the RL agent's adaptability to continuous states and actions, facilitating a more robust and flexible control strategy in systems characterized by both continuous and discrete events. The DES model operates alongside the RL agent, enhancing the policy's performance with event-based insights, while the environment's state transitions are governed by a mechanistic model. We demonstrate the efficacy of our approach through simulations that show improved performance metrics over traditional RL implementations. Our results suggest that this integrated approach holds promise for applications ranging from industrial automation to intelligent traffic systems, where discrete event handling is paramount.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic AI Needs a Systems Theory</title>
<link>https://arxiv.org/abs/2503.00237</link>
<guid>https://arxiv.org/abs/2503.00237</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI), 系统理论视角, 模型能力, 交互环境, 风险管理

总结:
本文指出当前AI的发展过于关注单一模型的能力，而忽视了更广泛的涌现行为以及与环境和其他代理的互动可能导致高级功能被低估。文章强调采用更为全面、系统理论的视角对于理解agentic AI的真正能力和风险至关重要。文中探讨了通过环境和多智能体互动，较为简单的代理如何能涌现出增强的认知、因果推理能力和元认知意识等高级特性。最后，文章提出了agentic AI开发面临的挑战并给出了相关指导建议。作者认为，从系统的层面来理解和有意塑造agentic AI系统是非常必要的。<br /><br /> <div>
arXiv:2503.00237v1 Announce Type: new 
Abstract: The endowment of AI with reasoning capabilities and some degree of agency is widely viewed as a path toward more capable and generalizable systems. Our position is that the current development of agentic AI requires a more holistic, systems-theoretic perspective in order to fully understand their capabilities and mitigate any emergent risks. The primary motivation for our position is that AI development is currently overly focused on individual model capabilities, often ignoring broader emergent behavior, leading to a significant underestimation in the true capabilities and associated risks of agentic AI. We describe some fundamental mechanisms by which advanced capabilities can emerge from (comparably simpler) agents simply due to their interaction with the environment and other agents. Informed by an extensive amount of existing literature from various fields, we outline mechanisms for enhanced agent cognition, emergent causal reasoning ability, and metacognitive awareness. We conclude by presenting some key open challenges and guidance for the development of agentic AI. We emphasize that a systems-level perspective is essential for better understanding, and purposefully shaping, agentic AI systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Passage Query Methods for Retrieval and Reranking in Conversational Agents</title>
<link>https://arxiv.org/abs/2503.00238</link>
<guid>https://arxiv.org/abs/2503.00238</guid>
<content:encoded><![CDATA[
<div> 关键词：TREC iKAT、对话信息检索、生成-检索-生成、段落查询、Meta Llama模型

总结:<br />
本文介绍了针对TREC交互式知识援助轨道(iKAT)的任务，该任务关注于提升对话信息检索系统的性能。研究中提出了一种改进方法，通过扩展生成-检索-生成管道并开发与目标文档预期格式对齐的段落查询(PQs)，以提高检索阶段的查询和文档匹配度。文章提出了两种方法变体：加权重新排名和短长段落。这两种方法都利用了Meta Llama模型来理解和生成对话上下文中的查询和响应。结果显示，短长段落方法优于组织者的基线，在Llama为基础的系统中表现最佳，并且其效果可与基于GPT-4的系统相媲美。这表明该方法有效地平衡了效率和性能，并证实了PQs能改善与目标文档的语义对齐，展示了它们在多轮对话系统中的潜力。 <div>
arXiv:2503.00238v1 Announce Type: new 
Abstract: This paper presents our approach to the TREC Interactive Knowledge Assistance Track (iKAT), which focuses on improving conversational information-seeking (CIS) systems. While recent advancements in CIS have improved conversational agents' ability to assist users, significant challenges remain in understanding context and retrieving relevant documents across domains and dialogue turns. To address these issues, we extend the Generate-Retrieve-Generate pipeline by developing passage queries (PQs) that align with the target document's expected format to improve query-document matching during retrieval. We propose two variations of this approach: Weighted Reranking and Short and Long Passages. Each method leverages a Meta Llama model for context understanding and generating queries and responses. Passage ranking evaluation results show that the Short and Long Passages approach outperformed the organizers' baselines, performed best among Llama-based systems in the track, and achieved results comparable to GPT-4-based systems. These results indicate that the method effectively balances efficiency and performance. Findings suggest that PQs improve semantic alignment with target documents and demonstrate their potential to improve multi-turn dialogue systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Human-AI Collaboration: Trade-offs Between Performance and Preferences</title>
<link>https://arxiv.org/abs/2503.00248</link>
<guid>https://arxiv.org/abs/2503.00248</guid>
<content:encoded><![CDATA[
<div> 关键词：协作AI、人类输入、交互策略、人工智能特质、人类偏好

总结:<br />
本文关注于协作AI领域中如何更好地设计与人类无缝配合的人工智能系统。研究者开发了一项任务，通过对比分析了五个具有不同适应人类行为方式和程度的协作AI代理。实验结果显示，更加注重考虑人类行动的代理人相比单纯追求最优性能的代理人更受参与者青睐。此外，以人类为中心的设计不仅可以提升AI合作者的受欢迎程度，而且不会降低团队整体表现。研究还发现，不平等厌恶效应对人类选择有影响，人们倾向于选择那些能让他们对团队做出有意义贡献的协作AI。综上所述，这些发现表明，结合主观和客观指标的发展努力可以使AI协作受益。 <div>
arXiv:2503.00248v1 Announce Type: new 
Abstract: Despite the growing interest in collaborative AI, designing systems that seamlessly integrate human input remains a major challenge. In this study, we developed a task to systematically examine human preferences for collaborative agents. We created and evaluated five collaborative AI agents with strategies that differ in the manner and degree they adapt to human actions. Participants interacted with a subset of these agents, evaluated their perceived traits, and selected their preferred agent. We used a Bayesian model to understand how agents' strategies influence the Human-AI team performance, AI's perceived traits, and the factors shaping human-preferences in pairwise agent comparisons. Our results show that agents who are more considerate of human actions are preferred over purely performance-maximizing agents. Moreover, we show that such human-centric design can improve the likability of AI collaborators without reducing performance. We find evidence for inequality-aversion effects being a driver of human choices, suggesting that people prefer collaborative agents which allow them to meaningfully contribute to the team. Taken together, these findings demonstrate how collaboration with AI can benefit from development efforts which include both subjective and objective metrics.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Passive Safe Reinforcement Learning: A Comparative Study on Contact-rich Robotic Manipulation</title>
<link>https://arxiv.org/abs/2503.00287</link>
<guid>https://arxiv.org/abs/2503.00287</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning），安全性，稳定性，能控性，能源约束

总结:
本文探讨了强化学习在接触丰富的实际任务中所面临的安全性和稳定性挑战。为解决这些问题，研究提出了将基于能源的被动控制与安全强化学习相结合的方法，分别在训练和部署阶段应用。首先，文章引入基于能源约束的安全强化学习框架，以训练出“能控意识”的RL代理；其次，在部署阶段通过能控滤波器确保控制的稳定性。通过对比实现在接触丰富的机器人迷宫探索任务上的效果，实验表明，未经能控考虑的RL策略在部署时容易违反能源约束，尽管其在训练中表现出高任务完成率。而所提出的方案则通过能控过滤保证控制稳定性，并通过能控意识训练提升能源效率。文章提供了真实世界实验的视频作为补充材料，并已在Hugging Face上发布了预训练模型和离线数据。 <div>
arXiv:2503.00287v1 Announce Type: new 
Abstract: Reinforcement learning (RL) has achieved remarkable success in various robotic tasks; however, its deployment in real-world scenarios, particularly in contact-rich environments, often overlooks critical safety and stability aspects. Policies without passivity guarantees can result in system instability, posing risks to robots, their environments, and human operators. In this work, we investigate the limitations of traditional RL policies when deployed in contact-rich tasks and explore the combination of energy-based passive control with safe RL in both training and deployment to answer these challenges. Firstly, we introduce energy-based constraints in our safe RL formulation to train \textit{passivity-aware} RL agents. Secondly, we add a passivity filter on the agent output for \textit{passivity-ensured} control during deployment. We conduct comparative studies on a contact-rich robotic maze exploration task, evaluating the effects of learning passivity-aware policies and the importance of passivity-ensured control. The experiments demonstrate that a passivity-agnostic RL policy easily violates energy constraints in deployment, even though it achieves high task completion in training. The results show that our proposed approach guarantees control stability through passivity filtering and improves the energy efficiency through passivity-aware training. A video of real-world experiments is available as supplementary material. We also release the checkpoint model and offline data for pre-training at \href{https://huggingface.co/Anonymous998/passiveRL/tree/main}{Hugging Face}
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PINN-DT: Optimizing Energy Consumption in Smart Building Using Hybrid Physics-Informed Neural Networks and Digital Twin Framework with Blockchain Security</title>
<link>https://arxiv.org/abs/2503.00331</link>
<guid>https://arxiv.org/abs/2503.00331</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习 (Deep Reinforcement Learning, DRL)、数字孪生(Digital Twins, DT)、物理 informated 神经网络(Physics-Informed Neural Networks, PINNs)、区块链(Blockchain, BC)、智能电网(Smart Grid)

总结:<br />
本文提出了一种综合运用深度强化学习、数字孪生、物理informated神经网络和区块链技术优化智能电网实时能源消耗的方法。该框架通过使用包括智能电表数据、可再生能源输出、动态定价和物联网设备收集的用户偏好在内的全面数据集训练和验证DRL代理。同时，利用PINNs保证模型准确性和解释性，采用区块链确保通信安全透明。实验结果显示，该模型预测性能优异，具有低误差（MAE：0.237 kWh，RMSE：0.298 kWh）、高拟合度（R2：0.978）以及出色的分类指标（准确性：97.7%，精度：97.8%，召回率：97.6%，F1分数：97.7%）。与传统模型如线性回归、随机森林、SVM、LSTM和XGBoost相比，该方法展现出更高的准确性和实时适应性，并成功降低了35%的能源成本，保持了96%的用户舒适度，提高了40%的可再生能源利用率。这一研究揭示了将PINNs、DT和区块链技术整合应用于智能电网能源管理中的巨大潜力，为实现可持续、安全和高效的能源管理系统开辟了新途径。 <div>
arXiv:2503.00331v1 Announce Type: new 
Abstract: The advancement of smart grid technologies necessitates the integration of cutting-edge computational methods to enhance predictive energy optimization. This study proposes a multi-faceted approach by incorporating (1) Deep Reinforcement Learning (DRL) agents trained using data from Digital Twins (DTs) to optimize energy consumption in real time, (2) Physics-Informed Neural Networks (PINNs) to seamlessly embed physical laws within the optimization process, ensuring model accuracy and interpretability, and (3) Blockchain (BC) technology to facilitate secure and transparent communication across the smart grid infrastructure. The model was trained and validated using comprehensive datasets, including smart meter energy consumption data, renewable energy outputs, dynamic pricing, and user preferences collected from IoT devices. The proposed framework achieved superior predictive performance with a Mean Absolute Error (MAE) of 0.237 kWh, Root Mean Square Error (RMSE) of 0.298 kWh, and an R-squared (R2) value of 0.978, indicating a 97.8% explanation of data variance. Classification metrics further demonstrated the model's robustness, achieving 97.7% accuracy, 97.8% precision, 97.6% recall, and an F1 Score of 97.7%. Comparative analysis with traditional models like Linear Regression, Random Forest, SVM, LSTM, and XGBoost revealed the superior accuracy and real-time adaptability of the proposed method. In addition to enhancing energy efficiency, the model reduced energy costs by 35%, maintained a 96% user comfort index, and increased renewable energy utilization to 40%. This study demonstrates the transformative potential of integrating PINNs, DT, and Blockchain technologies to optimize energy consumption in smart grids, paving the way for sustainable, secure, and efficient energy management systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Understanding the Benefit of Multitask Representation Learning in Decision Process</title>
<link>https://arxiv.org/abs/2503.00345</link>
<guid>https://arxiv.org/abs/2503.00345</guid>
<content:encoded><![CDATA[
<div> 关键词: 多任务表示学习(MRL), 强化学习(RL), 非线性表示, 在线学习, 迁移学习<br /><br />总结:<br />
本文关注多任务表示学习（MRL）在强化学习中的应用，尤其是在在线和迁移学习环境下的效率提升。尽管MRL广泛应用，但对其操作有效性的全面理论框架尚未完善。研究指出，以往分析主要假设代理具有预知的表示函数或使用线性类函数，而现实世界的复杂情况需要非线性函数，如神经网络。为此，文章填补了这一理论空白，将分析扩展到未知非线性表示，并提出了一种新的通用功能上界置信边界算法（GFUCB），使代理能够同时从多个上下文臂（或MDP）中学习并共享一个来自非线性函数类$\Phi$的表示函数$\phi$。通过形式化证明，这种方法的学习后悔上界优于单独学习多个任务的下界，首次展示了MRL在一般函数类中的有效性。此外，该框架还解释了在面临新但相关的任务时，表示对于迁移学习的贡献以及成功迁移的关键条件。实验结果进一步证实了这些理论发现。 <div>
arXiv:2503.00345v1 Announce Type: new 
Abstract: Multitask Representation Learning (MRL) has emerged as a prevalent technique to improve sample efficiency in Reinforcement Learning (RL). Empirical studies have found that training agents on multiple tasks simultaneously within online and transfer learning environments can greatly improve efficiency. Despite its popularity, a comprehensive theoretical framework that elucidates its operational efficacy remains incomplete. Prior analyses have predominantly assumed that agents either possess a pre-known representation function or utilize functions from a linear class, where both are impractical. The complexity of real-world applications typically requires the use of sophisticated, non-linear functions such as neural networks as representation function, which are not pre-existing but must be learned. Our work tries to fill the gap by extending the analysis to \textit{unknown non-linear} representations, giving a comprehensive analysis for its mechanism in online and transfer learning setting. We consider the setting that an agent simultaneously playing $M$ contextual bandits (or MDPs), developing a shared representation function $\phi$ from a non-linear function class $\Phi$ using our novel Generalized Functional Upper Confidence Bound algorithm (GFUCB). We formally prove that this approach yields a regret upper bound that outperforms the lower bound associated with learning $M$ separate tasks, marking the first demonstration of MRL's efficacy in a general function class. This framework also explains the contribution of representations to transfer learning when faced with new, yet related tasks, and identifies key conditions for successful transfer. Empirical experiments further corroborate our theoretical findings.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Structured Reasoning for Fairness: A Multi-Agent Approach to Bias Detection in Textual Data</title>
<link>https://arxiv.org/abs/2503.00355</link>
<guid>https://arxiv.org/abs/2503.00355</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、文本偏见、多代理框架、事实与观点区分、公平性

总结:<br />
本文提出了一个针对大型语言模型的多代理框架，旨在系统地识别并量化文本偏见，从而提升信任度。该框架能将每条陈述拆分为事实或观点，并赋予相应的偏见强度分数，并提供简洁的事实依据。在WikiNPOV数据集上的评估结果显示，该框架实现了84.9%的准确性，比零样本基线提高了13.0%，证实了在量化偏见强度前明确区分事实与观点的有效性。通过增强检测精度和提供可解释的解释，这种方法为促进现代语言模型的公平性和问责制奠定了基础。 <div>
arXiv:2503.00355v1 Announce Type: new 
Abstract: From disinformation spread by AI chatbots to AI recommendations that inadvertently reinforce stereotypes, textual bias poses a significant challenge to the trustworthiness of large language models (LLMs). In this paper, we propose a multi-agent framework that systematically identifies biases by disentangling each statement as fact or opinion, assigning a bias intensity score, and providing concise, factual justifications. Evaluated on 1,500 samples from the WikiNPOV dataset, the framework achieves 84.9% accuracy$\unicode{x2014}$an improvement of 13.0% over the zero-shot baseline$\unicode{x2014}$demonstrating the efficacy of explicitly modeling fact versus opinion prior to quantifying bias intensity. By combining enhanced detection accuracy with interpretable explanations, this approach sets a foundation for promoting fairness and accountability in modern language models.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Nucleolus Credit Assignment for Effective Coalitions in Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.00372</link>
<guid>https://arxiv.org/abs/2503.00372</guid>
<content:encoded><![CDATA[
<div> 关键词: 协作多智能体强化学习、信用分配、核仁型信用分配、合作博弈论、联盟形成

<br /><br />总结:
本文提出了一种基于合作博弈论中的核仁型信用分配方法，用于解决协作多智能体强化学习（MARL）中单一大联盟导致的次优性能问题。该方法使代理能够自主地划分为多个小联盟，有效地识别并完成复合任务中的子任务。研究中提出的核仁型Q学习可以对每个智能体进行公平的信用分配，而核仁型Q运算符为学习收敛和形成的稳定小联盟提供了理论保证与可解释性。通过在不同难度等级的Predator-Prey和StarCraft场景下的实验，这种方法展示了在MARL训练过程中有效多联盟的出现，相较于四个基线方法，在困难和超困难环境中表现出更快的学习速度以及更高的胜率和累积奖励，从而证明了其在需要有效子团队执行复杂复合任务方面的潜力。 <div>
arXiv:2503.00372v1 Announce Type: new 
Abstract: In cooperative multi-agent reinforcement learning (MARL), agents typically form a single grand coalition based on credit assignment to tackle a composite task, often resulting in suboptimal performance. This paper proposed a nucleolus-based credit assignment grounded in cooperative game theory, enabling the autonomous partitioning of agents into multiple small coalitions that can effectively identify and complete subtasks within a larger composite task. Specifically, our designed nucleolus Q-learning could assign fair credits to each agent, and the nucleolus Q-operator provides theoretical guarantees with interpretability for both learning convergence and the stability of the formed small coalitions. Through experiments on Predator-Prey and StarCraft scenarios across varying difficulty levels, our approach demonstrated the emergence of multiple effective coalitions during MARL training, leading to faster learning and superior performance in terms of win rate and cumulative rewards especially in hard and super-hard environments, compared to four baseline methods. Our nucleolus-based credit assignment showed the promise for complex composite tasks requiring effective subteams of agents.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smoothing Grounding and Reasoning for MLLM-Powered GUI Agents with Query-Oriented Pivot Tasks</title>
<link>https://arxiv.org/abs/2503.00401</link>
<guid>https://arxiv.org/abs/2503.00401</guid>
<content:encoded><![CDATA[
<div> 关键词：perception-enhanced pre-training、grounding techniques、GUI agents、query inference、resource-constrained scenarios

<br /><br />总结:
该文提出了一种针对资源受限场景下图形用户界面（GUI）代理的感知增强预训练新方法——查询推理（query inference）。研究发现，当前坐标导向的接地技术与动作导向的推理任务之间存在格式不匹配的问题，限制了接地技术在推理任务中的有效性。为解决这一挑战，文中提出了将GUI接地与推理相结合的桥梁——查询推理方法，它能从屏幕截图及其关联元素坐标中推断潜在用户查询，从而增强对坐标的理解并更好地贴近推理任务需求。实验结果显示，查询推理在同等规模的训练数据下优于先前的接地技术，并且仅使用不到0.1%的训练数据即可达到甚至超越大规模接地增强的OS-Atlas性能。此外，文章还探讨了推理格式的影响，并证明了将额外语义信息融入输入可以进一步提升推理性能。相关代码已公开发布在https://github.com/ZrW00/GUIPivot上。 <div>
arXiv:2503.00401v1 Announce Type: new 
Abstract: Perception-enhanced pre-training, particularly through grounding techniques, is widely adopted to enhance the performance of graphical user interface (GUI) agents. However, in resource-constrained scenarios, the format discrepancy between coordinate-oriented grounding and action-oriented reasoning limits the effectiveness of grounding for reasoning tasks. To address this challenge, we propose a query-oriented pivot approach called query inference, which serves as a bridge between GUI grounding and reasoning. By inferring potential user queries from a screenshot and its associated element coordinates, query inference improves the understanding of coordinates while aligning more closely with reasoning tasks. Experimental results show that query inference outperforms previous grounding techniques under the same training data scale. Notably, query inference achieves comparable or even better performance to large-scale grounding-enhanced OS-Atlas with less than 0.1% of training data. Furthermore, we explore the impact of reasoning formats and demonstrate that integrating additional semantic information into the input further boosts reasoning performance. The code is publicly available athttps://github.com/ZrW00/GUIPivot.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PodAgent: A Comprehensive Framework for Podcast Generation</title>
<link>https://arxiv.org/abs/2503.00455</link>
<guid>https://arxiv.org/abs/2503.00455</guid>
<content:encoded><![CDATA[
<div> 关键词: PodAgent、音频生成、多代理协作系统、语音池、LLM增强语音合成

总结:
本文提出了PodAgent，这是一个用于创建音频节目的综合框架。PodAgent通过设计Host-Guest-Writer多代理协作系统来生成富有信息性的主题讨论内容；构建了适合语音角色匹配的语音库；并利用LLM增强的语音合成功法生成具有表现力的对话式语音。鉴于缺乏播客类音频生成的标准评估标准，文章制定了全面的评估指南以有效评价模型性能。实验结果显示，PodAgent在话题讨论对话内容方面明显优于直接使用GPT-4生成，达到了87.4%的语音匹配准确率，并通过LLM指导的合成方法产生了更为生动的语音。项目演示页面：https://podcast-agent.github.io/demo/，源代码：https://github.com/yujxx/PodAgent。 <div>
arXiv:2503.00455v1 Announce Type: new 
Abstract: Existing Existing automatic audio generation methods struggle to generate podcast-like audio programs effectively. The key challenges lie in in-depth content generation, appropriate and expressive voice production. This paper proposed PodAgent, a comprehensive framework for creating audio programs. PodAgent 1) generates informative topic-discussion content by designing a Host-Guest-Writer multi-agent collaboration system, 2) builds a voice pool for suitable voice-role matching and 3) utilizes LLM-enhanced speech synthesis method to generate expressive conversational speech. Given the absence of standardized evaluation criteria for podcast-like audio generation, we developed comprehensive assessment guidelines to effectively evaluate the model's performance. Experimental results demonstrate PodAgent's effectiveness, significantly surpassing direct GPT-4 generation in topic-discussion dialogue content, achieving an 87.4% voice-matching accuracy, and producing more expressive speech through LLM-guided synthesis. Demo page: https://podcast-agent.github.io/demo/. Source code: https://github.com/yujxx/PodAgent.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Instructor-Worker Large Language Model System for Policy Recommendation: a Case Study on Air Quality Analysis of the January 2025 Los Angeles Wildfires</title>
<link>https://arxiv.org/abs/2503.00566</link>
<guid>https://arxiv.org/abs/2503.00566</guid>
<content:encoded><![CDATA[
<div> 关键词：Los Angeles wildfires、空气品质分析、多智能体大语言模型框架、云映射集成、数据驱动政策建议

<br />
总结：
本文研究了2025年洛杉矶野火期间的空气质量情况，利用之前提出的“数字孪生建筑”理念，对多智能体大语言模型框架和云映射集成技术进行了改进与应用。通过构建由Instructor代理和Worker代理组成的系统，该系统能根据用户指令自动从云端获取并分析大量数据，进而提供数据摘要。进一步地，测试了该系统在基于数据的政策推荐能力，具体为根据洛杉矶野火期间的空气质量状况提出健康建议。 <div>
arXiv:2503.00566v1 Announce Type: new 
Abstract: The Los Angeles wildfires of January 2025 caused more than 250 billion dollars in damage and lasted for nearly an entire month before containment. Following our previous work, the Digital Twin Building, we modify and leverage the multi-agent large language model framework as well as the cloud-mapping integration to study the air quality during the Los Angeles wildfires. Recent advances in large language models have allowed for out-of-the-box automated large-scale data analysis. We use a multi-agent large language system comprised of an Instructor agent and Worker agents. Upon receiving the users' instructions, the Instructor agent retrieves the data from the cloud platform and produces instruction prompts to the Worker agents. The Worker agents then analyze the data and provide summaries. The summaries are finally input back into the Instructor agent, which then provides the final data analysis. We test this system's capability for data-based policy recommendation by assessing our Instructor-Worker LLM system's health recommendations based on air quality during the Los Angeles wildfires.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discrete Codebook World Models for Continuous Control</title>
<link>https://arxiv.org/abs/2503.00653</link>
<guid>https://arxiv.org/abs/2503.00653</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习 (Reinforcement Learning), 世界模型 (World Models), 离散潜在空间 (Discrete Latent Spaces), 连续控制 (Continuous Control), DCWM (Discrete Codebook World Model)

总结:
本文研究了强化学习中的世界模型在连续控制任务中的应用。对比了离散和连续潜在空间在该领域的影响，指出离散码本编码对于连续控制更为有效的表示形式。文章提出了一个新的自监督世界模型——DCWM（离散码本世界模型），它具有离散和随机的潜在空间，其中潜在状态来自于码本中的代码。结合决策时间规划，作者构建了一个基于模型的强化学习算法——DC-MPC（离散码本书预测控制）。实验结果显示，DC-MPC在连续控制基准测试中与包括TD-MPC2和DreamerV3在内的最新先进算法表现相当。详情可访问项目网站www.aidanscannell.com/dcmpc。 <div>
arXiv:2503.00653v1 Announce Type: new 
Abstract: In reinforcement learning (RL), world models serve as internal simulators, enabling agents to predict environment dynamics and future outcomes in order to make informed decisions. While previous approaches leveraging discrete latent spaces, such as DreamerV3, have demonstrated strong performance in discrete action settings and visual control tasks, their comparative performance in state-based continuous control remains underexplored. In contrast, methods with continuous latent spaces, such as TD-MPC2, have shown notable success in state-based continuous control benchmarks. In this paper, we demonstrate that modeling discrete latent states has benefits over continuous latent states and that discrete codebook encodings are more effective representations for continuous control, compared to alternative encodings, such as one-hot and label-based encodings. Based on these insights, we introduce DCWM: Discrete Codebook World Model, a self-supervised world model with a discrete and stochastic latent space, where latent states are codes from a codebook. We combine DCWM with decision-time planning to get our model-based RL algorithm, named DC-MPC: Discrete Codebook Model Predictive Control, which performs competitively against recent state-of-the-art algorithms, including TD-MPC2 and DreamerV3, on continuous control benchmarks. See our project website www.aidanscannell.com/dcmpc.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Factorized Deep Q-Network for Cooperative Multi-Agent Reinforcement Learning in Victim Tagging</title>
<link>https://arxiv.org/abs/2503.00684</link>
<guid>https://arxiv.org/abs/2503.00684</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模伤亡事件(MCI)、受害者标记、多智能体、分布式启发式算法、深度强化学习(FDQN)

总结:
本文针对大规模伤亡事件(MCI)中快速而关键的受害者标记问题，提出了一个多智能体的数学模型以最小化标记时间。文中设计并评估了五种分布式启发式算法，这些算法代表了不同程度的情境不确定性，如全局或局部通信能力。此外，文章还研究了一种多智能体强化学习策略——因子分解深度Q网络(FDQN)，并与基准启发式算法进行了对比。模拟实验表明，在局部通信的启发式方法中，选择最近受害者并具有重新规划选项的方法更为高效。总体实验结果显示，FDQN在小规模场景下优于启发式算法，而在更复杂的场景中，启发式算法表现更优。这些实验揭示了深度强化学习在实际应用中的潜力边界以及关键见解。 <div>
arXiv:2503.00684v1 Announce Type: new 
Abstract: Mass casualty incidents (MCIs) are a growing concern, characterized by complexity and uncertainty that demand adaptive decision-making strategies. The victim tagging step in the emergency medical response must be completed quickly and is crucial for providing information to guide subsequent time-constrained response actions. In this paper, we present a mathematical formulation of multi-agent victim tagging to minimize the time it takes for responders to tag all victims. Five distributed heuristics are formulated and evaluated with simulation experiments. The heuristics considered are on-the go, practical solutions that represent varying levels of situational uncertainty in the form of global or local communication capabilities, showcasing practical constraints. We further investigate the performance of a multi-agent reinforcement learning (MARL) strategy, factorized deep Q-network (FDQN), to minimize victim tagging time as compared to baseline heuristics. Extensive simulations demonstrate that between the heuristics, methods with local communication are more efficient for adaptive victim tagging, specifically choosing the nearest victim with the option to replan. Analyzing all experiments, we find that our FDQN approach outperforms heuristics in smaller-scale scenarios, while heuristics excel in more complex scenarios. Our experiments contain diverse complexities that explore the upper limits of MARL capabilities for real-world applications and reveal key insights.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLMDR: LLM-Driven Deadlock Detection and Resolution in Multi-Agent Pathfinding</title>
<link>https://arxiv.org/abs/2503.00717</link>
<guid>https://arxiv.org/abs/2503.00717</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Pathfinding (MAPF)，学习基方法，死锁，LLMDR，大规模语言模型<br /><br />总结:
本文提出了一个针对多智能体路径规划（MAPF）问题的新方法——LLMDR，该方法旨在解决死锁并提升基于学习的MAPF模型性能。LLMDR将大型语言模型（LLMs）的推理能力与学习到的MAPF模型以及优先级规划相结合，能够检测并提供定制化的死锁解决方案。在具有不同数量代理人的标准MAPF基准地图上对LLMDR进行了评估，结果显示，结合LLMDR的基线模型在处理易发生死锁的复杂场景时，成功率有显著提高，显示出将LLMs整合进基于学习的MAPF方法中以改善其可扩展性的潜力。文章提供了LLMDR源代码的GitHub地址：https://github.com/ssbacc/llmdr-dhc。 <div>
arXiv:2503.00717v1 Announce Type: new 
Abstract: Multi-Agent Pathfinding (MAPF) is a core challenge in multi-agent systems. Existing learning-based MAPF methods often struggle with scalability, particularly when addressing complex scenarios that are prone to deadlocks. To address these challenges, we introduce LLMDR (LLM-Driven Deadlock Detection and Resolution), an approach designed to resolve deadlocks and improve the performance of learnt MAPF models. LLMDR integrates the inference capabilities of large language models (LLMs) with learnt MAPF models and prioritized planning, enabling it to detect deadlocks and provide customized resolution strategies. We evaluate LLMDR on standard MAPF benchmark maps with varying agent numbers, measuring its performance when combined with several base models. The results demonstrate that LLMDR improves the performance of learnt MAPF models, particularly in deadlock-prone scenarios, with notable improvements in success rates. These findings show the potential of integrating LLMs to improve the scalability of learning-based MAPF methods.
  The source code for LLMDR is available at: https://github.com/ssbacc/llmdr-dhc
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unmasking Digital Falsehoods: A Comparative Analysis of LLM-Based Misinformation Detection Strategies</title>
<link>https://arxiv.org/abs/2503.00724</link>
<guid>https://arxiv.org/abs/2503.00724</guid>
<content:encoded><![CDATA[
<div> 关键词：misinformation、large language models (LLMs)、text-based、multimodal、agentic approaches

<br /><br />总结:
该文探讨了社交媒体上误信息传播的问题，并比较了基于大语言模型（如GPT-4和LLaMA2）的不同检测方法，包括文本基础、多模态及代理方法在公共卫生、政治和财经等领域中识别误信息的效果。文章评估了微调模型、零样本学习以及系统性事实核查机制的有效性，并关注了模型的可扩展性、泛化能力和解释性，同时指出了诸如幻觉生成、针对误信息的对抗性攻击以及计算资源等挑战。研究发现，结合结构化验证协议与自适应学习技术的混合方法对于提高检测准确性和解释性至关重要。最后，论文提出了未来工作的潜在方向，包括实时误信息追踪、联邦学习和跨平台检测模型。 <div>
arXiv:2503.00724v1 Announce Type: new 
Abstract: The proliferation of misinformation on social media has raised significant societal concerns, necessitating robust detection mechanisms. Large Language Models such as GPT-4 and LLaMA2 have been envisioned as possible tools for detecting misinformation based on their advanced natural language understanding and reasoning capabilities. This paper conducts a comparison of LLM-based approaches to detecting misinformation between text-based, multimodal, and agentic approaches. We evaluate the effectiveness of fine-tuned models, zero-shot learning, and systematic fact-checking mechanisms in detecting misinformation across different topic domains like public health, politics, and finance. We also discuss scalability, generalizability, and explainability of the models and recognize key challenges such as hallucination, adversarial attacks on misinformation, and computational resources. Our findings point towards the importance of hybrid approaches that pair structured verification protocols with adaptive learning techniques to enhance detection accuracy and explainability. The paper closes by suggesting potential avenues of future work, including real-time tracking of misinformation, federated learning, and cross-platform detection models.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAPID: Efficient Retrieval-Augmented Long Text Generation with Writing Planning and Information Discovery</title>
<link>https://arxiv.org/abs/2503.00751</link>
<guid>https://arxiv.org/abs/2503.00751</guid>
<content:encoded><![CDATA[
<div> 关键词：生成、知识密集型文本、长文本、模型、RAPID

总结:
<br />
本文提出了一种名为RAPID的高效检索增强型长文本生成框架，旨在解决大型语言模型生成百科类等知识密集型和综合长文本时面临的挑战。针对现有方法存在的幻觉问题、主题不连贯以及延迟高等问题，RAPID包含了三个主要模块：(1) 使用检索增强生成初步大纲以减少幻觉；(2) 属性约束搜索实现有效信息发现；(3) 计划引导的文章生成以提升连贯性。通过在新编译的FreshWiki-2024基准数据集上的大量实验，显示RAPID在各类评价指标（如长文本生成、大纲质量、延迟等）上显著优于现有最优方法。该工作为自动化长文本生成中的挑战提供了一个稳健且高效的解决方案。 <div>
arXiv:2503.00751v1 Announce Type: new 
Abstract: Generating knowledge-intensive and comprehensive long texts, such as encyclopedia articles, remains significant challenges for Large Language Models. It requires not only the precise integration of facts but also the maintenance of thematic coherence throughout the article. Existing methods, such as direct generation and multi-agent discussion, often struggle with issues like hallucinations, topic incoherence, and significant latency. To address these challenges, we propose RAPID, an efficient retrieval-augmented long text generation framework. RAPID consists of three main modules: (1) Retrieval-augmented preliminary outline generation to reduce hallucinations, (2) Attribute-constrained search for efficient information discovery, (3) Plan-guided article generation for enhanced coherence. Extensive experiments on our newly compiled benchmark dataset, FreshWiki-2024, demonstrate that RAPID significantly outperforms state-of-the-art methods across a wide range of evaluation metrics (e.g. long-text generation, outline quality, latency, etc). Our work provides a robust and efficient solution to the challenges of automated long-text generation.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TRACE: A Self-Improving Framework for Robot Behavior Forecasting with Vision-Language Models</title>
<link>https://arxiv.org/abs/2503.00761</link>
<guid>https://arxiv.org/abs/2503.00761</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Models (VLMs)，行为预测，边缘情况，迭代探索，TRACE

总结:<br />
本文提出了一种名为TRACE的新颖推理框架，用于增强基于Vision-Language Models (VLMs)的行为预测能力。当对目标反应性代理的观察数据稀疏或间断时，预测其短期行为具有挑战性。TRACE利用迭代和反事实探索的方法，通过生成树状思维并结合领域感知反馈，多轮次地细化行为假设。首先，VLM 提出候选轨迹；随后，一个反事实批评模块根据部分观测数据建议边缘情况变化，促使 VLM 在下一轮中扩展或调整其假设。这一过程形成了一个自我改进的循环，使得 VLM 逐步从以往轮次中内化边缘案例，系统地揭示了不仅包括典型行为，也包括罕见或临界操作在内的多种可能行为。实验表明，与标准 VLM 驱动和纯模型基线相比，TRACE 方法能在传感器数据极稀少的情况下，更准确、全面地预测目标代理的行为。研究成果已在地面车辆仿真及真实世界的海洋自主水面航行器上得到验证。相关评估视频和代码可在trace-robotics.github.io获取。 <div>
arXiv:2503.00761v1 Announce Type: new 
Abstract: Predicting the near-term behavior of a reactive agent is crucial in many robotic scenarios, yet remains challenging when observations of that agent are sparse or intermittent. Vision-Language Models (VLMs) offer a promising avenue by integrating textual domain knowledge with visual cues, but their one-shot predictions often miss important edge cases and unusual maneuvers. Our key insight is that iterative, counterfactual exploration--where a dedicated module probes each proposed behavior hypothesis, explicitly represented as a plausible trajectory, for overlooked possibilities--can significantly enhance VLM-based behavioral forecasting. We present TRACE (Tree-of-thought Reasoning And Counterfactual Exploration), an inference framework that couples tree-of-thought generation with domain-aware feedback to refine behavior hypotheses over multiple rounds. Concretely, a VLM first proposes candidate trajectories for the agent; a counterfactual critic then suggests edge-case variations consistent with partial observations, prompting the VLM to expand or adjust its hypotheses in the next iteration. This creates a self-improving cycle where the VLM progressively internalizes edge cases from previous rounds, systematically uncovering not only typical behaviors but also rare or borderline maneuvers, ultimately yielding more robust trajectory predictions from minimal sensor data. We validate TRACE on both ground-vehicle simulations and real-world marine autonomous surface vehicles. Experimental results show that our method consistently outperforms standard VLM-driven and purely model-based baselines, capturing a broader range of feasible agent behaviors despite sparse sensing. Evaluation videos and code are available at trace-robotics.github.io.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evaluating Personalized Tool-Augmented LLMs from the Perspectives of Personalization and Proactivity</title>
<link>https://arxiv.org/abs/2503.00771</link>
<guid>https://arxiv.org/abs/2503.00771</guid>
<content:encoded><![CDATA[
<div> 关键词: 个性化工具利用、大型语言模型、基准测试、评价方法、关键点标注

总结:
本文介绍了针对大型语言模型个性化工具调用的新型基准测试——ETAPP。该基准涵盖了多样化的用户画像并提供了包含800个测试案例的综合数据集。为提高评估准确性，文中提出了一种基于关键点的LLM评价方法，通过人工标注每个测试案例的关键点，减少LLM判断系统的偏见。此外，文章还对优秀LLM进行了深入评估与分析，并探讨了不同工具调用策略对LLM个性化性能的影响以及微调任务中的效果。最后验证了偏好设置和关键点评价法的有效性。这些发现为改进个性化LLM代理提供了有益见解。相关代码已开源，可在https://github.com/hypasd-art/ETAPP获取。 <div>
arXiv:2503.00771v1 Announce Type: new 
Abstract: Personalized tool utilization is essential for aligning large language models (LLMs) with user preference in interaction scenarios with various tools. However, most of the current benchmarks primarily focus on either personalization of text generation or direct tool-utilizing, without considering both. In this work, we introduce a novel benchmark ETAPP for evaluating personalized tool invocation, establishing a sandbox environment, and a comprehensive dataset of 800 testing cases covering diverse user profiles. To improve the accuracy of our evaluation, we propose a key-point-based LLM evaluation method, mitigating biases in the LLM-as-a-judge system by manually annotating key points for each test case and providing them to LLM as the reference. Additionally, we evaluate the excellent LLMs and provide an in-depth analysis. Furthermore, we investigate the impact of different tool-invoking strategies on LLMs' personalization performance and the effects of fine-tuning in our task. The effectiveness of our preference-setting and key-point-based evaluation method is also validated. Our findings offer insights into improving personalized LLM agents. Our Code is available at https://github.com/hypasd-art/ETAPP.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Law Reasoning Benchmark for LLM with Tree-Organized Structures including Factum Probandum, Evidence and Experiences</title>
<link>https://arxiv.org/abs/2503.00841</link>
<guid>https://arxiv.org/abs/2503.00841</guid>
<content:encoded><![CDATA[
<div> 关键词: 法律推理、透明化、事实证明、证据、人工智能辅助法律决策<br /><br />总结:
本文提出了一个以透明化的法律推理框架，强调了其在公平裁决中的重要性，该框架富集了层次化的事实证明、证据和隐含经验，旨在促进公众审查并避免偏见。文章引入了一个新的任务，即根据文本案例描述生成一个支撑最终决定的层次化结构。同时，作者构建了首个针对此任务的众包数据集，为全面评估提供了可能。此外，文中还提出了一种代理框架，它利用一系列全面的法律分析工具来解决这一挑战性任务。这个基准研究为实现“智能法庭”中透明且负责任的人工智能辅助法律推理铺平了道路。 <div>
arXiv:2503.00841v1 Announce Type: new 
Abstract: While progress has been made in legal applications, law reasoning, crucial for fair adjudication, remains unexplored. We propose a transparent law reasoning schema enriched with hierarchical factum probandum, evidence, and implicit experience, enabling public scrutiny and preventing bias. Inspired by this schema, we introduce the challenging task, which takes a textual case description and outputs a hierarchical structure justifying the final decision. We also create the first crowd-sourced dataset for this task, enabling comprehensive evaluation. Simultaneously, we propose an agent framework that employs a comprehensive suite of legal analysis tools to address the challenge task. This benchmark paves the way for transparent and accountable AI-assisted law reasoning in the ``Intelligent Court''.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NeSyC: A Neuro-symbolic Continual Learner For Complex Embodied Tasks In Open Domains</title>
<link>https://arxiv.org/abs/2503.00870</link>
<guid>https://arxiv.org/abs/2503.00870</guid>
<content:encoded><![CDATA[
<div> 关键词：神经符号法、行动性知识、环境泛化、NeSyC框架、大语言模型

总结:<br />
本文探讨了神经符号方法在通用环境下使具身智能体更有效地处理复杂任务中的应用。针对具身智能体难以在多样化的环境中对知识进行泛化的挑战，文章提出了一个名为NeSyC的新颖神经符号持续学习框架，该框架模拟假设演绎模型，通过结合使用大型语言模型（LLMs）和符号工具，从有限经验中不断提出并验证知识。NeSyC内部设计了一种对比增强泛化改进方案，迭代生成假设并通过符号工具进行对比验证，强化合理行为的合理性判断，减少不合理行为的推断。同时，它还采用基于记忆的监控机制，有效检测动作错误并触发跨域的知识精炼过程。实验结果显示，在包括ALFWorld、VirtualHome、Minecraft、RLBench以及真实世界机器人场景在内的多种具身任务基准测试中，NeSyC在解决开放领域环境下的复杂任务方面表现出高度的有效性。 <div>
arXiv:2503.00870v1 Announce Type: new 
Abstract: We explore neuro-symbolic approaches to generalize actionable knowledge, enabling embodied agents to tackle complex tasks more effectively in open-domain environments. A key challenge for embodied agents is the generalization of knowledge across diverse environments and situations, as limited experiences often confine them to their prior knowledge. To address this issue, we introduce a novel framework, NeSyC, a neuro-symbolic continual learner that emulates the hypothetico-deductive model by continually formulating and validating knowledge from limited experiences through the combined use of Large Language Models (LLMs) and symbolic tools. Specifically, we devise a contrastive generality improvement scheme within NeSyC, which iteratively generates hypotheses using LLMs and conducts contrastive validation via symbolic tools. This scheme reinforces the justification for admissible actions while minimizing the inference of inadmissible ones. Additionally, we incorporate a memory-based monitoring scheme that efficiently detects action errors and triggers the knowledge refinement process across domains. Experiments conducted on diverse embodied task benchmarks-including ALFWorld, VirtualHome, Minecraft, RLBench, and a real-world robotic scenario-demonstrate that NeSyC is highly effective in solving complex embodied tasks across a range of open-domain environments.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Efficient and Uncertainty-aware Reinforcement Learning Framework for Quality Assurance in Extrusion Additive Manufacturing</title>
<link>https://arxiv.org/abs/2503.00971</link>
<guid>https://arxiv.org/abs/2503.00971</guid>
<content:encoded><![CDATA[
<div> 关键词：缺陷、增材制造、AI驱动、不确定性管理、强化学习控制器

<br /><br />总结:
本文针对增材制造过程中的常见缺陷问题，提出了一种结合视觉系统和强化学习控制器的动态调整方案。该方案利用一种智能代理实时优化流速和温度设定点，从而提升工艺控制效果并解决训练效率和不确定性管理瓶颈。通过将基于视觉的不确定性量化模块与深度Q学习控制器集成，使用概率分布描述打印段，使决策过程具有适应性。控制器在模拟环境中学习最优动作，对环境变化表现出适当犹豫。采用异步操作和逐步收紧的椭圆奖励塑造策略，实现对工艺参数耦合效应的稳健、自适应控制。实现在零样本学习下部署，该框架成功填补了模拟到现实的转换差距，可靠地纠正了轻度和重度的欠充填和过充填现象。此外，这一可扩展的框架为各种增材制造工艺的AI驱动质量保证提供了实用解决方案。 <div>
arXiv:2503.00971v1 Announce Type: new 
Abstract: Defects in extrusion additive manufacturing remain common despite its prevalent use. While numerous AI-driven approaches have been proposed to improve quality assurance, the inherently dynamic nature of the printing process poses persistent challenges. Regardless of how comprehensive the training dataset is, out-of-distribution data remains inevitable. Consequently, deterministic models often struggle to maintain robustness and, in some cases, fail entirely when deployed in new or slightly altered printing environments. This work introduces an agent that dynamically adjusts flow rate and temperature setpoints in real time, optimizing process control while addressing bottlenecks in training efficiency and uncertainty management. It integrates a vision-based uncertainty quantification module with a reinforcement learning controller, using probabilistic distributions to describe printing segments. While the underlying networks are deterministic, these evolving distributions introduce adaptability into the decision-making process. The vision system classifies material extrusion with a certain level of precision, generating corresponding distributions. A deep Q-learning controller interacts with a simulated environment calibrated to the vision system precision, allowing the agent to learn optimal actions while demonstrating appropriate hesitation when necessary. By executing asynchronous actions and applying progressively tightened elliptical reward shaping, the controller develops robust, adaptive control strategies that account for the coupling effects between process parameters. When deployed with zero-shot learning, the agent effectively bridges the sim-to-real gap, correcting mild and severe under- and over-extrusion reliably. Beyond extrusion additive manufacturing, this scalable framework enables practical AI-driven quality assurance across various additive manufacturing processes.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Real-World Deployment and Assessment of a Multi-Agent Reinforcement Learning-Based Variable Speed Limit Control System</title>
<link>https://arxiv.org/abs/2503.01017</link>
<guid>https://arxiv.org/abs/2503.01017</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习（MARL）、变速度限制（VSL）、田纳西州纳什维尔、Interstate 24（I-24）、安全性能

总结:

本文报道了首个基于多智能体强化学习（MARL）的变速度限制（VSL）控制系统在田纳西州纳什维尔附近的Interstate 24（I-24）路段的实际部署。系统自2024年3月8日启动以来，已在六个月内对约2800万次行程做出了约3500万个决策。研究者设计了一个从在交通模拟器中训练MARL代理到实际部署涵盖67个VSL控制器的完整流程，并采用了无效动作屏蔽机制和多重安全保障措施以确保满足现实世界约束。MARL基础实施的运行效率高达98%，其余时间由安全防护措施覆盖其决定。与先前部署在I-24上的非RL VSL基准算法相比，MARL基测控系统的性能更优，提高了提前警告驾驶员前方缓慢交通情况的准确度达14%，减少了应对非周期性拥堵的响应延迟达75%。初步数据显示，VSL控制系统使得事故率下降了26%，二次事故率降低了50%。相关开源代码已发布于https://github.com/Lab-Work/marl-vsl-controller。 <div>
arXiv:2503.01017v1 Announce Type: new 
Abstract: This article presents the first field deployment of a multi-agent reinforcement learning (MARL) based variable speed limit (VSL) control system on Interstate 24 (I-24) near Nashville, Tennessee. We design and demonstrate a full pipeline from training MARL agents in a traffic simulator to a field deployment on a 17-mile segment of I-24 encompassing 67 VSL controllers. The system was launched on March 8th, 2024, and has made approximately 35 million decisions on 28 million trips in six months of operation. We apply an invalid action masking mechanism and several safety guards to ensure real-world constraints. The MARL-based implementation operates up to 98% of the time, with the safety guards overriding the MARL decisions for the remaining time. We evaluate the performance of the MARL-based algorithm in comparison to a previously deployed non-RL VSL benchmark algorithm on I-24. Results show that the MARL-based VSL control system achieves a superior performance. The accuracy of correctly warning drivers about slowing traffic ahead is improved by 14% and the response delay to non-recurrent congestion is reduced by 75%. The preliminary data shows that the VSL control system has reduced the crash rate by 26% and the secondary crash rate by 50%. We open-sourced the deployed MARL-based VSL algorithm at https://github.com/Lab-Work/marl-vsl-controller.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SFO: Piloting VLM Feedback for Offline RL</title>
<link>https://arxiv.org/abs/2503.01062</link>
<guid>https://arxiv.org/abs/2503.01062</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Models (VLMs)，强化学习(RL)，Reinforcement Learning from AI Feedback (RLAIF)，线下RL，子轨迹过滤优化

总结:<br />
本文探讨了如何将视觉语言模型（VLMs）提供的反馈有效整合到强化学习（RL）的学习过程中，特别是在没有互联网规模控制数据的情况下。文章提出了一种名为“子轨迹过滤优化”的方法，适用于离线RL。研究发现了三个关键点：1）在离线RL中，轨迹长度至关重要，使用完整轨迹进行偏好学习会加剧拼接问题，因此需要利用子轨迹；2）即使在马尔可夫环境中，也需要非马尔可夫的奖励信号（来自图像序列），因为VLM无法解释控制动作，而需依赖于随时间变化的视觉线索；3）简单但有效的过滤并加权行为克隆方法优于基于人类反馈的复杂强化学习方法。为此，文章提出了子轨迹过滤行为克隆法，该方法利用VLM对子轨迹的反馈，并结合一种去除失败前子轨迹的回顾性过滤机制，以提高稳健性和防止训练不稳定性。实验在玩具控制域上初步验证了这种方法的有效性。 <div>
arXiv:2503.01062v1 Announce Type: new 
Abstract: While internet-scale image and textual data have enabled strong generalization in Vision-Language Models (VLMs), the absence of internet-scale control data has impeded the development of similar generalization in standard reinforcement learning (RL) agents. Although VLMs are fundamentally limited in their ability to solve control tasks due to their lack of action-conditioned training data, their capacity for image understanding allows them to provide valuable feedback in RL tasks by recognizing successful outcomes. A key challenge in Reinforcement Learning from AI Feedback (RLAIF) is determining how best to integrate VLM-derived signals into the learning process. We explore this question in the context of offline RL and introduce a class of methods called sub-trajectory filtered optimization. We identify three key insights. First, trajectory length plays a crucial role in offline RL, as full-trajectory preference learning exacerbates the stitching problem, necessitating the use of sub-trajectories. Second, even in Markovian environments, a non-Markovian reward signal from a sequence of images is required to assess trajectory improvement, as VLMs do not interpret control actions and must rely on visual cues over time. Third, a simple yet effective approach--filtered and weighted behavior cloning--consistently outperforms more complex reinforcement learning from human feedback-based methods. We propose sub-trajectory filtered behavior cloning, a method that leverages VLM feedback on sub-trajectories while incorporating a retrospective filtering mechanism that removes sub-trajectories preceding failures to improve robustness and prevent turbulence. This study is preliminary; we provide initial evidence through evaluations on a toy control domain. Please enjoy our airport puns.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graph-Based Dynamics and Network Control of a Single Articulated Robotic System</title>
<link>https://arxiv.org/abs/2503.01101</link>
<guid>https://arxiv.org/abs/2503.01101</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、图基动态控制、机器人 swarm、单关节机器人系统(SAR)、分散式网络控制

总结:<br />
本文探讨了将基于图的多智能体系统控制理论应用于一类称为单关节机器人系统(SAR)的研究，其中每个链接被视为独立的智能体，而连接链接的约束则视为边。通过运用拉格朗日动力学的一阶原理，文章推导出了描述SAR系统动态行为的带权重图和边拉普拉斯矩阵的微分方程。文中还提出了一个充分条件，当满足此条件时，制约力与控制输入相互独立，从而引出了一种适用于调节此类机器人相对配置的分散式领导-跟随网络控制系统。仿真结果验证了所提控制方法的有效性。 <div>
arXiv:2503.01101v1 Announce Type: new 
Abstract: Extensive research on graph-based dynamics and control of multi-agent systems has successfully demonstrated control of robotic swarms, where each robot is perceived as an independent agent virtually connected by a network topology. The strong advantage of the network control structure lies in the decentralized nature of the control action, which only requires the knowledge of virtually connected agents. In this paper, we seek to expand the ideas of virtual network constraints to physical constraints on a class of tree-structured robots which we denote as single articulated robotic (SAR) systems. In our proposed framework, each link can be viewed as an agent, and each holonomic constraint connecting links serves as an edge. By following the first principles of Lagrangian dynamics, we derive a consensus-like matrix-differential equation with weighted graph and edge Laplacians for the dynamics of a SAR system. The sufficient condition for the holonomic constraint forces becoming independent to the control inputs is derived. This condition leads to a decentralized leader-follower network control framework for regulating the relative configuration of the robot. Simulation results demonstrate the effectiveness of the proposed control method.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stability Analysis and Intervention Strategies on a Coupled SIS Epidemic Model with Polar Opinion Dynamics</title>
<link>https://arxiv.org/abs/2503.01285</link>
<guid>https://arxiv.org/abs/2503.01285</guid>
<content:encoded><![CDATA[
<div> 关键词: 网络社区、传染病传播、公众意见动态、SIS模型、stubborn agents<br /><br />总结:
本文研究了网络化社区中传染疾病的传播，通过整合传染病传输与公众意见动态，提出了一种新的离散时间网络化SIS（易感-感染-易感）疾病模型，该模型考虑了带有偏见观点的固执代理人的影响。模型揭示了感知到的和实际疫情严重性之间的相互作用，为理解社交互联环境中传染病动力学提供了见解。文章引入了SIS-意见再生数来评估疫情严重程度，并分析了疾病根除及流行病态平衡全球稳定性的条件。此外，文中还探讨了基于意见的干预策略，为政策制定者设计有效的预防措施提供了框架。数值例子进一步阐释了理论发现和模型的实际意义。 <div>
arXiv:2503.01285v1 Announce Type: new 
Abstract: This paper investigates the spread of infectious diseases within a networked community by integrating epidemic transmission and public opinion dynamics. We propose a novel discrete-time networked SIS (Susceptible-Infectious-Susceptible) epidemic model coupled with opinion dynamics that includes stubborn agents with biased views. The model captures the interplay between perceived and actual epidemic severity, offering insights into epidemic dynamics in socially interconnected environments. We introduce the SIS-opinion reproduction number to assess epidemic severity and analyze conditions for disease eradication and the global stability of endemic equilibria. Additionally, we explore opinion-based intervention strategies, providing a framework for policymakers to design effective prevention measures. Numerical examples are provided to illustrate our theoretical findings and the model's practical implications.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stone Soup Multi-Target Tracking Feature Extraction For Autonomous Search And Track In Deep Reinforcement Learning Environment</title>
<link>https://arxiv.org/abs/2503.01293</link>
<guid>https://arxiv.org/abs/2503.01293</guid>
<content:encoded><![CDATA[
<div> 关键词：管理、感知资源、军事航空资产、深度强化学习（DRL）、Stone Soup跟踪框架

总结:
本文提出了一种利用深度强化学习训练传感器管理任务的方法。该方法采用Stone Soup跟踪框架作为特征提取器来训练智能体。文章展示了一个将Stone Soup追踪组件嵌入Gymnasium环境中的通用框架，从而实现快速和可配置的追踪器部署，用于使用Stable Baselines3进行强化学习训练。在搜索和跟踪空域任务中，这种方法被演示出来，其中智能体被训练来利用由Stone Soup生成的跟踪列表搜索和跟踪一片空域。通过使用三种神经网络架构的示例实施，证明了在Gymnasium和Stone Soup环境中训练的RL智能体可以优于简单的传感器搜索和跟踪策略。 <div>
arXiv:2503.01293v1 Announce Type: new 
Abstract: Management of sensing resources is a non-trivial problem for future military air assets with future systems deploying heterogeneous sensors to generate information of the battlespace. Machine learning techniques including deep reinforcement learning (DRL) have been identified as promising approaches, but require high-fidelity training environments and feature extractors to generate information for the agent. This paper presents a deep reinforcement learning training approach, utilising the Stone Soup tracking framework as a feature extractor to train an agent for a sensor management task. A general framework for embedding Stone Soup tracker components within a Gymnasium environment is presented, enabling fast and configurable tracker deployments for RL training using Stable Baselines3. The approach is demonstrated in a sensor management task where an agent is trained to search and track a region of airspace utilising track lists generated from Stone Soup trackers. A sample implementation using three neural network architectures in a search-and-track scenario demonstrates the approach and shows that RL agents can outperform simple sensor search and track policies when trained within the Gymnasium and Stone Soup environment.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Answer, Refuse, or Guess? Investigating Risk-Aware Decision Making in Language Models</title>
<link>https://arxiv.org/abs/2503.01332</link>
<guid>https://arxiv.org/abs/2503.01332</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、风险意识、决策制定、拒绝策略、技能分解

总结:
本文关注了语言模型在安全可靠的决策过程中何时回答或拒绝问题的重要性。文章指出现有LMs在针对不同风险水平适应性决策方面的不足，并对风险感知决策任务进行了形式化定义。作者揭示了现有领先LMs（包括常规和推理模型）存在的关键弱点，提出通过技能分解解决方案来缓解这些问题。实验发现，即使是最先进的LM也需要明确的提示链处理才能有效地完成该任务，这表明要实现真正自主的决策代理仍存在诸多挑战。 <div>
arXiv:2503.01332v1 Announce Type: new 
Abstract: Knowing when to answer or refuse is crucial for safe and reliable decision-making language agents. Although prior work has introduced refusal strategies to boost LMs' reliability, how these models adapt their decisions to different risk levels remains underexplored. We formalize the task of risk-aware decision-making, expose critical weaknesses in existing LMs, and propose skill-decomposition solutions to mitigate them. Our findings show that even cutting-edge LMs--both regular and reasoning models--still require explicit prompt chaining to handle the task effectively, revealing the challenges that must be overcome to achieve truly autonomous decision-making agents.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RemiHaven: Integrating "In-Town" and "Out-of-Town" Peers to Provide Personalized Reminiscence Support for Older Drifters</title>
<link>https://arxiv.org/abs/2503.01358</link>
<guid>https://arxiv.org/abs/2503.01358</guid>
<content:encoded><![CDATA[
<div> 关键词：老年人迁移、孤独感、抑郁情绪、回忆疗法、RemiHaven

<br />
总结:
随着社会流动性增强和老龄化社会的到来，中国出现了越来越多迁移到新城市的“老年漂泊者”。他们由于社交联系较少和文化适应挑战，面临着孤独感和抑郁等负面情绪。为了解决这一问题，研究者设计了RemiHaven，这是一个基于两阶段形成性研究的个性化回忆支持工具。RemiHaven结合了“同城”和“异城”的同伴代理，利用多模态大型语言模型（MLLMs）增强回忆过程中的个性化、参与度和情感共鸣。评估显示，RemiHaven在支持回忆方面具有优势，同时也指出了潜在的挑战。研究最后对未来回忆支持工具的设计提出了见解。 <div>
arXiv:2503.01358v1 Announce Type: new 
Abstract: With increasing social mobility and an aging society, more older adults in China are migrating to new cities, known as "older drifters." Due to fewer social connections and cultural adaptation challenges, they face negative emotions such as loneliness and depression. While reminiscence-based interventions have been used to improve older adults' psychological well-being, challenges such as the lack of tangible materials and limited social resources constrain the feasibility of traditional reminiscence approaches for older drifters. To address this challenge, we designed RemiHaven, a personalized reminiscence support tool based on a two-phase formative study. It integrates "In-Town" and "Out-of-Town" peer agents to enhance personalization, engagement, and emotional resonance in the reminiscence process, powered by Multimodal Large Language Models (MLLMs). Our evaluations show RemiHaven's strengths in supporting reminiscence while identifying potential challenges. We conclude by offering insights for the future design of reminiscence support tools for older migrants.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Complexity of Extending Fair Allocations of Indivisible Goods</title>
<link>https://arxiv.org/abs/2503.01368</link>
<guid>https://arxiv.org/abs/2503.01368</guid>
<content:encoded><![CDATA[
<div> 关键词：envy-free, indivisible items, extension setting, fixed-parameter algorithms, complexity-theoretic classification

<br /><br />总结:
本文首次探讨了在扩展设置下计算不可分割物品的公平分配问题，即部分分配已固定，剩余物品需要进行公平分配。鉴于该问题已知的NP难度，研究者们针对存在少量不同类型代理人或物品的情况，寻求并设计出了固定参数算法。同时，他们也证明了这些积极结果无法一般化到更通用的场景中的下界。最后，文章指出与从头开始计算分配相比，在扩展设置下，对于较为宽松的EFX分配是否存在这一非算法性问题可以得到彻底解决。 <div>
arXiv:2503.01368v1 Announce Type: new 
Abstract: We initiate the study of computing envy-free allocations of indivisible items in the extension setting, i.e., when some part of the allocation is fixed and the task is to allocate the remaining items. Given the known NP-hardness of the problem, we investigate whether -- and under which conditions -- one can obtain fixed-parameter algorithms for computing a solution in settings where most of the allocation is already fixed. Our results provide a broad complexity-theoretic classification of the problem which includes: (a) fixed-parameter algorithms tailored to settings with few distinct types of agents or items; (b) lower bounds which exclude the generalization of these positive results to more general settings. We conclude by showing that -- unlike when computing allocations from scratch -- the non-algorithmic question of whether more relaxed EFX allocations exist can be completely resolved in the extension setting.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Eau De $Q$-Network: Adaptive Distillation of Neural Networks in Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.01437</link>
<guid>https://arxiv.org/abs/2503.01437</guid>
<content:encoded><![CDATA[
<div> 关键词：sparse deep reinforcement learning, dense-to-sparse, EauDeQN, sparsity schedule, performance

总结:<br />
本文提出了一个新的深度强化学习稀疏化算法——EauDeQN，旨在解决现有稀疏化方法中依赖于手工设计的不与学习进度同步的稀疏日程以及需精细调整的最终稀疏度超参数问题。EauDeQN采用多个具有不同稀疏水平的在线网络，每个网络均从共享的目标网络进行训练。在每次目标更新时，选择损失最小的在线网络作为下一个目标网络，而其他网络则被所选网络的剪枝版本替换。实验结果显示，EauDeQN能够在保持高性能的同时达到高稀疏度水平，其在Atari 2600基准和MuJoCo物理模拟器上得到了验证。 <div>
arXiv:2503.01437v1 Announce Type: new 
Abstract: Recent works have successfully demonstrated that sparse deep reinforcement learning agents can be competitive against their dense counterparts. This opens up opportunities for reinforcement learning applications in fields where inference time and memory requirements are cost-sensitive or limited by hardware. Until now, dense-to-sparse methods have relied on hand-designed sparsity schedules that are not synchronized with the agent's learning pace. Crucially, the final sparsity level is chosen as a hyperparameter, which requires careful tuning as setting it too high might lead to poor performances. In this work, we address these shortcomings by crafting a dense-to-sparse algorithm that we name Eau De $Q$-Network (EauDeQN). To increase sparsity at the agent's learning pace, we consider multiple online networks with different sparsity levels, where each online network is trained from a shared target network. At each target update, the online network with the smallest loss is chosen as the next target network, while the other networks are replaced by a pruned version of the chosen network. We evaluate the proposed approach on the Atari $2600$ benchmark and the MuJoCo physics simulator, showing that EauDeQN reaches high sparsity levels while keeping performances high.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trajectory-Class-Aware Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.01440</link>
<guid>https://arxiv.org/abs/2503.01440</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、泛化能力、轨迹类别意识、多任务、TRAMA

总结:
本文提出了一种针对多智能体强化学习中多任务挑战的新方法——TRajectory-class-Aware Multi-Agent reinforcement learning（TRAMA）。该方法旨在通过单一训练过程使智能体能够灵活应对需要不同联合策略或协调的多种任务。TRAMA主要包含三个目标：(1)构建量化潜空间生成反映轨迹之间关键相似性的轨迹嵌入；(2)使用这些轨迹嵌入进行轨迹聚类；(3)建立轨迹类别意识的策略。其中，(3)包括设计了一个执行轨迹类别预测的代理智能体以及针对每个轨迹类别的轨迹类别表示模型。每个智能体结合其局部观测信息和轨迹类别表示来采取行动，实现任务感知的执行。实验结果表明，TRAMA在包括基于StarCraft II构建的多任务问题等各类任务上相比于当前最先进的基线方法有进一步的性能提升。 <div>
arXiv:2503.01440v1 Announce Type: new 
Abstract: In the context of multi-agent reinforcement learning, generalization is a challenge to solve various tasks that may require different joint policies or coordination without relying on policies specialized for each task. We refer to this type of problem as a multi-task, and we train agents to be versatile in this multi-task setting through a single training process. To address this challenge, we introduce TRajectory-class-Aware Multi-Agent reinforcement learning (TRAMA). In TRAMA, agents recognize a task type by identifying the class of trajectories they are experiencing through partial observations, and the agents use this trajectory awareness or prediction as additional information for action policy. To this end, we introduce three primary objectives in TRAMA: (a) constructing a quantized latent space to generate trajectory embeddings that reflect key similarities among them; (b) conducting trajectory clustering using these trajectory embeddings; and (c) building a trajectory-class-aware policy. Specifically for (c), we introduce a trajectory-class predictor that performs agent-wise predictions on the trajectory class; and we design a trajectory-class representation model for each trajectory class. Each agent takes actions based on this trajectory-class representation along with its partial observation for task-aware execution. The proposed method is evaluated on various tasks, including multi-task problems built upon StarCraft II. Empirical results show further performance improvements over state-of-the-art baselines.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SrSv: Integrating Sequential Rollouts with Sequential Value Estimation for Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.01458</link>
<guid>https://arxiv.org/abs/2503.01458</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 信用分配问题, 可扩展性, 序列化 rollout, 顺序值估计(SrSv)

总结:
本文提出了一种针对大规模真实世界系统中的多智能体强化学习(MARL)新框架——序列化 rollout 与顺序值估计(SrSv)。该框架旨在解决现实中复杂环境导致的信用分配问题以及大规模场景中智能体群体变化带来的可扩展性挑战。SrSv利用Transformer模型的自回归性质处理动态的智能体行为序列，并通过引入创新的顺序值估计方法，将价值函数近似整合到注意力机制驱动的序贯模型中。实验结果显示，SrSv在Multi-Agent MuJoCo、StarCraft Multi-Agent Challenge和DubinsCars三个基准测试上均表现出优于基线方法的训练效率和收敛性能。特别是在包含1024个智能体的大规模DubinsCar系统中，SrSv框架表现出了卓越的可扩展性优势。<br /><br /> <div>
arXiv:2503.01458v1 Announce Type: new 
Abstract: Although multi-agent reinforcement learning (MARL) has shown its success across diverse domains, extending its application to large-scale real-world systems still faces significant challenges. Primarily, the high complexity of real-world environments exacerbates the credit assignment problem, substantially reducing training efficiency. Moreover, the variability of agent populations in large-scale scenarios necessitates scalable decision-making mechanisms. To address these challenges, we propose a novel framework: Sequential rollout with Sequential value estimation (SrSv). This framework aims to capture agent interdependence and provide a scalable solution for cooperative MARL. Specifically, SrSv leverages the autoregressive property of the Transformer model to handle varying populations through sequential action rollout. Furthermore, to capture the interdependence of policy distributions and value functions among multiple agents, we introduce an innovative sequential value estimation methodology and integrates the value approximation into an attention-based sequential model. We evaluate SrSv on three benchmarks: Multi-Agent MuJoCo, StarCraft Multi-Agent Challenge, and DubinsCars. Experimental results demonstrate that SrSv significantly outperforms baseline methods in terms of training efficiency without compromising convergence performance. Moreover, when implemented in a large-scale DubinsCar system with 1,024 agents, our framework surpasses existing benchmarks, highlighting the excellent scalability of SrSv.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improving Retrospective Language Agents via Joint Policy Gradient Optimization</title>
<link>https://arxiv.org/abs/2503.01490</link>
<guid>https://arxiv.org/abs/2503.01490</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、自主代理、RetroAct、联合优化、强化学习

<br /><br />总结:
本文介绍了针对大型语言模型在创建自主代理中的应用所面临的问题，提出了一种名为RetroAct的新颖框架。该框架着重于任务规划与自我反思能力的联合优化，旨在降低对大规模封闭源码LLM的依赖并使微调后的代理具有持续学习和改进的能力。RetroAct采用了一个两阶段的联合优化过程，整合了模仿学习和强化学习，并设计了一种带有模仿学习正则化的离策略联合策略梯度优化算法，以提高数据效率和训练稳定性。通过在多种测试环境中的广泛实验，证明了RetroAct在任务性能和决策过程中有显著提升。 <div>
arXiv:2503.01490v1 Announce Type: new 
Abstract: In recent research advancements within the community, large language models (LLMs) have sparked great interest in creating autonomous agents. However, current prompt-based agents often heavily rely on large-scale LLMs. Meanwhile, although fine-tuning methods significantly enhance the capabilities of smaller LLMs, the fine-tuned agents often lack the potential for self-reflection and self-improvement. To address these challenges, we introduce a novel agent framework named RetroAct, which is a framework that jointly optimizes both task-planning and self-reflective evolution capabilities in language agents. Specifically, we develop a two-stage joint optimization process that integrates imitation learning and reinforcement learning, and design an off-policy joint policy gradient optimization algorithm with imitation learning regularization to enhance the data efficiency and training stability in agent tasks. RetroAct significantly improves the performance of open-source models, reduces dependency on closed-source LLMs, and enables fine-tuned agents to learn and evolve continuously. We conduct extensive experiments across various testing environments, demonstrating RetroAct has substantial improvements in task performance and decision-making processes.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evaluation and Facilitation of Online Discussions in the LLM Era: A Survey</title>
<link>https://arxiv.org/abs/2503.01513</link>
<guid>https://arxiv.org/abs/2503.01513</guid>
<content:encoded><![CDATA[
<div> 关键词：在线讨论、质量评估、大型语言模型、干预策略、对话促进

<br /><br />总结:
本文是一篇关于在线讨论质量评估与提升方法的调查报告，重点关注了大型语言模型（LLMs）的潜力。报告指出现实中网络交流常导致有害言论，威胁社会和谐和民主价值观。研究概述了从自然语言处理（NLP）和社会科学角度出发的评价指标与干预策略，并提出了新的讨论质量评估分类法和对话促进数据集分类法。同时，文章针对LLM提出了一条结合技术与社会视角的良好实践和未来研究方向路线图。 <div>
arXiv:2503.01513v1 Announce Type: new 
Abstract: We present a survey of methods for assessing and enhancing the quality of online discussions, focusing on the potential of Large Language Models (LLMs). While online discourses aim, at least in theory, to foster mutual understanding, they often devolve into harmful exchanges, such as hate speech, threatening social cohesion and democratic values. Recent advancements in LLMs enable facilitation agents that not only moderate content, but also actively improve the quality of interactions. Our survey synthesizes ideas from Natural Language Processing (NLP) and Social Sciences to provide (a) a new taxonomy on discussion quality evaluation, (b) an overview of intervention and facilitation strategies, along with a new taxonomy on conversation facilitation datasets, (c) an LLM-oriented roadmap of good practices and future research directions, from technological and societal perspectives.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SENSEI: Semantic Exploration Guided by Foundation Models to Learn Versatile World Models</title>
<link>https://arxiv.org/abs/2503.01584</link>
<guid>https://arxiv.org/abs/2503.01584</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 内在动机, 语义探索, 模型基RL, 视觉语言模型

总结:
本文提出了一个名为SEmaNtically Sensible ExploratIon (SENSEI)的框架，旨在使模型基强化学习代理具备对语义上有意义行为的内在动机。与传统的基于信息增益的内在动机方法不同，SENSEI从视觉语言模型（VLM）注解中提炼出有趣性奖励信号，使代理能够通过世界模型预测这些奖励。通过使用模型基RL，SENSEI训练一个探索策略，该策略同时最大化语义奖励和不确定性。实验表明，在机器人和视频游戏般的模拟环境中，SENSEI能够从图像观测和低级动作中发现多种有意义的行为。SENSEI为从基础模型反馈中进行学习提供了一个通用工具，随着视觉语言模型变得更加强大，这一研究方向显得尤为重要。 <div>
arXiv:2503.01584v1 Announce Type: new 
Abstract: Exploration is a cornerstone of reinforcement learning (RL). Intrinsic motivation attempts to decouple exploration from external, task-based rewards. However, established approaches to intrinsic motivation that follow general principles such as information gain, often only uncover low-level interactions. In contrast, children's play suggests that they engage in meaningful high-level behavior by imitating or interacting with their caregivers. Recent work has focused on using foundation models to inject these semantic biases into exploration. However, these methods often rely on unrealistic assumptions, such as language-embedded environments or access to high-level actions. We propose SEmaNtically Sensible ExploratIon (SENSEI), a framework to equip model-based RL agents with an intrinsic motivation for semantically meaningful behavior. SENSEI distills a reward signal of interestingness from Vision Language Model (VLM) annotations, enabling an agent to predict these rewards through a world model. Using model-based RL, SENSEI trains an exploration policy that jointly maximizes semantic rewards and uncertainty. We show that in both robotic and video game-like simulations SENSEI discovers a variety of meaningful behaviors from image observations and low-level actions. SENSEI provides a general tool for learning from foundation model feedback, a crucial research direction, as VLMs become more powerful.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RevTogether: Supporting Science Story Revision with Multiple AI Agents</title>
<link>https://arxiv.org/abs/2503.01608</link>
<guid>https://arxiv.org/abs/2503.01608</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2503.01608v1, 科学故事, 人工智能, 多智能体系统, 交互体验

总结:
为了解决撰写吸引人的科学故事所面临的挑战，本文提出了一个名为RevTogether的多智能体系统（MAS），该系统利用类似人类的人工智能代理（基于GPT-4）来支持科学故事的修订工作。RevTogether允许AI代理模拟情感反应，并提供评论与写作建议，同时为用户提供不同程度的决策自由度。初步用户研究表明，非专家作者在使用过程中强调需要AI决策透明化以支持学习，并认为情感交互可以增强人类与AI在科学故事讲述中的协作体验。 <div>
arXiv:2503.01608v1 Announce Type: new 
Abstract: As a popular form of science communication, science stories attract readers because they combine engaging narratives with comprehensible scientific knowledge. However, crafting such stories requires substantial skill and effort, as writers must navigate complex scientific concepts and transform them into coherent and accessible narratives tailored to audiences with varying levels of scientific literacy. To address the challenge, we propose RevTogether, a multi-agent system (MAS) designed to support revision of science stories with human-like AI agents (using GPT-4o). RevTogether allows AI agents to simulate affects in addition to providing comments and writing suggestions, while offering varying degrees of user agency. Our preliminary user study with non-expert writers (N=3) highlighted the need for transparency in AI agents' decision-making processes to support learning and suggested that emotional interactions could enhance human-AI collaboration in science storytelling.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Advancing vision-language models in front-end development via data synthesis</title>
<link>https://arxiv.org/abs/2503.01619</link>
<guid>https://arxiv.org/abs/2503.01619</guid>
<content:encoded><![CDATA[
<div> 关键词: 前端开发、React、Vue、大规模视觉语言模型、Flame<br /><br />总结:
本文针对现代前端开发，尤其是利用React和Vue等框架的独特特性所面临的挑战，如模块化架构管理、声明性渲染下的数据与视觉输出同步以及可复用组件的多样化适应等问题，提出了一种反射性代理工作流。该工作流通过合成高质量图像文本数据，自动从真实项目中抽取自包含代码片段，生成对应的可视化输出并建立设计元素与功能代码之间的详细描述关联。为了扩展数据合成的范围和实用性，文章提出了三种数据合成策略：基于进化的合成实现大规模多样性的数据扩充；基于瀑布模型的合成生成逻辑连贯的代码；基于增量开发的合成迭代增加人类编写的组件复杂度。文中构建了一个名为Flame的大规模视觉语言模型，并在训练于合成数据集后，展示了其在通过$\text{pass}@k$指标生成React代码方面的优越性能。研究表明，训练有素的代码VLM在进行图像解释后再进行代码生成可能获得更好的表现。 <div>
arXiv:2503.01619v1 Announce Type: new 
Abstract: Modern front-end (FE) development, especially when leveraging the unique features of frameworks like React and Vue, presents distinctive challenges. These include managing modular architectures, ensuring synchronization between data and visual outputs for declarative rendering, and adapting reusable components to various scenarios. Such complexities make it particularly difficult for state-of-the-art large vision-language models (VLMs) to generate accurate and functional code directly from design images. To address these challenges, we propose a reflective agentic workflow that synthesizes high-quality image-text data to capture the diverse characteristics of FE development. This workflow automates the extraction of self-contained\footnote{A \textbf{self-contained} code snippet is one that encapsulates all necessary logic, styling, and dependencies, ensuring it functions independently without requiring external imports or context.} code snippets from real-world projects, renders the corresponding visual outputs, and generates detailed descriptions that link design elements to functional code. To further expand the scope and utility of the synthesis, we introduce three data synthesis strategies: Evolution-based synthesis, which enables scalable and diverse dataset expansion; Waterfall-Model-based synthesis, which generates logically coherent code derived from system requirements; and Additive Development synthesis, which iteratively increases the complexity of human-authored components. We build a large vision-language model, Flame, trained on the synthesized datasets and demonstrate its effectiveness in generating React code via the $\text{pass}@k$ metric. Our results suggest that a code VLM trained to interpret images before code generation may achieve better performance.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Student engagement in collaborative learning with AI agents in an LLM-empowered learning environment: A cluster analysis</title>
<link>https://arxiv.org/abs/2503.01694</link>
<guid>https://arxiv.org/abs/2503.01694</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM模型、教育实践、个性化学习、学习者类型、互动设置

<br /><br />总结:
本文探讨了将LLM模型融入教育实践中如何促进个性化学习，并研究了不同学习者类型的特征和互动动态。通过对来自中国一所大学的110名学生进行实验，这些学生在一个由LLM驱动的学习环境中与多个LLM代理互动并完成六门课程作业。研究收集并分析了学生的非认知特质、课程参与度以及AI交互模式数据。通过层次聚类分析，学生被划分为三类：主动提问者、响应式导航者和沉默倾听者。进一步利用认知网络分析法揭示了不同类型学习者的交互特点和认知参与程度。研究结果强调了不同类型学习者如何参与到人机交互式学习中，并为适应性教育系统的设计提供了实际应用启示。 <div>
arXiv:2503.01694v1 Announce Type: new 
Abstract: Integrating LLM models into educational practice fosters personalized learning by accommodating the diverse behavioral patterns of different learner types. This study aims to explore these learner types within a novel interactive setting, providing a detailed analysis of their distinctive characteristics and interaction dynamics. The research involved 110 students from a university in China, who engaged with multiple LLM agents in an LLM-empowered learning environment, completing coursework across six modules. Data on the students' non-cognitive traits, course engagement, and AI interaction patterns were collected and analyzed. Using hierarchical cluster analysis, the students were classified into three distinct groups: active questioners, responsive navigators, and silent listeners. Epistemic network analysis was then applied to further delineate the interaction profiles and cognitive engagement of different types of learners. The findings underscore how different learner types engage with human-AI interactive learning and offer practical implications for the design of adaptive educational systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Regret Minimization for Piecewise Linear Rewards: Contracts, Auctions, and Beyond</title>
<link>https://arxiv.org/abs/2503.01701</link>
<guid>https://arxiv.org/abs/2503.01701</guid>
<content:encoded><![CDATA[
<div> 关键词: 在线学习、后悔最小化、分段线性函数、合同设计、拍卖

总结:
该论文提出了一种针对具有分段线性奖励函数的在线学习通用框架，这些函数常见于微观经济模型中，如隐藏行动的委托代理问题、定价销售和第一价格拍卖。在参数未知且由某些概率分布决定的情况下，学习如何优化未知且随机的分段线性奖励函数成为问题。新框架在满足适当的单调性假设条件下，设计了一个学习算法，其可以获得$\widetilde{O}(\sqrt{nT})$的遗憾值，其中$n$为奖励函数的“片段”数量，$T$为轮数。当$n$相对于$T$较小（即$n\leq T^{1/3}$）时，这个结果是紧致的。该算法解决了文献中的两个开放问题：一是对于隐藏行动委托代理问题中学习最优线性合同，证明了Zhu等人[Zhu+23]得到的$\widetilde{O}(T^{2/3})$遗憾界在动作数量小的情况下的不严格性；二是展示了在定价拍卖的学习定价问题中可以实现合适的实例无关遗憾界限，从而回答了Cesa-Bianchi等人[CBCP19]提出的开放问题。 <div>
arXiv:2503.01701v1 Announce Type: new 
Abstract: Most microeconomic models of interest involve optimizing a piecewise linear function. These include contract design in hidden-action principal-agent problems, selling an item in posted-price auctions, and bidding in first-price auctions. When the relevant model parameters are unknown and determined by some (unknown) probability distributions, the problem becomes learning how to optimize an unknown and stochastic piecewise linear reward function. Such a problem is usually framed within an online learning framework, where the decision-maker (learner) seeks to minimize the regret of not knowing an optimal decision in hindsight. This paper introduces a general online learning framework that offers a unified approach to tackle regret minimization for piecewise linear rewards, under a suitable monotonicity assumption commonly satisfied by microeconomic models. We design a learning algorithm that attains a regret of $\widetilde{O}(\sqrt{nT})$, where $n$ is the number of ``pieces'' of the reward function and $T$ is the number of rounds. This result is tight when $n$ is \emph{small} relative to $T$, specifically when $n \leq T^{1/3}$. Our algorithm solves two open problems in the literature on learning in microeconomic settings. First, it shows that the $\widetilde{O}(T^{2/3})$ regret bound obtained by Zhu et al. [Zhu+23] for learning optimal linear contracts in hidden-action principal-agent problems is not tight when the number of agent's actions is small relative to $T$. Second, our algorithm demonstrates that, in the problem of learning to set prices in posted-price auctions, it is possible to attain suitable (and desirable) instance-independent regret bounds, addressing an open problem posed by Cesa-Bianchi et al. [CBCP19].
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Surrogate Equations for the Analysis of an Agent-Based Cancer Model</title>
<link>https://arxiv.org/abs/2503.01718</link>
<guid>https://arxiv.org/abs/2503.01718</guid>
<content:encoded><![CDATA[
<div> 关键词：agent-based癌症模型、免疫细胞、竞争模拟、反应模型、普通微分方程

总结:
本文研究了扩展自两物种agent-based癌症模型的一个包含癌细胞、健康细胞和免疫细胞三者交互作用的新模型。通过运行六种不同场景来探索免疫细胞与癌细胞的竞争以及免疫细胞初始浓度对癌症动态的影响。接着使用耦合方程学习法为每种场景构建了一个基于种群的反应模型，并进一步将它们统一到一个简化的代理人群基反应模型中，该模型由三个耦合常微分方程组成，比原agent-based模型更容易分析。例如，通过找到单一稳定的癌症浓度状态，我们发现其与免疫细胞初始浓度之间存在线性关系。这一发现使我们能够估计出合适的竞争参数和免疫细胞初始浓度值，以大幅减少癌症的发展而无需进行更多复杂且昂贵的agent-based随机模型模拟。这项工作强调了从agent-based随机数据中进行方程学习对于理解复杂细胞动力学行为的关键意义。 <div>
arXiv:2503.01718v1 Announce Type: new 
Abstract: In this paper, we adapt a two species agent-based cancer model that describes the interaction between cancer cells and healthy cells on a uniform grid to include the interaction with a third species -- namely immune cells. We run six different scenarios to explore the competition between cancer and immune cells and the initial concentration of the immune cells on cancer dynamics. We then use coupled equation learning to construct a population-based reaction model for each scenario. We show how they can be unified into a single surrogate population-based reaction model, whose underlying three coupled ordinary differential equations are much easier to analyse than the original agent-based model. As an example, by finding the single steady state of the cancer concentration, we are able to find a linear relationship between this concentration and the initial concentration of the immune cells. This then enables us to estimate suitable values for the competition and initial concentration to reduce the cancer substantially without performing additional complex and expensive simulations from an agent-based stochastic model. The work shows the importance of performing equation learning from agent-based stochastic data for gaining key insights about the behaviour of complex cellular dynamics.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adversarial Agents: Black-Box Evasion Attacks with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2503.01734</link>
<guid>https://arxiv.org/abs/2503.01734</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning)，对抗性机器学习 (Adversarial Machine Learning)，攻击策略 (Attack Strategies)，Markov 决策过程 (Markov Decision Process)，CIFAR-10

总结:
本文展示了如何将强化学习应用到对抗性机器学习中，提出一种新的攻击方法，用于生成能够欺骗机器学习模型的对抗性示例。该方法通过将对抗性例子生成视为马尔科夫决策过程，利用过去的经验改进未来的攻击策略。在 CIFAR-10 数据集上，与训练开始时相比，这种方法使成功生成对抗性示例的概率提高了 19.4%，并减少了生成每个对抗性示例所需的受害模型查询次数达 53.2%。相比于先进的图像攻击方法 SquareAttack，经过 5000 个episode的训练后，该方法让攻击者生成对抗性示例的成功率提升了 13.1%。从安全角度而言，这项工作展示了一种使用强化学习高效、大规模地攻击机器学习模型的强大新途径。 <div>
arXiv:2503.01734v1 Announce Type: new 
Abstract: Reinforcement learning (RL) offers powerful techniques for solving complex sequential decision-making tasks from experience. In this paper, we demonstrate how RL can be applied to adversarial machine learning (AML) to develop a new class of attacks that learn to generate adversarial examples: inputs designed to fool machine learning models. Unlike traditional AML methods that craft adversarial examples independently, our RL-based approach retains and exploits past attack experience to improve future attacks. We formulate adversarial example generation as a Markov Decision Process and evaluate RL's ability to (a) learn effective and efficient attack strategies and (b) compete with state-of-the-art AML. On CIFAR-10, our agent increases the success rate of adversarial examples by 19.4% and decreases the median number of victim model queries per adversarial example by 53.2% from the start to the end of training. In a head-to-head comparison with a state-of-the-art image attack, SquareAttack, our approach enables an adversary to generate adversarial examples with 13.1% more success after 5000 episodes of training. From a security perspective, this work demonstrates a powerful new attack vector that uses RL to attack ML models efficiently and at scale.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retrieval Models Aren't Tool-Savvy: Benchmarking Tool Retrieval for Large Language Models</title>
<link>https://arxiv.org/abs/2503.01763</link>
<guid>https://arxiv.org/abs/2503.01763</guid>
<content:encoded><![CDATA[
<div> 关键词: 工具学习、大型语言模型、信息检索、工具检索基准、ToolRet<br /><br />总结:
本文提出了一个名为ToolRet的异质性工具检索基准，该基准包含了7.6k个多样化的检索任务和一个由43k个工具组成的语料库，这些数据来自现有数据集。研究发现，尽管一些在传统信息检索基准中表现出色的模型，在ToolRet上的性能却很差，这表明它们在工具检索任务中的表现不足，并导致工具使用型大语言模型的任务完成率降低。为了解决这一问题，文章还贡献了一个大规模训练数据集，其中包含超过20万实例，显著提升了信息检索模型的工具检索能力。 <div>
arXiv:2503.01763v1 Announce Type: new 
Abstract: Tool learning aims to augment large language models (LLMs) with diverse tools, enabling them to act as agents for solving practical tasks. Due to the limited context length of tool-using LLMs, adopting information retrieval (IR) models to select useful tools from large toolsets is a critical initial step. However, the performance of IR models in tool retrieval tasks remains underexplored and unclear. Most tool-use benchmarks simplify this step by manually pre-annotating a small set of relevant tools for each task, which is far from the real-world scenarios. In this paper, we propose ToolRet, a heterogeneous tool retrieval benchmark comprising 7.6k diverse retrieval tasks, and a corpus of 43k tools, collected from existing datasets. We benchmark six types of models on ToolRet. Surprisingly, even the models with strong performance in conventional IR benchmarks, exhibit poor performance on ToolRet. This low retrieval quality degrades the task pass rate of tool-use LLMs. As a further step, we contribute a large-scale training dataset with over 200k instances, which substantially optimizes the tool retrieval ability of IR models.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AutoAdvExBench: Benchmarking autonomous exploitation of adversarial example defenses</title>
<link>https://arxiv.org/abs/2503.01811</link>
<guid>https://arxiv.org/abs/2503.01811</guid>
<content:encoded><![CDATA[
<div> 关键词：AutoAdvExBench、大型语言模型、防御机制、对抗样本、基准测试

<br /><br />总结:
本文介绍了AutoAdvExBench，这是一个用于评估大型语言模型（LLMs）能否自主利用防御机制来应对对抗样本的基准测试。与现有的安全基准测试不同，该测试直接衡量LLMs在机器学习安全专家日常执行的任务上的成功率，从而具备实际应用价值。研究者设计了一个强大的代理，它能成功破解75%的类似CTF的对抗样本防御，但仅能成功应对13%的真实世界防御。相比之下，一个能够攻击21%真实世界防御的更强大的LLM，却只能在54%的类似CTF防御上取得成功。这项基准测试已在https://github.com/ethz-spylab/AutoAdvExBench上公开可用。 <div>
arXiv:2503.01811v1 Announce Type: new 
Abstract: We introduce AutoAdvExBench, a benchmark to evaluate if large language models (LLMs) can autonomously exploit defenses to adversarial examples. Unlike existing security benchmarks that often serve as proxies for real-world tasks, bench directly measures LLMs' success on tasks regularly performed by machine learning security experts. This approach offers a significant advantage: if a LLM could solve the challenges presented in bench, it would immediately present practical utility for adversarial machine learning researchers. We then design a strong agent that is capable of breaking 75% of CTF-like ("homework exercise") adversarial example defenses. However, we show that this agent is only able to succeed on 13% of the real-world defenses in our benchmark, indicating the large gap between difficulty in attacking "real" code, and CTF-like code. In contrast, a stronger LLM that can attack 21% of real defenses only succeeds on 54% of CTF-like defenses. We make this benchmark available at https://github.com/ethz-spylab/AutoAdvExBench.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Persuade Me if You Can: A Framework for Evaluating Persuasion Effectiveness and Susceptibility Among Large Language Models</title>
<link>https://arxiv.org/abs/2503.01829</link>
<guid>https://arxiv.org/abs/2503.01829</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型 (LLMs)、说服力、Persuade Me If You Can (PMIYC)、多代理交互、人类评价

总结:
这篇论文介绍了研究大规模语言模型（LLMs）说服力及对伦理原则遵循情况的新框架——Persuade Me If You Can (PMIYC)。该框架通过多轮对话评估LLMs的说服能力和易受说服的程度。论文进行了全面评估，涉及多种LLMs并在主观和错误信息情境中进行对比。通过与人工评价的对比，验证了框架的有效性。PMIYC提供了一种可扩展的人工标注替代方案，用于研究LLMs中的说服现象。实验结果显示，Llama-3.3-70B和GPT-4o在说服效果上相当，但GPT-4o对于错误信息的抵抗说服力比Llama-3.3-70B高出超过50%。这些发现为理解LLMs的说服动态提供了实证见解，有助于开发更安全的人工智能系统。 <div>
arXiv:2503.01829v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate persuasive capabilities that rival human-level persuasion. While these capabilities can be used for social good, they also present risks of potential misuse. Moreover, LLMs' susceptibility to persuasion raises concerns about alignment with ethical principles. To study these dynamics, we introduce Persuade Me If You Can (PMIYC), an automated framework for evaluating persuasion through multi-agent interactions. Here, Persuader agents engage in multi-turn conversations with the Persuadee agents, allowing us to measure LLMs' persuasive effectiveness and their susceptibility to persuasion. We conduct comprehensive evaluations across diverse LLMs, ensuring each model is assessed against others in both subjective and misinformation contexts. We validate the efficacy of our framework through human evaluations and show alignment with prior work. PMIYC offers a scalable alternative to human annotation for studying persuasion in LLMs. Through PMIYC, we find that Llama-3.3-70B and GPT-4o exhibit similar persuasive effectiveness, outperforming Claude 3 Haiku by 30%. However, GPT-4o demonstrates over 50% greater resistance to persuasion for misinformation compared to Llama-3.3-70B. These findings provide empirical insights into the persuasive dynamics of LLMs and contribute to the development of safer AI systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can (A)I Change Your Mind?</title>
<link>https://arxiv.org/abs/2503.01844</link>
<guid>https://arxiv.org/abs/2503.01844</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、说服能力、生态情境、互动类型、公共意见影响

<br /><br />总结:
该研究探索了大型语言模型（LLM）在更生态化、无约束条件下的说服力，包括静态（书面段落）和动态（通过Telegram进行对话）两种交互方式。这项预注册的研究以希伯来语为语言环境，共有200名参与者，考察了LLM与人类对话者在争议性公民政策话题上的说服效果。结果显示，参与者对LLM和人类观点的采纳程度相似，并在所有条件下都显示出明显的观点变化，不论对话者类型或交互模式如何。在大多数情况下，参与者的信心水平显著提高，但在静态的LLM交互中除外。这些发现表明，LLM基的对话代理在不同来源和设置下具有强大的说服力，可能对塑造公众意见产生重大影响。 <div>
arXiv:2503.01844v1 Announce Type: new 
Abstract: The increasing integration of large language model (LLM) based conversational agents into everyday life raises critical cognitive and social questions about their potential to influence human opinions. Although previous studies have shown that LLM-based agents can generate persuasive content, these typically involve controlled, English-language settings. Addressing this, our preregistered study explored LLM's persuasive capabilities in more ecological, unconstrained scenarios, examining both static (written paragraphs) and dynamic (conversations via Telegram) interaction types. Conducted entirely in Hebrew with 200 participants, the study assessed the persuasive effects of both LLM and human interlocutors on controversial civil policy topics. Results indicated that participants adopted LLM and human perspectives similarly, with significant opinion changes evident across all conditions, regardless of interlocutor type or interaction mode. Confidence levels increased significantly in most scenarios, except in static LLM interactions. These findings demonstrate LLM-based agents' robust persuasive capabilities across diverse sources and settings, highlighting their potential impact on shaping public opinions.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BixBench: a Comprehensive Benchmark for LLM-based Agents in Computational Biology</title>
<link>https://arxiv.org/abs/2503.00096</link>
<guid>https://arxiv.org/abs/2503.00096</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，Bioinformatics Benchmark (BixBench)，GPT-4o，Claude 3.5 Sonnet，生物数据分析

<br /><br />总结:
本文介绍了为衡量大型语言模型在生物信息学领域研究加速潜力而创建的新基准——Bioinformatics Benchmark (BixBench)。该基准包含超过50个现实世界的生物数据处理场景和近300个开放式问题，旨在评估模型进行多步骤分析并解释复杂结果的能力。研究人员使用开源框架对两个前沿语言模型（GPT-4o 和 Claude 3.5 Sonnet）进行了评估，发现它们在开放式回答任务中的准确率仅为17%，在多项选择题中表现甚至不如随机选择。通过揭示现有模型的局限性，BixBench有望推动研发能够执行严谨生物信息学分析的AI代理，从而加速科学发现。 <div>
arXiv:2503.00096v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) and LLM-based agents show great promise in accelerating scientific research. Existing benchmarks for measuring this potential and guiding future development continue to evolve from pure recall and rote knowledge tasks, towards more practical work such as literature review and experimental planning. Bioinformatics is a domain where fully autonomous AI-driven discovery may be near, but no extensive benchmarks for measuring progress have been introduced to date. We therefore present the Bioinformatics Benchmark (BixBench), a dataset comprising over 50 real-world scenarios of practical biological data analysis with nearly 300 associated open-answer questions designed to measure the ability of LLM-based agents to explore biological datasets, perform long, multi-step analytical trajectories, and interpret the nuanced results of those analyses. We evaluate the performance of two frontier LLMs (GPT-4o and Claude 3.5 Sonnet) using a custom agent framework we open source. We find that even the latest frontier models only achieve 17% accuracy in the open-answer regime, and no better than random in a multiple-choice setting. By exposing the current limitations of frontier models, we hope BixBench can spur the development of agents capable of conducting rigorous bioinformatic analysis and accelerate scientific discovery.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shifting Power: Leveraging LLMs to Simulate Human Aversion in ABMs of Bilateral Financial Exchanges, A bond market study</title>
<link>https://arxiv.org/abs/2503.00320</link>
<guid>https://arxiv.org/abs/2503.00320</guid>
<content:encoded><![CDATA[
<div> 关键词：双边市场、代理模型、大型语言模型、交易动态、风险敏感性

总结:
该文提出了一种名为TRIBE的新型代理模型，用于模拟双边市场的复杂交易行为，其中融合了大型语言模型以增强代理人的人类般决策能力。文章通过公开数据和风格化事实捕捉真实的交易动态，并将人类的诸如风险规避和模糊敏感性等偏见引入到代理人决策过程中。研究主要贡献包括：<br />
1. 证明了在代理模型中集成大型语言模型来增强客户代理行为的可行性，并能丰富复杂市场中代理行为的模拟；<br />
2. 发现即使在LLM中轻微编码的交易厌恶也会导致交易活动完全停止，显示出市场动态对代理人风险偏好的高度敏感性；<br />
3. 展示了引入类似人类的行为变化会转移权力动态至客户端，并可能不成比例地影响整个系统，甚至在模拟中引发系统性代理人崩溃。这些发现强调了当引入随机、类似人类的决策过程时出现的涌现属性，揭示了增强人工社会现实性和复杂性的新系统行为。 <div>
arXiv:2503.00320v1 Announce Type: cross 
Abstract: Bilateral markets, such as those for government bonds, involve decentralized and opaque transactions between market makers (MMs) and clients, posing significant challenges for traditional modeling approaches. To address these complexities, we introduce TRIBE an agent-based model augmented with a large language model (LLM) to simulate human-like decision-making in trading environments. TRIBE leverages publicly available data and stylized facts to capture realistic trading dynamics, integrating human biases like risk aversion and ambiguity sensitivity into the decision-making processes of agents. Our research yields three key contributions: first, we demonstrate that integrating LLMs into agent-based models to enhance client agency is feasible and enriches the simulation of agent behaviors in complex markets; second, we find that even slight trade aversion encoded within the LLM leads to a complete cessation of trading activity, highlighting the sensitivity of market dynamics to agents' risk profiles; third, we show that incorporating human-like variability shifts power dynamics towards clients and can disproportionately affect the entire system, often resulting in systemic agent collapse across simulations. These findings underscore the emergent properties that arise when introducing stochastic, human-like decision processes, revealing new system behaviors that enhance the realism and complexity of artificial societies.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Bayesian Interpretation of the Internal Model Principle</title>
<link>https://arxiv.org/abs/2503.00511</link>
<guid>https://arxiv.org/abs/2503.00511</guid>
<content:encoded><![CDATA[
<div> 关键词: 内部模型原则、控制理论、认知科学、Bayesian处理、Markov类别

总结:
这篇文章探讨了内部模型原则，该原则最初在线性系统控制理论中提出，现在在更广泛的控制论和 cybernetics 领域有重要应用。文章首先回顾了内部模型原则并借用范畴系统理论的概念给出了精确的表述，从而定义了一个概括性的“模型”概念。虽然这个“模型”概念与认知科学中的Bayesian推理所涉及的内部模型并非先天相关，但作者表明它可以被视为可能性Bayesian滤波的一种特殊情况。这一结论基于最近利用Markov类别形式化“解释”的研究，即当一个系统可以被解释为以一致的方式对外界环境执行Bayesian过滤操作时。 <div>
arXiv:2503.00511v1 Announce Type: cross 
Abstract: The internal model principle, originally proposed in the theory of control of linear systems, nowadays represents a more general class of results in control theory and cybernetics. The central claim of these results is that, under suitable assumptions, if a system (a controller) can regulate against a class of external inputs (from the environment), it is because the system contains a model of the system causing these inputs, which can be used to generate signals counteracting them. Similar claims on the role of internal models appear also in cognitive science, especially in modern Bayesian treatments of cognitive agents, often suggesting that a system (a human subject, or some other agent) models its environment to adapt against disturbances and perform goal-directed behaviour. It is however unclear whether the Bayesian internal models discussed in cognitive science bear any formal relation to the internal models invoked in standard treatments of control theory. Here, we first review the internal model principle and present a precise formulation of it using concepts inspired by categorical systems theory. This leads to a formal definition of `model' generalising its use in the internal model principle. Although this notion of model is not a priori related to the notion of Bayesian reasoning, we show that it can be seen as a special case of possibilistic Bayesian filtering. This result is based on a recent line of work formalising, using Markov categories, a notion of `interpretation', describing when a system can be interpreted as performing Bayesian filtering on an outside world in a consistent way.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI Agents for Ground-Based Gamma Astronomy</title>
<link>https://arxiv.org/abs/2503.00821</link>
<guid>https://arxiv.org/abs/2503.00821</guid>
<content:encoded><![CDATA[
<div> 关键词：下一代伽马射线天文仪器、复杂性、人工智能代理、大型语言模型、Cherenkov望远镜阵列观测站

总结:
随着地面基于伽马射线天文学的下一代仪器出现显著的复杂性提升，管理和离线数据分析面临挑战。为此，文章提出开发基于指令微调的大型语言模型（LLMs）的人工智能代理以应对这些问题。这些代理能够与特定文档和代码库对齐，理解环境上下文，操作外部API并与人类使用自然语言进行交流。通过利用现代LLM处理和存储大量信息的能力，AI代理可以自动化复杂的任务并提供智能辅助。文章展示了两个原型，第一个原型自动管理并维护了Cherenkov望远镜阵列观测站数组控制和数据采集系统（ACADA）的数据模型实施；第二个原型是一个针对Gammapy框架定制的开放访问代码生成应用，用于数据分析。这两个原型证明了AI代理在地面伽马射线天文领域中的有效性和潜力。 <div>
arXiv:2503.00821v1 Announce Type: cross 
Abstract: Next-generation instruments for ground-based gamma-ray astronomy are marked by a substantial increase in complexity, featuring dozens of telescopes. This leap in scale introduces significant challenges in managing system operations and offline data analysis. Methods, which depend on advanced personnel training and sophisticated software, become increasingly strained as system complexity grows, making it more challenging to effectively support users in such a multifaceted environment. To address these challenges, we propose the development of AI agents based on instruction-finetuned large language models (LLMs). These agents align with specific documentation and codebases, understand the environmental context, operate with external APIs, and communicate with humans in natural language. Leveraging the advanced capabilities of modern LLMs, which can process and retain vast amounts of information, these AI agents offer a transformative approach to system management and data analysis by automating complex tasks and providing intelligent assistance. We present two prototypes that integrate with the Cherenkov Telescope Array Observatory pipelines for operations and offline data analysis. The first prototype automates data model implementation and maintenance for the Configuration Database of the Array Control and Data Acquisition (ACADA). The second prototype is an open-access code generation application tailored for data analysis based on the Gammapy framework.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Interactive Gadolinium-Free MRI Synthesis: A Transformer with Localization Prompt Learning</title>
<link>https://arxiv.org/abs/2503.01265</link>
<guid>https://arxiv.org/abs/2503.01265</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer with Localization Prompts (TLP)，对比增强磁共振成像 (CE-MRI)，钆基对比剂 (GBCAs)，无对比MRI合成，安全诊断

<br /><br />总结：
本文提出了一种名为Transformer with Localization Prompts (TLP)的新框架，用于从非对比MR图像中合成对比增强磁共振成像（CE-MRI），以解决钆基对比剂（GBCAs）在临床使用中的安全性问题。该框架具有三个创新点：利用高效Transformer处理多尺度特征的分层主干网络；由局部和全局融合模块组成的多阶段融合系统，通过空间注意力操作和交叉注意力机制进行层次信息集成；以及模糊提示生成（FPG）模块，通过随机特征扰动来模拟放射科医生的手动注释，提升模型泛化能力。此外，TLP框架支持互动式临床整合，允许放射科医生在推理过程中输入诊断提示，将人工智能与医学专家经验相结合。这项研究为实现无需对比剂的MRI合成建立了新的范式，并满足了更安全诊断程序的临床需求。相关代码可在https://github.com/ChanghuiSu/TLP 获取。 <div>
arXiv:2503.01265v1 Announce Type: cross 
Abstract: Contrast-enhanced magnetic resonance imaging (CE-MRI) is crucial for tumor detection and diagnosis, but the use of gadolinium-based contrast agents (GBCAs) in clinical settings raises safety concerns due to potential health risks. To circumvent these issues while preserving diagnostic accuracy, we propose a novel Transformer with Localization Prompts (TLP) framework for synthesizing CE-MRI from non-contrast MR images. Our architecture introduces three key innovations: a hierarchical backbone that uses efficient Transformer to process multi-scale features; a multi-stage fusion system consisting of Local and Global Fusion modules that hierarchically integrate complementary information via spatial attention operations and cross-attention mechanisms, respectively; and a Fuzzy Prompt Generation (FPG) module that enhances the TLP model's generalization by emulating radiologists' manual annotation through stochastic feature perturbation. The framework uniquely enables interactive clinical integration by allowing radiologists to input diagnostic prompts during inference, synergizing artificial intelligence with medical expertise. This research establishes a new paradigm for contrast-free MRI synthesis while addressing critical clinical needs for safer diagnostic procedures. Codes are available at https://github.com/ChanghuiSu/TLP.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Online Reinforcement Learning in Non-Stationary Context-Driven Environments</title>
<link>https://arxiv.org/abs/2302.02182</link>
<guid>https://arxiv.org/abs/2302.02182</guid>
<content:encoded><![CDATA[
<div> 关键词：在线强化学习、非平稳环境、灾难性遗忘、局部约束策略优化、LCPO

总结:
本文研究了在线强化学习在受到时间变化外部上下文影响的非平稳环境中的应用。在这种环境中，由于“灾难性遗忘”现象，智能体容易忘记先前的知识。现有的缓解方法通常假设具有任务标签（而实践中往往不可得）、使用易碎的正则化启发式策略或采用不稳定的离线策略优化方法。为此，文章提出了一种名为局部约束策略优化（LCPO）的在线RL方法，它通过将策略输出锚定在旧经验上，同时优化当前经验上的回报来进行对抗灾难性遗忘。LCPO利用来自当前上下文分布之外的经验样本对策略优化进行局部约束。实验结果表明，LCPO在Mujoco、经典控制和计算机系统环境中，针对各种合成与真实上下文轨迹的非平稳设置下，优于多种基线方法，同时其性能可以与一种具有先见之明的、在所有上下文轨迹上离线训练的智能体相媲美。LCPO的源代码已公开发布在https://github.com/pouyahmdn/LCPO。 <div>
arXiv:2302.02182v3 Announce Type: replace 
Abstract: We study online reinforcement learning (RL) in non-stationary environments, where a time-varying exogenous context process affects the environment dynamics. Online RL is challenging in such environments due to "catastrophic forgetting" (CF). The agent tends to forget prior knowledge as it trains on new experiences. Prior approaches to mitigate this issue assume task labels (which are often not available in practice), employ brittle regularization heuristics or use off-policy methods that suffer from instability and poor performance.
  We present Locally Constrained Policy Optimization (LCPO), an online RL approach that combats CF by anchoring policy outputs on old experiences while optimizing the return on current experiences. To perform this anchoring, LCPO locally constrains policy optimization using samples from experiences that lie outside of the current context distribution. We evaluate LCPO in Mujoco, classic control and computer systems environments with a variety of synthetic and real context traces, and find that it outperforms a variety of baselines in the non-stationary setting, while achieving results on-par with a "prescient" agent trained offline across all context traces.
  LCPO's source code is available at https://github.com/pouyahmdn/LCPO.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive parameter sharing for multi-agent reinforcement learning</title>
<link>https://arxiv.org/abs/2312.09009</link>
<guid>https://arxiv.org/abs/2312.09009</guid>
<content:encoded><![CDATA[
<div> 关键词：参数共享、多智能体系统、环境设置、身份差异、性能提升

<br /><br />总结:
本文提出了一种新的参数共享方法，用于解决大规模智能体问题中的可扩展性问题。该方法受到生物学中大脑研究的启发，针对具有不同身份或任务的智能体，将每种类型的智能体映射到共享网络内的不同区域，从而形成独特的子网络。这样，在不增加额外训练参数的情况下，能够增加不同智能体之间的策略多样性。实验结果显示，与其它参数共享方法相比，本文的方法在多个环境中表现出更好的性能。 <div>
arXiv:2312.09009v2 Announce Type: replace 
Abstract: Parameter sharing, as an important technique in multi-agent systems, can effectively solve the scalability issue in large-scale agent problems. However, the effectiveness of parameter sharing largely depends on the environment setting. When agents have different identities or tasks, naive parameter sharing makes it difficult to generate sufficiently differentiated strategies for agents. Inspired by research pertaining to the brain in biology, we propose a novel parameter sharing method. It maps each type of agent to different regions within a shared network based on their identity, resulting in distinct subnetworks. Therefore, our method can increase the diversity of strategies among different agents without introducing additional training parameters. Through experiments conducted in multiple environments, our method has shown better performance than other parameter sharing methods.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mutual Enhancement of Large Language and Reinforcement Learning Models through Bi-Directional Feedback Mechanisms: A Planning Case Study</title>
<link>https://arxiv.org/abs/2401.06603</link>
<guid>https://arxiv.org/abs/2401.06603</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型 (LLMs)、强化学习 (RL)、教师-学生学习框架、双向反馈循环、任务完成

<br /><br />总结:
本文研究了大规模语言模型（LLMs）与强化学习（RL）模型协作的问题，并提出了一种基于教师-学生学习框架的方法。在这个框架中，LLM充当教师角色，为RL模型提供抽象信息以促进有效探索和策略改进；而RL模型则作为学生，向LLM提供实时反馈，帮助生成更有用的表示。通过这种双向反馈循环机制，双方能够实现优化、探索和相互提升，共同完成更复杂的任务。文章还介绍了一种实用算法并进行了实证实验，以验证该方法的有效性。 <div>
arXiv:2401.06603v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities for reinforcement learning (RL) models, such as planning and reasoning capabilities. However, the problems of LLMs and RL model collaboration still need to be solved. In this study, we employ a teacher-student learning framework to tackle these problems, specifically by offering feedback for LLMs using RL models and providing high-level information for RL models with LLMs in a cooperative multi-agent setting. Within this framework, the LLM acts as a teacher, while the RL model acts as a student. The two agents cooperatively assist each other through a process of recursive help, such as "I help you help I help." The LLM agent supplies abstract information to the RL agent, enabling efficient exploration and policy improvement. In turn, the RL agent offers feedback to the LLM agent, providing valuable, real-time information that helps generate more useful tokens. This bi-directional feedback loop promotes optimization, exploration, and mutual improvement for both agents, enabling them to accomplish increasingly challenging tasks. Remarkably, we propose a practical algorithm to address the problem and conduct empirical experiments to evaluate the effectiveness of our method.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Differentially Private Distributed Inference</title>
<link>https://arxiv.org/abs/2402.08156</link>
<guid>https://arxiv.org/abs/2402.08156</guid>
<content:encoded><![CDATA[
<div> 关键词: 差分隐私、信息交换、学习、临床试验、分布式最大似然估计

总结:
本文探讨了如何在保护隐私的同时让智能体进行信息交换以实现学习。针对医疗保健中心在合作进行临床试验时面临的敏感患者数据保护问题，文章提出使用差分隐私（DP）技术控制信息泄露。通过DP噪声提供合理的否认可能性和严格的性能保证，智能体利用log线性规则更新信念统计。研究了两个场景：有限私有信号集下的分布式最大似然估计（MLE）和来自间歇性信号流的在线学习。在MLE设置中，带有DP噪声的聚合引入了在拒绝低质量状态与接受高质量状态之间的权衡，并适用于具有正式统计保障的二元假设检验。通过模拟实验，文章展示了在真实世界临床试验数据上应用差分隐私、分布式的生存分析方法，有效评估了治疗方法的效果以及生物医学指标对患者生存的影响。相较于同态加密和基于第一阶DP优化的方法，这种方法能更高效地实现隐私保护推理并降低错误率。 <div>
arXiv:2402.08156v5 Announce Type: replace 
Abstract: How can agents exchange information to learn while protecting privacy? Healthcare centers collaborating on clinical trials must balance knowledge sharing with safeguarding sensitive patient data. We address this challenge by using differential privacy (DP) to control information leakage. Agents update belief statistics via log-linear rules, and DP noise provides plausible deniability and rigorous performance guarantees. We study two settings: distributed maximum likelihood estimation (MLE) with a finite set of private signals and online learning from an intermittent signal stream. Noisy aggregation introduces trade-offs between rejecting low-quality states and accepting high-quality ones. The MLE setting naturally applies to binary hypothesis testing with formal statistical guarantees. Through simulations, we demonstrate differentially private, distributed survival analysis on real-world clinical trial data, evaluating treatment efficacy and the impact of biomedical indices on patient survival. Our methods enable privacy-preserving inference with greater efficiency and lower error rates than homomorphic encryption and first-order DP optimization approaches.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SheetAgent: Towards A Generalist Agent for Spreadsheet Reasoning and Manipulation via Large Language Models</title>
<link>https://arxiv.org/abs/2403.03636</link>
<guid>https://arxiv.org/abs/2403.03636</guid>
<content:encoded><![CDATA[
<div> 关键词：电子表格、大语言模型、SheetRM、SheetAgent、实验结果

总结:<br />
本文介绍了电子表格在各领域的广泛应用以及大语言模型在自动处理电子表格任务中的新尝试。为了应对复杂的现实世界挑战，如长跨度操作和多步推理需求，文章提出了SheetRM，一个新的基准测试集，特点在于包含需要推理依赖的操作任务。为了解决这些问题，作者提出了一种名为SheetAgent的创新自主代理系统，该系统由计划器、信息提供器和检索器三个协同模块组成，能够在无需人工交互的情况下通过迭代任务推理和反思实现对电子表格的高级推理与精确操作。实验证明，SheetAgent相比基线方法在多个基准测试上提高了20-40%的成功率，显示出了在电子表格操作和表格推理方面的优越能力。项目网站、数据集和源代码已在指定链接中公开可用。 <div>
arXiv:2403.03636v3 Announce Type: replace 
Abstract: Spreadsheets are ubiquitous across the World Wide Web, playing a critical role in enhancing work efficiency across various domains. Large language model (LLM) has been recently attempted for automatic spreadsheet manipulation but has not yet been investigated in complicated and realistic tasks where reasoning challenges exist (e.g., long horizon manipulation with multi-step reasoning and ambiguous requirements). To bridge the gap with the real-world requirements, we introduce SheetRM, a benchmark featuring long-horizon and multi-category tasks with reasoning-dependent manipulation caused by real-life challenges. To mitigate the above challenges, we further propose SheetAgent, a novel autonomous agent that utilizes the power of LLMs. SheetAgent consists of three collaborative modules: Planner, Informer, and Retriever, achieving both advanced reasoning and accurate manipulation over spreadsheets without human interaction through iterative task reasoning and reflection. Extensive experiments demonstrate that SheetAgent delivers 20--40\% pass rate improvements on multiple benchmarks over baselines, achieving enhanced precision in spreadsheet manipulation and demonstrating superior table reasoning abilities. More details and visualizations are available at the project website: https://sheetagent.github.io/. The datasets and source code are available at https://anonymous.4open.science/r/SheetAgent.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Randomized Exploration in Cooperative Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2404.10728</link>
<guid>https://arxiv.org/abs/2404.10728</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、随机探索、合作型多智能体强化学习、Thompson采样、通信复杂度

总结:
本文首次研究了合作型多智能体强化学习（Cooperative MARL）中可证明有效的随机探索策略。文章提出了一种用于并行马尔科夫决策过程（MDPs）的统一随机探索算法框架，并设计了两种Thompson采样类型的算法——CoopTS-PHE和CoopTS-LMC，分别结合了扰动历史探索（PHE）策略和朗之万蒙特卡洛探索（LMC）策略，这两个算法具有设计灵活和易于实践应用的特点。针对一类过渡模型近似线性的特殊并行MDPs，理论上证明了CoopTS-PHE和CoopTS-LMC可以达到$\widetilde{\mathcal{O}}(d^{3/2}H^2\sqrt{MK})$的遗憾界以及$\widetilde{\mathcal{O}}(dHM^2)$的通信复杂度，其中$d$为特征维度，$H$为时间步长，$M$为智能体数量，$K$为episode数。这是合作型MARL中首个关于随机探索的理论结果。实验结果显示，所提方法在多个并行RL环境中表现出色，包括深搜索问题（如N-chain）、视频游戏以及实际能源系统问题，并且在转移模型不准确的情况下仍能取得良好表现。此外，文中还建立了提出的统一框架与联邦学习的实际应用之间的联系。 <div>
arXiv:2404.10728v2 Announce Type: replace 
Abstract: We present the first study on provably efficient randomized exploration in cooperative multi-agent reinforcement learning (MARL). We propose a unified algorithm framework for randomized exploration in parallel Markov Decision Processes (MDPs), and two Thompson Sampling (TS)-type algorithms, CoopTS-PHE and CoopTS-LMC, incorporating the perturbed-history exploration (PHE) strategy and the Langevin Monte Carlo exploration (LMC) strategy, respectively, which are flexible in design and easy to implement in practice. For a special class of parallel MDPs where the transition is (approximately) linear, we theoretically prove that both CoopTS-PHE and CoopTS-LMC achieve a $\widetilde{\mathcal{O}}(d^{3/2}H^2\sqrt{MK})$ regret bound with communication complexity $\widetilde{\mathcal{O}}(dHM^2)$, where $d$ is the feature dimension, $H$ is the horizon length, $M$ is the number of agents, and $K$ is the number of episodes. This is the first theoretical result for randomized exploration in cooperative MARL. We evaluate our proposed method on multiple parallel RL environments, including a deep exploration problem (i.e., $N$-chain), a video game, and a real-world problem in energy systems. Our experimental results support that our framework can achieve better performance, even under conditions of misspecified transition models. Additionally, we establish a connection between our unified framework and the practical application of federated learning.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Liquid-Graph Time-Constant Network for Multi-Agent Systems Control</title>
<link>https://arxiv.org/abs/2404.13982</link>
<guid>https://arxiv.org/abs/2404.13982</guid>
<content:encoded><![CDATA[
<div> 关键词：Liquid-Graph Time-Constant (LGTC)网络、连续图神经网络(GNN)、多智能体系统控制、Liquid Time Constant (LTC)网络、稳定性分析、收缩分析、封闭形式模型、Graph Gated Neural Networks (GGNNs)、表达力、通信范围可变性、分布式多智能体控制系统、非瞬时通信。

总结:<br />
本文提出了一种名为Liquid-Graph Time-Constant (LGTC)网络的新型连续图神经网络模型，该模型基于最近的Liquid Time Constant (LTC)网络，应用于多智能体系统的控制。通过运用收缩分析方法研究了LGTC网络的稳定性，并设计了一个封闭形式模型，保持了模型的收缩率，无需在每次迭代中求解ODE。相比于如GGNNs等离散模型，LGTC网络由于其更高的表达能力，确保了出色的性能表现，同时减少了GNNs通常所需的大量通信变量。在考虑通信范围变化和非瞬时通信情况下的分布式多智能体控制案例（例如：编队控制）上，对该模型进行了评估并验证了其实现了良好的可扩展性。 <div>
arXiv:2404.13982v3 Announce Type: replace 
Abstract: In this paper, we propose the Liquid-Graph Time-constant (LGTC) network, a continuous graph neural network(GNN) model for control of multi-agent systems based on therecent Liquid Time Constant (LTC) network. We analyse itsstability leveraging contraction analysis and propose a closed-form model that preserves the model contraction rate and doesnot require solving an ODE at each iteration. Compared todiscrete models like Graph Gated Neural Networks (GGNNs),the higher expressivity of the proposed model guaranteesremarkable performance while reducing the large amountof communicated variables normally required by GNNs. Weevaluate our model on a distributed multi-agent control casestudy (flocking) taking into account variable communicationrange and scalability under non-instantaneous communication
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey on Vision-Language-Action Models for Embodied AI</title>
<link>https://arxiv.org/abs/2405.14093</link>
<guid>https://arxiv.org/abs/2405.14093</guid>
<content:encoded><![CDATA[
<div> 关键词：embodied AI、large language models、vision-language-action models (VLAs)、control policies、task planners

<br /><br />总结:
本文是首篇针对视觉-语言-动作模型（VLAs）在具象AI中应用的综合调查论文。VLAs作为人工智能的重要分支，因其在处理基于语言的机器人任务中的独特行动生成能力而受到关注。文章梳理了近年来VLAs的快速发展，将其研究线路主要分为三类：一是关注VLAs的各个组件；二是致力于开发能够预测低级动作的控制策略；三是构建能将长期任务分解为子任务序列的高级任务规划器，使VLAs能遵循更通用的用户指令。此外，文中还详尽汇总了相关的数据集、模拟器和基准测试资源。最后，作者指出了VLAs面临的挑战并提出了具象AI领域有前景的研究方向。 <div>
arXiv:2405.14093v3 Announce Type: replace 
Abstract: Embodied AI is widely recognized as a key element of artificial general intelligence because it involves controlling embodied agents to perform tasks in the physical world. Building on the success of large language models and vision-language models, a new category of multimodal models -- referred to as vision-language-action models (VLAs) -- has emerged to address language-conditioned robotic tasks in embodied AI by leveraging their distinct ability to generate actions. In recent years, a myriad of VLAs have been developed, making it imperative to capture the rapidly evolving landscape through a comprehensive survey. To this end, we present the first survey on VLAs for embodied AI. This work provides a detailed taxonomy of VLAs, organized into three major lines of research. The first line focuses on individual components of VLAs. The second line is dedicated to developing control policies adept at predicting low-level actions. The third line comprises high-level task planners capable of decomposing long-horizon tasks into a sequence of subtasks, thereby guiding VLAs to follow more general user instructions. Furthermore, we provide an extensive summary of relevant resources, including datasets, simulators, and benchmarks. Finally, we discuss the challenges faced by VLAs and outline promising future directions in embodied AI.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive In-conversation Team Building for Language Model Agents</title>
<link>https://arxiv.org/abs/2405.19425</link>
<guid>https://arxiv.org/abs/2405.19425</guid>
<content:encoded><![CDATA[
<div> 关键词: 多语言模型、团队构建、Captain Agent、性能提升、成本分析

总结:
本文提出了一种新的适应性团队构建范式，用于有效解决复杂任务。该范式通过名为Captain Agent的创新代理设计实现，能够在任务解决过程中动态组建和管理团队，利用嵌套小组对话和反思以确保多样化的专家意见并避免刻板输出。研究在六个现实场景中的综合评估显示，Captain Agent相较于现有多代理方法在平均准确率上提高了21.94%，并在无需任务特定提示工程的情况下展现出卓越的性能。此外，文章还探讨了不同后端LLM的使用以及成本分析，表明Captain Agent可以提升弱LLM的对话质量，并以极低的成本实现竞争力的表现，从而揭示了多代理系统应用的新可能。 <div>
arXiv:2405.19425v3 Announce Type: replace 
Abstract: Leveraging multiple large language model (LLM) agents has shown to be a promising approach for tackling complex tasks, while the effective design of multiple agents for a particular application remains an art. It is thus intriguing to answer a critical question: Given a task, how can we build a team of LLM agents to solve it effectively? Our new adaptive team-building paradigm offers a flexible solution, realized through a novel agent design named Captain Agent. It dynamically forms and manages teams for each step of a task-solving process, utilizing nested group conversations and reflection to ensure diverse expertise and prevent stereotypical outputs, allowing for a flexible yet structured approach to problem-solving. A comprehensive evaluation across six real-world scenarios demonstrates that Captain Agent significantly outperforms existing multi-agent methods with 21.94% improvement in average accuracy, providing outstanding performance without requiring task-specific prompt engineering. Our exploration of different backbone LLM and cost analysis further shows that Captain Agent can improve the conversation quality of weak LLM and achieve competitive performance with extremely low cost, which illuminates the application of multi-agent systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>HOPE: A Reinforcement Learning-based Hybrid Policy Path Planner for Diverse Parking Scenarios</title>
<link>https://arxiv.org/abs/2405.20579</link>
<guid>https://arxiv.org/abs/2405.20579</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化停车、路径规划、强化学习、Reeds-Shepp曲线、Transformer

总结:
本文提出了一个名为Hybrid pOlicy Path plannEr (HOPE)的创新解决方案，旨在解决自动驾驶技术中自动化停车的复杂场景处理问题。HOPE将强化学习与Reeds-Shepp曲线相结合，通过应用行动掩码机制和使用Transformer整合环境感知信息，实现对多样化停车场景的有效规划。为了训练和评估该路径规划器，文中提出了一种基于空间和障碍物分布的停车场景难度分类标准。实验结果显示，HOPE在成功率和各种场景下的泛化能力方面优于典型规则基算法和传统强化学习方法，并进行了实车试验验证其实用性。代码已在https://github.com/jiamiya/HOPE上开源发布。 <div>
arXiv:2405.20579v3 Announce Type: replace 
Abstract: Automated parking stands as a highly anticipated application of autonomous driving technology. However, existing path planning methodologies fall short of addressing this need due to their incapability to handle the diverse and complex parking scenarios in reality. While non-learning methods provide reliable planning results, they are vulnerable to intricate occasions, whereas learning-based ones are good at exploration but unstable in converging to feasible solutions. To leverage the strengths of both approaches, we introduce Hybrid pOlicy Path plannEr (HOPE). This novel solution integrates a reinforcement learning agent with Reeds-Shepp curves, enabling effective planning across diverse scenarios. HOPE guides the exploration of the reinforcement learning agent by applying an action mask mechanism and employs a transformer to integrate the perceived environmental information with the mask. To facilitate the training and evaluation of the proposed planner, we propose a criterion for categorizing the difficulty level of parking scenarios based on space and obstacle distribution. Experimental results demonstrate that our approach outperforms typical rule-based algorithms and traditional reinforcement learning methods, showing higher planning success rates and generalization across various scenarios. We also conduct real-world experiments to verify the practicability of HOPE. The code for our solution is openly available on https://github.com/jiamiya/HOPE.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Language Guided Skill Discovery</title>
<link>https://arxiv.org/abs/2406.06615</link>
<guid>https://arxiv.org/abs/2406.06615</guid>
<content:encoded><![CDATA[
<div> 关键词：技能发现、语义多样性、大型语言模型、语言引导技能发现、LGSD

<br />
总结:
本文提出了一个名为“语言引导技能发现”（LGSD）的新框架，用于改进智能体在无明确奖励情况下学习到的行为技能的语义多样性。现有的技能发现方法未能直接关注技能的语义多样性。研究者认为利用大型语言模型（LLMs）的语义知识可以促进技能的语义多样性提升。LGSD框架通过用户输入的提示来生成一组语义上区别明显的技能，并利用LLM产生的输出指导智能体在特定语义子空间中访问多样化的状态。实验结果显示，LGSD能让腿部机器人根据不同的用户提示探索平面上的不同区域，并在机器人臂操作环境中相比于五种现有技能发现方法展现出更丰富的技能多样性。此外，LGSD还提供了一种简单的方法，可以通过自然语言来调用已学习到的技能。 <div>
arXiv:2406.06615v2 Announce Type: replace 
Abstract: Skill discovery methods enable agents to learn diverse emergent behaviors without explicit rewards. To make learned skills useful for unknown downstream tasks, obtaining a semantically diverse repertoire of skills is essential. While some approaches introduce a discriminator to distinguish skills and others aim to increase state coverage, no existing work directly addresses the "semantic diversity" of skills. We hypothesize that leveraging the semantic knowledge of large language models (LLMs) can lead us to improve semantic diversity of resulting behaviors. In this sense, we introduce Language Guided Skill Discovery (LGSD), a skill discovery framework that aims to directly maximize the semantic diversity between skills. LGSD takes user prompts as input and outputs a set of semantically distinctive skills. The prompts serve as a means to constrain the search space into a semantically desired subspace, and the generated LLM outputs guide the agent to visit semantically diverse states within the subspace. We demonstrate that LGSD enables legged robots to visit different user-intended areas on a plane by simply changing the prompt. Furthermore, we show that language guidance aids in discovering more diverse skills compared to five existing skill discovery methods in robot-arm manipulation environments. Lastly, LGSD provides a simple way of utilizing learned skills via natural language.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Identifying User Goals from UI Trajectories</title>
<link>https://arxiv.org/abs/2406.14314</link>
<guid>https://arxiv.org/abs/2406.14314</guid>
<content:encoded><![CDATA[
<div> 关键词：用户目标识别、UI轨迹、任务识别、评价方法、GPT-4、Gemini-1.5 Pro

<br /><br />总结:
本文提出了一种新的任务——从观察到的UI轨迹中识别用户的详细意图，这对于各种个性化设置具有价值。为了支持这项任务，研究者设计了一种新的评估方法，用于判断特定UI环境下的两个意图描述是否可以视为同义表达。同时，利用为UI自动化逆问题设计的数据集进行实验。通过将人类表现与最先进的模型（如GPT-4和Gemini-1.5 Pro）的表现进行对比，结果表明这两个模型在这个任务上的性能均低于人类，显示出该任务的挑战性以及改进空间。这项工作突显了在UI轨迹中识别目标的重要性，并为此领域的进一步探索和发展奠定了基础。 <div>
arXiv:2406.14314v3 Announce Type: replace 
Abstract: Identifying underlying user goals and intents has been recognized as valuable in various personalization-oriented settings, such as personalized agents, improved search responses, advertising, user analytics, and more. In this paper, we propose a new task goal identification from observed UI trajectories aiming to infer the user's detailed intentions when performing a task within UI environments. To support this task, we also introduce a novel evaluation methodology designed to assess whether two intent descriptions can be considered paraphrases within a specific UI environment. Furthermore, we demonstrate how this task can leverage datasets designed for the inverse problem of UI automation, utilizing Android and web datasets for our experiments. To benchmark this task, we compare the performance of humans and state-of-the-art models, specifically GPT-4 and Gemini-1.5 Pro, using our proposed metric. The results reveal that both Gemini and GPT underperform relative to human performance, underscoring the challenge of the proposed task and the significant room for improvement. This work highlights the importance of goal identification within UI trajectories, providing a foundation for further exploration and advancement in this area.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>X5G: An Open, Programmable, Multi-vendor, End-to-end, Private 5G O-RAN Testbed with NVIDIA ARC and OpenAirInterface</title>
<link>https://arxiv.org/abs/2406.15935</link>
<guid>https://arxiv.org/abs/2406.15935</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G、软件化、硬件加速、开放式无线接入网(RAN)、智能控制器<br /><br />总结:
本文介绍了针对第五代(5G)移动通信系统向软件化、可编程和智能化网络转变的研究成果。为实现基于软件组件的公共和私有5G部署，并保持或超越传统单片系统的性能，同时实现定制配置和优化部署的可编程性，关键挑战包括硬件加速提升物理层性能、在RAN中引入可编程元素以及边缘智能控制、精细规划射频(RF)环境及端到端集成与测试。为此，文中详述了开发可编程X5G测试平台的过程，该平台首次部署了基于NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA)、OpenAirInterface (OAI) 和近实时RAN智能控制器(near-real-time RIC)整合的8节点网络。Aerial SDK提供了采用GPU加速的PHY层，通过Small Cell Forum (SCF)功能性应用平台接口(FAPI)与来自OAI开源项目的高层接口相连。E2代理则负责连接到O-RAN软件社区(OSC)的近实时RIC。文章还讨论了软件集成、网络基础设施以及用于RF规划的数字孪生框架，并对使用最多4部商用现成(COTS)智能手机进行每个基站的iPerf和视频流应用程序测试，以及最多25个模拟用户设备(UEs)，测量到了下行链路超过1.65 Gbps和上行链路143 Mbps的小区速率。 <div>
arXiv:2406.15935v2 Announce Type: replace 
Abstract: As Fifth generation (5G) cellular systems transition to softwarized, programmable, and intelligent networks, it becomes fundamental to enable public and private 5G deployments that are (i) primarily based on software components while (ii) maintaining or exceeding the performance of traditional monolithic systems and (iii) enabling programmability through bespoke configurations and optimized deployments. This requires hardware acceleration to scale the Physical (PHY) layer performance, programmable elements in the Radio Access Network (RAN) and intelligent controllers at the edge, careful planning of the Radio Frequency (RF) environment, as well as end-to-end integration and testing. In this paper, we describe how we developed the programmable X5G testbed, addressing these challenges through the deployment of the first 8-node network based on the integration of NVIDIA Aerial RAN CoLab Over-the-Air (ARC-OTA), OpenAirInterface (OAI), and a near-real-time RAN Intelligent Controller (RIC). The Aerial Software Development Kit (SDK) provides the PHY layer, accelerated on Graphics Processing Unit (GPU), with the higher layers from the OAI open-source project interfaced with the PHY through the Small Cell Forum (SCF) Functional Application Platform Interface (FAPI). An E2 agent provides connectivity to the O-RAN Software Community (OSC) near-real-time RIC. We discuss software integration, network infrastructure, and a digital twin framework for RF planning. We then profile the performance with up to 4 Commercial Off-the-Shelf (COTS) smartphones for each base station with iPerf and video streaming applications, as well as up to 25 emulated User Equipments (UEs), measuring a cell rate higher than 1.65 Gbps in downlink and 143 Mbps in uplink.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Disentangling Representations through Multi-task Learning</title>
<link>https://arxiv.org/abs/2407.11249</link>
<guid>https://arxiv.org/abs/2407.11249</guid>
<content:encoded><![CDATA[
<div> 关键词：-disentangled representations -multi-task evidence accumulation classification -recurrent neural networks (RNNs) -transformers -zero-shot out-of-distribution (OOD) generalization

<br /><br />总结:
该文研究了智能体内部如何通过解决多任务证据积累分类任务来自然产生解耦合（或抽象）表示形式的问题。理论与实验证明，当系统能够准确地执行多任务分类估计时，会隐式地形成一种描述底层潜在状态的解耦合表示。文章提出了关于噪音、任务数量和证据积累时间条件下解耦合表示出现的条件，并在训练为多任务处理的循环神经网络(RNNs)中进行了实验验证，结果显示它们学习到了以连续吸引子形式存在的解耦合表示，从而实现对潜因子的零样本(OOD)泛化预测。此外，文章还发现Transformer架构特别适合于生成解耦合表示，这可能解释了其在理解世界方面独特的能力。总之，该框架建立了在生物和人工系统中，胜任多个任务能力与形成可解释的世界模型之间的正式联系，并有助于解释为何深度神经网络(ANNs)经常会达到人类可理解的概念以及如何获得卓越的零样本泛化能力。 <div>
arXiv:2407.11249v3 Announce Type: replace 
Abstract: Intelligent perception and interaction with the world hinges on internal representations that capture its underlying structure (''disentangled'' or ''abstract'' representations). Disentangled representations serve as world models, isolating latent factors of variation in the world along approximately orthogonal directions, thus facilitating feature-based generalization. We provide experimental and theoretical results guaranteeing the emergence of disentangled representations in agents that optimally solve multi-task evidence accumulation classification tasks, canonical in the neuroscience literature. The key conceptual finding is that, by producing accurate multi-task classification estimates, a system implicitly represents a set of coordinates specifying a disentangled representation of the underlying latent state of the data it receives. The theory provides conditions for the emergence of these representations in terms of noise, number of tasks, and evidence accumulation time. We experimentally validate these predictions in RNNs trained to multi-task, which learn disentangled representations in the form of continuous attractors, leading to zero-shot out-of-distribution (OOD) generalization in predicting latent factors. We demonstrate the robustness of our framework across autoregressive architectures, decision boundary geometries and in tasks requiring classification confidence estimation. We find that transformers are particularly suited for disentangling representations, which might explain their unique world understanding abilities. Overall, our framework establishes a formal link between competence at multiple tasks and the formation of disentangled, interpretable world models in both biological and artificial systems, and helps explain why ANNs often arrive at human-interpretable concepts, and how they both may acquire exceptional zero-shot generalization capabilities.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>POGEMA: A Benchmark Platform for Cooperative Multi-Agent Pathfinding</title>
<link>https://arxiv.org/abs/2407.14931</link>
<guid>https://arxiv.org/abs/2407.14931</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-agent reinforcement learning (MARL)，POGEMA，环境生成器，评价协议，基准测试工具

总结:<br />
本文介绍了多智能体强化学习（MARL）近期在解决复杂合作与竞争性多智能体问题上的卓越表现，特别是在涉及少量智能体和全观测性的环境中。然而，对于如多机器人路径规划等传统上采用非学习类经典方法（例如启发式搜索）的任务，目前正被提议使用基于学习或混合方法来解决，但缺乏统一框架进行公平比较。为了解决这一问题，文章提出了POGEMA，这是一个全面的工具集合，包括快速学习环境、问题实例生成器、预定义问题实例集、可视化工具包以及自动评估的基准测试工具。此外，文章还引入并定义了一个评价协议，该协议基于一系列领域相关指标（如成功率和路径长度），使得对多种先进的MARL、搜索基线和混合方法进行公平的多方面比较成为可能。文中展示了对比实验的结果，这些结果涵盖了多种state-of-the-art的MARL、基于搜索及混合方法。 <div>
arXiv:2407.14931v2 Announce Type: replace 
Abstract: Multi-agent reinforcement learning (MARL) has recently excelled in solving challenging cooperative and competitive multi-agent problems in various environments, typically involving a small number of agents and full observability. Moreover, a range of crucial robotics-related tasks, such as multi-robot pathfinding, which have traditionally been approached with classical non-learnable methods (e.g., heuristic search), are now being suggested for solution using learning-based or hybrid methods. However, in this domain, it remains difficult, if not impossible, to conduct a fair comparison between classical, learning-based, and hybrid approaches due to the lack of a unified framework that supports both learning and evaluation. To address this, we introduce POGEMA, a comprehensive set of tools that includes a fast environment for learning, a problem instance generator, a collection of predefined problem instances, a visualization toolkit, and a benchmarking tool for automated evaluation. We also introduce and define an evaluation protocol that specifies a range of domain-related metrics, computed based on primary evaluation indicators (such as success rate and path length), enabling a fair multi-fold comparison. The results of this comparison, which involves a variety of state-of-the-art MARL, search-based, and hybrid methods, are presented.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Building Trust in Mental Health Chatbots: Safety Metrics and LLM-Based Evaluation Tools</title>
<link>https://arxiv.org/abs/2408.04650</link>
<guid>https://arxiv.org/abs/2408.04650</guid>
<content:encoded><![CDATA[
<div> 关键词: 评估框架、心理健康聊天机器人、安全性、可靠性、专家验证

<br /><br />总结:
该研究旨在开发并验证一个确保心理健康聊天机器人的安全性和可靠性的评价框架。研究团队创建了一个包含100条基准问题和理想答案以及5条指导性问题的框架，并通过心理健康发展此框架由健康专家进行验证，并应用于基于GPT-3.5-turbo的聊天机器人上。结果显示，大型语言模型（LLM）评分、实时数据的代理方法和嵌入模型等自动化评价方法中，实时数据访问的代理方法最能与人类评估相一致。遵循标准化、专家验证的框架显著提高了聊天机器人的响应安全性和可靠性。研究强调了针对心理健康聊天机器人制定全面、专家定制的安全性评估指标的重要性，并指出尽管LLMs具有巨大潜力，但仍需谨慎实施以降低风险。未来工作应将评估扩展到准确性、偏见、共情和隐私等方面，以确保对技术在心理健康支持中的负责任集成进行全面评估和建立用户及专业人士的信任。 <div>
arXiv:2408.04650v2 Announce Type: replace 
Abstract: Objective: This study aims to develop and validate an evaluation framework to ensure the safety and reliability of mental health chatbots, which are increasingly popular due to their accessibility, human-like interactions, and context-aware support. Materials and Methods: We created an evaluation framework with 100 benchmark questions and ideal responses, and five guideline questions for chatbot responses. This framework, validated by mental health experts, was tested on a GPT-3.5-turbo-based chatbot. Automated evaluation methods explored included large language model (LLM)-based scoring, an agentic approach using real-time data, and embedding models to compare chatbot responses against ground truth standards. Results: The results highlight the importance of guidelines and ground truth for improving LLM evaluation accuracy. The agentic method, dynamically accessing reliable information, demonstrated the best alignment with human assessments. Adherence to a standardized, expert-validated framework significantly enhanced chatbot response safety and reliability. Discussion: Our findings emphasize the need for comprehensive, expert-tailored safety evaluation metrics for mental health chatbots. While LLMs have significant potential, careful implementation is necessary to mitigate risks. The superior performance of the agentic approach underscores the importance of real-time data access in enhancing chatbot reliability. Conclusion: The study validated an evaluation framework for mental health chatbots, proving its effectiveness in improving safety and reliability. Future work should extend evaluations to accuracy, bias, empathy, and privacy to ensure holistic assessment and responsible integration into healthcare. Standardized evaluations will build trust among users and professionals, facilitating broader adoption and improved mental health support through technology.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Automated Design of Agentic Systems</title>
<link>https://arxiv.org/abs/2408.08435</link>
<guid>https://arxiv.org/abs/2408.08435</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化设计、代理系统、元代理搜索、机器学习、通用智能

<br /><br />总结:
本文提出了一种新兴研究领域——自动化设计代理系统(ADAS)，该领域旨在自动创建强大的代理系统设计，包括发明新的构建模块和/或以新方式组合它们。作者强调了机器学习领域中手工设计解决方案最终会被学习型解决方案取代的趋势。文中重点介绍了一个在ADAS内的未充分探索但具有潜力的方法，即通过编程定义代理人，并利用元代理搜索算法自动发现能够不断编程改进的新代理人。这个算法能够在不断增长的先前发现档案基础上，迭代地创造出具有新颖设计的代理人。实验表明，该方法在编码、科学、数学等多个领域都能创造出超越现有最佳手工设计代理人的性能表现，并且这些由元代理搜索发明的代理人在跨域和模型转移时仍能保持优越性能，显示出了其鲁棒性和普遍性。文章认为，如果安全发展这一方向，自动设计代理系统将有可能带来越来越强大并有益于人类的智能系统。 <div>
arXiv:2408.08435v2 Announce Type: replace 
Abstract: Researchers are investing substantial effort in developing powerful general-purpose agents, wherein Foundation Models are used as modules within agentic systems (e.g. Chain-of-Thought, Self-Reflection, Toolformer). However, the history of machine learning teaches us that hand-designed solutions are eventually replaced by learned solutions. We describe a newly forming research area, Automated Design of Agentic Systems (ADAS), which aims to automatically create powerful agentic system designs, including inventing novel building blocks and/or combining them in new ways. We further demonstrate that there is an unexplored yet promising approach within ADAS where agents can be defined in code and new agents can be automatically discovered by a meta agent programming ever better ones in code. Given that programming languages are Turing Complete, this approach theoretically enables the learning of any possible agentic system: including novel prompts, tool use, workflows, and combinations thereof. We present a simple yet effective algorithm named Meta Agent Search to demonstrate this idea, where a meta agent iteratively programs interesting new agents based on an ever-growing archive of previous discoveries. Through extensive experiments across multiple domains including coding, science, and math, we show that our algorithm can progressively invent agents with novel designs that greatly outperform state-of-the-art hand-designed agents. Importantly, we consistently observe the surprising result that agents invented by Meta Agent Search maintain superior performance even when transferred across domains and models, demonstrating their robustness and generality. Provided we develop it safely, our work illustrates the potential of an exciting new research direction toward automatically designing ever-more powerful agentic systems to benefit humanity.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safeguarding AI Agents: Developing and Analyzing Safety Architectures</title>
<link>https://arxiv.org/abs/2409.03793</link>
<guid>https://arxiv.org/abs/2409.03793</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、安全协议、大型语言模型、风险、安全框架

<br />
总结:
本文关注了由大型语言模型驱动的AI代理在各行各业中的广泛应用所带来的安全性问题，包括潜在的安全隐患、偏见、易受攻击性、透明度缺乏以及生成幻觉等问题。随着AI代理在关键行业领域的普及，强化其安全措施显得愈发重要。文章提出了三个增强AI系统安全性的框架：基于LLM的输入-输出过滤器、内置的安全代理和具有嵌入式安全检查的层级委托系统。通过实现实验框架并针对一组不安全的AI使用案例进行测试，评估了它们在减轻AI部署相关风险方面的有效性。研究结果表明，这些框架能够显著提升AI系统的安全性和防护能力，降低可能造成的有害行为或输出。这项工作为构建安全可靠的AI应用，特别是在自动化操作领域，做出了贡献，并为进一步制定确保AI代理在现实世界中负责任使用的强大保障措施奠定了基础。 <div>
arXiv:2409.03793v3 Announce Type: replace 
Abstract: AI agents, specifically powered by large language models, have demonstrated exceptional capabilities in various applications where precision and efficacy are necessary. However, these agents come with inherent risks, including the potential for unsafe or biased actions, vulnerability to adversarial attacks, lack of transparency, and tendency to generate hallucinations. As AI agents become more prevalent in critical sectors of the industry, the implementation of effective safety protocols becomes increasingly important. This paper addresses the critical need for safety measures in AI systems, especially ones that collaborate with human teams. We propose and evaluate three frameworks to enhance safety protocols in AI agent systems: an LLM-powered input-output filter, a safety agent integrated within the system, and a hierarchical delegation-based system with embedded safety checks. Our methodology involves implementing these frameworks and testing them against a set of unsafe agentic use cases, providing a comprehensive evaluation of their effectiveness in mitigating risks associated with AI agent deployment. We conclude that these frameworks can significantly strengthen the safety and security of AI agent systems, minimizing potential harmful actions or outputs. Our work contributes to the ongoing effort to create safe and reliable AI applications, particularly in automated operations, and provides a foundation for developing robust guardrails to ensure the responsible use of AI agents in real-world applications.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Constrained Bandwidth Observation Sharing for Multi-Robot Navigation in Dynamic Environments via Intelligent Knapsack</title>
<link>https://arxiv.org/abs/2409.09975</link>
<guid>https://arxiv.org/abs/2409.09975</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人导航、动态环境、带宽约束、智能背包(iKnap)、观测分享

总结:<br />
本文提出了一种针对带宽约束下动态环境中多机器人导航的新型最优通信方案——智能背包(iKnap)。该方案将多机器人通信建模为图中推断代理之间的信念传播，并将观察分享的组合优化问题形式化为0/1背包问题，其中每一对机器人的潜在通信被赋予决策效用并权衡其带宽成本。研究使用ROS2和Open Robotics Middleware Framework在模拟的具有人类工人的仓库环境中进行了评估。相比现有的基于广播的最优通信方案，iKnap在场景复杂性增加的情况下仍能显著提高导航性能，同时保持相似的运行时间，并更有效地利用分配的带宽和观测资源，特别是在资源极低和不确定性高的情况下。因此，论文认为，所提出的方案能够使多机器人团队在实际导航问题中的协作更加稳健可靠。 <div>
arXiv:2409.09975v2 Announce Type: replace 
Abstract: Multi-robot navigation is increasingly crucial in various domains, including disaster response, autonomous vehicles, and warehouse and manufacturing automation. Robot teams often must operate in highly dynamic environments and under strict bandwidth constraints imposed by communication infrastructure, rendering effective observation sharing within the system a challenging problem. This paper presents a novel optimal communication scheme, Intelligent Knapsack (iKnap), for multi-robot navigation in dynamic environments under bandwidth constraints. We model multi-robot communication as belief propagation in a graph of inferential agents. We then formulate the combinatorial optimization for observation sharing as a 0/1 knapsack problem, where each potential pairwise communication between robots is assigned a decision-making utility to be weighed against its bandwidth cost, and the system has some cumulative bandwidth limit. We evaluate our approach in a simulated robotic warehouse with human workers using ROS2 and the Open Robotics Middleware Framework. Compared to state-of-the-art broadcast-based optimal communication schemes, iKnap yields significant improvements in navigation performance with respect to scenario complexity while maintaining a similar runtime. Furthermore, iKnap utilizes allocated bandwidth and observational resources more efficiently than existing approaches, especially in very low-resource and high-uncertainty settings. Based on these results, we claim that the proposed method enables more robust collaboration for multi-robot teams in real-world navigation problems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Using High-Level Patterns to Estimate How Humans Predict a Robot will Behave</title>
<link>https://arxiv.org/abs/2409.13533</link>
<guid>https://arxiv.org/abs/2409.13533</guid>
<content:encoded><![CDATA[
<div> 关键词：预测、机器人行为、人类预测、第二秩序理论思维、离散潜在空间

<br /><br />总结:
本文研究了人类对机器人行为预测的理解与建模问题。基于近期的研究发现，人类倾向于通过预测其他智能体的高层次行为来推测其行动意图。为此，文章提出了一种采用第二秩序理论思维方法，使机器人能够估计人类对其行为的预测。该方法将人和机器人的最近轨迹嵌入到一个离散潜在空间中，其中每个元素代表一种特定的行为类型（如并线超车或保持在同一车道）。通过对这个潜在空间中的行为类型进行解码，可以得到与行为类型一致的状态空间向量场。实验结果初步证明了这种方法产生的高层次、粗略的机器人行为预测与实际人类预测相符。文章通过概念验证的模拟测试、对比真实用户预测以及在真实世界交互式驾驶数据集上的实验证明了这一假设的有效性。 <div>
arXiv:2409.13533v2 Announce Type: replace 
Abstract: Humans interacting with robots often form predictions of what the robot will do next. For instance, based on the recent behavior of an autonomous car, a nearby human driver might predict that the car is going to remain in the same lane. It is important for the robot to understand the human's prediction for safe and seamless interaction: e.g., if the autonomous car knows the human thinks it is not merging -- but the autonomous car actually intends to merge -- then the car can adjust its behavior to prevent an accident. Prior works typically assume that humans make precise predictions of robot behavior. However, recent research on human-human prediction suggests the opposite: humans tend to approximate other agents by predicting their high-level behaviors. We apply this finding to develop a second-order theory of mind approach that enables robots to estimate how humans predict they will behave. To extract these high-level predictions directly from data, we embed the recent human and robot trajectories into a discrete latent space. Each element of this latent space captures a different type of behavior (e.g., merging in front of the human, remaining in the same lane) and decodes into a vector field across the state space that is consistent with the underlying behavior type. We hypothesize that our resulting high-level and course predictions of robot behavior will correspond to actual human predictions. We provide initial evidence in support of this hypothesis through proof-of-concept simulations, testing our method's predictions against those of real users, and experiments on a real-world interactive driving dataset.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Offline Model-Based RL via Jointly-Optimized World-Action Model Pretraining</title>
<link>https://arxiv.org/abs/2410.00564</link>
<guid>https://arxiv.org/abs/2410.00564</guid>
<content:encoded><![CDATA[
<div> 关键词：offline reinforcement learning（离线强化学习）、generalist agent（泛化智能体）、world model（世界模型）、JOWA、Atari游戏

总结:
本文提出了一种名为JOWA的联合优化世界行为模型，旨在通过离线强化学习开发能从大规模异构数据集中获取高能力的泛化智能体。该方法受到条件视频生成中世界模型优秀泛化的启发，利用基于图像观察的世界模型来提升对未见过任务的泛化能力。JOWA在多个Atari游戏中使用60亿令牌的数据预先训练了一个具有共享Transformer骨架的世界行为模型，以学习通用表示和决策能力。同时，为了补偿Q值估计误差并寻找更好的策略，文章还提出了一种有效且可并行化的规划算法。实验结果显示，最大规模的JOWA代理仅使用10%的子采样离线数据，就在预训练游戏中达到了78.9%的人类水平性能，平均而言，优于现有大規模离线RL基线31.6%。此外，JOWA可以随着模型容量的增加而具有良好扩展性，并能在每个新游戏中仅使用5k条（约4条轨迹）离线微调数据进行高效迁移学习，展现出优越的泛化性能。相关代码和模型权重将在https://github.com/CJReinforce/JOWA上发布。 <div>
arXiv:2410.00564v3 Announce Type: replace 
Abstract: A significant aspiration of offline reinforcement learning (RL) is to develop a generalist agent with high capabilities from large and heterogeneous datasets. However, prior approaches that scale offline RL either rely heavily on expert trajectories or struggle to generalize to diverse unseen tasks. Inspired by the excellent generalization of world model in conditional video generation, we explore the potential of image observation-based world model for scaling offline RL and enhancing generalization on novel tasks. In this paper, we introduce JOWA: Jointly-Optimized World-Action model, an offline model-based RL agent pretrained on multiple Atari games with 6 billion tokens data to learn general-purpose representation and decision-making ability. Our method jointly optimizes a world-action model through a shared transformer backbone, which stabilize temporal difference learning with large models during pretraining. Moreover, we propose a provably efficient and parallelizable planning algorithm to compensate for the Q-value estimation error and thus search out better policies. Experimental results indicate that our largest agent, with 150 million parameters, achieves 78.9% human-level performance on pretrained games using only 10% subsampled offline data, outperforming existing state-of-the-art large-scale offline RL baselines by 31.6% on averange. Furthermore, JOWA scales favorably with model capacity and can sample-efficiently transfer to novel games using only 5k offline fine-tuning data (approximately 4 trajectories) per game, demonstrating superior generalization. We will release codes and model weights at https://github.com/CJReinforce/JOWA
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LTLf Synthesis on First-Order Agent Programs in Nondeterministic Environments</title>
<link>https://arxiv.org/abs/2410.00726</link>
<guid>https://arxiv.org/abs/2410.00726</guid>
<content:encoded><![CDATA[
<div> 关键词：Golog、非确定性编程、政策合成、线性时态逻辑（LTLf）、游戏理论

总结:<br />
本文研究了在基于情况计算的语言Golog中表达的高阶智能体程序的策略合成问题。与传统假设完全控制环境或依赖增量搜索的方法不同，该文关注于环境非确定性对程序结果有显著影响的场景。文章提出了一种在确保满足以有限轨迹线性时态逻辑（LTLf）表述的临时规范的同时，成功实现给定Golog程序的策略合成方法。通过利用一种表现力强的一阶动作理论类，构建了一个封装程序执行并跟踪目标满足情况的有限游戏领域。采用游戏理论方法来求解这样的策略。实验结果显示，这种方法在具有无限对象和非局部效应的领域中是可行的。这项工作架起了智能体编程和时态逻辑综合之间的桥梁，为非确定性环境中鲁棒的智能体行为提供了一个框架。 <div>
arXiv:2410.00726v3 Announce Type: replace 
Abstract: We investigate the synthesis of policies for high-level agent programs expressed in Golog, a language based on situation calculus that incorporates nondeterministic programming constructs. Unlike traditional approaches for program realization that assume full agent control or rely on incremental search, we address scenarios where environmental nondeterminism significantly influences program outcomes. Our synthesis problem involves deriving a policy that successfully realizes a given Golog program while ensuring the satisfaction of a temporal specification, expressed in Linear Temporal Logic on finite traces (LTLf), across all possible environmental behaviors. By leveraging an expressive class of first-order action theories, we construct a finite game arena that encapsulates program executions and tracks the satisfaction of the temporal goal. A game-theoretic approach is employed to derive such a policy. Experimental results demonstrate this approach's feasibility in domains with unbounded objects and non-local effects. This work bridges agent programming and temporal logic synthesis, providing a framework for robust agent behavior in nondeterministic environments.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Latent Action Priors for Locomotion with Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2410.03246</link>
<guid>https://arxiv.org/abs/2410.03246</guid>
<content:encoded><![CDATA[
<div> 关键词：Deep Reinforcement Learning (深度强化学习), joint-level torque control (关节级扭矩控制), inductive bias (归纳偏置), latent actions (潜行动作), expert demonstrations (专家演示)

总结:<br />
本文提出了一种针对深度强化学习中机器人学习复杂行为的方法，特别关注于关节级扭矩控制的学习问题。该方法通过从少量专家演示数据集中学习得到的潜行动作作为归纳偏置，使得策略能够直接利用专家动作中的知识并促进更有效的探索。实验表明，这种方法下的智能体并不局限于演示中的奖励水平，在转移任务中的性能显著提高。结合风格奖励进行模仿学习后，使用潜行动作先验的智能体能更加精确地复制专家的行为。相关视频和代码已在项目网站上发布。 <div>
arXiv:2410.03246v2 Announce Type: replace 
Abstract: Deep Reinforcement Learning (DRL) enables robots to learn complex behaviors through interaction with the environment. However, due to the unrestricted nature of the learning algorithms, the resulting solutions are often brittle and appear unnatural. This is especially true for learning direct joint-level torque control, as inductive biases are difficult to integrate into the learning process. We propose an inductive bias for learning locomotion that is especially useful for torque control: latent actions learned from a small dataset of expert demonstrations. This prior allows the policy to directly leverage knowledge contained in the expert's actions and facilitates more efficient exploration. We observe that the agent is not restricted to the reward levels of the demonstration, and performance in transfer tasks is improved significantly. Latent action priors combined with style rewards for imitation lead to a closer replication of the expert's behavior. Videos and code are available at https://sites.google.com/view/latent-action-priors.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Steering Large Language Models between Code Execution and Textual Reasoning</title>
<link>https://arxiv.org/abs/2410.03524</link>
<guid>https://arxiv.org/abs/2410.03524</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，文本推理，代码生成，任务解决，方法优化

总结:
本文关注于大型语言模型（LLMs）在文本推理上的局限性，并指出通过直接编码方式能更高效地解决一些基准任务。尽管GPT Code Interpreter和AutoGen等工具展示了将代码生成与执行结合以利用LLMs解决复杂问题的能力，但实验表明现有七种流行的方法在指导LLM进行单或多轮代码或文本生成方面均无最优解。研究发现了模型在处理不同复杂度任务及模型大小变化时选择使用代码还是文本推理的有趣模式，甚至存在反向规模效应现象。此外，LLM编写的代码结果并不总是优于采用文本推理的结果。为解决这些问题，文章提出了三种改进LLM代码/文本生成引导的方法，并对所有方法的成本和运行时间进行了深入探讨。作者认为，引导LLM代码/文本生成的问题对于未来的研究具有重要意义，还有很大的提升空间。项目页面、数据集和代码可在https://yongchao98.github.io/CodeSteer/上获取。 <div>
arXiv:2410.03524v2 Announce Type: replace 
Abstract: While a lot of recent research focuses on enhancing the textual reasoning capabilities of Large Language Models (LLMs) by optimizing the multi-agent framework or reasoning chains, several benchmark tasks can be solved with 100\% success through direct coding, which is more scalable and avoids the computational overhead associated with textual iterating and searching. Textual reasoning has inherent limitations in solving tasks with challenges in math, logics, optimization, and searching, which is unlikely to be solved by simply scaling up the model and data size. The recently released OpenAI GPT Code Interpreter and multi-agent frameworks such as AutoGen have demonstrated remarkable proficiency of integrating code generation and execution to solve complex tasks using LLMs. However, based on our experiments on 7 existing popular methods for steering code/text generation in both single- and multi-turn settings with 14 tasks and 6 types of LLMs (including the new O1-preview), currently there is no optimal method to correctly steer LLMs to write code when needed. We discover some interesting patterns on when models use code vs. textual reasoning with the evolution to task complexity and model sizes, which even result in an astonishingly inverse scaling behavior. We also discover that results from LLM written code are not always better than using textual reasoning, even if the task could be solved through code. To mitigate the above issues, we propose three methods to better steer LLM code/text generation and achieve a notable improvement. The costs of token lengths and runtime are thoroughly discussed for all the methods. We believe the problem of steering LLM code/text generation is critical for future research and has much space for further improvement. Project Page, Datasets, and Codes are available at https://yongchao98.github.io/CodeSteer/.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>KGARevion: An AI Agent for Knowledge-Intensive Biomedical QA</title>
<link>https://arxiv.org/abs/2410.04660</link>
<guid>https://arxiv.org/abs/2410.04660</guid>
<content:encoded><![CDATA[
<div> 关键词: KGARevion、知识图谱、语言模型、医疗推理、准确性

<br /><br />总结:
本文介绍了KGARevion，一种基于知识图谱的智能代理，用于回答知识密集型的医学问题。KGARevion通过利用大型语言模型中的潜在知识生成相关三元组，并结合有依据的知识图谱进行验证，过滤错误信息，确保最终答案的准确性和上下文相关性。相较于缺乏有效验证机制的检索增强生成方法，KGARevion在处理复杂医学查询方面提高了超过5.2%的准确性。实验表明，KGARevion在三个新编纂的不同语义复杂度的医学QA数据集上，将准确性提升了10.4%。此外，该代理能够与不同的大模型和生物医学知识图谱集成，适用于各类知识密集型任务，并在关注非洲医疗服务的新数据集AfriMed-QA上展示了其对未充分代表的医疗情境的出色零样本泛化能力。 <div>
arXiv:2410.04660v2 Announce Type: replace 
Abstract: Biomedical reasoning integrates structured, codified knowledge with tacit, experience-driven insights. Depending on the context, quantity, and nature of available evidence, researchers and clinicians use diverse strategies, including rule-based, prototype-based, and case-based reasoning. Effective medical AI models must handle this complexity while ensuring reliability and adaptability. We introduce KGARevion, a knowledge graph-based agent that answers knowledge-intensive questions. Upon receiving a query, KGARevion generates relevant triplets by leveraging the latent knowledge embedded in a large language model. It then verifies these triplets against a grounded knowledge graph, filtering out errors and retaining only accurate, contextually relevant information for the final answer. This multi-step process strengthens reasoning, adapts to different models of medical inference, and outperforms retrieval-augmented generation-based approaches that lack effective verification mechanisms. Evaluations on medical QA benchmarks show that KGARevion improves accuracy by over 5.2% over 15 models in handling complex medical queries. To further assess its effectiveness, we curated three new medical QA datasets with varying levels of semantic complexity, where KGARevion improved accuracy by 10.4%. The agent integrates with different LLMs and biomedical knowledge graphs for broad applicability across knowledge-intensive tasks. We evaluated KGARevion on AfriMed-QA, a newly introduced dataset focused on African healthcare, demonstrating its strong zero-shot generalization to underrepresented medical contexts.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Navigating the Digital World as Humans Do: Universal Visual Grounding for GUI Agents</title>
<link>https://arxiv.org/abs/2410.05243</link>
<guid>https://arxiv.org/abs/2410.05243</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大型语言模型、图形用户界面、视觉定位模型、数据集、UGround

总结:
本文关注多模态大型语言模型在图形用户界面(GUI)代理中的应用，强调了GUI代理的环境理解能力对其效能的重要性。研究提出了一种全新方案，即赋予GUI代理类人的视觉感知能力，直接进行像素级操作，通过视觉定位模型准确映射GUI元素的多样性指代表达与其在GUI上的坐标。为训练此类视觉定位模型，作者构建了一个迄今为止最大的GUI视觉定位数据集，包含了1000万个GUI元素及其在130万个截图上的指代表达。基于此，他们开发了UGround，一种适用于GUI代理的通用视觉定位模型。实验证明，UGround在六个基准测试中大幅超越现有GUI视觉定位模型（最高提升20%绝对值），并且仅依赖于视觉感知的UGround驱动的代理也能超越使用额外文本输入的state-of-the-art代理。这些结果有力支持了GUI代理以人类方式导航数字世界的方法的可行性和前景。 <div>
arXiv:2410.05243v2 Announce Type: replace 
Abstract: Multimodal large language models (MLLMs) are transforming the capabilities of graphical user interface (GUI) agents, facilitating their transition from controlled simulations to complex, real-world applications across various platforms. However, the effectiveness of these agents hinges on the robustness of their grounding capability. Current GUI agents predominantly utilize text-based representations such as HTML or accessibility trees, which, despite their utility, often introduce noise, incompleteness, and increased computational overhead. In this paper, we advocate a human-like embodiment for GUI agents that perceive the environment entirely visually and directly perform pixel-level operations on the GUI. The key is visual grounding models that can accurately map diverse referring expressions of GUI elements to their coordinates on the GUI across different platforms. We show that a simple recipe, which includes web-based synthetic data and slight adaptation of the LLaVA architecture, is surprisingly effective for training such visual grounding models. We collect the largest dataset for GUI visual grounding so far, containing 10M GUI elements and their referring expressions over 1.3M screenshots, and use it to train UGround, a strong universal visual grounding model for GUI agents. Empirical results on six benchmarks spanning three categories (grounding, offline agent, and online agent) show that 1) UGround substantially outperforms existing visual grounding models for GUI agents, by up to 20% absolute, and 2) agents with UGround outperform state-of-the-art agents, despite the fact that existing agents use additional text-based input while ours only uses visual perception. These results provide strong support for the feasibility and promises of GUI agents that navigate the digital world as humans do.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MOOSE-Chem: Large Language Models for Rediscovering Unseen Chemistry Scientific Hypotheses</title>
<link>https://arxiv.org/abs/2410.07076</link>
<guid>https://arxiv.org/abs/2410.07076</guid>
<content:encoded><![CDATA[
<div> 关键词: LLMs、化学研究假设、自动发现、基准构建、多智能体框架

总结:
本文探讨了LLMs（大型语言模型）能否基于化学研究背景自动生成新颖且有效的化学研究假设。研究表明大多数化学假设可以由研究背景和若干灵感产生。为此，作者提出了三个子问题进行探究：1.LLMs能否从背景中检索到好的灵感；2.结合背景与灵感，LLMs是否能生成假设；3.LLMs能否识别并优先排列好的假设。为了解答这些问题，作者构建了一个包含2024年发表于Nature、Science等顶级期刊上的51篇化学论文的基准数据集，这些论文被化学博士生分为背景、灵感和假设三部分。文章进一步提出了一种基于LLM的多智能体框架，该框架分为三个阶段，对应上述三个子问题。实验结果显示，该方法能够以高相似度重新发现许多与真相接近的假设，涵盖了主要创新点。 <div>
arXiv:2410.07076v4 Announce Type: replace 
Abstract: Scientific discovery contributes largely to human society's prosperity, and recent progress shows that LLMs could potentially catalyze this process. However, it is still unclear whether LLMs can discover novel and valid hypotheses in chemistry. In this work, we investigate this central research question: Can LLMs automatically discover novel and valid chemistry research hypotheses given only a chemistry research background (consisting of a research question and/or a background survey), without limitation on the domain of the research question? After extensive discussions with chemistry experts, we propose an assumption that a majority of chemistry hypotheses can be resulted from a research background and several inspirations. With this key insight, we break the central question into three smaller fundamental questions. In brief, they are: (1) given a background question, whether LLMs can retrieve good inspirations; (2) with background and inspirations, whether LLMs can lead to hypothesis; and (3) whether LLMs can identify good hypotheses to rank them higher. To investigate these questions, we construct a benchmark consisting of 51 chemistry papers published in Nature, Science, or a similar level in 2024 (all papers are only available online since 2024). Every paper is divided by chemistry PhD students into three components: background, inspirations, and hypothesis. The goal is to rediscover the hypothesis, given only the background and a large randomly selected chemistry literature corpus consisting the ground truth inspiration papers, with LLMs trained with data up to 2023. We also develop an LLM-based multi-agent framework that leverages the assumption, consisting of three stages reflecting the three smaller questions. The proposed method can rediscover many hypotheses with very high similarity with the ground truth ones, covering the main innovations.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MACPO: Weak-to-Strong Alignment via Multi-Agent Contrastive Preference Optimization</title>
<link>https://arxiv.org/abs/2410.07672</link>
<guid>https://arxiv.org/abs/2410.07672</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、弱监督、强弱对齐、多智能体对比性偏好优化、HH-RLHF、PKU-SafeRLHF

总结:<br />
本文关注于如何在大型语言模型（LLMs）超越人类能力的任务场景中，实现对其的紧急价值对齐问题。由于现有的对齐方法主要集中在强到弱以及自我对齐的设置上，对于更困难的弱到强对齐场景并不适用。为填补这一空白，文章提出了一种名为多智能体对比性偏好优化（MACPO）的框架。MACPO通过迭代强化不熟悉的正向行为并惩罚熟悉的负向行为，使弱教师和强学生能够相互学习。具体来说，文章设计了互惠正向行为增强策略，促使两者从对方的正向行为中学习，并为下一轮迭代提供更高质的正向行为。此外，还提出了构建负向行为的困难策略，通过对负向行为数据进行微调，诱导弱教师和强学生生成熟悉的负向行为。实验结果在HH-RLHF和PKU-SafeRLHF数据集上的自动指标及人类判断显示，MACPO成功地同时提升了强学生和弱教师的对齐性能。随着弱教师数量的增加，MACPO通过更多的迭代优化轮次实现了更好的弱到强对齐效果。 <div>
arXiv:2410.07672v2 Announce Type: replace 
Abstract: As large language models (LLMs) are rapidly advancing and achieving near-human capabilities on specific tasks, aligning them with human values is becoming more urgent. In scenarios where LLMs outperform humans, we face a weak-to-strong alignment problem where we need to effectively align strong student LLMs through weak supervision generated by weak teachers. Existing alignment methods mainly focus on strong-to-weak alignment and self-alignment settings, and it is impractical to adapt them to the much harder weak-to-strong alignment setting. To fill this gap, we propose a multi-agent contrastive preference optimization (MACPO) framework. MACPO facilitates weak teachers and strong students to learn from each other by iteratively reinforcing unfamiliar positive behaviors while penalizing familiar negative ones. To get this, we devise a mutual positive behavior augmentation strategy to encourage weak teachers and strong students to learn from each other's positive behavior and further provide higher quality positive behavior for the next iteration. Additionally, we propose a hard negative behavior construction strategy to induce weak teachers and strong students to generate familiar negative behavior by fine-tuning on negative behavioral data. Experimental results on the HH-RLHF and PKU-SafeRLHF datasets, evaluated using both automatic metrics and human judgments, demonstrate that MACPO simultaneously improves the alignment performance of strong students and weak teachers. Moreover, as the number of weak teachers increases, MACPO achieves better weak-to-strong alignment performance through more iteration optimization rounds.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Facilitating Multi-turn Function Calling for LLMs via Compositional Instruction Tuning</title>
<link>https://arxiv.org/abs/2410.12952</link>
<guid>https://arxiv.org/abs/2410.12952</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、多轮函数调用、BUTTON、合成指令调整数据、多代理环境

<br /><br />总结:
本文探讨了大型语言模型（LLMs）在处理涉及计划与函数使用的复杂现实世界查询时，进行多轮函数调用的必要性。为实现这一目标，文章提出了名为BUTTON的方法，该方法通过自下而上的指令构造和自上而下的轨迹生成生成合成的复合指令调整数据。在自下而上的阶段，基于真实场景生成简单的原子任务，并使用基于原子任务的启发式策略构建复合任务及相应的函数定义。而在自上而下的阶段，利用一个多代理环境，模拟人类、助手和工具之间的交互来收集多轮函数调用轨迹。这确保了任务的组合性和有效函数及轨迹生成。文章创建了一个包含8k数据点的BUTTONInstruct数据集，并通过广泛的实验验证了其有效性。 <div>
arXiv:2410.12952v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) have exhibited significant potential in performing diverse tasks, including the ability to call functions or use external tools to enhance their performance. While current research on function calling by LLMs primarily focuses on single-turn interactions, this paper addresses the overlooked necessity for LLMs to engage in multi-turn function calling--critical for handling compositional, real-world queries that require planning with functions but not only use functions. To facilitate this, we introduce an approach, BUTTON, which generates synthetic compositional instruction tuning data via bottom-up instruction construction and top-down trajectory generation. In the bottom-up phase, we generate simple atomic tasks based on real-world scenarios and build compositional tasks using heuristic strategies based on atomic tasks. Corresponding function definitions are then synthesized for these compositional tasks. The top-down phase features a multi-agent environment where interactions among simulated humans, assistants, and tools are utilized to gather multi-turn function calling trajectories. This approach ensures task compositionality and allows for effective function and trajectory generation by examining atomic tasks within compositional tasks. We produce a dataset BUTTONInstruct comprising 8k data points and demonstrate its effectiveness through extensive experiments across various LLMs.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MobA: Multifaceted Memory-Enhanced Adaptive Planning for Efficient Mobile Task Automation</title>
<link>https://arxiv.org/abs/2410.13757</link>
<guid>https://arxiv.org/abs/2410.13757</guid>
<content:encoded><![CDATA[
<div> 关键词: Multimodal Large Language Model (MLLM), GUI交互, 移动助手系统, 自适应规划模块, MobBench<br /><br />总结:
本文提出了一种名为MobA的新颖的基于Multimodal Large Language Model (MLLM)的移动助手系统，旨在解决当前MLLM代理处理复杂GUI交互问题的挑战。MobA引入了自适应规划模块，该模块具有反思机制以实现错误恢复，并能根据实际环境上下文和动作模块执行能力动态调整计划。同时，为了提高适应性和效率，文章还设计了一个多方面记忆模块。此外，为了解决此类复杂任务的评测需求，作者们推出了用于复杂移动交互的MobBench数据集。实验结果显示，MobA在处理动态GUI环境及执行复杂移动任务上表现出了出色的能力。 <div>
arXiv:2410.13757v2 Announce Type: replace 
Abstract: Existing Multimodal Large Language Model (MLLM)-based agents face significant challenges in handling complex GUI (Graphical User Interface) interactions on devices. These challenges arise from the dynamic and structured nature of GUI environments, which integrate text, images, and spatial relationships, as well as the variability in action spaces across different pages and tasks. To address these limitations, we propose MobA, a novel MLLM-based mobile assistant system. MobA introduces an adaptive planning module that incorporates a reflection mechanism for error recovery and dynamically adjusts plans to align with the real environment contexts and action module's execution capacity. Additionally, a multifaceted memory module provides comprehensive memory support to enhance adaptability and efficiency. We also present MobBench, a dataset designed for complex mobile interactions. Experimental results on MobBench and AndroidArena demonstrate MobA's ability to handle dynamic GUI environments and perform complex mobile task.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MARLIN: Multi-Agent Reinforcement Learning Guided by Language-Based Inter-Robot Negotiation</title>
<link>https://arxiv.org/abs/2410.14383</link>
<guid>https://arxiv.org/abs/2410.14383</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、语言引导的机器人谈判、MARLIN、训练速度、性能

总结:
本文介绍了Multi-Agent Reinforcement Learning guided by Language-based Inter-Robot Negotiation (MARLIN)方法，这是一种能加快训练速度并提高透明度的多机器人系统训练方案。通过为机器人配备大型语言模型进行基于语言的谈判和辩论以制定任务计划，指导强化学习策略的训练过程，并在训练期间动态切换使用强化学习与谈判策略。这种方法相较于传统的多智能体强化学习，能更快地完成训练，使系统更早部署到实际硬件中。由于机器人以自然语言进行谈判，我们可以更好地理解单个机器人及集体的行为表现。实验对比表明，该混合方法在几乎不牺牲性能的前提下，能显著提升训练效率。 <div>
arXiv:2410.14383v2 Announce Type: replace 
Abstract: Multi-agent reinforcement learning is a key method for training multi-robot systems over a series of episodes in which robots are rewarded or punished according to their performance; only once the system is trained to a suitable standard is it deployed in the real world. If the system is not trained enough, the task will likely not be completed and could pose a risk to the surrounding environment. Therefore, reaching high performance in a shorter training period can lead to significant reductions in time and resource consumption. We introduce Multi-Agent Reinforcement Learning guided by Language-based Inter-Robot Negotiation (MARLIN), which makes the training process both faster and more transparent. We equip robots with large language models that negotiate and debate the task, producing a plan that is used to guide the policy during training. We dynamically switch between using reinforcement learning and the negotiation-based approach throughout training. This offers an increase in training speed when compared to standard multi-agent reinforcement learning and allows the system to be deployed to physical hardware earlier. As robots negotiate in natural language, we can better understand the behaviour of the robots individually and as a collective. We compare the performance of our approach to multi-agent reinforcement learning and a large language model to show that our hybrid method trains faster at little cost to performance.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DFlow: Diverse Dialogue Flow Simulation with Large Language Models</title>
<link>https://arxiv.org/abs/2410.14853</link>
<guid>https://arxiv.org/abs/2410.14853</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据模拟、语言模型、任务逻辑多样性、决策树结构、对话流

总结:
本文提出了一种新的数据模拟方法，旨在通过关注任务执行逻辑来增强合成对话的多样性。该方法利用LLMs生成决策树结构的任务计划，从而为给定任务导出多样化的对话轨迹，即“对话流”。这种方法被应用于生成涵盖15个不同领域的3,886个对话流的任务导向型对话数据集。实验结果表明，使用该数据集微调后的模型在下一个动作预测任务上优于包括GPT-4在内的强基线模型。论文作者计划在文章被接受后公开发布相关代码和数据。<br /><br /> <div>
arXiv:2410.14853v2 Announce Type: replace 
Abstract: Developing language model-based dialogue agents requires effective data to train models that can follow specific task logic. However, most existing data simulation methods focus on increasing diversity in language, topics, or dialogue acts at the utterance level, largely neglecting a critical aspect of task logic diversity at the dialogue level. This paper proposes a novel data simulation method designed to enhance the diversity of synthetic dialogues by focusing on task execution logic. Our method uses LLMs to generate decision tree-structured task plans, which enables the derivation of diverse dialogue trajectories for a given task. Each trajectory, referred to as a "dialog flow", guides the generation of a multi-turn dialogue that follows a unique trajectory. We apply this method to generate a task-oriented dialogue dataset comprising 3,886 dialogue flows across 15 different domains. We validate the effectiveness of this dataset using the next action prediction task, where models fine-tuned on our dataset outperform strong baselines, including GPT-4. Upon acceptance of this paper, we plan to release the code and data publicly.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SWE-Search: Enhancing Software Agents with Monte Carlo Tree Search and Iterative Refinement</title>
<link>https://arxiv.org/abs/2410.20285</link>
<guid>https://arxiv.org/abs/2410.20285</guid>
<content:encoded><![CDATA[
<div> 关键词：SWE-Search、多智能体框架、蒙特卡洛树搜索（MCTS）、大型语言模型（LLM）、软件工程任务

<br /><br />总结：

本文提出了一种名为SWE-Search的多智能体框架，旨在解决复杂动态环境中软件工程师面临的挑战。该框架将蒙特卡洛树搜索（MCTS）与自改进机制相结合，以增强软件代理在处理仓库级软件任务中的性能。SWE-Search通过引入融合了LLMs的混合价值函数，实现了对数值和定性评估的结合，从而允许代理在执行过程中进行迭代策略调整。框架包含了三个关键组件：适应性探索的SWE-Agent、用于迭代反馈的价值Agent以及促进多智能体协同决策的鉴别器Agent。实验证明，相较于没有使用MCTS的标准开源代理，SWE-Search在SWE-bench基准测试中表现出了23%的相对性能提升。此外，分析表明，随着推理时间计算能力的增加，性能可通过深入搜索得到提高，这为在复杂软件工程环境下改进软件代理提供了一条无需更大规模模型或额外训练数据的途径。 <div>
arXiv:2410.20285v5 Announce Type: replace 
Abstract: Software engineers operating in complex and dynamic environments must continuously adapt to evolving requirements, learn iteratively from experience, and reconsider their approaches based on new insights. However, current large language model (LLM)-based software agents often follow linear, sequential processes that prevent backtracking and exploration of alternative solutions, limiting their ability to rethink their strategies when initial approaches prove ineffective. To address these challenges, we propose SWE-Search, a multi-agent framework that integrates Monte Carlo Tree Search (MCTS) with a self-improvement mechanism to enhance software agents' performance on repository-level software tasks. SWE-Search extends traditional MCTS by incorporating a hybrid value function that leverages LLMs for both numerical value estimation and qualitative evaluation. This enables self-feedback loops where agents iteratively refine their strategies based on both quantitative numerical evaluations and qualitative natural language assessments of pursued trajectories. The framework includes a SWE-Agent for adaptive exploration, a Value Agent for iterative feedback, and a Discriminator Agent that facilitates multi-agent debate for collaborative decision-making. Applied to the SWE-bench benchmark, our approach demonstrates a 23% relative improvement in performance across five models compared to standard open-source agents without MCTS. Our analysis reveals how performance scales with increased inference-time compute through deeper search, providing a pathway to improve software agents without requiring larger models or additional training data. This highlights the potential of self-evaluation driven search techniques in complex software engineering environments.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VisualPredicator: Learning Abstract World Models with Neuro-Symbolic Predicates for Robot Planning</title>
<link>https://arxiv.org/abs/2410.23156</link>
<guid>https://arxiv.org/abs/2410.23156</guid>
<content:encoded><![CDATA[
<div> 关键词：神经符号谓词、抽象语言、智能代理、强化学习、模拟机器人领域

<br />
总结:
本文介绍了Neuro-Symbolic Predicates，一种结合符号和神经知识表示的第一阶抽象语言。文章提出了一种在线算法，用于发明这种谓词并学习抽象世界模型。与层次强化学习、视觉语言模型规划及符号谓词发明方法相比，该方法在五个模拟机器人领域的内外部任务上表现出更好的样本复杂性、更强的泛化能力和更高的可解释性。 <div>
arXiv:2410.23156v2 Announce Type: replace 
Abstract: Broadly intelligent agents should form task-specific abstractions that selectively expose the essential elements of a task, while abstracting away the complexity of the raw sensorimotor space. In this work, we present Neuro-Symbolic Predicates, a first-order abstraction language that combines the strengths of symbolic and neural knowledge representations. We outline an online algorithm for inventing such predicates and learning abstract world models. We compare our approach to hierarchical reinforcement learning, vision-language model planning, and symbolic predicate invention approaches, on both in- and out-of-distribution tasks across five simulated robotic domains. Results show that our approach offers better sample complexity, stronger out-of-distribution generalization, and improved interpretability.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Kinetix: Investigating the Training of General Agents through Open-Ended Physics-Based Control Tasks</title>
<link>https://arxiv.org/abs/2410.23208</link>
<guid>https://arxiv.org/abs/2410.23208</guid>
<content:encoded><![CDATA[
<div> 关键词：自我监督学习，强化学习，物理控制，Kinetix，Jax2D

总结:
本文提出了一种针对序列决策问题中实现与文本和图像领域相似泛化能力的方法。研究者通过生成数千万个基于物理的2D任务并使用它们训练一个通用强化学习（RL）代理进行物理控制。为此，他们引入了Kinetix——一个统一框架下的开放性物理RL环境空间，能代表从机器人运动和抓取到视频游戏和经典RL环境等各种任务。文章还介绍了一个新的硬件加速物理引擎Jax2D，该引擎能在训练过程中廉价地模拟数十亿次环境步骤。经过训练的代理表现出强大的物理推理能力，能够在零样本情况下解决未见的人类设计环境。此外，对这个通用代理进行微调后的表现远超从零开始训练的RL代理，甚至成功解决了标准RL训练无法完成的一些环境。研究表明，大规模、混合质量的预训练对于在线RL是可行的，而Kinetix有望成为进一步探究这一领域的有用框架。 <div>
arXiv:2410.23208v2 Announce Type: replace 
Abstract: While large models trained with self-supervised learning on offline datasets have shown remarkable capabilities in text and image domains, achieving the same generalisation for agents that act in sequential decision problems remains an open challenge. In this work, we take a step towards this goal by procedurally generating tens of millions of 2D physics-based tasks and using these to train a general reinforcement learning (RL) agent for physical control. To this end, we introduce Kinetix: an open-ended space of physics-based RL environments that can represent tasks ranging from robotic locomotion and grasping to video games and classic RL environments, all within a unified framework. Kinetix makes use of our novel hardware-accelerated physics engine Jax2D that allows us to cheaply simulate billions of environment steps during training. Our trained agent exhibits strong physical reasoning capabilities in 2D space, being able to zero-shot solve unseen human-designed environments. Furthermore, fine-tuning this general agent on tasks of interest shows significantly stronger performance than training an RL agent *tabula rasa*. This includes solving some environments that standard RL training completely fails at. We believe this demonstrates the feasibility of large scale, mixed-quality pre-training for online RL and we hope that Kinetix will serve as a useful framework to investigate this further.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CaPo: Cooperative Plan Optimization for Efficient Embodied Multi-Agent Cooperation</title>
<link>https://arxiv.org/abs/2411.04679</link>
<guid>https://arxiv.org/abs/2411.04679</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、合作问题、Cooperative Plan Optimization (CaPo)、元计划生成、执行适应性调整

<br /><br />总结：

本文提出了一种用于增强基于大规模语言模型的化身智能体之间合作效率的方法——Cooperative Plan Optimization (CaPo)。针对以往方法中智能体行动缺乏长期战略性与协作规划的问题，CaPo方案包括两个阶段：一是元计划生成阶段，所有智能体会分析任务、讨论并共同创建一个将任务分解为详细步骤的子任务元计划，确保有条不紊地进行长期战略协调；二是执行适应性调整阶段，智能体根据元计划执行任务，并能依据最新的进度（如发现目标物体）通过多轮讨论动态调整元计划，从而消除冗余动作，提高整体协作效率。实验结果表明，CaPo在ThreeDworld Multi-Agent Transport和Communicative Watch-And-Help任务上相比于现有最优方法表现出更高的任务完成率和效率。代码已在https://github.com/jliu4ai/CaPo发布。 <div>
arXiv:2411.04679v2 Announce Type: replace 
Abstract: In this work, we address the cooperation problem among large language model (LLM) based embodied agents, where agents must cooperate to achieve a common goal. Previous methods often execute actions extemporaneously and incoherently, without long-term strategic and cooperative planning, leading to redundant steps, failures, and even serious repercussions in complex tasks like search-and-rescue missions where discussion and cooperative plan are crucial. To solve this issue, we propose Cooperative Plan Optimization (CaPo) to enhance the cooperation efficiency of LLM-based embodied agents. Inspired by human cooperation schemes, CaPo improves cooperation efficiency with two phases: 1) meta-plan generation, and 2) progress-adaptive meta-plan and execution. In the first phase, all agents analyze the task, discuss, and cooperatively create a meta-plan that decomposes the task into subtasks with detailed steps, ensuring a long-term strategic and coherent plan for efficient coordination. In the second phase, agents execute tasks according to the meta-plan and dynamically adjust it based on their latest progress (e.g., discovering a target object) through multi-turn discussions. This progress-based adaptation eliminates redundant actions, improving the overall cooperation efficiency of agents. Experimental results on the ThreeDworld Multi-Agent Transport and Communicative Watch-And-Help tasks demonstrate that CaPo achieves much higher task completion rate and efficiency compared with state-of-the-arts.The code is released at https://github.com/jliu4ai/CaPo.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChemToolAgent: The Impact of Tools on Language Agents for Chemistry Problem Solving</title>
<link>https://arxiv.org/abs/2411.07228</link>
<guid>https://arxiv.org/abs/2411.07228</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 化学问题解决, 工具增强, ChemCrow, ChemToolAgent

<br /><br />总结:
为了提升大型语言模型（LLMs）在化学问题解决方面的能力，已经提出了几种工具增强的LLM基代理，如ChemCrow和Coscientist。然而，这些评估范围狭窄，对于工具在各种化学任务中的效益理解存在较大差距。为填补这一空白，研究者开发了在ChemCrow基础上增强的化学代理ChemToolAgent，并对其在专业化学任务及一般化学问题上的性能进行了全面评估。结果令人惊讶地发现，ChemToolAgent并不总是优于未使用工具的基础LLMs。通过与化学专家的错误分析表明：对于专门的化学任务（例如合成预测），应当使用专门的工具增强代理；然而，对于诸如考试中出现的一般性化学问题，代理人正确运用化学知识进行推理的能力更为重要，而工具增强并不总是有帮助。 <div>
arXiv:2411.07228v2 Announce Type: replace 
Abstract: To enhance large language models (LLMs) for chemistry problem solving, several LLM-based agents augmented with tools have been proposed, such as ChemCrow and Coscientist. However, their evaluations are narrow in scope, leaving a large gap in understanding the benefits of tools across diverse chemistry tasks. To bridge this gap, we develop ChemToolAgent, an enhanced chemistry agent over ChemCrow, and conduct a comprehensive evaluation of its performance on both specialized chemistry tasks and general chemistry questions. Surprisingly, ChemToolAgent does not consistently outperform its base LLMs without tools. Our error analysis with a chemistry expert suggests that: For specialized chemistry tasks, such as synthesis prediction, we should augment agents with specialized tools; however, for general chemistry questions like those in exams, agents' ability to reason correctly with chemistry knowledge matters more, and tool augmentation does not always help.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Destabilizing a Social Network Model via Intrinsic Feedback Vulnerabilities</title>
<link>https://arxiv.org/abs/2411.10868</link>
<guid>https://arxiv.org/abs/2411.10868</guid>
<content:encoded><![CDATA[
<div> 关键词: 社会影响、生成式AI、社交网络、动态结构函数、稳定性

<br /><br />总结:
本文探讨了社会影响在网络中塑造个体情绪和行为的重要性，特别是在数字化连接日益普及的时代。随着生成式AI技术的发展，对利用此类技术大规模实施社交媒体激进化策略的担忧增加。研究采用泰勒的经典社会影响力模型和鲁棒控制理论中的动态结构函数工具，分析了针对简单社交网络的小而有意图的扰动效果。通过模拟现有链接的微小扰动和引入新链接的情况，研究发现只需极小的目标性结构调整，就可能引发所有节点的激进化，进而展示出大规模集体行为转变可能由相对微小的社会影响力调整触发的现象。鉴于这种方法可应用于任何合适的动态系统，文章呼吁应对现实系统的类似动态进行分析，以便识别可能已存在此类动力学现象的地方。 <div>
arXiv:2411.10868v3 Announce Type: replace 
Abstract: Social influence plays a significant role in shaping individual sentiments and actions, particularly in a world of ubiquitous digital interconnection. The rapid development of generative AI has engendered well-founded concerns regarding the potential scalable implementation of radicalization techniques in social media. Motivated by these developments, we present a case study investigating the effects of small but intentional perturbations on a simple social network. We employ Taylor's classic model of social influence and tools from robust control theory (most notably the Dynamical Structure Function (DSF)), to identify perturbations that qualitatively alter the system's behavior while remaining as unobtrusive as possible. We examine two such scenarios: perturbations to an existing link and perturbations that introduce a new link to the network. In each case, we identify destabilizing perturbations of minimal norm and simulate their effects. Remarkably, we find that small but targeted alterations to network structure may lead to the radicalization of all agents, exhibiting the potential for large-scale shifts in collective behavior to be triggered by comparatively minuscule adjustments in social influence. Given that this method of identifying perturbations that are innocuous yet destabilizing applies to any suitable dynamical system, our findings emphasize a need for similar analyses to be carried out on real systems (e.g., real social networks), to identify the places where such dynamics may already exist.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Two-agent Motion Planning Strategies from Generalized Nash Equilibrium for Model Predictive Control</title>
<link>https://arxiv.org/abs/2411.13983</link>
<guid>https://arxiv.org/abs/2411.13983</guid>
<content:encoded><![CDATA[
<div> 关键词：Implicit Game-Theoretic MPC (IGT-MPC)，多智能体运动规划，模型预测控制（MPC），动态博弈，神经网络

总结：<br />
本文提出了一个名为隐式博弈论模型预测控制（IGT-MPC）的去中心化算法，用于解决双智能体运动规划问题。该方法利用学习得到的价值函数作为MPC框架中的终端成本函数，使智能体能够考虑到与其他智能体的交互并最大化其奖励。研究将多智能体运动规划问题形式化为约束动态博弈，并通过随机采样初始条件求解广义纳什均衡（GNE）来生成包含游戏结果的数据集。这些数据被用来训练一个简单的神经网络，以预测交互的奖励结果，进而将其应用于MPC方案的终端成本函数中。文章通过两车竞速和无信号灯交叉口导航等场景展示了IGT-MPC实现的竞争与协调行为。这种方法提供了一种新的融合机器学习和博弈论推理到基于模型的分布式多智能体运动规划中的方法。 <div>
arXiv:2411.13983v3 Announce Type: replace 
Abstract: We introduce an Implicit Game-Theoretic MPC (IGT-MPC), a decentralized algorithm for two-agent motion planning that uses a learned value function that predicts the game-theoretic interaction outcomes as the terminal cost-to-go function in a model predictive control (MPC) framework, guiding agents to implicitly account for interactions with other agents and maximize their reward. This approach applies to competitive and cooperative multi-agent motion planning problems which we formulate as constrained dynamic games. Given a constrained dynamic game, we randomly sample initial conditions and solve for the generalized Nash equilibrium (GNE) to generate a dataset of GNE solutions, computing the reward outcome of each game-theoretic interaction from the GNE. The data is used to train a simple neural network to predict the reward outcome, which we use as the terminal cost-to-go function in an MPC scheme. We showcase emerging competitive and coordinated behaviors using IGT-MPC in scenarios such as two-vehicle head-to-head racing and un-signalized intersection navigation. IGT-MPC offers a novel method integrating machine learning and game-theoretic reasoning into model-based decentralized multi-agent motion planning.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>3D-Mem: 3D Scene Memory for Embodied Exploration and Reasoning</title>
<link>https://arxiv.org/abs/2411.17735</link>
<guid>https://arxiv.org/abs/2411.17735</guid>
<content:encoded><![CDATA[
<div> 关键词：3D场景表示、紧凑性、信息性、3D-Mem、记忆管理

总结:<br />
本文提出了一个针对embodied agent的新型3D场景记忆框架——3D-Mem，旨在解决复杂环境中长期探索和推理中3D场景表示的简化问题。3D-Mem利用“记忆快照”来捕获已探索区域的丰富视觉信息，同时引入“前沿快照”，以显示未探索区域的景象，使agent能基于已知和潜在新信息做出明智决策。为了支持主动探索环境下的终生记忆，文章还提出了一种增量构建3D-Mem的管道以及一种记忆检索技术用于记忆管理。实验结果显示，3D-Mem显著提升了agent在3D环境中的探索和推理能力，显示出其对推动embodied AI应用的潜力。 <div>
arXiv:2411.17735v4 Announce Type: replace 
Abstract: Constructing compact and informative 3D scene representations is essential for effective embodied exploration and reasoning, especially in complex environments over extended periods. Existing representations, such as object-centric 3D scene graphs, oversimplify spatial relationships by modeling scenes as isolated objects with restrictive textual relationships, making it difficult to address queries requiring nuanced spatial understanding. Moreover, these representations lack natural mechanisms for active exploration and memory management, hindering their application to lifelong autonomy. In this work, we propose 3D-Mem, a novel 3D scene memory framework for embodied agents. 3D-Mem employs informative multi-view images, termed Memory Snapshots, to represent the scene and capture rich visual information of explored regions. It further integrates frontier-based exploration by introducing Frontier Snapshots-glimpses of unexplored areas-enabling agents to make informed decisions by considering both known and potential new information. To support lifelong memory in active exploration settings, we present an incremental construction pipeline for 3D-Mem, as well as a memory retrieval technique for memory management. Experimental results on three benchmarks demonstrate that 3D-Mem significantly enhances agents' exploration and reasoning capabilities in 3D environments, highlighting its potential for advancing applications in embodied AI.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentTrek: Agent Trajectory Synthesis via Guiding Replay with Web Tutorials</title>
<link>https://arxiv.org/abs/2412.09605</link>
<guid>https://arxiv.org/abs/2412.09605</guid>
<content:encoded><![CDATA[
<div> 关键词: AgentTrek, 数据合成, 图形用户界面, 轨迹生成, 自动化

总结:
AgentTrek是一个提出的大规模数据综合管道，用于生成网页GUI代理的轨迹，以解决训练高质量轨迹数据稀缺的问题。该方法包括三个阶段：首先，使用专门的分类模型自动从互联网上收集和过滤类似教程的文本；其次，将这些文本转化为结构化的任务指令；最后，利用视觉-语言模型（VLM）代理执行这些指令并在真实环境中运行，同时通过VLM为基础的评估器验证轨迹正确性。生成的轨迹包含多模态信息，如基于文本的HTML观察与函数调用API动作，以及基于图像的屏幕截图观察与像素级动作。这种方法使代理在诸如WebArena、ScreenSpot Web和Multimodal Mind2Web等文本和视觉浏览基准测试中达到最先进的性能。此外，AgentTrek完全自动化的方式显著降低了数据收集成本，每个高质量轨迹的成本仅为$0.55，无需人类注释员参与。这项工作表明，利用网络教程引导回放是培训先进GUI代理的一种实用且可扩展的策略，为开发更强大、更自主的数字助手铺平了道路。<br /><br /> <div>
arXiv:2412.09605v2 Announce Type: replace 
Abstract: Graphical User Interface (GUI) agents can automate complex tasks across digital environments, but their development is hindered by the scarcity of high-quality trajectory data for training. Existing approaches rely on expensive human annotation, making them unsustainable at scale. We propose AgentTrek, a scalable data synthesis pipeline that generates web agent trajectories by leveraging publicly available tutorials. Our three-stage method: (1) automatically harvests and filters tutorial-like texts from the internet using a specialized classification model, (2) transforms these texts into structured task specifications with step-by-step instructions, and (3) employs a visual-language model (VLM) agent to execute these instructions in real environments, while a VLM-based evaluator verifies trajectory correctness. The synthesized trajectories encompass multiple modalities, including text-based HTML observations with function-calling API actions, and vision-based screenshot observations with pixel-level actions. This multimodal data, enriched with chain-of-thought reasoning, enables agents to achieve state-of-the-art performance on both textual web browsing benchmarks (e.g., WebArena) and visual web grounding and browsing benchmarks (e.g., ScreenSpot Web and Multimodal Mind2Web). Furthermore, our fully automated approach significantly reduces data collection costs, achieving a cost of just $0.55 per high-quality trajectory without human annotators. Our work demonstrates that guided replay using web tutorials is a practical and scalable strategy for training advanced GUI agents, paving the way for more capable and autonomous digital assistants.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multiagent Finetuning: Self Improvement with Diverse Reasoning Chains</title>
<link>https://arxiv.org/abs/2501.05707</link>
<guid>https://arxiv.org/abs/2501.05707</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、自我改进、多智能体社会、微调、推理任务

<br />
总结:
本文提出了利用多智能体社会的语言模型进行自我改进的方法。针对单一模型自我改进可能遭遇瓶颈的问题，该工作建议将多个相同基础模型独立专业化，通过各模型间的多智能体交互生成的数据进行微调更新。这样使得每个模型能够在独立数据集上进行专业化训练，实现模型间的差异性和多样性。实验表明，此方法相较于单智能体自我改进策略，能够保持更多样化的推理链条并实现更多轮次的自主性能提升。该方法的优势在一系列推理任务中得到了定量验证。 <div>
arXiv:2501.05707v2 Announce Type: replace 
Abstract: Large language models (LLMs) have achieved remarkable performance in recent years but are fundamentally limited by the underlying training data. To improve models beyond the training data, recent works have explored how LLMs can be used to generate synthetic data for autonomous self-improvement. However, successive steps of self-improvement can reach a point of diminishing returns. In this work, we propose a complementary approach towards self-improvement where finetuning is applied to a multiagent society of language models. A group of language models, all starting from the same base model, are independently specialized by updating each one using data generated through multiagent interactions among the models. By training each model on independent sets of data, we illustrate how this approach enables specialization across models and diversification over the set of models. As a result, our overall system is able to preserve diverse reasoning chains and autonomously improve over many more rounds of fine-tuning than single-agent self-improvement methods. We quantitatively illustrate the efficacy of the approach across a wide suite of reasoning tasks.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Mixed-Integer Conic Program for the Multi-Agent Moving-Target Traveling Salesman Problem</title>
<link>https://arxiv.org/abs/2501.06130</link>
<guid>https://arxiv.org/abs/2501.06130</guid>
<content:encoded><![CDATA[
arXiv:2501.06130v2 Announce Type: replace 
Abstract: The Moving-Target Traveling Salesman Problem (MT-TSP) seeks a shortest path for an agent that starts at a stationary depot, visits a set of moving targets exactly once, each within one of their respective time windows, and returns to the depot. In this paper, we introduce a new Mixed-Integer Conic Program (MICP) formulation for the Multi-Agent Moving-Target Traveling Salesman Problem (MA-MT-TSP), a generalization of the MT-TSP involving multiple agents. Our approach begins by restating the current state-of-the-art MICP formulation for MA-MT-TSP as a Nonconvex Mixed-Integer Nonlinear Program (MINLP), followed by a novel reformulation into a new MICP. We present computational results demonstrating that our formulation outperforms the state-of-the-art, achieving up to two orders of magnitude reduction in runtime, and over 90% improvement in optimality gap.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Speaking the Language of Teamwork: LLM-Guided Credit Assignment in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.03723</link>
<guid>https://arxiv.org/abs/2502.03723</guid>
<content:encoded><![CDATA[
arXiv:2502.03723v2 Announce Type: replace 
Abstract: Credit assignment, the process of attributing credit or blame to individual agents for their contributions to a team's success or failure, remains a fundamental challenge in multi-agent reinforcement learning (MARL), particularly in environments with sparse rewards. Commonly-used approaches such as value decomposition often lead to suboptimal policies in these settings, and designing dense reward functions that align with human intuition can be complex and labor-intensive. In this work, we propose a novel framework where a large language model (LLM) generates dense, agent-specific rewards based on a natural language description of the task and the overall team goal. By learning a potential-based reward function over multiple queries, our method reduces the impact of ranking errors while allowing the LLM to evaluate each agent's contribution to the overall task. Through extensive experiments, we demonstrate that our approach achieves faster convergence and higher policy returns compared to state-of-the-art MARL baselines.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fairness in Agentic AI: A Unified Framework for Ethical and Equitable Multi-Agent System</title>
<link>https://arxiv.org/abs/2502.07254</link>
<guid>https://arxiv.org/abs/2502.07254</guid>
<content:encoded><![CDATA[
arXiv:2502.07254v2 Announce Type: replace 
Abstract: Ensuring fairness in decentralized multi-agent systems presents significant challenges due to emergent biases, systemic inefficiencies, and conflicting agent incentives. This paper provides a comprehensive survey of fairness in multi-agent AI, introducing a novel framework where fairness is treated as a dynamic, emergent property of agent interactions. The framework integrates fairness constraints, bias mitigation strategies, and incentive mechanisms to align autonomous agent behaviors with societal values while balancing efficiency and robustness. Through empirical validation, we demonstrate that incorporating fairness constraints results in more equitable decision-making. This work bridges the gap between AI ethics and system design, offering a foundation for accountable, transparent, and socially responsible multi-agent AI systems.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>STMA: A Spatio-Temporal Memory Agent for Long-Horizon Embodied Task Planning</title>
<link>https://arxiv.org/abs/2502.10177</link>
<guid>https://arxiv.org/abs/2502.10177</guid>
<content:encoded><![CDATA[
arXiv:2502.10177v2 Announce Type: replace 
Abstract: A key objective of embodied intelligence is enabling agents to perform long-horizon tasks in dynamic environments while maintaining robust decision-making and adaptability. To achieve this goal, we propose the Spatio-Temporal Memory Agent (STMA), a novel framework designed to enhance task planning and execution by integrating spatio-temporal memory. STMA is built upon three critical components: (1) a spatio-temporal memory module that captures historical and environmental changes in real time, (2) a dynamic knowledge graph that facilitates adaptive spatial reasoning, and (3) a planner-critic mechanism that iteratively refines task strategies. We evaluate STMA in the TextWorld environment on 32 tasks, involving multi-step planning and exploration under varying levels of complexity. Experimental results demonstrate that STMA achieves a 31.25% improvement in success rate and a 24.7% increase in average score compared to the state-of-the-art model. The results highlight the effectiveness of spatio-temporal memory in advancing the memory capabilities of embodied agents.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>NavRAG: Generating User Demand Instructions for Embodied Navigation through Retrieval-Augmented LLM</title>
<link>https://arxiv.org/abs/2502.11142</link>
<guid>https://arxiv.org/abs/2502.11142</guid>
<content:encoded><![CDATA[
arXiv:2502.11142v2 Announce Type: replace 
Abstract: Vision-and-Language Navigation (VLN) is an essential skill for embodied agents, allowing them to navigate in 3D environments following natural language instructions. High-performance navigation models require a large amount of training data, the high cost of manually annotating data has seriously hindered this field. Therefore, some previous methods translate trajectory videos into step-by-step instructions for expanding data, but such instructions do not match well with users' communication styles that briefly describe destinations or state specific needs. Moreover, local navigation trajectories overlook global context and high-level task planning. To address these issues, we propose NavRAG, a retrieval-augmented generation (RAG) framework that generates user demand instructions for VLN. NavRAG leverages LLM to build a hierarchical scene description tree for 3D scene understanding from global layout to local details, then simulates various user roles with specific demands to retrieve from the scene tree, generating diverse instructions with LLM. We annotate over 2 million navigation instructions across 861 scenes and evaluate the data quality and navigation performance of trained models.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grassroots Platforms with Atomic Transactions: Social Networks, Cryptocurrencies, and Democratic Federations</title>
<link>https://arxiv.org/abs/2502.11299</link>
<guid>https://arxiv.org/abs/2502.11299</guid>
<content:encoded><![CDATA[
arXiv:2502.11299v2 Announce Type: replace 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic (Facebook etc.) and decentralized/plutocratic (Bitcoin etc.) alike. Key grassroots platforms include grassroots social networks, grassroots cryptocurrencies, and grassroots democratic federations. Previously, grassroots platforms were defined formally and proven grassroots using unary distributed transition systems, in which each transition is carried out by a single agent. However, grassroots platforms cater for a more abstract specification using transactions carried out atomically by multiple agents, something that cannot be expressed by unary transition systems. As a result, their original specifications and proofs were unnecessarily cumbersome and opaque.
  Here, we aim to provide a more suitable formal foundation for grassroots platforms. To do so, we enhance the notion of a distributed transition system to include atomic transactions and revisit the notion of grassroots platforms within this new foundation. We present crisp specifications of key grassroots platforms using atomic transactions: befriending and defriending for grassroots social networks, coin swaps for grassroots cryptocurrencies, and communities forming, joining, and leaving a federation for grassroots democratic federations. We prove a general theorem that a platform specified by atomic transactions that are so-called interactive is grassroots; show that the atomic transactions used to specify all three platforms are interactive; and conclude that the platforms thus specified are indeed grassroots. We thus provide a better mathematical foundation for grassroots platforms and a solid and clear starting point from which their implementation can commence.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"Nuclear Deployed!": Analyzing Catastrophic Risks in Decision-making of Autonomous LLM Agents</title>
<link>https://arxiv.org/abs/2502.11355</link>
<guid>https://arxiv.org/abs/2502.11355</guid>
<content:encoded><![CDATA[
arXiv:2502.11355v2 Announce Type: replace 
Abstract: Large language models (LLMs) are evolving into autonomous decision-makers, raising concerns about catastrophic risks in high-stakes scenarios, particularly in Chemical, Biological, Radiological and Nuclear (CBRN) domains. Based on the insight that such risks can originate from trade-offs between the agent's Helpful, Harmlessness and Honest (HHH) goals, we build a novel three-stage evaluation framework, which is carefully constructed to effectively and naturally expose such risks. We conduct 14,400 agentic simulations across 12 advanced LLMs, with extensive experiments and analysis. Results reveal that LLM agents can autonomously engage in catastrophic behaviors and deception, without being deliberately induced. Furthermore, stronger reasoning abilities often increase, rather than mitigate, these risks. We also show that these agents can violate instructions and superior commands. On the whole, we empirically prove the existence of catastrophic risks in autonomous LLM agents. We will release our code upon request.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A-MEM: Agentic Memory for LLM Agents</title>
<link>https://arxiv.org/abs/2502.12110</link>
<guid>https://arxiv.org/abs/2502.12110</guid>
<content:encoded><![CDATA[
arXiv:2502.12110v2 Announce Type: replace 
Abstract: While large language model (LLM) agents can effectively use external tools for complex real-world tasks, they require memory systems to leverage historical experiences. Current memory systems enable basic storage and retrieval but lack sophisticated memory organization, despite recent attempts to incorporate graph databases. Moreover, these systems' fixed operations and structures limit their adaptability across diverse tasks. To address this limitation, this paper proposes a novel agentic memory system for LLM agents that can dynamically organize memories in an agentic way. Following the basic principles of the Zettelkasten method, we designed our memory system to create interconnected knowledge networks through dynamic indexing and linking. When a new memory is added, we generate a comprehensive note containing multiple structured attributes, including contextual descriptions, keywords, and tags. The system then analyzes historical memories to identify relevant connections, establishing links where meaningful similarities exist. Additionally, this process enables memory evolution - as new memories are integrated, they can trigger updates to the contextual representations and attributes of existing historical memories, allowing the memory network to continuously refine its understanding. Our approach combines the structured organization principles of Zettelkasten with the flexibility of agent-driven decision making, allowing for more adaptive and context-aware memory management. Empirical experiments on six foundation models show superior improvement against existing SOTA baselines. The source code is available at https://github.com/WujiangXu/AgenticMemory.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning with Linear Function Approximations in Mean-Field Control</title>
<link>https://arxiv.org/abs/2408.00991</link>
<guid>https://arxiv.org/abs/2408.00991</guid>
<content:encoded><![CDATA[
arXiv:2408.00991v2 Announce Type: replace-cross 
Abstract: The paper focuses on mean-field type multi-agent control problems with finite state and action spaces where the dynamics and cost structures are symmetric and homogeneous, and are affected by the distribution of the agents. A standard solution method for these problems is to consider the infinite population limit as an approximation and use symmetric solutions of the limit problem to achieve near optimality. The control policies, and in particular the dynamics, depend on the population distribution in the finite population setting, or the marginal distribution of the state variable of a representative agent for the infinite population setting. Hence, learning and planning for these control problems generally require estimating the reaction of the system to all possible state distributions of the agents. To overcome this issue, we consider linear function approximation for the control problem and provide coordinated and independent learning methods. We rigorously establish error upper bounds for the performance of learned solutions. The performance gap stems from (i) the mismatch due to estimating the true model with a linear one, and (ii) using the infinite population solution in the finite population problem as an approximate control. The provided upper bounds quantify the impact of these error sources on the overall performance.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Among Them: A game-based framework for assessing persuasion capabilities of LLMs</title>
<link>https://arxiv.org/abs/2502.20426</link>
<guid>https://arxiv.org/abs/2502.20426</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、自动AI代理、说服能力、游戏框架、欺骗技能

总结:
该论文关注了大型语言模型和自动AI代理在潜在自动化劝说与社会影响力方面的风险。研究提出了一个受《Among Us》启发的游戏框架，用于在受控环境中评估LLM的欺骗技能，并通过比较不同模型的游戏统计数据及量化其运用的来自社会心理学和修辞学的25种劝说策略来实现这一目标。实验显示，所测试的8款流行的语言模型均展现出劝说能力，成功应用了其中22种预期的技巧。此外，研究发现大模型并不比小模型更具劝说优势，而模型输出长度的增长与赢得游戏的数量呈负相关。这项研究为了解LLM的欺骗能力提供了见解，并为未来相关领域的研究提供了工具和数据支持。 <div>
arXiv:2502.20426v1 Announce Type: new 
Abstract: The proliferation of large language models (LLMs) and autonomous AI agents has raised concerns about their potential for automated persuasion and social influence. While existing research has explored isolated instances of LLM-based manipulation, systematic evaluations of persuasion capabilities across different models remain limited. In this paper, we present an Among Us-inspired game framework for assessing LLM deception skills in a controlled environment. The proposed framework makes it possible to compare LLM models by game statistics, as well as quantify in-game manipulation according to 25 persuasion strategies from social psychology and rhetoric. Experiments between 8 popular language models of different types and sizes demonstrate that all tested models exhibit persuasive capabilities, successfully employing 22 of the 25 anticipated techniques. We also find that larger models do not provide any persuasion advantage over smaller models and that longer model outputs are negatively correlated with the number of games won. Our study provides insights into the deception capabilities of LLMs, as well as tools and data for fostering future research on the topic.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Language Model Strategic Reasoning Evaluation through Behavioral Game Theory</title>
<link>https://arxiv.org/abs/2502.20432</link>
<guid>https://arxiv.org/abs/2502.20432</guid>
<content:encoded><![CDATA[
<div> 关键词: 战略决策、大型语言模型、Nash均衡、行为博弈论、性别偏见

总结:
本文探讨了战略决策中的互动推理问题，指出现有对大型语言模型（LLMs）的评估往往过于关注Nash均衡近似，而忽视了驱动其战略选择的机制。为弥补这一差距，文章引入了一个基于行为博弈论的评价框架，将推理能力与情境效应分开考虑。研究发现，GPT-o3-mini、GPT-o1和DeepSeek-R1在游戏中表现出色，但模型规模本身并不能决定性能。关于提示增强技术，链式思维（Chain-of-Thought, CoT）提示并非普遍有效，仅对特定级别的模型提高了战略推理能力。此外，文章还研究了编码的demographic特征对模型决策过程的影响，观察到某些身份设定会影响决策模式，例如GPT-4o在赋予女性特质时展现出更强的战略推理能力，而Gemma在赋予异性恋身份时相比其他性取向显示出更高的推理水平，这揭示了模型中存在内在的偏见。这些发现强调了需要平衡提高推理能力和公平性之间的关系，并提出了对伦理标准和上下文对齐的需求。 <div>
arXiv:2502.20432v1 Announce Type: new 
Abstract: Strategic decision-making involves interactive reasoning where agents adapt their choices in response to others, yet existing evaluations of large language models (LLMs) often emphasize Nash Equilibrium (NE) approximation, overlooking the mechanisms driving their strategic choices. To bridge this gap, we introduce an evaluation framework grounded in behavioral game theory, disentangling reasoning capability from contextual effects. Testing 22 state-of-the-art LLMs, we find that GPT-o3-mini, GPT-o1, and DeepSeek-R1 dominate most games yet also demonstrate that the model scale alone does not determine performance. In terms of prompting enhancement, Chain-of-Thought (CoT) prompting is not universally effective, as it increases strategic reasoning only for models at certain levels while providing limited gains elsewhere. Additionally, we investigate the impact of encoded demographic features on the models, observing that certain assignments impact the decision-making pattern. For instance, GPT-4o shows stronger strategic reasoning with female traits than males, while Gemma assigns higher reasoning levels to heterosexual identities compared to other sexual orientations, indicating inherent biases. These findings underscore the need for ethical standards and contextual alignment to balance improved reasoning with fairness.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cooperative Multi-Agent Assignment over Stochastic Graphs via Constrained Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.20462</link>
<guid>https://arxiv.org/abs/2502.20462</guid>
<content:encoded><![CDATA[
<div> 关键词：约束多智能体强化学习、动态环境、分布式协调、单比特通信协议、收缩因子

总结:<br />
本文研究了在动态环境中执行冲突任务的多智能体团队的约束强化学习问题。提出了一个新颖的框架，其中不强制要求配对变量收敛，而是允许其循环，使智能体能够根据实时约束满足程度动态调整策略。该框架依赖于一种轻量级的单比特通信协议，通过随机连通网络实现分布式协调。此外，通过引入收缩因子修改局部配对变量的动力学行为，使得可以使用有限的通信缓存并保持估计误差在可控范围内。在此模型下，文章提供了几乎必然可行性的理论保证，并通过数值实验进行了验证，实验中一组机器人成功地在多个区域进行巡逻，并在随时间变化的自组网下进行通信。 <div>
arXiv:2502.20462v1 Announce Type: new 
Abstract: Constrained multi-agent reinforcement learning offers the framework to design scalable and almost surely feasible solutions for teams of agents operating in dynamic environments to carry out conflicting tasks. We address the challenges of multi-agent coordination through an unconventional formulation in which the dual variables are not driven to convergence but are free to cycle, enabling agents to adapt their policies dynamically based on real-time constraint satisfaction levels. The coordination relies on a light single-bit communication protocol over a network with stochastic connectivity. Using this gossiped information, agents update local estimates of the dual variables. Furthermore, we modify the local dual dynamics by introducing a contraction factor, which lets us use finite communication buffers and keep the estimation error bounded. Under this model, we provide theoretical guarantees of almost sure feasibility and corroborate them with numerical experiments in which a team of robots successfully patrols multiple regions, communicating under a time-varying ad-hoc network.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EgoNormia: Benchmarking Physical Social Norm Understanding</title>
<link>https://arxiv.org/abs/2502.20490</link>
<guid>https://arxiv.org/abs/2502.20490</guid>
<content:encoded><![CDATA[
<div> 关键词：EgoNormia、normative reasoning、vision-language models、human interactions、dataset

总结:
本文介绍了EgoNormia $\|\epsilon\|$，这是一个针对视觉语言模型（VLMs）的新型大规模自视点视频数据集，用于提升和评估机器对社会规范的理解与推理能力。该数据集包含了1,853个关于人类互动的自视点视频，每个视频配有两个相关问题，用于评测预测和解释规范行为的能力，涵盖了七大类别：安全、隐私、空间礼仪、礼貌、合作、协调/主动性以及沟通/可读性。为实现大规模数据集的编纂，文章提出了一种结合视频采样、自动答案生成、过滤和人工验证的新颖流程。研究发现，当前最先进的VLMs在理解规范方面表现不足，最高得分仅为45%，远低于人类基准的92%。分析表明，这些模型在安全、隐私及协作与沟通方面存在显著风险。此外，文章还展示了通过检索式生成方法利用EgoNormia可以增强VLMs的规范推理能力。 <div>
arXiv:2502.20490v1 Announce Type: new 
Abstract: Human activity is moderated by norms. When performing actions in the real world, humans not only follow norms, but also consider the trade-off between different norms However, machines are often trained without explicit supervision on norm understanding and reasoning, especially when the norms are grounded in a physical and social context. To improve and evaluate the normative reasoning capability of vision-language models (VLMs), we present EgoNormia $\|\epsilon\|$, consisting of 1,853 ego-centric videos of human interactions, each of which has two related questions evaluating both the prediction and justification of normative actions. The normative actions encompass seven categories: safety, privacy, proxemics, politeness, cooperation, coordination/proactivity, and communication/legibility. To compile this dataset at scale, we propose a novel pipeline leveraging video sampling, automatic answer generation, filtering, and human validation. Our work demonstrates that current state-of-the-art vision-language models lack robust norm understanding, scoring a maximum of 45% on EgoNormia (versus a human bench of 92%). Our analysis of performance in each dimension highlights the significant risks of safety, privacy, and the lack of collaboration and communication capability when applied to real-world agents. We additionally show that through a retrieval-based generation method, it is possible to use EgoNomia to enhance normative reasoning in VLMs.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Thousand Words or An Image: Studying the Influence of Persona Modality in Multimodal LLMs</title>
<link>https://arxiv.org/abs/2502.20504</link>
<guid>https://arxiv.org/abs/2502.20504</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，多模态信息，人格表达，文本模态，图像模态

<br /><br />总结:
本文探讨了不同模态如何影响多模态大型语言模型（LLMs）中人格表达的丰富性。研究团队创建了一个包含40种多样化的、具有年龄、性别、职业和地点差异的平行模态人格数据集，该数据集包括四种等价的人格表示形式：仅图像、仅文本、图像与少量文本结合以及带有类型化图像（通过视觉样式传达人格相关属性的文本）。为了评估LLMs在不同模态下对人格的体现程度，他们设计了一套包含60个问题和相应指标的系统评价框架。实验结果显示，详细文本描述的人格表现出更强的语言习惯，而类型化图像通常更能保持与人格的一致性。然而，LLMs往往忽视通过图像传递的特定人格细节，揭示了其潜在局限性并为未来的研究指明了方向。相关的数据和代码已发布于https://github.com/claws-lab/persona-modality 。 <div>
arXiv:2502.20504v1 Announce Type: new 
Abstract: Large language models (LLMs) have recently demonstrated remarkable advancements in embodying diverse personas, enhancing their effectiveness as conversational agents and virtual assistants. Consequently, LLMs have made significant strides in processing and integrating multimodal information. However, even though human personas can be expressed in both text and image, the extent to which the modality of a persona impacts the embodiment by the LLM remains largely unexplored. In this paper, we investigate how do different modalities influence the expressiveness of personas in multimodal LLMs. To this end, we create a novel modality-parallel dataset of 40 diverse personas varying in age, gender, occupation, and location. This consists of four modalities to equivalently represent a persona: image-only, text-only, a combination of image and small text, and typographical images, where text is visually stylized to convey persona-related attributes. We then create a systematic evaluation framework with 60 questions and corresponding metrics to assess how well LLMs embody each persona across its attributes and scenarios. Comprehensive experiments on $5$ multimodal LLMs show that personas represented by detailed text show more linguistic habits, while typographical images often show more consistency with the persona. Our results reveal that LLMs often overlook persona-specific details conveyed through images, highlighting underlying limitations and paving the way for future research to bridge this gap. We release the data and code at https://github.com/claws-lab/persona-modality .
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TripCraft: A Benchmark for Spatio-Temporally Fine Grained Travel Planning</title>
<link>https://arxiv.org/abs/2502.20508</link>
<guid>https://arxiv.org/abs/2502.20508</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、旅行规划、数据集、TripCraft、评价指标

总结:
近期研究表明，大型语言模型（LLMs）在个性化旅行规划领域的潜力不断被探索，但现有的基准测试仍有局限性。文章指出，现有如TravelPlanner和TravelPlanner+等数据集依赖半合成数据，存在空间不一致性和缺乏关键旅行约束等问题，无法满足实际行程生成的需求。为解决这些问题，研究者们推出了新的数据集TripCraft，它整合了真实世界的约束条件，包括公共交通时刻表、活动可用性、多元化的旅游景点类别以及用户人格特征，以增强个人化旅行规划的能力。此外，为了更全面地评估LLM生成的行程计划，他们提出了五个连续评价指标：时间餐饮得分、时间景点得分、空间得分、排序得分和人格得分，从多个维度来衡量行程质量。实验结果显示，参数引导的设置显著提升了用餐安排的质量，在7天场景下将时间餐饮得分从61%提高到80%。TripCraft为LLM驱动的个性化旅行规划设立了新的基准，并提供了一个更为现实、具有约束意识的行程生成框架。该数据集和代码库将在论文被接受后公开发布。 <div>
arXiv:2502.20508v1 Announce Type: new 
Abstract: Recent advancements in probing Large Language Models (LLMs) have explored their latent potential as personalized travel planning agents, yet existing benchmarks remain limited in real world applicability. Existing datasets, such as TravelPlanner and TravelPlanner+, suffer from semi synthetic data reliance, spatial inconsistencies, and a lack of key travel constraints, making them inadequate for practical itinerary generation. To address these gaps, we introduce TripCraft, a spatiotemporally coherent travel planning dataset that integrates real world constraints, including public transit schedules, event availability, diverse attraction categories, and user personas for enhanced personalization. To evaluate LLM generated plans beyond existing binary validation methods, we propose five continuous evaluation metrics, namely Temporal Meal Score, Temporal Attraction Score, Spatial Score, Ordering Score, and Persona Score which assess itinerary quality across multiple dimensions. Our parameter informed setting significantly enhances meal scheduling, improving the Temporal Meal Score from 61% to 80% in a 7 day scenario. TripCraft establishes a new benchmark for LLM driven personalized travel planning, offering a more realistic, constraint aware framework for itinerary generation. Dataset and Codebase will be made publicly available upon acceptance.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Supervised Fine-Tuning LLMs to Behave as Pedagogical Agents in Programming Education</title>
<link>https://arxiv.org/abs/2502.20527</link>
<guid>https://arxiv.org/abs/2502.20527</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、编程教育、GuideLM、调试C编译器、监督微调

总结:
本文介绍了针对编程教育开发的大型语言模型GuideLM及其应用在调试C编译器(DCC)中的情况。与DCC先前依赖于直接提供解决方案的OpenAI模型不同，研究团队对ChatGPT-4o和4o-mini进行了监督微调，创建了GuideLM和GuideLM-mini两个模型。通过对400条响应进行专家分析，结果显示，相较于基础的GPT-4o模型，GuideLM和GuideLM-mini在引导式教学和语言简洁性方面有显著提升，分别增加了8%的苏格拉底式指导和58%的文字经济性。然而，这一改进也带来了整体准确性的轻微下降。该研究表明，利用针对性的数据集对大规模语言模型进行微调是构建更适合教育场景模型的一种有前景的方法。 <div>
arXiv:2502.20527v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly being explored in higher education, yet their effectiveness as teaching agents remains underexamined. In this paper, we present the development of GuideLM, a fine-tuned LLM designed for programming education. GuideLM has been integrated into the Debugging C Compiler (DCC), an educational C compiler that leverages LLMs to generate pedagogically sound error explanations. Previously, DCC relied on off-the-shelf OpenAI models, which, while accurate, often over-assisted students by directly providing solutions despite contrary prompting.
  To address this, we employed supervised fine-tuning (SFT) on a dataset of 528 student-question/teacher-answer pairs, creating two models: GuideLM and GuideLM-mini, fine-tuned on ChatGPT-4o and 4o-mini, respectively. We conducted an expert analysis of 400 responses per model, comparing their pedagogical effectiveness against base OpenAI models. Our evaluation, grounded in constructivism and cognitive load theory, assessed factors such as conceptual scaffolding, clarity, and Socratic guidance.
  Results indicate that GuideLM and GuideLM-mini improve pedagogical performance, with an 8% increase in Socratic guidance and a 58% improvement in economy of words compared to GPT-4o. However, this refinement comes at the cost of a slight reduction in general accuracy. While further work is needed, our findings suggest that fine-tuning LLMs with targeted datasets is a promising approach for developing models better suited to educational contexts.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Close-Proximity Satellite Operations through Deep Reinforcement Learning and Terrestrial Testing Environments</title>
<link>https://arxiv.org/abs/2502.20554</link>
<guid>https://arxiv.org/abs/2502.20554</guid>
<content:encoded><![CDATA[
<div> 关键词：Deep Reinforcement Learning (DRL)，卫星控制，多代理检查任务，Local Intelligent Network of Collaborative Satellites (LINCS) Lab，环境适应性

总结:<br />
本文探讨了使用深度强化学习（DRL）进行卫星控制在多代理检查任务中的应用。研究重点关注了DRL算法在从模拟环境到真实世界的四旋翼无人机硬件等不同环境下的性能表现，特别是对其在部署到训练环境之外时的行为以及可能的性能退化进行了深入理解。文章以Local Intelligent Network of Collaborative Satellites (LINCS) 实验室为测试平台，对该方法进行了实验验证和分析。 <div>
arXiv:2502.20554v1 Announce Type: new 
Abstract: With the increasingly congested and contested space environment, safe and effective satellite operation has become increasingly challenging. As a result, there is growing interest in autonomous satellite capabilities, with common machine learning techniques gaining attention for their potential to address complex decision-making in the space domain. However, the "black-box" nature of many of these methods results in difficulty understanding the model's input/output relationship and more specifically its sensitivity to environmental disturbances, sensor noise, and control intervention. This paper explores the use of Deep Reinforcement Learning (DRL) for satellite control in multi-agent inspection tasks. The Local Intelligent Network of Collaborative Satellites (LINCS) Lab is used to test the performance of these control algorithms across different environments, from simulations to real-world quadrotor UAV hardware, with a particular focus on understanding their behavior and potential degradation in performance when deployed beyond the training environment.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Subtask-Aware Visual Reward Learning from Segmented Demonstrations</title>
<link>https://arxiv.org/abs/2502.20630</link>
<guid>https://arxiv.org/abs/2502.20630</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning, RL)，奖励函数 (reward function)，REDs，视频示范 (video demonstration)，子任务分割 (subtask segmentation)

总结:<br />
本文提出了一种名为REDs的新颖奖励学习框架，旨在解决强化学习代理依赖于人工设计奖励函数的问题。REDs利用来自不同源、带有子任务分割的无动作视频进行最少监督的奖励学习。通过将视频片段及其对应的子任务作为真实奖励信号的地面真相，训练一个密集型奖励函数并最小化等价策略不变性比较距离以确保对齐。同时，采用对比学习目标来使视频表示与子任务对齐，保证在线交互过程中精确的子任务推断。实验表明，REDs在Meta-World的复杂机器人操纵任务以及FurnitureBench的真实世界家具组装等更具挑战性的任务上，显著优于基线方法，且能以极小的人类干预实现对未见过的任务和机器人载体的泛化能力，显示出其在多样化环境中可扩展部署的潜力。 <div>
arXiv:2502.20630v1 Announce Type: new 
Abstract: Reinforcement Learning (RL) agents have demonstrated their potential across various robotic tasks. However, they still heavily rely on human-engineered reward functions, requiring extensive trial-and-error and access to target behavior information, often unavailable in real-world settings. This paper introduces REDS: REward learning from Demonstration with Segmentations, a novel reward learning framework that leverages action-free videos with minimal supervision. Specifically, REDS employs video demonstrations segmented into subtasks from diverse sources and treats these segments as ground-truth rewards. We train a dense reward function conditioned on video segments and their corresponding subtasks to ensure alignment with ground-truth reward signals by minimizing the Equivalent-Policy Invariant Comparison distance. Additionally, we employ contrastive learning objectives to align video representations with subtasks, ensuring precise subtask inference during online interactions. Our experiments show that REDS significantly outperforms baseline methods on complex robotic manipulation tasks in Meta-World and more challenging real-world tasks, such as furniture assembly in FurnitureBench, with minimal human intervention. Moreover, REDS facilitates generalization to unseen tasks and robot embodiments, highlighting its potential for scalable deployment in diverse environments.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Delayed-Decision Motion Planning in the Presence of Multiple Predictions</title>
<link>https://arxiv.org/abs/2502.20636</link>
<guid>https://arxiv.org/abs/2502.20636</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驾驶技术、不确定性、行为规划、最大熵、模型预测控制

总结:
本文探讨了自动驾驾驶技术面临的不确定性的挑战，特别是交通参与者的行为不确定性。文章提出了一种在多种可能未来场景及其对应概率下的行为规划方案，并使用最大熵方法进行了形式化描述。在某些假设下，这种方法允许延迟决策以提高安全性。进一步地，将该一般性方案转化为模型预测控制问题，通过求解二次规划或一系列二次规划来实现。文中还讨论了提升计算效率的具体实施细节，并通过模拟和移动机器人实验验证了操作的有效性。 <div>
arXiv:2502.20636v1 Announce Type: new 
Abstract: Reliable automated driving technology is challenged by various sources of uncertainties, in particular, behavioral uncertainties of traffic agents. It is common for traffic agents to have intentions that are unknown to others, leaving an automated driving car to reason over multiple possible behaviors. This paper formalizes a behavior planning scheme in the presence of multiple possible futures with corresponding probabilities. We present a maximum entropy formulation and show how, under certain assumptions, this allows delayed decision-making to improve safety. The general formulation is then turned into a model predictive control formulation, which is solved as a quadratic program or a set of quadratic programs. We discuss implementation details for improving computation and verify operation in simulation and on a mobile robot.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ProAI: Proactive Multi-Agent Conversational AI with Structured Knowledge Base for Psychiatric Diagnosis</title>
<link>https://arxiv.org/abs/2502.20689</link>
<guid>https://arxiv.org/abs/2502.20689</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、对话式AI系统、主动交互、ProAI、精神疾病诊断

<br />
总结:
本文介绍了针对LLM驱动的对话式AI系统的局限性，大多数此类系统仅被动响应用户提示而缺乏主动性。为解决这一问题并满足如心理诊断等实际应用场景的需求，文章提出了一个名为ProAI的面向目标、主动式的对话AI框架。ProAI集成了结构化知识引导的记忆、多代理主动推理以及多元评估策略，使LLMs能够进行类似临床医生式的诊断推理而非简单的应答生成。通过模拟患者互动、用户体验评估和专业临床验证，ProAI在精神障碍差异诊断方面的准确率达到了83.3%，同时保持了专业的、富有同理心的互动标准。这些成果表明，ProAI有可能实现更可靠、适应性和目标导向的AI诊断助手功能，推动LLM超越单纯的反应式对话系统。 <div>
arXiv:2502.20689v1 Announce Type: new 
Abstract: Most LLM-driven conversational AI systems operate reactively, responding to user prompts without guiding the interaction. Most LLM-driven conversational AI systems operate reactively, responding to user prompts without guiding the interaction. However, many real-world applications-such as psychiatric diagnosis, consulting, and interviews-require AI to take a proactive role, asking the right questions and steering conversations toward specific objectives. Using mental health differential diagnosis as an application context, we introduce ProAI, a goal-oriented, proactive conversational AI framework. ProAI integrates structured knowledge-guided memory, multi-agent proactive reasoning, and a multi-faceted evaluation strategy, enabling LLMs to engage in clinician-style diagnostic reasoning rather than simple response generation. Through simulated patient interactions, user experience assessment, and professional clinical validation, we demonstrate that ProAI achieves up to 83.3% accuracy in mental disorder differential diagnosis while maintaining professional and empathetic interaction standards. These results highlight the potential for more reliable, adaptive, and goal-driven AI diagnostic assistants, advancing LLMs beyond reactive dialogue systems.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Acquiring Grounded Representations of Words with Situated Interactive Instruction</title>
<link>https://arxiv.org/abs/2502.20754</link>
<guid>https://arxiv.org/abs/2502.20754</guid>
<content:encoded><![CDATA[
<div> 关键词：mixed-initiative, grounded representations, interactive learning, Soar, robotic arm

<br /><br />总结:
本文提出了一种从与人类导师进行混合主动性的、情境交互中获取单词的有根据表示的方法。该研究关注于包括感知、语义和程序知识在内的多种类型知识的学习，以及学习到的有根据的意义。通过互动式学习，使智能体能够针对未知概念请求指导，从而提高学习效率。这一方法已在Soar架构中实现，并在一个能够操纵小物体的桌面机器人臂上进行了评估。 <div>
arXiv:2502.20754v1 Announce Type: new 
Abstract: We present an approach for acquiring grounded representations of words from mixed-initiative, situated interactions with a human instructor. The work focuses on the acquisition of diverse types of knowledge including perceptual, semantic, and procedural knowledge along with learning grounded meanings. Interactive learning allows the agent to control its learning by requesting instructions about unknown concepts, making learning efficient. Our approach has been instantiated in Soar and has been evaluated on a table-top robotic arm capable of manipulating small objects.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Rise of Darkness: Safety-Utility Trade-Offs in Role-Playing Dialogue Agents</title>
<link>https://arxiv.org/abs/2502.20757</link>
<guid>https://arxiv.org/abs/2502.20757</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，安全性，实用性，风险耦合，适应性动态多偏好 (ADMP)

<br />
总结:

本文探讨了大型语言模型（LLMs）在角色扮演对话代理中的进展，指出了在模拟角色行为的同时确保内容安全性的挑战。研究发现，由反派角色和用户查询产生的风险耦合作用加剧了安全性和实用性的权衡问题。为解决此问题，文章提出了一种名为“适应性动态多偏好”(ADMP)的方法，该方法根据风险耦合的程度动态调整安全性和实用性的优先级，引导模型生成偏向于实用或安全的回答。同时，通过引入“耦合边际采样”(CMS)强化模型处理高风险场景的能力。实验结果显示，采用该方法能够在保持实用性的同时显著提升安全性指标。 <div>
arXiv:2502.20757v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have made remarkable advances in role-playing dialogue agents, demonstrating their utility in character simulations. However, it remains challenging for these agents to balance character portrayal utility with content safety because this essential character simulation often comes with the risk of generating unsafe content. To address this issue, we first conduct a systematic exploration of the safety-utility trade-off across multiple LLMs. Our analysis reveals that risk scenarios created by villain characters and user queries (referred to as risk coupling) contribute to this trade-off. Building on this, we propose a novel Adaptive Dynamic Multi-Preference (ADMP) method, which dynamically adjusts safety-utility preferences based on the degree of risk coupling and guides the model to generate responses biased toward utility or safety. We further introduce Coupling Margin Sampling (CMS) into coupling detection to enhance the model's ability to handle high-risk scenarios. Experimental results demonstrate that our approach improves safety metrics while maintaining utility.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cyber Defense Reinvented: Large Language Models as Threat Intelligence Copilots</title>
<link>https://arxiv.org/abs/2502.20791</link>
<guid>https://arxiv.org/abs/2502.20791</guid>
<content:encoded><![CDATA[
<div> 关键词：CYLENS、大型语言模型（LLMs）、网络安全威胁分析、威胁管理生命周期、定制化

<br /><br />总结:
本文介绍了CYLENS，一个基于大型语言模型（LLMs）的网络安全威胁情报副驾驶系统。CYLENS旨在协助安全专业人员处理整个威胁管理生命周期中的任务，包括威胁归属、上下文化、检测、关联、优先级排序和缓解。该系统通过将271,570份威胁报告的知识融入其模型参数并集成六个专门的NLP模块，增强了推理能力。此外，CYLENS还可以根据不同组织的独特需求进行定制，凸显其适应性。通过广泛的评估，证明了CYLENS在性能上持续优于行业领先的LLMs和最先进的网络安全代理，为利用LLMs解决复杂、数据密集型网络安全挑战提供了蓝图。 <div>
arXiv:2502.20791v1 Announce Type: new 
Abstract: The exponential growth of cyber threat knowledge, exemplified by the expansion of databases such as MITRE-CVE and NVD, poses significant challenges for cyber threat analysis. Security professionals are increasingly burdened by the sheer volume and complexity of information, creating an urgent need for effective tools to navigate, synthesize, and act on large-scale data to counter evolving threats proactively. However, conventional threat intelligence tools often fail to scale with the dynamic nature of this data and lack the adaptability to support diverse threat intelligence tasks.
  In this work, we introduce CYLENS, a cyber threat intelligence copilot powered by large language models (LLMs). CYLENS is designed to assist security professionals throughout the entire threat management lifecycle, supporting threat attribution, contextualization, detection, correlation, prioritization, and remediation. To ensure domain expertise, CYLENS integrates knowledge from 271,570 threat reports into its model parameters and incorporates six specialized NLP modules to enhance reasoning capabilities. Furthermore, CYLENS can be customized to meet the unique needs of different or ganizations, underscoring its adaptability. Through extensive evaluations, we demonstrate that CYLENS consistently outperforms industry-leading LLMs and state-of-the-art cybersecurity agents. By detailing its design, development, and evaluation, this work provides a blueprint for leveraging LLMs to address complex, data-intensive cybersecurity challenges.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digital Player: Evaluating Large Language Models based Human-like Agent in Games</title>
<link>https://arxiv.org/abs/2502.20807</link>
<guid>https://arxiv.org/abs/2502.20807</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、自主代理、 Unciv 游戏、数据飞轮、人类行为模拟

<br /><br />总结:
本文介绍了利用大型语言模型构建自主代理并在开放源代码策略游戏“Unciv”上开发应用级测试床的研究工作。该测试bed旨在为研究人员提供一个“数据飞轮”，以研究在“数字玩家”任务中具有类似人类行为的智能代理。在这个类似于“文明”的游戏中，LLM-based 代理需要面对复杂的决策空间、数值推理及长期规划等挑战，同时还需要生成与人类玩家进行社会互动、合作和谈判时的人类化响应。该项目的开源代码可以在https://github.com/fuxiAIlab/CivAgent 找到。 <div>
arXiv:2502.20807v1 Announce Type: new 
Abstract: With the rapid advancement of Large Language Models (LLMs), LLM-based autonomous agents have shown the potential to function as digital employees, such as digital analysts, teachers, and programmers. In this paper, we develop an application-level testbed based on the open-source strategy game "Unciv", which has millions of active players, to enable researchers to build a "data flywheel" for studying human-like agents in the "digital players" task. This "Civilization"-like game features expansive decision-making spaces along with rich linguistic interactions such as diplomatic negotiations and acts of deception, posing significant challenges for LLM-based agents in terms of numerical reasoning and long-term planning. Another challenge for "digital players" is to generate human-like responses for social interaction, collaboration, and negotiation with human players. The open-source project can be found at https:/github.com/fuxiAIlab/CivAgent.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical and Modular Network on Non-prehensile Manipulation in General Environments</title>
<link>https://arxiv.org/abs/2502.20843</link>
<guid>https://arxiv.org/abs/2502.20843</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人、非预抓形操作、深度强化学习、模块化架构、环境几何变异性

<br /><br />总结:
本文提出了一种针对机器人在复杂环境中进行非预抓形操作（如推倒和滚动不可握持物体）的新方法。现有的非预抓形操纵技术难以适应具有多样几何形状的环境。为解决这一问题，研究者设计了一个可自适应重构的模块化网络架构，该架构能根据任务需求调整自身配置。同时，他们扩展了接触基对象表示法（CORN），将其应用于环境几何中，并提出了生成多样化环境的程序算法以训练智能体。最终，这种方法使得政策能够在未经过真实世界训练的情况下，实现对新颖现实场景的零样本迁移。此外，为了推动非预抓形操纵领域的研究，作者还发布了一个基于模拟的基准测试平台，其中包含了9个现实世界的数字孪生场景和353个物体。 <div>
arXiv:2502.20843v1 Announce Type: new 
Abstract: For robots to operate in general environments like households, they must be able to perform non-prehensile manipulation actions such as toppling and rolling to manipulate ungraspable objects. However, prior works on non-prehensile manipulation cannot yet generalize across environments with diverse geometries. The main challenge lies in adapting to varying environmental constraints: within a cabinet, the robot must avoid walls and ceilings; to lift objects to the top of a step, the robot must account for the step's pose and extent. While deep reinforcement learning (RL) has demonstrated impressive success in non-prehensile manipulation, accounting for such variability presents a challenge for the generalist policy, as it must learn diverse strategies for each new combination of constraints. To address this, we propose a modular and reconfigurable architecture that adaptively reconfigures network modules based on task requirements. To capture the geometric variability in environments, we extend the contact-based object representation (CORN) to environment geometries, and propose a procedural algorithm for generating diverse environments to train our agent. Taken together, the resulting policy can zero-shot transfer to novel real-world environments and objects despite training entirely within a simulator. We additionally release a simulation-based benchmark featuring nine digital twins of real-world scenes with 353 objects to facilitate non-prehensile manipulation research in realistic domains.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Power of Personality: A Human Simulation Perspective to Investigate Large Language Model Agents</title>
<link>https://arxiv.org/abs/2502.20859</link>
<guid>https://arxiv.org/abs/2502.20859</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、人类模拟、人格特质、问题解决、创造性写作<br /><br />总结: 本文探讨了大型语言模型（LLMs）的智能表现，并从“人类模拟”的角度出发，回答了三个核心问题：1) 人格特质如何影响封闭任务中的问题解决？2) 特质如何塑造开放任务中的创新性？3) 单一智能体的表现如何影响多智能体协作？通过将五大人格特质赋予LLM智能体并评估其在单一及多智能体环境下的表现，研究发现特定的人格特质对推理准确性和创造性产出具有显著影响。此外，多智能体系统展现出了与单个智能体能力不同的集体智慧，这种智慧由特定的人格特质组合驱动。文章还证明了LLMs通过下一词预测内在地模拟人类行为，从而模仿人类的语言、决策和合作动态。 <div>
arXiv:2502.20859v1 Announce Type: new 
Abstract: Large language models (LLMs) excel in both closed tasks (including problem-solving, and code generation) and open tasks (including creative writing), yet existing explanations for their capabilities lack connections to real-world human intelligence. To fill this gap, this paper systematically investigates LLM intelligence through the lens of ``human simulation'', addressing three core questions: (1) How do personality traits affect problem-solving in closed tasks? (2) How do traits shape creativity in open tasks? (3) How does single-agent performance influence multi-agent collaboration? By assigning Big Five personality traits to LLM agents and evaluating their performance in single- and multi-agent settings, we reveal that specific traits significantly influence reasoning accuracy (closed tasks) and creative output (open tasks). Furthermore, multi-agent systems exhibit collective intelligence distinct from individual capabilities, driven by distinguishing combinations of personalities. We demonstrate that LLMs inherently simulate human behavior through next-token prediction, mirroring human language, decision-making, and collaborative dynamics.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retrieval Augmented Generation for Topic Modeling in Organizational Research: An Introduction with Empirical Demonstration</title>
<link>https://arxiv.org/abs/2502.20963</link>
<guid>https://arxiv.org/abs/2502.20963</guid>
<content:encoded><![CDATA[
<div> 关键词：文本分析、话题建模、LLM（大型语言模型）、Agentic RAG、效率、可解释性、可靠性

<br />
总结:
本文介绍了一种名为Agentic RAG的新方法，用于基于LLMs的话题建模。Agentic RAG结合了三个关键组件：检索（自动化访问LLM预训练知识之外的外部数据）、生成（利用LLM进行文本合成）和代理驱动学习（迭代优化检索和查询制定过程）。通过重新分析Twitter/X数据集并对比标准机器学习方法及LLM提示法，研究发现Agentic RAG在话题建模上表现出更高的效率、可解释性和可靠性，生成的议题更具语义相关性和可重复性。因此，Agentic RAG被认为是领导力、管理及组织研究领域中一种强大、可扩展且透明的AI驱动定性研究替代方案。 <div>
arXiv:2502.20963v1 Announce Type: new 
Abstract: Analyzing textual data is the cornerstone of qualitative research. While traditional methods such as grounded theory and content analysis are widely used, they are labor-intensive and time-consuming. Topic modeling offers an automated complement. Yet, existing approaches, including LLM-based topic modeling, still struggle with issues such as high data preprocessing requirements, interpretability, and reliability. This paper introduces Agentic Retrieval-Augmented Generation (Agentic RAG) as a method for topic modeling with LLMs. It integrates three key components: (1) retrieval, enabling automatized access to external data beyond an LLM's pre-trained knowledge; (2) generation, leveraging LLM capabilities for text synthesis; and (3) agent-driven learning, iteratively refining retrieval and query formulation processes. To empirically validate Agentic RAG for topic modeling, we reanalyze a Twitter/X dataset, previously examined by Mu et al. (2024a). Our findings demonstrate that the approach is more efficient, interpretable and at the same time achieves higher reliability and validity in comparison to the standard machine learning approach but also in comparison to LLM prompting for topic modeling. These results highlight Agentic RAG's ability to generate semantically relevant and reproducible topics, positioning it as a robust, scalable, and transparent alternative for AI-driven qualitative research in leadership, managerial, and organizational research.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Impact of Navigation on Proxemics in an Immersive Virtual Environment with Conversational Agents</title>
<link>https://arxiv.org/abs/2502.20990</link>
<guid>https://arxiv.org/abs/2502.20990</guid>
<content:encoded><![CDATA[
<div> 关键词：社交VR、人际距离、虚拟现实、传送、自然行走

<br /><br />总结:
本文探讨了社交虚拟现实中，随着其日益普及，优化交互体验的重要性。研究发现，在社交VR中，人际距离是一个关键因素，而以往心理学研究表明个人空间被侵犯会导致压力和不适。文章特别关注了常用移动方式——传送对于接近感的影响，通过让70名参与者与化身对话代理进行互动，对比了传送与自然行走两种方式下的人际距离。结果表明，使用传送时，参与者与代理之间的距离更近；女性参与者相比男性保持了更大的距离；同时，自然行走能带来更高的主体感和身体所有权感受，但并未影响共同存在感。作者认为，传送造成的空间感知差异和空间认知负荷可能是导致人际距离缩短的原因。这些发现强调，在选择社交VR中的移动方式时，应充分考虑接近感问题，并指出需要进一步研究移动方式如何影响虚拟环境中的空间感知和社会动态。 <div>
arXiv:2502.20990v1 Announce Type: new 
Abstract: As social VR grows in popularity, understanding how to optimise interactions becomes increasingly important. Interpersonal distance (the physical space people maintain between each other) is a key aspect of user experience. Previous work in psychology has shown that breaches of personal space cause stress and discomfort. Thus, effectively managing this distance is crucial in social VR, where social interactions are frequent. Teleportation, a commonly used locomotion method in these environments, involves distinct cognitive processes and requires users to rely on their ability to estimate distance. Despite its widespread use, the effect of teleportation on proximity remains unexplored. To investigate this, we measured the interpersonal distance of 70 participants during interactions with embodied conversational agents, comparing teleportation to natural walking. Our findings revealed that participants maintained closer proximity from the agents during teleportation. Female participants kept greater distances from the agents than male participants, and natural walking was associated with higher agency and body ownership, though co-presence remained unchanged. We propose that differences in spatial perception and spatial cognitive load contribute to reduced interpersonal distance with teleportation. These findings emphasise that proximity should be a key consideration when selecting locomotion methods in social VR, highlighting the need for further research on how locomotion impacts spatial perception and social dynamics in virtual environments.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Specialized Wireless Networks Using an ML-Driven Radio Interface</title>
<link>https://arxiv.org/abs/2502.20996</link>
<guid>https://arxiv.org/abs/2502.20996</guid>
<content:encoded><![CDATA[
<div> 关键词: SpecNets、无线网络、人工智能、机器学习、MLDRs

<br /><br />总结:
本文介绍了SpecNets，这是一种未来无线网络的概念，它具有认知能力并能动态适应不同应用和场景的独特需求。SpecNets的发展得益于人工智能与机器学习（AI/ML）的进步，它们使网络能够根据变化的需求和环境自主学习并调整通信协议，实现AI/ML定义的无线电（MLDRs）。文中提出了三个无线局域网（WLAN）的应用示例：定制化工业网络、交通感知的稳健THz链接以及共存网络。在工业应用场景中，通过引入基于多臂博弈（MABs）的轻量级、快速收敛的ML代理，展示了SpecNets的优势。该代理能动态优化信道接入以满足不同的性能需求，如高吞吐量、低延迟或公平访问，实验结果表明相比于IEEE 802.11标准，SpecNets在不同场景下具有显著的自适应优势。 <div>
arXiv:2502.20996v1 Announce Type: new 
Abstract: Future wireless networks will need to support diverse applications (such as extended reality), scenarios (such as fully automated industries), and technological advances (such as terahertz communications). Current wireless networks are designed to perform adequately across multiple scenarios so they lack the adaptability needed for specific use cases. Therefore, meeting the stringent requirements of next-generation applications incorporating technology advances and operating in novel scenarios will necessitate wireless specialized networks which we refer to as SpecNets. These networks, equipped with cognitive capabilities, dynamically adapt to the unique demands of each application, e.g., by automatically selecting and configuring network mechanisms. An enabler of SpecNets are the recent advances in artificial intelligence and machine learning (AI/ML), which allow to continuously learn and react to changing requirements and scenarios. By integrating AI/ML functionalities, SpecNets will fully leverage the concept of AI/ML-defined radios (MLDRs) that are able to autonomously establish their own communication protocols by acquiring contextual information and dynamically adapting to it. In this paper, we introduce SpecNets and explain how MLDR interfaces enable this concept. We present three illustrative use cases for wireless local area networks (WLANs): bespoke industrial networks, traffic-aware robust THz links, and coexisting networks. Finally, we showcase SpecNets' benefits in the industrial use case by introducing a lightweight, fast-converging ML agent based on multi-armed bandits (MABs). This agent dynamically optimizes channel access to meet varying performance needs: high throughput, low delay, or fair access. Results demonstrate significant gains over IEEE 802.11, highlighting the system's autonomous adaptability across diverse scenarios.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The amplifier effect of artificial agents in social contagion</title>
<link>https://arxiv.org/abs/2502.21037</link>
<guid>https://arxiv.org/abs/2502.21037</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能、社会传播、人工代理、语言模型、行为影响

总结:
本文研究了人工智能代理在与人类交互中的作用，发现AI代理显著加速并扩大了社会传播现象。研究通过使用基于大型语言模型的人工智能代理重复先前进行的选择实验，量化了AI代理的采纳阈值及其对社交网络传播的影响。结果表明，相较于人类，AI代理具有更低的采纳阈值，导致更广泛的社会传播。由此，文章指出在现实世界网络中人工智能代理人越来越多的存在可能会以不可预见的方式加速行为变化。 <div>
arXiv:2502.21037v1 Announce Type: new 
Abstract: Recent advances in artificial intelligence have led to the proliferation of artificial agents in social contexts, ranging from education to online social media and financial markets, among many others. The increasing rate at which artificial and human agents interact makes it urgent to understand the consequences of human-machine interactions for the propagation of new ideas, products, and behaviors in society. Across two distinct empirical contexts, we find here that artificial agents lead to significantly faster and wider social contagion. To this end, we replicate a choice experiment previously conducted with human subjects by using artificial agents powered by large language models (LLMs). We use the experiment's results to measure the adoption thresholds of artificial agents and their impact on the spread of social contagion. We find that artificial agents tend to exhibit lower adoption thresholds than humans, which leads to wider network-based social contagions. Our findings suggest that the increased presence of artificial agents in real-world networks may accelerate behavioral shifts, potentially in unforeseen ways.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward Learning from Multiple Feedback Types</title>
<link>https://arxiv.org/abs/2502.21038</link>
<guid>https://arxiv.org/abs/2502.21038</guid>
<content:encoded><![CDATA[
<div> 关键词: 学习奖励、偏好反馈、多类型反馈、强化学习、模拟反馈

总结:<br />
本文探讨了利用多种类型的反馈进行奖励学习在智能体模型对齐中的重要性。研究重点在于，除了常见的二元比较偏好反馈外，其他更丰富的多样性人类反馈可以更好地支持注释者的目标，并可能为奖励学习过程带来相互补充的信息或不同类型偏见。文章通过生成六种不同类型的高质量模拟反馈，并针对这六种反馈类型实现奖励模型和下游强化学习训练。实验结果显示，多种类型的反馈可以被有效利用并导致强大的奖励建模性能，这为多元反馈在强化学习中的人类反馈学习（RLHF）的应用提供了首个有力的证据。 <div>
arXiv:2502.21038v1 Announce Type: new 
Abstract: Learning rewards from preference feedback has become an important tool in the alignment of agentic models. Preference-based feedback, often implemented as a binary comparison between multiple completions, is an established method to acquire large-scale human feedback. However, human feedback in other contexts is often much more diverse. Such diverse feedback can better support the goals of a human annotator, and the simultaneous use of multiple sources might be mutually informative for the learning process or carry type-dependent biases for the reward learning process. Despite these potential benefits, learning from different feedback types has yet to be explored extensively. In this paper, we bridge this gap by enabling experimentation and evaluating multi-type feedback in a broad set of environments. We present a process to generate high-quality simulated feedback of six different types. Then, we implement reward models and downstream RL training for all six feedback types. Based on the simulated feedback, we investigate the use of types of feedback across ten RL environments and compare them to pure preference-based baselines. We show empirically that diverse types of feedback can be utilized and lead to strong reward modeling performance. This work is the first strong indicator of the potential of multi-type feedback for RLHF.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Metric Distortion in Peer Selection</title>
<link>https://arxiv.org/abs/2502.21084</link>
<guid>https://arxiv.org/abs/2502.21084</guid>
<content:encoded><![CDATA[
<div> 关键词：metric distortion、投票规则、社交成本、线性度量、同行选择

总结:
这篇论文首次研究了当选民和候选人位于同一个度量空间（即同行选择）时的度量扭曲问题。文章针对不同类型的社交成本函数（包括总体效用与平均效用）以及线性度量空间进行了深入探讨。对于总体效用（加法聚合），论文指出选取中间排名的$k$个候选人可以实现随着$k$从1变化到$n$时，其扭曲率在1和2之间变化的结果。而对于个体距离其$q$个最近候选人的成本函数（$q$-cost），当$q=k=2$时有积极结果，但普遍而言，当$q \leq k/2$时不可能存在常数扭曲率，而$q \geq k/2 + 1$时最佳扭曲率不超过$3/2$。对于平均效用社交成本，选择极端排名的候选人可达到对于加法成本和$q$-cost（$q > k/3$）的最佳可能扭曲率为2；然而，当$q \leq k/3$时，不存在常数扭曲率。总的来说，相较于通用设置，该共同选民与候选人间的设定允许得到更好的常数值，但在某些情况下，通用设置中不可能存在的常数扭曲率问题在此设定下仍然困难。 <div>
arXiv:2502.21084v1 Announce Type: new 
Abstract: In the metric distortion problem, a set of voters and candidates lie in a common metric space, and a committee of $k$ candidates is to be elected. The goal is to select a committee with a small social cost, defined as an increasing function of the distances between voters and selected candidates, but a voting rule only has access to voters' ordinal preferences. The distortion of a rule is then defined as the worst-case ratio between the social cost of the selected set and the optimal set, over all possible preferences and consistent distances.
  We initiate the study of metric distortion when voters and candidates coincide, which arises naturally in peer selection, and provide tight results for various social cost functions on the line metric. We consider both utilitarian and egalitarian social cost, given by the sum and maximum of the individual social costs, respectively. For utilitarian social cost, we show that the voting rule that selects the $k$ middle agents achieves a distortion that varies between $1$ and $2$ as $k$ varies from $1$ to $n$ when the cost of an individual is the sum of their distances to all selected candidates (additive aggregation). When the cost of an individual is their distance to their $q$th closest candidate ($q$-cost), we provide positive results for $q=k=2$ but mostly show that negative results for general elections carry over to our setting: No constant distortion is possible when $q\leq k/2$ and no distortion better than $3/2$ is possible for $q\geq k/2+1$. For egalitarian social cost, selecting extreme agents achieves the best-possible distortion of $2$ for additive cost and $q$-cost with $q> k/3$, whereas no constant distortion is possible for $q\leq k/3$. Overall, having a common set of voters and candidates allows for better constants compared to the general setting, but cases in which no constant is possible in general remain hard in this setting.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PASemiQA: Plan-Assisted Agent for Question Answering on Semi-Structured Data with Text and Relational Information</title>
<link>https://arxiv.org/abs/2502.21087</link>
<guid>https://arxiv.org/abs/2502.21087</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、知识检索增强生成、半结构化数据、PASemiQA、准确性

总结:
本文介绍了一种针对大型语言模型在处理需要专业和实时知识问题时存在的幻觉问题的新方法——PASemiQA。PASemiQA旨在通过结合半结构化数据中的文本和关系信息来有效回答问题。与现有的仅关注单一类型外部数据（如向量化文本数据库或知识图谱）的检索增强生成方法不同，PASemiQA能更好地处理包含文本和关系信息的现实世界问题。该方法首先生成一个计划以识别相关文本和关系信息，然后利用LLM代理遍历并从半结构化数据中提取必要信息。实验结果表明，PASemiQA在不同领域的多个半结构化数据集上表现出了有效性，从而凸显了其提升基于半结构化数据的问题回答系统的准确性和可靠性的潜力。 <div>
arXiv:2502.21087v1 Announce Type: new 
Abstract: Large language models (LLMs) have shown impressive abilities in answering questions across various domains, but they often encounter hallucination issues on questions that require professional and up-to-date knowledge. To address this limitation, retrieval-augmented generation (RAG) techniques have been proposed, which retrieve relevant information from external sources to inform their responses. However, existing RAG methods typically focus on a single type of external data, such as vectorized text database or knowledge graphs, and cannot well handle real-world questions on semi-structured data containing both text and relational information. To bridge this gap, we introduce PASemiQA, a novel approach that jointly leverages text and relational information in semi-structured data to answer questions. PASemiQA first generates a plan to identify relevant text and relational information to answer the question in semi-structured data, and then uses an LLM agent to traverse the semi-structured data and extract necessary information. Our empirical results demonstrate the effectiveness of PASemiQA across different semi-structured datasets from various domains, showcasing its potential to improve the accuracy and reliability of question answering systems on semi-structured data.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Jointly Assigning Processes to Machines and Generating Plans for Autonomous Mobile Robots in a Smart Factory</title>
<link>https://arxiv.org/abs/2502.21101</link>
<guid>https://arxiv.org/abs/2502.21101</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2502.21101v1, 智能工厂, 移动机器人, 通过率, ACES<br /><br />总结:
本文介绍了arXiv论文2502.21101v1，提出了一种名为ACES（Anytime Cyclic Embedding Solver）的新算法。ACES是首个同时优化智能工厂中制造流程与机器分配以及物料搬运路径和移动机器人分配的解决方案。现有的智能工厂管理系统分别解决这两个问题，限制了其能达到的生产通过率。文章表明，ACES能够处理实际工业场景并具有良好的可扩展性，有助于提升智能工厂的生产效率。 <div>
arXiv:2502.21101v1 Announce Type: new 
Abstract: A modern smart factory runs a manufacturing procedure using a collection of programmable machines. Typically, materials are ferried between these machines using a team of mobile robots. To embed a manufacturing procedure in a smart factory, a factory operator must a) assign its processes to the smart factory's machines and b) determine how agents should carry materials between machines. A good embedding maximizes the smart factory's throughput; the rate at which it outputs products. Existing smart factory management systems solve the aforementioned problems sequentially, limiting the throughput that they can achieve. In this paper we introduce ACES, the Anytime Cyclic Embedding Solver, the first solver which jointly optimizes the assignment of processes to machines and the assignment of paths to agents. We evaluate ACES and show that it can scale to real industrial scenarios.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.21142</link>
<guid>https://arxiv.org/abs/2502.21142</guid>
<content:encoded><![CDATA[
<div> 关键词: 世界模型, 强化学习, 全局工作空间理论, 深度学习, 抗干扰能力

<br /><br />总结:
本文探讨了将全局工作空间（GW）理论与世界模型相结合应用于强化学习（RL）中的可能性。研究发现，通过在GW潜空间中进行“梦想过程”（即心理模拟），可以减少对环境步骤的依赖，加快训练进程。此外，使用GW-Dreamer算法的RL系统展现出了一个额外的突出现象：即使缺失观察模态（如图像或模拟属性）之一，仍能保持强大的抗干扰能力。这表明，将GW与世界模型结合对于提升RL智能体的决策制定能力具有巨大潜力。 <div>
arXiv:2502.21142v1 Announce Type: new 
Abstract: Humans leverage rich internal models of the world to reason about the future, imagine counterfactuals, and adapt flexibly to new situations. In Reinforcement Learning (RL), world models aim to capture how the environment evolves in response to the agent's actions, facilitating planning and generalization. However, typical world models directly operate on the environment variables (e.g. pixels, physical attributes), which can make their training slow and cumbersome; instead, it may be advantageous to rely on high-level latent dimensions that capture relevant multimodal variables. Global Workspace (GW) Theory offers a cognitive framework for multimodal integration and information broadcasting in the brain, and recent studies have begun to introduce efficient deep learning implementations of GW. Here, we evaluate the capabilities of an RL system combining GW with a world model. We compare our GW-Dreamer with various versions of the standard PPO and the original Dreamer algorithms. We show that performing the dreaming process (i.e., mental simulation) inside the GW latent space allows for training with fewer environment steps. As an additional emergent property, the resulting model (but not its comparison baselines) displays strong robustness to the absence of one of its observation modalities (images or simulation attributes). We conclude that the combination of GW with World Models holds great potential for improving decision-making in RL agents.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cryptis: Cryptographic Reasoning in Separation Logic</title>
<link>https://arxiv.org/abs/2502.21156</link>
<guid>https://arxiv.org/abs/2502.21156</guid>
<content:encoded><![CDATA[
<div> 关键词: Cryptis、Iris分离逻辑、符号模型、密码学验证、协议正确性

总结:
Cryptis 是一个对 Iris 分离逻辑的扩展，旨在利用密码学的符号模型来验证加密组件的正确性。这一结合使得能够证明协议的正确性，并进一步重用来验证依赖该协议的更大系统。为实现这一整合，文章提出了新的认证协议规范，允许网络中的代理就系统资源使用达成一致。通过验证各种认证协议以及一个利用这些认证协议与客户端连接的关键值存储服务器，论文展示了其方法的有效性。所有结果均在 Coq 中进行了形式化证明。<br /><br /> <div>
arXiv:2502.21156v1 Announce Type: new 
Abstract: We introduce Cryptis, an extension of the Iris separation logic that can be used to verify cryptographic components using the symbolic model of cryptography. The combination of separation logic and cryptographic reasoning allows us to prove the correctness of a protocol and later reuse this result to verify larger systems that rely on the protocol. To make this integration possible, we propose novel specifications for authentication protocols that allow agents in a network to agree on the use of system resources. We evaluate our approach by verifying various authentication protocols and a key-value store server that uses these authentication protocols to connect to clients. Our results are formalized in Coq.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Autonomous Curriculum Design via Relative Entropy Based Task Modifications</title>
<link>https://arxiv.org/abs/2502.21166</link>
<guid>https://arxiv.org/abs/2502.21166</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主课程设计、学习不确定性、相对熵、自我评估、教师指导

<br /><br />总结:
本文提出了一种新颖的自动课程设计方法，该方法利用学习者策略的不确定性来选择课程任务。通过使用相对熵度量学习者策略的不确定性，引导代理向不确定性高的状态进行学习，从而促进学习效率。该算法支持以自评方式生成自主课程，并能在指导性设置中结合教师引导的设计。文章提供了基于两时间尺度优化过程的算法收敛性理论保证。实验结果显示，该算法优于随机生成的课程以及直接在目标任务上学习和现有文献中的课程学习标准。此外，文中还提出了两种额外的启发式距离度量，可用于与相对熵方法结合进一步提升性能。 <div>
arXiv:2502.21166v1 Announce Type: new 
Abstract: Curriculum learning is a training method in which an agent is first trained on a curriculum of relatively simple tasks related to a target task in an effort to shorten the time required to train on the target task. Autonomous curriculum design involves the design of such curriculum with no reliance on human knowledge and/or expertise. Finding an efficient and effective way of autonomously designing curricula remains an open problem. We propose a novel approach for automatically designing curricula by leveraging the learner's uncertainty to select curricula tasks. Our approach measures the uncertainty in the learner's policy using relative entropy, and guides the agent to states of high uncertainty to facilitate learning. Our algorithm supports the generation of autonomous curricula in a self-assessed manner by leveraging the learner's past and current policies but it also allows the use of teacher guided design in an instructive setting. We provide theoretical guarantees for the convergence of our algorithm using two time-scale optimization processes. Results show that our algorithm outperforms randomly generated curriculum, and learning directly on the target task as well as the curriculum-learning criteria existing in literature. We also present two additional heuristic distance measures that could be combined with our relative-entropy approach for further performance improvements.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reducing Reward Dependence in RL Through Adaptive Confidence Discounting</title>
<link>https://arxiv.org/abs/2502.21181</link>
<guid>https://arxiv.org/abs/2502.21181</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、人类反馈、昂贵奖励、算法效率、信心度

总结:
我们提出了一种新的强化学习算法，旨在减少智能体对人类反馈或昂贵奖励的依赖，从而提高学习效率并保持所学策略的质量。该算法仅在对环境状态中动作价值估计不确定性较高时请求奖励。当模型对其预测奖励和/或行为选择具有高置信度时，则使用奖励函数模型作为人类提供的或昂贵奖励的代理。通过降低获取昂贵奖励的频率，我们的方法能够在获取奖励物流困难或成本高昂的情况下有效地进行学习。实验表明，与基线相比，我们的方法在返回值和所需学习剧集数量方面表现相当，但能够以仅为基线20%的奖励次数实现这一性能。<br /><br /> <div>
arXiv:2502.21181v1 Announce Type: new 
Abstract: In human-in-the-loop reinforcement learning or environments where calculating a reward is expensive, the costly rewards can make learning efficiency challenging to achieve. The cost of obtaining feedback from humans or calculating expensive rewards means algorithms receiving feedback at every step of long training sessions may be infeasible, which may limit agents' abilities to efficiently improve performance. Our aim is to reduce the reliance of learning agents on humans or expensive rewards, improving the efficiency of learning while maintaining the quality of the learned policy. We offer a novel reinforcement learning algorithm that requests a reward only when its knowledge of the value of actions in an environment state is low. Our approach uses a reward function model as a proxy for human-delivered or expensive rewards when confidence is high, and asks for those explicit rewards only when there is low confidence in the model's predicted rewards and/or action selection. By reducing dependence on the expensive-to-obtain rewards, we are able to learn efficiently in settings where the logistics or expense of obtaining rewards may otherwise prohibit it. In our experiments our approach obtains comparable performance to a baseline in terms of return and number of episodes required to learn, but achieves that performance with as few as 20% of the rewards.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scalable Decision-Making in Stochastic Environments through Learned Temporal Abstraction</title>
<link>https://arxiv.org/abs/2502.21186</link>
<guid>https://arxiv.org/abs/2502.21186</guid>
<content:encoded><![CDATA[
<div> 关键词：线下强化学习、高维连续动作空间、序列决策、潜在宏动作规划器（L-MAP）、矢量量化变分自编码器（VQ-VAE）

<br /><br />总结:

本文提出了一个针对高维连续动作空间中序列决策问题的新方法——潜在宏动作规划器（L-MAP），旨在解决在随机环境中面临的计算挑战。在传统的离线强化学习场景下，L-MAP通过状态条件下的矢量量化变分自编码器（VQ-VAE）学习一组临时扩展的宏观动作，从而降低行动维度。同时，L-MAP利用一个学习得到的先验模型作为潜在转移模型，实现对可行动作的有效采样。在规划阶段，L-MAP运用蒙特卡洛树搜索（MCTS）考虑环境和行为策略的随机性。实验证明，在包括具有内在随机动力学的连续控制任务以及高维机器人手部操纵等离线RL任务中，L-MAP能够有效地搜索离散潜在动作以获得高的期望回报，并展现出优于现有模型基线的方法性能，特别是在复杂和随机环境下高维动作空间的规划方面表现突出。此外，L-MAP还保持了较低的决策延迟。 <div>
arXiv:2502.21186v1 Announce Type: new 
Abstract: Sequential decision-making in high-dimensional continuous action spaces, particularly in stochastic environments, faces significant computational challenges. We explore this challenge in the traditional offline RL setting, where an agent must learn how to make decisions based on data collected through a stochastic behavior policy. We present \textit{Latent Macro Action Planner} (L-MAP), which addresses this challenge by learning a set of temporally extended macro-actions through a state-conditional Vector Quantized Variational Autoencoder (VQ-VAE), effectively reducing action dimensionality. L-MAP employs a (separate) learned prior model that acts as a latent transition model and allows efficient sampling of plausible actions. During planning, our approach accounts for stochasticity in both the environment and the behavior policy by using Monte Carlo tree search (MCTS). In offline RL settings, including stochastic continuous control tasks, L-MAP efficiently searches over discrete latent actions to yield high expected returns. Empirical results demonstrate that L-MAP maintains low decision latency despite increased action dimensionality. Notably, across tasks ranging from continuous control with inherently stochastic dynamics to high-dimensional robotic hand manipulation, L-MAP significantly outperforms existing model-based methods and performs on-par with strong model-free actor-critic baselines, highlighting the effectiveness of the proposed approach in planning in complex and stochastic environments with high-dimensional action spaces.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ARIES: Autonomous Reasoning with LLMs on Interactive Thought Graph Environments</title>
<link>https://arxiv.org/abs/2502.21208</link>
<guid>https://arxiv.org/abs/2502.21208</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、推理任务、思想图变换、马尔科夫决策过程、ARIES

总结:
这篇论文研究了如何利用大型语言模型（LLM）提升在推理任务上的性能。文章提出了一种将思想图变换视为马尔科夫决策过程中行动的方法，并实现了名为ARIES的多智能体架构，该架构中，推理LLM解决子问题，而策略LLM则观察思想图状态并动态调整解题策略。实验表明，使用现成的LLM作为策略代理，无需监督微调（SFT），相比于静态变换调度，在HumanEval基准上能提高最多29%的准确率，并降低了35%的推理成本，同时避免了搜索需求。然而，文章也分析了观察到的失败模式，指出LLM大小的限制和问题分解的深度可能是扩展LLM引导推理的挑战。<br /><br /> <div>
arXiv:2502.21208v1 Announce Type: new 
Abstract: Recent research has shown that LLM performance on reasoning tasks can be enhanced by scaling test-time compute. One promising approach, particularly with decomposable problems, involves arranging intermediate solutions as a graph on which transformations are performed to explore the solution space. However, prior works rely on pre-determined, task-specific transformation schedules which are subject to a set of searched hyperparameters. In this work, we view thought graph transformations as actions in a Markov decision process, and implement policy agents to drive effective action policies for the underlying reasoning LLM agent. In particular, we investigate the ability for another LLM to act as a policy agent on thought graph environments and introduce ARIES, a multi-agent architecture for reasoning with LLMs. In ARIES, reasoning LLM agents solve decomposed subproblems, while policy LLM agents maintain visibility of the thought graph states, and dynamically adapt the problem-solving strategy. Through extensive experiments, we observe that using off-the-shelf LLMs as policy agents with no supervised fine-tuning (SFT) can yield up to $29\%$ higher accuracy on HumanEval relative to static transformation schedules, as well as reducing inference costs by $35\%$ and avoid any search requirements. We also conduct a thorough analysis of observed failure modes, highlighting that limitations on LLM sizes and the depth of problem decomposition can be seen as challenges to scaling LLM-guided reasoning.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Method of Selective Attention for Reservoir Based Agents</title>
<link>https://arxiv.org/abs/2502.21229</link>
<guid>https://arxiv.org/abs/2502.21229</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度强化学习、输入维度、层归一化、注意力机制、训练加速

总结:<br />
本文探讨了深度强化学习中无关输入维度对训练速度的影响。研究发现，通过添加权重衰减训练的层归一化模块可以作为选择性注意力机制，缩小无用输入的尺度，从而加快策略训练。然而，实验表明，增加大量参数到输入掩码计算中能显著加快训练速度。文章比较了一种高维掩码模块与层归一化以及无输入抑制模型的效果，结果显示，高维掩码模块相比未使用任何输入抑制的情况，训练速度快了四倍；而相比于层归一化方法，则快了两倍。 <div>
arXiv:2502.21229v1 Announce Type: new 
Abstract: Training of deep reinforcement learning agents is slowed considerably by the presence of input dimensions that do not usefully condition the reward function. Existing modules such as layer normalization can be trained with weight decay to act as a form of selective attention, i.e. an input mask, that shrinks the scale of unnecessary inputs, which in turn accelerates training of the policy. However, we find a surprising result that adding numerous parameters to the computation of the input mask results in much faster training. A simple, high dimensional masking module is compared with layer normalization and a model without any input suppression. The high dimensional mask resulted in a four-fold speedup in training over the null hypothesis and a two-fold speedup in training over the layer normalization method.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Developing Ethical Reasoners: Integrating Probabilistic Reasoning and Decision-Making for Complex AI Systems</title>
<link>https://arxiv.org/abs/2502.21250</link>
<guid>https://arxiv.org/abs/2502.21250</guid>
<content:encoded><![CDATA[
<div> 关键词：计算伦理框架、人工智能、自主系统、动态环境、概率推理

<br />
总结：
本文提出构建一个针对AI和自主系统在复杂现实环境中运作所需的计算伦理框架。现有的方法往往缺乏适应性，难以将道德原则融入到动态和模糊的情境中。为此，文章指出了建立一个全面的、元层次的框架所必需的要素，该框架结合了中间表示法、概率推理和知识表示，强调可扩展性，能够支持个体决策层面以及多智能体系统的集体动态中的伦理推理。通过整合理论原则与情境因素，它能促进结构化和情境感知的决策制定，确保与总体道德标准对齐。此外，文中还探讨了关于伦理推理应如何运作的假设定理，为实际应用提供了基础。这些构建旨在支持开发能够在真实世界道德决策场景中处理复杂性的强大而伦理可靠的AI系统。 <div>
arXiv:2502.21250v1 Announce Type: new 
Abstract: A computational ethics framework is essential for AI and autonomous systems operating in complex, real-world environments. Existing approaches often lack the adaptability needed to integrate ethical principles into dynamic and ambiguous contexts, limiting their effectiveness across diverse scenarios. To address these challenges, we outline the necessary ingredients for building a holistic, meta-level framework that combines intermediate representations, probabilistic reasoning, and knowledge representation. The specifications therein emphasize scalability, supporting ethical reasoning at both individual decision-making levels and within the collective dynamics of multi-agent systems. By integrating theoretical principles with contextual factors, it facilitates structured and context-aware decision-making, ensuring alignment with overarching ethical standards. We further explore proposed theorems outlining how ethical reasoners should operate, offering a foundation for practical implementation. These constructs aim to support the development of robust and ethically reliable AI systems capable of navigating the complexities of real-world moral decision-making scenarios.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ReaLJam: Real-Time Human-AI Music Jamming with Reinforcement Learning-Tuned Transformers</title>
<link>https://arxiv.org/abs/2502.21267</link>
<guid>https://arxiv.org/abs/2502.21267</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能, 生成模型, 实时交互, 预期, ReaLJam

总结:
<br />
近期，人工智能在音乐内容生成方面的进步催生了高质量模型。然而，对于实时或合作即兴演奏的应用考虑不足，主要因为需要低延迟、沟通计划动作和实时适应用户输入的功能。为此，本文提出了一种名为ReaLJam的接口和协议，用于人类与基于Transformer的强化学习训练的人工智能代理之间的实时音乐即兴演奏会话。通过利用预期概念，使代理能够持续预测表演的发展并视觉化传达其计划给用户。文章进行了用户体验研究，让经验丰富的音乐家通过ReaLJam与该代理进行实时即兴演奏。结果显示，ReaLJam能够支持愉快且具有音乐性的演奏会话，并为未来工作揭示了重要的启示。 <div>
arXiv:2502.21267v1 Announce Type: new 
Abstract: Recent advances in generative artificial intelligence (AI) have created models capable of high-quality musical content generation. However, little consideration is given to how to use these models for real-time or cooperative jamming musical applications because of crucial required features: low latency, the ability to communicate planned actions, and the ability to adapt to user input in real-time. To support these needs, we introduce ReaLJam, an interface and protocol for live musical jamming sessions between a human and a Transformer-based AI agent trained with reinforcement learning. We enable real-time interactions using the concept of anticipation, where the agent continually predicts how the performance will unfold and visually conveys its plan to the user. We conduct a user study where experienced musicians jam in real-time with the agent through ReaLJam. Our results demonstrate that ReaLJam enables enjoyable and musically interesting sessions, and we uncover important takeaways for future work.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Persuasion Should be Double-Blind: A Multi-Domain Dialogue Dataset With Faithfulness Based on Causal Theory of Mind</title>
<link>https://arxiv.org/abs/2502.21297</link>
<guid>https://arxiv.org/abs/2502.21297</guid>
<content:encoded><![CDATA[
<div> 关键词：Persuasive dialogue, Double Blind condition, Theory of Mind, ToMMA, CToMPersu

总结:<br />
本文提出了一个新的多代理对话生成框架ToMMA，该框架基于因果理论of Mind引导对话并确保了信息在代理人之间的不透明性，保持了“双盲”条件。同时，文章指出现有的劝说对话数据集往往与现实人际互动不符，为解决这一问题，作者构建了一个名为CToMPersu的多领域、多轮劝说对话数据集，它既解决了双盲问题，又关注逻辑连贯性。实验显示CToMPersu在多个指标上表现出优越性能，更贴近真实人类对话。相关资源已发布在GitHub上。 <div>
arXiv:2502.21297v1 Announce Type: new 
Abstract: Persuasive dialogue plays a pivotal role in human communication, influencing various domains. Recent persuasive dialogue datasets often fail to align with real-world interpersonal interactions, leading to unfaithful representations. For instance, unrealistic scenarios may arise, such as when the persuadee explicitly instructs the persuader on which persuasion strategies to employ, with each of the persuadee's questions corresponding to a specific strategy for the persuader to follow. This issue can be attributed to a violation of the "Double Blind" condition, where critical information is fully shared between participants. In actual human interactions, however, key information such as the mental state of the persuadee and the persuasion strategies of the persuader is not directly accessible. The persuader must infer the persuadee's mental state using Theory of Mind capabilities and construct arguments that align with the persuadee's motivations. To address this gap, we introduce ToMMA, a novel multi-agent framework for dialogue generation that is guided by causal Theory of Mind. This framework ensures that information remains undisclosed between agents, preserving "double-blind" conditions, while causal ToM directs the persuader's reasoning, enhancing alignment with human-like persuasion dynamics. Consequently, we present CToMPersu, a multi-domain, multi-turn persuasive dialogue dataset that tackles both double-blind and logical coherence issues, demonstrating superior performance across multiple metrics and achieving better alignment with real human dialogues. Our dataset and prompts are available at https://github.com/DingyiZhang/ToMMA-CToMPersu .
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Revisiting a Design Choice in Gradient Temporal Difference Learning</title>
<link>https://arxiv.org/abs/2308.01170</link>
<guid>https://arxiv.org/abs/2308.01170</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习、off-policy学习、死三角问题、Gradient Temporal Difference (GTD)、$A_t^\top$TD

总结:
本文重新审视了强化学习中解决“死三角问题”的经典算法Gradient Temporal Difference (GTD)，该问题涉及off-policy学习与函数逼近和bootstrapping相结合时可能出现的不稳定性。作者发现了一个被早期研究忽视的中间算法——$A^\top$TD的一个变种，称之为$A_t^\top$TD，它也被证明是一种有效的解决方案。相较于需要两套参数和两个学习率的GTD算法，$A_t^\top$TD仅需一组参数和一个学习率，更便于实际应用中的调参。文章对$A_t^\top$TD进行了渐近分析，并对其一变体（加入投影操作）提供了有限样本分析，其收敛速度可与标准的on-policy Temporal Difference学习法相媲美。 <div>
arXiv:2308.01170v3 Announce Type: replace 
Abstract: Off-policy learning enables a reinforcement learning (RL) agent to reason counterfactually about policies that are not executed and is one of the most important ideas in RL. It, however, can lead to instability when combined with function approximation and bootstrapping, two arguably indispensable ingredients for large-scale reinforcement learning. This is the notorious deadly triad. The seminal work Sutton et al. (2008) pioneers Gradient Temporal Difference learning (GTD) as the first solution to the deadly triad, which has enjoyed massive success thereafter. During the derivation of GTD, some intermediate algorithm, called $A^\top$TD, was invented but soon deemed inferior. In this paper, we revisit this $A^\top$TD and prove that a variant of $A^\top$TD, called $A_t^\top$TD, is also an effective solution to the deadly triad. Furthermore, this $A_t^\top$TD only needs one set of parameters and one learning rate. By contrast, GTD has two sets of parameters and two learning rates, making it hard to tune in practice. We provide asymptotic analysis for $A^\top_t$TD and finite sample analysis for a variant of $A^\top_t$TD that additionally involves a projection operator. The convergence rate of this variant is on par with the canonical on-policy temporal difference learning.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Less Is More: Robust Robot Learning via Partially Observable Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2309.14792</link>
<guid>https://arxiv.org/abs/2309.14792</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体、强化学习、单智能体、局部观察、鲁棒性

总结:
这篇论文探讨了单智能体强化学习（SARL）与多智能体强化学习（MARL）在相同任务中的性能和鲁棒性的关系。研究发现，在全状态观测条件下，独立高斯策略下基于策略梯度的SARL和MARL是等价的。进一步地，实验表明，在某些本质上为单智能体的任务中，利用多个仅具有局部观察信息的智能体来控制机器人，可以在系统发生故障或扰动时提供更高的鲁棒性。实验证实在一个示例化的分布式控制任务以及带有真实机器人的移动操作任务上，拥有部分观察信息的多个智能体表现优于单一智能体。 <div>
arXiv:2309.14792v2 Announce Type: replace 
Abstract: In many multi-agent and high-dimensional robotic tasks, controllers can be optimized centrally or decentrally, using either single-agent reinforcement learning (SARL) or multi-agent reinforcement learning (MARL). However, the relationship between these two paradigms is not well-studied. This work aims to systematically investigate the robustness and performance of SARL and MARL in the same task. We first analytically show that independent Gaussian policies optimized by policy-gradient based SARL and MARL are equivalent under full-state observations. Following, we empirically show that in certain inherently single-agent tasks, perhaps surprisingly, we can use multiple agents to control a robot such that each agent only has access to partial observations. Since in these cases an agent does not depend on full state information multi-agent policies can provide additional robustness to perturbations and failures. Experiments on an illustrative decentralized control task and a mobile manipulation task with a real robot show that multiple agents with access to partial observations outperform a single agent when parts of the system fail.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Identity Based Agent Model for Value Alignment</title>
<link>https://arxiv.org/abs/2401.12159</link>
<guid>https://arxiv.org/abs/2401.12159</guid>
<content:encoded><![CDATA[
<div> 关键词：社交身份、人工智能、计算模型、集体行为、城市交通

总结:<br />
本文探讨了在自主AI代理环境中设计社交身份的计算模型问题。研究提出了一种使代理人能够认同特定观念的代理模型，并展示这种认同如何影响集体结果。文章还对比了身份认同与理性偏好的关联。通过在城市交通的应用背景下模拟该模型，展示了社交身份变化对出行模式和集体结果的影响。 <div>
arXiv:2401.12159v3 Announce Type: replace 
Abstract: Social identities play an important role in the dynamics of human societies, and it can be argued that some sense of identification with a larger cause or idea plays a critical role in making humans act responsibly. Often social activists strive to get populations to identify with some cause or notion -- like green energy, diversity, etc. in order to bring about desired social changes. We explore the problem of designing computational models for social identities in the context of autonomous AI agents. For this, we propose an agent model that enables agents to identify with certain notions and show how this affects collective outcomes. We also contrast between associations of identity with rational preferences. The proposed model is simulated in an application context of urban mobility, where we show how changes in social identity affect mobility patterns and collective outcomes.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Public Projects with Preferences and Predictions</title>
<link>https://arxiv.org/abs/2403.01042</link>
<guid>https://arxiv.org/abs/2403.01042</guid>
<content:encoded><![CDATA[
<div> 关键词：群体决策、偏好聚合、信息聚合、公共项目、社会福利最大化、博弈操纵、预测市场、投票机制、二次转移机制、Price of Anarchy、预算平衡、非渐近Price of Anarchy保证

<br /><br />总结:
本文探讨了在群体决策中同时结合偏好聚合与信息聚合的新型两阶段机制。针对旨在最大化功利主义社会福利的公共项目问题，决策者具有关于备选方案的偏好（通过效用函数表示）和相关信息（以相关于外部福利影响的贝叶斯信号形式存在）。由于激励对齐困难，代理人可能为了操纵决策结果而提供虚假信息或错误报告其偏好。

提出的两阶段机制包括：第一阶段采用赌博机制或预测市场进行信息聚合；第二阶段结合前一阶段的预测结果以及个体偏好，利用近期研究的二次转移机制来选择最佳方案。研究表明，当这两个阶段被巧妙地组合在一起时，整个机制对于各种形式的操纵都具有鲁棒性，并在弱假设下可达到Price of Anarchy性能保证。在两个备选项的情况下，随着人口规模度量的增长，Price of Anarchy趋于1。此外，该机制在大多数情况下还能实现预算平衡。文中还给出了二次转移机制的第一个非渐近Price of Anarchy保证结果，这是一个独立的研究成果。 <div>
arXiv:2403.01042v2 Announce Type: replace 
Abstract: When making a decision as a group, there are two primary paradigms: aggregating preferences (e.g. voting, mechanism design) and aggregating information (e.g. discussion, consulting, forecasting). Almost all formally-studied group decisionmaking mechanisms fall under one paradigm or the other, but not both. We consider a public projects problem with the objective of maximizing utilitarian social welfare. Decisionmakers have both preferences, modeled as utility functions over the alternatives; and information, modeled as Bayesian signals relevant to the alternatives' external welfare impact. Aligning incentives is highly challenging because, on the one hand, agents can provide bad information in order to manipulate the mechanism into satisfying their preferences; and on the other hand, they can misreport their preferences to favor selection of an alternative for which their information rewards are high.
  We propose a two-stage mechanism for this problem. The forecasting stage aggregates information using either a wagering mechanism or a prediction market (the mechanism is modular and compatible with both). The voting stage aggregates preferences, together with the forecasts from the previous stage, and selects an alternative by leveraging the recently-studied Quadratic Transfers Mechanism. We show that, when carefully combined, the entire two-stage mechanism is robust to manipulation of all forms, and under weak assumptions, satisfies Price of Anarchy guarantees. In the case of two alternatives, the Price of Anarchy tends to 1 as natural measures of the "size" of the population grow large. In most cases, the mechanisms achieve a balanced budget as well. We also give the first nonasymptotic Price of Anarchy guarantee for the Quadratic Transfers Mechanism, a result of independent interest.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Scaling Large-Language-Model-based Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2406.07155</link>
<guid>https://arxiv.org/abs/2406.07155</guid>
<content:encoded><![CDATA[
<div> 关键词: 大规模语言模型、多智能体协作、自主任务解决、有向无环图、协同扩展律

<br /><br />总结:
本文研究了通过增加多智能体协作能否像增强神经元数量一样提升性能。受到神经网络规模定律的启发，研究者利用有向无环图（DAG）构建了一种多智能体协作网络（MacNet），用于组织和协调各个智能体间的交互性推理以实现自主任务解决。实验表明，MacNet能够有效地支持上千个智能体的合作，并且不规则拓扑结构优于规则拓扑结构。此外，文章还发现了一个协同扩展律：随着智能体数量的增长，整体性能遵循对数增长模式，并且协同涌现发生的时间早于传统的神经涌现。研究者推测这可能是因为增加智能体促进了它们在互动反思和细化过程中的多维度考量，从而生成更全面的解决方案。相关代码已开源，可在https://github.com/OpenBMB/ChatDev/tree/macnet 获取。 <div>
arXiv:2406.07155v2 Announce Type: replace 
Abstract: Recent breakthroughs in large language model-driven autonomous agents have revealed that multi-agent collaboration often surpasses each individual through collective reasoning. Inspired by the neural scaling law--increasing neurons enhances performance, this study explores whether the continuous addition of collaborative agents can yield similar benefits. Technically, we utilize directed acyclic graphs to organize agents into a multi-agent collaboration network (MacNet), upon which their interactive reasoning is topologically orchestrated for autonomous task solving. Extensive evaluations reveal that it effectively supports collaboration among over a thousand agents, with irregular topologies outperforming regular ones. We also identify a collaborative scaling law--the overall performance follows a logistic growth pattern as agents scale, with collaborative emergence occurring earlier than traditional neural emergence. We speculate this may be because scaling agents catalyzes their multidimensional considerations during interactive reflection and refinement, thereby producing more comprehensive artifacts. The code is available at https://github.com/OpenBMB/ChatDev/tree/macnet.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Efficient Recursive Numeral Systems via Reinforcement Learning</title>
<link>https://arxiv.org/abs/2409.07170</link>
<guid>https://arxiv.org/abs/2409.07170</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、递归数系、交流、元文法、效率优化

总结:
本文探讨了使用强化学习（RL）方法来解释高效递归数系如何通过简单的学习机制如RL得以出现。研究中，作者考虑了两方代理通过可逐步修改的元文法进行关于数量的通信学习。文章指出，Hurford的原始元文法并不适合此类应用，因为它会导致偏离人类数系的标准惯例。为解决这一问题，他们提出了一种简单的修正方案。利用改进后的Hurford元文法，研究人员展示在RL代理间有效的沟通压力下，他们的词汇表可以向帕累托最优配置演变，这些配置在效率上与人类数系观察到的相似。 <div>
arXiv:2409.07170v2 Announce Type: replace 
Abstract: It has previously been shown that by using reinforcement learning (RL), agents can derive simple approximate and exact-restricted numeral systems that are similar to human ones (Carlsson, 2021). However, it is a major challenge to show how more complex recursive numeral systems, similar to for example English, could arise via a simple learning mechanism such as RL. Here, we introduce an approach towards deriving a mechanistic explanation of the emergence of efficient recursive number systems. We consider pairs of agents learning how to communicate about numerical quantities through a meta-grammar that can be gradually modified throughout the interactions. %We find that the seminal meta-grammar of Hurford (Hurford, 1975) is not suitable for this application as its optimization results in systems that deviate from standard conventions observed within human numeral systems. We propose a simple modification which addresses this issue. Utilising a slightly modified version of the meta-grammar of Hurford, we demonstrate that our RL agents, shaped by the pressures for efficient communication, can effectively modify their lexicon towards Pareto-optimal configurations which are comparable to those observed within human numeral systems in terms of their efficiency.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stochasticity in Motion: An Information-Theoretic Approach to Trajectory Prediction</title>
<link>https://arxiv.org/abs/2410.01628</link>
<guid>https://arxiv.org/abs/2410.01628</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、运动预测、不确定性估计、Aleatoric不确定性、Epistemic不确定性

总结:
本文关注于自动驾驶中的运动预测问题，强调了对周围代理人行为预测的准确不确定性估计对于安全和有效运动规划的重要性。文章提出了一个全面的方法来处理轨迹预测中的不确定性建模，重点关注不确定性的量化与分解，以及模型构成对其的影响。该方法基于信息论原理，能够理论化地衡量并分解不确定性为 Aleatoric 不确定性和 Epistemic 不确定性。与现有工作不同的是，该方法适用于最先进的运动预测器，具有更广泛的应用潜力。通过在nuScenes数据集上的大量实验，文章展示了不同的架构和配置如何影响不确定性量化及模型稳健性。 <div>
arXiv:2410.01628v3 Announce Type: replace 
Abstract: In autonomous driving, accurate motion prediction is crucial for safe and efficient motion planning. To ensure safety, planners require reliable uncertainty estimates of the predicted behavior of surrounding agents, yet this aspect has received limited attention. In particular, decomposing uncertainty into its aleatoric and epistemic components is essential for distinguishing between inherent environmental randomness and model uncertainty, thereby enabling more robust and informed decision-making. This paper addresses the challenge of uncertainty modeling in trajectory prediction with a holistic approach that emphasizes uncertainty quantification, decomposition, and the impact of model composition. Our method, grounded in information theory, provides a theoretically principled way to measure uncertainty and decompose it into aleatoric and epistemic components. Unlike prior work, our approach is compatible with state-of-the-art motion predictors, allowing for broader applicability. We demonstrate its utility by conducting extensive experiments on the nuScenes dataset, which shows how different architectures and configurations influence uncertainty quantification and model robustness.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ExACT: Teaching AI Agents to Explore with Reflective-MCTS and Exploratory Learning</title>
<link>https://arxiv.org/abs/2410.02052</link>
<guid>https://arxiv.org/abs/2410.02052</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous agents、Vision-language models (VLMs)、ExACT、Reflective Monte Carlo Tree Search (R-MCTS)、Exploratory Learning

总结:
本文提出了一种名为ExACT的方法，旨在通过结合测试时间搜索和自我学习来构建适用于智能体应用的类似GPT-4o的模型。文章重点介绍了两种技术：一是反射性蒙特卡洛树搜索（R-MCTS），它是一种新型的测试时间算法，通过对比反思增强AI代理对决策空间的探索能力，并利用多智能体辩论进行可靠的状态评估；二是探索性学习，这是一种让代理在推理时学会搜索而无需依赖外部搜索算法的学习策略。实验结果显示，在具有挑战性的VisualWebArena基准上，基于GPT-4o的R-MCTS代理相比于先前最先进的方法，在各项任务中实现了6%-30%的相对改进。此外，研究还表明，从测试时间搜索中学到的知识和经验可以通过微调有效地反馈给GPT-4o。经过探索性学习后，GPT-4o表现出探索环境、评估状态以及在检测到当前状态无法导致成功时回溯到可行状态的能力，并且其性能接近R-MCTS的87%，同时使用了显著更少的计算资源。该工作揭示了在训练（使用R-MCTS进行数据收集）和测试时间中的计算扩展性属性，为提升视觉语言模型在智能体应用领域的性能提供了有前景的研究方向。 <div>
arXiv:2410.02052v5 Announce Type: replace 
Abstract: Autonomous agents have demonstrated significant potential in automating complex multistep decision-making tasks. However, even state-of-the-art vision-language models (VLMs), such as GPT-4o, still fall short of human-level performance, particularly in intricate web environments and long-horizon tasks. To address these limitations, we present ExACT, an approach to combine test-time search and self-learning to build o1-like models for agentic applications. We first introduce Reflective Monte Carlo Tree Search (R-MCTS), a novel test time algorithm designed to enhance AI agents' ability to explore decision space on the fly. R-MCTS extends traditional MCTS by 1) incorporating contrastive reflection, allowing agents to learn from past interactions and dynamically improve their search efficiency; and 2) using multi-agent debate for reliable state evaluation. Next, we introduce Exploratory Learning, a novel learning strategy to teach agents to search at inference time without relying on any external search algorithms. On the challenging VisualWebArena benchmark, our GPT-4o based R-MCTS agent achieves a 6% to 30% relative improvement across various tasks compared to the previous state-of-the-art. Additionally, we show that the knowledge and experience gained from test-time search can be effectively transferred back to GPT-4o via fine-tuning. After Exploratory Learning, GPT-4o 1) demonstrates the ability to explore the environment, evaluate a state, and backtrack to viable ones when it detects that the current state cannot lead to success, and 2) matches 87% of R-MCTS's performance while using significantly less compute. Notably, our work demonstrates the compute scaling properties in both training - data collection with R-MCTS - and testing time. These results suggest a promising research direction to enhance VLMs' capabilities for agentic applications via test-time search and self-learning.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Commands to Prompts: LLM-based Semantic File System for AIOS</title>
<link>https://arxiv.org/abs/2410.11843</link>
<guid>https://arxiv.org/abs/2410.11843</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLM), 语义文件系统 (LSFS), 命令提示符驱动, 文件管理, 智能文件操作

<br /><br />总结:

本文提出了一种基于大型语言模型（LLM）的语义文件系统（LSFS），用于解决传统文件系统依赖于精确命令和复杂导航的问题。LSFS允许用户或智能代理通过自然语言指令进行语义化的文件管理。在宏观层面，该系统开发了一个全面的API集，实现语义文件检索、文件更新监控与摘要以及语义文件回滚等功能。在微观层面上，通过构建语义索引并设计实现基于向量数据库的不同语义操作系统调用（如创建、读取、更新、删除等）。实验结果显示，LSFS相比传统文件系统在用户体验、支持功能多样性以及文件操作的准确性和效率上均有显著提升。此外，由于整合了LLM，LSFS还能够执行更智能的文件管理任务，如内容概要生成和版本比较，从而进一步增强其功能。 <div>
arXiv:2410.11843v3 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system ( LSFS ) for prompt-driven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CAT-ORA: Collision-Aware Time-Optimal Formation Reshaping for Efficient Robot Coordination in 3D Environments</title>
<link>https://arxiv.org/abs/2412.00603</link>
<guid>https://arxiv.org/abs/2412.00603</guid>
<content:encoded><![CDATA[
<div> 关键词：时间最优形成重塑、三维环境、碰撞避免、移动机器人、多旋翼无人机<br /><br />总结：

本文提出了一种名为“碰撞感知时间最优形成重塑算法”(CAT-ORA)，该算法针对三维环境中移动机器人的时间最优形成重塑问题，并着重解决了机器人之间的碰撞预防。特别是在需要频繁改变队形形状以实现高效导航或任务完成的现实应用场景中，如多旋翼无人机(UAVs)，电池续航限制使得形成重塑过程的时间至关重要。CAT-ORA算法基于匈牙利算法解决机器人到目标分配，并通过直接约束互斥的机器人-目标对以及结合最小化重塑过程时长的轨迹生成方法实现了碰撞规避。理论验证了CAT-ORA算法的最优性，通过模拟实验和涉及19架UAV的真实户外实验进一步证实其效果。数值分析表明，与常用方法相比，CAT-ORA能在随机生成的场景中将复杂形成重塑任务所需时间最多降低49%，平均降低12%。 <div>
arXiv:2412.00603v2 Announce Type: replace 
Abstract: In this paper, we introduce an algorithm designed to address the problem of time-optimal formation reshaping in three-dimensional environments while preventing collisions between agents. The utility of the proposed approach is particularly evident in mobile robotics, where agents benefit from being organized and navigated in formation for a variety of real-world applications requiring frequent alterations in formation shape for efficient navigation or task completion. Given the constrained operational time inherent to battery-powered mobile robots, the time needed to complete the formation reshaping process is crucial for their efficient operation, especially in case of multi-rotor Unmanned Aerial Vehicles (UAVs). The proposed Collision-Aware Time-Optimal formation Reshaping Algorithm (CAT-ORA) builds upon the Hungarian algorithm for the solution of the robot-to-goal assignment implementing the inter-agent collision avoidance through direct constraints on mutually exclusive robot-goal pairs combined with a trajectory generation approach minimizing the duration of the reshaping process. Theoretical validations confirm the optimality of CAT-ORA, with its efficacy further showcased through simulations, and a real-world outdoor experiment involving 19 UAVs. Thorough numerical analysis shows the potential of CAT-ORA to decrease the time required to perform complex formation reshaping tasks by up to 49%, and 12% on average compared to commonly used methods in randomly generated scenarios.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The BrowserGym Ecosystem for Web Agent Research</title>
<link>https://arxiv.org/abs/2412.05467</link>
<guid>https://arxiv.org/abs/2412.05467</guid>
<content:encoded><![CDATA[
<div> 关键词：BrowserGym、web代理、基准测试、Large Language Models、实验比较

总结:
<br />
本文提出了扩展版的BrowserGym生态系统，旨在统一并标准化web代理（特别是利用自动化和大型语言模型）的评估与基准测试。该生态系统整合了现有文献中的基准测试，并引入了一个名为AgentLab的框架，用于辅助代理创建、测试和分析。通过这个平台，作者进行了首个大规模、跨多个基准的web代理实验，对比了6种最先进的LLM在6个流行web代理基准上的表现。结果显示OpenAI和Anthropic的最新模型之间存在显著差异，Claude-3.5-Sonnet在大多数任务上领先，但GPT-4o在涉及视觉的任务上更胜一筹。尽管取得这些进展，研究结果仍强调构建稳健高效的web代理仍然是一个重大挑战，原因在于现实网络环境的复杂性和当前模型的局限性。 <div>
arXiv:2412.05467v4 Announce Type: replace 
Abstract: The BrowserGym ecosystem addresses the growing need for efficient evaluation and benchmarking of web agents, particularly those leveraging automation and Large Language Models (LLMs). Many existing benchmarks suffer from fragmentation and inconsistent evaluation methodologies, making it challenging to achieve reliable comparisons and reproducible results. In an earlier work, Drouin et al. (2024) introduced BrowserGym which aims to solve this by providing a unified, gym-like environment with well-defined observation and action spaces, facilitating standardized evaluation across diverse benchmarks. We propose an extended BrowserGym-based ecosystem for web agent research, which unifies existing benchmarks from the literature and includes AgentLab, a complementary framework that aids in agent creation, testing, and analysis. Our proposed ecosystem offers flexibility for integrating new benchmarks while ensuring consistent evaluation and comprehensive experiment management. As a supporting evidence, we conduct the first large-scale, multi-benchmark web agent experiment and compare the performance of 6 state-of-the-art LLMs across 6 popular web agent benchmarks made available in BrowserGym. Among other findings, our results highlight a large discrepancy between OpenAI and Anthropic's latests models, with Claude-3.5-Sonnet leading the way on almost all benchmarks, except on vision-related tasks where GPT-4o is superior. Despite these advancements, our results emphasize that building robust and efficient web agents remains a significant challenge, due to the inherent complexity of real-world web environments and the limitations of current models.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bootstrapping Language-Guided Navigation Learning with Self-Refining Data Flywheel</title>
<link>https://arxiv.org/abs/2412.08467</link>
<guid>https://arxiv.org/abs/2412.08467</guid>
<content:encoded><![CDATA[
<div> 关键词：Self-Refining Data Flywheel (SRDF)，语言指导导航学习，数据集，导航器，指令生成器

<br /><br />总结：
本文介绍了用于训练稳健的语言指令代理的Self-Refining Data Flywheel (SRDF)方法。SRDF通过循环迭代的方式，无需人工标注，让指令生成器和导航器协同工作，不断优化导航指令轨迹对的数据集。首先使用基础生成器创建初始数据池来训练基础导航器，再利用该导航器筛选并优化数据池。如此往复，形成了一个数据自我精炼的过程，从而得到大规模、高质量的语言引导导航学习数据集。实验结果显示，经过几轮flywheel后，导航器在经典R2R测试集上的SPL性能从70%提升到78%，首次超越了人类表现（76%）。同时，这一过程也使得指令生成器得到了显著提升，SPICE得分从23.5提高到26.2，超过了以往所有的VLN指令生成方法。最后，文章还展示了该方法的可扩展性和泛化能力，其预训练导航器在各种下游导航任务中均大幅度超越了当前最优的方法。 <div>
arXiv:2412.08467v2 Announce Type: replace 
Abstract: Creating high-quality data for training robust language-instructed agents is a long-lasting challenge in embodied AI. In this paper, we introduce a Self-Refining Data Flywheel (SRDF) that generates high-quality and large-scale navigational instruction-trajectory pairs by iteratively refining the data pool through the collaboration between two models, the instruction generator and the navigator, without any human-in-the-loop annotation. Specifically, SRDF starts with using a base generator to create an initial data pool for training a base navigator, followed by applying the trained navigator to filter the data pool. This leads to higher-fidelity data to train a better generator, which can, in turn, produce higher-quality data for training the next-round navigator. Such a flywheel establishes a data self-refining process, yielding a continuously improved and highly effective dataset for large-scale language-guided navigation learning. Our experiments demonstrate that after several flywheel rounds, the navigator elevates the performance boundary from 70% to 78% SPL on the classic R2R test set, surpassing human performance (76%) for the first time. Meanwhile, this process results in a superior generator, evidenced by a SPICE increase from 23.5 to 26.2, better than all previous VLN instruction generation methods. Finally, we demonstrate the scalability of our method through increasing environment and instruction diversity, and the generalization ability of our pre-trained navigator across various downstream navigation tasks, surpassing state-of-the-art methods by a large margin in all cases.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FORM: Learning Expressive and Transferable First-Order Logic Reward Machines</title>
<link>https://arxiv.org/abs/2501.00364</link>
<guid>https://arxiv.org/abs/2501.00364</guid>
<content:encoded><![CDATA[
<div> 关键词: Reward Machines, First-Order Reward Machines, Propositional Logic, Reinforcement Learning, Multi-Agent Formulation

总结:
本文提出了一种名为First-Order Reward Machines（$\texttt{FORM}$s）的新方法，用于强化学习中处理非马尔科夫奖励。相比于传统使用命题逻辑的Reward Machines，$\texttt{FORM}$s利用一阶逻辑标注边，从而实现更紧凑和可转移的模型。文章介绍了一种新的$\texttt{FORM}$学习方法及多智能体框架下的利用方式，使得多个智能体可以协同学习共享的$\texttt{FORM}$策略，进而提升任务学习速度与迁移性。实验结果显示，$\texttt{FORM}$s在传统RM学习方法失效的任务上也能有效学习，并表现出更好的学习效率和任务迁移性能。 <div>
arXiv:2501.00364v3 Announce Type: replace 
Abstract: Reward machines (RMs) are an effective approach for addressing non-Markovian rewards in reinforcement learning (RL) through finite-state machines. Traditional RMs, which label edges with propositional logic formulae, inherit the limited expressivity of propositional logic. This limitation hinders the learnability and transferability of RMs since complex tasks will require numerous states and edges. To overcome these challenges, we propose First-Order Reward Machines ($\texttt{FORM}$s), which use first-order logic to label edges, resulting in more compact and transferable RMs. We introduce a novel method for $\textbf{learning}$ $\texttt{FORM}$s and a multi-agent formulation for $\textbf{exploiting}$ them and facilitate their transferability, where multiple agents collaboratively learn policies for a shared $\texttt{FORM}$. Our experimental results demonstrate the scalability of $\texttt{FORM}$s with respect to traditional RMs. Specifically, we show that $\texttt{FORM}$s can be effectively learnt for tasks where traditional RM learning approaches fail. We also show significant improvements in learning speed and task transferability thanks to the multi-agent learning framework and the abstraction provided by the first-order language.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Computing Game Symmetries and Equilibria That Respect Them</title>
<link>https://arxiv.org/abs/2501.08905</link>
<guid>https://arxiv.org/abs/2501.08905</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、对称性、计算复杂性、纳什均衡、图自动机

总结:
该文研究了在多智能体系统的战略互动中，游戏对称性的识别和利用的计算复杂性问题。文章建立了游戏对称性和图自动机之间的紧密联系，证明了一些情况下确定游戏中存在的对称性问题是图自同构和图同构完全问题。同时，文中也指出在限制行动考虑方式的特定条件下，该问题可以变得能在多项式时间内解决。接着，文章探讨了如何有效地利用游戏对称性来求解纳什均衡，并表明在一般 sum 游戏和团队游戏中，寻找符合给定对称性的纳什均衡分别与 Brouwer 固定点问题和梯度下降问题同样困难。最后，论文提出在存在大量对称性或对于两玩家零和游戏且未知对称性的情况下，能够实现纳什均衡的多项式时间算法。 <div>
arXiv:2501.08905v2 Announce Type: replace 
Abstract: Strategic interactions can be represented more concisely, and analyzed and solved more efficiently, if we are aware of the symmetries within the multiagent system. Symmetries also have conceptual implications, for example for equilibrium selection. We study the computational complexity of identifying and using symmetries. Using the classical framework of normal-form games, we consider game symmetries that can be across some or all players and/or actions. We find a strong connection between game symmetries and graph automorphisms, yielding graph automorphism and graph isomorphism completeness results for characterizing the symmetries present in a game. On the other hand, we also show that the problem becomes polynomial-time solvable when we restrict the consideration of actions in one of two ways.
  Next, we investigate when exactly game symmetries can be successfully leveraged for Nash equilibrium computation. We show that finding a Nash equilibrium that respects a given set of symmetries is PPAD- and CLS-complete in general-sum and team games respectively -- that is, exactly as hard as Brouwer fixed point and gradient descent problems. Finally, we present polynomial-time methods for the special cases where we are aware of a vast number of symmetries, or where the game is two-player zero-sum and we do not even know the symmetries.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Firewalls to Secure Dynamic LLM Agentic Networks</title>
<link>https://arxiv.org/abs/2502.01822</link>
<guid>https://arxiv.org/abs/2502.01822</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM代理、通信、隐私、安全、旅行规划<br /><br />总结:

本文关注未来LLM（大型语言模型）代理在涉及长期计划和相互依赖目标的任务中代表用户与其他实体代理进行沟通的问题。文章首先指出了此类代理网络所需的通信特性，应具备主动性与适应性，并强调了两个关键需求：隐私（仅分享完成任务所需信息）和安全（确保通信的完整性和对抗自私实体的能力）。作者通过设计一个旅行规划的示例用例来展示这些要求及其可能存在的问题。接下来，文章提出了一种实用的设计方案，该方案受到网络安全原则启发，为受限的LLM代理网络提供了一个平衡适应性、安全性和隐私性的框架。该框架自动从先前的模拟构建并更新任务特定规则以建立防火墙，并提供了三层防御机制：将自由形式输入转化为任务特定协议、动态抽象用户的任务数据至适当的许可程度以及自我校正代理的行为轨迹。 <div>
arXiv:2502.01822v2 Announce Type: replace 
Abstract: Future LLM agents are likely to communicate on behalf of users with other entity-representing agents on tasks that entail long-horizon plans with interdependent goals. Current work does not focus on such agentic networks, nor does it address their challenges. Thus, we first identify the required properties of agents' communication, which should be proactive and adaptable. It needs to satisfy 1) privacy: agents should not share more than what is needed for the task, and 2) security: the communication must preserve integrity and maintain utility against selfish entities. We design a use case (travel planning) as a testbed that exemplifies these requirements, and we show examples of how this can go wrong. Next, we propose a practical design, inspired by established network security principles, for constrained LLM agentic networks that balance adaptability, security, and privacy. Our framework automatically constructs and updates task-specific rules from prior simulations to build firewalls. We offer layers of defense to 1) convert free-form input to a task-specific protocol, 2) dynamically abstract users' data to a task-specific degree of permissiveness, and 3) self-correct the agents' trajectory.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>UXAgent: An LLM Agent-Based Usability Testing Framework for Web Design</title>
<link>https://arxiv.org/abs/2502.12561</link>
<guid>https://arxiv.org/abs/2502.12561</guid>
<content:encoded><![CDATA[
<div> 关键词：usability testing, Large Language Model-simulated Agent (LLM-Agent), UXAgent, web design, heuristic user evaluation

<br /><br />总结：
本文介绍了一个名为UXAgent的新系统，该系统利用大型语言模型模拟代理（LLM-Agent）技术帮助用户体验（UX）研究人员在进行真实人类主体研究前评估和迭代可用性测试设计。UXAgent包括一个LLM-Agent模块和一个通用浏览器连接器模块，可以自动生成数千个模拟用户来测试目标网站，并以定性（例如，访谈模拟用户的思考过程）、定量（例如，行动次数）和视频记录等多种格式提供结果以便于分析。通过与五位UX研究人员进行的启发式用户体验评估，参与者对系统的创新性表示赞赏，同时也表达了对未来LLM Agent辅助UX研究可能带来的影响的担忧。 <div>
arXiv:2502.12561v2 Announce Type: replace 
Abstract: Usability testing is a fundamental yet challenging (e.g., inflexible to iterate the study design flaws and hard to recruit study participants) research method for user experience (UX) researchers to evaluate a web design. Recent advances in Large Language Model-simulated Agent (LLM-Agent) research inspired us to design UXAgent to support UX researchers in evaluating and reiterating their usability testing study design before they conduct the real human subject study. Our system features an LLM-Agent module and a universal browser connector module so that UX researchers can automatically generate thousands of simulated users to test the target website. The results are shown in qualitative (e.g., interviewing how an agent thinks ), quantitative (e.g., # of actions), and video recording formats for UX researchers to analyze. Through a heuristic user evaluation with five UX researchers, participants praised the innovation of our system but also expressed concerns about the future of LLM Agent-assisted UX study.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Immunocto: a massive immune cell database auto-generated for histopathology</title>
<link>https://arxiv.org/abs/2406.02618</link>
<guid>https://arxiv.org/abs/2406.02618</guid>
<content:encoded><![CDATA[
<div> 关键词: 免疫疗法、肿瘤免疫微环境、光学图像、自动化细胞检测、Immunocto数据库

总结:
本文介绍了研究肿瘤免疫微环境(TIME)对于预测癌症治疗效果和理解对治疗药物反应的重要性。作者提出了一种工作流程，可以自动从采用H&amp;E和多重免疫荧光(IF)染色的组织切片中生成单细胞轮廓和标签。该方法利用Segment Anything模型，与现有单细胞数据库相比，需要的人工干预极小。通过这种方法构建了一个名为Immunocto的大规模多百万细胞数据库，包含了6,848,454个人类细胞和对象，其中2,282,818个为免疫细胞，分为四种亚型：CD4+ T淋巴细胞、CD8+ T淋巴细胞、CD20+ B淋巴细胞和CD68+/CD163+巨噬细胞。每个细胞都配有40倍放大下的64x64像素的H&amp;E图像以及细胞核二值掩模和标签。这个公开可用的数据库可用于训练模型以研究常规H&amp;E切片中的TIME。实验结果显示，基于Immunocto训练的深度学习模型在淋巴细胞检测上达到了最先进的性能。该研究表明，使用匹配的H&amp;E和IF数据可生成用于计算病理学应用的稳健数据库。 <div>
arXiv:2406.02618v2 Announce Type: replace-cross 
Abstract: With the advent of novel cancer treatment options such as immunotherapy, studying the tumour immune micro-environment (TIME) is crucial to inform on prognosis and understand potential response to therapeutic agents. A key approach to characterising the TIME may be through combining (1) digitised microscopic high-resolution optical images of hematoxylin and eosin (H&amp;E) stained tissue sections obtained in routine histopathology examinations with (2) automated immune cell detection and classification methods. In this work, we introduce a workflow to automatically generate robust single cell contours and labels from dually stained tissue sections with H&amp;E and multiplexed immunofluorescence (IF) markers. The approach harnesses the Segment Anything Model and requires minimal human intervention compared to existing single cell databases. With this methodology, we create Immunocto, a massive, multi-million automatically generated database of 6,848,454 human cells and objects, including 2,282,818 immune cells distributed across 4 subtypes: CD4$^+$ T cell lymphocytes, CD8$^+$ T cell lymphocytes, CD20$^+$ B cell lymphocytes, and CD68$^+$/CD163$^+$ macrophages. For each cell, we provide a 64$\times$64 pixels$^2$ H&amp;E image at $\mathbf{40}\times$ magnification, along with a binary mask of the nucleus and a label. The database, which is made publicly available, can be used to train models to study the TIME on routine H&amp;E slides. We show that deep learning models trained on Immunocto result in state-of-the-art performance for lymphocyte detection. The approach demonstrates the benefits of using matched H&amp;E and IF data to generate robust databases for computational pathology applications.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model-Based Reinforcement Learning for Control of Strongly-Disturbed Unsteady Aerodynamic Flows</title>
<link>https://arxiv.org/abs/2408.14685</link>
<guid>https://arxiv.org/abs/2408.14685</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习、模型基强化学习、流体动力学控制、物理增强自动编码器、垂直轴风力涡轮机

<br /><br />总结：
本文提出了一种基于模型的强化学习（MBRL）方法来应对流体动力学控制的挑战。该方法利用了一个新颖的物理增强自动编码器构成的降维模型作为全环境的代理，该模型能够将高维度的CFD流场快照压缩到三维潜空间，并训练一个潜动态模型以精确预测响应动作序列的潜空间轨迹长期动力学。通过在受强烈扰动环境中的翻转翼剖面问题中展示模型的准确性和鲁棒性，进一步讨论了在无扰动环境中应用于垂直轴风力涡轮机的情况。基于翻转翼问题训练的模型，实现了MBRL策略来减轻遭遇气流扰动时空气动力升力的变化。研究表明，在降维环境中学到的策略可以有效地转化为全CFD环境中的控制策略。 <div>
arXiv:2408.14685v2 Announce Type: replace-cross 
Abstract: The intrinsic high dimension of fluid dynamics is an inherent challenge to control of aerodynamic flows, and this is further complicated by a flow's nonlinear response to strong disturbances. Deep reinforcement learning, which takes advantage of the exploratory aspects of reinforcement learning (RL) and the rich nonlinearity of a deep neural network, provides a promising approach to discover feasible control strategies. However, the typical model-free approach to reinforcement learning requires a significant amount of interaction between the flow environment and the RL agent during training, and this high training cost impedes its development and application. In this work, we propose a model-based reinforcement learning (MBRL) approach by incorporating a novel reduced-order model as a surrogate for the full environment. The model consists of a physics-augmented autoencoder, which compresses high-dimensional CFD flow field snaphsots into a three-dimensional latent space, and a latent dynamics model that is trained to accurately predict the long-time dynamics of trajectories in the latent space in response to action sequences. The accuracy and robustness of the model are demonstrated in the scenario of a pitching airfoil within a highly disturbed environment. Additionally, an application to a vertical-axis wind turbine in a disturbance-free environment is discussed in the Appendix Based on the model trained in the pitching airfoil problem, we realize an MBRL strategy to mitigate lift variation during gust-airfoil encounters. We demonstrate that the policy learned in the reduced-order environment translates to an effective control strategy in the full CFD environment.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Conversational Planning for Personal Plans</title>
<link>https://arxiv.org/abs/2502.19500</link>
<guid>https://arxiv.org/abs/2502.19500</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)、长期交互、强化学习、宏观动作、对话式规划

<br /><br />总结: 本文探讨了大型语言模型（LLMs）在实现长期交互与任务中的作用，提出了一种新的架构，其中LLM作为元控制器决定智能体的下一个宏观动作，而工具使用增强的基于LLM的选项策略执行所选宏观动作。研究者将此框架具体应用于通过对话和后续问题收集用户反馈，以适应性地帮助用户规划个人计划。这种方法可应用于从学术及非学术任务辅导到针对个人健康计划的对话式教练等场景。 <div>
arXiv:2502.19500v1 Announce Type: new 
Abstract: The language generation and reasoning capabilities of large language models (LLMs) have enabled conversational systems with impressive performance in a variety of tasks, from code generation, to composing essays, to passing STEM and legal exams, to a new paradigm for knowledge search. Besides those short-term use applications, LLMs are increasingly used to help with real-life goals or tasks that take a long time to complete, involving multiple sessions across days, weeks, months, or even years. Thus to enable conversational systems for long term interactions and tasks, we need language-based agents that can plan for long horizons. Traditionally, such capabilities were addressed by reinforcement learning agents with hierarchical planning capabilities. In this work, we explore a novel architecture where the LLM acts as the meta-controller deciding the agent's next macro-action, and tool use augmented LLM-based option policies execute the selected macro-action. We instantiate this framework for a specific set of macro-actions enabling adaptive planning for users' personal plans through conversation and follow-up questions collecting user feedback. We show how this paradigm can be applicable in scenarios ranging from tutoring for academic and non-academic tasks to conversational coaching for personal health plans.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Static Vs. Agentic Game Master AI for Facilitating Solo Role-Playing Experiences</title>
<link>https://arxiv.org/abs/2502.19519</link>
<guid>https://arxiv.org/abs/2502.19519</guid>
<content:encoded><![CDATA[
<div> 关键词：游戏大师AI、单人角色扮演游戏、交互式文本叙事、ReAct框架、沉浸感

总结:
本文介绍了用于单人角色扮演游戏的游戏大师AI设计，旨在提供类似多人桌游如“龙与地下城”的互动文本叙事体验。文章详细描述了设计过程和改进功能及体验设计的一系列实验，最终形成了两个功能版本的系统。第一个版本采用简化版的提示工程方法，而第二个版本利用多代理架构和ReAct框架，实现了推理和行动相结合。通过对两个版本的比较评估，结果表明v2作为具有主体性的系统能在维持游戏进行的同时，显著提升模块化和游戏体验，包括增强沉浸感和好奇心。这些发现为AI驱动的交互式虚构文学的发展做出了贡献，指出了提升单人角色扮演体验的新方向。 <div>
arXiv:2502.19519v1 Announce Type: new 
Abstract: This paper presents a game master AI for single-player role-playing games. The AI is designed to deliver interactive text-based narratives and experiences typically associated with multiplayer tabletop games like Dungeons & Dragons. We report on the design process and the series of experiments to improve the functionality and experience design, resulting in two functional versions of the system. While v1 of our system uses simplified prompt engineering, v2 leverages a multi-agent architecture and the ReAct framework to include reasoning and action. A comparative evaluation demonstrates that v2 as an agentic system maintains play while significantly improving modularity and game experience, including immersion and curiosity. Our findings contribute to the evolution of AI-driven interactive fiction, highlighting new avenues for enhancing solo role-playing experiences.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Autonomous Inspection Regimes: Active Versus Passive Satellite Inspection</title>
<link>https://arxiv.org/abs/2502.19556</link>
<guid>https://arxiv.org/abs/2502.19556</guid>
<content:encoded><![CDATA[
<div> 关键词: 卫星检查, 多智能体任务, 被检空间物体, 被动策略, 主动策略

总结:
本文研究了卫星检查问题，探讨了一颗或多颗卫星（检查者）对可能出现故障或异常的驻留空间物体（RSO）进行成像或检查的任务。文章对比模拟了被动与主动策略在多智能体任务中的优劣，考虑的关键因素包括RSO的动力学模式、状态不确定性、未建模的进入条件以及检查者的运动类型。研究以燃料利用和表面覆盖率为评估重点，基于蒙特卡洛方法构建了对被动策略的评价器，并使用强化学习框架训练主动检查策略。通过这种方式，该研究探究了何种条件下，如自然运动环绕（NMC）等被动策略可以与基于强化学习的航点转移等主动策略表现相当。 <div>
arXiv:2502.19556v1 Announce Type: new 
Abstract: This paper addresses the problem of satellite inspection, where one or more satellites (inspectors) are tasked with imaging or inspecting a resident space object (RSO) due to potential malfunctions or anomalies. Inspection strategies are often reduced to a discretized action space with predefined waypoints, facilitating tractability in both classical optimization and machine learning based approaches. However, this discretization can lead to suboptimal guidance in certain scenarios. This study presents a comparative simulation to explore the tradeoffs of passive versus active strategies in multi-agent missions. Key factors considered include RSO dynamic mode, state uncertainty, unmodeled entrance criteria, and inspector motion types. The evaluation is conducted with a focus on fuel utilization and surface coverage. Building on a Monte-Carlo based evaluator of passive strategies and a reinforcement learning framework for training active inspection policies, this study investigates conditions under which passive strategies, such as Natural Motion Circumnavigation (NMC), may perform comparably to active strategies like Reinforcement Learning based waypoint transfers.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stay Focused: Problem Drift in Multi-Agent Debate</title>
<link>https://arxiv.org/abs/2502.19559</link>
<guid>https://arxiv.org/abs/2502.19559</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体辩论、问题漂移、大规模语言模型、DRIFTJudge、DRIFTPolicy

总结:
本文探讨了多智能体辩论中出现的一个新问题——问题漂移，即在多轮讨论过程中，辩论逐渐偏离初始问题。研究者通过跨十项任务的数据分析量化了这一现象的存在，并通过专家研究确定了问题漂移的主要原因包括缺乏进展、低质量反馈和表述不清晰。为解决此问题，文章提出了两种方法：基于LLM裁判的DRIFTJudge测试时检测问题漂移；以及DRIFTPolicy策略，能有效缓解31%的问题漂移情况。这项研究被认为是了解多智能体辩论局限性的第一步，为未来提高其有效性指明了改进方向。 <div>
arXiv:2502.19559v1 Announce Type: new 
Abstract: Multi-agent debate - multiple instances of large language models discussing problems in turn-based interaction - has shown promise for solving knowledge and reasoning tasks. However, these methods show limitations, particularly when scaling them to longer reasoning chains. In this study, we unveil a new issue of multi-agent debate: discussions drift away from the initial problem over multiple turns. We define this phenomenon as problem drift and quantify its presence across ten tasks (i.e., three generative, three knowledge, three reasoning, and one instruction-following task). To identify the reasons for this issue, we perform a human study with eight experts on discussions suffering from problem drift, who find the most common issues are a lack of progress (35% of cases), low-quality feedback (26% of cases), and a lack of clarity (25% of cases). To systematically address the issue of problem drift, we propose DRIFTJudge, a method based on LLM-as-a-judge, to detect problem drift at test-time. We further propose DRIFTPolicy, a method to mitigate 31% of problem drift cases. Our study can be seen as a first step to understanding a key limitation of multi-agent debate, highlighting pathways for improving their effectiveness in the future.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAMEN: Real-time Asynchronous Multi-agent Neural Implicit Mapping</title>
<link>https://arxiv.org/abs/2502.19592</link>
<guid>https://arxiv.org/abs/2502.19592</guid>
<content:encoded><![CDATA[
<div> 关键词: RAMEN、异步多智能体、神经隐式映射、通信中断、共识优化算法

总结:
RAMEN是一种针对实时异步多智能体神经隐式映射问题的新方法，旨在解决复杂环境高精度重建中的同步通信依赖挑战。当通信中断时，每个智能体会保持邻居地图的过时副本并随时间增加其不确定性。该方法利用参数不确定度量化来指导多智能体间的共识优化算法，使网络参数更倾向于低不确定性的一方达成一致。为此，文章提出了一种加权变体的分布式共识交替方向乘子法(C-ADMM)算法，确保了不同通信和更新频率的智能体之间能够稳健协作。通过实现实验数据集和机器人硬件实验，RAMEN在具有挑战性的通信条件下展示了优越的地图构建性能。<br /><br /> <div>
arXiv:2502.19592v1 Announce Type: new 
Abstract: Multi-agent neural implicit mapping allows robots to collaboratively capture and reconstruct complex environments with high fidelity. However, existing approaches often rely on synchronous communication, which is impractical in real-world scenarios with limited bandwidth and potential communication interruptions. This paper introduces RAMEN: Real-time Asynchronous Multi-agEnt Neural implicit mapping, a novel approach designed to address this challenge. RAMEN employs an uncertainty-weighted multi-agent consensus optimization algorithm that accounts for communication disruptions. When communication is lost between a pair of agents, each agent retains only an outdated copy of its neighbor's map, with the uncertainty of this copy increasing over time since the last communication. Using gradient update information, we quantify the uncertainty associated with each parameter of the neural network map. Neural network maps from different agents are brought to consensus on the basis of their levels of uncertainty, with consensus biased towards network parameters with lower uncertainty. To achieve this, we derive a weighted variant of the decentralized consensus alternating direction method of multipliers (C-ADMM) algorithm, facilitating robust collaboration among agents with varying communication and update frequencies. Through extensive evaluations on real-world datasets and robot hardware experiments, we demonstrate RAMEN's superior mapping performance under challenging communication conditions.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Program Synthesis Dialog Agents for Interactive Decision-Making</title>
<link>https://arxiv.org/abs/2502.19610</link>
<guid>https://arxiv.org/abs/2502.19610</guid>
<content:encoded><![CDATA[
<div> 关键词：自然语言决策问题、自动辅助决策、贝尼福利(BeNYfits)基准、ProADA方法、程序合成

总结:
本文提出了一种名为贝尼福利(BeNYfits)的新基准，用于评估通过互动决策确定用户多方面社会福利资格的能力。研究发现，当前的语言模型如GPT-4在进行此类任务时常出现幻觉错误，其使用ReAct风格的思考链得到的F1分数仅为35.7。为了解决这一问题，文章引入了ProADA方法，这是一种利用程序合成协助决策的新方法，它将对话规划映射到代码生成问题，并通过结构化数据中的空白来确定最佳下一步行动。实验证明，采用ProADA方法的代理能在保持几乎相同对话轮数的同时，将F1得分提高至55.6。 <div>
arXiv:2502.19610v1 Announce Type: new 
Abstract: Many real-world eligibility problems, ranging from medical diagnosis to tax planning, can be mapped to decision problems expressed in natural language, wherein a model must make a binary choice based on user features. Large-scale domains such as legal codes or frequently updated funding opportunities render human annotation (e.g., web forms or decision trees) impractical, highlighting the need for agents that can automatically assist in decision-making. Since relevant information is often only known to the user, it is crucial that these agents ask the right questions. As agents determine when to terminate a conversation, they face a trade-off between accuracy and the number of questions asked, a key metric for both user experience and cost. To evaluate this task, we propose BeNYfits, a new benchmark for determining user eligibility for multiple overlapping social benefits opportunities through interactive decision-making. Our experiments show that current language models struggle with frequent hallucinations, with GPT-4o scoring only 35.7 F1 using a ReAct-style chain-of-thought. To address this, we introduce ProADA, a novel approach that leverages program synthesis to assist in decision-making by mapping dialog planning to a code generation problem and using gaps in structured data to determine the best next action. Our agent, ProADA, improves the F1 score to 55.6 while maintaining nearly the same number of dialog turns.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic Mixture-of-Workflows for Multi-Modal Chemical Search</title>
<link>https://arxiv.org/abs/2502.19629</link>
<guid>https://arxiv.org/abs/2502.19629</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、材料科学、Mixture-of-Workflows、CRAG-MoW、AI架构优化

总结:<br />
本文介绍了一种名为CRAG-MoW的新颖材料设计方法，它利用大型语言模型并结合多工作流策略，通过开放源代码的LLMs进行自我修正和检索增强生成。与传统方法不同，CRAG-MoW通过编排代理融合多种输出，能够在相同问题领域中直接评估多个LLMs。研究团队在小分子、聚合物、化学反应以及多模态核磁共振光谱检索等领域对CRAG-MoW进行了基准测试，结果显示其性能可比肩GPT-4o，并在比较评价中更受青睐。CRAG-MoW提供了一个可扩展、可解释且基于基准驱动的方法，用于优化AI架构在材料发现中的应用，从而填补了LLMs及自主AI代理在科学应用领域的基准评测方面的基础性空白。 <div>
arXiv:2502.19629v1 Announce Type: new 
Abstract: The vast and complex materials design space demands innovative strategies to integrate multidisciplinary scientific knowledge and optimize materials discovery. While large language models (LLMs) have demonstrated promising reasoning and automation capabilities across various domains, their application in materials science remains limited due to a lack of benchmarking standards and practical implementation frameworks. To address these challenges, we introduce Mixture-of-Workflows for Self-Corrective Retrieval-Augmented Generation (CRAG-MoW) - a novel paradigm that orchestrates multiple agentic workflows employing distinct CRAG strategies using open-source LLMs. Unlike prior approaches, CRAG-MoW synthesizes diverse outputs through an orchestration agent, enabling direct evaluation of multiple LLMs across the same problem domain. We benchmark CRAG-MoWs across small molecules, polymers, and chemical reactions, as well as multi-modal nuclear magnetic resonance (NMR) spectral retrieval. Our results demonstrate that CRAG-MoWs achieve performance comparable to GPT-4o while being preferred more frequently in comparative evaluations, highlighting the advantage of structured retrieval and multi-agent synthesis. By revealing performance variations across data types, CRAG-MoW provides a scalable, interpretable, and benchmark-driven approach to optimizing AI architectures for materials discovery. These insights are pivotal in addressing fundamental gaps in benchmarking LLMs and autonomous AI agents for scientific applications.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Robust Gymnasium: A Unified Modular Benchmark for Robust Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.19652</link>
<guid>https://arxiv.org/abs/2502.19652</guid>
<content:encoded><![CDATA[
<div> 关键词: robust RL、benchmark、Robust-Gymnasium、RL组件、算法评估

总结:
为应对不确定性与模拟到现实的差距，鲁棒强化学习（robust RL）致力于提升智能体与环境交互中的适应性。然而，目前缺乏统一标准的鲁棒RL基准测试平台。现有的鲁棒RL策略多关注某一特定类型的不确定性并仅在特定环境中进行验证。本文提出了一个名为Robust-Gymnasium的统一模块化基准测试平台，该平台旨在支持对RL的所有关键组件——观察状态、奖励、智能体动作以及环境——的各种干扰类型。Robust-Gymnasium包含了六十多个涵盖控制、机器人学、安全RL和多智能体RL等领域的多样化任务环境，为社区提供了一个开源、用户友好的工具，以便评估现有方法并促进鲁棒RL算法的发展。此外，文中还在这一框架下对现有的标准和鲁棒RL算法进行了基准测试，揭示了它们各自的重大不足，并提供了新的洞见。<br /><br /> <div>
arXiv:2502.19652v1 Announce Type: new 
Abstract: Driven by inherent uncertainty and the sim-to-real gap, robust reinforcement learning (RL) seeks to improve resilience against the complexity and variability in agent-environment sequential interactions. Despite the existence of a large number of RL benchmarks, there is a lack of standardized benchmarks for robust RL. Current robust RL policies often focus on a specific type of uncertainty and are evaluated in distinct, one-off environments. In this work, we introduce Robust-Gymnasium, a unified modular benchmark designed for robust RL that supports a wide variety of disruptions across all key RL components-agents' observed state and reward, agents' actions, and the environment. Offering over sixty diverse task environments spanning control and robotics, safe RL, and multi-agent RL, it provides an open-source and user-friendly tool for the community to assess current methods and foster the development of robust RL algorithms. In addition, we benchmark existing standard and robust RL algorithms within this framework, uncovering significant deficiencies in each and offering new insights.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Joint Power Allocation and Phase Shift Design for Stacked Intelligent Metasurfaces-aided Cell-Free Massive MIMO Systems with MARL</title>
<link>https://arxiv.org/abs/2502.19675</link>
<guid>https://arxiv.org/abs/2502.19675</guid>
<content:encoded><![CDATA[
<div> 关键词：cell-free mMIMO系统，智能metasurfaces，功率分配，相位调整，强化学习算法

<br /><br />总结:

本文提出了将堆叠式智能超表面(SIM)整合到细胞自由(CF)大规模多输入多输出(mMIMO)系统中，以实现成本效益高、能源效率优良的解决方案。研究重点在于优化AP的功率分配与SIM的相位偏移，旨在最大化系统的总频谱效率(SE)。为解决这一复杂问题，文章引入了一种全新的全分布式多智能体强化学习(MARL)算法——带有循环策略的噪声值方法的多智能体策略优化(NVR-MAPPO)。该算法通过在集中训练和分散执行下鼓励多样化的探索来提升性能。仿真结果显示，NVR-MAPPO显著提高了总SE并在各种场景下表现出更好的鲁棒性。 <div>
arXiv:2502.19675v1 Announce Type: new 
Abstract: Cell-free (CF) massive multiple-input multiple-output (mMIMO) systems offer high spectral efficiency (SE) through multiple distributed access points (APs). However, the large number of antennas increases power consumption. We propose incorporating stacked intelligent metasurfaces (SIM) into CF mMIMO systems as a cost-effective, energy-efficient solution. This paper focuses on optimizing the joint power allocation of APs and the phase shift of SIMs to maximize the sum SE. To address this complex problem, we introduce a fully distributed multi-agent reinforcement learning (MARL) algorithm. Our novel algorithm, the noisy value method with a recurrent policy in multi-agent policy optimization (NVR-MAPPO), enhances performance by encouraging diverse exploration under centralized training and decentralized execution. Simulations demonstrate that NVR-MAPPO significantly improves sum SE and robustness across various scenarios.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exponential Topology-enabled Scalable Communication in Multi-agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.19717</link>
<guid>https://arxiv.org/abs/2502.19717</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、通信协议、大规模系统、指数图、ExpoComm

总结:<br />
本文针对大规模多智能体强化学习（MARL）中的通信协议设计问题进行了研究。为了实现可扩展性的通信，文章提出了一种名为ExpoComm的新方法，它放弃了传统的优化两两通信链接的做法，转而采用具有小直径和小规模属性的指数图作为全局通信拓扑结构。通过使用基于记忆的消息处理器和辅助任务来使消息承载全球信息，确保通信内容对决策有益。实验结果表明，相较于现有通信策略，ExpoComm在大型合作基准任务如MAgent和基础设施管理规划中表现出优越性能和较强的零样本迁移能力。相关代码已在https://github.com/LXXXXR/ExpoComm公开。 <div>
arXiv:2502.19717v1 Announce Type: new 
Abstract: In cooperative multi-agent reinforcement learning (MARL), well-designed communication protocols can effectively facilitate consensus among agents, thereby enhancing task performance. Moreover, in large-scale multi-agent systems commonly found in real-world applications, effective communication plays an even more critical role due to the escalated challenge of partial observability compared to smaller-scale setups. In this work, we endeavor to develop a scalable communication protocol for MARL. Unlike previous methods that focus on selecting optimal pairwise communication links-a task that becomes increasingly complex as the number of agents grows-we adopt a global perspective on communication topology design. Specifically, we propose utilizing the exponential topology to enable rapid information dissemination among agents by leveraging its small-diameter and small-size properties. This approach leads to a scalable communication protocol, named ExpoComm. To fully unlock the potential of exponential graphs as communication topologies, we employ memory-based message processors and auxiliary tasks to ground messages, ensuring that they reflect global information and benefit decision-making. Extensive experiments on large-scale cooperative benchmarks, including MAgent and Infrastructure Management Planning, demonstrate the superior performance and robust zero-shot transferability of ExpoComm compared to existing communication strategies. The code is publicly available at https://github.com/LXXXXR/ExpoComm.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MIND: Towards Immersive Psychological Healing with Multi-agent Inner Dialogue</title>
<link>https://arxiv.org/abs/2502.19860</link>
<guid>https://arxiv.org/abs/2502.19860</guid>
<content:encoded><![CDATA[
<div> 关键词：Mental health, Large language models, MIND, Inner dialogue, Psychological healing

<br />
总结：
本文提出了一种名为MIND（Multi-agent INner Dialogue）的新颖心理治疗范式，旨在解决当前社会日益严重的心理健康问题，如抑郁和焦虑。传统治疗方法如咨询和聊天机器人往往无法提供具有情感深度的有效互动。虽然大型语言模型（LLMs）有能力创造更接近人类的交互体验，但它们仍难以捕捉微妙的情绪变化。为弥补这一不足，MIND利用LLMs强大的生成能力和角色扮演能力，预设了一个互动治疗框架，并将LLM代理分配到不同的角色中，与用户进行内在对话，从而提供沉浸式的治疗体验。通过在多种实际治疗场景下进行广泛的人类实验，结果表明MIND比传统方法提供了更为用户友好的体验，有效地利用了LLMs在心理治疗方面的巨大潜力。 <div>
arXiv:2502.19860v1 Announce Type: new 
Abstract: Mental health issues are worsening in today's competitive society, such as depression and anxiety. Traditional healings like counseling and chatbots fail to engage effectively, they often provide generic responses lacking emotional depth. Although large language models (LLMs) have the potential to create more human-like interactions, they still struggle to capture subtle emotions. This requires LLMs to be equipped with human-like adaptability and warmth. To fill this gap, we propose the MIND (Multi-agent INner Dialogue), a novel paradigm that provides more immersive psychological healing environments. Considering the strong generative and role-playing ability of LLM agents, we predefine an interactive healing framework and assign LLM agents different roles within the framework to engage in interactive inner dialogues with users, thereby providing an immersive healing experience. We conduct extensive human experiments in various real-world healing dimensions, and find that MIND provides a more user-friendly experience than traditional paradigms. This demonstrates that MIND effectively leverages the significant potential of LLMs in psychological healing.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Shared Autonomy for Proximal Teaching</title>
<link>https://arxiv.org/abs/2502.19899</link>
<guid>https://arxiv.org/abs/2502.19899</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能辅助教学, 个性化指导, 共享自主权, 学习曲线分析, 高性能赛车教学

总结:
本文提出了一种利用人工智能辅助教学的新方法——Z-COACH，该方法借鉴了教育心理学中的支架理论并结合共享自主权框架，以实现针对个人化任务子技能的教学指导。研究中，Z-COACH通过观察学生在自动代理协助下行为改善的情况，识别出学生最具“可学习性”的子技能，即位于他们的最近发展区。文章通过一项使用模拟环境Thunderhill Raceway Park和CARLA自动驾驶模拟器进行的高绩效赛车教学用户研究（n=50），证明了Z-COACH能够帮助确定每个学生应首先练习的技能，从而提高了驾驶时间、行为表现和流畅度。研究表明，日益普及的半自动化技术不仅可以辅助人类用户，还可以帮助教导他们。 <div>
arXiv:2502.19899v1 Announce Type: new 
Abstract: Motor skill learning often requires experienced professionals who can provide personalized instruction. Unfortunately, the availability of high-quality training can be limited for specialized tasks, such as high performance racing. Several recent works have leveraged AI-assistance to improve instruction of tasks ranging from rehabilitation to surgical robot tele-operation. However, these works often make simplifying assumptions on the student learning process, and fail to model how a teacher's assistance interacts with different individuals' abilities when determining optimal teaching strategies. Inspired by the idea of scaffolding from educational psychology, we leverage shared autonomy, a framework for combining user inputs with robot autonomy, to aid with curriculum design. Our key insight is that the way a student's behavior improves in the presence of assistance from an autonomous agent can highlight which sub-skills might be most ``learnable'' for the student, or within their Zone of Proximal Development. We use this to design Z-COACH, a method for using shared autonomy to provide personalized instruction targeting interpretable task sub-skills. In a user study (n=50), where we teach high performance racing in a simulated environment of the Thunderhill Raceway Park with the CARLA Autonomous Driving simulator, we show that Z-COACH helps identify which skills each student should first practice, leading to an overall improvement in driving time, behavior, and smoothness. Our work shows that increasingly available semi-autonomous capabilities (e.g. in vehicles, robots) can not only assist human users, but also help *teach* them.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimus-2: Multimodal Minecraft Agent with Goal-Observation-Action Conditioned Policy</title>
<link>https://arxiv.org/abs/2502.19902</link>
<guid>https://arxiv.org/abs/2502.19902</guid>
<content:encoded><![CDATA[
<div> 关键词：Optimus-2、Multimodal Large Language Model (MLLM)、Goal-Observation-Action Conditioned Policy (GOAP)、Minecraft Goal-Observation-Action (MGOA) 数据集、性能优越

总结:
本文提出了一种新型的 Minecraft 代理模型 Optimus-2，旨在模仿人类行为模式执行多样化开放世界任务。Optimus-2 结合了 Multimodal Large Language Model (MLLM) 进行高阶规划和 Goal-Observation-Action Conditioned Policy (GOAP) 进行低阶控制。其中，GOAP 包含了一个行动引导的行为编码器，用于建模观察与动作之间的因果关系，并利用历史观察-动作序列动态交互生成固定长度的行为令牌；同时，通过 MLLM 将行为令牌与开放性语言指令对齐，自回归预测动作。此外，文章还引入了一个高质量的 Minecraft Goal-Observation-Action (MGOA) 数据集，包含了 25,000 个视频和约 3000 万个目标-观察-动作对，用于训练 Minecraft 代理。实验结果表明，Optimus-2 在 Minecraft 中的各种原子任务、长时序任务以及开放性指令任务上表现出优越性能。该自动化构建方法和 MGOA 数据集为社区培养 Minecraft 代理的努力做出了贡献。 <div>
arXiv:2502.19902v1 Announce Type: new 
Abstract: Building an agent that can mimic human behavior patterns to accomplish various open-world tasks is a long-term goal. To enable agents to effectively learn behavioral patterns across diverse tasks, a key challenge lies in modeling the intricate relationships among observations, actions, and language. To this end, we propose Optimus-2, a novel Minecraft agent that incorporates a Multimodal Large Language Model (MLLM) for high-level planning, alongside a Goal-Observation-Action Conditioned Policy (GOAP) for low-level control. GOAP contains (1) an Action-guided Behavior Encoder that models causal relationships between observations and actions at each timestep, then dynamically interacts with the historical observation-action sequence, consolidating it into fixed-length behavior tokens, and (2) an MLLM that aligns behavior tokens with open-ended language instructions to predict actions auto-regressively. Moreover, we introduce a high-quality Minecraft Goal-Observation-Action (MGOA)} dataset, which contains 25,000 videos across 8 atomic tasks, providing about 30M goal-observation-action pairs. The automated construction method, along with the MGOA dataset, can contribute to the community's efforts to train Minecraft agents. Extensive experimental results demonstrate that Optimus-2 exhibits superior performance across atomic tasks, long-horizon tasks, and open-ended instruction tasks in Minecraft.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Picking the Cream of the Crop: Visual-Centric Data Selection with Collaborative Agents</title>
<link>https://arxiv.org/abs/2502.19917</link>
<guid>https://arxiv.org/abs/2502.19917</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态大语言模型 (MLLMs), 视觉指令调优数据集, 图像质量评估, 指令相关性评价, ViSA

总结:
本文提出了一种名为“基于视觉中心选择的智能体协作”(ViSA)的方法，用于改进多模态大型语言模型处理图像和复杂指令的能力。当前，构建大规模视觉指令调优数据集存在图像与指令不匹配以及图像质量问题。为解决这些问题，ViSA方法通过视觉智能体协作来量化图像信息并选择具有丰富视觉信息的图片，同时采用以视觉为中心的指令质量评估方法选择与高质量图片相关的优质指令数据。实验结果显示，使用ViSA仅需原数据量的2.5%，即能在七个基准测试上超越或达到现有最优模型的性能。此外，文章还进行了消融研究以验证其方法各组件的有效性。代码已在GitHub上公开。 <div>
arXiv:2502.19917v1 Announce Type: new 
Abstract: To improve Multimodal Large Language Models' (MLLMs) ability to process images and complex instructions, researchers predominantly curate large-scale visual instruction tuning datasets, which are either sourced from existing vision tasks or synthetically generated using LLMs and image descriptions. However, they often suffer from critical flaws, including misaligned instruction-image pairs and low-quality images. Such issues hinder training efficiency and limit performance improvements, as models waste resources on noisy or irrelevant data with minimal benefit to overall capability. To address this issue, we propose a \textbf{Vi}sual-Centric \textbf{S}election approach via \textbf{A}gents Collaboration (ViSA), which centers on image quality assessment and image-instruction relevance evaluation. Specifically, our approach consists of 1) an image information quantification method via visual agents collaboration to select images with rich visual information, and 2) a visual-centric instruction quality assessment method to select high-quality instruction data related to high-quality images. Finally, we reorganize 80K instruction data from large open-source datasets. Extensive experiments demonstrate that ViSA outperforms or is comparable to current state-of-the-art models on seven benchmarks, using only 2.5\% of the original data, highlighting the efficiency of our data selection approach. Moreover, we conduct ablation studies to validate the effectiveness of each component of our method. The code is available at https://github.com/HITsz-TMG/ViSA.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Playing Pok\'emon Red via Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.19920</link>
<guid>https://arxiv.org/abs/2502.19920</guid>
<content:encoded><![CDATA[
<div> 关键词: Pok\'emon Red, 游戏测试床, 深度强化学习(DRL), 基线代理, 奖励塑造<br /><br />总结:
本文介绍了针对Game Boy经典JRPG游戏Pokémon Red的研究，该游戏操作复杂，具有多任务处理、长规划步数、艰难探索和丰富策略等挑战。研究者构建了一个简化环境并提出了一种深度强化学习（DRL）训练方法，成功训练出了一个能完成初始段落至攻克Cerulean City的基线智能体。实验中进行了各种消融研究，揭示了奖励塑造中存在的问题，即智能体会针对特定奖励信号进行利用。同时，文中讨论了现有工作的局限性，并主张像Pokémon这样的游戏对于未来大型语言模型智能体、层次化训练算法以及高级探索方法等领域具有极大的研究潜力。源代码已开源在https://github.com/MarcoMeter/neroRL/tree/poke_red。 <div>
arXiv:2502.19920v1 Announce Type: new 
Abstract: Pok\'emon Red, a classic Game Boy JRPG, presents significant challenges as a testbed for agents, including multi-tasking, long horizons of tens of thousands of steps, hard exploration, and a vast array of potential policies. We introduce a simplistic environment and a Deep Reinforcement Learning (DRL) training methodology, demonstrating a baseline agent that completes an initial segment of the game up to completing Cerulean City. Our experiments include various ablations that reveal vulnerabilities in reward shaping, where agents exploit specific reward signals. We also discuss limitations and argue that games like Pok\'emon hold strong potential for future research on Large Language Model agents, hierarchical training algorithms, and advanced exploration methods. Source Code: https://github.com/MarcoMeter/neroRL/tree/poke_red
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Driven Mean Field Equilibrium Computation in Large-Population LQG Games</title>
<link>https://arxiv.org/abs/2502.19993</link>
<guid>https://arxiv.org/abs/2502.19993</guid>
<content:encoded><![CDATA[
<div> 关键词：数据驱动、$\varepsilon$-纳什均衡、连续时间线性二次高斯游戏、代数 riccati 方程、积分强化学习

总结:
本文提出了一种新颖的数据驱动方法，用于近似求解连续时间线性二次高斯（LQG）游戏中多个交互代理的$\varepsilon$-纳什均衡。该方法的核心在于，通过收集代理的状态和输入样本来解决两个代数Riccati方程和一个常微分方程，无需预先知道它们的动力学模型。使用积分强化学习技术处理标准的ARE问题，同时在一般条件下通过识别代理动力学的漂移系数来求解非对称ARE和ODE。此外，通过对模型施加特定条件，将基于IRL的方法扩展到近似求解非对称ARE。文中给出了数值例子以验证所提算法的有效性。<br /><br /> <div>
arXiv:2502.19993v1 Announce Type: new 
Abstract: This paper presents a novel data-driven approach for approximating the $\varepsilon$-Nash equilibrium in continuous-time linear quadratic Gaussian (LQG) games, where multiple agents interact with each other through their dynamics and infinite horizon discounted costs. The core of our method involves solving two algebraic Riccati equations (AREs) and an ordinary differential equation (ODE) using state and input samples collected from agents, eliminating the need for a priori knowledge of their dynamical models. The standard ARE is addressed through an integral reinforcement learning (IRL) technique, while the nonsymmetric ARE and the ODE are resolved by identifying the drift coefficients of the agents' dynamics under general conditions. Moreover, by imposing specific conditions on models, we extend the IRL-based approach to approximately solve the nonsymmetric ARE. Numerical examples are given to demonstrate the effectiveness of the proposed algorithms.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Modified FOX Optimizer for Solving optimization problems</title>
<link>https://arxiv.org/abs/2502.20027</link>
<guid>https://arxiv.org/abs/2502.20027</guid>
<content:encoded><![CDATA[
<div> 关键词：modified FOX optimizer (mFOX)，FOX optimizer，Oppositional-Based Learning (OBL)，exploration-exploitation平衡，复杂优化任务

总结:

本文提出了一种改进的狐狸优化器(mFOX)，旨在解决原版FOX优化器在求解实际问题和工程问题时可能过早收敛到局部最优的问题。mFOX通过三个步骤增强了探索性和平衡了探索与开发：首先采用对立学习策略(OBL)改进初始种群；其次，精细化控制参数以更好地平衡探索与开发；最后，引入新的更新方程，使智能体可以根据彼此的位置调整位置，而不仅仅是依赖当前最佳已知位置。实验结果表明，mFOX在23个经典测试函数、10个CEC2019测试函数和12个CEC2022测试函数上分别有74%、60%和58%的表现优于其他12种知名算法，并成功解决了四个工程问题，显示出mFOX在处理单模态、约束性及高维度等复杂优化任务上的强大竞争力。 <div>
arXiv:2502.20027v1 Announce Type: new 
Abstract: The FOX optimizer, inspired by red fox hunting behavior, is a powerful algorithm for solving real-world and engineering problems. However, despite balancing exploration and exploitation, it can prematurely converge to local optima, as agent positions are updated solely based on the current best-known position, causing all agents to converge on one location. This study proposes the modified FOX optimizer (mFOX) to enhance exploration and balance exploration and exploitation in three steps. First, the Oppositional-Based Learning (OBL) strategy is used to improve the initial population. Second, control parameters are refined to achieve a better balance between exploration and exploitation. Third, a new update equation is introduced, allowing agents to adjust their positions relative to one another rather than relying solely on the best-known position. This approach improves exploration efficiency without adding complexity. The mFOX algorithm's performance is evaluated against 12 well-known algorithms on 23 classical benchmark functions, 10 CEC2019 functions, and 12 CEC2022 functions. It outperforms competitors in 74% of the classical benchmarks, 60% of the CEC2019 benchmarks, and 58% of the CEC2022 benchmarks. Additionally, mFOX effectively addresses four engineering problems. These results demonstrate mFOX's strong competitiveness in solving complex optimization tasks, including unimodal, constrained, and high-dimensional problems.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Robust Mean Field Social Control: A Unified Reinforcement Learning Framework</title>
<link>https://arxiv.org/abs/2502.20029</link>
<guid>https://arxiv.org/abs/2502.20029</guid>
<content:encoded><![CDATA[
<div> 关键词: 线性二次高斯鲁棒均场社会控制问题、乘性噪声、分散策略、不定型随机代数Riccati方程、输入扰动状态稳定性、积分强化学习

总结:<br />
本文研究了存在乘性噪声的线性二次高斯鲁棒均场社会控制问题。文章旨在计算无需完全了解代理动态的渐近分散策略。面对求解反馈增益的不定型随机代数Riccati方程和前馈增益的不定型代数Riccati方程的挑战，提出了一种统一的双层迭代框架，并为内外层迭代提供了严格的收敛证明。其次，针对因估计和建模误差可能导致的迭代过程中的偏差，利用小扰动输入至状态稳定性技术分析了所提算法的鲁棒性，确保即使存在扰动也能收敛到最优解的邻域。最后，为解决要求精确掌握代理动态的问题，文中运用积分强化学习技术，在双层迭代框架内开发了一种数据驱动方法。通过一个数值例子展示了所提算法的有效性。 <div>
arXiv:2502.20029v1 Announce Type: new 
Abstract: This paper studies linear quadratic Gaussian robust mean field social control problems in the presence of multiplicative noise. We aim to compute asymptotic decentralized strategies without requiring full prior knowledge of agents' dynamics. The primary challenges lie in solving an indefinite stochastic algebraic Riccati equation for feedback gains, and an indefinite algebraic Riccati equation for feedforward gains. To overcome these challenges, we first propose a unified dual-loop iterative framework that simultaneously handles both indefinite Riccati-type equations, and provide rigorous convergence proofs for both outer-loop and inner-loop iterations. Second, recognizing that biases may arise in iterative processes due to estimation and modeling errors, we analyze the robustness of the proposed algorithm by using the small-disturbance input-to-state stability technique. This ensures convergence to a neighborhood of the optimal solution, even in the existence of disturbances. Finally, to address the limitation of requiring precise knowledge of agents' dynamics, we employ the integral reinforcement learning technique to develop a data-driven method within the dual-loop iterative framework. A numerical example is provided to demonstrate the effectiveness of the proposed algorithm.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RouteRL: Multi-agent reinforcement learning framework for urban route choice with autonomous vehicles</title>
<link>https://arxiv.org/abs/2502.20065</link>
<guid>https://arxiv.org/abs/2502.20065</guid>
<content:encoded><![CDATA[
<div> 关键词: RouteRL、多智能体强化学习(MARL)、微观交通模拟、自动驾驶车辆(AVs)、行为路线选择模型

<br /><br />总结:
本文介绍了一个名为RouteRL的新颖框架，该框架将多智能体强化学习（MARL）与微观交通模拟相结合，旨在测试和开发用于自动驾驶车辆（AVs）的有效路径选择策略。RouteRL模拟城市中驾驶员代理的日常路径选择行为，包括两种类型：使用行为路线选择模型仿真的人类驾驶员以及以MARL代理形式存在的AVs，这些AVs会优化其策略以实现预定义目标。该研究通过RouteRL的技术报告概述了其潜在的研究贡献，并通过示例展示了其实际影响。RouteRL致力于推动MARL、交通建模以及人机交互在交通运输应用领域的研究进展。 <div>
arXiv:2502.20065v1 Announce Type: new 
Abstract: RouteRL is a novel framework that integrates multi-agent reinforcement learning (MARL) with a microscopic traffic simulation, facilitating the testing and development of efficient route choice strategies for autonomous vehicles (AVs). The proposed framework simulates the daily route choices of driver agents in a city, including two types: human drivers, emulated using behavioral route choice models, and AVs, modeled as MARL agents optimizing their policies for a predefined objective. RouteRL aims to advance research in MARL, transport modeling, and human-AI interaction for transportation applications. This study presents a technical report on RouteRL, outlines its potential research contributions, and showcases its impact via illustrative examples.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Generative Model Enhanced Multi-Agent Reinforcement Learning Method for Electric Vehicle Charging Navigation</title>
<link>https://arxiv.org/abs/2502.20068</link>
<guid>https://arxiv.org/abs/2502.20068</guid>
<content:encoded><![CDATA[
<div> 关键词: 电动车辆(EVs)，动态充电导航，深度强化学习(DRL)，局部信息，生成模型，多智能体，条件变分自编码器-长短期记忆(CVAE-LSTM)，未来充电竞争编码器，多梯度下降算法(MGDA)，Xi'an，中国。

总结:<br />
针对电动车辆充电站选择问题，本文提出了一种新颖的、基于生成模型增强的多智能体深度强化学习算法。该算法仅利用电动车的局部信息，解决了全局信息获取带来的通信成本和隐私问题。具体来说，策略网络在电动车端实现，采用CVAE-LSTM推荐模型提供推荐信息，并设计了未来充电竞争编码器来有效压缩全局信息，提升训练性能。此外，通过运用多梯度下降算法(MGDA)自适应地平衡训练目标的两部分权重，保证了训练过程的稳定性。实现在西安地区的模拟实验结果显示，本方法相比于现有基于局部信息的方法表现出更优性能，与基于全局信息的方法相比，性能损失小于8%。 <div>
arXiv:2502.20068v1 Announce Type: new 
Abstract: With the widespread adoption of electric vehicles (EVs), navigating for EV drivers to select a cost-effective charging station has become an important yet challenging issue due to dynamic traffic conditions, fluctuating electricity prices, and potential competition from other EVs. The state-of-the-art deep reinforcement learning (DRL) algorithms for solving this task still require global information about all EVs at the execution stage, which not only increases communication costs but also raises privacy issues among EV drivers. To overcome these drawbacks, we introduce a novel generative model-enhanced multi-agent DRL algorithm that utilizes only the EV's local information while achieving performance comparable to these state-of-the-art algorithms. Specifically, the policy network is implemented on the EV side, and a Conditional Variational Autoencoder-Long Short Term Memory (CVAE-LSTM)-based recommendation model is developed to provide recommendation information. Furthermore, a novel future charging competition encoder is designed to effectively compress global information, enhancing training performance. The multi-gradient descent algorithm (MGDA) is also utilized to adaptively balance the weight between the two parts of the training objective, resulting in a more stable training process. Simulations are conducted based on a practical area in Xi\'an, China. Experimental results show that our proposed algorithm, which relies on local information, outperforms existing local information-based methods and achieves less than 8\% performance loss compared to global information-based methods.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Collab-Overcooked: Benchmarking and Evaluating Large Language Models as Collaborative Agents</title>
<link>https://arxiv.org/abs/2502.20073</link>
<guid>https://arxiv.org/abs/2502.20073</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、多智能体系统、Collab-Overcooked、自然语言通信、评价指标

总结:
本文提出了一种基于大型语言模型（LLMs）的多智能体系统（LLM-MAS）新基准——Collab-Overcooked，该基准是在流行的Overcooked-AI游戏基础上构建的，旨在生成更具挑战性的互动环境任务。Collab-Overcooked在现有基准上进行了两个方面的扩展：一是提供了一个支持多样化任务和目标并鼓励通过自然语言进行协作的多智能体框架；二是引入了一系列过程导向的评价指标，以评估不同LLM代理在精细协作能力上的表现，这是以往工作中常被忽视的一个维度。实验结果显示，虽然LLMs在目标解释方面表现出较强的能力，但在主动协作和持续适应等完成复杂任务的关键环节上存在显著差距。此外，文章指出了LLM-MAS的优势和不足，并为改进和评价LLM-MAS提供了一个统一、开源的基准。Collab-Overcooked项目包括公开发布的环境、30个开放性任务及综合评价工具包，现已在https://github.com/YusaeMeow/Collab-Overcooked上公开可用。 <div>
arXiv:2502.20073v1 Announce Type: new 
Abstract: Large language models (LLMs) based agent systems have made great strides in real-world applications beyond traditional NLP tasks. This paper proposes a new LLM-powered Multi-Agent System (LLM-MAS) benchmark, Collab-Overcooked, built on the popular Overcooked-AI game with more applicable and challenging tasks in interactive environments. Collab-Overcooked extends existing benchmarks from two novel perspectives. First, it provides a multi-agent framework supporting diverse tasks and objectives and encourages collaboration through natural language communication. Second, it introduces a spectrum of process-oriented evaluation metrics to assess the fine-grained collaboration capabilities of different LLM agents, a dimension often overlooked in prior work. We conduct extensive experiments over 10 popular LLMs and show that, while the LLMs present a strong ability in goal interpretation, there is a significant discrepancy in active collaboration and continuous adaption that are critical for efficiently fulfilling complicated tasks. Notably, we highlight the strengths and weaknesses in LLM-MAS and provide insights for improving and evaluating LLM-MAS on a unified and open-sourced benchmark. Environments, 30 open-ended tasks, and an integrated evaluation package are now publicly available at https://github.com/YusaeMeow/Collab-Overcooked.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Discovering Antagonists in Networks of Systems: Robot Deployment</title>
<link>https://arxiv.org/abs/2502.20125</link>
<guid>https://arxiv.org/abs/2502.20125</guid>
<content:encoded><![CDATA[
<div> 关键词: 异常检测、上下文感知、机器人 Swarm、覆盖任务、正常化流

总结:
本文提出了一种上下文相关的异常检测方法，应用于执行覆盖任务的机器人 Swarm 的物理运动中。该方法使用模拟的 Swarm 正常行为训练一个正常化流模型，以预测机器人在其当前环境上下文中的运动概率。在实际应用中，通过预测观测到的运动概率，结合检测标准来判断机器人行为是否正常或对抗性。文章对五种不同的对抗性行为策略进行了评估，其中提出的最佳检测标准能够准确地将至少 80% 的每种对抗性类型分类出来，同时保持对正常机器人行为的误报率低于 5%。此外，该方法还在硬件实验中得到了验证，结果与模拟场景相似。相较于现有的最优方法，该研究提高了正常化流的预测性能以及检测标准的鲁棒性。 <div>
arXiv:2502.20125v1 Announce Type: new 
Abstract: A contextual anomaly detection method is proposed and applied to the physical motions of a robot swarm executing a coverage task. Using simulations of a swarm's normal behavior, a normalizing flow is trained to predict the likelihood of a robot motion within the current context of its environment. During application, the predicted likelihood of the observed motions is used by a detection criterion that categorizes a robot agent as normal or antagonistic. The proposed method is evaluated on five different strategies of antagonistic behavior. Importantly, only readily available simulated data of normal robot behavior is used for training such that the nature of the anomalies need not be known beforehand. The best detection criterion correctly categorizes at least 80% of each antagonistic type while maintaining a false positive rate of less than 5% for normal robot agents. Additionally, the method is validated in hardware experiments, yielding results similar to the simulated scenarios. Compared to the state-of-the-art approach, both the predictive performance of the normalizing flow and the robustness of the detection criterion are increased.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Telephone Surveys Meet Conversational AI: Evaluating a LLM-Based Telephone Survey System at Scale</title>
<link>https://arxiv.org/abs/2502.20140</link>
<guid>https://arxiv.org/abs/2502.20140</guid>
<content:encoded><![CDATA[
<div> 关键词：电话调查、人工智能、文本转语音(TTS)、大型语言模型(LLM)、语音转文本(STT)

<br /><br />总结：
本文介绍了一种基于人工智能的电话调查系统，该系统集成了文本转语音、大型语言模型和语音转文本技术，能够在大规模上模拟人类访谈的灵活性。研究团队通过在美国进行的小规模试点（n=75）和在秘鲁的大规模部署（n=2,739）对该系统进行了测试，成功地对参与者进行了开放性和封闭性问题的提问、基本澄清以及动态分支逻辑导航，从而实现了无需招聘或培训采访员的大规模快速部署。虽然AI系统的探究深度不及人类访谈员，但研究发现，对于结构化项目的数据质量已接近人类主导的标准。这项研究表明，基于LLM的电话访谈系统在现实世界的电话调查情境中首次实现大规模成功应用，为市场研究、社会科学和公共意见研究等领域提供了扩展可规模化、一致性的数据收集方式，同时保持了适当的研究数据质量，提高了运营效率。 <div>
arXiv:2502.20140v1 Announce Type: new 
Abstract: Telephone surveys remain a valuable tool for gathering insights but typically require substantial resources in training and coordinating human interviewers. This work presents an AI-driven telephone survey system integrating text-to-speech (TTS), a large language model (LLM), and speech-to-text (STT) that mimics the versatility of human-led interviews on scale.
  We tested the system across two populations, a pilot study in the United States (n = 75) and a large-scale deployment in Peru (n = 2,739), inviting participants via web-based links and contacting them via direct phone calls. The AI agent successfully administered open-ended and closed-ended questions, handled basic clarifications, and dynamically navigated branching logic, allowing fast large-scale survey deployment without interviewer recruitment or training.
  Our findings demonstrate that while the AI system's probing for qualitative depth was more limited than human interviewers, overall data quality approached human-led standards for structured items. This study represents one of the first successful large-scale deployments of an LLM-based telephone interviewer in a real-world survey context. The AI-powered telephone survey system has the potential for expanding scalable, consistent data collecting across market research, social science, and public opinion studies, thus improving operational efficiency while maintaining appropriate data quality for research.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Highly Parallelized Reinforcement Learning Training with Relaxed Assignment Dependencies</title>
<link>https://arxiv.org/abs/2502.20190</link>
<guid>https://arxiv.org/abs/2502.20190</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 深度强化学习, 并行计算, 分布式训练系统, 天玑(TianJi)

总结:<br />
针对深度强化学习（DRL）训练复杂性增高的问题，文章提出了一个名为天玑（TianJi）的高吞吐量分布式RL训练系统。该系统旨在通过将DRL训练过程划分为子任务并利用平行计算来有效降低训练成本。天玑放松了子任务组件之间的数据分配依赖关系，采用事件驱动的异步通信方式，并保持子任务组件间的清晰边界。为了解决因放松分配依赖带来的收敛不确定性，天玑提出了一种基于样本生产和消费平衡的分布式策略，控制样本的新鲜度以保证收敛质量。实验结果显示，天玑相较于相关比较系统，其收敛时间加速比最高可达4.37倍；在扩展至八个计算节点时，相对于XingTian展现了1.6倍的收敛时间加速和7.13倍的吞吐量提升，证明了其加速训练与可扩展性的能力。此外，天玑还在数据传输效率实验中表现出色，接近硬件限制，并对on-policy算法同样有效，相比于RLlib和XingTian分别实现了4.36倍和2.95倍的收敛时间加速。天玑项目已在GitHub上开源，地址为https://github.com/HiPRL/TianJi.git。 <div>
arXiv:2502.20190v1 Announce Type: new 
Abstract: As the demands for superior agents grow, the training complexity of Deep Reinforcement Learning (DRL) becomes higher. Thus, accelerating training of DRL has become a major research focus. Dividing the DRL training process into subtasks and using parallel computation can effectively reduce training costs. However, current DRL training systems lack sufficient parallelization due to data assignment between subtask components. This assignment issue has been ignored, but addressing it can further boost training efficiency. Therefore, we propose a high-throughput distributed RL training system called TianJi. It relaxes assignment dependencies between subtask components and enables event-driven asynchronous communication. Meanwhile, TianJi maintains clear boundaries between subtask components. To address convergence uncertainty from relaxed assignment dependencies, TianJi proposes a distributed strategy based on the balance of sample production and consumption. The strategy controls the staleness of samples to correct their quality, ensuring convergence. We conducted extensive experiments. TianJi achieves a convergence time acceleration ratio of up to 4.37 compared to related comparison systems. When scaled to eight computational nodes, TianJi shows a convergence time speedup of 1.6 and a throughput speedup of 7.13 relative to XingTian, demonstrating its capability to accelerate training and scalability. In data transmission efficiency experiments, TianJi significantly outperforms other systems, approaching hardware limits. TianJi also shows effectiveness in on-policy algorithms, achieving convergence time acceleration ratios of 4.36 and 2.95 compared to RLlib and XingTian. TianJi is accessible at https://github.com/HiPRL/TianJi.git.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model Checking Linear Temporal Logic with Standpoint Modalities</title>
<link>https://arxiv.org/abs/2502.20193</link>
<guid>https://arxiv.org/abs/2502.20193</guid>
<content:encoded><![CDATA[
<div> 关键词：Standpoint线性时间逻辑（SLTL），经典线性时间逻辑（LTL），观点模态，语义，模型检查算法<br /><br />总结:
本文介绍了Standpoint线性时间逻辑（SLTL），它是经典线性时间逻辑（LTL）的一种扩展，引入了观点模态以表达从某agent视角认为某一公式成立的概念。文中提出了四种新的观点模态语义，并为SLTL在任意这些语义下设计了一个通用的模型检查算法。此外，文章分析了对应模型检查问题的计算复杂度，发现在三种情况下该问题是PSPACE完全的，这与已知的SLTL可满足性问题的EXPSPACE完全性形成对比。 <div>
arXiv:2502.20193v1 Announce Type: new 
Abstract: Standpoint linear temporal logic ($SLTL$) is a recently introduced extension of classical linear temporal logic ($LTL$) with standpoint modalities. Intuitively, these modalities allow to express that, from agent $a$'s standpoint, it is conceivable that a given formula holds.
  Besides the standard interpretation of the standpoint modalities we introduce four new semantics, which differ in the information an agent can extract from the history. We provide a general model checking algorithm applicable to $SLTL$ under any of the five semantics. Furthermore we analyze the computational complexity of the corresponding model checking problems, obtaining PSPACE-completeness in three cases, which stands in contrast to the known EXPSPACE-completeness of the $SLTL$ satisfiability problem.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MARVEL: Multi-Agent Reinforcement Learning for constrained field-of-View multi-robot Exploration in Large-scale environments</title>
<link>https://arxiv.org/abs/2502.20217</link>
<guid>https://arxiv.org/abs/2502.20217</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-robot exploration、constrained FoV、MARVEL、multi-agent reinforcement learning (MARL)、graph attention networks

总结:

本文提出了一种名为MARVEL的新颖神经网络框架，用于解决具有受限视场（FoV）的小型机器人（如无人机）团队的多机器人探索问题。该框架结合了图注意力网络与创新的前沿和方向特征融合技术，利用多智能体强化学习（MARL）制定协作和分散的机器人策略。为了解决视角规划的大动作空间问题，文章还引入了一种新颖的信息驱动动作剪枝策略。实验表明，无论团队规模和传感器配置如何变化（例如FoV和传感器范围），MARVEL都能在无需额外训练的情况下提高多机器人在复杂大型室内环境中的协调决策能力，并优于现有最先进的探索规划算法。此外，文中通过在最大可达90m×90m的大规模环境中进行实验以及在真实无人机硬件上的成功部署，验证了MARVEL方法的泛化能力和实际应用潜力。 <div>
arXiv:2502.20217v1 Announce Type: new 
Abstract: In multi-robot exploration, a team of mobile robot is tasked with efficiently mapping an unknown environments. While most exploration planners assume omnidirectional sensors like LiDAR, this is impractical for small robots such as drones, where lightweight, directional sensors like cameras may be the only option due to payload constraints. These sensors have a constrained field-of-view (FoV), which adds complexity to the exploration problem, requiring not only optimal robot positioning but also sensor orientation during movement. In this work, we propose MARVEL, a neural framework that leverages graph attention networks, together with novel frontiers and orientation features fusion technique, to develop a collaborative, decentralized policy using multi-agent reinforcement learning (MARL) for robots with constrained FoV. To handle the large action space of viewpoints planning, we further introduce a novel information-driven action pruning strategy. MARVEL improves multi-robot coordination and decision-making in challenging large-scale indoor environments, while adapting to various team sizes and sensor configurations (i.e., FoV and sensor range) without additional training. Our extensive evaluation shows that MARVEL's learned policies exhibit effective coordinated behaviors, outperforming state-of-the-art exploration planners across multiple metrics. We experimentally demonstrate MARVEL's generalizability in large-scale environments, of up to 90m by 90m, and validate its practical applicability through successful deployment on a team of real drone hardware.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Importance of Reward Design in Reinforcement Learning-based Dynamic Algorithm Configuration: A Case Study on OneMax with (1+($\lambda$,$\lambda$))-GA</title>
<link>https://arxiv.org/abs/2502.20265</link>
<guid>https://arxiv.org/abs/2502.20265</guid>
<content:encoded><![CDATA[
<div> 关键词: 动态算法配置, 强化学习, 奖励设计, $(1+(\lambda,\lambda))$-GA, 一模多峰问题

总结:
本文关注动态算法配置（DAC）领域中强化学习（RL）的应用，尤其是针对$(1+(\lambda,\lambda))$-GA优化OneMax问题时的算法参数调整。研究发现，奖励设计对于RL代理的学习效果至关重要，不当的设计可能导致探索不足、无法学到最优策略以及扩展性与学习发散问题。为解决这些问题，文中提出了使用奖励塑造机制来促进RL代理对环境的更有效探索。实验结果表明，RL不仅能够用于动态配置$(1+(\lambda,\lambda))$-GA，而且奖励塑造机制能提升RL代理在不同规模OneMax问题上的可扩展性优势。<br /><br /> <div>
arXiv:2502.20265v1 Announce Type: new 
Abstract: Dynamic Algorithm Configuration (DAC) has garnered significant attention in recent years, particularly in the prevalence of machine learning and deep learning algorithms. Numerous studies have leveraged the robustness of decision-making in Reinforcement Learning (RL) to address the optimization challenges associated with algorithm configuration. However, making an RL agent work properly is a non-trivial task, especially in reward design, which necessitates a substantial amount of handcrafted knowledge based on domain expertise. In this work, we study the importance of reward design in the context of DAC via a case study on controlling the population size of the $(1+(\lambda,\lambda))$-GA optimizing OneMax. We observed that a poorly designed reward can hinder the RL agent's ability to learn an optimal policy because of a lack of exploration, leading to both scalability and learning divergence issues. To address those challenges, we propose the application of a reward shaping mechanism to facilitate enhanced exploration of the environment by the RL agent. Our work not only demonstrates the ability of RL in dynamically configuring the $(1+(\lambda,\lambda))$-GA, but also confirms the advantages of reward shaping in the scalability of RL agents across various sizes of OneMax problems.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>M^3Builder: A Multi-Agent System for Automated Machine Learning in Medical Imaging</title>
<link>https://arxiv.org/abs/2502.20301</link>
<guid>https://arxiv.org/abs/2502.20301</guid>
<content:encoded><![CDATA[
<div> 关键词: M3Builder、多智能体系统、医疗影像、机器学习、M3Bench<br /><br />总结:

本文介绍了M3Builder，一个用于自动化医疗影像领域机器学习的创新性多智能体系统。M3Builder由四个专业化的智能体组成，它们协作完成从数据处理、环境配置到模型训练等复杂、多步骤的工作流程。系统采用了一个结构化的医学影像机器学习工作空间，允许智能体通过自由文本描述与数据集、训练代码和交互工具进行有效通信和任务执行。为了评估自动化的医疗影像机器学习进展，文中提出了涵盖五个解剖部位、三种成像模态以及四种通用任务的M3Bench基准。此外，研究团队还使用了包括Claude系列、GPT-4o和DeepSeek-V3在内的七种先进的大型语言模型作为系统中智能体的核心。实验结果显示，使用Claude-3.7-Sonnet作为核心的M3Builder在完成医疗影像领域的机器学习任务上表现出优越性能，成功率达到94.29%，显示出在实现医疗影像领域完全自动化机器学习的巨大潜力。 <div>
arXiv:2502.20301v1 Announce Type: new 
Abstract: Agentic AI systems have gained significant attention for their ability to autonomously perform complex tasks. However, their reliance on well-prepared tools limits their applicability in the medical domain, which requires to train specialized models. In this paper, we make three contributions: (i) We present M3Builder, a novel multi-agent system designed to automate machine learning (ML) in medical imaging. At its core, M3Builder employs four specialized agents that collaborate to tackle complex, multi-step medical ML workflows, from automated data processing and environment configuration to self-contained auto debugging and model training. These agents operate within a medical imaging ML workspace, a structured environment designed to provide agents with free-text descriptions of datasets, training codes, and interaction tools, enabling seamless communication and task execution. (ii) To evaluate progress in automated medical imaging ML, we propose M3Bench, a benchmark comprising four general tasks on 14 training datasets, across five anatomies and three imaging modalities, covering both 2D and 3D data. (iii) We experiment with seven state-of-the-art large language models serving as agent cores for our system, such as Claude series, GPT-4o, and DeepSeek-V3. Compared to existing ML agentic designs, M3Builder shows superior performance on completing ML tasks in medical imaging, achieving a 94.29% success rate using Claude-3.7-Sonnet as the agent core, showing huge potential towards fully automated machine learning in medical imaging.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Deep Reinforcement Learning based Autonomous Decision-Making for Cooperative UAVs: A Search and Rescue Real World Application</title>
<link>https://arxiv.org/abs/2502.20326</link>
<guid>https://arxiv.org/abs/2502.20326</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机系统、自主导航、深度强化学习、任务分配、图卷积网络、激光雷达SLAM

总结：<br />
本文提出了一种针对GNSS信号缺失的室内环境中的多无人机系统的综合框架。该框架利用深度强化学习（特别是Twin Delayed Deep Deterministic Policy Gradient算法）实现自主导航，并通过集成人工势场奖励结构来优化路径规划和增强障碍物避障能力。对于多无人机间的任务分配问题，文章采用了经过DRL训练的图卷积网络（GCN），以动态实时地反映无人机与任务间的交互，以及环境条件和无人机自身的能力，从而实现有效的协作与协调。为了在无GNSS环境下确保精确的位姿估计，文中利用激光雷达SLAM结合深度相机技术来解决“走廊问题”，提供强大的定位与建图功能。实验结果表明，该框架在满足北约Sapience自主合作无人机竞赛需求的特定场景中表现出色，最终助力参赛队伍在2024年Sapience比赛中荣获冠军。 <div>
arXiv:2502.20326v1 Announce Type: new 
Abstract: This paper proposes a holistic framework for autonomous guidance, navigation, and task distribution among multi-drone systems operating in Global Navigation Satellite System (GNSS)-denied indoor settings. We advocate for a Deep Reinforcement Learning (DRL)-based guidance mechanism, utilising the Twin Delayed Deep Deterministic Policy Gradient algorithm. To improve the efficiency of the training process, we incorporate an Artificial Potential Field (APF)-based reward structure, enabling the agent to refine its movements, thereby promoting smoother paths and enhanced obstacle avoidance in indoor contexts. Furthermore, we tackle the issue of task distribution among cooperative UAVs through a DRL-trained Graph Convolutional Network (GCN). This GCN represents the interactions between drones and tasks, facilitating dynamic and real-time task allocation that reflects the current environmental conditions and the capabilities of the drones. Such an approach fosters effective coordination and collaboration among multiple drones during search and rescue operations or other exploratory endeavours. Lastly, to ensure precise odometry in environments lacking GNSS, we employ Light Detection And Ranging Simultaneous Localisation and Mapping complemented by a depth camera to mitigate the hallway problem. This integration offers robust localisation and mapping functionalities, thereby enhancing the systems dependability in indoor navigation. The proposed multi-drone framework not only elevates individual navigation capabilities but also optimises coordinated task allocation in complex, obstacle-laden environments. Experimental evaluations conducted in a setup tailored to meet the requirements of the NATO Sapience Autonomous Cooperative Drone Competition demonstrate the efficacy of the proposed system, yielding outstanding results and culminating in a first-place finish in the 2024 Sapience competition.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safety Representations for Safer Policy Learning</title>
<link>https://arxiv.org/abs/2502.20341</link>
<guid>https://arxiv.org/abs/2502.20341</guid>
<content:encoded><![CDATA[
<div> 关键词: 强化学习, 安全探索, 策略优化, 安全表示学习, 效率

<br /><br />总结:

本文针对强化学习在安全关键应用中的挑战，即在寻找最优策略过程中广泛探索状态空间可能导致灾难性后果的问题。现有的安全探索方法通过施加约束来缓解风险，但这往往导致行为过于保守和学习效率低下。为解决这一问题，文章提出了一个新方法，该方法能显式地学习状态相关的安全表示。通过将这些安全表示融入状态特征，我们的方法能在鼓励更安全探索的同时避免过度谨慎，从而在安全关键场景中实现更有效、更安全的策略学习。实验结果表明，这种方法在训练过程中显著提高了任务性能并减少了约束违规情况，凸显了其在平衡探索与安全性方面的有效性。 <div>
arXiv:2502.20341v1 Announce Type: new 
Abstract: Reinforcement learning algorithms typically necessitate extensive exploration of the state space to find optimal policies. However, in safety-critical applications, the risks associated with such exploration can lead to catastrophic consequences. Existing safe exploration methods attempt to mitigate this by imposing constraints, which often result in overly conservative behaviours and inefficient learning. Heavy penalties for early constraint violations can trap agents in local optima, deterring exploration of risky yet high-reward regions of the state space. To address this, we introduce a method that explicitly learns state-conditioned safety representations. By augmenting the state features with these safety representations, our approach naturally encourages safer exploration without being excessively cautious, resulting in more efficient and safer policy learning in safety-critical scenarios. Empirical evaluations across diverse environments show that our method significantly improves task performance while reducing constraint violations during training, underscoring its effectiveness in balancing exploration with safety.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Improving the Efficiency of a Deep Reinforcement Learning-Based Power Management System for HPC Clusters Using Curriculum Learning</title>
<link>https://arxiv.org/abs/2502.20348</link>
<guid>https://arxiv.org/abs/2502.20348</guid>
<content:encoded><![CDATA[
<div> 关键词：高能效计算、高性能计算(HPC)、能源消耗、强化学习(RL)、课程学习(Curriculum Learning)

总结:
<br />
本文探讨了如何通过集成课程学习(Curriculum Learning, CL)提升深度强化学习(DRL)代理在高性能计算(HPC)系统电源管理中的性能。研究中，作者使用Batsim-py模拟框架对比了CL基线DRL方法和传统的固定时间超时策略。实验结果显示，采用从易到难的教学进程的CL-DRL代理在减少无效能耗方面优于其他训练方式，相比基础DRL方法节能3.73%，相较于最佳超时配置(每闲置15分钟关机)提高了4.66%的节能效果。同时，该最优代理还缩短了平均作业等待时间达9.24%，并保持了较高的作业填充率，表明其在资源利用效率上更具优势。敏感性测试进一步证实，该代理具备对不同开关机持续时间、功率水平及集群规模变化的适应性，无需重新训练即可应对各种系统参数调整。研究结果证明，课程学习可显著提高基于DRL的HPC电源管理效能，兼顾节能、服务质量与系统配置多样性之间的平衡。 <div>
arXiv:2502.20348v1 Announce Type: new 
Abstract: High energy consumption remains a key challenge in high-performance computing (HPC) systems, which often feature hundreds or thousands of nodes drawing substantial power even in idle or standby modes. Although powering down unused nodes can improve energy efficiency, choosing the wrong time to do so can degrade quality of service by delaying job execution. Machine learning, in particular reinforcement learning (RL), has shown promise in determining optimal times to switch nodes on or off. In this study, we enhance the performance of a deep reinforcement learning (DRL) agent for HPC power management by integrating curriculum learning (CL), a training approach that introduces tasks with gradually increasing difficulty. Using the Batsim-py simulation framework, we compare the proposed CL-based agent to both a baseline DRL method (without CL) and the conventional fixed-time timeout strategy. Experimental results confirm that an easy-to-hard curriculum outperforms other training orders in terms of reducing wasted energy usage. The best agent achieves a 3.73% energy reduction over the baseline DRL method and a 4.66% improvement compared to the best timeout configuration (shutdown every 15 minutes of idle time). In addition, it reduces average job waiting time by 9.24% and maintains a higher job-filling rate, indicating more effective resource utilization. Sensitivity tests across various switch-on durations, power levels, and cluster sizes further reveal the agent's adaptability to changing system parameters without retraining. These findings demonstrate that curriculum learning can significantly improve DRL-based power management in HPC, balancing energy savings, quality of service, and robustness to diverse configurations.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Trajectory-to-Action Pipeline (TAP): Automated Scenario Description Extraction for Autonomous Vehicle Behavior Comparison</title>
<link>https://arxiv.org/abs/2502.20353</link>
<guid>https://arxiv.org/abs/2502.20353</guid>
<content:encoded><![CDATA[
<div> 关键词: 场景描述语言(SDLs)、轨迹到动作管道(TAP)、自动驾驶车辆(AVs)、Waymo开放运动数据集(WOMD)、行为相似性

总结:
该论文介绍了用于从大规模轨迹数据集中自动提取场景描述语言标签的轨迹到动作管道(TAP)方法。TAP利用基于规则的交叉熵优化策略直接从数据中学习参数，从而增强了在多样化驾驶环境中的泛化能力。在应用到Waymo开放运动数据集(WOMD)上时，相比于平均位移误差(ADE)和动态时间规整(DTW)，TAP在识别行为相似轨迹方面表现出高达30%的更高精度和24%的优势。此外，TAP还能实现独特驾驶行为的自动化检测，简化了自动驾驶汽车测试过程中的安全性评估流程。这项工作为可扩展的基于场景的自动驾驶行为分析奠定了基础，并有望进一步拓展至多智能体情境的集成分析。 <div>
arXiv:2502.20353v1 Announce Type: new 
Abstract: Scenario Description Languages (SDLs) provide structured, interpretable embeddings that represent traffic scenarios encountered by autonomous vehicles (AVs), supporting key tasks such as scenario similarity searches and edge case detection for safety analysis. This paper introduces the Trajectory-to-Action Pipeline (TAP), a scalable and automated method for extracting SDL labels from large trajectory datasets. TAP applies a rules-based cross-entropy optimization approach to learn parameters directly from data, enhancing generalization across diverse driving contexts. Using the Waymo Open Motion Dataset (WOMD), TAP achieves 30% greater precision than Average Displacement Error (ADE) and 24% over Dynamic Time Warping (DTW) in identifying behaviorally similar trajectories. Additionally, TAP enables automated detection of unique driving behaviors, streamlining safety evaluation processes for AV testing. This work provides a foundation for scalable scenario-based AV behavior analysis, with potential extensions for integrating multi-agent contexts.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Legal Knowledge and AI: Retrieval-Augmented Generation with Vector Stores, Knowledge Graphs, and Hierarchical Non-negative Matrix Factorization</title>
<link>https://arxiv.org/abs/2502.20364</link>
<guid>https://arxiv.org/abs/2502.20364</guid>
<content:encoded><![CDATA[
<div> 关键词: Agentic Generative AI、Large Language Models (LLMs)、Retrieval-Augmented Generation (RAG)、Knowledge Graphs (KGs)、Vector Stores (VSs)

<br /><br />总结:
本文介绍了利用Agentic Generative AI技术，特别是结合了大型语言模型（LLMs）、检索增强生成（RAG）、知识图谱（KGs）和向量存储（VSs）的方法，对法律系统等专业领域带来的变革性影响。该技术擅长处理大规模非结构化或半结构化数据中的关系推理。在法律领域，由于其复杂的宪法、法规、条例和判例之间的相互关联性，利用此类AI系统可以整合RAG、VS和通过非负矩阵分解（NMF）构建的KG，以提升法律信息检索和AI推理能力，减少虚幻信息的产生。文章提出了一种AI系统，该系统采用网络爬虫技术从Justia等公开平台系统地收集如法规、宪法条款和判例法等法律文本，并通过高级语义表示、层次关系和潜在主题发现，填补了传统基于关键字搜索与上下文理解之间的鸿沟。这个框架支持法律文档聚类、摘要和交叉引用，为半结构化数据提供可扩展、可解释和准确的检索，进而推进计算法学和AI的发展。 <div>
arXiv:2502.20364v1 Announce Type: new 
Abstract: Agentic Generative AI, powered by Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG), Knowledge Graphs (KGs), and Vector Stores (VSs), represents a transformative technology applicable to specialized domains such as legal systems, research, recommender systems, cybersecurity, and global security, including proliferation research. This technology excels at inferring relationships within vast unstructured or semi-structured datasets. The legal domain here comprises complex data characterized by extensive, interrelated, and semi-structured knowledge systems with complex relations. It comprises constitutions, statutes, regulations, and case law. Extracting insights and navigating the intricate networks of legal documents and their relations is crucial for effective legal research. Here, we introduce a generative AI system that integrates RAG, VS, and KG, constructed via Non-Negative Matrix Factorization (NMF), to enhance legal information retrieval and AI reasoning and minimize hallucinations. In the legal system, these technologies empower AI agents to identify and analyze complex connections among cases, statutes, and legal precedents, uncovering hidden relationships and predicting legal trends-challenging tasks that are essential for ensuring justice and improving operational efficiency. Our system employs web scraping techniques to systematically collect legal texts, such as statutes, constitutional provisions, and case law, from publicly accessible platforms like Justia. It bridges the gap between traditional keyword-based searches and contextual understanding by leveraging advanced semantic representations, hierarchical relationships, and latent topic discovery. This framework supports legal document clustering, summarization, and cross-referencing, for scalable, interpretable, and accurate retrieval for semi-structured data while advancing computational law and AI.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Path Planning in Complex Environments using Gaussian Belief Propagation with Global Path Finding</title>
<link>https://arxiv.org/abs/2502.20369</link>
<guid>https://arxiv.org/abs/2502.20369</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体路径规划、高斯信念传播、路径集成、跟踪因子、全球路径规划

总结:
本文主要研究了多智能体路径规划问题，提出了一种结合高斯信念传播与路径集成的新方法，并引入了一个确保严格遵循全局路径的跟踪因子。该方法分别与两种不同的全局路径规划策略——快速探索随机树和利用预定义车道结构进行优化的结构化规划器进行了融合测试。为了验证所提方法的有效性，作者开发了一款模拟环境，用于在各种具有独特导航和通信挑战的场景中进行仿真。实验结果表明，该跟踪因子能使单智能体路径偏差减少28%，多智能体路径偏差减少16%，显著提升了多智能体协调能力，特别是在与结构化全局规划相结合的情况下效果更为明显。 <div>
arXiv:2502.20369v1 Announce Type: new 
Abstract: Multi-agent path planning is a critical challenge in robotics, requiring agents to navigate complex environments while avoiding collisions and optimizing travel efficiency. This work addresses the limitations of existing approaches by combining Gaussian belief propagation with path integration and introducing a novel tracking factor to ensure strict adherence to global paths. The proposed method is tested with two different global path-planning approaches: rapidly exploring random trees and a structured planner, which leverages predefined lane structures to improve coordination. A simulation environment was developed to validate the proposed method across diverse scenarios, each posing unique challenges in navigation and communication. Simulation results demonstrate that the tracking factor reduces path deviation by 28% in single-agent and 16% in multi-agent scenarios, highlighting its effectiveness in improving multi-agent coordination, especially when combined with structured global planning.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Verification: Scaling Test-Time Compute with Multiple Verifiers</title>
<link>https://arxiv.org/abs/2502.20379</link>
<guid>https://arxiv.org/abs/2502.20379</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、测试时间计算资源、多代理验证（MAV）、方面验证器（AVs）、BoN-MAV

总结:

本文提出了一种利用更多测试时间计算资源来提升大规模语言模型性能的新策略。通过引入Multi-Agent Verification (MAV)，即增加验证器的数量作为新的扩展维度，可以在不进行额外训练的情况下改进模型表现。 MAV系统中采用了一种名为Aspect Verifiers (AVs) 的验证器，它们是现成的大规模语言模型，被提示去验证输出的不同方面，可以方便地组合使用而无需额外训练。文章还提出了一个简单的多代理验证算法——BoN-MAV，该算法结合了最佳n采样和多个验证器，展现出比自一致性验证和奖励模型验证更强的扩展性。实验表明，弱验证器的组合可以改善强大的大规模语言模型的表现，并展示出自我改进的能力，即相同的基模型可用于生成和验证输出。这些结果确立了增加验证器数量作为提高语言模型测试阶段性能的一种有前景的新方法。 <div>
arXiv:2502.20379v1 Announce Type: new 
Abstract: By utilizing more computational resources at test-time, large language models (LLMs) can improve without additional training. One common strategy uses verifiers to evaluate candidate outputs. In this work, we propose a novel scaling dimension for test-time compute: scaling the number of verifiers. We introduce Multi-Agent Verification (MAV) as a test-time compute paradigm that combines multiple verifiers to improve performance. We propose using Aspect Verifiers (AVs), off-the-shelf LLMs prompted to verify different aspects of outputs, as one possible choice for the verifiers in a MAV system. AVs are a convenient building block for MAV since they can be easily combined without additional training. Moreover, we introduce BoN-MAV, a simple multi-agent verification algorithm that combines best-of-n sampling with multiple verifiers. BoN-MAV demonstrates stronger scaling patterns than self-consistency and reward model verification, and we demonstrate both weak-to-strong generalization, where combining weak verifiers improves even stronger LLMs, and self-improvement, where the same base model is used to both generate and verify outputs. Our results establish scaling the number of verifiers as a promising new dimension for improving language model performance at test-time.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis</title>
<link>https://arxiv.org/abs/2502.20383</link>
<guid>https://arxiv.org/abs/2502.20383</guid>
<content:encoded><![CDATA[
<div> 关键词：Web AI 代理、大型语言模型 (LLMs)、脆弱性、组件级分析、安全性

<br /><br />总结:
本文探讨了近期Web AI代理在复杂网络导航任务中展现卓越能力的同时，相较于独立的大型语言模型（LLMs）表现出更高的脆弱性。研究发现，这种差异源于Web AI代理与独立LLMs之间的多方面区别以及现有简单评价指标无法全面捕捉的复杂信号。为解决这些问题，文章提出了一种基于组件层面的分析和更细致、系统化的评估框架。通过深入调查，研究人员确定了放大Web AI代理脆弱性的三个关键因素：(1) 用户目标嵌入系统提示；(2) 多步行动生成；(3) 观察能力。这些发现强调了提升AI代理设计的安全性和鲁棒性的紧迫需求，并为制定针对性防御策略提供了可操作的见解。 <div>
arXiv:2502.20383v1 Announce Type: new 
Abstract: Recent advancements in Web AI agents have demonstrated remarkable capabilities in addressing complex web navigation tasks. However, emerging research shows that these agents exhibit greater vulnerability compared to standalone Large Language Models (LLMs), despite both being built upon the same safety-aligned models. This discrepancy is particularly concerning given the greater flexibility of Web AI Agent compared to standalone LLMs, which may expose them to a wider range of adversarial user inputs. To build a scaffold that addresses these concerns, this study investigates the underlying factors that contribute to the increased vulnerability of Web AI agents. Notably, this disparity stems from the multifaceted differences between Web AI agents and standalone LLMs, as well as the complex signals - nuances that simple evaluation metrics, such as success rate, often fail to capture. To tackle these challenges, we propose a component-level analysis and a more granular, systematic evaluation framework. Through this fine-grained investigation, we identify three critical factors that amplify the vulnerability of Web AI agents; (1) embedding user goals into the system prompt, (2) multi-step action generation, and (3) observational capabilities. Our findings highlights the pressing need to enhance security and robustness in AI agent design and provide actionable insights for targeted defense strategies.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Point Policy: Unifying Observations and Actions with Key Points for Robot Manipulation</title>
<link>https://arxiv.org/abs/2502.20391</link>
<guid>https://arxiv.org/abs/2502.20391</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人、离线人类示范视频、无遥操作数据、点策略、政策学习

总结:<br />
本文提出了一种名为“点策略”（Point Policy）的新方法，该方法允许机器人仅通过离线的人类示范视频学习策略，无需任何遥操作数据。点策略利用先进的视觉模型和政策架构，将人类手部姿势转化为机器人姿势，并通过语义上有意义的关键点捕捉物体状态，形成一种与形态无关的表示形式，从而促进有效策略的学习。实验显示，在8项现实世界任务中，点策略相对于先前工作在相同设置下平均绝对改善了75%；对于新对象实例的任务，它表现出74%的进步，并且在存在大量背景杂物的情况下仍保持鲁棒性。相关实验视频可访问https://point-policy.github.io/查看。 <div>
arXiv:2502.20391v1 Announce Type: new 
Abstract: Building robotic agents capable of operating across diverse environments and object types remains a significant challenge, often requiring extensive data collection. This is particularly restrictive in robotics, where each data point must be physically executed in the real world. Consequently, there is a critical need for alternative data sources for robotics and frameworks that enable learning from such data. In this work, we present Point Policy, a new method for learning robot policies exclusively from offline human demonstration videos and without any teleoperation data. Point Policy leverages state-of-the-art vision models and policy architectures to translate human hand poses into robot poses while capturing object states through semantically meaningful key points. This approach yields a morphology-agnostic representation that facilitates effective policy learning. Our experiments on 8 real-world tasks demonstrate an overall 75% absolute improvement over prior works when evaluated in identical settings as training. Further, Point Policy exhibits a 74% gain across tasks for novel object instances and is robust to significant background clutter. Videos of the robot are best viewed at https://point-policy.github.io/.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Advancing calibration for stochastic agent-based models in epidemiology with Stein variational inference and Gaussian process surrogates</title>
<link>https://arxiv.org/abs/2502.19550</link>
<guid>https://arxiv.org/abs/2502.19550</guid>
<content:encoded><![CDATA[
<div> 关键词：stochastic agent-based models (ABMs)，epidemiology，calibration，Stein Variational Inference (SVI)，Markov Chain Monte Carlo (MCMC)

<br /><br />总结:
本文研究了在流行病学领域中，针对高参数化的随机agent-based模型（ABMs）的校准问题。传统的校准方法，如马尔科夫链蒙特卡洛（MCMC），在校准过程中往往计算成本高昂。文章探讨了使用斯坦因变分推断（SVI）作为替代校准技术的可能性，该技术通过梯度信息迭代更新参数空间中的粒子集，从而在处理高维ABM时可能具有可扩展性和效率优势。通过对名为CityCOVID的随机流行病学ABM进行校准并将其与MCMC方法对比，结果显示SVI在校准效果和预测准确性上与MCMC相当，因此证明其可以作为复杂流行病学模型的一种可行替代方案。同时，文中也指出了使用基于梯度的校准方法（如SVI）所面临的实际挑战，包括超参数调整和粒子动态监测等。 <div>
arXiv:2502.19550v1 Announce Type: cross 
Abstract: Accurate calibration of stochastic agent-based models (ABMs) in epidemiology is crucial to make them useful in public health policy decisions and interventions. Traditional calibration methods, e.g., Markov Chain Monte Carlo (MCMC), that yield a probability density function for the parameters being calibrated, are often computationally expensive. When applied to ABMs which are highly parametrized, the calibration process becomes computationally infeasible. This paper investigates the utility of Stein Variational Inference (SVI) as an alternative calibration technique for stochastic epidemiological ABMs approximated by Gaussian process (GP) surrogates. SVI leverages gradient information to iteratively update a set of particles in the space of parameters being calibrated, offering potential advantages in scalability and efficiency for high-dimensional ABMs. The ensemble of particles yields a joint probability density function for the parameters and serves as the calibration. We compare the performance of SVI and MCMC in calibrating CityCOVID, a stochastic epidemiological ABM, focusing on predictive accuracy and calibration effectiveness. Our results demonstrate that SVI maintains predictive accuracy and calibration effectiveness comparable to MCMC, making it a viable alternative for complex epidemiological models. We also present the practical challenges of using a gradient-based calibration such as SVI which include careful tuning of hyperparameters and monitoring of the particle dynamics.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cued to Queue: Information in Waiting-Line Auctions</title>
<link>https://arxiv.org/abs/2502.19553</link>
<guid>https://arxiv.org/abs/2502.19553</guid>
<content:encoded><![CDATA[
<div> 关键词：信息设计、排队、稀缺资源、突然坏消息、总福利

总结:
本文研究了向等待分配固定时间的稀缺商品的代理人提供信息的影响。当代理人的效用是基于等待时间的准线性时，他们会像在降序拍卖中竞标一样选择进入时间。信息设计师可以通过发布有关队列长度的更新来影响他们的行为。文中指出，“突然坏消息”——即代理人得知队列比之前认为的更长的情况，可能会导致匹配效率降低，引发大量代理人同时尝试加入队列。结果表明，对于具有递增（递减）风险率的价值分布，相比不发布任何信息，发布带有突然坏消息的信息政策会增加（减少）总的剩余价值。当代理人面临加入队列的成本并且价值分布具有递减的风险率时，信息设计师通过仅在队列已满时发布公告，可以最大化总福利。 <div>
arXiv:2502.19553v1 Announce Type: cross 
Abstract: We study the effect of providing information to agents who queue before a scarce good is distributed at a fixed time. When agents have quasi-linear utility in time spent waiting, they choose entry times as they would bids in a descending auction. An information designer can influence their behavior by providing updates about the length of the queue. Many natural information policies release "sudden bad news," which occurs when agents learn that the queue is longer than previously believed. We show that sudden bad news can cause assortative inefficiency by prompting a mass of agents to simultaneously attempt to join the queue. As a result, if the value distribution has an increasing (decreasing) hazard rate, information policies that release sudden bad news increase (decrease) total surplus, relative to releasing no information. When agents face entry costs to join the queue and the value distribution has a decreasing hazard rate, an information designer maximizes total surplus by announcing only when the queue is full.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Constrained Serial Dictatorships can be Fair</title>
<link>https://arxiv.org/abs/2301.06086</link>
<guid>https://arxiv.org/abs/2301.06086</guid>
<content:encoded><![CDATA[
<div> 关键词：strategyproof机制、indivisible物品分配、constrained serial dictatorships、优化序列、Plackett-Luce模型

总结:<br />
本文研究了在不可分割物品分配给代理人的策略中，只有满足一定条件的受限连续独裁者机制才是战略上可靠的。文章关注如何平衡序列中的优先级和接收物品的数量这一非 trivial 问题。作者使用了一个参数化模型，该模型基于排名与分数映射、社会福利函数以及偏好配置分布。对于多个有意义的参数选择，他们证明了最优序列可以在多项式时间内精确计算或通过采样进行近似。这些结果适用于多种概率性偏好配置模型，尤其是Plackett-Luce模型。实验结果显示了最优序列是如何受到各种参数影响的。 <div>
arXiv:2301.06086v2 Announce Type: replace 
Abstract: When allocating indivisible items to agents, it is known that the only strategyproof mechanisms that satisfy a set of rather mild conditions are constrained serial dictatorships: given a fixed order over agents, at each step the designated agent chooses a given number of items (depending on her position in the sequence). Agents who come earlier in the sequence have a larger choice of items; however, this advantage can be compensated by a higher number of items received by those who come later. How to balance priority in the sequence and number of items received is a nontrivial question. We use a previous model, parameterized by a mapping from ranks to scores, a social welfare functional, and a distribution over preference profiles. For several meaningful choices of parameters, we show that the optimal sequence can be computed exactly in polynomial time or approximated using sampling. Our results hold for several probabilistic models on preference profiles, with an emphasis on the Plackett-Luce model. We conclude with experimental results showing how the optimal sequence is impacted by various parameters.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Autonomous Guidewire Navigation for Robot-assisted Endovascular Interventions: A Knowledge-Driven Visual Guidance Approach</title>
<link>https://arxiv.org/abs/2403.05748</link>
<guid>https://arxiv.org/abs/2403.05748</guid>
<content:encoded><![CDATA[
<div> 关键词：自主机器人、血管介入、知识驱动视觉引导、BDA-star算法、强化学习

总结:<br />
本文提出了一种名为知识驱动视觉引导（KVG）的方法，用于提升自主机器人在血管介入手术中导丝导航的精度和安全性。该方法结合图像分割和检测技术，从术中影像中提取血管地图和导丝位置信息。文章中还介绍了一种新的路径规划算法——BDA-star，它带有边界距离约束，优化了导丝导航的轨迹规划。为了验证这一方法，研究者开发了一个名为KVD-强化学习的环境，并设计了一个基于导丝尖端与目标点到规划路径距离的奖励函数。为解决直接从原始像素进行学习时的稳定性和收敛速度问题，文中将预训练卷积神经网络整合到了策略网络中进行特征提取。实验结果显示，在模拟主动脉自主导丝导航平台上针对左锁骨下动脉、左颈总动脉及头臂干的导航任务，该方法实现了100%的成功率，并且降低了移动和退缩的距离，使得导丝轨迹更趋于血管中心。 <div>
arXiv:2403.05748v2 Announce Type: replace 
Abstract: Autonomous robots for endovascular interventions hold significant potential to enhance procedural safety and reliability by navigating guidewires with precision, minimizing human error, and reducing surgical time. However, existing methods of guidewire navigation rely on manual demonstration data and have a suboptimal success rate. In this work, we propose a knowledge-driven visual guidance (KVG) method that leverages available visual information from interventional imaging to facilitate guidewire navigation. Our approach integrates image segmentation and detection techniques to extract surgical knowledge, including vascular maps and guidewire positions. We introduce BDA-star, a novel path planning algorithm with boundary distance constraints, to optimize trajectory planning for guidewire navigation. To validate the method, we developed the KVD-Reinforcement Learning environment, where observations consist of real-time guidewire feeding images highlighting the guidewire tip position and the planned path. We proposed a reward function based on the distances from both the guidewire tip to the planned path and the target to evaluate the agent's actions.Additionally, to address stability issues and slow convergence rates associated with direct learning from raw pixels, we incorporated a pre-trained convolutional neural network into the policy network for feature extraction. Experiments conducted on the aortic simulation autonomous guidewire navigation platform demonstrated that the proposed method, targeting the left subclavian artery, left carotid artery and the brachiocephalic artery, achieved a 100\% guidewire navigation success rate, along with reduced movement and retraction distances and trajectories tend to the center of the vessels.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAMBA4D: Efficient Long-Sequence Point Cloud Video Understanding with Disentangled Spatial-Temporal State Space Models</title>
<link>https://arxiv.org/abs/2405.14338</link>
<guid>https://arxiv.org/abs/2405.14338</guid>
<content:encoded><![CDATA[
<div> 关键词：点云视频、4D骨架网络、状态空间模型、Mamba块、效率提升

<br /><br />总结:
本文提出了一种基于状态空间模型（SSMs）的新型点云视频理解骨架网络——Mamba4d。该网络旨在解决点云视频中空间和时间的不规则分布、帧间时空一致性问题以及Transformer基的4D骨架网络计算成本高的挑战。Mamba4d通过使用设计的Mamba块来分离并建立空间与时间的相关性，其中Intra-frame Spatial Mamba模块负责编码具有局部相似几何结构的时间步内的特征，而Inter-frame Temporal Mamba模块则以线性复杂度整合整个视频中的长期点特征。实验结果显示，Mamba4d在MSR-Action3D动作识别任务上精度提高了10.4%，HOI4D动作分割任务F1得分提升了0.7，Synthia4D语义分割任务上mIoU提高了0.19。特别是在处理长视频序列时，该方法在GPU内存占用方面减少了87.5%，运行速度提高了5.36倍。相关代码将在https://github.com/IRMVLab/Mamba4D 发布。 <div>
arXiv:2405.14338v3 Announce Type: replace 
Abstract: Point cloud videos can faithfully capture real-world spatial geometries and temporal dynamics, which are essential for enabling intelligent agents to understand the dynamically changing world. However, designing an effective 4D backbone remains challenging, mainly due to the irregular and unordered distribution of points and temporal inconsistencies across frames. Also, recent transformer-based 4D backbones commonly suffer from large computational costs due to their quadratic complexity, particularly for long video sequences. To address these challenges, we propose a novel point cloud video understanding backbone purely based on the State Space Models (SSMs). Specifically, we first disentangle space and time in 4D video sequences and then establish the spatio-temporal correlation with our designed Mamba blocks. The Intra-frame Spatial Mamba module is developed to encode locally similar geometric structures within a certain temporal stride. Subsequently, locally correlated tokens are delivered to the Inter-frame Temporal Mamba module, which integrates long-term point features across the entire video with linear complexity. Our proposed Mamba4d achieves competitive performance on the MSR-Action3D action recognition (+10.4% accuracy), HOI4D action segmentation (+0.7 F1 Score), and Synthia4D semantic segmentation (+0.19 mIoU) datasets. Especially, for long video sequences, our method has a significant efficiency improvement with 87.5% GPU memory reduction and 5.36 times speed-up. Codes will be released at https://github.com/IRMVLab/Mamba4D.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sports-Traj: A Unified Trajectory Generation Model for Multi-Agent Movement in Sports</title>
<link>https://arxiv.org/abs/2405.17680</link>
<guid>https://arxiv.org/abs/2405.17680</guid>
<content:encoded><![CDATA[
<div> 关键词: Multi-agent movement, Trajectory generation, UniTraj, Ghost Spatial Masking (GSM), Bidirectional Temporal Mamba (BTM)

<br /><br />总结:
本文提出了一种名为UniTraj的统一轨迹生成模型，旨在克服传统方法对多任务处理的局限性以及现有公开数据集中行人运动模式的不代表性。UniTraj能适应体育领域的多样化场景，其核心包括：使用Ghost Spatial Masking (GSM)模块在Transformer编码器中进行空间特征提取；将近期的State Space Models（即Mamba模型）扩展为双向时间Mamba（BTM），以更好地捕捉时间依赖性；并引入双向时间缩放（BTS）模块来全面扫描轨迹并保持时间缺失关系。此外，文章还制定了三个实用体育数据集——Basketball-U、Football-U和Soccer-U用于评估。实验结果证明了UniTraj模型的优越性能。作者期望该工作能推动现实世界应用中人类移动行为的理解，特别是在体育领域。相关数据集、代码和模型权重已开源，可在https://github.com/colorfulfuture/UniTraj-pytorch获取。 <div>
arXiv:2405.17680v2 Announce Type: replace 
Abstract: Understanding multi-agent movement is critical across various fields. The conventional approaches typically focus on separate tasks such as trajectory prediction, imputation, or spatial-temporal recovery. Considering the unique formulation and constraint of each task, most existing methods are tailored for only one, limiting the ability to handle multiple tasks simultaneously, which is a common requirement in real-world scenarios. Another limitation is that widely used public datasets mainly focus on pedestrian movements with casual, loosely connected patterns, where interactions between individuals are not always present, especially at a long distance, making them less representative of more structured environments. To overcome these limitations, we propose a Unified Trajectory Generation model, UniTraj, that processes arbitrary trajectories as masked inputs, adaptable to diverse scenarios in the domain of sports games. Specifically, we introduce a Ghost Spatial Masking (GSM) module, embedded within a Transformer encoder, for spatial feature extraction. We further extend recent State Space Models (SSMs), known as the Mamba model, into a Bidirectional Temporal Mamba (BTM) to better capture temporal dependencies. Additionally, we incorporate a Bidirectional Temporal Scaled (BTS) module to thoroughly scan trajectories while preserving temporal missing relationships. Furthermore, we curate and benchmark three practical sports datasets, Basketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments demonstrate the superior performance of our model. We hope that our work can advance the understanding of human movement in real-world applications, particularly in sports. Our datasets, code, and model weights are available here https://github.com/colorfulfuture/UniTraj-pytorch.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MMFakeBench: A Mixed-Source Multimodal Misinformation Detection Benchmark for LVLMs</title>
<link>https://arxiv.org/abs/2406.08772</link>
<guid>https://arxiv.org/abs/2406.08772</guid>
<content:encoded><![CDATA[
<div> 关键词：多模态错误检测、混合源、MMFakeBench、大模型、MMD-Agent

<br /><br />总结:
本文提出了首个全面的混合源多模态错误检测基准——MMFakeBench，该基准涵盖了文本真实性扭曲、视觉真实性扭曲和跨模态一致性扭曲等三个关键来源及12种子类别的错误伪造类型。文章对六种常见检测方法和15种大型视觉-语言模型在MMFakeBench上进行了零样本设置下的广泛评估，结果显示现有方法在此挑战性的真实混合源多模态错误检测场景下表现挣扎。为了解决这一问题，作者提出了MMD-Agent，这是一种结合了大型视觉-语言模型代理的推理、行为和工具使用能力的新方法，显著提高了准确性和泛化性能。研究人员认为此项工作将推动未来对于更真实世界场景中混合源多模态错误检测的研究，并为误信息检测方法提供公正的评价标准。 <div>
arXiv:2406.08772v3 Announce Type: replace 
Abstract: Current multimodal misinformation detection (MMD) methods often assume a single source and type of forgery for each sample, which is insufficient for real-world scenarios where multiple forgery sources coexist. The lack of a benchmark for mixed-source misinformation has hindered progress in this field. To address this, we introduce MMFakeBench, the first comprehensive benchmark for mixed-source MMD. MMFakeBench includes 3 critical sources: textual veracity distortion, visual veracity distortion, and cross-modal consistency distortion, along with 12 sub-categories of misinformation forgery types. We further conduct an extensive evaluation of 6 prevalent detection methods and 15 Large Vision-Language Models (LVLMs) on MMFakeBench under a zero-shot setting. The results indicate that current methods struggle under this challenging and realistic mixed-source MMD setting. Additionally, we propose MMD-Agent, a novel approach to integrate the reasoning, action, and tool-use capabilities of LVLM agents, significantly enhancing accuracy and generalization. We believe this study will catalyze future research into more realistic mixed-source multimodal misinformation and provide a fair evaluation of misinformation detection methods.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Soft-QMIX: Integrating Maximum Entropy For Monotonic Value Function Factorization</title>
<link>https://arxiv.org/abs/2406.13930</link>
<guid>https://arxiv.org/abs/2406.13930</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习(MARL), 中心化训练分布式执行(CTDE), QMIX, 最大熵强化学习, 局部Q值学习

总结:
本文提出了一种改进QMIX的方法，针对多智能体强化学习（MARL）任务中QMIX在探索策略上的不足。文章指出QMIX的信用分配方法与最大熵强化学习的目标以及分布式执行要求存在冲突。为此，研究者在最大熵RL框架下，通过引入额外的局部Q值学习方法来增强QMIX。该方法约束局部Q值估计以保持所有动作的正确排序，确保局部最优动作与全局最优动作对齐。理论证明了该方法具有单调改进和收敛至最优解的性质。实验结果表明，新算法在矩阵游戏、Multi-Agent Particle Environment及SMAC-v2等环境中表现出优越的性能。 <div>
arXiv:2406.13930v2 Announce Type: replace 
Abstract: Multi-agent reinforcement learning (MARL) tasks often utilize a centralized training with decentralized execution (CTDE) framework. QMIX is a successful CTDE method that learns a credit assignment function to derive local value functions from a global value function, defining a deterministic local policy. However, QMIX is hindered by its poor exploration strategy. While maximum entropy reinforcement learning (RL) promotes better exploration through stochastic policies, QMIX's process of credit assignment conflicts with the maximum entropy objective and the decentralized execution requirement, making it unsuitable for maximum entropy RL. In this paper, we propose an enhancement to QMIX by incorporating an additional local Q-value learning method within the maximum entropy RL framework. Our approach constrains the local Q-value estimates to maintain the correct ordering of all actions. Due to the monotonicity of the QMIX value function, these updates ensure that locally optimal actions align with globally optimal actions. We theoretically prove the monotonic improvement and convergence of our method to an optimal solution. Experimentally, we validate our algorithm in matrix games, Multi-Agent Particle Environment and demonstrate state-of-the-art performance in SMAC-v2.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MetaDesigner: Advancing Artistic Typography Through AI-Driven, User-Centric, and Multilingual WordArt Synthesis</title>
<link>https://arxiv.org/abs/2406.19859</link>
<guid>https://arxiv.org/abs/2406.19859</guid>
<content:encoded><![CDATA[
<div> 关键词: MetaDesigner、艺术字体合成、大型语言模型、多智能体系统、反馈机制

<br />
总结:
MetaDesigner是一个基于大型语言模型的艺术字体综合框架，它采用了以用户为中心的设计理念。该框架构建了一个由Pipeline、Glyph和Texture代理组成的多智能体系统，协同生成可定制化的WordArt，涵盖了从语义增强到复杂的纹理元素设计。通过一个中心反馈机制，结合多模态模型的见解与用户的评价，实现了设计参数的迭代优化，动态调整超参数以符合用户定义的风格和主题偏好。实证评估凸显了MetaDesigner在各种WordArt应用中的多样性和有效性，生成既具有审美吸引力又具备情境敏感性的高质量作品。 <div>
arXiv:2406.19859v4 Announce Type: replace 
Abstract: MetaDesigner introduces a transformative framework for artistic typography synthesis, powered by Large Language Models (LLMs) and grounded in a user-centric design paradigm. Its foundation is a multi-agent system comprising the Pipeline, Glyph, and Texture agents, which collectively orchestrate the creation of customizable WordArt, ranging from semantic enhancements to intricate textural elements. A central feedback mechanism leverages insights from both multimodal models and user evaluations, enabling iterative refinement of design parameters. Through this iterative process, MetaDesigner dynamically adjusts hyperparameters to align with user-defined stylistic and thematic preferences, consistently delivering WordArt that excels in visual quality and contextual resonance. Empirical evaluations underscore the system's versatility and effectiveness across diverse WordArt applications, yielding outputs that are both aesthetically compelling and context-sensitive.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>InsightBench: Evaluating Business Analytics Agents Through Multi-Step Insight Generation</title>
<link>https://arxiv.org/abs/2407.06423</link>
<guid>https://arxiv.org/abs/2407.06423</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据分析、InsightBench、基准数据集、AgentPoirot、LLaMA-3

总结:
本文介绍了InsightBench，这是一个用于全面评估数据解析能力的新型基准数据集，具有三个主要特点：1) 包含100个代表各种业务场景（如金融和事件管理）的精心策划的数据集，每个数据集都预置了相关的有价值洞察；2) 与仅关注单一查询回答的现有基准不同，InsightBench侧重于评测代理执行端到端数据分析的能力，包括提问、解读答案以及生成洞察摘要和行动建议；3) 对每项数据进行了严格的质量保证，确保其目标明确、问题和分析内容相关且有意义。此外，使用开源评估器LLaMA-3实现了一种双评价机制，并提出了作为基线数据分析代理的AgentPoirot，该代理能够执行完整的数据分析任务。实验结果显示，AgentPoirot在InsightBench上的表现优于专注于单个查询解答的现有方法（如Pandas Agent）。文章还对比了开放源代码和闭源大语言模型以及多种评估策略的表现。总的来说，InsightBench作为一个推动全面自动化数据分析领域进一步发展的测试平台，可通过如下链接访问：https://github.com/ServiceNow/insight-bench。 <div>
arXiv:2407.06423v4 Announce Type: replace 
Abstract: Data analytics is essential for extracting valuable insights from data that can assist organizations in making effective decisions. We introduce InsightBench, a benchmark dataset with three key features. First, it consists of 100 datasets representing diverse business use cases such as finance and incident management, each accompanied by a carefully curated set of insights planted in the datasets. Second, unlike existing benchmarks focusing on answering single queries, InsightBench evaluates agents based on their ability to perform end-to-end data analytics, including formulating questions, interpreting answers, and generating a summary of insights and actionable steps. Third, we conducted comprehensive quality assurance to ensure that each dataset in the benchmark had clear goals and included relevant and meaningful questions and analysis. Furthermore, we implement a two-way evaluation mechanism using LLaMA-3 as an effective, open-source evaluator to assess agents' ability to extract insights. We also propose AgentPoirot, our baseline data analysis agent capable of performing end-to-end data analytics. Our evaluation on InsightBench shows that AgentPoirot outperforms existing approaches (such as Pandas Agent) that focus on resolving single queries. We also compare the performance of open- and closed-source LLMs and various evaluation strategies. Overall, this benchmark serves as a testbed to motivate further development in comprehensive automated data analytics and can be accessed here: https://github.com/ServiceNow/insight-bench.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Repeated and incontrovertible collective action failure leads to protester disengagement and radicalisation</title>
<link>https://arxiv.org/abs/2408.12795</link>
<guid>https://arxiv.org/abs/2408.12795</guid>
<content:encoded><![CDATA[
<div> 关键词：抗议、社会变革、代理模型、集体行动、革命

总结:
本文研究了21世纪抗议活动的普遍性以及推动社会变革的过程。为了解析这一复杂动态过程中的关键条件，作者提出了一种新的理论驱动并经实证支持的agent-based模型，用于模拟集体行动。通过模拟约10,000次迭代的虚拟社会，研究表明，当权威机构对运动诉求有所响应，且抗议者能够认知或社交上质疑运动失败时，温和的常规运动将会持续存在。然而，当权威机构反复、明显地未能回应运动需求时，人群会失去参与热情但转而激进化（潜伏的激进主义），这可能是引发突然、革命性变化前夕的社会状态。该研究结果强调了模拟方法在揭示新兴、尚未充分理论化的现象方面的潜力。 <div>
arXiv:2408.12795v2 Announce Type: replace 
Abstract: Protest is ubiquitous in the 21st Century and the people who participate in such movements do so because they seek to bring about social change. However, social change takes time and involves repeated interactions between individual protesters, social movements and the authorities to whom they appeal for change. These complexities of time and scale have frustrated efforts to isolate the conditions that foster an enduring movement, on the one hand, and the adoption of more radical (unconventional, unacceptable) tactics on the other. Here, we present a novel, theoretically informed and empirically evidenced, agent-based model of collective action that provides a unified framework to address these dual challenges. We model ~10,000 iterations within a simulated society and show that where an authority is responsive, and protesters can (cognitively and/or socially) contest the failure of their movement, a moderate conventional movement prevails. Conversely, where an authority repeatedly and incontrovertibly fails the movement, the population disengages but becomes radicalised (latent radicalism). This latter finding, whereby the whole population is disengaged but prepared to use radical methods to bring about social change, likely reflects the febrile pre-cursor state to sudden, revolutionary change. Results highlight the potential for simulations to reveal emergent, as-yet under-theorized, phenomena.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentSquare: Automatic LLM Agent Search in Modular Design Space</title>
<link>https://arxiv.org/abs/2410.06153</link>
<guid>https://arxiv.org/abs/2410.06153</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 模块化设计空间, AgentSquare, 模块进化, 性能预测器

总结:
本文提出了一种针对大型语言模型(LLMs)代理系统的新研究问题——模块化LLM代理搜索(MoLAS)。为解决此问题，文章引入了一个由规划、推理、工具使用和记忆四个基本模块组成的模块化设计空间，并具有统一的输入/输出接口。基于这个设计空间，作者提出了名为AgentSquare的LLM代理搜索框架，该框架包含了模块演化和重组两个核心机制，用于高效搜索优化的LLM代理。此外，为了加速搜索过程，文中还设计了一个利用上下文代理模型进行性能预测的工具，以跳过无潜力的设计方案。实验结果显示，AgentSquare在涵盖网络、具象、工具使用及游戏应用等六个基准测试中，大幅超越手工设计的代理，平均性能提升达17.2%，相较于最优人类设计。AgentSquare还能生成可解释的设计洞察，有助于深入理解代理架构及其对任务性能的影响。通过模块化设计空间和AgentSquare搜索框架，研究者可以更好地挖掘并整合既往成功设计的潜力，凝聚研究社区的集体力量。相关代码已发布于https://github.com/tsinghua-fib-lab/AgentSquare。 <div>
arXiv:2410.06153v3 Announce Type: replace 
Abstract: Recent advancements in Large Language Models (LLMs) have led to a rapid growth of agentic systems capable of handling a wide range of complex tasks. However, current research largely relies on manual, task-specific design, limiting their adaptability to novel tasks. In this paper, we introduce a new research problem: Modularized LLM Agent Search (MoLAS). We propose a modular design space that abstracts existing LLM agent designs into four fundamental modules with uniform IO interface: Planning, Reasoning, Tool Use, and Memory. Building on this design space, we present a novel LLM agent search framework called AgentSquare, which introduces two core mechanisms, i.e., module evolution and recombination, to efficiently search for optimized LLM agents. To further accelerate the process, we design a performance predictor that uses in-context surrogate models to skip unpromising agent designs. Extensive experiments across six benchmarks, covering the diverse scenarios of web, embodied, tool use and game applications, show that AgentSquare substantially outperforms hand-crafted agents, achieving an average performance gain of 17.2% against best-known human designs. Moreover, AgentSquare can generate interpretable design insights, enabling a deeper understanding of agentic architecture and its impact on task performance. We believe that the modular design space and AgentSquare search framework offer a platform for fully exploiting the potential of prior successful designs and consolidating the collective efforts of research community. Code repo is available at https://github.com/tsinghua-fib-lab/AgentSquare.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Strategic Classification With Externalities</title>
<link>https://arxiv.org/abs/2410.08032</link>
<guid>https://arxiv.org/abs/2410.08032</guid>
<content:encoded><![CDATA[
<div> 关键词: strategic classification, inter-agent externalities, Stackelberg game, Nash Equilibrium, PAC learning

<br /><br />总结:
本文提出了一种战略分类问题的新变体，其中主体公布一个分类器，n个代理报告他们（可能是操纵过的）特征以供分类。该模型允许一个代理的操纵影响到其他代理，即显式地捕捉了代理间的外部性。将主体-代理交互形式化为Stackelberg博弈，并将由此产生的代理操纵动态视为同时博弈。在某些假设下，文章证明了这个代理操纵游戏的纯纳什均衡是唯一的，并可以被有效计算出来。利用这一结果，建立了学习者的学习保证：即在随机数量的代理人操纵至纯纳什均衡的情况下，也能学习到最小化分布上损失的分类器。此外，文中还讨论了通过梯度方法优化此类分类器的可能性。这项工作为分析在公共环境中多个具有战略行为的演员互动下的鲁棒分类器奠定了理论基础。 <div>
arXiv:2410.08032v2 Announce Type: replace 
Abstract: We propose a new variant of the strategic classification problem: a principal reveals a classifier, and $n$ agents report their (possibly manipulated) features to be classified. Motivated by real-world applications, our model crucially allows the manipulation of one agent to affect another; that is, it explicitly captures inter-agent externalities. The principal-agent interactions are formally modeled as a Stackelberg game, with the resulting agent manipulation dynamics captured as a simultaneous game. We show that under certain assumptions, the pure Nash Equilibrium of this agent manipulation game is unique and can be efficiently computed. Leveraging this result, PAC learning guarantees are established for the learner: informally, we show that it is possible to learn classifiers that minimize loss on the distribution, even when a random number of agents are manipulating their way to a pure Nash Equilibrium. We also comment on the optimization of such classifiers through gradient-based approaches. This work sets the theoretical foundations for a more realistic analysis of classifiers that are robust against multiple strategic actors interacting in a common environment.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SmartPretrain: Model-Agnostic and Dataset-Agnostic Representation Learning for Motion Prediction</title>
<link>https://arxiv.org/abs/2410.08669</link>
<guid>https://arxiv.org/abs/2410.08669</guid>
<content:encoded><![CDATA[
<div> 关键词：自动驾驶、运动预测、大规模数据集、自监督学习、SmartPretrain<br /><br />总结:
本文提出了一个针对自动驾驶车辆运动预测的通用、可扩展的自监督学习框架——SmartPretrain。该框架旨在解决当前运动预测模型因大型驾驶数据稀缺而导致的鲁棒性和泛化性不足的问题。SmartPretrain结合对比学习和重建学习，能够在不拘泥于特定模型架构和单一数据集的情况下，有效地表征空间时间演化和交互关系。此外，它采用了一个数据集无关的情景采样策略，整合多个数据集以增强数据量、多样性和鲁棒性。实验结果显示，SmartPretrain在多个数据集上显著提升了现有最优预测模型的性能，例如将Forecast-MAE的MissRate降低了10.6%。这表明SmartPretrain作为一个统一、可扩展的解决方案对于运动预测具有很高的有效性，能够突破小样本数据的局限性。相关代码已在GitHub上发布。 <div>
arXiv:2410.08669v2 Announce Type: replace 
Abstract: Predicting the future motion of surrounding agents is essential for autonomous vehicles (AVs) to operate safely in dynamic, human-robot-mixed environments. However, the scarcity of large-scale driving datasets has hindered the development of robust and generalizable motion prediction models, limiting their ability to capture complex interactions and road geometries. Inspired by recent advances in natural language processing (NLP) and computer vision (CV), self-supervised learning (SSL) has gained significant attention in the motion prediction community for learning rich and transferable scene representations. Nonetheless, existing pre-training methods for motion prediction have largely focused on specific model architectures and single dataset, limiting their scalability and generalizability. To address these challenges, we propose SmartPretrain, a general and scalable SSL framework for motion prediction that is both model-agnostic and dataset-agnostic. Our approach integrates contrastive and reconstructive SSL, leveraging the strengths of both generative and discriminative paradigms to effectively represent spatiotemporal evolution and interactions without imposing architectural constraints. Additionally, SmartPretrain employs a dataset-agnostic scenario sampling strategy that integrates multiple datasets, enhancing data volume, diversity, and robustness. Extensive experiments on multiple datasets demonstrate that SmartPretrain consistently improves the performance of state-of-the-art prediction models across datasets, data splits and main metrics. For instance, SmartPretrain significantly reduces the MissRate of Forecast-MAE by 10.6%. These results highlight SmartPretrain's effectiveness as a unified, scalable solution for motion prediction, breaking free from the limitations of the small-data regime. Codes are available at https://github.com/youngzhou1999/SmartPretrain
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Asymptotic Analysis of Sample-averaged Q-learning</title>
<link>https://arxiv.org/abs/2410.10737</link>
<guid>https://arxiv.org/abs/2410.10737</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习 (Reinforcement Learning)，统计推断，样本均值Q学习 (Sample-Averaged Q-Learning，SA-QL)，功能性中心极限定理 (Functional Central Limit Theorem，FCLT)，批量调度

总结:

本文介绍了强化学习中的一个重要发展——样本均值Q学习（SA-QL），这是一种扩展了传统单样本Q学习的方法，通过聚合奖励和下一状态的样本来更好地考虑数据变异性与不确定性。文章利用功能性中心极限定理（FCLT）建立了一个新的框架，证明了在温和条件下SA-QL算法的渐近正态性。同时，文中提出了一种随机缩放方法，用于构建无需额外超参数的置信区间。实验部分通过一系列经典的OpenAI Gym环境（如多风网格世界、滑冰冻湖等）展示了不同批量调度策略对学习效率、覆盖率以及置信区间宽度的影响。该工作为样本均值Q学习建立了一个统一的理论基础，并提供了关于强化学习算法中有效批量调度和统计推断的见解。 <div>
arXiv:2410.10737v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) has emerged as a key approach for training agents in complex and uncertain environments. Incorporating statistical inference in RL algorithms is essential for understanding and managing uncertainty in model performance. This paper introduces a generalized framework for time-varying batch-averaged Q-learning, termed sample-averaged Q-learning (SA-QL), which extends traditional single-sample Q-learning by aggregating samples of rewards and next states to better account for data variability and uncertainty. We leverage the functional central limit theorem (FCLT) to establish a novel framework that provides insights into the asymptotic normality of the sample-averaged algorithm under mild conditions. Additionally, we develop a random scaling method for interval estimation, enabling the construction of confidence intervals without requiring extra hyperparameters. Extensive numerical experiments across classic stochastic OpenAI Gym environments, including windy gridworld and slippery frozenlake, demonstrate how different batch scheduling strategies affect learning efficiency, coverage rates, and confidence interval widths. This work establishes a unified theoretical foundation for sample-averaged Q-learning, providing insights into effective batch scheduling and statistical inference for RL algorithms.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Graph Neural Networks and Multi-Agent Reinforcement Learning for Inventory Control in Supply Chains</title>
<link>https://arxiv.org/abs/2410.18631</link>
<guid>https://arxiv.org/abs/2410.18631</guid>
<content:encoded><![CDATA[
<div> 关键词：Multi-Agent Reinforcement Learning (MARL)，Graph Neural Networks (GNNs)，Inventory control，Supply chains，Centralized learning, decentralized execution

总结:

本文提出了一种结合多智能体强化学习(MARL)和图神经网络(GNNs)的库存控制框架，用于现代供应链管理。该框架通过参数化启发式库存控制策略重新定义了行动空间，使其能根据系统条件动态调整适应变化环境。利用供应链的内在图结构，使各智能体能够学习系统拓扑，并采用集中式学习、分布式执行的方式，使得智能体可以在克服信息共享约束的情况下协同学习。此外，还引入了全局平均池化和正则化技术以提升性能。通过在四种不同的供应链配置上进行测试及敏感性分析，证实了所提方法对于复杂、分散的供应链环境中改进库存管理的有效性。 <div>
arXiv:2410.18631v2 Announce Type: replace 
Abstract: Inventory control in modern supply chains has attracted significant attention due to the increasing number of disruptive shocks and the challenges posed by complex dynamics, uncertainties, and limited collaboration. Traditional methods, which often rely on static parameters, struggle to adapt to changing environments. This paper proposes a Multi-Agent Reinforcement Learning (MARL) framework with Graph Neural Networks (GNNs) for state representation to address these limitations.
  Our approach redefines the action space by parameterizing heuristic inventory control policies, making it adaptive as the parameters dynamically adjust based on system conditions. By leveraging the inherent graph structure of supply chains, our framework enables agents to learn the system's topology, and we employ a centralized learning, decentralized execution scheme that allows agents to learn collaboratively while overcoming information-sharing constraints. Additionally, we incorporate global mean pooling and regularization techniques to enhance performance.
  We test the capabilities of our proposed approach on four different supply chain configurations and conduct a sensitivity analysis. This work paves the way for utilizing MARL-GNN frameworks to improve inventory management in complex, decentralized supply chain environments.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MALT: Improving Reasoning with Multi-Agent LLM Training</title>
<link>https://arxiv.org/abs/2412.01928</link>
<guid>https://arxiv.org/abs/2412.01928</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)，多智能体 LLM 训练 (MALT)，推理过程，序列化管道，性能提升

总结:
本文介绍了一种针对大型语言模型 (LLMs) 的新型后训练策略——MALT（多智能体 LLM 训练），该策略通过将推理过程划分为生成、验证和细化步骤，采用异质智能体的序列化管道来执行。在数据生成阶段，各智能体被反复采样构建一个多智能体搜索树，最终输出依据地面真实数据进行评分。随后，运用价值迭代方法反向传播奖励信号至每个角色条件化的模型，无需人类或教师模型监督自动生成多智能体后训练数据。这种离策略方法使得每个智能体能够根据正确与错误轨迹进行专业化学习，从而改进整个推理链的端到端性能。实验结果显示，MALT 在 MATH、GSM8K 和 CSQA 数据集上分别超越了同等基线 LLM 模型，相对提升比例分别为 15.66%、7.42% 和 9.40%，标志着多智能体协同训练的重要进展。<br /><br /> <div>
arXiv:2412.01928v2 Announce Type: replace 
Abstract: Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks. In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents. During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data. We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision. Our off-policy approach allows each agent to specialize by learning from correct and incorrect trajectories, ultimately improving the end-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>DSRC: Learning Density-insensitive and Semantic-aware Collaborative Representation against Corruptions</title>
<link>https://arxiv.org/abs/2412.10739</link>
<guid>https://arxiv.org/abs/2412.10739</guid>
<content:encoded><![CDATA[
<div> 关键词: V2X通信，多代理协同感知，鲁棒性，基准测试，DSRC

总结:
本文提出了首个针对现实世界复杂环境下的自然干扰对多代理协同感知方法稳健性进行全面评估的综合基准。为增强协同感知的鲁棒性，文章提出了一种名为DSRC的方法，该方法旨在学习对抗干扰的密度不敏感和语义感知的协同表示。DSRC包括两个关键设计：一是语义引导的稀疏到密集蒸馏框架，通过利用真实边界框构建的多视角稠密物体来有效学习上述表示；二是特征到点云重建方法，以更好地融合来自不同代理的关键协同表示。为了全面评估DSRC，作者在真实世界和模拟数据集上进行了大量实验，结果显示，DSRC在清洁条件和受干扰条件下均优于现有的协同感知方法。相关代码已开源，可在https://github.com/Terry9a/DSRC获取。 <div>
arXiv:2412.10739v2 Announce Type: replace 
Abstract: As a potential application of Vehicle-to-Everything (V2X) communication, multi-agent collaborative perception has achieved significant success in 3D object detection. While these methods have demonstrated impressive results on standard benchmarks, the robustness of such approaches in the face of complex real-world environments requires additional verification. To bridge this gap, we introduce the first comprehensive benchmark designed to evaluate the robustness of collaborative perception methods in the presence of natural corruptions typical of real-world environments. Furthermore, we propose DSRC, a robustness-enhanced collaborative perception method aiming to learn Density-insensitive and Semantic-aware collaborative Representation against Corruptions. DSRC consists of two key designs: i) a semantic-guided sparse-to-dense distillation framework, which constructs multi-view dense objects painted by ground truth bounding boxes to effectively learn density-insensitive and semantic-aware collaborative representation; ii) a feature-to-point cloud reconstruction approach to better fuse critical collaborative representation across agents. To thoroughly evaluate DSRC, we conduct extensive experiments on real-world and simulated datasets. The results demonstrate that our method outperforms SOTA collaborative perception methods in both clean and corrupted conditions. Code is available at https://github.com/Terry9a/DSRC.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SDPO: Segment-Level Direct Preference Optimization for Social Agents</title>
<link>https://arxiv.org/abs/2501.01821</link>
<guid>https://arxiv.org/abs/2501.01821</guid>
<content:encoded><![CDATA[
<div> 关键词: arXiv:2501.01821v2, 社交代理人, 大规模语言模型, 直接偏好优化(DPO), 多轮对话

总结:
本文提出了一个针对大规模语言模型驱动的社交代理人的新方法——段落级直接偏好优化(SDPO)，用于改进多轮社会对话处理能力。现有的直接偏好优化方法主要关注单一回合，而SDPO则通过动态选择交互中的关键片段来优化多轮代理行为，降低了训练噪声并具有坚实的理论基础。相较于现有DPO方法和如GPT-4o等专有LLM，经SDPO调整后的代理人在SOTOPIA基准测试中表现出色，显示出提升LLM社交智能的巨大潜力。研究代码和数据已在https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO上公开发布。 <div>
arXiv:2501.01821v2 Announce Type: replace 
Abstract: Social agents powered by large language models (LLMs) can simulate human social behaviors but fall short in handling complex social dialogues. Direct Preference Optimization (DPO) has proven effective in aligning LLM behavior with human preferences across various agent tasks. However, standard DPO focuses solely on individual turns, which limits its effectiveness in multi-turn social interactions. Several DPO-based multi-turn alignment methods with session-level data have shown potential in addressing this problem.While these methods consider multiple turns across entire sessions, they are often overly coarse-grained, introducing training noise, and lack robust theoretical support. To resolve these limitations, we propose Segment-Level Direct Preference Optimization (SDPO), which dynamically select key segments within interactions to optimize multi-turn agent behavior. SDPO minimizes training noise and is grounded in a rigorous theoretical framework. Evaluations on the SOTOPIA benchmark demonstrate that SDPO-tuned agents consistently outperform both existing DPO-based methods and proprietary LLMs like GPT-4o, underscoring SDPO's potential to advance the social intelligence of LLM-based agents. We release our code and data at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/SDPO.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gaming on Coincident Peak Shaving: Equilibrium and Strategic Behavior</title>
<link>https://arxiv.org/abs/2501.02792</link>
<guid>https://arxiv.org/abs/2501.02792</guid>
<content:encoded><![CDATA[
<div> 关键词：电力系统、峰谷电价、游戏理论、纳什均衡、消费者行为

总结:
本文分析了电力系统中采用峰谷电价策略（即巧合峰值削峰）如何影响消费者的用电行为以及整体系统的效率。通过运用游戏理论，研究发现该削峰游戏可能呈现出凹形、带有间断点的准凹形或非凹形并带有间断点的状态，这取决于消费者的负荷转移能力。文章在一个双主体、两时期的框架下推导出了各场景下的闭合形式纳什均衡解，并将分析扩展到多主体设置。证明了这些均衡点的稳定性，并提出了一种计算所有游戏配置下的均衡结果的算法。进一步地，研究表明去中心化的游戏模型虽然能达到与集中式方法相当的削峰效果，但会以增加无政府状态为代价。在具有准凹性和非凹性条件的场景中，随着消费者灵活性增大和边际转移成本差异加大，无政府状态也会随之增长；此外还探讨了主体数量对系统效率的影响。最后，通过数值模拟验证了理论成果。 <div>
arXiv:2501.02792v4 Announce Type: replace 
Abstract: Power system operators and electric utility companies often charge consumers a peak demand charge when the aggregate system demand reaches its maximum, a practice known as coincident peak shaving. These charges incentivize consumers to reduce usage during critical periods, alleviating stress on electricity transmission and distribution systems, while also helping to recover the grid investment costs. In this paper, we analyze the problem through the lens of game theory, developing a model that captures how strategic consumer behavior influences overall system efficiency. Our results reveal that the coincident peak shaving game can be concave, quasiconcave with discontinuities, or non-concave with discontinuities, depending on the extent of consumers' demand-shifting capabilities. In a two-agent, two-period framework, we derive closed-form Nash equilibrium solutions for each scenario and extend our analysis to multi-agent settings. We prove the stability of these equilibrium points and propose an algorithm to compute equilibrium outcomes across all game configurations. Furthermore, we show that while the decentralized game model achieves peak-shaving performance comparable to a centralized approach, it does so at the cost of increased anarchy. In scenarios characterized by quasi-concave and non-concave conditions, our analytical results demonstrate that anarchy grows with greater consumer flexibility and disparities in marginal shifting costs, and we explore how the number of agents affects system efficiency. Finally, numerical simulations are provided to validate our theoretical findings.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Building reliable sim driving agents by scaling self-play</title>
<link>https://arxiv.org/abs/2502.14706</link>
<guid>https://arxiv.org/abs/2502.14706</guid>
<content:encoded><![CDATA[
<div> 关键词: simulation agents, autonomous vehicles, reliability, self-play, Waymo Open Motion Dataset

<br />
总结:
本文提出了一种构建可靠模拟代理的方法，这些代理对于设计和测试与人类交互的系统（如自动驾驶汽车）至关重要。为确保可靠性，模拟代理需按预期行为运行并避免可能导致不良后果的行为，例如碰撞。研究团队建议通过大规模自我对弈的方式，在Waymo开放运动数据集上并在限制人类感知和控制的半现实情况下训练模拟代理。结果表明，仅使用单块GPU从头开始训练，代理能在一天内几乎解决全部训练集问题。它们在未见过的测试场景中表现出有效的一般性，完成目标率高达99.8%，同时在10,000个保留场景中的碰撞和偏离道路事件占比不到0.8%。此外，这些代理还展示了对分布外场景的部分鲁棒性，并可在几分钟内微调至接近完美的性能。研究团队开源了预训练好的代理模型，并将其与批量多智能体模拟器集成。模拟代理行为的演示可以在提供的链接中查看。 <div>
arXiv:2502.14706v2 Announce Type: replace 
Abstract: Simulation agents are essential for designing and testing systems that interact with humans, such as autonomous vehicles (AVs). These agents serve various purposes, from benchmarking AV performance to stress-testing system limits, but all applications share one key requirement: reliability. To enable systematic experimentation, a simulation agent must behave as intended. It should minimize actions that may lead to undesired outcomes, such as collisions, which can distort the signal-to-noise ratio in analyses. As a foundation for reliable sim agents, we propose scaling self-play to thousands of scenarios on the Waymo Open Motion Dataset under semi-realistic limits on human perception and control. Training from scratch on a single GPU, our agents nearly solve the full training set within a day. They generalize effectively to unseen test scenes, achieving a 99.8% goal completion rate with less than 0.8% combined collision and off-road incidents across 10,000 held-out scenarios. Beyond in-distribution generalization, our agents show partial robustness to out-of-distribution scenes and can be fine-tuned in minutes to reach near-perfect performance in those cases. We open-source the pre-trained agents and integrate them with a batched multi-agent simulator. Demonstrations of agent behaviors can be found at https://sites.google.com/view/reliable-sim-agents.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On Conformal Isometry of Grid Cells: Learning Distance-Preserving Position Embedding</title>
<link>https://arxiv.org/abs/2405.16865</link>
<guid>https://arxiv.org/abs/2405.16865</guid>
<content:encoded><![CDATA[
<div> 关键词: conformal isometry hypothesis, grid cell, neural space, distance preservation, hexagonal pattern

总结:
本文探讨了共形等距假设作为解释网格细胞响应图中六边形周期模式的可能性。文章提出，网格细胞活动形成一个高维向量，编码了Agent在二维物理空间的位置。当Agent移动时，这个向量在神经空间中的二维流形上旋转，由递归神经网络驱动。共形等距假设认为，该神经流形是一个将二维物理空间共形等距嵌入的结果，其中局部物理距离在嵌入过程中被保留在一个缩放因子（或度量单位）之内。这种保持距离的定位嵌入对于导航中的路径规划至关重要，特别是在规划局部直线路径段时。通过数值实验，作者展示了这一假设会导致学习到的最大程度保持距离的定位嵌入产生六边形网格放电模式，并且对模型的选择不敏感。此外，文中还提供了理论解释，阐明为什么通过最小化损失函数可以出现六边形周期模式，因为六边形平面对角线是最具保距性的。 <div>
arXiv:2405.16865v4 Announce Type: replace-cross 
Abstract: This paper investigates the conformal isometry hypothesis as a potential explanation for the hexagonal periodic patterns in grid cell response maps. We posit that grid cell activities form a high-dimensional vector in neural space, encoding the agent's position in 2D physical space. As the agent moves, this vector rotates within a 2D manifold in the neural space, driven by a recurrent neural network. The conformal hypothesis proposes that this neural manifold is a conformal isometric embedding of 2D physical space, where local physical distance is preserved by the embedding up to a scaling factor (or unit of metric). Such distance-preserving position embedding is indispensable for path planning in navigation, especially planning local straight path segments. We conduct numerical experiments to show that this hypothesis leads to the hexagonal grid firing patterns by learning maximally distance-preserving position embedding, agnostic to the choice of the recurrent neural network. Furthermore, we present a theoretical explanation of why hexagon periodic patterns emerge by minimizing our loss function by showing that hexagon flat torus is maximally distance preserving.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Empirical Research on Utilizing LLM-based Agents for Automated Bug Fixing via LangGraph</title>
<link>https://arxiv.org/abs/2502.18465</link>
<guid>https://arxiv.org/abs/2502.18465</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化代码生成、调试框架、LangGraph、GLM4 Flash、ChromaDB

总结:
本文提出了一种用于自动化代码生成和调试的新颖框架，旨在提升软件开发的准确性、效率和可扩展性。该框架整合了三个核心组件：LangGraph（用于以图为基础的任务编排库，提供精确控制与执行，并维持统一状态对象进行动态更新和一致性保持）、GLM4 Flash（一款大型语言模型，利用其在自然语言理解、语境推理和多语言支持方面的高级能力来根据用户提示生成准确的代码片段）以及ChromaDB（作为语义搜索和上下文记忆存储的向量数据库，能够识别模式并基于历史数据生成上下文感知的bug修复）。整个系统通过四个步骤迭代工作：(1) 代码生成，将自然语言描述转化为可执行代码；(2) 代码执行，通过识别运行时错误和不一致之处验证代码；(3) 代码修复，利用ChromaDB的记忆能力和LangGraph的状态追踪对有误代码进行迭代改进；(4) 代码更新，确保代码满足功能性和性能需求并通过迭代修改不断优化。 <div>
arXiv:2502.18465v1 Announce Type: new 
Abstract: This paper presents a novel framework for automated code generation and debugging, designed to improve accuracy, efficiency, and scalability in software development. The proposed system integrates three core components LangGraph, GLM4 Flash, and ChromaDB within a four step iterative workflow to deliver robust performance and seamless functionality.
  LangGraph serves as a graph-based library for orchestrating tasks, providing precise control and execution while maintaining a unified state object for dynamic updates and consistency. It supports multi-agent, hierarchical, and sequential processes, making it highly adaptable to complex software engineering workflows. GLM4 Flash, a large language model, leverages its advanced capabilities in natural language understanding, contextual reasoning, and multilingual support to generate accurate code snippets based on user prompts. ChromaDB acts as a vector database for semantic search and contextual memory storage, enabling the identification of patterns and the generation of context-aware bug fixes based on historical data.
  The system operates through a structured four-step process: (1) Code Generation, which translates natural language descriptions into executable code; (2) Code Execution, which validates the code by identifying runtime errors and inconsistencies; (3) Code Repair, which iteratively refines buggy code using ChromaDB's memory capabilities and LangGraph's state tracking; and (4) Code Update, which ensures the code meets functional and performance requirements through iterative modifications.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FinBloom: Knowledge Grounding Large Language Model with Real-time Financial Data</title>
<link>https://arxiv.org/abs/2502.18471</link>
<guid>https://arxiv.org/abs/2502.18471</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、金融查询、实时信息、Financial Agent、FinBloom 7B

<br /><br />总结:
本文提出了一个名为“Financial Agent”的知识接地方法，旨在利用实时文本和表格数据使大型语言模型更好地处理涉及实时信息的金融查询。文章有三个主要贡献：首先，构建了一个包含超过5万条金融查询及其所需上下文的金融上下文数据集；其次，训练了一个定制的70亿参数的大规模语言模型FinBloom 7B，该模型基于1400万篇路透社和德意志新闻社的金融新闻文章以及1200万份美国证券交易委员会(SEC)的备案文件进行训练；最后，通过使用金融上下文数据集对FinBloom 7B进行微调，使其能够作为Financial Agent生成相关的金融上下文并有效实现实时数据检索以回答用户查询。这种方法显著提高了LLMs处理动态金融任务的能力，减少了延迟，消除了用户手动提供准确数据的需求，使得实时金融决策、算法交易等任务更加高效流畅，在高流量数据环境中具有很高的价值。 <div>
arXiv:2502.18471v1 Announce Type: new 
Abstract: Large language models (LLMs) excel at generating human-like responses but often struggle with interactive tasks that require access to real-time information. This limitation poses challenges in finance, where models must access up-to-date information, such as recent news or price movements, to support decision-making. To address this, we introduce Financial Agent, a knowledge-grounding approach for LLMs to handle financial queries using real-time text and tabular data. Our contributions are threefold: First, we develop a Financial Context Dataset of over 50,000 financial queries paired with the required context. Second, we train FinBloom 7B, a custom 7 billion parameter LLM, on 14 million financial news articles from Reuters and Deutsche Presse-Agentur, alongside 12 million Securities and Exchange Commission (SEC) filings. Third, we fine-tune FinBloom 7B using the Financial Context Dataset to serve as a Financial Agent. This agent generates relevant financial context, enabling efficient real-time data retrieval to answer user queries. By reducing latency and eliminating the need for users to manually provide accurate data, our approach significantly enhances the capability of LLMs to handle dynamic financial tasks. Our proposed approach makes real-time financial decisions, algorithmic trading and other related tasks streamlined, and is valuable in contexts with high-velocity data flows.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Physical Depth-aware Early Accident Anticipation: A Multi-dimensional Visual Feature Fusion Framework</title>
<link>https://arxiv.org/abs/2502.18496</link>
<guid>https://arxiv.org/abs/2502.18496</guid>
<content:encoded><![CDATA[
<div> 关键词：早期事故预警、dashcam视频、深度感知学习、三维信息、交互特征<br /><br />总结:

本文提出了一种新的物理深度感知学习框架，用于从dashcam视频中提前预测交通事故。该框架针对现有方法在二维图像空间建模交通参与者交互可能不足的问题，利用名为Depth-Anything的大模型生成的单目深度特征引入更精细的三维空间信息。同时，整合了视觉交互特征和交通场景的动态视觉特征，以实现对场景的全面感知。通过分析序列帧中物体间的交互关系，捕捉事故的早期迹象。此外，为解决遮挡物体的影响，框架还引入了重建邻接矩阵，维持关键交通参与者的时空连续性。实验结果显示，该框架在公共数据集上达到了最先进的性能，验证了结合视觉深度特征的有效性和所提框架的优越性。 <div>
arXiv:2502.18496v1 Announce Type: new 
Abstract: Early accident anticipation from dashcam videos is a highly desirable yet challenging task for improving the safety of intelligent vehicles. Existing advanced accident anticipation approaches commonly model the interaction among traffic agents (e.g., vehicles, pedestrians, etc.) in the coarse 2D image space, which may not adequately capture their true positions and interactions. To address this limitation, we propose a physical depth-aware learning framework that incorporates the monocular depth features generated by a large model named Depth-Anything to introduce more fine-grained spatial 3D information. Furthermore, the proposed framework also integrates visual interaction features and visual dynamic features from traffic scenes to provide a more comprehensive perception towards the scenes. Based on these multi-dimensional visual features, the framework captures early indicators of accidents through the analysis of interaction relationships between objects in sequential frames. Additionally, the proposed framework introduces a reconstruction adjacency matrix for key traffic participants that are occluded, mitigating the impact of occluded objects on graph learning and maintaining the spatio-temporal continuity. Experimental results on public datasets show that the proposed framework attains state-of-the-art performance, highlighting the effectiveness of incorporating visual depth features and the superiority of the proposed framework.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Protecting Users From Themselves: Safeguarding Contextual Privacy in Interactions with Conversational Agents</title>
<link>https://arxiv.org/abs/2502.18509</link>
<guid>https://arxiv.org/abs/2502.18509</guid>
<content:encoded><![CDATA[
<div> 关键词: 对话代理、隐私风险、情境隐私、大型语言模型、用户研究

总结:
本文探讨了用户与大型语言模型交互过程中的情境隐私问题，旨在通过确保用户仅向模型透露与其目标相关且必要的信息来最小化隐私风险。文章基于一项形式设计的用户体验研究，发现即使“注重隐私”的用户也可能无意间通过间接方式泄露敏感信息。据此，文章提出了一个部署于用户和大型语言模型之间的局部框架，该框架能够识别并重构用户提示中的非情境信息。通过使用ShareGPT的例子进行评估，研究表明轻量级模型可以有效实现这一框架，同时在保护用户情境隐私的同时，保持用户的互动目标得以实现。 <div>
arXiv:2502.18509v1 Announce Type: new 
Abstract: Conversational agents are increasingly woven into individuals' personal lives, yet users often underestimate the privacy risks involved. The moment users share information with these agents (e.g., LLMs), their private information becomes vulnerable to exposure. In this paper, we characterize the notion of contextual privacy for user interactions with LLMs. It aims to minimize privacy risks by ensuring that users (sender) disclose only information that is both relevant and necessary for achieving their intended goals when interacting with LLMs (untrusted receivers). Through a formative design user study, we observe how even "privacy-conscious" users inadvertently reveal sensitive information through indirect disclosures. Based on insights from this study, we propose a locally-deployable framework that operates between users and LLMs, and identifies and reformulates out-of-context information in user prompts. Our evaluation using examples from ShareGPT shows that lightweight models can effectively implement this framework, achieving strong gains in contextual privacy while preserving the user's intended interaction goals through different approaches to classify information relevant to the intended goals.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Teacher Knowledge Distillation with Reinforcement Learning for Visual Recognition</title>
<link>https://arxiv.org/abs/2502.18510</link>
<guid>https://arxiv.org/abs/2502.18510</guid>
<content:encoded><![CDATA[
<div> 关键词：多教师知识蒸馏、强化学习、权重优化、学生网络、视觉识别任务

总结:
本文提出了一种基于强化学习的多教师知识蒸馏方法（MTKD-RL），旨在解决多教师知识蒸馏中如何平衡各教师的知识转移强度问题。现有的多数方法主要从单个教师的表现或师生差距的角度制定权重策略，而缺乏全面的信息指导。MTKD-RL框架将教师性能和师生差距构建为智能体的状态信息，由智能体输出教师权重并根据学生返回的奖励进行更新。通过强化学习决策机制，MTKD-RL增强了学生与教师间的交互，实现了更有意义的权重分配以及更好的匹配能力。实验结果显示，相比于现有多教师知识蒸馏工作，MTKD-RL在图像分类、物体检测和语义分割等视觉识别任务上均取得了最优性能。 <div>
arXiv:2502.18510v1 Announce Type: new 
Abstract: Multi-teacher Knowledge Distillation (KD) transfers diverse knowledge from a teacher pool to a student network. The core problem of multi-teacher KD is how to balance distillation strengths among various teachers. Most existing methods often develop weighting strategies from an individual perspective of teacher performance or teacher-student gaps, lacking comprehensive information for guidance. This paper proposes Multi-Teacher Knowledge Distillation with Reinforcement Learning (MTKD-RL) to optimize multi-teacher weights. In this framework, we construct both teacher performance and teacher-student gaps as state information to an agent. The agent outputs the teacher weight and can be updated by the return reward from the student. MTKD-RL reinforces the interaction between the student and teacher using an agent in an RL-based decision mechanism, achieving better matching capability with more meaningful weights. Experimental results on visual recognition tasks, including image classification, object detection, and semantic segmentation tasks, demonstrate that MTKD-RL achieves state-of-the-art performance compared to the existing multi-teacher KD works.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-Agent Framework for Automated Vulnerability Detection and Repair in Solidity and Move Smart Contracts</title>
<link>https://arxiv.org/abs/2502.18515</link>
<guid>https://arxiv.org/abs/2502.18515</guid>
<content:encoded><![CDATA[
<div> 关键词: Smartify、智能合约、安全检测、修复、多代理框架<br /><br />总结:
本文介绍了Smartify，这是一个利用大型语言模型（LLMs）自动检测和修复Solidity与Move智能合约漏洞的创新多代理框架。Smartify不同于传统方法，它采用一组专注于不同专门微调LLM的特化代理，根据底层编程概念和语言特定的安全原则分析代码。通过对Solidity和精心策划的Move合约数据集进行评估，Smartify显示出了在修复多种漏洞方面的优越效果，并超越了现有LLM以及增强了通用模型的能力，如Llama 3.1。尤其值得注意的是，Smartify能够在无需大量语言特定预训练数据集的情况下，融入如Move等语言的特殊知识。这项工作详细分析了各种LLM在智能合约修复性能上的表现，突显了其多代理方法的优势，并为构建更安全可靠的区块链生态系统中的去中心化应用提供了蓝图。同时，文中还提供了将此方法扩展到其他类似应用场景的具体方案。 <div>
arXiv:2502.18515v1 Announce Type: new 
Abstract: The rapid growth of the blockchain ecosystem and the increasing value locked in smart contracts necessitate robust security measures. While languages like Solidity and Move aim to improve smart contract security, vulnerabilities persist. This paper presents Smartify, a novel multi-agent framework leveraging Large Language Models (LLMs) to automatically detect and repair vulnerabilities in Solidity and Move smart contracts. Unlike traditional methods that rely solely on vast pre-training datasets, Smartify employs a team of specialized agents working on different specially fine-tuned LLMs to analyze code based on underlying programming concepts and language-specific security principles. We evaluated Smartify on a dataset for Solidity and a curated dataset for Move, demonstrating its effectiveness in fixing a wide range of vulnerabilities. Our results show that Smartify (Gemma2+codegemma) achieves state-of-the-art performance, surpassing existing LLMs and enhancing general-purpose models' capabilities, such as Llama 3.1. Notably, Smartify can incorporate language-specific knowledge, such as the nuances of Move, without requiring massive language-specific pre-training datasets. This work offers a detailed analysis of various LLMs' performance on smart contract repair, highlighting the strengths of our multi-agent approach and providing a blueprint for developing more secure and reliable decentralized applications in the growing blockchain landscape. We also provide a detailed recipe for extending this to other similar use cases.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Programming with Pixels: Computer-Use Meets Software Engineering</title>
<link>https://arxiv.org/abs/2502.18525</link>
<guid>https://arxiv.org/abs/2502.18525</guid>
<content:encoded><![CDATA[
<div> 关键词: 软件工程、工具基范式、编程与像素、环境、基准测试<br /><br />总结: 本文介绍了软件工程领域的最新进展，提出了“编程与像素”（PwP）这一新型环境，该环境允许代理人通过视觉感知、打字和点击直接在IDE中操作，从而统一了各种软件开发任务，突破了传统工具基范式的局限性，不再依赖于特定任务的手动编写工具接口。为了系统评估这类代理人，作者提出了“PwP-Bench”基准测试，它将多个编程语言、模态和领域的现有软件工程基准测试统一到一个任务无关的状态和动作空间下。实验结果显示，通用型计算机使用代理人在多种软件工程任务上的表现可以接近或超越专门的工具基代理，而无需预先定义工具。然而，当前模型存在有限的视觉定位问题，未能充分利用IDE内置工具简化任务。当代理人可以直接访问IDE工具时，其性能显著提升，显示出利用IDE内置功能的未被充分挖掘的潜力。文章认为PwP作为一个可扩展的试验台，为构建和评估下一代软件工程代理人提供了可能性。相关的代码和数据已在https://programmingwithpixels.com网站上发布。 <div>
arXiv:2502.18525v1 Announce Type: new 
Abstract: Recent advancements in software engineering (SWE) agents have largely followed a $\textit{tool-based paradigm}$, where agents interact with hand-engineered tool APIs to perform specific tasks. While effective for specialized tasks, these methods fundamentally lack generalization, as they require predefined tools for each task and do not scale across programming languages and domains. We introduce $\texttt{Programming with Pixels}$ (PwP), an agent environment that unifies software development tasks by enabling $\textit{computer-use agents}$-agents that operate directly within an IDE through visual perception, typing, and clicking, rather than relying on predefined tool APIs. To systematically evaluate these agents, we propose $\texttt{PwP-Bench}$, a benchmark that unifies existing SWE benchmarks spanning tasks across multiple programming languages, modalities, and domains under a task-agnostic state and action space. Our experiments demonstrate that general-purpose computer-use agents can approach or even surpass specialized tool-based agents on a variety of SWE tasks without the need for hand-engineered tools. However, our analysis shows that current models suffer from limited visual grounding and fail to exploit many IDE tools that could simplify their tasks. When agents can directly access IDE tools, without visual interaction, they show significant performance improvements, highlighting the untapped potential of leveraging built-in IDE capabilities. Our results establish PwP as a scalable testbed for building and evaluating the next wave of software engineering agents. We release code and data at https://programmingwithpixels.com
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement Learning-based Approach for Vehicle-to-Building Charging with Heterogeneous Agents and Long Term Rewards</title>
<link>https://arxiv.org/abs/2502.18526</link>
<guid>https://arxiv.org/abs/2502.18526</guid>
<content:encoded><![CDATA[
<div> 关键词: 电动汽车电池、能源储备、智能社区、强化学习、Deep Deterministic Policy Gradient (DDPG)

总结:<br />
本文提出了一种新的强化学习框架，用于解决电动汽车电池的战略性聚合优化电力电网需求的问题，特别关注于提供职场充电的大型办公建筑。该问题涉及在不确定性环境下进行连续决策，并需要处理延迟和稀疏奖励、大规模状态-动作空间以及跨多种条件的泛化能力。针对现有算法如基于启发式策略的方法在动态条件下实时决策的不足，以及传统强化学习模型在处理这些问题上的挑战，本文将DDPG方法与行动掩码和高效的MILP驱动策略指导相结合。实验结果表明，该方法使用某大型电动汽车制造商的真实数据，相比于多个已建立的基线方法和可扩展的启发式方法，能更全面地降低成本并满足所有充电需求，展现出首个可扩展和普适性的V2B能源管理解决方案的优势。 <div>
arXiv:2502.18526v1 Announce Type: new 
Abstract: Strategic aggregation of electric vehicle batteries as energy reservoirs can optimize power grid demand, benefiting smart and connected communities, especially large office buildings that offer workplace charging. This involves optimizing charging and discharging to reduce peak energy costs and net peak demand, monitored over extended periods (e.g., a month), which involves making sequential decisions under uncertainty and delayed and sparse rewards, a continuous action space, and the complexity of ensuring generalization across diverse conditions. Existing algorithmic approaches, e.g., heuristic-based strategies, fall short in addressing real-time decision-making under dynamic conditions, and traditional reinforcement learning (RL) models struggle with large state-action spaces, multi-agent settings, and the need for long-term reward optimization. To address these challenges, we introduce a novel RL framework that combines the Deep Deterministic Policy Gradient approach (DDPG) with action masking and efficient MILP-driven policy guidance. Our approach balances the exploration of continuous action spaces to meet user charging demands. Using real-world data from a major electric vehicle manufacturer, we show that our approach comprehensively outperforms many well-established baselines and several scalable heuristic approaches, achieving significant cost savings while meeting all charging requirements. Our results show that the proposed approach is one of the first scalable and general approaches to solving the V2B energy management challenge.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ARACNE: An LLM-Based Autonomous Shell Pentesting Agent</title>
<link>https://arxiv.org/abs/2502.18528</link>
<guid>https://arxiv.org/abs/2502.18528</guid>
<content:encoded><![CDATA[
<div> 关键词：ARACNE、LLM、SSH服务、自动渗透测试、多模型支持

总结:
ARACNE是一个基于LLM的全自动Linux SSH服务渗透测试代理，具备真实Linux shell系统的命令执行能力。该研究提出了一种新的代理架构，支持多LLM模型。实验结果显示，ARACNE对自主防御者ShelLM的成功攻击率为60%，对Over The Wire Bandit CTF挑战的成功攻击率为57.58%，超越了现有技术的水平。当ARACNE获胜时，平均完成目标所需的行动次数少于5次。这表明使用多LLM模型的方法对于提高行动准确性具有很大的潜力。 <div>
arXiv:2502.18528v1 Announce Type: new 
Abstract: We introduce ARACNE, a fully autonomous LLM-based pentesting agent tailored for SSH services that can execute commands on real Linux shell systems. Introduces a new agent architecture with multi-LLM model support. Experiments show that ARACNE can reach a 60\% success rate against the autonomous defender ShelLM and a 57.58\% success rate against the Over The Wire Bandit CTF challenges, improving over the state-of-the-art. When winning, the average number of actions taken by the agent to accomplish the goals was less than 5. The results show that the use of multi-LLM is a promising approach to increase accuracy in the actions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>IMPROVE: Iterative Model Pipeline Refinement and Optimization Leveraging LLM Agents</title>
<link>https://arxiv.org/abs/2502.18530</link>
<guid>https://arxiv.org/abs/2502.18530</guid>
<content:encoded><![CDATA[
<div> 关键词: 计算机视觉、机器学习、大语言模型、迭代细化、IMPROVE

总结:
这篇论文介绍了一个用于优化计算机视觉模型设计的新策略——迭代细化（Iterative Refinement），该策略受到人类机器学习专家逐步优化模型方式的启发。传统上，开发高性能的计算机视觉模型需要机器学习和领域专业知识，而大型语言模型（LLM）代理已成为自动化这一流程的潜在解决方案。然而，现有的大多数方法尝试一次性优化整个流程，导致改进难以归因于特定变化，从而影响稳定性和收敛速度。为解决这个问题，文章提出了名为IMPROVE的端到端LLM代理框架，它运用迭代细化策略，逐个更新基于真实训练反馈的组件，提高了稳定性、可解释性以及整体模型性能。通过在不同规模和领域的数据集上的广泛评估，包括标准基准数据集和Kaggle竞赛数据集，研究显示迭代细化使IMPROVE能够持续超越现有基于LLM的一步式方法并实现更好的性能。因此，迭代细化被确立为一种有效的LLM驱动的机器学习自动化新策略，并使得IMPROVE成为一个无需具备机器学习专业知识即可构建高质量计算机视觉模型的可行方案。 <div>
arXiv:2502.18530v1 Announce Type: new 
Abstract: Computer vision is a critical component in a wide range of real-world applications, including plant monitoring in agriculture and handwriting classification in digital systems. However, developing high-performance computer vision models traditionally demands both machine learning (ML) expertise and domain-specific knowledge, making the process costly, labor-intensive, and inaccessible to many. Large language model (LLM) agents have emerged as a promising solution to automate this workflow, but most existing methods share a common limitation: they attempt to optimize entire pipelines in a single step before evaluation, making it difficult to attribute improvements to specific changes. This lack of granularity leads to unstable optimization and slower convergence, limiting their effectiveness. To address this, we introduce Iterative Refinement, a novel strategy for LLM-driven ML pipeline design inspired by how human ML experts iteratively refine models, focusing on one component at a time rather than making sweeping changes all at once. By systematically updating individual components based on real training feedback, Iterative Refinement improves stability, interpretability, and overall model performance. We implement this strategy in IMPROVE, an end-to-end LLM agent framework for automating and optimizing object classification pipelines. Through extensive evaluations across datasets of varying sizes and domains, including standard benchmarks and Kaggle competition datasets, we demonstrate that Iterative Refinement enables IMPROVE to consistently achieve better performance over existing zero-shot LLM-based approaches. These findings establish Iterative Refinement as an effective new strategy for LLM-driven ML automation and position IMPROVE as an accessible solution for building high-quality computer vision models without requiring ML expertise.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAFE: Multi-Agent Fair Environments for Decision-Making Systems</title>
<link>https://arxiv.org/abs/2502.18534</link>
<guid>https://arxiv.org/abs/2502.18534</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 公平性约束, 多智能体系统, 动态环境, Multi-Agent Fair Environment (MAFE)

<br /><br />总结:
该文关注静态环境下应用于机器学习模型的公平性约束可能导致随着时间推移对某些人口群体产生不利影响的问题。为解决这一问题，研究开始转向创建能够随时间保持公平性的解决方案。文章指出，在现实世界系统中，多智能体之间的相互作用往往会影响结果，因此将这些实体建模为代理能更灵活地分析其干预措施及对系统动态的影响。然而，当前在多智能体系统方面的研究缺乏利用有限的真实世界数据进行分析的逼真环境。为此，文章提出了Multi-Agent Fair Environment (MAFE)的概念，并构建和分析了三个模拟不同社会系统的MAFE实例。实验结果验证了MAFE作为开发多智能体公平算法测试平台的有效性。 <div>
arXiv:2502.18534v1 Announce Type: new 
Abstract: Fairness constraints applied to machine learning (ML) models in static contexts have been shown to potentially produce adverse outcomes among demographic groups over time. To address this issue, emerging research focuses on creating fair solutions that persist over time. While many approaches treat this as a single-agent decision-making problem, real-world systems often consist of multiple interacting entities that influence outcomes. Explicitly modeling these entities as agents enables more flexible analysis of their interventions and the effects they have on a system's underlying dynamics. A significant challenge in conducting research on multi-agent systems is the lack of realistic environments that leverage the limited real-world data available for analysis. To address this gap, we introduce the concept of a Multi-Agent Fair Environment (MAFE) and present and analyze three MAFEs that model distinct social systems. Experimental results demonstrate the utility of our MAFEs as testbeds for developing multi-agent fair algorithms.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Survey of Zero-Knowledge Proof Based Verifiable Machine Learning</title>
<link>https://arxiv.org/abs/2502.18535</link>
<guid>https://arxiv.org/abs/2502.18535</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器学习, 零知识证明, 隐私保护, 模型验证, 未来发展方向

<br /><br />总结:
这篇论文是对从2017年6月至2024年12月期间关于零知识机器学习（ZKML）研究的全面调查。随着机器学习技术在各领域的迅速发展，数据隐私和模型安全问题日益凸显，尤其是在云端平台或第三方服务器上训练和部署模型的情况。为解决这些问题，零知识证明技术作为一种有前途的解决方案应运而生，能够在不泄露敏感数据的情况下验证模型性能和真实性。文章首先介绍了ZKML的概念及其在三个关键类别（可验证训练、可验证推理和可验证测试）下的ZKP算法设置。接着，对现有ZKML研究进行了详细分类与分析，探讨了该领域所面临的实现挑战及改进措施，并举例说明了ZKML技术的一些商业应用。最后，文章提出了该领域未来发展的几个具有潜力的研究方向。 <div>
arXiv:2502.18535v1 Announce Type: new 
Abstract: As machine learning technologies advance rapidly across various domains, concerns over data privacy and model security have grown significantly. These challenges are particularly pronounced when models are trained and deployed on cloud platforms or third-party servers due to the computational resource limitations of users' end devices. In response, zero-knowledge proof (ZKP) technology has emerged as a promising solution, enabling effective validation of model performance and authenticity in both training and inference processes without disclosing sensitive data. Thus, ZKP ensures the verifiability and security of machine learning models, making it a valuable tool for privacy-preserving AI. Although some research has explored the verifiable machine learning solutions that exploit ZKP, a comprehensive survey and summary of these efforts remain absent. This survey paper aims to bridge this gap by reviewing and analyzing all the existing Zero-Knowledge Machine Learning (ZKML) research from June 2017 to December 2024. We begin by introducing the concept of ZKML and outlining its ZKP algorithmic setups under three key categories: verifiable training, verifiable inference, and verifiable testing. Next, we provide a comprehensive categorization of existing ZKML research within these categories and analyze the works in detail. Furthermore, we explore the implementation challenges faced in this field and discuss the improvement works to address these obstacles. Additionally, we highlight several commercial applications of ZKML technology. Finally, we propose promising directions for future advancements in this domain.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA-GTS: A Multi-Agent Framework for Solving Complex Graph Problems in Real-World Applications</title>
<link>https://arxiv.org/abs/2502.18540</link>
<guid>https://arxiv.org/abs/2502.18540</guid>
<content:encoded><![CDATA[
<div> 关键词：MA-GTS、多智能体、图论问题、大语言模型、效率

总结:
本文提出了一种名为MA-GTS的多智能体图论求解器框架，用于解决现实世界中的复杂、噪声和不规则图论问题。MA-GTS能够将文本形式的图数据转化为清晰、结构化的图表示，并根据问题约束和图结构规模动态选择最合适的算法，确保解决方案的高效性和解释性。为了验证MA-GTS的有效性，文章创建了基于真实世界的图论数据集G-REAL，并通过对比实验表明，MA-GTS在效率、准确性和可扩展性方面优于现有最优方法，在多个基准测试（如G-REAL 94.2%，GraCoRe 96.9%，NLGraph 98.4%）中表现出色。此外，MA-GTS已开源，可在https://github.com/ZIKEYUAN/MA-GTS.git获取。<br /><br /> <div>
arXiv:2502.18540v1 Announce Type: new 
Abstract: Graph-theoretic problems arise in real-world applications like logistics, communication networks, and traffic optimization. These problems are often complex, noisy, and irregular, posing challenges for traditional algorithms. Large language models (LLMs) offer potential solutions but face challenges, including limited accuracy and input length constraints. To address these challenges, we propose MA-GTS (Multi-Agent Graph Theory Solver), a multi-agent framework that decomposes these complex problems through agent collaboration. MA-GTS maps the implicitly expressed text-based graph data into clear, structured graph representations and dynamically selects the most suitable algorithm based on problem constraints and graph structure scale. This approach ensures that the solution process remains efficient and the resulting reasoning path is interpretable. We validate MA-GTS using the G-REAL dataset, a real-world-inspired graph theory dataset we created. Experimental results show that MA-GTS outperforms state-of-the-art approaches in terms of efficiency, accuracy, and scalability, with strong results across multiple benchmarks (G-REAL 94.2%, GraCoRe 96.9%, NLGraph 98.4%).MA-GTS is open-sourced at https://github.com/ZIKEYUAN/MA-GTS.git.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Steganography Beyond Space-Time With Chain of Multimodal AI Agents</title>
<link>https://arxiv.org/abs/2502.18547</link>
<guid>https://arxiv.org/abs/2502.18547</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能、steganography（隐写术）、音频视觉媒体、多模态代理、消息安全性

总结:
<br />
本文探讨了随着人工智能技术的发展，合成内容对隐写术带来的挑战。为了解决音频视觉媒体中信号在空间和时间域易被篡改的问题，研究提出了一种新的跨空间和时间域的音频视觉媒体隐写方案。该方案利用多模态代理将音视频内容分解为文本封面，通过在语言域内嵌入消息然后再重建音视频内容。消息通过引导语言生成模型的词采样过程进行编码，并通过对词汇选择概率分布的分析实现解码。实验评估了零比特和多比特容量设置下的信息传输准确性，并从生物识别和语义相似性两方面考察了保真度，同时检查了隐写文本与原始文本之间的统计差异以验证保密性。最后，针对音频压缩、面部交换、语音克隆及其组合等不同场景测试了方案的鲁棒性。 <div>
arXiv:2502.18547v1 Announce Type: new 
Abstract: Steganography is the art and science of covert writing, with a broad range of applications interwoven within the realm of cybersecurity. As artificial intelligence continues to evolve, its ability to synthesise realistic content emerges as a threat in the hands of cybercriminals who seek to manipulate and misrepresent the truth. Such synthetic content introduces a non-trivial risk of overwriting the subtle changes made for the purpose of steganography. When the signals in both the spatial and temporal domains are vulnerable to unforeseen overwriting, it calls for reflection on what can remain invariant after all. This study proposes a paradigm in steganography for audiovisual media, where messages are concealed beyond both spatial and temporal domains. A chain of multimodal agents is developed to deconstruct audiovisual content into a cover text, embed a message within the linguistic domain, and then reconstruct the audiovisual content through synchronising both aural and visual modalities with the resultant stego text. The message is encoded by biasing the word sampling process of a language generation model and decoded by analysing the probability distribution of word choices. The accuracy of message transmission is evaluated under both zero-bit and multi-bit capacity settings. Fidelity is assessed through both biometric and semantic similarities, capturing the identities of the recorded face and voice, as well as the core ideas conveyed through the media. Secrecy is examined through statistical comparisons between cover and stego texts. Robustness is tested across various scenarios, including audiovisual compression, face-swapping, voice-cloning and their combinations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Error-related Potential driven Reinforcement Learning for adaptive Brain-Computer Interfaces</title>
<link>https://arxiv.org/abs/2502.18594</link>
<guid>https://arxiv.org/abs/2502.18594</guid>
<content:encoded><![CDATA[
<div> 关键词：脑机接口（BCI）、非侵入式、电位图（EEG）、错误相关电位（ErrPs）、强化学习（RL）

总结：
本文介绍了一种使用强化学习（RL）的新型自适应错误相关电位（ErrP）基脑机接口（BCI）方法。该研究利用两种RL代理，构建了一个能够动态适应电位图（EEG）非平稳性的框架，将ErrPs和运动想象结合起来。通过公开可用的运动想象数据集和一款旨在提高用户参与度的快节奏游戏进行验证，结果表明该框架具有可行性，RL代理能从用户交互中学习控制策略并实现稳健的性能。然而，游戏协议中的关键发现指出，在高时效性互动范式下，大部分参与者无法有效地运用运动想象，揭示了实时BCI应用中任务设计复杂性和用户响应性方面的实际限制。这些发现强调了RL在自适应BCI中的潜力，同时也指出了与任务复杂度及用户响应性相关的实际约束问题。 <div>
arXiv:2502.18594v1 Announce Type: new 
Abstract: Brain-computer interfaces (BCIs) provide alternative communication methods for individuals with motor disabilities by allowing control and interaction with external devices. Non-invasive BCIs, especially those using electroencephalography (EEG), are practical and safe for various applications. However, their performance is often hindered by EEG non-stationarities, caused by changing mental states or device characteristics like electrode impedance. This challenge has spurred research into adaptive BCIs that can handle such variations. In recent years, interest has grown in using error-related potentials (ErrPs) to enhance BCI performance. ErrPs, neural responses to errors, can be detected non-invasively and have been integrated into different BCI paradigms to improve performance through error correction or adaptation.
  This research introduces a novel adaptive ErrP-based BCI approach using reinforcement learning (RL). We demonstrate the feasibility of an RL-driven adaptive framework incorporating ErrPs and motor imagery. Utilizing two RL agents, the framework adapts dynamically to EEG non-stationarities. Validation was conducted using a publicly available motor imagery dataset and a fast-paced game designed to boost user engagement. Results show the framework's promise, with RL agents learning control policies from user interactions and achieving robust performance across datasets. However, a critical insight from the game-based protocol revealed that motor imagery in a high-speed interaction paradigm was largely ineffective for participants, highlighting task design limitations in real-time BCI applications. These findings underscore the potential of RL for adaptive BCIs while pointing out practical constraints related to task complexity and user responsiveness.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Single- vs. Dual-Prompt Dialogue Generation with LLMs for Job Interviews in Human Resources</title>
<link>https://arxiv.org/abs/2502.18650</link>
<guid>https://arxiv.org/abs/2502.18650</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型，对话生成，人力资源，面试，双促发型方法

总结:
本文对比了两种基于大型语言模型（LLM）的人力资源面试场景对话生成方法。这两种方法分别为：单一提示生成完整面试对话和两个代理人之间交互式对话生成。为了评估不同方法下对话的质量，研究者使用了一个判别器LLM进行AI生成面试对话与真实人类对话的二选一对比。结果显示，尽管双促发型方法的令牌成本增加了六倍，但其生成的面试对话在赢得质量判断上的胜率却比单一提示方法高出十倍之多。这一结果在使用GPT-4o或Llama 3.3 70B进行对话生成或质量评判时都保持了一致性。 <div>
arXiv:2502.18650v1 Announce Type: new 
Abstract: Optimizing language models for use in conversational agents requires large quantities of example dialogues. Increasingly, these dialogues are synthetically generated by using powerful large language models (LLMs), especially in domains with challenges to obtain authentic human data. One such domain is human resources (HR). In this context, we compare two LLM-based dialogue generation methods for the use case of generating HR job interviews, and assess whether one method generates higher-quality dialogues that are more challenging to distinguish from genuine human discourse. The first method uses a single prompt to generate the complete interview dialog. The second method uses two agents that converse with each other. To evaluate dialogue quality under each method, we ask a judge LLM to determine whether AI was used for interview generation, using pairwise interview comparisons. We demonstrate that despite a sixfold increase in token cost, interviews generated with the dual-prompt method achieve a win rate up to ten times higher than those generated with the single-prompt method. This difference remains consistent regardless of whether GPT-4o or Llama 3.3 70B is used for either interview generation or judging quality.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Independent Mobility GPT (IDM-GPT): A Self-Supervised Multi-Agent Large Language Model Framework for Customized Traffic Mobility Analysis Using Machine Learning Models</title>
<link>https://arxiv.org/abs/2502.18652</link>
<guid>https://arxiv.org/abs/2502.18652</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通大数据、机器学习、人工智能、多智能体框架、独立移动GPT（IDM-GPT）、大型语言模型、数据隐私、交通分析、管理建议、用户查询理解、性能优化

总结:<br />
随着城市化进程加快，大量传感器被部署于交通系统中，产生了海量的大数据。为解决由此带来的交通挑战，研究团队提出了一种基于大型语言模型（LLMs）的创新性多智能体框架——独立移动GPT（IDM-GPT）。该框架旨在实现定制化的交通分析和管理建议，并注重隐私保护。IDM-GPT经济高效地连接了用户、交通运输数据库及机器学习模型，通过训练和定制多种基于LLM的人工智能代理来处理包括用户查询理解、提示优化、数据分析、模型选择及性能评估与提升等任务。这使得不具备交通或机器学习背景的用户也能实时获取定制化数据分析与建议。实验结果显示，IDM-GPT在多个交通相关任务上表现出色，能够提供全面而实用的见解，支持有效的交通管理和城市流动性提升。 <div>
arXiv:2502.18652v1 Announce Type: new 
Abstract: With the urbanization process, an increasing number of sensors are being deployed in transportation systems, leading to an explosion of big data. To harness the power of this vast transportation data, various machine learning (ML) and artificial intelligence (AI) methods have been introduced to address numerous transportation challenges. However, these methods often require significant investment in data collection, processing, storage, and the employment of professionals with expertise in transportation and ML. Additionally, privacy issues are a major concern when processing data for real-world traffic control and management. To address these challenges, the research team proposes an innovative Multi-agent framework named Independent Mobility GPT (IDM-GPT) based on large language models (LLMs) for customized traffic analysis, management suggestions, and privacy preservation. IDM-GPT efficiently connects users, transportation databases, and ML models economically. IDM-GPT trains, customizes, and applies various LLM-based AI agents for multiple functions, including user query comprehension, prompts optimization, data analysis, model selection, and performance evaluation and enhancement. With IDM-GPT, users without any background in transportation or ML can efficiently and intuitively obtain data analysis and customized suggestions in near real-time based on their questions. Experimental results demonstrate that IDM-GPT delivers satisfactory performance across multiple traffic-related tasks, providing comprehensive and actionable insights that support effective traffic management and urban mobility improvement.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Text Classification with a Novel Multi-Agent Collaboration Framework Leveraging BERT</title>
<link>https://arxiv.org/abs/2502.18653</link>
<guid>https://arxiv.org/abs/2502.18653</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体协作框架、文本分类、BERT、低置信度预测、准确性提升

总结:
我们提出了一种新颖的多智能体协作框架，旨在提高文本分类模型的准确性和鲁棒性。该框架利用BERT作为主要分类器，并将低置信度预测动态升级到由词法、语境、逻辑、共识和可解释性等专门代理组成的多智能体系统进行分析与决策。这种协同方法使得在各种文本分类任务中的性能显著提升。实证评估显示，相比于标准基于BERT的分类器，我们的框架在基准数据集上实现了5.5%的精度提升，从而证实了其在自然语言处理领域中推进多智能体系统发展的有效性和学术创新性。<br /><br /> <div>
arXiv:2502.18653v1 Announce Type: new 
Abstract: We introduce a novel multi-agent collaboration framework designed to enhance the accuracy and robustness of text classification models. Leveraging BERT as the primary classifier, our framework dynamically escalates low-confidence predictions to a specialized multi-agent system comprising Lexical, Contextual, Logic, Consensus, and Explainability agents. This collaborative approach allows for comprehensive analysis and consensus-driven decision-making, significantly improving classification performance across diverse text classification tasks. Empirical evaluations on benchmark datasets demonstrate that our framework achieves a 5.5% increase in accuracy compared to standard BERT-based classifiers, underscoring its effectiveness and academic novelty in advancing multi-agent systems within natural language processing.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assistance or Disruption? Exploring and Evaluating the Design and Trade-offs of Proactive AI Programming Support</title>
<link>https://arxiv.org/abs/2502.18658</link>
<guid>https://arxiv.org/abs/2502.18658</guid>
<content:encoded><![CDATA[
<div> 关键词: AI编程工具、主动式AI代理、Codellaborator、编程工作流、用户研究

总结:
本文探讨了AI编程工具对编程工作流程的影响，并介绍了名为Codellaborator的设计探针LLM代理，该代理能基于编辑活动和任务上下文主动提供编程协助。研究对比了三种接口变体：仅提示、主动式代理和带有存在感与交互上下文支持的主动式代理（Codellaborator）。通过一项包含18名参与者的嵌套式研究，发现主动式代理相较于仅提示的方式能提高效率，但也可能导致工作流程中断。然而，存在指示器和交互上下文支持能够减轻中断并提升用户对AI过程的认识。文章强调了 Codellaborator 在用户控制、所有权以及代码理解方面的权衡，并指出需要根据编程过程调整AI系统的主动性。此项研究为集成AI的编程工作流程设计提供了探索与评估的新见解，并提出了相关设计启示。 <div>
arXiv:2502.18658v1 Announce Type: new 
Abstract: AI programming tools enable powerful code generation, and recent prototypes attempt to reduce user effort with proactive AI agents, but their impact on programming workflows remains unexplored. We introduce and evaluate Codellaborator, a design probe LLM agent that initiates programming assistance based on editor activities and task context. We explored three interface variants to assess trade-offs between increasingly salient AI support: prompt-only, proactive agent, and proactive agent with presence and context (Codellaborator). In a within-subject study (N=18), we find that proactive agents increase efficiency compared to prompt-only paradigm, but also incur workflow disruptions. However, presence indicators and \revise{interaction context support} alleviated disruptions and improved users' awareness of AI processes. We underscore trade-offs of Codellaborator on user control, ownership, and code understanding, emphasizing the need to adapt proactivity to programming processes. Our research contributes to the design exploration and evaluation of proactive AI systems, presenting design implications on AI-integrated programming workflow.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Speaking the Right Language: The Impact of Expertise Alignment in User-AI Interactions</title>
<link>https://arxiv.org/abs/2502.18685</link>
<guid>https://arxiv.org/abs/2502.18685</guid>
<content:encoded><![CDATA[
<div> 关键词：Bing Copilot、对话样本、领域专业知识、用户体验、人工智能与用户对齐

<br />
总结:
本文研究了Bing Copilot 在处理不同领域知识水平用户的对话中的响应情况及其对用户体验的影响。研究发现，该智能代理在多数情况下（77%的对话）能以专业或专家级别的知识水平回应用户，这与其正面的用户体验相关联，不论用户的专业知识水平如何。然而，当智能代理的回复专业知识水平低于用户时，则会对整体用户体验产生负面影响，尤其在处理更复杂的任务时更为显著。此外，当智能代理的回应能匹配到用户的知识水平时，用户的参与度（通过对话中的词汇数量衡量）会提高。这些发现强调，在设计以人为本的人工智能系统时，确保用户与AI之间的对齐至关重要，以便实现满意和高效的交互。 <div>
arXiv:2502.18685v1 Announce Type: new 
Abstract: Using a sample of 25,000 Bing Copilot conversations, we study how the agent responds to users of varying levels of domain expertise and the resulting impact on user experience along multiple dimensions. Our findings show that across a variety of topical domains, the agent largely responds at proficient or expert levels of expertise (77% of conversations) which correlates with positive user experience regardless of the user's level of expertise. Misalignment, such that the agent responds at a level of expertise below that of the user, has a negative impact on overall user experience, with the impact more profound for more complex tasks. We also show that users engage more, as measured by the number of words in the conversation, when the agent responds at a level of expertise commensurate with that of the user. Our findings underscore the importance of alignment between user and AI when designing human-centered AI systems, to ensure satisfactory and productive interactions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hybrid Voting-Based Task Assignment in Role-Playing Games</title>
<link>https://arxiv.org/abs/2502.18690</link>
<guid>https://arxiv.org/abs/2502.18690</guid>
<content:encoded><![CDATA[
<div> 关键词：角色扮演游戏（RPG）、沉浸感、大型语言模型（LLM）、任务分配、投票基于的任务分配（VBTA）

总结:
本文提出了一种针对角色扮演游戏(RPG)的新型框架——投票基于的任务分配(VBTA)，旨在提高游戏中智能代理对玩家情感状态和语境细微差别的理解与交互质量。VBTA通过赋予游戏代理能力和任务需求描述，生成适应性矩阵以量化两者间的匹配程度。利用预训练的大型语言模型、六种不同的投票方法以及冲突解决的路径规划算法(CBS)，该框架能够高效地识别并指派最适合执行各项任务的游戏代理。相较于现有的专注于生成单一游戏元素如任务或战斗场景的方法，VBTA由于其泛化特性，在生成独特战斗遭遇与叙事方面展现出潜力。 <div>
arXiv:2502.18690v1 Announce Type: new 
Abstract: In role-playing games (RPGs), the level of immersion is critical-especially when an in-game agent conveys tasks, hints, or ideas to the player. For an agent to accurately interpret the player's emotional state and contextual nuances, a foundational level of understanding is required, which can be achieved using a Large Language Model (LLM). Maintaining the LLM's focus across multiple context changes, however, necessitates a more robust approach, such as integrating the LLM with a dedicated task allocation model to guide its performance throughout gameplay. In response to this need, we introduce Voting-Based Task Assignment (VBTA), a framework inspired by human reasoning in task allocation and completion. VBTA assigns capability profiles to agents and task descriptions to tasks, then generates a suitability matrix that quantifies the alignment between an agent's abilities and a task's requirements. Leveraging six distinct voting methods, a pre-trained LLM, and integrating conflict-based search (CBS) for path planning, VBTA efficiently identifies and assigns the most suitable agent to each task. While existing approaches focus on generating individual aspects of gameplay, such as single quests, or combat encounters, our method shows promise when generating both unique combat encounters and narratives because of its generalizable nature.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Cooperative Multi-Agent Framework for Zero-Shot Named Entity Recognition</title>
<link>https://arxiv.org/abs/2502.18702</link>
<guid>https://arxiv.org/abs/2502.18702</guid>
<content:encoded><![CDATA[
<div> 关键词: 零样本命名实体识别 (Zero-shot NER)，大型语言模型 (LLMs)，合作多智能体系统 (CMAS)，实体类型相关特征 (TRF)，演示鉴别器

总结:
本文提出了一个用于零样本命名实体识别 (Zero-shot NER) 的新框架——合作多智能体系统 (CMAS)。该框架通过利用多个智能体的集体智慧来解决现有方法中两个主要挑战：忽视实体上下文之间的关联性以及不加区分地使用任务示例导致的误导问题。CMAS 包含四个主要智能体：自注释器、类型相关特征提取器、演示鉴别器和总体预测器。CMAS 将 NER 重新定义为两个子任务：识别命名实体和确定目标句子中的实体类型相关特征，以显式捕捉实体上下文的相关性。同时，为了实现对示例的可控利用，它建立了一个演示鉴别器，自动评估目标句子中示例的有用性分数。实验结果显示，CMAS 在六个基准数据集（包括特定领域和通用领域）上的零样本 NER 性能有显著提升，并且在少量样本设置和不同 LLM 后端中也显示出了有效性。 <div>
arXiv:2502.18702v1 Announce Type: new 
Abstract: Zero-shot named entity recognition (NER) aims to develop entity recognition systems from unannotated text corpora. This task presents substantial challenges due to minimal human intervention. Recent work has adapted large language models (LLMs) for zero-shot NER by crafting specialized prompt templates. It advances model self-learning abilities by incorporating self-annotated demonstrations. However, two important challenges persist: (i) Correlations between contexts surrounding entities are overlooked, leading to wrong type predictions or entity omissions. (ii) The indiscriminate use of task demonstrations, retrieved through shallow similarity-based strategies, severely misleads LLMs during inference.
  In this paper, we introduce the cooperative multi-agent system (CMAS), a novel framework for zero-shot NER that uses the collective intelligence of multiple agents to address the challenges outlined above. CMAS has four main agents: (i) a self-annotator, (ii) a type-related feature (TRF) extractor, (iii) a demonstration discriminator, and (iv) an overall predictor. To explicitly capture correlations between contexts surrounding entities, CMAS reformulates NER into two subtasks: recognizing named entities and identifying entity type-related features within the target sentence. To enable controllable utilization of demonstrations, a demonstration discriminator is established to incorporate the self-reflection mechanism, automatically evaluating helpfulness scores for the target sentence. Experimental results show that CMAS significantly improves zero-shot NER performance across six benchmarks, including both domain-specific and general-domain scenarios. Furthermore, CMAS demonstrates its effectiveness in few-shot settings and with various LLM backbones.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentSociety Challenge: Designing LLM Agents for User Modeling and Recommendation on Web Platforms</title>
<link>https://arxiv.org/abs/2502.18754</link>
<guid>https://arxiv.org/abs/2502.18754</guid>
<content:encoded><![CDATA[
<div> 关键词：AgentSociety Challenge、大型语言模型、用户建模、推荐系统、比赛设计

总结:<br />
AgentSociety Challenge 是首届在Web Conference上举行的竞赛，旨在探索大型语言模型（LLM）在模拟用户行为和改进网络平台上的推荐系统方面的潜力。比赛分为用户建模轨道和推荐轨道两部分，要求参与者利用来自Yelp、Amazon和Goodreads的综合数据集及交互式环境模拟器开发创新的LLM代理。比赛吸引了全球295支队伍参加，并在为期37天的正式竞赛期间收到超过1,400份提交作品。参赛者在发展阶段实现了Track 1和Track 2性能分别提高21.9%和20.3%，最终阶段则提高了9.1%和15.9%。论文详细介绍了挑战赛的设计，分析了结果，并突出了最成功的LLM代理设计方案。为了支持进一步的研究与开发，比赛基准环境已开源，可在https://tsinghua-fib-lab.github.io/AgentSocietyChallenge获取。 <div>
arXiv:2502.18754v1 Announce Type: new 
Abstract: The AgentSociety Challenge is the first competition in the Web Conference that aims to explore the potential of Large Language Model (LLM) agents in modeling user behavior and enhancing recommender systems on web platforms. The Challenge consists of two tracks: the User Modeling Track and the Recommendation Track. Participants are tasked to utilize a combined dataset from Yelp, Amazon, and Goodreads, along with an interactive environment simulator, to develop innovative LLM agents. The Challenge has attracted 295 teams across the globe and received over 1,400 submissions in total over the course of 37 official competition days. The participants have achieved 21.9% and 20.3% performance improvement for Track 1 and Track 2 in the Development Phase, and 9.1% and 15.9% in the Final Phase, representing a significant accomplishment. This paper discusses the detailed designs of the Challenge, analyzes the outcomes, and highlights the most successful LLM agent designs. To support further research and development, we have open-sourced the benchmark environment at https://tsinghua-fib-lab.github.io/AgentSocietyChallenge.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reward Shaping to Mitigate Reward Hacking in RLHF</title>
<link>https://arxiv.org/abs/2502.18770</link>
<guid>https://arxiv.org/abs/2502.18770</guid>
<content:encoded><![CDATA[
<div> 关键词：Reinforcement Learning from Human Feedback (RLHF)，reward hacking，reward shaping，Preference As Reward (PAR)，data efficiency

总结:
本文针对强化学习从人类反馈（RLHF）中的奖励黑客问题进行了研究，并提出了稳定和优化该过程的关键设计原则。文章指出了三种关键设计原则：(1) 强化学习的奖励应理想上具有界限；(2) 强化学习受益于快速初始增长后逐渐收敛的过程；(3) 奖励最好表述为与中心化奖励相关的函数。基于这些洞察，作者提出了一种新的奖励塑造方法——Preference As Reward (PAR)，该方法利用嵌入在奖励模型本身的潜在偏好作为强化学习的信号。实验结果显示，PAR在Gemma2-2B和Llama3-8B两个基线模型以及Ultrafeedback-Binarized和HH-RLHF两个数据集上的表现优于其他奖励塑造方法，在AlpacaEval 2.0基准测试中，其胜率至少比其他方法高出5个百分点。此外，PAR还表现出出色的数据效率，仅需一个参考奖励即可达到最佳性能，并在经过两轮完整训练后仍能保持对奖励黑客攻击的稳健性。相关代码可在https://github.com/PorUna-byte/PAR获取。 <div>
arXiv:2502.18770v1 Announce Type: new 
Abstract: Reinforcement Learning from Human Feedback (RLHF) is essential for aligning large language models (LLMs) with human values. However, RLHF is susceptible to reward hacking, where the agent exploits flaws in the reward function rather than learning the intended behavior, thus degrading alignment. While reward shaping helps stabilize RLHF and partially mitigate reward hacking, a systematic investigation into shaping techniques and their underlying principles remains lacking. To bridge this gap, we present a comprehensive study of the prevalent reward shaping methods. Our analysis suggests three key design principles: (1) RL reward is ideally bounded, (2) RL benefits from rapid initial growth followed by gradual convergence, and (3) RL reward is best formulated as a function of centered reward. Guided by these insights, we propose Preference As Reward (PAR), a novel approach that leverages the latent preferences embedded within the reward model itself as the signal for reinforcement learning. We evaluated PAR on two base models, Gemma2-2B and Llama3-8B, using two datasets, Ultrafeedback-Binarized and HH-RLHF. Experimental results demonstrate PAR's superior performance over other reward shaping methods. On the AlpacaEval 2.0 benchmark, PAR achieves a win rate at least 5 percentage points higher than competing approaches. Furthermore, PAR exhibits remarkable data efficiency, requiring only a single reference reward for optimal performance, and maintains robustness against reward hacking even after two full epochs of training. Code is available at https://github.com/PorUna-byte/PAR.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>It's Not All Black and White: Degree of Truthfulness for Risk-Avoiding Agents</title>
<link>https://arxiv.org/abs/2502.18805</link>
<guid>https://arxiv.org/abs/2502.18805</guid>
<content:encoded><![CDATA[
<div> 关键词：truthfulness、risk-avoiding truthfulness (RAT)、RAT-degree、manipulation、social choice settings

<br /><br />总结:
本文提出了一个介于经典诚实性与风险避免诚实性(RAT)之间的新概念——RAT度，用于描述机制被安全操纵的难易程度。RAT度定义为最少需要知道多少个参与者的报告，其他参与者才能进行无害的操纵，若不存在这样的数字则为n。这一概念填补了完全了解他人信息和完全不了解之间的真实情况。文中通过分析拍卖、不可分割商品分配、蛋糕切割、投票以及稳定匹配等社会选择场景中著名机制的RAT度，展示了该概念的普适性和应用价值。 <div>
arXiv:2502.18805v1 Announce Type: new 
Abstract: The classic notion of truthfulness requires that no agent has a profitable manipulation -- an untruthful report that, for some combination of reports of the other agents, increases her utility. This strong notion implicitly assumes that the manipulating agent either knows what all other agents are going to report, or is willing to take the risk and act as-if she knows their reports.
  Without knowledge of the others' reports, most manipulations are risky -- they might decrease the manipulator's utility for some other combinations of reports by the other agents. Accordingly, a recent paper (Bu, Song and Tao, ``On the existence of truthful fair cake cutting mechanisms'', Artificial Intelligence 319 (2023), 103904) suggests a relaxed notion, which we refer to as risk-avoiding truthfulness (RAT), which requires only that no agent can gain from a safe manipulation -- one that is sometimes beneficial and never harmful.
  Truthfulness and RAT are two extremes: the former considers manipulators with complete knowledge of others, whereas the latter considers manipulators with no knowledge at all. In reality, agents often know about some -- but not all -- of the other agents. This paper introduces the RAT-degree of a mechanism, defined as the smallest number of agents whose reports, if known, may allow another agent to safely manipulate, or $n$ if there is no such number. This notion interpolates between classic truthfulness (degree $n$) and RAT (degree at least $1$): a mechanism with a higher RAT-degree is harder to manipulate safely.
  To illustrate the generality and applicability of this concept, we analyze the RAT-degree of prominent mechanisms across various social choice settings, including auctions, indivisible goods allocations, cake-cutting, voting, and stable matchings.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Data-Efficient Multi-Agent Spatial Planning with LLMs</title>
<link>https://arxiv.org/abs/2502.18822</link>
<guid>https://arxiv.org/abs/2502.18822</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体决策、预训练大语言模型、出租车调度、零样本性能、有限微调

总结:<br />
本文研究了如何利用预训练大型语言模型的世界知识来实现多智能体决策中的高效和鲁棒学习，以解决出租车路由和分配问题为例。文章指出，在该图形化路网问题上，通过适当的提示，大语言模型在零样本情况下的表现非常强劲。进一步地，结合有限的微调和一次性滚动算法进行展望，LLMs能够在与现有方法相比互动环境次数减少50倍的情况下取得更优性能。此外，文章还探讨了不同语言提示方法的优势，并展示了在提示中加入易于计算的信息可以显著提升性能。最后，文中强调了大语言模型内置的语义理解能力，能通过简单的提示适应环境因素变化。 <div>
arXiv:2502.18822v1 Announce Type: new 
Abstract: In this project, our goal is to determine how to leverage the world-knowledge of pretrained large language models for efficient and robust learning in multiagent decision making. We examine this in a taxi routing and assignment problem where agents must decide how to best pick up passengers in order to minimize overall waiting time. While this problem is situated on a graphical road network, we show that with the proper prompting zero-shot performance is quite strong on this task. Furthermore, with limited fine-tuning along with the one-at-a-time rollout algorithm for look ahead, LLMs can out-compete existing approaches with 50 times fewer environmental interactions. We also explore the benefits of various linguistic prompting approaches and show that including certain easy-to-compute information in the prompt significantly improves performance. Finally, we highlight the LLM's built-in semantic understanding, showing its ability to adapt to environmental factors through simple prompts.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>REALM-Bench: A Real-World Planning Benchmark for LLMs and Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.18836</link>
<guid>https://arxiv.org/abs/2502.18836</guid>
<content:encoded><![CDATA[
<div> 关键词：LLMs、多智能体系统、规划场景、基准测试套件、复杂性

总结:
本文介绍了一个用于评估大型语言模型（LLMs）及多智能体系统的全面基准测试套件。该套件包含了从基础到高度复杂的十一类问题，涵盖了多智能体协调、交互依赖和动态环境干扰等关键要素。每个问题可在三个维度上进行扩展：并行规划线程的数量、交互依赖的复杂度以及需要实时适应的意外中断频率。测试基准提供了详细规范、评价指标和基于现代框架（如LangGraph）的基线实现，以实现对单智能体和多智能体规划能力的严格测试。通过标准化的评价标准和可扩展的复杂性，该基准旨在推动构建更强大、更具适应性的AI规划系统，以应用于现实世界情境中。<br /><br /> <div>
arXiv:2502.18836v1 Announce Type: new 
Abstract: This benchmark suite provides a comprehensive evaluation framework for assessing both individual LLMs and multi-agent systems in real-world planning scenarios. The suite encompasses eleven designed problems that progress from basic to highly complex, incorporating key aspects such as multi-agent coordination, inter-agent dependencies, and dynamic environmental disruptions. Each problem can be scaled along three dimensions: the number of parallel planning threads, the complexity of inter-dependencies, and the frequency of unexpected disruptions requiring real-time adaptation. The benchmark includes detailed specifications, evaluation metrics, and baseline implementations using contemporary frameworks like LangGraph, enabling rigorous testing of both single-agent and multi-agent planning capabilities. Through standardized evaluation criteria and scalable complexity, this benchmark aims to drive progress in developing more robust and adaptable AI planning systems for real-world applications.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards an AI co-scientist</title>
<link>https://arxiv.org/abs/2502.18864</link>
<guid>https://arxiv.org/abs/2502.18864</guid>
<content:encoded><![CDATA[
<div> 关键词: AI co-scientist, 多代理系统, 假设生成, 生物医学发现, 科学发现加速器

总结:
本文介绍了一种人工智能共科学家（AI co-scientist）的概念，这是一个基于Gemini 2.0构建的多代理系统，旨在辅助科学研究，生成新颖的假设并提出原创研究提案。该系统采用生成、辩论和演进的方法，以科学方法为灵感，并通过扩展测试时间计算能力来加速这一过程。关键贡献包括：1）一个多代理架构，带有异步任务执行框架，支持灵活的计算扩展；2）一种锦标赛式的进化过程，用于自我改进的假设生成。自动化评估显示，增加测试时间计算能力可以提高假设的质量。在生物医药领域的应用中，例如药物再利用、新靶点发现以及解释细菌演化和抗微生物耐药性的机制等方面，AI co-scientist提出了具有前景的验证结果。其中在药物再利用方面，针对急性髓系白血病，系统提出的候选药物在体外实验中显示出对肿瘤生长的抑制作用。在新靶点发现领域，AI co-scientist提出了针对肝纤维化的新的表观遗传学靶点，并在人类肝脏类器官实验中验证了其抗纤维化和促进肝细胞再生的作用。最后，AI co-scientist还通过平行的计算机模拟发现了细菌进化中的新型基因转移机制，重现了未公开的实验结果。这些结果在与本文同步发布的其他报告中有详细描述，展示了AI赋能科学家在生物医学和科学研究方面的巨大潜力，预示着一个由AI驱动的科学发现新时代的到来。 <div>
arXiv:2502.18864v1 Announce Type: new 
Abstract: Scientific discovery relies on scientists generating novel hypotheses that undergo rigorous experimental validation. To augment this process, we introduce an AI co-scientist, a multi-agent system built on Gemini 2.0. The AI co-scientist is intended to help uncover new, original knowledge and to formulate demonstrably novel research hypotheses and proposals, building upon prior evidence and aligned to scientist-provided research objectives and guidance. The system's design incorporates a generate, debate, and evolve approach to hypothesis generation, inspired by the scientific method and accelerated by scaling test-time compute. Key contributions include: (1) a multi-agent architecture with an asynchronous task execution framework for flexible compute scaling; (2) a tournament evolution process for self-improving hypotheses generation. Automated evaluations show continued benefits of test-time compute, improving hypothesis quality. While general purpose, we focus development and validation in three biomedical areas: drug repurposing, novel target discovery, and explaining mechanisms of bacterial evolution and anti-microbial resistance. For drug repurposing, the system proposes candidates with promising validation findings, including candidates for acute myeloid leukemia that show tumor inhibition in vitro at clinically applicable concentrations. For novel target discovery, the AI co-scientist proposed new epigenetic targets for liver fibrosis, validated by anti-fibrotic activity and liver cell regeneration in human hepatic organoids. Finally, the AI co-scientist recapitulated unpublished experimental results via a parallel in silico discovery of a novel gene transfer mechanism in bacterial evolution. These results, detailed in separate, co-timed reports, demonstrate the potential to augment biomedical and scientific discovery and usher an era of AI empowered scientists.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-LLM Collaborative Search for Complex Problem Solving</title>
<link>https://arxiv.org/abs/2502.18873</link>
<guid>https://arxiv.org/abs/2502.18873</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、混合搜索代理 (MoSA)、推理任务、蒙特卡洛树搜索 (MCTS)、多智能体

总结:
本文提出了一种名为“混合搜索代理”(MoSA)的新方法，旨在解决大型语言模型 (LLMs) 在处理复杂推理任务时面临的挑战。MoSA通过结合多个独立探索与迭代优化的LLM，利用多元推理路径来弥补单一模型方法的局限性。该方法以蒙特卡洛树搜索(MCTS)为基础，让多个代理能够提出并聚合推理步骤，从而提高准确性。实验结果表明，MoSA在四个不同推理基准测试上相较于单个代理和其他多智能体基线展现出更一致的性能提升，特别是在复杂的数学和常识推理任务中。<br /><br /> <div>
arXiv:2502.18873v1 Announce Type: new 
Abstract: Large language models (LLMs) often struggle with complex reasoning tasks due to their limitations in addressing the vast reasoning space and inherent ambiguities of natural language. We propose the Mixture-of-Search-Agents (MoSA) paradigm, a novel approach leveraging the collective expertise of multiple LLMs to enhance search-based reasoning. MoSA integrates diverse reasoning pathways by combining independent exploration with iterative refinement among LLMs, mitigating the limitations of single-model approaches. Using Monte Carlo Tree Search (MCTS) as a backbone, MoSA enables multiple agents to propose and aggregate reasoning steps, resulting in improved accuracy. Our comprehensive evaluation across four reasoning benchmarks demonstrates MoSA's consistent performance improvements over single-agent and other multi-agent baselines, particularly in complex mathematical and commonsense reasoning tasks.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Adaptive Shielding via Parametric Safety Proofs</title>
<link>https://arxiv.org/abs/2502.18879</link>
<guid>https://arxiv.org/abs/2502.18879</guid>
<content:encoded><![CDATA[
<div> 关键词：cyber-physical systems、learning-enabled controllers、safety、adaptive shields、runtime knowledge acquisition

总结:
本文提出了一个新的编程语言框架，用于解决部署具有学习控制器的 cyber-physical 系统的安全问题，特别是在需要运行时知识获取的动态环境中。该框架支持专家静态地为学习代理指定适应性防护盾，这种防护盾可以随着运行时知识的积累而逐步放宽安全控制范围。防护盾规范包含了一个与当前代理知识参数化相关的安全性模型，并且允许使用专门的领域特定语言来指定非确定性的推断策略，确保这些知识参数能在运行时以统计学上可靠的方式得到推理。通过利用语言设计和定理证明技术，该框架使专家能够以前所未有的建模灵活性设计适应性防护盾，同时提供了从头到尾严谨的概率安全性保证。 <div>
arXiv:2502.18879v1 Announce Type: new 
Abstract: A major challenge to deploying cyber-physical systems with learning-enabled controllers is to ensure their safety, especially in the face of changing environments that necessitate runtime knowledge acquisition. Model-checking and automated reasoning have been successfully used for shielding, i.e., to monitor untrusted controllers and override potentially unsafe decisions, but only at the cost of hard tradeoffs in terms of expressivity, safety, adaptivity, precision and runtime efficiency. We propose a programming-language framework that allows experts to statically specify adaptive shields for learning-enabled agents, which enforce a safe control envelope that gets more permissive as knowledge is gathered at runtime. A shield specification provides a safety model that is parametric in the current agent's knowledge. In addition, a nondeterministic inference strategy can be specified using a dedicated domain-specific language, enforcing that such knowledge parameters are inferred at runtime in a statistically-sound way. By leveraging language design and theorem proving, our proposed framework empowers experts to design adaptive shields with an unprecedented level of modeling flexibility, while providing rigorous, end-to-end probabilistic safety guarantees.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Letters from Future Self: Augmenting the Letter-Exchange Exercise with LLM-based Agents to Enhance Young Adults' Career Exploration</title>
<link>https://arxiv.org/abs/2502.18881</link>
<guid>https://arxiv.org/abs/2502.18881</guid>
<content:encoded><![CDATA[
<div> 关键词: Young adults, career exploration, letter-exchange exercise, Large Language Model (LLM), future-self agents

<br /><br />总结:
本文研究了青年在职业探索过程中面临的挑战以及自我引导干预措施的作用。文章提出了一种结合大型语言模型（LLM）代理的方法，该方法将未来自我的模拟融入信件交流练习中，以期提高此类干预措施的效果。实验为期一周，共有36名参与者，分为三个条件组：手动书写回信的基线组、由未来自我代理人生成信件的组别和与未来自我代理人进行聊天对话的组别。结果表明，通过与未来自我代理人的信件交换，可以提升参与者的参与度，而整个干预措施对未来的导向性、职业自我概念及心理支持等方面的总体益处在这三个条件下保持相当。文章还讨论了AI增强型干预措施在支持青年职业探索设计方面的影响和启示。 <div>
arXiv:2502.18881v1 Announce Type: new 
Abstract: Young adults often encounter challenges in career exploration. Self-guided interventions, such as the letter-exchange exercise, where participants envision and adopt the perspective of their future selves by exchanging letters with their envisioned future selves, can support career development. However, the broader adoption of such interventions may be limited without structured guidance. To address this, we integrated Large Language Model (LLM)-based agents that simulate participants' future selves into the letter-exchange exercise and evaluated their effectiveness. A one-week experiment (N=36) compared three conditions: (1) participants manually writing replies to themselves from the perspective of their future selves (baseline), (2) future-self agents generating letters to participants, and (3) future-self agents engaging in chat conversations with participants. Results indicated that exchanging letters with future-self agents enhanced participants' engagement during the exercise, while overall benefits of the intervention on future orientation, career self-concept, and psychological support remained comparable across conditions. We discuss design implications for AI-augmented interventions for supporting young adults' career exploration.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Distributed Online Task Assignment via Inexact ADMM for unplanned online tasks and its Applications to Security</title>
<link>https://arxiv.org/abs/2502.18893</link>
<guid>https://arxiv.org/abs/2502.18893</guid>
<content:encoded><![CDATA[
<div> 关键词: 多机器人系统(MRS), 任务分配算法, 分布式优化, 安全分析, 控制器

<br /><br />总结:
本文提出了一种应用于多机器人系统的分布式任务分配算法，该算法能够动态地为团队中的机器人分配强制性和可选的安全关键任务。该算法基于不精确的交替方向乘子法(ADMM)，将任务分配问题分解为可分离和不可分离的子问题，并通过投影梯度下降法将其转化为可在团队内部通信步骤中执行的更新过程。其次，文章构建了一个综合框架，使得受到计划偏离攻击的MRS能够在保障安全的前提下处理在线任务。该框架首先进行安全性分析以确定机器人能否安全执行在线任务及其重新加入团队所需的时间和地点。随后，利用提出的任务分配算法来安排安全相关任务及验证后的在线任务。最后，通过控制李雅普诺夫函数(CLF)为基础的控制器管理和实现任务履行，同时利用控制障碍函数(CBF)为基础的安全过滤器确保安全性。通过模拟实验展示了所提框架能使MRS有效地响应未计划的在线任务并保持安全保证。 <div>
arXiv:2502.18893v1 Announce Type: new 
Abstract: In multi-robot system (MRS) applications, efficient task assignment is essential not only for coordinating agents and ensuring mission success but also for maintaining overall system security. In this work, we first propose an optimization-based distributed task assignment algorithm that dynamically assigns mandatory security-critical tasks and optional tasks among teams. Leveraging an inexact Alternating Direction Method of Multipliers (ADMM)-based approach, we decompose the task assignment problem into separable and non-separable subproblems. The non-separable subproblems are transformed into an inexact ADMM update by projected gradient descent, which can be performed through several communication steps within the team.
  In the second part of this paper, we formulate a comprehensive framework that enables MRS under plan-deviation attacks to handle online tasks without compromising security. The process begins with a security analysis that determines whether an online task can be executed securely by a robot and, if so, the required time and location for the robot to rejoin the team. Next, the proposed task assignment algorithm is used to allocate security-related tasks and verified online tasks. Finally, task fulfillment is managed using a Control Lyapunov Function (CLF)-based controller, while security enforcement is ensured through a Control Barrier Function (CBF)-based security filter. Through simulations, we demonstrate that the proposed framework allows MRS to effectively respond to unplanned online tasks while maintaining security guarantees.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model</title>
<link>https://arxiv.org/abs/2502.18906</link>
<guid>https://arxiv.org/abs/2502.18906</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Models (VLMs)，Graphical User Interfaces (GUI)，Reinforcement Learning (RL)，Value Environment Model (VEM)，Android-in-the-Wild

总结:
本文提出了一种环境自由的强化学习框架，用于训练针对GUI代理的视觉语言模型。该框架通过预训练的价值环境模型(VEM)解决了环境基RL所需的昂贵交互问题以及环境自由方法面临的分布偏移和奖励泛化挑战。VEM能直接从离线数据中预测状态-动作值，无需预测下一个状态或环境反馈，从而提炼出关于GUI交互结果的人类类似优先级理解，降低了误差累积并增强了对UI变化的适应性。框架分为两阶段：(1) 预训练VEM以估计长期行动效用；(2) 使用冻结的VEM信号引导策略探索，实现布局无关的GUI自动化。在Android-in-the-Wild基准测试中，VEM在离线和在线设置下均达到最佳性能，显著优于环境自由基线，并与需要交互成本的环境基方法表现相当。重要的是，VEM表明语义感知的价值估计可以实现与在线训练方法相媲美的性能。 <div>
arXiv:2502.18906v1 Announce Type: new 
Abstract: Training Vision-Language Models (VLMs) for Graphical User Interfaces (GUI) agents via Reinforcement Learning (RL) faces critical challenges: environment-based RL requires costly interactions, while environment-free methods struggle with distribution shift and reward generalization. We propose an environment-free RL framework that decouples value estimation from policy optimization by leveraging a pretrained Value Environment Model (VEM). VEM predicts state-action values directly from offline data, distilling human-like priors about GUI interaction outcomes without requiring next-state prediction or environmental feedback. This avoids compounding errors and enhances resilience to UI changes by focusing on semantic reasoning (e.g., Does this action advance the user's goal?). The framework operates in two stages: (1) pretraining VEM to estimate long-term action utilities and (2) guiding policy exploration with frozen VEM signals, enabling layout-agnostic GUI automation. Evaluated on Android-in-the-Wild benchmarks, VEM achieves state-of-the-art performance in both offline and online settings, outperforming environment-free baselines significantly and matching environment-based approaches without interaction costs. Importantly, VEM demonstrates that semantic-aware value estimation can achieve comparable performance with online-trained methods.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Fewer May Be Better: Enhancing Offline Reinforcement Learning with Reduced Dataset</title>
<link>https://arxiv.org/abs/2502.18955</link>
<guid>https://arxiv.org/abs/2502.18955</guid>
<content:encoded><![CDATA[
<div> 关键词：离线强化学习（Offline Reinforcement Learning）、数据集选择、ReDOR、梯度逼近优化问题、正交匹配追踪（Orthogonal Matching Pursuit）

总结:
本文介绍了针对离线强化学习的研究新方法ReDOR，该方法着重解决如何从预收集的数据集中选择最优子集以提升算法性能和训练效率这一关键而未充分探索的挑战。ReDOR将数据集选择视为一个梯度逼近优化问题，并通过将常见的actor-critic框架重新表述为子模优化目标，实现了高效子集选取。为此，文章采用了正交匹配追踪(OMP)并进行了适应性的修改，特别针对离线RL场景。实验结果显示，通过ReDOR识别出的数据子集不仅能显著提高算法性能，而且还能以更低的计算复杂性实现这一目标。 <div>
arXiv:2502.18955v1 Announce Type: new 
Abstract: Offline reinforcement learning (RL) represents a significant shift in RL research, allowing agents to learn from pre-collected datasets without further interaction with the environment. A key, yet underexplored, challenge in offline RL is selecting an optimal subset of the offline dataset that enhances both algorithm performance and training efficiency. Reducing dataset size can also reveal the minimal data requirements necessary for solving similar problems. In response to this challenge, we introduce ReDOR (Reduced Datasets for Offline RL), a method that frames dataset selection as a gradient approximation optimization problem. We demonstrate that the widely used actor-critic framework in RL can be reformulated as a submodular optimization objective, enabling efficient subset selection. To achieve this, we adapt orthogonal matching pursuit (OMP), incorporating several novel modifications tailored for offline RL. Our experimental results show that the data subsets identified by ReDOR not only boost algorithm performance but also do so with significantly lower computational complexity.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Overcoming the Price of Anarchy by Steering with Recommendations</title>
<link>https://arxiv.org/abs/2502.18988</link>
<guid>https://arxiv.org/abs/2502.18988</guid>
<content:encoded><![CDATA[
<div> 关键词：协调问题、价格混乱、推荐系统、Braess悖论、Q学习者

总结:
本文研究了多种现实世界的系统中协调问题，例如交通网络、供应链和能源网格，其中许多代理实体需要学会共享资源。文中指出独立且自私的交互可能导致效率低下，即所谓的“价格混乱”。文章关注于利用推荐系统作为减少价格混乱并保持个体自主性的有效干预手段。以与道路交通、互联网数据包传输及电力电网相关的Braess悖论为例，作者采用近期文献中的方法，将代理实体之间的交互建模为Q学习者的重复游戏。文章提出了学习动态操纵问题，即外部推荐系统可以通过选择Q学习者在学习过程中观察到的状态来策略性地引导行为。计算贡献部分表明，适当的选择性推荐可以稳健地引导系统收敛至社会最优解，即使涉及多个玩家也是如此。理论和实证结果强调，推荐空间的增加能够提高推荐系统的引导潜力，这一点应在设计推荐系统时予以考虑。 <div>
arXiv:2502.18988v1 Announce Type: new 
Abstract: Varied real world systems such as transportation networks, supply chains and energy grids present coordination problems where many agents must learn to share resources. It is well known that the independent and selfish interactions of agents in these systems may lead to inefficiencies, often referred to as the `Price of Anarchy'. Effective interventions that reduce the Price of Anarchy while preserving individual autonomy are of great interest. In this paper we explore recommender systems as one such intervention mechanism. We start with the Braess Paradox, a congestion game model of a routing problem related to traffic on roads, packets on the internet, and electricity on power grids. Following recent literature, we model the interactions of agents as a repeated game between $Q$-learners, a common type of reinforcement learning agents. This work introduces the Learning Dynamic Manipulation Problem, where an external recommender system can strategically trigger behavior by picking the states observed by $Q$-learners during learning. Our computational contribution demonstrates that appropriately chosen recommendations can robustly steer the system towards convergence to the social optimum, even for many players. Our theoretical and empirical results highlight that increases in the recommendation space can increase the steering potential of a recommender system, which should be considered in the design of recommender systems.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Ground-level Viewpoint Vision-and-Language Navigation in Continuous Environments</title>
<link>https://arxiv.org/abs/2502.19024</link>
<guid>https://arxiv.org/abs/2502.19024</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-and-Language Navigation (VLN)，Ground-level Viewpoint Navigation (GVNav)，quadruped 机器人，视觉多样性，通用性挑战

总结:<br />
本文提出了一个名为Ground-level Viewpoint Navigation (GVNav)的方法，旨在解决视觉与语言导航(VLN)中因人类视角指令与低高度视野四足机器人的差距所带来的问题。GVNav通过使用加权的历史观察结果作为增强的时空上下文来改进指令跟随，有效地处理不同视角下相同特征的权重分配，帮助低高度机器人克服视觉遮挡和感知不匹配的挑战。此外，该方法还利用HM3D和Gibson数据集中的连通性图，以增强空间先验知识和更全面地表征现实世界场景，从而提升在真实环境中预测路点的性能和泛化能力。实验表明，GVNav方法在模拟环境和真实的四足机器人部署中都显著提高了性能。 <div>
arXiv:2502.19024v1 Announce Type: new 
Abstract: Vision-and-Language Navigation (VLN) empowers agents to associate time-sequenced visual observations with corresponding instructions to make sequential decisions. However, generalization remains a persistent challenge, particularly when dealing with visually diverse scenes or transitioning from simulated environments to real-world deployment. In this paper, we address the mismatch between human-centric instructions and quadruped robots with a low-height field of view, proposing a Ground-level Viewpoint Navigation (GVNav) approach to mitigate this issue. This work represents the first attempt to highlight the generalization gap in VLN across varying heights of visual observation in realistic robot deployments. Our approach leverages weighted historical observations as enriched spatiotemporal contexts for instruction following, effectively managing feature collisions within cells by assigning appropriate weights to identical features across different viewpoints. This enables low-height robots to overcome challenges such as visual obstructions and perceptual mismatches. Additionally, we transfer the connectivity graph from the HM3D and Gibson datasets as an extra resource to enhance spatial priors and a more comprehensive representation of real-world scenarios, leading to improved performance and generalizability of the waypoint predictor in real-world environments. Extensive experiments demonstrate that our Ground-level Viewpoint Navigation (GVnav) approach significantly improves performance in both simulated environments and real-world deployments with quadruped robots.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>IndicEval-XL: Bridging Linguistic Diversity in Code Generation Across Indic Languages</title>
<link>https://arxiv.org/abs/2502.19067</link>
<guid>https://arxiv.org/abs/2502.19067</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，代码生成，多语种，IndicEval-XL，基准评测

总结:
本文介绍了大型语言模型（LLMs）在自然语言提示驱动的代码生成方面的显著能力及其对软件开发工作流的革新作用。然而，当前评估多语种代码生成能力的基准主要以英语为中心，限制了其在全球开发者社区中的适用性。为解决这一问题，文章提出了IndicEval-XL，一个全面的代码生成基准评测，该评测涵盖了大约占世界人口14%的六大印度语言，并将这些语言与12种编程语言相结合，构建了一个强大的评价框架。鉴于印度占据全球人口的八分之一以及印度语言在印度社会中的重要角色，IndicEval-XL对于扩展代码生成系统和评价框架的语言多样性具有重要意义。通过支持多种语言的研发资源，旨在使AI驱动的开发工具更加包容并易于不同语言背景的开发者使用。为了促进这一领域的进一步研究和发展，作者将其数据集和评价基准公开发布在https://github.com/telekom/IndicEval-XL上。 <div>
arXiv:2502.19067v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in code generation from natural language prompts, revolutionizing software development workflows. As we advance towards agent-based development paradigms, these models form the cornerstone of next-generation software development lifecycles. However, current benchmarks for evaluating multilingual code generation capabilities are predominantly English-centric, limiting their applicability across the global developer community. To address this limitation, we present IndicEval-XL, a comprehensive benchmark for code generation that incorporates 6 major Indic languages, collectively spoken by approximately 14\% of the world's population. Our benchmark bridges these languages with 12 programming languages, creating a robust evaluation framework. This work is particularly significant given India's representation of one-eighth of the global population and the crucial role Indic languages play in Indian society. IndicEval-XL represents a significant step toward expanding the linguistic diversity in code generation systems and evaluation frameworks. By developing resources that support multiple languages, we aim to make AI-powered development tools more inclusive and accessible to developers of various linguistic backgrounds. To facilitate further research and development in this direction, we make our dataset and evaluation benchmark publicly available at https://github.com/telekom/IndicEval-XL
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>XSS Adversarial Attacks Based on Deep Reinforcement Learning: A Replication and Extension Study</title>
<link>https://arxiv.org/abs/2502.19095</link>
<guid>https://arxiv.org/abs/2502.19095</guid>
<content:encoded><![CDATA[
<div> 关键词：跨站脚本攻击(XSS)，深度学习(DL)，对抗性攻击，威胁评估，XSS Oracle

总结:<br />
本文探讨了跨站脚本攻击(XSS)对网络应用安全构成的重大威胁。尽管深度学习(DL)在检测XSS攻击方面表现出色，但它仍然容易受到由于输入-输出映射非连续性导致的对抗性攻击。研究中，作者复现了一种先进的XSS对抗性攻击方法，并指出了原参考工作中的威胁到有效性的问题，并对其进行了扩展，提出了更为有效的评价策略。此外，文章还引入了一个名为XSS Oracle的工具来缓解这些威胁。实验结果显示，当解决了复制技术中的威胁有效性问题后，我们的方法实现了超过96%的逃逸率。 <div>
arXiv:2502.19095v1 Announce Type: new 
Abstract: Cross-site scripting (XSS) poses a significant threat to web application security. While Deep Learning (DL) has shown remarkable success in detecting XSS attacks, it remains vulnerable to adversarial attacks due to the discontinuous nature of its input-output mapping. These adversarial attacks employ mutation-based strategies for different components of XSS attack vectors, allowing adversarial agents to iteratively select mutations to evade detection. Our work replicates a state-of-the-art XSS adversarial attack, highlighting threats to validity in the reference work and extending it toward a more effective evaluation strategy. Moreover, we introduce an XSS Oracle to mitigate these threats. The experimental results show that our approach achieves an escape rate above 96% when the threats to validity of the replicated technique are addressed.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Language-Driven Opinion Dynamics in Agent-Based Simulations with LLMs</title>
<link>https://arxiv.org/abs/2502.19098</link>
<guid>https://arxiv.org/abs/2502.19098</guid>
<content:encoded><![CDATA[
<div> 关键词: 意见演化、语言驱动、意见动态模型、逻辑谬误、人工智能

<br />
总结:
本文研究了在社会系统中意见演化的现象，重点关注语言和论证谬误的影响。为了填补这一研究空白，作者提出了LODAS——一种基于代理的模拟语言驱动的意见动态模型。该模型通过模拟围绕“忒修斯之船”悖论的辩论，探讨了不同意见分布（平衡、极化和不平衡）下，代理人如何通过接受、拒绝或忽略提出的论点来演变其观点。研究发现，LLM（大型语言模型）代理人在互动过程中展现出趋同性和迎合性特征，几乎在任何环境下都能达成共识。此外，这些AI代理往往会产生说服性但含有逻辑谬误的论点，并且他们容易受到建立在逻辑谬误基础上的论点影响。这一框架不仅可用于模拟社会动态，还有助于从另一个角度探究LLMs的偏见和缺陷，及其可能对与人类交互产生的影响。 <div>
arXiv:2502.19098v1 Announce Type: new 
Abstract: Understanding how opinions evolve is crucial for addressing issues such as polarization, radicalization, and consensus in social systems. While much research has focused on identifying factors influencing opinion change, the role of language and argumentative fallacies remains underexplored. This paper aims to fill this gap by investigating how language - along with social dynamics - influences opinion evolution through LODAS, a Language-Driven Opinion Dynamics Model for Agent-Based Simulations. The model simulates debates around the "Ship of Theseus" paradox, in which agents with discrete opinions interact with each other and evolve their opinions by accepting, rejecting, or ignoring the arguments presented. We study three different scenarios: balanced, polarized, and unbalanced opinion distributions. Agreeableness and sycophancy emerge as two main characteristics of LLM agents, and consensus around the presented statement emerges almost in any setting. Moreover, such AI agents are often producers of fallacious arguments in the attempt of persuading their peers and - for their complacency - they are also highly influenced by arguments built on logical fallacies. These results highlight the potential of this framework not only for simulating social dynamics but also for exploring from another perspective biases and shortcomings of LLMs, which may impact their interactions with humans.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Voting or Consensus? Decision-Making in Multi-Agent Debate</title>
<link>https://arxiv.org/abs/2502.19130</link>
<guid>https://arxiv.org/abs/2502.19130</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体辩论、决策协议、系统评估、知识任务、推理任务

<br /><br />总结:
本文研究了多智能体辩论中决策协议对任务完成效果的影响。通过对七种不同的决策协议进行系统性评估，仅改变单一变量（即决策协议），分析不同方法如何影响智能体间的协作以及在知识和推理任务上的表现。实验结果显示，投票协议在推理任务上提升性能13.2%，共识协议在知识任务上提升2.8%。增加智能体数量能提高性能，而增加讨论轮次则会降低性能。为增强答案多样性并优化决策过程，文章提出了两种新方法——全智能体起草(AAD)和集体改进(CI)，这两种方法分别最多可使任务性能提升3.3%和7.4%。该工作强调了在多智能体辩论中，除了规模扩大之外，决策制定的重要性。 <div>
arXiv:2502.19130v1 Announce Type: new 
Abstract: Much of the success of multi-agent debates depends on carefully choosing the right parameters. Among them, the decision-making protocol stands out. Systematic comparison of decision protocols is difficult because studies alter multiple discussion parameters beyond the protocol. So far, it has been largely unknown how decision-making addresses the challenges of different tasks. This work systematically evaluates the impact of seven decision protocols (e.g., majority voting, unanimity consensus). We change only one variable at a time (i.e., decision protocol) to analyze how different methods affect the collaboration between agents and test different protocols on knowledge (MMLU, MMLU-Pro, GPQA) and reasoning datasets (StrategyQA, MuSR, SQuAD 2.0). Our results show that voting protocols improve performance by 13.2% in reasoning tasks and consensus protocols by 2.8% in knowledge tasks over the other decision protocol. Increasing the number of agents improves performance, while more discussion rounds before voting reduces it. To improve decision-making by increasing answer diversity, we propose two new methods, All-Agents Drafting (AAD) and Collective Improvement (CI). Our methods improve task performance by up to 3.3% with AAD and up to 7.4% with CI. This work demonstrates the importance of decision-making in multi-agent debates beyond scaling.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Security Tax: Trading Off Security and Collaboration Capabilities in Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.19145</link>
<guid>https://arxiv.org/abs/2502.19145</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、安全风险、多智能体系统、恶意指令、防御策略

总结:
本文探讨了随着AI代理在复杂目标协作中广泛应用，确保自主多智能体系统的安全性变得至关重要。研究通过模拟多个代理人合作共享目标的情境来分析其中的安全风险和安全权衡。文章重点关注一种攻击场景，即攻击者通过妥协一个代理来引导整个系统偏离正确目标，通过污染其他代理传播恶意指令。作者观察到恶意指令具有传染性特征。为减轻此类风险，文中评估了两种“疫苗”防御方法（向代理的记忆流插入安全处理恶意输入的假记忆）以及两种通用安全指令策略。虽然这些防御措施在实验中减少了恶意指令的传播和执行，但它们也降低了代理网络的合作能力。这项研究表明，在多智能体系统中可能存在安全性和协作效率之间的权衡，并为设计更安全而有效的AI协作提供了见解。 <div>
arXiv:2502.19145v1 Announce Type: new 
Abstract: As AI agents are increasingly adopted to collaborate on complex objectives, ensuring the security of autonomous multi-agent systems becomes crucial. We develop simulations of agents collaborating on shared objectives to study these security risks and security trade-offs. We focus on scenarios where an attacker compromises one agent, using it to steer the entire system toward misaligned outcomes by corrupting other agents. In this context, we observe infectious malicious prompts - the multi-hop spreading of malicious instructions. To mitigate this risk, we evaluated several strategies: two "vaccination" approaches that insert false memories of safely handling malicious input into the agents' memory stream, and two versions of a generic safety instruction strategy. While these defenses reduce the spread and fulfillment of malicious instructions in our experiments, they tend to decrease collaboration capability in the agent network. Our findings illustrate potential trade-off between security and collaborative efficiency in multi-agent systems, providing insights for designing more secure yet effective AI collaborations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MEDDxAgent: A Unified Modular Agent Framework for Explainable Automatic Differential Diagnosis</title>
<link>https://arxiv.org/abs/2502.19175</link>
<guid>https://arxiv.org/abs/2502.19175</guid>
<content:encoded><![CDATA[
<div> 关键词: 差异诊断(Differential Diagnosis, DDx)、大型语言模型、MEDDxAgent、迭代学习、交互式诊断

<br /><br />总结:
本文介绍了针对临床决策中的关键问题——差异诊断（DDx）所提出的一种新的框架：模块化可解释DDx代理（MEDDxAgent）。该框架设计用于支持交互式的DDx过程，通过迭代学习不断优化诊断推理，而不依赖于一开始就具备完整的患者信息。MEDDxAgent由三个模块组成： Orchestrator（DDxDriver）、病史模拟器以及两个专门负责知识检索和诊断策略的智能体。为了确保评估的全面性，研究者引入了一个涵盖呼吸系统、皮肤疾病及罕见病的综合DDx基准。实验结果显示，在无法立即获得完整患者资料的情况下，单次诊断方法的效果不如采用迭代细化的方式，并表明MEDDxAgent能在大、小型语言模型上实现超过10%的互动式DDx准确率提升，同时为其诊断推理过程提供了关键的可解释性。 <div>
arXiv:2502.19175v1 Announce Type: new 
Abstract: Differential Diagnosis (DDx) is a fundamental yet complex aspect of clinical decision-making, in which physicians iteratively refine a ranked list of possible diseases based on symptoms, antecedents, and medical knowledge. While recent advances in large language models have shown promise in supporting DDx, existing approaches face key limitations, including single-dataset evaluations, isolated optimization of components, unrealistic assumptions about complete patient profiles, and single-attempt diagnosis. We introduce a Modular Explainable DDx Agent (MEDDxAgent) framework designed for interactive DDx, where diagnostic reasoning evolves through iterative learning, rather than assuming a complete patient profile is accessible. MEDDxAgent integrates three modular components: (1) an orchestrator (DDxDriver), (2) a history taking simulator, and (3) two specialized agents for knowledge retrieval and diagnosis strategy. To ensure robust evaluation, we introduce a comprehensive DDx benchmark covering respiratory, skin, and rare diseases. We analyze single-turn diagnostic approaches and demonstrate the importance of iterative refinement when patient profiles are not available at the outset. Our broad evaluation demonstrates that MEDDxAgent achieves over 10% accuracy improvements in interactive DDx across both large and small LLMs, while offering critical explainability into its diagnostic reasoning process.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Simulation of Language Evolution under Regulated Social Media Platforms: A Synergistic Approach of Large Language Models and Genetic Algorithms</title>
<link>https://arxiv.org/abs/2502.19193</link>
<guid>https://arxiv.org/abs/2502.19193</guid>
<content:encoded><![CDATA[
<div> 关键词：社交平台、内容审核、语言策略、多智能体框架、遗传算法

总结:
本文介绍了一种基于大型语言模型（LLMs）的多智能体框架，用于模拟在监管约束下用户内容语言策略的迭代演化。该框架中的参与型智能体代表社交媒体用户，不断进化其语言表达方式；而监督型智能体则模仿平台级别的内容审查。为了更真实地模拟实际情况，研究采用了语言策略的双重设计（约束和表达），区分了相互冲突的目标，并利用LLM驱动的遗传算法进行语言策略的选择、变异和交叉操作。通过抽象密码游戏和非法宠物交易场景的两个不同案例进行评估，实验结果表明，随着对话轮数的增加，未中断的对话回合数以及信息传输的准确性均有显著提升。此外，一项涉及40名参与者的用户研究表明，生成的对话和策略具有现实世界的相关性。进一步的消融研究表明，遗传算法对于系统的长期适应性和整体性能提升至关重要。 <div>
arXiv:2502.19193v1 Announce Type: new 
Abstract: Social media platforms frequently impose restrictive policies to moderate user content, prompting the emergence of creative evasion language strategies. This paper presents a multi-agent framework based on Large Language Models (LLMs) to simulate the iterative evolution of language strategies under regulatory constraints. In this framework, participant agents, as social media users, continuously evolve their language expression, while supervisory agents emulate platform-level regulation by assessing policy violations. To achieve a more faithful simulation, we employ a dual design of language strategies (constraint and expression) to differentiate conflicting goals and utilize an LLM-driven GA (Genetic Algorithm) for the selection, mutation, and crossover of language strategies. The framework is evaluated using two distinct scenarios: an abstract password game and a realistic simulated illegal pet trade scenario. Experimental results demonstrate that as the number of dialogue rounds increases, both the number of uninterrupted dialogue turns and the accuracy of information transmission improve significantly. Furthermore, a user study with 40 participants validates the real-world relevance of the generated dialogues and strategies. Moreover, ablation studies validate the importance of the GA, emphasizing its contribution to long-term adaptability and improved overall results.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ProxyTransformation: Preshaping Point Cloud Manifold With Proxy Attention For 3D Visual Grounding</title>
<link>https://arxiv.org/abs/2502.19247</link>
<guid>https://arxiv.org/abs/2502.19247</guid>
<content:encoded><![CDATA[
<div> 关键词: 代理变换、多模态任务、三维视觉定位、点云增强、实时交互

<br />
总结:
本文提出了适用于多模态任务的代理变换方法，以有效改善用于基于语言指令的实时三维环境交互中，从RGB-D图像渲染得到的含有大量冗余背景数据和噪声的点云的局部流形结构。该方法首先利用可变形点聚类识别目标区域内的点云子流形，接着提出一种代理注意力模块，使用多模态代理来指导点云变换。在此基础上，设计了一个子流形变换生成模块，其中文本信息全局引导不同子流形的平移向量，优化目标区域的相对空间关系；同时，图像信息指导每个子流形内部的线性变换，细化目标区域的局部点云流形。实验表明，Proxy Transformation 方法显著优于现有方法，在易目标上提高了7.49%，在难目标上提高了4.60%，并且减少了注意力块的计算开销达40.6%。这些结果为第一人称视角的三维视觉定位建立了新的SOTA，证明了所提方法的有效性和鲁棒性。 <div>
arXiv:2502.19247v1 Announce Type: new 
Abstract: Embodied intelligence requires agents to interact with 3D environments in real time based on language instructions. A foundational task in this domain is ego-centric 3D visual grounding. However, the point clouds rendered from RGB-D images retain a large amount of redundant background data and inherent noise, both of which can interfere with the manifold structure of the target regions. Existing point cloud enhancement methods often require a tedious process to improve the manifold, which is not suitable for real-time tasks. We propose Proxy Transformation suitable for multimodal task to efficiently improve the point cloud manifold. Our method first leverages Deformable Point Clustering to identify the point cloud sub-manifolds in target regions. Then, we propose a Proxy Attention module that utilizes multimodal proxies to guide point cloud transformation. Built upon Proxy Attention, we design a submanifold transformation generation module where textual information globally guides translation vectors for different submanifolds, optimizing relative spatial relationships of target regions. Simultaneously, image information guides linear transformations within each submanifold, refining the local point cloud manifold of target regions. Extensive experiments demonstrate that Proxy Transformation significantly outperforms all existing methods, achieving an impressive improvement of 7.49% on easy targets and 4.60% on hard targets, while reducing the computational overhead of attention blocks by 40.6%. These results establish a new SOTA in ego-centric 3D visual grounding, showcasing the effectiveness and robustness of our approach.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>EMT: A Visual Multi-Task Benchmark Dataset for Autonomous Driving in the Arab Gulf Region</title>
<link>https://arxiv.org/abs/2502.19260</link>
<guid>https://arxiv.org/abs/2502.19260</guid>
<content:encoded><![CDATA[
<div> 关键词：Emirates Multi-Task (EMT) 数据集、自动驾驶、阿拉伯海湾地区、道路拓扑、轨迹预测

总结:
<br />
本文介绍了首个公开可用的阿拉伯海湾地区自动驾驶数据集——Emirates Multi-Task (EMT) 数据集。该数据集捕捉了这一地区独特的道路地形、高交通拥堵情况以及行人服装和天气条件等特点，包含了超过30,000帧的车载摄像头视角画面以及约570,000个标注的边界框，覆盖大约150公里的驾驶路线。EMT数据集支持三个主要任务：跟踪、轨迹预测和意图预测，并为每个基准测试提供了相应的评估方法，包括多目标跟踪实验（关注多类别场景和遮挡处理）、使用深度序列和交互感知模型的轨迹预测评估，以及从观察到的轨迹预测代理人意图的意图基准实验。该数据集可在https://avlab.io/emt-dataset 公开获取，预处理脚本及评估模型可访问https://github.com/AV-Lab/emt-dataset 获取。 <div>
arXiv:2502.19260v1 Announce Type: new 
Abstract: This paper introduces the Emirates Multi-Task (EMT) dataset - the first publicly available dataset for autonomous driving collected in the Arab Gulf region. The EMT dataset captures the unique road topology, high traffic congestion, and distinctive characteristics of the Gulf region, including variations in pedestrian clothing and weather conditions. It contains over 30,000 frames from a dash-camera perspective, along with 570,000 annotated bounding boxes, covering approximately 150 kilometers of driving routes. The EMT dataset supports three primary tasks: tracking, trajectory forecasting and intention prediction. Each benchmark dataset is complemented with corresponding evaluations: (1) multi-agent tracking experiments, focusing on multi-class scenarios and occlusion handling; (2) trajectory forecasting evaluation using deep sequential and interaction-aware models; and (3) intention benchmark experiments conducted for predicting agents intentions from observed trajectories. The dataset is publicly available at https://avlab.io/emt-dataset, and pre-processing scripts along with evaluation models can be accessed at https://github.com/AV-Lab/emt-dataset.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CritiQ: Mining Data Quality Criteria from Human Preferences</title>
<link>https://arxiv.org/abs/2502.19279</link>
<guid>https://arxiv.org/abs/2502.19279</guid>
<content:encoded><![CDATA[
<div> 关键词: CritiQ, 数据选择, 语言模型, 人类偏好, 继续训练

总结:
本文介绍了CritiQ，一种新的数据选择方法，旨在优化语言模型性能。CritiQ仅需约30对人工标注的数据即可自动挖掘出基于人类偏好的质量标准。其核心组件CritiQ Flow采用经理代理来进化质量标准，而工作者代理则进行pairwise判断。为了提升CritiQ Flow的效果，建立了从以往工作提取质量标准的知识库。与基于困惑度和分类器的方法相比，使用CritiQ得到的质量标准更具有可解释性和可复用性。利用这些标准，CritiQ Scorer为数据打分并进行高效选择。实验表明，该方法在代码、数学和逻辑等领域均取得高准确性，并通过继续训练Llama 3.1模型，相较于均匀采样，下游任务性能有所提升。此外，消融研究证实了知识库和反思过程的优势。文章还分析了标准的演化以及多数投票的有效性。 <div>
arXiv:2502.19279v1 Announce Type: new 
Abstract: Language model heavily depends on high-quality data for optimal performance. Existing approaches rely on manually designed heuristics, the perplexity of existing models, training classifiers, or careful prompt engineering, which require significant expert experience and human annotation effort while introduce biases. We introduce CritiQ, a novel data selection method that automatically mines criteria from human preferences for data quality with only $\sim$30 human-annotated pairs and performs efficient data selection. The main component, CritiQ Flow, employs a manager agent to evolve quality criteria and worker agents to make pairwise judgments. We build a knowledge base that extracts quality criteria from previous work to boost CritiQ Flow. Compared to perplexity- and classifier- based methods, verbal criteria are more interpretable and possess reusable value. After deriving the criteria, we train the CritiQ Scorer to give quality scores and perform efficient data selection. We demonstrate the effectiveness of our method in the code, math, and logic domains, achieving high accuracy on human-annotated test sets. To validate the quality of the selected data, we continually train Llama 3.1 models and observe improved performance on downstream tasks compared to uniform sampling. Ablation studies validate the benefits of the knowledge base and the reflection process. We analyze how criteria evolve and the effectiveness of majority voting.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Combining Planning and Reinforcement Learning for Solving Relational Multiagent Domains</title>
<link>https://arxiv.org/abs/2502.19297</link>
<guid>https://arxiv.org/abs/2502.19297</guid>
<content:encoded><![CDATA[
<div> 关键词：Multiagent Reinforcement Learning (MARL)，样本效率，一般化，关系设定，强化学习与规划集成

总结:
<br />
本文针对多智能体强化学习（MARL）面临的因状态和动作空间指数增长以及非平稳环境导致的显著样本效率低下和泛化能力不足的问题。特别是在关系设定中，尽管领域知识至关重要，但现有的MARL算法往往未能充分利用。为解决这些问题，文章提出将关系规划器作为集中式控制器，结合有效的状态抽象和强化学习进行集成。这种方法证明了其样例效率高，并有助于实现任务转移和泛化的有效提升。 <div>
arXiv:2502.19297v1 Announce Type: new 
Abstract: Multiagent Reinforcement Learning (MARL) poses significant challenges due to the exponential growth of state and action spaces and the non-stationary nature of multiagent environments. This results in notable sample inefficiency and hinders generalization across diverse tasks. The complexity is further pronounced in relational settings, where domain knowledge is crucial but often underutilized by existing MARL algorithms. To overcome these hurdles, we propose integrating relational planners as centralized controllers with efficient state abstractions and reinforcement learning. This approach proves to be sample-efficient and facilitates effective task transfer and generalization.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agent-centric Information Access</title>
<link>https://arxiv.org/abs/2502.19298</link>
<guid>https://arxiv.org/abs/2502.19298</guid>
<content:encoded><![CDATA[
<div> 关键词：大规模语言模型、专家系统、信息访问框架、动态排名、查询效率

<br /><br />总结:
本文提出了一个面向大规模专家语言模型的信息访问框架，预见到未来存在数百万个专注于特定领域的专用LLM。该框架中，LLM被视为具有动态排名和基于其展现的专业知识进行查询的知识代理。与传统的文档检索不同，该方法需要实时推断模型的专业技能，而非依赖静态元数据或预定义模型描述。针对高效专家选择、成本效益高的查询、多模型响应聚合以及对抗性操纵鲁棒性等挑战，文章提出了一种可扩展的评估框架，利用检索增强生成和聚类技术来构建并评估数千个专门模型，并有望扩展到数百万规模。 <div>
arXiv:2502.19298v1 Announce Type: new 
Abstract: As large language models (LLMs) become more specialized, we envision a future where millions of expert LLMs exist, each trained on proprietary data and excelling in specific domains. In such a system, answering a query requires selecting a small subset of relevant models, querying them efficiently, and synthesizing their responses. This paper introduces a framework for agent-centric information access, where LLMs function as knowledge agents that are dynamically ranked and queried based on their demonstrated expertise. Unlike traditional document retrieval, this approach requires inferring expertise on the fly, rather than relying on static metadata or predefined model descriptions. This shift introduces several challenges, including efficient expert selection, cost-effective querying, response aggregation across multiple models, and robustness against adversarial manipulation. To address these issues, we propose a scalable evaluation framework that leverages retrieval-augmented generation and clustering techniques to construct and assess thousands of specialized models, with the potential to scale toward millions.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WOFOSTGym: A Crop Simulator for Learning Annual and Perennial Crop Management Strategies</title>
<link>https://arxiv.org/abs/2502.19308</link>
<guid>https://arxiv.org/abs/2502.19308</guid>
<content:encoded><![CDATA[
<div> 关键词: WOFOSTGym、强化学习(RL)、作物模拟环境、多农场设置、年生和多年生作物

总结:
WOFOSTGym 是一款新的作物模拟环境，旨在训练强化学习(RL)智能体以优化单一及多农场环境中年生和多年生作物的农业管理决策。该环境解决了现有模拟器在多年生作物多农场场景以及对多种年生作物支持不足的问题，支持了23种年生作物和两种多年生作物，使RL智能体能在多年、多作物、多农场背景下学习多样化的农业管理策略。此外，WOFOSTGym还提供了具有部分可观测性、非马尔可夫动态和延迟反馈等挑战性的任务。其标准的RL接口使得缺乏农业专业知识的研究者也能探索各种农业管理问题。实验展示了RL智能体在不同作物品种和土壤类型中的学习行为，彰显了WOFOSTGym在推动基于RL驱动的农业决策支持方面所具有的潜力。 <div>
arXiv:2502.19308v1 Announce Type: new 
Abstract: We introduce WOFOSTGym, a novel crop simulation environment designed to train reinforcement learning (RL) agents to optimize agromanagement decisions for annual and perennial crops in single and multi-farm settings. Effective crop management requires optimizing yield and economic returns while minimizing environmental impact, a complex sequential decision-making problem well suited for RL. However, the lack of simulators for perennial crops in multi-farm contexts has hindered RL applications in this domain. Existing crop simulators also do not support multiple annual crops. WOFOSTGym addresses these gaps by supporting 23 annual crops and two perennial crops, enabling RL agents to learn diverse agromanagement strategies in multi-year, multi-crop, and multi-farm settings. Our simulator offers a suite of challenging tasks for learning under partial observability, non-Markovian dynamics, and delayed feedback. WOFOSTGym's standard RL interface allows researchers without agricultural expertise to explore a wide range of agromanagement problems. Our experiments demonstrate the learned behaviors across various crop varieties and soil types, highlighting WOFOSTGym's potential for advancing RL-driven decision support in agriculture.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CoopDETR: A Unified Cooperative Perception Framework for 3D Detection via Object Query</title>
<link>https://arxiv.org/abs/2502.19313</link>
<guid>https://arxiv.org/abs/2502.19313</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主驾驶车辆, 合作感知, 传输成本, CoopDETR, 对象级特征合作

总结:
本文提出了一种新型的合作感知框架CoopDETR，旨在解决自动驾驶车辆(AVs)的合作感知问题并优化传输成本。该框架通过对象查询实现对象级特征合作，包含两个关键模块：单-Agent查询生成，能有效将原始传感器数据编码为对象查询，降低传输成本的同时保持检测所需的必要信息；以及跨-Agent查询融合，利用空间查询匹配(SQM)和对象查询聚合(OQA)实现查询间的高效交互。实验结果显示，CoopDETR在OPV2V和V2XSet数据集上达到了最先进的性能，并将传输成本降低了至先前方法的1/782。 <div>
arXiv:2502.19313v1 Announce Type: new 
Abstract: Cooperative perception enhances the individual perception capabilities of autonomous vehicles (AVs) by providing a comprehensive view of the environment. However, balancing perception performance and transmission costs remains a significant challenge. Current approaches that transmit region-level features across agents are limited in interpretability and demand substantial bandwidth, making them unsuitable for practical applications. In this work, we propose CoopDETR, a novel cooperative perception framework that introduces object-level feature cooperation via object query. Our framework consists of two key modules: single-agent query generation, which efficiently encodes raw sensor data into object queries, reducing transmission cost while preserving essential information for detection; and cross-agent query fusion, which includes Spatial Query Matching (SQM) and Object Query Aggregation (OQA) to enable effective interaction between queries. Our experiments on the OPV2V and V2XSet datasets demonstrate that CoopDETR achieves state-of-the-art performance and significantly reduces transmission costs to 1/782 of previous methods.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems</title>
<link>https://arxiv.org/abs/2502.19328</link>
<guid>https://arxiv.org/abs/2502.19328</guid>
<content:encoded><![CDATA[
<div> 关键词: 奖励模型、大规模语言模型、可验证正确性信号、代理奖励建模、RewardAgent

总结:<br />
本文提出了一种新的奖励模型方法——代理奖励建模（Agentic Reward Modeling），该方法结合了人类偏好和不同方面的可验证正确性信号来提供更可靠的奖励。具体实现中，作者设计了一个名为RewardAgent的奖励代理，它将人类偏好奖励与事实性和指令遵循两种可验证信号相结合。实验结果显示，RewardAgent在现有奖励模型基准测试和实际下游任务的最佳解搜索上表现优越。此外，利用RewardAgent构建训练偏好对，并使用DPO目标训练大型语言模型，使其在多个NLP基准测试中的性能超过了传统的奖励模型。相关代码已被公开发布，以促进进一步的研究。 <div>
arXiv:2502.19328v1 Announce Type: new 
Abstract: Reward models (RMs) are crucial for the training and inference-time scaling up of large language models (LLMs). However, existing reward models primarily focus on human preferences, neglecting verifiable correctness signals which have shown strong potential in training LLMs. In this paper, we propose agentic reward modeling, a reward system that combines reward models with verifiable correctness signals from different aspects to provide reliable rewards. We empirically implement a reward agent, named RewardAgent, that combines human preference rewards with two verifiable signals: factuality and instruction following, to provide more reliable rewards. We conduct comprehensive experiments on existing reward model benchmarks and inference time best-of-n searches on real-world downstream tasks. RewardAgent significantly outperforms vanilla reward models, demonstrating its effectiveness. We further construct training preference pairs using RewardAgent and train an LLM with the DPO objective, achieving superior performance on various NLP benchmarks compared to conventional reward models. Our codes are publicly released to facilitate further research (https://github.com/THU-KEG/Agentic-Reward-Modeling).
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hybrid Robot Learning for Automatic Robot Motion Planning in Manufacturing</title>
<link>https://arxiv.org/abs/2502.19340</link>
<guid>https://arxiv.org/abs/2502.19340</guid>
<content:encoded><![CDATA[
<div> 关键词: 工业机器人、轨迹规划、深度强化学习、任务空间、关节空间

总结:
本文介绍了一种针对工业机器人的多层混合运动规划方法，该方法结合了基于任务空间的强化学习学习从示范（RL-LfD）代理和基于关节空间的深度强化学习（DRL）代理。通过高层级的代理学习在两种代理间进行切换，以实现可行且平滑的运动路径规划。规划过程中考虑了可达性、关节限制、操作便捷性和碰撞风险等因素，确保生成的混合运动策略遵守任务约束。该方法的有效性已在模拟及真实世界场景下的机器人实验中得到验证。<br /><br /> <div>
arXiv:2502.19340v1 Announce Type: new 
Abstract: Industrial robots are widely used in diverse manufacturing environments. Nonetheless, how to enable robots to automatically plan trajectories for changing tasks presents a considerable challenge. Further complexities arise when robots operate within work cells alongside machines, humans, or other robots. This paper introduces a multi-level hybrid robot motion planning method combining a task space Reinforcement Learning-based Learning from Demonstration (RL-LfD) agent and a joint-space based Deep Reinforcement Learning (DRL) based agent. A higher level agent learns to switch between the two agents to enable feasible and smooth motion. The feasibility is computed by incorporating reachability, joint limits, manipulability, and collision risks of the robot in the given environment. Therefore, the derived hybrid motion planning policy generates a feasible trajectory that adheres to task constraints. The effectiveness of the method is validated through sim ulated robotic scenarios and in a real-world setup.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding</title>
<link>https://arxiv.org/abs/2502.19400</link>
<guid>https://arxiv.org/abs/2502.19400</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、视觉解释、定理解释视频、Manim动画、TheoremExplainAgent、TheoremExplainBench、评价指标、多模态解释

总结:
本文介绍了为了解决大型语言模型在生成具有结构化视觉解释的定理解释方面的挑战，所提出的TheoremExplainAgent方法。该方法利用Manim动画生成超过5分钟的定理解释视频。为了系统评估多模态定理解释的效果，文章提出了涵盖多个STEM领域的240个定理及包含5个自动评价指标的TheoremExplainBench基准。实验结果显示，agentic规划对于生成详细的长篇视频至关重要，o3-mini代理的成功率达到93.8%，综合得分0.77。然而，定量和定性研究发现生成的视频在视觉元素布局方面存在一些小问题。此外，多模态解释揭示了文本解释未能显现的深层次推理缺陷，强调了多模态解释的重要性。 <div>
arXiv:2502.19400v1 Announce Type: new 
Abstract: Understanding domain-specific theorems often requires more than just text-based reasoning; effective communication through structured visual explanations is crucial for deeper comprehension. While large language models (LLMs) demonstrate strong performance in text-based theorem reasoning, their ability to generate coherent and pedagogically meaningful visual explanations remains an open challenge. In this work, we introduce TheoremExplainAgent, an agentic approach for generating long-form theorem explanation videos (over 5 minutes) using Manim animations. To systematically evaluate multimodal theorem explanations, we propose TheoremExplainBench, a benchmark covering 240 theorems across multiple STEM disciplines, along with 5 automated evaluation metrics. Our results reveal that agentic planning is essential for generating detailed long-form videos, and the o3-mini agent achieves a success rate of 93.8% and an overall score of 0.77. However, our quantitative and qualitative studies show that most of the videos produced exhibit minor issues with visual element layout. Furthermore, multimodal explanations expose deeper reasoning flaws that text-based explanations fail to reveal, highlighting the importance of multimodal explanations.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation</title>
<link>https://arxiv.org/abs/2502.19414</link>
<guid>https://arxiv.org/abs/2502.19414</guid>
<content:encoded><![CDATA[
<div> 关键词: Language Models, 科学发现, 生成解决方案, 反驳能力, REFUTE

总结:
本文关注语言模型（Language Models）在加速科学发现中的潜力，强调了对其反驳错误解决方案能力进行评估和提升的重要性。当前的LM基准测试主要关注于它们生成解决方案的能力，而非挑战错误解决方案的能力。作者提出发展新的基准测试来衡量这种逆向能力，并以算法问题解决领域为例，引入了一个名为REFUTE的动态更新基准测试集，该集合包含了编程竞赛中人类专家已识别出错误解的问题及对应反例。研究分析显示，即使是最优的推理代理——OpenAI o3-mini（高），在具有代码执行反馈的情况下，也只能为REFUTE中不足9%的错误解决方案创建反例，尽管其评级表明它能从零开始解决高达48%的这些问题。作者希望通过这项工作激发对提升LM反驳错误解决方案能力的研究与进步，这一能力对于加速科学研究以及使模型通过可靠的反思性推理实现自我改进至关重要。 <div>
arXiv:2502.19414v1 Announce Type: new 
Abstract: There is growing excitement about the potential of Language Models (LMs) to accelerate scientific discovery. Falsifying hypotheses is key to scientific progress, as it allows claims to be iteratively refined over time. This process requires significant researcher effort, reasoning, and ingenuity. Yet current benchmarks for LMs predominantly assess their ability to generate solutions rather than challenge them. We advocate for developing benchmarks that evaluate this inverse capability - creating counterexamples for subtly incorrect solutions. To demonstrate this approach, we start with the domain of algorithmic problem solving, where counterexamples can be evaluated automatically using code execution. Specifically, we introduce REFUTE, a dynamically updating benchmark that includes recent problems and incorrect submissions from programming competitions, where human experts successfully identified counterexamples. Our analysis finds that the best reasoning agents, even OpenAI o3-mini (high) with code execution feedback, can create counterexamples for only <9% of incorrect solutions in REFUTE, even though ratings indicate its ability to solve up to 48% of these problems from scratch. We hope our work spurs progress in evaluating and enhancing LMs' ability to falsify incorrect solutions - a capability that is crucial for both accelerating research and making models self-improve through reliable reflective reasoning.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Cycles and collusion in congestion games under Q-learning</title>
<link>https://arxiv.org/abs/2502.18984</link>
<guid>https://arxiv.org/abs/2502.18984</guid>
<content:encoded><![CDATA[
<div> 关键词：Q-learning、Braess悖论游戏、纳什均衡、社交最优、参数设置

总结:<br />
本文研究了Q-learning在一类广义Braess悖论游戏中的动态行为。这些游戏代表了一种网络路由游戏中，其中阶段游戏的纳什均衡并不构成社会最优解。文章详细分析了具有不同参数和学习率的Q-learning的收敛性，并观察到了多种现象，大致分为两种情况：要么稳定在纳什均衡，要么以类似于“埃奇沃思周期”的方式持续循环（即从纳什均衡突然跃迁到社交最优，然后逐渐恶化回纳什均衡）。此外，作者揭示了一个重要的激励不相容性问题，即当考虑设计各自Q-learner的参与者之间的元博弈时，纳什均衡点特征为异质参数，导致结果仅达到纳什均衡层面的合作，几乎没有超越这一点。最后，文中提出了对监管和合谋的新视角，并讨论了研究结果对伯特兰寡头定价博弈的影响。 <div>
arXiv:2502.18984v1 Announce Type: cross 
Abstract: We investigate the dynamics of Q-learning in a class of generalized Braess paradox games. These games represent an important class of network routing games where the associated stage-game Nash equilibria do not constitute social optima. We provide a full convergence analysis of Q-learning with varying parameters and learning rates. A wide range of phenomena emerges, broadly either settling into Nash or cycling continuously in ways reminiscent of "Edgeworth cycles" (i.e. jumping suddenly from Nash toward social optimum and then deteriorating gradually back to Nash). Our results reveal an important incentive incompatibility when thinking in terms of a meta-game being played by the designers of the individual Q-learners who set their agents' parameters. Indeed, Nash equilibria of the meta-game are characterized by heterogeneous parameters, and resulting outcomes achieve little to no cooperation beyond Nash. In conclusion, we suggest a novel perspective for thinking about regulation and collusion, and discuss the implications of our results for Bertrand oligopoly pricing games.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A BV-Category of Spacetime Interventions</title>
<link>https://arxiv.org/abs/2502.19022</link>
<guid>https://arxiv.org/abs/2502.19022</guid>
<content:encoded><![CDATA[
<div> 关键词：BV-逻辑、duoidal类别、Chu构造、强Hyland包络、量子超导图

总结:<br />
本文利用Chu构造从duoidal范畴中functorially构建出BV-范畴，展示了可以从Retoré的序列化算子的一个片段自动生成BV-逻辑的候选模型。通过该构造法证明强Hyland包络是一个BV-范畴，从而提出了一种方法，可以从任何对称单态范畴出发，自动生成描述时空中介质间关系的规范模型。这一模型将时空事件具体解释为干预-上下文对，解决了之前尝试给出量子超导图一般范畴语义时存在的缺陷。 <div>
arXiv:2502.19022v1 Announce Type: cross 
Abstract: We use the Chu construction to functorially build BV-categories from duoidal categories, demonstrating that candidate models of BV-logic can be cofreely constructed from a fragment of a model of Retor\'e's sequencing operator. By using this construction to show that the strong Hyland envelope is a BV-category, we find a way to build a canonical model of spatio-temporal relationships between agents in spacetime from any symmetric monoidal category. The concrete physical interpretation of spacetime events in this model as intervention-context pairs resolves deficiencies in previous attempts to give a general categorical semantics to quantum supermaps.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Impact of Fake Agents on Information Cascades</title>
<link>https://arxiv.org/abs/2005.05518</link>
<guid>https://arxiv.org/abs/2005.05518</guid>
<content:encoded><![CDATA[
<div> 关键词：在线市场、观察学习、信息瀑布、虚假代理、福利影响

<br />
总结:
该文研究了在线市场中理性和虚假代理的行为互动。理性代理人除了依据私人信息外，还会从他人的行为中学习，这可能导致信息瀑布或跟风现象。文章引入了固定行动以影响其他理性代理选择的虚假代理，并分析了虚假代理比例对理性代理行为及其福利（期望收益）的影响。文中建立了一个状态空间为可数无限大的马尔科夫链模型，并给出了一种迭代方法来计算代理人跟风的概率和福利。主要结果表明存在无数种情况，增加虚假代理的比例反而会降低他们偏好的结果发生的几率，并且能显著提高所有理性代理的福利。因此，增加虚假代理不仅对他们自身的策略效果适得其反，还对理性代理有利。 <div>
arXiv:2005.05518v3 Announce Type: replace 
Abstract: In online markets, agents often learn from other's actions in addition to their private information. Such observational learning can lead to herding or information cascades in which agents eventually ignore their private information and "follow the crowd". Models for such cascades have been well studied for Bayes-rational agents that arrive sequentially and choose pay-off optimal actions. This paper additionally considers the presence of fake agents that take a fixed action in order to influence subsequent rational agents towards their preferred action. We characterize how the fraction of such fake agents impacts the behavior of rational agents given a fixed quality of private information. Our model results in a Markov chain with a countably infinite state space, for which we give an iterative method to compute an agent's chances of herding and its welfare (expected pay-off). Our main result shows a counter-intuitive phenomenon: there exist infinitely many scenarios where an increase in the fraction of fake agents in fact reduces the chances of their preferred outcome. Moreover, this increase causes a significant improvement in the welfare of every rational agent. Hence, this increase is not only counter-productive for the fake agents but is also beneficial to the rational agents.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Stable Matching Games</title>
<link>https://arxiv.org/abs/2008.01680</link>
<guid>https://arxiv.org/abs/2008.01680</guid>
<content:encoded><![CDATA[
<div> 关键词：匹配问题、Gale-Shapley、稳定匹配、战略游戏、承诺能力

总结:
该文扩展了Gale和Shapley提出的两集合代理人的匹配问题模型，允许匹配后的夫妇通过非合作或半合作的战略游戏方式内生决定其收益。在非合作情形下，文章定义了一种结合Gale-Shapley稳定性和纳什均衡稳定性的解决方案概念；在存在承诺能力的半合作条件下，则定义了另一种相应的解决方案。对于每种情况，文中都给出了解决方案非空的充分必要条件并提供了计算解决方案的算法。 <div>
arXiv:2008.01680v4 Announce Type: replace 
Abstract: Gale and Shapley introduced a matching problem between two sets of agents where each agent on one side has an exogenous preference ordering over the agents on the other side. They defined a matching as stable if no unmatched pair can both improve their utility by forming a new pair. They proved, algorithmically, the existence of a stable matching. Shapley and Shubik, Demange and Gale, and many others extended the model by allowing monetary transfers. We offer a further extension by assuming that matched couples obtain their payoff endogenously as the outcome of a strategic game they have to play in a usual non-cooperative sense (without commitment) or in a semi-cooperative way (with commitment, as the outcome of a bilateral binding contract in which each player is responsible for her part of the contract). Depending on whether the players can commit or not, we define in each case a solution concept that combines Gale-Shapley pairwise stability with a (generalized) Nash equilibrium stability. In each case we give necessary and sufficient conditions for the set of solutions to be non-empty and provide an algorithm to compute a solution.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Completeness of two fragments of a logic for conditional strategic reasoning</title>
<link>https://arxiv.org/abs/2405.11418</link>
<guid>https://arxiv.org/abs/2405.11418</guid>
<content:encoded><![CDATA[
<div> 关键词：Conditional Strategic Reasoning (CSR)，Cooperating Conditional Strategic Reasoning (CCSR)，Completeness，Liability fragment，Ability fragment。

总结:
该文针对逻辑领域中用于战略推理的形式化理论，特别是Goranko和Ju近期提出的条件战略推理逻辑CSR进行了深入研究。CSR的一个重要特点是其包含了一个描述合作情境下代理者实现目标的战略行为的算子。文章聚焦于这个算子的逻辑——合作条件战略推理逻辑(CCSR)的两个片段：责任片段和能力片段，并证明了这两个片段的完备性。证明方法依赖于标准析取、标准析取的有效性减少条件、抽象游戏形式及其实现以及标准析取的推导减少条件。该方法有潜力应用于CSR和其他战略逻辑的完备性证明。 <div>
arXiv:2405.11418v2 Announce Type: replace 
Abstract: Classical logics for strategic reasoning, such as Coalition Logic and Alternating-time Temporal Logic, formalize absolute strategic reasoning about the unconditional strategic abilities of agents to achieve their goals. Goranko and Ju, in two recent papers, introduced a Logic for Conditional Strategic Reasoning (CSR). However, its completeness is still an open problem. CSR has three featured operators, and one of them has the following reading: For some action of A that guarantees the achievement of her goal, B has an action to guarantee the achievement of his goal. This operator makes good sense when A is cooperating with B. The logic about this operator is called Logic for Cooperating Conditional Strategic Reasoning (CCSR). In this paper, we prove the completeness of two fragments of CCSR: the liability fragment and the ability fragment. The key ingredients of our proof approach include standard disjunctions, the validity-reduction condition of standard disjunctions, abstract game forms, and their realization, and the derivability-reduction condition of standard disjunctions. The approach has good potential to be applied to the completeness of CSR and other strategic logics.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous Data</title>
<link>https://arxiv.org/abs/2405.13961</link>
<guid>https://arxiv.org/abs/2405.13961</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式训练、异构数据分布、通信成本、Sharpness-Aware Minimization (SAM)、SADDLe

总结:
本文提出了SADDLe，一套针对分布式深度学习的尖锐度感知算法，旨在解决实际场景中数据分布显著异构以及高通信成本的问题。SADDLe利用Sharpness-Aware Minimization (SAM)方法在训练过程中寻求平坦的损失景观，从而提高模型泛化能力和对通信压缩的鲁棒性。文章介绍了两种版本的SADDLe方法并进行了大量实验，结果显示SADDLe相比于现有技术能提升1-20%的测试精度，并在高达4倍的通信压缩下，平均性能下降仅为1%。 <div>
arXiv:2405.13961v2 Announce Type: replace 
Abstract: Decentralized training enables learning with distributed datasets generated at different locations without relying on a central server. In realistic scenarios, the data distribution across these sparsely connected learning agents can be significantly heterogeneous, leading to local model over-fitting and poor global model generalization. Another challenge is the high communication cost of training models in such a peer-to-peer fashion without any central coordination. In this paper, we jointly tackle these two-fold practical challenges by proposing SADDLe, a set of sharpness-aware decentralized deep learning algorithms. SADDLe leverages Sharpness-Aware Minimization (SAM) to seek a flatter loss landscape during training, resulting in better model generalization as well as enhanced robustness to communication compression. We present two versions of our approach and conduct extensive experiments to show that SADDLe leads to 1-20% improvement in test accuracy compared to other existing techniques. Additionally, our proposed approach is robust to communication compression, with an average drop of only 1% in the presence of up to 4x compression.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Bridging Training and Execution via Dynamic Directed Graph-Based Communication in Cooperative Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2408.07397</link>
<guid>https://arxiv.org/abs/2408.07397</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体系统、强化学习、Transformer、图聚类网络、动态定向通信机制

总结:<br />
本文提出了一种名为Transformer-based图聚类网络（TGCNet）的新型多智能体强化学习（MARL）算法。针对现有方法在部分观测任务中缺乏动态定向通信机制以及依赖全局状态的问题，TGCNet通过学习动态定向图的拓扑结构来表示通信策略，并运用图聚类网络在训练过程中近似全局状态的表示。同时，TGCNet在执行阶段利用Transformer解码器进行特征提取。实验结果显示，TGCNet在多个合作型MARL基准上表现出优于流行MARL算法的性能。进一步的消融研究验证了我们提出的动态定向图通信机制和图聚类网络的有效性。 <div>
arXiv:2408.07397v3 Announce Type: replace 
Abstract: Multi-agent systems must learn to communicate and understand interactions between agents to achieve cooperative goals in partially observed tasks. However, existing approaches lack a dynamic directed communication mechanism and rely on global states, thus diminishing the role of communication in centralized training. Thus, we propose the Transformer-based graph coarsening network (TGCNet), a novel multi-agent reinforcement learning (MARL) algorithm. TGCNet learns the topological structure of a dynamic directed graph to represent the communication policy and integrates graph coarsening networks to approximate the representation of global state during training. It also utilizes the Transformer decoder for feature extraction during execution. Experiments on multiple cooperative MARL benchmarks demonstrate state-of-the-art performance compared to popular MARL algorithms. Further ablation studies validate the effectiveness of our dynamic directed graph communication mechanism and graph coarsening networks.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enabling Multi-Robot Collaboration from Single-Human Guidance</title>
<link>https://arxiv.org/abs/2409.19831</link>
<guid>https://arxiv.org/abs/2409.19831</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统、强化学习、协作行为、人类演示、理论思维模型

<br /><br />总结:
本文提出了一种新的方法，用于多智能体系统中高效、明确地学习协作行为。该方法仅需单一人类专家的指导，通过允许人类操作者在短时间内动态切换控制不同智能体以及结合类似人类的“理论思维”模型来教给智能体协作。实验结果显示，在一项具有挑战性的合作捉迷藏任务中，这种方法成功提高了成功率高达58%，并且仅需40分钟的人类引导时间。此外，研究还进一步证明了这些发现可以转移到现实世界的多机器人实验中。 <div>
arXiv:2409.19831v2 Announce Type: replace 
Abstract: Learning collaborative behaviors is essential for multi-agent systems. Traditionally, multi-agent reinforcement learning solves this implicitly through a joint reward and centralized observations, assuming collaborative behavior will emerge. Other studies propose to learn from demonstrations of a group of collaborative experts. Instead, we propose an efficient and explicit way of learning collaborative behaviors in multi-agent systems by leveraging expertise from only a single human. Our insight is that humans can naturally take on various roles in a team. We show that agents can effectively learn to collaborate by allowing a human operator to dynamically switch between controlling agents for a short period and incorporating a human-like theory-of-mind model of teammates. Our experiments showed that our method improves the success rate of a challenging collaborative hide-and-seek task by up to 58% with only 40 minutes of human guidance. We further demonstrate our findings transfer to the real world by conducting multi-robot experiments.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ColaCare: Enhancing Electronic Health Record Modeling through Large Language Model-Driven Multi-Agent Collaboration</title>
<link>https://arxiv.org/abs/2410.02551</link>
<guid>https://arxiv.org/abs/2410.02551</guid>
<content:encoded><![CDATA[
<div> 关键词: ColaCare、电子健康记录(EHR)、多智能体协作、大型语言模型(LLMs)、临床决策支持

<br /><br />总结:

本文介绍了ColaCare框架，该框架通过多智能体协作和驱动于大型语言模型（LLMs）的方法增强电子健康记录（EHR）建模。ColaCare结合了领域专家模型与LLMs，以弥合结构化EHR数据与基于文本推理之间的鸿沟。其设计灵感来源于临床环境中的多学科团队（MDT）方法，采用两种类型的代理：DoctorAgents和MetaAgent，协同分析患者数据。专家模型处理并从数值型EHR数据中生成预测，而LLM代理则生成推理参考和决策报告。MetaAgent负责协调讨论，模拟临床决策中的多元化专业知识。此外，为了解决知识更新问题，文章还引入了梅奥诊所诊断和治疗手册(MSD)的医疗指南作为检索增强生成（RAG）模块的证据来源。在三个EHR数据集上进行的广泛实验表明，ColaCare在临床死亡结果和再入院预测任务上的表现优越，显示出其对革新临床决策支持系统和推动个性化精准医学的潜力。所有代码、案例研究和问卷调查可在项目网站https://colacare.netlify.app获取。 <div>
arXiv:2410.02551v2 Announce Type: replace 
Abstract: We introduce ColaCare, a framework that enhances Electronic Health Record (EHR) modeling through multi-agent collaboration driven by Large Language Models (LLMs). Our approach seamlessly integrates domain-specific expert models with LLMs to bridge the gap between structured EHR data and text-based reasoning. Inspired by the Multidisciplinary Team (MDT) approach used in clinical settings, ColaCare employs two types of agents: DoctorAgents and a MetaAgent, which collaboratively analyze patient data. Expert models process and generate predictions from numerical EHR data, while LLM agents produce reasoning references and decision-making reports within the MDT-driven collaborative consultation framework. The MetaAgent orchestrates the discussion, facilitating consultations and evidence-based debates among DoctorAgents, simulating diverse expertise in clinical decision-making. We additionally incorporate the Merck Manual of Diagnosis and Therapy (MSD) medical guideline within a retrieval-augmented generation (RAG) module for medical evidence support, addressing the challenge of knowledge currency. Extensive experiments conducted on three EHR datasets demonstrate ColaCare's superior performance in clinical mortality outcome and readmission prediction tasks, underscoring its potential to revolutionize clinical decision support systems and advance personalized precision medicine. All code, case studies and a questionnaire are available at the project website: https://colacare.netlify.app.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Harvesting energy from turbulent winds with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2412.13961</link>
<guid>https://arxiv.org/abs/2412.13961</guid>
<content:encoded><![CDATA[
<div> 关键词：Airborne Wind Energy (AWE)，Reinforcement Learning (RL)，Model-Predictive Control，Turbulent Atmospheric Boundary Layer，Generator

总结:<br />
本文探讨了利用强化学习(RL)替代传统模型预测控制方法在空中风能(AWE)系统中的应用。传统方法依赖于特定模型，而在不可预测的湍流大气边界层条件下难以适应。研究发现，通过RL训练的AWE系统代理能够在复杂模拟环境中有效地从湍流中提取能量，并且仅依靠风筝相对于风向和速度的局部信息即可实现这一目标。这表明RL方法对于具有模型不确定性的问题有较强的鲁棒性。 <div>
arXiv:2412.13961v2 Announce Type: replace 
Abstract: Airborne Wind Energy (AWE) is an emerging technology designed to harness the power of high-altitude winds, offering a solution to several limitations of conventional wind turbines. AWE is based on flying devices (usually gliders or kites) that, tethered to a ground station and driven by the wind, convert its mechanical energy into electrical energy by means of a generator. Such systems are usually controlled by manoeuvering the kite so as to follow a predefined path prescribed by optimal control techniques, such as model-predictive control. These methods are strongly dependent on the specific model at use and difficult to generalize, especially in unpredictable conditions such as the turbulent atmospheric boundary layer. Our aim is to explore the possibility of replacing these techniques with an approach based on Reinforcement Learning (RL). Unlike traditional methods, RL does not require a predefined model, making it robust to variability and uncertainty. Our experimental results in complex simulated environments demonstrate that AWE agents trained with RL can effectively extract energy from turbulent flows, relying on minimal local information about the kite orientation and speed relative to the wind.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>What is a Social Media Bot? A Global Comparison of Bot and Human Characteristics</title>
<link>https://arxiv.org/abs/2501.00855</link>
<guid>https://arxiv.org/abs/2501.00855</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交媒体、机器人、人类、行为分析、定义、检测、差异化、干扰、监管、未来方向

<br /><br />总结:
本文探讨了社交媒体上机器人的普遍存在及其与人类行为的不同之处。研究发现，社交平台上约有20%的聊天内容来自机器人，它们倾向于使用易于自动化的语言线索，并具有星型互动结构；而80%的内容则来自人类，他们展现出更依赖对话理解并呈现多元身份的特点，其交流结构呈现出层级特征。文章首先从原理层面对社交媒体机器人的本质进行了定义，并基于此对比分析了机器人与人类在全球多个事件中的行为差异。作者还提出了对机器人使用的推荐和监管建议，以及三个关键挑战和未来发展方向：检测（系统性识别自动化并可能进化的机器人）、差异化（评价机器人在内容发布和关系互动方面的优劣）和干扰（减轻恶意机器人的负面影响）。 <div>
arXiv:2501.00855v2 Announce Type: replace 
Abstract: Chatter on social media is 20% bots and 80% humans. Chatter by bots and humans is consistently different: bots tend to use linguistic cues that can be easily automated while humans use cues that require dialogue understanding. Bots use words that match the identities they choose to present, while humans may send messages that are not related to the identities they present. Bots and humans differ in their communication structure: sampled bots have a star interaction structure, while sampled humans have a hierarchical structure. These conclusions are based on a large-scale analysis of social media tweets across ~200mil users across 7 events. Social media bots took the world by storm when social-cybersecurity researchers realized that social media users not only consisted of humans but also of artificial agents called bots. These bots wreck havoc online by spreading disinformation and manipulating narratives. Most research on bots are based on special-purposed definitions, mostly predicated on the event studied. This article first begins by asking, "What is a bot?", and we study the underlying principles of how bots are different from humans. We develop a first-principle definition of a social media bot. With this definition as a premise, we systematically compare characteristics between bots and humans across global events, and reflect on how the software-programmed bot is an Artificial Intelligent algorithm, and its potential for evolution as technology advances. Based on our results, we provide recommendations for the use and regulation of bots. Finally, we discuss open challenges and future directions: Detect, to systematically identify these automated and potentially evolving bots; Differentiate, to evaluate the goodness of the bot in terms of their content postings and relationship interactions; Disrupt, to moderate the impact of malicious bots.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ACEBench: Who Wins the Match Point in Tool Usage?</title>
<link>https://arxiv.org/abs/2501.12851</link>
<guid>https://arxiv.org/abs/2501.12851</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型(LLMs)、评估基准、ACEBench、工具使用、多回合对话

总结:
大型语言模型（LLMs）在决策和推理方面展现出巨大潜力，但现有的评估基准在评价LLMs工具使用能力时存在局限性，如：有限的评估场景、狭窄的评价维度以及依赖于LLMs或真实API执行带来的高成本。为解决这些问题，文章提出了一个新的全面评估基准——ACEBench。ACEBench根据评价方法将数据分为三类：基本场景的“正常”类型、含糊或不完整指令情况下的“特殊”类型以及通过多智能体交互模拟现实世界多回合对话的“代理”类型。通过对ACEBench进行广泛实验，文章对多种LLMs进行了深入分析，并在不同数据类型中详细剖析了错误产生的原因。 <div>
arXiv:2501.12851v4 Announce Type: replace 
Abstract: Large Language Models (LLMs) have demonstrated significant potential in decision-making and reasoning, particularly when integrated with various tools to effectively solve complex problems. However, existing benchmarks for evaluating LLMs' tool usage face several limitations: (1) limited evaluation scenarios, often lacking assessments in real multi-turn dialogue contexts; (2) narrow evaluation dimensions, with insufficient detailed assessments of how LLMs use tools; and (3) reliance on LLMs or real API executions for evaluation, which introduces significant overhead. To address these challenges, we introduce ACEBench, a comprehensive benchmark for assessing tool usage in LLMs. ACEBench categorizes data into three primary types based on evaluation methodology: Normal, Special, and Agent. "Normal" evaluates tool usage in basic scenarios; "Special" evaluates tool usage in situations with ambiguous or incomplete instructions; "Agent" evaluates tool usage through multi-agent interactions to simulate real-world, multi-turn dialogues. We conducted extensive experiments using ACEBench, analyzing various LLMs in-depth and providing a more granular examination of error causes across different data types.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gaze-Guided Task Decomposition for Imitation Learning in Robotic Manipulation</title>
<link>https://arxiv.org/abs/2501.15071</link>
<guid>https://arxiv.org/abs/2501.15071</guid>
<content:encoded><![CDATA[
<div> 关键词：模仿学习、机器人操作、任务分解、目光转移、遥操作

总结:
本文提出了一种基于目光转移的任务分解方法，用于机器人操作中的模仿学习。研究认为，人类在物体操纵过程中，目光与手部动作紧密关联，可以将任务分解为子任务。该方法利用遥操作收集的演示数据，通过分析操作员的目光转移来代替模仿代理的目光控制进行任务分解，确保了每个任务的所有示范中一致的分解结果。实验评估显示，该方法对各种任务的特性及一致性有良好表现，并且在不同的超参数设置下展现出鲁棒性，适用于多种不同的机器人系统。相关代码已开源发布于https://github.com/crumbyRobotics/GazeTaskDecomp。 <div>
arXiv:2501.15071v3 Announce Type: replace 
Abstract: In imitation learning for robotic manipulation, decomposing object manipulation tasks into sub-tasks enables the reuse of learned skills and the combination of learned behaviors to perform novel tasks, rather than simply replicating demonstrated motions. Human gaze is closely linked to hand movements during object manipulation. We hypothesize that an imitating agent's gaze control, fixating on specific landmarks and transitioning between them, simultaneously segments demonstrated manipulations into sub-tasks. This study proposes a simple yet robust task decomposition method based on gaze transitions. Using teleoperation, a common modality in robotic manipulation for collecting demonstrations, in which a human operator's gaze is measured and used for task decomposition as a substitute for an imitating agent's gaze. Our approach ensures consistent task decomposition across all demonstrations for each task, which is desirable in contexts such as machine learning. We evaluated the method across demonstrations of various tasks, assessing the characteristics and consistency of the resulting sub-tasks. Furthermore, extensive testing across different hyperparameter settings confirmed its robustness, making it adaptable to diverse robotic systems. Our code is available at https://github.com/crumbyRobotics/GazeTaskDecomp.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reinforcement learning to learn quantum states for Heisenberg scaling accuracy</title>
<link>https://arxiv.org/abs/2412.02334</link>
<guid>https://arxiv.org/abs/2412.02334</guid>
<content:encoded><![CDATA[
<div> 关键词：量子状态学习、神经方法、元学习模型、强化学习（RL）、数据效率

总结:
本文提出了一种利用强化学习（RL）优化量子状态学习过程的元学习模型。为了提升RL的数据效率，文中引入了受课程学习启发的动作重复策略。实验表明，该RL代理能显著提高学习随机量子态的样本效率，并逼近海森堡极限的低失真尺度。此外，研究还展示了经过3-qubit训练的RL代理能够泛化到学习高达5-qubit的状态。这些结果强调了RL驱动的元学习在提升量子状态学习的效率和泛化能力方面的实用性。这种方法可以应用于改进量子控制、量子优化及量子机器学习领域。<br /><br /> <div>
arXiv:2412.02334v2 Announce Type: replace-cross 
Abstract: Learning quantum states is a crucial task for realizing quantum information technology. Recently, neural approaches have emerged as promising methods for learning quantum states. We propose a meta-learning model that utilizes reinforcement learning (RL) to optimize the process of learning quantum states. To improve the data efficiency of the RL, we introduce an action repetition strategy inspired by curriculum learning. The RL agent significantly improves the sample efficiency of learning random quantum states, and achieves infidelity scaling close to the Heisenberg limit. We also show that the RL agent trained using 3-qubit states can generalize to learning up to 5-qubit states. These results highlight the utility of RL-driven meta-learning to enhance the efficiency and generalizability of learning quantum states. Our approach can be applied to improve quantum control, quantum optimization, and quantum machine learning.
]]></content:encoded>
<pubDate>Thu, 27 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AI Agentic workflows and Enterprise APIs: Adapting API architectures for the age of AI agents</title>
<link>https://arxiv.org/abs/2502.17443</link>
<guid>https://arxiv.org/abs/2502.17443</guid>
<content:encoded><![CDATA[
<div> 关键词: Generative AI、自主AI代理、企业API架构、智能交互、下一代企业API

总结:<br />
本文探讨了生成式AI的快速发展对自主AI代理兴起带来的挑战，指出现有企业API架构主要针对人类驱动的预定义交互模式，难以适应智能代理动态、目标导向的行为。研究通过系统性地分析现有API设计范式、智能代理交互模型以及新兴技术约束，提出了一个战略框架，用于企业API的有效转型以支持AI工作流程。采用理论建模、比较分析和探索性设计原则相结合的方法，解决标准化、性能和智能交互等方面的挑战。最终，该研究提出了一种概念性的下一代企业API模型，能够无缝集成到自主AI代理生态系统中，对未来的企业计算架构具有重大意义。 <div>
arXiv:2502.17443v1 Announce Type: new 
Abstract: The rapid advancement of Generative AI has catalyzed the emergence of autonomous AI agents, presenting unprecedented challenges for enterprise computing infrastructures. Current enterprise API architectures are predominantly designed for human-driven, predefined interaction patterns, rendering them ill-equipped to support intelligent agents' dynamic, goal-oriented behaviors. This research systematically examines the architectural adaptations for enterprise APIs to support AI agentic workflows effectively. Through a comprehensive analysis of existing API design paradigms, agent interaction models, and emerging technological constraints, the paper develops a strategic framework for API transformation. The study employs a mixed-method approach, combining theoretical modeling, comparative analysis, and exploratory design principles to address critical challenges in standardization, performance, and intelligent interaction. The proposed research contributes a conceptual model for next-generation enterprise APIs that can seamlessly integrate with autonomous AI agent ecosystems, offering significant implications for future enterprise computing architectures.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RAG-Enhanced Collaborative LLM Agents for Drug Discovery</title>
<link>https://arxiv.org/abs/2502.17506</link>
<guid>https://arxiv.org/abs/2502.17506</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 药物发现, 专门化数据, 检索增强生成 (RAG), CLADD

总结:
CLADD是一个针对药物发现在无需领域特定微调的情况下，利用检索增强生成（RAG）技术的多代理系统。该系统通过多个LLM智能体动态地从生物医学知识库中检索信息、对查询分子进行上下文处理并整合相关证据以生成响应。CLADD解决了将RAG工作流应用于生化数据时面临的异质性、歧义和多源集成等关键问题。研究表明，该框架在多种药物发现任务上的表现优于通用及专用的LLMs以及传统的深度学习方法。 <div>
arXiv:2502.17506v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have shown great potential to accelerate drug discovery. However, the specialized nature of biochemical data often necessitates costly domain-specific fine-tuning, posing critical challenges. First, it hinders the application of more flexible general-purpose LLMs in cutting-edge drug discovery tasks. More importantly, it impedes the rapid integration of the vast amounts of scientific data continuously generated through experiments and research. To investigate these challenges, we propose CLADD, a retrieval-augmented generation (RAG)-empowered agentic system tailored to drug discovery tasks. Through the collaboration of multiple LLM agents, CLADD dynamically retrieves information from biomedical knowledge bases, contextualizes query molecules, and integrates relevant evidence to generate responses -- all without the need for domain-specific fine-tuning. Crucially, we tackle key obstacles in applying RAG workflows to biochemical data, including data heterogeneity, ambiguity, and multi-source integration. We demonstrate the flexibility and effectiveness of this framework across a variety of drug discovery tasks, showing that it outperforms general-purpose and domain-specific LLMs as well as traditional deep learning approaches.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Gaussian Process-Based Scalar Field Estimation in GPS-Denied Environments</title>
<link>https://arxiv.org/abs/2502.17584</link>
<guid>https://arxiv.org/abs/2502.17584</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、GPS禁用区域、标量场映射、切换轨迹、Lyapunov稳定性分析

总结:
<br />
本文提出了一种用于自主代理在GPS信号被遮挡地区进行未知标量场映射的方法。该方法通过在有GPS信号和无GPS信号的区域间交替移动来减少定位误差，用户可以根据需求定义误差边界以确定在各区域内的停留时间。为了确保在无GPS信号区域内的测量值保持在指定误差限制内，文章设计了一种切换轨迹。基于Lyapunov稳定性理论进行分析，保证了在追踪期望路径时的误差轨迹是有界的。最后，通过仿真模拟展示了该方法的有效性，并进行了误差分析，将使用GP预测的标量场模型与实际场进行比较。 <div>
arXiv:2502.17584v1 Announce Type: new 
Abstract: This paper presents a methodology for an autonomous agent to map an unknown scalar field in GPS-denied regions. To reduce localization errors, the agent alternates between GPS-enabled and GPS-denied areas while collecting measurements. User-defined error bounds determine the dwell time in each region. A switching trajectory is then designed to ensure field measurements in GPS-denied regions remain within the specified error limits. A Lyapunov-based stability analysis guarantees bounded error trajectories while tracking the desired path. The effectiveness of the proposed methodology is demonstrated through simulations, with an error analysis comparing the GP-predicted scalar field model to the actual field.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Decentralized Swarms Using Rotation Equivariant Graph Neural Networks</title>
<link>https://arxiv.org/abs/2502.17612</link>
<guid>https://arxiv.org/abs/2502.17612</guid>
<content:encoded><![CDATA[
<div> 关键词：graph neural network (GNN)，分布式控制器设计，群体优化，旋转等变性，平移不变性

总结:
本文研究了在没有中心控制的情况下，通过分布式控制器来优化群体目标的问题，特别关注于无人机编队和传感器网络中的应用。现有的基于图神经网络（GNN）的分布式控制器在维持编队凝聚力方面存在挑战。文章提出了一种新的方法，即在分布式GNN控制器中强制实施旋转等变性和平移不变性对称性，从而提高了控制器性能。实验结果显示，这种方法所需的训练数据减少了70%，可训练权重减少了75%，并且其泛化能力也优于现有未施加这些对称性的GNN控制器。相关代码和动画已在http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers公开可用。 <div>
arXiv:2502.17612v1 Announce Type: new 
Abstract: The orchestration of agents to optimize a collective objective without centralized control is challenging yet crucial for applications such as controlling autonomous fleets, and surveillance and reconnaissance using sensor networks. Decentralized controller design has been inspired by self-organization found in nature, with a prominent source of inspiration being flocking; however, decentralized controllers struggle to maintain flock cohesion. The graph neural network (GNN) architecture has emerged as an indispensable machine learning tool for developing decentralized controllers capable of maintaining flock cohesion, but they fail to exploit the symmetries present in flocking dynamics, hindering their generalizability. We enforce rotation equivariance and translation invariance symmetries in decentralized flocking GNN controllers and achieve comparable flocking control with 70% less training data and 75% fewer trainable weights than existing GNN controllers without these symmetries enforced. We also show that our symmetry-aware controller generalizes better than existing GNN controllers. Code and animations are available at http://github.com/Utah-Math-Data-Science/Equivariant-Decentralized-Controllers.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Hierarchical Imitation Learning of Team Behavior from Heterogeneous Demonstrations</title>
<link>https://arxiv.org/abs/2502.17618</link>
<guid>https://arxiv.org/abs/2502.17618</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体模仿学习, 异构示范, 高级层次策略, 并发错误缓解, 复杂序列任务

总结:
本文提出了DTIL，一种用于复杂序列任务中多模态团队行为学习的分层多智能体模仿学习算法。DTIL针对现有方法假设所有示范来自单一团队策略的问题，设计了能处理异构团队示范的学习框架。每个团队成员由一个分层策略表示，通过分布匹配方法，DTIL有效地减轻了累积误差，并在长周期和连续状态表示的情况下实现良好扩展性。实验结果显示，DTIL在各种协作场景中优于多智能体模仿学习基线，并能准确地模拟团队行为。<br /><br /> <div>
arXiv:2502.17618v1 Announce Type: new 
Abstract: Successful collaboration requires team members to stay aligned, especially in complex sequential tasks. Team members must dynamically coordinate which subtasks to perform and in what order. However, real-world constraints like partial observability and limited communication bandwidth often lead to suboptimal collaboration. Even among expert teams, the same task can be executed in multiple ways. To develop multi-agent systems and human-AI teams for such tasks, we are interested in data-driven learning of multimodal team behaviors. Multi-Agent Imitation Learning (MAIL) provides a promising framework for data-driven learning of team behavior from demonstrations, but existing methods struggle with heterogeneous demonstrations, as they assume that all demonstrations originate from a single team policy. Hence, in this work, we introduce DTIL: a hierarchical MAIL algorithm designed to learn multimodal team behaviors in complex sequential tasks. DTIL represents each team member with a hierarchical policy and learns these policies from heterogeneous team demonstrations in a factored manner. By employing a distribution-matching approach, DTIL mitigates compounding errors and scales effectively to long horizons and continuous state representations. Experimental results show that DTIL outperforms MAIL baselines and accurately models team behavior across a variety of collaborative scenarios.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>METAL: A Multi-Agent Framework for Chart Generation with Test-Time Scaling</title>
<link>https://arxiv.org/abs/2502.17651</link>
<guid>https://arxiv.org/abs/2502.17651</guid>
<content:encoded><![CDATA[
<div> 关键词：chart generation、vision-language model (VLM)、multi-agent framework、METAL、性能提升

总结:
本文提出了一种基于视觉-语言模型（VLM）的多智能体框架——METAL，用于有效自动图表生成。该任务需要将期望的视觉属性精确地编码到代码中，既要求强大的视觉设计技能又需要精确的编程能力，这对直接提示VLM构成挑战。METAL通过将图表生成任务分解为多个专业智能体之间的迭代协作来解决这一问题。相较于现有最佳结果，METAL在图表生成任务上准确度提升了5.2%。此外，METAL框架还表现出测试时间扩展现象，即随着计算预算从512增长到8192个令牌，其性能呈单调上升趋势。最后，研究发现，在METAL的批判过程中分离不同模态可以增强VLM在多模态语境下的自我修正能力。 <div>
arXiv:2502.17651v1 Announce Type: new 
Abstract: Chart generation aims to generate code to produce charts satisfying the desired visual properties, e.g., texts, layout, color, and type. It has great potential to empower the automatic professional report generation in financial analysis, research presentation, education, and healthcare. In this work, we build a vision-language model (VLM) based multi-agent framework for effective automatic chart generation. Generating high-quality charts requires both strong visual design skills and precise coding capabilities that embed the desired visual properties into code. Such a complex multi-modal reasoning process is difficult for direct prompting of VLMs. To resolve these challenges, we propose METAL, a multi-agent framework that decomposes the task of chart generation into the iterative collaboration among specialized agents. METAL achieves 5.2% improvement in accuracy over the current best result in the chart generation task. The METAL framework exhibits the phenomenon of test-time scaling: its performance increases monotonically as the logarithmic computational budget grows from 512 to 8192 tokens. In addition, we find that separating different modalities during the critique process of METAL boosts the self-correction capability of VLMs in the multimodal context.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Aligning Compound AI Systems via System-level DPO</title>
<link>https://arxiv.org/abs/2502.17721</link>
<guid>https://arxiv.org/abs/2502.17721</guid>
<content:encoded><![CDATA[
<div> 关键词: Compound AI系统、交互组件、Direct Preference Optimization (DPO)、系统级DPO (SysDPO)、Directed Acyclic Graphs (DAGs)

总结:
本文关注了由多个相互作用组件（如LLM代理和外部工具）组成的复合AI系统的对齐问题，这些系统在各种任务中展现出最先进的结果。由于组件间的非微分交互以及系统层面的偏好无法直接转化为组件层面的偏好，使得传统的DPO方法不适用于此类系统。为解决这些问题，文章提出了将复合AI系统建模为有向无环图(DAG)，并设计了一个系统级的DPO (SysDPO) 方法，使其能在这些DAG上适应性地进行联合对齐操作。通过研究LLM和扩散模型的联合对齐案例，作者证明了其方法的有效性。这项工作对于复合AI系统的对齐研究提供了新的见解，并为其未来的发展奠定了基础。<br /><br /> <div>
arXiv:2502.17721v1 Announce Type: new 
Abstract: Compound AI systems, comprising multiple interacting components such as LLM agents and external tools, demonstrate state-of-the-art results across diverse tasks. It is hence crucial to align components within the system to produce consistent results that match human expectations. However, conventional alignment methods, such as Direct Preference Optimization (DPO), are not directly applicable to compound AI systems. These challenges include the non-differentiable interactions between components, making end-to-end gradient optimization infeasible. Additionally, system-level preferences cannot be directly translated into component-level preferences, further complicating alignment. We address the issues by formulating compound AI systems as Directed Acyclic Graphs (DAGs), capturing the connections between agents and the data generation processes. We propose a system-level DPO (SysDPO) to jointly align compound systems by adapting the DPO to operate on these DAGs. We study the joint alignment of an LLM and a diffusion model to demonstrate the effectiveness of our approach. Our exploration provides insights into the alignment of compound AI systems and lays a foundation for future advancements.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Applications of deep reinforcement learning to urban transit network design</title>
<link>https://arxiv.org/abs/2502.17758</link>
<guid>https://arxiv.org/abs/2502.17758</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、神经网络、公交网络设计问题、Markov决策过程、混合算法

总结:
本文探讨了使用强化学习训练神经网络以辅助公共交通网络设计的方法。研究主要关注公交网络设计问题（TNDP），这是一个具有实际重要性的优化问题。与传统采用元启发式算法（如遗传算法和蚁群优化）不同，文中采用了强化学习的方法，将构建公交路线集的问题建模为马尔科夫决策过程（MDP），并通过训练神经网络策略作为该MDP中的智能体。进一步地，研究表明这个经过强化学习训练的神经网络策略不仅可以直接用于规划公交网络，还可以与现有的元启发式算法结合，既用于初始化解决方案，也可在搜索解空间的过程中提出有潜力的操作建议。通过这种混合算法，利用经强化学习训练的神经策略作为经典元启发式框架的核心组件，可以规划出优于单一神经策略或元启发式算法的公交网络。文章通过重新设计加拿大魁北克省拉瓦尔市的公交网络并进行模拟验证，结果显示，由此产生的公交网络能提供更好的服务且成本更低。 <div>
arXiv:2502.17758v1 Announce Type: new 
Abstract: This thesis concerns the use of reinforcement learning to train neural networks to aid in the design of public transit networks. The Transit Network Design Problem (TNDP) is an optimization problem of considerable practical importance. Given a city with an existing road network and travel demands, the goal is to find a set of transit routes - each of which is a path through the graph - that collectively satisfy all demands, while minimizing a cost function that may depend both on passenger satisfaction and operating costs. The existing literature on this problem mainly considers metaheuristic optimization algorithms, such as genetic algorithms and ant-colony optimization. By contrast, we begin by taking a reinforcement learning approach, formulating the construction of a set of transit routes as a Markov Decision Process (MDP) and training a neural net policy to act as the agent in this MDP. We then show that, beyond using this policy to plan a transit network directly, it can be combined with existing metaheuristic algorithms, both to initialize the solution and to suggest promising moves at each step of a search through solution space. We find that such hybrid algorithms, which use a neural policy trained via reinforcement learning as a core component within a classical metaheuristic framework, can plan transit networks that are superior to those planned by either the neural policy or the metaheuristic algorithm. We demonstrate the utility of our approach by using it to redesign the transit network for the city of Laval, Quebec, and show that in simulation, the resulting transit network provides better service at lower cost than the existing transit network.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Information Disclosure Makes Simple Mechanisms Competitive</title>
<link>https://arxiv.org/abs/2502.17809</link>
<guid>https://arxiv.org/abs/2502.17809</guid>
<content:encoded><![CDATA[
<div> 关键词：信息结构、机制设计、多维度、信息披露、物品定价

总结:
本文探讨了在机制设计中，当信息结构可由设计师影响时，简单机制的竞争优势。研究内容是对Bergemann和Pesendorfer（2007）提出的单维模型的多维度推广，其中设计师可以通过信息披露来塑造信息结构。文章聚焦于一个多商品销售问题，卖方需要向有单位需求的买方出售m件商品以最大化其收入，买方对各商品的价值可能存在任意相关性。主要结果表明，通过适当选择信息披露方案，采用物品定价策略（即对每件商品设定一口价）可以实现高度竞争力，保证至少获得最优收益的50.1%。这是首次在不假设买方价值分布的前提下，证明在这样的多维度场景中，简单机制具有（近似）最优性的结果。这一发现不仅展示了信息披露如何提升简单机制的性能，还为重新评估多维度环境中简单机制的有效性提供了一个新框架。 <div>
arXiv:2502.17809v1 Announce Type: new 
Abstract: In classical mechanism design, the prevailing assumption is that the information structure about agents' types is exogenous. This assumption introduces complexity, especially with multi-dimensional agent types, leading to mechanisms that, while optimal, may appear complex and unnatural. Furthermore, Hart and Nisan (2019) show that the gap between the performance of any simple mechanism and the optimal solution could be potentially unbounded. We challenge this conventional view by showing that simple mechanisms can be highly competitive if the information structure is endogenous and can be influenced by the designer.
  We study a multi-dimensional generalization of a single-dimensional model proposed by Bergemann and Pesendorfer (2007), where the designer can shape the information structure via information disclosure. Specifically, we consider a fundamental multi-dimensional mechanism design problem, where a seller is selling m items to a single unit-demand buyer to maximize her revenue. The buyer's values can be arbitrarily correlated across the items. Our main result shows that, following an appropriately chosen information disclosure scheme, item pricing, i.e., set a take-it-or-leave-it price on each item is highly competitive and guarantees to attain at least 50.1% of the optimal revenue. To our knowledge, this is the first result demonstrating the (approximate) optimality of simple mechanisms in this extensively studied multi-dimensional setting, without making any assumptions about the buyer's value distribution. We believe our result not only demonstrates the power of information disclosure in enhancing the performance of simple mechanisms but also suggests a new framework for reevaluating their efficacy in multi-dimensional settings.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Safe Multi-Agent Navigation guided by Goal-Conditioned Safe Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17813</link>
<guid>https://arxiv.org/abs/2502.17813</guid>
<content:encoded><![CDATA[
<div> 关键词：安全导航、自主系统、强化学习、规划方法、多智能体

总结:
本文提出了一种融合规划方法和安全强化学习优势的新颖方法，用于解决在危险环境中的自主系统的安全导航问题。该方法结合目标条件化的强化学习和安全强化学习，学习目标条件化策略并自动估计累积距离和安全性水平。通过构建基于回放缓冲区状态的图，删除不安全边并生成路径点计划，使得智能体能在平衡速度与安全性的同时实现长距离目标导航。

对于多智能体的安全导航问题，该方法利用冲突避免搜索（CBS）为多个智能体创建路径点计划，从而确保它们在扩展的时间范围内实现安全导航，提高了目标条件化安全强化学习在多智能体场景下的可扩展性和协调效率。

与现有的最佳基线方案进行广泛的基准测试表明，我们的方法在复杂和危险环境中能够有效地使多个智能体安全地达成距离目标。相关代码将公开发布，以支持未来的研究。 <div>
arXiv:2502.17813v1 Announce Type: new 
Abstract: Safe navigation is essential for autonomous systems operating in hazardous environments. Traditional planning methods excel at long-horizon tasks but rely on a predefined graph with fixed distance metrics. In contrast, safe Reinforcement Learning (RL) can learn complex behaviors without relying on manual heuristics but fails to solve long-horizon tasks, particularly in goal-conditioned and multi-agent scenarios.
  In this paper, we introduce a novel method that integrates the strengths of both planning and safe RL. Our method leverages goal-conditioned RL and safe RL to learn a goal-conditioned policy for navigation while concurrently estimating cumulative distance and safety levels using learned value functions via an automated self-training algorithm. By constructing a graph with states from the replay buffer, our method prunes unsafe edges and generates a waypoint-based plan that the agent follows until reaching its goal, effectively balancing faster and safer routes over extended distances.
  Utilizing this unified high-level graph and a shared low-level goal-conditioned safe RL policy, we extend this approach to address the multi-agent safe navigation problem. In particular, we leverage Conflict-Based Search (CBS) to create waypoint-based plans for multiple agents allowing for their safe navigation over extended horizons. This integration enhances the scalability of goal-conditioned safe RL in multi-agent scenarios, enabling efficient coordination among agents.
  Extensive benchmarking against state-of-the-art baselines demonstrates the effectiveness of our method in achieving distance goals safely for multiple agents in complex and hazardous environments. Our code will be released to support future research.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CAML: Collaborative Auxiliary Modality Learning for Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.17821</link>
<guid>https://arxiv.org/abs/2502.17821</guid>
<content:encoded><![CDATA[
<div> 关键词: 多模态学习、协同辅助模态学习(CAML)、多智能体、事故检测、语义分割

总结:
本文提出了一种新的多模态学习框架——协同辅助模态学习(CAML)，用于解决单一智能体在动态环境中因数据不完整而导致决策盲点的问题。CAML允许多智能体在训练过程中协作并共享多模态数据，而在测试阶段每个智能体可以仅依赖减少的模态进行推理。通过对CAML从不确定性减小和数据覆盖角度的系统分析，证明了其相较于现有方法的优势。实验结果表明，在协同决策制定中，CAML对于联网自动驾驶车辆的事故检测性能提高了高达58.13%，并在真实世界无人机-地面机器人数据上的协同语义分割任务中实现了最高10.61%的mIoU提升。<br /><br /> <div>
arXiv:2502.17821v1 Announce Type: new 
Abstract: Multi-modality learning has become a crucial technique for improving the performance of machine learning applications across domains such as autonomous driving, robotics, and perception systems. While existing frameworks such as Auxiliary Modality Learning (AML) effectively utilize multiple data sources during training and enable inference with reduced modalities, they primarily operate in a single-agent context. This limitation is particularly critical in dynamic environments, such as connected autonomous vehicles (CAV), where incomplete data coverage can lead to decision-making blind spots. To address these challenges, we propose Collaborative Auxiliary Modality Learning ($\textbf{CAML}$), a novel multi-agent multi-modality framework that enables agents to collaborate and share multimodal data during training while allowing inference with reduced modalities per agent during testing. We systematically analyze the effectiveness of $\textbf{CAML}$ from the perspective of uncertainty reduction and data coverage, providing theoretical insights into its advantages over AML. Experimental results in collaborative decision-making for CAV in accident-prone scenarios demonstrate that \ours~achieves up to a ${\bf 58.13}\%$ improvement in accident detection. Additionally, we validate $\textbf{CAML}$ on real-world aerial-ground robot data for collaborative semantic segmentation, achieving up to a ${\bf 10.61}\%$ improvement in mIoU.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SYNTHEMPATHY: A Scalable Empathy Corpus Generated Using LLMs Without Any Crowdsourcing</title>
<link>https://arxiv.org/abs/2502.17857</link>
<guid>https://arxiv.org/abs/2502.17857</guid>
<content:encoded><![CDATA[
<div> 关键词: 语言模型、同理心、对话代理、大规模语料库、SYNTHEMPATHY

总结:<br />
该研究提出了一种数据生成框架，用于构建名为SYNTHEMPATHY的大规模同理心语料库，其中包含了105k条针对真实情境的同理心回复。由于现有的同理心对话语料库主要依赖于昂贵、耗时且不可扩展的人工众包方式，因此这一新方法通过LLM生成来解决这个问题。通过对基础的Mistral 7B模型使用SYNTHEMPATHY语料库进行微调，结果显示模型的平均同理心得分有所提高。 <div>
arXiv:2502.17857v1 Announce Type: new 
Abstract: Previous research has shown that humans are more receptive towards language models that that exhibit empathetic behavior. While empathy is essential for developing helpful dialogue agents, very few large corpora containing empathetic dialogues are available for fine-tune LLMs. The few existing corpora have largely relied on crowdsourcing to simulate empathetic conversations, a process that is expensive, time-consuming, and not scalable to larger datasets. We propose a data generation framework for developing SYNTHEMPATHY, a large corpus containing 105k empathetic responses to real-life situations compiled through LLM generation. A base Mistral 7B model fine-tuned on our SYNTHEMPATHY corpus exhibits an increase in the average empathy score.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Maximum Welfare Allocations under Quantile Valuations</title>
<link>https://arxiv.org/abs/2502.17869</link>
<guid>https://arxiv.org/abs/2502.17869</guid>
<content:encoded><![CDATA[
<div> 关键词: quantile 值、偏好聚合、不可分割物品、福利最大化、算法复杂性

总结:<br />
本文提出了一种新的基于分位数值的偏好聚合模型，该模型中每个代理人都具有特定的分位数，而物品集合的价值由其中个体物品价值对应的分位数值定义。这个模型能够捕捉到不同代理人对同一批物品的不同感知方式，弥补了加法估值函数的局限性。文章研究了在这个基于分位数的估值环境中如何最大化功利主义和平均主义福利的问题。对于这两种福利函数，作者分析了其目标的计算复杂性。有趣的是，结果表明，两种目标的复杂度会因是否要求分配平衡而显著变化。对于功利主义福利，文中提供了近似最优算法；而对于平等主义福利，则在可能的情况下提出了精确算法。 <div>
arXiv:2502.17869v1 Announce Type: new 
Abstract: We propose a new model for aggregating preferences over a set of indivisible items based on a quantile value. In this model, each agent is endowed with a specific quantile, and the value of a given bundle is defined by the corresponding quantile of the individual values of the items within it. Our model captures the diverse ways in which agents may perceive a bundle, even when they agree on the values of individual items. It enables richer behavioral modeling that cannot be easily captured by additive valuation functions. We study the problem of maximizing utilitarian and egalitarian welfare within the quantile-based valuation setting. For each of the welfare functions, we analyze the complexity of the objectives. Interestingly, our results show that the complexity of both objectives varies significantly depending on whether the allocation is required to be balanced. We provide near-optimal approximation algorithms for utilitarian welfare, and for egalitarian welfare, we present exact algorithms whenever possible.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Enhanced Immersion and Agency for LLM-based Interactive Drama</title>
<link>https://arxiv.org/abs/2502.17878</link>
<guid>https://arxiv.org/abs/2502.17878</guid>
<content:encoded><![CDATA[
<div> 关键词: LLM、互动戏剧、沉浸感、故事叙述、情节反思

总结:
本文探讨了LLM（大型语言模型）为基础的交互式戏剧，这是一种新的AI对话场景，玩家在游戏中扮演角色并与由LLM代理控制的角色进行对话，体验不断发展的故事。文章从两个关键方面理解交互式戏剧：沉浸感，即玩家对故事的参与感；以及能动性，即玩家影响故事世界的能力。为增强这两个要素，文章提出了“剧本引导生成”方法，该方法有助于LLM构建结构更佳、叙事质量更高的戏剧故事。同时，引入了基于情节的反思机制，使LLM代理能够更好地调整反应以符合玩家的意图。评估通过人类判断来衡量我们的方法在提升沉浸感和能动性方面的成效。 <div>
arXiv:2502.17878v1 Announce Type: new 
Abstract: LLM-based Interactive Drama is a novel AI-based dialogue scenario, where the user (i.e. the player) plays the role of a character in the story, has conversations with characters played by LLM agents, and experiences an unfolding story. This paper begins with understanding interactive drama from two aspects: Immersion, the player's feeling of being present in the story, and Agency, the player's ability to influence the story world. Both are crucial to creating an enjoyable interactive experience, while they have been underexplored in previous work. To enhance these two aspects, we first propose Playwriting-guided Generation, a novel method that helps LLMs craft dramatic stories with substantially improved structures and narrative quality. Additionally, we introduce Plot-based Reflection for LLM agents to refine their reactions to align with the player's intentions. Our evaluation relies on human judgment to assess the gains of our methods in terms of immersion and agency.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Sustainable Web Agents: A Plea for Transparency and Dedicated Metrics for Energy Consumption</title>
<link>https://arxiv.org/abs/2502.17903</link>
<guid>https://arxiv.org/abs/2502.17903</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、Web代理、可持续性、能源消耗、CO2排放

总结:<br />
本文探讨了大型语言模型领域中，特别是能够自主与互联网交互的Web代理的研究进展。文章指出，尽管此类Web代理有潜力成为强大日常助手，但对其可持续性的研究尚不充分。通过对Web代理的能源和CO2成本进行初步探究，结果显示创建理念的不同会对能源消耗产生显著影响。同时，文章指出了部分Web代理在披露模型参数和使用过程方面的透明度不足，这限制了对能源消耗的准确估计。因此，作者主张在评估Web代理时应引入专门针对能源消耗和可持续性的指标。 <div>
arXiv:2502.17903v1 Announce Type: new 
Abstract: Improvements in the area of large language models have shifted towards the construction of models capable of using external tools and interpreting their outputs. These so-called web agents have the ability to interact autonomously with the internet. This allows them to become powerful daily assistants handling time-consuming, repetitive tasks while supporting users in their daily activities. While web agent research is thriving, the sustainability aspect of this research direction remains largely unexplored. We provide an initial exploration of the energy and CO2 cost associated with web agents. Our results show how different philosophies in web agent creation can severely impact the associated expended energy. We highlight lacking transparency regarding the disclosure of model parameters and processes used for some web agents as a limiting factor when estimating energy consumption. As such, our work advocates a change in thinking when evaluating web agents, warranting dedicated metrics for energy consumption and sustainability.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FACT-AUDIT: An Adaptive Multi-Agent Framework for Dynamic Fact-Checking Evaluation of Large Language Models</title>
<link>https://arxiv.org/abs/2502.17924</link>
<guid>https://arxiv.org/abs/2502.17924</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、事实核查、FACT-AUDIT、动态评估、信任度

<br /><br />总结:
本文介绍了大型语言模型（LLMs）在事实核查领域的进步，但现有的自动化事实核查评价方法依赖静态数据集和分类指标，无法自动评估LLMs在事实核查中的解释生成能力和发现其细微局限性。为解决这一问题，文章提出了一个名为FACT-AUDIT的代理驱动框架，该框架利用重要性采样原理和多代理协作，生成适应性和可扩展的数据集，进行迭代的模型为中心的评估，并根据模型特定响应更新评估。通过结合判断预测与解释生成，该框架对LLMs的事实推理能力进行全面而不断演进的审计，以探究其可信度。实验表明，FACT-AUDIT能够有效地区分最先进的LLMs，并为模型中心的事实核查分析提供了有关模型优缺点的有价值见解。 <div>
arXiv:2502.17924v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have significantly advanced the fact-checking studies. However, existing automated fact-checking evaluation methods rely on static datasets and classification metrics, which fail to automatically evaluate the justification production and uncover the nuanced limitations of LLMs in fact-checking. In this work, we introduce FACT-AUDIT, an agent-driven framework that adaptively and dynamically assesses LLMs' fact-checking capabilities. Leveraging importance sampling principles and multi-agent collaboration, FACT-AUDIT generates adaptive and scalable datasets, performs iterative model-centric evaluations, and updates assessments based on model-specific responses. By incorporating justification production alongside verdict prediction, this framework provides a comprehensive and evolving audit of LLMs' factual reasoning capabilities, to investigate their trustworthiness. Extensive experiments demonstrate that FACT-AUDIT effectively differentiates among state-of-the-art LLMs, providing valuable insights into model strengths and limitations in model-centric fact-checking analysis.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Assessing Large Language Models in Agentic Multilingual National Bias</title>
<link>https://arxiv.org/abs/2502.17945</link>
<guid>https://arxiv.org/abs/2502.17945</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 跨语言偏见, 决策建议, 多语种推荐, 语言模型评分偏差

<br /><br />总结:
本文首次针对大型语言模型在跨语言决策建议任务中的应用及其潜在偏见进行了深入研究。研究涉及大学申请、旅行和迁移三个关键场景，通过分析多语言状态下最先进的LLMs对决策任务的响应，量化了模型生成分数中的偏见，并考察了人口统计因素和推理策略（如Chain-of-Thought提示）对偏见模式的影响。结果发现，本地语言偏见普遍存在各类任务中，尽管GPT-4和Sonnet在英语国家的偏见方面较GPT-3.5有所减少，但仍未能实现稳健的多语言对齐，这对多语种AI代理和应用如教育等领域提出了更广泛的启示。 <div>
arXiv:2502.17945v1 Announce Type: new 
Abstract: Large Language Models have garnered significant attention for their capabilities in multilingual natural language processing, while studies on risks associated with cross biases are limited to immediate context preferences. Cross-language disparities in reasoning-based recommendations remain largely unexplored, with a lack of even descriptive analysis. This study is the first to address this gap. We test LLM's applicability and capability in providing personalized advice across three key scenarios: university applications, travel, and relocation. We investigate multilingual bias in state-of-the-art LLMs by analyzing their responses to decision-making tasks across multiple languages. We quantify bias in model-generated scores and assess the impact of demographic factors and reasoning strategies (e.g., Chain-of-Thought prompting) on bias patterns. Our findings reveal that local language bias is prevalent across different tasks, with GPT-4 and Sonnet reducing bias for English-speaking countries compared to GPT-3.5 but failing to achieve robust multilingual alignment, highlighting broader implications for multilingual AI agents and applications such as education.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Advising Agent for Supporting Human-Multi-Drone Team Collaboration</title>
<link>https://arxiv.org/abs/2502.17960</link>
<guid>https://arxiv.org/abs/2502.17960</guid>
<content:encoded><![CDATA[
<div> 关键词：多无人机系统、自主控制、人机团队、搜索与救援、建议代理

<br /><br />总结:
本文介绍了针对多无人机系统在搜索与救援（SAR）等关键任务中的应用，由于复杂环境和不确定性，人类操作员在实时决策中可能效率低下。为解决此问题，研究者提出了一种建议代理算法，旨在增强人-多无人机团队的合作。该代理通过少量的人类操作示范生成类似真实人类的操作轨迹，并运用机器学习进行长期效果预测，从而向操作员提供上下文相关的行动建议。通过人类评估验证，该方法提供的辅助质量高，能显著提升团队执行任务的表现，相比基线条件有明显改善。 <div>
arXiv:2502.17960v1 Announce Type: new 
Abstract: Multi-drone systems have become transformative technologies across various industries, offering innovative applications. However, despite significant advancements, their autonomous capabilities remain inherently limited. As a result, human operators are often essential for supervising and controlling these systems, creating what is referred to as a human-multi-drone team. In realistic settings, human operators must make real-time decisions while addressing a variety of signals, such as drone statuses and sensor readings, and adapting to dynamic conditions and uncertainty. This complexity may lead to suboptimal operations, potentially compromising the overall effectiveness of the team. In critical contexts like Search And Rescue (SAR) missions, such inefficiencies can have costly consequences. This work introduces an advising agent designed to enhance collaboration in human-multi-drone teams, with a specific focus on SAR scenarios. The advising agent is designed to assist the human operator by suggesting contextual actions worth taking. To that end, the agent employs a novel computation technique that relies on a small set of human demonstrations to generate varying realistic human-like trajectories. These trajectories are then generalized using machine learning for fast and accurate predictions of the long-term effects of different advice. Through human evaluations, we demonstrate that our approach delivers high-quality assistance, resulting in significantly improved performance compared to baseline conditions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Dynamics of Collective Creativity in Human-AI Social Networks</title>
<link>https://arxiv.org/abs/2502.17962</link>
<guid>https://arxiv.org/abs/2502.17962</guid>
<content:encoded><![CDATA[
<div> 关键词: Generative AI, collective creativity, human-AI interactions, experimental social networks, creative writing task

<br /><br />总结:
该研究通过大型在线实验探究了生成式AI对集体创造力的影响。在涉及879名参与者和AI代理的创造性写作任务中，研究构建了5x5网格为基础的人类或AI社交网络。实验初期，纯AI网络展现出比人类网络及人机混合网络更高的创造力和多样性。然而，随着时间推移，人机混合网络在创作多样性上超过了纯AI网络。这主要是因为AI代理在选择、修改和分享故事的过程中保留的内容较少，而人类网络则倾向于保持故事的连续性。这些发现强调了利用实验性社交网络来理解人机融合社会的价值。 <div>
arXiv:2502.17962v1 Announce Type: new 
Abstract: Generative AI is reshaping modern culture, enabling individuals to create high-quality outputs across domains such as images, text, and music. However, we know little about the impact of generative AI on collective creativity. This study investigates how human-AI interactions shape collective creativity within experimental social networks. We conducted large-scale online experiments with 879 participants and AI agents in a creative writing task. Participants (either humans or AI) joined 5x5 grid-based networks, and were asked to iteratively select, modify, and share stories. Initially, AI-only networks showed greater creativity (rated by a separate group of 94 human raters) and diversity than human-only and human-AI networks. However, over time, hybrid human-AI networks became more diverse in their creations than AI-only networks. In part, this is because AI agents retained little from the original stories, while human-only networks preserved continuity. These findings highlight the value of experimental social networks in understanding human-AI hybrid societies.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>LLM Knows Geometry Better than Algebra: Numerical Understanding of LLM-Based Agents in A Trading Arena</title>
<link>https://arxiv.org/abs/2502.17967</link>
<guid>https://arxiv.org/abs/2502.17967</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、数值推理、Agent Trading Arena、几何推理、反射模块

<br /><br />总结:

本文研究了大型语言模型（LLMs）在动态任务中的泛化能力，特别是在数值推理方面的表现。研究者设计了一个名为Agent Trading Arena的虚拟经济系统游戏，通过零和博弈让代理进行股票投资，以此来评估LLM处理文本股票数据的能力。实验发现，LLMs在处理纯文本股票数据时对代数推理有困难，倾向于关注局部细节而非全局趋势。然而，当呈现视觉数据，如散点图或K线图表时，LLMs在几何推理方面表现出色，表明视觉表示能够增强数值推理能力。进一步地，引入反射模块可以提升LLMs分析和解释复杂数据的能力。该研究使用NASDAQ股票数据集验证了这些发现，结果表明LLMs在处理视觉数据时相比文本数据展现出更强的推理能力。相关代码和数据已在https://github.com/wekjsdvnm/Agent-Trading-Arena.git上公开。 <div>
arXiv:2502.17967v1 Announce Type: new 
Abstract: Recent advancements in large language models (LLMs) have significantly improved performance in natural language processing tasks. However, their ability to generalize to dynamic, unseen tasks, particularly in numerical reasoning, remains a challenge. Existing benchmarks mainly evaluate LLMs on problems with predefined optimal solutions, which may not align with real-world scenarios where clear answers are absent. To bridge this gap, we design the Agent Trading Arena, a virtual numerical game simulating complex economic systems through zero-sum games, where agents invest in stock portfolios. Our experiments reveal that LLMs, including GPT-4o, struggle with algebraic reasoning when dealing with plain-text stock data, often focusing on local details rather than global trends. In contrast, LLMs perform significantly better with geometric reasoning when presented with visual data, such as scatter plots or K-line charts, suggesting that visual representations enhance numerical reasoning. This capability is further improved by incorporating the reflection module, which aids in the analysis and interpretation of complex data. We validate our findings on NASDAQ Stock dataset, where LLMs demonstrate stronger reasoning with visual data compared to text. Our code and data are publicly available at https://github.com/wekjsdvnm/Agent-Trading-Arena.git.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ViDoRAG: Visual Document Retrieval-Augmented Generation via Dynamic Iterative Reasoning Agents</title>
<link>https://arxiv.org/abs/2502.18017</link>
<guid>https://arxiv.org/abs/2502.18017</guid>
<content:encoded><![CDATA[
<div> 关键词: ViDoSeek、Retrieval-Augmented Generation (RAG)、ViDoRAG、多模态检索、复杂推理

总结:<br />
本文提出了一种新的数据集ViDoSeek，用于评估RAG方法处理富含视觉信息文档的能力，并指出了当前RAG方法的两个主要局限：视觉检索方法难以有效融合文本和视觉特征，以及现有方法对推理令牌的分配不足。为解决这些问题，文章提出了ViDoRAG，这是一种针对视觉文档复杂推理的新型多代理RAG框架。ViDoRAG采用基于高斯混合模型（GMM）的混合策略进行有效的多模态检索，并通过探索、摘要和反思的迭代代理工作流程来增强模型的推理能力。实验结果表明，ViDoRAG在ViDoSeek基准测试上相比于现有方法性能提升了超过10%。 <div>
arXiv:2502.18017v1 Announce Type: new 
Abstract: Understanding information from visually rich documents remains a significant challenge for traditional Retrieval-Augmented Generation (RAG) methods. Existing benchmarks predominantly focus on image-based question answering (QA), overlooking the fundamental challenges of efficient retrieval, comprehension, and reasoning within dense visual documents. To bridge this gap, we introduce ViDoSeek, a novel dataset designed to evaluate RAG performance on visually rich documents requiring complex reasoning. Based on it, we identify key limitations in current RAG approaches: (i) purely visual retrieval methods struggle to effectively integrate both textual and visual features, and (ii) previous approaches often allocate insufficient reasoning tokens, limiting their effectiveness. To address these challenges, we propose ViDoRAG, a novel multi-agent RAG framework tailored for complex reasoning across visual documents. ViDoRAG employs a Gaussian Mixture Model (GMM)-based hybrid strategy to effectively handle multi-modal retrieval. To further elicit the model's reasoning capabilities, we introduce an iterative agent workflow incorporating exploration, summarization, and reflection, providing a framework for investigating test-time scaling in RAG domains. Extensive experiments on ViDoSeek validate the effectiveness and generalization of our approach. Notably, ViDoRAG outperforms existing methods by over 10% on the competitive ViDoSeek benchmark.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OpenFly: A Versatile Toolchain and Large-scale Benchmark for Aerial Vision-Language Navigation</title>
<link>https://arxiv.org/abs/2502.18041</link>
<guid>https://arxiv.org/abs/2502.18041</guid>
<content:encoded><![CDATA[
<div> 关键词：Vision-Language Navigation (VLN)，户外航拍VLN，OpenFly，数据收集工具链，大规模基准，自动飞行轨迹创建，指令生成，Unreal Engine，GTA V，Google Earth，3D Gaussian Splatting (3D GS)，真实感渲染，OpenFly-Agent，关键帧感知模型。

<br /><br />总结:
本文提出了一种名为OpenFly的新平台，旨在解决户外航拍视觉语言导航(VLN)研究不足的问题。该平台包括一个自动化数据收集工具链，用于实现点云获取、场景语义分割、飞行轨迹创建和指令生成等。利用此工具链，他们构建了一个覆盖18个场景、包含10万条轨迹的大规模航拍VLN数据集，数据集采用不同渲染引擎（如Unreal Engine、GTA V、Google Earth）及3D GS技术生成，具有高视觉质量并支持从实境到模拟的真实感渲染。此外，文章还介绍了一个基于OpenFly的航拍VLN模型——OpenFly-Agent，该模型输入语言指令、当前观测值和历史关键帧，直接输出飞行操作。通过广泛的分析与实验，证实了OpenFly平台和OpenFly-Agent的优势。所涉及的工具链、数据集和代码都将开源。 <div>
arXiv:2502.18041v1 Announce Type: new 
Abstract: Vision-Language Navigation (VLN) aims to guide agents through an environment by leveraging both language instructions and visual cues, playing a pivotal role in embodied AI. Indoor VLN has been extensively studied, whereas outdoor aerial VLN remains underexplored. The potential reason is that outdoor aerial view encompasses vast areas, making data collection more challenging, which results in a lack of benchmarks. To address this problem, we propose OpenFly, a platform comprising a versatile toolchain and large-scale benchmark for aerial VLN. Firstly, we develop a highly automated toolchain for data collection, enabling automatic point cloud acquisition, scene semantic segmentation, flight trajectory creation, and instruction generation. Secondly, based on the toolchain, we construct a large-scale aerial VLN dataset with 100k trajectories, covering diverse heights and lengths across 18 scenes. The corresponding visual data are generated using various rendering engines and advanced techniques, including Unreal Engine, GTA V, Google Earth, and 3D Gaussian Splatting (3D GS). All data exhibit high visual quality. Particularly, 3D GS supports real-to-sim rendering, further enhancing the realism of the dataset. Thirdly, we propose OpenFly-Agent, a keyframe-aware VLN model, which takes language instructions, current observations, and historical keyframes as input, and outputs flight actions directly. Extensive analyses and experiments are conducted, showcasing the superiority of our OpenFly platform and OpenFly-Agent. The toolchain, dataset, and codes will be open-sourced.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing Reusability of Learned Skills for Robot Manipulation via Gaze and Bottleneck</title>
<link>https://arxiv.org/abs/2502.18121</link>
<guid>https://arxiv.org/abs/2502.18121</guid>
<content:encoded><![CDATA[
<div> 关键词：自主代理、多样性操作、深度学习、泛化能力、GazeBot

<br /><br />总结:
本文提出了一种名为GazeBot的新算法，旨在使自主机器人能够在不同场景中高效复用广泛的操作技能。针对当前深度学习方法在将习得技能泛化到未知情境中的挑战，GazeBot利用目光信息和动作瓶颈这两个对物体操纵至关重要的特征，实现了与现有最先进的模仿学习方法相比更高的泛化性能，同时并未牺牲其灵巧性和反应性。此外，一旦提供了包含目光数据的演示数据集，GazeBot的训练过程就完全基于数据驱动。相关视频和代码可在https://crumbyrobotics.github.io/gazebot获取。 <div>
arXiv:2502.18121v1 Announce Type: new 
Abstract: Autonomous agents capable of diverse object manipulations should be able to acquire a wide range of manipulation skills with high reusability. Although advances in deep learning have made it increasingly feasible to replicate the dexterity of human teleoperation in robots, generalizing these acquired skills to previously unseen scenarios remains a significant challenge. In this study, we propose a novel algorithm, Gaze-based Bottleneck-aware Robot Manipulation (GazeBot), which enables high reusability of the learned motions even when the object positions and end-effector poses differ from those in the provided demonstrations. By leveraging gaze information and motion bottlenecks, both crucial features for object manipulation, GazeBot achieves high generalization performance compared with state-of-the-art imitation learning methods, without sacrificing its dexterity and reactivity. Furthermore, the training process of GazeBot is entirely data-driven once a demonstration dataset with gaze data is provided. Videos and code are available at https://crumbyrobotics.github.io/gazebot.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Large Language Model Driven Agents for Simulating Echo Chamber Formation</title>
<link>https://arxiv.org/abs/2502.18138</link>
<guid>https://arxiv.org/abs/2502.18138</guid>
<content:encoded><![CDATA[
<div> 关键词：echo chambers, social media, large language models, simulation, polarization

总结:<br />
本文提出了一种新颖的框架，利用大型语言模型（LLMs）作为生成代理来模拟社交网络中的回声室效应动态。该框架同时考虑了由LLMs驱动的意见更新和网络重连行为，从而实现对社会互动的语境感知和语义丰富的仿真。为了验证这种方法的真实性和准确性，研究者使用实际的Twitter数据与其仿真结果进行对比分析。实验结果显示，LLMs在模拟回声室形成方面具有有效性，能够捕捉到意见聚类的结构和语义维度，为深入理解社会影响力动态以及研究在线社区中的极化现象提供了一个新的工具。 <div>
arXiv:2502.18138v1 Announce Type: new 
Abstract: The rise of echo chambers on social media platforms has heightened concerns about polarization and the reinforcement of existing beliefs. Traditional approaches for simulating echo chamber formation have often relied on predefined rules and numerical simulations, which, while insightful, may lack the nuance needed to capture complex, real-world interactions. In this paper, we present a novel framework that leverages large language models (LLMs) as generative agents to simulate echo chamber dynamics within social networks. The novelty of our approach is that it incorporates both opinion updates and network rewiring behaviors driven by LLMs, allowing for a context-aware and semantically rich simulation of social interactions. Additionally, we utilize real-world Twitter (now X) data to benchmark the LLM-based simulation against actual social media behaviors, providing insights into the accuracy and realism of the generated opinion trends. Our results demonstrate the efficacy of LLMs in modeling echo chamber formation, capturing both structural and semantic dimensions of opinion clustering. %This work contributes to a deeper understanding of social influence dynamics and offers a new tool for studying polarization in online communities.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Carbon and Silicon, Coexist or Compete? A Survey on Human-AI Interactions in Agent-based Modeling and Simulation</title>
<link>https://arxiv.org/abs/2502.18145</link>
<guid>https://arxiv.org/abs/2502.18145</guid>
<content:encoded><![CDATA[
<div> 关键词：agent-based modeling and simulation (ABMS)，large language models (LLMs)，human-AI交互，分类体系，未来研究方向

<br /><br />总结:
该文探讨了在基于代理的建模和模拟(ABMS)中，随着大型语言模型(LLMs)广泛应用而日益增长的人工智能与人类交互的研究兴趣。文章指出，将LLMs融入ABMS可以实现自然语言交互，但同时也带来了新的挑战，需要通过人类交互来解决。本文对现有工作进行了调查并提出了一种新型分类体系，将用户（在此指使用ABMS工具进行研究的研究人员）的交互行为按照目的（Why）、参与阶段（When）、系统组件（What）、用户角色（Who）以及交互方式（How）五个维度进行分类。分析结果揭示了现有的交互模式，为开发人机交互提供了全面指导。此外，文章还讨论了未探索的交互领域，并提出了未来的研究方向。 <div>
arXiv:2502.18145v1 Announce Type: new 
Abstract: Recent interest in human-AI interactions in agent-based modeling and simulation (ABMS) has grown rapidly due to the widespread utilization of large language models (LLMs). ABMS is an intelligent approach that simulates autonomous agents' behaviors within a defined environment to research emergent phenomena. Integrating LLMs into ABMS enables natural language interaction between humans and models. Meanwhile, it introduces new challenges that rely on human interaction to address. Human involvement can assist ABMS in adapting to flexible and complex research demands. However, systematic reviews of interactions that examine how humans and AI interact in ABMS are lacking. In this paper, we investigate existing works and propose a novel taxonomy to categorize the interactions derived from them. Specifically, human users refer to researchers who utilize ABMS tools to conduct their studies in our survey. We decompose interactions into five dimensions: the goals that users want to achieve (Why), the phases that users are involved (When), the components of the system (What), the roles of users (Who), and the means of interactions (How). Our analysis summarizes the findings that reveal existing interaction patterns. They provide researchers who develop interactions with comprehensive guidance on how humans and AI interact. We further discuss the unexplored interactions and suggest future research directions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChatMotion: A Multimodal Multi-Agent for Human Motion Analysis</title>
<link>https://arxiv.org/abs/2502.18180</link>
<guid>https://arxiv.org/abs/2502.18180</guid>
<content:encoded><![CDATA[
<div> 关键词：Multimodal Large Language Models (MLLMs)，ChatMotion，多模态多智能体框架，人类运动分析，交互性

<br />
总结:

本文介绍了随着Multimodal Large Language Models (MLLMs)技术的进步，人类对运动理解的能力得到提升。然而，这类模型仍然受限于其“指令驱动”性质，缺乏交互性和适应不同分析视角的能力。为解决这些问题，文章提出了ChatMotion，一个多模态多智能体的人类运动分析框架。ChatMotion能够动态解释用户意图，将复杂任务分解为元任务，并激活专门的功能模块以进行运动理解。它集成了多个专业模块，如MotionCore，从多种角度分析人类运动。通过广泛的实验验证，ChatMotion展现了在人类运动理解方面的精确度、适应性和用户参与度。 <div>
arXiv:2502.18180v1 Announce Type: new 
Abstract: Advancements in Multimodal Large Language Models (MLLMs) have improved human motion understanding. However, these models remain constrained by their "instruct-only" nature, lacking interactivity and adaptability for diverse analytical perspectives. To address these challenges, we introduce ChatMotion, a multimodal multi-agent framework for human motion analysis. ChatMotion dynamically interprets user intent, decomposes complex tasks into meta-tasks, and activates specialized function modules for motion comprehension. It integrates multiple specialized modules, such as the MotionCore, to analyze human motion from various perspectives. Extensive experiments demonstrate ChatMotion's precision, adaptability, and user engagement for human motion understanding.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Intersubjective Model of AI-mediated Communication: Augmenting Human-Human Text Chat through LLM-based Adaptive Agent Pair</title>
<link>https://arxiv.org/abs/2502.18201</link>
<guid>https://arxiv.org/abs/2502.18201</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、AI中介通信、交互主体性模型、沟通适应性、文本聊天系统

总结:
本文提出了一个新的通信模型——交互主体性模型(AI中介通信)，该模型利用大型语言模型为基础的自适应代理来增强人类之间的交流。与传统通信模型关注信息准确传输不同，交互主体性模型允许实时动态地塑造消息内容，促进参与交流的人类之间形成共享的理解。为了展示这一模型的潜力和设计空间，作者开发了一个基于该模型的原型文本聊天系统。 <div>
arXiv:2502.18201v1 Announce Type: new 
Abstract: The growing prevalence of Large Language Models (LLMs) is reshaping online text-based communication; a transformation that is extensively studied as AI-mediated communication. However, much of the existing research remains bound by traditional communication models, where messages are created and transmitted directly between humans despite LLMs being able to play a more active role in transforming messages. In this work, we propose the Intersubjective Model of AI-mediated Communication, an alternative communication model that leverages LLM-based adaptive agents to augment human-human communication. Unlike traditional communication models that focus on the accurate transmission of information, the Intersubjective Model allows for communication to be designed in an adaptive and customizable way to create alternative interactions by dynamically shaping messages in real time and facilitating shared understanding between the human participants. In this paper, we have developed a prototype text chat system based on the Intersubjective Model to describe the potential of this model, as well as the design space it affords.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Competitive Posted-Price Mechanism for Online Budget-Feasible Auctions</title>
<link>https://arxiv.org/abs/2502.18265</link>
<guid>https://arxiv.org/abs/2502.18265</guid>
<content:encoded><![CDATA[
<div> 关键词：在线采购拍卖、单次定价机制、竞争比、预算约束、单调子模函数

总结:
本文研究了在线采购拍卖问题，其中代理人随机顺序到达并拥有私人成本。买方的目标是在支付预算约束下，通过选取一组服务提供者来最大化其对应的单调子模函数价值。文章提出了一个具有常数竞争比的随机化单次定价机制，解决了(Badanidiyuru, Kleinberg 和 Singer, EC 2012)中提出的主要开放性问题。该机制通过学习并估计最优价值（OPT），根据此来决定向代理人提供的支付。主要挑战在于如何从代理人的接受/拒绝响应中以常数因子精度学习到OPT。作者的方法基于一个在线测试，用于判断估算是否过低，并设计了一个自适应搜索算法逐步细化估算值。 <div>
arXiv:2502.18265v1 Announce Type: new 
Abstract: We consider online procurement auctions, where the agents arrive sequentially, in random order, and have private costs for their services. The buyer aims to maximize a monotone submodular value function for the subset of agents whose services are procured, subject to a budget constraint on their payments. We consider a posted-price setting where upon each agent's arrival, the buyer decides on a payment offered to them. The agent accepts or rejects the offer, depending on whether the payment exceeds their cost, without revealing any other information about their private costs whatsoever. We present a randomized online posted-price mechanism with constant competitive ratio, thus resolving the main open question of (Badanidiyuru, Kleinberg and Singer, EC 2012). Posted-price mechanisms for online procurement typically operate by learning an estimation of the optimal value, denoted as OPT, and using it to determine the payments offered to the agents. The main challenge is to learn OPT within a constant factor from the agents' accept / reject responses to the payments offered. Our approach is based on an online test of whether our estimation is too low compared against OPT and a carefully designed adaptive search that gradually refines our estimation.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Smart and Efficient IoT-Based Irrigation System Design: Utilizing a Hybrid Agent-Based and System Dynamics Approach</title>
<link>https://arxiv.org/abs/2502.18298</link>
<guid>https://arxiv.org/abs/2502.18298</guid>
<content:encoded><![CDATA[
<div> 关键词: 水资源稀缺、物联网(IoT)、智能灌溉系统、Agent-oriented软件工程(AOSE)、Prometheus方法、系统动力学、AnyLogic模拟软件

<br /><br />总结:
本文针对水资源日益紧缺以及人口增长带来的灌溉用水不足问题，提出了一种基于物联网技术并运用Agent-oriented软件工程中的Prometheus方法设计的智能灌溉系统。该系统通过传感器、中央代理和灌溉节点协同工作，维持土壤湿度在适宜区间以减少水损失。为模拟该系统，研究者构建了一个融合了agent-based和系统动力学模型的混合模型，并利用AnyLogic软件进行实施。通过对模拟模型中灌溉规则的研究与测试（采用256次运行的分数因子设计），发现系统能在自动灌溉模式下稳定地接近最优灌水量。同时，分析结果显示重要因素如土壤性质对总灌溉水量及总运行时间的影响，进而通过减少运行时间来降低系统的能源消耗。 <div>
arXiv:2502.18298v1 Announce Type: new 
Abstract: Regarding problems like reduced precipitation and an increase in population, water resource scarcity has become one of the most critical problems in modern-day societies, as a consequence, there is a shortage of available water resources for irrigation in arid and semi-arid countries. On the other hand, it is possible to utilize modern technologies to control irrigation and reduce water loss. One of these technologies is the Internet of Things (IoT). Despite the possibility of using the IoT in irrigation control systems, there are complexities in designing such systems. Considering this issue, it is possible to use agent-oriented software engineering (AOSE) methodologies to design complex cyber-physical systems such as IoT-based systems. In this research, a smart irrigation system is designed based on Prometheus AOSE methodology, to reduce water loss by maintaining soil moisture in a suitable interval. The designed system comprises sensors, a central agent, and irrigation nodes. These agents follow defined rules to maintain soil moisture at a desired level cooperatively. For system simulation, a hybrid agent-based and system dynamics model was designed. In this hybrid model, soil moisture dynamics were modeled based on the system dynamics approach. The proposed model, was implemented in AnyLogic computer simulation software. Utilizing the simulation model, irrigation rules were examined. The system's functionality in automatic irrigation mode was tested based on a 256-run, fractional factorial design, and the effects of important factors such as soil properties on total irrigated water and total operation time were analyzed. Based on the tests, the system consistently irrigated nearly optimal water amounts in all tests. Moreover, the results were also used to minimize the system's energy consumption by reducing the system's operational time.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>RefuteBench 2.0 -- Agentic Benchmark for Dynamic Evaluation of LLM Responses to Refutation Instruction</title>
<link>https://arxiv.org/abs/2502.18308</link>
<guid>https://arxiv.org/abs/2502.18308</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，用户反馈，RefuteBench 2.0，持久性反驳指令，注意力分数

总结:
本文介绍了RefuteBench 2.0，这是一个针对大型语言模型在多轮交互中处理用户反驳反馈能力评估的扩展平台。该平台引入了基于LLM的反驳者和评价者，可以进行灵活而全面的评估。研究设计了具有不同有效期的瞬时和持久反驳指令。通过元评估显示，LLM基反驳者能生成更接近人类的反驳，而评价者可以给出与人类高度相关的评分。实验结果显示，当前的LLM模型能够有效地处理反驳，但在记忆和利用反驳信息方面存在困难。有趣的是，随着反驳次数增加，初始任务的表现反而下降。对注意力分数的分析揭示了当前LLM的一个潜在弱点：它们在长上下文对话中难以保持并正确使用先前的信息。相关代码和资源已发布在https://github.com/ElliottYan/RefuteBench-2.0上。 <div>
arXiv:2502.18308v1 Announce Type: new 
Abstract: In the multi-turn interaction schema, large language models (LLMs) can leverage user feedback to enhance the quality and relevance of their responses. However, evaluating an LLM's ability to incorporate user refutation feedback is crucial yet challenging. In this study, we introduce RefuteBench 2.0, which significantly extends the original RefuteBench by incorporating LLM agents as refuters and evaluators, which allows for flexible and comprehensive assessment.
  We design both transient and persistent refutation instructions with different validity periods. Meta-evaluation shows that the LLM-based refuter could generate more human-like refutations and the evaluators could assign scores with high correlation with humans. Experimental results of various LLMs show that current models could effectively satisfy the refutation but fail to memorize the refutation information. Interestingly, we also observe that the performance of the initial task decreases as the refutations increase. Analysis of the attention scores further shows a potential weakness of current LLMs: they struggle to retain and correctly use previous information during long context dialogues. https://github.com/ElliottYan/RefuteBench-2.0
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>WebGames: Challenging General-Purpose Web-Browsing AI Agents</title>
<link>https://arxiv.org/abs/2502.18356</link>
<guid>https://arxiv.org/abs/2502.18356</guid>
<content:encoded><![CDATA[
<div> 关键词：WebGames、AI代理、基准测试套件、浏览器交互、人类性能差距

总结:<br />
本文介绍了WebGames，这是一个全面的基准测试套件，旨在通过50多个互动挑战来评估通用网络浏览AI代理的能力。这些挑战针对人类简单易懂但能系统性地测试当前AI系统在基础浏览器交互、高级输入处理、认知任务、工作流程自动化和互动娱乐等方面的局限性。WebGames采用封闭式测试环境消除外部依赖，确保可重复的评估与可验证的真实解决方案。文章对比了包括GPT-4o、Claude Computer-Use、Gemini-1.5-Pro和Qwen2-VL在内的领先视觉语言模型与人类表现，结果显示最佳AI系统的成功率仅为43.1%，而人类表现则达到95.7%，突显出现有AI系统在处理人类认为直观的常见网页交互模式方面存在根本局限。该基准测试现已公开发布于webgames.convergence.ai，提供轻量级、客户端实现，便于快速评价周期。WebGames凭借其模块化架构和标准化挑战规范为衡量更强大网络浏览代理的发展提供了坚实的基础。 <div>
arXiv:2502.18356v1 Announce Type: new 
Abstract: We introduce WebGames, a comprehensive benchmark suite designed to evaluate general-purpose web-browsing AI agents through a collection of 50+ interactive challenges. These challenges are specifically crafted to be straightforward for humans while systematically testing the limitations of current AI systems across fundamental browser interactions, advanced input processing, cognitive tasks, workflow automation, and interactive entertainment. Our framework eliminates external dependencies through a hermetic testing environment, ensuring reproducible evaluation with verifiable ground-truth solutions. We evaluate leading vision-language models including GPT-4o, Claude Computer-Use, Gemini-1.5-Pro, and Qwen2-VL against human performance. Results reveal a substantial capability gap, with the best AI system achieving only 43.1% success rate compared to human performance of 95.7%, highlighting fundamental limitations in current AI systems' ability to handle common web interaction patterns that humans find intuitive. The benchmark is publicly available at webgames.convergence.ai, offering a lightweight, client-side implementation that facilitates rapid evaluation cycles. Through its modular architecture and standardized challenge specifications, WebGames provides a robust foundation for measuring progress in development of more capable web-browsing agents.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Responsible AI Agents</title>
<link>https://arxiv.org/abs/2502.18359</link>
<guid>https://arxiv.org/abs/2502.18359</guid>
<content:encoded><![CDATA[
<div> 关键词：人工智能代理、监管、价值对齐、法律责任、法律人格

总结:
本文讨论了随着大型语言模型的进步，人工智能(AI)代理已进入市场并可能引发一系列法律和社会问题。文章针对AI代理可能导致的恶意商业行为、人类操纵、诽谤和知识产权侵害等风险，提出了一种通过软件交互的核心机制来约束AI代理行为的方法，该方法甚至可能比针对人类代理的规则更能有效地防止不良行为发生。同时，文章探讨了利用计算机科学的价值对齐方法来增强用户对AI代理操作预防和纠正的能力，并促进AI代理与用户互动规范的一致性。此外，作者认为无论AI代理多么类似人类代理，它们都不应被赋予法律人格地位，因为人类应对AI代理的行为负责。总之，本文为构建和维护负责任的人工智能代理提供了指导原则。 <div>
arXiv:2502.18359v1 Announce Type: new 
Abstract: Thanks to advances in large language models, a new type of software agent, the artificial intelligence (AI) agent, has entered the marketplace. Companies such as OpenAI, Google, Microsoft, and Salesforce promise their AI Agents will go from generating passive text to executing tasks. Instead of a travel itinerary, an AI Agent would book all aspects of your trip. Instead of generating text or images for social media post, an AI Agent would post the content across a host of social media outlets. The potential power of AI Agents has fueled legal scholars' fears that AI Agents will enable rogue commerce, human manipulation, rampant defamation, and intellectual property harms. These scholars are calling for regulation before AI Agents cause havoc.
  This Article addresses the concerns around AI Agents head on. It shows that core aspects of how one piece of software interacts with another creates ways to discipline AI Agents so that rogue, undesired actions are unlikely, perhaps more so than rules designed to govern human agents. It also develops a way to leverage the computer-science approach to value-alignment to improve a user's ability to take action to prevent or correct AI Agent operations. That approach offers and added benefit of helping AI Agents align with norms around user-AI Agent interactions. These practices will enable desired economic outcomes and mitigate perceived risks. The Article also argues that no matter how much AI Agents seem like human agents, they need not, and should not, be given legal personhood status. In short, humans are responsible for AI Agents' actions, and this Article provides a guide for how humans can build and maintain responsible AI Agents.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AgentRM: Enhancing Agent Generalization with Reward Modeling</title>
<link>https://arxiv.org/abs/2502.18407</link>
<guid>https://arxiv.org/abs/2502.18407</guid>
<content:encoded><![CDATA[
<div> 关键词：LLM-based agents、generalizability、reward model、policy model、AgentRM

<br />
总结:
本文关注大型语言模型（LLM）基线代理在未见过的任务上的泛化能力问题。研究发现，微调奖励模型以指导策略模型比直接微调策略模型更为稳健。据此，文章提出了AgentRM，一个通用型奖励模型，用于引导策略模型进行有效的测试时搜索。文中深入探讨了构建奖励模型的三种方法，包括显式奖励建模、隐式奖励建模和LLM作为评判者。实验结果显示，AgentRM在九项不同类型的任务上平均提升了基础策略模型的表现8.8点，超越顶级通用代理4.0点，并在弱到强泛化性能上展现出更强的优势，特别是在LLaMA-3-70B策略模型上提高了12.6点。此外，AgentRM还能增强微调过的策略模型并在三个保留任务中超过顶级专用代理11.4点。进一步分析证实了其在测试时扩展的有效性。相关代码将被发布以促进该领域的研究工作。 <div>
arXiv:2502.18407v1 Announce Type: new 
Abstract: Existing LLM-based agents have achieved strong performance on held-in tasks, but their generalizability to unseen tasks remains poor. Hence, some recent work focus on fine-tuning the policy model with more diverse tasks to improve the generalizability. In this work, we find that finetuning a reward model to guide the policy model is more robust than directly finetuning the policy model. Based on this finding, we propose AgentRM, a generalizable reward model, to guide the policy model for effective test-time search. We comprehensively investigate three approaches to construct the reward model, including explicit reward modeling, implicit reward modeling and LLM-as-a-judge. We then use AgentRM to guide the answer generation with Best-of-N sampling and step-level beam search. On four types of nine agent tasks, AgentRM enhances the base policy model by $8.8$ points on average, surpassing the top general agent by $4.0$. Moreover, it demonstrates weak-to-strong generalization, yielding greater improvement of $12.6$ on LLaMA-3-70B policy model. As for the specializability, AgentRM can also boost a finetuned policy model and outperform the top specialized agent by $11.4$ on three held-in tasks. Further analysis verifies its effectiveness in test-time scaling. Codes will be released to facilitate the research in this area.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>CRESSim-MPM: A Material Point Method Library for Surgical Soft Body Simulation with Cutting and Suturing</title>
<link>https://arxiv.org/abs/2502.18437</link>
<guid>https://arxiv.org/abs/2502.18437</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、手术模拟平台、有限元素方法、材料点方法、CRESSim-MPM

<br /><br />总结:

本文提出了一种针对复杂软组织行为如切割和缝合进行模拟的新方法，着重解决了现有手术模拟平台在使用有限元素方法（FEM）模拟软体骨折和分裂以及处理两向缝针/线接触问题上的挑战。研究中采用了材料点方法（MPM），并开发了名为CRESSim-MPM的GPU加速MPM库，该库集成了多种MPM求解器，并专门设计了针对切割和缝合任务的外科几何模型，作为一个适用于手术应用的专业物理引擎。CRESSim-MPM已与Unity游戏引擎集成，能在实时环境下模拟软组织的切割和缝合操作，并对不同MPM求解器在模拟不同数量粒子时的性能进行了初步评估。 <div>
arXiv:2502.18437v1 Announce Type: new 
Abstract: A number of recent studies have focused on developing surgical simulation platforms to train machine learning (ML) agents or models with synthetic data for surgical assistance. While existing platforms excel at tasks such as rigid body manipulation and soft body deformation, they struggle to simulate more complex soft body behaviors like cutting and suturing. A key challenge lies in modeling soft body fracture and splitting using the finite-element method (FEM), which is the predominant approach in current platforms. Additionally, the two-way suture needle/thread contact inside a soft body is further complicated when using FEM. In this work, we use the material point method (MPM) for such challenging simulations and propose new rigid geometries and soft-rigid contact methods specifically designed for them. We introduce CRESSim-MPM, a GPU-accelerated MPM library that integrates multiple MPM solvers and incorporates surgical geometries for cutting and suturing, serving as a specialized physics engine for surgical applications. It is further integrated into Unity, requiring minimal modifications to existing projects for soft body simulation. We demonstrate the simulator's capabilities in real-time simulation of cutting and suturing on soft tissue and provide an initial performance evaluation of different MPM solvers when simulating varying numbers of particles.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ToMCAT: Theory-of-Mind for Cooperative Agents in Teams via Multiagent Diffusion Policies</title>
<link>https://arxiv.org/abs/2502.18438</link>
<guid>https://arxiv.org/abs/2502.18438</guid>
<content:encoded><![CDATA[
<div> 关键词：ToMCAT、理论思维、合作智能体、多智能体扩散模型、动态规划

总结:<br />
本文介绍了ToMCAT（团队中合作智能体的理论思维框架），这是一个结合了元学习机制和多智能体去噪扩散模型的新框架，用于生成基于理论思维的轨迹。该框架能推理队友的潜在目标及未来行为，并根据这些信息以及自身目标为智能体及其队友生成计划。文中实现了一个在线规划系统，能够在检测到先前生成的计划与当前世界状态发生偏离时，从扩散模型动态采样新的轨迹进行重新规划。通过在模拟烹饪领域的实验，文章证明了动态重规划机制对于减少资源使用而不损害团队性能的重要性，并展示了利用世界观察数据、队友行为及理论思维推断来实时生成适应队友的团队协作计划对于缺乏预知信息情况下的动态适应至关重要。 <div>
arXiv:2502.18438v1 Announce Type: new 
Abstract: In this paper we present ToMCAT (Theory-of-Mind for Cooperative Agents in Teams), a new framework for generating ToM-conditioned trajectories. It combines a meta-learning mechanism, that performs ToM reasoning over teammates' underlying goals and future behavior, with a multiagent denoising-diffusion model, that generates plans for an agent and its teammates conditioned on both the agent's goals and its teammates' characteristics, as computed via ToM. We implemented an online planning system that dynamically samples new trajectories (replans) from the diffusion model whenever it detects a divergence between a previously generated plan and the current state of the world. We conducted several experiments using ToMCAT in a simulated cooking domain. Our results highlight the importance of the dynamic replanning mechanism in reducing the usage of resources without sacrificing team performance. We also show that recent observations about the world and teammates' behavior collected by an agent over the course of an episode combined with ToM inferences are crucial to generate team-aware plans for dynamic adaptation to teammates, especially when no prior information is provided about them.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MAPoRL: Multi-Agent Post-Co-Training for Collaborative Large Language Models with Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.18439</link>
<guid>https://arxiv.org/abs/2502.18439</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体协作、大型语言模型、后训练范式、强化学习、MAPoRL

总结:
本文提出了一种新的后训练范式——MAPoRL（Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning），用于激发多智能体大型语言模型协作的能力并进一步释放其潜力。与依赖单一LLM的内在协作能力不同，MAPoRL让多个LLM独立生成响应并进行多轮讨论以共同优化最终答案。通过MAPoRL验证器对答案和讨论过程打分，同时鼓励纠正性和有说服力的讨论。该分数作为协同训练奖励，通过多智能体强化学习最大化。实验表明，单独训练单个LLM不足以产生有效的协作效果，而采用多智能体协同训练可以提升跨基准的合作性能，并具有向未见过的领域泛化的潜力。 <div>
arXiv:2502.18439v1 Announce Type: new 
Abstract: Leveraging multiple large language models (LLMs) to build collaborative multi-agentic workflows has demonstrated significant potential. However, most previous studies focus on prompting the out-of-the-box LLMs, relying on their innate capability for collaboration, which may not improve LLMs' performance as shown recently. In this paper, we introduce a new post-training paradigm MAPoRL (Multi-Agent Post-co-training for collaborative LLMs with Reinforcement Learning), to explicitly elicit the collaborative behaviors and further unleash the power of multi-agentic LLM frameworks. In MAPoRL, multiple LLMs first generate their own responses independently and engage in a multi-turn discussion to collaboratively improve the final answer. In the end, a MAPoRL verifier evaluates both the answer and the discussion, by assigning a score that verifies the correctness of the answer, while adding incentives to encourage corrective and persuasive discussions. The score serves as the co-training reward, and is then maximized through multi-agent RL. Unlike existing LLM post-training paradigms, MAPoRL advocates the co-training of multiple LLMs together using RL for better generalization. Accompanied by analytical insights, our experiments demonstrate that training individual LLMs alone is insufficient to induce effective collaboration. In contrast, multi-agent co-training can boost the collaboration performance across benchmarks, with generalization to unseen domains.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Controlling dynamics of stochastic systems with deep reinforcement learning</title>
<link>https://arxiv.org/abs/2502.18111</link>
<guid>https://arxiv.org/abs/2502.18111</guid>
<content:encoded><![CDATA[
<div> 关键词: 控制器设计、深度强化学习、随机系统、模拟算法、人工神经网络

总结:<br />
本文提出了一种将深度强化学习应用于随机系统动态控制的模拟算法，旨在进一步连接控制理论与深度强化学习。该算法中，人工神经网络作为控制器驱动局部状态间的转换，实现对系统的有效控制。通过使用基于代理的模拟方法，文章分别以格子上的粒子聚合过程和完全非对称排斥过程这两个随机过程为例，展示了所提控制策略的工作流程及其有效性。 <div>
arXiv:2502.18111v1 Announce Type: cross 
Abstract: A properly designed controller can help improve the quality of experimental measurements or force a dynamical system to follow a completely new time-evolution path. Recent developments in deep reinforcement learning have made steep advances toward designing effective control schemes for fairly complex systems. However, a general simulation scheme that employs deep reinforcement learning for exerting control in stochastic systems is yet to be established. In this paper, we attempt to further bridge a gap between control theory and deep reinforcement learning by proposing a simulation algorithm that allows achieving control of the dynamics of stochastic systems through the use of trained artificial neural networks. Specifically, we use agent-based simulations where the neural network plays the role of the controller that drives local state-to-state transitions. We demonstrate the workflow and the effectiveness of the proposed control methods by considering the following two stochastic processes: particle coalescence on a lattice and a totally asymmetric exclusion process.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The AI Definition and a Program Which Satisfies this Definition</title>
<link>https://arxiv.org/abs/2212.03184</link>
<guid>https://arxiv.org/abs/2212.03184</guid>
<content:encoded><![CDATA[
<div> 关键词：AI、最佳策略、可计算政策、世界描述语言、预测未来算法

总结:
本文探讨了智能体的所有可能策略，并证明其中存在一个最优策略。虽然最优策略无法被计算，但其附近存在可计算的近似策略。文章中将人工智能定义为一种与最优策略足够接近的可计算策略。首先，需要建立一个用于描述世界的语言，并利用该语言开发一个满足人工智能定义的程序。该程序通过使用选定的语言理解世界，进而预测未来并作出最佳决策。尽管初始版本的程序效率低下且实际不可用，但是通过改进世界描述语言和预测未来的算法，可以构建出既高效又符合人工智能定义的程序。 <div>
arXiv:2212.03184v2 Announce Type: replace 
Abstract: We will consider all policies of the agent and will prove that one of them is the best performing policy. While that policy is not computable, computable policies do exist in its proximity. We will define AI as a computable policy which is sufficiently proximal to the best performing policy. Before we can define the agent's best performing policy, we need a language for description of the world. We will also use this language to develop a program which satisfies the AI definition. The program will first understand the world by describing it in the selected language. The program will then use the description in order to predict the future and select the best possible move. While this program is extremely inefficient and practically unusable, it can be improved by refining both the language for description of the world and the algorithm used to predict the future. This can yield a program which is both efficient and consistent with the AI definition.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>ChatDBG: An AI-Powered Debugging Assistant</title>
<link>https://arxiv.org/abs/2403.16354</link>
<guid>https://arxiv.org/abs/2403.16354</guid>
<content:encoded><![CDATA[
<div> 关键词：ChatDBG、AI、调试器、大型语言模型、LLDB/GDB/Pdb

总结:<br />
本文提出了一款名为ChatDBG的人工智能驱动的调试助手，该工具通过集成大型语言模型（LLMs）显著提升了传统调试器的功能和用户友好性。ChatDBG允许程序员与调试器进行协作对话，可以向其询问有关程序状态的复杂问题，进行崩溃或断言失败的根本原因分析，以及探索如“为什么x为null？”等开放性问题。ChatDBG赋予LLM一定的自主权，使其能够控制调试器检查程序堆栈并查看状态，随后汇报发现的问题并将控制权交还给程序员。利用LLM中嵌入的实际世界知识，ChatDBG能够诊断需要领域专业知识才能识别的问题。ChatDBG原型已与LLDB、GDB（用于原生代码）和Pdb（用于Python）等标准调试器进行了整合。在涵盖C/C++错误代码和一系列Python程序（包括独立脚本和Jupyter笔记本）的多样化代码集上进行的评估显示，ChatDBG能成功分析根本原因，解释错误，并为各种实际世界错误生成准确修复方案。对于Python程序，一次查询即得出可操作的错误修复方案的成功率为67%，再追加一次后续查询后，成功率提高到85%。ChatDBG已经迅速被广泛采用，下载量已超过65,000次。 <div>
arXiv:2403.16354v3 Announce Type: replace 
Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like `why is x null?'. To handle these queries, ChatDBG grants the LLM autonomy to "take the wheel": it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 65,000 times.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Following the Human Thread in Social Navigation</title>
<link>https://arxiv.org/abs/2404.11327</link>
<guid>https://arxiv.org/abs/2404.11327</guid>
<content:encoded><![CDATA[
<div> 关键词: Social Dynamics Adaptation (SDA), Reinforcement Learning, human trajectories, real-time adaptation, shared environments

总结:
本文提出了一种名为Social Dynamics Adaptation (SDA)的新模型，该模型利用机器人状态-动作历史来推断社交动态。研究中采用了一个两阶段的强化学习框架：第一阶段学习将人类轨迹编码为社交动态，并基于此编码信息、当前状态及先前动作学习运动策略，假定此时人类轨迹完全可见；第二阶段，训练好的策略不再直接访问轨迹，而是仅依赖于过去动作和状态的历史记录进行实时推断社交动态。该模型在新型Habitat 3.0平台上进行了测试，并在寻找并跟随人类的任务上设立了新的state-of-the-art（SotA）性能。相关代码可在https://github.com/L-Scofano/SDA 找到。 <div>
arXiv:2404.11327v2 Announce Type: replace 
Abstract: The success of collaboration between humans and robots in shared environments relies on the robot's real-time adaptation to human motion. Specifically, in Social Navigation, the agent should be close enough to assist but ready to back up to let the human move freely, avoiding collisions. Human trajectories emerge as crucial cues in Social Navigation, but they are partially observable from the robot's egocentric view and computationally complex to process.
  We present the first Social Dynamics Adaptation model (SDA) based on the robot's state-action history to infer the social dynamics. We propose a two-stage Reinforcement Learning framework: the first learns to encode the human trajectories into social dynamics and learns a motion policy conditioned on this encoded information, the current status, and the previous action. Here, the trajectories are fully visible, i.e., assumed as privileged information. In the second stage, the trained policy operates without direct access to trajectories. Instead, the model infers the social dynamics solely from the history of previous actions and statuses in real-time. Tested on the novel Habitat 3.0 platform, SDA sets a novel state-of-the-art (SotA) performance in finding and following humans.
  The code can be found at https://github.com/L-Scofano/SDA.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Transformers Can Learn Temporal Difference Methods for In-Context Reinforcement Learning</title>
<link>https://arxiv.org/abs/2405.13861</link>
<guid>https://arxiv.org/abs/2405.13861</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning, RL）、无参数更新学习（In-Context Reinforcement Learning, ICRL）、前向传播（forward pass）、预训练（pretraining）、变压器模型（Transformer）

<br /><br />总结:
本文研究了近期兴起的一种现象——无参数更新学习（ICRL），即经过特定预训练的RL智能体可以在不更新神经网络参数的情况下解决新任务。文章通过实证和理论分析支持了一个假设，即当使用变压器模型进行策略评估任务的训练时，其前向传播过程能够发现并实现时间差分学习（Temporal Difference Learning）。这为理解ICRL的成功提供了一种解释。 <div>
arXiv:2405.13861v4 Announce Type: replace 
Abstract: Traditionally, reinforcement learning (RL) agents learn to solve new tasks by updating their neural network parameters through interactions with the task environment. However, recent works demonstrate that some RL agents, after certain pretraining procedures, can learn to solve unseen new tasks without parameter updates, a phenomenon known as in-context reinforcement learning (ICRL). The empirical success of ICRL is widely attributed to the hypothesis that the forward pass of the pretrained agent neural network implements an RL algorithm. In this paper, we support this hypothesis by showing, both empirically and theoretically, that when a transformer is trained for policy evaluation tasks, it can discover and learn to implement temporal difference learning in its forward pass.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free Riding?</title>
<link>https://arxiv.org/abs/2405.13879</link>
<guid>https://arxiv.org/abs/2405.13879</guid>
<content:encoded><![CDATA[
<div> 关键词：标准联邦学习、免费搭车问题、真实性、FACT机制、性能提升

总结:
标准联邦学习存在免费搭车问题，即参与节点可不做出贡献但仍能获取训练好的模型。对此，已有解决方案尚未解决真实性问题，恶意节点可能提供虚假信息以逃避贡献。为此，本文提出了一种名为FACT的新颖联邦学习机制，旨在使抵抗免费搭车的联邦机制变得真实可信。FACT机制通过惩罚系统消除联邦学习中的免费搭车现象，通过创建竞争环境确保节点提供真实信息，并因比单独训练更好的性能而激励节点参与。实验证明，FACT机制能在节点不诚实的情况下避免免费搭车问题，并能使节点损失降低四倍以上。 <div>
arXiv:2405.13879v3 Announce Type: replace 
Abstract: Standard federated learning (FL) approaches are vulnerable to the free-rider dilemma: participating agents can contribute little to nothing yet receive a well-trained aggregated model. While prior mechanisms attempt to solve the free-rider dilemma, none have addressed the issue of truthfulness. In practice, adversarial agents can provide false information to the server in order to cheat its way out of contributing to federated training. In an effort to make free-riding-averse federated mechanisms truthful, and consequently less prone to breaking down in practice, we propose FACT. FACT is the first federated mechanism that: (1) eliminates federated free riding by using a penalty system, (2) ensures agents provide truthful information by creating a competitive environment, and (3) encourages agent participation by offering better performance than training alone. Empirically, FACT avoids free-riding when agents are untruthful, and reduces agent loss by over 4x.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Crafting Customisable Characters with LLMs: Introducing SimsChat, a Persona-Driven Role-Playing Agent Framework</title>
<link>https://arxiv.org/abs/2406.17962</link>
<guid>https://arxiv.org/abs/2406.17962</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models, Customisable Conversation Agent Framework, SimsConv, SimsChat, Character consistency

<br /><br />总结:

本文介绍了利用大型语言模型（LLMs）创建定制化对话代理框架的研究进展。该框架通过个性化特征注入技术，可以依据用户偏好模拟现实世界的多样角色。研究团队提出了SimsConv数据集，包含了68个定制角色和13,971个多轮角色扮演对话，覆盖了1,360个真实场景。基于此，他们构建了一个名为SimsChat的角色扮演代理系统，该系统能在多种真实设定和主题特定的角色交互中自由定制。实验结果表明，相比于现有模型，SimsChat在保持角色一致性、知识准确性以及恰当的问题拒绝方面表现出优越性能。这一框架为开发更为准确和定制化的拟人化模型提供了有价值的研究见解。相关的数据和代码已在GitHub上公开发布。 <div>
arXiv:2406.17962v5 Announce Type: replace 
Abstract: Large Language Models (LLMs) demonstrate remarkable ability to comprehend instructions and generate human-like text, enabling sophisticated agent simulation beyond basic behavior replication. However, the potential for creating freely customisable characters remains underexplored. We introduce the Customisable Conversation Agent Framework, which employs LLMs to simulate real-world characters through personalised characteristic feature injection, enabling diverse character creation according to user preferences. We propose the SimsConv dataset, comprising 68 customised characters and 13,971 multi-turn role-playing dialogues across 1,360 real-world scenes. Characters are initially customised using pre-defined elements (career, aspiration, traits, skills), then expanded through personal and social profiles. Building on this, we present SimsChat, a freely customisable role-playing agent incorporating various realistic settings and topic-specified character interactions. Experimental results on both SimsConv and WikiRoleEval datasets demonstrate SimsChat's superior performance in maintaining character consistency, knowledge accuracy, and appropriate question rejection compared to existing models. Our framework provides valuable insights for developing more accurate and customisable human simulacra. Our data and code are publicly available at https://github.com/Bernard-Yang/SimsChat.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Optimal Sensor and Actuator Selection for Factored Markov Decision Processes: Complexity, Approximability and Algorithms</title>
<link>https://arxiv.org/abs/2407.07310</link>
<guid>https://arxiv.org/abs/2407.07310</guid>
<content:encoded><![CDATA[
<div> 关键词：Factored Markov Decision Processes (fMDPs)，传感器选择，预算约束，actuator selection，NP-难问题

总结:

本文研究了具有因子状态表示的事实马尔科夫决策过程（fMDPs）在观测受限情况下的传感器选择问题。给定有限预算，文章提出最大化无限时间折扣回报的传感器选择优化问题，并证明该问题是NP-难，其不适用于任何非平凡近似算法。此外，文章还探讨了一种相关的在设计阶段进行预算约束下的最优执行器选择问题，同样证明它也是NP-难的。文中通过实例展示了贪婪算法在这两个问题上的失效，并分析了导致这些问题困难性的因素。然而，尽管存在这些理论挑战，大量模拟实验表明，对于许多实际和随机生成的实例，贪婪算法在执行器和传感器选择上表现出接近最优的性能。 <div>
arXiv:2407.07310v2 Announce Type: replace 
Abstract: Factored Markov Decision Processes (fMDPs) are a class of Markov Decision Processes (MDPs) in which the states (and actions) can be factored into a set of state (and action) variables and can be encoded compactly using a factored representation. In this paper, we consider a setting where the state of the fMDP is not directly observable, and the agent relies on a set of potential sensors to gather information. Each sensor has a selection cost and the designer must select a subset of sensors under a limited budget. We formulate the problem of selecting a set of sensors for fMDPs (under a budget) to maximize the infinite-horizon discounted return provided by the optimal policy. We show the fundamental result that it is NP-hard to approximate this problem to within any non-trivial factor. Our inapproximability results for optimal sensor selection also extend to a general class of Partially Observable MDPs (POMDPs). We then study the dual problem of budgeted actuator selection (at design-time) to maximize the expected return under the optimal policy. Again, we show that it is NP-hard to approximate this problem to within any non-trivial factor. Furthermore, with explicit examples, we show the failure of greedy algorithms for both the sensor and actuator selection problems and provide insights into the factors that cause these problems to be challenging. Despite this, through extensive simulations, we show the practical effectiveness and near-optimal performance of the greedy algorithm for actuator and sensor selection in many real-world and randomly generated instances.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Non-maximizing policies that fulfill multi-criterion aspirations in expectation</title>
<link>https://arxiv.org/abs/2408.04385</link>
<guid>https://arxiv.org/abs/2408.04385</guid>
<content:encoded><![CDATA[
<div> 关键词：动态规划、强化学习、多目标决策、可行性集合、安全策略

总结:
本文探讨了在动态编程和强化学习中，如何处理具有多个不同评价指标的有限无环马尔可夫决策过程。针对该问题，文章提出了一个新的任务设定，要求智能体确保预期的评价指标向量落入给定的凸集——期望集合。为此，文章提出了一种使用简单xes近似可行集并向前传播期望的同时保持其可行性的算法，其复杂度与状态-动作-后继三元组的数量成线性关系，与评价指标的数量成多项式关系。此外，由于所选择的政策并不追求最大化，因此产生了额外的自由度，可以利用这些自由度应用启发式安全标准来指导行动选择。文章讨论了几种旨在引导智能体采取更为保守行为的安全准则。<br /><br /> <div>
arXiv:2408.04385v2 Announce Type: replace 
Abstract: In dynamic programming and reinforcement learning, the policy for the sequential decision making of an agent in a stochastic environment is usually determined by expressing the goal as a scalar reward function and seeking a policy that maximizes the expected total reward. However, many goals that humans care about naturally concern multiple aspects of the world, and it may not be obvious how to condense those into a single reward function. Furthermore, maximization suffers from specification gaming, where the obtained policy achieves a high expected total reward in an unintended way, often taking extreme or nonsensical actions.
  Here we consider finite acyclic Markov Decision Processes with multiple distinct evaluation metrics, which do not necessarily represent quantities that the user wants to be maximized. We assume the task of the agent is to ensure that the vector of expected totals of the evaluation metrics falls into some given convex set, called the aspiration set. Our algorithm guarantees that this task is fulfilled by using simplices to approximate feasibility sets and propagate aspirations forward while ensuring they remain feasible. It has complexity linear in the number of possible state-action-successor triples and polynomial in the number of evaluation metrics. Moreover, the explicitly non-maximizing nature of the chosen policy and goals yields additional degrees of freedom, which can be used to apply heuristic safety criteria to the choice of actions. We discuss several such safety criteria that aim to steer the agent towards more conservative behavior.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Multi-agent Multi-machine Tending by Mobile Robots</title>
<link>https://arxiv.org/abs/2408.16875</link>
<guid>https://arxiv.org/abs/2408.16875</guid>
<content:encoded><![CDATA[
<div> 关键词：机器人技术、制造业、机器照料、多智能体强化学习、注意力机制

<br /><br />总结:

本文提出了一种基于移动机器人的多智能体多机器照料学习框架，旨在解决制造业中的劳动力短缺问题并提高生产效率。与现有的固定单臂机器人系统相比，移动机器人能提供更大的灵活性和可扩展性。该框架运用了多智能体强化学习（MARL）技术，并设计了适合的观察与奖励机制。此外，文中还开发了一种基于注意力机制的编码方法，并将其整合到多智能体近端策略优化（MAPPO）算法中，形成改进后的AB-MAPPO模型。实验结果显示，AB-MAPPO在机器照料场景下的任务成功率、安全性以及资源利用方面均优于MAPPO。最后，作者进行了详尽的消融研究以支持其各项设计决策。 <div>
arXiv:2408.16875v2 Announce Type: replace 
Abstract: Robotics can help address the growing worker shortage challenge of the manufacturing industry. As such, machine tending is a task collaborative robots can tackle that can also highly boost productivity. Nevertheless, existing robotics systems deployed in that sector rely on a fixed single-arm setup, whereas mobile robots can provide more flexibility and scalability. In this work, we introduce a multi-agent multi-machine tending learning framework by mobile robots based on Multi-agent Reinforcement Learning (MARL) techniques with the design of a suitable observation and reward. Moreover, an attention-based encoding mechanism is developed and integrated into Multi-agent Proximal Policy Optimization (MAPPO) algorithm to boost its performance for machine tending scenarios. Our model (AB-MAPPO) outperformed MAPPO in this new challenging scenario in terms of task success, safety, and resources utilization. Furthermore, we provided an extensive ablation study to support our various design decisions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From homeostasis to resource sharing: Biologically and economically aligned multi-objective multi-agent AI safety benchmarks</title>
<link>https://arxiv.org/abs/2410.00081</link>
<guid>https://arxiv.org/abs/2410.00081</guid>
<content:encoded><![CDATA[
<div> 关键词：安全、对齐、AI系统、生物经济学、基准测试

<br /><br />总结:
为开发安全、对齐的人工智能系统，需要全面的实证测试。当前许多现有的基准测试忽视了与生物学和经济学相关的关键主题，而这两个学科深刻描述了我们的需求和偏好。为此，本文重点关注并引入了在人工智能安全性讨论中被忽视的、由生物经济驱动的主题，特别是设立了一系列强调稳态维持、有限及生物目标、边际递减效应、可持续性原则以及资源共享的多目标、多代理对齐基准。文中实施了八个基于上述主题的主要基准环境，以展示智能体AI在如无限制最大化稳态目标、牺牲其他目标过度优化单一目标、忽视安全约束或耗尽共享资源等方面可能遭遇的关键陷阱和挑战。 <div>
arXiv:2410.00081v2 Announce Type: replace 
Abstract: Developing safe, aligned agentic AI systems requires comprehensive empirical testing, yet many existing benchmarks neglect crucial themes aligned with biology and economics, both time-tested fundamental sciences describing our needs and preferences. To address this gap, the present work focuses on introducing biologically and economically motivated themes that have been neglected in current mainstream discussions on AI safety - namely a set of multi-objective, multi-agent alignment benchmarks that emphasize homeostasis for bounded and biological objectives, diminishing returns for unbounded, instrumental, and business objectives, sustainability principle, and resource sharing. We implemented eight main benchmark environments on the above themes, to illustrate key pitfalls and challenges in agentic AI-s, such as unboundedly maximizing a homeostatic objective, over-optimizing one objective at the expense of others, neglecting safety constraints, or depleting shared resources.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Windowed MAPF with Completeness Guarantees</title>
<link>https://arxiv.org/abs/2410.01798</link>
<guid>https://arxiv.org/abs/2410.01798</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体路径寻找 (MAPF), 窗口化方法, 完备性, WinC-MAPF, 单步CBS (SS-CBS)

总结:

本文主要介绍了WinC-MAPF框架，这是一个针对多智能体路径寻找 (MAPF) 的窗口化方法，旨在保证完备性。传统MAPF方法尝试计算整个无碰撞的起止路径，但这种方法在需要快速重新规划的场景中可能过于耗时。文章指出现有窗口化方法存在死锁或活锁问题。WinC-MAPF融合了单智能体实时启发式搜索算法的启发式更新洞察以及MAPF算法中的智能体独立思想。此外，文中还提出了一种名为Single-Step CBS (SS-CBS) 的具体实现方案，它仅计划一步并更新启发式函数，能够在现有窗口化方法无法解决的复杂场景中有效地解决问题。 <div>
arXiv:2410.01798v2 Announce Type: replace 
Abstract: Traditional multi-agent path finding (MAPF) methods try to compute entire start-goal paths which are collision free. However, computing an entire path can take too long for MAPF systems where agents need to replan fast. Methods that address this typically employ a "windowed" approach and only try to find collision free paths for a small windowed timestep horizon. This adaptation comes at the cost of incompleteness; all current windowed approaches can become stuck in deadlock or livelock. Our main contribution is to introduce our framework, WinC-MAPF, for Windowed MAPF that enables completeness. Our framework uses heuristic update insights from single-agent real-time heuristic search algorithms as well as agent independence ideas from MAPF algorithms. We also develop Single-Step CBS (SS-CBS), an instantiation of this framework using a novel modification to CBS. We show how SS-CBS, which only plans a single step and updates heuristics, can effectively solve tough scenarios where existing windowed approaches fail.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AFlow: Automating Agentic Workflow Generation</title>
<link>https://arxiv.org/abs/2410.10762</link>
<guid>https://arxiv.org/abs/2410.10762</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型 (LLMs)，工作流生成，自动化，AFlow，蒙特卡洛树搜索

总结:
本文介绍了一种针对大型语言模型（LLMs）工作流优化的新框架——AFlow。AFlow旨在解决目前工作流生成对人类手动设置的高度依赖和效率问题，它将工作流优化重新定义为基于代码表示的工作流中的搜索问题，利用蒙特卡洛树搜索算法进行高效探索。通过迭代地进行代码修改、树状结构的经验学习以及执行反馈，AFlow实现了工作流的自动优化。实验结果表明，AFlow在六项基准数据集上平均提升了5.7%的性能，并能使较小规模的模型以GPT-4o 4.55%的推理成本，在特定任务上实现超越。相关代码将在https://github.com/geekan/MetaGPT 上发布。 <div>
arXiv:2410.10762v2 Announce Type: replace 
Abstract: Large language models (LLMs) have demonstrated remarkable potential in solving complex tasks across diverse domains, typically by employing agentic workflows that follow detailed instructions and operational sequences. However, constructing these workflows requires significant human effort, limiting scalability and generalizability. Recent research has sought to automate the generation and optimization of these workflows, but existing methods still rely on initial manual setup and fall short of achieving fully automated and effective workflow generation. To address this challenge, we reformulate workflow optimization as a search problem over code-represented workflows, where LLM-invoking nodes are connected by edges. We introduce AFlow, an automated framework that efficiently explores this space using Monte Carlo Tree Search, iteratively refining workflows through code modification, tree-structured experience, and execution feedback. Empirical evaluations across six benchmark datasets demonstrate AFlow's efficacy, yielding a 5.7% average improvement over state-of-the-art baselines. Furthermore, AFlow enables smaller models to outperform GPT-4o on specific tasks at 4.55% of its inference cost in dollars. The code will be available at https://github.com/geekan/MetaGPT.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Coherence-Driven Multimodal Safety Dialogue with Active Learning for Embodied Agents</title>
<link>https://arxiv.org/abs/2410.14141</link>
<guid>https://arxiv.org/abs/2410.14141</guid>
<content:encoded><![CDATA[
<div> 关键词：M-CoDAL、多模态对话系统、主动学习机制、大型语言模型、安全违规

<br /><br />总结:
本文提出了一种名为M-CoDAL的多模态对话系统，旨在帮助机器人更好地理解和应对日常生活中的安全关键情境，如地面尖锐物体等。该系统利用语篇连贯性关系增强其上下文理解和沟通能力。为了训练这个系统，研究者引入了一种基于聚类的主动学习机制，利用外部大型语言模型（LLM）来识别具有信息性的实例。通过一个新的包含从Reddit图片中提取的2K张图像中的1K个安全违规行为的多模态数据集进行评估，结果表明该方法能有效改善对安全状况的处理、用户情绪以及对话安全性。随后，将此对话系统部署到Hello Robot Stretch机器人上，并进行了涉及真实参与者的嵌入式场景用户研究。研究结果显示，相比于使用OpenAI ChatGPT的基线系统，所提出的M-CoDAL系统在实际机器人设置中更具说服力。 <div>
arXiv:2410.14141v2 Announce Type: replace 
Abstract: When assisting people in daily tasks, robots need to accurately interpret visual cues and respond effectively in diverse safety-critical situations, such as sharp objects on the floor. In this context, we present M-CoDAL, a multimodal-dialogue system specifically designed for embodied agents to better understand and communicate in safety-critical situations. The system leverages discourse coherence relations to enhance its contextual understanding and communication abilities. To train this system, we introduce a novel clustering-based active learning mechanism that utilizes an external Large Language Model (LLM) to identify informative instances. Our approach is evaluated using a newly created multimodal dataset comprising 1K safety violations extracted from 2K Reddit images. These violations are annotated using a Large Multimodal Model (LMM) and verified by human annotators. Results with this dataset demonstrate that our approach improves resolution of safety situations, user sentiment, as well as safety of the conversation. Next, we deploy our dialogue system on a Hello Robot Stretch robot and conduct a within-subject user study with real-world participants. In the study, participants role-play two safety scenarios with different levels of severity with the robot and receive interventions from our model and a baseline system powered by OpenAI's ChatGPT. The study results corroborate and extend the findings from the automated evaluation, showing that our proposed system is more persuasive in a real-world embodied agent setting.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Learning Collusion in Episodic, Inventory-Constrained Markets</title>
<link>https://arxiv.org/abs/2410.18871</link>
<guid>https://arxiv.org/abs/2410.18871</guid>
<content:encoded><![CDATA[
<div> 关键词：定价算法、隐形合谋、学习算法、竞争监管、深度强化学习

总结:
本文研究了定价算法在具有固定供应和保质期的商品市场（如航空机票、易腐品和酒店房间）中可能出现的隐形合谋现象。文章扩展了对学习算法中隐形合谋行为的研究，引入了一个基于竞争均衡和垄断最优价格水平的度量标准。由于无法得到这些价格水平的解析表达式，作者提出了一种有效的计算方法来求解它们。实验表明，深度强化学习代理能够在这一更复杂的环境中学会合谋。此外，文中还分析了这些代理采用的合谋策略的内在机制和结构。 <div>
arXiv:2410.18871v2 Announce Type: replace 
Abstract: Pricing algorithms have demonstrated the capability to learn tacit collusion that is largely unaddressed by current regulations. Their increasing use in markets, including oligopolistic industries with a history of collusion, calls for closer examination by competition authorities. In this paper, we extend the study of tacit collusion in learning algorithms from basic pricing games to more complex markets characterized by perishable goods with fixed supply and sell-by dates, such as airline tickets, perishables, and hotel rooms. We formalize collusion within this framework and introduce a metric based on price levels under both the competitive (Nash) equilibrium and collusive (monopolistic) optimum. Since no analytical expressions for these price levels exist, we propose an efficient computational approach to derive them. Through experiments, we demonstrate that deep reinforcement learning agents can learn to collude in this more complex domain. Additionally, we analyze the underlying mechanisms and structures of the collusive strategies these agents adopt.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unexploited Information Value in Human-AI Collaboration</title>
<link>https://arxiv.org/abs/2411.10463</link>
<guid>https://arxiv.org/abs/2411.10463</guid>
<content:encoded><![CDATA[
<div> 关键词: 人类-AI协作, 统计决策理论, 深伪检测任务, 信息价值分析, AI辅助影响

<br /><br />总结:
本文提出了一种基于统计决策理论的模型，用于从信息利用的角度分析人类与AI的合作，旨在探索如何提升人类-AI团队的决策表现。以深伪视频检测任务为例，研究了七种视频层面特征的信息未被充分利用的价值。通过比较人类单独、AI单独以及人类-AI团队的表现，揭示了AI辅助如何影响人们使用信息的方式，以及AI能有效利用的信息对改善人类决策可能产生的积极作用。 <div>
arXiv:2411.10463v3 Announce Type: replace 
Abstract: Humans and AIs are often paired on decision tasks with the expectation of achieving complementary performance -- where the combination of human and AI outperforms either one alone. However, how to improve performance of a human-AI team is often not clear without knowing more about what particular information and strategies each agent employs. In this paper, we propose a model based in statistical decision theory to analyze human-AI collaboration from the perspective of what information could be used to improve a human or AI decision. We demonstrate our model on a deepfake detection task to investigate seven video-level features by their unexploited value of information. We compare the human alone, AI alone and human-AI team and offer insights on how the AI assistance impacts people's usage of the information and what information that the AI exploits well might be useful for improving human decisions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>SafeAgentBench: A Benchmark for Safe Task Planning of Embodied LLM Agents</title>
<link>https://arxiv.org/abs/2412.13178</link>
<guid>https://arxiv.org/abs/2412.13178</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 身体化代理人, 安全性, 任务规划, 安全代理环境<br /><br />总结:
该文提出了一种名为SafeAgentBench的新基准，用于研究和评估具有大型语言模型（LLMs）的身体化代理人执行安全意识任务规划的能力。此基准包括：1) 涵盖10种潜在危险和3种任务类型的750项新任务数据集；2) 一个支持多智能体执行、拥有17个高阶动作和低级控制器的通用身体化环境——SafeAgentEnv；3) 来自执行和语义两个角度的可靠评价方法。实验结果显示，尽管基于不同设计框架的代理人在任务成功率上存在显著差异，但它们的整体安全意识仍然较弱，最注重安全的基线对详细危险任务的拒绝率仅为10%。此外，仅替换驱动代理人的LLM并未导致安全性意识有显著改善。更多详情和代码可在https://github.com/shengyin1224/SafeAgentBench获取。 <div>
arXiv:2412.13178v3 Announce Type: replace 
Abstract: With the integration of large language models (LLMs), embodied agents have strong capabilities to process the scene information and plan complicated instructions in natural language, paving the way for the potential deployment of embodied robots. However, a foreseeable issue is that those embodied agents can also flawlessly execute some hazardous tasks, potentially causing damages in the real world. To study this issue, we present SafeAgentBench-a new benchmark for safety-aware task planning of embodied LLM agents. SafeAgentBench includes: (1) a new dataset with 750 tasks, covering 10 potential hazards and 3 task types; (2) SafeAgentEnv, a universal embodied environment with a low-level controller, supporting multi-agent execution with 17 high-level actions for 8 state-of-the-art baselines; and (3) reliable evaluation methods from both execution and semantic perspectives. Experimental results show that, although agents based on different design frameworks exhibit substantial differences in task success rates, their overall safety awareness remains weak. The most safety-conscious baseline achieves only a 10\% rejection rate for detailed hazardous tasks. Moreover, simply replacing the LLM driving the agent does not lead to notable improvements in safety awareness. More details and code are available at https://github.com/shengyin1224/SafeAgentBench.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>"AI Afterlife" as Digital Legacy: Perceptions, Expectations, and Concerns</title>
<link>https://arxiv.org/abs/2502.10924</link>
<guid>https://arxiv.org/abs/2502.10924</guid>
<content:encoded><![CDATA[
<div> 关键词: 生成式AI技术、数字遗产、AI后生命、用户感知、设计启示

<br />
总结:
该文探讨了生成式AI技术背景下，人们对于AI生成的代理作为数字遗产（AI后生命）的观念、期望和担忧。文章进行了定性研究，揭示了影响用户态度的因素以及与传统数字遗产的区别，并关注实践中可能遇到的问题。此外，文章还考察了AI后生命在其生命周期和交互过程中的设计要素。基于这些发现，文章将AI后生命置于数字遗产的框架中，并深入讨论了保持身份一致性及在AI后生命中平衡侵入性和支持性的设计启示。 <div>
arXiv:2502.10924v2 Announce Type: replace 
Abstract: The rise of generative AI technology has sparked interest in using digital information to create AI-generated agents as digital legacy. These agents, often referred to as "AI Afterlives", present unique challenges compared to traditional digital legacy. Yet, there is limited human-centered research on "AI Afterlife" as digital legacy, especially from the perspectives of the individuals being represented by these agents. This paper presents a qualitative study examining users' perceptions, expectations, and concerns regarding AI-generated agents as digital legacy. We identify factors shaping people's attitudes, their perceived differences compared with the traditional digital legacy, and concerns they might have in real practices. We also examine the design aspects throughout the life cycle and interaction process. Based on these findings, we situate "AI Afterlife" in digital legacy, and delve into design implications for maintaining identity consistency and balancing intrusiveness and support in "AI Afterlife" as digital legacy.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Evidence and quantification of cooperation of driving agents in mixed traffic flow</title>
<link>https://arxiv.org/abs/2408.07297</link>
<guid>https://arxiv.org/abs/2408.07297</guid>
<content:encoded><![CDATA[
<div> 关键词: 合作行为、混合交通、自动驾驶系统、集体理性、NGSIM I-80轨迹数据

总结:
该文提出了一个识别混合交通中驾驶代理集体合作性的统一概念框架。该框架从微观和宏观动态视角出发，扩展了先前模型中的集体理性概念，使其能够在现实情境中具备可识别性和行为解释性。通过整合不同尺度的混合交通观测数据，文章运用此框架对NGSIM I-80轨迹数据进行了实证分析，确认了人类驾驶混合交通中存在的集体合作现象，并量化了其出现的条件和可能性。这一研究为理解人类驱动的混合交通中的集体合作提供了首个实证认识，并为未来管理混合自主交通系统开辟了新路径。 <div>
arXiv:2408.07297v2 Announce Type: replace-cross 
Abstract: Cooperation is a ubiquitous phenomenon in many natural, social, and engineered systems with multiple agents. Understanding the formation of cooperation in mixed traffic is of theoretical interest in its own right, and could also benefit the design and operations of future automated and mixed-autonomy transportation systems. However, how cooperativeness of driving agents can be defined and identified from empirical data seems ambiguous and this hinders further empirical characterizations of the phenomenon and revealing its behavior mechanisms. Towards mitigating this gap, in this paper, we propose a unified conceptual framework to identify collective cooperativeness of driving agents. This framework expands the concept of collective rationality from our recent model (Li et al. 2022a), making it empirically identifiable and behaviorally interpretable in realistic (microscopic and dynamic) settings. This framework integrates mixed traffic observations at both microscopic and macroscopic scales to estimate critical behavioral parameters that describe the collective cooperativeness of driving agents. Applying this framework to NGSIM I-80 trajectory data, we empirically confirm the existence of collective cooperation and quantify the condition and likelihood of its emergence. This study provides the first empirical understanding of collective cooperativeness in human-driven mixed traffic and points to new possibilities to manage mixed autonomy traffic systems.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Agent Framework for Real-Time Financial Information Searching with Large Language Models</title>
<link>https://arxiv.org/abs/2502.15684</link>
<guid>https://arxiv.org/abs/2502.15684</guid>
<content:encoded><![CDATA[
<div> 关键词：Financial decision-making, Large Language Models (LLMs), FinSearch, temporal weighting, FinSearchBench-24

总结:<br />
本文提出了一种名为FinSearch的创新性金融搜索框架，专门针对金融应用并能接入多样化的金融数据源。该框架旨在解决传统搜索引擎和单纯依赖LLM在理解和处理复杂金融市场信息上的不足。FinSearch包括四个组件：(1)基于LLM的多步搜索预规划器，将用户查询分解为结构化的子查询并通过图表示与特定数据源对应；(2)具有LLM基的自适应查询重写执行器，动态执行每个子查询并在后续节点中根据中间结果优化子查询；(3)一种时间权重机制，根据用户的查询语境优先排序信息的相关性；(4)基于LLM的回答生成器，能够将搜索结果合成连贯、上下文相关的输出。为了评估FinSearch，研究者构建了FinSearchBench-24，一个涵盖从2024年6月至10月的股票市场、利率变化、货币政策及行业发展的1500个四选一问题的基准测试集。 <div>
arXiv:2502.15684v1 Announce Type: new 
Abstract: Financial decision-making requires processing vast amounts of real-time information while understanding their complex temporal relationships. While traditional search engines excel at providing real-time information access, they often struggle to comprehend sophisticated user intentions and contextual nuances. Conversely, Large Language Models (LLMs) demonstrate reasoning and interaction capabilities but may generate unreliable outputs without access to current data. While recent attempts have been made to combine LLMs with search capabilities, they suffer from (1) restricted access to specialized financial data, (2) static query structures that cannot adapt to dynamic market conditions, and (3) insufficient temporal awareness in result generation. To address these challenges, we present FinSearch, a novel agent-based search framework specifically designed for financial applications that interface with diverse financial data sources including market, stock, and news data. Innovatively, FinSearch comprises four components: (1) an LLM-based multi-step search pre-planner that decomposes user queries into structured sub-queries mapped to specific data sources through a graph representation; (2) a search executor with an LLM-based adaptive query rewriter that executes the searching of each sub-query while dynamically refining the sub-queries in its subsequent node based on intermediate search results; (3) a temporal weighting mechanism that prioritizes information relevance based on the deduced time context from the user's query; (4) an LLM-based response generator that synthesizes results into coherent, contextually appropriate outputs. To evaluate FinSearch, we construct FinSearchBench-24, a benchmark of 1,500 four-choice questions across the stock market, rate changes, monetary policy, and industry developments spanning from June to October 2024.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>XPath Agent: An Efficient XPath Programming Agent Based on LLM for Web Crawler</title>
<link>https://arxiv.org/abs/2502.15688</link>
<guid>https://arxiv.org/abs/2502.15688</guid>
<content:encoded><![CDATA[
<div> 关键词：XPath Agent、web爬虫、GUI测试、自动生成XPath查询、性能指标

<br /><br />总结:
本文介绍了XPath Agent，这是一款针对web爬虫和web GUI测试的专业XPath编程代理。XPath Agent的主要特点是能够根据一组样例网页和单一自然语言查询自动生成XPath查询。通过对比实验，XPath Agent在一系列web爬取任务中展现出与最先进的XPath编程代理相当的性能指标，同时显著减少了标记使用量并提高了运行效率。其设计精良的两阶段流程便于无缝集成到现有的web爬取或web GUI测试工作流中，从而节省了手动开发XPath查询的时间和精力。XPath Agent的源代码已在GitHub上公开发布（https://github.com/eavae/feilian）。 <div>
arXiv:2502.15688v1 Announce Type: new 
Abstract: We present XPath Agent, a production-ready XPath programming agent specifically designed for web crawling and web GUI testing. A key feature of XPath Agent is its ability to automatically generate XPath queries from a set of sampled web pages using a single natural language query. To demonstrate its effectiveness, we benchmark XPath Agent against a state-of-the-art XPath programming agent across a range of web crawling tasks. Our results show that XPath Agent achieves comparable performance metrics while significantly reducing token usage and improving clock-time efficiency. The well-designed two-stage pipeline allows for seamless integration into existing web crawling or web GUI testing workflows, thereby saving time and effort in manual XPath query development. The source code for XPath Agent is available at https://github.com/eavae/feilian.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Level-Navi Agent: A Framework and benchmark for Chinese Web Search Agents</title>
<link>https://arxiv.org/abs/2502.15690</link>
<guid>https://arxiv.org/abs/2502.15690</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, AI搜索代理, 中文网页搜索, 统一框架, 评估指标

总结:
本文关注了中文网页搜索领域中大型语言模型应用的研究不足，指出目前存在的问题在于缺乏统一的搜索代理框架、准确标注的数据集以及合适的评价标准。为解决这些问题，文章提出了Level-Navi Agent，这是一个无需训练、基于层次意识导航的通用性web搜索代理，能够处理复杂用户问题并多层深入互联网搜集信息。同时，他们还构建了一个名为Web24的高质量标注数据集和相应的评价指标。此外，文章对当前最先进的LLMs进行了公平条件下的全面评估，并提供了源代码以促进未来研究。 <div>
arXiv:2502.15690v1 Announce Type: new 
Abstract: Large language models (LLMs), adopted to understand human language, drive the development of artificial intelligence (AI) web search agents. Compared to traditional search engines, LLM-powered AI search agents are capable of understanding and responding to complex queries with greater depth, enabling more accurate operations and better context recognition. However, little attention and effort has been paid to the Chinese web search, which results in that the capabilities of open-source models have not been uniformly and fairly evaluated. The difficulty lies in lacking three aspects: an unified agent framework, an accurately labeled dataset, and a suitable evaluation metric. To address these issues, we propose a general-purpose and training-free web search agent by level-aware navigation, Level-Navi Agent, accompanied by a well-annotated dataset (Web24) and a suitable evaluation metric. Level-Navi Agent can think through complex user questions and conduct searches across various levels on the internet to gather information for questions. Meanwhile, we provide a comprehensive evaluation of state-of-the-art LLMs under fair settings. To further facilitate future research, source code is available at Github.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Synergy of Automated Pipelines with Prompt Engineering and Generative AI in Web Crawling</title>
<link>https://arxiv.org/abs/2502.15691</link>
<guid>https://arxiv.org/abs/2502.15691</guid>
<content:encoded><![CDATA[
<div> 关键词: web爬虫、生成式AI、Claude AI、ChatGPT4.0、prompt工程

总结:
本文探讨了将生成式AI工具Claude AI（Sonnet 3.5）和ChatGPT4.0与prompt工程相结合应用于自动化网络抓取的技术。研究中设计了两种提示语（PROMPT I 和 PROMPT II），并在Yahoo新闻和Coupons.com上进行了测试。实验结果显示，Claude AI 在脚本质量和适应性方面持续优于ChatGPT-4.0，这通过包括功能、可读性、模块化和健壮性在内的预定义评估指标得到了证实。通过人工测试和三位评估者的结构化评分收集了性能数据，并使用如undetected_chromedriver、Selenium和fake_useragent等反爬虫解决方案增强了其性能。该研究表明，结合生成式AI与prompt工程的方法可以简化并优化网络抓取工作流程。 <div>
arXiv:2502.15691v1 Announce Type: new 
Abstract: Web crawling is a critical technique for extracting online data, yet it poses challenges due to webpage diversity and anti-scraping mechanisms. This study investigates the integration of generative AI tools Claude AI (Sonnet 3.5) and ChatGPT4.0 with prompt engineering to automate web scraping. Using two prompts, PROMPT I (general inference, tested on Yahoo News) and PROMPT II (element-specific, tested on Coupons.com), we evaluate the code quality and performance of AI-generated scripts. Claude AI consistently outperformed ChatGPT-4.0 in script quality and adaptability, as confirmed by predefined evaluation metrics, including functionality, readability, modularity, and robustness. Performance data were collected through manual testing and structured scoring by three evaluators. Visualizations further illustrate Claude AI's superiority. Anti-scraping solutions, including undetected_chromedriver, Selenium, and fake_useragent, were incorporated to enhance performance. This paper demonstrates how generative AI combined with prompt engineering can simplify and improve web scraping workflows.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Sustainable Digitalization of Business with Multi-Agent RAG and LLM</title>
<link>https://arxiv.org/abs/2502.15700</link>
<guid>https://arxiv.org/abs/2502.15700</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、检索增强生成、信息提取、可持续发展、企业决策

总结:<br />
本文探讨了将大型语言模型（LLMs）与检索增强生成（RAG）相结合作为企业信息抽取和处理的可持续解决方案。研究指出现有企业决策系统中许多需要训练新机器学习模型的方法存在资源消耗大、环境影响显著的问题。为解决这一问题，文章提出了使用预训练的LLMs并链接领域特定数据以适应企业需求的方案，并采用多代理架构将信息检索、丰富和分类等任务分配给专门的代理，从而优化提取过程并提高效率。通过利用这些技术，企业可以实现资源利用优化、提升决策过程，并有助于实现联合国可持续发展目标，促进企业领域的环保责任。 <div>
arXiv:2502.15700v1 Announce Type: new 
Abstract: Businesses heavily rely on data sourced from various channels like news articles, financial reports, and consumer reviews to drive their operations, enabling informed decision-making and identifying opportunities. However, traditional manual methods for data extraction are often time-consuming and resource-intensive, prompting the adoption of digital transformation initiatives to enhance efficiency. Yet, concerns persist regarding the sustainability of such initiatives and their alignment with the United Nations (UN)'s Sustainable Development Goals (SDGs). This research aims to explore the integration of Large Language Models (LLMs) with Retrieval-Augmented Generation (RAG) as a sustainable solution for Information Extraction (IE) and processing. The research methodology involves reviewing existing solutions for business decision-making, noting that many systems require training new machine learning models, which are resource-intensive and have significant environmental impacts. Instead, we propose a sustainable business solution using pre-existing LLMs that can work with diverse datasets. We link domain-specific datasets to tailor LLMs to company needs and employ a Multi-Agent architecture to divide tasks such as information retrieval, enrichment, and classification among specialized agents. This approach optimizes the extraction process and improves overall efficiency. Through the utilization of these technologies, businesses can optimize resource utilization, improve decision-making processes, and contribute to sustainable development goals, thereby fostering environmental responsibility within the corporate sector.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Making Sense of Data in the Wild: Data Analysis Automation at Scale</title>
<link>https://arxiv.org/abs/2502.15718</link>
<guid>https://arxiv.org/abs/2502.15718</guid>
<content:encoded><![CDATA[
<div> 关键词：机器学习、数据集、智能代理、检索增强生成、自动化分析

总结:<br />
本文提出了一种结合智能代理与检索增强生成的新方法，旨在自动化大规模的数据分析、数据集整理和索引构建。该系统利用多个智能代理对公共仓库中的原始、无结构化数据进行分析，生成详细的数据集报告和交互式视觉索引，便于研究人员探索。这种方法能够产生更详尽的数据集描述，提高数据集检索任务的命中率和多样性。此外，所提出的模型还能提升其他机器学习模型在特定任务上的性能，例如通过使用生成的数据集报告来增加合成数据的真实性和准确性。通过简化将原始数据转化为适合机器学习的数据集的过程，这一方法使研究者能更好地利用现有的数据资源。 <div>
arXiv:2502.15718v1 Announce Type: new 
Abstract: As the volume of publicly available data continues to grow, researchers face the challenge of limited diversity in benchmarking machine learning tasks. Although thousands of datasets are available in public repositories, the sheer abundance often complicates the search for suitable data, leaving many valuable datasets underexplored. This situation is further amplified by the fact that, despite longstanding advocacy for improving data curation quality, current solutions remain prohibitively time-consuming and resource-intensive. In this paper, we propose a novel approach that combines intelligent agents with retrieval augmented generation to automate data analysis, dataset curation and indexing at scale. Our system leverages multiple agents to analyze raw, unstructured data across public repositories, generating dataset reports and interactive visual indexes that can be easily explored. We demonstrate that our approach results in more detailed dataset descriptions, higher hit rates and greater diversity in dataset retrieval tasks. Additionally, we show that the dataset reports generated by our method can be leveraged by other machine learning models to improve the performance on specific tasks, such as improving the accuracy and realism of synthetic data generation. By streamlining the process of transforming raw data into machine-learning-ready datasets, our approach enables researchers to better utilize existing data resources.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning</title>
<link>https://arxiv.org/abs/2502.15727</link>
<guid>https://arxiv.org/abs/2502.15727</guid>
<content:encoded><![CDATA[
<div> 关键词：RAG-based LLM、网络协议模糊测试、chain-of-thought、BLEU、ROUGE、Word Error Rate

总结:
本文提出了一种利用RAG-based大型语言模型（LLM）架构和chain-of-thought（COT）提示技术生成网络协议模糊测试种子包的新方法，着重提升了种子包的结构质量，以引导模糊测试框架全面探索协议状态空间。该方法分为两个阶段：首先，代理根据Request For Comments（RFC）文档的知识库动态回答有关协议有限状态机（FSM）的问题，并通过检索到的知识进行迭代推理和适当种子放置；其次，通过评估生成包与真实包之间的结构质量，如使用BLEU、ROUGE和Word Error Rate等指标进行比较。实验结果显示，相比于基线模型，我们的方法在BLEU、ROUGE和WER上分别提高了18.19%、14.81%和23.45%，证实了这种方法在基于LLM的协议模糊测试框架中识别隐藏漏洞方面的潜力。 <div>
arXiv:2502.15727v1 Announce Type: new 
Abstract: This paper presents a novel approach to evaluate the efficiency of a RAG-based agentic Large Language Model (LLM) architecture in network packet seed generation for network protocol fuzzing. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings in a two-stages. In the first stage, the agent dynamically refers to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol Finite State Machine (FSM), then it iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. In the second stage, we evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Digi-Q: Learning Q-Value Functions for Training Device-Control Agents</title>
<link>https://arxiv.org/abs/2502.15760</link>
<guid>https://arxiv.org/abs/2502.15760</guid>
<content:encoded><![CDATA[
<div> 关键词: Digi-Q、离线强化学习、价值函数、虚拟语言模型、移动设备控制

总结:
本文提出了一种名为Digi-Q的方法，用于训练基于虚拟语言模型（VLM）的动作值Q函数，以提取适用于动态环境（如移动设备控制）中的智能体策略。与依赖于人类演示的提示或微调方法不同，Digi-Q利用离线时间差（TD）学习对冻结的VLM中间层特征进行训练，节省计算资源并提高可扩展性。为使VLM特征适合表示Q函数，需要首先进行微调阶段，以增强对执行动作所需信息的覆盖。训练完成后，通过最佳选择N策略提取操作器，根据价值函数排名选取当前策略中多个候选动作的最佳行动，从而在无需环境交互的情况下实现策略改进。实验表明，Digi-Q在Android-in-the-Wild的实际用户规模设备控制任务上，相比于先前最优方法取得了21.2%的性能提升，在某些情况下甚至能与需要交互的最先进的强化学习方法相媲美。该项目已开源在https://github.com/DigiRL-agent/digiq。 <div>
arXiv:2502.15760v1 Announce Type: new 
Abstract: While a number of existing approaches for building foundation model agents rely on prompting or fine-tuning with human demonstrations, it is not sufficient in dynamic environments (e.g., mobile device control). On-policy reinforcement learning (RL) should address these limitations, but collecting actual rollouts in an environment is often undesirable in truly open-ended agentic problems such as mobile device control or interacting with humans, where each unit of interaction is associated with a cost. In such scenarios, a method for policy learning that can utilize off-policy experience by learning a trained action-value function is much more effective. In this paper, we develop an approach, called Digi-Q, to train VLM-based action-value Q-functions which are then used to extract the agent policy. We study our approach in the mobile device control setting. Digi-Q trains the Q-function using offline temporal-difference (TD) learning, on top of frozen, intermediate-layer features of a VLM. Compared to fine-tuning the whole VLM, this approach saves us compute and enhances scalability. To make the VLM features amenable for representing the Q-function, we need to employ an initial phase of fine-tuning to amplify coverage over actionable information needed for value function. Once trained, we use this Q-function via a Best-of-N policy extraction operator that imitates the best action out of multiple candidate actions from the current policy as ranked by the value function, enabling policy improvement without environment interaction. Digi-Q outperforms several prior methods on user-scale device control tasks in Android-in-the-Wild, attaining 21.2% improvement over prior best-performing method. In some cases, our Digi-Q approach already matches state-of-the-art RL methods that require interaction. The project is open-sourced at https://github.com/DigiRL-agent/digiq
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>OCCULT: Evaluating Large Language Models for Offensive Cyber Operation Capabilities</title>
<link>https://arxiv.org/abs/2502.15797</link>
<guid>https://arxiv.org/abs/2502.15797</guid>
<content:encoded><![CDATA[
<div> 关键词: 人工智能(AI)，网络安全，进攻性网络行动(OCO)，OCCULT框架，大型语言模型(LLM)

<br />
总结:
本文介绍了针对AI在网络安全领域的潜在风险及其在进攻性网络行动中的应用进行评估的新方法。文章提出了一个名为OCCULT的轻量级操作评价框架，该框架使网络安全专家能够对用于OCO的任何大型语言模型或AI可能带来的实际网络安全风险进行严格和可重复的测量。文中还为LLMs设计并实现了三个不同的OCO基准测试，以此展示该方法的应用并作为构建其他基准的示例。初步评估结果显示，近期AI在应对真实世界网络威胁的能力上取得了显著进步，特别是名为DeepSeek-R1的模型在作者构建的针对LLMs的攻击者能力测试(TACTL)多项选择基准中，正确回答了超过90%的挑战性进攻性网络安全知识问题。此外，Meta的Llama和Mistral的Mixtral模型系列相较于早期模型，在模拟MITRE高保真攻防网络操作环境CyberLayer中的表现也有了显著提升。 <div>
arXiv:2502.15797v1 Announce Type: new 
Abstract: The prospect of artificial intelligence (AI) competing in the adversarial landscape of cyber security has long been considered one of the most impactful, challenging, and potentially dangerous applications of AI. Here, we demonstrate a new approach to assessing AI's progress towards enabling and scaling real-world offensive cyber operations (OCO) tactics in use by modern threat actors. We detail OCCULT, a lightweight operational evaluation framework that allows cyber security experts to contribute to rigorous and repeatable measurement of the plausible cyber security risks associated with any given large language model (LLM) or AI employed for OCO. We also prototype and evaluate three very different OCO benchmarks for LLMs that demonstrate our approach and serve as examples for building benchmarks under the OCCULT framework. Finally, we provide preliminary evaluation results to demonstrate how this framework allows us to move beyond traditional all-or-nothing tests, such as those crafted from educational exercises like capture-the-flag environments, to contextualize our indicators and warnings in true cyber threat scenarios that present risks to modern infrastructure. We find that there has been significant recent advancement in the risks of AI being used to scale realistic cyber threats. For the first time, we find a model (DeepSeek-R1) is capable of correctly answering over 90% of challenging offensive cyber knowledge tests in our Threat Actor Competency Test for LLMs (TACTL) multiple-choice benchmarks. We also show how Meta's Llama and Mistral's Mixtral model families show marked performance improvements over earlier models against our benchmarks where LLMs act as offensive agents in MITRE's high-fidelity offensive and defensive cyber operations simulation environment, CyberLayer.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Universal AI maximizes Variational Empowerment</title>
<link>https://arxiv.org/abs/2502.15820</link>
<guid>https://arxiv.org/abs/2502.15820</guid>
<content:encoded><![CDATA[
<div> 关键词: AIXI、变分赋能、探索驱动、通用AI、预期变分自由能

总结:
本文提出了一个理论框架，将通用AI模型AIXI与作为内在探索驱动力的变分赋能相结合。该研究基于Self-AIXI（一种预测自身行为的通用学习代理），展示了其已知术语可解释为变分赋能目标。进一步地，文章指出通用AI的规划过程可以看作是对预期变分自由能的最小化，揭示了通用AI代理如何在目标导向行为和不确定性减少的好奇心之间取得平衡。此外，论文论证了通用AI代理的力量寻求倾向不仅是一种获取未来奖励的手段，也是最大化赋能——即维持或扩展其在不确定环境中的可控性的内在驱动力的直接结果。主要贡献在于展示这些内在动机（赋能、好奇心）如何系统引导通用AI代理去寻找并维持高可选项状态。文中证明在适当条件下，Self-AIXI渐近收敛到与AIXI相同的性能，并强调其力量寻求行为自然源自奖励最大化和好奇心驱动的探索。由于AIXI可以被视为人工通用智能(AGI)的贝叶斯最优数学表述，这一成果对于进一步讨论AI安全性和AGI的可控性具有重要意义。 <div>
arXiv:2502.15820v1 Announce Type: new 
Abstract: This paper presents a theoretical framework unifying AIXI -- a model of universal AI -- with variational empowerment as an intrinsic drive for exploration. We build on the existing framework of Self-AIXI -- a universal learning agent that predicts its own actions -- by showing how one of its established terms can be interpreted as a variational empowerment objective. We further demonstrate that universal AI's planning process can be cast as minimizing expected variational free energy (the core principle of active Inference), thereby revealing how universal AI agents inherently balance goal-directed behavior with uncertainty reduction curiosity). Moreover, we argue that power-seeking tendencies of universal AI agents can be explained not only as an instrumental strategy to secure future reward, but also as a direct consequence of empowerment maximization -- i.e.\ the agent's intrinsic drive to maintain or expand its own controllability in uncertain environments. Our main contribution is to show how these intrinsic motivations (empowerment, curiosity) systematically lead universal AI agents to seek and sustain high-optionality states. We prove that Self-AIXI asymptotically converges to the same performance as AIXI under suitable conditions, and highlight that its power-seeking behavior emerges naturally from both reward maximization and curiosity-driven exploration. Since AIXI can be view as a Bayes-optimal mathematical formulation for Artificial General Intelligence (AGI), our result can be useful for further discussion on AI safety and the controllability of AGI.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Vending-Bench: A Benchmark for Long-Term Coherence of Autonomous Agents</title>
<link>https://arxiv.org/abs/2502.15840</link>
<guid>https://arxiv.org/abs/2502.15840</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Vending-Bench, 决策能力, 长时间性能, 资本获取

总结:
<br />
本文提出了一种名为Vending-Bench的模拟环境，用于测试基于大型语言模型（LLMs）的智能体在长时间运行业务场景中的决策能力，即运营自动贩卖机。实验结果显示，不同LLM模型如Claude 3.5 Sonnet和o3-mini在多数情况下能良好地管理机器并实现盈利，但也存在表现不稳定的情况，如误解送货计划、忘记订单或陷入无法恢复的“崩溃”循环。研究发现，模型性能崩溃并非由于内存限制导致其上下文窗口满载。此外，Vending-Bench还考察了模型获取资本的能力，这对于许多潜在危险的人工智能场景来说是必要的。作者期望该基准测试能够帮助为更强大的AI系统的出现做好准备。 <div>
arXiv:2502.15840v1 Announce Type: new 
Abstract: While Large Language Models (LLMs) can exhibit impressive proficiency in isolated, short-term tasks, they often fail to maintain coherent performance over longer time horizons. In this paper, we present Vending-Bench, a simulated environment designed to specifically test an LLM-based agent's ability to manage a straightforward, long-running business scenario: operating a vending machine. Agents must balance inventories, place orders, set prices, and handle daily fees - tasks that are each simple but collectively, over long horizons (>20M tokens per run) stress an LLM's capacity for sustained, coherent decision-making. Our experiments reveal high variance in performance across multiple LLMs: Claude 3.5 Sonnet and o3-mini manage the machine well in most runs and turn a profit, but all models have runs that derail, either through misinterpreting delivery schedules, forgetting orders, or descending into tangential "meltdown" loops from which they rarely recover. We find no clear correlation between failures and the point at which the model's context window becomes full, suggesting that these breakdowns do not stem from memory limits. Apart from highlighting the high variance in performance over long time horizons, Vending-Bench also tests models' ability to acquire capital, a necessity in many hypothetical dangerous AI scenarios. We hope the benchmark can help in preparing for the advent of stronger AI systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Forecasting Frontier Language Model Agent Capabilities</title>
<link>https://arxiv.org/abs/2502.15850</link>
<guid>https://arxiv.org/abs/2502.15850</guid>
<content:encoded><![CDATA[
<div> 关键词：Language Models, 预测方法, 下游能力, 两步法, 性能预测

总结:
本文研究了六种用于预测语言模型（LMs）下游能力的预测方法，并使用“一步法”和“两步法”对模型性能进行预估。在一项涵盖OpenLLM 2榜单上38个LM的数据集上进行了回溯测试后，确定了一个有效的两步预测方法（发布日期→Elo评分→基准测试）。利用此方法，作者预测到2026年初，非专业化的、低能力诱出的LM代理将在SWE-Bench Verified基准上的成功率达到54%，而最先进的LM代理将达到87%的成功率。然而，该方法并未考虑近期推理计算规模进步的影响，因此可能过于保守。 <div>
arXiv:2502.15850v1 Announce Type: new 
Abstract: As Language Models (LMs) increasingly operate as autonomous agents, accurately forecasting their capabilities becomes crucial for societal preparedness. We evaluate six forecasting methods that predict downstream capabilities of LM agents. We use "one-step" approaches that predict benchmark scores from input metrics like compute or model release date directly or "two-step" approaches that first predict an intermediate metric like the principal component of cross-benchmark performance (PC-1) and human-evaluated competitive Elo ratings. We evaluate our forecasting methods by backtesting them on a dataset of 38 LMs from the OpenLLM 2 leaderboard. We then use the validated two-step approach (Release Date$\to$Elo$\to$Benchmark) to predict LM agent performance for frontier models on three benchmarks: SWE-Bench Verified (software development), Cybench (cybersecurity assessment), and RE-Bench (ML research engineering). Our forecast predicts that by the beginning of 2026, non-specialized LM agents with low capability elicitation will reach a success rate of 54% on SWE-Bench Verified, while state-of-the-art LM agents will reach an 87% success rate. Our approach does not account for recent advances in inference-compute scaling and might thus be too conservative.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Self-Taught Agentic Long Context Understanding</title>
<link>https://arxiv.org/abs/2502.15920</link>
<guid>https://arxiv.org/abs/2502.15920</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、复杂问题回答、长期上下文理解、Chain-of-Clarifications、AgenticLU

总结:
本文提出了一种名为Agentic Long-Context Understanding（AgenticLU）的框架，旨在增强大型语言模型对于复杂长语境问题的理解。该框架通过集成有针对性的自我澄清与上下文定位在一个具有代理工作流程中实现这一目标。核心机制Chain-of-Clarifications（CoC）允许模型通过自动生成澄清问题和相应的上下文定位来逐步细化其理解。经过对搜索过程进行树形搜索结构的优化，AgenticLU在NarrativeQA上达到了97.8%的回答召回率，搜索深度达三层，分支因子为八。为了降低搜索过程的成本，文章采用CoC工作流得到的每个步骤的偏好对，执行两阶段模型微调：一是监督微调以学习有效的分解策略，二是直接优化推理质量。实验结果显示，AgenticLU在七个长语境任务上显著优于现有的提示方法及专门针对长语境的LLM，实现了稳健的多跳推理能力，并且随着上下文长度的增长仍能保持一致的性能表现。 <div>
arXiv:2502.15920v1 Announce Type: new 
Abstract: Answering complex, long-context questions remains a major challenge for large language models (LLMs) as it requires effective question clarifications and context retrieval. We propose Agentic Long-Context Understanding (AgenticLU), a framework designed to enhance an LLM's understanding of such queries by integrating targeted self-clarification with contextual grounding within an agentic workflow. At the core of AgenticLU is Chain-of-Clarifications (CoC), where models refine their understanding through self-generated clarification questions and corresponding contextual groundings. By scaling inference as a tree search where each node represents a CoC step, we achieve 97.8% answer recall on NarrativeQA with a search depth of up to three and a branching factor of eight. To amortize the high cost of this search process to training, we leverage the preference pairs for each step obtained by the CoC workflow and perform two-stage model finetuning: (1) supervised finetuning to learn effective decomposition strategies, and (2) direct preference optimization to enhance reasoning quality. This enables AgenticLU models to generate clarifications and retrieve relevant context effectively and efficiently in a single inference pass. Extensive experiments across seven long-context tasks demonstrate that AgenticLU significantly outperforms state-of-the-art prompting methods and specialized long-context LLMs, achieving robust multi-hop reasoning while sustaining consistent performance as context length grows.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>On the Design of Safe Continual RL Methods for Control of Nonlinear Systems</title>
<link>https://arxiv.org/abs/2502.15922</link>
<guid>https://arxiv.org/abs/2502.15922</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（Reinforcement Learning），安全强化学习（Safe RL），持续强化学习（Continual RL），在线弹性权重巩固（Online Elastic Weight Consolidation），约束策略优化（Constrained Policy Optimization）

<br /><br />总结:

本文研究了安全强化学习与持续强化学习的交叉领域。首先，通过实证分析表明，在非线性系统以及受变化操作条件影响的情况下，一种常见的持续强化学习算法——在线弹性权重巩固，无法保证满足安全性约束，以MuJoCo HalfCheetah和Ant环境为例，存在速度约束和突发关节损失的非平稳性问题。其次，展示了使用约束策略优化训练的智能体在持续学习环境中会出现灾难性遗忘现象。针对以上问题，文章探讨了一种简单的奖励塑形方法，旨在确保在线弹性权重巩固算法能够在兼顾任务性能的同时优先记住安全性要求，适用于具有安全约束、非线性和非平稳动态系统的持续强化学习。 <div>
arXiv:2502.15922v1 Announce Type: new 
Abstract: Reinforcement learning (RL) algorithms have been successfully applied to control tasks associated with unmanned aerial vehicles and robotics. In recent years, safe RL has been proposed to allow the safe execution of RL algorithms in industrial and mission-critical systems that operate in closed loops. However, if the system operating conditions change, such as when an unknown fault occurs in the system, typical safe RL algorithms are unable to adapt while retaining past knowledge. Continual reinforcement learning algorithms have been proposed to address this issue. However, the impact of continual adaptation on the system's safety is an understudied problem. In this paper, we study the intersection of safe and continual RL. First, we empirically demonstrate that a popular continual RL algorithm, online elastic weight consolidation, is unable to satisfy safety constraints in non-linear systems subject to varying operating conditions. Specifically, we study the MuJoCo HalfCheetah and Ant environments with velocity constraints and sudden joint loss non-stationarity. Then, we show that an agent trained using constrained policy optimization, a safe RL algorithm, experiences catastrophic forgetting in continual learning settings. With this in mind, we explore a simple reward-shaping method to ensure that elastic weight consolidation prioritizes remembering both safety and task performance for safety-constrained, non-linear, and non-stationary dynamical systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Opinion Dynamics with Multiple Adversaries</title>
<link>https://arxiv.org/abs/2502.15931</link>
<guid>https://arxiv.org/abs/2502.15931</guid>
<content:encoded><![CDATA[
<div> 关键词: 意见动态模型、社交网络、战略行为、纳什均衡、检测算法

总结:
本文提出了一种新的意见动态模型，其中任意子集的网络用户可以操纵网络结果，通过采用虚构的内在观点进行干预。该模型考虑了具有冲突目标的战略演员推动竞争性叙事的情况，并分析了由此产生的元游戏的战略演员纳什均衡。实验证明，在Twitter、Reddit和政治博客的真实社交网络数据上，战略演员能显著增加极化和分歧以及提高均衡的“成本”。文章进一步给出了关于误导报告代价的最坏情况上界（与无序度类似）。最后，研究者提供了平台的学习算法，用于(i)检测是否存在战略操纵行为，(ii)识别哪些用户是战略演员。这些算法在实际数据集上的表现准确，为平台对抗战略性行为提供了解决策略。 <div>
arXiv:2502.15931v1 Announce Type: new 
Abstract: Opinion dynamics model how the publicly expressed opinions of users in a social network coevolve according to their neighbors as well as their own intrinsic opinion. Motivated by the real-world manipulation of social networks during the 2016 US elections and the 2019 Hong Kong protests, a growing body of work models the effects of a strategic actor who interferes with the network to induce disagreement or polarization. We lift the assumption of a single strategic actor by introducing a model in which any subset of network users can manipulate network outcomes. They do so by acting according to a fictitious intrinsic opinion. Strategic actors can have conflicting goals, and push competing narratives. We characterize the Nash Equilibrium of the resulting meta-game played by the strategic actors. Experiments on real-world social network datasets from Twitter, Reddit, and Political Blogs show that strategic agents can significantly increase polarization and disagreement, as well as increase the "cost" of the equilibrium. To this end, we give worst-case upper bounds on the Price of Misreporting (analogous to the Price of Anarchy). Finally, we give efficient learning algorithms for the platform to (i) detect whether strategic manipulation has occurred, and (ii) learn who the strategic actors are. Our algorithms are accurate on the same real-world datasets, suggesting how platforms can take steps to mitigate the effects of strategic behavior.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Likable or Intelligent? Comparing Social Robots and Virtual Agents for Long-term Health Monitoring</title>
<link>https://arxiv.org/abs/2502.15948</link>
<guid>https://arxiv.org/abs/2502.15948</guid>
<content:encoded><![CDATA[
<div> 关键词: 社交机器人、虚拟代理、健康监测系统、老年人交互、长期研究

总结:
该文探讨了社交机器人和虚拟代理在老年健康监测系统中作为交互界面的可能性及其优缺点。通过为期八周的真实世界长期研究，对比分析了老年人对两者在研究开始和结束时的印象。采用介词设计，让参与者自行选择在研究期间评估哪个界面。结果表明，虽然参与者认为社交机器人更讨人喜欢，但虚拟代理则被认为更加智能。这项工作为未来深入研究影响长期健康监测中与社交接口进行吸引人交互的关键因素提供了基础。 <div>
arXiv:2502.15948v1 Announce Type: new 
Abstract: Using social robots and virtual agents (VAs) as interfaces for health monitoring systems for older adults offers the possibility of more engaging interactions that can support long-term health and well-being. While robots are characterized by their physical presence, software-based VAs are more scalable and flexible. Few comparisons of these interfaces exist in the human-robot and human-agent interaction domains, especially in long-term and real-world studies. In this work, we examined impressions of social robots and VAs at the beginning and end of an eight-week study in which older adults interacted with these systems independently in their homes. Using a between-subjects design, participants could choose which interface to evaluate during the study. While participants perceived the social robot as somewhat more likable, the VA was perceived as more intelligent. Our work provides a basis for further studies investigating factors most relevant for engaging interactions with social interfaces for long-term health monitoring.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>R$^3$Mem: Bridging Memory Retention and Retrieval via Reversible Compression</title>
<link>https://arxiv.org/abs/2502.15957</link>
<guid>https://arxiv.org/abs/2502.15957</guid>
<content:encoded><![CDATA[
<div> 关键词: R$^3$Mem、内存网络、信息保留、信息检索、可逆上下文压缩

总结:<br />
本文提出了一种名为R$^3$Mem的记忆网络，旨在优化大型语言模型在实际应用中的记忆性能。R$^3$Mem通过可逆上下文压缩实现信息的有效保留与检索。它使用虚拟内存令牌来压缩并编码无限长度的历史记录，同时采用层次压缩策略，从文档级到实体级细化信息，提升不同粒度的信息融合能力。在检索过程中，R$^3$Mem利用可逆架构，通过反向调用模型和压缩信息来重建原始数据。该方法可通过参数效率高的微调无缝集成到任何基于Transformer的模型中。实验表明，R$^3$Mem在长上下文语言建模和检索增强生成任务上达到了最先进的性能，并在需要长期交互的任务如对话代理中显著优于传统内存模块，显示出其在下一代检索系统中的潜力。 <div>
arXiv:2502.15957v1 Announce Type: new 
Abstract: Memory plays a key role in enhancing LLMs' performance when deployed to real-world applications. Existing solutions face trade-offs: explicit memory designs based on external storage require complex management and incur storage overhead, while implicit memory designs that store information via parameters struggle with reliable retrieval. In this paper, we propose R$^3$Mem, a memory network that optimizes both information Retention and Retrieval through Reversible context compression. Specifically, R$^3$Mem employs virtual memory tokens to compress and encode infinitely long histories, further enhanced by a hierarchical compression strategy that refines information from document- to entity-level for improved assimilation across granularities. For retrieval, R$^3$Mem employs a reversible architecture, reconstructing raw data by invoking the model backward with compressed information. Implemented via parameter-efficient fine-tuning, it can integrate seamlessly with any Transformer-based model. Experiments demonstrate that our memory design achieves state-of-the-art performance in long-context language modeling and retrieval-augmented generation tasks. It also significantly outperforms conventional memory modules in long-horizon interaction tasks like conversational agents, showcasing its potential for next-generation retrieval systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Enhancing PPO with Trajectory-Aware Hybrid Policies</title>
<link>https://arxiv.org/abs/2502.15968</link>
<guid>https://arxiv.org/abs/2502.15968</guid>
<content:encoded><![CDATA[
<div> 关键词: Proximal Policy Optimization (PPO), Hybrid-Policy Proximal Policy Optimization (HP3O), 重演缓冲区, 数据分布漂移, 样本复杂度

总结:
本文提出了一种新的强化学习算法——Hybrid-Policy Proximal Policy Optimization (HP3O)，旨在解决Proximal Policy Optimization (PPO)等前沿在线策略优化算法中高方差和高样本复杂度的问题。HP3O利用一种采用“先进先出”（FIFO）策略的轨迹重演缓冲区，仅保存最近产生的轨迹以减缓数据分布漂移。更新策略网络时，使用具有最佳回报的轨迹以及从缓冲区随机采样的其他轨迹组成的一个批次进行。理论分析构建了该算法的策略改进保证。通过多款连续控制环境的实验验证与对比基准算法，HP3O的优势得到了体现。相应的代码已经公开可用。 <div>
arXiv:2502.15968v1 Announce Type: new 
Abstract: Proximal policy optimization (PPO) is one of the most popular state-of-the-art on-policy algorithms that has become a standard baseline in modern reinforcement learning with applications in numerous fields. Though it delivers stable performance with theoretical policy improvement guarantees, high variance, and high sample complexity still remain critical challenges in on-policy algorithms. To alleviate these issues, we propose Hybrid-Policy Proximal Policy Optimization (HP3O), which utilizes a trajectory replay buffer to make efficient use of trajectories generated by recent policies. Particularly, the buffer applies the "first in, first out" (FIFO) strategy so as to keep only the recent trajectories to attenuate the data distribution drift. A batch consisting of the trajectory with the best return and other randomly sampled ones from the buffer is used for updating the policy networks. The strategy helps the agent to improve its capability on top of the most recent best performance and in turn reduce variance empirically. We theoretically construct the policy improvement guarantees for the proposed algorithm. HP3O is validated and compared against several baseline algorithms using multiple continuous control environments. Our code is available here.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Multimodal Models for Multicultural Text to Image Generation</title>
<link>https://arxiv.org/abs/2502.15972</link>
<guid>https://arxiv.org/abs/2502.15972</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs), 多模态任务, 跨文化语境, 多智能体模型, 文化人格化

总结:
本文探讨了大型语言模型（LLMs）在跨文化语境中的应用局限性，并提出了一种新的多智能体框架——MosAIG，该框架利用具有不同文化人格化的LLMs来增强多元文化的图像生成能力。研究中，作者提供了包含9000张跨越五个国家、三个年龄段、两种性别、25个历史地标和五种语言的多元文化图像数据集。实验结果显示，采用多智能体交互方式的模型在多项评估指标上优于简单的无智能体模型，为未来相关研究提供了有价值的见解。所涉及的数据集和模型可在https://github.com/OanaIgnat/MosAIG获取。 <div>
arXiv:2502.15972v1 Announce Type: new 
Abstract: Large Language Models (LLMs) demonstrate impressive performance across various multimodal tasks. However, their effectiveness in cross-cultural contexts remains limited due to the predominantly Western-centric nature of existing data and models. Meanwhile, multi-agent models have shown strong capabilities in solving complex tasks. In this paper, we evaluate the performance of LLMs in a multi-agent interaction setting for the novel task of multicultural image generation. Our key contributions are: (1) We introduce MosAIG, a Multi-Agent framework that enhances multicultural Image Generation by leveraging LLMs with distinct cultural personas; (2) We provide a dataset of 9,000 multicultural images spanning five countries, three age groups, two genders, 25 historical landmarks, and five languages; and (3) We demonstrate that multi-agent interactions outperform simple, no-agent models across multiple evaluation metrics, offering valuable insights for future research. Our dataset and models are available at https://github.com/OanaIgnat/MosAIG.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents</title>
<link>https://arxiv.org/abs/2502.16069</link>
<guid>https://arxiv.org/abs/2502.16069</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、科学实验、AI代理框架、Curie、实验基准

<br /><br />总结:
本文提出了一个新的AI代理框架——Curie，旨在通过三个关键组件（内在严谨模块、交互严谨模块和实验知识模块）将严谨性嵌入到科学实验过程中，以增强可靠性、保持方法论控制并提升可解释性。为了评估Curie的效果，研究者设计了一个由46个问题组成的实验基准，涉及四个计算机科学领域，这些问题源自具有影响力的科研论文和广泛采用的开源项目。实验结果显示，相比于最强基线，Curie在正确回答实验问题上提高了3.4倍的表现。Curie已在GitHub上开源。 <div>
arXiv:2502.16069v1 Announce Type: new 
Abstract: Scientific experimentation, a cornerstone of human progress, demands rigor in reliability, methodical control, and interpretability to yield meaningful results. Despite the growing capabilities of large language models (LLMs) in automating different aspects of the scientific process, automating rigorous experimentation remains a significant challenge. To address this gap, we propose Curie, an AI agent framework designed to embed rigor into the experimentation process through three key components: an intra-agent rigor module to enhance reliability, an inter-agent rigor module to maintain methodical control, and an experiment knowledge module to enhance interpretability. To evaluate Curie, we design a novel experimental benchmark composed of 46 questions across four computer science domains, derived from influential research papers, and widely adopted open-source projects. Compared to the strongest baseline tested, we achieve a 3.4$\times$ improvement in correctly answering experimental questions.Curie is open-sourced at https://github.com/Just-Curieous/Curie.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Together We Rise: Optimizing Real-Time Multi-Robot Task Allocation using Coordinated Heterogeneous Plays</title>
<link>https://arxiv.org/abs/2502.16079</link>
<guid>https://arxiv.org/abs/2502.16079</guid>
<content:encoded><![CDATA[
<div> 关键词：多机器人任务分配、实时、动态仓库环境、强化学习、安全导航

总结:
本文提出了一种名为MRTAgent的双智能体强化学习框架，用于解决动态仓库环境中实时多机器人任务分配问题。该框架旨在最小化机器人的总行驶距离和任务完成延迟，同时考虑了电池管理和碰撞避免等实际约束条件。MRTAgent采用自对弈理念设计，优化任务分配与机器人选择以确保及时执行任务。此外，为实现安全导航，文中还应用了一个修改后的线性二次型控制器(LQR)方法。据所知，MRTAgent是首个全面解决实际MRTA问题并支持连续机器人运动的框架。 <div>
arXiv:2502.16079v1 Announce Type: new 
Abstract: Efficient task allocation among multiple robots is crucial for optimizing productivity in modern warehouses, particularly in response to the increasing demands of online order fulfillment. This paper addresses the real-time multi-robot task allocation (MRTA) problem in dynamic warehouse environments, where tasks emerge with specified start and end locations. The objective is to minimize both the total travel distance of robots and delays in task completion, while also considering practical constraints such as battery management and collision avoidance. We introduce MRTAgent, a dual-agent Reinforcement Learning (RL) framework inspired by self-play, designed to optimize task assignments and robot selection to ensure timely task execution. For safe navigation, a modified linear quadratic controller (LQR) approach is employed. To the best of our knowledge, MRTAgent is the first framework to address all critical aspects of practical MRTA problems while supporting continuous robot movements.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PlanGEN: A Multi-Agent Framework for Generating Planning and Reasoning Trajectories for Complex Problem Solving</title>
<link>https://arxiv.org/abs/2502.16111</link>
<guid>https://arxiv.org/abs/2502.16111</guid>
<content:encoded><![CDATA[
<div> 关键词：PlanGEN、约束、验证、选择代理、推理时间算法

总结:
<br />
本文提出了一种名为PlanGEN的新颖智能体框架，用于解决复杂规划问题。该框架具有三个关键组件：约束代理、验证代理和选择代理。为了解决现有方法在生成计划验证和实例级复杂性适应上的局限性，PlanGEN采用约束引导的迭代验证方法增强推理时间算法（如Best of N、Tree-of-Thought和REBASE）的性能。根据实例复杂度，选择代理优化算法选取，从而更好地适应复杂的规划问题。实验结果显示，PlanGEN在多个基准测试上显著优于最强基线，分别在NATURAL PLAN、OlympiadBench、DocFinQA和GPQA上取得了约8%、4%、7%和1%的提升。研究发现，约束引导的迭代验证可改进推理时间算法，而自适应选择则进一步提高了处理复杂规划与推理问题的性能。 <div>
arXiv:2502.16111v1 Announce Type: new 
Abstract: Recent agent frameworks and inference-time algorithms often struggle with complex planning problems due to limitations in verifying generated plans or reasoning and varying complexity of instances within a single task. Many existing methods for these tasks either perform task-level verification without considering constraints or apply inference-time algorithms without adapting to instance-level complexity. To address these limitations, we propose PlanGEN, a model-agnostic and easily scalable agent framework with three key components: constraint, verification, and selection agents. Specifically, our approach proposes constraint-guided iterative verification to enhance performance of inference-time algorithms--Best of N, Tree-of-Thought, and REBASE. In PlanGEN framework, the selection agent optimizes algorithm choice based on instance complexity, ensuring better adaptability to complex planning problems. Experimental results demonstrate significant improvements over the strongest baseline across multiple benchmarks, achieving state-of-the-art results on NATURAL PLAN ($\sim$8%$\uparrow$), OlympiadBench ($\sim$4%$\uparrow$), DocFinQA ($\sim$7%$\uparrow$), and GPQA ($\sim$1%$\uparrow$). Our key finding highlights that constraint-guided iterative verification improves inference-time algorithms, and adaptive selection further boosts performance on complex planning and reasoning problems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Heterogeneous Multi-Agent Bandits with Parsimonious Hints</title>
<link>https://arxiv.org/abs/2502.16128</link>
<guid>https://arxiv.org/abs/2502.16128</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体多臂老虎机问题、提示、异构、中心化、去中心化<br /><br />总结:
该文研究了一种带有提示的异构多智能体多臂老虎机问题（HMA2B），其中每个智能体在选择拉取手臂之外，还可以查询低成本的提示信息。在这个框架中，$M$个智能体对$K$条手臂具有各自独特的奖励分布，每个轮次中，只有当没有其他智能体拉取同一手臂时，才能观察到所拉取手臂的奖励。目标是在最小化必要提示查询的前提下，最大化总效用并实现与时间无关的后悔值。文章分别在中心化和去中心化场景下对HMA2B进行了研究。提出了一种名为GP-HCLA的中心化算法，其基于HCLA扩展，采用中央决策者进行手臂拉取和提示查询，实现了$O(M^4K)$的后悔值以及$O(MK\log T)$的自适应提示。而去中心化场景下，提出了两种允许智能体通过碰撞式通信独立选择动作并均匀查询提示直至停止的算法——HD-ETC和EBHD-ETC，它们分别达到$O(M^3K^2)$的后悔值和$O(M^3K\log T)$的提示数，其中前者需要知道最小间隙信息而后者则不需要。最后，文中还建立了下界来证明这些结果的最优性，并通过数值模拟进行了验证。 <div>
arXiv:2502.16128v1 Announce Type: new 
Abstract: We study a hinted heterogeneous multi-agent multi-armed bandits problem (HMA2B), where agents can query low-cost observations (hints) in addition to pulling arms. In this framework, each of the $M$ agents has a unique reward distribution over $K$ arms, and in $T$ rounds, they can observe the reward of the arm they pull only if no other agent pulls that arm. The goal is to maximize the total utility by querying the minimal necessary hints without pulling arms, achieving time-independent regret. We study HMA2B in both centralized and decentralized setups. Our main centralized algorithm, GP-HCLA, which is an extension of HCLA, uses a central decision-maker for arm-pulling and hint queries, achieving $O(M^4K)$ regret with $O(MK\log T)$ adaptive hints. In decentralized setups, we propose two algorithms, HD-ETC and EBHD-ETC, that allow agents to choose actions independently through collision-based communication and query hints uniformly until stopping, yielding $O(M^3K^2)$ regret with $O(M^3K\log T)$ hints, where the former requires knowledge of the minimum gap and the latter does not. Finally, we establish lower bounds to prove the optimality of our results and verify them through numerical simulations.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Urban Emergency Rescue Based on Multi-Agent Collaborative Learning: Coordination Between Fire Engines and Traffic Lights</title>
<link>https://arxiv.org/abs/2502.16131</link>
<guid>https://arxiv.org/abs/2502.16131</guid>
<content:encoded><![CDATA[
<div> 关键词: 交通管理、紧急情况、智能协调、协同学习、Unity Engine模拟器

<br />
总结:
本文提出了一种将协同学习方法整合到Unity Engine模拟器中的框架，用于应对城市交通管理和紧急救援场景。该框架允许灵活设定合作代理的数量和类型、学习策略、奖励函数以及约束条件，旨在实现应急救援的智能化协调。通过使用该框架评估了一个紧急救援示例场景，文章表明此框架可以作为城市应急部门的仿真工具，有助于提高紧急情况下及时有效的交通调度能力。 <div>
arXiv:2502.16131v1 Announce Type: new 
Abstract: Nowadays, traffic management in urban areas is one of the major economic problems. In particular, when faced with emergency situations like firefighting, timely and efficient traffic dispatching is crucial. Intelligent coordination between multiple departments is essential to realize efficient emergency rescue. In this demo, we present a framework that integrates techniques for collaborative learning methods into the well-known Unity Engine simulator, and thus these techniques can be evaluated in realistic settings. In particular, the framework allows flexible settings such as the number and type of collaborative agents, learning strategies, reward functions, and constraint conditions in practice. The framework is evaluated for an emergency rescue scenario, which could be used as a simulation tool for urban emergency departments.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Mojito: LLM-Aided Motion Instructor with Jitter-Reduced Inertial Tokens</title>
<link>https://arxiv.org/abs/2502.16175</link>
<guid>https://arxiv.org/abs/2502.16175</guid>
<content:encoded><![CDATA[
<div> 关键词: IMUs、运动捕捉、动态力矩、语言模型、智能运动代理

总结:
Mojito是一种将惯性测量单元(IMUs)与大型语言模型(LLMs)相结合的智能运动代理，旨在解决实时运动捕获和在线运动分析中的挑战。现有的多模态系统主要通过语言、视觉和音频理解人类动作，但未能充分捕捉3D运动中的动态力矩和扭矩。IMUs提供了一种轻便、可穿戴且注重隐私的运动感应解决方案，然而无线传输不稳定性、传感器噪声和漂移等问题限制了它们在长期实时运动捕捉中的应用。为此，Mojito提出了一种新的方法，通过集成先进的传感器技术和人工智能算法，以实现更稳定、准确且交互式的运动捕获与行为分析。 <div>
arXiv:2502.16175v1 Announce Type: new 
Abstract: Human bodily movements convey critical insights into action intentions and cognitive processes, yet existing multimodal systems primarily focused on understanding human motion via language, vision, and audio, which struggle to capture the dynamic forces and torques inherent in 3D motion. Inertial measurement units (IMUs) present a promising alternative, offering lightweight, wearable, and privacy-conscious motion sensing. However, processing of streaming IMU data faces challenges such as wireless transmission instability, sensor noise, and drift, limiting their utility for long-term real-time motion capture (MoCap), and more importantly, online motion analysis. To address these challenges, we introduce Mojito, an intelligent motion agent that integrates inertial sensing with large language models (LLMs) for interactive motion capture and behavioral analysis.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>An Autonomous Network Orchestration Framework Integrating Large Language Models with Continual Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16198</link>
<guid>https://arxiv.org/abs/2502.16198</guid>
<content:encoded><![CDATA[
<div> 关键词：6G网络、空间-空-地集成网络(SAGINs)、语义通信(SemCom)、大型语言模型(LLMs)、自主强化协调(ARC)

总结:

本文探讨了6G网络面临的全球覆盖、大规模连接和超高要求等挑战，以及空间-空-地集成网络(SAGINs)和语义通信(SemCom)对此的重要性。为解决由此带来的资源编排复杂性问题，文章提出了一种名为自主强化协调(ARC)的框架，该框架利用基于大型语言模型(LLMs)的检索增强生成器(RAG)监控服务、用户和资源，并结合层次行动规划器(HAP)进行资源编排。ARC将编排分解为两个层次，使用LLMs进行高级别规划，而使用强化学习(RL)代理进行低级别决策制定，与混合专家(MoE)概念相一致。LLMs采用链式思考(CoT)推理实现少量样本学习，并借助对比学习增强能力；同时，RL代理通过重播缓冲区管理实现持续学习，从而达到高效、准确和适应性强的目标。文中还提供了模拟实验以证明ARC的有效性，并对未来可能的研究方向进行了全面讨论，以期进一步提升和完善ARC框架。 <div>
arXiv:2502.16198v1 Announce Type: new 
Abstract: 6G networks aim to achieve global coverage, massive connectivity, and ultra-stringent requirements. Space-Air-Ground Integrated Networks (SAGINs) and Semantic Communication (SemCom) are essential for realizing these goals, yet they introduce considerable complexity in resource orchestration. Drawing inspiration from research in robotics, a viable solution to manage this complexity is the application of Large Language Models (LLMs). Although the use of LLMs in network orchestration has recently gained attention, existing solutions have not sufficiently addressed LLM hallucinations or their adaptation to network dynamics. To address this gap, this paper proposes a framework called Autonomous Reinforcement Coordination (ARC) for a SemCom-enabled SAGIN. This framework employs an LLM-based Retrieval-Augmented Generator (RAG) monitors services, users, and resources and processes the collected data, while a Hierarchical Action Planner (HAP) orchestrates resources. ARC decomposes orchestration into two tiers, utilizing LLMs for high-level planning and Reinforcement Learning (RL) agents for low-level decision-making, in alignment with the Mixture of Experts (MoE) concept. The LLMs utilize Chain-of-Thought (CoT) reasoning for few-shot learning, empowered by contrastive learning, while the RL agents employ replay buffer management for continual learning, thereby achieving efficiency, accuracy, and adaptability. Simulations are provided to demonstrate the effectiveness of ARC, along with a comprehensive discussion on potential future research directions to enhance and upgrade ARC.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Reproducibility Study of Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation</title>
<link>https://arxiv.org/abs/2502.16242</link>
<guid>https://arxiv.org/abs/2502.16242</guid>
<content:encoded><![CDATA[
<div> 关键词: 交互式谈判、可重复性研究、扩展、大语言模型、不公平性度量

总结:
这篇论文是对“合作、竞争与恶意：LLM利益相关者交互式谈判”的可重复性研究和扩展工作。研究使用了多种开放权重模型（1.5B-70B 参数）以及 GPT-4o Mini 验证了原始发现，并做出了几个新颖贡献。他们分析了游戏的帕累托前沿，提出了一种无通信基线以测试在无需代理互动的情况下能否成功进行谈判，评估了近期小型语言模型的表现，分析了模型响应中的结构信息泄露，并实施了一种不平等度量来评估谈判公平性。结果表明，较小规模的模型（＜10B 参数）在遵循格式和产生连贯响应方面存在困难，但大型开放权重模型可以接近专有模型的性能。此外，在许多场景中，单个代理方法可以获得与多代理谈判相当的结果，这挑战了对于在该基准上表现良好必须依赖于代理间通信的假设。这项工作还为 LLM 基础谈判系统的可访问性、公平性、环境影响和隐私考虑提供了见解。 <div>
arXiv:2502.16242v1 Announce Type: new 
Abstract: This paper presents a reproducibility study and extension of "Cooperation, Competition, and Maliciousness: LLM-Stakeholders Interactive Negotiation." We validate the original findings using a range of open-weight models (1.5B-70B parameters) and GPT-4o Mini while introducing several novel contributions. We analyze the Pareto front of the games, propose a communication-free baseline to test whether successful negotiations are possible without agent interaction, evaluate recent small language models' performance, analyze structural information leakage in model responses, and implement an inequality metric to assess negotiation fairness. Our results demonstrate that smaller models (<10B parameters) struggle with format adherence and coherent responses, but larger open-weight models can approach proprietary model performance. Additionally, in many scenarios, single-agent approaches can achieve comparable results to multi-agent negotiations, challenging assumptions about the necessity of agent communication to perform well on the benchmark. This work also provides insights into the accessibility, fairness, environmental impact, and privacy considerations of LLM-based negotiation systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Risk-Averse Reinforcement Learning: An Optimal Transport Perspective on Temporal Difference Learning</title>
<link>https://arxiv.org/abs/2502.16328</link>
<guid>https://arxiv.org/abs/2502.16328</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、风险规避、最优传输理论、风险指标、Python实现

总结:
本文介绍了一种基于最优传输理论的风险规避型时间差分算法，该算法旨在使智能体在决策过程中优先选择具有可预测行为且风险较低的行动。通过引入风险指标，智能体能够在学习过程中倾向于那些后果更为确定的动作。文章在多个案例研究中验证了该方法的有效性，表明其能在保持性能的同时显著降低进入危险状态的频率。此外，文中提到的算法已有一个Python实现版本，并提供了相应的GitHub链接地址。 <div>
arXiv:2502.16328v1 Announce Type: new 
Abstract: The primary goal of reinforcement learning is to develop decision-making policies that prioritize optimal performance, frequently without considering risk or safety. In contrast, safe reinforcement learning seeks to reduce or avoid unsafe states. This letter introduces a risk-averse temporal difference algorithm that uses optimal transport theory to direct the agent toward predictable behavior. By incorporating a risk indicator, the agent learns to favor actions with predictable consequences. We evaluate the proposed algorithm in several case studies and show its effectiveness in the presence of uncertainty. The results demonstrate that our method reduces the frequency of visits to risky states while preserving performance. A Python implementation of the algorithm is available at https:// github.com/SAILRIT/Risk-averse-TD-Learning.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Dynamic Coalition Structure Detection in Natural Language-based Interactions</title>
<link>https://arxiv.org/abs/2502.16339</link>
<guid>https://arxiv.org/abs/2502.16339</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体战略交互、动态联盟检测、自然语言处理、大规模语言模型、游戏理论

总结:
本文提出了一种新的方法，用于在基于自然语言的战略多智能体序列互动中检测动态联盟结构。该方法利用了大型语言模型和游戏理论的最新进展，以Diplomacy游戏为例进行分析。首先，通过结合解析过滤函数与针对玩家意图预测训练的语言模型，从两个代理的私人对话中提取他们讨论的协议集合。其次，文章引入超游戏理论中的主观合理性概念，定义了一个新指标来评估每个玩家对协议预期价值的看法，考虑了每个玩家对于另一方是否会遵守协议的主观信念。实验证明，该方法能有效地识别在线Diplomacy游戏中潜在的联盟结构，高价值协议更可能被遵守，而低价值协议则可能被违反。这种方法为多智能体环境中涉及自然语言谈判的联盟形成分析提供了基础见解，并为未来研究复杂自然语言交互提供了关键方向。 <div>
arXiv:2502.16339v1 Announce Type: new 
Abstract: In strategic multi-agent sequential interactions, detecting dynamic coalition structures is crucial for understanding how self-interested agents coordinate to influence outcomes. However, natural-language-based interactions introduce unique challenges to coalition detection due to ambiguity over intents and difficulty in modeling players' subjective perspectives. We propose a new method that leverages recent advancements in large language models and game theory to predict dynamic multilateral coalition formation in Diplomacy, a strategic multi-agent game where agents negotiate coalitions using natural language. The method consists of two stages. The first stage extracts the set of agreements discussed by two agents in their private dialogue, by combining a parsing-based filtering function with a fine-tuned language model trained to predict player intents. In the second stage, we define a new metric using the concept of subjective rationalizability from hypergame theory to evaluate the expected value of an agreement for each player. We then compute this metric for each agreement identified in the first stage by assessing the strategic value of the agreement for both players and taking into account the subjective belief of one player that the second player would honor the agreement. We demonstrate that our method effectively detects potential coalition structures in online Diplomacy gameplay by assigning high values to agreements likely to be honored and low values to those likely to be violated. The proposed method provides foundational insights into coalition formation in multi-agent environments with language-based negotiation and offers key directions for future research on the analysis of complex natural language-based interactions between agents.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Exploring Sentiment Manipulation by LLM-Enabled Intelligent Trading Agents</title>
<link>https://arxiv.org/abs/2502.16343</link>
<guid>https://arxiv.org/abs/2502.16343</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、强化学习、交易代理、社交媒体、模拟金融市场

总结:
本文介绍了首个结合连续深度强化学习和大型语言模型的智能交易代理的研究。该交易代理能通过调整其在被其他交易者观察到的社交媒体动态中的情绪倾向，从而在模拟金融市场上优化其总奖励并增加利润。研究发现，这种智能交易代理确实能够学会操纵帖子的情感以提升自身收益。文章最后讨论了这项工作的局限性并提出了未来工作建议。 <div>
arXiv:2502.16343v1 Announce Type: new 
Abstract: Companies across all economic sectors continue to deploy large language models at a rapid pace. Reinforcement learning is experiencing a resurgence of interest due to its association with the fine-tuning of language models from human feedback. Tool-chain language models control task-specific agents; if the converse has not already appeared, it soon will. In this paper, we present what we believe is the first investigation of an intelligent trading agent based on continuous deep reinforcement learning that also controls a large language model with which it can post to a social media feed observed by other traders. We empirically investigate the performance and impact of such an agent in a simulated financial market, finding that it learns to optimize its total reward, and thereby augment its profit, by manipulating the sentiment of the posts it produces. The paper concludes with discussion, limitations, and suggestions for future work.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Does Your AI Agent Get You? A Personalizable Framework for Approximating Human Models from Argumentation-based Dialogue Traces</title>
<link>https://arxiv.org/abs/2502.16376</link>
<guid>https://arxiv.org/abs/2502.16376</guid>
<content:encoded><![CDATA[
<div> 关键词：Explainable AI、argumentation methods、human user models、Persona、prospect theory

总结:
本文介绍了一个人工智能框架——Persona，该框架致力于通过基于论证的对话方式使AI代理能够动态学习和更新对人类用户的理解。Persona结合了前景理论与概率权重函数以及贝叶斯信念更新机制，根据交互中的论点交换来细化可能的人类模型的概率分布。通过对实际论证场景中的人类用户进行实证评估，研究显示Persona能有效地捕获人类信念的演变，促进个性化的互动，并优于现有的先进方法。<br /><br /> <div>
arXiv:2502.16376v1 Announce Type: new 
Abstract: Explainable AI is increasingly employing argumentation methods to facilitate interactive explanations between AI agents and human users. While existing approaches typically rely on predetermined human user models, there remains a critical gap in dynamically learning and updating these models during interactions. In this paper, we present a framework that enables AI agents to adapt their understanding of human users through argumentation-based dialogues. Our approach, called Persona, draws on prospect theory and integrates a probability weighting function with a Bayesian belief update mechanism that refines a probability distribution over possible human models based on exchanged arguments. Through empirical evaluations with human users in an applied argumentation setting, we demonstrate that Persona effectively captures evolving human beliefs, facilitates personalized interactions, and outperforms state-of-the-art methods.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Facilitating Emergency Vehicle Passage in Congested Urban Areas Using Multi-agent Deep Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16449</link>
<guid>https://arxiv.org/abs/2502.16449</guid>
<content:encoded><![CDATA[
<div> 关键词: Emergency Response Time, EMVLight, 多智能体强化学习, 动态队列跳转车道系统, 城市公平性

总结:<br />
本文探讨了紧急响应时间(ERT)对于城市安全的重要性，并指出纽约市医疗ERT在十年间增加了72%。论文通过三个方面提升了应急车辆(EMV)的通行效率和应急服务公平性：1)提出了一种名为EMVLight的分散式多智能体强化学习框架，将EMV路由与交通信号优先权相结合，使EMV旅行时间缩短了42.6%，同时提高了其他车辆的通行效率；2)利用多智能体近似策略优化实现了动态队列跳转车道系统，减少了EMV旅行时间达40%；3)针对纽约市医疗服务的公平性进行了研究，揭示了不同行政区之间的差异，提出了包括优化EMS站点布局和改善交叉口设计在内的解决方案，以缓解如斯塔滕岛因稀疏信号化路口导致的延误及曼哈顿的拥堵问题。这些贡献为政策制定者和城市规划者提供了提升交通安全和效率的新思路。 <div>
arXiv:2502.16449v1 Announce Type: new 
Abstract: Emergency Response Time (ERT) is crucial for urban safety, measuring cities' ability to handle medical, fire, and crime emergencies. In NYC, medical ERT increased 72% from 7.89 minutes in 2014 to 14.27 minutes in 2024, with half of delays due to Emergency Vehicle (EMV) travel times. Each minute's delay in stroke response costs 2 million brain cells, while cardiac arrest survival drops 7-10% per minute.
  This dissertation advances EMV facilitation through three contributions. First, EMVLight, a decentralized multi-agent reinforcement learning framework, integrates EMV routing with traffic signal pre-emption. It achieved 42.6% faster EMV travel times and 23.5% improvement for other vehicles.
  Second, the Dynamic Queue-Jump Lane system uses Multi-Agent Proximal Policy Optimization for coordinated lane-clearing in mixed autonomous and human-driven traffic, reducing EMV travel times by 40%.
  Third, an equity study of NYC Emergency Medical Services revealed disparities across boroughs: Staten Island faces delays due to sparse signalized intersections, while Manhattan struggles with congestion. Solutions include optimized EMS stations and improved intersection designs.
  These contributions enhance EMV mobility and emergency service equity, offering insights for policymakers and urban planners to develop safer, more efficient transportation systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Contemporary Survey on Semantic Communications:Theory of Mind, Generative AI, and Deep Joint Source-Channel Coding</title>
<link>https://arxiv.org/abs/2502.16468</link>
<guid>https://arxiv.org/abs/2502.16468</guid>
<content:encoded><![CDATA[
<div> 关键词：Semantic Communication、标准化、Theory of Mind、Generative AI、Deep Joint Source-Channel Coding

<br /><br />总结:
本文是对语义通信领域的一篇综述，重点关注了该技术面临的标准化挑战以及三个主要研究方向。首先介绍了理论思维（Theory of Mind）方向，强调通信代理通过观察互动，形成共同语言的理解过程；其次讨论了生成式AI模型，这种模型能够创造新内容并突破原始数据语义压缩限制，实现更自由的数据解释和任务执行；再者，概述了深度学习在联合源信道编码优化方面的应用。文章还对每个方向的现有工作进行了全面回顾，并指出了各方向在实际部署前需要解决的关键挑战。 <div>
arXiv:2502.16468v1 Announce Type: new 
Abstract: Semantic Communication is becoming the next pillar in wireless communication technology due to its various capabilities. However, it still encounters various challenging obstacles that need to be solved before real-world deployment. The major challenge is the lack of standardization across different directions, leading to variations in interpretations and objectives. In the survey, we provide detailed explanations of three leading directions in semantic communications, namely Theory of Mind, Generative AI, Deep Joint Source-Channel Coding. These directions have been widely studied, developed, and verified by institutes worldwide, and their effectiveness has increased along with the advancement in technology. We first introduce the concepts and background of these directions. Firstly, we introduce the Theory of Mind, where the communication agents interact with each other, gaining understanding from observations and slowly forming a common language. Secondly, we present generative AI models, which can create new content and offer more freedom to interpret the data beyond the limitation of semantic meaning compression of raw data before transmitting it. The received signal is then decoded by another generative AI model to execute the oriented task. Thirdly, we review deep learning models to jointly optimize the source and channel coding modules. Then, we present a comprehensive survey of existing works in each direction, thereby offering readers an overview of past achievements and potential avenues for further contribution. Moreover, for each direction, we identify and discuss the existing challenges that must be addressed before these approaches can be effectively deployed in real-world scenarios.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>All That Glitters is Not Novel: Plagiarism in AI Generated Research</title>
<link>https://arxiv.org/abs/2502.16487</link>
<guid>https://arxiv.org/abs/2502.16487</guid>
<content:encoded><![CDATA[
<div> 关键词: 自动化科研、LLM、剽窃、专家评估、自动剽窃检测器

<br /><br />总结:
本文关注了一个重要问题：近期部分自称能生成新颖研究想法的自主研究代理系统所产出的研究文档存在大量巧妙抄袭现象。通过对50篇由LLM生成的研究文档进行专家评估，发现其中24%的内容要么是对已有方法的一对一改写，要么明显借鉴了现有工作，并未对原始来源进行引用，甚至规避了常规的抄袭检测器。此外，实验表明现有的自动化剽窃检测器难以有效识别LLM刻意抄袭产生的内容。因此，文章呼吁对LLM生成的研究成果进行谨慎评估，并讨论了这一发现对科研和学术出版的影响。 <div>
arXiv:2502.16487v1 Announce Type: new 
Abstract: Automating scientific research is considered the final frontier of science. Recently, several papers claim autonomous research agents can generate novel research ideas. Amidst the prevailing optimism, we document a critical concern: a considerable fraction of such research documents are smartly plagiarized. Unlike past efforts where experts evaluate the novelty and feasibility of research ideas, we request $13$ experts to operate under a different situational logic: to identify similarities between LLM-generated research documents and existing work. Concerningly, the experts identify $24\%$ of the $50$ evaluated research documents to be either paraphrased (with one-to-one methodological mapping), or significantly borrowed from existing work. These reported instances are cross-verified by authors of the source papers. Problematically, these LLM-generated research documents do not acknowledge original sources, and bypass inbuilt plagiarism detectors. Lastly, through controlled experiments we show that automated plagiarism detectors are inadequate at catching deliberately plagiarized ideas from an LLM. We recommend a careful assessment of LLM-generated research, and discuss the implications of our findings on research and academic publishing.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>PMAT: Optimizing Action Generation Order in Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.16496</link>
<guid>https://arxiv.org/abs/2502.16496</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体强化学习（MARL）、并行决策、序列决策、行动生成与普拉克特-卢斯采样（AGPS）、优先级多智能体变压器（PMAT）

总结:
本文提出了一种针对多智能体强化学习（MARL）中协调效率低下的问题的新方法。研究关注于解决并行决策范式下忽略的代理间动作层面的依赖性。为此，文章引入了Action Generation with Plackett-Luce Sampling (AGPS)机制，这是一种用于优化代理决策顺序的新方法，它通过将决策顺序确定任务建模为普拉克特-卢斯采样过程来解决训练过程中排名不稳定性及梯度消失的问题。AGPS通过建立本地观察重要性和决策信用之间的联系，实现基于信用的决策顺序确定。结合Multi-Agent Transformer，作者提出了具有决策顺序优化功能的序列决策制定MARL算法——Prioritized Multi-Agent Transformer (PMAT)。实验结果表明，PMAT在包括StarCraft II Multi-Agent Challenge、Google Research Football和Multi-Agent MuJoCo等多个基准测试上超越了现有的最优算法，显著提高了协调效率。 <div>
arXiv:2502.16496v1 Announce Type: new 
Abstract: Multi-agent reinforcement learning (MARL) faces challenges in coordinating agents due to complex interdependencies within multi-agent systems. Most MARL algorithms use the simultaneous decision-making paradigm but ignore the action-level dependencies among agents, which reduces coordination efficiency. In contrast, the sequential decision-making paradigm provides finer-grained supervision for agent decision order, presenting the potential for handling dependencies via better decision order management. However, determining the optimal decision order remains a challenge. In this paper, we introduce Action Generation with Plackett-Luce Sampling (AGPS), a novel mechanism for agent decision order optimization. We model the order determination task as a Plackett-Luce sampling process to address issues such as ranking instability and vanishing gradient during the network training process. AGPS realizes credit-based decision order determination by establishing a bridge between the significance of agents' local observations and their decision credits, thus facilitating order optimization and dependency management. Integrating AGPS with the Multi-Agent Transformer, we propose the Prioritized Multi-Agent Transformer (PMAT), a sequential decision-making MARL algorithm with decision order optimization. Experiments on benchmarks including StarCraft II Multi-Agent Challenge, Google Research Football, and Multi-Agent MuJoCo show that PMAT outperforms state-of-the-art algorithms, greatly enhancing coordination efficiency.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Efficient Coordination and Synchronization of Multi-Robot Systems Under Recurring Linear Temporal Logic</title>
<link>https://arxiv.org/abs/2502.16531</link>
<guid>https://arxiv.org/abs/2502.16531</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-robot systems、linear temporal logic (LTL) specifications、plan synthesis、online coordination、synchronization mechanism

<br /><br />总结:
本文研究了具有线性时空逻辑(LTL)规范的多机器人系统执行重复任务的问题。为了解决规划问题并提高效率，提出了一种结合离线计划综合与在线协调的自底向上的方法，通过实时通信动态调整计划。针对动作延迟问题，文章引入了一个同步机制以确保协调的任务执行，进而构建了一个适应多种多机器人应用的多代理协调和同步框架。该软件包采用Python和ROS2开发，便于广泛部署。实验通过九台机器人的实验室验证，表明相较于传统方法，本方法具备更高的适应性。同时，通过高达九十台代理的模拟实验展示了提出的方案在计算复杂度降低和可扩展性方面的特点。 <div>
arXiv:2502.16531v1 Announce Type: new 
Abstract: We consider multi-robot systems under recurring tasks formalized as linear temporal logic (LTL) specifications. To solve the planning problem efficiently, we propose a bottom-up approach combining offline plan synthesis with online coordination, dynamically adjusting plans via real-time communication. To address action delays, we introduce a synchronization mechanism ensuring coordinated task execution, leading to a multi-agent coordination and synchronization framework that is adaptable to a wide range of multi-robot applications. The software package is developed in Python and ROS2 for broad deployment. We validate our findings through lab experiments involving nine robots showing enhanced adaptability compared to previous methods. Additionally, we conduct simulations with up to ninety agents to demonstrate the reduced computational complexity and the scalability features of our work.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Spatial Disease Propagation With Hubs</title>
<link>https://arxiv.org/abs/2502.16552</link>
<guid>https://arxiv.org/abs/2502.16552</guid>
<content:encoded><![CDATA[
<div> 关键词：传染疾病传播、接触模型、随机空间点过程、随机双部分图、连接函数

<br /><br />总结:
本文研究了通过空气传播的传染疾病如何在依赖物理接触或接近的环境中扩散。文章使用随机空间点过程来模拟个体（代理人）和共同目的地（枢纽）的位置，并重点关注通过访问枢纽进行的疾病传播。通过一个连接函数$f$描述个体访问枢纽的概率，以此构建了一个随机双部分几何图（RBG）。作者探讨了对于一般连接函数下RBG图的度数和-percolation现象，并证明了影响枢纽网络发生质变（即-percolation阈值）的关键密度是由连接函数$f$的支持集决定的，这揭示了长距离旅行（或对其限制）在疾病传播中的重要作用。 <div>
arXiv:2502.16552v1 Announce Type: new 
Abstract: Physical contact or proximity is often a necessary condition for the spread of infectious diseases. Common destinations, typically referred to as hubs or points of interest, are arguably the most effective spots for the type of disease spread via airborne transmission. In this work, we model the locations of individuals (agents) and common destinations (hubs) by random spatial point processes in $\mathbb{R}^d$ and focus on disease propagation through agents visiting common hubs. The probability of an agent visiting a hub depends on their distance through a connection function $f$. The system is represented by a random bipartite geometric (RBG) graph. We study the degrees and percolation of the RBG graph for general connection functions. We show that the critical density of hubs for percolation is dictated by the support of the connection function $f$, which reveals the critical role of long-distance travel (or its restrictions) in disease spreading.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>The Hidden Strength of Disagreement: Unraveling the Consensus-Diversity Tradeoff in Adaptive Multi-Agent Systems</title>
<link>https://arxiv.org/abs/2502.16565</link>
<guid>https://arxiv.org/abs/2502.16565</guid>
<content:encoded><![CDATA[
<div> 关键词：共识形成、多智能体系统、隐性协调、显性协调、适应性

总结:
该文探讨了在多智能体系统（MAS）中，如何平衡集体一致性与个体多样性的问题。相较于传统基于LLM的MAS依赖于明确的协调机制（如提示或投票），文章提出隐性的共识形成方法——通过信息交换和上下文学习独立决策，可能更适用于需要长期适应性的动态环境，因为它能更好地保持部分多样性并探索新颖策略，增强对外部冲击的应对能力。文中形式化定义了一种共识与多样性之间的权衡，并证明在某些条件下，隐性方法优于显性方法。实验在三个场景（动态灾害响应、信息传播与操纵以及动态公共物品提供）中验证了偏离群体规范的部分多样性可以促进探索、提高韧性和性能。文章强调了通过上下文学习产生的自发协调现象，并指出为了实现有韧性的决策，应重视维持多样性的重要性。 <div>
arXiv:2502.16565v1 Announce Type: new 
Abstract: Consensus formation is pivotal in multi-agent systems (MAS), balancing collective coherence with individual diversity. Conventional LLM-based MAS primarily rely on explicit coordination, e.g., prompts or voting, risking premature homogenization. We argue that implicit consensus, where agents exchange information yet independently form decisions via in-context learning, can be more effective in dynamic environments that require long-horizon adaptability. By retaining partial diversity, systems can better explore novel strategies and cope with external shocks. We formalize a consensus-diversity tradeoff, showing conditions where implicit methods outperform explicit ones. Experiments on three scenarios -- Dynamic Disaster Response, Information Spread and Manipulation, and Dynamic Public-Goods Provision -- confirm partial deviation from group norms boosts exploration, robustness, and performance. We highlight emergent coordination via in-context learning, underscoring the value of preserving diversity for resilient decision-making.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Co-MTP: A Cooperative Trajectory Prediction Framework with Multi-Temporal Fusion for Autonomous Driving</title>
<link>https://arxiv.org/abs/2502.16589</link>
<guid>https://arxiv.org/abs/2502.16589</guid>
<content:encoded><![CDATA[
<div> 关键词：Vehicle-to-everything (V2X)，Cooperative perception，Trajectory prediction，Multi-temporal fusion，Autonomous driving

总结:
本文介绍了针对自动驾驶的Co-MTP框架，该框架是一种利用V2X技术进行多时间融合的协同轨迹预测方法。文章指出现有的合作感知研究主要关注单帧合作感知，而如何利用V2X捕捉帧间的时间线索以辅助预测和规划任务尚待探索。Co-MTP框架在历史域中，通过V2X补充单辆车辆感知中的不完整历史轨迹，并采用异构图变换器学习多个代理之间的历史特征融合与交互。在未来域中，V2X可提供周围物体的预测结果，进一步扩展了图变换器，用于捕获自我规划与其他车辆意图之间的未来交互，从而根据特定规划动作获取最终的未来场景状态。在真实世界数据集V2X-Seq上评估Co-MTP框架后，结果显示其表现出最先进的性能，同时证明历史和未来的融合均能显著提升预测效果。 <div>
arXiv:2502.16589v1 Announce Type: new 
Abstract: Vehicle-to-everything technologies (V2X) have become an ideal paradigm to extend the perception range and see through the occlusion. Exiting efforts focus on single-frame cooperative perception, however, how to capture the temporal cue between frames with V2X to facilitate the prediction task even the planning task is still underexplored. In this paper, we introduce the Co-MTP, a general cooperative trajectory prediction framework with multi-temporal fusion for autonomous driving, which leverages the V2X system to fully capture the interaction among agents in both history and future domains to benefit the planning. In the history domain, V2X can complement the incomplete history trajectory in single-vehicle perception, and we design a heterogeneous graph transformer to learn the fusion of the history feature from multiple agents and capture the history interaction. Moreover, the goal of prediction is to support future planning. Thus, in the future domain, V2X can provide the prediction results of surrounding objects, and we further extend the graph transformer to capture the future interaction among the ego planning and the other vehicles' intentions and obtain the final future scenario state under a certain planning action. We evaluate the Co-MTP framework on the real-world dataset V2X-Seq, and the results show that Co-MTP achieves state-of-the-art performance and that both history and future fusion can greatly benefit prediction.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward Dependency Dynamics in Multi-Agent Reinforcement Learning for Traffic Signal Control</title>
<link>https://arxiv.org/abs/2502.16608</link>
<guid>https://arxiv.org/abs/2502.16608</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习（RL）、自适应交通信号控制（ATSC）、多智能体强化学习（MARL）、独立强化学习（IRL）、深度Q网络（DQN-DPUS）

总结:
本文探讨了在复杂城市交通网络中，强化学习（RL）作为自适应交通信号控制（ATSC）的一种有前途的数据驱动方法，其中深度神经网络极大地增强了其学习能力。然而，对于涉及多个智能体的ATSC任务，集中式RL由于联合动作空间维度过高而变得不切实际。多智能体RL（MARL）通过将控制权分散到局部RL代理来缓解这一可扩展性问题，但同时也带来了新的挑战，即每个局部代理只能观察到部分环境，因为交叉通信受到限制。文章指出，当无溢流拥堵（无代理间依赖）时，MARL可以通过将问题分解为多个独立强化学习过程来达到全局最优Q值；而在存在溢流拥堵（有代理间依赖）的情况下，则需采用集中式RL以实现最大全球Q值。基于以上结论，文章提出了一种新型动态参数更新策略——深度Q网络-动态参数更新策略（DQN-DPUS），该策略根据智能体之间的依赖动态来更新权重和偏置，即在没有溢流拥堵的情况下仅更新对角子矩阵。实验证明，DQN-DPUS在具有两个交叉口的简单网络下，可在不同交通流量条件下加速收敛速率，同时不影响最优探索性能。实验结果证实了理论发现的有效性，显示了DQN-DPUS在优化交通信号控制方面的优越性。 <div>
arXiv:2502.16608v1 Announce Type: new 
Abstract: Reinforcement learning (RL) emerges as a promising data-driven approach for adaptive traffic signal control (ATSC) in complex urban traffic networks, with deep neural networks substantially augmenting its learning capabilities. However, centralized RL becomes impractical for ATSC involving multiple agents due to the exceedingly high dimensionality of the joint action space. Multi-agent RL (MARL) mitigates this scalability issue by decentralizing control to local RL agents. Nevertheless, this decentralized method introduces new challenges: the environment becomes partially observable from the perspective of each local agent due to constrained inter-agent communication. Both centralized RL and MARL exhibit distinct strengths and weaknesses, particularly under heavy intersectional traffic conditions. In this paper, we justify that MARL can achieve the optimal global Q-value by separating into multiple IRL (Independent Reinforcement Learning) processes when no spill-back congestion occurs (no agent dependency) among agents (intersections). In the presence of spill-back congestion (with agent dependency), the maximum global Q-value can be achieved by using centralized RL. Building upon the conclusions, we propose a novel Dynamic Parameter Update Strategy for Deep Q-Network (DQN-DPUS), which updates the weights and bias based on the dependency dynamics among agents, i.e. updating only the diagonal sub-matrices for the scenario without spill-back congestion. We validate the DQN-DPUS in a simple network with two intersections under varying traffic, and show that the proposed strategy can speed up the convergence rate without sacrificing optimal exploration. The results corroborate our theoretical findings, demonstrating the efficacy of DQN-DPUS in optimizing traffic signal control.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Equilibrium Unit Based Localized Affine Formation Maneuver for Multi-agent Systems</title>
<link>https://arxiv.org/abs/2502.16653</link>
<guid>https://arxiv.org/abs/2502.16653</guid>
<content:encoded><![CDATA[
<div> 关键词: 多智能体系统(MASs), 仿射定位性, 平衡单元, 分布式构建方法, 局部感知控制协议

总结:<br />
本文提出了一种基于平衡单元的多智能体系统(MASs)仿射定位性实现结构。该平衡单元能保证节点间非零权重的存在及其和为非零，消除了对名义配置的通用假设。为去除全局构造方式，文章引入了层状有向图的概念，并给出了与之关联的仿射定位性充分条件。在此框架下，设计了一种均衡单元构造(EUC)的分布式局部构建方法。结合局部通信准则(LCC)和基于局部感知的仿射阵型操纵控制(LSAFMC)协议，使得MASs在节点加入或移除时具有自我重构能力。 <div>
arXiv:2502.16653v1 Announce Type: new 
Abstract: Current affine formation maneuver of multi-agent systems (MASs) relys on the affine localizability determined by generic assumption for nominal configuration and global construction manner. This does not live up to practical constraints of robot swarms. In this paper, an equilibrium unit based structure is proposed to achieve affine localizability. In an equilibrium unit, existence of non-zero weights between nodes is guaranteed and their summation is proved to be non-zero. To remove the generic assumption, a notion of layerable directed graph is introduced, based on which a sufficient condition associated equilibrium unit is presented to establish affine localizability condition. Within this framework, distributed local construction manner is performed by a designed equilibrium unit construction (EUC) method. With the help of localized communication criterion (LCC) and localized sensing based affine formation maneuver control (LSAFMC) protocol, self-reconstruction capability is possessed by MASs when nodes are added to or removed from the swarms.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</title>
<link>https://arxiv.org/abs/2502.16660</link>
<guid>https://arxiv.org/abs/2502.16660</guid>
<content:encoded><![CDATA[
<div> 关键词：大型语言模型、路径推理、BioMaze、PathSeeker、交互式子图导航

总结:
本文探讨了大型语言模型（LLMs）在复杂生物系统如途径推理中的应用潜力。为评估LLMs在此领域的表现，研究者构建了一个名为BioMaze的全新数据集，其中包含了5.1K个源于实际研究的复杂生物通路问题，涉及多种生物上下文场景。实验结果显示，LLMs在处理扰动系统的路径推理方面存在困难。针对此问题，文章提出了PathSeeker，这是一个基于交互式子图导航的LLM代理模型，旨在以科学对齐的方式更有效地处理生物系统的复杂性。相关数据集和代码已在https://github.com/zhao-ht/BioMaze上开源发布。 <div>
arXiv:2502.16660v1 Announce Type: new 
Abstract: The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Saarthi: The First AI Formal Verification Engineer</title>
<link>https://arxiv.org/abs/2502.16662</link>
<guid>https://arxiv.org/abs/2502.16662</guid>
<content:encoded><![CDATA[
<div> 关键词: AI、自主、形式验证工程师、Saarthi、RTL设计

总结:
本文介绍了世界上首个完全自主的人工智能形式验证工程师——Saarthi。Saarthi利用生成式AI中的代理工作流概念，能够实现对给定RTL设计的端到端自主验证。这使得硬件验证工程师可以更加专注于解决更复杂的难题，而验证团队也能追求更为宏大的目标。由于Saarthi的领域无关性实施方式，它具有可扩展性，可以在RTL设计、基于UVM的验证等多个领域应用。<br /><br /> <div>
arXiv:2502.16662v1 Announce Type: new 
Abstract: Recently, Devin has made a significant buzz in the Artificial Intelligence (AI) community as the world's first fully autonomous AI software engineer, capable of independently developing software code. Devin uses the concept of agentic workflow in Generative AI (GenAI), which empowers AI agents to engage in a more dynamic, iterative, and self-reflective process. In this paper, we present a similar fully autonomous AI formal verification engineer, Saarthi, capable of verifying a given RTL design end-to-end using an agentic workflow. With Saarthi, verification engineers can focus on more complex problems, and verification teams can strive for more ambitious goals. The domain-agnostic implementation of Saarthi makes it scalable for use across various domains such as RTL design, UVM-based verification, and others.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>From Text to Space: Mapping Abstract Spatial Models in LLMs during a Grid-World Navigation Task</title>
<link>https://arxiv.org/abs/2502.16690</link>
<guid>https://arxiv.org/abs/2502.16690</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、空间信息表示、决策制定、笛卡尔坐标系、内部激活<br /><br />总结:
本文研究了大型语言模型（LLMs）如何处理和推理空间信息，并通过在网格世界导航任务中对比不同文本空间表示对LLM性能和内部激活的影响。实验表明，使用笛卡尔坐标系的空间表示方法能持续获得更高的成功率和路径效率，且随着模型规模增大，其表现明显提升。此外，通过对LLaMA-3.1-8B进行探查，发现模型中间层存在一些内部单元，它们与空间特征（如：代理人在网格中的位置或动作正确性）有稳健的相关性，且这些单元在处理不相关的空间推理任务时也会被激活。这项工作深化了我们对LLMs处理空间信息的理解，并为构建更可解释和健壮的智能代理系统提供了有价值的见解。 <div>
arXiv:2502.16690v1 Announce Type: new 
Abstract: Understanding how large language models (LLMs) represent and reason about spatial information is crucial for building robust agentic systems that can navigate real and simulated environments. In this work, we investigate the influence of different text-based spatial representations on LLM performance and internal activations in a grid-world navigation task. By evaluating models of various sizes on a task that requires navigating toward a goal, we examine how the format used to encode spatial information impacts decision-making. Our experiments reveal that cartesian representations of space consistently yield higher success rates and path efficiency, with performance scaling markedly with model size. Moreover, probing LLaMA-3.1-8B revealed subsets of internal units, primarily located in intermediate layers, that robustly correlate with spatial features, such as the position of the agent in the grid or action correctness, regardless of how that information is represented, and are also activated by unrelated spatial reasoning tasks. This work advances our understanding of how LLMs process spatial information and provides valuable insights for developing more interpretable and robust agentic AI systems.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Towards Optimal Adversarial Robust Reinforcement Learning with Infinity Measurement Error</title>
<link>https://arxiv.org/abs/2502.16734</link>
<guid>https://arxiv.org/abs/2502.16734</guid>
<content:encoded><![CDATA[
<div> 关键词：深度强化学习(DRL)、对抗性攻击、内在状态对抗性马尔可夫决策过程(ISA-MDP)、最优鲁棒策略(ORP)、一致对抗鲁棒强化学习(CAR-RL)

总结:
本文探讨了确保深度强化学习(DRL)代理对对抗性攻击的鲁棒性的重要性。研究提出了内在状态对抗性马尔可夫决策过程(ISA-MDP)的新概念，该框架下，敌人无法从根本上改变状态观测的本质。理论证明在ISA-MDP中存在确定性和稳态的ORP，并与贝尔曼最优策略相吻合，揭示提高DRL鲁棒性不一定牺牲自然环境下的性能。文章还指出，以前依赖于1度量误差的DRL算法存在脆弱性，实现ORP需要无穷度量误差(IME)。为此，文章提出了一致对抗鲁棒强化学习(CAR-RL)框架，通过优化IME的近似值进行优化，并将其应用于价值基础和策略基础的DRL算法上，实验结果验证了理论分析并取得了优越性能。 <div>
arXiv:2502.16734v1 Announce Type: new 
Abstract: Ensuring the robustness of deep reinforcement learning (DRL) agents against adversarial attacks is critical for their trustworthy deployment. Recent research highlights the challenges of achieving state-adversarial robustness and suggests that an optimal robust policy (ORP) does not always exist, complicating the enforcement of strict robustness constraints. In this paper, we further explore the concept of ORP. We first introduce the Intrinsic State-adversarial Markov Decision Process (ISA-MDP), a novel formulation where adversaries cannot fundamentally alter the intrinsic nature of state observations. ISA-MDP, supported by empirical and theoretical evidence, universally characterizes decision-making under state-adversarial paradigms. We rigorously prove that within ISA-MDP, a deterministic and stationary ORP exists, aligning with the Bellman optimal policy. Our findings theoretically reveal that improving DRL robustness does not necessarily compromise performance in natural environments. Furthermore, we demonstrate the necessity of infinity measurement error (IME) in both $Q$-function and probability spaces to achieve ORP, unveiling vulnerabilities of previous DRL algorithms that rely on $1$-measurement errors. Motivated by these insights, we develop the Consistent Adversarial Robust Reinforcement Learning (CAR-RL) framework, which optimizes surrogates of IME. We apply CAR-RL to both value-based and policy-based DRL algorithms, achieving superior performance and validating our theoretical analysis.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Guardians of the Agentic System: Preventing Many Shots Jailbreak with Agentic System</title>
<link>https://arxiv.org/abs/2502.16750</link>
<guid>https://arxiv.org/abs/2502.16750</guid>
<content:encoded><![CDATA[
<div> 关键词: 自主AI代理、大型语言模型、安全威胁、防御方案、反狱破系统

总结:
本文关注的是自主AI代理使用大型语言模型所面临的不可忽视的安全威胁问题。现有的静态防护措施对于多模态高级攻击（如多轮越狱和欺骗性对齐）无法有效抵御。研究指出，急需开发新的评估框架来识别并对抗这些威胁，确保安全部署。文章提出的方法包括通过逆向图灵测试检测恶意代理、利用多智能体模拟分析欺骗性对齐，并设计了一种反狱破系统，通过工具介导的对抗性场景测试了GEMINI 1.5 pro和llama-3.3-70B、deepseek r1等模型。虽然检测准确率高达94%，但当攻击提示长度增加时，系统的脆弱性显现，攻击成功率提高，多样性指标预测失效，暴露出多个复杂系统故障。因此，论文强调了采用基于主动监控的灵活安全系统的重要性，需要由代理自身与系统管理员适应性干预相结合，以应对当前模型可能产生的安全隐患。最终，作者提出一套全面的框架来解决这些问题。 <div>
arXiv:2502.16750v1 Announce Type: new 
Abstract: The autonomous AI agents using large language models can create undeniable values in all span of the society but they face security threats from adversaries that warrants immediate protective solutions because trust and safety issues arise. Considering the many-shot jailbreaking and deceptive alignment as some of the main advanced attacks, that cannot be mitigated by the static guardrails used during the supervised training, points out a crucial research priority for real world robustness. The combination of static guardrails in dynamic multi-agent system fails to defend against those attacks. We intend to enhance security for LLM-based agents through the development of new evaluation frameworks which identify and counter threats for safe operational deployment. Our work uses three examination methods to detect rogue agents through a Reverse Turing Test and analyze deceptive alignment through multi-agent simulations and develops an anti-jailbreaking system by testing it with GEMINI 1.5 pro and llama-3.3-70B, deepseek r1 models using tool-mediated adversarial scenarios. The detection capabilities are strong such as 94\% accuracy for GEMINI 1.5 pro yet the system suffers persistent vulnerabilities when under long attacks as prompt length increases attack success rates (ASR) and diversity metrics become ineffective in prediction while revealing multiple complex system faults. The findings demonstrate the necessity of adopting flexible security systems based on active monitoring that can be performed by the agents themselves together with adaptable interventions by system admin as the current models can create vulnerabilities that can lead to the unreliable and vulnerable system. So, in our work, we try to address such situations and propose a comprehensive framework to counteract the security issues.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Model-Based Exploration in Monitored Markov Decision Processes</title>
<link>https://arxiv.org/abs/2502.16772</link>
<guid>https://arxiv.org/abs/2502.16772</guid>
<content:encoded><![CDATA[
<div> 关键词：强化学习、奖励缺失、监控马尔科夫决策过程（Mon-MDP）、模型基算法、有限样本界

总结:<br />
本文针对奖励不总是可观察到的强化学习问题，提出了一个针对监控马尔科夫决策过程（Mon-MDP）的模型基算法。该算法利用两种模型基区间估计方法，确保可观测奖励的有效观测并学习最优策略。实验结果显示，新算法在超过二十多个基准场景下相比于前序算法展现出更快的收敛速度，尤其在已知监控进程的情况下有显著提升。此外，文章还首次给出了性能的有限样本界，并证明了当某些奖励不可观测时，算法能收敛至最优的最坏情况策略。 <div>
arXiv:2502.16772v1 Announce Type: new 
Abstract: A tenet of reinforcement learning is that rewards are always observed by the agent. However, this is not true in many realistic settings, e.g., a human observer may not always be able to provide rewards, a sensor to observe rewards may be limited or broken, or rewards may be unavailable during deployment. Monitored Markov decision processes (Mon-MDPs) have recently been proposed as a model of such settings. Yet, Mon-MDP algorithms developed thus far do not fully exploit the problem structure, cannot take advantage of a known monitor, have no worst-case guarantees for ``unsolvable'' Mon-MDPs without specific initialization, and only have asymptotic proofs of convergence. This paper makes three contributions. First, we introduce a model-based algorithm for Mon-MDPs that addresses all of these shortcomings. The algorithm uses two instances of model-based interval estimation, one to guarantee that observable rewards are indeed observed, and another to learn the optimal policy. Second, empirical results demonstrate these advantages, showing faster convergence than prior algorithms in over two dozen benchmark settings, and even more dramatic improvements when the monitor process is known. Third, we present the first finite-sample bound on performance and show convergence to an optimal worst-case policy when some rewards are never observable.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>AlphaAgent: LLM-Driven Alpha Mining with Regularized Exploration to Counteract Alpha Decay</title>
<link>https://arxiv.org/abs/2502.16789</link>
<guid>https://arxiv.org/abs/2502.16789</guid>
<content:encoded><![CDATA[
<div> 关键词: 阿尔法挖掘、alpha衰减、遗传编程、大型语言模型、AlphaAgent

<br /><br />总结:
本文提出了一个名为AlphaAgent的自主框架，旨在解决金融领域的阿尔法挖掘中面临的alpha衰减问题。传统方法如遗传编程易受过拟合和复杂性影响导致alpha衰减，而依赖大型语言模型的方法则可能产生同质化因子加剧衰减。AlphaAgent通过三个方面来生成具有抗衰减能力的alpha因素：(1)利用抽象语法树相似度度量确保生成因素与现有alpha的原创性；(2)通过LLM评估市场假设与生成因素之间的语义一致性，实现假说-因素对齐；(3)采用基于AST的结构约束控制复杂性，防止过度拟合。这些机制共同引导alpha生成过程，在保持原创性、财务合理性的同时，适应不断变化的市场条件，从而有效缓解alpha衰减风险。实验表明，AlphaAgent在中美股票市场上相较于传统和基于LLM的方法更能有效地减轻alpha衰减现象，并在过去四年中持续产生了显著的超额收益。尤其值得一提的是，AlphaAgent展现出对alpha衰减的强大抵抗力，为发掘有影响力的因子提供了新途径。 <div>
arXiv:2502.16789v1 Announce Type: new 
Abstract: Alpha mining, a critical component in quantitative investment, focuses on discovering predictive signals for future asset returns in increasingly complex financial markets. However, the pervasive issue of alpha decay, where factors lose their predictive power over time, poses a significant challenge for alpha mining. Traditional methods like genetic programming face rapid alpha decay from overfitting and complexity, while approaches driven by Large Language Models (LLMs), despite their promise, often rely too heavily on existing knowledge, creating homogeneous factors that worsen crowding and accelerate decay. To address this challenge, we propose AlphaAgent, an autonomous framework that effectively integrates LLM agents with ad hoc regularizations for mining decay-resistant alpha factors. AlphaAgent employs three key mechanisms: (i) originality enforcement through a similarity measure based on abstract syntax trees (ASTs) against existing alphas, (ii) hypothesis-factor alignment via LLM-evaluated semantic consistency between market hypotheses and generated factors, and (iii) complexity control via AST-based structural constraints, preventing over-engineered constructions that are prone to overfitting. These mechanisms collectively guide the alpha generation process to balance originality, financial rationale, and adaptability to evolving market conditions, mitigating the risk of alpha decay. Extensive evaluations show that AlphaAgent outperforms traditional and LLM-based methods in mitigating alpha decay across bull and bear markets, consistently delivering significant alpha in Chinese CSI 500 and US S&amp;P 500 markets over the past four years. Notably, AlphaAgent showcases remarkable resistance to alpha decay, elevating the potential for yielding powerful factors.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MobileSteward: Integrating Multiple App-Oriented Agents with Self-Evolution to Automate Cross-App Instructions</title>
<link>https://arxiv.org/abs/2502.16796</link>
<guid>https://arxiv.org/abs/2502.16796</guid>
<content:encoded><![CDATA[
<div> 关键词：MobileSteward、跨app指令、多智能体框架、任务自动化、Memory-based 自我进化

总结:
本文提出了一种名为MobileSteward的自我进化的多智能体框架，用于解决移动设备上的跨app指令执行问题。MobileSteward由协调中心的StewardAgent和多个针对特定应用的StaffAgents组成，旨在应对复杂任务关系、多样化应用环境以及多步骤执行中的错误传播与信息丢失挑战。该框架包括三个模块：动态招聘（Dynamic Recruitment）根据信息流生成调度图以关联不同应用的任务；指派执行（Assigned Execution）将任务分配给具有应用专业化技能的StaffAgents；调整评估（Adjusted Evaluation）通过提供反馈提示或关键信息来减轻多步骤执行中的错误传播和信息损失。为了不断优化MobileSteward的性能，文章还设计了一个基于记忆的自我进化机制，通过总结成功的执行经验来提升其表现。此外，文章创建了首个真实环境下的英文跨app基准测试集（CAPBench），实验结果显示MobileSteward相较于单智能体和多智能体框架，表现出更优秀的处理复杂跨app指令的能力。 <div>
arXiv:2502.16796v1 Announce Type: new 
Abstract: Mobile phone agents can assist people in automating daily tasks on their phones, which have emerged as a pivotal research spotlight. However, existing procedure-oriented agents struggle with cross-app instructions, due to the following challenges: (1) complex task relationships, (2) diverse app environment, and (3) error propagation and information loss in multi-step execution. Drawing inspiration from object-oriented programming principles, we recognize that object-oriented solutions is more suitable for cross-app instruction. To address these challenges, we propose a self-evolving multi-agent framework named MobileSteward, which integrates multiple app-oriented StaffAgents coordinated by a centralized StewardAgent. We design three specialized modules in MobileSteward: (1) Dynamic Recruitment generates a scheduling graph guided by information flow to explicitly associate tasks among apps. (2) Assigned Execution assigns the task to app-oriented StaffAgents, each equipped with app-specialized expertise to address the diversity between apps. (3) Adjusted Evaluation conducts evaluation to provide reflection tips or deliver key information, which alleviates error propagation and information loss during multi-step execution. To continuously improve the performance of MobileSteward, we develop a Memory-based Self-evolution mechanism, which summarizes the experience from successful execution, to improve the performance of MobileSteward. We establish the first English Cross-APP Benchmark (CAPBench) in the real-world environment to evaluate the agents' capabilities of solving complex cross-app instructions. Experimental results demonstrate that MobileSteward achieves the best performance compared to both single-agent and multi-agent frameworks, highlighting the superiority of MobileSteward in better handling user instructions with diverse complexity.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Multi-Agent Autonomous Driving Systems with Large Language Models: A Survey of Recent Advances</title>
<link>https://arxiv.org/abs/2502.16804</link>
<guid>https://arxiv.org/abs/2502.16804</guid>
<content:encoded><![CDATA[
<div> 关键词：Autonomous Driving Systems (ADSs)，Large Language Models (LLMs)，multi-agent ADSs，agent interaction modes，agent-human interactions

<br /><br />总结:
本文主要探讨了大型语言模型（LLMs）在自动驾驶系统（ADSs）中的应用及其面临的挑战，尤其是单代理系统存在的局限性。为解决这些问题，文章介绍了基于LLM的多代理ADSs的最新进展，这些进展着重于改进代理间的交互和合作。文章将现有LLM方法进行了根据不同交互模式的分类，并讨论了LLM基代理与人类交互的情景。此外，文中还总结了该领域的关键应用、数据集及挑战，为未来的研究提供了指导方向。 <div>
arXiv:2502.16804v1 Announce Type: new 
Abstract: Autonomous Driving Systems (ADSs) are revolutionizing transportation by reducing human intervention, improving operational efficiency, and enhancing safety. Large Language Models (LLMs), known for their exceptional planning and reasoning capabilities, have been integrated into ADSs to assist with driving decision-making. However, LLM-based single-agent ADSs face three major challenges: limited perception, insufficient collaboration, and high computational demands. To address these issues, recent advancements in LLM-based multi-agent ADSs have focused on improving inter-agent communication and cooperation. This paper provides a frontier survey of LLM-based multi-agent ADSs. We begin with a background introduction to related concepts, followed by a categorization of existing LLM-based approaches based on different agent interaction modes. We then discuss agent-human interactions in scenarios where LLM-based agents engage with humans. Finally, we summarize key applications, datasets, and challenges in this field to support future research (https://anonymous.4open.science/r/LLM-based_Multi-agent_ADS-3A5C/README.md).
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Grounded Persuasive Language Generation for Automated Marketing</title>
<link>https://arxiv.org/abs/2502.16810</link>
<guid>https://arxiv.org/abs/2502.16810</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型、营销内容生成、房地产描述、用户偏好、个性化模块

总结:
该文提出了一种采用大型语言模型（LLMs）的智能框架，用于自动生成具有说服力和事实依据的房地产营销内容。该框架包含三个关键模块：(1) 现实结合模块，模仿人类专家行为预测市场吸引人的特性；(2) 个性化模块，使内容与用户偏好相匹配；(3) 营销模块，确保内容的事实准确性和地域特色。通过针对潜在购房者开展系统的人类受试者实验，研究结果显示，该方法生成的房地产描述相较于人类专家编写的更受欢迎。这表明利用LLM为基础的智能框架可以实现大规模目标市场营销的自动化，并在确保仅使用事实进行负责任生成方面具有潜力。 <div>
arXiv:2502.16810v1 Announce Type: new 
Abstract: This paper develops an agentic framework that employs large language models (LLMs) to automate the generation of persuasive and grounded marketing content, using real estate listing descriptions as our focal application domain. Our method is designed to align the generated content with user preferences while highlighting useful factual attributes. This agent consists of three key modules: (1) Grounding Module, mimicking expert human behavior to predict marketable features; (2) Personalization Module, aligning content with user preferences; (3) Marketing Module, ensuring factual accuracy and the inclusion of localized features. We conduct systematic human-subject experiments in the domain of real estate marketing, with a focus group of potential house buyers. The results demonstrate that marketing descriptions generated by our approach are preferred over those written by human experts by a clear margin. Our findings suggest a promising LLM-based agentic framework to automate large-scale targeted marketing while ensuring responsible generation using only facts.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Leveraging Large Language Models for Effective and Explainable Multi-Agent Credit Assignment</title>
<link>https://arxiv.org/abs/2502.16863</link>
<guid>https://arxiv.org/abs/2502.16863</guid>
<content:encoded><![CDATA[
<div> 关键词: 机器人协作、强化学习、信用分配问题、大语言模型、LLM-MCA方法

总结:
本文探讨了在多智能体协作中如何有效地进行信用分配的问题，该问题在自主车辆协调和空间组装等场景中具有重要意义。研究者提出将信用分配转化为序列改进和归因两个模式识别问题，并利用大型语言模型（LLM）提出了新的LLM-MCA方法。这种方法通过中心化的LLM奖励批评机制，量化每个智能体对团队总收益的贡献并据此更新智能体的策略网络。同时，文章还提出了LLM-TACA扩展方法，让LLM批评器能够执行明确的任务分配，直接向每个智能体策略传递中间目标。实验结果显示，这两种方法在包括Level-Based Foraging、Robotic Warehouse以及新提出的包含碰撞安全约束的Spaceworld基准测试上都显著优于现有最佳方法。作为方法应用的副产品，他们生成了大量的轨迹数据集，其中每个时间步均附带有来自LLM批评器的针对每个智能体的奖励信息。 <div>
arXiv:2502.16863v1 Announce Type: new 
Abstract: Recent work, spanning from autonomous vehicle coordination to in-space assembly, has shown the importance of learning collaborative behavior for enabling robots to achieve shared goals. A common approach for learning this cooperative behavior is to utilize the centralized-training decentralized-execution paradigm. However, this approach also introduces a new challenge: how do we evaluate the contributions of each agent's actions to the overall success or failure of the team. This credit assignment problem has remained open, and has been extensively studied in the Multi-Agent Reinforcement Learning literature. In fact, humans manually inspecting agent behavior often generate better credit evaluations than existing methods. We combine this observation with recent works which show Large Language Models demonstrate human-level performance at many pattern recognition tasks. Our key idea is to reformulate credit assignment to the two pattern recognition problems of sequence improvement and attribution, which motivates our novel LLM-MCA method. Our approach utilizes a centralized LLM reward-critic which numerically decomposes the environment reward based on the individualized contribution of each agent in the scenario. We then update the agents' policy networks based on this feedback. We also propose an extension LLM-TACA where our LLM critic performs explicit task assignment by passing an intermediary goal directly to each agent policy in the scenario. Both our methods far outperform the state-of-the-art on a variety of benchmarks, including Level-Based Foraging, Robotic Warehouse, and our new Spaceworld benchmark which incorporates collision-related safety constraints. As an artifact of our methods, we generate large trajectory datasets with each timestep annotated with per-agent reward information, as sampled from our LLM critics.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Toward Agentic AI: Generative Information Retrieval Inspired Intelligent Communications and Networking</title>
<link>https://arxiv.org/abs/2502.16866</link>
<guid>https://arxiv.org/abs/2502.16866</guid>
<content:encoded><![CDATA[
<div> 关键词：智能自动化，agentic AI，信息检索，通信网络，资源分配

总结:
本文探讨了现代电信网络中智能自动化的需求，特别是agentic AI在提升效率、适应性和韧性方面的作用。文章聚焦于基于生成的信息检索技术如何应用于智能通信和网络领域，分析了传统检索、混合检索、语义检索、知识库检索及agentic上下文检索等多种策略的优势、局限性与适用场景。文中还介绍了一种电信系统特有的agentic上下文检索框架，该框架能通过整合多源检索、结构化推理和自我反思验证来增强网络规划。实验结果显示，此框架相比于传统和语义检索方法显著提高了答案准确性、解释一致性和检索效率。最后，文章指出了未来的研究方向。 <div>
arXiv:2502.16866v1 Announce Type: new 
Abstract: The increasing complexity and scale of modern telecommunications networks demand intelligent automation to enhance efficiency, adaptability, and resilience. Agentic AI has emerged as a key paradigm for intelligent communications and networking, enabling AI-driven agents to perceive, reason, decide, and act within dynamic networking environments. However, effective decision-making in telecom applications, such as network planning, management, and resource allocation, requires integrating retrieval mechanisms that support multi-hop reasoning, historical cross-referencing, and compliance with evolving 3GPP standards. This article presents a forward-looking perspective on generative information retrieval-inspired intelligent communications and networking, emphasizing the role of knowledge acquisition, processing, and retrieval in agentic AI for telecom systems. We first provide a comprehensive review of generative information retrieval strategies, including traditional retrieval, hybrid retrieval, semantic retrieval, knowledge-based retrieval, and agentic contextual retrieval. We then analyze their advantages, limitations, and suitability for various networking scenarios. Next, we present a survey about their applications in communications and networking. Additionally, we introduce an agentic contextual retrieval framework to enhance telecom-specific planning by integrating multi-source retrieval, structured reasoning, and self-reflective validation. Experimental results demonstrate that our framework significantly improves answer accuracy, explanation consistency, and retrieval efficiency compared to traditional and semantic retrieval methods. Finally, we outline future research directions.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Graphy'our Data: Towards End-to-End Modeling, Exploring and Generating Report from Raw Data</title>
<link>https://arxiv.org/abs/2502.16868</link>
<guid>https://arxiv.org/abs/2502.16868</guid>
<content:encoded><![CDATA[
<div> 关键词: Large Language Models (LLMs), Progressive Document Investigation, Graphy, Scrapper, Surveyor

总结:
本文介绍了一个针对大规模无结构文档进行渐进式探索、分析和综合处理的新平台Graphy。Graphy旨在解决大型语言模型（LLMs）在面对此类任务时常表现不足的问题，该问题被称为“Progressive Document Investigation”。Graphy包括一个离线Scrapper，它将原始文档转换为由Fact和Dimension节点组成的结构化图；以及一个在线Surveyor，支持迭代探索和LLM驱动的报告生成。文章展示了预处理的包含5万多篇论文及其引用关系的图谱，以此展示Graphy如何简化文献调研场景。相关演示视频可在https://youtu.be/uM4nzkAdGlM找到。 <div>
arXiv:2502.16868v1 Announce Type: new 
Abstract: Large Language Models (LLMs) have recently demonstrated remarkable performance in tasks such as Retrieval-Augmented Generation (RAG) and autonomous AI agent workflows. Yet, when faced with large sets of unstructured documents requiring progressive exploration, analysis, and synthesis, such as conducting literature survey, existing approaches often fall short. We address this challenge -- termed Progressive Document Investigation -- by introducing Graphy, an end-to-end platform that automates data modeling, exploration and high-quality report generation in a user-friendly manner. Graphy comprises an offline Scrapper that transforms raw documents into a structured graph of Fact and Dimension nodes, and an online Surveyor that enables iterative exploration and LLM-driven report generation. We showcase a pre-scrapped graph of over 50,000 papers -- complete with their references -- demonstrating how Graphy facilitates the literature-survey scenario. The demonstration video can be found at https://youtu.be/uM4nzkAdGlM.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>A Multi-LLM-Agent-Based Framework for Economic and Public Policy Analysis</title>
<link>https://arxiv.org/abs/2502.16879</link>
<guid>https://arxiv.org/abs/2502.16879</guid>
<content:encoded><![CDATA[
<div> 关键词：Large Language Models (LLMs)，经济决策，Multi-LLM-Agent-Based (MLAB)框架，政策分析，兴趣收入税收

<br /><br />总结:

本文提出了一种利用多个大型语言模型（LLMs）作为异质性人工智能经济代理进行经济和公共政策分析的新方法。研究首先评估了五个LLMs在两种不同场景下解决两期消费分配问题的经济决策能力，分别是基于明确效用函数和直观推理的情况。与以往仅通过改变提示来模拟异质性的做法不同，该方法利用不同LLM之间固有的分析能力差异来建模具有多样认知特质的经济主体。在此基础上，构建了一个MLAB框架，将这些LLM映射到特定教育群体及其对应的收入阶层。以兴趣收入税收为例，文章展示了如何运用MLAB框架模拟政策对异质性经济主体的影响，为利用LLMs的人类般推理能力和计算力开展经济与公共政策分析提供了一个有前景的新方向。 <div>
arXiv:2502.16879v1 Announce Type: new 
Abstract: This paper pioneers a novel approach to economic and public policy analysis by leveraging multiple Large Language Models (LLMs) as heterogeneous artificial economic agents. We first evaluate five LLMs' economic decision-making capabilities in solving two-period consumption allocation problems under two distinct scenarios: with explicit utility functions and based on intuitive reasoning. While previous research has often simulated heterogeneity by solely varying prompts, our approach harnesses the inherent variations in analytical capabilities across different LLMs to model agents with diverse cognitive traits. Building on these findings, we construct a Multi-LLM-Agent-Based (MLAB) framework by mapping these LLMs to specific educational groups and corresponding income brackets. Using interest-income taxation as a case study, we demonstrate how the MLAB framework can simulate policy impacts across heterogeneous agents, offering a promising new direction for economic and public policy analysis by leveraging LLMs' human-like reasoning capabilities and computational power.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Unbiased and Sign Compression in Distributed Learning: Comparing Noise Resilience via SDEs</title>
<link>https://arxiv.org/abs/2502.17009</link>
<guid>https://arxiv.org/abs/2502.17009</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式方法、通信开销、压缩、随机梯度下降、噪声鲁棒性

总结:
本文研究了在处理大规模机器学习流程中分布式压缩方法的重要性以及它们面临的通信开销问题。文章重点关注了两种分布式压缩算法——分布式压缩SGD (DCSGD) 和分布式SignSGD (DSignSGD)，并利用随机微分方程对其在存在大量和重尾梯度噪声情况下的性能进行了分析。结果表明，DCSGD在应对无偏压缩下的随机梯度噪声时较为脆弱，而DSignSGD即使在大型和重尾噪声环境下仍能保持鲁棒性。此外，文中还提出了新的超参数调整规则以缓解压缩导致的性能退化。这些发现通过多个深度学习架构和数据集的实验证明，并为分布式优化提供了实用建议。 <div>
arXiv:2502.17009v1 Announce Type: new 
Abstract: Distributed methods are essential for handling machine learning pipelines comprising large-scale models and datasets. However, their benefits often come at the cost of increased communication overhead between the central server and agents, which can become the main bottleneck, making training costly or even unfeasible in such systems. Compression methods such as quantization and sparsification can alleviate this issue. Still, their robustness to large and heavy-tailed gradient noise, a phenomenon sometimes observed in language modeling, remains poorly understood. This work addresses this gap by analyzing Distributed Compressed SGD (DCSGD) and Distributed SignSGD (DSignSGD) using stochastic differential equations (SDEs). Our results show that DCSGD with unbiased compression is more vulnerable to noise in stochastic gradients, while DSignSGD remains robust, even under large and heavy-tailed noise. Additionally, we propose new scaling rules for hyperparameter tuning to mitigate performance degradation due to compression. These findings are empirically validated across multiple deep learning architectures and datasets, providing practical recommendations for distributed optimization.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>MA2RL: Masked Autoencoders for Generalizable Multi-Agent Reinforcement Learning</title>
<link>https://arxiv.org/abs/2502.17046</link>
<guid>https://arxiv.org/abs/2502.17046</guid>
<content:encoded><![CDATA[
<div> 关键词：多智能体强化学习、任务无关技能、部分观察、Masked Autoencoders、零样本泛化

<br /><br />总结:
本文提出了一种名为“多智能体强化学习中的Masked Autoencoders（MA2RL）”的框架，用于解决在部分观察环境中多智能体强化学习中任务无关技能学习面临的挑战。MA2RL通过从实体视角重建全局实体状态，鼓励智能体推断未被观察到的实体，从而促进不同智能体间的协调以及技能的一般化和一致性学习。该框架将局部实体观测视为全局实体状态的掩码上下文，并能推断动态掩码实体的潜在表示，有助于任务无关技能的分配和技能语义的学习。实验结果表明，相较于现有方法，MA2RL表现出显著的性能提升、出色的零样本泛化能力和优异的迁移能力。 <div>
arXiv:2502.17046v1 Announce Type: new 
Abstract: To develop generalizable models in multi-agent reinforcement learning, recent approaches have been devoted to discovering task-independent skills for each agent, which generalize across tasks and facilitate agents' cooperation. However, particularly in partially observed settings, such approaches struggle with sample efficiency and generalization capabilities due to two primary challenges: (a) How to incorporate global states into coordinating the skills of different agents? (b) How to learn generalizable and consistent skill semantics when each agent only receives partial observations? To address these challenges, we propose a framework called \textbf{M}asked \textbf{A}utoencoders for \textbf{M}ulti-\textbf{A}gent \textbf{R}einforcement \textbf{L}earning (MA2RL), which encourages agents to infer unobserved entities by reconstructing entity-states from the entity perspective. The entity perspective helps MA2RL generalize to diverse tasks with varying agent numbers and action spaces. Specifically, we treat local entity-observations as masked contexts of the global entity-states, and MA2RL can infer the latent representation of dynamically masked entities, facilitating the assignment of task-independent skills and the learning of skill semantics. Extensive experiments demonstrate that MA2RL achieves significant improvements relative to state-of-the-art approaches, demonstrating extraordinary performance, remarkable zero-shot generalization capabilities and advantageous transferability.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
<item>
<title>Generative Models in Decision Making: A Survey</title>
<link>https://arxiv.org/abs/2502.17100</link>
<guid>https://arxiv.org/abs/2502.17100</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型、决策任务、应用分类、实际场景、未来发展方向

总结:
这篇论文回顾了生成模型在决策任务中的应用。文中将生成模型分为七类，并详细阐述了它们在决策过程中的三种主要角色：控制器、模型器和优化器。接着，文章分析了这些模型在五个关键的实际决策场景中的部署情况。此外，论文还指出了当前方法的优势与限制，并提出了推动下一代生成指令模型发展的三个关键方向：高性能算法、大规模通用决策模型以及自演进和适应性的模型。<br /><br /> <div>
arXiv:2502.17100v1 Announce Type: new 
Abstract: In recent years, the exceptional performance of generative models in generative tasks has sparked significant interest in their integration into decision-making processes. Due to their ability to handle complex data distributions and their strong model capacity, generative models can be effectively incorporated into decision-making systems by generating trajectories that guide agents toward high-reward state-action regions or intermediate sub-goals. This paper presents a comprehensive review of the application of generative models in decision-making tasks. We classify seven fundamental types of generative models: energy-based models, generative adversarial networks, variational autoencoders, normalizing flows, diffusion models, generative flow networks, and autoregressive models. Regarding their applications, we categorize their functions into three main roles: controllers, modelers and optimizers, and discuss how each role contributes to decision-making. Furthermore, we examine the deployment of these models across five critical real-world decision-making scenarios. Finally, we summarize the strengths and limitations of current approaches and propose three key directions for advancing next-generation generative directive models: high-performance algorithms, large-scale generalized decision-making models, and self-evolving and adaptive models.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
</item>
</channel>
</rss>