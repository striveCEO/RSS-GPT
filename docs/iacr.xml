<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Cryptology ePrint Archive</title>
<link>https://eprint.iacr.org/rss/rss.xml</link>

<item>
<title>Blockchain-Based Decentralized Domain Name System</title>
<link>https://eprint.iacr.org/2025/1381</link>
<guid>https://eprint.iacr.org/2025/1381</guid>
<content:encoded><![CDATA[

The current Domain Name System (DNS) infrastructure faces critical vulnerabilities including poisoning attacks, censorship mechanisms, and centralized points of failure that compromise internet freedom and security. Recent incidents such as DNS poisoning attacks on ISP customers highlight the urgent need for resilient alternatives. This paper presents a novel blockchain-based Decentralized Domain Name System (DDNS). We designed a specialized Proof-of-Work blockchain to maximize support for DNS-related protocols and achieve node decentralization. The system integrates our blockchain with IPFS for distributed storage, implements cryptographic primitives for end-to-end trust signatures, and achieves Never Trust, Always Verify zero-trust verification. Our implementation achieves 15-second domain record propagation times, supports 20 standard DNS record types, and provides perpetual free .ddns domains. The system has been deployed across distributed infrastructure in San Jose, Los Angeles, and Orange County, demonstrating practical scalability and resistance to traditional DNS manipulation techniques. Performance evaluation shows the system can handle up to Max Theor. TPS 1,111.1 tx/s (minimal transactions) and Max Theor. TPS 266.7 tx/s (regular transactions) for domain operations while maintaining sub-second query resolution through intelligent caching mechanisms.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 12:55:21 +0000</pubDate>
<pubDate>Tue, 29 Jul 2025 12:55:21 +0000</pubDate>
</item>
<item>
<title>Securing Credential Sequence Verification</title>
<link>https://eprint.iacr.org/2025/1371</link>
<guid>https://eprint.iacr.org/2025/1371</guid>
<content:encoded><![CDATA[

Credentials are used to verify a user’s identity and attributes
and form the basis of securing user access to the system resources. Users
obtain credentials and store them on their (mobile) devices, and present
them when needed. Anonymous credentials protect the user’s identity,
and ensure unlinkability of multiple showing of the credential. In this
paper, we consider a setting where a user is issued multiple credentials
in sequence (e.g., for completing courses), and credential subsequences
must be presented in order of issuance. We focus on the anonymous credential
system where information such as the time of issuing is hidden
for anonymity, or settings where there is no global clock and issuing
time information is not recorded. We propose a novel order-preserving
Proof-of-Credential-Subsequence (PoCS) system called KROM that allows
a user that is potentially untrusted, to present a subsequence of
their locally stored credentials to a verifier, while the relative chronological
order of issuance is preserved. We formalize the security and privacy
of KROM and present two constructions: a basic one that is based on
Merkle trees and one with batched verification that significantly improves
the efficiency of the system. We use KROM to construct an anonymous
order-preserving proof-of-location-subsequence system and prove its security.
The system enables users to selectively present a subsequence of
their visited locations to a verifier or an auditor. The main challenge that
is addressed is to ensure that the location information that must be in
plaintext, does not breach privacy when used in sequence.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 04:03:47 +0000</pubDate>
<pubDate>Mon, 28 Jul 2025 04:03:47 +0000</pubDate>
</item>

<item>
<title>Unmodified Half-Gates is Adaptively Secure - So is Unmodified Three-Halves</title>
<link>https://eprint.iacr.org/2023/1528</link>
<guid>https://eprint.iacr.org/2023/1528</guid>
<content:encoded><![CDATA[
Circuit garbling is a crucial cryptographic tool in many practical privacy-preserving applications due to two features: efficiency - it can be constructed in the random permutation model, allowing hardware acceleration; adaptivity - the majority of the communication can be transmitted offline before inputs are known. However, existing adaptive garbling schemes can only be proven in the random oracle model at best, leading to 20$\times$ slowdown.

In this work, we apply analysis often used for symmetric-key primitives to adaptive garbling and show that two practically deployed selective-secure schemes, half-gates and three-halves, already satisfy adaptive security without any modification to their implementations or security assumptions. We show how to bound an adaptive advantage via an adversary-dependent statistical distance and analyze this distance by adapting the H-coefficient technique to remove this adversary dependence. For real-life systems, our result solves the security concern about the heuristic of using the two schemes with offline communication. As a byproduct, we discuss when we can further offload the decoding information of garbled outputs to the offline phase, leading to a separation result.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 17:01:15 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Readiness in EdDSA Chains</title>
<link>https://eprint.iacr.org/2025/1368</link>
<guid>https://eprint.iacr.org/2025/1368</guid>
<content:encoded><![CDATA[
The impending threat posed by large-scale quantum computers necessitates a reevaluation of signature schemes deployed in blockchain protocols. In particular, blockchains relying on ECDSA, such as Bitcoin and Ethereum, exhibit inherent vulnerabilities due to on-chain public key exposure and the lack of post-quantum security guarantees. Although several post-quantum transition proposals have been introduced, including hybrid constructions and zero-knowledge-based key migration protocols, these approaches often fail to protect inactive "sleeping" accounts, are cumbersome, or require address changes, violating core immutability and full backward compatibility assumptions.

In this work, we observe that blockchains employing EdDSA with RFC 8032-compliant key derivation (e.g., Sui, Solana, Near, Stellar, Aptos, Cosmos) possess an underexplored structural advantage. Specifically, EdDSA’s hash-based deterministic secret key generation enables post-quantum zero-knowledge proofs of elliptic curve private key ownership, which can help switching to a quantum-safe algorithm proactively without requiring transfer of assets to new addresses.

We demonstrate how Post-Quantum NIZKs can be constructed to prove knowledge of the "seed" used in EdDSA key derivation, enabling post-quantum-secure transaction authorization without altering addresses or disclosing elliptic curve data. By post-quantum readiness, we mean that with a single user action all future signatures can be made post-quantum secure, even if past transactions used classical elliptic curve cryptography. This allows even users who have previously exposed their public key to seamlessly enter the post-quantum era without transferring assets or changing their account address.

As part of this analysis, we also show that BIP32-based ECDSA wallets are not post-quantum ready without breaking changes, as they rely on direct scalar exposure in derivation, making backward-compatible upgrades infeasible. In contrast, SLIP-0010  hash-chain based EdDSA private key derivation provides a foundation for seamless, backwards-compatible migration to quantum-safe wallets, supporting secure upgrades even for dormant or legacy accounts.

This mechanism affords a quantum-resilient path and is the first of its kind that preserves full backward compatibility, supports account abstraction, and critically secures dormant accounts, whether from users or custodians, that would otherwise be compromised under quantum adversaries.
]]></content:encoded>
<pubDate>Sat, 26 Jul 2025 13:48:05 +0000</pubDate>
</item>
<item>
<title>Randomized Distributed Function Computation (RDFC): Ultra-Efficient Semantic Communication Applications to Privacy</title>
<link>https://eprint.iacr.org/2025/1370</link>
<guid>https://eprint.iacr.org/2025/1370</guid>
<content:encoded><![CDATA[
We establish the randomized distributed function computation (RDFC) framework, in which a sender transmits just enough information for a receiver to generate a randomized function of the input data. Describing RDFC as a form of semantic communication, which can be essentially seen as a generalized remote‑source‑coding problem, we show that security and privacy constraints naturally fit this model, as they generally require a randomization step. Using strong coordination metrics, we ensure (local differential) privacy for every input sequence and prove that such guarantees can be met even when no common randomness is shared between the transmitter and receiver.

This work provides lower bounds on Wyner's common information (WCI), which is the communication cost when common randomness is absent, and proposes numerical techniques to evaluate the other corner point of the RDFC rate region for continuous‑alphabet random variables with unlimited shared randomness. Experiments illustrate that a sufficient amount of common randomness can reduce the semantic communication rate by up to two orders of magnitude compared to the WCI point, while RDFC without any shared randomness still outperforms lossless transmission by a large margin. A finite blocklength analysis further confirms that the privacy parameter gap between the asymptotic and non-asymptotic RDFC methods closes exponentially fast with input length. Our results position RDFC as an energy-efficient semantic communication strategy for privacy‑aware distributed computation systems.
]]></content:encoded>
<pubDate>Sun, 27 Jul 2025 14:13:47 +0000</pubDate>
</item>
<item>
<title>Encrypted Matrix Multiplication Using 3-Dimensional Rotations</title>
<link>https://eprint.iacr.org/2025/1367</link>
<guid>https://eprint.iacr.org/2025/1367</guid>
<content:encoded><![CDATA[
Fully homomorphic encryption (FHE) enables computations over encrypted data without the need for decryption.  Recently there has been an increased interest in developing FHE based algorithms to facilitate encrypted matrix multiplication (EMM) due to rising data security concerns surrounding cyber-physical systems, sensor processing, blockchain, and machine learning.  Presently, FHE operations have a high computational overhead, resulting in an increased need for low operational complexity algorithms to compensate.  We present a novel matrix encoding and EMM algorithm for power-of-2 cyclotomic based rings, utilizing three-dimensional rotations which offer improvements over the one-dimensional rotations used in previous work.  We encode each $d \times d$ matrix as a single, batch-encoded, ciphertext, with minimum ciphertext size $d^3$.  The proposed algorithm improves the number of plaintext-ciphertext multiplications from $O(d)$ to $O(1)$ and the number of rotations from $O(d)$ to $O(\log_2{d})$.  In addition, our work supports rectangular matrix multiplication and matrix packing without incurring additional operations per execution.  Benchmarks were obtained with a Microsoft SEAL implementation and compared against leading EMM algorithm, with our work performing $4$ times faster for $16 \times 16$ matrices on consumer hardware.  Our algorithm is compatible with existing encrypted machine learning frameworks and can be a drop-in replacement for existing matrix multiplication algorithms for increased speed.  The favorable time complexity is well suited for time sensitive encrypted algorithms such as computer vision, controls, and patient health monitoring.
]]></content:encoded>
<pubDate>Sat, 26 Jul 2025 03:13:40 +0000</pubDate>
</item>
<item>
<title>Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives</title>
<link>https://eprint.iacr.org/2025/1365</link>
<guid>https://eprint.iacr.org/2025/1365</guid>
<content:encoded><![CDATA[
Privacy-preserving machine learning (PPML) based on cryptographic protocols has emerged as a promising paradigm to protect user data privacy in cloud-based machine learning services. While it achieves formal privacy protection, PPML often incurs significant efficiency and scalability costs due to orders of magnitude overhead compared to the plaintext counterpart. Therefore, there has been a considerable focus on mitigating the efficiency gap for PPML. In this survey, we provide a comprehensive and systematic review of recent PPML studies with a focus on cross-level optimizations. Specifically, we categorize existing papers into protocol level, model level, and system level, and review progress at each level. We also provide qualitative and quantitative comparisons of existing works with technical insights, based on which we discuss future research directions and highlight the necessity of integrating optimizations across protocol, model, and system levels. We hope this survey can provide an overarching understanding of existing approaches and potentially inspire future breakthroughs in the PPML field. As the field is evolving fast, we also provide a public GitHub repository to continuously track the developments, which is available at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 16:24:56 +0000</pubDate>
</item>
<item>
<title>Universally Composable Adaptor Signatures</title>
<link>https://eprint.iacr.org/2025/1363</link>
<guid>https://eprint.iacr.org/2025/1363</guid>
<content:encoded><![CDATA[
Adaptor signatures extend the functionality of digital signatures by enabling the computation of pre-signatures on messages relative to statements in NP relations.
Pre-signatures are publicly verifiable objects that simultaneously hide and commit to a standard signature on the same message. 
Anyone possessing a valid witness for the statement can adapt the pre-signature into a full signature under the underlying signature scheme. 
Since adaptor signatures are commonly used as building blocks in larger systems—such as blockchain protocols—it is natural to seek a security definition within the Universal Composability (UC) framework. 
A recent attempt by Tairi et al. (CCS'23) introduced the first UC functionality for adaptor signatures.

This paper makes both negative and positive contributions. On the negative side, we show that the functionality proposed by Tairi et al. suffers from critical limitations:
    - The functionality fails to guarantee extractability and adaptability—the core security properties of adaptor signatures—to higher-level protocols.
    - No adaptor signature scheme can realize the functionality.

On the positive side, we propose a new UC functionality that faithfully captures the latest security guarantees of adaptor signatures as formalized via game-based notions by Gerhart et al. (EUROCRYPT'24).
    - Our functionality guarantees extractability, unique extractability, and pre-signature adaptability in a way that is composable and meaningful for higher-level protocols.
    - We show that it is realizable by an enhanced Schnorr-based adaptor signature scheme that we construct. Our construction maintains compatibility with existing infrastructure and is efficient enough for practical deployment, particularly in Bitcoin-like environments.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 16:00:31 +0000</pubDate>
</item>
<item>
<title>Revisiting the Generalized Birthday Problem and Equihash: Single or K Lists?</title>
<link>https://eprint.iacr.org/2025/1351</link>
<guid>https://eprint.iacr.org/2025/1351</guid>
<content:encoded><![CDATA[
The Generalized Birthday Problem ($\textsf{GBP}$), which seeks $k$ hash values from $k$ lists whose XOR is zero, is a fundamental problem across multiple cryptographic domains. Wagner's \(k\)-list algorithm (Crypto'02) for $\textsf{GBP}$ has advanced the optimization of solving the syndrome decoding problem and established new cryptanalytic benchmarks for incremental cryptography and blind signatures. $\textsf{Equihash}$ (NDSS'16) underscores the critical advantages of $\textsf{GBP}$ in proof-of-work design, particularly its ASIC-resistance in blockchain. While the k-list $\textsf{GBP}$ has been extensively studied, many schemes including $\textsf{Equihash}$ utilize a single-list variant (selecting hash values from a single list) without clear theoretical grounding. In this work, we revisit these two long-conflated problems and fill in theoretical gaps in solving the single-list $\textsf{GBP}$.

In the realm of $\textsf{Equihash}$, the index-pointer technique has significantly weakened its ASIC-resistance. Our trade-off optimization to Wagner's algorithmic framework further diminishes this resistance by reducing peak memory by at least 50% across most $\textsf{Equihash}$ parameters. To address this, we propose $\textsf{Sequihash}$, a PoW with enhanced ASIC-resistance, rigorously aligned with the $k$-list $\textsf{GBP}$. Furthermore, we explore the implications of $\textsf{GBP}$ in the field of incremental hash and propose a new collision attack on ID-based incremental hash (Eurocrypt'97). Our attack achieves an asymptotic time complexity of $\mathcal{O}(\sqrt{n} \cdot 2^{\sqrt{2n}})$, significantly improving upon the previous Wagner's bound of $\mathcal{O}(2^{\sqrt{4n}})$. Applying our attack to $\textsf{iSHAKE256}$, we reduce its security lower bound from \( 2^{256} \) to \( 2^{189} \).
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 15:32:27 +0000</pubDate>
</item>
<item>
<title>A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies</title>
<link>https://eprint.iacr.org/2025/1335</link>
<guid>https://eprint.iacr.org/2025/1335</guid>
<content:encoded><![CDATA[
Digital signatures are essential cryptographic tools that provide authentication and integrity in digital communications. However, privacy-sensitive applications—such as e-voting and digital cash—require more restrictive verification models to ensure confidentiality and control. Strong Designated Verifier Signature (SDVS) schemes address this need by enabling the signer to designate a specific verifier, ensuring that only this party can validate the signature. Existing SDVS constructions are primarily based on number-theoretic assumptions and are therefore vulnerable to quantum attacks. Although post-quantum alternatives—particularly those based on lattices—have been proposed, they often entail large key and signature sizes.  
In this work, we introduce $\mathsf{CSI\text{-}SDVS}$, a novel isogeny-based SDVS scheme that offers a compact, quantum-resistant alternative. Our construction builds on the ideal class group action framework of CSIDH and the signature techniques of CSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse Problem (MT-GAIP). $\mathsf{CSI\text{-}SDVS}$ achieves strong security guarantees—namely, Strong Unforgeability under Chosen-Message Attacks (SUF-CMA), Non-Transferability (NT), and Privacy of Signer’s Identity (PSI)—in the random oracle model. Remarkably, both the keys and signatures in $\mathsf{CSI\text{-}SDVS}$ are of size $\mathcal{O}(\lambda)$, representing a significant improvement over the typical $\mathcal{O}(\lambda^2)$ bounds in existing post-quantum SDVS schemes, thereby making it among the most compact PQC-based SDVS schemes and the only post-quantum secure construction based on isogenies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 05:42:29 +0000</pubDate>
</item>
<item>
<title>Technical Note: LeanSig for Post-Quantum Ethereum</title>
<link>https://eprint.iacr.org/2025/1332</link>
<guid>https://eprint.iacr.org/2025/1332</guid>
<content:encoded><![CDATA[
In this note, we present a new instantiation of the hash-based multi-signature framework introduced by Drake, Khovratovich, Kudinov, and Wagner (CiC Vol 2 Issue 1, eprint 2025/055) for Ethereum’s consensus layer. Inspired by a recent work of Khovratovich, Kudinov, and Wagner (Crypto 2025, eprint 2025/889), we instantiate the framework with a novel incomparable encoding that improves the tradeoff between signature size and verification hashing. The purpose of this document is to make explicit how to use the ideas of the latter work within the framework of Drake, Khovratovich, Kudinov, and Wagner.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 16:14:53 +0000</pubDate>
</item>
<item>
<title>Private Set Intersection and other Set Operations in the Third Party Setting</title>
<link>https://eprint.iacr.org/2025/1328</link>
<guid>https://eprint.iacr.org/2025/1328</guid>
<content:encoded><![CDATA[
We present a collection of protocols to perform privacy-preserving set operations in the third-party private set intersection (PSI) setting. This includes several protocols for multi-party third party PSI. In this model, there are multiple input parties (or clients) each holding a private set of elements and the receiver is an external party (termed as third-party) with no inputs. Multi-party third party PSI enables the receiver to learn only the intersection result of all input clients' private sets while revealing nothing else to the clients and the receiver. Our solutions include constructions that are provably secure against an arbitrary number of colluding parties in the semi-honest model. Additionally, we present protocols for third-party private set difference and private symmetric difference, whereby the learned output by the inputless third-party is the set difference and symmetric difference respectively of two other input parties, while preserving the same privacy guarantees. The motivation in the design of these protocols stems from their utilities in numerous real-world applications. We implemented our protocols and conducted experiments across various input and output set sizes.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 08:08:13 +0000</pubDate>
</item>
<item>
<title>Ordering Transactions with Bounded Unfairness: Definitions, Complexity and Constructions</title>
<link>https://eprint.iacr.org/2023/1253</link>
<guid>https://eprint.iacr.org/2023/1253</guid>
<content:encoded><![CDATA[
An important consideration in the context of distributed ledger protocols is fairness in terms of transaction ordering. Recent work [Crypto 2020] revealed a connection of (receiver) order fairness to social choice theory and related impossibility results arising from the Condorcet paradox. As a result of the impossibility, various relaxations of order fairness were proposed in prior works. Given that distributed ledger protocols, especially those processing smart contracts, must serialize the input transactions, a natural objective is to minimize the distance (in terms of number of transactions) between any pair of unfairly ordered transactions in the output ledger — a concept we call bounded unfairness. In state machine replication (SMR) parlance this asks for minimizing the number of unfair state updates occurring before the processing of any request. This unfairness minimization objective gives rise to a natural class of parametric order fairness definitions that has not been studied before. As we observe, previous realizable relaxations of order fairness do not yield good unfairness bounds.

Achieving optimal order fairness in the sense of bounded unfairness turns out to be connected to the graph theoretic properties of the underlying transaction dependency graph and specifically the bandwidth metric of strongly connected components in this graph. This gives rise to a specific instance of the definition that we call “directed bandwidth order-fairness” which we show that it captures the best possible that any ledger protocol can achieve in terms of bounding unfairness. We prove ordering transactions in this fashion is NP-hard and non-approximable for any constant ratio. Towards realizing the property, we put forth a new distributed ledger protocol called Taxis that achieves directed bandwidth order-fairness. We present two variations, one that matches the property perfectly but (necessarily) lacks in performance and liveness, and another that achieves liveness and better complexity while offering a slightly relaxed version of the property. Finally, we comment on applications of our work to social choice, a direction which we believe to be of independent interest.
]]></content:encoded>
<pubDate>Fri, 18 Aug 2023 13:45:58 +0000</pubDate>
</item>
<item>
<title>Permissionless Clock Synchronization with Public Setup</title>
<link>https://eprint.iacr.org/2022/1220</link>
<guid>https://eprint.iacr.org/2022/1220</guid>
<content:encoded><![CDATA[
The permissionless clock synchronization problem asks how it is possible for a population of parties to maintain a system-wide synchronized clock, while their participation rate fluctuates --- possibly very widely --- over time. The underlying assumption is that parties experience the passage of time with roughly the same speed, but however they may disengage and engage with the protocol following arbitrary (and even chosen adversarially) participation patterns. This (classical) problem has received renewed attention due to the advent of blockchain protocols, and recently it has been solved in the setting of proof of stake, i.e., when parties are assumed to have access to a trusted PKI setup [Badertscher et al., Eurocrypt '21].

In this work, we present the first proof-of-work (PoW)-based permissionless clock synchronization protocol. Our construction assumes a public setup (e.g., a CRS) and relies on an honest majority of computational power that, for the first time, is described in a fine-grain timing model that does not utilize a global clock that exports the current time to all parties. As a secondary result of independent interest, our protocol gives rise to the first PoW-based ledger consensus protocol that does not rely on an external clock for the time-stamping of transactions and adjustment of the PoW difficulty.
]]></content:encoded>
<pubDate>Wed, 14 Sep 2022 18:05:34 +0000</pubDate>
</item>
<item>
<title>Threshold Receipt-Free Voting with Server-Side Vote Validation</title>
<link>https://eprint.iacr.org/2025/1321</link>
<guid>https://eprint.iacr.org/2025/1321</guid>
<content:encoded><![CDATA[
Proving the validity of ballots is a central element of verifiable elections. Such proofs can however create challenges when one desires to make a protocol receipt-free.
We explore the challenges raised by validity proofs in the context of protocols where threshold receipt-freeness is obtained by secret sharing an encryption of a vote between multiple authorities. 
In such contexts, previous solutions verified the validity of votes by decrypting them after passing them through a mix-net. This approach however creates subtle privacy risks, especially when invalid votes leak structural patterns that threaten receipt-freeness. 
We propose a different approach of threshold receipt-free voting in which authorities re-randomize ballot shares then jointly compute a ZK proof of ballot validity before letting the ballots enter a (possibly homomorphic) tallying phase. Our approach keeps the voter computational costs limited while offering verifiability and improving the ballot privacy of previous solutions.  
We present two protocols that enable a group of servers to verify and publicly prove that encrypted votes satisfy some validity properties: Minimix, which preserves prior voter-side behavior with minimal overhead, and Homorand, which requires voters to submit auxiliary data to facilitate validation over large vote domains. We show how to use our two protocols within a threshold receipt-free voting framework. We provide formal security proofs and efficiency analyses to illustrate trade-offs in our designs.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 17:27:26 +0000</pubDate>
</item>
<item>
<title>Bridging Usability and Performance: A Tensor Compiler for Autovectorizing Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1319</link>
<guid>https://eprint.iacr.org/2025/1319</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) offers strong privacy guarantees by enabling computation over encrypted data. However, the performance of tensor operations in HE is highly sensitive to how the plaintext data is packed into ciphertexts. Large tensor programs introduce numerous possible layout assignments, making it both challenging and tedious for users to manually write efficient HE programs.

In this paper, we present Rotom, a compilation framework that autovectorizes tensor programs into optimized HE programs. Rotom systematically explores a wide range of layout assignments, applies state-of-the-art optimizations, and automatically finds an equivalent, efficient HE program. At its core, Rotom utilizes a novel, lightweight ApplyRoll layout conversion operator to easily modify the underlying data layouts and unlock new avenues for performance gains. Our evaluation demonstrates that Rotom scalably compiles all benchmarks in under 5 minutes, reduces rotations in manually optimized protocols by up to 4×, and achieves up to 80× performance improvement over prior systems.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 16:17:50 +0000</pubDate>
</item>
<item>
<title>FunBic-CCA: Function Secret Sharing for Biclusterings Applied to Cheng and Church Algorithm (Extended Version)</title>
<link>https://eprint.iacr.org/2025/1317</link>
<guid>https://eprint.iacr.org/2025/1317</guid>
<content:encoded><![CDATA[
High-throughput technologies (e.g., the microarray) have fostered the rapid growth of gene expression data collection. These biomedical datasets, increasingly distributed among research institutes and hospitals, fuel various machine learning applications such as anomaly detection, prediction or clustering. In particular, unsupervised classification techniques based on biclustering like the Cheng and Church Algorithm (CCA) have proven to adapt particularly well to gene expression data. However, biomedical data is highly sensitive, hence its sharing across multiple entities introduces privacy and security concerns, with an ever-present threat of accidental disclosure or leakage of private patient information. To address such threat, this work introduces a novel, highly efficient privacy-preserving protocol based on secure multiparty computation (MPC) between two servers to compute CCA. Our protocol performs operations relying on an additive secret sharing and function secret sharing, leading us to reformulate the steps of the CCA into MPC-friendly equivalents. Leveraging lightweight cryptographic primitives, our new technique named FunBic-CCA is first to exploit the efficiency of function secret sharing to achieve fast evaluation of the CCA biclustering algorithm.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 12:26:14 +0000</pubDate>
</item>
<item>
<title>Two-Server Sublinear PIR with Symmetric Privacy and Statistical Security</title>
<link>https://eprint.iacr.org/2025/1313</link>
<guid>https://eprint.iacr.org/2025/1313</guid>
<content:encoded><![CDATA[
The field of private information retrieval (PIR) has made significant strides with a recent focus on protocols that offer sublinear online time, ensuring efficient access to public databases without compromising the privacy of the queries. The pioneering two-server PIR protocols developed by Corrigan-Gibbs and Kogan (EUROCRYPT 2020) enjoy the dual benefits of sublinear online time and statistical security. This allows their protocols to provide high efficiency and resist computationally unbounded adversaries. In this work, we extend this seminal work to the symmetric PIR (SPIR) context, where the protocol must ensure that the client is privy only to the requested database entries, with no knowledge of the remaining data. This enhancement aligns with scenarios where the confidentiality of non-requested information is as critical as the query itself. Our main result is the introduction of the first two-server SPIR protocols that achieve both sublinear online time and statistical security, together with an enhancement for achieving sublinear amortized time. Our protocols require a pragmatic level of shared randomness between the servers, which however is necessary for implementing statistical security in two-server SPIR, as showed by Gertner et al. (STOC 1998).
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 02:57:44 +0000</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Privacy-Preserving Decision Trees Based on Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1310</link>
<guid>https://eprint.iacr.org/2025/1310</guid>
<content:encoded><![CDATA[
Decision trees are extensively employed in artificial intelligence and machine learning due to their interpretability, efficiency, and robustness-qualities that are particularly valued in sensitive domains such as healthcare, finance, and cybersecurity. In response to evolving data privacy regulations, there is an increasing demand for models that ensure data confidentiality during both training and inference. Homomorphic encryption emerges as a promising solution by enabling computations directly on encrypted data without exposing plaintext inputs. This survey provides a comprehensive review of privacy-preserving decision tree protocols leveraging homomorphic encryption. After
introducing fundamental concepts and the adopted methodology,
a dual-layer taxonomy is presented, encompassing system and
data characteristics as well as employed processing techniques.
This taxonomy facilitates the classification and comparison of
existing protocols, evaluating their effectiveness in addressing key
challenges related to privacy, efficiency, usability, and deploy-
ment. Finally, current limitations, emerging trends, and future
research directions are discussed to enhance the security and
practicality of homomorphic encryption frameworks for decision
trees in privacy-sensitive applications.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 15:01:36 +0000</pubDate>
</item>
<item>
<title>FHERMA Cookbook: FHE Components for Privacy-Preserving Applications</title>
<link>https://eprint.iacr.org/2025/1302</link>
<guid>https://eprint.iacr.org/2025/1302</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) enables computation over
encrypted data and is considered a fundamental tool for privacy-preserving systems.
Despite significant theoretical progress, its practical adoption remains limited. One
contributing factor is the absence of reusable, application-level components suitable
for integration into real-world systems.
This work introduces a library of FHE components developed through a competition-
based framework. The components are outcomes of a series of formalized challenges
published on the FHERMA platform, each targeting a specific challenge—such
as comparison, sorting, or matrix operations—under concrete cryptographic and
performance constraints.
This initial release includes contributions from independent researchers and reflects
a variety of approaches across different FHE schemes. The library is intended to
expand over time as new challenges are introduced and solved, forming a foundation
for building and evaluating privacy-preserving applications.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 17:16:10 +0000</pubDate>
</item>
<item>
<title>PlasmaFold: An Efficient and Scalable Layer 2 with Client-Side Proving</title>
<link>https://eprint.iacr.org/2025/1300</link>
<guid>https://eprint.iacr.org/2025/1300</guid>
<content:encoded><![CDATA[
Despite the growing popularity of blockchains, their scalability remains a significant challenge. Layer-2s (L2s) aim to address this by introducing an operator to process transactions off-chain and post compact summaries to the Layer-1 (L1). However, existing L2 designs struggle with unsatisfactory throughput improvements, complex exit games, limited data availability, or high computational overhead for users.

This paper introduces PlasmaFold, a novel L2 designed to overcome these limitations. PlasmaFold utilizes a hybrid architecture: an operator (aggregator) generates proofs on server side for the honest construction of blocks, while users maintain balance proofs on their own devices. This separation of concerns enables instant, non-interactive exits via balance proofs, while block proofs handle most of the validations, minimizing users’ costs. By leveraging Incrementally Verifiable Computation (IVC), PlasmaFold achieves concrete efficiency. Users can update their balance proofs within a browser in under 1 second per transaction using less than 1 GB of RAM. Furthermore, only the identities of users who have acknowledged data receipt are posted to L1, ensuring data availability with a minimal on-chain footprint. This design keeps L1 costs extremely low, enabling a theoretical throughput of over 14000 transactions per second.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 14:28:36 +0000</pubDate>
</item>
<item>
<title>OverModRaise: Reducing Modulus Consumption of CKKS Bootstrapping</title>
<link>https://eprint.iacr.org/2025/1298</link>
<guid>https://eprint.iacr.org/2025/1298</guid>
<content:encoded><![CDATA[
The Cheon-Kim-Kim-Song (CKKS) homomorphic encryption scheme is widely adopted for securely evaluating circuits over real numbers, such as those arising in privacy-preserving machine learning (PPML), because it efficiently supports approximate floating-point arithmetic of messages. A CKKS ciphertext has a finite level, which corresponds to the budget for how many multiplicative operations can be applied. Once these levels are consumed, the ciphertext must be refreshed through a bootstrapping procedure to restore its capacity for further computation. However, bootstrapping itself also consumes a significant number of levels, leaving fewer levels after each bootstrapping. 

In this work, we propose three techniques—OverModRaise1, OverModRaise2, and Tuple-C2S/S2C—that target reductions in the modulus consumption of C2S/S2C among the CKKS bootstrapping procedures, without introducing substantial overhead or compromising security. By combining these techniques, our implementation demonstrates a 27–61% throughput improvement compared to the state-of-the-art bootstrapping.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 10:56:42 +0000</pubDate>
</item>
<item>
<title>AD-MPC: Asynchronous Dynamic MPC with Guaranteed Output Delivery</title>
<link>https://eprint.iacr.org/2024/1653</link>
<guid>https://eprint.iacr.org/2024/1653</guid>
<content:encoded><![CDATA[
MPC-as-a-Service (MPCaaS) systems enable clients to outsource privacy-preserving computations to distributed servers, offering flexibility by adapting and configuring MPC protocols to meet diverse security requirements. However, traditional MPC protocols rely on a fixed set of servers for the entire computation process, limiting scalability. Dynamic MPC (DMPC) addresses this limitation by permitting participants to join or leave during the computation. Nevertheless, existing DMPC protocols assume synchronous networks, which can lead to failures under unbounded network delays. In this paper, we present AD-MPC, the first asynchronous dynamic MPC protocol. Our protocol ensures guaranteed output delivery under optimal resilience ($n=3t+1$). To achieve this, we introduce two critical components: an asynchronous dynamic preprocessing protocol that facilitates the on-demand generation of Beaver triples for secure multiplication, and an asynchronous transfer protocol that maintains consistency during party hand-offs. These components collectively ensure computation correctness and transfer consistency across participants. We implement AD-MPC and evaluate its performance across up to 20 geographically distributed nodes. Experimental results demonstrate that the protocol not only offers strong security guarantees in dynamic and asynchronous network environments but also achieves performance comparable to state-of-the-art DMPC protocols.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 02:51:42 +0000</pubDate>
</item>
<item>
<title>SecFePAS: Secure Facial-Expression-Based Pain Assessment with Deep Learning at the Edge</title>
<link>https://eprint.iacr.org/2025/1280</link>
<guid>https://eprint.iacr.org/2025/1280</guid>
<content:encoded><![CDATA[
Patient monitoring in hospitals, nursing centers, and home care can be largely automated using cameras and machine-learning-based video analytics, thus considerably increasing the efficiency of patient care. In particular, Facial-expression-based Pain Assessment Systems (FePAS) can automatically detect pain and notify medical personnel. However, current FePAS solutions using cloud-based video analytics offer very limited security and privacy protection. This is problematic, as video feeds of patients constitute highly sensitive information.
To address this problem, we introduce SecFePAS, the first FePAS solution with strong security and privacy guarantees. SecFePAS uses advanced cryptographic protocols to perform neural network inference in a privacy-preserving way. To counteract the significant overhead of the used cryptographic protocols, SecFePAS uses multiple optimizations. First, instead of a cloud-based setup, we use edge computing with a 5G connection to benefit from lower network latency. Second, we use a combination of transfer learning and quantization to devise neural networks with high accuracy and optimized inference time. Third, SecFePAS quickly filters out unessential frames of the video to focus the in-depth analysis on key frames. We tested SecFePAS with the SqueezeNet and ResNet50 neural networks on a real pain estimation benchmark. SecFePAS outperforms state-of-the-art FePAS systems in accuracy and optimizes secure processing time.
]]></content:encoded>
<pubDate>Sun, 13 Jul 2025 15:54:34 +0000</pubDate>
</item>
<item>
<title>Multi-Authority Registered Attribute-Based Encryption</title>
<link>https://eprint.iacr.org/2025/1279</link>
<guid>https://eprint.iacr.org/2025/1279</guid>
<content:encoded><![CDATA[
Registered attribute-based encryption (ABE) enables fine-grained access control to encrypted data without a trusted authority. In this model, users generate their own public keys and register their public key along with a set of attributes with a key curator. The key curator aggregates the public keys into a short master public key that functions as the public key for an ABE scheme.

A limitation of ABE (registered or centralized) is the assumption that a single entity manages all of the attributes in a system. In many settings, the attributes belong to different organizations, making it unrealistic to expect that a single entity manage all of them. In the centralized setting, this motivated the notion of multi-authority ABE, where multiple independent authorities control their individual set of attributes. Access policies are then defined over attributes across multiple authorities.

In this work, we introduce multi-authority registered ABE, where multiple (independent) key curators each manage their individual sets of attributes. Users can register their public keys with any key curator, and access policies can be defined over attributes from multiple key curators. Multi-authority registered ABE combines the trustless nature of registered ABE with the decentralized nature of multi-authority ABE.

We start by constructing a multi-authority registered ABE scheme from composite-order pairing groups. This scheme supports an a priori bounded number of users and access policies that can be represented by a linear secret sharing scheme (which includes monotone Boolean formulas). Our construction relies on a careful integration of ideas from pairing-based registered ABE and multi-authority ABE schemes. We also construct a multi-authority registered ABE scheme that supports an unbounded number of users and arbitrary monotone policies using indistinguishability obfuscation (and function-binding hash functions).
]]></content:encoded>
<pubDate>Sun, 13 Jul 2025 04:58:41 +0000</pubDate>
</item>
<item>
<title>Improved Matrix Inversion with Packed Ciphertexts using Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1274</link>
<guid>https://eprint.iacr.org/2025/1274</guid>
<content:encoded><![CDATA[
Matrix inversion is a fundamental operation, but performing it over encrypted matrices remains a significant challenge.
This is mainly due to the fact that conventional inversion algorithms—such as Gaussian elimination—depend heavily on comparison and division operations, which are computationally expensive to perform under homomorphic encryption. 
To mitigate this, Ahn et al. (ESORICS 2023) introduced an inversion method based on iterative matrix multiplications. However, their approach encrypts matrices entry-wise, leading to poor scalability. A key limitation of prior work stems from the absence of an efficient matrix multiplication technique for matrix-packed ciphertexts, particularly one with low multiplicative depth.

In this paper, we present a novel homomorphic matrix multiplication algorithm optimized for matrix-packed ciphertexts, requiring only a multiplicative depth of two. 
Building on this foundation, we propose an efficient algorithm for homomorphic matrix inversion. 
Experimental results show that our method outperforms the state-of-the-art: for $8\times 8$ matrices, it achieves a $6.8\times$ speedup over the method by Ahn et al., and enables inversion of larger matrices that were previously infeasible.
We further compare our homomorphic matrix multiplication technique against existing matrix-packed homomorphic matrix multiplication algorithms.
When used for iterative inversion, our method consistently outperforms prior approaches. 
In particular, for $16\times 16$ and $32\times 32$ matrices, it achieves $1.88\times$ and $1.43\times$ speedups, respectively, over the algorithm by Aikata and Roy.
Finally, we demonstrate the practical benefits of our method by applying it to privacy-preserving linear regression. For a dataset of $64$ samples with $8$ features, our approach achieves a $1.13\times$ speedup in training time compared to the state-of-the-art homomorphic matrix inversion solution.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 08:35:06 +0000</pubDate>
</item>
<item>
<title>Threshold Structure-Preserving Signatures with Randomizable Key</title>
<link>https://eprint.iacr.org/2025/1273</link>
<guid>https://eprint.iacr.org/2025/1273</guid>
<content:encoded><![CDATA[
While digital signatures serve to confirm message integrity
and the identity of the signer, the inherent link between the public key
and the signer’s identity can pose challenges in anonymized networks or
applications focused on preserving privacy. Signatures with randomiz-
able keys aim to disentangle the signer’s identity from their public key,
thus preserving the signature’s validity. This approach ensures that the
signature, even with a randomized key, maintains its verifiability without
linking it to the signer’s identity.
Although signatures with randomizable keys effectively maintain privacy,
additional structural improvements are necessary in specialized signature
schemes for complex cryptographic frameworks. Threshold structure-
preserving signatures offer a way to construct modular protocols while
retaining the benefits of structure-preserving properties. Thus, the ran-
domizable key version of it is essential for a wide range of applications,
making it the foundation of this work. In this study, signatures with ran-
domizable key principles combined with threshold structure-preserving
signatures to build a strong cryptographic base for privacy-preserving
applications. This foundation makes sure that signatures are valid while
also being modular and unlinkable.
An earlier version of this work appeared in the 22nd International Con-
ference on Security and Cryptography(SECRYPT 2025) [6]; the present
article extends that study by adding the formal security proofs of the
introduced protocols.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 20:44:53 +0000</pubDate>
</item>
<item>
<title>Applications Of Zero-Knowledge Proofs On Bitcoin</title>
<link>https://eprint.iacr.org/2025/1271</link>
<guid>https://eprint.iacr.org/2025/1271</guid>
<content:encoded><![CDATA[
This paper explores how zero-knowledge proofs can enhance Bitcoin's functionality and privacy. First, we consider Proof-of-Reserve schemes: by using zk-STARKs, a custodian can prove its Bitcoin holdings are more than a predefined threshold X, without revealing addresses or actual balances. We outline a STARK-based protocol for Bitcoin UTXOs and discuss its efficiency. Second, we examine ZK Light Clients, where a mobile or lightweight device verifies Bitcoin's proof-of-work chain using succinct proofs. We propose a protocol for generating and verifying a STARK-based proof of a chain of block headers, enabling trust-minimized client operation. Third, we explore Privacy-Preserving Rollups via BitVM: leveraging BitVM, we design a conceptual rollup that keeps transaction data confidential using zero-knowledge proofs. In each case, we analyze security, compare with existing approaches, and discuss implementation considerations. Our contributions include the design of concrete protocols adapted to Bitcoin's UTXO model and an assessment of their practicality. The results suggest that while ZK proofs can bring powerful features (e.g., on-chain reserve audits, trustless light clients, and private layer-2 execution) to Bitcoin, each application requires careful trade-offs in efficiency and trust assumptions.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 18:29:20 +0000</pubDate>
</item>
<item>
<title>Efficiently parsing existing eID documents for zero-knowledge proofs</title>
<link>https://eprint.iacr.org/2025/1266</link>
<guid>https://eprint.iacr.org/2025/1266</guid>
<content:encoded><![CDATA[
Online services increasingly require users to verify their identity or parts of it, often by law. This verification is usually performed by processing data from official identity documents, like national identity cards. However, these documents often contain significantly more information than the verifying party needs to know, including information that should stay private. Disclosing this information is a significant privacy and security risk for the user.
Traditional work has designed selective disclosure and zero-knowledge proof protocols for such use cases.
However, because these require a complete reimplementation, recall and redistribution of existing identity documents, they have never been adopted on a large scale. More recent work has focused on creating zero-knowledge proofs from existing identity documents like the US passport or specific US driver licenses. In this article, we propose an R1CS protocol to efficiently parse and extract fields from existing European National Identity Cards, with an implementation for the Belgian BeID.
The protocol is able to prove correct extraction of a date-of-birth field in 22 seconds on a consumer device, with verification taking 230 milliseconds. With this, we aim to provide EU citizens with a practical solution to the privacy and security risks that arise when one has to prove their authenticity or authority to a third party.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 13:46:16 +0000</pubDate>
</item>
<item>
<title>OasisDB: An Oblivious and Scalable System for Relational Data</title>
<link>https://eprint.iacr.org/2025/1263</link>
<guid>https://eprint.iacr.org/2025/1263</guid>
<content:encoded><![CDATA[
We present OasisDB, an oblivious and scalable RBDMS framework designed to securely manage relational data while protecting against access and volume pattern attacks. Inspired by plaintext RDBMSs, OasisDB leverages existing oblivious key value stores (KV-stores) as storage engines and securely scales them to enhance per-formance. Its novel multi-tier architecture allows for independent scaling of each tier while supporting multi-user environments without compromising privacy. We demonstrate OasisDB’s flexibility by deploying it with two distinct oblivious KV-stores, PathORAM and Waffle, and show its capability to execute a variety of SQL queries, including point and range queries, joins, aggregations, and limited updates. Experimental evaluations on the Epinions dataset show that OasisDB scales linearly with the number of machines. When deployed with a plaintext KV-store, OasisDB introduces negligible overhead in its multi-tier architecture compared to a plaintext database, CockroachDB. We also compare OasisDB with ObliDB, an oblivious RDBMS, highlighting its advantages with scalability and multi-user support.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 03:30:30 +0000</pubDate>
</item>
<item>
<title>BitVM with Succinct On-Chain Cost from AB-LFE, HMAC, or Privacy-Free GC</title>
<link>https://eprint.iacr.org/2025/1253</link>
<guid>https://eprint.iacr.org/2025/1253</guid>
<content:encoded><![CDATA[
This paper aims to be a systematization of knowledge on how to instantiate BitVM with succinct on-chain cost from attribute-based laconic function evaluation (AB-LFE), homomorphic message authentication codes (HMAC), or privacy-free garbled circuits (GC) with suitable properties, specifically with:

- AB-LFE with unbounded depth and with bounded depth, which implies reusable privacy-free garbled circuits

- HMAC in with unbounded depth, which implies succinct privacy-free garbled circuits

- privacy-free garbled circuits and their succinct garbling as in BitGC

They vary in complexity, concrete overhead, succinctness, reusability, and security mechanisms against a malicious garbler. This paper is a literature review, as instantiating BitVM with them is straightforward.
]]></content:encoded>
<pubDate>Mon, 07 Jul 2025 19:47:20 +0000</pubDate>
</item>
<item>
<title>On the Estonian Internet Voting System, IVXV, SoK  and Suggestions</title>
<link>https://eprint.iacr.org/2025/506</link>
<guid>https://eprint.iacr.org/2025/506</guid>
<content:encoded><![CDATA[
The Estonian i-voting experience is probably the richest to analyze; a country that is considered a pioneer in digitizing both the government and private sector since 2001 followed by online internet voting (i-voting) in 2005. However, there are still some complaints submitted, critics and remarks to consider about the IVXV system. In this paper, we introduce a Systemization of Knowledge of the Estonian IVXV i-voting system and propose some added security enhancements. The presented SoK discusses applications implemented by election observers in 2023 & 2024 elections, which, to our knowledge, have never been mentioned and/or analyzed in the academia before. We also point out to unnoticed automated formal verification analysis of IVXV; the researchers discovered a privacy attack that we show extendable to a possible large scale encrypted vote copying. In addition, we identify and analyze recent fixes and improvements in the June 2024 version used in the European Parliament elections connecting them to their academic sources. Finally, we discuss the current system status, propose our own suggestions to some remaining vulnerabilities, then raise the inevitable question of the approaching quantum threat.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 19:16:27 +0000</pubDate>
</item>
<item>
<title>OMIX: Offline Mixing for Scalable Self-Tallying Elections</title>
<link>https://eprint.iacr.org/2025/1232</link>
<guid>https://eprint.iacr.org/2025/1232</guid>
<content:encoded><![CDATA[
In electronic voting systems, guaranteeing voter anonymity is essential. One primary method to ensure this is the use of a mix-net, in which a set of mix-servers sequentially shuffle a set of encrypted votes, and generate proofs that a correct permutation has been applied. Whilst mix-nets offer advantages over alternative approaches,  their traditional use during the tallying phase introduces a significant robustness bottleneck: the process is inherently sequential and critically depends on trusted authorities to perform shuffling and decryption. Any disruption can prevent the final result from being revealed.

In this work, we propose offline mixing OMIX, the first voting framework to support a mix-net-based system in which trustees never handle encrypted votes, while also ensuring that each voter's cost is independent of the total number of voters. In particular, the contributions of permutations by mix-servers and decryption shares by trustees are completed and publicly verified before any vote is cast. This eliminates the need for their participation during tallying and enables the first scalable, mix-net-based, and self-tallying voting protocol in the sense of Kiayias and Yung (PKC'02).

At the core of OMIX is a distributed key-generation mechanism: each voter locally generates a private voting key and registers a constant-size set of basis public keys. These are permuted and partially decrypted in an offline phase, resulting in a final public decryption key that reveals votes in shuffled order. Our construction leverages the homomorphic and structure-preserving properties of function-hiding inner-product functional encryption, combined with standard primitives, to achieve self-tallying, client scalability, ballot privacy and other voting properties. To support the new mixing structure introduced by OMIX, we also develop a compact and verifiable offline mix-net, based on an enhanced linearly homomorphic signature scheme. This latter primitive may be of independent interest.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 20:46:52 +0000</pubDate>
</item>
<item>
<title>ABE Cubed: Advanced Benchmarking Extensions for ABE Squared</title>
<link>https://eprint.iacr.org/2025/1230</link>
<guid>https://eprint.iacr.org/2025/1230</guid>
<content:encoded><![CDATA[
Since attribute-based encryption (ABE) was proposed in 2005, it has established itself as a valuable tool in the enforcement of access control. For practice, it is important that ABE satisfies many desirable properties such as multi-authority and negations support. Nowadays, we can attain these properties simultaneously, but none of these schemes have been implemented. Furthermore, although simpler schemes have been optimized extensively on a structural level, there is still much room for improvement for these more advanced schemes. However, even if we had schemes with such structural improvements, we would not have a way to benchmark and compare them fairly to measure the effect of such improvements. The only framework that aims to achieve this goal, ABE Squared (TCHES '22), was designed with simpler schemes in mind.

In this work, we propose the ABE Cubed framework, which provides advanced benchmarking extensions for ABE Squared. To motivate our framework, we first apply structural improvements to the decentralized ciphertext-policy ABE scheme supporting negations presented by Riepel, Venema and Verma (ACM CCS '24), which results in five new schemes with the same properties. We use these schemes to uncover and bridge the gaps in the ABE Squared framework. In particular, we observe that advanced schemes depend on more "variables" that affect the schemes' efficiency in different dimensions. Whereas ABE Squared only considered one dimension (as was sufficient for the schemes considered there), we devise a benchmarking strategy that allows us to analyze the schemes in multiple dimensions. As a result, we obtain a more complete overview on the computational efficiency of the schemes, and ultimately, this allows us to make better-founded choices about which schemes provide the best efficiency trade-offs for practice.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 15:13:17 +0000</pubDate>
</item>
<item>
<title>Rational Censorship Attack: Breaking Blockchain with a Blackboard</title>
<link>https://eprint.iacr.org/2025/1226</link>
<guid>https://eprint.iacr.org/2025/1226</guid>
<content:encoded><![CDATA[
Censorship resilience is a fundamental assumption underlying the security of blockchain protocols. Additionally, the analysis of blockchain security from an economic and game theoretic perspective has been growing in popularity in recent years.
In this work, we present a surprising rational censorship attack on blockchain censorship resilience when we adopt the analysis of blockchain security from a game theoretic lens and assume all users are rational. 
In our attack, a colluding group with sufficient voting power censors the remainder nodes such that the group alone can gain all the rewards from maintaining the blockchain.
We show that if nodes are rational, coordinating this attack just requires a public read and write blackboard and we formally model the attack using a game theoretic framework.
Furthermore, we note that to ensure the success of the attack, nodes need to know the total true voting power held by the colluding group.
We prove that the strategy to join the rational censorship attack and also for nodes to honestly declare their power is a subgame perfect equilibrium in the corresponding extensive form game induced by our attack.
Finally, we discuss the implications of the attack on blockchain users and protocol designers as well as some potential countermeasures.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 07:34:40 +0000</pubDate>
</item>
<item>
<title>Baloo: Nearly Optimal Lookup Arguments</title>
<link>https://eprint.iacr.org/2022/1565</link>
<guid>https://eprint.iacr.org/2022/1565</guid>
<content:encoded><![CDATA[
We present Baloo, a protocol for lookup tables where the prover work is linear on the number of lookups and independent of the table size. Baloo is built over previous lookup arguments, and the framework for SNARKs from Ràfols and Zapico (CRYPTO 21).
Our protocol supports commit-and-prove expansions: the prover selects the subtable containing the elements used in the lookup, that is unknown to the verifier, commits to it and later proves its relation with the committed elements. This feature makes Baloo especially suitable for proving input-output relations on hash functions, and in particular to instantiate the Ethereum Virtual Machine (EVM).
]]></content:encoded>
<pubDate>Thu, 10 Nov 2022 11:21:50 +0000</pubDate>
</item>
<item>
<title>Lattice EPID with Efficient Revocation</title>
<link>https://eprint.iacr.org/2025/1225</link>
<guid>https://eprint.iacr.org/2025/1225</guid>
<content:encoded><![CDATA[
Enhanced Privacy Identification (EPID) is one of the anonymous authentication mechanisms that found their way into the industry, being deployed in billions of chips and standardized at ISO. The linchpin of EPID lies in its decentralized revocation procedure that allows to revoke a signer by simply placing one of its signatures on a signature revocation list SRL. Each new signature must then include a proof that it has been generated with a key different from those used to produce the signatures on the SRL. This proof of non-revocation in current post-quantum schemes either relies on general-purpose NIZKs or on regular zero-knowledge proofs (ZKP) but with a witness dimension linear in the size of the SRL, which leads to large size and/or computational complexity. 
In this paper, we rethink the standard approach of non-revocation so as to avoid its heavy reliance on ZKP. Our construction indeed combines features from different tools (such as Falcon signatures) that are unusual in this context to pull most elements out of the ZKP, leading to significant performance improvements. Providing all these elements unconcealed creates many security challenges for our construction but we yet manage to address all of them and prove security under well-understood lattice assumptions, and in the strong model of Sanders-Traoré (CT-RSA'21) allowing malicious SRLs.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 13:08:06 +0000</pubDate>
</item>
<item>
<title>Revisiting Module Lattice-based Homomorphic Encryption and Application to Secure-MPC</title>
<link>https://eprint.iacr.org/2025/1218</link>
<guid>https://eprint.iacr.org/2025/1218</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) schemes have gained significant popularity in modern privacy-preserving applications across various domains. While research on HE constructions based on learning with errors (LWE) and ring-LWE has received major attention from both cryptographers and software-hardware designers alike, their module-LWE-based counterpart has remained comparatively under-explored in the literature. A recent work provides a module-LWE-based instantiation (MLWE-HE) of the Cheon-Kim-Kim-Song (CKKS) scheme and showcases several of its advantages such as parameter flexibility and improved parallelism. However, a primary limitation of this construction is the quadratic growth in the size of the relinearization keys. Our contribution is two-pronged: first, we present a new relinearization key-generation technique that addresses the issue of quadratic key size expansion by reducing it to linear growth. Second, we extend the application of MLWE-HE in a multi-group homomorphic encryption (MGHE) framework, thereby generalizing the favorable properties of the single-keyed HE to a multi-keyed setting as well as investigating additional flexibility attributes of the MGHE framework.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 06:41:12 +0000</pubDate>
</item>
<item>
<title>SoK: Signatures With Randomizable Keys</title>
<link>https://eprint.iacr.org/2023/1524</link>
<guid>https://eprint.iacr.org/2023/1524</guid>
<content:encoded><![CDATA[
Digital signature schemes with specific properties have recently seen various real-world applications with a strong emphasis on privacy-enhancing technologies. They have been extensively used to develop anonymous credentials schemes and to achieve an even more comprehensive range of functionalities in the decentralized web.

Substantial work has been done to formalize different types of signatures where an allowable set of transformations can be applied to message-signature pairs to obtain new related pairs. Most of the previous work focused on transformations with respect to the message being signed, but little has been done to study what happens when transformations apply to the signing keys. A first attempt to thoroughly formalize such aspects was carried by Derler and Slamanig (ePrint'16, Designs, Codes and Cryptography'19), followed by the more recent efforts by Backes et al. (ASIACRYPT'18) and Eaton et al. (ePrint'23). However, the literature on the topic is vast and different terminology is used across contributions, which makes it difficult to compare related works and understand the range of applications covered by a given construction.

In this work, we present a unified view of signatures with randomizable keys and revisit their security properties. We focus on state-of-the-art constructions and related applications,identifying existing challenges. Our systematization allows us to highlight gaps, open questions and directions for future research on signatures with randomizable keys.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 12:19:53 +0000</pubDate>
</item>
<item>
<title>RingSG: Optimal Secure Vertex-Centric Computation for Collaborative Graph Processing</title>
<link>https://eprint.iacr.org/2025/1209</link>
<guid>https://eprint.iacr.org/2025/1209</guid>
<content:encoded><![CDATA[
Collaborative graph processing refers to the joint analysis of inter-connected graphs held by multiple graph owners. To honor data privacy and support various graph processing algorithms, existing approaches employ secure multi-party computation (MPC) protocols to express the vertex-centric abstraction. Yet, due to certain computation-intensive cryptography constructions, state-of-the-art (SOTA) approaches are asymptotically suboptimal, imposing significant overheads in terms of computation and communication. In this paper, we present RingSG, the first system to attain optimal communication/computation complexity within the MPC-based vertex-centric abstraction for collaborative graph processing. This optimal complexity is attributed to Ring-ScatterGather, a novel computation paradigm that can avoid exceedingly expensive cryptography operations (e.g., oblivious sort), and simultaneously ensure the overall workload can be optimally decomposed into parallelizable and mutually exclusive MPC tasks. Within Ring-ScatterGather, RingSG improves the concrete runtime efficiency by incorporating 3-party secure computation via share conversion, and optimizing the most cost-heavy part using a novel oblivious group aggregation protocol. Finally, unlike prior approaches, we instantiate RingSG into two end-to-end applications to effectively obtain application-specific results from the protocol outputs in a privacy-preserving manner. We developed a prototype of RingSG and extensively evaluated it across various graph collaboration settings, including different graph sizes, numbers of parties, and average vertex degrees. The results show RingSG reduces the system running time of SOTA approaches by up to 15.34× and per-party communication by up to 10.36×. Notably, RingSG excels in processing sparse global graphs collectively held by more parties, consistent with our theoretical cost analysis.
]]></content:encoded>
<pubDate>Sat, 28 Jun 2025 03:25:17 +0000</pubDate>
</item>
<item>
<title>BitBatSPIR: Efficient Batch Symmetric Private Information Retrieval from PSI</title>
<link>https://eprint.iacr.org/2025/1201</link>
<guid>https://eprint.iacr.org/2025/1201</guid>
<content:encoded><![CDATA[
Private Information Retrieval (PIR) allows a client to retrieve an entry from a database held by a server without leaking which entry is being requested. Symmetric PIR (SPIR) is a stronger variant of PIR with database privacy so that the client knows nothing about the database other than the retrieved entry.

This work studies SPIR in the batch setting (BatchSPIR), where the client wants to retrieve multiple entries. In particular, we focus on the case of bit entries, which has important real-world applications. We set up the connection between bit-entry information retrieval and set operation, and propose a black-box construction of BatchSPIR from Private Set Intersection (PSI). By applying an efficient PSI protocol with asymmetric set sizes, we obtain our BatchSPIR protocol named $\mathsf{BitBatSPIR}$. We also introduce several optimizations for the underlying PSI. These optimizations improve the efficiency of our concrete BatchSPIR construction as well as the PSI protocol.

We implement $\mathsf{BitBatSPIR}$ and compare the performance with the state-of-the-art PIR protocol in the batch setting. Our experimental results show that $\mathsf{BitBatSPIR}$ not only achieves a stronger security guarantee (symmetric privacy) but also has a better performance for large databases, especially in the Wide Area Network (WAN) setting.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 09:25:51 +0000</pubDate>
</item>
<item>
<title>Tricycle: Private Transformer Inference with Tricyclic Encodings</title>
<link>https://eprint.iacr.org/2025/1200</link>
<guid>https://eprint.iacr.org/2025/1200</guid>
<content:encoded><![CDATA[
The growing adoption of Large Language Models in privacy-sensitive domains necessitates secure inference mechanisms that preserve data confidentiality. Homomorphic encryption offers a promising pathway by enabling computation on encrypted inputs, yet existing approaches struggle to scale efficiently to full transformer models due to limitations in packing schemes, which must efficiently support a wide range of operations, including matrix multiplications, row-wise nonlinear operations, and self-attention. In this work, we present Tricycle, a framework for private transformer inference built on our novel packing scheme, called tricyclic encodings, which are designed to efficiently support these core operations. Tricyclic encodings are a generalization of bicyclic encodings, enabling privacy-preserving batch matrix multiplications with optimal multiplicative depth in order to facilitate parallelized multi-head self-attention. We optimize our matrix multiplications by incorporating Baby-Step Giant-Step optimizations to reduce ciphertext rotations and presenting new ciphertext-plaintext matrix multiplication techniques that relax prior limitations. A further contribution of our work is a lightweight and effective approach for stabilizing the softmax function via statistical max estimation. Our end-to-end implementation on a BERT-Tiny model shows that Tricycle achieves a \(1.5 \times\) to \(3 \times\) speedup over previous approaches, marking a step toward practical and scalable private LLM inference without sacrificing model fidelity.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 07:40:55 +0000</pubDate>
</item>
<item>
<title>Private coins extension with verifiable encryption</title>
<link>https://eprint.iacr.org/2025/1194</link>
<guid>https://eprint.iacr.org/2025/1194</guid>
<content:encoded><![CDATA[
This paper introduces a protocol for verifiable encryption of values committed using Pedersen commitments. It enables a recipient to decrypt the hidden amount while proving its consistency with the original commitment, without revealing the value publicly. The construction combines symmetric encryption with zero-knowledge proofs and is made non-interactive via the Fiat-Shamir heuristic. The protocol is particularly useful in blockchain settings where confidential but verifiable value transfers are required.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 10:39:02 +0000</pubDate>
</item>
<item>
<title>Arithmetic PCA for Encrypted Data</title>
<link>https://eprint.iacr.org/2023/1544</link>
<guid>https://eprint.iacr.org/2023/1544</guid>
<content:encoded><![CDATA[
Reducing the size of large dimensional data is a critical task in machine learning (ML) that often involves using principal component analysis (PCA). In privacy-preserving ML, data confidentiality is of utmost importance, and reducing data size is a crucial way to cut overall costs.

This work focuses on minimizing the number of normalization processes in the PCA algorithm, which is a costly procedure in encrypted PCA. By modifying Krasulina's algorithm, non-polynomial operations were eliminated, except for a single delayed normalization at the end.

Our PCA algorithm demonstrated similar performance to conventional PCA algorithms in face recognition applications. We also implemented it using the CKKS (Cheon-Kim-Kim-Song) homomorphic encryption scheme and obtained the first 6 principal components of a 128$\times$128 real matrix in 7.85 minutes using 8 threads.
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 01:02:47 +0000</pubDate>
</item>
<item>
<title>PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection</title>
<link>https://eprint.iacr.org/2025/1192</link>
<guid>https://eprint.iacr.org/2025/1192</guid>
<content:encoded><![CDATA[
In digital advertising, accurate measurement is essential for optimiz- ing ad performance, requiring collaboration between advertisers and publishers to compute aggregate statistics—such as total conver- sions—while preserving user privacy. Traditional secure two-party computation methods allow joint computation on single-identifier data without revealing raw inputs, but they fall short when mul- tidimensional matching is needed and leak the intersection size, exposing sensitive information to privacy attacks.
This paper tackles the challenging and practical problem of multi- identifier private user profile matching for privacy-preserving ad measurement, a cornerstone of modern advertising analytics. We introduce a comprehensive cryptographic framework leveraging re- versed Oblivious Pseudorandom Functions (OPRF) and novel blind key rotation techniques to support secure matching across multiple identifiers. Our design prevents cross-identifier linkages and in- cludes a differentially private mechanism to obfuscate intersection sizes, mitigating risks such as membership inference attacks.
We present a concrete construction of our protocol that achieves both strong privacy guarantees and high efficiency. It scales to large datasets, offering a practical and scalable solution for privacy- centric applications like secure ad conversion tracking. By combin- ing rigorous cryptographic principles with differential privacy, our work addresses a critical need in the advertising industry, setting a new standard for privacy-preserving ad measurement frameworks.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 03:08:14 +0000</pubDate>
</item>
<item>
<title>Performance and Privacy: A Low-Latency Secure Anonymous Authentication Protocol with OPRF</title>
<link>https://eprint.iacr.org/2025/1189</link>
<guid>https://eprint.iacr.org/2025/1189</guid>
<content:encoded><![CDATA[
erforming privacy-preserving queries, particularly anonymous authentication, against large-scale datasets presents critical tradeoffs between security, latency, scalability. Existing cryptographic solutions often impose linear 
computation or communication overheads. This paper introduces a novel, 
efficient protocol for secure anonymous authentication, uniquely combining matrix partitioning via hash prefixes with Oblivious Pseudorandom Functions in a 
three-server semi-honest model. Crucially, compared to our previous work published at TrustCom 2024, this enhanced protocol eliminates the dependency on a 
designated fully trusted server, achieving security when any single server is corrupted. Furthermore, our protocol demonstrates significant performance improvements over current state-of-the-art methods. It achieves sub-linear online 
communication complexity. Evaluations show that for datasets of size 𝑚 ≈ 106
, 
our protocol reduces online communication by at least 30% compared to other 
sub-linear schemes, while maintaining competitive online computation times. Security is proven via simulation, and comprehensive experiments confirm practicality for datasets up to 𝑚 = 10^8
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 05:10:01 +0000</pubDate>
</item>
<item>
<title>Unconditional Individual Verifiability with Receipt Freeness via Post-Cast Isolation</title>
<link>https://eprint.iacr.org/2025/1186</link>
<guid>https://eprint.iacr.org/2025/1186</guid>
<content:encoded><![CDATA[
We introduce a trapdoorless tracker construction for electronic voting that fundamentally reimagines verifiability through information flow control. Unlike existing E2E verifiable systems where receipt-freeness compromises individual verifiability, our approach achieves both simultaneously by requiring only temporary isolation of the voting calculator between ballot casting and verification—when voters enter unique challenges to compute trackers for locating their votes on the public tally board. Our construction leverages perfectly hiding Pedersen commitments and a unique tracker challenge mechanism to simultaneously achieve unconditional individual verifiability, practical everlasting privacy, and receipt-freeness while relying only on standard cryptographic assumptions. When verification failures occur, our system provides transparent accountability by precisely identifying whether the voting calculator or voting device is responsible. The system maintains security even with partial compliance with isolation procedures and offers robust protection against various adversaries while requiring minimal trust assumptions.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 16:38:22 +0000</pubDate>
</item>
<item>
<title>zkGPT: An Efficient Non-interactive Zero-knowledge Proof Framework for LLM Inference</title>
<link>https://eprint.iacr.org/2025/1184</link>
<guid>https://eprint.iacr.org/2025/1184</guid>
<content:encoded><![CDATA[
Large Language Models (LLMs) are widely employed for their ability to generate human-like text. However, service providers may deploy smaller models to reduce costs, potentially deceiving users. Zero-Knowledge Proofs (ZKPs) offer a solution by allowing providers to prove LLM inference without compromising the privacy of model parameters. Existing solutions either do not support LLM architectures or suffer from significant inefficiency and tremendous overhead. To address this issue, this paper introduces several new techniques. We propose new methods to efficiently prove linear and non-linear layers in LLMs, reducing computation overhead by orders of magnitude. To further enhance efficiency, we propose constraint fusion to reduce the overhead of proving non-linear layers and circuit squeeze to improve parallelism. We implement our efficient protocol, specifically tailored for popular LLM architectures like GPT-2, and deploy optimizations to enhance performance. Experiments show that our scheme can prove GPT-2 inference in less than 25 seconds. Compared with state-of-the-art systems such as Hao et al. (USENIX Security'24) and ZKML (Eurosys'24), our work achieves nearly $279\times$ and $185\times$ speedup, respectively.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 09:05:26 +0000</pubDate>
</item>
<item>
<title>Outsourced Cloud Data Privacy-Preserving Framework: An Efficient Broadcast Encrypted Search Realization</title>
<link>https://eprint.iacr.org/2024/761</link>
<guid>https://eprint.iacr.org/2024/761</guid>
<content:encoded><![CDATA[
The development of cloud networks facilitates data outsourcing, sharing, and storage, but it has also raised several security concerns. Public key authenticated encryption with keyword search (PAEKS) enables the encrypted search over cloud data while resisting the insider keyword guessing attacks (IKGAs). However, existing PAEKS schemes are limited to a single receiver, restricting application prospects in cloud networks. In addition, quantum computing attacks and key leakage issues further threaten data security, which has attracted extensive attention from researchers. Therefore, designing an encrypted search scheme to resist the above-mentioned attacks is still far-reaching. In this paper, we first propose BroSearch, an outsourced data privacy-preserving framework through efficient broadcast encrypted search for cloud networks. It utilizes lattice sampling algorithms to authenticate the keyword and offers searchability over broadcasting ciphertext while enjoying IKGAs-resistance in a quantum setting. To get around key leakage issues, we then incorporate the minimal cover set technique and lattice basis extension algorithm to construct FS-BroSearch as an enhanced version. Furthermore, we give a rigorous security analysis and a comprehensive performance evaluation of BroSearch and FS-BroSearch. Specifically, BroSearch consumes only 61.11%, 81.82%, and 83.33% of the execution time compared to prior art in terms of ciphertext calculation, trapdoor generation, and search procedures, which is practical and efficient in cloud networks.
]]></content:encoded>
<pubDate>Sat, 18 May 2024 08:23:59 +0000</pubDate>
</item>
<item>
<title>UOV-Based Verifiable Timed Signature Scheme</title>
<link>https://eprint.iacr.org/2025/1181</link>
<guid>https://eprint.iacr.org/2025/1181</guid>
<content:encoded><![CDATA[
Verifiable Timed Signatures (VTS) are cryptographic primitives that enable the creation of a signature that can only be retrieved after a specific time delay, while also providing verifiable evidence of its existence. This framework is particularly useful in blockchain applications. Current VTS schemes rely on signature algorithms such as BLS, Schnorr, and ECDSA, which are vulnerable to quantum attacks due to the vulnerability of the discrete logarithm problem to Shor's Algorithm. We introduce VT-UOV, a novel VTS scheme based on the Salt-Unbalanced Oil and Vinegar (Salt-UOV) Digital Signature Algorithm. As a multivariate polynomial-based cryptographic primitive, Salt-UOV provides strong security against both classical and quantum adversaries. Adapting Salt-UOV into the VTS framework requires addressing challenges such as complex parameters instead of a integer, the computational complexity of solving multivariate equations, and the integration of Time-Lock Puzzles (TLPs) for enforcing delayed signature generation. Our experimental results show that VT-UOV exhibits a unique performance profile among existing VTS constructions. This paper offers a detailed exploration of the VT-UOV scheme and its overall security and performance properties.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 22:41:36 +0000</pubDate>
</item>
<item>
<title>Efficient Constant-Size Linkable Ring Signatures for Ad-Hoc Rings via Pairing-Based Set Membership Arguments</title>
<link>https://eprint.iacr.org/2025/1174</link>
<guid>https://eprint.iacr.org/2025/1174</guid>
<content:encoded><![CDATA[
Linkable Ring Signatures (LRS) allow users to anonymously sign messages on behalf of ad-hoc rings, while ensuring that multiple signatures from the same user can be linked. This feature makes LRS widely used in privacy-preserving applications like e-voting and e-cash. To scale to systems with large user groups, efficient schemes with short signatures and fast verification are essential. Recent works, such as DualDory (ESORICS’22) and LLRing (ESORICS’24), improve verification efficiency through offline precomputations but rely on static rings, limiting their applicability in ad-hoc ring scenarios. Similarly, constant-size ring signature schemes based on accumulators face the same limitation.

In this paper, we propose a framework for constructing constant-size LRS suitable for large ad-hoc rings. We introduce a novel pairing-based Set Membership Argument (SMA) with a proof size of only three group elements. By leveraging KZG polynomial commitments, we optimize the verification to require only constant group exponentiations and pairings, as well as linear field multiplications. Utilizing the SMA, our framework achieves constant-size signatures with verification dominated by linear field operations, outperforming existing schemes that require linear group exponentiations in ad-hoc ring settings. Moreover, it exhibits strong scalability: (i) compatibility with any PKI-based cryptosystem and (ii) scoped linkability, enabling flexible definitions of linking scope.

We instantiate our framework using a discrete logarithm public key structure. On the $BN254$ curve, our signature size is fixed at 687 bytes, which to our best knowledge is the shortest LRS for ring sizes larger than 32. For a ring size of 1024, our verification cost is only 10.4 ms, achieving 48.6×, 2.6×–467×, 7.9×–13.2×, and 2.2×–102.5× improvements over Omniring (CCS’19), DualDory (with and without precomputation), LLRing-DL (with and without precomputation), and LLRing-P (with and without precomputation), respectively. Moreover, this performance gap continues to grow as the ring size increases.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:18:42 +0000</pubDate>
</item>
<item>
<title>The Effectiveness of Differential Privacy in Real-world Settings:  A Metrics-based Framework to help Practitioners Visualise and Evaluate $\varepsilon$</title>
<link>https://eprint.iacr.org/2025/1173</link>
<guid>https://eprint.iacr.org/2025/1173</guid>
<content:encoded><![CDATA[
Differential privacy (DP) has emerged as a preferred solution for privacy-preserving data analysis, having been adopted by several leading Internet companies. DP is a privacy-preserving mechanism that protects against re-identification of individuals within aggregated datasets. It is known that the privacy budget $\varepsilon$ determines the trade-off between privacy and utility. In this paper, we propose the use of novel set of metrics and an easy-to-implement, step-by-step framework to facilitate the implementation of the DP mechanism on real-world datasets and guide the selection of $\varepsilon$ based on desired accuracy vs utility trade-off. Currently, for a given query there is no widely accepted methodology on how to select $\varepsilon$ and choose the best DP mechanism that offers an optimal trade-off between privacy and utility. In order to address this gap, we perform experiments by considering three real-world datasets, aiming to identify optimal $\varepsilon$ and suitable mechanisms (Laplace or Gaussian) based on privacy utility trade-off as per use case for the commonly used count, sum and average queries for each dataset. Based on our experiment results, we observe that using our metric and framework, one can analyse noise distribution charts of multiple queries, and choose the suitable $\varepsilon$ and the DP mechanism for achieving a balance between privacy and utility. Additionally, we show that the optimal $\varepsilon$ depends on the particular query, desired accuracy and context in which DP is implemented, which suggests that an arbitrary, a-prior selection of $\varepsilon$ cannot provide adequate results. Our framework prioritises the plotting and visualisation of values and results in the DP analysis, making its adoption easy for a wider audience.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:05:25 +0000</pubDate>
</item>
<item>
<title>Guarding the Signal: Secure Messaging with Reverse Firewalls</title>
<link>https://eprint.iacr.org/2025/1172</link>
<guid>https://eprint.iacr.org/2025/1172</guid>
<content:encoded><![CDATA[
Secure messaging protocols allow users to communicate asynchronously over untrusted channels with strong guarantees of privacy, authenticity, forward secrecy, and post-compromise security. However, traditional security analyses of these protocols assume complete trust in the hardware and software of honest participants, overlooking a significant class of real-world threats known as subversion attacks. These attacks alter cryptographic algorithms to compromise security, by exfiltrating secrets or creating vulnerabilities that are often undetected.

The notion of reverse firewalls (EC'15), aims at protecting against subversion attacks by introducing a third party, called a "reverse firewall" (RF), which sits between a party and the outside world and modifies its  outgoing and incoming messages in a way such that, even if the party's machine has been corrupted (in a way that maintains functionality), security is still preserved. Importantly, the firewall shares no private information with the parties, and parties put no more trust in the firewall than they do in the communication channel. In this work, we address the existing gap in secure messaging and subversion attacks by presenting several key contributions: 

- We design the first subversion-resilient secure messaging protocol based on the model of RF. Our protocol is based on the Signal protocol---the current state-of-the-art in two-party secure messaging, though it lacks subversion resilience---and achieves subversion resilience with only constant overhead over Signal. 

- We develop a subversion-resilient version of the X3DH protocol in the RF model. X3DH is a core component that facilitates secure initial key agreement in Signal's protocol. 

- We introduce and formalize the notion of Continuous Key Agreement with Tamper Detection, an essential concept for subversion-resilient secure messaging. Our notion enables parties to continuously agree on keys, even in the presence of active adversaries capable of partially tampering with the key exchange transcript. We present a construction of our notion and prove its subversion resilience in the model of RF.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:02:55 +0000</pubDate>
</item>
<item>
<title>SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models</title>
<link>https://eprint.iacr.org/2025/1162</link>
<guid>https://eprint.iacr.org/2025/1162</guid>
<content:encoded><![CDATA[
Ensuring the security of complex system-on-chips (SoCs) designs is a critical imperative, yet traditional verification techniques struggle to keep pace due to significant challenges in automation, scalability, comprehensiveness, and adaptability. The advent of large language models (LLMs), with their remarkable capabilities in natural language understanding, code generation, and advanced reasoning, presents a new paradigm for tackling these issues. Moving beyond monolithic models, an agentic approach allows for the creation of multi-agent systems where specialized LLMs collaborate to solve complex problems more effectively. Recognizing this opportunity, we introduce SV-LLM, a novel multi-agent assistant system designed to automate and enhance SoC security verification. By integrating specialized agents for tasks like verification question answering, security asset identification, threat modeling, test plan and property generation, vulnerability detection, and simulation-based bug validation, SV-LLM streamlines the workflow. To optimize their performance in these diverse tasks, agents leverage different learning paradigms, such as in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The system aims to reduce manual intervention, improve accuracy, and accelerate security analysis, supporting proactive identification and mitigation of risks early in the design cycle. We demonstrate its potential to transform hardware security practices through illustrative case studies and experiments that showcase its applicability and efficacy.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 11:52:33 +0000</pubDate>
</item>
<item>
<title>On Frontrunning Risks in Batch-Order Fair Systems for Blockchains (Extended Version)</title>
<link>https://eprint.iacr.org/2025/1168</link>
<guid>https://eprint.iacr.org/2025/1168</guid>
<content:encoded><![CDATA[
In timing-sensitive blockchain applications, such as decentralized finance (DeFi), achieving first-come-first-served (FCFS) transaction ordering among decentralized nodes is critical to prevent frontrunning attacks. Themis[CCS'23], a state-of-the-art decentralized FCFS ordering system, has become a key reference point for high-throughput fair ordering systems for real-world blockchain applications, such as rollup chains and decentralized sequencing, and has influenced the design of several subsequent proposals. In this paper, we critically analyze its core system property of practical batch-order fairness and evaluate the frontrunning resistance claim of Themis.  We present the Ambush attack, a new frontrunning technique that achieves nearly 100% success against the practical batch-order fair system with only a single malicious node and negligible attack costs. This attack causes a subtle temporary information asymmetry among nodes, which is allowed due to the heavily optimized communication model of the system. A fundamental trade-off we identify is a challenge in balancing security and performance in these systems; namely, enforcing timely dissemination of transaction information among nodes (to mitigate frontrunning) can easily lead to non-negligible network overheads (thus, degrading overall throughput performance). We show that it is yet possible to balance these two by delaying transaction dissemination to a certain tolerable level for frontrunning mitigation while maintaining high throughput. Our evaluation demonstrates that the proposed delayed gossiping mechanism can be seamlessly integrated into existing systems with only minimal changes.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 07:01:16 +0000</pubDate>
</item>
<item>
<title>Bridging Bitcoin to Second Layers via BitVM2</title>
<link>https://eprint.iacr.org/2025/1158</link>
<guid>https://eprint.iacr.org/2025/1158</guid>
<content:encoded><![CDATA[
A holy grail in blockchain infrastructure is a trustless bridge between Bitcoin and its second layers or other chains. We make progress toward this vision by introducing the first light-client based Bitcoin bridge. At the heart of its design lies BitVM2-core, a novel paradigm that enables arbitrary program execution on Bitcoin, combining Turing-complete expressiveness with the security of Bitcoin consensus. BitVM2-bridge advances prior approaches by reducing the trust assumption from an honest majority (t-of-n) to existential honesty (1-of-n) during setup. Liveness is guaranteed with only one rational operator, and any user can act as a challenger, enabling permissionless verification. A production-level implementation of BitVM2 has been developed and a full challenge verification has been executed on the Bitcoin mainnet.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 20:55:16 +0000</pubDate>
</item>
<item>
<title>Privacy-aware White and Black List Searching for Fraud Analysis</title>
<link>https://eprint.iacr.org/2025/1153</link>
<guid>https://eprint.iacr.org/2025/1153</guid>
<content:encoded><![CDATA[
In many areas of cybersecurity, we require access to Personally Identifiable Information (PII), such as names, postal addresses and email addresses. Unfortunately, this can lead to data breaches, especially in relation to data compliance regulations such as GDPR. An Internet Protocol (IP) address is an identifier that is assigned to a networked device to enable it to communicate over networks that use IP. Thus, in applications which are privacy-aware, we may aim to hide the IP address while aiming to determine if the address comes from a blacklist. One solution to this is to use homomorphic encryption to match an encrypted version of an IP address to a blacklisted network list. This matching allows us to encrypt the IP address and match it to an encrypted version of a blacklist. In this paper, we use the OpenFHE library \cite{OpenFHE} to encrypt network addresses with the BFV homomorphic encryption scheme. In order to assess the performance overhead of BFV, we implement a matching method using the OpenFHE library and compare it against partial homomorphic schemes, including Paillier, Damgard-Jurik, Okamoto-Uchiyama, Naccache-Stern and Benaloh. The main findings are that the BFV method compares favourably against the partial homomorphic methods in most cases.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 12:06:56 +0000</pubDate>
</item>
<item>
<title>ZK-ProVer: Proving Programming Verification in Non-Interactive Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/1152</link>
<guid>https://eprint.iacr.org/2025/1152</guid>
<content:encoded><![CDATA[
Program verification ensures software correctness through formal methods but incurs substantial computational overhead. It typically encodes program execution into formulas that are verified using a SAT solver and its extensions. However, this process exposes sensitive program details and requires redundant computations when multiple parties need to verify correctness. To overcome these limitations, zero-knowledge proofs (ZKPs) generate compact, reusable proofs with fast verification times, while provably hiding the program’s internal logic. We propose a two-phase zero-knowledge protocol that hides program implementation details throughout verification. Phase I uses a zero-knowledge virtual machine (zkVM) to encode programs into SAT formulas without
revealing their semantics. Phase II employs the encoding of resolution proofs for UNSAT instances and circuits for satisfying assignment verification for SAT instances through PLONKish circuits. Evaluation on the Boolector benchmark demonstrates that our method achieves verification time that is efficient and is independent of clause width for UNSAT instances and formula size for SAT instances. The resulting ZKPs enable efficient verification of program properties while providing strong end-to-end privacy guarantees.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 11:45:40 +0000</pubDate>
</item>
<item>
<title>Lightweight Sorting in Approximate Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1150</link>
<guid>https://eprint.iacr.org/2025/1150</guid>
<content:encoded><![CDATA[
Sorting encrypted values is an open research problem that plays a crucial role in the broader objective of providing efficient and practical privacy-preserving online services. 
The current state of the art work by Mazzone, Everts, Hahn and Peter (USENIX Security '25) proposes efficient algorithms for ranking, indexing and sorting based on the CKKS scheme, which deviates from the compare-and-swap paradigm, typically used by sorting networks, using a permutation-based approach. This allows to build shallow sorting circuits in a very simple way.
In this work, we follow up their work and explore different approaches to approximate the nonlinear functions required by the encrypted circuit (where only additions and multiplications can be evaluated), and we propose simpler solutions that allow for faster computations and smaller memory requirements. 

In particular, we drastically reduce the upper bound on the depth of the circuits from 65 to 20, making our circuits usable in relatively small rings such as $N=2^{16}$, even for sorting values while preserving up to three decimal places. As an example, our circuit sorts 128 values with duplicates in roughly 20 seconds on a laptop, using roughly 1 GB of memory, maintaining a precision of 0.01.
Furthermore, we propose an implementation of a swap-based bitonic network that is not based on approximations of the sgn$(x)$ function, which scales linearly with the number of values, useful when the number of available slots is small.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 11:01:28 +0000</pubDate>
</item>
<item>
<title>Jigsaw: Doubly Private Smart Contracts</title>
<link>https://eprint.iacr.org/2025/1147</link>
<guid>https://eprint.iacr.org/2025/1147</guid>
<content:encoded><![CDATA[
Privacy is a growing concern for smart contracts on public ledgers. 
In recent years, we have seen several practical systems for privacy-preserving smart contracts, but they only target privacy of on-chain data, and rely on trusted off-chain parties with user data -- for instance, a decentralized finance application (e.g. exchange) relies on an off-chain matching engine to process client orders that get settled on-chain, where privacy only applies to the on-chain data.
Privacy conscious users demand stronger notions of privacy, for their identity and their data, from all other parties in the ecosystem.

We propose a novel framework for smart contracts that ensures {\em doubly private}
execution, addressing {both on-chain and off-chain privacy} requirements. 
In our framework, clients submit their requests in a privacy-preserving manner to a group of (potentially mutually untrusting) servers. These servers collaboratively match client requests without learning any information about the data or identities of the clients.

We then present {\em Jigsaw}, an efficient cryptographic realization of our proposed framework. {\em Jigsaw} builds on the ZEXE architecture (Bowe et al., S\&amp;P 2020), which leverages zkSNARKs, and extends Collaborative zkSNARKs (Ozdemir and Boneh, USENIX 2022) to enable proof generation by a group of servers.

In Jigsaw, we introduce a novel collaborative zkSNARK construction that achieves low latency and reduced proving time, and showcase these advantages over sample applications ranging from trading in a decentralized exchange to auctions and voting.
Our experiments demonstrate that {\em Jigsaw} is roughly $40-50$x faster in proof generation and uses orders-of-magnitude less bandwidth than the naive approach of using off-the-shelf Collaborative zkSNARKs.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 04:31:56 +0000</pubDate>
</item>
<item>
<title>QV-net: Decentralized Self-Tallying Quadratic Voting with Maximal Ballot Secrecy</title>
<link>https://eprint.iacr.org/2025/1146</link>
<guid>https://eprint.iacr.org/2025/1146</guid>
<content:encoded><![CDATA[
Decentralized e-voting enables secure and transparent elections without relying on trusted authorities, with blockchain emerging as a popular platform. It has compelling applications in Decentralized Autonomous Organizations (DAOs), where governance relies on voting with blockchain-issued tokens. Quadratic voting (QV), a mechanism that mitigates the dominance of large token holders, has been adopted by many DAO elections to enhance fairness. However, current QV systems deployed in practice publish voters' choices in plaintext with digital signatures. The open nature of all ballots comprises voter privacy, potentially affecting voters' honest participation. Prior research proposes using cryptographic techniques to encrypt QV ballots, but they work in a centralized setting, relying on a trusted group of tallying authorities to administrate an election. However, in DAO voting, there is no trusted third party.   

In this paper, we propose QV Network (QV-net), the first decentralized quadratic voting scheme, in which voters do not need to trust any third party other than themselves for ballot secrecy. QV-net is self-tallying with maximal ballot secrecy. Self-tallying allows anyone to compute election results once all ballots are cast. Maximal ballot secrecy ensures that what each voter learns from QV-net is nothing more than the tally and their own ballot. We provide an open-source implementation of QV-net to demonstrate its practicality based on real-world DAO voting settings, reporting only a few milliseconds for voting and a maximum of 255 milliseconds for tallying.

The exceptional efficiency of QV-net is attributed to the design of two new Zero-Knowledge Argument of Knowledge (ZKAoK) protocols for QV ballot secrecy and integrity. Previous works generally rely on pairing-friendly curves to prove the well-formedness of an encrypted QV ballot. But they incur heavy computation and large data sizes. We tackle the challenges of appropriately formalizing and proving ZKAoK relations for QV without using these curves. Specifically, we develop a succinct ZKAoK to prove a new relation: the sum of squares of a private vector's components equals a private scalar. We also introduce the first aggregated range proof to prove that values committed under different keys fall within their respective ranges. Together, these two new zero-knowledge protocols enable us to build an efficient decentralized QV scheme and are of independent interest.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 03:10:46 +0000</pubDate>
</item>
<item>
<title>Dynamic Group Signatures with Verifier-Local Revocation</title>
<link>https://eprint.iacr.org/2025/1145</link>
<guid>https://eprint.iacr.org/2025/1145</guid>
<content:encoded><![CDATA[
Group Signatures are fundamental cryptographic primitives that allow users to sign a message on behalf of a predefined set of users, curated by the group manager. The security properties ensure that members of the group can sign anonymously and without fear of being framed. In dynamic group signatures, the group manager has finer-grained control over group updates while ensuring membership privacy (i.e., hiding when users join and leave). The only known scheme that achieves standard security properties and membership privacy has been proposed by Backes et al. CCS 2019. However, they rely on an inefficient revocation mechanism that re-issues credentials to all active members during every group update, and users have to rely on a secure and private channel to join the group.
In this paper, we introduce a dynamic group signature that supports verifier-local revocation, while achieving strong security properties, including membership privacy for users joining over a public channel. Moreover, when our scheme is paired with structure-preserving signatures over equivalence class it enjoys a smaller signature size compared to Backes et al. Finally, as a stand-alone contribution we extend the primitive Asynchronous Remote Key Generation (Frymann et al. CCS 2020) with trapdoors and introduce new security properties to capture this new functionality, which is fundamental to the design of our revocation mechanism
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 22:51:47 +0000</pubDate>
</item>
<item>
<title>Parasol Compiler: Pushing the Boundaries of FHE Program Efficiency</title>
<link>https://eprint.iacr.org/2025/1144</link>
<guid>https://eprint.iacr.org/2025/1144</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) is a key technology to enable privacy-preserving computation. While optimized FHE implementations already exist, the inner workings of FHE are technically complex. This makes it challenging, especially for non-experts, to develop highly-efficient FHE programs that can exploit the advanced hardware of today. Although several compilers have emerged to help in this process, due to design choices, they are limited in terms of application support and the efficiency levels they can achieve.

In this work, we showcase how to make FHE accessible to non-expert developers while retaining the performance provided by an expert-level implementation. We introduce Parasol, a novel end-to-end compiler encompassing a virtual processor with a custom Instruction Set Architecture (ISA) and a low-level library that implements FHE operations. Our processor integrates with existing compiler toolchains, thereby providing mainstream language support. We extract parallelism at multiple levels via our processor design and its computing paradigm. Specifically, we champion a Circuit Bootstrapping (CBS)-based paradigm, enabling efficient FHE circuit composition with multiplexers. Furthermore, Parasol’s underlying design highlights the benefits of expressing FHE computations at a higher level—producing highly compact program representations. Our experiments demonstrate the superiority of Parasol, in terms of runtime (up to 17x faster), program size (up to 22x smaller), and compile time (up to 32x shorter) compared to the current state-of-the-art. We expect the FHE computing paradigm underlying Parasol to attract future interest since it exposes added parallelism for FHE accelerators to exploit.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 18:51:55 +0000</pubDate>
</item>
<item>
<title>LZKSA: Lattice-Based Special Zero-Knowledge Proofs for Secure Aggregation's Input Verification</title>
<link>https://eprint.iacr.org/2025/1141</link>
<guid>https://eprint.iacr.org/2025/1141</guid>
<content:encoded><![CDATA[
In many fields, the need to securely collect and aggregate data from distributed systems is growing. However, designs that rely solely on encrypted data transmission make it difficult to trace malicious users. To address this challenge, we have enhanced the secure aggregation (SA) protocol proposed by Bell et al. (CCS 2020) by introducing verification features that ensure compliance with user inputs and encryption processes while preserving data privacy. We present LZKSA, a quantum-safe secure aggregation system with input verification. LZKSA employs seven zero-knowledge proof (ZKP) protocols based on the Ring Learning with Errors problem, specifically designed for secure aggregation. These protocols verify whether users have correctly used SA keys and their $L_{\infty}$, $L_2$ norms and cosine similarity of data, meet specified constraints, to exclude malicious users from current and future aggregation processes. The specialized ZKPs we propose significantly enhance proof efficiency. In practical federated learning scenarios, our experimental evaluations demonstrate that the proof generation time for $L_{\infty}$ and $L_2$ constraints is reduced to about $10^{-3}$ of that required by the current state-of-the-art method, RoFL (S\&amp;P 2023), and ACORN (USENIX 2023). For example, the proof generation/verification time of RoFL, ACORN and LZKSA for $L_{\infty}$ is 94s/29.9s, 78.7s/33.9s, and 0.02s/0.0062s for CIFAR10, respectively.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 04:11:00 +0000</pubDate>
</item>
<item>
<title>ZK-NR: A Layered Cryptographic Architecture for  Explainable Non-Repudiation</title>
<link>https://eprint.iacr.org/2025/1138</link>
<guid>https://eprint.iacr.org/2025/1138</guid>
<content:encoded><![CDATA[
This paper introduces ZK-NR, a modular cryptographic protocol designed to ensure privacy-preserving non-repudiation in the co-production of digital public services. By integrating Merkle commitments, zero-knowledge proofs (STARKs), threshold BLS signatures, and post-quantum Dilithium authentication, ZK-NR enables the creation of secure, verifiable, and auditable evidence across decentralized infrastructures. Unlike traditional digital signatures or blockchain-based logs, ZK-NR provides formally verifiable attestations without disclosing sensitive content, making it suitable for public finance, e-government, and regulated digital ecosystems. The protocol is modeled in Tamarin and implemented as a proof-of-concept using open cryptographic tools. This contribution offers a reproducible foundation for future infrastructures requiring long-term trust, data minimization, and legal admissibility, particularly in contexts where citizens and institutions share responsibility for digital evidence. ZK-NR addresses the tension between confidentiality and accountability, providing an interoperable and future-ready layer for trustworthy public service delivery.
This preliminary work focuses on architectural composition and implementation feasibility. It does not include formal security proofs.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 19:55:21 +0000</pubDate>
</item>
<item>
<title>Succinct Computational Secret Sharing</title>
<link>https://eprint.iacr.org/2023/955</link>
<guid>https://eprint.iacr.org/2023/955</guid>
<content:encoded><![CDATA[
A secret-sharing scheme enables a dealer to share a secret $s$ among $n$ parties such that only authorized subsets of parties, specified by a monotone access structure $f:\{0,1\}^n\to\{0,1\}$, can reconstruct $s$ from their shares. Other subsets of parties learn nothing about $s$.

The question of minimizing the (largest) share size for a given $f$ has been the subject of a large body of work. However, in most existing constructions for general access structures $f$, the share size is not much smaller than the size of some natural computational representation of $f$, a fact that has often been referred to as the ``representation size barrier'' in secret sharing.

In this work, we initiate a systematic study of succinct computational  secret sharing (SCSS), where the secrecy requirement is computational and the goal is to substantially beat the representation size barrier. We obtain the following main results.

(1) SCSS via Projective PRGs. We introduce the notion of a *projective PRG*, a pseudorandom generator for which any subset of the output bits can be revealed while keeping the other output bits hidden, using a *short* projective seed. We construct projective PRGs with different levels of succinctness under a variety of computational assumptions, and apply them towards constructing SCSS for graph access structures, monotone CNF formulas, and (less succinctly) useful subclasses of monotone circuits and branching programs. Most notably, under the sub-exponential RSA assumption, we obtain a SCSS scheme that, given an arbitrary access structure $f$, represented by a truth table of size $N=2^n$, produces shares of size polylog(N)=\poly(n) in time $\tilde O(N)$. For comparison, the share size of the best known information-theoretic schemes is $O(N^{0.58})$.

(2) SCSS via One-way Functions. Under the (minimal) assumption that one-way functions exist, we obtain a near-quadratic separation between the total share size of computational and information-theoretic secret sharing. This is the strongest separation one can hope for, given the state of the art in secret sharing lower bounds. We also construct SCSS schemes from one-way functions for useful classes of access structures, including forbidden graphs and monotone DNF formulas.  This leads to constructions of fully-decomposable conditional disclosure of secrets (also known as privacy-free garbled circuits) for general functions, represented by a truth table of size $N=2^n$, with share size polylog(N) and computation time $\tilde O(N)$, assuming sub-exponentially secure one-way functions.
]]></content:encoded>
<pubDate>Sun, 18 Jun 2023 17:33:05 +0000</pubDate>
</item>
<item>
<title>Reusable Designated Verifier NIZK from Lossy Trapdoor Functions</title>
<link>https://eprint.iacr.org/2025/1125</link>
<guid>https://eprint.iacr.org/2025/1125</guid>
<content:encoded><![CDATA[
Understanding the minimal assumptions necessary for constructing non-interactive zero-knowledge arguments (NIZKs) for NP and placing it within the hierarchy of cryptographic primitives has been a central goal in cryptography. Unfortunately, there are very few examples of ``generic'' constructions of NIZKs or any of its natural relaxations.

In this work, we consider the relaxation of NIZKs to the designated-verifier model (DV-NIZK) and present a new framework for  constructing (reusable) DV-NIZKs for NP generically from  lossy trapdoor functions and PRFs computable by polynomial-size branching programs (a class that includes NC1). Previous ``generic'' constructions  of DV-NIZK for NP from standard primitives relied either on (doubly-enhanced) trapdoor permutations or on a public-key encryption scheme plus a KDM-secure secret key encryption scheme.

Notably, our DV-NIZK framework achieves statistical zero-knowledge. To our knowledge, this is the first DV-NIZK construction from any ``generic" standard assumption with statistical zero-knowledge that does not already yield a NIZK. 

A key technical component of our construction is an efficient, unconditionally secure secret sharing scheme for non-monotone functions with randomness recovery for all polynomial-size branching programs. As an independent contribution we present an incomparable randomness recoverable (monotone) secret sharing for NC1 in a model with trusted setup that guarantees computational privacy assuming one-way functions. We believe that these primitives will be useful in related contexts in the future.
]]></content:encoded>
<pubDate>Sat, 14 Jun 2025 17:30:36 +0000</pubDate>
</item>
<item>
<title>Toxic Decoys: A Path to Scaling Privacy-Preserving Cryptocurrencies</title>
<link>https://eprint.iacr.org/2025/1124</link>
<guid>https://eprint.iacr.org/2025/1124</guid>
<content:encoded><![CDATA[
Anonymous cryptocurrencies attracted much attention over the past decade, yet ensuring both integrity and privacy in an open system remains challenging. Their transactions preserve privacy because they do not reveal on which earlier transaction they depend, specifically which outputs of previous transactions are spent. However, achieving privacy imposes a significant storage overhead due to two current limitations. First, the set of potentially unspent outputs of transactions grows indefinitely because the design hides cryptographically which one have been consumed; and, second, additional data must be stored for each spent output to ensure integrity, that is, to prevent that it can be spent again. We introduce a privacy-preserving payment scheme that mitigates these issues by randomly partitioning unspent outputs into fixed-size bins. Once a bin has been referenced in as many transactions as its size, it is pruned from the ledger. This approach reduces storage overhead while preserving privacy. We first highlight the scalability benefits of using smaller untraceability sets instead of considering the entire set of outputs, as done in several privacy-preserving cryptocurrencies. We then formalize the security and privacy notions required for a scalable, privacy-preserving payment system and analyze how randomized partitioning plays a key role in both untraceability and scalability. To instantiate our approach, we provide constructions based on Merkle trees and one based on cryptographic accumulators. We finally show the storage benefits of our scheme and analyze its resilience against large-scale flooding attacks using empirical transaction data.
]]></content:encoded>
<pubDate>Sat, 14 Jun 2025 16:52:16 +0000</pubDate>
</item>
<item>
<title>Strong Secret Sharing with Snitching</title>
<link>https://eprint.iacr.org/2025/1119</link>
<guid>https://eprint.iacr.org/2025/1119</guid>
<content:encoded><![CDATA[
One of the main shortcomings of classical distributed cryptography is its reliance on a certain fraction of participants remaining honest. Typically, honest parties are assumed to follow the protocol and not leak any information, even if behaving dishonestly would benefit them economically. More realistic models used in blockchain consensus rely on weaker assumptions, namely that no large coalition of corrupt parties exists, although every party can act selfishly. This is feasible since, in a consensus protocol, active misbehavior can be detected and "punished" by other parties. However, "information leakage", where an adversary reveals sensitive information via, e.g., a subliminal channel, is often impossible to detect and, hence, much more challenging to handle.

    A recent approach to address this problem was proposed by Dziembowski, Faust, Lizurej, and Mielniczuk (ACM CCS 2024), who introduced a new notion called secret sharing with snitching. This primitive guarantees that as long as no large coalition of mutually trusting parties exists, every leakage of the shared secret produces a "snitching proof" indicating that some party participated in the illegal secret reconstruction. This holds in a very strong model, where mutually distrusting parties use an MPC protocol to reconstruct any information about the shared secret. Such a "snitching proof" can be sent to a smart contract (modeled as a "judge") deployed on the blockchain, which punishes the aving party financially.

    In this paper, we extend the results from the work of CCS'24  by addressing its two main shortcomings. Firstly, we significantly strengthen the attack model by considering the case when mutually distrusting parties can also rely on a trusted third party (e.g., a smart contract). We call this new primitive strong secret sharing with snitching (SSSS). 
    We present an SSSS protocol that is secure in this model. Secondly, unlike in the construction from CCS'24, our protocol does not require the honest parties to perform any MPC computations on hash functions. Besides its theoretical interest, this improvement is of practical importance, as it allows the construction of SSSS from any (even very "MPC-unfriendly") hash function.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 16:06:13 +0000</pubDate>
</item>
<item>
<title>The Pipes Model for Latency Analysis</title>
<link>https://eprint.iacr.org/2025/1116</link>
<guid>https://eprint.iacr.org/2025/1116</guid>
<content:encoded><![CDATA[
Protocols for State-Machine-Replication (sometimes called 'blockchain' protocols)  generally make use of rotating leaders to drive consensus. In typical protocols (henceforth called 'single-sender' protocols), the leader is a single processor responsible for making and disseminating proposals to others. Since the leader acts as a bottleneck, apparently limiting throughput, a recent line of research has investigated the use of 'multi-sender' protocols in which many processors distribute proposals in parallel. Examples include DAG-based protocols such as DAG-Rider, Bullshark, Sailfish, Cordial Miners, Mysticeti, and variants such as Autobahn. However, existing models do not allow for a formal analysis to determine whether these protocols can actually handle higher throughputs than single-sender protocols such as PBFT, Tendermint, and HotStuff.

In this paper, we describe a very simple model that allows for such an analysis. For any given protocol, the model allows one to calculate latency as a function of  network bandwidth, network delays, the number of processors $n$, and the incoming transaction rate. Each protocol has a latency bottleneck: an incoming transaction rate at which latency becomes unbounded over the protocol execution, i.e., a maximum throughput that the protocol can handle without unbounded latency.  

With the aim of building to an analysis for state-of-the-art State-Machine-Replication (SMR) protocols, we begin by considering protocols for simpler primitives, such as Best-effort Broadcast and Reliable Broadcast. For Best-effort Broadcast, we establish a tight lower bound on latency for single-sender and multi-sender protocols when blocks are distributed without the use of techniques such as erasure coding. Perhaps unsurprisingly, a key difference between the single-sender and multi-sender approaches in this case is a factor $n$ in the point at which the latency bottleneck appears. However, for other primitives such as Reliable Broadcast,  our results may be more surprising: the factor $n$ difference now disappears, and maximum throughput for the two approaches differs by a constant factor, while multi-sender approaches will generally have latency that grows more quickly with $n$. For state-of-the-art SMR protocols, the picture that emerges is one with seemingly inherent trade-offs. If one compares single-sender protocols that use pipelining and erasure coding, such as DispersedSimplex, with DAG-based protocols such as Sailfish or Bullshark, the former are seen to have lower latency for a wide range of throughputs, while the benefit of the latter protocols is that they have  a latency bottleneck which is higher by a constant factor.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 13:42:36 +0000</pubDate>
</item>
<item>
<title>High-Throughput Permissionless Blockchain Consensus under   Realistic Network Assumptions</title>
<link>https://eprint.iacr.org/2025/1115</link>
<guid>https://eprint.iacr.org/2025/1115</guid>
<content:encoded><![CDATA[
Throughput, i.e., the amount of payload data processed per unit of
  time, is a crucial measure of scalability for blockchain consensus
  mechanisms.  This paper revisits the design of secure,
  high-throughput proof-of-stake (PoS) protocols in the
  \emph{permissionless} setting.  Existing high-throughput protocols
  are either analyzed using overly simplified network models or are
  designed for permissioned settings, with the task of adapting them
  to a permissionless environment while maintaining both scalability
  and adaptive security (which is essential in permissionless
  environments) remaining an open question. 

  Two particular challenges arise when designing high-throughput
  protocols in a permissionless setting: \emph{message bursts}, where
  the adversary simultaneously releases a large volume of withheld
  protocol messages, and---in the PoS setting---\emph{message
    equivocations}, where the adversary diffuses arbitrarily many
  versions of a protocol message.  It is essential for the security of
  the ultimately deployed protocol that these issues be captured by
  the network model.

  Therefore, this work first introduces a new, realistic network model
  based on the operation of real-world gossip networks---the standard
  means of diffusion in permissionless systems, which may involve
  many thousands of nodes.  The model specifically addresses challenges
  such as message bursts and PoS equivocations and is also of
  independent interest.

  The second and main contribution of this paper is Leios, a
  blockchain protocol that transforms any underlying low-throughput
  base protocol into a blockchain achieving a throughput corresponding
  to a $(1-\delta)$-fraction of the network capacity---while affecting
  latency only by a related constant.  In particular, if the
  underlying protocol has constant expected settlement time, this
  property is retained under the Leios overlay.  Combining Leios with
  any permissionless protocol yields the first near-optimal throughput
  permissionless ``layer-1'' blockchain protocol proven secure under
  realistic network assumptions.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 12:31:55 +0000</pubDate>
</item>
<item>
<title>Sassafras: Efficient Batch Single Leader Election</title>
<link>https://eprint.iacr.org/2023/031</link>
<guid>https://eprint.iacr.org/2023/031</guid>
<content:encoded><![CDATA[
In a single secret leader election (SSLE), a set of participants elect exactly one leader, who remains anonymous until they announce themselves by providing a proof. SSLE protocols are used in proof-of-stake blockchains to elect the leader who publishes the next block. Anonymity of the leader is an important security property, as the leader makes for an attractive target and may be subject to denial-of-service (DOS) attacks.

In this work, we propose a novel single leader election protocol, called Sassafras. We depart from the common approach of shuffling for constructing SSLE and instead employ a ring verifiable random function, which hides the identity of the leader within a ring of participants. Moreover, Sassafras is designed for batch leader elections, in which a single leader is selected for several elections at once. This allows the rate of leader election to match the rate of block production, an often-sought property not met by most SSLE protocols in the literature. We characterize single leader election with batching in the form of an ideal functionality in the Universal Composability (UC) framework and prove that Sassafras realizes this functionality. Sassafras is secure against an adaptive adversary, while achieving a slightly relaxed notion of anonymity for leaders. Sassafras features exceptionally low communication and computational complexity, outperforming other SSLE protocols by an order of magnitude or more.
]]></content:encoded>
<pubDate>Tue, 10 Jan 2023 11:55:15 +0000</pubDate>
</item>
<item>
<title>SEAF: Secure Evaluation on Activation Functions with Dynamic Precision for Secure Two-Party Inference</title>
<link>https://eprint.iacr.org/2025/1111</link>
<guid>https://eprint.iacr.org/2025/1111</guid>
<content:encoded><![CDATA[
Secure evaluation of non-linear functions is one of the most expensive operations in secure two-party computation, particularly for activation functions in privacy preserving machine learning (PPML). This work introduces SEAF, a novel framework for efficient Secure Evaluation on Activation Functions. SEAF is based on the linear approximation approach, but enhances it by introducing two key innovations: Trun-Eq based interval test protocols and linear approximation with dynamic precision, which have the potential for broader applicability. Furthermore, we classify common activation functions into several categories, and present specialized methods to evaluate them using our enhanced techniques. Our implementation of SEAF demonstrates $3.5 \times$ to $5.9 \times$ speedup on activation functions $\mathsf{Tanh}$ and $\mathsf{Sigmoid}$ compared to SirNN (S\&amp;P'21). When applied on $\mathsf{GELU}$, SEAF outperforms Iron (NeurIPS'22) by more than $10 \times$ and Bolt (S\&amp;P'24) by up to $3.4 \times$. For end-to-end secure inference on BERT, the original $\mathsf{GELU}$ accounts for $31.3 \%$ and $22.5 \%$ of the total runtime in Iron and Bolt, respectively. In contrast, our optimized $\mathsf{GELU}$ reduces these proportions to  $4.3 \%$ and $9.8 \%$, eliminating $\mathsf{GELU}$ as a bottleneck in secure inference.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 02:32:35 +0000</pubDate>
</item>
<item>
<title>TEEMS: A Trusted Execution Environment based Metadata-protected Messaging System</title>
<link>https://eprint.iacr.org/2025/1102</link>
<guid>https://eprint.iacr.org/2025/1102</guid>
<content:encoded><![CDATA[
Ensuring privacy of online messaging remains a challenge.  While the contents or data of online communications are often protected by end-to-end encryption, the metadata of communications are not.  Metadata such as who is communicating with whom, how much, and how often, are leaked by popular messaging systems today.

In the last four decades we have witnessed a rich literature of designs towards metadata-protecting communications systems (MPCS).  While recent MPCS works often target metadata-protected messaging systems, no existing construction simultaneously attains four desirable properties for messaging systems, namely (i) low latency, (ii) high throughput, (iii) horizontal scalability, and (iv) asynchronicity.  Existing designs often capture disjoint subsets of these properties.  For example, PIR-based approaches achieve low latency and asynchronicity but have low throughput and lack horizontal scalability, mixnet-based approaches achieve high throughput and horizontal scalability but lack asynchronicity, and approaches based on trusted execution environments (TEEs) achieve high throughput and asynchronicity but lack horizontal scalability.

In this work, we present TEEMS, the first MPCS designed for metadata-protected messaging that simultaneously achieves all four desirable properties. Our distributed TEE-based system uses an oblivious mailbox design to provide metadata-protected messaging.  TEEMS presents novel oblivious routing protocols that adapt prior work on oblivious distributed sorting.  Moreover, we introduce the notion of ID and token channels to circumvent shortcomings of prior designs.  We empirically demonstrate TEEMS' ability to support $2^{20}$ clients engaged in metadata-protected conversations in under 1 s, with 205 cores, achieving an 18× improvement over prior work for latency and throughput, while supporting significantly better scalability and asynchronicity properties.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 11:45:28 +0000</pubDate>
</item>
<item>
<title>Tanuki: New Frameworks for (Concurrently Secure) Blind Signatures from Post-Quantum Groups Actions</title>
<link>https://eprint.iacr.org/2025/1100</link>
<guid>https://eprint.iacr.org/2025/1100</guid>
<content:encoded><![CDATA[
Blind signatures are fundamental cryptographic primitives enabling privacy-preserving authentication and have seen renewed interest in the post-quantum literature. 
Existing efficient constructions predominantly rely on Fischlin’s generic paradigm instantiated over lattice assumptions, while blinding techniques for sigma-protocol-based blind signatures remain sparse beyond lattices. Moreover, achieving provable concurrent security under polynomially many sessions has been a longstanding open challenge for this approach in the post-quantum literature as evidenced by the recent attacks in EC’24 and PKC’24. 


This work broadens the landscape of post-quantum blind signatures by introducing novel techniques and proposing four frameworks based on general cryptographic group actions, without requiring commutativity. Our constructions admit instantiations under diverse post-quantum assumptions, including CSIDH (isogeny-based), LESS (code-based, NIST round-two), and more. These frameworks offer flexible trade-offs in assumptions (from interactive one-more to the standard inversion problem) and key/signature sizes, and culminate in a construction that achieves security under polynomially many concurrent sessions. This enables the first efficient blind signatures from isogenies and codes with provable concurrent security with 3.9 and 56 KB respectively. We also outline several directions for optimization and further instantiations for future work.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 21:02:16 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Accumulator and Application to Anonymous Credential Revocation</title>
<link>https://eprint.iacr.org/2025/1099</link>
<guid>https://eprint.iacr.org/2025/1099</guid>
<content:encoded><![CDATA[
An accumulator is a cryptographic system for compactly representing a set of elements such that every element in the set has a short membership witness. A dynamic accumulator, furthermore, allows elements to be added to and deleted from the accumulator.  Camenisch and Lysyanskaya (CRYPTO'02) constructed the first dynamic accumulator under the strong-RSA assumption and showed how it can be used to enable revocation of anonymous credentials.  In this paper, we give a lattice-based dynamic accumulator tailor-made for enabling revocation of post-quantum anonymous credential systems. As a concrete example, we instantiate our dynamic accumulator on top of the anonymous credential system implemented in the LaZer library (ACM CCS 2024).
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 20:34:27 +0000</pubDate>
</item>
<item>
<title>CuFDFB: Fast and Private Computation on Non-Linear Functions Using FHE</title>
<link>https://eprint.iacr.org/2025/1096</link>
<guid>https://eprint.iacr.org/2025/1096</guid>
<content:encoded><![CDATA[
Privacy-preserving neural network inference using Fully Homomorphic Encryption (FHE) faces significant challenges in efficiently evaluating non-polynomial functions, such as activation functions, which are critical for introducing non-linearity in neural networks. Full-Domain Functional Bootstrap (FDFB) algorithms provide a promising solution by enabling the evaluation of arbitrary functions while simultaneously refreshing ciphertexts to manage noise accumulation. Despite their theoretical advantages, the practicality of FDFB algorithms has been limited by excessive computational overhead, often exceeding 1000 ms per ciphertext, which restricts their scalability for large neural networks.

To overcome the computational bottlenecks of FDFB, we have re-engineered the algorithms for massively parallel execution on GPUs. Our primary contribution is a hierarchical parallelization strategy that exploits concurrency at the thread, stream, and device levels. A key optimization involves the use of CUDA streams to create a data pipeline that effectively mitigates the overhead of memory transfers between the host and device. This optimized architecture achieves a significant speedup of up to 524$\times$ compared to CPU-based implementations. Our implementation maintains full precision for evaluating various activation functions, confirming its viability for large-scale, privacy-preserving machine learning tasks and paving the way for practical FHE-based deep learning.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 15:47:28 +0000</pubDate>
</item>
<item>
<title>On the Concrete Security of BBS/BBS+ Signatures</title>
<link>https://eprint.iacr.org/2025/1093</link>
<guid>https://eprint.iacr.org/2025/1093</guid>
<content:encoded><![CDATA[
BBS/BBS+ signatures are the most promising solution to instantiate practical and lightweight anonymous credentials. They underlie standardization efforts by the W3C and the IRTF. Due to their potential for large scale deployment, it is paramount to understand their concrete security, but a number of questions have been left open by prior works. To this end, the security proofs by Au et al. (SCN '06), Camenisch et al. (TRUST '16), and Tessaro and Zhu (EUROCRYPT '23) show reductions from $q$-SDH in groups of prime order $p$, where $q$ is the number of issued signatures. 
    
    However, these prior works left the possibility open that BBS/BBS+ is "even more secure" than what can be guaranteed by such proofs. Indeed, while the $q$-SDH assumption is subject to an attack that uses $O(\sqrt{p/q})$ group exponentiations (Cheon, EUROCRYPT '06) for several choices of $q$, no attack with a similar complexity appears to affect either of BBS+ and "deterministic" BBS, for which the best known attacks amount to recovering the secret key by breaking the discrete logarithm problem. The assumption that this attack is best possible also seemingly justifies the choice of parameters in practice.

    Our result shows that this expectation is not true. We show new attacks against BBS+ and deterministic BBS which, after seeing $q$ signatures, allow us to recover the secret key with the same complexity as solving the $\Theta(q)$-Discrete Logarithm problem, which in turn is proportional to $O(\sqrt{p/q})$ for many choices of $q$. Further, we also extend the attack to a reduction showing that the security of BBS+ and deterministic BBS implies the $\Theta(q)$-SDH assumption.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 04:27:47 +0000</pubDate>
</item>
<item>
<title>Concrete Treatment of Signal Handshake’s Deniability: Efficient Post-Quantum Deniable Ring Signature</title>
<link>https://eprint.iacr.org/2025/1090</link>
<guid>https://eprint.iacr.org/2025/1090</guid>
<content:encoded><![CDATA[
The Signal protocol relies on a handshake protocol, formerly X3DH and now PQXDH, to set up secure conversations. One of its privacy properties, of value to Signal, is deniability, allowing users to deny participation in communications. Prior analyses of deniability for these protocols, including post-quantum variants, use models highly tailored to the individual protocols and generally make ad-hoc adaptations to ``standard'' AKE definitions, obscuring the concrete deniability guarantees and complicating comparisons across protocols. Building on Hashimoto et al.’s abstraction for Signal handshake protocols (USENIX’25)'s abstraction for Signal handshake protocols (USENIX'25), we address this gap by presenting a unified framework for analyzing their deniability. We analyze Signal's classically secure X3DH and harvest-now-decrypt-later-secure PQXDH, and show that PQXDH is deniable against harvest-now-judge-later attacks, where a quantum judge retrospectively assesses the participation of classical users. We further analyze post-quantum alternatives like RingXKEM, whose deniability relies on ring signatures (RS).
By introducing a novel metric inspired by differential privacy, we provide relaxed, pragmatic guarantees for deniability. We also use this metric to define deniability for RS, a relaxation of anonymity, allowing us to build an efficient RS from NIST-standardized Falcon (and MAYO), which is not anonymous, but is provably deniable.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 12:20:27 +0000</pubDate>
</item>
<item>
<title>Novel approximations of elementary functions in zero-knowledge proofs</title>
<link>https://eprint.iacr.org/2024/859</link>
<guid>https://eprint.iacr.org/2024/859</guid>
<content:encoded><![CDATA[
In this paper, we study the computation of complex mathematical functions in statements executed on top of zero-knowledge proofs (ZKP); these functions may include roots, exponentials and logarithms, trigonometry etc. While existing approaches to these functions in privacy-preserving computations (and sometimes also in general-purpose processors) have relied on polynomial approximation, more powerful methods are available for ZKP. In this paper, we note that in ZKP, all algebraic functions are exactly computable. Recognizing that, we proceed to the approximation of transcendental functions with algebraic functions. We develop methods of approximation, instantiate them on a number of common transcendental functions, and benchmark their precision and efficiency in comparison with best polynomial approximations.
]]></content:encoded>
<pubDate>Fri, 31 May 2024 08:41:54 +0000</pubDate>
</item>
<item>
<title>FABLE: Batched Evaluation on Confidential Lookup Tables in 2PC</title>
<link>https://eprint.iacr.org/2025/1081</link>
<guid>https://eprint.iacr.org/2025/1081</guid>
<content:encoded><![CDATA[
Abstract
Secure two-party computation (2PC) is a cryptographic technique that enables two mutually distrusting parties to jointly evaluate a function over their private inputs. We consider a 2PC primitive called confidential lookup table (LUT) evaluation, which is useful in privacy-preserving ML inference and data analytics. In this setting, a server holds a confidential LUT and evaluates it over an input secret-shared between a client and the server, producing a secret-shared output. Existing approaches for 2PC LUT evaluation suffer from high asymptotic complexity and practical inefficiency, with some designs lacking confidentiality guarantees for the LUT. Recognizing that many applications involving confidential LUT evaluation require processing multiple inputs with the same LUT, we propose FABLE, a system designed to efficiently evaluate a LUT on a large batch of queries simultaneously. Compared to the state-of-the-art confidential LUT evaluation methods, FABLE achieves up to 28.46-101.47$\times$ speedup in LAN environments and up to 50.10-392.93$\times$ speedup in WAN environments.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 15:54:39 +0000</pubDate>
</item>
<item>
<title>Fairness in the Wild: Secure Atomic Swap with External Incentives</title>
<link>https://eprint.iacr.org/2025/1086</link>
<guid>https://eprint.iacr.org/2025/1086</guid>
<content:encoded><![CDATA[
Atomic swaps enable asset exchanges across blockchains without relying on trusted intermediaries, and are a key component of decentralized finance (DeFi) ecosystems. Recently, Chung, Masserova, Shi, and Thyagarajan introduced Rapidash (Financial Cryptography 2025), an atomic swap protocol that remains incentive compatible under user-miner collusion, by ensuring that the honest strategy forms a coalition-resistant Nash equilibrium. However, their model assumes a closed system where players act solely based on internal protocol incentives. In practice, participants may be influenced by external incentives such as off-chain rewards or adversarial bribes, which can undermine such equilibrium guarantees.

In this work, we introduce a new game-theoretic notion, bounded maximin fairness, which ensures that honest participants remain protected against rational adversaries with arbitrary but bounded external incentives. We construct an atomic swap protocol that satisfies this notion, while preserving the equilibrium properties of prior work in the absence of external influence.

As we show, our protocol is easy to implement and can be instantiated even in Bitcoin’s limited scripting language.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 22:01:27 +0000</pubDate>
</item>
<item>
<title>SmallWood: Hash-Based Polynomial Commitments and Zero-Knowledge Arguments for Relatively Small Instances</title>
<link>https://eprint.iacr.org/2025/1085</link>
<guid>https://eprint.iacr.org/2025/1085</guid>
<content:encoded><![CDATA[
Zero-knowledge proofs (ZKPs) are a fundamental building block in cryptography, enabling powerful privacy-preserving and verifiable computations. In the post-quantum era, hash-based ZKPs have emerged as a promising direction due to their conjectured resistance to quantum attacks, along with their simplicity and efficiency.

In this work, we introduce SmallWood, a hash-based polynomial commitment scheme (PCS) and zero-knowledge argument system optimized for relatively small instances. Building on the recent degree-enforcing commitment scheme (DECS) from the Threshold-Computation-in-the-Head (TCitH) framework, we refine its formalization and combine it with techniques from Brakedown. This results in a new hash-based PCS that is particularly efficient for polynomials of relatively small degree —typically up to $2^{16}$— outperforming existing approaches in this range.

Leveraging this new PCS, we design a hash-based zero-knowledge argument system that outperforms the state-of-the-art in terms of proof sizes for witness size ranging from $2^6$ to $2^{16}$. Additionally, we present exact zero-knowledge arguments for lattice-based problems using SmallWood, demonstrating highly competitive performance: our scheme yields proof sizes under 25 KB across a wide range of lattice parameters, including Kyber and Dilithium instances.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 21:39:46 +0000</pubDate>
</item>
<item>
<title>How to (not) combine Oblivious Pseudorandom Functions</title>
<link>https://eprint.iacr.org/2025/1084</link>
<guid>https://eprint.iacr.org/2025/1084</guid>
<content:encoded><![CDATA[
An oblivious pseudorandom function (OPRF) is a cryptographic tool that enables fast and secure authentication and key derivation from passwords. In the past few years, the adoption of OPRFs has flourished and today they are at the core of the PIN-protected backup methods of WhatsApp and Signal, and of privacy-enhancing browser technologies. All vendors deploy the so-called 2Hash-Diffie-Hellman (2HashDH) OPRF, which relies on discrete-logarithm-type assumptions that are standard yet known to be prone to quantum attacks.

Recent advancements in cryptographic research (e.g., Dodgson et al., Eurocrypt 2025) have brought up post-quantum OPRFs that are fast enough to deploy them in the setting of, e.g., WhatsApp or Signal. Yet none of these constructions %that achieves the required level of security e.g., for WhatsApps backup protocol are based on standard assumptions.

In this work, we investigate combiners for OPRFs, namely a ``best-of-both'' combination of a classical and a post-quantum OPRF that is secure as long as one of them is. First, we give formal evidence that so-called black-box combiners do not exist, indicating that combining OPRFs is subtle and bears similarities with other powerful yet hard-to-combine cryptographic primitives like oblivious transfer (OT).

We then give a (non-black-box) combiner for OPRFs and show that it can be instantiated with 2HashDH and the currently most efficient post-quantum OPRFs based on Legendre symbols. In particular, the reliance on the less standard Legendre-based hardness assumption does not harm the security of 2HashDH. This gives vendors a viable path to lift the security of their OPRF deployments to a post-quantum level.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 20:12:40 +0000</pubDate>
</item>
<item>
<title>Weight reduction in distributed protocols: new algorithms and analysis</title>
<link>https://eprint.iacr.org/2025/1076</link>
<guid>https://eprint.iacr.org/2025/1076</guid>
<content:encoded><![CDATA[
We study the problem of minimizing the total weight of (potentially many) participants of a distributed protocol, a necessary step when the original values are large but the scheme to be deployed scales poorly with the weights. We assume that $\alpha$ fraction of the original weights can be corrupted and we must output new weights with at most $\beta$ adversarial fraction, for $\alpha < \beta$. This problem can be viewed from the prism of electing a small committee that does the heavy work, a powerful tool for making distributed protocols scalable. We solve the variant that requires giving parties potentially multiple seats in the committee and counting each seat towards the cost of the solution. Moreover, we focus on the ``deterministic'' version of the problem where the computed committee must be secure for any subset of parties that can be corrupted by the adversary; such a committee can be smaller than a randomly sampled one in some cases and is useful when security against adaptive corruptions is desired but parties in the sub-protocol speak multiple times.

Presented are new algorithms for the problem as well as analysis of prior work. We give two variants of the algorithm Swiper (PODC 2024), one that significantly improves the running time without sacrificing the quality of the output and the other improving the output for a reasonable increase in the running time. We prove, however, that all known algorithms, including our two variants of Swiper, have worst case approximation ratio $\Omega(n)$. To counter that, we give the first polynomial time algorithm with approximation factor $n / \log^2 n$ and also the first sub-exponential time exact algorithm, practical for some real-world inputs. Of theoretical interest is another polytime algorithm that we present, based on linear programming, whose output is no worse than an optimal solution to the problem with slightly different parameters.

We implemented and tested previous and new algorithms, comparing them on the stake distributions of popular proof-of-stake blockchains, and found that our second variant of Swiper computes solutions extremely close to the optimal, confirmed by our exact algorithm.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 06:53:22 +0000</pubDate>
</item>
<item>
<title>Fabric-X: Redesigning Hyperledger Fabric Architecture for High-throughput Regulated Asset Exchange Applications</title>
<link>https://eprint.iacr.org/2023/1717</link>
<guid>https://eprint.iacr.org/2023/1717</guid>
<content:encoded><![CDATA[
The adoption of Distributed Ledger Technology (DLT) for critical
financial infrastructures like Central Bank Digital Currencies (CB-
DCs) is hindered by a significant performance gap. Permissioned
blockchains such as Hyperledger Fabric, while conceptually suit-
able, are limited by architectural bottlenecks in their monolithic
peer design and consensus mechanisms, preventing them from
achieving the required scale.

This paper presents a fundamental re-architecture of Hyper-
ledger Fabric that addresses these challenges end-to-end. We de-
compose the monolithic peer into independently scalable microser-
vices for endorsement, validation, and committing. To maximize
parallelism, we introduce a transaction dependency graph that en-
ables the safe, concurrent validation of transactions across multiple
blocks. Complementing the peer redesign, we introduce Arma, a
novel sharded Byzantine Fault Tolerant (BFT) ordering service that
dramatically increases throughput by ordering compact transaction
digests rather than full transaction payloads. We implemented and
benchmarked this framework with a UTXO-based CBDC applica-
tion. Our evaluation demonstrates a peak throughput exceeding
200,000 transactions per second (TPS)—a two-orders-of-magnitude
improvement over the standard implementation. This work proves
that permissioned DLTs can be engineered for national-scale pay-
ment systems, providing a resilient and highly performant foun-
dation for practical CBDC deployments and the integration of ad-
vanced, computationally intensive features.
]]></content:encoded>
<pubDate>Mon, 06 Nov 2023 08:41:54 +0000</pubDate>
</item>
<item>
<title>LAPWN: A Lightweight User–Server Authentication Protocol for Wireless Networks</title>
<link>https://eprint.iacr.org/2025/1073</link>
<guid>https://eprint.iacr.org/2025/1073</guid>
<content:encoded><![CDATA[
The Internet of Things (IoT) is composed of interconnected devices that exchange data over a network,
enabling applications in healthcare, transportation, and smart environments. As IoT ecosystems expand,
ensuring security and privacy remains a critical challenge. Many IoT devices rely on wireless
networks for data transmission, making them vulnerable to eavesdropping, tracking, and tampering.
This highlights the need for robust authentication mechanisms. To address these concerns, numerous
authentication protocols have been proposed. However, many fail to ensure adequate security against
both passive and active attacks. In this research, we introduce LAPWN, a lightweight protocol for
user–server communication, specifically designed for constrained environments, ensuring a balance
between security and efficiency. The proposed protocol is implemented as a fully functional Python
application, demonstrating its practical usability and evaluating its efficiency in real-world scenarios.
To validate its security, we performboth informal and formal analyses, utilizing Scyther, ProVerif, and
the Real-or-Random (RoR) model. The results confirm that LAPWN provides a secure, lightweight,
and efficient authentication solution with low computational and communication overhead. Furthermore,
performance evaluations show that it surpasses existing authentication protocols, making it a
highly effective solution for secure user–server interactions in constrained environments.
]]></content:encoded>
<pubDate>Sun, 08 Jun 2025 15:01:18 +0000</pubDate>
</item>
<item>
<title>Full Anonymity in the Asynchronous Setting from Peony Onion Encryption</title>
<link>https://eprint.iacr.org/2025/1067</link>
<guid>https://eprint.iacr.org/2025/1067</guid>
<content:encoded><![CDATA[
Onion routing is a popular practical approach to anonymous communication, and the subject of a growing body of foundational theoretical work aiming to design efficient schemes with provable anonymity, the strongest notion of which is full anonymity.

Unfortunately, all previous schemes that achieve full anonymity assume the synchronous communication setting, which is unrealistic as real networks may experience message loss and timing attacks that render such schemes insecure. Recently, Ando, Lysyanskaya, and Upfal (TCC '24) took a first step towards addressing the asynchronous setting by constructing an efficient onion routing protocol with the strictly weaker guarantee of differential privacy. Their scheme relies on a new primitive called bruisable onion encryption. 

In this paper, we construct the first efficient fully anonymous onion routing protocol in the asynchronous setting. To do so, we overcome two main technical challenges: First, we develop the first bruisable onion construction that does not leak information about the onion's position on the routing path. Second, we design an onion routing protocol that uses such bruisable onion encryption to achieve full anonymity (rather than just differential privacy). Along the way, we develop a new fully anonymous onion routing protocol in the synchronous setting, which improves on the state of the art in terms of communication complexity and round complexity.

Both our protocols are secure against an active adversary corrupting a constant fraction of the nodes (up to <1 for the synchronous protocol, and <1/2 for the asynchronous protocol) and rely on standard cryptographic assumptions (CCA-secure public key encryption and collision-resistant hash functions).
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 17:56:00 +0000</pubDate>
</item>
<item>
<title>From Signature-Based Witness Encryption to RAM Obfuscation: Achieving Blockchain-Secured Cryptographic Primitives</title>
<link>https://eprint.iacr.org/2025/1064</link>
<guid>https://eprint.iacr.org/2025/1064</guid>
<content:encoded><![CDATA[
Goyal and Goyal demonstrated that extractable witness encryption, when combined with smart-contract equipped proof-of-stake blockchains, can yield powerful cryptographic primitives such as one-time programs and pay-to-use programs. However, no standard model construction for extractable witness encryption is known, and instantiations from alternatives like indistinguishability obfuscation are highly inefficient.

This paper circumvents the need for extractable witness encryption by combining signature-based witness encryption (Döttling et al.) with witness encryption for KZG commitments (Fleischhacker et al.). Inspired by Goyal et al., we introduce $T+1$-Extractable Witness Encryption for Blockchains ($T+1$-eWEB), a novel primitive that encrypts a secret, making its decryption contingent upon the subsequent block's state. Leveraging $T+1$-eWEBs, we then build a conditional one-time memory, leading to a $T+1$ one-time program ($T+1$-OTP) also conditional on the next block state. Finally, using our $T+1$-OTP, we develop a conditional RAM obfuscation scheme where program execution can be contingent on the blockchain state, thereby enabling applications like pay-to-use programs.

Despite its theoretical value, our construction is impractical due to a "bit-by-bit" signing requirement for the state root and an inefficient method for storing validator keys. We thus posit the construction of a practical $T+1$-OTP as a significant open problem. This work provides the first theoretical pathway for building such primitives without extractable witness encryption, representing a novel step for blockchain-secured cryptography
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 14:36:43 +0000</pubDate>
</item>
<item>
<title>TrafficProof: Privacy-Preserving Reliable Traffic Information Sharing in Social Internet of Vehicles</title>
<link>https://eprint.iacr.org/2025/1062</link>
<guid>https://eprint.iacr.org/2025/1062</guid>
<content:encoded><![CDATA[
In the Social Internet of Vehicles (SIoV), effective data sharing is essential for applications including road safety, traffic management, and situational awareness. However, the decentralized and open nature of SIoV presents significant challenges in simultaneously ensuring data integrity, user privacy, and system accountability. This paper presents a protocol for secure and location-accurate traffic data sharing that fully preserves the anonymity and privacy of participating witnesses. The protocol leverages zero-knowledge proofs (ZKPs) to allow vehicles to broadcast redacted traffic information—such as images—tied to specific geographic locations, while withholding both the original content and the identity of the reporting vehicle. To ensure the authenticity of the redacted content and the legitimacy of the witness, an additional ZKP is used to privately validate both elements. Upon receiving a report, the verifying node checks the submitted proofs, aggregates validated inputs, and publishes the resulting metadata to both IPFS and a blockchain. This design ensures public verifiability, tamper resistance, and the reliability of the shared data, while maintaining strong privacy guarantees through cryptographic anonymity. To improve the efficiency of proof generation on resource-constrained devices, the protocol employs folding-based ZKP constructions. We conduct a formal security and soundness analysis of the protocol and implement a proof-of-concept, which is publicly available as open-source software. Experimental evaluations on commodity hardware demonstrate that the protocol is computationally efficient and introduces less than 1.5\% communication overhead relative to the size of the shared traffic data, indicating its suitability for real-world deployment.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 12:37:01 +0000</pubDate>
</item>
<item>
<title>Blockchain Governance via Sharp Anonymous Multisignatures</title>
<link>https://eprint.iacr.org/2023/1881</link>
<guid>https://eprint.iacr.org/2023/1881</guid>
<content:encoded><![CDATA[
Electronic voting has occupied a large part of the cryptographic protocols literature. The recent reality of blockchains---in particular, their need for online governance mechanisms---has brought new parameters and requirements to the problem. We identify the key requirements of a blockchain governance mechanism, namely correctness (including eliminative double votes), voter anonymity, and traceability, and investigate mechanisms that can achieve them with minimal interaction and under assumptions that fit the blockchain setting.

First, we define a signature-like primitive, which we term \textit{sharp anonymous multisignatures} (in short, $\sharp$AMS) that tightly meets the needs of blockchain governance. In a nutshell, $\sharp$AMSs allow any set of parties to generate a signature, e.g., on a proposal to be voted upon, which, if posted on the blockchain, hides the identities of the signers/voters but reveals their number. This can be seen as a (strict) generalization of threshold ring signatures (TRS). 

We next turn to constructing such $\sharp$AMSs and using them in various governance scenarios---e.g., single vote vs. multiple votes per voter. In this direction, although the definition of TRS does not imply $\sharp$AMS, one can compile some existing TRS constructions into $\sharp$AMS. This raises the question: What is the TRS structure that allows such a compilation? 
To answer the above, we devise templates for TRSs. Our templates encapsulate and abstract the structure that allows for the above compilation---most of the TRS schemes that can be compiled into $\sharp$AMS are, in fact, instantiations of our template. This abstraction makes our template generic for instantiating TRSs and $\sharp$AMSs from different cryptographic assumptions (e.g., DDH, LWE, etc.). One of our templates is based on chameleon hashes, and we explore a framework of lossy chameleon hashes to understand their nature fully.

Finally, we turn to how $\sharp$AMS schemes can be used in our applications. We provide fast (in some cases non-interactive) $\sharp$AMS-based blockchain governance mechanisms for a wide spectrum of assumptions on the honesty (semi-honest vs malicious) and availability of voters and proposers.
]]></content:encoded>
<pubDate>Thu, 07 Dec 2023 03:28:45 +0000</pubDate>
</item>
<item>
<title>Private Signaling Secure Against Actively Corrupted Servers</title>
<link>https://eprint.iacr.org/2025/1056</link>
<guid>https://eprint.iacr.org/2025/1056</guid>
<content:encoded><![CDATA[
Private signaling allows servers to identify a recipient's messages on a public bulletin board without knowing the recipient's metadata. It is a central tool for systems like privacy-preserving blockchains and anonymous messaging. However, unless with TEE, current constructions all assume that the servers are only passively corrupted, which significantly limits their practical relevance. In this work, we present a TEE-free simulation-secure private signaling protocol assuming two non-colluding servers, either of which can be actively corrupted.
 
Crucially, we convert signal retrieval into a problem similar to private set intersection and use custom-built zero-knowledge proofs to ensure consistency with the public bulletin board. As a result, our protocol achieves lower server-to-server communication overhead and a much smaller digest compared to state-of-the-art semi-honest protocol. For example, for a board size of $2^{19}$ messages, the resulting digest size is only 33.57KB. Our protocol is also computationally efficient: retrieving private signals only takes about 2 minutes, using 16 threads and a LAN network.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 02:52:28 +0000</pubDate>
</item>
<item>
<title>Rewardable Naysayer Proofs</title>
<link>https://eprint.iacr.org/2025/1054</link>
<guid>https://eprint.iacr.org/2025/1054</guid>
<content:encoded><![CDATA[
Combining verifiable computation with optimistic approaches is a promising direction to scale blockchain applications. 
The basic idea consists of saving computations by avoiding the verification of proofs unless there are complaints.

A key tool to design systems in the above direction has been recently proposed by Seres, Glaeser and Bonneau [FC'24] who formalized the concept of a Naysayer proof: an efficient to verify proof disproving a more demanding to verify original proof. 

In this work, we discuss the need of rewarding naysayer provers, the risks deriving from front-running attacks, and the failures of generic approaches trying to defeat them. 
Next, we introduce the concept of verifiable delayed naysayer proofs and show a construction leveraging proofs of sequential work, without relying on any additional infrastructure.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 19:31:42 +0000</pubDate>
</item>
<item>
<title>Constrained Verifiable Random Functions Without Obfuscation and Friends</title>
<link>https://eprint.iacr.org/2025/1045</link>
<guid>https://eprint.iacr.org/2025/1045</guid>
<content:encoded><![CDATA[
CVRFs are PRFs that unify the properties of verifiable and constrained PRFs. Since they were introduced concurrently by Fuchsbauer and Chandran-Raghuraman-Vinayagamurthy in 2014, it has been an open problem to construct CVRFs without using heavy machinery such as multilinear maps, obfuscation or functional encryption.

We solve this problem by constructing a prefix-constrained verifiable PRF that does not rely on the aforementioned assumptions. Essentially, our construction is a verifiable version of the Goldreich-Goldwasser-Micali PRF. To achieve verifiability we leverage degree-2 algebraic PRGs and bilinear groups. In short, proofs consist of intermediate values of the Goldreich-Goldwasser-Micali PRF raised to the exponents of group elements. These outputs can be verified using pairings since the underlying PRG is of degree 2.

We prove the selective security of our construction under the Decisional Square Diffie-Hellman (DSDH) assumption and a new assumption, which we dub recursive Decisional Diffie-Hellman (recursive DDH).

We prove the soundness of recursive DDH in the generic group model assuming the hardness of the Multivariate Quadratic (MQ) problem and a new variant thereof, which we call MQ+.

Last, in terms of applications, we observe that our CVRF is also an exponent (C)VRF in the plain model. Exponent VRFs were recently introduced by Boneh et al. (Eurocrypt’25) with various applications to threshold cryptography in mind. In addition to that, we give further applications for prefix-CVRFs in the blockchain setting, namely, stake-pooling and compressible randomness beacons.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 12:08:42 +0000</pubDate>
</item>
<item>
<title>When Threshold Meets Anamorphic Signatures: What is Possible and What is Not!</title>
<link>https://eprint.iacr.org/2025/1044</link>
<guid>https://eprint.iacr.org/2025/1044</guid>
<content:encoded><![CDATA[
Anamorphic signatures allow covert communication through signatures in environments where encryption is restricted. They enable trusted recipients with a double key to extract hidden messages while the signature remains indistinguishable from a fresh and regular one. However, the traditional notion of anamorphic signatures suffers from vulnerabilities, particularly when a single recipient or sender is compromised, exposing all hidden messages and providing undeniable proof that citizens are part of the anamorphic exchange.

To address these limitations, we explore a threshold-based approach to distribute trust among multiple recipients, preventing adversaries from decrypting anamorphic messages even if some recipients are compromised. Our first contribution is the formalization of the notion of \emph{threshold-recipient anamorphic signatures}, where decryption is possible only through collaboration among a subset of recipients. 

We then explore a \emph{stronger model} where the dictator controls the key generation process through which it learns all secret keys and how citizens store cryptographic keys. A particular example of this model in the real world is a dictator providing citizens with electronic identity documents (eIDs) and blocking all other usage of cryptography. We demonstrate that anamorphic communication is still possible even in such a scenario. Our construction is secure against post-quantum adversaries and does not rely on any computational assumptions except the random oracle model.

Finally, we show an \emph{impossibility result} for encoding anamorphic messages with a threshold-sender model when using many existing threshold signature schemes and the adversary is part of the signing group. Our work outlines both the possibilities and limitations of extending anamorphic signatures with threshold cryptography, offering new insights into improving the security and privacy of individuals under authoritarian regimes.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 10:14:06 +0000</pubDate>
</item>
<item>
<title>Rubato: Provably Post-Quantum Secure and Batched Asynchronous Randomness Beacon</title>
<link>https://eprint.iacr.org/2025/1041</link>
<guid>https://eprint.iacr.org/2025/1041</guid>
<content:encoded><![CDATA[
Distributed Randomness Beacons (DRBs) provide secure, unbiased random numbers for decentralized systems. However, existing protocols face critical limitations. Most rely on cryptographic assumptions which are vulnerable to quantum attacks, risking long-term security in asynchronous networks where unbounded delays may allow attackers time to exploit these weaknesses. Many achieve low beacon generation rates, often below 100 beacons per minute in moderate-scale networks (e.g., Spurt IEEE S&amp;P’22), hindering their use in applications requiring high-throughput randomness. Additionally, traditional Verifiable Secret Sharing (VSS)-based DRBs, using a share-consensus-reconstruct paradigm, are unsuitable for asynchronous networks due to circular dependencies between beacon generation and consensus. Given these limitations, we propose Rubato, the first provably post-quantum secure DRB for asynchronous environments, incorporating a lattice-based batched Asynchronous Verifiable Secret Sharing scheme (bAVSS-PQ). Rubato supports batching of $\mathcal{O}(\lambda^2)$ secrets with communication complexity $\mathcal{O}(\lambda n^3 \log n)$ and tolerates Byzantine faults in up to one-third of the nodes. Integrated with DAG-based consensus protocols like Bullshark or Tusk, its epoch-staggered architecture resolves circular dependencies, enabling efficient and secure randomness generation. Evaluations across 10 to 50 nodes show Rubato generates 5200 to 350 beacons per minute with per-beacon latencies of 11.60 to 96.37 milliseconds, achieving a consensus throughput of 186,088 transactions per second with a latency of 16.78 seconds at 30 nodes. Rubato offers robust post-quantum security and high performance for small-to-medium-scale decentralized systems.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 03:16:30 +0000</pubDate>
</item>
<item>
<title>Trusted Hardware-Assisted Leaderless Byzantine Fault Tolerance Consensus</title>
<link>https://eprint.iacr.org/2025/1033</link>
<guid>https://eprint.iacr.org/2025/1033</guid>
<content:encoded><![CDATA[
Byzantine Fault Tolerance (BFT) Consensus protocols with trusted hardware assistance have been extensively explored for their improved resilience to tolerate more faulty processes. Nonetheless, the potential of trust hardware has been scarcely investigated in leaderless BFT protocols. RedBelly is assumed to be the first blockchain network whose consensus is based on a truly leaderless BFT algorithm. This paper proposes a trusted hardware-assisted leaderless BFT consensus protocol by offering a hybrid solution for the set BFT problem defined in the RedBelly blockchain. Drawing on previous studies, we present two crucial trusted services: the counter and the collector. Based on these two services, we introduce two primitives to formulate our leaderless BFT protocol: a hybrid verified broadcast (VRB) protocol and a hybrid binary agreement. The hybrid VRB protocol enhances the hybrid reliable broadcast protocol by integrating a verification function. This addition ensures that a broadcast message is verified not only for authentication but also for the correctness of its content. Our hybrid BFT consensus is integrated with these broadcast protocols to deliver binary decisions on all proposals. We prove the correctness of the proposed hybrid protocol and demonstrate its enhanced performance in comparison to the prior trusted BFT protocol.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 08:48:21 +0000</pubDate>
</item>
<item>
<title>Rapidash: Atomic Swaps Secure under User-Miner Collusion</title>
<link>https://eprint.iacr.org/2022/1063</link>
<guid>https://eprint.iacr.org/2022/1063</guid>
<content:encoded><![CDATA[
Cross-chain trading is fundamental to blockchains and Decentralized Finance (DeFi). A way to achieve such trading in a truly decentralized manner, i.e., without trusted third parties, is by using atomic swaps. However, recent works revealed that Hashed Time-Lock Contract, a key building block of the existing atomic swaps, is entirely insecure in the presence of user-miner collusion. Specifically, a user can bribe the miners of the blockchain to help it cheat.

In this work, we give the first and rigorous formal treatment of fair trading on blockchains, where users and miners may enter arbitrary binding contracts on the side. We propose Rapidash, a new atomic swap protocol, and prove its incentive-compatibility in the presence of user-miner collusion. Specifically, we show that Rapidash satisfies a coalition-resistant Nash equilibrium absent external incentives. We give instantiations of Rapidash that are compatible with Bitcoin and Ethereum, and incur only minimal overheads in terms of costs for the users.
]]></content:encoded>
<pubDate>Tue, 16 Aug 2022 04:17:47 +0000</pubDate>
</item>
<item>
<title>Everlasting Anonymous Rate-Limited Tokens</title>
<link>https://eprint.iacr.org/2025/1030</link>
<guid>https://eprint.iacr.org/2025/1030</guid>
<content:encoded><![CDATA[
Anonymous rate-limited tokens are a special type of credential that can be used to improve the efficiency of privacy-preserving authentication systems like Privacy Pass. In such a scheme, a user obtains a "token dispenser" by interacting with an issuer, and the dispenser allows the user to create up to a pre-determined number $k$ of unlinkable and publicly verifiable tokens. Unlinkable means that one should not be able to tell that two tokens originate from the same dispenser, but also they cannot be linked to the interaction that generated the dispenser. Furthermore, we can limit the rate at which these tokens are created by linking each token to a context (e.g., the service we are authenticating to), and imposing a limit $N \leq k$ such that seeing more than $N$ tokens for the same context will reveal the identity of the user.
Constructions of such tokens were first given by Camenisch, Hohenberger and Lysyanskaya (EUROCRYPT '05) and Camenisch, Hohenberger, Kohlweiss, Lysyanskaya, and Meyerovich (CCS '06). 

In this work, we present the first construction of \emph{everlasting} anonymous rate-limited tokens, for which unlinkability holds against computationally unbounded adversaries, whereas other security properties (e.g., unforgeability) remain computational. Our construction relies on pairings. While several parameters in our construction unavoidably grow with $k$, the key challenge we resolve is ensuring that the complexity of dispensing a token is independent of the parameter $k$. 

We are motivated here by the goal of providing solutions that are robust to potential future quantum attacks against the anonymity of previously stored tokens. A construction based on post-quantum secure assumptions (e.g., based on lattices) would be rather inefficient---instead, we take a pragmatic approach dispensing with post-quantum security for properties not related to privacy.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 06:20:26 +0000</pubDate>
</item>
<item>
<title>Group Key Progression: Strong Security for Shared Persistent Data</title>
<link>https://eprint.iacr.org/2025/1028</link>
<guid>https://eprint.iacr.org/2025/1028</guid>
<content:encoded><![CDATA[
End-to-end encryption allows data to be outsourced and stored on an untrusted server, such as in the cloud, without compromising data privacy. In the setting when this data is shared between a group of users, members also all share access to the same static key material used for data encryption. When the group membership changes, access control is only enforced by the server: security breaches or compelled disclosure would allow even a removed member to decrypt the current shared data.

We propose to move away from static keys and instead use a group key progression (GKP) scheme, a novel primitive that enables a dynamic group of users to agree on a persistent sequence of keys while keeping a compact local state. GKP ensures that group members can only derive keys within a certain interval of the sequence, a notion that we call interval access control (IAC), and also provide post-compromise security. Our GKP construction, called Grappa, combines continuous group key agreement (CGKA, by Alwen et al., 2020) with a new abstraction called interval scheme. The latter is a symmetric-key primitive that can derive a sequence of keys from a compact state while preserving IAC. We explore different interval scheme constructions and simulate their storage and communication costs when used in group settings. The most efficient of them is a generalization of dual key regression (Shafagh et al., 2020), which we formalize and prove secure. Overall, our protocols offer a practical and robust solution to protect persistent data shared by a group.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 22:53:02 +0000</pubDate>
</item>
<item>
<title>Malicious Security in Collaborative zk-SNARKs: More than Meets the Eye</title>
<link>https://eprint.iacr.org/2025/1026</link>
<guid>https://eprint.iacr.org/2025/1026</guid>
<content:encoded><![CDATA[
Collaborative zk-SNARKs (Ozdemir and Boneh, USENIX’22) are a multiparty variant of zk-SNARKs where multiple, mutually distrustful provers, each holding a private input, jointly compute a zk-SNARK using their combined inputs. A sequence of works has proposed efficient constructions of collaborative zk-SNARKs using a common template that involves designing secure multiparty computation (MPC) protocols to emulate a zk-SNARK prover without making non-black-box use of cryptography. To achieve security against malicious adversaries, these works adopt compilers from the MPC literature that transform semi-honest MPC into malicious-secure MPC.

In this work, we revisit this design template.
• Pitfalls: We demonstrate two pitfalls in the template, which can lead to a loss of input privacy. We first show that it is possible to compute collaborative proofs on invalid witnesses, which in turn can leak the inputs of honest provers. Next, we show that using state-of-the-art malicious security compilers as-is for proof computation is insecure, in general. Finally, we discuss mitigation strategies.
• Malicious Security Essentially for Free: As our main technical result, we show that in the honest-majority setting, one can forego malicious security checks performed by state-of-the-art malicious security compilers during collaborative proof generation of several widely used zk-SNARKs. In other words, we can avoid the overheads of malicious security compilers, enabling faster proof generation.

To the best of our knowledge, this is the first example of non-trivial computations where semi-honest MPC protocols achieve malicious security. The observations underlying our positive results are general and may have applications beyond collaborative zkSNARKs.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 20:25:28 +0000</pubDate>
</item>
<item>
<title>Secure Noise Sampling for Differentially Private Collaborative Learning</title>
<link>https://eprint.iacr.org/2025/1025</link>
<guid>https://eprint.iacr.org/2025/1025</guid>
<content:encoded><![CDATA[
Differentially private stochastic gradient descent (DP-SGD) trains machine learning (ML) models with formal privacy guarantees for the training set by adding random noise to gradient updates. In collaborative learning (CL), where multiple parties jointly train a model, noise addition occurs either (i) before or (ii) during secure gradient aggregation. The first option is deployed in distributed DP methods, which require greater amounts of total noise to achieve security, resulting in degraded model utility. The second approach preserves model utility but requires a secure multiparty computation (MPC) protocol. Existing methods for MPC noise generation require tens to hundreds of seconds of runtime per noise sample because of the number of parties involved. This makes them impractical for collaborative learning, which often requires thousands or more samples of noise in each training step.

We present a novel protocol for MPC noise sampling tailored to the collaborative learning setting. It works by constructing an approximation of the distribution of interest which can be efficiently sampled by a series of table lookups. Our method achieves significant runtime improvements and requires much less communication compared to previous work, especially at higher numbers of parties. It is also highly flexible – while previous MPC sampling methods tend to be optimized for specific distributions, we prove that our method can generically sample
noise from statistically close approximations of arbitrary discrete distributions. This makes it compatible with a wide variety of DP mechanisms. Our experiments demonstrate the efficiency and utility of our method applied to a discrete Gaussian mechanism for differentially private collaborative learning. For 16 parties, we achieve a runtime of 0.06 seconds and 11.59 MB total communication per sample, a 230× runtime improvement and 3× less communication compared to the prior state-of-the-art for sampling from discrete Gaussian distribution in MPC.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 19:30:57 +0000</pubDate>
</item>
<item>
<title>Towards Trustless Provenance: A Privacy-Preserving Framework for On-chain Media Verification</title>
<link>https://eprint.iacr.org/2025/1024</link>
<guid>https://eprint.iacr.org/2025/1024</guid>
<content:encoded><![CDATA[
As generative models continue to evolve, verifying the authenticity, provenance, and integrity of digital media has become increasingly critical—particularly for domains like journalism, digital art, and scientific documentation.
In this work, we present a decentralized verifiable media ecosystem for managing, verifying, and transacting authentic digital media using zero-knowledge proofs (ZKPs).
Building on VIMz (Dziembowski et al., PETS'25), we extend the framework in three key directions. First, we generalize the model to support arbitrary image regions to achieve selective transformations support such as redaction and regional blurring—features commonly required in privacy-preserving applications. Second, we introduce performance optimizations that yield up to an 18% improvement in off-chain proof generation, and enhance the framework to support cost-efficient on-chain verification. Third, we design and implement a modular smart contract architecture to support a wide range of decentralized media applications.
As a flagship use case, we develop a decentralized media marketplace that enables permissionless licensing, ownership transfer, and verifiable attribution. In this setting, users can share transformed media—such as cropped, blurred, or resized previews—alongside ZKPs that prove derivation from a signed original, eliminating the need to trust the seller.
Unlike prior fair exchange protocols, which rely on trusted descriptions or encrypted payload delivery, our system enables verifiable public previews and origin-bound proofs without revealing the full content. This approach unlocks new applications beyond marketplaces, including automated infringement dispute resolution and photography contests with verifiable criteria.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:42:37 +0000</pubDate>
</item>
<item>
<title>Universal Channel Rebalancing: Flexible Coin Shifting in Payment Channel Networks</title>
<link>https://eprint.iacr.org/2025/1023</link>
<guid>https://eprint.iacr.org/2025/1023</guid>
<content:encoded><![CDATA[
Payment Channel Networks (PCNs) enhance blockchain scalability by enabling off-chain transactions. However, repeated unidirectional multi-hop payments often cause channel imbalance or depletion, limiting scalability and usability. Existing rebalancing protocols, such as Horcrux [NDSS’25] and Shaduf [NDSS’22], rely on on-chain operations, which hinders efficiency and broad applicability.
  We propose Universal Channel Rebalancing (UCRb), a blockchain-agnostic, fully off-chain framework that ensures correct behavior among untrusted participants without on-chain interaction. 
  UCRb incorporates the following core innovations: 
  (1) a fair and reliable incentive-compatible mechanism that encourages voluntary user participation in off-chain channel rebalancing,  
  (2) integration of Pedersen commitments to achieve atomic off-chain payments and rebalancing operations, while ensuring balance security, and  
  (3) zero-knowledge proofs to enable privacy-preserving channel initialization and coin shifting, ensuring that user identities and fund allocations remain hidden throughout the process.

  We evaluate UCRb using real-world Lightning Network dataset and compare its performance against state-of-the-art solutions including Horcrux, Shaduf, and Revive [CCS'17]. 
  UCRb exhibits a success ratio enhancement between 15% and 50%, while also reducing the required user deposits by 72%--92%. It maintains an almost negligible rate of channel depletion. Additionally, the long-term performance of UCRb is roughly 1.5 times that of its short-term performance, suggesting that continuous operation leads to improved efficiency. We implement a prototype for UCRb smart contracts and demonstrate its practicality through extensive evaluation. As \texttt{CoinShift} operations require no on-chain interaction, the protocol incurs minimal gas costs. For instance, opening and closing channels with 10 neighbors costs only 130K-160K gas—significantly lower than comparable solutions.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:37:20 +0000</pubDate>
</item>
<item>
<title>Burn Your Vote: Decentralized and Publicly Verifiable Anonymous Voting at Scale</title>
<link>https://eprint.iacr.org/2025/1022</link>
<guid>https://eprint.iacr.org/2025/1022</guid>
<content:encoded><![CDATA[
Secure and trustworthy electronic voting requires more than correctness and censorship resistance, it must also ensure voter privacy, vote confidentiality, and protection against coercion. Prior work attempt to address these challenges using heavyweight cryptographic primitives such as homomorphic encryption, time-lock puzzles, or multi-party computation. These approaches often involve complex computations, depend on trusted parties, and typically do not scale well. We propose a lightweight, fully on-chain anonymous voting protocol based on a novel application of the proof-of-burn (PoB) mechanism. Voters anonymously commit to their votes by burning tokens to pseudorandom addresses and later submit zero-knowledge proofs attesting to their valid participation. Our design achieves vote integrity, coercion resistance, and unlinkability without relying on encrypted ballots, trusted third parties, or centralized tallying. The tallying process is public and operates on plaintext votes that are authenticated yet unlinkable to voters. This enables flexible voting models—including token-weighted and quadratic voting—with minimal on-chain overhead. We formally analyze the protocol’s security guarantees and demonstrate support for a broad range of voting models. We implement the protocol as an open-source library fully compatible with the Ethereum Virtual Machine (EVM), and our experimental evaluation confirms its high scalability and improved efficiency compared to the state-of-the-art.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:28:20 +0000</pubDate>
</item>
<item>
<title>Silent Splitter: Privacy for Payment Splitting via New Protocols for Distributed Point Functions</title>
<link>https://eprint.iacr.org/2025/1019</link>
<guid>https://eprint.iacr.org/2025/1019</guid>
<content:encoded><![CDATA[
In a world where financial transactions are primarily performed or recorded online, protecting sensitive transaction details has become crucial. Roommates sharing housing costs or friends splitting travelling expenses may use applications such as Splitwise to easily track debts and minimize the number of individual repayments. However, these apps reveal potentially sensitive financial transaction activity to their operators. In this paper, we present Silent Splitter, a privacy-preserving payment splitting system which enables users to securely set up groups, perform transactions within those groups, and "settle up" without revealing group membership or any sensitive transaction details (such as the users involved or amount of money exchanged) to the system itself. Silent Splitter operates in the two server setting and uses Distributed Point Functions (DPFs) to securely record transactions. Of independent interest, we also present new protocols for proving knowledge of properties of DPFs as part of our system.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 14:24:53 +0000</pubDate>
</item>
<item>
<title>Silentium: Implementation of a Pseudorandom Correlation Generator for Beaver Triples</title>
<link>https://eprint.iacr.org/2025/1013</link>
<guid>https://eprint.iacr.org/2025/1013</guid>
<content:encoded><![CDATA[
Secure Multi-Party Computation is a privacy-enhancing technology that allows several parties to securely compute on distributed private data.  
In the line of the well established SPDZ protocol,  the by far most expensive task is the generation of Beaver triples in the so called  offline phase.
Silentium is our implementation of an actively secure offline phase in the form of a Pseudorandom Correlation Generator for Beaver triples (Bt-PCG, Boyle et al. CRYPTO 2020), which, as any PCG, is designed to have low communication. Compared to previous offline phases, their Bt-PCG reduces the communication costs by three orders of magnitude. However, so far efficiency was only estimated. With Silentium, we  demonstrate that their Bt-PCG can achieve even better running times than state-of-the-art offline phase implementations in the  MP-SPDZ library. To actually achieve such a performance, Silentium  comprises a systematic   parallelization strategy and implementation-friendly decomposition scenarios of the Bt-PCG into structured modules. 
Looking forward for large-scale applications on the cloud,  Silentium is designed to be versatile to support hardware acceleration in future.
]]></content:encoded>
<pubDate>Sun, 01 Jun 2025 12:18:18 +0000</pubDate>
</item>
<item>
<title>Efficient and Generic Methods to Achieve Active Security in Private Information Retrieval and More Advanced Database Search</title>
<link>https://eprint.iacr.org/2024/375</link>
<guid>https://eprint.iacr.org/2024/375</guid>
<content:encoded><![CDATA[
Motivated by secure database search, we present secure computation protocols for a function $f$ in the client-servers setting, where a client can obtain $f(x)$ on a private input $x$ by communicating with multiple servers each holding $f$. Specifically, we propose generic compilers from passively secure protocols, which only keep security against servers following the protocols, to actively secure protocols, which guarantee privacy and correctness even against malicious servers. Our compilers are applied to protocols computing any class of functions, and are efficient in that the overheads in communication and computational complexity are only polynomial in the number of servers, independent of the complexity of functions. We then apply our compilers to obtain concrete actively secure protocols for various functions including private information retrieval (PIR), bounded-degree multivariate polynomials and constant-depth circuits. For example, our actively secure PIR protocols achieve exponentially better computational complexity in the number of servers than the currently best-known protocols. Furthermore, our protocols for polynomials and constant-depth circuits reduce the required number of servers compared to the previous actively secure protocols. In particular, our protocol instantiated from the sparse Learning Parity with Noise (LPN) assumption is the first actively secure protocol for multivariate polynomials which has the minimum number of servers, without assuming fully homomorphic encryption.
]]></content:encoded>
<pubDate>Thu, 29 Feb 2024 09:22:37 +0000</pubDate>
</item>
<item>
<title>Kerblam — Anonymous Messaging System Protecting Both Senders and Recipients</title>
<link>https://eprint.iacr.org/2025/997</link>
<guid>https://eprint.iacr.org/2025/997</guid>
<content:encoded><![CDATA[
While popular messaging apps already offer end-to-end confidentially, end-to-end metadata privacy is still far from being practical. Although several meta-data hiding systems have been developed and some like Tor have been popular, the proposed solutions lack in one or more aspects: the Tor network is prone to easy low-resourced attacks, and most others solely focus on anonymity for senders or receivers but do not both. Some recent solutions do consider end-to-end anonymity, however, they put significant restrictions on how users use the system. Particularly, the receivers must stay online or trust online servers that receive messages on behalf of receivers. This work presents a scalable end-to-end anonymity messaging system, $\mathsf{ORAM}^{-}$, that overcomes the mentioned issues and restrictions. It stems from a key observation that combining the recently-emerged oblivious message retrieval (OMR) primitive with oblivious shuffling can offer the desired end-to-end anonymity without severely restricting the number of messages a sender may send or a receiver may receive. We build our solution using two non-colluding servers and recent OMR protocol HomeRun and a compatible oblivious shuffle protocol. We then extend our solution to allow larger messages by employing a novel two-server distributed oblivious RAM technique, called $\mathsf{ORAM}^{-}$. Our performance analysis demonstrates that with the increase in the number and size of messages, the performance improvement brought by $\mathsf{ORAM}^{-}$ becomes higher. Specifically, for $2^{20}$ messages of size 1KB, our scheme only needs $5.577$ s to transmit a message.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 01:13:53 +0000</pubDate>
</item>
<item>
<title>Distance-Aware OT with Application to Fuzzy PSI</title>
<link>https://eprint.iacr.org/2025/996</link>
<guid>https://eprint.iacr.org/2025/996</guid>
<content:encoded><![CDATA[
A two-party fuzzy private set intersection (PSI) protocol between Alice and Bob with input sets $A$ and $B$ allows Alice to learn nothing more than the points of Bob that are ``$\delta$-close'' to its points in some metric space $\texttt{dist}$. More formally, Alice learns only the set $\{ b\ |~\texttt{dist}{(a,b)} \leq \delta , a \in A,b\in B\}$ for a predefined threshold $\delta$ and distance metric $\texttt{dist}$, while Bob learns nothing about Alice's set.  Fuzzy PSI is a valuable privacy tool in scenarios where private set intersection needs to be computed over imprecise or measurement-based data, such as GPS coordinates or healthcare data. Previous approaches to fuzzy PSI rely on asymmetric cryptographic primitives, generic two-party computation (2PC) techniques like garbled circuits, or function secret sharing methods, all of which are computationally intensive and lead to poor concrete efficiency.

This work introduces a new modular framework for fuzzy PSI, {primarily built on efficient symmetric key primitives}. Our framework reduces the design of efficient fuzzy PSI to a novel variant of oblivious transfer (OT), which we term distance-aware random OT (da-ROT). This variant enables the sender to obtain two random strings $(r_0, r_1)$, while the receiver obtains one of these values $r_b$,  depending on whether the receiver’s input keyword $a$ and the sender’s input keyword $b$ are close in some metric space i.e., $\texttt{dist}{(a,b)} \leq \delta$. The da-ROT can be viewed as a natural extension of traditional OT, where the condition (choice bit) is known to the receiver. We propose efficient constructions for da-ROT based on standard OT techniques tailored for small domains, supporting distance metrics such as the Chebyshev norm, the Euclidean norm, and the Manhattan norm. 

By integrating these da-ROT constructions, our fuzzy PSI framework achieves up to a $14\times$ reduction in communication cost and up to a $54\times$ reduction in computation cost compared to previous state-of-the-art protocols, across input set sizes ranging from $2^8$ to $2^{16}$. Additionally, we extend our framework to compute fuzzy PSI cardinality and fuzzy join from traditional PSI-related functionalities. All proposed protocols are secure in the semi-honest model.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 23:58:08 +0000</pubDate>
</item>
<item>
<title>MOAI: Module-Optimizing Architecture for Non-Interactive Secure Transformer Inference</title>
<link>https://eprint.iacr.org/2025/991</link>
<guid>https://eprint.iacr.org/2025/991</guid>
<content:encoded><![CDATA[
The advent of Large Language Models (LLM) has brought about a new wave productivity, revolutionizing business operations while keeping cost relatively low. The human-like interface of LLM enables it to be easily integrated with business functions, thereby freeing up precious human resources for more complex, valuable tasks. However, due to the intensive computation and memory requirements of LLM inference, it is preferable and cheaper to deploy LLMs with the Cloud Service Providers (CSP) that offer high performance computation resources and low-latency networking. Nevertheless, privacy concerns have been raised about the possibility of data leakage to the CSP. In this work, we seek to address such privacy concerns through the use of Fully Homomorphic Encryption (FHE). FHE enables the CSP to work on data in its encrypted form, thus ensuring that the data stay private and secure. We propose the implementation of LLM inference with FHE. While a series of prior work have demonstrated that it is possible to execute LLM inference in a private manner, it remains a challenge to design a solution that is practical.
Our contributions are as follows: We provide the first end-to-end open-source implementation of a non-interactive transformer inference with FHE. We report an amortized time of 9.6 minutes of one input with 128 tokens when evaluating the BERT model on CPU. Our packing methods for encrypted matrices remove the need to repack ciphertext between encrypted matrix multiplication and activation layers. Additionally, we introduce interleaved batching to eliminate the internal rotations during ciphertext matrix multiplications. Our approach also avoids HE rotations in evaluations of the softmax and layerNorm, leading to a speedup of 4.22× and 122× than existing works respectively. Our implementation supports arbitrary token lengths, in contrast with existing solutions that requires a full token embedding. Our implementation can be found at GitHub.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 05:30:53 +0000</pubDate>
</item>
<item>
<title>OptAttest: Verifying Multi-List Multi-Hop History via a Hybrid Zero-Knowledge Architecture</title>
<link>https://eprint.iacr.org/2025/974</link>
<guid>https://eprint.iacr.org/2025/974</guid>
<content:encoded><![CDATA[
To prevent privacy-preserving digital assets from becoming instruments of despotism via unitary-executivist compliance regimes, we propose OptAttest, a hybrid zero-knowledge architecture. This system empowers users to optionally generate verifiable attestation history for the current (Hop 0) and immediately preceding (Hop 1) transactions involving their private commitments. For crucial 0-hop multi-list attestations, users employ Zero-Knowledge Proofs (ZKPs) of claims from selected Verifiable Credentials (VCs). Users achieve per-transaction efficiency with diverse VC types by pre-computing and caching proofs of their VC validity. This approach avoids mandated adherence to singular, fallible external standards. Opted-in lightweight updates create cryptographic accumulator summaries, verified by network infrastructure (e.g., Layer 2 scaling solutions using Zero-Knowledge Virtual Machines), and are paired with user-managed Intermediate Attestation Data Packets (IADPs) containing detailed evidence. For comprehensive verification, users can then generate full recursive proofs from these IADPs for their attestation-enabled funds, leveraging native zkVM recursion. The protocol facilitates optional attestation generation, not enforcement, allowing downstream policy application. Aiming to cultivate a permissionless ethos, we propose a user-centric balance between privacy and verifiable accountability, distinct from models compelling broader data access. Folding schemes are noted as potential future enhancements for recursive proof efficiency.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 08:42:32 +0000</pubDate>
</item>
<item>
<title>How Does Satoshi Set His Clock? Full Analysis of Nakamoto Consensus</title>
<link>https://eprint.iacr.org/2020/277</link>
<guid>https://eprint.iacr.org/2020/277</guid>
<content:encoded><![CDATA[
Nakamoto consensus, arguably the most exciting development in decentralized computation in the last few years, is in a sense a recasting of the traditional state machine replication problem in an unauthenticated setting, where furthermore parties come and go without warning. The protocol relies on a cryptographic primitive known as proof of work (PoW) which is used to throttle message passing. Importantly, the PoW diﬃculty level is appropriately adjusted throughout the course of the protocol execution relying on the blockchain’s timekeeping ability.

While the original formulation was only accompanied by rudimentary analysis, significant and steady progress has been made in abstracting the protocol’s properties and providing a formal analysis under various restrictions and protocol simplifications. Still, a full analysis of the protocol that includes its PoW target value recalculation and, notably, its timestamp adjustment mechanism, which equip it to operate in its intended setting of bounded communication delays, imperfect clocks and dynamic participation, has remained open. (Specifically, the protocol allows incoming block timestamps in the near future, as determined by a protocol parameter, and rejects blocks that have a timestamp in the past of the median time of a specific number of blocks on-chain [namely, 11].)

The gap is that Nakamoto’s protocol fundamentally depends on the blockchain itself to be a consistent timekeeper that should advance roughly on par with real time. In order to tackle this question we introduce a new analytical tool we call `hot-hand executions,' which capture the regular occurrence of high concentration of honestly generated blocks, and correspondingly put forth and prove a new blockchain property called `concentrated chain quality,' which may be of independent interest. Utilizing these tools and techniques we demonstrate that Nakamoto’s protocol achieves, under suitable conditions, consistency, liveness as well as (consistent) timekeeping.
]]></content:encoded>
<pubDate>Wed, 04 Mar 2020 08:11:05 +0000</pubDate>
</item>
<item>
<title>On Proving Equivalence Class Signatures Secure from Non-interactive Assumptions</title>
<link>https://eprint.iacr.org/2025/973</link>
<guid>https://eprint.iacr.org/2025/973</guid>
<content:encoded><![CDATA[
Equivalence class signatures (EQS), introduced by Hanser
and Slamanig (AC’14, J.Crypto’19), sign vectors of elements from a bi-
linear group. Their main feature is “adaptivity”: given a signature on a
vector, anyone can transform it to a (uniformly random) signature on any
multiple of the vector. A signature thus authenticates equivalence classes
and unforgeability is defined accordingly. EQS have been used to improve
the efficiency of many cryptographic applications, notably (delegatable)
anonymous credentials, (round-optimal) blind signatures, group signa-
tures and anonymous tokens. EQS security implies strong anonymity
(or blindness) guarantees for these schemes which hold against malicious signers without trust assumptions.

Unforgeability of the original EQS construction is proven directly in
the generic group model. While there are constructions from standard
assumptions, these either achieve prohibitively weak security notions
(PKC’18) or they require a common reference string (AC’19, PKC’22),
which reintroduces trust assumptions avoided by EQS.

In this work we ask whether EQS schemes that satisfy the original secu-
rity model can be proved secure under standard (or even non-interactive)
assumptions with standard techniques. Our answer is negative: assum-
ing a reduction that, after running once an adversary breaking unforge-
ability, breaks a non-interactive computational assumption, we construct
efficient meta-reductions that either break the assumption or break class-
hiding, another security requirement for EQS.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 07:47:44 +0000</pubDate>
</item>
<item>
<title>Sabot: Efficient and Strongly Anonymous Bootstrapping of Communication Channels</title>
<link>https://eprint.iacr.org/2025/971</link>
<guid>https://eprint.iacr.org/2025/971</guid>
<content:encoded><![CDATA[
Anonymous communication is vital for enabling individuals to participate in social discourse without fear of marginalization or persecution. An important but often overlooked part of anonymous communication is the bootstrapping of new communication channels, generally assumed to occur out-of-band. However, if the bootstrapping discloses metadata, communication partners are revealed even if the channel itself is fully anonymized. We propose Sabot, the first anonymous bootstrapping protocol that achieves both strong cryptographic privacy guarantees and bandwidth-efficient communication. In Sabot, clients cooperatively generate a private relationship matrix, which encodes who wants to contact whom. Clients communicate with k ≥ 2 servers to obtain “their” part of the matrix and augment the received information using Private Information Retrieval (PIR) to learn about their prospective communication partners. Compared to previous solutions, Sabot achieves stronger privacy guarantees and reduces the bandwidth overhead by an order of magnitude.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 19:46:48 +0000</pubDate>
</item>
<item>
<title>Decentralized Data Archival: New Definitions and Constructions</title>
<link>https://eprint.iacr.org/2025/969</link>
<guid>https://eprint.iacr.org/2025/969</guid>
<content:encoded><![CDATA[
We initiate the study of a new abstraction 
called incremental decentralized data archival (${\sf iDDA}$). 
Specifically, imagine that there is an ever-growing, massive database such as a blockchain, a comprehensive  human knowledge base like Wikipedia,  or the Internet archive.  We want to build a decentralized archival of such datasets 
to ensure long-term robustness and sustainability.  

We identify several important properties
that an ${\sf iDDA}$ scheme should satisfy. First, 
to promote heterogeneity and decentralization, 
we want to encourage even weak nodes  with limited space (e.g., users' home computers) to contribute.  The minimum space requirement to contribute should be approximately independent of the data size.   Second, if a collection of nodes together receive rewards commensurate with contributing a total of $m$ blocks of space, then we want the following reassurances:  1) if $m$ is at least the database size, we should be able to reconstruct the entire dataset; and 2)  these nodes should actually be commiting roughly $m$ space in aggregate --- even when $m$ is much larger than the data size,  the nodes should be storing redundant copies of the database rather than storing just one copy, and yet impersonating arbitrarily many pseudonyms to get unbounded rewards.  

We propose new definitions  that mathematically formalize the aforementioned requirements of an ${\sf iDDA}$ scheme. 
We also devise an efficient construction in the random oracle model which satisfies the desired security requirements.   Our scheme incurs  only $\widetilde{O}(1)$ audit cost, as well as  $\widetilde{O}(1)$ update cost for both the publisher and each node, where $\widetilde{O}(\cdot)$ hides polylogarithmic factors. Further, the minimum space provisioning required to contribute is as small as polylogarithmic. 

Our construction exposes several interesting technical challenges. Specifically, we show that a straightforward application of the standard hierarchical data structure fails, since both our security definition and  the underlying cryptographic primitives we employ lack the desired compositional  guarantees. We devise novel techniques to overcome these compositional issues, resulting in a construction with provable security while still retaining efficiency. Finally, our new definitions also make a conceptual contribution, and lay the theoretical groundwork for the study of ${\sf iDDA}$.   We raise several interesting open problems along this direction.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 17:06:25 +0000</pubDate>
</item>
<item>
<title>TOOP: A transfer of ownership protocol over Bitcoin</title>
<link>https://eprint.iacr.org/2025/964</link>
<guid>https://eprint.iacr.org/2025/964</guid>
<content:encoded><![CDATA[
The Transfer of Ownership Protocol (TOOP) enables a secure transfer of assets from Bitcoin to other blockchains and back. This is achieved through a committee-based validation protocol that requires only 1-out-of-nhonest security. The protocol operates in distinct phases: the lock phase, where the initial setup and individual assets are locked on Bitcoin, and the unlocking with ownership transfer phase, where the asset is transferred to a possibly different legitimate owner. This protocol solves a limitation of all existing BitVM-like protocols that restricts the unlocking transfers to only addresses known and preregistered during lock and setup. Accordingly, our protocol avoids the financially costly, regulatory problematic, and congestion-prone front-and-reimburse paradigm. TOOP has been implemented for the first time in Cardinal, a protocol for wrapping Bitcoin Unspent Transaction Outputs (UTxOs) onto the Cardano blockchain, with Bitcoin Ordinals represented as Cardano Non-Fungible Tokens (NFTs).
]]></content:encoded>
<pubDate>Tue, 27 May 2025 02:40:40 +0000</pubDate>
</item>
<item>
<title>Accountable Light Client Systems for Proof-of-Stake Blockchains</title>
<link>https://eprint.iacr.org/2022/1205</link>
<guid>https://eprint.iacr.org/2022/1205</guid>
<content:encoded><![CDATA[
A major challenge for blockchain interoperability is having an on-chain light client protocol that is both efficient and secure. We present a protocol that provides short proofs about the state of a decentralised consensus protocol while being able to detect misbehaving parties. To do this naively, a verifier would need to maintain an updated list of all participants' public keys which makes the corresponding proofs long. In general, existing solutions either lack accountability or are not efficient. We define and design a committee key scheme with short proofs that do not include any of the individual participants' public keys in plain. Our committee key scheme, in turn, uses a custom designed SNARK which has a fast prover time. Moreover, using our committee key scheme, we define and design an accountable light client system as the main cryptographic core for building bridges between proof of stake blockchains. Finally, we implement a prototype of our custom SNARK for which we provide benchmarks.
]]></content:encoded>
<pubDate>Mon, 12 Sep 2022 23:36:40 +0000</pubDate>
</item>
<item>
<title>LEAF: A Low-Latency Evaluation Architecture for Feedforward Block in Privacy-Preserving Transformer Inference</title>
<link>https://eprint.iacr.org/2025/956</link>
<guid>https://eprint.iacr.org/2025/956</guid>
<content:encoded><![CDATA[
Fully homomorphic encryption (FHE) is an appealing and promising solution for privacy-preserving transformer inference to protect users' privacy. However, the huge computational overhead makes it unrealistic to apply FHE in real-world transformers for large language models (LLM). Current FHE-based approaches to secure transformer inference face significant performance challenges, with total latency exceeding 5 hours for 32-input batches.
The feedforward block, comprising a large-scale matrix multiplication followed by a GELU evaluation, is widely recognized as one of the most computationally intensive components in privacy-preserving transformer inference. In the state-of-the-art system NEXUS, evaluating the feedforward block incurs a total latency of 5,378 seconds, processing up to 32 inputs per batch. 
We aim to reduce the latency and propose LEAF, a low-latency evaluation architecture for the feedforward block. LEAF introduces a novel combination of fast matrix multiplication and an asymptotically efficient algorithm for computing non-polynomial activations. When evaluated on the BERT-base model, LEAF reduces total latency to 53.4 seconds, offering a $100\times$ speedup over the state-of-the-art method in the same environment. Our implementations are available.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 07:16:29 +0000</pubDate>
</item>
<item>
<title>Breaking Poseidon Challenges with Graeffe  Transforms and Complexity Analysis by FFT  Lower Bounds</title>
<link>https://eprint.iacr.org/2025/950</link>
<guid>https://eprint.iacr.org/2025/950</guid>
<content:encoded><![CDATA[
Poseidon and Poseidon2 are cryptographic hash functions designed for efficient zero-knowledge proof protocols and have been widely adopted in Ethereum applications. To encourage security research, the Ethereum Foundation announced a bounty program in November 2024 for breaking the Poseidon challenges, i.e. solving the CICO (Constrained Input, Constrained Output) problems for round-reduced Poseidon constructions. In this paper, we explain how to apply the Graeffe transform to univariate polynomial solving, enabling efficient interpolation attacks against Poseidon. We will provide an open-source code and details our approach for solving several challenges valued at $20000 in total. Compared to existing attacks, we improves 2^{13} and 2^{4.5} times in wall time and memory usage, respectively. For all challenges we solved, the cost of memory access turns out to be an essential barrier, which makes the security margin much larger than expected. We actually prove that the memory access cost for FFT grows as the 4/3-power of the input size, up to a logarithmic factor. This indicates the commonly used pseudo linear estimate may be overly conservative. This is very different from multivariate equation solving whose main bottleneck is linear algebra over finite fields. Thus, it might be preferable to choose parameters such that the best known attack is interpolation, as it presents more inherent hardness.
]]></content:encoded>
<pubDate>Sun, 25 May 2025 03:08:44 +0000</pubDate>
</item>
<item>
<title>On the (in)security of Proofs-of-Space based Longest-Chain Blockchains</title>
<link>https://eprint.iacr.org/2025/942</link>
<guid>https://eprint.iacr.org/2025/942</guid>
<content:encoded><![CDATA[
The Nakamoto consensus protocol underlying the Bitcoin blockchain uses proof of work as a voting mechanism. Honest miners who contribute hashing power towards securing the chain try to extend the longest chain they are aware of. Despite its simplicity, Nakamoto consensus achieves meaningful security guarantees assuming that at any point in time, a majority of the hashing power is controlled by honest parties. This also holds under ``resource variability'', i.e., if the total hashing power varies greatly over time.

Proofs of space (PoSpace) have been suggested as a more sustainable replacement for proofs of work. Unfortunately, no construction of a ``longest-chain'' blockchain based on PoSpace, that is secure under dynamic availability, is known. In this work, we prove that without additional assumptions no such protocol exists. We exactly quantify this impossibility result by proving a bound on the length of the fork required for double spending as a function of the adversarial capabilities. This bound holds for any chain selection rule, and we also show a chain selection rule (albeit a very strange one) that almost matches this bound.  

Concretely, we consider a security game in which the honest parties at any point control $\phi>1$ times more space than the adversary. The adversary can change the honest space by a factor $1\pm \varepsilon$ with every block (dynamic availability), and ``replotting'' the space (which allows answering two challenges using the same space) takes as much time as $\rho$ blocks.

We prove that no matter what chain selection rule is used, in this game the adversary can create a fork of length $\phi^2\cdot \rho / \varepsilon$ that will be picked as the winner by the chain selection rule.

We also provide an upper bound that matches the lower bound up to a factor $\phi$. There exists a chain selection rule (albeit a very strange one) which in the above game requires forks of length at least $\phi\cdot \rho / \varepsilon$.



Our results show the necessity of additional assumptions to create a secure PoSpace based longest-chain blockchain. The Chia network in addition to PoSpace uses a verifiable delay function. 
Our bounds show that an additional primitive like that is necessary.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 14:58:30 +0000</pubDate>
</item>
<item>
<title>Attacking Poseidon via Graeffe-Based Root-Finding over NTT-Friendly Fields</title>
<link>https://eprint.iacr.org/2025/937</link>
<guid>https://eprint.iacr.org/2025/937</guid>
<content:encoded><![CDATA[
This paper explores the algebraic structure of the Poseidon and Poseidon2 permutations
over NTT-friendly finite fields, with a focus on preimage recovery via root-finding
techniques. We introduce an algorithm for efficiently identifying single roots of high-degree
univariate polynomials that emerge from these constructions, based on the Graeffe transform
and the tangent Graeffe method. Our approach is evaluated on reduced-round bounty
instances of these permutations at various security levels, as proposed by the Ethereum
Foundation, demonstrating practical effectiveness. These results yield new insights into the
security of permutation-based cryptographic primitives instantiated over NTT-friendly prime
fields.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 07:24:02 +0000</pubDate>
</item>
<item>
<title>SEEC: Memory Safety Meets Efficiency in Secure Two-Party Computation</title>
<link>https://eprint.iacr.org/2025/930</link>
<guid>https://eprint.iacr.org/2025/930</guid>
<content:encoded><![CDATA[
Secure Multi-Party Computation (MPC) allows multiple parties to perform privacy-preserving computation on their secret data.  MPC protocols based on secret sharing have high throughput which makes them well-suited for batch processing, where multiple instances are evaluated in parallel. 
So far, practical implementations of secret sharing-based MPC protocols mainly focus on runtime and communication efficiency, so the memory overhead of protocol implementations is often overlooked. Established techniques to reduce the memory overhead for constant-round garbled circuit protocols cannot be directly applied to secret sharing-based protocols because they would increase the round complexity. Additionally, state-of-the-art implementations of secret sharing-based MPC protocols are implemented in C/C++ and may exhibit memory unsafety and memory leaks, which could lead to undefined behavior.

In this paper, we present SEEC: SEEC Executes Enormous Circuits, a framework for secret sharing-based MPC 
with a novel approach to address memory efficiency and safety without compromising on runtime and communication efficiency. We realize SEEC in Rust, a language known for memory-safety at close-to-native speed. To reduce the memory footprint, we develop an in-memory representation for sub-circuits. Thus, we never inline sub-circuit calls during circuit evaluation, a common issue that blows up memory usage in MPC implementations. 
We compare SEEC with the state-of-the-art secret sharing-based MPC frameworks ABY (NDSS'15), MP-SPDZ (CCS'20), and MOTION (TOPS'22) w.r.t. runtime, memory, and communication efficiency. Our results show that our reliable and memory-safe implementation has competitive or even better performance.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 09:42:45 +0000</pubDate>
</item>
<item>
<title>The DROP Protocol: Dispute Resolution via Observation in Public for Verifiable, In-Person Voting</title>
<link>https://eprint.iacr.org/2025/929</link>
<guid>https://eprint.iacr.org/2025/929</guid>
<content:encoded><![CDATA[
Dispute resolution has been a significant challenge in verifiable election protocols since such protocols were first proposed more than forty years ago. This work explores the problem from a new perspective and offers strong dispute resolution for in-person voting by depending on observers.

It proposes a simple definition of dispute resolution as a property of a voting protocol---a definition that is independent of any other security goal. It also presents the DROP protocol, a verifiable, in-person voting protocol that runs in the presence of observers who will always reach a correct conclusion in the case of a dispute without ever being able to compromise privacy or facilitate coercion.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 09:01:01 +0000</pubDate>
</item>
<item>
<title>Zero-knowledge Authenticator for Blockchain: Policy-private and Obliviously Updateable</title>
<link>https://eprint.iacr.org/2025/921</link>
<guid>https://eprint.iacr.org/2025/921</guid>
<content:encoded><![CDATA[
Transaction details and participant identities on the blockchain are often publicly exposed. In this work, we posit that blockchain's transparency should not come at the cost of privacy. To that end, we introduce zero-knowledge authenticators (zkAt), a new cryptographic primitive for privacy-preserving authentication on public blockchains. zkAt utilizes zero-knowledge proofs to enable users to authenticate transactions, while keeping the underlying authentiction policies private. 

Prior solutions for such {policy-private authentication} required the use of threshold signatures, which can only hide the threshold access structure itself. In comparison, zkAt provides privacy for arbitrarily complex authentication policies, and offers a richer interface even within the threshold access structure by, for instance, allowing for the combination of signatures under distinct signature schemes.

In order to construct zkAt, we design a compiler that transforms the popular Groth16 non-interactive zero knowledge (NIZK) proof system into a NIZK with equivocable verification keys, a property that we define in this work. Then, for any zkAt constructed using proof systems with this new property, we show that all public information must be independent of the policy, thereby achieving policy-privacy.

Next, we give an extension of zkAt, called zkAt+ wherein, assuming a trusted authority, policies can be updated obliviously in the sense that a third-party learns no new information when a policy is updated by the policy issuer. We also give a theoretical construction for zkAt+ using recursive NIZKs, and explore the integration of zkAt into modern blockchains. Finally, to evaluate their feasibility, we implement both our schemes for a specific threshold access structure. Our findings show that zkAt achieves comparable performance to traditional threshold signatures, while also attaining privacy for significantly more complex policies with very little overhead.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 05:34:51 +0000</pubDate>
</item>
<item>
<title>Rep3 Reloaded: On the Cost of Function-Dependent Preprocessing in Semi-Honest 3PC with Honest Majority</title>
<link>https://eprint.iacr.org/2025/919</link>
<guid>https://eprint.iacr.org/2025/919</guid>
<content:encoded><![CDATA[
Rep3 denotes the implementation of semi-honest three-party computation with an honest majority in MP-SPDZ (CCS'20). It uses replicated secret sharing with one message per multiplication and party as proposed by Araki et al. (CCS'16). This approach is rivaled by Astra (CCSW'19) and Trio (PETS'25), which use function-dependent preprocessing. The latter is more involved than, e.g., Beaver triples which can be used as a commodity.

In this work, we present a full implementation of Astra and Trio in MP-SPDZ, and we evaluate the costs of the different approaches. We show the equivalence of the schemes, which implies that a protocol in any of the schemes can be translated to one in another with the same overall communication cost. We also present an improvement to two important building blocks for privacy-preserving computation, namely secure comparison and probabilistic truncation used in fixed-point arithmetic. To evaluate our implementation, we have benchmarked machine learning training and inference in all three schemes, improving on Keller and Sun (ICML'22) by over 30%. Our implementation also highlights the large storage requirements of function-dependent preprocessing as it runs the two phases separately. To the best of our knowledge, this is the first implementation to do so.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 03:02:09 +0000</pubDate>
</item>
<item>
<title>The Accidental Computer: Polynomial Commitments from Data Availability</title>
<link>https://eprint.iacr.org/2025/918</link>
<guid>https://eprint.iacr.org/2025/918</guid>
<content:encoded><![CDATA[
In this paper, we show two simple variations of a data availability scheme which enable it to act as a multilinear polynomial commitment scheme over the data in a block. The first variation enables commitments over all of the block's data with zero prover overhead: the data availability construction simply serves both purposes. The second variation allows commitments over subsets of data with nonzero but still concretely small proving costs, since most work is already done during data encoding. This works especially well for blockchains with a high degree of data parallelism, as data-parallel computation is particularly amenable to efficient GKR proofs. Since, in GKR, opening the polynomial commitment contributes significantly to prover costs, our construction enables the prover to reuse work already done by the data availability scheme, reducing—or wholly removing—work associated with the polynomial commitment scheme.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:46:09 +0000</pubDate>
</item>
<item>
<title>Automated Verification of Consistency in Zero-Knowledge Proof Circuits</title>
<link>https://eprint.iacr.org/2025/916</link>
<guid>https://eprint.iacr.org/2025/916</guid>
<content:encoded><![CDATA[
Circuit languages like Circom and Gnark have become essential tools for programmable zero-knowledge cryptography,  allowing developers to build privacy-preserving applications. These domain-specific languages (DSLs) encode both the computation to be verified (as a witness generator) and the corresponding arithmetic circuits, from which the prover and verifier can be automatically generated.   However, for these programs to be correct, the witness generator and the arithmetic circuit need to be mutually consistent in a certain technical sense, and inconsistencies can result in security vulnerabilities. This paper formalizes the consistency requirement for circuit DSLs and proposes the first automated technique for verifying it. We evaluate the method on hundreds of real-world circuits, demonstrating its utility for both automated verification and uncovering errors that existing tools are unable to detect.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 22:40:21 +0000</pubDate>
</item>
<item>
<title>Enforcing arbitrary constraints on Bitcoin transactions</title>
<link>https://eprint.iacr.org/2025/912</link>
<guid>https://eprint.iacr.org/2025/912</guid>
<content:encoded><![CDATA[
The challenge of enforcing constraints on Bitcoin transac-
tions has recently gained a lot of attention. The current approach to
solve this problem falls short in certain aspects, such as privacy and
programmability. We design a new solution that leverages zkSNARKs
and allows enforcing arbitrary constraints on Bitcoin transactions while
maintaining some information private. Our approach also bypasses the
non-Turing completeness of Bitcoin Script, allowing the enforcement of
unbounded constraints, namely constraints that repeat a certain opera-
tion an unbounded number of times.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 10:47:25 +0000</pubDate>
</item>
<item>
<title>Covert Attacks on Machine Learning Training in Passively Secure MPC</title>
<link>https://eprint.iacr.org/2025/906</link>
<guid>https://eprint.iacr.org/2025/906</guid>
<content:encoded><![CDATA[
Secure multiparty computation (MPC) allows data owners to train machine learning models on combined data while keeping the underlying training data private. The MPC threat model either considers an adversary who passively corrupts some parties without affecting their overall behavior, or an adversary who actively modifies the behavior of corrupt parties. It has been argued that in some settings, active security is not a major concern, partly because of the potential risk of reputation loss if a party is detected cheating.

In this work we show explicit, simple, and effective attacks that an active adversary can run on existing passively secure MPC training protocols, while keeping essentially zero risk of the attack being detected. The attacks we show can compromise both the integrity and privacy of the model, including attacks reconstructing exact training data.
Our results challenge the belief that a threat model that does not include malicious behavior by the involved parties may be reasonable in the context of PPML, motivating the use of actively secure protocols for training.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:59:57 +0000</pubDate>
</item>
<item>
<title>A Generic Framework for Practical Lattice-Based Non-interactive Publicly Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/901</link>
<guid>https://eprint.iacr.org/2025/901</guid>
<content:encoded><![CDATA[
Non-interactive publicly verifiable secret sharing (PVSS) schemes enable the decentralized (re-)sharing of secrets in adversarial environments, allowing anyone to verify the correctness of distributed shares. Such schemes are essential for large-scale decentralized applications, including committee-based systems that require both transparency and robustness. However, existing PVSS schemes rely on group-based cryptography, resulting them vulnerable to quantum attacks and limiting their suitability for post-quantum applications.

In this work, we propose the first practical, fully lattice-based, non-interactive PVSS scheme, grounded on standard lattice assumptions for post-quantum security. At the heart of our design is a generic framework that transforms vector commitments and linear encryption schemes into efficient PVSS protocols. We enhance vector commitments by incorporating functional hiding and proof of smallness, ensuring that encrypted shares are both verifiable and privacy-preserving. Our construction introduces two tailored lattice-based encryption schemes, each supporting efficient proofs of decryption correctness. This framework provides strong verifiability guarantees while maintaining low proof sizes and computational efficiency, making it suitable for systems with large numbers of participants.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 16:24:57 +0000</pubDate>
</item>
<item>
<title>Blinding Post-Quantum Hash-and-Sign Signatures</title>
<link>https://eprint.iacr.org/2025/895</link>
<guid>https://eprint.iacr.org/2025/895</guid>
<content:encoded><![CDATA[
Blind signature schemes are essential for privacy-preserving applications such as electronic voting, digital currencies or anonymous credentials. In this paper, we revisit Fischlin's framework for round-optimal blind signature schemes and its recent efficient lattice-based instantiations. Our proposed framework compiles any post-quantum hash-and-sign signature scheme into a blind signature scheme. The resulting scheme ensures blindness by design and achieves one-more unforgeability, relying solely on the unforgeability of the underlying signature scheme and the random oracle model.

To achieve this we introduce the notion of commit-append-and-prove (CAP) systems, which generalizes traditional commit-and-prove system by making their commitments updatable before proving. This building block allows us to unlock the technical challenges encountered when generalizing previous variants of the Fischlin's framework to any hash-and-sign signature scheme. We provide efficient CAP system instantiations based on recent MPC-in-the-Head techniques.

We showcase our framework by constructing blind versions of UOV and Wave, thereby introducing the first practical blind signatures based on multivariate cryptography and code-based cryptography. Our blind UOV signatures range from 3.8 KB to 11 KB, significantly outperforming previous post-quantum blind signatures, such as the 22 KB lattice-based blind signatures, which were the most compact until now.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 16:22:39 +0000</pubDate>
</item>
<item>
<title>Practical cryptanalysis of pseudorandom correlation generators based on quasi-Abelian syndrome decoding</title>
<link>https://eprint.iacr.org/2025/892</link>
<guid>https://eprint.iacr.org/2025/892</guid>
<content:encoded><![CDATA[
Quasi-Abelian Syndrome Decoding (QA-SD) is a recently in-
troduced generalization of Ring-LPN that uses multivariate polynomials
rings. As opposed to Ring-LPN, it enables the use of small finite field such as GF(3) and GF(4). It was introduced by Bombar et al (Crypto 2023) in order to obtain pseudorandom correlation generators for Beaver triples over small fields. This theoretical work was turned into a concrete and efficient protocol called F4OLEage by Bombar et al. (Asiacrypt 2024) that allows several parties to generate Beaver triples over GF(2).

We propose efficient algorithms to solve the decoding problem underlying
the QA-SD assumption. We observe that it reduce to a sparse multivariate polynomial interpolation problem over a small finite field where the
adversary only has access to random evaluation points, a blind spot in
the otherwise rich landscape of sparse multivariate interpolation. We develop new algorithms for this problem: using simple techniques we interpolate polynomials with up to two monomials. By sending the problem
to the field of complex numbers and using convex optimization techniques inspired by the field of “compressed sensing”, we can interpolate
polynomials with more terms.

This enables us to break in practice parameters proposed by Bombar et
al. at Crypto’23 and Asiacrypt’24 as well as Li et al. at Eurocrypt’25
(IACR flagship conferences Grand Slam). In the case of the F4OLEage
protocol, our implementation recovers all the secrets in a few hours with
probability 60%. This not only invalidates the security proofs, but it
yields real-life privacy attacks against multiparty protocols using the
Beaver triples generated by the broken pseudorandom correlation generators.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 11:54:59 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure Blockchain-Aided Decentralized Storage Networks: Formalization and Generic Construction</title>
<link>https://eprint.iacr.org/2025/887</link>
<guid>https://eprint.iacr.org/2025/887</guid>
<content:encoded><![CDATA[
This work revisits the current Decentralized Storage Network (DSN) definition to propose a novel general construction based on a UTxO based ledger. To the best of our knowledge, this is the first adaptively secure UTxO blockchain-aided DSN. More concretely, we revisit the currently existing designs to thoroughly formalize the DSN definition and its security. Moreover we present a general construction, which a client delegates data to a DSN that keeps custody of it during a jointly agreed period. Our newly proposed approach, leveraged by the Extended UTxO (EUTxO) Model, neatly allows the storage network to offer automatic verifiability, i.e., without any interaction of the data owner, via proofs published in the blockchain.  In summary, this work presents a redesign of the DSN with the aid of a EUTxO based blockchain, by (1) putting forth a formal and rigorous description of a blockchain-aided DSN protocol, (2) offering a thorough description of a practical EUTxO based DSN, and (3) detailing a security analysis showing that our protocol is adaptively secure by providing (rational) security guarantees.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 03:36:59 +0000</pubDate>
</item>
<item>
<title>$k$-out-of-$n$ Proofs and Application to Privacy-Preserving Cryptocurrencies</title>
<link>https://eprint.iacr.org/2025/884</link>
<guid>https://eprint.iacr.org/2025/884</guid>
<content:encoded><![CDATA[
Cryptocurrencies enable transactions among mutually distrustful users, necessitating strong privacy, namely, concealing both transfer amounts and participants' identities, while maintaining practical efficiency. While UTXO-based cryptocurrencies offer mature solutions achieving strong privacy and supporting multi-receiver transfers, account-based cryptocurrencies currently lack practical solutions that simultaneously guarantee these properties.

With the aim to close this gap, we propose a generic framework for account-based cryptocurrencies that achieve strong  privacy and support multi-receiver transfers, and then give a practical instantiation called \textit{Anonymous PGC}. Experimental results demonstrate that, for a 64-sized anonymity set and 8 receivers, Anonymous PGC outperforms Anonymous Zether (IEEE S\&amp;P 2021) --- which offers limited anonymity and no multi-receiver support --- 
achieving 2.6$\times$ faster transaction generation, 5.1$\times$ faster verification, 
and 2.1$\times$ reduction in transaction size. 


Along the way of building Anonymous PGC, we present two novel $k$-out-of-$n$ proofs. First, we generalize the Groth-Kohlweiss (GK) $1$-out-of-$n$ proof (EUROCRYPT 2015) to the $k$-out-of-$n$ case, resolving an open problem of its natural generalization. Particularly, the obtained $k$-out-of-$n$ proof lends itself to integrate with range proofs in a seamless way, yielding an efficient $k$-out-of-$n$ range proof, which demonstrates that $k$ witnesses among $n$ instances lie in specific ranges. Second, we extend the Attema-Cramer-Fehr (ACF) $k$-out-of-$n$ proof (CRYPTO 2021) to support distinct group homomorphisms, improving its expressiveness while reducing both prover and verifier complexities from quadratic to linear. We believe these two $k$-out-of-$n$ proofs are of independent interest, and will find more applications in privacy-preserving scenarios.
]]></content:encoded>
<pubDate>Sat, 17 May 2025 15:58:11 +0000</pubDate>
</item>
<item>
<title>Papercraft: Lattice-based Verifiable Delay Function Implemented</title>
<link>https://eprint.iacr.org/2025/879</link>
<guid>https://eprint.iacr.org/2025/879</guid>
<content:encoded><![CDATA[
A verifiable delay function (VDF) requires a specified number of sequential steps to compute, yet the validity of its output can be verified efficiently, much faster than recomputing the function from scratch. VDFs are a versatile cryptographic tool, with many industrial applications, such as blockchain consensus protocols, lotteries and verifiable randomness. Unfortunately, without exceptions, all known practical VDF constructions are broken by quantum algorithms. In this work, we investigate the practicality of VDFs with plausible post-quantum security. We propose Papercraft, a working implementation of a VDF based entirely on lattice techniques and thus plausibly post-quantum secure. Our VDF is based on new observations on lattice-based succinct argument systems with many low-level optimisations, yielding the first lattice-based VDF that is implementable on today's hardware. As an example, our Papercraft implementation can verify a computation of almost 6 minutes in just 7 seconds. Overall, our work demonstrates that lattice-based VDFs are not just a theoretical construct, paving the way for their practical deployment.
]]></content:encoded>
<pubDate>Sat, 17 May 2025 04:46:56 +0000</pubDate>
</item>
<item>
<title>Decentralized Multi-Authority Attribute-Based Inner-Product Functional Encryption: Noisy and Evasive Constructions from Lattices</title>
<link>https://eprint.iacr.org/2025/874</link>
<guid>https://eprint.iacr.org/2025/874</guid>
<content:encoded><![CDATA[
We initiate the study of multi-authority attribute-based functional encryption for noisy inner-product functionality, and propose two new primitives: (1) multi-authority attribute-based (noisy) inner-product functional encryption (MA-AB(N)IPFE), and (2) multi-authority attribute-based evasive inner-product functional encryption (MA-ABevIPFE). The MA-AB(N)IPFE primitive generalizes the existing multi-authority attribute-based inner-product functional encryption schemes by Agrawal et al. [AGT21], by enabling approximate inner-product computation under decentralized attribute-based control. This newly proposed notion combines the approximate function evaluation of noisy inner-product functional encryption (IPFE) with the decentralized key-distribution structure of multi-authority attribute-based encryption. To better capture noisy functionalities within a flexible security framework, we formulate the MA-ABevIPFE primitive under a generic-model view, inspired by the evasive IPFE framework by Hsieh et al. [HLL24]. It shifts the focus from pairwise ciphertext indistinguishability to a more relaxed pseudorandomness-based game.

  To support the above notions, we introduce two variants of lattice-based computational assumptions: 
- The evasive IPFE assumption (evIPFE): it generalizes the assumption introduced in [HLL24] to the multi-authority setting and admits a reduction from the evasive LWE assumption proposed by Waters et al. [WWW22];

- The indistinguishability-based evasive IPFE assumption (IND-evIPFE): it is an indistinguishability-based variant of the evasive IPFE assumption designed to capture the stronger security guarantees required by our MA-AB(N)IPFE scheme.

  We present concrete lattice-based constructions for both primitives supporting subset policies, building upon the framework of [WWW22]. Our schemes are proven to be statically secure in the random oracle model under the standard LWE assumption and the newly introduced assumptions. Additionally, we demonstrate that our MA-AB(N)IPFE scheme can be transformed, via standard modulus switching, into a noiseless MA-ABIPFE scheme that supports exact inner-product functionality consistent with the MA-IPFE syntax in [AGT21,DP23]. This yields the first lattice-based construction of such a primitive. All our schemes support arbitrary polynomial-size attribute policies and are secure in the random oracle model under lattice assumptions with a sub-exponential modulus-to-noise ratio, making them practical candidates for noise-tolerant, fine-grained access control in multi-authority settings.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 17:28:06 +0000</pubDate>
</item>
<item>
<title>From List-Decodability to Proximity Gaps</title>
<link>https://eprint.iacr.org/2025/870</link>
<guid>https://eprint.iacr.org/2025/870</guid>
<content:encoded><![CDATA[
Proximity testing for linear codes is a fundamental problem in coding theory with critical applications in cryptographic protocols, blockchain, and distributed storage systems. This work addresses the proximity gaps for linear codes, a crucial aspect for efficiently verifying whether a batch of codewords is close to a given code. We present a general framework for deriving proximity gaps from the list-decodability properties of the underlying linear code.

Our main result shows that if a code $C\subseteq \mathbb{F}_q^n$ is $(p,L)$-list-decodable, then the probability that a random combination of a batch of $t$ codewords containing a $\delta$-far codeword (for $\delta\le 1-\sqrt{1-p+\varepsilon}$) remains $\delta$-far from $C$ is bounded by $O(\frac{tL^2pn}{q}+\frac{t}{\varepsilon q})$. This result also establishes a form of (mutual) correlated agreement for linear codes, which can be used to strengthen soundness analyses in protocols that rely on proximity testing, thereby reducing query complexity and enabling practical instantiations over smaller finite fields.
In particular, we apply our main result to randomly punctured Reed–Solomon codes and folded Reed–Solomon codes—both of which are known to achieve list-decodability up to capacity—and derive linear proximity gaps for these families under the Johnson bound.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 12:11:05 +0000</pubDate>
</item>
<item>
<title>Delegated PSI from Homomorphic Encryptions</title>
<link>https://eprint.iacr.org/2025/868</link>
<guid>https://eprint.iacr.org/2025/868</guid>
<content:encoded><![CDATA[
This paper presents an efficient protocol for private set intersection in a setting with multiple set owners and a semi-honest cloud server. The core idea is to reduce the intersection computation to secure operations over Bloom filters, enabling both scalability and efficiency. By leveraging this transformation, our protocols achieve strong privacy guarantees while minimizing computation and communication overhead.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 10:26:46 +0000</pubDate>
</item>
<item>
<title>Side Channel Analysis in Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/867</link>
<guid>https://eprint.iacr.org/2025/867</guid>
<content:encoded><![CDATA[
Homomorphic encryption provides many opportunities for privacy-aware processing, including with methods related to machine learning. Many of our existing cryptographic methods have been shown in the past to be susceptible to side channel attacks. With these, the implementation of the cryptographic methods can reveal information about the private keys used, the result, or even the original plaintext. An example of this includes the processing of the RSA exponent using the Montgomery method, and where 0's and 1's differ in their processing time for modular exponentiation. With FHE, we typically use lattice methods, and which can have particular problems in their implementation in relation to side channel leakage. This paper aims to outline a range of weaknesses within FHE implementations as related to side channel analysis. It outlines a categorization for side-channel analysis, some case studies, and mitigation strategies.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 09:52:45 +0000</pubDate>
</item>
<item>
<title>Data Availability for Thousands of Nodes</title>
<link>https://eprint.iacr.org/2025/865</link>
<guid>https://eprint.iacr.org/2025/865</guid>
<content:encoded><![CDATA[
Scalable data availability (DA) is essential for high-throughput, decentralized blockchains, enabling lightweight nodes to verify block availability without incurring the prohibitive costs of full data replication. 
Reed-Solomon (RS) code commitment schemes underpin modern DA protocols by ensuring that dispersed data fragments can be verified as part of a valid codeword, even in the presence of malicious block producers. 
However, state-of-the-art schemes such as FRIDA (Crypto'24), while computationally efficient, incur substantial per-node communication overhead at the scale of thousands of network nodes, often 5.7$\times$ the size of the actual data fragment.

In this work, we introduce CONDA, a new interleaved RS code commitment scheme that significantly reduces the communication overhead while retaining FRIDA's prover efficiency. 
At its core is a novel evaluation consolidation technique for polynomial commitment scheme (PCS) that reduces the problem of proving $n$ evaluations at fixed points (one per verifier) to a single evaluation at a random point, using logarithmic communication.
This technique is lightweight, hash-based, and compatible with any multilinear PCS.

To further optimize for DA applications, we introduce LightLigero, a new multilinear PCS that improves upon DeepFold (Sec'25) with $O(\log n)$ reduction in proof size and only $30\%$ slowdown in prover time.
Combining CONDA and LightLigero yields an efficient DA scheme for thousands of nodes. 

Our implementation demonstrates a 4$\times$ reduction in communication cost compared to FRIDA, while incurring only a 25\% increase in prover time. 
It also achieves near-best prover time and near-best communication cost simultaneously among all code commitment schemes.
CONDA also offers at least $3\times$ smaller proofs and $4\times$ faster provers than state-of-the-art verifiable secret sharing constructions such as ZXH+22 (Sec'22) and PolyFRIM (Sec'24).
]]></content:encoded>
<pubDate>Fri, 16 May 2025 05:39:13 +0000</pubDate>
</item>
<item>
<title>Fheanor: a new, modular FHE library for designing and optimising schemes</title>
<link>https://eprint.iacr.org/2025/864</link>
<guid>https://eprint.iacr.org/2025/864</guid>
<content:encoded><![CDATA[
Implementations of modern FHE schemes are available in various highly-optimized libraries. Many of these libraries are designed to allow developers who may not have deep expertise in FHE to build fast and secure privacy-preserving applications. To support such users, the API of these libraries often hides the internals of the schemes in question from the user. However, this design choice makes it hard for users of these libraries to modify existing schemes, or implement new ones; work that is often valuable when conducting research on FHE schemes.
We present our new Rust library Fheanor, which aims to facilitate such research on FHE schemes. The core target user is an FHE researcher, rather than an application developer. Most importantly, the design of Fheanor is very modular, and mirrors the mathematical structure of the available FHE schemes. By exposing the mathematical structure, but still hiding implementation details, it is easy to modify or extend the functionality of FHE schemes implemented in the library and still preserve high performance. Indeed, Fheanor demonstrates performance that is close to that of HElib or SEAL, with the potential for optimizations in the future.
Fheanor implements several features that have not, or have only rarely, been implemented in previous libraries. These include non-power-of-two cyclotomic rings, single-RNS based ring arithmetic, the CLPX/GBFV scheme, and bootstrapping for BFV and BGV. 
In addition, this paper presents new theoretical contributions that are also implemented in Fheanor. The first is an extension of optimal digit extraction circuits, used in BFV/BGV bootstrapping, to the case 2^23. The second is a more efficient algorithm for computing the trace in the non-power-of-two cyclotomic setting.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 02:33:19 +0000</pubDate>
</item>
<item>
<title>sPAR: (Somewhat) Practical Anonymous Router</title>
<link>https://eprint.iacr.org/2025/860</link>
<guid>https://eprint.iacr.org/2025/860</guid>
<content:encoded><![CDATA[
Anonymous communication is one of the fundamental tools to achieve privacy for communication over the internet. Almost all existing design strategies (e.g., onion routing/Tor, mixnets) for anonymous communication rely on the existence of some honest server/router in the network infrastructure to provide anonymity. A recent seminal work by Shi and Wu (Eurocrypt 2021) proposes the first cryptographic design for a non-interactive anonymous router (NIAR) that can use a single untrusted server or router to permute a set of messages without revealing the permutation to the untrusted router. This work is a really important step towards showing the possibility of designing such protocol from standard cryptographic assumptions. However, their construction is only of theoretical nature and still leaves many open questions towards realizing such systems in practice:  (1) the cryptographic building blocks (multi-client functional encryption, correlated pseudorandom function) used in their design are really difficult to implement in practice. (2) Their setup phase takes the permutation as an input to generate the encryption/decryption keys; which means that the messages from the same sender in different rounds will be at the same position in the output vector, unless the setup phase is run before every round with a new permutation. (3) It is not known how to realize such a setup procedure, that initializes a random permutation obliviously, without any trusted entities in the system.

In this paper, we propose the first (somewhat) practical design, which we call sPAR, that solves the above problems using homomorphic encryption techniques. Our design also relies on a one-time setup phase, however the setup phase does not take any specific permutation as input. Instead, our design generates a fresh permutation for every round based on the random values locally generated by the clients. Already existing practical instantiations of fully homomorphic encryption (FHE) schemes make our design implementable and deployable in practice. Our design presents a new direction for designing anonymous communication systems. Unlike some existing systems like Tor, sPAR does not scale to millions of users, however, we demonstrate with a proof-of-concept implementation that sPAR could easily support around hundred users with a few seconds of latency for each message.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 09:00:24 +0000</pubDate>
</item>
<item>
<title>V$\epsilon$rity: Verifiable Local Differential Privacy</title>
<link>https://eprint.iacr.org/2025/851</link>
<guid>https://eprint.iacr.org/2025/851</guid>
<content:encoded><![CDATA[
Local differential privacy (LDP) enables individuals to report sensitive data while preserving privacy. Unfortunately, LDP mechanisms are vulnerable to poisoning attacks, where adversaries controlling a fraction of the reporting users can significantly distort the aggregate output--much more so than in a non-private solution where the inputs are reported directly. In this paper, we present two novel solutions that prevent poisoning attacks under LDP while preserving its privacy guarantees.  
Our first solution, $\textit{V}\epsilon\textit{rity-}{\textit{Auth}}$, addresses scenarios where the users report inputs with a ground truth available to a third party. The second solution, $\textit{V}\epsilon\textit{rity}$, tackles the more challenging case in which the users locally generate their input and there is no ground truth which can be used to bootstrap verifiable randomness generation.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 01:27:17 +0000</pubDate>
</item>
<item>
<title>On Graphs of Incremental Proofs of Sequential Work</title>
<link>https://eprint.iacr.org/2025/848</link>
<guid>https://eprint.iacr.org/2025/848</guid>
<content:encoded><![CDATA[
In this work, we characterize graphs of  \emph{(graph-labeling) incremental proofs of sequential work} (iPoSW). First, we define \emph{incremental} graphs and prove they are necessary for iPoSWs. Relying on space pebbling complexity of incremental graphs, we show that the depth-robust graphs underling the PoSW of Mahmoody et al.\ are not incremental, and hence, their PoSW cannot be transformed into an iPoSW. 

Second, and  toward a generic iPoSW construction, we define graphs whose structure is compatible with the incremental sampling technique (Döttling et al.). These are \emph{dynamic} graphs.  We observe that the graphs underlying all PoSWs, standalone or incremental, are dynamic. We then generalize current iPoSW schemes  by giving a generic construction that transforms any PoSW whose underlying graph is incremental and dynamic into an iPoSW.  As a corollary,  we get a new iPoSW based on the modified Cohen-Pietrzak graph (Abusalah et al.). When used in constructing blockchain light-client bootstrapping protocols (Abusalah et al.) such an iPoSW, results in the most efficient bootstrappers/provers, in terms of both proof size and space complexity.

Along the way, we show that previous iPoSW definitions allow for trivial solutions. To overcome this, we provide a refined definition that captures the essence of iPoSWs and is satisfied by all known iPoSW constructions.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 11:58:04 +0000</pubDate>
</item>
<item>
<title>CTng: Secure Certificate and Revocation Transparency</title>
<link>https://eprint.iacr.org/2021/818</link>
<guid>https://eprint.iacr.org/2021/818</guid>
<content:encoded><![CDATA[
We present CTng, an evolutionary and practical PKI design that efficiently addresses multiple key challenges faced by deployed PKI systems. CTng ensures strong security properties, including guaranteed transparency of certificates and guaranteed, unequivocal revocation, achieved under NTTP-security, i.e., without requiring trust in any single CA, logger, or relying party. These guarantees hold even in the presence of arbitrary corruptions of these entities, assuming only a known bound (f) of corrupt monitors (e.g., f=8), with minimal performance impact.

CTng also enables offline certificate validation and preserves relying-party privacy, while providing scalable and efficient distribution of revocation updates. Furthermore, CTng is post-quantum ready, maintaining efficiency even with high-overhead quantum-secure signature schemes.

These properties significantly improve upon current PKI designs. In particular, while Certificate Transparency (CT) aims to eliminate single points of trust, the existing specification still assumes benign loggers. Addressing this through log redundancy is possible, but rather inefficient, limiting deployed configurations to f ≤ 2.

We present a security analysis and an evaluation of our open-source CTng prototype, showing that it is efficient and scalable under realistic deployment conditions.
]]></content:encoded>
<pubDate>Wed, 16 Jun 2021 13:37:20 +0000</pubDate>
</item>
<item>
<title>Verifiable E-Voting with a Trustless Bulletin Board</title>
<link>https://eprint.iacr.org/2025/841</link>
<guid>https://eprint.iacr.org/2025/841</guid>
<content:encoded><![CDATA[
Voter privacy and end-to-end (E2E) verifiability are critical features of electronic voting (e-voting) systems to safeguard elections. To achieve these properties commonly a perfect bulletin board (BB) is assumed that provides consistent, reliable, and tamper-proof storage and transmission of voting data. However, in practice, BBs operate in asynchronous and unreliable networks, and hence, are susceptible to vulnerabilities such as equivocation attacks and dropped votes, which can compromise both verifiability and privacy. Although prior research has weakened the perfect BB assumption, it still depends on trusting certain BB components.

In this work, we present and initiate a formal exploration of designing e-voting systems based on fully untrusted BBs. For this purpose, we leverage the notion of accountability and in particular use accountable BBs. Accountability ensures that if a security breach occurs, then cryptographic evidence can identify malicious parties. Fully untrusted BBs running in asynchronous networks bring new challenges. Among others, we identify several types of attacks that a malicious but accountable BB might be able to perform and propose a new E2E verifiability notion for this setting. Based on this notion and as a proof of concept, we construct the first e-voting system that is provably E2E verifiable and provides vote privacy  even when the underlying BB is fully malicious. This establishes an alternative to traditional e-voting architectures that rely on (threshold) trusted BB servers.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 12:55:52 +0000</pubDate>
</item>
<item>
<title>BPDTE: Batch Private Decision Tree Evaluation via Amortized Efficient Private Comparison</title>
<link>https://eprint.iacr.org/2024/619</link>
<guid>https://eprint.iacr.org/2024/619</guid>
<content:encoded><![CDATA[
Machine learning as a service requires clients to entrust their information to the server, raising privacy concerns. Private Decision Tree Evaluation (PDTE) are proposal to address these concerns in decision trees, which are fundamental models in machine learning. However, existing solutions perform poorly with massive datasets in real-world applications, therefore, we focus on the batching variant called BPDTE, which supports a single evaluation on multiple data and significantly improves performance.
Firstly, we propose three private comparison (PrivCMP) algorithms that privately compare two numbers to determine which one is larger, by utilizing thermometer encoding and a novel folklore-inspired dichotomy method. These algorithms are non-interactive, batchable, and high-precision, achieving an amortized cost of less than 1 ms at 32-bit precision.
Secondly, we propose six BPDTE schemes based on our PrivCMP and the Clear Rows Relation (CRR) algorithm, introduced to ensure batching security. Experimental results show that our schemes improve amortized efficiency, offer more flexible batch sizes, and achieve higher precision. 
Finally, we provide a formal security analysis of these schemes.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:29:07 +0000</pubDate>
</item>
<item>
<title>KeyJoin: Privacy-Focused CoinJoin Protocol for Bitcoin</title>
<link>https://eprint.iacr.org/2025/838</link>
<guid>https://eprint.iacr.org/2025/838</guid>
<content:encoded><![CDATA[
Bitcoin is based on the Blockchain, an open ledger containing information about each transaction in the Bitcoin network. Blockchain serves many purposes, but it allows anyone to track all transactions and activities of each Bitcoin address. The privacy of the network is being threatened by some organizations that track transactions. Tracking and subsequent filtering of coins lead to the loss of exchangeability of Bitcoin.

Despite Bitcoin’s transparency, it is possible to increase user privacy using a variety of existing methods. One of these methods is called CoinJoin, was proposed by Bitcoin developer Greg Maxwell in 2013. This technology involves combining several users transactions to create a single transaction with multiple inputs and outputs, which makes transaction analysis more complicated.

This work describes the KeyJoin, a privacy-focused CoinJoin protocol based on the keyed-verification anonymous credentials (KVAC).
]]></content:encoded>
<pubDate>Sun, 11 May 2025 17:52:06 +0000</pubDate>
</item>
<item>
<title>Conditional disclosure of secrets with quantum resources</title>
<link>https://eprint.iacr.org/2024/630</link>
<guid>https://eprint.iacr.org/2024/630</guid>
<content:encoded><![CDATA[
The conditional disclosure of secrets (CDS) primitive is among the simplest cryptographic settings in which to study the relationship between communication, randomness, and security. CDS involves two parties, Alice and Bob, who do not communicate but who wish to reveal a secret $z$ to a referee if and only if a Boolean function $f$ has $f(x,y)=1$. Alice knows $x,z$, Bob knows $y$, and the referee knows $x,y$. Recently, a quantum analogue of this primitive called CDQS was defined and related to f-routing, a task studied in the context of quantum position-verification. CDQS has the same inputs, outputs, and communication pattern as CDS but allows the use of shared entanglement and quantum messages. We initiate the systematic study of CDQS, with the aim of better understanding the relationship between privacy and quantum resources in the information theoretic setting. We begin by looking for quantum analogues of results already established in the classical CDS literature. Doing so we establish a number of basic properties of CDQS, including lower bounds on entanglement and communication stated in terms of measures of communication complexity. Because of the close relationship to the $f$-routing position-verification scheme, our results have relevance to the security of these schemes.
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 14:44:51 +0000</pubDate>
</item>
<item>
<title>A Specification of an Anonymous Credential System Using BBS+ Signatures with Privacy-Preserving Revocation and Device Binding</title>
<link>https://eprint.iacr.org/2025/824</link>
<guid>https://eprint.iacr.org/2025/824</guid>
<content:encoded><![CDATA[
Recently, there has been a growing interest in anonymous credentials (ACs) as they can mitigate the risk of personal data being processed by untrusted actors without consent and beyond the user's control. Furthermore, due to the privacy-by-design paradigm of ACs, they can prove possession of personal attributes, such as an authenticated government document containing sensitive personal information, while preserving the privacy of the individual by not actually revealing the data. Typically, AC specifications consider the privacy of individuals during the presentation of an AC, but often neglect privacy-preserving approaches for enhanced security features such as AC non-duplication or AC revocation. To achieve more privacy-friendly enhanced security features of non-duplication and privacy-preserving revocation, an AC can be partially stored on secure, trusted hardware and linked to a status credential that reflects its revocation status.
In this paper, we specify an AC system that satisfies the requirements of minimality of information, unlinkability, non-duplication, and privacy-preserving revocation.
This is achieved by adapting the hardware binding method of the Direct Anonymous Attestation protocol with the BBS+ short group signatures of Camenisch et al. and combining it with status credentials.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 07:38:15 +0000</pubDate>
</item>
<item>
<title>Sampling Arbitrary Discrete Distributions for RV Commitment Schemes Using the Trimmed-Tree Knuth-Yao Algorithm</title>
<link>https://eprint.iacr.org/2025/823</link>
<guid>https://eprint.iacr.org/2025/823</guid>
<content:encoded><![CDATA[
Sampling from non-uniform randomness according to an algorithm which keeps the internal randomness used by the sampler hidden is increasingly important for cryptographic applications, such as timing-attack-resistant lattice-based cryptography or certified differential privacy. In this paper we present a provably efficient sampler that maintains random sample privacy, or random sample hiding, and is applicable to arbitrary discrete random variables. Namely, we present a constant-time version of the classic Knuth-Yao algorithm that we name "trimmed-tree" Knuth-Yao. We establish distribution-tailored Boolean circuit complexity bounds for this algorithm, in contrast to the previous naive distribution-agnostic bounds. For a $\sigma^2$-sub-Gaussian discrete distribution where $b_t$ is the number of bits for representing the domain, and $b_p$ is the bits for precision of the PDF values, we prove the Boolean circuit complexity of the trimmed-tree Knuth-Yao algorithm has upper bound $O(\sigma b_p^{3/2} b_t)$, an exponential improvement over the naive bounds, and in certain parameter regimes establish the lower bound $\widetilde{\Omega}( ( \sigma + b_p ) b_t )$. Moreover, by proving the subtrees in the trimmed-tree Knuth-Yao circuit are small, we prove it can computed by running $b_p$ circuits of size $O(\sigma b_p^{1/2} b_t)$ in parallel and then running $O(b_p b_t )$ sequential operations on the output. We apply these circuits for trimmed-tree Knuth-Yao to constructing random variable commitment schemes for arbitrary discrete distributions, giving exponential improvements in the number of random bits and circuit complexity used for certified differentially private means and counting queries over large datasets and domains.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 23:01:12 +0000</pubDate>
</item>
<item>
<title>An Attack on TON’s ADNL Secure Channel Protocol</title>
<link>https://eprint.iacr.org/2025/818</link>
<guid>https://eprint.iacr.org/2025/818</guid>
<content:encoded><![CDATA[
We present an attack on the Abstract Datagram
Network Layer (ADNL) protocol used in The Open Network
(TON), currently the 10th largest blockchain by market cap-
italization. In its TCP variant, ADNL secures communication
between clients and specialized nodes called liteservers, which
provide access to blockchain data. We identify two crypto-
graphic design flaws in this protocol: a handshake that permits
session-key replay and a non-standard integrity mechanism
whose security critically depends on message confidentiality.
We transform these vulnerabilities into an efficient plaintext-
recovery attack by exploiting two ADNL communication pat-
terns, allowing message reordering across replayed sessions.
We then develop a plaintext model for this scenario and con-
struct an efficient algorithm that recovers the keystream using
a fraction of known plaintexts and a handful of replays. We
implement our attack and show that an attacker intercepting
the communication between a TON liteserver and a widely de-
ployed ADNL client can recover the keystream used to encrypt
server responses by performing eight connection replays to the
server. This allows the decryption of sensitive data, such as
account balances and user activity patterns. Additionally, the
attacker can modify server responses to manipulate blockchain
information displayed to the client, including account balances
and asset prices.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 09:20:49 +0000</pubDate>
</item>
<item>
<title>Relating Definitions of Computational Differential Privacy in Wider Parameter Regimes</title>
<link>https://eprint.iacr.org/2025/817</link>
<guid>https://eprint.iacr.org/2025/817</guid>
<content:encoded><![CDATA[
The literature on computational differential privacy (CDP) has focused almost exclusively on definitions that are computational analogs of `pure' $(\epsilon,0)$-DP. We initiate the formal study of computational versions of approximate DP, i.e. $(\epsilon, \delta)$-DP with non-negligible $\delta$. We focus on IND-CDP and SIM$_{\forall\exists}$-CDP and show that the hierarchy between them when $\delta > 0$ potentially differs substantially from when $\delta = 0$. In one direction, we show that for $\delta < 1$, any mechanism which is $(\epsilon,\delta)$-SIM$_{\forall\exists}$-CDP also is $(\epsilon,\delta)$-IND-CDP, but only if $\epsilon$ is logarithmic in the security parameter. As a special case, this proves that the existing implication from $(\epsilon,0)$-SIM$_{\forall\exists}$-CDP to $(\epsilon,0)$-IND-CDP does not hold for arbitrary $\epsilon$, as previously claimed. Furthermore, we prove that when the parameters are the same in IND-CDP and SIM$_{\forall\exists}$-CDP and $\epsilon$ is superlogarithmic, there exists a natural task that can be solved whilst satisfying SIM$_{\forall\exists}$-CDP but which no IND-CDP mechanism can solve. This is the first separation in the CDP literature which is not due to using a task contrived specifically in order to give rise to the separation. 
    In the other direction, we show that the techniques for establishing an implication from $(\epsilon,0)$-IND-CDP to $(\epsilon,0)$-SIM$_{\forall\exists}$-CDP extend only to that a mechanism being $(\epsilon,\delta)$-IND-CDP implies it is also $(\epsilon,\delta')$-SIM$_{\forall\exists}$-CDP with $\delta' > \delta$. Finally, we show that the Groce-Katz-Yerukhimovich barrier results against separations between CDP and statistical DP hold also in the setting of non-negligible $\delta$.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 08:31:33 +0000</pubDate>
</item>
<item>
<title>Actively Secure MPC in the Dishonest Majority Setting: Achieving Constant Complexity in Online Communication, Computation Per Gate, Rounds, and Private Input Size</title>
<link>https://eprint.iacr.org/2025/810</link>
<guid>https://eprint.iacr.org/2025/810</guid>
<content:encoded><![CDATA[
SPDZ-style and BMR-style protocols are widely known as practical MPC protocols that achieve active security in the dishonest majority setting.  However, to date, SPDZ-style protocols have not achieved constant rounds, and BMR-style protocols have struggled to achieve scalable communication or computation.  Additionally, there exists fully homomorphic encryption (FHE)-based MPC protocols that achieve both constant rounds and scalable communication, but they face challenges in achieving active security in the dishonest majority setting and are considered impractical due to computational inefficiencies.

In this work, we propose an MPC framework that constructs an efficient and scalable FHE-based MPC protocol by integrating a linear secret sharing scheme (LSSS)-based MPC and FHE. The resulting FHE-based MPC protocol achieves active security in the dishonest majority setting and constant complexity in online communication, computation per gate, rounds, and private input size. Notably, when instantiated with the SPDZ protocol and gate FHE for the framework, the resulting FHE-based MPC protocol efficiently achieves active security in the dishonest majority setting by using SPDZ-style MAC and ensures the computation per gate time within 3 ms. Moreover, its offline phase achieves scalable communication and computation, both of which grow linearly with the number of parties $n$. In other words, the proposed FHE-based MPC preserves the key advantages of existing FHE-based MPCs and simultaneously overcomes the weaknesses of them. As a result, the proposed FHE-based MPC is a highly practical and secure like SPDZ-style and BMR-style protocols.

For the first time, we introduce the concept of circuit-privacy, which ensures that external adversaries who eavesdrop on communications do not obtain information about the circuit. We rigorously prove that our construction inherently satisfy circuit- privacy, thereby establishing a novel security option for MPC.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 16:28:27 +0000</pubDate>
</item>
<item>
<title>Asynchronous Byzantine Agreement with Subquadratic Communication</title>
<link>https://eprint.iacr.org/2020/851</link>
<guid>https://eprint.iacr.org/2020/851</guid>
<content:encoded><![CDATA[
Understanding the communication complexity of Byzantine agreement (BA) is a fundamental problem in distributed computing. In particular, as protocols are run with a large number of parties (as, e.g., in the context of blockchain protocols), it is important to understand the dependence of the communication on the number of parties $n$. Although adaptively secure BA protocols with $o(n^2)$ communication are known in the synchronous and partially synchronous settings, no such protocols are known in the fully asynchronous case.

We show here an asynchronous BA protocol with subquadratic communication tolerating an adaptive adversary who can corrupt  $f<(1-\epsilon)n/3$ of the parties (for any $\epsilon>0$).
One variant of our protocol assumes initial setup done by a trusted dealer, after which an unbounded number of BA executions can be run; alternately, we can achieve subquadratic amortized communication with no prior setup. We also show that some form of setup is needed for (non-amortized) subquadratic BA tolerating $\Theta(n)$ corrupted parties.

As a contribution of independent interest, we show a secure-computation protocol in the same threat model that has $o(n^2)$ communication when computing no-input functionalities with short output (e.g., coin tossing).
]]></content:encoded>
<pubDate>Sun, 12 Jul 2020 12:41:03 +0000</pubDate>
</item>
<item>
<title>The Internet Computer for Geeks</title>
<link>https://eprint.iacr.org/2022/087</link>
<guid>https://eprint.iacr.org/2022/087</guid>
<content:encoded><![CDATA[
Smart contracts are a new form of software that will revolutionize how software is written, IT systems are maintained, and applications and whole businesses are built.  Smart contracts are composable and autonomous pieces of software that run on decentralized blockchains, which makes them tamperproof and unstoppable.  

In this paper, we describe the Internet Computer (IC), which is a radical new design of blockchain that unleashes the full potential of smart contracts, overcoming the limitations of smart contracts on traditional blockchains with respect to speed, storage costs, and computational capacity.  This allows smart contracts for the first time to implement fully decentralized applications that are hosted end to end on blockchain.  

The IC consists of a set of cryptographic protocols that connects independently operated nodes into a collection of blockchains. These blockchains host and execute ``canisters'',  the IC’s form of smart contracts. Canisters can store data, perform very general computations on that data, and provide a complete technology stack, serving web pages directly to end users. Computational and storage costs are covered by a ``reverse-gas model'', where canister developers pre-pay costs in cycles that are obtained from ICP, the native token of the IC.  ICP tokens are also used for governance: the IC is governed by a decentralized autonomous organization, or DAO, which, among other things, determines changes to the topology of the network and upgrades to the protocol.
]]></content:encoded>
<pubDate>Tue, 25 Jan 2022 07:20:59 +0000</pubDate>
</item>
<item>
<title>Guidance for Efficient Selection of Secure Parameters for Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1001</link>
<guid>https://eprint.iacr.org/2024/1001</guid>
<content:encoded><![CDATA[
The field of Fully Homomorphic Encryption (FHE) has seen many theoretical and computational advances in recent years, bringing the technology closer to practicality than ever before. For this reason, practitioners from neighbouring fields such as machine learning have sought to understand FHE to provide privacy to their work. Unfortunately, selecting secure and efficient parameters in FHE is a daunting task due to the many interdependencies between the parameters involved. In this work, we solve this problem by moving away from the standard parameter selection procedure, introducing formulas which provide secure and optimal parameters for any lattice-based scheme. We build our formulas from a strong theoretical foundation based on cryptanalysis against LWE.
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 20:17:33 +0000</pubDate>
</item>
<item>
<title>Putting Sybils on a Diet: Securing Distributed Hash Tables using Proofs of Space</title>
<link>https://eprint.iacr.org/2025/804</link>
<guid>https://eprint.iacr.org/2025/804</guid>
<content:encoded><![CDATA[
Distributed Hash Tables (DHTs) are peer-to-peer protocols that serve as building blocks for more advanced applications. Recent examples, motivated by blockchains, include decentralized storage networks (e.g., IPFS), data availability sampling, or Ethereum's peer discovery protocol.

In the blockchain context, DHTs are vulnerable to Sybil attacks, where an adversary compromises the network by joining with many malicious nodes. Mitigating such attacks requires restricting the adversary's ability to create a lot of Sybil nodes. Surprisingly, the above applications take no such measures. Seemingly, existing techniques are unsuitable for the proposed applications.

For example, a simple technique proposed in the literature uses proof of work (PoW), where nodes periodically challenge their peers to solve computational challenges. This, however, does not work well in practice. Since the above applications do not require honest nodes to have a lot of computational power, challenges cannot be too difficult. Thus, even moderately powerful hardware can sustain many Sybil nodes.

In this work, we investigate using Proof of Space (PoSp) to limit the number of Sybils DHTs. While PoW proves that a node wastes computation, PoSp proves that a node wastes disk space. This aligns better with the resource requirements of the above applications. Many of them are related to storage and ask honest nodes to contribute a substantial amount of disk space to ensure the application's functionality.

With this synergy in mind, we propose a mechanism to limit Sybils where honest nodes dedicate a fraction of their disk space to PoSp. This guarantees that the adversary cannot control a constant fraction of all DHT nodes unless it provides a constant fraction of whole the disk space contributed to the application in total. Since this is typically a significant amount, attacks become economically expensive.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 17:09:39 +0000</pubDate>
</item>
<item>
<title>Universally Composable On-Chain Quadratic Voting for Liquid Democracy</title>
<link>https://eprint.iacr.org/2025/803</link>
<guid>https://eprint.iacr.org/2025/803</guid>
<content:encoded><![CDATA[
Decentralized governance plays a critical role in blockchain communities, allowing stakeholders to shape the evolution of platforms such as Cardano, Gitcoin, Aragon, and MakerDAO through distributed voting on proposed projects in order to support the most beneficial of them. In this context, numerous voting protocols for decentralized decision-making have been developed, enabling secure and verifiable voting on individual projects (proposals). However, these protocols are not designed to support more advanced models such as quadratic voting (QV), where the voting power, defined as the square root of a voter’s stake, must be distributed among the selected by voter projects. Simply executing multiple instances of a single-choice voting scheme in parallel is insufficient, as it can not enforce correct voting power splitting. To address this, we propose an efficient blockchain-based voting protocol that supports liquid democracy under the QV model, while ensuring voter privacy, fairness and verifiability of the voting results. In our scheme, voters can delegate their votes to trusted representatives (delegates), while having the ability to distribute their voting power across selected projects. We model our protocol in the Universal Composability framework and formally prove its UC-security under the Decisional Diffie–Hellman (DDH) assumption. To evaluate the performance of our protocol, we developed a prototype implementation and conducted performance testing. The results show that the size and processing time of a delegate’s ballot scale linearly with the number of projects, while a voter’s ballot scales linearly with both the number of projects and the number of available delegation options. In a representative setting with 64 voters, 128 delegates and 128 projects, the overall traffic amounts to approximately 2.7 MB per voted project, confirming the practicality of our protocol for modern blockchain-based governance systems.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 16:59:57 +0000</pubDate>
</item>
<item>
<title>POBA: Privacy-Preserving Operator-Side Bookkeeping and Analytics</title>
<link>https://eprint.iacr.org/2025/801</link>
<guid>https://eprint.iacr.org/2025/801</guid>
<content:encoded><![CDATA[
Many user-centric applications face a common privacy problem: the need to collect, store, and analyze sensitive user data. Examples include check-in/check-out based payment systems for public transportation, charging/discharging electric vehicle batteries in smart grids, coalition loyalty programs, behavior-based car insurance, and more. We propose and evaluate a generic solution to this problem. More specifically, we provide a formal framework integrating privacy-preserving data collection, storage, and analysis, which can be used for many different application scenarios, present an instantiation, and perform an experimental evaluation of its practicality.

We consider a setting where multiple operators (e.g., different mobility providers, different car manufacturers and insurance companies), who do not fully trust each other, intend to maintain and analyze data produced by the union of their user sets. The data is collected in an anonymous (wrt.\ all operators) but authenticated way and stored in so-called user logbooks. In order for the operators to be able to perform analyses at any time without requiring user interaction, the logbooks are kept on the operator's side. Consequently, this potentially sensitive data must be protected from unauthorized access. To achieve this, we combine several selected cryptographic techniques, such as threshold signatures and oblivious RAM. The latter ensures that user anonymity is protected even against memory access pattern attacks.

To the best of our knowledge, we provide and evaluate the first generic framework that combines data collection, operator-side data storage, and data analysis in a privacy-preserving manner, while providing a formal security model, a UC-secure protocol, and a full implementation. With three operators, our implementation can handle over two million new logbook entries per day.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 10:46:44 +0000</pubDate>
</item>
<item>
<title>Rushing at SPDZ: On the Practical Security of Malicious MPC Implementations</title>
<link>https://eprint.iacr.org/2025/789</link>
<guid>https://eprint.iacr.org/2025/789</guid>
<content:encoded><![CDATA[
Secure multi-party computation (MPC) enables parties to compute a function over private inputs while maintaining confidentiality. Although MPC has advanced significantly and attracts a growing industry interest, open-source implementations are still at an early stage, with no production-ready code and a poor understanding of their actual security guarantees.
In this work, we study the real-world security of modern MPC implementations, focusing on the SPDZ protocol (Damgård et al., CRYPTO 2012, ESORICS 2013), which provides security against malicious adversaries when all-but-one of the participants may be corrupted. We identify a novel type of MAC key leakage in the MAC check protocol of SPDZ, which can be exploited in concurrent, multi-threaded settings, compromising output integrity and, in some cases, input privacy. In our analysis of three SPDZ implementations (MP-SPDZ, SCALE-MAMBA, and FRESCO), two are vulnerable to this attack, while we also uncover further issues and vulnerabilities with all implementations. We propose mitigation strategies and some recommendations for researchers, developers and users, which we hope can bring more awareness to these issues and avoid them reoccurring in future.
]]></content:encoded>
<pubDate>Sat, 03 May 2025 20:22:04 +0000</pubDate>
</item>
<item>
<title>AES Is Not Enough: the Block Ciphers Zoo Goes Homormorphic (over TFHE)</title>
<link>https://eprint.iacr.org/2025/782</link>
<guid>https://eprint.iacr.org/2025/782</guid>
<content:encoded><![CDATA[
The dream of achieving data privacy during external computations has
become increasingly concrete in recent years. Indeed, since the early days of Fully Homomorphic Encryption (FHE) more than a decade ago, new cryptosystems and techniques have constantly optimized the efficiency of computation on encrypted data.
However, one of the main disadvantages of FHE, namely its significant ciphertext expansion factor, remains at the center of the efficiency bottleneck of FHE schemes. To tackle the issue of slow uplink FHE data transmission, we use transciphering. With transciphering, the client naturally encrypts its data under a symmetric scheme and sends them to the server with (once and for all) an FHE encryption of the symmetric scheme’s key. With its larger computing power, the server then evaluates the symmetric scheme’s decryption algorithm within the homomorphic domain to obtain homomorphic ciphertexts that allow it to perform the requested calculations.
Since the first use of this method a bit more than ten years ago, papers on the homomorphic evaluation of AES have been numerous. And as the AES execution is the application chosen by NIST in the FHE part of its recent call for proposals on threshold encryption, the stakes of such work go up another level. But what about other standardized block ciphers? Is the AES the more efficient option? In this work, we leverage on two methods which have successfully been applied to the
homomorphic evaluation of AES to study several state-of-the-art symmetric block ciphers (namely CLEFIA, PRESENT, PRINCE, SIMON, SKINNY). That is to say, we implement a representative set of symmetric block ciphers using TFHE.
These implementations allow us to compare the efficiency of this set of symmetric schemes and to categorize them. We highlight the characteristics of block ciphers that are fast to execute in the homomorphic domain and those that are particularly costly.
Finally, this classification of operation types enables us to sketch out what the ideal block cipher for transciphering homomorphic data in integer mode might look like.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 14:01:55 +0000</pubDate>
</item>
<item>
<title>AuthOr: Lower Cost Authenticity-Oriented Garbling of Arbitrary Boolean Circuits</title>
<link>https://eprint.iacr.org/2025/775</link>
<guid>https://eprint.iacr.org/2025/775</guid>
<content:encoded><![CDATA[
Authenticity-oriented (previously named as privacy-free) garbling
schemes of Frederiksen et al. Eurocrypt ’15 are designed to satisfy
only the authenticity criterion of Bellare et al. ACM CCS ’12, and to be
more efficient compared to full-fledged garbling schemes. In this work,
we improve the state-of-the-art authenticity-oriented version of half gates
(HG) garbling of Zahur et al. Crypto ’15 by allowing it to be bandwidth-free
if any of the input wires of an AND gate is freely settable by the
garbler. Our full solution AuthOr then successfully combines the ideas
from information-theoretical garbling of Kondi and Patra Crypto ’17 and
the HG garbling-based scheme that we obtained. AuthOr has a lower
communication cost (i.e. garbled circuit or GC size) than HG garbling
without any further security assumption. Theoretically, AuthOr’s GC
size reduction over HG garbling lies in the range between 0 to 100%,
and the exact improvement depends on the circuit structure. We have
implemented our scheme and conducted tests on various circuits that are
constructed by independent researchers. Our experimental results show
that in practice, the GC size gain may be up to roughly 98%.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 14:31:44 +0000</pubDate>
</item>
<item>
<title>Exploring Adversarial Attacks on the MaSTer Truncation Protocol</title>
<link>https://eprint.iacr.org/2025/773</link>
<guid>https://eprint.iacr.org/2025/773</guid>
<content:encoded><![CDATA[
At CANS 2024, Zbudila et al. presented MaSTer, a maliciously secure multi-party computation protocol for truncation. It allows adversaries to manipulate outputs with a bounded additive error while avoiding detection with a certain probability. In this work, we analyse the broader implications of adversarial exploitation in probabilistic truncation protocols, specifically in relation to MaSTer. We propose three attack strategies aimed at inducing misclassification in deep neural network (DNN) inference. Our empirical evaluation across multiple datasets demonstrates that while adversarial influence remains negligible under realistic constraints, certain configurations and network architectures exhibit increased vulnerability. By improving the understanding of the risks associated with probabilistic truncation protocols in privacy-preserving machine learning, our work demonstrates that the MaSTer protocol is robust in realistic settings.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 13:43:14 +0000</pubDate>
</item>
<item>
<title>Publicly Auditable Garbled Circuit</title>
<link>https://eprint.iacr.org/2025/772</link>
<guid>https://eprint.iacr.org/2025/772</guid>
<content:encoded><![CDATA[
Generic Secure Multiparty Computation (Generic MPC) recently received much attraction in the blockchain realm as it allows mutually distrustful parties to jointly compute a global function using their private inputs while keeping them private; and more so; the expression of the function can be done in a programmable manner (hence `generic'); as opposed to the first rising star cryptographic technique Zero-Knowledge Proof (ZKP) which only allows computation on private input of a single party (via the `commit-and-prove' approach). While ZKP, by nature, allows public verifiability, Generic MPC is not so: Generic MPC mostly focuses on Malicious Security in which the computing result is verifiable only among the computing parties. Yet, in the blockchain realm, public verifiability is important, as the consensus protocol is not just among the computing parties but also external servers. A few works were done to bridge this gap (albeit not in the blockchain realm), i.e., Public Auditable MPC. Public Audtitability is a stronger property than Public Verifiability: the first one certifies the computation done in the MPC, while the latter certifies only the relation between the outputs and the inputs. However, they are non-constant round protocols and only for Secret-Sharing-based MPC, i.e., round complexity scales linearly with the circuit multiplicative depth, while round latency is an important cost metric in the blockchain domain. We address this problem by providing a Public Auditable Garbled Circuit protocol that is maliciously secure, publicly auditable, and constant-round. Our protocol is efficient, with only minimal overhead in terms of round, communication, and public transcript size.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 08:27:31 +0000</pubDate>
</item>
<item>
<title>Distributed Point Function with Constraints, Revisited</title>
<link>https://eprint.iacr.org/2024/937</link>
<guid>https://eprint.iacr.org/2024/937</guid>
<content:encoded><![CDATA[
Distributed Point Function (DPF) provides a way for a dealer to split a point function $f_{\alpha, \beta}$ into multiple succinctly described function-shares, where  the function $f_{\alpha, \beta}$ for a special input $\alpha$, returns a special output value $\beta$, and returns a fixed value $0$ otherwise. As the security requirement, any strict subset of the function-shares reveals nothing about the function $f_{\alpha,\beta}$. However, each function-share can be individually evaluated on the common input $x$, and these evaluation results can then be merged together to reconstruct the value $f_{\alpha, \beta}(x)$. 

Recently, Servan-Schreiber et al. (S&amp;P 2023) investigate the access control problem for  DPF; namely, the DPF evaluators can ensure that the DPF dealer is authorized to share the given function with privacy assurance. In this work, we revisit this problem, introducing a new notion called DPF with constraints; meanwhile, we identify that there exists a subtle flaw in their privacy definition as well as a soundness issue in one of their proposed schemes due to the lack of validation of the special output value $\beta$. Next, we show how to reduce both the storage size of the constraint representation and the server's computational overhead from $O(N)$ to $O(\log N)$, where $N$ is the number of authorized function sets. In addition, we show how to achieve fine-grained private access control, that is, the wildcard-style constraint for the choice of the special output $\beta$. Our benchmarks show that the amortized running time of our logarithmic storage scheme is $2\times$ - $3\times$ faster than the state-of-the-art when $N=2^{15}$. Furthermore, we provide the first impossibility and feasibility results of the DPF with constraints where the evaluators do not need to communicate with each other.
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 18:25:56 +0000</pubDate>
</item>
<item>
<title>ZHE: Efficient Zero-Knowledge Proofs for HE Evaluations</title>
<link>https://eprint.iacr.org/2025/770</link>
<guid>https://eprint.iacr.org/2025/770</guid>
<content:encoded><![CDATA[
Homomorphic Encryption (HE) allows computations on encrypted data without decryption. It can be used where the users’ information are to be processed by an untrustful server, and has been a popular choice in privacy-preserving applica- tions. However, in order to obtain meaningful results, we have to assume an honest-but-curious server, i.e., it will faithfully follow what was asked to do. If the server is malicious, there is no guarantee that the computed result is correct. The notion of verifiable HE (vHE) is introduced to detect malicious server’s behaviors, but current vHE schemes are either more than four orders of magnitude slower than the underlying HE operations (Atapoor et. al, CIC 2024) or fast but incompatible with server- side private inputs (Chatel et. al, CCS 2024).

In this work, we propose a vHE framework ZHE: effi- cient Zero-Knowledge Proofs (ZKPs) that prove the correct execution of HE evaluations while protecting the server’s private inputs. More precisely, we first design two new highly- efficient ZKPs for modulo operations and (Inverse) Number Theoretic Transforms (NTTs), two of the basic operations of HE evaluations. Then we build a customized ZKP for HE evaluations, which is scalable, enjoys a fast prover time and has a non-interactive online phase. Our ZKP is applicable to all Ring-LWE based HE schemes, such as BGV and CKKS. Finally, we implement our protocols for both BGV and CKKS and conduct extensive experiments on various HE workloads. Compared to the state-of-the-art works, both of our prover time and verifier time are improved; especially, our prover cost is only roughly 27-36× more expensive than the underlying HE operations, this is two to three orders of magnitude cheaper than state-of-the-arts.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 02:03:40 +0000</pubDate>
</item>
<item>
<title>Incompleteness in Number-Theoretic Transforms: New Tradeoffs and Faster Lattice-Based Cryptographic Applications</title>
<link>https://eprint.iacr.org/2025/768</link>
<guid>https://eprint.iacr.org/2025/768</guid>
<content:encoded><![CDATA[
Lattices are the basis of most NIST-recommended post-quantum cryptography (PQC) schemes, required to thwart the threat posed by the eventual construction of large-scale quantum computers. At the same time, lattices enable more advanced cryptographic constructions, such as fully homomorphic encryption (FHE), which is increasingly used for privacy-preserving applications like machine learning. This work delves into the efficiency and trade-off assessment of polynomial multiplication algorithms and their applications to PQC, FHE, and other schemes. Such algorithms are at the core of lattice-based cryptography and may become a critical bottleneck when deploying PQC- and FHE-based solutions on resource-constrained devices. We propose a formal analysis of so-called incompleteness in the Number Theoretic Transform (NTT). Although this concept is not new, our systematization shows how to optimize polynomial multiplication in quotient rings, considering factors such as the degree of incompleteness, the associated prime moduli, constraints of the target platform, and target security level. Besides efficiency, we formally show that the systematized family of incomplete NTT variants supports a larger set of prime moduli. This property enables new trade-offs for algorithms like the FIPS-approved module-lattice-based key encapsulation mechanism (ML-KEM) and faster amortized bootstrapping in FHE schemes. Our results include shorter ciphertexts in ML-KEM with only a modest hit in performance and a 6-42% performance boost in the NTT computation of a state-of-the-art FHE solution.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:22:04 +0000</pubDate>
</item>
<item>
<title>ZKPoG: Accelerating WitGen-Incorporated End-to-End Zero-Knowledge Proof on GPU</title>
<link>https://eprint.iacr.org/2025/765</link>
<guid>https://eprint.iacr.org/2025/765</guid>
<content:encoded><![CDATA[
Zero-Knowledge Proof (ZKP) is a cornerstone technology in privacy-preserving computing, addressing critical challenges in domains such as finance and healthcare by ensuring data confidentiality during computation. However, the high computational overhead of ZKP, particularly in proof generation and verification, limits its scalability and usability in real-world applications. Existing efforts to accelerate ZKP primarily focus on specific components, such as polynomial commitment schemes or elliptic curve operations, but fail to deliver an integrated, flexible, and efficient end-to-end solution that includes witness generation.

In this work, we present ZKPoG, a GPU-based ZKP acceleration platform that achieves full end-to-end optimization. ZKPoG addresses three key challenges: (1) designing a witness-generation-incorporated flow for Plonkish circuits, enabling seamless integration of frontend and backend with GPU acceleration; (2) optimizing memory usage to accommodate large-scale circuits on affordable GPUs with limited memory; and (3) introducing an automated compiler for custom gates, simplifying adaptation to diverse applications. Experimental results on an NVIDIA RTX 4090 GPU show on average $22.8\times$ end-to-end acceleration compared to state-of-the-art CPU implementations and on average $12.7\times$ speedup over existing GPU-based approaches.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 14:51:19 +0000</pubDate>
</item>
<item>
<title>LEAGAN: A Decentralized Version-Control Framework for Upgradeable Smart Contracts</title>
<link>https://eprint.iacr.org/2025/752</link>
<guid>https://eprint.iacr.org/2025/752</guid>
<content:encoded><![CDATA[
Smart contracts are integral to decentralized systems like blockchains and enable the automation of processes through programmable conditions. However, their immutability, once deployed, poses challenges when addressing errors or bugs. Existing solutions, such as proxy contracts, facilitate upgrades while preserving application integrity. Yet, proxy contracts bring issues such as storage constraints and proxy selector clashes - along with complex inheritance management. This paper introduces a novel upgradeable smart contract framework with version control, named "decentraLized vErsion control and updAte manaGement in upgrAdeable smart coNtracts (LEAGAN)." LEAGAN is the first decentralized updatable smart contract framework that employs data separation with Incremental Hash (IH) and Revision Control System (RCS). It updates multiple contract versions without starting anew for each update, and reduces time complexity, and where RCS optimizes space utilization through differentiated version control. LEAGAN also introduces the first status contract in upgradeable smart contracts, and which reduces overhead while maintaining immutability. In Ethereum Virtual Machine (EVM) experiments, LEAGAN shows 40\% better space utilization, 30\% improved time complexity, and 25\% lower gas consumption compared to state-of-the-art models. It thus stands as a promising solution for enhancing blockchain system efficiency.
]]></content:encoded>
<pubDate>Sun, 27 Apr 2025 13:00:06 +0000</pubDate>
</item>
<item>
<title>Secure Rate-Distortion-Perception Trade-off Over Channels: A Randomized Distributed Function Computation (RDFC) Application</title>
<link>https://eprint.iacr.org/2025/750</link>
<guid>https://eprint.iacr.org/2025/750</guid>
<content:encoded><![CDATA[
Secure rate-distortion-perception (RDP) trade-offs arise in critical applications, such as semantic compression and privacy-preserving generative coding, where preserving perceptual quality while minimizing distortion is vital. This paper studies a framework for secure RDP over noiseless and noisy broadcast channels under strong secrecy constraints. We first characterize the exact secure RDP region for noiseless transmission channels. We then develop an inner bound on the secure RDP region for a memoryless broadcast channel with correlated noise components at the receivers' observations and prove its tightness under a more capable broadcast channel assumption. Our results demonstrate how optimized binning schemes simultaneously achieve high perceptual quality, low distortion, and strong secrecy, illuminating fundamental information-theoretic limits for next-generation trustworthy computation systems.
]]></content:encoded>
<pubDate>Sun, 27 Apr 2025 10:13:15 +0000</pubDate>
</item>
<item>
<title>OPSA: Efficient and Verifiable One-Pass Secure Aggregation with TEE for Federated Learning</title>
<link>https://eprint.iacr.org/2024/476</link>
<guid>https://eprint.iacr.org/2024/476</guid>
<content:encoded><![CDATA[
Federated learning enables collaborative model training while preserving data privacy by keeping data local. To protect user privacy during model aggregation, secure aggregation (SA) protocols are widely adopted to mask models. However, existing SA protocols require at least three round trips per aggregation and lack mechanisms to verify aggregation results. Verifiable SA addresses the verification gap but incurs high communication costs. TEE-based SA minimizes round trips but faces computational bottlenecks due to TEE's limited physical memory, especially when handling larger models or numerous clients. In this work, we introduce OPSA, an efficient and verifiable one-pass SA protocol based on TEE. By handling client dropouts via server-side TEE, OPSA enables the server to aggregate masked models in a single pass, significantly reducing round trips. To mitigate TEE's limitations, OPSA offloads tasks like model aggregation and mask elimination outside TEE, with only shared keys processed within TEE. Building on this design, we propose KhPRF-OPSA (single masking) and POT-OPSA (double masking) protocols, both incorporating novel cryptographic primitives. Furthermore, OPSA integrates commitment and signature mechanisms to ensure result verifiability with only $O(1)$ additional communication overhead per client. Compared to state-of-the-art schemes, OPSA achieves a 2$\sim$10$\times$ speedup in multi-round aggregation while guaranteeing result verification.
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:54:52 +0000</pubDate>
</item>
<item>
<title>CoinMaze: Privacy-Focused CoinJoin Protocol for Bitcoin</title>
<link>https://eprint.iacr.org/2025/747</link>
<guid>https://eprint.iacr.org/2025/747</guid>
<content:encoded><![CDATA[
Bitcoin is based on the Blockchain, an open ledger containing information about each transaction in the Bitcoin network. Blockchain serves many purposes, but it allows anyone to track all transactions and
activities of each Bitcoin address. The privacy of the network is being threatened by some organizations that track transactions. Tracking and subsequent filtering of coins lead to the loss of exchangeability of Bitcoin.

Despite Bitcoin’s transparency, it is possible to increase user privacy using a variety of existing methods. One of these methods is called CoinJoin, was proposed by Bitcoin developer Greg Maxwell in 2013.
This technology involves combining several users transactions to create a single transaction with multiple inputs and outputs, which makes transaction analysis more complicated.

This work describes the CoinMaze, a privacy-focused CoinJoin protocol based on the keyed-verification
anonymous credentials (KVAC).
]]></content:encoded>
<pubDate>Sat, 26 Apr 2025 20:28:37 +0000</pubDate>
</item>
<item>
<title>Candidate Matchmaking Encryption from Attribute-Based Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/744</link>
<guid>https://eprint.iacr.org/2025/744</guid>
<content:encoded><![CDATA[
We were deeply impressed by the paper by Ateniese et al., published in Crypto 2019. In it, they presented a black-box construction of matchmaking encryption (ME) based on functional encryption. In our work, we propose an ME scheme based on standard assumptions in the standard model. This scheme has been proven to be secure under the learning with error (LWE) assumption. Our ME scheme is achieved through a novel framework of bilateral-policy attribute-based encryption (BP-ABE) and a new intermediate primitive termed a perturbed pseudorandom generator (PPRG), which facilitates the implementation of authentication functionality by replacing non-interactive zero-knowledge proof functionality.

In the scheme presented in this paper, the user's "public key" is generated using Hamming correlation robustness and user attributes. Note that the 'public key' is not public. In order to preserve the privacy of the two parties involved in matchmaking encryption, our BP-ABE scheme does not use the 'public key' directly to encrypt the plaintext. Instead, the message sender selects matching attributes and uses a Hamming correlation robustness and homomorphic pseudorandom function (HPRF) to generate temporary public keys and hide the public key and user attributes.

When these temporary public keys satisfy the access policy, the receiver can decrypt the data using their private key. Regarding the authentication function of matchmaking encryption, this paper proposes a non-interactive privacy set intersection (PSI) scheme based on HPRF and PPRG. The message sender encrypts their 'public key' using the proposed PSI scheme as part of the ciphertext. The receiver also encrypts their 'public key' using the proposed PSI scheme and matches the attributes, thereby completing the message authentication function. We consider our approach to be a significant departure from existing constructions, despite its simplicity.
]]></content:encoded>
<pubDate>Sat, 26 Apr 2025 03:21:37 +0000</pubDate>
</item>
<item>
<title>Otter: Scalable Sharding-Based Atomic Broadcast with Abortable Fork Detection</title>
<link>https://eprint.iacr.org/2025/740</link>
<guid>https://eprint.iacr.org/2025/740</guid>
<content:encoded><![CDATA[
Sharding is a generic approach to enhance the scalability of distributed systems. In recent years, many efforts have been made to scale the consensus mechanism of blockchains from sharding. A crucial research question is how to achieve the sweet spot of having a relatively small shard size (to achieve decent performance) while achieving an overwhelming probability of correctness (so the system is safe and live). Many recent works fall into the two-layer design that uses some coordinating shards to monitor the correctness of other shards (CCS 2022, NDSS 2024, INFOCOM 2023). All of them involve expensive communication costs between the shards, significantly degrading performance.

We present Otter, a scalable partially synchronous sharding-based Byzantine fault-tolerant atomic broadcast (ABC) protocol. We use coordinating shards in a completely new way. In particular, we randomly sample coordinating shards to directly participate in the consensus protocol. Such a random sampling mechanism makes it possible to analyze the correctness of the ABC protocol using a probabilistic model. In this way, we can significantly lower the shard size (informally, from over 1,200 in previous work to around 100) without lowering the probability of correctness. We also present a new notion called abortable fork detection (AFD) that might be of independent interest. Our evaluation results on Amazon EC2 using up to 1,000 replicas show that Otter achieves up to 4.38x the throughput of the state-of-the-art protocol.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 08:00:54 +0000</pubDate>
</item>
<item>
<title>Universal Blind and Verifiable Delegated Quantum Computation with Classical Clients</title>
<link>https://eprint.iacr.org/2025/734</link>
<guid>https://eprint.iacr.org/2025/734</guid>
<content:encoded><![CDATA[
Delegation of quantum computation in a trustful way is one of the most fundamental challenges toward the realization of future quantum cloud computing. While considerable progress has been made, no known protocol provides a purely classical client with universal delegated quantum computation while simultaneously ensuring blindness (input privacy), verifiability (soundness), and robustness against quantum noise—a feat that must be achieved under stringent cryptographic assumptions and with low overhead.

In this work, I introduce UVCQC, a new delegation framework that, for the first time, realizes a fully composable protocol for securely delegating quantum computations to an untrusted quantum server from a classical client. My scheme employs trap-based quantum authentication, post-quantum cryptographic commitments, and zero-knowledge proofs to provide full guarantees: the client remains purely classical; the server learns nothing about the computation; and any attempt to deviate from the specified circuit is detected with high probability.

I rigorously prove completeness, soundness, and perfect blindness of the protocol and demonstrate its universal composability against unbounded quantum adversaries. Furthermore, I propose a thermodynamically inspired verification mechanism based on energy dissipation and entropy change, enabling physically testable verification independent of cryptographic assumptions.

Beyond its core architecture, UVCQC is deeply intertwined with multidisciplinary frameworks: it admits a game-theoretic formulation where honesty is a Nash equilibrium, an information-theoretic treatment grounded in Holevo bounds, a categorical model via compact closed structures, and novel cryptographic enhancements based on isogeny-based primitives and topological invariants.

This research offers a scalable and unified solution to the blind and verifiable delegation problem, pushing forward the theoretical and practical frontiers of secure quantum computation—and opening a tangible path toward trustable quantum cloud services for classical users.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 12:22:46 +0000</pubDate>
</item>
<item>
<title>Provably Secure Butterfly Key Expansion from the CRYSTALS Post-Quantum Schemes</title>
<link>https://eprint.iacr.org/2024/946</link>
<guid>https://eprint.iacr.org/2024/946</guid>
<content:encoded><![CDATA[
Key blinding produces pseudonymous digital identities by
rerandomizing public keys of a digital signature scheme. It provides privacy in decentralized networks. Current key blinding schemes are based on the discrete log assumption. Eaton, Stebila and Stracovsky (LATINCRYPT 2021) proposed the first post-quantum key blinding schemes from lattice assumptions. However, the large public keys and lack of QROM security means they are not ready to replace existing solutions. We present a general framework to build post-quantum signature schemes with key blinding based on the MPC-in-the-Head paradigm. This results in schemes that rely on well-studied symmetric cryptographic primitives and admit short public keys. We prove generic security results in the quantum random oracle model (QROM).

We instantiate our framework with the recent AES-based Helium signature scheme (Kales and Zaverucha, 2022) to obtain an efficient post-quantum key blinding scheme with small keys. Both Helium and the aforementioned lattice-based key blinding schemes were only proven secure in the ROM. This makes our results the first QROM proof of Helium and the first fully quantum-safe public key blinding scheme.
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 18:13:48 +0000</pubDate>
</item>
<item>
<title>Boomy: Batch Opening Of Multivariate polYnomial commitment</title>
<link>https://eprint.iacr.org/2023/1599</link>
<guid>https://eprint.iacr.org/2023/1599</guid>
<content:encoded><![CDATA[
We present Boomy, a multivariate polynomial commitment scheme enabling the proof of the evaluation of multiple points, i.e., batch opening. Boomy is the natural extension of two popular protocols: the univariate polynomial commitment scheme of Kate, Zaverucha and Goldberg~\cite{AC:KatZavGol10} and its multivariate counterpart from Papamanthou, Shi and Tamassia~\cite{papamanthou2013signatures}. Our construction is proven secure under the selective security model. In this paper, we present Boomy's complexity and the applications on which it can have a significant impact. In fact, Boomy is perfectly suited to tackling blockchain data availability problems, shrinking existing challenges. We also present special lower-complexity cases that occur frequently in practical situations.
]]></content:encoded>
<pubDate>Mon, 16 Oct 2023 12:45:23 +0000</pubDate>
</item>
<item>
<title>Tetris! Traceable Extendable Threshold Ring Signatures and More</title>
<link>https://eprint.iacr.org/2025/730</link>
<guid>https://eprint.iacr.org/2025/730</guid>
<content:encoded><![CDATA[
Traceable ring signatures enhance ring signatures by adding an accountability layer. Specifically, if a party signs two different messages within the protocol, their identity is revealed.  Another desirable feature is $\textit{extendability}$. In particular, $\textit{extendable threshold}$ ring signatures (ETRS) allow to $\textit{non-interactively}$ update already finalized signatures by enlarging the ring or the set of signers.

Combining traceability and extendability in a single scheme is unexplored and would offer a new tool for privacy-preserving voting schemes in scenarios where the voters are not known in advance.
In this paper, we show how to reconcile both properties by introducing and constructing a new cryptographic primitive called Tetris.
Notably, our Tetris construction simultaneously achieves strong anonymity and linear-size signatures, which is the main technical challenge in existing techniques.
To solve this challenge, we develop a new approach to traceability that leads to several conceptual and technical contributions. Among those, we introduce and construct, based on Groth-Sahai proofs, $\textit{extendable}$ shuffle arguments that can be $\textit{non-interactively}$ updated by several provers.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 13:04:46 +0000</pubDate>
</item>
<item>
<title>Privacy and Security in Distributed Data Markets</title>
<link>https://eprint.iacr.org/2025/724</link>
<guid>https://eprint.iacr.org/2025/724</guid>
<content:encoded><![CDATA[
Data markets play a pivotal role in modern industries by facilitating the exchange of data for predictive modeling, targeted marketing, and research. However, as data becomes a valuable commodity, privacy and security concerns have grown, particularly regarding the personal information of individuals. This tutorial explores privacy and security issues when integrating different data sources in data market platforms. As motivation for the importance of enforcing privacy requirements, we discuss attacks on data markets focusing on membership inference and reconstruction attacks. We also discuss security vulnerabilities in decentralized data marketplaces, including adversarial manipulations by buyers or sellers. We provide an overview of privacy and security mechanisms designed to mitigate these risks. In order to enforce the least amount of trust for buyers and sellers, we focus on distributed protocols. Finally, we conclude with opportunities for future research on understanding and mitigating privacy and security concerns in distributed data markets.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 22:45:28 +0000</pubDate>
</item>
<item>
<title>Towards Lightweight CKKS: On Client Cost Efficiency</title>
<link>https://eprint.iacr.org/2025/720</link>
<guid>https://eprint.iacr.org/2025/720</guid>
<content:encoded><![CDATA[
The large key size for fully homomorphic encryption (FHE) requires substantial costs to generate and transmit the keys. This has been problematic for FHE clients who want to delegate the computation, as they often have limited power. A recent work, Lee-Lee-Kim-No [Asiacrypt 2023], partly solved this problem by suggesting a hierarchical key management system. However, the overall key size was still several gigabytes for real-world applications, and it is barely satisfactory for mobile phones and IoT devices. 

In this work, we propose new key management systems, KG+ and BTS+, which reduce the client's cost for FHE on top of Lee-Lee-Kim-No. The KG+system significantly reduces the key size without any compromise in the efficiency of homomorphic computation compared to Lee-Lee-Kim-No. The BTS+ system further reduces the key size, while it compromises only the granularity of the homomorphic computation.

In our new systems, the client generates and sends ``transmission keys'' with size-optimal parameters, and the server generates ``evaluation keys'' with computation-optimal parameters. For this purpose, we introduce a new ring-switching technique for keys to bridge keys with different parameters. 
Using the new ring-switching technique, a client can transmit the transmission keys in extension rings that can generate FHE keys in the computation-efficient subring. By decoupling the rings of FHE keys during transmission and computation, we significantly reduce the communication cost for transferring FHE keys. 

We provide concrete CKKS FHE parameters that the client's keys are $325$--$609$ MB and $285$ MB, by using KG+ and BTS+, respectively. Note that all parameters generate keys for CKKS with ring degree $2^{16}$, which is a conventional choice for CKKS applications to privacy-preserving machine learning. These are $3.09$--$4.37$ and $3.51$--$9.30$ times lower than Lee-Lee-Kim-No, respectively. For real-world applications, the server requires more evaluation keys for faster homomorphic computation. For the secure ResNet-20 inference, the parameters for KG+ and BTS+ result in client key sizes of $325$--$609$ MB and $285$ MB, respectively. These are $3.95$--$5.73\times$ and $4.53$--$12.25\times$ smaller than Lee-Lee-Kim-No.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 10:17:24 +0000</pubDate>
</item>
<item>
<title>Thunderbolt: A Formally Verified Protocol for Off-Chain Bitcoin Transfers</title>
<link>https://eprint.iacr.org/2025/709</link>
<guid>https://eprint.iacr.org/2025/709</guid>
<content:encoded><![CDATA[
We present Bitcoin Thunderbolt, a novel off-chain protocol for asynchronous, secure transfer of Bitcoin UTXOs between uncoordinated users. Unlike prior solutions such as payment channels or the Lightning Network, Bitcoin Thunderbolt requires no prior trust, direct interaction, or continuous connectivity between sender and receiver. At its core, Bitcoin Thunderbolt employs a Byzantine fault-tolerant committee to manage threshold Schnorr signatures, enabling secure ownership delegation and on-chain finalization.

Our design supports recursive, off-chain UTXO transfers using tweakable, verifiable signature components. The protocol tolerates up to $f$ malicious nodes in a $3f+1$ committee and ensures correctness, consistency, and one-time spendability under asynchronous network conditions.

We formally verify Bitcoin Thunderbolt’s key security properties, namely, unforgeability, ownership soundness, and liveness—using the Tamarin prover. Our results demonstrate that Thunderbolt provides robust, scalable, and non-interactive off-chain Bitcoin transfers, significantly expanding the practical utility of Bitcoin for decentralized applications.
]]></content:encoded>
<pubDate>Sat, 19 Apr 2025 01:09:05 +0000</pubDate>
</item>
<item>
<title>Arbigraph: Verifiable Turing-Complete Execution Delegation</title>
<link>https://eprint.iacr.org/2025/710</link>
<guid>https://eprint.iacr.org/2025/710</guid>
<content:encoded><![CDATA[
Dependence on online infrastructure is rapidly growing as services like online payments and insurance replace traditional options, while others, like social networks, offer new capabilities. 
The centralized service operators wield unilateral authority over user conflicts, content moderation, and access to essential services.
In the context of payments, blockchains provide a decentralized alternative. 
They also enable decentralized execution of stateful programs called smart contracts. 
But those lack the contextual understanding and interpretative capabilities that would enable reasoning about complex scenarios.
Advancements in machine learning (ML) are raising interest in actually-smart contracts, but blockchain computation constraints prohibit direct ML inference execution.
While many projects deploy computation delegation mechanisms, they lack Turing-completeness, prohibit parallel computation, or suffer from high overhead.

We present Arbigraph, a blockchain-based execution delegation protocol.
Like previous optimistic solutions, the parties submit their computation results, allowing a smart contract to arbitrate in case of dispute.
But Arbigraph employs a novel dual-graph data structure and takes advantage of the nature of the dispute process to achieve Turing completeness, constant-time memory access, and parallel execution.
We formalize the problem and show that Arbigraph guarantees completeness, soundness, and progress. 
Experiments on LLM inference as well as matrix multiplication, which is at the core of ML inference, demonstrate that parallelization speedup grows linearly with matrix dimensions. 
We demonstrate Arbigraph's practical cost with a deployment on the Avalanche blockchain. 
Arbigraph thus enables decentralized, context-aware decision-making and unlocks unprecedented use cases for blockchains.
]]></content:encoded>
<pubDate>Sat, 19 Apr 2025 10:30:39 +0000</pubDate>
</item>
<item>
<title>Signature-Free Atomic Broadcast with Optimal $O(n^2)$ Messages and $O(1)$ Expected Time</title>
<link>https://eprint.iacr.org/2023/1549</link>
<guid>https://eprint.iacr.org/2023/1549</guid>
<content:encoded><![CDATA[
Byzantine atomic broadcast (ABC) is at the heart of  permissioned blockchains and various multi-party computation protocols. We resolve a long-standing open problem in ABC, presenting the first information-theoretic (IT) and signature-free asynchronous ABC protocol that achieves optimal $O(n^2)$ messages and $O(1)$ expected time.  Our ABC protocol adopts a new design, relying on a reduction from---perhaps surprisingly---a somewhat neglected  primitive called multivalued Byzantine agreement (MBA).
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 12:26:39 +0000</pubDate>
</item>
<item>
<title>Updatable Signature with Public Tokens</title>
<link>https://eprint.iacr.org/2025/715</link>
<guid>https://eprint.iacr.org/2025/715</guid>
<content:encoded><![CDATA[
The Updatable Signature (US) allows valid signatures to be updated by an update token without accessing the newly generated signing key. Cini et al. (PKC'21) formally defined this signature and gave several constructions. However, their security model requires the secrecy of the update token, which is only applicable in some specific scenarios, such as software verification in the trusted App Store. In Web3, information is usually shared via a public blockchain, and decentralized private computation is expensive. In addition, one can use the same token to update both the signing key and signatures and all signatures can be updated with a single token. The adversarial signature generated by an adversary might also be updated. Therefore, this work explores the (im)possibility of constructing an Updatable Signature with public tokens (USpt), the tokens of which are signature-dependent. Specifically, we define the updatable signature with public tokens and present its security model. Then, we present a concrete USpt scheme based on the Boneh–Lynn–Shacham signature. This variant introduces a limitation for the signer who must maintain a dataset about its signed messages or hashes of them, which is applicable in our applications.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 03:03:01 +0000</pubDate>
</item>
<item>
<title>Fast Plaintext-Ciphertext Matrix Multiplication from Additively Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/711</link>
<guid>https://eprint.iacr.org/2025/711</guid>
<content:encoded><![CDATA[
Plaintext-ciphertext matrix multiplication (PC-MM) is an indispensable tool in privacy-preserving computations such as secure machine learning and encrypted signal processing. While there are many established algorithms for plaintext-plaintext matrix multiplication, efficiently computing plaintext-ciphertext (and ciphertext-ciphertext) matrix multiplication is an active area of research which has received a lot of attention. Recent literature have explored various techniques for privacy-preserving matrix multiplication using fully homomorphic encryption (FHE) schemes with ciphertext packing and Single Instruction Multiple Data (SIMD) processing. On the other hand, there hasn't been any attempt to speed up PC-MM using unpacked additively homomorphic encryption (AHE) schemes beyond the schoolbook method and Strassen's algorithm for matrix multiplication. In this work, we propose an efficient PC-MM from unpacked AHE, which applies Cussen's compression-reconstruction algorithm for plaintext-plaintext matrix multiplication in the encrypted setting. We experimentally validate our proposed technique using a concrete instantiation with the additively homomorphic elliptic curve ElGamal encryption scheme and its software implementation on a Raspberry Pi 5 edge computing platform. Our proposed approach achieves up to an order of magnitude speedup compared to state-of-the-art for large matrices with relatively small element bit-widths. Extensive measurement results demonstrate that our fast PC-MM is an excellent candidate for efficient privacy-preserving computation even in resource-constrained environments.
]]></content:encoded>
<pubDate>Sun, 20 Apr 2025 05:38:55 +0000</pubDate>
</item>
<item>
<title>Proofs of Useful Work from Arbitrary Matrix Multiplication</title>
<link>https://eprint.iacr.org/2025/685</link>
<guid>https://eprint.iacr.org/2025/685</guid>
<content:encoded><![CDATA[
We revisit the longstanding open problem of implementing Nakamoto's proof-of-work (PoW) consensus based on a real-world computational task $T(x)$ (as opposed to artificial random hashing), in a truly  permissionless setting where the miner itself chooses the input $x$. The challenge in designing such a Proof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$ to produce a PoW certificate with prescribed hardness and with negligible computational overhead over the worst-case complexity of $T(\cdot)$ -- This  ensures malicious miners cannot ``game the system" by fooling the verifier to accept with higher probability compared to honest miners (while using similar computational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead is trivial for any task $T$, but also useless. 

Our main result is a PoUW for the task of Matrix Multiplication $\mathsf{MatMul}(A,B)$ of arbitrary matrices with  $1+o(1)$ multiplicative overhead compared to na\"ive $\mathsf{MatMul}$ (even in the presence of Fast Matrix Multiplication-style algorithms, which are currently impractical). We conjecture that our protocol has optimal security in the sense that a malicious prover cannot obtain any significant advantage over an honest prover. This conjecture is based on reducing hardness of our protocol to the task of solving a batch of low-rank random linear equations which is of independent interest.

Since $\mathsf{MatMul}$s are the bottleneck of AI compute as well as countless industry-scale applications, this primitive suggests a concrete design of a new L1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin mining -- allowing GPU consumers to reduce their AI training and inference costs by ``re-using" it for blockchain consensus, in exchange for block rewards (2-for-1). This blockchain is currently under construction.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 18:46:53 +0000</pubDate>
</item>
<item>
<title>Bitcoin-Enhanced Proof-of-Stake Security: Possibilities and Impossibilities</title>
<link>https://eprint.iacr.org/2022/932</link>
<guid>https://eprint.iacr.org/2022/932</guid>
<content:encoded><![CDATA[
Bitcoin is the most secure blockchain in the world, supported by the immense hash power of its Proof-of-Work miners. Proof-of-Stake chains are energy-efficient, have fast finality but face several security issues: susceptibility to non-slashable long-range safety attacks, low liveness resilience and difficulty to bootstrap from low token valuation.  We show that these security issues are inherent in any PoS chain without an external trusted source, and propose a new protocol, Babylon, where an off-the-shelf PoS protocol checkpoints onto Bitcoin to resolve these issues. An impossibility result justifies the optimality of Babylon. A use case of Babylon is to reduce the stake withdrawal delay: our experimental results show that this delay can be reduced from weeks in existing PoS chains to less than 5 hours using Babylon, at a transaction cost of less than 10K USD per annum for posting the checkpoints onto Bitcoin.
]]></content:encoded>
<pubDate>Mon, 18 Jul 2022 06:03:55 +0000</pubDate>
</item>
<item>
<title>Priv-PFL: A Privacy-Preserving and Efficient Personalized Federated Learning Approach</title>
<link>https://eprint.iacr.org/2025/703</link>
<guid>https://eprint.iacr.org/2025/703</guid>
<content:encoded><![CDATA[
Federated Learning (FL) allows clients to engage in learning without revealing their raw data. However, traditional FL focuses on developing a single global model for all clients, limiting their ability to have personalized models tailored to their specific needs. Personalized FL (PFL) enables clients to obtain their customized models, either with or without a central party.  Current PFL research includes mechanisms to detect poisoning attacks, in which a couple of malicious nodes try to manipulate training convergence by submitting misleading data. However, these detection approaches often overlook privacy concerns, as they require clients to share their models with all other clients.
This paper extends BALANCE, a personalized poisoning detection mechanism based on client models and their expectations. Our method enhances both security and privacy by ensuring clients are not required to share their model data with other clients. By leveraging server-assisted PFL and Fully Homomorphic Encryption (FHE), we enable a central party to identify unpoisoned clients from the perspective of individual clients and train personalized models securely. Additionally, we introduce an efficient personalized client selection algorithm that prevents redundant checks and ensures the inheritance of unpoisoned clients.
]]></content:encoded>
<pubDate>Fri, 18 Apr 2025 03:38:22 +0000</pubDate>
</item>
<item>
<title>Hermes: Efficient and Secure Multi-Writer Encrypted Database</title>
<link>https://eprint.iacr.org/2025/701</link>
<guid>https://eprint.iacr.org/2025/701</guid>
<content:encoded><![CDATA[
Searchable encryption (SE) enables privacy-preserving keyword search on encrypted data. Public-key SE (PKSE) supports multi-user searches but suffers from high search latency due to expensive public-key operations. Symmetric SE (SSE) offers a sublinear search but is mainly limited to single-user settings. Recently, hybrid SE (HSE) has combined SSE and PKSE to achieve the best of both worlds, including multi-writer encrypted search functionalities, forward privacy, and sublinear search with respect to database size. Despite its advantages, HSE inherits critical security limitations, such as susceptibility to dictionary attacks, and still incurs significant overhead for search access control verification, requiring costly public-key operation invocations (i.e., pairing) across all authorized keywords. Additionally, its search access control component must be rebuilt periodically for forward privacy, imposing substantial writer overhead.   
In this paper, we propose Hermes, a new HSE scheme that addresses the aforementioned security issues in prior HSE designs while maintaining minimal search complexity and user efficiency at the same time. Hermes enables multi-writer encrypted search functionalities and offers forward privacy along with resilience to dictionary attacks. To achieve this, we develop a new identity-based encryption scheme with hidden identity and key-aggregate properties, which could be of independent interest. We also design novel partitioning and epoch encoding techniques in Hermes to minimize search complexity and offer low user overhead in maintaining forward privacy. We conducted intensive experiments to assess and compare the performance of Hermes and its counterpart on commodity hardware. Experimental results showed that Hermes performs search one to two orders of magnitude faster than the state-of-the-art HSE while offering stronger security guarantees to prevent dictionary and injection attacks.
]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 20:09:07 +0000</pubDate>
</item>
<item>
<title>Fherret: Proof of FHE Correct-and-Honest Evaluation with Circuit Privacy from MPCitH</title>
<link>https://eprint.iacr.org/2025/700</link>
<guid>https://eprint.iacr.org/2025/700</guid>
<content:encoded><![CDATA[
The major Fully Homomorphic Encryption (FHE) schemes guarantee the privacy of the encrypted message only in the honest-but-curious setting, when the server follows the protocol without deviating. However, various attacks in the literature show that an actively malicious server can recover sensitive information by executing incorrect functions, tampering with ciphertexts, or observing the client’s reaction during decryption.

Existing integrity solutions for FHE schemes either fail to guarantee circuit privacy, exposing the server's computations to the client, or introduce significant computational overhead on the prover by requiring proofs of FHE operations on ciphertexts.

In this work, we present Fherret, a novel scheme leveraging the MPC-in-the-Head (MPCitH) paradigm to provide a proof of correct-and-honest homomorphic evaluation while preserving circuit privacy. This proof guarantees that the client can safely decrypt the ciphertext obtained from the server without being susceptible to reaction-based attacks, such as verification and decryption oracle attacks. Additionally, this proof guarantees that the server’s evaluation maintains correctness, thereby protecting the client from $\mathsf{IND}\text{-}\mathsf{CPA}^{\mathsf{D}}$-style attacks.

Our solution achieves a prover overhead of $4\lambda$ homomorphic evaluations of random functions from the function space $\mathcal{F}$, while retaining a competitive verifier overhead of $2 \lambda$ homomorphic evaluations and a communication size proportional to $\sqrt{2\lambda}$ times the size of a function from $\mathcal{F}$. 

Furthermore, Fherret is inherently parallelizable, achieving a parallel computation overhead similar to a homomorphic evaluation of a random function from $\mathcal{F}$ for both the prover and the verifier.
]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 12:15:18 +0000</pubDate>
</item>
<item>
<title>Efficient Foreign-Field Arithmetic in PLONK</title>
<link>https://eprint.iacr.org/2025/695</link>
<guid>https://eprint.iacr.org/2025/695</guid>
<content:encoded><![CDATA[
PLONK is a prominent universal and updatable zk-SNARK for general circuit satisfiability, which allows a prover to produce a short certificate of the validity of a certain statement/computation. Its expressive model of computation and its highly efficient verifier complexity make PLONK a powerful tool for a wide range of blockchain applications.

Supporting standard cryptographic primitives (such us ECDSA over SECP256k1) or advanced recursive predicates (e.g. incrementally verifiable computation) on a SNARK presents a significant challenge. It requires so-called foreign-field arithmetic (enforcing constraints over algebraic fields that differ from the SNARK native field) which was previously believed to incur an overhead of two or three orders of magnitude.

We build on the techniques by Lubarov and Baylina and observe that, by considering tight bounds on their encoding of foreign-field multiplication, the number of PLONK constraints can be significantly reduced. We show that these techniques also extend to elliptic curve emulation, with an overhead of just one order of magnitude (with respect to its native counterpart). We validate soundness and completeness of our main results in EasyCrypt. Finally, we implement an open-source library with support for foreign-field arithmetic. Our experimental results showcase the generality of our techniques and confirm their suitability for real-world applications.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 16:17:52 +0000</pubDate>
</item>
<item>
<title>A Formal Security Analysis of Hyperledger AnonCreds</title>
<link>https://eprint.iacr.org/2025/694</link>
<guid>https://eprint.iacr.org/2025/694</guid>
<content:encoded><![CDATA[
In an anonymous credential system, users collect credentials from issuers, and can use their credentials to generate privacy-preserving identity proofs that can be shown to third-party verifiers. Since the introduction of anonymous credentials by Chaum in 1985, there has been promising advances with respect to system design, security analysis and real-world implementations of anonymous credential systems.

In this paper, we examine Hyperledger AnonCreds, an anonymous credential system that was introduced in 2017 and is currently undergoing specification. Despite being implemented in deployment-ready identity system platforms, there is no formal security analysis of the Hyperledger AnonCreds protocol. We rectify this, presenting syntax and a security model for, and a first security analysis of, the Hyperledger AnonCreds protocol. In particular, we demonstrate that Hyperledger AnonCreds is correct, and satisfies notions of unforgeability and anonymity. We conclude with a discussion on the implications of our findings, highlighting the importance of rigorous specification efforts to support security evaluation of real-world cryptographic protocols.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 16:16:57 +0000</pubDate>
</item>
<item>
<title>Accountable Liveness</title>
<link>https://eprint.iacr.org/2025/693</link>
<guid>https://eprint.iacr.org/2025/693</guid>
<content:encoded><![CDATA[
Safety and liveness are the two classical security properties of consensus protocols. Recent works have strengthened safety with accountability: should any safety violation occur, a sizable fraction of adversary nodes can be proven to be protocol violators. This paper studies to what extent analogous accountability guarantees are achievable for liveness. To reveal the full complexity of this question, we introduce an interpolation between the classical synchronous and partially-synchronous models that we call the $x$-partially-synchronous network model in which, intuitively, at most an $x$ fraction of the time steps in any sufficiently long interval are asynchronous (and, as with a partially-synchronous network, all time steps are synchronous following the passage of an unknown "global stablization time"). We prove a precise characterization of the parameter regime in which accountable liveness is achievable: if and only if $x < 1/2$ and $f < n/2$, where $n$ denotes the number of nodes and $f$ the number of nodes controlled by an adversary. We further refine the problem statement and our analysis by parameterizing by the number of violating nodes identified following a liveness violation, and provide evidence that the guarantees achieved by our protocol are near-optimal (as a function of $x$ and $f$). Our results provide rigorous foundations for liveness-accountability heuristics such as the  "inactivity leaks" employed in Ethereum.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 15:04:09 +0000</pubDate>
</item>
<item>
<title>DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures</title>
<link>https://eprint.iacr.org/2025/692</link>
<guid>https://eprint.iacr.org/2025/692</guid>
<content:encoded><![CDATA[
An interactive aggregate signature scheme allows $n$ signers, each with their own secret/public key pair $(sk_i, pk_i)$ and message $m_i$, to jointly produce a short signature that simultaneously witnesses that $m_i$ has been signed under $pk_i$ for every $i \in \{1, \dots, n\}$. Despite the large potential for savings in terms of space and verification time, which constitute the two main bottlenecks for large blockchain systems such as Bitcoin, aggregate signatures have received much less attention than the other members of the multi-party signature family, namely multi-signatures such as $\mathsf{MuSig2}$ and threshold signatures such as $\mathsf{FROST}$.

In this paper, we propose $\mathsf{DahLIAS}$, the first aggregate signature scheme with constant-size signatures—a signature has the same shape as a standard Schnorr signature—directly based on discrete logarithms in pairing-free groups. The signing protocol of $\mathsf{DahLIAS}$ consists of two rounds, the first of which can be preprocessed without the message, and verification (for a signature created by $n$ signers) is dominated by one multi-exponentiation of size $n+1$, which is asymptotically twice as fast as batch verification of $n$ individual Schnorr signatures.

$\mathsf{DahLIAS}$ is designed with real-world applications in mind. Besides the aforementioned benefits of space savings and verification speedups, $\mathsf{DahLIAS}$ offers key tweaking, a technique commonly used in Bitcoin to derive keys in hierarchical deterministic wallets and to save space as well as enhance privacy on the blockchain. We prove $\mathsf{DahLIAS}$ secure in the concurrent setting with key tweaking under the (algebraic) one-more discrete logarithm assumption in the random oracle model.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 12:49:45 +0000</pubDate>
</item>
<item>
<title>SASTA: Ambushing Hybrid Homomorphic Encryption Schemes with a Single Fault</title>
<link>https://eprint.iacr.org/2024/041</link>
<guid>https://eprint.iacr.org/2024/041</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption offers an effective solution for privacy-preserving computation, but its adoption is hindered by substantial computational and communication overheads. To address these, the Hybrid Homomorphic Encryption (HHE) protocol was developed, where the client encrypts data using a symmetric encryption scheme (SE), and the server homomorphically evaluates its decryption. Previous studies have demonstrated that the HHE protocol has no impact on the correctness of applications; however, in this work, we shift the focus to its security resilience  when subjected to Differential Fault Analysis (DFA). While DFA has proven effective against standalone symmetric-key primitives, no DFA study has been proposed that exploits the HHE protocol as a whole. Furthermore, previous DFA approaches on SE rely on strong assumptions such as nonce reuse, which limits their applicability in real-world protocols or practical applications.

In this work, we show that the structure of the HHE protocol itself exposes new avenues for fault exploitation. We introduce Sasta-DFA, which, to our knowledge, is the first DFA targeting HHE protocol in its entirety. Our study demonstrates that an attacker can achieve complete key recovery with a single fault injection. A key feature of this attack is that it does not require nonce reuse, thus adhering to nonce-related specifications. We adapt the IND-CPAD threat model proposed by Li and Micciancio at Eurocrypt’21 for HHE in the context of fault attacks. 

We conduct the first DFA study on the emerging HHE-specific integer-based SE schemes— Rubato, Hera, Pasta, and Masta. Notably, our attack methodology is generalizable and applicable to a broader class of HHE-friendly SE schemes, including boolean schemes like Rasta and even the standard scheme AES. We also present the first experimental validation of fault analysis on these new HHE-enabling schemes. Our attack, mounted on an ATXmega128D4-AU microcontroller, successfully demonstrates full key recovery. Finally, we also extend Sasta-DFA to Authenticated Transciphering protocols under a weaker threat model that removes any functional dependency.
]]></content:encoded>
<pubDate>Wed, 10 Jan 2024 13:43:36 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Protocol for Knowledge of Known Discrete Logarithms: Applications to Ring Confidential Transactions and Anonymous Zether</title>
<link>https://eprint.iacr.org/2025/690</link>
<guid>https://eprint.iacr.org/2025/690</guid>
<content:encoded><![CDATA[
The securities of a large fraction of zero-knowledge arguments of knowledge schemes rely on the discrete logarithm (DL) assumption or the discrete logarithm relation assumption, such as Bulletproofs (S&amp;P 18) and compressed $\Sigma$-protocol (CRYPTO 20). At the heart of these protocols is an interactive proof of knowledge between a prover and a verifier showing that a Pedersen vector commitment $P=h^{\rho}\cdot\textbf{g}^{\textbf{x}}$  to a vector $\textbf{x}$  satisfies multi-variate equations, where the DL relations among the vector of generators $\textbf{g}$ are unknown. However, in some circumstances, the prover may know the DL relations among the generators, and the DL relation assumption no longer holds, such as ring signatures, ring confidential transactions (RingCT) and K-out-of-N proofs, which will make the soundness proof of these protocols infeasible.
This paper is concerned with a problem called knowledge of known discrete logarithms (KKDL) that appears but has not been clearly delineated in the literature.  Namely, it asks to prove a set of multi-exponent equalities, starting with the fact that the prover may know the DL relations among the generators of these equalities.  Our contributions are three-fold:  (1) We propose a special honest-verifier zero-knowledge protocol for the problem.  Using the Fiat-Shamir heuristic and the improved inner-product argument of Bulletproofs,  the proof size of our protocol is logarithmic to the dimension of the vector. (2) As applications, our protocol can be utilized to construct logarithmic-size RingCT securely which fixes the issues of Omniring (CCS 19), ring signatures (with signature size $2\cdot \lceil \log_2(N) \rceil+10$ for ring size $N$) and  $K$-out-of-$N$ proof of knowledge (with proof size $2\cdot \lceil \log_2(N) \rceil+14$) which achieves the most succinct proof size improving on previous results. Meanwhile, we propose the first account-based multi-receiver privacy scheme considering the sender's privacy with logarithmic proof size (to the best of our knowledge). (3) We describe an attack on RingCT-3.0 (FC 20) where an attacker can spend a coin of an arbitrary amount that never existed on the blockchain.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 09:51:57 +0000</pubDate>
</item>
<item>
<title>SUMAC: an Efficient Administrated-CGKA Using Multicast Key Agreement</title>
<link>https://eprint.iacr.org/2025/682</link>
<guid>https://eprint.iacr.org/2025/682</guid>
<content:encoded><![CDATA[
Since the standardization of the Secure Group Messaging protocol Messaging Layer Security (MLS) [4 ], whose core subprotocol is a Continuous Group Key Agreement (CGKA) mechanism named TreeKEM, CGKAs have become the norm for group key exchange protocols. However, in order to alleviate the security issue originating from the fact that all users in a CGKA are able to carry out sensitive operations on the member group, an augmented protocol called Administrated-CGKA (A-CGKA) has been recently created [2].

An A-CGKA includes in the cryptographic protocol the management of the administration rights that restrict the set of privileged users, giving strong security guarantees for the group administration. The protocol designed in [2] is a plugin added to a regular (black-box) CGKA, which consequently add some complexity to the underlying CGKA and curtail its performances. Yet, leaving the fully decentralized paradigm of a CGKA offers the perspective of new protocol designs, potentially more efficient.

We propose in this paper an A-CGKA called SUMAC, which offers strongly enhanced communication and storage performances compared to other A-CGKAs and even to TreeKEM. Our protocol is based on a novel design that modularly combines a regular CGKA used by the administrators of the group and a Tree-structured Multicast Key Agreement (TMKA) [9] – which is a centralized group key exchange mechanism administrated by a single group manager – between each administrator and all the standard users. That TMKA gives SUMAC an asymptotic communication cost logarithmic in the number of users, similarly to a CGKA. However, the concrete performances of our protocol are much better than the latter, especially in the post-quantum framework, due to the intensive use of secret-key cryptography that offers a lighter bandwidth than the public-key encryption schemes from a CGKA.

In practice, SUMAC improves the communication cost of TreeKEM by a factor 1.4 to 2.4 for admin operations and a factor 2 to 38 for user operations. Similarly, its storage cost divides that of TreeKEM by a factor 1.3 to 23 for an administrator and 3.9 to 1,070 for a standard user.

Our analysis of SUMAC is provided along with a ready-to-use open-source rust implementation that confirms the feasibility and the performances of our protocol.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 13:20:26 +0000</pubDate>
</item>
<item>
<title>Pirouette: Query Efficient Single-Server PIR</title>
<link>https://eprint.iacr.org/2025/680</link>
<guid>https://eprint.iacr.org/2025/680</guid>
<content:encoded><![CDATA[
Private information retrieval (PIR) allows a client to query a public database privately and serves as a key building block for privacy-enhancing applications. Minimizing query size is particularly important in many use cases, for example when clients operate on low-power or bandwidth-constrained devices. However, existing PIR protocols exhibit large query sizes: to query $2^{25}$ records, the smallest query size of 14.8KB is reported in Respire [Burton et al., CCS'24]. Respire is based on fully homomorphic encryption (FHE), where a common approach to lower the client-to-server communication cost is transciphering. When combining the state-of-the-art transciphering [Bon et al., CHES'24] with Respire, the resulting protocol (referred to as T-Respire) has a 336B query size, while incurring a 16.2x times higher server computation cost than Respire.

Our work presents the Pirouette protocol, which achieves a query size of just 36B without transciphering. This represents a 9.3x reduction compared to T-Respire and a 420x reduction to Respire. For queries over $2^{25}$ records, the single-core server computation in Pirouette is only 2x slower than Respire and 8.1x faster than T-Respire, and the server computation is highly parallelizable. Furthermore, Pirouette requires no database-specific hint for clients and naturally extends to support queries over encrypted databases.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 11:29:04 +0000</pubDate>
</item>
<item>
<title>Trilithium: Efficient and Universally Composable Distributed ML-DSA Signing</title>
<link>https://eprint.iacr.org/2025/675</link>
<guid>https://eprint.iacr.org/2025/675</guid>
<content:encoded><![CDATA[
<div> 关键词: Trilithium、分布式密钥生成、签名协议、FIPS 204 (ML-DSA)、恶意安全、通用可组合性(UC)模型、Rust实现、性能基准测试

总结:
本文介绍了Trilithium协议，这是一项符合FIPS 204（ML-DSA）标准的分布式密钥生成和签名协议。该协议允许“服务器”和“手机”在相关随机数提供者的协助下生成标准的ML-DSA签名。文章证明了在通用可组合性(UC)模型下，即使面对恶意的服务器或手机，Trilithium协议也能确保安全，并引入了一些新的技术来论证针对一方具有活性安全，而对另一方仅具有活性隐私保护的两方安全计算协议的安全性。此外，文中还提供了使用Rust语言实现的Trilithium协议，并对其进行了性能基准测试，证实了该协议的实际可行性。 <div>
In this paper, we present Trilithium: a protocol for distributed key generation and signing compliant with FIPS 204 (ML-DSA). Our protocol allows two parties, "server" and "phone" with assistance of correlated randomness provider (CRP) to produce a standard ML-DSA signature. We prove our protocol to be secure against a malicious server or phone in the universal composability (UC) model, introducing some novel techniques to argue the security of two-party secure computation protocols with active security against one party, but only active privacy against the other. We provide an implementation of our protocol in Rust and benchmark it, showing the practicality of the protocol.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 20:36:41 +0000</pubDate>
</item>
<item>
<title>A Dilithium-like Multisignature in Fully Split Ring and Quantum Random Oracle Model</title>
<link>https://eprint.iacr.org/2025/671</link>
<guid>https://eprint.iacr.org/2025/671</guid>
<content:encoded><![CDATA[
<div> 关键词：多签名方案、后量子密码学、量子随机oracle模型（QROM）、Dilithium、$\nu$-SelfTargetMSIS

总结:<br />
本文提出了一种基于Dilithium的新颖多签名方案，该方案旨在保证在量子随机oracle模型（QROM）下的安全性并优化实际应用效率。方案利用了环$\mathbb{Z}_q[X]/(x^n+1)$与$q \equiv 1 \pmod{2n}$的设计，实现了环的完全分割和高效的多项式算术通过数论变换（NTT）。此外，文章还提出了一种新的困难度假设——$\nu$-SelfTargetMSIS，扩展了原有的SelfTargetMSIS（出自Eurocrypt 2018），用于适应多个挑战目标的情况。这一新假设在QROM下被证明安全，并被用来构建一个既安全又高效的多签名方案。相较于先前技术，本文方法避免了局限性，减少了安全性损失，并得出一个更紧凑、更适合部署在后量子密码系统中的实用方案。 <div>
Multisignature schemes are crucial for secure operations in digital wallets and escrow services within smart contract platforms, particularly in the emerging post-quantum era. Existing post-quantum multisignature constructions either do not address the stringent requirements of the Quantum Random Oracle Model (QROM) or fail to achieve practical efficiency due to suboptimal parameter choices. 

In this paper, we present a novel Dilithium-based multisignature scheme designed to be secure in the QROM and optimized for practical use. Our scheme operates over the polynomial ring  $\mathbb{Z}_q[X]/(x^n+1)$ with $q \equiv 1 \pmod{2n}$, enabling full splitting of the ring and allowing for efficient polynomial arithmetic via the Number Theoretic Transform (NTT). This structure not only ensures post-quantum security but also bridges the gap between theoretical constructs and real-world implementation needs.

We further propose a new hardness assumption, termed 
$\nu$-SelfTargetMSIS, extending SelfTargetMSIS (Eurocrypt 2018) to accommodate multiple challenge targets. We prove its security in the QROM and leverage it to construct a secure and efficient multisignature scheme. Our approach avoids the limitations of previous techniques, reduces security loss in the reduction, and results in a more compact and practical scheme suitable for deployment in post-quantum cryptographic systems.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 10:18:41 +0000</pubDate>
</item>
<item>
<title>SoK: FHE-Friendly Symmetric Ciphers and Transciphering</title>
<link>https://eprint.iacr.org/2025/669</link>
<guid>https://eprint.iacr.org/2025/669</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全同态加密(FHE), 加密数据计算, 明文-密文扩展比, 变换加密技术, 性能基准测试

总结:
本文关注了完全同态加密（FHE）中的一个重要挑战，即显著的明文-密文扩展比率导致的高通信开销。为解决此问题，文章探讨了一种有效的变换加密技术，该技术通过首先使用空间高效的对称密码加密数据，然后再将对称密文转换为FHE密文，而无需解密。研究者已经开发了二十多种FHE友好的对称密码和变换加密方法，但选择与比较这些方案需要深入理解对称加密和FHE。为此，本文进行了详尽的调查，并基于安全级别、效率和兼容性等标准对这些方法进行了评估。作者还设计并执行了实验，以基准测试不同应用场景下各种对称密码和变换加密方法组合的性能。研究结果为根据任务上下文定制高效的变换加密提供了见解。此外，作者还将利用最新FHE实现的示例代码开源共享。 <div>
Fully Homomorphic Encryption (FHE) enables computation on encrypted data without decryption, demonstrating significant potential for privacy-preserving applications.
However, FHE faces several challenges, one of which is the significant plaintext-to-ciphertext expansion ratio, resulting in high communication overhead between client and server. The transciphering technique can effectively address this problem by first encrypting data with a space-efficient symmetric cipher, then converting symmetric ciphertext to FHE ciphertext without decryption.

Numerous FHE-friendly symmetric ciphers and transciphering methods have been developed by researchers, each with unique advantages and limitations. These often require extensive knowledge of both symmetric cryptography and FHE to fully grasp, making comparison and selection among these schemes challenging. To address this, we conduct a comprehensive survey of over 20 FHE-friendly symmetric ciphers and transciphering methods, evaluating them based on criteria such as security level, efficiency, and compatibility. We have designed and executed experiments to benchmark the performance of the feasible combinations of symmetric ciphers and transciphering methods across various application scenarios. Our findings offer insights into achieving efficient transciphering tailored to different task contexts. Additionally, we make our example code available open-source, leveraging state-of-the-art FHE implementations.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 01:34:00 +0000</pubDate>
</item>
<item>
<title>SQIAsignHD: SQIsignHD Adaptor Signature</title>
<link>https://eprint.iacr.org/2024/561</link>
<guid>https://eprint.iacr.org/2024/561</guid>
<content:encoded><![CDATA[
<div> 关键词：adaptor签名、量子攻击、椭圆曲线、超奇异同构、SIDH协议

总结:
本文提出了一种新的量子抵抗型适配器签名方案$\mathsf{SQIAsignHD}$，该方案基于超奇异椭圆曲线上的同构，并利用SIDH（超奇异同构Diffie-Hellman密钥交换）协议中的人工定向思想定义其基础难题。$\mathsf{SQIAsignHD}$旨在解决现有适配器签名方案对量子攻击的脆弱性问题。同时，文中还为所提出的签名方案提供了正式的安全证明。此工作对于区块链应用，包括加密货币以及支付通道网络、支付通道中心和原子交换等领域具有重要意义，因为它可以降低链上成本、提高可替代性和实现离链支付。 <div>
Adaptor signatures can be viewed as a generalized form of standard digital signature schemes by linking message authentication to the disclosure of a secret value. As a recent cryptographic primitive, they have become essential for blockchain applications, including cryptocurrencies, by reducing on-chain costs, improving fungibility, and enabling off-chain payments in payment-channel networks, payment-channel hubs, and atomic swaps. However, existing adaptor signature constructions are vulnerable to quantum attacks due to Shor's algorithm. In this work, we introduce $\mathsf{SQIAsignHD}$, a new quantum-resistant adaptor signature scheme based on isogenies of supersingular elliptic curves, using SQIsignHD - as the underlying signature scheme - and exploiting the idea of the artificial orientation on the supersingular isogeny Diffie-Hellman key exchange protocol, SIDH, to define the underlying hard relation. We, furthermore, provide a formal security proof for our proposed scheme.
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 13:31:30 +0000</pubDate>
</item>
<item>
<title>Vector Commitment Design, Analysis, and Applications: A Survey</title>
<link>https://eprint.iacr.org/2025/667</link>
<guid>https://eprint.iacr.org/2025/667</guid>
<content:encoded><![CDATA[
<div> 关键词: 哈希承诺、矢量承诺、多项式承诺、功能性承诺、分布式应用<br /><br />总结:
本文系统地梳理了哈希承诺以及其中的矢量承诺、多项式承诺和功能性承诺的设计原理、特性、属性及应用场景。文章首先定义并探讨了这些不同类型承诺方案之间的关系，明确了它们的安全性概念及相关性质。接着，对一些主流构造方法进行了对比分析，考虑了各自的特性、证明/更新信息大小以及证明/承诺复杂度。此外，文中还讨论了它们在各种分布式和隐私保护应用中的效率。最后，作者指出了未来可能的研究方向。 <div>
Due to their widespread applications in decentralized and privacy preserving technologies, commitment schemes have become increasingly important cryptographic primitives. With a wide variety of applications, many new constructions have been proposed, each enjoying different features and security guarantees. In this paper, we systematize the designs, features, properties, and applications of vector commitments (VCs). We define vector, polynomial, and functional commitments and we discuss the relationships shared between these types of commitment schemes. We first provide an overview of the definitions of the commitment schemes we will consider, as well as their security notions and various properties they can have. We proceed to compare popular constructions, taking into account the properties each one enjoys, their proof/update information sizes, and their proof/commitment complexities. We also consider their effectiveness in various decentralized and privacy preserving applications. Finally, we conclude by discussing some potential directions for future work.
]]></content:encoded>
<pubDate>Sun, 13 Apr 2025 02:11:13 +0000</pubDate>
</item>
<item>
<title>MProve-Nova: A Privacy-Preserving Proof of Reserves Protocol for Monero</title>
<link>https://eprint.iacr.org/2025/665</link>
<guid>https://eprint.iacr.org/2025/665</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof of Reserves (PoR), MProve-Nova, Monero, Nova recursive SNARK, Merkle trees

总结:
MProve-Nova 是一种针对门罗币（Monero）的无需可信设置的Proof of Reserves (PoR)协议，它利用Nova递归SNARK技术实现了两个创新点。首先，该协议首次仅揭示交易所拥有的输出数量，而不泄露其他关于输出或其密钥图像的信息。其次，它是首个拥有常量证明大小和验证时间的门罗币PoR协议，证明大小和验证时间与门罗区块链上的输出数量及交易所持有的输出数量无关。为了实现常量验证时间，MProve-Nova需要一个预处理步骤，该步骤会从门罗区块链的所有输出和密钥图像构建两棵默克尔树。

MProve-Nova由两个基于Nova的子协议组成：用于生成储备承诺的RCG协议和用于证明两个交易所之间未共谋的非共谋（NC）协议。RCG协议的证明大小约为28 KB，验证时间为4.3秒；而NC协议的证明大小约为24 KB，验证时间为0.2秒。两个协议的证明时间均随交易所持有的输出数量线性增加，但与门罗区块链上的输出数量无关。平均而言，对于RCG协议，每处理1000个输出大约需要42分钟，而对于NC协议，每处理1000个输出大约需要5分钟。 <div>
A proof of reserves (PoR) protocol enables a cryptocurrency exchange to prove to its users that it owns a certain amount of coins, as a first step towards proving that it is solvent. We present the design, implementation, and security analysis of MProve-Nova, a PoR protocol for Monero that leverages the Nova recursive SNARK to achieve two firsts (without requiring any trusted setup). It is the first Monero PoR protocol that reveals only the number of outputs owned by an exchange; no other information about the outputs or their key images is revealed. It is also the first Monero PoR protocol where the proof size and proof verification time are constant, i.e. they are independent of the number of outputs on the Monero blockchain and the number of outputs owned by the exchange. To achieve constant verification times, MProve-Nova requires a pre-processing step which creates two Merkle trees from all the outputs and key images on the Monero blockchain.

MProve-Nova consists of two Nova-based subprotocols, a reserves commitment generator (RCG) protocol used to compute a commitment to the total reserves owned by an exchange and a non-collusion (NC) protocol used to prove non-collusion between two exchanges. For the RCG protocol, we observed proof sizes of about 28 KB and verification times of 4.3 seconds. For the NC protocol, we observed proof sizes of about 24 KB and verification times of 0.2 seconds. Proving times for both protocols increase linearly with the number of outputs owned by the exchange but remain independent of the number of outputs on the Monero blockchain. On average, the RCG protocol required about 42 minutes per 1000 outputs and the NC protocol required about 5 minutes per 1000 outputs.
]]></content:encoded>
<pubDate>Sat, 12 Apr 2025 18:47:40 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Generalized Secret Sharing Schemes and Their Applications</title>
<link>https://eprint.iacr.org/2025/664</link>
<guid>https://eprint.iacr.org/2025/664</guid>
<content:encoded><![CDATA[
<div> 关键词：Generalized Secret Sharing (GSS)，Publicly Verifiable Generalized Secret Sharing (PVGSS)，Distributed Computing，Decentralized Exchange (DEX)，Non-Interactive Zero-Knowledge Proofs (NIZK)

<br /><br />总结:
本文提出了一种新的公开可验证广义秘密共享(PVGSS)方案，旨在提升GSS在透明系统中的应用性。PVGSS允许经销商基于细粒度的访问结构分享秘密，并使任何人都能验证经销商和股东是否诚信行事。文章首先介绍了两种实现GSS方案的方法，分别基于递归Shamir秘密共享和线性秘密共享方案(LSSS)。接着，通过将非交互式零知识证明集成到GSS方案中，提出了PVGSS构造方法，并证明该方案在DDH假设下达到了IND1保密性。为了展示PVGSS的实际应用，文章实现了一个支持公平原子交换ERC-20代币的去中心化交易所(DEX)协议，设计了复杂的访问结构以实现正常执行时的公平原子交换以及在出现纠纷时提供可问责仲裁的容错被动观察者。BN128曲线上的基准测试显示了PVGSS方案的计算效率，而Ethereum Gas成本分析证实了DEX实施的可行性。 <div>
Generalized secret sharing (GSS), which accommodates monotone access structures, has been under-explored in distributed computing over the past decades. In this paper, we propose the publicly verifiable generalized secret sharing (PVGSS) scheme, enhancing the applicability of GSS in transparent systems. PVGSS not only enables a dealer to share a secret with fine-grained access structures, but also allows anyone to verify whether the dealer and shareholders are acting honestly or not. We begin by introducing two approaches to implement GSS schemes: one based on recursive Shamir secret sharing and another utilizing linear secret sharing scheme (LSSS). Then, we present PVGSS constructions by integrating non-interactive zero-knowledge proofs into the GSS schemes. Further, we prove that the proposed PVGSS schemes achieve IND1-secrecy under DDH assumption. To showcase the practical applicability of PVGSS schemes, we implement a decentralized exchange (DEX) protocol that enables fair atomic swaps of ERC-20 tokens. A sophisticated access structure is devised to: (1) enable fair atomic swaps during normal protocol execution, and (2) incorporate fault-tolerant passive watchers to provide accountable arbitration when disputes occur. Our benchmarks on the BN128 curve demonstrate the computational efficiency of PVGSS schemes, while Ethereum gas cost analysis confirms the viability of the DEX implementation.
]]></content:encoded>
<pubDate>Sat, 12 Apr 2025 04:15:51 +0000</pubDate>
</item>
<item>
<title>Attribute-Based Publicly Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/662</link>
<guid>https://eprint.iacr.org/2025/662</guid>
<content:encoded><![CDATA[
<div> 关键词: 属性基秘密分享(AB-SS), 公开验证秘密分享(AB-PVSS), 加密策略属性基加密(CP-ABE), 非交互式零知识证明(NIZK), 乐观公平交换

总结:
本文提出了一种新的属性基秘密分享(AB-SS)方案，允许经销商根据用户属性而非特定个体分配秘密，只有满足预设访问结构的授权用户才能恢复秘密。进一步地，引入了属性基公开验证秘密分享(AB-PVSS)概念，使得外部用户能验证经销商和股东广播消息的正确性。为了构建AB-PVSS方案，首先实现了一个去中心化的、具有较小密文尺寸和较少计算操作的CP-ABE方案，但作为权衡，该方案并未完全实现。接着，通过整合非交互式零知识证明(NIZK)，实现了CP-ABE密文的公共验证功能。基于CP-ABE和NIZK，构建了AB-PVSS原语。此外，还利用AB-PVSS方案实现了一个直观的乐观公平交换实现。最后，对提出的CP-ABE和AB-PVSS方案进行了安全性分析及全面实验，结果显示这两个方案相比于相关工作均表现出合理的性能。 <div>
Can a dealer share a secret without knowing the shareholders? We provide a positive answer to this question by introducing the concept of an attribute-based secret sharing (AB-SS) scheme. With AB-SS, a dealer can distribute a secret based on attributes rather than specific individuals or shareholders. Only authorized users whose attributes satisfy a given access structure can recover the secret. Furthermore, we introduce the concept of attribute-based publicly verifiable secret sharing (AB-PVSS). An AB-PVSS scheme allows external users to verify the correctness of all broadcast messages from the dealer and shareholders, similar to a traditional PVSS scheme. Additionally, AB-SS (or AB-PVSS) distinguishes itself from traditional SS (or PVSS) by enabling a dealer to generate shares according to an arbitrary monotone access structure. To construct an AB-PVSS scheme, we first implement a decentralized ciphertext-policy attribute-based encryption (CP-ABE) scheme. The proposed CP-ABE scheme offers a smaller ciphertext size and requires fewer computational operations, although it is not fully-fledged as a trade-off. We then incorporate non-interactive zero-knowledge (NIZK) proofs to enable public verification of the CP-ABE ciphertext. Based on the CP-ABE and NIZK proofs, we construct an AB-PVSS primitive. Furthermore, we present an intuitive implementation of optimistic fair exchange based on the AB-PVSS scheme. Finally, we conduct security analysis and comprehensive experiments on the proposed CP-ABE and AB-PVSS schemes. The results demonstrate that both schemes exhibit plausible performance compared to related works.
]]></content:encoded>
<pubDate>Fri, 11 Apr 2025 13:28:24 +0000</pubDate>
</item>
<item>
<title>Scalable and Fine-Tuned Privacy Pass from Group Verifiable Random Functions</title>
<link>https://eprint.iacr.org/2025/659</link>
<guid>https://eprint.iacr.org/2025/659</guid>
<content:encoded><![CDATA[
<div> 关键词: 匿名令牌方案、可信用户、组可验证随机函数(GVRF)、通信成本、服务器计算成本

总结:
本文提出了一个新的匿名令牌方案设计方法，该方案不再依赖于两方计算实现隐私保护的伪随机函数评估，而是利用GVRF使得用户能够生成可验证的伪随机数。GVRF在可信用户群内部提供匿名验证功能。文章基于Dodis-Yampolskiy VRF和等价类签名，利用配对和新的Diffie-Hellman反演假设，在通用群模型中构建了组可验证随机函数。这种构造具有紧凑的公钥和证明，同时评价与验证的成本只比Dodis-Yampolskiy VRF略有增加。通过使用GVRF代替OPRF，新方案实现了在发放阶段通信和服务器端计算成本为常量且独立于用户请求的令牌数量。此外，文中还引入了可更新令牌策略的概念，能够在事后（即通过信誉检查后）根据当前或预期网络状况动态调整流通中的未使用的令牌数量。该方案的令牌还可计数并公开可验证，但相对于Privacy Pass协议来说，其兑换和验证的计算开销更高，且unlinkability保证稍弱。 <div>
Abstract—Anonymous token schemes are cryptographic
protocols for limiting the access to online resources to
credible users. The resource provider issues a set of access
tokens to the credible user that they can later redeem
anonymously, i.e., without the provider being able to link
their redemptions. When combined with credibility tests such
as CAPTCHAs, anonymous token schemes can significantly
increase user experience and provider security, without
exposing user access patterns to providers.
Current anonymous token schemes such as the Privacy
Pass protocol by Davidson et al. rely on oblivious
pseudorandom functions (OPRFs), which let server and user
jointly compute randomly looking access tokens. For those
protocols, token issuing costs are linear in the number of
requested tokens.
In this work, we propose a new approach for building
anonymous token schemes. Instead of relying on two-party
computation to realize a privacy-preserving pseudorandom
function evaluation, we propose to offload token generation
to the user by using group verifiable random functions
(GVRFs). GVRFs are a new cryptographic primitive
that allow users to produce verifiable pseudorandomness.
Opposed to standard VRFs, verification is anonymous within
the group of credible users. We give a construction of group
VRFs from the Dodis-Yampolskiy VRF and Equivalence-
Class Signatures, based on pairings and a new Diffie-
Hellman inversion assumption that we analyze in the Generic
Group Model. Our construction enjoys compact public keys
and proofs, while evaluation and verification costs are only
slightly increased compared to the Dodis-Yampolskiy VRF.
By deploying a group VRF instead of a OPRF, we
obtain an anonymous token scheme where communication
as well as server-side computation during the issuing phase
is constant and independent of the number of tokens a
user requests. Moreover, by means of our new concept of updatable token policies, the number of unspent tokens in
circulation can retrospectively (i.e., even after the credibility
check) be decreased or increased in order to react to
the current or expected network situation. Our tokens are
further countable and publicly verifiable. This comes at the
cost of higher computational efforts for token redemption
and verification as well as somewhat weaker unlinkability
guarantees compared to Privacy Pass.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 09:50:30 +0000</pubDate>
</item>
<item>
<title>Efficient Verifiable Mixnets from Lattices, Revisited</title>
<link>https://eprint.iacr.org/2025/658</link>
<guid>https://eprint.iacr.org/2025/658</guid>
<content:encoded><![CDATA[
<div> 关键词: Mixnets、量子安全、零知识证明、环同态加密、解密混合网

总结:
本文提出了一个基于环问题硬度的最紧凑可验证混合网络，旨在确保隐私和可验证性，同时抵抗量子计算机带来的安全性威胁。文章指出了现有基于环同态加密的混合网方案中证明洗牌过程的声望证明存在的问题，并指出该问题在实际实现中的影响，成功对其中一个混合网实施了攻击。为解决此问题，文章提出了一种适用于分裂环的通用洗牌证明方法。为了提高效率，新方案采用了解密混合网，并利用多项式环上的LWE和LWR问题的困难度实现了非常高效的层叠结构，使得密文大小缩小了约10倍和2倍，线性大小的零知识证明也减小了4倍和2倍。 <div>
Mixnets are powerful building blocks for providing anonymity
in applications like electronic voting and anonymous messaging. The en-
cryption schemes upon which traditional mixnets are built, as well as the
zero-knowledge proofs used to provide verifiability, will, however, soon
become insecure once a cryptographically-relevant quantum computer is
built. In this work, we construct the most compact verifiable mixnet that
achieves privacy and verifiability through encryption and zero-knowledge
proofs based on the hardness of lattice problems, which are believed to
be quantum-safe.

A core component of verifiable mixnets is a proof of shuffle. The starting
point for our construction is the proof of shuffle of Aranha et al. (CT-
RSA 2021). We first identify an issue with the soundness proof in that
work, which is also present in the adaptation of this proof in the mixnets
of Aranha et al. (ACM CCS 2023) and Hough et al. (IACR CiC 2025).
The issue is that one cannot directly adapt classical proofs of shuffle
to the lattice setting due to the splitting structure of the rings used in
lattice-based cryptography. This is not just an artifact of the proof, but
a problem that manifests itself in practice, and we successfully mount an
attack against the implementation of the first of the mixnets. We fix the
problem and introduce a general approach for proving shuffles in split-
ting rings that can be of independent interest.

The efficiency improvement of our mixnet over prior work is achieved by
switching from re-encryption mixnets (as in the works of Aranha et al.
and Hough et al.) to decryption mixnets with very efficient layering based
on the hardness of the LWE and LWR problems over polynomial rings.
The ciphertexts in our scheme are smaller by approximately a factor of
10X and 2X over the aforementioned instantiations, while the linear-size
zero-knowledge proofs are smaller by a factor of 4X and 2X.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 09:35:21 +0000</pubDate>
</item>
<item>
<title>Unbounded Multi-Hop Proxy Re-Encryption with HRA Security: An LWE-Based Optimization</title>
<link>https://eprint.iacr.org/2025/656</link>
<guid>https://eprint.iacr.org/2025/656</guid>
<content:encoded><![CDATA[
<div> 关键词: Proxy Re-Encryption, 多跳, 线性代数基, 适应性HRA安全, 高效率

<br /><br />总结:
本文提出了一种基于线性代数基的、具有适应性HRA安全级别的新型无界多跳Proxy Re-Encryption（PRE）方案。与此前Zhao等人提出的仅支持选择性CPA安全的无界多跳PRE方案相比，我们的方案提供更强的安全性。我们优化了基于FHEW-like盲旋转的重加密过程，解决了将Fuchsbauer等人框架应用于FHEW-like方案时，噪声泛滥技术与该框架之间的不兼容问题，从而降低了公钥的存储需求并提高了效率。此外，我们的优化无界多跳PRE方案还可以修改为无界同态PRE方案，允许对新鲜、重新加密和评估过的密文进行任意的同态计算，更加适用于实际应用场景。 <div>
Proxy re-encryption (PRE) schemes enable a semi-honest proxy to transform a ciphertext of one user $i$ to another user $j$ while preserving the privacy of the underlying message. Multi-hop PRE schemes allow a legal ciphertext to undergo multiple transformations, but for lattice-based multi-hop PREs, the number of transformations is typically bounded due to the increase of error terms. Recently, Zhao et al. (Esorics 2024) introduced a lattice-based unbounded multi-hop (homomorphic) PRE scheme that supports an unbounded number of hops. Nevertheless, their scheme only achieves the selective CPA security. In contrast, Fuchsbauer et al. (PKC 2019) proposed a generic framework for constructing HRA-secure unbounded multi-hop PRE schemes from FHE. Despite this, when instantiated with state-of-the-art FHEW-like schemes, the overall key size and efficiency remain unsatisfactory. 

In this paper, we present a lattice-based unbounded multi-hop PRE scheme with the stronger adaptive HRA security (i.e. security against honest re-encryption attacks), which is more suitable for practical applications. Our scheme features an optimized re-encryption process based on the FHEW-like blind rotation, which resolves the incompatibility between the noise flooding technique and Fuchsbauer et al. 's framework when instantiated with FHEW-like schemes. This results in reduced storage requirements for public keys and offers higher efficiency. Moreover, our optimized unbounded multi-hop PRE scheme can be modified to an unbounded homomorphic PRE, a scheme allowing for arbitrary homomorphic computations over fresh, re-encrypted, and evaluated ciphertexts.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 07:14:20 +0000</pubDate>
</item>
<item>
<title>ECDSA Cracking Methods</title>
<link>https://eprint.iacr.org/2025/654</link>
<guid>https://eprint.iacr.org/2025/654</guid>
<content:encoded><![CDATA[
<div> 关键词: ECDSA、区块链、数字签名、nonce、安全性

总结:
ECDSA（椭圆曲线数字签名算法）被许多区块链网络用于生成数字签名，包括比特币和以太坊。然而，其安全性和高效性的同时，对nonce值的使用需要谨慎处理。文章指出了几种可以利用来破解ECDSA签名的方法：一是nonce值泄露，二是弱nonce选择，三是nonce重复使用，四是两个密钥与共享nonce，五是故障攻击。这些情况都可能给ECDSA的安全性带来严重威胁。<br /><br /> <div>
The ECDSA (Elliptic Curve Digital Signature Algorithm) is used in many blockchain networks for digital signatures. This includes the Bitcoin and the Ethereum blockchains. While it has good performance levels and as strong current security, it should be handled with care. This care typically relates to the usage of the nonce value which is used to create the signature. This paper outlines the methods that can be used to break ECDSA signatures, including revealed nonces, weak nonce choice, nonce reuse, two keys and shared nonces, and fault attack.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 20:49:17 +0000</pubDate>
</item>
<item>
<title>Fission: Distributed Privacy-Preserving Large Language Model Inference</title>
<link>https://eprint.iacr.org/2025/653</link>
<guid>https://eprint.iacr.org/2025/653</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 隐私保护, 安全多方计算, 分割推理, Fission

总结:
本文提出了一种名为Fission的隐私保护框架，旨在解决大型语言模型（LLMs）应用中的隐私问题。Fission结合了安全多方计算（MPC）和非线性函数计算器网络，其中线性计算通过MPC网络进行，而非线性计算则在接收打乱值的独立评估网络上完成，从而确保每个评估器仅能访问部分打乱数据，同时保持模型权重的私密性。相较于现有方法，Fission在广泛测试的LLMs上实现了最高达八倍的更快推理速度和八倍的带宽降低，同时还保持了高精度。此外，文中还构建了一个针对相关工作中的分割推理技术的攻击示例，揭示了其存在显著的信息泄露问题，进一步证明了Fission在增强隐私保护方面所具有的优势。 <div>
The increased popularity of large language models (LLMs) raises serious privacy concerns, where users' private queries are sent to untrusted servers. Many cryptographic techniques have been proposed to provide privacy, such as secure multiparty computation (MPC), which enables the evaluation of LLMs directly on private data. However, cryptographic techniques have been deemed impractical as they introduce large communication and computation. On the other hand, many obfuscation techniques have been proposed, such as split inference, where part of the model is evaluated on edge devices to hide the input data from untrusted servers, but these methods provide limited privacy guarantees.

We propose Fission, a privacy-preserving framework that improves latency while providing strong privacy guarantees. Fission utilizes an MPC network for linear computations, while nonlinearities are computed on a separate evaluator network that receives shuffled values in the clear and returns nonlinear functions evaluated at these values back to the MPC network. As a result, each evaluator only gets access to parts of the shuffled data, while the model weights remain private. We evaluate fission on a wide set of LLMs and compare it against prior works. Fission results in up to eight times faster inference and eight times reduced bandwidth compared to prior works while retaining high accuracy. Finally, we construct an attack on obfuscation techniques from related works that show significant information leakage, and we demonstrate how Fission enhances privacy.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 19:07:20 +0000</pubDate>
</item>
<item>
<title>Anamorphic Voting: Ballot Freedom Against Dishonest Authorities</title>
<link>https://eprint.iacr.org/2025/647</link>
<guid>https://eprint.iacr.org/2025/647</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子投票、解密密钥、投票隐私、共谋环境、幻影投票、加密技术

总结:
文章提出了“幻影投票”这一概念，用于解决电子投票系统在完全不诚实环境下，所有计票机构可能合谋破坏选民投票隐私的问题。幻影投票允许选民在投出看似常规的选票的同时，能够向审计员真实传达其投票意向。文章进一步展示了新的加密技术，证明了若干现有的投票方案可以支持幻影投票的实现。<br /><br /> <div>
Electronic voting schemes typically ensure ballot privacy by
assuming that the decryption key is distributed among tallying authorities, preventing any single authority from decrypting a voter’s ballot.
However, this assumption may fail in a fully dishonest environment where
all tallying authorities collude to break ballot privacy.
In this work, we introduce the notion of anamorphic voting, which enables voters to convey their true voting intention to an auditor while
casting an (apparently) regular ballot. We present new cryptographic
techniques demonstrating that several existing voting schemes can support anamorphic voting.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 08:10:06 +0000</pubDate>
</item>
<item>
<title>GIGA Protocol: Unlocking Trustless Parallel Computation in Blockchains</title>
<link>https://eprint.iacr.org/2025/645</link>
<guid>https://eprint.iacr.org/2025/645</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、可扩展性、SNARK协议、并行执行、交易复杂性

总结:
本文提出了一种名为GIGA的基于SNARK协议的区块链解决方案，旨在解决现代去中心化区块链系统的可扩展性问题。GIGA协议通过将交易组织成非冲突批处理并在多个分布式实体间信任lessly地并行执行和证明，实现了并发处理非冲突操作，同时保持安全性和状态一致性。通过递归聚合批量证明为单个简洁证明，该协议消除了网络中的冗余重执行，显著提升了区块链吞吐量，不影响去中心化特性。

在相同的系统假设下（例如共识、网络和虚拟机架构），当大多数交易作用于状态的不同部分时，与采用顺序执行模型的流行区块链架构相比，GIGA协议的吞吐量提升可达一万倍以上，相较于使用节点内部并行化方案的区块链架构，也有超过五百倍的性能提升。此外，该协议还支持更高的交易计算复杂性，从而解锁了传统区块链架构上因计算能力有限而无法实现的各种应用场景。

另外，文章还提出了一个奖励机制，以确保证明网络的经济可持续性，动态适应计算需求并基于成本效率和可靠性激励竞争。 <div>
The scalability of modern decentralized blockchain systems is constrained by the requirement that the participating nodes execute the entire chains transactions without the ability to delegate the verification workload across multiple actors trustlessly. This is further limited by the need for sequential transaction execution and repeated block validation, where each node must re-execute all transactions before accepting blocks, also leading to delayed broadcasting in many architectures.

Consequently, throughput is limited by the capacity of individual nodes, significantly preventing scalability.

In this paper, we introduce GIGA, a SNARK-based protocol that enables trustless parallel execution of transactions, processing non-conflicting operations concurrently, while preserving security guarantees and state consistency. The protocol organizes transactions into non-conflicting batches which are executed and proven in parallel, distributing execution across multiple decentralized entities. These batch proofs are recursively aggregated into a single succinct proof that validates the entire block.

As a result, the protocol both distributes the execution workload and removes redundant re-execution from the network, significantly improving blockchain throughput while not affecting decentralization.

Performance estimates demonstrate that, under the same system assumptions (e.g., consensus, networking, and virtual machine architecture) and under high degrees of transaction parallelism (i.e., when most transactions operate on disjoint parts of the state), our protocol may achieve over a 10000x throughput improvement compared to popular blockchain architectures that use sequential execution models, and over a 500x improvement compared to blockchain architectures employing intra-node parallelization schemes. 

Furthermore, our protocol enables a significant increase in transaction computational complexity, unlocking a wide range of use cases that were previously unfeasible on traditional blockchain architectures due to the limited on-chain computational capacity.

Additionally, we propose a reward mechanism that ensures the economic sustainability of the proving network, dynamically adjusting to computational demand while fostering competition among provers based on cost-efficiency and reliability.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 17:18:19 +0000</pubDate>
</item>
<item>
<title>Scalable Non-Fungible Tokens on Bitcoin</title>
<link>https://eprint.iacr.org/2025/641</link>
<guid>https://eprint.iacr.org/2025/641</guid>
<content:encoded><![CDATA[
<div> 关键词: NFT、Bitcoin、桥接式铸造、二级共识系统、OP_RETURN<br /><br />总结:
该文提出了一种协议，用于扩展比特币上的非同质化代币（NFT）的创建、管理和交易。该协议借鉴了其他区块链上使用的无桥接铸造模式，通过利用比特币链上的数据处理所有与代币所有权相关的事宜，包括交易，并结合了一个二级共识系统来实现铸造和可选的元数据修改。为尽可能减小其在比特币主链上的占用空间，该协议使用OP_RETURN机制记录所有权信息，而相关的NFT操作则存储在LAOS区块链上。所有的数据均永久保存在链上，并不依赖于桥梁或第三方运营商。 <div>
This paper presents a protocol for scaling the creation, management, and trading of non-fungible tokens (NFTs) on Bitcoin by extending bridgeless minting patterns previously used on other blockchains. The protocol leverages on-chain Bitcoin data to handle all aspects of token ownership, including trading, while integrating a secondary consensus system for minting and optionally modifying token metadata. To minimize its on-chain footprint, the protocol utilizes the OP_RETURN mechanism for ownership records, while complementary NFT-related actions are stored on the LAOS blockchain. All data remains permanently on-chain, with no reliance on bridges or third-party operators.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 11:00:04 +0000</pubDate>
</item>
<item>
<title>A Study of Blockchain Consensus Protocols</title>
<link>https://eprint.iacr.org/2025/637</link>
<guid>https://eprint.iacr.org/2025/637</guid>
<content:encoded><![CDATA[
<div> 关键词: 比特币、共识机制、POW、Proof of Stake、区块链应用

总结:

本文介绍了自比特币开创第一代加密货币并采用工作量证明(POW)共识机制以来，为了解决能源消耗大和碳足迹重的问题，出现了一系列创新如空间证明(Proof of Space)、权益证明(POS)等不同的共识机制。随着区块链技术应用场景和类型的扩展，比如物联网(IoT)区块链和互操作性解决方案，对各种优化的共识机制产生了需求，例如拜占庭容错(BFT)算法。文章着重梳理了现有的区块链共识理论成果，整理了设计挑战、权衡以及研究领域，并以互操作性解决方案的案例为例展示了区块链设计空间的多样性和灵活性，旨在为研究人员提供一个全面的专题概述及深入研究每个细节的相关链接资源。 <div>
When Nakamoto invented Bitcoin, the first generation of cryptocurrencies followed it in applying POW (Proof of Work) consensus mechanism; due to its excessive energy consumption and heavy carbon footprints, new innovations evolved like Proof of Space, POS (Proof of Stake), and a lot more with many variants for each. Furthermore, the emergence of more blockchain applications and kinds beyond just cryptocurrencies needed more consensus mechanisms that is optimized to fit requirements of each application or blockchain kind; examples range from IoT (Internet of Things) blockchains for sustainability applications that often use variants of BFT (Byzantine Fault Tolerance) algorithm, and consensus needed to relay transactions and/or assets between different blockchains in interoperability solutions. Previous studies concentrated on surveying and/or proposing different blockchain consensus rules, on a specific consensus issue like attacks, randomization, or on deriving theoretical results. Starting from discussing most important theoretical results, this paper tries to gather and organize all significant existing material about consensus in the blockchain world explaining design challenges, tradeoffs and research areas. We realize that the topic could fit for a complete textbook, so we summarize the basic concepts and support with tables and appendices. Then we highlight some case examples from interoperability solutions to show how flexible and wide the design space is to fit both general and special purpose systems. The aim is to provide researchers with a comprehensive overview of the topic, along with the links to go deeper into every detail.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 07:30:27 +0000</pubDate>
</item>
<item>
<title>Towards Scalable YOSO MPC via Packed Secret-Sharing</title>
<link>https://eprint.iacr.org/2025/635</link>
<guid>https://eprint.iacr.org/2025/635</guid>
<content:encoded><![CDATA[
<div> 关键词: YOSO模型、分布式设置、安全多方计算、通信复杂度、fail-stop敌人

总结:
本文介绍了YOSO（You Only Speak Once）模型在实现分布式环境如区块链中的强大安全保障方面的应用。针对安全多方计算（MPC）这一核心问题，文章提出首个随参与方数量增加而提高效率（以通信复杂度衡量）的YOSO MPC协议。该协议中，对于$t<\frac{1}{2}$的诚实多数委员会成员，只需略微增加委员会规模，即可显著减少在线通信量。此外，文章还特别考虑了fail-stop类型的敌人（即可能因DoS攻击或软硬件错误而意外失败的诚实参与者），与先前的工作相比，这种情况下协议具有更好的可扩展性。在此前的研究中，这类敌人被视为完全恶意的参与者。 <div>
The YOSO (You Only Speak Once) model, introduced by Gentry et al. (CRYPTO 2021), helps to achieve strong security guarantees in cryptographic protocols for  distributed settings, like blockchains, with large number of parties. YOSO protocols typically employ smaller anonymous committees to execute individual rounds of the protocol instead of having all parties execute the entire protocol. After completing their tasks, parties encrypt protocol messages for the next anonymous committee and erase their internal state before publishing ciphertexts, thereby enhancing security in dynamically changing environments.

In this work, we consider the problem of secure multi-party computation (MPC), a fundamental problem in cryptography and distributed computing. We assume honest majority among the committee members, and work in the online-offline, i.e., preprocessing, setting.
   In this context, we present the first YOSO MPC protocol where efficiency---measured as communication complexity---improves as the number of parties increases. Specifically, for $0<\epsilon<1/2$ and an adversary corrupting $t<n(\frac{1}{2}-\epsilon)$ out of $n$ parties, our MPC protocol exhibits enhanced scalability as $n$ increases, where the online phase communication becomes independent of $n$.
   Prior YOSO MPC protocols considered $t$ as large as $(n-1)/2$, but a significant hurdle persisted in obtaining YOSO MPC with communication that does not scale linearly with the number of committee members, a challenge that is exagerbated when the committee size was large per YOSO's requirements.
   We show that, by considering a small ``gap'' of $\epsilon>0$, the sizes of the committees are only marginally increased, while online communication is significantly reduced.


Furthermore, we explicitly consider fail-stop adversaries, i.e., honest participants who may inadvertently fail due to reasons such as denial of service or software/hardware errors. In prior YOSO work, these adversaries were grouped with fully malicious parties. Adding explicit support for them allows us to achieve even better scalability.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 05:25:39 +0000</pubDate>
</item>
<item>
<title>Dyna-hinTS: Silent Threshold Signatures for Dynamic Committees</title>
<link>https://eprint.iacr.org/2025/631</link>
<guid>https://eprint.iacr.org/2025/631</guid>
<content:encoded><![CDATA[
<div> 关键词：silent threshold signatures (STS), committee-based silent threshold signature (c-STS), hinTS, Dyna-hinTS, Ethereum Altair, Dfinity

总结:
本文提出了一个新的密码学概念——委员会型沉默阈值签名(c-STS)方案，旨在适应像Ethereum Altair和Dfinity这样的系统，其中只有指定的委员会被授权在特定时间段进行签名。现有的STS方案无法直接应用于委员会设置，因为其仅验证签名者的数量，而不能确认他们所属的委员会。针对这一问题，文章提出了首个c-STS方案——Dyna-hinTS，它是hinTS的升级版，实现了对委员会设置的支持。在一组1024个签名人（其中682个签名人可能被篡改）中，与hinTS相比，Dyna-hinTS在由80个签名人组成的委员会中能够在0.35秒内生成聚合签名，性能提高了4.9倍，但代价是签名验证时间比hinTS增加了4%。此外，Dyna-hinTS还支持一般的访问结构、加权签名，并改进了现有的多宇宙阈值签名技术。 <div>
The works of Garg et al. [S&amp;P'24] (aka hinTS) and Das et al. [CCS'23] introduced the notion of silent threshold signatures (STS) - where a set of signers silently perform local computation to generate a public verification key. To sign a message, any set of $t$ signers sign the message non-interactively and these are aggregated into a constant-sized signature. This paradigm avoids performing expensive Distributed Key Generation procedure for each set of signers while keeping the public verification key constant-sized. 

In this work, we propose the notion of committee-based silent threshold signature (c-STS) scheme. In a c-STS scheme, a set of signers initially perform a one-time setup to generate the verification key, and then a subset of signers are randomly chosen for an epoch to perform the threshold signing while the other signers are not authorized to sign during that epoch. This captures existing systems like Ethereum Altair and Dfinity where only a specific committee is authorized to sign in a designated epoch. The existing STS schemes cannot be extended to the committee setting because the signature verification only attests to the number of signing parties, not which committee they belong to.

So, we upgrade hinTS to the committee setting by proposing Dyna-hinTS. It is the $first$ c-STS scheme and it requires a one-time silent setup and generates a one-time public verification key that does not vary with the committee. Assuming a set of 1024 signers (with corrupt 682 signers), hinTS generates an aggregated signature in 1.7s whereas Dyna-hinTS generates it in $0.35$s within a committee of $80$ signers. This yields a $4.9\times$ improvement over hinTS for signature generation at the cost of increasing signature verification time by $4\%$ over hinTS. Dyna-hinTS supports general access structure, weighted signatures and improves existing multiverse threshold signatures.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 15:27:03 +0000</pubDate>
</item>
<item>
<title>Charge Your Clients: Payable Secure Computation and Its Applications</title>
<link>https://eprint.iacr.org/2025/630</link>
<guid>https://eprint.iacr.org/2025/630</guid>
<content:encoded><![CDATA[
<div> 关键词：数据市场、隐私保护、恶意客户端行为、安全计算、付费协议

总结:
针对当前数据市场存在的客户隐私保护不力和易受恶意客户端行为影响的问题，本文提出了“付费安全计算”这一新型安全计算范式，旨在保护客户查询隐私的同时，使服务器能够安全获取定价信息，并防范恶意客户端的行为。为具体应用，文章设计了适用于关键词私有信息检索（KPIR）和私有集合交集（PSI）两种场景的定制化付费协议。实验结果显示，相较于不支持定价功能的基线协议，提出的付费协议并未引入过多开销。付费KPIR协议在线成本与基线相同，但设置时间慢约1.3-1.6倍；付费PSI协议则需要大约2倍的通信成本，运行时间根据网络环境不同，比基线协议慢1.5-3.2倍。 <div>
The online realm has witnessed a surge in the buying and selling of data, prompting the emergence of dedicated data marketplaces. These platforms cater to servers (sellers), enabling them to set prices for access to their data, and clients (buyers), who can subsequently purchase these data, thereby streamlining and facilitating such transactions. However, the current data market is primarily confronted with the following issues. Firstly, they fail to protect client privacy, presupposing that clients submit their queries in plaintext. Secondly, these models are susceptible to being impacted by malicious client behavior, for example, enabling clients to potentially engage in arbitrage activities.

To address the aforementioned issues, we propose payable secure computation, a novel secure computation paradigm specifically designed for data pricing scenarios. It grants the server the ability to securely procure essential pricing information while protecting the privacy of client queries. Additionally, it fortifies the server's privacy against potential malicious client activities. As specific applications, we have devised customized payable protocols for two distinct secure computation scenarios: Keyword Private Information Retrieval (KPIR) and Private Set Intersection (PSI). 

We implement our two payable protocols and compare them with the state-of-the-art related protocols that do not support pricing as a baseline. Since our payable protocols are more powerful in the data pricing setting, the experiment results show that they do not introduce much overhead over the baseline protocols. 
Our payable KPIR achieves the same online cost as baseline, while the setup is about $1.3-1.6\times$ slower than it. Our payable PSI needs about $2\times$ more communication cost than that of baseline protocol, while the runtime is $1.5-3.2\times$ slower than it depending on the network setting.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 13:45:34 +0000</pubDate>
</item>
<item>
<title>CertainSync: Rateless Set Reconciliation with Certainty</title>
<link>https://eprint.iacr.org/2025/623</link>
<guid>https://eprint.iacr.org/2025/623</guid>
<content:encoded><![CDATA[
<div> 关键词: Set Reconciliation、Blockchain Networks、CertainSync、Invertible Bloom Lookup Tables (IBLTs)、Universe Reduction

<br /><br />总结:
本文提出了名为 CertainSync 的一种新颖的集合同步框架，该框架首次保证了无需任何参数化或估计器的情况下成功进行集合和解同步。CertainSync 基于可逆布隆查找表 (IBLTs) 的近期构造，能够适应未知对称差集大小并确保当通信开销达到与对称差集和全集大小相关的下限时，完成成功的集合和解同步。理论上对其进行了分析以证明其确定性。通过仿真验证了该方法相对于其他基准集合和解同步方案的优势，同时对于区块链网络中大型全集的情况，扩展了 UniverseReduceSync 技术来进一步降低通信开销。通过对来自 Ethereum 区块链网络的真实交易哈希数据的模拟比较和验证，结果显示了一个改进通信开销与保持和解同步保障之间的权衡，为不同场景下的集合和解同步提供了全面解决方案。 <div>
Set reconciliation is a fundamental task in distributed systems, particularly in blockchain networks, where it enables the synchronization of transaction pools among peers and facilitates block dissemination. Existing traditional set reconciliation schemes are either statistical, providing success probability as a function of the communication overhead and the size of the symmetric difference, or require parametrization and estimation of the size of the symmetric difference, which can be prone to error. In this paper, we present CertainSync, a novel reconciliation framework that, to the best of our knowledge, is the first to guarantee successful set reconciliation without any parametrization or estimators in use. The framework is rateless and adapts to the unknown symmetric difference size. The set reconciliation is guaranteed to be completed successfully whenever the communication overhead reaches a lower bound derived from the symmetric difference size and the universe size. Our framework is based on recent constructions of Invertible Bloom Lookup Tables (IBLTs) ensuring successful element listing as long as the number of elements is bounded. We provide a theoretical analysis to prove the certainty in the set reconciliation for multiple constructions. The approach is also validated by simulations, showing the ability to synchronize sets with efficient communication costs while maintaining reconciliation guarantees compared to other baseline schemes for set reconciliation. To further improve communication overhead for large universes as blockchain networks, CertainSync is extended with a universe reduction technique to minimize communication overhead. We compare and validate the extended framework UniverseReduceSync against the basic CertainSync framework through simulations using real blockchain transaction hash data from the Ethereum blockchain network. The results illustrate a trade-off between improved communication costs and maintaining reconciliation guarantees without relying on parametrization or estimators, offering a comprehensive solution for set reconciliation in diverse scenarios.
]]></content:encoded>
<pubDate>Sun, 06 Apr 2025 20:17:58 +0000</pubDate>
</item>
<item>
<title>Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/620</link>
<guid>https://eprint.iacr.org/2025/620</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明 (ZKPs)，隐私保护，可验证计算，GPU加速，ASIC加速，zkSpeed，HyperPlonk，可信设置，证明大小，验证成本，共识系统，SumCheck，多标量乘法 (MSMs)，芯片架构，带宽，性能提升。

<br /><br />总结：
本文介绍了针对零知识证明（ZKPs）技术的一种新型加速器——zkSpeed，该技术正在逐步成为隐私保护和可验证计算领域的关键工具。现有的ZKP协议加速方案存在需要每次应用都建立可信设置或产生较大证明规模、增加验证成本等问题。文章提出的新加速器zkSpeed专注于加速HyperPlonk这一支持一次性、通用设置以及为公共验证和基于共识系统的典型ZKP应用生成小规模证明的先进ZKP协议。文中设计了一个采用366.46 mm²面积和2TB/s带宽的全芯片架构，实现了对整个证明生成过程的加速，相比CPU基线实现了平均801倍的速度提升。 <div>
(Preprint) Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable machine learning, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process.Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 23:56:21 +0000</pubDate>
</item>
<item>
<title>Making BBS Anonymous Credentials eIDAS 2.0 Compliant</title>
<link>https://eprint.iacr.org/2025/619</link>
<guid>https://eprint.iacr.org/2025/619</guid>
<content:encoded><![CDATA[
<div> 关键词: eIDAS 2.0、BBS#、匿名凭证系统、数字身份钱包、隐私保护

总结:
本文提出了一个名为BBS#的数字身份钱包解决方案，旨在助力实现eIDAS 2.0的目标，为欧洲公民提供高安全性和隐私保护的个人数字身份钱包。BBS#是在BBS和BBS+基础上进行改进的版本，去除了对双线性映射和配对友好曲线的依赖，转而采用传统椭圆曲线上的已知数字签名方案（如ECDSA或ECSchnorr）。这一方案无需改变现有硬件或其所支持的算法，且已在随机预言机模型下被证明安全，同时保持了BBS系系统的不可伪造性以及匿名性等安全属性。

通过在不同智能手机的安全执行环境中实施BBS#，实验证明可以实现高效（约70毫秒在Android StrongBox上）、安全且达到最高等级认证要求的eIDAS 2.0交易，同时为所有欧洲身份证钱包用户提供最优级别的隐私保护。 <div>
eIDAS 2.0 (electronic IDentification, Authentication and trust Services) is a very ambitious regulation aimed at equipping European citizens with a personal digital identity wallet (EU Digital Identity Wallet) on a mobile phone that not only needs to achieve a high level of security, but also needs to be available as soon as possible for a large number of citizens and respect their privacy (as per GDPR - General Data Protection Regulation).  

In this paper, we introduce the foundations of a digital identity wallet solution that could help move closer to this objective by leveraging the proven anonymous credentials system BBS (Eurocrypt 2023), also known as BBS+, but modifying it to avoid the limitations that have hindered its widespread adoption, especially in certified infrastructures requiring trusted hardware implementation.  
In particular, the solution we propose, which we call BBS#, does not rely, contrary to BBS/BBS +, on bilinear maps and pairing-friendly curves (which are not supported by existing hardware) and only depends on the hardware implementation of well-known digital signature schemes such as ECDSA (ISO/IEC 14888-3) or ECSDSA (also known as ECSchnorr, ISO/IEC 14888-3) using classical elliptic curves. More precisely, BBS# can be rolled out without requiring any change in existing hardware or the algorithms that hardware supports. 
BBS# , which is proven secure in the random oracle model, retains the well-known security property (unforgeability of the credentials under the (gap) q-SDH assumption) and anonymity properties (multi-show full unlinkability and statistical anonymity of presentation proofs) of BBS/BBS+. 

By implementing BBS# on several smartphones using different secure execution environments, we show that it is possible to achieve eIDAS 2.0 transactions which are not only efficient (around 70 ms on Android StrongBox), secure and certifiable at the highest level but also provide strong (optimal) privacy protection for all European ID Wallet users.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 17:44:46 +0000</pubDate>
</item>
<item>
<title>Anonymous Self-Credentials and their Application to Single-Sign-On</title>
<link>https://eprint.iacr.org/2025/618</link>
<guid>https://eprint.iacr.org/2025/618</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字身份、隐私保护、Sybil抵抗、匿名自证明（ASC）、用户发行的不可链接单点登录（U2SSO）

总结:
随着数字身份变得不可或缺，确保用户隐私和实现服务提供者的Sybil抵抗机制至关重要。文章提出了一个新的加密概念——匿名自证明（ASC）及其两种实施方案，该方案允许用户在保持匿名集合内的隐私的同时，使服务提供者能够实现Sybil阻力。基于ASC，文章还介绍了一种用户发行的不可链接单点登录（U2SSO）解决方案，它仅依赖于一个身份注册库来不可变地存储身份，使得用户可以使用一套主凭据为每个服务提供商生成不可链接的子凭据。通过实际的概念验证，文章展示了U2SSO解决方案的实用性和效率。 <div>
Modern life makes having a digital identity no longer optional, whether one needs to manage a bank account or subscribe to a newspaper. As the number of online services increases, it is fundamental to safeguard user privacy and equip service providers (SP) with mechanisms enforcing Sybil resistance, i.e., preventing a single entity from showing as many. 
  Current approaches, such as anonymous credentials and self-sovereign identities, typically rely on identity providers or identity registries trusted not to track users' activities. However, this assumption of trust is no longer appropriate in a world where user data is considered a valuable asset. 
  To address this challenge, we introduce a new cryptographic notion, Anonymous Self-Credentials (ASC) along with two implementations. This approach enables users to maintain their privacy within an anonymity set while allowing SPs to obtain Sybil resistance. Then, we present a User-issued Unlinkable Single Sign-On (U2SSO) implemented from ASC that solely relies on an identity registry to immutably store identities. A U2SSO solution allows users to generate unlinkable child credentials for each SP using only one set of master credentials.
  We demonstrate the practicality and efficiency of our U2SSO solution by providing a complete proof-of-concept.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 16:44:58 +0000</pubDate>
</item>
<item>
<title>State Machine Replication Without Borders</title>
<link>https://eprint.iacr.org/2025/616</link>
<guid>https://eprint.iacr.org/2025/616</guid>
<content:encoded><![CDATA[
<div> 关键词: 状态机复制(SMR), 不诚实节点, 查询率, 恒定时间, 自我时钟同步

总结:
本文提出了一种在无权限设置下的状态机复制(SMR)协议，该协议针对具有不可信、不可靠的八卦网络环境中的不诚实节点。协议的目标是在参与节点持续波动及存在控制单位时间内查询率少于一半的拜占庭敌手的情况下，确保各节点对状态机器的公平访问并实时处理诚实节点提交的所有操作符号。与比特币区块链提供的协议（其在对抗拜占庭敌手时能实现多项式轮次的结算，但公平性仅在失败停止模型中成立）不同，新提出的协议首次实现了在该环境中同时具备预期恒定时延的结算和快速公平性。此外，此协议还具备自我时钟同步能力，能在参与者动态变化的情况下仍保持容错运行。 <div>
A set of unacquainted  parties, some of which may misbehave, communicate with each other over an unauthenticated and unreliable gossip network. They wish to jointly replicate a state machine $\Pi$ so that each one of them has fair access to its operation. Specifically, assuming parties' computational power is measured as queries to an oracle machine $H(\cdot)$, parties can issue symbols to the state machine in proportion to their queries to $H(\cdot)$ at a given fixed rate. Moreover, if such access to the state machine is provided continuously in expected constant time installments we qualify it as fast fairness.

A state machine replication (SMR) protocol in this permissionless setting is expected to offer consistency across parties and reliably process all symbols that honest parties wish to add to it in a timely manner despite  continuously fluctuating participation and in the presence of an adversary who commands less than half of the total queries to $H(\cdot)$ per unit of time.

A number of protocols strive to offer the above guarantee together with fast settlement  — notably, the Bitcoin blockchain offers a protocol that settles against Byzantine adversaries in polylogarithmic rounds, while fairness only holds in a fail-stop adversarial model (due to the fact that Byzantine behavior can bias access to the state machine in the adversary's favor). In this work, we put forth the first Byzantine-resilient protocol solving SMR in this setting with both expected-constant-time settlement and fast fairness. In addition, our protocol is self-sufficient in the sense of performing its own time keeping while tolerating an adaptively fluctuating set of parties.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 15:50:40 +0000</pubDate>
</item>
<item>
<title>Highly Efficient Actively Secure Two-Party Computation with One-Bit Advantage Bound</title>
<link>https://eprint.iacr.org/2025/614</link>
<guid>https://eprint.iacr.org/2025/614</guid>
<content:encoded><![CDATA[
<div> 关键词：两方计算（2PC）、主动安全性、一比特泄漏、公平性、一比特优势界<br /><br />总结：<br />
本文提出了一个新的安全概念——主动安全性带一比特优势界，通过渐进式揭示机制严格限制了敌手的优势不超过诚实方获取信息的一比特。为实现这一目标，文章设计了一种基于标签结构的高效常数轮2PC协议，该协议在双工网络中实现了与被动安全性garbled电路几乎相同的运行时间性能（例如，在LAN环境下对{\tt SHA256}电路，其通信开销仅比后者高$1.033\times$），并且输出渐进揭示的额外开销极低（每释放一位结果仅需通信$80$字节）。由于具备强化的安全保证和较低的额外开销，该协议非常适合实际应用中的两方计算场景。 <div>
Secure two-party computation (2PC) enables two parties to jointly evaluate a function while maintaining input privacy. Despite recent significant progress, a notable efficiency gap remains between actively secure and passively secure protocols. In S\&amp;P'12, Huang, Katz, and Evans formalized the notion of \emph{active security with one-bit leakage}, providing a promising approach to bridging this gap. Protocols derived from this notion have become foundational in designing highly efficient actively secure 2PC protocols. However, a critical challenge identified by Huang, Katz, and Evans remains unexplored: these protocols face significant weaknesses in ensuring fairness for honest parties when employed in standalone settings rather than as components within larger protocols. While the authors proposed two potential solutions to mitigate this issue, both approaches are prohibitively expensive and lack formalization of security guarantees.

In this paper, we first formally define an enhanced notion called \emph{active security with one-bit-advantage bound}, in which the adversaries' advantages are strictly bounded to at most one bit beyond what honest parties obtain. This bound is enforced through a \emph{progressive revelation} mechanism, where the evaluation result is disclosed incrementally bit by bit. In addition, we propose a novel approach leveraging label structures within garbled circuits to design a highly efficient constant-round 2PC protocol that achieves active security with one-bit advantage bound. Our protocol demonstrates \emph{runtime performance nearly identical to that of passively secure garbled-circuit counterparts} in duplex networks (\eg $1.033\times$ for the {\tt SHA256} circuit in LAN), with \emph{low overhead} for output progressive revelation (only $80$ communicated bytes per bit release).

With its strengthened security guarantees and minimal overhead, our protocol is highly suitable for practical 2PC applications.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 12:54:09 +0000</pubDate>
</item>
<item>
<title>Low-Latency Rate-Distortion-Perception Trade-off: A Randomized Distributed Function Computation Application</title>
<link>https://eprint.iacr.org/2025/613</link>
<guid>https://eprint.iacr.org/2025/613</guid>
<content:encoded><![CDATA[
<div> 关键词: 语义通信系统、率-失真-感知问题、图像压缩、物理层安全、量子攻击

<br /><br />
总结:
本文针对语义通信系统的应用背景，重点研究了在带宽有限和延迟敏感环境下图像压缩的率-失真-感知（RDP）问题。文章在随机分布式函数计算框架下，建立了非渐近性的RDP区域，明确了在有限块长度条件下率、失真与感知质量之间的权衡关系，符合语义通信的目标。进一步地，将这一区域扩展至包含保密性约束的情况，通过物理层安全方法确保对量子攻击具有抵抗能力。作者的主要贡献包括：(1) 在现实性和失真约束下建立非渐近性RDP区域的可行界；(2) 将这些边界扩展以提供强大的安全性保障；(3) 描述了在严格现实性约束下的渐近安全RDP区域特性；(4) 展示了在引入保密约束及有限块长度条件下的码率显著降低及其影响。这些研究成果为设计低延迟、高保真、安全的图像压缩系统提供了行动指南，尤其适用于隐私关键领域的应用。 <div>
Semantic communication systems, which focus on transmitting the semantics of data rather than its exact reconstruction, redefine the design of communication networks for transformative efficiency in bandwidth-limited and latency-critical applications. Addressing these goals, we tackle the rate-distortion-perception (RDP) problem for image compression, a critical challenge in achieving perceptually realistic reconstructions under rate constraints. Formulated within the randomized distributed function computation (RDFC) framework, we establish an achievable non-asymptotic RDP region, providing finite blocklength trade-offs between rate, distortion, and perceptual quality, aligning with semantic communication objectives. We extend this region to also include a secrecy constraint, providing strong secrecy guarantees against eavesdroppers via physical-layer security methods, ensuring resilience against quantum attacks. Our contributions include (i) establishing achievable bounds for non-asymptotic RDP regions under realism and distortion constraints; (ii) extending these bounds to provide strong secrecy guarantees; (iii) characterizing the asymptotic secure RDP region under a perfect realism constraint; and (iv) illustrating significant reductions in rates and the effects of secrecy constraints and finite blocklengths. Our results provide actionable insights for designing low-latency, high-fidelity, and secure image compression systems with realistic outputs, advancing applications, e.g., in privacy-critical domains.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 07:51:58 +0000</pubDate>
</item>
<item>
<title>SCALES: MPC with Small Clients and Larger Ephemeral Servers</title>
<link>https://eprint.iacr.org/2022/751</link>
<guid>https://eprint.iacr.org/2022/751</guid>
<content:encoded><![CDATA[
<div> 关键词: YOSO模型、MPC、SCALES、重随机化加密码方案、适应性服务器腐败

总结:
YOSO模型是一种创新的MPC（多-party计算）方法，能够在公共区块链上执行并抵抗适应性玩家腐败。然而，由于其构建模块的成本问题，实际应用中YOSO模型效率低下。为了解决这一问题，文章提出了SCALES模型，该模型保持了对适应性服务器腐败的抗性，同时大大提高了协议效率。在SCALES模型中，只有负责MPC计算的服务器是短暂和不可预测的（一次性发送消息并揭示身份），而输入提供者（客户端）仅发布问题实例并收集结果，不参与计算过程。SCALES模型利用重随机化加密码方案构建而成，这是一个具有独立兴趣的技术贡献，还具备其他潜在应用。 <div>
The recently proposed YOSO model is a groundbreaking approach to MPC, executable on a public blockchain, circumventing adaptive player corruption by hiding the corruption targets until they are worthless. Players are selected unpredictably from a large pool to perform  MPC subtasks, in which each selected player sends a single message (and reveals their identity). While YOSO MPC has attractive asymptotic complexity,  unfortunately, it is concretely prohibitively expensive due to the cost of its building blocks.

We propose a modification to the YOSO model that preserves  resilience to adaptive server corruption, but allows for much more efficient protocols. In SCALES (Small Clients And Larger Ephemeral Servers) only the servers facilitating the MPC computation are ephemeral (unpredictably selected and ``speak once''). Input providers (clients) publish problem instances and collect the output, but do not otherwise participate in computation. SCALES offers attractive features, and improves over YOSO protocols in outsourcing MPC to a large pool of servers under adaptive corruption.

We build SCALES from rerandomizable garbling schemes, which is a contribution of independent interest, with additional applications.
]]></content:encoded>
<pubDate>Sun, 12 Jun 2022 08:55:52 +0000</pubDate>
</item>
<item>
<title>Clubcards for the WebPKI: smaller certificate revocation tests in theory and practice</title>
<link>https://eprint.iacr.org/2025/610</link>
<guid>https://eprint.iacr.org/2025/610</guid>
<content:encoded><![CDATA[
<div> 关键词：CRLite、低带宽、低延迟、隐私保护、证书吊销

总结:
CRLite是一种低带宽、低延迟且能保护隐私的证书吊销数据分布机制。研究者提出了一种名为“clubcard”的新颖数据结构用于会员资格测试，该结构能够高效地编码撤销数据。文章指出，截至2024年11月，WebPKI包含超过9亿份有效证书和800万份已吊销证书。通过CRLite的新实例化，这些证书的吊销状态可以被压缩到6.7 MB的包中，相较于2017年IEEE安全与隐私研讨会上提出的原始CRLite减少了54%，并且比该工作声称的下限还小了21%。使用俱乐部卡序列可编码动态数据集，如WebPKI吊销集合，平均而言，对于每6小时更新一次的WebPKI，其俱乐部卡编码可压缩至26.8 kB，这使得CRLite真正具备实用性。研究人员已经扩展了Mozilla的CRLite基础设施以生成俱乐部卡，并在Firefox中添加了对这一系统的客户端支持。目前，该实现已成为Firefox Nightly版默认的吊销检查机制，同时提出了进一步降低CRLite带宽需求的策略。 <div>
CRLite is a low-bandwidth, low-latency, privacy-preserving mechanism for distributing certificate revocation data. A CRLite aggregator periodically encodes revocation data into a compact static hash set, or membership test, which can can be downloaded by clients and queried privately. We present a novel data-structure for membership tests, which we call a clubcard, and we evaluate the encoding efficiency of clubcards using data from Mozilla's CRLite infrastructure.

As of November 2024, the WebPKI contains over 900 million valid certificates and over 8 million revoked certificates. We describe an instantiation of CRLite that encodes the revocation status of these certificates in a 6.7 MB package. This is $54\%$ smaller than the original instantiation of CRLite presented at the 2017 IEEE Symposium on Security and Privacy, and it is $21\%$ smaller than the lower bound claimed in that work.

A sequence of clubcards can encode a dynamic dataset like the WebPKI revocation set. Using data from late 2024 again, we find that clubcards encoding 6 hour delta updates to the WebPKI can be compressed to 26.8 kB on average---a size that makes CRLite truly practical.

We have extended Mozilla's CRLite infrastructure so that it can generate clubcards, and we have added client-side support for this system to Firefox. We report on some performance aspects of our implementation, which is currently the default revocation checking mechanism in Firefox Nightly, and we propose strategies for further reducing the bandwidth requirements of CRLite.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 17:24:30 +0000</pubDate>
</item>
<item>
<title>SoK: Self-Generated Nudes over Private Chats: How Can Technology Contribute to a Safer Sexting?</title>
<link>https://eprint.iacr.org/2025/597</link>
<guid>https://eprint.iacr.org/2025/597</guid>
<content:encoded><![CDATA[
<div> 关键词: 移动应用、裸照分享、安全性、隐私保护、技术提案

总结:
本文针对越来越多的人利用移动应用程序进行交友和轻度接触，进而引发的自拍裸照分享现象，以及由此产生的安全与隐私问题进行了研究。通过系统性文献回顾和对52款约会、消息传递及社交网络应用的调查，作者定义了艳照分享威胁模型，衍生出了相关提案/功能的分类体系，并讨论了其不足之处，同时梳理了隐私相关的概念。研究表明，学术提案和应用功能生态系统非常多样，实现更安全的艳照分享远不止于裸体检测。没有一种技术能全面解决所有威胁，但每种技术都能从不同角度为更安全的艳照分享做出贡献。未来的研究和开发可以从这些发现中汲取启示。 <div>
More and more people take advantage of mobile apps to strike up relationships and casual contacts. This sometimes results in the sharing of self-generated nudes. While this opens a way for sexual exploration, it also raises concerns. In this paper, we review existing technology-assisted permissive proposals/features that provide security or privacy benefits when sharing nudes online. To do so, we performed a systematic literature review combing through 10,026 search results and cross-references, and we identified real-world solutions by surveying OS features and 52 dating, messaging and social network apps. We systematized knowledge by defining a sexting threat model, deriving a taxonomy of the proposals/features, discussing some of their shortcomings, organizing privacy-related concepts, and providing take-aways with some directions for future research and development. Our study found a very diverse ecosystem of academic proposals and app features, showing that safer sexting goes far beyond nude detection. None of the techniques represents the ultimate solution for all threats, but each contributes to safer sexting in a different way.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 10:31:56 +0000</pubDate>
</item>
<item>
<title>Mobile Byzantine Agreement in a Trusted World</title>
<link>https://eprint.iacr.org/2025/603</link>
<guid>https://eprint.iacr.org/2025/603</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Agreement、移动拜占庭节点、同步系统、Garay模型、Bonnet模型、Buhrman模型、可信计数器抽象、处理器数量、算法

<br /><br />总结：
本文关注的是在同步系统中，移动拜占庭节点能够从一个进程转移到另一个进程并破坏其宿主环境下的拜占庭一致性问题。研究了三种代表性模型：Garay模型、Bonnet模型和Buhrman模型。对于每个模型，文章指出了容忍$t$个移动拜占庭节点所需的最小处理器数量：Garay模型为$4t+1$，Bonnet模型为$5t+1$，Buhrman模型为$3t+1$。为了提高对移动拜占庭节点的容错能力，文章提出了一种集成可信计数器抽象的新模型，这可以防止节点产生矛盾行为。在新模型下，证明了分别需要$3t+1$、$4t+1$以及$2t+1$个处理器来容忍$t$个移动拜占庭节点。此外，针对Garay模型、Bonnet模型和Buhrman模型，本文还提出了新的移动拜占庭一致性算法，这些算法与上述新的下界相匹配。 <div>
In this paper, we address the Byzantine Agreement problem in synchronous systems where Byzantine agents can move from process to process, corrupting their host. 
We focus on three representative models: \emph{Garay's}, \emph{Bonnet's} and \emph{Buhrman's} models.
In \emph{Garay's model} when a process has been left by the Byzantine, it is in the \emph{cured} state and it is aware of its condition and thus can remain silent for a round to prevent the dissemination of wrong information.
In \emph{Bonnet's model} a cured process may send messages (based on a state corrupted by the malicious agent), however it will behave correctly in the way it sends those messages: i.e., send messages according to the algorithm.
In \emph{Buhrman's model} Byzantine agents move together with the message.  
It has been shown that in order to solve Byzantine Agreement in the \emph{Garay's model} at least $4t+1$ processors are needed, for \emph{Bonnet's model} at least $5t+1$ processors are needed, while for \emph{Buhrman's model} at least $3t+1$ processors are needed.
In this paper we target to increase the tolerance to mobile Byzantines by integrating a trusted counter abstraction to the above models. This abstraction prevents nodes to equivocate. In the new models we prove that at least $3t+1$, respectively $4t+1$, and $2t+1$ processors are needed  to tolerate $t$ mobile Byzantine agents. Furthermore,  we propose novel Mobile Byzantine Agreement algorithms that  match these new lower bounds for \emph{Garay's}, \emph{Bonnet's} and \emph{Buhrman's} models.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 20:38:55 +0000</pubDate>
</item>
<item>
<title>DSM: Decentralized State Machine - The Missing Trust Layer of the Internet</title>
<link>https://eprint.iacr.org/2025/592</link>
<guid>https://eprint.iacr.org/2025/592</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized State Machine (DSM), 中心化信任系统, 量子-resistant, 确定性状态转换, 持续、无气体经济模型

总结:
文章介绍了Decentralized State Machine (DSM)，这是一种旨在解决当前互联网中依赖于企业、政府和中介机构的中心化信任系统所带来问题的新技术。DSM通过数学强制的信任层消除了对共识机制、第三方验证者和集中式基础设施的需求，提供了量子-resistant和确定性状态转换，确保了数字身份和价值交换的即时最终性和防篡改的前向仅进状态进展。与传统区块链执行模型不同，DSM采用预承诺的状态转移实现安全、多路径工作流，无需图灵完备或全球共识。其协议架构基于直链哈希和稀疏索引的稀疏默克尔树（SMTs），确保高效验证、可扩展性和隐私保护。DSM还引入了一种可持续的、无gas经济模型，基于密码学订阅承诺。总的来说，DSM提供了一种实用且可扩展的选择，以去中心化和可信的方式实现在线和离线环境中的节点间交互，从而打破了对传统互联网信任模型的依赖。 <div>
The modern internet relies heavily on centralized trust systems controlled by corporations, governments, and intermediaries to manage authentication, identity, and value transfer. These models introduce fundamental vulnerabilities, including censorship, fraud, and systemic insecurity. The Decentralized State Machine (DSM) addresses these issues by introducing a mathematically enforced trust layer that eliminates the need for consensus mechanisms, third-party validators, and centralized infrastructure. DSM enables quantum-resistant, deterministic state transitions for digital identity and value exchange—offering immediate finality, offline capability, and tamper-proof forward-only state progression.

DSM replaces traditional blockchain execution models with deterministic, pre-committed state transitions, enabling secure, multi-path workflows without requiring Turing-completeness or global consensus. The protocol architecture is based on a straight hash chain with sparse indexing and Sparse Merkle Trees (SMTs), ensuring efficient verification, scalability, and privacy. A bilateral isolation model supports asynchronous, offline operation with built-in consistency guarantees. DSM introduces a sustainable, gas-free economic model based on cryptographic subscription commitments.

This paper outlines the architecture, cryptographic foundations, and security guarantees of DSM, and demonstrates how it achieves verifiable, trustless interaction between peers—both online and offline. By decoupling security from consensus and enabling self-validating state transitions, DSM offers a practical and scalable alternative to conventional internet trust models.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 18:03:39 +0000</pubDate>
</item>
<item>
<title>A Place for Everyone vs Everyone in its Place: Measuring and Attacking the Ethereum Global Network</title>
<link>https://eprint.iacr.org/2025/588</link>
<guid>https://eprint.iacr.org/2025/588</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum Global Network (EGN), 多服务架构, 节点发现效率, 安全性, 攻击抵抗力

<br /><br />总结：

本文对以太坊全球网络（EGN）的设计及其宣称的优势进行了批判性分析。研究发现，EGN在节点发现过程中存在显著缺陷，其多服务架构导致超过四分之三的连接尝试未能找到提供所需服务的节点，例如有一个案例中，一个节点平均需要尝试$45,908$次才能找到一个邻居。此外，这种混合架构还削弱了EGN的安全性，网络对于DHT污染和分区攻击高度易感。只需$300$个恶意节点，攻击者就能隔离数千个节点，严重阻碍网络恢复。相比之下，如此少量的恶意节点对单一服务P2P网络的影响则微乎其微。文章提出了改进EGN节点发现效率以及增强其抵御攻击能力的解决方案。 <div>
The Ethereum Global Network (EGN) is the peer-to-peer (P2P) network underlying Ethereum and thousands of subsequent blockchain services. Deviating from traditional single-service P2P networks, EGN's multi-service architecture has gained widespread acceptance for supposedly improving node discovery efficiency and security. This paper challenges this belief by critically examining EGN's design and its purported benefits. Our analysis reveals significant shortcomings in EGN's node discovery process. EGN nodes struggle to connect with peers offering the desired service: over three-quarters of connection attempts reach nodes of other services. In an extreme case, one node spent an average of $45\,908$ connection attempts to find each neighbor. Moreover, this blended architecture compromises EGN's security. The network demonstrates high susceptibility to DHT pollution and partition attacks. Even with only $300$ malicious nodes in EGN, an attacker can isolate thousands of nodes, significantly hindering recovery. In contrast, such a small number of malicious nodes has minimal impact on every single-service P2P network. We propose solutions to improve EGN's node discovery efficiency and strengthen its resilience against attacks.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 05:47:35 +0000</pubDate>
</item>
<item>
<title>Reusable Dynamic Multi-Party Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/581</link>
<guid>https://eprint.iacr.org/2025/581</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密、多密钥同态加密、多 party 同态加密、可重用动态多 party 同态加密、通信复杂度

总结:
本文探讨了在多用户环境下利用同态加密技术保护隐私的方法。针对多密钥同态加密(MKHE)存在的空间和计算开销随着用户数 n 增大而线性增长的问题，以及多 party 同态加密(MPHE)中密文不可复用、动态加入受限的缺点，文章提出了一种新的“可重用动态多 party 同态加密”(Reusable Dynamic MPHE)方案。该方案允许秘密密钥持有者在计算前进行有限轮次的通信，从而将密文大小和评估复杂度从 $\mathcal O(n)$ 降低到 $\mathcal O(1)$，达到单密钥同态加密的水平。此外，新方案还具备与 MKHE 相当的功能效率，同时具有低通信复杂度和独立于用户数量的评估/空间复杂度优势。通过理论分析和实验证明了其在实际场景中的适用性。 <div>
Homomorphic Encryption (HE) is a promising primitive for evaluating arbitrary circuits while keeping the user's privacy. We investigate how to use HE in the multi-party setting where data is encrypted with several distinct keys. One may use the Multi-Key Homomorphic Encryption (MKHE) in this setting, but it has space/computation overhead of $\mathcal O(n)$ for the number of users $n$, which makes it impractical when $n$ grows large. On the contrary, Multi-Party Homomorphic Encryption (MPHE) is the other Homomorphic Encryption primitive in the multi-party setting, where the space/computation overhead is $\mathcal O(1)$; however, is limited in terms of ciphertext reusability and dynamicity, that ciphertexts are encrypted just for a group of parties and cannot be reused for other purposes, and that additional parties cannot join the computation dynamically. 

Contrary to MKHE, where the secret key owners engage only in the decryption phase, we consider a more relaxed situation where the secret key owners can communicate before the computation. In that case, we can reduce the size of a ciphertext and the evaluation complexity from $\mathcal O(n)$ to $\mathcal O(1)$ as in a single-key HE setting. We call this primitive as {\em Reusable Dynamic Multi-Party Homomorphic Encryption}, which is more suitable in real-world scenarios.

We show that 1) the procedures before the computation can be done in a very few rounds of communications, 2) the evaluation/space complexities are independent of the number of users, and 3) the functionalities are as efficient as MKHE, with asymptotic analysis and with implementation.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 05:53:40 +0000</pubDate>
</item>
<item>
<title>REGKYC: Supporting Privacy and Compliance Enforcement for KYC in Blockchains</title>
<link>https://eprint.iacr.org/2025/579</link>
<guid>https://eprint.iacr.org/2025/579</guid>
<content:encoded><![CDATA[
<div> 关键词: Know Your Customer (KYC), Anti-Money Laundering (AML), REGKYC, Attribute-Based Access Control (ABAC), Blockchain<br /><br />总结:<br />
REGKYC 是一种针对区块链环境提出的隐私保护型属性基访问控制（ABAC）框架，旨在平衡用户隐私与外部强制的KYC和反洗钱（AML）要求。该框架利用结构化的ABAC模型支持灵活的KYC属性验证和合规政策执行，对多方利益相关者具有益处。首先，它使得合法用户能够在满足合规要求的同时，保护其在链上的活动隐私；其次，赋予加密资产服务提供商（CASPs）根据业务需求定制合规策略的能力，以适应不断演变的监管规定；最后，通过授权匿名性的解除，提升了监管问责能力，可有效识别并追踪恶意行为者。本文期望这一工作能激发未来关于如何在区块链系统中协调用户隐私与监管合规的研究。 <div>
Know Your Customer (KYC) is a core component of the Anti-Money Laundering (AML) framework, designed to prevent illicit activities within financial systems. However, enforcing KYC and AML on blockchains remains challenging due to difficulties in establishing accountability and preserving user privacy. This study proposes REGKYC, a privacy-preserving Attribute-Based Access Control (ABAC) framework that balances user privacy with externally mandated KYC and AML requirements. REGKYC leverages a structured ABAC model to support the flexible verification of KYC attributes and the enforcement of compliance policies, providing benefits to multiple stakeholders. First, it enables legitimate users to meet compliance requirements while preserving the privacy of their on-chain activities. Second, it empowers Crypto-asset Service Providers (CASPs) to tailor compliance policies to operational needs, ensuring adaptability to evolving regulations. Finally, it enhances regulatory accountability by enabling authorized deanonymization of malicious actors. We hope this work inspires future research to harmonize user privacy and regulatory compliance in blockchain systems.
]]></content:encoded>
<pubDate>Sun, 30 Mar 2025 23:33:19 +0000</pubDate>
</item>
<item>
<title>Buffalo: A Practical Secure Aggregation Protocol for Asynchronous Federated Learning</title>
<link>https://eprint.iacr.org/2025/574</link>
<guid>https://eprint.iacr.org/2025/574</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习（FL）、同步FL、Buffered异步FL（BAsyncFL）、安全聚合（SA）、Buffalo

总结:
联邦学习中的同步训练方法因受慢速客户端影响导致效率降低，为此引入了Buffered异步FL（BAsyncFL）以消除同步瓶颈。然而，现有的安全聚合技术不适用于异步环境。针对这一问题，本文提出了首个适用于BAsyncFL的实用安全聚合协议——Buffalo。Buffalo利用格基加密解决大型ML模型的可扩展性挑战，并引入了助手角色协助服务器进行安全的客户端更新聚合。同时，为了防范恶意篡改服务器，Buffalo允许客户端验证其本地更新是否已正确整合到全局模型中。通过对理论分析和基准数据集上的实际实验进行全面评估，结果显示Buffalo是在BAsyncFL环境中高效且可伸缩的隐私保护解决方案。 <div>
Federated Learning (FL) has become a crucial framework for collaboratively training Machine Learning (ML) models while ensuring data privacy. Traditional synchronous FL approaches, however, suffer from delays caused by slower clients (called stragglers), which hinder the overall training process.

Specifically, in a synchronous setting, model aggregation happens once all the intended clients have submitted their local updates to the server. To address these inefficiencies, Buffered Asynchronous FL (BAsyncFL) was introduced, allowing clients to update the global model as soon as they complete local training. In such a setting, the new global model is obtained once the buffer is full, thus removing synchronization bottlenecks. Despite these advantages, existing Secure Aggregation (SA) techniques—designed to protect client updates from inference attacks—rely on synchronized rounds, making them unsuitable for asynchronous settings.

In this paper, we present Buffalo, the first practical SA protocol tailored for BAsyncFL. Buffalo leverages lattice-based encryption to handle scalability challenges in large ML models and introduces a new role, the assistant, to support the server in securely aggregating client updates. To protect against an actively corrupted server, we enable clients to verify that their local updates have been correctly integrated into the global model. Our comprehensive evaluation—incorporating theoretical analysis and real-world experiments on benchmark datasets—demonstrates that Buffalo is an efficient and scalable privacy-preserving solution in BAsyncFL environments.
]]></content:encoded>
<pubDate>Sat, 29 Mar 2025 15:49:51 +0000</pubDate>
</item>
<item>
<title>Zinnia: An Expressive and Efficient Tensor-Oriented Zero-Knowledge Programming Framework</title>
<link>https://eprint.iacr.org/2025/572</link>
<guid>https://eprint.iacr.org/2025/572</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、Zinnia、编程框架、机器学习、数据科学

总结:
Zinnia 是一款针对零知识证明（ZKP）设计的高实用性、高表达性和高效能的编程框架，特别适用于张量计算。该框架旨在解决ZKP在机器学习和数据科学中应用困难的问题。Zinnia 提供了一种高级编程语言，使得开发者能够轻松编写ZKP程序，并通过创新的符号执行启发式方法从这些程序中生成算术电路。同时，它支持张量运算并具备丰富的编程结构、优化手段以及强大的静态类型系统，用于表达和优化复杂的逻辑。通过对涵盖25个真实世界编程任务及用户研究的评估，结果显示Zinnia 在实用性和表达性方面优于现有的解决方案（如DSL和zkVM，例如Halo2、SP1和RISC0），并且在开发时间上缩短了约2到3倍，代码长度减少了75%，电路尺寸缩小了19.3%，相较于zkVMs，证明时间最高提升了245倍，从而为各种领域中的实际ZKP应用铺平了道路。 <div>
Zero-knowledge proofs (ZKPs) are cryptographic protocols that enable a prover to convince a verifier of a statement's truth without revealing any details beyond its validity. Typically, the statement is encoded as an arithmetic circuit, and allows the prover to demonstrate that the circuit evaluates to true without revealing its inputs. Despite their potential to enhance privacy and security, ZKPs are difficult to write and optimize, limiting their adoption in machine learning and data science. To address these challenges, we introduce Zinnia, a zero-knowledge programming framework with high utility, expressiveness and efficiency for tensor-oriented computation. Zinnia provides a high-level programming language that enables developers to easily write ZKP programs, and it employs a novel symbolic execution-inspired approach to extracting semantics from these programs to generate arithmetic circuits. Zinnia supports tensor-oriented computations and provides a rich set of programming constructs, optimizations, and a powerful static type system for expressing and optimizing complex logic. We evaluate Zinnia across 25 real-world programming tasks and a user study, comparing it to existing solutions, including DSLs and zkVMs (Halo2, SP1, and RISC0). Our results demonstrate that Zinnia outperforms these baselines in utility, expressiveness, and efficiency, with a statistically significant reduction in development time, $2-3\times$ shorter code length, 19.3% smaller circuit size, and up to $245\times$ faster proving time compared to zkVMs, paving the way for practical ZKP applications in various domains.
]]></content:encoded>
<pubDate>Sat, 29 Mar 2025 12:06:05 +0000</pubDate>
</item>
<item>
<title>Solving Data Availability Limitations in Client-Side Validation with UTxO Binding</title>
<link>https://eprint.iacr.org/2025/569</link>
<guid>https://eprint.iacr.org/2025/569</guid>
<content:encoded><![CDATA[
<div> 关键词: 发行代币、比特币、客户端验证（CSV）、UTxO绑定、辅助区块链

总结:
文章提出了一个针对在比特币上发行代币问题的新框架——UTxO绑定。鉴于比特币原生功能有限以及存储挑战，当前采用的客户端验证（CSV）方法虽然实现了部分扩展但存在数据丢失和恶意数据扣留的风险。UTxO绑定方案创新性地将比特币的UTxO与辅助区块链上的UTxO安全绑定，利用后者提供数据存储和可编程性的同时，确保防止双重花费。文章通过形式化证明了该方案的安全性，并以Nervos CKB作为辅助区块链实现了这一设计。 <div>
Issuing tokens on Bitcoin remains a highly sought-after goal, driven by its market dominance and robust security. However, Bitcoin's limited on-chain storage and functionality pose significant challenges. Among the various approaches to token issuance on Bitcoin, client-side validation (CSV) has emerged as a prominent solution. CSV delegates data storage and functionalities beyond Bitcoin’s native capabilities to off-chain clients, while leveraging the blockchain to validate tokens and prevent double-spending. Nevertheless, these protocols require participants to maintain token ownership and transactional data, rendering them vulnerable to data loss and malicious data withholding. In this paper, we propose UTxO binding, a novel framework that achieves both robust data availability and enhanced functionality compared to existing CSV designs. This approach securely binds a Bitcoin UTxO, which prevents double-spending, to a UTxO on an auxiliary blockchain, providing data storage and programmability. We formally prove its security and implement our design using Nervos CKB as the auxiliary blockchain.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 13:05:29 +0000</pubDate>
</item>
<item>
<title>An Efficient SNARK for Field-Programmable and RAM Circuits</title>
<link>https://eprint.iacr.org/2024/507</link>
<guid>https://eprint.iacr.org/2024/507</guid>
<content:encoded><![CDATA[
<div> 关键词: SNARK、效率、隐私、预处理、可验证计算

总结:
本文提出了一个新的具有常量证明大小的SNARK方案，旨在解决频繁变换计算目标情况下，SNARK预处理数据重生产带来的挑战。该方案结合了Groth16协议的高效性（但不具备新问题的普适性）和PlonK协议的普适性（但预处理数据维度较大）。新SNARK在保持高效性和普适性的同时，显著降低了预处理数据的维度。此外，它还能无缝应用于可验证机器计算，所需的证明尺寸比其他相关工作小约四到十倍。 <div>
The advancement of succinct non-interactive argument of knowledge (SNARK) with constant proof size has significantly enhanced the efficiency and privacy of verifiable computation. Verifiable computation finds applications in distributed computing networks, particularly in scenarios where nodes cannot be generally trusted, such as blockchains. However, fully harnessing the efficiency of SNARK becomes challenging when the computing targets in the network change frequently, as the SNARK verification can involve some untrusted preprocess of the target, which is expected to be reproduced by other nodes. This problem can be addressed with two approaches: One relieves the reproduction overhead by reducing the dimensionality of preprocessing data; The other utilizes verifiable machine computation, which eliminates the dependency on preprocess at the cost of increased overhead to SNARK proving and verification. In this paper, we propose a new SNARK with constant proof size applicable to both approaches. The proposed SNARK combines the efficiency of Groth16 protocol, albeit lacking universality for new problems, and the universality of PlonK protocol, albeit with significantly larger preprocessing data dimensions. Consequently, we demonstrate that our proposed SNARK maintains the efficiency and the universality while significantly reducing the dimensionality of preprocessing data. Furthermore, our SNARK can be seamlessly applied to the verifiable machine computation, requiring a proof size smaller about four to ten times than other related works.
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 08:49:24 +0000</pubDate>
</item>
<item>
<title>ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification</title>
<link>https://eprint.iacr.org/2025/561</link>
<guid>https://eprint.iacr.org/2025/561</guid>
<content:encoded><![CDATA[
<div> 关键词: 威胁建模，测试计划生成，硬件安全验证，ThreatLens，LLM

总结:
<br />
针对当前硬件安全验证过程中依赖人工威胁建模和测试计划生成的问题，该文提出了一个基于LLM驱动的多Agent框架——ThreatLens。ThreatLens利用检索增强生成（RAG）技术提取相关安全知识，运用LLM进行威胁评估，并结合用户交互反馈以确保生成实际可行的测试计划。通过自动化这些流程，该框架降低了手动验证工作量，提高了覆盖面，并确保了安全验证方法的结构化和适应性。在NEORV32 SoC上的评估结果显示，ThreatLens能够通过结构化的测试计划实现硬件安全验证的自动化，并在现实场景中验证了其有效性。 <div>
Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 21:25:06 +0000</pubDate>
</item>
<item>
<title>Public Key Accumulators for Revocation of Non-Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/549</link>
<guid>https://eprint.iacr.org/2025/549</guid>
<content:encoded><![CDATA[
<div> 关键词：数字身份钱包、加密积累器、撤销机制、零知识证明、计算与通信成本

总结:
本文关注于分析加密积累器作为数字身份钱包凭证撤销方案的应用。文中介绍了几种主流的公钥积累器，并探讨了如何结合零知识证明实现非匿名凭证的撤销。同时，通过对计算和通信成本进行理论与实验评估，结果表明这些方法在证书撤销场景中的性能可与现有方案相媲美。<br /><br /> <div>
Digital identity wallets allow citizens to prove who they are and manage digital documents, called credentials, such as mobile driving licenses or passports. As with physical documents, secure and privacy-preserving management of the credential lifecycle is crucial: a credential can change its status from issued to valid, revoked or expired. In this paper, we focus on the analysis of cryptographic accumulators as a revocation scheme for digital identity wallet credentials. We describe the most well-established public key accumulators, and how zero-knowledge proofs can be used with accumulators for revocation of non-anonymous credentials. In addition, we assess the computational and communication costs analytically and experimentally. Our results show that they are comparable with existing schemes used in the context of certificate revocation.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 11:20:04 +0000</pubDate>
</item>
<item>
<title>Aegis: Scalable Privacy-preserving CBDC Framework with Dynamic   Proof of Liabilities</title>
<link>https://eprint.iacr.org/2025/539</link>
<guid>https://eprint.iacr.org/2025/539</guid>
<content:encoded><![CDATA[
<div> 关键词: Central Bank Digital Currencies (CBDC), hybrid model, zk-SNARKs, transaction batching, dynamic Proof of Liabilities

总结:
本文探讨了中央银行数字货币（CBDC）的设计挑战，重点关注隐私保护和可扩展性问题。针对公共区块链透明度带来的隐私顾虑，文章提出了一个基于zk-SNARKs的新颖智能合约框架——Aegis。该框架采用交易批处理技术以提升系统可扩展性，并定义了一种新型动态Proof of Liabilities机制，能应对用户负债实时变动的问题。文章对系统的安全性进行了形式化定义与严格证明，并通过实例化框架进行性能评估，结果显示：对于包含512笔交易的完整流程，包括生成证明的时间大约为2.8秒，每位用户的gas消耗量为74,726。 <div>
Blockchain advancements, currency digitalization, and declining cash usage have fueled global interest in Central Bank Digital Currencies (CBDCs). The BIS states that the hybrid model, where central banks authorize intermediaries to manage distribution, is more suitable than the direct model. However, designing a CBDC for practical implementation requires careful consideration. First, the public blockchain raises privacy concerns due to transparency. While zk-SNARKs can be a solution, they can introduce significant proof generation overhead for large-scale transactions. Second, intermediaries that provide user-facing services on behalf of the central bank commonly performs Proof of Liabilities on customers' static liabilities. However, in real-world scenarios where user liabilities can arbitrarily increase or decrease, the static nature poses such as window attacks. 

In this paper, we propose a new smart contract-based privacy-preserving CBDC framework based on zk-SNARKs, called $\textbf{Aegis}$. our framework introduces a transaction batching technique to enhance scalability and  defines a new dynamic PoL which is near-real time. We formally define the security models for our system and provide rigorous security proofs to demonstrate its robustness. To evaluate the system’s performance, we instantiate our proposed framework and measure its efficiency. The result indicates that, the end-to-end process, including proof generation for 512 transactions, takes approximately 2.8 seconds, with a gas consumption of 74,726 per user.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 04:37:41 +0000</pubDate>
</item>
<item>
<title>Efficient Proofs of Possession for Legacy Signatures</title>
<link>https://eprint.iacr.org/2025/538</link>
<guid>https://eprint.iacr.org/2025/538</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字签名、证明占有、zkSNARK、RSA、ECDSA、Ed25519、效率提升、Dorian、R1CS、椭圆曲线

总结:
本文研究了如何将证明占有的概念应用于广泛部署的传统数字签名方案（如RSA、ECDSA和Ed25519）中，以提高安全性、隐私性和匿名性。为实现这一目标，文章提出了新的策略：将签名验证算法编码为R1CS，并使用zkSNARK来证明解决方案的知识。为了提高效率，研究者设计并分析了一种支持随机计算的新zkSNARK——Dorian，以及用于编码哈希、椭圆曲线操作和模算术的新技术。他们还提出一种新方法，允许在R1CS外部执行ECDSA和Ed25519验证中最耗时的部分，并生成了一种新型椭圆曲线，可以非常高效地表示Ed25519曲线操作。这些技术使R1CS大小缩小高达200倍，证明生成时间减少3至22倍。例如，现在可以在三秒内生成一个针对两千字节TLS证书大小的消息的RSA签名的240字节的占有证明。 <div>
Digital signatures underpin identity, authenticity, and trust in modern computer systems. Cryptography research has shown that it is possible to prove possession of a valid message and signature for some public key, without revealing the message or signature. These proofs of possession work only for specially-designed signature schemes. Though these proofs of possession have many useful applications to improving security, privacy, and anonymity, they are not currently usable for widely deployed, legacy signature schemes such as RSA, ECDSA, and Ed25519. Unlocking practical proofs of possession for these legacy signature schemes requires closing a huge efficiency gap.

This work brings proofs of possession for legacy signature schemes very close to practicality. Our design strategy is to encode the signature's verification algorithm as a rank-one constraint system (R1CS), then use a zkSNARK to prove knowledge of a solution. To do this efficiently we (1) design and analyze a new zkSNARK called Dorian that supports randomized computations, (2) introduce several new techniques for encoding hashes, elliptic curve operations, and modular arithmetic,  (3) give a new approach that allows performing the most expensive parts of ECDSA and Ed25519 verifications outside R1CS, and (4) generate a novel elliptic curve that allows expressing Ed25519 curve operations very efficiently. Our techniques reduce R1CS sizes by up to 200$\times$ and prover times by 3-22$\times$. 

We can generate a 240-byte proof of possession of an RSA signature over a message the size of a typical TLS certificate (two kilobytes) in only three seconds.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 01:23:44 +0000</pubDate>
</item>
<item>
<title>Large Language Models for Blockchain Security: A Systematic Literature Review</title>
<link>https://eprint.iacr.org/2024/477</link>
<guid>https://eprint.iacr.org/2024/477</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、区块链安全 (BS)、文献回顾、智能合约审计、交易异常检测

总结:
本文针对大型语言模型在区块链安全领域的应用进行了一次全面的文献回顾，旨在深入理解和分析LLMs如何增强区块链系统的安全性。研究探讨了LLMs在智能合约审计、交易异常检测、漏洞修复、智能合约程序分析以及作为加密货币社区参与者等方面的应用。同时，文章也评估了利用LLMs提升区块链安全性所面临的挑战与限制，包括可扩展性、隐私问题和伦理考量等。通过这篇详尽的综述，为研究人员、实践者及政策制定者提供了关于LLM应用于区块链安全的机会与潜在风险的宝贵见解。 <div>
Large Language Models (LLMs) have emerged as powerful tools across various domains within cyber security. Notably,
recent studies are increasingly exploring LLMs applied to the context of blockchain security (BS).
However, there remains a gap in a comprehensive understanding regarding the full scope of applications, impacts, and potential constraints of LLMs on blockchain security.
To fill this gap, we undertake a literature review focusing on the studies that apply LLMs in blockchain security (LLM4BS).

Our study aims to comprehensively analyze and understand existing research, and elucidate how LLMs contribute to enhancing the security of blockchain systems.
Through a thorough examination of existing literature, we delve into the integration of LLMs into various aspects of blockchain security. 
We explore the mechanisms through which LLMs can bolster blockchain security, including their applications in smart contract auditing, transaction anomaly detection, vulnerability repair, program analysis of smart contracts, and serving as participants in the cryptocurrency community.
Furthermore, we assess the challenges and limitations associated with leveraging LLMs for enhancing blockchain security, considering factors such as scalability, privacy concerns, and ethical concerns. 
Our thorough review sheds light on the opportunities and potential risks of tasks on LLM4BS, providing valuable insights for researchers, practitioners, and policymakers alike.
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 09:22:49 +0000</pubDate>
</item>
<item>
<title>Force: Highly Efficient Four-Party Privacy-Preserving Machine Learning on GPU</title>
<link>https://eprint.iacr.org/2023/493</link>
<guid>https://eprint.iacr.org/2023/493</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算、效率提升、三党计算、四党计算、隐私保护机器学习<br /><br />总结:
本文提出了一种名为Force的高效四党计算(4PC)系统，用于实现隐私保护机器学习(PPML)。研究发现，通过引入新的共享类型X-share以及在半诚实多数设置下的MPC协议，Force能够使每个参与方享有最少的本地计算量、最小的显存消耗和最低的数据交换。相较于现有的最优GPU基半诚实安全系统（如Piranha、SecureML、Falcon、FantasticFour、CryptGPU和CrypTen），实验结果显示，Force能够在保持安全性的同时，将PPML性能提高2到38倍，从而证实了资源线性增长可以带来超过线性的性能提升。 <div>
Tremendous efforts have been made to improve the efficiency of secure Multi-Party Computation (MPC), which allows n ≥ 2 parties to jointly evaluate a target function without leaking their own private inputs. It has been confirmed by previous research that Three-Party Computation (3PC) and outsourcing computations to GPUs can lead to huge performance improvement of MPC in computationally intensive tasks such as Privacy-Preserving Machine Learning (PPML). A natural question to ask is whether super-linear performance gain is possible for a linear increase in resources. In this paper, we give an affirmative answer to this question. We propose Force, an extremely efficient Four-Party Computation (4PC) system for PPML. To the best of our knowledge, each party in Force enjoys the least number of local computations, smallest graphic memory consumption and lowest data exchanges between parties. This is achieved by introducing a new sharing type X-share along with MPC protocols in privacy-preserving training and inference that are semi-honest secure in the honest-majority setting. By comparing the results with state-of-the-art research, we showcase that Force is sound and extremely efficient, as it can improve the PPML performance by a factor of 2 to 38 compared with other latest GPU-based semi-honest secure systems, such as Piranha (including SecureML, Falcon, FantasticFour), CryptGPU and CrypTen.
]]></content:encoded>
<pubDate>Tue, 04 Apr 2023 19:37:15 +0000</pubDate>
</item>
<item>
<title>VeRange: Verification-efficient Zero-knowledge Range Arguments with Transparent Setup for Blockchain Applications and More</title>
<link>https://eprint.iacr.org/2025/528</link>
<guid>https://eprint.iacr.org/2025/528</guid>
<content:encoded><![CDATA[
<div> 关键词: Zero-knowledge range arguments, 透明设置, 区块链, 计算开销, VeRange

总结:
本文介绍了VeRange，这是一种新的零知识范围论证方案，应用于离散对数环境中。VeRange优化了验证效率，仅需$c\sqrt{N/\log N}$次群指数运算进行验证，其中$N$为表示范围的位数，$c$是一个小常数，使其在区块链部署中具有高度的实用性和较低的Gas成本。此外，VeRange还具备聚合性，允许证明者在一个论证中同时证明$T$个范围论证，只需$O(\sqrt{TN/\log(TN)})+T$次群指数运算进行验证。论文将VeRange实现在以太坊上并测量了其实际Gas成本，结果显示VeRange在实践中拥有基于离散对数范围论证中的最快验证运行时间和最低Gas成本。<br /><br /> <div>
Zero-knowledge range arguments are a fundamental cryptographic primitive that allows a prover to convince a verifier of the knowledge of a secret value lying within a predefined range. They have been utilized in diverse applications, such as confidential transactions, proofs of solvency and anonymous credentials. Range arguments with a transparent setup dispense with any trusted setup to eliminate security backdoor and enhance transparency. They are increasingly deployed in diverse decentralized applications on blockchains. One of the major concerns of practical deployment of range arguments on blockchains is the incurred gas cost and high computational overhead associated with blockchain miners. Hence, it is crucial to optimize the verification efficiency in range arguments to alleviate the deployment cost on blockchains and other decentralized platforms. In this paper, we present VeRange with several new zero-knowledge range arguments in the discrete logarithm setting, requiring only $c \sqrt{N/\log N}$ group exponentiations for verification, where $N$ is the number of bits to represent a range and $c$ is a small constant, making them concretely efficient for blockchain deployment with a very low gas cost. Furthermore, VeRange is aggregable, allowing a prover to simultaneously prove $T$ range arguments in a single argument, requiring only $O(\sqrt{TN/\log (TN)}) + T$ group exponentiations for verification. We deployed {\tt VeRange} on Ethereum and measured the empirical gas cost, achieving the fastest verification runtime and the lowest gas cost among the discrete-logarithm-based range arguments in practice.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 02:03:24 +0000</pubDate>
</item>
<item>
<title>SoK: Fully-homomorphic encryption in smart contracts</title>
<link>https://eprint.iacr.org/2025/527</link>
<guid>https://eprint.iacr.org/2025/527</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、智能合约、隐私挑战、全同态加密(FHE)、隐私增强技术(PET)

<br /><br />总结:
本文探讨了区块链技术和智能合约如何通过实现去中心化和无信任价值交换而带来革命性变化，但同时也指出了其透明度和不可变性带来的显著隐私问题。特别是在智能合约为所有网络参与者公开合同细节的情况下，可能导致敏感信息泄露。为解决这一问题，文章强调了在智能合约中引入隐私保护机制的重要性。作者提出了只有装备了隐私机制的智能合约才能实现的高级经济学应用场景，并具体分析了全同态加密（FHE）作为隐私增强技术（PET）在公共区块链上的智能合约中的应用潜力，能够实现在保持自动化、去中心化和安全性的同时保护敏感信息。接着，文章对现有的FHE解决方案进行了全面梳理，并结合所考虑的应用场景进行评估，同时识别出了开放性问题，并对未来的研究方向提出建议，以进一步提升区块链智能合约中的隐私保护水平。 <div>
Blockchain technology and smart contracts have revolutionized digital transactions by enabling trustless and decentralized exchanges of value. However, the inherent transparency and immutability of blockchains pose significant privacy challenges. On-chain data, while pseudonymous, is publicly visible and permanently recorded, potentially leading to the inadvertent disclosure of sensitive information. This issue is particularly pronounced in smart contract applications, where contract details are accessible to all network participants, risking the exposure of identities and transactional details.

To address these privacy concerns, there is a pressing need for privacy-preserving mechanisms in smart contracts. To showcase this need even further, in our paper we bring forward advanced use-cases in economics which only smart contracts equipped with privacy mechanisms can realize, and show how  fully-homomorphic encryption (FHE) as a privacy enhancing technology (PET) in smart contracts, operating on a public blockchain, can make possible the implementation of these use-cases. Furthermore, we perform a comprehensive systematization of FHE-based approaches in smart contracts, examining their potential to maintain the confidentiality of sensitive information while retaining the benefits of smart contracts, such as automation, decentralization, and security. After we evaluate these existing FHE solutions in the context of the use-cases we consider, we  identify open problems, and suggest future research directions to enhance privacy in blockchain smart contracts.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 01:27:39 +0000</pubDate>
</item>
<item>
<title>Mitigating MEV via Multiparty Delay Encryption</title>
<link>https://eprint.iacr.org/2023/1612</link>
<guid>https://eprint.iacr.org/2023/1612</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、最大可提取价值(MEV)、交易审查、多方延迟加密(MDE)、时间锁谜题

<br /><br />总结:

本文针对以太坊网络中存在的最大可提取价值(MEV)问题以及交易审查现象，提出了一个创新的 mempool 加密方案。该方案通过分离交易包含和执行过程，并在执行前保持交易加密，旨在缓解 MEV 和审查问题。文章中定义了多方延迟加密(MDE)的概念，并基于时间锁谜题构建了一个实用的MDE方案。此方法在可扩展性（交易解密方面）、效率（最小化通信和存储开销）和安全性（仅需最小的信任假设）方面表现出色。为了证明MDE方案的有效性，研究者已在本地以太坊测试网上实现了该方案，并证明了其在每个以太坊槽位只有一个诚实的见证聚合器的情况下仍能确保安全。 <div>
Ethereum is a decentralized and permissionless network offering several attractive features. However, block proposers in Ethereum can exploit the order of transactions to extract value. This phenomenon, known as $maximal$ $extractable$ $value$ (MEV), not only disrupts the optimal functioning of different protocols but also undermines the stability of the underlying consensus mechanism. Furthermore, current block production architecture allows transaction censorship that compromises credible neutrality, a fundamental principle of Ethereum’s design philosophy.
In this work, we present a novel $mempool$ $encryption$ scheme to alleviate the censorship and MEV problem by separating transaction inclusion and execution, keeping transactions encrypted before execution. We formulate the notion of $multiparty$ $delay$ $encryption$ (MDE) and construct a practical MDE scheme based on time-lock puzzles. Our method excels in scalability (in terms of transaction decryption), efficiency (minimizing communication and storage overhead), and security (with minimal trust assumptions). 
To demonstrate the effectiveness of our MDE scheme, we have implemented it on a local Ethereum testnet and prove its security under the presence of only one honest attestation aggregator per Ethereum slot.
]]></content:encoded>
<pubDate>Tue, 17 Oct 2023 22:38:35 +0000</pubDate>
</item>
<item>
<title>Revisiting attacker's knowledge in inference attacks against Searchable Symmetric Encryption</title>
<link>https://eprint.iacr.org/2023/1883</link>
<guid>https://eprint.iacr.org/2023/1883</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密搜索方案、安全漏洞、泄漏滥用攻击、数据相似性、统计工具

总结:
本文针对加密搜索方案中的安全问题以及数据相似性的模糊假设进行了研究。首先，文章提出了基于统计估计器的数学模型，用于分析攻击者知识和相似性的概念。其次，开发了统计工具来量化相似性对攻击准确性的影响。作者将这些工具应用于三个现有的攻击场景中，探究相似性是否为影响攻击准确性的唯一因素。接着，文章指出限制最大索引尺寸可以增加攻击者满足“类似数据”假设的难度，并提出一种统计方法，用于根据给定攻击和数据集估算合适的最大索引尺寸。具体到对Enron数据集的最佳已知攻击而言，通过设置最大索引尺寸为200，可保证（以高概率）攻击的准确性低于5%。 <div>
Encrypted search schemes have been proposed to address growing privacy concerns. However, several leakage-abuse attacks have highlighted some security vulnerabilities. Recent attacks assumed an attacker's knowledge containing data "similar" to the indexed data. However, this vague assumption is barely discussed in literature: how likely is it for an attacker to obtain a "similar enough" data?

Our paper provides novel statistical tools usable on any attack in this setting to analyze its sensitivity to data similarity. First, we introduce a mathematical model based on statistical estimators to analytically understand the attackers' knowledge and the notion of similarity. Second, we conceive statistical tools to model the influence of the similarity on the attack accuracy. We apply our tools on three existing attacks to answer questions such as: is similarity the only factor influencing accuracy of a given attack? Third, we show that the enforcement of a maximum index size can make the ``similar-data'' assumption harder to satisfy. In particular, we propose a statistical method to estimate an appropriate maximum size for a given attack and dataset. For the best known attack on the Enron dataset, a maximum index size of 200 guarantees (with high probability) the attack accuracy to be below 5%.
]]></content:encoded>
<pubDate>Thu, 07 Dec 2023 10:15:59 +0000</pubDate>
</item>
<item>
<title>AI Agents in Cryptoland: Practical Attacks and No Silver Bullet</title>
<link>https://eprint.iacr.org/2025/526</link>
<guid>https://eprint.iacr.org/2025/526</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、Web3生态系统、安全风险、上下文操纵、防御措施

<br /><br />总结:
本文探讨了AI代理与区块链金融生态系统的整合所带来的安全隐患，尤其是在遭遇现实世界中的对抗性威胁时。提出了“上下文操纵”这一全面攻击向量的概念，它利用未受保护的输入通道、内存模块和外部数据源等上下文表面进行攻击。通过实证分析用于自动化的Web3操作的去中心化AI代理框架ElizaOS，展示了恶意指令如何注入到提示或历史交互记录中，导致意外的资产转移和协议违规，可能造成严重的经济损失。研究发现，基于提示的防御措施并不充分，因为恶意输入可破坏代理存储的上下文，进而引发跨交互和平台的级联漏洞。因此，文章强调了迫切需要开发既安全又具备财务责任意识的AI代理。 <div>
The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness, yet also introduces underexplored security risks, as these agents dynamically interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. Through empirical analysis of ElizaOS, a decentralized AI agent framework for automated Web3 operations, we demonstrate how adversaries can manipulate context by injecting malicious instructions into prompts or historical interaction records, leading to unintended asset transfers and protocol violations which could be financially devastating.  Our findings indicate that prompt-based defenses are insufficient, as malicious inputs can corrupt an agent's stored context, creating cascading vulnerabilities across interactions and platforms. This research highlights the urgent need to develop AI agents that are both secure and fiduciarily responsible.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 15:55:10 +0000</pubDate>
</item>
<item>
<title>Ring Referral: Efficient Publicly Verifiable Ad hoc Credential Scheme with Issuer and Strong User Anonymity for Decentralized Identity and More</title>
<link>https://eprint.iacr.org/2025/524</link>
<guid>https://eprint.iacr.org/2025/524</guid>
<content:encoded><![CDATA[
<div> 关键词：环签名、第三方签署、用户匿名性、透明设置、多消息验证效率

总结:<br />
本文提出了一种环引荐方案，该方案允许用户公开证明自己知道由一组临时授权发行者之一对私密消息签署的有效签名，同时不泄露签署的发行者身份。环引荐是对传统环签名称的自然扩展，支持用户从第三方签署者获取签名。此方案适用于多种应用场景，如隐藏证书的去中心化身份、增强隐私的联合认证、匿名背书和隐私保护的推荐营销。与先前的发行者隐藏凭证方案相比，环引荐方案具备更多独特特性：(1) 对临时环内的签名进行公共可验证性；(2) 在发行者和验证者合谋追踪用户的情况下提供强大的用户匿名性；(3) 采用透明设置；(4) 消息隐藏；(5) 实现了高效的多消息对数级验证效率；(6) 支持需要多个共同签署发行者的阈值方案。最后，文中实现了环引荐方案并进行了广泛的实证评估。 <div>
In this paper, we present a ring referral scheme, by which a user can publicly prove her knowledge of a valid signature for a private message that is signed by one of an ad hoc set of authorized issuers, without revealing the signing issuer. Ring referral is a natural extension to traditional ring signature by allowing a prover to obtain a signature from a third-party signer. Our scheme is useful for diverse applications, such as certificate-hiding decentralized identity, privacy-enhancing federated authentication, anonymous endorsement and privacy -preserving referral marketing. In contrast with prior issuer-hiding credential schemes, our ring referral scheme supports more distinguishing features, such as (1) public verifiability over an ad hoc ring, (2) strong user anonymity against collusion among the issuers and verifier to track a user, (3) transparent setup,  (4) message hiding, (5) efficient multi-message logarithmic verifiability, (6) threshold scheme for requiring multiple co-signing issuers. Finally, we implemented our ring referral scheme with extensive empirical evaluation
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 06:10:58 +0000</pubDate>
</item>
<item>
<title>New Techniques for Analyzing Fully Secure Protocols: A Case Study of Solitary Output Secure Computation</title>
<link>https://eprint.iacr.org/2025/522</link>
<guid>https://eprint.iacr.org/2025/522</guid>
<content:encoded><![CDATA[
<div> 关键词: 孤立输出安全计算、完全安全性、函数计算、三党计算、特殊轮协议

<br /><br />总结:
本文关注的是孤立输出安全计算的研究，这是一种允许互不信任的各方在保证特定一方获取输出的同时，计算其输入的功能性方法。该领域的研究要求满足正确性、隐私性、输入独立性和确保输出交付等全面的安全属性。Halevi等人在[TCC 2019]中对该领域进行了初步而深入的研究，但未完全描述可以实现完全安全计算的功能集合。Alon等人在[EUROCRYPT 2024]中探讨了三党场景下，其中输出接收方无输入的全部布尔功能的完全安全计算，并发现它与公平性的概念存在潜在关联。文章继续这一研究方向，着眼于所有党派均持有私有输入的三党孤立输出布尔功能集。主要贡献在于定义并分析了一类“特殊轮”协议家族，这扩展了先前提出的协议集合。通过这些技术，我们能识别哪些特殊轮协议能够安全地计算给定功能（如果存在）。值得注意的是，这项分析还可应用于存在公平性问题的两党设置。因此，作者认为，这些技术可能对其他场景的理解和应用产生积极影响，加深我们对于不同设置之间联系的认识。 <div>
Solitary output secure computation allows a set of mutually distrustful parties to compute a function of their inputs such that only a designated party obtains the output. Such computations should satisfy various security properties such as correctness, privacy, independence of inputs, and even guaranteed output delivery. We are interested in full security, which captures all of these properties. Solitary output secure computation has been the study of many papers in recent years, as it captures many real-world scenarios.

A systematic study of fully secure solitary output computation was initiated by Halevi et al. [TCC 2019]. They showed several positive and negative results, however, they did not characterize what functions can be computed with full security. Alon et al. [EUROCRYPT 2024] considered the special, yet important case, of three parties with Boolean output, where the output-receiving party has no input. They completely characterized the set of such functionalities that can be computed with full security. Interestingly, they also showed a possible connection with the seemingly unrelated notion of fairness, where either all parties obtain the output or none of them do.

We continue this line of investigation and study the set of three-party solitary output Boolean functionalities where all parties hold private inputs. Our main contribution is defining and analyzing a family of ``special-round'' protocols, which generalizes the set of previously proposed protocols. Our techniques allow us to identify which special-round protocols securely compute a given functionality (if such exists). Interestingly, our analysis can also be applied in the two-party setting (where fairness is an issue). Thus, we believe that our techniques may prove useful in additional settings and deepen our understanding of the connections between the various settings.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 21:21:35 +0000</pubDate>
</item>
<item>
<title>Secret-Sharing Schemes for General Access Structures: An Introduction</title>
<link>https://eprint.iacr.org/2025/518</link>
<guid>https://eprint.iacr.org/2025/518</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密共享方案、访问结构、阈值秘密共享方案、信息论安全性、理想秘密共享方案

总结:<br />
本文详细介绍了秘密共享方案的关键内容。首先讨论了最实用的阈值秘密共享方案，它允许大小至少为某个阈值𝑡的集合可以恢复秘密。接下来，讲述了针对一般访问结构的有效构造方法，如利用单调公式和单调span程序构建线性秘密共享方案，并给出了对于任意𝑛方访问结构具有常数𝑐<1的2𝑐𝑛份额大小的简单构造。此外，文中通过展示如何使用秘密共享方案构建安全多方计算协议以强调其重要性。然而，现有的秘密共享方案主要问题在于份额大小过大，与数量成指数关系。文章提及了已知的关于份额大小的下界以及线性秘密共享方案上的指数下界。接着研究了理想的秘密共享方案，其中每个参与者的份额大小与秘密本身相同，这是效率最高的秘密共享方案，通过matroid对具备理想方案的访问结构进行了刻画。最后讨论了计算型秘密共享方案，即仅对抗多项式时间敌手安全的方案，展示了针对单调和非单调电路的此类构造，这些构造比具有信息论安全性的最佳已知方案更为高效。 <div>
A secret-sharing scheme is a method by which a dealer distributes shares to parties such that only authorized subsets of parties can reconstruct the secret. Secret-sharing schemes are an important tool in cryptography and they are used as a building block in many secure protocols, e.g., secure multiparty computation protocols for arbitrary functionalities, Byzantine agreement, threshold cryptography, access control, attribute-based encryption, and weighted cryptography (e.g., stake-based blockchains). The collection of authorized sets that should be able to reconstruct the secret is called an access structure. The main goal in secret sharing is to minimize the share size in a scheme realizing an access structure. In most of this monograph, we will consider secret-sharing schemes with information-theoretic security, i.e., schemes in which unauthorized sets cannot deduce any information on the secret even when the set has unbounded computational power. Although research on secret-sharing schemes has been conducted for nearly 40 years, we still do not know what the optimal share size required to realize an arbitrary 𝑛-party access structure is; there is an exponential gap between the best known upper bounds and the best known lower bounds on the share size.

In this monograph, we review the most important topics on secret sharing. We start by discussing threshold secret-sharing schemes in which the authorized sets are all sets whose size is at least some threshold 𝑡; these are the most useful secret-sharing schemes. We then describe efficient constructions of secret-sharing schemes for general access structures; in particular, we describe constructions of linear secret-sharing schemes from monotone formulas and monotone span programs and provide a simple construction for arbitrary 𝑛-party access structures with share size 2𝑐𝑛 for some constant 𝑐 < 1. To demonstrate the importance of secret-sharing schemes, we show how they are used to construct secure multi-party computation protocols for arbitrary functions. We next discuss the main problem with known secret-sharing schemes – the large share size, which is exponential in the number of parties. We present the known lower bounds on the share size. These lower bounds are fairly weak, and there is a big gap between the lower and upper bounds. For linear secret-sharing schemes, which are a class of schemes based on linear algebra that contains most known schemes, exponential lower bounds on the share size are known. We then turn to study ideal secret-sharing schemes in which the share size of each party is the same as the size of the secret; these schemes are the most efficient secret-sharing schemes. We describe a characterization of the access structures that have ideal schemes via matroids. Finally, we discuss computational secret-sharing schemes, i.e., secret-sharing schemes that are secure only against polynomial-time adversaries. We show computational schemes for monotone and non-monotone circuits; these constructions are more efficient than the best known schemes with information-theoretic security.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 14:26:28 +0000</pubDate>
</item>
<item>
<title>Compressed Sigma Protocols: New Model and Aggregation Techniques</title>
<link>https://eprint.iacr.org/2025/515</link>
<guid>https://eprint.iacr.org/2025/515</guid>
<content:encoded><![CDATA[
<div> 关键词: Sigma协议、压缩模型、非线性约束、双重折叠承诺、论证知识

总结:
本文提出了一种新的压缩$\Sigma$-协议模型，该模型有效地解决了原有模型在处理复杂关系时表达力不足的问题，特别关注了涉及非线性约束的关系。新模型的核心在于定义了双重折叠承诺以及提出的论证知识，这既扩展了关系表示的范围，又为之前的模型中的压缩和摊销过程提供了更一般的框架，并为进一步讨论证明大小优化的一般聚合技术奠定了基础。为了验证新模型的实用性和灵活性，文中通过实例展示了几个现有的协议可以使用此模型进行实例化，并指出了在如二进制证明和$k$-out-of-$n$证明等传统上被认为是“不太紧凑”的应用中，我们的通用模型能带来增强效果。因此，这种新型模型为密码学应用中的$\Sigma$-协议提供了一个更为高效和表达能力强的替代选择，为更广泛的适用性和优化开辟了道路。<br /><br /> <div>
Sigma protocols ($\Sigma$-protocols) provide a foundational paradigm for constructing secure algorithms in privacy-preserving applications. To enhance efficiency, several extended models [BG18], [BBB+18], [AC20] incorporating various optimization techniques have been proposed as ``replacements'' for the original $\Sigma$-protocol. However, these models often lack the expressiveness needed to handle complex relations and hinder designers from applying appropriate instantiation and optimization strategies.

In this paper, we introduce a novel compressed $\Sigma$-protocol model that effectively addresses these limitations by providing concrete constructions for relations involving non-linear constraints. Our approach is sufficiently expressive to encompass a wide range of relations. Central to our model is the definition of doubly folded commitments, which, along with a proposed Argument of Knowledge, generalizes the compression and amortization processes found in previous models. Despite the ability to express more relations, this innovation also provides a foundation to discuss a general aggregation technique, optimizing the proof size of instantiated schemes. 

To demonstrate the above statements, we provide a brief review of several existing protocols that can be instantiated using our model to demonstrate the versatility of our construction. We also present use cases where our generalized model enhances applications traditionally considered ``less compact'', such as binary proofs [BCC+15] and $k$-out-of-$n$ proofs [ACF21]. In conclusion, our new model offers a more efficient and expressive alternative to the current use of $\Sigma$-protocols, paving the way for broader applicability and optimization in cryptographic applications.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 11:22:55 +0000</pubDate>
</item>
<item>
<title>Server-Aided Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/513</link>
<guid>https://eprint.iacr.org/2025/513</guid>
<content:encoded><![CDATA[
<div> 关键词：server-aided anonymous credentials (SAACs)，elliptic curves，formal security definitions，proofs，BBS#，keyed-verification ACs (KVACs)，oblivious issuance protocols，statistical anonymity，unforgeability，Gap q-SDH，computational anonymity，DDH。

总结:<br />
本文提出了服务器辅助匿名凭证（SAACs）的概念，并阐述了其在基于配对无关椭圆曲线的轻量级“公共可验证和多用途”AC实现中的重要性。文章指出，BBS#这一欧盟数字身份钱包候选方案大致符合SAAC模型，但缺乏正式的安全定义和证明。为了解决这一问题，本文提供了SAACs的严格安全定义，并展示了如何从KVACs以及特殊类型的零知识证明无意识发行协议实现SAACs。文中给出了两个构造实例：一个在Gap q-SDH假设下实现了统计匿名性和不可伪造性；另一个在DDH假设下实现了计算匿名性和不可伪造性。 <div>
This paper formalizes the notion of server-aided anonymous credentials (SAACs), a new model for anonymous credentials (ACs) where, in the process of showing a credential, the holder is helped by additional auxiliary information generated in an earlier (anonymous) interaction with the issuer. This model enables lightweight instantiations of 'publicly verifiable and multi-use' ACs from pairing-free elliptic curves, which is important for compliance with existing national standards. A recent candidate for the EU Digital Identity Wallet, BBS#, roughly adheres to the SAAC model we have developed; however, it lacks formal security definitions and proofs.

In this paper, we provide rigorous definitions of security for SAACs, and show how to realize SAACs from the weaker notion of keyed-verification ACs (KVACs) and special types of oblivious issuance protocols for zero-knowledge proofs. We instantiate this paradigm to obtain two constructions: one achieves statistical anonymity with unforgeability under the Gap $q$-SDH assumption, and the other achieves computational anonymity and unforgeability under the DDH assumption.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 08:49:06 +0000</pubDate>
</item>
<item>
<title>VeriSSO: A Privacy-Preserving Legacy-Compatible Single Sign-On Protocol Using Verifiable Credentials</title>
<link>https://eprint.iacr.org/2025/511</link>
<guid>https://eprint.iacr.org/2025/511</guid>
<content:encoded><![CDATA[
<div> 关键词：Single Sign-On (SSO), 隐私挑战, Verifiable Credentials (VC), VeriSSO, 安全性与效率

总结:
<br />
本文提出了一个名为VeriSSO的新型单点登录（SSO）协议，旨在解决传统SSO机制中的隐私问题和单点故障风险。VeriSSO利用可验证凭证（VC）技术，通过一个独立的身份验证服务器委员会来管理服务提供商（RP）和用户认证，实现了用户匿名认证与RP认证的同时进行，保持了用户unlinkability并支持RP使用现有的授权代码流（ACF）验证流程。此外，VeriSSO设计还支持合法的去匿名化，以确保在用户匿名状态下仍能追究其不当行为的责任。实验结果显示，VeriSSO具有高效性和实用性，完成身份验证过程只需约100毫秒。 <div>
Single Sign-On (SSO) is a popular authentication mechanism enabling users to access multiple web services with a single set of credentials. Despite its convenience, SSO faces outstanding privacy challenges. The Identity Provider (IdP) represents a single point of failure and can track users across different Relying Parties (RPs). Multiple colluding RPs may track users through common identity attributes. In response, anonymous credential-based SSO solutions have emerged to offer privacy-preserving authentication without revealing unnecessary user information. However, these solutions face two key challenges: supporting RP authentication without compromising user unlinkability and maintaining compatibility with the predominant Authorization Code Flow (ACF).

This paper introduces VeriSSO, a novel SSO protocol based on verifiable credentials (VC) that supports RP authentication while preserving privacy and avoiding single points of failure. VeriSSO employs an independent authentication server committee to manage RP and user authentication, binding RP authentication with credential-based anonymous user authentication. This approach ensures user unlinkability while supporting RP authentication and allows RPs to continue using their existing verification routines with identity tokens as in the ACF workflow. VeriSSO's design also supports lawful de-anonymization, ensuring user accountability for misbehavior during anonymity. Experimental evaluations of VeriSSO demonstrate its efficiency and practicality, with authentication processes completed within 100 milliseconds.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 01:32:26 +0000</pubDate>
</item>
<item>
<title>Adaptive Adversaries in Byzantine-Robust Federated Learning: A survey.</title>
<link>https://eprint.iacr.org/2025/510</link>
<guid>https://eprint.iacr.org/2025/510</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、安全、模型鲁棒性、自适应攻击、防御机制

<br /><br />总结:
本文关注了联邦学习（Federated Learning，FL）的安全领域，特别是针对模型鲁棒性的脆弱性。文章首先全面概述了FL系统的基本构成和现有漏洞；接着，详细介绍了针对FL系统的各类攻击向量以及现有的攻击方法与防御机制。文章提出了一个利用重新连接的恶意客户端进行攻击的新颖基线方法，并指出目前针对自适应敌手的防御措施存在显著不足，如常用的Krum和Trimmed Mean等安全聚合规则无法有效抵御这类攻击。此外，改进这些算法的工作也未解决这一问题。最后，文章指出了对抗自适应攻击的未来研究方向，并强调了其对于重新定义FL安全范式的重要性。 <div>
Federated Learning (FL) has recently emerged as one of the leading paradigms for collaborative machine learning, serving as a tool for model computation without a need to expose one’s privately stored data. However, despite its advantages, FL systems face severe challenges within its own security solutions that address both privacy and robustness of models. This paper focuses on vulnerabilities within the domain of FL security with emphasis on model-robustness. Identifying critical gaps in current defences, particularly against adaptive adversaries which modify their attack strategies after being disconnected and rejoin systems to continue attacks. To our knowledge, other surveys in this domain do not cover the concept of adaptive adversaries, this along with the significance of their impact serves as the main motivation for this work. Our contributions are fivefold: (1) we present a comprehensive overview of FL systems, presenting a complete summary of its fundamental building blocks, (2) an extensive overview of existing vulnerabilities that target FL systems in general, (3) highlight baseline attack vectors as well as state-of-the-art approaches to development of attack methods and defence mechanisms, (4) introduces a novel baseline method of attack leveraging reconnecting malicious clients, and (5) identifies future research directions to address and counter adaptive attacks. We demonstrate through experimental results that existing baseline secure aggregation rules used in other works for comparison such as Krum and Trimmed Mean are insufficient against those attacks. Further, works improving upon those algorithms do not address this concern either. Our findings serve as a basis for redefining FL security paradigms in the direction of adaptive adversaries.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 15:44:42 +0000</pubDate>
</item>
<item>
<title>Capitalized Bitcoin Fork for National Strategic Reserve</title>
<link>https://eprint.iacr.org/2025/505</link>
<guid>https://eprint.iacr.org/2025/505</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、零成本、国家控股、比特币分叉、战略储备比特币（SRBTC）

总结:
该文提出了一种策略，使一个国家能够在不对纳税人造成任何成本的情况下获得比特币的多数股权。这个策略是通过政府赞助的比特币分叉实现的，新创建的分叉币种称为战略储备比特币（SRBTC），其创世区块将大量新的代币分配给国家财政部，数量为当前比特币（BTC）总量的多倍。原版BTC和SRBTC在分叉链上继续保持1:1等价关系。国家只需要承诺接受SRBTC作为法定货币，如税收支付。

文章通过三个竞争性游戏来证明这一提议的合理性：
1. 第一场游戏显示，如果投资者只有BTC和SRBTC两种选择，那么已持有BTC财富比例达到某一阈值θ的投资者会将新增资金投入原始链，而BTC财富占比低于θ的投资者则会选择投资SRBTC。
2. 第二场游戏表明，如果有第三个投资选择——正在贬值（经通胀调整）的现金，那么BTC持有量低于阈值θ的投资者将倾向于投资SRBTC，但前提是在未来允许挖掘的新SRBTC数量足够大（与1/d成线性增长关系）。
3. 第三场游戏证明了当比特币的分叉版本和一个不认可原版BTC价值的比特币复制品同时存在时，即使两者都由一个或多个国家同等支持，投资者也会更偏好于比特币的分叉版本。 <div>
We describe a strategy for a nation to acquire majority stake in Bitcoin with zero cost to the taxpayers of the nation. We propose a bitcoin fork sponsored by the the government of the nation, and backed by the full faith of treasury of the nation, such that the genesis block of this fork attributes fixed large amount of new kinds of tokens called strategic-reserve-bitcoin tokens (SRBTC) to the nation's treasury, which is some  multiple (greater than one) of the amount of all Bitcoin tokens (BTC) currently set in the Bitcoin protocol. The BTC tokens continue to be treated 1:1 as SRBTC tokens in the forked chain. The only capital that the nation puts up is its explicit guarantee that the SRBTC tokens of the fork will be accepted as legal tender, such as payment of tax to the treasury.

We suggest that this is a better approach than starting a new blockchain that mimics Bitcoin, as it will be  partially fair to the current holders of Bitcoin, which in turn would make it competitive in the space of other such possible forks by other powerful nations. Moreover, such a proof-of-work blockchain  retains its egalitarian and democratic nature, which competitively deters the said nation from any dilutions in the future. 

To justify our proposal we setup three competitive games, and show strategies for different players that are in Nash equilibrium and which throw further light on these claims. In particular, 

1. The first game shows that if the only two alternatives for investors is to invest in BTC or SRBTC, then individuals who have a certain fraction $\theta$ of their wealth already invested in BTC, will invest new money in the original chain, whereas the individuals whose current wealth invested in BTC is less than the $\theta$ fraction will invest new money in SRBTC.
2. The second game shows that if there is a third alternative for investment, which is cash that is losing value (inflation-adjusted) by a percentage $d$, then the investors who had less than $\theta$ fraction of wealth in Bitcoin, will invest in SRBTC only if the dilution of SRBTC is large enough (as an increasing (linear) function of $1/d$). Here by dilution we mean the new SRBTC tokens that are allowed to be eventually mined in the fork.
3.  The third game shows that investors would prefer a fork of Bitcoin over a replica of Bitcoin that doesn't value original BTC, when both are available and even if both are backed similarly by one or more nations.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 19:12:17 +0000</pubDate>
</item>
<item>
<title>Sanitization of FHE Ciphertexts</title>
<link>https://eprint.iacr.org/2016/164</link>
<guid>https://eprint.iacr.org/2016/164</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE)，Somewhat Homomorphic Encryption (SHE)，bootstrapping，ciphertext sanitization，circuit privacy

总结：
文章介绍了关于全同态加密（FHE）的一种新方法。FHE方案定义中支持同态解密，现有的所有FHE构造都是通过从某种程度上可同态加密（SHE）方案利用bootstrapping技术构建的。文章提出一种算法，利用公钥提供的重随机化操作对密文进行净化，使其分布变得规范，不再依赖于导致该密文生成的电路，从而在诚实但好奇模型下实现了电路隐私。这种方法与基于噪声淹没的先前方法不同，不会显著降低底层FHE的安全性和效率权衡。这项技术可以应用于目前为止提出的全部基于格的FHE方案，而不实质性地影响其具体的参数设置。<br /><br /> <div>
By definition, fully homomorphic encryption (FHE) schemes
support homomorphic decryption, and all known FHE constructions are bootstrapped from a Somewhat Homomorphic Encryption (SHE) scheme via this technique. Additionally, when a public key is provided, ciphertexts are also re-randomizable, e.g., by adding to them fresh encryptions of 0. From those two operations we devise an algorithm to sanitize a ciphertext, by making its distribution canonical. In particular, the distribution of the ciphertext does not depend on the circuit that led to it via homomorphic evaluation, thus providing circuit privacy in the honest-but-curious model. Unlike the previous approach based on noise flooding, our approach does not degrade much the security/efficiency trade-off of the underlying FHE. The technique can be applied to all lattice-based FHE proposed so far, without substantially affecting their concrete parameters.
]]></content:encoded>
<pubDate>Fri, 19 Feb 2016 20:16:36 +0000</pubDate>
</item>
<item>
<title>Endorser Peer Anonymization in Hyperledger Fabric for Consortium of Organizations</title>
<link>https://eprint.iacr.org/2025/492</link>
<guid>https://eprint.iacr.org/2025/492</guid>
<content:encoded><![CDATA[
<div> 关键词: Hyperledger Fabric、隐私保护、背书系统、阈值环签名、Pedersen承诺

总结:<br />
本文针对Hyperledger Fabric区块链平台中的交易流程中存在endorser签名和背书策略暴露导致的安全隐患问题，提出了一种隐私保护的背书系统。该系统通过采用范围关联的阈值环签名方案匿名化背书者，并利用Pedersen承诺和非交互式知识证明来保护背书策略的安全性。同时，通过使用非交互式共根证明方法，实现了计算效率的提升。文章进行了必要的安全性分析，证明了所提方案能够确保匿名性和不可链接性属性。通过对现有框架进行比较分析，显示提出的方案提供了更高级别的安全性和优化的效率。 <div>
Hyperledger Fabric is a unique permissioned platform for implementing blockchain in a consortium. It has a distinct transaction flow of execute-order-validate. During the execution phase, a pre-determined set of endorsing peers execute a transaction and sign the transaction response. This process is termed endorsement. In the validation phase, peers validate the transaction with reference to an endorsement policy. The identity of the endorsing organizations is obtainable to all the nodes in the network through the endorser signature and endorsement policy. Knowing this has led to serious vulnerabilities in the blockchain network.
In this paper, we propose a privacy-preserving endorsement system which conceals both endorser signature and endorsement policy. Endorser is anonymized by replacing the signature scheme with a scoped-linkable threshold ring signature scheme. Endorsement policy is secured using Pedersen commitments and non-interactive proof of knowledge of integer vector. We also achieve efficiency in the computation by employing non-interactive proof of co-prime roots. We provide the necessary security analysis to prove that the proposed work guarantees anonymity and unlinkability properties. A comparative analysis of our work with an existing framework is provided which shows that the proposed scheme offers higher level of security and it is optimal in terms of efficiency.
]]></content:encoded>
<pubDate>Sat, 15 Mar 2025 13:18:58 +0000</pubDate>
</item>
<item>
<title>Blind Brother: Attribute-Based Selective Video Encryption</title>
<link>https://eprint.iacr.org/2025/491</link>
<guid>https://eprint.iacr.org/2025/491</guid>
<content:encoded><![CDATA[
<div> 关键词: 选择性视频加密(SVE), 细粒度访问控制, ABSVE协议, 区域感兴趣(ROI), 密文策略属性基加密(CP-ABE)

总结:<br />
针对现有选择性视频加密方案存在的粗粒度加密和单一访问级别的局限性，本文提出了一个基于细粒度访问控制的选择性视频加密方案——ABSVE及其应用协议\protocol。该方案通过使用独特的对称密钥加密不同的区域感兴趣(ROI)，并利用CP-ABE方案将这些密钥与特定访问策略绑定，从而实现单个加密视频流的多级访问权限。此外，文章还为ABSVE提供了正式的语法和安全性定义，填补了先前工作中对此类方案严格安全性分析的空白。最后，本文在Kvazaar HEVC编码器上实现了该协议并进行了评估，结果显示，提出的方案在增强安全性和隐私保护的同时，还能实现对视频内容的可控访问，并且效率接近未加密压缩的情况。 <div>
The emergence of video streams as a primary medium for communication and the demand for high-quality video sharing over the internet have given rise to several security and privacy issues, such as unauthorized access and data breaches. To address these limitations, various Selective Video Encryption (SVE) schemes have been proposed, which encrypt specific portions of a video while leaving others unencrypted. The SVE approach balances security and usability, granting unauthorized users access to certain parts while encrypting sensitive content. However, existing SVE schemes adopt an all-or-nothing coarse-grain encryption approach, where a user with a decryption key can access all the contents of a given video stream. This paper proposes and designs a fine-grained access control-based selective video encryption scheme, ABSVE, and a use-case protocol called \protocol. Our scheme encrypts different identified Regions of Interest (ROI) with a unique symmetric key and applies a Ciphertext Policy Attribute Based Encryption (CP-ABE) scheme to tie these keys to specific access policies. This method provides multiple access levels for a single encrypted video stream. Crucially, we provide a formal syntax and security definitions for ABSVE, allowing for rigorous security analysis of this and similar schemes --  which is absent in prior works. Finally, we provide an implementation and evaluation of our protocol in the Kvazaar HEVC encoder. Overall, our constructions enhance security and privacy while allowing controlled access to video content and achieve comparable efficiency to compression without encryption.
]]></content:encoded>
<pubDate>Sat, 15 Mar 2025 13:13:35 +0000</pubDate>
</item>
<item>
<title>PREAMBLE: Private and Efficient Aggregation of Block Sparse Vectors and Applications</title>
<link>https://eprint.iacr.org/2025/490</link>
<guid>https://eprint.iacr.org/2025/490</guid>
<content:encoded><![CDATA[
<div> 关键词：secure aggregation、two-server system、Prio、block-sparse vectors、PREAMBLE

总结:<br />
本文关注的是在两服务器系统中高维度向量的安全聚合问题，如Prio系统中用于隐私联邦学习的梯度聚合。现有的方法需要随着维度的增长而增加通信量，从而限制了能有效处理的向量维度。为此，文章提出了PREAMBLE——一种针对块稀疏欧几里得向量的新型分布式点函数扩展，它实现了对块稀疏向量的高效通信和计算聚合。进一步地，PREAMBLE可以与随机采样及采样结果下的隐私增强相结合，实现向量聚合的渐近最优隐私-效用权衡，同时只需很小的通信成本。结合最近在数值隐私会计领域的进展，相比于应用于Prio的高斯机制，本方法在噪声方差上的开销可忽略不计。 <div>
We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential privacy. Existing approaches require communication scaling with the dimensionality, and thus limit the dimensionality of vectors one can efficiently process in this setup.

We propose PREAMBLE: Private Efficient Aggregation Mechanism for  Block-sparse Euclidean Vectors. PREAMBLE is a novel extension of distributed point functions that enables communication- and computation-efficient aggregation of block-sparse vectors, which are sparse vectors where the non-zero entries occur in a small number of clusters of consecutive coordinates. We then show that PREAMBLE can be combined with random sampling and privacy amplification by sampling results, to allow asymptotically optimal privacy-utility trade-offs for vector aggregation, at a fraction of the communication cost. When coupled with recent advances in numerical privacy accounting, our approach incurs a negligible overhead in noise variance, compared to the Gaussian mechanism used with Prio.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 22:02:42 +0000</pubDate>
</item>
<item>
<title>webSPDZ: Versatile MPC on the Web</title>
<link>https://eprint.iacr.org/2025/487</link>
<guid>https://eprint.iacr.org/2025/487</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、可用性、浏览器基础、webSPDZ、MP-SPDZ

总结:
随着多党计算（MPC）在如医疗、金融和机器学习等领域解决隐私与安全问题日益实用化，其用户体验成为一大关注点。为提升MPC的易用性，可构建基于浏览器的MPC引擎，例如JIFF和MPyC的网络版本。文章提出将性能强大、通用性强的MPC引擎MP-SPDZ引入网络环境，创建名为webSPDZ的新引擎。通过使用Emscripten将MP-SPDZ的C++后端编译为WebAssembly并升级浏览器通信（使用WebRTC或WebSocket）。webSPDZ支持≥40种不同安全模型的MPC协议，相较于现有的MPyC-Web和JIFF等网络版MPC引擎，在端到端实验中表现出更优性能。因此，webSPDZ不仅提升了MPC的易用性，还将其实用范围扩展至更广泛的用户群体，推动了MPC实践应用的边界。 <div>
Multi-party computation (MPC) has become increasingly practical in the last two decades, solving privacy and security issues in various domains, such as healthcare, finance, and machine learning. One big caveat is that MPC sometimes lacks usability since the knowledge barrier for regular users can be high. Users have to deal with, e.g., various CLI tools, private networks, and sometimes even must install many dependencies, which are often hardware-dependent.

A solution to improve the usability of MPC is to build browser-based MPC engines where each party runs within a browser window. Two examples of such an MPC web engine are JIFF and the web variant of MPyC. Both support an honest majority with passive corruptions.

$\texttt{webSPDZ}$: Our work brings one of the most performant and versatile general-purpose MPC engines, MP-SPDZ, to the web. MP-SPDZ supports ≥40 MPC protocols with different security models, enabling many security models on the web. To port MP-SPDZ to the web, we use Emscripten to compile MP-SPDZ’s C++ BackEnd to WebAssembly and upgrade the party communication for the browser (WebRTC or WebSockets). We call the new MPC web engine webSPDZ. As with the native versions of the mentioned MPC web engines, MPyC-Web and JIFF, webSPDZ outperforms them in our end-to-end experiments.

We believe that webSPDZ brings forth many interesting and practically relevant use cases. Thus, webSPDZ pushes the boundaries of practical MPC: making MPC more usable and enabling it for a broader community.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 07:30:45 +0000</pubDate>
</item>
<item>
<title>On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations</title>
<link>https://eprint.iacr.org/2025/486</link>
<guid>https://eprint.iacr.org/2025/486</guid>
<content:encoded><![CDATA[
<div> 关键词: One-shot signatures (OSS), 量子签名钥匙, 不可克隆原理, 可区分性混淆(iO), LWE假设

总结:
本文首次提出了基于标准模型的一次性签名方案(OSS)，该方案的安全性依赖于亚指数级的不可区分性混淆(iO)和LWE假设。这同时也解决了长达十年的一个开放问题，即首次在标准模型下实现了区分古典绑定与坍缩绑定的后量子承诺/哈希的分离。在此过程中，文章还给出了第一个无条件安全的经典oracle模型下的OSS构造。为了实现标准模型的构造，作者们提出了一种名为可交换伪随机置换(permutable PRPs)的概念，并展示了它们如何用于将涉及随机置换的oracle证明转化为基于混淆的证明。具体来说，混淆可交换PRP可以得到一个全域的带有陷阱门的一次性单向函数，这也解决了另一个使用(iO)和一次函数构建此类对象长达十年的问题。 <div>
One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and Zhandry (STOC'20). These allow for signing exactly one message, after which the signing key self-destructs, preventing a second message from ever being signed. While such an object is impossible classically, Amos et al observe that OSS may be possible using quantum signing keys by leveraging the no-cloning principle. OSS has since become an important conceptual tool with many applications in decentralized settings and for quantum cryptography with classical communication. OSS are also closely related to separations between classical-binding and collapse-binding for post-quantum hashing and commitments. Unfortunately, the only known OSS construction due to Amos et al. was only justified in a classical oracle model, and moreover their justification was ultimately found to contain a fatal bug. Thus, the existence of OSS, even in a classical idealized model, has remained open. 

We give the first standard-model OSS, with provable security assuming (sub-exponential) indistinguishability obfuscation (iO) and LWE. This also gives the first standard-model separation between classical and collapse-binding post-quantum commitments/hashing, solving a decade-old open problem. Along the way, we also give the first construction with unconditional security relative to a classical oracle. To achieve our standard-model construction, we develop a notion of permutable pseudorandom permutations (permutable PRPs), and show how they are useful for translating oracle proofs involving random permutations into obfuscation-based proofs. In particular, obfuscating permutable PRPs gives a trapdoor one-way permutation that is $\textit{full-domain}$, solving another decade-old-problem of constructing this object from (sub-exponential) iO and one-way functions.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 06:49:30 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Zero-Knowledge Proofs with Certified Deletion</title>
<link>https://eprint.iacr.org/2024/1848</link>
<guid>https://eprint.iacr.org/2024/1848</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式零知识证明，认证删除，量子，学习与错误问题，可撤销匿名凭证

总结:
本文提出了具有认证删除功能的非交互式零知识（NIZK）证明的概念。该概念允许NIZK证明的接收者在删除证明后获得一个证明删除行为的古典证书。文中给出了两个基于标准密码学假设的候选构造方案，第一个方案依赖于经典的NIZK证明和量子抗性的一次函数，但需要证明者和验证者都运行量子算法。随后，作者提出了一种扩展方案，允许证明者为经典设备，这个方案基于学习与错误问题，并要求证明者和验证者之间进行一次实例独立的交互式设置。此外，这些成果在可撤销的知识签名和可撤销匿名凭证的应用上也有所体现，文中对这两个应用进行了定义并构建了相应的方案。<br /><br /> <div>
We introduce the notion of non-interactive zero-knowledge (NIZK) proofs with certified deletion. Our notion enables the recipient of a (quantum) NIZK proof to delete the proof and obtain a (classical) certificate proving such deletion. We define this notion and propose two candidate constructions from standard cryptographic assumptions. Our first construction is based on classical NIZK proofs and quantum-hard one-way functions but needs both the prover and verifier to run quantum algorithms. We then present an extension that allows the prover to be classical; this is based on the learning with errors problem and requires an instance-independent interactive setup between the prover and verifier. 

Our results have applications to revocable signatures of knowledge and revocable anonymous credentials, which we also define and construct.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:05:19 +0000</pubDate>
</item>
<item>
<title>Client-Efficient Online-Offline Private Information Retrieval</title>
<link>https://eprint.iacr.org/2024/719</link>
<guid>https://eprint.iacr.org/2024/719</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Information Retrieval (PIR), Online-Offline PIR (OO-PIR), Pirex, Client inbound bandwidth, Storage cost

总结:<br />
本文提出了一种名为Pirex的新颖两服务器在线离线私人信息检索(PIR)方案，该方案具有半诚实安全性。Pirex显著降低了客户端的带宽和存储成本，同时保持了亚线性处理效率。与现有的OO-PIR方案相比，Pirex的设计更为简洁，主要操作自然低成本且高效（如XOR、PRF和模数运算）。已经完全实现了Pirex并使用商用硬件对其进行了实际性能评估。结果显示，Pirex比现有方案至少快两个数量级。例如，在面对1TB数据库查询4KB条目时，Pirex仅需55毫秒，而最先进的方案需要9到30秒。对于含有数十亿个4KB条目的实际数据库，Pirex只需16KB的进站带宽，效率提高了三个数量级。 <div>
Private Information Retrieval (PIR) permits clients to query data entries from a public database hosted on untrusted servers while preserving client privacy. Traditional PIR models suffer from high computation and/or bandwidth overhead due to linear database processing for privacy. Recently, Online-Offline PIR (OO-PIR) has been proposed to improve PIR practicality by precomputing query-independent materials to accelerate online access. While state-of-the-art OO-PIR schemes (e.g., S&amp;P’24, CRYPTO’23) successfully reduce online processing cost to sublinear levels, they still impose substantial bandwidth and storage burdens on the client, especially when operating on large databases.

In this paper, we propose Pirex, a new two-server OO-PIR with semi-honest security that offers minimal client inbound bandwidth and storage cost while retaining the sublinear processing efficiency. The Pirex design is simple with most operations are naturally low-cost and streamlined (e.g., XOR, PRF, modular arithmetic). We have fully implemented Pirex and evaluated its real-world performance using commodity hardware. Our results showed that Pirex outperforms existing OO-PIR schemes by at least two orders of magnitude. With a 1 TB database, Pirex takes 55ms to retrieve a 4 KB entry, compared with 9-30s by state-of-the-art. For practical databases with billions of 4 KB entries, Pirex only takes 16 KB of inbound bandwidth, which is up to three orders of magnitude more efficient.
]]></content:encoded>
<pubDate>Fri, 10 May 2024 02:53:56 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure Threshold Blind BLS Signatures and Threshold Oblivious PRF</title>
<link>https://eprint.iacr.org/2025/483</link>
<guid>https://eprint.iacr.org/2025/483</guid>
<content:encoded><![CDATA[
<div> 关键词: 原始文本、首次、阈值盲签名方案、阈值Oblivious PRF (OPRF)、适应性安全性

总结:
我们首次提出了在适应性对手存在下仍能保持安全性的阈值盲签名方案和阈值Oblivious PRF (OPRF)方案。这些方案允许对手在整个协议生命周期中自适应地选择要腐败的参与者。与仅针对静态对手提供安全性的先前解决方案相比，我们的方案仅增加了少量计算开销，并保持了最小的通信轮数复杂度。我们的阈值盲签名方案基于标准的BLS签名，而阈值OPRF则采用高效的“2HashDH”OPRF。这两个方案都在代数群模型(AGM)中证明了其适应性安全性。此外，我们的适应性安全阈值方案同样具备实用性和与其基础的单服务器BLS盲签名以及2HashDH OPRF相同的效率，可以用于为依赖于盲签名（如匿名凭证和电子现金系统）或Oblivious PRF（如OPAQUE密码认证和Privacy Pass匿名认证方案等）的系统增添加密容错能力和去中心化的信任机制。 <div>
We show the first threshold blind signature scheme and threshold Oblivious PRF (OPRF) scheme which remain secure in the presence of an adaptive adversary, who can adaptively decide which parties to corrupt throughout the lifetime of the scheme.  Moreover, our adaptively secure schemes preserve the minimal round complexity and add only a small computational overhead over prior solutions that offered security only for a much less realistic static adversary, who must choose the subset of corrupted parties before initializing the protocol.

Our threshold blind signature scheme computes standard BLS signatures while our threshold OPRF computes a very efficient "2HashDH" OPRF [JKK14].  We prove adaptive security of both schemes in the Algebraic Group Model (AGM).  Our adaptively secure threshold schemes are as practical as the underlying standard single-server BLS blind signature and 2HashDH OPRF, and they can be used to add cryptographic fault-tolerance and decentralize trust in any system that relies on blind signatures, like anonymous credentials and e-cash, or on OPRF, like the OPAQUE password authentication and the Privacy Pass anonymous authentication scheme, among many others.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:02:29 +0000</pubDate>
</item>
<item>
<title>Post Quantum Migration of Tor</title>
<link>https://eprint.iacr.org/2025/479</link>
<guid>https://eprint.iacr.org/2025/479</guid>
<content:encoded><![CDATA[
<div> 关键词：Shor's算法，Grover's算法，量子计算机，Tor网络，后量子密码学(PQC)

总结:
本文针对Shor's和Grover's算法以及量子计算机技术进步可能对现有隐私保护加密方式构成的潜在威胁进行了探讨。文章以匿名通信系统Tor为例，首先分析了其中使用的非量子抗性加密方案，并提出了评估本地Tor网络性能的理论方法。研究分为三个阶段进行：一是基准测试局部Tor网络模拟在受限设备上的运行时间，以孤立出古典密码学过程所需的时间；二是结合现有的量子安全算法基准测试结果，对比这些算法在同类设备上的性能表现；最后，通过对传统密码学执行时间替换为在特定Tor环境中记录的PQC执行时间，来估算采用PQC所带来的开销。通过关注可替代的加密组件、运用理论估计并利用现有基准测试数据，本文旨在无需完全实现PQC的情况下，对未来PQC对Tor网络可能产生的影响提供有价值的见解。 <div>
Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as harvest now, decrypt later attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 10:35:48 +0000</pubDate>
</item>
<item>
<title>Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and OpenFHE</title>
<link>https://eprint.iacr.org/2025/473</link>
<guid>https://eprint.iacr.org/2025/473</guid>
<content:encoded><![CDATA[
<div> 关键词: 云计算, 隐私保护, 欧同态加密(HE), SEAL, OpenFHE

总结:
这篇论文评估了两种主流的欧同态加密库——SEAL和OpenFHE，关注其在处理敏感数据的安全计算性能、易用性以及对如BGV和CKKS等著名HE方案的支持。研究分析了它们在Linux和Windows平台上的计算效率、内存使用及可扩展性，强调了其在现实世界场景中的适用性。结果显示，Linux平台在计算效率上优于Windows，而OpenFHE则在各种密码学设定下表现出更优的整体性能。这些发现为研究人员和实践者推进基于HE的隐私保护应用提供了有价值的参考。 <div>
The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS.   Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 22:21:53 +0000</pubDate>
</item>
<item>
<title>Practical Semi-Open Chat Groups for Secure Messaging Applications</title>
<link>https://eprint.iacr.org/2025/469</link>
<guid>https://eprint.iacr.org/2025/469</guid>
<content:encoded><![CDATA[
<div> 关键词: 实践型、隐私保护、声誉系统、安全即时通讯应用、成员准入自动化

总结:
设计了一个实用且注重隐私保护的声誉系统，该系统能基于现有成员对新成员的声誉评估自动批准其加入大规模聊天群组，如Signal、Telegram和Whatsapp中的群组。系统在单服务器模型中证明了对恶意敌手的安全性，无需额外的信任假设，并能在大部分成员离线的情况下几乎正常进行任意声誉计算。此外，通过开源实现展示了其实用性。对于人数为50（或200）的群组，对获得40（或80）评分的新成员进行准入过程分别需要通信量1312.2 KiB（或5239.4 KiB），以及单核计算时间3.3秒（或16.3秒）。虽然本协议的设计与现有的安全即时通讯应用相匹配，但我们认为它在分布式声誉计算领域的应用场景超越了这一问题设定。 <div>
Chat groups in secure messaging applications such as Signal, Telegram, and Whatsapp are nowadays used for rapid and widespread dissemination of information to large groups of people. This is common even in sensitive contexts, associated with the organisation of protests, activist groups, and internal company dialogues. Manual administration of who has access to such groups quickly becomes infeasible, in the presence of hundreds or thousands of members.

We construct a practical, privacy-preserving reputation system, that automates the approval of new group members based on their reputation amongst the existing membership. We demonstrate security against malicious adversaries in a single-server model, with no further trust assumptions required. Furthermore, our protocol supports arbitrary reputation calculations while almost all group members are offline (as is likely). In addition, we demonstrate the practicality of the approach via an open-source implementation. For groups of size 50 (resp. 200), an admission process on a user that received 40 (resp. 80) scores requires 1312.2 KiB (resp. 5239.4 KiB) of communication, and 3.3s (resp. 16.3s) of overall computation on a single core. While our protocol design matches existing secure messaging applications, we believe it can have value in distributed reputation computation beyond this problem setting.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 11:23:47 +0000</pubDate>
</item>
<item>
<title>zkAML: Zero-knowledge Anti Money Laundering in Smart Contracts with whitelist approach</title>
<link>https://eprint.iacr.org/2025/465</link>
<guid>https://eprint.iacr.org/2025/465</guid>
<content:encoded><![CDATA[
<div> 关键词：反洗钱（AML）、打击恐怖主义融资（CFT）、零知识证明（zk-SNARK）、隐私保护、区块链网络

总结：
本文提出了一种名为\textsf{zkAML}的加密框架，旨在解决传统AML/CFT合规性监管中出现的效率低下、交易延迟和隐私泄露问题。该框架利用zk-SNARK技术，使得用户能够在不透露敏感个人信息的情况下，证明其符合监管要求，从而避免了冗余的身份检查，简化了合规流程，并提升了交易效率。文章进一步阐述了\textsf{zkAML}在区块链网络上的实现与评估结果，显示在公共网络上可达到55笔/秒的交易处理能力，在私有网络上可达324笔/秒。生成发送方和接收方的zk-SNARK证明的时间分别为226.59毫秒和215.76毫秒，每笔交易的验证时间恒定为1.47毫秒。这些实验结果证实了\textsf{zkAML}作为隐私保护与法规遵从解决方案在现代金融系统中的应用潜力。 <div>
In the interconnected global financial system, anti-money laundering (AML) and combating the financing of terrorism (CFT) regulations are indispensable for safeguarding financial integrity. However, while illicit transactions constitute only a small fraction of overall financial activities, traditional AML/CFT frameworks impose uniform compliance burdens on all users, resulting in inefficiencies, transaction delays, and privacy concerns. 
These issues stem from the institution-centric model, where financial entities independently conduct compliance checks, resulting in repeated exposure of personally identifiable information (PII) and operational bottlenecks.
To address these challenges, we introduce \textsf{zkAML}, a cryptographic framework that offers a novel approach to AML/CFT compliance. By leveraging zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK) proofs, \textsf{zkAML}~enables users to cryptographically demonstrate their regulatory compliance without revealing sensitive personal information. This approach eliminates redundant identity checks, streamlines compliance procedures, and enhances transaction efficiency while preserving user privacy.
We implement and evaluate \textsf{zkAML}~on a blockchain network to demonstrate its practicality. Our experimental results show that \textsf{zkAML}~achieves 55 transactions per second (TPS) on a public network and 324 TPS on a private network. The zk-SNARK proof generation times are $226.59$ms for senders and $215.76$ms for receivers, with a constant verification time of $1.47$ms per transaction. These findings highlight \textsf{zkAML}'s potential as a privacy-preserving and regulation-compliant solution for modern financial systems.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 08:43:03 +0000</pubDate>
</item>
<item>
<title>Leaking Arbitrarily Many Secrets: Any-out-of-Many Proofs and Applications to RingCT Protocols</title>
<link>https://eprint.iacr.org/2021/1405</link>
<guid>https://eprint.iacr.org/2021/1405</guid>
<content:encoded><![CDATA[
<div> 关键词：Ring Confidential Transaction (RingCT), 任何-out-of-many证明, 零知识证明, 多重秘密, 匿名性<br /><br />总结: 本文提出了一种新颖的“任何-out-of-many”证明方案，这是一种对公开列表中任意多的秘密进行知识证明的、对数大小的零知识证明策略。与现有部分知识证明不同，该方法在证明多个秘密的同时不泄露确切的秘密数量。通过采用Bulletproofs压缩技术的通用内积变换，进一步提高了效率，将证明尺寸减少到$2 \lceil \log_2(N) \rceil \! + \! 9$。基于此证明方案，文章构建了一个紧凑型的RingCT协议，用于隐私加密货币，实现了处理具有多个输入交易的对数级通信复杂度，并提供了最高级别的匿名性。相较于如Omniring等其他方法，这是首个从部分知识证明实例化的RingCT协议，同时它也可以适应其他应用，如多重环签名和区块链中的币混服务。文章认为这些技术在更多隐私保护场景中也具有潜在的应用价值。 <div>
Ring Confidential Transaction (RingCT) protocol is an effective cryptographic component for preserving the privacy of cryptocurrencies. However, existing RingCT protocols are instantiated from one-out-of-many proofs with only one secret, leading to low efficiency and weak anonymity when handling transactions with multiple inputs. Additionally, current partial knowledge proofs with multiple secrets are neither secure nor efficient to be applied in a RingCT protocol.
    
In this paper, we propose a novel \emph{any-out-of-many proof}, a logarithmic-sized zero-knowledge proof scheme for showing the knowledge of arbitrarily many secrets out of a public list. Unlike other partial knowledge proofs that have to reveal the number of secrets [ACF21], our approach proves the knowledge of multiple secrets without leaking the exact number of them. Furthermore, we improve the efficiency of our method with a generic inner-product transformation to adopt the Bulletproofs compression [BBB+18], which reduces the proof size to $2 \lceil \log_2(N) \rceil \! + \! 9$.
    
Based on our proposed proof scheme, we further construct a compact RingCT protocol for privacy cryptocurrencies, which can provide a logarithmic-sized communication complexity for transactions with multiple inputs. More importantly, as the only known RingCT protocol instantiated from the partial knowledge proofs, our protocol can achieve the highest anonymity level compared with other approaches like Omniring [LRR+19]. For other applications, such as multiple ring signatures, our protocol can also be applied with some modifications. We believe our techniques are also applicable in other privacy-preserving scenarios, such as multiple ring signatures and coin-mixing in the blockchain.
]]></content:encoded>
<pubDate>Sun, 24 Oct 2021 07:27:47 +0000</pubDate>
</item>
<item>
<title>Token meets Wallet: Formalizing Privacy and Revocation for FIDO2</title>
<link>https://eprint.iacr.org/2022/084</link>
<guid>https://eprint.iacr.org/2022/084</guid>
<content:encoded><![CDATA[
<div> 关键词：FIDO2标准、WebAuthn组件、安全模型、隐私保护、全局密钥撤销

总结:<br />
本文针对FIDO2标准中的WebAuthn组件进行了安全性重新审视。首先，改进了Barbosa等人提出的模型，以涵盖使用密钥派生或密钥封装的认证令牌。其次，提出了FIDO2中WebAuthn组件的第一个正式隐私定义，并证明如果选用适当的底层构建模块，则该组件在常见FIDO2令牌实现中可保证用户隐私。最后，解决了FIDO2全局密钥撤销问题，为此引入并分析了一种基于广泛应用于加密货币钱包的BIP32标准的简单撤销程序，该程序能够与现有的FIDO2服务器高效实施。 <div>
The FIDO2 standard is a widely-used class of challenge-response type protocols that allows to authenticate to an online service using a hardware token.  
Barbosa et al. (CRYPTO `21) provided the first formal security model and analysis for the FIDO2 standard.
However, their model has two shortcomings: (1) It does not include privacy, one of the key features claimed by FIDO2. (2) It only covers tokens that store {all secret keys locally}.
In contrast, due to limited memory, most existing FIDO2 tokens either derive all secret keys from a common seed or store keys on the server (the latter approach is also known as {key wrapping}).

In this paper, we revisit the security of the WebAuthn component of FIDO2 as implemented in practice. Our contributions are as follows.
(1) We adapt the model of Barbosa et al. so as to capture authentication tokens using key derivation or key wrapping.
(2) We provide the {first formal definition of privacy for the WebAuthn component of FIDO2}. We then prove the privacy of this component in common FIDO2 token implementations if the underlying building blocks are chosen appropriately.
(3) We address the unsolved problem of {global key revocation} in FIDO2. 
To this end, we introduce and analyze a simple revocation procedure that builds on the popular BIP32 standard used in cryptocurrency wallets and can efficiently be implemented with existing FIDO2 servers.
]]></content:encoded>
<pubDate>Sun, 23 Jan 2022 13:01:17 +0000</pubDate>
</item>
<item>
<title>Multi-Party Computation in Corporate Data Processing: Legal and Technical Insights</title>
<link>https://eprint.iacr.org/2025/463</link>
<guid>https://eprint.iacr.org/2025/463</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算(MPC), 欧盟通用数据保护条例(GDPR), 法律分析, 技术实现, 隐私保护

总结:
本文研究了多方计算（MPC）在企业数据处理环境中的应用及其在欧洲联盟通用数据保护条例（GDPR）下的法律和技术影响。文章通过结合密码学和法律分析的专业知识，探讨了MPC作为匿名化方法在GDPR下适用性的关键问题，重点关注分布式控制等架构要求以有效降低重新识别风险。法律评估得到两个独立评估的支持。文章系统性地回答了关键监管问题，强调对于意图采用MPC的同时确保遵守隐私法的组织来说，结构化的法律评估至关重要。此外，为了补充这一理论分析，文章还利用Carbyne Stack——一个基于云原生的、用于可扩展MPC应用的开源平台，以及其后端集成的MP-SPDZ框架，实现了隐私保护的数据分析，并对不同安全模型下的SQL查询进行了基准测试，以评估其可扩展性和效率。 <div>
This paper examines the deployment of Multi-Party Computation (MPC) in corporate data processing environments, focusing on its legal and technical implications under the European Union’s General Data Protection Regulation (GDPR). By combining expertise in cryptography and legal analysis, we address critical questions necessary for assessing the suitability of MPC for real-world applications. Our legal evaluation explores the conditions under which MPC qualifies as an anonymizing approach under GDPR, emphasizing the architectural requirements, such as the distribution of control among compute parties, to minimize re-identification risks effectively. The assertions put forth in the legal opinion are validated by two distinct assessments conducted independently.

We systematically answer key regulatory questions, demonstrating that a structured legal assessment is indispensable for organizations aiming to adopt MPC while ensuring compliance with privacy laws. In addition, we complement this analysis with a practical implementation of privacy-preserving analytics using Carbyne Stack, a cloud-native open-source platform for scalable MPC applications, which integrates the MP-SPDZ framework as its backend. We benchmark SQL queries under various security models to evaluate scalability and efficiency.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 08:19:28 +0000</pubDate>
</item>
<item>
<title>Achieving Data Reconstruction Hardness and Efficient Computation in Multiparty Minimax Training</title>
<link>https://eprint.iacr.org/2025/460</link>
<guid>https://eprint.iacr.org/2025/460</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型、联邦学习、数据重建、多 party 计算、生成对抗网络<br /><br />总结: 本文关注在保持训练成本可管理的同时，提高基于生成对抗网络（GAN）训练过程中数据重构的难度。研究了两种使用公共生成器和多方计算（MPC）鉴别器的训练协议：协议1（P1）采用完全私有的鉴别器，而协议2（P2）仅对前三层鉴别器进行隐私保护。我们证明了对于P1和P2，只要鉴别器的前两层是私有的，公共生成器就不能恢复真实的训练数据；并通过ReLU网络存在的已知近似难度结果，证明了至少有三层私有层的鉴别器不能通过多项式时间复杂度的算法来重构真实数据。实验结果显示，与完全MPC训练相比，P1能够将训练时间减少2倍，而P2则能进一步将其减少到4至16倍。 <div>
Generative models have achieved remarkable success in a wide range of applications. Training such models using proprietary data from multiple parties has been studied in the realm of federated learning. Yet recent studies showed that reconstruction of authentic training data can be achieved in such settings. 
On the other hand, multiparty computation (MPC) guarantees standard data privacy, yet scales poorly for training generative models. 
In this paper, we focus on improving reconstruction hardness during Generative Adversarial Network (GAN) training while keeping the training cost tractable. To this end, we explore two training protocols that use a public generator and an MPC discriminator: Protocol 1 (P1) uses a fully private discriminator, while Protocol 2 (P2) privatizes the first three discriminator layers. We prove reconstruction hardness for P1 and P2 by showing that (1) a public generator does not allow recovery of authentic training data, as long as the first two layers of the discriminator are private; and through an existing approximation hardness result on ReLU networks, (2) a discriminator with at least three private layers does not allow authentic data reconstruction with algorithms polynomial in network depth and size. We show empirically that compared with fully MPC training, P1 reduces the training time by $2\times$ and P2 further by $4-16\times$.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 22:39:40 +0000</pubDate>
</item>
<item>
<title>Revisiting the Security and Privacy of FIDO2</title>
<link>https://eprint.iacr.org/2025/459</link>
<guid>https://eprint.iacr.org/2025/459</guid>
<content:encoded><![CDATA[
<div> 关键词: FIDO2、隐私安全分析、信任设置假设、安全模型、隐私保证

总结:<br />
本文重新审视了广泛应用于网络无密码认证标准FIDO2的隐私与安全性分析。文中指出了以往工作的局限性，包括不切实际的信任设置假设、针对当前实战攻击的安全模型不足以及未全面分析FIDO2的整体隐私保障。为填补这些空白，文章提出了修订后的隐私和身份验证安全模型，并采用新模型对FIDO2进行模块化分析，重点关注其组件协议WebAuthn和CTAP2，明确了它们的确切安全保障。特别地，本研究首次确立了FIDO2整体的隐私保护承诺。此外，还提出了一些小修改建议，以帮助FIDO2能够达到更强大的隐私和认证定义要求，并抵抗已知和新型攻击。 <div>
We revisit the privacy and security analyses of FIDO2, a widely deployed standard for passwordless authentication on the Web. 
We discuss previous works 
and conclude that each of them has at least one of the following limitations:
(i) impractical trusted setup assumptions, 
(ii) security models that are inadequate in light of state of the art of practical attacks,
(iii) not analyzing FIDO2 as a whole, especially for its privacy guarantees.
Our work addresses these gaps and proposes revised security models for privacy and authentication. Equipped with our new models, we analyze FIDO2 modularly and focus on its component protocols, WebAuthn and CTAP2, clarifying their exact security guarantees. 
In particular, our results, for the first time, establish privacy guarantees for FIDO2 as a whole.
Furthermore, we suggest minor modifications that can help FIDO2 provably meet stronger privacy and authentication definitions and withstand known and novel attacks.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 21:09:06 +0000</pubDate>
</item>
<item>
<title>Concretely Efficient Correlated Oblivious Permutation</title>
<link>https://eprint.iacr.org/2025/449</link>
<guid>https://eprint.iacr.org/2025/449</guid>
<content:encoded><![CDATA[
<div> 关键词： Oblivious Permutation (OP)，Correlated Oblivious Permutation (COP)，secure multi-party computation (MPC)，communication cost，execution time。

总结:<br />
本文针对 Oblivious Permutation (OP) 中的性能瓶颈问题进行了研究。OP 是许多重要 MPC 应用的基础，但其高复杂度限制了其实效性。Chase 等人在 Asiacrypt'20 提出了离线-在线 OP 模型，利用可预计算资源“Share Translation”降低在线成本。然而，生成 Share Translation 的高额离线成本仍是待优化领域。本文重新定义了该预计算资源为新的密码学原语——Correlated Oblivious Permutation (COP) 并对其两种生成方案（网络和矩阵方案）进行了深入分析与优化。对于网络方案，改进减少了构建交换机的通信/计算成本并降低了网络中的交换机数量；对矩阵方案，则降低了小规模 COP 生成的通信成本及大规模 COP 生成的通过内外分解的成本。作者实现了这两种 COP 生成协议并进行了全面评估，结果显示，使用 128 位输入数据为例，网络方案和矩阵方案分别比基线协议快达 1.7 倍和 1.6 倍。进一步地，将优化后的 COP 应用于最先进的 PSU 协议中，实现了超过 25% 的通信成本减少和 35% 的执行时间下降，证明了 COP 优化对于现实世界 MPC 原语的重大改进意义。 <div>
Oblivious permutation (OP) enables two parties, a sender with a private data vector $x$ and a receiver with a private permutation π, to securely obtain the shares of π(x). OP has been used to construct many important MPC primitives and applications such as secret shuffle, oblivious sorting, private set operations, secure database analysis, and privacy-preserving machine learning. Due to its high complexity, OP has become a performance bottleneck in several practical applications, and many efforts have been devoted to enhancing its concrete efficiency. Chase et al. (Asiacrypt'20) proposed an offline-online OP paradigm leveraging a pre-computable resource termed Share Translation. While this paradigm significantly reduces online costs, the substantial offline cost of generating Share Translation remains an area for further investigation.

In this work, we redefine the pre-computable resource as a cryptographic primitive known as Correlated Oblivious Permutation (COP) and conduct in-depth analyses and optimizations of the two COP generation solutions: network-based solution and matrix-based solution. The optimizations for the network-based solution halve the communication/computation cost of constructing a switch (the basic unit of the permutation network) and reduce the number of switches in the permutation network. The optimizations for the matrix-based solution halve the communication cost of small-size COP generation and reduce the cost of large-size COP generation with in-outside permutation decomposition.

We implement our two COP generation protocols and conduct comprehensive evaluations. Taking commonly used 128-bit input data as an example, our network-based and matrix-based solutions are up to 1.7x and 1.6x faster than baseline protocols, respectively. 
 We further facilitate the state-of-the-art (SOTA) PSU protocols with our optimized COP, achieving over 25% reduction in communication cost and 35% decrease in execution time. This shows that our COP optimizations bring significant improvements for real-world MPC primitives.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 09:25:29 +0000</pubDate>
</item>
<item>
<title>Ciphertext-Ciphertext Matrix Multiplication: Fast for Large Matrices</title>
<link>https://eprint.iacr.org/2025/448</link>
<guid>https://eprint.iacr.org/2025/448</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护机器学习、加密矩阵乘法、大规模、快速算法、密钥大小优化

总结:
为了解决隐私保护机器学习中大型加密矩阵乘法（CC-MM）的关键挑战，本文提出了一种新的算法。该算法结合了明文矩阵乘法（PP-MM）和加密矩阵转置算法（C-MT），其中我们设计了一个计算成本较低的快速C-MT算法。通过利用高性能BLAS库优化PP-MM，实现了大规模CC-MM并显著提升了性能。此外，我们还提出了轻量级算法，将CC-MM所需的密钥大小从1960 MB降低到1.57 MB，同时保持了相当的效率。

实验结果显示，对于单线程实现，C-MT算法能在$0.76$秒内完成对一个$2\ 048 \times 2\ 048$的加密矩阵进行转置；而我们的CC-MM算法可在$85.2$秒内完成两个$4\ 096 \times 4\ 096$加密矩阵的乘法操作。相较于Jiang-Kim-Lauter-Song在CCS'18会议上提出的最先进的CC-MM方法，我们的算法在处理大规模矩阵时表现出超过$800$倍的性能提升。 <div>
Matrix multiplication of two encrypted matrices (CC-MM) is a key challenge for privacy-preserving machine learning applications. As modern machine learning models focus on scalability, fast CC-MM on large datasets is increasingly in demand.

In this work, we present a CC-MM algorithm for large matrices. The algorithm consists of plaintext matrix multiplications (PP-MM) and ciphertext matrix transpose algorithms (C-MT). We propose a fast C-MT algorithm, which is computationally inexpensive compared to PP-MM. By leveraging high-performance BLAS libraries to optimize PP-MM, we implement large-scale CC-MM with substantial performance improvements. Furthermore, we propose lightweight algorithms, significantly reducing the key size from $1\ 960$ MB to $1.57$ MB for CC-MM with comparable efficiency.

In a single-thread implementation, the C-MT algorithm takes $0.76$ seconds to transpose a $2\ 048\times 2\ 048$ encrypted matrix. The CC-MM algorithm requires $85.2$ seconds to multiply two $4\ 096\times 4\ 096$ encrypted matrices. For large matrices, our algorithm outperforms the state-of-the-art CC-MM method from Jiang-Kim-Lauter-Song [CCS'18] by a factor of over $800$.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 07:30:23 +0000</pubDate>
</item>
<item>
<title>Disincentivize Collusion in Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/446</link>
<guid>https://eprint.iacr.org/2025/446</guid>
<content:encoded><![CDATA[
<div> 关键词: 可验证秘密共享(VSS), 隐私针对性合谋, 冗余机制, 跟踪可访问结构(TAS), 斯蒂尼系统

总结:

本文研究了在可验证秘密共享(VSS)场景中，如何设计和分析阻止持有份额的理性与恶意党派进行隐私针对性合谋的机制。首先，文章提出了两种防止合谋的冗余机制，特别是在希望实现公平性（即非合谋者不受损失）的同时，允许在最佳恶意故障容忍度下恢复秘密的情况下，定义并设计了适用于TAS的专用威慑机制。其次，文中估算了最优TAS的大小，利用斯蒂尼系统构造了它们，并使用部分斯蒂尼系统构建了高度鲁棒的TAS，还为各种参数范围提供了接近最优TAS的高效秘密分享方案。最后，作者展示了TAS中的可追踪性与离散数学中的组合对象如（部分）斯蒂尼系统、受限交集的均匀子集以及适当的二进制码之间的联系，并指出访问结构的鲁棒性等价于超图的最小顶点覆盖问题。文章认为这些密码学、博弈论和离散数学之间的连接具有更广泛的研究价值。 <div>
In verifiable secret sharing (VSS), a dealer shares a secret input among several parties, ensuring each share is verifiable. Motivated by its applications in the blockchain space, we focus on a VSS where parties holding shares are not allowed to reconstruct the dealer's secret (even partially) on their own terms, which we address as privacy-targeted collusion if attempted. 

    In this context, our work investigates mechanisms deterring such collusion in VSS among rational and malicious parties. For this problem, we make both algorithmic and combinatorial contributions:
    1. We provide two collusion-deterrent mechanisms to discourage parties from colluding and recovering the dealer's secret. Notably, when it is desired to achieve fairness---where non-colluding parties are not at a loss---while allowing for the best achievable malicious fault tolerance, we define ``trackable access structures'' (TAS) and design a deterrence mechanism tailored for VSS on these structures. 
    2. We estimate the size of the optimal TAS, construct them from Steiner systems, provide highly robust TAS using partial Steiner systems, and present efficient secret sharing schemes for the latter close-to-optimal TAS for various parameter regimes.
    3. We demonstrate that trackability in access structures is connected to combinatorial objects like (partial) Steiner systems, uniform subsets with restricted intersections, and appropriate binary codes. The robustness of access structures is equivalent to the minimum vertex cover of hypergraphs. 

    We believe these connections between cryptography, game theory, and discrete mathematics will be of broader interest.
]]></content:encoded>
<pubDate>Sun, 09 Mar 2025 00:20:38 +0000</pubDate>
</item>
<item>
<title>Homomorphic Signature-based Witness Encryption and Applications</title>
<link>https://eprint.iacr.org/2025/443</link>
<guid>https://eprint.iacr.org/2025/443</guid>
<content:encoded><![CDATA[
<div> 关键词: 实际应用、签名基础见证加密（SWE）、未来加密、同态SWE（HSWE）、隐私保护

总结:
本文提出了同态签名基础见证加密（HSWE）的概念，以提升定时释放加密方案的实用性。HSWE能够在保持时间释放功能的同时，提高效率并促进部署。文章指出构建HSWE需要依赖于一对加密和签名方案，其中签名的独特性是在加密方案基于单向注入函数时所必需的。接着，文中利用BLS、RSA和Rabin签名技术构建了三种不同的HSWE方案，并展示如何实现一种隐私保护的变体，该变体只允许提取同态聚合的结果，同时保持各个明文的机密性。 <div>
Practical signature-based witness encryption (SWE) schemes recently emerged as a viable alternative to instantiate timed-release cryptography in the honest majority setting. In particular, assuming threshold trust in a set of parties that release signatures at a specified time, one can ``encrypt to the future'' using an SWE scheme. Applications of SWE schemes include voting, auctions, distributed randomness beacons, and more. However, the lack of homomorphism in existing SWE schemes reduces efficiency and hinders deployment. In this work, we introduce the notion of homomorphic SWE (HSWE) to improve the practicality of timed-release encryption schemes. We show one can build HSWE using a pair of encryption and signature schemes where the uniqueness of the signature is required when the encryption scheme relies on injective one-way functions. We then build three HSWE schemes in various settings using BLS, RSA, and Rabin signatures and show how to achieve a privacy-preserving variant that only allows extracting the homomorphically aggregated result while keeping the individual plaintexts confidential
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 17:27:02 +0000</pubDate>
</item>
<item>
<title>A Unified Framework for Succinct Garbling from Homomorphic Secret Sharing</title>
<link>https://eprint.iacr.org/2025/442</link>
<guid>https://eprint.iacr.org/2025/442</guid>
<content:encoded><![CDATA[
<div> 关键词: 密码学、简洁加密方案、Yao's 加密电路构造、同态秘密分享、布尔电路

总结:
本文提出了一种新的简洁加密方案框架，该框架利用轻量级的同态秘密分享技术替代了以往大多数构造中的繁重机制。具体来说，该框架在复合阶或素数阶群以及基于晶格的基础上，实现了布尔电路每门电路只需1比特的（平均）加密大小。同时，这一思想被扩展到分层电路和算术电路中，将每门电路的成本降低至1比特以下，并消除了模p计算通常具有的Ω(λ)-因子开销。这些构建还包括了消除对循环安全要求的“分级”变体，但会在加密大小上增加与深度相关的项。

本研究显著拓展了Liu等人（Eurocrypt 2025）关于基于晶格的简洁加密方案的技术，并为实现实用化的简洁加密开辟了新途径。对于拥有几百万门电路的中等规模电路，我们的加密电路可以比Yao风格的加密电路小两个数量级。虽然我们的加密和解密算法速度较慢，但仍具备实际可行性，这与依赖昂贵工具如iO或FHE和ABE非黑盒组合的先前完全简洁加密方案不同。这种权衡使得当加密电路作为功能密文被广播或存储在多个位置（例如区块链上）时，我们的框架可能会更具吸引力，因为在这种情况下，通信和存储成本可能主导总体开销。 <div>
A major challenge in cryptography is the construction of succinct garbling schemes that have asymptotically smaller size than Yao’s garbled circuit construction. We present a new framework for succinct garbling that replaces the heavy machinery of most previous constructions by lighter-weight homomorphic secret sharing techniques.

Concretely, we achieve 1-bit-per-gate (amortized) garbling size for Boolean circuits under circular variants of standard assumptions in composite-order or prime-order groups, as well as a lattice-based instantiation. We further extend these ideas to layered circuits, improving the per-gate cost below 1 bit, and to arithmetic circuits, eliminating the typical Ω(λ)-factor overhead for garbling mod-p computations. Our constructions also feature “leveled” variants that remove circular-security requirements at the cost of adding a depth-dependent term to the garbling size.

Our framework significantly extends a recent technique of Liu, Wang, Yang, and Yu (Eurocrypt 2025) for lattice-based succinct garbling, and opens new avenues toward practical succinct garbling. For moderately large circuits with a few million gates, our garbled circuits can be two orders of magnitude smaller than Yao-style garbling. While our garbling and evaluation algorithms are much slower, they are still practically feasible, unlike previous fully succinct garbling schemes that rely on expensive tools such as iO or a non-black-box combination of FHE and ABE. This trade-off
can make our framework appealing when a garbled circuit is used as a functional ciphertext that is broadcast or stored in multiple locations (e.g., on a blockchain), in which case communication and storage may dominate computational cost.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 17:14:00 +0000</pubDate>
</item>
<item>
<title>Transmitting Secrets by Transmitting only Plaintext</title>
<link>https://eprint.iacr.org/2025/438</link>
<guid>https://eprint.iacr.org/2025/438</guid>
<content:encoded><![CDATA[
<div> 关键词：加密、标记字母、密钥、隐藏信息、网络安全

总结：
该文提出了一种新的加密使用方式，不是用于隐藏秘密，而是用于标记字母。发送者将2n个字母的明文分为两部分，分别用密钥K1和K2加密得到n个对应的密文字母。尽管发送者同时提供了两个密钥，使得接收者可以轻易解密回原始明文，但其实这个过程暗含了一个秘密消息S，它由n位组成。通过记录经K1和K2加密后的字母混合顺序（共有2^n种可能），可以在看似平常的信息传输中隐藏秘密消息。这种技术可在文本消息平台上应用，使得网络空间中的用户能够在不暴露正在传递秘密信息的情况下进行秘密通信，从而大大提高网络安全性和隐私保护水平。 <div>
Presenting a novel use of encryption, not for hiding a secret, but for marking letters.  Given a 2n letters plaintext, the transmitter encrypts the first n letters with  key K1 to generate corresponding n cipherletters, and encrypts the second n letters with key K2 to generate n corresponding cipherletters. The transmitter sends the 2n cipherletters along with the keys, K1 and K2  The recipient (and any interceptor) will readily decrypt the 2n cipherletters to the original plaintext.  This makes the above procedure equivalent to sending out the plaintext.  So why bother?  When decrypting the 2n cipherletters one will make a note of how the letters that were encrypted with K1 are mixed with the letters encrypted with K2 while keeping the original order of the letters encrypted with each key. There are 2^n possible mixings. Which means that the choice of mixing order can deliver a secret message, S,  comprising n bits. So while on the surface a given plaintext is sent out from transmitter to recipient, this plaintext hides a secret.  Imagine a text messaging platform that uses this protocol. An adversary will not know which plain innocent message harbors a secret message.  This allows residents of cyberspace to communicate secrets without exposing the fact that they communicated a secret. Expect a big impact on the level of cyberspace privacy.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 03:08:44 +0000</pubDate>
</item>
<item>
<title>The 2Hash OPRF Framework and Efficient Post-Quantum Instantiations</title>
<link>https://eprint.iacr.org/2024/450</link>
<guid>https://eprint.iacr.org/2024/450</guid>
<content:encoded><![CDATA[
<div> 关键词：Oblivious Pseudo-Random Function (OPRF)，量子安全，多党计算，Legendre符号，AES加密

总结:<br />
本文提出了一种基于后量子多党计算构建Oblivious Pseudo-Random Function (OPRF)的框架。该框架关注一类被称为“2Hash PRFs”的构造，它们将函数评估置于两个哈希操作之间。核心是一个编译器，能从任何具有抗键碰撞和一更多不可预测性的函数生成OPRF。文章通过使用Legendre符号和AES加密提供了满足要求的此类函数实例，并设计了一个针对Legendre基函数的安全评估协议，该协议结合了盲转移(OT)和零知识证明(ZKP)。当使用基于晶格的OT和ZKPs实现时，文中提出的量子安全OPRF能在0.57秒内完成，通信量少于1MB。 <div>
An Oblivious Pseudo-Random Function (OPRF) is a two-party protocol for jointly evaluating a Pseudo-Random Function (PRF), where a user has an input x and a server has an input k. At the end of the protocol, the user learns the evaluation of the PRF using key k at the value x, while the server learns nothing about the user's input or output. 

OPRFs are a prime tool for building secure authentication and key exchange from passwords, private set intersection, private information retrieval, and many other privacy-preserving systems. While classical OPRFs run as fast as a TLS Handshake, current *quantum-safe* OPRF candidates are still practically inefficient. 

In this paper, we propose a framework for constructing OPRFs from post-quantum multi-party computation. The framework captures a family of so-called "2Hash PRFs", which sandwich a function evaluation in between two hashes. The core of our framework is a compiler that yields an OPRF from a secure evaluation of any function that is key-collision resistant and one-more unpredictable. We instantiate this compiler by providing such functions built from Legendre symbols, and from AES encryption. We then give a case-tailored protocol for securely evaluating our Legendre-based function, built from oblivious transfer (OT) and zero-knowledge proofs (ZKP). Instantiated with lattice-based OT and ZKPs, we obtain a quantum-safe OPRF that completes in 0.57 seconds, with less than 1MB of communication.
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 15:52:21 +0000</pubDate>
</item>
<item>
<title>Matchmaker: Fast Secure Inference across Deployment Scenarios</title>
<link>https://eprint.iacr.org/2025/424</link>
<guid>https://eprint.iacr.org/2025/424</guid>
<content:encoded><![CDATA[
<div> 关键词: Secure Two-Party Computation (2PC), 性能优化, 密钥延迟, 网络速度, Linear Secret Sharing (LSS), Function Secret Sharing (FSS), $LSS^M$, $FSS^M$, CPU, GPU, 异构处理

总结:
本文关注于提升基于Secure Two-Party Computation (2PC) 的安全推理性能，同时考虑了部署场景中的关键因素，如密钥从存储中获取的延迟和网络速度。为了解决这些问题，研究者设计了针对小密钥尺寸优化的LSS-based系统$LSS^M$以及针对通信效率优化的FSS-based系统$FSS^M$。特别地，他们实现了一个高度优化、硬件感知的CPU-based $LSS^M$系统，其性能相比之前的GPU-based LSS系统提高了高达50倍。进一步的研究发现，在特定部署条件下，可以结合使用$LSS^M$与$FSS^M$来利用CPU和GPU之间的异构处理能力。这种协议-系统协同设计方法使得新方案相比于现有最先进的安全推理系统性能提升了最高达21倍（平均提升3.25倍）。 <div>
Secure Two-Party Computation (2PC) enables secure inference with cryptographic guarantees that protect the privacy of the model owner and client. However, it adds significant performance overhead. In this work, we make 2PC-based secure inference efficient while considering important deployment scenarios.   
We observe that the hitherto unconsidered latency of fetching keys from storage significantly impacts performance, as does network speed. We design a Linear Secret Sharing (LSS)-based system $LSS^M$ and a Function Secret Sharing (FSS)-based system $FSS^M$ for secure inference, optimized for small key size and communication, respectively. Notably, our highly-optimized and hardware-aware CPU-based $LSS^M$ outperforms prior GPU-based LSS systems by up to $50\times$. We then show that the best choice between $LSS^M$ and $FSS^M$ depends on the deployment scenario.
In fact, under certain deployments, a combination of $LSS^M$ and $FSS^M$ can leverage heterogeneous processing across CPU and GPU. Such protocol-system co-design lets us outperform state-of-the-art secure inference systems 
by up to $21\times$ (geomean $3.25\times$).
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 11:45:54 +0000</pubDate>
</item>
<item>
<title>Multi-Client Attribute-Based Unbounded Inner Product Functional Encryption, and More</title>
<link>https://eprint.iacr.org/2025/423</link>
<guid>https://eprint.iacr.org/2025/423</guid>
<content:encoded><![CDATA[
<div> 关键词: 多客户端功能加密 (MC-FE)，属性基内积函数 (AB-IP)，无界设置，标准模型，单输入AB-UIPFE

总结:
本文提出了一种针对属性基内积函数的无界多客户端功能加密（MC-AB-UIPFE）方案，该方案在无界设置中不再受向量长度约束，允许秘密密钥支持任意长度的函数，同时客户端可在加密过程中动态选择向量长度。文章基于矩阵决策性Diffie-Hellman假设，在自然许可的无界环境下构建了如下构造：

1. 首个在标准模型下安全的无界单输入AB-UIPFE方案，解决了之前只能加密固定长度数据的问题；
2. 基于相同假设下的首个公共密钥环境中的多输入AB-UIPFE（MI-AB-UIPFE），改进了先前有界的构造；
3. 首个动态分散式无界内积功能加密（DD-UIPFE），提升了前作的动态性属性。

技术上，本文沿袭Agrawal等人[CRYPTO'23]的研究蓝图，但首先提出了一个新的无界FE——扩展槽位无界内积FE。我们首先在标准模型下构建了一个单输入AB-UIPFE，然后将其扩展到多输入场景。总的来说，本文工作展示了内积功能隐藏安全性在实现能够编码无界长度向量（无论是在密钥生成还是加密阶段）的各种多输入FE变体中的应用价值。 <div>
This paper presents the concept of a multi-client functional encryption (MC-FE) scheme for attribute-based inner product functions (AB-IP), initially proposed by Abdalla et al. [ASIACRYPT’20], in an unbounded setting. In such a setting, the setup is independent of vector length constraints, allowing secret keys to support functions of arbitrary lengths, and clients can dynamically choose vector lengths during encryption. The functionality outputs the sum of inner products if vector lengths and indices meet a specific relation, and all clients’ attributes satisfy the key’s policy. We propose the following constructions based on the matrix decisional Diffie-Hellman assumption in a natural permissive setting
of unboundedness:

– the first multi-client attribute-based unbounded IPFE (MC-AB-UIPFE) scheme secure in the standard model, overcoming previous limitations where clients could only encrypt fixed-length data;
– the first multi-input AB-UIPFE (MI-AB-UIPFE) in the public key setting; improving upon prior bounded constructions under the same assumption;
– the first dynamic decentralized UIPFE (DD-UIPFE); enhancing the dynamism property of prior works.

Technically, we follow the blueprint of Agrawal et al. [CRYPTO’23] but begin with a new unbounded FE called extended slotted unbounded IPFE. We first construct a single-input AB-UIPFE in the standard model and then extend it to multi-input settings. In a nutshell, our work demonstrates the applicability of function-hiding security of IPFE in realizing variants of multi-input FE capable of encoding unbounded
length vectors both at the time of key generation and encryption.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 10:45:09 +0000</pubDate>
</item>
<item>
<title>Private Computation on Common Fuzzy Records</title>
<link>https://eprint.iacr.org/2025/422</link>
<guid>https://eprint.iacr.org/2025/422</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人计算、共同记录、模糊记录、有序阈值匹配、电路基私人集合交集协议

总结:
本文研究了如何在基于模糊记录的准标识符上实现私有计算的问题。为了解决这个问题，文章提出了有序阈值一对一(OTO)匹配方法，该方法可以利用电路基私人集合交集(CPSI)协议和多方计算(MPC)技术进行有效实现。此外，文中还引入了一些将传统匹配规则转换为OTO匹配的通用编码技术。最终，作者设计了一个安全高效的私有计算协议，支持多种已广泛应用的匹配规则。

实验验证了该提案的优越性：首先，实证检验表明，对于模糊记录匹配文献中的基准数据集，使用该编码到OTO匹配并不会对准确性造成显著影响；其次，实现了该协议并取得了显著的速度提升，尽管通信开销增加，但与先前的隐私保护记录链接(PPRL)协议相比，在处理每个数据集拥有10万条记录的情况下，通信成本为147.58MB，设置时间为10.71秒，在线时间为1.97秒，整体运行速度提高了约7.78倍（仅考虑在线时间则提升了50.12倍）。 <div>
Private computation on common records refers to analyze data from two databases containing shared records without revealing personal information. As a basic requirement for private computation, the databases involved essentially need to be aligned by a common identification system. However, it is hard to expect such common identifiers in real world scenario. For this reason, multiple quasi-identifiers can be used to identify common records. As some quasi-identifiers might be missing or have typos, it is important to support fuzzy records setting. Identifying common records using quasi-identifiers requires manipulation of highly sensitive information, which could be privacy concerns.

This work studies the problem of enabling such data analysis on the fuzzy records of quasi-identifiers. To this end, we propose ordered threshold-one (OTO) matching which can be efficiently realized by circuit-based private set intersection (CPSI) protocols and some multiparty computation (MPC) techniques. Furthermore, we introduce some generic encoding techniques from traditional matching rules to the OTO matching. Finally, we achieve a secure efficient private computation protocol which supports various matching rules which have already been widely used.

We also demonstrate the superiority of our proposal with experimental validation. First, we empirically check that our encoding to OTO matching does not affect accuracy a lot for the benchmark datasets found in the fuzzy record matching literature. Second, we implement our protocol and achieve significantly faster performance at the cost of communication overhead compared to previous privacy-preserving record linkage (PPRL) protocols. In the case of 100K records for each dataset, our work shows 147.58MB communication cost, 10.71s setup time, and 1.97s online time, which is 7.78 times faster compared to the previous work (50.12 times faster when considering online time only).
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 09:07:21 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Verifiable Aggregation</title>
<link>https://eprint.iacr.org/2025/420</link>
<guid>https://eprint.iacr.org/2025/420</guid>
<content:encoded><![CDATA[
<div> 关键词：Non-Interactive Verifiable Aggregation (NIVA)，Privacy，Robustness，PEAR，Functional Encryption，Fully-Linear Probabilistically-Checkable Proofs，Performance Evaluation

总结:<br />
本文提出了一个新的隐私保护和鲁棒性兼备的非交互式可验证聚合（NIVA）协议——PEAR。该协议旨在让弱分析师能外包大规模客户端数据收集与聚合统计工作给强大的服务器，同时保证客户端数据对服务器和分析师的隐私性，并防止恶意客户端篡改结果。PEAR基于功能加密（inner-product FE）和全线性概率检查证明（fully-linear probabilistically-checkable proofs）的创新结合，允许针对任意NP有效性规则进行输入验证。协议具有非交互、公钥以及黑盒使用底层密码学原语的特点，并为实际相关有效性规则实现了大量优化。文中还实现了PEAR并进行了详尽性能评估，对比两种更直接或“现成”的NIVA协议展现了性能优势，证实了新方法的优势。然而，当前协议的瓶颈在于需要基于大型域上的“无限制”IPFE方案，随着未来此类方案效率的提升，可以直接应用到PEAR中以进一步提高性能。 <div>
Consider a weak analyst that wishes to outsource data collection and computation of aggregate statistics over a a potentially large population of (also weak) clients to a powerful server. For flexibility and efficiency, we consider public-key and non-interactive protocols, meaning the clients know the analyst's public key but do not share secrets, and each client sends at most one message. Furthermore, the final step should be silent, whereby the analyst simply downloads the (encrypted) result from the server when needed. To capture this setting, we define a new primitive  we call Non-Interactive Verifiable Aggregation (NIVA). 
We require both privacy and robustness for a NIVA protocol to be deemed secure. Namely, our security notion for NIVA ensures that the clients' data remains private to both the server and the analyst, while also ensuring that  malicious clients cannot skew the results by providing faulty data.
We propose a secure NIVA protocol, which we call PEAR (for Private, Efficient, Accurate, Robust), which can validate inputs according to any NP validity rule.  PEAR is based on a novel combination of functional encryption for inner-products (Abdalla et al., PKC 2015) and fully-linear probabilistically-checkable proofs (Boneh et al., Crypto 2019). We emphasize that PEAR is non-interactive, public-key, and  makes black-box use of the underlying cryptographic primitives. Additionally, we devise substantial  optimizations of PEAR for practically-relevant validity rules. Finally, we implement PEAR to show feasibility for such validity rules,  conducting a thorough performance evaluation. In particular, we compare PEAR to two more straightforward or "off-the-shelf" NIVA protocols and show performance gains, demonstrating the merit of our new approach. The bottleneck in our protocol comes from the fact that we require the underlying IPFE scheme to be "unrestricted" over a large field. As more efficient such schemes are developed, they can be immediately be plugged into PEAR for further gains.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 04:03:31 +0000</pubDate>
</item>
<item>
<title>Evaluation of Privacy-aware Support Vector Machine (SVM) Learning using Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/417</link>
<guid>https://eprint.iacr.org/2025/417</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私意识机器学习、全同态加密(FHE)、PII、支持向量机(SVM)、OpenFHE库

总结:
这篇论文探讨了使用全同态加密(FHE)解决隐私问题的方法，特别是在涉及PII数据的机器学习训练中的应用。文章中，研究者利用OpenFHE库对SVM机器学习模型进行了加密处理，通过Python和scikit-learn库进行实现。实验考察了一系列变量的影响，包括乘法深度、规模大小、第一模数大小、安全性级别、批处理大小和环维数，同时对比了两种不同的SVM模型：多项式SVM（SVM-Poly）和线性SVM（SVM-Linear）。结果显示，影响性能的主要参数为环维数和模数大小，而SVM-Poly与SVM-Linear在性能表现上相当。 <div>
The requirement for privacy-aware machine learning increases as we continue to use PII (Personally Identifiable Information) within machine training. To overcome these privacy issues, we can apply Fully Homomorphic Encryption (FHE) to encrypt data before it is fed into a machine learning model. This involves creating a homomorphic encryption key pair, and where the associated public key will be used to encrypt the input data, and the private key will decrypt the output. But, there is often a performance hit when we use homomorphic encryption, and so this paper evaluates the performance overhead of using the SVM machine learning technique with the OpenFHE homomorphic encryption library. This uses Python and the scikit-learn library for its implementation.  The experiments include a range of variables such as multiplication depth, scale size, first modulus size, security level, batch size, and ring dimension, along with two different SVM models, SVM-Poly and SVM-Linear. Overall, the results show that the two main parameters which affect performance are the ring dimension and the modulus size, and that SVM-Poly and SVM-Linear show similar performance levels.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 20:01:14 +0000</pubDate>
</item>
<item>
<title>Garblet: Multi-party Computation for Protecting Chiplet-based Systems</title>
<link>https://eprint.iacr.org/2025/413</link>
<guid>https://eprint.iacr.org/2025/413</guid>
<content:encoded><![CDATA[
<div> 关键词：芯片模块化、安全威胁、Garblet、Garbled Circuits（GC）、Oblivious Transfer（OT）

<br /><br />总结：

本文提出了一个名为Garblet的新框架，用于应对由异构芯片模块化架构引入的安全威胁。该框架利用芯片模块技术与基于Garbled Circuits（GC）的多方计算，确保在潜在恶意芯片let环境中也能实现高效、安全的计算。Garblet将定制化的硬件Oblivious Transfer（OT）模块和优化的评估器引擎集成到基于芯片模块的平台上，通过在两个芯片模块之间分配电路的加扰和评估任务，降低通信成本并提升计算速度。文章在AMD/Xilinx UltraScale+多芯片模块上实现了这一框架，并通过基准函数展示了其实效性。此外，文中还介绍了一种新的电路分解技术，允许在多个芯片模块间进行并行处理，从而进一步提高计算效率。实验结果显示，芯片模块系统有望加速GC计算，例如加扰AES的时间复杂度可降至0.0226毫秒，有效保障了芯片模块计算的安全性和隐私性。 <div>
The introduction of shared computation architectures assembled from
heterogeneous chiplets introduces new security threats. Due to the shared logical and physical resources, an untrusted chiplet can act maliciously to surreptitiously probe the data communication between chiplets or sense the computation shared between them. This paper presents Garblet, the first framework to leverage the flexibility offered by chiplet technology and Garbled Circuits (GC)-based MPC to enable efficient, secure computation even in the presence of potentially compromised chiplets. Our approach integrates a customized hardware Oblivious Transfer (OT) module and an optimized evaluator engine into chiplet-based platforms. This configuration distributes the tasks of garbling and evaluating circuits across two chiplets, reducing communication costs and enhancing computation speed. We implement this framework on an AMD/Xilinx UltraScale+ multi-chip module and demonstrate its effectiveness using benchmark functions. Additionally, we introduce a novel circuit decomposition technique that allows for parallel processing across multiple chiplets to further improve computational efficiency. Our results highlight the potential of chiplet systems for accelerating GC (e.g., the time complexity of garbled AES is 0.0226ms) in order to guarantee the security and privacy of the computation on chiplets.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 16:32:54 +0000</pubDate>
</item>
<item>
<title>Multi-Authority Functional Encryption: Corrupt Authorities, Dynamic Collusion, Lower Bounds, and More</title>
<link>https://eprint.iacr.org/2025/412</link>
<guid>https://eprint.iacr.org/2025/412</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化、多权威功能性加密（MAFE）、区块链、安全多方计算、公钥加密（PKE）

总结：

本文研究了多权威功能性加密（MAFE）问题，这是一种分布式加密系统的流行形式。文章主要贡献如下：<br />
1. 设计了一种适用于所有多项式大小电路的MAFE方案，基于PKE和OWFs的最小假设，改进了先前需要次指数级安全的混淆、$\log n$-党派密钥交换或随机预言机与次指数级安全PKE的需求。此外，在IBE和OWFs的最小假设下，我们还将其扩展到动态共谋模型，并且该系统真正动态，不限制最大权限数量。<br />
2. 在学习带有错误（LWE）假设下，设计了一个允许对手自适应腐败局部权限的MAFE方案，其中敌手可以腐蚀任意$k$个($k$小于等于$n$，且${n}\choose{k}$为多项式阶的$\lambda$)局部权限。这比先前依赖次指数级安全混淆的方案有所改进，并提出了一个新的MAFE编译器，用于将选择性权限腐败提升为非自适应权限腐败。<br />
3. 证明了MAFE与(变种模糊/不可区分性)混淆之间的紧密蕴含关系，表明只有当所有被腐败的局部权限共同控制的属性位数大于$\omega(\log \lambda)$时，MAFE才意味着混淆。这证明了对于广泛参数范围内的第二个结果的最优性。<br />
4. 提出了一种新的MAFE系统，称为多权威属性基功能加密（MA-ABFE），旨在融合完全共谋抵抗的MA-ABE和有限共谋抵抗的MAFE的优势。结合现有MA-ABE结果，从标准双线性配对假设出发，获得了适用于$\mathsf{NC}^1 \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE；从LWE假设出发，在随机预言机模型中获得了适用于$\mathsf{DNF} \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE；并描述了一个基于见证加密的简单MA-ABE构造，以及通过已知结果，得到了适用于$\mathsf{P}/\mathsf{Poly} \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE，这是从逃避型LWE假设得出的。 <div>
Decentralization is a great enabler for adoption of modern cryptography in real-world systems. Widespread adoption of blockchains and secure multi-party computation protocols are perfect evidentiary examples for dramatic rise in deployment of decentralized cryptographic systems. Much of cryptographic research can be viewed as reducing (or eliminating) the dependence on trusted parties, while shielding from stronger adversarial threats. In this work, we study the problem of multi-authority functional encryption (MAFE), a popular decentralized generalization of functional encryption (FE). Our main contributions are:

    1. We design MAFE for all poly-sized circuits, in the bounded collusion model, under the minimal assumption of PKE/OWFs. Prior to our work, this required either sub-exponentially secure obfuscation, or $\log n$-party key exchange, or Random Oracles and sub-exponentially secure PKE. We also extend our constructions to the dynamic collusion model under the minimal assumptions of IBE/OWFs. Unlike all prior works, our MAFE systems are truly dynamic and put no restrictions on the maximum number of authorities.

    2. Under the hardness of learning with errors (LWE) assumption, we design MAFE for all poly-sized circuits where we allow adversaries to adaptively corrupt local authorities. We allow an adversary to corrupt any $k$ out of $n$ local authorities as long as ${{n}\choose{k}}$ = poly$(\lambda)$. Prior to this, such MAFE relied on sub-exponentially secure obfuscation. Additionally, we design a new MAFE compiler for boosting selective authority corruptions to non-adaptive authority corruptions.

    3. We prove a tight implication from MAFE to (VBB/indistinguishability) obfuscation. We show that MAFE implies obfuscation only if the number of attribute bits (jointly) controlled by all corrupt local authorities is $\omega(\log \lambda)$. This proves optimality of our second result for a wide range of parameters.

    4. Finally, we propose a new MAFE system that we refer to as multi-authority attribute-based functional encryption (MA-ABFE). We view it as an approach to get best of both worlds (fully collusion resistant MA-ABE, and bounded collusion resistant MAFE). By combining our results with prior MA-ABE results, we obtain MA-ABFE for $\mathsf{NC}^1 \circ \mathsf{P}/\mathsf{Poly}$ from standard pairing-based assumptions, and for $\mathsf{DNF} \circ \mathsf{P}/\mathsf{Poly}$ from LWE, both in the Random Oracle Model. We also describe a simple construction of MA-ABE for general predicates from witness encryption, and combining with known results, we also get MA-ABFE for $\mathsf{P}/\mathsf{Poly} \circ \mathsf{P}/\mathsf{Poly}$ from evasive LWE.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 14:22:01 +0000</pubDate>
</item>
<item>
<title>Hybrid Obfuscated Key Exchange and KEMs</title>
<link>https://eprint.iacr.org/2025/408</link>
<guid>https://eprint.iacr.org/2025/408</guid>
<content:encoded><![CDATA[
<div> 关键词：元数据隐藏、互联网协议、加密协议、后量子安全、OKEMs<br /><br />总结:

本文关注于互联网协议中元数据隐藏的重要性，以及在后量子时代实现完全加密协议的安全性。现有的如Tor的pluggable transport协议obfs4依赖于Diffie-Hellman和Elligator编码进行密钥交换的模糊处理。然而，目前还没有提供混合模糊保障的OKEM（模糊密钥封装机制）用于实际过渡协议。文章提出了首个同时具备混合IND-CCA安全性和混合模糊保证的OKEM组合器，并基于此构建了Drivel协议，使其与混合OKEM兼容。此外，文章还介绍了如何实现LWE基OKEM的无条件公钥模糊化，并探讨了包括构建第一个在UC模型下抗适应性破坏的混合密码验证密钥交换（PAKE）协议在内的混合OKEM更广泛的应用。 <div>
Hiding the metadata in Internet protocols serves to protect user privacy, dissuade traffic analysis, and prevent network ossification. Fully encrypted protocols require even the initial key exchange to be obfuscated: a passive observer should be unable to distinguish a protocol execution from an exchange of random bitstrings. Deployed obfuscated key exchanges such as Tor's pluggable transport protocol obfs4 are Diffie–Hellman-based, and rely on the Elligator encoding for obfuscation. Recently, Günther, Stebila, and Veitch (CCS '24) proposed a post-quantum variant pq-obfs, using a novel building block called obfuscated key encapsulation mechanisms (OKEMs): KEMs whose public keys and ciphertexts look like random bitstrings.

For transitioning real-world protocols, pure post-quantum security is not enough. Many are taking a hybrid approach, combining traditional and post-quantum schemes to hedge against security failures in either component. While hybrid KEMs are already widely deployed (e.g., in TLS 1.3), existing hybridization techniques fail to provide hybrid obfuscation guarantees for OKEMs. Further, even if a hybrid OKEM existed, the pq-obfs protocol would still not achieve hybrid obfuscation.

In this work, we address these challenges by presenting the first OKEM combiner that achieves hybrid IND-CCA security with hybrid ciphertext obfuscation guarantees, and using this to build Drivel, a modification of pq-obfs that is compatible with hybrid OKEMs. Our OKEM combiner allows for a variety of practical instantiations, e.g., combining obfuscated versions of DHKEM and ML-KEM. We additionally provide techniques to achieve unconditional public key obfuscation for LWE-based OKEMs, and explore broader applications of hybrid OKEMs, including a construction of the first hybrid password-authenticated key exchange (PAKE) protocol secure against adaptive corruptions in the UC model.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:52:26 +0000</pubDate>
</item>
<item>
<title>Provably Secure Approximate Computation Protocols from CKKS</title>
<link>https://eprint.iacr.org/2025/395</link>
<guid>https://eprint.iacr.org/2025/395</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全多方计算、同态加密、CKKS方案、噪音模糊技术、分布式采样

总结:
本文研究了基于CKKS方案的安全近似多方计算问题。首先分析了在两方设置中，CKKS基础协议的应用情况：当仅一方持有私人输入而另一方作为评估者时，通过在加密方使用噪音模糊技术可实现标准意义上的安全性。当双方都具有私人输入时，现有协议只能满足宽松的“自由安全”定义，为此，文章提出了一种新的协议，利用分布式采样方法在安全环境下生成模糊噪音，从而满足标准安全性定义。进一步地，将两方协议扩展到多方面设置，由于现有的基于阈值的CKKS多方计算协议仅能满足“自由安全”，文中提出一种新颖的多方面协议，通过应用多方分布式采样生成模糊误差来实现标准安全性。对于所有提出的协议，作者均形式化定义了其功能并在基于模拟的安全框架下进行了严谨的安全性分析。据作者所知，这是首次对基于CKKS的近似多方计算功能进行明确定义并实现正式的安全性保证的工作。 <div>
Secure multi-party computation (MPC) enables collaborative, privacy-preserving computation over private inputs. Advances in homomorphic encryption (HE), particularly the CKKS scheme, have made secure computation practical, making it well-suited for real-world applications involving approximate computations. However, the inherent approximation errors in CKKS present significant challenges in developing MPC protocols.

This paper investigates the problem of secure approximate MPC from CKKS. We first analyze CKKS-based protocols in two-party setting. When only one party holds a private input and the other party acts as an evaluator, a simple protocol with the noise smudging technique on the encryptor's side achieves security in the standard manner. When both parties have private inputs, we demonstrate that the protocol incorporating independent errors from each party achieves a relaxed standard security notion, referred to as a liberal security. Nevertheless, such a protocol fails to satisfy the standard security definition. To address this limitation, we propose a novel protocol that employs a distributed sampling approach to generate smudging noise in a secure manner, which satisfies the standard security definition. 

Finally, we extend the two-party protocols to the multi-party setting. Since the existing threshold CKKS-based MPC protocol only satisfies the liberal security, we present a novel multi-party protocol achieving the standard security by applying multi-party distributed sampling of a smudging error. 

For all the proposed protocols, we formally define the functionalities and provide rigorous security analysis within the simulation-based security framework. To the best of our knowledge, this is the first work to explicitly define the functionality of CKKS-based approximate MPC and achieve formal security guarantees.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 02:34:42 +0000</pubDate>
</item>
<item>
<title>An Efficient Quantum Oblivious Transfer Protocol</title>
<link>https://eprint.iacr.org/2025/393</link>
<guid>https://eprint.iacr.org/2025/393</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious Transfer (OT), 量子OT (qOT), 单光子, 项目测量, 长期安全

总结:
本文介绍了量子隐私保护协议的重要组成部分——量子版的 Oblivious Transfer (qOT)。现有的经典 OT 协议基于非量子安全的数论假设，而许多量子 OT 协议效率不高或不够实用。文章提出了一种名为 qOT 的简洁高效量子 OT 协议，它利用了 Gao 等人提出的非对称密钥分布作为构建模块。qOT 协议仅需要单光子作为量子态源，并通过单粒子投影测量来计算状态，这使得 qOT 在实际应用中更为高效。此外，该设计被证明能抵抗量子攻击，并提供长期安全性。 <div>
Oblivious Transfer (OT) is a significant two party privacy preserving cryptographic primitive. OT involves a sender having several pieces of information and a receiver having a choice bit. The choice bit represents the piece of information that the receiver wants to obtain as an output of OT. At the end of the protocol, sender remains oblivious about the choice bit and receiver remains oblivious to the contents of the information that were not chosen. It has applications ranging from secure multi-party computation, privacy-preserving protocols to cryptographic protocols for secure communication. Most of the classical OT protocols are based on number theoretic assumptions which are not quantum secure and existing quantum OT protocols are not so efficient and practical. Herein, we present the design and analysis of a simple yet efficient quantum OT protocol, namely qOT. qOT is designed by using the asymmetric key distribution proposed by Gao et al. [18] as a building block. The designed qOT requires only single photons as a source of a quantum state, and the measurements of the states are computed using single particle projective measurement. These make qOT efficient and practical. Our proposed design is secure against quantum attacks. Moreover, qOT also provides long-term security.
]]></content:encoded>
<pubDate>Sun, 02 Mar 2025 13:47:20 +0000</pubDate>
</item>
<item>
<title>Blockchain-based Secure D2D localisation with adaptive precision</title>
<link>https://eprint.iacr.org/2025/392</link>
<guid>https://eprint.iacr.org/2025/392</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全、最佳努力、局部化信息、分布式账本、智能合约

总结:
本文提出了一种安全的最佳努力方法，用于在异构网络中为无法访问GPS或重型加密基础设施的设备提供局部化信息。该方法使每个设备仅基于其相邻锚点提供的数据就能计算出自身位置，以最高精度保证定位准确性。通过利用智能合约在分布式账本上注册局部化信息，确保了定位服务的安全性。文中证明了方案在适应性选择消息攻击模型下的安全性。此外，作者通过以Hyperledger Besu与QBFT共识作为案例研究，评估了该解决方案的有效性，具体考察了平均注册位置时间、失败请求以及总执行时间等指标。 <div>
In this paper we propose a secure  best effort methodology for providing localisation information to devices in a heterogenous network where devices do not have access to GPS-like technology or heavy cryptographic infrastructure. Each device will compute its localisation with the highest possible accuracy  based solely on the data provided by its neighboring anchors. The security of the localisation is guarantied by registering the localisation information on  a distributed ledger via smart contracts. We prove the security of our solution under  the adaptive chosen  message attacks model. We furthermore evaluate the effectiveness of our solution by measuring the  average register location time,  failed  requests, and total execution time using as DLT case study Hyperledger Besu with QBFT consensus.
]]></content:encoded>
<pubDate>Sun, 02 Mar 2025 10:11:56 +0000</pubDate>
</item>
<item>
<title>Fair Exchange for Decentralized Autonomous Organizations via Threshold Adaptor Signatures</title>
<link>https://eprint.iacr.org/2025/388</link>
<guid>https://eprint.iacr.org/2025/388</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Organization (DAO)，公平交换，区块链，加密机制，智能合约，多党派管理，数字资产，见证分享，签名密钥分享，资金转移，公平性保障，DAO间公平性，DAO内公平性，标准密码学假设，高效协议，认证见证加密，门限适配器签名。

<br /><br />总结:
本文关注的是在不依赖智能合约的情况下，通过一种基于区块链技术的加密机制实现DAO间的公平交换。研究场景涉及由$n_\mathsf{S}$个卖家持有的见证分享$w$与由$n_\mathsf{B}$个买家持有的签名密钥分享$sk$之间的交互，目标是以预定金额的资金转移换取$w$。文章提出了DAO间及DAO内部的双重公平性要求：只有当双方DAO都完成资产交换时，各自的成员才能获取相应的资产。为达成这一目标，文章形式化定义了公平性属性并设计了一个高效的协议，该协议利用了认证见证加密和门限适配器签名这两个具有独立研究价值的新颖原语，并展示了它们的高效构建方法。 <div>
A Decentralized Autonomous Organization (DAO) enables multiple parties to collectively manage digital assets in a blockchain setting. We focus on achieving fair exchange between DAOs using a cryptographic mechanism that operates with minimal blockchain assumptions and, crucially, does not rely on smart contracts.  

Specifically, we consider a setting where a DAO consisting of $n_\mathsf{S}$ sellers holding shares of a witness $w$ interacts with a DAO comprising $n_\mathsf{B}$ buyers holding shares of a signing key $sk$; the goal is for the sellers to exchange $w$ for a signature under $sk$ transferring a predetermined amount of funds.  
Fairness is required to hold both between DAOs (i.e., ensuring that each DAO receives its asset if and only if the other does) as well as within each DAO (i.e., ensuring that all members of a DAO receive their asset if and only if every other member does).  

We formalize these fairness properties and present an efficient protocol for DAO-based fair exchange under standard cryptographic assumptions. Our protocol leverages certified witness encryption and threshold adaptor signatures, two primitives of independent interest that we introduce and show how to construct efficiently.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 21:49:09 +0000</pubDate>
</item>
<item>
<title>Generic Composition: From Classical to Quantum Security</title>
<link>https://eprint.iacr.org/2025/387</link>
<guid>https://eprint.iacr.org/2025/387</guid>
<content:encoded><![CDATA[
<div> 关键词: Authenticated encryption, Encrypt-then-MAC, Quantum setting, Chosen-ciphertext security, Quantum pseudorandom function<br /><br />总结:<br />
该文研究了量子环境下的Encrypt-then-MAC组合的安全性，其中攻击者对加密和响应的查询可能处于叠加状态。文章指出，当使用选择明文（IND-qCPA）安全的对称加密方案SE与加一不可伪造MAC结合时，Encrypt-then-MAC组合无法实现选择密文（IND-qCCA）安全性。然而，通过将MAC替换为量子伪随机函数（qPRF），Encrypt-then-MAC或Encrypt-and-MAC组合能够确保IND-qCCA安全性。 <div>
Authenticated encryption (AE) provides both authenticity and privacy.
Starting with Bellare's and Namprempre's work in 2000, the Encrypt-then-MAC composition of an encryption scheme for privacy and a MAC for authenticity has become a well-studied and common approach.
This work investigates the security of the Encrypt-then-MAC composition in a quantum setting which means that adversarial queries as well as the responses to those queries may be in superposition.
We demonstrate that the Encrypt-then-MAC composition of a chosen-plaintext (IND-qCPA) secure symmetric encryption scheme SE and a plus-one unforgeable MAC fails to achieve chosen-ciphertext (IND-qCCA) security.
On the other hand, we show that it suffices to choose a quantum pseudorandom function (qPRF) as the MAC.
Namely, the Encrypt-then-MAC composition of SE and a qPRF is IND-qCCA secure.
The same holds for the Encrypt-and-MAC composition of SE and a qPRF
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 16:45:24 +0000</pubDate>
</item>
<item>
<title>On the Security and Privacy of CKKS-based Homomorphic Evaluation Protocols</title>
<link>https://eprint.iacr.org/2025/382</link>
<guid>https://eprint.iacr.org/2025/382</guid>
<content:encoded><![CDATA[
<div> 关键词: CKKS、同态加密、差分隐私、DPHE协议、零知识证明<br /><br />总结:
本文提出了一种针对基于CKKS的同态加密协议的新定义——差分隐私同态评估(DPHE)协议。该定义将发送者的隐私条件从不可区分性放松到差分隐私的范畴，重点关注PPML协议中评价结果的差分隐私而非仿真可评估性。作者证明了如果理想功能满足差分隐私，且一个协议满足DPHE，则其输出也满足差分隐私。文章进一步提供了一个通用编译器，通过结合拉普拉斯机制和CKKS的零知识论证知识(ZKAoK)，将普通的CKKS协议转换为DPHE协议，实现了发送者隐私保护并降低了噪声。同时，文章对CKKS的ZKAoK进行了具体实现，采用PIOP形式，并设计了新的验证技术，利用同态计算在验证过程中证明CKKS密文和公钥的正确性。最后，作者通过使用HSS多项式承诺方案实现了PIOP的编译，展示了所提ZKAoK应用于CKKS的实用性。 <div>
CKKS is a homomorphic encryption (HE) scheme that supports arithmetic over complex numbers in an approximate manner. 
Despite its utility in PPML protocols, formally defining the security of CKKS-based protocols is challenging due to its approximate nature.
To be precise, in a sender-receiver model, where the receiver holds input ciphertexts and the sender evaluates its private circuit, it is difficult to define sender's privacy in terms of indistinguishability, whereas receiver's privacy is easily achieved through the semantic security of CKKS.

In this paper, we present a new definition for CKKS-based protocols, called Differentially Private Homomorphic Evaluation (DPHE) protocols, along with a general method to achieve this.
In our definition, we relax the sender’s privacy condition from indistinguishability to differential privacy notion. 
We focus on the fact that most security concern for PPML protocols is differential privacy on evaluation results, rather than the simulatability of the evaluation.
We prove that if the ideal functionality satisfies differential privacy and a protocol satisfies DPHE, then the output of the protocol also satisfies differential privacy.

Next, we provide a general compiler that transforms a plain CKKS-based protocol into a DPHE one. 
We achieve this by mixing the Laplace mechanism and zero-knowledge argument of knowledge (ZKAoK) for CKKS. 
This approach allows us to achieve sender's privacy with a moderate noise, whereas the previous indistinguishability-based approach requires exponentially large overhead.

Finally, we provide a concrete instantiation of ZKAoK for CKKS in the form of PIOP.
To prove the well-formedness of CKKS ciphertexts and public keys, we devise new proof techniques that use homomorphic evaluation during verification.
We also provide an implementation to demonstrate the practicality of our ZKAoK for CKKS by compiling PIOPs using the HSS polynomial commitment scheme (Crypto'24).
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 03:24:53 +0000</pubDate>
</item>
<item>
<title>Functional Oblivious Transfer with Applications in Privacy-Preserving Machine Learning</title>
<link>https://eprint.iacr.org/2025/371</link>
<guid>https://eprint.iacr.org/2025/371</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious Transfer (OT), Functional OT (FOT), 加密原语, 隐私保护机器学习, Federated Learning (FL)

总结:
本文首次提出了功能性隐匿传输(FOT)的概念，这是一种对传统隐匿传输的增强，确保接收者只能了解到所选消息的函数值而非具体的消息本身。文中提出了一系列实现FOT的协议，针对求平均值、众数、加法和乘法等特定函数进行了具体的实例化设计。这些方案高效且无条件安全。此外，还提到了一个利用全同态加密(FHE)和 oblivionous 线性函数评估来支持任意函数的非平凡协议，其对消息数量 n 的 FHE 调用次数为常数 O(1)。文章通过渐进和具体的成本分析展示了无条件安全的 FOT 协议的效率。FOT 可以提升隐私保护机器学习的安全性，尤其是在K-最近邻算法和联邦学习中的客户端选择场景中。 <div>
Oblivious Transfer (OT) is a fundamental cryptographic primitive introduced nearly four decades ago. OT allows a receiver to select and learn $t$ out of $n$ private messages held by a sender. It ensures that the sender does not learn which specific messages the receiver has chosen, while the receiver gains no information about the remaining $n − t$ messages. In this work, we introduce the notion of functional OT (FOT), for the first time. FOT adds a layer of security to the conventional OT by ensuring that the receiver only learns a function of the selected messages rather than the $t$ individual messages themselves. We propose several protocols that realize this concept. In particular, we propose concrete instantiations of FOT when the function to be executed on the selected message is mean, mode, addition, or multiplication. The schemes are efficient and unconditionally secure. We also propose a non-trivial protocol that supports arbitrary functions on the selected messages mainly using fully homomorphic encryption (FHE) and oblivious linear function evaluation, where the number of FHE invocations is constant $O(1)$ with respect to $n$. Our asymptotic and concrete cost analyses demonstrate the efficiency of our unconditionally secure FOT protocols. FOT can enhance the security of privacy-preserving machine learning, particularly in (i) K-Nearest Neighbors schemes and (ii) client selection in Federated Learning (FL).
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 19:00:47 +0000</pubDate>
</item>
<item>
<title>Higher Residuosity Attacks on Small RSA Subgroup Decision Problems</title>
<link>https://eprint.iacr.org/2025/369</link>
<guid>https://eprint.iacr.org/2025/369</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全两方比较、同态加密、 Carlton et al.、Bourse et al.、高次剩余攻击

总结:
本文关注于安全两方比较这一隐私保护计算中的核心问题，特别是在基于同态加密的解决方案上。Carlton et al.和Bourse et al.提出的新型协议相较于传统的DGK协议，已经展现出显著的性能提升。然而，文章中引入了一类新的高次剩余攻击，将其视为对决策性Diffie-Hellman问题的经典二次剩余攻击的扩展。研究发现，CEK和BST协议所依赖的小RSA子群决策问题在素基数$p_0$较小时（如$p_0 < 100$）并不难解决，这使得这两种协议在这些条件下达到最优整体性能。对此，文章给出了防范此类攻击的建议，其中包括一种不会影响协议性能的方法。同时，作者希望这种攻击分析方法可以应用于其他数论难度假设的研究中。<br /><br /> <div>
Secure two-party comparison, known as Yao's millionaires' problem, has been a fundamental challenge in privacy-preserving computation. It enables two parties to compare their inputs without revealing the exact values of those inputs or relying on any trusted third party. One elegant approach to secure computation is based on homomorphic encryption. Recently, building on this approach, Carlton et al. (CT-RSA 2018) and Bourse et al. (CT-RSA 2020) presented novel solutions for the problem of secure integer comparison. These protocols have demonstrated significantly improved performance compared to the well-known and frequently used DGK protocol (ACISP 2007 and Int. J. Appl. Cryptogr. 1(4),323–324, 2009). In this paper, we introduce a class of higher residuosity attacks, which can be regarded as an extension of the classical quadratic residuosity attack on the decisional Diffie-Hellman problem. We demonstrate that the small RSA subgroup decision problems, upon which both the CEK and BST protocols are based, are not difficult to solve when the prime base $p_0$ is small (e.g., \( p_0 < 100 \)). Under these conditions, the protocols achieve optimal overall performance. Furthermore, we offer recommendations for precluding such attacks, including one approach that does not adversely affect performance. We hope that these attacks can be applied to analyze other number-theoretic hardness assumptions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 11:42:03 +0000</pubDate>
</item>
<item>
<title>Traitor Tracing in Multi-sender Setting ($\textsf{TMCFE}$: Traceable Multi-client Functional Encryption)</title>
<link>https://eprint.iacr.org/2025/364</link>
<guid>https://eprint.iacr.org/2025/364</guid>
<content:encoded><![CDATA[
<div> 关键词：traitor tracing、functional encryption、multi-client functional encryption、traceable multi-client functional encryption、lattice-based security

总结:<br />
本文提出了一个新的密码学原语——可追踪多客户端功能加密（$\textsf{TMCFE}$），旨在解决多发送者环境下隐私保护联合计算中的背叛追溯问题。传统背叛追溯技术仅限于单一发送者场景，而本文概念性地将这一框架扩展到多发送者加密中，允许追踪来自接收者和发送者的秘密信息泄露源头。从技术层面，文章基于近期提出的强可承认性概念构建了一个通用编译器，该编译器能将具有弱可承认性的多客户端功能加密方案转化为具有强可承认性的方案，克服了现有挑战并可能在功能性加密领域具有广泛应用价值。此外，文中还提供了一种针对内积功能的基于晶格的安全实现$\textsf{TMCFE}$方案，该方案在标准假设下具备后量子安全性。 <div>
Traitor tracing is a traditional cryptographic primitive designed for scenarios with multiple legitimate receivers. When the plaintext - that is, the output of decryption - is leaked and more than one legitimate receiver exists, it becomes imperative to identify the source of the leakage, a need that has motivated the development of traitor tracing techniques. Recent advances in standard encryption have enabled decryption outcomes to be defined in a fine-grained manner through the introduction of Functional Encryption (FE). Constructing FE schemes is intriguing, and achieving the tracing property adds an additional layer of complexity. Traitor tracing techniques have been actively developed for more than three decades, yet they have always remained within the same framework - a single sender responsible for encrypting all the data.

However, fine-grained decryption is particularly useful when data originates from multiple sources, allowing for joint computation on personal data. This leads to the concept of multi-client functional encryption (MCFE), where multiple concurrent senders independently encrypt their data while agreeing on the decryption of a specific function (e.g., a statistical measure) computed on the aggregated data, without revealing any additional information. In the era of cloud computing and big data, privacy-preserving joint computation is crucial, and tracing the source of any breach by dishonest participants becomes essential. Thus, in this paper we take the first step toward addressing the tracing problem in the general context of joint computation with multiple senders. Our contributions are twofold:
  - $\textbf{Conceptually:}$ We propose the first tracing model in the context of multi-sender encryption, namely $\textit{Traceable Multi-Client Functional Encryption}$ ($\textsf{TMCFE}$), which allows a pirate to extract secret information from both receivers and senders. Our model supports strong and naturally admissible decoders, removing artificial restrictions on the pirate decoder and thus addressing the shortcomings of existing traceable functional encryption schemes designed for the single-sender setting.
  - $\textbf{Technically:}$ To achieve our conceptual objective, we build upon the recently introduced notion of strong admissibility for MCFE. Our main technical contribution is a generic compiler that transforms a large class of MCFE schemes with weak admissibility into schemes with strong admissibility. This compiler not only helps overcome existing challenges but may also be of general interest within the functional encryption domain. Finally, we present a concrete lattice-based scheme $\textsf{TMCFE}$ for inner-product functionalities that achieves post-quantum security under standard assumptions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 10:11:10 +0000</pubDate>
</item>
<item>
<title>Identity-based Matchmaking Encryption with Stronger Security and Instantiation on Lattices</title>
<link>https://eprint.iacr.org/2022/1718</link>
<guid>https://eprint.iacr.org/2022/1718</guid>
<content:encoded><![CDATA[
<div> 关键词:身份基匹配加密(IB-ME), 匿名性, 认证安全性, 量子攻击, 环境适应性<br /><br />总结:
本文针对现有的身份基匹配加密(IB-ME)方案在对抗量子攻击和可能存在的潜在威胁方面的不足，提出了更强的安全定义——考虑了新的攻击方式以适应现实世界场景。文中首先提出了一种基于两层匿名层级身份基加密(HIBE)和身份基签名(IBS)的IB-ME通用构建方法。此外，为了提升基于格的IB-ME效率，文章还改进了一个基于格的IBS，缩短其签名长度，从而减少了最终IB-ME密文的大小。通过将改进后的IBS与任何具备匿名性和适应性安全性的二级基于格的HIBE相结合，最终实现了首个直接实现IB-ME的基于格的构造方案。 <div>
An identity-based matchmaking encryption (IB-ME) scheme proposed at JOC 2021 supports anonymous but authenticated communications in a way that communication parties can both specify the senders or receivers on the fly. IB-ME is easy to be used in several network applications requiring privacy-preserving for its efficient implementation and special syntax. In the literature, IB-ME schemes are built from the variants of Diffie-Hellman assumption and all fail to retain security for quantum attackers. Despite the rigorous security proofs in previous security models, the existing schemes are still possibly vulnerable to some potential neglected attacks. Aiming at the above problems, we provide a stronger security definition of authenticity considering new attacks to fit real-world scenarios and then propose a generic construction of IB-ME satisfying the new model. Inspired by the prior IB-ME construction of Chen et al., the proposed scheme is constructed by combining 2-level anonymous hierarchical IBE (HIBE) and identity-based signature (IBS) schemes. In order to upgrade lattice-based IB-ME with better efficiency, we additionally improve a lattice IBS, as an independent technical contribution, to shorten its signature and thus reduce the final IB-ME ciphertext size. By combining the improved IBS and any 2-level adaptively-secure lattice-based HIBE with anonymity, we finally obtain the first lattice-based construction that implements IB-ME directly.
]]></content:encoded>
<pubDate>Mon, 12 Dec 2022 08:03:11 +0000</pubDate>
</item>
<item>
<title>OCash: Fully Anonymous Payments between Blockchain Light Clients</title>
<link>https://eprint.iacr.org/2024/246</link>
<guid>https://eprint.iacr.org/2024/246</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、匿名支付系统、轻客户端、全节点、UC模型

总结:
本文研究了一种基于区块链的轻客户端之间的可验证匿名支付系统。该系统中，轻客户端通过全节点与区块链交互，而全节点可以看到轻客户端的读写操作。文章旨在实现即使在面对能观察到数据元素移动情况的全节点情况下，也能保障轻客户端进行匿名支付并维持隐私的目标。作者在UC模型下对问题进行了形式化定义，并提出了一种可证明安全的解决方案。他们展示了一种树ORAM的变体可以实现即使对手能够追踪其自身数据元素在树中的移动也能够保持无感知性。利用这一特性，文章实现了在区块链上的支付混淆以保证匿名性，同时允许轻客户端在不知道当前区块链状态的情况下知道其支付可能存在的几个位置。相较于现有工作，本文首次同时提供了强匿名性保证、可证明的安全性和针对全节点的匿名性。此外，文中还做出了一些独立贡献，包括定义并构建了适用于匿名支付系统的匿名币友好加密方案，以及定义和构造了高效的可压缩随机性信标，这种信标能够在规定时间间隔内生成不可预测的值，并能将其所有发布的值存储在一个简短的摘要中。 <div>
We study blockchain-based provably anonymous payment systems between light clients. Such clients interact with the blockchain through full nodes, which can see what the light clients read and write. The goal of our work is to enable light clients to perform anonymous payments, while maintaining privacy even against the full nodes through which they interact with the blockchain. We formalize the problem in the UC model and present a provably secure solution. We show that a variation of tree ORAM gives obliviousness even when an adversary can follow how its own data elements move in the tree. We use this for anonymity via shuffling of payments on the blockchain, while at the same time allowing the light client to know a few positions among which to find its payment without knowing the current state of the blockchain. In comparison to existing works, we are the first ones that simultaneously provide strong anonymity guarantees, provable security, and anonymity with respect to full nodes. Along the way, we make several contributions that may be of independent interest. We define and construct anonymous-coin friendly encryption schemes and show how they can be used within anonymous payment systems. We define and construct efficient compressible randomness beacons, which produce unpredictable values in regular intervals and allow for storing all published values in a short digest.
]]></content:encoded>
<pubDate>Thu, 15 Feb 2024 14:42:02 +0000</pubDate>
</item>
<item>
<title>Stronger Security for Threshold Blind Signatures</title>
<link>https://eprint.iacr.org/2025/353</link>
<guid>https://eprint.iacr.org/2025/353</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、阈值盲签名、安全性、一更多不可伪造性、多签发者

总结:
文章探讨了阈值盲签名的安全性问题，其中盲签名允许用户以保护隐私的方式从签发者获取签名，而阈值版本则将私钥分散到n个签发者中，需要用户至少从t≤n个签发者那里获得签名份额才能生成最终签名。文章指出现有的一更多不可伪造性概念在单签发者场景下理解清晰，但在阈值场景中由于盲签名发行的特性导致挑战较大。现有的工作通过简化模型规避这一挑战，但无法完全体现阈值设置的预期。为此，文章提出了一个新的适用于c＜t个签发者被攻击情况的一更多不可伪造性框架，该框架可适应交互式和非交互式协议，并提供了一组逐步增强保证的自然属性，使签发者对份额组合拥有更多控制权。接着，文章重新审视了现有基于BLS和Snowblind的阈值盲签名方案在新框架下的安全性，并展示了如何提升它们的安全性。总的来说，文章旨在为阈值盲签名提供更强大且明确的安全保障。 <div>
Blind signatures allow a user to obtain a signature from an issuer in a privacy-preserving way: the issuer neither learns the signed message, nor can link the signature to its issuance. The threshold version of blind signatures further splits the secret key among n issuers, and requires the user to obtain at least t ≤ n of signature shares in order to derive the final signature. Security should then hold as long as at most t − 1 issuers are corrupt. Security for blind signatures is expressed through the notion of one-more unforgeability and demands that an adversary must not be able to produce more signatures than what is considered trivial after its interactions with the honest issuer(s). While one-more unforgeability is well understood for the single-issuer setting, the situation is much less clear in the threshold case: due to the blind issuance, counting which interactions can yield a trivial signature is a challenging task. Existing works bypass that challenge by using simplified models that do not fully capture the expectations of the threshold setting. In this work, we study the security of threshold blind signatures, and propose a framework of one-more unforgeability notions where the adversary can corrupt c < t issuers. Our model is generic enough to capture both interactive and non-interactive protocols, and it provides a set of natural properties with increasingly stronger guarantees, giving the issuers gradually more control over how their shares can be combined. As a point of comparison, we reconsider the existing threshold blind signature models and show that their security guarantees are weaker and less clearly comprehensible than they seem. We then re-assess the security of existing threshold blind signature schemes – BLS-based and Snowblind – in our framework, and show how to lift them to provide stronger security.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 12:39:58 +0000</pubDate>
</item>
<item>
<title>Helix: Scalable Multi-Party Machine Learning Inference against Malicious Adversaries</title>
<link>https://eprint.iacr.org/2025/347</link>
<guid>https://eprint.iacr.org/2025/347</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私、安全多方计算、PPML、恶意安全性、Helix

总结:
本文提出了一个名为Helix的框架，旨在实现大规模参与者的恶意安全PPML协议，提升恶意安全协议的可扩展性和实用性。文章指出了LXY24工作在前缀OR操作中存在的隐私泄漏问题，并提出了一种基于单轮矢量化三层乘法协议的优化方案作为替代。此外，通过利用计算过程中的可重用性，Helix设计了轻量级压缩协议以提高乘法验证效率，并开发了批量检查协议来降低恶意环境中揭示操作的计算复杂度。实验结果显示，在63方神经网络推理场景下，相比于半诚实的LXY24，Helix在线阶段慢1.9倍（LAN环境下为1.1倍），预处理阶段慢1.2倍（WAN环境下为1.1倍），但在最佳情况下表现出了较高的效率优势。 <div>
With the growing emphasis on data privacy, secure multi-party computation has garnered significant attention for its strong security guarantees in developing privacy-preserving machine learning (PPML) schemes. However, only a few works address scenarios with a large number of participants. The state of the art by Liu et al. (LXY24, USENIX Security'24) first achieves a practical PPML protocol for up to 63 parties but is constrained to semi-honest security. Although naive extensions to the malicious setting are possible, they would introduce significant overhead.
In this paper, we propose Helix, a scalable framework for maliciously secure PPML in the honest majority setting, aiming to enhance both the scalability and practicality of maliciously secure protocols. In particular, we report a privacy leakage issue in LXY24 during prefix OR operations and introduce a round-optimized alternative based on a single-round vectorized three-layer multiplication protocol. Additionally, by exploiting reusability properties within the computation process, we propose lightweight compression protocols that substantially improve the efficiency of multiplication verification. We also develop a batch check protocol to reduce the computational complexity of revealing operations in the malicious setting. For 63-party neural network inference, compared to the semi-honest LXY24, Helix is only 1.9$\times$ (1.1$\times$) slower in the online phase and 1.2$\times$ (1.1$\times$) slower in preprocessing under LAN (WAN) in the best case.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 01:34:53 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Threshold Proxy Re-encryption and Its Application in Data Rights Confirmation</title>
<link>https://eprint.iacr.org/2025/345</link>
<guid>https://eprint.iacr.org/2025/345</guid>
<content:encoded><![CDATA[
<div> 关键词: Proxy Re-Encryption, PVTPRE, Public Verifiability, Data Rights Confirmation, Blockchain

总结:
本文提出了一个新的代理重加密方案——公开可验证阈值代理重加密(PVTPRE)，该方案填补了在大数据时代对数据拥有者诚实性考虑的空白。PVTPRE通过创新地应用稍作修改的公开可验证秘密分享(PVSS)方案，将重加密密钥分布式地分配给多个代理，实现数据拥有者的非交互式公开可验证性。同时，通过执行PVSS重构算法，确保了数据用户解密的正确性和代理重加密的公共可验证性。文章进一步证明PVTPRE满足IND-CPA安全性标准。此外，基于PVTPRE和区块链技术，文中提出了一种隐私保护的数据权利确认框架，为数据所有权和使用提供明确原则，并利用区块链作为数据银行和智能合约引擎，提供可靠存储与验证服务。据作者所知，这是首次系统研究兼顾隐私保护与公开可验证性的数据权利确认机制，旨在保护数据权利并确保透明度。最后，文章进行了全面的实验以证实PVTPRE的正确性、可行性和有效性，并显示其在许多方面优于其他代理重加密方案。 <div>
Proxy re-encryption (PRE) has been regarded as an effective cryptographic primitive in data sharing systems with distributed proxies. However, no literature considers the honesty of data owners, which is critical in the age of big data. In this paper, we fill the gap by introducing a new proxy re-encryption scheme, called publicly verifiable threshold PRE (PVTPRE). Briefly speaking, we innovatively apply a slightly modified publicly verifiable secret sharing (PVSS) scheme to distribute the re-encryption keys to multiple proxies. Consequently, we achieve publicly verifiability of data owners non-interactively. Then, the correctness of data users in decryption and public verifiability of proxies in re-encryption are guaranteed seamlessly through execution of the PVSS reconstruction algorithms. We further prove that PVTPRE satisfies IND-CPA security. Besides, we put forward a privacy-preserving data rights confirmation framework by providing clear principles for data ownership and usage, based on the PVTPRE scheme and blockchain. Blockchain plays the role of data bank and smart contract engine, providing reliable storage and verification for all framework. To our knowledge, we are the first to systematically investigate data rights confirmation considering privacy as well as public verifiability, addressing the growing need for robust mechanisms to protect data rights and ensure transparency. Finally, we conduct comprehensive experiments to illustrate the correctness, feasibility and effectiveness. The experimental results show that our PVTPRE outperforms other PREs in many aspects.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:21:38 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Generalized Secret Sharing and Its Application in Building Decentralized Exchange</title>
<link>https://eprint.iacr.org/2025/344</link>
<guid>https://eprint.iacr.org/2025/344</guid>
<content:encoded><![CDATA[
<div> 关键词: Generalized Secret Sharing (GSS), Publicly Verifiable Generalized Secret Sharing (PVGSS), Non-Interactive Zero-Knowledge (NIZK), Decentralized Exchange (DEX), Fairness

<br /><br />总结:
本文提出了公开可验证广义秘密共享（PVGSS）方案，旨在提升分布式计算中GSS机制的适用性，尤其是在区块链等透明系统中的应用。首先介绍了基于Shamir秘密共享和线性秘密共享方案两种GSS构造方法。接着，将GSS与非交互式零知识证明（NIZK）相结合构建了PVGSS方案。进一步地，利用PVGSS方案设计了一个去中心化交易所（DEX），用户可以在其中公平地进行ERC-20代币交换，而被动观察者通过提供仲裁服务获取利润。DEX的关键特性“公平性”由PVGSS方案支持的复杂访问结构保障。文章还对PVGSS方案的性能以及DEX中用户的经济成本进行了全面评估，结果表明该方法在现实世界应用中具有可行性和实用性。 <div>
Generalized secret sharing (GSS), which can offer more flexibility by accommodating diverse access structures and conditions, has been under-explored in distributed computing over the past decades. To address the gaps, we propose the publicly verifiable generalized secret sharing (PVGSS) scheme, enhancing the applicability of GSS in transparent systems. Public verifiability is a crucial property to gain trustworthiness for decentralized systems like blockchain.  We begin by introducing two GSS constructions, one based on Shamir's secret sharing and the other on the linear secret sharing scheme (LSSS). Next, we present PVGSS schemes that combine GSS with non-interactive zero-knowledge (NIZK) proofs.  Further, we construct a decentralized exchange (DEX) based on PVGSS scheme, where any users can participate in exchanges and engage in arbitrage. Specifically, users can fairly swap ERC-20 tokens with passive watchers, who earn profits by providing arbitration services. The critical property of "fairness" required by the DEX is ensured through a sophisticated access structure, supported by the PVGSS scheme. We provide a comprehensive evaluation on the performance of the PVGSS schemes and the monetary costs for users in the DEX. The results demonstrate the feasibility and practicality of this approach in real-world applications.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 23:42:56 +0000</pubDate>
</item>
<item>
<title>CCA-Secure Traceable Threshold (ID-based) Encryption and Application</title>
<link>https://eprint.iacr.org/2025/341</link>
<guid>https://eprint.iacr.org/2025/341</guid>
<content:encoded><![CDATA[
<div> 关键词：traceable threshold encryption、CCA安全性、一致性、身份基加密、Boneh-Franklin IBE、Boneh-Boyen IBE

<br /><br />总结：

本文提出了更强版本的可追踪门限加密定义，支持CCA安全性与解密一致性。文章首先引入了基于身份的可追踪加密变种，并通过两个通用变换将其转化为CCA安全构造，这些变换利用了一次性签名和指纹编码技术。接着，文章给出了两种高效的身份基方案实例，第一种基于Boneh-Franklin IBE，具有常数大小的密文但公钥大小为二次级，其安全性依赖于XDH和BDDH假设；第二种基于Boneh-Boyen IBE，同时支持常数大小的密文和公钥，安全性基于双线性配对的一种变种——“uber”假设。具体分析表明，第一种方案的密文比第二种小约6倍。最后，为了实现一致性，文章扩展了相关定义并加入了一个有效的非交互式正确加密证明。 <div>
A recent work by Boneh, Partap, and Rotem [Crypto'24] introduced the concept of traceable threshold encryption, in that if $t$ or more parties collude to construct a decryption box, which performs decryptions, then at least one party's identity can be traced by making a few black-box queries to the box. This has important applications, e.g., in blockchain mempool privacy, where collusion yields high financial gain through MEVs without any consequence - the possibility of tracing discourages collusion.
Nevertheless, their definitions leave room for exploitation as they only achieve CPA security and do not consider inconsistency in decryption via different participating sets.

This paper proposes stronger definitions of traceable threshold encryption, which supports CCA-security and consistency. Our main approach considers identity-based variants of traceable encryption (which we also define). It converts that to a CCA-secure construction, adapting two generic transformations, first using a one-time signature and then a fingerprinting code. 
We put forward two efficient instantiations of our identity-based scheme with different merits: our first construction is based on Boneh-Franklin IBE [Crypto'01] and has constant size ciphertexts but quadratic size public keys - this is proven secure based on XDH and BDDH. Our second construction is based on Boneh-Boyen IBE [Eurocrypt'04]. It supports both constant-size ciphertexts and constant-size public keys - this is proven secure based on a variant of the uber assumption over bilinear pairings. Our concrete analysis shows that the first construction's ciphertext is much (~6x) smaller than the second construction. Finally, we extend the definitions to support consistency and achieve it by adjoining an efficient, non-interactive proof of correct encryption.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 15:59:42 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Multi-Signatures: Generic Techniques and Constructions Without Pairings</title>
<link>https://eprint.iacr.org/2025/335</link>
<guid>https://eprint.iacr.org/2025/335</guid>
<content:encoded><![CDATA[
<div> 关键词: 多重签名、隐私保护、集体签名、BLS型、Schnorr型

总结:
这篇文章研究了多重签名在隐私保护集体签名中的应用。Lehmann和Özbay最近的工作提出了具有概率性但可验证密钥聚合的新型BLS型多重签名，允许用户在不泄露所属组信息的情况下复用长期密钥参与不同群组。然而，这一技术不能应用于Schnorr型多重签名。对此，文章重新审视了他们的隐私框架，并做出了两个贡献：一是提出一种通用方法，将隐私保护添加到任何确定性密钥聚合的多重签名中；二是针对两种具体的多重签名方案（MuSig2和基于 lattice 的 DualMS）给出了针对性的转换，使MuSig2无需额外成本即可实现最强隐私属性，同时使 DualMS 变种成为首个适用于隐私保护的动态群体签名的后量子安全多重签名方案。虽然修改后的 DualMS 方案略有开销增加，但仍能保持原方案的竞争力。 <div>
Multi-signatures allow a set of parties to produce a single signature for a common message by combining their individual signatures. The result can be verified using the aggregated public key that represents the group of signers. Very recent work by Lehmann and Özbay (PKC '24) studied the use of multi-signatures for ad-hoc privacy-preserving group signing, formalizing the notion of multi-signatures with probabilistic yet verifiable key aggregation. Moreover, they proposed new BLS-type multi-signatures, allowing users holding a long-term key pair to engage with different groups, without the aggregated key leaking anything about the corresponding group. This enables key-reuse across different groups in a privacy-preserving way. Unfortunately, their technique cannot be applied to Schnorr-type multi-signatures, preventing state-of-the-art multi-signatures to benefit from those privacy features.

In this work, we revisit the privacy framework from Lehmann and Özbay. Our first contribution is a generic lift that adds privacy to any multi-signature with deterministic key aggregation. As our second contribution, we study two concrete multi-signatures, and give dedicated transforms that take advantage of the underlying structures for improved efficiency. The first one is a slight modification of the popular MuSig2 scheme, achieving the strongest privacy property for free compared to the original scheme. The second is a variant of the lattice-based multi-signature scheme DualMS, making our construction the first post-quantum secure multi-signature for ad-hoc privacy-preserving group signing. The light overhead incurred by the modifications in our DualMS variant still allow us to benefit from the competitiveness of the original scheme.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 13:35:38 +0000</pubDate>
</item>
<item>
<title>How to Share an NP Statement or Combiners for Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/334</link>
<guid>https://eprint.iacr.org/2025/334</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密分享、NP陈述、信息论安全性、多项式复杂性、非交互式组合

<br /><br />总结:
本文探讨了秘密分享NP陈述（NPSS）的概念，并对其进行了深化，提出了信息论安全性的NPSS定义，该定义可以视为标准NP归约的加密变体，并能利用任何单向函数编译为GJS定义。文章构建了一个适用于任意$t\leq n$值的信息论安全的$t$-out-of-$n$ NPSS构造，其复杂度为多项式级别。在此过程中，作者引入了一种新的安全多方计算概念，具有独立的研究价值。

接着，本文的NPSS框架支持非交互式地结合$n$个零知识证明实例，只要其中满足$t_s + t_z > n$，即可实现仅有$t_s$个实例保证声音性和仅有$t_z$个实例保证零知识性。基于此，文章在仅需单向函数假设下实现了以下成果：
(1) 标准NIZK蕴含多字符串模型中的NIZK，只要多数共同参考字符串是诚实生成的，即可确保安全性。此前此类转换仅知在公共随机串模型中可行。
(2) 在多字符串模型中实现了指定证明者NIZK，达到了一种强形式的两轮多验证器零知识，在诚实多数设置下。
(3) 基于诚实多数设置，提出了一种三轮安全多方计算协议，对于一般功能而言，其轮数复杂度是最优的，从而解决了以往依赖更强假设的一系列研究问题（如Aharonov等人，Eurocrypt'12；Gordon等人，Crypto'15；Ananth等人，Crypto'18；Badrinarayanan等人，Asiacrypt'20；Applebaum等人，TCC'22）。 <div>
In Crypto'19, Goyal, Jain, and Sahai (GJS) introduced the elegant notion of *secret-sharing of an NP statement* (NPSS). Roughly speaking, a $t$-out-of-$n$ secret sharing of an NP statement is a reduction that maps an instance-witness pair to $n$ instance-witness pairs such that any subset of $(t-1)$ reveals no information about the original witness, while any subset of $t$ allows full recovery of the original witness. Although the notion was formulated for general $t \leq n$, the only existing construction (due to GJS) applies solely to the case where $t = n$ and provides only computational privacy. In this paper, we further explore NPSS and present the following contributions.  

1. **Definition.** We introduce a refined definition of information-theoretically secure NPSS. This notion can be seen as a cryptographic variant of standard NP-reductions and can be compiled into the GJS definition using any one-way function.

2. **Construction.** We construct information-theoretic $t$-out-of-$n$ NPSS for any values of $t\leq n$ with complexity polynomial in $n$. Along the way, we present a new notion of secure multiparty computation that may be of independent interest.

3. **Applications.** Our NPSS framework enables the *non-interactive combination* of $n$ instances of zero-knowledge proofs, where only $t_s$ of them are sound and only $t_z$ are zero-knowledge, provided that $t_s + t_z > n$. Our combiner preserves various desirable properties, such as the succinctness of the proof. Building on this, we establish the following results under the minimal assumption of one-way functions: 
(i) *Standard NIZK implies NIZK in the Multi-String Model* (Groth and Ostrovsky, J. Cryptology, 2014), where security holds as long as a majority of the $n$ common reference strings were honestly generated. Previously, such a transformation was only known in the common random string model, where the reference string is uniformly distributed.
(ii) A *Designated-Prover NIZK in the Multi-String Model*, achieving a strong form of two-round Multi-Verifier Zero-Knowledge in the honest-majority setting.
(iii) A *three-round secure multiparty computation protocol* for general functions in the honest-majority setting. The round complexity of this protocol is optimal, resolving a line of research that previously relied on stronger assumptions (Aharonov et al., Eurocrypt'12; Gordon et al., Crypto'15; Ananth et al., Crypto'18; Badrinarayanan et al., Asiacrypt'20; Applebaum et al., TCC'22).
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 11:30:03 +0000</pubDate>
</item>
<item>
<title>Leap: A Fast, Lattice-based OPRF With Application to Private Set Intersection</title>
<link>https://eprint.iacr.org/2025/333</link>
<guid>https://eprint.iacr.org/2025/333</guid>
<content:encoded><![CDATA[
<div> 关键词： Oblivious Pseudorandom Functions (OPRFs)，量子攻击，Leap，学习与舍入假设，私人集合交集 (PSI)

总结:
本文介绍了基于他uristic lattice假设的新型Oblivious Pseudorandom Function (OPRF)——Leap。考虑到未来潜在的量子攻击对大多数依赖于经典假设的OPRFs构成威胁，Leap构建在Spring [BBL+15] 基于学习与舍入假设的伪随机函数之上，并结合了多方计算中的Oblivious Transfer (OT) 和 Oblivious Linear Evaluation (OLE) 技术。通过这种方式，Leap实现了在现代计算机上不到一毫秒的评估时间。其原型实现的计算时间为客户端11微秒、服务器端750微秒（不包括基础OT预处理开销），并具有在线通信成本仅为23 kB每评估的特点，其中客户端仅需发送约380字节的数据。为了展示Leap的实际应用潜力，文章使用Leap构建了一个高效的私人集合交集(PSI)协议，该协议能在不到一分钟的在线时间内完成大小为2^24和2^15的两个集合的交集计算，总耗时超过两分钟。这一应用表明Leap可以被整合到各种隐私保护的应用场景中。 <div>
Oblivious pseudorandom functions (OPRFs) are an important primitive in privacy-preserving cryptographic protocols. The growing interest in OPRFs, both in theory and practice, has led to the development of numerous constructions and variations. However, most of these constructions rely on classical assumptions. Potential future quantum attacks may limit the practicality of those OPRFs for real-world applications. 

To close this gap, we introduce Leap, a novel OPRF based on heuristic lattice assumptions. Fundamentally, Leap builds upon the Spring [BBL+15] pseudorandom function (PRF), which relies on the learning with rounding assumption, and integrates techniques from multi-party computation, specifically Oblivious Transfer (OT) and Oblivious Linear Evaluation (OLE). With this combination of oblivious protocols, we construct an OPRF that evaluates in less than a millisecond on a modern computer.

Efficiency-wise, our prototype implementation achieves computation times of just 11 microseconds for the client and 750 microseconds for the server, excluding some base OT preprocessing overhead. Moreover, Leap requires an online communication cost of 23 kB per evaluation, where the client only has to send around 380 bytes online. To demonstrate the practical applicability of Leap, we present an efficient private set intersection (PSI) protocol built on top of Leap. This application highlights the potential for the integration of Leap into various privacy-preserving applications: We can compute an unbalanced set intersection with set sizes of 2^24 and 2^15 in under a minute of online time and just over two minutes overall.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 11:20:47 +0000</pubDate>
</item>
<item>
<title>Private Multi-Party Neural Network Training over $\mathbb{Z}_{2^k}$ via Galois Rings</title>
<link>https://eprint.iacr.org/2025/331</link>
<guid>https://eprint.iacr.org/2025/331</guid>
<content:encoded><![CDATA[
<div> 关键词: 秘密共享、多党计算、隐私保护机器学习、Shamir秘密分享方案、Galois环

总结:
本文提出了一种基于Shamir秘密分享方案和Galois环\(GR(2^k, d)\)的隐私保护神经网络训练新协议。该协议利用了Galois环的代数结构，仅需对\(2^k\)进行模运算而非素数，使其更适应现代计算机架构。通过将不同训练样本嵌入到表示单个Galois环元素的多项式的不同系数中，实现了并行处理训练数据，并证明此嵌入过程与一次处理一个样本相比，无需额外通信开销。实验在MNIST数据集上进行了不同参与者数量下的私人神经网络训练，结果显示我们的协议相较于现有基于\(\mathbb{F}_p\)实现的优势。 <div>
Secret-sharing-based multi-party computation provides effective solutions for privacy-preserving machine learning. In this paper, we present novel protocols for privacy-preserving neural network training using Shamir secret sharing scheme over Galois rings. The specific Galois ring we use is \(GR(2^k, d)\), which contains $\mathbb{Z}_{2^k}$ as a subring. The algebraic structure of \(GR(2^k, d)\) enables us to benefit from Shamir scheme while performing modulo operations only on \(2^k\) instead of a prime number, making our protocols more compatible with modern computer architectures. We achieve the parallel processing of training data by embedding different training samples into the different coefficients of the polynomial representing a single Galois ring element, and we show that this embedding can be performed with no additional communication overhead compared to processing only one sample at a time. To evaluate our methods, we conduct private training of neural networks on the MNIST dataset between different numbers of participants. The experimental results indicate the advantages of our protocols compared to existing $\mathbb{F}_p$-based implementations in this domain.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 02:00:59 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Epidemiological Modeling on Mobile Graphs</title>
<link>https://eprint.iacr.org/2020/1546</link>
<guid>https://eprint.iacr.org/2020/1546</guid>
<content:encoded><![CDATA[
<div> 关键词: RIPPLE、隐私保护、流行病学模拟、社交接触图、PIR-SUM

总结:
RIPPLE 是一个创新的隐私保护流行病学建模框架，能够在不泄露任何个人联系信息的情况下，基于人群的真实社交接触图进行传染病模型的标准模拟。为了实现这一目标，该框架采用了一种名为 PIR-SUM 的新型私人信息检索扩展技术，用于安全地从数据库下载元素总和。文中还包括了一个概念验证的实现，展示了在 7 分钟内完成对 50 万参与者为期两周的模拟，每个参与者之间的通信数据量少于 50 KB，这表明了该方法的有效性和高效性。 <div>
The latest pandemic COVID-19 brought governments worldwide to use various containment measures to control its spread, such as contact tracing, social distance regulations, and curfews. Epidemiological simulations are commonly used to assess the impact of those policies before they are implemented. Unfortunately, the scarcity of relevant empirical data, specifically detailed social contact graphs, hampered their predictive accuracy. As this data is inherently privacy-critical, a method is urgently needed to perform powerful epidemiological simulations on real-world contact graphs without disclosing any sensitive information.

In this work, we present RIPPLE, a privacy-preserving epidemiological modeling framework enabling standard models for infectious disease on a population’s real contact graph while keeping all contact information locally on the participants’ devices. As a building block of independent interest, we present PIR-SUM, a novel extension to private information retrieval for secure download of element sums from a database. Our protocols are supported by a proof-of-concept implementation, demonstrating a 2-week simulation over half a million participants completed in 7 minutes, with each participant communicating less than 50 KB.
]]></content:encoded>
<pubDate>Sun, 13 Dec 2020 16:59:07 +0000</pubDate>
</item>
<item>
<title>Black-box Collision Attacks on Widely Deployed Perceptual Hash Functions</title>
<link>https://eprint.iacr.org/2024/1869</link>
<guid>https://eprint.iacr.org/2024/1869</guid>
<content:encoded><![CDATA[
<div> 关键词：感知哈希函数、客户端扫描、神经网络哈希、NeuralHash、PhotoDNA<br /><br />总结:<br />
本文讨论了感知哈希函数在识别多媒体内容中的应用及其潜在问题。它们常用于检测版权侵犯和非法内容，但设计细节通常保密，缺乏透明度。政府考虑将其应用于客户端扫描（CSS）中，对端到端加密服务的内容进行预加密验证。苹果曾提出基于NeuralHash的CSS方案，但由于隐私和安全顾虑受到强烈批评而撤回，尽管该软件仍存在于Apple设备上。研究发现，NeuralHash存在易构造两个视觉上明显不同的输入产生相同哈希值的问题，对于人脸图像集合，随机碰撞的概率在$2^{16}$大小的输入集里显著增加。此外，还指出其错误否定率也较高。相似攻击也被成功应用于微软提出的广泛部署的PhotoDNA感知哈希函数。这些结果表明，当前的感知哈希函数设计不适合大规模客户端扫描，因为会导致无法接受的高误报率。因此，文章强调需要重新评估感知哈希函数的安全性和可行性，特别是在具有严重后果的大型应用场景下。 <div>
Perceptual hash functions identify multimedia content by mapping similar inputs to similar outputs. They are widely used for detecting copyright violations and illegal content but lack transparency, as their design details are typically kept secret.
Governments are considering extending the application of these functions to Client-Side Scanning (CSS) for end-to-end encrypted services: multimedia content would be verified against known illegal content before applying encryption.
In 2021, Apple presented a detailed proposal for CSS based on the NeuralHash perceptual hash function. After strong criticism pointing out privacy and security concerns, Apple has withdrawn the proposal, but the NeuralHash software is  still present on Apple devices. 
Brute force collisions for NeuralHash (with a 96-bit result) require $2^{48}$ evaluations. Shortly after the publication of NeuralHash, it was demonstrated that it is easy to craft two  colliding inputs for NeuralHash that are perceptually dissimilar. In the context of CSS, this means that it is easy to falsely incriminate someone by sending an innocent picture with the same hash value as illegal content. This work shows a more serious weakness: when inputs are restricted to a set of human faces, random collisions are highly likely to occur in input sets of size $2^{16}$. Unlike the targeted attack, our attacks are black-box attacks: they do not require knowledge of the design of the perceptual hash functions. In addition, we show that the false negative rate is high as well. We demonstrate the generality of our approach by applying a similar attack to PhotoDNA, a widely deployed perceptual hash function proposed by Microsoft with a hash result of 1152 bits. Here we show that specific small input sets result in near-collisions, with similar impact. These results imply that the current designs of perceptual hash function are completely unsuitable for large-scale client scanning, as they would result in an unacceptably high false positive rate. This work underscores the need to reassess the security and feasibility of perceptual hash functions, particularly for large-scale applications where privacy risks and false positives have serious consequences.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 13:00:53 +0000</pubDate>
</item>
<item>
<title>Partial and Fully Homomorphic Matching of IP Addresses Against Blacklists for Threat Analysis</title>
<link>https://eprint.iacr.org/2025/322</link>
<guid>https://eprint.iacr.org/2025/322</guid>
<content:encoded><![CDATA[
<div> 关键词: 个人信息安全、同态加密、IP地址、BFV方法、性能比较

总结:
本文关注于在网络信息安全领域中保护个人隐私的问题，特别是涉及IP地址的情况下。为了解决这一问题，文章提出使用同态加密技术来隐藏IP地址，同时实现对黑名单的匹配检查。具体而言，文中采用了OpenFHE库将网络地址转换为BFV同态加密方法。为了评估BFV方法的性能影响，文章将其与部分同态加密方法（包括Paillier、Damgard-Jurik、Okamoto-Uchiyama、Naccache-Stern和Benaloh）进行了对比测试。结果显示，BFV方法在多数情况下相对于这些部分同态加密方法表现更优。 <div>
In many areas of cybersecurity, we require access to Personally Identifiable Information (PII), such as names, postal addresses and email addresses. Unfortunately, this can lead to data breaches, especially in relation to data compliance regulations such as GDPR. An IP address is a typical identifier which is used to map a network address to a person. Thus, in applications which are privacy-aware, we may aim to hide the IP address while aiming to determine if the address comes from a blacklist. One solution to this is to use homomorphic encryption to match an encrypted version of an IP address to a blacklisted network list. This matching allows us to encrypt the IP address and match it to an encrypted version of a blacklist. In this paper, we use the OpenFHE library \cite{OpenFHE} to convert network addresses into the BFV homomorphic encryption method. In order to assess the performance impact of BFV, it implements a matching method using the OpenFHE library and compares this against the partial homomorphic methods of Paillier, Damgard-Jurik, Okamoto-Uchiyama, Naccache-Stern and Benaloh. The main findings are that the BFV method compares favourably against the partial homomorphic methods in most cases.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 20:36:43 +0000</pubDate>
</item>
<item>
<title>Committing Authenticated Encryption: Generic Transforms with Hash Functions</title>
<link>https://eprint.iacr.org/2025/320</link>
<guid>https://eprint.iacr.org/2025/320</guid>
<content:encoded><![CDATA[
<div> 关键词：authenticated encryption, committing security, generic transform, hash function, MR security

总结:
本文关注了认证加密（AE）方案中的承诺安全性需求，提出了多种基于哈希函数的通用转换方法，以克服现有技术的局限性，包括不完全承诺加密上下文、涉及非标准原语、非黑盒转换以及有限的承诺安全性。研究中，作者构建了三个基础转换方案$\mathsf{HtAE}, \mathsf{AEaH}$和$\mathsf{EtH}$，它们都保证了强大的安全性，并指出$\mathsf{EtH}$可应用于AE和基本隐私加密方案。对于滥用抵抗（MR）安全，作者提出了两个高级哈希基转换方案$\mathsf{AEtH}$和$\mathsf{chaSIV}$。其中，$\mathsf{AEtH}$可以为MR安全的AE方案添加承诺安全性，而$\mathsf{chaSIV}$则是首个能直接将基本AE提升至同时具有承诺和MR安全性的通用转换方案，而且它还可与任意隐私加密方案配合使用。在性能评估方面，$\mathsf{AEaH}$显示出了基础转换中的最高实际效率，而$\mathsf{AEtH}$在MRAE保持型转换中表现出色。MRAE提升转换$\mathsf{chaSIV}$在消息长度超过约360字节时，其性能与MRAE保持型转换相当甚至更优；对于更长的消息，它甚至超越了标准化的非承诺方案$\mathsf{AES}\text{-}\mathsf{GCM}\text{-}\mathsf{SIV}$。<br /><br /> <div>
Recent applications and attacks have highlighted the need for authenticated encryption (AE) schemes to achieve the so-called committing security beyond privacy and authenticity. As a result, several generic solutions have been proposed to transform a non-committing AE scheme to a committing one, for both basic unique-nonce security and advanced misuse-resistant (MR) security. We observe that all existing practical generic transforms are subject to at least one of the following limitations: (i) not committing to the entire encryption context, (ii) involving non-standard primitives, (iii) not being a black-box transform, (iv) providing limited committing security. Furthermore, so far, there has been no generic transform that can directly elevate a basic AE scheme to a committing AE scheme that offers MR security. Our work fills these gaps by developing black-box generic transforms that crucially rely on hash functions, which are well standardized and widely deployed.

First, we construct three basic transforms that combine AE with a single hash function, which we call $\mathsf{HtAE}, \mathsf{AEaH}$ and $\mathsf{EtH}$. They all guarantee strong security, and $\mathsf{EtH}$ can be applied to both AE and basic privacy-only encryption schemes. Next, for MR security, we propose two advanced hash-based transforms that we call $\mathsf{AEtH}$ and $\mathsf{chaSIV}$. $\mathsf{AEtH}$ is an MRAE-preserving transform that adds committing security to an MR-secure AE scheme. $\mathsf{chaSIV}$ is the first generic transform that can directly elevate basic AE to one with both committing and MR security; moreover, $\mathsf{chaSIV}$ also works with arbitrary privacy-only encryption schemes. Both of them feature a simple design and ensure strong security.

For performance evaluation, we compare our transforms to similar existing ones, both in theory and through practical implementations. The results show that our $\mathsf{AEaH}$ achieves the highest practical efficiency among basic transforms, while $\mathsf{AEtH}$ excels in MRAE-preserving transforms. Our MRAE-lifting transform $\mathsf{chaSIV}$ demonstrates comparable performance to MRAE-preserving ones and surpasses them for messages larger than approximately $360$ bytes; for longer messages, it even outperforms the benchmark, non-committing standardized $\mathsf{AES}\text{-}\mathsf{GCM}\text{-}\mathsf{SIV}$.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 15:51:43 +0000</pubDate>
</item>
<item>
<title>Stateless Deterministic Multi-Party EdDSA Signatures with Low Communication</title>
<link>https://eprint.iacr.org/2024/358</link>
<guid>https://eprint.iacr.org/2024/358</guid>
<content:encoded><![CDATA[
<div> 关键词: EdDSA、多党派、阈值签名、零知识证明、信息论安全消息认证码

总结:
本文提出了一种新的全阈值环境下，能够容忍最多一名恶意成员破坏的无状态、确定性多党派EdDSA协议。相较于现有的Garillot等人提出的方案，新协议在保持三轮通信结构不变的同时，将通信成本降低了56倍，但计算成本增加了约2.25倍。我们利用信息论安全的消息认证码（IT-MAC）在多验证器场景下对值进行身份验证，并通过改进的多验证器扩展双重认证位（mv-edabits）将其从布尔域转换到算术域。此外，采用伪随机相关函数（PCF）以无状态和确定性的方式生成IT-MAC。结合这些元素，设计了一个用于无状态和确定性随机数生成的多验证器零知识（MVZK）协议。该协议可应用于构建更安全的区块链钱包和托管解决方案，增强密钥保护。<br /><br /> <div>
EdDSA is a standardized signing algorithm, by both the IRTF and NIST, that is widely used in blockchain, e.g., Hyperledger, Cardano, Zcash, etc. It is a variant of the well-known Schnorr signature scheme that leverages Edwards curves. It features stateless and deterministic nonce generation, meaning it does not rely on a reliable source of randomness or state continuity. Recently, NIST issued a call for multi-party threshold EdDSA signatures, with one approach verifying nonce generation through zero-knowledge (ZK) proofs. In this paper, we propose a new stateless and deterministic multi-party EdDSA protocol in the full-threshold setting, capable of tolerating all-but-one malicious corruption. Compared to the state-of-the-art multi-party EdDSA protocol by Garillot et al. (Crypto’21), our protocol reduces communication cost by a factor of 56x while maintaining the same three-round structure, albeit with a roughly 2.25x increase in computational cost. We utilize information-theoretic message authentication codes (IT-MACs) in a multi-verifier setting to authenticate values and transform them from the Boolean domain to the arithmetic domain by refining multi-verifier extended doubly-authenticated bits (mv-edabits). Additionally, we employ pseudorandom correlation functions (PCF) to generate IT-MACs in a stateless and deterministic manner. Combining these elements, we design a multi-verifier zero-knowledge (MVZK) protocol for stateless and deterministic nonce generation. Our protocol can be used to build secure blockchain wallets and custody solutions, enhancing key protection.
]]></content:encoded>
<pubDate>Wed, 28 Feb 2024 07:51:27 +0000</pubDate>
</item>
<item>
<title>HELM: Navigating Homomorphic Encryption through Gates and Lookup Tables</title>
<link>https://eprint.iacr.org/2023/1382</link>
<guid>https://eprint.iacr.org/2023/1382</guid>
<content:encoded><![CDATA[
<div> 关键词：云安全、数据保密性、同态加密、HELM、隐私保护

总结:
随着云计算广泛应用，保障托管给第三方云服务提供商的数据机密性成为关键问题。文章提出了一种名为HELM的框架，该框架利用同态加密技术实现对数据处理过程中的隐私保护。HELM能将使用硬件描述语言（如Verilog）编写的任意程序自动转换为等效的同态电路，支持在加密输入的情况下进行高效评估。它提供了两种加密评估模式：一是基于标准布尔门电路的模式；二是查表模式，通过将多个门电路合并到查找表中以显著减小电路规模。此外，HELM还引入了一个调度器，实现了加密域内的并行处理。通过对ISCAS'85和ISCAS'89基准套件以及实际应用如AES和图像滤波的测试，HELM的表现比先前工作最高提升了65倍。 <div>
As cloud computing continues to gain widespread adoption, safeguarding the confidentiality of data entrusted to third-party cloud service providers becomes a critical concern. While traditional encryption methods offer protection for data at rest and in transit, they fall short when it comes to where it matters the most, i.e., during data processing.

To address this limitation, we present HELM, a framework for privacy-preserving data processing using homomorphic encryption. HELM automatically transforms arbitrary programs expressed in a Hardware Description Language (HDL), such as Verilog, into equivalent homomorphic circuits, which can then be efficiently evaluated using encrypted inputs. HELM features two modes of encrypted evaluation: a) a gate mode that consists of standard Boolean gates, and b) a lookup table mode which significantly reduces the size of the circuit by combining multiple gates into lookup tables. Finally, HELM introduces a scheduler that enables embarrassingly parallel processing in the encrypted domain. We evaluate HELM with the ISCAS'85 and ISCAS'89 benchmark suites as well as real-world applications such as AES and image filtering. Our results outperform prior works by up to $65\times$.
]]></content:encoded>
<pubDate>Fri, 15 Sep 2023 04:57:50 +0000</pubDate>
</item>
<item>
<title>Malleable SNARKs and Their Applications</title>
<link>https://eprint.iacr.org/2025/311</link>
<guid>https://eprint.iacr.org/2025/311</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARKs、malleable SNARKs、recursive SNARKs、adversarial one-way function (AOWF)、post-quantum cryptography

总结:
本文研究了可塑性SNARKs（malleable SNARKs），这是递归SNARK概念的一种推广，允许修改SNARK证明以展示相关陈述，并保持篡改后的证明与新鲜产生的证明无法区分。文章提出了针对通用语言和关系的可塑性SNARK实例化方法，并给出了几个应用案例，包括首个后量子RCCA安全的重随机化和更新加密方案、一种通用的反向防火墙构造以及一种不可链接的（即计算隐藏的）目标可塑性全同态加密方案。技术上，该可塑性SNARK构造依赖于递归证明，但为实现强大篡改后的不可辨识性，需要允许无限递归深度。为了在这种情况下仍能保证合理的可提取性（特别是确保最终能提取到不引用先前SNARK证明的“正确”见证），文章引入了一种名为对抗性单向函数（AOWF）的新颖且通用的计算原语，并提供了一个AOWF候选方案及其在随机预言模型下的安全性证明。 <div>
Succinct non-interactive arguments of knowledge (SNARKs) are variants of non-interactive zero-knowledge proofs (NIZKs) in which complex statements can be proven in a compact way. SNARKs have had tremendous impact in several areas of cryptography, including verifiable computing, blockchains, and anonymous communication. A recurring concept in many applications is the concept of recursive SNARKs, in which a proof references a previous proof to show an evolved statement.

In this work, we investigate malleable SNARKs, a generalization of this concept of recursion. An adaptation of the existing concept of malleable NIZKs, malleable SNARKs allow to modify SNARK proofs to show related statements, but such that such mauled proofs are indistinguishable from “properly generated” fresh proofs of the related statement. We show how to instantiate malleable SNARKs for universal languages and relations, and give a number of applications: the first post-quantum RCCA-secure rerandomizable and updatable encryption schemes, a generic construction of reverse firewalls, and an unlinkable (i.e., computation-hiding) targeted malleable homomorphic encryption scheme.

Technically, our malleable SNARK construction relies on recursive proofs, but with a twist: in order to support the strong indistinguishability properties of mauled and fresh SNARK proofs, we need to allow an unbounded recursion depth. To still allow for a reasonable notion of extractability in this setting (and in particular to guarantee that extraction eventually finishes with a “proper” witness that does not refer to a previous SNARK proof), we rely on a new and generic computational primitive called adversarial one-way function (AOWF) that may be of independent interest. We give an AOWF candidate and prove it secure in the random oracle model.
]]></content:encoded>
<pubDate>Thu, 20 Feb 2025 21:24:29 +0000</pubDate>
</item>
<item>
<title>Practical Zero-Trust Threshold Signatures in Large-Scale Dynamic Asynchronous Networks</title>
<link>https://eprint.iacr.org/2025/297</link>
<guid>https://eprint.iacr.org/2025/297</guid>
<content:encoded><![CDATA[
<div> 关键词: 压力签名, 权限不清除区块链, ECDSA, EdDSA/Schnorr, 安全性<br /><br />总结:

我们提出了在客户端和权限不清除分散式区块链之间分布压力签名过程的新协议，针对ECDSA和EdDSA/Schnorr签名进行了设计。现有的由可信托管人使用的阈值访问架构存在蜜罐问题，资产持有量越大，被攻破的动机越强。我们的实现克服了几个挑战：1）适应异步可靠的广播通信通道，并具有可识别中止、公共可验证性和保证输出交付的特点；2）设计了一个流体协议，支持每轮通信中的后决定动态多数参与签署；3）提供了网络再配置协议，复杂度独立于系统中的客户端数量，并有效支持基于权重的阈值访问结构。此外，协议优化了与客户端交互的过程，去除了零知识证明，并实现了非交互式客户端预签，降低了通信开销并提高了应对高需求时段流量峰值的能力。我们的协议具备UC安全性，并提出了一种新颖的安全假设——稍微增强的ECDSA不可伪造性，为支持并行执行预签操作的阈值ECDSA提供了对256位椭圆曲线的具体安全保证。该协议不仅用于加密货币钱包的安全，还展示了如何应用于跨链场景，如去中心化桥接、未来交易和钱包转移，旨在提高多区块链环境下的安全性、可扩展性和灵活性，尤其对于去中心化金融（DeFi）生态系统具有重要意义。 <div>
Threshold signatures have become a critical tool in cryptocurrency systems, offering enhanced security by distributing the signing process among multiple signers. In this work, we distribute this process between a client and a permissionless decentralized blockchain, and present novel protocols for ECDSA and EdDSA/Schnorr signatures in this setting. Typical threshold access architectures used by trusted custodians suffer from the honeypot problem, wherein the more assets the custodian holds, the greater the incentive of compromising it.

Implementing threshold signatures over permissionless blockchains poses a few challenges.
First, existing networks typically work over an asynchronous reliable broadcast communication channel. Accordingly, our protocol is implemented over such a channel. As a result, it also benefits from identifiable abort, public verifiability, and guaranteed output delivery, and the client benefits from censorship resistance of blockchain systems.
Second, upon signing each block, the participating quorum may dynamically change and is post-determined.
Therefore, we design a fluid protocol, that supports a post-determined dynamic quorum in each communication round, thereby complying with existing broadcast channel implementations. Third, in permissionless networks, parties may join, leave, and change their stake. Therefore, we offer protocols for network reconfiguration, with complexity independent of the number of clients in the system, and our protocol efficiently supports a weighted threshold access structure for the network. Specifically, the complexity of distributed key generation and presign only depends on the number of parties and not on the overall weight, and the amortized cost of sign only depends on the individual weight.

Furthermore, our protocol introduces key improvements, including the removal of zero-knowledge proofs towards the client, and presigns with a non-interactive client. For Schnorr, the presigns are client-independent, and can be collected by the blockchain in a common pool, available for all clients in the system. These optimizations reduce communication overhead and improve the system's ability to handle traffic spikes during high-demand periods.

Our protocol is UC-secure, and is therefore natively designed for multiple clients to use the system in parallel. Notably, we propose a novel assumption, Slightly-Enhanced ECDSA Unforgeability, offering concrete security for 256-bit elliptic curves for threshold ECDSA with support for parallel execution of presigns.

In addition to securing cryptocurrency wallets, we demonstrate how our protocol enables various cross-chain applications, such as decentralized bridges, future transactions, andwallet transfer. Our system is designed for interoperability across multiple blockchains, enhancing security, scalability, and flexibility for decentralized finance (DeFi) ecosystems.
]]></content:encoded>
<pubDate>Thu, 20 Feb 2025 08:21:42 +0000</pubDate>
</item>
<item>
<title>Anamorphic-Resistant Encryption; Or Why the Encryption Debate is Still Alive</title>
<link>https://eprint.iacr.org/2025/293</link>
<guid>https://eprint.iacr.org/2025/293</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密、政府解密权限、语义安全、后门、Anamorphic-resistant (AR)加密

<br /><br />总结:
这篇文章探讨了关于政府是否应该有权解密公民私人信息的问题。传统观点认为，语义安全性使得总会存在某种形式的隐写术，因此为保证安全性不应在加密方案中添加后门，因为这只会削弱“好人”的安全性，而“坏人”可以轻易规避审查。然而，本文提出了三个假设世界：Dictatoria（政府完全控制，无法方便使用隐写术）、Warrantland（有制衡机制，需要用户配合但无便捷隐写术）和Privatopia（隐私至上，内置高效率隐写术）。作者通过定义并设计名为Anamorphic-resistant (AR)的新型加密方案，给出了这三个世界可能性的有力证据。与文献中研究过的可塑性加密方案不同，任何试图利用AR加密方案进行隐写通信的行为都将变得非常困难或极其缓慢。这一发现重新从技术层面开启了加密辩论。 <div>
Ever since the introduction of encryption, society has been divided over whether the government (or law enforcement agencies) should have the capability to decrypt private messages (with or without a war- rant) of its citizens. From a technical viewpoint, the folklore belief is that semantic security always enables some form of steganography. Thus, adding backdoors to semantically secure schemes is pointless: it only weakens the security of the “good guys”, while “bad guys” can easily circumvent censorship, even if forced to hand over their decryption keys. 

In this paper we put a dent in this folklore. We formalize three worlds: Dictatoria (“dictator wins”: no convenient steganography, no user co- operation needed), Warrantland (“checks-and-balances”: no convenient steganography, but need user’s cooperation) and Privatopia (“privacy wins”: built-in, high-rate steganography, even if giving away the decryption key). We give strong evidence that all these worlds are possible, thus reopening the encryption debate on a technical level. 

Our main novelty is the definition and design of special encryption schemes we call anamorphic-resistant (AR). In contrast to so called “anamorphic schemes”, — which were studied in the literature and form the basis of Privatopia, — any attempt to steganographically communicate over an AR-encryption scheme will be either impossible or hugely slow (depending on the definitional details).
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 21:48:22 +0000</pubDate>
</item>
<item>
<title>Dynamic Decentralized Functional Encryption: Generic Constructions with Strong Security</title>
<link>https://eprint.iacr.org/2025/290</link>
<guid>https://eprint.iacr.org/2025/290</guid>
<content:encoded><![CDATA[
<div> 关键词: 动态分布式功能性加密 (DDFE)，功能隐藏，学习与错误 (LWE) 假设，内积，属性权重和访问控制

总结:
本文提出了新的通用编译器，这些编译器在利用现有文献中的方案实例化后，能在安全级别、计算假设以及功能方面超越当前最先进的动态分布式功能性加密（DDFE）技术。具体来说，我们首次实现了在标准模型及更强的功能隐藏设置下适应性安全的DDFE方案，用于内积运算，保证了消息及所评估函数的隐私。此外，我们还展示了首个基于LWE假设在标准模型下证明安全性的DDFE内积方案。最后，我们给出了首个带有属性权重和访问控制的DDFE构造（尽管存在一些限制）。而此前的所有构造仅能提供选择性安全性，依赖于基于配对的群组假设，并无法实现访问控制。 <div>
Dynamic Decentralized Functional Encryption (DDFE) is a generalization of Functional Encryption which allows multiple users to join the system dynamically without interaction and without relying on a trusted third party.  Users can independently encrypt their inputs for a joint evaluation under functions embedded in functional decryption keys; and they keep control on these functions as they all have to contribute to the generation of the functional keys.
 
In this work, we present new generic compilers which, when instantiated with existing schemes from the literature, improve over the state-of-the-art in terms of security, computational assumptions and functionality. Specifically, we obtain the first adaptively secure DDFE schemes for inner products in both the standard and the stronger function-hiding setting which guarantees privacy not only for messages but also for the evaluated functions. Furthermore, we present the first DDFE for inner products whose security can be proven under the LWE assumption in the standard model. Finally, we give the first construction of a DDFE for the attribute-weighted sums functionality with attribute-based access control (with some limitations). All prior constructions guarantee only selective security, rely on group-based assumptions on pairings, and cannot provide access control.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 15:57:18 +0000</pubDate>
</item>
<item>
<title>Verifiable Computation for Approximate Homomorphic Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/286</link>
<guid>https://eprint.iacr.org/2025/286</guid>
<content:encoded><![CDATA[
<div> 关键词：homomorphic encryption, RingLWE, CKKS方案, polynomial ring, proof system

总结:
本文针对基于同态加密（HE）方案的计算正确性验证问题提出了一种新解决方案，特别是处理RingLWE基础上的CKKS方案中的近似算术运算。该方法能在多项式环$R_q$中高效地处理密文算术，无需额外的仿真开销，并能以较小的成本管理密文维护操作，如模切换、密钥切换和重缩放。主要成果是一个简洁的论证系统，能够有效地处理关于$R_q$上的算术运算和范围检查。为构建这一论证系统，文章设计了新的多项式交互式Oracle证明（PIOPs）和支持$R_q$上多项式的多线性多项式承诺，与以往仅关注有限域的工作不同。通过实现和实验，我们验证了本方法的具体复杂度，相较于当前RNS方案的可验证HE的最优实践，对于小电路，我们的方法展现出相似性能，同时能更有效地扩展到更大的电路，这是先前构造所面临的重大挑战，因为它们需要验证如重新线性化等程序。 <div>
We address the problem of proving the validity of computation on ciphertexts of homomorphic encryption (HE) schemes, a feature that enables outsourcing of data and computation while ensuring both data privacy and integrity.
We propose a new solution that handles computations in RingLWE-based schemes, particularly the CKKS scheme for approximate arithmetic. Our approach efficiently handles ciphertext arithmetic in the polynomial ring $R_q$ without emulation overhead and manages ciphertexts maintenance operations, such as modulus switching, key switching, and rescaling, with small cost.
Our main result is a succinct argument that efficiently handles arithmetic computations and range checks over the ring $R_q$. To build this argument system, we construct new polynomial interactive oracle proofs (PIOPs) and multilinear polynomial commitments supporting polynomials over $R_q$, unlike prior work which focused on finite fields. We validate the concrete complexity of our approach through implementation and experimentation. Compared to the current state-of-the-art on verifiable HE for RNS schemes, we present similar performance for small circuits while being able to efficiently scale to larger ones, which was a major challenge for previous constructions as it requires verifying procedures such as relinearization.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 09:36:05 +0000</pubDate>
</item>
<item>
<title>S2DV: Scalable and Secure DAO Voting</title>
<link>https://eprint.iacr.org/2025/284</link>
<guid>https://eprint.iacr.org/2025/284</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Autonomous Organization (DAO), voting system, scalability, security, Groth16 zk-SNARKs, exponential ElGamal encryption算法

总结:
本文提出了一种针对去中心化自治组织(DAO)的可扩展且安全的投票系统。该系统利用Groth16 zk-SNARKs保证了投票过程的安全性，确保了加密的选票准确反映选民的投票权、仅加密有效的非负投票值以及正确执行同态求和。同时，通过应用指数ElGamal加密算法实现离线计算，减少了区块链的计算成本，实现了决策制定的规模化。实验证明，该S2DV协议的证明验证速度极快，非常适用于可扩展的DAO投票系统，同时保持了选举的安全性。 <div>
Decentralized Autonomous Organization operates without a central entity, being owned and governed collectively by its members. In this organization, decisions are carried out automatically through smart contracts for routine tasks, while members vote for unforeseen issues. Scalability in decision-making through voting on proposals is essential to accommodate a growing number of members without sacrificing security. This paper addresses this challenge by introducing a scalable and secure DAO voting system that ensures security through Groth16 zk-SNARKs and exponential ElGamal encryption algorithm while achieving scalability by verifiably delegating heavy computations to untrusted entities. While offline computation on the exponential ElGamal homomorphic encryption algorithm is enabled to reduce the computational cost of the blockchain, Groth16 is allowed to maintain robust off-chain calculation without revealing any further details. Specifically, the Groth16 proof guarantees that (i) the encrypted votes accurately reflect the voter's voting power, ensuring no unauthorized weight manipulation; (ii) only valid non-negative vote values are encrypted, preventing unintended or malicious vote tampering; and (iii) the homomorphic summation is performed correctly.  The implementation shows that the proofs are verified remarkably fast, making the S2DV protocol highly suitable for scalable DAO voting, while preserving the security of the election.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 07:47:51 +0000</pubDate>
</item>
<item>
<title>Breaking and Fixing Anonymous Credentials for the Cloud</title>
<link>https://eprint.iacr.org/2019/1061</link>
<guid>https://eprint.iacr.org/2019/1061</guid>
<content:encoded><![CDATA[
<div> 关键词: 属性基凭证(ABC)、加密属性基凭证(EABC)、云计算提供商、安全性攻击、修订模型

总结:
文章讨论了属性基凭证(ABC)系统及其在实际中的应用，特别是在Krenn等人提出的加密属性基凭证(EABC)中，计算被外包给半可信的云钱包以提高效率并实现隐私保护的身份管理服务。然而，文章指出了一个简单的攻击方式：当云钱包与另一用户合谋时，可以泄露用户的属性信息，这是原模型未考虑的情况。因此，文章对Krenn等人的模型和构造进行了修订，成功防止了上述攻击，并移除了原有构架中关于钱包和服务提供者或发行者之间不串通的假设。同时，新协议仍保持高效性，用户端的计算工作仅涉及一次指数运算，整体效率与Krenn等人原始工作相当。 <div>
In an attribute-based credential (ABC) system, users obtain a digital certificate on their personal attributes, and can later prove possession of such a certificate in an unlinkable way, thereby selectively disclosing chosen attributes to the service provider. Recently, the concept of encrypted ABCs (EABCs) was introduced by Krenn et al. at CANS 2017, where virtually all computation is outsourced to a semi-trusted cloud-provider called wallet, thereby overcoming existing efficiency limitations on the user’s side, and for the first time enabling “privacy-preserving identity management as a service”.
While their approach is highly relevant for bringing ABCs into the real world, we present a simple attack allowing the wallet to learn a user's attributes when colluding with another user -- a scenario which is not covered by their modeling but which needs to be considered in practice. We then revise the model and construction of Krenn et al. in various ways, such that the above attack is no longer possible. Furthermore, we also remove existing non-collusion assumptions between wallet and service provider or issuer from their construction.  Our protocols are still highly efficient in the sense that the computational effort on the end user side consists of a single exponentiation only, and otherwise efficiency is comparable to the original work of Krenn et al.
]]></content:encoded>
<pubDate>Sat, 21 Sep 2019 11:55:46 +0000</pubDate>
</item>
<item>
<title>Transistor: a TFHE-friendly Stream Cipher</title>
<link>https://eprint.iacr.org/2025/282</link>
<guid>https://eprint.iacr.org/2025/282</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密(FHE), 通信开销, 变换加密, Transistor, TFHE框架

总结:
Transistor是一种针对TFHE全同态加密框架设计的高效流密码，旨在解决FHE中因数据加密导致的通信开销问题。Transistor工作在$\mathbb{F}_{17}$域上，优化了TFHE性能。该流密码的关键组件采用TFHE友好的LFSR实现技术来低成本地增加状态大小，并使用类似于AES轮函数的非线性变换来更新仅有的、在TFHE中对应于昂贵可编程引导操作的小型有限状态机。与SNOW或LEX等其他流密码不同，Transistor提供了信息论安全证明，表明攻击者无法从三个或更少连续密钥流输出中获取关于秘密密钥的任何信息。通过对潜在相关性的深入分析，进一步限制了恢复秘密密钥所需的最小密钥流长度。在实际应用中，Transistor的实现显著优于现有TFHE变换加密技术，实现了超过60位/秒的标准CPU吞吐量，同时避免了需要昂贵的初始化过程。 <div>
Fully Homomorphic Encryption (FHE) allows computations on encrypted data without requiring decryption, ensuring data privacy during processing.  However, FHE introduces a significant expansion of ciphertext sizes compared to plaintexts, which results in higher communication. A practical solution to mitigate this issue is  transciphering, where only the master key is homomorphically encrypted, while the actual data is encrypted using a symmetric cipher, usually a stream cipher. The server then homomorphically evaluates the stream cipher to convert the encrypted data into a homomorphically encrypted form.

We introduce Transistor, a stream cipher specifically designed for efficient homomorphic evaluation within the TFHE scheme, a widely-used FHE framework known for its fast bootstrapping and ability to handle low-precision data. Transistor operates on $\mathbb{F}_{17}$ which is chosen to optimize TFHE performances. Its components are carefully engineered to both control noise growth and provide strong security guarantees. First, a simple TFHE-friendly implementation technique for LFSRs allows us to use such components to cheaply increase the state size. At the same time, a small Finite State Machine is the only part of the state updated non-linearly, each non-linear operation corresponding in TFHE to a rather expensive Programmable Bootstrapping. This update is done using an AES-round-like transformation. But, in contrast to other stream ciphers like SNOW or LEX, our construction comes with information-theoretic security arguments proving that an attacker cannot obtain any information about the secret key from three or fewer consecutive keystream outputs. These information-theoretic arguments are then combined with a thorough analysis of potential correlations to bound the minimal keystream length required for recovering the secret key.

Our implementation of Transistor significantly outperforms the state of the art of TFHE transciphering, achieving a throughput of over 60 bits/s on a standard CPU, all while avoiding the need for an expensive initialization process.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 19:21:38 +0000</pubDate>
</item>
<item>
<title>Tighter Control for Distributed Key Generation: Share Refreshing and Expressive Reconstruction Policies</title>
<link>https://eprint.iacr.org/2025/277</link>
<guid>https://eprint.iacr.org/2025/277</guid>
<content:encoded><![CDATA[
<div> 关键词: 私钥管理、安全性、分布式秘密共享、Shamir's secret sharing、刷新机制、访问结构、阈值访问树

<br /><br />总结:
本文针对私钥安全管理问题，特别是对于公众而言，丢失私钥可能导致不可逆资产损失的挑战。文章关注了传统的托管方式存在的安全风险，并提出了一种基于Shamir's secret sharing的分布式、可验证和可扩展的密钥恢复方案的扩展，该方案通过将信任分散到多个参与方来提高安全性。关键创新在于引入了一个刷新阶段，确保私钥份额的安全性，防止长期暴露。文中探讨了三种不同的份额刷新方法，分析并比较了它们的安全保证和计算复杂度。此外，为了实现对密钥重构更细粒度的控制，该协议还被扩展以支持更复杂的访问结构，特别关注了阈值访问树的应用。 <div>
The secure management of private keys is a fundamental challenge, particularly for the general public, as losing these keys can result in irreversible asset loss. Traditional custodial approaches pose security risks, while decentralized secret sharing schemes offer a more resilient alternative by distributing trust among multiple parties. In this work, we extend an existing decentralized, verifiable, and extensible cryptographic key recovery scheme based on Shamir's secret sharing. We introduce a refresh phase that ensures proactive security, preventing long-term exposure of secret shares. Our approach explores three distinct methods for refreshing shares, analyzing and comparing their security guarantees and computational complexity. Additionally, we extend the protocol to support more complex access structures, with a particular focus on threshold access trees, enabling fine-grained control over key reconstruction.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 14:56:47 +0000</pubDate>
</item>
<item>
<title>White-Box Watermarking Signatures against Quantum Adversaries and Its Applications</title>
<link>https://eprint.iacr.org/2025/265</link>
<guid>https://eprint.iacr.org/2025/265</guid>
<content:encoded><![CDATA[
<div> 关键词：软件水印、公钥加密、量子对手、数字签名、白盒提取

总结:
本文探讨了针对量子敌手的白盒水印技术在数字签名中的应用。研究内容包括构造能在保证签名功能完整性的前提下，从海盗量子电路中安全提取嵌入水印的白盒水印签名方案，同时确保对带有水印的签名函数的黑盒访问不会泄露嵌入信息。文章指出，在签名场景下，隐私保护问题相比公钥加密更为关键，并提出了利用学习错误（LWE）假设和量子全同态加密构建的安全方案。此外，文中还关注了签名的通用复制保护概念，定义了一个不改变验证密钥或验证算法，将任何量子安全签名方案转化为具有复制保护特性的机制。然而，文章进一步证明了对于所有量子安全签名实现普遍复制保护是不可能的，这一结论基于其提出的对抗量子敌手的白盒水印签名方案。 <div>
Software watermarking for cryptographic functionalities enables embedding an arbitrary message (a mark) into a cryptographic function. An extraction algorithm, when provided with a (potentially unauthorized) circuit, retrieves either the embedded mark or a special symbol unmarked indicating the absence of a mark. It is difficult to modify or remove the embedded mark without destroying the functionality of a marked function. Previous works have primarily employed black-box extraction techniques, where the extraction algorithm requires only input-output access to the circuit rather than its internal descriptions (white-box extraction). Zhandry (CRYPTO 2021) identified several challenges in watermarking public-key encryption (PKE) with black-box extraction and introduced the notion of privacy for white-box watermarking against classical adversaries. Kitagawa and Nishimaki (Journal of Cryptology 37(3)) extended watermarking techniques to pseudorandom functions (PRFs) and PKE in the presence of quantum adversaries, enabling extraction from pirate quantum circuits but failing to achieve privacy.

In this work, we investigate white-box watermarking for digital signatures secure against quantum adversaries. Our constructions enable the extraction of embedded marks from the description of a pirate quantum circuit that produces valid signatures while ensuring that black-box access to a marked signing function does not reveal information about the embedded mark. We define and construct white-box watermarking signatures that are secure against quantum adversaries, leveraging the leaning with errors (LWE) assumption and quantum fully homomorphic encryption. Furthermore, we highlight that privacy concerns are even more critical in the context of signatures than in PKE. We also present a compelling practical application of white-box watermarking signatures.

Additionally, we explore the concept of universal copy protection for signatures. We define universal copy protection as a mechanism that transforms any quantumly secure signature scheme into a copy-protected variant without altering the verification key or verification algorithm. This approach is preferable to developing specific copy-protected signature schemes, as it allows existing schemes to be secured without modifying their published verification keys. We demonstrate that universal copy protection for all quantum secure signatures is impossible by leveraging our white-box watermarking signatures secure against quantum adversaries.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 05:01:32 +0000</pubDate>
</item>
<item>
<title>HasteBoots: Proving FHE Bootstrapping in Seconds</title>
<link>https://eprint.iacr.org/2025/261</link>
<guid>https://eprint.iacr.org/2025/261</guid>
<content:encoded><![CDATA[
<div> 关键词：Fully Homomorphic Encryption (FHE)，验证完整性，bootstrapping，HasteBoots，zkVM，SNARKs，证明生成时间，效率提升，可扩展性，隐私保护计算。

<br /><br />总结: 本文提出了一个名为HasteBoots的新颖方案，用于解决全同态加密（FHE）中计算完整性的验证问题，特别是针对FHE中最耗时的操作——引导（bootstrapping）。现有的方法如基于zkVM的解决方案和通用SNARKs在证明生成时间上存在效率低下问题，可能需要数小时至数天。通过定制化的多项式交互式Oracle证明和优化的多项式承诺方案，HasteBoots实现了对FHE引导操作在几秒内完成证明生成，显著优于现有技术。这表明了实现可扩展且高效的可验证FHE的可能性，为实践中的隐私保护计算铺平道路。 <div>
Fully Homomorphic Encryption (FHE) enables computations on encrypted data, ensuring privacy for outsourced computation. However, verifying the integrity of FHE computations remains a significant challenge, especially for bootstrapping, the most computationally intensive operation in FHE. Prior approaches, including zkVM-based solutions and general-purpose SNARKs, suffer from inefficiencies, with proof generation times ranging from several hours to days. In this work, we propose HasteBoots, a succinct argument tailored for FHE operations. By designing customized polynomial interactive oracle proofs and optimized polynomial commitment schemes, HasteBoots achieves proof generation in a few seconds for FHE bootstrapping, significantly outperforming existing methods. Our approach demonstrates the potential for scalable and efficient verifiable FHE, paving the way for practical, privacy-preserving computations.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 02:20:55 +0000</pubDate>
</item>
<item>
<title>TFHE Gets Real: an Efficient and Flexible Homomorphic Floating-Point Arithmetic</title>
<link>https://eprint.iacr.org/2025/257</link>
<guid>https://eprint.iacr.org/2025/257</guid>
<content:encoded><![CDATA[
<div> 关键词: 浮点数运算、全同态加密(FHE)、TFHE、精度、计算速度

总结:
本文关注于在全同态加密（FHE）领域中实现浮点数运算是如何至关重要的，特别是在保护机器学习中的用户隐私方面。文章以TFHE为例，开发了新的同态算子，旨在构建精确且可适应的同态浮点运算。尽管面临如小消息空间和计算过程中缺乏信息等挑战，研究者仍成功为常见的浮点数精度（例如32位和64位）确定了参数，并实现了较高的计算速度：在多线程环境下，32位浮点数加法可在2.5秒内完成，乘法大约需要1秒。这些实测结果表明，提出的方案具有高效性和实用性，显著超越了先前的工作，从而在理论上与实际应用之间架起了一座桥梁，使FHE在现实场景中的运用变得更加可行。 <div>
Floating-point arithmetic plays a central role in computer science and is used in various domains where precision and computational scale are essential. One notable application is in machine learning, where Fully Homomorphic Encryption (FHE) can play a crucial role in safeguarding user privacy. In this paper, we focus on TFHE and develop novel homomorphic operators designed to enable the construction of precise and adaptable homomorphic floating-point operations. Integrating floating-point arithmetic within the context of FHE is particularly challenging due to constraints such as small message space and the lack of information during computation. Despite these challenges, we were able to determine parameters for common precisions (e.g., 32-bit, 64-bit) and achieve remarkable computational speeds, with 32-bit floating-point additions completing in 2.5 seconds and multiplications in approximately 1 second in a multi-threaded environment. These metrics provide empirical evidence of the efficiency and practicality of our proposed methods, which significantly outperform previous efforts. Our results demonstrate a significant advancement in the practical application of FHE, making it more viable for real-world scenarios and bridging the gap between theoretical encryption techniques and practical usability.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 14:59:27 +0000</pubDate>
</item>
<item>
<title>Inaccessible Entropy for Watermarking Generative Agents</title>
<link>https://eprint.iacr.org/2025/256</link>
<guid>https://eprint.iacr.org/2025/256</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、生成式代理、不可伪造水印、无失真、公开验证

总结:
本文提出了一种针对语言模型和生成式代理的无失真、不可伪造水印构造方法。该水印方案确保了水印无法被对手有效伪造或在不显著降低模型输出质量的情况下移除。水印输出保持无失真，即水印算法不会明显改变模型输出的质量，而且没有公共检测密钥的攻击者无法有效区分是否添加了水印的输出。水印方案的核心在于将消息与可公开验证的数字签名嵌入到生成的模型输出中。在检测阶段，任何拥有公钥的授权实体都可以提取并验证这些信息。文章证明，基于标准密码学假设——单向函数的存在，可以构建这样的无失真、不可伪造水印方案。该框架依赖于分析基于单向函数的计算熵概念的水印方案的不可访问熵。 <div>
In this work, we construct distortion-free and unforgeable watermarks for language models and generative agents. The watermarked output cannot be forged by a adversary nor removed by the adversary without significantly degrading model output quality. That is, the watermarked output is distortion-free: the watermarking algorithm does not noticeably change the quality of the model output and without the public detection key, no efficient adversary can distinguish output that is watermarked from outputs which are not. The core of the watermarking schemes involve embedding a message and publicly-verifiable digital signature in the generated model output. The message and signature can be extracted during the detection phase and verified by any authorized entity that has a public key. We show that, assuming the standard cryptographic assumption of one-way functions, we can construct distortion-free and unforgeable watermark schemes. Our framework relies on analyzing the inaccessible entropy of the watermarking schemes based on computational entropy notions derived from the existence of one-way functions.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 13:09:06 +0000</pubDate>
</item>
<item>
<title>Masquerade: Verifiable Multi-Party Aggregation with Secure Multiplicative Commitments</title>
<link>https://eprint.iacr.org/2021/1370</link>
<guid>https://eprint.iacr.org/2021/1370</guid>
<content:encoded><![CDATA[
<div> 关键词: 众包数据聚合、隐私保护、公共审计、可验证性、分布式账本

总结:
本文提出两种名为Masquerade和zk-Masquerade的协议，用于计算私有统计数据（如求和、平均值和直方图）的同时，不泄露参与者的原始数据。为确保数据聚合的完整性，文中设计了一种定制化的乘法承诺方案，并将所有参与者的承诺发布到分布式账本上，以实现公众可验证性。针对恶意参与者可能尝试破坏聚合结果的问题，zk-Masquerade采用两种零知识证明协议，确保共享数据点的有效性并在聚合前进行验证，从而支持广泛的数量和类别研究。实验中，使用了同态加密和承诺对不同数量的参与者进行了评估，并分析了协议运行时间和通信成本。 <div>
In crowd-sourced data aggregation over the Internet, participants share their data points with curators. However, a lack of strong privacy guarantees may discourage participation, which motivates the need for privacy-preserving aggregation protocols. Moreover, existing solutions remain limited with respect to public auditing without revealing the participants' data. In realistic applications, however, there is an increasing need for public verifiability (i.e., verifying the protocol correctness) while preserving the privacy of the participants' inputs, since the participants do not always trust the data curators. At the same time, while publicly distributed ledgers may provide public auditing, these schemes are not designed to protect sensitive information.

In this work, we introduce two protocols, dubbed Masquerade and zk-Masquerade, for computing private statistics, such as sum, average, and histograms, without revealing anything about participants' data. We propose a tailored multiplicative commitment scheme to ensure the integrity of data aggregations and publish all the participants' commitments on a ledger to provide public verifiability. zk-Masquerade detects malicious participants who attempt to poison the aggregation results by adopting two zero-knowledge proof protocols that ensure the validity of shared data points before being aggregated and enable a broad range of numerical and categorical studies. In our experiments, we use homomorphic ciphertexts and commitments for a variable number of participants and evaluate the runtime and the communication cost of our protocols.
]]></content:encoded>
<pubDate>Tue, 12 Oct 2021 06:24:19 +0000</pubDate>
</item>
<item>
<title>K-Linkable Ring Signatures and Applications in Generalized Voting</title>
<link>https://eprint.iacr.org/2025/243</link>
<guid>https://eprint.iacr.org/2025/243</guid>
<content:encoded><![CDATA[
<div> 关键词：Linkable Ring Signatures (LRS)，$k$-Linkable Ring Signatures ($k$-LRS)，投票隐私，匿名性，集体$k$-链接性

总结:

本文提出了$k$-可链接环签名($k$-LRS)这一新型密码学原语，用于在多样化的投票场景中同时实现匿名性和隐私保护。传统的可链接环签名(LRS)适用于防止重复投票的多数制选举，但在排名投票等更复杂的规则下，会暴露选民个体的投票偏好。$k$-LRS具有$k$级匿名性和$k$级链接性特点：用户最多可以匿名签署$k$次，使得即使是无限制的对手也无法关联其签名（$k$级匿名性）；若任何签名人签超过$k$次，则其所有签名将被公开链接（个体$k$-链接性），并且任何$c$个签名人无法生成多于$k\cdot c$个未链接的签名（集体$k$-链接性）。文章提供了基于DDH和SIS（因此是后量子安全的）两种$k$-LRS构造方法，并展示了如何将其应用于包括得分投票、多轮投票和博尔达计数等多种投票规则中。提出的协议为非交互式投票，即每个选民只需在公告板上发布一条消息，这突显了$k$-LRS在区块链治理等场景中的应用潜力。 <div>
$\textit{Linkable ring signatures}$ (LRS) allow a user to sign anonymously on behalf of a ring, while maintaining linkability—two signatures from the same signer are publicly identified, i.e., linked. This linkability makes LRS suitable to prevent double-voting in classical, $\textit{plurality}$ voting protocols—each voter casts one vote and the candidate with the most votes wins the election. 

    Several voting scenarios rely on (generalized) rules rather than plurality. For example, in $\textit{ranked voting}$, voters submit a ranking of the candidates, and the outcome is a function of these rankings. Such generalized voting rules are common in social choice theory, and have recently found their way into blockchain governance, e.g., for prioritizing (voting on) proposed (candidate)  projects. However, unlike plurality voting, using LRS for voters to sign their votes (rankings) does not guarantee vote privacy as one can observe the rankings of each individual voter, which, depending on the scoring rule, is more information than what the outcome of the election offers. 

We introduce $k$-$\textit{linkable ring signatures}$ ($k$-LRS) as a primitive for simultaneously achieving anonymity and privacy in generalized voting. A $k$-LRS scheme has the following properties: 
   ($k$-)$\textit{Anonymity}$: a user can sign anonymously (on behalf of the ring) up to $k$ times, so that even an unbounded adversary cannot link his signatures.
   ($k$-)$\textit{Linkability}$: If any signer signs more than $k$ times, all his signatures are publicly linked $\textit{(individual $k$-linkability)}$; and, any set of $c$ signers cannot generate more than $k\cdot c$ unlinked signatures $\textit{(collective $k$-linkability)}$.

    We provide two constructions of $k$-LRS: one is from the DDH, and the other is from SIS (hence post-quantum). Finally, we show how $k$-LRS can be applied to a broad range of voting rules, including $\textit{score voting}$, $\textit{multi-voting}$, and $\textit{Borda}$. Our protocols are non-interactive voting—each voter just posts a message on a bulletin board—which highlights the potential of $k$-LRS in blockchain-governance scenarios.
]]></content:encoded>
<pubDate>Sun, 16 Feb 2025 05:14:11 +0000</pubDate>
</item>
<item>
<title>IBE-IBE: Intent-Based Execution through Identity-Based Encryption and Auctions</title>
<link>https://eprint.iacr.org/2025/241</link>
<guid>https://eprint.iacr.org/2025/241</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式、无领导节点、密封投标拍卖、动态定价、区块链网络、多党计算(MPC)、身份基加密(IBE)、公平性、去中心化、价格发现透明度、安全性、竞争、意图保密、全同态加密(FHE)、可信执行环境(TEE)、 frontrunning风险、中央集权化、快速结算、去中心金融(DeFi)

<br /><br />总结:

本文提出了一种基于区块链网络的分布式、无领导节点的密封投标拍卖模型，用于动态定价意图。该模型利用多党计算(MPC)和身份基加密(IBE)来提升定价效率并确保公平与去中心化。通过解决当前集中式或静态定价机制的脆弱性，我们的方法促进了透明、安全且具有竞争力的价格发现过程。同时，我们通过多党计算(MPC)、全同态加密(FHE)和可信执行环境(TEE)进一步增强了意图信息的机密性，有效降低了frontrunning风险和中央集权化的隐患，保持了去中心金融(DeFi)中至关重要的快速结算时间。 <div>
This paper introduces a decentralized and leaderless sealed bid auction model for dynamic pricing of intents across blockchain networks. We leverage Multi-Party Computation (MPC) and Identity-Based Encryption (IBE) to improve pricing while ensuring fairness and decentralization. By addressing the vulnerabilities of current centralized or static pricing mechanisms, our approach fosters transparent, secure, and competitive price discovery. We further enhance the confidentiality of intents through Multi-Party Computation (MPC), Fully Homomorphic Encryption (FHE), and Trusted Execution Environments (TEE). Our novel methodology mitigates the risks of frontrunning and centralization while preserving the rapid settlement times essential to decentralized finance (DeFi).
]]></content:encoded>
<pubDate>Sat, 15 Feb 2025 22:52:28 +0000</pubDate>
</item>
<item>
<title>DART: Decentralized, Anonymous, and Regulation-friendly Tokenization</title>
<link>https://eprint.iacr.org/2025/239</link>
<guid>https://eprint.iacr.org/2025/239</guid>
<content:encoded><![CDATA[
<div> 关键词: DART、匿名支付系统、多资产类型、非交互式支付、可逆性机制

总结:
DART是一个全新的完全匿名、基于账户的支付系统，它兼顾了现实世界的多种考量因素，包括监管合规性，并实现了常量级别的交易大小。该系统支持多种资产类型，允许用户发行链上资产，如代币化的现实世界资产。通过隐藏资产类型、交易金额、余额以及发送者和接收者的身份信息，DART确保了交易的机密性和匿名性，并保证了交易间的不可链接性。同时，系统提供了一种针对特定资产的审计机制，使得发行人可以为他们发行的资产指定特定的审计员，同时保护审计员的身份隐私，以实现资产类型隐私。只有指定的审计员才能解密与其关联资产相关的交易，并且用户能在交易中有效地证明（隐藏的）资产类型与（隐藏的）指定审计员之间的关联。

DART还支持非交互式支付，即使接收方离线，在线的发送方也能提交交易，同时还结合了一个接收方确认机制，体现了现实中接收方需确认或否认接收到的交易这一合规要求。据我们所知，这是无许可环境中首个此类方案。为了应对各种可能情况，DART还包括了一个可逆性机制，使发送方可以在接收方未确认的情况下从待处理交易中取回资金。此外，它还提供了保护隐私的资产余额证明机制。

DART系统在支持并发的入站和出站交易的同时保持了完全匿名性，解决了许多基于账户的匿名系统中存在的常见问题。DART还展示了如何高效地支持多方交易，即在一个交易中向多个接收方付款。我们在通用组合(UC)设置下给出了完整的正式模型以及一个UC协议实现。 <div>
We introduce DART, a fully anonymous, account-based payment system designed to address a comprehensive set of real-world considerations, including regulatory compliance, while achieving constant transaction size. DART supports multiple asset types, enabling users to issue on-chain assets such as tokenized real-world assets. It ensures confidentiality and anonymity by concealing asset types, transaction amounts, balances, and the identities of both senders and receivers, while guaranteeing unlinkability between transactions. Our design provides a mechanism for asset-specific auditing. Issuers can designate asset-specific auditors for the assets they issue, with the system preserving the privacy of the auditor’s identity to achieve asset type privacy. Only the designated auditor is authorized to decrypt transactions related to their associated asset, and users efficiently prove the association between the (hidden) asset type and the (hidden) designated auditor in their transactions. 

DART supports non-interactive payments, allowing an online sender to submit a transaction even when the receiver is offline, while still incorporating a receiver affirmation mechanism that captures the real-world compliance consideration where the receiver must confirm (or deny) an incoming transaction. To the best of our knowledge, this is the first scheme of this kind in the permissionless setting. To accommodate all eventualities, DART also incorporates a reversibility mechanism, enabling senders to reclaim funds from pending transactions if the receiver’s affirmation is not yet provided. Finally, it offers a privacy-preserving proof of balance (per asset type) mechanism. 

Our system achieves full anonymity while supporting concurrent incoming and outgoing transactions, resolving a common issue that plagues many account-based anonymous systems. We further demonstrate how our system supports multi-party transactions, allowing payment to multiple receivers in one transaction efficiently. We provide a full formal model in the Universal Composition (UC) setting, as well as a UC protocol realization.
]]></content:encoded>
<pubDate>Sat, 15 Feb 2025 14:46:13 +0000</pubDate>
</item>
<item>
<title>The Quantum Decoherence Model: Everlasting Composable Secure Computation and More</title>
<link>https://eprint.iacr.org/2025/220</link>
<guid>https://eprint.iacr.org/2025/220</guid>
<content:encoded><![CDATA[
<div> 关键词：量子密码学、量子退相干模型（QDM）、通用可组合性框架、非交互式承诺方案、永远安全

总结:
文章提出了一个新的安全模型——量子退相干模型（QDM），该模型描述了在协议运行期间和结束后一段时间内受到计算限制的对手，但在协议终止很久之后变得计算上无限制，但只能记住有限数量的先前状态的量子位。在此基础上，文章提供了一个带有量子随机预言机的增强版通用可组合性框架，并构建了一个针对恶意发送者具有无条件和统计安全性，以及对恶意接收者具有永远安全性的非交互式承诺方案。此方案可以推广到实现具有永远安全性的多方安全计算。此外，文章的核心技术还可以应用于更广泛的问题，如生成在QDM下具有永远安全性的公开密钥加密和OT，以及在量子退相干设置下的压缩不可行加密，并表明使用后量子IND-CPA安全的公钥加密无需依赖随机预言机即可实现这一概念。这一切都基于一个新颖而简洁的强大反熵不确定性原理。 <div>
Quantum cryptography allows to achieve security goals which are unobtainable using classical cryptography alone: it offers the promise of everlasting privacy. Thatis, an adversary trying to attack a protocol must succeed during the run of the protocol.
After the protocol has terminated, security holds unconditionally.
In this work, we initiate the study of a new model which we call the quantum decoherence model (QDM). In a nutshell, this model captures adversaries that are computationally bounded during the run of a protocol (and some time after), but become computationally unbounded long after the protocol terminates. Importantly, once the adversary becomes computationally unbounded, he can only remember a bounded number of qubits from before the computational bound was lifted.
We provide a variant of the Universal Composability framework which captures the new notion of quantum decoherence and augment it with quantum random oracles. As our main contribution, we construct a non-interactive commitment scheme achieving unconditional and statistical security against malicious senders and everlasting security against malicious receivers under our new security notion. Such commitments imply general secure multiparty computation with everlasting security.
Finally, we show that our core technique can be applied to a broader spectrum of problems. We show that it gives rise to everlasting public key encryption and OT in the QDM. Finally, we also consider the weaker notion of incompressible encryption in the setting of quantum decoherence, and show that post-quantum IND-CPA secure public
key encryption is sufficient to realize this notion without resorting to random oracles.
At the technical core of our constructions is a new, conceptually simple yet powerful reverse entropic uncertainty relation.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 13:08:09 +0000</pubDate>
</item>
<item>
<title>Slot a la carte: Centralization Issues in Ethereum's Proof-of-Stake Protocol</title>
<link>https://eprint.iacr.org/2025/219</link>
<guid>https://eprint.iacr.org/2025/219</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、proof-of-stake (PoS)、distributed randomness beacons (DRBs)、RANDAO、manipulation

总结:

本文研究发现，以太坊当前的权益证明（PoS）共识机制对去中心化构成重大威胁。文章重点关注分布式随机数生成器（DRBs）在领导者选择中的可操纵性问题，特别是以太坊所使用的RANDAO DRB在现有形式下存在严重漏洞。研究指出，在有丰厚收益的槽位被预见的情况下，质押实体可能会临时合谋控制超过33%的验证者，从而使得他们能够以高达99.5%的成功率执行一系列RANDAO操纵攻击，锁定目标槽位。该方法的有效性源于其对于可能攻击行为模型的深入探索，包括通过在敌人自己的槽位中隐瞒区块或通过分叉他人的提议区块来错过主链上的区块。文章认为，虽然PoS有可能为区块链的未来发展铺平道路，但以太坊目前的DRB实现必须替换为更安全的机制。 <div>
In this paper, we demonstrate that Ethereum's current proof-of-stake (PoS) consensus mechanism poses a significant threat to decentralisation. Our research focuses on the manipulability of distributed randomness beacons (DRBs) in leader selection. Specifically, we show that RANDAO - Ethereum's DRB - is seriously vulnerable to manipulations in its current form.  For example, if a lucrative slot is foreseen, there is a risk that staking entities may temporarily collude to control $33\%$ of the validators, enabling them to execute a series of RANDAO manipulation attacks that secure the target slot with a $99.5\%$ success rate. The effectiveness of our method stems from the fact that we work with a significantly richer model of the possible attacks compared to previous works. Our manipulative strategies work by missing blocks from the canonical chain - either by withholding blocks in the adversary's own slots or by forking out blocks proposed by others. We argue that while PoS can pave the path in the future for blockchains, Ethereum's current DRB implementation has to be replaced with a more secure mechanism.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 12:29:05 +0000</pubDate>
</item>
<item>
<title>Practical Circuit Privacy/Sanitization for TFHE</title>
<link>https://eprint.iacr.org/2025/216</link>
<guid>https://eprint.iacr.org/2025/216</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全同态加密 (FHE), 两方计算 (2PC), 清理算法, TFHE, 实践性

总结:
本文介绍了针对TFHE（全同态加密）的一种新型清理算法，该算法解决了服务器输入隐私和电路隐私保护的问题。传统清理算法存在效率低下问题，需要多次引导或大量随机评估。新提出的算法仅对原始TFHE引导过程添加了两个轻量级的随机化步骤，无需改动核心算法，实现了单次引导和最小化的随机化清理，从而更接近实际应用。通过实证评估，新方法在一个TFHE密文清理上耗时35.88 ms，相比原版TFHE引导仅慢了3.4%（即1.18 ms）。相较于先前的工作，新方法在速度上有4.82到209.03倍的提升，显著提高了清理算法的效率和实用性。 <div>
Fully homomorphic encryption (FHE) enables the computation of arbitrary circuits over encrypted data. A widespread application of FHE is a simple two-party computation (2PC) protocol, where the server evaluates a circuit over the client's encrypted data and its private inputs. However, while the security of FHE guarantees that the client's data is protected from the server, there is no inherent support for the privacy of the server's input and the circuit.

One effective solution to this problem is an additional algorithm for FHE called sanitization, introduced by Ducas and Stehlé (Eurocrypt 2016). Roughly speaking, a sanitization algorithm removes any meaningful information contained in the ciphertext, including previous evaluations of circuits. Following their definition, several constructions for sanitization have been proposed, particularly for TFHE. However, all of these methods were impractical, requiring several bootstrappings or an excessive amount of randomized evaluations.

In this work, we construct a novel sanitization algorithm for TFHE that overcomes these issues. Our method only adds two lightweight randomization steps to the original TFHE bootstrapping, without any modifications to the core algorithms. As a result, our algorithm achieves sanitization with a single bootstrapping and minimal randomization, bringing sanitization closer to practicality.

To empirically evaluate the efficiency of our method, we provide concrete benchmark results based on our proof-of-concept implementation. Our algorithm sanitizes a single TFHE ciphertext in 35.88 ms, which is only 3.4% (1.18 ms) slower than the original TFHE bootstrapping with the same parameters. When directly compared to previous works, our method achieves a speedup by a factor of 4.82 to 209.03.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 10:47:11 +0000</pubDate>
</item>
<item>
<title>Prior-Based Label Differential Privacy via Secure Two-Party Computation</title>
<link>https://eprint.iacr.org/2025/211</link>
<guid>https://eprint.iacr.org/2025/211</guid>
<content:encoded><![CDATA[
<div> 关键词: 差分隐私(DP), 局部差分隐私(LDP), 标签差分隐私, 安全两方计算(2PC), 数据集(MNIST, CIFAR-10)

总结:
本文关注了在基于先验的局部差分隐私机制中存在的一种敏感先验信息泄露的隐私问题。为了解决这一挑战，同时保持训练模型的效率和准确性，文章提出了一种利用安全两方计算(2PC)协议的新方法来实施此类LDP机制，以避免先验信息泄漏。作者已在标准数据集MNIST和CIFAR-10上实现了该方案并进行了端到端测试。实验结果显示，采用2PC带来的安全性增强几乎无需额外成本：对于CIFAR-10，在强差分隐私参数下，使用2PC导致的运行时间开销仅增加了约3.9%，而相对于不安全（非2PC）方法，精度下降仅为0.4%。 <div>
Differential privacy (DP) is a fundamental technique used in machine learning (ML) training for protecting the privacy of sensitive individual user data. In the past few years, a new approach for combining prior-based Local Differential Privacy (LDP) mechanisms with a relaxed DP criterion, known as Label DP, has shown great promise in increasing the utility of the final trained model without compromising on the DP privacy budget. In this work, we identify a crucial privacy gap in the current implementations of these prior-based LDP mechanisms, namely the leakage of sensitive priors. We address the challenge of implementing such LDP mechanisms without leaking any information about the priors while preserving the efficiency and accuracy of the current insecure implementations. To that end, we design simple and efficient secure two-party computation (2PC) protocols for addressing this challenge, implement them, and perform end-to-end testing on standard datasets such as MNIST, CIFAR-10. Our empirical results indicate that the added security benefit essentially comes almost for free in the sense that the gap between the current insecure implementations and our proposed secure version, in terms of run-time overhead and accuracy degradation, is minimal. E.g., for CIFAR-10, with strong DP privacy parameter, the additional runtime due to 2PC is $\approx 3.9\%$ over WAN with $0.4\%$ decrease in accuracy over an insecure (non-2PC) approach.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 03:10:03 +0000</pubDate>
</item>
<item>
<title>NovaTEE: Private Clearing and Settlement on Trusted Execution Hardware</title>
<link>https://eprint.iacr.org/2025/209</link>
<guid>https://eprint.iacr.org/2025/209</guid>
<content:encoded><![CDATA[
<div> 关键词: NovaTEE、私有多边结算网络、可信执行环境(TEEs)、阈值密码学、资本效率

总结:
NovaTEE是一种创新的私有多边结算网络，旨在解决传统金融市场和加密货币交易中的关键效率问题。它利用可信执行环境(TEEs)和阈值密码学技术，实现多方之间的安全、私密和高效结算。该系统采用分布式密钥生成模型和新颖的清算机制，通过多边净额结算优化资本效率，并保持强大的隐私保护和合规性能力。通过结合TEE提供的安全性与零知识证明、稀疏默克尔树等高级加密协议，NovaTEE解决方案能实现在保护敏感交易信息的同时，进行跨平台和跨链的有效结算，显著降低市场参与者的资本要求、优化交易成本，并为机构级清算基础设施提供支持，而无需牺牲安全性和隐私性。其体系结构确保无单一实体完全掌握交易详情，同时通过分布式备份网络保持可审计性，为此类系统的机构采纳提供了切实可行的解决方案。 <div>
NovaTEE is a novel private multilateral settlement network designed to address critical inefficiencies in both traditional financial markets and cryptocurrency trading. The current clearing landscape suffers from fragmented capital allocation, restrictive prime brokerage relationships, and prolonged settlement timeframes in traditional finance, while cryptocurrency markets face challenges with over-collateralization, siloed lending pools, and security risks from centralized exchanges.

We introduce a settlement system that leverages Trusted Execution Environments (TEEs) and threshold cryptography to enable secure, private, and efficient settlement of obligations between multiple parties. The system utilizes a distributed key generation model and novel clearing mechanisms to optimize capital efficiency through multilateral netting, while maintaining strong privacy guarantees and regulatory compliance capabilities. By combining TEE-based security with advanced cryptographic protocols, including zero-knowledge proofs and sparse Merkle trees for data verification, our solution enables efficient cross-venue and cross-chain settlement while protecting sensitive trading information. This approach significantly reduces capital requirements for market participants, optimizes transaction costs, and provides institutional-grade clearing infrastructure without compromising on security or privacy. The system's architecture ensures that no single party has complete access to transaction details while maintaining auditability through a distributed backup network, offering a practical solution for institutional adoption of on-chain settlement.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 21:29:13 +0000</pubDate>
</item>
<item>
<title>Addressing Scalability Issues of Blockchains with Hypergraph Payment Networks</title>
<link>https://eprint.iacr.org/2025/205</link>
<guid>https://eprint.iacr.org/2025/205</guid>
<content:encoded><![CDATA[
<div> 关键词: 支付通道、Layer-2解决方案、交易成功率、交易费用、超边<br /><br />总结:
为了解决传统区块链上链交易数量过多和交易吞吐量不足的问题，支付通道成为Layer-2解决方案中的理想候选。本文提出在支付通道中引入柔韧性并构建具有多端点的超边，以此扩展支付网络图。通过对比比特币闪电网络和其他先进方案，研究发现基于超边的实现不仅能提高交易成功率，而且能将网络成本降低超过50%，相比闪电网络具有显著优势。 <div>
Payment channels are auspicious candidates in layer-2 solutions to reduce the number of on-chain transactions on traditional blockchains and increase transaction throughput. To construct payment channels, peers lock funds on 2-of-2 multisig addresses and open channels between one another to transact via instant peer-to-peer transactions. Transactions between peers without a direct channel are made possible by routing the payment over a series of adjacent channels. In certain cases, this can lead to relatively low transaction success rates and high transaction fees. In this work, we introduce pliability to constructing payment channels and graft edges with more than two endpoints into the payment graph. We refer to these constructions as hyperedges. We present hyperedge-based topologies to form hypergraphs and compare them to Bitcoin's Lightning network and other state-of-the-art solutions. The results demonstrate that hyperedge-based implementations can both increase transaction success rate, in addition to decreasing the network cost by more than 50% compared to that of the Lightning Network.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 14:02:52 +0000</pubDate>
</item>
<item>
<title>Ciphertext-Simulatable HE from BFV with Randomized Evaluation</title>
<link>https://eprint.iacr.org/2025/203</link>
<guid>https://eprint.iacr.org/2025/203</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, 两方计算, Ciphertext Simulatability, BFV方案, Security Notion

总结:
本文提出了一个新的同态加密安全概念——密文模拟性，该概念针对同态加密在构建高效两方计算协议中的隐私保护需求进行了精确刻画。接着，文章从BFV方案出发，通过修改其评估算法，实现了一个具有密文模拟性的同态加密构造，并对其理论分析和实验结果进行了展示，证实了所提方法在参数大小和错误增长方面几乎无显著开销。此外，文中还探讨了如何将这种设计密文可模拟的BFV方案进一步扩展，以满足更强的安全属性，如净化等。<br /><br /> <div>
Homomorphic Encryption (HE) is a privacy-enhancing technology that enables computation over encrypted data without the need for decryption. A primary application of HE is in the construction of communication-efficient Two-Party Computation (2PC) protocols between a client and a server, serving as the key owner and the evaluator, respectively. In this context, it is reasonable to assume that the evaluation circuit involves some confidential information of the server; otherwise, the client could compute it on their own. However, the 2PC protocol built on an HE scheme is not necessarily secure, as the standard IND-CPA security of HE does not guarantee the privacy of the evaluation circuit. Several enhanced security notions for HE, such as circuit privacy and sanitization, have been proposed to address this issue, but they require significant overhead in terms of parameter size or complexity.

In this work, we introduce a novel security notion for HE, called ciphertext simulatability, which precisely captures the security requirements of HE in the construction of 2PC. Then, we provide a concrete construction of ciphertext-simulatable HE from the BFV scheme by modifying its evaluation algorithm. We provide theoretical analysis and demonstrate experimental results to ensure that our solution has insignificant overhead in terms of parameter size and error growth. As a matter of independent interest, we demonstrate how our approach of designing ciphertext-simulatable BFV can be further extended to satisfy stronger security notions such as sanitization.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 12:01:19 +0000</pubDate>
</item>
<item>
<title>AUCIL: An Inclusion List Design for Rational Parties</title>
<link>https://eprint.iacr.org/2025/194</link>
<guid>https://eprint.iacr.org/2025/194</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、审查抵抗、包含列表、多提议者、拍卖式包含列表<br /><br />总结: 本文首次对区块链领域的包含列表进行了正式研究，以增强其审查抵抗能力。文章提出了一种利用多个提议者提出交易并提升审查阻力的包含列表设计方案。该设计包含两个关键部分：一是基于效用最大化的输入列表创建机制，使理性提议者能够在优先考虑高价值交易的同时达到协同均衡状态；二是AUCIL（基于拍卖的包含列表）机制，用于整合提议者的输入列表，最终生成一个包含列表。 <div>
The decentralized nature of blockchains is touted to provide censorship resistance. However, in reality, the ability of proposers to completely control the contents of a block makes censorship relatively fragile. To combat this, a notion of inclusion lists has been proposed in the blockchain community. This paper presents the first formal study of inclusion lists. Our inclusion list design leverages multiple proposers to propose transactions and improve censorship resistance. The design has two key components. The first component is a utility-maximizing input list creation mechanism that allows rational proposers to achieve a correlated equilibrium while prioritizing high-value transactions. The second component, AUCIL (auction-based inclusion list), is a mechanism for aggregating the input lists from the proposers to output an inclusion list.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 12:09:58 +0000</pubDate>
</item>
<item>
<title>BulletCT: Towards More Scalable Ring Confidential Transactions With Transparent Setup</title>
<link>https://eprint.iacr.org/2025/188</link>
<guid>https://eprint.iacr.org/2025/188</guid>
<content:encoded><![CDATA[
<div> 关键词: RingCT签名、Any-out-of-N证明、DLOG设置、K-out-of-N证明、可链接性

总结:
文章首次对ZGSX23提出的基于离散对数设置的新型Any-out-of-N证明及其关联的RingCT方案进行了深入分析。研究发现，虽然Any-out-of-N证明提供了更强的匿名性，但存在交易大小增加、密码学复杂度提升和潜在安全风险等问题，加剧了可扩展性的瓶颈问题。针对这些问题，文章探索使用K-out-of-N证明来增强RingCT方案的可扩展性，并创新地提出了一种新的DLOG基础的RingCT签名方案，该方案结合了优化的“K-权重”K-out-of-N证明以及首个能有效实现由前者衍生出的RingCT签名可链接性的新标签证明，从而抵抗双花攻击。此外，文章还发现了ZGSX23签名中的可链接性缺陷并予以修复。通过对新旧方案进行基准测试，显示本文提出的方案在可扩展性上取得了显著提升，为RingCT技术的发展迈出了一步。 <div>
RingCT signatures are essential components of Ring Confidential Transaction (RingCT) schemes on blockchain platforms, enabling anonymous transaction spending and significantly impacting the scalability of these schemes. This paper makes two primary contributions:

We provide the first thorough analysis of a recently developed Any-out-of-N proof in the discrete logarithm (DLOG) setting and the associated RingCT scheme, introduced by ZGSX23 (S&amp;P '23). The proof conceals the number of the secrets to offer greater anonymity than K-out-of-N proofs and uses an efficient "K-Weight" technique for its construction. However, we identify for the first time several limitations of using Any-out-of-N proofs, such as increased transaction sizes, heightened cryptographic complexities and potential security risks. These limitations prevent them from effectively mitigating the longstanding scalability bottleneck.

We then continue to explore the potential of using K-out-of-N proofs to enhance scalability of RingCT schemes. Our primary innovation is a new DLOG-based RingCT signature that integrates a refined "K-Weight"-based K-out-of-N proof and an entirely new tag proof. The latter is the first to efficiently enable the linkability of RingCT signatures derived from the former, effectively resisting double-spending attacks.

Finally, we identify and patch a linkability flaw in ZGSX23's signature. We benchmark our scheme against this patched one to show that our scheme achieves a boost in scalability, marking a promising step forward.
]]></content:encoded>
<pubDate>Sat, 08 Feb 2025 22:06:24 +0000</pubDate>
</item>
<item>
<title>NodeChain: Cheap Data Integrity Without Consensus</title>
<link>https://eprint.iacr.org/2025/184</link>
<guid>https://eprint.iacr.org/2025/184</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化应用、约束设备、数据结构、安全性证明<br /><br />总结:
我们提出了一种新的基于区块链的数据结构，该结构放弃了复制要求，同时保持了区块链的追加唯一性特性，使其适合在存储受限的设备网络中维护数据完整性。由于我们的目标应用并不需要共识机制（例如，安全存储货船集装箱中的传感器数据），因此我们没有提供这一功能。我们通过多方面证实了这种方法的实际潜力：(i) 我们在通用组合(UC)环境中形式化地证明了协议的安全性；(ii) 提供了一个小规模的概念验证实现；(iii) 对大规模部署进行了性能模拟，显示与传统区块链相比，存储需求减少了超过1000倍；(iv) 并进行了一项鲁棒性模拟，预测了网络阻塞攻击对实际运行的影响。 <div>
Blockchains enable decentralised applications that withstand Byzantine failures and do not need a central authority. Unfortunately, their massive replication requirements preclude their use on constrained devices.

We propose a novel blockchain-based data structure which forgoes replication without affecting the append-only nature of blockchains, making it suitable for maintaining data integrity over networks of storage-constrained devices. Our solution does not provide consensus, which is not required by our motivating application, namely securely storing sensor data of containers in cargo ships.

We elucidate the practical promise of our technique by following a multi-faceted approach: We (i) formally prove the security of our protocol in the
Universal Composition (UC) setting, as well as (ii) provide a small-scale proof-of-concept implementation, (iii) a performance simulation for large-scale deployments which showcases a reduction in storage of more than $1000$x compared to traditional blockchains, and (iv) a resilience simulation that predicts the practical effects of network jamming attacks.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 18:46:07 +0000</pubDate>
</item>
<item>
<title>HyperLoop: Rationally secure efficient cross-chain bridge</title>
<link>https://eprint.iacr.org/2025/176</link>
<guid>https://eprint.iacr.org/2025/176</guid>
<content:encoded><![CDATA[
<div> 关键词: Cross-chain bridges, rational-malicious model, HyperLoop, whistle-blower nodes, sliding window mechanism

总结:
本文提出了一种名为HyperLoop的高效跨链多签名桥接器，该桥接器在更为现实的理性恶意模型下被证明在安全性和活跃性方面具有理论保障。针对理性节点可能因经济利益而偏离协议甚至合谋的问题，文章引入了吹哨人节点作为监控机制，它们持续检查桥接器的操作并在发现异常时向投诉解决网络报告。为实施惩罚并确保安全性，要求节点在参与成为桥接器前需要抵押一定金额，并通过滑动窗口机制设置资金转移量上限。此外，文中描述的滑动窗口机制确立了抵押额与滑动窗口限制之间的关系。最终，实现了一个在经济、计算和通信效率上均表现出色的桥接器原型，并成功部署在以太坊和Polygon两条测试链之间。实验结果显示，在一个由19个节点组成的桥接器网络中，每个桥接器节点平均只需3毫秒就能检测并签署源链请求，体现出极高的效率和低延迟特性。 <div>
Cross-chain bridges, realizing the transfer of information and assets between blockchains, form the core of blockchain interoperability solutions. Most existing bridge networks are modeled in an honest-malicious setting, where the bridge nodes are either honest or malicious. Rationality allows the nodes to deviate from the protocol arbitrarily for an economic incentive. In this work, we present HyperLoop, an efficient cross-chain multi-signature bridge and prove that it is safe and live game-theoretically, under the more realistic rational-malicious model.

As rational bridge nodes are allowed to deviate from the protocol and even collude, a monitor mechanism is necessitated, which we realize by introducing whistle-blower nodes. These whistle-blowers constantly check the operations of the bridge and raise complaints to a complaint resolution network in case of discrepancies. To enforce punishments, it is necessary for the nodes to stake an amount before participating as bridge nodes. Consequently, a cap on the volume of funds transferred over the bridge is established. We describe a sliding window mechanism and establish a relation between the stake and the sliding window limit necessary for the safety of the bridge.

Our design yields an economic, computation, and communication-efficient bridge. We realize and deploy our bridge prototype bridging Ethereum and Polygon chains over testnets. For a 19-node bridge network, each bridge node takes an average of only 3 msec to detect and sign a source chain request, showing the highly efficiency and low-latency of the bridge.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 20:06:00 +0000</pubDate>
</item>
<item>
<title>VITARIT: Paying for Threshold Services on Bitcoin and Friends</title>
<link>https://eprint.iacr.org/2025/174</link>
<guid>https://eprint.iacr.org/2025/174</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链服务、分布式阈值加密服务、UTXO模型、公平性、VITARIT

总结:

本文介绍了一种名为VITARIT的新颖支付解决方案，该方案针对比特币等基于UTXO模型的区块链系统中，分布式阈值加密服务（如t-out-of-n分布式阈值可验证随机函数VRF服务）的需求进行了定制。VITARIT协议保证了强大的可证明安全性并方便实际部署，允许客户端向分布式阈值VRF服务请求可验证随机函数值，并触发对最多t+1个服务器的支付。该设计依赖于简单的交易和签名验证脚本，可以直接应用于类似比特币的系统。同时，文章还引入了新的密码学和交易层面的工具与技术，包括一种用于标准构建的创新性的签名-VRF交换协议，以及防止恶意服务器重复获取支付的交易流程设计，对去中心化支付系统具有更广泛的影响。原型实现表明，在两方交互情况下，客户端耗时126.4毫秒，服务器耗时204毫秒，证实了系统的实用性和可部署性。 <div>
Blockchain service offerings have seen a rapid rise
in recent times. Many of these services realize a decentralized
architecture with a threshold adversary to avoid a single
point of failure and to mitigate key escrow issues. While
payments to such services are straightforward in systems
supporting smart contracts, achieving fairness poses challenges
in systems like Bitcoin, adhering to the UTXO model with
limited scripting capabilities. This is especially challenging
without smart contracts, as we wish to pay only the required
threshold of t + 1 out of the n servers offering the service
together, without any server claiming the payment twice.

In this paper, we introduce VITARIT 1, a novel payment
solution tailored for threshold cryptographic services in UTXO
systems like Bitcoin. Our approach guarantees robust provable
security while facilitating practical deployment. We focus on
the t-out-of-n distributed threshold verifiable random function
(VRF) service with certain properties, such as threshold BLS
signatures, a recently highlighted area of interest. Our protocol
enables clients to request verifiable random function (VRF)
values from the threshold service, triggering payments to up
to t + 1 servers of the distributed threshold VRF.

Our efficient design relies on simple transactions using
signature verification scripts, making it immediately applicable
in Bitcoin-like systems. We also introduce new tools and
techniques at both the cryptographic and transaction layers,
including a novel signature-VRF exchange protocol for standard
constructions, which may be of independent interest. Addition-
ally, our transaction flow design prevents malicious servers
from claiming payments twice, offering broader implications for
decentralized payment systems. Our prototype implementation
shows that in the two-party interaction, the client takes 126.4
msec, and the server takes 204 msec, demonstrating practicality
and deployability of the system
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 18:17:35 +0000</pubDate>
</item>
<item>
<title>VRaaS: Verifiable Randomness as a Service on Blockchains</title>
<link>https://eprint.iacr.org/2024/957</link>
<guid>https://eprint.iacr.org/2024/957</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3应用、随机性服务、区块链、可验证随机性、Verifiable Randomness as a Service (VRaaS)

<br /><br />总结:
本文针对Web3应用程序中对于公正、不可预测和公开可验证随机性的广泛需求，首次提出了区块链环境下的可验证随机性服务（VRaaS）的概念，并进行了深入的正式化分析。文章中，作者定义了一个理想功能$\mathcal{F}_{\text{VRaaS}}$以在通用可组合模型中形式化VRaaS，该定义涵盖了随机性服务的核心特性，如无偏性、不可预测性和公共可验证性，以及涉及智能合约等不同实体的相关细节。

在此框架下，作者研究了一种基于可验证随机函数（VRF）的通用随机性服务设计，其中随机性请求者提供输入以生成作为VRF输出的随机数。证明了这种设计方案满足他们所提出的VRaaS形式化定义，并指出该通用协议能够涵盖现实世界中的许多随机性服务实例，如Chainlink VRF和Supra dVRF。

此外，作者还探讨了该框架的极简主义性质。首先，他们展示了框架内置的两个交易对于支持随机性服务的基本品质实际上是必要的。同时，他们发现其他一些设计，如Algorand信标、Pyth VRF和Band VRF，在其框架内存在实际漏洞。 <div>
Web3 applications, such as on-chain games, NFT minting, and leader elections necessitate access to unbiased, unpredictable, and publicly verifiable randomness. Despite its broad use cases and huge demand, there is a notable absence of comprehensive treatments of on-chain verifiable randomness services. To bridge this, we offer an extensive formal analysis of on-chain verifiable randomness services. 

     We present the $first$ formalization of on-chain verifiable randomness in the blockchain setting by introducing the notion of Verifiable Randomness as a Service (VRaaS). We formally define VRaaS using an ideal functionality $\mathcal{F}_{\text{VRaaS}}$ in the Universal Composability model. Our definition not only captures the core features of randomness services, such as unbiasability, unpredictability, and public verifiability, but also accounts for many other crucial nuances pertaining to different entities involved, such as smart contracts. 

     Within our framework we study a generic design of Verifiable Random Function (VRF)-based randomness service - where the randomness requester provides an input on which the randomness is evaluated as VRF output. We show that it does satisfy our formal VRaaS definition. Furthermore, we show that the generic protocol captures many real-world randomness services like Chainlink VRF and Supra dVRF. 
    
     Moreover, we investigate the minimalism of the framework. Towards that, first we show that, the two transactions in-built in our framework are actually $necessary$ for any randomness service to support the essential qualities. We also discover $practical$ $vulnerabilities$ in other designs such as Algorand beacon, Pyth VRF and Band VRF, captured within our framework.
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 05:45:37 +0000</pubDate>
</item>
<item>
<title>Wiretapping LLMs: Network Side-Channel Attacks on Interactive LLM Services</title>
<link>https://eprint.iacr.org/2025/167</link>
<guid>https://eprint.iacr.org/2025/167</guid>
<content:encoded><![CDATA[
<div> 关键词：服务器端优化、投机解码、侧信道漏洞、大型语言模型（LLM）、安全性框架、攻击方法、加密用户提示、网络包时间、大小差异、隐私敏感应用、准确性、性能安全权衡

总结:<br />
本文揭示了服务器端的优化，如投机解码，虽然提高了大型语言模型（LLM）服务的交互性和资源效率，但却意外引入了新的通过网络包时间和大小变化的输入依赖性侧信道漏洞。研究者提出了一种新颖的攻击方法，利用该安全框架证明了现实世界中采用流式API的LLM服务存在不安全性。攻击者能准确预测加密的用户提示和响应中的敏感信息，例如在医学和金融领域的隐私敏感LLM应用中，对开源vLLM服务的预测精度达到71%至92%，对商业ChatGPT服务的预测精度为50%至90%。最后，文章指出，隐藏这些侧信道的不同解决方案会在安全性和性能之间产生权衡，具体表现为交互性和网络带宽开销的增加。 <div>
Recent server-side optimizations like speculative decoding significantly enhance the interactivity and resource efficiency of Large Language Model (LLM) services. However, we show that these optimizations inadvertently introduce new side-channel vulnerabilities through network packet timing and size variations that tend to be input-dependent. Network adversaries can leverage these side channels to learn sensitive information contained in \emph{encrypted} user prompts to and responses from public LLM services.  

This paper formalizes the security implications using a novel indistinguishability framework and introduces a novel attack that establishes the insecurity of real-world LLM services with streaming APIs under our security framework.

Our proposed attack effectively deconstructs encrypted network packet traces to reveal the sizes of underlying LLM-generated tokens and whether the tokens were generated with or without certain server-side optimizations. Our attack can accurately predict private attributes in real-world privacy-sensitive LLM applications in medicine and finance with $71$--$92\%$ accuracy on an open-source vLLM service and $50$--$90\%$ accuracy on the commercial ChatGPT service. Finally, we show that solutions that hide these side channels to different degrees expose a tradeoff between security and performance --- specifically, interactivity and network bandwidth overheads.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 15:27:58 +0000</pubDate>
</item>
<item>
<title>Learning from Functionality Outputs: Private Join and Compute in the Real World</title>
<link>https://eprint.iacr.org/2025/162</link>
<guid>https://eprint.iacr.org/2025/162</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Join and Compute (PJC), 两方协议, 隐私风险, 攻击, 安全模型

总结:
Private Join and Compute (PJC)是由Google提出的一种两方协议，用于包括广告转化在内的多种场景，并扩展了其部署的私人集合交集求和(PSI-SUM)协议。然而，PJC的功能输出通常并未在MPC文献的安全模型中考虑，但可能存在实际的隐私风险，对PJC等协议的潜在部署产生了关注。本文分析了与PJC功能输出相关的风险，假设一方参与者作为攻击者，描述了四种能够破坏另一方输入隐私、恢复交集中键值对成员资格及其关联值的实战攻击。这些攻击揭示了部署过程中与隐私威胁相关的问题，并强调应将功能输出纳入MPC安全模型的一部分。 <div>
Private Join and Compute (PJC) is a two-party protocol recently proposed by Google for various use-cases, including ad conversion (Asiacrypt 2021) and which generalizes their deployed private set intersection sum (PSI-SUM) protocol (EuroS&amp;P 2020).

PJC allows two parties, each holding a key-value database, to privately evaluate the inner product of the values whose keys lie in the intersection. While the functionality output is not typically considered in the security model of the MPC literature, it may pose real-world privacy risks, thus raising concerns about the potential deployment of protocols like PJC. 

In this work, we analyze the risks associated with the PJC functionality output. We consider an adversary that is a participating party of PJC and describe four practical attacks that break the other party's input privacy, and which are able to recover both membership of keys in the intersection and their associated values.  Our attacks consider the privacy threats associated with deployment and highlight the need to include the functionality output as part of the MPC security model.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 16:02:28 +0000</pubDate>
</item>
<item>
<title>HELP: Everlasting Privacy through Server-Aided Randomness</title>
<link>https://eprint.iacr.org/2025/140</link>
<guid>https://eprint.iacr.org/2025/140</guid>
<content:encoded><![CDATA[
<div> 关键词: 永恒隐私、Store-Now-Decrypt-Later问题、Hypervisor EverLasting Privacy (HELP)、Dodis和Yeo、Universal Composability框架

总结:
本文关注永恒隐私（Everlasting Privacy）及其在解决Store-Now-Decrypt-Later（SNDL）问题中的应用。作者重新审视了Dodis和Yeo提出的Hypervisor EverLasting Privacy (HELP)模型，并提出了一种新型架构，该架构通过半可信服务器网络生成共享随机数，降低了存储和分布大型共享密钥的需求。尽管Dodis和Yeo的方法在理论上有效，但在实践中效率较低。为此，文章对HELP架构进行了抽象和泛化，并构建了几种具体高效的实现方案，这些方案基于诸如哈希和消息认证等基本加密操作。此外，文章证明了一个强大的组合定理，表明其永恒隐私架构可以使用在Universal Composability (UC)框架下计算上安全的消息传输方法，这是关于永恒隐私的第一个积极组合结果，之前已知永恒隐私存在许多“非组合”结果。 <div>
Everlasting (EL) privacy offers an attractive solution to the Store-Now-Decrypt-Later (SNDL) problem, where future increases in the attacker's capability could break systems which are believed to be secure today. Instead of requiring full information-theoretic security, everlasting privacy allows computationally-secure transmissions of ephemeral secrets, which are only "effective" for a limited periods of time, after which their compromise is provably useless for the SNDL attacker.

In this work we revisit such everlasting privacy model of Dodis and Yeo (ITC'21), which we call Hypervisor EverLasting Privacy (HELP). HELP is a novel architecture for generating shared randomness using a network of semi-trusted servers (or "hypervisors"), trading the need to store/distribute large shared secrets with the assumptions that it is hard to: (a) simultaneously compromise too many publicly accessible ad-hoc servers; and (b) break a computationally-secure encryption scheme very quickly. While Dodis and Yeo presented good HELP solutions in the asymptotic sense, their solutions were concretely expensive and used heavy tools (like large finite fields or gigantic Toeplitz matrices). 

We abstract and generalize the HELP architecture to allow for more efficient instantiations, and construct several concretely efficient HELP solutions. Our solutions use elementary cryptographic operations, such as hashing and message authentication. We also prove a very strong composition theorem showing that our EL architecture can use any message transmission method which is computationally-secure in the Universal Composability (UC) framework. This is the first positive composition result for everlasting privacy, which was otherwise known to suffer from many "non-composition" results (Müller-Quade and Unruh; J of Cryptology'10).
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 01:59:45 +0000</pubDate>
</item>
<item>
<title>Efficient Oblivious Sorting and Shuffling for Hardware Enclaves</title>
<link>https://eprint.iacr.org/2023/1258</link>
<guid>https://eprint.iacr.org/2023/1258</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious算法、隐私保护、flexway o-sort、硬件安全隔离、性能提升

总结:
这篇论文提出了一种新的 Oblivious 排序算法——flexway o-sort，该算法具有渐进最优性、实际效率高以及适合在如Intel SGX等硬件安全隔离环境中实现的特点。对于输入数据量为12GB的中等到大规模场景，当数据完全适应硬件隔离区时，flexway o-sort 相比已知的 Oblivious 排序算法能带来1.32至28.8倍的性能提升；而在数据超出硬件隔离区的情况，这一优势可达到4.1至208倍。此外，论文还实现了基于 Oblivious 排序的应用，包括直方图计算、数据库连接和ORAM数据结构初始化。这些应用在处理8GB至32GB的数据集时，相比于传统的位onic排序，在数据适应硬件隔离区的情况下速度提升了1.44至2.3倍，而当数据不适应硬件隔离区时，则提高了4.9至5.5倍的速度。 <div>
Oblivious algorithms are being deployed at large scale in real world to enable privacy-preserving applications such as Signal's private contact discovery. Oblivious sorting is a fundamental building block in the design of oblivious algorithms for numerous computation tasks. Unfortunately, there is still a theory-practice gap for oblivious sort. The commonly implemented bitonic sorting algorithm is not asymptotically optimal, whereas known asymptotically optimal algorithms suffer from large constants.
In this paper, we construct a new oblivious sorting algorithm called flexway o-sort, which is asymptotically optimal, concretely efficient, and suitable for implementation in hardware enclaves such as Intel SGX. For moderately large inputs of $12$ GB, our flexway o-sort algorithm outperforms known oblivious sorting algorithms by $1.32\times$ to $28.8\times$ when the data fits within the hardware enclave, and by $4.1\times$ to $208\times$ when the data does not fit within the hardware enclave. We also implemented various applications of oblivious sorting, including histogram, database join, and initialization of an ORAM data structure. For these applications and data sets from 8GB to 32GB, we achieve $1.44 \sim 2.3\times$ speedup over bitonic sort when the data fits within the enclave, and $4.9 \sim 5.5\times$ speedup when the data does not fit within the enclave.
]]></content:encoded>
<pubDate>Sun, 20 Aug 2023 22:45:36 +0000</pubDate>
</item>
<item>
<title>Path Privacy and Handovers: Preventing Insider Traceability Attacks During Secure Handovers</title>
<link>https://eprint.iacr.org/2025/139</link>
<guid>https://eprint.iacr.org/2025/139</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G, 物联网(IoT), 安全手over, 路径隐私, 密码学形式化

总结:
随着5G和物联网技术的发展，安全通信从集中式同质化转变为异构移动设备在网络间不断切换的新格局。本文首次提出了安全手over的密码学正式化方案，强调了设备在不同网络间安全连接转移的重要性。文章中，我们引入了一个新的安全性属性——路径隐私，这是针对手over过程的一种此前未被探索的特性。此外，我们还制定了安全手over的语法，并确定了适用于安全手over方案的安全属性。最后，我们提出了一种通用的手over方案，该方案综合了我们的新颖路径隐私概念与其他现有手over方案所具有的安全属性，从而证明了我们框架的稳健性和灵活性。 <div>
The rise of 5G and IoT has shifted secure communication from centralized and homogeneous to a landscape of heterogeneous mobile devices constantly travelling between myriad networks. In such environments, it is desirable for devices to securely extend their connection from one network to another, often referred to as a handover. In this work we introduce the first cryptographic formalisation of secure handover schemes. We leverage our formalisation to propose path privacy, a novel security property for handovers that has hitherto remained unexplored. We further develop a syntax for secure handovers, and identify security properties appropriate for secure handover schemes. Finally, we introduce a generic handover scheme that captures all the strong notions of security we have identified, combining our novel path privacy concept with other security properties characteristic to existing handover schemes, demonstrating the robustness and versatility of our framework.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 22:45:51 +0000</pubDate>
</item>
<item>
<title>Naysayer proofs</title>
<link>https://eprint.iacr.org/2023/1472</link>
<guid>https://eprint.iacr.org/2023/1472</guid>
<content:encoded><![CDATA[
<div> 关键词：naysayer证明、零知识证明、NP语言、常量大小、常量时间

总结:
本文提出了“naysayer证明”的概念，指出在许多（零知识）证明系统中，验证者通过naysayer确认一个错误的证明无效比检查一个真实的证明有效要高效得多。文章展示了每一个NP语言都可以拥有常量大小和常量时间的naysayer证明。此外，文中还给出了针对FRI多项式承诺、后量子安全数字签名以及可验证洗牌等几个示例证明系统的实际构造。naysayer证明为资源受限的验证器，如智能合约，提供了一种新的乐观验证模式的可能性。 <div>
This work introduces the notion of naysayer proofs. We observe that in numerous (zero-knowledge) proof systems, it is significantly more efficient for the verifier to be convinced by a so-called naysayer that a false proof is invalid than it is to check that a genuine proof is valid. We show that every NP language has constant-size and constant-time naysayer proofs. We also show practical constructions for several example proof systems, including FRI polynomial commitments, post-quantum secure digital signatures, and verifiable shuffles. Naysayer proofs enable an interesting new optimistic verification mode potentially suitable for resource-constrained verifiers, such as smart contracts.
]]></content:encoded>
<pubDate>Mon, 25 Sep 2023 14:24:01 +0000</pubDate>
</item>
<item>
<title>Intmax2: A ZK-rollup with Minimal Onchain Data and Computation Costs Featuring Decentralized Aggregators</title>
<link>https://eprint.iacr.org/2023/1082</link>
<guid>https://eprint.iacr.org/2023/1082</guid>
<content:encoded><![CDATA[
<div> 关键词: Intmax2、区块链扩容、零知识汇总(ZK-rollup)、客户端、安全性证明<br /><br />总结:
Intmax2是一个名为Intmax2的区块链扩容解决方案，它是一种基于零知识汇总（ZK-rollup）协议的方案，具有无状态和无需许可的区块生成特点。该方案独特之处在于将大部分数据处理和计算成本转移至客户端，而非对区块生产者或底层Layer 1区块链施加繁重要求。区块生产者的任务仅限于定期生成交易集合的承诺，向每个发送者分发包含证明，并收集及聚合发送者的签名。这种设计实现了无权限和无状态的区块生成，并随用户数量增加而高度可扩展。此外，该协议的主要安全属性已由Nethermind形式验证团队使用Lean定理证明器进行了正式验证。 <div>
We present a blockchain scaling solution called Intmax2, which is a Zero-Knowledge rollup (ZK-rollup) protocol with stateless and permissionless block production, while minimizing the usage of data and computation on the underlying blockchain. Our architecture distinctly diverges from existing ZK-rollups since essentially all of the data and computational costs are shifted to the client-side as opposed to imposing heavy requirements on the block producers or the underlying Layer 1 blockchain. The only job for block producers is to periodically generate a commitment to a set of transactions, distribute inclusion proofs to each sender, and collect and aggregate signatures by the senders. This design allows permissionless and stateless block production, and is highly scalable with the number of users. We give a proof of the main security property of the protocol, which has been formally verified by the Nethermind Formal Verification Team in the Lean theorem prover.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 15:34:58 +0000</pubDate>
</item>
<item>
<title>Distributional Private Information Retrieval</title>
<link>https://eprint.iacr.org/2025/132</link>
<guid>https://eprint.iacr.org/2025/132</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Information Retrieval（私有信息检索），Distributional Private Information Retrieval（分布式私有信息检索），经典PIR，流行度分布，CrowdSurf

总结:

我们提出了分布式私有信息检索（Distributional PIR）这一新型PIR方案，它在处理数据库记录流行度严重偏斜的情况下，能够比经典PIR实现更快的运行速度，同时保持与经典PIR相同的加密隐私保护。分布式PIR的成功概率保证针对的是分布内的查询，而对分布外的查询成功率较低。文章构建了一个利用经典PIR协议作为黑盒的分布式PIR方案，并证明了对于一大类分布式PIR方案的服务器运行时间下限。在两个实际流行度分布的数据集上，相比于现有技术，我们的分布式PIR构造方法将计算成本降低了5至77倍。最后，我们构建了一个名为CrowdSurf的端到端系统，用于私人获取推文，并显示分布式PIR将端到端服务器成本减少了8倍。 <div>
A private-information-retrieval (PIR) scheme lets a client fetch a record from a remote database without revealing which record it fetched. Classic PIR schemes treat all database records the same but, in practice, some database records are much more popular (i.e., commonly fetched) than others. We introduce distributional private information retrieval, a new type of PIR that can run faster than classic PIR–both asymptotically and concretely–when the popularity distribution is heavily skewed. Distributional PIR provides exactly the same cryptographic privacy as classic PIR. The speedup comes from a relaxed form of correctness: distributional PIR guarantees that in-distribution queries succeed with good probability, while out-of-distribution queries succeed with lower probability.

We construct a distributional-PIR scheme that makes black-box use of classic PIR protocols, and prove a lower bound on the server-runtime of a large class of distributional-PIR schemes. On two real-world popularity distributions, our distributional-PIR construction reduces compute costs by $5$-$77\times$ compared to existing techniques. Finally, we build CrowdSurf, an end-to-end system for privately fetching tweets, and show that distributional-PIR reduces the end-to-end server cost by $8\times$.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 03:04:53 +0000</pubDate>
</item>
<item>
<title>Always by Your Side: Constructing Traceable Anonymous Credentials with Hardware-Binding</title>
<link>https://eprint.iacr.org/2025/126</link>
<guid>https://eprint.iacr.org/2025/126</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Identity, Anonymous Credential, Traceability, Public Key Encryption, Equality Test

总结:
本文关注去中心化身份（DID）和匿名凭证（AC）技术及其可追溯性的发展，指出现有方案中引入受信任的监管方可能存在用户隐私风险。为解决这一问题，文章提出了一种基于公共密钥加密与等式测试的监管文本方法，用于每个认证记录，确保方案具备可验证性、不可陷害性和轮次隔离安全性。该方案的优势在于其等式测试能力并不依赖于公钥，而是取决于认证的轮次标识符。文章进一步实现了一个基于智能卡和BBS+签名的可追踪、硬件绑定的AC方案，并进行了性能分析。相较于其他可追踪AC方案，作者展示了其在追溯任务以及安全地外包方面的优势。 <div>
With the development of decentralized identity (DID), anonymous credential (AC) technology, as well as its traceability, is receiving more and more attention. Most works introduce a trusted party (regulator) that holds a decryption key or backdoor to directly deanonymize the user identity of anonymous authentication. While some cryptographic primitives can help regulators handle complex tracing tasks among large amounts of user profiles (stored by the issuer) and authentication records (stored by the service provider), additional security primitives are still needed to ensure the privacy of other users. Besides, hardware-binding anonymous credential (hbAC) systems have been proposed to prevent credential sharing or address platform resource constraints, the traceability of hbAC has yet to be discussed.

In this paper, we introduce a public key encryption with equality test as a regulatory text for each authentication record to address the above-mentioned challenges. The security of this feature is guaranteed by the verifiability, non-frameability, and round isolation of the proposed scheme. We compared the asymptotic complexity of our scheme with other traceable AC schemes and shows our scheme has advantages in tracing tasks as well as securely outsourcing them. The key feature of our scheme is that the ability of equality test of regulatory texts is independent of the public key, but rather depends on the round identifier of the authentication. We instantiate a traceable, hardware-binding AC scheme based on smart cards and BBS+ signature and give the performance analysis of it.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 04:35:31 +0000</pubDate>
</item>
<item>
<title>Summation-based Private Segmented Membership Test from Threshold-Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/753</link>
<guid>https://eprint.iacr.org/2024/753</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Segmented Membership Test (PSMT)，Private Set Intersection (PSI)，Multi-Party PSI (MPSI)，Private Membership Test (PMT)，Oblivious RAM (ORAM)

总结:
该文章引入了一种名为Private Segmented Membership Test (PSMT)的新颖原始数据隐私保护技术。针对存在大量数据持有者的情况下，客户端希望检查其持有的数据元素是否存在于加密状态下的多个集合中的场景，现有的PSI、MPSI、PMT和ORAM方案在隐私保护或效率上存在问题。文章提出一种基于阈值近似算术同态加密的基本协议来构建PSMT，并成功避免了泄露持有交集元素的数据持有者信息以及产生大量误报的情况，同时确保了IND-CPA^D安全级别。相较于现有最佳方法，新方案在支持大量数据持有者方面具有更好的可扩展性，通过使用基于求和的同态成员资格检查而非基于乘积的方法，以及解决各种技术挑战的新颖思路，实现在实验中能有效处理多达4096个数据持有者的情况（相比于此前大约100个）。实验结果显示，对于1024个数据持有者和大小为2^25的集合，结果聚合可以在92.5秒内完成，并且随着发送者数量增加，其开销增长缓慢。此外，文中还将PSMT协议与其他领先的PSI和MPSI协议进行了对比，并讨论了其在隐私模型改进和更大规模参与方方面的优越性。 <div>
In many real-world scenarios, there are cases where a client wishes to check if a data element they hold is included in a set segmented across a large number of data holders. To protect user privacy, the client's query and the data holders' sets should remain encrypted throughout the whole process. Prior work on Private Set Intersection (PSI), Multi-Party PSI (MPSI), Private Membership Test (PMT), and Oblivious RAM (ORAM) falls short in this scenario in many ways. They either require data holders to possess the sets in plaintext, incur prohibitively high latency for aggregating results from a large number of data holders, leak the information about the party holding the intersection element, or induce a high false positive. 

This paper introduces the primitive of a Private Segmented Membership Test (PSMT). We give a basic construction of a protocol to solve PSMT using a threshold variant of approximate-arithmetic homomorphic encryption and show how to overcome existing challenges to construct a PSMT protocol without leaking information about the party holding the intersection element or false positives for a large number of data holders ensuring IND-CPA^D security. Our novel approach is superior to existing state-of-the-art approaches in scalability with regard to the number of supported data holders. This is enabled by a novel summation-based homomorphic membership check rather than a product-based one, as well as various novel ideas addressing technical challenges. Our PSMT protocol supports many more parties (up to 4096 in experiments) compared to prior related work that supports only around 100 parties efficiently. Our experimental evaluation shows that our method's aggregation of results from data holders can run in 92.5s for 1024 data holders and a set size of 2^25, and our method's overhead increases very slowly with the increasing number of senders. We also compare our PSMT protocol to other state-of-the-art PSI and MPSI protocols and discuss our improvements in usability with a better privacy model and a larger number of parties.
]]></content:encoded>
<pubDate>Thu, 16 May 2024 18:35:58 +0000</pubDate>
</item>
<item>
<title>A Privacy Model for Classical &amp; Learned Bloom Filters</title>
<link>https://eprint.iacr.org/2025/125</link>
<guid>https://eprint.iacr.org/2025/125</guid>
<content:encoded><![CDATA[
<div> 关键词: Classical Bloom Filter, Learned Bloom Filter, Probabilistic Data Structure, Differential Privacy, Privacy Attacks/Defenses

总结:
本文探讨了Bloom Filter在处理敏感输入数据并确保隐私安全方面的应用。提出了一个更强的基于差分隐私的Bloom Filter模型。文章中，设计并构建了满足$(\epsilon, 0)$-差分隐私的Classical Bloom Filter和Learned Bloom Filter。这是首次在严格模型下对Learned Bloom Filter的隐私问题进行分析和解决，从而填补了该领域的研究空白。<br /><br /> <div>
The Classical Bloom Filter (CBF) is a class of Probabilistic Data Structures (PDS) for handling Approximate Query Membership (AMQ). The Learned Bloom Filter (LBF) is a recently proposed class of PDS that combines the Classical Bloom Filter with a Learning Model while preserving the Bloom Filter's one-sided error guarantees. Bloom Filters have been used in settings where inputs are sensitive and need to be private in the presence of an adversary with access to the Bloom Filter through an API or in the presence of an adversary who has access to the internal state of the Bloom Filter. Prior work has investigated the privacy of the Classical Bloom Filter providing attacks and defenses under various privacy definitions. In this work, we formulate a stronger differential privacy-based model for the Bloom Filter. We propose constructions of the Classical and Learned Bloom Filter that satisfy $(\epsilon, 0)$-differential privacy. This is also the first work that analyses and addresses the privacy of the Learned Bloom Filter under any rigorous model, which is an open problem.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:12:40 +0000</pubDate>
</item>
<item>
<title>Efficient 2PC for Constant Round Secure Equality Testing and Comparison</title>
<link>https://eprint.iacr.org/2024/949</link>
<guid>https://eprint.iacr.org/2024/949</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全等值测试、安全比较、两方计算、在线/离线范式、通信成本

总结:
本文提出了新的常数轮两方计算（2PC）协议，用于安全等值测试和比较。这些协议基于在线/离线范式设计，针对32位输入，其等值测试协议的在线通信成本低至76比特（ABY的1%），而安全比较协议的成本为384比特（ABY的5%）。实验结果显示：(1) 对于32位等值测试，相较于Guo等人（EUROCRYPT 2023）的方案，我们的方案速度快了9倍，比采用半门优化的加密封装电路（CRYPTO 2015）快了15倍；(2) 在32位的安全比较中，我们的方案比Guo等人（EUROCRYPT 2023）快3倍，同时比Rathee等人（CCS 2020）以及采用半门优化的加密封装电路快6倍。 <div>
Secure equality testing and comparison are two important primitives widely used in many secure computation scenarios, such as  privacy-preserving machine learning,  private set intersection, and secure data mining, etc. This work proposes new constant-round two-party computation (2PC) protocols for secure equality testing and comparison. 
Our protocols are designed in the online/offline paradigm. 
For 32-bit inputs, the online communication cost of our equality testing protocol and secure comparison protocol are as low as 76 bits (1\% of ABY) and 384 bits (5\% of ABY) , respectively.  
Our benchmarks show that (i) for 32-bit equality testing, our scheme performs $9 \times$ faster than the Guo \emph{et al.} (EUROCRYPT 2023) and $15 \times$ of the garbled circuit (GC) with the half-gate optimization (CRYPTO 2015). (ii) for 32-bit secure comparison, our scheme performs  $3 \times$ faster than Guo \emph{et al.} (EUROCRYPT 2023), $6 \times$ faster than both Rathee \emph{et al.} (CCS 2020) and GC with the half-gate optimization.
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 06:22:37 +0000</pubDate>
</item>
<item>
<title>One-shot Signatures and Applications to Hybrid Quantum/Classical Authentication</title>
<link>https://eprint.iacr.org/2020/107</link>
<guid>https://eprint.iacr.org/2020/107</guid>
<content:encoded><![CDATA[
<div> 关键词：one-shot signatures、量子无克隆定理、经典oracle、indistinguishability obfuscation、混合量子/古典密码学任务

<br /><br />总结:
本文提出了“一次签名”(one-shot signatures)的概念，这是一种利用量子无克隆定理实现的签名方案，其特点是私钥只能用于签署一条消息后即自我销毁。文章表明，在经典预言机的帮助下可以构造这样的签名方案，并通过已知的不可区分混淆方案进行启发式模糊化处理。此外，文章展示了这种一次性签名在混合量子/古典密码学任务中的广泛应用，包括一次性签名令牌、基于经典通信的量子货币、无需区块链的去中心化加密货币、具有不可复制私钥的签名方案、非交互式的可证明最小熵等。因此，作者将一次签名定位为新型量子密码协议的重要构建模块。 <div>
We define the notion of one-shot signatures, which are signatures where any secret key can be used to sign only a single message, and then self-destructs. While such signatures are of course impossible classically, we construct one-shot signatures using quantum no-cloning. In particular, we show that such signatures exist relative to a classical oracle, which we can then heuristically obfuscate using known indistinguishability obfuscation schemes.

We show that one-shot signatures have numerous applications for hybrid quantum/classical cryptographic tasks, where all communication is required to be classical, but local quantum operations are allowed. Applications include one-time signature tokens, quantum money with classical communication, decentralized blockchain-less cryptocurrency, signature schemes with unclonable secret keys, non-interactive certifiable min-entropy, and more. We thus position one-shot signatures as a powerful new building block for novel quantum cryptographic protocols.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2020 16:18:02 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Stealth Address Protocols</title>
<link>https://eprint.iacr.org/2025/112</link>
<guid>https://eprint.iacr.org/2025/112</guid>
<content:encoded><![CDATA[
<div> 关键词：Stealth Address Protocol (SAP)，Dual-Key SAP (DKSAP)，Elliptic Curve Pairing Dual-Key SAP (ECPDKSAP)，量子攻击，Lattice-based cryptography，Learning With Errors (LWE)，Ring-LWE SAP，Module-LWE SAP

总结:
本文介绍了三种基于 lattice-based 密码学的新式 Stealth Address Protocol (SAP)：LWE SAP、Ring-LWE SAP 和 Module-LWE SAP。这些协议利用 Learning With Errors (LWE) 问题确保了对量子攻击的抵抗性。其中，基于 Kyber 密钥封装机制的 Module-LWE SAP 表现出最佳性能，在ephemeral 公开密钥登记簿的扫描时间上相比 ECPDKSAP 提高了约 66.8% 的效率。这三种新型 SAP 为解决依赖于椭圆曲线密码学并可能受量子计算机威胁的现有 SAP（如 DKSAP 和 ECPDKSAP）提供了替代方案。 <div>
The Stealth Address Protocol (SAP) allows users to receive assets through stealth addresses that are unlinkable to their stealth meta-addresses. The most widely used SAP, Dual-Key SAP (DKSAP), and the most performant SAP, Elliptic Curve Pairing Dual-Key SAP (ECPDKSAP), are based on elliptic curve cryptography, which is vulnerable to quantum attacks. These protocols depend on the elliptic curve discrete logarithm problem, which could be efficiently solved on a sufficiently powerful quantum computer using the Shor algorithm. In this paper three novel post-quantum SAPs based on lattice-based cryptography are presented: LWE SAP, Ring-LWE SAP and Module-LWE SAP. These protocols leverage Learning With Errors (LWE) problem to ensure quantum-resistant privacy. Among them, Module-LWE SAP, which is based on the Kyber key encapsulation mechanism, achieves the best performance and outperforms ECPDKSAP by approximately 66.8% in the scan time of the ephemeral public key registry.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 15:01:35 +0000</pubDate>
</item>
<item>
<title>A Formal Treatment of Homomorphic Encryption Based Outsourced Computation in the Universal Composability Framework</title>
<link>https://eprint.iacr.org/2025/109</link>
<guid>https://eprint.iacr.org/2025/109</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, Secure Function Evaluation, Outsourced Computation, Non-Interactive, Sender Privacy

总结:
这篇文章讨论了同态加密和安全函数评估技术在实际应用中的局限性。作者在尝试将一个简单的 PSI 协议应用于基于用户资料匹配的网络服务时，发现现有的外包框架存在不足，要么要求客户端执行超出贡献输入的任务，要么依赖于服务器与客户端之间的非共谋假设，这在网络服务场景中显得不切实际。为此，他们提出了首个基于黑盒同态加密的非交互式外包计算通用构造，该方法依赖于两个专用服务器间的非共谋假设，更符合网络服务环境的现实情况。此外，他们在通用可组合性（UC）框架下为这一构造提供了安全性证明，假定对手为半诚实（即被动）的。不同于一般的单向两方 SFE 协议，该构造还特别强调发送方隐私，要求发送方仅以加密形式提供其输入，从而实现更强的隐私保护并拓宽协议的应用范围。这个新构造适用于所有单向两方发送方私密的安全函数评估协议以及基于服务器的加密输入算术运算。最后，文章通过将其应用于实际场景下的外包私人集合交集（OPSI）来展示了该通用外包计算框架的实际适用性，并对其效率进行了详细的评估。 <div>
The adoption of Homomorphic Encryption (HE) and Secure
Function Evaluation (SFE) applications in the real world remains lim-
ited, even nearly 50 years after the introduction of HE. This is particu-
larly unfortunate given the strong privacy and confidentiality guarantees
these tools can offer to modern digital life.
While attempting to incorporate a simple straw-man PSI protocol into
a web service for matching individuals based on their profiles, we en-
countered several shortcomings in current outsourcing frameworks. Ex-
isting outsourced protocols either require clients to perform tasks beyond
merely contributing their inputs or rely on a non-collusion assumption
between a server and a client, which appears implausible in standard web
service scenarios.
To address these issues, we present, to the best of our knowledge, the first
general construction for non-interactive outsourced computation based
on black-box homomorphic encryption. This approach relies on a non-
collusion assumption between two dedicated servers, which we consider
more realistic in a web-service setting. Furthermore, we provide a proof
of our construction within the Universal Composability (UC) framework,
assuming semi-honest (i.e., passive) adversaries.
Unlike general one-sided two-party SFE protocols, our construction addi-
tionally requires sender privacy. Specifically, the sender must contribute
its inputs solely in encrypted form. This ensures stronger privacy guar-
antees and broadens the applicability of the protocol.
Overall, the range of applications for our construction includes all one-
sided two-party sender-private SFE protocols as well as server-based
arithmetic computations on encrypted inputs. Finally, we demonstrate
the practical applicability of our general outsourced computation frame-
work by applying it to the specific use case of Outsourced Private Set
Intersection (OPSI) in a real-world scenario, accompanied by a detailed
evaluation of its efficiency.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 13:01:38 +0000</pubDate>
</item>
<item>
<title>Additive Randomized Encodings from Public Key Encryption</title>
<link>https://eprint.iacr.org/2025/104</link>
<guid>https://eprint.iacr.org/2025/104</guid>
<content:encoded><![CDATA[
<div> 关键词: Additive Randomized Encodings (ARE), k-party function, non-interactive secure function evaluation, shuffle model, public-key encryption

<br /><br />总结:
本文介绍了由Halevi、Ishai、Kushilevitz和Rabin在CRYPTO 2023上提出的加性随机编码（ARE），这种技术将$k$方函数$f(x_1,\dots,x_k)$的计算简化为对每个输入$x_i$进行局部编码$\hat x_i$，然后在一个阿贝尔群中将其相加得到输出编码$\hat y = \sum \hat x_i$，而不会泄露除结果以外的任何信息。ARE的吸引力在于其非局部计算仅涉及加法操作，这使得在洗牌模型中的非交互式安全函数评估成为可能。原文通过双线性群中的Diffie-Hellman类型假设构建了ARE。而本文则提出了基于公钥加密的ARE构造方法，关键思想是一方隐私保护的单向ARE相对容易实现，可以通过某种方式提升为完整的ARE，并给出了从CDH假设出发的更高效的黑盒构造方法。 <div>
Introduced by Halevi, Ishai, Kushilevitz, and Rabin (CRYPTO 2023), Additive randomized encodings (ARE) reduce the computation of a $k$-party function $f(x_1,\dots,x_k)$ to locally computing encodings $\hat x_i$ of each input $x_i$ and then adding them together over some Abelian group into an output encoding $\hat y = \sum \hat x_i$, which reveals nothing but the result. The appeal of ARE comes from the simplicity of the non-local computation, involving only addition. This gives rise for instance to non-interactive secure function evaluation in the shuffle model where messages from different parties are anonymously shuffled before reaching their destination. Halevi, Ishai, Kushilevitz, and Rabin constructed ARE based on Diffie-Hellman type assumptions in bilinear groups.

We construct ARE assuming public-key encryption. The key insight behind our construction is that one-sided ARE, which only guarantees privacy for one of the parties, are relatively easy to construct, and yet can be lifted to full-fledged ARE. We also give a more efficient black-box construction from the CDH assumption.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 17:33:25 +0000</pubDate>
</item>
<item>
<title>Unveiling Privacy Risks in Quantum Optimization Services</title>
<link>https://eprint.iacr.org/2025/101</link>
<guid>https://eprint.iacr.org/2025/101</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算量子计算、隐私保护、混淆方法、变量置换、组合方法、攻击策略、Trivium密码家族、优化问题、复杂度、反制措施。

总结：
随着云计算量子计算服务（如D-Wave提供的服务）在实际应用中的普及，针对数据安全、隐私和法律合规的关注日益增加，因此隐私保护方法（如混淆）变得至关重要。文章指出了已提出的用于量子优化问题的混淆方法中，签反向已被证明不安全。研究提出了对变量置换及组合方法的两种攻击策略，能在被提供模糊化问题及其解决方案的情况下，有效地恢复原问题，特别是在解决Trivium密码家族的加密分析优化问题上下文中。这些攻击策略具有高效性和实用性，对于拥有n个变量、采用组合方法混淆的问题，解混淆复杂度仅为$O(n^2)$，远低于暴力破解所需的$O\left( n \cdot n! \cdot 2^n \right)$。文章还提供了攻击实现并演示了其在处理全量Trivium密码时可在两分钟内的高效运行，并提出了可能的反制措施，强调了在此领域进一步发展的必要性。<br /><br /> <div>
As cloud-based quantum computing services, such as those offered by D-Wave, become more popular for practical applications, privacy-preserving methods (such as obfuscation) are essential to address data security, privacy, and legal compliance concerns.
Several efficient obfuscation methods have been proposed, which do not increase the time complexity of solving the obfuscated problem, for quantum optimization problems. These include {\em sign reversing}, {\em variable permutation}, and the combination of both methods assumed to provide greater protection. Unfortunately, sign reversing has already been shown to be insecure. 

We present two attacks on variable permutation and the combined method, where it is possible to efficiently recover the deobfuscated problem, particularly when given access to the obfuscated problem and its obfuscated solution, as a cloud-based quantum provider would have.
Our attacks are in the context of an optimization problem of cryptanalysis of the Trivium cipher family, but our approach generalizes to other similarly structured problems.

Our attacks are efficient and practical.
Deobfuscating an optimization problem with \( n \) variables obfuscated with the combined method has a complexity of $O(n^2)$ compared to the complexity of $O\left( n \cdot n! \cdot 2^n \right)$ of the brute force attack.
We provide an implementation of our attack; using a commodity laptop, our attack using the full Trivium cipher takes less than two minutes if optimized.
We also present possible countermeasures to mitigate our attacks and bring attention to the need for further development in this area.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 11:58:36 +0000</pubDate>
</item>
<item>
<title>Fast, private and regulated payments in asynchronous networks</title>
<link>https://eprint.iacr.org/2025/098</link>
<guid>https://eprint.iacr.org/2025/098</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化、完全隐私、非交互式零知识证明（NIZK）、监管机制、Paxpay

总结:<br />
我们提出了一种去中心化的资产转移系统，该系统实现了全面的隐私保护，除了交易发起者和接收者之外，任何一方都无法得知交易详情，而接收者只知道交易金额。此系统不依赖共识或同步假设，因此具有响应性，能以实际网络速度运行。每个交易会在生成可消费的代币时附带一个NIZK，用于证实发行方有足够的资金，但不会泄露其身份信息、接收方的身份信息或支付金额等任何信息。此外，我们的系统还配备了一个监管执行机制，能够在保持系统隐私保证的同时，对转账限额或特定地址的资金收发进行限制。最后，我们报告了使用Gnark库实现全私有资产转移（FPAT）的Paxpay系统，并在基准测试中表现出优于以往仅提供部分隐私保护、需要网络同步假设或者未实施监管功能的提案的性能。因此，我们的系统成功地兼顾了隐私、响应性、监管执行与性能。 <div>
We propose a decentralized asset-transfer system that enjoys full privacy: no party can learn the details of a transaction, except for its issuer and its recipient. Furthermore, the recipient is only aware of the amount of the transaction. Our system does not rely on consensus or synchrony assumptions, and therefore, it is responsive, since it runs at the actual network speed. Under the hood, every transaction creates a consumable coin equipped with a non-interactive zero-knowledge proof (NIZK) that confirms that the issuer has sufficient funds without revealing any information about her identity, the recipient's identity, or the payment amount. Moreover, we equip our system with a regulatory enforcement mechanism that can be used to regulate transfer limits or restrict specific addresses from sending or receiving funds, while preserving the system's privacy guarantees.
        
Finally, we report on Paxpay, our implementation of Fully Private Asset Transfer (FPAT) that uses the Gnark library for the NIZKs. In our benchmark, Paxpay exhibits better performance than earlier proposals that either ensure only partial privacy, require some kind of network synchrony or do not implement regulation features. Our system thus reconciles privacy, responsiveness, regulation enforcement and performance.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 09:01:00 +0000</pubDate>
</item>
<item>
<title>Available Attestation: Towards a Reorg-Resilient Solution for Ethereum Proof-of-Stake</title>
<link>https://eprint.iacr.org/2025/097</link>
<guid>https://eprint.iacr.org/2025/097</guid>
<content:encoded><![CDATA[
<div> 关键词: 以太坊、权益证明(PoS)共识、重组织攻击、安全性、效率

总结:
<br />
以太坊已于2022年9月从工作量证明(PoW)共识机制转变为权益证明(PoS)共识。然而，这一升级引入了新的安全隐患，如恶意重组织攻击，攻击者通过故意操纵权威链以摒弃诚实验证器的区块，从而获取更多收益或威胁系统活性。文章指出，许多针对以太坊PoS的已知攻击实质上都属于重组织攻击，且这些攻击即使在网络同步（存在消息传输和处理的已知上限）的情况下也能实施。与现有的针对性防御措施不同，本文提出了一种系统性方法，提供了一个既优雅又高效的解决方案来抵御重组织攻击，该方案在同步网络中被证明是安全的，无法发起重组织攻击；在部分同步网络中，则能实现共识协议的传统安全性与活性属性。评估结果显示，该解决方案能够抵抗五种类型的重组织攻击，并具有高效率。 <div>
Ethereum transitioned from Proof-of-Work consensus to Proof-of-Stake (PoS) consensus in September 2022. While this upgrade brings significant improvements (e.g., lower energy costs and higher throughput), it also introduces new vulnerabilities. One notable example is the so-called malicious \textit{reorganization attack}. Malicious reorganization denotes an attack in which the Byzantine faulty validators intentionally manipulate the canonical chain so the blocks by honest validators are discarded. By doing so, the faulty validators can gain benefits such as higher rewards, lower chain quality, or even posing a liveness threat to the system. 

In this work, we show that the majority of the known attacks on Ethereum PoS are some form of reorganization attacks. In practice, most of these attacks can be launched even if the network is synchronous (there exists a known upper bound for message transmission and processing). Different from existing studies that mitigate the attacks in an ad-hoc way, we take a systematic approach and provide an elegant yet efficient solution to reorganization attacks. Our solution is provably secure such that no reorganization attacks can be launched in a synchronous network. In a partially synchronous network, our approach achieves the conventional safety and liveness properties of the consensus protocol. Our evaluation results show that our solution is resilient to five types of reorganization attacks and also highly efficient.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 02:15:20 +0000</pubDate>
</item>
<item>
<title>A Survey on Transciphering and Symmetric Ciphers for Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/093</link>
<guid>https://eprint.iacr.org/2025/093</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私、同态加密、计算负载、通信开销、HE友好密码体制<br /><br />总结:
随着云计算、大数据分析和物联网的发展，数据隐私问题日益凸显。同态加密作为一种在加密数据上进行计算的技术，因其现有方案存在加密速度慢和密文膨胀大的缺点，其实际应用受到限制，尤其是在客户端资源有限的情况下。为解决此问题，Naehrig等人于2011年提出了转置加密技术，旨在减少客户端的计算和通信负担，这种技术依赖于具有最小乘法复杂度的对称密码体制，被称为HE友好密码体制（HEFCs）。本文详细研究了同态加密中的转置加密技术，系统整理了现有的知识并明确了研究挑战，重点考察了最先进的HEFC构造方法。我们的工作突显出了该领域的研究空白、未解决问题及未来研究方向。 <div>
Data privacy concerns are sharply rising in the current digital era, hyperdriven by cloud computing, big data analytics, and the Internet of Things. Homomorphic Encryption (HE) has emerged as an ideal technique for computing on encrypted data, but current schemes suffer from slow encryption speed and large ciphertext expansion. Practical implementation is hindered, especially when the client has limited bandwidth, memory, and computing power. In 2011, Naehrig et al. proposed transciphering, reducing computational and communication overload on the client side. This involves symmetric ciphers with minimized multiplicative complexity, 
referred to as HE-Friendly Ciphers (HEFCs). 

In this work, we present a detailed study of transciphering for HE by systematizing existing knowledge and crystallizing research challenges. Particularly we conduct a comprehensive study on state-of-the-art HEFC constructions. Our work highlights gaps, open problems, and directions for future research.
]]></content:encoded>
<pubDate>Tue, 21 Jan 2025 23:05:50 +0000</pubDate>
</item>
<item>
<title>poqeth: Efficient, post-quantum signature verification on Ethereum</title>
<link>https://eprint.iacr.org/2025/091</link>
<guid>https://eprint.iacr.org/2025/091</guid>
<content:encoded><![CDATA[
<div> 关键词：后量子密码学（Post-Quantum）、数字签名、区块链、以太坊虚拟机、Naysayer 证明

总结:<br />
本文探讨了在区块链环境中标准化后量子数字签名算法的应用与高效部署，特别地，实现了并评估了四种PQ签名算法——W-OTS$^+$、XMSS、SPHINCS+和MAYO在以太坊虚拟机上的表现。文章重点关注优化验证算法的 Gas 成本，因为这是用户承担交易费用的关键因素。研究中，作者考察了两种在链上验证后量子数字签名的方法，实际性能评估显示，完全在链上验证的成本往往过高。为此，提出了利用 Naysayer 证明实现的一种新型乐观验证模式，该模式通常成本最低，但需增加额外的信任假设。最后，作者将其实现成果 poqeth 开源作为一个库公开发布。 <div>
This work explores the application and efficient deployment of (standardized) post-quantum (PQ) digital signature algorithms in the blockchain environment. Specifically, we implement and evaluate four PQ signatures in the Ethereum Virtual Machine: W-OTS$^{+}$, XMSS, SPHINCS+, and MAYO. We focus on optimizing the gas costs of the verification algorithms as that is the signature schemes' only algorithm executed on-chain, thus incurring financial costs (transaction fees) for the users. Hence, the verification algorithm is the signature schemes' main bottleneck for decentralized applications.

We examine two methods to verify post-quantum digital signatures on-chain. Our practical performance evaluation shows that full on-chain verification is often prohibitively costly. Naysayer proofs (FC'24) allow a novel optimistic verification mode. We observe that the Naysayer verification mode is generally the cheapest, at the cost of additional trust assumptions. We release our implementation called poqeth as an open-source library.
]]></content:encoded>
<pubDate>Tue, 21 Jan 2025 15:03:01 +0000</pubDate>
</item>
<item>
<title>ICT: Insured Cryptocurrency Transactions</title>
<link>https://eprint.iacr.org/2025/088</link>
<guid>https://eprint.iacr.org/2025/088</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、欺诈风险、保险框架、Insured Cryptocurrency Transactions (ICT)、Insured Cryptocurrency Exchange (ICE)

总结:<br />
本文提出了一个针对加密货币交易中欺诈风险问题的解决方案——Insured Cryptocurrency Transactions (ICT)，这是一种新颖的去中心化保险框架，旨在保障因欺诈交易受损的诚实用户能够获得财务补偿。ICT框架通过严格的正式化方法确保了强大的安全性，以抵御恶意攻击者。文章进一步介绍了ICT的一个具体应用实例——Insured Cryptocurrency Exchange (ICE)，它是一个针对中心化加密货币交易所设计的保险机制，利用智能合约在交易所遭受安全漏洞、破产或发生欺诈行为等情况时，为用户提供赔偿。已经实现了ICE的智能合约并对其进行了链上成本评估，结果显示其具有较低的运行开销。据作者所知，ICT和ICE是加密货币领域内首个正式提出的去中心化保险框架方案。 <div>
Cryptocurrencies have emerged as a critical medium for digital financial transactions, driving widespread adoption while simultaneously exposing users to escalating fraud risks. The irreversible nature of cryptocurrency transactions, combined with the absence of consumer protection mechanisms, leaves users vulnerable to substantial financial losses and emotional distress. To address these vulnerabilities, we introduce Insured Cryptocurrency Transactions (ICT), a novel decentralized insurance framework designed to ensure financial recovery for honest users affected by fraudulent cryptocurrency transactions. We rigorously formalize the ICT framework, establishing strong security guarantees to protect against malicious adversaries. Furthermore, we present Insured Cryptocurrency Exchange (ICE), a concrete instantiation of ICT tailored for centralized cryptocurrency exchanges. ICE relies primarily on a standard smart contract and provides a robust mechanism to compensate users in cases of security breaches, insolvency, or fraudulent activities affecting the exchange. We have implemented ICE’s smart contract and evaluated its on-chain costs. The evaluation results demonstrate ICE’s low operational overhead. To our knowledge, ICT and ICE represent the first formal approaches to decentralized insurance frameworks in the cryptocurrency domain.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 19:14:25 +0000</pubDate>
</item>
<item>
<title>Arbitrary-Threshold Fully Homomorphic Encryption with Lower Complexity</title>
<link>https://eprint.iacr.org/2025/084</link>
<guid>https://eprint.iacr.org/2025/084</guid>
<content:encoded><![CDATA[
<div> 关键词: Threshold Fully Homomorphic Encryption (ThFHE), Arbitrary Threshold (ATh)-FHE, Non-participants, Approximate Secret Sharing (ApproxSS), ATASSES

总结:
本文提出了一种新的任意阈值全同态加密(ThFHE)方案——ATh-FHE，旨在解决多方在不泄露敏感数据隐私的情况下计算函数的问题。相较于大多数仅支持完全阈值的ThFHE方案，ATh-FHE能更好地应对非参与者的情况，并适用于更多现实世界的应用场景。然而，现有的ATh-FHE方案要么在处理大量参与方和大数据规模时效率低下，要么无法容忍所有类型的非参与者。为此，本文提出了一个新的抽象原语——近似秘密分享(ApproxSS)，并将ATh-FHE方案的构建归约为设计该原语的问题。通过建立ApproxSS与ATh-FHE之间正确性和安全性的理论证明，作者揭示了现有ATh-FHE方案隐含地采用了“噪声份额”的设计理念，但这种方法存在高复杂度问题，成为性能瓶颈。为了解决这个问题，文章开发了一个基于“加密份额”新理念的ATh-ApproxSS方案——ATASSES，将其计算和通信复杂度分别从$\mathcal{O}(N^2K)$降低到$\mathcal{O}(N^2+K)$和从$\mathcal{O}(NK)$降低到$\mathcal{O}(N+K)$。理论分析与实证评估均表明，相比于现有基准方案，当应用于包含一千个参与方的系统时，ATASSES可实现高达$3.83\times$至$15.4\times$的速度提升。 <div>
Threshold fully homomorphic encryption (ThFHE) enables multiple parties to compute functions over their sensitive data without leaking data privacy. Most of existing ThFHE schemes are restricted to full threshold and require the participation of all parties to output computing results. Compared with these full-threshold schemes, arbitrary threshold (ATh)-FHE schemes are robust to non-participants and can be a promising solution to many real-world applications. However, existing AThFHE schemes are either inefficient to be applied with a large number of parties $N$ and a large data size $K$, or insufficient to tolerate all types of non-participants. In this paper, we propose an AThFHE scheme to handle all types of non-participants with lower complexity over existing schemes. At the core of our scheme is the reduction from AThFHE construction to the design of a new primitive called approximate secret sharing (ApproxSS). Particularly, we formulate ApproxSS and prove the correctness and security of AThFHE on top of arbitrary-threshold (ATh)-ApproxSS's properties. Such a reduction reveals that existing AThFHE schemes implicitly design ATh-ApproxSS following a similar idea called ``noisy share''. Nonetheless, their ATh-ApproxSS design has high complexity and become the performance bottleneck. By developing ATASSES, an ATh-ApproxSS scheme based on a novel ``encrypted share'' idea, we reduce the computation (resp. communication) complexity from $\mathcal{O}(N^2K)$ to $\mathcal{O}(N^2+K)$ (resp. from $\mathcal{O}(NK)$ to $\mathcal{O}(N+K)$). We not only theoretically prove the (approximate) correctness and security of ATASSES, but also empirically evaluate its efficiency against existing baselines. Particularly, when applying to a system with one thousand parties, ATASSES achieves a speedup of $3.83\times$ -- $15.4\times$ over baselines.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 02:29:50 +0000</pubDate>
</item>
<item>
<title>Recover from Excessive Faults in Partially-Synchronous BFT SMR</title>
<link>https://eprint.iacr.org/2025/083</link>
<guid>https://eprint.iacr.org/2025/083</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine故障容错(BFT SMR), 过度故障设置, 修复算法, 线性链状、群组同步SMR, 故障检测模块

总结:
本文研究了在过度故障设置下，拜占庭容错（BFT SMR）状态机复制协议如何从由过多故障引发的错误状态中恢复。首先，文章提出了首个针对线性链状和基于群组同步的SMR的部分故障修复算法，该算法利用不误判正常副本的任何故障检测模块实现。在此过程中，虽然活动生成保证略有减弱，但原文档中不可能在存在过多故障的情况下维持原安全特性。

文章实现了可恢复的HotStuff协议，并使用Rust编程语言完成。在恢复程序结束后，当有7个副本发生故障时，吞吐量恢复到无过多故障情况下的正常水平，并且在有30个副本发生故障时，仅减少了不超过4.3%。平均而言，对于7个副本，延迟增加了12.87%\usenix{(而对于30个副本，延迟增加为8.85%)}。

此外，文章还建立了对于具有最多(n-2)个（总共有n个副本）拜占庭副本攻击安全性的情况，一般BFT SMR协议能够实现完整且准确的故障检测的充分条件。文章首次提出了一种适用于任意SMR协议的无需额外通信轮次的封闭式故障检测算法，并进一步描述了在Tendermint和HotStuff中的开箱即用的故障检测例程，从而在理论上和具体实现上都降低了开销。 <div>
Byzantine fault-tolerant (BFT) state machine replication (SMR) protocols form the basis of modern blockchains as they maintain a consistent state across all blockchain nodes while tolerating a bounded number of Byzantine faults. We analyze BFT SMR in the excessive fault setting where the actual number of Byzantine faults surpasses a protocol's tolerance. 

We start by devising the very first repair algorithm for linearly chained and quorum-based partially synchronous SMR to recover from faulty states caused by excessive faults. Such a procedure can be realized using any commission fault detection module -- an algorithm that identifies the faulty replicas without falsely locating any correct replica. We achieve this with a slightly weaker liveness guarantee, as the original security notion is impossible to satisfy given excessive faults.


We implement recoverable HotStuff in Rust. The throughput resumes to the normal level (without excessive faults) after recovery routines terminate for $7$ replicas and is slightly reduced by $\leq 4.3\%$ for $30$ replicas. On average, it increases the latency by $12.87\%$ for $7$ replicas \usenix{and $8.85\%$ for $30$ replicas}.

Aside from adopting existing detection modules, we also establish the sufficient condition for a general BFT SMR protocol to allow for complete and sound fault detection when up to $(n-2)$ Byzantine replicas (out of $n$ total replicas) attack safety. We start by providing the first closed-box fault detection algorithm for any SMR protocol without any extra rounds of communication. We then describe open-box instantiations of our fault detection routines in Tendermint and Hotstuff, further reducing the overhead, both asymptotically and concretely.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:31:06 +0000</pubDate>
</item>
<item>
<title>Breaking verifiability and vote privacy in CHVote</title>
<link>https://eprint.iacr.org/2025/080</link>
<guid>https://eprint.iacr.org/2025/080</guid>
<content:encoded><![CDATA[
<div> 关键词: CHVote、电子投票系统、瑞士、安全性漏洞、攻击

总结:<br />
CHVote是瑞士政治选举中开发的主要电子投票系统之一，其运作需满足特定法规和信任假设。然而，研究发现，只要其中一个在线组件不诚实，CHVote就无法实现投票秘密性和个人投票意图可验证性，这与CHVote的安全声明相矛盾。研究人员共发现了针对CHVote的9种攻击或变体，其中2种源于其参考实现中的bug。这些发现已通过概念验证的攻击实施得到确认。 <div>
Abstract. CHVote is one of the two main electronic voting systems developed in the context of political elections in Switzerland, where the regulation requires a specific setting and specific trust assumptions.  We show that actually, CHVote fails to achieve vote secrecy and individual verifiability (here, recorded-as-intended), as soon as one of the online components is dishonest, contradicting the security claims of CHVote.  In total, we found 9 attacks or variants against CHVote, 2 of them being based on a bug in the reference implementation. We confirmed our findings through a proof-of-concept implementation of our attacks.
]]></content:encoded>
<pubDate>Sat, 18 Jan 2025 13:34:35 +0000</pubDate>
</item>
<item>
<title>Hardware-Accelerated Encrypted Execution of General-Purpose Applications</title>
<link>https://eprint.iacr.org/2023/641</link>
<guid>https://eprint.iacr.org/2023/641</guid>
<content:encoded><![CDATA[
<div> 关键词：Fully Homomorphic Encryption (FHE)，CGGI方案，ArctyrEX，加速加密执行，GPU加速Concrete库

总结:
本文研究了全同态加密（FHE）技术，特别是当前先进的基于环域的CGGI方案。针对CGGI方案在处理如sigmoid等简单非线性函数时效率低下的问题，文章提出了一种名为ArctyrEX的新框架，该框架能实现端到端的加速加密执行。使用ArctyrEX，开发者无需深入了解复杂的FHE库，只需以C程序描述计算任务，相比于GPU加速的Concrete库，在乘法密集型基准测试中平均性能提升了18倍。 <div>
Fully Homomorphic Encryption (FHE) is a cryptographic method that guarantees the privacy and security of user data during computation. FHE algorithms can perform unlimited arithmetic computations directly on encrypted data without decrypting it. Thus, even when processed by untrusted systems, confidential data is never exposed. In this work, we develop new techniques for accelerated encrypted execution and demonstrate the significant performance advantages of our approach. Our current focus is the Fully Homomorphic Encryption over the Torus (CGGI) scheme, which is a current state-of-the-art method for evaluating arbitrary functions in the encrypted domain. CGGI represents a computation as a graph of homomorphic logic gates and each individual bit of the plaintext is transformed into a polynomial in the encrypted domain. Arithmetic on such data becomes very expensive: operations on bits become operations on entire polynomials.  Therefore, evaluating even relatively simple nonlinear functions with the CGGI cryptosystem, such as a sigmoid, can take thousands of seconds on a single CPU thread. Using our novel framework for end-to-end accelerated encrypted execution called ArctyrEX, developers with no knowledge of complex FHE libraries can simply describe their computation as a C program that is evaluated 18x faster on average relative to the GPU-accelerated Concrete library for multiplication-intensive benchmarks.
]]></content:encoded>
<pubDate>Fri, 05 May 2023 15:25:03 +0000</pubDate>
</item>
<item>
<title>On Multi-Key FuncCPA Secure Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/077</link>
<guid>https://eprint.iacr.org/2025/077</guid>
<content:encoded><![CDATA[
<div> 关键词：funcCPA安全、同态加密、非同态公钥加密、多密钥设置、KDM安全

总结:
文章介绍了funcCPA安全性这一概念，最初由Akavia等人在TCC 2022上提出，主要针对同态加密中的引导技术。然而，Dodis等人在TCC 2023中指出，funcCPA安全也可应用于非同态公钥加密，特别是在无同态计算情况下的隐私保护外包计算领域。尽管前期研究仅关注单密钥设定，但近年来多 parties 合作在外包计算中的重要性日益凸显，使得对funcCPA安全支持多密钥设置的需求变得迫切。因此，本文引入了一个新的安全性概念——多密钥funcCPA（MKfunc）以满足这一需求，并证明如果一个公钥加密方案具备KDM安全性，则它也具有MKfuncCPA安全性。此外，文中还讨论了该理论可同样适用于对称密钥加密的情况。 <div>
The notion of funcCPA security for homomorphic encryption schemes was introduced by Akavia \textit{et~al.}\ (TCC 2022). Whereas it aims to capture the bootstrapping technique in homomorphic encryption schemes, Dodis \textit{et~al.}\ (TCC 2023) pointed out that funcCPA security can also be applied to non-homomorphic public-key encryption schemes (PKE). As an example, they presented a use case for privacy-preserving outsourced computation without homomorphic computation. It should be noted that prior work on funcCPA security, including the use case presented by Dodis \textit{et~al.}, considered only the single-key setting. However, in recent years, multi-party collaboration in outsourced computation has garnered significant attention, making it desirable for funcCPA security to support the multi-key setting. Therefore, in this work, we introduce a new notion of security called Multi-Key funcCPA (MKfunc) to address this need, and show that if a PKE scheme is KDM-secure, then it is also MKfuncCPA secure. Furthermore, we show that similar discussions can be applied to symmetric-key encryption.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 13:28:27 +0000</pubDate>
</item>
<item>
<title>RSA Blind Signatures with Public Metadata</title>
<link>https://eprint.iacr.org/2023/1199</link>
<guid>https://eprint.iacr.org/2023/1199</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名令牌、公共元数据、RSA盲签名、安全性证明、实际部署

<br /><br />总结: 本文研究了具有公共元数据的匿名令牌概念，这是一种允许发行者生成与特定公共元数据相关联的签名，同时保护用户身份隐私的技术。文中提出了一种RSA盲签名的变体，该变体仅能为预设的公共元数据生成有效的签名，其基于Abe和Fujisaki的一项方案进行改进，并使用标准密码学技术实现。安全性的证明建立在一个带有多个指数的一次性RSA假设上，预计其实际安全性接近标准RSA盲签名。实验结果显示，此协议相比标准RSA盲签名仅有轻微的开销，并已作为技术规范被纳入一个IRTF互联网草案中，还展示了其实战部署的可扩展性。 <div>
Anonymous tokens are, essentially, digital signature schemes that enable issuers to provide users with signatures without learning the user inputs or the final signatures. These primitives allow applications to propagate trust while simultaneously protecting the user identity. They have become a core component for improving the privacy of several real-world applications including ad measurements, authorization protocols, spam detection, and VPNs.
In certain applications, it is natural to associate signatures with specific public metadata, ensuring that trust is only propagated with respect to only a certain set of users and scenarios. To solve this, we study the notion of anonymous tokens with public metadata. We present a variant of RSA blind signatures with public metadata where issuers may only generate signatures that verify for a certain choice of public metadata a modification of a scheme by Abe and Fujisaki [9]. Our protocol exclusively uses standard cryptography with widely available implementations. We prove security from the one-more RSA assumptions with multiple exponents that we introduce. Furthermore, we provide evidence that the concrete security bounds should be nearly identical to standard RSA blind signatures. We show that our protocol incurs minimal overhead over standard RSA blind signatures and report anonymous telemetry for a real-world deployment to showcase its scalability. Moreover, the protocol in this paper has been proposed as a technical specification in an IRTF internet draft [12].
]]></content:encoded>
<pubDate>Tue, 08 Aug 2023 01:23:07 +0000</pubDate>
</item>
<item>
<title>PSMT: Private Segmented Membership Test for Distributed Record Linkage</title>
<link>https://eprint.iacr.org/2025/072</link>
<guid>https://eprint.iacr.org/2025/072</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Segmented Membership Test (PSMT), 多方 PSI (MPSI), 加密 Homomorphic, 带阈值的近似算术, 实验评估

总结:
本文提出了一种基于带阈值的近似算术同态加密的Private Segmented Membership Test (PSMT)基本协议，旨在解决多方数据持有者场景下，客户端查询多个数据元素是否存在于多个加密集合中的隐私保护问题。与现有方法相比，新协议避免了泄露匹配元素持有者的身份信息，降低了处理多元素查询时的通信开销，并减少了大量数据持有者情况下的误报率，同时确保了IND-CPA^D安全级别。该协议具有更好的可扩展性，支持更多的数据持有者和查询元素（实验中可达4096个参与方和512个查询）。实验结果显示，在处理来自1024个数据持有者的、大小为2^15的集合的结果聚合时，仅需71.2秒，每增加一个查询仅需额外1.2秒。相较于其他现有的PSI和MPSI协议以及先前的工作，新的PSMT协议在可用性和更强的隐私模型方面有所改进，并能支持更大数量的参与者和查询。 <div>
In various real-world situations, a client may need to verify whether specific data elements they possess are part of a set segmented among numerous data holders. 
To maintain user privacy, it’s essential that both the client’s data elements and the data holders’ sets remain encrypted throughout the process. 
Existing approaches like Private Set Intersection (PSI), Multi-Party PSI (MPSI), Private Segmented Membership Test (PSMT), and Oblivious RAM (ORAM) face challenges in these contexts.
They either require data holders to access the sets in plaintext, result in high latency when aggregating data from multiple holders, risk exposing the identity of the party with the matching element, cause a large communication overhead for multiple-element queries, or lead to high false positives.

This work introduces the primitive of a Private Segmented Membership Test (PSMT) for clients with multiple query elements. 
We present a basic protocol for solving PSMT using a threshold variant of approximate-arithmetic homomorphic encryption, addressing the challenges of avoiding information leakage about the party with the intersection element, minimizing communication overhead for multiple query elements, and preventing false positives for a large number of data holders ensuring IND-CPA^D security.
Our novel approach surpasses current state-of-the-art methods in scalability, supporting significantly more data holders.
This is achieved through a novel summation-based homomorphic membership check rather than a product-based one, as well as various novel ideas addressing technical challenges. 

Our new PSMT protocol supports a large number of parties and query elements (up to 4096 parties and 512 queries in experiments) compared to previous methods.
Our experimental evaluation shows that our method's aggregation of results from 1024 data holders with a set size of 2^15 can run in 71.2s and only requires an additional 1.2 seconds per query for processing multiple queries.
We also compare our PSMT protocol to other state-of-the-art PSI and MPSI protocols and our previous work and discuss our improvements in usability with a better privacy model and a larger number of parties and queries.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 20:04:16 +0000</pubDate>
</item>
<item>
<title>On Composing Generic Voting Schemes for Improved Privacy</title>
<link>https://eprint.iacr.org/2025/069</link>
<guid>https://eprint.iacr.org/2025/069</guid>
<content:encoded><![CDATA[
<div> 关键词：hybrid encryption, 量子计算, 投票方案, 正确性, 完整性, 隐私性

总结:
<br />
本文探讨了混合加密技术如何通过组合多种现有加密方案来在众多计算假设中分布信任，特别是在量子计算发展背景下，使得我们能同时利用后量子时代的隐私性和经典加密方案的成熟性。文章展示了如何将一类非常广泛的投票方案进行组合，并证明这种组合能够保持正确性和完整性的同时，还能提升隐私性相比其组成部分。此外，文中还给出了一个使用基于格的解密混合网络的例子，其中隐私性的提升可以间接带来完整性的改善。 <div>
Hybrid encryption provides a way for schemes to distribute trust among many computational assumptions, for instance by composing existing schemes. This is increasingly relevant as quantum computing advances because it lets us get the best of both worlds from the privacy of the post quantum schemes and the more battle tested classical schemes.
    We show how to compose members of a very general class of voting schemes and prove that this preserves correctness and integrity and improves privacy compared to its constituent parts.
    We also show an example composition using a lattice based decryption mixnet where the improvement in privacy can indirectly lead to an improvement in integrity.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 11:17:28 +0000</pubDate>
</item>
<item>
<title>Shielded CSV: Private and Efficient Client-Side Validation</title>
<link>https://eprint.iacr.org/2025/068</link>
<guid>https://eprint.iacr.org/2025/068</guid>
<content:encoded><![CDATA[
<div> 关键词: Cryptocurrency, Client-Side Validation (CSV), Privacy, Shielded CSV, Proof Carrying Data (PCD)

总结:
本文介绍了Shielded CSV，这是一种改进的客户端验证（CSV）协议，旨在解决加密货币中的通信、计算和存储成本以及隐私问题。相较于传统私人加密货币设计，Shielded CSV只需在区块链上记录每个交易的64字节数据——nullifier，并使接收者执行一次Schnorr签名验证即可，同时非用户可忽略此数据。其coin证明的大小和验证成本与交易历史无关。该方案提出将比特币的交易处理速度提升至每秒100笔，前提是存在适当的桥接机制到区块链。文章利用Proof Carrying Data (PCD)抽象来规范Shielded CSV，并讨论了两种实用的实现策略：基于Folding Schemes和Recursive STARKs的方法，并提出了未来扩展的建议，展示了Shielded CSV框架及其之上构建的协议的巨大潜力。 <div>
Cryptocurrencies allow mutually distrusting users to transact monetary value over the internet without relying on a trusted third party.

Bitcoin, the first cryptocurrency, achieved this through a novel protocol used to establish consensus about an ordered transaction history.
This requires every transaction to be broadcasted and verified by the network, incurring communication and computational costs.
Furthermore, transactions are visible to all nodes of the network, eroding privacy, and are recorded permanently, contributing to increasing storage requirements over time.
To limit resource usage of the network, Bitcoin currently supports an average of 11 transactions per second.

Most cryptocurrencies today still operate in a substantially similar manner.
Private cryptocurrencies like Zcash and Monero address the privacy issue by replacing transactions with proofs of transaction validity.
However, this enhanced privacy comes at the cost of increased communication, storage, and computational requirements.

Client-Side Validation (CSV) is a paradigm that addresses these issues by removing transaction validation from the blockchain consensus rules.
This approach allows sending the coin along with a validity proof directly to its recipient, reducing communication, computation and storage cost.
CSV protocols deployed on Bitcoin today do not fully leverage the paradigm's potential, as they still necessitate the overhead of publishing ordinary Bitcoin transactions.
Moreover, the size of their coin proofs is proportional to the coin's transaction history, and provide limited privacy.
A recent improvement is the Intmax2 CSV protocol, which writes significantly less data to the blockchain compared to a blockchain transaction and has succinct coin proofs.

In this work, we introduce Shielded CSV, which improves upon state-of-the-art CSV protocols by providing the first construction that offers truly private transactions.
It addresses the issues of traditional private cryptocurrency designs by requiring only 64 bytes of data per transaction, called a nullifier, to be written to the blockchain.
Moreover, for each nullifier in the blockchain, Shielded CSV users only need to perform a single Schnorr signature verification, while non-users can simply ignore this data.
The size and verification cost of coin proofs for Shielded CSV receivers is independent of the transaction history.
Thus, one application of Shielded CSV is adding privacy to Bitcoin at a rate of 100 transactions per second, provided there is an adequate bridging mechanism to the blockchain.

We specify Shielded CSV using the Proof Carrying Data (PCD) abstraction.
We then discuss two implementation strategies that we believe to be practical, based on Folding Schemes and Recursive STARKs, respectively.
Finally, we propose future extensions, demonstrating the power of the PCD abstraction and the extensibility of Shielded CSV.
This highlights the significant potential for further improvements to the Shielded CSV framework and protocols built upon it.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 08:49:45 +0000</pubDate>
</item>
<item>
<title>Constant latency and finality for dynamically available DAG</title>
<link>https://eprint.iacr.org/2025/067</link>
<guid>https://eprint.iacr.org/2025/067</guid>
<content:encoded><![CDATA[
<div> 关键词: DAG、区块链性能、CAP定理、结构化传播、分级公共前缀 (GCP)、活性、安全性、网络分区、预期延迟、吞吐量、低通信步骤、容错性、Ebb-and-Flow框架、混合协议、最终性

总结:<br />
本文探讨了两种基于有向无环图（DAG）的协议，分别针对活性与安全性进行优化。首先，文章提出了首个具有常数预期延迟的DAG协议——结构化传播，其预期延迟为$3\Delta$，并能在睡眠模型下实现高吞吐量动态可用性，通过跨多台机器的原型验证优于现有常数延迟的睡眠模型BFT。其次，分级公共前缀（GCP）是一种在网络分区下保证安全性的协议，相较于现有的低延迟部分同步BFT仅需两步通信，且能避免依赖单一领导者提案，增强了对崩溃的容错性，实验也验证了GCP的理论优势。最后，文章将这些发现应用于扩展Ebb-and-Flow框架，通过两个BFT子协议使系统中不同类型客户端可以优先选择活性或安全性，实现了无需重复运行标准共识协议的高效、动态可用和具有最终性的混合DAG协议。 <div>
Directed Acyclic Graph (DAG) based protocols have shown great promise to improve the performance of blockchains. The CAP theorem shows that it is impossible to have a single system that achieves both liveness (known as dynamic availability) and safety under network partition.This paper explores two types of DAG-based protocols prioritizing liveness or safety, named structured dissemination and Graded Common Prefix (GCP), respectively. 
    
    For the former, we introduce the first DAG-based protocol with constant expected latency, providing high throughput dynamic availability under the sleepy model. Its expected latency is $3\Delta$ and its throughput linearly scales with participation. We validate these expected performance improvements over existing constant latency sleepy model BFT by running prototypes of each protocol across multiple machines.
    
    The latter, GCP, is a primitive that provides safety under network partition, while being weaker than standard consensus. As a result, we are able to obtain a construction that runs in only $2$ communication steps, as opposed to the $4$ steps of existing low latency partially synchronous BFT. In addition, GCP can easily avoid relying on single leaders' proposals, becoming more resilient to crashes. We also validate these theoretical benefits of GCP experimentally.
    
    We leverage our findings to extend the Ebb-and-Flow framework, where two BFT sub-protocols allow different types of clients in the same system to prioritize either liveness or safety. Our extension integrates our two types of DAG-based protocols. This provides a hybrid DAG-based protocol with high throughput, dynamical availability, and finality under network partitions, without running a standard consensus protocol twice as required in existing work.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 08:44:58 +0000</pubDate>
</item>
<item>
<title>SoK: Trusted setups for powers-of-tau strings</title>
<link>https://eprint.iacr.org/2025/064</link>
<guid>https://eprint.iacr.org/2025/064</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密协议, 可信设置, 公共参数, 零知识简洁非交互式证明, 多方协议

总结:
这篇文章关注了加密协议中可信设置的重要性和应用，特别是在区块链领域利用零知识简洁非交互式论证（zk-SNARKs）的情况下。文章区分了设置"协议"和"仪式"两个概念，并探讨了不同方法的特点。文中提出了一种可信设置协议的分类体系，并根据设计原则、优缺点对现实世界的仪式进行了评估。文章旨在系统化现有可信设置的知识，强调了多方协议在防止陷阱门泄露以确保安全性方面的作用，以及公开仪式对于建立信任的重要性。 <div>
Many cryptographic protocols rely upon an initial \emph{trusted setup} to generate public parameters.  While the concept is decades old, trusted setups have gained prominence with the advent of blockchain applications utilizing zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs), many of which rely on a ``powers-of-tau'' setup. Because such setups feature a dangerous trapdoor which undermines security if leaked, multiparty protocols are used to prevent the trapdoor from being known by any one party.  Practical setups utilize an elaborate public ceremony to build confidence that the setup was not subverted.  In this paper, we aim to systematize existing knowledge on trusted setups, drawing the distinction between setup \emph{protocols} and \emph{ceremonies}, and shed light on the different features of various approaches. We establish a taxonomy of protocols and evaluate real-world ceremonies based on their design principles, strengths, and weaknesses.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:21:01 +0000</pubDate>
</item>
<item>
<title>PunSearch: Enabling Puncturable Encrypted Search over Lattice for Cloud Storage Systems</title>
<link>https://eprint.iacr.org/2025/063</link>
<guid>https://eprint.iacr.org/2025/063</guid>
<content:encoded><![CDATA[
<div> 关键词：可搜索加密（SE）、细粒度搜索权限撤销、量子安全、穿孔加密（PE）、PunSearch

总结:
本文提出了一种名为PunSearch的新型可搜索加密方案——首个基于格的穿孔加密搜索方案，用于云存储系统的外包数据隐私保护。该方案实现了细粒度的搜索权限撤销并具备量子安全性。与现有的PE方案不同，PunSearch通过评估算法和格前像采样技术构建了新颖的陷阱门生成机制，并设计了搜索权限验证方法以撤销对特定关键词的搜索能力。此外，文章还提出了一个新的IND-Pun-CKA安全模型来分析PunSearch的安全性。全面的性能评估显示，在最优情况下，PunSearch的Encrypt、Trapdoor、Search和Puncture算法的计算开销分别仅为其他先前方案的0.06、0.005、0.05和0.31倍，证明了PunSearch对于云存储系统既有效又安全。 <div>
Searchable encryption (SE) has been widely studied for cloud storage systems, allowing data encrypted search and retrieval. However, existing SE schemes can not support the fine-grained searchability revocation, making it impractical for real applications. Puncturable encryption (PE) [Oakland'15] can revoke the decryption ability of a data receiver for a specific message, which can potentially alleviate this issue. Moreover, the threat of quantum computing remains an important and realistic concern, potentially leading to data privacy leakage for cloud storage systems. Consequently, designing a post-quantum puncturable encrypted search scheme is still far-reaching. In this paper, we propose PunSearch, the first puncturable encrypted search scheme over lattice for outsourced data privacy-preserving in cloud storage systems. PunSearch provides a fine-grained searchability revocation while enjoying quantum safety. Different from existing PE schemes, we construct a novel trapdoor generation mechanism through evaluation algorithms and lattice pre-image sampling technique. We then design a search permission verification method to revoke the searchability for specific keywords. Furthermore, we formalize a new IND-Pun-CKA security model, and utilize it to analyze the security of PunSearch. Comprehensive performance evaluation indicates that the computational overheads of Encrypt, Trapdoor, Search, and Puncture algorithms in PunSearch are just 0.06, 0.005, 0.05, and 0.31 times of other prior arts, respectively under the best cases. These results demonstrate that PunSearch is effective and secure for cloud storage systems.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 17:05:42 +0000</pubDate>
</item>
<item>
<title>Fair Signature Exchange</title>
<link>https://eprint.iacr.org/2025/059</link>
<guid>https://eprint.iacr.org/2025/059</guid>
<content:encoded><![CDATA[
<div> 关键词：公平签名交换（FSE）、Schnorr签名方案、区块链、批量适配器签名、盲签交换

总结:
本文提出了公平签名交换（FSE）的概念，该机制使客户端能够在公平条件下获取多个消息的签名——只有当签署者收到约定的付款时，客户端才能获得所有签名。文章对FSE进行了形式化安全定义，并基于Schnorr签名方案给出了一种实际构建方法，避免了使用如SNARKs这样的计算密集型加密原语。此方案对Schnorr签名的签署者和验证者的开销极小，仅保留了与标准Schnorr签名相同的验证过程。通过利用区块链作为可信第三方来确保公平性，并在链上只交换常量级别的信息，无论签名交换的数量多少。文中还展示了如何使用FSE构建批量适配器签名方案，并实现了基于Schnorr的FSE构造，从而为离散对数问题提供了一个高效的批量Schnorr适配器签名方案实现。实验表明，该方案相对于标准Schnorr签名几乎无额外开销，例如，在Vesta曲线上交换$2^{10}$个签名，签署方耗时约80毫秒，验证方耗时约300毫秒，相较于原始Schnorr协议，签署方几乎无额外开销，而验证方有约2倍的开销。此外，文章还提出了一种扩展方案，即盲签名交换，使得签署者不会得知被签名的消息内容，这是通过对盲化的Schnorr签名的一种自然适应实现的。 <div>
We introduce the concept of Fair Signature Exchange (FSE). FSE enables a client to obtain signatures on multiple messages in a fair manner: the client receives all signatures if and only if the signer receives an agreed-upon payment. We formalize security definitions for FSE and present a practical construction based on the Schnorr signature scheme, avoiding computationally expensive cryptographic primitives such as SNARKs. Our scheme imposes minimal overhead on the Schnorr signer and verifier, leaving the signature verification process unchanged from standard Schnorr signatures. Fairness is enforced using a blockchain as a trusted third party, while exchanging only a constant amount of information on-chain regardless of the number of signatures exchanged. We demonstrate how to construct a batch adaptor signature scheme using FSE, and our FSE construction based on Schnorr results in an efficient implementation of a batch Schnorr adaptor signature scheme for the discrete logarithm problem. We implemented our scheme to show that it has negligible overhead compared to standard Schnorr signatures. For instance, exchanging $2^{10}$ signatures on the Vesta curve takes approximately $80$ms for the signer and $300$ms for the verifier, with almost no overhead for the signer and $2$x overhead for the verifier compared to the original Schnorr protocol. Additionally, we propose an extension to blind signature exchange, where the signer does not learn the messages being signed. This is achieved through a natural adaptation of blinded Schnorr signatures.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 14:19:54 +0000</pubDate>
</item>
<item>
<title>$\mathsf{Cougar}$: Cubic Root Verifier Inner Product Argument under Discrete Logarithm Assumption</title>
<link>https://eprint.iacr.org/2024/616</link>
<guid>https://eprint.iacr.org/2024/616</guid>
<content:encoded><![CDATA[
<div> 关键词：内心积论证（IPA），$\mathsf{Cougar}$，零知识证明，立方根验证器，离散对数假设

总结：

本文提出了一种新的高效内心积论证（IPA）——$\mathsf{Cougar}$，它旨在克服基于离散对数假设下平方根复杂度的限制。$\mathsf{Cougar}$的特点包括立方根验证器和在通信复杂性上的对数级别性能。为了实现这一目标，我们结合了Kim等人在Asiacrypt2022上提出的两个基于离散对数假设的平方根验证器IPA，即使用配对的$\mathsf{Protocol3}$（后来被称为$\mathsf{Leopard}$）和不使用配对的$\mathsf{Protocol4}$。通过重新构建$\mathsf{Protocol4}$并使其与同态承诺方案的证明系统兼容，再利用$\mathsf{Protocol3}$作为其证明系统。此外，为了解决$\mathsf{Protocol4}$中出现的椭圆曲线点之间的关系证明问题，我们引入了一个基于$\mathsf{Plonkish}$的新证明系统，该系统配备了混合椭圆曲线加法的定制门电路。我们证明了$\mathsf{Cougar}$确实满足所声称的所有特性，并在离散对数假设下提供了完整性的证明。此外，我们使用Rust实现了$\mathsf{Cougar}$，结果显示当见证长度$N=2^{20}$时，其验证时间仅为0.346秒，相比其他基于离散对数假设和透明设置的IPA（如BulletProofs和$\mathsf{Leopard}$）有显著速度提升，具体来说，比BulletProofs快约50倍。 <div>
An inner product argument (IPA) is a cryptographic primitive used to construct a zero-knowledge proof system, which is a notable privacy-enhancing technology. We propose a novel efficient IPA called $\mathsf{Cougar}$. $\mathsf{Cougar}$ features cubic root verifier and logarithmic communication under the discrete logarithm (DL) assumption. At Asiacrypt2022, Kim et al. proposed two square root verifier IPAs under the DL assumption. Our main objective is to overcome the limitation of square root complexity in the DL setting. To achieve this, we combine two distinct square root IPAs from Kim et al.: one with pairing ($\mathsf{Protocol3}$; one was later named $\mathsf{Leopard}$) and one without pairing ($\mathsf{Protocol4}$). To construct $\mathsf{Cougar}$, we first revisit $\mathsf{Protocol4}$ and reconstruct it to make it compatible with the proof system for the homomorphic commitment scheme. Next, we utilize $\mathsf{Protocol3}$ as the proof system for the reconstructed $\mathsf{Protocol4}$. Finally, to facilitate proving the relation between elliptic curve points appearing in $\mathsf{Protocol4}$, we introduce a novel $\mathsf{Plonkish}$-based proof system equipped with custom gates for mixed elliptic curve addition. We show that $\mathsf{Cougar}$ indeed satisfies all the claimed features, along with providing a soundness proof under the DL assumption. In addition, we implemented $\mathsf{Cougar}$ in Rust, demonstrating that the verification time of $\mathsf{Cougar}$ increases much slowly as the length of the witness $N$ grows, compared to other IPAs under the DL assumption and transparatent setup: BulletProofs and $\mathsf{Leopard}$. Concretely, $\mathsf{Cougar}$ takes 0.346s for verification in our setting when $N = 2^{20}$, which is a $50\times$ speed-up from BulletProofs.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:48:25 +0000</pubDate>
</item>
<item>
<title>Foundations of Data Availability Sampling</title>
<link>https://eprint.iacr.org/2023/1079</link>
<guid>https://eprint.iacr.org/2023/1079</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据可用性采样(DAS), 以太坊, 密码学研究, 消息认证码, 抵抗删除编码<br /><br />总结:<br />
本文针对数据可用性采样（DAS）这一用于提升区块链可扩展性的技术展开了密码学研究。DAS允许网络参与者确保数据完全可用，而无需任何一方完全下载。鉴于DAS在实践中受到广泛关注，但目前尚无其正式定义、安全概念和安全证明，文章首先对DAS进行了精确的密码学原始定义。接着，文章通过定义一种新型的消息认证码，该认证码自然地推广了向量承诺和多项式承诺，展示了DAS与擦除编码的关系。文中分析并证明了现有构造的安全性，并提出了基于更弱假设、计算效率更高且不依赖可信设置的新构造，尽管通信复杂度略有增加。最后，文章评估了不同构造之间的权衡。 <div>
Towards building more scalable blockchains, an approach known as data availability sampling (DAS) has emerged over the past few years. 
Even large blockchains like Ethereum are planning to eventually deploy DAS to improve their scalability.
In a nutshell, DAS allows the participants of a network to ensure the full availability of some data without any one participant downloading it entirely.
Despite the significant practical interest that DAS has received, there are currently no formal definitions for this primitive, no security notions, and no security proofs for any candidate constructions.
For a cryptographic primitive that may end up being widely deployed in large real-world systems, this is a rather unsatisfactory state of affairs.

In this work, we initiate a cryptographic study of data availability sampling.
To this end, we define data availability sampling precisely as a clean cryptographic primitive.
Then, we show how data availability sampling relates to erasure codes.
We do so by defining a new type of commitment schemes which naturally generalizes vector commitments and polynomial commitments.
Using our framework, we analyze existing constructions and prove them secure.
In addition, we give new constructions which are based on weaker assumptions, computationally more efficient, and do not rely on a trusted setup, at the cost of slightly larger communication complexity.
Finally, we evaluate the trade-offs of the different constructions.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 10:50:30 +0000</pubDate>
</item>
<item>
<title>REED: Chiplet-Based  Accelerator for Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2023/1190</link>
<guid>https://eprint.iacr.org/2023/1190</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密（FHE）、ASIC加速器、多芯片模块化、REED、性能提升

总结:<br />
本文提出了一种名为REED的创新性多芯片模块化全同态加密（FHE）加速器，旨在解决现有单片式（monolithic）ASIC FHE加速器所面临的挑战，如不灵活性、低良率和高昂制造成本。REED采用了可扩展的芯片设计方法、有效的负载分布框架、定制化的跨芯片通信策略以及优化的管道数论变换和自同构设计以提升性能。实验结果显示，基于7纳米技术的REED 2.5D微处理器面积为96.7mm²，平均功率消耗为49.4W，相比于24核双倍英特尔X5690 CPU，其运行速度提高了约2991倍，性能提升了1.9倍，并且相较于最先进的ASIC FHE加速器，开发成本降低了50%。此外，文中还首次展示了对加密深度神经网络（DNN）训练的基准测试。总体而言，REED架构设计为加速FHE提供了极具实效性的解决方案，显著推进了FHE在现实世界应用中的实用性和部署可行性。 <div>
Fully Homomorphic Encryption (FHE) enables privacy-preserving computation and has many applications. However, its practical implementation faces massive computation and memory overheads. To address this bottleneck, several Application-Specific Integrated Circuit (ASIC) FHE accelerators have been proposed. All these prior works put every component needed for FHE onto one chip (monolithic), hence offering high performance. However, they encounter common challenges associated with large-scale chip design, such as inflexibility, low yield, and high  manufacturing costs. In this paper, we present the first-of-its-kind multi-chiplet-based FHE accelerator ‘REED’ for overcoming the limitations of prior monolithic designs. To utilize the advantages of multi-chiplet structures while matching the performance of larger monolithic systems, we propose and implement several novel strategies in the context of FHE. These include a scalable chiplet design approach, an effective framework for workload distribution, a custom inter-chiplet communication strategy, and advanced pipelined Number Theoretic Transform and automorphism design to enhance performance.

Our instruction-set and power simulations experiments with a prelayout netlist indicate that REED 2.5D microprocessor consumes 96.7mm2 chip area, 49.4 W average power in 7nm technology. It could achieve a remarkable speedup of up to 2,991× compared to a CPU (24-core 2×Intel X5690) and offer 1.9× better performance, along with a 50% reduction in development costs when compared to state-of-the-art ASIC FHE accelerators. Furthermore, our work presents the first instance of benchmarking an encrypted deep neural network (DNN) training. Overall, the REED architecture design offers a highly effective solution for accelerating FHE, thereby significantly  advancing the practicality and deployability of FHE in real-world applications.
]]></content:encoded>
<pubDate>Fri, 04 Aug 2023 05:21:11 +0000</pubDate>
</item>
<item>
<title>BlindPerm: Efficient MEV Mitigation with an Encrypted Mempool and Permutation</title>
<link>https://eprint.iacr.org/2023/1061</link>
<guid>https://eprint.iacr.org/2023/1061</guid>
<content:encoded><![CDATA[
<div> 关键词: 最大可提取价值(MEV)、随机化置换、交易排序、权益证明(PoS)委员会共识、盲化置换(BlindPerm)

总结:
针对最大可提取价值(MEV)带来的负面影响，本文提出了利用随机化置换对已提交区块内的交易顺序进行混淆的技术方案。现有基于加密mempool的方法对于防止区块生产者的攻击并不充分，而可以通过结合置换技术实现多层保护的扩展。文章重点关注PoS委员会共识机制，并介绍了名为BlindPerm的框架，该框架通过在加密mempool基础上添加置换功能并提出一系列优化措施。其中，我们设计了一个协议，使得这一增强功能几乎无需额外开销，可通过借用现有的加密mempool实现。此外，还探讨了如何将此防御技术扩展到工作量证明(PoW)最长链共识中。最后，通过对历史以太坊数据运行模拟实验，展示了我们的解决方案在防范套利和夹心攻击两种主要类型的MEV提取方面的有效性。 <div>
To mitigate the negative effects of the maximal extractable value (MEV), we propose techniques that utilize randomized permutation to shuffle the order of transactions in a committed block before execution. We argue that existing approaches based on encrypted mempools cannot provide sufficient mitigation, particularly against block producer, and can be extended by permutation-based techniques to provide multi-layer protection. With a focus on PoS committee-based consensus we then introduce BlindPerm, a framework enhancing an encrypted mempool with permutation and present various optimizations. Notably, we propose a protocol where this enhancement comes at essentially no overheads by piggybacking on the encrypted mempool. Further, we demonstrate how to extend our mitigation technique to support PoW longest-chain consensus. Finally, we illustrate the effectiveness of our solutions on arbitrage and sandwich attacks as the two main types of MEV extraction through running simulations using historical Ethereum data.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 05:47:52 +0000</pubDate>
</item>
<item>
<title>On the Privacy of Sublinear-Communication Jaccard Index Estimation via Min-hash Sketching</title>
<link>https://eprint.iacr.org/2023/1523</link>
<guid>https://eprint.iacr.org/2023/1523</guid>
<content:encoded><![CDATA[
<div> 关键词：min-hash sketch、differential privacy (DP)、distributional differential privacy (DDP)、random oracle模型、两方计算协议

总结:<br />
本文研究了min-hash草图在保护输入数据隐私方面的效果。首先，在集中式设置中，当hash函数由min-hash功能选择且对参与者未知的情况下，证明min-hash输出满足标准的差分隐私（DP）定义，无需额外噪声。这进而导出了基于全同态加密（FHE）的低通信量、半诚实型两方计算协议。为了提高效率，文章考虑在随机预言机模型下实现，参与者共同采样公开前缀以进行随机预言机的域分离，并在其输入集上局部评估生成的hash函数。然而，在这种公共hash函数场景下，min-hash输出不再满足DP。因此，文章转向探讨Bassily等人在FOCS 2013提出的分布式差分隐私（DDP）。若诚实方的集合具有足够高的最小熵，则min-hash功能的输出可以实现DDP，同样无需添加噪声。这导致了一个在随机预言机模型下的更高效半诚实两方计算协议，双方首先本地哈希其输入集，然后执行两方计算进行比较。通过证明这些协议分别满足DP和DDP，本文正式确认并界定了关于min-hash协议能够保护其输入隐私的民间观点。 <div>
The min-hash sketch is a well-known technique for low-communication approximation of the Jaccard index between two input sets.  Moreover, there is a folklore belief that min-hash sketch based protocols protect the privacy of the inputs.  In this paper, we investigate this folklore to quantify the privacy of the min-hash sketch.

We begin our investigation by considering the privacy of min-hash in a centralized setting where the hash functions are chosen by the min-hash functionality and are unknown to the participants.  We show that in this case the min-hash output satisfies the standard definition of differential privacy (DP) without any additional noise.  This immediately yields a privacy-preserving sublinear-communication semi-honest 2-PC protocol based on FHE where the hash function is evaluated homomorphically.

To improve the efficiency of this protocol, we next consider an implementation in the random oracle model. Here, the protocol participants jointly sample public prefixes for domain separation of the random oracle, and locally evaluate the resulting hash functions on their input sets.  Unfortunately, we show that in this public hash function setting, the min-hash output is no longer DP.  We therefore consider the notion of distributional differential privacy (DDP) introduced by Bassily et al.(FOCS 2013). We show that if the honest party's set has sufficiently high min-entropy then the output of the min-hash functionality achieves DDP, again without any added noise. This yields a more efficient semi-honest two-party protocol in the random oracle model, where parties first locally hash their input sets and then perform a 2PC for comparison.
    
By proving that our protocols satisfy DP and DDP respectively, our results formally confirm and qualify the folklore belief that min-hash based protocols protect the privacy of their inputs.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 10:02:12 +0000</pubDate>
</item>
<item>
<title>Trustless Bridges via Random Sampling Light Clients</title>
<link>https://eprint.iacr.org/2025/057</link>
<guid>https://eprint.iacr.org/2025/057</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、互操作性、去中心化、随机采样、Byzantine Fault Tolerance (BFT)

总结:
本文提出了一种名为Bridge Protocol的去中心化、高效的区块链互操作性解决方案，该方案依赖于相连的两个链的拜占庭容错（BFT）机制，不需要额外的信任假设。其中，消息交换中介者（即中继器）为无权限和去中心化的，消除了单点故障风险。文章引入了随机采样这一创新技术，使得基于PoS的区块链的轻客户端能更高效地追踪历史记录，减少了所需的签名验证次数。随机数通过以太坊的RANDAO等手段在链上生成。从加密经济学角度分析了桥接协议的安全性，并提供了确定安全性参数的框架，包括处理并发问题和原始设计中的随机性偏差。虽然此协议可应用于多种PoS链，但文中通过实例展示了在Polkadot与Ethereum之间建立桥梁（目前已部署）的可行性，并讨论了一些实际安全挑战。此外，还评估了在以太坊智能合约中实现的基于链上轻客户端验证器的效率（ Gas成本），相比于SNARK基方法，即使在大的验证者集合规模（高达$10^6$）下，其签名验证Gas成本也要低一个数量级。 <div>
The increasing number of blockchain projects introduced annually has led to a pressing need for secure and efficient interoperability solutions. Currently, the lack of such solutions forces end-users to rely on centralized intermediaries, contradicting the core principle of decentralization and trust minimization in blockchain technology. In this paper, we propose a decentralized and efficient interoperability solution (aka Bridge Protocol) that operates without additional trust assumptions, relying solely on the Byzantine Fault Tolerance (BFT) of the two chains being connected. In particular, relayers (actors that exchange messages between networks) are permissionless and decentralized, hence eliminating any single point of failure. We introduce Random Sampling, a novel technique for on-chain light clients to efficiently follow the history of PoS blockchains by reducing the signature verifications required. Here, the randomness is drawn on-chain, for example, using Ethereum's RANDAO. We analyze the security of the bridge from a crypto- economic perspective and provide a framework to derive the security parameters. This includes handling subtle concurrency issues and randomness bias in strawman designs. While the protocol is applicable to various PoS chains, we demonstrate its feasibility by instantiating a bridge between Polkadot and Ethereum (currently deployed), and discuss some practical security challenges. We also evaluate the efficiency (gas costs) of an on-chain light-client verifier implemented as a smart contract on ethereum against SNARK-based approaches. Even for large validator set sizes (up to $10^6$), the signature verification gas costs of our light-client verifier are a magnitude lower.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 11:06:33 +0000</pubDate>
</item>
<item>
<title>Hash-Based Multi-Signatures for Post-Quantum Ethereum</title>
<link>https://eprint.iacr.org/2025/055</link>
<guid>https://eprint.iacr.org/2025/055</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算机、以太坊、非交互式多签名、BLS签名、哈希基础签名方案

总结:<br />
随着量子计算机带来的威胁，以太坊等系统需要转向抵抗量子攻击的加密原语。文章关注的是非交互式多签名方案，该方案在以太坊权益证明共识中使用了BLS签名。为了提供后量子时代的替代方案，文章引入了一种基于哈希的签名方案家族，作为对BLS签名的补充。研究内容包括利用（哈希基础）简洁论证方法聚合签名，并专注于实现底层签名方案，其中提出了XMSS签名方案的变体。作者建立了一个新颖且统一的框架来分析这些方案，旨在最小化安全性损失并优化参数选择。本文关键特点在于避免在安全性证明中使用随机预言机，而是为底层哈希函数定义明确的标准模型要求。这解决了将哈希函数同时视为随机预言机和聚合明确电路的悖论，并为密码分析人员提供了评估哈希函数安全性时清晰的目标。此外，文章还提供了关于哈希函数实用实例及具体参数设置的建议，并支持已知和新提出的关于标准模型属性的启发式边界。 <div>
With the threat posed by quantum computers on the horizon, systems like Ethereum must transition to cryptographic primitives resistant to quantum attacks. One of the most critical of these primitives is the non-interactive multi-signature scheme used in Ethereum's proof-of-stake consensus, currently implemented with BLS signatures. This primitive enables validators to independently sign blocks, with their signatures then publicly aggregated into a compact aggregate signature.

In this work, we introduce a family of hash-based signature schemes as post-quantum alternatives to BLS. We consider the folklore method of aggregating signatures via (hash-based) succinct arguments, and our work is focused on instantiating the underlying signature scheme. The proposed schemes are variants of the XMSS signature scheme, analyzed within a novel and unified framework. While being generic, this framework is designed to minimize security loss, facilitating efficient parameter selection. A key feature of our work is the avoidance of random oracles in the security proof. Instead, we define explicit standard model requirements for the underlying hash functions. This eliminates the paradox of simultaneously treating hash functions as random oracles and as explicit circuits for aggregation. Furthermore, this provides cryptanalysts with clearly defined targets for evaluating the security of hash functions. Finally, we provide recommendations for practical instantiations of hash functions and concrete parameter settings, supported by known and novel heuristic bounds on the standard model properties.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 09:35:50 +0000</pubDate>
</item>
<item>
<title>Doubly Efficient Fuzzy Private Set Intersection  for High-dimensional Data with Cosine Similarity</title>
<link>https://eprint.iacr.org/2025/054</link>
<guid>https://eprint.iacr.org/2025/054</guid>
<content:encoded><![CDATA[
<div> 关键词: Fuzzy PSI、高维数据、通信成本、计算复杂性、余弦相似性

总结:
本文提出了一种新的模糊私人集合交集(Fuzzy PSI)协议——FPHE，该协议针对余弦相似性的隐私保护匹配问题进行了优化。FPHE克服了现有方法在处理高维数据时面临的通信和计算成本指数级增加的问题，实现了线性的时间和通信复杂度。此外，FPHE不再依赖于特定的数据分布假设，并引入了一种创新的证明技术，平衡了近似比较函数中的误差与噪声填充，确保了协议在半诚实模型下的安全性。FPHE还可以扩展支持如标签或电路模糊PSI等不同功能。实验结果显示，FPHE能够在几分钟内对512维数据执行模糊PSI操作，这是此前同类方案难以实现的。 <div>
Fuzzy private set intersection (Fuzzy PSI) is a cryptographic protocol for privacy-preserving similarity matching, which is one of the essential operations in various real-world applications such as facial authentication, information retrieval, or recommendation systems. Despite recent advancements in fuzzy PSI protocols, still a huge barrier remains in deploying them for these applications. The main obstacle is the high dimensionality, e.g., from 128 to 512, of data; lots of existing methods, Garimella et al. (CRYPTO’23, CRYPTO’24) or van Baarsen et al. (EUROCRYPT’24), suffer from exponential overhead on communication and/or computation cost. In addition, the dominant similarity metric in these applications is cosine similarity, which disables several optimization tricks based on assumptions for the distribution of data, e.g., techniques by Gao et al. (ASIACRYPT’24). In this paper, we propose a novel fuzzy PSI protocol for cosine similarity, called FPHE, that overcomes these limitations at the same time. FPHE features linear complexity on both computation and communication with respect to the dimension of set elements, only requiring much weaker assumption than prior works. The basic strategy of ours is to homomorphically compute cosine similarity and run an approximated comparison function, with a clever packing method for efficiency. In addition, we introduce a novel proof technique to harmonize the approximation error from the sign function with the noise flooding, proving the security of FPHE under the semi-honest model. Moreover, we show that our construction can be extended to support various functionalities, such as labeled or circuit fuzzy PSI. Through experiments, we show that FPHE can perform fuzzy PSI over 512-dimensional data in a few minutes, which was computationally infeasible for all previous proposals under the same assumption as ours.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 05:49:19 +0000</pubDate>
</item>
<item>
<title>More Efficient Lattice-Based Electronic Voting from NTRU</title>
<link>https://eprint.iacr.org/2023/933</link>
<guid>https://eprint.iacr.org/2023/933</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、lattice假设、电子投票、RLWE、NTRU

总结：
本文提出了一种基于量子安全的lattice问题（RLWE和NTRU）的电子投票方案，该方案在实现上更为高效，与现有最佳的lattice基投票方案相比，实现了5.3倍的密文大小减小、2.5倍的总通信成本降低以及2倍的总计算时间减少。本设计特别关注了加密隐私性和过程可验证性，以确保在面对量子计算机威胁时的安全性。此外，通过使用非三元NTRU秘密来优化参数，文中还扩展了Ducas和van Woerden关于NTRU的工作，确定了对于任意秘密的NTRU具体疲劳点公式，这对于理解参数安全性及改进del Pino和Katsumata提出的部分盲签名方案具有重要意义。 <div>
In recent years, there has been much focus on developing core cryptographic primitives based on lattice assumptions, driven by the NIST call for post-quantum key encapsulation and digital signature algorithms. However, more work must be conducted on efficient privacy-preserving protocols based on quantum-safe assumptions.

Electronic voting is one such privacy-preserving protocol whose adoption is increasing across the democratic world. E-voting offers both a fast and convenient alternative to postal voting whilst further ensuring cryptographic privacy of votes and offering full verifiability of the process. Owing to the sensitivity of voting and its infrastructure challenges, it is crucial to ensure security against quantum computers is baked into e-voting solutions.

We present an e-voting scheme from quantum-safe assumptions based on the hardness of the RLWE and NTRU lattice problems, providing concrete parameters and an efficient implementation. Our design achieves a factor $5.3 \times$ reduction in ciphertext size, $2.5 \times$ reduction in total communication cost, and $2 \times$ reduction in total computation time compared to the state-of-the-art lattice-based voting scheme by Aranha et al. (ACM CCS 2023). We argue that the efficiency of this scheme makes it suitable for real-world elections.

Our scheme makes use of non-ternary NTRU secrets to achieve optimal parameters. In order to compute the security of our design, we extend the ternary-NTRU work of Ducas and van Woerden (ASIACRYPT 2021) by determining the concrete fatigue point (for general secrets) of NTRU to be $q = 0.0058 \cdot \sigma^2 \cdot d^{2.484}$ (above which parameters become overstretched) for modulus $q$, ring dimension $d$, and secrets drawn from a Gaussian of parameter $\sigma$. We consider this relation to be of independent interest and demonstrate its significance by improving the efficiency of the (partially) blind signature scheme by del Pino and Katsumata (CRYPTO 2022).
]]></content:encoded>
<pubDate>Wed, 14 Jun 2023 21:23:33 +0000</pubDate>
</item>
<item>
<title>Keyed-Verification Anonymous Credentials with Highly Efficient Partial Disclosure</title>
<link>https://eprint.iacr.org/2025/041</link>
<guid>https://eprint.iacr.org/2025/041</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名凭证（AC）、部分披露、键控验证AC（KVAC）、零知识证明、常量大小

总结:
本文提出两种高效的关键控验证匿名凭证（KVAC）系统构造方案，这两个方案消除了凭证展示阶段对计算昂贵的零知识证明的需求，并实现了常量大小的展示。第一个方案基于Fuchsbauer等人在公开可验证设置中实现常量大小凭证展示的工作，引入了结构保持的消息认证码在等价类（SP-MAC-EQ）和指定验签者集合承诺（DVSC），从而得到一种具有常量大小凭证（2组元素）和展示（4组元素）的KVAC系统。第二个方案采用同态MAC和简化DVSC，虽牺牲了常量大小的凭证（$n+2$组元素，其中$n$为属性数量），但保持了常量大小的展示（2组元素），并适应于无配对环境。文章对两个构造的安全性进行了正式证明，并提供了开源实现结果以证明其实用性。此外，还对所提出的SP-MAC-EQ方案与原始的SPS-EQ方案进行了效率基准测试，显示出显著的性能提升。 <div>
An anonymous credential (AC) system with partial disclosure allows users to prove possession of a credential issued by an issuer while selectively disclosing a subset of their attributes to a verifier in a privacy-preserving manner. In keyed-verification AC (KVAC) systems, the issuer and verifier share a secret key. Existing KVAC schemes rely on computationally expensive zero-knowledge proofs during credential presentation, with the presentation size growing linearly with the number of attributes. In this work, we propose two highly efficient KVAC constructions that eliminate the need for zero-knowledge proofs during the credential presentation and achieve constant-size presentations.
    Our first construction adapts the approach of Fuchsbauer et al. (JoC'19), which achieved constant-size credential presentation in a publicly verifiable setting using their proposed structure-preserving signatures on equivalence classes (SPS-EQ) and set commitment schemes, to the KVAC setting. We introduce structure-preserving message authentication codes on equivalence classes (SP-MAC-EQ) and designated-verifier set commitments (DVSC), resulting in a KVAC system with constant-size credentials (2 group elements) and presentations (4 group elements). To avoid the bilinear groups and pairing operations required by SP-MAC-EQ, our second construction uses a homomorphic MAC with a simplified DVSC. While this sacrifices constant-size credentials ($n+2$ group elements, where $n$ is the number of attributes), it retains constant-size presentations (2 group elements) in a pairingless setting. 
    We formally prove the security of both constructions and provide open-source implementation results demonstrating their practicality. We extensively benchmarked our KVAC protocols and, additionally, bechmarked the efficiency of our SP-MAC-EQ scheme against the original SPS-EQ scheme, showcasing significant performance improvements.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 18:08:39 +0000</pubDate>
</item>
<item>
<title>VDORAM: Towards a Random Access Machine with Both Public Verifiability and Distributed Obliviousness</title>
<link>https://eprint.iacr.org/2025/039</link>
<guid>https://eprint.iacr.org/2025/039</guid>
<content:encoded><![CDATA[
<div> 关键词：可验证随机访问机器(vRAM)、分布式无意识RAM (VDORAM)、多证明者零知识证明(ZKP)、公开可验证多方计算(MPC)协议、ComptCircuit

总结:
本文介绍了为解决复杂计算中具有可证明安全性的问题而提出的可验证随机访问机器（vRAM）。然而，现有的vRAM并未实现分布式无意识性，这在涉及多个证明者防止信息泄露给其他证明者和验证者的场景中至关重要。文章提出了两大挑战：缺乏先进的公开可验证多方计算（MPC）协议和多证明者ZKP的前端实现。针对这些问题，文中引入了名为CompatCircuit的创新方案，它是首个具备协同zkSNARKs功能的多证明者ZKP前端实现，能支持构建具有丰富功能的公开可验证MPC协议。基于CompatCircuit，文章构建了首个公开可验证的分布式无意识RAM（VDORAM），通过结合分布式无意识架构与可验证RAM，实现了在通信开销和证明生成时间之间的高效RAM设计。作者实现了大约15,000行代码的CompatCircuit和VDORAM，并展示了其实用性和效率，性能评估结果显示系统在提供分布式无意识性的同时仍保持着适度的性能。 <div>
Verifiable random access machines (vRAMs) serve as a foundational model for expressing complex computations with provable security guarantees, serving applications in areas such as secure electronic voting, financial auditing, and privacy-preserving smart contracts. However, no existing vRAM provides distributed obliviousness, a critical need in scenarios where multiple provers seek to prevent disclosure against both other provers and the verifiers.
Implementing a publicly verifiable distributed oblivious RAM (VDORAM) presents several challenges. Firstly, the development of VDORAM is hindered by the limited availability of sophisticated publicly verifiable multi-party computation (MPC) protocols. Secondly, the lack of readily available front-end implementations for multi-prover zero-knowledge proofs (ZKPs) poses a significant obstacle to developing practical applications. Finally, directly adapting existing RAM designs to the VDORAM paradigm may prove either impractical or inefficient due to the inherent complexities of reconciling oblivious computation with the generation of publicly verifiable proofs.

To address these challenges, we introduce CompatCircuit, the first multi-prover ZKP front-end implementation to our knowledge. CompatCircuit integrates collaborative zkSNARKs to implement publicly verifiable MPC protocols with rich functionalities beyond those of an arithmetic circuit, enabling the development of multi-prover ZKP applications. Building upon CompatCircuit, we present VDORAM, the first publicly verifiable distributed oblivious RAM. By combining distributed oblivious architectures with verifiable RAM, VDORAM achieves an efficient RAM design that balances communication overhead and proof generation time. We have implemented CompatCircuit and VDORAM in approximately 15,000 lines of code, demonstrating usability by providing a practical and efficient implementation. Our performance evaluation result reveals that the system still provides moderate performance with distributed obliviousness.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 10:50:58 +0000</pubDate>
</item>
<item>
<title>Cauchyproofs: Batch-Updatable Vector Commitment with Easy Aggregation and Application to Stateless Blockchains</title>
<link>https://eprint.iacr.org/2025/038</link>
<guid>https://eprint.iacr.org/2025/038</guid>
<content:encoded><![CDATA[
<div> 关键词: Stateless区块链、Cauchyproofs、批量可更新向量承诺、KZG方案、历史证明查询算法

总结:

本文介绍了Cauchyproofs，这是一种用于状态less区块链设计的批量可更新向量承诺方案，旨在解决随着用户和交易数量增加而带来的证明更新计算资源需求大的问题。Cauchyproofs利用优化的KZG方案，将更新证明的时间复杂度降低至$O\left(\left(\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|\right) \log^2 (\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|)\right)$，相比之前的$O\left(\left|\vec{\alpha}\right|\cdot|\vec{\beta}|\right)$方法有显著提升，从而减轻了证明服务节点的计算负担并提高了大用户群体中证明维护的效率。实验表明，这种方法在以太坊级别的区块大小下，比原始方法快约五倍。此外，文章还提出了一种基于Cauchy矩阵的KZG证明新型矩阵表示法，能够减少椭圆曲线操作，加速所有证明的计算。最后，文中还提供了一个历史证明查询算法，支持高效的历史证明生成。这些贡献极大地提升了状态less区块链框架中证明服务节点的可扩展性和实用性。 <div>
Stateless blockchain designs have emerged to address the challenge of growing blockchain size by utilizing succinct global states. Previous works have developed vector commitments that support proof updates and aggregation to be used as such states. However, maintaining proofs for multiple users still demands significant computational resources, particularly in updating proofs with every transaction.  This paper introduces Cauchyproofs, a batch-updatable vector commitment enabling proof-serving nodes to efficiently update proofs in quasi-linear time relative to the number of users and transactions, utilizing an optimized KZG scheme to achieve complexity $O\left(\left(\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|\right) \log^2 (\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|)\right)$, compared to previous $O\left(\left|\vec{\alpha}\right|\cdot|\vec{\beta}|\right)$ approaches. This advancement reduces the computational burden on proof-serving nodes, allowing for efficient proof maintenance across large user groups. We demonstrate that our approach is approximately five times faster than the naive approach at the Ethereum-level block size. Additionally, we present a novel matrix representation for KZG proofs utilizing Cauchy matrices, enabling faster all-proof computations with reduced elliptic curve operations. Finally, we propose an algorithm for history proof query, supporting retrospective proof generation with high efficiency. Our contributions substantially enhance the scalability and practicality of proof-serving nodes in stateless blockchain frameworks.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 02:15:53 +0000</pubDate>
</item>
<item>
<title>Blink: An Optimal Proof of Proof-of-Work</title>
<link>https://eprint.iacr.org/2024/692</link>
<guid>https://eprint.iacr.org/2024/692</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、Proof-of-Work、区块链、Blink、安全性、资源消耗、零知识证明、可信设置、Bitcoin Backbone模型、评估、下载量

总结:<br />
本文介绍了Blink，这是首个无需可信设置的交互式、安全的$\mathcal{O}(1)$ PoW轻客户端。Blink可以应用于支付验证、启动引导以及跨链桥接等多个场景。相比于传统的线性资源消耗，近年来轻客户端的资源需求已逐步降低至$\mathcal{O}(\text{polylog}( \mathcal{C}))$和$\mathcal{O}(1)$，但后者的实现往往依赖于可信设置。而Blink则在不需可信设置的前提下实现了$\mathcal{O}(1)$的资源效率。文章证明了Blink在比特币背骨模型中的安全性，并对其证明大小进行了评估，结果显示，使用Blink只需下载1.6KB即可获取到比特币当前状态的承诺，相较于SPV（需要67.3MB）和基于零知识的轻客户端（需要197KB）显著降低了资源消耗。 <div>
Designing light clients to securely and efficiently read Proof-of-Work blockchains has been a foundational problem since the inception of blockchains. Nakamoto themselves, in the original Bitcoin paper, presented the first client protocol, i.e., the Simplified Payment Verification, which consumes an amount of bandwidth, computational, and storage resources that grows linearly in the system's lifetime $\mathcal{C}$.

Today, the blockchain ecosystem is more mature and presents a variety of applications and protocols deployed on-chain and, often, cross-chain. In this landscape, light clients have become the cornerstone of decentralized bridges, playing a pivotal role in the security and efficiency of cross-chain operations. 
These new use cases, combined with the growth of blockchains over time, raise the need for more minimalist clients, which further reduce the resource requirements and, when applicable, on-chain costs. 
Over the years, the light client resource consumption has been reduced from $\mathcal{O}( \mathcal{C})$ to $\mathcal{O}(\text{polylog}( \mathcal{C}))$, and then down to $\mathcal{O}(1)$ with zero-knowledge techniques at the cost of often assuming a trusted setup. 

In this paper, we present Blink, the first interactive provably secure $\mathcal{O}(1)$ PoW light client without trusted setup. Blink can be used for a variety of applications ranging from payment verification and bootstrapping, to bridges. 
We prove Blink secure in the Bitcoin Backbone model, and we evaluate its proof size demonstrating that, at the moment of writing, Blink obtains a commitment to the current state of Bitcoin by downloading only 1.6KB, instead of 67.3MB and 197KB for SPV and zk-based clients, respectively.
]]></content:encoded>
<pubDate>Mon, 06 May 2024 08:32:01 +0000</pubDate>
</item>
<item>
<title>Forking the RANDAO: Manipulating Ethereum's Distributed Randomness Beacon</title>
<link>https://eprint.iacr.org/2025/037</link>
<guid>https://eprint.iacr.org/2025/037</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-stake、distributed randomness beacons (DRBs)、RANDAO、forking attack、selfish mining

总结:
本文分析了以太坊共识机制中当前使用的分布式随机数生成器（RANDAO）的操纵性。尽管RANDAO具有高效率，但仍存在通过故意省略区块来操纵随机数生成的漏洞，即所谓的自私挖矿攻击。文章提出并评估了一种新的操纵策略——RANDAO分叉攻击，与自私挖矿不同的是，这种策略依赖于选择性地分叉诚实提议者的区块以最大化交易费收入和区块奖励。文章指出，分叉攻击比自私挖矿更具危害性，因为它加剧了验证者之间的不公平，并严重损害了区块链对普通用户的可靠性，导致已发布的区块频繁被分叉出去。同时，研究发现攻击者可以发起分叉而不损失槽位，并且这些损失会在后期得到充分补偿。实证测量表明，在以太坊主网上目前尚未发现这类攻击的统计显著痕迹。 <div>
Proof-of-stake consensus protocols often rely on distributed randomness beacons (DRBs) to generate randomness for leader selection. This work analyses the manipulability of Ethereum's DRB implementation, RANDAO, in its current consensus mechanism. Even with its efficiency, RANDAO remains vulnerable to manipulation through the deliberate omission of blocks from the canonical chain. Previous research has shown that economically rational players can withhold blocks --~known as a block withholding attack or selfish mixing~-- when the manipulated RANDAO outcome yields greater financial rewards.

We introduce and evaluate a new manipulation strategy, the RANDAO forking attack. Unlike block withholding, whereby validators opt to hide a block, this strategy relies on selectively forking out an honest proposer's block to maximize transaction fee revenues and block rewards. 
In this paper, we draw attention to the fact that the forking attack is significantly more harmful than selfish mixing for two reasons. Firstly, it exacerbates the unfairness among validators. More importantly, it significantly undermines the reliability of the blockchain for the average user by frequently causing already published blocks to be forked out. By doing so, the attacker can fork the chain without losing slots, and we demonstrate that these are later fully compensated for. Our empirical measurements, investigating such manipulations on Ethereum mainnet, revealed no statistically significant traces of these attacks to date.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 19:24:20 +0000</pubDate>
</item>
<item>
<title>Scalable Post-Quantum Oblivious Transfers for Resource-Constrained Receivers</title>
<link>https://eprint.iacr.org/2025/036</link>
<guid>https://eprint.iacr.org/2025/036</guid>
<content:encoded><![CDATA[
<div> 关键词: 原子转移、现代化、低功耗设备、Helix OT、Priority OT

总结:
本文提出两种可扩展的原子转移方案以适应现代数字时代对隐私保护计算的需求，尤其是在低功耗设备上的应用。这两种方案分别是：1-out-of-n 的 Helix OT 和 t-out-of-n 的 Priority OT，两者均具有无条件安全性，能抵抗量子攻击。Helix OT 实现了接收端下载复杂度为 O(1)，优化了大规模数据场景下的效率。针对有紧急或重要性区分的数据传输需求，Priority OT 则通过 O(t) 的接收端下载复杂度实现数据优先级传输，确保最重要数据优先接收，从而更有效地利用带宽、存储和处理资源。实验结果显示，Helix OT 在1秒内完成从 n=16,777,216 消息中选择1条的消息传输，而 Priority OT 可在30秒内处理 t=1,048,576 项选择任务，性能优于现有 t-out-of-n OT（当 t≥1 时）。据作者所知，Helix OT 和 Priority OT 均具备与以往方案不同的独特优势，适用于大规模应用场景。 <div>
It is imperative to modernize traditional core cryptographic primitives, such as Oblivious Transfer (OT), to address the demands of the new digital era, where privacy-preserving computations are executed on low-power devices. This modernization is not merely an enhancement but a necessity to ensure security, efficiency, and continued relevance in an ever-evolving technological landscape. 

This work introduces two scalable OT schemes: (1) Helix OT, a $1$-out-of-$n$ OT, and (2) Priority OT, a $t$-out-of-$n$ OT. Both schemes provide unconditional security, ensuring resilience against quantum adversaries. Helix OT achieves a receiver-side download complexity of $O(1)$. In big data scenarios, where certain data may be more urgent or valuable, we propose Priority OT. With a receiver-side download complexity of $O(t)$, this scheme allows data to be received based on specified priorities. By prioritizing data transmission, Priority OT ensures that the most important data is received first, optimizing bandwidth, storage, and processing resources.  Performance evaluations indicate that Helix OT completes the transfer of 1 out of $n=$ 16,777,216 messages in 9 seconds, and Priority OT handles $t=$ 1,048,576 out of $n$ selections in 30 seconds. Both outperform existing $t$-out-of-$n$ OTs (when $t\geq 1$), underscoring their suitability for large-scale applications. To the best of our knowledge, Helix OT and Priority OT introduce unique advancements that distinguish them from previous schemes.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 14:44:28 +0000</pubDate>
</item>
<item>
<title>A New Paradigm for Server-Aided MPC</title>
<link>https://eprint.iacr.org/2025/032</link>
<guid>https://eprint.iacr.org/2025/032</guid>
<content:encoded><![CDATA[
<div> 关键词：server-aided MPC、多党计算、安全性保证、信任假设、效率

总结:
该文提出了一个新的服务器辅助多党计算（MPC）模型，挑战了原有假设，即所有客户端必须选择相同的服务器和接受相同的腐败阈值。在这个新模型中，每个客户端可以选择自己的服务器集和自己的腐败阈值，并且只要满足其自身的阈值，就能保证其隐私安全，这一特性被称为“每党私有”服务器辅助MPC，兼顾了安全性和效率两方面保障：(1) 每党隐私，意味着每个参与方根据自身选择的服务器得到独立的隐私保护；(2) 每党复杂度，意味着每个参与方只需与其选定的服务器进行通信。文章的主要贡献是一个新的服务器辅助MPC理论框架，并给出了两个可行性协议，但将追求具体效率的协议留作未来工作。 <div>
The server-aided model for multiparty computation (MPC) was introduced to capture a real-world scenario where clients wish to off-load the heavy computation of MPC protocols to dedicated servers. A rich body of work has studied various trade-offs between security guarantees (e.g., semi-honest vs malicious),  trust assumptions (e.g., the threshold on corrupted servers), and efficiency. 

However, all existing works make the assumption that all clients must agree on employing the same servers, and accept the same corruption threshold. In this paper, we challenge this assumption and introduce a new paradigm for server-aided MPC, where each client can choose their own set of servers and their own threshold of corrupted servers. In this new model, the privacy of each client is guaranteed as long as their own threshold is satisfied, regardless of the other servers/clients. We call this paradigm per-party private server-aided MPC to highlight both a security and efficiency guarantee: (1) per-party privacy, which means that each party gets their own privacy guarantees that depend on their own choice of the servers; (2) per-party complexity, which means that each party only needs to communicate with their chosen servers. Our primary contribution is a new theoretical framework for server-aided MPC. We provide two protocols to show feasibility, but leave it as a future work to investigate protocols that focus on concrete efficiency.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 20:17:40 +0000</pubDate>
</item>
<item>
<title>Delegated Multi-party Private Set Intersection from Secret Sharing</title>
<link>https://eprint.iacr.org/2025/030</link>
<guid>https://eprint.iacr.org/2025/030</guid>
<content:encoded><![CDATA[
<div> 关键词: Delegated PSI (D-PSI)、云服务器、多党设置、安全、计算复杂性

总结:
本文探讨了委托私有集合交集(D-PSI)问题，其中引入云服务器处理大部分计算和通信任务。D-PSI允许用户安全地将私人集合委托给云端，同时保证数据隐私并有效计算交集。该云服务器在严格的安全要求下运行，不获取个体集合或交集结果的任何信息。此外，D-PSI减少了用户间的通信并支持“静默”处理，即除了集合委托和结果检索外，云可以独立执行计算。文章形式化定义了D-PSI问题，并提出一种创新构建方案，不仅适用于两方场景，还可扩展到多方设置。该方案满足对半诚实敌手的安全性要求，并实现了接近理想“完美”D-PSI协议的计算和通信复杂度。通过基准实现和优化版本，作者展示了其方法的实用性，进一步降低了计算开销，为现实世界云计算场景中安全高效的PSI奠定了坚实基础。 <div>
In this work, we address the problem of Delegated PSI (D-PSI), where a cloud server is introduced to handle most computational and communication tasks. D-PSI enables users to securely delegate their private sets to the cloud, ensuring the privacy of their data while allowing efficient computation of the intersection. The cloud operates under strict security requirements, learning nothing about the individual sets or the intersection result. Moreover, D-PSI minimizes user-to-user communication and supports "silent" processing, where the cloud can perform computations independently without user interaction, apart from set delegation and result retrieval.

We formally define the D-PSI problem and propose a novel construction that extends beyond two-party scenarios to support multi-party settings. Our construction adheres to the D-PSI requirements, including security against semi-honest adversaries, and achieves computational and communication complexities close to the ideal "perfect" D-PSI protocol. Additionally, we demonstrate the practicality of our approach through a baseline implementation and an optimized version that further reduces computational overhead. Our results establish a strong foundation for secure and efficient PSI in real-world cloud computing scenarios.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 11:35:17 +0000</pubDate>
</item>
<item>
<title>Highly Efficient Server-Aided Multiparty Subfield VOLE Distribution Protocol</title>
<link>https://eprint.iacr.org/2025/029</link>
<guid>https://eprint.iacr.org/2025/029</guid>
<content:encoded><![CDATA[
<div> 关键词：secure multi-party computation, pseudorandom correlations, subfield vector oblivious linear evaluation (sVOLE), three-party, four-party honest majority settings, trusted server, communication cost, memory storage, arbitrary length, utility rate, precomputability.

<br /><br />总结：
本文介绍了一种新的子域向量无意识线性评估（sVOLE）分布方法，该方法应用于三 party 和四 party 诚实多数设置中，借助可信服务器的帮助。新方法显著降低了随机 sVOLE 实例的通信成本和内存存储需求。同时，它还实现了一个流畅的分布流程，能够生成任意长度的 sVOLE 实例，从而在多维度的隐私保护计算协议中实现了随机 sVOLE 的100%效用率，同时保持了完整的预计算能力。 <div>
In recent development of secure multi-party computation (MPC), pseudorandom correlations of subfield vector oblivious linear evaluation (sVOLE) type become popular due to their amazing applicability in multi-dimensional MPC protocols such as privacy-preserving biometric identification and privacy-preserving machine learning protocols. In this paper, we introduce a novel way of VOLE distribution in three-party and four-party honest majority settings with the aid of a trusted server. This new method significantly decreases the communication cost and the memory storage of random sVOLE instances. On the other hand, it also enables a streamline distribution process that can generate a sVOLE instance of an arbitrary length, which results in 100 percent of utility rate of random sVOLE in multi-dimensional MPC protocols while preserving complete precomputability.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 09:01:56 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proofs for Set Membership: Efficient, Succinct, Modular</title>
<link>https://eprint.iacr.org/2019/1255</link>
<guid>https://eprint.iacr.org/2019/1255</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、集合成员资格、隐私保护、非成员资格证明、Pedersen承诺

总结:
本文关注的是在不泄露元素本身的情况下，利用零知识证明技术证明某个元素属于公开集合且满足特定属性的问题。文章设计了一种新的模块化和高效的方法，构建了基于承诺的集合并验证零知识系统，用于证明某值 $u$ 在公共承诺 $c_u$ 中属于集合 $S$。同时，该方法还支持非成员资格证明，即证明 $u$ 不属于集合 $S$。由于采用的是基于 Pedersen 承诺的方案，这些解决方案与诸如 Bulletproofs 或 Groth16 等流行系统兼容，可作为“$u \in S$ 并且 $P(u)$ 成立”这类复合声明中的即插即用模块。相较于之前的类似工作（如结合 zkSNARKs 和默克尔树的 Zcash 技术），实验表明，该方案提供了更高的灵活性，更短的公共参数以及对于大小为 $2^{64}$ 的集合，证明时间提升了 3.7 倍至 30 倍之多。此外，作者已将这些方案实现为软件库，并进行了性能测试。 <div>
We consider the problem of proving in zero knowledge that an element of a public set satisfies a given property without disclosing the element, i.e., for some $u$, ``$u \in S$ and $P(u)$ holds''. This problem arises in many applications (anonymous cryptocurrencies, credentials or whitelists) where, for privacy or anonymity reasons, it is crucial to hide certain data while ensuring properties of such data.
We design new \textit{modular} and \textit{efficient} constructions for this problem through new \textit{commit-and-prove zero-knowledge systems for set membership}, i.e. schemes proving  $u \in S$ for a value $u$ that is in a public commitment $c_u$. We also extend our results to support {\em non-membership proofs}, i.e. proving $u \notin S$.
Being commit-and-prove, our solutions can act as plug-and-play modules in statements of the form ``$u \in S$ and $P(u)$ holds'' by combining our set (non-)membership systems with any other commit-and-prove scheme for $P(u)$. Also, they work with Pedersen commitments over prime order groups which makes them compatible with popular systems such as Bulletproofs or Groth16.
We implemented our schemes as a software library, and tested experimentally their performance. Compared to previous work that achieves similar properties---the clever techniques combining zkSNARKs and Merkle Trees in Zcash---our solutions offer more flexibility, shorter public parameters and $3.7 \times$--$30\times$ faster proving time for a set of size $2^{64}$.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2019 08:28:02 +0000</pubDate>
</item>
<item>
<title>Blind accumulators for e-voting</title>
<link>https://eprint.iacr.org/2022/373</link>
<guid>https://eprint.iacr.org/2022/373</guid>
<content:encoded><![CDATA[
<div> 关键词: blind accumulator、电子投票系统、加密原语、匿名性、验证性

总结:
本文提出了一种新型加密原语——盲累积器，旨在构建电子投票系统。盲累积器能够以去中心化的方式收集合格选民的私钥，同时不获取这些私钥的信息。完成累积后，选民可以处理得到的累积器并导出与其先前添加的私钥对应的公钥。公钥的生成是确定性的，因此可以作为固定的选民伪名使用。选民利用所积累的私钥对选票进行签名，而对应的公钥则用于验证签名。由于公钥固定不变，易于实现可验证性，保护选民免受重复投票的影响，或者允许重复投票但仅计算最后一次提交的选票。文章提出了盲累积器的语法和安全要求，并将其嵌入到Pseudonymous Key Generation（PKG）协议中，详细描述了在接近实际电子投票场景中的应用。此外，文章还提出了一种类似于Diffie-Hellman协议的盲累积器方案实例，并证明了该实例的安全性。 <div>
We present a novel cryptographic primitive, blind accumulator, aimed at constructing e-voting systems. Blind accumulators collect private keys of eligible voters in a decentralized manner not getting information about the keys. Once the accumulation is complete, a voter processes the resulting accumulator and derives a public key which refers to a private key previously added by this voter. Public keys are derived deterministically and can therefore stand as fixed voter pseudonyms. The voter can prove that the derived key refers to some accumulated private key without revealing neither that key nor the voter itself. The voter uses the accumulated private key to sign a ballot. The corresponding public key is used to verify the signature. Since the public key is fixed, it is easy to achieve verifiability, to protect against multiple submissions of ballots by the same voter or, conversely, to allow multiple submissions but count only the last one. We suggest a syntax of blind accumulators and security requirements for them. We embed blind accumulators in the Pseudonymous Key Generation (PKG) protocol which details the use of accumulators in practical settings close to e-voting. We propose an instantiation of the blind accumulator scheme whose main computations resemble the Diffie-Hellman protocol. We justify the security of the proposed instantiation.
]]></content:encoded>
<pubDate>Tue, 22 Mar 2022 13:27:26 +0000</pubDate>
</item>
<item>
<title>Extending Groth16 for Disjunctive Statements</title>
<link>https://eprint.iacr.org/2025/028</link>
<guid>https://eprint.iacr.org/2025/028</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式零知识证明（NIZK）、$\Sigma$协议、zk-SNARK、组合证明、Groth16<br /><br />总结：
本文关注的是非交互式零知识证明（NIZK）中涉及代数和算术混合成分的析取性陈述问题。现有的zk-SNARK协议通常用于证明算术陈述，并与加密、承诺等代数密码学方案结合实现复杂应用。然而，对于包括代数和算术在内的复合陈述，直接扩展zk-SNARK电路会导致电路规模增大，证明时间和CRS大小变得不可行。文章提出了一种Groth16变体——CompGroth16，该框架允许Groth16证明包含代数和算术组件的析取性陈述。通过CompGroth16可以直接与其他$\Sigma$协议或自身进行逻辑组合，从而获得更广泛的表达能力、更高的证明者效率以及更短的CRS。此外，文中还针对CompGroth16与$\Sigma$协议的组合给出了两个具体的应用场景示例，展示了该构造的实际可行性。 <div>
Two most common ways to design non-interactive zero knowledge (NIZK) proofs are based on Sigma ($\Sigma$)-protocols (an efficient way to prove algebraic statements) and zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARK) protocols (an efficient way to prove arithmetic statements). However, in the applications of cryptocurrencies such as privacy-preserving credentials, privacy-preserving audits, and  blockchain-based voting systems, the zk-SNARKs for general statements are usually implemented with encryption, commitment, or other algebraic cryptographic schemes. Moreover, zk-SNARKs for many different arithmetic statements may also be required to be implemented together. Clearly, a typical solution is to extend the zk-SNARK circuit to include the code for algebraic part. However, complex cryptographic operations in the algebraic algorithms will significantly increase the circuit size, which leads to impractically large proving time and CRS size. Thus, we need a flexible enough proof system for composite statements including both algebraic and arithmetic statements. Unfortunately, while the conjunction of zk-SNARKs is relatively natural and numerous effective solutions are currently available (e.g. by utilizing the commit-and-prove technique), the disjunction of zk-SNARKs is rarely discussed in detail.
        In this paper, we mainly focus on the disjunctive statements of Groth16, and we propose a Groth16 variant---CompGroth16, which provides a framework for Groth16 to prove the disjunctive statements that consist of a mix of algebraic and arithmetic components. Specifically, we could directly combine CompGroth16 with $\Sigma$-protocol or even CompGroth16 with CompGroth16 just like the logical composition of $\Sigma$-protocols. From this, we can gain many good properties, such as broader expression, better prover's efficiency and shorter CRS. In addition, for the combination of CompGroth16 and $\Sigma$-protocol, we also present two representative application scenarios to demonstrate the practicality of our construction.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 07:38:47 +0000</pubDate>
</item>
<item>
<title>Quantum-resistant secret handshakes with dynamic joining, leaving, and banishment: GCD revisited</title>
<link>https://eprint.iacr.org/2025/024</link>
<guid>https://eprint.iacr.org/2025/024</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密握手、公平性、隐私保护、自区分性、叛徒捕捉

总结:
本文提出了一种对秘密握手协议的重要更新，增强了效率和隐私保障。该更新基于Tsudik和Xu的模块化框架，通过替换组签名原语为新的List MAC构造，实现了用户在握手会话中自我区分的能力，同时不泄露其身份，从而提供了更强的隐私保证。为了保持其他参与者的匿名性，引入了叛徒捕捉范式，握手记录仅揭示叛徒的身份。此外，文章展示了两个后量子时代的具体实现（基于哈希和基于 lattice 的），证明了新框架的灵活性和健壮性，并修正了以前的限制，为秘密握手中的隐私和安全设立了新的基准。 <div>
Secret handshakes, introduced by Balfanz et al. [3], allow users associated with various groups to determine if they share a common affiliation. These protocols ensure crucial properties such as fairness (all participants learn the result simultaneously), affiliation privacy (failed handshakes reveal no affiliation information), and result-hiding (even participants within a shared group cannot infer outcomes of unrelated handshakes). Over time, various secret-handshake schemes have been proposed, with a notable advancement being the modular framework by Tsudik and Xu. Their approach integrates three key components: group signature schemes, centralized secure channels for each group, and decentralized group key-agreement protocols.
Building upon this modularity, we propose significant updates. By addressing hidden complexities and revising the security model, we enhance both the efficiency and the privacy guarantees of the protocol. Specifically, we achieve the novel property of Self distinction—the ability to distinguish between two users in a session without revealing their identities—by replacing the group signature primitive with a new construct, the List MAC. This primitive is inherently untraceable, necessitating adjustments to the original syntax to support stronger privacy guarantees. Consequently, we introduce the Traitor Catching paradigm, where the transcript of a handshake reveals only the identity of a traitor, preserving the anonymity of all other participants.
To showcase the flexibility and robustness of our updated framework, we present two post-quantum instantiations (a hash-based one and another based on lattices). Our approach not only corrects prior limitations but also establishes a new benchmark for privacy and security in secret handshakes.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 09:13:51 +0000</pubDate>
</item>
<item>
<title>Foundations of Platform-Assisted Auctions</title>
<link>https://eprint.iacr.org/2025/019</link>
<guid>https://eprint.iacr.org/2025/019</guid>
<content:encoded><![CDATA[
<div> 关键词：平台辅助拍卖、加密货币、机制设计、多方计算、区块链

总结:
本文提出了一个新的模型来研究无许可环境下的平台辅助拍卖，探讨在这种情况下是否存在能够让买家、卖家、平台以及平台与买卖方联盟均选择诚实行为作为利益最大化的理想的拍卖方案。作者揭示了加密货币和机制设计之间的有趣联系，并展示如何利用加密技术设计具有理想属性的有效平台辅助拍卖。文章进一步分析了当服务提供者（如实现多方计算或区块链协议的节点）具备战略性的特点并可能与卖方或买方合谋时的游戏理论影响。此外，文中指出标准多方计算文献中采用的全模拟范式可能导致过高的成本，尤其是对于拍卖协议，因为每个玩家都有不同的私人结果，使用任何通用多方计算协议都将至少产生n²的总成本。为此，他们提出了一种新的模拟概念——“效用主导的模拟”，该模拟足以保证拍卖所需的游戏理论性质。在此基础上，他们展示了如何设计具有准线性效率的高效拍卖协议，相较于任何通用方法实现了n倍的成本改进。 <div>
Today, many auctions are carried out with the help of intermediary platforms like Google and eBay. These platforms serve as a  rendezvous point for the buyers and sellers, and charge a fee for its service. We refer to such auctions as platform-assisted auctions. Traditionally, the auction theory literature mainly focuses on designing auctions that incentivize the buyers to bid truthfully, assuming that the platform always faithfully implements the auction. In practice, however, the platforms have been found to   manipulate the auctions to earn more profit, resulting in high-profile anti-trust lawsuits. 

We propose a new model  for studying platform-assisted  auctions in the permissionless setting, where anyone can register and participate in the auction. We explore whether it is possible to design a dream auction in this new model, such that honest behavior  is the utility-maximizing strategy for each individual buyer, the platform, the seller, as well as platform-seller or platform-buyer coalitions. Through a collection of feasibility and infeasibility results, we carefully characterize the mathematical landscape of platform-assisted auctions. 

Interestingly, our work reveals exciting connections between cryptography and mechanism design. We show how cryptography can lend to the design of an efficient platform-assisted auction with dream properties. Although a line of works have also used multi-party computation (MPC) or the blockchain to remove the reliance on a trusted auctioneer, our work is distinct in nature in several dimensions. First, we initiate a systematic exploration of  the game theoretic implications when the service providers (e.g., nodes that implement the MPC or blockchain protocol) are strategic and can collude with sellers or buyers.  Second,  we observe that the full simulation paradigm used in the standard MPC literature is too stringent and leads to high asymptotical costs. Specifically,  because every player has a different private outcome in an auction protocol, to the best of our knowledge, running any generic MPC  protocol among the players would incur at least $n^2$ total cost  where $n$ is the number of buyers.We propose a new notion of simulation called {\it utility-dominated emulation} that is sufficient for guaranteeing the game-theoretic properties needed in an auction. Under this new notion of simulation, we show how to design efficient auction protocols with quasilinear efficiency, which gives an $n$-fold improvement over any generic approach.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 01:26:40 +0000</pubDate>
</item>
<item>
<title>Dynamically Available Common Subset</title>
<link>https://eprint.iacr.org/2025/016</link>
<guid>https://eprint.iacr.org/2025/016</guid>
<content:encoded><![CDATA[
<div> 关键词: 共识协议、区块链、临时故障、审查攻击、动态可用公共子集(DACS)

总结:
本文针对互联网规模的区块链共识协议提出了一个全新的原子广播协议，该协议在存在预期的临时故障（即睡眠模型）的情况下仍能保持运行，尤其适合对延迟敏感的金融应用。现有的领导者架构使这些协议容易受到短期审查攻击，允许提案者排除特定交易以获取利益。与传统方法不同，新协议不依赖于每个区块高度的单一提案者，而是采用了一种名为动态可用公共子集(DACS)的协议，这是在睡眠模型中的首创。此外，该构建还确保了确定性同步：一旦诚实节点确认一个区块，所有其他诚实节点将在常数时间内进行确认，从而解决了许多低延迟睡眠协议中存在的问题。 <div>
Internet-scale consensus protocols used by blockchains are designed to remain operational in the presence of unexpected temporary crash faults (the so-called sleepy model of consensus) -- a critical feature for the latency-sensitive financial applications running on these systems. 
However, their leader-based architecture, where a single block proposer is responsible for creating the block at each height, makes them vulnerable to short-term censorship attacks, in which the proposers profit at the application layer by excluding certain transactions. 
In this work, we introduce an atomic broadcast protocol, secure in the sleepy model, that ensures the inclusion of all transactions within a constant expected time, provided that at least one participating node is non-censoring at all times. 
Unlike traditional approaches, our protocol avoids designating a single proposer per block height, instead leveraging a so-called dynamically available common subset (DACS) protocol -- the first of its kind in the sleepy model. Additionally, our construction guarantees deterministic synchronization -- once an honest node confirms a block, all other honest nodes do so within a constant time, thus addressing a shortcoming of many low-latency sleepy protocols.
]]></content:encoded>
<pubDate>Sat, 04 Jan 2025 14:19:51 +0000</pubDate>
</item>
<item>
<title>SPY-PMU: Side-Channel Profiling of Your Performance Monitoring Unit to Leak Remote User Activity</title>
<link>https://eprint.iacr.org/2025/014</link>
<guid>https://eprint.iacr.org/2025/014</guid>
<content:encoded><![CDATA[
<div> 关键词: 性能监控单元(PMU), 边信道攻击, 微架构指纹, 机器学习(ML), 隐私泄露

总结:<br />
本文探讨了现代计算系统中普遍存在的性能监控单元（PMU）所带来的安全风险。通过利用PMU数据进行远程边信道攻击，揭示了能够侵犯用户隐私并实现远程隐秘监视的安全漏洞。研究团队通过对PMU特征空间分析，为基准应用创建独特的微架构指纹，并运用这些指纹构建机器学习（ML）模型以检测对应的基准应用。这种方法使得攻击者在远程访问受害者的PMU数据时，可以使用预训练模型准确识别受害者正在使用的应用程序。实验中，该预训练模型成功地通过远程PMU数据识别出受害者所使用的应用程序，证明了PMU数据用于远程侧信道分析的潜在恶意利用风险。研究人员针对stress-ng基准测试构建了逻辑回归、决策树、k近邻和随机森林等ML分类器模型，平均预测精度高达98%。这凸显了防范PMU数据远程侧信道攻击的紧迫性，并为未来微架构安全领域的研究奠定了基础。 <div>
The Performance Monitoring Unit (PMU), a standard feature in all modern computing systems, presents significant security risks by leaking sensitive user activities through microarchitectural event data. This work demonstrates the feasibility of remote side-channel attacks leveraging PMU data, revealing vulnerabilities that compromise user privacy and enable covert surveillance without physical access to the target machine. By analyzing the PMU feature space, we create distinct micro-architectural fingerprints for benchmark applications, which are then utilized in machine learning (ML) models to detect the corresponding benchmarks. This approach allows us to build a pre-trained model for benchmark detection using the unique micro-architectural fingerprints derived from PMU data. Subsequently, when an attacker remotely accesses the victim’s PMU data, the pre-trained model enables the identification of applications used by the victim with high accuracy. In our proof-of-concept demonstration, the pre-trained model successfully identifies applications used by a victim when the attacker remotely accesses PMU data, showcasing the potential for malicious exploitation of PMU data. We analyze stress-ng benchmarks and build our classifiers using logistic regression, decision tree, k-nearest neighbors, and random forest ML models. Our proposed models achieve an average prediction accuracy of 98%, underscoring the potential risks associated with remote side-channel analysis using PMU data and emphasizing the need for more robust safeguards. This work underscores the urgent need for robust countermeasures to protect against such vulnerabilities and provides a foundation for future research in micro-architectural security.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 20:29:25 +0000</pubDate>
</item>
<item>
<title>Probabilistic Attacks and Enhanced Security for "Private Set Intersection in the Internet Setting from Lightweight Oblivious PRF"</title>
<link>https://eprint.iacr.org/2024/969</link>
<guid>https://eprint.iacr.org/2024/969</guid>
<content:encoded><![CDATA[
<div> 关键词: Privacy Set Intersection (PSI), CM20协议, 安全漏洞, 概率攻击, 敏感数据保护<br /><br />总结:<br />
本文针对隐私集合交集(PSI)中的CM20协议进行了分析，指出了其存在的安全漏洞。CM20协议利用伪随机函数(PRF)加密用户隐私，但若攻击者获取了$\delta$和$F_2$，则可能恢复PRF加密的隐私信息。文章提出了名为“概率攻击”的方法来利用这一漏洞对CM20进行攻击。为解决此问题，文中引入了一种新的工具——扰动伪随机生成器(PPRG)，通过替换CM20协议中的随机 Oblivious Transfer 和其中一个哈希函数，以抵御此类概率攻击。最后，文章制定了一个针对该 PSI 协议的针对性选择明文攻击(IND-CPA)安全性模型，并表明提出的 PSI 解决方案在各种设备上的效率可与 CM20 相媲美。 <div>
Privacy Set Intersection (PSI) has been an important research topic within privacy computation. Its main function is to allow two parties to compute the intersection of their private sets without revealing any other private information. Therefore, PSI can be applied to various real-world scenarios.

Chase and Miao presented an impressive construction ``Private set intersection in the Internet setting from lightweight oblivious prf'' (CM20 for short) at Crypto 2020, highlighting its convenient structure and optimal communication cost. However, it does have some security vulnerabilities. Let $X$ be the privacy set of user $P_1$, $Y$ be the privacy set of user $P_2$. The CM20 protocol uses a pseudorandom function (PRF) to encrypt the privacy $x\in X$ of $P_1$ into $D_1$ and the privacy $y\in Y$ of $P_2$ into $D_2$, $D_1 = D_2$ as $x=y$. It then sends random data $F_1$ to user $P_1$ and random data $F_2$ to user $P_2$ using a random oblivious transfer technique. User $P_2$ computes $\delta=D_2\oplus F_2$ and sends $\delta$ to user $P_1$, and user $P_1$ uses $\delta$ and $F_1$ to re-encrypt $D_1$. Repeat this until $P_1$ re-encrypts all the privacy in all the privacy sets $X$, packages them up and sends them to $P_2$, who completes the privacy set intersection. However, if an adversary obtains $\delta$ and $F_2$ by any means, they can recover the PRF's encryption of the user's privacy, and the recovery process is non-trivial. This significantly weakens the security of the CM20 protocol.

In this paper, we make three main contributions. First, based on the above analysis, we present a method for attacking CM20, called {\em probabilistic attacks}. This attack is based on estimating and analysing the frequency distribution of the encrypted data from the PRF and the probability distribution of the original private data, and determining the relationship between the two. Although not 100\% effective, this method of attack poses a significant threat to the security of user data.

Secondly, we introduce a new tool called the {\em perturbed pseudorandom generator} (PPRG). We show that the PPRG can overcome probabilistic attacks by replacing the random oblivious transfer and one of the hash functions (originally there were two) in CM20.

Finally, we provide a dedicated indistinguishability against chosen-plaintext attack (IND-CPA) security model for this PSI protocol. The efficiency analysis shows that the proposed PSI is comparable to CM20's PSI, whether on a PC, MAC, pad or mobile phone.
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 02:53:16 +0000</pubDate>
</item>
<item>
<title>Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks</title>
<link>https://eprint.iacr.org/2023/1842</link>
<guid>https://eprint.iacr.org/2023/1842</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof of Stake (PoS), Lido, stETH, Leverage Staking, Risk Analysis

总结:
在以太坊的权益证明（PoS）生态系统中，用户可以通过Lido将ETH进行staking并获得stETH，这是一种液体staking衍生品（LSD），代表了已staking的ETH并积累staking收益。LSD提高了质押资产的流动性，使其能在二级市场如Aave的抵押借贷或Curve上的资产交换中使用。利用Lido、Aave和Curve的组合性，出现了一种名为杠杆staking的新策略，该策略能增强财务回报但同时也引入了潜在风险。文章构建了一个关于使用stETH进行杠杆staking的正式框架，并发现过去963天内在以太坊上存在442个这样的位置，涉及总价值为537,123 ETH（8.77亿美元）。数据显示，81.7%的杠杆staking头寸实现了比Lido常规staking更高的年化收益率（APR）。然而，我们注意到高回报伴随着潜在风险，如Terra崩溃事件展示了代币贬值对市场的影响。因此，我们进行了极端情况下stETH大幅贬值的压力测试，以评估相关的风险。模拟结果显示，杠杆staking会放大强制平仓和去杠杆化过程中的卖出压力风险，加速stETH价格下滑，并引发连锁反应，危及到杠杆头寸和普通头寸的稳定性。 <div>
In the Proof of Stake (PoS) Ethereum ecosystem, users can stake ETH on Lido to receive stETH, a Liquid Staking Derivative (LSD) that represents staked ETH and accrues staking rewards. LSDs improve the liquidity of staked assets by facilitating their use in secondary markets, such as for collateralized borrowing on Aave or asset exchanges on Curve. The composability of Lido, Aave, and Curve enables an emerging strategy known as leverage staking, an iterative process that enhances financial returns while introducing potential risks. This paper establishes a formal framework for leverage staking with stETH and identifies 442 such positions on Ethereum over 963 days. These positions represent a total volume of 537,123 ETH (877m USD). Our data reveal that 81.7% of leverage staking positions achieved an Annual Percentage Rate (APR) higher than conventional staking on Lido. Despite the high returns, we also recognize the potential risks. For example, the Terra crash incident demonstrated that token devaluation can impact the market. Therefore, we conduct stress tests under extreme conditions of significant stETH devaluation to evaluate the associated risks. Our simulations reveal that leverage staking amplifies the risk of cascading liquidations by triggering intensified selling pressure through liquidation and deleveraging processes. Furthermore, this dynamic not only accelerates the decline of stETH prices but also propagates a contagion effect, endangering the stability of both leveraged and ordinary positions.
]]></content:encoded>
<pubDate>Thu, 30 Nov 2023 11:03:01 +0000</pubDate>
</item>
<item>
<title>Fast SNARK-based Non-Interactive Distributed Verifiable Random Function with Ethereum Compatibility</title>
<link>https://eprint.iacr.org/2024/968</link>
<guid>https://eprint.iacr.org/2024/968</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式随机数生成器(DRBs), 非交互式分布式可验证随机函数(NI-DVRF), 以太坊, Rust, Solidity, Boba Network, 层2扩容方案, zkRand

总结:<br />
本文提出了一种迄今为止最高效的直接构建和实现非交互式分布式可验证随机函数(NI-DVRF)的方法，该方法完全兼容以太坊。该NI-DVRF方案利用配对技术并结合了秘密共享、SNARKs和BLS签名的技巧，其安全属性在随机Oracle模型下基于标准的配对基础假设被形式化建模和证明。为了证实效率和成本优势以及在实际中的应用潜力，该方案已在Rust和Solidity中进行了高度优化的实现，并正在研究部署于Boba Network提供的多链层2扩容解决方案上，用于驱动其zkRand DRB服务。实验分析还评估了所提NI-DVRF及其实现的性能和可扩展性属性。 <div>
Distributed randomness beacons (DRBs) are fundamental for various decentralised applications, such as consensus protocols,  decentralised gaming and lotteries, and collective governance protocols. These applications are heavily used on modern blockchain platforms.

This paper presents the so far most efficient direct construction and implementation of a non-interactive distributed verifiable random function (NI-DVRF) that is fully compatible with Ethereum. Our NI-DVRF scheme adopts pairings and combines techniques from secret sharing, SNARKs, and BLS signatures. The security properties of the resulting NI-DVRF scheme are formally modelled and proven in the random oracle model under standard pairing-based assumptions.

To justify the efficiency and cost claims and more generally its adoption potential in practice, the proposed NI-DVRF scheme was implemented in Rust and Solidity. Our implementation is highly optimised and is currently being investigated for deployment on the multichain layer-2 scaling solution provided by Boba Network to power its DRB service zkRand. Our experimental analysis, therefore, also evaluates performance and scalability properties of the proposed NI-DVRF and its implementation.
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 20:07:25 +0000</pubDate>
</item>
<item>
<title>Voting with coercion resistance and everlasting privacy using linkable ring signatures</title>
<link>https://eprint.iacr.org/2025/002</link>
<guid>https://eprint.iacr.org/2025/002</guid>
<content:encoded><![CDATA[
<div> 关键词：e-voting协议、linkable环签名、无条件匿名性、胁迫抵抗、JCJ框架、可验证性、选票保密性。

总结:<br />
我们提出了一种基于新颖linkable环签名方案的电子投票协议，该协议具有无条件匿名性，确保无论攻击者多么强大都无法推断出投票者的身份，从而实现永久隐私。此外，我们的协议在JCJ框架下提供了胁迫抵抗力，当对手试图强迫投票者进行特定投票时，投票者可通过创建一个带有假但无法区分凭证的签名来规避攻击，在确保隐私的时刻投出真实选票。同时，该协议还具备可验证性和选票保密性。 <div>
We propose an e-voting protocol based on a novel linkable ring signature scheme with unconditional anonymity. In our system, all voters register create private credentials and register their public counterparts. To vote, they create a ring (anonymity set) consisting of public credentials together with a proof of knowledge of their secret credential via our signature. Its unconditional anonymity prevents an attacker, no matter how powerful, from deducing the identity of the voter, thus attaining everlasting privacy. Additionally, our protocol provides coercion resistance in the JCJ framework; when an adversary tries to coerce a voter, the attack can be evaded by creating a signature with a fake but indistinguishable credential. During a moment of privacy, they will cast their real vote. Our scheme also provides verifiability and ballot secrecy.
]]></content:encoded>
<pubDate>Wed, 01 Jan 2025 08:08:50 +0000</pubDate>
</item>
<item>
<title>Smaug: Modular Augmentation of LLVM for MPC</title>
<link>https://eprint.iacr.org/2025/004</link>
<guid>https://eprint.iacr.org/2025/004</guid>
<content:encoded><![CDATA[
<div> 关键词: Secure Multi-Party Computation, MPC编程工具, Smaug, LLVM, Oblivious Computation

总结:
Smaug是一个基于LLVM的模块化扩展，旨在为MPC（安全多方计算）程序员提供更好的支持。现有的MPC编程工具由于缺乏文档、维护和与传统代码库的组合能力而难以吸引用户。Smaug引入了错误消息、文档、代码优化和多种语言编译至LLVM中间表示(IR)的支持。它可以有效地将非无知(Non-oblivious)的LLVM IR转换为其无知(Oblivious)等价物，同时应用LLVM的常用优化技术。通过C++和Rust编写并使用Yao和GMW协议作为后端的基准测试，Smaug的表现与使用领域特定语言的先前工具相当，甚至有时更优。最后，利用Smaug成功地将实现扫雷和21点游戏的开源项目编译成了可行的两方游戏，使得开发过程变得简单易行。 <div>
Secure multi-party computation (MPC) is a crucial tool for privacy-preserving computation, but it is getting increasingly complicated due to recent advancements and optimizations. Programming tools for MPC allow programmers to develop MPC applications without mastering all cryptography. However, most existing MPC programming tools fail to attract real users due to the lack of documentation, maintenance, and the ability to compose with legacy codebases. In this work, we build Smaug, a modular extension of LLVM. Smaug seamlessly brings all LLVM support to MPC programmers, including error messaging, documentation, code optimization, and frontend support to compile from various languages to LLVM intermediate representation (IR). Smaug can efficiently convert non-oblivious LLVM IR to their oblivious counterparts while applying popular optimizations as LLVM code transformations. With benchmarks written in C++ and Rust and backends for Yao and GMW protocols, we observe that Smaug performs as well as (and sometimes much better than) prior tools using domain-specific languages with similar backends. Finally, we use Smaug to compile open-source projects that
implement Minesweeper and Blackjack, producing usable two-party games with ease.
]]></content:encoded>
<pubDate>Wed, 01 Jan 2025 04:01:59 +0000</pubDate>
</item>
<item>
<title>MicroNova: Folding-based arguments with efficient (on-chain) verification</title>
<link>https://eprint.iacr.org/2024/2099</link>
<guid>https://eprint.iacr.org/2024/2099</guid>
<content:encoded><![CDATA[
<div> 关键词: MicroNova、折叠式递归论证、增量计算、验证效率、以太坊区块链

总结:
MicroNova是一种用于生成形式为$y=F^{(\ell)}(x)$的增量计算证明的设计与实现方案，其中$F$是一个可能非确定性的计算（使用如R1CS这样的约束系统编码），$x$是初始输入，$y$是输出，$\ell > 0$表示步骤数。该证明逐步生成，无论$\ell$大小，其证明大小和验证时间均不依赖于它。最后一步的证明会被压缩，进一步提高证明的简洁性。相比于之前的折叠式论证，MicroNova的一个显著特点是其在资源受限环境（如以太坊区块链）中具有高效的验证器实现。具体来说，压缩后的证明仅包含$O(\log{N})$个群元素，并能通过$O(\log{N})$个群标量乘法和两次配对操作进行验证，其中$N$是单次调用$F$时的约束数量。MicroNova需要一个通用的可信设置，并可以利用已经为流行的KZG一元多项式承诺方案创建的任何现有设置材料。实验结果显示，MicroNova的证明可以在以太坊区块链上高效地验证，大约耗用2.2M gas。此外，MicroNova的证明者在其基线Nova证明者的顶部只产生了轻微的开销。 <div>
We describe the design and implementation of MicroNova, a folding-based recursive argument for producing proofs of incremental computations of the form $y = F^{(\ell)}(x)$, where $F$ is a possibly non-deterministic computation (encoded using a constraint system such as R1CS), $x$ is the initial input, $y$ is the output, and $\ell > 0$. The proof of an $\ell$-step computation is produced step-by-step such that the proof size nor the time to verify it depends on $\ell$. The proof at the final iteration is then compressed, to achieve further succinctness in terms of proof size and verification time. Compared to prior folding-based arguments, a distinguishing aspect of MicroNova is the concrete efficiency of the verifier—even in a resource-constrained environment such as Ethereum’s blockchain. In particular, the compressed proof consists of $O(\log{N})$ group elements and it can be verified with $O(\log{N})$ group scalar multiplications and two pairing operations, where $N$ is the number of constraints for a single invocation of $F$. MicroNova requires a universal trusted setup and can employ any existing setup material created for the popular KZG univariate polynomial commitment scheme. Finally, we implement and experimentally evaluate MicroNova. We find that MicroNova’s proofs can be efficiently verified on the Ethereum blockchain with $\approx$2.2M gas. Furthermore, MicroNova’s prover incurs minimal overheads atop its baseline Nova’s prover.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 17:29:55 +0000</pubDate>
</item>
<item>
<title>NMFT: A Copyrighted Data Trading Protocol based on NFT and AI-powered Merkle Feature Tree</title>
<link>https://eprint.iacr.org/2024/2097</link>
<guid>https://eprint.iacr.org/2024/2097</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、NFT、版权保护、Merkle Feature Tree (MFT)、Locality-Sensitive Hashing (LSH)

总结:
为了解决区块链上基于NFT的数据交易中面临的版权保护问题，本文提出了一种版权保护数据交易协议。该协议主要包括两个创新点：首先，引入了增强版的默克尔树——Merkle Feature Tree (MFT)，它在数据层之上结合了一个AI驱动的特征层，以更好地保护版权信息；其次，在交易过程中设计了版权挑战阶段，利用高相似度特征向量和更早的链上时间戳来确认原始所有者的合法地位。为了实现在区块链上进行高效低能耗的特征向量相似性计算，文章采用了Locality-Sensitive Hashing (LSH)算法，将高维浮点特征向量压缩成单个uint256整数。实验结果显示，LSH能够在压缩前后有效地保持高度相似特征向量之间的相似性，支持基于相似性的版权挑战。此外，以太坊Sepolia测试网上的实验表明，NMFT具有可扩展性，其 Gas 消耗随规模增长呈亚线性，同时保持稳定的延迟。 <div>
With the rapid growth of blockchain-based Non-Fungible Tokens (NFTs), data trading has evolved to incorporate NFTs for ownership verification. However, the NFT ecosystem faces significant challenges in copyright protection, particularly when malicious buyers slightly modify the purchased data and re-mint it as a new NFT, infringing upon the original owner's rights. In this paper, we propose a copyright-preserving data trading protocol to address this challenge.

First, we introduce the Merkle Feature Tree (MFT), an enhanced version of the traditional Merkle Tree that incorporates an AI-powered feature layer above the data layer. Second, we design a copyright challenge phase during the trading process, which recognizes the data owner with highly similar feature vectors and earlier on-chain timestamp as the legitimate owner. Furthermore, to achieve efficient and low-gas feature vector similarity computation on blockchain, we employ Locality-Sensitive Hashing (LSH) to compress high-dimensional floating-point feature vectors into single uint256 integers.

Experiments with multiple image and text feature extraction models demonstrate that LSH effectively preserves the similarity between highly similar feature vectors before and after compression, thus supporting similarity-based copyright challenges. Experimental results on the Ethereum Sepolia testnet demonstrate NMFT's scalability with sublinear growth in gas consumption while maintaining stable latency.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 10:37:15 +0000</pubDate>
</item>
<item>
<title>Secure Vault scheme in the Cloud Operating Model</title>
<link>https://eprint.iacr.org/2024/2094</link>
<guid>https://eprint.iacr.org/2024/2094</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私保险库、云环境、数据安全、令牌化算法、形式化框架

总结:
文章介绍了随着对云环境中数据隐私需求的增长，数据隐私保险库作为一种安全管理敏感信息的解决方案应运而生。然而，目前尚无针对数据隐私保险库的安全性进行严格定义和形式化证明的工作。本文关注这一问题，提出了适用于大型语言模型训练数据存储的数据隐私保险库新框架，该框架在云操作模式下运行，假设服务器可信但无状态，存储外包。文中提出了一种新颖的令牌化算法作为保护敏感数据的核心机制，既能生成安全、不可预测的令牌，又能确保敏感数据的安全存储并实现基于预定义访问级别的受控数据检索。此外，本文还为数据隐私保险库提供了正式定义和具体实现，并附带了安全性证明，填补了现有文献中的空白，从而增强了对保险库方案的理解，并为云计算时代安全数据管理提供了一个可行的解决方案。 <div>
The rising demand for data privacy in cloud-based environments has led to the development of advanced mechanisms for securely managing sensitive information. A prominent solution in this domain is the "Data Privacy Vault," a concept that is being provided commercially by companies such as Hashicorp, Basis Theory, Skyflow Inc., VGS, Evervault, Protegrity, Anonomatic, and BoxyHQ. However, no existing work has rigorously defined the security notions required for a Data Privacy Vault or proven them within a formal framework which is the focus of this paper.

Among its other uses, data privacy vaults are increasingly being used as storage for LLM training data which necessitates a scheme that enables users to securely store sensitive information in the cloud while allowing controlled access for performing analytics on specific non-sensitive attributes without exposing sensitive data. Conventional solutions involve users generating encryption keys to safeguard their data, but these solutions are not deterministic and are therefore unsuited for the LLM setting. To address this, we propose a novel framework that is deterministic as well as semantically secure. Our scheme operates in the Cloud Operating model where the server is trusted but stateless, and the storage is outsourced.

We provide a formal definition and a concrete instantiation of this data privacy vault scheme. We introduce a novel tokenization algorithm that serves as the core mechanism for protecting sensitive data within the vault. Our approach not only generates secure, unpredictable tokens for sensitive data but also securely stores sensitive data while enabling controlled data retrieval based on predefined access levels. Our work fills a significant gap in the existing literature by providing a formalized framework for the data privacy vault, complete with security proofs and a practical construction - not only enhancing the understanding of vault schemes but also offering a viable solution for secure data management in the era of cloud computing.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 14:03:33 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Privacy for Traceable Receipt-Free Encryption</title>
<link>https://eprint.iacr.org/2024/2087</link>
<guid>https://eprint.iacr.org/2024/2087</guid>
<content:encoded><![CDATA[
<div> 关键词: Traceable Receipt-free Encryption (TREnc), 量子计算机, 隐私保护, Ring Learning With Errors (RLWE), 配对式统计零知识证明

总结:
文章介绍了可追溯收据自由加密(TREnc)这一新兴的公开密钥加密原语及其在投票系统中的应用。现有的TREnc机制主要依赖于离散对数相关假设，易受未来量子计算机的攻击。为解决这一局限性，文章构建了首个能抵御量子敌手隐私攻击的TREnc方案。首先，作者对原始的TREnc模型进行了通用化，使其更易于与基于格的语义安全加密兼容。该实现依赖于Ring Learning With Errors (RLWE)和Groth-Sahai的配对式统计零知识模拟声学证明，并进一步具备公共硬币共同参考字符串的特点，从而消除了对可信设置的需求。 <div>
Traceable Receipt-free Encryption (TREnc) has recently been introduced as a verifiable public-key encryption primitive endowed with a unique security model. In a nutshell, TREnc allows randomizing ciphertexts in transit in order to remove any subliminal information up to a public trace that ensures the non-malleability of the underlying plaintext. A remarkable property of TREnc is the indistinguishability of the randomization of chosen ciphertexts against traceable chosen-ciphertext attacks (TCCA). The main application lies in voting systems by allowing voters to encrypt their votes, tracing whether a published ballot takes their choices into account, and preventing them from proving how they
voted. While being a very promising primitive, the few existing TREnc mechanisms solely rely on discrete-logarithm related assumptions making them vulnerable to the well-known record-now/decrypt-later attack in the wait of quantum computers.
We address this limitation by building the first TREnc whose privacy withstands the advent of quantum adversaries in the future. To design our construction, we first generalize the original TREnc primitive that is too restrictive to be easily compatible with built-in lattice-based semantically-secure encryption. Our more flexible model keeps all the ingredients generically implying receipt-free voting. Our instantiation relies on Ring Learning With Errors (RLWE) with pairing-based statistical zero-knowledge simulation sound proofs from Groth-Sahai, and further enjoys a public-coin common reference string removing the need of a trusted setup.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 21:23:18 +0000</pubDate>
</item>
<item>
<title>How To Think About End-To-End Encryption and AI: Training, Processing, Disclosure, and Consent</title>
<link>https://eprint.iacr.org/2024/2086</link>
<guid>https://eprint.iacr.org/2024/2086</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端加密(E2EE)、人工智能(AI)、安全冲突、法律影响、推荐实践

<br /><br />总结:
本文对人工智能模型与端到端加密应用的兼容性进行了批判性审查，主要从两个方面展开：一是E2EE应用中集成AI“助手”，二是使用E2EE数据训练AI模型。文章分析了这两种情况下的潜在安全影响，指出它们可能与E2EE提供的安全性保证相冲突，并探讨了AI整合对E2EE承诺的机密性的法律影响。最后，基于技术与法律分析，文章提出了若干详细建议，包括为了维护E2EE安全应优先考虑的技术设计选择、服务提供商如何准确表述E2EE的安全性以及AI功能的默认行为和征求用户同意的最佳实践。作者期望这篇论文能引发关于AI迅速部署与E2EE所提供安全性的紧张关系之间的知情讨论，并指导新AI特性负责任地开发。 <div>
End-to-end encryption (E2EE) has become the gold standard for securing communications, bringing strong confidentiality and privacy guarantees to billions of users worldwide. However, the current push towards widespread integration of artificial intelligence (AI) models, including in E2EE systems, raises some serious security concerns.

This work performs a critical examination of the (in)compatibility of AI models and E2EE applications. We explore this on two fronts: (1) the integration of AI “assistants” within E2EE applications, and (2) the use of E2EE data for training AI models. 
We analyze the potential security implications of each, and identify conflicts with the security guarantees of E2EE. Then, we analyze legal implications of integrating AI models in E2EE applications, given how AI integration can undermine the confidentiality that E2EE promises. Finally, we offer a list of detailed recommendations based on our technical and legal analyses, including: technical design choices that must be prioritized to uphold E2EE security; how service providers must accurately represent E2EE security; and best practices for the default behavior of AI features and for requesting user consent. We hope this paper catalyzes an informed conversation on the tensions that arise between the brisk deployment of AI and the security offered by E2EE, and guides the responsible development of new AI features.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 20:08:40 +0000</pubDate>
</item>
<item>
<title>Definition of End-to-end Encryption</title>
<link>https://eprint.iacr.org/2024/2085</link>
<guid>https://eprint.iacr.org/2024/2085</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端加密（E2EE）、加密机制、通信安全、隐私保护、消息、电子邮件、视频、音频、媒体、保密性、完整性、真实性、前向安全性。

总结:
端到端加密（E2EE）是一种应用加密技术确保两端点间通信安全与隐私的应用，涵盖了包括消息、电子邮件、视频、音频等不同形式的媒体内容。E2EE为人们的交流提供了四个关键保障：保密性，确保信息仅由发送者和接收者阅读；完整性，保证数据在传输过程中不被篡改；真实性，确认信息来自预期的发送方；以及前向安全性，即使密钥丢失，过去通信内容仍能保持安全。 <div>
This document provides a definition of end-to-end encryption (E2EE). End-to-end encryption is an application of cryptographic mechanisms to provide security and privacy to communication between endpoints. Such communication can include messages, email, video, audio, and other forms of media. E2EE provides security and privacy through confidentiality, integrity, authenticity and forward secrecy for communication amongst people.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 20:03:19 +0000</pubDate>
</item>
<item>
<title>Zero Knowledge Memory-Checking Techniques for Stacks and Queues</title>
<link>https://eprint.iacr.org/2024/2084</link>
<guid>https://eprint.iacr.org/2024/2084</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、内存技术、队列、栈、多项式评估

总结:<br />
本文提出了适用于特殊数据结构——队列和栈的内存技术。针对队列，文章介绍了一种基于算术电路的实现方法，该方法在每次读取时需要3个多项式乘法门和1个建议值，每次写入时需要2个多项式乘法门。该方法利用Horner规则来验证队列中读取和写入值的一致性。对于栈，文章提出一种优化版的RAM方案，基于Yang和Heath的方法，读取操作需要5个多项式乘法门和4个建议值，而写入仍为2个多项式乘法门。该优化方案利用栈的特性避免了对每个访问插入哑操作的需求。此外，文中还引入了一种更适合栈和队列应用场景的“多路复用”或“操作隐私”的新概念，所有的技术都是基于在随机点上评估多项式并使用随机评估的多项式作为通用哈希函数来检查集合/向量的等价性。 <div>
There are a variety of techniques for implementing read/write memory inside of zero-knowledge proofs and validating consistency of memory accesses. These techniques are generally implemented with the goal of implementing a RAM or ROM. In this paper, we present memory techniques for more specialized data structures: queues and stacks. We first demonstrate a technique for implementing queues in arithmetic circuits that requires 3 multiplication gates and 1 advice value per read and 2 multiplication gates per write. This is based on using Horner's Rule to evaluate 2 polynomials at random points and check that the values read from the queue are equal to the values written to the queue as vectors. Next, we present a stack scheme based on an optimized version of the RAM scheme of Yang and Heath that requires 5 multiplication gates and 4 advice values per read and 2 multiplication gates per write. This optimizes the RAM scheme by observing that reads and writes to a stack are already "paired" which avoids the need for inserting dummy operations for each access as in a stack.
    We also introduce a different notion of "multiplexing" or "operation privacy" that is better suited to the use case of stacks and queues. All of the techniques we provide are based on evaluating polynomials at random points and using randomly evaluated polynomials as universal hash functions to check set/vector equality.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 18:57:30 +0000</pubDate>
</item>
<item>
<title>ClusterGuard: Secure Clustered Aggregation for Federated Learning with Robustness</title>
<link>https://eprint.iacr.org/2024/2082</link>
<guid>https://eprint.iacr.org/2024/2082</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习、安全聚合、dropout处理、中毒攻击、ClusterGuard

总结:
联邦学习中，为了保护数据隐私并实现模型协同训练，安全聚合与dropout处理是关键挑战。现有的先进方法如Liu等人（UAI'22）和Li等人（ASIACRYPT'23）方案存在通信开销大、实施复杂以及易受中毒攻击的问题。部分连接图结构的方法虽能降低通信成本（如Bell等人，CCS'20和ACORN, USENIX Sec'23），但在图构建过程中可能遭受恶意操纵。为此，我们提出了ClusterGuard，一种用于联邦学习的安全聚类聚合方案。ClusterGuard利用可验证随机函数（VRF）确保公平透明的聚类选择，并结合轻量级密钥同态掩码机制及高效的dropout处理实现安全聚类聚合。此外，ClusterGuard还引入基于余弦相似性和范数的双重过滤机制来有效检测和缓解中毒攻击。实验表明，ClusterGuard相比于先进的安全聚合方法在效率上提升了超过2倍，即使在有20%的客户端恶意的情况下，训练出的模型仍能保持与原模型相当的准确性，优于现有鲁棒性解决方案。因此，ClusterGuard为实际应用中的联邦学习提供了更为高效、安全和鲁棒的解决方案。 <div>
Federated Learning (FL) enables collaborative model training while preserving data privacy by avoiding the sharing of raw data. However, in large-scale FL systems, efficient secure aggregation and dropout handling remain critical challenges. Existing state-of-the-art methods, such as those proposed by Liu et al. (UAI'22) and Li et al. (ASIACRYPT'23), suffer from prohibitive communication overhead, implementation complexity, and vulnerability to poisoning attacks. Alternative approaches that utilize partially connected graph structures (resembling client grouping) to reduce communication costs, such as Bell et al. (CCS'20) and ACORN (USENIX Sec'23), face the risk of adversarial manipulation during the graph construction process.

To address these issues, we propose ClusterGuard, a secure clustered aggregation scheme for federated learning. ClusterGuard leverages Verifiable Random Functions (VRF) to ensure fair and transparent cluster selection and employs a lightweight key-homomorphic masking mechanism, combined with efficient dropout handling, to achieve secure clustered aggregation. Furthermore, ClusterGuard incorporates a dual filtering mechanism based on cosine similarity and norm to effectively detect and mitigate poisoning attacks.

Extensive experiments on standard datasets demonstrate that ClusterGuard achieves over 2x efficiency improvement compared to advanced secure aggregation methods. Even with 20% of clients being malicious, the trained model maintains accuracy comparable to the original model, outperforming state-of-the-art robustness solutions. ClusterGuard provides a more efficient, secure, and robust solution for practical federated learning.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 15:12:04 +0000</pubDate>
</item>
<item>
<title>Blind Signatures from Proofs of Inequality</title>
<link>https://eprint.iacr.org/2024/2076</link>
<guid>https://eprint.iacr.org/2024/2076</guid>
<content:encoded><![CDATA[
<div> 关键词: Blind signatures、pairing-free、random oracle模型、DDH假设、效率提升

总结:
这篇文章介绍了新的盲签名构造方法，该方法旨在缩小效率上的差距，特别是在不需要配对的情况下。与最高效的基于配对的AGM盲签名方案相比，新方案在通信和签名大小上分别只有3倍和2倍的相对开销，并在随机预言机模型下基于DDH假设可证明安全性。此外，通过增加一步操作和一个$\mathbb{Z}_p$元素，该方案还实现了更强的防伪造性。这一成果受到了Chairattana-Apirom, Tessaro, 和 Zhu (Crypto 2024)以及Klooß, Reichle, 和Wagner (Asiacrypt 2024)近期工作的启发，并针对这些工作中的效率瓶颈开发了定制化技术。具体来说，新方案实现了192字节的签名大小和608字节的通信大小。 <div>
Blind signatures are an important primitive for privacy-preserving technologies. To date, highly efficient pairing-free constructions rely on the random oracle model, and additionally, a strong assumption, such as interactive assumptions or the algebraic group model.

In contrast, for signatures we know many efficient constructions that rely on the random oracle model and standard assumptions. In this work, we develop techniques to close this gap. Compared to the most efficient pairing-free AGM-based blind signature by Crites et. al. (Crypto 2023), our construction has a relative overhead of only a factor $3\times$ and $2\times$ in terms of communication and signature size, and it is provable in the random oracle model under the DDH assumption. With one additional move and $\mathbb{Z}_p$ element, we also achieve one-more strong unforgeability.

Our construction is inspired by the recent works by Chairattana-Apirom, Tessaro, and Zhu (Crypto 2024) and Klooß, Reichle, and Wagner (Asiacrypt 2024), and we develop a tailored technique to circumvent the sources of inefficiency in their constructions. Concretely, we achieve signature and communication size of $192$ B and $608$ B, respectively.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 20:28:26 +0000</pubDate>
</item>
<item>
<title>Advancements in Distributed RSA Key Generation: Enhanced Biprimality Tests</title>
<link>https://eprint.iacr.org/2024/2072</link>
<guid>https://eprint.iacr.org/2024/2072</guid>
<content:encoded><![CDATA[
<div> 关键词：RSA、安全多方计算、Boneh-Franklin测试、Lucas双素性测试、分布式RSA模数生成

总结:

本文针对RSA密码学实践中广泛使用的 Boneh-Franklin 双素性测试进行了深入研究。首先，证明了该测试在接受概率上的上限其实为1/4，而非原先假设的1/2，除非$p=q=3$，这意味着在实际应用中执行相同安全性检验所需的迭代次数可以减半。随后，文章提出了两种类型的Lucas双素性测试。其中一种测试在最坏情况下的接受率不超过$1/4 + 1.25/(p_{\min}-3)$，其中$p_{\min}$为$N$的最小质因数，模拟研究表明它通常比Boneh-Franklin测试更高效地检测$N$是否为RSA模数。另一种Lucas测试可应用于任意RSA模数$p$和$q$，但其效率较低。当生成RSA模数的安全性错误设定约为$2^{-80}$时，该测试最多泄露46个二次符号值。此外，文章还设计了对应于这两种测试的协议，并验证了它们对于半诚实敌手的鲁棒性，这些协议可以应用于已知的大多数分布式RSA模数生成协议。通过对包括Burkhardt等人在CCS 2023上提出的Miller-Rabin测试变种、Boneh-Franklin测试以及所提Lucas型测试在内的多种知名协议进行详尽分析和比较后，发现所提Lucas测试在验证$N$是否为RSA模数方面具有高度竞争力。 <div>
RSA is widely used in modern cryptographic practice, with certain RSA-based protocols relying on the secrecy of $p$ and $q$. A common approach is to use secure multiparty computation to address the privacy concerns of 
$p$ and $q$.
Specifically constrained to distributed RSA modulus generation protocols, the biprimality test for Blum integers $N=pq$, where $p\equiv q\equiv 3 \mod 4$ are two primes, proposed by Boneh and Franklin in $2001$ is the most commonly used. Over the past $20 $ years, the worst-case acceptance rate of this test has been consistently assumed to be $1/2$ under the condition $\gcd(pq,p+q-1)=1$.
In this paper, we show that for the Boneh-Franklin test, its acceptance probability is at most $1/4$ rather than $1/2$,
except in the case where $p = q = 3$.  At the same time, $1/4$ is also the tightest upper bound. Enhance the effectiveness of applying the Boneh-Franklin test in this result: achieving the same soundness for the RSA modulus requires only half the number of iterations commonly recognized. 
Furthermore, we propose two types of Lucas biprimality tests. In the worst case, one of proposed tests acceptance rate is at most $1/4 +  1.25/(p_{\min} -3)$, where $p_{\min}$ is the smallest prime factors of $N$. However, simulation study suggests that this test is generally more efficient than the Boneh-Franklin test for detecting when $N$ is not an RSA modulus.
The second type of Lucas test, though less efficient, can be applied to arbitrary RSA moduli $p$ and $q$. Nevertheless, if the soundness error for generating an RSA modulus is set at approximately $2^{-80}$, it leaks at most $46$ quadratic symbol values, regardless of the public key length. We also design corresponding protocols for both tests and validate their resilience against semi-honest adversaries, which can be applied to most known distributed RSA modulus generation protocols. After thoroughly analyzing and comparing well-known protocols, including the variant Miller-Rabin test used by Burkhardt et al. (CCS 2023), the Boneh-Franklin test, and our proposed Lucas-type tests, our proposed Lucas test is also highly competitive in verifying whether $N$ is an RSA modulus.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 16:44:46 +0000</pubDate>
</item>
<item>
<title>COCO: Coconuts and Oblivious Computations for Orthogonal Authentication</title>
<link>https://eprint.iacr.org/2024/2066</link>
<guid>https://eprint.iacr.org/2024/2066</guid>
<content:encoded><![CDATA[
<div> 关键词：COCO、身份验证、隐私保护、Oblivious Pseudorandom Functions (OPRFs)、 CoconutCredential Scheme

<br /><br />总结：
本文提出了一种名为COCO（Coconuts和 Oblivious Computations for Orthogonal Authentication）的框架，旨在实现隐私保护的身份验证。COCO通过将角色分割为验证者、认证器和客户端，避免了认证器直接访问虚拟公共标识或现实世界标识的需求。该框架利用Oblivious Pseudorandom Functions (OPRFs) 和扩展的Coconut Credential Scheme，引入了独立的不可链接的正交认证标识以及全共识机制，从而进行零知识认证，保证证明在多个会话中均不可链接。这种身份验证过程成为自我包含的，防止虚拟公共标识与现实世界标识之间的明确反向追踪。 <div>
Authentication often bridges real-world individuals and their virtual public identities, like usernames, user IDs and e-mails, exposing vulnerabilities that threaten user privacy. This research introduces COCO (Coconuts and Oblivious Computations for Orthogonal Authentication), a framework that segregates roles among Verifiers, Authenticators, and Clients to achieve privacy-preserving authentication.

COCO eliminates the need for Authenticators to directly access virtual public identifiers or real-world identifiers for authentication. Instead, the framework leverages Oblivious Pseudorandom Functions (OPRFs) and an extended Coconut Credential Scheme to ensure privacy by introducing separate unlinkable orthogonal authentication identifiers and a full-consensus mechanism to perform zero-knowledge authentications whose proof-s are unlinkable across multiple sessions. Authentication process becomes self-contained, preventing definitive reverse tracing of virtual public identifiers to real-world identifiers.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 14:43:26 +0000</pubDate>
</item>
<item>
<title>Greco: Fast Zero-Knowledge Proofs for Valid FHE RLWE Ciphertexts Formation</title>
<link>https://eprint.iacr.org/2024/594</link>
<guid>https://eprint.iacr.org/2024/594</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密(FHE), 多方计算, 密文投票, 零知识证明, Greco<br /><br />总结: 全同态加密（FHE）允许对加密数据执行任意函数运算。在多方FHE应用中，不同参与者加密其秘密数据并提交给服务器，服务器根据应用逻辑对这些密文进行同态操作。以秘密投票为例，计票是通过对表示选票的密文求和来计算的。恶意选民可能会发送如$E(145127835)$这样的无效加密选票，从而破坏选举结果。为解决此问题，用户需利用零知识证明证明他们提交的RLWE密文是有效的，并且加密的消息是一个有效的选票（例如，1或0）。Greco利用零知识证明让用户证明其RLWE密文构造正确。此外，该证明可以与特定应用逻辑结合，并在非交互式环境中公开验证。对于秘密投票应用，还可以进一步证明消息的其他属性甚至关于选民的属性，从而支持匿名投票。Greco的实现采用了Halo2-lib作为证明系统，基准测试显示它可以被无缝集成到面向用户的应用程序中，而不会过度增加用户使用的摩擦。该实现已在https://github.com/privacy-scaling-explorations/greco上发布。 <div>
Fully homomorphic encryption (FHE) allows for evaluating arbitrary functions over encrypted data. In Multi-party FHE applications, different parties encrypt their secret data and submit ciphertexts to a server, which, according to the application logic, performs homomorphic operations on them. For example, in a secret voting application, the tally is computed by summing up the ciphertexts encoding the votes. Valid encrypted votes are of the form $E(0)$ and $E(1)$. A malicious voter could send an invalid encrypted vote such as $E(145127835)$, which can mess up the whole election. Because of that, users must prove that the ciphertext they submitted is a valid Ring-Learning with Errors (RLWE) ciphertext and that the plaintext message they encrypted is a valid vote (for example, either a 1 or 0). Greco uses zero-knowledge proof to let a user prove that their RLWE ciphertext is well-formed. Or, in other words, that the encryption operation was performed correctly. The resulting proof can be, therefore, composed with additional application-specific logic and subject to public verification in a non-interactive setting. Considering the secret voting application, one can prove further properties of the message being encrypted or even properties about the voter, allowing the application to support anonymous voting as well. The prover has been implemented using Halo2-lib as a proving system, and the benchmarks have shown that Greco can already be integrated into user-facing applications without creating excessive friction for the user. The implementation is available at https://github.com/privacy-scaling-explorations/greco
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 09:49:00 +0000</pubDate>
</item>
<item>
<title>Security Analysis of SFrame</title>
<link>https://eprint.iacr.org/2021/424</link>
<guid>https://eprint.iacr.org/2021/424</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私意识、端到端加密（E2EE）、SFrame、安全评估、伪造攻击

<br /><br />总结：
本文讨论了用于互联网视频/音频群组通信的端到端加密机制SFrame的安全性。尽管SFrame是一个相对较新的项目，但已被多个实际应用采纳部署。文章对SFrame原始规范进行了深入评估，发现其中存在可能导致恶意组成员以实际复杂度实施伪装（伪造）攻击的关键问题。进一步调查还显示，这些问题存在于几个公开可用的SFrame实现中。因此，文中提出了针对所有潜在攻击的应对措施以及从性能和安全性角度出发的实施方案考虑。 <div>
Increasing privacy consciousness has popularized the use of end-to-end encryption (E2EE). In this paper, we discuss the security of SFrame, an E2EE mechanism proposed to the Internet Engineering Task Force for video/audio group communications over the Internet. Despite being a quite recent project, SFrame has been deployed in several real-world applications. The original specification of SFrame is evaluated herein to find critical issues that can cause impersonation (forgery) attacks with a practical complexity by a malicious group member. Further investigations have revealed that these issues are present in several publicly available SFrame implementations. Therefore, we provide several countermeasures against all the proposed attacks and considerations from performance and security perspectives toward their implementation.
]]></content:encoded>
<pubDate>Tue, 06 Apr 2021 07:09:37 +0000</pubDate>
</item>
<item>
<title>Minimizing the Use of the Honest Majority in YOSO MPC with Guaranteed Output Delivery</title>
<link>https://eprint.iacr.org/2024/2059</link>
<guid>https://eprint.iacr.org/2024/2059</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算、诚实多数、最小参与、一次性发言 (YOSO)、公共计算

总结:
本文探讨了多方计算(MPC)协议中诚实多数的必要性，并提出一种创新方案。该方案表明虽然诚实多数是必需的，但其参与度可以极小化。文中展示了一个具有保证输出交付的MPC协议，其中大部分执行由存在不诚实多数的委员会序列完成；而仅需一个拥有诚实多数的委员会，其成员的工作与电路大小无关，且每个参与者只需发言一次（即YOSO属性）。作为独立的研究模块，文章引入了“公共计算”概念，这是一种类似区块链上智能合约的隐私无关的、具有保证输出交付的多方计算。此外，文章还展示了在公共公告板上实现公共计算的三种不同方式，各自具有不同的假设、轮数和空间利用权衡。 <div>
Cleve (STOC 86) shows that an honest majority is necessary for MPC with guaranteed output delivery. In this paper, we show that while an honest majority is indeed necessary, its involvement can be minimal. We demonstrate an MPC protocol with guaranteed output delivery, the majority of which is executed by a sequence of committees with dishonest majority; we leverage $\textit{one}$ committee with an honest majority, each member of which does work independent of the circuit size. Our protocol has the desirable property that every participant speaks only once (YOSO, Crypto 2021).
As a building block of independent interest, we introduce \emph{public computation}, which is essentially privacy-free MPC with guaranteed output delivery (akin to smart contracts realized on blockchains). We instantiate public computation on a public bulletin board in three different ways (with different assumption / round / space utilization trade-offs).
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 21:19:05 +0000</pubDate>
</item>
<item>
<title>Leveraging remote attestation APIs for secure image sharing in messaging apps</title>
<link>https://eprint.iacr.org/2024/2057</link>
<guid>https://eprint.iacr.org/2024/2057</guid>
<content:encoded><![CDATA[
<div> 关键词: 敏感图片、隐私保护、即时通讯应用、远程认证、加密解密

总结:<br />
本文针对通过移动聊天应用程序分享的敏感图片（如护照照片和私密照片）的隐私保护问题，提出了一种基于多平台系统的解决方案。该系统在即时通讯应用之上对敏感图片进行加密和解密，并利用可用的应用程序完整性API进行远程认证以确保安全性。相比于以前提出的中间件中的图像加密方案，这种方法提供了增强的安全性、额外的隐私优势，简化了集成并提高了用户体验，因为它无需用户事先交换密钥材料。实验结果显示，发送和接收私人图片时平均分别增加了3.8秒和4.5秒的延迟。 <div>
Sensitive pictures such as passport photos and nudes are commonly shared through mobile chat applications. One popular strategy for the privacy protection of this material is to use ephemeral messaging features, such as the view once snaps in Snapchat. However, design limitations and implementation bugs in messaging apps may allow attackers to bypass the restrictions imposed by those features on the received material. One way by which attackers may accomplish so is by tampering with the software stack on their own devices. In this paper, we propose and test a protection strategy based on a multiplatform system that encrypts and decrypts sensitive pictures on top of messaging apps and performs remote attestation with available app integrity APIs to safeguard its security. Our analysis and experiments show that, compared to previous proposals for image encryption in a middleware, remote attestation offers increased security, adds privacy benefits, simplifies integration, and improves usability by not requiring users to exchange key material a priori. In our experiments, it incurs an added average latency of 3.8 and 4.5 seconds when sending and receiving private pictures, respectively.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 17:11:28 +0000</pubDate>
</item>
<item>
<title>Simulation Secure Multi-Input Quadratic Functional Encryption: Applications to Differential Privacy</title>
<link>https://eprint.iacr.org/2024/2050</link>
<guid>https://eprint.iacr.org/2024/2050</guid>
<content:encoded><![CDATA[
<div> 关键词: 多输入功能性加密、秘密钥、二次功能性加密、模拟安全性、数据隐私保护

<br /><br />总结:
本文提出了首个满足模拟安全性的秘密钥多输入二次功能性加密方案。现有的二次功能支持构造仅达到基于不可区分性的安全性。文中构建了一个新的函数隐藏型内积功能性加密方案，该方案在标准模型下被证明对一个挑战密文具有模拟安全性，这本身具有独立的研究价值。利用这两个结果，作者构建了一个高效的随机化二次功能性加密方案，从而实现对支持二次查询的加密数据库进行不同ially 私有数据分析。最后，文章提供了所提随机化方案的完整实现与基准测试。这一工作是在SAC '24会议论文的基础上扩展的，首次提出了多输入二次功能性加密方案和函数隐藏型内积功能性加密方案。 <div>
Multi-input functional encryption is a primitive that allows for the evaluation of an $\ell$-ary function over multiple ciphertexts, without learning any information about the underlying plaintexts. This type of computation is useful in many cases where one has to compute over encrypted data, such as privacy-preserving cloud services, federated learning, or more generally delegation of computation from multiple clients. It has recently been shown by Alborch et al. in PETS '24 to be useful to construct a randomized functional encryption scheme for obtaining differentially private data analysis over an encrypted database supporting linear queries.

In this work we propose the first secret-key multi-input quadratic functional encryption scheme satisfying simulation security. Current constructions supporting quadratic functionalities, proposed by Agrawal et al. in CRYPTO '21 and TCC '22, only reach indistinguishibility-based security. Our proposed construction is generic, and for a concrete instantiation, we propose a new function-hiding inner-product functional encryption scheme proven simulation secure against one challenge ciphertext in the standard model, which is of independent interest. We then use these two results to construct an efficient randomized quadratic functional encryption scheme, from which we obtain differentially private data analysis over an encrypted database supporting quadratic queries. Finally, we give and fully benchmark an implementation of the randomized scheme. This work is an extended version of the paper "Simulation Secure Multi-Input Quadratic Functional Encryption" at SAC '24, where the multi-input quadratic functional encryption scheme and function-hiding inner-product functional encryption schemes were first presented (Section 3 and Seciton 4).
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 14:36:56 +0000</pubDate>
</item>
<item>
<title>Cryptographic Commitments on Anonymizable Data</title>
<link>https://eprint.iacr.org/2024/2044</link>
<guid>https://eprint.iacr.org/2024/2044</guid>
<content:encoded><![CDATA[
<div> 关键词: Local Differential Privacy (LDP), LDP commitment, cryptographic primitive, privacy, usability

<br /><br />总结:
本文提出了一种新的密码学原语——LDP承诺机制，该机制结合了局部差分隐私技术，使得数据拥有者可以在保护隐私的同时，将添加了可控噪声的数据公开。LDP承诺要求在揭示值之前需证明已正确应用了LDP机制，以确保数据仍可用于统计目的。文中还定义了该原语的安全模型以及隐藏性和绑定性这两个性质。接着，文章给出了一种基于经典密码学工具和标准假设的、适用于LDP阶梯机制的具体方案，并实现了Rust版本的高效代码（生成承诺只需几毫秒）。在应用场景中，该机制可同时保障医疗数据在开放科学背景下的隐私、可用性和可追溯性。具体场景为：一家医院在对敏感患者数据进行匿名处理并由医生签名后，将其提供给研究机构；研究机构可以验证数据来源（即验证医生签名），同时也能确认数据已被正确匿名处理（即数据虽被匿名但仍具有使用价值）。 <div>
Local Differential Privacy (LDP) mechanisms consist of (locally) adding controlled noise to data in order to protect the privacy of their owner. In this paper, we introduce a new cryptographic primitive called LDP commitment. Usually, a commitment ensures that the committed value cannot be modified before it is revealed. In the case of an LDP commitment, however, the value is revealed after being perturbed by an LDP mechanism. Opening an LDP commitment therefore requires a proof that the mechanism has been correctly applied to the value, to ensure that the value is still usable for statistical purposes. We also present a security model for this primitive, in which we define the hiding and binding properties. Finally, we present a concrete scheme for an LDP staircase mechanism (generalizing the randomized response technique), based on classical cryptographic tools and standard assumptions. We provide an implementation in Rust that demonstrates its practical efficiency (the generation of a commitment requires just a few milliseconds). On the application side, we show how our primitive can be used to ensure simultaneously privacy, usability and traceability of medical data when it is used for statistical studies in an open science context. We consider a scenario where a hospital provides sensitive patients data signed by doctors to a research center after it has been anonymized, so that the research center can verify both the provenance of the data (i.e. verify the doctors’ signatures even though the data has been noised) and that the data has been correctly anonymized (i.e. is usable even though it has been anonymized).
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 08:49:54 +0000</pubDate>
</item>
<item>
<title>Distributed Asynchronous Remote Key Generation</title>
<link>https://eprint.iacr.org/2024/846</link>
<guid>https://eprint.iacr.org/2024/846</guid>
<content:encoded><![CDATA[
<div> 关键词: 异步远程密钥生成(ARKG), 分布式ARVG(dARKG), 公开验证非对称密钥协议(1PVAKA), 双线性群, BLS12-381曲线

总结:<br />
本文提出了分布式异步远程密钥生成(dARKG)，它扩展了ARKG的安全属性至分布式环境。在dARKG中，发送者可以为一组n个接收者生成公钥$pk'$，对应的私钥$sk'$只能由其中任意大小为t≤n的子集共同计算，实现了基于阈值的访问保护。文章通过新提出的、一轮公开验证的非对称密钥协议(1PVAKA)来构建dARKG，该协议异步且允许第三方从用户输出验证并生成公钥。文章还讨论了针对双线性群的1PVAKA和dARKG的具体实现方案，并使用BLS12-381曲线进行了实现与性能分析，证明其实用性。 <div>
Asynchronous Remote Key Generation (ARKG) is a primitive introduced by Frymann et al. at ACM CCS 2020. It enables a sender to generate a new public key $pk'$ for a receiver ensuring only it can, at a later time, compute the corresponding private key $sk'$. These key pairs are indistinguishable from freshly generated ones and can be used in various public-key cryptosystems such as digital signatures and public-key encryption. ARKG has been explored for applications in WebAuthn credential backup and delegation, as well as for enhancing receiver privacy via stealth addresses.

In this paper, we introduce distributed ARKG (dARKG) aiming to provide similar security properties in a distributed setting. Here, a sender generates $pk'$ for a group of $n$ receivers and the corresponding $sk'$ can only be computed by any sub-group of size $t\leq n$. This introduces threshold-based access protection for $sk'$, enabling for instance a set of proxies to jointly access a WebAuthn account or claim blockchain funds.

We construct dARKG using one-round publicly verifiable asymmetric key agreement, called 1PVAKA, a new primitive formalized in this work. Unlike traditional distributed key generation protocols where users interact with one another, 1PVAKA is asynchronous and allows a third party to verify and generate a public key from users' outputs.

We discuss 1PVAKA and dARKG instantiations tailored for use with bilinear groups and demonstrate practicality with implementation and performance analysis for the BLS12-381 curve.
]]></content:encoded>
<pubDate>Wed, 29 May 2024 12:50:55 +0000</pubDate>
</item>
<item>
<title>Verified Foundations for Differential Privacy</title>
<link>https://eprint.iacr.org/2024/2040</link>
<guid>https://eprint.iacr.org/2024/2040</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私（DP）、SampCert、机械验证、Laplace采样、Gaussian采样

总结:
SampCert 是首个针对差分隐私的全面且机械化基础，它使用 Lean 编写了超过 12,000 行的证明代码。该框架提供了一个可针对不同DP定义（如纯DP、集中DP、Rényi DP）进行实例化的通用DP概念，以及用于构建和组合DP机制的框架。此外，SampCert还包含了经过形式化验证的离散Laplace和高斯采样算法，避免了浮点实现中的陷阱。其创新之处包括：(1) 支持多种DP定义的通用DP基础；(2) 正式验证的离散Laplace和Gaussian采样算法；(3) 简单的概率Monad及新颖的证明技术，简化了形式化过程。为了证明DP和随机数生成的复杂正确性属性，SampCert充分利用了Lean的广泛Mathlib库，利用傅里叶分析、测度与概率论、数论和拓扑等领域的定理。实际上，SampCert的经验证明算法已被应用于亚马逊网络服务(AWS)的DP产品中，显示出了其实际应用的影响。 <div>
Differential privacy (DP) has become the gold standard for privacy-preserving data analysis, but implementing
it correctly has proven challenging. Prior work has focused on verifying DP at a high level, assuming the
foundations are correct and a perfect source of randomness is available. However, the underlying theory of
differential privacy can be very complex and subtle. Flaws in basic mechanisms and random number generation
have been a critical source of vulnerabilities in real-world DP systems.

In this paper, we present SampCert, the first comprehensive, mechanized foundation for differential privacy.
SampCert is written in Lean with over 12,000 lines of proof. It offers a generic and extensible notion of DP, a
framework for constructing and composing DP mechanisms, and formally verified implementations of Laplace
and Gaussian sampling algorithms. SampCert provides (1) a mechanized foundation for developing the next
generation of differentially private algorithms, and (2) mechanically verified primitives that can be deployed in
production systems. Indeed, SampCert’s verified algorithms power the DP offerings of Amazon Web Services
(AWS), demonstrating its real-world impact.

SampCert’s key innovations include: (1) A generic DP foundation that can be instantiated for various DP
definitions (e.g., pure, concentrated, Rényi DP); (2) formally verified discrete Laplace and Gaussian sampling
algorithms that avoid the pitfalls of floating-point implementations; and (3) a simple probability monad and
novel proof techniques that streamline the formalization. To enable proving complex correctness properties of
DP and random number generation, SampCert makes heavy use of Lean’s extensive Mathlib library, leveraging
theorems in Fourier analysis, measure and probability theory, number theory, and topology.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 02:45:39 +0000</pubDate>
</item>
<item>
<title>Multilateral Trade Credit Set-off in MPC via Graph Anonymization and Network Simplex</title>
<link>https://eprint.iacr.org/2024/2037</link>
<guid>https://eprint.iacr.org/2024/2037</guid>
<content:encoded><![CDATA[
<div> 关键词: 多边贸易信用对冲 (MTCS), 隐私保护, 最小成本流问题 (MCF), 图匿名化, 网络单纯形算法

总结:
本文提出了一种针对多边贸易信用对冲(MTCS)的协议，该协议旨在保护参与公司的敏感数据，如债务金额和交易伙伴身份。传统的方法，即安全最小成本流问题(MCF)，其通信复杂度为$O(n^{10}\log n)$，不适用于大规模实例。我们的解决方案利用了新颖的安全技术，包括图匿名化和网络单纯形算法，将MCF问题的复杂度降低到$O(max(n,\ log\log{n+m}))$轮交互每执行一次枢轴操作，并在此过程中执行$O(max(n^2,\ nm))$次比较和乘法运算。实验结果表明了隐私保护与最优解之间的权衡关系。 <div>
Multilateral Trade Credit Set-off (MTCS) is a process run by a service provider that collects trade credit data (i.e. obligations from a firm to pay another firm) from a network of firms and detects cycles of debts that can be removed from the system. The process yields liquidity savings for the participants, who can discharge their debts without relying on expensive loans. We propose an MTCS protocol that protects firms' sensitive data, such as the obligation amount or the identity of the firms they trade with. Mathematically, this is analogous to solving the Minimum Cost Flow (MCF) problem over a graph of $n$ firms, where the $m$ edges are the obligations. State-of-the-art techniques for Secure MCF have an overall complexity of $O(n^{10} \log n)$ communication rounds, making it barely applicable even to small-scale instances. Our solution leverages novel secure techniques such as Graph Anonymization and Network Simplex to reduce the complexity of the MCF problem to $O(max(n, \log\log{n+m}))$ rounds of interaction per pivot operations in which $O(max(n^2, nm))$ comparisons and multiplications are performed. Experimental results show the tradeoff between privacy and optimality.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 15:59:02 +0000</pubDate>
</item>
<item>
<title>Janus: Fast Privacy-Preserving Data Provenance For TLS</title>
<link>https://eprint.iacr.org/2023/1377</link>
<guid>https://eprint.iacr.org/2023/1377</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据收集、隐私保护、TLS或acles、零知识证明、TLS 1.3

总结:
本文提出了一种新的隐私保护TLS预言机协议，该协议能够在大规模上选择性地验证敏感网络数据的来源。文章创新点在于采用诚实验证者零知识证明系统，在不对称隐私环境中确保安全性，同时对抗恶意对手。针对TLS 1.3，文章优化了“混淆后证明”的范式，在处理恶意敌手的安全设置中，展示了TLS 1.3的一种特殊操作模式，允许在混淆阶段的大多数计算中使用半诚实安全计算而不需认证混淆。通过这些性能改进，新方案达到了验证私人数据源的新效率水平，从而促进了隐私保护TLS预言机在web浏览器中的实际部署。<br /><br /> <div>
Web users can gather data from secure endpoints and demonstrate the provenance of sensitive data to any third party by using privacy-preserving TLS oracles. In practice, privacy-preserving TLS oracles remain limited and cannot selectively verify larger sensitive data sets. In this work, we introduce a new oracle protocol, which reaches new scales in selectively verifying the provenance of confidential web data. The novelty of our work is a construction which deploys an honest verifier zero-knowledge proof system in the asymmetric privacy setting while retaining security against malicious adversaries. Concerning TLS 1.3, we optimize the garble-then-prove paradigm in a security setting with malicious adversaries. Here, we show that a specific operation mode of TLS 1.3 allows to use semi-honest secure computations without authentic garbling for the majority of computations in the garble phase. Our performance improvements reach new efficiency scales in verifying private data provenance and facilitate the practical deployment of privacy-preserving TLS oracles in web browsers.
]]></content:encoded>
<pubDate>Thu, 14 Sep 2023 12:04:35 +0000</pubDate>
</item>
<item>
<title>Impact Tracing: Identifying the Culprit of  Misinformation in Encrypted Messaging Systems</title>
<link>https://eprint.iacr.org/2024/2027</link>
<guid>https://eprint.iacr.org/2024/2027</guid>
<content:encoded><![CDATA[
<div> 关键词：加密消息系统、内容审核、影响追踪、隐私保护、非影响力用户<br /><br />总结: 这篇文章主要探讨了加密消息系统中如何在保障用户隐私的同时有效抵制错误信息传播的问题。文章提出了“影响追踪”的新方法，旨在追踪对错误信息传播有重大影响的用户，同时为非影响力用户提供隐私保护。文中描述了一种添加噪声的技术手段来隐藏非影响力用户的身份，证明这种方法不会妨碍识别影响力传播者，并确保了非影响力用户的差分隐私保护。通过定义三个评估指标并在真实数据集上进行实验，结果显示该方案能以高达82%至99%的准确率识别最具影响力的传播者，而且每条消息仅需平台存储额外的6字节空间，同时保持低延迟（＜0.25毫秒）。 <div>
Encrypted messaging systems obstruct content moderation, although they provide end-to-end security. As a result, misinformation proliferates in these systems, thereby exacerbating online hate and harassment. The paradigm of ``Reporting-then-Tracing" shows great potential in mitigating the spread of misinformation. For instance, message traceback (CCS'19) traces all the dissemination paths of a message, while source tracing (CCS'21) traces its originator. However, message traceback lacks privacy preservation for non-influential users (e.g., users who only receive the message once), while source tracing maintains privacy but only provides limited traceability.

In this paper, we initiate the study of impact tracing. Intuitively, impact tracing traces influential spreaders central to disseminating misinformation while providing privacy protection for non-influential users. We introduce noises to hide non-influential users and demonstrate that these noises do not hinder the identification of influential spreaders. Then, we formally prove our scheme's security and show it achieves differential privacy protection for non-influential users. Additionally, we define three metrics to evaluate its traceability, correctness, and privacy using real-world datasets. The experimental results show that our scheme identifies the most influential spreaders with accuracy from 82% to 99% as the amount of noise varies. Meanwhile, our scheme requires only a 6-byte platform storage overhead for each message while maintaining a low messaging latency (< 0.25ms).
]]></content:encoded>
<pubDate>Sat, 14 Dec 2024 07:20:05 +0000</pubDate>
</item>
<item>
<title>Mira: Efficient Folding for Pairing-based Arguments</title>
<link>https://eprint.iacr.org/2024/2025</link>
<guid>https://eprint.iacr.org/2024/2025</guid>
<content:encoded><![CDATA[
<div> 关键词：pairing-based arguments、Groth16 SNARKs、KZG polynomial commitments、folding scheme、Mira

总结:
本文介绍了Mira，一种针对配对基础论证的新型折叠方案，旨在解决证明聚合的成本问题。现有的构造方法将配对操作编码到通用约束系统中，导致证明者开销较高。Mira通过扩展Protostar框架以支持更广泛的特殊声学协议类来实现这一目标。应用示例表明，Mira在Groth16证明聚合和可验证机器学习推理方面展现出高效性和灵活性，其相比于现有最先进的证明聚合系统实现了5.8倍的更快prove时间以及9.7倍的更低内存使用量，同时保持了常数大小的证明。此外，为了提高可验证机器学习推理的效率，文章还提出了一种新的lincheck协议，其验证器度独立于矩阵顺序，使得Mira能够有效地扩展到更大的模型，克服了当前方案中的内存瓶颈。 <div>
Pairing-based arguments offer remarkably small proofs and space-efficient provers, but aggregating such proofs remains costly. Groth16 SNARKs and KZG polynomial commitments are prominent examples of this class of arguments. These arguments are widely deployed in decentralized systems, with millions of proofs generated per day. Recent folding schemes have greatly reduced the cost of proving incremental computations, such as batch proof verification. However, existing constructions require encoding pairing operations in generic constraint systems, leading to high prover overhead. In this work, we introduce Mira, a folding scheme that directly supports pairing-based arguments. We construct this folding scheme by generalizing the framework in Protostar to support a broader class of special-sound protocols. We demonstrate the versatility and efficiency of this framework through two key applications: Groth16 proof aggregation and verifiable ML inference. Mira achieves 5.8x faster prover time and 9.7x lower memory usage than the state-of-the-art proof aggregation system while maintaining a constant-size proof. To improve the efficiency of verifiable ML inference, we provide a new lincheck protocol with a verifier degree that is independent of the matrix order. We show that Mira scales effectively to larger models, overcoming the memory bottlenecks of current schemes.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 21:58:09 +0000</pubDate>
</item>
<item>
<title>Derecho: Privacy Pools with Proof-Carrying Disclosures</title>
<link>https://eprint.iacr.org/2023/273</link>
<guid>https://eprint.iacr.org/2023/273</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私池、Tornado Cash、美国财政部、Derecho、证明携带数据

总结:<br />
本文介绍了隐私池的概念及其可能被用于隐藏资金来源的问题，特别是在美国财政部制裁了最大的以太坊隐私池Tornado Cash之后，该池被指控为朝鲜支持的Lazarus集团洗钱超过4.55亿美元。这一裁决使得美国个人和机构接收或使用经过Tornado Cash的资金成为非法行为。针对此背景，文章提出了名为Derecho的新系统。Derecho利用证明携带数据技术，使用户能够在隐私池的交易图中传播允许列表成员资格的证明，从而让机构可以请求基金来源的加密证明而非简单地拒绝来自隐私池的所有资金。Derecho系统与现有的以太坊隐私池设计向后兼容，不会增加gas成本，并且用户生成证明仅需花费几秒钟时间。 <div>
A privacy pool enables clients to deposit units of a cryptocurrency into a shared pool where ownership of deposited currency is tracked via a system of cryptographically hidden records. Clients may later withdraw from the pool without linkage to previous deposits. Some privacy pools also support hidden transfer of currency ownership within the pool. In August 2022, the U.S. Department of Treasury sanctioned Tornado Cash, the largest Ethereum privacy pool, on the premise that it enables illicit actors to hide the origin of funds, citing its usage by the DPRK-sponsored Lazarus Group to launder over \$455 million dollars worth of stolen cryptocurrency. This ruling effectively made it illegal for U.S. persons/institutions to use or accept funds that went through Tornado Cash, sparking a global debate among privacy rights activists and lawmakers. Against this backdrop, we present Derecho, a system that institutions could use to request cryptographic attestations of fund origins rather than naively rejecting all funds coming from privacy pools. Derecho is a novel application of proof-carrying data, which allows users to propagate allowlist membership proofs through a privacy pool's transaction graph. Derecho is backwards-compatible with existing Ethereum privacy pool designs, adds no overhead in gas costs, and costs users only a few seconds to produce attestations.
]]></content:encoded>
<pubDate>Thu, 23 Feb 2023 20:59:36 +0000</pubDate>
</item>
<item>
<title>Hash-Prune-Invert: Improved Differentially Private Heavy-Hitter Detection in the Two-Server Model</title>
<link>https://eprint.iacr.org/2024/2024</link>
<guid>https://eprint.iacr.org/2024/2024</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私(DP)，重 hitter 检测，错误边际(Δ)，服务器协同计算，hash-prune-invert (HPI)

总结:
文章介绍了一种针对大规模数据域(d)下的差分隐私重 hitter 检测新方法——hash-prune-invert (HPI) 技术。现有的多服务器协同计算协议在效率（计算、通信和轮复杂度）与准确性（即错误边际）上对 log(d) 有依赖性，不适合处理大型数据域。而 HPI 技术可以将具有上述问题的重 hitter 协议转化为一个新的协议，使得计算、通信和轮复杂度大致依赖于 log(n) 而非 log(d)，并且错误边际不再依赖于数据域大小 d。此外，该转换还保持了在最多一个服务器被恶意攻击者篡改以及任意数量客户端的情况下，依然能保证隐私安全。文中还将 HPI 应用于改进版的 Poplar 算法，使 Poplar 的错误边际提高了大约 n 的平方根倍（与 d 无关）。实验结果显示，由此产生的新协议在大 d 情况下显著提升了效率和准确性。 <div>
Differentially private (DP) heavy-hitter detection is an important primitive for  data analysis. Given a threshold $t$ and a dataset of $n$ items from a domain of size $d$, such detection algorithms ignore items occurring fewer than $t$ times while identifying items occurring more than $t+\Delta$ times; we call $\Delta$ the error margin. In the central model where a curator holds the entire dataset, $(\varepsilon,\delta)$-DP algorithms can achieve error margin $\Theta(\frac 1 \varepsilon \log \frac 1 \delta)$, which is optimal when $d \gg 1/\delta$.
    
    Several works, e.g., Poplar (S&amp;P 2021), have proposed protocols in which two or more non-colluding servers jointly compute the heavy hitters from inputs held by $n$ clients. Unfortunately, existing protocols suffer from an undesirable dependence on $\log d$ in terms of both server efficiency (computation, communication, and round complexity) and accuracy (i.e., error margin), making them unsuitable for large domains (e.g., when items are kB-long strings, $\log d \approx 10^4$).
    
    We present hash-prune-invert (HPI), a technique for compiling any heavy-hitter protocol with the $\log d$ dependencies mentioned above into a new protocol with improvements across the board: computation, communication, and round complexity depend (roughly) on $\log n$ rather than $\log d$, and the error margin is independent of $d$. Our transformation preserves privacy against an active adversary corrupting at most one of the servers and any number of clients. We apply HPI to an improved version of Poplar, also introduced in this work, that improves Poplar's error margin by roughly a factor of $\sqrt{n}$ (regardless of $d$). Our experiments confirm that the resulting protocol improves efficiency and accuracy for large $d$.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 20:56:38 +0000</pubDate>
</item>
<item>
<title>PrivQuant: Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization</title>
<link>https://eprint.iacr.org/2024/2021</link>
<guid>https://eprint.iacr.org/2024/2021</guid>
<content:encoded><![CDATA[
<div> 关键词: 私有深度神经网络、安全两方计算、通信效率、 PrivQuant、协议优化

总结:

 PrivQuant是一个针对私有深度神经网络(DNN)推理的安全两方计算(2PC)框架，旨在提升隐私保护的同时降低高延迟问题。该框架通过同时优化基于2PC的量化推理协议和网络量化算法，实现更高效的通信私密推断。具体来说，PrivQuant针对通信密集型量化运算符提出了DNN架构感知的优化方案，并进行了图级操作器融合以减少通信量。此外，它还开发了一种通信感知的混合精度量化算法，旨在提高推断效率并保持高准确性。通过网络/协议协同优化，PrivQuant相比于现有2PC框架如SiRNN、COINN和CoPriv，显著降低了通信量（分别减少了11倍、2.5倍和2.8倍），进而将延迟减少了8.7倍、1.8倍和2.4倍。 <div>
Private deep neural network (DNN) inference based on secure two-party computation (2PC) enables secure privacy protection for both the server and the client. However, existing secure 2PC frameworks suffer from a high inference latency due to enormous communication. As the communication of both linear and non-linear DNN layers reduces with the bit widths of weight and activation, in this paper, we propose PrivQuant, a framework that jointly optimizes the 2PC-based quantized inference protocols and the network quantization algorithm, enabling communication-efficient private inference. PrivQuant proposes DNN architecture-aware optimizations for the 2PC protocols for communication-intensive quantized operators and conducts graph-level operator fusion for communication reduction. Moreover, PrivQuant also develops a communication-aware mixed precision quantization algorithm to improve the inference efficiency while maintaining high accuracy. The network/protocol co-optimization enables PrivQuant to outperform prior-art 2PC frameworks. With extensive experiments, we demonstrate PrivQuant reduces communication by $11\times, 2.5\times \mathrm{and}~  2.8\times$, which results in $8.7\times, 1.8\times ~ \mathrm{and}~ 2.4\times$ latency reduction compared with SiRNN, COINN, and CoPriv, respectively.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 13:51:36 +0000</pubDate>
</item>
<item>
<title>On the BUFF Security of ECDSA with Key Recovery</title>
<link>https://eprint.iacr.org/2024/2018</link>
<guid>https://eprint.iacr.org/2024/2018</guid>
<content:encoded><![CDATA[
<div> 关键词: ECDSA，key recovery，BUFF安全，弱非重签性，Ethereum地址

总结:
本文探讨了使用密钥恢复的椭圆曲线数字签名算法（KR-ECDSA）的安全性，特别是在Ethereum环境下的Beyond UnForgeability Features（BUFF）安全。研究结果显示，KR-ECDSA提供了BUFF安全性，但存在弱非重签性（wNR）问题。文中指出，KR-ECDSA验证算法需要输入以太坊地址addr，该地址由对应的ECDSA验证密钥通过Keccak-256哈希计算得到的右起160位组成，并检查恢复的验证密钥的哈希值是否等于addr，这是保证BUFF安全性的必要条件。此外，文章分析表明原始ECDSA不提供任何BUFF安全性，并揭示了一个针对Aumayr等人提出的基于ECDSA的适配器签名方案的攻击，此攻击超出了其安全模型范围。 <div>
In the usual syntax of digital signatures, the verification algorithm takes a verification key in addition to a signature and a message, whereas in ECDSA with key recovery, which is used in Ethereum,  no verification key is input to the verification algorithm. Instead, a verification key is recovered from a signature and a message. In this paper, we explore BUFF security of ECDSA with key recovery (KR-ECDSA), where BUFF stands for Beyond UnForgeability Features (Cremers et al., IEEE S&amp;P 2021).  As a result, we show that KR-ECDSA provides BUFF security, except weak non-resignability (wNR). We pay attention to that the verification algorithm of KR-ECDSA takes an Ethereum address addr as input, which is defined as the rightmost 160-bits of the Keccak-256 hash of the corresponding ECDSA verification key, and checks the hash value of the recovered verification key is equal to addr.  Our security analysis shows that this procedure is mandatory to provide BUFF security. We also discuss whether wNR is mandatory in Ethereum or not.  To clarify the above equality check is mandatory to provide BUFF security in KR-ECDSA, we show that the original ECDSA does not provide any BUFF security. As a by-product of the analysis, we show that one of our BUFF attacks also works against the Aumayr et al.'s ECDSA-based adaptor signature scheme (ASIACRYPT 2021). We emphasize that the attack is positioned outside of their security model.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 05:56:52 +0000</pubDate>
</item>
<item>
<title>Byzantine Consensus in Wireless Networks</title>
<link>https://eprint.iacr.org/2024/2017</link>
<guid>https://eprint.iacr.org/2024/2017</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine共识协议、无线网络、分布式系统、可靠广播协议、部分同步

总结:
本文提出了一种新的可靠广播协议，该协议在故障容忍度方面超过了当前最先进的技术(PODC '05)。在此基础上，文章进一步开发了首个适用于无线网络的部分同步环境下的拜占庭共识协议。这个新的共识协议不再需要领导者和故障转移机制。作者对新提出的广播协议和共识协议的正确性进行了正式证明。这表明，在无线网络中实现高容错性的共识同样重要，并为该领域的研究带来了创新突破。 <div>
A Byzantine consensus protocol is essential in decentralized systems as the protocol ensures system consistency despite node failures.
Research on consensus in wireless networks receives relatively less attention, while significant advancements in wired networks.
However, consensus in wireless networks has equal significance as in wired networks.

In this paper, we propose a new reliable broadcast protocol that can achieve reliability with high fault tolerance over than the SOTA (PODC '05). With the new protocol, we further develop the first wireless network Byzantine consensus protocol under the assumption of partial synchrony. Notably, this consensus protocol removes the requirement of leaders and fail-over mechanism in prior works. We formally prove the correctness of both our new broadcast protocol and consensus protocol.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 04:46:33 +0000</pubDate>
</item>
<item>
<title>Crescent: Stronger Privacy for Existing Credentials</title>
<link>https://eprint.iacr.org/2024/2013</link>
<guid>https://eprint.iacr.org/2024/2013</guid>
<content:encoded><![CDATA[
<div> 关键词: Crescent、隐私保护凭证、零知识证明、选择性披露、unlinkability

总结:
Crescent是一个旨在提升现有凭证（如JSON Web Tokens (JWTs)和Mobile Driver's License (mDL)）隐私特性的系统实现。该系统无需新的发证方即可通过使用零知识证明技术来实现凭证的选择性披露和不可链接性等功能。Crescent具备实际应用性能，能在一次性的凭证设置阶段后提供快速的证明生成和验证时间（数十毫秒）。文中展示了两个实用场景的演示：基于雇主颁发JWT的福利资格证明以及基于mDL的在线年龄验证。此外，他们提供了开源实现以促进进一步的研究与实验，相关代码库可在https://github.com/microsoft/crescent-credentials找到。 <div>
We describe Crescent, a construction and implementation of privacy-preserving credentials. The system works by upgrading the privacy features of existing credentials, such as JSON Web Tokens (JWTs) and Mobile Driver’s License (mDL) and as such does not require a new party to issue credentials. By using zero-knowledge proofs of possession of these credentials, we can add privacy features such as selective disclosure and unlinkability, without help from credential issuers. The system has practical performance, offering fast proof generation and verification times (tens of milliseconds) after a once-per-credential setup phase. We give demos for two practical scenarios, proof of employment for benefits eligibility (based on an employer-issued JWT), and online age verification (based on an mDL). We provide an open-source implementation to enable further research and experimentation.

This paper is an early draft describing our work, aiming to include enough material to describe the functionality, and some details of the internals of our new library, available at https://github.com/microsoft/crescent-credentials.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 01:42:20 +0000</pubDate>
</item>
<item>
<title>GraSS: Graph-based Similarity Search on Encrypted Query</title>
<link>https://eprint.iacr.org/2024/2012</link>
<guid>https://eprint.iacr.org/2024/2012</guid>
<content:encoded><![CDATA[
<div> 关键词：相似性搜索、图基方法、全同态加密（FHE）、客户端隐私、服务器隐私

总结:
我们提出了一种名为GraSS的安全协议，用于基于全同态加密（FHE）实现客户端（查询拥有者）和服务器端（数据集拥有者）之间的图基相似性搜索。该协议能够在基于FHE的安全假设下保证客户端输入对服务器的隐私以及服务器输入对客户端的隐私。为了提高可扩展性和降低计算复杂度，我们设计了一个对FHE友好的图结构及新颖的索引编码方法，将邻域检索过程的时间复杂度从$O(n^2)$降低到$\tilde{O}(n)$，其中n为总节点数。同时，我们还提出了几项核心的FHE算法，用于在新的图结构下执行图操作。最后，我们实现了完整的GraSS解决方案，这是首个基于FHE的安全图基数据库搜索方案。经过实测，GraSS在百万规模的数据集上可以在约83小时内找到近似的前16名结果，准确率达到0.918，比此前已知的最佳FHE方案快了超过28倍。 <div>
Similarity search, i.e., retrieving vectors in a database that are similar to a query, is the backbone of many applications. Especially, graph-based methods show state-of-the-art performance. For sensitive applications, it is critical to ensure the privacy of the query and the dataset.

In this work, we introduce GraSS, a secure protocol between client (query owner) and server (dataset owner) for graph-based similarity search based on fully homomorphic encryption (FHE).  Both the client-input privacy against the server and the server-input privacy against the client are achievable based on underlying security assumptions on FHE.

We first propose an FHE-friendly graph structure with a novel index encoding method that makes our protocol highly scalable in terms of data size, reducing the computational complexity of neighborhood retrieval process from $O(n^2)$ to $\tilde{O}(n)$ for the total number of nodes $n$. We also propose several core FHE algorithms to perform graph operations under the new graph structure. Finally, we introduce GraSS, an end-to-end solution of secure graph-based similarity search based on FHE. To the best of our knowledge, it is the first FHE-based solution for secure graph-based database search.

We implemented GraSS with an open-source FHE library and estimated the performance on a million-scale dataset. GraSS identifies (approximate) top-16 in about $83$ hours achieving search accuracy of $0.918$, making it over $28\times$ faster than the previous best-known FHE-based solution.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:11:45 +0000</pubDate>
</item>
<item>
<title>Anonymous credentials from ECDSA</title>
<link>https://eprint.iacr.org/2024/2010</link>
<guid>https://eprint.iacr.org/2024/2010</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名数字凭证、大规模部署、BBS+、ECDSA、零知识证明

总结:<br />
本文提出了一种新的匿名数字凭证方案，该方案针对广泛应用且具有大量历史部署的椭圆曲线数字签名算法（ECDSA）进行设计。此方案无需改变身份发行者的现有流程，不需对移动设备进行硬件安全元素和操作系统的更新，也不依赖非标准的密码学假设，从而解决了大规模部署匿名凭证体系面临的困难。为了实现这一目标，文章通过采用基于sumcheck和Ligero论证系统的零知识证明方法，设计了适用于ECDSA所需的有限域上的高效Reed-Solomon编码方法以及专门的电路。生成ECDSA的零知识证明只需60毫秒，在结合ISO标准化的身份协议如MDOC标准后，可在移动设备上根据凭证大小在1.2秒内生成MDOC展示流程的零知识证明。因此，该方案被认为是隐私保护型数字身份应用的一个有前景的候选方案。 <div>
Anonymous digital credentials allow a user to prove possession of an attribute that has been asserted by an identity issuer without revealing any extra information about themselves.  For example, a user who has received a digital passport credential can prove their “age is $>18$” without revealing any other attributes such as their name or date of birth.

    Despite inherent value for privacy-preserving authentication, anonymous credential schemes have been difficult to deploy at scale.  Part of the difficulty arises because schemes in the literature, such as BBS+, use new cryptographic assumptions that require system-wide changes to existing issuer infrastructure.  In addition,  issuers often require digital identity credentials to be *device-bound* by incorporating the device’s secure element into the presentation flow.  As a result, schemes like BBS+ require updates to the hardware secure elements and OS on every user's device.
    
    In this paper, we propose a new anonymous credential scheme for the popular and legacy-deployed Elliptic Curve Digital Signature Algorithm (ECDSA) signature scheme.  By adding efficient zk arguments for statements about SHA256 and document parsing for ISO-standardized identity formats, our anonymous credential scheme is that first one that can be deployed *without* changing any issuer processes, *without* requiring changes to mobile devices, and *without* requiring non-standard cryptographic assumptions.

    Producing ZK proofs about ECDSA signatures has been a bottleneck for other ZK proof systems because standardized curves such as P256 use finite fields which do not support efficient number theoretic transforms.  We overcome this bottleneck by designing a ZK proof system around sumcheck and the Ligero argument system, by designing efficient methods for Reed-Solomon encoding over the required fields, and by designing specialized circuits for ECDSA.
        
    Our proofs for ECDSA can be generated in 60ms.  When incorporated into a fully standardized identity protocol such as the ISO MDOC standard, we can generate a zero-knowledge proof for the MDOC presentation flow in 1.2 seconds on mobile devices depending on the credential size. These advantages make our scheme a promising candidate for privacy-preserving digital identity applications.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 18:49:06 +0000</pubDate>
</item>
<item>
<title>PrivCirNet: Efficient Private Inference via Block Circulant Transformation</title>
<link>https://eprint.iacr.org/2024/2008</link>
<guid>https://eprint.iacr.org/2024/2008</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption (HE), Deep Neural Network (DNN), Circulant Matrices, PrivCirNet, Computation Overhead

总结:
本文提出了一种名为PrivCirNet的新框架，该框架基于块循环变换对同态加密（HE）下的深度神经网络（DNN）推理进行了协议与网络的联合优化。通过将DNN权重转化为循环矩阵，可以将一般的矩阵向量乘法转换为HE友好的一维卷积，显著降低了HE计算成本。在协议层面，PrivCirNet定制了与块循环变换完全兼容的HE编码算法，能够按块大小比例减少计算延迟。在网络层面，文章提出了一个基于二阶信息的延迟感知公式来搜索各层的块大小分配，并利用层融合进一步降低推理成本。实验结果表明，相比于最先进的HE基框架Bolt和HE友好剪枝方法SpENCNN，PrivCirNet在ResNet-18和Vision Transformer (ViT)在Tiny ImageNet上的推理延迟分别减少了5.0倍和1.3倍，同时保持了相同的精度水平，并在准确性上分别提升了4.1%和12%。对于MobileNetV2在ImageNet上的任务，PrivCirNet实现了比Bolt和SpENCNN低1.7倍的延迟以及更高的4.2%准确率。项目代码和检查点已在https://github.com/Tianshi-Xu/PrivCirNet开源。 <div>
Homomorphic encryption (HE)-based deep neural network (DNN) inference protects data and model privacy but suffers from significant computation overhead. We observe transforming the DNN weights into circulant matrices converts general matrix-vector multiplications into HE-friendly 1-dimensional convolutions, drastically reducing the HE computation cost. Hence, in this paper, we propose PrivCirNet, a protocol/network co-optimization framework based on block circulant transformation. At the protocol level, PrivCirNet customizes the HE encoding algorithm that is fully compatible with the block circulant transformation and reduces the computation latency in proportion to the block size. At the network level, we propose a latency-aware formulation to search for the layer-wise block size assignment based on second-order information. PrivCirNet also leverages layer fusion to further reduce the inference cost. We compare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S&amp;P 2024) and HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and Vision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by $5.0\times$ and $1.3\times$ with iso-accuracy over Bolt, respectively, and improves accuracy by $4.1\%$ and $12\%$ over SpENCNN, respectively. For MobileNetV2 on ImageNet, PrivCirNet achieves $1.7\times$ lower latency and $4.2\%$ better accuracy over Bolt and SpENCNN, respectively. 
    Our code and checkpoints are available at https://github.com/Tianshi-Xu/PrivCirNet.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 14:46:10 +0000</pubDate>
</item>
<item>
<title>Xiezhi: Toward Succinct Proofs of Solvency</title>
<link>https://eprint.iacr.org/2024/2001</link>
<guid>https://eprint.iacr.org/2024/2001</guid>
<content:encoded><![CDATA[
<div> 关键词: 证明清偿能力、零知识证明、中心化加密货币交易所、验证时间、bls12-381

总结:
本文提出了改进中心化加密货币交易所的证明清偿能力方案，旨在提供一种快速（几分钟）、体积小（KB级）和验证快捷（几秒钟）的全程端到端论证。文章关注的重点包括：一是提出并实现这样一个优化的证明系统；二是针对比特币与以太坊不同的密码学环境（如secp256k1曲线与更为理想的简洁性设置，如配对密码学），采用了一种新颖的映射方法来处理两者间的自然冲突；三是讨论了如何将该协议适应于具体参数为bls12-381的情况，因为对于规模稍大的交易所，所有用户余额的位分解将会超过该曲线的最大单位根。 <div>
A proof of solvency (or proof of reserves) is a zero-knowledge proof conducted by centralized cryptocurrency exchange to offer evidence that the exchange owns enough cryptocurrency to settle each of its users' balances. The proof seeks to reveal nothing about the finances of the exchange or its users, only the fact that it is solvent. The literature has already started to explore how to make proof size and verifier time independent of the number of (i) users on the exchange, and (ii) addresses used by the exchange. We argue there are a few areas of improvement. First, we propose and implement a full end-to-end argument that is fast for the exchange to prove (minutes), small in size (KBs), and fast to verify (seconds). Second, we deal with the natural conflict between Bitcoin and Ethereum's cryptographic setting (secp256k1) and more ideal settings for succinctness (e.g., pairing-based cryptography) with a novel mapping approach. Finally, we discuss how to adapt the protocol to the concrete parameters of bls12-381 (which is relevant because the bit-decomposition of all user balances will exceed the largest root of unity of the curve for even moderately-sized exchanges).
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 21:55:31 +0000</pubDate>
</item>
<item>
<title>BitVM: Quasi-Turing Complete Computation on Bitcoin</title>
<link>https://eprint.iacr.org/2024/1995</link>
<guid>https://eprint.iacr.org/2024/1995</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、比特币脚本、计算能力、虚拟机、BitVM

总结:
本文针对区块链社区长期存在的一个问题进行了研究，即在具有有限脚本语言（如比特币脚本）的加密货币中，哪些类型的计算能够得到有效表达。文章首次证明了无需修改现有语言或依赖额外安全假设（例如可信硬件、可信方或安全多数委员会），任意计算可以在今天的比特币脚本中被编码。为此，提出了$\mathsf{BitVM}$，这是一个结合了密码学和激励机制的两方协议，实现了一个通用虚拟机。对$\mathsf{BitVM}$进行了形式化分析，明确了其功能、系统假设及安全性属性。同时，文章还展示了该方法的实用性：在乐观情况下，只需三次链上交易即可完成协议执行；而在悲观情况下，交易数量随着虚拟机规模的增长呈对数级增加。这项工作不仅解决了长期以来的理论问题，而且还对实践产生了强烈影响，为在比特币中开发复杂应用开辟了新的可能。 <div>
A long-standing question in the blockchain community is which class of computations are efficiently expressible in cryptocurrencies with limited scripting languages, such as Bitcoin Script. Such languages expose a reduced trusted computing base, thereby being less prone to hacks and vulnerabilities, but have long been believed to support only limited classes of payments.

In this work, we confute this long-standing belief by showing for the first time that arbitrary computations can be encoded in today's Bitcoin Script, without introducing any language modification or additional security assumptions, such as trusted hardware, trusted parties, or committees with secure majority. In particular, we present $\mathsf{BitVM}$, a two-party protocol realizing a generic virtual machine by a combination of cryptographic and incentive mechanisms. We conduct a formal analysis of $\mathsf{BitVM}$, characterizing its functionality, system assumptions, and security properties. We further demonstrate the practicality of our approach:  in the optimistic case (i.e., in the absence of disputes between parties), our protocol requires just three on-chain transactions, whereas in the pessimistic case, the number of transactions grows logarithmically with the size of the virtual machine.  This work not only solves a long-standing theoretical problem, but it also promises a strong practical impact, enabling the development of complex applications in Bitcoin.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 21:56:17 +0000</pubDate>
</item>
<item>
<title>UTRA: Universe Token Reusability Attack and Verifiable Delegatable Order-Revealing Encryption</title>
<link>https://eprint.iacr.org/2024/1983</link>
<guid>https://eprint.iacr.org/2024/1983</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据集增长、隐私保护、加密数据、委托可揭示加密、安全可揭示加密

总结:
随着数据集的增长，用户在本地机器上处理任务面临困难，同时对数据泄漏的隐私关注导致数据拥有者将加密数据上传至云端并使用安全范围查询。为了解决这些问题，出现了针对大量数值数据的可揭示排序加密（ORE），并在多客户端环境中进一步发展出了委托可揭示加密（DORE）。然而，存在安全风险，即未经授权的用户可能利用授权令牌进行未授权的数据操作。因此，提出了安全可揭示加密方案（SEDORE）和高效的委托可揭示加密（EDORE）。尽管SEDORE和EDORE旨在抵御这类攻击，但我们发现它们仍存在相同威胁模型下的漏洞。为此，我们提出了验证性委托可揭示加密（VDORE），通过使用Schnorr签名方案验证用户发送的令牌的有效性，以防止此类攻击。此外，VDORE的令牌生成算法相比SEDORE提供了大约1.5倍的速度提升。 <div>
As dataset sizes continue to grow, users face increasing difficulties in performing processing tasks on their local machines. From this, privacy concerns about data leakage have led data owners to upload encrypted data and utilize secure range queries to cloud servers. 
To address these challenges, order-revealing encryption (ORE) has emerged as a promising solution for large numerical datasets. Building on this, delegatable order-revealing encryption (DORE) was introduced, allowing operations between encrypted datasets with different secret keys in multi-client ORE environments. DORE operates through authorization tokens issued by the data owner. However, security concerns had arisen about unauthorized users exploiting data without permission, leading to the development of a secure order-revealing encryption scheme (SEDORE). These attacks can result in unauthorized data access and significant financial losses in modern cloud service providers (CSPs) utilizing pay-per-query systems. In addition, efficient delegatable order-revealing encryption (EDORE), which improves speed and storage compared to SEDORE with identical security levels, was also introduced.
Although both SEDORE and EDORE were designed to be robust against these attacks, we have identified that they still retain the same vulnerabilities within the same threat model. To address these issues, we propose Verifiable Delegatable Order-Revealing Encryption (VDORE), which protects against attacks by using the Schnorr Signature Scheme to verify the validity of the token that users send. We propose a precise definition and robust proof to improve the unclear definition and insufficient proof regarding token unforgeability in the SEDORE.
Furthermore, the token generation algorithm in VDORE provides about a $1.5\times$ speed-up compared to SEDORE.
]]></content:encoded>
<pubDate>Sun, 08 Dec 2024 01:46:18 +0000</pubDate>
</item>
<item>
<title>Shutter Network: Private Transactions from Threshold Cryptography</title>
<link>https://eprint.iacr.org/2024/1981</link>
<guid>https://eprint.iacr.org/2024/1981</guid>
<content:encoded><![CDATA[
<div> 关键词: DeFi, 交易重排序攻击, 前序交易/夹心交易, MEV, Shutter网络<br /><br />总结:
随着DeFi的发展，基于交易重排序的攻击成为公共区块链面临的重要问题，如前序交易或夹心交易，攻击者通过操纵交易顺序影响金融资产市场价格，这种价值在以太坊生态系统中被称为矿工/最大可提取价值(MEV)，目前估计已超过13亿美元。为抵御MEV，一种有前景的方法是隐藏交易数据，使区块提议者无法根据交易内容选择执行顺序。本文描述了Shutter网络所采用的加密协议，该网络自2021年底以来已成为开源项目，并自2022年10月起投入生产运行。 <div>
With the emergence of DeFi, attacks based on re-ordering transactions have become an essential problem for public blockchains. Such attacks include front-running or sandwiching transactions, where the adversary places transactions at a particular place within a block to influence a financial asset’s market price. In the Ethereum space, the value extracted by such attacks is often referred to as miner/maximal extractable value (MEV), which to date is estimated to have reached a value of more than USD 1.3B. A promising approach to protect against MEV is to hide the transaction data so block proposers cannot choose the order in which transactions are executed based on the transactions’ content. This paper describes the cryptographic protocol underlying the Shutter network. Shutter has been available as an open-source project since the end of 2021 and has been running in production since Oct. 2022.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 21:34:08 +0000</pubDate>
</item>
<item>
<title>HI-CKKS: Is High-Throughput Neglected? Reimagining CKKS Efficiency with Parallelism</title>
<link>https://eprint.iacr.org/2024/1976</link>
<guid>https://eprint.iacr.org/2024/1976</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据外包, 云服务, 隐私保护, CKKS, Homomorphic加密, 性能优化, HI-CKKS, 吞吐量, 异步执行, (I)NTT 原语, 高性能实现, 数学模块指令集, 内存优化, 并行同态乘法

总结:<br />
随着数据外包和云服务的普及，隐私问题日益凸显。CKKS作为一种重要的全同态加密方案，可以在加密数据上进行计算，为隐私保护提供了关键保障。然而，其性能瓶颈限制了广泛应用。本文提出了HI-CKKS，一种面向吞吐量优化、高性能实现的CKKS全同态加密方案。HI-CKKS通过引入支持批处理的异步执行策略，有效缓解了主机与服务器间频繁的数据交互及等待延迟问题。同时，针对CKKS中的核心(I)NTT原语，开发了一种层次化、混合型高吞吐量实现方法，包括高效的算术模块指令集、统一内核融合以及混合内存优化策略。此外，还提出了一种多维度并行同态乘法方案，旨在最大化吞吐量并提升(I)NTT和同态乘法的性能。实验结果表明，HI-CKKS在RTX 4090显卡上实现了显著的吞吐量性能提升，与CPU实现相比，NTT、INTT和HMult的吞吐量分别提高了$175.08\times$、$191.27\times$和$679.57\times$；相较于最新的GPU基线工作，其吞吐量性能仍然表现出显著优势，提升幅度从$1.54\times$到$693.17\times$不等。 <div>
The proliferation of data outsourcing and cloud services has heightened privacy vulnerabilities. CKKS, among the most prominent homomorphic encryption schemes, allows computations on encrypted data, serving as a critical privacy safeguard. However, performance remains a central bottleneck, hindering widespread adoption. Existing optimization efforts often prioritize latency reduction over throughput performance. This paper presents HI-CKKS, a throughput-oriented High-performance Implementation of CKKS homomorphic encryption, addressing these challenges. Our HI-CKKS introduces a batch-supporting asynchronous execution scheme, effectively mitigating frequent data interactions and high waiting delays between hosts and servers in service-oriented scenarios. We analyze the fundamental (I)NTT primitive, which is critical in CKKS, and develop a hierarchical, hybrid high-throughput implementation. This includes efficient arithmetic module instruction set implementations, unified kernel fusion, and hybrid memory optimization strategies that significantly improve memory access efficiency and the performance of (I)NTT operations. Additionally, we propose a multi-dimensional parallel homomorphic multiplication scheme aimed at maximizing throughput and enhancing the performance of (I)NTT and homomorphic multiplication. In conclusion, our implementation is deployed on the RTX 4090, where we conduct a thorough throughput performance evaluation of HI-CKKS, enabling us to pinpoint the most effective parallel parameter settings. Compared to the CPU implementation, our system achieves throughput increases of $175.08\times$, $191.27\times$, and $679.57\times$ for NTT, INTT, and HMult, respectively. And our throughput performance still demonstrates a significant improvement, ranging from $1.54\times$ to $693.17\times$ compared to the latest GPU-based works.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 11:53:02 +0000</pubDate>
</item>
<item>
<title>Arke: Scalable and Byzantine Fault Tolerant Privacy-Preserving Contact Discovery</title>
<link>https://eprint.iacr.org/2023/1218</link>
<guid>https://eprint.iacr.org/2023/1218</guid>
<content:encoded><![CDATA[
<div> 关键词: Contact discovery, Arke, Privacy, Scalability, Byzantine fault tolerance

总结:
Arke是一种新型的联系人发现方法，旨在解决现有方案在隐私、可扩展性和对可信第三方依赖方面的局限性。Arke确保用户交互的不可链接性，减轻枚举攻击风险，并在无单一故障点或信任中心的情况下运行。它是首个性能与总用户数和能否在拜占庭环境中运行无关的联系人发现系统。Arke通过基于身份的非交互式密钥交换构建的unlinkable握手机制实现其隐私目标。利用定制的分布式架构，Arke能够在避免共识成本的同时实现可扩展性，同时在拜占庭容错环境中保持一致性。性能评估显示，Arke可以在全球规模上支持足够的吞吐量，同时在大型地理分布式设置中保持亚秒级延迟。 <div>
Contact discovery is a crucial component of social applications, facilitating interactions between registered contacts. This work introduces Arke, a novel approach to contact discovery that addresses the limitations of existing solutions in terms of privacy, scalability, and reliance on trusted third parties. Arke ensures the unlinkability of user interactions, mitigates enumeration attacks, and operates without single points of failure or trust. Notably, Arke is the first contact discovery system whose performance is independent of the total number of users and the first that can operate in a Byzantine setting. It achieves its privacy goals through an unlinkable handshake mechanism built on top of an identity-based non-interactive key exchange. By leveraging a custom distributed architecture, Arke forgoes the expense of consensus to achieve scalability while maintaining consistency in a Byzantine fault tolerant environment. Performance evaluations demonstrate that Arke can support enough throughput to operate at a planetary scale while maintaining sub-second latencies in a large geo-distributed setting.
]]></content:encoded>
<pubDate>Thu, 10 Aug 2023 21:57:24 +0000</pubDate>
</item>
<item>
<title>Consistency-or-Die: Consistency for Key Transparency</title>
<link>https://eprint.iacr.org/2024/879</link>
<guid>https://eprint.iacr.org/2024/879</guid>
<content:encoded><![CDATA[
<div> 关键词: 一致性协议、分割视图攻击、随机用户委员会、Consistency-or-Die (CoD)、可验证随机函数、密钥演进签名、安全性水平、恶意用户、实用性、中档智能手机、大规模系统、亿级用户

总结:
本文提出了一种新的名为Consistency-or-Die (CoD)的一致性协议，该协议旨在保护关键透明度日志不受分割视图攻击，并且与以往工作不同，它不依赖于小规模的已知外部审计员委员会、脱机通道或区块链（全广播系统）。CoD通过使用加密机制随机选取并保密的小型用户委员会来背书当前的日志视图。协议保证用户能够得知自己是否处于一致状态，一旦发现日志中的不一致，用户将停止使用此资源并变为非活动状态（“死亡”）。CoD基于成熟的安全技术，如可验证随机函数和密钥演进签名，现有轻量级实现方案。文章还提供了新颖的统计分析方法，用于确定不同安全级别和恶意用户百分比下的最优背书人数（即视图的最小支持者数量）。实验结果表明，CoD在实际应用中具有可行性，能够在拥有数亿用户的大型系统的背景下在中档智能手机上运行。 <div>
This paper proposes a new consistency protocol that protects a key transparency log against split-view attacks and - contrary to all previous work - does not to rely on small committees of known external auditors, or out-of-band channels, or blockchains (full broadcast systems).

Our approach is to use a mechanism for cryptographically selecting a small committee of random and initially undisclosed users, which are then tasked to endorse the current view of the log. The name of our protocol, Consistency-or-Die (CoD), reflects that users are guaranteed to know if they are in a consistent state or not, and upon spotting an inconsistency in the key transparency log, users stop using this resource and become inactive (die). CoD relies on well-established cryptographic building blocks, such as verifiable random functions and key-evolving signatures, for which lightweight constructions exist. We provide a novel statistical analysis for identifying optimal quorum sizes (minimal number of endorsers for a view) for various security levels and percentages of malicious users.

Our experiments support that CoD is practical and can run in the background on mid-tier smart phones, for large-scale systems with billions of users.
]]></content:encoded>
<pubDate>Sun, 02 Jun 2024 14:22:00 +0000</pubDate>
</item>
<item>
<title>Onion Franking: Abuse Reports for Mix-Based Private Messaging</title>
<link>https://eprint.iacr.org/2024/1965</link>
<guid>https://eprint.iacr.org/2024/1965</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人消息应用、端到端加密、滥用报告、元数据保护、洋葱加密

总结:<br />
本文提出了适用于基于洋葱加密的任何私人消息系统的新型滥用报告机制，这包括采用启发式或机会性用户流量混合的低延迟系统以及基于混排网络的方案。文章指出，适合E2EE环境的设计决策和抽象可能在保护元数据的场景中阻碍安全性和性能提升，并探讨了比先前工作更强的滥用报告和内容审核威胁模型。此外，文中还分析了现有工作的不足，并提出如何强化自身方案和其他方案（包括已部署的E2EE消息平台）以实现更高安全级别。实验结果显示，所提出的原型系统在消息传递和报告过程中的每个步骤上，其性能优于当前最优解决方案一个数量级以上，且开销接近现今E2EE加密消息应用所使用的消息认证技术。 <div>
The fast-paced development and deployment of private messaging applications demands mechanisms to protect against the concomitant potential for abuse. While widely used end-to-end encrypted (E2EE) messaging systems have deployed mechanisms for users to verifiably report abusive messages without compromising the privacy of unreported messages, abuse reporting schemes for systems that additionally protect message metadata are still in their infancy. Existing solutions either focus on a relatively small portion of the design space or incur much higher communication and computation costs than their E2EE brethren.

This paper introduces new abuse reporting mechanisms that work for any private messaging system based on onion encryption. This includes low-latency systems that employ heuristic or opportunistic mixing of user traffic, as well as schemes based on mixnets. Along the way, we show that design decisions and abstractions that are well-suited to the E2EE setting may actually impede security and performance improvements in the metadata-hiding setting. We also explore stronger threat models for abuse reporting and moderation not explored in prior work, showing where prior work falls short and how to strengthen both our scheme and others' -- including deployed E2EE messaging platforms -- to achieve higher levels of security.

We implement a prototype of our scheme and find that it outperforms the best known solutions in this setting by well over an order of magnitude for each step of the message delivery and reporting process, with overheads almost matching those of message franking techniques used by E2EE encrypted messaging apps today.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 15:32:40 +0000</pubDate>
</item>
<item>
<title>SoK: Privacy-Preserving Transactions in Blockchains</title>
<link>https://eprint.iacr.org/2024/1959</link>
<guid>https://eprint.iacr.org/2024/1959</guid>
<content:encoded><![CDATA[
<div> 关键词: 交易隐私、区块链系统、隐私保护技术、加密货币、匿名性

总结:<br />
本文针对具有原生隐私特性的加密货币中的隐私保护技术进行了系统化知识研究。文章界定了包括机密性、k-匿名性、完全匿名性和发送者-接收者不可链接性在内的隐私概念，并对实现这些保证所采用的密码学技术进行了分类和比较。分析指出了隐私保障与可扩展性以及监管合规性之间的权衡关系。同时，评估了最受欢迎的私人加密货币的实际部署和用户体验。通过这项分析，文章识别出现在隐私解决方案中的关键差距和挑战，强调了需要进一步研究和开发以增强隐私性的同时保持可扩展性和安全性的重要性。 <div>
Ensuring transaction privacy in blockchain systems is essential to safeguard user data and financial activity from exposure on public ledgers. This paper conducts a systematization of knowledge (SoK) on privacy-preserving techniques in cryptocurrencies with native privacy features. We define and compare privacy notions such as confidentiality, k-anonymity, full anonymity, and sender-receiver unlinkability, and categorize the cryptographic techniques employed to achieve these guarantees. Our analysis highlights the trade-offs between privacy guarantees, scalability, and regulatory compliance.  Finally, we evaluate the usability of the most popular private cryptocurrencies providing insights into their practical deployment and user interaction. 

Through this analysis, we identify key gaps and challenges in current privacy solutions, highlighting areas where further research and development are needed to enhance privacy while maintaining scalability and security.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 17:04:55 +0000</pubDate>
</item>
<item>
<title>Worst-Case Lattice Sampler with Truncated Gadgets and Applications</title>
<link>https://eprint.iacr.org/2024/1952</link>
<guid>https://eprint.iacr.org/2024/1952</guid>
<content:encoded><![CDATA[
<div> 关键词: gadget-based sampler、Micciancio-Peikert (MP)、truncation、worst-case sampler、performance improvement

总结:<br />
本文提出了一个新的最坏情况下的采样器，该采样器适用于截断的gadget，解决了现有截断方案无法逆推任意 syndrome 的问题。这一创新克服了MP采样器线性增长维度的问题，同时保持了其主要特性，并为选择截断参数提供了灵活性。因此，它可以作为依赖于MP采样器的所有应用的直接替代品，实验证明能带来高达30%的性能提升。文章还对新采样器进行了全面的安全分析，并通过具体实现展示了其实用性。 <div>
Gadget-based samplers have proven to be a key component of several cryptographic primitives, in particular in the area of privacy-preserving mechanisms. Most constructions today follow the approach introduced by Micciancio and Peikert (MP) yielding preimages whose dimension linearly grows with that of the gadget. To improve performance, some papers have proposed to truncate the gadget but at the cost of an important feature of the MP sampler, namely the ability to invert arbitrary syndromes. Technically speaking, they replace the worst-case MP sampler by an average-case sampler that can only be used in specific contexts. Far from being a mere theoretical restriction, it prevents the main applications of gadget-based samplers from using truncated variants and thus from benefiting from the associated performance gains.
In this paper, we solve this problem by describing a worst-case sampler that still works with truncated gadgets. Its main strength is that it retains the main characteristics of the MP sampler while providing flexibility in the choice of the truncation parameter. As a consequence, it can be used as a plug-in replacement for all applications relying on the MP sampler so far, leading to performance improvements up to 30% as illustrated by several examples in this paper. Our sampler is supported by a thorough security analysis that addresses the hurdles met by previous works and its practicality is demonstrated by a concrete implementation.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 16:45:40 +0000</pubDate>
</item>
<item>
<title>Vote&amp;Check: Secure Postal Voting with Reduced Trust Assumptions</title>
<link>https://eprint.iacr.org/2024/1951</link>
<guid>https://eprint.iacr.org/2024/1951</guid>
<content:encoded><![CDATA[
<div> 关键词: 邮政投票、安全性、验证性、隐私保护、Vote&amp;Check

总结:
邮政投票是一种常用的替代现场投票的方式，其安全性和可验证性历来依赖于组织措施和多方信任。近年来，已有方案提出增加邮政投票的可验证性同时保持投票隐私。文章对邮政投票环境进行了系统分析，识别出一系列不可避免的攻击风险，并将这些分析应用于现有文献中的系统。针对这些问题，文章提出了一个名为Vote&amp;Check的邮政投票协议，该协议具有高安全级别并仅需少数基础加密原语——哈希函数和签名。Vote&amp;Check的安全属性已在符号模型中通过ProVerif工具得到了证明。 <div>
Postal voting is a frequently used alternative to on-site voting. Traditionally, its security relies on organizational measures, and voters have to trust many entities. In the recent years, several schemes have been proposed to add verifiability properties to postal voting, while preserving vote privacy.
Postal voting comes with specific constraints. We conduct a systematic analysis of this setting and we identify a list of generic attacks, highlighting that some attacks seem unavoidable. This study is applied to existing systems of the literature.
We then propose Vote&amp;Check, a postal voting protocol which provides a high level of security, with a reduced number of authorities. Furthermore, it requires only basic cryptographic primitives, namely hash functions and signatures. The security properties are proven in a symbolic model, with the help of the ProVerif tool.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 13:13:03 +0000</pubDate>
</item>
<item>
<title>ARK: Adaptive Rotation Key Management for Fully Homomorphic Encryption Targeting Memory Efficient Deep Learning Inference</title>
<link>https://eprint.iacr.org/2024/1948</link>
<guid>https://eprint.iacr.org/2024/1948</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习、隐私保护、全同态加密(FHE)、内存消耗、Adaptive Rotation Key(ARK)

总结:
本文关注深度学习中隐私保护的问题，提出了一种名为Adaptive Rotation Key (ARK)的新技术，旨在解决全同态加密(FHE)的高内存消耗问题。ARKeep能够通过全面分析数值模式来生成最小化的共享旋转密钥集合，从而减少旋转密钥的内存占用。此外，ARK还提供了两种配置选项，允许用户根据需求在内存效率和计算速度之间进行权衡。在内存优先模式下，ARK能降低41.17%的旋转密钥内存消耗，但会导致执行时间增加12.57%；而在速度优先模式下，它实现了24.62%的旋转密钥内存减少，仅对执行时间造成0.21%的影响。因此，ARK为优化基于FHE的隐私保护系统提供了一个灵活而有效的解决方案，标志着该领域在优化策略上的一项重要进展。 <div>
Advancements in deep learning (DL) not only revolutionized many aspects in our lives, but also introduced privacy concerns, because it processed vast amounts of information that was closely related to our daily life. Fully Homomorphic Encryption (FHE) is one of the promising solutions to this privacy issue, as it allows computations to be carried out directly on the encrypted data. However, FHE requires high computational cost, which is a huge barrier to its widespread adoption. Many prior works proposed techniques to enhance the speed performance of FHE in the past decade, but they often impose significant memory requirements, which may be up to hundreds of gigabytes. Recently, focus has shifted from purely improving speed performance to managing FHE’s memory consumption as a critical challenge. Rovida and Leporati introduced a technique to minimize rotation key memory by retaining only essential keys, yet this technique is limited to cases with symmetric numerical patterns (e.g., -2 -1 0 1 2), constraining its broader utility. In this paper, a new technique, Adaptive Rotation Key (ARK), is proposed that minimizes rotation key memory consumption by exhaustively analyzing numerical patterns to produce a minimal subset of shared rotation keys. ARK also provides a dual-configuration option, enabling users to prioritize memory efficiency or computational speed. In memory-prioritized mode, ARK reduces rotation key memory consumption by 41.17% with a 12.57% increase in execution time. For speed-prioritized mode, it achieves a 24.62% rotation key memory reduction with only a 0.21% impact on execution time. This flexibility positions ARK as an effective solution for optimizing FHE across varied use cases, marking a significant advancement in optimization strategies for FHE-based privacy-preserving systems.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 03:50:20 +0000</pubDate>
</item>
<item>
<title>Alba: The Dawn of Scalable Bridges for Blockchains</title>
<link>https://eprint.iacr.org/2024/197</link>
<guid>https://eprint.iacr.org/2024/197</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币, 互操作性, 信任桥梁协议, 支付通道, Pay2Chain桥

总结:
本文关注了过去十年加密货币领域的发展，特别是区块链生态系统和新颖应用的增长。为了解决当前信任桥梁协议在效率上的问题，如轻客户端和零知识证明（zk）方案存在的不足，文章提出了Pay2Chain桥的概念，该桥利用支付通道等离链解决方案的优势克服现有桥梁限制。文中所提出的Pay2Chain桥——Alba，能够实现基于离链事件的高效、安全和无需信任的有条件支付或智能合约执行，从而丰富源区块链生态，支持DeFi应用、多资产支付通道及乐观状态型离链计算。

论文进一步在UC框架下形式化定义了Alba对拜占庭敌手的安全性，并结合博弈论进行分析；同时引入正式可扩展性指标展示其效率优势。实证评估证实了Alba在通信复杂度和链上成本方面的效率，其乐观情况下的费用仅是标准以太坊代币所有权转移交易费用的两倍。 <div>
Over the past decade, cryptocurrencies have garnered attention from academia and industry alike, fostering a diverse blockchain ecosystem and novel applications. The inception of bridges improved interoperability, enabling asset transfers across different blockchains to capitalize on their unique features. Despite their surge in popularity and the emergence of Decentralized Finance (DeFi), trustless bridge protocols remain inefficient, either relaying too much information (e.g., light-client-based bridges) or demanding expensive computation (e.g., zk-based bridges). These inefficiencies arise because existing bridges securely prove a transaction's on-chain inclusion on another blockchain. Yet this is unnecessary as off-chain solutions, like payment and state channels, permit safe transactions without on-chain publication. However, existing bridges do not support the verification of off-chain payments.

This paper fills this gap by introducing the concept of Pay2Chain bridges that leverage the advantages of off-chain solutions like payment channels to overcome current bridges' limitations. Our proposed Pay2Chain bridge, named Alba, facilitates the efficient, secure, and trustless execution of conditional payments or smart contracts on a target blockchain based on off-chain events. Alba, besides its technical advantages, enriches the source blockchain's ecosystem by facilitating DeFi applications, multi-asset payment channels, and optimistic stateful off-chain computation.

We formalize the security of Alba against Byzantine adversaries in the UC framework and complement it with a game theoretic analysis. We further introduce formal scalability metrics to demonstrate Alba’s efficiency. Our empirical evaluation confirms Alba efficiency in terms of communication complexity and on-chain costs, with its optimistic case incurring only twice the cost of a standard Ethereum transaction of token ownership transfer.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 14:38:00 +0000</pubDate>
</item>
<item>
<title>Dynamic-FROST: Schnorr Threshold Signatures with a Flexible Committee</title>
<link>https://eprint.iacr.org/2024/896</link>
<guid>https://eprint.iacr.org/2024/896</guid>
<content:encoded><![CDATA[
<div> 关键词：_threshold signatures_ ， _FROST_ ， _CHURP_ ， _dynamic update_ ， _Schnorr threshold signature_

<br /><br />总结：

本文提出了一个名为Dynamic-FROST (简称D-FROST) 的协议，它将FROST——一种基于Schnorr的阈值签名方案，与CHURP——一种动态主动秘密分享方案相结合。D-FROST 是首个能够支持委员会成员和阈值值动态变更的Schnorr阈值签名方案，而且无需依赖可信第三方。此外，文章还对D-FROST的安全性进行了证明，表明其保持了原签署方案的存在的选择消息攻击下的不可伪造性属性。这一创新对于那些需要动态调整阈值或参与者的应用，如共识算法和区块链钱包等，具有实际意义和应用价值。 <div>
Threshold signatures enable any subgroup of predefined cardinality $t$ out of a committee of $n$ participants to generate a valid, aggregated signature. 
Although several $(t,n)$-threshold signature schemes exist, most of them assume that the threshold $t$ and the set of participants do not change over time. 
Practical applications of threshold signatures might benefit from the possibility of updating the threshold or the committee of participants. Examples of such applications are consensus algorithms and blockchain wallets.
In this paper, we present Dynamic-FROST (D-FROST, for short) that combines FROST, a Schnorr threshold signature scheme, with CHURP, a dynamic proactive secret sharing scheme. The resulting protocol is the first Schnorr threshold signature scheme that  accommodates changes in both the committee and the threshold value without relying on a trusted third party.
Besides detailing the protocol, we present a proof of its security: as the original signing scheme, D-FROST preserves the property of Existential Unforgeability under Chosen-Message Attack.
]]></content:encoded>
<pubDate>Wed, 05 Jun 2024 12:34:38 +0000</pubDate>
</item>
<item>
<title>Distributed Differentially Private Data Analytics via Secure Sketching</title>
<link>https://eprint.iacr.org/2024/1946</link>
<guid>https://eprint.iacr.org/2024/1946</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式差分隐私、计算效率、线性变换模型、中央模型、局部模型

总结:
我们研究了在多个服务器间进行分布式差分隐私计算，旨在平衡由差分隐私机制引入的误差与分布式算法的计算效率之间的权衡。为此，我们提出了线性变换模型，在该模型中，客户端能够访问一个可信任平台，该平台能够对输入数据应用公开矩阵。利用简单的安全多方计算技术，这种计算可以安全地分布到多个服务器上。

线性变换模型介于高度表达性的中央模型和限制较多的局部模型之间。中央模型允许客户端使用可信任平台对其输入执行任何函数运算，但这种表达能力的成本在于难以分布式实现，通常需要一个单一可信服务器来实施。而局部模型则不假设存在可信任平台，这迫使客户端在其数据中添加大量噪声。线性变换模型避免了中央模型中的单点隐私故障风险，同时也减轻了局部模型所需的高噪声。

我们证明线性变换对于差分隐私非常有用，可以用于计算输入数据的线性草图。这些草图在保持诸如私人低秩近似和私人岭回归等任务的实用性方面做得很好，同时仅引入最小的误差，关键的是，这个误差独立于客户端的数量。在此之前，这类准确性只有在更具有表达性的中央模型中才能实现。 <div>
We explore the use of distributed differentially private computations across multiple servers, balancing the tradeoff between the error introduced by the differentially private mechanism and the computational efficiency of the resulting distributed algorithm.

We introduce the linear-transformation model, where clients have access to a trusted platform capable of applying a public matrix to their inputs. Such computations can be securely distributed across multiple servers using simple and efficient secure multiparty computation techniques.

The linear-transformation model serves as an intermediate model between the highly expressive central model and the minimal local model. In the central model, clients have access to a trusted platform capable of applying any function to their inputs. However, this expressiveness comes at a cost, as it is often expensive to distribute such computations, leading to the central model typically being implemented by a single trusted server. In contrast, the local model assumes no trusted platform, which forces clients to add significant noise to their data. The linear-transformation model avoids the single point of failure for privacy present in the central model, while also mitigating the high noise required in the local model.

We demonstrate that linear transformations are very useful for differential privacy, allowing for the computation of linear sketches of input data. These sketches largely preserve utility for tasks such as private low-rank approximation and private ridge regression, while introducing only minimal error, critically independent of the number of clients. Previously, such accuracy had only been achieved in the more expressive central model.
]]></content:encoded>
<pubDate>Sat, 30 Nov 2024 18:13:15 +0000</pubDate>
</item>
<item>
<title>DGMT: A Fully Dynamic Group Signature From Symmetric-key Primitives</title>
<link>https://eprint.iacr.org/2024/1942</link>
<guid>https://eprint.iacr.org/2024/1942</guid>
<content:encoded><![CDATA[
<div> 关键词：群签名、匿名性、责任追究、对称密钥、动态性

总结:
本文提出了一种名为DGMT的基于对称密钥的完全动态群签名方案，该方案重新设计了DGM（Buser等人在ESORICS 2019上的工作），解决了其在实际应用中的两个重要局限：(i) 签名验证需要与组经理交互，以及 (ii) 组经理需要存储和管理大量不可接受的数据。文章证明了DGMT在安全性方面（不可伪造性、匿名性和可追溯性）的表现，并对其进行了完整实现。相较于已知具有同等安全级别的后量子群签名方案，DGMT拥有最短的签名长度。此外，文中还分析了DGM的签名撤销方法，揭示了虽然其概念新颖，但其实现成本显著高于使用传统的撤销列表方法。<br /><br /> <div>
A group signatures allows a user to sign a message anonymously  on behalf of a group and provides accountability by using  an opening authority who can ``open'' a signature and reveal the signer's identity. Group signatures have been widely used in privacy-preserving applications including anonymous attestation and anonymous authentication. Fully dynamic group signatures allow new members to join the group and existing members to be revoked if needed.  Symmetric-key based group signature schemes are post-quantum group signatures whose security rely on the security of symmetric-key primitives such as cryptographic hash functions and pseudorandom functions. 

In this paper, we design a symmetric-key based fully dynamic group signature scheme, called DGMT, that redesigns DGM (Buser et al. ESORICS 2019) and  removes its two important shortcomings that limit its application in practice: (i) interaction with the group manager for signature verification, and (ii) the need for storing and managing an unacceptably large amount of data by the group manager. We prove  security of DGMT (unforgeability, anonymity, and traceability)  and give a full implementation of the system. Compared to  all known post-quantum group signature schemes with the same security level, DGMT has the shortest signature size. We also analyze DGM signature revocation approach and show that despite its conceptual novelty, it  has significant hidden costs that makes it much more costly than using traditional revocation list approach.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 23:25:59 +0000</pubDate>
</item>
<item>
<title>A Formal Treatment of Key Transparency Systems with Scalability Improvements</title>
<link>https://eprint.iacr.org/2024/1938</link>
<guid>https://eprint.iacr.org/2024/1938</guid>
<content:encoded><![CDATA[
<div> 关键词: Key Transparency, 安全模型, 伪装攻击, 可验证Bloom过滤器, 扩展性

总结:
本文首次提出了一个关于密钥透明度（KT）系统的加密学上健全的形式化模型，明确了其安全假设、属性和潜在漏洞。文中揭示了一个重要的安全隐患——恶意服务提供商可能实施的伪装攻击，并提出了一种向后兼容的解决方案。此外，针对KT系统的扩展性瓶颈，文章设计并实现了一种新的隐私保护型可验证Bloom过滤器（VBF），它显著提高了KT的效率而不牺牲安全性。实验结果证明了该方法的有效性，标志着在可扩展的KT解决方案的理论研究和实际部署方面迈出了重要一步。 <div>
Key Transparency (KT) systems have emerged as a critical technology for securely distributing and verifying the correctness of public keys used in end-to-end encrypted messaging services. Despite substantial academic interest, increased industry adoption, and IETF standardization efforts, KT systems lack a holistic and formalized security model, limiting their resilience to practical threats and constraining future development. In this paper, we introduce the first cryptographically sound formalization of KT as an ideal functionality, clarifying the assumptions, security properties, and potential vulnerabilities of deployed KT systems. We identify a significant security concern — a possible impersonation attack by a malicious service provider — and propose a backward-compatible solution. Additionally, we address a core scalability bottleneck by designing and implementing a novel, privacy-preserving verifiable Bloom filter (VBF) that significantly improves KT efficiency without compromising security. Experimental results demonstrate the effectiveness of our approach, marking a step forward in both the theoretical and practical deployment of scalable KT solutions.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 10:26:00 +0000</pubDate>
</item>
<item>
<title>RevoLUT : Rust Efficient Versatile Oblivious Look-Up-Tables</title>
<link>https://eprint.iacr.org/2024/1935</link>
<guid>https://eprint.iacr.org/2024/1935</guid>
<content:encoded><![CDATA[
<div> 关键词: RevoLUT、Rust、Look-Up-Tables (LUT)、 Oblivious操作、隐私保护

总结:
本文介绍了RevoLUT，这是一个使用Rust语言实现的库，它重新构想了查找表（LUT）的用途，不再局限于TFHE编程式引导中常见的函数编码作用。RevoLUT将LUT作为一级对象，支持在表内部高效地进行 oblivious 操作，如数组访问、元素排序和置换。这种做法为执行 oblivious 算法提供了便利，从而在各种应用中实现了对敏感数据的安全、隐私保护的处理方式。 <div>
In this paper we present RevoLUT, a library implemented in Rust that reimagines the use of Look-Up-Tables (LUT) beyond their conventional role in function encoding, as commonly used in TFHE's programmable boostrapping. Instead, RevoLUT leverages LUTs as first class objects, enabling efficient oblivious operations such as array access, elements sorting and permutation directly within the table. This approach supports oblivious algortithm, providing a secure, privacy-preserving solution for handling sensitive data in various applications.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 02:47:05 +0000</pubDate>
</item>
<item>
<title>HomeRun: High-efficiency Oblivious Message Retrieval, Unrestricted</title>
<link>https://eprint.iacr.org/2024/188</link>
<guid>https://eprint.iacr.org/2024/188</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护区块链应用、无感知消息检索(OMR)、HomeRun、安全属性、性能

总结:
文章介绍了一个名为HomeRun的新型无感知消息检索(OMR)协议，该协议针对隐私保护区块链应用设计。HomeRun具有以下优点：<br />
1. 提供了在同一地址多次请求之间的unlinkability（不可链接性），增强了用户隐私保护。<br />
2. 不限制同一收件人可以接收的消息数量，防止“消息余额耗尽”攻击，提升了系统可用性。<br />
3. 允许服务器定期删除已检索到的消息和相关辅助数据，降低了服务器的计算成本和存储成本。<br />
4. 相比现有方案，HomeRun巧妙运用高效的密码学技术，显著提高了运行效率：与Liu等人在CRYPTO '22上基于全同态加密的工作相比，其服务器总运行时间减少了约3830倍；与Madathil等人在USENIX Security '22上基于两个半诚实非共谋服务器的设计相比，至少减少了1459倍，且是在单线程WAN环境下的表现。 <div>
In the realm of privacy-preserving blockchain applications such as Zcash, oblivious message retrieval (OMR) enables recipients to privately access messages directed to them on blockchain nodes (or bulletin board servers). OMR prevents servers from linking a message and its corresponding recipient's address, thereby safeguarding recipient privacy. Several OMR schemes have emerged recently to meet the demands of these privacy-centric blockchains; however, we observe that existing solutions exhibit shortcomings in various critical aspects and may only achieve certain objectives inefficiently, sometimes relying on trusted hardware, thereby impacting their practical utility. This work introduces a novel OMR protocol, HomeRun,  that leverages two semi-honest, non-colluding servers to excel in both performance and security attributes as compared to the current state-of-the-art.

HomeRun stands out by providing unlinkability across multiple requests for the same recipient's address. Moreover, it does not impose a limit on the number of pertinent messages that can be received by a recipient, which thwarts ``message balance exhaustion'' attacks and enhances system usability. HomeRun also empowers servers to regularly delete the retrieved messages and the associated auxiliary data, which mitigates the constantly increasing computation costs and storage costs incurred by servers. Remarkably, none of the existing solutions offer all of these features collectively. Finally, thanks to its judicious use of highly efficient cryptographic building blocks, HomeRun is highly performant: Specifically, the total runtime of servers in HomeRun is $3830 \times$ less than that in the work by Liu et al. (CRYPTO '22) based on fully-homomorphic encryption, and at least $1459 \times$ less than that in the design by Madathil et al. (USENIX Security '22) based on two semi-honest and non-colluding servers, using a single thread in a WAN setting.
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 20:50:20 +0000</pubDate>
</item>
<item>
<title>EndGame: Field-Agnostic Succinct Blockchain with Arc</title>
<link>https://eprint.iacr.org/2024/1925</link>
<guid>https://eprint.iacr.org/2024/1925</guid>
<content:encoded><![CDATA[
<div> 关键词：EndGame、区块链架构、Reed-Solomon积累方案、常量时间验证、安全属性、编码、状态转换、Reed-Solomon码、ARC框架、轻客户端验证成本、无信任设置、状态管理。

<br /><br />总结:  
EndGame是一种新颖的区块链架构，它利用Reed-Solomon积累方案实现了简洁性。该构造允许在保持强大安全属性的同时，实现对区块链状态的常量时间验证。通过有效地使用Reed-Solomon码对区块链状态转移进行编码，并借助ARC框架累积证明状态的有效性，EndGame协议达成了轻客户端最优的验证成本，并支持了无需信任设置的高效状态管理。 <div>
We present EndGame, a novel blockchain architecture that achieves succinctness through Reed-Solomon accumulation schemes. Our construction enables constant-time verification of blockchain state while maintaining strong security properties. We demonstrate how to efficiently encode blockchain state transitions using Reed-Solomon codes and accumulate proofs of state validity using the ARC framework. Our protocol achieves optimal light client verification costs and supports efficient state management without trusted setup.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 10:47:51 +0000</pubDate>
</item>
<item>
<title>Algebraic Zero Knowledge Contingent Payment</title>
<link>https://eprint.iacr.org/2024/1930</link>
<guid>https://eprint.iacr.org/2024/1930</guid>
<content:encoded><![CDATA[
<div> 关键词: Modular Algebraic Proof Contingent Payment (MAPCP), zero-knowledge contingent payment (ZKCP), zk-SNARKs, Hash Time-Locked Contracts (HTLC), fungibility

总结:
本文介绍了Modular Algebraic Proof Contingent Payment (MAPCP)，这是一种新颖的零知识条件支付方案。MAPCP首次实现了无需依赖zk-SNARKs作为零知识证明工具以及不使用Hash Time-Locked Contracts (HTLC)进行原子化交换秘密和支付的方式。因此，它避免了公共参考字符串(crs)创建问题，并能与几乎任何具有有限或无智能合约支持的加密货币兼容，同时提高了支付的可互换性，使其能够与标准加密货币支付无缝融合。

文章分析了MAPCP的安全性并证明其具备原子性：(i) 买家在支付记录上链后可以获取数字产品（保障买家安全）；(ii) 若买家已获得数字产品的访问权，则卖家将收到付款（保障卖家安全）。此外，文中还展示了一个具体应用案例，即客户通过MAPCP向公证人付费以获取文档签名。 <div>
In this work, we introduce Modular Algebraic Proof Contingent Payment (MAPCP), a novel zero-knowledge contingent payment (ZKCP) construction. Unlike previous approaches, MAPCP is the first that simultaneously avoids using zk-SNARKs as the tool for zero-knowledge proofs and HTLC contracts to atomically exchange a secret for a payment. As a result, MAPCP sidesteps the common reference string (crs) creation problem and is compatible with virtually any cryptocurrency, even those with limited or no smart contract support. Moreover, MAPCP contributes to fungibility, as its payment transactions blend seamlessly with standard cryptocurrency payments.
We analyze the security of MAPCP and demonstrate its atomicity, meaning that, (i) the buyer gets the digital product after the payment is published in the blockchain (buyer security); and (ii) the seller receives the payment if the buyer gets access to the digital product (seller security). Moreover, we present a construction of MAPCP in a use case where a customer pays a notary in exchange for a document signature.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 11:01:29 +0000</pubDate>
</item>
<item>
<title>PASTA on Edge: Cryptoprocessor for Hybrid Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1919</link>
<guid>https://eprint.iacr.org/2024/1919</guid>
<content:encoded><![CDATA[
<div> 关键词: Fully Homomorphic Encryption (FHE), Hybrid Homomorphic Encryption (HHE), PASTA, FPGA, ASIC

总结:<br />
本文首次实现了名为PASTA的Hybrid Homomorphic Encryption (HHE)方案，这是一种针对整数设计的对称加密方案，旨在加速客户端加密和服务器端的同态解密。研究中对比了FPGA和ASIC平台上的性能结果，其中在低功耗的130nm ASIC技术上的RISC-V SoC实现相比CPU实现了43-171倍的速度提升；而在高端的7nm和28nm ASIC平台上，相较于之前的FHE公钥客户端加速器，其速度提升了97倍。此外，该设计已公开并应用于支持未来的相关研究。 <div>
Fully Homomorphic Encryption (FHE) enables privacy-preserving computation but imposes significant computational and communication overhead on the client for the public-key encryption. To alleviate this burden, previous works have introduced the Hybrid Homomorphic Encryption (HHE) paradigm, which combines symmetric encryption with homomorphic decryption to enhance performance for the FHE client. While early HHE schemes focused on binary data, modern versions now support integer prime fields, improving their efficiency for practical applications such as secure machine learning.

Despite several HHE schemes proposed in the literature, there has been no comprehensive study evaluating their performance or area advantages over FHE for encryption tasks. This paper addresses this gap by presenting the first implementation of an HHE scheme- PASTA. It is a symmetric encryption scheme over integers designed to facilitate fast client encryption and homomorphic symmetric decryption on the server. We provide performance results for both FPGA and ASIC platforms, including a RISC-V System-on-Chip (SoC) implementation on a low-end 130nm ASIC technology, which achieves a 43–171$\times$ speedup compared to a CPU. Additionally, on high-end 7nm and 28nm ASIC platforms, our design demonstrates a 97$\times$ speedup over prior public-key client accelerators for FHE. We have made our design public and benchmarked an application to support future research.
]]></content:encoded>
<pubDate>Tue, 26 Nov 2024 14:24:23 +0000</pubDate>
</item>
<item>
<title>Orion's Ascent: Accelerating Hash-Based Zero Knowledge Proof on Hardware Platforms</title>
<link>https://eprint.iacr.org/2024/1918</link>
<guid>https://eprint.iacr.org/2024/1918</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、Orion、优化、硬件加速、FPGA

总结:
针对零知识证明（ZKP）方案Orion中存在的承诺阶段性能瓶颈问题，本文提出了多项算法和硬件层面的优化措施。首先，将递归编码构造替换为迭代方法，并设计了面向硬件优化的新型扩增图策略，以提高并行性和减少外部内存访问。其次，实现了动态生成扩增图的技术，大幅降低内存使用量。此外，对Merkle树生成过程中的SHA3哈希操作进行了优化，显著加快了多项式承诺阶段的速度。文中通过FPGA实现，利用高效的内存访问策略对高带宽内存（HBM）进行深度优化，相较于高性能CPU上的软件实现，线性编码速度提升最高可达381倍，哈希操作速度提升高达2,390倍。在实际应用中，如基于ZKP的深度神经网络训练验证场景下，这些技术可使多项式承诺阶段的速度提升至241倍。 <div>
Zero-knowledge proofs (ZKPs) are cryptographic protocols that enable one party to prove the validity of a statement without revealing the underlying data. Such proofs have applications in privacy-preserving technologies and verifiable computations. However, slow proof generation poses a significant challenge in the wide-scale adoption of ZKP. Orion is a recent ZKP scheme with linear prover time. It leverages coding theory, expander graphs, and Merkle hash trees to improve computational efficiency. However, the polynomial commitment phase in Orion is yet a primary performance bottleneck due to the memory-intensive nature of expander graph-based encoding and the data-heavy hashing required for Merkle Tree generation.

This work introduces several algorithmic and hardware-level optimizations aimed at accelerating Orion’s commitment phase. We replace the recursive encoding construction with an iterative approach and propose novel expander graph strategies optimized for hardware to enable more parallelism and reduce off-chip memory access. Additionally, we implement an on-the-fly expander graph generation technique, reducing memory usage by gigabytes. Further optimizations in Merkle Tree generation reduce the cost of SHA3 hashing, resulting in significant speedups of the polynomial commitment phase. Our FPGA implementation heavily optimizes access to the off-chip high-bandwidth memory (HBM) utilizing memory-efficient computational strategies. The accelerator demonstrates speedups of up to 381$\times$ for linear encoding and up to 2,390$\times$ for the hashing operations over a software implementation on a high-end CPU. In the context of real-world applications, such as zero-knowledge proof-of-training of deep neural networks (DNNs), our techniques show up to 241$\times$ speed up for the polynomial commitment.
]]></content:encoded>
<pubDate>Tue, 26 Nov 2024 11:02:32 +0000</pubDate>
</item>
<item>
<title>Decentralized FHE Computer</title>
<link>https://eprint.iacr.org/2024/1917</link>
<guid>https://eprint.iacr.org/2024/1917</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式计算机、隐私保护、全同态加密、区块链环境、开发者激励

<br />
总结:
本文提出了一个基于全同态加密（FHE）技术的去中心化计算机模型，旨在解决现有区块链系统中处理私密数据能力不足的问题。通过利用FHE技术，该模型能在保证数据加密状态下的安全计算与隐私保护。将此模型融入到去中心化生态系统中，可以有效扩展应用场景，特别是在对保密性要求高的领域。此外，该方案还具有可扩展性和为开发者贡献提供激励机制的特点，从而为构建一个支持隐私计算的去中心化计算机提供了有力框架。 <div>
The concept of a decentralized computer is a powerful and transformative idea that has proven its significance in enabling trustless, distributed computations. However, its application has been severely constrained by an inability to handle private data due to the inherent transparency of blockchain systems. This limitation restricts the scope of use cases, particularly in domains where confidentiality is critical.

In this work, we introduce a model for a Fully Homomorphic Encryption (FHE) decentralized computer. Our approach leverages recent advancements in FHE technology to enable secure computations on encrypted data while preserving privacy. By integrating this model into the decentralized ecosystem, we address the long-standing challenge of privacy in public blockchain environments. The proposed FHE computer supports a wide range of use cases, is scalable, and offers a robust framework for incentivizing developer contributions.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 19:11:00 +0000</pubDate>
</item>
<item>
<title>Sublinear-Round Broadcast without Trusted Setup</title>
<link>https://eprint.iacr.org/2024/770</link>
<guid>https://eprint.iacr.org/2024/770</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine广播、分布式计算、信任假设、可扩展性、子线性轮次<br /><br />总结:
本文提出了一种针对不诚实多数环境下的首个无需信任设置、子线性轮次的拜占庭广播协议。该协议不再依赖于线性数量级的通信轮次或对可信设置的要求，也不需要存在一个诚实的密钥发放者和相关随机字符串的经销商，以及随机预言机。协议的设置仅限于无结构的均匀参考字符串和平凡公钥基础设施（即公告板PKI）。协议的核心是一个“有调解的梯度广播”协议，用于达成共享随机字符串的弱一致性。利用这些字符串，可以公正地运行基于委员会的拜占庭协议，实现子线性轮次的终止。为此，文章提出了一个新的委员会选举构造，它既不依赖随机预言机，也不依赖可信经销商，而是使用了NIZK证明和时间锁谜题。此协议能抵抗任意常数比例的动态敌手攻击。 <div>
Byzantine broadcast is one of the fundamental problems in distributed computing. Many of its practical applications, from multiparty computation to consensus mechanisms for blockchains,  require increasingly weaker trust assumptions, as well as scalability for an ever-growing number of users $n$. This rules out existing solutions which run in a linear number of rounds in $n$ or rely on trusted setup requirements. In this paper, we propose the first sublinear-round and trustless Byzantine broadcast protocol for the dishonest majority setting. Unlike previous sublinear-round protocols, our protocol assumes neither the existence of a trusted dealer who honestly issues keys and correlated random strings to the parties nor random oracles. Instead, we present a solution whose setup is limited to an unstructured uniform reference string and a plain public key infrastructure (a.k.a. bulletin-board PKI).

    Our broadcast protocol builds on top of a \emph{moderated gradecast} protocol which parties can use to reach weak agreement on shared random strings. Using these strings, we can then run in an unbiased fashion a committee-based Byzantine protocol, similar to that of Chan et al. (PKC 2020), which terminates in a sublinear number of rounds. To this end, we propose a novel construction for committee election, which does not rely either on random oracles or on a trusted dealer, and uses NIZKs and time-lock puzzles. Our protocol is resilient against an adaptive adversary who corrupts any constant fraction of parties.
]]></content:encoded>
<pubDate>Mon, 20 May 2024 08:30:07 +0000</pubDate>
</item>
<item>
<title>DiStefano: Decentralized Infrastructure for Sharing Trusted Encrypted Facts and Nothing More</title>
<link>https://eprint.iacr.org/2023/1063</link>
<guid>https://eprint.iacr.org/2023/1063</guid>
<content:encoded><![CDATA[
<div> 关键词：DiStefano、TLS加密、私人承诺、第三方验证、性能优化

总结:
DiStefano 是一个高效且针对恶意攻击安全的框架，用于在使用 TLS-1.3 加密的网络流量上生成私有承诺，以便由指定的第三方进行验证。相较于之前的 TLS 承诺系统，DiStefano 提供了多项改进，包括：针对 TLS 1.3 的模块化协议、对加密数据上任意可验证声明的支持、客户端浏览历史在预批准 TLS 服务器之间的隐私保护，以及确保 TLS 1.3 会话快速在线性能的各种优化。DiStefano 的一个开源实现已经集成到 BoringSSL 密码学库（被基于 Chromium 的互联网浏览器使用）中。实验表明，无论是在局域网还是广域网环境中，DiStefano 在对任意 TLS 流量中的事实进行承诺时都具有实用性，完成整个在线阶段协议的执行所需时间少于 1 秒且数据传输量不超过 80 KiB。 <div>
We design DiStefano: an efficient, maliciously-secure framework for generating private commitments over TLS-encrypted web traffic, for verification by a designated third-party. DiStefano provides many improvements over previous TLS commitment systems, including: a modular protocol specific to TLS 1.3, support for arbitrary verifiable claims over encrypted data, client browsing history privacy amongst pre-approved TLS servers, and various optimisations to ensure fast online performance of the TLS 1.3 session. We build a permissive open-source implementation of DiStefano integrated into the BoringSSL cryptographic library (used by Chromium-based Internet browsers). We show that DiStefano is practical in both LAN and WAN settings for committing to facts in arbitrary TLS traffic, requiring \(<\) 1 s and \(≤\) 80 KiB to execute the complete online phase of the protocol.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 17:56:08 +0000</pubDate>
</item>
<item>
<title>A Better Proof-of-Work Fork Choice Rule</title>
<link>https://eprint.iacr.org/2024/200</link>
<guid>https://eprint.iacr.org/2024/200</guid>
<content:encoded><![CDATA[
<div> 关键词: 修改、工作量证明、选择规则、内在工作、确认延迟<br /><br />总结:<br />
我们提出了一种针对工作量证明区块链的共识机制修改方案，即不再选择最长链，而是选择具有最多内在工作量的链。内在工作量是指区块哈希值前部的零数量。这一改动使得协议运行速度得以安全提升，相较于比特币，在面对近10%的恶意节点情况下，确认延迟可以大约减少40%。该修改是在工作量证明不等式层面进行的，因此可以与文献中提出的其他提高延迟的方法（如GHOST）结合使用。我们通过模拟执行了长达3,000年的系统仿真，获取了详细的证据。同时，我们在比特币骨干模型下正式证明了新协议的安全性，并在证明过程中引入了一个新的技术工具：实值随机Oracle，这可能具有独立的研究价值。 <div>
We propose a modification to the fork choice rule of proof-of-work blockchains. Instead of choosing the heaviest chain, we choose the chain with the most intrinsic work. The intrinsic work of a block is roughly the number of zeroes at the front of its hash. This modification allows us to safely speed up the protocol, yielding a roughly 40% improvement in confirmation delay as compared to Bitcoin for adversaries close to 10%. Our modification is at the level of the proof-of-work inequality, and thus can be composed with any other methods to improve latency proposed in the literature (e.g., GHOST). We compile detailed simulation evidence from 3,000 years of simulated executions of our system across different parameters. We formally prove the security of our new protocol in the Bitcoin Backbone model. These proofs use a new technical tool, the real-valued Random Oracle which may be of independent interest.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 16:50:17 +0000</pubDate>
</item>
<item>
<title>Double Auction Meets Blockchain: Consensus from Scored Bid-Assignment</title>
<link>https://eprint.iacr.org/2022/1471</link>
<guid>https://eprint.iacr.org/2022/1471</guid>
<content:encoded><![CDATA[
<div> 关键词: 双重拍卖系统、区块链、持久性、活性、proof-of-work (PoW)

总结:
本文提出了一种针对双重拍卖系统的新型区块链协议设计，该设计直接从竞标分配计算中构建，确保了透明度和不可变性。文章创新点在于采用一种基于得分的广义多分配问题（SGMAP）的替代proof-of-work (PoW)方案，并将其整合到定制的区块链协议中。与传统PoW协议不同，该方案的领导者选择由与SGMAP评分函数相关的区块分数驱动，该函数具有足够的灵活性以定义难度级别并适应双重拍卖系统的实际需求。文中证明了设计方案的持久性和修改后的活性属性，并通过实施结果验证了其实用性和鲁棒性。 <div>
A double auction system, where buyers and sellers trade through bids, requires a transparent and immutable mechanism to record allocation results. This demand can be met with robust ledgers that ensure persistence and liveness, as exemplified by the Bitcoin blockchain (EuroCrypt '15). While existing blockchain-aided auction systems often rely on secure smart contracts or layer-$2$ techniques, this work proposes a more fundamental approach by constructing a provably secure blockchain protocol directly from the computation of bid allocations. The core component is an alternative proof-of-work (PoW) scheme based on a scored generalized multiple assignment problem (SGMAP), integrated into a tailored blockchain protocol. Unlike conventional PoW-based protocols, our leader selection is driven by block scores derived from the SGMAP scoring function, which is designed to be flexible enough to define the difficulty level and accommodate real-life requirements of the underlying double auction system. We prove persistence and a modified liveness property for our design, and present implementation results to validate its robustness and practicality.
]]></content:encoded>
<pubDate>Thu, 27 Oct 2022 03:19:10 +0000</pubDate>
</item>
<item>
<title>Stealth Software Trojan: Amplifying Hidden RF Side-Channels with Ultra High SNR and Data-Rate</title>
<link>https://eprint.iacr.org/2024/1910</link>
<guid>https://eprint.iacr.org/2024/1910</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网设备、安全漏洞、射频侧信道攻击、软件木马、信息盗窃

<br /><br />总结:
本文介绍了物联网设备带来的生活便利性与安全隐患之间的矛盾。文章提出了一种结合射频(RF)侧信道攻击和软件木马的新方法，能够以几乎无法检测且极为隐匿的方式，在毫秒级时间内从千米之外窃取大量秘密信息。该技术利用由外围设备、总线、内存和CPU引起的木马诱导电气干扰，实现高信噪比数据泄漏。实验结果显示其具有极短的数据获取时间和极高的隐蔽性。此外，研究还引入了优化的调制、解调方案以及专门的同步符号，以降低错误率并提高数据传输速率。文章着重强调了需要开发先进的检测和防御机制来确保物联网设备的安全性和隐私保护。 <div>
Interconnected devices enhance daily life but introduce security
vulnerabilities, new technologies enable malicious activities
such as information theft. This article combines radio frequency (RF) side-channel attacks with software Trojans to create a hard-to-detect, stealthy method for extracting kilobytes of secret information per millisecond over record distances with a single measurement in the RF spectrum. The technique exploits Trojan-induced electrical disturbances in RF components originating from peripherals, buses, memories and CPUs to achieve high SNR data leakage schemes. Experimental results show negligible acquisition time and stealth. The research introduces optimized modulation, demodulation schemes, and specialized synchronization symbols to minimize error rates and maximize data rates. It highlights the need for advanced detection and defense mechanisms to ensure the security and privacy of interconnected devices.
]]></content:encoded>
<pubDate>Sun, 24 Nov 2024 12:51:12 +0000</pubDate>
</item>
<item>
<title>NewtonPIR: Communication Efficient Single-Server PIR</title>
<link>https://eprint.iacr.org/2024/1909</link>
<guid>https://eprint.iacr.org/2024/1909</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人信息检索(PIR), 通信效率, 单服务器PIR协议, NewtonPIR, 计算成本

总结:
本文提出了一种名为NewtonPIR的新单服务器PIR协议，旨在提高通信效率并实现适用于现实世界的计算成本。与现有最佳PIR协议相比，NewtonPIR能将通信开销降低7.5倍，相较于其他协议则降低了35.9至75倍。当数据库和条目大小增加时，NewtonPIR的通信开销保持稳定。通过使用单密文全同态加密(FHE)方案、简单的牛顿插值多项式以及在离线阶段预先计算系数，NewtonPIR成功地将计算开销从小时级别降至秒级别，成为首个实现与数据库大小无关的通信成本且计算开销可与基于环学习带错误(RLWE)的PIR方案相媲美的协议。此外，文章还扩展并引入了一个更有效地平衡计算和通信开销的私人集合交集(PSI)协议。 <div>
Private information retrieval (PIR) is a key component of many privacy-preserving systems. Although numerous PIR protocols have been proposed, designing a PIR scheme with communication overhead independent of the database size $N$ and computational cost practical for real-world applications remains a challenge. In this paper, we propose the NewtonPIR protocol, a communication efficient single-server PIR scheme. NewtonPIR can directly generate query values for the entire index without splitting the index and sending multiple query ciphertexts. Specifically, NewtonPIR achieves communication overhead that is 7.5$\times$ better than the state-of-the-art PIR protocol and 35.9$\sim$75$\times$ better than the other protocols. In experiments, when the database size and entry size increase, the communication overhead of NewtonPIR remains stable. By utilizing the single-ciphertext fully homomorphic encryption (FHE) scheme and the simple Newton interpolation polynomial, along with precomputing coefficients in the offline phase, we reduce the computational overhead of NewtonPIR from hours in previous schemes to seconds. To the best of our knowledge, NewtonPIR is the first protocol to achieve communication cost independent of $N$ along with computational overhead comparable to ring learning with errors (RLWE)-based PIR schemes. Additionally, we extend and introduce a private set intersection (PSI) protocol that balances computational and communication overhead more effectively.
]]></content:encoded>
<pubDate>Sun, 24 Nov 2024 11:03:11 +0000</pubDate>
</item>
<item>
<title>ZK-SNARKs for Ballot Validity: A Feasibility Study</title>
<link>https://eprint.iacr.org/2024/1902</link>
<guid>https://eprint.iacr.org/2024/1902</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子投票、零知识证明、ZK-SNARKs、Exponential ElGamal加密、可行性研究

总结:
文章探讨了将通用型零知识证明（GPZKPs）应用于基于Exponential ElGamal加密的电子投票系统的可行性。作者们在Huber等人关于Pedersen向量承诺的研究基础上，进一步阐述了如何利用Groth16 ZK-SNARK来验证使用Exponential ElGamal加密的各种选举类型和选票格式的有效性。他们还实现并对比测试了一系列不同投票方法和选票格式的实例，结果表明GPZKPs在保证选票隐私的同时，确实可用于证实此类投票系统中选票的有效性，为协议设计者提供了是否采用GPZKP的决策依据。 <div>
Electronic voting (e-voting) systems have become more prevalent in recent years, but security concerns have also increased, especially regarding the privacy and verifiability of votes. As an essential ingredient for constructing secure e-voting systems, designers often employ zero-knowledge proofs (ZKPs), allowing voters to prove their votes are valid without revealing them. Invalid votes can then be discarded to protect verifiability without compromising the privacy of valid votes.

General purpose zero-knowledge proofs (GPZKPs) such as ZK-SNARKs can be used to prove arbitrary statements, including ballot validity. While a specialized ZKP that is constructed only for a specific election type/voting method, ballot format, and encryption/commitment scheme can be more efficient than a GPZKP, the flexibility offered by GPZKPs would allow for quickly constructing e-voting systems for new voting methods and new ballot formats. So far, however, the viability of GPZKPs for showing ballot validity for various ballot formats, in particular, whether and in how far they are practical for voters to compute, has only recently been investigated for ballots that are computed as Pedersen vector commitments in an ACM CCS 2022 paper by Huber et al.

Here, we continue this line of research by performing a feasibility study of GPZKPs for the more common case of ballots encrypted via Exponential ElGamal encryption. Specifically, building on the work by Huber et al., we describe how the Groth16 ZK-SNARK can be instantiated to show ballot validity for arbitrary election types and ballot formats encrypted via Exponential ElGamal. As our main contribution, we implement, benchmark, and compare several such instances for a wide range of voting methods and ballot formats. Our benchmarks not only establish a basis for protocol designers to make an educated choice for or against such a GPZKP, but also show that GPZKPs are actually viable for showing ballot validity in voting systems using Exponential ElGamal.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 10:40:03 +0000</pubDate>
</item>
<item>
<title>Light Clients for Lazy Blockchains</title>
<link>https://eprint.iacr.org/2022/384</link>
<guid>https://eprint.iacr.org/2022/384</guid>
<content:encoded><![CDATA[
<div> 关键词：lazy blockchains, transaction verification, light clients, logarithmic complexity, bisection game

总结:<br />
本文针对懒散区块链（lazy blockchains）提出了一个新的协议，旨在解决其在高效轻量级（SPV）客户端创建上的挑战。该协议利用了对区块链执行时间呈对数级的交互轮次和通信复杂性。文章所设计的方案基于一种遍历包含所有有效或无效交易的默克尔树（Merkle tree）的二分游戏。通过证明该证明系统具有简洁性、完备性和有效性，并通过实证演示了该方案的可行性。 <div>
Lazy blockchains decouple consensus from transaction verification and execution to increase throughput. Although they can contain invalid transactions (e.g., double spends) as a result, these can easily be filtered out by full nodes that check if there have been previous conflicting transactions. However, creating light (SPV) clients that do not see the whole transaction history becomes a challenge: A record of a transaction on the chain does not necessarily entail transaction confirmation. In this paper, we devise a protocol that enables the creation of efficient light clients for lazy blockchains. The number of interaction rounds and the communication complexity of our protocol are logarithmic in the blockchain execution time. Our construction is based on a bisection game that traverses the Merkle tree containing the ledger of all - valid or invalid - transactions. We prove that our proof system is succinct, complete and sound, and empirically demonstrate the feasibility of our scheme.
]]></content:encoded>
<pubDate>Mon, 28 Mar 2022 14:35:08 +0000</pubDate>
</item>
<item>
<title>A Tool for Fast and Secure LWE Parameter Selection: the FHE case</title>
<link>https://eprint.iacr.org/2024/1895</link>
<guid>https://eprint.iacr.org/2024/1895</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密（FHE）、参数选择、LWE基础方案、安全性、效率

总结:
针对全同态加密（FHE）中参数选择的复杂性和挑战性问题，该工作着重于为基于LWE的方案提供严格的理论基础。首先，通过对LWE问题上的 lattice 攻击进行深入分析，得到了最有效攻击的确切表达式。接着，文章引入了闭合形式公式，明确了LWE参数之间的关系。此外，提出了一种数值方法，能够准确地根据所需的安全部署级别选取可配置参数。最后，利用这些研究成果构建了一个实用且高效的工具，旨在帮助研究者和实践者在真实世界应用中部署FHE，确保其既具备严谨的安全性又具有良好的效率。 <div>
The field of fully homomorphic encryption (FHE) has seen many theoretical and computational advances in recent years, bringing the technology closer to practicality than ever before. For this reason, practitioners in related fields, such as machine learning, are increasingly interested in using FHE to provide privacy to their applications. 

Despite this progress, selecting secure and efficient parameters for FHE remains a complex and challenging task due to the intricate interdependencies between parameters. In this work, we address this issue by providing a rigorous theoretical foundation for parameter selection for any LWE-based schemes, with a specific focus on FHE. Our approach starts with an in-depth analysis of lattice attacks on the LWE problem, deriving precise expressions for the most effective ones. Building on this, we introduce closed-form formulas that establish the relationships among the LWE parameters. 

In addition, we introduce a numerical method to enable the accurate selection of any configurable parameter to meet a desired security level.
Finally, we use our results to build a practical and efficient tool for researchers and practitioners deploying FHE in real-world applications, ensuring that our approach is both rigorous and accessible.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 20:52:41 +0000</pubDate>
</item>
<item>
<title>Shardora: Towards Scaling Blockchain Sharding via Unleashing Parallelism</title>
<link>https://eprint.iacr.org/2024/1896</link>
<guid>https://eprint.iacr.org/2024/1896</guid>
<content:encoded><![CDATA[
<div> 关键词: 分片、区块链可扩展性、TPS-退化问题、零-TPS问题、Shardora<br /><br />总结:<br />
为了解决区块链分片在重新配置过程中面临的TPS-退化和零-TPS问题，本文提出了Shardora这一区块链分片系统，旨在通过释放并行性来提高区块链的可扩展性。Shardora实现了两个关键机制：(1) 并行化的双委员会框架配合声誉机制，以减轻TPS-退化问题的同时确保系统安全性；(2) 并行化的密钥预谈判机制结合秘钥重用策略，有效避免零-TPS问题，保持高TPS。理论证明了Shardora具有安全保障。团队已在阿里云上实现Shardora的原型并进行部署，实验结果显示，Shardora显著降低了ledger同步和密钥谈判的开销，比现有的分片方案性能至少提升90%。此外，Shardora在吞吐量和延迟方面表现出优越性能，在单个分片拥有600节点的LAN环境下，达到了峰值吞吐量8300 TPS。Shardora的源代码已在GitHub上公开可用。 <div>
Sharding emerges as a promising solution to enhance blockchain scalability. However, it faces two critical limitations during shard reconfiguration: (1) the TPS-Degradation issue, arising from ledger synchronization conflicts during transaction processing, and (2) the Zero-TPS issue, caused by disruptions in transaction processing due to key negotiation. To this end, we propose Shardora, a blockchain sharding system for scaling blockchain by unleashing parallelism. In Shardora, we implement two essential mechanisms: (1) A parallelized dual committee framework with a reputation mechanism to mitigate the TPS-Degradation issue while ensuring system security. (2) A parallelized key pre-negotiation mechanism with a secret-reuse strategy to avoid the Zero-TPS issue while maintaining a continuously high TPS. We prove that Shardora offers theory-guaranteed security. We implement a prototype of Shardora and deploy it on Alibaba Cloud. Experimental results demonstrate that Shardora addresses the limitations by significantly reducing the overhead of both ledger synchronization and key negotiation, which outperforms state-of-the-art sharding schemes by at least 90%. In addition, Shardora shows its superior performance in terms of throughput and latency, achieving a peak throughput of 8300 TPS on a single shard with 600 nodes under LAN conditions. The code of Shardora is publicly available on GitHub.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 03:34:28 +0000</pubDate>
</item>
<item>
<title>A non-comparison oblivious sort and its application to private k-NN</title>
<link>https://eprint.iacr.org/2024/1894</link>
<guid>https://eprint.iacr.org/2024/1894</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密数据、全同态加密(FHE)、计数排序适应性、盲计数排序算法、隐私保护

总结:
本文提出了一种对计数排序的独特改编方案，该方案能够在使用全同态加密（FHE）的情况下对加密数据进行排序。这是首个不依赖于比较操作的加密数据排序算法。实现过程中利用了TFHE的查找表（LUT）上的基本操作，并将这些操作整合到了基于tfhe-rs构建的开源库RevoLUT中，该库对于无感知算法具有独立的研究价值。通过开发应用于隐私保护的顶-k选择算法并将其应用于k-最近邻分类问题，证明了盲计数排序算法比当前最先进的方法快约5倍。 <div>
This paper introduces a novel adaptation of counting sort that enables sorting of encrypted data using Fully Homomorphic Encryption (FHE). Our approach represents the first known sorting algorithm for encrypted data that does not rely on comparisons. The implementation leverages some basic operations on TFHE's Look-Up-Tables (LUT). We have integrated these operations into RevoLUT, a comprehensive open-source library built upon tfhe-rs, which can be of independent interest for oblivious algorithms. We demonstrate the effectiveness of our Blind Counting Sort algorithm by developing a top-$k$ selection algorithm and applying it to privacy-preserving $k$-Nearest Neighbors classification. This proves to be approximately 5x faster than current state-of-the-art methods.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 18:23:02 +0000</pubDate>
</item>
<item>
<title>IO-Optimized Design-Time Configurable Negacyclic Seven-Step NTT Architecture for FHE Applications</title>
<link>https://eprint.iacr.org/2024/1889</link>
<guid>https://eprint.iacr.org/2024/1889</guid>
<content:encoded><![CDATA[
<div> 关键词: FHE、NTT、negacyclic ring、FPGA、Seven-Step NTT

总结:
文章介绍了针对全同态加密（FHE）中关键的多项式乘法运算，提出了一种新的层次化四步NTT方法，该方法应用于负循环环上的多项式，消除了现有方法中的预处理和后处理步骤。为了加速NTT操作，文章提出了基于FPGA的、参数化且全程流水线化的七步NTT算法实现架构，支持最高达$2^{16}$的环大小和$64$位模数。设计重点关注配置吞吐量，根据HBM带宽约束进行IO参数化设计，目标是在Alveo U280 FPGA上最大化吞吐量。实测结果显示，对于环大小为$2^{16}$和宽度为32位的情况，与当前最先进的设计方案相比，面积-时间产品降低了$2.08\times$，速度提高了$10.32\times$。 <div>
FHE enables computations on encrypted data, making it essential for privacy-preserving applications. However, it involves computationally demanding tasks, such as polynomial multiplication, while NTT is the state-of-the-art solution to perform this task. Most FHE schemes operate over the negacyclic ring of polynomials. We introduce a novel formulation of the hierarchical Four-Step NTT approach for the negacyclic ring, eliminating the need for pre- and post-processing steps found in the existing methods. To accelerate NTT operations, the FPGAs offer flexible and powerful computing platforms. We propose an FPGA-based, parametric and fully pipelined architecture that implements the improved Seven-Step NTT algorithm (which builds upon the four-step). Our design supports a wide range of parameters, including ring sizes up to $2^{16}$ and modulus sizes up to $64$-bit. We focus on achieving configurable throughput, as constrained by the bandwidth of HBM bandwidth, and aim to maximize throughput through an IO parametric design on the Alveo U280 FPGA. The implementation results demonstrate a reduction in the area-time-product by $2.08\times$ and a speed-up of $10.32\times$ for a ring size of $2^{16}$ and a 32-bit width compared to the current state-of-the-art designs.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 13:27:28 +0000</pubDate>
</item>
<item>
<title>Age-aware Fairness in Blockchain Transaction Ordering for Reducing Tail Latency</title>
<link>https://eprint.iacr.org/2024/1884</link>
<guid>https://eprint.iacr.org/2024/1884</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链网络、交易延迟、公平性、交易年龄、声明方案

总结:
区块链网络中，交易延迟对于服务质量（QoS）至关重要。文章提出了一种基于交易等待时间增加其优先级的公平性方法，以降低高延迟交易的发生。然而，由于交易传播影响，交易的实际年龄并不绝对，而且节点可能会谎报交易年龄以获取更高优先级。为此，文章建议采用一种新的声明方案技术，使得节点能够公正地宣布其待处理交易并验证交易年龄。通过对以太坊实际数据和多种场景的合成数据进行评估，该方法在现实条件下展现出减少尾部延迟和维护公平性的优势。 <div>
In blockchain networks, transaction latency is crucial for determining the quality of service (QoS). The latency of a transaction is measured as the time between its issuance and its inclusion in a block in the chain. A block proposer often prioritizes transactions with higher fees or transactions from accounts it is associated with, to minimize their latencies. To maintain fairness among transactions, a block proposer is expected to select the included transactions randomly. The random selection might cause some transactions to experience high latency following the variance in the time a transaction waits until it is selected. We suggest an alternative, age-aware approach towards fairness so that transaction priority is increased upon observing a large waiting time. We explain that a challenge with this approach is that the age of a transaction is not absolute due to transaction propagation. Moreover, a node might present its transactions as older to obtain priority. We describe a new technique to enforce a fair block selection while prioritizing transactions that observed high latency.  The technique is based on various declaration schemes in which a node declares its pending transactions, providing the ability to validate transaction age. By evaluating the solutions on Ethereum data and synthetic data of various scenarios, we demonstrate the advantages of the approach under realistic conditions and understand its potential impact to maintain fairness and reduce tail latency.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 10:43:58 +0000</pubDate>
</item>
<item>
<title>THOR: Secure Transformer Inference with Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1881</link>
<guid>https://eprint.iacr.org/2024/1881</guid>
<content:encoded><![CDATA[
<div> 关键词: THOR、安全推理框架、加密数据、矩阵乘法算法、非线性函数

总结:
THOR是一个针对Transformer模型在加密数据上的安全推理框架。该框架首先提出了基于对角主序编码的新快速矩阵乘法算法，并通过紧凑密文打包技术将其扩展到并行矩阵计算中。其次，设计了用于安全计算softmax、LayerNorm、GELU和Tanh等四个非线性函数的有效协议，这些协议结合了先进的底层近似方法与定制优化。相比现有的HE-based安全推理协议（如Park等人预印本），THOR的新矩阵乘法算法能将BERT-base模型中注意力块线性层中的密钥切换操作减少高达14.5倍。实验结果显示，THOR在单GPU上为BERT-base模型提供安全推理服务的延迟时间为10.43分钟，同时在MRPC数据集上保持了相当的推理精度。 <div>
As language models are increasingly deployed in cloud environments, privacy concerns have become a significant issue. To address this, we design THOR, a secure inference framework for transformer models on encrypted data. Specifically, we first propose new fast matrix multiplication algorithms based on diagonal-major order encoding and extend them to parallel matrix computation through the compact ciphertext packing technique. Second, we design efficient protocols for secure computations of four non-linear functions such as softmax, LayerNorm, GELU, and Tanh, by integrating advanced underlying approximation methods with tailored optimizations. Our matrix multiplication algorithms reduce the number of key-switching operations in the linear layers of the attention block in the BERT-base model by up to 14.5x, compared to the state-of-the-art HE-based secure inference protocol (Park et al., Preprint). Combined with cryptographic optimizations, our experimental results demonstrate that THOR provides secure inference for the BERT-base model with a latency of 10.43 minutes on a single GPU, while maintaining comparable inference accuracy on the MRPC dataset.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 02:59:44 +0000</pubDate>
</item>
<item>
<title>Practical Zero-Knowledge PIOP for Public Key and Ciphertext Generation in (Multi-Group) Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1879</link>
<guid>https://eprint.iacr.org/2024/1879</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption (HE), Multi-group HE (MGHE), Zero-knowledge Techniques, Polynomial Interactive Oracle Proof (PIOP), zk-SNARKs

总结:
本文研究了多组态同态加密（MGHE）的安全性证明系统，以确保公钥和密文的正确性。针对恶意敌手场景，文章设计了一种优化的多项式交互式Oracle证明（PIOP）用于MGHE，并能够利用多项式承诺方案（PCS）将其编译为zk-SNARKs。通过使用基于格的PCS实现该PIOP，相较于先前最优构造PELTA（ACM CCS 2023），本文的方法在证明尺寸上减少了5.5倍、证明生成速度提高了70倍、验证时间提升了343倍。此外，提出的PIOP具有模块化特性，可适应其他PCS以进一步优化如减小证明尺寸等其他方面的需求。 <div>
Homomorphic encryption (HE) is a foundational technology in privacy-enhancing cryptography, enabling non-interactive computation over encrypted data. Recently, generalized HE primitives designed for multi-party applications, such as multi-group HE (MGHE), have gained significant research interest.
While constructing secure multi-party protocols from (MG)HE in the semi-honest model is straightforward, zero-knowledge techniques are essential for ensuring security against malicious adversaries.

In this work, we design practical proof systems for MGHE to guarantee the well-formedness of public keys and ciphertexts. Specifically, we develop and optimize a polynomial interactive oracle proof (PIOP) for MGHE, which can be compiled into zk-SNARKs using a polynomial commitment scheme (PCS).

We compile our PIOP using a lattice-based PCS, and our implementation achieves a 5.5x reduction in proof size, a 70x speed-up in proof generation, and a 343x improvement in verification time compared to the previous state-of-the-art construction, PELTA (ACM CCS 2023). Additionally, our PIOPs are modular, enabling the use of alternative PCSs to optimize other aspects, such as further reducing proof sizes.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 06:47:14 +0000</pubDate>
</item>
<item>
<title>PerfOMR: Oblivious Message Retrieval with Reduced Communication and Computation</title>
<link>https://eprint.iacr.org/2024/204</link>
<guid>https://eprint.iacr.org/2024/204</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名消息传递、隐私保护、Oblivious Message Retrieval (OMR)、Ring-LWE、效率提升

总结:
文章探讨了如何在不泄露接收者元数据的情况下，利用不可信服务器协助实现匿名消息传递。近期研究提出了使用同态加密技术的Oblivious Message Retrieval (OMR)协议，但存在计算成本高、消息及公钥大小过大的问题。本文针对这一现状，构建了更为高效的OMR方案。首先，提出了一种新的基于Ring-LWE的协议，优化检索电路设计，使homomorphically evaluated的运行时间比先前工作快约$13.8$x倍。其次，设计了一种不同的同态解密电路，通过调整Ring-LWE加密参数，显著减小了公共钥匙的大小（约为先前工作的$235$x），同时降低了消息大小（约$1.6$x）。第二个协议的运行时间为${\sim}40.0$毫秒/条消息，仍然比先前的工作快超过$2.5$x倍。 <div>
Anonymous message delivery, as in privacy-preserving blockchain and private messaging applications, needs to protect recipient metadata: eavesdroppers should not be able to link messages to their recipients. This raises the question: how can untrusted servers assist in delivering the pertinent messages to each recipient, without learning which messages are addressed to whom?

Recent work constructed Oblivious Message Retrieval (OMR) protocols that outsource the message detection and retrieval in a privacy-preserving way, using homomorphic encryption. Their construction exhibits significant costs in computation per message scanned (${\sim}0.1$ second), as well as in the size of the associated messages (${\sim}1$kB overhead) and public keys (${\sim}132$kB).

This work constructs more efficient OMR schemes, by replacing the LWE-based clue encryption of prior works with a Ring-LWE variant, and utilizing the resulting flexibility to improve several components of the scheme. We thus devise, analyze, and benchmark two protocols:

The first protocol focuses on improving the detector runtime, using a new retrieval circuit that can be homomorphically evaluated $13.8$x faster than the prior work.
  
The second protocol focuses on reducing the communication costs, by designing a different homomorphic decryption circuit that allows the parameter of the Ring-LWE encryption to be set such that the public key size is about $235$x smaller than the prior work, and the message size is roughly $1.6$x smaller. The runtime of this second construction is ${\sim}40.0$ms per message, still more than $2.5$x faster than prior works.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 20:54:48 +0000</pubDate>
</item>
<item>
<title>Succinctly Verifiable Computation over Additively-Homomorphically Encrypted Data with Applications to Privacy-Preserving Blueprints</title>
<link>https://eprint.iacr.org/2024/675</link>
<guid>https://eprint.iacr.org/2024/675</guid>
<content:encoded><![CDATA[
<div> 关键词：additively homomorphic encryption (AHE)、non-interactive zero-knowledge proof、ElGamal-based encryption、Camenisch-Shoup cryptosystem、privacy-preserving blueprint (PPB)

总结:
本文介绍了基于加性同态加密（AHE）的非交互式零知识证明系统，该系统能够在不泄露输入密文对应明文的情况下，证明一个密文是通过对多个密文和私有输入进行同态评估某个总度数不超过1的多项式函数得到的结果。证明简洁，其大小仅与私有输入数量和函数中变量的最大度数有关。

文章给出了两种实现方法，分别是基于DDH假设的ElGamal加密和基于DCR假设的Camenisch-Shoup密码系统的变种。这两个证明系统的计算和验证时间与对多项式函数的同态评估相当。

进一步地，文章利用上述简洁的零知识证明系统改进了隐私保护蓝图（PPB）系统。对于特定功能如审计黑名单等，新方案不仅扩展了可高效处理的功能类，例如允许审计员追踪犯罪嫌疑人的电子现金交易；而且对于类似黑名单的功能，将用户托管数据（escrow）的大小从依赖于审计员输入的线性规模降低到了对数规模。同时，文章定义并确保了一个更强的安全性标准，即恶意审计员无法陷害未参与交易的用户。 <div>
With additively homomorphic encryption (AHE), one can compute, from input ciphertexts $\mathsf{Enc}(x_1),\ldots,\mathsf{Enc}(x_n)$, and additional inputs $y_1,\ldots,y_k$, a ciphertext $c_\textit{f}=\mathsf{Enc}(f(x_1,\ldots,x_n,y_1,\ldots, y_k))$ for any polynomial $f$ in which each monomial has total degree at most $1$ in the $x$-variables (but can be arbitrary in the $y$-variables).  For AHE that satisfies a set of natural requirements, we give a non-interactive zero-knowledge proof system (in the random-oracle model) for showing that a ciphertext $c_\textit{f}$ is the result of homomorphically evaluating $f$ on ciphertexts $c_1,\ldots,c_n$ and private inputs $y_1,\ldots,y_k$ that correspond to commitments $C_1,\ldots,C_k$.  Our proofs are $\textit{succinct}$, i.e., their size is independent of the number of ciphertexts $n$, and is instead $O(k\log d)$ where $k$ is the number of private inputs, and $d$ is the maximum degree of any variable in $f$.  

We give two ways of instantiating this framework: with ElGamal-based encryption (under the DDH assumption) and with a variant of the Camenisch-Shoup cryptosystem (under the DCR assumption).  Both yield proof systems where computing and verifying the proof takes a comparable amount of time to homomorphically evaluating $f$.

Next, we show that our framework yields a dramatically improved privacy-preserving blueprint (PPB) system.  Introduced by Kohlweiss, Lysyanskaya, and Nguyen (Eurocrypt'23), an $f$-PPB system allows an auditor with secret input $x$ to create a public encoding $\sf pk$ of the function $f(x,\cdot)$ that reveals nothing about $x$.
Yet, it allows a user to compute an encoding, or escrow $Z$, of the value  $f(x,y)$  on input the user's private data $y$ corresponding to a commitment $C_y$; $Z$ will verifiably correspond to the commitment $C_y$.  The auditor will be able to recover $f(x,y)$ from $Z$, but will learn no other information about $y$.  For example, if $f$ is the watchlist function where $f(x,y)$ outputs $y$ only in the event that $y$ is on the list $x$, then an $f$-PPB allows the auditor to trace watchlisted users in an otherwise anonymous system.  

Using our succinct zero-knowledge proof system for additively homomorphic computation we achieve the following results: (1) We provide efficient schemes for a bigger class of functions $f$; for example, we show how to realize $f$ that would allow the auditor to trace e-cash transactions of a criminal suspect which was previously not efficient. (2) For the watchlist and related functions, we reduce the size of the escrow $Z$ from linear in the size of the auditor's input $x$, to logarithmic.
Additionally, we define and satisfy a stronger notion of security for $f$-PPBs, where a malicious auditor cannot frame a user in a transaction in which the user was not involved in.
]]></content:encoded>
<pubDate>Thu, 02 May 2024 19:49:30 +0000</pubDate>
</item>
<item>
<title>How to Redact the Bitcoin Backbone Protocol</title>
<link>https://eprint.iacr.org/2024/813</link>
<guid>https://eprint.iacr.org/2024/813</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、Redactable区块链、Garay等人( Eurocrypt, 2015)、零知识证明、可扩展性

<br /><br />总结:
本文提出了如何将Garay等人在2015年Eurocrypt会议上提出的比特币主干模型扩展以适应可擦除区块链的方法。该扩展使得区块链能够满足流动性的数据库需求和符合现有法规，例如GDPR中的“被遗忘权”或需要从节点数据库中删除可能引发法律关闭的违规数据。所提出的可擦除主干协议保持了区块链的核心属性，并利用零知识证明技术，无需信任第三方或关于过去链验证的启发式方法即可安全地擦除旧数据。此解决方案可以直接在比特币上立即实施而无需硬分叉，并具有可扩展性。它允许对未确认交易（尚未在网络中广泛传播）以及UTXOs中的数据进行擦除，同时保证比特币状态的一致性，因此，违规数据不必临时甚至永久存在于系统中。 <div>
We explain how to extend the Bitcoin backbone model of Garay et al. (Eurocrypt, 2015) to accommodate for redactable blockchains. Our extension captures fluid blockchain-based databases (with mutability requirements) and compliance with existing legislation, such as the GDPR right to be forgotten, or the need to erase offending data from nodes’ databases that would otherwise provoke legal shutdowns. Our redactable backbone protocol retains the essential properties of blockchains. Leveraging zero-knowledge proofs, old data can be erased without requiring trusted third parties or heuristics about past chain validation. Our solution can be implemented on Bitcoin immediately without hard-forks, and it is scalable. It allows the redaction of data from UTXOs or unconfirmed transactions that have not yet flooded the network, while guaranteeing invariance of the Bitcoin state. Thus, offending data does not need to persist in the system, not even temporarily.
]]></content:encoded>
<pubDate>Fri, 24 May 2024 15:58:09 +0000</pubDate>
</item>
<item>
<title>Multi-Holder Anonymous Credentials from BBS Signatures</title>
<link>https://eprint.iacr.org/2024/1874</link>
<guid>https://eprint.iacr.org/2024/1874</guid>
<content:encoded><![CDATA[
<div> 关键词：eIDAS 2.0、匿名凭证、多持有者匿名凭证方案、安全性、不可伪造性

总结:<br />
eIDAS 2.0法规旨在为欧洲公民开发互操作性的数字身份，并已生效。该法规要求凭证不可链接，而匿名凭证允许用户证明其身份属性而不透露身份或防止不同使用情境下的凭证关联，因此可能成为欧洲数字身份的技术基础。本文提出了一种多持有者匿名凭证方案的概念，其中认证因素（或“持有者”）会收到凭证的份额，并需联合运行阈值展示协议来出示凭证。安全定义要求该方案具有不可伪造性，即对手不能成功展示与所控制的身份不匹配的凭证；即使对手可以获取其所选择的凭证并导致并发执行展示协议也是如此。此外，展示协议还需具备可识别的中止安全性。同时，所有诚实持有者的展示必须不可链接，并且不能向控制了用户部分认证因素的对手泄露用户的秘密身份属性。文章设计并证明了一个基于BBS匿名凭证方案的多持有者版本的安全性（包括并发安全性）。在此构造中，每个持有者都会获得一份BBS凭证的秘密份额。利用这些份额，持有者们共同计算出与传统单持有者版本（由Tessaro和Zhu在Eurocrypt'23上提出）相同的BBS凭证展示。 <div>
The eIDAS 2.0 regulation aims to develop interoperable digital identities for European citizens, and it has recently become law.  One of its requirements is that credentials be unlinkable.  Anonymous credentials (AC) allow holders to prove statements about their identity in a way that does not require to reveal their identity and does not enable linking different usages of the same credential. As a result,  they are likely to become the technology that provides digital identity for Europeans.

Any digital credential system, including anonymous credentials, needs to be secured against identity theft and fraud.  In this work, we introduce the notion of a multi-holder anonymous credential scheme that allows issuing shares of credentials to different authentication factors (or ``holders''). To present the credential, the user's authentication factors jointly run a threshold presentation protocol.  Our definition of security requires that the scheme provide unforgeability: the adversary cannot succeed in presenting a credential with identity attributes that do not correspond to an identity for which the adversary controls at least $t$ shares; this is true even if the adversary can obtain credentials of its choice and cause concurrent executions of the presentation protocol.  Further, our definition requires that the presentation protocol provide security with identifiable abort.  Finally, presentations generated by all honest holders must be unlinkable and must not reveal the user's secret identity attributes even to an adversary that controls some of the user's authentication factors.

We design and prove the (concurrent) security of a multi-holder version of the BBS anonymous credential scheme. In our construction, each holder is issued a secret share of a BBS credential. 
Using these shares, the holders jointly compute a credential presentation that is identical to (and therefore compatible with) the traditional, single-holder variant (due to Tessaro and Zhu, Eurocrypt'23) of a BBS credential presentation.
]]></content:encoded>
<pubDate>Sat, 16 Nov 2024 04:34:07 +0000</pubDate>
</item>
<item>
<title>IMOK: A compact connector for non-prohibition proofs to privacy-preserving applications</title>
<link>https://eprint.iacr.org/2024/1868</link>
<guid>https://eprint.iacr.org/2024/1868</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私保护应用、制裁名单、禁止名单、用户验证、Freedom Tool、投票解决方案、生物护照、列表管理、版本控制、过滤数据集、组合列表、其他隐私保护应用

总结:<br />
本文提出了一种针对隐私保护应用的扩展方案，该方案旨在让用户在执行特定操作时能够证明自己不在制裁或禁止名单中，同时无需泄露敏感信息。以将此方案应用于基于生物护照的投票解决方案——Freedom Tool为例，文章探讨了如何整合这一方法到应用程序中，并考虑了制裁名单的管理方式、版本原则、配置过滤数据集、合并不同名单的方法以及如何将其运用到其他隐私保护应用中的可能性。 <div>
This article proposes an extension for privacy-preserving applications to introduce sanctions or prohibition lists. When initiating a particular action, the user can prove, in addition to the application logic, that they are not part of the sanctions lists (one or more) without compromising sensitive data. We will show how this solution can be integrated into applications, using the example of extending Freedom Tool (a voting solution based on biometric passports). We will also consider ways to manage these lists, versioning principles, configuring the filter data set, combining different lists, and using the described method in other privacy-preserving applications.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 11:15:35 +0000</pubDate>
</item>
<item>
<title>Randomness Bounds for Private Simultaneous Messages and Conditional Disclosure of Secrets</title>
<link>https://eprint.iacr.org/2021/1037</link>
<guid>https://eprint.iacr.org/2021/1037</guid>
<content:encoded><![CDATA[
<div> 关键词：私有同时消息（PSM），条件秘密披露（CDS），随机字符串长度，通信复杂度，随机性下界

总结:
文章探讨了在加密学中$k$-党派的私有同时消息（PSM）和条件秘密披露（CDS）协议，关注于带有公共随机字符串的函数$f$的最优随机字符串长度（随机性复杂度）以及完美和统计隐私条件下的界限。首先，建立了消息总长度（通信复杂度）与随机字符串长度之间的通用联系。其次，为PSM和CDS协议的一般函数证明了随机性下界。对于具有完美隐私的PSM协议，文章证明了一般的连接关系为$\lambda - 1 \leq \rho$，并进一步得出在普遍重构条件下，对于一般函数$f:(\{0,1\}^n)^k\rightarrow\{0,1\}$，随机性复杂度至少为$2^{(k-1)n}-1$，这意味着Feige-Killian-Naor的PSM协议是针对一般函数的最优方案。此外，还证明了对于广义内积函数，随机性下界为$\rho > kn-2$，这证实了Liu、Vaikuntanathan和Wee提出的两党派PSM协议对于内积函数的最优性。对于具有完美隐私的CDS协议，展示了随机字符串长度与消息长度和秘密长度之间的关系$\rho \geq \lambda - \sigma$，并得到了对于XOR、AND和广义内积函数的随机性下界为$\rho \geq (k-1)\sigma$，从而表明Applebaum和Arkis的$k$-党派CDS协议对于一般函数在大$k$情况下具有常数因子内的最优性。 <div>
In cryptography, the private simultaneous messages (PSM) and conditional disclosure of secrets (CDS) are closely related fundamental primitives. We consider $k$-party PSM and CDS protocols for a function $f$ with a common random string, where each party $P_i$ generates a message and sends it to a referee $P_0$. We consider bounds for the optimal length $\rho$ of the common random string among $k$ parties (or, {\it randomness complexity}) in PSM and CDS protocols with perfect and statistical privacy through combinatorial and entropic arguments. ($i$) We provide general connections from the optimal total length $\lambda$ of the messages (or, {\it communication complexity}) to the randomness complexity $\rho$. ($ii$) We also prove randomness lower bounds in PSM and CDS protocols for general functions. ($iii$) We further prove randomness lower bounds for several important explicit functions. They contain the following results: For PSM protocols with perfect privacy, we prove $\lambda-1 \le \rho$ as the general connection. From the general lower bound, we prove $\rho\ge 2^{(k-1)n}-1$ for a general function $f:(\{0,1\}^n)^k\rightarrow\{0,1\}$ under universal reconstruction, in which $P_0$ is independent of $f$. This implies that the Feige-Killian-Naor PSM protocol for a general function [Proc.~STOC '94, pp.554--563] is optimal with respect to randomness complexity.  We also provide a randomness lower bound $\rho> kn-2$ for a generalized inner product function. This implies the optimality of the $2$-party PSM protocol for the inner-product function of Liu, Vaikuntanathan, and Wee [Proc.~CRYPTO 2017, pp.758--790]. For CDS protocols with perfect privacy, we show $\rho\ge\lambda-\sigma$ as the general connection by similar argument to those for PSM protocols, where $\sigma$ is the length of secrets. We also obtain randomness lower bounds $\rho\ge (k-1)\sigma$ for XOR, AND, and generalized inner product functions. These imply the optimality of Applebaum and Arkis's $k$-party CDS protocol for a general function [Proc. TCC 2018, pp.317--344] up to a constant factor in a large $k$.
]]></content:encoded>
<pubDate>Mon, 16 Aug 2021 13:08:24 +0000</pubDate>
</item>
<item>
<title>Distributed Differential Privacy via Shuffling vs Aggregation: a Curious Study</title>
<link>https://eprint.iacr.org/2023/1764</link>
<guid>https://eprint.iacr.org/2023/1764</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式差分隐私、shuffle模型、本地DP模型、私有聚合、协议准确性

总结:
文章探讨了分布式差分隐私在无信任中心情况下的实现方法，重点关注shuffle模型和私有聚合模型。shuffle模型引入一个未受信任的混排器来随机排列用户已经局部随机化的数据，从而实现更好的隐私保护效果和更高的数据准确性。然而，研究发现，尽管shuffle模型具有隐私放大效应，但在与私有聚合模型的首次比较研究中，并未明显显示出优势。事实上，私有聚合模型在隐私放大、功能实现、协议准确性和实用性等多个方面，有时甚至显著优于shuffle模型。因此，两种模型各有优劣，具体应用场景应根据实际需求选择。 <div>
How to achieve distributed differential privacy (DP) without a trusted central party is of great interest in both theory and practice. Recently, the shuffle model has attracted much attention. Unlike the local DP model in which the users send randomized data directly to the data collector/analyzer, in the shuffle model an intermediate untrusted shuffler is introduced to randomly permute the data, which have already been randomized by the users, before they reach the analyzer. The most appealing aspect is that while shuffling does not explicitly add more noise to the data, it can make privacy better. The privacy amplification effect in consequence means the users need to add less noise to the data than in the local DP model, but can achieve the same level of differential privacy. Thus, protocols in the shuffle model can provide better accuracy than those in the local DP model. What looks interesting to us is that the architecture of the shuffle model is similar to private aggregation, which has been studied for more than a decade. In private aggregation, locally randomized user data are aggregated by an intermediate untrusted aggregator. Thus, our question is whether aggregation also exhibits some sort of privacy amplification effect? And if so, how good is this ``aggregation model'' in comparison with the shuffle model. We conducted the first comparative study between the two, covering privacy amplification, functionalities, protocol accuracy, and practicality. The results as yet suggest that the new shuffle model does not have obvious advantages over the old aggregation model. On the contrary, protocols in the aggregation model outperform those in the shuffle model, sometimes significantly, in many aspects.
]]></content:encoded>
<pubDate>Wed, 15 Nov 2023 03:05:42 +0000</pubDate>
</item>
<item>
<title>Carbon Footprint Traction System Incorporated as Blockchain</title>
<link>https://eprint.iacr.org/2024/1863</link>
<guid>https://eprint.iacr.org/2024/1863</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、碳足迹跟踪系统、tokenization、智能合约、环境可持续性

总结:<br />
本文提出了一个利用前瞻性的方法解决环境可持续性问题的方案，即构建基于区块链技术的碳足迹追踪系统，并结合tokenization使其日常使用更为便捷高效。该系统将碳足迹数据视为可交易和分享的、具有货币价值的 fungible utility 代币。文章分析了区块链技术如何为全球碳追踪系统所带来的挑战提供有效解决方案，并提出一个具体的使用案例，详细阐述了区块链平台的关键特性以及系统内各方角色和用户交互方式。最终，文章建议采用区块链技术、智能合约及tokenization相结合的方式进行碳足迹管理。 <div>
This article tries to offer a solution to an environmental sustainability problem using a forward-thinking approach and tries to construct a carbon footprint tracking system based on blockchain technology while also introducing tokenization intertwined with the blockchain to make everyday use as accessible and effective as possible.
This effort aims to provide a solid use case for environmental sustainability and lays the groundwork of a new generation social construct where carbon footprint is a valuable unit like money next to the other important tokenized attributes a person can possibly hold. The study proposes a blockchain-based solution to store the data. Through tokenization, the transacting and sharing is facilitated. As a result, carbon footprint data can be treated as a fungible utility token.
The article tries to explain how and which blockchain technology offers an effective solution to challenges in global carbon tracking systems. In this context, a use case was proposed. The critical features of the blockchain-based platform are examined. In addition, the roles of parties and user interactions within the system are detailed.
In conclusion, this article proposes the adaptation of blockchain technology together with smart contracts and tokenization to the management of carbon footprints.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 13:26:12 +0000</pubDate>
</item>
<item>
<title>BatchZK: A Fully Pipelined GPU-Accelerated System for Batch Generation of Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2024/1862</link>
<guid>https://eprint.iacr.org/2024/1862</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、GPU加速、批量生成、流水线、高性能

总结:
我们提出了一种完全流水线化的GPU加速系统，用于批量生成零知识证明。该系统有三个特点以提高吞吐量：<br />
1. 设计了流水线化的方法，使每个GPU线程能持续执行其指定的证明生成任务，避免空闲。
<br />
2. 系统支持高效的ZKP协议，包括求和检查协议、默克尔树和线性时间编码器，并对其计算模块进行了定制，以适应流水线执行。
<br />
3. 采用动态加载方法减少证明生成所需设备内存，并利用多流技术重叠数据传输与GPU计算，降低主机与设备间的数据交换开销。

实验证明，相比于现有最先进的GPU加速系统，我们的系统实现了超过259.5倍的更高吞吐量。此外，在可验证机器学习应用中，我们的系统能够实现每秒生成9.52个证明，首次在此领域成功实现亚秒级证明生成。 <div>
Zero-knowledge proof (ZKP) is a cryptographic primitive that enables one party to prove the validity of a statement to other parties without disclosing any secret information. With its widespread adoption in applications such as blockchain and verifiable machine learning, the demand for generating zero-knowledge proofs has increased dramatically. In recent years, considerable efforts have been directed toward developing GPU-accelerated systems for proof generation. However, these previous systems only explored efficiently generating a single proof by reducing latency rather than batch generation to provide high throughput.

We propose a fully pipelined GPU-accelerated system for batch generation of zero-knowledge proofs. Our system has three features to improve throughput. First, we design a pipelined approach that enables each GPU thread to continuously execute its designated proof generation task without being idle. Second, our system supports recent efficient ZKP protocols with their computational modules: sum-check protocol, Merkle tree, and linear-time encoder. We customize these modules to fit our pipelined execution. Third, we adopt a dynamic loading method for the data required for proof generation, reducing the required device memory. Moreover, multi-stream technology enables the overlap of data transfers and GPU computations, reducing overhead caused by data exchanges between host and device memory.

We implement our system and evaluate it on various GPU cards. The results show that our system achieves more than 259.5× higher throughput compared to state-of-the-art GPU-accelerated systems. Moreover, we deploy our system in the verifiable machine learning application, where our system generates 9.52 proofs per second, successfully achieving sub-second proof generation for the first time in this field.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 10:42:07 +0000</pubDate>
</item>
<item>
<title>Fully Encrypted Machine Learning Protocol using Functional Encryption</title>
<link>https://eprint.iacr.org/2024/1859</link>
<guid>https://eprint.iacr.org/2024/1859</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私保护机器学习, 全同态加密, 多方安全计算, 功能性加密, 两层神经网络

总结:
本文提出了一种基于功能性加密的完全加密隐私保护机器学习协议，该协议首次实现了对加密数据上任意复杂函数的评估，同时在计算过程中无信息泄漏。为实现这一目标，文章构建了一个针对二次多项式的向量功能加密方案，并将其与内积加密方案相结合，使得可以多次组合二次多项式以加密方式计算任意复杂的函数。此协议在恶意模型下具有安全性，即即使对手偏离协议，也无法获取输入数据的任何信息。此外，文中展示了如何使用该协议构建一个带有二次激活函数的全加密两层神经网络模型并给出了实验结果。<br /><br /> <div>
As privacy concerns have arisen in machine learning, privacy-preserving machine learning (PPML) has received significant attention. Fully homomorphic encryption (FHE) and secure multi-party computation (MPC) are representative building blocks for PPML. However, in PPML protocols based on FHE and MPC, interaction between the client (who provides encrypted input data) and the evaluator (who performs the computation) is essential to obtain the final result in plaintext. 
Functional encryption (FE) is a promising candidate to remove this constraint, but existing FE-based PPML protocols are restricted to evaluating only simple ML models, such as one-layer neural networks, or they support partially encrypted PPML, which makes them vulnerable to information leakage beyond the inference results.

In this paper, we propose a fully encrypted FE-based PPML protocol, which supports the evaluation of arbitrary functions over encrypted data with no information leakage during computation, for the first time. 
To achieve this, we newly construct a vector functional encryption scheme for quadratic polynomials and combine it with an inner product encryption scheme. This enables multiple compositions of quadratic polynomials to compute arbitrary complex functions in an encrypted manner. 

Our FE-based PPML protocol is secure in the malicious model, which means that an adversary cannot obtain any information about the input data even though they intentionally deviate from the protocol. 
We then show how to use our protocol to build a fully encrypted 2-layer neural network model with quadratic activation functions and present experimental results.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 02:13:15 +0000</pubDate>
</item>
<item>
<title>Lova: A Novel Framework for Verifying Mathematical Proofs with Incrementally Verifiable Computation</title>
<link>https://eprint.iacr.org/2024/1855</link>
<guid>https://eprint.iacr.org/2024/1855</guid>
<content:encoded><![CDATA[
<div> 关键词：Incrementally Verifiable Computation (IVC)，Nova recursive SNARKs，Lova，proof splicing，multiplexing circuit

总结:
本文提出了一个名为Lova的新颖框架，用于高效验证数学证明。该框架解决了现有Incrementally Verifiable Computation方法（如Nova递归SNARKs）的一些限制，特别是对于线性证明和相同步骤的要求。Lova的主要创新点包括：<br />
1. 引入了创新的证明拼接机制，能够生成独立的证明序列；
2. 开发了一套线性算法系统，可以验证多种数学逻辑规则；
3. 提出了一种新颖的多路复用电路，允许不同类型的证明序列在一个Nova证明中同时被验证。
此外，Lova实现了一个具有线性时间复杂度的证明者时间、常数级别的验证能力、动态/易于修改以及可选的零知识隐私保护功能的验证流程。相关代码可在https://github.com/noelkelias/lova获取。 <div>
Efficiently verifying mathematical proofs and computations has been a heavily researched topic within Computer Science. Particularly, even repetitive steps within a proof become much more complex and inefficient to validate as proof sizes grow. To solve this problem, we suggest viewing it through the lens of  Incrementally Verifiable Computation (IVC). However, many IVC methods, including the state-of-the-art Nova recursive SNARKs, require proofs to be linear and for each proof step to be identical. This paper proposes Lova, a novel framework to verify mathematical proofs end-to-end that solves these problems. Particularly, our approach achieves a few novelties alongside the first-of-its-kind implementation of Nova: (i) an innovative proof splicing mechanism to generate independent proof sequences, (ii) a system of linear algorithms to verify a variety of mathematical logic rules, and (iii) a novel multiplexing circuit allowing non-homogeneous proof sequences to be verified together in a single Nova proof. The resulting Lova pipeline has linear prover time, constant verifying capability, dynamic/easy modification, and optional zero-knowledge privacy to efficiently validate mathematical proofs. Code is available at https://github.com/noelkelias/lova.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 04:23:00 +0000</pubDate>
</item>
<item>
<title>Secure Transformer-Based Neural Network Inference for Protein Sequence Classification</title>
<link>https://eprint.iacr.org/2024/1851</link>
<guid>https://eprint.iacr.org/2024/1851</guid>
<content:encoded><![CDATA[
<div> 关键词: 蛋白质序列分类、大型语言模型、隐私保护、加密DASHformer、 Homomorphic加密

总结:
本文提出了一个名为“加密DASHformer”的隐私保护协议，用于利用 homomorphic 加密技术对蛋白质序列进行分类。该协议适用于 transformer 基于的神经网络 DASHformer，源自 iDASH 2024-Track 1 竞赛提供的任务。此方案是首个仅使用分级同态加密（无需引导）实现批量多蛋白质序列分类的安全变压器推理协议。为达成这一目标，文章创新性地提出了一系列新方法和算法优化，包括数据驱动的非多项式函数拟合、张量打包以及双婴儿步-巨人步算法来计算多个加密矩阵的乘积。这些技术和改进使得协议能在约165秒内完成对163条加密蛋白质序列的分类，达到每条序列平均耗时约一秒钟的高效性能，并确保了128位安全性。这一方案在解决蛋白质序列分类问题的同时，有效地保护了数据隐私。 <div>
Protein sequence classification is crucial in many research areas, such as predicting protein structures and discovering new protein functions. Leveraging large language models (LLMs) is greatly promising to enhance our ability to tackle protein sequence classification problems; however, the accompanying privacy issues are becoming increasingly prominent. In this paper, we present a privacy-preserving, non-interactive, efficient, and accurate protocol called encrypted DASHformer to evaluate a transformer-based neural network for protein sequence classification named DASHformer, provided by the iDASH 2024-Track 1 competition.  The presented protocol is based on our solution for this competition, which won the first place. It is arguably the first secure transformer inference protocol capable of performing batch classification for multiple protein sequences in a single execution only using leveled homomorphic encryption (i.e., without bootstrapping). To achieve this, we propose a series of new techniques and algorithmic improvements, including data-driven non-polynomial function fitting, tensor packing, and double baby-step-giant-step for computing the product of multiple encrypted matrices. These techniques and improvements enable the protocol to classify $163$ encrypted protein sequences in about $165$ seconds with $128$-bit security, achieving an amortized time of about one second per sequence.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 10:30:24 +0000</pubDate>
</item>
<item>
<title>Rotatable Zero Knowledge Sets: Post Compromise Secure Auditable Dictionaries with application to Key Transparency</title>
<link>https://eprint.iacr.org/2022/1264</link>
<guid>https://eprint.iacr.org/2022/1264</guid>
<content:encoded><![CDATA[
<div> 关键词: Key Transparency, 隐私保护, 服务器妥协, 可旋转零知识集 (RZKS), 可旋转可验证随机函数 (Rotatable VRF)

总结:
本文关注的是构建具备后妥协安全性的键透明性系统（Key Transparency, KT），尤其是针对现有方案在服务器遭受攻击后的隐私恢复问题。为解决这一问题，文章提出了一个新的抽象概念——可旋转零知识集 (Rotatable Zero-Knowledge Set, RZKS)，它能实现Post-Compromise Security（PCS）并保持审计属性。此外，RZKS还具有更强的可提取声望性和允许通信方高效“追赶”当前纪元同时确保服务器未删除任何历史数据的能力。文中还引入了一个新的原语——可旋转可验证随机函数 (Rotatable Verifiable Random Function, RVRF)，并展示了如何通过可旋转VRF、有序累加器和只追加向量承诺方案来模块化地构建RZKS。 <div>
Key Transparency (KT) systems allow end-to-end encrypted service providers (messaging, calls, etc.) to maintain an auditable directory of their users’ public keys, producing proofs that all participants have a consistent view of those keys, and allowing each user to check updates to their own keys. KT has lately received a lot of attention, in particular its privacy preserving variants, which also ensure that users and auditors do not learn anything beyond what is necessary to use the service and keep the service provider accountable. 

Abstractly, the problem of building such systems reduces to constructing so-called append-only Zero-Knowledge Sets (aZKS). Unfortunately, existing aZKS (and KT) solutions do not allow to adequately restore the privacy guarantees after a server compromise, a form of Post-Compromise Security (PCS), while maintaining the auditability properties. In this work we address this concern through the formalization of an extension of aZKS called Rotatable ZKS (RZKS). In addition to providing PCS, our notion of RZKS has several other attractive features, such as a stronger (extractable) soundness notion, and the ability for a communication party with out-of-date data to efficiently “catch up” to the current epoch while ensuring that the server did not erase any of the past data. 

Of independent interest, we also introduce a new primitive called a Rotatable Verifiable Random Function (VRF), and show how to build RZKS in a modular fashion from a rotatable VRF, ordered accumulator, and append-only vector commitment schemes.
]]></content:encoded>
<pubDate>Fri, 23 Sep 2022 20:27:51 +0000</pubDate>
</item>
<item>
<title>MixBuy: Contingent Payment in the Presence of Coin Mixers</title>
<link>https://eprint.iacr.org/2024/953</link>
<guid>https://eprint.iacr.org/2024/953</guid>
<content:encoded><![CDATA[
<div> 关键词: 继承支付协议、区块链、混淆器、unlinkable 继承支付（UCP）、MixBuy

总结:
本文提出了一个名为MixBuy的系统，实现了unlinkable 继承支付（UCP），这是一种在买家购买数字产品时通过不可信混淆器路由支付的方式，同时确保支付过程中的 unlinkability，即混淆器和其他观察者无法得知哪个买家向哪个卖家付款。为了实现这一目标，文章提出了一种基于预言机的unlinkable 继承支付（O-UCP）四方加密协议，该协议要求四个安全属性：(i) 混淆器安全性，保证如果混淆器向卖家付款，则混淆器必须从买家那里获得付款；(ii) 卖家安全性，保证如果卖家向买家交付产品，卖家必须从混淆器处获得付款；(iii) 买家安全性，保证如果买家向混淆器付款，买家必须获得产品；以及(iv) 不可链接性，保证混淆器不应知道哪些买家向哪些卖家付款。文中给出了一个经过形式化安全证明和高效实施的O-UCP构造方案，适用于大多数区块链，因为其功能需求最小（例如只需数字签名和时间锁）。为了展示其实用性，文章提供了O-UCP的概念验证及性能基准测试，结果显示通信开销小（每条消息仅几kB）且运行时间低于一秒。 <div>
A contingent payment protocol involves two mutually distrustful parties,  a buyer and a seller, operating on the same blockchain, and a digital product, whose ownership is not tracked on a blockchain (e.g. a digital book). The buyer holds coins on the blockchain and transfers them to the seller in exchange for the product.  However, if the blockchain does not hide transaction details, any observer can learn that a buyer purchased some product from a seller.

    In this work, we take contingent payment a step further: we consider a buyer who wishes to buy a digital product from a seller routing the payment via an untrusted mixer.
    Crucially, we require that said payment is unlinkable, meaning that the mixer (or any other observer) does not learn which buyer is paying  which seller. We refer to such setting as unlinkable contingent payment (UCP).
    
    We present MixBuy,  a system that realizes UCP. Mixbuy relies on oracle-based unlinkable contingent payment (O-UCP), a novel four-party cryptographic protocol where the mixer pays the seller and the seller provides the buyer with the product only if a semi-trusted notary attests that the buyer has paid the mixer. More specifically, we require four security notions: (i) mixer security that guarantees that if the mixer pays the seller, the mixer must get paid from the buyer; (ii) seller security that guarantees that if the seller delivers the product to the buyer, the seller must get paid from the mixer; (iii) buyer security that guarantees that if the buyer pays the mixer, the buyer must obtain the product; and  (iv) unlinkability that guarantees that given a set of buyers and sellers, the mixer should not learn which buyer paid which seller.

    We present a provably secure and efficient cryptographic construction for O-UCP. Our construction can be readily used to realize UCP on most blockchains, as it has minimal functionality requirements (i.e., digital signatures and timelocks). To demonstrate the practicality of our construction, we provide a proof of concept for O-UCP and our benchmarks in commodity hardware show that the communication overhead is small (a few kB per message) and the running time is below one second.
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 15:27:21 +0000</pubDate>
</item>
<item>
<title>The LaZer Library: Lattice-Based Zero Knowledge and Succinct Proofs for Quantum-Safe Privacy</title>
<link>https://eprint.iacr.org/2024/1846</link>
<guid>https://eprint.iacr.org/2024/1846</guid>
<content:encoded><![CDATA[
<div> 关键词: 硬度、格问题、量子安全加密、零知识证明、简洁证明库

总结:
文章介绍了基于格问题硬度的量子安全加密技术，特别是其中的零知识证明领域取得了显著效率提升，并为许多场景提供了最短、最高效的证明。然而，非专家使用这些证明时面临诸多挑战，因为它们内部参数依赖于特定实例。为此，文中提出了一款简洁而高效的C代码库，其上层封装了易于使用的Python接口，使用户无需了解格基础证明知识，只需指定要证明的格关系和范数约束，库就能自动生成相应的证明系统。该库支持LaBRADOR或Lyubashevsky等人提出的两种证明方案。通过Python接口，用户还能进行常见的 lattice 基础密码学操作，方便在简单的Python环境中编写和原型化完整协议。文章以盲签协议、匿名凭据、Swoosh协议所需的零知识证明、Kyber密钥知识证明以及聚合签名方案等为例，展示了该库的应用价值，表明这些实现从尺寸、速度和内存角度讲，均是最优的量子安全实例。 <div>
The hardness of lattice problems offers one of the most promising
security foundations for quantum-safe cryptography. Basic schemes
for public key encryption and digital signatures are already close to
standardization at NIST and several other standardization bodies,
and the research frontier has moved on to building primitives with
more advanced privacy features. At the core of many such primi-
tives are zero-knowledge proofs. In recent years, zero-knowledge
proofs for (and using) lattice relations have seen a dramatic jump
in efficiency and they currently provide arguably the shortest, and
most computationally efficient, quantum-safe proofs for many sce-
narios. The main difficulty in using these proofs by non-experts
(and experts!) is that they have a lot of moving parts and a lot of
internal parameters depend on the particular instance that one is
trying to prove.
Our main contribution is a library for zero-knowledge and suc-
cinct proofs which consists of efficient and flexible C code under-
neath a simple-to-use Python interface. Users without any back-
ground in lattice-based proofs should be able to specify the lattice
relations and the norm bounds that they would like to prove and the
library will automatically create a proof system, complete with the
intrinsic parameters, using either the succinct proofs of LaBRADOR
(Beullens and Seiler, Crypto 2023) or the linear-size, though smaller
for certain application, proofs of Lyubashevsky et al. (Crypto 2022).
The Python interface also allows for common operations used in
lattice-based cryptography which will enable users to write and pro-
totype their full protocols within the syntactically simple Python
environment.
We showcase some of the library’s usefulness by giving protocol
implementations for blind signatures, anonymous credentials, the
zero-knowledge proof needed in the recent Swoosh protocol (Gaj-
land et al., Usenix 2024), proving knowledge of Kyber keys, and an
aggregate signature scheme. Most of these are the most efficient,
from a size, speed, and memory perspective, known quantum-safe
instantiations.
]]></content:encoded>
<pubDate>Sun, 10 Nov 2024 18:41:01 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Location Privacy via Accurate Floating-Point SNARKs</title>
<link>https://eprint.iacr.org/2024/1842</link>
<guid>https://eprint.iacr.org/2024/1842</guid>
<content:encoded><![CDATA[
<div> 关键词: Zero-Knowledge Location Privacy (ZKLP), Zero-Knowledge Proof (ZKP), IEEE 754标准, 浮点运算, 隐私保护

总结:
本文介绍了零知识位置隐私（ZKLP）技术，该技术允许用户向第三方证明他们位于特定地理区域内，而不泄露其精确位置。ZKLP支持不同级别的粒度，可以根据具体应用场景进行定制。为了实现ZKLP，研究者首次提出了完全符合IEEE 754浮点运算标准的ZKP电路。实验结果显示，这些浮点电路具有高效的摊还性能，对于$2^{15}$个单精度浮点数乘法操作，每个乘法仅需$64$个约束条件。利用这一浮点数实现，成功地实现了ZKLP范式。与基准方案相比，使用单精度浮点值优化后的实现方案约束条件减少了$15.9\times$，而使用双精度浮点值则减少了$12.2\times$。为了验证ZKLP的实用性，文章构建了一个隐私保护的点对点近邻测试协议，使得Alice无需透露任何其他地理位置信息就能通过接收一条消息来判断自己是否接近Bob。在这种配置下，Bob可以在$0.26s$内创建一个（非）接近性的证明，而Alice每秒可以验证约$470$个同伴的距离。 <div>
We introduce Zero-Knowledge Location Privacy (ZKLP), enabling users to prove to third parties that they are within a specified geographical region while not disclosing their exact location. ZKLP supports varying levels of granularity, allowing for customization depending on the use case. To realize ZKLP, we introduce the first set of Zero-Knowledge Proof (ZKP) circuits that are fully compliant to the IEEE 754 standard for floating-point arithmetic.
  Our results demonstrate that our floating point circuits amortize efficiently, requiring only $64$ constraints per multiplication for $2^{15}$ single-precision floating-point multiplications. We utilize our floating point implementation to realize the ZKLP paradigm. In comparison to a baseline, we find that our optimized implementation has $15.9 \times$ less constraints utilizing single precision floating-point values, and $12.2 \times$ less constraints when utilizing double precision floating-point values. We demonstrate the practicability of ZKLP by building a protocol for privacy preserving peer-to-peer proximity testing - Alice can test if she is close to Bob by receiving a single message, without either party revealing any other information about their location. In such a configuration, Bob can create a proof of (non-)proximity in $0.26 s$, whereas Alice can verify her distance to about $470$ peers per second.
]]></content:encoded>
<pubDate>Sat, 09 Nov 2024 13:29:56 +0000</pubDate>
</item>
<item>
<title>Cryptographically Secure Digital Consent</title>
<link>https://eprint.iacr.org/2024/1839</link>
<guid>https://eprint.iacr.org/2024/1839</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字同意、加密安全、第三方服务、客户端、身份管理器

总结:
本文提出了一个灵活且加密安全的数字同意方案，以适应不同的在线应用场景并确保同意过程的完整性。该框架涉及客户端（指用户或其设备）、身份管理器（负责认证客户端）和代理（在获得同意后执行操作）。客户端仅需记住一个密码，方案着重解决了防止离线词典攻击、确保不可否认的同意证明以及防止代理人未经授权的操作等安全与隐私挑战。即使身份管理器或代理被妥协，只要不同时发生，仍能保持安全性。文中所指的身份管理器可以包括多种认证因素的组合，如密码、智能手机、安全设备、生物特征或电子护照，并通过签署PDF文档、电子银行和密钥恢复等多个应用实例进行了演示。 <div>
In the digital age, the concept of consent for online actions executed by third parties is crucial for maintaining trust and security in third-party services. 
This work introduces the notion of cryptographically secure digital consent, which aims to replicate the traditional consent process in the online world. 
We provide a flexible digital consent solution that accommodates different use cases and ensures the integrity of the consent process.

The proposed framework involves a client (referring to the user or their devices), an identity manager (which authenticates the client), and an agent (which executes the action upon receiving consent). 
It supports various applications and ensures compatibility with existing identity managers. 
We require the client to keep no more than a password. The design addresses several security and privacy challenges, including preventing offline dictionary attacks, ensuring non-repudiable consent, and preventing unauthorized actions by the agent. 
Security is maintained even if either the identity manager or the agent is compromised, but not both.

Our notion of an identity manager is broad enough to include combinations of different authentication factors such as a password, a smartphone, a security device, biometrics, or an e-passport. We demonstrate applications for signing PDF documents, e-banking, and key recovery.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 20:24:02 +0000</pubDate>
</item>
<item>
<title>A Query Reconstruction Attack on the Chase-Shen Substring-Searchable Symmetric Encryption Scheme</title>
<link>https://eprint.iacr.org/2024/1837</link>
<guid>https://eprint.iacr.org/2024/1837</guid>
<content:encoded><![CDATA[
<div> 关键词：可搜索对称加密（SSE）、泄漏分析、子串查询、Chase和Shen方案、攻击模型

<br /><br />总结:
本文首次针对Chase和Shen在 PoPETS '15 提出的子串可搜索对称加密（substring-SSE）方案进行了泄漏分析。研究中，作者提出了一个创新的基于推理的查询重建攻击方法，该方法利用了该方案实际泄漏概况的一个简化版本，并假设了一个比原方案声称的安全模型更为宽松的攻击模型。作者已实现并实验验证了此攻击的成功率和效率，它在包含10万条字符串的真实世界数据集上实现了高查询重建率，并能有效扩展到大规模数据集。据所知，这是至今为止对任何子串-SSE方案的第一个也是唯一一个查询重建攻击，以及第一次系统性的泄漏分析。 <div>
Searchable symmetric encryption (SSE) enables queries over symmetrically encrypted databases. To achieve practical efficiency, SSE schemes incur a certain amount of leakage; however, this leads to the possibility of leakage cryptanalysis, i.e., cryptanalytic attacks that exploit the leakage from the target SSE scheme to subvert its data and query privacy guarantees. Leakage cryptanalysis has been widely studied in the context of SSE schemes supporting either keyword queries or range queries, often with devastating consequences. However, little or no attention has been paid to cryptanalysing substring-SSE schemes, i.e., SSE schemes supporting arbitrary substring queries over encrypted data. This is despite their relevance to many real-world applications, e.g., in the context of securely querying outsourced genomic databases. In particular, the first ever substring-SSE scheme, proposed nearly a decade ago by Chase and Shen (PoPETS '15), has not been cryptanalysed to date.

In this paper, we present the first leakage cryptanalysis of the substring-SSE scheme of  Chase and Shen. We propose a novel inference-based query reconstruction attack that: (i) exploits a reduced version of the actual leakage profile of their scheme,  and (ii) assumes a weaker attack model as compared to the one in which Chase and Shen originally claimed security. We implement our attack and experimentally validate its success rate and efficiency over two real-world datasets. Our attack achieves high query reconstruction rate with practical efficiency, and scales smoothly to large datasets containing $100,000$ strings. 

To the best of our knowledge, ours is the first and only query reconstruction attack on (and the first systematic leakage cryptanalysis of) any substring-SSE scheme till date.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 10:59:11 +0000</pubDate>
</item>
<item>
<title>One Server for the Price of Two: Simple and Fast Single-Server Private Information Retrieval</title>
<link>https://eprint.iacr.org/2022/949</link>
<guid>https://eprint.iacr.org/2022/949</guid>
<content:encoded><![CDATA[
<div> 关键词：SimplePIR、最快单服务器私有信息检索、学习带有错误假设、DoublePIR、私人审计

总结:
<br />
本文介绍了SimplePIR，这是目前最快的已知单服务器私有信息检索方案，其安全性基于学习带有错误的假设。SimplePIR在回答客户端查询时，对每个数据库字节执行少于一次32位乘法和一次32位加法操作，实现了接近机器内存带宽的10 GB/s/core的服务器吞吐量，性能逼近最快的双服务器（需要非共谋）私有信息检索方案。然而，SimplePIR具有较大的通信成本，为查询1 GB的数据库，客户端需要下载121 MB的“提示”数据；之后客户端可以进行无限次数的查询，每次查询需通信242 KB。文章还提出了另一个名为DoublePIR的单服务器方案，它将提示数据缩小到16 MB，但每查询通信成本提高至345 KB，同时服务器吞吐量降至7.4 GB/s/core。最后，文章将这两个新的私有信息检索方案与一种新颖的大致集合成员资格数据结构相结合，应用于证书透明度中的私有审核任务，实现了比Google Chrome当前方法更严格的隐私保护概念，同时也仅带来了适度的通信开销：每月下载16 MB，以及每个TLS连接额外150字节的数据传输。 <div>
We present SimplePIR, the fastest single-server private information retrieval scheme known to date. SimplePIR’s security holds under the learning-with-errors assumption. To answer a client’s query, the SimplePIR server performs fewer than one 32-bit multiplication and one 32-bit addition per database byte. SimplePIR achieves 10 GB/s/core server throughput, which approaches the memory bandwidth of the
machine and the performance of the fastest two-server private-information-retrieval schemes (which require non-colluding servers). SimplePIR has relatively large communication costs: to make queries to a 1 GB database, the client must download a 121 MB "hint" about the database contents; thereafter, the client may make an unbounded number of queries, each requiring 242 KB of communication. We present a second single-server scheme, DoublePIR, that shrinks the hint to 16 MB at the cost of slightly higher per-query communication (345 KB) and slightly lower throughput (7.4 GB/s/core). Finally, we apply our new private-information-retrieval schemes, together with a novel data structure for approximate set membership, to the task of private auditing in Certificate Transparency. We achieve a strictly stronger notion of privacy than Google Chrome’s current approach with modest communication overheads: 16 MB of download per month, along with 150 bytes per TLS connection.
]]></content:encoded>
<pubDate>Fri, 22 Jul 2022 23:41:48 +0000</pubDate>
</item>
<item>
<title>Scutum: Temporal Verification for Cross-Rollup Bridges via Goal-Driven Reduction</title>
<link>https://eprint.iacr.org/2024/1834</link>
<guid>https://eprint.iacr.org/2024/1834</guid>
<content:encoded><![CDATA[
<div> 关键词: Scalability, Blockchain, Rollups, Cross-rollup bridges, Security verification

总结:
随着区块链领域对可扩展性的需求日益增加，Rollups（尤其是零知识和乐观Rollups）通过链下处理交易以保持以太坊的安全性，降低 gas 费并提高速度。然而，跨Rollup桥接器如Orbiter Finance虽然实现了不同Layer 2及与Layer 1之间的资产无缝转移，但其安全性问题也愈发突出，近期多起重大黑客攻击事件造成了数亿美元损失。鉴于传统安全分析方法如静态分析和模糊测试对于这类复杂设计的跨Rollup桥接器难以奏效，本文提出了一种可扩展的验证器来系统评估跨Rollup桥接器的安全性。该方法采用全面的多模型框架，利用时态属性捕获单个行为和复杂的交互关系。为了提高可扩展性，我们通过图表示合约的可达性分析近似实现时态安全性验证，并结合先进的程序分析技术。此外，我们引入了基于冲突驱动的细化循环来消除误报并提高精度。实证研究中，我们在主流跨Rollup桥接器（包括Orbiter Finance）上发现多个零日漏洞，证明了这种方法的实际应用价值。该工具还表现出良好的运行时间性能，适合实时或近乎实时的应用场景进行有效分析。 <div>
Scalability remains a key challenge for blockchain adoption. Rollups—especially zero-knowledge (ZK) and optimistic rollups—address this by processing transactions off-chain while maintaining Ethereum’s security, thus reducing gas fees and improving speeds. Cross-rollup bridges like Orbiter Finance enable seamless asset transfers across various Layer 2 (L2) rollups and between L2 and Layer 1 (L1) chains. However, the increasing reliance on these bridges raises significant security concerns, as evidenced by major hacks like those of Poly Network and Nomad Bridge, resulting in losses of hundreds of millions of dollars. Traditional security analysis methods such as static analysis and fuzzing are inadequate for cross-rollup bridges due to their complex designs involving multiple entities, smart contracts, and zero-knowledge circuits. These systems require reasoning about temporal sequences of events across different entities, which exceeds the capabilities of conventional analyzers.
In this paper, we introduce a scalable verifier to systematically assess the security of cross-rollup bridges. Our approach features a comprehensive multi-model framework that captures both individual behaviors and complex interactions using temporal properties. To enhance scalability, we approximate temporal safety verification through reachability analysis of a graph representation of the contracts, leveraging advanced program analysis techniques. Additionally, we incorporate a conflict-driven refinement loop to eliminate false positives and improve precision. Our evaluation on mainstream cross-rollup bridges, including Orbiter Finance, uncovered multiple zero-day vulnerabilities, demonstrating the practical utility of our method. The tool also exhibited favorable runtime performance, enabling efficient analysis suitable for real-time or near-real-time applications.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 04:03:24 +0000</pubDate>
</item>
<item>
<title>A Tight Analysis of GHOST Consistency</title>
<link>https://eprint.iacr.org/2024/1830</link>
<guid>https://eprint.iacr.org/2024/1830</guid>
<content:encoded><![CDATA[
<div> 关键词: GHOST协议、Nakamoto共识机制、以太坊、安全性区域、区块生产率

总结:
本文探讨了GHOST协议作为对比特币中Nakamoto共识机制改进的安全性区域。与Nakamoto共识规则不同，GHOST规则通过计算子树权重而非单个路径来选择区块链。该机制已被多种共识协议采纳，并应用于当前支持以太坊的协议中。文章精确刻画了GHOST协议的安全性区域，揭示了诚实区块生产和恶意区块生产速率以及网络延迟之间达成共识所需的关联关系。研究发现，其安全性区域取决于协议采用的平局解决方式：针对敌对平局解决（不利于共识）和确定性平局解决（在整个执行过程中一致性地打破平局），文中都提出了具体的攻击策略并证明了两种情况下共识可能在安全区域之外被阻塞。结果表明，通过引入平局解决机制可以严格改善GHOST协议的安全性区域，但无论采用何种方式，最终的安全性区域仍逊色于Nakamoto共识机制的安全性区域。 <div>
The GHOST protocol has been proposed as an improvement to the Nakamoto consensus mechanism that underlies Bitcoin. In contrast to the Nakamoto fork-choice rule, the GHOST rule justifies selection of a chain with weights computed over subtrees rather than individual paths. This mechanism has been adopted by a variety of consensus protocols, and is a part of the currently deployed protocol supporting Ethereum.

We establish an exact characterization of the security region of the GHOST protocol, identifying the relationship between the rate of honest block production, the rate of adversarial block production, and network delays that guarantee that the protocol reaches consensus. In contrast to the closely related Nakamoto consensus protocol, we find that the region depends on the convention used by the protocol for tiebreaking; we establish tight results for both adversarial tiebreaking, in which ties are broken adversarially in order to frustrate consensus, and deterministic tiebreaking, in which ties between pairs of blocks are broken consistently throughout an execution. We provide explicit attacks for both conventions which stall consensus outside of the security region. 

Our results conclude that the security region of GHOST can be strictly improved by incorporating a tiebreaking mechanism; in either case, however, the final region of security is inferior to the region of Nakamoto consensus.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 19:37:02 +0000</pubDate>
</item>
<item>
<title>A Composability Treatment of Bitcoin's Transaction Ledger with Variable Difficulty</title>
<link>https://eprint.iacr.org/2024/1823</link>
<guid>https://eprint.iacr.org/2024/1823</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、proof-of-work (PoW)、动态参与、安全性分析、模拟-based 分析

总结:<br />
本文首次（据作者所知）针对运行于动态环境中的比特币区块链进行了基于模拟的分析。文章指出，现有的关于比特币的安全性分析是基于属性的，仅保证了协议在孤立运行时的安全性。研究中，提出了比特币背骨协议的抽象模型，该模型在特定参与限制条件下，能够体现出比特币预期的设计规范。此外，本文扩展了固定难度设置下的普适组合性处理方式，并发展出了可能具有更广泛适用性的技术，特别是对于依赖难度调整的其他可组合区块链协议的分析形式。 <div>
As the first proof-of-work (PoW) permissionless blockchain, Bitcoin aims at maintaining a decentralized yet consistent transaction ledger as protocol participants (“miners”) join and leave as they please. This is achieved by means of a subtle PoW difficulty adjustment mechanism that adapts to the perceived block generation rate, and important steps have been taken in previous work to provide a rigorous analysis of the conditions (such as bounds on dynamic participation) that are sufficient for Bitcoin’s security properties to be ascertained.

Such existing analysis, however, is property-based, and as such only guarantees security when the protocol is run $\textbf{in isolation}$. In this paper we present the first (to our knowledge) simulation-based analysis of the Bitcoin ledger in the dynamic setting where it operates, and show that the protocol abstraction known as the Bitcoin backbone protocol emulates, under certain participation restrictions, Bitcoin’s intended specification. Our formulation and analysis extend the existing Universally Composable treatment for the fixed-difficulty setting, and develop techniques that might be of broader applicability, in particular to other composable formulations of blockchain protocols that rely on difficulty adjustment.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 09:30:47 +0000</pubDate>
</item>
<item>
<title>Anonymous Public-Key Quantum Money and Quantum Voting</title>
<link>https://eprint.iacr.org/2024/1822</link>
<guid>https://eprint.iacr.org/2024/1822</guid>
<content:encoded><![CDATA[
<div> 关键词：量子货币、隐私、公开密钥、不可追踪性、投票方案<br /><br />总结:<br />
本文主要关注了量子货币领域的隐私问题以及其在投票应用中的潜力。首先，文章提出了量子货币的隐私安全定义，并构建了首个具有用户匿名性和当局可追踪性的公钥量子货币方案。同时，也设计了一个连当局都无法追踪的不可追踪量子货币方案。此外，利用量子力学的不可克隆原理，文章还构造了一个基于经典投票的、具有普适验证性的量子投票方案。为了实现这些目标，文中引入了一种新的技术工具——具有强正确性的公共重随机化加密方案，并在假设学习错误困难性和量子学习错误困难性的前提下，给出了一个后量子时代的经典实现。 <div>
Quantum information allows us to build quantum money schemes, where a bank can issue banknotes in the form of authenticatable quantum states that cannot be cloned or counterfeited: a user in possession of k banknotes cannot produce k +1 banknotes. Similar to paper banknotes, in existing quantum money schemes, a banknote consists of an unclonable quantum state and a classical serial number, signed by bank. Thus, they lack one of the most fundamental properties cryptographers look for in a currency scheme: privacy. In this work, we first further develop the formal definitions of privacy for quantum money schemes. Then, we construct the first public-key quantum money schemes that satisfy these security notions. Namely, 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Errors, we construct a public-key quantum money scheme with anonymity against users and traceability by authorities. 

Since it is a policy choice whether authorities should be able to track banknotes or not, we also construct an untraceable money scheme, where no one (not even the authorities) can track banknotes. 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Er- rors, we construct a public-key quantum money scheme with untraceability. 

Further, we show that the no-cloning principle, a result of quantum mechanics, allows us to construct schemes, with security guarantees that are classically impossible, for a seemingly unrelated application: voting! 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Errors, we construct a universally verifiable quantum voting scheme with classical votes. 

Finally, as a technical tool, we introduce the notion of publicly rerandomizable encryption with strong correctness, where no adversary is able to produce a malicious ciphertext and a malicious random tape such that the ciphertext before and after rerandomization (with the malicious tape) decrypts to different values! We believe this might be of independent interest. • Assuming the (quantum) hardness of Learning with Errors, we construct a (post-quantum) classical publicly rerandomizable encryption scheme with strong correctness
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 07:25:38 +0000</pubDate>
</item>
<item>
<title>SCIF: Privacy-Preserving Statistics Collection with Input Validation and Full Security</title>
<link>https://eprint.iacr.org/2024/1821</link>
<guid>https://eprint.iacr.org/2024/1821</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全聚合、SCIF、输入验证、恶意服务器、拒绝服务攻击

<br /><br />总结:
本文介绍了一种名为SCIF的新颖多服务器安全聚合协议，该协议带有输入验证功能，并能在存在少于三分之一恶意服务器的情况下确保安全性。与现有协议（如Prio、Prio+、Elsa和Whisper）相比，SCIF具有两大优势：(1) 确保输出交付，即恶意参与者无法阻止协议完成，从而增强了对拒绝服务攻击的抵抗能力；(2) 确保输入包含，意味着恶意参与者无法阻止诚实参与者的输入被纳入计算。同时，SCIF在不增加客户端成本的同时保持了服务器成本的适度。文章还展示了SCIF的强大可实施性，通过将其集成到模拟的Tor网络中，实现了隐私保护测量的便捷部署。 <div>
Secure aggregation is the distributed task of securely computing a sum of values (or a vector of values) held by a set of parties, revealing only the output (i.e., the sum) in the computation. Existing protocols, such as Prio (NDSI’17), Prio+ (SCN’22), Elsa (S&amp;P’23), and Whisper (S&amp;P’24), support secure aggregation with input validation to ensure inputs belong to a specified domain. However, when malicious servers are present, these protocols primarily guarantee privacy but not input validity. Also, malicious server(s) can cause the protocol to abort. We introduce SCIF, a novel multi-server secure aggregation protocol with input validation, that remains secure even in the presence of malicious actors, provided fewer than one-third of the servers are malicious. Our protocol overcomes previous limitations by providing two key properties: (1) guaranteed output delivery, ensuring malicious parties cannot prevent the protocol from completing, and (2) guaranteed input inclusion, ensuring no malicious party can prevent an honest party’s input from being included in the computation. Together, these guarantees provide strong resilience against denial-of-service attacks. Moreover, SCIF offers these guarantees without increasing client costs over Prio and keeps server costs moderate. We present a robust end-to-end implementation of SCIF and demonstrate the ease with which it can be instrumented by integrating it in a simulated Tor network for privacy-preserving measurement.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 21:12:04 +0000</pubDate>
</item>
<item>
<title>SophOMR: Improved Oblivious Message Retrieval from SIMD-Aware Homomorphic Compression</title>
<link>https://eprint.iacr.org/2024/1814</link>
<guid>https://eprint.iacr.org/2024/1814</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护区块链、私密消息服务、Oblivious Message Retrieval (OMR)、Homomorphic Encryption (HE)、性能优化

总结:

我们提出了一种新的Oblivious Message Retrieval (OMR)方案，旨在解决隐私保护区块链和私密消息服务中客户端需逐个扫描大量公开载荷以避免漏收消息的用户体验问题。该方案通过使用Homomorphic Encryption (HE)将昂贵的扫描过程安全地外包给服务提供商。相比于之前的最优方案PerfOMR，我们的实现显示出了显著的改进：运行时间减少了3.3倍，摘要大小减小了2.2倍，密钥大小减小了1.3倍。这些提升的核心在于我们创新的同态压缩机制，它能够将长度与总载荷数成比例的密文压缩为长度与相关载荷数上限成比例的摘要。不同于以往的方法，我们的方案充分利用了底层HE方案固有的同态SIMD结构，从而大幅提高了效率。在描述的场景（65536个每个612字节的载荷，其中最多50个相关）下，我们的压缩方案相比PerfOMR实现了7.4倍的速度提升。 <div>
Privacy-preserving blockchains and private messaging services that ensure receiver-privacy face a significant UX challenge: each client must scan every payload posted on the public bulletin board individually to avoid missing messages intended for them. Oblivious Message Retrieval (OMR) addresses this issue by securely outsourcing this expensive scanning process to a service provider using Homomorphic Encryption (HE).

In this work, we propose a new OMR scheme that substantially improves upon the previous state-of-the-art, PerfOMR (USENIX Security'24). Our implementation demonstrates reductions of 3.3x in runtime, 2.2x in digest size, and 1.3x in key size, in a scenario with 65536 payloads (each 612 bytes), of which up to 50 are pertinent.

At the core of these improvements is a new homomorphic compression mechanism, where ciphertexts of length proportional to the number of total payloads are compressed into a digest whose length is proportional to the upper bound on the number of pertinent payloads. Unlike previous approaches, our scheme fully exploits the native homomorphic SIMD structure of the underlying HE scheme, significantly enhancing efficiency. In the setting described above, our compression scheme achieves 7.4x speedup compared to PerfOMR.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:39:25 +0000</pubDate>
</item>
<item>
<title>Revisiting Leakage-Resilient MACs and Succinctly-Committing AEAD: More Applications of Pseudo-Random Injections</title>
<link>https://eprint.iacr.org/2024/1813</link>
<guid>https://eprint.iacr.org/2024/1813</guid>
<content:encoded><![CDATA[
<div> 关键词: Pseudo-Random Injections (PRIs), Message Authentication Codes (MACs), Authenticated Encryption with Associated Data (AEAD), Collision Resistance, UnForgeability

总结:
本文重新探讨了伪随机注入（PRIs）在构建消息认证码（MACs）和Authenticated Encryption with Associated Data（AEAD）方案中的应用。首先，文章分析了在不同泄漏模型下，PRIs作为具有小明文空间的MAC时所具有的碰撞抵抗性和不可伪造性等性质。接着，展示了如何将PRIs与抗碰撞哈希函数结合，构建针对长明文的MAC，根据PRI和相等性检查的实现方式提供灵活的安全性。若两者都无泄漏，则MAC提供接近最优安全性；即使仅相等性检查具有泄漏抵抗力，安全性能也只会轻微下降；而在相等性检查有无界泄漏的情况下，安全性降低至基线水平而非完全不安全。

此外，文章提出了使用PRIs从头开始构建一个名为scoAE的简洁承诺在线AEAD方案，该方案实现了简洁的CMT4安全、隐私以及Ciphertext Integrity with Misuse and Leakage (CIML2) 安全性。最后，通过结合SIV范式与基于PRI的加密（例如Encode-then-Encipher (EtE)框架），文章展示了一个简洁的nonce耐滥用（MRAE）AEAD方案——scMRAE。 <div>
Pseudo-Random Injections (PRIs) have had several applications in symmetric-key cryptography, such as in the idealization of Authenticated Encryption with Associated Data (AEAD) schemes, building robust AEAD, and, recently, in converting a committing AEAD scheme into a succinctly committing AEAD scheme. In Crypto 2024, Bellare and Hoang showed that if an AEAD scheme is already committing, it can be transformed into a succinctly committed scheme by encrypting part of the plaintext using a PRI. In this paper, we revisit the applications of PRIs in building Message Authentication Codes (MACs) and AEAD schemes. 

First, we look at some of the properties and definitions PRIs, such as collision resistance and unforgeability when used as a MAC with small plaintext space, under different leakage models. Next, we show how they can be combined with collision-resistant hash functions to build a MAC for long plaintexts, offering flexible security depending on how the PRI and equality check are implemented. If both the PRI and equality check are leak-free, the MAC provides almost optimal security, but the security 
only degrades a little if the equality check is only leakage-resilient (rather than leak-free). If the equality check has unbounded leakage, the security drops to a baseline security, rather than being completely insecure. Next, we show how to use PRIs to build a succinctly committing online AEAD scheme dubbed as scoAE from scratch that achieves succinct CMT4 security, privacy, and Ciphertext Integrity with Misuse and Leakage (CIML2) security. Last but not least, we show how to build a succinct nonce Misuse-Resistant (MRAE) AEAD scheme, dubbed as scMRAE. The construction combines the SIV paradigm with PRI-based encryption (e.g. the Encode-then-Encipher (EtE) framework).
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 21:43:34 +0000</pubDate>
</item>
<item>
<title>Foundations of Adaptor Signatures</title>
<link>https://eprint.iacr.org/2024/1809</link>
<guid>https://eprint.iacr.org/2024/1809</guid>
<content:encoded><![CDATA[
<div> 关键词：adaptor签名、安全性、预签名、应用、安全模型<br /><br />总结:
本文针对adaptor签名的安全性和构建进行了重新审视。首先，作者指出了Aumayr等人在ASIACRYPT'21中提出的adaptor签名安全模型存在的缺陷，这些缺陷导致已知的一些应用于私人币混洗和基于oracle支付的协议不安全，并通过实例说明了根据原有定义仍被认为是安全的adaptor签名可能在实际应用中引发不安全性。为填补这一空白，作者提出了适应这些实际应用场景的最小化模块化定义。其次，鉴于所有已知构造要么源自识别方案并通过Fiat-Shamir变换在随机预言机模型中构建，要么需要修改基础签名验证算法而不适用于加密货币场景，而且它们都只是基于Aumayr等人的不足定义证明了安全性，因此目前没有可用于实际应用的可证明安全的adaptor签名方案。对此，本文证明了广泛使用的Schnorr adaptor签名在新提议的定义下是安全的，并提供了新的构造，包括首次为Camenisch-Lysyanskaya（CL）、Boneh-Boyen-Shacham（BBS+）和Waters签名设计的adaptor签名方案，且所有这些都在标准模型中被证明安全。新构造依赖于名为dichotomic签名的新颖数字签名抽象，以及一种用于证明所有构造（包括基于识别的方案）安全性的新型非黑盒证明技术。同时，作者提出的新数字签名抽象和证明技术对于社区来说具有独立的研究价值。 <div>
Adaptor signatures extend the functionality of regular signatures through the computation of pre-signatures on messages for statements of NP relations. Pre-signatures are publicly verifiable; they simultaneously hide and commit to a signature of an underlying signature scheme on that message. Anybody possessing a corresponding witness for the statement can adapt the pre-signature to obtain the "regular" signature. Adaptor signatures have found numerous applications for conditional payments in blockchain systems, like payment channels (CCS'20, CCS'21), private coin mixing (CCS'22, SP'23), and oracle-based payments (NDSS'23). 

In our work, we revisit the state of the security of adaptor signatures and their constructions. In particular, our two main contributions are:

- Security Gaps and Definitions: We review the widely-used security model of adaptor signatures due to Aumayr et al. (ASIACRYPT'21) and identify gaps in their definitions that render known protocols for private coin-mixing and oracle-based payments insecure. We give simple counterexamples of adaptor signatures that are secure w.r.t. their definitions but result in insecure instantiations of these protocols. To fill these gaps, we identify a minimal set of modular definitions that align with these practical applications.
 
- Secure Constructions: Despite their popularity, all known constructions are (1) derived from identification schemes via the Fiat-Shamir transform in the random oracle model or (2) require modifications to the underlying signature verification algorithm, thus making the construction useless in the setting of cryptocurrencies. More concerningly, all known constructions were proven secure w.r.t. the insufficient definitions of Aumayr et al., leaving us with no provably secure adaptor signature scheme to use in applications.
    
    Firstly, in this work, we salvage all current applications by proving the security of the widely-used Schnorr adaptor signatures under our proposed definitions. We then provide several new constructions, including presenting the first adaptor signature schemes for Camenisch-Lysyanskaya (CL), Boneh-Boyen-Shacham (BBS+), and Waters signatures, all of which are proven secure in the standard model. Our new constructions rely on a new abstraction of digital signatures, called dichotomic signatures, which covers the essential properties we need to build adaptor signatures. Proving the security of all constructions (including identification-based schemes) relies on a novel non-black-box proof technique. Both our digital signature abstraction and the proof technique could be of independent interest to the community.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 10:37:42 +0000</pubDate>
</item>
<item>
<title>Siniel: Distributed Privacy-Preserving zkSNARK</title>
<link>https://eprint.iacr.org/2024/1803</link>
<guid>https://eprint.iacr.org/2024/1803</guid>
<content:encoded><![CDATA[
<div> 关键词：zkSNARK、计算开销、私有委托、Siniel、EOS

<br /><br />总结：

本文提出了一种名为Siniel的高效私有委托框架，用于优化zkSNARK（零知识简洁非交互式知识论证）。Siniel通过结合多项式交互式预言机证明（PIOP）和多项式承诺方案（PCS），使得计算能力有限的证明者（即委托人）能够将昂贵的证明计算任务安全地委托给多个工作者，同时不泄露任何关于私有见证的信息。与当前最先进的zkSNARK证明者委托框架EOS相比，Siniel的独特之处在于，证明者在发送私有见证的份额后无需参与多 party 计算（MPC）协议，这意味着证明者可以完全将计算过程外包给工作者。实验结果显示，在低带宽（10Mbps）条件下，Siniel相较于EOS为委托者节省约65%的时间；而在高带宽（1000Mbps）条件下，这一比例提高到约95%，显示了Siniel在性能上的显著优势。 <div>
Zero-knowledge Succinct Non-interactive Argument of Knowledge (zkSNARK) is a powerful cryptographic primitive, in which a prover convinces a verifier that a given statement is true without leaking any additional information. However, existing zkSNARKs suffer from high computation overhead in the proof generation. This limits the applications of zkSNARKs, such as private payments, private smart contracts, and anonymous credentials. Private delegation has become a prominent way to accelerate proof generation.
In this work, we propose Siniel, an efficient private delegation framework for zkSNARKs constructed from polynomial interactive oracle proof (PIOP) and polynomial commitment scheme (PCS). Our protocol allows a computationally limited prover (a.k.a. delegator) to delegate its expensive prover computation to several workers without leaking any information about the private witness. Most importantly, compared with the recent work EOS (USENIX’23), the state-of-the-art zkSNARK prover delegation framework, a prover in Siniel needs not to engage in the MPC protocol after sending its shares of private witness. This means that a Siniel prover can outsource the entire computation to the workers.
We compare Siniel with EOS and show significant performance advantages of the former. The experimental results show that, under low bandwidth conditions (10MBps),
Siniel saves about 65% time for delegators than that of EOS, whereas under high bandwidth conditions (1000MBps), Siniel saves about 95% than EOS.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 13:08:31 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Multi-Party Search via Homomorphic Encryption with Constant Multiplicative Depth</title>
<link>https://eprint.iacr.org/2024/1800</link>
<guid>https://eprint.iacr.org/2024/1800</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、多方搜索协议、阈值级同态加密、电路深度常数、动态数据库

总结:
我们的研究提出了一种采用阈值级同态加密技术的隐私保护多方搜索协议。我们证明了该协议在诚实但好奇的对手面前是正确且安全的。与现有方法不同的是，我们的协议保持了恒定的电路深度，这使得它更适用于涉及动态底层数据库的实际应用场景。<br /><br /> <div>
We propose a privacy-preserving multiparty search protocol
using threshold-level homomorphic encryption, which we prove correct
and secure to honest but curious adversaries. Unlike existing approaches,
our protocol maintains a constant circuit depth. This feature enhances
its suitability for practical applications involving dynamic underlying
databases.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 08:14:14 +0000</pubDate>
</item>
<item>
<title>IrisLock: Iris Biometric Key Derivation with 42 bits of security</title>
<link>https://eprint.iacr.org/2024/100</link>
<guid>https://eprint.iacr.org/2024/100</guid>
<content:encoded><![CDATA[
<div> 关键词：生物特征认证、模糊提取器、安全、独立性假设、IrisLock

总结:

本文介绍了IrisLock，一种基于虹膜的密钥衍生系统，该系统结合了虹膜特征提取技术与改进后的模糊提取器，旨在解决生物特征认证领域的理论与实践之间的鸿沟。传统的生物特征认证算法依赖于泄露私人信息的数据和外部的安全措施，而模糊提取器理论上可以实现安全且保护隐私的生物特征认证。然而，现有模糊提取器系统要么基于未经统计验证或已被证明为错误的独立性假设，要么使用了错误的密码学分析。

IrisLock系统纠正了sample-then-lock方法的证明，并指出子集最小最小熵是相关安全性度量标准。它提供$42$位安全性以及$45\%$的真实接受率(TAR)，与现有系统相比，其定量安全性水平相当甚至更高。通过添加密码，安全性可提升至$64$位。在评估TAR和安全性时，所使用的虹膜数据与训练和收集统计数据的数据类互不重叠（开放式数据集方案）。IrisLock唯一必要的统计假设是对最小熵估计的准确性。 <div>
Despite decades of effort, a chasm exists between the theory and practice of device-level biometric authentication. Deployed authentication algorithms rely on data that overtly leaks private information about the biometric; thus systems rely on externalized security measures such as trusted execution environments. The authentication algorithms have no cryptographic guarantees.
  
This is  frustrating given the research that has developed theoretical tools, known as fuzzy extractors, that enable secure, privacy-preserving biometric authentication with public enrollment data (Dodis et al., SIAM JoC 2008). Unfortunately, fuzzy extractor systems either:
-Make strong independence assumptions, such as:
-- Bits of biometrics are i.i.d. (or that all correlation is pairwise between features (Hine et al., TIFS 2023)), or
-- For an error-correcting code, the nearest codeword and the coset of biometric readings are independent (Zhang, Cui, and Yu, ePrint 2021/1559).
  These assumptions either have not been statistically checked or 
  statistical analysis indicates they are false.
- Or use incorrect cryptographic analysis.  Simhadri et al. (ISC, 2019) assume the security of sample-then-lock (Canetti et al., Journal of Cryptology 2021) is captured by the average min-entropy of subsets.  Zhang et al. (ICPR, 2022) show an attack on this incorrect analysis. 

This work introduces IrisLock, an iris key derivation system powered by technical advances in both
1) feature extraction from the iris  and
2) the fuzzy extractor used to secure authentication keys.  The fuzzy extractor builds on sample-then-lock (Canetti et al., Journal of Cryptology 2021). We correct a proof in Canetti et al. and show the minimum of min-entropy of subsets is the relevant security measure.  Our primary parameters are $42$ bits of security at $45\%$ true accept rate (TAR).  Our quantitive level of security is as good as the above systems, Simhadri et al's incorrect analysis yields an estimate of $32$ bits, while Zhang et al.'s system on the face estimates $45$ bits (with the independence condition). One can easily incorporate a password, boosting security to $64$ bits.

Irises used to evaluate TAR and security are class disjoint from those used for training and collecting statistics (the open dataset regime).
The only statistical assumption made is necessary: the accuracy of min-entropy estimation.
]]></content:encoded>
<pubDate>Mon, 22 Jan 2024 18:21:35 +0000</pubDate>
</item>
<item>
<title>Amun: Securing E-Voting Against Over-the-Shoulder Coercion</title>
<link>https://eprint.iacr.org/2021/851</link>
<guid>https://eprint.iacr.org/2021/851</guid>
<content:encoded><![CDATA[
<div> 关键词：Amun协议、选举、投票隐私、防肩窥、安全性证明<br /><br />总结:
Amun协议是在一场允许每个选民对M个可能选项表达P个偏好级别的选举中，确保投票安全性的方案。它防范了过肩窥视攻击，保护了投票隐私，同时保持了公平性、端到端可验证性和正确性。在选举前，每位选民会收到含有有效和干扰代币的选票，只有有效代币会对最终计票产生影响，但它们与干扰代币无法区分，从而防止了肩窥攻击的发生。我们依据随机预言模型下标准的决策Diffie-Hellman假设证明了该构造的安全性。 <div>
In an election where each voter may express $P$ preferences among $M$ possible choices, the Amun protocol allows to secure vote casting against over-the-shoulder adversaries, retaining privacy, fairness, end-to-end verifiability, and correctness.

Before the election, each voter receives a ballot containing valid and decoy tokens: only valid tokens contribute in the final tally, but they remain indistinguishable from the decoys.
Since the voter is the only one who knows which tokens are valid (without being able to prove it to a coercer), over-the-shoulder attacks are thwarted.

We prove the security of the construction under the standard Decisional Diffie Hellman assumption in the random oracle model.
]]></content:encoded>
<pubDate>Tue, 22 Jun 2021 14:37:01 +0000</pubDate>
</item>
<item>
<title>Is Periodic Pseudo-randomization Sufficient for Beacon Privacy?</title>
<link>https://eprint.iacr.org/2024/1782</link>
<guid>https://eprint.iacr.org/2024/1782</guid>
<content:encoded><![CDATA[
<div> 关键词: 蓝牙低功耗(BLE)、隐私机制、定时序列不可区分性、计时器操纵攻击、随机化调度

总结:
本文研究了蓝牙低功耗(BLE)信标周期性更换伪随机身份的隐私机制是否足以确保隐私。文章提出了一个新的自然隐私概念，称为“定时序列不可区分性”，它不仅关注广播内容，还考虑了可从物理世界中观察到的广播时间，这一定义比传统的不可区分性更强。接着，文章证明周期性更换身份的BLE信标无法实现定时序列不可区分性，并提出了一种名为“计时器操纵攻击”的新颖隐私攻击方法，该攻击只需在对手选择的时间插入或重新插入信标的电池即可实施。作者们对一个实际部署的信标执行了此攻击。为了对抗这种基于周期信号的攻击，他们提出了一种新的随机化调度身份变化的对策，证明此对策可以确保信标的定时序列不可区分性，从而增强其隐私性。此外，文中还展示了如何在被攻击系统中集成这一对策，同时基本上保持其实现可行性和实用性，这对于实际工业应用至关重要。 <div>
In this paper, we investigate whether the privacy mechanism of periodically changing the pseudorandom identities of Bluetooth Low Energy (BLE) beacons is sufficient to ensure privacy.

We consider a new natural privacy notion for BLE broadcasting beacons which we call ``Timed-sequence- indistinguishability'' of beacons. This new privacy definition is stronger than the well-known indistinguishability, since it considers not just the advertisements' content, but also the advertisements' broadcasting times which are observable in the physical world. 

We then prove that beacons with periodically changing pseudorandom identities do not achieve timed-sequence- indistinguishability. We do this by presenting a novel privacy attack against BLE beacons, which we call the ``Timer Manipulation Attack.'' This new time-based privacy attack can be executed by merely inserting or reinserting the beacon's battery at the adversary's chosen time. We performed this attack against an actually deployed beacon.

To mitigate the ``Timer Manipulation Attack'' and other attacks associated with periodic signaling, we propose a new countermeasure involving quasi-periodic randomized scheduling of identity changes. We prove that our countermeasure ensures timed-sequence indistinguishability for beacons, thereby enhancing the beacon's privacy. Additionally, we show how to integrate this countermeasure in the attacked system while essentially preserving its feasibility and utility, which is crucial for practical industrial adoption.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 07:41:25 +0000</pubDate>
</item>
<item>
<title>FLock: Robust and Privacy-Preserving Federated Learning based on Practical Blockchain State Channels</title>
<link>https://eprint.iacr.org/2024/1797</link>
<guid>https://eprint.iacr.org/2024/1797</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习、中毒攻击防御、数据隐私、区块链、状态通道

<br /><br />总结:
本文提出了一种基于实用区块链状态通道的联邦学习方案——FLock，旨在解决现有联邦学习中的关键问题。首先，FLock通过量化、中位数和汉明距离方法，提出一种轻量级安全的多党计算友好型鲁棒聚合策略，能抵抗最多半数恶意客户端的中毒攻击，同时保证模型准确度。其次，利用通信效率高的基于Shamir秘密分享的多党计算协议保护数据隐私并维持高模型精度。再者，FLock借助区块链的离链状态通道实现不可篡改的模型记录和激励分配，并与以太坊等实际加密货币平台实现了成本效益兼容及公平激励机制。此外，FLock还整合了流水线式的拜占庭容错共识，使每个聚合器能够重建最终聚合结果，增强聚合环节的容错性。最后，实验证明FLock能够在保持高效和高模型准确度的同时，显著提升抗毒性和隐私保护，例如在具有25个聚合器和100个客户端的情况下，FLock可在WAN上于两分钟内完成一次针对ResNet的安全聚合，成功实现了大量聚合器下的安全聚合，增强了聚合环节的容错能力。 <div>
\textit{Federated Learning} (FL) is a distributed machine learning paradigm that allows multiple clients to train models collaboratively without sharing local data. Numerous works have explored security and privacy protection in FL, as well as its integration with blockchain technology. However, existing FL works still face critical issues.  \romannumeral1) It is difficult to achieving \textit{poisoning robustness} and \textit{data privacy} while ensuring high \textit{model accuracy}. Malicious clients can launch \textit{poisoning attacks} that degrade the global model. Besides, aggregators can infer private data from the gradients, causing \textit{privacy leakages}. Existing privacy-preserving poisoning defense FL solutions suffer from decreased model accuracy and high computational overhead. \romannumeral2) Blockchain-assisted FL records iterative gradient updates on-chain to prevent model tampering, yet existing schemes are not compatible with practical blockchains and incur high costs for maintaining the gradients on-chain. Besides, incentives are overlooked, where unfair reward distribution hinders the sustainable development of the FL community. In this work, we propose FLock, a robust and privacy-preserving FL scheme based on practical blockchain state channels. First, we propose a lightweight secure \textit{Multi-party Computation} (MPC)-friendly robust aggregation method through quantization, median, and Hamming distance, which could resist poisoning attacks against up to $<50\%$ malicious clients. Besides, we propose communication-efficient Shamir's secret sharing-based MPC protocols to protect data privacy with high model accuracy. Second, we utilize blockchain off-chain state channels to achieve immutable model records and incentive distribution. FLock achieves cost-effective compatibility with practical cryptocurrency platforms, e.g. Ethereum, along with fair incentives, by merging the secure aggregation into a multi-party state channel. In addition, a pipelined \textit{Byzantine Fault-Tolerant} (BFT) consensus is integrated where each aggregator can reconstruct the final aggregated results. Lastly, we implement FLock and the evaluation results demonstrate that FLock enhances robustness and privacy, while maintaining efficiency and high model accuracy. Even with 25 aggregators and 100 clients, FLock can complete one secure aggregation for ResNet in $2$ minutes over a WAN. FLock successfully implements secure aggregation with such a large number of aggregators, thereby enhancing the fault tolerance of the aggregation.
]]></content:encoded>
<pubDate>Sun, 03 Nov 2024 16:32:03 +0000</pubDate>
</item>
<item>
<title>How Much Public Randomness Do Modern Consensus Protocols Need?</title>
<link>https://eprint.iacr.org/2024/1794</link>
<guid>https://eprint.iacr.org/2024/1794</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、共识协议、效率、安全性、随机性<br /><br />总结:
现代基于区块链的共识协议旨在实现高效性和对适应性敌手的安全性，通常依赖公共随机性源来为参与者分配角色。本文深入研究了这种随机性需求的程度。首先，文章证明了没有任何共识协议能够同时做到高效、适应性安全并且仅使用$O(\log n)$位的随机源熵。接下来，展示了一个三难困境：存在三个共识协议方案，它们可以分别实现这三个属性中的任意两个。 <div>
Modern blockchain-based consensus protocols 
aim for efficiency (i.e., low communication and round complexity) while maintaining security against adaptive adversaries.
These goals are usually achieved using a public randomness beacon to select roles for each participant.  
We examine to what extent this randomness is necessary.
Specifically, we provide tight bounds on the amount of entropy a Byzantine Agreement protocol must consume from a beacon in order to enjoy efficiency and adaptive security.
We first establish that no consensus protocol can simultaneously be efficient, be adaptively secure, and use $O(\log n)$ bits of beacon entropy. We then show this bound is tight and, in fact, a trilemma by presenting three consensus protocols that achieve any two of these three properties.
]]></content:encoded>
<pubDate>Sat, 02 Nov 2024 18:00:29 +0000</pubDate>
</item>
<item>
<title>Stealth and Beyond: Attribute-Driven Accountability in Bitcoin Transactions</title>
<link>https://eprint.iacr.org/2024/1789</link>
<guid>https://eprint.iacr.org/2024/1789</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、隐私、问责制、双责任机制、Identity-Based Matchmaking Signatures (IB-MSS)

<br /><br />总结:
该论文针对比特币交易中隐私与问责制平衡的问题，提出了一种新颖的双责任机制。此机制在比特币交易中既约束发送者只能花费符合特定条件的未花费交易输出（UTXOs），又要求接收方在接受资金前满足法律和道德要求。通过将合规属性融入隐形地址，方案在保持用户隐私的同时确保了政策遵循。为支持审计流程简化，文中引入了一种新的密码学原语——基于身份的匹配签名（IB-MSS）。这一解决方案完全兼容现有的比特币基础设施，不需要对核心协议进行改动，从而在保护隐私和去中心化的同时实现了交易审计和合规性。 <div>
Bitcoin enables decentralized, pseudonymous transactions, but balancing privacy with accountability remains a challenge. This paper introduces a novel dual accountability mechanism that enforces both sender and recipient compliance in Bitcoin transactions. Senders are restricted to spending Unspent Transaction Outputs (UTXOs) that meet specific criteria, while recipients must satisfy legal and ethical requirements before receiving funds. We enhance stealth addresses by integrating compliance attributes, preserving privacy while ensuring policy adherence. Our solution introduces a new cryptographic primitive, Identity-Based Matchmaking Signatures (IB-MSS), which supports streamlined auditing. Our approach is fully compatible with existing Bitcoin infrastructure and does not require changes to the core protocol, preserving both privacy and decentralization while enabling transaction auditing and compliance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 16:32:51 +0000</pubDate>
</item>
<item>
<title>An Efficient and Secure Boolean Function Evaluation Protocol</title>
<link>https://eprint.iacr.org/2024/1787</link>
<guid>https://eprint.iacr.org/2024/1787</guid>
<content:encoded><![CDATA[
<div> 关键词: 布尔函数、密码学、安全布尔评估、两方协议、轻量级

总结:
布尔函数在加密系统设计和分析中扮演重要角色，而安全布尔评估（SBE）则是研究重点，允许双方在不暴露私有输入的情况下联合计算布尔函数。本文提出了一种利用1-out-of-2 不知转移（OT）作为构建模块的高效、通用的两方协议——$\textsf{BooleanEval}$。该协议仅使用XOR操作作为核心计算步骤，因此轻量且快速。与当前其他轻量级SBE设计不同，$\textsf{BooleanEval}$避免了使用额外的加密原语，如哈希函数和承诺方案，从而减少了计算开销。<br /><br /> <div>
Boolean functions play an important role in designing and analyzing many cryptographic systems, such as block ciphers, stream ciphers, and hash functions, due to their unique cryptographic properties such as nonlinearity, correlation immunity, and algebraic properties. The secure evaluation of Boolean functions or Secure Boolean Evaluation (SBE) is an important area of research. SBE allows parties to jointly compute Boolean functions without exposing their private inputs. SBE finds applications in privacy-preserving protocols and secure multi-party computations. In this manuscript, we present an efficient and generic two-party protocol
(namely $\textsf{BooleanEval}$) for the secure evaluation of Boolean functions by utilizing a 1-out-of-2 Oblivious Transfer (OT) as a building block. $\textsf{BooleanEval}$ only employs XOR operations as the core computational step, thus making it lightweight and fast. Unlike other lightweight state-of-the-art designs of SBE, $\textsf{BooleanEval}$ avoids the use of additional cryptographic primitives, such as hash functions and commitment schemes to reduce the computational overhead.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 14:02:24 +0000</pubDate>
</item>
<item>
<title>PriSrv: Privacy-Enhanced and Highly Usable Service Discovery in Wireless Communications</title>
<link>https://eprint.iacr.org/2024/1783</link>
<guid>https://eprint.iacr.org/2024/1783</guid>
<content:encoded><![CDATA[
<div> 关键词：服务发现、隐私保护、PriSrv、匿名凭证基匹配加密（ACME）、快速匿名凭证（FAC）

<br /><br />总结:
本文提出了一种名为PriSrv的私有服务发现协议，旨在解决无线通信中服务提供者和客户端的隐私保护问题。PriSrv允许双方指定细粒度的身份验证策略，在建立连接前确保对方满足条件。该协议包括私人服务广播阶段和匿名相互认证阶段，同时隐藏双方的敏感信息。为实现这一目标，文章引入了匿名凭证基匹配加密（ACME）的概念，一次操作即可实现双边灵活策略控制、选择性属性披露及多展示不可链接性。作为ACME的基础组件，还设计了一个快速匿名凭证（FAC）方案，以提供常量大小的凭证和高效的展示/验证机制，适合于无线网络中的隐私增强型和高可用性服务发现。此外，PriSrv协议与Wi-Fi EAP、mDNS、BLE和Airdrop等流行无线通信协议兼容，提供了增强隐私保护的功能。文章对PriSrv进行了形式化安全证明并对其在多种硬件平台上的性能进行了评估，实现在桌面、笔记本电脑和移动电话上完成私人发现和安全连接的时间均少于0.973秒，在Raspberry Pi 4B上的时间则少于2.712秒。最后，将PriSrv集成到IEEE 802.1X的实际网络环境中，证实了其实用性。 <div>
Service discovery is essential in wireless communications. However, existing service discovery protocols provide no or very limited privacy protection for service providers and clients, and they often leak sensitive information (e.g., service type, client’s identity and mobility pattern), which leads to various network-based attacks (e.g., spoofing, man-in-the-middle, identification and tracking). In this paper, we propose a private service discovery protocol, called PriSrv, which allows a service provider and a client to respectively specify a fine-grained authentication policy that the other party must satisfy before a connection is established. PriSrv consists of a private service broadcast phase and an anonymous mutual authentication phase with bilateral control, where the private information of both parties is hidden beyond the fact that a mutual match to the respective authentication policy occurred. As a core component of PriSrv, we introduce the notion of anonymous credential-based matchmaking encryption (ACME), which exerts dual-layer matching in one step to simultaneously achieve bilateral  flexible policy control, selective attribute disclosure and multi-show unlinkability. As a building block of ACME, we design a fast anonymous credential (FAC) scheme to provide constant size credentials and efficient show/verification mechanisms, which is suitable for privacy-enhanced and highly usable service discovery in wireless networks. We present a concrete PriSrv protocol that is interoperable with popular wireless communication protocols, such as Wi-Fi Extensible Authentication Protocol (EAP), mDNS, BLE and Airdrop, to offer privacy-enhanced protection. We present formal security proof of our protocol and evaluate its performance on multiple hardware platforms: desktop, laptop, mobile phone and Raspberry Pi. PriSrv accomplishes private discovery and secure connection in less than 0.973 s on the first three platforms, and in less than 2.712 s on Raspberry Pi 4B. We also implement PriSrv into IEEE 802.1X in the real network to demonstrate its practicality.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 10:02:29 +0000</pubDate>
</item>
<item>
<title>zkMarket : Privacy-preserving Digital Data Trade System via Blockchain</title>
<link>https://eprint.iacr.org/2024/1775</link>
<guid>https://eprint.iacr.org/2024/1775</guid>
<content:encoded><![CDATA[
<div> 关键词：zkMarket、隐私保护、公平交易、区块链、zk-SNARK

总结:
zkMarket是一款基于区块链的隐私保护公平交易系统，旨在解决交易隐私和计算效率问题。该系统利用匿名转移协议保证交易隐私，并结合加密技术和零知识简洁非交互式证明（zk-SNARK），使得买卖双方能实现公正交易。通过加密解密密钥并运用commit-and-prove SNARK（CP-SNARK）以及创新的矩阵形式伪随机生成器（MatPRG），优化了数据注册流程并减少了卖家的证明时间。实验证明，相较于传统区块链解决方案，zkMarket显著降低了计算开销，同时保持了强大的安全性和隐私性。其中，卖家可以在3.2秒内注册1MB的数据，买家能在0.2秒内生成交易事务，而卖家能在0.4秒内完成交易结算。 <div>
In this paper, we introduce zkMarket, a privacy-preserving fair trade system on the blockchain. zkMarket addresses the challenges of transaction privacy and computational efficiency. To ensure transaction privacy, zkMarket is built upon an anonymous transfer protocol. By combining encryption with zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARK), both the seller and the buyer are enabled to trade fairly. Furthermore, by encrypting the decryption key, we make the data registration process more concise and improve the seller's proving time by leveraging commit-and-prove SNARK (CP-SNARK) and our novel pseudorandom generator, the matrix-formed PRG (MatPRG).

Our evaluation demonstrates that zkMarket significantly reduces the computational overhead associated with traditional blockchain solutions while maintaining robust security and privacy. The seller can register 1MB of data in 3.2 seconds, while the buyer can generate the trade transaction in 0.2 seconds, and the seller can finalize the trade in 0.4 seconds.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 04:47:17 +0000</pubDate>
</item>
<item>
<title>Universal Adaptor Signatures from Blackbox Multi-Party Computation</title>
<link>https://eprint.iacr.org/2024/1773</link>
<guid>https://eprint.iacr.org/2024/1773</guid>
<content:encoded><![CDATA[
<div> 关键词：适配器签名（AS）、通用适配器签名方案（UAS）、多 Party 计算 in the head（MPCitH）、区块链、隐私保护系统

<br /><br />总结:
本文提出了一个新的构建通用适配器签名方案（UAS）的方法，该方法不再依赖于刘等人工作中的成本高昂的卡普还原到哈密顿循环问题，而是利用多 Party 计算 in the head（MPCitH）范式。这使得新方案设计更为简化，并扩大了UAS在包括区块链和隐私保护系统等分布式应用中的适用范围。此外，基于MPCitH的UAS方案在提供强大安全性保障的同时，也成为现实世界密码学协议设计中具有潜力的工具。 <div>
Adaptor signatures (AS) extend the functionality of traditional digital signatures by enabling the generation of a pre-signature tied to an instance of a hard NP relation, which can later be turned (adapted) into a full signature upon revealing a corresponding witness. The recent work by Liu et al. [ASIACRYPT 2024] devised a generic AS scheme that can be used for any NP relation---which here we will refer to as universal adaptor signatures scheme, in short UAS---from any one-way function. However, this generic construction depends on the Karp reduction to the Hamiltonian cycle problem, which adds significant overhead and hinders practical applicability.

In this work, we present an alternative approach to construct universal adaptor signature schemes relying on the multi-party computation in the head (MPCitH) paradigm. This overcomes the reliance on the costly Karp reduction, while inheriting the core property of the MPCitH---which makes it an invaluable tool in efficient cryptographic protocols---namely, that the construction is black-box with respect to the underlying cryptographic primitive (while it remains non-black-box in the relation being proven). Our framework simplifies the design of UAS and enhances their applicability across a wide range of decentralized applications, such as blockchain and privacy-preserving systems. Our results demonstrate that MPCitH-based UAS schemes offer strong security guarantees while making them a promising tool in the design of real-world cryptographic protocols.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 02:31:17 +0000</pubDate>
</item>
<item>
<title>PRIME: Differentially Private Distributed Mean Estimation with Malicious Security</title>
<link>https://eprint.iacr.org/2024/1771</link>
<guid>https://eprint.iacr.org/2024/1771</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式均值估计(DME)、多方计算(MPC)、安全性、鲁棒性、差分隐私

<br /><br />总结:
本文提出了一种针对分布式均值估计(DME)任务的新型安全聚合协议，该协议同时解决了恶意客户端输入操纵和信息泄露问题。首先，该协议具备鲁棒性保障，能够有效抵御由恶意客户引入的“故障”输入对系统的攻击。其次，它确保了差分隐私，防止底层函数泄漏个人敏感信息。这是首次将鲁棒性和差分隐私保证结合应用于DME领域的全面尝试。文中借鉴Mironov等人(2009年CRYPTO会议)的工作，通过一种融合了“有用性”和差分隐私的概念来刻画协议的安全性，并对其进行了正式的安全性分析。 <div>
Distributed mean estimation (DME) is a fundamental and important task as it serves as a subroutine in convex optimization, aggregate statistics, and, more generally, federated learning. The inputs for distributed mean estimation (DME) are provided by clients (such as mobile devices), and these inputs often contain sensitive information. Thus, protecting privacy and mitigating the influence of malicious adversaries are critical concerns in DME. A surge of recent works has focused on building multiparty computation (MPC) based protocols tailored for the task of secure aggregation. However, MPC fails to directly address these two issues: (i) the potential manipulation of input by adversaries, and (ii) the leakage of information from the underlying function.  This paper presents a novel approach that addresses both these issues. We propose a secure aggregation protocol with a robustness guarantee, effectively protecting the system from "faulty" inputs introduced by malicious clients. Our protocol further ensures differential privacy, so that the underlying function will not leak significant information about individuals. 
Notably, this work represents the first comprehensive effort to combine robustness and differential privacy guarantees in the context of DME. In particular, we capture the security of the protocol via a notion of "usefulness" combined with differential privacy inspired by the work of Mironov et al. (CRYPTO 2009) and formally analyze this security guarantee for our protocol.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 14:24:23 +0000</pubDate>
</item>
<item>
<title>Push-Button Verification for BitVM Implementations</title>
<link>https://eprint.iacr.org/2024/1768</link>
<guid>https://eprint.iacr.org/2024/1768</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin, BitVM, 层2解决方案, 正式验证工具, Domain-Specific Language (DSL)

总结:<br />
本文针对比特币（Bitcoin）扩展性和吞吐量限制问题，特别是对于像BTCFi这样的生态系统项目的发展所面临的挑战，提出了BitVM这一具有前景的Layer 2（L2）解决方案。然而，比特币受限的编程环境（如非图灵完备的Script语言、无循环和递归以及严格的区块大小限制）使得开发复杂应用变得困难且易出错。为了解决这些问题，文章首次提出了一种针对BitVM实现的正式验证工具。该方法设计了一个基于寄存器的、更高级别的领域特定语言（DSL），以抽象处理复杂的栈操作，使开发者能更容易地推断程序正确性，同时保持原有的比特币Script语义。通过构建一个形式化的计算模型来捕捉BitVM执行和比特币Script的语义，为严谨的验证提供了基础。为了高效处理大规模程序和模拟循环的展开计算所带来的复杂约束，文中利用循环不变量谓词对“循环式”计算进行概括。通过采用反例引导的归纳综合（CEGIS）过程将低级比特币Script转换为DSL，实现了高效的验证而不失准确性。在对BitVM SNARK验算器的98个基准测试中，该工具有效验证了94%的情况，仅需几秒钟，证明了其在提升BitVM安全性与可靠性方面的有效性。 <div>
Bitcoin, while being the most prominent blockchain with the largest market capitalization, suffers from scalability and throughput limitations that impede the development of ecosystem projects like Bitcoin Decentralized Finance (BTCFi). Recent advancements in BitVM propose a promising Layer 2 (L2) solution to enhance Bitcoin's scalability by enabling complex computations off-chain with on-chain verification. However, Bitcoin's constrained programming environment—characterized by its non-Turing-complete Script language lacking loops and recursion, and strict block size limits—makes developing complex applications labor-intensive, error-prone, and necessitates manual partitioning of scripts. Under this complex programming model, subtle mistakes could lead to irreversible damage in a trustless environment like Bitcoin. Ensuring the correctness and security of such programs becomes paramount.

To address these challenges, we introduce the first formal verification tool for BitVM implementations. Our approach involves designing a register-based, higher-level domain-specific language (DSL) that abstracts away complex stack operations, allowing developers to reason about program correctness more effectively while preserving the semantics of the original Bitcoin Script. We present a formal computational model capturing the semantics of BitVM execution and Bitcoin Script, providing a foundation for rigorous verification. To efficiently handle large programs and complex constraints arising from unrolled computations that simulate loops, we summarize repetitive "loop-style" computations using loop invariant predicates in our DSL. We leverage a counterexample-guided inductive synthesis (CEGIS) procedure to lift low-level Bitcoin Script into our DSL, facilitating efficient verification without sacrificing accuracy. Evaluated on 98 benchmarks from BitVM's SNARK verifier, our tool successfully verifies 94% of cases within seconds, demonstrating its effectiveness in enhancing the security and reliability of BitVM.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 08:24:11 +0000</pubDate>
</item>
<item>
<title>Fully Homomorphic Encryption with Efficient Public Verification</title>
<link>https://eprint.iacr.org/2024/1764</link>
<guid>https://eprint.iacr.org/2024/1764</guid>
<content:encoded><![CDATA[
<div> 关键词: 公开验证、全同态加密、简洁证明、Ring R1CS、SNARG

总结:<br />
本文提出了一种高效的公开验证全同态加密方案，该方案不仅能对密文执行任意布尔电路计算，还能生成正确的同态计算的简洁证明。此方案基于Ducas和Micciancio提出的FHEW（Eurocrypt'15），并结合GINX同态累加器（Eurocrypt'16）以提高引导效率。为了有效生成证明，文章将广泛使用的Rank-1约束系统（R1CS）推广至环设置中，形成了Ring R1CS，从而能原生表达FHEW中的同态计算。进一步地，文章构建了一个针对Ring R1CS实例的SNARG，通过将Ring R1CS实例转换为多项式上的求和检查协议，再利用Cini等人（Crypto'24）提出的基于格的多项式承诺方案将其编译成简洁非交互式证明。综上所述，该公开验证的FHE方案依赖于标准的格问题困难度假设，能在时间复杂度为$O(|C|^2\cdot poly(\lambda))$和空间复杂度为$O(\log^2{|C|}\cdot poly(\lambda))$的情况下生成关于电路$C$的同态计算的简洁证明。此外，该方案实现了Walter最近提出的IND-SA安全模型（EPrint 2024/1207），能够精确保护客户端数据隐私，即使在可验证的同态计算中也是如此。 <div>
We present an efficient Publicly Verifiable Fully Homomorphic Encryption scheme that, along with being able to evaluate arbitrary boolean circuits over ciphertexts, also generates a succinct proof of correct homomorphic computation. Our scheme is based on FHEW proposed by Ducas and Micciancio (Eurocrypt'15), and we incorporate the GINX homomorphic accumulator (Eurocrypt'16) for improved bootstrapping efficiency. In order to generate the proof efficiently, we generalize the widely used Rank-1 Constraint System (R1CS) to the ring setting and obtain Ring R1CS, to natively express homomorphic computation in FHEW.
  
In particular, we develop techniques to efficiently express in our Ring R1CS the "non-arithmetic" operations, such as gadget decomposition and modulus switching used in the FHEW construction. We further construct a SNARG for Ring R1CS instances, by translating the Ring R1CS instance into a sum-check protocol over polynomials, and then compiling it into a succinct non-interactive proof by incorporating the lattice-based polynomial commitment scheme of Cini, Malavolta, Nguyen, and Wee (Crypto'24). Putting together, our Publicly Verifiable FHE scheme relies on standard hardness assumptions about lattice problems such that it generates a succinct proof of homomorphic computation of circuit $C$ in time $O(|C|^2\cdot poly(\lambda))$ and of size $O(\log^2{|C|}\cdot poly(\lambda))$. Besides, our scheme achieves the recently proposed IND-SA (indistinguishability under semi-active attack) security by Walter (EPrint 2024/1207) that exactly captures client data privacy when a homomorphic computation can be verified.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 20:01:00 +0000</pubDate>
</item>
<item>
<title>Homomorphic Matrix Operations under Bicyclic Encoding</title>
<link>https://eprint.iacr.org/2024/1762</link>
<guid>https://eprint.iacr.org/2024/1762</guid>
<content:encoded><![CDATA[
<div> 关键词: homomorphic encryption, matrix operations, bicyclic encoding, BMM-I, BMM-II

总结:
本文提出了一种新的矩阵编码方法——双循环编码（bicyclic encoding），该方法被应用于加密矩阵乘法中。基于此编码方式，作者提出了两种加密矩阵乘法算法BMM-I和BMM-II。理论上，BMM-II的表现优于当前最先进的算法，而在实践中，当处理高维度矩阵时，BMM-I结合分段策略展现出优秀性能。此外，双循环编码的一个显著优点在于可以免费地对加密矩阵进行转置操作。通过概念验证实现的全面实验研究表明，本文提出的每个算法在特定场景下都超越了现有算法，速度提升范围从2倍到38倍。 <div>
Homomorphically encrypted matrix operations are extensively  used in various privacy-preserving applications. Consequently, reducing the cost of encrypted matrix operations is a crucial topic on which numerous studies have been conducted. In this paper, we introduce a novel matrix encoding method, named bicyclic encoding, under which we propose two new algorithms BMM-I and BMM-II for encrypted matrix multiplication. BMM-II outperforms the stat-of-the-art algorithms in theory, while BMM-I, combined with the segmented strategy, performs well in practice, particularly for matrices with high dimensions. Another noteworthy advantage of bicyclic encoding is that it allows for transposing an encrypted matrix entirely free. A comprehensive experimental study based on our proof-of-concept implementation shows that each algorithm introduced in this paper has specific scenarios outperforming existing algorithms, achieving speedups ranging from 2x to 38x.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 09:58:53 +0000</pubDate>
</item>
<item>
<title>HTCNN: High-Throughput Batch CNN Inference with Homomorphic Encryption for Edge Computing</title>
<link>https://eprint.iacr.org/2024/1753</link>
<guid>https://eprint.iacr.org/2024/1753</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, CNN, CKKS, Latency, Throughput

总结:
本文探讨了同态加密（HE）技术在保护隐私的同时实现数据处理的可能性，特别是在CNN推理中的应用。CKKS算法因其对实数计算的支持而在同态CNN推理中受到青睐，但其存在的计算延迟和资源开销问题限制了其实用性。针对这一现状，文章提出了一种基于CKKS的分级同态CNN推理新方案，旨在减少延迟并提高吞吐量。该策略利用卷积的滑动窗口属性和CKKS的单指令多数据（SIMD）特性，将多个输入映射到一组密文上。同时，为了进一步优化速度，还引入了包括掩模权重合并、旋转复用、步长卷积分割和折叠旋转在内的多项技术。通过在MNIST和CIFAR-10数据集上的评估实验，证明了该同态推理方案的有效性。对于MNIST数据集，单CPU线程下163张图像的推理可在10.4秒内完成，准确率达到98.9%，相比现有最佳方法提高了6.9倍的吞吐量。对比分析显示，该提案在延迟、吞吐量、通信开销和内存利用率等方面均展现出优越性能。 <div>
Homomorphic Encryption (HE) technology allows for processing encrypted data, breaking through data isolation barriers and providing a promising solution for privacy-preserving computation. The integration of HE technology into Convolutional Neural Network (CNN) inference shows potential in addressing privacy issues in identity verification, medical imaging diagnosis, and various other applications. The CKKS HE algorithm stands out as a popular option for homomorphic CNN inference due to its capability to handle real number computations. However, challenges such as computational delays and resource overhead present significant obstacles to the practical implementation of homomorphic CNN inference, largely due to the complex nature of HE operations. In addition, current methods for speeding up homomorphic CNN inference primarily address individual images or large batches of input images, lacking a solution for efficiently processing a moderate number of input images with fast homomorphic inference capabilities, which is more suitable for edge computing applications. In response to these challenges, we introduce a novel leveled homomorphic CNN inference scheme aimed at reducing latency and improving throughput using the CKKS scheme. Our proposed inference strategy involves mapping multiple inputs to a set of ciphertext by exploiting the sliding window properties of convolutions to utilize CKKS's inherent Single-Instruction-Multiple-Data (SIMD) capability. To mitigate the delay associated with homomorphic CNN inference, we introduce optimization techniques, including mask-weight merging, rotation multiplexing, stride convolution segmentation, and folding rotations. The efficacy of our homomorphic inference scheme is demonstrated through evaluations carried out on the MNIST and CIFAR-10 datasets. Specifically, results from the MNIST dataset on a single CPU thread show that inference for 163 images can be completed in 10.4 seconds with an accuracy of 98.9%, which is a 6.9 times throughput improvement over state-of-the-art works. Comparative analysis with existing methodologies highlights the superior performance of our proposed inference scheme in terms of latency, throughput, communication overhead, and memory utilization.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 03:32:21 +0000</pubDate>
</item>
<item>
<title>Secure and Privacy-preserving CBDC Offline Payments using a Secure Element</title>
<link>https://eprint.iacr.org/2024/1746</link>
<guid>https://eprint.iacr.org/2024/1746</guid>
<content:encoded><![CDATA[
<div> 关键词: 中央银行数字货币、离线支付、双花攻击、安全元素、移动设备

总结:
本文探讨了中央银行数字货帀如何利用离线支付解决现有数字支付方案中的金融包容性不足问题。然而，离线支付的安全设计非常复杂，特别是在网络连接缺失的情况下，双花攻击变得容易发生。为防范这类攻击，文章提出采用安全元素作为预防措施，但鉴于其计算和存储能力有限，难以保证与实体现金相当的隐私保障。因此，文中提出一种协议，将大部分支付计算任务交给用户的移动设备处理，而仅在安全元素上执行删除已使用代币及生成等效于ECDSA签名的计算。该文主张对于消费者之间的安全支付，需要使用移动设备或增强型智能卡设备。为了进一步强化协议安全性，还实现了对成功实施双花攻击的攻击者进行高效识别的功能。最后，通过理想/现实世界范式证明了协议的安全性，并对其性能进行了评估，证实其实用性。 <div>
Offline payments present an opportunity for central bank digital currency to address the lack of digital financial inclusion plaguing existing digital payment solutions. However, the design of secure offline payments is a complex undertaking; for example, the lack of connectivity during the payments renders double spending attacks trivial. While the identification of double spenders and penal sanctions may curb attacks by individuals, they may not be sufficient against concerted efforts by states or well-funded institutions. It is hence important to also rely on preventive measures that reduce the scale of such attacks. An example of such a measure is secure elements. These however are limited in compute and storage, making the design of solutions that offer comparable privacy guarantees to those of physical cash challenging.
We address this with a protocol that offloads most of the payment computation to the user’s mobile device and restricts the computation on the secure element to deleting spent tokens, and generating a signature with a computation equivalent to that of ECDSA. We claim that the use of mobile devices or enhanced smart card-based devices are required for secure consumer-to-consumer payments. To further harden the protocol, we enable the efficient identification of double spenders on the off-chance an attacker successfully double spends. Finally, we prove its security in the ideal/real world paradigm, and evaluate its performance to demonstrate its practicality.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 11:44:06 +0000</pubDate>
</item>
<item>
<title>Secure and Efficient Outsourced Matrix Multiplication with Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1730</link>
<guid>https://eprint.iacr.org/2024/1730</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密（FHE）、神经网络、矩阵乘法、 SIMD、KeySwitch操作

总结：<br />
本文主要关注全同态加密（FHE）下神经网络评估的优化问题。研究重点在于改进矩阵乘法这一关键操作，通过利用FHE中的Single Instruction Multiple Data（SIMD）特性，提高数据打包效率并降低昂贵的KeySwitch操作次数，从而使多级乘法深度降至仅两层。当前最佳的两层深度下的矩阵乘法复杂度为$\mathcal{O}(d)$，而本方法将其降低到$\mathcal{O}(\log{d})$，同时保持了相同级别的数据打包效率。此外，该技术还被推广至支持任意打包大小和矩形矩阵的情况，从而显著提升了隐私保护环境下神经网络应用的矩阵乘法性能。 <div>
Fully Homomorphic Encryption (FHE) is a promising privacy-enhancing technique that enables secure and private data processing on untrusted servers, such as privacy-preserving neural network (NN) evaluations. However, its practical application presents significant challenges. Limitations in how data is stored within homomorphic ciphertexts and restrictions on the types of operations that can be performed create computational bottlenecks. As a result, a growing body of research focuses on optimizing existing evaluation techniques for efficient execution in the homomorphic domain.

One key operation in this space is matrix multiplication, which forms the foundation of most neural networks. Several studies have even proposed new FHE schemes specifically to accelerate this operation. The optimization of matrix multiplication is also the primary goal of our work. We leverage the Single Instruction Multiple Data (SIMD) capabilities of FHE to increase data packing and significantly reduce the KeySwitch operation count— an expensive low-level routine in homomorphic encryption. By minimizing KeySwitching, we surpass current state-of-the-art solutions, requiring only a minimal multiplicative depth of two.

The best-known complexity for matrix multiplication at this depth is $\mathcal{O}(d)$ for matrices of size  $d\times d$. Remarkably, even the leading techniques that require a multiplicative depth of three still incur a KeySwitch complexity of $\mathcal{O}(d)$. In contrast, our method reduces this complexity to $\mathcal{O}(\log{d})$ while maintaining the same level of data packing. Our solution broadly applies to all FHE schemes supporting Single Instruction Multiple Data (SIMD) operations.
We further generalize the technique in two directions: allowing arbitrary packing availability and extending it to rectangular matrices. This versatile approach offers significant improvements in matrix multiplication performance and enables faster evaluation of privacy-preserving neural network applications.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 12:34:34 +0000</pubDate>
</item>
<item>
<title>PISA: Privacy-Preserving Smart Parking</title>
<link>https://eprint.iacr.org/2024/1725</link>
<guid>https://eprint.iacr.org/2024/1725</guid>
<content:encoded><![CDATA[
<div> 关键词: 城市停车、私人停车位共享、PISA、隐私保护、安全协议

<br /><br />总结:
随着城市车辆数量急剧增加和停车场供应量相对固定，造成了严重的停车难问题。为了解决这一问题并帮助车主创收，文章提出了一个名为PISA的创新性隐私保护智能停车方案。PISA通过一种加密安全协议，实现了私人停车位在业主不在时的临时匿名共享，使得驾驶员可以在不泄露个人身份信息的情况下停车。该方案的核心贡献包括构建了一个全面的双向匿名框架，确保双方彼此无法识别，同时利用形式化验证方法证明了其安全措施的健全性和可靠性。与现有解决方案相比，PISA在保障安全性的同时也注重效率。 <div>
In recent years, urban areas have experienced a rapid increase in vehicle numbers, while the availability of parking spaces has remained largely static, leading to a significant shortage of parking spots. This shortage creates considerable inconvenience for drivers and contributes to traffic congestion. A viable solution is the temporary use of private parking spaces by homeowners during their absence, providing a means to alleviate the parking problem and generate additional income for the owners. However, current systems for sharing parking spaces often neglect security and privacy concerns, exposing users to potential risks.
This paper presents PISA, a novel Privacy-Preserving Smart Parking scheme designed to address these issues through a cryptographically secure protocol. PISA enables the anonymous sharing of parking spots and allows vehicle owners to park without revealing any personal identifiers. Our primary contributions include the development of a comprehensive bi-directional anonymity framework that ensures neither party can identify the other, and the use of formal verification methods to substantiate the soundness and reliability of our security measures. Unlike existing solutions, which often lack a security focus, fail to provide formal validation, or are computationally intensive, PISA is designed to be both secure and efficient.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 20:36:00 +0000</pubDate>
</item>
<item>
<title>$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning</title>
<link>https://eprint.iacr.org/2024/723</link>
<guid>https://eprint.iacr.org/2024/723</guid>
<content:encoded><![CDATA[
<div> 关键词：安全聚合，一次性私有聚合（$\mathsf{OPA}$），通信轮次，联邦学习，阈值密钥同态PRF

总结:<br />
本文主要研究了在单服务器设置下的安全聚合问题，提出了仅交互一次的一次性私有聚合协议$\mathsf{OPA}$，该协议允许客户端在每次聚合评估中仅发言一次，简化了对掉线和动态参与情况的管理。与需要多轮交互的传统联邦学习协议不同，$\mathsf{OPA}$应用于隐私保护的联邦学习场景中，客户端只需一次交互。此外，$\mathsf{OPA}$不需要复杂的委员会选择协议即可实现适应性安全性，相比现有方案在实际性能上有所提升，并在多个数据集上进行了基准测试。文章构建了两种版本的$\mathsf{OPA}$，分别基于阈值密钥同态PRF和种子同态PRG及秘密共享。其中，阈值密钥同态PRF旨在解决依赖DDH和LWR的先前工作中的不足，同时文中还提出基于类群、DCR或LWR假设的新阈值密钥同态PRF。 <div>
Our work aims to minimize interaction in secure computation due to the high cost and challenges associated with communication rounds, particularly in scenarios with many clients. In this work, we revisit the problem of secure aggregation in the single-server setting where a single evaluation server can securely aggregate client-held individual inputs. Our key contribution is the introduction of One-shot Private Aggregation ($\mathsf{OPA}$) where clients speak only once (or even choose not to speak) per aggregation evaluation. Since each client communicates only once per aggregation, this simplifies managing dropouts and dynamic participation, contrasting with multi-round protocols and aligning with plaintext secure aggregation, where clients interact only once. 

We construct $\mathsf{OPA}$ based on LWR, LWE, class groups, DCR and demonstrate applications to privacy-preserving Federated Learning (FL) where clients {speak once}. This is a sharp departure from prior multi-round FL protocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover, unlike the YOSO (You Only Speak Once) model for general secure computation, $\mathsf{OPA}$ eliminates complex committee selection protocols to achieve adaptive security. Beyond asymptotic improvements, $\mathsf{OPA}$ is practical, outperforming state-of-the-art solutions. We benchmark logistic regression classifiers for two datasets, while also building an MLP classifier to train on MNIST, CIFAR-10, and CIFAR-100 datasets.

We build two flavors of $\mathsf{OPA}$ (1) from (threshold) key homomorphic PRF and (2) from seed homomorphic PRG and secret sharing. 
The threshold Key homomorphic PRF addresses shortcomings observed in previous works that relied on DDH and LWR in the work of Boneh et al. (CRYPTO, 2013), marking it as an independent contribution to our work. Moreover, we also present new threshold key homomorphic PRFs based on class groups or DCR or the LWR assumption.
]]></content:encoded>
<pubDate>Sat, 11 May 2024 01:20:12 +0000</pubDate>
</item>
<item>
<title>Scalable Mixnets from Two-Party Mercurial Signatures on Randomizable Ciphertexts</title>
<link>https://eprint.iacr.org/2024/1503</link>
<guid>https://eprint.iacr.org/2024/1503</guid>
<content:encoded><![CDATA[
<div> 关键词: mixnet、Hébant et al.、homomorphic signatures、mercurial signatures、receipt-free voting

总结:
针对投票领域的隐私保护需求，文章指出现有由Hébant等人提出的mixnet方案因依赖于信任权威机构而存在局限性。为此，研究者们利用最近在等价类签名上的进展，将同态签名替换为新开发的两方随机化密文上的水银签名。这种改进使得用户和权威机构能在保持嵌入消息的同时，共同签署并随机化密钥、密文和签名，从而实现无需信任权威机构即可保证投票隐私的收据自由投票。通过与其它可扩展mixnet解决方案对比及实施协议并提供具体性能基准测试，结果显示新方案在计算效率和通信效率上均显著优于现有替代方案，例如，在一台普通笔记本电脑上使用十个混合器验证50,000个密文的混合过程仅需135秒，证明了该方法的实际可行性。 <div>
A mixnet developed by Hébant et al. (PKC '20) employs certified ciphertexts that carry homomorphic signatures from an authority, reducing the complexity of the shuffling proof, and thereby enabling efficient large-scale deployment. However, their privacy relies on trusting the authority, making it unsuitable for voting, the primary application of mixnets.

Building on the prior work, we leverage recent advances in equivalence class signatures by replacing homomorphic signatures with newly developed two-party mercurial signatures on randomizable ciphertexts. This allows users and the authority to jointly sign ciphertexts and randomize keys, ciphertexts, and signatures, all while preserving the embedded messages. We demonstrate that our mixnet is suitable for receipt-free voting without requiring trust in the signing authority for privacy.

To assess scalability, we compare our approach to other scalable mixnet solutions, implement our protocols, and provide concrete performance benchmarks. Our results show that our mixnet significantly outperforms existing alternatives in both computation and communication efficiency. Specifically, verifying the mixing process for 50,000 ciphertexts takes just 135 seconds on a commodity laptop using ten mixers, illustrating the practical viability of our approach.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 08:05:18 +0000</pubDate>
</item>
<item>
<title>Dumbo-MPC: Efficient Fully Asynchronous MPC with Optimal Resilience</title>
<link>https://eprint.iacr.org/2024/1705</link>
<guid>https://eprint.iacr.org/2024/1705</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全异步多 party 计算 (AMPC), 隐私保护, 保证输出交付 (G.O.D.), Dumbo-MPC, HoneyBadgerMPC, 抗恶意攻击

总结:
本文提出了一种名为 Dumbo-MPC 的全新完全异步多 party 计算 (AMPC) 设计方案，旨在解决现有 AMPC 协议在实际应用中的局限性，如非最优鲁棒性、高通信成本和额外的在线加密开销。Dumbo-MPC 提供了全面的 G.O.D. 和对 $t3$ 恶意参与者的最优鲁棒性保障（总参与者数为 $n$）。其在线阶段与 HoneyBadgerMPC 类似，具有稳健的、几乎信息理论级别的安全性，但不同的是，Dumbo-MPC 设计了一个创新的双模式离线协议，能在异步环境中鲁棒地预处理乘法三元组。该协议在乐观情况下每三元组通信复杂度为 $O(n)$，并在出现故障时无缝切换到悲观路径以保持 G.O.D. 安全性。为了优化悲观路径的实现效率，文章设计了一种基于紧凑型 KZG 多项式承诺的、针对秘密份额产品关系的高效零知识证明，将两个秘密份额乘积的次数从 $2t$ 减少到 $t$，具有独立的研究价值。

此外，研究者实现了 Dumbo-MPC 并在最多 31 台 AWS 服务器的不同网络设置下进行了详尽评估。据所知，这是首个实现所有阶段 G.O.D. 的 AMPC 实例。文章还将 Dumbo-MPC 与近期由 Groth 和 Shoup 提出的异步三元生成协议 (GS23) 进行了实测对比。当 $n=31$ 时，Dumbo-MPC 在悲观情况下的三元生成速度达到了 94 个/秒（几乎是 GS23 的两倍），而在良好条件下达到了 349 个/秒（比 GS23 快六倍）。这使得 31 个参与者仅需 2-8 分钟即可准备好涉及 100 名竞标者的私人 Vickrey 拍卖的预处理工作，或者只需 10-36 分钟完成包含 $2^{10}$ 输入的混合网络的预处理任务。 <div>
Fully asynchronous multi-party computation (AMPC) has superior robustness in realizing privacy and guaranteed output delivery (G.O.D.) against asynchronous adversaries that can arbitrarily delay communications. However, none of these protocols are truly practical, as they either have sub-optimal resilience, incur cumbersome communication cost, or suffer from an online phase with extra cryptographic overhead. The only attempting implementation---HoneyBadgerMPC (hbMPC)---merely ensures G.O.D. in some implausible optimistic cases due to a non-robust offline pre-processing phase.

We propose Dumbo-MPC a concretely efficient  AMPC-as-a-service design with all phases G.O.D. and optimal resilience against  $t3$ malicious parties (where $n$ is the total number of parties). Same to hbMPC, Dumbo-MPC has a robust (almost) information-theoretic online phase that can efficiently perform online computations, given pre-processed multiplication triples. While for achieving all phases G.O.D., we design a novel dual-mode offline protocol that can robustly pre-process multiplication triples in asynchrony. The offline phase features $O(n)$ per-triple communication in the optimistic case, followed by a fully asynchronous fallback to a pessimistic path to securely restore G.O.D. in the bad case. To efficiently implement the pessimistic path, we devise a concretely efficient zk-proof for product relationship of secret shares over compact KZG polynomial commitments, which enables us to reduce the degree of two secret shares' product from $2t$ to  $t$ and could be of independent interest.

We also implement and extensively evaluate Dumbo-MPC (particularly its offline phase) in varying network settings with up to 31 AWS servers. To our knowledge, we provide the first implementation of AMPC with all-phase G.O.D. A recent asynchronous triple generation protocol from Groth and Shoup (GS23) is also implemented and experimentally compared. When $n = 31$, Dumbo-MPC generates 94 triplessec (almost twice of GS23) in the pessimistic case and 349 triples/sec (6X of GS23) in the good case, such that 31 parties require only 2-8 min to prepare a private Vickrey auction of 100 bidders or 10-36 min for a mixing network of $2^{10}$ inputs.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 12:14:10 +0000</pubDate>
</item>
<item>
<title>From One-Time to Two-Round Reusable Multi-Signatures without Nested Forking</title>
<link>https://eprint.iacr.org/2024/1704</link>
<guid>https://eprint.iacr.org/2024/1704</guid>
<content:encoded><![CDATA[
<div> 关键词: 多重签名方案、两轮方案、DLOG问题、安全性证明、应用

总结:
本文关注了基于DLOG难题安全性的两轮多重签名方案，特别是那些具有键聚合功能并在明文公钥模型中运行的方案。针对现有方案的安全性证明提供的具体保证不足的问题，文章提出了两种放松的安全性概念。首先，定义了一次性不可伪造性，扩展了单签署者情况下的类似概念，允许攻击者获取一条特定消息和一组选定签署者的签名。文章构造了一个基于环同态一维函数的非交互式一次性方案，并提供了基于DLOG和RSA假设的有效实例。其次，提出了单集合不可伪造性，限制攻击者只能使用一组选定的签署者来获取多项签名。通过将任何非交互式一次性方案转换为两轮单集合方案的新颖无分支构造方法，该方法将经典的Naor-Yung树形方法扩展到多签署者场景。文章中的多重签名方案在保持安全性的同时，优化了验证密钥和签名的长度，使其独立于签署者数量。 <div>
Multi-signature schemes are gaining significant interest due to their blockchain applications. Of particular interest are two-round schemes in the plain public-key model that offer key aggregation, and whose security is based on the hardness of the DLOG problem. Unfortunately, despite substantial recent progress, the security proofs of the proposed schemes provide rather insufficient concrete guarantees (especially for 256-bit groups). This frustrating situation has so far been approached either by relying on the security of seemingly stronger assumptions or by considering restricted classes of attackers (e.g., algebraic attackers, which are assumed to provide an algebraic justification of each group element that they produce).

We present a complementing approach by constructing multi-signature schemes that satisfy two relaxed notions of security, whose applicability nevertheless ranges from serving as drop-in replacements to enabling expressive smart contract validation procedures. Our first notion, one-time unforgeability, extends the analogous single-signer notion by considering attackers that obtain a single signature for some message and set of signers of their choice. We construct a non-interactive one-time scheme based on any ring-homomorphic one-way function, admitting efficient instantiations based on the DLOG and RSA assumptions. Aggregated verification keys and signatures consist of two group elements and a single group element, respectively, and our security proof consists of a single application of the forking lemma (thus avoiding the substantial security loss exhibited by the proposed two-round schemes). Additionally, we demonstrate that our scheme naturally extends to a $t$-time scheme, where aggregated verification keys consist of $t+1$ group elements, while aggregated signatures still consist of a single group element.

Our second notion, single-set unforgeability, considers attackers that obtain any polynomial number of signatures but are restricted to a single set of signers of their choice. We transform any non-interactive one-time scheme into a two-round single-set scheme via a novel forking-free construction that extends the seminal Naor-Yung tree-based approach to the multi-signer setting. Aggregated verification keys are essentially identical to those of the underlying one-time scheme, and the length of aggregated signatures is determined by that of the underlying scheme while scaling linearly with the length of messages (noting that long messages can always be hashed using a collision-resistant function). Instantiated with our one-time scheme, we obtain aggregated verification keys and signatures whose lengths are completely independent of the number of signers.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 11:55:05 +0000</pubDate>
</item>
<item>
<title>Secure Computation with Parallel Calls to 2-ary Functions</title>
<link>https://eprint.iacr.org/2024/1701</link>
<guid>https://eprint.iacr.org/2024/1701</guid>
<content:encoded><![CDATA[
<div> 关键词：加密算法、简化的函数、二元函数、安全计算、协议

<br /><br />总结:

本文研究了将任意函数的安全计算简化为仅使用二元函数进行安全计算的问题。首先，文章指出存在一个次数为2的多项式$p$，表明没有任何利用并行调用二元函数的协议可以以统计安全性（带有abort）来计算它。接着，文章给出了两种绕过这一不可能性结果的方法：一是通过弱化安全定义，证明所有次数为2的多项式可以通过并行调用二元函数实现具有统计隐私和已知输出的知识（PwKO）；二是借助计算安全性，证明对于任何函数$f$，都存在一种依赖于半诚实安全盲转移假设的协议，该协议可并行调用二元函数并实现对计算受限敌手的安全性（带有abort）。此外，文章还将此问题与减少多党派随机编码（MPRE）的编码复杂性的任务联系起来，展示在标准计算假设下，存在一种可通过常数扇出的$\mathrm{NC}^0$电路实现编码器的MPRE。最后，文章还探讨了在诚实多数设置和具有三元函数情况下的问题，并分别给出了类似的结果，其中后者在恶意多数设置中假设了一次性函数的存在。 <div>
Reductions are the workhorses of cryptography. They allow constructions of complex cryptographic primitives from simple building blocks. A prominent example is the non-interactive reduction from securely computing a ``complex" function $f$ to securely computing a ``simple" function $g$ via randomized encodings.

    Prior work equated simplicity with functions of small degree. In this work, we consider a different notion of simplicity where we require $g$ to only take inputs from a small number of parties. In other words, we want the arity of $g$ to be as small as possible. 

    In more detail, we consider the problem of reducing secure computation of arbitrary functions to secure computation of functions with arity two (two is the minimal arity required to compute non-trivial functions). Specifically, we want to compute a function $f$ via a protocol that makes parallel calls to 2-ary functions. We want this protocol to be secure against malicious adversaries that could corrupt an arbitrary number of parties. We obtain the following results:
    
- Negative Result: We show that there exists a degree-2 polynomial $p$ such that no protocol that makes parallel calls to 2-ary functions can compute $p$ with statistical security with abort.
            
- Positive Results: We give two ways to bypass the above impossibility result.
             
  1. Weakening the Security Notion. We show that every degree-2 polynomial can be computed with statistical privacy with knowledge of outputs (PwKO) by making parallel calls to 2-ary functions. Privacy with knowledge of outputs is weaker than security with abort.
                        
  2. Computational Security. We prove that for every function $f$, there exists a protocol for computing $f$ that makes parallel calls to 2-ary functions and achieves security with abort against computationally-bounded adversaries. The security of this protocol relies on the existence of semi-honest secure oblivious transfer.
              
- Applications: We give connections between this problem and the task of reducing the encoding complexity of Multiparty Randomized Encodings (MPRE) (Applebaum, Brakerski, and Tsabary, TCC 2018). Specifically, we show that under standard computational assumptions, there exists an MPRE where the encoder can be implemented by an $\mathrm{NC}^0$ circuit with constant fan-out.
  
- Extensions: We explore this problem in the honest majority setting and give similar results assuming one-way functions. We also show that if the parties have access to 3-ary functions then we can construct a computationally secure protocol in the dishonest majority setting assuming one-way functions.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 04:58:31 +0000</pubDate>
</item>
<item>
<title>Updatable Privacy-Preserving Blueprints</title>
<link>https://eprint.iacr.org/2023/1787</link>
<guid>https://eprint.iacr.org/2023/1787</guid>
<content:encoded><![CDATA[
<div> 隐私保护蓝图方案 更新 零知识证明 同态加密 蓝图大小<br /><br />总结:<br />本文介绍了一种新的隐私保护蓝图方案（UPPB），该方案允许多个用户非交互式地更新其私人输入，同时保持更新过程的隐私性。与原始方案相比，UPPB引入了对累积输入进行验证的能力，而无需泄露用户的私人信息。本文提出了UBlu方案，专门用于比较用户累计输入和审计员提供的固定值，适用于反洗钱等场景。技术上，通过引入一种新颖的可塑性表征方法，有效控制了蓝图的大小，使其不依赖于更新次数，从而适用于实际应用。这一方案基于全同态加密和非交互式零知识证明构建。 <div>
Privacy-preserving blueprint schemes (Kohlweiss et al., EUROCRYPT'23) offer a mechanism for safeguarding user's privacy while allowing for specific legitimate controls by a designated auditor agent. 

These schemes enable users to create escrows encrypting the result of evaluating a function $y=P(t,x)$, with $P$ being publicly known, $t$ a secret used during the auditor's key generation, and $x$ the user's private input.  Crucially, escrows only disclose the blueprinting result $y=P(t,x)$ to the designated auditor, even in cases where the auditor is fully compromised. The original definition and construction only support the evaluation of functions $P$ on an input $x$ provided by a single user. 
    
We address this limitation by introducing updatable privacy-preserving blueprint schemes (UPPB), which enhance the original notion with the ability for multiple users to non-interactively update the private user input $x$ while blueprinting. Moreover, UPPBs contain a proof that $y$ is the result of a sequence of valid updates, while revealing nothing else about the private inputs $\{x_i\}$ of updates. As in the case of privacy-preserving blueprints, we first observe that UPPBs can be realized via a generic construction for arbitrary predicates $P$ based on FHE and NIZKs. Our main result is UBlu, an efficient instantiation for a specific predicate comparing the values $x$ and $t$, where $x$ is the cumulative sum of users' private inputs and $t$ is a fixed private value provided by the auditor in the setup phase. This rather specific setting already finds interesting applications such as privacy-preserving anti-money laundering and location tracking, and can be extended to support more generic predicates.
    
From the technical perspective, we devise a novel technique to keep the escrow size concise, independent of the number of updates, and reasonable for practical applications. We achieve this via a novel characterization of malleability for the algebraic NIZK by Couteau and Hartmann (CRYPTO’20) that allows for an additive update function.
]]></content:encoded>
<pubDate>Sun, 19 Nov 2023 17:36:23 +0000</pubDate>
</item>
<item>
<title>Computational Attestations of Polynomial Integrity Towards Verifiable Machine Learning</title>
<link>https://eprint.iacr.org/2024/639</link>
<guid>https://eprint.iacr.org/2024/639</guid>
<content:encoded><![CDATA[
<div> 零知识证明 差分隐私 线性回归 MLaaS 计算效率<br /><br />总结: 本文展示了使用零知识证明技术验证差分隐私线性回归训练的过程。实验在单机上对50,000样本数据集进行训练，耗时不到6分钟，并且验证整个计算过程仅需0.17秒。据我们所知，这是目前文献中已知的针对如此大规模数据集的最快可证明差分隐私实例。这一结果被认为是构建端到端隐私机器学习即服务（MLaaS）的关键步骤。 <div>
Machine-learning systems continue to advance at a rapid pace, demonstrating remarkable utility in various fields and disciplines. As these systems continue to grow in size and complexity, a nascent industry is emerging which aims to bring machine-learning-as-a-service (MLaaS) to market. Outsourcing the operation and training of these systems to powerful hardware carries numerous advantages, but challenges arise when privacy and the correctness of work carried out must be ensured. Recent advancements in the field of zero-knowledge cryptography have led to a means of generating arguments of integrity for any computation, which in turn can be efficiently verified by any party, in any place, at any time. In this work we prove the correct training of a differentially-private (DP) linear regression over a dataset of 50,000 samples on a single machine in less than 6 minutes, verifying the entire computation in 0.17 seconds. To our knowledge, this result represents the fastest known instance in the literature of provable-DP over a dataset of this size. We believe this result constitutes a key stepping-stone towards end-to-end private MLaaS.
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 02:17:26 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Threshold BBS+ From Pseudorandom Correlations</title>
<link>https://eprint.iacr.org/2023/1076</link>
<guid>https://eprint.iacr.org/2023/1076</guid>
<content:encoded><![CDATA[
<div> 阈值签名 非交互式签名 子线性通信 多方计算 普遍组合模型<br /><br />总结: 本文提出了一种新的$t$-out-of-$n$门限BBS+协议，以解决单点故障问题。该协议支持任意安全阈值$t \leq n$，并在预处理设置中实现了非交互式签名和子线性通信复杂度。文中设计了专门的预签名，可以直接从伪随机相关性计算得到，使得服务器可以在没有跨服务器通信的情况下创建签名份额。该协议在主动安全性的普遍组合模型中有效。实验结果表明，对于$t \leq 30$的情况，在线协议执行时间少于15毫秒，且在线签名过程中$t$的影响小于6%，大部分开销发生在离线阶段。此外，本文实现的PCG扩展是首个考虑多于3方之间相关性的实现，显示了即使在10个服务器组成的委员会中，每个服务器也可以在大约600毫秒内扩展多达$2^{16}$个预签名。 <div>
The BBS+ signature scheme is one of the most prominent solutions for realizing anonymous credentials. Its prominence is due to properties like selective disclosure and efficient protocols for creating and showing possession of credentials. Traditionally, a single credential issuer produces BBS+ signatures, which poses significant risks due to a single point of failure.

In this work, we address this threat via a novel $t$-out-of-$n$ threshold BBS+ protocol. Our protocol supports an arbitrary security threshold $t \leq n$ and works in the so-called preprocessing setting. In this setting, we achieve non-interactive signing in the online phase and sublinear communication complexity in the number of signatures in the offline phase, which, as we show in this work, are important features from a practical point of view. As it stands today, none of the widely studied signature schemes, such as threshold ECDSA and threshold Schnorr, achieve both properties simultaneously. To this end, we design specifically tailored presignatures that can be directly computed from pseudorandom correlations and allow servers to create signature shares without additional cross-server communication. Both our offline and online protocols are actively secure in the Universal Composability model. Finally, we evaluate the concrete efficiency of our protocol, including an implementation of the online phase and the expansion algorithm of the pseudorandom correlation generator (PCG) used during the offline phase. The online protocol without network latency takes less than $15 ms$ for $t \leq 30$ and credentials sizes up to $10$. Further, our results indicate that the influence of $t$ on the online signing is insignificant, $< 6 \%$ for $t \leq 30$, and the overhead of the thresholdization occurs almost exclusively in the offline phase. Our implementation of the PCG expansion is the first considering correlations between more than $3$ parties and shows that even for a committee size of $10$ servers, each server can expand a correlation of up to $2^{16}$ presignatures in about $600$ ms per presignature.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 05:09:29 +0000</pubDate>
</item>
<item>
<title>Overlapped Bootstrapping for FHEW/TFHE and Its Application to SHA3</title>
<link>https://eprint.iacr.org/2024/1667</link>
<guid>https://eprint.iacr.org/2024/1667</guid>
<content:encoded><![CDATA[
<div> bootstrapping, FHEW/TFHE, 加密数据, Keccak, 性能提升<br /><br />总结: 本文提出了一种针对FHEW和TFHE方案的新颖高效引导方法，该方法利用加密数据的可变缩放因子，尤其适用于连续异或门电路。实验结果显示，这种方法将基于FHEW/TFHE的Keccak函数的运行时间减少了42%。新方法无需额外密钥或参数集，由计算方直接采用，无需额外信息。文章指出，尽管FHEW和TFHE因其轻量级特性和对任意逻辑门的支持而适合用于智能合约，但它们需要在每次执行二进制门后进行引导操作，这成为性能瓶颈。本文提出的引导方法旨在解决这一问题。 <div>
Homomorphic Encryption (HE) enables operations on encrypted data without requiring decryption, thus allowing for secure handling of confidential data within smart contracts.  Among the known HE schemes, FHEW and TFHE are particularly notable for use in smart contracts due to their lightweight nature and support for arbitrary logical gates. In contrast, other HE schemes often require several gigabytes of keys and are limited to supporting only addition and multiplication.  As a result, there has been significant work implementing smart contract functionalities over HE, broadening the potential applications of blockchain technology.  However, a significant drawback of the FHEW/TFHE schemes is the need for bootstrapping after the execution of each binary gate. While bootstrapping reduces noise in the ciphertext, it also becomes a performance bottleneck due to its computational complexity.

In this work, we propose an efficient new bootstrapping method for FHEW/TFHE that takes advantage of the flexible scaling factors of encrypted data.  The proposed method is particularly beneficial in circuits with consecutive XOR gates.  Moreover, we implement Keccak using FHEW/TFHE, as it is one of the most important functions in smart contracts.  Our experimental results demonstrate that the proposed method reduces the runtime of Keccak over HE by 42%. Additionally, the proposed method does not require additional keys or parameter sets from the key-generating party and can be adopted by the computing party without need for any extra information.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 03:43:52 +0000</pubDate>
</item>
<item>
<title>HADES: Range-Filtered Private Aggregation on Public Data</title>
<link>https://eprint.iacr.org/2024/1699</link>
<guid>https://eprint.iacr.org/2024/1699</guid>
<content:encoded><![CDATA[
<div> 隐私保护 聚合查询 全同态加密 范围谓词 布尔组合<br /><br />总结: 本文介绍了一种名为HADES的全同态加密（FHE）基础的私有聚合系统，旨在处理公共数据中的隐私保护问题。现有解决方案要么需要额外设置，要么效率低下，尤其是不支持范围谓词和布尔组合。HADES系统支持点、范围谓词及布尔组合，并通过利用公有数据记录的明文形式，高效生成谓词指示器。该系统引入了元素级映射操作和优化的缩减算法，实现了在有限噪声预算内的低延迟。实验结果显示，HADES在端到端TPC-H查询中性能提升了204至6574倍，将100万条记录的聚合时间从15小时缩短到了38秒。这一改进使得HADES在实际应用中具有更高的可扩展性和效率。 <div>
In aggregation queries, predicate parameters often reveal user intent. Protecting these parameters is critical for user privacy, regardless of whether the database is public or private. While most existing works focus on private data settings, we address a public data setting where the server has access to the database. Current solutions for this setting either require additional setups (e.g., noncolluding servers, hardware enclaves) or are inefficient for practical workloads. Furthermore, they often do not support range predicates or boolean combinations commonly seen in real-world use cases. 

To address these limitations, we built HADES, a fully homomorphic encryption (FHE) based private aggregation system for public data that supports point, range predicates, and boolean combinations. Our one-round HADES protocol efficiently generates predicate indicators by leveraging the plaintext form of public data records. It introduces a novel elementwise-mapping operation and an optimized reduction algorithm, achieving latency efficiency within a limited noise budget. Our highly scalable, multi-threaded implementation improves performance over previous one-round FHE solutions by 204x to 6574x on end-to-end TPC-H queries, reducing aggregation time on 1M records from 15 hours to 38 seconds
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:07:06 +0000</pubDate>
</item>
<item>
<title>Homomorphic Encryption with Authority</title>
<link>https://eprint.iacr.org/2024/1689</link>
<guid>https://eprint.iacr.org/2024/1689</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密，隐私保护，公共安全，权威机构，法律授权<br /><br />总结:<br />本文介绍了一种名为HEwA（具有权威的同态加密）的新框架，旨在平衡数据隐私与公共安全。HEwA在正常阶段保护客户数据隐私，在调查阶段允许政府等合法授权机构恢复可疑客户的加密数据。文章提出了HEwA的安全模型，并以CKKS同态加密方案为基础设计了一个高效系统，适用于AI领域如安全基因分析。该方法解决了云计算服务中隐私与公共安全之间的紧张关系，为实际应用中的同态加密负责任使用铺平了道路。 <div>
Fully homomorphic encryption enables computations over encrypted data, which allows privacy-preserving services to be held between a server and a client. However, real-world applications demand practical considerations, especially concerning public safety and legal investigations. Existing FHE schemes focus solely on privacy, neglecting the societal risks posed by criminal activities utilizing privacy-preserving services. This paper introduces Homomorphic Encryption with Authority (HEwA), a novel framework that balances data privacy with public safety by incorporating an "authority" party. The proposed HEwA system operates in two phases: a normal phase, where client data privacy is protected, and an investigative phase, where the authority referring to a legally authorized entity such as government agencies exerts the right to recover suspicious client’s data. We formalize the security model for HEwA, ensuring that client privacy is protected during the normal phase while enabling authorities to recover encrypted data in the investigative phase. As a concrete example, we design an efficient HEwA system solely based on the CKKS homomorphic encryption scheme, which supports approximate computations over real-number data, making it highly suitable for fruitful applications in AI such as secure genomic analysis. We further provide rigorous security proofs. This new approach addresses the tension between privacy and public safety in cloud services, paving the way for responsible use of homomorphic encryption in practice.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 05:59:21 +0000</pubDate>
</item>
<item>
<title>Sunfish: Reading Ledgers with Sparse Nodes</title>
<link>https://eprint.iacr.org/2024/1680</link>
<guid>https://eprint.iacr.org/2024/1680</guid>
<content:encoded><![CDATA[
<div> sparse node, light node, full node, throughput, Sunfish<br /><br />总结:<br />文章提出了区块链中的一种新型节点——稀疏节点（sparse node），以解决高吞吐量区块链中全节点和轻节点存在的问题。稀疏节点只跟踪区块链的一部分状态，验证与其子状态相关的交易集是否完整并重新执行这些交易来评估其有效性。这种节点即使在恶意多数情况下也保持重要的安全属性，并且资源需求与子状态中的交易数量和子状态大小成比例。文中还介绍了Sunfish，一种稀疏节点协议的实现，分析表明Sunfish相比全节点可将带宽消耗降低几个数量级。这为提高区块链应用效率提供了一种新方法。 <div>
The increased throughput offered by modern blockchains, such as Sui, Aptos, and Solana, enables processing thousands of transactions per second, but it also introduces higher costs for decentralized application (dApp) developers who need to track and verify changes in the state of their application. This is true because dApp developers run full nodes, which download and re-execute every transaction to track the global state of the chain. However, this becomes prohibitively expensive for high-throughput chains due to high bandwidth, computational, and storage requirements. A common alternative is to use light nodes. However, light nodes only verify the inclusion of a set of transactions and have no guarantees that the set is complete, i.e., that includes all relevant transactions. Under a dishonest majority, light nodes can also be tricked into accepting invalid transactions.

To bridge the gap between full and light nodes, we propose and formalize a new type of blockchain node: the sparse node. A sparse node tracks only a subset of the blockchain’s state: it verifies that the received set of transactions touching the substate is complete, and re-executes those transactions to assess their validity. A sparse node retains important security properties even under adversarial majorities, and requires an amount of resources proportional to the number of transactions in the substate and to the size of the substate itself. 

We further present Sunfish, an instantiation of a sparse node protocol. Our analysis and evaluation show that Sunfish reduces the bandwidth consumption of real blockchain applications by several orders of magnitude when compared to a full node.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 13:36:17 +0000</pubDate>
</item>
<item>
<title>Testing Robustness of Homomorphically Encrypted Split Model LLMs</title>
<link>https://eprint.iacr.org/2024/1675</link>
<guid>https://eprint.iacr.org/2024/1675</guid>
<content:encoded><![CDATA[
<div> 关键词：大语言模型, 全同态加密, 模型保护, 攻击向量, 本地计算<br /><br />总结: 本文探讨了使用全同态加密（FHE）技术在大语言模型（LLMs）中保护神经网络模型知识产权的方法。由于LLMs规模庞大及FHE计算开销高，实际应用中采用了一种分割模型的方法，即将加密数据发送到服务器进行部分计算，其余计算则在用户端完成。然而，研究发现这种做法存在缺陷，即用户可以通过新的攻击手段轻易提取服务器上的模型知识产权，从而削弱了加密计算所宣称的保护效果。文章分析了这一攻击的可行性，并讨论了可能的缓解措施。 <div>
Large language models (LLMs) have recently transformed many industries, enhancing content generation, customer service agents, data analysis and even software generation. These applications are often hosted on remote servers to protect the neural-network model IP; however, this raises concerns about the privacy of input queries. Fully Homomorphic Encryption (FHE), an encryption technique that allows for computations on private data, has been proposed as a solution to the challenge. Nevertheless, due to the increased size of LLMs and the computational overheads of FHE, today's practical FHE LLMs are implemented using a split model approach. Here, a user sends their FHE encrypted data to the server to run an encrypted attention head layer; then the server returns the result of the layer for the user to run the rest of the model locally. By employing this method, the server maintains part of their model IP, and the user still gets to perform private LLM inference. In this work, we evaluate the neural-network model IP protections of single layer split model LLMs, and demonstrate a novel attack vector that makes it easy for a user to extract the neural network model IP from the server, bypassing the claimed protections for encrypted computation. In our analysis, we demonstrate the feasibility of this attack, and discuss potential mitigations.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:50:31 +0000</pubDate>
</item>
<item>
<title>Provable Security Analysis of Butterfly Key Mechanism Protocol in IEEE 1609.2.1 Standard</title>
<link>https://eprint.iacr.org/2024/1674</link>
<guid>https://eprint.iacr.org/2024/1674</guid>
<content:encoded><![CDATA[
<div> 关键词：Butterfly Key Mechanism, V2X通信, 安全性分析, 隐私保护, 通信真实性<br /><br />总结: 本文对IEEE 1609.2.1标准中的Butterfly Key Mechanism（BKM）协议进行了首次安全性分析。BKM协议旨在高效地为车辆到一切（V2X）通信请求多个证书。我们定义了BKM的主要安全目标，包括车辆隐私和通信真实性。研究证明，通过少量修改，BKM协议能够满足这些安全目标。此外，还提出了一种显著提高协议效率的方法，同时不牺牲安全性。 <div>
The paper provides the first provable security analysis of the Butterfly Key Mechanism (BKM) protocol from IEEE 1609.2.1 standard. The BKM protocol specifies a novel approach for efficiently requesting multiple certificates for use in vehicle-to-everything (V2X)  communication. We define the main security goals of BKM, such as vehicle privacy and communication authenticity. We prove that the BKM protocol, with small modifications, meets those security goals. We also propose a way to significantly improve the protocol's efficiency without sacrificing security.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:47:48 +0000</pubDate>
</item>
<item>
<title>Proteus: A Fully Homomorphic Authenticated Transciphering Protocol</title>
<link>https://eprint.iacr.org/2024/1673</link>
<guid>https://eprint.iacr.org/2024/1673</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密, 超_cipher转换, 认证, 轻量级加密, 应用

<br /><br />总结:<br />
文章介绍了Proteus，一种新的认证超_cipher转换方法，用于全同态加密（FHE），以实现防篡改的数据处理。Proteus采用NIST推荐的轻量级加密标准ASCON进行同态哈希和认证转换，与TFHE加密方案结合使用。该方法解决了现有FHE超_cipher转换方案中存在的未认证和可篡改问题，通过防止用户下载未认证或恶意数据来提供安全保护。文中还展示了Proteus在实际隐私保护应用中的效果，包括URL钓鱼检测、私人内容仇恨言论审查以及生物特征认证等。 <div>
Fully Homomorphic Encryption (FHE) is a powerful technology that allows a cloud server to perform computations directly on ciphertexts. To overcome the overhead of sending and storing large FHE ciphertexts, the concept of FHE transciphering was introduced, allowing symmetric key encrypted ciphertexts to be transformed into FHE ciphertexts by deploying symmetric key decryption homomorphically. However, existing FHE transciphering schemes remain unauthenticated and malleable, allowing attackers to manipulate data and remain undetected. This work introduces Proteus, a new methodology for authenticated transciphering, which enables oblivious access control, preventing users from downloading unauthenticated or malicious data. Our protocol implementation adopts ASCON, NIST's new standard for lightweight cryptography, to enable homomorphic hashing and authenticated transciphering. Our ASCON transcipher is paired with the TFHE encryption scheme, which is well suited to perform encrypted rotation and bitwise operations. We evaluate our approach with a variety of real-life privacy-preserving applications, including URL phishing detection, private content moderation of hate speech, and biometric authentication.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:15:36 +0000</pubDate>
</item>
<item>
<title>DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning using Packed Secret Sharing</title>
<link>https://eprint.iacr.org/2024/1665</link>
<guid>https://eprint.iacr.org/2024/1665</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 差分隐私, 矩阵机制, 分布式机制, 密集秘密共享<br /><br />总结:<br />本文介绍了联邦学习（FL）中差分隐私（DP）的应用，特别是在隐私保护和模型效用之间的权衡问题。主要探讨了中心化DP和本地化DP两种形式。尽管在中心化DP设置下已经通过矩阵机制取得了显著进展，但在本地化DP环境下进展有限。文章提出了一种新的分布式矩阵机制来实现本地化DP的同时改善隐私-效用权衡。该机制采用一种加密协议，利用密集秘密共享技术安全地传输敏感信息，支持用户在训练轮次中的动态参与。实验表明，新机制显著提升了FL模型的隐私-效用权衡，同时几乎不增加额外开销。 <div>
Federated Learning (FL) has gained lots of traction recently, both in industry and academia. In FL, a machine learning model is trained using data from various end-users arranged in committees across several rounds. Since such data can often be sensitive, a primary challenge in FL is providing privacy while still retaining utility of the model. Differential Privacy (DP) has become the main measure of privacy in the FL setting. DP comes in two flavors: central and local. In the former, a centralized server is trusted to receive the users' raw gradients from a training step, and then perturb their aggregation with some noise before releasing the next version of the model. In the latter (more private) setting, noise is applied on users' local devices, and only the aggregation of users' noisy gradients is revealed even to the server. Great strides have been made in increasing the privacy-utility trade-off in the central DP setting, by utilizing the so-called \emph{matrix mechanism}. However, progress has been mostly stalled in the local DP setting. In this work, we introduce the \emph{distributed} matrix mechanism to achieve the best-of-both-worlds; local DP and also better privacy-utility trade-off from the matrix mechanism. We accomplish this by proposing a cryptographic protocol that securely transfers sensitive values across rounds, which makes use of \emph{packed secret sharing. This protocol accommodates the dynamic participation of users per training round required by FL, including those that may drop out from the computation. We provide experiments which show that our mechanism indeed significantly improves the privacy-utility trade-off of FL models compared to previous local DP mechanisms, with little added overhead.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 02:19:55 +0000</pubDate>
</item>
<item>
<title>Consensus on SNARK pre-processed circuit polynomials</title>
<link>https://eprint.iacr.org/2024/1664</link>
<guid>https://eprint.iacr.org/2024/1664</guid>
<content:encoded><![CDATA[
<div> 共识协议 区块链 竞争图 交互式提交 验证复杂度<br /><br />总结: 本文提出了一种基于多数规则的共识协议，用于处理可变的电路电线映射（wire maps），这些映射可能因程序输入或论证声明而变化。为了保持简洁性，某些零知识证明（SNARK）协议需要预先准备对电线映射的承诺，但这可能会很昂贵。该协议利用有向无环图（DAG）结构来表示来自不可信方的冲突电线映射。通过交互式的提交-证明-验证方案，该协议实现了高效的边缘验证。分析表明，即使在恶意环境下，该协议也能在几小时到几天内完成共识，同时保证了固定的验证复杂度。此外，引入了一个可调参数N，以在成本和时间与安全性之间取得平衡。 <div>
This paper addresses verifiable consensus of pre-processed circuit polynomials for succinct non-interactive argument of knowledge (SNARK). More specifically, we focus on parts of circuits, referred to as wire maps, which may change based on program inputs or statements being argued. Preparing commitments to wire maps in advance is essential for certain SNARK protocols to maintain their succinctness, but it can be costly. SNARK verifiers can alternatively consider receiving wire maps from an untrusted parties.

We propose a consensus protocol that reaches consensus on wire maps using a majority rule. The protocol can operate on a distributed, irreversible, and transparent server, such as a blockchain. Our analysis shows that while the protocol requires over 50\% honest participants to remain robust against collusive attacks, it enables consensus on wire maps with a low and fixed verification complexity per communication, even in adversarial settings. The protocol guarantees consensus completion within a time frame ranging from a few hours to several days, depending on the wire map degree and the honest participant proportion.

Technically, our protocol leverages a directed acyclic graph (DAG) structure to represent conflicting wire maps among the untrusted deliverers. Wire maps are decomposed into low-degree polynomials, forming vertices and edges of this DAG. The consensus participants, or deliverers, collaboratively manage this DAG by submitting edges to branches they support. The protocol then returns a commitment to the wire map that is written in the first fully grown branch. The protocol's computational efficiency is derived from an interactive commit-prove-verify scheme that enables efficient validation of submitted edges.

Our analysis implies that the practical provides a practical solution for achieving secure consensus on SNARK wire maps in environments with dynamic proportion of honest participants. Additionally, we introduce a tunable parameter $N$ that allows the protocol to minimize cost and time to consensus while maintaining a desired level of security.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 22:09:10 +0000</pubDate>
</item>
<item>
<title>High-Throughput Three-Party DPFs with Applications to ORAM and Digital Currencies</title>
<link>https://eprint.iacr.org/2024/1658</link>
<guid>https://eprint.iacr.org/2024/1658</guid>
<content:encoded><![CDATA[
<div> DPF 三党协议 隐私计算 PIR ORAM CBDC<br /><br />总结: 本文介绍了一种新的三方分布式点函数（DPF）构造，该构造在安全性和效率上与最先进的两方DPF相当。具体而言，它能抵御恶意对手的攻击，并且在函数大小和评估时间上与最佳的两方DPF一致。与现有三方DPF相比，新构造的函数大小和评估时间分别减少了40到120倍。此外，该DPF被应用于私有信息检索（PIR）、隐私写入（PIW）和不经意RAM（ORAM），并设计了一个支持访问策略的ORAM，特别适用于基于账户的数字货币，包括央行数字货币（CBDC）。文章还提出了一种称为可更新DPF的新原语，用于直接计算DPF与向量之间的点积，这在其他应用中也具有潜在价值。 <div>
Distributed point functions (DPF) are increasingly becoming a foundational tool with applications for application-specific and general secure computation.
While two-party DPF constructions are readily available for those applications with satisfiable performance, the three-party ones are left behind in both security and efficiency.
In this paper we close this gap and propose the first three-party DPF construction that matches the state-of-the-art two-party DPF on all metrics.
Namely, it is secure against a malicious adversary corrupting both the dealer and one out of the three evaluators, its function's shares are of the same size and evaluation takes the same time as in the best two-party DPF.
Compared to the state-of-the-art three-party DPF, our construction enjoys $40-120\times$ smaller function's share size and shorter evaluation time, for function domains of $2^{16}-2^{40}$, respectively.

Apart from DPFs as a stand-alone tool, our construction finds immediate applications to private information retrieval (PIR), writing (PIW) and oblivious RAM (ORAM).
To further showcase its applicability, we design and implement an ORAM with access policy, an extension to ORAMs where a policy is being checked before accessing the underlying database.
The policy we plug-in is the one suitable for account-based digital currencies, and in particular to central bank digital currencies (CBDCs).
Our protocol offers the first design and implementation of a large scale privacy-preserving account-based digital currency. While previous works supported anonymity sets of 64-256 clients and less than 10 transactions per second (tps), our protocol supports anonymity sets in the millions, performing $\{500,200,58\}$ tps for anonymity sets of $\{2^{16},2^{18},2^{20}\}$, respectively.

Toward that application, we introduce a new primitive called updatable DPF, which enables a direct computation of a dot product between a DPF and a vector; we believe that updatable DPF and the new dot-product protocol will find interest in other applications.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 14:55:34 +0000</pubDate>
</item>
<item>
<title>Securely Computing One-Sided Matching Markets</title>
<link>https://eprint.iacr.org/2024/1657</link>
<guid>https://eprint.iacr.org/2024/1657</guid>
<content:encoded><![CDATA[
<div> 关键词: Top Trading Cycles, 隐私保护, 功能图, 同态加密, 循环节点

<br /><br />总结:<br />
本文介绍了一种隐私保护的Top Trading Cycles (TTC)算法，用于在一组代理之间交易不可分割的商品。这是首次以这种方式实现TTC算法。作为技术贡献的一部分，本文提出了一种新的算法来确定功能图中所有位于循环中的节点。该算法特别适合安全实现，因为它不需要分支和随机内存访问。最后，本文报告了一个基于同态加密的协议原型实现。 <div>
Top trading cycles (TTC) is a famous algorithm for trading indivisible goods between a set of agents such that all agents are as happy as possible about the outcome. In this paper, we present a protocol for executing TTC in a privacy preserving way. To the best of our knowledge, it is the first of its kind. As a technical contribution of independent interest, we suggest a new algorithm for determining all nodes in a functional graph that are on a cycle. The algorithm is particularly well suited for secure implementation in that it requires no branching and no random memory access. Finally, we report on a prototype implementation of the protocol based on somewhat homomorphic encryption.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 13:58:49 +0000</pubDate>
</item>
<item>
<title>Secure Stateful Aggregation: A Practical Protocol with Applications in Differentially-Private Federated Learning</title>
<link>https://eprint.iacr.org/2024/1655</link>
<guid>https://eprint.iacr.org/2024/1655</guid>
<content:encoded><![CDATA[
<div> 差分隐私 联邦学习 联邦MPC 状态聚合 安全聚合<br /><br />总结:<br />本文介绍了一种名为安全状态聚合的方法，用于实现基于差分隐私联邦梯度下降（DP-FTRL）的完全私有、单个不可信服务器的联邦学习协议。这种方法允许在不信任的中央服务器上安全地存储和处理聚合值，同时保持隐私性。该技术基于环学习难题，并适用于高维数据。通过引入联邦MPC模型，使得强大的持久化服务器可以与弱且短暂的客户端进行交互。这种方法不仅提高了DPFL的效用保证，而且相比现有技术具有较低的开销，同时保持了隐私保护。<br /> <div>
Recent advances in differentially private federated learning (DPFL) algorithms have found that using correlated noise across the rounds of federated learning (DP-FTRL) yields provably and empirically better accuracy than using independent noise (DP-SGD). While DP-SGD is well-suited to federated learning with a single untrusted central server using lightweight secure aggregation protocols, secure aggregation is not conducive to implementing modern DP-FTRL techniques without assuming a trusted central server. DP-FTRL based approaches have already seen widespread deployment in industry, albeit with a trusted central curator who provides and applies the correlated noise.

To realize a fully private, single untrusted server DP-FTRL federated learning protocol, we introduce secure stateful aggregation: a simple append-only data structure that allows for the private storage of aggregate values and reading linear functions of the aggregates. Assuming Ring Learning with Errors, we provide a lightweight and scalable realization of this protocol for high-dimensional data in a new security/resource model, Federated MPC: where a powerful persistent server interacts with weak, ephemeral clients. We observe that secure stateful aggregation suffices for realizing DP-FTRL-based private federated learning: improving DPFL utility guarantees over the state of the art while maintaining privacy with an untrusted central party. Our approach has minimal overhead relative to existing techniques which do not yield comparable utility. The secure stateful aggregation primitive and the federated MPC paradigm may be of interest for other practical applications.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 11:52:43 +0000</pubDate>
</item>
<item>
<title>Logstar: Efficient Linear* Time Secure Merge</title>
<link>https://eprint.iacr.org/2024/159</link>
<guid>https://eprint.iacr.org/2024/159</guid>
<content:encoded><![CDATA[
<div> Logstar Median SquareRootMerge CubeRootMerge 实效优化<br /><br />总结: 本文介绍了两种高效的隐私保护合并算法：Logstar和Median。Logstar通过减少通信带宽实现了接近线性的运行时间，而Median则通过减少轮次优化了时间复杂度。此外，文章还提出了两种处理不同列表大小的合并算法，即SquareRootMerge和CubeRootMerge，它们分别能在O(n)时间内完成合并操作。这些算法不仅提高了理论效率，还在实际应用中展示了更好的性能，比如Logstar减少了约2倍的带宽成本，Median减少了约1.5倍的轮次。这些成果对于需要高效、安全地合并数据的应用场景具有重要意义。 <div>
Secure merge considers the problem of combining two sorted lists into a single sorted secret-shared list. Merge is a fundamental building block for many real-world applications. For example, secure merge can implement a large number of SQL-like database joins, which are essential for almost any data processing task such as privacy-preserving fraud detection, ad conversion rates, data deduplication, and many more.

We present two constructions with communication bandwidth and rounds tradeoff. Logstar, our bandwidth-optimized construction, takes inspiration from Falk and Ostrovsky (ITC, 2021) and runs in  $O(n\log^*n)$ time and communication with $O(\log n)$ rounds. In particular, for all conceivable $n$, the $\log^*n$ factor will be equal to the constant $2$, and therefore we achieve a near-linear running time. Median, our rounds-optimized construction, builds on the classic parallel medians-based insecure merge approach of Valiant (SIAM J. Comput., 1975), later explored in the secure setting by Blunk et al. (2022), and requires $O(n \log^c n)$, $c \approx 1.71$, communication with $O(\log \log n)$ rounds. 

We introduce two additional constructions that merge input lists of different sizes. SquareRootMerge merges lists of sizes $n^{\frac{1}{2}}$ and $n$ and runs in $O(n)$ time and communication with $O(\log n)$ rounds. CubeRootMerge is closely inspired by Blunk et al.'s (2022) construction and merges lists of sizes $n^{\frac{1}{3}}$ and $n$. It runs in $O(n)$ time and communication with $O(1)$ rounds.

We optimize our constructions for concrete efficiency. Today, concretely efficient secure merge protocols rely on standard techniques such as Batcher's merging network or generic sorting. These approaches require an $O(n \log n)$ size circuit of $O(\log n)$ depth. Despite significant research thrust, no work has been able to reduce their concrete costs. Our constructions are the first to be more efficient by improving their asymptotics and maintaining small constants. We analytically benchmark against these constructions and show that Logstar reduces bandwidth costs $\approx2.0\times$ and Median reduces rounds $\approx1.5\times$.
]]></content:encoded>
<pubDate>Sat, 03 Feb 2024 01:07:24 +0000</pubDate>
</item>
<item>
<title>Large-Scale MPC: Scaling Private Iris Code Uniqueness Checks to Millions of Users</title>
<link>https://eprint.iacr.org/2024/705</link>
<guid>https://eprint.iacr.org/2024/705</guid>
<content:encoded><![CDATA[
<div> 隐私保护 生物特征验证 神经网络通信库 高性能计算 安全多方计算<br /><br />总结: 本文介绍了一种用于生物特征验证系统中的隐私保护方案，通过安全多方计算（MPC）技术保护查询和数据库中的虹膜代码。该方案显著提升了性能，比现有最先进的系统Janus快三个数量级，单核CPU下每秒可处理超过69万次虹膜代码比较。此外，利用Nvidia NCCL实现GPU版本的协议，直接让GPU访问网络接口，从而避免了数据传输成本，使得在三方MPC设置中，每秒可以进行42.9亿次虹膜代码比较。此GPU实现满足了Worldcoin基金会的性能需求，将应用于其部署的World ID基础设施中。 <div>
In this work we tackle privacy concerns in biometric verification systems that typically require server-side processing of sensitive data (e.g., fingerprints and Iris Codes). Concretely, we design a solution that allows us to query whether a given Iris Code is similar to one contained in a given database, while all queries and datasets are being protected using secure multiparty computation (MPC). Addressing the substantial performance demands of operational systems like World ID and aid distributions by the Red Cross, we propose new protocols to improve performance by more than three orders of magnitude compared to the recent state-of-the-art system Janus (S&amp;P 24). Our final protocol can achieve a throughput of over 690 thousand Iris Code comparisons per second on a single CPU core, while protecting the privacy of both the query and database Iris Codes. Furthermore, using Nvidia NCCL we implement the whole protocol on GPUs while letting GPUs directly access the network interface. Thus we are able to avoid the costly data transfer between GPUs and CPUs, allowing us to achieve a throughput of 4.29 billion Iris Code comparisons per second in a 3-party MPC setting, where each party has access to 8 H100 GPUs. This GPU implementation achieves the performance requirements set by the Worldcoin foundation and will thus be used in their deployed World ID infrastructure.
]]></content:encoded>
<pubDate>Tue, 07 May 2024 16:38:57 +0000</pubDate>
</item>
<item>
<title>Computationally Secure Aggregation and Private Information Retrieval in the Shuffle Model</title>
<link>https://eprint.iacr.org/2024/870</link>
<guid>https://eprint.iacr.org/2024/870</guid>
<content:encoded><![CDATA[
<div> shuffle模型 信息论安全 计算安全 聚合协议 PIR<br /><br />总结: 本文研究了计算安全下的聚合协议和私有信息检索（PIR）在shuffle模型中的应用。文章指出，通过改进先前的加法共享洗牌技术，并基于标准学习 parity with noise (LPN) 假设或新的多不相交综合症解码 (MDSD) 猜想，可以提高效率。对于长向量的安全聚合，本文提出的协议相比以前的信息论安全解决方案减少了9到25倍的通信需求。此外，本文的PIR协议在单一服务器上存储数据库的同时，保持了多服务器PIR的简单性和具体效率优势，并且在MDSD假设下，相比最近的单服务器PIR构造，性能提升了两个数量级。 <div>
The shuffle model has recently emerged as a popular setting for differential privacy, where clients can communicate with a central server using anonymous channels or an intermediate message shuffler. This model was also explored in the context of cryptographic tasks such as secure aggregation and private information retrieval (PIR). However, this study was almost entirely restricted to the stringent notion of information-theoretic security. 

In this work, we study computationally secure aggregation protocols and PIR in the shuffle model. Our starting point is the insight that the previous technique of shuffling additive shares can be improved in the computational setting. We show that this indeed holds under the standard learning parity with noise (LPN) assumption, but even better efficiency follows from plausible conjectures about the multi-disjoint syndrome decoding (MDSD) problem that we introduce and study in this work.

We leverage the above towards improving the efficiency of secure aggregation and PIR in the shuffle model. For secure aggregation of long vectors, our protocols require $9\times$-$25\times$ less communication than the previous information-theoretic solutions. Our PIR protocols enjoy the simplicity and concrete efficiency benefits of multi-server PIR while only requiring a single server to store the database. Under the MDSD assumption, they improve over recent single-server PIR constructions by up to two orders of magnitude.
]]></content:encoded>
<pubDate>Sat, 01 Jun 2024 07:24:09 +0000</pubDate>
</item>
<item>
<title>Oblivious Turing Machine</title>
<link>https://eprint.iacr.org/2023/1643</link>
<guid>https://eprint.iacr.org/2023/1643</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式计算, 同态加密, 图灵机模型, 隐私保护, 非交互式<br /><br />总结:<br />本文探讨了在分布式计算环境中，数据和程序隐私保护的重要性。文章指出，现有的方案主要关注数据保密性，而忽略了通过服务器执行函数可能泄露的信息。为了解决这个问题，文章提出了一种结合全同态加密与图灵机模型的新方法，开发了首个完全安全、非交互式的全同态图灵机。该方法基于环学习带误差问题的难度、非线性函数的同态评估能力和数据结构元素的盲旋转能力三个假设。文章还介绍了基于TFHE密码系统的实现，并展示了实施结果。 <div>
In the ever-evolving landscape of Information Tech- nologies, private decentralized computing on an honest yet curious server has emerged as a prominent paradigm. While numerous schemes exist to safeguard data during computation, the focus has primarily been on protecting the confidentiality of the data itself, often overlooking the potential information leakage arising from the function evaluated by the server. Recognizing this gap, this article aims to address the issue by presenting and implementing an innovative solution for ensuring the privacy of both the data and the program. We introduce a novel approach that combines the power of Fully Homomorphic Encryption with the concept of the Turing Machine model, resulting in the first fully secure practical, non-interactive oblivious Turing Machine. Our Oblivious Turing Machine construction is based on only three hypotheses, the hardness of the Ring Learning With Error problem, the ability to homomorphically evaluate non-linear functions and the capacity to blindly rotate elements of a data structure. Only based on those three assumptions, we propose an implementation of an Oblivious Turing Machine relying on the TFHE cryptosystem and present some implementation results.
]]></content:encoded>
<pubDate>Mon, 23 Oct 2023 20:21:51 +0000</pubDate>
</item>
<item>
<title>Secure Transformer Inference</title>
<link>https://eprint.iacr.org/2023/1763</link>
<guid>https://eprint.iacr.org/2023/1763</guid>
<content:encoded><![CDATA[
<div> 安全 模型参数 用户数据 效率瓶颈 半对称置换<br /><br />总结: 本文针对Transformer模型服务中的安全问题，特别是模型参数和用户数据的安全性进行了探讨。作者基于实际开发经验，指出传统的两方威胁模型存在效率瓶颈，并提出了一种新的三方威胁模型，包括模型开发者、模型服务器和数据所有者。在此基础上，设计了一种半对称置换保护方案STIP，实现了无推断准确度损失的高效安全推断协议。文章还分析了STIP对暴力破解、已知明文和社交工程攻击的抵抗能力，并通过实验验证了其在大规模模型上的安全性和准确性。此外，还提出了一种方法将可信执行环境与STIP结合，增强模型参数对模型提取和微调攻击的抵抗力。实验结果表明，STIP在保持高安全性的同时，大幅降低了推断延迟。 <div>
Security of model parameters and user data is critical for Transformer-based services, such as ChatGPT.
While recent strides in secure two-party protocols have successfully addressed security concerns in serving Transformer models, their adoption is practically infeasible due to the prohibitive cryptographic overheads involved.
Drawing insights from our hands-on experience in developing two real-world Transformer-based services, we identify the inherent efficiency bottleneck in the two-party assumption. 
To overcome this limitation, we propose a novel three-party threat model that consists of model developer, model server, and data owner. 
Based on this framework, we design a semi-symmetric permutation-based protection scheme and present STIP, the first secure Transformer inference protocol without any inference accuracy loss.
We analyze STIP's resistance to brute force, known-plaintext, and social engineering attacks and prove the privacy leakage upper bound using distance correlation.
And we propose a method to integrate the trusted execution environment with STIP to make model parameters resistant to model extraction and fine-tuning attacks.
Experiments on six representative series of Transformer models, with up to 70 billion parameters, in real systems show that STIP has strong security and no loss of accuracy.
For auto-regressive token generation, STIP achieves 31.7 ms latency for LLaMA2-7b model, significantly reducing the 5-minute overhead of the state-of-the-art two-party protocols.
]]></content:encoded>
<pubDate>Wed, 15 Nov 2023 02:55:09 +0000</pubDate>
</item>
<item>
<title>Ripple: Accelerating Programmable Bootstraps for FHE with Wavelet Approximations</title>
<link>https://eprint.iacr.org/2024/866</link>
<guid>https://eprint.iacr.org/2024/866</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密 查找表 离散小波变换 精度 误差减少

<br /><br />总结:<br />
文章介绍了一种名为Ripple的新框架，该框架旨在解决同态加密中查找表精度与成本之间的矛盾。通过采用离散小波变换（DWT）方法来减少查找表中的条目数量，同时保持高精度。研究表明，与传统的量化方法相比，Ripple在多个非线性函数上实现了显著的误差减少。此外，Ripple还提高了如逻辑回归和互相关等实际基准测试的运行时间性能。 <div>
Homomorphic encryption can address key privacy challenges in cloud-based outsourcing by enabling potentially untrusted servers to perform meaningful computation directly on encrypted data. While most homomorphic encryption schemes offer addition and multiplication over ciphertexts natively, any non-linear functions must be implemented as costly polynomial approximations due to this restricted computational model. Nevertheless, the CGGI cryptosystem is capable of performing arbitrary univariate functions over ciphertexts in the form of lookup tables through the use of programmable bootstrapping. While promising, this procedure can quickly become costly when high degrees of precision are required. To address this challenge, we propose Ripple: a framework that introduces different approximation methodologies based on discrete wavelet transforms (DWT) to decrease the number of entries in homomorphic lookup tables while maintaining high accuracy. Our empirical evaluations demonstrate significant error reduction compared to plain quantization methods across multiple non-linear functions. Notably, Ripple improves runtime performance for several realistic benchmarks, such as logistic regression and cross-correlation, among others.
]]></content:encoded>
<pubDate>Fri, 31 May 2024 20:57:39 +0000</pubDate>
</item>
<item>
<title>TokenWeaver: Privacy Preserving and Post-Compromise Secure Attestation</title>
<link>https://eprint.iacr.org/2022/1691</link>
<guid>https://eprint.iacr.org/2022/1691</guid>
<content:encoded><![CDATA[
<div> TokenWeaver 可证明性 隐私保护 后妥协安全 链式令牌 互不连接<br /><br />总结: 本文介绍了一种名为TokenWeaver的方法，这是一种基于可信执行环境（TEE）的隐私保护后妥协安全证明方法。通过结合可链接和不可链接两种类型的令牌链，TokenWeaver旨在即使在TEE被攻击后也能恢复其安全性，同时保证用户隐私不被追踪。该方法提供了Tamarin和DeepSec验证器的完整形式化模型及协议、安全属性和证明，以确保其核心特性的正确性。此外，还提供了一个Python的概念验证实现，展示了解决方案的简洁性和适用性。这一研究有助于解决现代认证系统中的隐私保护与安全性之间的矛盾。 <div>
Modern attestation based on Trusted Execution Environments (TEEs) can significantly reduce the risk of secret compromise,  allowing users to securely perform sensitive computations such as running cryptographic protocols for authentication across security critical services. However, this has also made TEEs a high-value attack target, driving an arms race between novel compromise attacks and continuous TEEs updates. 

Ideally, we want to achieve Post-Compromise Security (PCS): even after a TEE compromise, we can update it back into a secure state. However, at the same time, we would like to guarantee the privacy of users, in particular preventing providers (such as Intel, Google, or Samsung) or services from tracking users across services. This requires unlinkability, which seems incompatible with standard PCS healing mechanisms.

In this work, we develop TokenWeaver, the first privacy-preserving post-compromise secure attestation method with automated formal proofs for its core properties. We base our construction on weaving together two types of token chains, one of which is linkable and the other is unlinkable. We provide the full formal models based on the Tamarin and DeepSec provers, including protocol, security properties, and proofs for reproducibility, as well as a proof-of-concept implementation in python that shows the simplicity and applicability of our solution.
]]></content:encoded>
<pubDate>Tue, 06 Dec 2022 15:45:37 +0000</pubDate>
</item>
<item>
<title>Curve Forests: Transparent Zero-Knowledge Set Membership with Batching and  Strong Security</title>
<link>https://eprint.iacr.org/2024/1647</link>
<guid>https://eprint.iacr.org/2024/1647</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、集合成员性、透明性、曲线树、批量验证

总结:

本文提出了一种新的高效构造方法，用于解决批量验证的零知识集合成员性问题。该构造方法具有透明性，无需信任设置，基于Campanelli、Hall-Andersen和Kamp在USENIX 2023年会议上提出的曲线树。主要技术贡献包括在批量设置中通过利用曲线树的代数特性来实现曲线树成本的摊销，这使得证明速度提升约2倍，验证速度提升约3倍，证明大小减少约60%。此外，文章还对曲线树的关键技术要求进行了修改，简化了其设计并获得了更强的安全属性，特别是当集合的承诺由攻击者提供时，仍能保持安全，而原始的曲线树则要求诚实的承诺。

这种新的构造方法为隐私保护应用提供了更高效的解决方案，如匿名支付、凭证和白名单，通过减少信息泄露，增强了数据安全性与隐私保护。 <div>
Zero-knowledge for set membership is a building block at the core of several privacy-aware applications, such as anonymous payments, credentials and whitelists.
We propose a new efficient construction for the batching variant of the problem, where a user intends to show knowledge of several elements (a batch) in a  set without any leakage on the elements. Our construction is transparent—it does not requires a trusted setup—and based on Curve Trees by Campanelli, Hall-Andersen and Kamp (USENIX 2023). Our first technical contribution consists in techniques to amortize Curve Trees costs in the batching setting for which we crucially exploit its algebraic properties. Even for small batches we obtain $\approx 2\times$ speedups for proving, $\approx3\times$ speedups for verification and $\approx 60\%$ reduction in proof size. Our second contribution is a modifications of a key technical requirement in Curve Trees (related to so called "permissible points") which arguably simplifies its design and obtains a stronger security property. In particular, our construction is secure even for the case where the  commitment  to the set is provided by the adversary (in contrast to the honest one required by the original Curve Trees).
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 17:11:18 +0000</pubDate>
</item>
<item>
<title>Fiat-Shamir Goes Rational</title>
<link>https://eprint.iacr.org/2024/1645</link>
<guid>https://eprint.iacr.org/2024/1645</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式、理性证明、Fiat-Shamir变换、智能合约、安全保证

总结:
本文探讨了构建非交互式理性证明的开放性问题。理性证明是由Azar和Micali在2012年提出的模型，其中计算能力强大的服务器可以通过运行昂贵的计算$f(x)$来获得弱客户端的奖励。当服务器理性行事时，任何声称错误输出$y \neq f(x)$的对手将预期损失金钱。当前所有非平凡的理性证明构造都是交互式的。开发非交互式理性协议将是一个游戏规则改变者，使其在智能合约等自然应用中变得可行。

文章的主要发现包括：
1. 提出并解决了标准Fiat-Shamir变换不适用于验证器仅对输入$x$有随机探针访问的问题。
2. 提出了两种版本的Fiat-Shamir变换：一种是基本版，另一种是增强版（验证器可以访问其输入的真实计算摘要）。这两种版本都无法确保AM13或CG15在非交互式设置下保持安全性。
3. 提供了一个关于理性证明（无论是交互式还是非交互式）的原始兴趣的新颖且可能更简单的完好数学定义。

通过这些研究，文章为理解Fiat-Shamir变换在理性证明中的适用性和构建非交互式理性证明提供了关键洞察，并指出了未来工作的可能性。 <div>
This paper investigates the open problem of how to construct non-interactive rational proofs. Rational proofs, introduced by Azar and Micali (STOC 2012), are a model of interactive proofs where a computationally powerful server can be rewarded by a weaker client for running an expensive computation $f(x)$. The honest strategy is enforced by design when the server is rational: any adversary claiming a false output $y \neq f(x)$ will lose money on expectation.
Rational proof constructions have appealing properties: they are simple, feature an extremely efficient verifier—reading only a sublinear number of bits of the input $x$—and do not require any collateral from the prover. Currently, all non-trivial constructions of rational proofs are interactive. Developing non-interactive rational protocols would be a game-changer, making them practical for use in smart contracts, one of their most natural applications.
Our investigation revolves around the Fiat-Shamir transform, a common approach to compiling interactive proofs into their non-interactive counterparts. We are the first to tackle the question: "Can Fiat-Shamir be successfully applied to rational protocols?"
We find negative evidence by showing that, after applying Fiat-Shamir in the random oracle model to two representative protocols in literature (AM13 and CG15) these lose their security guarantees. Our findings point to more general impossibility theorems, which we leave as future work.
To achieve our results we first need to address a fundamental technical challenge:  the standard Fiat-Shamir transform does not apply to protocols where the verifier has only oracle access to its input $x$ (a core feature of the rational setting). We propose two versions of Fiat-Shamir for this setting, a "vanilla" variant and a "stronger" variant (where the verifier has access to an honestly computed digest of its input). We show that neither variant is sufficient to ensure that AM13 or CG15 are secure in the non-interactive setting.
Finally, as an additional contribution, we provide a novel, and arguably simpler, definition for the soundness property of rational proofs (interactive or non-interactive) of independent interest.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 13:30:06 +0000</pubDate>
</item>
<item>
<title>Transaction Execution Mechanisms</title>
<link>https://eprint.iacr.org/2024/1646</link>
<guid>https://eprint.iacr.org/2024/1646</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、交易执行机制、资源分配、多队列系统、全局共识

总结:本文探讨了区块链中的交易执行机制(TEM)，着重于如何在多个并行执行队列或“本地费用市场”之间高效分配资源。研究构建了一个模型，考虑了容量限制、用户评估和延迟成本，在具有全球共识的聚合容量约束的多队列系统中。文章指出，收益最大化倾向于将容量分配给支付最高的队列，而福利最大化通常服务于所有队列。不同队列的相对定价取决于市场大小、需求弹性以及局部和全局拥堵之间的平衡。这些发现对正在演变的区块链架构具有重要影响，包括并行执行、DAG基系统和多个并发提议者，并能帮助设计更高效的TEM。通过理解这些机制，开发者可以优化网络性能，提高用户体验，并确保系统的公平性和稳定性。 <div>
This paper studies transaction execution mechanisms (TEMs) for blockchains, as the efficient resource allocation across multiple parallel executions queues or "local fee markets." We present a model considering capacity constraints, user valuations, and delay costs in a multi-queue system with an aggregate capacity constraint due to global consensus. We show that revenue maximization tends to allocate capacity to the highest-paying queue, while welfare maximization generally serves all queues. Optimal relative pricing of different queues depends on factors such as market size, demand elasticity, and the balance between local and global congestion.  Our results have implications for evolving blockchain architectures, including parallel execution, DAG-based systems, and multiple concurrent proposers, and can help design more efficient TEMs.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 15:16:32 +0000</pubDate>
</item>
<item>
<title>Optimizing Liveness for Blockchain-Based Sealed-Bid Auctions in Rational Settings</title>
<link>https://eprint.iacr.org/2024/1643</link>
<guid>https://eprint.iacr.org/2024/1643</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、拍卖市场、公平性、透明度、分布式匿名出价

总结:

本文研究了基于区块链的拍卖市场，与传统中心化拍卖相比，其在公平性和透明度上具有显著优势。文章主要贡献在于提出了一种去中心化的匿名存入出价（DADB）方案，为该机制提供了正式的语法和安全性定义。不同于依赖智能合约的传统方法，该方案采用了主链-侧链架构，兼容扩展的UTXO模型。这种设计使得能够构建一个专门用于安全记录投标并进行分配的共识机制在侧链上。

文章通过游戏理论视角证明，即使没有明确的激励（如费用）来包括投标，我们的设计也能优化理性参与者加入拍卖的存活延迟时间。最后，实施结果表明，缺乏块资格机制可能导致性能下降。

综上所述，本文通过提出DADB方案，不仅增强了区块链拍卖市场的公平性和透明度，还通过理论分析和实证研究验证了其在提高效率方面的潜力，为区块链技术在拍卖领域的应用提供了新的思路和方法。 <div>
Blockchain-based auction markets offer stronger fairness and transparency compared to their centralized counterparts. Deposits and sealed bid formats are usually applied to enhance security and privacy. However, to our best knowledge, the formal treatment of deposit-enabled sealed-bid auctions remains lacking in the cryptographic literature. To address this gap, we first propose a decentralized anonymous deposited-bidding (DADB) scheme, providing formal syntax and security definitions. Unlike existing approaches that rely on smart contracts, our construction utilizes a mainchain-sidechain structure that is also compatible with the extended UTXO model. This design further allows us to develop a consensus mechanism on the sidechain dedicated to securely recording bids for allocation. Specifically, we build atop an Algorand-style protocol and integrate a novel block qualification mechanism into the block selection. Consequently, we prove, from a game-theoretical perspective, that our design optimizes liveness latency for rational users who want to join the auction, even without explicit incentives (e.g., fees) for including bids. Finally, our implementation results demonstrate the potential performance degradation without the block qualification mechanism.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 04:24:11 +0000</pubDate>
</item>
<item>
<title>Fully Secure Searchable Encryption from PRFs, Pairings, and Lattices</title>
<link>https://eprint.iacr.org/2024/1632</link>
<guid>https://eprint.iacr.org/2024/1632</guid>
<content:encoded><![CDATA[
<div> 关键词：搜索加密、全安全、查询限制、普适、假随机函数

本文主要探讨了搜索加密领域中的全安全性概念及其实现。全安全包括了密文隐私和陷阱门隐私两个方面，确保在进行搜索操作时，既不泄露密文内容也不泄露陷阱门信息。文章首先指出，由于理论限制，目前仅能构建查询限制的全安全方案，而实现普适的全安全方案较为困难。

接着，作者提出了一种基于伪随机函数的查询限制全安全方案，并进一步设计了两种基于双线性对和格的高效（无限制）全安全方案。这些方案在保证全安全性的前提下，提高了搜索效率和实用性。

同时，文章还对已有的全安全方案进行了深入分析。通过简化前人的工作并提供正式证明，澄清了某方案关于安全性的错误宣传。这不仅增强了对现有方案的理解，也为后续研究提供了宝贵的反馈。

总结: 本文通过构建新的全安全搜索加密方案，以及对现有方案的深入分析与优化，推动了搜索加密领域的理论与实践发展。其中，基于伪随机函数的方案为查询限制场景提供了安全保证；基于双线性和格的方案则在保持全安全性的同时，提升了方案的适用性和效率；此外，通过修正前人关于安全性的错误表述，为学术界提供了更为准确的安全性评估标准。这些贡献共同推进了搜索加密技术在隐私保护与数据检索领域的应用。 <div>
Searchable encryption is a cryptographic primitive that allows us to perform searches on encrypted data. Searchable encryption schemes require that ciphertexts do not leak information about keywords. However, most of the existing schemes do not achieve the security notion that trapdoors do not leak information. Shen et al. (TCC 2009) proposed a security notion called full security, which includes both ciphertext privacy and trapdoor privacy, but there are few fully secure constructions. Full security is defined for the secret key settings since it is known that public key schemes cannot achieve the trapdoor privacy in principle.
In this paper, we construct a query-bounded fully secure scheme from pseudorandom functions. In addition, we propose two types of efficient (unbounded) fully secure schemes, each of which is based on bilinear groups and lattices respectively. We then analyze the existing constructions. First, we simplify the Cheng et al. scheme (Information Sciences 2023) and prove its security. This scheme had not been proved to be secure. Second, we show that the Li-Boyen pairing-based scheme (IACR CiC 2024) does not achieve the trapdoor privacy, not as claimed.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 12:31:16 +0000</pubDate>
</item>
<item>
<title>Efficient Key-Switching for Word-Type FHE and GPU Acceleration</title>
<link>https://eprint.iacr.org/2024/1629</link>
<guid>https://eprint.iacr.org/2024/1629</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算、全同态加密（FHE）、量子安全性、线性复杂度、GPU优化

总结:
本文研究了云计算环境下提高全同态加密（FHE）性能和安全性的方法。全同态加密允许在数据加密状态下进行计算，同时保护数据隐私。特别地，基于格的全同态加密具有量子安全性，可抵御量子计算机攻击。然而，当前FHE方案的性能不佳，主要由于数据长度和多个资源密集型操作的高成本。

研究中引入了一种新算法，该算法通过实现Number Theoretic Transform（NTT）的线性复杂度，有效解决了关键切换过程中的复杂计算问题。该算法不仅在效率上与现有最佳方法相当，而且在复杂性和GPU内存使用上显著简化，节省高达95%的空间，特别适合GPU环境。

通过优化GPU性能，此算法实现了相比基线方法和当前最佳方法高达2.0倍的加速效果。这种平衡了简单性和性能的算法，为现代硬件平台上的加密计算提供了更实际和高效的实现方式，从而推动了全同态加密在云计算环境中的广泛应用。 <div>
Speed efficiency, memory optimization, and quantum resistance are essential for safeguarding the performance and security of cloud computing environments. Fully Homomorphic Encryption (FHE) addresses this need by enabling computations on encrypted data without requiring decryption, thereby maintaining data privacy. Additionally, lattice-based FHE is quantum secure, providing defense against potential quantum computer attacks. However, the performance of current FHE schemes remains unsatisfactory, largely because of the length of the operands and the computational expense associated with several resource-intensive operations. Among these operations, key-switching is one of the most demanding processes because it involves complex arithmetic operations necessary to conduct computations in a larger cyclotomic ring.

In this research, we introduce a novel algorithm that achieves linear complexity in the Number Theoretic Transform (NTT) for key-switching. This algorithm offers efficiency comparable to the state-of-the-art while being significantly simpler and consumes less GPU memory. Notably, it reduces space consumption by up to 95\%, making it highly friendly for GPU memory. By optimizing GPU performance, our implementation achieves up to a 2.0$\times$ speedup compared to both the baseline approach and the current state-of-the-art methods. This algorithm effectively balances simplicity and performance, thereby enhancing cryptographic computations on modern hardware platforms and paving the way to more practical and efficient FHE implementations in cloud computing environments.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 04:59:43 +0000</pubDate>
</item>
<item>
<title>General Functional Bootstrapping using CKKS</title>
<link>https://eprint.iacr.org/2024/1623</link>
<guid>https://eprint.iacr.org/2024/1623</guid>
<content:encoded><![CDATA[
<div> 关键词：Ducas-Micciancio、Chilotti-Gama-Georgieva-Izabachène、Cheon-Kim-Kim-Song、全同态加密、功能重灌注

<br /><br />
总结:本文提出了一种基于Cheon-Kim-Kim-Song(FHE)方案的功能重灌注方法，以解决全同态加密(FHE)系统在执行任意函数表(LUT)计算时效率低下的问题。该方法通过利用三角Hermite插值理论构建了一个理论工具包，实现了对任意函数的评估，并对噪声降低过程进行了控制。实验结果表明，对于8位LUT评估，所提出的方法达到了0.75毫秒的平均时间，比Ducas-Micciancio和Chilotti-Gama-Georgieva-Izabachène的方案快三个数量级，且比基于Brakerski/Fan-Vercauteren(FBV)方案的更受限的功能重灌注方法快6.6倍。这标志着在保持隐私的同时，显著提高了FHE系统的计算效率与实用性。 <div>
The Ducas-Micciancio (DM/FHEW) and Chilotti-Gama-Georgieva-Izabachène (CGGI/TFHE) cryptosystems provide a general privacy-preserving computation capability. These fully homomorphic encryption (FHE) cryptosystems can evaluate an arbitrary function expressed as a general look-up table (LUT) via the method of functional bootstrapping (also known as programmable bootstrapping). The main limitation of DM/CGGI functional bootstrapping is its efficiency because this procedure has to bootstrap every encrypted number separately. A different bootstrapping approach, based on the Cheon-Kim-Kim-Song (CKKS) FHE scheme, can achieve much smaller amortized time due to its ability to bootstrap many thousands of numbers at once. However, CKKS does not currently provide a functional bootstrapping capability that can evaluate a general LUT. An open research question is whether such capability can be efficiently constructed. We give a positive answer to this question by proposing and implementing a general functional bootstrapping method based on CKKS-style bootstrapping. We devise a theoretical toolkit for evaluating an arbitrary function using the theory of trigonometric Hermite interpolations, which provides control over noise reduction during functional bootstrapping. Our experimental results for 8-bit LUT evaluation show that the proposed method achieves the amortized time of 0.75 milliseconds, which is three orders of magnitude faster than the DM/CGGI approach and 6.6x faster than (a more restrictive) amortized functional bootstrapping method based on the Brakerski/Fan-Vercauteren (BFV) FHE scheme.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 19:28:47 +0000</pubDate>
</item>
<item>
<title>Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference</title>
<link>https://eprint.iacr.org/2024/1611</link>
<guid>https://eprint.iacr.org/2024/1611</guid>
<content:encoded><![CDATA[
<div> 关键词：Rhombus、矩阵-向量乘法、半诚实模型、同态加密、性能优化

文章主要介绍了一种名为“Rhombus”的新型安全矩阵-向量乘法（MVM）协议，适用于半诚实的两方设置。该协议能够无缝集成到现有的隐私保护机器学习（PPML）框架中，并作为线性层安全计算的基础。Rhombus采用了基于RLWE的同态加密（HE）与系数编码相结合的方式，允许消息选择不仅限于域\(\mathbb{F}_p\)，还包括整环\(\mathbb{Z}_{2^\ell}\)，这在非线性层中支持更快的计算。

为了提高效率，作者开发了输入-输出打包技术，减少了使用系数编码的同态加密带来的通信成本，大约降低了21倍。此外，提出了分割点选取技术，将旋转次数减少至矩阵维度的亚线性级别。相较于近期的协议HELiKs，Rhombus在MVM协议整体性能上提升了约7.4至8倍，对于ResNet50安全双方推理的端到端性能提高了约4.6至18倍。

总结: Rhombus协议通过采用创新的同态加密方法和优化技术，显著提高了矩阵-向量乘法操作的效率和性能，特别是对于需要高安全性的隐私保护机器学习应用。通过减少通信成本和优化旋转次数，Rhombus在保持安全性的同时，实现了计算性能的大幅增强，为构建高效、安全的机器学习系统提供了有力支持。 <div>
We present $\textit{Rhombus}$, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers. 
$\textit{Rhombus}$ adopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field $\mathbb{F}_p$ but also a ring $\mathbb{Z}_{2^\ell}$, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about $21\times$, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocol $\textit{HELiKs}$ by Balla and Koushanfar (CCS'23), our implementation demonstrates that $\textit{Rhombus}$ improves the whole performance of an MVM protocol by a factor of $7.4\times \sim 8\times$, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of $4.6\times \sim 18\times$.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 02:45:46 +0000</pubDate>
</item>
<item>
<title>Secret Sharing with Snitching</title>
<link>https://eprint.iacr.org/2024/1610</link>
<guid>https://eprint.iacr.org/2024/1610</guid>
<content:encoded><![CDATA[
<div> 关键词：股东共谋、秘密共享、个体加密、秘密出卖、多党计算

总结:

本文探讨了在个体加密模型下检测和惩罚股东共谋的问题，该模型假设存在仅单台机器能有效执行的任务，而将其分散到多个互不信任的设备上则是不可行的。为了应对这一挑战，文章引入了一种新的密码学工具——秘密共享与出卖（SSS），旨在确保任何非法重构共享秘密的行为都能被证明并受到惩罚。

首先，文章定义了阈值（t-out-of-n）秘密共享与出卖（SSS），其中t代表所需的最小份额数量以重构秘密。接下来，通过构建适用于t=n的情况，文章展示了如何构建此类机制。最终，利用这一基础构造，文章进一步设计出适用于任意t值的SSS方案。

为了证明此方案的安全性，文章提出了对随机原象模型的扩展，允许在多党计算过程中模拟哈希函数的评估。这为确保SSS方案的有效性和安全性提供了理论基础。

综上所述，文章通过引入秘密共享与出卖的概念，以及对其安全性的深入分析，提供了一种有效防止股东共谋的技术框架。这一框架不仅针对直接的秘密重构行为，还涵盖了利用多党计算协议进行秘密泄露的行为，从而在理论上为预防和惩罚此类共谋行为提供了坚实的基础。 <div>
We address the problem of detecting and punishing shareholder collusion in secret-sharing schemes. We do it in the recently proposed cryptographic model called individual cryptography (Dziembowski, Faust, and Lizurej, Crypto 2023), which assumes that there exist tasks that can be efficiently computed by a single machine but distributing this computation across multiple (mutually distrustful devices) is infeasible.

Within this model, we introduce a novel primitive called secret sharing with snitching (SSS), in which each attempt to illegally reconstruct the shared secret $S$ results in a proof that can be used to prove such misbehavior (and, e.g., financially penalize the cheater on a blockchain). This holds in a very strong sense, even if the shareholders attempt not to reconstruct the entire secret~$S$ but only learn some partial information about it. Our notion also captures the attacks performed using multiparty computation protocols (MPCs), i.e., those where the malicious shareholders use MPCs to compute partial information on $S$. The main idea of SSS is that any illegal reconstruction can be proven and punished, which suffices to discourage illegal secret reconstruction. Hence, our SSS scheme effectively prevents shareholders' collusion. We provide a basic definition of threshold ($t$-out-of-$n$) SSS. We then show how to construct it for $t = n$, and later, we use this construction to build an SSS scheme for an arbitrary $t$.

In order to prove the security of our construction, we introduce a generalization of the random oracle model (Bellare, Rogaway, CCS 1993), which allows modelling hash evaluations made inside MPC.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 20:10:46 +0000</pubDate>
</item>
<item>
<title>Mild Asymmetric Message Franking: Illegal-Messages-Only and Retrospective Content Moderation</title>
<link>https://eprint.iacr.org/2024/1608</link>
<guid>https://eprint.iacr.org/2024/1608</guid>
<content:encoded><![CDATA[
<div> 关键词：E2E加密、非法内容、消息打码、技术平衡、框架构建

总结:

本文探讨了广泛采用端到端（E2E）加密后，信息平台面临的用户隐私与非法内容管理之间的技术挑战。主要问题在于现有的解决方案往往侧重于不可帧化或否认性，但缺乏有效的非法内容处理机制，同时可能被滥用。为解决这些问题，文章提出了一种名为“温和非对称消息打码”（MAMF）的新概念，旨在实现非法消息专有和回溯内容管理，同时支持不可帧化和否认性。

文章进一步提供了一个构建MAMF的框架，并引入了两个新的基础组件，这些组件不仅对于实现MAMF具有重要意义，也可能是独立研究的有价值贡献。通过这种框架，信息平台可以在保护用户隐私的同时，有效管理和监控非法内容，从而实现用户隐私与内容安全的平衡。

该解决方案的核心在于创造一种机制，允许平台对非法消息进行标记或打码，使得非法消息仅可由指定人员访问，同时确保其他合法通信内容的隐私和安全性不受影响。此外，该系统还具备回溯功能，允许在特定情况下审查和处理历史消息，以应对潜在的非法内容传播问题。通过这一创新，文章为信息平台提供了在维护用户隐私的同时，有效应对非法内容挑战的技术路径。 <div>
Many messaging platforms have integrated end-to-end (E2E) encryption into their services. This widespread adoption of E2E encryption has triggered a technical tension between user privacy and illegal content moderation. The existing solutions either support only unframeability or deniability, or they are prone to abuse (the moderator can perform content moderation for all messages, whether illegal or not), or they lack mechanisms for retrospective content moderation.

To address the above issues, we introduce a new primitive called \emph{mild asymmetric message franking} (MAMF) to establish illegal-messages-only and retrospective content moderation for messaging systems, supporting unframeability and deniability simultaneously. We provide a framework to construct MAMF, leveraging two new building blocks, which might be of independent interest.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 12:49:58 +0000</pubDate>
</item>
<item>
<title>Reckle Trees: Updatable Merkle Batch Proofs with Applications</title>
<link>https://eprint.iacr.org/2024/493</link>
<guid>https://eprint.iacr.org/2024/493</guid>
<content:encoded><![CDATA[
<div> 关键词: Reckle树、矢量承诺、递归论证、梅克尔树、更新性批验证

总结:
文章提出了一种新的矢量承诺机制——Reckle树，它基于递归论证和梅克尔树。Reckle树的独特之处在于支持紧凑的可更新批验证，这对于区块链环境中的应用非常关键，因为这些应用需要高效地处理不断变化的块流。该机制通过嵌入批哈希计算到递归梅克尔验证中，利用哈希基积构造“标准”进行实现。这使得批证明能够在时间复杂度为对数级别的情况下更新，且当批中的某个梅克尔叶（无论是否属于批）发生变化时，只需要维护一个存储先前计算的递归证明的数据结构。

为了进一步扩展其应用范围，文章还引入了Reckle+树，这是一种用于某些类型Map/Reduce运算的矢量承诺机制。在Reckle+树中，验证者可以对内存进行承诺，并为子集上的Map/Reduce运算生成紧凑的证明。当子集或内存发生变化时，证明可以被有效地更新。

文章还介绍了Reckle树和Reckle+树在动态摘要转换和可更新BLS聚合两个具体应用中的实现与评估。在动态摘要转换中，系统维护着两种不同哈希函数计算的梅克尔摘要等价性的证明。在可更新BLS聚合中，系统维护着对一组BLS密钥集合中子集的正确聚合证明。

实验结果表明，与现有方法相比，Reckle树和Reckle+树在更新时间和验证时间上表现出显著优势，提高了应用效率，降低了成本。同时，它们在聚合性能方面也具有竞争力。 <div>
We propose Reckle trees, a new vector commitment based on succinct RECursive arguments and MerKLE trees. Reckle trees' distinguishing feature is their support for succinct batch proofs that are updatable - enabling new applications in the blockchain setting where a proof needs to be computed and efficiently maintained over a moving stream of blocks. Our technical approach is based on embedding the computation of the batch hash inside the recursive Merkle verification via a hash-based accumulator called canonical hashing. Due to this embedding, our batch proofs can be updated in logarithmic time, whenever a Merkle leaf (belonging to the batch or not) changes, by maintaining a data structure that stores previously-computed recursive proofs. Assuming enough parallelism, our batch proofs are also computable in $O(\log n)$ parallel time - independent of the size of the batch. As a natural extension of Reckle trees, we also introduce Reckle+ trees. Reckle+ trees provide updatable and succinct proofs for certain types of Map/Reduce computations. In this setting, a prover can commit to a memory $\mathsf{M}$ and produce a succinct proof for a Map/Reduce computation over a subset $I$ of $\mathsf{M}$. The proof can be efficiently updated whenever $I$ or $\mathsf{M}$ changes.

We present and experimentally evaluate two applications of Reckle+ trees, dynamic digest translation and updatable BLS aggregation. In dynamic digest translation we are maintaining a proof of equivalence between Merkle digests computed with different hash functions, e.g., one with a SNARK-friendly Poseidon and the other with a SNARK-unfriendly Keccak. In updatable BLS aggregation we maintain a proof for the correct aggregation of a $t$-aggregate BLS key, derived from a $t$-subset of a Merkle-committed set of individual BLS keys. Our evaluation using Plonky2 shows that Reckle trees and Reckle+ trees have small memory footprint, significantly outperform previous approaches in terms of updates ($10\times$ to $15\times$) and verification  ($4.78\times$ to $1485\times$) time, enable applications that were not possible before due to huge costs involved (Reckle trees are up to 200 times faster), and have similar aggregation performance with previous implementations of batch proofs.
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 19:01:01 +0000</pubDate>
</item>
<item>
<title>Nebula: Efficient read-write memory and switchboard circuits for folding schemes</title>
<link>https://eprint.iacr.org/2024/1605</link>
<guid>https://eprint.iacr.org/2024/1605</guid>
<content:encoded><![CDATA[
<div> 关键词：Folding schemes、增量验证计算（IVC）、承诺携带、高效读写内存、开关板电路构造

总结:
文章主要探讨了通过使用新的技术方法来优化基于折叠方案的增量验证计算（Incrementally Verifiable Computation, IVC）的性能，特别是针对长时间运行的机器执行场景，如zkVMs（零知识虚拟机）。文章提出的关键技术包括承诺携带IVC、高效读写内存和开关板电路构造。

1. **承诺携带IVC**：文章引入了一种名为“承诺携带”的增量验证计算机制，该机制允许证明者在不同步骤中提供非确定性建议，并通过证明携带增量承诺来确保其一致性。这种机制有助于提高证明效率和空间效率。

2. **高效读写内存**：结合承诺携带IVC，文章展示了如何实现高效读写内存，这不仅支持索引查找等操作，而且在成本方面与非递归论证具有相同的效率。这一改进对于处理复杂数据结构和频繁访问的数据尤为重要。

3. **开关板电路构造**：文章提出了一种新颖的“开关板”电路构建方法，通过将不同指令的电路组合在一起，并在执行过程中动态关闭未调用的电路元素和约束，实现了按需付费的证明者成本模型。这种方法能够显著降低证明系统的规模，从而加速证明生成过程。

4. **原型实现与性能评估**：为了验证这些理论和技术的有效性，文章实施了一个基于Nebula的zkVM原型，用于Ethereum虚拟机（EVM）。实验结果表明，与传统的内存检查技术相比，Nebula技术能显著减少约束系统的规模，并使标准ERC20代币转账交易的证明生成速度提升至约260倍。

5. **整体贡献**：综上所述，文章通过提出和实施承诺携带IVC、高效读写内存和开关板电路构造等创新技术，显著提高了基于折叠方案的增量验证计算的性能，特别是在处理大规模和长时间运行的机器执行任务时。这些改进不仅优化了证明系统的效率和成本，还为zkVMs等零知识证明应用提供了更强大的支持。 <div>
Folding schemes enable prover-efficient incrementally verifiable computation (IVC), where a proof is generated step-by-step, resulting in a space-efficient prover that naturally supports continuations. These attributes make them a promising choice for proving long-running machine executions (popularly, "zkVMs"). A major problem is designing an efficient read-write memory. Another challenge is overheads incurred by unused machine instructions when incrementally proving a program execution step.

Nebula addresses these with new techniques that can paired with modern folding schemes. First, we introduce commitment-carrying IVC, where a proof carries an incremental commitment to the prover’s non-deterministic advice provided at different steps. Second, we show how this unlocks efficient read-write memory (which implies indexed lookups) with a cost-profile identical to that of non-recursive arguments. Third, we provide a new universal "switchboard" circuit construction that combines circuits of different instructions such that one can "turn off" uninvoked circuit elements and constraints, offering a new way to achieve pay-per-use prover costs.

We implement a prototype of a Nebula-based zkVM for the Ethereum virtual machine (EVM). We find that Nebula’s techniques qualitatively provide a $30\times$ smaller constraint system to represent the EVM over standard memory-checking techniques, and lead to over $260\times$ faster proof generation for the standard ERC20 token transfer transaction.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 00:36:09 +0000</pubDate>
</item>
<item>
<title>Stateful Communication with Malicious Parties</title>
<link>https://eprint.iacr.org/2024/1593</link>
<guid>https://eprint.iacr.org/2024/1593</guid>
<content:encoded><![CDATA[
<div> 关键词：Chat Sessions、模块化抽象、状态化群通信、安全保证、UatChat

总结:

文章主要介绍了一种名为“Chat Sessions”的模块化抽象模型，用于实现状态化的群通信。这种模型能够提供全异步环境下的安全性保障，无需假设任何参与方的诚实性。其核心在于通过参数化的权限策略来定义不同参与者在特定聊天状态下的操作权利。

Chat Sessions模型具备高度的模块性，能够方便地扩展以涵盖诸如消息的真实性、机密性、匿名性以及离线记录等额外的安全需求。作者展示了如何利用Maurer等人提出的Multi-Designated Receiver Public Key Encryption方案构建具有上述所有安全特性的通信通道。

基于Chat Sessions模型和上述安全通道，作者进一步开发了名为UatChat的即时通讯应用。UatChat不仅继承了上述所有安全特性，还实现了全新的“离线记录”功能，使得用户可以否认发送的消息，甚至否认自己参与过某次聊天，从而提供了首个完全意义上的离线记录（Off-The-Record）即时通讯应用。这一创新为用户隐私保护带来了革命性的提升，同时体现了Chat Sessions模型的灵活性和实用性。 <div>
Cryptography's most common use is secure communication---e.g. Alice can use encryption to hide the contents of the messages she sends to Bob (confidentiality) and can use signatures to assure Bob she sent these messages (authenticity). While one typically considers stateless security guarantees---for example a channel that Alice can use to send messages securely to Bob---one can also consider stateful ones---e.g. an interactive conversation between Alice, Bob and their friends where participation is dynamic: new parties can join the conversation and existing ones can leave. A natural application of such stateful guarantees are messengers.

We introduce a modular abstraction for stateful group communication, called Chat Sessions, which captures security guarantees that are achievable in fully asynchronous settings when one makes no party-honesty assumptions: anyone (including group members themselves) can be fully dishonest. Our abstraction is parameterized by (and enforces) a permissions policy that defines what operations parties have the right to perform in a given chat state. We show how to construct, use and extend Chat Sessions.

Our construction is fully decentralized (in particular, it need not a delivery service), does not incur additional interaction between chat participants (other than what is inherent from chat operations like sending a message) and liveness depends solely on messages being delivered.

A key feature of Chat Sessions is modularity: we extend Chat Sessions to capture authenticity, confidentiality, anonymity and off-the-record, and show our construction provides these guarantees if the underlying communication channels do too. We complement this by proving Maurer et al.'s Multi-Designated Receiver Public Key Encryption scheme (Eurocrypt '22) constructs matching communication channels (i.e. with all these guarantees).

We use Chat Sessions to construct UatChat: a simple and equally modular messaging application. Since UatChat preserves each of the guarantees mentioned above, this means we give the first fully Off-The-Record messaging application: parties can plausibly deny not only having sent any messages but even of being aware of a chat's existence.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 10:20:30 +0000</pubDate>
</item>
<item>
<title>DART: Distributed argument of knowledge for rough terrains</title>
<link>https://eprint.iacr.org/2024/1592</link>
<guid>https://eprint.iacr.org/2024/1592</guid>
<content:encoded><![CDATA[
<div> 关键词：KZG、Snark、Cocks-Pinch、Brezing-Weng、pairing-friendly曲线

文章主要介绍了使用KZG（KZG多值承诺方案）为基础的全分布式零知识证明系统，该系统适用于任何具有足够大标量域的配对友好曲线。特别地，此证明系统与Cocks-Pinch或Brezing-Weng外曲线兼容，如secp256k1, ED25519, BLS12-381和BN254等广泛使用的曲线。

文章提到，通过使用双变量KZG多项式承诺方案，可以实现线性于电路大小的通用可更新共通参考系(CRS)，使得证明系统的规模、验证时间和通信复杂度保持常数。对于特定的曲线（如Ed25519），当使用9位配对友好外曲线时，证明的大小为5KB，每台工作节点的通信复杂度也是5KB，主节点的通信复杂度同样为每台机器5KB。

对于电路大小为T·M的电路在M台机器上的有效验证时间，公式为O(T·log(T)+M·log(M))。每台验证器机器的工作主要由长度为T的G1组的MSMs（复数乘法序列）主导，以及通过多模快速傅里叶变换计算的单个多变元多项式产品的求和。主节点的工作则主要由长度为M的G1组的MSMs和通过多模快速傅里叶变换计算的单个多变元多项式产品的求和主导。

总结:
本文提出了一种基于KZG的全分布式零知识证明系统，该系统适用于各种配对友好曲线，包括Cocks-Pinch和Brezing-Weng外曲线，如secp256k1, ED25519, BLS12-381和BN254。通过使用双变量KZG多项式承诺方案，实现了线性于电路大小的通用可更新共通参考系，保证了证明系统的规模、验证时间和通信复杂度保持常数。对于特定曲线（如Ed25519），在使用9位配对友好外曲线时，证明的大小为5KB，每台工作节点的通信复杂度也是5KB，主节点的通信复杂度为每台机器5KB。同时，详细描述了验证时间、每台验证器机器和主节点的工作流程，显示了该系统的高效性和可扩展性。 <div>
We describe a fully distributed KZG-based Snark instantiable with any pairing-friendly curve with a sufficiently large scalar field. In particular, the proof system is compatible with Cocks-Pinch
or Brezing-Weng outer curves to the the widely used curves such as secp256k1, ED25519, BLS12-381 and BN254.

This allows us to retain the fully parallelizable nature and the O(1) communication complexity of Pianist ([LXZ+23]) in conjunction with circumventing the huge overhead of non-native arithmetic for
prominent use cases such as scalar multiplications and/or pairings for Bitcoin (secp256k1), Cosmos (Ed25519) and Ethereum PoS (BLS12-381) signatures.

As in [LXZ+23], we use a bivariate KZG polynomial commitment scheme, which entails a universal updatable CRS linear in the circuit size. The proof size is constant, as are the verification time -
dominated by three pairings - and the communication complexity between the Prover machines. With a 9-limb pairing-friendly outer curve to Ed25519, the proof size is 5 KB. With the same curve, the communication complexity for each worker node is 5 KB and that of the master node is 5 KB per machine.

The effective Prover time for a circuit of size T ·M on M machines is O(T · log(T)+M · log(M)). The work of each Prover machine is dominated by the MSMs of length T in the group G1 and a single sum of univariate polynomial products computed via multimodular FFTs1 of size 2T. Likewise, the work of the master node is dominated by the MSMs of length M in the group G1 and a single sum of univariate polynomial products via multimodular FFTs of size 2M.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 09:29:20 +0000</pubDate>
</item>
<item>
<title>Mutable Batch Arguments and Applications</title>
<link>https://eprint.iacr.org/2024/737</link>
<guid>https://eprint.iacr.org/2024/737</guid>
<content:encoded><![CDATA[
<div> 关键词: 可变批参数、可变批论证系统、强隐私概念、实用应用、标准假设

总结:

本文提出了一种新型的批参数（BARG）概念——可变批参数（mutable BARGs），旨在重新思考和使用BARG的方式。传统上，BARG证明π是一个不可变的原始见证ω1到ωk的编码。而可变BARG系统则将每个证明字符串π视为原始见证的可变编码，关注于对证明的可变性操作。

研究了可变BARG的强隐私概念，旨在隐藏所有非显而易见的见证信息。这种可变BARG非常适合许多敏感隐私的应用场景。主要贡献包括引入可变BARG的概念，识别可行的可变类，设计满足不同能力的可变BARG构造，以及从标准加密假设出发设计新的构造，从而在多种高级签名（同态/可删除/聚合签名）中启用新应用。这些成果显著提升了当前已知的签名系统状态。

具体而言，本文提供了首个基于标准假设的多密钥同态签名，其签名简洁；首次实现了真正紧凑的可删除签名，预/后删除签名保持固定大小；首次从标准假设出发提供了满足消息隐私的本地验证多签者聚合签名。这些贡献极大地推动了密码学领域，尤其是签名技术的发展。 <div>
We put forth a new concept of mutability for batch arguments (BARGs), called mutable batch arguments. Our goal is to re-envision how we think about and use BARGs. Traditionally, a BARG proof $\pi$ is an immutable encoding of $k$ $\mathbf{NP}$ witness $\omega_1, \ldots, \omega_{k}$. A mutable BARG system captures the notion of computations over BARGs, where each proof string $\pi$ is treated as a mutable encoding of original witnesses. We also study strong privacy notions for mutable BARGs, with the goal of hiding all non-trivial information about witnesses from a mutated proof. Such mutable BARGs are a naturally good fit for many privacy sensitive applications.

Our main contributions include introducing the concept of mutable BARGs, identifying non-trivial classes of feasible mutations, designing new constructions for mutable BARGs with varying capabilities satisfying mutation privacy from standard cryptographic assumptions, and enabling new applications to many advanced signatures (homomorphic/ redactable/ aggregate signatures). Our results improve state-of-the-art known for many signature systems. E.g., we provide the first multi-key homomorphic signature with succinct signatures from standard assumptions, and we provide the first truly compact redactable signature where pre/post-redaction signatures are of fixed size, and we provide the first locally verifiable multi-signer aggregate signature satisfying message privacy from standard assumptions.
]]></content:encoded>
<pubDate>Mon, 13 May 2024 19:45:35 +0000</pubDate>
</item>
<item>
<title>Matching radar signals and fingerprints with MPC</title>
<link>https://eprint.iacr.org/2024/1590</link>
<guid>https://eprint.iacr.org/2024/1590</guid>
<content:encoded><![CDATA[
<div> 关键词：Vessels、Navigation radar、Radar fingerprint、Secure multiparty computation、Information exchange agreement

总结:

本文主要讨论了通过雷达信号识别船只的技术及其背后的安全机制。船只可以通过其导航雷达被识别，这有助于建立情境意识，而无需暴露自身存在。各国维护着雷达指纹数据库，但出于国家安全考虑，不愿轻易共享这些信息。为了促进合作，正确的身份识别变得尤为重要。文中提出使用安全多方计算（Secure multiparty computation）技术，该技术可以匹配雷达信号测量与秘密数据库中的信息，并输出可能的匹配结果及其概率。此外，还提供了一个基于MP-SPDZ的演示实例，展示这一技术的应用。这种合作机制不仅能够提升海上航行的安全性，还能增强各国在信息安全方面的互信与协作。通过安全的多方计算，可以在不泄露敏感数据的情况下实现信息共享，为国际间的合作提供了新的可能。 <div>
Vessels can be recognised by their navigation radar due to the characteristics of the emitted radar signal. This is particularly useful if one wants to build situational awareness without revealing one's own presence. Most countries maintain databases of radar fingerprints but will not readily share these due to national security regulations. Sharing of such information will generally require some form of information exchange agreement.

However, all parties in a coalition benefit from correct identification. We use secure multiparty computation to match a radar signal measurement against secret databases and output plausible matches with their likelihoods. We also provide a demonstrator using MP-SPDZ.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 06:39:10 +0000</pubDate>
</item>
<item>
<title>A Note on ``Privacy-Preserving and Secure Cloud Computing: A Case of Large-Scale Nonlinear Programming''</title>
<link>https://eprint.iacr.org/2024/1588</link>
<guid>https://eprint.iacr.org/2024/1588</guid>
<content:encoded><![CDATA[
<div> 关键词：外包算法、线性约束、输出隐私、翻译变换、混合变换

<br />
<br />总结:

本文针对《IEEE Transactions on Cloud Computing》中2023年第11卷第1期，第484至498页的一篇文章进行了深入分析。文章指出，对于线性约束条件下的外包算法，其输出隐私可能无法得到保障，主要原因是简单翻译变换的存在。这种情况下，通过对手中数据进行处理，可以轻易地推断出原始数据的信息，从而破坏了隐私保护。

为解决这一问题，作者提出了一种补救方法——采用混合变换策略。该策略结合了传统的翻译变换和缩放变换，旨在增强数据处理过程中的隐私保护能力。通过这种混合变换，可以在不显著影响数据处理效果的前提下，有效地防止对原始数据信息的推断，从而实现更好的输出隐私保护。

综上所述，文章揭示了现有外包算法在处理线性约束问题时存在的隐私泄露风险，并提供了一种改进方案以增强算法的安全性和隐私保护性能。这不仅为相关研究提供了理论依据，也为实际应用中的数据安全与隐私保护提供了新的思路和方法。 <div>
We show that the outsourcing algorithm for the case of linear constraints  [IEEE Trans. Cloud Comput., 2023, 11(1), 484-498] cannot keep output privacy, due to the simple  translation transformation. We also suggest a remedy method by adopting a hybrid transformation which combines the usual  translation transformation and resizing transformation so as to protect the output privacy.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:24:43 +0000</pubDate>
</item>
<item>
<title>Efficient Pairing-Free Adaptable k-out-of-N Oblivious Transfer Protocols</title>
<link>https://eprint.iacr.org/2024/1583</link>
<guid>https://eprint.iacr.org/2024/1583</guid>
<content:encoded><![CDATA[
<div> 关键词：Oblivious Transfer、Efficient Two-Round、Pairing-Free、k-out-of-N、Standard Security

<br />
总结:

这篇论文介绍了三种基于最小通信模式的、无配对操作的、两轮k-out-of-N Oblivious Transfer（OT）协议，具有标准安全性。这些协议遵循接收方发送k条消息给发送方，后者响应n+k条消息的模式，实现了无配对操作的k-out-of-n OT方案中最低的数据传输量。此外，它们支持适应性，并允许发送方离线加密n条消息，无需依赖接收方的变量，特别适合于单发送者多接收者的场景。

论文提供的安全证明基于计算Diffie-Hellman（CDH）假设和RSA假设，无需随机预言机模型。这些协议通过结合最少通信轮数、适应性、离线加密能力以及可验证安全性，为需要高效OT的隐私保护应用提供了理想的解决方案。尤其对于资源受限设备而言，前两个提出的方案只需要一次操作，极大地提高了效率。 <div>
Oblivious Transfer (OT) is one of the fundamental building blocks in cryptography that enables various privacy-preserving applications. Constructing efficient OT schemes has been an active research area. This paper presents three efficient two-round pairing-free k-out-of-N oblivious transfer protocols with standard security. Our constructions follow the minimal communication pattern: the receiver sends k messages to the sender, who responds with n+k messages, achieving the lowest data transmission among pairing-free k-out-of-n OT schemes. Furthermore, our protocols support adaptivity and also, enable the sender to encrypt the n messages offline, independent of the receiver's variables, offering significant performance advantages in one-sender-multiple-receiver scenarios. We provide security proofs under the Computational Diffie-Hellman (CDH) and RSA assumptions, without relying on the Random Oracle Model. Our protocols combine minimal communication rounds, adaptivity, offline encryption capability, and provable security, making them well-suited for privacy-preserving applications requiring efficient oblivious transfer. Furthermore, the first two proposed schemes require only one operation, making them ideal for resource-constrained devices.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 14:01:27 +0000</pubDate>
</item>
<item>
<title>Re-visiting Authorized Private Set Intersection: A New Privacy-Preserving Variant and Two Protocols</title>
<link>https://eprint.iacr.org/2024/1579</link>
<guid>https://eprint.iacr.org/2024/1579</guid>
<content:encoded><![CDATA[
<div> 关键词：APSI、Partial-APSI、Bilinear Pairings、Parallelizability、Commodity Hardware

总结:

本文探讨了授权私密集合交集（APSI）问题以及其在生物基因匹配、广告转化和GDPR等隐私政策合规中的应用。APSI允许不信任的双方通过可信第三方裁判授权他们的项目，然后进行私密交集计算。为了解决这一问题，作者提出了两个基于双线性对的协议，均具有线性通信量。第一个协议实现了APSI功能，安全对抗恶意客户端，仅需一次在线阶段的通信。第二个协议则实现了Partial-APSI功能，适用于客户端可能恶意注入元素但遵循半诚实协议的情况。这两个协议均被证明是正确的并且具有安全性。实验结果显示，这些协议可以在普通硬件上高效运行，并且可以并行化执行，实验在50个核心的计算网格上进行了验证。

通过这两个协议，作者不仅解决了APSI和Partial-APSI的问题，而且展示了其实现的高效性和可扩展性，为实际应用提供了有力的支持。特别是对于需要处理大量数据和高并发请求的场景，如在线广告和生物信息分析，这些协议提供了安全、高效且易于扩展的解决方案。 <div>
We revisit the problem of Authorized Private Set Intersection (APSI), which allows mutually untrusting parties to authorize their items using a trusted third-party judge before privately computing the intersection. We also initiate the study of Partial-APSI, a novel privacy-preserving generalization of APSI in which the client only reveals a subset of their items to a third-party semi-honest judge for authorization. Partial-APSI allows for partial verification of the set, preserving the privacy of the party whose items are being verified. Both APSI and Partial-APSI have a number of applications, including genome matching, ad conversion, and compliance with privacy policies such as the GDPR.
    
We present two protocols based on bilinear pairings with linear communication. The first realizes the APSI functionality, is secure against a malicious client, and requires only one round of communication during the online phase. Our second protocol realizes the Partial-APSI functionality and is secure against a client that may maliciously inject elements into its input set, but who follows the protocol semi-honestly otherwise. We formally prove correctness and security of these protocols and provide an experimental evaluation to demonstrate their practicality. Our protocols can be efficiently run on commodity hardware. We also show that our protocols are massively parallelizable by running our experiments on a compute grid across 50 cores.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 08:24:25 +0000</pubDate>
</item>
<item>
<title>Efficiently-Thresholdizable Selective Batched Identity Based Encryption, with Applications</title>
<link>https://eprint.iacr.org/2024/1575</link>
<guid>https://eprint.iacr.org/2024/1575</guid>
<content:encoded><![CDATA[
<div> 关键词：Selective Batched IBE、Thresholdized Version、Identity-Based Encryption、Blockchain、Decryption Key

总结:

本文提出了一种新的加密原语——选择性批处理身份基加密（Selective Batched IBE）及其阈值化版本。这种加密技术允许加密具有特定身份和批次标签的消息，其中批次标签可以代表区块链上的块编号。对于某个批次中任意子集的身份，该技术能够高效地发行一个单个解密密钥，用于解密所有包含在子集中身份的密文，同时保持不在子集中的密文的隐私。核心创新在于一种能够在不使用任何秘密知识的情况下对任意子集身份进行公共聚合的新技术，生成一个精简摘要。这个摘要被用来通过主密钥来推导一个适用于该批次中所有身份的单个精简解密密钥。在阈值系统中，主密钥被分散为多个权威机构的秘密共享，这种方法显著降低了这些机构在密钥发行过程中的通信（有时还有计算）开销。

具体实例基于Kate等人在Asiacrypt'10提出的KZG多项式承诺方案和Boneh等人在Asiacrypt'01修改后的BLS签名方案构建。构造在通用群模型下证明了安全性。

在区块链背景下，该新构造可用于实现交易池隐私，通过将交易加密到区块中，仅公开包含在特定区块中的交易并隐藏未包含的交易。阈值化版本允许多个权威（验证者）协作管理解密过程。其他可能的应用包括基于区块链的欺诈多数MPC公平性支持的可扩展性增强，以及条件批量阈值解密，可用于实现安全的荷兰拍卖和隐私保护期权交易。 <div>
We propose a new cryptographic primitive called ``selective batched identity-based encryption'' (Selective Batched IBE) and its thresholdized version. The new primitive allows encrypting messages with specific identities and batch labels, where the latter can represent, for example, a block number on a blockchain. Given an arbitrary subset of identities for a particular batch, our primitive enables efficient issuance of a single decryption key that can be used to decrypt all ciphertexts having identities that are included in the subset while preserving the privacy of all ciphertexts having identities that are excluded from the subset. At the heart of our construction is a new technique that enables public aggregation (i.e. without knowledge of any secrets) of any subset of identities, into a succinct digest. This digest is used to derive, via a master secret key, a single succinct decryption key for all the identities that were digested in this batch. In a threshold system, where the master key is distributed as secret shares among multiple authorities, our method significantly reduces the communication (and in some cases, computation) overhead for the authorities. It achieves this by making their costs for key issuance independent of the batch size.

We present a concrete instantiation of a Selective Batched IBE scheme based on the KZG polynomial commitment scheme by Kate et al. (Asiacrypt'10) and a modified form of the BLS signature scheme by Boneh et al. (Asiacrypt'01). The construction is proven secure in the generic group model (GGM).

In a blockchain setting, the new construction can be used for achieving mempool privacy by encrypting transactions to a block, opening only the transactions included in a given block and hiding the transactions that are not included in it.  With the thresholdized version,  multiple authorities (validators) can collaboratively manage the decryption process.  Other possible applications include scalable support via blockchain for fairness of dishonest majority MPC, and conditional batched threshold decryption that can be used for implementing secure Dutch auctions and privacy preserving options trading.
]]></content:encoded>
<pubDate>Sun, 06 Oct 2024 10:19:44 +0000</pubDate>
</item>
<item>
<title>OML: Open, Monetizable, and Loyal AI</title>
<link>https://eprint.iacr.org/2024/1573</link>
<guid>https://eprint.iacr.org/2024/1573</guid>
<content:encoded><![CDATA[
<div> 关键词：AI, OML, 区块链, AI-原生加密, 模型指纹识别

<br />
总结:

本文提出了一种名为OML（Open, Monetizable, Loyal AI）的全新AI开发框架，旨在打破当前AI领域由少数大型组织和个体垄断的局面。OML通过结合AI、区块链和密码学等跨学科方法，为AI的开放性、可盈利性和忠诚度提供了解决方案。关键创新在于引入了AI-原生加密这一新兴领域，该领域利用定制化的密码技术来适应AI数据的连续性和低维特性，以提升近似性能。

OML的核心概念是模型指纹识别，这是一种新颖的AI-原生加密工具，用于保护AI模型的完整性和所有权。通过区块链技术，OML实现了一个去中心化、透明的AI开发平台，让社区成员能够贡献、盈利并拥有自己的AI模型。这一创新性框架旨在建立一个更加包容的AI生态系统，通过分散控制权和确保透明度，克服当前AI部署中集中化和缺乏公开监督的问题。

通过实施OML 1.0系统，作者证明了AI-原生加密技术的实际可行性，并分析了其安全性和有效性。此系统不仅提供了保护AI模型免受攻击的手段，还促进了AI开发过程中的开放合作与资源共享，从而推动了更广泛的AI创新和发展。 <div>
Artificial Intelligence (AI) has steadily improved across a wide range of tasks, and a significant breakthrough towards general intelligence was achieved with the rise of generative deep models, which have garnered worldwide attention. However, the development and deployment of AI are almost entirely controlled by a few powerful organizations and individuals who are racing to create Artificial General Intelligence (AGI). These centralized entities make decisions with little public oversight, shaping the future of humanity, often with unforeseen consequences.
In this paper, we propose OML, which stands for Open, Monetizable, and Loyal AI, an approach designed to democratize AI development and shift control away from these monopolistic actors. OML is realized through an interdisciplinary framework spanning AI, blockchain, and cryptography. We present several ideas for constructing OML systems using technologies such as Trusted Execution Environments (TEE), traditional cryptographic primitives like fully homomorphic encryption and functional encryption, obfuscation, and AI-native solutions rooted in the sample complexity and intrinsic hardness of AI tasks.
A key innovation of our work is the introduction of a new scientific field: AI-native cryptography, which leverages cryptographic primitives tailored to AI applications. Unlike conventional cryptography, which focuses on discrete data and binary security guarantees, AI-native cryptography exploits the continuous nature of AI data representations and their low-dimensional manifolds, focusing on improving approximate performance. One core idea is to transform AI attack methods, such as data poisoning, into security tools. This novel approach serves as a foundation for OML 1.0, an implemented system that demonstrates the practical viability of AI-native cryptographic techniques. At the heart of OML 1.0 is the concept of model fingerprinting, a novel AI-native cryptographic primitive that helps protect the integrity and ownership of AI models.
The spirit of OML is to establish a decentralized, open, and transparent platform for AI development, enabling the community to contribute, monetize, and take ownership of AI models. By decentralizing control and ensuring transparency through blockchain technology, OML prevents the concentration of power and provides accountability in AI development that has not been possible before.
To the best of our knowledge, this paper is the first to:
•  Identify the monopolization and lack of transparency challenges in AI deployment today and formulate the challenge as OML (Open, Monetizable, Loyal).
•  Provide an interdisciplinary approach to solving the OML challenge,  incorporating ideas from AI, blockchain, and cryptography.
•  Introduce and formally define the new scientific field of AI-native cryptography.
•  Develop novel AI-native cryptographic primitives and implement them in OML 1.0, analyzing their security and effectiveness.
•  Leverage blockchain technology to host OML solutions, ensuring transparency, decentralization, and alignment with the goals of democratized AI development.
Through OML, we aim to provide a decentralized framework for AI development that prioritizes open collaboration, ownership rights, and transparency, ultimately fostering a more inclusive AI ecosystem.
]]></content:encoded>
<pubDate>Sat, 05 Oct 2024 22:50:01 +0000</pubDate>
</item>
<item>
<title>Efficient Secure Multiparty Computation for Multidimensional Arithmetics and Its Application in Privacy-Preserving Biometric Identification</title>
<link>https://eprint.iacr.org/2023/1863</link>
<guid>https://eprint.iacr.org/2023/1863</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、高效运算、张量三元组、生物识别、机器学习

<br /><br />
总结:
本文探讨了在多党计算（MPC）的发展中，为了提高多维MPC协议的效率，引入了一种新的相关性概念——“张量三元组”。张量三元组的设计旨在优化涉及向量元素数据集的MPC协议，如隐私保护生物识别和隐私保护机器学习。文章详细阐述了张量三元组的生成过程、使用方法及其应用范围。研究显示，该技术能够显著加速诸如FingerCode、Eigenfaces和FaceNet等隐私保护生物识别协议，其加速效果超过1000倍，尽管需要一定的预处理成本。

文章首先介绍了张量三元组的概念及其在多维MPC中的作用，强调了其对于提升生物识别和机器学习等场景下数据处理效率的关键性。随后，详细解释了张量三元组如何通过优化数据交互和计算流程，实现对MPC协议性能的显著增强。最后，通过具体案例分析，展示了张量三元组在实际应用中的效果，特别是其在隐私保护生物识别领域的应用，证实了其能有效提升协议执行速度，同时保持合理的时间成本投入。 <div>
Over years of the development of secure multi-party computation (MPC), many sophisticated functionalities have been made pratical and multi-dimensional operations occur more and more frequently in MPC protocols, especially in protocols involving datasets of vector elements, such as privacy-preserving biometric identification and privacy-preserving machine learning. In this paper, we introduce a new kind of correlation, called tensor triples, which is designed to make multi-dimensional MPC protocols more efficient. We will discuss the generation process, the usage, as well as the applications of tensor triples and show that it can accelerate privacy-preserving biometric identification protocols, such as FingerCode, Eigenfaces and FaceNet, by more than 1000 times, with reasonable offline costs.
]]></content:encoded>
<pubDate>Tue, 05 Dec 2023 06:49:23 +0000</pubDate>
</item>
<item>
<title>Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing</title>
<link>https://eprint.iacr.org/2023/1773</link>
<guid>https://eprint.iacr.org/2023/1773</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式密钥生成、DLog基密码系统、适应性安全、区块链、广播通道

总结:

本文提出了一种面向DLog基密码系统的实用分布式密钥生成（DKG）协议，旨在解决大型分布式部署中的计算和通信开销问题。该协议利用“共同硬币”机制和一系列针对适应性安全的策略，使得即使在最多存在拜占庭节点的情况下，每个节点的计算和通信成本也能保持线性或接近线性。此外，该协议确保了当超过半数节点被适配性攻击者控制时，系统依然能够维持安全性。

文章还引入了一种通用转换器，用于在参与者具有不同权重的情况下高效部署传统分布式协议，如上述DKG。通过结合区块链和数据分散网络（如IPFS）构建的扩展广播通道，实现了任意大小消息的可靠广播，同时仅需常量大小的区块链存储空间。

该DKG协议的应用实例为Filecoin的检查点机制提供了基础，允许所有验证者定期执行DKG和阈值签名来创建比特币上的检查点，从而增强PoS区块链的安全性。与最近的检查点方法Babylon相比，本文提出的方案在比特币交易费用成本上有着显著优势，对于2^12个验证者的场景，其成本仅为Babylon方法的0.4%。 <div>
The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy computation and communication (particularly broadcast) overhead in their adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. This group is randomly sampled and consists of a small number of individuals. The population only trusts that at least one member in the group is honest, without knowing which one. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights. Additionally, we introduce an extended broadcast channel based on a blockchain and data dispersal network (such as IPFS), enabling reliable broadcasting of arbitrary-size messages at the cost of constant-size blockchain storage. 

Our DKG leads to a fully practical instantiation of Filecoin's checkpointing mechanism, in which all validators of a Proof-of-Stake (PoS) blockchain periodically run DKG and threshold signing to create checkpoints on Bitcoin, to enhance the security of the PoS chain. In comparison with the recent checkpointing approach of Babylon (Oakland, 2023), ours enjoys a significantly smaller cost of Bitcoin transaction fees. For $2^{12}$ validators,  our cost is merely 0.4\% of that incurred by Babylon's approach.
]]></content:encoded>
<pubDate>Thu, 16 Nov 2023 01:44:04 +0000</pubDate>
</item>
<item>
<title>Distributed Randomness using Weighted VUFs</title>
<link>https://eprint.iacr.org/2024/198</link>
<guid>https://eprint.iacr.org/2024/198</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、随机性、拜占庭容错、权益证明、可验证不可预测函数

总结:
本文探讨了区块链中内置随机性的方法，尤其是针对基于权益证明的拜占庭容错系统。研究提出了一种称为“链上”随机性的设计思路，即让区块链验证者在每块区块生成共享随机性。这一设计依赖于一种加权可验证不可预测函数（VUF），其显著特点是计算和通信成本与参与者权重无关，这对于频繁快速评估链上随机性至关重要。

为了实现这一目标，文章还设计了一个新的可公开验证的秘密分享方案（PVSS），具有可聚合的传输特性，并基于此设计了一个分布式密钥生成（DKG）协议，用于构建VUF。这些方案被实现在生产部署的Aptos区块链上，并通过112个验证者进行端到端评估，总权重达到4053。实验结果显示，引入随机性协议仅增加了133毫秒的延迟，相比无随机性的情况。此外，研究还通过与基线方法的详细比较，展示了设计性能上的显著提升。

通过上述创新，文章旨在增强区块链对随机化应用的支持，并提高其安全性，同时减少对外部随机性源的依赖，从而提升系统的整体可靠性和效率。 <div>
Shared randomness in blockchain can expand its support for randomized applications and can also help strengthen its security. Many existing blockchains rely on external randomness beacons for shared randomness, but this approach reduces fault tolerance, increases latency, and complicates application development. An alternate approach is to let the blockchain validators generate fresh shared randomness themselves once for every block. We refer to such a design as the \emph{on-chain} randomness. 

In this paper, we design an efficient on-chain randomness protocol for Byzantine fault-tolerance based Proof-of-Stake blockchains with weighted validators. A key component of our protocol is a weighted verifiable unpredictable function (VUF). The notable feature of our weighted VUF is that the computation and communication costs of parties are independent of their weight. This is crucial for scalability of on-chain randomness where we repeatedly evaluate the weighted VUF in quick succession. We also design a new scalable publicly verifiable secret sharing~(PVSS) scheme with aggregatable transcript and use it to design a distributed key generation~(DKG) protocol for our VUF. We implemented our schemes on top of Aptos, a proof-of-stake blockchain deployed in production, conducted an end-to-end evaluation with 112 validators and a total weight of up to 4053. In this setup, our on-chain randomness protocol adds only 133 milliseconds of latency compared to a protocol without randomness. We also demonstrate the performance improvements of our design through rigorous comparison with baseline methods.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 15:48:28 +0000</pubDate>
</item>
<item>
<title>PAC-Private Algorithms</title>
<link>https://eprint.iacr.org/2024/718</link>
<guid>https://eprint.iacr.org/2024/718</guid>
<content:encoded><![CDATA[
<div> 关键词：PAC隐私、算法证明、黑盒算法、模拟算法、稳定性验证

总结:

本文研究了如何利用“可能接近正确（PAC）隐私”理论，为一系列实际应用中的黑盒算法——如K均值聚类、支持向量机（SVM）、主成分分析（PCA）和随机森林——提供形式化、机械化和基于模拟的隐私证明。研究中提出了一种新的模拟算法，用于高效地确定任何给定隐私水平所需的各向异性噪声扰动，并证明了该算法的正确性。该算法显示了与等效的各向同性噪声相比，各向异性噪声在提高隐私保护方面具有实质性优势。

文章还展示了稳定算法更容易实现隐私保护，并通过引入正则化技术，实现了较小的准确性损失下的有意义的隐私保证。为了减少算法输出的不稳定性并简化几何稳定性的验证，文章提出了新的技术，将难以处理的几何稳定性验证转化为高效的确定性稳定性验证。

最后，文章包括了详细的实验结果，验证了所提出的证明方法在对抗最先进的经验攻击方面的有效性，证明了算法在确保隐私的同时保持了良好的性能。 <div>
Provable privacy typically requires involved analysis and is often associated with unacceptable accuracy loss. While many empirical verification or approximation methods, such as Membership Inference Attacks (MIA) and Differential Privacy Auditing (DPA), have been proposed, these do not offer rigorous privacy guarantees. In this paper, we apply recently-proposed Probably Approximately Correct (PAC) Privacy to give formal, mechanized, simulation-based proofs for a range of practical, black-box algorithms: K-Means, Support Vector Machines (SVM), Principal Component Analysis (PCA) and Random Forests. To provide these proofs, we present a new simulation algorithm that efficiently determines anisotropic noise perturbation required for any given level of privacy. We provide a proof of correctness for this algorithm and demonstrate that anisotropic noise has substantive benefits over isotropic noise.

Stable algorithms are easier to privatize, and we demonstrate privacy amplification resulting from introducing regularization in these algorithms; meaningful privacy guarantees are obtained with small losses in accuracy. We propose new techniques in order to reduce instability in algorithmic output and convert intractable geometric stability verification into efficient deterministic stability verification. Thorough experiments are included, and we validate our provable adversarial inference hardness against state-of-the-art empirical attacks.
]]></content:encoded>
<pubDate>Fri, 10 May 2024 01:25:08 +0000</pubDate>
</item>
<item>
<title>Succinct Arguments over Towers of Binary Fields</title>
<link>https://eprint.iacr.org/2023/1784</link>
<guid>https://eprint.iacr.org/2023/1784</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARK、Brakedown、多线性多项式承诺方案、HyperPlonk、Lasso

总结:

本文提出了一种针对二进制域塔结构的高效SNARK（ Succinct Non-Interactive Argument of Knowledge）。该研究主要贡献在于构建了一个适用于小域上多项式的多线性多项式承诺方案，该方案无需嵌入开销即可处理小域多项式。此外，作者还引入了HyperPlonk和Lasso中产品检查和排列检查的二进制领域适应版本，以及Lasso中的查找检查的二进制领域版本。

文章进一步展示了其二进制PLONKish变体如何高效捕获标准哈希函数，如Keccak-256和Grøstl，为现代以太坊扩展努力提供关键的Keccak-256证明。通过详尽的性能基准测试，文章论证了所提出的方案能够有效生成这些关键的Keccak-256证明，对于实现以太坊的可扩展性具有重要意义。

通过改进的SNARK技术，本文为提升区块链平台性能，特别是以太坊的可扩展性和效率提供了新的途径，通过优化多项式承诺和哈希函数的表示，使得大规模数据验证成为可能。 <div>
We introduce an efficient SNARK for towers of binary fields. Adapting Brakedown (CRYPTO '23), we construct a multilinear polynomial commitment scheme suitable for polynomials over tiny fields, including that with just two elements. Our commitment scheme, unlike those of previous works, treats small-field polynomials with no embedding overhead. We further introduce binary-field adaptations of HyperPlonk (EUROCRYPT '23)'s product and permutation checks and of Lasso ('23)'s lookup. Our binary PLONKish variant captures standard hash functions—like Keccak-256 and Grøstl—extremely efficiently. With recourse to thorough performance benchmarks, we argue that our scheme can efficiently generate precisely those Keccak-256-proofs which critically underlie modern efforts to scale Ethereum.
]]></content:encoded>
<pubDate>Fri, 17 Nov 2023 21:58:26 +0000</pubDate>
</item>
<item>
<title>Fully Privacy-preserving Billing Models for Peer-to-Peer Electricity Trading Markets</title>
<link>https://eprint.iacr.org/2024/1562</link>
<guid>https://eprint.iacr.org/2024/1562</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、电量交易、完全同态加密、伪随机零共享、实时数据分析

<br /><br />
总结:
本文提出了一种全新的、全面隐私保护的计费协议，旨在为能源交易中的计费协议提供保护，同时保护用户敏感的消费和生产数据。该协议通过采用高级加密技术，如全同态加密（FHE）和伪随机零共享（PRZS），确保了数据的安全性和机密性，即使在电力供应和需求波动时也能准确处理。实验证明，该模型能够以0.17秒的速度对100户家庭进行实时数据分析并计算个人账单，同时保证了隐私性，不暴露任何敏感信息给交易平台或计费服务器。这一创新解决方案不仅提高了能源交易的效率和准确性，还确保了用户数据的私密性。 <div>
Peer-to-peer energy trading markets enable users to exchange electricity, directly offering them increased financial benefits. However, discrepancies often arise between the electricity volumes committed to in trading auctions and the volumes actually consumed or injected. Solutions designed to address this issue often require access to sensitive information that should be kept private.  

This paper presents a novel, fully privacy-preserving billing protocol designed to protect users' sensitive consumption and production data in the context of billing protocols for energy trading. Leveraging advanced cryptographic techniques, including fully homomorphic encryption (FHE) and pseudorandom zero sharing (PRZS), our protocol ensures robust security and confidentiality while addressing the critical issue of managing discrepancies between promised and actual electricity volumes. The proposed protocol guarantees that users' sensitive information remains inaccessible to external parties, including the trading platform and billing server. By utilizing FHE, the protocol allows computations on encrypted data without compromising privacy, while PRZS ensures secure aggregation of individual discrepancies of each household. This combination of cryptographic primitives maintains data privacy and enhances billing accuracy, even when fluctuations in energy supply and demand occur.

We analyze real-time consumption and production data from 100 households to experimentally validate the effectiveness and efficiency of our billing model. By implementing a flexible framework compatible with any billing method, we demonstrate that our protocol can accurately compute individual bills for 100 households in approximately 0.17 seconds.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 12:41:01 +0000</pubDate>
</item>
<item>
<title>FLUENT: A Tool for Efficient Mixed-Protocol Semi-Private Function Evaluation</title>
<link>https://eprint.iacr.org/2024/1561</link>
<guid>https://eprint.iacr.org/2024/1561</guid>
<content:encoded><![CDATA[
<div> 关键词：Semi-Private Function Evaluation（SPFE）、High-Level Synthesis（HLS）、Performance Overhead、Open-Source Project、Practical Deployment

总结:本文提出了一种新型框架，旨在使非专家能够理解和实施Semi-Private Function Evaluation（SPFE），并为实际部署提供可行解决方案。该框架通过引入高阶综合（HLS）来优化开发者体验，使得工具更易于使用，相较于先前的技术，其性能提升达到了两倍之多，得益于更高效的底层构建和对查找表（LUTs）的利用。为了评估性能，文章从通信和运行时效率两个方面进行了深入分析。最后，整个实现作为开源项目发布，旨在缩小高级加密协议与工业场景实践应用之间的差距，推动SPFE技术在实际业务中的普及与应用。 <div>
In modern business to customer interactions, handling private or confidential data is essential. Private Function Evaluation (PFE) protocols ensure the privacy of both the customers' input data and the business' function evaluated on it which is often sensitive intellectual property (IP). However, fully hiding the function in PFE results in high performance overhead. Semi-Private Function Evaluation (SPFE) is a generalization of PFE to only partially hide the function, whereas specific non-critical components remain public. Our paper introduces a novel framework designed to make SPFE accessible to non-experts and practical for real-world deployments.

To achieve this, we improve on previous SPFE solutions in two aspects. 
First, we enhance the developer experience by leveraging High-Level Synthesis (HLS), making our tool more user-friendly than previous SPFE frameworks.
Second, we achieve a \(2 \times\) speedup compared to the previous state-of-the-art through more efficient underlying constructions and the usage of Lookup Tables (LUTs).

We evaluate the performance of our framework in terms of communication and runtime efficiency. Our final implementation is available as an open-source project, aiming to bridge the gap between advanced cryptographic protocols and their practical application in industry scenarios.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 12:29:16 +0000</pubDate>
</item>
<item>
<title>Understanding Leakage in Searchable Encryption: a Quantitative Approach</title>
<link>https://eprint.iacr.org/2024/1558</link>
<guid>https://eprint.iacr.org/2024/1558</guid>
<content:encoded><![CDATA[
<div> 关键词：搜索加密、结构化加密、标准安全性、定量信息流、q-泄漏分析

总结:

本文提出了一种新型框架来量化泄漏，称之为q-泄漏分析。这一方法受到定量信息流启发，旨在评估搜索加密和结构化加密方案中的信息泄露程度。q-泄漏分析与标准安全性有着密切关联，通过此方法可以更精确地理解加密数据和查询的泄露情况。

文章指出，尽管存在不可避免的信息泄露，但一些看似无害的泄漏可能被攻击者利用，从而损害用户隐私并恢复其数据或查询，尽管这些加密方案在理论上被认为是安全的。然而，到目前为止，关于如何评估这种泄漏的研究相对较少。

为了解决这一问题，作者提出了q-泄漏分析方法，该方法能够对现有具有复杂泄漏函数的加密方案进行安全性分析。通过这种方法，可以更好地理解这些加密方案在实际应用中的安全性和隐私保护能力。

总的来说，本文通过引入q-泄漏分析框架，提供了一种新的途径来量化和评估搜索加密和结构化加密方案中的信息泄露风险，这对于加强加密系统的安全性、保护用户隐私具有重要意义。 <div>
Searchable encryption, or more generally, structured encryption, permits search over encrypted data. It is  an important cryptographic tool for securing cloud storage. The standard security notion for structured encryption mandates that a protocol leaks nothing about the data or queries, except for some allowed leakage, defined by the leakage function. This is due to the fact that some leakage  is unavoidable for efficient  schemes. Unfortunately, it was shown by numerous  works that even innocuous-looking leakage can often be exploited by attackers to undermine users' privacy and recover their queries and/or data, despite the structured encryption schemes being provably secure. Nevertheless, the standard security remains the go-to notion used to show the "security" of structured encryption schemes. While it is not likely that researchers will design practical structured encryption schemes with no leakage, it is not satisfactory that very few works study ways to assess leakage. This work proposes  a novel framework to quantify leakage. Our methodology is inspired by the quantitative information flow, and we call our method  $q$-leakage analysis. We show how $q$-leakage analysis is related to the standard security. We also demonstrate the usefulness of $q$-leakage analysis by analyzing the security of two existing schemes with complex leakage functions.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 18:46:39 +0000</pubDate>
</item>
<item>
<title>Private Laconic Oblivious Transfer with Preprocessing</title>
<link>https://eprint.iacr.org/2024/1555</link>
<guid>https://eprint.iacr.org/2024/1555</guid>
<content:encoded><![CDATA[
<div> 关键词：Laconic Cryptography、Laconic Oblivious Transfer、Preprocessing、Symmetric-key Assumptions、Online Computational Complexity

文章主要探讨了名为“Laconic Cryptography”的加密技术，该技术旨在通过两个消息协议在大量数据上进行安全计算，同时将通信成本降至最低。其中的核心概念是“Laconic Oblivious Transfer”，它允许接收方学习由选择位决定的消息，而发送方的输入包括两条消息和一个索引，这个模型在安全计算中更为实用。然而，现有的实现方法往往依赖于复杂的加密技术以及非黑盒技术，效率不高。

文章提出了一种基于对称密钥假设的私有Laconic OT（PLaOT）协议，其特点在于能够隐藏发送者的索引信息，并在预处理阶段生成所需的关联，后续的在线阶段则非常轻量级，接收方的在线计算复杂度呈亚线性增长。此外，该协议还具备可更新性和接收方隐私特性。

最后，作者展示了如何利用PLaOT协议实现RAM程序的Laconic函数评估与预处理的私有集合交集，这表明了Laconic Cryptography在实际应用中的潜力和效率提升。

总结: 这篇文章研究了一种新的加密技术Laconic Cryptography，特别关注于Laconic Oblivious Transfer的实现及其在实际应用中的潜力。通过基于对称密钥假设的方法，实现了高效、私有的Laconic OT协议，同时保持了在线阶段的计算效率，并引入了预处理功能。此外，该协议还具有可更新性和接收方隐私特性。文章还讨论了该协议在RAM程序评估和私有集合交集中的应用，展现了其在安全计算领域的广泛应用前景。 <div>
Laconic cryptography studies two-message protocols that securely compute on large amounts of data with minimal communication cost. Laconic oblivious transfer (OT) is a central primitive where the receiver's input is a large database $\mathsf{DB}$ and the sender's inputs are two messages $m_0$, $m_1$ along with an index $i$, such that the receiver learns the message determined by the choice bit $\mathsf{DB}_i$. OT becomes even more useful for secure computation when considering its laconic variants, which offer succinctness and round optimality. However, existing constructions are not practically efficient because they rely on heavy cryptographic machinery and non-black-box techniques. 

In this work, we initiate the study of laconic OT correlations, where the model allows an offline phase to generate the correlations later used in a lightweight online phase. Our correlation is conceptually simple, captured by an inner product computation, and enables us to achieve a private laconic OT protocol where the sender's index $i$ is also hidden from the receiver. Our construction is the first private laconic OT with database-dependent preprocessing based solely on symmetric-key assumptions, achieving sublinear online computational complexity for the receiver. Furthermore, we enhance our construction with updatability and receiver privacy. Finally, we demonstrate the applications of private laconic OT to laconic function evaluation for RAM programs and laconic private set intersection with preprocessing.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 17:07:53 +0000</pubDate>
</item>
<item>
<title>Application-Aware Approximate Homomorphic Encryption: Configuring FHE for Practical Use</title>
<link>https://eprint.iacr.org/2024/203</link>
<guid>https://eprint.iacr.org/2024/203</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、Cheon-Kim-Kim-Song（CKKS）方案、隐私保护机器学习、应用感知同态加密、安全性定义

总结：

文章主要讨论了全同态加密（FHE）中的一个具体实现——基于Cheon-Kim-Kim-Song（CKKS）方案的同态加密技术，特别是在处理实数和复数时的应用。该方案为许多隐私保护机器学习应用提供了高效计算能力。然而，随着Li和Micciancio在EUROCRYPT'21中发现的针对$IND-CPA^D$设置的秘密密钥恢复攻击，现有关于如何安全地为特定应用实例化该方案的理解变得模糊。

为了澄清这一混乱，文章引入了“应用感知同态加密”概念，并提出相关安全定义，这些定义更符合同态加密方案的实际实施和应用方式。同时，文章还制定了实施应用感知同态加密模型以达到$IND-CPA^D$安全性的指导原则，适用于CKKS的实际应用。此外，文章表明应用感知模型不仅适用于CKKS方案，还能用于安全、高效地实例化精确同态加密方案。

通过上述措施，文章旨在提供一个更为明确和实用的框架，以确保在实际应用中正确和安全地使用FHE技术，特别是在面对复杂的安全挑战时。 <div>
Fully Homomorphic Encryption (FHE) is a powerful tool for performing privacy-preserving analytics over encrypted data. A promising method for FHE over real and complex numbers is approximate homomorphic encryption, instantiated with the Cheon-Kim-Kim-Song (CKKS) scheme. The CKKS scheme enables efficient evaluation for many privacy-preserving machine learning applications. While the efficiency advantages of CKKS are clear, there is currently a lot of confusion on how to securely instantiate the scheme for any given application, especially after secret-key recovery attacks were discovered by Li and Micciancio (EUROCRYPT'21) for the $IND-CPA^D$ setting, i.e., where decryption results are shared with other parties. On the one hand, the generic definition of $IND-CPA^D$ is application-agnostic and often requires impractically large parameters. On the other hand, practical CKKS implementations target specific applications and use tighter parameters. A good illustration are the recent secret-key recovery attacks against a CKKS implementation in the OpenFHE library by Guo et al. (USENIX Security'24). These attacks misuse the library by employing different circuits during parameter estimation and run-time computation, yet they do not violate the generic (application-agnostic) $IND-CPA^D$ definition.

To address this confusion, we introduce the notion of application-aware homomorphic encryption and devise related security definitions, which correspond more closely to how homomorphic encryption schemes are implemented and used in practice. We then formulate the guidelines for implementing the application-aware homomorphic encryption model to achieve $IND-CPA^D$ security for practical applications of CKKS. We also show that our application-aware model can be used for secure, efficient instantiation of exact homomorphic encryption schemes.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 20:24:14 +0000</pubDate>
</item>
<item>
<title>Revisiting Keyed-Verification Anonymous Credentials</title>
<link>https://eprint.iacr.org/2024/1552</link>
<guid>https://eprint.iacr.org/2024/1552</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名认证、CMZ、BBDT、BBS RFC、非交互式证明

文章主要探讨了两种关键的匿名认证系统——Chase等人的CMZ（或PS MAC）和Barki等人的BBDT（或BBS MAC）。作者提出了一种方法使CMZ具有统计匿名性，并使BBDT与BBS RFC草案兼容。他们对这些系统的安全性进行了全面分析，包括更强的不可伪造性和匿名性的属性。这使得用户可以根据需要选择组合这些属性。

为了加速复杂证明的速度，文章中提供了一个编译器，该编译器使用交互式Oracle证明和指定验证者多项式承诺来构建指定验证者的非交互式论证。对于基于密钥验证的匿名认证，指定验证者证明就足够了，因为验证者的身份在预先已知。

文章还讨论了可能从这种方法受益的扩展，例如那些需要快速证明的复杂情况。

总结：
文章重新审视了两种主流的匿名认证系统，即CMZ（PS MAC）和BBDT（BBS MAC），并提出了使其更安全和兼容的技术改进。通过构建一个专门的编译器，提高了复杂证明的处理速度，同时确保了系统的匿名性和不可伪造性。这种方法不仅增强了原有系统的安全性，还提供了更多的灵活性，允许用户根据实际需求定制认证流程。此外，该技术还能应用于其他需要快速证明验证的情况，进一步扩大了其应用范围。 <div>
Keyed-verification anonymous credentials are widely recognized as among the most efficient tools for anonymous authentication. In this work, we revisit two prominent credential systems: the scheme by Chase et al. (CCS 2014), commonly referred to as CMZ or PS MAC, and the scheme by Barki et al. (SAC 2016), known as BBDT or BBS MAC. We show how to make CMZ statistically anonymous and BBDT compatible with the BBS RFC draft. We provide a comprehensive security analysis for strong(er) properties of unforgeability and anonymity. These properties allow them to be composed with extensions that users can pick and choose.  We show that simpler variants satisfying one-more unforgeability can still be anonymous tokens (Kreuter et al., CRYPTO 2020).

To enable faster proofs for complex presentations, we present a compiler that uses an interactive oracle proof and a designated-verifier polynomial commitment to construct a designated-verifier non-interactive argument. For keyed-verification anonymous credentials, designated-verifier proofs suffice since the verifier is known in advance. We explore extensions that could benefit from this approach.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 15:37:29 +0000</pubDate>
</item>
<item>
<title>PoUDR: Proof of Unified Data Retrieval in Decentralized Storage Networks</title>
<link>https://eprint.iacr.org/2024/1544</link>
<guid>https://eprint.iacr.org/2024/1544</guid>
<content:encoded><![CDATA[
<div> 关键词：IPFS、Filecoin、Proof of Unified Data Retrieval（PoUDR）、ZK-SNARK、Secure Swarming Data Exchange（SSDE）

总结:

本文探讨了去中心化存储网络中数据检索支付机制的缺失，并提出了解决方案——Proof of Unified Data Retrieval（PoUDR）协议。PoUDR通过整合零知识证明（ZK-SNARK）技术，旨在实现数据交换过程中的公平性和效率性。该协议显著减少了区块链交易的数量，无论是单个块还是数据簇检索，只需要提供方在特定时间框架内提交一次密钥揭示交易即可。

为了进一步优化交易数量，PoUDR采用了提供方侧的批处理证明技术，使得在数据由多个提供者提供、被多个查询者请求的情况下，仅需N_P次交易，而非N_P*N_Q次。这极大地提高了经济效率和可扩展性。

此外，文章详细定义了安全集群数据交换（SSDE），并提供了基于游戏的安全分析。通过将PoUDR集成到Bitswap协议（IPFS的一部分），实现了一种名为Relaxed Groth16的算法，该算法解决了生成零知识证明的重大技术挑战，有效降低了整体成本，为去中心化存储网络中的安全数据检索提供了可行解决方案。 <div>
Decentralized storage networks, including IPFS and Filecoin, have created a marketplace where individuals exchange storage space for profit. These networks employ protocols that reliably ensure data storage providers accurately store data without alterations, safeguarding the interests of storage purchasers. However, these protocols lack an effective and equitable payment mechanism for data retrieval, particularly when multiple data queriers are involved. This necessitates a protocol that ensures both data integrity and fair compensation for data providers.

In decentralized storage, data is fragmented into small blocks and stored across multiple nodes, a process known as data swarming. Due to this property, traditional data exchange protocols are inadequate in terms of communication and economic efficiency.

We propose the Proof of Unified Data Retrieval protocol (PoUDR). PoUDR incorporates ZK-SNARK to facilitate a fair data exchange protocol. PoUDR reduces the number of blockchain transactions for both single block and data swarming retrieval. The protocol requires only a single key-revealing transaction submitted by the provider to the blockchain for each data block. This architecture allows for further optimization of transaction numbers through a batched proof technique on the provider's side.  This approach necessitates only $N_P$ transactions within a specific time frame when data consisting of $N_D$ blocks, provided by $N_P$ providers, is queried by $N_Q$ queriers.

This work provides a comprehensive definition for Secure Swarming Data Exchange (SSDE), including security assumptions. Also it offers a detailed game-based security analysis for the PoUDR protocol. Moreover, the PoUDR protocol has been fully integrated into the Bitswap protocol (IPFS). Within this integration, our proposed Relaxed Groth16 algorithm addresses the significant technical challenge of generating zero-knowledge proofs, leading to substantial cost reductions for overall feasibility of secure data retrieval in decentralized storage networks.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 22:42:26 +0000</pubDate>
</item>
<item>
<title>HEonGPU: a GPU-based Fully Homomorphic Encryption Library 1.0</title>
<link>https://eprint.iacr.org/2024/1543</link>
<guid>https://eprint.iacr.org/2024/1543</guid>
<content:encoded><![CDATA[
<div> 关键词：HEonGPU、高效率、全同态加密、图形处理单元、多流架构

总结:

HEonGPU是一种旨在优化全同态加密(FHE)操作在图形处理器(GPU)上的性能的高级库。它通过利用GPU的并行处理能力显著减少了与FHE相关的计算开销，允许对加密数据执行更快速的同态计算。这种能力特别适用于隐私保护机器学习和安全数据处理的实时应用。HEonGPU的关键优势在于其多流架构，不仅能够实现任务的并行处理以提高吞吐量，还能消除主机设备（即CPU）与GPU之间的数据传输开销。通过在GPU内部高效管理数据，多流架构减少了重复内存传输的需求，进一步提高了性能。针对各种FHE方案，HEonGPU的GPU优化设计使其非常适合大规模加密计算，为用户提供更低的延迟和更高的性能。 <div>
HEonGPU is a high-performance library designed to optimize Fully Homomorphic Encryption (FHE) operations on Graphics Processing Unit (GPU). By leveraging the parallel processing capac- ity of GPUs, HEonGPU significantly reduces the computational overhead typically associated with FHE by executing complex operation concurrently. This allows for faster execution of homomorphic computations on encrypted data, enabling real-time applications in privacy-preserving machine learn- ing and secure data processing. A key advantage of HEonGPU lies in its multi-stream architecture, which not only allows parallel processing of tasks to improve throughput but also eliminates the over- head of data transfers between the host device (i.e., CPU) and GPU. By efficiently managing data within the GPU using multi-streams, HEonGPU minimizes the need for repeated memory transfers, further enhancing performance. HEonGPU’s GPU-optimized design makes it ideal for large-scale encrypted computations, providing users with reduced latency and higher performance across various FHE schemes.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 22:05:03 +0000</pubDate>
</item>
<item>
<title>More Efficient Lattice-based OLE from Circuit-private Linear HE with Polynomial Overhead</title>
<link>https://eprint.iacr.org/2024/1534</link>
<guid>https://eprint.iacr.org/2024/1534</guid>
<content:encoded><![CDATA[
<div> 关键词：电路隐私、线性同态加密、半诚实模型、零知识证明、主动安全性

总结:
文章提出了一种新的方法，用于获得基于格的线性同态加密的电路隐私，该方法避免了使用指数级大错误的噪声泛滥或迭代重启动。这种方法直接导致了一个半诚实盲线性评估(OLE)协议，其效率显著提高，将前代最佳通信成本减少了50%。在100Mbps网络环境下，我们的协议的平均时间改进了前工作33%。我们的半诚实OLE首次实现了同时的高效率和近最优的渐进性。通过结合最近的零知识证明的密文知识，我们的LHE提供了一个比前作通信量减少2.7倍的主动安全OLE。当应用于Overdrive（Eurocrypt '18）这一预处理协议时，我们的方法在通信上提供了相对于现状1.4倍的改进。

文章的核心贡献在于提出了一种高效且无需复杂计算步骤的方法来实现电路隐私，从而显著提高了OLE协议的效率，特别是通信成本的大幅降低。同时，该方法还扩展了零知识证明技术的应用，使得OLE协议在保证安全性的同时，也能达到较高的通信效率。在实际应用中，这种方法被证明能有效提升MPC预处理协议的通信效率，展现出在现代密码学领域的广泛潜力与应用价值。 <div>
We present a new and efficient method to obtain circuit privacy for lattice-based linearly homomorphic encryptions (LHE). In particular, our method does not involve noise-flooding with exponetially large errors or iterative bootstrapping. As a direct result, we obtain a semi-honest oblivious linear evaluation (OLE) protocol with the same efficiency, reducing the communication cost of the prior state of the art by 50%. 
Consequently, the amortized time of our protocol improves the prior work by 33% under 100Mbps network setting. Our semi-honest OLE is the first to achieve both concrete efficiency and asymptotic quasi-optimality. Together with an extension of the recent zero-knowledge proof of plaintext knowledge, our LHE yields actively-secure OLE with 2.7x reduced communication from the prior work. When applied to Overdrive (Eurocrypt '18), an MPC preprocessing protocol, our method provides 1.4x improvement in communication over the state of the art.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 08:11:22 +0000</pubDate>
</item>
<item>
<title>BEAT-MEV: Epochless Approach to Batched Threshold Encryption for MEV Prevention</title>
<link>https://eprint.iacr.org/2024/1533</link>
<guid>https://eprint.iacr.org/2024/1533</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance（DeFi）、Batched Threshold Encryption（BTE）、Market Manipulation、Miner Extractable Value（MEV）、Privacy Concerns

总结:

本文探讨了去中心化金融（DeFi）中公开待处理交易带来的隐私问题及其对市场操纵的影响，特别是通过矿工可提取价值（MEV）所引发的潜在风险。研究指出，当区块提议者利用重新排序、省略或添加交易的能力时，用户可能会遭受由抢先交易导致的经济损失。近期的研究方向集中在加密待处理交易上，以隐藏交易数据直至区块最终确定。

Choudhuri等人提出了一个名为Batched Threshold Encryption（BTE）的新原始概念，它允许一个委员会选择一批加密交易，并在区块最终确定后才进行解密。BTE实现了低通信复杂度的解密过程，并确保了未被选入批次的所有加密交易的隐私性。然而，其存在需要昂贵的MPC设置来为每批解密过程创建的局限性。

本文提出了一种新颖的BTE方案，解决了上述限制，无需昂贵的周期性设置即可实现实用的加密和解密时间（分别小于2ms和440ms，对于512笔交易）。此外，文章还探索了用户如何协调其交易的问题，这对于系统功能至关重要。在过程中，文章提供了多项优化和复杂度之间的权衡策略，以实现标准硬件上的实用性能。最后，证明了构建方案的安全性，涵盖了对MEV预防机制的实际攻击模型。 <div>
In decentralized finance (DeFi), the public availability of pending transactions presents significant privacy concerns, enabling market manipulation through miner extractable value (MEV). MEV occurs when block proposers exploit the ability to reorder, omit, or include transactions, causing financial loss to users from frontrunning. Recent research has focused on encrypting pending transactions, hiding transaction data until block finalization. To this end, Choudhuri et al. (USENIX '24) introduce an elegant new primitive called Batched Threshold Encryption (BTE) where a batch of encrypted transactions is selected by a committee and only decrypted after block finalization. Crucially,  BTE achieves low communication complexity during decryption and guarantees that all encrypted transactions outside the batch remain private. An important shortcoming of their construction is, however, that it progresses in epochs and requires a costly setup in MPC for each batch decryption.
    In this work, we introduce a novel BTE scheme addressing the limitations by eliminating the need for an expensive epoch setup while achieving practical encryption and decryption times. Additionally, we explore the problem of how users can coordinate their transactions, which is crucial for the functionality of the system. Along the way, we present several optimizations and trade-offs between communication and computational complexity that allow us to achieve practical performance on standard hardware ($<2$ ms for encryption and $<440$ ms for decrypting $512$ transactions). Finally, we prove our constructions secure in a model that captures practical attacks on MEV-prevention mechanisms.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 21:36:16 +0000</pubDate>
</item>
<item>
<title>Folding Schemes with Privacy Preserving Selective Verification</title>
<link>https://eprint.iacr.org/2024/1530</link>
<guid>https://eprint.iacr.org/2024/1530</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、折叠方案、隐私保护、陈述隐藏、验证成本

总结: 

文章主要探讨了折叠方案这一新颖的理论，它将执行多个关于相同关系的零知识证明任务简化为一次零知识证明和若干低成本的包含证明。近期，折叠方案被用于减轻向多个独立验证者证明不同陈述的成本问题，这在多种应用中展现出潜力。然而，当一起证明的陈述信息可能泄露时，这种设计可能会引起安全问题。

为解决此问题，作者提出了隐私保护折叠方案的概念及其所需的安全性定义。隐私保护折叠方案旨在确保在证明过程中不泄露任何有关被合并陈述的信息。为了构建此类方案，作者引入了“陈述隐藏”这一概念，它允许将一个关系实例隐秘地表示为另一个关系实例，同时保持其真实性的验证。通过结合现有折叠方案和“陈述隐藏”的技术，可以构造出既能降低验证成本又具备隐私保护功能的方案。该方案首先对每个需要证明的陈述进行隐藏，然后利用折叠方案验证这些隐藏的陈述是否正确地合并到其他声明中。 <div>
Folding schemes are an exciting new primitive, transforming the task of performing multiple zero-knowledge proofs of knowledge for a relation into performing just one zero-knowledge proof, for the same relation, and a number of cheap inclusion-proofs. Recently, folding schemes have been used to amortize the cost associated with proving different statements to multiple distinct verifiers, which has various applications. We observe that for these uses, leaking information about the statements folded together can be problematic, yet this happens with previous constructions. Towards resolving this issue, we give a natural definition of privacy preserving folding schemes, and what security they should offer. To construct privacy preserving folding schemes, we first define a statement hiders, a primitive which might be of independent interest. In a nutshell, a statement hider hides an instance of a relation as a new instance in the same relation. The new instance is in the relation if and only if the initial instance is. With this building block, we can utilize existing folding schemes to construct a privacy preserving folding scheme, by first hiding each of the statements. Folding schemes allow verifying that a statement was folded into another statement, while statement hiders allow verifying that a statement was hidden as another statement.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 10:49:25 +0000</pubDate>
</item>
<item>
<title>Challenges in Timed Cryptography: A Position Paper</title>
<link>https://eprint.iacr.org/2024/1529</link>
<guid>https://eprint.iacr.org/2024/1529</guid>
<content:encoded><![CDATA[
<div> 关键词：时间锁谜题、理想化、分析技术、陷阱门函数、模拟器

总结:

本文探讨了时间锁谜题这一领域，该领域涉及使用计算复杂性来在一段时间后解锁信息。文章指出，尽管该领域已有超过25年的历史，但其基础并未得到充分理解。当前的分析技术在构建包含过期安全性的组件时缺乏稳固机制，特别是在多方协议中。此外，现有分析常常依赖于对理想化和模拟器进行不切实际计算能力的理想化假设。

文章首先指出了现有尝试存在的问题，包括缺乏可组合性、不一致的分析或功能限制。这些缺陷最终归结为Mahmoody等人的一项不可能性结果，即无法仅通过随机或acles构建具有超多项式差距的时间锁谜题。然而，当前对代数谜题的分析仍假定每一步都是通用或随机或acles。文章指出，如果生成过程依赖于不能被视为随机或acles的陷阱门函数（以允许高效生成并避免上述不可能性结果），那么在分析求解过程时，也应不将此类陷阱门函数及其中间状态视为随机或acles。

文章还讨论了时间锁谜题证明技术中的其他问题，特别是当谜题需要保密一段时间时，减少应限制模拟器的运行时间。它评估了各种尝试对这一原则的遵守情况以及它们在组合方面的实现程度。文章强调了现有框架在构建包含过期安全性的复合多方协议时的局限性和潜在挑战，并提出了解决这些问题的可能方向。 <div>
Time-lock puzzles are unique cryptographic primitives that use computational complexity to keep information secret for some period of time, after which security expires. This topic, while over 25 years old, is still in a state where foundations are not well understood: For example, current analysis techniques of time-lock primitives provide no sound mechanism to build composed multi-party cryptographic protocols which use expiring security as a building block. Further, there are analyses that employ idealizations and simulators of unrealistic computational power to be an acceptable sound security argument. Our goal with this short paper is to advocate for understanding what approaches may lead to sound modeling beyond idealization, and what approaches may, in fact, be hopeless at this task of sound modeling. 

We explain in this paper how existing  attempts at this subtle problem lack either composability, a fully consistent analysis, or functionality. The subtle flaws in the existing frameworks reduce to an impossibility result by Mahmoody et al., who showed that time-lock puzzles with super-polynomial gaps (between committer and solver) cannot be constructed from random oracles alone (or any repetitive computation where the next state is completely random given the prior state); yet still the analyses of algebraic puzzles today treat the solving process as if each step is a generic or random oracle. We point out that if the generation process relies on a trapdoor function that cannot be treated as a random oracle (to allow efficient generation while avoiding this impossibility result), then, to be consistent, the analysis of the solving process should also not treat such a trapdoor function (and its intermediate states) as a random oracle. 

We also delineate additional issues with the proof techniques used for time-lock puzzles. Specifically, when a time-lock puzzle must retain privacy for some amount of time, the reduction should bound the running time of the simulator. A simulator that can ``simulate" if given time that if given to an adversary allows said adversary to solve the puzzle is not a valid security argument. We survey the adherence of various attempts to this principle, as well as the properties that different attempts achieve toward composition.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 02:01:32 +0000</pubDate>
</item>
<item>
<title>FANNG-MPC: Framework for Artificial Neural Networks and Generic MPC</title>
<link>https://eprint.iacr.org/2023/1918</link>
<guid>https://eprint.iacr.org/2023/1918</guid>
<content:encoded><![CDATA[
<div> 关键词：FANNG-MPC、安全多方计算、主动安全性、机器学习即服务、隐私保护

总结:

本文介绍了一种名为FANNG-MPC的灵活安全多方计算框架，该框架为隐私保护的机器学习即服务(MLaaS)提供了主动安全性。FANNG-MPC是从已废弃的SCALE-MAMBA衍生而来的一个数据导向型分支，它集成了新的库和指令，用于实现私密神经网络，有效地复活了流行框架。与SCALE-MAMBA不同的是，FANNG-MPC解耦了离线和在线阶段，并在软件中实现了经销商模型，允许一组独立实体生成离线材料。框架还支持数据库功能，引入了预处理材料的新指令集，包括门控电路和卷积及矩阵乘法三元组。此外，FANNG-MPC还实现了新型私有比较协议和优化的神经网络功能库。通过开源实现，文章详细评估了使用LeNet和VGG16等流行神经网络进行私人推理的效果。这是首个在不诚实多数设置下提供活跃安全性的MPC框架，对隐私保护机器学习领域具有重要意义。 <div>
In this work, we introduce FANNG-MPC, a versatile secure multi-party computation framework capable to offer active security for privacy preserving machine learning as a service (MLaaS). Derived from the now deprecated SCALE-MAMBA, FANNG is a data-oriented fork, featuring novel set of libraries and instructions for realizing private neural networks, effectively reviving the popular framework. To the best of our knowledge, FANNG is the first MPC framework to offer actively secure MLaaS in the dishonest majority setting.

FANNG goes beyond SCALE-MAMBA by decoupling offline and online phases and materializing the dealer model in software, enabling a separate set of entities to produce offline material. The framework incorporates database support, a new instruction set for pre-processed material, including garbled circuits and convolutional and matrix multiplication triples. FANNG also implements novel private comparison protocols and an optimized library supporting Neural Network functionality. All our theoretical claims are substantiated by an extensive evaluation using an open-sourced implementation, including the private inference of popular neural networks like LeNet and VGG16.
]]></content:encoded>
<pubDate>Thu, 14 Dec 2023 13:21:42 +0000</pubDate>
</item>
<item>
<title>Instance-Hiding Interactive Proofs</title>
<link>https://eprint.iacr.org/2024/776</link>
<guid>https://eprint.iacr.org/2024/776</guid>
<content:encoded><![CDATA[
<div> 关键词：Instance-Hiding Interactive Proof、平均难度语言、One-Way Functions、随机编码、复合

文章总结：

文章主要探讨了Instance-Hiding Interactive Proof（IHIP）这一概念及其性质和应用。IHIP是一种交互证明系统，其中验证者与不受限制的证明者进行交互以确定输入x是否属于语言L，同时保证证明者无法获取任何关于x的信息。以下是文章的关键发现：

1. **IHIP与复杂性类的关系**：任何具有IHIP的语言都位于NP/poly和coNP/poly之间，这意味着它们可以在多项式时间内验证。

2. **IHIP与One-Way Functions的关系**：如果存在一个平均难度语言具有IHIP，则可以证明One-Way Functions的存在。这表明IHIP在密码学中具有重要意义。

3. **IHIP与随机编码的关系**：IHIP可以视为随机编码概念的一种推广，它提供了一种新的方式来保护数据隐私。

4. **IHIP的封闭性**：IHIP具有封闭性，即它们可以通过与任何可有效计算的函数复合而保持其性质。

5. **Simulatable IHIP的增强特性**：对于一种更强大的IHIP版本（称为Simulatable IHIP），证明者的视角可以被有效模拟。这导致了更严格的复杂性分类结果，如任何具有Simulatable IHIP的语言都位于AM和coAM之间。

6. **最坏情况下的难度与One-Way Functions**：如果存在一个最坏情况下的硬语言具有Simulatable IHIP，则可以证明One-Way Functions的存在，进一步强调了IHIP在理论计算机科学中的重要性。

通过这些发现，文章深入探讨了IHIP在复杂性理论、密码学和计算理论中的角色和潜力，为理解交互证明系统的性质提供了新的视角。 <div>
In an Instance-Hiding Interactive Proof (IHIP) [Beaver et al. CRYPTO 90], an efficient verifier with a _private_ input x interacts with an unbounded prover to determine whether x is contained in a language L. In addition to completeness and soundness, the instance-hiding property requires that the prover should not learn anything about x in the course of the interaction. Such proof systems capture natural privacy properties, and may be seen as a generalization of the influential concept of Randomized Encodings [Ishai et al. FOCS 00, Applebaum et al. FOCS 04, Agrawal et al. ICALP 15], and as a counterpart to Zero-Knowledge proofs [Goldwasser et al. STOC 89]. 

We investigate the properties and power of such instance-hiding proofs, and show the following:
1. Any language with an IHIP is contained in NP/poly and coNP/poly.
2. If an average-case hard language has an IHIP, then One-Way Functions exist.
3. There is an oracle with respect to which there is a language that has an IHIP but not an SZK proof.
4. IHIP's are closed under composition with any efficiently computable function.

We further study a stronger version of IHIP (that we call Simulatable IHIP) where the view of the honest prover can be efficiently simulated. For these, we obtain stronger versions of some of the above:
5. Any language with a Simulatable IHIP is contained in AM and coAM.
6. If a _worst-case_ hard language has a Simulatable IHIP, then One-Way Functions exist.
]]></content:encoded>
<pubDate>Tue, 21 May 2024 07:55:56 +0000</pubDate>
</item>
<item>
<title>Overpass Channels: Horizontally Scalable, Privacy-Enhanced, with Independent Verification, Fluid Liquidity, and Robust Censorship Proof, Payments</title>
<link>https://eprint.iacr.org/2024/1526</link>
<guid>https://eprint.iacr.org/2024/1526</guid>
<content:encoded><![CDATA[
<div> 关键词：Overpass Channels、区块链、零知识证明、横向扩展、隐私保护

总结:

文章介绍了Overpass Channels这一创新的区块链技术，其主要特点包括：1) 横向扩展性，实现更高的交易处理能力；2) 隐私增强支付网络，通过零知识证明确保交易的匿名性和安全性；3) 独立验证机制，提高系统的透明度和信任度；4) 流动性与去中心化，确保资金高效流通同时保持网络的分散性；5) 抗审查能力，抵抗外部干预，保护用户权益。

Overpass Channels采用零知识证明（特别是zk-SNARKs）技术，以替代传统的共识机制和矿工角色，从而实现更低的成本和能源消耗。系统设计围绕单边支付通道和离链交易处理，保证高速、低延迟的操作，同时不牺牲安全性和去中心化特性。该技术的应用范围广泛，不仅限于全球支付，还涵盖了机密投票、安全健康记录管理等多元领域。通过这种创新架构，Overpass Channels旨在提供一个更高效、更安全、更私密的区块链解决方案。 <div>
Overpass Channels presents a groundbreaking approach to blockchain scalability, offering a horizontally scalable, privacy-enhanced payment network with independent verification, fluid liquidity, and robust censorship resistance. This paper introduces a novel architecture that leverages zero-knowledge proofs, specifically zk-SNARKs, to ensure transaction validity and privacy while enabling unprecedented throughput and efficiency. 
By eliminating the need for traditional consensus mechanisms and miners, Overpass Channels achieves remarkable cost-effectiveness and energy efficiency. The system's design focuses on unilateral payment channels and off-chain transaction processing, allowing for high-speed, low-latency operations without compromising security or decentralization. This paper provides a comprehensive analysis of the Overpass Channels system, including its cryptographic foundations, scalability metrics, integration, and potential applications across various domains, from global payments to confidential voting systems and secure health record management.
]]></content:encoded>
<pubDate>Sat, 28 Sep 2024 17:20:13 +0000</pubDate>
</item>
<item>
<title>DUPLEX: Scalable Zero-Knowledge Lookup Arguments over RSA Group</title>
<link>https://eprint.iacr.org/2024/1509</link>
<guid>https://eprint.iacr.org/2024/1509</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、查找论证、RSA组、可扩展性、隐私保护

总结:本文提出了一种名为$\duplex$的新颖零知识查找论证方案，旨在解决大规模查找元素向量在SNARK中的应用问题。$\duplex$具有多项显著优势：

1. **高效性**：对于$m$个查找元素，其证明时间仅为$O(m\log m)$，且证明大小固定，验证过程快速，无需依赖表大小。

2. **适应性**：$\duplex$首次支持在RSA组上进行查找操作，通过将元素转换为质数，确保了与RSA组的兼容性，同时保持了较低的计算成本。

3. **安全性**：该方案确保了查找元素的隐私性，即使在动态更新表的情况下，也能有效保护信息不被泄露。

4. **实用性**：$\duplex$在实际应用中表现出色，相比于当前最先进的查找论证Caulk，其证明时间明显缩短，同时保持了合理的证明大小和验证速度。

5. **可扩展性**：$\duplex$的设计使其非常适合于大规模、隐私敏感的计算验证场景，提高了可扩展性和实用性。

通过这些特点，$\duplex$为SNARK在处理非算术运算如批量范围检查或位操作等任务提供了更为高效、安全和实用的解决方案。 <div>
Lookup arguments enable a prover to convince a verifier that a committed vector of lookup elements $\vec{f} \in \mathbb{F}^m$ is contained within a predefined table $T \in \mathbb{F}^N$. These arguments are particularly beneficial for enhancing the performance of SNARKs in handling non-arithmetic operations, such as batched range checks or bitwise operations. While existing works have achieved efficient and succinct lookup arguments, challenges remain, particularly when dealing with large vectors of lookup elements in privacy-sensitive applications.

In this paper, we introduce $\duplex$, a scalable zero-knowledge lookup argument scheme that offers significant improvements over previous approaches. Notably, we present the first lookup argument designed to operate over the RSA group. Our core technique allows for the transformation of elements into prime numbers to ensure compatibility with the RSA group, all without imposing substantial computational costs on the prover. Given $m$ lookup elements, $\duplex$ achieves an asymptotic proving time of $O(m \log m)$, with constant-sized proofs, constant-time verification, and a public parameter size independent of the table size $N$. Additionally, $\duplex$ ensures the privacy of lookup elements and is robust against dynamic table updates, making it highly suitable for scalable verifiable computation in real-world applications.

We implemented and empirically evaluated $\duplex$, comparing it with the state-of-the-art zero-knowledge lookup argument Caulk [CCS'22]. Our experimental results demonstrate that $\duplex$ significantly outperforms Caulk in proving time for both single and batched lookup arguments, while maintaining practical proof size and verification time.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 04:48:02 +0000</pubDate>
</item>
<item>
<title>Evaluating Leakage Attacks Against Relational Encrypted Search</title>
<link>https://eprint.iacr.org/2024/1525</link>
<guid>https://eprint.iacr.org/2024/1525</guid>
<content:encoded><![CDATA[
<div> 关键词：加密搜索算法、数据泄漏、隐私保护、安全存储、查询执行

总结:

本文探讨了加密搜索算法（ESAs）在关系数据库场景中的适用性，以及主要的数据泄漏攻击在这一背景下的应用。ESAs允许用户对敏感数据进行加密存储并远程访问，同时保持对关键词或查询的搜索能力，从而保护隐私和确保数据安全。

1. **数据泄漏与攻击**: 原有ESAs在文档和关键词搜索中应用时，存在一定程度的信息泄露问题。这些信息泄露被用于辅助攻击者获取关于明文的额外信息。然而，大多数针对泄漏攻击的研究集中在关键词ESAs上，而非关系型ESAs。

2. **攻击适应性**: 作者对主要的泄漏攻击进行了重新评估，以适应关系型ESAs环境，并在不同特性的关系型数据集上进行了广泛测试。

3. **攻击效果差异**: 实验结果表明，这些主要的攻击方法在已知数据设置下确实可以有效作用于关系型ESAs。但攻击性能在不同的数据集、利用的模式和攻击方法之间存在显著差异。

4. **数据集特性影响**: 不同属性的数据集对攻击效果产生了显著影响，说明了在实际应用中需要考虑数据集的具体特性来评估安全性和隐私保护水平。

5. **结论与展望**: 该研究揭示了关系型ESAs面临的数据泄漏风险，并强调了对这类系统进行针对性安全性评估的重要性。未来工作可能包括开发更有效的防御策略、改进ESAs设计以减少泄漏，以及进一步探索针对关系型数据的新型攻击和防御机制。 <div>
Encrypted Search Algorithms (ESAs) are a technique to encrypt data while the user can still search over it. ESAs can protect privacy and ensure security of sensitive data stored on a remote storage. Originally, ESAs were used in the context of documents that consist of keywords. The user encrypts the documents, sends them to a remote server and is still able to search for keywords, without exposing information about the plaintext. The idea of ESAs has also been applied to relational databases, where queries (similar to SQL statements) can be privately executed on an encrypted database.But just as traditional schemes for Keyword-ESAs, also Relational-ESAs have the drawback of exposing some information, called leakage. Leakage attacks have been proposed in the literature that use this information together with auxiliary information to learn details about the plaintext. However, these leakage attacks have overwhelmingly been designed for and applied to Keyword-ESAs and not Relational-ESAs.
In this work, we review the suitability of major leakage attacks against ESAs in the relational setting by adapting them accordingly. We perform extensive re-evaluations of the attacks on various relational datasets with different properties.
Our evaluations show that major attacks can work against Relational-ESAs in the known-data setting. However, the attack performance differs between datasets, exploited patterns, and attacks.
]]></content:encoded>
<pubDate>Sat, 28 Sep 2024 13:36:29 +0000</pubDate>
</item>
<item>
<title>Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments</title>
<link>https://eprint.iacr.org/2024/1523</link>
<guid>https://eprint.iacr.org/2024/1523</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3系统、智能合约、适配签名、功能加密、公平信息销售

总结:
本文聚焦于在Web3系统的信任无界环境中，如何实现敏感数据的公平功能性销售。主要讨论了两种解决方案：基于智能合约的方法和依赖适配签名的技术。前者提供了原子交易，允许买家仅获取函数$f(x)$的结果而无法完全访问原始数据$x$，但存在效率低、成本高、隐私保护不足和与非智能合约系统兼容性差的问题。后者解决了上述问题，但买家可以完全提取$x$，不支持对敏感数据的功能性提取。

为解决这些局限，文章提出了一种新的加密原语——功能适配签名（FAS）。FAS允许卖家发布承诺$x$的广告，买家预签支付交易关于函数$f$，并将该预签发送给卖家。卖家将预签适应为有效的买家签名，然后在区块链上发布支付和适应后的签名以获得付款。最后，买家使用预签和发布的签名高效提取$f(x)$，完成交易。

文章详细阐述了FAS的安全属性，包括一种名为见证隐私的新概念，旨在保护卖家的隐私，确保买家仅学习到$f(x)$，而不会了解更多关于$x$的信息。文章提出了不同级别的见证隐私概念，如见证隐藏、见证不可区分性和零知识，以捕捉恶意买家可能获取的关于$x$的额外信息量。

文章还介绍了两种支持线性函数（如统计/聚合、机器学习中的核等）的FAS高效构造，这些构造满足最强的见证隐私概念。一种基于素数阶群的构造兼容Schnorr签名用于支付，另一种基于格的构造兼容Lyubashevsky签名方案的变体。文章的主要理论贡献在于揭示了功能加密与适配签名之间意想不到的联系，以及通过使用特定安全增强技术的内积功能加密（IPFE）的黑盒方式来避免复杂的加密工具，从而实现改进的效率。文章还展示了FAS构造在Schnorr签名上的实现，证明即使对于大小适度的卖家证词，不同操作也相当高效，即使是普通硬件也能胜任。 <div>
In scenarios where a seller holds sensitive data $x$, like employee / patient records or ecological data, and a buyer seeks to obtain an evaluation of specific function $f$ on this data, solutions in trustless digital environments like blockchain-based Web3 systems typically fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions leveraging tools such as adaptor signatures. The former approach offers atomic transactions where the buyer learns the function evaluation $f(x)$ (and not $x$ entirely) upon payment. However, this approach is often inefficient, costly, lacks privacy for the seller's data, and is incompatible with systems that do not support smart contracts with required functionalities. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an "all-or-nothing" guarantee, where the buyer fully extracts $x$ and does not support functional extraction of the sensitive data. In this work, we aim to bridge the gap between these approaches, developing a solution that enables fair functional sales of information while offering improved efficiency, privacy, and compatibility similar to adaptor signatures.

Towards this, we propose functional adaptor signatures (FAS) a novel cryptographic primitive that achieves all the desired properties as listed above. Using FAS, the seller can publish an advertisement committing to $x$. The buyer can pre-sign the payment transaction w.r.t. a function $f$, and send it along with the transaction to the seller.
The seller adapts the pre-signature into a valid (buyer's) signature and posts the payment and the adapted signature on the blockchain to get paid. Finally, using the pre-signature and the posted signature, the buyer efficiently extracts $f(x)$, and completes the sale. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond $f(x)$.
We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge, to capture varying levels of leakage about $x$ beyond $f(x)$ to a malicious buyer.

We introduce two efficient constructions of FAS supporting linear functions (like statistics/aggregates, kernels in machine learning, etc.), that satisfy the strongest notion of witness privacy. One construction is based on prime-order groups and compatible with Schnorr signatures for payments, and the other is based on lattices and compatible with a variant of Lyubashevsky's signature scheme. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption, a well-explored concept over the past decade, and adaptor signatures, a relatively new primitive in the cryptographic landscape. On a technical level, we avoid heavy cryptographic machinery and achieve improved efficiency, by making black-box use of building blocks like inner product functional encryption (IPFE) while relying on certain security-enhancing techniques for the IPFE in a non-black-box manner. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, the different operations are quite efficient even for commodity hardware.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 18:54:54 +0000</pubDate>
</item>
<item>
<title>Practical Mempool Privacy via One-time Setup Batched Threshold Encryption</title>
<link>https://eprint.iacr.org/2024/1516</link>
<guid>https://eprint.iacr.org/2024/1516</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi、mempool隐私、DKG、一次性设置、效率优化

总结:

文章探讨了在去中心化金融（DeFi）生态系统中保护交易隐私的重要性，特别是关于在内存池（mempool）中的交易可能遭受市场操纵的问题。文章提出了一种实用的、基于一次性分布式密钥生成（DKG）方案的mempool隐私解决方案，以确保交易隐私，并且在每个区块周期内仅需进行一次初始化设置。该方案通过让客户端加密交易，直到选定一定数量（B个）交易进入区块后，这些交易可以被解密服务器以极低的信息通信量解密。

相比先前的工作，该方案在不增加初始设置开销的同时，降低了通信需求，提高了处理效率，并保证了未被选中的交易的隐私性。实证研究表明，这种加密过程几乎不受参与节点数量的影响，而批量解密所需的通信量则与每个节点无关。当应用于以太坊这样的区块链平台时，计算和解密时间也相对较低，使得整体性能优化明显。

文章的贡献在于提供了一个既能有效保护交易隐私，又能保持高效运行的mempool隐私方案，这对于推动DeFi应用的安全性和用户数据保护具有重要意义。 <div>
An important consideration with the growth of the DeFi ecosystem is the protection of clients who submit transactions to the system. As it currently stands, the public visibility of these transactions in the memory pool (mempool) makes them susceptible to market manipulations such as frontrunning and backrunning. More broadly, for various reasons—ranging from avoiding market manipulation to including time-sensitive information in their transactions—clients may want the contents of their transactions to remain private until they are executed, i.e. they have *pending transaction privacy*. Therefore, *mempool privacy* is becoming an increasingly important feature as DeFi applications continue to spread.

    We construct the first *practical* mempool privacy scheme that uses a *one-time* DKG setup for $n$ decryption servers. Our scheme ensures the strong privacy requirement by not only hiding the transactions until they are decrypted but also guaranteeing privacy for transactions that were not selected in the epoch (*pending transaction privacy*). For each epoch (or block), clients can encrypt their transactions so that, once $B$ (encrypted) transactions are selected for the epoch, they can be decrypted by each decryption server while communicating only $O(1)$ information. 

    Our result improves upon the best-known prior works, which either: (i) require an expensive initial setup involving a (special purpose) multiparty computation protocol executed by the $n$ decryption servers, along with an additional *per-epoch* setup; (ii) require each decryption server to communicate $O(B)$ information; or (iii) do not guarantee pending transaction privacy.

    We implement our scheme and find that transactions can be encrypted in approximately 8.5 ms, independent of committee size, and the communication required to decrypt an entire batch of transactions is 48 bytes per party, independent of the number of transactions. If deployed on Ethereum, which processes close to 500 transactions per block, it takes close to 3.2 s for each committee member to compute a partial decryption and 3.0 s to decrypt all transactions for a block in single-threaded mode. Compared to prior work, which had an expensive setup phase per epoch, we incur $<2\times$ overhead in the worst case. On some metrics such as partial decryptions size, we actually fare better.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 16:47:03 +0000</pubDate>
</item>
<item>
<title>Comments on "Privacy-Enhanced Federated Learning Against Poisoning Adversaries"</title>
<link>https://eprint.iacr.org/2024/1504</link>
<guid>https://eprint.iacr.org/2024/1504</guid>
<content:encoded><![CDATA[
<div> 关键词：Liu et al., IEEE TIFS'21, PEFL, 恶意行为检测, 同态加密

<br /><br />总结:

在2021年8月发表于IEEE TIFS期刊的Liu等人的文章中，提出了一种名为PEFL的隐私增强框架。该框架旨在通过同态加密技术高效检测联邦学习（FL）中的恶意行为。然而，本文揭示了PEFL并未真正保护隐私。具体来说，文章指出PEFL实际上暴露了所有参与实体的完整梯度向量，这违反了隐私原则。

文章进一步分析指出，即使对PEFL进行立即修复，也无法确保隐私安全。这是因为系统中存在多个漏洞，这些漏洞仍然允许敏感信息泄露。因此，虽然PEFL最初的目标是提高联邦学习环境的安全性，但其实际实现却未能达到预期的隐私保护效果。这一发现强调了在设计和部署用于保护敏感数据的加密技术时，需要仔细考虑潜在的弱点和漏洞。 <div>
In August 2021, Liu et al. (IEEE TIFS'21) proposed a privacy-enhanced framework named PEFL  to efficiently detect poisoning behaviours in Federated Learning (FL) using homomorphic encryption. In this article, we show that PEFL does not preserve privacy. In particular, we illustrate that PEFL reveals the entire gradient vector of all users in clear to one of the participating entities, thereby violating privacy. Furthermore, we clearly show that an immediate fix for this issue is still insufficient to achieve privacy by pointing out multiple flaws in the proposed system.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 10:52:18 +0000</pubDate>
</item>
<item>
<title>Practical Implementation of Pairing-Based zkSNARK in Bitcoin Script</title>
<link>https://eprint.iacr.org/2024/1498</link>
<guid>https://eprint.iacr.org/2024/1498</guid>
<content:encoded><![CDATA[
<div> 关键词：Groth16、零知识证明、比特币脚本、主网、可验证计算

总结:

本文介绍了在BSV主网上实现Groth16验证器的实践性方法。Groth16是一个基于配对的零知识证明方案，其证明大小固定，验证算法高效。通过将Groth16验证器集成到比特币脚本中，可以在区块链上进行链上验证，从而实现离链计算的验证。这种解决方案不仅提供了隐私保护，还提升了区块链的扩展性。此外，它还为比特币引入了智能合约功能，这在过去被认为是非常有限或不存在的。通过生成Groth16证明来验证离链计算的正确性，再使用比特币脚本在链上进行验证，这种方式不仅保证了数据的机密性，而且提高了交易处理能力，为比特币生态系统带来了新的可能性和灵活性。 <div>
Groth16 is a pairing-based zero-knowledge proof scheme that has a constant proof size and an efficient verification algorithm. Bitcoin Script is a stack-based low-level programming language that is used to lock and unlock bitcoins. In this paper, we present a practical implementation of the Groth16 verifier in Bitcoin Script deployable on the mainnet of a Bitcoin blockchain called BSV. Our result paves the way for a framework of verifiable computation on Bitcoin: a Groth16 proof is generated for the correctness of an off-chain computation and is verified in Bitcoin Script on-chain. This approach not only offers privacy but also scalability. Moreover, this approach enables smart contract capability on Bitcoin which was previously thought rather limited if not non-existent.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 16:56:05 +0000</pubDate>
</item>
<item>
<title>No Fish Is Too Big for Flash Boys! Frontrunning on DAG-based Blockchains</title>
<link>https://eprint.iacr.org/2024/1496</link>
<guid>https://eprint.iacr.org/2024/1496</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、Frontrunning攻击、DAG、区块优先级、对策

总结:

本文深入分析了针对基于有向无环图(DAG)的区块链系统的Frontrunning攻击策略。主要发现和讨论如下：

1. **新型攻击策略**：提出了一种新颖的跨区块Frontrunning攻击方法，允许攻击者在其交易在不同区块中优先于受害者交易。

2. **攻击策略介绍**：介绍了三种攻击策略——裂缝攻击（通过断开受害者区块来推迟受害者交易的排序）、投机攻击（预先构建具有优先排序的交易块）以及迟缓攻击（通过故意创建低轮次但高优先级的区块来影响排序）。

3. **实验验证**：通过在AWS和本地环境中使用开源DAG区块链Bullshark和Tusk进行了实验，结果显示攻击的有效性极高，尤其是投机攻击在Bullshark和Tusk上的成功率分别达到92.86%和86.27%。

4. **对策探讨**：提出了随机排序区块和基于交易费用全局重排序的对策以抵御攻击，但发现这些措施可能损害系统性能或增加现有Frontrunning策略的脆弱性。

5. **结论与展望**：强调了对DAG区块链系统中Frontrunning攻击的深入理解和防御的重要性，指出需要进一步研究更有效的防御机制以保护此类区块链系统的安全性和公平性。 <div>
Frontrunning is rampant in blockchain ecosystems, yielding attackers profits that have already soared into several million. Most existing frontrunning attacks focus on manipulating transaction order (namely, prioritizing attackers' transactions before victims' transactions) $\textit{within}$ a block. However, for the emerging directed acyclic graph (DAG)-based blockchains, these intra-block frontrunning attacks may not fully reveal the frontrunning vulnerabilities as they introduce block ordering rules to order transactions belonging to distinct blocks. 

This work performs the first in-depth analysis of frontrunning attacks toward DAG-based blockchains. We observe that the current block ordering rule is vulnerable to a novel $\textit{inter-block}$ frontrunning attack, which enables the attacker to prioritize ordering its transactions before the victim transactions across blocks. We introduce three attacking strategies: $\textit{(i)}$ Fissure attack, where attackers render the victim transactions ordered later by disconnecting the victim's blocks. $\textit{(ii)}$ Speculative attack, where attackers speculatively construct order-priority blocks. $\textit{(iii)}$ Sluggish attack, where attackers deliberately create low-round blocks assigned a higher ordering priority by the block ordering rule.

We implement our attacks on two open-source DAG-based blockchains, Bullshark and Tusk. We extensively evaluate our attacks in geo-distributed AWS and local environments by running up to $n=100$ nodes. Our experiments show remarkable attack effectiveness. For instance, with the speculative attack, the attackers can achieve a $92.86\%$ attack success rate (ASR) on Bullshark and an $86.27\%$ ASR on Tusk. Using the fissure attack, the attackers can achieve a $94.81\%$ ASR on Bullshark and an $87.31\%$ ASR on Tusk. 

We also discuss potential countermeasures for the proposed attack, such as ordering blocks randomly and reordering transactions globally based on transaction fees. However, we find that they either compromise the performance of the system or make the protocol more vulnerable to frontrunning using the existing frontrunning strategies.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 13:34:03 +0000</pubDate>
</item>
<item>
<title>Concretely Efficient Private Set Union via Circuit-based PSI</title>
<link>https://eprint.iacr.org/2024/1494</link>
<guid>https://eprint.iacr.org/2024/1494</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Set Intersection (PSI), Private Set Union (PSU), Public-key operations, Communication overhead, Symmetric-key primitives

总结:

本文提出了一种新型的私有集合并集（PSU）协议，该协议主要基于高效对称密钥机制，同时保持与公钥基础替代方案相当的通信效率。PSU协议的核心创新在于利用先进的电路基PSI技术实现多查询反向私有成员测试（mq-RPMT），这一技术对于构建PSU至关重要。文章揭示了电路基PSI中常见哈希方法导致的隐私泄露问题，并通过盲化伪随机函数（OPRF）和新设计的洗牌子协议来缓解这一问题。

该协议采用模块化设计，各个组成部分可以方便地替换为更高效的版本，这将直接提升整体性能。实验结果显示，与Chen等人在PKC'24上提出的公钥基础PSU协议相比，本文的PSU协议在输入集大小为$2^{20}$时运行时间提高了10%。此外，与Zhang等人在USENIX Sec'23上提出的基于对称密钥的PSU协议相比，本文的协议在通信方面改善了1.6倍。

通过这些改进，本文的PSU协议不仅优化了计算效率，还降低了通信开销，为私有集合操作提供了更为高效、实用的解决方案。 <div>
Private set intersection (PSI) is a type of private set operation (PSO) for which concretely efficient linear-complexity protocols do exist.
However, the situation is currently less satisfactory for other relevant PSO problems such as private set union (PSU):
For PSU, the most promising protocols either rely entirely on computationally expensive public-key operations or suffer from substantial communication overhead.

In this work, we present the first PSU protocol that is mainly based on efficient symmetric-key primitives yet enjoys comparable communication as public-key-based alternatives.
Our core idea is to re-purpose state-of-the-art circuit-based PSI to realize a multi-query reverse private membership test (mq-RPMT), which is instrumental for building PSU.
We carefully analyze a privacy leakage issue resulting from the hashing paradigm commonly utilized in circuit-based PSI and show how to mitigate this via oblivious pseudorandom function (OPRF) and new shuffle sub-protocols.
Our protocol is modularly designed as a sequential execution of different building blocks that can be easily replaced by more efficient variants in the future, which will directly benefit the overall performance.

We implement our resulting PSU protocol, showing a run-time improvement of 10% over the state-of-the-art public-key-based protocol of Chen et al. (PKC'24) for input sets of size $2^{20}$.
Furthermore, we improve communication by $1.6\times$ over the state-of-the-art symmetric-key-based protocol of Zhang et al. (USENIX Sec'23).
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 11:57:38 +0000</pubDate>
</item>
<item>
<title>Simple and Practical Amortized Sublinear Private Information Retrieval using Dummy Subsets</title>
<link>https://eprint.iacr.org/2023/1072</link>
<guid>https://eprint.iacr.org/2023/1072</guid>
<content:encoded><![CDATA[
<div> 关键词：私有信息检索、子线性时间、多轮交互、状态依赖、效率优化

总结:

本文探讨了私有信息检索（Private Information Retrieval，简称PIR）领域中的一种新型方法——基于预处理和状态依赖的子线性时间PIR方案。主要贡献在于提出了一种使用新技巧构建和利用提示（hints）的方法，以解决现有PIR方案中面临的一系列挑战，包括客户端存储量大、通信成本高、实用性低、服务器需非共谋以及客户端查询序列受限等问题。

通过引入“假集”到客户端请求中，该方案成功地消除了任何泄露或正确性失败的可能性。这意味着即使在非共谋的服务器环境下，或者单个服务器场景下，也能实现高效和隐私保护的检索操作。在数据库规模为2^28个32字节条目的情况下，对于双服务器方案，每个查询仅需消耗34KB的通信量和2.7毫秒的计算时间；而单服务器方案则消耗约47KB的通信量和4.5毫秒的计算时间。这些性能指标显著优于先前的研究成果，实现了在保持隐私的同时，极大提升了实际应用中的效率。 <div>
Recent works in amortized sublinear Private Information Retrieval (PIR) have demonstrated great potential. Despite the inspiring progress, existing schemes in this new paradigm are still faced with various challenges and bottlenecks, including large client storage, high communication, poor practical efficiency, need for non-colluding servers, or restricted client query sequences. We present simple and practical amortized sublinear stateful private information retrieval schemes without these drawbacks using new techniques in hint construction and usage. In particular, we introduce a dummy set to the client's request to eliminate any leakage or correctness failures. Our techniques can work with two non-colluding servers or a single server. The resulting PIR schemes achieve practical efficiency. The online response overhead is only twice that of simply fetching the desired entry without privacy. For a database with $2^{28}$ entries of 32-byte, each query of our two-server scheme consumes 34 KB of communication and 2.7 milliseconds of computation, and each query of our single-server scheme consumes amortized 47 KB of communication and 4.5 milliseconds of computation. These results are one or more orders of magnitude better than prior works.
]]></content:encoded>
<pubDate>Mon, 10 Jul 2023 02:16:25 +0000</pubDate>
</item>
<item>
<title>Towards Practical Transciphering for FHE with Setup Independent of the Plaintext Space</title>
<link>https://eprint.iacr.org/2023/1531</link>
<guid>https://eprint.iacr.org/2023/1531</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、非交互式协议、带宽优化、混合同态加密、自适应精度

总结: 文章提出了一种新的方法来解决全同态加密（FHE）在实际应用中带宽需求过高的问题。通过结合任何FHE兼容的对称加密算法与自适应精度的转换过程，该方法允许服务器根据具体应用需求动态选择加密精度，从而显著减少了通信成本。文章以使用FiLIP密钥作为示例，结合了最实用的同态计算技术，成功实现了从2^2到2^8的不同精度范围内的加密操作，每项操作仅需13ms至137ms的时间。这种方法不仅优化了带宽使用，而且保持了操作的高效性，为FHE的应用提供了更灵活和高效的解决方案。

文章的核心贡献在于引入了一种无需预先确定消息精度的方法，解决了现有技术中对于消息大小或应用底层结构的约束问题。通过将原始数据逐位加密并随后根据需要转换为整数域上的FHE密文，这种方法使得FHE的非交互式隐私保护协议能够在保持计算和通信效率的同时，适应各种不同的应用场景。这种创新的策略极大地扩展了FHE在实际应用中的潜力，尤其是在需要处理大量数据和高精度要求的场景下。 <div>
Fully Homomorphic Encryption (FHE) is a powerful tool to achieve non-interactive privacy preserving protocols with optimal computation/communication complexity. However, the main disadvantage is that the actual communication cost (bandwidth) is high due to the large size of FHE ciphertexts. As a solution, a technique called transciphering (also known as Hybrid Homomorphic Encryption) was introduced to achieve almost optimal bandwidth for such protocols. However, all of existing works require clients to fix a  precision for the messages or a mathematical structure for the message space beforehand. It results in unwanted constraints on the plaintext size or underlying structure of FHE based applications.

In this article, we introduce a new approach for transciphering which does not require fixed message precision decided by the client, for the first time. In more detail, a client uses any kind of FHE-friendly symmetric cipher  for $\{0,1\}$ to send its input data encrypted bit-by-bit, then the server can choose a precision $p$ depending on the application and homomorphically transforms the encrypted bits into FHE ciphertexts encrypting integers in $\mathbb{Z}_p$. To illustrate our new technique, we evaluate a transciphering using FiLIP cipher and adapt the most practical homomorphic evaluation technique [CCS'22] to keep the practical latency.  As a result, our proof-of-concept implementation for $p$ from $2^2$ to $2^8$ takes only from $13$ ms to $137$ ms.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 21:43:10 +0000</pubDate>
</item>
<item>
<title>Mastic: Private Weighted Heavy-Hitters and Attribute-Based Metrics</title>
<link>https://eprint.iacr.org/2024/221</link>
<guid>https://eprint.iacr.org/2024/221</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、用户隐私、Mastic协议、重头项、属性基度量

总结:

本文讨论了在保护用户隐私的前提下，通过多党计算技术获取大型软件系统和网络服务中用户行为和体验的洞察。文章介绍了Prio和Poplar两种基于多党计算的协议，它们分别用于通用统计和热门输入的计算。然而，这两种协议并未覆盖所有IETF识别的应用场景。

为填补这一空白，文章提出了一种名为Mastic的新协议，用于处理每个客户端持有输入及其权重的情况（例如，URL及其页面加载时间）。对于给定的候选输入或前缀，一小部分非共谋服务器可以安全地聚合持有该输入（或具有相同前缀的输入）的客户端的权重，而无需学习这些权重或哪个客户端持有哪个输入。这种功能开辟了两个新应用领域：一是对传统热门输入概念的扩展——加权热门输入；二是对Prio风格指标的增强——属性基指标，其中聚合结果根据用户的层级属性进行分类（如地理位置或软件版本）。

文章还通过实际案例展示了Mastic在实现这两个新应用方面的可行性，并与Prio和Poplar进行了性能比较。结果显示，对于简单的热门输入计算，Mastic的表现优于Poplar至少一个数量级；而对于属性基指标，其性能提升幅度约为1.5到2倍。 <div>
Insight into user experience and behavior is critical to the success of large software systems and web services. Gaining such insights, while preserving user privacy, is a significant challenge. Recent advancements in multi-party computation have made it practical to securely compute aggregates over secret shared data. Two such protocols have emerged as candidates for standardization at the IETF: Prio (NSDI 2017) for general-purpose statistics; and Poplar (IEEE S&amp;P 2021) for heavy hitters, where the goal is to compute the most popular inputs held by users without learning the inputs themselves. While each of these protocols is well-suited to certain applications, there remain a number of use cases identified by IETF for which neither Prio nor Poplar is practical.

We introduce Mastic, a protocol for the following functionality: each of a large number of clients holds an input (e.g., a URL) and its corresponding weight (e.g., page load time); for a given candidate input (or prefix), a small number of non-colluding servers wish to securely aggregate the weights of clients that hold that input (or some input with that prefix), without learning the weights or which client holds which input. This functionality makes two new classes of applications possible. The first is a natural generalization of heavy hitters we call weighted heavy-hitters. The second is an enhancement of Prio-style metrics we call attribute-based metrics in which aggregates are grouped by hierarchical user attributes (e.g., their geographic location or software version). We demonstrate Mastic's practicality for these applications with a real-world example of each. We also compare our protocol with Prio and Poplar on a wide area network. Overall, we report over one order of magnitude performance improvement over Poplar for plain heavy-hitters and $1.5-2\times$ improvement over Prio for attribute-based metrics.
]]></content:encoded>
<pubDate>Tue, 13 Feb 2024 16:41:06 +0000</pubDate>
</item>
<item>
<title>PipeSwap: Forcing the Timely Release of a Secret for Atomic Swaps Across All Blockchains</title>
<link>https://eprint.iacr.org/2024/881</link>
<guid>https://eprint.iacr.org/2024/881</guid>
<content:encoded><![CDATA[
<div> 关键词：原子跨链交换、双声称攻击、管道交换、普适性、理想功能

总结:

本文针对原子跨链交换领域存在的问题进行了深入研究与创新。首先，作者揭示了一种名为“双声称攻击”的新形式，这种攻击会导致诚实用户以压倒性的概率损失硬币，并直接破坏原子性。此外，这种攻击易于实施，并可以自然地应用于其他跨链交换协议以及支付通道网络中，这凸显了设计普适性原子交换的普遍挑战。

为了克服这些挑战，作者提出了“管道交换”(pipeSwap)协议，旨在同时满足安全性和实用性。该协议通过使用两跳交换和两跳退款技术来设计一种新颖的硬币流模式，以避免相同冻结硬币的重复声称，从而违反原子性属性。pipeSwap实现了普适性，无需依赖特定的脚本语言（除了基本的签名验证能力），进一步证明了其不依赖于任何特定脚本语言的能力。

文章还分析了现有理想功能在捕捉原子性属性方面的不足，并首次定义了确保原子性的理想功能。在通用可组合性框架下，对pipeSwap进行了详细的安全分析，并开发了一个基于Schnorr/ECDSA签名的原型实现。实验结果显示，pipeSwap可以在不到1.7秒的时间内完成，并且通信开销小于7kb，证明了其高效性。

总的来说，本文通过揭示双声称攻击，提出管道交换协议，解决了原子跨链交换中的安全性与普适性问题，并通过实验验证了其高效性，为原子跨链交换领域的研究提供了新的视角和解决方案。 <div>
Atomic cross-chain swap, which allows users to exchange coins securely, is critical functionality to facilitate inter-currency exchange and trading. Although most classic atomic swap protocols based on Hash Timelock Contracts have been applied and deployed in practice, they are substantially far from universality due to the inherent dependence of rich scripting language supported by the underlying blockchains. The recently proposed Universal Atomic Swaps protocol [IEEE S\&amp;P'22] takes a novel path to scriptless cross-chain swap, and it ingeniously delegates scripting functionality to cryptographic lock mechanisms, particularly the adaptor signature and timed commitment schemes designed to guarantee atomicity. However, in this work, we discover a new form of attack called double-claiming attack, such that the honest user would lose coins with overwhelming probability and atomicity is directly broken. Moreover, this attack is easy to carry out and can be naturally generalized to other cross-chain swap protocols as well as the payment channel networks, highlighting a general difficulty in designing universal atomic swap.

We present pipeSwap, a cross-chain swap protocol that satisfies both security and practical universality. To avoid transactions of the same frozen coins being double-claimed to violate the atomicity property, pipeSwap proposes a novelly designed paradigm of pipelined coins flow by using two-hop swap and two-hop refund techniques. pipeSwap achieves universality by not relying on any specific script language, aside from the basic ability to verify signatures. Furthermore, we analyze why existing ideal functionality falls short in capturing the atomicity property of Universal Atomic Swaps, and define for the first time ideal functionality to guarantee atomicity. In addition to a detailed security analysis in the Universal Composability framework, we develop a proof-of-concept implementation of pipeSwap with Schnorr/ECDSA signatures, and conduct extensive experiments to evaluate the overhead. The experimental results show that pipeSwap can be performed in less than 1.7 seconds and requires less than 7 kb of communication overhead on commodity machines, which demonstrates its high efficiency.
]]></content:encoded>
<pubDate>Mon, 03 Jun 2024 01:21:19 +0000</pubDate>
</item>
<item>
<title>Verifiable Distributed Aggregation Functions</title>
<link>https://eprint.iacr.org/2023/130</link>
<guid>https://eprint.iacr.org/2023/130</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、可验证分布式聚合函数(VDAFs)、隐私保护、Prio3、Doplar

总结:
本文提出了一种分析可验证分布式聚合函数（VDAFs）的正式框架，并将其应用于两个构建。首先是对IETF标准化候选之一的Prio3进行分析，证明了通过微调草案，Prio3能够实现所设定的安全目标。其次，本文引入了一个名为Doplar的新构建，它是对Boneh等人的Poplar系统的圆减少变体，旨在提高效率，但以增加整体带宽和计算成本为代价。Doplar作为Prio3的改进版本，进一步展示了多党计算在保护用户隐私的同时，能够有效地处理大规模数据聚合任务的能力。这些研究不仅为VDAFs提供了理论基础，也为未来标准化和实际应用提供了重要参考。 <div>
The modern Internet is built on systems that incentivize collection of information about users. In order to minimize privacy loss, it is desirable to prevent these systems from collecting more information than is required for the application. The promise of multi-party computation is that data can be aggregated without revealing individual measurements to the data collector. This work offers a provable security treatment for "Verifiable Distributed Aggregation Functions (VDAFs)", a class of multi-party computation protocols being considered for standardization by the IETF.

We propose a formal framework for the analysis of VDAFs and apply it to two constructions. The first is Prio3, one of the candidates for standardization. This VDAF is based on the Prio system of Corrigan-Gibbs and Boneh (NSDI 2017). We prove that Prio3 achieves our security goals with only minor changes to the draft. The second construction, called Doplar, is introduced by this paper. Doplar is a round-reduced variant of the Poplar system of Boneh et al. (IEEE S&amp;P 2021), itself a candidate for standardization. The cost of this improvement is a modest increase in overall bandwidth and computation.
]]></content:encoded>
<pubDate>Sat, 04 Feb 2023 02:48:49 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure BLS Threshold Signatures from DDH and co-CDH</title>
<link>https://eprint.iacr.org/2023/1553</link>
<guid>https://eprint.iacr.org/2023/1553</guid>
<content:encoded><![CDATA[
<div> 关键词：阈签名、BLS、适应性安全、DDH、共CDH

<br />
总结: 本文主要介绍了第一种基于随机原象模型（ROM）的适应性安全的阈值BLS签名方案，该方案依赖于非对称配对群中的DDH（Diffie-Hellman假设）和共CDH（Co-CDH）假设。此方案具有非交互式签名、与非阈值BLS验证兼容以及与Boldyreva方案相媲美的实用性，从而确保了其在实际应用中作为具有证明适应性安全性的候选方案的潜力。

文章首先指出，阈签名在分布式系统中扮演着重要角色，而BLS阈签名因其独特的属性（如唯一性和简洁性、非交互式签名过程和与非阈值BLS验证的一致性）而广受欢迎和应用。然而，直到最近，BLS阈签名的安全性仅被证明对于静态攻击者有效，且其安全性证明依赖于强且非标准的假设。

随后，文章介绍了一项突破，即Bacho和Loss提出的针对BLS阈签名的首个适应性安全证明，尽管他们需要依赖于一多离散对数（OMDL）的难度和代数组模型（AGM）等较强的非标准假设。这是适应性安全证明领域的重要进展。

文章的主要贡献在于提出了一种全新的适应性安全的阈值BLS签名方案，该方案仅依赖于DDH和共CDH假设，且在ROM中实现。这一创新不仅提高了方案的安全性，而且保持了与BLS签名相同的高效特性和与非阈值BLS验证的兼容性，使其成为实用性和安全性兼备的优选方案。

通过上述分析，本文不仅填补了适应性安全BLS阈签名在理论上的空白，还提供了实际应用中更为可靠和强大的安全基础，为分布式系统中关键信息的保护提供了更优的选择。 <div>
Threshold signatures are one of the most important cryptographic primitives in distributed systems. A popular choice of threshold signature scheme is the BLS threshold signature introduced by Boldyreva (PKC'03). Some attractive properties of Boldyreva's threshold signature are that the signatures are unique and short, the signing process is non-interactive, and the verification process is identical to that of non-threshold BLS. These properties have resulted in its practical adoption in several decentralized systems. However, despite its popularity and wide adoption, up until recently, the Boldyreva scheme has been proven secure only against a static adversary. Very recently, Bacho and Loss (CCS'22) presented the first proof of adaptive security for the Boldyreva scheme, but they have to rely on strong and non-standard assumptions such as the hardness of one-more discrete log (OMDL) and the Algebraic Group Model~(AGM). In this paper, we present the first adaptively secure threshold BLS signature scheme that relies on the hardness of DDH and co-CDH in asymmetric pairing groups in the Random Oracle Model~(ROM). Our signature scheme also has non-interactive signing, compatibility with non-threshold BLS verification, and practical efficiency like Boldyreva's scheme. These properties make our protocol a suitable candidate for practical adoption with the added benefit of provable adaptive security.
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 20:56:57 +0000</pubDate>
</item>
<item>
<title>On the Anonymity of One Authentication and Key Agreement Scheme for Peer-to-Peer Cloud</title>
<link>https://eprint.iacr.org/2024/1491</link>
<guid>https://eprint.iacr.org/2024/1491</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、伪匿名性、网络隐私、中等协议、关键同意方案

<br /><br />
总结:本文探讨了匿名性和伪匿名性的概念及其在网络通信中的应用。匿名性指的是用户完全不暴露其真实身份的状态，而伪匿名性则涉及使用可关联但不一定反映真实身份的虚构名称。两者都为用户提供了一定程度的隐私保护。文章指出，人们常常混淆这两种概念。进一步地，文章分析了一篇声称提供匿名性的中等协议的关键同意方案，发现实际上未能达到预期的匿名性效果。这表明在设计和实现网络通信系统时，需要更加精确地理解和应用匿名性和伪匿名性概念，以确保用户的隐私安全。 <div>
Peer-to-peer communication systems can provide many functions, including anonymized routing of network traffic, massive parallel computing environments, and distributed storage. Anonymity refers to the state of being completely nameless, with no attached identifiers. Pseudonymity involves the use of a fictitious name that can be consistently linked to a particular user, though not necessarily to the real identity. Both  provide a layer of privacy, shielding the user's true identity from public view. But we find their significations are often misunderstood. In this note, we clarify the differences between anonymity and pseudonymity. We also find the Zhong et al.'s key agreement scheme [IEEE TCC, 2022, 10(3), 1592-1603] fails to keep anonymity, not as claimed.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 01:48:22 +0000</pubDate>
</item>
<item>
<title>Adaptive Security, Erasures, and Network Assumptions in Communication-Local MPC</title>
<link>https://eprint.iacr.org/2024/1489</link>
<guid>https://eprint.iacr.org/2024/1489</guid>
<content:encoded><![CDATA[
<div> 关键词：可靠通信、安全通信、多对多通信、适应性安全、多方计算

<br /><br />总结:

本文主要探讨了低度网络环境下可靠和安全的全对全通信问题，这一问题对于基于本地通信的多方计算(MPC)和区块链协议中的点对点网络通信至关重要。文章首先揭示了一类称为存储转发协议的通信协议存在强不可实现性结果，这类协议包括了当前已知的所有基于标准密码假设的MPC协议。接着，在假设仅存在公钥基础设施(PKI)的情况下，文章证明了在多数诚实设置下，即使不假设多发消息的能力，也可以通过安全擦除机制构建具有多项式对数局部性的全对全通信协议。然而，在少数欺诈设置下，这一结果并不成立。

最后，文章在更加强大的假设条件下，即使用具有反向域采样的陷阱门置换、紧凑型恶意电路私有FHE等，构建了一个具有多项式对数局部性的全对一通信协议，该协议能够适应性地抵抗任意常数比例的破坏，无需假设安全擦除或多发消息能力。这一结果通过创新地结合了适应性安全加密与静态FHE来绕过Katz等人提出的关于紧凑型适应性安全FHE的不可能性，这一发现可能对独立研究者具有重要意义。

此外，文章还提出了子线性输出集全对全通信(SOS-RMT)，并展示了如何利用标准MPC的已知界限，通过额外的匿名PKI假设，将SOS-RMT应用于子线性输出集MPC(SOS-MPC)。这一系列发现丰富了全对全通信和适应性安全MPC的研究领域，并为构建更加高效、安全的网络通信和计算协议提供了理论基础。 <div>
The problem of reliable/secure all-to-all communication over low-degree networks has been essential for communication-local (CL) n-party MPC (i.e., MPC protocols where every party directly communicates only with a few, typically polylogarithmic in n, parties) and more recently for communication over ad hoc networks, which are used in blockchain protocols. However, a limited number of adaptively secure solutions exist, and they all make relatively strong assumptions on the ability of parties to act in some specific manner before the adversary can corrupt them. Two such assumptions were made in the work of Chandran et al. [ITCS ’15]---parties can (a) multisend messages to several receivers simultaneously; and (b) securely erase the message and the identities of the receivers, before the adversary gets a chance to corrupt the sender (even if a receiver is corrupted). A natural question to ask is: Are these assumptions necessary for adaptively secure CL MPC? In this paper, we characterize the feasibility landscape for all-to-all reliable message transmission (RMT) under these two assumptions, and use this characterization to obtain (asymptotically) tight feasibility results for CL MPC.

– First, we prove a strong impossibility result for a broad class of RMT protocols, termed here store-and-forward protocols, which includes all known communication protocols for CL MPC from standard cryptographic assumptions. Concretely, we show that no such protocol with a certain expansion rate can tolerate a constant fraction of parties being corrupted.

– Next, under the assumption of only a PKI, we show that assuming secure erasures, we can obtain an RMT protocol between all pairs of parties with polylogarithmic locality (even without assuming multisend) for the honest majority setting. We complement this result by showing a negative result for the setting of dishonest majority.

– Finally, and somewhat surprisingly, under stronger assumptions (i.e., trapdoor permutations with a reverse domain sampler, and compact and malicious circuit-private FHE), we construct a polylogarithmic-locality all-to-one RMT protocol, which is adaptively secure and tolerates any constant fraction of corruptions, without assuming either secure erasures or multisend. This last result uses a novel combination of adaptively secure (e.g., non-committing) encryption and (static) FHE to bypass the impossibility of compact adaptively secure FHE by Katz et al. [PKC’13], which we believe may be of independent interest. Intriguingly, even such assumptions do not allow reducing all-to-all RMT to all-to-one RMT (a reduction which is trivial in the non-CL setting). Still, we can implement what we call sublinear output-set RMT (SOS-RMT for short). We show how SOS-RMT can be used for SOS-MPC under the known bounds for feasibility of MPC in the standard (i.e., non-CL) setting assuming, in addition to SOS-RMT, an anonymous PKI.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 21:45:57 +0000</pubDate>
</item>
<item>
<title>Distributing Keys and Random Secrets with Constant Complexity</title>
<link>https://eprint.iacr.org/2024/876</link>
<guid>https://eprint.iacr.org/2024/876</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Secret Sharing Generation、Distributed Key Generation、Communication Complexity、Public Bulletin Board、Near-threshold Setting

总结:

本文研究了分布式秘密共享生成(Distributed Secret Sharing Generation, DSG)和分布式密钥生成(Distributed Key Generation, DKG)的通信复杂性。文章旨在探讨在不增长的通信量下实现这些功能的可能性，特别是通过利用公共公告板（如区块链账本）进行广播通信。

首先，作者提出了一种常数轮次的DSG/ DKG协议，其中每个参与者的通信量仅依赖于安全参数和字段大小，而与参与方数量无关。这一创新解决了现有解决方案中至少有部分参与者需要发送Ω(n)比特的问题。

其次，该协议适用于近阈值设置，允许容忍一定比例的主动被破坏参与者，同时根据特定的隐私性和正确性参数生成随机秘密的共享。通过使用非交互式零知识证明、非交互式承诺和基于低密度校验码的新秘密共享方案的特殊鲁棒性，实现这一目标。

此外，文章还扩展了基于多方计算的DSG/ DKG处理方法，探讨了线性秘密共享方案的新方面，从而为加密货币和区块链应用提供了更高效的解决方案。 <div>
In the *Distributed Secret Sharing Generation* (DSG) problem $n$ parties wish to obliviously sample a secret-sharing of a random value $s$ taken from some finite field, without letting any of the parties learn $s$. *Distributed Key Generation* (DKG) is a closely related variant of the problem in which, in addition to their private shares, the parties also generate a public ``commitment'' $g^s$ to the secret. Both DSG and DKG are central primitives in the domain of secure multiparty computation and threshold cryptography. 

In this paper, we study the communication complexity of DSG and DKG. Motivated by large-scale cryptocurrency and blockchain applications, we ask whether it is possible to obtain protocols in which the communication per party is a constant that does not grow with the number of parties. We answer this question to the affirmative in a model where broadcast communication is implemented via a public bulletin board (e.g., a ledger). Specifically, we present a constant-round DSG/DKG protocol in which the number of bits that each party sends/receives from the public bulletin board is a constant that depends only on the security parameter and the field size but does not grow with the number of parties $n$. In contrast, in all existing solutions at least some of the parties send $\Omega(n)$ bits.

Our protocol works in the near-threshold setting. Given arbitrary privacy/correctness parameters $0<\tau_p<\tau_c<1$, the protocol tolerates up to $\tau_p n$ actively corrupted parties and delivers shares of a random secret according to some $\tau_p n$-private $\tau_c n$-correct secret sharing scheme, such that the adversary cannot bias the secret or learn anything about it. The protocol is based on non-interactive zero-knowledge proofs, non-interactive commitments and a novel secret-sharing scheme with special robustness properties that is based on Low-Density Parity-Check codes. As a secondary contribution, we extend the formal MPC-based treatment of DKG/DSG, and study new aspects of Affine Secret Sharing Schemes.
]]></content:encoded>
<pubDate>Sun, 02 Jun 2024 08:36:48 +0000</pubDate>
</item>
<item>
<title>On Security Proofs of Existing Equivalence Class Signature Schemes</title>
<link>https://eprint.iacr.org/2024/183</link>
<guid>https://eprint.iacr.org/2024/183</guid>
<content:encoded><![CDATA[
<div> 关键词：Equivalence class signatures, 原始构造, 安全性证明, 通用组模型, 参数化非交互式困难假设

总结:
文章探讨了等价类签名(EQS)的安全性及其在不同模型下的适用性。等价类签名是一种独特的公钥加密技术，允许任何实体将对向量元素的签名转换为该向量任何倍数的签名，从而认证等价类。文章指出，原始的EQS构造在通用组模型下具有安全性，而第一个基于标准假设的方案则仅满足较弱的安全模型，不适用于大多数应用。后续研究提出了适用于实际应用的方案，但其安全性证明存在瑕疵。

文章的关键发现是，这些被质疑的方案可能在代数组模型下证明安全，但作者通过引入参数化的非交互式困难假设，展示了原始的更高效、已广泛应用于多个领域的EQS构造实际上在代数组模型下也是安全的。这一发现对于理解等价类签名的安全性及其在不同模型下的适用性提供了新的见解，对于未来的研究和应用具有重要意义。 <div>
Equivalence class signatures (EQS; Asiacrypt '14), sign vectors of elements from a bilinear group.   Anyone can transform a signature on a vector to a signature on any multiple of that vector; signatures thus authenticate equivalence classes.  A transformed signature/message pair is indistinguishable from a random signature on a random message.  EQS have been used to efficiently instantiate (delegatable) anonymous credentials, (round-optimal) blind signatures, ring and group signatures, anonymous tokens and contact-tracing schemes, to name a few.

The original EQS construction (J. Crypto '19) is proven secure in the generic group model, and the first scheme from standard assumptions (PKC '18) satisfies a weaker model insufficient for most applications.  Two works (Asiacrypt '19, PKC '22) propose applicable schemes that assume trusted parameters.  Their unforgeability is argued via a security proof from standard (or non-interactive) assumptions.
   
We show that their security proofs are flawed and explain the subtle issue.  While the schemes might be provable in the algebraic group model (AGM), we instead show that the original construction, which is more efficient and has found applications in many works, is secure in the AGM under a parametrized non-interactive hardness assumption.
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 08:24:24 +0000</pubDate>
</item>
<item>
<title>Signature-based Witness Encryption with Compact Ciphertext</title>
<link>https://eprint.iacr.org/2024/1477</link>
<guid>https://eprint.iacr.org/2024/1477</guid>
<content:encoded><![CDATA[
<div> 关键词：Signature-based witness encryption (SWE), 拆解, indistinguishability obfuscation (iO), strongly puncturable signatures (SPS), 指数级增长

总结: 文章探讨了签名基于见证加密(Signature-based witness encryption, SWE)这一新颖概念及其在分布式系统中的潜在应用。SWE允许将消息加密为特定标签和一组验证密钥集，只有持有至少k个有效签名和k个不同验证密钥的实体才能解密。然而，现有的无可信设置的SWE方案存在一个关键问题——其密文大小与验证密钥数量呈线性关系，这在系统变得更加分布化且参与方数量增加时成为瓶颈。

针对这一挑战，文章提出了一种基于图灵机不可区分混淆化(Indistinguishability Obfuscation, iO)和强可中断签名(Strongly Puncturable Signatures, SPS)的SWE构造方法。这种方法旨在实现密文大小与验证密钥数量之间的关系为次线性，从而解决指数级增长的问题，为分布式系统如区块链等提供更高效、灵活的安全加密解决方案。通过引入这些高级安全工具，该方案不仅能够维持安全性，还能显著减少密文大小，提高系统的可扩展性和性能。 <div>
Signature-based witness encryption (SWE) is a recently proposed notion that allows to encrypt a message with respect to a tag $T$ and a set of signature verification keys. The resulting ciphertext can only be decrypted by a party who holds at least $k$ different valid signatures w.r.t. $T$ and $k$ different verification keys out of the $n$ keys specified at encryption time. Natural applications of this primitive involve distributed settings (e.g., blockchains), where multiple parties sign predictable messages, such as polling or randomness beacons. However, known SWE schemes without trusted setup have ciphertexts that scale linearly in the number of verification keys. This quickly becomes a major bottleneck as the system gets more distributed and the number of parties increases.
    
    Towards showing the feasibility of SWE with ciphertext size sub-linear in the number of keys, we give a construction based on indistinguishability obfuscation (iO) for Turing machines and strongly puncturable signatures (SPS).
]]></content:encoded>
<pubDate>Sat, 21 Sep 2024 00:31:24 +0000</pubDate>
</item>
<item>
<title>Isogeny-Based Secure Voting Systems for Large-Scale Elections</title>
<link>https://eprint.iacr.org/2024/1472</link>
<guid>https://eprint.iacr.org/2024/1472</guid>
<content:encoded><![CDATA[
<div> 关键词：是生成法、电子投票系统、量子攻击、隐私保护、安全性证明

总结:
本文深入研究了基于是生成法的加密方法，旨在开发既安全又可扩展的电子投票系统。文章着重解决关键挑战，包括选民隐私、投票完整性以及对量子攻击的抵抗能力。通过引入利用是生成法的新型加密协议，建立了适用于大规模选举的后量子安全电子投票框架。

数学基础、协议设计和安全性证明的详细说明，展示了所提议系统的有效性和可扩展性。这些措施确保了在大型选举中的应用，同时保证了选民隐私和投票的完整性，同时也为抵御潜在的量子计算威胁提供了坚实的基础。通过这些创新，文章为电子投票系统的未来发展提供了重要的理论和技术支撑，为未来的选举提供了一种更加安全、可靠和私密的解决方案。 <div>
This article presents an in-depth study of isogeny-based cryptographic methods for the development of secure and scalable electronic voting systems. We address critical challenges such as voter privacy, vote integrity, and resistance to quantum attacks. Our work introduces novel cryptographic protocols leveraging isogenies, establishing a robust framework for post-quantum secure electronic voting. We provide detailed mathematical foundations, protocol designs, and security proofs, demonstrating the efficacy and scalability of our proposed system in large-scale elections.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 13:26:02 +0000</pubDate>
</item>
<item>
<title>Communication Efficient Secure and Private Multi-Party Deep Learning</title>
<link>https://eprint.iacr.org/2024/1471</link>
<guid>https://eprint.iacr.org/2024/1471</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式训练、模型联合训练、安全性、隐私保护、差分隐私

总结:
本文探讨了在多参与方各自数据分布的情况下进行模型联合训练的方法，以应对大型多样数据集带来的挑战。然而，这种策略立即引发了安全性和隐私性问题，涉及各参与方保护其数据不被其他方获取，以及防止在训练后通过各种推理攻击泄露私人信息。为同时解决这些问题，本文设计了一种高效地结合了差分隐私与多方计算技术的DP-MPC协议，用于联合训练多参与方数据中的模型。

在两方设置中，我们的DP-MPC协议在通信效率上比以往同类协议提高了56-794倍，速度上快了16-182倍。理论和实践上，本文简化并改进了之前尝试将安全多方计算和差分隐私技术相结合的方法，特别是在机器学习训练领域的应用。通过优化算法设计和提升通信效率，我们的方案显著降低了训练过程中的资源消耗，同时确保了数据的安全性和隐私保护，为多参与方合作训练模型提供了一种更可靠、更高效的解决方案。 <div>
Distributed training that enables multiple parties to jointly train
a model on their respective datasets is a promising approach to
address the challenges of large volumes of diverse data for training
modern machine learning models. However, this approach immedi-
ately raises security and privacy concerns; both about each party
wishing to protect its data from other parties during training and
preventing leakage of private information from the model after
training through various inference attacks. In this paper, we ad-
dress both these concerns simultaneously by designing efficient
Differentially Private, secure Multiparty Computation (DP-MPC)
protocols for jointly training a model on data distributed among
multiple parties. Our DP-MPC protocol in the two-party setting
is 56-794× more communication-efficient and 16-182× faster than
previous such protocols. Conceptually, our work simplifies and
improves on previous attempts to combine techniques from secure
multiparty computation and differential privacy, especially in the
context of ML training.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 04:51:34 +0000</pubDate>
</item>
<item>
<title>P2C2T: Preserving the Privacy of Cross-Chain Transfer</title>
<link>https://eprint.iacr.org/2024/1467</link>
<guid>https://eprint.iacr.org/2024/1467</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数字货币、隐私保护、跨链传输、原子性

总结: 

本文主要探讨了区块链技术在数字货币系统中的应用及其挑战。首先指出，当前的区块链数字货币系统在互操作性方面存在不足，这导致资产跨系统转移变得复杂且不安全。为解决这一问题，作者提出了一种名为P2C2T（Peer-to-Chain-to-Target）的隐私保护跨链传输方案。该方案基于“阈值匿名原子锁”（TA²L），能够确保跨链交易的原子性、不可链接性、不可区分性和无需抵押，同时对底层区块链的要求较低。

P2C2T通过结合“可验证时间离散对数”方案，使得跨链交易在安全性和性能上与常规的链内交易相匹配。特别地，它消除了发送方的抵押要求，并仅需要底层区块链具备签名验证能力。为了证明TA²L的安全性，作者引入了“阈值盲条件签名”的概念，并通过必要的证明展示了P2C2T的整体安全性。

此外，作者还对比了P2C2T与现有最接近的方案，在运行时间、通信成本和存储成本上，P2C2T至少降低了85.488%，并提供了实际案例来展示其隐私性和实用性。通过使用比特币测试网和Litecoin测试网进行的跨链和链内转账实验，证实了P2C2T的有效性和高效性。 <div>
Blockchain-enabled digital currency systems have typically operated in isolation, lacking necessary mechanisms for seamless interconnection. Consequently, transferring assets across distinct currency systems remains a complex challenge, with existing schemes often falling short in ensuring security, privacy, and practicality. This paper proposes P2C2T -- a privacy-preserving cross-chain transfer scheme. It is the first scheme to address atomicity, unlinkability, indistinguishability, non-collateralization, and required functionalities across diverse currency systems. P2C2T is based on \textit{threshold anonymous atomic locks} (TA$^2$L), also proposed by us, serving as the cornerstone for guaranteeing atomic cross-chain transfer while obscuring the payment relationships between users. By combining TA$^2$L with \textit{verifiable timed discrete logarithm} schemes, P2C2T renders cross-chain transactions indistinguishable from regular intra-chain ones. Notably, P2C2T eliminates the collateralization of senders and imposes minimal requirements on underlying blockchains, specifically on the ability to verify signatures. We substantiate the security of TA$^2$L based on a proposed cryptographic notion called \textit{threshold blind conditional signatures} and demonstrate the security of P2C2T through necessary proofs. Additionally, we compare the performance of P2C2T with an existing scheme that has properties closest to P2C2T. The comparison reveals that P2C2T reduces overhead by at least $85.488\%$ in terms of running time, communication cost, and storage cost when completing a cross-chain transfer. We further conduct cross-chain transfers and intra-chain payments using the Bitcoin testnet and Litecoin testnet to illustrate the privacy and practicality of P2C2T.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 13:21:42 +0000</pubDate>
</item>
<item>
<title>SoK: Descriptive Statistics Under Local Differential Privacy</title>
<link>https://eprint.iacr.org/2024/1464</link>
<guid>https://eprint.iacr.org/2024/1464</guid>
<content:encoded><![CDATA[
<div> 关键词：Local Differential Privacy、系统化、比较、实证研究、推荐

总结: 本文首先对局部差分隐私（LDP）方法进行了系统化的概述，对比了它们的特性和需求。发现基于伯努利分布采样的多个均值估计方法在一维情况下是等价的，并引入了方差估计的方法。接下来，文章通过实证研究比较了用于均值、方差和频率估计的LDP方法。最后，文章提供了使用LDP方法进行描述性统计的建议，并讨论了其局限性和未解决的问题。

通过系统的比较和实证研究，本文为理解和选择适用于描述性统计分析的LDP方法提供了宝贵的指导。它揭示了一些等效的方法，为实践者节省了资源，并通过实验数据验证了这些方法的有效性。同时，它也指出了当前方法的局限性和需要进一步探索的领域，例如频率估计方法的优化以及多维数据处理的挑战。这些发现不仅有助于提高数据保护和隐私计算的效率，也为未来的研究提供了方向。 <div>
Local Differential Privacy (LDP) provides a formal guarantee of privacy that enables the collection and analysis of sensitive data without revealing any individual's data. While LDP methods have been extensively studied, there is a lack of a systematic and empirical comparison of LDP methods for descriptive statistics. In this paper, we first provide a systematization of LDP methods for descriptive statistics, comparing their properties and requirements. We demonstrate that several mean estimation methods based on sampling from a Bernoulli distribution are equivalent in the one-dimensional case and introduce methods for variance estimation. We then empirically compare methods for mean, variance, and frequency estimation. Finally, we provide recommendations for the use of LDP methods for descriptive statistics and discuss their limitations and open questions.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 09:11:51 +0000</pubDate>
</item>
<item>
<title>Asynchronous Verifiable Secret Sharing with Elastic Thresholds and Distributed Key Generation</title>
<link>https://eprint.iacr.org/2024/1463</link>
<guid>https://eprint.iacr.org/2024/1463</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Key Generation（DKG）、Asynchronous Distributed Key Generation（ADKG）、Elastic Threshold、Verifiable Secret Sharing Protocol、Simultaneous Commitments

<br />
<br />总结:

本文提出了一种具有弹性阈值的异步可验证秘密共享协议，该协议允许经销商与总共有n个参与方的情况下共享最多t+1个秘密，其中n ≥ 3f+1且f是最大恶意节点数。协议的主要贡献在于它将秘密分享的弹性阈值从固定的f或2f扩展到范围内的任意值，同时保持了较低的通信复杂度O(λn^3)，其中λ是安全参数。此外，通过修改Schnorr协议，实现了对多个秘密的并发承诺，我们称之为m-Schnorr。这种改进不仅提高了协议的灵活性，还优化了通信效率，对于构建更高效和安全的分布式系统具有重要意义。

<br /> <div>
Distributed Key Generation (DKG) is a technique that enables the generation of threshold cryptography keys among a set of mutually untrusting nodes. DKG generates keys for a range of decentralized applications such as threshold signatures, multiparty computation, and Byzantine consensus. Over the past five years, research on DKG has focused on optimizing network communication protocols to improve overall system efficiency by reducing communication complexity. However, SOTA asynchronous distributed key generation (ADKG) schemes (e.g., Kokoris-Kogias ADKG, CCS 2020 and Das ADKG, S\&amp;P 2022, and others) only support recovery thresholds of either $f$ or $2f$, where $f$ is the maximum number of malicious nodes. This paper proposes an asynchronous verifiable secret sharing protocol featuring an elastic threshold, where $t \in [f,n-f-1]$ and $n \ge 3f+1$ is the total number of parties. Our protocol enables a dealer to share up to $t+1$ secrets with a total communication cost of O($\lambda n^3$), where $\lambda$ is the security parameter, and the protocol relies on the hardness of the $q$-SDH problem. We further modified the Schnorr protocol to enable simultaneous commitments to multiple secrets, which we refer to $m$-Schnorr.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 07:45:10 +0000</pubDate>
</item>
<item>
<title>PPSA: Polynomial Private Stream Aggregation for Time-Series Data Analysis</title>
<link>https://eprint.iacr.org/2024/1460</link>
<guid>https://eprint.iacr.org/2024/1460</guid>
<content:encoded><![CDATA[
<div> 关键词：PPSA、Private Polynomial Stream Aggregation、数据隐私、聚合函数、低延迟

本文介绍了一种名为PPSA（Private Polynomial Stream Aggregation）的新协议，该协议允许在不受信任的聚合器存在的情况下，对用户数据流进行任意多项式函数的私密计算。与之前的最佳实践相比，PPSA不依赖于可信硬件或预设的信任方，仅利用密码学和差分隐私工具即可实现这一目标。实验结果表明，PPSA在加密和聚合过程中的延迟非常低，分别仅为10.5毫秒和21.6毫秒，对于1000名用户而言，这一性能相较于现有最佳方案快了138倍。

总结: PPSA协议提供了一种高效且私密的数据聚合方法，无需依赖于可信硬件，仅使用基本的密码学和差分隐私技术，就能实现对用户数据流的多项式函数计算。其显著优势在于低延迟的加密与聚合过程，相较于当前最佳实践，速度提升幅度高达138倍，为大规模数据处理提供了更高效、更安全的解决方案。 <div>
Modern data analytics requires computing functions on streams of data points from many users that are challenging to calculate, due to both the high scale and nontrivial nature of the computation at hand. The need for data privacy complicates this matter further, as general-purpose privacy-enhancing technologies face limitations in at least scalability or utility. Existing work has attempted to improve this by designing purpose-built protocols for the use case of Private Stream Aggregation; however, prior work lacks the ability to compute more general aggregative functions without the assumption of trusted parties or hardware.

In this work, we present PPSA, a protocol that performs Private Polynomial Stream Aggregation, allowing the private computation of any polynomial function on user data streams even in the presence of an untrusted aggregator. Unlike previous state-of-the-art approaches, PPSA enables secure aggregation beyond simple summations without relying on trusted hardware; it utilizes only tools from cryptography and differential privacy. Our experiments show that PPSA has low latency during the encryption and aggregation processes with an encryption latency of 10.5 ms and aggregation latency of 21.6 ms for 1000 users, which are up to 138$\times$ faster than the state-of-the-art prior work.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 16:32:23 +0000</pubDate>
</item>
<item>
<title>GoAT: File Geolocation via Anchor Timestamping</title>
<link>https://eprint.iacr.org/2021/697</link>
<guid>https://eprint.iacr.org/2021/697</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized存储系统、Proof of Geo-Retrievability（PoGeoRet）、GoAT、时间戳服务器、互联网物理约束

总结:
文章主要介绍了Proof of Geo-Retrievability（PoGeoRet）和GoAT，这是一种新的证明机制，旨在证明文件位于特定地理边界内。PoGeoRet通过确保文件复制分布在不同的地理位置来增强去中心化存储系统的鲁棒性。GoAT是一种实现这一目标的实际方案，它利用互联网上的任何具有固定已知位置的时间戳服务器作为地理定位锚点，提供可靠的地理定位保证。

GoAT通过创新地使用通信效率高的Proof-of-Retrievability（PoRet）方案来实现其证明，使得PoRet组件的大小保持常数。这不仅确保了数据的可访问性，还提高了验证过程的效率。

为了验证GoAT的实用性，文章进行了一项初步的测量研究，以寻找可用的锚点，并执行了一个实地实验。结果显示，互联网的很大一部分可以作为锚点使用，GoAT能够实现低至500公里的地理定位半径。

综上所述，PoGeoRet和GoAT为去中心化存储系统提供了地理定位证明，通过利用互联网物理约束提供可靠保障，同时通过优化技术提高验证效率，从而增强了数据存储的安全性和可靠性。 <div>
Decentralized storage systems are a crucial component of the rapidly growing blockchain ecosystem. They aim to achieve robustness by proving that they store multiple replicas of every file. They have a serious limitation, though: They cannot prove that file replicas are spread across distinct systems, e.g., different hard drives. Consequently, files are vulnerable to loss in a single, locally catastrophic event.

We introduce a new primitive, Proof of Geo-Retrievability or PoGeoRet, that proves that a file is located within a strict geographic boundary. Using PoGeoRet, one can, for example, prove that a file is spread across several distinct geographic regions---and by extension across multiple systems, e.g., hard drives. We define what it means for a PoGeoRet scheme to be complete and sound, extending prior formalism in key ways. 

We also propose GoAT, a practical PoGeoRet scheme to prove file geolocation. Unlike previous geolocation systems that only offer nominal geolocation guarantees and require dedicated anchors, GoAT geolocates provers using any timestamping server on the internet with a fixed, known location as a geolocation anchor.
GoAT's geolocation guarantees directly depend on the physical constraints of the internet, making them very reliable. 
GoAT internally uses a communication-efficient Proof-of-Retrievability (PoRet) scheme in a novel way to achieve constant-size PoRet-component in its proofs.

We validate GoAT's practicality by conducting an initial measurement study to find usable anchors and perform a real-world experiment. The results show that a significant fraction of the internet can be used as anchors and that GoAT achieves geolocation radii as low as 500km.
]]></content:encoded>
<pubDate>Fri, 28 May 2021 09:14:42 +0000</pubDate>
</item>
<item>
<title>Proofs of Space with Maximal Hardness</title>
<link>https://eprint.iacr.org/2023/1530</link>
<guid>https://eprint.iacr.org/2023/1530</guid>
<content:encoded><![CDATA[
<div> 关键词：证明空间、计算复杂性、安全目标、深度鲁棒图、预后鲁棒图

总结:

本文提出了一种新型的证明空间构造方法，旨在确保在证明者试图节省任意小比例存储空间时，必须重做几乎全部原始复杂计算的大部分部分。这种方法的实现是通过将现有的SDR（Fisch, Eurocrypt 2019）构造进行扩展和优化完成的，这种优化不仅保持了通用性，还展示了已经部署的SDR构造在安全性方面具有比先前显示的更好的性能。

该构造的核心技术在于对预后鲁棒图的增强利用。预后鲁棒图是一种特殊的有向无环图，其中任何足够相对大小的子图都包含一个相对较大的单一汇节点连接组件。文章通过构建一个更大的预后鲁棒图，不仅优化了参数设置，还增强了关于汇节点位置的额外保证，同时仅通过增加很小的常数来提高度数。这种方法实现了几乎完全的计算复原，显著提高了证明空间的安全性。 <div>
In a proof of space, a prover performs a complex computation with a large output. A verifier periodically checks that the prover still holds the output. The security goal for a proof of space construction is to ensure that a prover who erases even a portion of the output has to redo a large portion of the complex computation in order to satisfy the verifier.

In existing constructions of proofs of space, the computation that a cheating prover is forced to redo is a small fraction (vanishing or small constant) of the original complex computation. The only exception is a construction of Pietrzak (ITCS 2019) that requires extremely depth-robust graphs, which result in impractically high complexity of the initialization process.

We present the first proof of space of reasonable complexity that ensures that the prover has to redo almost the entire computation (fraction arbitrarily close to 1) when trying to save even an arbitrarily small constant fraction of the space. 
Our construction is a generalization of an existing construction called SDR (Fisch, Eurocrypt 2019) deployed on the Filecoin blockchain. Our improvements, while general, also demonstrate that the already deployed construction has considerably better security than previously shown.

Technically, our construction can be viewed as amplifying predecessor-robust graphs. These are directed acyclic graphs in which every subgraph of sufficient relative size $\pi$ contains a large single-sink connected component of relative size $\alpha_\pi$. We take a predecessor-robust graph with constant parameters $(\pi, \alpha_\pi)$, and build a bigger predecessor-robust graph with a near-optimal set of parameters and additional guarantees on sink placement, while increasing the degree only by a small additive constant.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 18:02:28 +0000</pubDate>
</item>
<item>
<title>Interactive Threshold Mercurial Signatures and Applications</title>
<link>https://eprint.iacr.org/2024/625</link>
<guid>https://eprint.iacr.org/2024/625</guid>
<content:encoded><![CDATA[
<div> 关键词：Mercurial Signatures、Interactive Threshold、Class-Hiding Property、Multi-party、Privacy

总结:
本文主要研究了Mercurial签名的交互阈值版本，旨在解决其原始设计中存在的隐私问题。Mercurial签名是一种允许消息和签名在公共密钥类中进行灵活操作的签名方案，但当前最有效实现存在公共密钥类隐藏性不足的问题，使得原始签名者能够关联同一类中的公钥，对隐私构成威胁。

文章提出了两种基于交互的双方和多方Mercurial签名构造方法。这些构造避免了复杂分布式计算，如随机数生成、求逆和乘法，甚至不需要双方间的私密通信。其中一个构造基于通用多方计算的蓝图，结合了验证秘密共享技术，同时进行了优化。

文中展示了在匿名凭证系统中的应用实例，特别是对于双发情况，该方法通过彻底去除权威机构的信任需求，提供了更强的隐私保护。此外，文章还讨论了盲签名、多签、阈值环签名等更多应用领域。

最后，作者实施了这些交互构造，并与相关替代方案进行了比较，以展示其实用性。通过这种方式，Mercurial签名的隐私问题得到了有效解决，为实际应用提供了新的可能性。 <div>
Mercurial signatures are an extension of equivalence class signatures that allow malleability for the public keys, messages, and signatures within the respective classes. Unfortunately, the most efficient construction to date suffers from a weak public key class-hiding property, where the original signer with the signing key can link the public keys in the same class. This is a severe limitation in their applications, where the signer is often considered untrustworthy of privacy.

This paper presents two-party and multi-party interactive threshold mercurial signatures that overcome the above limitation by eliminating the single entity who knows the signing key. For the general case, we propose two constructions. The first follows the same interactive structure as the two-party case, avoiding complex distributed computations such as randomness generation, inversion, and multiplication, and even eliminates the need for private communication between parties. The second is based on a blueprint for general multi-party computation using verifiable secret sharing, but adopting optimizations.

We show applications in anonymous credential systems that individually fit the two-party and multi-party constructions. In particular, in the two-party case, our approach provides stronger privacy by completely removing the trust in the authorities. We also discuss more applications, from blind signatures to multi-signatures and threshold ring signatures.

Finally, to showcase the practicality of our approach, we implement our interactive constructions and compare them against related alternatives.
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 06:56:33 +0000</pubDate>
</item>
<item>
<title>Compute, but Verify: Efficient Multiparty Computation over Authenticated Inputs</title>
<link>https://eprint.iacr.org/2022/1648</link>
<guid>https://eprint.iacr.org/2022/1648</guid>
<content:encoded><![CDATA[
<div> 关键词：安全多方计算、输入认证、编译器、通信开销、计算开销

总结:本文提出了一个通用且高效的编译器，用于将基于线性秘密共享的诚实多数安全多方计算(MPC)协议转换为具有输入认证的协议。该编译器显著降低了计算成本和通信开销，与现有最佳解决方案相比，其通信开销仅为O(n log l)，而计算开销仅为每个参与者O(ℓ)组指数操作，而现有最佳解决方案的通信开销为O(n²)，计算开销为O(ℓn)。对于容忍度为t3的腐败阈值，该编译器保留了底层MPC协议的更强的可识别中断安全性，这是现有任何认证MPC解决方案都无法实现的，无论腐败阈值如何。

文章还涉及了几个独立的技术贡献，包括分布式知识证明的概念及其对多个常用数字签名方案和Pedersen承诺开证明等关系的具体实现。这些技术不仅支持了编译器的功能，而且对其他安全计算领域也有潜在的应用价值。 <div>
Traditional notions of secure multiparty computation (MPC) allow mutually distrusting parties to jointly compute a function over their private inputs, but typically do not specify how these inputs are chosen. Motivated by real-world applications where corrupt inputs could adversely impact privacy and operational legitimacy, we consider a notion of authenticated MPC where the inputs are authenticated, e.g., signed using a digital signature by some certification authority. We propose a generic and efficient compiler that transforms any linear secret sharing based honest-majority MPC protocol into one with input authentication.

Our compiler incurs significantly lower computational costs and competitive communication overheads when compared to the best existing solutions, while entirely avoiding the (potentially expensive) protocol-specific techniques and pre-processing requirements that are inherent to these solutions. For $n$-party honest majority MPC protocols with abort security where each party has $\ell$ inputs, our compiler incurs $O(n\log \ell)$ communication overall and a computational overhead of $O(\ell)$ group exponentiations per party (the corresponding overheads for the most efficient existing solution are $O(n^2)$ and $O(\ell n)$). Finally, for a corruption threshold $t3$, our compiler preserves the stronger identifiable abort security of the underlying MPC protocol. No existing solution for authenticated MPC achieves this regardless of the corruption threshold.

Along the way, we make several technical contributions that are of independent interest. This includes the notion of distributed proofs of knowledge and concrete realizations of the same for several relations of interest, such as proving knowledge of many popularly used digital signature schemes, and proving knowledge of opening of a Pedersen commitment.
]]></content:encoded>
<pubDate>Mon, 28 Nov 2022 06:38:29 +0000</pubDate>
</item>
<item>
<title>Attestation Proof of Association – provability that attestation keys are bound to the same hardware and person</title>
<link>https://eprint.iacr.org/2024/1444</link>
<guid>https://eprint.iacr.org/2024/1444</guid>
<content:encoded><![CDATA[
<div> 关键词：Wallet Trust Evidence (WTE), Proof of Association (PoA), European Digital Identity (EUDI) Wallet, cryptographic hardware, eIDAS Level of Assurance

<br /><br />
总结:

本文主要讨论了Wallet Trust Evidence（WTE）和与之相关的三个特定指令，旨在为欧洲数字身份(EUDI)钱包中的加密硬件提供指导。这些指令特别关注了证明关联（Proof of Association，PoA）的生成，允许EUDI钱包向第三方（发行者、依赖方）保证认证私钥不仅被绑定到符合标准的加密硬件上，还被绑定到相同的硬件设备上。这一举措使EUDI钱包能够达到eIDAS高安全等级的同时，也确保了隐私保护。

文中提出的方法不仅适用于基于全球平台的安全元素（如电子身份证或嵌入式SIM卡）等所有预期的EUDI钱包架构，还考虑到了它们的便利实施和通用标准认证（Common Criteria）。这进一步细化并具体化了由NI-Scy联盟与eIDAS专家小组合作开发的wallet架构和参考框架中关于WTE/PoA逻辑的描述，但请注意，当前文档仅为讨论稿，尚未获得NI-Scy联盟、eIDAS专家小组或荷兰政府的认可。 <div>
We propose a wallet provider issued attestation called Wallet Trust Evidence (WTE) and three related specific instructions for the European Digital Identity (EUDI) Wallet cryptographic hardware, most notably the generation of a Proof of Association (PoA). These allow the EUDI Wallet providing verifiable assurance to third parties (issuers, relying parties) that attestation private keys are not only bound to conformant cryptographic hardware but also that they are bound to the same such hardware. This allows the EUDI Wallet meeting eIDAS Level of Assurance ``high'' as well as operating in a privacy friendly manner. The instructions specified in this document cater for convenient implementation in all envisioned EUDI Wallet architectures including those based on a GlobalPlatform based Secure Element such as an eID-card or an embedded SIM (eSIM). By their simplicity, the three instructions also allow for convenient Common Criteria certification. This document is a further refinement and cryptographic concretization of the WTE/PoA logic specified in the wallet Architecture and Reference Framework (ARF), which is based on the EPIC-09 result developed in a cooperation between the NI-Scy consortium and the eIDAS expert group. However, the present draft document is meant for discussion only and not approved by the NI-Scy consortium, the eIDAS expert group or Dutch government.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 11:40:16 +0000</pubDate>
</item>
<item>
<title>SnarkFold: Efficient Proof Aggregation from Incrementally Verifiable Computation and Applications</title>
<link>https://eprint.iacr.org/2023/1946</link>
<guid>https://eprint.iacr.org/2023/1946</guid>
<content:encoded><![CDATA[
<div> 关键词：SnarkFold、SNARK、证明聚合、常数验证时间、折迭方案

总结: 
本文介绍了一种新型的SNARK证明聚合方案——SnarkFold。SnarkFold旨在解决现有区块链系统中独立验证每个证明导致的节点负担过重和用户交易费用高昂的问题。它通过引入一种基于增量可验证计算（IVC）的方法，并进一步优化以实现折迭方案，使得验证多条证明的时间和证明大小保持常数级。SnarkFold的核心创新在于将昂贵的SNARK验证过程，如椭圆曲线配对，推迟到最终步骤执行，从而显著提高验证效率。

此外，文章提出了一种通用技术，允许验证者将实例聚合任务委托给证明者，验证者仅需进行简单的预处理来检查委托的有效性。为了适应不同类型的SNARK证明，如Groth16和Plonk，作者还设计了特定的折迭方案。

实验结果表明，使用SnarkFold聚合Plonk证明的大小仅为0.5KB，验证4096个Plonk证明只需4.5ms，显示出显著的性能提升。这一方案为区块链系统的效率优化提供了有力支持，有望降低验证成本，提高整体性能。 <div>
The succinct non-interactive argument of knowledge (SNARK) technique has been extensively utilized in blockchain systems to replace the costly on-chain computation with the verification of a succinct proof. However, most existing applications verify each proof independently, resulting in a heavy load on nodes and high transaction fees for users. Currently, the mainstream proof aggregation schemes are based on a generalized inner product argument, which has a logarithmic proof size and verification cost. To improve the efficiency of verifying multiple proofs, we introduce SnarkFold, a novel SNARK-proof aggregation scheme with constant verification time and proof size. SnarkFold is derived from incrementally verifiable computation (IVC) and is optimized further through the folding scheme. By folding multiple instance-proof pairs, SnarkFold defers the expensive SNARK verification (e.g., elliptic curve pairing) to the final step. Additionally, we propose a generic technique to enhance the verifier's efficiency by delegating instance aggregation tasks to the prover. The verifier only needs a simple preprocessing to check the validity of the delegation. We further introduce folding schemes for Groth16 and Plonk proofs. Experimental results demonstrate that SnarkFold offers significant advantages, with an aggregated Plonk proof size of just $0.5$ KB and the verification time of only $4.5$ ms for aggregating 4096 Plonk proofs.
]]></content:encoded>
<pubDate>Fri, 22 Dec 2023 15:36:21 +0000</pubDate>
</item>
<item>
<title>Traffic-aware Merkle Trees for Shortening Blockchain Transaction Proofs</title>
<link>https://eprint.iacr.org/2024/1451</link>
<guid>https://eprint.iacr.org/2024/1451</guid>
<content:encoded><![CDATA[
<div> 关键词：Merkle树、区块链网络、交易处理、通信成本、智能合约

总结:本文主要研究了如何通过优化Merkle树结构和算法，以降低区块链网络中交易处理过程中的通信成本。通过分析典型交易特征，特别是多个账户共同参与的交易场景，作者提出了基于账户分布的通信成本下限理论。接着，他们设计了一套考虑流量模式的算法，旨在显著减少通信成本，该算法灵感来源于霍夫曼编码、分区与权重平衡等编码方法。此外，文章还扩展了方法以适应智能合约交易的复杂性，这些交易可能涉及任意数量的账户。为了验证方法的有效性，作者使用了真实区块链数据（以太坊网络）进行实验，结果显示对于支付交易和智能合约交易，该方法均能实现成本节省。 <div>
Merkle trees play a crucial role in blockchain networks in organizing network state. They allow proving a particular value of an entry in the state to a node that maintains only the root of the Merkle trees, a hash-based signature computed over the data in a hierarchical manner. Verification of particular state entries is crucial in reaching a consensus on the execution of a block where state information is required in the processing of its transactions. For instance, a payment transaction should be based on the balance of the two involved accounts. The proof length affects the network communication and is typically logarithmic in the state size. In this paper, we take advantage of typical transaction characteristics for better organizing Merkle trees to improve blockchain network performance. We focus on the common transaction processing where Merkle proofs are jointly provided for multiple accounts. We first provide lower bounds for the communication cost that are based on the distribution of accounts involved in the transactions. We then describe algorithms that consider traffic patterns for significantly reducing it. The algorithms are inspired by various coding methods such as Huffman coding, partition and weight balancing. We also generalize our approach towards the encoding of smart contract transactions that involve an arbitrary number of accounts. Likewise, we rely on real blockchain data to show the savings allowed by our approach. The experimental evaluation is based on transactions from the Ethereum network and demonstrates cost reduction for both payment transactions and smart contract transactions.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 15:17:44 +0000</pubDate>
</item>
<item>
<title>Randomness in Private Sequential Stateless Protocols</title>
<link>https://eprint.iacr.org/2024/1448</link>
<guid>https://eprint.iacr.org/2024/1448</guid>
<content:encoded><![CDATA[
<div> 关键词：信息论密码学、随机性复杂度、私密计算、分支程序、Private Sequential Stateless（PSS）模型

总结:

本文在信息论密码学领域对随机性在私密计算中的作用进行了深入研究。主要贡献如下：

1. **新模型与分类**：文章引入了Private Sequential Stateless（PSS）模型，探索了该模型下具有固定复杂度随机性的函数类别。这些函数被证明与具有常宽分支程序紧密相关。

2. **构造与转换**：通过构建一种新颖的PSS协议，针对所谓的“强正交分支程序”（SRBP），该文展示了任何具有常宽的分支程序都可以被转换为常宽的SRBP，从而证实了上述分类的一边。

3. **双向论证**：利用Kushilevitz等人在通信和随机性之间的转换思想，文章提供了从SRBP到具有固定复杂度随机性的函数的反向论证，完成了分类的双向证明。

4. **效率与实用性**：所提出的协议不仅结构简单，而且在理论上覆盖了具有小宽度、一次读取（或多次读取）的分支程序类函数，这在考虑1隐私时可能具有实际应用价值。

5. **改进与扩展**：作为结果的副产品，文章还提供了一种对Couteau和Rosén关于AND函数的协议的改进，虽然在随机性数量上没有提升，但在协议结构上实现了更简单的序列化和无状态化。

通过上述贡献，本文不仅深化了对随机性复杂度在私密计算中作用的理解，也为特定类型函数的私密计算提供了更高效、更实用的解决方案。 <div>
A significant body of work in information-theoretic cryptography has been devoted to the fundamental problem of understanding the power of randomness in private computation. This has included both in-depth study of the randomness complexity of specific functions (e.g., Couteau and Ros ́en, ASIACRYPT 2022, gives an upper bound of 6 for n-party $\mathsf{AND}$), and results for broad classes of functions (e.g., Kushilevitz et al. STOC 1996, gives an $O(1)$ upper bound for all functions with linear-sized circuits). In this work, we make further progress on both fronts by studying randomness complexity in a new simple model of secure computation called Private Sequential Stateless (PSS) model.
We show that functions with $O(1)$ randomness complexity in the PSS model are exactly those with constant-width branching programs, restricting to “speak-constant-times” protocols and to “read-constant-times” branching programs.
Towards this our main construction is a novel PSS protocol for “strongly regular branching programs” (SRBP). As we show, any constant-width branching program can be converted to a constant-width SRBP, yielding one side of our characterization. The converse direction uses ideas from Kushilevitz et al. to translate randomness to communication.
Our protocols are concretely efficient, has a simple structure, covers the broad class of functions with small-width, read-once (or read-a-few-times) branching programs, and hence may be of practical interest when 1-privacy is considered adequate. Also, as a consequence of our general result for SRBPs, we obtain an improvement over the protocol of Couteau and Ros ́en for $\mathsf{AND}$ in certain cases — not in terms of the number of bits of randomness, but in terms of a simpler protocol structure (sequential, stateless).
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 08:22:52 +0000</pubDate>
</item>
<item>
<title>Another Walk for Monchi</title>
<link>https://eprint.iacr.org/2024/1445</link>
<guid>https://eprint.iacr.org/2024/1445</guid>
<content:encoded><![CDATA[
<div> 关键词：Monchi、隐私保护、生物识别、同态加密、函数秘密共享

文章主要探讨了将Bassit等人的生物识别技术与Monchi协议相结合的方法。首先，文章提出了一种扩展的生物识别解决方案，该方案利用函数秘密共享来替代最终评分比较步骤中的同态乘法操作。其次，文章介绍了使用查找表计算评分的两方计算方法，该方法与函数秘密共享的评分比较相兼容。这些解决方案特别适用于Monchi协议中提出的登机流程场景。

文章的主要内容包括：

1. 将Bassit等人引入的评分计算技术与Monchi协议相结合，通过使用函数秘密共享来优化评分比较过程，以减少对同态乘法的需求。
2. 提出了一个使用查找表进行评分计算的两方计算方法，这种方法与函数秘密共享的评分比较方式协同工作，进一步增强了隐私保护。
3. 所提出的解决方案旨在适应Monchi协议中所描述的飞行登机场景，强调了在实际应用中如何实现高效和安全的生物特征识别系统。
4. 文章详细讨论了如何通过引入查找表和函数秘密共享来优化评分计算和比较过程，从而提高隐私保护级别和计算效率。
5. 最终目标是在不牺牲隐私的前提下，提供一种安全、高效、易于集成到现有登机流程中的生物识别解决方案。

总结: 通过将Bassit等人引入的评分计算技术与Monchi协议结合，文章提出了利用函数秘密共享优化评分比较过程的方法，并引入了查找表进行评分计算的两方计算，旨在提升生物识别系统的隐私保护水平和计算效率。这些解决方案特别适合于飞行登机场景，为实际应用提供了高效、安全的生物特征识别解决方案。 <div>
Monchi is a new protocol aimed at privacy-preserving biometric identification. It begins with scores computation in the encrypted domain thanks to homomorphic encryption and ends with comparisons of these scores to a given threshold with function secret sharing. We here study the integration in that context of scores computation techniques recently introduced by Bassit et al. that eliminate homomorphic multiplications by replacing them by lookup tables. First, we extend this lookup tables biometric recognition solution by adding the use of function secret sharing for the final comparison of scores. Then, we introduce a two-party computation of the scores with lookup tables which fits nicely together with the function secret sharing scores comparison. Our solutions accommodate well with the flight boarding use case introduced by Monchi.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 16:17:32 +0000</pubDate>
</item>
<item>
<title>FlashSwift: A Configurable and More Efficient Range Proof With Transparent Setup</title>
<link>https://eprint.iacr.org/2024/1441</link>
<guid>https://eprint.iacr.org/2024/1441</guid>
<content:encoded><![CDATA[
<div> 关键词：FlashSwift、DLOG、零知识证明、范围证明、透明设置

总结:

本文介绍了一种名为FlashSwift的新零知识范围证明方法，它基于离散对数(DLOG)假设，采用透明设置。FlashSwift在现有技术的基础上实现了更短的证明长度和显著的计算效率提升，特别是在常见范围内(N≤64)。它通过融合Flashproof和SwiftRange的技术，克服了两者之间的固有不兼容性。当N=64时，FlashSwift与Bulletproof在通信效率上相当，但在证明效率、验证效率上分别提高了2.3倍和1.65倍，与SwiftRange相比，提高了3.2倍和1.7倍。此外，FlashSwift在没有可信设置的情况下，创造了8位和16位范围内最小证明大小的新记录（289字节和417字节）。最重要的是，FlashSwift具有可配置性，允许用户根据不同的需求在通信效率和计算效率之间进行权衡。文章还提供了与其他最新技术的全面性能基准测试，以展示其实际应用的可行性。 <div>
Bit-decomposition-based zero-knowledge range proofs in the discrete logarithm (DLOG) setting with a transparent setup, e.g., Bulletproof (IEEE S\&amp;P \textquotesingle 18), Flashproof (ASIACRYPT \textquotesingle 22), and SwiftRange (IEEE S\&amp;P \textquotesingle 24), have garnered widespread popularity across various privacy-enhancing applications. These proofs aim to prove that a committed value falls within the non-negative range $[0, 2^N-1]$ without revealing it, where $N$ represents the bit length of the range. Despite their prevalence, the current implementations still suffer from suboptimal performance. Some exhibit reduced communication costs at the expense of increased computational costs while others experience the opposite. Presently, users are compelled to utilize these proofs in scenarios demanding stringent requirements for both communication and computation efficiency.

In this paper, we introduce, FlashSwift, a stronger DLOG-based logarithmic-sized alternative. It stands out for its greater shortness and significantly enhanced computational efficiency compared with the cutting-edge logarithmic-sized ones for the most common ranges where $N \leq 64$. It is developed by integrating the techniques from Flashproof and SwiftRange without using a trusted setup. The substantial efficiency gains stem from our dedicated efforts in overcoming the inherent incompatibility barrier between the two techniques. Specifically, when $N=64$, our proof achieves the same size as Bulletproof and exhibits 1.1$\times$ communication efficiency of SwiftRange. More importantly, compared with the two, it achieves $2.3\times$ and $1.65\times$ proving efficiency, and $3.2\times$ and $1.7\times$ verification efficiency, respectively. At the time of writing, our proof also creates two new records of the smallest proof sizes, 289 bytes and 417 bytes, for 8-bit and 16-bit ranges among all the bit-decomposition-based ones without requiring trusted setups. Moreover, to the best of our knowledge, it is the first {\em configurable} range proof that is adaptable to various scenarios with different specifications, where the configurability allows to trade off communication efficiency for computational efficiency. In addition, we offer a bonus feature: FlashSwift supports the aggregation of multiple single proofs for efficiency improvement. Finally, we provide comprehensive performance benchmarks against the state-of-the-art ones to demonstrate its practicality.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 08:17:02 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-of-Identity: Sybil-Resistant, Anonymous Authentication on Permissionless Blockchains and Incentive Compatible, Strictly Dominant Cryptocurrencies</title>
<link>https://eprint.iacr.org/2019/546</link>
<guid>https://eprint.iacr.org/2019/546</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、身份验证、区块链、挖矿、社会最优

总结: 文章提出了一种基于零知识证明的“零知识证明的身份验证”（zk-PoI）机制，旨在解决无许可区块链中存在的问题，如工作量证明（PoW）和权益证明（PoS）的高能耗、环境影响、资本囤积和交易量限制等。该机制允许每个人加入区块链网络并限制个人控制的挖矿节点数量，从而避免了完全去中心化的不可能性和区块链可扩展性三难困境。同时，文章论证了zk-PoI具有激励兼容的加密货币奖励发放协议、矿工选择其作为最优策略的纳什均衡和演化稳定策略、避免了加密无政府状态的价格损失、在流通量上优于其他PoW/PoS加密货币、以及从国家身份证和电子护照固有的社会网络中产生的网络效应优于其他加密货币。最后，由于其较低的基础设施成本，zk-PoI存在唯一的优势平衡点，使其成为其他支付形式的主导者。 <div>
Zero-Knowledge Proof-of-Identity from trusted public certificates (e.g., national identity cards and/or ePassports; eSIM) is introduced here to permissionless blockchains in order to remove the inefficiencies of Sybil-resistant mechanisms such as Proof-of-Work (i.e., high energy and environmental costs) and Proof-of-Stake (i.e., capital hoarding and lower transaction volume). The proposed solution effectively limits the number of mining nodes a single individual would be able to run while keeping membership open to everyone, circumventing the impossibility of full decentralization and the blockchain scalability trilemma when instantiated on a blockchain with a consensus protocol based on the cryptographic random selection of nodes. Resistance to collusion is also considered.
Solving one of the most pressing problems in blockchains, a zk-PoI cryptocurrency is proved to have the following advantageous properties:
- an incentive-compatible protocol for the issuing of cryptocurrency rewards based on a unique Nash equilibrium
- strict domination of mining over all other PoW/PoS cryptocurrencies, thus the zk-PoI cryptocurrency becoming the preferred choice by miners is proved to be a Nash equilibrium and the Evolutionarily Stable Strategy
- PoW/PoS cryptocurrencies are condemned to pay the Price of Crypto-Anarchy, redeemed by the optimal efficiency of zk-PoI as it implements the social optimum
- the circulation of a zk-PoI cryptocurrency Pareto dominates other PoW/PoS cryptocurrencies
- the network effects arising from the social networks inherent to national identity cards and ePassports dominate PoW/PoS cryptocurrencies
- the lower costs of its infrastructure imply the existence of a unique equilibrium where it dominates other forms of payment
]]></content:encoded>
<pubDate>Wed, 22 May 2019 11:23:04 +0000</pubDate>
</item>
<item>
<title>Non-interactive Blind Signatures: Post-quantum and Stronger Security</title>
<link>https://eprint.iacr.org/2024/614</link>
<guid>https://eprint.iacr.org/2024/614</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、非交互式盲签名（NIBS）、电路私有层化同态加密、后量子安全性、增强安全性

文章总结：

本文探讨了非交互式盲签名（NIBS）在设计更高效盲签名方案中的应用。非交互式盲签名允许接收者异步生成对任意接收者的部分签名，只有意图接收者才能从中提取出随机消息的盲签名。这一创新克服了传统盲签名的两轮交互限制，同时保持了广泛的应用能力。文章引用Hanzlik在Eurocrypt '23的贡献，展示了利用双线性对提供了新实用设计。

进一步地，作者提出了NIBS的增强安全性属性，并提供了一系列具有不同安全性和具体效率级别的构造。其中一种新颖的通用范式采用电路私有层化同态加密技术，以达到与任何非盲签名相同的最优大小签名，但需要较大的公钥。此外，文章还探索了具有后量子安全性的具体高效NIBS实现，满足了Hanzlik提出的较弱隐私水平要求。

此研究为构建更高效、安全的NIBS方案提供了理论基础和实践路径，对密码学领域尤其是非交互式通信和数据保护有着重要意义。通过结合先进加密技术与优化的安全策略，该工作不仅推动了NIBS理论的发展，也为实际应用提供了可能。 <div>
Blind signatures enable a receiver to obtain signatures on messages of its choice without revealing any message to the signer. Round-optimal blind signatures are designed as a two-round interactive protocol between a signer and receiver. Coincidentally, the choice of message is not important in many applications, and is routinely set as a random (unstructured) message by a receiver.

With the goal of designing more efficient blind signatures for such applications, Hanzlik (Eurocrypt '23) introduced a new variant called non-interactive blind signatures (NIBS). These allow a signer to asynchronously generate partial signatures for any recipient such that only the intended recipient can extract a blinded signature for a random message. This bypasses the two-round barrier for traditional blind signatures, yet enables many known applications. Hanzlik provided new practical designs for NIBS from bilinear pairings.

In this work, we propose new enhanced security properties for NIBS as well as provide multiple constructions with varying levels of security and concrete efficiency. We propose a new generic paradigm for NIBS from circuit-private leveled homomorphic encryption achieving optimal-sized signatures (i.e., same as any non-blind signature) at the cost of large public keys. We also investigate concretely efficient NIBS with post-quantum security, satisfying weaker level of privacy as proposed by Hanzlik.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 03:29:45 +0000</pubDate>
</item>
<item>
<title>Dishonest Majority Multiparty Computation over Matrix Rings</title>
<link>https://eprint.iacr.org/2023/1912</link>
<guid>https://eprint.iacr.org/2023/1912</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护机器学习、矩阵乘法、线性代数、多方计算、亚线性通信复杂度

总结:
本文提出了一种针对矩阵环的不诚实多数多方计算(MPC)协议，专门支持矩阵乘法和加法操作。该协议可视为SPDZ协议的变体，其秘密为一个m×m矩阵，密钥和认证码长度也为m。相较于经典SPDZ协议，新协议在安全计算矩阵乘法时的通信复杂度至少降低了m倍。与[16]中提出的针对矩阵运算的不诚实多数MPC协议相比，通信复杂度同样为O(m²n²logq)在预处理阶段和O(m²nlogq)在在线阶段。新协议的份额大小和乘法次数分别比[16]减少了约50%和40%，但采取了完全不同的方法。[16]协议使用BFV方案的变体将整个矩阵嵌入单个密文，并将矩阵操作视为密文内的元素级操作，而新协议则利用子域盲线性评估(VOLE)的变体进行安全计算，使得对于v∈F_q^b, x∈F_q^a，可以以亚线性通信复杂度计算v*x的共享值。此外，新协议易于扩展到小域。

文章的核心贡献在于提出了一个优化的MPC协议，旨在减少计算和通信成本，特别适用于大规模机器学习模型，如深度学习中的矩阵运算。通过引入子域盲线性评估技术，实现了在保持安全性的前提下，显著降低通信复杂度，提高了协议的效率。 <div>
The privacy-preserving machine learning (PPML) has gained growing importance over the last few years. One of the biggest challenges is to improve the efficiency of PPML so that the communication and computation costs of PPML are affordable for large machine learning models such as deep learning. As we know, linear algebra such as matrix multiplication occupies a significant part of the computation in deep learning such as deep convolutional neural networks (CNN). Thus, it is desirable to propose the MPC protocol specialized for the matrix operations. In this work, we propose a dishonest majority MPC protocol over matrix rings which supports matrix multiplication and addition. Our MPC protocol can be seen as a variant of SPDZ protocol, i.e., the MAC and global key of our protocol are vectors of length $m$ and the secret of our protocol is an $m\times m$ matrix. Compared to the classic SPDZ protocol, our MPC protocol reduces the communication complexity by at least $m$ times to securely compute a matrix multiplication. We also show that the communication complexity of our MPC protocol is asymptotically as good as [16] which also presented a dishonest majority MPC protocol specialized for matrix operations, i.e., the communication complexity of securely computing a multiplication gate is $O(m^2n^2\log q)$ in the preprocessing phase and $O(m^2n\log q)$ in the online phase. The share size and the number of multiplications of our protocol are reduced by around $50\%$ and $40\%$ of [16], respectively. However, we take a completely different approach. The protocol in [16] uses a variant of BFV scheme to embed a whole matrix into a single ciphertext and then treats the matrix operation as the entry-wise operation in the ciphertext while our approach resorts to a variant of vector linear oblivious evaluation (VOLE) called the subfield VOLE [33] which can securely compute the additive sharing of $v {\bf x}$ for $v\in \mathbb{F}_{q^b}, {\bf x}\in \mathbb{F}_q^a$ with sublinear communication complexity. Finally, we note that our MPC protocol can be easily extended to small fields.
]]></content:encoded>
<pubDate>Wed, 13 Dec 2023 06:32:33 +0000</pubDate>
</item>
<item>
<title>HierNet: A Hierarchical Deep Learning Model for SCA on Long Traces</title>
<link>https://eprint.iacr.org/2024/1437</link>
<guid>https://eprint.iacr.org/2024/1437</guid>
<content:encoded><![CDATA[
<div> 关键词：侧通道分析（SCA）、深度学习（DL）、长原始轨迹、特征选择、抗干扰性

总结:
本文探讨了侧通道分析（SCA）中的挑战及其解决策略。SCA通过利用诸如功率消耗、电磁辐射或时间变化等侧信道泄露来威胁现代数字系统的安全性和隐私。传统的SCA方法依赖于特征选择步骤，但这种方法可能受到掩码和抖动等防御措施的影响。为了解决这些问题，本文提出了一种基于深度学习的层次模型——HierNet，该模型能够处理长原始轨迹数据，并且具有对抗各种干扰措施的能力。

HierNet采用两级信息整合过程来提取信息：首先，低级的深度学习模型利用移不变特性从较小的轨迹段中提取信息；其次，高级的深度学习模型整合低级模型的输出以生成最终结果。实验结果显示，HierNet在处理长轨迹、对抗时钟抖动以及训练数据量较少的情况下均表现出色。与现有的SCA基准模型相比，HierNet在某些场景下表现出优越性，特别是在使用较少的训练样本达到特定性能目标时。这表明HierNet为SCA提供了一种新的、更有效的解决方案，特别是针对长轨迹和对抗多种防御措施的情况。 <div>
Side-channel analysis (SCA) compromises the security of cryptographic devices by exploiting various side-channel leakages such as power consumption, electromagnetic (EM) emanations, or timing variations, posing a practical threat to the security and privacy of modern digital systems. In power or EM SCA, statistical or machine learning methods are employed to extract secret information from power/EM traces. In many practical scenarios, raw power/EM traces can span hundreds of thousands of features, with relevant leakages occurring over only a few small segments. Consequently, existing SCAs often select a small number of features before launching the attack, making their success highly dependent on the feasibility of feature selection. However, feature selection may not always be possible, such as in the presence of countermeasures like masking or  jitters.

Several recent works have employed deep learning (DL) methods to conduct SCA on long raw traces, thereby reducing dependence on feature selection steps. However, these methods often perform poorly against various jitter-based countermeasures. While some of these methods have shown high robustness to jitter-based countermeasures on relatively shorter traces, we demonstrate in this work that their performance deteriorates as trace lengths increase. Based on these observations, we develop a hierarchical DL model for SCA on long traces that is robust against various countermeasures. The proposed model, HierNet, extracts information from long traces using a two-level information assimilation process. At the base level, a DL model with shift-invariance is employed to extract information from smaller trace segments. Subsequently, a top-level DL model integrates the outputs of the base model to generate the final output. The proposed model has been experimentally evaluated against various combinations of masking, random delay, and clock jitter countermeasures using traces with lengths exceeding $200K$ features. The results have been compared with three existing SCA benchmark models. They demonstrate HierNet's superiority in several scenarios, such as on long traces, against clock jitter countermeasures, and low training data scenarios. In particular, while other models fail to reach the guessing entropy $1$ using as many as $5K$ traces, HierNet achieves the same with fewer than or close to $10$ traces.
]]></content:encoded>
<pubDate>Sat, 14 Sep 2024 09:47:21 +0000</pubDate>
</item>
<item>
<title>$Shortcut$: Making MPC-based Collaborative Analytics Efficient on Dynamic Databases</title>
<link>https://eprint.iacr.org/2024/1433</link>
<guid>https://eprint.iacr.org/2024/1433</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation（MPC）、Multi-party Computation（MCASs）、动态数据库、查询结果更新（QRU）协议、性能优化

总结:
本文提出了名为“Shortcut”的框架，旨在与基于MPC的协作分析系统（MCASs）结合，以提高对动态数据库的查询效率。动态数据库支持数据插入、删除和更新操作。传统的MCASs在处理这些动态变化时效率低下，主要原因是重复内容导致的大量冗余计算。为解决这一问题，“Shortcut”框架的核心理念是预存历史查询结果，并通过自定义的查询结果更新（QRU）协议来直接更新这些结果，从而获得当前的查询结果。

为了实现这一目标，“Shortcut”为常见的SQL操作，如Order-by-Limit、Group-by-Aggregate、Distinct、Join、Select和Global Aggregate，定制了高效的QRU协议。这些协议不仅能够相容以实现各种查询功能，而且特别设计了两种常数轮次的协议来支持数据插入和删除操作。这些协议可以作为其他协议的基础构建块，并且具有独立的研究价值，解决了安全地将一行数据插入或从有序表中删除，同时保持其顺序的问题。

实验结果显示，“Shortcut”在处理动态数据库中的小幅度更新时，相比于传统MCASs，能够实现高达186.8倍的性能提升。例如，对于动态数据库中数量级在2^16到2^20之间的数据，仅对单个查询进行一次插入操作，“Shortcut”就能实现显著的性能改进。这表明“Shortcut”框架对于许多现实应用（如保险服务、账户数据管理等）的需求有很好的适应性和高效性。 <div>
Secure Multi-party Computation (MPC) provides a promising solution for privacy-preserving multi-source data analytics. However, existing MPC-based collaborative analytics systems (MCASs) have unsatisfying performance for scenarios with dynamic databases. Naively running an MCAS on a dynamic database would lead to significant redundant costs and raise performance concerns, due to the substantial duplicate contents between the pre-updating and post-updating databases. 

In this paper, we propose $Shortcut$, a framework that can work with MCASs to enable efficient queries on dynamic databases that support data insertion, deletion, and update. The core idea of $Shortcut$ is to materialize previous query results and directly update them via our query result update (QRU) protocol to obtain current query results. We customize several efficient QRU protocols for common SQL operators, including Order-by-Limit, Group-by-Aggregate, Distinct, Join, Select, and Global Aggregate. These protocols are composable to implement a wide range of query functions. In particular, we propose two constant-round protocols to support data insertion and deletion. These protocols can serve as important building blocks of other protocols and are of independent interest. They address the problem of securely inserting/deleting a row into/from an ordered table while keeping the order. Our experiments show that $Shortcut$ outperforms naive MCASs for minor updates arriving in time, which captures the need of many realistic applications (e.g., insurance services, account data management). For example, for a single query after an insertion, $Shortcut$ achieves up to $186.8 \times$ improvement over those naive MCASs without our QRU protocols on a dynamic database with $2^{16} \sim 2^{20}$ rows, which is common in real-life applications.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 04:20:57 +0000</pubDate>
</item>
<item>
<title>Powerformer: Efficient Privacy-Preserving Transformer with Batch Rectifier-Power Max Function and Optimized Homomorphic Attention</title>
<link>https://eprint.iacr.org/2024/1429</link>
<guid>https://eprint.iacr.org/2024/1429</guid>
<content:encoded><![CDATA[
<div> 关键词：Powerformer、非交互式、隐私保护、Transformer、高效算法

总结:文章提出了一种名为Powerformer的高效非交互式隐私保护Transformer推理架构。该架构通过引入基于ReLU的新函数“Batch Rectifier-Power max”（BRPmax）来替换softmax操作，解决了先前研究中因使用多轮Bootstrapping而导致的精度下降和执行时间延长问题。BRPmax函数无需任何不稳定近似方法，即使在BERT-Large模型中也能超越原始BERT性能，仅需单次Bootstrapping。此外，文章还提供了针对注意力块的矩阵乘法算法，相较于现有最优方法，可减少35%至91%的关键切换次数。最后，设计了清晰的基于HE的私有Transformer模型端到端实现，并实现了使用RNS-CKKS的Powerformer模型在单线程CPU上的运行时间为503秒，这是已知的首个使用HE的非交互式Transformer端到端实现。 <div>
We propose an efficient non-interactive privacy-preserving Transformer inference architecture called Powerformer. Since softmax is a non-algebraic operation, previous studies have attempted to modify it to be HE-friendly, but these methods have encountered issues with accuracy degradation or prolonged execution times due to the use of multiple bootstrappings. We propose replacing softmax with a new ReLU-based function called the \textit{Batch Rectifier-Power max} (BRPmax) function without any unstable approximation methods, which outperforms even original BERT performance within BERT-Large model while requiring fewer levels, allowing it to operate with only a single bootstrapping. We also present a matrix multiplication algorithms specialized for attention block that reduce the number of key-switchings by 35% to 91% compared to existing state-of-the-art methods. We design clear end-to-end HE-based implementation for private Transformer model, and our implementation of Powerformer on the BERT-tiny model using RNS-CKKS takes 503 seconds on a single-threaded CPU, and to the best of our knowledge, this is the first end-to-end non-interactive Transformer implementation using HE.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 06:04:04 +0000</pubDate>
</item>
<item>
<title>Evolving Secret Sharing Made Short</title>
<link>https://eprint.iacr.org/2023/1534</link>
<guid>https://eprint.iacr.org/2023/1534</guid>
<content:encoded><![CDATA[
<div> 关键词：Evolving Secret Sharing, Komargodski, Naor, Yogev, TCC’16, Computational Setting

在这篇论文中，研究者们针对演进型秘密共享（Komargodski, Naor, and Yogev在TCC’16提出的概念）展开了系统性的研究。在演进型秘密共享中，成员可以动态地加入系统，且系统初始时并不知道最终的最大成员数或访问结构。研究的目标是在保证计算安全的前提下，最小化新成员加入时对现有成员份额的影响，并且使份额大小相对于成员数量保持较小。

主要发现包括：

1. 对于多种实用且重要的访问结构类型（如图访问结构、DNF和CNF公式访问结构、单调电路访问结构以及阈值访问结构），在标准假设下，存在高效的计算隐私秘密分享方案，其中份额大小远小于自然表示演进访问结构所需的数据量。

2. 研究引入了演进型秘密共享在计算环境下的概念，允许最大成员数为安全参数的多项式函数，但同时仍不知道具体数值，进一步增强了其实际应用性。

3. 提出了针对特定类型访问结构的有效秘密分享方案设计方法，这些方案不仅满足计算隐私要求，而且能够显著减少成员加入时的份额更新复杂度，从而提高系统效率和可扩展性。

4. 结果表明，通过适当的假设和技术手段，可以在不牺牲安全性的同时，实现高效、适应动态成员变化的秘密分享机制，这对于需要处理大量动态成员的分布式系统具有重要意义。

5. 这一研究为演进型秘密共享领域提供了新的理论基础和实践指导，有助于促进相关技术在网络安全、云计算、区块链等领域的应用和发展。

总结: 本文通过系统性研究，揭示了在计算环境下，如何有效实现演进型秘密共享，特别是在未知最大成员数和访问结构的情况下，提出了一种能够保持计算隐私、确保份额大小合理、适应动态成员变化的秘密分享方案，特别针对多种实用访问结构类型进行了深入探讨，为未来分布式系统中的成员动态管理提供了重要理论支持与实践指南。 <div>
Evolving secret sharing (Komargodski, Naor, and Yogev, TCC’16) generalizes the notion of secret sharing to the setting of evolving access structures, in which the share holders are added to the system in an online manner, and where the dealer does not know neither the access structure nor the maximum number of parties in advance. Here, the main difficulty is to distribute shares to the new players without updating the shares of old players; moreover, one would like to minimize the share size as a function of the number of players.
In this paper, we initiate a systematic study of evolving secret sharing in the computational setting, where the maximum number of parties is polynomial in the security parameter, but the dealer still does not know this value, neither it knows the access structure in advance. Moreover, the privacy guarantee only holds against computationally bounded adversaries corrupting an unauthorized subset of the players.
Our main result is that for many interesting, and practically relevant, evolving access structures (including graphs access structures, DNF and CNF formulas access structures, monotone circuits access structures, and threshold access structures), under standard hardness assumptions, there exist efficient secret sharing schemes with computational privacy and in which the shares are succinct (i.e., much smaller compared to the size of a natural computational representation of the evolving access structure).
]]></content:encoded>
<pubDate>Sat, 07 Oct 2023 10:43:21 +0000</pubDate>
</item>
<item>
<title>New Secret Keys for Enhanced Performance in (T)FHE</title>
<link>https://eprint.iacr.org/2023/979</link>
<guid>https://eprint.iacr.org/2023/979</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、GLWE、改进、安全性、性能提升

总结:本文提出了一种改进全同态加密（FHE）技术的方法，主要针对GLWE（Gaussian Learning With Errors）基方案。文章识别了两种FHE技术的局限性：一是无法精确控制GLWE密钥大小；二是由于安全原因，无法使用低于特定值的噪声方差，导致在某些情况下无法灵活调整安全级别，造成不必要的高安全设置。为解决这些问题，作者引入了两种新的GLWE密钥类型，这些新密钥既保证了与传统密钥同等的安全性，又带来了性能上的显著提升。

具体来说，新密钥系统使得在保持相同安全性和失败概率的前提下，计算速度可以提升1.3到2.4倍。同时，关键转换和启动密钥的大小也分别减少了1.5到2.7倍。这些改进不仅提高了加密系统的效率，而且扩展了其应用范围，特别是在处理敏感信息保护方面具有重要意义。通过对比现有TFHE技术与传统密钥方法，研究证明了新密钥系统的优越性，为全同态加密技术的进一步发展提供了有力支持。 <div>
Fully Homomorphic Encryption has known impressive improvements in the last 15 years, going from a technology long thought to be impossible to an existing family of encryption schemes able to solve a plethora of practical use cases related to the privacy of sensitive information. 
Recent results mainly focus on improving techniques within the traditionally defined framework of GLWE-based schemes, but the recent CPU implementation improvements are mainly incremental.
To keep improving this technology, one solution is to modify the aforementioned framework, by using slightly different hardness assumptions.
In this paper, we identify two limitations with (T)FHE:
(i) there is no fine-grained control over the size of a GLWE secret key, which is traditionally composed of $k$ polynomials with $N=2^\alpha>1$ coefficients;
(ii) for security reasons one cannot use a noise variance smaller than a certain $\sigma_{\min}$ so, for all ciphertext modulus $q\in \mathbb{N}$, there exists an integer 
$n_{\mathsf{plateau}}$ such that, with any secret key of size  $k\cdot N \ge n_{\mathsf{plateau}}$, one cannot control their level of security, resulting in unnecessary big security levels.
To overcome the aforementioned limitations, we introduce two new types of secret keys for GLWE-based cryptosystems, that can be used separately or together.
We explain why these new secret keys are as secure as the traditional ones and we detail all the improvements that they bring to existing FHE algorithms alongside new algorithms especially efficient with these new keys.
We provide many comparisons with state-of-the-art TFHE techniques with traditional secret keys, and some benchmarks showing computational speed-ups between $1.3$ and $2.4$ while keeping the same level of security and failure probability (correctness).
Furthermore, the size of the key switching and bootstrapping keys is also reduced with this contribution by factors ranging from $1.5$ to $2.7$.
]]></content:encoded>
<pubDate>Fri, 23 Jun 2023 08:44:49 +0000</pubDate>
</item>
<item>
<title>SmartZKCP: Towards Practical Data Exchange Marketplace Against Active Attacks</title>
<link>https://eprint.iacr.org/2024/941</link>
<guid>https://eprint.iacr.org/2024/941</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据市场、零知识证明、智能合约、安全优化

总结:

本文探讨了将基于区块链的零知识条件支付（ZKCP）协议应用于公共数据市场的可能性及其潜在挑战。ZKCP协议通过区块链技术和零知识证明为数字商品提供无信任的公平交换，但在实际数据市场中应用时存在多种安全风险。

针对这些问题，文章提出了一种改进方案——SmartZKCP，旨在增强安全性并优化性能。SmartZKCP不仅确保了协议的正式化实现以维护公平性，还针对可能的攻击进行了强化防御。同时，该协议还实现了效率提升和通信成本的降低。

通过评估结果，SmartZKCP被证明既实用又高效，符合数据交换市场的应用需求。这一改进方案克服了ZKCP在实际部署中遇到的障碍，提供了更加安全和高效的交易环境，为数据市场的发展提供了有力支持。 <div>
The trading of data is becoming increasingly important as it holds substantial value. A blockchain-based data marketplace can provide a secure and transparent platform for data exchange. To facilitate this, developing a fair data exchange protocol for digital goods has garnered considerable attention in recent decades. The Zero Knowledge Contingent Payment (ZKCP) protocol enables trustless fair exchanges with the aid of blockchain and zero-knowledge proofs. However, applying this protocol in a practical data marketplace is not trivial.

In this paper, several potential attacks are identified when applying the ZKCP protocol in a practical public data marketplace. To address these issues, we propose SmartZKCP, an enhanced solution that offers improved security measures and increased performance. The protocol is formalized to ensure fairness and secure against potential attacks. Moreover, SmartZKCP offers efficiency optimizations and minimized communication costs. Evaluation results show that SmartZKCP is both practical and efficient, making it applicable in a data exchange marketplace.
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 07:23:45 +0000</pubDate>
</item>
<item>
<title>Kronos: A Secure and Generic Sharding Blockchain Consensus with Optimized Overhead</title>
<link>https://eprint.iacr.org/2024/206</link>
<guid>https://eprint.iacr.org/2024/206</guid>
<content:encoded><![CDATA[
<div> 关键词：Kronos、安全、低延迟、高吞吐量、通用框架

总结:

本文提出了一种名为Kronos的安全分片区块链共识机制，旨在优化分片网络的效率与安全性。Kronos的核心创新在于引入了一个由分片成员联合管理的缓冲区，用于传输有效交易并拒绝无效交易。这种设计确保了在恶意客户端存在的情况下，系统仍能实现原子性，并保持最优的分片内开销。

Kronos特别关注跨分片交易带来的挑战，通过高效拒绝机制，即使在快乐路径中也不需要执行拜占庭容错(BFT)协议，而在不快乐路径中的成本也仅相当于两阶段提交。此外，文章还提出了安全的跨分片认证方法，证明了处理b个交易时，Kronos的跨分片通信开销为O(n b λ)，其中n代表分片大小，λ为安全参数。这一特性使得Kronos成为增强现有BFT协议性能和可扩展性的通用框架。

Kronos支持异步网络等通用模型，并展示了在实际部署中显著提升的吞吐量（可达320 ktx/sec，延迟2.0秒），在处理跨分片交易工作负载时，相较于过去解决方案，Kronos表现出高达12倍的吞吐量提升和50%的延迟减少。 <div>
Sharding enhances blockchain scalability by dividing the network into shards, each managing specific unspent transaction outputs or accounts. As an introduced new transaction type, cross-shard transactions pose a critical challenge to the security and efficiency of sharding blockchains. Currently, there is a lack of a generic sharding blockchain consensus pattern that achieves both security and low overhead.

In this paper, we present Kronos, a secure sharding blockchain consensus achieving optimized overhead. In particular, we propose a new secure sharding blockchain consensus pattern, based on a buffer managed jointly by shard members. Valid transactions are transferred to the payee via the buffer, while invalid ones are rejected through happy or unhappy paths. Kronos is proved to achieve security with atomicity under malicious clients while maintaining optimal intra-shard overhead. Efficient rejection even requires no Byzantine fault tolerance (BFT) protocol execution in happy paths, and the cost in unhappy paths is still not higher than a two-phase commit. Besides, we propose secure cross-shard certification methods. Handling b transactions, Kronos is proved to achieve cross-shard communication with low cross-shard overhead O(n b \lambda) (n for the shard size and \lambda for the security parameter). Notably, Kronos imposes no restrictions on BFT and does not rely on timing assumptions, offering optional constructions in various modules. Kronos could serve as a universal framework for enhancing the performance and scalability of existing BFT protocols. Kronos supports generic models, including asynchronous networks, and can increase the throughput by several orders of magnitude.

We implement Kronos using two prominent BFT protocols: asynchronous Speeding Dumbo (NDSS'22) and partially synchronous Hotstuff (PODC'19). Extensive experiments (over up to 1000 AWS EC2 nodes across 4 AWS regions) demonstrate Kronos scales the consensus nodes to thousands, achieving a substantial throughput of 320 ktx/sec with 2.0 sec latency. Compared with the past solutions, Kronos outperforms, achieving up to a 12$\times$ improvement in throughput and a 50% reduction in latency when cross-shard transactions dominate the workload.
]]></content:encoded>
<pubDate>Sat, 10 Feb 2024 12:30:47 +0000</pubDate>
</item>
<item>
<title>Blind Multisignatures for Anonymous Tokens with Decentralized Issuance</title>
<link>https://eprint.iacr.org/2024/1406</link>
<guid>https://eprint.iacr.org/2024/1406</guid>
<content:encoded><![CDATA[
<div> 关键词:匿名令牌、去中心化发行、盲多重签名、BLS签名、离散对数

文章主要探讨了一种新的数字令牌形式——匿名令牌，该令牌允许用户从动态变化的签发者集合中获取，且每次获取过程都保持公开可验证和不可链接性。实现这一目标的关键在于引入了盲多重签名（BMS）的概念，它允许用户与多个签发者交互以获取签名，即使所有签发者合谋也无法将签名与任一交互链接起来。

文章提供了两种基于BLS签名和离散对数（无配对）的BMS构建方案，并证明了这些构建方案在代数群模型中的安全性。此外，还提供了一个原型实现，结果显示其验证操作成本较低，这对于区块链应用而言至关重要。

总结:
文章首先提出了一种新型的匿名令牌，这种令牌具有去中心化的发行机制，使得用户可以从任意一组签发者处获取令牌，且每次获取过程都保持匿名。实现这一机制的核心是盲多重签名技术，它允许用户与多个签发者进行交互并获得签名，即使所有签发者合谋也无法关联到具体的交互过程。文章分别设计了基于BLS签名和离散对数（不使用配对）的两种BMS构建方案，并证明了这些方案在代数群模型下的安全性。最后，通过原型实现展示了其验证操作的成本效益，这是区块链应用中至关重要的特性。 <div>
We propose the first constructions of anonymous tokens with decentralized issuance. Namely, we consider a dynamic set of signers/issuers; a user can obtain a token from any subset of the signers, which is publicly verifiable and unlinkable to the issuance process. To realize this new primitive we formalize the notion of Blind Multi-Signatures (BMS), which allow a user to interact with multiple signers to obtain a (compact) signature; even if all the signers collude they are unable to link a signature to an interaction with any of them.

We then present two BMS constructions, one based on BLS signatures and a second based on discrete logarithms without pairings. We prove security of both our constructions in the Algebraic Group Model.

We also provide a proof-of-concept implementation and show that it has low-cost verification, which is the most critical operation in blockchain applications.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 09:11:55 +0000</pubDate>
</item>
<item>
<title>Security Bounds for Proof-Carrying Data from Straightline Extractors</title>
<link>https://eprint.iacr.org/2023/1646</link>
<guid>https://eprint.iacr.org/2023/1646</guid>
<content:encoded><![CDATA[
<div> 关键词：证明携带数据、SNARK、直线下知识完整性、安全分析、递归组成

总结:

本文探讨了递归组成的实际应用和安全性分析。证明携带数据（PCD）是一种允许互不信任的各方以可验证的方式执行分布式计算的加密技术。当前的PCD构造通常是通过嵌套安全论证（SNARK）或相关原理实现的，但这种构建方式导致的安全性评估往往过于复杂，导致实践中对参数设置的忽视，因为这些评估会导致成本过高的参数选择。

文章的主要发现是，从具有“直线下知识完整性”的SNARK中获得的PCD实际上具有与基础SNARK相同的本质安全性，即递归组成不会造成安全性损失。通过分析在不同预言机模型中的SNARK如何实现直线下知识完整性，研究者提供了一种高效的安全性分析方法，该方法可以黑盒使用SNARK的预言机，而无需实例化预言机即可进行安全性推导。

作为应用示例，这项工作为区块链系统中使用的递归STARK的实用安全性提供了新的理论见解，尽管这些见解具有一定的启发性和假设性。这项研究为理解如何合理设置具有实际意义的PCD构造的参数提供了理论依据，同时也为解释实践者在设计递归STARK时所采用的参数选择策略提供了部分证据支持。 <div>
Proof-carrying data (PCD) is a powerful cryptographic primitive that allows mutually distrustful parties to perform distributed computation in an efficiently verifiable manner. Real-world deployments of PCD have sparked keen interest within the applied community and industry.

Known constructions of PCD are obtained by recursively-composing SNARKs or related primitives. Unfortunately, known security analyses incur expensive blowups, which practitioners have disregarded as the analyses would lead to setting parameters that are prohibitively expensive.

In this work we study the concrete security of recursive composition, with the goal of better understanding how to reasonably set parameters for certain PCD constructions of practical interest. Our main result is that PCD obtained from SNARKs with \emph{straightline knowledge soundness} has essentially the same security as the underlying SNARK (i.e., recursive composition incurs essentially no security loss).

We describe how straightline knowledge soundness is achieved by SNARKs in several oracle models, which results in a highly efficient security analysis of PCD that makes black-box use of the SNARK's oracle (there is no need to instantiated the oracle to carry out the security reduction).

As a notable application, our work offers an idealized model that provides new, albeit heuristic, insights for the concrete security of \emph{recursive STARKs} used in blockchain systems. Our work could be viewed as partial evidence justifying the parameter choices for recursive STARKs made by practitioners.
]]></content:encoded>
<pubDate>Tue, 24 Oct 2023 11:06:22 +0000</pubDate>
</item>
<item>
<title>Blockchain-based decentralized identity system: Design and security analysis</title>
<link>https://eprint.iacr.org/2024/597</link>
<guid>https://eprint.iacr.org/2024/597</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、物联网、设备间通信、分布式存储、智能合约

总结: 这篇论文提出了一种新型的基于区块链的去中心化身份系统（DID），专为增强物联网（IoT）和设备对设备（D2D）网络中的数字身份管理设计。该系统具有层次结构，巧妙地将分布式账本与移动D2D网络融合，确保了强大的安全性同时简化了通信流程。系统的核心在于网关节点，它们作为中介，通过智能合约和分布式存储系统实现DID注册和设备认证。全面的安全分析证明了该系统的抗常见网络攻击能力，并遵循了最终性与活生生原则等关键准则。 <div>
This paper presents a novel blockchain-based decentralized identity system (DID), tailored for enhanced digital identity management in Internet of Things (IoT) and device-to-device (D2D) networks. The proposed system features a hierarchical structure that effectively merges a distributed ledger with a mobile D2D network, ensuring robust security while streamlining communication. Central to this design are the gateway nodes, which serve as intermediaries, facilitating DID registration and device authentication through smart contracts and distributed storage systems. A thorough security analysis underscores the system’s resilience to common cyber threats and adherence to critical principles like finality and liveness.
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 08:51:29 +0000</pubDate>
</item>
<item>
<title>Privacy Comparison for Bitcoin Light Client Implementations</title>
<link>https://eprint.iacr.org/2024/1415</link>
<guid>https://eprint.iacr.org/2024/1415</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、SPV、Neutrino、隐私、可扩展性

总结:

本文深入探讨了比特币可扩展性问题中两种主要轻客户端实现方式——SPV和Neutrino——的隐私特性。通过定义一系列隐私度量指标，研究者对这些实现方式在实际比特币数据上的隐私表现进行了评估与比较，揭示了隐私与通信之间固有的权衡关系。同时，文章提出了一般性方法以增强现有轻客户端的隐私保护，并提出了一个新的基于SPV的轻客户端模型——聚合模型，该模型能够提供超过现有实现的更高隐私水平。

文章首先通过定义隐私度量指标来量化SPV和Neutrino的隐私特性，随后使用真实比特币数据进行评估，揭示了不同时间点上这两种轻客户端实现方式的隐私差异。进一步地，文章讨论了隐私和通信之间的权衡，指出为了获得更高的隐私，可能需要牺牲一定的通信效率或资源。在此基础上，文章提出了增强现有轻客户端隐私性的通用技术策略。

最后，文章引入了一个名为聚合模型的新SPV基轻客户端概念，通过详细分析证明了它相较于现有的轻客户端实现方式能提供更优的隐私性能。这一模型通过创新的设计，成功地在不显著增加通信开销的情况下，实现了对用户地址状态更新的更严格隐私保护，为提升比特币网络整体隐私性提供了新的思路和实践路径。 <div>
Light clients implement a simple solution for Bitcoin's scalability problem, as they do not store the entire blockchain but only the state of particular addresses of interest. To be able to keep track of the updated state of their addresses, light clients rely on full nodes to provide them with the required information. To do so, they must reveal information about the addresses they are interested in. This paper studies the two most common light client implementations, SPV and Neutrino with regards to their privacy. We define privacy metrics for comparing the privacy of the different implementations. We evaluate and compare the privacy of the implementations over time on real Bitcoin data and discuss the inherent privacy-communication tradeoff. In addition, we propose general techniques to enhance light client privacy in the existing implementations. Finally, we propose a new SPV-based light client model, the aggregation model, evaluate it, and show it can achieve enhanced privacy than in the existing light client implementations.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 19:17:19 +0000</pubDate>
</item>
<item>
<title>Code-Based Zero-Knowledge from VOLE-in-the-Head and Their Applications: Simpler, Faster, and Smaller</title>
<link>https://eprint.iacr.org/2024/1414</link>
<guid>https://eprint.iacr.org/2024/1414</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识协议、代码基础密码学、MPC-in-the-head、VOLE-in-the-head、斯特恩协议

总结:

本文提出了一种基于VOLEitH范式的新型代码基础零知识协议，用于证明多种关系的正确性。这一创新为构建更高效的隐私保护系统开辟了道路。首先，文章提供了一种用于验证非线性编码过程正确性的新零知识协议，这是许多高级隐私保护系统中常见的需求。其次，文中设计了针对具体代码关系的新零知识协议，包括优化积木值的零知识证明，适用于积木（accumulator）。

这些新协议相较于斯特恩式协议具有简化、更快、更小的特点，使得构建更高效的隐私保护系统成为可能。作者利用这些协议构建了环签名（RS）、组签名（GS）和全动态属性基签名方案，其签名大小显著优于基于斯特恩协议的同类方案，最高可达数个数量级的减小。

最后，文中提出的第一种零知识协议还生成了一个标准签名方案，其“签名大小+公钥大小”仅为3.05KB，这在各种参数设置下都达到了与当前最佳基于常规综态解码问题的签名方案相比的较小规模，展示了新协议在实际应用中的潜力和效率。 <div>
Zero-Knowledge (ZK) protocols allow a prover to demonstrate the truth of a statement without disclosing additional information about the underlying witness. Code-based cryptography has a long history but did suffer from periods of slow development. Recently, a prominent line of research have been contributing to designing efficient code-based ZK from MPC-in-the-head (Ishai et al., STOC 2007) and VOLE-in-the head (VOLEitH)  (Baum et al., Crypto 2023) paradigms, resulting in quite efficient standard signatures. However, none of them could be directly used to construct privacy-preserving cryptographic primitives. Therefore, Stern's protocols remain to be the major technical stepping stones for developing  advanced code-based privacy-preserving systems. 

This work proposes new code-based ZK protocols from VOLEitH paradigm for various relations and designs several code-based privacy-preserving systems that considerably advance the state-of-the-art in code-based cryptography. Our first contribution is a new ZK protocol for proving the correctness of a regular (non-linear) encoding process, which is utilized in many advanced privacy-preserving systems. Our second contribution are new ZK protocols for concrete code-based relations.   In particular, we provide a ZK of accumulated values  with optimal witness size for the accumulator (Nguyen et al.,  Asiacrypt 2019).  Our protocols thus open the door for constructing more efficient  privacy-preserving systems. Moreover, our ZK protocols have the advantage of being simpler, faster, and smaller compared to Stern-like protocols.  To illustrate the effectiveness of our new ZK protocols, we develop ring signature (RS) scheme, group signature (GS) scheme, fully dynamic attribute-based signature scheme from our new ZK. The signature sizes of the resulting schemes are two to three orders of magnitude smaller than those based on Stern-like protocols in various parameter settings. Finally, our first ZK protocol yields a standard signature scheme, achieving ``signature size + public key size'' as small as $3.05$ KB, which is slightly smaller than the state-of-the-art signature scheme (Cui et al., PKC 2024) based on the regular syndrome decoding problems.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 12:12:36 +0000</pubDate>
</item>
<item>
<title>Cryptobazaar: Private Sealed-bid Auctions at Scale</title>
<link>https://eprint.iacr.org/2024/1410</link>
<guid>https://eprint.iacr.org/2024/1410</guid>
<content:encoded><![CDATA[
<div> 关键词：Cryptobazaar、隐私保护、去中心化、密封投标拍卖、单个不可信协调者

<br /><br />
总结:本文引入了一种名为Cryptobazaar的创新性、可扩展、私密且去中心化的密封投标拍卖协议。该协议通过确保投标人的隐私不被泄露，同时保证拍卖结果的公开验证和仅依赖单一不可信的协调者来执行任务，实现了在安全与效率之间的平衡。其核心在于结合了高效分布式协议以计算一串二元编码投标的逻辑或运算，以及多种新颖的零知识简洁论证知识。此外，文章还介绍了Cryptobazaar协议的不同变体，用于实现包括第一价、第二价以及更广泛的(p+1)价和顺序第一价拍卖在内的多种拍卖类型。通过性能评估，证明了该实现的高度实用性，例如，在有128位竞标者和1024个价格范围的情况下，一次拍卖只需不到0.5秒即可完成，每位竞标者发送和接收的数据量约为32KB。 <div>
This work introduces Cryptobazaar, a novel scalable, private, and decentralized sealed-bid auction protocol. In particular, our protocol protects the privacy of losing bidders by preserving the confidentiality of their bids while ensuring public verifiability of the outcome and relying only on a single untrusted auctioneer for coordination. At its core, Cryptobazaar combines an efficient distributed protocol to compute the logical-OR for a list of unary-encoded bids with various novel zero-knowledge succinct arguments of knowledge that may be of independent interest. We further present variants of our protocol that can be used for efficient first-, second-, and more generally $(p+1)$st-price as well as sequential first-price auctions. Finally, the performance evaluation of our Cryptobazaar implementation shows that it is highly practical. For example, a single run of an auction with $128$ bidders and a price range of $1024$ values terminates in less than $0.5$ sec and requires each bidder to send and receive only about $32$ KB of data.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 07:55:13 +0000</pubDate>
</item>
<item>
<title>Encrypted MultiChannel Communication (EMC2): Johnny Should Use Secret Sharing</title>
<link>https://eprint.iacr.org/2024/1407</link>
<guid>https://eprint.iacr.org/2024/1407</guid>
<content:encoded><![CDATA[
<div> 关键词：点对点加密、TLS协议、End-to-End Encryption（E2EE）、Pgp、Signal

总结: 文章探讨了当前End-to-End Encryption（E2EE）解决方案所面临的问题，如低可用性、小用户基础、依赖中心服务提供商以及易受后门攻击等。同时，文章指出美国和欧盟正提出新的监控法规，要求聊天监控，这引发了对合法后门设置的担忧。为解决这些问题，文章提出了一个新的E2EE解决方案——Encrypted MultiChannel Communication（EMC2），基于n-out-of-n秘密共享机制。EMC2将消息分割成多个秘密共享，并通过独立通道发送，提供无单一信任点、无需设置且易于公众理解的E2EE方式。该方案旨在通过展示合法后门无效性来加强反对其设置的论据，并与现有工具相补充，从而增强E2EE的安全性和隐私保护能力。 <div>
Nowadays, the problem of point-to-point encryption is solved by the wide adaptation of protocols like TLS. However, challenges persist for End-to-End Encryption (E2EE). Current E2EE solutions, such as PGP and secure messengers like Signal, suffer from issues like 1) low usability, 2) small user base, 3) dependence on central service providers, and 4) susceptibility to backdoors. Concerns over legally mandated backdoors are rising as the US and EU are proposing new surveillance regulations requiring chat monitoring. We present a new E2EE solution called Encrypted MultiChannel Communication, based on n-out-of-n secret sharing. EMC2 splits messages into multiple secret shares and sends them through independent channels. We show that multiple independent channels exist between users and EMC2 provides E2EE with no single point of trust, no setup, and is understandable by the general public. Our solution complements existing tools and aims to strengthen the argument against legally enforced backdoors by demonstrating their ineffectiveness.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 09:33:15 +0000</pubDate>
</item>
<item>
<title>Lego-DLC: batching module for commit-carrying SNARK under Pedersen Engines</title>
<link>https://eprint.iacr.org/2024/1405</link>
<guid>https://eprint.iacr.org/2024/1405</guid>
<content:encoded><![CDATA[
<div> 关键词：LegoSNARK、cc-SNARK、CP-SNARK、Groth16、Lego-DLC

总结:

文章主要讨论了如何优化zk-SNARK系统在处理大量承诺证明时的效率问题。首先，文章引入了cc-SNARK（commit-carrying SNARK）这一新型概念，它是CP-SNARK（commit-and-prove SNARK）的一种特殊形式，用于构建承诺与证明SNARK系统。通过cc-SNARK，文章展示了改进后的Groth16版本，其证明时间提高了约5000倍。

然而，当需要同时证明l个承诺时，使用上述方法会遇到性能瓶颈，因为LegoSNARK的链接系统在验证器侧需要进行O(l)次配对操作。为解决这一问题，文章提出了一种新的批处理模块——Lego-DLC，它结合了Σ协议与基于Pedersen引擎的承诺携带SNARK，旨在高效处理多个承诺。通过具体实例化Groth16和Plonk，该方法在验证时间上表现出了显著的效率提升，对于2^16个承诺，验证时间仅需0.064秒，比LegoSNARK的1.972秒快了超过30倍。尽管这导致了约8倍的证明时间增加（从0.177秒增加到1.413秒），但整体来看，这种性能提升是值得的。

文章通过对比实验展示了Lego-DLC在处理大规模承诺证明场景中的优势，为zk-SNARK系统的实际应用提供了有效的解决方案。 <div>
The synergy of commitments and zk-SNARKs is
widely used in various applications, particularly in fields like
blockchain, to ensure data privacy and integrity without revealing
secret information. However, proving multiple commitments in
a batch imposes a large overhead on a zk-SNARK system. One
solution to alleviate the burden is the use of commit-and-prove
SNARK (CP-SNARK) approach. LegoSNARK defines a new
notion called commit-carrying SNARK (cc-SNARK), a special-
ized form of CP-SNARK, and introduces a compiler to build
commit-carrying SNARKs into commit-and-prove SNARKs. Us-
ing this compiler, the paper shows a commit-and-prove version
of Groth16 that improves the proving time (about 5,000×).
However, proving $l$-multiple commitments simultaneously with
this compiler faces a performance issue, as the linking system in
LegoSNARK requires $O(l)$ pairings on the verifier side.
To enhance efficiency, we propose a new batching module
called Lego-DLC, designed for handling multiple commitments. This
module is built by combining a $\Sigma$-protocol with commitment-
carrying SNARKs under Pedersen engines in which our mod-
ule can support all commit-carrying SNARKs under Pedersen
engines. In this paper, we provide the concrete instantiations
for Groth16 and Plonk. In the performance comparison, for
$2^{16}$ commitments, with a verification time of just 0.064s—over
30x faster than LegoSNARK’s 1.972s—our approach shows
remarkable efficiency. The slightly longer prover time of 1.413s
(compared to LegoSNARK’s 0.177s), around 8x is a small trade-
off for this performance gain.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 07:44:03 +0000</pubDate>
</item>
<item>
<title>A Recursive zk-based State Update System</title>
<link>https://eprint.iacr.org/2024/1402</link>
<guid>https://eprint.iacr.org/2024/1402</guid>
<content:encoded><![CDATA[
<div> 关键词：ZKP、SNARK证明、zkVM、递归证明系统、区块链

总结: 这篇论文提出了一种基于零知识证明（ZKP）的区块更新系统，其中每个区块包含一个由用户生成的zkVM证明聚合而成的SNARK证明。该系统允许用户在其本地机器上生成状态更新证明，从而促进了一个安全、分散的验证过程。论文的主要贡献是递归证明系统，它通过将用户证明进行层级化树结构验证并最终形成根证明来解决可扩展性问题，该根证明作为区块证明用于验证。该解决方案改进了当前区块链范式，通过ZKP提供高效递归验证，增强了安全性并减少了计算负载。 <div>
This paper introduces a ZKP (zero-knowledge proof) based state update system, where each block contains a SNARK proof aggregated from the user generated zkVM (zero knowledge virtual machine) proofs. It enables users to generate state update proofs in their local machines, contributing to a secure, decentralized verification process. Our main contribution in this paper, the recursive proofs system, addresses scalability by recursively verifying user proofs and aggregating them in a hierarchical tree structure up to a root proof, serving as a block proof. The proposed solution advances current blockchain paradigms by offering efficient recursive verification through ZKP, enhancing security and reducing computational load.
]]></content:encoded>
<pubDate>Sat, 07 Sep 2024 17:04:51 +0000</pubDate>
</item>
<item>
<title>SLAMP-FSS: Two-Party Multi-Point Function Secret Sharing from Simple Linear Algebra</title>
<link>https://eprint.iacr.org/2024/1394</link>
<guid>https://eprint.iacr.org/2024/1394</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算（MPC）、随机性关联、多点函数秘密共享（FSS）、伪随机关联生成器、树结构

总结:
本文探讨了多党计算(MPC)中随机性关联的重要性及其在提高计算和通信效率的同时保护数据隐私的应用。文章首先介绍了几种常见的随机性关联形式，如盲化一对一转移(OT)、盲化线性函数评估(OLE)、乘法三元组以及一次性真值表。随后指出，多点函数秘密共享(FSS)是构建伪随机关联生成器的有效工具。

研究提出了一种基于Boyle等人的方案的自然扩展，通过引入树结构、伪随机生成器和线性方程系统来构建新的多点FSS方案——SLAMP-FSS和SLAMPR-FSS。这些新方案在评估阶段展现出更高的效率，相比先前的多点FSS方案，它们更灵活，并在其他效率指标上与之相似。

总的来说，本文通过改进多点FSS方案，旨在提供一种既能提高MPC中计算和通信效率，又能在保护数据隐私方面发挥关键作用的新技术。通过利用树结构和伪随机生成器，新方案实现了在保持灵活性的同时，优化了评估阶段的性能，为MPC领域带来了创新性的解决方案。 <div>
Multiparty computation (MPC) is an important field of cryptography that deals with protecting the privacy of data, while allowing to do computation on that data. A key part of MPC is the parties involved having correlated randomness that they can use to make the computation or the communication between themselves more efficient, while still preserving the privacy of the data. Examples of these correlations include random oblivious transfer (OT) correlations, oblivious linear-function evaluation (OLE) correlations, multiplication triples (also known as Beaver triples) and one-time truth tables. Multi-point function secret sharing (FSS) has been shown to be a great building block for pseudo-random correlation generators. The main question is how to construct fast and efficient multi-point FSS schemes. Here we propose a natural generalization of the scheme of Boyle et al 2016 using a tree structure, a pseudorandom generator and systems of linear equations. 
Our schemes SLAMP-FSS and SLAMPR-FSS are more efficient in the evaluation phase than other previously proposed multi-point FSS schemes while being also more flexible and being similar in other efficiency parameters.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 08:38:24 +0000</pubDate>
</item>
<item>
<title>Survivable Payment Channel Networks</title>
<link>https://eprint.iacr.org/2024/1393</link>
<guid>https://eprint.iacr.org/2024/1393</guid>
<content:encoded><![CDATA[
<div> 关键词：支付通道网络、交易吞吐量、多跳路径、保护方案、容量分配优化

<br />
<br />
总结: 文章主要探讨了支付通道网络（PCN）在加密货币中作为提高交易吞吐量的主要方法。PCN允许两个参与者通过锁定一定资金的链上交易来建立双向支付通道，进行多次互付而不需提交到区块链。然而，打开或维护通道需要较长时间和资源，限制了其数量。为了解决这个问题，用户可以利用多跳路径绕过为每个新目的地开设和维护通道的需求。

文章还分析了支付通道的停止时间（即通道耗尽的时间），并研究了网络中一组通道的平均停止时间和特定拓扑结构下通道的停止时间。为了提高网络的最小停止时间，提出了优化通道容量分布的方案。实验结果验证了模型的准确性和优化方案的有效性。总体而言，文章旨在通过优化支付通道网络中的容量分配策略，提升系统整体的稳定性和效率，减少由于通道耗尽导致的支付失败情况。 <div>
Payment channel networks (PCNs) are a leading method to scale the transaction throughput in cryptocurrencies. Two participants can use a bidirectional payment channel for making multiple mutual payments without committing them to the blockchain. Opening a payment channel is a slow operation that involves an on-chain transaction locking a certain amount of funds. These aspects limit the number of channels that can be opened or maintained. Users may route payments through a multi-hop path and thus avoid opening and maintaining a channel for each new destination. Unlike regular networks, in PCNs capacity depends on the usage patterns and, moreover, channels may become unidirectional. Since payments often fail due to channel depletion, a protection scheme to overcome failures is of interest. We define the stopping time of a payment channel as the time at which the channel becomes depleted. We analyze the mean stopping time of a channel as well as that of a network with a set of channels and examine the stopping time of channels in particular topologies. We then propose a scheme for optimizing the capacity distribution among the channels in order to increase the minimal stopping time in the network. We conduct experiments and demonstrate the accuracy of our model and the efficiency of the proposed optimization scheme.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 08:32:20 +0000</pubDate>
</item>
<item>
<title>Haze and Daze: Compliant Privacy Mixers</title>
<link>https://eprint.iacr.org/2023/1152</link>
<guid>https://eprint.iacr.org/2023/1152</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、隐私混币器、合规性、去中心化、智能合约

总结:本文提出了两种隐私混币器协议:Haze和Daze，旨在解决非法活动者滥用隐私混币器的问题。Haze协议确保用户隐私与合规性相结合，即只有非受限地址的资金才能提取，且不透露任何匹配存款信息。一旦用户被标记为违规，其资金将无法退出混币器。然而，这可能导致坏分子在被列入受限地址名单前尝试提取资金。为了解决这个问题，引入了Daze协议，它不仅支持合规性，还允许对违规用户的交易进行追溯匿名识别，使混币器对它们失去效用。同时，Haze和Daze提供了一个可选功能，让违规资金可以被释放到预设实体。实验结果显示，对于合规用户，这两种协议的Gas消耗与Tornado Cash相当。这是首次在区块链上实现智能合约的合规性和隐私保证。 <div>
Blockchains enable mutually distrustful parties to perform financial operations in a trustless, decentralized, publicly-verifiable environment. Blockchains typically offer little privacy, and thus motivated the construction of privacy mixers, a solution to make funds untraceable. Privacy mixers concern regulators due to their increasing use by bad actors to illegally conceal the origin of funds. Consequently, Tornado Cash, the largest privacy mixer to date, is sanctioned by large portions of the Ethereum network.

In this work, we propose Haze and Daze, two privacy mixers that mitigate the undesired abuse of privacy mixers for illicit activities. Haze guarantees users’ privacy together with compliance, i.e., funds can be withdrawn as long as they were deposited from a non-banned address, without revealing any information on the matching deposit. This means that once a user is flagged as non-compliant, their funds can no longer exit the mixer. However, this leads to a race condition for bad actors to withdraw funds before becoming flagged as unlawful in the banned-addresses list. Thus, we introduce Daze, a second mixer protocol that, in addition to compliance, enables retroactive de-anonymization of transactions of non-compliant users, making the mixer fruitless for them. To maintain privacy of compliant users, the de-anonymization procedure is performed by a committee, with privacy guaranteed as long as at least one of the committee members is honest. Moreover, Haze and Daze have an optional feature for non-compliant funds to be released from the mixer to some predetermined entity.

We empirically evaluate our solution in a proof-of-concept system, demonstrating gas consumption for each deposit and withdrawal that is comparable to Tornado Cash for compliant users, both for Haze and Daze. To the best of our knowledge, our solution is the first to guarantee compliance and privacy on the blockchain (on-chain) that is implemented via a smart contract.
]]></content:encoded>
<pubDate>Tue, 25 Jul 2023 12:29:28 +0000</pubDate>
</item>
<item>
<title>Practical Two-party Computational Differential Privacy with Active Security</title>
<link>https://eprint.iacr.org/2024/004</link>
<guid>https://eprint.iacr.org/2024/004</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、主动安全、多方计算、模拟基础差分隐私、几何噪声采样

总结:

本文重新探讨了利用通用型模型预测控制（MPC）方案模拟可信数据持有者以实现差分隐私（DP）的方法，旨在无需信任单一数据持有者即可达到相同精度。文章特别关注了双方模型，即两个计算实体（或数据持有者），各自拥有数据集，希望共同计算其结合数据的典型DP机制，并且使用主动安全性。

首先，文章指出现有定义的计算DP（CDP）协议在用于此类场景时存在缺陷，要么未能充分捕捉到通用型MPC协议通常提供的强大安全保证，要么要求过于严格，需要对常见DP和MPC技术进行重大调整才能满足。因此，文章提出了一种新的基于模拟的CDP版本，称为SIM* CDP，并证明它比IND-CDP和SIM CDP更强，与SIM+ CDP不可比较。通过使用现有分布式协议进行截断几何噪声采样，文章展示了如何满足SIM* CDP定义。进一步地，该协议被用来在具有CDP和主动安全性的条件下计算双方内积，且准确性与中心模型相等，这是首次实现此功能。最后，文章提供了开源实现并对其实际性能进行了基准测试。实现生成截断几何样本的时间范围大约在0.035至3.5秒之间（平均化后），根据网络和参数设置而变化，与现有实现相比表现出色。 <div>
In this work we revisit the problem of using general-purpose MPC schemes to emulate the trusted dataholder in differential privacy (DP), to achieve the same accuracy but without the need to trust one single dataholder. In particular, we consider the two-party model where two computational parties (or dataholders), each with their own dataset, wish to compute a canonical DP mechanism on their combined data and to do so with active security. We start by remarking that available definitions of computational DP (CDP) for protocols are somewhat ill-suited for such a use-case, due to them either poorly capturing some strong security guarantees commonly given by general-purpose MPC protocols, or having too strict requirements in the sense that they need significant adjustment in order to be satisfiable by using common DP and MPC techniques. With this in mind, we propose a new version of simulation-based CDP, called SIM$^*$-CDP, and prove it to be stronger than the IND-CDP and SIM-CDP and incomparable to SIM$^+$-CDP. We demonstrate the usability of the SIM$^*$-CDP definition by showing how to satisfy it by the use of an available distributed protocol for sampling truncated geometric noise. Further, we use the protocol to compute two-party inner-products with CDP and active security, and with accuracy equal to that of the central model, being the first to do so. Finally, we provide an open-sourced implementation and benchmark its practical performance. Our implementation generates a truncated geometric sample in between about 0.035 and 3.5 seconds (amortized), depending on network and parameter settings, comparing favourably to existing implementations.
]]></content:encoded>
<pubDate>Tue, 02 Jan 2024 09:29:54 +0000</pubDate>
</item>
<item>
<title>ASOZ: a decentralized payment system with privacy preserving and auditing on public blockchain</title>
<link>https://eprint.iacr.org/2023/1816</link>
<guid>https://eprint.iacr.org/2023/1816</guid>
<content:encoded><![CDATA[
<div> 关键词：ASOZ、积木化账户、Merkle树、隐私保护、审计方案

<br />
总结:

本文提出了一种名为ASOZ的去中心化支付系统设计。该系统利用基于Merkle树的积木化账户进行记账，同时结合Twisted ElGamal、非交互式零知识证明（NIZK）、Bulletproofs和zk-SNARKs等技术来实现隐私保护与审计功能。通过这种方式，ASOZ方案能够在全局混合中实现全面交易审计，尽管增加了约8%的证明生成时间和23%的验证时间，但总体成本保持在可接受范围内。

ASOZ设计特别适用于大型交易场景，如指定合约市场，并提供在硬币混币方案中最强的隐私保护能力。该系统不仅确保了资产的私密性，还实现了有效的审计机制，平衡了隐私与安全之间的需求，为去中心化支付系统的未来发展提供了新的思路和解决方案。 <div>
Decentralized payment systems have gradually received more attention in recent years. By removing the trusted intermediary used for accounting ledgers, those payment systems fundamentally empower users to control their assets. As privacy concerns grow, some cryptocurrencies are proposed to preserve the privacy of users. However, those cryptocurrencies also inadvertently facilitate illicit activities such as money laundering, fraudulent trading, etc. So it is necessary to design an auditing scheme. To solve this problem, many privacy-preserving and auditing schemes have been proposed. However, there exists no scheme that effectively solves the issue of privacy-preserving and auditing on both user identity and transaction value. 
In this paper, we propose a design for a decentralized payment system named ASOZ. We use cryptographic accumulators based on Merkle trees for accounting and use a combination of Twisted ElGamal, Non-Interactive Zero-Knowledge(NIZK), Bulletproofs, and zk-SNARKs for privacy-preserving and auditing. Our scheme achieves full transaction audit in global mixing, while the additional cost introduced remains within an acceptable range, specifically an 8% increment in proof generation time and a 23% rise in verification time. Our scheme is capable of handling large-scale transaction scenarios such as designated contract markets, and offers the strongest privacy protection capabilities in coin mixer schemes.
]]></content:encoded>
<pubDate>Fri, 24 Nov 2023 09:17:18 +0000</pubDate>
</item>
<item>
<title>Improved Circuit Synthesis with Multi-Value Bootstrapping for FHEW-like Schemes</title>
<link>https://eprint.iacr.org/2023/1223</link>
<guid>https://eprint.iacr.org/2023/1223</guid>
<content:encoded><![CDATA[
<div> 关键词：多值补码、简化方法、FHE-Deck库、优化技术、隐私计算

总结:

本文主要探讨了在隐私保护计算领域，特别是在布尔型全同态加密(FHE)方案上的进步与挑战。通过显著简化Carpov、Izabachène和Mollimard提出的多值补码方法，本文为基于布尔的FHE方案如FHEW或TFHE的实用性提供了基础。简化后的多值补码概念被集成到开源库FHE-Deck中，该库提供了一个易于使用的接口，并生成了具有最高安全性的多比特加密参数集。此外，作者提出并整合了首个针对FHE特定优化的技术，包括查找表（LUT）分组和加法器替换，以提高电路合成效率。

通过LUT分组，平均减少了40%的补码操作，而加法器替换则在某些情况下将所需补码操作减少了高达85%。整体而言，当启用所有优化时，执行时间比之前的最优电路合成技术快了4.2倍。这一系列改进旨在解决隐私保护计算中的关键问题——性能和易用性，从而加速这些技术的实际应用。 <div>
In recent years, the research community has made great progress in improving techniques for privacy-preserving computation, such as fully homomorphic encryption (FHE). Despite the progress, there remain open challenges, mainly in performance and usability, to further advance the adoption of these technologies. This work provides multiple contributions that improve the current state-of-the-art in both areas. More specifically, we significantly simplify the multi-value bootstrapping by Carpov, Izabachène, and Mollimard [CIM19] for Boolean-based FHE schemes such as FHEW or TFHE, making the concept usable in practice. Based on our simplifications, we implement an easy-to-use interface for multi-value bootstrapping in the open-source library FHE-Deck [fhe23], derive new parameter sets for multi-bit encryptions with state-of-the-art security, and build a toolset that translates high-level code to multi-bit operations on encrypted data using circuit synthesis. We propose and integrate the first non-trivial FHE-specific optimizations for privacy-preserving circuit synthesis: look-up table (LUT) grouping and adder substitution. Using LUT grouping, we reduce the number of bootstrapping operations by almost 40% on average, while for adder substitution, we reduce the number of required bootstrappings by up to 85% for certain use cases. Overall, the execution time is up to 4.2x faster with all optimizations enabled compared to previous state-of-the-art circuit synthesis.
]]></content:encoded>
<pubDate>Fri, 11 Aug 2023 20:22:21 +0000</pubDate>
</item>
<item>
<title>Practical Post-Quantum Signatures for Privacy</title>
<link>https://eprint.iacr.org/2024/131</link>
<guid>https://eprint.iacr.org/2024/131</guid>
<content:encoded><![CDATA[
<div> 关键词：后量子密码学、隐私保护应用、盲签名、团体签名、匿名凭证

总结:
本文研究了后量子密码学背景下隐私保护应用中的关键组件，如盲签名、团体签名和匿名凭证。当前的挑战在于寻找高效且在标准假设下安全的后量子算法来替代现有技术。作者通过重新审视Jeudy等人的工作，提出了一种高效协议（SEP）的构建方法，成功实现了短元素长度与无安全妥协的理想平衡。这一创新被应用于匿名凭证系统中，显著减少了凭证大小至不足80KB，这在同类系统中是前所未有的。

此外，文章还详细介绍了复杂零知识框架的实现，这是迄今为止未见于公开文献中的工作。通过这一实证研究，不仅提高了隐私保护解决方案的效率和现实部署的理解，而且为整个领域带来了新的进展。这种结合理论创新与实践验证的方法，不仅推动了后量子密码学在隐私保护领域的应用，也为未来标准的制定提供了有价值的参考。 <div>
The transition to post-quantum cryptography has been an enormous challenge and effort for cryptographers over the last decade, with impressive results such as the future NIST standards. However, the latter has so far only considered central cryptographic mechanisms (signatures or KEM) and not more advanced ones, e.g., targeting privacy-preserving applications. Of particular interest is the family of solutions called blind signatures, group signatures and anonymous credentials, for which standards already exist, and which are deployed in billions of devices. Such a family does not have, at this stage, an efficient post-quantum counterpart although very recent works  improved this state of affairs by offering two different alternatives: either one gets a system with rather large elements but a security proved under standard assumptions or one gets a more efficient system at the cost of ad-hoc interactive assumptions or weaker security models. Moreover, all these works have only considered size complexity without implementing the quite complex building blocks their systems are composed of. In other words, the practicality of such systems is still very hard to assess, which is a problem if one envisions a post-quantum transition for the corresponding systems/standards.

In this work, we propose a construction of so-called signature with efficient protocols (SEP), which is the core of such privacy-preserving solutions. By revisiting the approach by Jeudy et al. (Crypto 2023) we manage to get the best of the two alternatives mentioned above, namely short sizes with no compromise on security. To demonstrate this, we plug our SEP in an anonymous credential system, achieving credentials of less than 80 KB. In parallel, we fully implemented our system, and in particular the complex zero-knowledge framework of Lyubashevsky et al. (Crypto'22), which has, to our knowledge, not be done so far. Our work thus not only improves the state-of-the-art on privacy-preserving solutions, but also significantly improves the understanding of efficiency and implications for deployment in real-world systems.
]]></content:encoded>
<pubDate>Tue, 30 Jan 2024 10:37:10 +0000</pubDate>
</item>
<item>
<title>FaultyGarble: Fault Attack on Secure Multiparty Neural Network Inference</title>
<link>https://eprint.iacr.org/2024/980</link>
<guid>https://eprint.iacr.org/2024/980</guid>
<content:encoded><![CDATA[
<div> 关键词：深学习、多方计算、模型隐私、故障注入攻击、模型提取攻击

总结:

本文探讨了深学习在各种应用中的成功及其对用户数据和深度学习模型隐私的潜在威胁。随着安全多方计算技术的发展，用于解决隐私问题的提案数量显著增加，并在效率上取得了改进。然而，现有文献中对客户端行为的假设主要集中在客户端遵循协议的“被动”情况，而没有充分考虑客户端出于不同动机可能采取的“主动”恶意行为，以泄露模型所有权者的私有信息。

文章首次提出针对基于门控电路的安全推理实现的故障注入攻击，作为多方计算方案的一个例子。通过结合激光故障注入与模型提取攻击，作者成功地针对那些被假定安全免受主动攻击的解决方案进行了攻击。值得注意的是，该攻击所需的查询数量与在半诚实场景下针对安全推理引擎的最佳模型提取攻击相同。

这一发现强调了在设计安全多方计算方案时需要考虑客户端的恶意行为，特别是在模型隐私保护方面。它揭示了现有的安全措施可能存在的漏洞，并为未来的研究提供了方向，以开发更强大的防御策略和安全机制，确保模型隐私不受威胁。 <div>
The success of deep learning across a variety of
applications, including inference on edge devices, has led to
increased concerns about the privacy of users’ data and deep
learning models. Secure multiparty computation allows parties
to remedy this concern, resulting in a growth in the number
of such proposals and improvements in their efficiency. The
majority of secure inference protocols relying on multiparty
computation assume that the client does not deviate from the
protocol and passively attempts to extract information. Yet
clients, driven by different incentives, can act maliciously to
actively deviate from the protocol and disclose the deep learning
model owner’s private information. Interestingly, faults are
well understood in multiparty computation-related literature,
although fault attacks have not been explored. Our paper
introduces the very first fault attack against secure inference
implementations relying on garbled circuits as a prime example
of multiparty computation schemes. In this regard, laser fault
injection coupled with a model-extraction attack is successfully
mounted against existing solutions that have been assumed to
be secure against active attacks. Notably, the number of queries
required for the attack is equal to that of the best model extraction
attack mounted against the secure inference engines
under the semi-honest scenario.
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 02:42:02 +0000</pubDate>
</item>
<item>
<title>Atomic and Fair Data Exchange via Blockchain</title>
<link>https://eprint.iacr.org/2024/418</link>
<guid>https://eprint.iacr.org/2024/418</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、原子交换、可验证加密、承诺密钥、数据可用性

总结:

本文介绍了一种基于区块链的公平数据交换(FDE)协议，旨在实现数据文件的安全、原子级传输。该协议允许存储服务器与客户端进行交易，确保只有在服务器收到预约定价的支付后，客户端才能接收到文件。为保障这一过程的顺利执行，文章提出了“可验证加密在承诺密钥下”(VECK)的新定义，并提供了两种实现方案。

VECK机制确保了客户端在获取正确数据（符合预先设定的承诺）的前提下才需释放解密密钥，从而保证了数据的安全性。该协议设计简洁，仅需少量的区块链通信（3个签名、1个验证密钥和1个秘密密钥），大部分数据的存储和传输则在链下完成，降低了对区块链资源的消耗。此外，该协议还支持部分数据的交换、服务器工作负载的分摊以及使用不同承诺方案设计更多FDE协议的灵活性。

文章以Ethereum的Danksharding数据可用性方案为例，说明了利用KZG多项式承诺来实现数据承诺的可行性。同时，作者还提供了两种VECK实例的开源实现代码，展示了该协议在实际应用中的高效性和实用性。 <div>
We introduce a blockchain Fair Data Exchange (FDE) protocol, enabling a storage server to transfer a data file to a client atomically: the client receives the file if and only if the server receives an agreed-upon payment. We put forth a new definition for a cryptographic scheme that we name verifiable encryption under committed key (VECK), and we propose two instantiations for this scheme. Our protocol relies on a blockchain to enforce the atomicity of the exchange and uses VECK to ensure that the client receives the correct data (matching an agreed-upon commitment) before releasing the payment for the decrypting key. Our protocol is trust-minimized and requires only constant-sized on-chain communication, concretely 3 signatures, 1 verification key, and 1 secret key, with most of the data stored and communicated off-chain. It also supports exchanging only a subset of the data, can amortize the server's work across multiple clients, and offers a general framework to design alternative FDE protocols using different commitment schemes. A prominent application of our protocol is the Danksharding data availability scheme on Ethereum, which commits to data via KZG polynomial commitments. We also provide an open-source implementation for our protocol with both instantiations for VECK, demonstrating our protocol's efficiency and practicality on Ethereum.
]]></content:encoded>
<pubDate>Sat, 09 Mar 2024 23:41:14 +0000</pubDate>
</item>
<item>
<title>SPADE: Digging into Selective and PArtial DEcryption using Functional Encryption</title>
<link>https://eprint.iacr.org/2024/1387</link>
<guid>https://eprint.iacr.org/2024/1387</guid>
<content:encoded><![CDATA[
<div> 关键词：Functional Encryption、隐私保护、数据访问控制、细粒度控制、基因组学数据分析

总结:
文章主要介绍了SPADE，一种新型的功能加密方案。SPADE支持多用户环境，并通过部分解密密文提供了精细的数据访问控制。与现有功能加密方案不同的是，SPADE还支持对质性数据（如基因组学数据）的隐私保护分析，这极大地扩展了隐私保护分析的应用领域，尤其是在医疗保健和金融领域。为了验证其可行性，研究团队进行了大量的实验，分别在睡眠医学（如睡眠阶段图数据）和DNA分析（如基因记录）的数据集上进行了测试。

SPADE在功能加密领域是一个重要的进步，它平衡了隐私保护和数据分析的需求，提供了更全面的数据研究可能性。通过实现细粒度的数据访问控制，SPADE允许用户根据特定政策访问数据的特定部分，从而在保证隐私的同时促进数据的有效利用。此外，支持基因组学数据的分析使得SPADE在医疗研究和个性化医疗等领域具有巨大的应用潜力，能够帮助研究人员和医疗机构更深入地理解遗传信息与健康状况之间的关系。 <div>
Functional Encryption (FE) is a cryptographic technique established to guarantee data privacy while allowing the retrieval of specific results from the data.
While traditional decryption methods rely on a secret key disclosing all the data, FE introduces a more subtle approach. The key generation algorithm generates function-specific decryption keys that can be adaptively provided based on policies. Adaptive access control is a good feature for privacy-preserving techniques. Generic schemes have been designed to run basic functions, such as linear regression. However, they often provide a narrow set of outputs, resulting in a lack of thorough analysis. The bottom line is that despite significant research, FE still requires appropriate constructions to unleash its full potential in securely analyzing data and providing more insights. In this article, we introduce SPADE, a novel FE scheme that features multiple users and offers fine-grained access control through partial decryption of the ciphertexts. Unlike existing FE schemes, our construction also supports qualitative data, such as genomics, expanding the applications of privacy-preserving analysis to enable a comprehensive study of the data. SPADE is a significant advancement that balances privacy and data analysis with clear implications in healthcare and finance.
To verify its applicability, we conducted extensive experiments on datasets used in sleep medicine (hypnogram data) and DNA analysis (genomic records).
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 12:11:23 +0000</pubDate>
</item>
<item>
<title>Tightly Secure Non-Interactive BLS Multi-Signatures</title>
<link>https://eprint.iacr.org/2024/1368</link>
<guid>https://eprint.iacr.org/2024/1368</guid>
<content:encoded><![CDATA[
<div> 关键词：BLS、多签名、紧致安全性、兼容性、高效

总结:
本文引入了一种新的BLS多签名变体，该变体在保持与常规BLS完全兼容的同时实现了紧致安全性。这种新方案能够无缝地与常规BLS签名结合使用，从而生成常规的BLS签名。它还支持黑盒实现，易于集成到现有的BLS实现中。值得注意的是，该方案在非交互式多签名方面是最高效的方案之一，并且比之前的紧致安全性方案更为高效。通过证明，当前使用BLS进行权益证明协议的系统可以采用我们的变体，以获得完全兼容的、紧致的安全性选择。这一创新不仅提升了安全性，而且不影响系统的整体性能和兼容性，为区块链技术提供了更安全、高效的解决方案。 <div>
Due to their simplicity, compactness, and algebraic structure, BLS signatures are among the most widely used signatures in practice. For example, used as multi-signatures, they are integral in Ethereum's proof-of-stake consensus. From the perspective of concrete security, however, BLS (multi-)signatures suffer from a security loss linear in the number of signing queries. It is well-known that this loss can not be avoided using current proof techniques. 

In this paper, we introduce a new variant of BLS multi-signatures that achieves tight security while remaining fully compatible with regular BLS. In particular, our signatures can be seamlessly combined with regular BLS signatures, resulting in regular BLS signatures. Moreover, it can easily be implemented using existing BLS implementations in a black-box way. Our scheme is also one of the most efficient non-interactive multi-signatures, and in particular more efficient than previous tightly secure schemes. We demonstrate the practical applicability of our scheme by showing how proof-of-stake protocols that currently use BLS can adopt our variant for fully compatible opt-in tight security.
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 13:08:33 +0000</pubDate>
</item>
<item>
<title>Horcrux: Synthesize, Split, Shift and Stay Alive Preventing Channel Depletion via Universal and Enhanced Multi-hop Payments</title>
<link>https://eprint.iacr.org/2024/1338</link>
<guid>https://eprint.iacr.org/2024/1338</guid>
<content:encoded><![CDATA[
<div> 关键词：Horcrux, 多方虚拟通道协议, 流中立性, 安全性证明, 实验结果

总结:

本文介绍了Horcrux，一种无需额外信任假设、脚本语言或持续在线要求的全局通用可组合性框架下的多党虚拟通道协议。Horcrux通过引入流中立性概念，有效地解决了通道耗竭问题，降低了多跳支付对通道平衡分配的影响。文章还对Horcrux的安全性进行了正式证明，并通过模型分析了其性能。

实验结果显示，与Shaduf、Thora和Revive等现有重平衡方案相比，Horcrux的整个过程成本低于1美元，显著降低；支付成功率提高了12%-30%，用户为通道所需的押金减少了70%-91%；长期运行下，Horcrux的性能提高了1.2倍至1.5倍；最重要的是，Horcrux保持了几乎零通道耗竭率，而Revive和Shaduf则导致了数千个通道耗竭。

通过这些实证研究，本文表明Horcrux在解决当前区块链网络面临的扩展性和效率问题上具有明显优势，为改进支付通道网络的稳健性和规模提供了新的途径。 <div>
Payment Channel Networks (PCNs) have been highlighted as viable solutions to address the scalability issues in current permissionless blockchains. They facilitate off-chain transactions, significantly reducing the load on the blockchain. However, the extensive reuse of multi-hop routes in the same direction poses a risk of channel depletion, resulting in involved channels becoming unidirectional or even closing, thereby compromising the sustainability and scalability of PCNs. Even more concerning, existing rebalancing protocol solutions heavily rely on trust assumptions and scripting languages, resulting in compromised universality and reliability.

In this paper, we present Horcrux, a universal and efficient multi-party virtual channel protocol without relying on extra trust assumptions, scripting languages, or the perpetual online requirement. Horcrux fundamentally addresses the channel depletion problem using a novel approach termed flow neutrality, which minimizes the impact on channel balance allocations during multi-hop payments (MHPs). Additionally, we formalize the security properties of Horcrux by modeling it within the Global Universal Composability framework and provide a formal security proof.

We implement Horcrux on a real Lightning Network dataset, comprising 10,529 nodes and 38,910 channels, and compare it to the state-of-the-art rebalancing schemes such as Shaduf [NDSS'22], Thora [CCS'22], and Revive [CCS'17]. The experimental results demonstrate that (1) the entire process of Horcrux costs less than 1 USD, significantly lower than Shaduf; (2) Horcrux achieves a $12\%$-$30\%$ increase in payment success ratio and reduces user deposits required for channels by $70\%$-$91\%$; (3) the performance of Horcrux improves by $1.2x$-$1.5x$ under long-term operation; and (4) Horcrux maintains a nearly zero channel depletion rate, whereas both Revive and Shaduf result in thousands of depleted channels.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 07:15:02 +0000</pubDate>
</item>
<item>
<title>Jackpot: Non-Interactive Aggregatable Lotteries</title>
<link>https://eprint.iacr.org/2023/1570</link>
<guid>https://eprint.iacr.org/2023/1570</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式聚合彩票、安全保证、存储效率、可扩展性、随机预言机

文章主要探讨了在权益证明区块链中确保系统活性的方法。在这些系统中，通过选择随机的领导者群体来提议新区块和驱动共识进程，以确保系统的活跃性。然而，现有的解决方案需要将所有公开的获胜彩票单独存储在链上，这引入了不必要的存储开销。

为了解决这个问题，文章提出了非交互式聚合彩票的概念，并展示了一种高效构建此类彩票的方法。这种彩票不仅提供了与以往彩票构建相同的安全性保证，而且还允许第三方对已发布的获胜彩票进行聚合，生成一个简短的摘要。文章还提供了一个在通用组合框架下的形式模型，以及一种新的原语实现。

作为技术贡献的一部分，文章还引入了具有模拟提取性的可聚合向量承诺，并在有随机预言机的情况下给出了一个在代数组模型中的高效构造。这些承诺被用于构建非交互式聚合彩票。

文章还实现了名为Jackpot的构造，并提供了基准测试结果，以突出其实现的效率。

总结: 本文提出了非交互式聚合彩票，这是一种新型的彩票设计，它不仅可以降低存储开销，还能提高区块链系统的活性和可扩展性。通过引入可聚合向量承诺并结合随机预言机的概念，作者设计了一种高效、安全的彩票系统。此外，他们还实现了一个名为Jackpot的实例，并通过性能测试验证了其实际效率，展示了该方法在区块链应用中的潜力。 <div>
In proof-of-stake blockchains, liveness is ensured by repeatedly selecting random groups of parties as leaders, who are then in charge of proposing new blocks and driving consensus forward.
The lotteries that elect those leaders need to ensure that adversarial parties are not elected disproportionately often and that an adversary can not tell who was elected before those parties decide to speak, as this would potentially allow for denial-of-service attacks.
Whenever an elected party speaks, it needs to provide a winning lottery ticket, which proves that the party did indeed win the lottery.
Current solutions require all published winning tickets to be stored individually on-chain, which introduces undesirable storage overheads.

In this work, we introduce non-interactive aggregatable lotteries and show how these can be constructed efficiently.
Our lotteries provide the same security guarantees as previous lottery constructions, but additionally allow any third party to take a set of published winning tickets and aggregate them into one short digest.
We provide a formal model of our new primitive in the universal composability framework.

As one of our technical contributions, which may be of independent interest, we introduce aggregatable vector commitments with simulation-extractability and present a concretely efficient construction thereof in the algebraic group model in the presence of a random oracle.
We show how these commitments can be used to construct non-interactive aggregatable lotteries.
We have implemented our construction, called Jackpot, and provide benchmarks that underline its concrete efficiency.
]]></content:encoded>
<pubDate>Wed, 11 Oct 2023 11:34:15 +0000</pubDate>
</item>
<item>
<title>FLIP-and-prove R1CS</title>
<link>https://eprint.iacr.org/2024/1364</link>
<guid>https://eprint.iacr.org/2024/1364</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARKs、Prover、FLIP、Groth16、Filecoin

总结:
本文研究了一种新型的SNARK（可扩展性非交互式知识证明）协议，旨在解决资源有限的用户外包证明生成任务给外部实体（Prover）的问题。主要贡献包括设计了一个高效的折叠方案FLIP和一种改进的Groth16变体。

FLIP方案通过应用内部配对产品论证将具有相同语言的R1CS实例折叠成单个松弛R1CS实例，从而减少了证明时间和通信复杂性。任何适用于松弛R1CS语言的证明系统都可以用于验证最终实例。

其次，文章提出了一种针对Groth16的新型变体，该变体在保持相同的通信复杂度的同时，增加了两个额外的配对用于验证，并对可信设置进行了适应性修改。

与SnarkPack等现有解决方案相比，此方案在单个证明生成和聚合工作量上的总成本上提供了数量级级别的改进，特别适合于生成大量复杂电路SNARK的场景，如Filecoin分布式存储网络每天生成超过6百万个SNARK的情况。 <div>
In this work, we consider the setting where one or more users with low computational resources would lie to outsource the task of proof generation for SNARKs to one external entity, named Prover. We study the scenario in which Provers have access to all statements and witnesses to be proven beforehand. We take a different approach to proof aggregation and design a new protocol that reduces simultaneously proving time and communication complexity, without going through recursive proof composition. 
Our two main contributions: We first design FLIP, a communication efficient folding scheme where we apply the Inner Pairing Product Argument to fold R1CS instances of the same language into a single relaxed R1CS instance. Then, any proof system for relaxed R1CS language can be applied to prove the final instance. As a second contribution, we build a novel variation of Groth16 with the same communication complexity for relaxed R1CS and two extra pairings for verification, with an adapted trusted setup. 
Compared to SnarkPack - a  prior solution addressing scaling for multiple Groth16 proofs - our scheme improves in prover complexity by orders of magnitude, if we consider the total cost to generated the SNARK proofs one by one and the aggregation effort. 
An immediate application of our solution is Filecoin, a decentralized storage network based on incentives that generates more than 6 million SNARKs for large circuits of 100 million constraints per day.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 17:42:34 +0000</pubDate>
</item>
<item>
<title>A Documentation of Ethereum’s PeerDAS</title>
<link>https://eprint.iacr.org/2024/1362</link>
<guid>https://eprint.iacr.org/2024/1362</guid>
<content:encoded><![CDATA[
<div> 关键词：数据可用性采样、PeerDAS、加密技术、安全保证、以太坊共识层

总结:

本文旨在为加密社区提供对PeerDAS中所使用的加密技术的概述，鼓励创新与改进，并明确阐述了PeerDAS的安全保障。数据可用性采样（Data Availability Sampling）是一种方法，允许客户端在无需下载完整数据的情况下验证来自不可信来源的网络上数据的可用性。PeerDAS作为通向全面协议的桥梁，将被整合进以太坊的共识层，其安全性至关重要。

PeerDAS采用多项加密技术来实现这一目标，包括但不限于基于多项式承诺和张量码的解决方案。这些技术确保数据的完整性与真实性，即使在数据存储于分布式网络中时也能有效验证。同时，PeerDAS设计时充分考虑了安全保证，包括但不限于数据隐私保护、抗篡改性以及抵抗恶意节点攻击的能力。通过这些措施，PeerDAS不仅增强了以太坊网络的数据可用性，还提高了整体系统的安全性和可靠性。

为了促进加密社区对该技术的理解和持续优化，文章详细描述了PeerDAS的加密机制，明确了其在安全层面的承诺。这不仅为以太坊社区提供了重要的技术支持，也为整个加密领域的研究与实践提供了宝贵的资源。 <div>
Data availability sampling allows clients to verify availability of data on a peer-to-peer network provided by an untrusted source. This is achieved without downloading the full data by sampling random positions of the encoded data.

The long-term vision of the Ethereum community includes a comprehensive data availability protocol using polynomial commitments and tensor codes. As the next step towards this vision, an intermediate solution called PeerDAS is about to integrated, to bridge the way to the full protocol. With PeerDAS soon becoming an integral part of Ethereum's consensus layer, understanding its security guarantees is essential.

This document aims to describe the cryptography used in PeerDAS in a manner accessible to the cryptographic community, encouraging innovation and improvements, and to explicitly state the security guarantees of PeerDAS.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 16:00:57 +0000</pubDate>
</item>
<item>
<title>What Did Come Out of It? Analysis and Improvements of DIDComm Messaging</title>
<link>https://eprint.iacr.org/2024/1361</link>
<guid>https://eprint.iacr.org/2024/1361</guid>
<content:encoded><![CDATA[
<div> 关键词：Self-Sovereign Identity（SSI）、Decentralized Identifiers（DIDs）、DIDComm、Composable Security、Anonymity and Authenticity

总结:

本文详细分析了DIDComm的加密通信层，这是Self-Sovereign Identity（SSI）体系中一个关键组件。作者采用可组合安全方法，对DIDComm在通用网络上的安全性进行了全面建模，将其目标定义为一种强理想通信资源，以确保发送者的匿名性和真实性。

研究发现，提出的加密模式达到了预期的隐私和真实性水平，但泄露信息量仅限于由底层网络引发的泄漏（通过可参数化的资源表示）。进一步地，基于此模型，作者提出并证明了两个改进方案：一是优化算法，同时实现匿名性和真实性，符合DIDComm消息格式，其在密文大小和计算时间上分别比现有DIDComm提案提高了近2倍；二是新提出的DIDComm模式，具有匿名性保护特性，即它不会泄露超过网络本身引发的任何额外信息。最后，作者展示了如何将这一新模式整合到优化算法中，形成了一种高效的一体化模式，确保了全面的匿名性和真实性。

此研究不仅对DIDComm的加密机制进行了深入探索，还提出了实用的改进策略，为提升SSI体系中的数据隐私和安全性提供了理论基础和技术指导。 <div>
Self-Sovereign Identity (SSI) empowers individuals and organizations with full control over their data. Decentralized identifiers (DIDs) are at its center, where a DID contains a collection of public keys associated with an entity, and further information to enable entities to engage via secure and private messaging across different platforms. A crucial stepping stone is DIDComm, a cryptographic communication layer that is in production with version 2. Due to its widespread and active deployment, a formal study of DIDComm is highly overdue.

We present the first formal analysis of DIDComm’s cryptography, and formalize its goal of (sender-) anonymity and authenticity. We follow a composable approach to capture its security over a generic network, formulating the goal of DIDComm as a strong ideal communication resource. We prove that the proposed encryption modes reach the expected level of privacy and authenticity, but leak beyond the leakage induced by an underlying network (captured by a parameterizable resource).

We further use our formalism to propose enhancements and prove their security: first, we present an optimized algorithm that achieves simultaneously anonymity and authenticity, conforming to the DIDComm message format, and which outperforms the current DIDComm proposal in both ciphertext size and computation time by almost a factor of 2. Second, we present a novel DIDComm mode that fulfills the notion of anonymity preservation, in that it does never leak more than the leakage induced by the network it is executed over. We finally show how to merge this new mode into our improved algorithm, obtaining an efficient all-in-one mode for full anonymity and authenticity.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 13:44:02 +0000</pubDate>
</item>
<item>
<title>Understanding the Blockchain Interoperability Graph based on Cryptocurrency Price Correlation</title>
<link>https://eprint.iacr.org/2024/1357</link>
<guid>https://eprint.iacr.org/2024/1357</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链生态系统、加密货币、区块链互操作性、价格分析、去中心化金融（DeFi）

<br /><br />
总结:本文研究了当前加密货币领域的区块链生态系统及其互操作性，通过分析超过4800种在76个区块链上实现的加密货币在过去一年的日价格数据，揭示了不同区块链之间的关系。这一研究对于理解加密货币市场的动态和复杂性至关重要，特别是对于去中心化金融(DeFi)领域有着潜在的影响。研究发现，加密货币实施的区块链之间的相关性可以为投资者提供有价值的参考信息，帮助他们制定更有效的投资策略并进行风险管理。通过深入分析这些数据，研究人员能够构建一个互操作性图，展示不同区块链之间的连接性和交互性，从而为未来加密货币市场的发展提供洞见。

<br /><br /> <div>
Cryptocurrencies have gained high popularity in
recent years, with over 9000 of them, including major ones such
as Bitcoin and Ether. Each cryptocurrency is implemented on
one blockchain or over several such networks. Recently, various
technologies known as blockchain interoperability have been
developed to connect these different blockchains and create an
interconnected blockchain ecosystem. This paper aims to provide
insights on the blockchain ecosystem and the connection between
blockchains that we refer to as the interoperability graph. Our
approach is based on the analysis of the correlation between
cryptocurrencies implemented over the different blockchains.
We examine over 4800 cryptocurrencies implemented on 76
blockchains and their daily prices over a year. This experimental
study has potential implications for decentralized finance (DeFi),
including portfolio investment strategies and risk management.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 10:10:11 +0000</pubDate>
</item>
<item>
<title>Leakage-Resilience of Circuit Garbling</title>
<link>https://eprint.iacr.org/2024/1356</link>
<guid>https://eprint.iacr.org/2024/1356</guid>
<content:encoded><![CDATA[
<div> 关键词：泄漏-resilient garbling、GLNP、GLNPLR、侧通道攻击、性能比较

总结:

本文探讨了在存在部分内部秘密信息泄露的情况下，保持安全性的“抗泄漏归结”。作者通过增加对归结函数泄露的隐私、无意识和真实性概念，定义了其抗泄漏版本。研究发现，广泛使用的归结方案中存在额外的侧通道弱点，如线路标签重用和XOR泄露。为了解决这个问题，作者改进了Gueron等人的GLNP归结方案，引入了标签刷新的概念，并提出了名为GLNPLR的新变体。该方案在证明上满足了抗泄漏定义。性能对比显示，当带宽为2Gbps时，使用AES-NI的GLNPLR比带有第二级侧通道遮罩的HalfGates归结快60倍，不使用AES-NI时则快5倍。这表明，通过引入抗泄漏机制，即使在敏感于侧通道攻击的环境中，也可以实现高效的归结操作。 <div>
Due to the ubiquitous requirements and performance leap in the past decade, it has become feasible to execute garbling and secure computations in settings sensitive to side-channel attacks, including smartphones, IoTs and dedicated hardwares, and the possibilities have been demonstrated by recent works. To maintain security in the presence of a moderate amount of leaked information about internal secrets, we investigate {\it leakage-resilient garbling}. We augment the classical privacy, obliviousness and authenticity notions with leakages of the garbling function, and define their leakage-resilience analogues. We examine popular garbling schemes and unveil additional side-channel weaknesses due to wire label reuse and XOR leakages. We then incorporate the idea of label refreshing into the GLNP garbling scheme of Gueron et al. and propose a variant GLNPLR that provably satisfies our leakage-resilience definitions. Performance comparison indicates that GLNPLR is 60X (using AES-NI) or 5X (without AES-NI) faster than the HalfGates garbling with second order side-channel masking, for garbling AES circuit when the bandwidth is 2Gbps.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 07:53:32 +0000</pubDate>
</item>
<item>
<title>Votexx: Extreme Coercion Resistance</title>
<link>https://eprint.iacr.org/2024/1354</link>
<guid>https://eprint.iacr.org/2024/1354</guid>
<content:encoded><![CDATA[
<div> 关键词：VoteXX、极端强制抵抗、零知识证明、选举权威、信任代理

总结:

本文提出了一种名为VoteXX的新颖投票系统，旨在解决无监督投票中的“不当影响”问题，即投票购买和投票胁迫。与以往提案不同，该系统首次能够保护投票者免受学习了所有投票者密钥的强大敌手的攻击，这种特性被称为“极端强制抵抗”。当密钥被盗时，每个投票者或其可信代理（称为“刺猬”）可以“废除”（有效取消）他们的投票，这种行动不可逆转且无法归咎于投票者或其刺猬，且废除行为对投票者和刺猬的隐私都进行了保护。

系统允许投票者使用公私钥进行授权投票，并将公钥登记给选举权威以证明他们记忆了与私钥对应的密码短语。这样即使敌手获取了投票者的密钥，投票者本人仍保留有副本。担心密钥被窃取的投票者或通过委托给一个或多个不信任的代理（刺猬）监测密钥使用的恶意投票行为，并在零知识证明的帮助下，以隐私保护的方式取消这些投票。

相较于以往的提案，此系统能为最强大的敌手提供一定程度的防护，这些敌手甚至能获取所有密钥。其他抗胁迫协议要么未处理此类攻击、限制敌手能力，或者依赖于完全可信赖的第三方协助投票者管理密钥。 <div>
We provide a novel perspective on a long-standing challenge to the integrity of votes cast without the supervision of a voting booth: "improper influence,'' which we define as any combination of vote buying and voter coercion. In comparison with previous proposals, our system is the first in the literature to protect against a strong adversary who learns all of the voter's keys---we call this property "extreme coercion resistance.'' When keys are stolen, each voter, or their trusted agents (which we call "hedgehogs''), may "nullify'' (effectively cancel) their vote in a way that is unstoppable and irrevocable, and such that the nullification action is forever unattributable to that voter or their hedgehog(s). We demonstrate the security of our VoteXX system in the universal composability model. 

As in many other coercion-resistant systems, voters are authorized to vote with public-private keys. Each voter registers their public keys with the Election Authority (EA) in a way that convinces the EA that the voter has memorized a passphrase that corresponds to their private keys. As a consequence, if an adversary obtains a voter's keys, the voter also retains a copy. Voters concerned about adversaries stealing their private keys can themselves, or by delegating to one or more untrusted hedgehog(s), monitor the bulletin board for malicious ballots cast with their keys, and can act to nullify these ballots in a privacy-preserving manner with zero-knowledge proofs. 

In comparison with previous proposals, our system offers some protection against even the strongest adversary who learns all keys. Other coercion-resistant protocols either do not address these attacks, place strong limitations on adversarial abilities, or rely on fully trusted parties to assist voters with their keys.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 21:40:11 +0000</pubDate>
</item>
<item>
<title>Oblivious Pseudo Random Function base on Ideal Lattice, Application in PSI and PIR</title>
<link>https://eprint.iacr.org/2024/1349</link>
<guid>https://eprint.iacr.org/2024/1349</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、量子攻击、理想格假设、Oblivious Pseudorandom Function、Oblivious Transfer

总结:
本文旨在设计一种兼顾安全性与效率的新型Oblivious Pseudorandom Function（OPRF），以应对量子计算可能带来的威胁。通过基于理想格假设和Chase与Miao在2020年Crypto会议上提出的Oblivious Transfer技术，构建了一种高效且能够抵抗量子攻击的OPRF。该OPRF简化了结构设计，为隐私保护技术提供了更为安全和实用的解决方案。

本文进一步将构建的OPRF应用于隐私集交集(PSI)和私有信息检索(PIR)中，实现了在保持用户数据隐私的同时，提高了系统性能和安全性。通过采用Oblivious Transfer技术，确保了在数据交互过程中，参与方无法获取对方多余的信息，从而有效保护了敏感数据。

综上所述，本文通过创新性地结合理想格假设和Oblivious Transfer技术，不仅实现了OPRF的量子安全特性，还简化了其结构，提高了效率，成功应用于PSI和PIR，为隐私保护领域提供了一个全面且高效的解决方案。 <div>
Privacy set intersection (PSI) and private information retrieval (PIR) are important areas of research in privacy protection technology. One of the key tools for both is the oblivious pseudorandom function (OPRF). Currently, existing oblivious pseudorandom functions either focus solely on efficiency without considering quantum attacks, or are too complex, resulting in low efficiency. The aim of this paper is to achieve a balance: to ensure that the oblivious pseudorandom function can withstand quantum attacks while simplifying its structure as much as possible. This paper constructs an efficient oblivious pseudorandom function based on the ideal lattice hardness assumption and the oblivious transfer (OT) technique by Chase and Miao (CRYPTO 2020), and also constructs PSI and PIR.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 10:34:30 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Validation for an Offline Electronic Document Wallet using Bulletproofs</title>
<link>https://eprint.iacr.org/2024/1348</link>
<guid>https://eprint.iacr.org/2024/1348</guid>
<content:encoded><![CDATA[
<div> 关键词：电子钱包、零知识证明、官方政府文档、隐私保护、广泛适用性

总结:

文章描述了一种设计用于存放官方政府文件的电子钱包系统。该系统利用零知识证明技术，确保仅分享必要的信息，以此来解决向不可信第三方展示文件数据的问题。例如，允许用户证明自己已达到饮酒年龄。系统在满足多个实际应用约束的同时，实现这一目标，包括在离线场景下使用、采用不侵犯用户隐私的通用通信方法以及仅使用标准、广泛研究的加密算法构建，以提供足够的安全性。

为确保实用性与安全性，系统设计着重于：

1. **离线兼容性**：确保在无网络环境下也能正常运行，使用户能在任何情况下访问其电子文档。
   
2. **隐私保护**：仅分享所需信息，避免泄露额外敏感数据，维护用户隐私。
   
3. **广泛适用性**：使用易于获取且不侵犯隐私的通信方式，确保不同用户群体都能方便地使用。
   
4. **安全构建**：基于经过广泛研究的加密算法，确保数据传输和存储的安全性。
   
5. **综合考量**：在设计中平衡了功能、性能和安全性要求，最终成功实现了所有附加约束条件。

通过上述措施，电子钱包系统不仅解决了特定应用场景中的问题，而且在实用性和安全性方面达到了较高的标准，为用户提供了一个可靠、私密的官方文档存储解决方案。 <div>
We describe designs for an electronic wallet, meant for the housing
of official government documents, which solves the problem of
displaying document data to untrusted parties (e.g., in order to allow
users to prove that they are above the drinking age). The wallet
attains this goal by employing Zero-Knowledge Proof technologies,
ascertaining that nothing beyond the intended information is ever
shared. In order to be practically applicable, the wallet has to meet
many additional constraints, such as to be usable in offline scenarios,
to employ only widely-accessible communication methods which,
themselves, must not impinge on the user’s privacy, and to be
constructed solely over standard, widely-studied cryptographic
algorithms, offering appropriately high levels of cryptographic
security. We explain how our design was able to successfully meet
all such additional constraints.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 08:07:44 +0000</pubDate>
</item>
<item>
<title>TandaPay Whistleblowing Communities:  Shifting Workplace Culture Towards Zero-Tolerance Sexual Harassment Policies</title>
<link>https://eprint.iacr.org/2023/655</link>
<guid>https://eprint.iacr.org/2023/655</guid>
<content:encoded><![CDATA[
<div> 关键词：TandaPay、性骚扰政策、自审抑制、企业文化、去中心化报告协议

总结:

本文探讨了企业性骚扰政策存在的问题及其对员工的影响。主要问题在于这些政策更侧重于规避法律责任而非构建无骚扰的企业环境。员工在面对性骚扰时往往需要单独向人力资源部门报告，这导致了一个自我审查的环境，因为员工可能不信任HR能公正调解。这种现象在企业内部存在容忍某些类型骚扰的文化时尤为严重。

为了解决这些问题，论文提出了一种名为TandaPay的去中心化投诉报告协议。TandaPay旨在赋予举报群体自主权，使他们能够集体批准自己的骚扰指控。通过这一系统，员工不再依赖HR作为中介，从而减少了自我审查的可能性，因为他们现在可以自己掌控报告过程。

TandaPay还采用了一种创新的方法，利用财务激励来防止合谋行为，确保只有有效的指控才能被批准。这为公司提供了保证，即员工只能批准真实有效的投诉。

通过实施TandaPay，公司能够给予员工更大的自主权，目标是减少自我审查，增加事件报告，进而改变企业文化，使之更加尊重和负责任。 <div>
Abstract—Corporate sexual harassment policies often prioritize liability mitigation over the creation of a corporate culture free of harassment. Victims of sexual harassment are often required to report claims individually to HR. This can create an environment of self-censorship when employees feel that they cannot trust HR to act as an unbiased mediator. This problem is compounded when corporations have a culture that is tolerant of certain types of harassment. Forcing employees to report incidents to HR does nothing to address employees’ fear of bias and uncertainty. This paper presents TandaPay, a decentralized grievance reporting protocol designed to address sexual harassment. TandaPay empowers whistleblowing communities to collectively approve their own harassment claims. TandaPay reduces self-censorship by allowing employees to take ownership of the reporting process, as employees no longer need to rely on HR to act as an intermediary. The protocol employs a novel method of using financial incentives to guard against collusion. This provides corporations with a guarantee that employees can only approve valid claims. Using TandaPay, corporations can give employees greater autonomy with the goal of minimizing self-censorship. This increases the reporting of incidents, enabling workers to change the corporate culture to one of respect and accountability.
]]></content:encoded>
<pubDate>Tue, 09 May 2023 15:10:32 +0000</pubDate>
</item>
<item>
<title>Improved Reductions from Noisy to Bounded and Probing Leakages via Hockey-Stick Divergences</title>
<link>https://eprint.iacr.org/2024/1009</link>
<guid>https://eprint.iacr.org/2024/1009</guid>
<content:encoded><![CDATA[
<div> 关键词：理论与实践、侧信道攻击、模糊泄漏模型、Hockey-stick偏移、安全性证明

总结:本文深入探讨了理论与实践在密码学领域中的不一致性，特别是在面对泄漏时。理论研究中，提出了方便分析多种设计安全性的模型，如有界泄漏模型和随机探针模型。然而，在实践中，侧信道攻击产生的长记录通常带有噪声，提供有关内部计算的全面信息，这与理论模型有所偏差。文章进一步引入了基于Hockey-stick偏移的模糊泄漏模型，这是一种综合统计距离和差分隐私基础的新模型。作者通过实验展示了理论模型中对有界泄漏和随机探针的抵抗能力，能够有效转化为对模糊泄漏的抵抗力，相较于基于统计距离或互信息的模型，参数有所优化。此外，研究还提供了关于多泄漏组成的定理，揭示了这些连接在处理多个泄漏情况时的扩展性。值得注意的是，该研究不仅在理论上为安全性证明提供了新视角，还讨论了其在实际应用中的相关性和局限性。具体而言，研究结果适用于现实世界中具有噪声水平显著降低的实用泄漏函数，同时，对随机探针的减小也有助于推广先前的工作，尽管在某些情况下，当操作掩码的域大小增加时，仍存在限制。 <div>
There exists a mismatch between the theory and practice of cryptography in the presence of leakage. On the theoretical front, the bounded leakage model, where the adversary learns bounded-length but noiseless information about secret components, and the random probing model, where the adversary learns some internal values of a leaking implementation with some probability, are convenient abstractions to analyze the security of numerous designs. On the practical front, side-channel attacks produce long transcripts which are inherently noisy but provide information about all internal computations, and this noisiness is usually evaluated with closely related metrics like the mutual information or statistical distance. Ideally, we would like to claim that resilience to bounded leakage or random probing implies resilience to noisy leakage evaluated according to these metrics. However, prior work (Duc, Dziembowski and Faust, Eurocrypt 2014; Brian et al., Eurocrypt 2021) has shown that proving such reductions with useful parameters is challenging.    

In this work, we study noisy leakage models stemming from hockey-stick divergences, which generalize statistical distance and are also the basis of differential privacy. First, we show that resilience to bounded leakage and random probing implies resilience to our new noisy leakage model with improved parameters compared to models based on the statistical distance or mutual information. Second, we establish composition theorems for our model, showing that these connections extend to a setting where multiple leakages are obtained from a leaking  implementation. We complement our theoretical results with a discussion of practical relevance, highlighting that (i) the reduction to bounded leakage applies to realistic leakage functions with noise levels that are decreased by several orders of magnitude compared to Brian et al., and (ii) the reduction to random probing usefully generalizes the seminal work of Duc, Dziembowski, and Faust, although it remains limited when the field size in which masking operates grows (i.e., hockey-stick divergences can better hide the field size dependency of the noise requirements, but do not annihilate it).
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 11:45:22 +0000</pubDate>
</item>
<item>
<title>Pay Less for Your Privacy: Towards Cost-Effective On-Chain Mixers</title>
<link>https://eprint.iacr.org/2023/1222</link>
<guid>https://eprint.iacr.org/2023/1222</guid>
<content:encoded><![CDATA[
<div> 关键词：Tornado Cash, Merkle Pyramid Builder, Verifiable Computations, 隐私保护, 成本降低

总结:
本文提出了Merkle金字塔构建者方法，旨在通过在链上混合器中逐步构建Merkle树并根据每批存款更新树，从而降低使用混合器的整体成本。这种方法在减少存款平均成本方面表现出显著效果，与现有链上混合器相比，最高可减少7倍的成本。重要的是，这些改进不会损害用户的隐私。

此外，文章还提议利用可验证计算将Merkle树更新的责任从链上智能合约转移到离链客户端，进一步降低存款成本。分析显示，我们的设计确保了公平性，通过时间分布将Merkle树更新费用均匀分配给客户端。这为非隐私保护区块链用户提供了更经济、更私密的交易解决方案。 <div>
On-chain mixers, such as Tornado Cash (TC), have become a popular privacy solution for many non-privacy-preserving blockchain users. These mixers enable users to deposit a fixed amount of coins and withdraw them to another address, while effectively reducing the linkability between these addresses and securely obscuring their transaction history. However, the high cost of interacting with existing on-chain mixer smart contracts prohibits standard users from using the mixer, mainly due to the use of computationally expensive cryptographic primitives. For instance, the deposit cost of TC on Ethereum is approximately $1.1m$ gas (i.e., $66$ USD in June 2023), which is $53\times$ higher than issuing a base transfer transaction.


In this work, we introduce the Merkle Pyramid Builder approach, to incrementally build the Merkle tree in an on-chain mixer and update the tree per batch of deposits, which can therefore decrease the overall cost of using the mixer. Our evaluation results highlight the effectiveness of this approach, showcasing a significant reduction of up to $7\times$ in the amortized cost of depositing compared to state-of-the-art on-chain mixers. Importantly, these improvements are achieved without compromising users' privacy. Furthermore, we propose the utilization of verifiable computations to shift the responsibility of Merkle tree updates from on-chain smart contracts to off-chain clients, which can further reduce deposit costs. Additionally, our analysis demonstrates that our designs ensure fairness by distributing Merkle tree update costs among clients over time.
]]></content:encoded>
<pubDate>Fri, 11 Aug 2023 19:30:10 +0000</pubDate>
</item>
<item>
<title>PulpFHE: Complex Instruction Set Extensions for FHE Processors</title>
<link>https://eprint.iacr.org/2024/1315</link>
<guid>https://eprint.iacr.org/2024/1315</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算、隐私保护、传统加密、全同态加密（FHE）、PulpFHE

总结:

本文探讨了云计算环境下数据隐私保护的挑战，尤其是数据在云服务器上的传输和存储安全。传统的加密方法虽然能保护数据不被窃取，但在加密数据需要云服务提供商进行处理时却显得力不从心。为解决这一问题，全同态加密(FHE)技术应运而生，它允许在数据保持加密状态下进行运算。近年来，研究人员致力于开发专门针对FHE数据处理的处理器设计。

在此背景下，作者提出了PulpFHE，这是一种面向下一代FHE处理器优化的指令集扩展。PulpFHE提供对加密数据非线性操作的原生支持，显著提升了各种实际应用中的同态计算速度。通过引入这些定制化的FHE指令，不仅增强了数据处理效率，还提高了隐私保护水平，确保了数据在云环境下的安全性和有效性。这一创新成果为云计算领域提供了更安全、高效的解决方案，对于促进云计算的广泛应用具有重要意义。 <div>
The proliferation of attacks to cloud computing, coupled with the vast amounts of data outsourced to online services, continues to raise major concerns about the privacy for end users. Traditional cryptography can help secure data transmission and storage on cloud servers, but falls short when the already encrypted data needs to be processed by the cloud provider. An emerging solution to this challenge is fully homomorphic encryption (FHE), which enables computations directly on encrypted data, and recent works have focused on developing new processor designs tailored for native processing of FHE data. In this work, we introduce PulpFHE, an optimized instruction set extension tailored for the next generation of FHE processors. Our proposed FHE instructions offer native support for non-linear operations on encrypted data, and enable significantly faster homomorphic computations for a broad range of realistic applications.
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 17:06:23 +0000</pubDate>
</item>
<item>
<title>Dynamic Threshold Key Encapsulation with a Transparent Setup</title>
<link>https://eprint.iacr.org/2024/1311</link>
<guid>https://eprint.iacr.org/2024/1311</guid>
<content:encoded><![CDATA[
<div> 关键词：动态TKEM、透明设置、配对操作、决策性Diffie-Hellman假设、安全性证明

总结: 文章提出了一种动态阈值密钥封装机制（TKEM），旨在解决现有构建依赖于可信设置的问题。这种机制允许在不依赖第三方的情况下，灵活选择接收者和阈值，从而提高了系统的安全性和鲁棒性。它不使用配对运算，而是基于决策性Diffie-Hellman假设来确保选择性选择-密文安全性和解封装一致性。通过安全证明和概念验证实现，该方法不仅提高了阈值加密领域的实践可行性，也显著提升了效率，为分布式系统提供了更安全、灵活的密钥分发方案。 <div>
A threshold key encapsulation mechanism (TKEM) facilitates the secure distribution of session keys among multiple participants, allowing key recovery through a threshold number of shares. TKEM has gained significant attention, especially for decentralized systems, including blockchains. However, existing constructions often rely on trusted setups, which pose security risks such as a single point of failure, and are limited by fixed participant numbers and thresholds. To overcome this, we propose a dynamic TKEM with a transparent setup, allowing for a flexible selection of recipients and thresholds without relying on trusted third parties in the setup phase. In addition, our construction does not rely on pairing operations. We prove the security of our TKEM under the decisional Diffie-Hellman assumption, ensuring selective chosen-ciphertext security and decapsulation consistency. Our proof-of-concept implementation highlights the practicality and efficiency of this approach, advancing the field of threshold cryptography.
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 07:09:30 +0000</pubDate>
</item>
<item>
<title>Kalos: Hierarchical-auditable and Human-binding Authentication Scheme for Clinical Trial</title>
<link>https://eprint.iacr.org/2024/1301</link>
<guid>https://eprint.iacr.org/2024/1301</guid>
<content:encoded><![CDATA[
<div> 关键词：Kalos、临床试验、隐私保护、数据可靠性、信任鸿沟

文章主要介绍了一种名为Kalos的新颖认证方案，旨在解决临床试验中数据收集和处理过程中面临的数据隐私保护与可靠性之间的权衡问题。该方案利用了多样化的加密工具，如基于卡片的匿名凭证和零知识证明，实现了可视化验证和属性选择性披露，从而支持层次审计和数据去重，以提高临床试验的可靠性。Kalos具有不可伪造性、盲性、隐私保护和人性绑定等特性，有助于解决物理世界与数字世界之间的信任差距。

总结:
Kalos认证方案为临床试验提供了一种创新的解决方案，通过结合多种加密技术，实现了在确保数据隐私的同时，增强数据可靠性和可审计性。它解决了传统方法在处理大量参与者数据时面临的信任鸿沟问题，通过提供可视化的验证过程和对属性的选择性披露，Kalos不仅提高了数据的可信度，还有效防止了数据重复录入的问题。该方案的计算成本不依赖于认证属性的数量，且在常见属性数量下，总计算时间保持在毫秒级范围内，这使得Kalos具有在医疗消费电子产品场景中部署的潜力。 <div>
Clinical trials are crucial in the development of new medical treatment methods. To ensure the correctness of clinical trial results, medical institutes need to collect and process large volumes of participant data, which has prompted research on privacy preservation and data reliability. However, existing solutions struggle to resolve the trade-off between them due to the trust gap between the physical and digital worlds, limiting their practicality. To tackle the issues above, we present Kalos, a novel authentication scheme for clinical trials. Kalos leverages diversified cryptographic tools, such as card-based anonymous credential and zero-knowledge proof to achieve authentication with visual verification and selective disclosure of attributes. It has properties such as unforgeability, blindness, privacy preservation, and human-binding that support hierarchical auditability and data de-duplication to enhance the reliability of clinical trials. We then provide the security and performance analysis of Kalos to show its potential to be deployed in the medical consumer electronics scenario. The computational cost of the smartcard is irrespective of the number of certified attributes, and the total computational cost of Kalos is within tens of milliseconds with the commonly used number of attributes.
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 09:35:32 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Succinct Mercurial Functional Commitment for Boolean Circuits: Definitions and Constructions</title>
<link>https://eprint.iacr.org/2024/617</link>
<guid>https://eprint.iacr.org/2024/617</guid>
<content:encoded><![CDATA[
<div> 关键词：Vector Commitments（VC）、Mercurial Vector Commitments（MVC）、Mercurial Functional Commitments（MFC）、Zero-Knowledge Sets、Lattice-Based Cryptography

总结:

文章首先提出了梅尔库里矢量承诺（MVC）和梅尔库里功能承诺（MFC）的系统和安全性模型，以支持布尔电路。这解决了现有MFC仅支持线性函数的问题，扩大了其在构建具有线性函数查询能力的零知识集合和零知识功能基础数据库（ZK-FEDB）中的应用范围。然而，当前的MFC和ZK-FEDB主要基于群假设，无法抵抗量子计算机攻击。

为解决这一问题，作者引入了一种新的可验证假设——Wee和Wu在EUROCRYPT '23中提出的BASIS假设，以此为基础构建了第一个基于格的简洁梅尔库里功能承诺，用于布尔电路。这种承诺机制不仅克服了现有方法的局限性，还确保了安全性和抗量子攻击的能力。

通过将此承诺机制应用于构建第一个基于格的ZK-FEDB，文章展示了其在现有通用框架下的应用潜力，显著扩展了零知识技术在复杂查询场景中的适用性。这一创新不仅丰富了密码学领域的理论研究，也为实际应用提供了更安全、更高效的解决方案。 <div>
Vector commitments (VC) have gained significant attention due to their extensive use in applications such as blockchain and accumulators. Mercurial vector commitments (MVC) and mercurial functional commitments (MFC), as variants of VC, are central techniques for constructing more advanced cryptographic primitives, such as zero-knowledge sets and zero-knowledge functional elementary databases (ZK-FEDB). However, existing MFCs $\textit{only support linear functions}$, which limits their applicability—for instance, in building ZK-FEDBs that support only linear function queries. Moreover, to the best of our knowledge, the current MFCs and ZK-FEDBs, including the state-of-the-art proposed by Zhang and Deng (ASIACRYPT '23) using RSA accumulators, are all based on group-based assumptions and $\textit{cannot resist quantum computer attacks}$.

To address these limitations, we $\textit{first}$ formalize the system and security models of MFC to support Boolean circuits. Then, we target specific properties of a new falsifiable assumption, namely the $\mathsf{BASIS}$ assumption proposed by Wee and Wu (EUROCRYPT '23), to construct the $\textit{first}$ lattice-based succinct mercurial functional commitment for Boolean circuits. As an application of our construction, we demonstrate how it can be used to build the $\textit{first}$ lattice-based ZK-FEDB within the existing generic framework.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 09:29:41 +0000</pubDate>
</item>
<item>
<title>Permissionless Verifiable Information Dispersal (Data Availability for Bitcoin Rollups)</title>
<link>https://eprint.iacr.org/2024/1299</link>
<guid>https://eprint.iacr.org/2024/1299</guid>
<content:encoded><![CDATA[
<div> 关键词：Rollups、比特币、数据可用性、Verifiable Information Dispersal（VID）、状态机复制（SMR）

总结:

文章主要探讨了如何在比特币网络中引入数据可用性问题的解决方案，以提高其作为分布式账本的效率。Rollups作为一种特殊应用，通过在主区块链之外的辅助机器上执行交易，来解决交易吞吐量和成本问题。然而，当计算瓶颈被移除后，通信成为新的瓶颈。

Verifiable Information Dispersal（VID）系统被提出作为解决数据可用性问题的关键技术，它能以比线性更小的通信开销确保数据的可获取性。该系统适用于比特币的无许可模型，需要一个额外的假设：参与者之间存在可靠的通信机制。VID系统与比特币的状态机复制（SMR）协议结合，实现了对数据可用性的保障，同时保持了与比特币的兼容性。

作者通过在比特币核心的回归测试网络（regtest）上实现VID系统，证明了其在减少通信成本和降低延迟方面有显著效果，通信成本降低了超过1000倍，延迟降低了超过10倍。这一改进对于提升比特币网络的效率和扩展性具有重要意义。 <div>
Rollups are special applications on distributed state machines (aka blockchains) for which the underlying state machine only logs, but does not execute transactions. Rollups have become a popular way to scale applications on Ethereum and there is now growing interest in running rollups on Bitcoin. Rollups scale throughput and reduce transaction costs by using auxiliary machines that have higher throughput and lower cost of executing transactions than the underlying blockchain. State updates are periodically posted to the underlying blockchain and either verified directly through succinct cryptographic proofs (zk rollups) or can be challenged for a defined period of time in a verifiable way by third parties (optimistic rollups). 
   
However, once computation is removed as a bottleneck, communication quickly becomes the new bottleneck. The critical service the underlying blockchain provides in addition to verification is data availability: that necessary data can always be recovered upon request. While broadcasting transaction data is one way to ensure this, it requires communication blowup linear in the number of participating nodes. Verifiable information dispersal (VID) systems achieve sublinear blowup in the same participation model and the same security assumptions as Ethereum, where all nodes have a strong public-key identity. It was not known how to do so in the same permissionless model as Bitcoin, where participants are unauthenticated and participation is dynamic. 
    
We construct a VID system that is secure under the same model as Bitcoin, with one minimal additional requirement on the existence of reliable participants.  Our system uses a state machine replication (SMR) protocol (e.g., Bitcoin) as a black box, and is therefore backward compatible. We implemented the system on top of Bitcoin core with the Regression Test Network (regtest), and our analysis shows that it reduces communication costs by more than 1,000x and latency by more than 10x.
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 00:20:03 +0000</pubDate>
</item>
<item>
<title>SoK: Computational and Distributed Differential Privacy for MPC</title>
<link>https://eprint.iacr.org/2024/1290</link>
<guid>https://eprint.iacr.org/2024/1290</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、多方计算、计算性定义、分布式版本、多分布模型

总结:

本文系统化了过去十五年中，差分隐私与多方计算等加密领域融合产生的各种定义。这些定义结合了实用性和理论性，针对不同应用场景和现有加密工具进行了定制，形成了计算性和分布式版本的差分隐私。文章按照分布模型和计算视角对定义进行排序，并提出识别通用概念的视角。排序揭示了定义之间的清晰层级关系，允许用户权衡准确性与更强隐私保护或更少信任假设之间的取舍。

文章还探讨了定义之间的理论结果，并扩展了一些结果。它还讨论了知名开放问题的状态并提出了新的研究方向。最后，文章考虑了不同概念的实际应用方面，为未来的研究提供了指导。通过分析各种定义的特性，该工作有助于理解和选择最适合特定场景的差分隐私定义，从而促进安全、隐私保护的数据处理技术的发展。 <div>
In the last fifteen years, there has been a steady stream of works combining differential privacy with various other cryptographic disciplines, particularly that of multi-party computation, yielding both practical and theoretical unification. As a part of that unification, due to the rich definitional nature of both fields, there have been many proposed definitions of differential privacy adapted to the given use cases and cryptographic tools at hand, resulting in computational and/or distributed versions of differential privacy. In this work, we offer a systemization of such definitions, with a focus on definitions that are both computational and tailored for a multi-party setting. We order the definitions according to the distribution model and computational perspective and propose a viewpoint on when given definitions should be seen as instantiations of the same generalised notion. The ordering highlights a clear, and sometimes strict, hierarchy between the definitions, where utility (accuracy) can be traded for stronger privacy guarantees or lesser trust assumptions. Further, we survey theoretical results relating the definitions to each other and extend some such results. We also discuss the state of well-known open questions and suggest new open problems to study. Finally, we consider aspects of the practical use of the different notions, hopefully giving guidance also to future applied work.
]]></content:encoded>
<pubDate>Fri, 16 Aug 2024 13:39:14 +0000</pubDate>
</item>
<item>
<title>Improved Lattice Blind Signatures from Recycled Entropy</title>
<link>https://eprint.iacr.org/2024/1289</link>
<guid>https://eprint.iacr.org/2024/1289</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、后量子计算、拉格矩阵、零知识证明、隐私保护

总结:本文提出了一种新的设计，旨在缓解盲签名过程中“显示”阶段的复杂性问题。通过在“发行”阶段注入过量随机性，并利用显示阶段回收熵余量来简化零知识证明的复杂度。这一设计不仅使得盲签名方案具有较小的大小和较低的计算复杂度，而且仍基于广为人知的拉格矩阵假设，从而实现了隐私保护的同时提高了效率和安全性。与现有基于拉格矩阵的盲签名构造相比，该方案在保持或增强某些关键特性（如安全性、效率）的同时，解决了其他方面的问题，例如签名尺寸和执行效率。这标志着在后量子计算背景下，对于盲签名技术研究的一个重要进展。 <div>
Blind signatures represent a class of cryptographic primitives enabling privacy-preserving authentication with several applications such as e-cash or e-voting. It is still a very active area of research, in particular in the post-quantum setting where the history of blind signatures has been hectic. Although it started to shift very recently with the introduction of a few lattice-based constructions, all of the latter give up an important characteristic of blind signatures (size, efficiency, or security under well-known assumptions) to achieve the others. In this paper, we propose another design which revisits the link between the two main procedures of blind signatures, namely issuance and showing, demonstrating that we can significantly alleviate the second one by adapting the former. Concretely, we show that we can harmlessly inject excess randomness in the issuance phase, and then recycle the entropy surplus during showing to decrease the complexity of the zero-knowledge proof which constitutes the main component of the signature. This leads to a blind signature scheme with small sizes, low complexity, and that still relies on well-known lattice assumptions.
]]></content:encoded>
<pubDate>Fri, 16 Aug 2024 11:59:01 +0000</pubDate>
</item>
<item>
<title>REACTIVE: Rethinking Effective Approaches Concerning Trustees in Verifiable Elections</title>
<link>https://eprint.iacr.org/2024/915</link>
<guid>https://eprint.iacr.org/2024/915</guid>
<content:encoded><![CDATA[
<div> 关键词：选举系统、可信执行、隐私保护、密钥生成、安全证明

文章主要探讨了设计可验证选举系统时面临的两大核心问题：如何确保结果的公正性以及如何保护选民的投票隐私。文中指出，虽然已经提出了多种解决方案来解决第一个问题，如使用混合网络和同态汇总等技术，但在学术文献中，对于第二个问题的回答一直相对单一，即通过将解密权限分散给多个独立的“托管人”，以防止恶意联合泄露隐私。

然而，实际部署过程中发现这一模式存在挑战。人工托管人往往缺乏明确职责认知，且通常使用相同的软件执行任务，这可能导致他们更像是执行特定指令的机器，而非真正维护隐私的守护者。文章进一步分析了选举中使用的各种加密协议对托管人的角色影响，并指出即使是理论上的正确使用托管人也比想象的复杂得多。文章还指出，其中一种仅有的描述选举中完整阈值分布式密钥生成（DKG）方法的参考文献实际上定义了一个不安全的协议，而Belenios声称依赖于该文献进行其DKG和安全性证明，但并未继承同样的漏洞。文章为此提供了Belenios DKG的安全证明。

文章随后讨论了人类、软件和硬件在实践层面对基于托管人模型的隐私保护实现的影响。总结:

文章首先深入探讨了选举系统设计中关于结果公正性和选民隐私保护的两大核心问题。接着，它强调了学术界对于保护隐私方法的传统理解——依赖于将解密权限分配给多个独立“托管人”的策略，尽管这一策略理论上旨在防止隐私泄露，但在实际操作中面临多重挑战，包括托管人职责模糊、使用相同软件执行任务可能导致执行成为被动的执行者而非隐私保护者。

文章进一步揭示了一种描述选举中使用分布式密钥生成（DKG）方法的参考文献实际上存在安全漏洞，指出Belenios声称基于此文献构建其DKG和安全证明，但并未直接继承该漏洞。最后，文章提供了针对Belenios DKG的详细安全证明，以增强选民隐私保护的技术基础。此外，文章还分析了在不同实践场景下，如涉及人类、软件和硬件的交互，对基于托管人模型的隐私保护部署的具体影响，突显了理论与实践之间的差异及其复杂性。 <div>
For more than forty years, two principal questions have been asked when designing verifiable election systems: how will the integrity of the results be demonstrated and how will the privacy of votes be preserved? Many approaches have been taken towards answering the first question such as use of MixNets and homomorphic tallying. But in the academic literature, the second question has always been answered in the same way: decryption capabilities are divided amongst multiple independent “trustees” so that a collusion is required to compromise privacy.

In practice, however, this approach can be fairly challenging to deploy. Human trustees rarely have a clear understanding of their responsibilities, and they typically all use identical software for their tasks. Rather than exercising independent judgment to maintain privacy, trustees are often reduced to automata who just push the buttons they are told to when they are told to, doing little towards protecting voter privacy. This paper looks at several aspects of the trustee experience. It begins by discussing various cryptographic protocols that have been used for key generation in elections, explores their impact on the role of trustees, and notes that even the theory of proper use of trustees is more challenging than it might seem. This is illustrated by showing that one of the only references defining a full threshold distributed key generation (DKG) for elections defines an insecure protocol. Belenios claims to rely on that reference for its DKG and security proof. Fortunately, it does not inherit the same vulnerability. We offer a security proof for the Belenios DKG. 

The paper then discusses various practical contexts, in terms of humans, software, and hardware, and their impact on the practical deployment of a trustee-based privacy model.
]]></content:encoded>
<pubDate>Fri, 07 Jun 2024 23:01:34 +0000</pubDate>
</item>
<item>
<title>Elastic MSM: A Fast, Elastic and Modular Preprocessing Technique for Multi-Scalar Multiplication Algorithm on GPUs</title>
<link>https://eprint.iacr.org/2024/057</link>
<guid>https://eprint.iacr.org/2024/057</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、GPU、多尺度乘法、预处理技术、Pippenger算法

总结:
本文主要关注在GPU上优化多尺度乘法（MSM）算法的运行时间和存储空间需求。提出了一种名为“弹性MSM”的新颖、模块化和自适应参数配置技术，允许用户根据自己的需求调整MSM的规模，通过相应的预处理操作。该技术能够充分利用各种高效的并行MSM算法潜力。研究者在GPU上实现了并测试了弹性MSM，针对三种主流的Pippenger并行算法进行了优化。

弹性MSM不仅被视为Pippenger算法的一种预处理技术，而且具有模块性，可以加速几乎所有最先进的GPU上的Pippenger并行算法。此外，它提供了在不同存储空间限制下GPU上的Pippenger算法运行时间与额外存储空间需求之间的可调折衷方案。这是首次在不同的存储空间限制下保留预处理带来的改进MSM计算的技术。

研究结果显示，针对三种并行Pippenger算法，弹性MSM分别实现了约1.90×、1.08×和1.36×（2.58×、1.39×和1.91×）的加速效果。同时，对于两种最先进的预处理Pippenger算法，弹性MSM分别实现了约192×和223×（159×和174×）的加速效果。这些结果表明，弹性MSM显著提高了零知识证明中的多尺度乘法运算效率，为GPU上的大规模加密计算提供了有力支持。 <div>
Zero-knowledge proof (ZKP) is a cryptographic primitive that enables a prover to convince a verifier that a statement is true, without revealing any other information beyond the correctness of the statement itself. Due to its powerful capabilities, its most practical type, called zero-knowledge Succinct Non-interactive ARgument of Knowledge (zkSNARK), has been widely deployed in various privacy preserving applications such as cryptocurrencies and verifiable computation. Although state-of-the-art zkSNARKs are highly efficient for the verifier, the computational overhead for the prover is still orders of magnitude too high to warrant use in many applications. This overhead arises from several time-consuming operations, including large-scale matrix-vector multiplication (MUL), number-theoretic transform (NTT), and especially the multi-scalar multiplication (MSM) which constitutes the largest proportion. Therefore, further efficiency improvements are needed.

  In this paper, we focus on comprehensive optimization of running time and storage space required by the MSM algorithm on GPUs. Specifically, we propose a novel, modular and adaptive parameter configuration technique—elastic MSM to enable us to adjust the scale of MSM according to our own wishes by performing a corresponding amount of preprocessing. This technique enables us to fully unleash the potential of various efficient parallel MSM algorithms. We have implemented and tested elastic MSM over three prevailing parallel Pippenger algorithms on GPUs. Across various preprocessing space limitations (across various MSM scales), our constructions achieve up to about 1.90×, 1.08× and 1.36× (2.58×, 1.39× and 1.91×) speedup versus three state-of-the-art parallel Pippenger algorithms on GPUs, respectively.

  From another perspective, elastic MSM could also be regarded as a preprocessing technique over the well-known Pippenger algorithm, which is modular and could be used to accelerate almost all the most advanced parallel Pippenger algorithms on GPUs. Meanwhile, elastic MSM provides an adaptive trade-off between the running time and the extra storage space needed by parallel Pippenger algorithms on GPUs. This is the first preprocessing technique to retain the improved MSM computation brought by preprocessing under varying storage space limitations. Specifically, across various preprocessing space limitations (across various MSM scales), our constructions achieve up to about 192× and 223× (159× and 174×) speedup versus two state-of-the-art preprocessing parallel Pippenger algorithms on GPUs, respectively.
]]></content:encoded>
<pubDate>Mon, 15 Jan 2024 07:19:29 +0000</pubDate>
</item>
<item>
<title>Stackproofs: Private proofs of stack and contract execution using Protogalaxy</title>
<link>https://eprint.iacr.org/2024/1281</link>
<guid>https://eprint.iacr.org/2024/1281</guid>
<content:encoded><![CDATA[
<div> 关键词：zk-SNARK、Aztec协议、增量可验证计算、重复计算与全局状态、证明系统

总结:

本文探讨了一种简化版的zk-SNARK构造方法，该方法被应用于Aztec协议中。该方法受增量可验证计算(IVC)启发，提出了“重复计算与全局状态”(RCG)的概念。与IVC不同，RCG假定计算在证明开始前结束，并允许一些全局一致性检查，同时要求证明者空间效率接近于无需证明全局一致性的IVC证明者。

在设计私有智能合约系统如Aztec时，RCG证明系统显得尤为有用。通过利用RCG，Aztec能够确保计算过程的隐私性，同时保证全局状态的一致性，这在构建安全、高效且私密的区块链应用时至关重要。这种证明系统的应用不仅提高了计算的隐私保护能力，还优化了证明者处理数据和执行一致性检查的方式，从而实现了更高的性能和更低的空间复杂度。

通过将RCG融入Aztec协议中，可以构建出一个既能满足高隐私需求又能保证系统稳定性和效率的智能合约环境。这不仅为区块链技术在实际应用中的隐私保护提供了新的思路，也为未来的智能合约设计提供了可能的方向。 <div>
The goal of this note is to describe and analyze a simplified variant of the zk-SNARK construction used in the Aztec protocol.
Taking inspiration from the popular notion of Incrementally Verifiable Computation[Val09] (IVC)
we define a related notion of $\textrm{Repeated Computation with Global state}$ (RCG). As opposed to IVC, in RCG we assume the computation terminates before proving starts, and in addition to the local transitions some global consistency checks of the whole computation are allowed. However, we require the space efficiency of the prover to be close to that of an IVC prover not required to prove this global consistency.
We show how RCG is useful for designing a proof system for a private smart contract system like Aztec.
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 00:50:12 +0000</pubDate>
</item>
<item>
<title>OPTIKS: An Optimized Key Transparency System</title>
<link>https://eprint.iacr.org/2023/1515</link>
<guid>https://eprint.iacr.org/2023/1515</guid>
<content:encoded><![CDATA[
<div> 关键词：OPTIKS、公开密钥分布系统、可扩展性、安全性、隐私性

总结:

本文介绍了名为OPTIKS的全面优化且具有可扩展性的密钥透明度（KT）系统。与以往工作相比，该系统在设计上更为简洁高效，能够以更小的存储开销支持更强的安全性和隐私性要求。其核心贡献包括：

1. **优化设计**：OPTIKS通过简化设计和提升性能，实现了对现有构建的改进，使其更适合实际应用，同时保证了系统的稳定性和效率。

2. **抗故障架构**：系统采用了具有抗故障特性的服务器架构，确保了在机器失效情况下仍能维持正常运行，显著提升了系统的可扩展性和鲁棒性。

3. **全面功能**：除了基础的密钥透明度功能外，OPTIKS还考虑到了账户撤销和用户到设备映射等现实世界中的问题，提高了系统适用范围和实用性。

4. **安全与隐私**：系统设计中融入了强安全性和隐私保护机制，确保了用户数据的安全和匿名性，增强了用户信任。

5. **性能验证**：通过详细的基准测试，证明了OPTIKS在实际应用中的高效表现，为系统的广泛部署提供了有力的数据支持。

综上所述，OPTIKS不仅提供了一种高效的密钥透明度解决方案，而且在设计、性能、安全性和实用性方面均表现出色，为密钥管理领域带来了重要的进步。 <div>
Key Transparency (KT) refers to a public key distribution system with transparency mechanisms proving its correct operation, i.e., proving that it reports consistent values for each user's public key. While prior work on KT systems have offered new designs to tackle this problem, relatively little attention has been paid on the issue of scalability. Indeed, it is not straightforward to actually build a scalable and practical KT system from existing constructions, which may be too complex, inefficient, or non-resilient against machine failures.

In this paper, we present OPTIKS, a full featured and optimized KT system that focuses on scalability. Our system is simpler and more performant than prior work, supporting smaller storage overhead while still meeting strong notions of security and privacy. Our design also incorporates a crash-tolerant and scalable server architecture, which we demonstrate by presenting extensive benchmarks. Finally, we address several real-world problems in deploying KT systems that have received limited attention in prior work, including account decommissioning and user-to-device mapping.
]]></content:encoded>
<pubDate>Wed, 04 Oct 2023 19:49:16 +0000</pubDate>
</item>
<item>
<title>Cryptographic Analysis of the Bluetooth Secure Connection Protocol Suite</title>
<link>https://eprint.iacr.org/2021/1597</link>
<guid>https://eprint.iacr.org/2021/1597</guid>
<content:encoded><![CDATA[
<div> 关键词：蓝牙、安全连接协议套件、分析、攻击、信任首次使用

总结:
本文对蓝牙安全连接协议套件进行了深入的加密分析。分析了该协议套件中的多个子协议，如数字比较、密码输入和无需工作的功能，以适应不同设备的输入/输出能力。与以往仅关注单个子协议安全性的研究不同，本文着重于不同子协议间的交互可能引发的安全问题，特别是通过方法混淆攻击等实际验证的攻击手段，这些攻击表明无法证明蓝牙协议套件是一个安全的认证密钥交换协议。

为了应对这些挑战，文章提出了假设的信任首次使用（TOFU）关系下的安全策略，即确保协议在初次连接时抵御主动攻击，随后的连接则可视为安全。同时，文章也探讨了蓝牙低功耗版本中的地址随机化机制，指出其在提供一定程度的地址隐私方面表现良好，但不能排除通过其他方式识别设备的可能性，例如物理特性。

总的来说，虽然蓝牙安全连接协议套件存在潜在的安全风险，尤其是在不同子协议间的交互上，但通过适当的策略和假设，仍能在一定程度上保证通信的安全性和隐私性。 <div>
We give a cryptographic analysis of the Bluetooth Secure Connections Protocol Suite. Bluetooth supports several subprotocols, such as Numeric Comparison, Passkey Entry, and Just Works, in order to match the devices' different input/output capabilities.

Previous analyses (e.g., Lindell, CT-RSA'09, or Troncoso and Hale, NDSS'21) often considered (and confirmed) the security  of single subprotocols only. Recent practically verified attacks, however, such as the Method Confusion Attack (von Tschirschnitz et al., S&amp;P'21) against Bluetooth's authentication and key secrecy property, often exploit the bad interplay of different subprotocols. Even worse, some of these attacks demonstrate that one cannot prove the Bluetooth protocol suite to be a secure authenticated key exchange protocol.

We therefore aim at the best we can hope for and show that the protocol still matches the common key secrecy requirements of a key exchange protocol if one assumes a trust-on-first-use (TOFU) relationship. This means that the adversary needs to mount an active attack during the initial connection, otherwise the subsequent reconnections remain secure.

Investigating the cryptographic strength of the Bluetooth protocol, we also look into the privacy mechanism of address randomization in Bluetooth (which is only available in the Low Energy version). We show that the cryptography indeed provides a decent level of address privacy, although this does not rule out identification of devices via other means, such as physical characteristics.
]]></content:encoded>
<pubDate>Thu, 09 Dec 2021 03:10:30 +0000</pubDate>
</item>
<item>
<title>Analyzing and Benchmarking ZK-Rollups</title>
<link>https://eprint.iacr.org/2024/889</link>
<guid>https://eprint.iacr.org/2024/889</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、ZK-Rollups、零知识证明、层2解决方案、经济影响

总结:

本文通过理论和实证研究深入探讨了ZK-Rollups（零知识证明型Rollups）在区块链技术中的应用与效能。研究首先从概念出发，解析了ZK-Rollups在提高区块链网络处理能力、降低交易成本以及保障安全性的优势，特别是通过利用零知识证明机制，实现快速链上验证，从而提升整体效率。

接下来，文章进行了一次详细的成本分析，涵盖了ZK-Rollups设计中涉及的各项费用，包括但不限于计算资源、存储需求及网络通信成本。同时，针对当前市场上两个知名ZK-Rollup项目——Polygon zkEVM和zkSync Era进行了具体案例研究，通过对比分析揭示了不同设计决策带来的性能差异及其对经济因素的影响。

研究最终提出了评估ZK-Rollup系统的一套系统化方法论，旨在为后续的研究、开发与部署提供指导。通过对现有项目的实际数据进行分析，本研究不仅提供了对ZK-Rollup实施过程中的初步理解，还指出了可能存在的优化空间和未来研究方向，对于推动ZK-Rollups技术的成熟与普及具有重要意义。 <div>
As blockchain technology continues to transform the realm of digital transactions, scalability has emerged as a critical issue. This challenge has spurred the creation of innovative solutions, particularly Layer 2 scalability techniques like rollups. Among these, ZK-Rollups are notable for employing Zero-Knowledge Proofs to facilitate prompt on-chain transaction verification, thereby improving scalability and efficiency without sacrificing security. Nevertheless, the intrinsic complexity of ZK-Rollups has hindered an exhaustive evaluation of their efficiency, economic impact, and performance.

This paper offers a theoretical and empirical examination aimed at comprehending and evaluating ZK-Rollups, with particular attention to ZK-EVMs. We conduct a qualitative analysis to break down the costs linked to ZK-Rollups and scrutinize the design choices of well-known implementations. Confronting the inherent difficulties in benchmarking such intricate systems, we introduce a systematic methodology for their assessment, applying our method to two prominent ZK-Rollups: Polygon zkEVM and zkSync Era. Our research provides initial findings that illuminate trade-offs and areas for enhancement in ZK-Rollup implementations, delivering valuable insights for future research, development, and deployment of these systems.
]]></content:encoded>
<pubDate>Tue, 04 Jun 2024 09:46:07 +0000</pubDate>
</item>
<item>
<title>Information-Theoretic Topology-Hiding Broadcast: Wheels, Stars, Friendship, and Beyond</title>
<link>https://eprint.iacr.org/2024/1266</link>
<guid>https://eprint.iacr.org/2024/1266</guid>
<content:encoded><![CDATA[
<div> 关键词：拓扑隐藏广播、信息论安全、轮图、子图、友谊图

总结:

本文研究了信息论安全（IT）条件下的拓扑隐藏广播（THB），特别关注于轮图及其子图类。主要发现如下：

1. **轮图及其子图的IT-THB可行性**：文章通过分析具有嵌入星结构的轮图子图，揭示了其IT-THB可行性与对应图的更精细度结构相关，而不仅仅是简单的连通性。

2. **新图类的完美IT-THB实现**：文章提供了一些新的正向结果，实现了对未知节点数的图类的完美IT-THB，这是之前未解决的问题。

3. **多故障情况下的IT-THB**：首次证明了在具有t>1个故障的非退化图类中实现IT-THB的可能性，具体为友谊图类，这标志着在多故障场景下实现信息论安全THB的一个重要进展。

4. **理论框架的扩展**：通过研究轮图及其子图，文章扩展了之前关于IT-THB可行性的理论框架，为理解不同图类下的THB提供了新的视角和工具。

5. **技术贡献**：这项工作不仅提供了理论上的见解，还可能启发新的安全通信协议设计，特别是在网络拓扑保护方面，对于构建更加安全和私密的分布式系统具有重要意义。 <div>
Topology-hiding broadcast (THB) enables parties communicating over an incomplete network to broadcast messages while hiding the network topology from within a given class of graphs. Although broadcast is a privacy-free task, it is known that THB for certain graph classes necessitates computational assumptions, even against "honest but curious" adversaries, and even given a single corrupted party. Recent works have tried to understand when THB can be obtained with information-theoretic (IT) security (without cryptography or setup assumptions) as a function of properties of the corresponding graph class.

We revisit this question through a case study of the class of wheel graphs and their subgraphs. The $n$'th wheel graph is established by connecting $n$ nodes who form a cycle with another "center" node, thus providing a natural extension that captures and enriches previously studied graph classes in the setting of IT-THB.

We present a series of new findings in this line.
We fully characterize feasibility of IT-THB for any class of subgraphs of the wheel, each possessing an embedded star (i.e., a well-defined center connected to all other nodes). Our characterization provides evidence that IT-THB feasibility may correlate with a more fine-grained degree structure---as opposed to pure connectivity---of the corresponding graphs.
We provide positive results achieving perfect IT-THB for new graph classes, including ones where the number of nodes is unknown. Further, we provide the first feasibility of IT-THB on non-degenerate graph-classes with $t>1$ corruptions, for the class of friendship graphs (Erdos, Renyi, Sos '66).
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 13:05:02 +0000</pubDate>
</item>
<item>
<title>Succinct Non-Subsequence Arguments</title>
<link>https://eprint.iacr.org/2024/1264</link>
<guid>https://eprint.iacr.org/2024/1264</guid>
<content:encoded><![CDATA[
<div> 关键词：非子序列论证、多变量多项式承诺方案、证明时间、验证时间、批处理子序列论证

总结:本文提出了首个简洁的非子序列论证方案。该方案利用求和检查协议，可与任何多变量多项式承诺方案结合使用。我们的解决方案在证明者运行时间上实现了线性增长，与序列s、t及其各自字母表Σ的大小成正比。证明的大小为O(log₂|s| + log₂|t| + log₂|Σ|)，验证时间则为O(√|s| + √|t| + √|Σ|)。基于Sona多项式承诺方案（EUROCRYPT'24），我们能够实现高效的证明机制。此外，通过扩展技术，我们还能够构建批处理子序列论证，用于同时验证多个交错子序列和非子序列论证，而无需证明大小出现线性增长。这项工作对DNA序列分析、物联网、区块链、自然语言处理、语音识别等领域具有潜在的重要应用价值。 <div>
Lookup arguments have recently attracted a lot of developments due to their applications in the constructions of succinct non-interactive arguments of knowledge (SNARKs). A closely related topic is subsequence arguments in which one can prove that string $\mathbf{s}$ is a subsequence of another string $\mathbf{t}$, i.e., deleting some characters in $\mathbf{t}$ can achieve $\mathbf{s}$. A dual notion, namely, non-subsequence arguments, is to prove that $\mathbf{s}$ is not a subsequence of $\mathbf{t}$. 
These problems have a lot of important applications in DNA sequence analysis, internet of things, blockchains, natural language processing, speech recognition, etc. However, despite their applications, they are not well-studied in cryptography, especially succinct arguments for non-subsequences with efficient proving time and sublinear verification time.

In this work, we propose the first succinct non-subsequence argument. Our solution applies the sumcheck protocol and is instantiable by any multivariate polynomial commitment schemes (PCSs). We achieve an efficient prover whose running time is linear in the size of sequences $\mathbf{s}$, $\mathbf{t}$ and their respective alphabet $\Sigma$. Our proof is succinct and the verifier time is sublinear assuming the employed PCS has succinct commitments and sublinear verification time. When instantiating with Sona PCS (EUROCRYPT'24), we achieve proof size $\mathcal{O}(\log_2|\mathbf{s}| + \log_2|\mathbf{t}|+\log_2|\Sigma|)$, prover time $\mathcal{O}(|\mathbf{s}|+|\mathbf{t}|+|\Sigma|)$  and verifier time $\mathcal{O}(\sqrt{|\mathbf{s}|}+\sqrt{|\mathbf{t}|}+\sqrt{|\Sigma|})$.

Extending our technique, we can achieve a batch subsequence argument for proving in batch $k$ interleaving subsequence and non-subsequence arguments without proof size suffering a linear blow-up in $k$.
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 06:52:34 +0000</pubDate>
</item>
<item>
<title>Dilithium-Based Verifiable Timed Signature Scheme</title>
<link>https://eprint.iacr.org/2024/1262</link>
<guid>https://eprint.iacr.org/2024/1262</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Timed Signatures（VTS）、BLS签名、Schnorr签名、ECDSA、CRYSTALS-Dilithium

文章总结：

Verifiable Timed Signatures（VTS）是一种用于在未来特定时间获取签名并证明其合法性的加密构建。它们在支付通道网络、多方签名操作或多方计算等区块链应用中具有重要价值。目前，VTS方案主要基于BLS签名、Schnorr签名和ECDSA等签名算法。然而，这些算法在量子攻击下被认为是不安全的，因为Shor算法对离散对数问题的影响。为了解决这个问题，本文提出了一种基于NIST选定的量子抗性数字签名标准CRYSTALS-Dilithium的VT-Dilithium新VTS方案。该方案克服了Dilithium集成到VTS方案中的复杂性问题，包括多项式乘法、舍入操作等复杂的数学运算以及大模参数如多项式、多项式向量和矩阵。

综上所述，VT-Dilithium方案通过采用量子安全的CRYSTALS-Dilithium算法，提供了一种增强安全性和适应未来量子计算威胁的VTS解决方案。这不仅提高了系统在传统攻击下的安全性，而且确保了在量子计算时代下系统的持续安全性。此外，针对Dilithium特有的数学挑战，VT-Dilithium方案还引入了优化策略，以高效地处理其复杂度高的运算，从而实现更有效的VTS生成与验证过程。 <div>
Verifiable Timed Signatures (VTS)  are cryptographic constructs that enable obtaining a signature at a specific time in the future and provide evidence that the signature is legitimate. This framework particularly finds utility in applications such as payment channel networks, multiparty signing operations, or multiparty computation, especially within blockchain architectures. Currently, VTS schemes are based on signature algorithms such as BLS signature, Schnorr signature, and ECDSA. These signature algorithms are considered insecure against quantum attacks due to the effect of Shor's Algorithm on the discrete logarithm problem. We present a new VTS scheme called VT-Dilithium based on CRYSTALS-Dilithium Digital Signature Algorithm that has been selected as NIST's quantum-resistant digital signature standard and is considered secure against both classical and quantum attacks. Integrating Dilithium into the VTS scheme is more challenging problem due to its complex mathematical operations (i.e. polynomial multiplications, rounding operations) and large module parameters such as polynomials, polynomial vectors, and matrices. This work aims to provide a comprehensive exposition of the VT-Dilithium scheme.
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 06:03:14 +0000</pubDate>
</item>
<item>
<title>zk-Promises: Making Zero-Knowledge Objects Accept the Call for Banning and Reputation</title>
<link>https://eprint.iacr.org/2024/1260</link>
<guid>https://eprint.iacr.org/2024/1260</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、匿名性、可问责性、异步交互、状态机

总结:

本文提出了一种名为zk-promises的框架，旨在解决隐私保护系统中匿名客户端与多方互动时的状态完整性问题，同时支持异步更新。该框架的核心是将客户端状态存储在一个零知识证明（zk）对象中，通过加密承诺和零知识证明技术来确保状态的保密性、完整性和原子性。

zk-promises允许创建复杂的、带有任意异步回调的Turing完备状态机，使得客户端能够修改并证明其状态，同时还能将回调给第三方，从而实现对违规行为的追踪和惩罚。通过精心设计的协议，确保了那些更新其状态的客户端必须接收由第三方调用的回调。

基于此框架，构建了一个具有先进性能和功能的匿名声誉系统，包括异步声誉更新、封禁以及基于声誉的速率限制，以更有效地抵御Sybil攻击。该系统不仅保证了匿名性，还实现了对违规行为的可问责性，同时提高了系统的效率和用户体验。 <div>
Privacy preserving systems often need to allow anonymity while requiring accountability.  For anonymous clients, depending on application, this may mean banning/revoking their accounts, docking their reputation, or updating their state in some complex access control scheme. Frequently, these operations happen asynchronously when some violation, e.g., a forum post, is found well after the offending action occurred. Malicious clients, naturally, wish to evade this asynchronous negative feedback. Considering privacy-preserving analogues of modern access control and reputation schemes raises a more fundamental technical challenge with far broader applications: how do we allow multiple parties to interact with private state stored by an anonymous client while ensuring state integrity and supporting oblivious updates?

We propose zk-promises, a framework which supports Turing-complete state machines with arbitrary asynchronous callbacks. In zk-promises, client state is stored in a zk-object. Updates to the zk-object, represented as a cryptographic commitment to the new, modified object, require a zkSNARK that ensures integrity and atomicity while providing confidentiality.  Clients can modify and prove their state by calling valid methods (e.g, to show they are authorized to post) and can give callbacks to third parties (e.g., to later hold them accountable). Through careful protocol design, we ensure clients who advance their state-machine are forced to ingest callbacks that are called by a third party.

zk-promises allows us to build a privacy-preserving account model. State that would normally be stored on a trusted server can be privately outsourced to the client while preserving the server's ability to update the account. To demonstrate the feasibility of our approach, we build an anonymous reputation system with better than state-of-the-art performance and features, supporting asynchronous reputation updates, banning, and reputation-dependent rate limiting to better protect against Sybil attacks.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 21:20:57 +0000</pubDate>
</item>
<item>
<title>Efficient (Non-)Membership Tree from Multicollision-Resistance with Applications to Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2024/1259</link>
<guid>https://eprint.iacr.org/2024/1259</guid>
<content:encoded><![CDATA[
<div> 关键词：积聚器、认证字典、Merkle树、零知识证明、非对抗性攻击

文章主要讨论了在各种应用中使用的积聚器和认证字典，如证书透明度、区块链、隐私保护的去中心化电子货币等。文中提出了一个新型的（非）成员身份证明，具有更小的树深度，同时保持相同的安全性水平。此外，还引入了适用于特定场景的版本，深度最多可减少6倍。这些构造不需要动态树深度，简化了常规模块零知识证明电路，并确保了更小的深度上限。

在对抗性上下文中，该工作旨在实现高效且无需信任树管理者的构建，例如在区块链中，允许非受信任方执行操作并由任何人验证。文中考虑了特殊实例，特别是序列号（即nullifiers）的表示，并强调了构造的通用性，它们不仅适用于区块链和零知识证明，还能在非对抗性环境中使用，包括哈希表、数据库和其他数据结构。

总结:
本文提出了一种改进的积聚器和认证字典构造，旨在提高效率和安全性。通过减少树深度，新构造能够提供与传统方法相同的安全保障，同时支持更复杂的零知识证明应用。在非对抗性环境下，这些构造可以增强区块链系统的隐私性和可扩展性，同时确保非受信任方能够验证交易的有效性。此外，这些技术还可应用于其他数据存储系统，提高其性能和安全性。通过减少对动态深度的需求，该工作为构建常规模块零知识证明电路提供了基础，使得在实际应用中实现更高效的验证过程成为可能。 <div>
Many applications rely on accumulators and authenticated dictionaries, from timestamping certificate transparency and memory checking to blockchains and privacy-preserving decentralized electronic money, while Merkle tree and its variants are efficient for arbitrary element membership proofs, non-membership proofs, i.e., universal accumulators, and key-based membership proofs may require trees up to 256 levels for 128 bits of security, assuming binary tree, which makes it inefficient in practice, particularly in the context of zero-knowledge proofs. 

Building on the hardness of multi-collision we introduce a novel (non-)membership, optionally key-value, accumulator with up to 2x smaller tree depth while preserving the same security level, as well as multiple application-specific versions with even shallower trees, up to 6x smaller depth, that rely on the low-entropy source.
Moreover, solving for special case of adversarial attacks we introduce key index variants which might be a stepping stone for an entropy-free accumulator.

Notably, unlike other constructions, this work, although may, doesn't depend on the dynamic depth of the tree which is simpler and more suitable for constant-size ZKP circuits, while ensuring a substantially smaller upper bound on depth.

Efficient in practice construction in the adversarial context, e.g. blockchain, where the tree manager doesn't need to be trusted, i.e., operations can be carried out by an untrusted party and verified by anyone, is the primary goal.
Example instantiations are considered, where special treatment is given to the application of representing serial numbers, aka nullifiers. 
Nevertheless, the constructions are self-sufficient and can be used in other contexts, without blockchain and/or zero-knowledge proofs, including non-adversarial contexts.

Furthermore, our findings might be of independent interest for other use cases, such as hash tables, databases and other data structures.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 19:38:08 +0000</pubDate>
</item>
<item>
<title>Compass: Encrypted Semantic Search with High Accuracy</title>
<link>https://eprint.iacr.org/2024/1255</link>
<guid>https://eprint.iacr.org/2024/1255</guid>
<content:encoded><![CDATA[
<div> 关键词：Compass、加密数据、高准确性、隐私保护、Hierarchical Navigable Small Worlds（HNSW）

总结:
Compass 是一种在加密数据上实现的语义搜索系统，其准确度与传统明文搜索算法相当，同时能确保数据、查询和检索结果不被服务器完全攻击的威胁所泄露。此外，Compass 支持隐私保护的 RAG（关系图检索）场景，使得数据库和查询都能得到保护。为了实现这些功能，Compass 引入了一种新颖的方法，即使用 Oblivious RAM（ oblivious RAM）来在 Hierarchical Navigable Small Worlds（HNSW）这种高性能向量最近邻搜索中遍历搜索图。通过定向邻居过滤、推测贪婪搜索和针对 HNSW 的路径 ORAM 技术，Compass 能够实现用户感知的几秒级延迟，并且比基于加密嵌入的搜索基准快几个数量级。这些技术的结合不仅保证了搜索效率，还极大地增强了数据的安全性和隐私性。 <div>
We introduce Compass, a semantic search system over encrypted data that offers high accuracy, comparable to state-of-the-art plaintext search algorithms while protecting data, queries and search results from a fully compromised server. Compass also enables privacy-preserving RAG where both the RAG database and the query are protected. Compass's search index contributes a novel way to traverse the search graph in  Hierarchical Navigable Small Worlds (HNSW), a top performing vector nearest neighbor search, using Oblivious RAM, a cryptographic primitive with strong security guarantees. Our techniques, Directional Neighbor Filtering, Speculative Greedy Search and HNSW-tailored Path ORAM ensure that Compass achieves user-perceived latencies of few seconds and is orders of magnitude faster than a baseline for encrypted embeddings search.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 04:29:55 +0000</pubDate>
</item>
<item>
<title>Complete Knowledge: Preventing Encumbrance of Cryptographic Secrets</title>
<link>https://eprint.iacr.org/2023/044</link>
<guid>https://eprint.iacr.org/2023/044</guid>
<content:encoded><![CDATA[
<div> 关键词：加密协议、可信执行环境（TEE）、安全多方计算、完全知识证明（CK）、区块链资产

总结:

本文探讨了加密协议中对密钥知识的传统模型面临的挑战，特别是随着可信执行环境（TEE）和安全多方计算的普及。这些技术允许有条件地访问秘密而不实际知道秘密本身，从而可能引发诸如投票出售、非法服务凭证交易以及匿名消息系统中否认性降低等问题。现有的证明知识方法未能表明秘密是否被限制或“束缚”。

为解决这一问题，文章引入并定义了一种新的概念——完全知识证明（CK）。CK不仅要求证明者知道秘密，还要求证明者拥有未被限制的、不受约束的秘密使用能力。通过利用特殊硬件，如可信执行环境（TEE）和现成的挖矿ASIC，文章提出了两个实用的CK方案，并证明了其安全性。此外，文章还展示了如何将CK应用于实践，包括与智能合约的集成验证，以及用于证明对区块链资产所有权的新型应用。

通过这些创新，文章旨在增强加密协议的安全性，防止由秘密束缚导致的潜在威胁，并拓展了完全知识证明在现代密码学中的应用领域。 <div>
Most cryptographic protocols model a player’s knowledge of secrets in a simple way. Informally, the player knows a secret in the sense that she can directly furnish it as a (private) input to a protocol, e.g., to digitally sign a message.

The growing availability of Trusted Execution Environments (TEEs) and secure multiparty computation, however, undermines this model of knowledge. Such tools can encumber a secret sk and permit a chosen player to access sk conditionally, without actually knowing sk. By permitting selective access to sk by an adversary, encumbrance of secrets can enable vote-selling in cryptographic voting schemes, illegal sale of credentials for online services, and erosion of deniability in anonymous messaging systems. 

Unfortunately, existing  proof-of-knowledge protocols fail to demonstrate that a secret is unencumbered. We therefore introduce and formalize a new notion called complete knowledge (CK). A proof (or argument) of CK shows that a prover does not just know a secret, but also has fully unencumbered knowledge, i.e., unrestricted ability to use the secret.

We introduce two practical CK schemes that use special-purpose hardware, specifically TEEs and off-the-shelf mining ASICs. We prove the security of these schemes and explore their practical deployment with a complete, end-to-end prototype with smart-contract verification that supports both. We show how CK can address encumbrance attacks identified in previous work. Finally, we introduce two new applications enabled by CK that involve proving ownership of blockchain assets.
]]></content:encoded>
<pubDate>Sun, 15 Jan 2023 08:50:38 +0000</pubDate>
</item>
<item>
<title>PROF: Protected Order Flow in a Profit-Seeking World</title>
<link>https://eprint.iacr.org/2024/1241</link>
<guid>https://eprint.iacr.org/2024/1241</guid>
<content:encoded><![CDATA[
<div> 关键词：PROF、分散式金融（DeFi）、Proposer-Builder Separation (PBS)、最大可提取价值（MEV）、交易顺序操纵

总结:

本文介绍了针对分散式金融(DeFi)应用中面临的由交易顺序操纵导致的最大可提取价值(MEV)风险的一种解决方案——PROF系统。PROF旨在通过两个关键策略限制有害形式的MEV：

1. **交易流保护**：PROF对一组私有输入的交易进行排序，并确保这一排序在整个区块生成过程中得以执行，防止交易顺序被操纵。

2. **盈利性区块生产**：创建的交易组对于区块生产者来说具有利润性，确保这些交易能及时被包含在区块中。

PROF系统具备与现有和未来PBS设计的兼容性，不增加额外的信任假设，执行效率高，延迟低。通过量化和定性分析，比较了PROF系统与现有解决方案的激励结构以及用户效益。此外，还报告了PROF交易的纳入可能性及其端到端实现的具体延迟时间。整体而言，PROF提供了一种在不牺牲系统性能的前提下，有效对抗MEV风险、保护用户利益的解决方案。 <div>
Users of decentralized finance (DeFi) applications face significant risks from adversarial actions that manipulate the order of transactions to extract value from users. Such actions---an adversarial form of what is called maximal-extractable value (MEV)---impact both individual outcomes and the stability of the DeFi ecosystem. MEV exploitation, moreover, is being institutionalized through an architectural paradigm known Proposer-Builder Separation (PBS).

This work introduces a system called PROF (PRotected Order Flow) that is designed to limit harmful forms of MEV in existing PBS systems. PROF aims at this goal using two ideas. First, PROF imposes an ordering on a set ("bundle") of privately input transactions and enforces that ordering all the way through to block production-preventing transaction-order manipulation. Second, PROF creates bundles whose inclusion is profitable to block producers, thereby ensuring that bundles see timely inclusion in blocks.

PROF is backward-compatible, meaning that it works with existing and future PBS designs. PROF is also compatible with any desired algorithm for ordering transactions within a PROF bundle (e.g., first-come, first-serve, fee-based, etc.). It executes efficiently, i.e., with low latency, and requires no additional trust assumptions among PBS entities. We quantitatively and qualitatively analyze PROF’s incentive structure, and its utility to users compared with existing solutions. We also report on inclusion likelihood of PROF transactions, and concrete latency numbers through our end-to-end implementation.
]]></content:encoded>
<pubDate>Tue, 06 Aug 2024 01:14:16 +0000</pubDate>
</item>
<item>
<title>Efficient Differentially Private Set Intersection</title>
<link>https://eprint.iacr.org/2024/1239</link>
<guid>https://eprint.iacr.org/2024/1239</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Set Intersection (PSI), Differentially Private (DPSI), Fully Homomorphic Encryption (FHE), Reverse Private Membership Test (RPMT), Private Set Operation (PSO)

<br />
<br />总结:

本文研究了如何在保护敏感信息的同时进行数据集交集的计算。首先，文章回顾并重新定义了差分隐私条件下的私有集合交集（DPSI），识别出构建高效DPSI协议所需的关键需求，并提出了两种构建高效DPSI协议的方法框架。第一种方法将现有的DPSI概念进行了扩展，表明任何电路PSI都可以用于构建DPSI，并通过插入当前最先进的电路PSI协议来获得更高效的DPSI协议。第二种方法利用多查询逆私密成员测试（mqRPMT）来构建私有集合操作（PSO），但mqRPMT会额外泄露交集大小给发送方。为解决此问题，文章通过在输入集中填充随机占位符项目以限制泄露，利用差分隐私原则对这种泄露进行了控制。

实验结果显示，基于这两种方法构建的DPSI协议在通信效率和执行速度上都显著优于现有技术，分别是现有技术的2.5至22.6倍和110.5至151.8倍。此外，文章还展示了mqRPMT的新应用场景，除了用于获取PSO之外，还可以用于构建DPSI。这一工作不仅提高了DPSI协议的效率，还扩展了私有集合操作的使用场景，为数据安全与隐私保护提供了新的解决方案。 <div>
Private Set Intersection (PSI) enables a sender and a receiver to jointly compute the intersection of their sets without disclosing other information about items not in the intersection. However, in many cases of joint data analysis, it is not just the items outside the intersection that are sensitive but the items within it. To protect such sensitive information, prior work presents a Differentially Private version of PSI (DPSI) based on a circuit-PSI using Fully Homomorphic Encryption. However, their concrete protocol is somewhat inefficient compared with the state-of-the-art (SOTA) circuit-PSI.

In this paper, we revisit the DPSI definition and formalize its ideal functionality. We identify the key desiderata required by PSI-related tools to construct DPSI and propose two frameworks to construct efficient DPSI protocols. The first one generalizes the idea of existing DPSI, showing that any circuit-PSI can be used to construct DPSI. We obtain a more efficient DPSI protocol by plugging the SOTA circuit-PSI protocol in the framework. The second one helps to obtain a more efficient DPSI protocol based on the multi-query Reverse Private Membership Test (mqRPMT) that was previously used to construct Private Set Operation (PSO). However, mqRPMT additionally leaks the intersection size to the sender. We bound such leakage using differential privacy by padding random dummy items in input sets. We implement numerous constructions based on our frameworks. Experiments show that our protocols significantly outperform the existing DPSI construction, 2.5-22.6$\times$ more communication efficient and up to 110.5-151.8$\times$ faster. Our work also shows a new use case for mqRPMT besides obtaining PSO.
]]></content:encoded>
<pubDate>Mon, 05 Aug 2024 02:44:49 +0000</pubDate>
</item>
<item>
<title>XHash: Efficient STARK-friendly Hash Function</title>
<link>https://eprint.iacr.org/2023/1045</link>
<guid>https://eprint.iacr.org/2023/1045</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、哈希函数、ZK-STARK、Marvellous设计策略、XHash

总结:

本文提出了一种名为XHash的高性能哈希函数，专为ZK-STARKs设计，其性能超越了Rescue和Poseidon，成为STARKs中最有效的ZK友好哈希函数。XHash在CPU架构上的平均速度约为3μs，比Marvellous家族中最快的RPO快约2.5倍。从安全性角度看，XHash继承了Marvellous设计策略的安全性，并分析了其对当前代数攻击的抵抗能力。此外，文章还提出了针对代数攻击的新安全论证类型，基于一个合理且明确的新假设。最后，XHash为Polygon Miden VM提供了标准版本，其AIR复杂度为504，相比Rescue的672和Poseidon的1176，更具竞争力。

文章详细探讨了XHash的设计与性能优化，强调了其在零知识证明系统中的应用潜力，特别是在ZK-STARKs环境下的高效能表现。同时，XHash的安全性分析表明，它能够抵御当前的代数攻击手段，进一步增强了其在实际应用中的可靠性。此外，通过引入新的安全论证方法，文章为评估哈希函数的安全性提供了一种创新途径，这在提升整个零知识证明系统的安全性方面具有重要意义。最后，针对特定虚拟机环境的优化设计，使得XHash不仅在理论上表现出色，而且在具体应用中也具有较高的实用性。 <div>
Zero-knowledge proofs are widely used in real-world applications
for authentication, access control, blockchains, and cryptocurren-
cies, to name a few. A core element in zero-knowledge proof systems
is the underlying hash function, which plays a vital role in the effi-
ciency of the proof system. While the traditional hash functions,
such as SHA3 or BLAKE3 are efficient on CPU architectures, they
perform poorly within zero-knowledge proof systems. This is pri-
marily due to the requirement of these systems for hash functions
that operate efficiently over finite fields of large prime order as well
as binary fields. To address this challenge, a new paradigm called
Arithmetization-Orientation has emerged. These designs are tai-
lored to improve the efficiency of hashing within zero-knowledge
proof systems while providing reliable security guarantees.
In this work, we propose XHash, which is a high-performance
hash function designed for ZK-STARKs and is inspired by the Mar-
vellous design strategy. When using Algebraic Intermediate Repre-
sentation, XHash outperforms Rescue and Poseidon as the most im-
portant ZK-friendly hash functions for STARKs. Moreover, XHash
has a competitive performance on CPU architectures with an av-
erage speed of ≈ 3𝜇𝑠 for 2-to-1 hashing. Compared to RPO, which
is the fastest hash function of the Marvellous family, XHash per-
forms ≈ 2.5 times faster on CPU. From the security perspective,
XHash inherits the security of the Marvellous design strategy, and
we analyze its security against state-of-the-art algebraic attacks.
Additionally, we propose a new type of security argument against
algebraic attacks that relies on a single well-defined and reasonable
conjecture of a novel type. Finally, we specify a standard version of
XHash designed for Polygon Miden VM, with its AIR complexity
being 504, compared to Rescue with an AIR complexity of 672, and
Poseidon with an AIR complexity of 1176.
]]></content:encoded>
<pubDate>Tue, 04 Jul 2023 14:23:33 +0000</pubDate>
</item>
<item>
<title>Route Discovery in Private Payment Channel Networks</title>
<link>https://eprint.iacr.org/2021/1539</link>
<guid>https://eprint.iacr.org/2021/1539</guid>
<content:encoded><![CDATA[
<div> 关键词：私有信道网络、路由发现、隐私保护、多党计算、效率

总结:

本文研究了私有信道网络中的路由发现问题。首先，文章定义了在此环境下理想的隐私标准，并指出通过多党计算实现这一标准的协议存在，但其效率低下，因为整个网络都参与路径发现过程。

接着，文章提出了一种具有较弱隐私保证但更高效性的路由协议。这些协议允许路由发现主要由网络中一小部分节点完成，同时泄露了一些关于拓扑结构和平衡的信息，而这些信息超出交易执行所需。

核心理念是，发送者和接收者同时广播消息，这些消息逐渐在整个网络中传播。一旦网络中的任何节点接收到两个消息，路径就被找到。第一种协议总是将消息发送给所有相邻节点，延迟与边费用成正比。第二种协议仅随机选择一个邻居发送消息，概率与其度数成正比。尽管第一种协议总能找到最便宜的路径，但第二种可能无法做到这一点，但涉及的网络节点数量较少。

此外，文章讨论了使用双线性映射来重新随机化广播消息的扩展，以提高隐私性。还提出了进一步改进隐私性的方法，如使用双线性映射。

通过模拟研究，文章发现第一种协议通常涉及约12%的6376个节点，而第二种则仅触及约18个节点（不到0.3%），找到的路径成本大约是最佳路径成本的两倍。 <div>
In this work, we are the first to explore route discovery in private channel networks.
We first determine what ``ideal" privacy for a routing protocol means in this setting.  We observe that protocols achieving this strong privacy definition exist by leveraging (topology hiding) Multi-Party Computation but they are (inherently) inefficient as route discovery must involve the entire network.

We then present protocols with weaker privacy guarantees but much better efficiency. In particular, route discovery typically only involves small fraction of the nodes but some information on the topology and balances -- beyond what is necessary for performing the transaction -- is leaked.

The core idea is that both  sender and receiver gossip a message which then slowly propagates through the network, and the moment any node in the network receives both messages, a path is found. In our first protocol the message is always sent to all neighbouring nodes with a delay proportional to the fees of that edge. In our second protocol the message is only sent to one neighbour chosen randomly with a probability proportional to its degree. While the first instantiation always finds the cheapest path, the second might not, but it involves a smaller fraction of the network.

% We discuss some extensions like employing bilinear maps so the gossiped messages can be re-randomized, making them unlikeable and thus improving privacy.
We also discuss some extensions to further improve privacy by employing bilinear maps.

Simulations of our protocols on the Lightning network topology (for random transactions and uniform fees) show that our first protocol (which finds the cheapest path) typically involves around 12\%  of the 6376 nodes, while the second only touches  around 18 nodes $(<0.3\%)$,  and the cost of the path that is found  is around twice the cost of  the optimal one.
]]></content:encoded>
<pubDate>Mon, 22 Nov 2021 11:36:25 +0000</pubDate>
</item>
<item>
<title>Efficient and Privacy-Preserving Collective Remote Attestation for NFV</title>
<link>https://eprint.iacr.org/2024/1232</link>
<guid>https://eprint.iacr.org/2024/1232</guid>
<content:encoded><![CDATA[
<div> 关键词：虚拟化网络功能、集体远程验证、移动网络运营商、安全性和隐私性、验证协议

总结:

本文聚焦于集体远程验证(cRA)在虚拟化移动网络中的应用，特别是在验证虚拟网络功能(VNF)组的状态方面。cRA已被广泛研究应用于物联网领域，但本文首次将这一技术引入到虚拟化移动网络中，以解决其特有的挑战和约束。

1. **提出了一种新的协议**：该协议专门用于验证构成VNF转发图的一组虚拟网络功能的状态，确保了验证的不可伪造性、相关组件验证的可链接性以及基础设施提供商敏感配置细节的隐私性。

2. **定义并分析了新属性**：这是首次正式定义并分析VNF-FG验证过程中的这些关键安全和隐私属性，为虚拟化网络环境下的验证提供了理论基础。

3. **实施验证**：通过概念验证实现，展示了所提出的协议不仅在理论上具有强大且可证明的安全性，而且在实际应用中也是高效的。

4. **满足安全与隐私需求**：该方案旨在满足移动网络运营商对安全性和隐私性的严格要求，通过提供强大的验证机制，确保网络状态的可靠性和数据保护。

5. **填补技术空白**：本文的研究填补了现有技术在虚拟化移动网络验证领域的空白，为未来此类网络的建设和运营提供了先进的验证解决方案。 <div>
The virtualization of network functions is a promising technology, which can enable mobile network operators to provide more flexibility and better resilience for their infrastructure and services. Yet, virtualization comes with challenges, as 5G operators will require a means of verifying the state of the virtualized network components (e.g. Virtualized Network Functions (VNFs) or managing hypervisors) in order to fulfill security and privacy commitments. One such means is the use of attestation protocols. In this paper, we focus on Collective Remote Attestation (cRA), which is used to attest the state of a group of devices. Although cRA has been extensively studied in the context of IoT, it has not been used yet in virtualized mobile networks, a different use-case, with constraints of its own.  

In this paper, we propose the first protocol to efficiently and securely attest a group of Virtualized Network Functions which make up a VNF Forwarding Graph. Our protocol comes with strong and provable guarantees of: unforgeability of attestation, the linkability of attestations for related components, and the privacy of sensitive configuration details for the infrastructure provider. In particular, we are the first to formally define and analyze such properties for VNF-FG attestation. Finally, through our Proof-of-Concept implementation, we show that our construction is not only strongly secure, but also efficient.
]]></content:encoded>
<pubDate>Fri, 02 Aug 2024 13:50:00 +0000</pubDate>
</item>
<item>
<title>A Constructive View of Homomorphic Encryption and Authenticator</title>
<link>https://eprint.iacr.org/2024/1231</link>
<guid>https://eprint.iacr.org/2024/1231</guid>
<content:encoded><![CDATA[
<div> 关键词：Homomorphic Encryption（HE）、Homomorphic Authenticator（HA）、Composable Security、Confidential Channel、Authenticated Channel

总结:
本文探讨了同态加密(HE)和同态认证(HA)的安全性及其组合，以构建同时保证保密性和完整性的通信通道。首先，文章分析了HE和HA在确保数据保密性和完整性方面的重要性，并指出当前安全定义的挑战，特别是在处理包含消息评估的应用场景时。为了填补这一空白，作者提出了基于构造性安全分析的方法，通过将HE和HA分别视为保密通道和认证通道，来明确其独立安全要求。

接着，文章比较了现有基于游戏的安全定义，判断它们是否充分捕捉了HE和HA的意图安全目标。进一步地，文章对HE和HA的组合进行了分析，以确定它们是否能形成同态认证加密(HAE)，从而在消息评估的背景下提供保密性和完整性。具体来说，文章考察了HE和HA的串联组合，相当于经典加密中的“加密后附加MAC”(EtM)组合方式，以构建安全的同态认证加密系统。

最后，文章通过这种方式，旨在为HE和HA的安全性及其组合提供更清晰、更全面的理解，为实际应用提供理论基础和支持。 <div>
Homomorphic Encryption (HE) is a cutting-edge cryptographic technique that enables computations on encrypted data to be mirrored on the original data. This has quickly attracted substantial interest from the research community due to its extensive practical applications, such as in cloud computing and privacy-preserving machine learning.

In addition to confidentiality, the importance of authenticity has emerged to ensure data integrity during transmission and evaluation. To address authenticity, various primitives have been developed including Homomorphic Authenticator (HA). Corresponding security notions have also been introduced by extending the existing notions to their homomorphic versions.

Despite these advancements, formalizing the security of HE and HA remains challenging due to the novelty of these primitives and complexity of application scenarios involving message evaluation. It is inclusive which definitions in this zoo of notions are insufficient or overly complex. Moreover, HE and HA are designed to be combined to construct a secure communication channel that ensures both confidentiality and authenticity. However, the security of such compositions is not always clear when game-based notions are used to formalize security.

To bridge this gap, we conduct a constructive analysis through the lens of com- posable security. This method enables us to examine the security properties of each primitive in isolation and to more effectively evaluate their security when integrated into a larger system. We introduce the concepts of a confidential channel and an au- thenticated channel to specify the security requirements for HE and HA, respectively. We make a comparison with existing game-based notions to determine whether they adequately capture the intended security objectives.

We then analyze whether the composition of HE and HA constructs a Homomorphic Authenticated Encryption (HAE) that provides both confidentiality and authenticity in presence of message evaluation. Specifically, we examine a serial composition of HE and HA, corresponding to Encrypt-then-MAC (EtM) composition for constructing classical AE.
]]></content:encoded>
<pubDate>Fri, 02 Aug 2024 12:29:13 +0000</pubDate>
</item>
<item>
<title>Privacy Preserving Biometric Authentication for Fingerprints and Beyond</title>
<link>https://eprint.iacr.org/2024/525</link>
<guid>https://eprint.iacr.org/2024/525</guid>
<content:encoded><![CDATA[
<div> 关键词：生物识别、隐私保护计算、安全多方计算、两阶段认证、多阶段安全模型

总结: 

本文聚焦于生物识别认证中的隐私保护挑战。主要提出了以下几点关键创新：

1. **隐私保护计算应用**：作者引入了隐私保护计算技术，以解决传统生物识别存储问题，避免敏感生物数据直接暴露于服务器。

2. **安全威胁模型**：采用了一种假设，即客户端始终为恶意，而辅助服务器可以是半诚实或恶意，以此来设计更安全的认证方案。

3. **多阶段安全模型**：鉴于生物识别认证的两阶段特性（注册与认证），作者扩展了现有安全定义，提出了一种适用于多阶段应用的新型安全模型。

4. **实施与性能**：通过实际实现验证了所提出的解决方案的有效性，证明了其能够支持实时认证过程，具有良好的实践性能。

5. **安全性证明**：不仅展示了新模型下的安全性，还提供了理论上的证明，确保了方案在不同安全威胁场景下的可靠性。

通过上述创新，文章旨在提供一种既高效又安全的生物识别认证方法，兼顾了用户隐私保护和系统性能，为生物识别技术的安全应用提供了新的视角和途径。 <div>
Biometric authentication eliminates the need for users to remember secrets and serves as a convenient mechanism for user authentication. Traditional implementations of biometric-based authentication store sensitive user biometry on the server and the server becomes an attractive target of attack and a source of large-scale unintended disclosure of biometric data. To mitigate the problem, we can resort to privacy-preserving computation and store only protected biometrics on the server. While a variety of secure computation techniques is available, our analysis of privacy-preserving biometric computation and biometric authentication constructions revealed that available solutions fall short of addressing the challenges of privacy-preserving biometric authentication. Thus, in this work we put forward new constructions to address the challenges.

Our solutions employ a helper server and use strong threat models, where a client is always assumed to be malicious, while the helper server can be semi-honest or malicious. We also determined that standard secure multi-party computation security definitions are insufficient to properly demonstrate security in the two-phase (enrollment and authentication) entity authentication application. We thus extend the model and formally show security in the multi-phase setting, where information can flow from one phase to another and the set of participants can change between the phases. We implement our constructions and show that they exhibit practical performance for authentication in real time.
]]></content:encoded>
<pubDate>Thu, 04 Apr 2024 01:43:02 +0000</pubDate>
</item>
<item>
<title>Competitive Policies for Online Collateral Maintenance</title>
<link>https://eprint.iacr.org/2024/1022</link>
<guid>https://eprint.iacr.org/2024/1022</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、层二协议、扩容、在线策略、竞对性分析

总结:
本文探讨了在区块链技术中层二协议的挑战与解决方案。主要关注如何优化层二协议中的抵押品和钱包管理，以提高交易效率并确保安全性。研究首先提出了一个通用模型，描述了一个实体在链上持有抵押品C的情况下，决定是否结算或放弃每笔新进交易的策略，以及何时补充C的政策。随后，研究引入了一个离散模型，将C分为k个等额的钱包，当某个钱包满载无法处理更多交易时，将自动补充。

文章设计了多种在线策略来处理上述模型中的问题，并通过与具有完整未来交易流知识的理想（离线）策略进行比较，评估这些在线策略的性能。这是首次在区块链背景下研究和制定针对抵押品和钱包管理的在线竞争性策略，对于提升层二协议的效率和用户体验具有重要意义。通过优化策略，可以实现更高的价值结算，减少交易费用，并增强整体网络的安全性。 <div>
Layer-two blockchain protocols emerged to address scalability issues related to fees, storage cost, and confirmation delay of on-chain transactions. They aggregate off-chain transactions into a fewer on-chain ones, thus offering immediate settlement and reduced transaction fees. To preserve security of the underlying ledger, layer-two protocols often work in a collateralized model; resources are committed on-chain to backup off-chain activities. A fundamental challenge that arises in this setup is determining a policy for establishing, committing, and replenishing the collateral in a way that maximizes the value of settled transactions.

In this paper, we study this problem under two settings that model collateralized layer-two protocols. The first is a general model in which a party has an on-chain collateral $C$ with a policy to decide on whether to settle or discard each incoming transaction. The policy also specifies when to replenish $C$ based on the remaining collateral value. The second model considers a discrete setup in which $C$ is divided among $k$ wallets, each of which is of size $C/k$, such that when a wallet is full, and so cannot settle any incoming transactions, it will be replenished. We devise several online policies for these models, and show how competitive they are compared to optimal (offline) policies that have full knowledge of the incoming transaction stream. To the best of our knowledge, we are the first to study and formulate online competitive policies for collateral and wallet management in the blockchain setting.
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 20:06:41 +0000</pubDate>
</item>
<item>
<title>PEReDi: Privacy-Enhanced, Regulated and Distributed Central Bank Digital Currencies</title>
<link>https://eprint.iacr.org/2022/974</link>
<guid>https://eprint.iacr.org/2022/974</guid>
<content:encoded><![CDATA[
<div> 关键词：中央银行数字货币（CBDCs）、异步模型、分布式构造、隐私保护、监管友好

总结:

本文探讨了中央银行数字货币（CBDCs）在同时满足隐私性和监管友好性两个需求上的挑战。CBDCs旨在提供物理现金的数字替代品，但其设计需要在保护用户隐私与满足反洗钱（AML）、反恐融资（CFT）等法规要求之间找到平衡。为解决这一难题，文章提出了一种新的异步模型和高效构建方案，首次实现了同时满足这两方面需求的目标。

该方案不仅确保了CBDC的隐私性，避免了金融监控问题，还提供了必要的功能以辅助遵守各种金融法规，如客户识别（KYC）、反洗钱（AML）和恐怖主义融资（CFT）。此外，该方案采用分布式架构，提高了系统的健壮性，即使部分节点被恶意控制，系统整体性能也能保持稳定。

文章还详细介绍了如何使用合适的加密工具防止中间人攻击，展示了一种新型的追踪机制，相比已知技术显著提升了性能。令人意外的是，该方案能够通过乐观执行路径实现支付过程中的拜占庭一致性或广播，从而优化通信模式和开销。

最后，该CBDC概念在通用组合（UC）框架下得以表达和实现，为CBDC嵌入更大的金融生态系统提供了模块化和安全的方法。这种设计不仅确保了CBDC的安全性，还提高了其在复杂金融环境中的适应性，为未来的数字货币发展提供了重要的理论和技术支撑。 <div>
Central Bank Digital Currencies (CBDCs) aspire to offer a digital replacement for physical cash and as such need to tackle two fundamental requirements that are in conflict. On the one hand, it is desired they are private so that a financial “panopticon” is avoided, while on the other, they should be regulation friendly in the sense of facilitating any threshold-limiting, tracing, and counterparty auditing functionality that is necessary to comply with regulations such as Know Your Customer (KYC), Anti Money Laundering (AML) and Combating Financing of Terrorism (CFT) as well as financial stability considerations. 
In this work, we put forth a new asynchronous model for CBDCs and an efficient construction that, for the first time, fully addresses these issues simultaneously. Moreover, recognizing the importance of avoiding a single point of failure, our construction is distributed so that all its properties can withstand a suitably bounded entities getting corrupted by an adversary. Achieving all the above properties efficiently is technically involved; among others, our construction uses suitable cryptographic tools to thwart man-in-the-middle attacks, it showcases a novel traceability mechanism with significant performance gains compared to previously known techniques and, perhaps surprisingly, shows how to obviate Byzantine agreement or broadcast from the optimistic execution path of a payment, something that results in an essentially optimal communication pattern and communication overhead. We demonstrate the efficiency of our payment system by presenting detailed computation and communication costs. Going beyond “simple” payments, we also discuss how our scheme can facilitate one-off large transfers complying with Know Your Transaction (KYT) disclosure requirements. Our CBDC concept is expressed and realized in the Universal Composition (UC) framework providing in this way a modular and secure way to embed it within a larger financial ecosystem.
]]></content:encoded>
<pubDate>Fri, 29 Jul 2022 23:15:35 +0000</pubDate>
</item>
<item>
<title>ZIPNet: Low-bandwidth anonymous broadcast from (dis)Trusted Execution Environments</title>
<link>https://eprint.iacr.org/2024/1227</link>
<guid>https://eprint.iacr.org/2024/1227</guid>
<content:encoded><![CDATA[
<div> 关键词：ZIPNet、匿名广播通道（ABCs）、服务器计算成本、服务器带宽成本、盖流量成本

总结: 
本文介绍了ZIPNet的设计、实现与评估，它是一个针对任何信任服务器的可扩展匿名广播通道。主要创新点包括：
1. **优化服务器计算成本**：通过减少每个服务器的计算负担，ZIPNet允许其支持成百上千的服务器节点，从而提高了系统的整体效率和可扩展性。
2. **降低服务器带宽成本**：通过将客户端消息的聚合任务外包给非受信任的基础设施，ZIPNet显著减少了服务器端的带宽消耗。这种策略既保障了隐私性，又提高了系统性能。
3. **支持经济的盖流量**：ZIPNet设计了机制，使得生成和处理盖流量的成本对客户端和服务器来说都相对较低，这有助于增强匿名广播通道的实用性和吸引力。

综上所述，ZIPNet通过一系列技术手段，成功地解决了当前匿名广播通道中面临的关键问题，如服务器计算与带宽成本高、盖流量成本高昂等，为低带宽环境下的应用提供了更为高效、经济和私密的解决方案。 <div>
Anonymous Broadcast Channels (ABCs) allow a group of clients to announce messages without revealing the exact author. Modern ABCs operate in a client-server model, where anonymity depends on some threshold (e.g., 1 of 2) of servers being honest. ABCs are an important application in their own right, e.g., for activism and whistleblowing. Recent work on ABCs (Riposte, Blinder) has focused on minimizing the bandwidth cost to clients and servers when supporting large broadcast channels for such applications. But, particularly for low bandwidth settings, they impose large costs on servers, make cover traffic costly, and make volunteer operators unlikely.

In this paper, we describe the design, implementation, and evaluation of ZIPNet, an anonymous broadcast channel that 1) scales to hundreds of anytrust servers by minimizing the computational costs of each server, 2) substantially reduces the servers’ bandwidth costs by outsourcing the aggregation of client messages to untrusted (for privacy) infrastructure, and 3) supports cover traffic that is both cheap for clients to produce and for servers to handle.
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 14:12:32 +0000</pubDate>
</item>
<item>
<title>A short-list of pairing-friendly curves resistant to the Special TNFS algorithm at the 192-bit security level</title>
<link>https://eprint.iacr.org/2024/1223</link>
<guid>https://eprint.iacr.org/2024/1223</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、公钥加密、后量子密码学、配对、192位安全级别

文章概述：

本文旨在提供192位安全级别的配对综合研究。首先，通过文献回顾，作者筛选出所有可能的配对构造推荐，并从中提取出在效率和安全性方面最优秀的候选者。特别关注了针对高级特殊TNFS攻击的分析。研究不仅聚焦于配对计算本身，还考虑了在基于配对的应用中相关的额外操作，如配对组的哈希、因子清除和子群成员测试。

研究方法包括使用RELIC密码工具库实现所有功能，以识别在192位安全级别下最高效的配对实现，并提供了详细的实验结果。

总结：

本文进行了一项深入的研究，旨在确定192位安全级别的最佳配对方案。通过广泛的文献回顾，作者筛选并评估了一系列配对构造，着重于它们的效率和安全性。研究不仅局限于配对计算，还涵盖了与配对应用相关的其他关键操作，如哈希到配对组、因子清除和子群成员测试。通过实施RELIC工具库中的所有功能，研究最终确定了在192位安全级别下最为高效的一系列配对实现，并提供了详尽的实验数据，为未来基于配对的加密技术提供了重要的参考。 <div>
For more than two decades, pairings have been a fundamental tool for designing elegant cryptosystems, varying from digital signature schemes to more complex privacy-preserving constructions. However, the advancement of quantum computing threatens to undermine public-key cryptography. Concretely, it is widely accepted that a future large-scale quantum computer would be capable to break any public-key cryptosystem used today, rendering today's public-key cryptography obsolete and mandating the transition to quantum-safe cryptographic solutions. This necessity is enforced by numerous recognized government bodies around the world, including NIST which initiated the first open competition in standardizing post-quantum (PQ) cryptographic schemes, focusing primarily on digital signatures and key encapsulation/public-key encryption schemes. Despite the current efforts in standardizing PQ primitives, the landscape of complex, privacy-preserving cryptographic protocols, e.g., zkSNARKs/zkSTARKs, is at an early stage. Existing solutions suffer from various disadvantages in terms of efficiency and compactness and in addition, they need to undergo the required scrutiny to gain the necessary trust in the academic and industrial domains. Therefore, it is believed that the migration to purely  quantum-safe cryptography would require an intermediate step where current classically secure protocols and quantum-safe solutions will co-exist. This is enforced by the report of the Commercial National Security Algorithm Suite version 2.0, mandating transition to quantum-safe cryptographic algorithms by 2033 and suggesting to incorporate ECC at 192-bit security in the meantime. To this end, the present paper aims at providing a comprehensive study on pairings at 192-bit security level. We start with an exhaustive review in the literature to search for all possible recommendations of such pairing constructions, from which we extract the most promising candidates in terms of efficiency and security, with respect to the advanced Special TNFS attacks. Our analysis is focused, not only on the pairing computation itself, but on additional operations that are relevant in pairing-based applications, such as hashing to pairing groups, cofactor clearing and subgroup membership testing. We implement all functionalities of the most promising candidates within the RELIC cryptographic toolkit in order to identify the most efficient pairing implementation at 192-bit security and provide extensive experimental results.
]]></content:encoded>
<pubDate>Wed, 31 Jul 2024 07:56:18 +0000</pubDate>
</item>
<item>
<title>Delegatable Anonymous Credentials From Mercurial Signatures With Stronger Privacy</title>
<link>https://eprint.iacr.org/2024/1216</link>
<guid>https://eprint.iacr.org/2024/1216</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名凭证、可委派、隐私保护、梅尔库里亚尔签名、撤销机制

文章主要探讨了可委派匿名凭证（Delegatable Anonymous Credentials，DACs）的隐私问题及解决方案。作者首先指出了现有基于梅尔库里亚尔签名的DACs设计中存在隐私缺陷，即如果恶意发行者参与了诚实用户的委托链，该恶意发行者能够检测到这一事实并识别具体参与者的身份。为解决这一问题，作者提出了一种新的梅尔库里亚尔签名方案，该方案提供了敌对手公共密钥类隐藏特性，使得即使敌对手签发者参与了委托链，也无法识别这一事实。这一特性通过引入结构化公共参数实现，每个层级的参数都包含强隐私功能。同时，为了克服设置这些参数产生的陷阱门对隐私应用的负面影响，作者利用零知识证明系统中的可更新结构化参考字符串技术进行了改进。

此外，文章还提出了一个简化的方法来实现基于Crites和Lysyanskaya（CL型）DACs的撤销机制，即使用撤销令牌的概念。这种方法不仅适用于本文提出的DAC方案，而且可以通用地应用于任何CL型DAC系统。撤销机制是匿名凭证系统中被忽视但极其重要的功能之一，它的实现有助于使DAC方案更加吸引实际应用。

总结:
本文首先揭示了现有基于梅尔库里亚尔签名的可委派匿名凭证设计中存在的隐私问题，即恶意发行者能够检测其参与了诚实用户的委托链。为解决这一问题，作者提出了一种新的梅尔库里亚尔签名方案，通过引入结构化公共参数和利用零知识证明系统的可更新结构化参考字符串技术，实现了敌对手公共密钥类隐藏特性，有效防止了恶意发行者的检测。此外，文章还提出了一个简化的方法来实现撤销机制，该方法不仅适用于本文的DAC方案，而且可以通用地应用于任何基于Crites和Lysyanskaya的DAC系统。这一撤销机制的实现是匿名凭证系统中不可或缺的功能，有助于提高DAC方案的实际应用价值。 <div>
Delegatable anonymous credentials (DACs) are anonymous credentials that allow a
root issuer to delegate their credential-issuing power to secondary issuers
who, in turn, can delegate further. This delegation, as well as credential
showing, is carried out in a privacy-preserving manner, so that credential
recipients and verifiers learn nothing about the issuers on the delegation
chain.  One particularly efficient approach to constructing DACs is due to
Crites and Lysyanskaya (CT-RSA'19), based on mercurial signatures, which is a
type of equivalence-class signatures. In contrast to previous approaches, this
design is conceptually simple and does not require extensive use of
non-interactive zero-knowledge proofs. Unfortunately, the ``CL-type'' DAC
schemes proposed so far have a privacy limitation: if an adversarial issuer
(even an honest-but-curious one) was part of an honest user's delegation chain,
the adversary will be able to detect this fact (and identify the specific
adversarial issuer) when an honest user shows its credential.  This is because
underlying mercurial signature schemes allow the owner of a secret key to
detect when his key was used in a delegation chain.

In this paper we show that it is possible to construct CL-type DACs that does
not suffer from this privacy issue.  We give a new mercurial signature scheme
that provides adversarial public key class hiding; i.e. even if an adversarial
signer participated in the delegation chain, the adversary won't be able to
identify this fact. This is achieved by introducing structured public
parameters which for each delegation level, enabling strong privacy features in
DAC. Since the setup of these parameters also produces trapdoors that are
problematic in privacy applications, we show how to overcome this problem by
using techniques from updatable structured reference string in zero-knowledge
proof systems (Groth et al. CRYPTO'18).

In addition, we propose a simple way to realize revocation for CL-type DACs via
the concept of revocation tokens. While we showcase this approach to revocation
using our DAC scheme, it is generic and can be applied to any CL-type DAC
system. Revocation is a feature that is largely unexplored and notoriously hard
to achieve for DACs. However as it is  a vital feature for any anonymous
credential system, this can help to make DAC schemes more attractive for
practical applications.
]]></content:encoded>
<pubDate>Mon, 29 Jul 2024 17:07:57 +0000</pubDate>
</item>
<item>
<title>Collaborative CP-NIZKs: Modular, Composable Proofs for Distributed Secrets</title>
<link>https://eprint.iacr.org/2024/1209</link>
<guid>https://eprint.iacr.org/2024/1209</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式零知识证明、协作证明、可组合性、承诺与证明设计、分布式协议

总结:

本文探讨了在非交互式零知识证明（NIZK）中引入可组合性的概念，特别是针对多验证者场景。研究的核心是构建一种名为协作承诺与证明（CP-NIZK）的框架，该框架允许用户结合不同特化的NIZK（如算术电路、布尔电路和范围证明），以期减少证明生成时间，并为多个应用场景提供了可能性，包括互斥的验证者组、结合单方证明和多方计算（MPC）验证者组以及高效实现公开可审计的MPC（PA-MPC）。

通过提出一个通用定义并构建分布式协议来实现CP-NIZK证明的知识，作者实施了这两种常见NIZK（Groth16和Bulletproofs）的原型，并在各种计算环境中进行了实践评估。实验结果表明，尽管可组合性增加了少量开销，但尤其是在大型电路中，这一开销非常小。在应用案例中，与先前的工作相比，该协议将延迟降低了18至55倍，同时只使用了通信量的0.2%。

此研究不仅扩展了NIZK在隐私保护应用中的潜力，还展示了如何通过创新设计和实现代价控制来优化协作证明的性能和效率，从而为安全、隐私敏感的计算环境提供了更强大的工具。 <div>
Non-interactive zero-knowledge (NIZK) proofs of knowledge have proven to be highly relevant for securely realizing a wide array of applications that rely on both privacy and correctness. They enable a prover to convince any party of the correctness of a public statement for a secret witness. However, most NIZKs do not natively support proving knowledge of a secret witness that is distributed over multiple provers. Previously, collaborative proofs [51] have been proposed to overcome this limitation. We investigate the notion of composability in this setting, following the Commit-and-Prove design of LegoSNARK [17]. Composability allows users to combine different, specialized NIZKs (e.g., one arithmetic circuit, one boolean circuit, and one for range proofs) with the aim of reducing the prove generation time. Moreover, it opens the door to efficient realizations of many applications in the collaborative setting such as mutually exclusive prover groups, combining collaborative and single-party proofs and efficiently implementing publicly auditable MPC (PA-MPC).

We present the first, general definition for collaborative commit-and-prove NIZK (CP-NIZK) proofs of knowledge and construct distributed protocols to enable their realization. We implement our protocols for two commonly used NIZKs, Groth16 and Bulletproofs, and evaluate their practicality in a variety of computational settings. Our findings indicate that composability adds only minor overhead, especially for large circuits. We experimented with our construction in an application setting, and when compared to prior works, our protocols reduce latency by 18–55× while requiring only a fraction (0.2%) of the communication.
]]></content:encoded>
<pubDate>Sat, 27 Jul 2024 08:22:28 +0000</pubDate>
</item>
<item>
<title>Hᴇᴋᴀᴛᴏɴ: Horizontally-Scalable zkSNARKs via Proof Aggregation</title>
<link>https://eprint.iacr.org/2024/1208</link>
<guid>https://eprint.iacr.org/2024/1208</guid>
<content:encoded><![CDATA[
<div> 关键词：Hᴇᴋᴀᴛᴏɴ、zkSNARKs、分布式证明、大数据处理、实际应用

总结:

本文介绍了一种名为Hᴇᴋᴀᴛᴏɴ的新型零知识简洁非交互式知识论证（zkSNARKs），它克服了现有zkSNARKs在大规模计算中无法扩展的问题。Hᴇᴋᴀᴛᴏɴ通过一种新的“分解与聚合”框架工作，将大型计算任务分割成小块，并在分布式系统中并行验证这些块，最终将结果块证明聚合为单个简洁证明。该框架背后的技术用于高效处理跨块共享的数据，具有独立的兴趣价值。

为了实现Hᴇᴋᴀᴛᴏɴ，作者构建了一个分布式证明者，并在计算集群上对其性能进行了评估。实验结果显示，Hᴇᴋᴀᴛᴏɴ在节点数量增加时实现了强大的水平扩展性（证明时间线性减少），并且能够快速证明大规模计算：它可以证明大小为$2^{35}$门的计算在不到一小时内完成，远快于先前的工作。

此外，Hᴇᴋᴀᴛᴏɴ被应用于两个具有实际意义的应用场景：批处理插入证明的可验证键目录和证明RAM计算的正确性。在这些情况下，Hᴇᴋᴀᴛᴏɴ都能有效地处理现实负载，相比以往的工作效率更高。 <div>
Zero-knowledge Succinct Non-interactive ARguments of Knowledge (zkSNARKs) allow a prover to convince a verifier of the correct execution of a large computation in private and easily-verifiable manner.  These properties make zkSNARKs a powerful tool for adding accountability, scalability, and privacy to numerous systems such as blockchains and verifiable key directories. Unfortunately, existing zkSNARKs are unable to scale to large computations due to time and space complexity requirements for the prover algorithm. As a result, they cannot handle real-world instances of the aforementioned applications.
  
In this work, we introduce Hᴇᴋᴀᴛᴏɴ, a zkSNARK that overcomes these barriers and can efficiently handle arbitrarily large computations. We construct Hᴇᴋᴀᴛᴏɴ via a new "distribute-and-aggregate" framework that breaks up large computations into small chunks, proves these chunks in parallel in a distributed system, and then aggregates the resulting chunk proofs into a single succinct proof. Underlying this framework is a new technique for efficiently handling data that is shared between chunks that we believe could be of independent interest.
  
We implement a distributed prover for Hᴇᴋᴀᴛᴏɴ, and evaluate its performance on a compute cluster. Our experiments show that Hᴇᴋᴀᴛᴏɴ achieves strong horizontal scalability (proving time decreases linearly as we increase the number of nodes in the cluster), and is able to prove large computations quickly: it can prove computations of size $2^{35}$ gates in under an hour, which is much faster than prior work.

Finally, we also apply Hᴇᴋᴀᴛᴏɴ to two applications of real-world interest: proofs of batched insertion for a verifiable key directory and proving correctness of RAM computations. In both cases, Hᴇᴋᴀᴛᴏɴ is able to scale to handle realistic workloads with better efficiency than prior work.
]]></content:encoded>
<pubDate>Fri, 26 Jul 2024 21:00:30 +0000</pubDate>
</item>
<item>
<title>What Have SNARGs Ever Done for FHE?</title>
<link>https://eprint.iacr.org/2024/1207</link>
<guid>https://eprint.iacr.org/2024/1207</guid>
<content:encoded><![CDATA[
<div> 关键词：FHE、SNARGs、输入隐私、安全模型、IND-CCA1

总结:

本文主要探讨了在功能加密(FHE)与结构化非交互式论证(SNARGs)结合使用时，对于客户端输入隐私的影响及其安全性。文章指出，虽然近几年来，研究者们主要致力于提高这种组合方案的效率，但关于其对输入隐私保护的确切安全模型的研究仍然不足。最近，Manulis和Nguyen在Eurocrypt'24上发表的研究表明，这种组合并不提供IND-CCA1级别的安全性。

为了深入理解SNARG是否为输入隐私提供了有意义的安全性，本文提出了一个能够准确描述FHE加SNARG构造安全性的新定义。这一安全定义旨在清晰地界定该组合方案在实际应用中可能面临的风险和挑战，从而为后续研究提供理论基础。

简而言之，本文通过提出一个新的安全模型，试图解决FHE与SNARG组合使用时输入隐私保护的问题，揭示了现有组合方式在安全性方面的局限性，并为未来研究指明了方向。 <div>
In recent years, there have been several constructions combining FHE with SNARGs to add integrity guarantees to FHE schemes. Most of these works focused on improving efficiency, while the precise security model with regards to client side input privacy has remained understudied. Only recently it was shown by Manulis and Nguyen (Eurocrypt'24) that this combination does not yield IND-CCA1 security. So an interesting open question is: does the SNARG actually add any meaningful security to input privacy? We address this question in this note and give a security definition that meaningfully captures the security of the FHE plus SNARG construction.
]]></content:encoded>
<pubDate>Fri, 26 Jul 2024 09:06:12 +0000</pubDate>
</item>
<item>
<title>MUSES: Efficient Multi-User Searchable Encrypted Database</title>
<link>https://eprint.iacr.org/2023/720</link>
<guid>https://eprint.iacr.org/2023/720</guid>
<content:encoded><![CDATA[
<div> 关键词：MUSES、多写入、隐私保护、高效搜索、分布式加密协议

总结:

本文提出了一种名为MUSES的新颖多写者加密搜索平台，旨在解决现有加密搜索设计的功能性、安全性和性能限制。MUSES支持单一阅读者、多写者功能，并允许权限撤销，同时隐藏所有统计信息（包括搜索、结果和体积模式），并保持用户开销极小。

具体而言，MUSES通过集成分布式点函数、分布式PRF和盲线性群操作等新兴分布式加密协议，实现了其独特功能。此外，还引入了适用于一般多方设置（包括多数欺诈）的盲计数和算术分享上的盲洗牌的新型分布式协议，这些技术在其他应用中也具有潜在价值。

实验结果显示，使用MUSES进行关键词搜索的速度比最先进的方法快两个数量级，同时用户带宽成本降低了高达97倍。这表明MUSES在多写者加密搜索领域提供了一种高效、安全且用户负担轻的解决方案。 <div>
Searchable encrypted systems enable privacy-preserving keyword search on encrypted data. Symmetric systems achieve high efficiency (e.g., sublinear search), but they mostly support single-user search. Although systems based on public-key or hybrid models support multi-user search, they incur inherent security weaknesses (e.g., keyword-guessing vulnerabilities) and scalability limitations due to costly public-key operations (e.g., pairing). More importantly, most encrypted search designs leak statistical information (e.g., search, result, and volume patterns) and thus are vulnerable to devastating leakage-abuse attacks. Some pattern-hiding schemes were proposed. However, they incur significant user bandwidth/computation costs, and thus are not desirable for large-scale outsourced databases with resource-constrained users. 
In this paper, we propose MUSES, a new multi-writer encrypted search platform that addresses the functionality, security, and performance limitations in the existing encrypted search designs. Specifically, MUSES permits single-reader, multi-writer functionalities with permission revocation and hides all statistical information (including search, result, and volume patterns) while featuring minimal user overhead. In MUSES, we demonstrate a unique incorporation of various emerging distributed cryptographic protocols including Distributed Point Function, Distributed PRF, and Oblivious Linear Group Action. We also introduce novel distributed protocols for oblivious counting and shuffling on arithmetic shares for the general multi-party setting with a dishonest majority, which can be found useful in other applications. Our experimental results showed that the keyword search by MUSES is two orders of magnitude faster with up to 97× lower user bandwidth cost than the state-of-the-art.
]]></content:encoded>
<pubDate>Thu, 18 May 2023 20:04:21 +0000</pubDate>
</item>
<item>
<title>SEC: Symmetric Encrypted Computation via Fast Look-ups</title>
<link>https://eprint.iacr.org/2023/628</link>
<guid>https://eprint.iacr.org/2023/628</guid>
<content:encoded><![CDATA[
<div> 关键词：Encrypted Computation、Fully Homomorphic Encryption (FHE)、Searchable Symmetric Encryption (SSE)、Symmetric Encrypted Computation (SEC)、Arbitrary Boolean Circuit Evaluations

<br />
<br />总结:
本文探讨了使用搜索对称加密（SSE）进行对称加密数据上的任意布尔电路评估的高效方法，进而提出了一种名为对称加密计算（SEC）的新方法。SEC是一种基于对称密钥加密原语的实用和可证明安全的查找基础构造，能够支持对对称加密数据执行任意布尔电路的评估，同时扩展并概括了SSE的功能能力，继承了其数据隐私保证和性能优势。

SEC依赖于纯对称密钥密码学原语，实现了灵活的性能与泄漏之间的权衡。相较于传统的全同态加密（FHE），SEC在基本布尔门操作评估中提供了大约1000倍的速度提升，并在处理具有多比特输入的功能时表现出良好的可扩展性，如对AES-128电路和AlexNet架构中的三个最大池化层的加密评估。在这些实验中，SEC在处理时间上比最先进的FHE实现高出1000倍，而存储成本仅增加了250倍。 <div>
Encrypted computation allows a client to securely outsource the storage and processing of sensitive private data to an untrusted third party cloud server. Fully homomorphic encryption (FHE) allows computing arbitrary functions over encrypted data, but incurs huge overheads and does not practically scale to large databases. Whereas, slightly weaker yet efficient constructions- Searchable Symmetric Encryption (SSE) support lookup-based evaluations of a restricted class of Boolean circuits over symmetrically encrypted data. In this paper, we investigate the use of SSE to efficiently perform arbitrary Boolean circuit evaluations over symmetrically encrypted data via look-ups. To this end, in this work, we propose Symmetric Encrypted Computation (SEC): the first practically efficient and provably secure lookup-based construction, analogous
to traditional FHE, that supports evaluation of arbitrary Boolean circuits over symmetrically encrypted data. SEC relies on purely symmetric-key cryptoprimitives and achieves flexible performance versus leakage trade-offs. SEC extends and generalizes the functional capabilities of SSE, while inheriting its data privacy guarantees and desirable performance benefits. We provide a concrete construction of SEC and analyze its security with respect to a rigorously defined and thoroughly analyzed leakage profile. We also present a prototype implementation of SEC and experimentally validate its practical efficiency. Our experiments show that SEC outperforms state-of-the-art FHE schemes (such as Torus FHE) substantially, with around 1000× speed-up in basic Boolean gate evaluations. We further showcase the scalability of SEC for functions
with multi-bit inputs via experiments performing encrypted evaluation of the entire AES-128 circuit, as well as three max-pooling layers of AlexNet architecture. For both sets of experiments, SEC outperforms state-of-the-art and accelerated FHE implementations by 1000× in terms of processing time, while incurring 250× lower storage.
]]></content:encoded>
<pubDate>Tue, 02 May 2023 15:11:16 +0000</pubDate>
</item>
<item>
<title>FssNN: Communication-Efficient Secure Neural Network Training via Function Secret Sharing</title>
<link>https://eprint.iacr.org/2023/073</link>
<guid>https://eprint.iacr.org/2023/073</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、神经网络、安全多方计算（MPC）、通信效率、安全训练与推理

总结:

本文介绍了一种基于安全多方计算（MPC）的高效通信隐私保护神经网络框架——FssNN。该框架旨在解决传统方法中由于非线性函数安全计算导致的高通信成本问题。FssNN提出了减小密钥大小的关键方案，通过分析DCF密钥之间的相关性，设计了具有紧凑加性构造的密钥缩减DCF方案，这显著减少了密钥大小和离线通信成本。此外，通过利用MPC友好的伪随机数生成器，FssNN设计了一个无信任第三方参与的分布式密钥生成协议，进一步提高了系统的实用性。

在FssNN中，非线性和线性函数分别使用密钥缩减DCF和加性秘密共享进行计算，设计了具有常数在线通信轮次的安全计算协议，显著降低了在线通信成本。最后，文章提供了形式化的安全性证明，并在各种模型和数据集上进行了性能评估，结果表明，与最先进的框架AriaNN相比，FssNN在安全训练和推理阶段的总通信成本分别降低了约25.4%和26.4%。

通过上述改进，FssNN不仅提高了通信效率，还增强了系统的实用性，为在分布式环境中安全有效地训练和推理神经网络提供了有力的支持。 <div>
Privacy-preserving neural network based on secure multi-party computation (MPC) enables multiple parties to jointly train neural network models without revealing sensitive data. In privacy-preserving neural network, the high communication costs of securely computing non-linear functions is the primary performance bottleneck. For commonly used non-linear functions, such as ReLU, existing work adopts an offline-online computation paradigm and utilizes distributed comparison function (DCF) to reduce communication costs. Specifically, these works prepare DCF keys in the offline phase and perform secure ReLU using these DCF keys in the online phase. However, the practicality of existing work is significantly limited due to the substantial size of DCF keys and the heavy reliance on a trusted third party in the offline phase.

In this work, we introduce a communication-efficient secure two-party neural network framework called FssNN, which proposes a key-reduced DCF scheme without a trusted third party to enable practical secure training and inference. First, by analyzing the correlations between DCF keys to eliminate redundant parameters, we propose a key-reduced DCF scheme with a compact additive construction, which decreases the size of DCF keys by about $17.9\%$ and the offline communication costs by approximately $28.0\%$. Secondly, by leveraging an MPC-friendly pseudorandom number generator, we propose a secure two-party distributed key generation protocol for our key-reduced DCF, thereby eliminating the reliance on the trusted third party. Finally, we utilize the key-reduced DCF and additive secret sharing to compute non-linear and linear functions, respectively, and design secure computation protocols with constant online communication rounds for neural network operators, reducing the online communication costs by $28.9\% \sim 43.4\%$.

We provide formal security proofs and evaluate the performance of FssNN on various models and datasets. Experimental results show that compared to the state-of-the-art framework AriaNN, our framework reduces the total communication costs of secure training and inference by approximately $25.4\%$ and $26.4\%$ respectively.
]]></content:encoded>
<pubDate>Sun, 22 Jan 2023 16:28:47 +0000</pubDate>
</item>
<item>
<title>The Espresso Sequencing Network: HotShot Consensus, Tiramisu Data-Availability, and Builder-Exchange</title>
<link>https://eprint.iacr.org/2024/1189</link>
<guid>https://eprint.iacr.org/2024/1189</guid>
<content:encoded><![CDATA[
Building a Consensus platform for shared sequencing can power an ecosystem of layer-2 solutions such as rollups which are crucial for scaling blockchains (e.g.,Ethereum). However, it drastically differs from conventional Consensus for blockchains in two key considerations:
• (No) Execution: A shared sequencing platform is not responsible for pre-validating blocks nor for processing state updates. Therefore, agreement is formed on a sequence of certificates of block data-availability (DA) without persisting them or obtaining blocks in full. At the same time, the platform must stream block data with very high efficiency to layer-2 entities for execution, or (in the case of rollups) for proof generation.
• Builder-Exchange: A shared sequencing platform delegates to external entities to build blocks and separates it from the role of a consensus proposer. This allows an ecosystem of specialized builders to pre-validate transactions for diversified rollups, languages, and MEV exploits. However, separating the task of block-building from proposing brings a new challenge. Builders want assurances that their blocks would commit in exchange for revealing their contents, whereas validators/proposers want assurance that the data in committed blocks will be available and fees paid. Neither one trusts the other, hence the shared sequencing platform should facilitate a “fair-exchange”  between builders and the sequencing network. The Espresso Sequencing Network is purpose-built to address these unique considerations.
Among the main novelties of the design are (i) a three-layered DA system called Tiramisu, coupled with (ii) a costless integration of the DA with the platform’s consensus core, and (iii) a Builder-Exchange mechanism between builders and the consensus core.
Note that this paper relies substantially on and can be seen as an extension of The Espresso Sequencer: HotShot Consensus and Tiramisu Data Availability [84].
]]></content:encoded>
<pubDate>Tue, 23 Jul 2024 19:57:45 +0000</pubDate>
</item>
<item>
<title>Hyperion: Transparent End-to-End Verifiable Voting with Coercion Mitigation</title>
<link>https://eprint.iacr.org/2024/1182</link>
<guid>https://eprint.iacr.org/2024/1182</guid>
<content:encoded><![CDATA[
We present Hyperion, an end-to-end verifiable e-voting scheme that allows the voters to identify their votes in cleartext in the final tally. In contrast to schemes like Selene or sElect, identification is not via (private) tracker numbers but via cryptographic commitment terms. After publishing the tally, the Election Authority provides each voter with an individual dual key. Voters identify their votes by raising their dual key to their secret trapdoor key and finding the matching commitment term in the tally. 
The dual keys are self-certifying in that, without the voter's trapdoor key, it is intractable to forge a dual key that, when raised to the trapdoor key, will match an alternative commitment. On the other hand, a voter can use their own trapdoor key to forge a dual key to fool any would-be coercer.
Additionally, we propose a variant of Hyperion that counters the tracker collision threat present in Selene. We introduce individual verifiable views: each voter gets their own independently shuffled view of the master Bulletin Board. 
We provide new improved definitions of privacy and verifiability for e-voting schemes and prove the scheme secure against these, as well as proving security with respect to earlier definitions in the literature.
Finally, we provide a prototype implementation and provide measurements which demonstrate that our scheme is practical for large scale elections.
]]></content:encoded>
<pubDate>Mon, 22 Jul 2024 17:26:10 +0000</pubDate>
</item>
<item>
<title>AQQUA: Augmenting Quisquis with Auditability</title>
<link>https://eprint.iacr.org/2024/1181</link>
<guid>https://eprint.iacr.org/2024/1181</guid>
<content:encoded><![CDATA[
We propose AQQUA: a digital payment system that combines auditability and privacy. AQQUA extends Quisquis by adding two authorities; one for registration and one for auditing. These authorities do not intervene in the everyday transaction processing; as a consequence, the decentralized nature of the cryptocurrency is not disturbed. Our construction is account-based. An account consists of an updatable public key which functions as a cryptographically unlinkable pseudonym, and of commitments to the balance, the total amount of coins spent, and the total amount of coins received. In order to participate in the system a user creates an initial account with the registration authority. To protect their privacy, whenever the user wants to transact they create unlinkable new accounts by updating their public key and the total number of accounts they own (maintained in committed form). The audit authority may request an audit at will. The user must prove in zero-knowledge that all their accounts are compliant to  specific policies. We formally define a security model capturing the properties that a private and auditable digital payment system should possess and we analyze the security of AQQUA under this model.
]]></content:encoded>
<pubDate>Mon, 22 Jul 2024 16:04:13 +0000</pubDate>
</item>
<item>
<title>Post-quantum XML and SAML Single Sign-On</title>
<link>https://eprint.iacr.org/2024/828</link>
<guid>https://eprint.iacr.org/2024/828</guid>
<content:encoded><![CDATA[
Extensible Markup Language (XML) is one of the most popular serialization languages. Since many security protocols are built using XML, it also provides cryptographic functionality. A central framework in this area is the Security Assertion Markup Language (SAML). This standard is one of the most widely used options for implementing Single Sign-On (SSO), which allows users to authenticate to different service providers using the credentials from a single identity provider. Like all other security protocols currently in use, the security and privacy of XML-based frameworks such as SAML is threatened by the development of increasingly powerful quantum computers. In fact, future attackers with access to scalable quantum computers will be able to break the currently used cryptographic building blocks and thus undermine the security of the SAML SSO to illegally access sensitive private information. Post-quantum cryptography algorithms have been developed to protect against such quantum attackers. While many security protocols have been migrated into the quantum age by using post-quantum cryptography, no such solutions for XML and the security protocols based on it have been developed, let alone tested. We make the following contributions to fill this gap. We have designed post-quantum solutions for the cryptographic building blocks in XML and integrated them into the SAML SSO protocol. We implemented our solutions in the OpenSAML, Apache Santuario, and BouncyCastle libraries and extensively tested their performance for various post-quantum instantiations. As a result, we have created a comprehensive and solid foundation for post-quantum XML and post-quantum SAML SSO migration.
]]></content:encoded>
<pubDate>Mon, 27 May 2024 15:52:37 +0000</pubDate>
</item>
<item>
<title>Succinctly-Committing Authenticated Encryption</title>
<link>https://eprint.iacr.org/2024/875</link>
<guid>https://eprint.iacr.org/2024/875</guid>
<content:encoded><![CDATA[
Recent attacks and applications have led to the need for symmetric encryption schemes that, in addition to providing the usual authenticity and privacy, are also committing. In response, many committing authenticated encryption schemes have been proposed. However, all known schemes, in order to provide s bits of committing security, suffer an expansion---this is the length of the ciphertext minus the length of the plaintext---of 2s bits. This incurs a cost in bandwidth or storage. (We typically want s=128, leading to 256-bit expansion.) However, it has been considered unavoidable due to birthday attacks. We show how to bypass this limitation. We give authenticated encryption (AE) schemes that provide s bits of committing security, yet suffer expansion only around s as long as messages are long enough, namely more than s bits. We call such schemes succinct. We do this via a generic, ciphertext-shortening transform called SC: given an AE scheme with 2s-bit expansion, SC returns an AE scheme with s-bit expansion while preserving committing security. SC is very efficient; an AES-based instantiation has overhead just two AES calls. As a tool, SC uses a collision-resistant invertible PRF called HtM, that we design, and whose analysis is technically difficult. To add the committing security that SC assumes to a base scheme, we also give a transform CTY that improves Chan and Rogaway's CTX. Our results hold in a general framework for authenticated encryption, called AE3, that includes both AE1 (also called AEAD) and AE2 (also called nonce-hiding AE) as special cases, so that we in particular obtain succinctly-committing AE schemes for both these settings.
]]></content:encoded>
<pubDate>Sat, 01 Jun 2024 23:38:52 +0000</pubDate>
</item>
<item>
<title>Linea Prover Documentation</title>
<link>https://eprint.iacr.org/2022/1633</link>
<guid>https://eprint.iacr.org/2022/1633</guid>
<content:encoded><![CDATA[
Rollup technology today promises long-term solutions to the scalability of the blockchain. Among a thriving ecosystem, Consensys has launched the Linea zkEVM Rollup network for Ethereum. 

At a high level, the Ethereum blockchain can be seen as a state machine and its state transition can be arithmetized carefully. Linea's prover protocol uses this arithmetization, along with transactions on layer two in order to compute a cryptographic proof that the state transition is performed correctly. 

The proof is then sent over to the Ethereum layer, where the smart contract (verifier contract) on Ethereum checks the proof and accepts the state transition if the proof is valid. The interaction between layer two and Ethereum is costly, which imposes substantial limitations on the proof size. Therefore, Linea's prover aims to compress the proof via cryptographic tools such as list polynomial commitments (LPCs), polynomial interactive oracle proofs (PIOPs), and Succinct Non-Interactive Arguments of Knowledge (SNARKs).

We introduce Wizard-IOP, a cryptographic tool for handling a wide class of queries (such as range checks, scalar products, permutations checks, etc.) needed to ensure the correctness of the executions of the state machines efficiently and conveniently. Another cryptographic tool is the Arcane compiler, which outputs standard PIOPs and is employed by Wizard-IOP to make different queries homogeneous. After applying Arcane, all the queries constitute evaluation queries over the polynomials. We then apply the Unique Evaluation compiler (UniEval), which receives the output of the Arcane and provides us with a PIOP that requires only a single evaluation check. 

At this point, we employ Vortex, a list polynomial commitment (LPC) scheme to convert the resulting PIOP into an argument of knowledge. The argument of knowledge is then made succinct by applying different techniques such as self-recursion, standard recursion, and proof aggregations.
]]></content:encoded>
<pubDate>Thu, 24 Nov 2022 11:00:59 +0000</pubDate>
</item>
<item>
<title>Towards Quantum-Safe Blockchain: Exploration of PQC and Public-key Recovery on Embedded Systems</title>
<link>https://eprint.iacr.org/2024/1178</link>
<guid>https://eprint.iacr.org/2024/1178</guid>
<content:encoded><![CDATA[
<div> 关键词：Post-Quantum Cryptography (PQC), Blockchain, IoT, Embedded Systems, Quantum-Safe

总结: <br />
文章探讨了区块链技术在依赖公钥加密的背景下对量子计算威胁的脆弱性。为解决这一问题，作者提出将后量子密码学(PQC)融入区块链框架，以增强安全性与韧性，特别针对物联网(IoT)和嵌入式系统。研究着重于PQC在嵌入式环境中的实现，如NIST标准中的算法。通过优化交易大小，如使用Falcon的公钥恢复技术，可减少交易体积高达17%。Falcon-512和XMSS被推荐为量子安全区块链的合适选项，但Dilithium在嵌入式设备上的TPS更高。此外，文章还讨论了智能合约功能与PQC结合的影响。总的来说，研究证实了在嵌入式系统中部署量子安全区块链的可行性，为构建未来-proof的IoT应用提供了坚实基础。 <div>
Blockchain technology ensures accountability,
transparency, and redundancy in critical applications, includ-
ing IoT with embedded systems. However, the reliance on
public-key cryptography (PKC) makes blockchain vulnerable to
quantum computing threats. This paper addresses the urgent
need for quantum-safe blockchain solutions by integrating Post-
Quantum Cryptography (PQC) into blockchain frameworks.
Utilizing algorithms from the NIST PQC standardization pro-
cess, we aim to fortify blockchain security and resilience, partic-
ularly for IoT and embedded systems. Despite the importance
of PQC, its implementation in blockchain systems tailored for
embedded environments remains underexplored. We propose
a quantum-secure blockchain architecture, evaluating various
PQC primitives and optimizing transaction sizes through tech-
niques such as public-key recovery for Falcon, achieving up
to 17% reduction in transaction size. Our analysis identifies
Falcon-512 as the most suitable algorithm for quantum-secure
blockchains in embedded environments, with XMSS as a viable
stateful alternative. However, for embedded devices, Dilithium
demonstrates a higher transactions-per-second (TPS) rate
compared to Falcon, primarily due to Falcon’s slower sign-
ing performance on ARM CPUs. This highlights the signing
time as a critical limiting factor in the integration of PQC
within embedded blockchains. Additionally, we integrate smart
contract functionality into the quantum-secure blockchain,
assessing the impact of PQC on smart contract authentication.
Our findings demonstrate the feasibility and practicality of
deploying quantum-secure blockchain solutions in embedded
systems, paving the way for robust and future-proof IoT
applications.
]]></content:encoded>
<pubDate>Sun, 21 Jul 2024 13:51:38 +0000</pubDate>
</item>
<item>
<title>AVeCQ: Anonymous Verifiable Crowdsourcing with Worker Qualities</title>
<link>https://eprint.iacr.org/2024/1175</link>
<guid>https://eprint.iacr.org/2024/1175</guid>
<content:encoded><![CDATA[
<div> 关键词：Crowdsourcing, Anonymity, Unlinkability, Worker Quality, Cryptographic Tools.

总结:<br />
AVeCQ是一个创新的去中心化、隐私保护的众包系统，它结合了增强匿名性和可验证的工人质量更新。该系统利用零知识证明等密码学工具来保障工人隐私，验证答案和评分的准确性，以及公平支付。AVeCQ模块化设计，允许请求者和工人通过支持匿名性、信息记录和支付的平台交互。与现有方案相比，如在图像注解、平均评价和盖洛普民意调查等任务中，AVeCQ表现出更高的效率，包括减少计算和验证证明，以及区块链交易处理的开销，例如在128名工人参与的平均评价任务中，AVeCQ比现有系统快40%，同时请求者的交易消耗降低87%。 <div>
In crowdsourcing systems, requesters publish tasks, and interested workers provide answers to get rewards. Worker anonymity motivates participation since it protects their privacy. Anonymity with unlinkability is an enhanced version of anonymity because it makes it impossible to ``link'' workers across the tasks they participate in. Another core feature of crowdsourcing systems is worker quality which expresses a worker's trustworthiness and quantifies their historical performance. In this work, we present AVeCQ, the first crowdsourcing system that reconciles these properties, achieving enhanced anonymity and verifiable worker quality updates. AVeCQ relies on a suite of cryptographic tools, such as zero-knowledge proofs, to (i) guarantee workers' privacy, (ii) prove the correctness of worker quality scores and task answers, and (iii) commensurate payments. AVeCQ is developed modularly, where requesters and workers communicate over a platform that supports pseudonymity, information logging, and payments. To compare AVeCQ with the state-of-the-art, we prototype it over Ethereum. AVeCQ outperforms the state-of-the-art in three popular crowdsourcing tasks (image annotation, average review, and Gallup polls). E.g., for an Average Review task with 5 choices and 128 workers AVeCQ is 40% faster (including computing and verifying necessary proofs, and blockchain transaction processing overheads) with the task's requester consuming 87% fewer gas.
]]></content:encoded>
<pubDate>Sat, 20 Jul 2024 15:54:15 +0000</pubDate>
</item>
<item>
<title>Rudraksh: A compact and lightweight post-quantum key-encapsulation mechanism</title>
<link>https://eprint.iacr.org/2024/1170</link>
<guid>https://eprint.iacr.org/2024/1170</guid>
<content:encoded><![CDATA[
<div> 关键词：Post-quantum cryptography (PQC), lightweight implementation, resource-constrained devices, lattice-based KEM, area optimization.

总结:<br />
本文关注的是在资源受限的设备中集成后量子密码学（PQC）的挑战。首先，作者提出了一种基于硬晶格问题的轻量级选择密钥封装机制（KEM），以应对这些设备的低内存和低功耗需求。通过精心分析和优化设计元素，如多项式大小、域模结构、还原算法等，新设计在保持100位PQ安全的同时，相比当前标准Kyber KEM，实现了约3倍的面积效率提升。这项工作为PQC在物联网和无线传感器等设备中的应用开辟了新的可能性。 <div>
Resource-constrained devices such as wireless sensors and Internet of Things (IoT) devices have become ubiquitous in our digital ecosystem. These devices generate and handle a major part of our digital data.  In the face of the impending threat of quantum computers on our public-key infrastructure, it is impossible to imagine the security and privacy of our digital world without integrating post-quantum cryptography (PQC) into these devices. Usually, due to the resource constraints of these devices, the cryptographic schemes in these devices have to operate with very small memory and consume very little power. Therefore, we must provide a lightweight implementation of existing PQC schemes by possibly trading off the efficiency. The other option that can potentially provide the most optimal result is by designing PQC schemes suitable for lightweight and low-power-consuming implementation.  Unfortunately, the latter method has been largely ignored in PQC research.

In this work, we first provide a lightweight CCA-secure PQ key-encapsulation mechanism (KEM) design based on hard lattice problems. We have done a scrupulous and extensive analysis and evaluation of different design elements, such as polynomial size, field modulus structure, reduction algorithm, secret and error distribution, etc., of a lattice-based KEM. We have optimized each of them to obtain a lightweight design. Our design provides a $100$ bit of PQ security and shows $\sim3$x improvement in terms of area with respect to the state-of-the-art Kyber KEM, a PQ standard.
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 15:39:16 +0000</pubDate>
</item>
<item>
<title>Expanding the Toolbox: Coercion and Vote-Selling at Vote-Casting Revisited</title>
<link>https://eprint.iacr.org/2024/1167</link>
<guid>https://eprint.iacr.org/2024/1167</guid>
<content:encoded><![CDATA[
<div> 关键词：coercion, vote-buying, electronic voting, remote, blockchain

总结:<br />
本文探讨了电子投票，特别是远程电子投票中面临的胁迫（coercion）和贿赂选票（vote-buying）问题。作者指出，尽管已有抵抗措施，但现有的技术工具如区块链、延迟加密和隐私保护智能合约可能被恶意行为者利用加强这些攻击。文章强调，现有的胁迫模型需要重新评估，提出新的胁迫定义和无收据自由（receipt-freeness）概念。研究者建议在设计新的选举系统时考虑这些新定义，以确保更安全的民主投票环境。 <div>
Coercion is a challenging and multi-faceted threat that prevents people from expressing their will freely. Similarly, vote-buying does to undermine the foundation of free democratic elections. These threats are especially dire for remote electronic voting, which relies on voters to express their political will freely but happens in an uncontrolled environment outside the polling station and the protection of the ballot booth. However, electronic voting in general, both in-booth and remote, faces a major challenge, namely to ensure that voters can verify that their intent is captured correctly without providing a receipt of the cast vote to the coercer or vote buyer.

Even though there are known techniques to resist or partially mitigate coercion and vote-buying, we explicitly demonstrate that they generally underestimate the power of malicious actors by not accounting for current technological tools that could support coercion and vote-selling. 

In this paper, we give several examples of how a coercer can force voters to comply with his demands or how voters can prove how they voted. To do so, we use tools like blockchains, delay encryption, privacy-preserving smart contracts, or trusted hardware. Since some of the successful coercion attacks occur on voting schemes that were supposed/claimed/proven to be coercion-resistant or receipt-free, the main conclusion of this work is that the coercion models should be re-evaluated, and new definitions of coercion and receipt-freeness are necessary. We propose such new definitions as part of this paper and investigate their implications.
]]></content:encoded>
<pubDate>Fri, 19 Jul 2024 07:08:37 +0000</pubDate>
</item>
<item>
<title>Key-and-Signature  Compact Multi-Signatures for Blockchain: A Compiler with  Realizations</title>
<link>https://eprint.iacr.org/2023/061</link>
<guid>https://eprint.iacr.org/2023/061</guid>
<content:encoded><![CDATA[
<div> 关键词：multi-signature, linear ID, public-key, signature, lattice-based ID

总结: 这篇论文介绍了一种新的方法，将线性标识（linear ID）方案转换为多签名协议，以实现短小的聚合公钥和签名。这种转换器解决了去中心化环境下防止恶意攻击的问题，并优化了区块链上的存储需求。研究者利用两种身份验证方案——Schnorr ID和基于 lattice 的新方案，实现了这一编译器。通过这种方式，他们得到了第一个无需重启签名人过程的常规 lattice 基础多签名方案，同时保持了关键和签名的紧凑性。这种方法简化了多方问题，转而依赖于弱式两方安全问题的解决方案。 <div>
Multi-signature is a protocol where a set of signatures jointly sign a message so that the final signature is significantly shorter than concatenating individual  signatures together. Recently, it finds applications in blockchain, where several users want to jointly authorize a payment through a multi-signature.  However, in this setting, there is no centralized authority and it could suffer from a rogue key attack where the attacker can generate his own keys arbitrarily. Further, to minimize the storage on blockchain, it is desired that the aggregated  public-key and the aggregated signature are both as short as possible. In this paper,  we find a compiler that converts a kind  of identification (ID) scheme (which we call a linear ID) to a multi-signature so that both the aggregated  public-key and the aggregated signature have a  size independent of the number of signers. Our compiler is provably secure. The advantage of our results is that we reduce a multi-party problem to a weakly secure two-party problem.  We realize our compiler with two ID schemes. The first is  Schnorr ID. The second is a new lattice-based ID scheme,  which via our compiler gives the first regular lattice-based multi-signature scheme with  key-and-signature compact without a restart during signing process.
]]></content:encoded>
<pubDate>Thu, 19 Jan 2023 22:29:39 +0000</pubDate>
</item>
<item>
<title>Abuse-Resistant Location Tracking: Balancing Privacy and Safety in the Offline Finding Ecosystem</title>
<link>https://eprint.iacr.org/2023/1332</link>
<guid>https://eprint.iacr.org/2023/1332</guid>
<content:encoded><![CDATA[
<div> 关键词：location tracking, privacy guarantees, tracker-based stalking, abuse-resistant offline finding protocols, multi-dealer secret sharing

总结:<br />文章探讨了位置追踪附件（如Apple和Samsung销售的跟踪标签）的隐私问题。这些设备设计初衷是为了保护用户隐私，但现实中却面临$\textit{tracker-based stalking}$（跟踪式骚扰）的问题。为平衡隐私和对跟踪行为的识别，提出了$\textit{abuse-resistant offline finding protocols}$（抗滥用离线查找协议）。作者提出了一种高效协议，利用$\textit{multi-dealer secret sharing}$（多经销商秘密共享）这一新型隐私增强工具，结合Interleaved Reed-Solomon代码和新的 lattice-based decoding算法，实现在保护用户隐私的同时有效检测跟踪者。这一成果对于边缘设备的高效实现具有重要意义。 <div>
Location tracking accessories (or "tracking tags") such as those sold by Apple, Samsung, and Tile, allow owners to track the location of their property via offline finding networks. The tracking protocols were designed to ensure that no entity (including the vendor) can use a tag's broadcasts to surveil its owner. These privacy guarantees, however, seem to be at odds with the  phenomenon of $\textit{tracker-based stalking}$, where attackers use these very tags to monitor a target's movements. Numerous such criminal incidents have been reported, and in response, manufacturers have chosen to substantially weaken privacy guarantees in order to allow users to detect stalker tags. This compromise has been adopted in a recent IETF draft jointly proposed by Apple and Google. 
 

We put forth the notion of $\textit{abuse-resistant offline finding protocols}$ that aim to achieve a better balance between user privacy and stalker detection. We present an efficient protocol that achieves stalker detection under realistic conditions without sacrificing honest user privacy. At the heart of our result, and of independent interest, is a new notion of $\textit{multi-dealer secret sharing}$ which strengthens standard secret sharing with novel privacy and correctness guarantees. We show that this primitive can be instantiated efficiently on edge devices using variants of Interleaved Reed-Solomon codes combined with new lattice-based decoding algorithms.
]]></content:encoded>
<pubDate>Thu, 07 Sep 2023 03:50:56 +0000</pubDate>
</item>
<item>
<title>Respire: High-Rate PIR for Databases with Small Records</title>
<link>https://eprint.iacr.org/2024/1165</link>
<guid>https://eprint.iacr.org/2024/1165</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Information Retrieval（PIR）、Communication Overhead、Database、Small Records、Lattice-Based Scheme。

总结:<br />本文介绍了一种名为Respire的新型基于 lattice 的隐私信息检索（PIR）方案，特别针对小记录数据库设计。与现有最高效方案相比，Respire在下载单个记录时的在线通信量减少了5.9倍，仅需6.1KB。此外，Respire支持批量查询，相比先前高效通信的批处理PIR方案，它在总通信上降低了3.4-7.1倍，同时保持了相近的吞吐量（200-400MB/s）。其设计创新之处在于运用了新的查询压缩和响应打包技术，这些技术基于同态加密中的环切换。 <div>
Private information retrieval (PIR) is a key building block in many privacy-preserving systems, and recent works have made significant progress on reducing the concrete computational costs of single-server PIR. However, existing constructions have high communication overhead, especially for databases with small records. In this work, we introduce Respire, a lattice-based PIR scheme tailored for databases of small records. To retrieve a single record from a database with over a million 256-byte records, the Respire protocol requires just 6.1 KB of online communication; this is a 5.9x reduction compared to the best previous lattice-based scheme. Moreover, Respire naturally extends to support batch queries. Compared to previous communication-efficient batch PIR schemes, Respire achieves a 3.4-7.1x reduction in total communication while maintaining comparable throughput (200-400 MB/s). The design of Respire relies on new query compression and response packing techniques based on ring switching in homomorphic encryption.
]]></content:encoded>
<pubDate>Thu, 18 Jul 2024 17:26:24 +0000</pubDate>
</item>
<item>
<title>Cross Ledger Transaction Consistency for Financial Auditing</title>
<link>https://eprint.iacr.org/2024/1155</link>
<guid>https://eprint.iacr.org/2024/1155</guid>
<content:encoded><![CDATA[
<div> 关键词：Auditing, Organizations, Ledgers, Security, Scalability

总结:<br />本文主要探讨了审计在财政年度对交易活跃组织的重要性，以及当前审计过程中存在的挑战。为解决大量组织数据核查的计算问题，作者提出CLOSC和CLOLC两种协议，旨在确保不同账本之间的交易一致性，同时保护交易金额、组织与审计者之间的匿名性和交易组织间的隐私。这两种协议基于两层账本架构和加密工具，实现了高效安全的审计。文章通过性能评估显示，即使处理百万级交易，计算和验证时间也能保持在秒级别，而单个审计周期的链上存储成本也非常合理。 <div>
Auditing throughout a fiscal year is integral to organizations with transactional activity. Organizations transact with each other and record the details for all their economical activities so that a regulatory committee can verify the lawfulness and legitimacy of their activity. However, it is computationally infeasible for the committee to perform all necessary checks for each organization. To overcome this, auditors assist in this process: organizations give access to all their internal data to their auditors, who then produce reports regarding the consistency of the organization's data, alerting the committee to any inconsistencies. Despite this, numerous issues that result in fines annually revolve around such inconsistencies in bookkeeping across organizations. Notably, committees wishing to verify the correctness of auditor-provided reports need to redo all their calculations; a process which is computationally proportional to the number of organizations. In fact, it becomes prohibitive when considering real-world settings with thousands of organizations. In this work, we propose two protocols, CLOSC and CLOLC, whose goals are to enable auditors and a committee to verify the consistency of transactions across different ledgers. Both protocols ensure that for every transaction recorded in an organization's ledger, there exists a dual one in the ledger of another organization while safeguarding against other potential attacks. Importantly, we minimize the information leakage to auditors and other organizations and guarantee three crucial security and privacy properties that we propose: (i) transaction amount privacy, (ii) organization-auditor unlinkability, and (iii) transacting organizations unlinkability. At the core of our protocols lies a two-tier ledger architecture alongside a suite of cryptographic tools. To demonstrate the practicality and scalability of our designs, we provide extensive performance evaluation for both CLOSC and CLOLC. Our numbers are promising, i.e., all computation and verification times lie in the range of seconds, even for millions of transactions, while the on-chain storage costs for an auditing epoch are encouraging i.e. in the range of GB for millions of transactions and thousands of organizations.
]]></content:encoded>
<pubDate>Tue, 16 Jul 2024 12:41:36 +0000</pubDate>
</item>
<item>
<title>Blockchain Space Tokenization</title>
<link>https://eprint.iacr.org/2024/1154</link>
<guid>https://eprint.iacr.org/2024/1154</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain systems, transaction inclusion policy, fee predictability, delay predictability, incentive compatibility

总结: 
本文关注区块链系统的交易拥堵问题，特别是如何在保证安全性和去中心化的同时实现交易费用和延迟的可预测性。传统方法如拍卖或动态调整费用存在矛盾。为此，作者提出区块链空间令牌化（BST）的概念，允许用户预付费锁定一段时间内的交易能力，以提高交易的确定性和抗攻击性。文章通过安全游戏模型分析了BST机制，证明它能提供可预测的最优延迟、费用以及激励兼容性，从而正面回答了研究中的问题。 <div>
Handling congestion in blockchain systems is a fundamental problem given that the security and decentralization objectives of such systems lead to designs that compromise on (horizontal) scalability (what sometimes is referred to as the ``blockchain trilemma''). Motivated by this, we focus on the question whether it is possible to design a  transaction inclusion policy for block producers  that facilitates  fee and delay predictability while being incentive compatible at the same time. 


Reconciling these three properties is seemingly paradoxical given that the dominant approach to transaction processing is based on first-price auctions (e.g., as in Bitcoin) or dynamic adjustment of the minimum admissible fee (e.g. as in Ethereum EIP-1559) something that breaks fee predictability. At the same time, in fixed fee mechanisms (e.g., as in Cardano),  fees are trivially predictable but are subject to  relatively inexpensive bribing or denial of service attacks where transactions may be delayed indefinitely by a well funded attacker, hence breaking delay predictability.  

In this work, we set out to address this problem by putting forward blockchain space tokenization (BST), namely a new capability of a blockchain system to tokenize its capacity for transactions and allocate it to interested users who are willing to pay ahead of time for the ability to post transactions regularly for a period of time. We analyze our system in the face of  worst-case transaction-processing attacks by introducing a security game played between the mempool mechanism and an adversary.  Leveraging this framework, we prove that BST offers predictable and asymptotically optimal delays, predictable fees, and is incentive compatible, thus answering the question posed in the affirmative.
]]></content:encoded>
<pubDate>Tue, 16 Jul 2024 11:26:44 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Data Deduplication for Enhancing Federated Learning of Language Models</title>
<link>https://eprint.iacr.org/2024/1151</link>
<guid>https://eprint.iacr.org/2024/1151</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning, Deduplication, Privacy-Preserving, Efficient Privacy-MPD, Performance Improvement.

总结: <br />
文章探讨了在联邦学习中进行数据去重（deduplication）的重要性和挑战。为解决这一问题，作者提出了一种创新协议：高效隐私保护多方去重（EP-MPD）。EP-MPD通过两个新型的私密集合交集协议模块构建，实现了在保护数据隐私的同时，从多个客户端数据集中高效去除重复项。实验结果表明，去重显著提高了大型语言模型的联邦学习性能，如降低 perplexity 达19.61%，并减少运行时间高达27.95%。EP-MPD在联邦学习中兼顾了隐私和效率，为大规模应用提供了有价值解决方案。 <div>
Deduplication is a vital preprocessing step that enhances machine learning model performance and saves training time and energy. However, enhancing federated learning through deduplication poses challenges, especially regarding scalability and potential privacy violations if deduplication involves sharing all clients’ data. In this paper, we address the problem of deduplication in a federated setup by introducing a pioneering protocol, Efficient Privacy-Preserving Multi-Party Deduplication (EP-MPD). It efficiently removes duplicates from multiple clients’ datasets without compromising data privacy. EP-MPD is constructed in a modular fashion, utilizing two novel variants of the Private Set Intersection protocol. Our extensive experiments demonstrate the significant benefits of deduplication in federated learning of large language models. For instance, we observe up to 19.61% improvement in perplexity and up to 27.95% reduction in running time. EP-MPD effectively balances privacy and performance in federated learning, making it a valuable solution for large-scale applications.
]]></content:encoded>
<pubDate>Mon, 15 Jul 2024 20:53:24 +0000</pubDate>
</item>
<item>
<title>Faster Private Decision Tree Evaluation for Batched Input from Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/662</link>
<guid>https://eprint.iacr.org/2024/662</guid>
<content:encoded><![CDATA[
<div> 关键词：Privacy-preserving, Decision tree evaluation, Non-interactive, Batched, Speedup

总结: <br />
本文提出两种新型非交互式批量隐私保护决策树评估（PDTE）协议：OursRCC和OursCW，分别基于批量加密值与单个明文值的比较算法——批量范围覆盖比较器（RCC）和常数权重片段比较器（CW）。相较于最先进的Level Up（CCS'23），它们在16位批量加密值比较中速度提升高达72倍。此外，作者创新了适应性SumPath树遍历方法，降低了服务器响应的复杂度至$\mathcal{O}(1)$，而Level Up为$\mathcal{O}(2^d)$，且客户端查询效率提高。总的来说，新提出的PDTE协议具有最优的服务器到客户端通信复杂度，对于批量大小16384，速度提升可达17倍。 <div>
Privacy-preserving decision tree evaluation (PDTE) allows a client that holds feature vectors to perform inferences against a decision tree model on the server side without revealing feature vectors to the server. Our work focuses on the non-interactive batched setting where the client sends a batch of encrypted feature vectors and then obtains classifications, without any additional interaction. This is useful in privacy-preserving credit scoring, biometric authentication, and many more applications.

In this paper, we propose two novel non-interactive batched PDTE protocols, OursRCC and OursCW, based on two batched ciphertext-plaintext comparison algorithms, our batched range cover comparison (RCC) comparator and the constant-weight (CW) piece-wise comparator, respectively. When comparing 16-bit batched encrypted values to a single plaintext value, our comparison algorithms show a speedup of up to $72\times$ compared to the state-of-the-art Level Up (CCS'23). Moreover, we introduced a new tree traversal method called adapted SumPath, to achieve $\mathcal{O}(1)$ complexity of the server's response, whereas Level Up has $\mathcal{O}(2^d)$ complexity for a depth-$d$ tree and the client needs to look up classification values in a table.

Overall, our PDTE protocols attain the optimal server-to-client communication complexity and are up to $17\times$ faster than Level Up in batch size 16384.
]]></content:encoded>
<pubDate>Mon, 29 Apr 2024 20:49:56 +0000</pubDate>
</item>
<item>
<title>Identity-Based Matchmaking Encryption, Revisited: Improved Constructions with Strong Security</title>
<link>https://eprint.iacr.org/2023/1435</link>
<guid>https://eprint.iacr.org/2023/1435</guid>
<content:encoded><![CDATA[
<div> 关键词：Identity-based matchmaking encryption (IB-ME), Security definitions, Privacy, Authentication, Constructions.

总结:<br />
这篇论文主要探讨了身份匹配加密（IB-ME）的安全性定义和构造。首先，它对现有IB-ME的安全概念进行了分类，将隐私分为三种类型（对称、选择性和解密错误时的隐私）和四种类型的认证（内部和外部的非冒充和强认证）。作者提出了一种新的“解密错误安全”游戏，以更好地理解这种特殊情况下的隐私保护。其次，论文提供了两种高效且强安全的IB-ME方案：一种基于Boneh-Franklin IBE，具有更紧凑的密钥和更强大的安全性；另一种是通用构造，提供最短的密文和更强的保障，适用于各种假设，如标准模型中的对称外部Diffie-Hellman假设和量子随机Oracle模型中的 lattice。这些改进增强了IB-ME的实用性和安全性。 <div>
Identity-based matchmaking encryption (IB-ME) [Ateniese et al. Crypto 2019] allows users to communicate privately in an anonymous and authenticated manner. After the seminal paper by Ateniese et al., a lot of work has been done on the security and construction of IB-ME. In this work, we revisit the security definitions of IB-ME and provide improved constructions of it. First, we classify the existing security notions of IB-ME, systematically categorizing privacy into three categories (CPA, CCA, and privacy in the case of mismatch) and authenticity into four categories (NMA and CMA both against insiders and outsiders).In particular, we reconsider the privacy when the sender's identity is mismatched during decryption, and provide a new simple security game, called mismatch security, capturing the essence of it. Second, we propose efficient and strongly secure IB-ME schemes from the bilinear Diffie-Hellman assumption in the random oracle model and from anonymous identity-based encryption, identity-based signature, and reusable extractors in the standard model. The first scheme is based on Boneh-Franklin IBE similar to the Ateniese et al. scheme, but ours achieves a more compact decryption key and ciphertext and stronger CCA-privacy, CMA-authenticity, and mismatch security. The second scheme is an improved generic construction, which active not only stronger security but also the shortest ciphertext among existing generic constructions.  Through this construction, we obtain, for example, a more efficient scheme from the symmetric external Diffie-Hellman assumption in the standard model, and a practical scheme from lattices in the quantum random oracle model.
]]></content:encoded>
<pubDate>Thu, 21 Sep 2023 10:42:32 +0000</pubDate>
</item>
<item>
<title>Crypto Dark Matter on the Torus: Oblivious PRFs from shallow PRFs and FHE</title>
<link>https://eprint.iacr.org/2023/232</link>
<guid>https://eprint.iacr.org/2023/232</guid>
<content:encoded><![CDATA[
<div> 关键词：Partially Oblivious Pseudorandom Functions (POPRFs), Lattice Assumptions, Crypto Dark Matter PRF, Random Oracle Model, Torus Fully Homomorphic Encryption (TFHE).

总结:<br />
本文提出了一种新颖的基于 lattice 假设和 Crypto Dark Matter PRF 的 Partially Oblivious Pseudorandom Functions (POPRF) 构造，该方案利用了 TFHE 中的混合模计算和可编程提升。它提供了恶意客户端安全性和客户端隐私保护，分别基于电路私有 FHE 和 FHE 方案的语义安全性。此外，作者探索了通过低深度计算欺骗电路的难度来实现可验证性的方法，从而得到可验证的 (P)OPRF。文章提供了原型实现和初步性能指标，核心在线 OPRF 功能的通信成本为每次评估10.0KB，客户端一次性设置通信为2.5MB。 <div>
Partially Oblivious Pseudorandom Functions (POPRFs) are 2-party protocols that allow a client to learn pseudorandom function (PRF) evaluations on inputs of its choice from a server. The client submits two inputs, one public and one private. The security properties ensure that the server cannot learn the private input, and the client cannot learn more than one evaluation per POPRF query. POPRFs have many applications including password-based key exchange and privacy-preserving authentication mechanisms. However, most constructions are based on classical assumptions, and those with post quantum security suffer from large eﬀiciency drawbacks.

In this work, we construct a novel POPRF from lattice assumptions and the “Crypto Dark Matter” PRF candidate (TCC’18) in the random oracle model. At a conceptual level, our scheme exploits the alignment of this family of PRF candidates, relying on mixed modulus computations, and programmable bootstrapping in the torus fully homomorphic encryption scheme (TFHE). We show that our construction achieves malicious client security based on circuit-private FHE, and client privacy from the semantic security of the FHE scheme. We further explore a heuristic approach to extend our scheme to support verifiability, based on the difficulty of computing cheating circuits in low depth. This would yield a verifiable (P)OPRF. We provide a proof-of-concept implementation and preliminary benchmarks of our construction. For the core online OPRF functionality, we require amortised 10.0KB communication per evaluation and a one-time per-client setup communication of 2.5MB.
]]></content:encoded>
<pubDate>Mon, 20 Feb 2023 17:31:18 +0000</pubDate>
</item>
<item>
<title>Round Efficient Byzantine Agreement from VDFs</title>
<link>https://eprint.iacr.org/2022/823</link>
<guid>https://eprint.iacr.org/2022/823</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine agreement, Resource-based model, Verifiable Delay Function (VDF), Adaptive corruption, Communication complexity.

总结:
 Byzantine协议在分布式系统中至关重要，尤其在区块链中。本文关注资源受限模型，其中参与者使用如计算（VDF）或金钱作为资源。首先，我们实现了期望常数轮次的BA协议，支持适应性攻击、诚实多数且无需公钥基础设施，这是先前工作的突破。其次，给出了首个限制计算资源模型下BA通信复杂性的下限，证明即使有VDF访问，多播复杂度至少为$\sqrt{n}$。这些结果揭示了在资源受限环境下BA协议设计的复杂性和挑战。 <div>
Byzantine agreement (BA) is a fundamental primitive in distributed systems and has received huge interest as an important building block for blockchain systems. Classical byzantine agreement considers a setting where $n$ parties with fixed, known identities want to agree on an output in the presence of an adversary. Motivated by blockchain systems, the assumption of fixed identities is weakened by using a \emph{resource-based model}. In such models, parties do not have fixed known identities but instead have to invest some expensive resources to participate in the protocol. Prominent examples for such resources are computation (measured by, e.g., proofs-of-work) or money (measured by proofs-of-stake). Unlike in the classical setting where BA without trusted setup (e.g., a PKI or an unpredictable beacon) is impossible for $t \geq n/3$ corruptions, in such resource-based models, BA can be constructed for the optimal threshold of $t <n/2$. In this work, we investigate BA without a PKI in the model where parties have restricted computational resources. Concretely, we consider sequential computation modeled via computing a verifiable delay function (VDF) and establish the following results:

Positive Result: We present the first protocol for BA with expected constant round complexity and termination under adaptive corruption, honest majority and without a PKI. Earlier work achieved round complexity $O(n\kappa^2)$ (CRYPTO'15) or $O(\kappa)$ (PKC'18), where $\kappa$ is the security parameter.

Negative Result: We give the first lower bound on the communication complexity of BA in a model where parties have restricted computational resources. Concretely, we show that a multicast complexity of $O(\sqrt{n})$ is necessary even if the parties have access to a VDF oracle.
]]></content:encoded>
<pubDate>Thu, 23 Jun 2022 09:58:37 +0000</pubDate>
</item>
<item>
<title>Optimized Privacy-Preserving Clustering with Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1141</link>
<guid>https://eprint.iacr.org/2024/1141</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), k-means clustering, one-hot vector, minimum evaluation, bootstrapping

总结:<br />
文章提出了一种新的基于FHE的k-means聚类方法，旨在克服现有FHE聚类方案的高计算开销问题。该方法通过利用FHE的单指令多数据(SIMD)特性，设计了一个高效的加密环境下最小值评估算法，结合FHE的bootstrap技术，实现了单轮交互的FHE k-means，能够在一次迭代中完成整个加密数据聚类过程。实验表明，新方法在多种公开数据集上性能优于现有方案，且保持与明文结果相当的准确性。此外，还扩展了协议以支持大规模数据的mini-batch k-means，展示了其在大型数据集上的性能。 <div>
Clustering is a crucial unsupervised learning method extensively used in the field of data analysis. For analyzing big data, outsourced computation is an effective solution but privacy concerns arise when involving sensitive information. Fully homomorphic encryption (FHE) enables computations on encrypted data, making it ideal for such scenarios. However, existing privacy-preserving clustering based on FHE are often constrained by the high computational overhead incurred from FHE, typically requiring decryption and interactions after only one iteration of the clustering algorithm. In this work, we propose a more efficient approach to evaluate the one-hot vector for the index of the minimum in an array with FHE, which fully exploits the parallelism of single-instruction-multiple-data of FHE schemes. By combining this with FHE bootstrapping, we present a practical FHE-based k-means clustering protocol whose required round of interactions between the data owner and the server is optimal, i.e., accomplishing the entire clustering process on encrypted data in a single round. We implement this protocol using the CKKS FHE scheme. Experiments show that our protocol significantly outperforms the state-of-the-art FHE-based k-means clustering protocols on various public datasets and achieves comparable accuracy to plaintext result. Additionally, We adapt our protocol to support mini-batch k-means for large-scale datasets and report its performance.
]]></content:encoded>
<pubDate>Sat, 13 Jul 2024 11:18:13 +0000</pubDate>
</item>
<item>
<title>Anonymous Outsourced Statekeeping with Reduced Server Storage</title>
<link>https://eprint.iacr.org/2024/1139</link>
<guid>https://eprint.iacr.org/2024/1139</guid>
<content:encoded><![CDATA[
<div> 关键词：strike-lists、anonymous tickets functionality、secure protocol、server storage、anonymous outsourced state-keeping functionality

总结: <br />
这篇文章主要探讨了如何通过改进strike-lists技术来降低服务器存储需求。匿名门票功能(anonymous tickets functionality)旨在实现存储需求从$N \cdot t$降至$N \log(t)$，通过构建基于标准假设的加密协议，每个客户端的存储需求仅为$O(N)$个长度为$O(\log(t))$的消息的密文。此外，文章还扩展了strike-lists，考虑了匿名外包状态保持功能，防止恶意客户回滚状态，同时保护诚实客户的匿名性和机密性。关键在于提出了一种新方法，对抗服务器的有针对性攻击，确保恶意行为不会阻止诚实用户兑换票证或提供逃逸机制，使得服务器无法区分真实操作。 <div>
Strike-lists are a common technique for rollback and replay prevention in protocols that require that clients remain anonymous or that their current position in a state machine remain confidential. Strike-lists are heavily used in anonymous credentials, e-cash schemes, and trusted execution environments, and are widely deployed on the web in the form of Privacy Pass (PoPETS '18) and Google Private State Tokens.
In such protocols, clients submit pseudorandom tokens associated with each action (e.g.,  a page view in Privacy Pass) or state transition, and the token is added to a server-side list to prevent reuse. 

Unfortunately, the size of a strike-list, and hence the storage required by the server, is proportional to the total number of issued tokens, $N \cdot t$, where $N$ is the number of clients and $t$ is the maximum number of tickets per client. In this work, we ask whether it is possible to realize a strike-list-like functionality, which we call the anonymous tickets functionality, with storage requirements proportional to $N \log(t)$.

For the anonymous tickets functionality we construct a secure protocol from standard assumptions that achieves server storage of $O(N)$ ciphertexts, where each ciphertext encrypts a message of length $O(\log(t))$. We also consider an extension of the strike-list functionality where the server stores an arbitrary state for each client and clients advance their state with some function $s_i\gets f(s_{i-1},\mathsf{auxinput})$, which we call the anonymous outsourced state-keeping functionality. In this setting, malicious clients are prevented from rolling back their state, while honest clients are guaranteed anonymity and confidentiality against a malicious server. We achieve analogous results in this setting for two different classes of functions.

Our results rely on a new technique to preserve client anonymity in the face of selective failure attacks by a malicious server. Specifically, our protocol guarantees that misbehavior of the server either (1) does not prevent the honest client from redeeming a ticket or (2) provides the honest client with an escape hatch that can be used to simulate a redeem in a way that is indistinguishable to the server.
]]></content:encoded>
<pubDate>Fri, 12 Jul 2024 19:49:44 +0000</pubDate>
</item>
<item>
<title>Scalable and Lightweight State-Channel Audits</title>
<link>https://eprint.iacr.org/2024/1135</link>
<guid>https://eprint.iacr.org/2024/1135</guid>
<content:encoded><![CDATA[
<div> 关键词：Payment channels, Off-chain scaling, AML auditing, Provable audibility, Cryptographic operations

总结: <br />
本文主要关注区块链系统中支付渠道的监管问题。文章提出了一种创新方法，旨在为信任层2协议提供一种轻量级、可扩展且安全的审计解决方案，以满足反洗钱(AML)监管需求。该方案确保每个状态通道都能针对预定义的政策查询进行可验证审计，不会泄露额外信息，同时保持加密操作成本低、设置简单和存储复杂度与交易图无关。研究构建了一个基于Hydra Isomorphic State Channels (FC'21)的实际协议，将状态通道关联到真实世界的标识符，包括去中心化标识符和可验证的法律实体标识(vLEI)，这在金融服务业和监管机构中越来越受欢迎。这一工作有助于提升对离链支付通道的透明度和可控性。 <div>
Payment channels are one of the most prominent off-chain scaling solutions for blockchain systems. However, regulatory institutions have difficulty embracing them, as the channels lack insights needed for Anti-Money Laundering (AML) auditing purposes. Our work tackles the problem of a formal reliable and controllable inspection of off-ledger payment channels, by offering a novel approach for maintaining and reliably auditing statistics of payment channels. We extend a typical trustless Layer 2 protocol and provide a lightweight and scalable protocol such that:
        - every state channel is provably auditable w.r.t. a configurable set of policy queries, such that a regulator can retrieve reliable insights about the channel;
        - no information beyond the answers to auditing queries is leaked;
        - the cryptographic operations are inexpensive, the setup is simple, and storage complexity is independent of the transaction graph's size.
    We present a concrete protocol, based on Hydra Isomorphic State Channels (FC'21), and tie the creation of a state channel to real-world identifiers, both in a plain and privacy-preserving manner. For this, we employ verifiable credentials for decentralized identifiers, specifically verifiable Legal Entity Identifiers (vLEI) that increasingly gain traction for financial service providers and regulated institutions.
]]></content:encoded>
<pubDate>Fri, 12 Jul 2024 14:00:38 +0000</pubDate>
</item>
<item>
<title>A New PPML Paradigm for Quantized Models</title>
<link>https://eprint.iacr.org/2024/1132</link>
<guid>https://eprint.iacr.org/2024/1132</guid>
<content:encoded><![CDATA[
<div> 关键词：quantization, privacy-preserving machine learning (PPML), lookup tables, quantized operators, online performance

总结:
这篇文章主要探讨了如何在隐私保护机器学习(PPML)中有效利用量化模型。作者提出了一种新的PPML方法，特别针对量化模型设计，通过简化量化操作中的复杂内部结构，将模型推理视为一系列由查找表实现的量化运算。他们开发了一种高效的私有查找表评估协议，具有极低的在线通信成本，仅需$\log n$，其中$n$为查找表的大小。在单个CPU核心上，该协议能快速处理大量表格。基于此框架，量化模型的PPML实现了显著的速度提升，对于CNN（如AlexNet、VGG16和ResNet18）和大型语言模型（如GPT-2、GPT-Neo和Llama2）的在线性能分别提高了40-60倍和10-25倍。 <div>
Model quantization has become a common practice in machine learning (ML) to improve efficiency and reduce computational/communicational overhead. However, adopting quantization in privacy-preserving machine learning (PPML) remains challenging due to the complex internal structure of quantized operators, which leads to inefficient protocols under the existing PPML frameworks. 

In this work, we propose a new PPML paradigm that is tailor-made for and can benefit from quantized models. Our main observation is that lookup tables can ignore the complex internal constructs of any functions which can be used to simplify the quantized operator evaluation. We view the model inference process as a sequence of quantized operators, and each operator is implemented by a lookup table. We then develop an efficient private lookup table evaluation protocol, and its online communication cost is only $\log n$, where $n$ is the size of the lookup table.  
On a single CPU core, our protocol can evaluate $2^{15}$ tables with 8-bit input and 8-bit output per second.

The resulting PPML framework for quantized models offers extremely fast online performance.
 The experimental results demonstrate that our quantization strategy achieves substantial speedups over SOTA PPML solutions, improving the online performance by $40\sim 60 \times$ w.r.t. convolutional neural network (CNN) models, such as AlexNet, VGG16, and ResNet18, and by $10\sim 25 \times$ w.r.t. large language models (LLMs), such as GPT-2, GPT-Neo, and Llama2.
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 12:42:53 +0000</pubDate>
</item>
<item>
<title>KAIME : Central Bank Digital Currency with Realistic and Modular Privacy</title>
<link>https://eprint.iacr.org/2023/713</link>
<guid>https://eprint.iacr.org/2023/713</guid>
<content:encoded><![CDATA[
<div> 关键词：Central Bank Digital Currency (CBDC), Privacy Conflict, Banks, Financial Institutions, User.

总结:
这篇文章主要探讨了中央银行数字货币（CBDC）的发展趋势，尤其是关注其对传统货币的改进以及面临的隐私挑战。研究者指出，尽管许多研究关注用户与监管机构之间的隐私权平衡，但忽视了银行和金融机构与用户之间的隐私问题。KAIME作为一种解决方案，旨在解决这一矛盾，同时保护用户的隐私。KAIME采用模块化设计，允许发送者和接收者的隐私得以隐藏，且其安全性基于简单且成熟的加密方法，这使得其在实施上比类似研究更为简便。因此，KAIME为CBDC系统中的隐私保护提供了一个全面的视角。 <div>
Recently, with the increasing interest in Central Bank Digital Currency (CBDC), many countries have been working on researching and developing digital currency. The most important reasons for this interest are that CBDC eliminates the disadvantages of traditional currencies and provides a safer, faster, and more efficient payment system. These benefits also come with challenges, such as safeguarding individuals’ privacy and ensuring regulatory mechanisms. While most researches address the privacy conflict between users and regulatory agencies, they miss an important detail. Important parts of a financial system are banks and financial institutions. Some studies ignore the need for privacy and include these institutions in the CBDC system, no system currently offers a solution to the privacy conflict between banks, financial institutions, and users. In this study, while we offer a solution to the privacy conflict between the user and the regulatory agencies, we also provide a solution to the privacy conflict between the user and the banks. Our solution, KAIME  has also a modular structure. The privacy of the sender and receiver can be hidden if desired. Compared to previous related research, security analysis and implementation of KAIME is substantially simpler because simple and well-known cryptographic methods are used.
]]></content:encoded>
<pubDate>Wed, 17 May 2023 19:36:59 +0000</pubDate>
</item>
<item>
<title>Distributed Verifiable Random Function With Compact Proof</title>
<link>https://eprint.iacr.org/2024/1130</link>
<guid>https://eprint.iacr.org/2024/1130</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Random Functions (VRFs), Distributed VRFs (DVRFs), DVRFwCP, constant-size proofs, efficient verification.

总结:<br />
本文提出了一种新型的分布式可验证随机函数系统(DVRFwCP)，它在解决现有DVRFs的问题上取得了显著进步。DVRFwCP的特点在于其拥有常数大小的证明，这意味着证明的大小不会随着参与者数量增加而变化，这相较于早期系统是一个重大改进。此外，DVRFwCP通过移除对计算密集型的双线性配对的需求，实现了更高效的验证过程。与DDH-DVRF和GLOW-DVRF等知名实现相比，DVRFwCP在安全性与可扩展性方面具有明显优势，尤其是在估计的燃气成本上。这一创新为去中心化环境中生成可验证随机数提供了更为可靠和高效的解决方案。 <div>
Verifiable Random Functions (VRFs) are cryptographic primitives that generate unpredictable randomness along with proofs that are verifiable, a critical requirement for blockchain applications in decentralized finance, online gaming, and more. Existing VRF constructions often rely on centralized entities, creating security vulnerabilities. Distributed VRFs (DVRFs) offer a decentralized alternative but face challenges like large proof sizes or dependence on computationally expensive bilinear pairings. 
In this research, a unique distributed VRF (DVRF) system called DVRFwCP with considerable improvements is proposed. DVRFwCP has constant-size proofs, which means that the size of the proof does not change based on the number of participants. This overcomes a significant drawback of earlier DVRF systems, which saw proof size increase with participant count. Furthermore, DVRFwCP produces more efficient verification than previous systems by eliminating the requirement for bilinear pairings throughout the verification process. These innovations contribute to a more secure and scalable solution for generating verifiable randomness in decentralized environments.
We compare our construction to well-established DVRF instantiations such as DDH-DVRF and GLOW-DVRF while also pointing out the major improvement in the estimated gas cost of these algorithms.
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 13:33:43 +0000</pubDate>
</item>
<item>
<title>Cryptiny: Compacting Cryptography for Space-Restricted Channels and its Use-case for IoT-E2EE</title>
<link>https://eprint.iacr.org/2024/1128</link>
<guid>https://eprint.iacr.org/2024/1128</guid>
<content:encoded><![CDATA[
<div> 关键词：cryptiny、IoT、security goals、CCA-secrecy、SDHIES

总结:<br />
Cryptiny是一种新型加密范式，它使用单一加密值实现多重安全目标，适用于带宽受限的物联网环境。文章以BLE广播信标与远程配对的主人之间的实时通信为例，该场景中，信标通过BLE-IP网关设备和云服务器发送信息。要求保障高安全性和隐私性，如双向安全和观察者的前向后向安全性。为了实现这些，文章提出了一种名为SDHIES的新加密方案，其特点是使用公钥的函数进行加密，而非直接使用公钥。通过cryptiny，作者证明了协议能提供信标和观察者消息的CCA保密性，以及观察者的双向安全和双方的互私性。 <div>
We present a novel cryptographic paradigm denoted  ``cryptiny:'' Employing a single cryptographic value for several security goals, thus ``compacting'' the communication sent over a space-restricted (narrow) channel, while still proving security. Cryptiny is contrary to the classical cryptographic convention of using a separate cryptographic element for each security goal. 

Demonstrating  the importance of cryptiny, we employ it for securing a critical IoT configuration in which a broadcasting ``thing'' (called beacon) operates within stringent bandwidth constraints. In this setting, a compact BLE-broadcasting beacon lacking Internet connectivity efficiently directs brief (non fragmented) messages to its remotely pre-paired owner in real-time. Communication transpires through BLE-to-IP gateway devices denoted observers, (typically smartphones in the beacon's vicinity), and subsequently via a cloud app server. The gateway device as well, piggybacks on the transmission a secure and private message to the owner. This configuration is a generic setting for the current and future IoT real-time ecosystems, where billion of owners, beacons, and observers operate. 

The configuration instances (analogous to TLS instances over the Internet) imposes high security and privacy demands. We prove that our cryptiny-based protocol for securing the above configuration achieves CCA-secrecy for the beacon's and the observer's messages with backward and forward security for the observer's message, as well simultaneously achieving  mutual privacy for beacons and for observers. Achieving backward and forward security is important since beacon devices may be far from their owners for a long duration and may be passively tampered with. In addition, for the backward security proof we develop a new encryption scheme we call ``shifted-DHIES'' (``SDHIES'' for short), which generalizes DHIES. An interesting feature of SDHIES is that encryption is performed with a function of the public key rather than the public key itself.
]]></content:encoded>
<pubDate>Thu, 11 Jul 2024 10:02:44 +0000</pubDate>
</item>
<item>
<title>Curl: Private LLMs through Wavelet-Encoded Look-Up Tables</title>
<link>https://eprint.iacr.org/2024/1127</link>
<guid>https://eprint.iacr.org/2024/1127</guid>
<content:encoded><![CDATA[
<div> 关键词：transformers, secure multiparty computation (MPC), CrypTen, non-linear functions, discrete wavelet transformations

总结:
Curl是一个新的安全多方计算（MPC）框架，专注于提升非线性函数的处理效率。它通过使用离散小波变换来减小查找表大小，从而减少 rounds 和通信量，相比于CrypTen有高达19倍的改进。Curl提供了类似于CrypTen的编程模型和并行化能力，适用于大型语言模型（LLMs），如BERT、GPT-2和GPT Neo。此外，文章还解决了关于常用概率截断协议安全性的争议，证明其在独立模型中的安全性，这对依赖这类技术的其他研究具有重要意义。总的来说，Curl通过优化和增强MPC在处理复杂机器学习任务中的隐私保护性能，推动了该领域的进步。 <div>
Recent advancements in transformers have revolutionized machine learning, forming the core of Large language models (LLMs). However, integrating these systems into everyday applications raises privacy concerns as client queries are exposed to model owners. Secure multiparty computation (MPC) allows parties to evaluate machine learning applications while keeping sensitive user inputs and proprietary models private. Due to inherent MPC costs, recent works introduce model-specific optimizations that hinder widespread adoption by machine learning researchers. CrypTen (NeurIPS'21) aimed to solve this problem by exposing MPC primitives via common machine learning abstractions such as tensors and modular neural networks. Unfortunately, CrypTen and many other MPC frameworks rely on polynomial approximations of the non-linear functions, resulting in high errors and communication complexity.

This paper introduces Curl, an easy-to-use MPC framework that evaluates non-linear functions as lookup tables, resulting in better approximations and significant round and communication reduction. Curl exposes a similar programming model as CrypTen and is highly parallelizable through tensors. At its core, Curl relies on discrete wavelet transformations to reduce the lookup table size without sacrificing accuracy, which results in up to $19\times$ round and communication reduction compared to CrypTen for non-linear functions such as logarithms and reciprocals. We evaluate Curl on a diverse set of LLMs, including BERT, GPT-2, and GPT Neo, and compare against state-of-the-art related works such as Iron (NeurIPS'22) and Bolt (S&amp;P'24) achieving at least $1.9\times$ less communication and latency.

Finally, we resolve a long-standing debate regarding the security of widely used probabilistic truncation protocols by proving their security in the stand-alone model. This is of independent interest as many related works rely on this truncation style.
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 22:22:00 +0000</pubDate>
</item>
<item>
<title>OPPID: Single Sign-On with Oblivious Pairwise Pseudonyms</title>
<link>https://eprint.iacr.org/2024/1124</link>
<guid>https://eprint.iacr.org/2024/1124</guid>
<content:encoded><![CDATA[
<div> 关键词：Single Sign-On (SSO), Pseudonym, Identity Provider (IdP), Relying Parties (RPs), Security.

总结:<br />文章探讨了现有的单点登录（SSO）系统中用户隐私问题，尤其是当IdP知道用户访问哪个RP时。为了解决这一问题，作者提出了一种新的、无观察、强安全且便利的SSO系统，允许IdP在不暴露RP身份的情况下生成对RP特定的伪匿名标识。该模型强调了RP的身份验证需求，即IdP需要验证令牌和伪匿名是否发给注册的RP。作者构建了一个结合签名、知识证明和盲但可验证的哈希版Diffie-Hellman PRF的方案，并证明其安全性。实验表明，该方案在运行时间上高效，每方耗时2-20ms。 <div>
Single Sign-On (SSO) allows users to conveniently authenticate to many Relying Parties (RPs) through a central Identity Provider (IdP). SSO supports unlinkable authentication towards the RPs via pairwise pseudonyms, where the IdP assigns the user an RP-specific pseudonym. This feature has been rolled out prominently within Apple's SSO service. While establishing unlinkable identities provides privacy towards RPs, it actually emphasizes the main privacy problem of SSO: with every authentication request, the IdP learns the RP that the user wants to access. Solutions to overcome this limitation exist, but either assume users to behave honestly or require them to manage long-term cryptographic keys.

In this work, we propose the first SSO system that can provide such pseudonymous authentication in an unobservable yet strongly secure and convenient manner. That is, the IdP blindly derives the user's pairwise pseudonym for the targeted RP without learning the RP's identity and without requiring key material handled by the user. We formally define the desired security and privacy properties for such unlinkable, unobservable, and strongly secure SSO. In particular, our model includes the often neglected RP authentication: the IdP typically wants to limit its services to registered RPs only and thus must be able to (blindly) verify that it issues the token and pseudonym to such a registered RP. We propose a simple construction that combines signatures with efficient proofs-of-knowledge with a blind, yet verifiable, evaluation of the Hashed-Diffie-Hellman PRF. We prove the security of our construction and demonstrate its efficiency through a prototypical implementation, which requires a running time of 2-20ms per involved party.
]]></content:encoded>
<pubDate>Wed, 10 Jul 2024 13:36:26 +0000</pubDate>
</item>
<item>
<title>PARScoin: A Privacy-preserving, Auditable, and Regulation-friendly Stablecoin</title>
<link>https://eprint.iacr.org/2023/1908</link>
<guid>https://eprint.iacr.org/2023/1908</guid>
<content:encoded><![CDATA[
<div> 关键词：Stablecoins, Privacy, Auditable, Regulation-friendly, Scalability

总结: <br />
PARScoin是一种新型的隐私保护、可审计和符合监管要求的稳定币设计，旨在解决传统稳定币在隐私、费用和可扩展性方面的问题。它通过智能合约实现，具有高性能和可扩展性，适用于大规模用户场景。PARScoin的设计是区块链无关的，采用通用组合(UC)框架进行分析，为无缝融入现有区块链生态系统提供了一种安全且模块化的方法。这种创新设计旨在提升稳定币的使用体验和信任度，同时保持高效运作。 <div>
Stablecoins are digital assets designed to maintain a consistent value relative to a reference point, serving as a vital component in Blockchain, and Decentralized Finance (DeFi) ecosystem. Typical implementations of stablecoins via smart contracts come with important downsides such as a questionable level of privacy, potentially high fees, and lack of scalability. We put forth a new design, PARScoin, for a Privacy-preserving, Auditable, and Regulation-friendly Stablecoin that mitigates these issues while enabling high performance both in terms of speed of settlement and for scaling to large numbers of users as our performance analysis demonstrates. Our construction is blockchain-agnostic and is analyzed in the Universal Composition (UC) framework, offering a secure and modular approach for its integration into the broader blockchain ecosystem.
]]></content:encoded>
<pubDate>Tue, 12 Dec 2023 15:40:09 +0000</pubDate>
</item>
<item>
<title>DiLizium 2.0: Revisiting Two-Party Crystals-Dilithium</title>
<link>https://eprint.iacr.org/2022/644</link>
<guid>https://eprint.iacr.org/2022/644</guid>
<content:encoded><![CDATA[
<div> 关键词：threshold signature, Dilithium, Module-LWE, Module-SIS, two-party protocol

总结:<br />
本文提出了一种新的两党 Dilithium 签名方案变体，专注于用户身份验证。该设计基于 Dilithium 签名的压缩技术，沿用了 Damgård 等人（PKC 2021）中使用的加法同态承诺方案，但更接近 NIST PQC 竞赛提交的版本。新方案的安全性建立在模块化 LWE 和 SIS 问题的困难性之上，展示了对现有量子攻击防御的考虑。 <div>
In previous years there has been an increased interest in designing threshold signature schemes. Most of the recent works focus on constructing threshold versions of ECDSA or Schnorr signature schemes due to their appealing usage in blockchain technologies. Additionally, a lot of research is being done on cryptographic schemes that are resistant to quantum computer attacks.
In this work, we propose a new version of the two-party Dilithium signature scheme. The security of our scheme is based on the hardness of Module-LWE and Module-SIS problems. In our construction, we follow a similar logic as Damgård et al. (PKC 2021) and use an additively homomorphic commitment scheme. However, compared to them, our protocol uses signature compression techniques from the original Dilithium signature scheme which makes it closer to the version submitted to the NIST PQC competition. We focus on two-party signature schemes in the context of user authentication.
]]></content:encoded>
<pubDate>Wed, 25 May 2022 08:36:33 +0000</pubDate>
</item>
<item>
<title>DeCAF: Decentralizable Continuous Group Key Agreement with Fast Healing</title>
<link>https://eprint.iacr.org/2022/559</link>
<guid>https://eprint.iacr.org/2022/559</guid>
<content:encoded><![CDATA[
<div> 关键词：Continuous Group Key Agreement (CGKA), TreeKEM, Concurrent CGKA, CoCoA, DeCAF.

总结:
本文主要关注连续群密钥协议（Continuous Group Key Agreement, CGKA）的并发解决方案。文章提到现有的TreeKEM（RFC 9420）在处理并发请求时存在局限，而CoCoA虽然并发且通信复杂度低，但用户更新可能需要多次请求。为解决这些问题，作者提出了DeCAF（Decentralized Concurrency-Aware Fast Healing），一种适用于中心服务器和去中心化设置的高效协议。

DeCAF特别适合去中心化的组消息系统，如区块链环境，它能在最多$\log(t)$轮请求内修复被攻击情况，相比CoCoA的$\log(n)$轮更快速。尽管在中心服务器场景中，CoCoA在下载通信方面更优，但在去中心化情况下，DeCAF在修复速度和每轮用户通信成本上具有显著优势。 <div>
Continuous group key agreement (CGKA) allows a group of users to maintain a continuously updated shared key in an asynchronous setting where parties only come online sporadically and their messages are relayed by an untrusted server. CGKA captures the basic primitive underlying group messaging schemes.

Current solutions including TreeKEM ("Messaging Layer Security'' (MLS) IETF RFC 9420) cannot handle concurrent requests while retaining low communication complexity. The exception being CoCoA, which is concurrent while having extremely low communication complexity (in groups of size $n$ and for $m$ concurrent updates the communication per user is $\log(n)$, i.e., independent of $m$). The main downside of CoCoA is that in groups of size $n$, users might have to do up to $\log(n)$ update requests to the server to ensure their (potentially corrupted) key material has been refreshed.

In this work we present a "fast healing'' concurrent CGKA protocol, named DeCAF, where users will heal after at most $\log(t)$ requests, with $t$ being the number of corrupted users. While also suitable for the standard central-server setting, our protocol is particularly interesting for realizing decentralized group messaging, where protocol messages (add, remove, update) are being posted on some append-only data structure rather than sent to a server. In this setting, concurrency is crucial once the rate of requests exceeds, say, the rate at which new blocks are added to a blockchain.

In the central-server setting, CoCoA (the only alternative with  concurrency, sub-linear communication and basic post-compromise security)  enjoys much lower download communication. However, in the decentralized setting - where there is no server which can craft specific messages for different users to reduce their download communication - our protocol  significantly outperforms CoCoA. DeCAF heals in fewer rounds ($\log(t)$ vs. $\log(n)$) while incurring a similar per round per user communication cost.
]]></content:encoded>
<pubDate>Tue, 10 May 2022 08:20:37 +0000</pubDate>
</item>
<item>
<title>Shared-Custodial Password-Authenticated Deterministic Wallets</title>
<link>https://eprint.iacr.org/2024/1118</link>
<guid>https://eprint.iacr.org/2024/1118</guid>
<content:encoded><![CDATA[
<div> 关键词：password-authenticated, deterministic wallets (PADW), shared-custodial wallets, privacy, security

总结: <br />
密码验证确定性钱包(PADW)是一种创新的共享托管钱包解决方案，它在用户和服务器之间共享用户的秘密密钥，提供强大的安全和隐私保障。用户通过密码验证后与服务器进行交互式签名协议。PADW的安全性基于至少一方被攻击的前提下，保证交易安全。隐私方面，即使服务器被攻破，也无法将交易与特定用户关联。我们给出了一个盲Schnorr签名的实现，支持确定性密钥生成，且不依赖复杂加密技术。该方案在随机Oracle模型下对适应性攻击证明了安全性，仅依赖Schnorr签名不可伪造性和公钥加密的CCA安全。 <div>
Cryptographic wallets are an essential tool in Blockchain networks to ensure the secure storage and maintenance of an user's cryptographic keys. Broadly, wallets can be divided into three categories, namely custodial, non-custodial, and shared-custodial wallets. The first two are centralized solutions, i.e., the wallet is operated by a single entity, which inherently introduces a single point of failure. Shared-custodial wallets, on the other hand, are maintained by two independent parties, e.g., the wallet user and a service provider, and hence avoid the single point of failure centralized solutions. Unfortunately, current shared-custodial wallets suffer from significant privacy issues.

In our work, we introduce password-authenticated deterministic wallets (PADW), a novel and efficient shared-custodial wallet solution, which exhibits strong security and privacy guarantees. In a nutshell, in a PADW scheme, the secret key of the user is shared between the user and the server. In order to generate a signature, the user first authenticates itself to the server by providing a password and afterwards engages in an interactive signing protocol with the server. Security is guaranteed as long as at most one of the two parties is corrupted. Privacy, on the other hand, guarantees that a corrupted server cannot link a transaction to a particular user. We formally model the notion of PADW schemes and we give an instantiation from blind Schnorr signatures. Our construction allows for deterministic key derivation, a feature that is widely used in practice by existing wallet schemes, and it does not rely on any heavy cryptographic primitives. We prove our scheme secure against adaptive adversaries in the random oracle model and under standard assumptions. That is, our security proof only relies on the assumption that the Schnorr signature scheme is unforgeable and that a public key encryption scheme is CCA-secure.
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 12:51:45 +0000</pubDate>
</item>
<item>
<title>Public vs Private Blockchains lineage storage</title>
<link>https://eprint.iacr.org/2024/1115</link>
<guid>https://eprint.iacr.org/2024/1115</guid>
<content:encoded><![CDATA[
<div> 关键词：实验结果、智能合约、区块链、存储成本、时间与gas成本。

总结:
这篇文章主要探讨了通过部署在私有和公共区块链上的智能合约来存储线性事件的实验。研究关注了三个关键指标：部署智能合约的成本（初期的以太坊“gas”单位），存储单个或多个客户端事件的时间和gas费用。实验涵盖了多种公共区块链，如Hedera、Fantom、Harmony Shard0等，以及Polygon Amoy、Ethereum Sepolia、Optimism Sepolia、Klaytn Baobab和Arbitrum Sepolia。同时，文章还分析了Hyperledger Besu使用不同共识算法作为私有链的性能。这些发现有助于评估不同区块链平台在存储效率和成本方面的优劣。 <div>
This paper reports the experimental results related to lineage event storage via smart contracts deployed on private and public blockchain. In our experiments we measure the following three metrics: the cost to deploy the storage smart contract on the blockchain, which measures the initial expenditure, typically in gas units, required to deploy the smart contract that facilitates lineage event storage, then the time and gas costs needed to store a lineage event. We investigated both single and multi-clients scenarios. We considered the following public blockchains: Hedera, Fantom, Harmony Shard0, Polygon Amoy, Ethereum Sepolia, Optimism Sepolia, Klaytn Baobab and Arbitrum Sepolia. Furthermore, we investigate the performances of Hyperledger Besu with different consensus algorithms as private blockchains.
]]></content:encoded>
<pubDate>Tue, 09 Jul 2024 07:59:46 +0000</pubDate>
</item>
<item>
<title>QuickPool: Privacy-Preserving Ride-Sharing Service</title>
<link>https://eprint.iacr.org/2024/1109</link>
<guid>https://eprint.iacr.org/2024/1109</guid>
<content:encoded><![CDATA[
<div> 关键词：Online ride-sharing services, Privacy concerns, Oblivious matching, Secure multi-party computation, Performance.

总结:<br />本文提出了一种名为QuickPool的在线拼车服务解决方案，以解决环境和交通问题，同时保护用户隐私。QuickPool允许乘客和司机通过加密的方式向服务提供商（SP）提交行程信息，仅涉及部分路线重叠和起点终点位置的区城性模糊匹配，无需第三方服务器。该方案在半诚实设置下使用安全多方计算技术，提供了协议安全证明并进行了性能测试，与现有工作的比较显示了1.6-2倍的速度提升。QuickPool有效地提高了拼车服务的效率和用户隐私保护。 <div>
Online ride-sharing services (RSS) have become very popular owing to increased awareness of environmental concerns and as a response to increased traffic congestion. To request a ride, users submit their locations and route information for ride matching to a service provider (SP), leading to possible privacy concerns caused by leakage of users' location data. We propose QuickPool, an efficient SP-aided RSS solution that can obliviously match multiple riders and drivers simultaneously, without involving any other auxiliary server. End-users, namely, riders and drivers share their route information with SP as encryptions of the ordered set of points-of-interest (PoI) of their route from their start to end locations. SP performs a zone based oblivious matching of drivers and riders, based on partial route overlap as well as proximity of start and end points. QuickPool is in the semi-honest setting, and makes use of secure multi-party computation. We provide security proof of our protocol, perform extensive testing of our implementation and show that our protocol simultaneously matches multiple drivers and riders very efficiently. We compare the performance of QuickPool with state-of-the-art works and observe a speed up of 1.6 - 2$\times$.
]]></content:encoded>
<pubDate>Mon, 08 Jul 2024 10:27:56 +0000</pubDate>
</item>
<item>
<title>Information-Theoretic 2-Party Computation from Additive Somewhat Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/273</link>
<guid>https://eprint.iacr.org/2024/273</guid>
<content:encoded><![CDATA[
<div> 关键词：secret key, additive somewhat homomorphic, perfect privacy, server inputs, malicious model.

总结: <br />该研究关注的是秘密关键的加法稍微同态方案，其中客户端拥有完美隐私，即使服务器是计算无界的。文章介绍了一种处理电路乘法的方法，通过将乘法运算交给客户端执行并加密返回结果。另一个特点是2-party协议可以处理包含服务器输入的情况，但服务器隐私依赖于子集和问题的难度，而非信息理论。此外，协议设计允许通过为较小子电路使用独立的加密参数来扩展2PC，保持密文大小在电路增大时不变。在恶意模型中，服务器的正确性可以通过第三方高概率验证，同时保护客户端和服务器的隐私不被验证者获取。 <div>
Two-party computation has been an active area of research since Yao's breakthrough results on garbled circuits. We present secret key additive somewhat homomorphic schemes where the client has perfect privacy (server can be computationally unbounded). Our basic scheme is additive somewhat homomorphic and we give protocols to handle addition and multiplication. In one scheme, the server handles circuit multiplication gates by returning the multiplicands to the client which does the multiplication and sends back the encrypted product. We give a 2-party protocol that 
also incorporates server inputs where the client has perfect privacy. Server privacy is not information-theoretic, but rather depends on hardness of the subset sum problem.
Correctness for the server in the malicious model can be verified by a 3rd party with high probability where the client and server privacy are information-theoretically protected from the verifier. Scaling the 2PC protocol via separate encryption parameters for smaller subcircuits allows the ciphertext size to remain constant as circuit size grows.
]]></content:encoded>
<pubDate>Sun, 18 Feb 2024 23:20:46 +0000</pubDate>
</item>
<item>
<title>Fast, Large Scale Dimensionality Reduction Schemes Based on CKKS</title>
<link>https://eprint.iacr.org/2024/849</link>
<guid>https://eprint.iacr.org/2024/849</guid>
<content:encoded><![CDATA[
<div> 关键词：Artificial Intelligence, Big Data, High-Dimensional Data, Homomorphic Encryption, Dimensionality Reduction.

总结:<br />
这篇文章关注的是在人工智能和大数据时代，如何处理高维度数据的安全存储和高效分析。为了解决这一问题，研究者提出了一种基于CKKS的新型同态加密降维方案（HE-DR）。HE-DR通过修改Rank-Revealing方法使其适应全同态加密，实现了无需传输原始用户数据的加密数据降维，显著提高了安全性和效率。相比于传统方法，HE-DR在计算效率上提升约60-200倍，通信开销减小至1/3。实验显示，即使处理高维度数据，HE-DR的性能依然稳定，计算效率与数据维度的关系趋于平缓，而计算误差保持在极低水平。总的来说，该方案为多方参与的高维数据保护和分析提供了一个有效的解决方案。 <div>
The proliferation of artificial intelligence and big data has resulted in a surge in data demand and increased data dimensionality. This escalation has consequently heightened the costs associated with storage and processing. Concurrently, the confidential nature of data collected by various institutions, which cannot be disclosed due to personal privacy concerns, has exacerbated the challenges associated with data analysis and machine learning model training. Therefore, designing a secure and efficient high-dimensional data reduction method that supports multi-party joint participation becomes critical to solving these problems.

This paper proposes a novel homomorphic encryption dimensionality reduction scheme (HE-DR) based on CKKS, which modifies the Rank-Revealing (RR) method to make it more applicable to fully homomorphic encryption, thereby achieving fast and secure dimension reduction for high-dimensional data. Compared to traditional homomorphic encryption dimensionality reduction schemes, our approach does not transmit the user’s original data to other participants in any format (Ciphertext or Plaintext). Moreover, our method's computational efficiency is nearly $60-200$ times faster than similar algorithms, and the communication overhead is only $1/3$ of theirs. Finally, we have shown that our proposed scheme can preserve its computational efficiency and accuracy even when dealing with high-dimensional data. As dimensionality escalates, the ratio of ciphertext to plaintext computational efficiency plateaus at approximately 5 times, while the computational error (distance between subspaces) remains around $1e^{-11}$
]]></content:encoded>
<pubDate>Thu, 30 May 2024 07:24:18 +0000</pubDate>
</item>
<item>
<title>On Efficient and Secure Compression Modes for Arithmetization-Oriented Hashing</title>
<link>https://eprint.iacr.org/2024/047</link>
<guid>https://eprint.iacr.org/2024/047</guid>
<content:encoded><![CDATA[
<div> 关键词：ZK-SNARKs, Merkle树, Arithmetization-Oriented, PGV模式, Hades blockcipher

总结:<br />
本文探讨了基于AO（Arithmetization-Oriented）的ZK-SNARKs中，使用PGV模式构建高效的FIL（固定输入长度）压缩函数的方法。作者提出了PGV-LC和PGV-ELC两种模式，继承并扩展了经典的Preneel-Govaerts-Vandewalle（PGV）框架，保证了在理想密码模型下的碰撞和预映射抵抗，以及对Merkle树的开放抵抗。通过与流行的Poseidon和其改进版Poseidon2比较，新设计在性能上有所提升，特别是在Groth16 SNARK框架中更快。此外，文章还研究了使用高阶Merkle树的优势，优化了Hades blockcipher与PGV-ELC的组合，显著减少了Merkle树构造和证明生成时间。 <div>
ZK-SNARKs, a fundamental component of privacy-oriented payment systems, identity protocols, or anonymous voting systems, are advanced cryptographic protocols for verifiable computation: modern SNARKs allow to encode the invariants of a program, expressed as an arithmetic circuit, in an appropriate constraint language from which short, zero-knowledge proofs for correct computations can be constructed.

  One of the most important computations that is run through SNARK systems is the verification of Merkle tree (MT) opening proofs, which relies on the evaluation of a fixed-input-length (FIL) cryptographic compression function over binary MTs. 
  As classical, bit-oriented hash functions like SHA-2 are not compactly representable in SNARK frameworks, Arithmetization-Oriented (AO) cryptographic designs have emerged as an alternative, efficient solution.
  
  Today, the majority of AO compression functions are built from the Sponge permutation-based hashing mode. 
  While this approach allows cost savings, compared to blockcipher-based modes, as it does not require key-scheduling, AO blockcipher schedulers are often cheap to compute. 
  Furthermore, classical bit-oriented cryptography has long studied how to construct provably secure compression functions from blockciphers, following the Preneel-Govaerts-Vandewalle (PGV) framework. 
  The potential efficiency gains together with the strong provable security foundations in the classic setting, motivate the study of AO blockcipher-based compression functions.
  
  In this work, we propose PGV-LC and PGV-ELC, two AO blockcipher-based FIL compression modes inspired by and extending the classical PGV approach, offering flexible input and output sizes and coming with provable security guarantees in the AO setting. 
  We prove the collision and preimage resistance in the ideal cipher model, and give bounds for collision and opening resistance over MTs of arbitrary arity.
  
  We compare experimentally the AO PGV-ELC mode over the Hades blockcipher with its popular and widely adopted Sponge instantiation, Poseidon, and its improved variant Poseidon2. 
  Our resulting constructions are up to \(3\times \) faster than Poseidon and \(2\times \) faster than Poseidon2 in native x86 execution, and up to \(50\% \) faster in the Groth16 SNARK framework. 
  
  Finally, we study the benefits of using MTs of arity wider than two, proposing a new strategy to obtain a compact R1CS constraint system in such case.
  In fact, by combining an efficient parametrization of the Hades blockcipher over the PGV-ELC mode, together with an optimal choice of the MT arity, we measured an improvement of up to \(9\times \) in native MT construction time, and up to \(2.5\times \) in proof generation time, compared to Poseidon over binary MTs.
]]></content:encoded>
<pubDate>Thu, 11 Jan 2024 16:37:43 +0000</pubDate>
</item>
<item>
<title>Bringing Order to Chaos: The Case of Collision-Resistant Chameleon-Hashes</title>
<link>https://eprint.iacr.org/2020/403</link>
<guid>https://eprint.iacr.org/2020/403</guid>
<content:encoded><![CDATA[
<div> 关键词：Chameleon-hash functions, Trapdoor, Collision-resistance, Notions, Black-box construction.

总结:<br />
Chameleon-hash函数是一种由Krawczyk和Rabin在2000年NDSS会议上提出的特殊哈希函数，它依赖于公钥，私钥可导致碰撞。这些函数在密码学中有广泛应用，如提升非适应性安全签名到适应性安全。文章探讨了不同的碰撞抵抗概念，指出在某些复杂应用中，实际需求可能未被充分覆盖。研究者重新审视现有理论，分析它们之间的关系，并针对可编辑区块链等应用讨论不同抵抗性的实际影响。此外，他们提出了一种更强大、更理想的碰撞抵抗定义，并提供了一个简单高效的黑盒构造方法来实现这种强抵抗性。 <div>
Chameleon-hash functions, introduced by Krawczyk and Rabin at NDSS 2000, are trapdoor collision-resistant hash-functions parametrized by a public key. If the corresponding secret key is known, arbitrary collisions for the hash function can be efficiently found. Chameleon-hash functions have prominent applications in the design of cryptographic primitives, such as lifting non-adaptively secure signatures to adaptively secure ones. Recently, this primitive also received a lot of attention as a building block in more complex cryptographic applications ranging from editable blockchains to advanced signature and encryption schemes.

We observe that in latter applications various different notions of collision-resistance are used, and it is not always clear if the respective notion does really cover what seems intuitively required by the application. Therefore, we revisit existing collision-resistance notions in the literature, study their relations, and - using the example of the recent redactable blockchain proposals - discuss which practical impact different notions of collision-resistance might have. Moreover, we provide a stronger, and arguably more desirable, notion of collision-resistance than what is known from the literature. Finally, we present a surprisingly simple and efficient black-box construction of chameleon-hash functions achieving this strong notion.
]]></content:encoded>
<pubDate>Mon, 13 Apr 2020 10:27:27 +0000</pubDate>
</item>
<item>
<title>BumbleBee: Secure Two-party Inference Framework for Large Transformers</title>
<link>https://eprint.iacr.org/2023/1678</link>
<guid>https://eprint.iacr.org/2023/1678</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer模型、隐私保护、两党设置、矩阵乘法、非线性激活函数。

总结:<br />
该研究关注大型Transformer模型的隐私保护问题，特别是在两党设置下的私有推理。为此，作者提出BumbleBee，一个专注于速度和通信效率的系统。其贡献包括：<br />
1. 优化的矩阵乘法协议，比先前方法减少80%-90%的通信成本。
2. 针对Transformer模型中使用的非线性激活函数的高效协议，显著提升处理速度并降低80%-95%的通信开销。
3. 对五种Transformer模型进行了广泛测试，证明了BumbleBee的实用性，如使用CPU评估LLaMA-7B模型生成一个token只需约14分钟。
4. 相比Iron (NeurIPS22)有超过一倍的速度优势，且比BOLT (Oakland24)快三倍，同时通信量少十分之一。 <div>
Abstract—Large transformer-based models have realized state- of-the-art performance on lots of real-world tasks such as natural language processing and computer vision. However, with the increasing sensitivity of the data and tasks they handle, privacy has become a major concern during model deployment. In this work, we focus on private inference in two-party settings, where one party holds private inputs and the other holds the model. We introduce BumbleBee, a fast and communication-friendly two- party private transformer inference system. Our contributions are three-fold: First, we propose optimized protocols for matrix multiplication, which significantly reduce communication costs by 80% – 90% compared to previous techniques. Secondly, we develop a methodology for constructing efficient protocols tailored to the non-linear activation functions employed in transformer models. The proposed activation protocols have realized a significant enhancement in processing speed, alongside a remarkable reduction in communication costs by 80% – 95% compared with two prior methods. Lastly, we have performed extensive benchmarks on five transformer models. BumbleBee demonstrates its capability by evaluating the LLaMA-7B model, generating one token in approximately 14 minutes using CPUs. Our results further reveal that BumbleBee outperforms Iron (NeurIPS22) by over an order of magnitude and is three times faster than BOLT (Oakland24) with one-tenth communication.
]]></content:encoded>
<pubDate>Mon, 30 Oct 2023 02:48:51 +0000</pubDate>
</item>
<item>
<title>Faster Asynchronous Blockchain Consensus and MVBA</title>
<link>https://eprint.iacr.org/2024/1108</link>
<guid>https://eprint.iacr.org/2024/1108</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain consensus, 2-chain VABA, sMVBA, 2PAC, Super Fast Pipelined Blocks

总结:
本文介绍了一种新的区块链共识协议设计，包括2PAC（两阶段异步共识）和超级快速管道块。2PAC分为两个变体，2PAC$^\text{lean}$具有简洁链路和$9.5\delta$预期延迟，通过减少消息复杂度达到更高的吞吐量；而2PAC$^\text{BIG}$则是最快的异步协议，具有立方级消息复杂度，能在无消息乱序的情况下实现单次决策仅需$4\delta$。超级快速管道块改进了管道块的决策速度，即使在故障节点存在时也能保证低延迟，同时保持一致性。结合这些技术，如s2PAC$^\text{lean}$、s2PAC$^\text{BIG}$和sGradedDAG等协议分别实现了更快的决策时间。 <div>
Blockchain consensus, a.k.a. BFT SMR, are protocols enabling $n$ processes to decide on an ever-growing chain. The fastest known asynchronous one is called 2-chain VABA (PODC'21 and FC'22), and is used as fallback chain in Abraxas* (CCS'23). It has a claimed $9.5\delta$ expected latency when used for a single shot instance, a.k.a. an MVBA.
We exhibit attacks breaking it. Hence, the title of the fastest asynchronous MVBA with quadratic messages complexity goes to sMVBA (CCS'22), with $10\delta$ expected latency.
Our positive contributions are two new and complementary designs.

$\bullet$  2PAC (2-phase asynchronous consensus). It has a simpler and lighter chaining than in previous approaches. Instantiated with either quadratic or cubic phases of voting, it yields:

   2PAC$^\text{lean}$: $+90\%$ throughput and $9.5\delta$ expected latency, with quadratic ($O(n^2)$) messages complexity. In both 2-chain VABA and sMVBA (as if chained, with pipelining), the quorum-certified transactions which were produced in the worst-case 1/3 of views with a slow leader were dumped, so the work was lost. The simpler design of 2PAC inserts such blocks in straight-line in the chain.
Thus, contrary to naive uncle-referencing, this comes with no computational overhead, yielding a net $+50\%$ throughput gain over chained sMVBA. Both the remaining throughput and latency ($-0.5\delta$) gains, come from the lighter interactive construction of proofs of consistency appended to proposed blocks, compared to sMVBA.

   2PAC$^\text{BIG}$: the fastest asynchronous blockchain consensus with cubic ($O(n^3)$) messages complexity. Fault-free single shot MVBA runs decide in just $4\delta$, as soon as no message is delivered more than twice faster than others: GradedDAG (SRDS'23) required furthermore no messages reordering.

$\bullet$  Super Fast Pipelined Blocks. This is an upgrade of previous approaches for pipelining: in 2-chain VABA, Cordial Miners (DISC'23) and GradedDAG, a block pipelined by a leader in the middle of the view had almost twice larger latency than the non-pipelined block. Our design provides a fast path deciding the pipelined block with even smaller latency than the non-pipelined block. The fast delay is guaranteed in all executions with a fair scheduler, but remarkably, whatever the behaviors of faulty processes. Consistency is preserved by a lightweight mechanism, of one threshold signature appended per proposal.
Instantiated with the previous protocols, it yields: s2PAC$^\text{lean}$, with fast decision of pipelined blocks in $4\delta$; s2PAC$^\text{BIG}$, in $3\delta$; and sGradedDAG, in $3\delta$.
]]></content:encoded>
<pubDate>Mon, 08 Jul 2024 00:46:12 +0000</pubDate>
</item>
<item>
<title>FHE-MENNs: Opportunities and Pitfalls for Accelerating Fully Homomorphic Private Inference with Multi-Exit Neural Networks</title>
<link>https://eprint.iacr.org/2024/1099</link>
<guid>https://eprint.iacr.org/2024/1099</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), multi-exit neural networks (MENNs), latency, side-channel attack, cost-benefit analysis.

总结:<br />
本文探讨了在数据隐私日益重要的背景下，利用可完全同态加密（FHE）进行机器学习服务的潜在解决方案。研究者提出了使用多出口神经网络（MENNs）来加速FHE推理，以降低计算成本和时间。文章分析了FHE-MENN推理的延迟、通信、准确性和资源消耗，并介绍了名为TorMENNt的攻击，该攻击能利用用户提前终止计算来实施侧信道攻击，预测图像分类结果。文章还讨论了可能的防御措施及其有效性，并结合成本效益分析，为FHE-MENN的实际应用提供了一条实用路径。 <div>
With concerns about data privacy growing in a connected world, cryptography researchers have focused on fully homomorphic encryption (FHE) for promising machine learning as a service solutions. Recent advancements have lowered the computational cost by several orders of magnitude, but the latency of fully homomorphic neural networks remains a barrier to adoption. This work proposes using multi-exit neural networks (MENNs) to accelerate the FHE inference. MENNs are network architectures that provide several exit points along the depth of the network. This approach allows users to employ results from any exit and terminate the computation early, saving both time and power. First, this work weighs the latency, communication, accuracy, and computational resource benefits of running FHE-based MENN inference. Then, we present the TorMENNt attack that can exploit the user's early termination decision to launch a concrete side-channel on MENNs. We demonstrate that the TorMENNt attack can predict the private image classification output of an image set for both FHE and plaintext threat models. We discuss possible countermeasures to mitigate the attack and examine their effectiveness. Finally, we tie the privacy risks with a cost-benefit analysis to obtain a practical roadmap for FHE-based MENN adoption.
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 15:56:11 +0000</pubDate>
</item>
<item>
<title>BOLT: Privacy-Preserving, Accurate and Efficient Inference for Transformers</title>
<link>https://eprint.iacr.org/2023/1893</link>
<guid>https://eprint.iacr.org/2023/1893</guid>
<content:encoded><![CDATA[
<div> 关键词：transformers, privacy-preserving, secure multiparty computation (MPC), matrix multiplications, BOLT.

总结:<br />这篇文章主要探讨了Transformer模型广泛应用中信息泄露的问题。为了解决这一问题，作者提出了BOLT（Privacy-preserving Inference Framework for Transformer）框架，它专注于高效处理大规模模型的矩阵乘法和非线性计算。BOLT通过机器学习优化减少了10.91倍的通信成本。实验结果显示，BOLT在各种网络环境下比现有最先进的系统快4.8-9.5倍，同时保持与浮点模型相当的准确性。总的来说，BOLT是一个在保证隐私的同时提升Transformer模型推理效率的关键解决方案。 <div>
The advent of transformers has brought about significant advancements in traditional machine learning tasks. However, their pervasive deployment has raised concerns about the potential leakage of sensitive information during inference. Existing approaches using secure multiparty computation (MPC) face limitations when applied to transformers due to the extensive model size and resource-intensive matrix-matrix multiplications. In this paper, we present BOLT, a privacy-preserving inference framework for transformer models that supports efficient matrix multiplications and nonlinear computations. Combined with our novel machine learning optimizations, BOLT reduces the communication cost by 10.91x. Our evaluation on diverse datasets demonstrates that BOLT maintains comparable accuracy to floating-point models and achieves 4.8-9.5x faster inference across various network settings compared to the state-of-the-art system.
]]></content:encoded>
<pubDate>Sat, 09 Dec 2023 04:31:33 +0000</pubDate>
</item>
<item>
<title>Efficient Universally-Verifiable Electronic Voting with Everlasting Privacy</title>
<link>https://eprint.iacr.org/2024/742</link>
<guid>https://eprint.iacr.org/2024/742</guid>
<content:encoded><![CDATA[
<div> 关键词：universal verifiability、electronic voting、everlasting privacy、linearly-homomorphic signatures、receipt-freeness。

总结:
本文探讨了如何利用线性同态签名在电子投票系统中实现普遍可验证性和永恒隐私。传统的做法涉及公开加密投票和证明，但牺牲了长期隐私。作者提出了一种新方法，通过结合完美隐藏承诺和线性同态签名，既能确保投票过程的公正性（即普遍可验证性），又能保证投票的绝对隐私（即永恒隐私），即使在结果公布和证明发布后也是如此。这种方法的证明有效性基于代数群模型和随机 oracle 模型。这种技术革新为电子投票系统提供了高效且兼顾隐私保护的解决方案。 <div>
Universal verifiability is a must-to-have for electronic voting schemes. It is essential to ensure honest behavior of all the players during the whole process, together with the eligibility. However, it should not endanger the privacy of the individual votes, which is another major requirement.
Whereas the first property prevents attacks during the voting process, privacy of the votes should hold forever, which has been called everlasting privacy.

A classical approach for universal verifiability is to add some proofs together with the encrypted votes, which requires publication of the latter, while eligibility needs a link between the votes and the voters: it definitely excludes long-term privacy. An alternative is the use of perfectly-hiding commitments, on which proofs are published, while ciphertexts are kept private for computing the tally.

In this paper, we show how recent linearly-homomorphic signatures can be exploited for all the proofs, leading to very efficient procedures towards universal verifiability with both strong receipt-freeness and everlasting privacy.
Privacy will indeed be unconditional, after the publication of the results and the proofs, whereas the soundness of the proofs holds in the algebraic group model and the random oracle model.
]]></content:encoded>
<pubDate>Wed, 15 May 2024 20:08:35 +0000</pubDate>
</item>
<item>
<title>Random Beacons in Monte Carlo: Efficient Asynchronous Random Beacon without Threshold Cryptography</title>
<link>https://eprint.iacr.org/2023/1755</link>
<guid>https://eprint.iacr.org/2023/1755</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed random beacon, HashRand, Post-Quantum security, Asynchronous SMR, Communication efficiency.

总结: <br />
HashRand是一种高效、异步的分布式随机信标协议，它仅依赖安全哈希和对称安全通信，以克服现有系统的局限性。该协议具有每节点的平均通信复杂度为$\mathcal{O}(\lambda n \log(n))$比特/信标，显著降低了计算成本，尤其在量子安全方面，通过使用安全哈希函数对抗量子攻击。在一个包含136个节点的全球分布测试环境中，HashRand每分钟能产生78个信标，比Spurt快至少5倍。此外，HashRand的应用实例包括实现了一个Post-Quantum安全的异步SMR协议，对于16个节点的WAN环境，响应率超过135k交易/秒，延迟仅为2.3秒。 <div>
Regular access to unpredictable and bias-resistant randomness is important for applications such as blockchains, voting, and secure distributed computing. Distributed random beacon protocols address this need by distributing trust across multiple nodes, with the majority of them assumed to be honest. Numerous applications across the blockchain space have led to the proposal of several distributed random beacon protocols, with some already implemented. However, many current random beacon systems rely on threshold cryptographic setups or exhibit high computational costs, while others expect the network to be partial or bounded synchronous. To overcome these limitations, we propose HashRand, a computation and communication-efficient asynchronous random beacon protocol that only demands secure hash and pairwise secure channels to generate beacons. HashRand has a per-node amortized communication complexity of $\mathcal{O}(\lambda n \log(n))$ bits per beacon. The computational efficiency of HashRand is attributed to the two orders of magnitude lower time of a one-way Hash computation compared to discrete log exponentiation. Interestingly, besides reduced overhead,  HashRand achieves Post-Quantum security by leveraging the secure Hash function against quantum adversaries, setting it apart from other random beacon protocols that use discrete log cryptography. In a geo-distributed testbed of $n=136$ nodes, HashRand produces 78 beacons per minute, which is at least 5x higher than Spurt [IEEE S\&amp;P'22]. We also demonstrate the practical utility of HashRand by implementing a Post-Quantum secure Asynchronous SMR protocol, which has a response rate of over 135k transactions per second at a latency of $2.3$ seconds over a WAN for $n=16$ nodes.
]]></content:encoded>
<pubDate>Mon, 13 Nov 2023 16:39:12 +0000</pubDate>
</item>
<item>
<title>A Scalable Coercion-resistant Voting Scheme for Blockchain Decision-making</title>
<link>https://eprint.iacr.org/2023/1578</link>
<guid>https://eprint.iacr.org/2023/1578</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain voting, coercion-resistance, scalability, private differential voting power, liquid democracy

总结:
本文设计了首个可扩展的防胁迫区块链投票方案，支持私人差额投票权和一层液体民主。该方案复杂度为O(n)，其中n为选民数，将球票大小从张等人的Θ(m)减少到Θ(1)，m为专家和/或候选人数量。它保证了球票隐私、可验证性和防胁迫性。实验表明，与VoteAgain相比，该方案在大量选民和高额外球票率选举中的计票速度超过6倍。这项工作有望解决区块链投票中的胁迫问题，并提升系统的效率。 <div>
Typically, a decentralized collaborative blockchain decision-making mechanism is realized by remote voting. To date, a number of blockchain voting schemes have been proposed; however, to the best of our knowledge, none of these schemes achieve coercion-resistance. In particular, for most blockchain voting schemes, the randomness used by the voting client can be viewed as a witness/proof of the actual vote, which enables improper behaviors such as coercion and vote-buying. Unfortunately, the existing coercion-resistant voting schemes cannot be directly adopted in the blockchain context. In this work, we design the first scalable coercion-resistant blockchain voting scheme that supports private differential voting power and 1-layer liquid democracy as introduced by Zhang et al. (NDSS '19). Its overall complexity is $O(n)$, where $n$ is the number of voters. Moreover, the ballot size is reduced from Zhang et al.'s $\Theta(m)$ to $\Theta(1)$, where $m$ is the number of experts and/or candidates. We formally prove that our scheme has ballot privacy, verifiability, and coercion-resistance. We implement a prototype of the scheme and the evaluation result shows that our scheme's tally procedure is more than 6x faster than VoteAgain (USENIX '20) in an election with over 10,000 voters and over 50\% extra ballot rate.

Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.
]]></content:encoded>
<pubDate>Thu, 12 Oct 2023 12:02:44 +0000</pubDate>
</item>
<item>
<title>Faster Lookup Table Evaluation with Application to  Secure LLM Inference</title>
<link>https://eprint.iacr.org/2024/1093</link>
<guid>https://eprint.iacr.org/2024/1093</guid>
<content:encoded><![CDATA[
<div> 关键词：secure two-party computation, lookup tables (LUTs), $\mathsf{ROTL}$, FLUTE, secure LLM inference.

总结:
本文主要关注在大型语言模型的隐私保护下，如何通过安全的两方计算进行模型推理。研究者提出了$\mathsf{ROTL}$，一种针对查找表（LUT）评估的高效安全协议，相比现有最先进方法FLUTE，$\mathsf{ROTL}$在性能上分别有11.6倍和155倍的提升。特别地，$\mathsf{ROTL}$支持算术共享，而FLUTE仅限于布尔共享。文章还优化了FLUTE以支持布尔共享，显著减少了在线性能的带宽需求。这些改进对于保障用户隐私的同时提高大型语言模型的推理效率具有重要意义。 <div>
As large language models (LLMs) continue to gain popularity, concerns about user privacy are amplified, given that the data submitted by users for inference may contain sensitive information. Therefore, running LLMs through secure two-party computation (a.k.a. secure LLM inference) has emerged as a prominent topic. However, many operations in LLMs, such as Softmax and GELU, cannot be computed using conventional gates in secure computation; instead, lookup tables (LUTs) have to be utilized, which makes LUT to be an essential primitive in secure LLM inference.

In this paper, we propose $\mathsf{ROTL}$, a secure two-party protocol for LUT evaluations. Compared with FLUTE (the state-of-the-art LUT presented at  Oakland '23), it achieves upto  11.6$\times$ speedup in terms of overall performance and 155$\times$ speedup in terms of online performance. Furthermore, $\mathsf{ROTL}$ can support arithmetic shares (which is required by secure LLM inference), whereas FLUTE can only support boolean shares. At the heart of $\mathsf{ROTL}$ is a novel protocol for secret-shared rotation, which allows two parties to generate additive shares of the rotated table without revealing the rotation offset. We believe this protocol is of independent interest. Based on $\mathsf{ROTL}$, we design a novel secure comparison protocol; compared with the state-of-the-art, it achieves a 2.4$\times$ bandwidth reduction in terms of online performance. 

To support boolean shares, we further provide an optimization for FLUTE, by reducing its computational complexity from $O(l\cdot n^2)$ to $O(n\log n+l\cdot n)$ and shifting $O(n\log n)$ computation to the preprocessing phase. As a result, compared with FLUTE, it achieves upto 10.8$\times$ speedup in terms of overall performance and 962$\times$ speedup in terms of online performance.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 16:43:48 +0000</pubDate>
</item>
<item>
<title>MatcHEd: Privacy-Preserving Set Similarity based on MinHash</title>
<link>https://eprint.iacr.org/2024/1091</link>
<guid>https://eprint.iacr.org/2024/1091</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), MinHash, Carter-Wegman (CW) hash function, bitwise operations, encrypted set similarity

总结:<br />
文章提出了一种利用MinHash算法和CGGI FHE方案改进的加密集相似性计算方法。传统的FHE比较操作昂贵，尤其是对大量数据。通过引入高效的位级FHE友好的摘要函数(FFD)，替代Carter-Wegman哈希中的模运算，减少了在FHE环境中的复杂性和低效性。这种方法显著减少与直接计算Jaccard相似度所需的比较次数，并且天然支持多CPU和GPU并行处理，适用于隐私保护的文档抄袭检测等场景。总的来说，新方法提高了加密计算效率，降低了计算成本。 <div>
Fully homomorphic encryption (FHE) enables arbitrary computation on encrypted data, but certain applications remain prohibitively expensive in the encrypted domain. As a case in point, comparing two encrypted sets of data is extremely computationally expensive due to the large number of comparison operators required. In this work, we propose a novel methodology for encrypted set similarity inspired by the MinHash algorithm and the CGGI FHE scheme. Doing comparisons in FHE requires comparators and multiplexers or an expensive approximation, which further increases the latency, especially when the goal is to compare two sets of data. The MinHash algorithm can significantly reduce the number of comparisons required by employing a special Carter-Wegman (CW) hash function as a key building block. However, the modulus operation in the CW hash becomes another key bottleneck because the encrypted sub-circuits required to perform the modular reduction are very large and inefficient in an FHE setting. Towards that end, we introduce an efficient bitwise FHE-friendly digest function (FFD) to employ as the cornerstone of our proposed encrypted set-similarity. In a Boolean FHE scheme like CGGI, the bitwise operations can be implemented efficiently with Boolean gates, which allows for faster evaluation times relative to standard Carter-Wegman constructions. Overall, our approach drastically reduces the number of comparisons required relative to the baseline approach of directly computing the Jaccard similarity coefficients, and is inherently parallelizable, allowing for efficient encrypted computation on multi-CPU and GPU-based cloud servers. We validate our approach by performing a privacy-preserving plagiarism detection across encrypted documents.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 02:33:02 +0000</pubDate>
</item>
<item>
<title>PolyFHEmus: Rethinking Multiplication in Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1090</link>
<guid>https://eprint.iacr.org/2024/1090</guid>
<content:encoded><![CDATA[
<div> 关键词：Homomorphic encryption, Cloud computing, Latency, Polynomial multiplication, Accelerated computing.

总结:
这篇文章关注的是同态加密技术在云计算中的应用，这种技术允许在加密数据上进行计算以保护隐私。然而，它面临的主要挑战是高延迟问题，尤其是由于多项式乘法运算效率低下。文章的核心内容是识别了这一瓶颈，并探讨了寻找更高效算法的可能性，以期加速加密计算，从而推动同态加密在实际场景中的广泛应用。通过优化多项式运算，有望降低云计算中隐私保护操作的时间成本，促进该技术的普及和发展。 <div>
Homomorphic encryption is a powerful technology that solves key privacy concerns in cloud computing by enabling computation on encrypted data. However, it has not seen widespread adoption due to prohibitively high latencies. In this article, we identify polynomial multiplication as a bottleneck and investigate alternative algorithms to accelerate encrypted computing.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 01:56:46 +0000</pubDate>
</item>
<item>
<title>HElix: Genome Similarity Detection in the Encrypted Domain</title>
<link>https://eprint.iacr.org/2024/1088</link>
<guid>https://eprint.iacr.org/2024/1088</guid>
<content:encoded><![CDATA[
<div> 关键词：genomics, genome analysis, fully homomorphic encryption, MinHash, bloom filter.

总结:<br />这篇文章探讨了随着基因组学研究的发展，保护用户隐私和数据安全的挑战。作者提出两种基于全同态加密的方法，以在不泄露DNA序列的情况下进行比较。第一种方法是利用MinHash算法检测数据库中是否存在相似序列，另一种则是定制的布隆过滤器用于精确匹配。实验验证了这些方法在不同数据库规模下，无论使用GPU还是CPU云服务器，都能有效实现隐私保护下的基因组分析。 <div>
As the field of genomics continues to expand and more sequencing data is gathered, genome analysis becomes increasingly relevant for many users. For example, a common scenario entails users trying to determine if their DNA samples are similar to DNA sequences hosted in a larger remote repository. Nevertheless, end users may be reluctant to upload their DNA sequences, while the owners of remote genomics repositories are unwilling to openly share their database. To address this challenge, we propose two distinct approaches based on fully homomorphic encryption to preserve the privacy of the genomic data and enable queries directly on ciphertexts. The first is based on the ubiquitous MinHash algorithm and can determine if similar matches exist in the database, while the second involves a bespoke bloom filter construction for determining exact matches. We validate both approaches across various database sizes using both GPU and CPU-based cloud servers.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 00:21:09 +0000</pubDate>
</item>
<item>
<title>Randomized Distributed Function Computation with Semantic Communications: Applications to Privacy</title>
<link>https://eprint.iacr.org/2024/1085</link>
<guid>https://eprint.iacr.org/2024/1085</guid>
<content:encoded><![CDATA[
<div> 关键词：randomized distributed function computation, semantic communications, privacy, Wyner's common information, common randomness.

总结: <br />
本文研究了随机分布式函数计算中语义通信的应用，特别是在保证隐私的前提下减少通信负载。主要关注两点：<br />
1. 通过利用语义通信框架，结合远程源编码方法，可以在满足安全和隐私约束时，实现输入序列的随机化模拟，同时保证每个输入序列的地方差分隐私。
2. 文章提供了Wyner共同信息（WCI）的下界，这是协调-随机性速率区域的两个角点之一，该区域定义了随机分布式函数计算的极限。WCI对应于没有共享随机性的场景。
3. 对于连续随机变量，提出了数值方法来计算另一个角点，即无限共享随机性的情况。
4. 实例分析表明，即使在有限共享随机性情况下，语义通信也能显著降低通信需求，优于无失真压缩方法。
5. 结论指出，进一步研究有限共享随机性场景对于优化随机分布式函数计算具有重要意义。 <div>
Randomized distributed function computation refers to remote function computation where transmitters send data to receivers which compute function outputs that are randomized functions of the inputs. We study the applications of semantic communications in randomized distributed function computation to illustrate significant reductions in the communication load, with a particular focus on privacy. The semantic communication framework leverages generalized remote source coding methods, where the remote source is a randomized version of the observed data. Since satisfying security and privacy constraints generally require a randomization step, semantic communication methods can be applied to such function computation problems, where the goal is to remotely simulate a sequence at the receiver such that the transmitter and receiver sequences follow a target probability distribution. Our performance metrics guarantee (local differential) privacy for each input sequence, used in two different distributed function computation problems, which is possible by using strong coordination methods. 

This work provides lower bounds on Wyner's common information (WCI), which is one of the two corner points of the coordination-randomness rate region characterizing the ultimate limits of randomized distributed function computation. The WCI corresponds to the case when there is no common randomness shared by the transmitter and receiver. Moreover, numerical methods are proposed to compute the other corner point for continuous-valued random variables, for which an unlimited amount of common randomness is available. Results for two problems of practical interest illustrate that leveraging common randomness can decrease the communication load as compared to the WCI corner point significantly. We also illustrate that semantic communication gains over lossless compression methods are achieved also without common randomness, motivating further research on limited common randomness scenarios.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 10:52:51 +0000</pubDate>
</item>
<item>
<title>Enabling Complete Atomicity for Cross-chain Applications Through Layered State Commitments</title>
<link>https://eprint.iacr.org/2024/1084</link>
<guid>https://eprint.iacr.org/2024/1084</guid>
<content:encoded><![CDATA[
<div> 关键词：Cross-chain dApps, Complete atomicity, Avalon, State synchronization, Cosmos ecosystem.

总结:<br />Avalon是一个创新的跨链去中心化应用（dApp）交易执行框架，它首次实现了完整的原子性。通过在原生状态之上引入多层状态缓存，Avalon有效地管理状态转换，确保复杂任务的正确执行。对于并发的跨链交易，Avalon不仅解决了链内的冲突，还通过一种新颖的状态同步协议处理不同区块链之间的潜在不一致，实现串行化的跨链执行。Avalon使用Cosmos生态系统的智能合约进行实现，并在实验中展示了其承诺性能，即使在冲突情况下，也具有可接受的延迟和gas消耗。 <div>
Cross-chain Decentralized Applications (dApps) are increasingly popular for their ability to handle complex tasks across various blockchains, extending beyond simple asset transfers or swaps. However, ensuring all dependent transactions execute correctly together, known as complete atomicity, remains a challenge. Existing works provide financial atomicity, protecting against monetary loss, but lack the ability to ensure correctness for complex tasks. In this paper, we introduce Avalon, a transaction execution framework for cross-chain dApps that guarantees complete atomicity for the first time. Avalon achieves this by introducing multiple state layers above the native one to cache state transitions, allowing for efficient management of these state transitions. Most notably, for concurrent cross-chain transactions, Avalon resolves not only intra-chain conflicts but also addresses potential inconsistencies between blockchains via a novel state synchronization protocol, enabling serializable cross-chain execution. We implement Avalon using smart contracts in Cosmos ecosystem and evaluate its commitment performance, demonstrating acceptable latency and gas consumption even under conflict cases.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 07:13:00 +0000</pubDate>
</item>
<item>
<title>Practical Non-interactive Multi-signatures, and a Multi- to Aggregate Signatures Compiler</title>
<link>https://eprint.iacr.org/2024/1081</link>
<guid>https://eprint.iacr.org/2024/1081</guid>
<content:encoded><![CDATA[
<div> 关键词：fNIM, fNIA, $\mathsf{dms}$, multi-to-aggregate compiler, verification time

总结:
本文提出了一种新的高效非交互式多签名方案($\mathsf{dms}$)，解决了现有fNIM的两个关键问题。首先，$\mathsf{dms}$通过添加Schnorr PoPs简化了Boldyreva的对称配对基础fNIM，同时提供了更好的性能和在小群体中的快速验证。其在AGM模型下的安全性证明是主要技术贡献，具有大约128位的DL安全保证。其次，文章介绍了一个简单的编译器$\mathcal{M}to\mathcal{A}$，将任何fNIM转换为适合聚合具有公共前缀消息的fNIA，如Diem中应用$\mathsf{dms}$后的例子，验证速度显著提升。总的来说，$\mathsf{dms}$和$\mathcal{M}to\mathcal{A}$优化了签名效率和安全性，适用于大规模共识协议。 <div>
In a fully non-interactive multi- , resp. aggregate-, signature scheme (fNIM, resp. fNIA), signatures issued by many signers on the same message, resp. on different messages, can be succinctly ``combined'', resp. ``aggregated''.
fNIMs are used in the Ethereum consensus protocol, to produce the certificates of validity of blocks which are to be verified by billions of clients. fNIAs are used in some PBFT-like consensus protocols, such as the production version of Diem by Aptos, to replace the forwarding of many signatures by a new leader. In this work we address three complexity bottlenecks.
(i) fNIAs have larger cost than fNIMs, e.g., we observe that the fNIA of BGLS (Eurocrypt'03) over 3000 signatures, takes 100x longer verification time than a batch verification of 3000 Schnorr signatures.
(ii) fNIMs impose that each verifier processes the setup published by the group of potential signers. This processing consists either in verifying proofs of possession (PoPs), such as in Pixel (Usenix'20) and in the IETF'22 draft inherited from Ristenpart-Yilek (Eurocrypt'07), which costs a product of pairings over all published keys. Or, it consists in re-randomizing the keys, such as in SMSKR (FC'24).
(iii) Existing proven security bounds on efficient fNIMs do not give any guarantee in practical curves with 256bits-large groups, such as BLS12-381 (used in Ethereum) or BLS12-377 (used in Zexe). Thus, computing in much larger curves is required to have provable guarantees.

Our first contribution is a new fNIM called $\mathsf{dms}$, it addresses both (ii) and (iii).
It is as simple as adding Schnorr PoPs to the schoolbook pairing-based fNIM of Boldyreva (PKC'03).
(ii) For a group of 1000 signers, processing these PoPs is $5+$ times faster than for the previous pairing-based PoPs, and $3+$ times faster than the processing of SMSKR, which had furthermore to be done for every new group member. 
(iii) In the algebraic group model (AGM), and given the current estimation of roughly 128 bits of security for the discrete logarithm (DL) in both the curves BLS12-381 and BLS12-377, then we prove a probability of forgery of $\mathsf{dms}$ no higher than about $2^{-93}$ for a time $2^{80}$ adversary.
This proof of security is our main technical contribution. The only related proof before was for an interactive Schnorr-based multi-signature scheme, using Schnorr PoPs. We observe a gap in its proof, which is that the adversary has not access to a signing oracle before publishing its PoPs, although it should have. On the one hand, the gap can easily be fixed in their context. But in our context of pairing-based multi-signatures, the signing oracle produces a correlated random string which significantly complicates our extraction of the keys of the adversary.
We finally provide another application of $\mathsf{dms}$, which is that it can be plugged in recent threshold signatures without setup (presented by Das et al at CCS'23, and Garg et al at SP'24), since these schemes implicitly build on any arbitrary BLS-based fNIM.

Our second contribution addresses (i), it is a very simple compiler: $\mathcal{M}to\mathcal{A}$ (multi-to-aggregate). It turns any fNIM into an fNIA, suitable for aggregation of signatures on messages with a prefix in common, with the restriction that a signer must not sign twice using the same prefix. The obtained fNIA is post-quantum as soon as the fNIM is, such as Chipmunk (CCS'23). We demonstrate the relevance for Diem by applying $\mathcal{M}to\mathcal{A}$ to $\mathsf{dms}$: the resulting fNIA enables to verify 39x faster an aggregate of 129 signatures, over messages with $7$ bits-long variable parts, than BGLS.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 02:59:14 +0000</pubDate>
</item>
<item>
<title>GAuV: A Graph-Based Automated Verification Framework for Perfect Semi-Honest Security of Multiparty Computation Protocols</title>
<link>https://eprint.iacr.org/2024/1078</link>
<guid>https://eprint.iacr.org/2024/1078</guid>
<content:encoded><![CDATA[
<div> 关键词：Multiparty Computation (MPC), Security proof, Simulator, Automated framework, Perfect soundness.

总结:<br />
该研究提出了一种通用的自动化框架，用于验证多方计算(MPC)协议在面对半诚实攻击时的完美安全性。该框架具有完美完备性，能证明BGW协议等实例在给定的攻击者设置下的安全性，且能在多项式时间内完成。与仅关注黑盒隐私的传统方法不同，该框架适用于任意MPC协议的验证。通过实现原型，研究展示了其有效性和效率，能在合理时间内自动证明BGW和B2A转换协议的半诚实安全。这种方法简化了MPC协议的安全证明过程，提高了实践中的检测能力。 <div>
Proving the security of a Multiparty Computation (MPC) protocol is a difficult task. Under the current simulation-based definition of MPC, a security proof consists of a simulator, which is usually specific to the concrete protocol and requires to be manually constructed, together with a theoretical analysis of the output distribution of the simulator and corrupted parties' views in the real world. This presents an obstacle in verifying the security of a given MPC protocol. Moreover, an instance of a secure MPC protocol can easily lose its security guarantee due to careless implementation, and such a security issue is hard to detect in practice. 

In this work, we propose a general automated framework to verify the perfect security of instances of MPC protocols against the semi-honest adversary. Our framework has perfect soundness: any protocol that is proven secure under our framework is also secure under the simulation-based definition of MPC. We demonstrate the completeness of our framework by showing that for any instance of the well-known BGW protocol, our framework can prove its security for every corrupted party set with polynomial time. Unlike prior work that only focuses on black-box privacy which requires the outputs of corrupted parties to contain no information about the inputs of the honest parties, our framework may potentially be used to prove the security of arbitrary MPC protocols.

We implement our framework as a prototype. The evaluation shows that our prototype automatically proves the perfect semi-honest security of BGW protocols and B2A (binary to arithmetic) conversion protocols in reasonable durations.
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 16:39:44 +0000</pubDate>
</item>
<item>
<title>Anonymous, Timed and Revocable Proxy Signatures</title>
<link>https://eprint.iacr.org/2023/833</link>
<guid>https://eprint.iacr.org/2023/833</guid>
<content:encoded><![CDATA[
<div> 关键词：proxy signature, anonymity, timed delegation, revocability, blockchain

总结:<br />该文章提出了一种新的匿名、定时和可撤销的代理签名方案，填补了现有技术在满足时间限制、匿名性、撤销权限和政策执行等多方面需求上的空白。首先，通过基于Schnorr签名的可分割数字签名，实现安全的签名人身份令牌分配。其次，利用区块链作为公共公告板，结合时间锁定加密技术，确保签名人只能一次性使用令牌、在指定时间内代理签署以及在需要时撤销委托，同时保持全程去中心化和匿名性。文章还定义了代理签名的统一形式化概念，并证明了该方案符合这一概念，同时讨论了实际部署中的设计考量。 <div>
A proxy signature enables a party to delegate her signing power to another. This is useful in practice to achieve goals related to robustness, crowd-sourcing, and workload sharing. Such applications, especially in the blockchain model, usually require delegation to satisfy several properties, including time bounds, anonymity, revocability, and policy enforcement. Despite the large amount of work on proxy signatures in the literature, none of the existing schemes satisfy all these properties; even there is no unified formal notion that captures them. 

In this work, we close this gap and propose an anonymous, timed, and revocable proxy signature scheme. We achieve this in two steps: First, we introduce a tokenizable digital signature based on Schnorr signature allowing for secure distribution of signing tokens. Second, we utilize a public bulletin board, instantiated as a blockchain, and timelock encryption to support: (1) one-time usage of the signing tokens by tracking tokens used so far based on unique values associated to them, (2) timed delegation so that a proxy signer cannot sign outside a given period, and (3) delegation revocation allowing the original signer to end a delegation earlier than provisioned. All of these are done in a decentralized and anonymous way so that no one can tell that someone else signed on behalf of the original signer or even that a delegation took place. We define a formal notion for proxy signatures capturing all these properties, and prove that our construction realizes this notion. We also discuss several design considerations addressing issues related to deployment in practice.
]]></content:encoded>
<pubDate>Mon, 05 Jun 2023 11:15:33 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Dijkstra</title>
<link>https://eprint.iacr.org/2024/988</link>
<guid>https://eprint.iacr.org/2024/988</guid>
<content:encoded><![CDATA[
<div> 关键词：secret-sharing, adjacency list, $d$-normalized, oblivious conversion, secure operations

总结:
这篇文章介绍了一种方法，将秘密共享的邻接列表图形转换为更适用于多方计算（MPC）的$d$-规范化表示。这个过程分为两步：首先，安全地将节点重命名，从任意字符串转换为1到$V$的整数，以保持排序，这需要$O(\log V)$轮和$O((V+E)\log V)$次安全操作。其次，对已排序的整数节点进行$d$-规范化，仅需$O(1)$轮和$O(V+E)$次操作。这种转换有助于设计隐私保护的Dijkstra算法，实现$(V+E) \cdot \log V$次安全操作和$V \cdot \log V \cdot \log \log\log V$轮的复杂度。这种方法适用于常数数量的服务器，并适用于任何邻接列表表示，只要节点标签和权重能适应固定内存字节数。 <div>
Given a graph $G(V,E)$, represented as a secret-sharing of an adjacency list, we show how to obliviously convert it into an alternative, MPC-friendly secret-shared representation, so-called $d$-normalized replicated adjacency list (which we abbreviate to $d$-normalized), where the size of our new data-structure is only 4x larger -- compared to the original (secret-shared adjacency list) representation of $G$. Yet, this new data structure enables us to execute oblivious graph algorithms that simultaneously improve underlying graph algorithms' round, computation, and communication complexity. Our $d$-normalization proceeds in two steps: 

First, we show how for any graph $G$, given a secret-shared adjacency list, where vertices are arbitrary alphanumeric strings that fit into a single RAM memory word, we can efficiently and securely rename vertices to integers from $1$ to $V$  that will appear in increasing order in the resulting secret-shared adjacency list. The secure renaming takes $O(\log V)$ rounds and $O((V+E)\log V)$ secure operations. Our algorithm also outputs two secret-shared arrays: a mapping from integers to alphanumeric names and its sorted inverse. Of course, if the adjacency list is already in such a format, this step could be omitted.

Second, given a secret-shared adjacency list for any graph $G$, where vertices are integers from $1$ to $V$ and are sorted, we show an oblivious $d$-normalization algorithm that takes $O(1)$ rounds and $O(V+E)$ secure operations.

We believe that both conversions are of independent interest. We demonstrate the power of our data structures by designing a privacy-preserving Dijkstra's single-source shortest-path algorithm that simultaneously achieves $O((V +E) \cdot \log V)$ secure operations and   $O(V \cdot \log V \cdot  \log \log\log V)$ rounds. Our secure Dijkstra algorithm works for any adjacency list representation as long as all vertex labels and weights can individually fit into a constant number of RAM memory words. Our algorithms work for two or a constant number of servers in the honest but curious setting.  The limitation of our result (to only a constant number of servers) is due to our reliance on linear work and constant-round secure shuffle.
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 08:02:46 +0000</pubDate>
</item>
<item>
<title>A $3$-Round Near-Linear Third-Party Private Set Intersection Protocol</title>
<link>https://eprint.iacr.org/2024/566</link>
<guid>https://eprint.iacr.org/2024/566</guid>
<content:encoded><![CDATA[
<div> 关键词：private set intersection（私密集合交集）、third-party PSI、communication rounds（通信轮数）、computational complexity（计算复杂性）、post-quantum security（后量子安全）。

总结:<br />
本文提出了一种高效的第三方私密集合交集协议，仅需3轮通信，显著降低了计算工作量。该协议适用于对效率有高要求的真实世界应用，如接触者追踪，同时保护隐私。其算法改进和新技巧的应用使得计算复杂度达到近线性，即$O(n^{1+\varepsilon})$，适用于大数据集。此外，文章还首次探讨了第三方私密集合交集的基数功能，即仅第三方获知交集大小，而无其他信息。此基数功能的实现具有近线性计算复杂度。这些改进和创新为后量子时代的隐私保护提供了新的解决方案。 <div>
Third-party private set intersection (PSI) enables two parties, each holding a private set to compute their intersection and reveal the result only to an inputless third party. In this paper, we present an efficient third-party PSI protocol requiring only 3 communication rounds, while significantly lowering the computational workload compared to prior work. Our work is motivated by real-world applications such as contact tracing whereby expedition is essential while concurrently preserving privacy. Our construction attains a near-linear computational complexity of $O(n^{1+\varepsilon})$ for large dataset size $n$, where $\varepsilon>0$ is any fixed constant, and achieves post-quantum security. Our improvements stem from algorithmic changes and the incorporation of new techniques along with precise parameter selections to achieve a tight asymptotic bound. Furthermore, we also present a third-party PSI cardinality protocol which has not been explored in prior third-party PSI work. In a third-party PSI cardinality setting, only the third-party obtains the size of the intersection and nothing else. Our construction to achieve the cardinality functionality attains a quasilinear computational complexity for the third-party.
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 03:33:48 +0000</pubDate>
</item>
<item>
<title>Securely Training Decision Trees Efficiently</title>
<link>https://eprint.iacr.org/2024/1077</link>
<guid>https://eprint.iacr.org/2024/1077</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation (MPC), Decision Tree, Communication Complexity, Protocol, MP-SPDZ Framework

总结: <br />
该研究专注于改进决策树的隐私保护训练方法，利用secure multi-party computation (MPC)技术。文章的主要贡献在于提出了一种新的协议，将通信复杂度从$\mathcal{O}(hmN\log N)$降低到$\mathcal{O}(mN\log N + hmN + hN\log N)$，相比先前工作约减少了$\mathsf{min}(h, m, \log N)$。核心创新是一个能保持元素相对顺序的高效排序和分组方法。通过在MP-SPDZ框架中的实现，新协议比现有状态-of-the-art节省了10倍的通信并快9倍。这为处理大规模、高维度数据集的隐私保护决策树训练提供了更有效的解决方案。 <div>
Decision trees are an important class of supervised learning algorithms. When multiple entities contribute data to train a decision tree (e.g. for fraud detection in the financial sector), data privacy concerns necessitate the use of a privacy-enhancing technology such as secure multi-party computation (MPC) in order to secure the underlying training data. Prior state-of-the-art (Hamada et al.)  construct an MPC protocol for decision tree training with a communication of $\mathcal{O}(hmN\log N)$, when building a decision tree of height $h$ for a training dataset of $N$ samples, each having $m$ attributes.

In this work, we significantly reduce the communication complexity of secure decision tree training. 
We construct a protocol with communication complexity $\mathcal{O}(mN\log N + hmN + hN\log N)$, thereby achieving an improvement of $\approx \mathsf{min}(h, m, \log N)$ over Hamada et al. 
At the core of our technique is an improved protocol to regroup sorted private elements further into additional groups (according to a flag vector) while maintaining their relative ordering. We implement our protocol in the MP-SPDZ framework and show that it requires $10\times$ lesser communication and is $9\times$ faster than the state-of-the-art.
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 07:55:04 +0000</pubDate>
</item>
<item>
<title>Secret Key Recovery in a Global-Scale End-to-End Encryption System</title>
<link>https://eprint.iacr.org/2024/887</link>
<guid>https://eprint.iacr.org/2024/887</guid>
<content:encoded><![CDATA[
<div> 关键词：End-to-end encryption, Messaging applications, Decryption keys, Secure Value Recovery 3 (SVR3), Heterogeneous enclaves.

总结:<br />文章讨论了端到端加密消息应用中用户面临的一个挑战：如果丢失设备且无法访问解密密钥，将无法访问账户。为解决这个问题，Secure Value Recovery 3 (SVR3)被提出，它是一种秘密密钥恢复系统，通过在不同云提供商管理的不同硬件安全隔间（enclaves）之间分散信任，保护用户的解密密钥。SVR3是首个跨异构隔间部署的密钥恢复系统，降低了单一隔间成为攻击目标的风险。该系统利用回滚保护和故障 tolerance 技术适应隔间的安全性。SVR3的年度成本为0.0025美元/用户，用户恢复密钥的时间为365毫秒，这是一个罕见的操作。SVR3已在一个支持数亿真实用户的部署中实施，显示出处理大规模用户的能力。 <div>
End-to-end encrypted messaging applications ensure that an attacker cannot read a user's message history without their decryption keys. While this provides strong privacy, it creates a usability problem: if a user loses their devices and cannot access their decryption keys, they can no longer access their account. To solve this usability problem, users should be able to back up their account information with the messaging provider. For privacy, this backup should be encrypted and the provider should not have access to users' decryption keys. To solve this problem, we present Secure Value Recovery 3 (SVR3), a secret key recovery system that distributes trust across different types of hardware enclaves run by different cloud providers in order to protect users' decryption keys. SVR3 is the first deployed secret key recovery system to split trust across heterogeneous enclaves managed by different cloud providers: this design ensures that a single type of enclave does not become a central point of attack. SVR3 protects decryption keys via rollback protection and fault tolerance techniques tailored to the enclaves' security guarantees. SVR3 costs \$0.0025/user/year and takes 365ms for a user to recover their key, which is a rare operation. A part of SVR3 has been rolled out to millions of real users in a deployment with capacity for over 500 million users, demonstrating the ability to operate at scale.
]]></content:encoded>
<pubDate>Mon, 03 Jun 2024 17:04:58 +0000</pubDate>
</item>
<item>
<title>Improved Multi-Party Fixed-Point Multiplication</title>
<link>https://eprint.iacr.org/2024/1047</link>
<guid>https://eprint.iacr.org/2024/1047</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、机器学习、多党安全计算、固定点乘法、秘密分享。

总结:<br />
本文研究了在多服务器（$N \geq 3$）环境下进行隐私保护的机器学习问题。作者设计了新的多党安全固定点乘法协议，适用于三种秘密分享形式：复制、Shamir和加性共享，针对半诚实攻击提供安全保证。对于复制共享，还提出了一种对抗恶意攻击的高效协议。这些协议提高了通信效率，用于构建支持加法和固定点乘法（带截断）的任意算术电路的多党计算（MPC）协议。所有协议均基于标准的模拟安全性定义得到证明。其中，复制和Shamir共享协议需要至少一半服务器是诚实的，而加性共享协议可以容忍多数恶意行为。 <div>
Machine learning is widely used for a range of applications and is increasingly offered as a service by major technology companies. However, the required massive data collection raises privacy concerns during both training and inference. Privacy-preserving machine learning aims to solve this problem. In this setting, a collection of servers secret share their data and use secure multi-party computation to train and evaluate models on the joint data. All prior work focused on the scenario where the number of servers is two or three. In this work, we study the problem where there are $N \geq 3$ servers amongst whom the data is secret shared. 

A key component of machine learning algorithms is to perform fixed-point multiplication with truncation of secret shared decimal values. In this work, we design new protocols for multi-party secure fixed-point multiplication where each of the $N$ parties have one share each of the two values to be multiplied and receive one share of the product at the end of the protocol. We consider three forms of secret sharing - replicated, Shamir, and additive, and design an efficient protocol secure in the presence of a semi-honest adversary for each of the forms. Our protocols are more communication efficient than all prior work on performing multi-party fixed-point multiplication. Additionally, for replicated secret sharing, we design another efficient protocol that is secure in the presence of a malicious adversary. Finally, we leverage our fixed-point multiplication protocols to design secure multi-party computation (MPC) protocols for arbitrary arithmetic circuits that have addition and fixed-point multiplication with truncation gates. All our protocols are proven secure using a standard simulation based security definition. Our protocols for replicated and Shamir sharing work in the presence of an honest majority of parties while the one for additive sharing can tolerate a dishonest majority as well.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 21:16:25 +0000</pubDate>
</item>
<item>
<title>Message Latency in Waku Relay with Rate Limiting Nullifiers</title>
<link>https://eprint.iacr.org/2024/1073</link>
<guid>https://eprint.iacr.org/2024/1073</guid>
<content:encoded><![CDATA[
<div> 关键词: Waku, GossipSub, Rate Limiting Nullifiers (RLN), message propagation latency, decentralized messaging

总结:
Waku是一种注重隐私、通用和去中心化的消息传递协议。它结合了GossipSub（用于路由）和RLN（防止垃圾信息）技术。本文通过理论分析、大规模单节点模拟和多节点全球部署实验，评估了Waku的消息传播延迟。实验结果证实，中等大小（25 KB）的消息能在1秒内送达，满足像去中心化通信这样的应用场景需求。Waku在保证匿名性和可扩展性的同时，实现了满意的延迟性能。 <div>
Waku is a privacy-preserving, generalized, and decentralized messaging protocol suite. Waku uses GossipSub for message routing and Rate Limiting Nullifiers (RLN) for spam protection. GossipSub ensures fast and reliable peer-to-peer message delivery in a permissionless environment, while RLN enforces a common publishing rate limit using zero-knowledge proofs.

This paper presents a practical evaluation of message propagation latency in Waku. First, we estimate latencies analytically, building a simple mathematical model for latency under varying conditions. Second, we run a large-scale single-host simulation with 1000 nodes. Third, we set up a multi-host Waku deployment using five nodes in different locations across the world. Finally, we compare our analytical estimations to the results of the simulation and the real-world measurement.

The experimental results are in line with our theoretical model. Under realistic assumptions, medium-sized messages (25 KB) are delivered within 1 second. We conclude that Waku can achieve satisfactory latency for typical use cases, such as decentralized messengers, while providing scalability and anonymity.
]]></content:encoded>
<pubDate>Mon, 01 Jul 2024 19:43:18 +0000</pubDate>
</item>
<item>
<title>Exploiting Internal Randomness for Privacy in Vertical Federated Learning</title>
<link>https://eprint.iacr.org/2024/671</link>
<guid>https://eprint.iacr.org/2024/671</guid>
<content:encoded><![CDATA[
<div> 关键词：Vertical Federated Learning (VFL), Differential Privacy (DP), Variational Autoencoder (VAE), Empirical Local Differential Privacy (dELDP), Privacy Attacks.

总结:<br />
本文主要探讨了在Vertical Federated Learning (VFL)中，如何利用Variational Autoencoder (VAE)的内在随机性增强隐私保护。作者提出了一种新的差分隐私估计方法，称为距离基局部差分隐私(dELDP)，用于量化模型或模型组件的隐私参数。通过实验，dELDP在VAE中的应用显示出高达ε ≈ 6.4和δ = 2^{-32}的隐私值。研究发现，包含VAE的VFL系统对特征重建攻击具有稳健性，并且在对手拥有75%特征的标签推断攻击中，相比其他隐私增强方法表现出色。这表明，利用VAE的内部随机性可以在保持一定性能的同时提供有效的隐私保护。 <div>
Vertical Federated Learning (VFL) is becoming a standard collaborative learning paradigm with various practical applications. Randomness is essential to enhancing privacy in VFL, but introducing too much external randomness often leads to an intolerable performance loss. Instead, as it was demonstrated for other federated learning settings, leveraging internal randomness —as provided by variational autoencoders (VAEs) —can be beneficial. However, the resulting privacy has never been quantified so far, nor has the approach been investigated for VFL.
We therefore propose a novel differential privacy (DP) estimate, denoted as distance-based empirical local differential privacy (dELDP). It allows us to empirically bound DP parameters of models or model components, quantifying the internal randomness with appropriate distance and sensitivity metrics. We apply dELDP to investigate the DP of VAEs and observe values up to ε ≈ 6.4 and δ = 2−32. Based on this, to link the dELDP parameters to the privacy of VAE-including VFL systems in practice, we conduct comprehensive experiments on the robustness against state-of-the-art privacy attacks. The results illustrate that the VAE system is robust against feature reconstruction attacks and outperforms other privacy-enhancing methods for VFL, especially when the adversary holds 75% of the features during label inference attacks.
]]></content:encoded>
<pubDate>Thu, 02 May 2024 11:08:22 +0000</pubDate>
</item>
<item>
<title>Decentralized Multi-Client Functional Encryption with Strong Security</title>
<link>https://eprint.iacr.org/2024/764</link>
<guid>https://eprint.iacr.org/2024/764</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Multi-Client Functional Encryption (DMCFE), Inner Products, Function-Hiding, Random Oracle Model, Security Guarantees.

总结:
本文探讨了去中心化的多客户端功能加密（DMCFE）的新构造，特别关注于内积函数的保密性。作者提出了一种新的证明方法，为这一构造提供了强大的随机 Oracle 模型下的安全保证。与之前仅在选择性攻击下证明安全性的构造不同，这个新方案允许对手进行适应性查询，包括带有重复消息标签的挑战密文和固定数量重复密钥标签的挑战密钥。这增加了对敏感函数（如机器学习模型）的保护。总的来说，研究者通过改进技术增强了多客户端功能加密在实际应用中的安全性。 <div>
Decentralized Multi-Client Functional Encryption (DMCFE) extends the basic functional encryption to multiple clients that do not trust each other. They can independently encrypt the multiple plaintext-inputs to be given for evaluation to the function embedded in the functional decryption key, defined by multiple parameter-inputs. And they keep control on these functions as they all have to contribute to the generation of the functional decryption keys. Tags can be used in the ciphertexts and the keys to specify which inputs can be combined together. As any encryption scheme, DMCFE provides privacy of the plaintexts. But the functions associated to the functional decryption keys might be sensitive too (e.g. a model in machine learning). The function-hiding property has thus been introduced to additionally protect the function evaluated during the decryption process.

  In this paper, we provide new proof techniques to analyze a new concrete construction of function-hiding DMCFE for inner products, with strong security guarantees in the random oracle model: the adversary can adaptively query multiple challenge ciphertexts and multiple challenge keys, with unbounded repetitions of the same message tags in the ciphertext-queries and a fixed polynomially-large number of repetitions of the same key tags in the key-queries, allowing static corruption of the secret encryption keys. Previous constructions were proven secure in the selective setting only.
]]></content:encoded>
<pubDate>Sun, 19 May 2024 17:14:22 +0000</pubDate>
</item>
<item>
<title>SECDSA: Mobile signing and authentication under classical ``sole control''</title>
<link>https://eprint.iacr.org/2021/910</link>
<guid>https://eprint.iacr.org/2021/910</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子签名、eIDAS、智能卡、移动平台、独控制。

总结:<br />该文章探讨了2014年欧洲eIDAS法规对电子签名和强电子认证的要求，特别是关于“独控制”的变化。传统的智能卡通过用户直接与依赖方交互实现独控制，但eIDAS允许将用户互动外包给中间服务，如移动应用。然而，移动设备的加密硬件有限，无法支持复杂的密钥控制（如PIN）。作者提出一种新的设计，旨在为标准移动平台提供类似智能卡的独控制，满足eIDAS的严格要求。此外，文章还提及了基于SECDSA的欧洲数字身份钱包方案，这是eIDAS更新的一部分。这种设计确保即使在使用移动设备时，也能保持用户对电子签名的独控制，增强电子交易的安全性。 <div>
The 2014 European eIDAS regulation regulates strong electronic authentication and legally binding electronic signatures. Both require user "sole control". Historically smartcards are used based on direct interaction between user and relying party. Here sole control is provided by giving users both physical possession and control of the cryptographic key used for signing/authentication through a PIN.
Such **classical** sole control is required in the 1999 electronic signature directive by some interpretations.
The eIDAS regulation repeals the directive and explicitly relaxes its sole control requirements in a trade-off between security and usability.
This allows user interaction to be outsourced to intermediary parties (authentication providers, signing services). This also allows mobile applications as user friendly alternatives for smartcards. However, current mobile platforms are only equipped with limited cryptographic hardware not supporting secure knowledge factors (PINs) controlling keys. The eIDAS relaxation raises concerns on sole control; intermediary parties should not be able to act as man-in-the-middle and impersonate users. In this paper we present a simple cryptographic design for signing and authentication on standard mobile platforms providing classical sole control. We argue that our design can meet the highest eIDAS requirements, effectively introducing a new signature category in a 2016 decision of the European Commission.
We also sketch a SECDSA based implementation of the European Digital Identity Wallet recently proposed by the European Commission as part of the eIDAS regulation update.
]]></content:encoded>
<pubDate>Mon, 05 Jul 2021 18:55:07 +0000</pubDate>
</item>
<item>
<title>$\textsf{Asterisk}$: Super-fast MPC with a Friend</title>
<link>https://eprint.iacr.org/2023/1098</link>
<guid>https://eprint.iacr.org/2023/1098</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure multiparty computation (MPC), Dishonest majority, Helper party (HP), Fairness, Asterisk framework.

总结:<br />
这篇文章探讨了在存在恶意多数方的多方计算(MPC)中，引入一个半诚实、非协作的辅助 party（HP）以提高效率和保障安全性的可能性。作者设计并实现了一个名为Asterisk的高效通用多党框架，它仅需少量调用HP，实现了公平性保障，适用于数百个参与者，且在预处理和在线时间上都优于现有协议，甚至能与诚实多数情况下的协议竞争。实验表明，Asterisk在预处理速度上比最佳方案快228-288倍，能支持大规模电路的快速计算，并成功应用于暗池实例，展示了其在实际应用中实现隐私保护的强大能力。 <div>
Secure multiparty computation$~$(MPC) enables privacy-preserving collaborative computation over sensitive data held by multiple mutually distrusting parties. Unfortunately, in the most natural setting where a majority of the parties are maliciously corrupt$~$(also called the $\textit{dishonest majority}$ setting), traditional MPC protocols incur high overheads and offer weaker security guarantees than are desirable for practical applications. In this paper, we explore the possibility of circumventing these drawbacks and achieving practically efficient dishonest majority MPC protocols with strong security guarantees by assuming an additional semi-honest, non-colluding helper party $\mathrm{HP}$. We believe that this is a more realistic alternative to assuming an honest majority, since many real-world applications of MPC involving potentially large numbers of parties$~$(such as dark pools) are typically enabled by a central governing entity that can be modeled as the $\mathrm{HP}$.

    In the above model, we are the first to design, implement and benchmark a practically-efficient and general multi-party framework, $\textsf{Asterisk}$. Our framework requires invoking $\mathrm{HP}$ only a constant number of times, achieves the strong security guarantee of $\textit{fairness}$ (either all parties learn the output or none do), scales to hundreds of parties, outperforms all existing dishonest majority MPC protocols, and is, in fact, competitive with state-of-the-art honest majority MPC protocols. Our experiments show that $\textsf{Asterisk}$ achieves $228-288\times$ speedup in preprocessing as compared to the best dishonest majority MPC protocol. With respect to online time, $\textsf{Asterisk}$ supports $100$-party evaluation of a circuit with $10^6$ multiplication gates in approximately $20$ seconds. We also implement and benchmark practically efficient and highly scalable dark pool instances using $\textsf{Asterisk}$. The corresponding run times showcase the effectiveness of $\textsf{Asterisk}$ in enabling efficient realizations of real-world privacy-preserving applications with strong security guarantees.
]]></content:encoded>
<pubDate>Fri, 14 Jul 2023 05:44:23 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proofs of Training for Deep Neural Networks</title>
<link>https://eprint.iacr.org/2024/162</link>
<guid>https://eprint.iacr.org/2024/162</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、深度神经网络（DNN）、迭代训练、GKR风格证明系统、证明大小和验证器时间。

总结:<br />
\name是一种专为深度神经网络设计的零知识证明（zkPoT），旨在保证隐私、效率和简洁性。它允许证人通过梯度下降迭代训练模型，每次迭代后生成一个证明，证明模型参数的正确性。文章的核心贡献包括：1）提出优化的GKR风格证明系统，降低证人成本；2）开发通用框架，实现多轮GKR证明的高效组合；3）实证表明，\name能处理大规模模型如VGG-11，证明大小仅1.63MB，验证器运行时间低至130毫秒，独立于迭代次数和数据集大小，显著提高效率。 <div>
A zero-knowledge proof of training (zkPoT) enables a party to prove that they have correctly trained a committed model based on a committed dataset without revealing any additional information about the model or the dataset. An ideal zkPoT should offer provable security and privacy guarantees, succinct proof size and verifier runtime, and practical prover efficiency. In this work, we present \name, a zkPoT targeted for deep neural networks (DNNs) that achieves all these goals at once. Our construction enables a prover to iteratively train their model via (mini-batch) gradient descent, where the number of iterations need not be fixed in advance; at the end of each iteration, the prover generates a commitment to the trained model parameters attached with a succinct zkPoT, attesting to the correctness of the executed iterations. The proof size and verifier time are independent of the number of iterations.

Our construction relies on two building blocks. First, we propose an optimized GKR-style (sumcheck-based) proof system for the gradient-descent algorithm with concretely efficient prover cost; this allows the prover to generate a proof for each iteration. We then show how to recursively compose these proofs across multiple iterations to attain succinctness. As of independent interest, we propose a generic framework for efficient recursive composition of GKR-style proofs, along with aggregatable polynomial commitments.

Benchmarks indicate that \name\ can handle the training of complex models such as VGG-11 with 10~million parameters and batch size~$16$. The prover runtime is $15$~minutes per iteration, which is $\mathbf{24 \times}$ faster than generic recursive proofs, with prover memory overhead $\mathbf{27\times}$ lower. The proof size is $1.63$~megabytes, and the verifier runtime is only $130$~milliseconds, where both are independent of the number of iterations and the size of the dataset.
]]></content:encoded>
<pubDate>Sun, 04 Feb 2024 22:43:14 +0000</pubDate>
</item>
<item>
<title>Secure Vickrey Auctions with Rational Parties</title>
<link>https://eprint.iacr.org/2024/1011</link>
<guid>https://eprint.iacr.org/2024/1011</guid>
<content:encoded><![CDATA[
<div> 关键词：second price auction, Vickrey auction, privacy, rational parties, dominant strategy equilibrium

总结:<br />
本文设计了一种无需拍卖人的第二价格（Vickrey）拍卖协议（SPA），确保了在理性、计算能力有限且注重隐私的参与者之间的完全隐私。该协议保护了最高出价和第二高出价者的身份不被泄露。参与者被模型化为自我利益驱动、遵循个人优势（通过合适的效用函数衡量）的理性个体，他们不会随意偏离协议。研究证明，在这种SPA中存在一种隐私保护的主导策略均衡，每个参与者都倾向于遵守协议。

该协议基于开源加密技术实现，具有高效性和低通信量。在一个拥有15名竞标者、每笔投标10位的实验中，SPA仅需1.26秒完成，总通信量为0.77MB。相比之下，类似条件下Atlas（半诚实）协议的运行时间增加了40%，通信量增加了87%。这表明作者的SPA协议在效率和隐私保护上具有显著优势。 <div>
In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual `advantage' -- without any consideration for others. Such an advantage is modeled using suitable utility functions. 

We show that for rational and computationally bounded parties participating in our second-price auctions protocol, there exists a privacy-preserving dominant strategy equilibrium in which every party prefers to follow the protocol rather than to deviate. 

Our protocol is implemented using open-source cryptographic constructs. Running our SPA protocol on commodity hardware with $15$ bidders,  with bids of length $10$ bits,  completes in $1.26$sec and has total communication of $0.77$MB whereas, under similar conditions, Atlas (semi-honest) protocol takes $40\%$ more time ($2.11$ sec) and $87\%$ more communication ($6.09$MB).
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 04:11:28 +0000</pubDate>
</item>
<item>
<title>FSSiBNN: FSS-based Secure Binarized Neural Network Inference with Free Bitwidth Conversion</title>
<link>https://eprint.iacr.org/2024/1010</link>
<guid>https://eprint.iacr.org/2024/1010</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure neural network inference, Binarized neural networks (BNNs), Secure multi-party computation (MPC), Function secret sharing (FSS), Communication overhead.

总结:<br />
本文提出了一种名为FSSiBNN的安全二值神经网络（BNN）推理框架，旨在解决在使用MPC进行BNN推理时的隐私保护和通信效率问题。FSSiBNN利用函数秘密共享（FSS）实现免费的位宽转换，设计了一种位宽减半的参数编码方案，将位宽转换无缝融入FSS安全二值激活和最大池化协议中，显著减少了通信开销。通过预计算矩阵乘法和比较操作，FSSiBNN在实验中表现出色，相比XONN有7倍的更快推理速度和577倍的通信成本降低，相较于SecureBiNN和FLEXBNN，FSSiBNN在速度和通信效率上也有显著优势。 <div>
Neural network inference as a service enables a cloud server to provide inference services to clients. To ensure the privacy of both the cloud server's model and the client's data, secure neural network inference is essential. Binarized neural networks (BNNs), which use binary weights and activations, are often employed to accelerate inference. However, achieving secure BNN inference with secure multi-party computation (MPC) is challenging because MPC protocols cannot directly operate on values of different bitwidths and require bitwidth conversion. Existing bitwidth conversion schemes expand the bitwidths of weights and activations, leading to significant communication overhead.

To address these challenges, we propose FSSiBNN, a secure BNN inference framework featuring free bitwidth conversion based on function secret sharing (FSS). By leveraging FSS, which supports arbitrary input and output bitwidths, we introduce a bitwidth-reduced parameter encoding scheme. This scheme seamlessly integrates bitwidth conversion into FSS-based secure binary activation and max pooling protocols, thereby eliminating the additional communication overhead. Additionally, we enhance communication efficiency by combining and converting multiple BNN layers into fewer matrix multiplication and comparison operations. We precompute matrix multiplication tuples for matrix multiplication and FSS keys for comparison during the offline phase, enabling constant-round online inference.

In our experiments, we evaluated various datasets and models, comparing our results with state-of-the-art frameworks. Compared with the two-party framework XONN (USENIX Security '19), FSSiBNN achieves approximately 7$\times$ faster inference times and reduces communication overhead by about 577$\times$. Compared with the three-party frameworks SecureBiNN (ESORICS '22) and FLEXBNN (TIFS '23), FSSiBNN is approximately 2.5$\times$ faster in inference time and reduces communication overhead by 1.3$\times$ to 16.4$\times$.
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 14:45:30 +0000</pubDate>
</item>
<item>
<title>Auditable Attribute-Based Credentials Scheme and Its Application in Contact Tracing</title>
<link>https://eprint.iacr.org/2023/1060</link>
<guid>https://eprint.iacr.org/2023/1060</guid>
<content:encoded><![CDATA[
<div> 关键词：attribute-based credentials (ABC), auditable, anonymity, revocability, contact tracing

总结:<br />该文章探讨了在疫情期间，隐私保护联系追踪系统的需求升级。作者将注意力转向了基于属性的凭证(ABC)方案，提出了一种可审计的ABC扩展，增加了审计能力，允许指定的审计机构撤销特定发行者的匿名性。为此，他们设计了可更新公钥的“可审计公钥”机制，并将其应用于Connolly等人的ABC构造中。此外，文章还改进了Wang等人的框架，提供了安全定义和协议构建，以及一个实现来展示设计的实用性。这个工作不仅解决了现有系统的局限，而且"可审计公钥"机制具有通用性，可能对其他加密技术有独立价值。 <div>
During the pandemic, the limited functionality of existing privacy-preserving contact tracing systems highlights the need for new designs. Wang et al. proposed an environmental-adaptive framework (CSS '21) but failed to formalize the security. The similarity between their framework and attribute-based credentials (ABC) inspires us to reconsider contact tracing from the perspective of ABC schemes. In such schemes, users can obtain credentials on attributes from issuers and prove the credentials anonymously (i.e., hiding sensitive information of both user and issuer). This work first extends ABC schemes with auditability, which enables designated auditing authorities to revoke the anonymity of particular issuers. For this purpose, we propose an ``auditable public key (APK)'' mechanism that extends the updatable public key by Fauzi et al. (AsiaCrypt '19). We provide formal security definitions regarding auditability and build our auditable ABC scheme by adding a DDH-based APK to Connolly et al.'s ABC construction (PKC '22). Note that the APK mechanism can be used as a plug-in for other cryptographic primitives and may be of independent interest. Finally, regarding contact tracing, we refine Wang et al.'s framework and present a formal treatment that includes security definitions and protocol construction. An implementation is provided to showcase the practicality of our design.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 00:04:39 +0000</pubDate>
</item>
<item>
<title>Stochastic Secret Sharing with $1$-Bit Shares and Applications to MPC</title>
<link>https://eprint.iacr.org/2024/1053</link>
<guid>https://eprint.iacr.org/2024/1053</guid>
<content:encoded><![CDATA[
<div> 关键词：secret-sharing, 1-bit shares, corruption probability, error-correcting codes, binary erasure channel

总结:<br />
这篇文章探讨了一种新的随机模型，用于设计具有单比特份额的阈值秘密共享方案，以抵抗任意常数概率$p<0.5$的攻击。作者通过建立与纠错码在二进制擦除信道上达到容量的联系，提出了创新的构造方法。这些线性且可乘的方案有助于构建高效、实时的多方计算（MPC）协议，即使门电路按顺序实时到来，也能保证低通信量，每个AND门只需单比特通信，XOR门无需通信。这对于实现实时环境下的安全计算是一个重要突破。 <div>
The problem of minimizing the share size of threshold secret-sharing schemes is a basic research question that has been extensively studied. Ideally, one strives for schemes in which the share size equals the secret size. While this is achievable for large secrets (Shamir, CACM '79), no similar solutions are known for the case of binary, single-bit secrets. Current approaches often rely on so-called ramp secret sharing that achieves a constant share size at the expense of a slight gap between the privacy and the correctness thresholds. In the case of single-bit shares, this leads to a large gap which is typically unacceptable. The possibility of a meaningful notion of secret sharing scheme with 1-bit shares and almost optimal threshold has been left wide open. Of special interest is the case of threshold 0.5, which is motivated by information-theoretic honest-majority secure multiparty computation (MPC).

In this work, we present a new stochastic model for secret-sharing where each party is corrupted by the adversary with probability $p$, independently of the other parties, and correctness and privacy are required to hold with high probability over the choice of the corrupt parties. We present new secret sharing schemes with single-bit shares that tolerate any constant corruption probability $p<0.5$. Our construction is based on a novel connection between such stochastic secret-sharing schemes and error-correcting codes that achieve capacity over the binary erasure channel.

Our schemes are linear and multiplicative. We demonstrate the usefulness of the model by using our new schemes to construct MPC protocols with security against an adversary that passively corrupts an arbitrary subset of $0.499n$ of the parties, where the online communication per party consists of a single bit per AND gate and zero communication per XOR gate. Unlike competing approaches for communication-efficient MPC, our solution is applicable even in a real-time model in which the parties should compute a Boolean circuit whose gates arrive in real-time, one at a time, and are not known in advance.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 06:24:00 +0000</pubDate>
</item>
<item>
<title>A New Fine Tuning Method for FHEW/TFHE Bootstrapping with IND-CPAD Security</title>
<link>https://eprint.iacr.org/2024/1052</link>
<guid>https://eprint.iacr.org/2024/1052</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), FHEW, TFHE, IND-CPA-D security, key recovery attack

总结:<br />
文章讨论了全同态加密(FHE)方案，特别是FHEW和TFHE，这两种方法在处理加密数据的计算上表现出色。然而，它们的评估失败概率对参数选择敏感，导致必须选择过低的失败概率以抵抗Cheon等人的关键恢复攻击，这牺牲了运行效率。为解决这个问题，作者提出了一种新的FHEW/TFHE的提升方法，它允许精确地平衡运行时间和失败概率，同时提供易于实现的特性。新方法允许根据所需安全级别选择更合适的参数集，兼顾效率和安全性。 <div>
Fully homomorphic encryption (FHE) schemes enable computations on encrypted data, making them a crucial component of privacy-enhancing technologies. 
Ducas and Micciancio introduced FHEW (Eurocrypt '15), and Chillotti et al. improved it in TFHE (Asiacrypt '16), both of which provide homomorphic binary (or larger) gate evaluations with fast latency due to their small parameters. 
However, their evaluation failure probability is highly sensitive to parameter selection, resulting in a limited set of viable parameters and a trade-off between failure probability and runtime.

Recently, Cheon et al. proposed a key recovery attack against FHEW/TFHE schemes based on a new security model for FHE, called IND-CPA-D security, which was first introduced by Li and Micciancio (Eurocrypt '21). 
To prevent this attack, it is necessary to make the failure probability negligible (e.g., $2^{-128}$). 
However, due to limited choice parameters, it is forced to use a parameter set with unnecessarily low failure probabilities than needed, causing inefficiencies in runtime.

We propose a new bootstrapping method for FHEW/TFHE, providing a precise balance between runtime and failure probability, and easy to implement.
The proposed methods enable the selection of parameter sets that achieve negligible failure probabilities for each desired security level while optimizing runtime.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 04:46:10 +0000</pubDate>
</item>
<item>
<title>Efficient Verifiable Differential Privacy with Input Authenticity in the Local and Shuffle Model</title>
<link>https://eprint.iacr.org/2024/1042</link>
<guid>https://eprint.iacr.org/2024/1042</guid>
<content:encoded><![CDATA[
<div> 关键词：Local differential privacy (LDP), malicious clients, input manipulation, output manipulation, verifiable LDP (VLDP).

总结: 这篇文章探讨了如何保护Local Differential Privacy (LDP)机制免受恶意客户端的攻击。作者提出了一种高效的方法，通过设计防止输入和输出操纵的Verifiable LDP (VLDP)方案，确保了数据隐私。VLDP完全防御输出操纵，使用签名数据防止输入攻击，仅需一次客户端与服务器交互，提高了系统的安全性。文章还提供了两种在常规模型下的VLDP方案和一种在shuffle模型下的实现，且具有良好的实践性，客户端运行时间少于2秒，服务器处理时间为每客户5-7毫秒。 <div>
Local differential privacy (LDP) is an efficient solution for providing privacy to client's sensitive data while simultaneously releasing aggregate statistics without relying on a trusted central server (aggregator) as in the central model of differential privacy. The shuffle model with LDP provides an additional layer of privacy, by disconnecting the link between clients and the aggregator, further improving the utility of LDP. However, LDP has been shown to be vulnerable to malicious clients who can perform both input and output manipulation attacks, i.e., before and after applying the LDP mechanism, to skew the aggregator's results. In this work, we show how to prevent malicious clients from compromising LDP schemes. Specifically, we give efficient constructions to prevent both input ánd output manipulation attacks from malicious clients for generic LDP algorithms. Our proposed schemes for verifiable LDP (VLDP), completely protect from output manipulation attacks, and prevent input attacks using signed data, requiring only one-time interaction between client and server, unlike existing alternatives [28, 33]. Most importantly, we are the first to provide an efficient scheme for VLDP in the shuffle model. We describe and prove secure, two schemes for VLDP in the regular model, and one in the shuffle model. We show that all schemes are highly practical, with client runtimes of < 2 seconds, and server runtimes of 5-7 milliseconds per client.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 07:19:55 +0000</pubDate>
</item>
<item>
<title>Encryption Based Covert Channel for Large Language Models</title>
<link>https://eprint.iacr.org/2024/586</link>
<guid>https://eprint.iacr.org/2024/586</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer神经网络、安全性、Covert Channel攻击、Claude.ai、隐私风险。

总结:<br />
Transformer神经网络因其在大型语言模型中的出色表现而备受关注。本文聚焦于这些模型的安全隐患，特别是Covert Channel（隐蔽信道）攻击。研究者利用加密手段在Claude.ai上实施了攻击，并发现该模型会记录用户查询。值得注意的是，攻击在两天内被察觉并阻止，这引发了两个关键问题：一是大语言模型可能过度收集用户数据，对隐私构成威胁；二是频繁的阻断可能导致学术界对于此类模型安全性的研究受限，难以重复实验。 <div>
Transformer neural networks have gained significant traction since their introduction, becoming pivotal across diverse domains. Particularly in large language models like Claude and ChatGPT, the transformer architecture has demonstrated remarkable efficacy. This paper provides a concise overview of transformer neural networks and delves into their security considerations, focusing on covert channel attacks and their implications for the safety of large language models. We present a covert channel utilizing encryption and demonstrate its efficacy in circumventing Claude.ai's security measures. Our experiment reveals that Claude.ai appears to log our queries and blocks our attack within two days of our initial successful breach.  This raises two concerns within the community: (1) The extensive logging of user inputs by large language models could pose privacy risks for users. (2) It may deter academic research on the security of such models due to the lack of experiment repeatability.
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 04:22:48 +0000</pubDate>
</item>
<item>
<title>SACfe: Secure Access Control in Functional Encryption with Unbounded Data</title>
<link>https://eprint.iacr.org/2024/1031</link>
<guid>https://eprint.iacr.org/2024/1031</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、功能加密（FE）、SACfe、安全访问控制、内积属性。<br /><br />总结: 这篇文章探讨了在大规模数字应用中保护用户隐私的重要性，特别是针对云计算和机器学习服务。作者提出了一种新的属性基功能加密方案（SACfe），它提供了安全、细粒度的访问控制，同时隐藏用户属性和对数据的操作，确保数据保密性。SACfe特别支持对加密数据进行线性计算，并基于内积条件执行访问控制。文章还展示了SACfe如何用于在线生物识别，实现隐私保护的访问控制。此外，文章还介绍了一种适用于无限长度消息和函数的线性FE，其控制基于单调span程序。实验结果表明，该方案在实践中具有高效性，通过CiFEr库实现了这些协议。 <div>
Privacy is a major concern in large-scale digital applications, such as cloud-computing, machine learning services, and access control. Users want to protect not only their plain data but also their associated attributes (e.g., age, location, etc). Functional encryption (FE) is a cryptographic tool that allows fine-grained access control over encrypted data. However, existing FE fall short as they are either inefficient and far from reality or they leak sensitive user-specific information.

We propose SACfe, a novel attribute-based FE scheme that provides secure, fine-grained access control and hides both the user’s attributes and the function applied to the data, while preserving the data’s confidentiality. Moreover, it enables users to encrypt unbounded-length messages along with an arbitrary number of hidden attributes into ciphertexts. We design SACfe, a protocol for performing linear computation on encrypted data while enforcing access control based on inner product predicates. We show how SACfe can be used for online biometric authentication for privacy-preserving access control. As an additional contribution, we introduce an attribute-based linear FE for unbounded length of messages and functions where access control is realized by monotone span programs. We implement our protocols using the CiFEr cryptographic library and show its efficiency for practical settings.
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 07:19:42 +0000</pubDate>
</item>
<item>
<title>Stateless and Verifiable Execution Layer for Meta-Protocols on Bitcoin</title>
<link>https://eprint.iacr.org/2024/408</link>
<guid>https://eprint.iacr.org/2024/408</guid>
<content:encoded><![CDATA[
<div> 关键词：Layer-2解决方案、比特币指数器、Turing-incomplete、INDECURE、数据完整性

总结: <br />
本文讨论了比特币生态系统中的发展，尤其是Layer-2解决方案（如inscriptions和ordinal protocols）在提高交易效率和创建独特资产方面的贡献。然而，比特币脚本的限制性使其需要使用指数器进行复杂操作。INDECURE是一个提出的新型模块化指数器架构，它旨在解决传统分布式指数器的安全问题，如Sybil攻击。INDECURE利用多项式承诺作为检查点，通过数据证明确保状态信息的可靠性，减少验证过程中的计算和存储需求。初步评估显示，INDECURE在BRC20、Bitmap和satsnames等协议中表现出更好的性能，为比特币的去中心化和高效应用提供了坚实的基础。 <div>
The Bitcoin ecosystem has continued to evolve beyond its initial promises of decentralization, transparency, and security. Recent advancements have notably been made with the integration of Layer-2 solutions, which address scalability issues by offloading transactions from the main blockchain. This facilitates faster and more cost-effective transactions while maintaining integrity. The advent of inscriptions and ordinal protocols has further broadened the spectrum of capabilities, enabling the creation of unique, indivisible assets on the blockchain. Despite these technological strides, the inherent limitations of Bitcoin's script being Turing-incomplete restrict complex executions directly on the blockchain, necessitating the use of Bitcoin indexers. These indexers act as off-chain execution layers, allowing for the incorporation of Turing-complete programming languages to manage and update state transitions based on blockchain data. However, this off-chain solution introduces challenges to data integrity and availability, compounded by the decentralized nature of blockchain which complicates data maintenance and accuracy.

To address these challenges, we propose a new modular indexer architecture that enables a fully decentralized and user-verified network, mitigating the risks associated with traditional decentralized indexer networks susceptible to Sybil attacks. Our solution, INDECURE, leverages polynomial commitments as checkpoints to streamline the verification process, significantly reducing the overhead associated with integrity checks of state transitions. By implementing a robust data attestation procedure, INDECURE ensures the reliability of state information against malicious alterations, facilitating trustless verifications by users. Our preliminary evaluations of INDECURE across various indexer protocols—BRC20, Bitmap, and satsnames—demonstrate its superiority in reducing computation time and data block size while maintaining high integrity in state transitions. This modular approach not only enhances the security and efficiency of Bitcoin's off-chain executions but also sets a foundational layer for scalable, secure blockchain applications.
]]></content:encoded>
<pubDate>Wed, 06 Mar 2024 18:14:24 +0000</pubDate>
</item>
<item>
<title>MUSEN: Aggregatable Key-Evolving Verifiable Random Functions and Applications</title>
<link>https://eprint.iacr.org/2024/628</link>
<guid>https://eprint.iacr.org/2024/628</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Random Function (VRF), Aggregatable Key-Evolving VRF (A-KE-VRF), Proof-of-Stake (PoS), Proofs of Proof-of-Stake (PoPoS), Encryption to the Future (EtF)

总结:<br />
本文提出了一种新的可聚合密钥演进Verifiable Random Function (A-KE-VRF)，它具有聚合和密钥演进的特性。A-KE-VRF有助于提升Proof-of-Stake (PoS)区块链的块大小效率，优化PoPoS，并构建了面向未来的加密和来自过去的认证方案。这些技术对于YOSO MPC框架至关重要，提供了增强的安全性。通过结合这些功能，A-KE-VRF为未来加密协议设计开辟了新路径。 <div>
A Verifiable Random Function (VRF) can be evaluated on an input by a prover who holds a secret key, generating a pseudorandom output and a proof of output validity that can be verified using the corresponding public key. VRFs are a central building block of committee election mechanisms that sample parties to execute tasks in cryptographic protocols, e.g. generating blocks in a Proof-of-Stake (PoS) blockchain or executing a round of MPC protocols. We propose the notion, and a matching construction, of an Aggregatable Key-Evolving VRF (A-KE-VRF) with the following extra properties: 1. Aggregation: combining proofs for several VRF evaluations of different inputs under different secret keys into a single constant size proof; 2. Key-Evolving: preventing adversaries who corrupt a party (learning their secret key) from ``forging'' proofs of past VRF evaluations. As an immediate application, we improve on the block size of PoS blockchains and on the efficiency of Proofs of Proof-of-Stake (PoPoS). Furthermore, the A-KE-VRF notion allows us to construct Encryption to the Future (EtF) and Authentication from the Past (AfP) schemes with a Key-Evolving property, which provides forward security.  An EtF scheme allows for sending a message to a party who is randomly selected to execute a role in the future, while an AfP scheme allows for this party to authenticate their messages as coming from a past execution of this role. These primitives are essential for realizing the YOSO MPC Framework (CRYPTO'21).
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 07:32:44 +0000</pubDate>
</item>
<item>
<title>"Act natural!": Having a Private Chat on a Public Blockchain</title>
<link>https://eprint.iacr.org/2021/1073</link>
<guid>https://eprint.iacr.org/2021/1073</guid>
<content:encoded><![CDATA[
<div> 关键词：subliminal channel, blockchain, secret-recoverable splittable signature, public-key, random oracle model

总结:<br />
本文提出了一种利用区块链上秘密可恢复分割签名方案的公开密钥隐秘通信渠道。这种设计在随机Oracle模型下，在常见加密假设下是不可检测的。方法适用于98种顶级加密货币中使用的98种秘密可恢复分割签名方案，仅增加每条消息一个签名的常量开销。研究还分析了比特币、Monero和RippleNet网络的适用性，并提供了比特币和RippleNet的原型实现。这一创新为匿名但可追踪的通信提供了一种新的可能，增加了信息安全的隐蔽性。 <div>
Messengers have become an essential means of interpersonal interaction. Yet untraceable private communication remains an elusive goal, as most messengers hide content, but not communication patterns. The knowledge of communication patterns can by itself reveal too much, as happened, e.g., in the context of the Arab Spring. Subliminal channels in cryptographic systems enable untraceable private communication in plain sight. In this context, bulletin boards in the form of blockchains are a natural object for subliminal communication: accessing them is innocuous, as they rely on distributed access for verification and extension. At the same time, blockchain users generate hundreds of thousands of transactions per day that are individually signed and placed on the blockchain. Thus, blockchains may serve as innocuous repository for publicly accessible cryptographic transactions where subliminal channels can be placed. This significantly increases the availability of publicly accessible cryptographic transactions where subliminal channels can be placed.
In this paper, we propose a public-key subliminal channel using secret-recoverable splittable signature schemes on blockchains and prove that our construction is undetectable in the random oracle model under common cryptographic assumptions. Our approach is applicable to any secret-recoverable splittable signature scheme and introduces a constant overhead of a single signature per message. Such schemes are used by 98 of the top 100 cryptocurrencies. We also analyze the applicability of our approach to the Bitcoin, Monero, and RippleNet networks and present proof of concept implementations for Bitcoin and RippleNet.
]]></content:encoded>
<pubDate>Mon, 23 Aug 2021 06:32:15 +0000</pubDate>
</item>
<item>
<title>From Interaction to Independence: zkSNARKs for Transparent and Non-Interactive Remote Attestation</title>
<link>https://eprint.iacr.org/2024/1068</link>
<guid>https://eprint.iacr.org/2024/1068</guid>
<content:encoded><![CDATA[
<div> 关键词：remote attestation (RA), transparency, zkSNARKs, non-interactive, publicly provable

总结:
本文介绍了一种新型的远程验证协议(zRA)，它利用零知识 Succinct Non-Interactive Argument of Knowledge (zkSNARKs)技术，解决了现有RA协议的透明度问题。zRA无需预共享密钥或访问敏感数据，实现了无交互、公开可验证的设备验证。它不依赖在线服务，也不增加额外的安全假设，适用于点对点和发布/订阅网络结构。作者还开发了开源实现，并表明zRA适用于公共许可区块链，用于存储和保护免受DoS攻击的认证数据。总的来说，zRA促进了更广泛地采用远程验证技术，保证了系统的可信度和审计性。 <div>
Remote attestation (RA) protocols have been widely
used to evaluate the integrity of software on remote devices.
Currently, the state-of-the-art RA protocols lack a crucial feature: transparency. This means that the details of the final
attestation verification are not openly accessible or verifiable by
the public. Furthermore, the interactivity of these protocols often
limits attestation to trusted parties who possess privileged access
to confidential device data, such as pre-shared keys and initial
measurements. These constraints impede the widespread adoption
of these protocols in various applications.
In this paper, we introduce zRA, a non-interactive, transparent, and publicly provable RA protocol based on zkSNARKs.
zRA enables verification of device attestations without the need
for pre-shared keys or access to confidential data, ensuring a
trustless and open attestation process. This eliminates the reliance
on online services or secure storage on the verifier side. Moreover,
zRA does not impose any additional security assumptions beyond
the fundamental cryptographic schemes and the essential trust
anchor components on the prover side (i.e., ROM and MPU).
The zero-knowledge attestation proofs generated by devices have
constant size regardless of the network complexity and number
of attestations. Moreover, these proofs do not reveal sensitive
information regarding internal states of the device, allowing verification by anyone in a public and auditable manner. We conduct
an extensive security analysis and demonstrate scalability of zRA
compared to prior work. Our analysis suggests that zRA excels
especially in peer-to-peer and Pub/Sub network structures. To
validate the practicality, we implement an open-source prototype
of zRA using the Circom language. We show that zRA can be
securely deployed on public permissionless blockchains, serving
as an archival platform for attestation data to achieve resilience
against DoS attacks.
]]></content:encoded>
<pubDate>Mon, 01 Jul 2024 12:23:31 +0000</pubDate>
</item>
<item>
<title>Distributional Secure Merge</title>
<link>https://eprint.iacr.org/2024/1048</link>
<guid>https://eprint.iacr.org/2024/1048</guid>
<content:encoded><![CDATA[
<div> 关键词：secure merge, uniformly random lists, near linear, logarithmic overheads, implementation

总结:<br />
本文主要探讨了在处理随机列表的 secure merge 问题上，提出了一种新的协议。该协议实现了近乎线性的通信和计算复杂度，每轮运行时间为 $O(\log\log n)$，对于长度为 $2^{20}$ 的列表，运行时间和通信量比现有状态提高了一个数量级。与之前的理论工作相比，虽然在理论上的最优时间复杂度有所差距，但实证表明，新协议在实际应用中更为高效。此外，该协议还扩展到了来自任意分布的列表，尤其是当列表近似同分布时，效率接近于随机列表，从而显著提升了 PSI 和 Secure Join 等关键应用的性能。 <div>
Secure merge refers to the problem of merging two sorted lists. The problem appears in different settings where each list is held by one of two parties, or the lists are themselves shared among two or more parties. The output of a secure merge protocol is secret shared. Each variant of the problem offers many useful applications.

The difficulty in designing secure merge protocols vis-a-vis insecure merge protocols (which work in linear time with a single pass over the lists) has to do with operations having to be oblivious or data-independent. In particular, the protocol cannot leak the positions of items of each list in the final merged list. On account of this, sorting-based secure merge protocols have been a common solution to the problem. However, as they introduce (poly)logarithmic overheads, there has been active investigation into the task of building (near) linear time secure merge protocols. Most recently, Hemenway et al. put forth a protocol for secure merge that does achieve linear communication and computation and a round complexity of $O({\log\log n})$, where $n$ is the length of the lists being merged. While this shows the feasibility of a linear time secure merge, it still leaves room for the design of a concretely efficient linear time secure merge.

In this work, we consider a relaxation of the problem where the lists are uniformly random. We show a secure merge protocol for uniformly random lists that achieves $O({n\log\log n})$, i.e., near linear communication and computation and a round complexity of $O({\log\log n})$, where $n$ is the length of the lists being merged. Our protocol design is general and can be instantiated in a variety of settings so long as the building blocks (basic ones such as comparisons and shuffles) can be realized in said settings. Although we do not achieve the same asymptotic guarantees as Hemenway et al., our work is concretely efficient. We implement our protocol and compare it to the state of the art sorting protocols and demonstrate an order of magnitude improvement in running times and communication for lists of size of $2^{20}$. 

We also extend our protocol to work for lists sampled from arbitrary distributions. In particular, when the lists are (close to) identically distributed, we achieve the same efficiency as uniform lists. This immediately improve the performance of many crucial applications including PSI & Secure Join, thus illustrating the significance and applicability of our protocol in practice.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 22:07:39 +0000</pubDate>
</item>
<item>
<title>ammBoost: State Growth Control for AMMs</title>
<link>https://eprint.iacr.org/2024/1021</link>
<guid>https://eprint.iacr.org/2024/1021</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance（去中心化金融）、Automated Market Makers（自动市场 maker，AMM）、Blockchain、Scalability（可扩展性）、ammBoost。

总结: <br />
文章讨论了去中心化金融（DeFi）中自动市场 makers（AMM）的可扩展性问题，尤其是在区块链上处理大量交易时产生的存储和交易成本问题。为解决这一问题，作者提出了一种名为ammBoost的新型侧链架构，旨在减少链上交易、提高吞吐量并支持区块链修剪。该系统采用多种技术确保AMM的正确性和安全性。通过构建Uniswap启发式用例的原型，实验结果表明ammBoost能将交易气体成本降低94.53%，链增长至少减少80%，并且能够支持比实际Uniswap高出500倍的日流量。总的来说，ammBoost是一种有效的解决方案，旨在优化AMM在DeFi中的性能和可持续性。 <div>
Automated market makers (AMMs) are a form of decentralized cryptocurrency exchanges and considered a prime example of Decentralized Finance (DeFi) applications. Their popularity and high trading activity have resulted in millions of on-chain transactions leading to serious scalability issues. In this paper, we address the on-chain storage overhead problem of AMMs by utilizing a new sidechain architecture as a layer 2 solution, building a system called ammBoost. Our system reduces the amount of on-chain transactions, boosts throughput, and supports blockchain pruning. We devise several techniques to enable layer 2 processing for AMMs while preserving correctness and security of the underlying AMM. We also build a proof-of-concept of ammBoost for a Uniswap-inspired use case to empirically evaluate its performance. Our experiments show that ammBoost decreases the gas cost by 94.53% and the chain growth by at least 80%, and that it can support up to 500x of the daily traffic volume observed for Uniswap in practice.
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 19:20:08 +0000</pubDate>
</item>
<item>
<title>A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance</title>
<link>https://eprint.iacr.org/2024/304</link>
<guid>https://eprint.iacr.org/2024/304</guid>
<content:encoded><![CDATA[
<div> 关键词：Reticulum, sharding, blockchain, scalability, adversarial nodes

总结: <br />
Reticulum是一种创新的分片协议，旨在解决区块链网络中的可扩展性和安全性问题。它采用两阶段设计，分为控制和处理分片，以应对不同类型的攻击。控制分片确保网络的多数诚实节点，而处理分片负责交易处理，通过一致同意减少参与验证的节点，实现高吞吐量。在出现争议时，控制分片作为仲裁者。实验表明，Reticulum在保持高交易速度的同时，具有更强的抗攻击性，相较于现有协议更具优势。 <div>
Sharding is a critical technique that enhances the scalability of blockchain technology. However, existing protocols often assume adversarial nodes in a general term without considering the different types of attacks, which limits transaction throughput at runtime because attacks on liveness could be mitigated. There have been attempts to increase transaction throughput by separately handling the attacks; however, they have security vulnerabilities. This paper introduces Reticulum, a novel sharding protocol that overcomes these limitations and achieves enhanced scalability in a blockchain network without security vulnerabilities.

Reticulum employs a two-phase design that dynamically adjusts transaction throughput based on runtime adversarial attacks on either or both liveness and safety. It consists of `control' and `process' shards in two layers corresponding to the two phases. Process shards are subsets of control shards, with each process shard expected to contain at least one honest node with high confidence. Conversely, control shards are expected to have a majority of honest nodes with high confidence. Reticulum leverages unanimous voting in the first phase to involve fewer nodes in accepting/rejecting a block, allowing more parallel process shards. The control shard finalizes the decision made in the first phase and serves as a lifeline to resolve disputes when they surface.

Experiments demonstrate that the unique design of Reticulum empowers high transaction throughput and robustness in the face of different types of attacks in the network, making it superior to existing sharding protocols for blockchain networks.
]]></content:encoded>
<pubDate>Fri, 23 Feb 2024 00:13:18 +0000</pubDate>
</item>
<item>
<title>Non-interactive VSS using Class Groups and Application to DKG</title>
<link>https://eprint.iacr.org/2023/451</link>
<guid>https://eprint.iacr.org/2023/451</guid>
<content:encoded><![CDATA[
<div> 关键词：non-interactive verifiable secret sharing (NI-VSS), class groups (cgVSS), range proof, public verifiability, non-interactive distributed key generation (NI-DKG).

总结:
本文提出了一种基于类群的非交互式可验证秘密共享方案(cgVSS)，它不依赖于范围证明，利用类群的独特结构实现高效的大整数加密。cgVSS简化了NI-VSS过程，相比现有方案有显著性能提升。文章还定义了公共可验证性，并扩展到即使所有接收者可能被攻击也能保持的强公共可验证性。通过通用转换，作者得到了一个基于类群的非交互式分布式密钥生成方案(cgDKG)，适用于阈值系统。安全分析考虑了公共可验证性对DKG的影响。总的来说，这篇论文展示了类群在构建高效、可验证的密码学协议中的潜力。 <div>
We put forward a non-interactive verifiable secret sharing (NI-VSS) scheme using class groups – we call it cgVSS. Our construction follows the standard framework of encrypting the shares to a set of recipients and generating a non-interactive proof of correct sharing. However, as opposed to prior works, such as Groth’s [Eprint 2021], or Gentry et al.’s [Eurocrypt 2022], we do not require any range proof - this is possible due to the unique structure of class groups, that enables efficient encryption/decryption of large field elements in the exponent of an ElGamal-style encryption scheme. Importantly, this is possible without destroying the additive holomorphic structure, which is required to make the proof-of-correctness highly efficient. This approach not only substantially simplifies the NI-VSS process, but also outperforms the state-of-art schemes significantly. For example, our implementation shows that for a 150 node system cgVSS outperforms (a simplified implementation of) Groth’s protocol in overall communication complexity by 5.6x, about 9.3 − 9.7x in the dealer time and 2.4 − 2.7x in the receiver time per node.

Additionally, we formalize the notion of public verifiability, which enables anyone, possibly outside the participants, to verify the correctness of the dealing. In fact, we re-interpret the notion of public verifiability and extend it to the setting when potentially all recipients may be corrupt and yet can not defy public verifiability – to distinguish from state-of-art, we call this strong public verifiability. Our formalization uses the universal composability framework.

Finally, through a generic transformation, we obtain a non-interactive distributed key generation (NI-DKG) scheme for threshold systems, where the secret key is the discrete log of the public key. Our security analysis in the VSS-hybrid model uses a formalization that considers a (strong) public verifiability notion for DKG, even when more than threshold parties are corrupt. Instantiating with cgVSS we obtain a NI-DKG scheme from class groups – we call it cgDKG.
]]></content:encoded>
<pubDate>Tue, 28 Mar 2023 17:30:50 +0000</pubDate>
</item>
<item>
<title>Asynchronous Consensus without Trusted Setup or Public-Key Cryptography</title>
<link>https://eprint.iacr.org/2024/677</link>
<guid>https://eprint.iacr.org/2024/677</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine共识、异步协议、可信设置、公钥加密、随机 oracle。

总结:<br />
本文研究了无需可信设置和不使用公钥加密的异步拜占庭共识协议。提出了一种基于随机 oracle 的 Asynchronous Common Subset（ACS）协议，具有$O(\kappa n^3)$总通信量和$O(1)$期望轮数。该协议仅依赖于密码哈希函数，因此对量子攻击也安全。与现有实现相比，实验表明该协议更为高效。此外，文中还介绍了新引入的异步秘密密钥共享和覆盖聚集等概念，这些可能独立具有价值。 <div>
Byzantine consensus is a fundamental building block in distributed cryptographic problems. Despite decades of research, most existing asynchronous consensus protocols require a strong trusted setup and expensive public-key cryptography. In this paper, we study asynchronous Byzantine consensus protocols that do not rely on a trusted setup and do not use public-key cryptography such as digital signatures. We give an Asynchronous Common Subset (ACS) protocol whose security is only based on cryptographic hash functions modeled as a random oracle. Our protocol has $O(\kappa n^3)$ total communication and runs in expected $O(1)$ rounds. The fact that we use only cryptographic hash functions also means that our protocol is post-quantum secure. The minimal use of cryptography and the small number of rounds make our protocol practical. We implement our protocol and evaluate it in a geo-distributed setting with up to 128  machines. Our experimental evaluation shows that our protocol is more efficient than the only other setup-free consensus protocol that has been implemented to date. En route to our asynchronous consensus protocols, we also introduce new primitives called asynchronous secret key sharing and cover gather, which may be of independent interest.
]]></content:encoded>
<pubDate>Fri, 03 May 2024 13:40:00 +0000</pubDate>
</item>
<item>
<title>VIMz: Verifiable Image Manipulation using Folding-based zkSNARKs</title>
<link>https://eprint.iacr.org/2024/1063</link>
<guid>https://eprint.iacr.org/2024/1063</guid>
<content:encoded><![CDATA[
<div> 关键词：generative AI, zero-knowledge proofs (ZKP), folding-based zkSNARKs, VIMz, trustless smart contract system

总结:
本文探讨了随着生成式AI技术的发展，媒体真实性验证的需求增加。为确保图像来源的可信度，作者提出了一种名为VIMz的高效可验证图像操纵系统，它利用折叠式zkSNARKs技术降低证明者复杂性。与先前方法相比，VIMz在处理高清和4K图像时，实现了时间速度提升3倍，内存消耗减少96倍（从309GB降至3.2GB）。此外，文章还设计了一个无信任智能合约系统，用于自动验证媒体真实性的证明，支持版权和所有权的透明管理，符合内容可追溯性和真实性联盟（C2PA）标准。这一系统为构建去中心化的媒体市场奠定了基础，具有广泛的应用前景。 <div>
With the rise of generative AI technology, the media's credibility as a source of truth has been significantly compromised. This highlights the need to verify the authenticity of media and its originality.
Ensuring the integrity of media during capture using the device itself presents a straightforward solution to this challenge.
However, raw captured media often require certain refinements or redactions before publication. Zero-knowledge proofs (ZKP) offer a solution by allowing attestation of the correctness of specific transformations applied to an authorized image. While shown to be feasible, previous approaches faced challenges in practice due to their high prover complexity.

In this paper, we aim to develop a practical framework for efficiently proving the authenticity of HD and 4K images on commodity hardware. Our goal is to minimize prover complexity by utilizing the folding-based zkSNARKs technique, resulting in VIMz, the first practical verifiable image manipulation system of this kind. VIMz leverages Nova's folding scheme to achieve low complexity recursive zkSNARK proofs of authentic image manipulation. Our implementation results demonstrate a substantial reduction in prover complexity—up to a 3$\times$ speedup in time and a 96$\times$ reduction in memory (from 309 GB in [Kang et al., arXiv 2022] to only 3.2 GB). Moreover, the low memory consumption allows VIMz to prove the correctness of multiple chained transformations simultaneously, further increasing the performance (up to 3.5$\times$).
Additionally,
we propose a trustless smart contract system that autonomously verifies the proofs of media authenticity, achieving trustless copyright and ownership management, aligning with the standards of the Coalition for Content Provenance and Authenticity (C2PA).
Such a system serves as a foundational infrastructure for constructing trustless media marketplaces with diverse applications.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 13:05:39 +0000</pubDate>
</item>
<item>
<title>Compact Key Function Secret Sharing with Non-linear Decoder</title>
<link>https://eprint.iacr.org/2024/1062</link>
<guid>https://eprint.iacr.org/2024/1062</guid>
<content:encoded><![CDATA[
<div> 关键词：Function Secret Sharing (FSS), Distributed Point Function (DPF), Comparison Function, Interval Function, Key Size.

总结:<br />
本文主要探讨了一种针对点、比较和区间函数的变体Function Secret Sharing (FSS)方案，旨在实现更紧凑的$p$- party（$p \geq 3$）密钥大小。相比于现有构造，该方案显著减少了DPF的密钥大小，降低了$2^p$倍，同时对非线性解码器进行了一次额外的比较操作。对于分布式比较函数，作者实现了史上最小的密钥大小，减少了一个$q^{p-1}$因子，对隐私保护机器学习（PPML）中的应用有实际意义。此外，文章还展示了如何将这种改进应用于神经网络的分布式实现，如分布式ReLU激活函数，证实了新方案的有效性。 <div>
We present a variant of Function Secret Sharing (FSS) schemes tailored for point, comparison, and interval functions, featuring compact key sizes at the expense of additional comparison. While existing FSS constructions are primarily geared towards $2$-party scenarios, exceptions such as the work by Boyle et al. (Eurocrypt 2015) and Riposte (S&amp;P 2015) have introduced FSS schemes for $p$-party scenarios ($p \geq 3$). This paper aims to achieve the most compact $p$-party FSS key size to date. We achieve a noteworthy reduction in key size, a $2^p$-factor decrease compared to state-of-the-art FSS constructions (including computationally efficient constructions using symmetric-key primitives) of distributed point function (DPF). Compared to the previous public-key-based FSS design for DPF, we also get a key size reduction equal to a $2^{n/2}$-sized row vector, where $2^n$ is the domain size of the point function. This reduction in key size comes at the cost of a required comparison operation by the decoder (hence called a non-linear decoder), a departure from prior schemes. In $p$-party scenarios, our construction outperforms existing FSS constructions in key size, remaining on par with Riposte in evaluation time and showing significant improvement over Boyle et al.

In addition to constructing FSS for distributed point functions (DPF), we extend our approach to distributed comparison and interval functions, achieving the most efficient key size to date. Our distributed comparison function exhibits a key-size reduction by a factor of $q^{p-1}$, where $q$ denotes the size of the algebraic group used in the scheme's construction.
The reduced key size of the comparison function has practical implications, particularly in applications like privacy-preserving machine learning (PPML), where thousands of comparison functions are employed in each neural network layer.
To demonstrate the effectiveness of our improvements, we design and prototype-implement a scalable privacy-preserving framework for neural networks over distributed models. Specifically, we implement a distributed rectified linear unit (ReLU) activation function using our distributed comparison function, showcasing the efficacy of our proposed scheme.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 09:03:44 +0000</pubDate>
</item>
<item>
<title>Insta-Pok3r: Real-time Poker on Blockchain</title>
<link>https://eprint.iacr.org/2024/1061</link>
<guid>https://eprint.iacr.org/2024/1061</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式服务、多党计算（MPC）、身份-based加密、公开可验证、在线扑克。

总结: <br />
我们的文章介绍了一种分布式服务，用于为在线扑克玩家生成私密但可公开验证的关联随机性，如洗牌。该服务利用多党计算协议在离线阶段创建一个加密的卡片排列，确保其是卡片的唯一排列。当玩家加入时，他们仅需通过安全渠道获取身份特定的解密密钥并本地解密，简化了在线过程。文章的关键创新在于提出可缩简证明的多身份基加密（SVME），以及一种高效的小集合随机排列的秘密共享生成协议。整个系统在保证实时性和成本效益的同时，提供了信任最小化的在线扑克体验。在实验中，8个MPC参与者为64张牌生成可验证排列仅需3秒，而玩家获取牌只需0.3秒。 <div>
We develop a distributed service for generating correlated randomness (e.g. permutations) for multiple parties, where each party’s output is private but publicly verifiable. This service provides users with a low-cost way to play online poker in real-time, without a trusted party.
Our service is backed by a committee of compute providers, who run a multi-party computation (MPC) protocol to produce an (identity-based) encrypted permutation of a deck of cards, in an offline phase well ahead of when the players’ identities are known. When the players join, what we call the online phase, they decrypt their designated cards immediately after deriving the identity-based decryption keys, a much simpler computation. In addition, the MPC protocol also generates a publicly-verifiable proof that the output is a permutation.
In our construction, we introduce a new notion of succinctly verifiable multi-identity based encryption (SVME), which extends the existing notion of verifiable encryption to a multi-identity-based setting, but with a constant sized proof – this may be of independent interest. We instantiate this for a permutation relation (defined over a small set) along with identity-based encryption, polynomial commitments and succinct proofs – our choices are made to enable a distributed computation when the card deck is always secret shared. Moreover, we design a new protocol to efficiently generate a secret-sharing of random permutation of a small set, which is run prior to distributed SVME.
Running these protocols offline simplifies the online phase substantially, as parties only derive their identity-specific keys privately via secure channels with the MPC committee, and then decrypt locally to obtain their decks. We provide a rigorous UC-based formalization in a highly modularized fashion.
Finally, we demonstrate practicality with an implementation that shows that for 8 MPC parties, gen- erating a secret publicly-verifiable permutation of 64 cards takes under 3 seconds, while accessing cards for a player takes under 0.3 seconds.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 04:27:35 +0000</pubDate>
</item>
<item>
<title>CoGNN: Towards Secure and Efficient Collaborative Graph Learning</title>
<link>https://eprint.iacr.org/2024/987</link>
<guid>https://eprint.iacr.org/2024/987</guid>
<content:encoded><![CDATA[
<div> 关键词：Collaborative Graph Learning, Federated Learning, Secure Machine Learning, Graph Neural Networks, CoGNN.

总结:<br />
本文提出了一种新的框架CoGNN，它结合了联邦学习和安全机器学习在协作图学习中的优点。CoGNN通过一种新的消息传递机制和两阶段Dispatch-Collect执行方案，实现了对图神经网络（GNN）训练和推理的隐私保护、高效计算和可扩展性。实验表明，相比于最先进的安全机器学习方法，CoGNN在运行时间和通信成本上分别减少了123倍和522倍，同时保持了与全局图训练相近的模型精度，甚至在某些情况下提高了11.06%。总的来说，CoGNN为协作图学习提供了一个高效且安全的解决方案。 <div>
Collaborative graph learning represents a learning paradigm where multiple parties jointly train a graph neural network (GNN) using their own proprietary graph data. To honor the data privacy of all parties, existing solutions for collaborative graph learning are either based on federated learning (FL) or secure machine learning (SML). Although promising in terms of efficiency and scalability due to their distributed training scheme, FL-based approaches fall short in providing provable security guarantees and achieving good model performance. Conversely, SML-based solutions, while offering provable privacy guarantees, are hindered by their high computational and communication overhead, as well as poor scalability as more parties participate.

To address the above problem, we propose CoGNN, a novel framework that simultaneously reaps the benefits of both FL-based and SML-based approaches. At a high level, CoGNN is enabled by (i) a novel message passing mechanism that can obliviously and efficiently express the vertex data propagation/aggregation required in GNN training and inference and (ii) a two-stage Dispatch-Collect execution scheme to securely decompose and distribute the GNN computation workload for concurrent and scalable executions. We further instantiate the CoGNN framework, together with customized optimizations, to train Graph Convolutional Network (GCN) models. Extensive evaluations on three graph datasets demonstrate that compared with the state-of-the-art (SOTA) SML-based approach, CoGNN reduces up to $123$x running time and up to $522$x communication cost per party. Meanwhile, the GCN models trained using CoGNN have nearly identical accuracies as the plaintext global-graph training, yielding up to $11.06\%$ accuracy improvement over the GCN models trained via federated learning.
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 04:20:23 +0000</pubDate>
</item>
<item>
<title>Adaptor Signatures: New Security Definition and A Generic Construction for NP Relations</title>
<link>https://eprint.iacr.org/2024/1051</link>
<guid>https://eprint.iacr.org/2024/1051</guid>
<content:encoded><![CDATA[
<div> 关键词：Adaptor Signatures (AS), Witness Hiding, NP relation, One-way Functions, Trapdoor Commitments.

总结:
本文主要探讨了适应性签名(Adaptor Signatures, AS)及其增强的安全特性——隐藏见证。AS最初允许签名者为硬关系实例生成预签名，但早期构造存在缺陷，预签名关联的见证会暴露。为解决这个问题，作者提出了一种新的定义，即“见证隐藏”，并证明在仅依赖单向函数假设下，可以构建AS，满足这一安全属性。文章还提出了一种基于签名和弱型陷阱门承诺（特定可适应消息的陷阱门承诺）的通用构造，通过实例化基于汉密尔顿回路问题，扩展到任何NP关系。这一工作为AS的应用，特别是在区块链等场景，提供了更安全的解决方案。 <div>
An adaptor signatures (AS) scheme is an extension of digital signatures that allows the signer to generate a pre-signature for an instance of a hard relation. This pre-signature can later be adapted to a full signature with a corresponding witness. Meanwhile, the signer can extract a witness from both the pre-signature and the signature. AS have recently garnered more attention due to its scalability and interoperability. Dai et al. [INDOCRYPT 2022] proved that AS can be constructed for any NP relation using a generic construction. However, their construction has a shortcoming: the associated witness is exposed by the adapted signature. This flaw poses limits the applications of AS, even in its motivating setting, i.e., blockchain, where the adapted signature is typically uploaded to the blockchain and is public to everyone.

To address this issue, in this work we augment the security definition of AS by a natural property which we call witness hiding. We then prove the existence of AS for any NP relation, assuming the existence of one-way functions. Concretely, we propose a generic construction of witness-hiding AS from signatures and a weak variant of trapdoor commitments, which we term trapdoor commitments with a specific adaptable message. We instantiate the latter based on the Hamiltonian cycle problem. Since the Hamiltonian cycle problem is NP-complete, we can obtain witness hiding adaptor signatures for any NP relation.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 04:12:15 +0000</pubDate>
</item>
<item>
<title>On Sequential Functions and Fine-Grained Cryptography</title>
<link>https://eprint.iacr.org/2024/1050</link>
<guid>https://eprint.iacr.org/2024/1050</guid>
<content:encoded><![CDATA[
<div> 关键词：sequential functions, one-way functions, oracle separation, continuous iterative sequential functions (CISF), fine-grained cryptography

总结:<br />
这篇文章主要探讨了序列函数（sequential functions）的理论复杂性和其与单向函数的关系。作者展示了存在一个黑盒Oracle，它能证明序列函数的存在但不能证明单向函数的存在，这与通常的构造方式形成对比。文章还深入研究了连续迭代序列函数（CISF）的决策性最坏情况问题，证明其是PSPACE-完全的。此外，通过仅假设非单向CISF，构建了“细粒度”加密和MAC等安全协议。最后，文中定义了称为交换式序列函数的新概念，它可用于实现细粒度密钥交换。这些结果揭示了序列函数在密码学中的潜在应用，即使在不依赖单向函数的情况下。 <div>
A sequential function is, informally speaking, a function $f$ for which a massively parallel adversary cannot compute "substantially" faster than an honest user with limited parallel computation power. Sequential functions form the backbone of many primitives that are extensively used in blockchains such as verifiable delay functions (VDFs) and time-lock puzzles. Despite this widespread practical use, there has been little work studying the complexity or theory of sequential functions.

Our main result is a black-box oracle separation between sequential functions and one-way functions: in particular, we show the existence of an oracle $\mathcal{O}$ that implies a sequential function but not a one-way function. This seems surprising since sequential functions are typically constructed from very strong assumptions that imply one-way functions and also since time-lock puzzles are known to imply one-way functions (Bitansky et al., ITCS '16).

We continue our exploration of the theory of sequential functions. We show that, informally speaking, the decisional, worst-case variant of a certain class of sequential function called a continuous iterative sequential function (CISF) is PSPACE-complete. A CISF is, in a nutshell, a sequential function $f$ that can be written in the form $f \left(k, x \right) = g^{k} \left(x \right)$ for some function $g$ where $k$ is an input determining the number of "rounds" the function is evaluated. We then show that more general forms of sequential functions are not contained in PSPACE relative to a random oracle.

Given these results, we then ask if it is possible to build any interesting cryptographic primitives from sequential functions that are not one-way. It turns out that even if we assume just the existence of a CISF that is not one-way, we can build certain "fine-grained" cryptographic primitives where security is defined similarly to traditional primitives with the exception that it is only guaranteed for some (generally polynomial) amount of time. In particular, we show how to build "fine-grained" symmetric key encryption and "fine-grained" MACs from a CISF. We also show how to build fine-grained public-key encryption from a VDF with a few extra natural properties and indistinguishability obfucsation (iO) for null circuits. We do not assume one-way functions. Finally, we define a primitive that we call a commutative sequential function - essentially a sequential function that can be computed in sequence to get the same output in two different ways - and show that it implies fine-grained key exchange.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 03:36:20 +0000</pubDate>
</item>
<item>
<title>Efficient Secret Sharing for Large-Scale Applications</title>
<link>https://eprint.iacr.org/2024/1045</link>
<guid>https://eprint.iacr.org/2024/1045</guid>
<content:encoded><![CDATA[
<div> 关键词：threshold secret sharing, reconstruction time, ramp secret sharing, adaptive corruptions, distributed generation

总结:<br />
该论文研究了改进的阈值秘密共享方案，特别关注减少消息重建时间。提出了一种新型的$(t,c)$-ramp秘密分享方案，对于高阈值$t$（如$2^{20}$），其重建时间比现有方法快2-7.8倍，从$t=256$开始就有明显改善。新方案基于Cramer等人的框架和Applebaum等人的工作，利用随机带状矩阵构建高效且适应适应性攻击的错误纠正代码。应用上，该技术可降低联邦学习中安全聚合协议的计算成本，同时提供更快的可验证ramp秘密共享和分布式可验证随机函数。总的来说，这项工作显著提升了阈值秘密共享的效率和实用性。 <div>
Threshold secret sharing enables distributing a message to $n$ parties such that no subset of fewer than $t$ parties can learn the message, whereas any subset of at least $t$ parties can recover the message. Despite being a fundamental primitive, secret sharing still suffers from one significant drawback, where its message reconstruction algorithm is computationally expensive for large privacy thresholds $t$. In this paper, we aim to address this significant drawback.

We study general $(t,c)$-ramp secret sharing schemes where the number of parties c needed to reconstruct the secret may be larger than $t$. We present a ramp secret sharing scheme whose reconstruction time is 2-7.8x faster than prior constructions suitable against adversaries that adaptively corrupt parties. For $t = 2^{20}$, our new protocol has reconstruction time of 5 seconds whereas prior work requires nearly half a minute. We see improvements starting from as small as $t = 256$. Furthermore, we obtain correctness threshold as small as $c \ge 1.05t$. To obtain our construction, we first improve the secret sharing frameworks by Cramer et al. (EUROCRYPT'15) and Applebaum et al. (CRYPTO'23) from erasure codes. Our new framework obtains secret sharing schemes that may be used against adversaries with adaptive corruptions while requiring only weaker correctness guarantees from the underlying erasure code with a distributed generation property. Furthermore, our new framework also maintains the linear homomorphism of the prior works. Afterwards, we present a concretely efficient erasure code from random band matrices that satisfies the distributed generation property.

We show that our secret sharing scheme can improve many real-world applications. In secure aggregation protocols for federated learning, we obtain up to 22% reductions in computational cost by replacing Shamir's scheme with our construction. We extend our protocol to obtain a verifiable ramp secret sharing scheme where each party can verify the consistency of the shares. Our new verifiable ramp secret sharing has 8.2-25.2x faster sharing and 2.7-23.2x faster reconstruction time compared to prior works. Finally, we present an improved distributed verifiable random function that may be used for decentralized randomness beacons.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 17:59:50 +0000</pubDate>
</item>
<item>
<title>Byzantine Fault Tolerance with Non-Determinism, Revisited</title>
<link>https://eprint.iacr.org/2024/134</link>
<guid>https://eprint.iacr.org/2024/134</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine fault tolerance (BFT), non-determinism, Block-ND, multivalued Byzantine agreement (MBA), asynchronous setting

总结:
这篇文章主要关注在非确定性环境下改进拜占庭容错（BFT）算法。作者提出了一种新的设计Block-ND，它将交易顺序的共识和状态共识分离，允许在现有的BFT实现基础上进行扩展。Block-ND通过将状态共识降级为多值拜占庭协议（MBA）来处理非确定性，尽管MBA在实践系统中被忽视。文章提供了一个比现有方案更快的MBA构造，并在部分同步和纯异步环境中实现了Block-ND。实验结果显示，Block-ND在91个节点的广域网部署中，其性能损失相对较小，与传统BFT相比具有更好的适应性。 <div>
The conventional Byzantine fault tolerance (BFT) paradigm requires replicated state machines to execute deterministic operations only. In practice, numerous applications and scenarios, especially in the era of blockchains, contain various sources of non-determinism. Despite decades of research on BFT, we still lack an efficient and easy-to-deploy solution for BFT with non-determinism—BFT-ND, especially in the asynchronous setting.
We revisit the problem of BFT-ND and provide a formal and asynchronous treatment of BFT-ND. In particular, we design and implement Block-ND that insightfully separates the task of agreeing on the order of transactions from the task of agreement on the state: Block-ND allows reusing existing BFT implementations; on top of BFT, we reduce the agreement on the state to multivalued Byzantine agreement (MBA), a somewhat neglected primitive by practical systems. Block-ND is completely asynchronous as long as the underlying BFT is asynchronous.
We provide a new MBA construction significantly faster than existing MBA constructions. We instantiate Block-ND in both the partially synchronous setting (with PBFT, OSDI 1999) and the purely asynchronous setting (with PACE, CCS 2022). Via a 91-instance WAN deployment on Amazon EC2, we show that Block-ND has only marginal performance degradation compared to conventional BFT.
]]></content:encoded>
<pubDate>Wed, 31 Jan 2024 03:06:58 +0000</pubDate>
</item>
<item>
<title>Attribute-Based Threshold Issuance Anonymous Counting Tokens and Its Application to Sybil-Resistant Self-Sovereign Identity</title>
<link>https://eprint.iacr.org/2024/1024</link>
<guid>https://eprint.iacr.org/2024/1024</guid>
<content:encoded><![CDATA[
<div> 关键词：self-sovereign identity (SSI), CanDID, privacy-preserving, attribute-based threshold anonymous counting tokens (tACT), Sybil-resistant

总结:<br />
本文探讨了自我主权身份（SSI）系统中的挑战，特别是CanDID方案的局限性。作者提出了可公开验证的属性基阈值匿名计数令牌（tACT），这是一种分布式信任环境下的创新解决方案，旨在增强匿名性和减少用户与发行者交互。tACT通过支持阈值发行、多显示选择性披露和非交互式非转移凭证，构建了一个高效的Sybil攻击抵抗的SSI系统。这个新系统在效率上优于CanDID，支持更多发行者，并实现了一轮并行协议，显著提升了用户隐私和控制性。 <div>
Self-sovereign identity (SSI) systems empower users to (anonymously) establish and verify their identity when accessing both digital and real-world resources, emerging as a promising privacy-preserving solution for user-centric identity management. Recent work by Maram et al. proposes the privacy-preserving Sybil-resistant decentralized SSI system CanDID (IEEE S&amp;P 2021). While this is an important step, notable shortcomings undermine its efficacy. The two most significant among them being the following: First, unlinkability breaks in the presence of a single malicious issuer. Second, it introduces interactiveness, as the users are required to communicate each time with issuers to collect credentials intended for use in interactions with applications. This contradicts the goal of SSI, whose aim is to give users full control over their identities. This paper first introduces the concept of publicly verifiable attribute-based threshold anonymous counting tokens (tACT). Unlike recent approaches confined to centralized settings (Benhamouda et al., ASIACRYPT 2023), tACT operates in a distributed-trust environment. Accompanied by a formal security model and a provably secure instantiation, tACT introduces a novel dimension to token issuance, which, we believe, holds independent interest. Next, the paper leverages the proposed tACT scheme to construct an efficient Sybil-resistant SSI system. This system supports various functionalities, including threshold issuance, unlinkable multi-show selective disclosure, and non-interactive, non-transferable credentials that offer constant-size credentials. Finally, our benchmark results show an efficiency improvement in our construction when compared to CanDID all while accommodating a greater number of issuers and additionally reducing to a one-round protocol that can be run in parallel with all issuers.
]]></content:encoded>
<pubDate>Tue, 25 Jun 2024 11:26:25 +0000</pubDate>
</item>
<item>
<title>Nakamoto Consensus under Bounded Processing Capacity</title>
<link>https://eprint.iacr.org/2023/381</link>
<guid>https://eprint.iacr.org/2023/381</guid>
<content:encoded><![CDATA[
<div> 关键词：Nakamoto共识、Proof-of-Work（PoW）、Proof-of-Stake（PoS）、block production rate、security-performance tradeoff。

总结:<br />
Nakamoto共识协议在有限资源网络中的安全性与性能之间存在经典问题。传统分析忽视了节点处理块的速率限制导致的拥堵。本文提出新的分析方法，揭示了在带宽受限模型中，与经典模型不同，私人攻击不再是最糟情况，而一种名为“逗弄策略”的新攻击更糟。对于PoS，equivocation会加剧拥堵，使得传统PoS NC在高生产率下不安全。为此，作者提出Blanking NC（BlaNC），它能提供与PoW NC相同的抗攻击性，同时解决拥堵问题。 <div>
For Nakamoto's longest-chain consensus protocol, whose proof-of-work (PoW) and proof-of-stake (PoS) variants power major blockchains such as Bitcoin and Cardano, we revisit the classic problem of the security--performance tradeoff: Given a network of nodes with finite communication- and computation-resources, against what fraction of adversary power is Nakamoto consensus (NC) secure for a given block production rate? State-of-the-art analyses of NC fail to answer this question, because their bounded-delay model does not capture the rate limits to nodes' processing of blocks, which cause congestion when blocks are released in quick succession. We develop a new analysis technique to prove a refined security--performance tradeoff for PoW NC in a bounded-capacity model. In this model, we show that, in contrast to the classic bounded-delay model, Nakamoto's private attack is no longer the worst attack, and a new attack we call the teasing strategy, that exploits congestion, is strictly worse. In PoS, equivocating blocks can exacerbate congestion, making traditional PoS NC insecure except at very low block production rates. To counter such equivocation spamming, we present a variant of PoS NC we call Blanking NC (BlaNC), which achieves the same resilience as PoW NC.
]]></content:encoded>
<pubDate>Thu, 16 Mar 2023 06:26:28 +0000</pubDate>
</item>
<item>
<title>Security-Performance Tradeoff in DAG-based Proof-of-Work Blockchain Protocols</title>
<link>https://eprint.iacr.org/2023/1089</link>
<guid>https://eprint.iacr.org/2023/1089</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work（PoW）、Directed Acyclic Graphs（DAGs）、Congestible Blockchain Model（CBM）、Late-Predecessor Attack、Prism、OHIE。

总结:
这篇文章探讨了基于DAG的PoW区块链协议在高吞吐量环境下的安全性和性能。通过引入CBM模型，研究者分析了同时存在的块和复杂依赖如何影响延迟。他们设计了一种攻击策略——late-predecessor攻击，利用块间的依赖延迟诚实块的处理。针对Prism和OHIE两个旨在打破安全性能权衡的协议，研究发现它们在高吞吐量下会面临降级的安全性以及延长的延迟，这类似于传统的链式协议。 <div>
Proof-of-work (PoW) blockchain protocols based on directed acyclic graphs (DAGs) have demonstrated superior transaction confirmation performance compared to their chain-based predecessors. However, it is uncertain whether their security deteriorates in high-throughput settings similar to their predecessors, because their acceptance of simultaneous blocks and complex block dependencies presents challenges for rigorous security analysis.

We address these challenges by analyzing DAG-based protocols via a congestible blockchain model (CBM), a general model that allows case-by-case upper bounds on the block propagation delay, rather than a uniform upper bound as in most previous analyses. CBM allows us to capture two key phenomena of high-throughput settings: (1) simultaneous blocks increase each other's propagation delay, and (2) a block can be processed only after receiving all the blocks it refers to. We further devise a reasonable adversarial block propagation strategy in CBM, called the late-predecessor attack, which exploits block dependencies to delay the processing of honest blocks. We then evaluate the security and performance of Prism and OHIE, two DAG-based protocols that aim to break the security-performance tradeoff, in the presence of an attacker capable of launching the late predecessor attack. Our results show that these protocols suffer from reduced security and extended latency in high-throughput settings similar to their chain-based predecessors.
]]></content:encoded>
<pubDate>Thu, 13 Jul 2023 04:05:02 +0000</pubDate>
</item>
</channel>
</rss>