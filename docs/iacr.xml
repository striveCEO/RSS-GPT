<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Cryptology ePrint Archive</title>
<link>https://eprint.iacr.org/rss/rss.xml</link>

<item>
<title>Information-Theoretic 2-Party Computation from Additive Somewhat Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/273</link>
<guid>https://eprint.iacr.org/2024/273</guid>
<content:encoded><![CDATA[
<div> 关键词：secret key, additive somewhat homomorphic, perfect privacy, server inputs, malicious model.

总结: <br>该研究关注的是秘密关键的加法稍微同态方案，其中客户端拥有完美隐私，即使服务器是计算无界的。文章介绍了一种处理电路乘法的方法，通过将乘法运算交给客户端执行并加密返回结果。另一个特点是2-party协议可以处理包含服务器输入的情况，但服务器隐私依赖于子集和问题的难度，而非信息理论。此外，协议设计允许通过为较小子电路使用独立的加密参数来扩展2PC，保持密文大小在电路增大时不变。在恶意模型中，服务器的正确性可以通过第三方高概率验证，同时保护客户端和服务器的隐私不被验证者获取。 <div>
Two-party computation has been an active area of research since Yao's breakthrough results on garbled circuits. We present secret key additive somewhat homomorphic schemes where the client has perfect privacy (server can be computationally unbounded). Our basic scheme is additive somewhat homomorphic and we give protocols to handle addition and multiplication. In one scheme, the server handles circuit multiplication gates by returning the multiplicands to the client which does the multiplication and sends back the encrypted product. We give a 2-party protocol that 
also incorporates server inputs where the client has perfect privacy. Server privacy is not information-theoretic, but rather depends on hardness of the subset sum problem.
Correctness for the server in the malicious model can be verified by a 3rd party with high probability where the client and server privacy are information-theoretically protected from the verifier. Scaling the 2PC protocol via separate encryption parameters for smaller subcircuits allows the ciphertext size to remain constant as circuit size grows.
]]></content:encoded>
<pubDate>Sun, 18 Feb 2024 23:20:46 +0000</pubDate>
<pubDate>Sun, 18 Feb 2024 23:20:46 +0000</pubDate>
</item>

<item>
<title>Fast, Large Scale Dimensionality Reduction Schemes Based on CKKS</title>
<link>https://eprint.iacr.org/2024/849</link>
<guid>https://eprint.iacr.org/2024/849</guid>
<content:encoded><![CDATA[
<div> 关键词：Artificial Intelligence, Big Data, High-Dimensional Data, Homomorphic Encryption, Dimensionality Reduction.

总结:<br />
这篇文章关注的是在人工智能和大数据时代，如何处理高维度数据的安全存储和高效分析。为了解决这一问题，研究者提出了一种基于CKKS的新型同态加密降维方案（HE-DR）。HE-DR通过修改Rank-Revealing方法使其适应全同态加密，实现了无需传输原始用户数据的加密数据降维，显著提高了安全性和效率。相比于传统方法，HE-DR在计算效率上提升约60-200倍，通信开销减小至1/3。实验显示，即使处理高维度数据，HE-DR的性能依然稳定，计算效率与数据维度的关系趋于平缓，而计算误差保持在极低水平。总的来说，该方案为多方参与的高维数据保护和分析提供了一个有效的解决方案。 <div>
The proliferation of artificial intelligence and big data has resulted in a surge in data demand and increased data dimensionality. This escalation has consequently heightened the costs associated with storage and processing. Concurrently, the confidential nature of data collected by various institutions, which cannot be disclosed due to personal privacy concerns, has exacerbated the challenges associated with data analysis and machine learning model training. Therefore, designing a secure and efficient high-dimensional data reduction method that supports multi-party joint participation becomes critical to solving these problems.

This paper proposes a novel homomorphic encryption dimensionality reduction scheme (HE-DR) based on CKKS, which modifies the Rank-Revealing (RR) method to make it more applicable to fully homomorphic encryption, thereby achieving fast and secure dimension reduction for high-dimensional data. Compared to traditional homomorphic encryption dimensionality reduction schemes, our approach does not transmit the user’s original data to other participants in any format (Ciphertext or Plaintext). Moreover, our method's computational efficiency is nearly $60-200$ times faster than similar algorithms, and the communication overhead is only $1/3$ of theirs. Finally, we have shown that our proposed scheme can preserve its computational efficiency and accuracy even when dealing with high-dimensional data. As dimensionality escalates, the ratio of ciphertext to plaintext computational efficiency plateaus at approximately 5 times, while the computational error (distance between subspaces) remains around $1e^{-11}$
]]></content:encoded>
<pubDate>Thu, 30 May 2024 07:24:18 +0000</pubDate>
</item>
<item>
<title>On Efficient and Secure Compression Modes for Arithmetization-Oriented Hashing</title>
<link>https://eprint.iacr.org/2024/047</link>
<guid>https://eprint.iacr.org/2024/047</guid>
<content:encoded><![CDATA[
<div> 关键词：ZK-SNARKs, Merkle树, Arithmetization-Oriented, PGV模式, Hades blockcipher

总结:<br />
本文探讨了基于AO（Arithmetization-Oriented）的ZK-SNARKs中，使用PGV模式构建高效的FIL（固定输入长度）压缩函数的方法。作者提出了PGV-LC和PGV-ELC两种模式，继承并扩展了经典的Preneel-Govaerts-Vandewalle（PGV）框架，保证了在理想密码模型下的碰撞和预映射抵抗，以及对Merkle树的开放抵抗。通过与流行的Poseidon和其改进版Poseidon2比较，新设计在性能上有所提升，特别是在Groth16 SNARK框架中更快。此外，文章还研究了使用高阶Merkle树的优势，优化了Hades blockcipher与PGV-ELC的组合，显著减少了Merkle树构造和证明生成时间。 <div>
ZK-SNARKs, a fundamental component of privacy-oriented payment systems, identity protocols, or anonymous voting systems, are advanced cryptographic protocols for verifiable computation: modern SNARKs allow to encode the invariants of a program, expressed as an arithmetic circuit, in an appropriate constraint language from which short, zero-knowledge proofs for correct computations can be constructed.

  One of the most important computations that is run through SNARK systems is the verification of Merkle tree (MT) opening proofs, which relies on the evaluation of a fixed-input-length (FIL) cryptographic compression function over binary MTs. 
  As classical, bit-oriented hash functions like SHA-2 are not compactly representable in SNARK frameworks, Arithmetization-Oriented (AO) cryptographic designs have emerged as an alternative, efficient solution.
  
  Today, the majority of AO compression functions are built from the Sponge permutation-based hashing mode. 
  While this approach allows cost savings, compared to blockcipher-based modes, as it does not require key-scheduling, AO blockcipher schedulers are often cheap to compute. 
  Furthermore, classical bit-oriented cryptography has long studied how to construct provably secure compression functions from blockciphers, following the Preneel-Govaerts-Vandewalle (PGV) framework. 
  The potential efficiency gains together with the strong provable security foundations in the classic setting, motivate the study of AO blockcipher-based compression functions.
  
  In this work, we propose PGV-LC and PGV-ELC, two AO blockcipher-based FIL compression modes inspired by and extending the classical PGV approach, offering flexible input and output sizes and coming with provable security guarantees in the AO setting. 
  We prove the collision and preimage resistance in the ideal cipher model, and give bounds for collision and opening resistance over MTs of arbitrary arity.
  
  We compare experimentally the AO PGV-ELC mode over the Hades blockcipher with its popular and widely adopted Sponge instantiation, Poseidon, and its improved variant Poseidon2. 
  Our resulting constructions are up to \(3\times \) faster than Poseidon and \(2\times \) faster than Poseidon2 in native x86 execution, and up to \(50\% \) faster in the Groth16 SNARK framework. 
  
  Finally, we study the benefits of using MTs of arity wider than two, proposing a new strategy to obtain a compact R1CS constraint system in such case.
  In fact, by combining an efficient parametrization of the Hades blockcipher over the PGV-ELC mode, together with an optimal choice of the MT arity, we measured an improvement of up to \(9\times \) in native MT construction time, and up to \(2.5\times \) in proof generation time, compared to Poseidon over binary MTs.
]]></content:encoded>
<pubDate>Thu, 11 Jan 2024 16:37:43 +0000</pubDate>
</item>
<item>
<title>Bringing Order to Chaos: The Case of Collision-Resistant Chameleon-Hashes</title>
<link>https://eprint.iacr.org/2020/403</link>
<guid>https://eprint.iacr.org/2020/403</guid>
<content:encoded><![CDATA[
<div> 关键词：Chameleon-hash functions, Trapdoor, Collision-resistance, Notions, Black-box construction.

总结:<br />
Chameleon-hash函数是一种由Krawczyk和Rabin在2000年NDSS会议上提出的特殊哈希函数，它依赖于公钥，私钥可导致碰撞。这些函数在密码学中有广泛应用，如提升非适应性安全签名到适应性安全。文章探讨了不同的碰撞抵抗概念，指出在某些复杂应用中，实际需求可能未被充分覆盖。研究者重新审视现有理论，分析它们之间的关系，并针对可编辑区块链等应用讨论不同抵抗性的实际影响。此外，他们提出了一种更强大、更理想的碰撞抵抗定义，并提供了一个简单高效的黑盒构造方法来实现这种强抵抗性。 <div>
Chameleon-hash functions, introduced by Krawczyk and Rabin at NDSS 2000, are trapdoor collision-resistant hash-functions parametrized by a public key. If the corresponding secret key is known, arbitrary collisions for the hash function can be efficiently found. Chameleon-hash functions have prominent applications in the design of cryptographic primitives, such as lifting non-adaptively secure signatures to adaptively secure ones. Recently, this primitive also received a lot of attention as a building block in more complex cryptographic applications ranging from editable blockchains to advanced signature and encryption schemes.

We observe that in latter applications various different notions of collision-resistance are used, and it is not always clear if the respective notion does really cover what seems intuitively required by the application. Therefore, we revisit existing collision-resistance notions in the literature, study their relations, and - using the example of the recent redactable blockchain proposals - discuss which practical impact different notions of collision-resistance might have. Moreover, we provide a stronger, and arguably more desirable, notion of collision-resistance than what is known from the literature. Finally, we present a surprisingly simple and efficient black-box construction of chameleon-hash functions achieving this strong notion.
]]></content:encoded>
<pubDate>Mon, 13 Apr 2020 10:27:27 +0000</pubDate>
</item>
<item>
<title>BumbleBee: Secure Two-party Inference Framework for Large Transformers</title>
<link>https://eprint.iacr.org/2023/1678</link>
<guid>https://eprint.iacr.org/2023/1678</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer模型、隐私保护、两党设置、矩阵乘法、非线性激活函数。

总结:<br />
该研究关注大型Transformer模型的隐私保护问题，特别是在两党设置下的私有推理。为此，作者提出BumbleBee，一个专注于速度和通信效率的系统。其贡献包括：<br />
1. 优化的矩阵乘法协议，比先前方法减少80%-90%的通信成本。
2. 针对Transformer模型中使用的非线性激活函数的高效协议，显著提升处理速度并降低80%-95%的通信开销。
3. 对五种Transformer模型进行了广泛测试，证明了BumbleBee的实用性，如使用CPU评估LLaMA-7B模型生成一个token只需约14分钟。
4. 相比Iron (NeurIPS22)有超过一倍的速度优势，且比BOLT (Oakland24)快三倍，同时通信量少十分之一。 <div>
Abstract—Large transformer-based models have realized state- of-the-art performance on lots of real-world tasks such as natural language processing and computer vision. However, with the increasing sensitivity of the data and tasks they handle, privacy has become a major concern during model deployment. In this work, we focus on private inference in two-party settings, where one party holds private inputs and the other holds the model. We introduce BumbleBee, a fast and communication-friendly two- party private transformer inference system. Our contributions are three-fold: First, we propose optimized protocols for matrix multiplication, which significantly reduce communication costs by 80% – 90% compared to previous techniques. Secondly, we develop a methodology for constructing efficient protocols tailored to the non-linear activation functions employed in transformer models. The proposed activation protocols have realized a significant enhancement in processing speed, alongside a remarkable reduction in communication costs by 80% – 95% compared with two prior methods. Lastly, we have performed extensive benchmarks on five transformer models. BumbleBee demonstrates its capability by evaluating the LLaMA-7B model, generating one token in approximately 14 minutes using CPUs. Our results further reveal that BumbleBee outperforms Iron (NeurIPS22) by over an order of magnitude and is three times faster than BOLT (Oakland24) with one-tenth communication.
]]></content:encoded>
<pubDate>Mon, 30 Oct 2023 02:48:51 +0000</pubDate>
</item>
<item>
<title>Faster Asynchronous Blockchain Consensus and MVBA</title>
<link>https://eprint.iacr.org/2024/1108</link>
<guid>https://eprint.iacr.org/2024/1108</guid>
<content:encoded><![CDATA[
<div> 关键词：Blockchain consensus, 2-chain VABA, sMVBA, 2PAC, Super Fast Pipelined Blocks

总结:
本文介绍了一种新的区块链共识协议设计，包括2PAC（两阶段异步共识）和超级快速管道块。2PAC分为两个变体，2PAC$^\text{lean}$具有简洁链路和$9.5\delta$预期延迟，通过减少消息复杂度达到更高的吞吐量；而2PAC$^\text{BIG}$则是最快的异步协议，具有立方级消息复杂度，能在无消息乱序的情况下实现单次决策仅需$4\delta$。超级快速管道块改进了管道块的决策速度，即使在故障节点存在时也能保证低延迟，同时保持一致性。结合这些技术，如s2PAC$^\text{lean}$、s2PAC$^\text{BIG}$和sGradedDAG等协议分别实现了更快的决策时间。 <div>
Blockchain consensus, a.k.a. BFT SMR, are protocols enabling $n$ processes to decide on an ever-growing chain. The fastest known asynchronous one is called 2-chain VABA (PODC'21 and FC'22), and is used as fallback chain in Abraxas* (CCS'23). It has a claimed $9.5\delta$ expected latency when used for a single shot instance, a.k.a. an MVBA.
We exhibit attacks breaking it. Hence, the title of the fastest asynchronous MVBA with quadratic messages complexity goes to sMVBA (CCS'22), with $10\delta$ expected latency.
Our positive contributions are two new and complementary designs.

$\bullet$  2PAC (2-phase asynchronous consensus). It has a simpler and lighter chaining than in previous approaches. Instantiated with either quadratic or cubic phases of voting, it yields:

   2PAC$^\text{lean}$: $+90\%$ throughput and $9.5\delta$ expected latency, with quadratic ($O(n^2)$) messages complexity. In both 2-chain VABA and sMVBA (as if chained, with pipelining), the quorum-certified transactions which were produced in the worst-case 1/3 of views with a slow leader were dumped, so the work was lost. The simpler design of 2PAC inserts such blocks in straight-line in the chain.
Thus, contrary to naive uncle-referencing, this comes with no computational overhead, yielding a net $+50\%$ throughput gain over chained sMVBA. Both the remaining throughput and latency ($-0.5\delta$) gains, come from the lighter interactive construction of proofs of consistency appended to proposed blocks, compared to sMVBA.

   2PAC$^\text{BIG}$: the fastest asynchronous blockchain consensus with cubic ($O(n^3)$) messages complexity. Fault-free single shot MVBA runs decide in just $4\delta$, as soon as no message is delivered more than twice faster than others: GradedDAG (SRDS'23) required furthermore no messages reordering.

$\bullet$  Super Fast Pipelined Blocks. This is an upgrade of previous approaches for pipelining: in 2-chain VABA, Cordial Miners (DISC'23) and GradedDAG, a block pipelined by a leader in the middle of the view had almost twice larger latency than the non-pipelined block. Our design provides a fast path deciding the pipelined block with even smaller latency than the non-pipelined block. The fast delay is guaranteed in all executions with a fair scheduler, but remarkably, whatever the behaviors of faulty processes. Consistency is preserved by a lightweight mechanism, of one threshold signature appended per proposal.
Instantiated with the previous protocols, it yields: s2PAC$^\text{lean}$, with fast decision of pipelined blocks in $4\delta$; s2PAC$^\text{BIG}$, in $3\delta$; and sGradedDAG, in $3\delta$.
]]></content:encoded>
<pubDate>Mon, 08 Jul 2024 00:46:12 +0000</pubDate>
</item>
<item>
<title>FHE-MENNs: Opportunities and Pitfalls for Accelerating Fully Homomorphic Private Inference with Multi-Exit Neural Networks</title>
<link>https://eprint.iacr.org/2024/1099</link>
<guid>https://eprint.iacr.org/2024/1099</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), multi-exit neural networks (MENNs), latency, side-channel attack, cost-benefit analysis.

总结:<br />
本文探讨了在数据隐私日益重要的背景下，利用可完全同态加密（FHE）进行机器学习服务的潜在解决方案。研究者提出了使用多出口神经网络（MENNs）来加速FHE推理，以降低计算成本和时间。文章分析了FHE-MENN推理的延迟、通信、准确性和资源消耗，并介绍了名为TorMENNt的攻击，该攻击能利用用户提前终止计算来实施侧信道攻击，预测图像分类结果。文章还讨论了可能的防御措施及其有效性，并结合成本效益分析，为FHE-MENN的实际应用提供了一条实用路径。 <div>
With concerns about data privacy growing in a connected world, cryptography researchers have focused on fully homomorphic encryption (FHE) for promising machine learning as a service solutions. Recent advancements have lowered the computational cost by several orders of magnitude, but the latency of fully homomorphic neural networks remains a barrier to adoption. This work proposes using multi-exit neural networks (MENNs) to accelerate the FHE inference. MENNs are network architectures that provide several exit points along the depth of the network. This approach allows users to employ results from any exit and terminate the computation early, saving both time and power. First, this work weighs the latency, communication, accuracy, and computational resource benefits of running FHE-based MENN inference. Then, we present the TorMENNt attack that can exploit the user's early termination decision to launch a concrete side-channel on MENNs. We demonstrate that the TorMENNt attack can predict the private image classification output of an image set for both FHE and plaintext threat models. We discuss possible countermeasures to mitigate the attack and examine their effectiveness. Finally, we tie the privacy risks with a cost-benefit analysis to obtain a practical roadmap for FHE-based MENN adoption.
]]></content:encoded>
<pubDate>Fri, 05 Jul 2024 15:56:11 +0000</pubDate>
</item>
<item>
<title>BOLT: Privacy-Preserving, Accurate and Efficient Inference for Transformers</title>
<link>https://eprint.iacr.org/2023/1893</link>
<guid>https://eprint.iacr.org/2023/1893</guid>
<content:encoded><![CDATA[
<div> 关键词：transformers, privacy-preserving, secure multiparty computation (MPC), matrix multiplications, BOLT.

总结:<br />这篇文章主要探讨了Transformer模型广泛应用中信息泄露的问题。为了解决这一问题，作者提出了BOLT（Privacy-preserving Inference Framework for Transformer）框架，它专注于高效处理大规模模型的矩阵乘法和非线性计算。BOLT通过机器学习优化减少了10.91倍的通信成本。实验结果显示，BOLT在各种网络环境下比现有最先进的系统快4.8-9.5倍，同时保持与浮点模型相当的准确性。总的来说，BOLT是一个在保证隐私的同时提升Transformer模型推理效率的关键解决方案。 <div>
The advent of transformers has brought about significant advancements in traditional machine learning tasks. However, their pervasive deployment has raised concerns about the potential leakage of sensitive information during inference. Existing approaches using secure multiparty computation (MPC) face limitations when applied to transformers due to the extensive model size and resource-intensive matrix-matrix multiplications. In this paper, we present BOLT, a privacy-preserving inference framework for transformer models that supports efficient matrix multiplications and nonlinear computations. Combined with our novel machine learning optimizations, BOLT reduces the communication cost by 10.91x. Our evaluation on diverse datasets demonstrates that BOLT maintains comparable accuracy to floating-point models and achieves 4.8-9.5x faster inference across various network settings compared to the state-of-the-art system.
]]></content:encoded>
<pubDate>Sat, 09 Dec 2023 04:31:33 +0000</pubDate>
</item>
<item>
<title>Efficient Universally-Verifiable Electronic Voting with Everlasting Privacy</title>
<link>https://eprint.iacr.org/2024/742</link>
<guid>https://eprint.iacr.org/2024/742</guid>
<content:encoded><![CDATA[
<div> 关键词：universal verifiability、electronic voting、everlasting privacy、linearly-homomorphic signatures、receipt-freeness。

总结:
本文探讨了如何利用线性同态签名在电子投票系统中实现普遍可验证性和永恒隐私。传统的做法涉及公开加密投票和证明，但牺牲了长期隐私。作者提出了一种新方法，通过结合完美隐藏承诺和线性同态签名，既能确保投票过程的公正性（即普遍可验证性），又能保证投票的绝对隐私（即永恒隐私），即使在结果公布和证明发布后也是如此。这种方法的证明有效性基于代数群模型和随机 oracle 模型。这种技术革新为电子投票系统提供了高效且兼顾隐私保护的解决方案。 <div>
Universal verifiability is a must-to-have for electronic voting schemes. It is essential to ensure honest behavior of all the players during the whole process, together with the eligibility. However, it should not endanger the privacy of the individual votes, which is another major requirement.
Whereas the first property prevents attacks during the voting process, privacy of the votes should hold forever, which has been called everlasting privacy.

A classical approach for universal verifiability is to add some proofs together with the encrypted votes, which requires publication of the latter, while eligibility needs a link between the votes and the voters: it definitely excludes long-term privacy. An alternative is the use of perfectly-hiding commitments, on which proofs are published, while ciphertexts are kept private for computing the tally.

In this paper, we show how recent linearly-homomorphic signatures can be exploited for all the proofs, leading to very efficient procedures towards universal verifiability with both strong receipt-freeness and everlasting privacy.
Privacy will indeed be unconditional, after the publication of the results and the proofs, whereas the soundness of the proofs holds in the algebraic group model and the random oracle model.
]]></content:encoded>
<pubDate>Wed, 15 May 2024 20:08:35 +0000</pubDate>
</item>
<item>
<title>Random Beacons in Monte Carlo: Efficient Asynchronous Random Beacon without Threshold Cryptography</title>
<link>https://eprint.iacr.org/2023/1755</link>
<guid>https://eprint.iacr.org/2023/1755</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed random beacon, HashRand, Post-Quantum security, Asynchronous SMR, Communication efficiency.

总结: <br />
HashRand是一种高效、异步的分布式随机信标协议，它仅依赖安全哈希和对称安全通信，以克服现有系统的局限性。该协议具有每节点的平均通信复杂度为$\mathcal{O}(\lambda n \log(n))$比特/信标，显著降低了计算成本，尤其在量子安全方面，通过使用安全哈希函数对抗量子攻击。在一个包含136个节点的全球分布测试环境中，HashRand每分钟能产生78个信标，比Spurt快至少5倍。此外，HashRand的应用实例包括实现了一个Post-Quantum安全的异步SMR协议，对于16个节点的WAN环境，响应率超过135k交易/秒，延迟仅为2.3秒。 <div>
Regular access to unpredictable and bias-resistant randomness is important for applications such as blockchains, voting, and secure distributed computing. Distributed random beacon protocols address this need by distributing trust across multiple nodes, with the majority of them assumed to be honest. Numerous applications across the blockchain space have led to the proposal of several distributed random beacon protocols, with some already implemented. However, many current random beacon systems rely on threshold cryptographic setups or exhibit high computational costs, while others expect the network to be partial or bounded synchronous. To overcome these limitations, we propose HashRand, a computation and communication-efficient asynchronous random beacon protocol that only demands secure hash and pairwise secure channels to generate beacons. HashRand has a per-node amortized communication complexity of $\mathcal{O}(\lambda n \log(n))$ bits per beacon. The computational efficiency of HashRand is attributed to the two orders of magnitude lower time of a one-way Hash computation compared to discrete log exponentiation. Interestingly, besides reduced overhead,  HashRand achieves Post-Quantum security by leveraging the secure Hash function against quantum adversaries, setting it apart from other random beacon protocols that use discrete log cryptography. In a geo-distributed testbed of $n=136$ nodes, HashRand produces 78 beacons per minute, which is at least 5x higher than Spurt [IEEE S\&amp;P'22]. We also demonstrate the practical utility of HashRand by implementing a Post-Quantum secure Asynchronous SMR protocol, which has a response rate of over 135k transactions per second at a latency of $2.3$ seconds over a WAN for $n=16$ nodes.
]]></content:encoded>
<pubDate>Mon, 13 Nov 2023 16:39:12 +0000</pubDate>
</item>
<item>
<title>A Scalable Coercion-resistant Voting Scheme for Blockchain Decision-making</title>
<link>https://eprint.iacr.org/2023/1578</link>
<guid>https://eprint.iacr.org/2023/1578</guid>
<content:encoded><![CDATA[
<div> 关键词：blockchain voting, coercion-resistance, scalability, private differential voting power, liquid democracy

总结:
本文设计了首个可扩展的防胁迫区块链投票方案，支持私人差额投票权和一层液体民主。该方案复杂度为O(n)，其中n为选民数，将球票大小从张等人的Θ(m)减少到Θ(1)，m为专家和/或候选人数量。它保证了球票隐私、可验证性和防胁迫性。实验表明，与VoteAgain相比，该方案在大量选民和高额外球票率选举中的计票速度超过6倍。这项工作有望解决区块链投票中的胁迫问题，并提升系统的效率。 <div>
Typically, a decentralized collaborative blockchain decision-making mechanism is realized by remote voting. To date, a number of blockchain voting schemes have been proposed; however, to the best of our knowledge, none of these schemes achieve coercion-resistance. In particular, for most blockchain voting schemes, the randomness used by the voting client can be viewed as a witness/proof of the actual vote, which enables improper behaviors such as coercion and vote-buying. Unfortunately, the existing coercion-resistant voting schemes cannot be directly adopted in the blockchain context. In this work, we design the first scalable coercion-resistant blockchain voting scheme that supports private differential voting power and 1-layer liquid democracy as introduced by Zhang et al. (NDSS '19). Its overall complexity is $O(n)$, where $n$ is the number of voters. Moreover, the ballot size is reduced from Zhang et al.'s $\Theta(m)$ to $\Theta(1)$, where $m$ is the number of experts and/or candidates. We formally prove that our scheme has ballot privacy, verifiability, and coercion-resistance. We implement a prototype of the scheme and the evaluation result shows that our scheme's tally procedure is more than 6x faster than VoteAgain (USENIX '20) in an election with over 10,000 voters and over 50\% extra ballot rate.

Note: This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.
]]></content:encoded>
<pubDate>Thu, 12 Oct 2023 12:02:44 +0000</pubDate>
</item>
<item>
<title>Faster Lookup Table Evaluation with Application to  Secure LLM Inference</title>
<link>https://eprint.iacr.org/2024/1093</link>
<guid>https://eprint.iacr.org/2024/1093</guid>
<content:encoded><![CDATA[
<div> 关键词：secure two-party computation, lookup tables (LUTs), $\mathsf{ROTL}$, FLUTE, secure LLM inference.

总结:
本文主要关注在大型语言模型的隐私保护下，如何通过安全的两方计算进行模型推理。研究者提出了$\mathsf{ROTL}$，一种针对查找表（LUT）评估的高效安全协议，相比现有最先进方法FLUTE，$\mathsf{ROTL}$在性能上分别有11.6倍和155倍的提升。特别地，$\mathsf{ROTL}$支持算术共享，而FLUTE仅限于布尔共享。文章还优化了FLUTE以支持布尔共享，显著减少了在线性能的带宽需求。这些改进对于保障用户隐私的同时提高大型语言模型的推理效率具有重要意义。 <div>
As large language models (LLMs) continue to gain popularity, concerns about user privacy are amplified, given that the data submitted by users for inference may contain sensitive information. Therefore, running LLMs through secure two-party computation (a.k.a. secure LLM inference) has emerged as a prominent topic. However, many operations in LLMs, such as Softmax and GELU, cannot be computed using conventional gates in secure computation; instead, lookup tables (LUTs) have to be utilized, which makes LUT to be an essential primitive in secure LLM inference.

In this paper, we propose $\mathsf{ROTL}$, a secure two-party protocol for LUT evaluations. Compared with FLUTE (the state-of-the-art LUT presented at  Oakland '23), it achieves upto  11.6$\times$ speedup in terms of overall performance and 155$\times$ speedup in terms of online performance. Furthermore, $\mathsf{ROTL}$ can support arithmetic shares (which is required by secure LLM inference), whereas FLUTE can only support boolean shares. At the heart of $\mathsf{ROTL}$ is a novel protocol for secret-shared rotation, which allows two parties to generate additive shares of the rotated table without revealing the rotation offset. We believe this protocol is of independent interest. Based on $\mathsf{ROTL}$, we design a novel secure comparison protocol; compared with the state-of-the-art, it achieves a 2.4$\times$ bandwidth reduction in terms of online performance. 

To support boolean shares, we further provide an optimization for FLUTE, by reducing its computational complexity from $O(l\cdot n^2)$ to $O(n\log n+l\cdot n)$ and shifting $O(n\log n)$ computation to the preprocessing phase. As a result, compared with FLUTE, it achieves upto 10.8$\times$ speedup in terms of overall performance and 962$\times$ speedup in terms of online performance.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 16:43:48 +0000</pubDate>
</item>
<item>
<title>MatcHEd: Privacy-Preserving Set Similarity based on MinHash</title>
<link>https://eprint.iacr.org/2024/1091</link>
<guid>https://eprint.iacr.org/2024/1091</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), MinHash, Carter-Wegman (CW) hash function, bitwise operations, encrypted set similarity

总结:<br />
文章提出了一种利用MinHash算法和CGGI FHE方案改进的加密集相似性计算方法。传统的FHE比较操作昂贵，尤其是对大量数据。通过引入高效的位级FHE友好的摘要函数(FFD)，替代Carter-Wegman哈希中的模运算，减少了在FHE环境中的复杂性和低效性。这种方法显著减少与直接计算Jaccard相似度所需的比较次数，并且天然支持多CPU和GPU并行处理，适用于隐私保护的文档抄袭检测等场景。总的来说，新方法提高了加密计算效率，降低了计算成本。 <div>
Fully homomorphic encryption (FHE) enables arbitrary computation on encrypted data, but certain applications remain prohibitively expensive in the encrypted domain. As a case in point, comparing two encrypted sets of data is extremely computationally expensive due to the large number of comparison operators required. In this work, we propose a novel methodology for encrypted set similarity inspired by the MinHash algorithm and the CGGI FHE scheme. Doing comparisons in FHE requires comparators and multiplexers or an expensive approximation, which further increases the latency, especially when the goal is to compare two sets of data. The MinHash algorithm can significantly reduce the number of comparisons required by employing a special Carter-Wegman (CW) hash function as a key building block. However, the modulus operation in the CW hash becomes another key bottleneck because the encrypted sub-circuits required to perform the modular reduction are very large and inefficient in an FHE setting. Towards that end, we introduce an efficient bitwise FHE-friendly digest function (FFD) to employ as the cornerstone of our proposed encrypted set-similarity. In a Boolean FHE scheme like CGGI, the bitwise operations can be implemented efficiently with Boolean gates, which allows for faster evaluation times relative to standard Carter-Wegman constructions. Overall, our approach drastically reduces the number of comparisons required relative to the baseline approach of directly computing the Jaccard similarity coefficients, and is inherently parallelizable, allowing for efficient encrypted computation on multi-CPU and GPU-based cloud servers. We validate our approach by performing a privacy-preserving plagiarism detection across encrypted documents.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 02:33:02 +0000</pubDate>
</item>
<item>
<title>PolyFHEmus: Rethinking Multiplication in Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1090</link>
<guid>https://eprint.iacr.org/2024/1090</guid>
<content:encoded><![CDATA[
<div> 关键词：Homomorphic encryption, Cloud computing, Latency, Polynomial multiplication, Accelerated computing.

总结:
这篇文章关注的是同态加密技术在云计算中的应用，这种技术允许在加密数据上进行计算以保护隐私。然而，它面临的主要挑战是高延迟问题，尤其是由于多项式乘法运算效率低下。文章的核心内容是识别了这一瓶颈，并探讨了寻找更高效算法的可能性，以期加速加密计算，从而推动同态加密在实际场景中的广泛应用。通过优化多项式运算，有望降低云计算中隐私保护操作的时间成本，促进该技术的普及和发展。 <div>
Homomorphic encryption is a powerful technology that solves key privacy concerns in cloud computing by enabling computation on encrypted data. However, it has not seen widespread adoption due to prohibitively high latencies. In this article, we identify polynomial multiplication as a bottleneck and investigate alternative algorithms to accelerate encrypted computing.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 01:56:46 +0000</pubDate>
</item>
<item>
<title>HElix: Genome Similarity Detection in the Encrypted Domain</title>
<link>https://eprint.iacr.org/2024/1088</link>
<guid>https://eprint.iacr.org/2024/1088</guid>
<content:encoded><![CDATA[
<div> 关键词：genomics, genome analysis, fully homomorphic encryption, MinHash, bloom filter.

总结:<br />这篇文章探讨了随着基因组学研究的发展，保护用户隐私和数据安全的挑战。作者提出两种基于全同态加密的方法，以在不泄露DNA序列的情况下进行比较。第一种方法是利用MinHash算法检测数据库中是否存在相似序列，另一种则是定制的布隆过滤器用于精确匹配。实验验证了这些方法在不同数据库规模下，无论使用GPU还是CPU云服务器，都能有效实现隐私保护下的基因组分析。 <div>
As the field of genomics continues to expand and more sequencing data is gathered, genome analysis becomes increasingly relevant for many users. For example, a common scenario entails users trying to determine if their DNA samples are similar to DNA sequences hosted in a larger remote repository. Nevertheless, end users may be reluctant to upload their DNA sequences, while the owners of remote genomics repositories are unwilling to openly share their database. To address this challenge, we propose two distinct approaches based on fully homomorphic encryption to preserve the privacy of the genomic data and enable queries directly on ciphertexts. The first is based on the ubiquitous MinHash algorithm and can determine if similar matches exist in the database, while the second involves a bespoke bloom filter construction for determining exact matches. We validate both approaches across various database sizes using both GPU and CPU-based cloud servers.
]]></content:encoded>
<pubDate>Thu, 04 Jul 2024 00:21:09 +0000</pubDate>
</item>
<item>
<title>Randomized Distributed Function Computation with Semantic Communications: Applications to Privacy</title>
<link>https://eprint.iacr.org/2024/1085</link>
<guid>https://eprint.iacr.org/2024/1085</guid>
<content:encoded><![CDATA[
<div> 关键词：randomized distributed function computation, semantic communications, privacy, Wyner's common information, common randomness.

总结: <br />
本文研究了随机分布式函数计算中语义通信的应用，特别是在保证隐私的前提下减少通信负载。主要关注两点：<br />
1. 通过利用语义通信框架，结合远程源编码方法，可以在满足安全和隐私约束时，实现输入序列的随机化模拟，同时保证每个输入序列的地方差分隐私。
2. 文章提供了Wyner共同信息（WCI）的下界，这是协调-随机性速率区域的两个角点之一，该区域定义了随机分布式函数计算的极限。WCI对应于没有共享随机性的场景。
3. 对于连续随机变量，提出了数值方法来计算另一个角点，即无限共享随机性的情况。
4. 实例分析表明，即使在有限共享随机性情况下，语义通信也能显著降低通信需求，优于无失真压缩方法。
5. 结论指出，进一步研究有限共享随机性场景对于优化随机分布式函数计算具有重要意义。 <div>
Randomized distributed function computation refers to remote function computation where transmitters send data to receivers which compute function outputs that are randomized functions of the inputs. We study the applications of semantic communications in randomized distributed function computation to illustrate significant reductions in the communication load, with a particular focus on privacy. The semantic communication framework leverages generalized remote source coding methods, where the remote source is a randomized version of the observed data. Since satisfying security and privacy constraints generally require a randomization step, semantic communication methods can be applied to such function computation problems, where the goal is to remotely simulate a sequence at the receiver such that the transmitter and receiver sequences follow a target probability distribution. Our performance metrics guarantee (local differential) privacy for each input sequence, used in two different distributed function computation problems, which is possible by using strong coordination methods. 

This work provides lower bounds on Wyner's common information (WCI), which is one of the two corner points of the coordination-randomness rate region characterizing the ultimate limits of randomized distributed function computation. The WCI corresponds to the case when there is no common randomness shared by the transmitter and receiver. Moreover, numerical methods are proposed to compute the other corner point for continuous-valued random variables, for which an unlimited amount of common randomness is available. Results for two problems of practical interest illustrate that leveraging common randomness can decrease the communication load as compared to the WCI corner point significantly. We also illustrate that semantic communication gains over lossless compression methods are achieved also without common randomness, motivating further research on limited common randomness scenarios.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 10:52:51 +0000</pubDate>
</item>
<item>
<title>Enabling Complete Atomicity for Cross-chain Applications Through Layered State Commitments</title>
<link>https://eprint.iacr.org/2024/1084</link>
<guid>https://eprint.iacr.org/2024/1084</guid>
<content:encoded><![CDATA[
<div> 关键词：Cross-chain dApps, Complete atomicity, Avalon, State synchronization, Cosmos ecosystem.

总结:<br />Avalon是一个创新的跨链去中心化应用（dApp）交易执行框架，它首次实现了完整的原子性。通过在原生状态之上引入多层状态缓存，Avalon有效地管理状态转换，确保复杂任务的正确执行。对于并发的跨链交易，Avalon不仅解决了链内的冲突，还通过一种新颖的状态同步协议处理不同区块链之间的潜在不一致，实现串行化的跨链执行。Avalon使用Cosmos生态系统的智能合约进行实现，并在实验中展示了其承诺性能，即使在冲突情况下，也具有可接受的延迟和gas消耗。 <div>
Cross-chain Decentralized Applications (dApps) are increasingly popular for their ability to handle complex tasks across various blockchains, extending beyond simple asset transfers or swaps. However, ensuring all dependent transactions execute correctly together, known as complete atomicity, remains a challenge. Existing works provide financial atomicity, protecting against monetary loss, but lack the ability to ensure correctness for complex tasks. In this paper, we introduce Avalon, a transaction execution framework for cross-chain dApps that guarantees complete atomicity for the first time. Avalon achieves this by introducing multiple state layers above the native one to cache state transitions, allowing for efficient management of these state transitions. Most notably, for concurrent cross-chain transactions, Avalon resolves not only intra-chain conflicts but also addresses potential inconsistencies between blockchains via a novel state synchronization protocol, enabling serializable cross-chain execution. We implement Avalon using smart contracts in Cosmos ecosystem and evaluate its commitment performance, demonstrating acceptable latency and gas consumption even under conflict cases.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 07:13:00 +0000</pubDate>
</item>
<item>
<title>Practical Non-interactive Multi-signatures, and a Multi- to Aggregate Signatures Compiler</title>
<link>https://eprint.iacr.org/2024/1081</link>
<guid>https://eprint.iacr.org/2024/1081</guid>
<content:encoded><![CDATA[
<div> 关键词：fNIM, fNIA, $\mathsf{dms}$, multi-to-aggregate compiler, verification time

总结:
本文提出了一种新的高效非交互式多签名方案($\mathsf{dms}$)，解决了现有fNIM的两个关键问题。首先，$\mathsf{dms}$通过添加Schnorr PoPs简化了Boldyreva的对称配对基础fNIM，同时提供了更好的性能和在小群体中的快速验证。其在AGM模型下的安全性证明是主要技术贡献，具有大约128位的DL安全保证。其次，文章介绍了一个简单的编译器$\mathcal{M}to\mathcal{A}$，将任何fNIM转换为适合聚合具有公共前缀消息的fNIA，如Diem中应用$\mathsf{dms}$后的例子，验证速度显著提升。总的来说，$\mathsf{dms}$和$\mathcal{M}to\mathcal{A}$优化了签名效率和安全性，适用于大规模共识协议。 <div>
In a fully non-interactive multi- , resp. aggregate-, signature scheme (fNIM, resp. fNIA), signatures issued by many signers on the same message, resp. on different messages, can be succinctly ``combined'', resp. ``aggregated''.
fNIMs are used in the Ethereum consensus protocol, to produce the certificates of validity of blocks which are to be verified by billions of clients. fNIAs are used in some PBFT-like consensus protocols, such as the production version of Diem by Aptos, to replace the forwarding of many signatures by a new leader. In this work we address three complexity bottlenecks.
(i) fNIAs have larger cost than fNIMs, e.g., we observe that the fNIA of BGLS (Eurocrypt'03) over 3000 signatures, takes 100x longer verification time than a batch verification of 3000 Schnorr signatures.
(ii) fNIMs impose that each verifier processes the setup published by the group of potential signers. This processing consists either in verifying proofs of possession (PoPs), such as in Pixel (Usenix'20) and in the IETF'22 draft inherited from Ristenpart-Yilek (Eurocrypt'07), which costs a product of pairings over all published keys. Or, it consists in re-randomizing the keys, such as in SMSKR (FC'24).
(iii) Existing proven security bounds on efficient fNIMs do not give any guarantee in practical curves with 256bits-large groups, such as BLS12-381 (used in Ethereum) or BLS12-377 (used in Zexe). Thus, computing in much larger curves is required to have provable guarantees.

Our first contribution is a new fNIM called $\mathsf{dms}$, it addresses both (ii) and (iii).
It is as simple as adding Schnorr PoPs to the schoolbook pairing-based fNIM of Boldyreva (PKC'03).
(ii) For a group of 1000 signers, processing these PoPs is $5+$ times faster than for the previous pairing-based PoPs, and $3+$ times faster than the processing of SMSKR, which had furthermore to be done for every new group member. 
(iii) In the algebraic group model (AGM), and given the current estimation of roughly 128 bits of security for the discrete logarithm (DL) in both the curves BLS12-381 and BLS12-377, then we prove a probability of forgery of $\mathsf{dms}$ no higher than about $2^{-93}$ for a time $2^{80}$ adversary.
This proof of security is our main technical contribution. The only related proof before was for an interactive Schnorr-based multi-signature scheme, using Schnorr PoPs. We observe a gap in its proof, which is that the adversary has not access to a signing oracle before publishing its PoPs, although it should have. On the one hand, the gap can easily be fixed in their context. But in our context of pairing-based multi-signatures, the signing oracle produces a correlated random string which significantly complicates our extraction of the keys of the adversary.
We finally provide another application of $\mathsf{dms}$, which is that it can be plugged in recent threshold signatures without setup (presented by Das et al at CCS'23, and Garg et al at SP'24), since these schemes implicitly build on any arbitrary BLS-based fNIM.

Our second contribution addresses (i), it is a very simple compiler: $\mathcal{M}to\mathcal{A}$ (multi-to-aggregate). It turns any fNIM into an fNIA, suitable for aggregation of signatures on messages with a prefix in common, with the restriction that a signer must not sign twice using the same prefix. The obtained fNIA is post-quantum as soon as the fNIM is, such as Chipmunk (CCS'23). We demonstrate the relevance for Diem by applying $\mathcal{M}to\mathcal{A}$ to $\mathsf{dms}$: the resulting fNIA enables to verify 39x faster an aggregate of 129 signatures, over messages with $7$ bits-long variable parts, than BGLS.
]]></content:encoded>
<pubDate>Wed, 03 Jul 2024 02:59:14 +0000</pubDate>
</item>
<item>
<title>GAuV: A Graph-Based Automated Verification Framework for Perfect Semi-Honest Security of Multiparty Computation Protocols</title>
<link>https://eprint.iacr.org/2024/1078</link>
<guid>https://eprint.iacr.org/2024/1078</guid>
<content:encoded><![CDATA[
<div> 关键词：Multiparty Computation (MPC), Security proof, Simulator, Automated framework, Perfect soundness.

总结:<br />
该研究提出了一种通用的自动化框架，用于验证多方计算(MPC)协议在面对半诚实攻击时的完美安全性。该框架具有完美完备性，能证明BGW协议等实例在给定的攻击者设置下的安全性，且能在多项式时间内完成。与仅关注黑盒隐私的传统方法不同，该框架适用于任意MPC协议的验证。通过实现原型，研究展示了其有效性和效率，能在合理时间内自动证明BGW和B2A转换协议的半诚实安全。这种方法简化了MPC协议的安全证明过程，提高了实践中的检测能力。 <div>
Proving the security of a Multiparty Computation (MPC) protocol is a difficult task. Under the current simulation-based definition of MPC, a security proof consists of a simulator, which is usually specific to the concrete protocol and requires to be manually constructed, together with a theoretical analysis of the output distribution of the simulator and corrupted parties' views in the real world. This presents an obstacle in verifying the security of a given MPC protocol. Moreover, an instance of a secure MPC protocol can easily lose its security guarantee due to careless implementation, and such a security issue is hard to detect in practice. 

In this work, we propose a general automated framework to verify the perfect security of instances of MPC protocols against the semi-honest adversary. Our framework has perfect soundness: any protocol that is proven secure under our framework is also secure under the simulation-based definition of MPC. We demonstrate the completeness of our framework by showing that for any instance of the well-known BGW protocol, our framework can prove its security for every corrupted party set with polynomial time. Unlike prior work that only focuses on black-box privacy which requires the outputs of corrupted parties to contain no information about the inputs of the honest parties, our framework may potentially be used to prove the security of arbitrary MPC protocols.

We implement our framework as a prototype. The evaluation shows that our prototype automatically proves the perfect semi-honest security of BGW protocols and B2A (binary to arithmetic) conversion protocols in reasonable durations.
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 16:39:44 +0000</pubDate>
</item>
<item>
<title>Anonymous, Timed and Revocable Proxy Signatures</title>
<link>https://eprint.iacr.org/2023/833</link>
<guid>https://eprint.iacr.org/2023/833</guid>
<content:encoded><![CDATA[
<div> 关键词：proxy signature, anonymity, timed delegation, revocability, blockchain

总结:<br />该文章提出了一种新的匿名、定时和可撤销的代理签名方案，填补了现有技术在满足时间限制、匿名性、撤销权限和政策执行等多方面需求上的空白。首先，通过基于Schnorr签名的可分割数字签名，实现安全的签名人身份令牌分配。其次，利用区块链作为公共公告板，结合时间锁定加密技术，确保签名人只能一次性使用令牌、在指定时间内代理签署以及在需要时撤销委托，同时保持全程去中心化和匿名性。文章还定义了代理签名的统一形式化概念，并证明了该方案符合这一概念，同时讨论了实际部署中的设计考量。 <div>
A proxy signature enables a party to delegate her signing power to another. This is useful in practice to achieve goals related to robustness, crowd-sourcing, and workload sharing. Such applications, especially in the blockchain model, usually require delegation to satisfy several properties, including time bounds, anonymity, revocability, and policy enforcement. Despite the large amount of work on proxy signatures in the literature, none of the existing schemes satisfy all these properties; even there is no unified formal notion that captures them. 

In this work, we close this gap and propose an anonymous, timed, and revocable proxy signature scheme. We achieve this in two steps: First, we introduce a tokenizable digital signature based on Schnorr signature allowing for secure distribution of signing tokens. Second, we utilize a public bulletin board, instantiated as a blockchain, and timelock encryption to support: (1) one-time usage of the signing tokens by tracking tokens used so far based on unique values associated to them, (2) timed delegation so that a proxy signer cannot sign outside a given period, and (3) delegation revocation allowing the original signer to end a delegation earlier than provisioned. All of these are done in a decentralized and anonymous way so that no one can tell that someone else signed on behalf of the original signer or even that a delegation took place. We define a formal notion for proxy signatures capturing all these properties, and prove that our construction realizes this notion. We also discuss several design considerations addressing issues related to deployment in practice.
]]></content:encoded>
<pubDate>Mon, 05 Jun 2023 11:15:33 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Dijkstra</title>
<link>https://eprint.iacr.org/2024/988</link>
<guid>https://eprint.iacr.org/2024/988</guid>
<content:encoded><![CDATA[
<div> 关键词：secret-sharing, adjacency list, $d$-normalized, oblivious conversion, secure operations

总结:
这篇文章介绍了一种方法，将秘密共享的邻接列表图形转换为更适用于多方计算（MPC）的$d$-规范化表示。这个过程分为两步：首先，安全地将节点重命名，从任意字符串转换为1到$V$的整数，以保持排序，这需要$O(\log V)$轮和$O((V+E)\log V)$次安全操作。其次，对已排序的整数节点进行$d$-规范化，仅需$O(1)$轮和$O(V+E)$次操作。这种转换有助于设计隐私保护的Dijkstra算法，实现$(V+E) \cdot \log V$次安全操作和$V \cdot \log V \cdot \log \log\log V$轮的复杂度。这种方法适用于常数数量的服务器，并适用于任何邻接列表表示，只要节点标签和权重能适应固定内存字节数。 <div>
Given a graph $G(V,E)$, represented as a secret-sharing of an adjacency list, we show how to obliviously convert it into an alternative, MPC-friendly secret-shared representation, so-called $d$-normalized replicated adjacency list (which we abbreviate to $d$-normalized), where the size of our new data-structure is only 4x larger -- compared to the original (secret-shared adjacency list) representation of $G$. Yet, this new data structure enables us to execute oblivious graph algorithms that simultaneously improve underlying graph algorithms' round, computation, and communication complexity. Our $d$-normalization proceeds in two steps: 

First, we show how for any graph $G$, given a secret-shared adjacency list, where vertices are arbitrary alphanumeric strings that fit into a single RAM memory word, we can efficiently and securely rename vertices to integers from $1$ to $V$  that will appear in increasing order in the resulting secret-shared adjacency list. The secure renaming takes $O(\log V)$ rounds and $O((V+E)\log V)$ secure operations. Our algorithm also outputs two secret-shared arrays: a mapping from integers to alphanumeric names and its sorted inverse. Of course, if the adjacency list is already in such a format, this step could be omitted.

Second, given a secret-shared adjacency list for any graph $G$, where vertices are integers from $1$ to $V$ and are sorted, we show an oblivious $d$-normalization algorithm that takes $O(1)$ rounds and $O(V+E)$ secure operations.

We believe that both conversions are of independent interest. We demonstrate the power of our data structures by designing a privacy-preserving Dijkstra's single-source shortest-path algorithm that simultaneously achieves $O((V +E) \cdot \log V)$ secure operations and   $O(V \cdot \log V \cdot  \log \log\log V)$ rounds. Our secure Dijkstra algorithm works for any adjacency list representation as long as all vertex labels and weights can individually fit into a constant number of RAM memory words. Our algorithms work for two or a constant number of servers in the honest but curious setting.  The limitation of our result (to only a constant number of servers) is due to our reliance on linear work and constant-round secure shuffle.
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 08:02:46 +0000</pubDate>
</item>
<item>
<title>A $3$-Round Near-Linear Third-Party Private Set Intersection Protocol</title>
<link>https://eprint.iacr.org/2024/566</link>
<guid>https://eprint.iacr.org/2024/566</guid>
<content:encoded><![CDATA[
<div> 关键词：private set intersection（私密集合交集）、third-party PSI、communication rounds（通信轮数）、computational complexity（计算复杂性）、post-quantum security（后量子安全）。

总结:<br />
本文提出了一种高效的第三方私密集合交集协议，仅需3轮通信，显著降低了计算工作量。该协议适用于对效率有高要求的真实世界应用，如接触者追踪，同时保护隐私。其算法改进和新技巧的应用使得计算复杂度达到近线性，即$O(n^{1+\varepsilon})$，适用于大数据集。此外，文章还首次探讨了第三方私密集合交集的基数功能，即仅第三方获知交集大小，而无其他信息。此基数功能的实现具有近线性计算复杂度。这些改进和创新为后量子时代的隐私保护提供了新的解决方案。 <div>
Third-party private set intersection (PSI) enables two parties, each holding a private set to compute their intersection and reveal the result only to an inputless third party. In this paper, we present an efficient third-party PSI protocol requiring only 3 communication rounds, while significantly lowering the computational workload compared to prior work. Our work is motivated by real-world applications such as contact tracing whereby expedition is essential while concurrently preserving privacy. Our construction attains a near-linear computational complexity of $O(n^{1+\varepsilon})$ for large dataset size $n$, where $\varepsilon>0$ is any fixed constant, and achieves post-quantum security. Our improvements stem from algorithmic changes and the incorporation of new techniques along with precise parameter selections to achieve a tight asymptotic bound. Furthermore, we also present a third-party PSI cardinality protocol which has not been explored in prior third-party PSI work. In a third-party PSI cardinality setting, only the third-party obtains the size of the intersection and nothing else. Our construction to achieve the cardinality functionality attains a quasilinear computational complexity for the third-party.
]]></content:encoded>
<pubDate>Fri, 12 Apr 2024 03:33:48 +0000</pubDate>
</item>
<item>
<title>Securely Training Decision Trees Efficiently</title>
<link>https://eprint.iacr.org/2024/1077</link>
<guid>https://eprint.iacr.org/2024/1077</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation (MPC), Decision Tree, Communication Complexity, Protocol, MP-SPDZ Framework

总结: <br />
该研究专注于改进决策树的隐私保护训练方法，利用secure multi-party computation (MPC)技术。文章的主要贡献在于提出了一种新的协议，将通信复杂度从$\mathcal{O}(hmN\log N)$降低到$\mathcal{O}(mN\log N + hmN + hN\log N)$，相比先前工作约减少了$\mathsf{min}(h, m, \log N)$。核心创新是一个能保持元素相对顺序的高效排序和分组方法。通过在MP-SPDZ框架中的实现，新协议比现有状态-of-the-art节省了10倍的通信并快9倍。这为处理大规模、高维度数据集的隐私保护决策树训练提供了更有效的解决方案。 <div>
Decision trees are an important class of supervised learning algorithms. When multiple entities contribute data to train a decision tree (e.g. for fraud detection in the financial sector), data privacy concerns necessitate the use of a privacy-enhancing technology such as secure multi-party computation (MPC) in order to secure the underlying training data. Prior state-of-the-art (Hamada et al.)  construct an MPC protocol for decision tree training with a communication of $\mathcal{O}(hmN\log N)$, when building a decision tree of height $h$ for a training dataset of $N$ samples, each having $m$ attributes.

In this work, we significantly reduce the communication complexity of secure decision tree training. 
We construct a protocol with communication complexity $\mathcal{O}(mN\log N + hmN + hN\log N)$, thereby achieving an improvement of $\approx \mathsf{min}(h, m, \log N)$ over Hamada et al. 
At the core of our technique is an improved protocol to regroup sorted private elements further into additional groups (according to a flag vector) while maintaining their relative ordering. We implement our protocol in the MP-SPDZ framework and show that it requires $10\times$ lesser communication and is $9\times$ faster than the state-of-the-art.
]]></content:encoded>
<pubDate>Tue, 02 Jul 2024 07:55:04 +0000</pubDate>
</item>
<item>
<title>Secret Key Recovery in a Global-Scale End-to-End Encryption System</title>
<link>https://eprint.iacr.org/2024/887</link>
<guid>https://eprint.iacr.org/2024/887</guid>
<content:encoded><![CDATA[
<div> 关键词：End-to-end encryption, Messaging applications, Decryption keys, Secure Value Recovery 3 (SVR3), Heterogeneous enclaves.

总结:<br />文章讨论了端到端加密消息应用中用户面临的一个挑战：如果丢失设备且无法访问解密密钥，将无法访问账户。为解决这个问题，Secure Value Recovery 3 (SVR3)被提出，它是一种秘密密钥恢复系统，通过在不同云提供商管理的不同硬件安全隔间（enclaves）之间分散信任，保护用户的解密密钥。SVR3是首个跨异构隔间部署的密钥恢复系统，降低了单一隔间成为攻击目标的风险。该系统利用回滚保护和故障 tolerance 技术适应隔间的安全性。SVR3的年度成本为0.0025美元/用户，用户恢复密钥的时间为365毫秒，这是一个罕见的操作。SVR3已在一个支持数亿真实用户的部署中实施，显示出处理大规模用户的能力。 <div>
End-to-end encrypted messaging applications ensure that an attacker cannot read a user's message history without their decryption keys. While this provides strong privacy, it creates a usability problem: if a user loses their devices and cannot access their decryption keys, they can no longer access their account. To solve this usability problem, users should be able to back up their account information with the messaging provider. For privacy, this backup should be encrypted and the provider should not have access to users' decryption keys. To solve this problem, we present Secure Value Recovery 3 (SVR3), a secret key recovery system that distributes trust across different types of hardware enclaves run by different cloud providers in order to protect users' decryption keys. SVR3 is the first deployed secret key recovery system to split trust across heterogeneous enclaves managed by different cloud providers: this design ensures that a single type of enclave does not become a central point of attack. SVR3 protects decryption keys via rollback protection and fault tolerance techniques tailored to the enclaves' security guarantees. SVR3 costs \$0.0025/user/year and takes 365ms for a user to recover their key, which is a rare operation. A part of SVR3 has been rolled out to millions of real users in a deployment with capacity for over 500 million users, demonstrating the ability to operate at scale.
]]></content:encoded>
<pubDate>Mon, 03 Jun 2024 17:04:58 +0000</pubDate>
</item>
<item>
<title>Improved Multi-Party Fixed-Point Multiplication</title>
<link>https://eprint.iacr.org/2024/1047</link>
<guid>https://eprint.iacr.org/2024/1047</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、机器学习、多党安全计算、固定点乘法、秘密分享。

总结:<br />
本文研究了在多服务器（$N \geq 3$）环境下进行隐私保护的机器学习问题。作者设计了新的多党安全固定点乘法协议，适用于三种秘密分享形式：复制、Shamir和加性共享，针对半诚实攻击提供安全保证。对于复制共享，还提出了一种对抗恶意攻击的高效协议。这些协议提高了通信效率，用于构建支持加法和固定点乘法（带截断）的任意算术电路的多党计算（MPC）协议。所有协议均基于标准的模拟安全性定义得到证明。其中，复制和Shamir共享协议需要至少一半服务器是诚实的，而加性共享协议可以容忍多数恶意行为。 <div>
Machine learning is widely used for a range of applications and is increasingly offered as a service by major technology companies. However, the required massive data collection raises privacy concerns during both training and inference. Privacy-preserving machine learning aims to solve this problem. In this setting, a collection of servers secret share their data and use secure multi-party computation to train and evaluate models on the joint data. All prior work focused on the scenario where the number of servers is two or three. In this work, we study the problem where there are $N \geq 3$ servers amongst whom the data is secret shared. 

A key component of machine learning algorithms is to perform fixed-point multiplication with truncation of secret shared decimal values. In this work, we design new protocols for multi-party secure fixed-point multiplication where each of the $N$ parties have one share each of the two values to be multiplied and receive one share of the product at the end of the protocol. We consider three forms of secret sharing - replicated, Shamir, and additive, and design an efficient protocol secure in the presence of a semi-honest adversary for each of the forms. Our protocols are more communication efficient than all prior work on performing multi-party fixed-point multiplication. Additionally, for replicated secret sharing, we design another efficient protocol that is secure in the presence of a malicious adversary. Finally, we leverage our fixed-point multiplication protocols to design secure multi-party computation (MPC) protocols for arbitrary arithmetic circuits that have addition and fixed-point multiplication with truncation gates. All our protocols are proven secure using a standard simulation based security definition. Our protocols for replicated and Shamir sharing work in the presence of an honest majority of parties while the one for additive sharing can tolerate a dishonest majority as well.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 21:16:25 +0000</pubDate>
</item>
<item>
<title>Message Latency in Waku Relay with Rate Limiting Nullifiers</title>
<link>https://eprint.iacr.org/2024/1073</link>
<guid>https://eprint.iacr.org/2024/1073</guid>
<content:encoded><![CDATA[
<div> 关键词: Waku, GossipSub, Rate Limiting Nullifiers (RLN), message propagation latency, decentralized messaging

总结:
Waku是一种注重隐私、通用和去中心化的消息传递协议。它结合了GossipSub（用于路由）和RLN（防止垃圾信息）技术。本文通过理论分析、大规模单节点模拟和多节点全球部署实验，评估了Waku的消息传播延迟。实验结果证实，中等大小（25 KB）的消息能在1秒内送达，满足像去中心化通信这样的应用场景需求。Waku在保证匿名性和可扩展性的同时，实现了满意的延迟性能。 <div>
Waku is a privacy-preserving, generalized, and decentralized messaging protocol suite. Waku uses GossipSub for message routing and Rate Limiting Nullifiers (RLN) for spam protection. GossipSub ensures fast and reliable peer-to-peer message delivery in a permissionless environment, while RLN enforces a common publishing rate limit using zero-knowledge proofs.

This paper presents a practical evaluation of message propagation latency in Waku. First, we estimate latencies analytically, building a simple mathematical model for latency under varying conditions. Second, we run a large-scale single-host simulation with 1000 nodes. Third, we set up a multi-host Waku deployment using five nodes in different locations across the world. Finally, we compare our analytical estimations to the results of the simulation and the real-world measurement.

The experimental results are in line with our theoretical model. Under realistic assumptions, medium-sized messages (25 KB) are delivered within 1 second. We conclude that Waku can achieve satisfactory latency for typical use cases, such as decentralized messengers, while providing scalability and anonymity.
]]></content:encoded>
<pubDate>Mon, 01 Jul 2024 19:43:18 +0000</pubDate>
</item>
<item>
<title>Exploiting Internal Randomness for Privacy in Vertical Federated Learning</title>
<link>https://eprint.iacr.org/2024/671</link>
<guid>https://eprint.iacr.org/2024/671</guid>
<content:encoded><![CDATA[
<div> 关键词：Vertical Federated Learning (VFL), Differential Privacy (DP), Variational Autoencoder (VAE), Empirical Local Differential Privacy (dELDP), Privacy Attacks.

总结:<br />
本文主要探讨了在Vertical Federated Learning (VFL)中，如何利用Variational Autoencoder (VAE)的内在随机性增强隐私保护。作者提出了一种新的差分隐私估计方法，称为距离基局部差分隐私(dELDP)，用于量化模型或模型组件的隐私参数。通过实验，dELDP在VAE中的应用显示出高达ε ≈ 6.4和δ = 2^{-32}的隐私值。研究发现，包含VAE的VFL系统对特征重建攻击具有稳健性，并且在对手拥有75%特征的标签推断攻击中，相比其他隐私增强方法表现出色。这表明，利用VAE的内部随机性可以在保持一定性能的同时提供有效的隐私保护。 <div>
Vertical Federated Learning (VFL) is becoming a standard collaborative learning paradigm with various practical applications. Randomness is essential to enhancing privacy in VFL, but introducing too much external randomness often leads to an intolerable performance loss. Instead, as it was demonstrated for other federated learning settings, leveraging internal randomness —as provided by variational autoencoders (VAEs) —can be beneficial. However, the resulting privacy has never been quantified so far, nor has the approach been investigated for VFL.
We therefore propose a novel differential privacy (DP) estimate, denoted as distance-based empirical local differential privacy (dELDP). It allows us to empirically bound DP parameters of models or model components, quantifying the internal randomness with appropriate distance and sensitivity metrics. We apply dELDP to investigate the DP of VAEs and observe values up to ε ≈ 6.4 and δ = 2−32. Based on this, to link the dELDP parameters to the privacy of VAE-including VFL systems in practice, we conduct comprehensive experiments on the robustness against state-of-the-art privacy attacks. The results illustrate that the VAE system is robust against feature reconstruction attacks and outperforms other privacy-enhancing methods for VFL, especially when the adversary holds 75% of the features during label inference attacks.
]]></content:encoded>
<pubDate>Thu, 02 May 2024 11:08:22 +0000</pubDate>
</item>
<item>
<title>Decentralized Multi-Client Functional Encryption with Strong Security</title>
<link>https://eprint.iacr.org/2024/764</link>
<guid>https://eprint.iacr.org/2024/764</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Multi-Client Functional Encryption (DMCFE), Inner Products, Function-Hiding, Random Oracle Model, Security Guarantees.

总结:
本文探讨了去中心化的多客户端功能加密（DMCFE）的新构造，特别关注于内积函数的保密性。作者提出了一种新的证明方法，为这一构造提供了强大的随机 Oracle 模型下的安全保证。与之前仅在选择性攻击下证明安全性的构造不同，这个新方案允许对手进行适应性查询，包括带有重复消息标签的挑战密文和固定数量重复密钥标签的挑战密钥。这增加了对敏感函数（如机器学习模型）的保护。总的来说，研究者通过改进技术增强了多客户端功能加密在实际应用中的安全性。 <div>
Decentralized Multi-Client Functional Encryption (DMCFE) extends the basic functional encryption to multiple clients that do not trust each other. They can independently encrypt the multiple plaintext-inputs to be given for evaluation to the function embedded in the functional decryption key, defined by multiple parameter-inputs. And they keep control on these functions as they all have to contribute to the generation of the functional decryption keys. Tags can be used in the ciphertexts and the keys to specify which inputs can be combined together. As any encryption scheme, DMCFE provides privacy of the plaintexts. But the functions associated to the functional decryption keys might be sensitive too (e.g. a model in machine learning). The function-hiding property has thus been introduced to additionally protect the function evaluated during the decryption process.

  In this paper, we provide new proof techniques to analyze a new concrete construction of function-hiding DMCFE for inner products, with strong security guarantees in the random oracle model: the adversary can adaptively query multiple challenge ciphertexts and multiple challenge keys, with unbounded repetitions of the same message tags in the ciphertext-queries and a fixed polynomially-large number of repetitions of the same key tags in the key-queries, allowing static corruption of the secret encryption keys. Previous constructions were proven secure in the selective setting only.
]]></content:encoded>
<pubDate>Sun, 19 May 2024 17:14:22 +0000</pubDate>
</item>
<item>
<title>SECDSA: Mobile signing and authentication under classical ``sole control''</title>
<link>https://eprint.iacr.org/2021/910</link>
<guid>https://eprint.iacr.org/2021/910</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子签名、eIDAS、智能卡、移动平台、独控制。

总结:<br />该文章探讨了2014年欧洲eIDAS法规对电子签名和强电子认证的要求，特别是关于“独控制”的变化。传统的智能卡通过用户直接与依赖方交互实现独控制，但eIDAS允许将用户互动外包给中间服务，如移动应用。然而，移动设备的加密硬件有限，无法支持复杂的密钥控制（如PIN）。作者提出一种新的设计，旨在为标准移动平台提供类似智能卡的独控制，满足eIDAS的严格要求。此外，文章还提及了基于SECDSA的欧洲数字身份钱包方案，这是eIDAS更新的一部分。这种设计确保即使在使用移动设备时，也能保持用户对电子签名的独控制，增强电子交易的安全性。 <div>
The 2014 European eIDAS regulation regulates strong electronic authentication and legally binding electronic signatures. Both require user "sole control". Historically smartcards are used based on direct interaction between user and relying party. Here sole control is provided by giving users both physical possession and control of the cryptographic key used for signing/authentication through a PIN.
Such **classical** sole control is required in the 1999 electronic signature directive by some interpretations.
The eIDAS regulation repeals the directive and explicitly relaxes its sole control requirements in a trade-off between security and usability.
This allows user interaction to be outsourced to intermediary parties (authentication providers, signing services). This also allows mobile applications as user friendly alternatives for smartcards. However, current mobile platforms are only equipped with limited cryptographic hardware not supporting secure knowledge factors (PINs) controlling keys. The eIDAS relaxation raises concerns on sole control; intermediary parties should not be able to act as man-in-the-middle and impersonate users. In this paper we present a simple cryptographic design for signing and authentication on standard mobile platforms providing classical sole control. We argue that our design can meet the highest eIDAS requirements, effectively introducing a new signature category in a 2016 decision of the European Commission.
We also sketch a SECDSA based implementation of the European Digital Identity Wallet recently proposed by the European Commission as part of the eIDAS regulation update.
]]></content:encoded>
<pubDate>Mon, 05 Jul 2021 18:55:07 +0000</pubDate>
</item>
<item>
<title>$\textsf{Asterisk}$: Super-fast MPC with a Friend</title>
<link>https://eprint.iacr.org/2023/1098</link>
<guid>https://eprint.iacr.org/2023/1098</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure multiparty computation (MPC), Dishonest majority, Helper party (HP), Fairness, Asterisk framework.

总结:<br />
这篇文章探讨了在存在恶意多数方的多方计算(MPC)中，引入一个半诚实、非协作的辅助 party（HP）以提高效率和保障安全性的可能性。作者设计并实现了一个名为Asterisk的高效通用多党框架，它仅需少量调用HP，实现了公平性保障，适用于数百个参与者，且在预处理和在线时间上都优于现有协议，甚至能与诚实多数情况下的协议竞争。实验表明，Asterisk在预处理速度上比最佳方案快228-288倍，能支持大规模电路的快速计算，并成功应用于暗池实例，展示了其在实际应用中实现隐私保护的强大能力。 <div>
Secure multiparty computation$~$(MPC) enables privacy-preserving collaborative computation over sensitive data held by multiple mutually distrusting parties. Unfortunately, in the most natural setting where a majority of the parties are maliciously corrupt$~$(also called the $\textit{dishonest majority}$ setting), traditional MPC protocols incur high overheads and offer weaker security guarantees than are desirable for practical applications. In this paper, we explore the possibility of circumventing these drawbacks and achieving practically efficient dishonest majority MPC protocols with strong security guarantees by assuming an additional semi-honest, non-colluding helper party $\mathrm{HP}$. We believe that this is a more realistic alternative to assuming an honest majority, since many real-world applications of MPC involving potentially large numbers of parties$~$(such as dark pools) are typically enabled by a central governing entity that can be modeled as the $\mathrm{HP}$.

    In the above model, we are the first to design, implement and benchmark a practically-efficient and general multi-party framework, $\textsf{Asterisk}$. Our framework requires invoking $\mathrm{HP}$ only a constant number of times, achieves the strong security guarantee of $\textit{fairness}$ (either all parties learn the output or none do), scales to hundreds of parties, outperforms all existing dishonest majority MPC protocols, and is, in fact, competitive with state-of-the-art honest majority MPC protocols. Our experiments show that $\textsf{Asterisk}$ achieves $228-288\times$ speedup in preprocessing as compared to the best dishonest majority MPC protocol. With respect to online time, $\textsf{Asterisk}$ supports $100$-party evaluation of a circuit with $10^6$ multiplication gates in approximately $20$ seconds. We also implement and benchmark practically efficient and highly scalable dark pool instances using $\textsf{Asterisk}$. The corresponding run times showcase the effectiveness of $\textsf{Asterisk}$ in enabling efficient realizations of real-world privacy-preserving applications with strong security guarantees.
]]></content:encoded>
<pubDate>Fri, 14 Jul 2023 05:44:23 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proofs of Training for Deep Neural Networks</title>
<link>https://eprint.iacr.org/2024/162</link>
<guid>https://eprint.iacr.org/2024/162</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、深度神经网络（DNN）、迭代训练、GKR风格证明系统、证明大小和验证器时间。

总结:<br />
\name是一种专为深度神经网络设计的零知识证明（zkPoT），旨在保证隐私、效率和简洁性。它允许证人通过梯度下降迭代训练模型，每次迭代后生成一个证明，证明模型参数的正确性。文章的核心贡献包括：1）提出优化的GKR风格证明系统，降低证人成本；2）开发通用框架，实现多轮GKR证明的高效组合；3）实证表明，\name能处理大规模模型如VGG-11，证明大小仅1.63MB，验证器运行时间低至130毫秒，独立于迭代次数和数据集大小，显著提高效率。 <div>
A zero-knowledge proof of training (zkPoT) enables a party to prove that they have correctly trained a committed model based on a committed dataset without revealing any additional information about the model or the dataset. An ideal zkPoT should offer provable security and privacy guarantees, succinct proof size and verifier runtime, and practical prover efficiency. In this work, we present \name, a zkPoT targeted for deep neural networks (DNNs) that achieves all these goals at once. Our construction enables a prover to iteratively train their model via (mini-batch) gradient descent, where the number of iterations need not be fixed in advance; at the end of each iteration, the prover generates a commitment to the trained model parameters attached with a succinct zkPoT, attesting to the correctness of the executed iterations. The proof size and verifier time are independent of the number of iterations.

Our construction relies on two building blocks. First, we propose an optimized GKR-style (sumcheck-based) proof system for the gradient-descent algorithm with concretely efficient prover cost; this allows the prover to generate a proof for each iteration. We then show how to recursively compose these proofs across multiple iterations to attain succinctness. As of independent interest, we propose a generic framework for efficient recursive composition of GKR-style proofs, along with aggregatable polynomial commitments.

Benchmarks indicate that \name\ can handle the training of complex models such as VGG-11 with 10~million parameters and batch size~$16$. The prover runtime is $15$~minutes per iteration, which is $\mathbf{24 \times}$ faster than generic recursive proofs, with prover memory overhead $\mathbf{27\times}$ lower. The proof size is $1.63$~megabytes, and the verifier runtime is only $130$~milliseconds, where both are independent of the number of iterations and the size of the dataset.
]]></content:encoded>
<pubDate>Sun, 04 Feb 2024 22:43:14 +0000</pubDate>
</item>
<item>
<title>Secure Vickrey Auctions with Rational Parties</title>
<link>https://eprint.iacr.org/2024/1011</link>
<guid>https://eprint.iacr.org/2024/1011</guid>
<content:encoded><![CDATA[
<div> 关键词：second price auction, Vickrey auction, privacy, rational parties, dominant strategy equilibrium

总结:<br />
本文设计了一种无需拍卖人的第二价格（Vickrey）拍卖协议（SPA），确保了在理性、计算能力有限且注重隐私的参与者之间的完全隐私。该协议保护了最高出价和第二高出价者的身份不被泄露。参与者被模型化为自我利益驱动、遵循个人优势（通过合适的效用函数衡量）的理性个体，他们不会随意偏离协议。研究证明，在这种SPA中存在一种隐私保护的主导策略均衡，每个参与者都倾向于遵守协议。

该协议基于开源加密技术实现，具有高效性和低通信量。在一个拥有15名竞标者、每笔投标10位的实验中，SPA仅需1.26秒完成，总通信量为0.77MB。相比之下，类似条件下Atlas（半诚实）协议的运行时间增加了40%，通信量增加了87%。这表明作者的SPA协议在效率和隐私保护上具有显著优势。 <div>
In this work, we construct a second price (Vickrey) auction protocol (SPA), which does not require any auctioneers and ensures total privacy in the presence of rational parties participating in auction. In particular, the confidentiality of the highest bid and the identity of the second highest bidder are protected. We model the bidders participating in the second price auction as rational, computationally bounded and privacy-sensitive parties. These are self-interested agents who care about winning the auction more than learning about the private bids of other parties. A rational party does not deviate from the protocol arbitrarily but does so only for its own individual `advantage' -- without any consideration for others. Such an advantage is modeled using suitable utility functions. 

We show that for rational and computationally bounded parties participating in our second-price auctions protocol, there exists a privacy-preserving dominant strategy equilibrium in which every party prefers to follow the protocol rather than to deviate. 

Our protocol is implemented using open-source cryptographic constructs. Running our SPA protocol on commodity hardware with $15$ bidders,  with bids of length $10$ bits,  completes in $1.26$sec and has total communication of $0.77$MB whereas, under similar conditions, Atlas (semi-honest) protocol takes $40\%$ more time ($2.11$ sec) and $87\%$ more communication ($6.09$MB).
]]></content:encoded>
<pubDate>Sat, 22 Jun 2024 04:11:28 +0000</pubDate>
</item>
<item>
<title>FSSiBNN: FSS-based Secure Binarized Neural Network Inference with Free Bitwidth Conversion</title>
<link>https://eprint.iacr.org/2024/1010</link>
<guid>https://eprint.iacr.org/2024/1010</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure neural network inference, Binarized neural networks (BNNs), Secure multi-party computation (MPC), Function secret sharing (FSS), Communication overhead.

总结:<br />
本文提出了一种名为FSSiBNN的安全二值神经网络（BNN）推理框架，旨在解决在使用MPC进行BNN推理时的隐私保护和通信效率问题。FSSiBNN利用函数秘密共享（FSS）实现免费的位宽转换，设计了一种位宽减半的参数编码方案，将位宽转换无缝融入FSS安全二值激活和最大池化协议中，显著减少了通信开销。通过预计算矩阵乘法和比较操作，FSSiBNN在实验中表现出色，相比XONN有7倍的更快推理速度和577倍的通信成本降低，相较于SecureBiNN和FLEXBNN，FSSiBNN在速度和通信效率上也有显著优势。 <div>
Neural network inference as a service enables a cloud server to provide inference services to clients. To ensure the privacy of both the cloud server's model and the client's data, secure neural network inference is essential. Binarized neural networks (BNNs), which use binary weights and activations, are often employed to accelerate inference. However, achieving secure BNN inference with secure multi-party computation (MPC) is challenging because MPC protocols cannot directly operate on values of different bitwidths and require bitwidth conversion. Existing bitwidth conversion schemes expand the bitwidths of weights and activations, leading to significant communication overhead.

To address these challenges, we propose FSSiBNN, a secure BNN inference framework featuring free bitwidth conversion based on function secret sharing (FSS). By leveraging FSS, which supports arbitrary input and output bitwidths, we introduce a bitwidth-reduced parameter encoding scheme. This scheme seamlessly integrates bitwidth conversion into FSS-based secure binary activation and max pooling protocols, thereby eliminating the additional communication overhead. Additionally, we enhance communication efficiency by combining and converting multiple BNN layers into fewer matrix multiplication and comparison operations. We precompute matrix multiplication tuples for matrix multiplication and FSS keys for comparison during the offline phase, enabling constant-round online inference.

In our experiments, we evaluated various datasets and models, comparing our results with state-of-the-art frameworks. Compared with the two-party framework XONN (USENIX Security '19), FSSiBNN achieves approximately 7$\times$ faster inference times and reduces communication overhead by about 577$\times$. Compared with the three-party frameworks SecureBiNN (ESORICS '22) and FLEXBNN (TIFS '23), FSSiBNN is approximately 2.5$\times$ faster in inference time and reduces communication overhead by 1.3$\times$ to 16.4$\times$.
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 14:45:30 +0000</pubDate>
</item>
<item>
<title>Auditable Attribute-Based Credentials Scheme and Its Application in Contact Tracing</title>
<link>https://eprint.iacr.org/2023/1060</link>
<guid>https://eprint.iacr.org/2023/1060</guid>
<content:encoded><![CDATA[
<div> 关键词：attribute-based credentials (ABC), auditable, anonymity, revocability, contact tracing

总结:<br />该文章探讨了在疫情期间，隐私保护联系追踪系统的需求升级。作者将注意力转向了基于属性的凭证(ABC)方案，提出了一种可审计的ABC扩展，增加了审计能力，允许指定的审计机构撤销特定发行者的匿名性。为此，他们设计了可更新公钥的“可审计公钥”机制，并将其应用于Connolly等人的ABC构造中。此外，文章还改进了Wang等人的框架，提供了安全定义和协议构建，以及一个实现来展示设计的实用性。这个工作不仅解决了现有系统的局限，而且"可审计公钥"机制具有通用性，可能对其他加密技术有独立价值。 <div>
During the pandemic, the limited functionality of existing privacy-preserving contact tracing systems highlights the need for new designs. Wang et al. proposed an environmental-adaptive framework (CSS '21) but failed to formalize the security. The similarity between their framework and attribute-based credentials (ABC) inspires us to reconsider contact tracing from the perspective of ABC schemes. In such schemes, users can obtain credentials on attributes from issuers and prove the credentials anonymously (i.e., hiding sensitive information of both user and issuer). This work first extends ABC schemes with auditability, which enables designated auditing authorities to revoke the anonymity of particular issuers. For this purpose, we propose an ``auditable public key (APK)'' mechanism that extends the updatable public key by Fauzi et al. (AsiaCrypt '19). We provide formal security definitions regarding auditability and build our auditable ABC scheme by adding a DDH-based APK to Connolly et al.'s ABC construction (PKC '22). Note that the APK mechanism can be used as a plug-in for other cryptographic primitives and may be of independent interest. Finally, regarding contact tracing, we refine Wang et al.'s framework and present a formal treatment that includes security definitions and protocol construction. An implementation is provided to showcase the practicality of our design.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 00:04:39 +0000</pubDate>
</item>
<item>
<title>Stochastic Secret Sharing with $1$-Bit Shares and Applications to MPC</title>
<link>https://eprint.iacr.org/2024/1053</link>
<guid>https://eprint.iacr.org/2024/1053</guid>
<content:encoded><![CDATA[
<div> 关键词：secret-sharing, 1-bit shares, corruption probability, error-correcting codes, binary erasure channel

总结:<br />
这篇文章探讨了一种新的随机模型，用于设计具有单比特份额的阈值秘密共享方案，以抵抗任意常数概率$p<0.5$的攻击。作者通过建立与纠错码在二进制擦除信道上达到容量的联系，提出了创新的构造方法。这些线性且可乘的方案有助于构建高效、实时的多方计算（MPC）协议，即使门电路按顺序实时到来，也能保证低通信量，每个AND门只需单比特通信，XOR门无需通信。这对于实现实时环境下的安全计算是一个重要突破。 <div>
The problem of minimizing the share size of threshold secret-sharing schemes is a basic research question that has been extensively studied. Ideally, one strives for schemes in which the share size equals the secret size. While this is achievable for large secrets (Shamir, CACM '79), no similar solutions are known for the case of binary, single-bit secrets. Current approaches often rely on so-called ramp secret sharing that achieves a constant share size at the expense of a slight gap between the privacy and the correctness thresholds. In the case of single-bit shares, this leads to a large gap which is typically unacceptable. The possibility of a meaningful notion of secret sharing scheme with 1-bit shares and almost optimal threshold has been left wide open. Of special interest is the case of threshold 0.5, which is motivated by information-theoretic honest-majority secure multiparty computation (MPC).

In this work, we present a new stochastic model for secret-sharing where each party is corrupted by the adversary with probability $p$, independently of the other parties, and correctness and privacy are required to hold with high probability over the choice of the corrupt parties. We present new secret sharing schemes with single-bit shares that tolerate any constant corruption probability $p<0.5$. Our construction is based on a novel connection between such stochastic secret-sharing schemes and error-correcting codes that achieve capacity over the binary erasure channel.

Our schemes are linear and multiplicative. We demonstrate the usefulness of the model by using our new schemes to construct MPC protocols with security against an adversary that passively corrupts an arbitrary subset of $0.499n$ of the parties, where the online communication per party consists of a single bit per AND gate and zero communication per XOR gate. Unlike competing approaches for communication-efficient MPC, our solution is applicable even in a real-time model in which the parties should compute a Boolean circuit whose gates arrive in real-time, one at a time, and are not known in advance.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 06:24:00 +0000</pubDate>
</item>
<item>
<title>A New Fine Tuning Method for FHEW/TFHE Bootstrapping with IND-CPAD Security</title>
<link>https://eprint.iacr.org/2024/1052</link>
<guid>https://eprint.iacr.org/2024/1052</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE), FHEW, TFHE, IND-CPA-D security, key recovery attack

总结:<br />
文章讨论了全同态加密(FHE)方案，特别是FHEW和TFHE，这两种方法在处理加密数据的计算上表现出色。然而，它们的评估失败概率对参数选择敏感，导致必须选择过低的失败概率以抵抗Cheon等人的关键恢复攻击，这牺牲了运行效率。为解决这个问题，作者提出了一种新的FHEW/TFHE的提升方法，它允许精确地平衡运行时间和失败概率，同时提供易于实现的特性。新方法允许根据所需安全级别选择更合适的参数集，兼顾效率和安全性。 <div>
Fully homomorphic encryption (FHE) schemes enable computations on encrypted data, making them a crucial component of privacy-enhancing technologies. 
Ducas and Micciancio introduced FHEW (Eurocrypt '15), and Chillotti et al. improved it in TFHE (Asiacrypt '16), both of which provide homomorphic binary (or larger) gate evaluations with fast latency due to their small parameters. 
However, their evaluation failure probability is highly sensitive to parameter selection, resulting in a limited set of viable parameters and a trade-off between failure probability and runtime.

Recently, Cheon et al. proposed a key recovery attack against FHEW/TFHE schemes based on a new security model for FHE, called IND-CPA-D security, which was first introduced by Li and Micciancio (Eurocrypt '21). 
To prevent this attack, it is necessary to make the failure probability negligible (e.g., $2^{-128}$). 
However, due to limited choice parameters, it is forced to use a parameter set with unnecessarily low failure probabilities than needed, causing inefficiencies in runtime.

We propose a new bootstrapping method for FHEW/TFHE, providing a precise balance between runtime and failure probability, and easy to implement.
The proposed methods enable the selection of parameter sets that achieve negligible failure probabilities for each desired security level while optimizing runtime.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 04:46:10 +0000</pubDate>
</item>
<item>
<title>Efficient Verifiable Differential Privacy with Input Authenticity in the Local and Shuffle Model</title>
<link>https://eprint.iacr.org/2024/1042</link>
<guid>https://eprint.iacr.org/2024/1042</guid>
<content:encoded><![CDATA[
<div> 关键词：Local differential privacy (LDP), malicious clients, input manipulation, output manipulation, verifiable LDP (VLDP).

总结: 这篇文章探讨了如何保护Local Differential Privacy (LDP)机制免受恶意客户端的攻击。作者提出了一种高效的方法，通过设计防止输入和输出操纵的Verifiable LDP (VLDP)方案，确保了数据隐私。VLDP完全防御输出操纵，使用签名数据防止输入攻击，仅需一次客户端与服务器交互，提高了系统的安全性。文章还提供了两种在常规模型下的VLDP方案和一种在shuffle模型下的实现，且具有良好的实践性，客户端运行时间少于2秒，服务器处理时间为每客户5-7毫秒。 <div>
Local differential privacy (LDP) is an efficient solution for providing privacy to client's sensitive data while simultaneously releasing aggregate statistics without relying on a trusted central server (aggregator) as in the central model of differential privacy. The shuffle model with LDP provides an additional layer of privacy, by disconnecting the link between clients and the aggregator, further improving the utility of LDP. However, LDP has been shown to be vulnerable to malicious clients who can perform both input and output manipulation attacks, i.e., before and after applying the LDP mechanism, to skew the aggregator's results. In this work, we show how to prevent malicious clients from compromising LDP schemes. Specifically, we give efficient constructions to prevent both input ánd output manipulation attacks from malicious clients for generic LDP algorithms. Our proposed schemes for verifiable LDP (VLDP), completely protect from output manipulation attacks, and prevent input attacks using signed data, requiring only one-time interaction between client and server, unlike existing alternatives [28, 33]. Most importantly, we are the first to provide an efficient scheme for VLDP in the shuffle model. We describe and prove secure, two schemes for VLDP in the regular model, and one in the shuffle model. We show that all schemes are highly practical, with client runtimes of < 2 seconds, and server runtimes of 5-7 milliseconds per client.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 07:19:55 +0000</pubDate>
</item>
<item>
<title>Encryption Based Covert Channel for Large Language Models</title>
<link>https://eprint.iacr.org/2024/586</link>
<guid>https://eprint.iacr.org/2024/586</guid>
<content:encoded><![CDATA[
<div> 关键词：Transformer神经网络、安全性、Covert Channel攻击、Claude.ai、隐私风险。

总结:<br />
Transformer神经网络因其在大型语言模型中的出色表现而备受关注。本文聚焦于这些模型的安全隐患，特别是Covert Channel（隐蔽信道）攻击。研究者利用加密手段在Claude.ai上实施了攻击，并发现该模型会记录用户查询。值得注意的是，攻击在两天内被察觉并阻止，这引发了两个关键问题：一是大语言模型可能过度收集用户数据，对隐私构成威胁；二是频繁的阻断可能导致学术界对于此类模型安全性的研究受限，难以重复实验。 <div>
Transformer neural networks have gained significant traction since their introduction, becoming pivotal across diverse domains. Particularly in large language models like Claude and ChatGPT, the transformer architecture has demonstrated remarkable efficacy. This paper provides a concise overview of transformer neural networks and delves into their security considerations, focusing on covert channel attacks and their implications for the safety of large language models. We present a covert channel utilizing encryption and demonstrate its efficacy in circumventing Claude.ai's security measures. Our experiment reveals that Claude.ai appears to log our queries and blocks our attack within two days of our initial successful breach.  This raises two concerns within the community: (1) The extensive logging of user inputs by large language models could pose privacy risks for users. (2) It may deter academic research on the security of such models due to the lack of experiment repeatability.
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 04:22:48 +0000</pubDate>
</item>
<item>
<title>SACfe: Secure Access Control in Functional Encryption with Unbounded Data</title>
<link>https://eprint.iacr.org/2024/1031</link>
<guid>https://eprint.iacr.org/2024/1031</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、功能加密（FE）、SACfe、安全访问控制、内积属性。<br /><br />总结: 这篇文章探讨了在大规模数字应用中保护用户隐私的重要性，特别是针对云计算和机器学习服务。作者提出了一种新的属性基功能加密方案（SACfe），它提供了安全、细粒度的访问控制，同时隐藏用户属性和对数据的操作，确保数据保密性。SACfe特别支持对加密数据进行线性计算，并基于内积条件执行访问控制。文章还展示了SACfe如何用于在线生物识别，实现隐私保护的访问控制。此外，文章还介绍了一种适用于无限长度消息和函数的线性FE，其控制基于单调span程序。实验结果表明，该方案在实践中具有高效性，通过CiFEr库实现了这些协议。 <div>
Privacy is a major concern in large-scale digital applications, such as cloud-computing, machine learning services, and access control. Users want to protect not only their plain data but also their associated attributes (e.g., age, location, etc). Functional encryption (FE) is a cryptographic tool that allows fine-grained access control over encrypted data. However, existing FE fall short as they are either inefficient and far from reality or they leak sensitive user-specific information.

We propose SACfe, a novel attribute-based FE scheme that provides secure, fine-grained access control and hides both the user’s attributes and the function applied to the data, while preserving the data’s confidentiality. Moreover, it enables users to encrypt unbounded-length messages along with an arbitrary number of hidden attributes into ciphertexts. We design SACfe, a protocol for performing linear computation on encrypted data while enforcing access control based on inner product predicates. We show how SACfe can be used for online biometric authentication for privacy-preserving access control. As an additional contribution, we introduce an attribute-based linear FE for unbounded length of messages and functions where access control is realized by monotone span programs. We implement our protocols using the CiFEr cryptographic library and show its efficiency for practical settings.
]]></content:encoded>
<pubDate>Wed, 26 Jun 2024 07:19:42 +0000</pubDate>
</item>
<item>
<title>Stateless and Verifiable Execution Layer for Meta-Protocols on Bitcoin</title>
<link>https://eprint.iacr.org/2024/408</link>
<guid>https://eprint.iacr.org/2024/408</guid>
<content:encoded><![CDATA[
<div> 关键词：Layer-2解决方案、比特币指数器、Turing-incomplete、INDECURE、数据完整性

总结: <br />
本文讨论了比特币生态系统中的发展，尤其是Layer-2解决方案（如inscriptions和ordinal protocols）在提高交易效率和创建独特资产方面的贡献。然而，比特币脚本的限制性使其需要使用指数器进行复杂操作。INDECURE是一个提出的新型模块化指数器架构，它旨在解决传统分布式指数器的安全问题，如Sybil攻击。INDECURE利用多项式承诺作为检查点，通过数据证明确保状态信息的可靠性，减少验证过程中的计算和存储需求。初步评估显示，INDECURE在BRC20、Bitmap和satsnames等协议中表现出更好的性能，为比特币的去中心化和高效应用提供了坚实的基础。 <div>
The Bitcoin ecosystem has continued to evolve beyond its initial promises of decentralization, transparency, and security. Recent advancements have notably been made with the integration of Layer-2 solutions, which address scalability issues by offloading transactions from the main blockchain. This facilitates faster and more cost-effective transactions while maintaining integrity. The advent of inscriptions and ordinal protocols has further broadened the spectrum of capabilities, enabling the creation of unique, indivisible assets on the blockchain. Despite these technological strides, the inherent limitations of Bitcoin's script being Turing-incomplete restrict complex executions directly on the blockchain, necessitating the use of Bitcoin indexers. These indexers act as off-chain execution layers, allowing for the incorporation of Turing-complete programming languages to manage and update state transitions based on blockchain data. However, this off-chain solution introduces challenges to data integrity and availability, compounded by the decentralized nature of blockchain which complicates data maintenance and accuracy.

To address these challenges, we propose a new modular indexer architecture that enables a fully decentralized and user-verified network, mitigating the risks associated with traditional decentralized indexer networks susceptible to Sybil attacks. Our solution, INDECURE, leverages polynomial commitments as checkpoints to streamline the verification process, significantly reducing the overhead associated with integrity checks of state transitions. By implementing a robust data attestation procedure, INDECURE ensures the reliability of state information against malicious alterations, facilitating trustless verifications by users. Our preliminary evaluations of INDECURE across various indexer protocols—BRC20, Bitmap, and satsnames—demonstrate its superiority in reducing computation time and data block size while maintaining high integrity in state transitions. This modular approach not only enhances the security and efficiency of Bitcoin's off-chain executions but also sets a foundational layer for scalable, secure blockchain applications.
]]></content:encoded>
<pubDate>Wed, 06 Mar 2024 18:14:24 +0000</pubDate>
</item>
<item>
<title>MUSEN: Aggregatable Key-Evolving Verifiable Random Functions and Applications</title>
<link>https://eprint.iacr.org/2024/628</link>
<guid>https://eprint.iacr.org/2024/628</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Random Function (VRF), Aggregatable Key-Evolving VRF (A-KE-VRF), Proof-of-Stake (PoS), Proofs of Proof-of-Stake (PoPoS), Encryption to the Future (EtF)

总结:<br />
本文提出了一种新的可聚合密钥演进Verifiable Random Function (A-KE-VRF)，它具有聚合和密钥演进的特性。A-KE-VRF有助于提升Proof-of-Stake (PoS)区块链的块大小效率，优化PoPoS，并构建了面向未来的加密和来自过去的认证方案。这些技术对于YOSO MPC框架至关重要，提供了增强的安全性。通过结合这些功能，A-KE-VRF为未来加密协议设计开辟了新路径。 <div>
A Verifiable Random Function (VRF) can be evaluated on an input by a prover who holds a secret key, generating a pseudorandom output and a proof of output validity that can be verified using the corresponding public key. VRFs are a central building block of committee election mechanisms that sample parties to execute tasks in cryptographic protocols, e.g. generating blocks in a Proof-of-Stake (PoS) blockchain or executing a round of MPC protocols. We propose the notion, and a matching construction, of an Aggregatable Key-Evolving VRF (A-KE-VRF) with the following extra properties: 1. Aggregation: combining proofs for several VRF evaluations of different inputs under different secret keys into a single constant size proof; 2. Key-Evolving: preventing adversaries who corrupt a party (learning their secret key) from ``forging'' proofs of past VRF evaluations. As an immediate application, we improve on the block size of PoS blockchains and on the efficiency of Proofs of Proof-of-Stake (PoPoS). Furthermore, the A-KE-VRF notion allows us to construct Encryption to the Future (EtF) and Authentication from the Past (AfP) schemes with a Key-Evolving property, which provides forward security.  An EtF scheme allows for sending a message to a party who is randomly selected to execute a role in the future, while an AfP scheme allows for this party to authenticate their messages as coming from a past execution of this role. These primitives are essential for realizing the YOSO MPC Framework (CRYPTO'21).
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 07:32:44 +0000</pubDate>
</item>
<item>
<title>"Act natural!": Having a Private Chat on a Public Blockchain</title>
<link>https://eprint.iacr.org/2021/1073</link>
<guid>https://eprint.iacr.org/2021/1073</guid>
<content:encoded><![CDATA[
<div> 关键词：subliminal channel, blockchain, secret-recoverable splittable signature, public-key, random oracle model

总结:<br />
本文提出了一种利用区块链上秘密可恢复分割签名方案的公开密钥隐秘通信渠道。这种设计在随机Oracle模型下，在常见加密假设下是不可检测的。方法适用于98种顶级加密货币中使用的98种秘密可恢复分割签名方案，仅增加每条消息一个签名的常量开销。研究还分析了比特币、Monero和RippleNet网络的适用性，并提供了比特币和RippleNet的原型实现。这一创新为匿名但可追踪的通信提供了一种新的可能，增加了信息安全的隐蔽性。 <div>
Messengers have become an essential means of interpersonal interaction. Yet untraceable private communication remains an elusive goal, as most messengers hide content, but not communication patterns. The knowledge of communication patterns can by itself reveal too much, as happened, e.g., in the context of the Arab Spring. Subliminal channels in cryptographic systems enable untraceable private communication in plain sight. In this context, bulletin boards in the form of blockchains are a natural object for subliminal communication: accessing them is innocuous, as they rely on distributed access for verification and extension. At the same time, blockchain users generate hundreds of thousands of transactions per day that are individually signed and placed on the blockchain. Thus, blockchains may serve as innocuous repository for publicly accessible cryptographic transactions where subliminal channels can be placed. This significantly increases the availability of publicly accessible cryptographic transactions where subliminal channels can be placed.
In this paper, we propose a public-key subliminal channel using secret-recoverable splittable signature schemes on blockchains and prove that our construction is undetectable in the random oracle model under common cryptographic assumptions. Our approach is applicable to any secret-recoverable splittable signature scheme and introduces a constant overhead of a single signature per message. Such schemes are used by 98 of the top 100 cryptocurrencies. We also analyze the applicability of our approach to the Bitcoin, Monero, and RippleNet networks and present proof of concept implementations for Bitcoin and RippleNet.
]]></content:encoded>
<pubDate>Mon, 23 Aug 2021 06:32:15 +0000</pubDate>
</item>
<item>
<title>From Interaction to Independence: zkSNARKs for Transparent and Non-Interactive Remote Attestation</title>
<link>https://eprint.iacr.org/2024/1068</link>
<guid>https://eprint.iacr.org/2024/1068</guid>
<content:encoded><![CDATA[
<div> 关键词：remote attestation (RA), transparency, zkSNARKs, non-interactive, publicly provable

总结:
本文介绍了一种新型的远程验证协议(zRA)，它利用零知识 Succinct Non-Interactive Argument of Knowledge (zkSNARKs)技术，解决了现有RA协议的透明度问题。zRA无需预共享密钥或访问敏感数据，实现了无交互、公开可验证的设备验证。它不依赖在线服务，也不增加额外的安全假设，适用于点对点和发布/订阅网络结构。作者还开发了开源实现，并表明zRA适用于公共许可区块链，用于存储和保护免受DoS攻击的认证数据。总的来说，zRA促进了更广泛地采用远程验证技术，保证了系统的可信度和审计性。 <div>
Remote attestation (RA) protocols have been widely
used to evaluate the integrity of software on remote devices.
Currently, the state-of-the-art RA protocols lack a crucial feature: transparency. This means that the details of the final
attestation verification are not openly accessible or verifiable by
the public. Furthermore, the interactivity of these protocols often
limits attestation to trusted parties who possess privileged access
to confidential device data, such as pre-shared keys and initial
measurements. These constraints impede the widespread adoption
of these protocols in various applications.
In this paper, we introduce zRA, a non-interactive, transparent, and publicly provable RA protocol based on zkSNARKs.
zRA enables verification of device attestations without the need
for pre-shared keys or access to confidential data, ensuring a
trustless and open attestation process. This eliminates the reliance
on online services or secure storage on the verifier side. Moreover,
zRA does not impose any additional security assumptions beyond
the fundamental cryptographic schemes and the essential trust
anchor components on the prover side (i.e., ROM and MPU).
The zero-knowledge attestation proofs generated by devices have
constant size regardless of the network complexity and number
of attestations. Moreover, these proofs do not reveal sensitive
information regarding internal states of the device, allowing verification by anyone in a public and auditable manner. We conduct
an extensive security analysis and demonstrate scalability of zRA
compared to prior work. Our analysis suggests that zRA excels
especially in peer-to-peer and Pub/Sub network structures. To
validate the practicality, we implement an open-source prototype
of zRA using the Circom language. We show that zRA can be
securely deployed on public permissionless blockchains, serving
as an archival platform for attestation data to achieve resilience
against DoS attacks.
]]></content:encoded>
<pubDate>Mon, 01 Jul 2024 12:23:31 +0000</pubDate>
</item>
<item>
<title>Distributional Secure Merge</title>
<link>https://eprint.iacr.org/2024/1048</link>
<guid>https://eprint.iacr.org/2024/1048</guid>
<content:encoded><![CDATA[
<div> 关键词：secure merge, uniformly random lists, near linear, logarithmic overheads, implementation

总结:<br />
本文主要探讨了在处理随机列表的 secure merge 问题上，提出了一种新的协议。该协议实现了近乎线性的通信和计算复杂度，每轮运行时间为 $O(\log\log n)$，对于长度为 $2^{20}$ 的列表，运行时间和通信量比现有状态提高了一个数量级。与之前的理论工作相比，虽然在理论上的最优时间复杂度有所差距，但实证表明，新协议在实际应用中更为高效。此外，该协议还扩展到了来自任意分布的列表，尤其是当列表近似同分布时，效率接近于随机列表，从而显著提升了 PSI 和 Secure Join 等关键应用的性能。 <div>
Secure merge refers to the problem of merging two sorted lists. The problem appears in different settings where each list is held by one of two parties, or the lists are themselves shared among two or more parties. The output of a secure merge protocol is secret shared. Each variant of the problem offers many useful applications.

The difficulty in designing secure merge protocols vis-a-vis insecure merge protocols (which work in linear time with a single pass over the lists) has to do with operations having to be oblivious or data-independent. In particular, the protocol cannot leak the positions of items of each list in the final merged list. On account of this, sorting-based secure merge protocols have been a common solution to the problem. However, as they introduce (poly)logarithmic overheads, there has been active investigation into the task of building (near) linear time secure merge protocols. Most recently, Hemenway et al. put forth a protocol for secure merge that does achieve linear communication and computation and a round complexity of $O({\log\log n})$, where $n$ is the length of the lists being merged. While this shows the feasibility of a linear time secure merge, it still leaves room for the design of a concretely efficient linear time secure merge.

In this work, we consider a relaxation of the problem where the lists are uniformly random. We show a secure merge protocol for uniformly random lists that achieves $O({n\log\log n})$, i.e., near linear communication and computation and a round complexity of $O({\log\log n})$, where $n$ is the length of the lists being merged. Our protocol design is general and can be instantiated in a variety of settings so long as the building blocks (basic ones such as comparisons and shuffles) can be realized in said settings. Although we do not achieve the same asymptotic guarantees as Hemenway et al., our work is concretely efficient. We implement our protocol and compare it to the state of the art sorting protocols and demonstrate an order of magnitude improvement in running times and communication for lists of size of $2^{20}$. 

We also extend our protocol to work for lists sampled from arbitrary distributions. In particular, when the lists are (close to) identically distributed, we achieve the same efficiency as uniform lists. This immediately improve the performance of many crucial applications including PSI & Secure Join, thus illustrating the significance and applicability of our protocol in practice.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 22:07:39 +0000</pubDate>
</item>
<item>
<title>ammBoost: State Growth Control for AMMs</title>
<link>https://eprint.iacr.org/2024/1021</link>
<guid>https://eprint.iacr.org/2024/1021</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance（去中心化金融）、Automated Market Makers（自动市场 maker，AMM）、Blockchain、Scalability（可扩展性）、ammBoost。

总结: <br />
文章讨论了去中心化金融（DeFi）中自动市场 makers（AMM）的可扩展性问题，尤其是在区块链上处理大量交易时产生的存储和交易成本问题。为解决这一问题，作者提出了一种名为ammBoost的新型侧链架构，旨在减少链上交易、提高吞吐量并支持区块链修剪。该系统采用多种技术确保AMM的正确性和安全性。通过构建Uniswap启发式用例的原型，实验结果表明ammBoost能将交易气体成本降低94.53%，链增长至少减少80%，并且能够支持比实际Uniswap高出500倍的日流量。总的来说，ammBoost是一种有效的解决方案，旨在优化AMM在DeFi中的性能和可持续性。 <div>
Automated market makers (AMMs) are a form of decentralized cryptocurrency exchanges and considered a prime example of Decentralized Finance (DeFi) applications. Their popularity and high trading activity have resulted in millions of on-chain transactions leading to serious scalability issues. In this paper, we address the on-chain storage overhead problem of AMMs by utilizing a new sidechain architecture as a layer 2 solution, building a system called ammBoost. Our system reduces the amount of on-chain transactions, boosts throughput, and supports blockchain pruning. We devise several techniques to enable layer 2 processing for AMMs while preserving correctness and security of the underlying AMM. We also build a proof-of-concept of ammBoost for a Uniswap-inspired use case to empirically evaluate its performance. Our experiments show that ammBoost decreases the gas cost by 94.53% and the chain growth by at least 80%, and that it can support up to 500x of the daily traffic volume observed for Uniswap in practice.
]]></content:encoded>
<pubDate>Mon, 24 Jun 2024 19:20:08 +0000</pubDate>
</item>
<item>
<title>A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance</title>
<link>https://eprint.iacr.org/2024/304</link>
<guid>https://eprint.iacr.org/2024/304</guid>
<content:encoded><![CDATA[
<div> 关键词：Reticulum, sharding, blockchain, scalability, adversarial nodes

总结: <br />
Reticulum是一种创新的分片协议，旨在解决区块链网络中的可扩展性和安全性问题。它采用两阶段设计，分为控制和处理分片，以应对不同类型的攻击。控制分片确保网络的多数诚实节点，而处理分片负责交易处理，通过一致同意减少参与验证的节点，实现高吞吐量。在出现争议时，控制分片作为仲裁者。实验表明，Reticulum在保持高交易速度的同时，具有更强的抗攻击性，相较于现有协议更具优势。 <div>
Sharding is a critical technique that enhances the scalability of blockchain technology. However, existing protocols often assume adversarial nodes in a general term without considering the different types of attacks, which limits transaction throughput at runtime because attacks on liveness could be mitigated. There have been attempts to increase transaction throughput by separately handling the attacks; however, they have security vulnerabilities. This paper introduces Reticulum, a novel sharding protocol that overcomes these limitations and achieves enhanced scalability in a blockchain network without security vulnerabilities.

Reticulum employs a two-phase design that dynamically adjusts transaction throughput based on runtime adversarial attacks on either or both liveness and safety. It consists of `control' and `process' shards in two layers corresponding to the two phases. Process shards are subsets of control shards, with each process shard expected to contain at least one honest node with high confidence. Conversely, control shards are expected to have a majority of honest nodes with high confidence. Reticulum leverages unanimous voting in the first phase to involve fewer nodes in accepting/rejecting a block, allowing more parallel process shards. The control shard finalizes the decision made in the first phase and serves as a lifeline to resolve disputes when they surface.

Experiments demonstrate that the unique design of Reticulum empowers high transaction throughput and robustness in the face of different types of attacks in the network, making it superior to existing sharding protocols for blockchain networks.
]]></content:encoded>
<pubDate>Fri, 23 Feb 2024 00:13:18 +0000</pubDate>
</item>
<item>
<title>Non-interactive VSS using Class Groups and Application to DKG</title>
<link>https://eprint.iacr.org/2023/451</link>
<guid>https://eprint.iacr.org/2023/451</guid>
<content:encoded><![CDATA[
<div> 关键词：non-interactive verifiable secret sharing (NI-VSS), class groups (cgVSS), range proof, public verifiability, non-interactive distributed key generation (NI-DKG).

总结:
本文提出了一种基于类群的非交互式可验证秘密共享方案(cgVSS)，它不依赖于范围证明，利用类群的独特结构实现高效的大整数加密。cgVSS简化了NI-VSS过程，相比现有方案有显著性能提升。文章还定义了公共可验证性，并扩展到即使所有接收者可能被攻击也能保持的强公共可验证性。通过通用转换，作者得到了一个基于类群的非交互式分布式密钥生成方案(cgDKG)，适用于阈值系统。安全分析考虑了公共可验证性对DKG的影响。总的来说，这篇论文展示了类群在构建高效、可验证的密码学协议中的潜力。 <div>
We put forward a non-interactive verifiable secret sharing (NI-VSS) scheme using class groups – we call it cgVSS. Our construction follows the standard framework of encrypting the shares to a set of recipients and generating a non-interactive proof of correct sharing. However, as opposed to prior works, such as Groth’s [Eprint 2021], or Gentry et al.’s [Eurocrypt 2022], we do not require any range proof - this is possible due to the unique structure of class groups, that enables efficient encryption/decryption of large field elements in the exponent of an ElGamal-style encryption scheme. Importantly, this is possible without destroying the additive holomorphic structure, which is required to make the proof-of-correctness highly efficient. This approach not only substantially simplifies the NI-VSS process, but also outperforms the state-of-art schemes significantly. For example, our implementation shows that for a 150 node system cgVSS outperforms (a simplified implementation of) Groth’s protocol in overall communication complexity by 5.6x, about 9.3 − 9.7x in the dealer time and 2.4 − 2.7x in the receiver time per node.

Additionally, we formalize the notion of public verifiability, which enables anyone, possibly outside the participants, to verify the correctness of the dealing. In fact, we re-interpret the notion of public verifiability and extend it to the setting when potentially all recipients may be corrupt and yet can not defy public verifiability – to distinguish from state-of-art, we call this strong public verifiability. Our formalization uses the universal composability framework.

Finally, through a generic transformation, we obtain a non-interactive distributed key generation (NI-DKG) scheme for threshold systems, where the secret key is the discrete log of the public key. Our security analysis in the VSS-hybrid model uses a formalization that considers a (strong) public verifiability notion for DKG, even when more than threshold parties are corrupt. Instantiating with cgVSS we obtain a NI-DKG scheme from class groups – we call it cgDKG.
]]></content:encoded>
<pubDate>Tue, 28 Mar 2023 17:30:50 +0000</pubDate>
</item>
<item>
<title>Asynchronous Consensus without Trusted Setup or Public-Key Cryptography</title>
<link>https://eprint.iacr.org/2024/677</link>
<guid>https://eprint.iacr.org/2024/677</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine共识、异步协议、可信设置、公钥加密、随机 oracle。

总结:<br />
本文研究了无需可信设置和不使用公钥加密的异步拜占庭共识协议。提出了一种基于随机 oracle 的 Asynchronous Common Subset（ACS）协议，具有$O(\kappa n^3)$总通信量和$O(1)$期望轮数。该协议仅依赖于密码哈希函数，因此对量子攻击也安全。与现有实现相比，实验表明该协议更为高效。此外，文中还介绍了新引入的异步秘密密钥共享和覆盖聚集等概念，这些可能独立具有价值。 <div>
Byzantine consensus is a fundamental building block in distributed cryptographic problems. Despite decades of research, most existing asynchronous consensus protocols require a strong trusted setup and expensive public-key cryptography. In this paper, we study asynchronous Byzantine consensus protocols that do not rely on a trusted setup and do not use public-key cryptography such as digital signatures. We give an Asynchronous Common Subset (ACS) protocol whose security is only based on cryptographic hash functions modeled as a random oracle. Our protocol has $O(\kappa n^3)$ total communication and runs in expected $O(1)$ rounds. The fact that we use only cryptographic hash functions also means that our protocol is post-quantum secure. The minimal use of cryptography and the small number of rounds make our protocol practical. We implement our protocol and evaluate it in a geo-distributed setting with up to 128  machines. Our experimental evaluation shows that our protocol is more efficient than the only other setup-free consensus protocol that has been implemented to date. En route to our asynchronous consensus protocols, we also introduce new primitives called asynchronous secret key sharing and cover gather, which may be of independent interest.
]]></content:encoded>
<pubDate>Fri, 03 May 2024 13:40:00 +0000</pubDate>
</item>
<item>
<title>VIMz: Verifiable Image Manipulation using Folding-based zkSNARKs</title>
<link>https://eprint.iacr.org/2024/1063</link>
<guid>https://eprint.iacr.org/2024/1063</guid>
<content:encoded><![CDATA[
<div> 关键词：generative AI, zero-knowledge proofs (ZKP), folding-based zkSNARKs, VIMz, trustless smart contract system

总结:
本文探讨了随着生成式AI技术的发展，媒体真实性验证的需求增加。为确保图像来源的可信度，作者提出了一种名为VIMz的高效可验证图像操纵系统，它利用折叠式zkSNARKs技术降低证明者复杂性。与先前方法相比，VIMz在处理高清和4K图像时，实现了时间速度提升3倍，内存消耗减少96倍（从309GB降至3.2GB）。此外，文章还设计了一个无信任智能合约系统，用于自动验证媒体真实性的证明，支持版权和所有权的透明管理，符合内容可追溯性和真实性联盟（C2PA）标准。这一系统为构建去中心化的媒体市场奠定了基础，具有广泛的应用前景。 <div>
With the rise of generative AI technology, the media's credibility as a source of truth has been significantly compromised. This highlights the need to verify the authenticity of media and its originality.
Ensuring the integrity of media during capture using the device itself presents a straightforward solution to this challenge.
However, raw captured media often require certain refinements or redactions before publication. Zero-knowledge proofs (ZKP) offer a solution by allowing attestation of the correctness of specific transformations applied to an authorized image. While shown to be feasible, previous approaches faced challenges in practice due to their high prover complexity.

In this paper, we aim to develop a practical framework for efficiently proving the authenticity of HD and 4K images on commodity hardware. Our goal is to minimize prover complexity by utilizing the folding-based zkSNARKs technique, resulting in VIMz, the first practical verifiable image manipulation system of this kind. VIMz leverages Nova's folding scheme to achieve low complexity recursive zkSNARK proofs of authentic image manipulation. Our implementation results demonstrate a substantial reduction in prover complexity—up to a 3$\times$ speedup in time and a 96$\times$ reduction in memory (from 309 GB in [Kang et al., arXiv 2022] to only 3.2 GB). Moreover, the low memory consumption allows VIMz to prove the correctness of multiple chained transformations simultaneously, further increasing the performance (up to 3.5$\times$).
Additionally,
we propose a trustless smart contract system that autonomously verifies the proofs of media authenticity, achieving trustless copyright and ownership management, aligning with the standards of the Coalition for Content Provenance and Authenticity (C2PA).
Such a system serves as a foundational infrastructure for constructing trustless media marketplaces with diverse applications.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 13:05:39 +0000</pubDate>
</item>
<item>
<title>Compact Key Function Secret Sharing with Non-linear Decoder</title>
<link>https://eprint.iacr.org/2024/1062</link>
<guid>https://eprint.iacr.org/2024/1062</guid>
<content:encoded><![CDATA[
<div> 关键词：Function Secret Sharing (FSS), Distributed Point Function (DPF), Comparison Function, Interval Function, Key Size.

总结:<br />
本文主要探讨了一种针对点、比较和区间函数的变体Function Secret Sharing (FSS)方案，旨在实现更紧凑的$p$- party（$p \geq 3$）密钥大小。相比于现有构造，该方案显著减少了DPF的密钥大小，降低了$2^p$倍，同时对非线性解码器进行了一次额外的比较操作。对于分布式比较函数，作者实现了史上最小的密钥大小，减少了一个$q^{p-1}$因子，对隐私保护机器学习（PPML）中的应用有实际意义。此外，文章还展示了如何将这种改进应用于神经网络的分布式实现，如分布式ReLU激活函数，证实了新方案的有效性。 <div>
We present a variant of Function Secret Sharing (FSS) schemes tailored for point, comparison, and interval functions, featuring compact key sizes at the expense of additional comparison. While existing FSS constructions are primarily geared towards $2$-party scenarios, exceptions such as the work by Boyle et al. (Eurocrypt 2015) and Riposte (S&amp;P 2015) have introduced FSS schemes for $p$-party scenarios ($p \geq 3$). This paper aims to achieve the most compact $p$-party FSS key size to date. We achieve a noteworthy reduction in key size, a $2^p$-factor decrease compared to state-of-the-art FSS constructions (including computationally efficient constructions using symmetric-key primitives) of distributed point function (DPF). Compared to the previous public-key-based FSS design for DPF, we also get a key size reduction equal to a $2^{n/2}$-sized row vector, where $2^n$ is the domain size of the point function. This reduction in key size comes at the cost of a required comparison operation by the decoder (hence called a non-linear decoder), a departure from prior schemes. In $p$-party scenarios, our construction outperforms existing FSS constructions in key size, remaining on par with Riposte in evaluation time and showing significant improvement over Boyle et al.

In addition to constructing FSS for distributed point functions (DPF), we extend our approach to distributed comparison and interval functions, achieving the most efficient key size to date. Our distributed comparison function exhibits a key-size reduction by a factor of $q^{p-1}$, where $q$ denotes the size of the algebraic group used in the scheme's construction.
The reduced key size of the comparison function has practical implications, particularly in applications like privacy-preserving machine learning (PPML), where thousands of comparison functions are employed in each neural network layer.
To demonstrate the effectiveness of our improvements, we design and prototype-implement a scalable privacy-preserving framework for neural networks over distributed models. Specifically, we implement a distributed rectified linear unit (ReLU) activation function using our distributed comparison function, showcasing the efficacy of our proposed scheme.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 09:03:44 +0000</pubDate>
</item>
<item>
<title>Insta-Pok3r: Real-time Poker on Blockchain</title>
<link>https://eprint.iacr.org/2024/1061</link>
<guid>https://eprint.iacr.org/2024/1061</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式服务、多党计算（MPC）、身份-based加密、公开可验证、在线扑克。

总结: <br />
我们的文章介绍了一种分布式服务，用于为在线扑克玩家生成私密但可公开验证的关联随机性，如洗牌。该服务利用多党计算协议在离线阶段创建一个加密的卡片排列，确保其是卡片的唯一排列。当玩家加入时，他们仅需通过安全渠道获取身份特定的解密密钥并本地解密，简化了在线过程。文章的关键创新在于提出可缩简证明的多身份基加密（SVME），以及一种高效的小集合随机排列的秘密共享生成协议。整个系统在保证实时性和成本效益的同时，提供了信任最小化的在线扑克体验。在实验中，8个MPC参与者为64张牌生成可验证排列仅需3秒，而玩家获取牌只需0.3秒。 <div>
We develop a distributed service for generating correlated randomness (e.g. permutations) for multiple parties, where each party’s output is private but publicly verifiable. This service provides users with a low-cost way to play online poker in real-time, without a trusted party.
Our service is backed by a committee of compute providers, who run a multi-party computation (MPC) protocol to produce an (identity-based) encrypted permutation of a deck of cards, in an offline phase well ahead of when the players’ identities are known. When the players join, what we call the online phase, they decrypt their designated cards immediately after deriving the identity-based decryption keys, a much simpler computation. In addition, the MPC protocol also generates a publicly-verifiable proof that the output is a permutation.
In our construction, we introduce a new notion of succinctly verifiable multi-identity based encryption (SVME), which extends the existing notion of verifiable encryption to a multi-identity-based setting, but with a constant sized proof – this may be of independent interest. We instantiate this for a permutation relation (defined over a small set) along with identity-based encryption, polynomial commitments and succinct proofs – our choices are made to enable a distributed computation when the card deck is always secret shared. Moreover, we design a new protocol to efficiently generate a secret-sharing of random permutation of a small set, which is run prior to distributed SVME.
Running these protocols offline simplifies the online phase substantially, as parties only derive their identity-specific keys privately via secure channels with the MPC committee, and then decrypt locally to obtain their decks. We provide a rigorous UC-based formalization in a highly modularized fashion.
Finally, we demonstrate practicality with an implementation that shows that for 8 MPC parties, gen- erating a secret publicly-verifiable permutation of 64 cards takes under 3 seconds, while accessing cards for a player takes under 0.3 seconds.
]]></content:encoded>
<pubDate>Sat, 29 Jun 2024 04:27:35 +0000</pubDate>
</item>
<item>
<title>CoGNN: Towards Secure and Efficient Collaborative Graph Learning</title>
<link>https://eprint.iacr.org/2024/987</link>
<guid>https://eprint.iacr.org/2024/987</guid>
<content:encoded><![CDATA[
<div> 关键词：Collaborative Graph Learning, Federated Learning, Secure Machine Learning, Graph Neural Networks, CoGNN.

总结:<br />
本文提出了一种新的框架CoGNN，它结合了联邦学习和安全机器学习在协作图学习中的优点。CoGNN通过一种新的消息传递机制和两阶段Dispatch-Collect执行方案，实现了对图神经网络（GNN）训练和推理的隐私保护、高效计算和可扩展性。实验表明，相比于最先进的安全机器学习方法，CoGNN在运行时间和通信成本上分别减少了123倍和522倍，同时保持了与全局图训练相近的模型精度，甚至在某些情况下提高了11.06%。总的来说，CoGNN为协作图学习提供了一个高效且安全的解决方案。 <div>
Collaborative graph learning represents a learning paradigm where multiple parties jointly train a graph neural network (GNN) using their own proprietary graph data. To honor the data privacy of all parties, existing solutions for collaborative graph learning are either based on federated learning (FL) or secure machine learning (SML). Although promising in terms of efficiency and scalability due to their distributed training scheme, FL-based approaches fall short in providing provable security guarantees and achieving good model performance. Conversely, SML-based solutions, while offering provable privacy guarantees, are hindered by their high computational and communication overhead, as well as poor scalability as more parties participate.

To address the above problem, we propose CoGNN, a novel framework that simultaneously reaps the benefits of both FL-based and SML-based approaches. At a high level, CoGNN is enabled by (i) a novel message passing mechanism that can obliviously and efficiently express the vertex data propagation/aggregation required in GNN training and inference and (ii) a two-stage Dispatch-Collect execution scheme to securely decompose and distribute the GNN computation workload for concurrent and scalable executions. We further instantiate the CoGNN framework, together with customized optimizations, to train Graph Convolutional Network (GCN) models. Extensive evaluations on three graph datasets demonstrate that compared with the state-of-the-art (SOTA) SML-based approach, CoGNN reduces up to $123$x running time and up to $522$x communication cost per party. Meanwhile, the GCN models trained using CoGNN have nearly identical accuracies as the plaintext global-graph training, yielding up to $11.06\%$ accuracy improvement over the GCN models trained via federated learning.
]]></content:encoded>
<pubDate>Wed, 19 Jun 2024 04:20:23 +0000</pubDate>
</item>
<item>
<title>Adaptor Signatures: New Security Definition and A Generic Construction for NP Relations</title>
<link>https://eprint.iacr.org/2024/1051</link>
<guid>https://eprint.iacr.org/2024/1051</guid>
<content:encoded><![CDATA[
<div> 关键词：Adaptor Signatures (AS), Witness Hiding, NP relation, One-way Functions, Trapdoor Commitments.

总结:
本文主要探讨了适应性签名(Adaptor Signatures, AS)及其增强的安全特性——隐藏见证。AS最初允许签名者为硬关系实例生成预签名，但早期构造存在缺陷，预签名关联的见证会暴露。为解决这个问题，作者提出了一种新的定义，即“见证隐藏”，并证明在仅依赖单向函数假设下，可以构建AS，满足这一安全属性。文章还提出了一种基于签名和弱型陷阱门承诺（特定可适应消息的陷阱门承诺）的通用构造，通过实例化基于汉密尔顿回路问题，扩展到任何NP关系。这一工作为AS的应用，特别是在区块链等场景，提供了更安全的解决方案。 <div>
An adaptor signatures (AS) scheme is an extension of digital signatures that allows the signer to generate a pre-signature for an instance of a hard relation. This pre-signature can later be adapted to a full signature with a corresponding witness. Meanwhile, the signer can extract a witness from both the pre-signature and the signature. AS have recently garnered more attention due to its scalability and interoperability. Dai et al. [INDOCRYPT 2022] proved that AS can be constructed for any NP relation using a generic construction. However, their construction has a shortcoming: the associated witness is exposed by the adapted signature. This flaw poses limits the applications of AS, even in its motivating setting, i.e., blockchain, where the adapted signature is typically uploaded to the blockchain and is public to everyone.

To address this issue, in this work we augment the security definition of AS by a natural property which we call witness hiding. We then prove the existence of AS for any NP relation, assuming the existence of one-way functions. Concretely, we propose a generic construction of witness-hiding AS from signatures and a weak variant of trapdoor commitments, which we term trapdoor commitments with a specific adaptable message. We instantiate the latter based on the Hamiltonian cycle problem. Since the Hamiltonian cycle problem is NP-complete, we can obtain witness hiding adaptor signatures for any NP relation.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 04:12:15 +0000</pubDate>
</item>
<item>
<title>On Sequential Functions and Fine-Grained Cryptography</title>
<link>https://eprint.iacr.org/2024/1050</link>
<guid>https://eprint.iacr.org/2024/1050</guid>
<content:encoded><![CDATA[
<div> 关键词：sequential functions, one-way functions, oracle separation, continuous iterative sequential functions (CISF), fine-grained cryptography

总结:<br />
这篇文章主要探讨了序列函数（sequential functions）的理论复杂性和其与单向函数的关系。作者展示了存在一个黑盒Oracle，它能证明序列函数的存在但不能证明单向函数的存在，这与通常的构造方式形成对比。文章还深入研究了连续迭代序列函数（CISF）的决策性最坏情况问题，证明其是PSPACE-完全的。此外，通过仅假设非单向CISF，构建了“细粒度”加密和MAC等安全协议。最后，文中定义了称为交换式序列函数的新概念，它可用于实现细粒度密钥交换。这些结果揭示了序列函数在密码学中的潜在应用，即使在不依赖单向函数的情况下。 <div>
A sequential function is, informally speaking, a function $f$ for which a massively parallel adversary cannot compute "substantially" faster than an honest user with limited parallel computation power. Sequential functions form the backbone of many primitives that are extensively used in blockchains such as verifiable delay functions (VDFs) and time-lock puzzles. Despite this widespread practical use, there has been little work studying the complexity or theory of sequential functions.

Our main result is a black-box oracle separation between sequential functions and one-way functions: in particular, we show the existence of an oracle $\mathcal{O}$ that implies a sequential function but not a one-way function. This seems surprising since sequential functions are typically constructed from very strong assumptions that imply one-way functions and also since time-lock puzzles are known to imply one-way functions (Bitansky et al., ITCS '16).

We continue our exploration of the theory of sequential functions. We show that, informally speaking, the decisional, worst-case variant of a certain class of sequential function called a continuous iterative sequential function (CISF) is PSPACE-complete. A CISF is, in a nutshell, a sequential function $f$ that can be written in the form $f \left(k, x \right) = g^{k} \left(x \right)$ for some function $g$ where $k$ is an input determining the number of "rounds" the function is evaluated. We then show that more general forms of sequential functions are not contained in PSPACE relative to a random oracle.

Given these results, we then ask if it is possible to build any interesting cryptographic primitives from sequential functions that are not one-way. It turns out that even if we assume just the existence of a CISF that is not one-way, we can build certain "fine-grained" cryptographic primitives where security is defined similarly to traditional primitives with the exception that it is only guaranteed for some (generally polynomial) amount of time. In particular, we show how to build "fine-grained" symmetric key encryption and "fine-grained" MACs from a CISF. We also show how to build fine-grained public-key encryption from a VDF with a few extra natural properties and indistinguishability obfucsation (iO) for null circuits. We do not assume one-way functions. Finally, we define a primitive that we call a commutative sequential function - essentially a sequential function that can be computed in sequence to get the same output in two different ways - and show that it implies fine-grained key exchange.
]]></content:encoded>
<pubDate>Fri, 28 Jun 2024 03:36:20 +0000</pubDate>
</item>
<item>
<title>Efficient Secret Sharing for Large-Scale Applications</title>
<link>https://eprint.iacr.org/2024/1045</link>
<guid>https://eprint.iacr.org/2024/1045</guid>
<content:encoded><![CDATA[
<div> 关键词：threshold secret sharing, reconstruction time, ramp secret sharing, adaptive corruptions, distributed generation

总结:<br />
该论文研究了改进的阈值秘密共享方案，特别关注减少消息重建时间。提出了一种新型的$(t,c)$-ramp秘密分享方案，对于高阈值$t$（如$2^{20}$），其重建时间比现有方法快2-7.8倍，从$t=256$开始就有明显改善。新方案基于Cramer等人的框架和Applebaum等人的工作，利用随机带状矩阵构建高效且适应适应性攻击的错误纠正代码。应用上，该技术可降低联邦学习中安全聚合协议的计算成本，同时提供更快的可验证ramp秘密共享和分布式可验证随机函数。总的来说，这项工作显著提升了阈值秘密共享的效率和实用性。 <div>
Threshold secret sharing enables distributing a message to $n$ parties such that no subset of fewer than $t$ parties can learn the message, whereas any subset of at least $t$ parties can recover the message. Despite being a fundamental primitive, secret sharing still suffers from one significant drawback, where its message reconstruction algorithm is computationally expensive for large privacy thresholds $t$. In this paper, we aim to address this significant drawback.

We study general $(t,c)$-ramp secret sharing schemes where the number of parties c needed to reconstruct the secret may be larger than $t$. We present a ramp secret sharing scheme whose reconstruction time is 2-7.8x faster than prior constructions suitable against adversaries that adaptively corrupt parties. For $t = 2^{20}$, our new protocol has reconstruction time of 5 seconds whereas prior work requires nearly half a minute. We see improvements starting from as small as $t = 256$. Furthermore, we obtain correctness threshold as small as $c \ge 1.05t$. To obtain our construction, we first improve the secret sharing frameworks by Cramer et al. (EUROCRYPT'15) and Applebaum et al. (CRYPTO'23) from erasure codes. Our new framework obtains secret sharing schemes that may be used against adversaries with adaptive corruptions while requiring only weaker correctness guarantees from the underlying erasure code with a distributed generation property. Furthermore, our new framework also maintains the linear homomorphism of the prior works. Afterwards, we present a concretely efficient erasure code from random band matrices that satisfies the distributed generation property.

We show that our secret sharing scheme can improve many real-world applications. In secure aggregation protocols for federated learning, we obtain up to 22% reductions in computational cost by replacing Shamir's scheme with our construction. We extend our protocol to obtain a verifiable ramp secret sharing scheme where each party can verify the consistency of the shares. Our new verifiable ramp secret sharing has 8.2-25.2x faster sharing and 2.7-23.2x faster reconstruction time compared to prior works. Finally, we present an improved distributed verifiable random function that may be used for decentralized randomness beacons.
]]></content:encoded>
<pubDate>Thu, 27 Jun 2024 17:59:50 +0000</pubDate>
</item>
<item>
<title>Byzantine Fault Tolerance with Non-Determinism, Revisited</title>
<link>https://eprint.iacr.org/2024/134</link>
<guid>https://eprint.iacr.org/2024/134</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine fault tolerance (BFT), non-determinism, Block-ND, multivalued Byzantine agreement (MBA), asynchronous setting

总结:
这篇文章主要关注在非确定性环境下改进拜占庭容错（BFT）算法。作者提出了一种新的设计Block-ND，它将交易顺序的共识和状态共识分离，允许在现有的BFT实现基础上进行扩展。Block-ND通过将状态共识降级为多值拜占庭协议（MBA）来处理非确定性，尽管MBA在实践系统中被忽视。文章提供了一个比现有方案更快的MBA构造，并在部分同步和纯异步环境中实现了Block-ND。实验结果显示，Block-ND在91个节点的广域网部署中，其性能损失相对较小，与传统BFT相比具有更好的适应性。 <div>
The conventional Byzantine fault tolerance (BFT) paradigm requires replicated state machines to execute deterministic operations only. In practice, numerous applications and scenarios, especially in the era of blockchains, contain various sources of non-determinism. Despite decades of research on BFT, we still lack an efficient and easy-to-deploy solution for BFT with non-determinism—BFT-ND, especially in the asynchronous setting.
We revisit the problem of BFT-ND and provide a formal and asynchronous treatment of BFT-ND. In particular, we design and implement Block-ND that insightfully separates the task of agreeing on the order of transactions from the task of agreement on the state: Block-ND allows reusing existing BFT implementations; on top of BFT, we reduce the agreement on the state to multivalued Byzantine agreement (MBA), a somewhat neglected primitive by practical systems. Block-ND is completely asynchronous as long as the underlying BFT is asynchronous.
We provide a new MBA construction significantly faster than existing MBA constructions. We instantiate Block-ND in both the partially synchronous setting (with PBFT, OSDI 1999) and the purely asynchronous setting (with PACE, CCS 2022). Via a 91-instance WAN deployment on Amazon EC2, we show that Block-ND has only marginal performance degradation compared to conventional BFT.
]]></content:encoded>
<pubDate>Wed, 31 Jan 2024 03:06:58 +0000</pubDate>
</item>
<item>
<title>Attribute-Based Threshold Issuance Anonymous Counting Tokens and Its Application to Sybil-Resistant Self-Sovereign Identity</title>
<link>https://eprint.iacr.org/2024/1024</link>
<guid>https://eprint.iacr.org/2024/1024</guid>
<content:encoded><![CDATA[
<div> 关键词：self-sovereign identity (SSI), CanDID, privacy-preserving, attribute-based threshold anonymous counting tokens (tACT), Sybil-resistant

总结:<br />
本文探讨了自我主权身份（SSI）系统中的挑战，特别是CanDID方案的局限性。作者提出了可公开验证的属性基阈值匿名计数令牌（tACT），这是一种分布式信任环境下的创新解决方案，旨在增强匿名性和减少用户与发行者交互。tACT通过支持阈值发行、多显示选择性披露和非交互式非转移凭证，构建了一个高效的Sybil攻击抵抗的SSI系统。这个新系统在效率上优于CanDID，支持更多发行者，并实现了一轮并行协议，显著提升了用户隐私和控制性。 <div>
Self-sovereign identity (SSI) systems empower users to (anonymously) establish and verify their identity when accessing both digital and real-world resources, emerging as a promising privacy-preserving solution for user-centric identity management. Recent work by Maram et al. proposes the privacy-preserving Sybil-resistant decentralized SSI system CanDID (IEEE S&amp;P 2021). While this is an important step, notable shortcomings undermine its efficacy. The two most significant among them being the following: First, unlinkability breaks in the presence of a single malicious issuer. Second, it introduces interactiveness, as the users are required to communicate each time with issuers to collect credentials intended for use in interactions with applications. This contradicts the goal of SSI, whose aim is to give users full control over their identities. This paper first introduces the concept of publicly verifiable attribute-based threshold anonymous counting tokens (tACT). Unlike recent approaches confined to centralized settings (Benhamouda et al., ASIACRYPT 2023), tACT operates in a distributed-trust environment. Accompanied by a formal security model and a provably secure instantiation, tACT introduces a novel dimension to token issuance, which, we believe, holds independent interest. Next, the paper leverages the proposed tACT scheme to construct an efficient Sybil-resistant SSI system. This system supports various functionalities, including threshold issuance, unlinkable multi-show selective disclosure, and non-interactive, non-transferable credentials that offer constant-size credentials. Finally, our benchmark results show an efficiency improvement in our construction when compared to CanDID all while accommodating a greater number of issuers and additionally reducing to a one-round protocol that can be run in parallel with all issuers.
]]></content:encoded>
<pubDate>Tue, 25 Jun 2024 11:26:25 +0000</pubDate>
</item>
<item>
<title>Nakamoto Consensus under Bounded Processing Capacity</title>
<link>https://eprint.iacr.org/2023/381</link>
<guid>https://eprint.iacr.org/2023/381</guid>
<content:encoded><![CDATA[
<div> 关键词：Nakamoto共识、Proof-of-Work（PoW）、Proof-of-Stake（PoS）、block production rate、security-performance tradeoff。

总结:<br />
Nakamoto共识协议在有限资源网络中的安全性与性能之间存在经典问题。传统分析忽视了节点处理块的速率限制导致的拥堵。本文提出新的分析方法，揭示了在带宽受限模型中，与经典模型不同，私人攻击不再是最糟情况，而一种名为“逗弄策略”的新攻击更糟。对于PoS，equivocation会加剧拥堵，使得传统PoS NC在高生产率下不安全。为此，作者提出Blanking NC（BlaNC），它能提供与PoW NC相同的抗攻击性，同时解决拥堵问题。 <div>
For Nakamoto's longest-chain consensus protocol, whose proof-of-work (PoW) and proof-of-stake (PoS) variants power major blockchains such as Bitcoin and Cardano, we revisit the classic problem of the security--performance tradeoff: Given a network of nodes with finite communication- and computation-resources, against what fraction of adversary power is Nakamoto consensus (NC) secure for a given block production rate? State-of-the-art analyses of NC fail to answer this question, because their bounded-delay model does not capture the rate limits to nodes' processing of blocks, which cause congestion when blocks are released in quick succession. We develop a new analysis technique to prove a refined security--performance tradeoff for PoW NC in a bounded-capacity model. In this model, we show that, in contrast to the classic bounded-delay model, Nakamoto's private attack is no longer the worst attack, and a new attack we call the teasing strategy, that exploits congestion, is strictly worse. In PoS, equivocating blocks can exacerbate congestion, making traditional PoS NC insecure except at very low block production rates. To counter such equivocation spamming, we present a variant of PoS NC we call Blanking NC (BlaNC), which achieves the same resilience as PoW NC.
]]></content:encoded>
<pubDate>Thu, 16 Mar 2023 06:26:28 +0000</pubDate>
</item>
<item>
<title>Security-Performance Tradeoff in DAG-based Proof-of-Work Blockchain Protocols</title>
<link>https://eprint.iacr.org/2023/1089</link>
<guid>https://eprint.iacr.org/2023/1089</guid>
<content:encoded><![CDATA[
<div> 关键词：Proof-of-Work（PoW）、Directed Acyclic Graphs（DAGs）、Congestible Blockchain Model（CBM）、Late-Predecessor Attack、Prism、OHIE。

总结:
这篇文章探讨了基于DAG的PoW区块链协议在高吞吐量环境下的安全性和性能。通过引入CBM模型，研究者分析了同时存在的块和复杂依赖如何影响延迟。他们设计了一种攻击策略——late-predecessor攻击，利用块间的依赖延迟诚实块的处理。针对Prism和OHIE两个旨在打破安全性能权衡的协议，研究发现它们在高吞吐量下会面临降级的安全性以及延长的延迟，这类似于传统的链式协议。 <div>
Proof-of-work (PoW) blockchain protocols based on directed acyclic graphs (DAGs) have demonstrated superior transaction confirmation performance compared to their chain-based predecessors. However, it is uncertain whether their security deteriorates in high-throughput settings similar to their predecessors, because their acceptance of simultaneous blocks and complex block dependencies presents challenges for rigorous security analysis.

We address these challenges by analyzing DAG-based protocols via a congestible blockchain model (CBM), a general model that allows case-by-case upper bounds on the block propagation delay, rather than a uniform upper bound as in most previous analyses. CBM allows us to capture two key phenomena of high-throughput settings: (1) simultaneous blocks increase each other's propagation delay, and (2) a block can be processed only after receiving all the blocks it refers to. We further devise a reasonable adversarial block propagation strategy in CBM, called the late-predecessor attack, which exploits block dependencies to delay the processing of honest blocks. We then evaluate the security and performance of Prism and OHIE, two DAG-based protocols that aim to break the security-performance tradeoff, in the presence of an attacker capable of launching the late predecessor attack. Our results show that these protocols suffer from reduced security and extended latency in high-throughput settings similar to their chain-based predecessors.
]]></content:encoded>
<pubDate>Thu, 13 Jul 2023 04:05:02 +0000</pubDate>
</item>
</channel>
</rss>