<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom">
<channel>
<title>Cryptology ePrint Archive</title>
<link>https://eprint.iacr.org/rss/rss.xml</link>

<item>
<title>Perfect 2-Party Computation from Additive Somewhat Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/273</link>
<guid>https://eprint.iacr.org/2024/273</guid>
<content:encoded><![CDATA[

We present protocols where one entity, the server, evaluates a circuit with encrypted inputs from the second party, the client.
We give secret key somewhat homomorphic additive schemes where the client has perfect privacy (server is computationally unbounded). 
Our scheme is somewhat homomorphic additive and we extend it to support multiplication. The server handles circuit multiplication gates by sending the multiplicands to the client which does the multiplication and updates the decryption key so that the original ciphertext vector includes the encrypted multiplication gate outputs. The key idea for client privacy is the permutation table which consists of rows of vectors modulo a prime integer
$m.$ The initial row is $(1, d_2, \ldots, d_c)$ where $d_{i-1} | d_i,$ $d_i > N d_{i-1},$ for an integer $N$ which is a power of 2, $2 \leq i \leq c.$ Subsequent rows are integer multiples of the first row, modulo $m.$ The permutation table has a subset of rows (vectors) that are relatively short (facilitating addition without overflowing $m$) and which map to every possible vector modulo $N$ (giving perfect privacy since every plaintext vector is possible given a ciphertext vector from the table.)

We present a new computational hardness problem: the Hidden Subset Sum Problem (HSSP). In the HSSP, the base elements 
which are summed are not shared with the adversary. 

We give a 2-party computation (2PC) protocol that also incorporates server inputs where the client has perfect privacy.
Server privacy only holds against a computationally bounded adversary since it depends on the hardness of the HSSP and the DDH (Decisional Diffie Hellman Assumption). We leverage the Castagnos Laguillaumie linear homomorrphic public key encryption for setup. The 2PC protocol maintains circuit privacy except for leaking the number of multiplication gates to the client. Scaling the 2PC protocol via separate encryption parameters for smaller subcircuits allows the ciphertext size to remain constant as circuit size grows.
]]></content:encoded>
<pubDate>Sun, 18 Feb 2024 23:20:46 +0000</pubDate>
<pubDate>Sun, 18 Feb 2024 23:20:46 +0000</pubDate>
</item>
<item>
<title>PAC-Private Databases</title>
<link>https://eprint.iacr.org/2026/238</link>
<guid>https://eprint.iacr.org/2026/238</guid>
<content:encoded><![CDATA[

As data collection and sharing becomes more prevalent, quantifying leakage about released data is an increasingly crucial privacy issue. Prior work in private database analytics demonstrates how to provide strong theoretical privacy guarantees through differential privacy (DP). However, these techniques are often limited to specific queries; to the best of our knowledge, among the 19 queries in the TPC-H benchmark which do not directly leak customer information, prior work in DP can handle at most 9 queries, without additional analyst effort.

In this work, we apply the recently-proposed Probably Approximately Correct (PAC)  Privacy mechanism in order to provide a black-box technique to privatize general SQL queries against membership inference attacks. Naively applying PAC Privacy would allow us to privatize any individual query. However, databases are an interactive process: a user queries the database, views the response, and then chooses their next query. Prior work in PAC Privacy cannot provide any theoretical guarantees in this setting; instead, users would be required to provide all the queries a priori, which is a fundamental usability limitation. We construct the first algorithm to allow users to query the database adaptively and prove that algorithmic modifications via independent randomness provide automatic privatization guarantees.

Our privatization layer, PAC-DB, does not require any human analysis in order to privately return a response for a general SQL query. PAC-DB is compatible with any database management system and does not require a trusted data curator. We provide an open-source implementation, where we privatize all of the 19 queries in consideration from the TPC-H benchmark with customers as our privacy concern. We provide both relative errors and initial performance estimates.
]]></content:encoded>
<pubDate>Thu, 12 Feb 2026 19:55:36 +0000</pubDate>
<pubDate>Thu, 12 Feb 2026 19:55:36 +0000</pubDate>
</item>

<item>
<title>RAGtime-PIANO: Efficient Secure Remote RAG</title>
<link>https://eprint.iacr.org/2026/231</link>
<guid>https://eprint.iacr.org/2026/231</guid>
<content:encoded><![CDATA[
Retrieval Augmented Generation (RAG) can enhance the performance of Large Language Models (LLMs) when used in conjunction with a comprehensive knowledge database. However, the space required to store the necessary information can be taxing when RAG is used locally. As such, the concept of RAG-as-a-Service (RaaS) has emerged, in which third-party servers can be used to process client queries via an external database. Unfortunately, using such a service would expose the client's query to a third party, making the product unsuitable for processing sensitive queries. Our scheme ensures that throughout the entire RAG processing, neither the query, any distances, nor retrieval information is known to the database hosting server. Using a two-pronged approach, we employ Fully Homomorphic Encryption (FHE) and Private Information Retrieval (PIR) to ensure complete security during RAG processing. FHE is used to maintain privacy during initial query processing, during which the query embedding is encrypted and sent to the server for k-means centroid scoring to obtain a similarity ranking. Then, a series of PIR queries is used to privately retrieve the centroid-associated embeddings and the top-ranked documents. A first-of-its-kind, lightweight, fully secure RAG protocol, RAGtime-PIANO, enables efficient secure RAG.
]]></content:encoded>
<pubDate>Wed, 11 Feb 2026 19:53:40 +0000</pubDate>
</item>
<item>
<title>Analysis and Vulnerabilities in zkLogin</title>
<link>https://eprint.iacr.org/2026/227</link>
<guid>https://eprint.iacr.org/2026/227</guid>
<content:encoded><![CDATA[
Zero-Knowledge Authorization (ZKA) systems allow users to prove possession of externally issued credentials (e.g., JSON Web Tokens) without revealing the credentials in full via the usage of Zero-Knowledge Proofs (ZKP). They are increasingly promoted as privacy-preserving and decentralized alternatives for authorization, and are already deployed in practice, with proposals for higher-stakes settings such as government access-control frameworks. In this work, we show that the security and privacy of zkLogin—the most widely deployed ZKA system—cannot only be reduced to the underlying ZKP. Instead, zkLogin critically depends on non-cryptographic assumptions about JWT/JSON parsing, issuer trust policy, architectural binding, and execution-environment integrity: none of which are specified or enforced as protocol-level properties.

Via an analysis of the public documentation, source code and surveys on wallets and public endpoints, we identify three broad classes of vulnerabilities in zkLogin: (i) permissive, non-canonical claim extraction that admits malformed JWTs; (ii) transformation of short-lived authentication artifacts into durable authorization credentials without enforcing their issuance context (issuer, audience, subject and temporal validity binding), which enables cross-application impersonation and misuse—particularly in browser-based deployments that expose system’s material; and (iii) systemic centralization and privacy risks arising from reliance on a small set of issuers and outsourced proving infrastructure, including disclosure of user identity attributes to third-party services without consent. We note that none of the vulnerabilities identified are cryptographic in nature. Overall, our findings demonstrate that zkLogin inherits, and in some cases amplifies, fragilities of web-based authentication ecosystems, and that the security of the system cannot be reduced only to the ZKPs
]]></content:encoded>
<pubDate>Wed, 11 Feb 2026 11:13:10 +0000</pubDate>
</item>
<item>
<title>Optimizing Differential Privacy in Federated Analytics under Known Input Distributions</title>
<link>https://eprint.iacr.org/2026/220</link>
<guid>https://eprint.iacr.org/2026/220</guid>
<content:encoded><![CDATA[
Differential privacy (DP) is one of the most efficient tools for protecting the privacy of individual data holders under computation. This property guarantees that the computation outputs for every pair of adjacent input sets are statistically indistinguishable with respect to a given parameter ε, which is independent of the likelihood that specific inputs occur or not. While the distribution of input sets is generally unknown, in some use cases (approximate) information about it might be available. If the latter is the case, two adjacent inputs of one individual are sometimes already obfuscated by other inputs and the computation itself (i.e., without any additional noise). For example, if the sum of n independent and identically distributed uniformly random bits outputs approximately n/2, both values for the first bit remain (almost) equally likely for large n.

Based on this observation, we present a new DP mechanism that uses an estimate of the input distribution to reduce the noise addition (compared to standard DP) and hence improves the accuracy of the output. We first explore this idea in the central model, where a single central party collects all data. Then, we provide a new technique (possibly of independent interest) that allows multiple entities to jointly generate reduced noise, using the property of infinite divisibility. This allows each party to individually add noise to their respective inputs, e.g., in Federated Analytics applications.

We apply our theoretical results, both for the single and multi-party setups, to perform data analysis over human resources data from different subsidiaries within a corporate group. Our benchmarks show that our new DP mechanism provides more accurate outputs while retaining the same privacy level as state-of-the-art DP approaches using the geometric mechanism.
]]></content:encoded>
<pubDate>Tue, 10 Feb 2026 11:44:15 +0000</pubDate>
</item>
<item>
<title>Cavefish: Communication-Optimal Light Client Protocol for UTxO Ledgers</title>
<link>https://eprint.iacr.org/2026/217</link>
<guid>https://eprint.iacr.org/2026/217</guid>
<content:encoded><![CDATA[
Blockchain light clients (LCs) are agents with limited resources that are not able or not willing to maintain a fully validated copy of the ledger. They rely on service providers (SPs), typically full nodes, to access data required for tasks such as constructing transactions or interacting with off-chain applications.
We introduce Cavefish, a novel protocol for UTxO-based platforms that enables LCs to submit transactions with minimal trust, storage, and computation overheads. Cavefish defines a two-party computation protocol between an LC and an SP, in which the LC specifies a transaction and the SP constructs it. The LC only receives a blinded version of the transaction, preventing modification and reuse, but allowing the LC to verify the transaction against the original intent. The SP is compensated inside the constructed transaction, eliminating the need for a separate protocol or exchange.
To support this, we propose a variant of the predicate blind signature (PBS) scheme of Fuchsbauer and Wolf (Eurocrypt 2024), letting the SP obtain a valid signature on the unblinded transaction, which can then be posted on chain as the resulting signatures verify as standard Schnorr signatures. When combined with hierarchical deterministic (HD) wallets, the LC can provide a single public key and chain code to the SP, reducing communication footprint to a minimum. To further reduce overheads, our PBS variant relaxes the unlinkability requirements of traditional blind signatures in favor of efficiency as transactions only need to stay private until posted.
On top of this, we define a multi-SP version of Cavefish that provides strong liveness and optimality guarantees. We benchmark the Non-interactive Argument of Knowledge (NArg) component of Cavefish on two major UTxO-based blockchains. Our results show that proving and verification times, as well as circuit sizes, are practical for real-world deployment.
]]></content:encoded>
<pubDate>Tue, 10 Feb 2026 09:13:40 +0000</pubDate>
</item>
<item>
<title>ECHO: Efficient Covertly-Secure Three-party Computation with Applications to Private Machine Learning</title>
<link>https://eprint.iacr.org/2026/216</link>
<guid>https://eprint.iacr.org/2026/216</guid>
<content:encoded><![CDATA[
Secure three-party computation with an honest majority is one of the most efficient settings in secure computation, and has been widely adopted in practical applications. However, achieving malicious security in this setting incurs significant concrete efficiency penalties, which could be an order of magnitude worse than that of their semi-honest counterparts. Covert security offers a potential security-efficiency trade-off by detecting malicious behavior with a certain probability (such as $50\%$), deterring rational adversaries through the risk of detection and loss of credibility. Yet, existing covert security research primarily focuses on two-party or general $n$-party protocols in the dishonest-majority setting, with limited progress toward efficient three-party solutions. 


This work presents the first comprehensive framework, $\mathsf{ECHO}$, for covertly secure, honest-majority three-party computation with applications to privacy-preserving machine learning. We systematically explore the design space of cheating detection and cheater identification techniques, and propose a suite of novel protocols for both arithmetic and Boolean circuits. Each protocol is engineered for a distinct performance goal: minimal online latency, high end-to-end efficiency, or low communication. Notably, for arithmetic circuits over rings, we introduce a protocol leveraging asymmetric message authentication codes, achieving an online phase that is only $1.26\times$ slower than the semi-honest baseline, over three times faster than its maliciously secure counterpart. For Boolean circuits, our novel cut-and-choose-based method outperforms the best previous maliciously secure protocol by a factor of five. In practical PPML benchmarks, our framework achieves near semi-honest performance while delivering up to $8\times$ speedup over maliciously secure protocols on real-world tasks.
]]></content:encoded>
<pubDate>Tue, 10 Feb 2026 08:40:58 +0000</pubDate>
</item>
<item>
<title>Orbit: Optimizing Rescale and Bootstrap Placement with Integer Linear Programming Techniques for Secure Inference</title>
<link>https://eprint.iacr.org/2026/213</link>
<guid>https://eprint.iacr.org/2026/213</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) allows computation on encrypted data without decrypting it. In theory, FHE makes privacy-preserving machine learning possible. In practice, however, it remains impractically slow for real workloads. A major source of slowdown is bootstrap operations; in CKKS, a popular FHE scheme for tensor workloads, the slowdown is compounded by scale management and rescale operations.  

FHE compilers aim to make bootstrap placement and scale management efficient and easy by compiling high-level programs into low-level, optimized FHE computations. Unfortunately, existing approaches miss crucial optimization opportunities because they overlook a key property of CKKS programs: bootstrap and rescale placement are fundamentally coupled through the level budget. In this paper, we present Orbit, an FHE compiler that jointly optimizes bootstrap and rescale placement through a novel Integer Linear Programming (ILP) formulation that reasons about both ciphertext level and scale constraints. To make this formulation tractable for end-to-end programs, we introduce three techniques that reduce ILP complexity while preserving optimality. Across five convolutional neural networks and multiple cryptographic parameter configurations, Orbit achieves a geometric mean speedup up to 1.19× over DaCapo, 1.73× over Orion, and 1.52× over ReSBM, keeps compilation under 6 minutes, and retains model accuracy within 0.3% of plaintext execution.
]]></content:encoded>
<pubDate>Tue, 10 Feb 2026 03:24:47 +0000</pubDate>
</item>
<item>
<title>zkAgent: Verifiable Agent Execution via One-Shot Complete LLM Inference Proof</title>
<link>https://eprint.iacr.org/2026/199</link>
<guid>https://eprint.iacr.org/2026/199</guid>
<content:encoded><![CDATA[
Recent advances in large language models have enabled LLM-based agents to move beyond text generation toward long-term execution involving tool use, multi-step interactions, and autonomous decision-making. However, the agent provider may be compromised and return malicious outputs. As agents increasingly manage sensitive data and financial assets, such misbehavior can cause severe real-world harm. Recent work leverages zero-knowledge proofs to verify the correctness of LLM inference, ensuring that the provider can only return outputs consistent with the claimed model. Nevertheless, these approaches are limited to standalone transformer computations and fail to support agent executions.

We present zkAgent, an efficient SNARK system for agent execution. Beyond prior Transformer-only proofs, zkAgent proves the entire agent execution, including end-to-end LLM inference and tool interactions.
Furthermore, zkAgent achieves scalable proof generation by proving multi-step agent interactions through a single, one-shot inference proof, eliminating the need to prove each intermediate token generation. To our knowledge, zkAgent is the first system to provide practical verifiable agent execution that simultaneously attests to complete LLM inference and tool interactions.

Our evaluation shows that, for a 512-token agent inference with GPT-2, zkAgent achieves an amortized proving time of 1.05s/token, a $294\times$ speedup over the state of the art, zkGPT (USENIX Security~’25) which requires $309$s/token with step-by-step generation. 
zkAgent also reduces verification time by $9{,}690\times$ (0.45s vs. 4361.09s).
Moreover, for end-to-end agent executions, such as a weather agent and a coding assistant, zkAgent completes proving in 240s and verification in about 0.5s, with proof size of $42$MB, making verifiable agent execution practical in real-world deployments.
]]></content:encoded>
<pubDate>Sat, 07 Feb 2026 16:15:22 +0000</pubDate>
</item>
<item>
<title>ELLMo: Packing- and Depth-Aware Encrypted Transformer Inference</title>
<link>https://eprint.iacr.org/2026/198</link>
<guid>https://eprint.iacr.org/2026/198</guid>
<content:encoded><![CDATA[
Cloud-based Large Language Model (LLM) inference processes sensitive user inputs, yet current deployments offer limited confidentiality guarantees. Fully Homomorphic Encryption (FHE) can provide strong privacy, but it clashes with transformer architectures, where rigid ciphertext packing demands expensive rotations, and deep polynomial circuits for nonlinearities necessitate costly bootstrapping. Although recent work has reported promising speed-ups, maintaining model accuracy is a challenge. We address these issues with ELLMo, a packing- and depth-aware encrypted transformer design. ELLMo introduces a novel matrix multiplication algorithm to reduce the ciphertext rotations. Further, head-split and merge steps are fused into this new algorithm at no additional cost. To reduce the depth of nonlinear layers, our contributions, Statistical-max Softmax and DelayNorm, help bypass deep comparison trees and homomorphic divisions to reduce bootstrapping by up to 46%. On encrypted BERT-Tiny, ELLMo achieves a $1.4\times$ speedup over state-of-the-art baselines with 0-1.5% accuracy loss across SST-2, MRPC, and RTE downstream tasks.
]]></content:encoded>
<pubDate>Sat, 07 Feb 2026 02:28:23 +0000</pubDate>
</item>
<item>
<title>Identity-Based Matchmaking Encryption with Enhanced Privacy Against Chosen-Ciphertext Attacks</title>
<link>https://eprint.iacr.org/2023/1435</link>
<guid>https://eprint.iacr.org/2023/1435</guid>
<content:encoded><![CDATA[
<div> 关键词：身份基匹配加密、选择密文攻击、增强隐私、标准模型、安全性分类

<br /><br />总结:  
1. 本文提出了两个具备抗选择密文攻击（CCA）增强隐私性的身份基匹配加密（IB-ME）方案。  
2. 第一个方案基于双线性Diffie–Hellman假设，在随机预言机模型下实现，相比Ateniese等人方案具有更紧凑的解密密钥和密文，并提供更强的安全性。  
3. 第二个方案为通用构造，结合匿名身份基加密、数字签名、NIZK系统和可重用提取器，在标准模型中首次实现强安全性的IB-ME。  
4. 该方案推广了Francati等人在INDOCRYPT 2021的工作。  
5. 作者还对现有IB-ME方案的真实性概念进行了系统分类，划分为四类（内/外部攻击者下的无消息攻击与选择消息攻击），便于精确比较不同方案的安全性。 <div>
Identity-based matchmaking encryption (IB-ME) proposed by Ateniese et al. [CRYPTO 2019; Journal of Cryptology 2021] enables users to communicate privately, anonymously, and authentically. Following the seminal work of Ateniese et al., considerable research has been conducted on the security and construction of IB-ME schemes, but no scheme with enhanced privacy against chosen-ciphertext attacks is known.
In this paper, we propose two IB-ME schemes that simultaneously achieve enhanced privacy against chosen-ciphertext attacks. The first scheme is built on the bilinear Diffie–Hellman assumption in the random oracle model. Inspired by the scheme of Ateniese et al., our construction attains stronger security guarantees while providing more compact decryption keys and ciphertexts than the scheme of Ateniese et al.
The second scheme is a generic construction built upon anonymous identity-based encryption, digital signatures, NIZK systems, and reusable extractors. This scheme is obtained by generalizing the specific scheme of Francati et al. [INDOCRYPT 2021] and constitutes the first IB-ME scheme achieving the stronger security notions in the standard model.
As an additional contribution, we classify existing authenticity notions for IB-ME into four categories—no message attacks (NMA) and chosen message attacks (CMA), each considered against both insiders and outsiders. This taxonomy enables a precise comparison among existing IB-ME schemes.
]]></content:encoded>
<pubDate>Thu, 21 Sep 2023 10:42:32 +0000</pubDate>
</item>
<item>
<title>Three-Round (Robust) Threshold ECDSA from Threshold CL Encryption</title>
<link>https://eprint.iacr.org/2026/190</link>
<guid>https://eprint.iacr.org/2026/190</guid>
<content:encoded><![CDATA[
<div> 阈值ECDSA、通信复杂度、三轮协议、CL加密、鲁棒性<br /><br />总结:  
1. 阈值ECDSA可有效避免区块链系统中的单点故障，是关键安全组件。  
2. 现有方案中，Doerner等人提出三轮协议但通信复杂度为O(n)，Wong等人实现常数通信复杂度却需至少四轮。  
3. 本文提出首个基于阈值CL加密的三轮阈值ECDSA方案，兼具三轮交互与常数出站通信复杂度。  
4. 进一步增强了方案的鲁棒性，在保持三轮通信的同时牺牲了常数通信复杂度。  
5. 实验表明，基础方案在运行时间和通信开销上达到最优，鲁棒版本在小规模场景下仅带来轻微额外开销，并减少了Wong等人方案所需的通信轮数。 <div>
Threshold ECDSA has become a crucial security component in blockchain and decentralized systems, as it mitigates the risk of a single point of failure. Following the multiplicative-to-additive approach, the state-of-the-art threshold ECDSA (Doerner et al. in S&amp;P24) requires only three rounds but has \( O(n) \) outgoing communication complexity. Based on threshold CL encryption, Wong et al. (in NDSS24) proposed the first scheme with constant outgoing communication; however, their scheme requires at least four rounds.  

We bridge this gap by introducing a three-round threshold ECDSA scheme with constant outgoing communication based on threshold CL encryption. Additionally, we enhance our basic scheme with robustness while maintaining the number of communication rounds, albeit at the cost of non-constant outgoing communication. Our implementation demonstrates that the basic scheme achieves optimal runtime and communication costs, while the robust variant reduces the communication rounds required by Wong et al.'s scheme, incurring only a small additional cost in small-scale settings.
]]></content:encoded>
<pubDate>Thu, 05 Feb 2026 16:58:00 +0000</pubDate>
</item>
<item>
<title>Computing in a Safe House: Accountable Universally Composable Asynchronous Secure Distributed Computing</title>
<link>https://eprint.iacr.org/2026/182</link>
<guid>https://eprint.iacr.org/2026/182</guid>
<content:encoded><![CDATA[
<div> 非同步网络、容错协议、可问责性、零知识编译器、拜占庭容错<br /><br />总结:<br />1. 在非同步网络中，当恶意节点数 $f \geq n - 2t$ 时，传统 $t$-容错协议难以保证安全性，需引入可问责机制。<br />2. 本文提出通用编译器 $\tau_{zk\text{-}scr}$，可将半诚实崩溃故障安全的协议 $\mathcal{P}$ 转换为具备拜占庭容错与可问责性的协议 $\bar{\mathcal{P}}$。<br />3. 该编译器基于CLOS编译器解构设计，通过全局传播实现各组件的可问责性，并在 $f \leq t_{\epsilon} = \lceil n (\frac{1}{3}-\epsilon) \rceil - 1$ 时保留原协议的隐私、输入独立性、正确性与输出交付等超属性。<br />4. 当 $f > t_{\epsilon}$ 时，要么保持超安全性（可能无输出），要么所有正确节点获得可验证的作恶证据。<br />5. 在透明设置下，对任意常数 $\epsilon > 0$，其实例可抵御1延迟自适应攻击者，通信开销为 $o(n^2)$，并基于AUC框架形式化证明其安全性。 <div>
In non-synchronous networks, partitioning arguments show that $t$-resilient protocols among $n$ processes can typically not guarantee safety when the number of malicious processes $f$ is $\geq n - 2t$. This fragility motivates augmenting such protocols with accountability schemes to deter safety violations. So far however, such schemes have been limited in their verifiability, scalability or privacy.

This paper presents $\tau_{zk\text{-}scr}$, a universal compiler that circumvents such limitations. The compiler transforms any protocol $\mathcal{P}$, that is secure against semi-honest crash-failure adversaries, into a Byzantine-tolerant, accountable counterpart $\bar{\mathcal{P}}$.  Essentially, we devise $\tau_{zk\text{-}scr}$ by deconstructing the celebrated CLOS compiler (STOC 2002), observing that each resulting component is ``easily accountable'', and globally propagating the accountability through the reconstruction. The guarantees provided by $\tau_{zk\text{-}scr}$  are defined with respect to a resilience threshold $t_{\epsilon} = \lceil n (\frac{1}{3}-\epsilon) \rceil - 1$, for any $\epsilon \geq 0$.  $\bar{\mathcal{P}}$ preserves the hyperproperties of $\mathcal{P}$, including privacy, input-independence, correctness, and output delivery, whenever $f \leq t_{\epsilon}$.

If $f > t_{\epsilon}$, then either: (1) $\bar{\mathcal{P}}$ emulates $\mathcal{P}$, in the sense that all its hypersafety properties are preserved, though output delivery may not occur; or (2) all correct processes obtain externally verifiable proofs of misbehavior involving a significant subset of faulty parties. By adjusting its parameters, $\tau_{zk\text{-}scr}$ achieves various trade-offs. Assuming a transparent setup, for any strictly positive constant $\epsilon \in \Omega(1)$, the most efficient instantiation provides security against a 1-delayed-adaptive adversary (i.e., where corruption decisions are postponed just long enough to allow messages in transit to be delivered) with $o(n^2)$ multiplicative communication overhead.

Our results are formalized and proven following the Accountable Universal Composability (AUC) blueprint (S&amp;P 2023), an extension of UC designed to support modular analysis of accountability guarantees.
]]></content:encoded>
<pubDate>Wed, 04 Feb 2026 12:57:54 +0000</pubDate>
</item>
<item>
<title>Nudge: A Private Recommendations Engine</title>
<link>https://eprint.iacr.org/2026/179</link>
<guid>https://eprint.iacr.org/2026/179</guid>
<content:encoded><![CDATA[
<div> Nudge、推荐系统、密码学隐私、三方计算、矩阵分解<br /><br />总结:<br />1. Nudge 是一个具备密码学隐私保护的推荐系统，由三个基础设施服务器和大量用户组成。<br />2. 用户从大型数据集中检索和评分项目，其评分以秘密共享形式提交，保障隐私。<br />3. 三个服务器通过新型三方计算协议执行矩阵分解，训练轻量级推荐模型，过程中不泄露用户个体偏好。<br />4. 系统可抵御攻破单个服务器全部密态的攻击者，确保用户隐私安全。<br />5. 在 Netflix 数据集上的实验表明，Nudge 能在 50 分钟内完成模型训练，推荐质量（nDCG@20=0.29）接近非隐私神经推荐系统（0.31）。 <div>
Nudge is a recommender system with cryptographic privacy. A Nudge deployment consists of three infrastructure servers and many users, who retrieve/rate items from a large data set (e.g., videos, posts, businesses). Periodically, the Nudge servers collect ratings from users in secret-shared form, then run a three-party computation to train a lightweight recommender model on users’ private ratings. Finally, the servers deliver personalized recommendations to each user. At every step, Nudge reveals nothing to the servers about any user’s preferences beyond the aggregate model itself. User privacy holds against an adversary that compromises the entire secret state of one server. The technical core of Nudge is a new, three-party protocol for matrix factorization. On the Netflix data set with half a million users and ten thousand items, Nudge (running on three 192-core servers on a local-area network) privately learns a recommender model in 50 mins with 40 GB of server-to-server communication. On a standard quality benchmark (nDCG@20), Nudge scores 0.29 out of 1.0, on par with non-private matrix factorization and just shy of non-private neural recommenders, which score 0.31.
]]></content:encoded>
<pubDate>Wed, 04 Feb 2026 01:10:01 +0000</pubDate>
</item>
<item>
<title>gcVM: Publicly Auditable MPC via Garbled Circuits with Applications to Private EVM-Compatible Computation</title>
<link>https://eprint.iacr.org/2026/170</link>
<guid>https://eprint.iacr.org/2026/170</guid>
<content:encoded><![CDATA[
<div> 区块链 隐私保护 安全多方计算 混淆电路 gcVM<br /><br />总结:<br />1. 当前区块链在可扩展性和容错性方面取得进展，但在保密性上仍存在根本限制，阻碍了对隐私计算有需求的用户采用。<br />2. 现有零知识证明方案在多参与方共享私有状态的计算中面临性能与可组合性挑战。<br />3. 本文提出gcVM，一种基于混淆电路的安全多方计算扩展，集成到以太坊虚拟机（EVM）中，支持通用型链上隐私计算。<br />4. gcVM在保证公有链透明性的同时，实现强保密性，支持不可信参与方之间的交易交互。<br />5. 实验表明gcVM在标准云实例上可达83 cTPS，预计优化后达500 cTPS，远超基于全同态加密（FHE）的方案，且兼容现有EVM工具、无需可信硬件、支持公开审计。 <div>
Blockchains have achieved substantial progress in scalability
and fault tolerance, yet they remain fundamentally limited in
confidentiality, hindering adoption by businesses, communities, and individuals who require privacy-preserving computations. Existing zero-knowledge (ZK) solutions provide partial privacy guarantees but struggle with performance and composability, especially for multi-party computations over shared private state. In this work, we introduce gcVM, a novel extension to the Ethereum Virtual Machine (EVM) that
integrates garbled-circuit-based secure multi-party computation to enable general-purpose, privacy-preserving computation on-chain. gcVM allows transactional interactions between
untrusted parties while balancing the transparency of public blockchains with strong confidentiality. Our implementation demonstrates up to 83 confidential transactions per second (cTPS) on standard cloud instances, with projected enhancements expected to scale throughput to approximately 500 cTPS—two to three orders of magnitude faster than comparable FHE-based solutions. gcVM is compatible with existing EVM tooling, provides public auditability, and requires no trusted hardware, offering a practical and efficient platform for privacy-centric blockchain applications across finance, governance, and decentralized services.
]]></content:encoded>
<pubDate>Mon, 02 Feb 2026 10:07:41 +0000</pubDate>
</item>
<item>
<title>Secure Montgomery Curves over TMVP-Friendly Primes for High-Performance ECC</title>
<link>https://eprint.iacr.org/2026/165</link>
<guid>https://eprint.iacr.org/2026/165</guid>
<content:encoded><![CDATA[
<div> Curve5453 Curve6071 Montgomery曲线 Crandall素数 Mersenne素数<br /><br />总结:<br />1. 提出了两条Montgomery曲线Curve5453和Curve6071，分别基于Crandall素数$2^{545}-3$和Mersenne素数$2^{607}-1$，提供271位和302位经典安全强度。<br />2. 安全性分析表明，Curve6071满足所有可验证的SafeCurves标准，Curve5453除完整性外均满足。<br />3. 针对64位架构的10段表示，设计了优化的TMVP域乘法，分别比现有方案提速12.0%和20.4%。<br />4. ARM64平台上的标量乘法耗时分别为871,898和895,028周期，性能优于或媲美如E-521等低安全级别曲线。<br />5. 这些曲线填补了高安全混合后量子密码、长期安全区块链及强健实现场景中缺乏高效且SafeCurves兼容方案的空白。 <div>
We propose Curve5453 and Curve6071, two Montgomery curves over the Crandall prime $2^{545}-3$ and Mersenne prime $2^{607}-1$, respectively, providing 271 and 302 bits of classical security.
Comprehensive security analysis shows Curve6071 passes all verifiable SafeCurves criteria, while Curve5453 passes all except completeness.
We develop TMVP-optimized field multiplication tailored to the arithmetic structure of these primes for 10-limb representations on 64-bit architectures, achieving $12.0\%$ and $20.4\%$ speedups over the closest alternative.
ARM64 benchmarks show scalar multiplication completing in 871,898 and 895,028 cycles, respectively, competitive with existing lower-security alternatives such as E-521 (259-bit security) while delivering higher security levels.
These curves address a critical gap for hybrid post-quantum constructions requiring classical security commensurate with quantum-resistant components, blockchain systems with decades-long security requirements, and specialized deployments where implementation robustness and enhanced classical security are essential---providing the first SafeCurves-compliant alternatives beyond 260 bits with demonstrated practical performance on modern architectures.
]]></content:encoded>
<pubDate>Sun, 01 Feb 2026 03:11:38 +0000</pubDate>
</item>
<item>
<title>Leveraging ASIC AI Chips for Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2026/160</link>
<guid>https://eprint.iacr.org/2026/160</guid>
<content:encoded><![CDATA[
<div> 同态加密、TPU、AI加速器、能效优化、编译器框架<br /><br />总结:<br />1. 同态加密（HE）虽保障云服务数据隐私，但计算开销大；GPU可加速HE，但能效远低于专用ASIC。<br />2. 现有AI加速器（如TPU）具备高能效潜力，但其低精度矩阵引擎（MXU）和粗粒度内存架构与当前面向GPU设计的HE算法不兼容。<br />3. GPU优化的HE算法依赖高精度整数运算和细粒度数据重排，在TPU上导致资源利用率低、性能下降。<br />4. 为此提出CROSS编译器框架，包含两项关键技术：Basis-Aligned Transformation（BAT）将高精度模运算转为INT8矩阵乘法以激活MXU；Memory-Aligned Transformation（MAT）通过离线参数转换将数据重排嵌入计算核，避免运行时开销。<br />5. 实验表明，CROSS在TPU v6e上对NTT和HE算子的能效优于现有方案，确立AI ASIC为HE高效执行的新标杆。 <div>
Homomorphic Encryption (HE) provides strong data privacy for cloud services but at the cost of prohibitive computational overhead. While GPUs have emerged as a practical platform for accelerating HE, there remains an order-of-magnitude energy-efficiency gap compared to specialized (but expensive) HE ASICs. This paper explores an alternate direction: leveraging existing AI accelerators, like Google's TPUs with coarse-grained compute and memory architectures, to offer a path toward ASIC-level energy efficiency for HE. However, this architectural paradigm creates a fundamental mismatch with SoTA HE algorithms designed for GPUs. These algorithms rely heavily on: (1) high-precision (32-bit) integer arithmetic to now run on a TPU's low-throughput vector unit, leaving its high-throughput low-precision (8-bit) matrix engine (MXU) idle, and (2) fine-grained data permutations that are inefficient on the TPU's coarse-grained memory subsystem. Consequently, porting GPU-optimized HE libraries to TPUs results in severe resource under-utilization and performance degradation. To tackle above challenges, we introduce CROSS, a compiler framework that systematically transforms HE workloads to align with the TPU's architecture. CROSS makes two key contributions: (1) Basis-Aligned Transformation (BAT), a novel technique that converts high-precision modular arithmetic into dense, low-precision (INT8) matrix multiplications, unlocking and improving the utilization of TPU's MXU for HE, and (2) Memory-Aligned Transformation (MAT), which eliminates costly runtime data reordering by embedding reordering into compute kernels through offline parameter transformation. CROSS (TPU v6e) achieves higher throughput per watt on NTT and HE operators than WarpDrive, FIDESlib, FAB, HEAP, and Cheddar, establishing AI ASIC as the SotA efficient platform for HE operators. Code: https://github.com/EfficientPPML/CROSS
]]></content:encoded>
<pubDate>Sat, 31 Jan 2026 03:58:20 +0000</pubDate>
</item>
<item>
<title>Setup Protocols for Sender Anonymity</title>
<link>https://eprint.iacr.org/2026/158</link>
<guid>https://eprint.iacr.org/2026/158</guid>
<content:encoded><![CDATA[
<div> 匿名通信、简单I/O设置、增强拨号协议、发送者匿名性、隐私与正确性权衡<br /><br />总结:  
1. 匿名通信在公共网络中至关重要，现有方案依赖“简单I/O设置”来隐藏真实通信模式。  
2. 当前唯一实现该设置的方法是拨号协议，但会泄露发送者身份，破坏发送者匿名性。  
3. 本文提出“增强拨号协议”概念，并首次对其发送者匿名性进行形式化研究。  
4. 构建了一个包含安全性、正确性和公平性的分析框架。  
5. 提出Fusion协议，在保证完美正确性与公平性的同时仅泄露不可避免的信息；其变体Fusion+通过引入差分隐私进一步减少泄露，但牺牲部分正确性，揭示了隐私与正确性之间的基本权衡。 <div>
Anonymous communication is essential for secure and private interactions over public networks. Existing solutions that provide provable anonymity rely on the so-called simple I/O setting, where every participant sends and receives the same number of messages, masking their true communication pattern. The only known way to enforce this setting is through dialing protocols. Such protocols establish pairwise conversations, but each recipient inevitably learns who attempted to contact them, violating sender anonymity, the guaranty that even the recipient cannot determine who attempted to contact them.

In this work, we introduce the notion of enhanced dialing protocols, a broad class of protocols that enforce the simple I/O setting. We also initiate the first formal study of such protocols with respect to sender anonymity. We introduce a framework that captures three key properties: security, correctness, and fairness. Within this framework, we present Fusion, a protocol that achieves perfect correctness and fairness while incurring only unavoidable leakage, and Fusion+, a differentially private variant that reduces this leakage at the cost of some correctness. Through theoretical analysis, we quantify the fundamental trade-off between privacy and correctness in Fusion+.
]]></content:encoded>
<pubDate>Fri, 30 Jan 2026 19:58:02 +0000</pubDate>
</item>
<item>
<title>Claiming bounties on small scale Poseidon and Poseidon2 instances using resultant-based algebraic attacks</title>
<link>https://eprint.iacr.org/2026/150</link>
<guid>https://eprint.iacr.org/2026/150</guid>
<content:encoded><![CDATA[
<div> 以太坊基金会、Poseidon、Poseidon2、CICO挑战、赏金计划<br /><br />总结:  
1. 2024年11月，以太坊基金会发起针对Poseidon和Poseidon2哈希函数的CICO挑战赏金计划。  
2. 挑战目标是在不同素数域上对轮数缩减的Poseidon-256、Poseidon2-64、Poseidon2-31m和Poseidon2-31k实例求解CICO问题（前两者为CICO-1，后两者为CICO-2）。  
3. 研究团队成功找到Poseidon2-31m和Poseidon2-31k前三个实例及Poseidon-256前两个实例的CICO解。  
4. 除Poseidon-256首个实例被其他团队抢先提交外，其余解均获以太坊基金会确认并符合赏金资格。  
5. 团队对Poseidon2-31m/k采用新型基于结式（resultant-based）的方法，而对Poseidon-256则仅使用已知的一元根查找技术。 <div>
In november 2024, the Ethereum foundation (EF) issued a bounty program with challenges on Poseidon and Poseidon2. The goal of these challenges is to find CICO solutions on different round-reduced instances of Poseidon and Poseidon2, defined on different prime fields. We denote the four main instances Poseidon-256, Poseidon2-64, Poseidon2-31m and Poseidon2-31k. In the challenges, the goal is to solve CICO-1 for Poseidon-256 and Poseidon-64, and CICO-2 for Poseidon-31m and Poseidon-31k.

We found CICO solutions to the first 3 proposed instances of Poseidon2-31m and Poseidon2-31k, along with solutions for the first two Poseidon-256 instances. These solutions have been confirmed to be correct and eligible for bounty by the Ethereum fundation, except for the first instance of Poseidon-256, which was claimed by another team before us. In order to solve the instances of Poseidon2-31m and Poseidon2-31k, we used a new resultant-based approach, whereas our attacks on Poseidon-256 only relies on already-known univariate root finding.
]]></content:encoded>
<pubDate>Fri, 30 Jan 2026 10:34:00 +0000</pubDate>
</item>
<item>
<title>Private IP Address Inference in NAT Networks via Off-Path TCP Control-Plane Attack</title>
<link>https://eprint.iacr.org/2026/149</link>
<guid>https://eprint.iacr.org/2026/149</guid>
<content:encoded><![CDATA[
<div> NAT、TCP劫持、隐私泄露、私有IP地址、Wi-Fi路由器<br /><br />总结:<br />1. 研究发现，广泛部署的Wi-Fi路由器NAT行为（如端口保留、反向路径验证不足、缺乏TCP窗口跟踪）存在设计缺陷，可被远程攻击者利用实施TCP劫持。<br />2. 攻击者不仅能中断或操控NAT后客户端与目标服务器的活跃TCP连接，还能准确推断出该客户端的私有IP地址。<br />3. 该攻击基于现实假设，通过利用NAT状态管理和TCP控制平面交互中的未被探索行为，重构完整的客户端连接元组。<br />4. 实验在实验室和真实Wi-Fi网络中验证：对SSH连接可可靠识别私有IP并强制断开；对HTTPS连接虽会快速重建，但仍能泄露私有IP。<br />5. 此类攻击不仅造成连接中断，更导致内部主机去匿名化，构成严重且此前未被认知的隐私威胁。 <div>
Recent work at NDSS 2024 demonstrated that widely deployed NAT
behaviors in Wi-Fi routers - including port preservation, insufficient
reverse-path validation, and the absence of TCP window tracking
enable off-path TCP hijacking attacks in NATed wireless networks.
These attacks exploit design weaknesses in NAT gateway routers to
detect whether some internal client behind the NAT maintains an
active TCP connection with a target server and, upon detection, to
disrupt or manipulate that connection. In this paper, we show that
these behaviors have significantly broader privacy implications. We
demonstrate that an off-path attacker can not only hijack active
TCP connections but also accurately infer the private IP addresses
of individual clients behind a NAT that are engaged in TCP commu-
nication with a target server. Our attack operates under the same
realistic assumptions as prior work, yet leverages previously unex-
plored behaviors in NAT state management and TCP control-plane
interactions to reconstruct the full client-side connection tuple. We
evaluate our attack both in a controlled laboratory testbed and
in a real-world Wi-Fi network. For SSH connections, our method
reliably identifies the private IP addresses of connected clients and
enables forcible termination of their TCP sessions. For HTTPS
connections, although the attacker successfully terminates the un-
derlying TCP connection, modern browsers rapidly re-establish
a new connection using new ephemeral ports; nevertheless, our
attack reveals the private IP addresses of the originating clients, ex-
posing a persistent privacy leakage. Our findings demonstrate that
off-path TCP hijacking attacks in NATed Wi-Fi networks pose a seri-
ous and previously unrecognized threat to client privacy, extending
well beyond connection disruption to enable deanonymization of
internal hosts.
]]></content:encoded>
<pubDate>Fri, 30 Jan 2026 10:28:18 +0000</pubDate>
</item>
<item>
<title>OptiBridge: A Trustless, Cost-Efficient Bridge Between the Lightning Network and Ethereum</title>
<link>https://eprint.iacr.org/2026/147</link>
<guid>https://eprint.iacr.org/2026/147</guid>
<content:encoded><![CDATA[
<div> OptiBridge、跨链桥、支付通道、乐观机制、智能合约<br /><br />总结:<br />1. 传统跨链桥假设源账本事件公开可见，但Layer-2支付通道（如闪电网络）的状态更新是链下且不可见的，导致现有设计失效。<br />2. 本文提出OptiBridge，一种连接支付通道与智能合约区块链（如以太坊）的新桥接方案，无需新增信任假设且兼容现有协议栈。<br />3. OptiBridge在正常情况下采用乐观机制：诚实双方通过揭示预共享密钥在目标链上确认状态，大幅降低Gas成本（相比Alba节省约73%）。<br />4. 针对故障或恶意行为，OptiBridge提供按需部署的争议解决合约，虽争议路径成本较高，但能有效防止资产被盗。<br />5. 理性用户会优先选择低成本的乐观路径，而偏离者将面临更高费用和延迟，从而保障系统安全与活性。 <div>
Bridges, protocols that enforce a state transition on a destination ledger conditioned on an event on a source ledger, are central to modern DeFi.
Conventional designs implicitly assume the source ledger event is publicly observable, an assumption that breaks with Layer-2 payment channels such as the Lightning Network, where state updates occur off-chain between counterparties and are invisible to others. This state of affairs advocates for new bridge designs for this setting.

This paper introduces OptiBridge, a bridge between a payment channel (e.g., Lightning Network) and a smart-contract blockchain (e.g., Ethereum) that preserves safety and liveness without adding trust assumptions and remains fully compatible with existing Lightning and Ethereum stacks. OptiBridge follows an optimistic path in the common case: two honest channel peers materialize the intended state on the destination chain by revealing a pre-agreed secret.
To handle faults and adversarial behavior, OptiBridge provides a dispute path orchestrated by a more expressive contract that is deployed {only on demand}. An implementation demonstrates substantial cost savings in the optimistic case: compared to Alba (NDSS’25), the optimistic contract deployment uses $\sim 73\%$ less gas ($1.22$M vs. $4.51$M), and proof submission costs $40{,}107$ vs. $253{,}566$ gas; when disputes arise, the dispute contract deployment costs $2{,}785{,}514$ gas and the core dispute call is cheaper ($196{,}438$ vs.$515{,}860$). Our analysis shows that rational users strictly prefer the optimistic path, whereas the dispute mechanism prevents coin theft and imposes higher fees and delays on the deviator.
]]></content:encoded>
<pubDate>Fri, 30 Jan 2026 01:42:10 +0000</pubDate>
</item>
<item>
<title>Minimizing Mempool Dependency in PoW Mining on Blockchain: A Paradigm Shift with Compressed Block Representation for Enhanced Scalability, Decentralization and Security.</title>
<link>https://eprint.iacr.org/2026/141</link>
<guid>https://eprint.iacr.org/2026/141</guid>
<content:encoded><![CDATA[
<div> 关键词：工作量证明（PoW）、区块传播、内存池不一致、延迟验证、可扩展性

<br /><br />总结:  
1. 现有基于PoW的区块链在可扩展性、效率和去中心化方面存在固有局限。  
2. 紧凑区块传播方法虽能减少带宽和延迟，但受节点间内存池不一致影响，性能下降。  
3. 论文提出新协议，降低对内存池同步的依赖，通过在紧凑区块中包含压缩交易输入ID列表，使节点无需完整验证即可立即开始挖矿。  
4. 采用“延迟验证”机制，在挖矿同时并行完成交易的完整验证。  
5. 该方案在保持比特币安全性和去中心化前提下，显著提升吞吐量（如10MB区块达约66.7 TPS）。 <div>
While existing Proof-of-Work (PoW) based blockchain protocols have demonstrated innovative potential, they face inherent limitations regarding scalability, efficiency, and decentralization. The compact block propagation method, though effective in reducing network bandwidth and propagation delay in ideal environments, suffers from performance degradation due to mempool inconsistencies among nodes. This paper proposes a novel block propagation and consensus protocol that mitigates the blockchain's dependency on mempool synchronization. The proposed approach redefines the PoW process to shorten the time to consensus despite increased block sizes. Specifically, it includes a compressed transaction input ID list within the compact block to induce nodes to immediately begin mining without full verification. The full verification of transactions adopts a 'delayed verification' method, performed in parallel with the mining operation. This study enables the processing of more transactions quickly while maintaining the decentralization and security of Bitcoin (e.g., achieving approximately 66.7 TPS with 10MB blocks).
]]></content:encoded>
<pubDate>Thu, 29 Jan 2026 09:47:02 +0000</pubDate>
</item>
<item>
<title>Private Proofs of When and Where</title>
<link>https://eprint.iacr.org/2026/136</link>
<guid>https://eprint.iacr.org/2026/136</guid>
<content:encoded><![CDATA[
<div> 位置验证、零知识、量子协议、位置承诺、后量子单向函数<br /><br />总结:  
1. 位置验证是一种交互式协议，允许实体向他人证明其物理位置，经典协议无法实现安全的位置验证，但量子协议可以。  
2. 本文提出“零知识位置验证”概念，扩展了传统位置验证：一是可证明更复杂的时空位置陈述（如“昨天中午我不在某地”），二是保护除所证声明外的其他真实位置信息隐私。  
3. 该方案基于标准位置验证和后量子单向函数构建，核心工具是“位置承诺”，即实体可在某一时刻对其物理位置进行私密承诺，并在之后揭示。 <div>
Position verification schemes are interactive protocols where entities prove their physical location to others; this enables interactive proofs for statements of the form "I am at a location L." Although secure position verification cannot be achieved with classical protocols (even with computational assumptions), they are feasible with quantum protocols.
In this paper we introduce the notion of zero-knowledge position verification, which generalizes position verification in two ways:
1. enabling entities to prove more sophisticated statements about their locations at different times (for example, "I was NOT near location L at noon yesterday").
2. maintaining privacy for any other detail about their true location besides the statement they are proving.
We construct zero-knowledge position verification from standard position verification and post-quantum one-way functions. The central tool in our construction is a primitive we call position commitments, which allow entities to privately commit to their physical position in a particular moment, which is then revealed at some later time.
]]></content:encoded>
<pubDate>Wed, 28 Jan 2026 14:30:39 +0000</pubDate>
</item>
<item>
<title>Randomness-Recovery Trapdoors: a new methodology for enhancing anamorphic encryption</title>
<link>https://eprint.iacr.org/2026/135</link>
<guid>https://eprint.iacr.org/2026/135</guid>
<content:encoded><![CDATA[
<div> Anamorphic加密、Trapdoor-Aided随机性恢复、公钥AE、对抗性独裁者、格密码<br /><br />总结:<br />1. Anamorphic加密（AE）旨在在极端对抗环境下（如独裁者强制交出密钥或胁迫发送特定消息）保障通信双方的隐私。<br />2. 提出一种基于“Trapdoor-Aided随机性恢复”的新方法，通过生成含特殊陷门的密钥对，在不泄露解密能力的前提下从密文中提取隐藏消息所用的随机性。<br />3. 该陷门与传统解密陷门计算上独立，首次实现通用的公钥AE构造，无需通信双方预先共享私密信息。<br />4. 新方法还能抵御独裁者索要加密随机性的攻击，增强安全性。<br />5. 基于格密码，具体实例化了Dual Regev和Lindner-Peikert方案，并通过定义“随机性查找（RFinding）”问题，将LWE假设归约至其困难性，证明方案安全。 <div>
The primary goal of Anamorphic encryption ($\mathsf{AE}$), introduced at Eurocrypt 2022, is to enable private communication even in highly adversarial settings, such as when an adversarial  $\textit {dictator}$ "legally" confiscates a user's secret keys (compromising the receiver's privacy) and/or coerces users into sending specific messages (compromising the sender's privacy).  To achieve this, $\mathsf{AE}$ embeds hidden additional messages within seemingly innocuous ciphertexts where the sender and receiver comply with the dictator's demands and, in doing so, $\mathsf{AE}$ uncovers novel structural properties of encryption mechanisms. One methodology that extends the capability of a ciphertext is to embed the hidden anamorphic message in the randomness used in encryption. However, not all schemes reveal this randomness as part of the decryption process! Here, we unveil a conceptually simple yet general new methodology that achieves $\mathsf{AE}$. It is based on the concept of $\textit {Trapdoor-Aided Randomness Recovery}$ by which one can generate special key pairs $(\mathsf{pk},\mathsf{sk})$  that are still indistinguishable from honestly generated key pairs but possess an associated trapdoor $\mathsf{td}$ that first allows for randomness extraction from a ciphertext (and nothing more). Secondly, importantly and differently from prior proposals, the new trapdoor should be different from and computationally independent of "the decryption trapdoor key." Primarily, this new methodology allows for a generic construction of $\textit{public-key}~\mathsf{AE}$ which is a notion introduced at Crypto 24, where, to date, the only known public-key anamorphism relied on a specific CCA encryption scheme. Note that public-key $\mathsf{AE}$ eliminates the need for a preliminary private interaction between the receiver and the sender, thus greatly extending the applicability of anamorphism. In addition to obtaining public-key anamorphism, the new methodology, in turn, generically allows for extended anamorphic properties: Specifically and significantly, the methodology allows protections against a dictator that may ask for the randomness employed by the sender.

 We then show concrete instantiations of the above methodology based on known lattice-based schemes. Specifically, due to the new methodology, we give efficient anamorphic versions of the Dual Regev scheme and the Lindner-Peikert scheme. Technically, we first define a new problem, called $\textit{randomness finding}~(\mathsf{RFinding})$, which requires that even if the adversary obtains the receiver's secret key, then, while it can decrypt, it cannot fully recover the randomness from the ciphertext.  Secondly, we reduce the standard LWE assumptions to the hardness of $\mathsf{RFinding}$  for both schemes.  Notably, in both schemes we achieve public-key anamorphism utilizing the "trapdoor techniques for lattices" introduced by Micciancio and Peikert at Eurocrypt 2012.
]]></content:encoded>
<pubDate>Wed, 28 Jan 2026 08:27:31 +0000</pubDate>
</item>
<item>
<title>Homomorphic Signatures : A Systematization of Knowledge</title>
<link>https://eprint.iacr.org/2026/133</link>
<guid>https://eprint.iacr.org/2026/133</guid>
<content:encoded><![CDATA[
<div> 同态签名、功能性表达能力、密码学原语、安全模型、多密钥同态签名<br /><br />总结:<br />1. 同态签名（HS）允许验证者在不接触原始签名输入的情况下，验证由不可信方处理后的数据计算正确性。<br />2. HS已从早期代数受限的线性方案发展为支持非线性和全同态签名（FHS）的高表达性构造。<br />3. 本文系统化梳理了现有HS方案，按功能性表达能力、底层密码学原语、安全模型（选择性/自适应、单密钥/多密钥）及上下文隐藏等隐私保障进行分类。<br />4. 研究趋势显示，HS正从代数构造转向基于证明和抗量子的设计，并日益重视适用于去中心化场景的多密钥同态签名（MKHS）。<br />5. 文章最后指出需解决若干开放问题，以缩小理论构造与实际可验证计算应用之间的差距。 <div>
Homomorphic Signatures (HS) enable the authentication of data that has been processed by an untrusted party, allowing a verifier to check the correctness of a computation without access to the original signed inputs. Since their introduction, HS have evolved from algebraically restricted linear schemes to expressive non-linear and Fully Homomorphic Signature (FHS) constructions, spanning diverse cryptographic assumptions and security models.

This paper presents a Systematization of Knowledge (SoK) on homomorphic signatures. We organize existing schemes along key dimensions including functional expressiveness, underlying cryptographic primitives, security notions (selective vs. adaptive, single-key vs. multi-key), and privacy guarantees such as context hiding. This unified perspective highlights a fundamental shift from algebraic constructions toward proof-based and post-quantum designs, as well as the growing importance of Multi-Key Homomorphic Signatures (MKHS) for decentralized settings. We conclude by identifying open problems and emerging directions that must be addressed to bridge the gap between theoretical HS constructions and practical verifiable computation.
]]></content:encoded>
<pubDate>Tue, 27 Jan 2026 18:47:09 +0000</pubDate>
</item>
<item>
<title>Online-Friendly Robust Threshold ECDSA with Constant Amortized Communication</title>
<link>https://eprint.iacr.org/2026/130</link>
<guid>https://eprint.iacr.org/2026/130</guid>
<content:encoded><![CDATA[
<div> 阈值ECDSA、MtA范式、打包秘密共享、通信复杂度、区块链应用<br /><br />总结:<br />1. 阈值ECDSA在区块链等领域应用广泛，现有方案主要分为基于阈值线性同态加密（TLHE）和基于乘法转加法（MtA）两类。<br />2. TLHE方案通信开销低但在线阶段昂贵且需广播信道；MtA方案在线效率高但每方通信复杂度为O(n)。<br />3. 本文提出一种基于MtA的新方案，利用打包秘密共享技术，在恶意多数设定下实现常数级摊销通信复杂度，可同时生成ℓ=εn个签名。<br />4. 进一步扩展该技术，在诚实多数设定下构建了具备鲁棒性的阈值ECDSA方案，保证有效签名输出，且通信复杂度为常数。<br />5. 实验表明，所提方案在摊销效率上优于DKLs24，鲁棒版本优于TX25，在线效率显著提升，整体复杂度与WMC24相当。 <div>
Threshold ECDSA has been an active research topic in recent years, driven by its wide-ranging applications, particularly in blockchain domains. Existing constructions of threshold ECDSA generally fall into two categories: those based on threshold linearly homomorphic encryption (TLHE) and those leveraging the Multiplicative-to-Additive (MtA) paradigm. The TLHE-based approach (e.g., WMC24 in NDSS'24) achieves constant communication per party but incurs an expensive online phase and requires a broadcast channel. In contrast, the MtA-based approach (e.g., DKLs24 in S\&amp;P'24) offers an optimal online phase and avoids the use of a broadcast channel. However, it has the drawback of requiring linear (i.e., $O(n)$) communication per party when $n$ parties are involved.

In this work, we propose an MtA-based threshold ECDSA scheme with constant amortized communication. At the core of our approach is the use of packed secret sharing, which enables the same MtA operations to generate $\ell = \epsilon n$ signatures. With a constant $\epsilon$, the communication complexity per signature is amortized to a constant in dishonest-majority settings. Furthermore,  we extend this packing technique to design a robust threshold ECDSA with constant communication under honest-majority settings, which ensures the delivery of valid signatures as long as a sufficient number of parties are honest. In contrast, the state-of-the-art robust MtA-based construction (TX25 in S\&amp;P’25) requires linear communication per party. We implement our packed constructions using both CL-based and OT-based MtA protocols. Benchmark results show that our amortized efficiency surpasses that of DKLs24. Moreover, our robust scheme outperforms TX25 and has significantly better online efficiency with comparable overall complexity to WMC24.
]]></content:encoded>
<pubDate>Tue, 27 Jan 2026 08:54:40 +0000</pubDate>
</item>
<item>
<title>Toward Verifiable Privacy in Decentralized Identity: A Formal Framework for Minimal Disclosure and Unlinkability</title>
<link>https://eprint.iacr.org/2026/127</link>
<guid>https://eprint.iacr.org/2026/127</guid>
<content:encoded><![CDATA[
<div> 去中心化身份、最小披露、会话不可关联性、环签名、W3C合规<br /><br />总结:<br />1. 该文提出一个去中心化身份（DID）的形式化框架，实现最小披露与会话不可关联性，并支持公开可验证性。<br />2. 框架实例化为PrivDID，用户通过单个环签名证明关于承诺属性的谓词，隐藏于从公共账本动态选择的匿名集中。<br />3. PrivDID基于Pedersen承诺和二进制范围编码，在随机预言机模型下被证明安全。<br />4. 系统完全符合W3C标准，且无需可信设置。<br />5. 实验表明其在存储、通信和计算方面具有实用效率，具备现实可行性。 <div>
This paper presents a formal framework for decentralized identity (DID), which achieves both minimal disclosure and session unlinkability under public verifiability. We instantiate this framework as PrivDID. In PrivDID,  a user can prove a predicate about a committed attribute via a single ring signature, thereby hiding in an anonymity set dynamically selected from the public ledger. PrivDID builds on Pedersen commitments and binary-range encodings, and is proven secure in the random oracle model. It is fully W3C-compliant and requires no trusted setup. Implementation shows practical efficiency in storage, communication, and computation, confirming real-world feasibility.
]]></content:encoded>
<pubDate>Tue, 27 Jan 2026 05:54:30 +0000</pubDate>
</item>
<item>
<title>Re2creds: Reusable Anonymous Credentials from Malleable NIZK and Legacy Signatures</title>
<link>https://eprint.iacr.org/2026/119</link>
<guid>https://eprint.iacr.org/2026/119</guid>
<content:encoded><![CDATA[
<div> 去中心化身份、匿名凭证、可重用凭证展示、遗留签名兼容、NIST推荐曲线<br /><br />总结:  
1. 去中心化身份通过让用户掌控个人数据，革新了安全数字交互。  
2. 现有匿名凭证（AC）系统在谓词表达能力、隐私保护及与基于NIST推荐曲线的遗留签名兼容性方面存在不足。  
3. 本文提出新系统Re2creds，引入可重用凭证展示机制，大幅降低跨会话的计算开销。  
4. Re2creds通过证明组合机制，将高成本密码运算移出算术电路，高效支持遗留签名。  
5. 实验表明，Re2creds在凭证生成时间上减少超50%，且可在1秒内完成基于BN254的BLS签名展示，显著优于现有方案。 <div>
Decentralized identity is revolutionizing secure digital interactions by giving users control over their personal data. Anonymous credentials (ACs) are fundamental to this paradigm, yet their practical application is hindered by significant usability and efficiency challenges. Existing AC systems often struggle with limitations in predicate expressiveness, privacy protection, and incompatibility with widely adopted legacy signatures based on recommended curves. To overcome these obstacles, this paper introduces a novel AC system named Re2creds. Re2creds  establishes a new paradigm of reusable credential presentation, which drastically cuts computational costs by allowing the core of a presentation to be reused across multiple sessions with only lightweight updates. Furthermore, Re2creds incorporates a proof combination mechanism that efficiently supports legacy signatures by moving the most computationally intensive cryptographic operations outside the arithmetic circuit. This approach makes it practical to use credentials based on NIST-recommended curves, removing a critical barrier to real-world adoption. We demonstrate Re2creds’ security properties through a refined UC ideal functionality, accompanied by rigorous proofs. Experimental evaluations demonstrate significant performance improvements over existing schemes: credential generation time decreases by more than 50% when derivingfrom an existing presentation. Additionally, Re2creds makes the presentation of legacy signatures feasible compared to other ACs, which takes less than 1s for a BLS signature based on BN254.
]]></content:encoded>
<pubDate>Sun, 25 Jan 2026 03:59:39 +0000</pubDate>
</item>
<item>
<title>PETCHA: Post-quantum Efficient Transciphering with ChaCha</title>
<link>https://eprint.iacr.org/2026/112</link>
<guid>https://eprint.iacr.org/2026/112</guid>
<content:encoded><![CDATA[
<div> 全同态加密、转密计算、后量子安全、ChaCha、AES<br /><br />总结:<br />1. 全同态加密（FHE）允许弱客户端将计算外包给强服务器并保护隐私，但存在密文膨胀问题。<br />2. 转密计算通过结合对称加密与FHE缓解该问题，常用AES作为基准，但现有方案仅使用AES-128，缺乏后量子安全性。<br />3. 本文提出基于标准密码的后量子安全转密计算协议，选用具有256位经典安全强度（即128位量子安全）的ChaCha密码。<br />4. 设计了高效在FHE下评估ChaCha的算法。<br />5. 实验表明，相比当前最先进的基于AES的方案（如Hippogryph），新方案在单核环境下运行速度最高快11.7倍，吞吐量提升超50倍。 <div>
Fully Homomorphic Encryption (FHE) is a powerful primitive which allows a computationally weak client to outsource computation to a powerful server while maintaining privacy. However, FHE typically suffers from high ciphertext expansion, meaning that the amount of data the client has to send to the server increases by many orders of magnitude after it is encrypted. To solve this problem, the approach known as transciphering consists in combining symmetric encryption with FHE. The most common choice of cipher in this context is the AES, which has been used as a benchmark for transciphering. However, although FHE is typically post-quantum secure, existing transciphering protocols only use AES-128, failing thus to offer security against quantum adversaries.
In this work, we construct transciphering protocols based on standard ciphers that offer post-quantum security. For this, we propose algorithms to efficiently evaluate the ChaCha cipher with FHE. We notice that ChaCha is a well-established cipher which even has a standardized version in TLS offering 256 bits of security against classic attackers, thus, 128 bits of security in the quantum world.
We show that our solutions have both better latency and throughput than the state-of-the-art transciphering protocol based on AES. Namely, compared with an extended (128-bit PQ secure) version of Hippogryph  (Belaïd et al., IACR CiC 2025), in single-core experiments, our running times are up to 11.7 times faster while our throughput is more than 50 times higher.
]]></content:encoded>
<pubDate>Fri, 23 Jan 2026 20:22:16 +0000</pubDate>
</item>
<item>
<title>Concretely Efficient Blind Signatures Based on VOLE-in-the-Head  Proofs and the MAYO Trapdoor</title>
<link>https://eprint.iacr.org/2026/109</link>
<guid>https://eprint.iacr.org/2026/109</guid>
<content:encoded><![CDATA[
<div> 盲签名、后量子密码、格密码、VOLE-in-the-head、MAYO签名<br /><br />总结:<br />1. 盲签名是匿名凭证和电子现金等隐私保护应用的关键组件。<br />2. 现有基于格的后量子盲签名方案在通信开销（至少20KB）和计算效率（超过100ms）方面仍不实用。<br />3. 本文提出新方案PoMFRIT，结合VOLE-in-the-head零知识证明系统与MAYO数字签名，实现更高效的后量子盲签名。<br />4. PoMFRIT在128位安全强度下，签名展示耗时低于76ms，签发通信量仅0.45KB，签名大小为6.7KB。<br />5. 该工作还首次实现了适用于SHA-3哈希函数族的VOLE-in-the-head证明，具有独立研究价值。 <div>
Blind signatures (Chaum, CRYPTO 82) are important building blocks in many privacy-preserving applications, such as anonymous credentials or e-cash schemes. Recent years saw a strong interest in building Blind signatures from post-quantum assumptions, primarily from lattices. While performance has improved, no construction has reached practical efficiency in terms of computation and communication. The state of the art requires at least $20$ KB size of communication for each showing of a lattice-based Blind signature to a verifier, and more than $100$ ms in prover time.

In this work, we propose an alternative direction with a plausibly post-quantum Blind signature scheme called PoMFRIT. It builds on top of the VOLE-in-the-head Zero-Knowledge proof system (Baum et al. CRYPTO 2023), which we combine with the MAYO digital signature scheme (Beullens, SAC 2021). We implement multiple versions of PoMFRIT to demonstrate security and performance trade-offs, and provide detailed benchmarks of our constructions. Signature issuance requires \(0.45\) KB communication for Blind signatures of size \(6.7\) KB. Showing a Blind signature can be done in $<76$ ms even for a conservative construction with $128$ bit security. As a building block for our Blind signature scheme, we implement the first VOLE-in-the-head proof for hash functions in the SHA-3 family, which we consider of independent interest.
]]></content:encoded>
<pubDate>Fri, 23 Jan 2026 16:02:01 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving LLM Inference in Practice: A Comparative Survey of Techniques, Trade-Offs, and Deployability</title>
<link>https://eprint.iacr.org/2026/105</link>
<guid>https://eprint.iacr.org/2026/105</guid>
<content:encoded><![CDATA[
<div> 大语言模型、隐私保护、Transformer、隐私增强技术、可信执行环境<br /><br />总结:<br />1. 文章聚焦于大语言模型（LLM）作为云服务部署时的用户提示与生成内容保密问题。<br />2. 提出端到端隐私目标：仅客户端可读取提示与生成结果。<br />3. 围绕隐私增强技术（PETs）的主要类别，分析代表性系统如何应对非线性层和自回归解码等关键瓶颈。<br />4. 从信任假设、可扩展性和部署成熟度三方面比较不同方案。<br />5. 建议一条信任最小化的部署路径：从当前基于可信执行环境（TEE）的大规模方案，过渡到结合密码学以降低硬件依赖的方案，最终迈向全同态加密（FHE）实现非交互式长期保密。 <div>
Large Language Models (LLMs) are increasingly deployed as cloud services, raising practical concerns about the confidentiality of user prompts and generated completions. In this paper, we survey privacy-preserving inference solutions for Transformer-based LLMs with the explicit goal of supporting operational choices in real-world deployments. We adopt a strong operational notion of privacy: only the client can read the prompt and the corresponding completion, end to end. The review is organised around the main families of Privacy-Enhancing Technologies (PETs). For each family, we examine representative systems and how they address key bottlenecks in confidential LLM inference, such as non-linear layers and autoregressive decoding. We then compare these approaches in terms of trust assumptions, scalability, and deployment maturity. This comparison characterises the current practical landscape of privacy-preserving LLM inference and motivates a trust-minimising deployment trajectory: from TEE-based solutions that enable large-scale confidential inference today; through crypto-augmented designs that reduce reliance on hardware trust at higher computational cost; toward Fully Homomorphic Encryption as a principled long-term endpoint for non-interactive confidentiality.
]]></content:encoded>
<pubDate>Thu, 22 Jan 2026 17:27:35 +0000</pubDate>
</item>
<item>
<title>When Only Parts Matter: Efficient Privacy-Preserving Analytics with Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2026/103</link>
<guid>https://eprint.iacr.org/2026/103</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、区域选择性加密、数据机密性、云计算、隐私保护计算<br /><br />总结:  
1. 针对云环境中数据密集型应用的数据机密性问题，提出了一种混合隐私保护计算协议 $\Pi_{ROI}$。  
2. 该协议仅对敏感的“感兴趣区域”（ROI）使用全同态加密（FHE），非敏感部分保留明文，兼顾安全性与效率。  
3. 在标准密码学假设（如IND-CPA、IND-CCA2等）下，协议被证明能安全实现理想功能 $\mathcal{F}_{\text{proc}}$，可抵御半诚实云服务商攻击。  
4. 实验表明，$\Pi_{ROI}$ 在混合敏感度工作负载（如图像分析、矩阵运算）中显著提升计算性能。  
5. 该方法在保障端到端敏感数据机密性的同时，有效缓解了FHE在大规模场景中的高开销问题。 <div>
The increasing reliance on cloud-based computation for data-intensive applications raises critical concerns about data confidentiality. Fully Homomorphic Encryption (FHE) provides strong theoretical guarantees by allowing computations over encrypted data, but its high computational cost limits its practicality in large-scale scenarios such as image analysis or matrix-based workloads. In this work, we introduce $\Pi_{ROI}$, a hybrid privacy-preserving computation protocol that leverages region-based selective encryption. The core idea is to encrypt only the sensitive Regions of Interest (ROIs) under an FHE scheme, while keeping the remaining, non-sensitive parts of the data in plaintext. This approach achieves end-to-end confidentiality for sensitive regions while significantly improving computational efficiency. We formally define the security of $\Pi_{ROI}$ through an ideal functionality $\mathcal{F}_{\text{proc}}$ and prove that it securely realizes $\mathcal{F}_{\text{proc}}$ against a semi-honest cloud service provider under standard cryptographic assumptions (IND-CPA, IND-CCA2, EUF-CMA, and collision-resistance). Experimental evaluation demonstrates that $\Pi_{ROI}$ offers substantial performance gains in mixed-sensitivity workloads.
]]></content:encoded>
<pubDate>Thu, 22 Jan 2026 11:12:52 +0000</pubDate>
</item>
<item>
<title>On the Impossibility of Round-Optimal Pairing-Free Blind Signatures in the ROM</title>
<link>https://eprint.iacr.org/2026/090</link>
<guid>https://eprint.iacr.org/2026/090</guid>
<content:encoded><![CDATA[
<div> 盲签名、无配对群、三轮交互、随机预言模型、通用群模型<br /><br />总结:<br />1. 盲签名在隐私保护认证中至关重要，尤其在无配对群中构造的方案自1990年代起备受关注。<br />2. 现有无配对群下的盲签名方案均需至少三轮交互，依赖随机预言模型且将群结构视为黑盒。<br />3. 这些方案虽计算高效，但要求签名者在会话中保持状态，而其他假设（如RSA、格、配对）下已有轮数最优方案。<br />4. 本文探究三轮交互是否为无配对群中盲签名的固有限制。<br />5. 在结合随机预言模型与Maurer通用群模型的框架下，作者首次证明：若签名长消息且仅进行对数级随机预言查询，则无法实现安全的盲签名，从而提供该限制并非固有的初步反证。 <div>
Blind signatures play a central role in cryptographic protocols for privacy-preserving authentication and have attracted substantial attention in both theory and practice. A major line of research, dating back to the 1990s, has focused on constructing blind signatures from pairing-free groups. However, all known constructions in this setting require at least three moves of interaction between the signer and the user. These schemes treat the underlying group as a black box and rely on the random oracle in their security proofs. While computationally efficient, they suffer from the drawback that the signer must maintain state during a signing session. In contrast, round-optimal solutions are known under other assumptions and structures (e.g., RSA, lattices, and pairings), or via generic transformations such as Fischlin’s method (CRYPTO~'06), which employ non-black-box techniques.

  This paper investigates whether the three-round barrier for pairing-free groups is inherent. We provide the first negative evidence by proving that, in a model combining the Random Oracle Model (ROM) with Maurer’s Generic Group Model, no blind signature scheme can be secure if it signs sufficiently long messages while making at most a logarithmic number of random oracle queries. Our lower-bound techniques are novel in that they address the interaction of both models (generic groups and random oracles) simultaneously.
]]></content:encoded>
<pubDate>Tue, 20 Jan 2026 10:45:20 +0000</pubDate>
</item>
<item>
<title>2PC Memory-Manipulating Programs with Constant Overhead</title>
<link>https://eprint.iacr.org/2026/086</link>
<guid>https://eprint.iacr.org/2026/086</guid>
<content:encoded><![CDATA[
<div> 安全多方计算　随机存取内存　分布式点函数　单次访问机模型　隐私保护图遍历<br /><br />总结:  
1. 文章提出一种基于分布式点函数（DPF）的高效两方安全计算（2PC）随机存取内存（RAM）方案，仅需不经意传输（OT）和黑盒伪随机生成器（PRG）。  
2. 该方案在处理大字长数据时，每次内存访问的通信开销为常数级，尽管计算开销仍为线性。  
3. 方案构建于新型“单次访问机模型”（SAM），其中每个内存单元最多被读取一次，每次操作在线通信仅为 $2w + 2\lg n$ 比特。  
4. RAM操作通过非加密方式编译为少量（至多对数级）SAM操作，大字长下效率更高。  
5. 该2PC SAM可直接高效实现隐私保护图遍历（如DFS/BFS），在线通信达 $O(n \lg n)$ 比特，与明文遍历渐近匹配，且仅泄露运行时间。 <div>
General-purpose secure multiparty computation (MPC) remains bottlenecked in large part by a lack of efficient techniques for handling memory access. We demonstrate a remarkably simple and efficient 2PC instantiation of random access memory (RAM), based on distributed point functions (DPFs, Gilboa and Ishai, Eurocrypt'14). Our semi-honest 2PC protocol can be achieved from oblivious transfer (OT) and a black-box pseudorandom generator (PRG).

For a memory that stores large enough data words, our 2PC RAM incurs constant communication overhead per access. Like prior works that leverage DPFs to achieve memory access, our work incurs linear computation per access, but our per-access communication is lean.

Our 2PC RAM is built on top of an obliviousness-friendly model of computation called the single access machine model (SAM, Appan et al., CCS'24).  In the SAM model, each memory slot can be read at most once. We present a simple 2PC SAM protocol, where each single-access memory operation incurs at most $2w + O(\lambda \lg n)$ bits of communication, where $w$ is the word size, $n$ is the number of memory words, and $\lambda$ is a security parameter. Of this cost, only $2w + 2\lg n$ bits are incurred in the online phase.

Our RAM operations are (non-cryptographically) compiled to SAM operations.  At most a logarithmic number of SAM operations are needed per RAM operation; if word size is large, even fewer SAM operations are required.  Alternatively, there are now many oblivious algorithms that compile directly  to SAM more efficiently than via a compilation to RAM, and our 2PC SAM can  instantiate these algorithms.  As one example, we can use our 2PC SAM to implement privacy-preserving  graph traversal (DFS or BFS) over a secret-shared size-$n$ graph while  revealing nothing beyond the runtime of the SAM program.  Our construction achieves online communication $O(n \lg n)$ bits, asymptotically matching the number of  bits touched in a corresponding cleartext graph traversal.
]]></content:encoded>
<pubDate>Mon, 19 Jan 2026 21:33:21 +0000</pubDate>
</item>
<item>
<title>Tag-Friendly Lattice Sampler and Applications</title>
<link>https://eprint.iacr.org/2026/083</link>
<guid>https://eprint.iacr.org/2026/083</guid>
<content:encoded><![CDATA[
<div> 关键词：NIST、格密码、匿名认证、采样器、标签管理<br /><br />总结:<br />1. NIST的格密码标准即将广泛应用，主要解决密钥协商与签名认证问题。<br />2. 随着基础应用落地，研究焦点转向更复杂的原语，如门限密码和隐私增强技术，尤其在后量子匿名认证中面临性能挑战。<br />3. 格采样器是提升性能的关键组件，但现有方案忽视了“标签”（tag）的作用。<br />4. 本文提出一种新型采样器，改进标签管理，保持现有采样器特性，可直接替换使用。<br />5. 新采样器生成的预像更小、更快，相比Jeudy和Sanders的最新方案，在多个高级认证机制中实现最高30%的尺寸缩减和35%的速度提升。 <div>
The NIST lattice-based cryptographic standards are set to be widely adopted, offering solutions to the most common cryptographic needs, namely key establishment and authentication (signature). This shifted the attention to more advanced primitives such as threshold cryptography as well as privacy-enhanced technologies, where the transition is expected to be more complex. This is particularly true in the context of post-quantum anonymous authentication where the existing mechanisms may not match the performance requirements of industrial applications. An important avenue for improvement of said performances is the lattice sampler, which is at the center of these mechanisms. Despite recent progress, prior samplers neglected one component: the tag. The latter is not only necessary for security, but it also impacts the efficiency of the subsequent constructions if not handled properly.
In this paper, we introduce a new sampler with an enhanced tag management that yet retain the main features of current samplers, and can thus be used as a plug-in replacement. It offers a sampling quality independent of the tag, allowing for producing preimages that are both smaller and faster to generate than those from the very recent sampler of Jeudy and Sanders (Asiacrypt'25). Far from being anecdotal, plugging it into several advanced authentication mechanisms results in size improvements of up to 30%, while being 35% faster.
]]></content:encoded>
<pubDate>Mon, 19 Jan 2026 10:23:12 +0000</pubDate>
</item>
<item>
<title>SoK: Outsourced Private Set Intersection</title>
<link>https://eprint.iacr.org/2026/080</link>
<guid>https://eprint.iacr.org/2026/080</guid>
<content:encoded><![CDATA[
<div> 隐私增强技术、私有集合交集（PSI）、外包计算、云服务器、协议评估框架<br /><br />总结:  
1. 私有集合交集（PSI）是多种实际应用场景中的关键隐私增强技术，但直接在参与方之间执行会导致性能开销过大。  
2. 为此，研究转向外包PSI，即客户端将繁重的计算任务委托给不受信任的云服务器。  
3. 本文提出一个包含12项属性的评估框架，从安全性、功能性和效率三方面对现有外包PSI协议进行系统化分类。  
4. 作者通过该框架分析了20个协议，为研究人员和实践者提供选型参考及交互式工具。  
5. 文章还指出了常规PSI与外包PSI之间的研究差距，并提出了未来值得探索的方向。 <div>
Private set intersection (PSI) protocols are an essential privacy-enhancing technology for many real-world use cases, ranging from mobile contact discovery to fraud detection. However, PSI executed directly between input parties can result in unreasonable performance overhead. This motivates the study of outsourced PSI, where clients delegate the heavy PSI operations to an untrusted (cloud) server.

In this SoK, we introduce a framework of 12 distinct properties that characterize outsourced PSI protocols based on security, functionality, and efficiency. By analyzing 20 protocols through this framework, we provide a valuable resource and an interactive tool for researchers and practitioners to select the most suitable protocols for their specific requirements. Finally, we discuss research gaps between trends in regular PSI and the current state of outsourced PSI, identifying promising avenues for future work.
]]></content:encoded>
<pubDate>Sun, 18 Jan 2026 14:15:18 +0000</pubDate>
</item>
<item>
<title>Automatically Detecting Compromised Secrets: Foundations, Design Principles, and Applications</title>
<link>https://eprint.iacr.org/2017/234</link>
<guid>https://eprint.iacr.org/2017/234</guid>
<content:encoded><![CDATA[
<div> 自动检测、密钥泄露、安全协议、自动响应、统一框架<br /><br />总结:<br />1. 文章提出一种能自动检测密钥或密码等秘密信息是否泄露的安全协议框架，且无误报。<br />2. 该框架支持自动响应机制，如自动撤销密钥或关闭受攻击服务，以最小化泄露影响。<br />3. 威胁模型涵盖恶意代理、被临时或永久攻陷的代理以及克隆设备。<br />4. 与以往依赖特定领域设计且需人工干预的方案（如证书透明度、RFID克隆检测）不同，本文提供通用、可自动执行的解决方案。<br />5. 通过多个案例（如Web登录、支付系统、电子门锁）验证其机制有效性，并改进并形式化验证了Cloudflare的Keyless SSL协议。 <div>
We develop foundations and several constructions for security protocols that can automatically detect, without false positives, if a secret (such as a key or password) has been compromised. Such constructions can be used, e.g., to automatically shut down compromised services, or to automatically revoke compromised secrets to minimize the effects of compromise. Our threat model includes malicious agents, (temporarily or permanently) compromised agents, and clones. 

Previous works have studied domain-specific partial solutions to this problem. For example, Google's Certificate Transparency aims to provide infrastructure to detect the compromise of a certificate authority's signing key, logs have been used for detecting endpoint compromise, and protocols have been proposed to detect cloned RFID/smart cards. Contrary to these existing approaches, for which the designs are interwoven with domain-specific considerations and which usually do not enable fully automatic response (i.e., they need human assessment), our approach shows where automatic action is possible. Our results unify, provide design rationales, and suggest improvements for the existing domain-specific solutions.

Based on our analysis, we construct several mechanisms for the detection of compromised secrets. Our mechanisms enable automatic response, such as revoking keys or shutting down services, thereby substantially limiting the impact of a compromise.

In several case studies, we show how our mechanisms can be used to substantially increase the security guarantees of a wide range of systems, such as web logins, payment systems, or electronic door locks. For example, we propose and formally verify an improved version of Cloudflare's Keyless SSL protocol that enables key compromise detection.
]]></content:encoded>
<pubDate>Sat, 11 Mar 2017 14:37:51 +0000</pubDate>
</item>
<item>
<title>Formalizing Privacy in Decentralized Identity: A Provably Secure Framework with Minimal Disclosure</title>
<link>https://eprint.iacr.org/2026/077</link>
<guid>https://eprint.iacr.org/2026/077</guid>
<content:encoded><![CDATA[
<div> 去中心化身份、隐私保护、零知识证明、属性承诺、W3C DID标准<br /><br />总结:<br />1. 提出一个形式化框架，解决区块链可验证性与最小数据披露原则之间的冲突。<br />2. 引入基于属性承诺和零知识证明的密码协议，用户可在不泄露敏感信息的前提下证明其属性满足特定条件。<br />3. 在半诚实敌手模型下定义了系统所需的安全与隐私要求，包括一致性及两类不可区分性。<br />4. 构建了一个在标准密码假设下满足上述要求的具体方案，并确保与W3C DID标准完全向后兼容。<br />5. 通过安全性分析和性能评估，验证了方案的可证明安全性和在资源受限环境中的高效性。 <div>
This paper presents a formal framework for enhancing privacy in decentralized identity (DID) systems, resolving the inherent conflict between blockchain verifiability and the principle of minimal data disclosure. At its core, we introduce a provably secure cryptographic protocol that leverages attribute commitments on-chain and zero-knowledge proofs for off-chain validation. This approach allows users to demonstrably prove the validity of predicates about their attributes without revealing the underlying sensitive values.
We formally define the security and privacy requirements for such a system—including consistency, attribute-based indistinguishability, and predicate-based indistinguishability—within a semi-honest adversarial model. We then construct a concrete scheme that realizes these properties under standard cryptographic assumptions. The proposed architecture is designed for full backward compatibility with W3C DID standards, ensuring practical deployability. Security analysis provides rigorous, provable guarantees, while performance evaluation confirms the efficiency of the core cryptographic operations, supporting its use in resource-constrained environments. This work establishes a foundational and analyzable basis for building decentralized identity systems where both accountability and user privacy are essential.
]]></content:encoded>
<pubDate>Sat, 17 Jan 2026 09:48:55 +0000</pubDate>
</item>
<item>
<title>Lether: Practical Post-Quantum Account-Based Private Blockchain Payments</title>
<link>https://eprint.iacr.org/2026/076</link>
<guid>https://eprint.iacr.org/2026/076</guid>
<content:encoded><![CDATA[
<div> Lether、后量子格密码、匿名支付协议、可刷新同态加密、零知识证明<br /><br />总结:<br />1. 提出了Lether，首个基于格的实用账户型隐私区块链支付协议，遵循Anonymous Zether范式。<br />2. 针对格密码中缺乏关键组件的问题，设计了可验证可刷新的加法同态多消息多接收者公钥加密（mmPKE）和事件导向的可链接标签方案。<br />3. 引入轻量级“刷新”机制，避免使用FHE中的复杂技术，在保证无界同态计算的同时，将每次刷新的通信与计算开销分别降至交易成本的1.3%和1.5%。<br />4. 优化LNP22零知识证明系统实现，支持高效批处理，典型交易总通信量约68KB，其中证明部分占51KB，生成与验证均在普通PC上耗时不到1秒。<br />5. 提出更贴合实际区块链场景的Anonymous Zether类协议新形式化定义，具有通用性，可推动账户型隐私支付协议的发展。 <div>
We introduce Lether, the first practical account-based private block-chain payment protocol based on post-quantum lattice assumptions, following the paradigm of Anonymous Zether (FC '19, IEEE S&amp;P '21). The main challenge in building such a protocol from lattices lies in the absence of core building blocks: unbounded-level additively-homomorphic multi-message multi-recipient public key encryption (mmPKE), and event-oriented linkable ring signatures with support for multiple tags (events). To address these issues, we propose a verifiable refreshable additively-homomorphic mmPKE scheme and a plug-and-play event-oriented linkable tag scheme from lattices. We believe both to be of independent interest.

To achieve unbounded-level homomorphic evaluation in the lattice-based setting without relying on heavy techniques such as bootstrapping or large moduli (e.g., over 60 bits) in fully homomorphic encryption (FHE), we introduce a lightweight and blockchain-friendly mechanism called refresh. Namely, each user is required to verifiably refresh their account after a certain number of transactions. With our tailored parameter settings, the amortized per-refresh costs of communication and computation are only about 1.3% and 1.5%, respectively, of the cost of a transaction.

We also optimize the implementations of LNP22 lattice-based zero-knowledge proof system (Crypto '22) in the LaZer library (CCS ’24), to support efficient batching of various proof components. Overall, for a typical transaction, the total communication cost becomes about 68 KB, with the associated zero-knowledge proof accounting for about 51 KB of this total. Each of proof generation and verification take a fraction of a second on a standard PC.

As an additional contribution, we formalize new definitions for Anonymous Zether-like protocols that more accurately capture real-world blockchain settings. These definitions are generic and are expected to benefit the broader development of account-based private blockchain payment protocols, beyond just lattice settings.
]]></content:encoded>
<pubDate>Sat, 17 Jan 2026 06:49:44 +0000</pubDate>
</item>
<item>
<title>From $\textsf{TS-SUF-2}$ to $\textsf{TS-SUF-4}$: Practical Security Enhancements for $\textsf{FROST2}$ Threshold Signatures</title>
<link>https://eprint.iacr.org/2026/075</link>
<guid>https://eprint.iacr.org/2026/075</guid>
<content:encoded><![CDATA[
<div> 阈值签名、FROST2、TS-SUF-4安全性、预处理令牌验证、分布式密钥生成<br /><br />总结:<br />1. FROST2是一种高效的阈值Schnorr签名方案，但在CRYPTO 2022中被证明仅满足TS-SUF-2安全性，易受TS-UF-3攻击。<br />2. 本文提出两种改进方案：FROST2+ 和 FROST2#，均在相同计算假设下实现更强的TS-SUF-4安全性。<br />3. FROST2+ 通过引入额外的预处理令牌验证机制，有效缓解TS-UF-3和TS-UF-4漏洞，并兼容分布式密钥生成协议如PedPoP。<br />4. FROST2# 在FROST2+基础上优化冗余计算，显著提升效率，性能比原FROST2快至少3倍。<br />5. 实验表明，FROST2+ 保持与原方案相当的效率，而FROST2# 在安全性和性能上均有显著提升。 <div>
Threshold signature schemes play a vital role in securing digital assets within blockchain and distributed systems. $\textsf{FROST2}$ stands out as a practical threshold Schnorr signature scheme, noted for its efficiency and compatibility with standard verification processes. However, under the one-more discrete logarithm assumption, with static corruption and centralized key generation settings, $\textsf{FROST2}$ has been shown by Bellare et al. (in CRYPTO 2022) to achieve only $\textsf{TS-SUF-2}$ security, which is a consequence of its vulnerability to $\textsf{TS-UF-3}$ attacks.

In this paper, we address this security limitation by presenting two enhanced variants of $\textsf{FROST2}$: $\textsf{FROST2}\texttt{+}$ and $\textsf{FROST2}\texttt{#}$, both achieving the $\textsf{TS-SUF-4}$ security level under the same computational assumptions as the original $\textsf{FROST2}$. 
The first variant, $\textsf{FROST2}\texttt{+}$, strengthens $\textsf{FROST2}$ by integrating additional pre-processing token verifications that help mitigate $\textsf{TS-UF-3}$ and $\textsf{TS-UF-4}$ vulnerabilities while maintaining practical efficiency. 
We show that $\textsf{FROST2}\texttt{+}$ can achieve $\textsf{TS-SUF-4}$ security not only under the same conditions as the original $\textsf{FROST2}$ analysis, but also when initialized with a distributed key generation protocol such as $\textsf{PedPoP}$. 
Building on these improvements, we identify optimization opportunities that lead to our second variant, $\textsf{FROST2}\texttt{#}$, which achieves $\textsf{TS-SUF-4}$ security with enhanced computational efficiency by eliminating redundant calculations.
Our benchmark shows that the performance of $\textsf{FROST2}\texttt{+}$ is comparable to $\textsf{FROST2}$ while $\textsf{FROST2}\texttt{#}$ is at least 3 times faster than $\textsf{FROST2}$.
]]></content:encoded>
<pubDate>Sat, 17 Jan 2026 06:11:54 +0000</pubDate>
</item>
<item>
<title>Noisette: Certifying Differential Privacy Mechanisms Efficiently</title>
<link>https://eprint.iacr.org/2026/074</link>
<guid>https://eprint.iacr.org/2026/074</guid>
<content:encoded><![CDATA[
<div> 差分隐私、噪声采样认证、Noisette协议、离散与连续机制、高效可扩展<br /><br />总结:  
1. 现有差分隐私实现依赖于对噪声采样方的信任，存在被恶意篡改的风险。  
2. 本文提出Noisette协议族，首次实现对离散和连续差分隐私噪声采样的高效认证。  
3. 针对离散分布，采用可认证的查找表评估；针对连续机制，引入阶梯式优化提升效率。  
4. 在均值估计和联邦学习等应用中验证了协议实用性，运行速度提升最高64倍，通信开销降低24倍。  
5. Noisette在不牺牲准确性的前提下，提供了首个高效、可扩展、通用的可认证差分隐私解决方案。 <div>
Differential privacy (DP) has emerged as a rigorous framework for privacy-preserving data analysis, with widespread deployment in industry and government. Yet existing implementations typically assume that the party applying the mechanism can be trusted to sample noise correctly. This trust assumption is overly optimistic: a malicious party may deviate from the protocol to gain accuracy or avoid scrutiny, thereby undermining users’ privacy guarantees.

In this paper, we introduce Noisette, a family of efficient protocols for certifying DP noise sampling across both discrete and continuous settings. We design a protocol that supports any discrete distribution through certifiable lookup table evaluation, and introduce a staircase-based optimization that greatly improves efficiency without compromising privacy or utility. We further extend this framework to continuous mechanisms, providing the first efficient protocol for certifiable continuous noise sampling.
    
We demonstrate the practicality of our protocols through concrete DP applications, including mean estimation and federated learning. Our protocols outperform the prior state-of-the-art by up to $64\times$ in runtime and $24\times$ in communication, while preserving the same accuracy as uncertified DP mechanisms. These results establish Noisette as the first efficient, scalable, and general-purpose solution for certifiable DP noise sampling, making certified privacy guarantees practical in high-stakes applications.
]]></content:encoded>
<pubDate>Fri, 16 Jan 2026 22:34:21 +0000</pubDate>
</item>
<item>
<title>Scalable Distributed Key Generation for Blockchains</title>
<link>https://eprint.iacr.org/2026/072</link>
<guid>https://eprint.iacr.org/2026/072</guid>
<content:encoded><![CDATA[
<div> 分布式密钥生成（DKG）、区块链、阈值密码系统、拜占庭容错、通信复杂度<br /><br />总结:<br />1. 本文提出首个面向区块链的离散对数型分布式密钥生成（DKG）协议，利用区块链内置共识机制提升效率。<br />2. 协议支持在非同步环境下容忍高达一半的拜占庭故障，具备异步安全性。<br />3. 通过引入随机信标选取小规模委员会，实现次立方通信复杂度、次平方计算复杂度和极低链上存储开销。<br />4. 仅需一次共识调用，在理想部分同步区块链上最快11轮通信即可完成。<br />5. 实验表明，相比现有独立DKG协议，本方案在带宽开销相当或更低的同时，运行速度显著更快，256节点下乐观场景仅需约6.5秒（32 vCPU）。 <div>
Distributed key generation (DKG) is a foundational building block for designing efficient threshold cryptosystems, which are crucial components of blockchain ecosystems. Existing DKG protocols address the problem in a standalone setting, focusing on establishing the final DKG public key and individual secret keys among the participating parties. This work focuses on DKG primitives for use over blockchain, where the final DKG public key must be available on-chain, enabling on-chain smart contracts to seamlessly execute threshold cryptographic verifications. We observe that existing standalone DKG designs do {\em not} sufficiently exploit the presence of blockchain, leaving substantial scope for improvement in performance. 

In this work, we design the first discrete-log-based DKG protocol tailored for use over blockchain, leveraging the blockchain's built-in consensus mechanism to realize DKG efficiently. Interestingly, the use of blockchains enables us to solve DKG while tolerating up to one-half Byzantine faults even in non-synchronous settings. Our protocol is asynchronous, allowing it to operate independently of the network's timing assumptions, with the exact network model depending on the destination blockchain.  

Our solution further utilizes an associated random beacon to select smaller committees and achieves a DKG protocol with sub-cubic communication complexity, sub-quadratic computation complexity, and minimal on-chain storage. Notably, our protocol employs a single invocation of consensus and can terminate in just eleven communication rounds in the good case when deployed on an optimal latency partially synchronous blockchain. Our experiments show that our protocol terminates faster than state-of-the-art standalone protocols, with similar bandwidth overhead for committee members and significantly reduced bandwidth for other parties. Additionally, our protocol benefits from higher CPU resources—when deployed on machines with $32$ vCPUs, it completes in approximately $6.5$ seconds in the optimistic case, even for larger systems with $256$ nodes.
]]></content:encoded>
<pubDate>Fri, 16 Jan 2026 16:38:12 +0000</pubDate>
</item>
<item>
<title>Revisiting Polynomial NTRU for FHE: Amortized Bootstrapping with Sparse Keys</title>
<link>https://eprint.iacr.org/2026/068</link>
<guid>https://eprint.iacr.org/2026/068</guid>
<content:encoded><![CDATA[
<div> 全同态加密、NTRU假设、多项式环、摊销自举、稀疏密钥<br /><br />总结:<br />1. 全同态加密（FHE）支持在加密数据上进行计算，对隐私保护机器学习至关重要。<br />2. 现有基于NTRU假设的FHE方案使用矩阵表示，破坏了多项式环结构，阻碍了现代摊销自举技术的应用。<br />3. 本文将NTRU-FHE重构为标准多项式环形式，使解密操作可分解为与FHEW风格累加器兼容的内积形式。<br />4. 基于此，作者将基于单项式-多项式乘法的摊销自举方法适配到NTRU框架，并采用稀疏密钥以保留多项式结构。<br />5. 新方案在密钥汉明重量较低时，显著降低计算开销和自举密钥大小，Python原型验证了其正确性与效率提升。 <div>
Fully homomorphic encryption (FHE) enables computation over encrypted data, playing a fundamental role in privacy-preserving machine learning. Recent work has demonstrated that FHE schemes can be constructed under the NTRU assumption, leveraging the benefits of compact ciphertexts. However, existing NTRU-based FHE constructions rely on matrix representations, which break the polynomial ring structure and prevent the direct adoption of modern amortized bootstrapping techniques.

In this work, we revisit NTRU-based FHE by reformulating the matrix-based construction into a standard polynomial-ring setting. We show that the NTRU decryption operation can be decomposed into a set of inner products compatible with FHEW-style accumulators, while preserving the polynomial structure required for further optimization. Building on this formulation, we adapt a recent amortized bootstrapping approach based on monomial-by-polynomial multiplication to the NTRU setting using sparse secret keys.

The resulting scheme combines compact ciphertexts with efficient amortized bootstrapping, reducing both computational cost and bootstrapping key size when the secret key has low Hamming weight. A proof-of-concept Python implementation validates the correctness of the proposed scheme and confirms the expected reduction in bootstrapping cost under conservative security parameters.
]]></content:encoded>
<pubDate>Fri, 16 Jan 2026 09:41:10 +0000</pubDate>
</item>
<item>
<title>\textsc{Npir}: High-Rate PIR for Databases with Moderate-Size Records</title>
<link>https://eprint.iacr.org/2025/2257</link>
<guid>https://eprint.iacr.org/2025/2257</guid>
<content:encoded><![CDATA[
<div> 隐私信息检索、高率PIR、NTRU编码、服务器吞吐量、NTRU打包<br /><br />总结:<br />1. 本文研究高率单服务器隐私信息检索（PIR）方案，旨在提升服务器吞吐量，尤其适用于记录大小为几十KB的数据库（如私有广告系统）。<br />2. 提出新方案\textsc{Npir}，基于NTRU编码，在1GB至32GB数据库中，其服务器吞吐量比Spiral高1.50–2.84倍，比NTRUPIR高1.77–2.55倍。<br />3. 设计了新型“NTRU打包”技术，将多个NTRU编码的常数项压缩至单一编码中，减小服务器响应体积，同时保持高率特性。<br />4. \textsc{Npir}天然支持批量处理中等大小记录，并能灵活处理不同大小的记录查询。 <div>
Private information retrieval (PIR) is a widely used technique in privacy-preserving applications that enables users to retrieve records from a database without revealing any information about their queries. This study focuses on a type of PIR that has a high ratio between the size of the record retrieved by the client and the server's response. Although significant progress has been made in high-rate PIR in recent years, the computational overhead on the server side remains rather high. This results in low server throughput, particularly for applications involving databases with moderate-size records (i.e. tens of kilobytes), such as private advertising system.
    In this paper, we present \textsc{Npir}, a high-rate single-server PIR that is based on NTRU encoding and outperforms the state-of-the-art Spiral (Menon \& Wu, S\&amp;P 2022) and NTRUPIR (Xia \& Wang, EuroS\&amp;P 2024) in terms of server throughput for databases with moderate-size records. In specific, for databases ranging from 1 GB to 32 GB with 32 KB records, the server throughput of \textsc{Npir} is 1.50 to 2.84 times greater than that of Spiral and 1.77 to 2.55 times greater than that of NTRUPIR.
    To improve server throughput without compromising the high-rate feature, we propose a novel tool called NTRU packing, which compresses the constant terms of underlying polynomials of multiple NTRU encodings into a single NTRU encoding, thereby reducing the size of the server's response. Furthermore, \textsc{Npir} naturally supports batch processing for moderate-size records, and can easily handle retrieving for records of varying sizes.tions, we advance secure communication protocols under challenging conditions.
]]></content:encoded>
<pubDate>Tue, 16 Dec 2025 06:06:05 +0000</pubDate>
</item>
<item>
<title>BABE: Verifying Proofs on Bitcoin Made 1000x Cheaper</title>
<link>https://eprint.iacr.org/2026/065</link>
<guid>https://eprint.iacr.org/2026/065</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、简洁证明、BitVM3、BABE协议、Groth16验证

<br /><br />总结:  
1. 为比特币引入简洁证明验证能力，可实现扩容及跨链信任使用，但受限于脚本语言表达力和区块空间。  
2. BitVM2虽已部署，但在异常路径下链上交易费用极高（超14,000美元）。  
3. BitVM3通过混淆SNARK验证器大幅降低链上成本，但其混淆电路体积达42GB，导致高昂的链下存储与设置开销。  
4. 新提出的BABE协议在保持BitVM3链上成本优势的同时，将链下存储与设置成本降低三个数量级。  
5. BABE结合线性配对关系的见证加密与基于Argo MAC的高效混淆电路，实现对Groth16证明的高效验证。 <div>
Endowing Bitcoin with the ability to verify succinct proofs has been a longstanding problem with important applications such as scaling Bitcoin and allowing the Bitcoin asset to be used in other blockchains trustlessly. It is a challenging problem due to the lack of expressiveness in the Bitcoin scripting language and the small Bitcoin block space. BitVM2 is the state-of-the-art verification protocol for Bitcoin used in several mainnets and testnets, but it suffers from very high on-chain Bitcoin transaction fees in the unhappy path (over $14,000 in a recent experiment). Recent research BitVM3 dramatically reduces this on-chain cost by using a garbled SNARK verifier circuit to shift most of the verification off-chain, but each garbled circuit is 42 Gibytes in size, so the off-chain storage and setup costs are huge. This paper introduces BABE, a new proof verification protocol on Bitcoin, which preserves BitVM3's savings of on-chain costs but reduces its off-chain storage and setup costs by three orders of magnitude. BABE uses a witness encryption scheme for linear pairing relations to verify Groth16 proofs. Since Groth16 verification involves non-linear pairings, this witness encryption scheme is augmented with a secure two-party computation protocol implemented using a very efficient garbled circuit for scalar multiplication on elliptic curves. The design of this garbled circuit builds on a recent work, Argo MAC, which gives an efficient garbling scheme to compute homomorphic MACs on such curves.
]]></content:encoded>
<pubDate>Fri, 16 Jan 2026 03:51:25 +0000</pubDate>
</item>
<item>
<title>Heli: Heavy-Light Private Aggregation</title>
<link>https://eprint.iacr.org/2026/059</link>
<guid>https://eprint.iacr.org/2026/059</guid>
<content:encoded><![CDATA[
<div> 关键词：Heli系统、隐私保护、聚合统计、轻量服务器、聚合加密<br /><br />总结:<br />1. Heli是一个双服务器系统，可在不泄露任何个体客户端数据的前提下，安全地收集客户端私有数据的聚合统计信息。<br />2. 该系统能抵御恶意服务器对隐私的侵犯，并防止行为异常的客户端破坏计算正确性，支持平均值、方差等常用统计函数。<br />3. Heli的创新在于仅“重服务器”需执行与客户端数量成正比的计算，而“轻服务器”在一次性设置后仅需次线性计算量。<br />4. 这使得计算资源有限的组织（如小型非营利机构）也能担任轻服务器，参与大规模部署（如千万级客户端）。<br />5. 系统基于新型密码学原语“仅聚合加密”，实现在加密数据上计算受限聚合函数；实验显示，在千万客户端场景下，轻服务器计算开销比先前方案减少12万倍。 <div>
This paper presents Heli, a system that lets a pair of servers collect aggregate statistics about private client-held data without learning anything more about any individual client's data. Like prior systems, Heli protects client privacy against a malicious server, protects correctness against misbehaving clients, and supports common statistical functions: average, variance, and more. Heli's innovation is that only one of the servers (the "heavy server") needs to do per-run work proportional to the number of clients; the other server (the "light server") does work sublinear in the number of clients, after a one-time setup phase. As a result, a computationally limited party, such as a low-budget non-profit, could potentially serve as the second server for a Heli deployment with millions of clients.

Heli relies on a new cryptographic primitive, aggregation-only encryption, that allows computing certain restricted functions on many clients' encrypted data. In a deployment with ten million clients, in which the servers privately compute the sum of 32 client-held 1-bit integers, Heli's heavy server does 240,000 core-s of work and the light server does 7 core-ms of work. Compared with prior work, the heavy server does 38$\times$ more computation, but the light server does 120,000$\times$ less.
]]></content:encoded>
<pubDate>Thu, 15 Jan 2026 06:17:53 +0000</pubDate>
</item>
<item>
<title>Bridging Keyword PIR and Index PIR via MPHF and Batch PIR</title>
<link>https://eprint.iacr.org/2025/2252</link>
<guid>https://eprint.iacr.org/2025/2252</guid>
<content:encoded><![CDATA[
<div> 关键词：Keyword PIR、Index PIR、MPHF-KVS、Batch PIR、Binary Fuse Filter<br /><br />总结:<br />1. 本文提出一种关键词私有信息检索（Keyword PIR）方案，其在线计算与通信开销仅为底层Index PIR的常数倍。<br />2. 引入基于最小完美哈希函数（MPHF）的键值存储结构MPHF-KVS，使每次关键词查询仅需一次索引查询。<br />3. 设计通用Batch PIR框架，通过KVS编码将Index PIR转化为Keyword PIR。<br />4. 当KYS采用Binary Fuse Filter（BFF-KVS）实现时，Keyword PIR可简化为Batch PIR。<br />5. 借助带侧信息PIR的可更新提示结构，提出“Rewind & Skip”技术，支持单轮执行多查询；MPHF-KVS开销不超过Index PIR的2倍，BFF-KVS方案开销低于7倍且保持次线性在线复杂度。 <div>
This paper presents a Keyword Private Information Retrieval (Keyword PIR) scheme that achieves a constant-factor online computation and communication overhead compared to the underlying Index PIR, bridging the gap between Keyword PIR and Index PIR, and enabling efficient and privacy-preserving queries over diverse databases. We introduce a new Key-Value Store (KVS) instantiate by Minimal Perfect Hash Function, referred to as MPHF-KVS, in which each keyword query requires only a single index query. We then develop a generic Batch PIR framework that converts Index PIR into Keyword PIR using KVS encoding.
In particular, when the KVS is instantiated using a Binary Fuse Filter (BFF-KVS), Keyword PIR can be reduced to Batch PIR. Leveraging the updatable hint structure of PIR with side information, we propose a novel {Rewind \& Skip} technique that enables the execution of multiple queries within a single round.

In MPHF-KVS, the online computation and communication costs are at most $2\times$ those of Index PIR. In our Batch PIR with BFF-KVS, building upon three recent PIR schemes with sublinear server-side online computation and communication cost and without extra hint store, our approach inherits their advantages and achieves keyword query costs of less than $7\times$ the cost of an index query, while still maintaining sublinear online complexity.
]]></content:encoded>
<pubDate>Mon, 15 Dec 2025 06:32:12 +0000</pubDate>
</item>
<item>
<title>A Scalable Coercion-resistant Voting Scheme for Blockchain Decision-making</title>
<link>https://eprint.iacr.org/2023/1578</link>
<guid>https://eprint.iacr.org/2023/1578</guid>
<content:encoded><![CDATA[
<div> 区块链投票、抗胁迫性、隐私保护、可验证性、液体民主<br /><br />总结:  
1. 现有区块链投票方案普遍缺乏抗胁迫性，因投票客户端使用的随机数可作为投票证据，易引发胁迫与贿选。  
2. 传统抗胁迫投票方案难以直接应用于区块链环境。  
3. 本文提出首个可扩展的抗胁迫区块链投票方案，支持私有加权投票和单层液体民主。  
4. 方案整体复杂度为O(n)，且将选票大小从Θ(m)降至Θ(1)，显著提升效率。  
5. 形式化证明该方案具备选票隐私性、可验证性与抗胁迫性；原型实验显示其计票速度比VoteAgain快6倍以上（5万选民规模）。 <div>
Typically, a decentralized collaborative blockchain decision-making mechanism is realized by remote voting. To date, a number of blockchain voting schemes have been proposed; however, to the best of our knowledge, none of these schemes achieve coercion-resistance. In particular, for most blockchain voting schemes, the randomness used by the voting client can be viewed as a witness/proof of the actual vote, which enables improper behaviors such as coercion and vote-buying. Unfortunately, the existing coercion-resistant voting schemes cannot be directly adopted in the blockchain context. In this work, we design the first scalable coercion-resistant blockchain voting scheme that supports private weighted votes and 1-layer liquid democracy as introduced by Zhang et al. (NDSS '19). Its overall complexity is $O(n)$, where $n$ is the number of voters. Moreover, the ballot size is reduced from Zhang et al.'s $\Theta(m)$ to $\Theta(1)$, where $m$ is the number of experts and/or candidates. We formally prove that our scheme has ballot privacy, verifiability, and coercion-resistance. We implement a prototype of the scheme, and the evaluation results show that our scheme's tally procedure is more than 6x faster than VoteAgain (USENIX '20) in an election with over 50,000 voters and over 50\% extra ballot rate.
]]></content:encoded>
<pubDate>Thu, 12 Oct 2023 12:02:44 +0000</pubDate>
</item>
<item>
<title>XM-VRF: Forward Secure, Fast and Key Updatable Hash Based Verifiable Random Function</title>
<link>https://eprint.iacr.org/2026/052</link>
<guid>https://eprint.iacr.org/2026/052</guid>
<content:encoded><![CDATA[
<div> 关键词：可验证随机函数（VRF）、后量子安全、密钥更新、XMSS、Algorand区块链

<br /><br />总结:  
1. 文章提出一种名为XM-VRF的后量子安全、支持密钥更新的可验证随机函数（VRF）方案，适用于Web3和区块链应用。  
2. XM-VRF基于对称密码组件（如哈希函数和伪随机生成器），核心采用多层结构的量子安全扩展Merkle签名方案（XMSS）。  
3. 该方案显著提升密钥生成效率，并支持从同一密钥对进行多次VRF评估，适用于多轮区块链操作。  
4. XM-VRF具备前向安全性，能抵御伪造攻击，且在生成VRF输出的同时自动更新私钥，确保状态连续性。  
5. 作者设计了一个基于XM-VRF的随机委员会选择协议，用于Algorand区块链，实现无偏、可验证且与持币量成比例的参与者选取。 <div>
Randomness that is unbiased, unpredictable and publicly
verifiable is a crucial requirement for many blockchain-based Web3 ap-
plications. Verifiable Random Functions (VRFs) inherently provide these
properties. A practical VRF scheme requires fast key generation time as
well as features like many evaluations also for different rounds in the
blockchain. In this work, we propose a post-quantum secure key updat-
able VRF construction namely XM-VRF that relies on symmetric cryp-
tographic building blocks such as hash functions and PseudoRandom
Generators (PRGs). At the heart of our construction lies a quantum
safe Extended Merkle Signature Scheme(XMSS) organized across multi-
ple layers. We reformulate the XMSS signature scheme in a structured
manner to align with our XM-VRF construction. The principal benefit
of proposed XM-VRF compared to existing solution is it’s enhanced key
generation efficiency as well as the property of many evaluations from
each secret-verification key pair. The proposed scheme is proven to sat-
isfy forward security, while also being resilient against forgery attacks,
as established through a rigorous security analysis. We emphasize that
our XM-VRF autonomously updates its secret key during the evaluation
process, performing this update concurrently with the VRF output gen-
eration to maintain uninterrupted state progression. Finally, we design a
protocol for random committee selection within the Algorand blockchain
framework,leveraging XM-VRF to ensure unbiased, verifiable, and stake-
proportional participant selection.
]]></content:encoded>
<pubDate>Tue, 13 Jan 2026 07:00:16 +0000</pubDate>
</item>
<item>
<title>SLVer Bullet: Straight-Line Verification for Bulletproofs</title>
<link>https://eprint.iacr.org/2025/1345</link>
<guid>https://eprint.iacr.org/2025/1345</guid>
<content:encoded><![CDATA[
<div> 椭圆曲线、函数域、零知识证明、验证效率、隐私保护<br /><br />总结:<br />1. Eagen提出了一种基于椭圆曲线的计算证明框架，用函数域上的高效计算替代昂贵的群运算。<br />2. 原工作缺乏清晰的协议描述、形式化安全证明和完整的效率分析。<br />3. 本文改进了现有文献，提供了详细的协议描述，并分析了完备性、可靠性和复杂度。<br />4. 将该构造应用于Schnorr和Bulletproofs协议，显著降低了验证者的计算开销。<br />5. 该方法特别适用于需频繁验证证明的隐私保护场景（如区块链和Tor路由），也可普遍提升基于椭圆曲线的零知识证明系统的验证效率。 <div>
Eagen introduced a framework for proof-of-computation over elliptic curves, replacing costly group operations with efficient computations over a function field. This work lacks clear protocol descriptions, formal security proofs, and a thorough efficiency analysis; we improve upon the literature, present a detailed protocol description, then analyze completeness, soundness, and complexity. We apply our construction to the Schnorr and Bulletproofs protocols, highlighting how this reduces verifier costs significantly compared to the original proposals. This tradeoff most clearly benefits privacy-centered constructions like blockchain cryptocurrencies and Tor routing - where proofs must be verified repeatedly - but more generally may be used to improve verification time in generic curve-based zero-knowledge proof systems.
]]></content:encoded>
<pubDate>Wed, 23 Jul 2025 21:14:58 +0000</pubDate>
</item>
<item>
<title>Argo MAC: Garbling with Elliptic Curve MACs</title>
<link>https://eprint.iacr.org/2026/049</link>
<guid>https://eprint.iacr.org/2026/049</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、链下密码学、SNARK、混淆电路、Argo MAC<br /><br />总结:  
1. 链下密码学可增强比特币智能合约的表达能力。  
2. 现有方案（如BitVM）利用SNARK证明任意计算，并通过混淆电路将验证过程移至链下。  
3. 作者提出新混淆原语Argo MAC，使混淆后的SNARK验证器效率提升超1000倍。  
4. Argo MAC能高效地将曲线点的比特分解编码转换为该点的同态MAC。  
5. 同态MAC显著提升了混淆电路的效率，后续工作将展示其在配对友好型SNARK验证器中的应用。 <div>
Off-chain cryptography enables more expressive smart contracts for Bitcoin. Recent work, including BitVM, use SNARKs to prove arbitrary computation, and garbled circuits to verifiably move proof verification off-chain. We define a new garbling primitive, Argo MAC, that enables over $1000\times$ more efficient garbled SNARK verifiers. Argo MAC efficiently translates from an encoding of the bit decomposition of a curve point to a homomorphic MAC of that point. These homomorphic MACs enable much more efficient garbling. In subsequent work, we will describe how to use Argo MAC to construct garbled SNARK verifiers for pairing-based SNARKs.
]]></content:encoded>
<pubDate>Mon, 12 Jan 2026 21:04:50 +0000</pubDate>
</item>
<item>
<title>SoK of Private Deep Neural Network Inference with Approximate Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2026/047</link>
<guid>https://eprint.iacr.org/2026/047</guid>
<content:encoded><![CDATA[
<div> 深度神经网络 全同态加密 隐私保护 推理效率 高性能硬件<br /><br />总结:<br />1. 深度神经网络（DNNs）已广泛应用于解决实际问题，但其模型与输入数据常涉及强隐私保护需求。<br />2. 全同态加密（FHE）可在加密数据上执行运算，提供后量子安全的隐私保障，但导致数据体积剧增。<br />3. 当前FHE在DNN推理中受限于极长的执行时间和巨大的内存消耗，仅适用于简化模型和小型数据集。<br />4. 本文系统综述了该领域的研究现状与实践进展，识别出实现生产级高效DNN隐私推理的主要挑战。<br />5. 聚焦高性能硬件上的深度学习推理，提出一个理想的DNN隐私推理系统框架，整合并推广现有文献中的关键理念。 <div>
Deep neural networks (DNNs), a hot topic in this decade, are already solving many practical problems previously unchallenged. There are clear use cases of strong requirements for privacy protection in DNN models and input data. Fully Homomorphic Encryption (FHE) schemes provide privacy by enabling operations upon encrypted data with post-quantum security, at the expense of vast data size increase. Overwhelming execution times and memory sizes currently limit DNN inference with FHE to severely reduced models and datasets. In this article, we thoroughly review the state of the art and the state of the practice around this topic, and identify the current challenges remaining to enable efficient DNN inference with FHE in production-sized use cases, along with the most promising trends to address them. Advancing upon previous review articles in the literature, our focus is specifically on deep learning inference on top of high-performance hardware. From our analysis, we set what we consider to be an ideal private inference system for DNNs, capturing notions already present in the literature and generalizing them.
]]></content:encoded>
<pubDate>Mon, 12 Jan 2026 10:30:38 +0000</pubDate>
</item>
<item>
<title>Euston: Efficient and User-Friendly Secure Transformer Inference with Non-Interactivity</title>
<link>https://eprint.iacr.org/2026/046</link>
<guid>https://eprint.iacr.org/2026/046</guid>
<content:encoded><![CDATA[
<div> 安全Transformer推理、非交互式框架、同态加密、奇异值分解、非线性运算优化<br /><br />总结:<br />1. 针对现有非交互式安全Transformer推理（STFI）框架在同态矩阵乘法（HMM）中密文过大、旋转操作多及用户端开销高的问题，提出新方案Euston。<br />2. Euston结合RNS-CKKS全同态加密与优化方法，在离线-在线推理范式下显著提升效率。<br />3. 在线性运算中，采用奇异值分解（SVD）与批量HMM，减小密文尺寸、降低旋转次数，从而减少用户计算、通信和存储开销。<br />4. 在非线性运算中，使用列（对角）打包密文格式避免高成本旋转，并通过深度调控策略降低深度消耗，实现无用户-服务器通信的高效推理。<br />5. 相比最新方案NEXUS，Euston将用户预处理成本降低高达3100倍，系统整体推理性能提升8.8倍，其中HMM和HNE分别加速90倍和165.7倍。 <div>
Secure TransFormer Inference (STFI) frameworks have been proposed to address privacy concerns over user inputs and model parameters in Transformer-based LLMs. While most existing solutions rely on interactive protocols that incur substantial user-server communication overhead, non-interactive STFI variants have recently emerged to eliminate such dependencies. Nevertheless, state-of-the-art non-interactive STFI frameworks still suffer from critical limitations. (i) Large ciphertext sizes and multiple rotations alongside heavy user-side overhead in Homomorphic Matrix Multiplication (HMM). (ii) High approximation costs and depth consumptions in Homomorphic Nonlinear Evaluations (HNE).

To address these limitations, we present Euston, an efficient and user-friendly STFI with non-interactivity. By combining RNS-CKKS fully homomorphic encryption with optimized methods, Euston achieves unprecedented efficiency in offline online inference paradigm. The key innovations are twofold. (i) For linear operations, we adopt Singular Value Decomposition (SVD) with our novel batched HMMs to minimize ciphertext size and reduce rotation counts, simultaneously lowering user-side computational, communication and storage overhead. (ii) For nonlinear operations, we employ column(diagonal)-packed ciphertext matrix formats to eliminate costly rotations and depth regulation strategies to reduce depth consumption in non-interactive HNEs, which not only avoids user-server communications but also accelerates inference performance. In comparision with the state-of-the-art approach (NEXUS, NDSS 2025), Euston achieves up to 3100× lower preprocessing costs for the user and 8.8× higher system-wide inference performance, specifically delivering a 90× speedup for HMM and a 165.7× speedup for HNE. Our results demonstrate that Euston establishes new efficiency frontiers for user-friendly STFI deployment across cloud and edge environments.
]]></content:encoded>
<pubDate>Mon, 12 Jan 2026 09:35:31 +0000</pubDate>
</item>
<item>
<title>Towards Privacy-Preserving Unmanned Aerial Vehicles Shared Logistics  via Dynamic Sanitizable Signature with Multiple Sanitizers</title>
<link>https://eprint.iacr.org/2026/041</link>
<guid>https://eprint.iacr.org/2026/041</guid>
<content:encoded><![CDATA[
<div> 无人机物流、隐私保护、可净化签名、动态权限管理、网络安全<br /><br />总结:<br />1. 无人机（UAV）在物流配送中具有高效、低成本和适应复杂地形的优势，尤其适用于解决“最后一公里”问题。<br />2. 开放环境中的第三方无人机系统易受窃听、篡改等网络攻击，存在敏感信息泄露风险。<br />3. 物流系统中用于清除隐私信息的仓库节点需根据需求动态调整，带来权限管理挑战。<br />4. 研究提出一种支持多净化者的动态可净化签名方案，允许多个净化者独立处理签名消息中的敏感信息，保障数据隐私。<br />5. 该方案支持灵活添加或撤销净化者权限，无需更改现有密钥，并在AmovLab Prometheus 600无人机上验证了其低计算与通信开销，具备良好安全性与实用性。 <div>
In recent years, unmanned aerial vehicles (UAVs) have shown great potential in logistics delivery due to their ability to bypass traffic congestion and adapt to complex terrains. Their high efficiency, low cost, and wide coverage make them a valuable supplement to last-mile logistics. 
However, third-party UAV systems operating in open environments are vulnerable to eavesdropping, tampering, and other cyber-attacks, which poses risks of sensitive information leakage. 
Meanwhile, warehouse nodes for sanitizing private information are widely deployed in logistics systems and need to be dynamically adjusted according to demand, which poses a challenges for the management of sanitization permissions.
To address these issues, we propose a dynamic sanitizable signature with multiple sanitizers, enabling each sanitizer to independently sanitize sensitive information in signed messages, thus preserving logistics data privacy. 
Our scheme is applicable to UAV logistics scenarios and supports the addition and revocation of sanitizers without modifying existing keys, thereby enabling flexible and efficient permissions management.
Security analysis shows that the proposed scheme ensures unforgeability, privacy preservation, and other security properties. A implementation on AmovLab Prometheus 600 UAVs demonstrates lower computational and communication overhead than existing privacy-preserving schemes, confirming its efficiency and practicality in UAV logistics systems.
]]></content:encoded>
<pubDate>Sun, 11 Jan 2026 09:03:35 +0000</pubDate>
</item>
<item>
<title>Scalable Honest-majority MPC for Machine Learning from Mixed Secret Sharings</title>
<link>https://eprint.iacr.org/2026/038</link>
<guid>https://eprint.iacr.org/2026/038</guid>
<content:encoded><![CDATA[
<div> 安全多方计算、隐私保护机器学习、Shamir秘密共享、打包Shamir秘密共享、混合秘密共享策略<br /><br />总结:  
1. 针对现有安全多方计算（MPC）在隐私保护机器学习中面临的可扩展性与效率问题，提出一种混合秘密共享策略。  
2. 该策略对非线性层采用打包Shamir秘密共享（PS），对线性层（如矩阵乘法）采用标准Shamir秘密共享（SS）。  
3. 设计了SS与PS之间的通用转换机制，并集成到ML协议中，避免额外通信与计算开销。  
4. 开发了基于PS的高效非线性基础操作协议，使多个非线性操作的通信成本接近单个操作。  
5. 实验表明，相比最新工作LXY24，在广域网中通信量减少3.6–6.1倍，运行时间提升1.5–4.3倍；在局域网中性能相当或提升最高达2.3倍。 <div>
Secure multi-party computation (MPC) provides a promising approach for privacy-preserving machine learning (ML). Existing solutions generally fall into two categories but face scalability and efficiency limitations. Protocols based on Shamir secret sharing (SS) incur high communication costs, while those relying on packed Shamir secret sharing (PS) remain largely theoretical and often require costly secret routing, especially for complex ML tasks.

In this work, we propose a mixed secret sharing strategy that leverages PS sharing for non-linear layers with repeated and independent operations, and SS sharing for linear layers such as matrix multiplications. To efficiently support alternating linear and non-linear computations, we design generic conversions between SS and PS sharings and further integrate them into the corresponding ML protocols, thereby eliminating additional communication and computation overhead. Moreover, we develop efficient PS sharing-based protocols for primitive non-linear building blocks, which enable multiple non-linear operations to be executed with essentially the same communication cost as a single operation.

We implement our framework for secure multi-party ML inference and conduct extensive experiments. Compared to the SOTA work LXY24 (USENIX Security '24), our approach reduces communication by $3.6$-$6.1 \times$, while achieving $1.5$-$4.3 \times$ runtime improvement in the WAN setting and comparable or up to $2.3 \times$ better performance in the LAN setting.
]]></content:encoded>
<pubDate>Fri, 09 Jan 2026 11:22:55 +0000</pubDate>
</item>
<item>
<title>On the design of Survivable Distributed Passwordless Authentication and Single Sign-On</title>
<link>https://eprint.iacr.org/2026/028</link>
<guid>https://eprint.iacr.org/2026/028</guid>
<content:encoded><![CDATA[
<div> 关键词：单点登录（SSO）、身份提供商、钓鱼攻击、无密码认证、可生存性协议<br /><br />总结:  
1. 现有单点登录（SSO）协议在身份提供商被攻破时，攻击者可伪造身份凭证，冒充用户。  
2. 当前的可生存SSO协议仅适用于基于密码的认证，难以抵御凭证钓鱼等高级攻击。  
3. 虽然已有抗钓鱼的无密码认证标准，但缺乏对入侵容忍性的保障。  
4. 本文首次提出“可生存无密码SSO”（SPS）研究方向，并定义其子协议“可生存无密码挑战-响应”（SPC）。  
5. 提出了针对SPC和SPS的首个形式化安全框架与博弈式安全定义，涵盖会话注入、克隆认证器检测等新旧攻击模型，并通过模块化设计支持协议组合与扩展应用。 <div>
Single Sign-On (SSO) protocols allow an identity provider to authenticate users and report the outcome by issuing identity attestations. Recent attacks show that breaching the identity provider infrastructure enables adversaries to issue arbitrary identity attestations and impersonate users. Survivable SSO protocols limit the risks of similar intrusions, but they have only been defined for password-based authentication, inheriting their limitations against powerful attacks such as credential phishing. While phishing-resistant passwordless authentication protocols have been standardized, they are not designed to guarantee intrusion tolerance. We initiate the research for Survivable Passwordless SSO (SPS) and propose a modular approach which includes the novel definition of Survivable Passwordless Challenge-response (SPC) protocols for authentication as a sub-routine of SSO. We give the first frameworks and game-based security definitions both for SPC and SPS which capture both novel attack classes, such as session injection attacks in a decentralized setting, and existing but not yet formalized attack classes, such as detection of cloned authenticators. The design of the models includes novel strategies to capture proactive security in survivable protocols within security definitions and to compose authentication and SSO through a modular approach. Our strategies and models may also be applied with minor modifications to non-survivable protocols, possibly providing a novel approach to assess the security of existing SSO protocols.
]]></content:encoded>
<pubDate>Wed, 07 Jan 2026 16:34:31 +0000</pubDate>
</item>
<item>
<title>Practical SNARGs for Matrix Multiplications over Encrypted Data</title>
<link>https://eprint.iacr.org/2026/027</link>
<guid>https://eprint.iacr.org/2026/027</guid>
<content:encoded><![CDATA[
<div> 全同态加密、可验证计算、矩阵-向量乘法、隐私保护、恶意安全<br /><br />总结:<br />1. 全同态加密（FHE）允许在加密数据上直接计算，保障医疗和金融等敏感领域的隐私。<br />2. FHE在“诚实但好奇”模型下确保机密性，但要实现抵御恶意攻击的完整安全（含完整性和隐私），需引入可验证性。<br />3. 现有将FHE与可验证计算结合的方案（即vFHE）通常计算开销大，难以实用。<br />4. 本文提出一种专用于矩阵–向量乘法的高效可验证同态加密方案，而非通用vFHE。<br />5. 作者提供了开源实现，实验表明该方案效率高，具备实际部署可行性。 <div>
Fully Homomorphic Encryption (FHE) enables computations to be performed directly on encrypted data, without ever requiring decryption. This capability is particularly crucial for privacy-preserving outsourced computation in sensitive fields such as healthcare and finance. While FHE ensures data confidentiality under the honest-but-curious adversarial model, achieving full malicious security, encompassing both integrity and privacy, requires an additional layer of verifiability.

To address this, a growing body of research has explored combining FHE with techniques from verifiable computation, leading to the notion of verifiable FHE (vFHE). However, the integration of these two paradigms often results in substantial computational overhead, making existing approaches largely impractical for real-world deployment.

In this work, rather than targeting general-purpose verifiable FHE, we design a novel and practical verifiable homomorphic encryption scheme tailored for an important and widely used operation: matrix–vector multiplication. We provide an open-source implementation and our experimental results demonstrate that the proposed scheme achieves high efficiency, making it ready for practical adoption.
]]></content:encoded>
<pubDate>Wed, 07 Jan 2026 16:22:19 +0000</pubDate>
</item>
<item>
<title>EHDSA:  Elliptic  Curve-Based  Homomorphic  Digital  Signature  Algorithm  with  Isomorphic  Message Mapping</title>
<link>https://eprint.iacr.org/2026/023</link>
<guid>https://eprint.iacr.org/2026/023</guid>
<content:encoded><![CDATA[
<div> 椭圆曲线密码学、同态数字签名、ECDSA、隐私增强、群同构<br /><br />总结:<br />1. 本文提出EHDSA（椭圆曲线同态数字签名算法），在经典ECDSA基础上引入新群同构φ，将椭圆曲线群映射到整数环ℤₙ。<br />2. 利用秘密参数t∈ℤₙ*构建标量映射，有效隐藏临时公钥成分，同时保留验证所需的代数与同态性质。<br />3. 该方案增强了签名的不可链接性和不可区分性，显著提升隐私保护能力。<br />4. 在保持ECDSA计算效率的同时，仅引入极小计算开销。<br />5. 文章提供了基于标准密码假设的形式化安全证明，并验证了方案的正确性与计算复杂度。 <div>
Elliptic curve-based cryptographic systems have established themselves as fundamental components of modern cryptography, providing both efficiency and security guarantees. In this paper, we propose EHDSA (Elliptic Curve Homomorphic Digital Signature Algorithm), which addresses the privacy limitations inherent in classical ECDSA by introducing a novel isomorphism $\phi$ from the elliptic curve group $E(\mathbb{F}_p)$ to the integer ring $\mathbb{Z}_n$. Our approach utilizes a secret parameter $t \in \mathbb{Z}_n^*$ to define a scalar mapping that effectively obfuscates ephemeral public key components while maintaining the algebraic and homomorphic properties essential for signature verification. This transformation provides enhanced unlinkability and signature indistinguishability while preserving the computational efficiency of ECDSA. We provide formal security proofs under standard cryptographic assumptions, demonstrate correctness, and analyze computational complexity, showing that EHDSA achieves security levels equivalent to ECDSA with minimal computational overhead.
]]></content:encoded>
<pubDate>Wed, 07 Jan 2026 06:04:23 +0000</pubDate>
</item>
<item>
<title>Qurrency: a quantum-secure, private, and auditable platform for digital assets</title>
<link>https://eprint.iacr.org/2026/015</link>
<guid>https://eprint.iacr.org/2026/015</guid>
<content:encoded><![CDATA[
<div> 关键词：央行数字货币（CBDC）、UTXO模型、隐私保护、抗量子安全、可审计性<br /><br />总结:  
1. 央行数字货币（CBDC）及相关数字资产平台虽具变革潜力，但受限于隐私、抗量子安全和可审计性三大问题。  
2. 本文首次对基于UTXO模型的私有数字资产系统进行形式化建模，填补了该领域研究空白。  
3. 建模过程中发现并披露了开源项目Hyperledger Zeto中的关键安全漏洞，已获修复。  
4. 提出名为Qurrency的高效构造方案，兼具隐私保护、可审计性，并能抵御“先存储后解密”类量子攻击。  
5. Qurrency已在EVM兼容区块链上实现，验证了其实际可行性和部署便捷性。 <div>
Central bank digital currencies (CBDCs) and other related digital asset platforms have the potential to revolutionize the financial world.  While these platforms have been deployed in test environments by virtually all large financial institutions, including central banks, there are still several limitations of these systems that prevent widespread adoption.  These include (i) privacy, (ii) security against quantum adversaries, and (iii) auditability. In this work, we undertake (to our knowledge) the first formal study of these systems.

While there have been many digital asset platforms implemented, we do not know of any formal model for a fundamentally UTXO-based digital asset platform/CBDC. Our first contribution is a formal modeling of a UTXO-based private digital asset system that meets our requirements listed above.  This model is loosely based upon the open source software that we found came the closest to meeting our requirements, Hyperledger Zeto.  In the course of our formal modeling, we found a critical security bug in Zeto which we responsibly disclosed to the Zeto maintainers and has since been fixed. We then provide an efficient construction of such a system, which we call Qurrency.  Qurrency is an efficient UTXO-based privacy-preserving token system that includes an auditing mechanism and is secure against "harvest now, decrypt later" attacks, which is critically important for several central banks, including the Bank of Brazil. We implemented our construction to show that it is practically efficient and can be used on any EVM-based blockchain system with ease.
]]></content:encoded>
<pubDate>Mon, 05 Jan 2026 17:50:33 +0000</pubDate>
</item>
<item>
<title>Third-Party Moderation of Abuse Reports for End-to-End Encrypted Messaging with Multiple Moderators</title>
<link>https://eprint.iacr.org/2026/010</link>
<guid>https://eprint.iacr.org/2026/010</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端加密、消息标记、多审核员、可验证举报、隐私保护<br /><br />总结:<br />1. 现有消息标记（message franking）机制通常假设平台与审核员为同一实体，且仅支持单一审核员，限制了内容审核策略的灵活性。<br />2. 本文提出支持多个经认证审核员的新技术，允许用户自主选择消息举报所用的审核员。<br />3. 多审核员环境需定义新的安全概念，包括对平台和其他审核员的否认性保障，以及用户选择审核员的隐私保护。<br />4. 作者系统研究了相关需求，并设计了三种适用于不同部署场景的可验证举报协议，在安全性和性能之间提供多种权衡。<br />5. 实验评估表明，新方案在多数情况下性能优于或媲美仅支持单一审核员的现有方案。 <div>
Abuse reporting tools like message franking allow end-to-end encrypted (E2EE) messaging platforms to verify user-generated abuse reports as part of their platform content moderation policies. While the lightweight message franking protocol deployed by Meta's Messenger is designed with the assumption that the moderator and the platform processing messages are the same entity, proposals for other message franking-style protocols allow for a separation between the platform and moderator, albeit at a higher cost. Unfortunately, all works in this space assume that there exists a single moderator working with a platform who verifies and moderates all reports. This results in a situation where technical limitations limit platforms' moderation policy options.

This paper introduces new techniques that allow E2EE messaging platforms to work with multiple vetted moderators, giving users options in their choice of moderators for messages they send to their friends. Verifiable abuse reporting in a multi-moderator setting requires new security notions to capture deniability requirements with respect to the platform and other moderators, as well as new privacy requirements with respect to users' choice of moderator(s). We comprehensively study these requirements and propose three protocols for verifiable abuse reporting in this setting, offering a range of security and performance tradeoffs for different deployment scenarios. We evaluate the performance of our proposed schemes, showing that in many cases they match or exceed the performance of prior schemes that only support a single moderator.
]]></content:encoded>
<pubDate>Sun, 04 Jan 2026 14:03:48 +0000</pubDate>
</item>
<item>
<title>A SNARK for (Non-)Subsequences with Text-Sub-Linear Proving Time</title>
<link>https://eprint.iacr.org/2026/008</link>
<guid>https://eprint.iacr.org/2026/008</guid>
<content:encoded><![CDATA[
<div> 关键词：子序列、非子序列、预处理、证明方案、运行时间<br /><br />总结:<br />1. 文章研究如何高效判断一个字符串是否为另一字符串的子序列或非子序列，该问题在基因分析、区块链和自然语言处理等领域有广泛应用。<br />2. 针对现有方法（如Ling等人基于多变量sumcheck的方案）中证明者运行时间较高（至少为$\mathcal{O}(n + N + |\Sigma|)$）的问题，提出一种两阶段证明方案。<br />3. 该方案将证明过程分为预处理阶段和（非）子序列证明阶段，其中预处理仅依赖文本$\mathbf{t}$和字符集$\Sigma$，可提前完成。<br />4. 利用缓存商技术，预处理时间达到关于$N + |\Sigma|$的拟线性复杂度，而（非）子序列证明时间仅为$\mathcal{O}(n \log_2 (N + |\Sigma|))$。<br />5. 在$n \ll N$且$\log_2(N + |\Sigma|)$较小的常见场景下，该方案显著降低证明者运行时间，实现对文本长度的次线性证明效率。 <div>
A keyword $\mathbf{s}$ is a subsequence of a text $\mathbf{t}$ if $\mathbf{s}$ can be obtained by deleting some characters of $\mathbf{t}$. Otherwise, $\mathbf{s}$ is considered a non-subsequence of $\mathbf{t}$. Determining (non-)subsequence relationships involves various fields, e.g., genetic analysis, blockchains, natural language processing, etc. Ling et al. (SCN 2024) provided a succinct argument for non-subsequences from multivariate sumcheck (Lund et al., FOCS 1990) whose prover's runtime is at least $\mathcal{O}(n + N + |\Sigma|)$ where $n$, $N$, and $\Sigma$ are respectively the lengths of strings $\mathbf{s}$ and $\mathbf{t}$, and the alphabet $\Sigma$ capturing all characters of $\mathbf{s}$ and $\mathbf{t}$. As indicated by Ling et al., proving non-subsequences is non-trivial since one needs to model such an argument into smaller ones for sumcheck, permutation, and lookup.

We propose a subsequence scheme that separates proving either subsequence or non-subsequence arguments into two phases: (i) proof of preprocessing and (ii) proof of (non-)subsequence argument, assuming $n \ll N$ (i.e., $|\mathbf{s}| \ll |\mathbf{t}|$). Then, we can make a proof of preprocessing with inputs $\mathbf{t}$ and $\Sigma$ in advance, without any knowledge about $\mathbf{s}$. When $\mathbf{s}$ is known, we can determine whether $\mathbf{s}$ is a subsequence of $\mathbf{t}$ and proceed to prove that $\mathbf{s}$ is a (non-)subsequence of $\mathbf{t}$. Employing cached quotients (IACR ePrint 2022/1763), we achieve the running time quasilinear in $N + |\Sigma|$ for preprocessing, while the running time of proving (non-)subsequences is $\mathcal{O}(n \log_2 (N + |\Sigma|))$. Since $n \ll N$ and $\log_2(N + |\Sigma|)$ is small, this saves the prover's runtime, assuming a preprocessing depending only on $\mathbf{t}$ is computed in advance. As $\mathcal{O}(n \log_2 (N + |\Sigma|))$ is sub-linear in $N + |\Sigma|$, we achieve a text-sub-linear proving time.
]]></content:encoded>
<pubDate>Sun, 04 Jan 2026 04:21:01 +0000</pubDate>
</item>
<item>
<title>Mina: Decentralized Cryptocurrency at Scale</title>
<link>https://eprint.iacr.org/2020/352</link>
<guid>https://eprint.iacr.org/2020/352</guid>
<content:encoded><![CDATA[
<div> 简洁区块链、状态机、常数时间验证、SNARKs、Mina（Coda）<br /><br />总结:<br />1. 提出“简洁区块链”概念，是一种复制状态机，其每个状态转换（区块）均可在常数时间内高效验证，不受历史交易数量影响。<br />2. 传统区块链的验证时间随交易数量线性增长，而简洁区块链显著提升了效率。<br />3. 利用递归组合的简洁非交互式知识证明（SNARKs）构建该区块链。<br />4. 基于此构建了名为Coda（现称Mina）的支付系统，功能类似比特币。<br />5. Mina验证整个链历史仅需约200毫秒，使轻量级客户端和移动设备可实现完整验证。 <div>
We introduce the notion of a succinct blockchain, a replicated state machine in which each state transition (block) can be efficiently verified in constant time regardless of the number of prior transitions in the system. Traditional blockchains require verification time linear in the number of transitions. We show how to construct a succinct blockchain using recursively composed succinct non-interactive arguments of knowledge (SNARKs). Finally, we instantiate this construction to implement Coda (now known as Mina), a payment system (cryptocurrency) using a succinct blockchain. Coda offers payment functionality similar to Bitcoin, with a dramatically faster verification time of 200ms making it practical for lightweight clients and mobile devices to perform full verification of the system’s history.
]]></content:encoded>
<pubDate>Thu, 26 Mar 2020 07:49:46 +0000</pubDate>
</item>
<item>
<title>SoK: Approximate Agreement</title>
<link>https://eprint.iacr.org/2025/2339</link>
<guid>https://eprint.iacr.org/2025/2339</guid>
<content:encoded><![CDATA[
<div> Your abstract presents a strong foundation for a **Systematization of Knowledge (SoK)** paper on **Byzantine-resilient Approximate Agreement (AA)** in complete networks. Below is a refined version of your abstract with improved clarity, flow, and academic tone—suitable for submission to a top-tier security or distributed systems conference (e.g., IEEE S&amp;P, USENIX Security, PODC, or DISC):

---

**Abstract.**  
Approximate Agreement (AA) relaxes the traditional consensus problem by allowing honest parties to output values that are *close* to one another—within the range of the honest inputs—rather than requiring exact agreement. Since its introduction, AA has emerged as a powerful primitive with diverse applications, including blockchain oracles, sensor fusion in cyber-physical systems, and decentralized governance mechanisms.

This paper presents a Systematization of Knowledge (SoK) on Byzantine-resilient Approximate Agreement in complete networks, focusing primarily on the real-valued variant. We provide a comprehensive survey of existing protocols across three fundamental communication models: synchronous, asynchronous, and network-agnostic (e.g., Crusader or Hybrid models). For each model, we map out the feasibility frontiers in terms of fault tolerance, characterizing tight bounds on resilience (i.e., the maximum number of Byzantine faults tolerated under various assumptions).

We systematically compare protocols along key performance dimensions: round complexity, communication overhead, and convergence quality. In doing so, we identify and clarify subtle gaps, overlooked assumptions, and inconsistencies in prior work—such as implicit trust in timing guarantees or imprecise definitions of approximation accuracy.

Beyond the standard correctness conditions, we examine strengthened requirements, such as ensuring outputs are not only mutually close but also *proximal to meaningful statistics* of the honest inputs—most notably, the median. This property enhances fairness and representativeness, which is crucial in applications like decentralized price oracles.

Finally, we contextualize real-valued AA within the broader landscape of Approximate Agreement over non-standard domains—such as multi-dimensional vectors, metric spaces, and graphs—highlighting how structural complexity increases both theoretical and practical challenges. Through this SoK, we aim to consolidate insights, guide future research, and promote robust, efficient, and well-understood deployment of AA in real-world systems.

---

### Suggestions for the Full Paper Structure:
To maximize impact, consider organizing the full paper as follows:

1. **Introduction**  
   - Motivation: Why AA? Where is it used?
   - Key differences from exact consensus.
   - Scope: Real-valued inputs, complete graphs, Byzantine adversaries.

2. **Problem Definition & Models**  
   - Formal definition of Approximate Agreement.
   - Correctness properties: Validity (range containment), ε-Agreement.
   - Communication models: Sync, Async, Partially Synchronous / Network-Agnostic.
   - Adversarial model: static vs adaptive, rushing.

3. **Feasibility Landscape**  
   - Tight resilience bounds per model (e.g., $ f < n/3 $ async, $ f < n/2 $ sync).
   - Impossibility results and their implications.
   - Role of input range and convergence criteria.

4. **Protocol Taxonomy & Comparison**  
   - Survey major protocols (e.g., Dolev et al., Abraham et al., Mendes & Herlihy for high-dimensions).
   - Tabular comparison: rounds, message complexity, approximation factor, assumptions.
   - Highlight optimizations: averaging strategies, iterative refinement, early termination.

5. **Strengthened Properties**  
   - Median proximity: desiderata and known approaches.
   - Fair validity, centrality, bias resistance.
   - Trade-offs between accuracy and fault tolerance.

6. **Beyond Real Numbers**  
   - AA in higher dimensions (vector consensus).
   - Metric space embeddings.
   - Graph-based inputs and geometric median generalizations.

7. **Applications & Lessons Learned**  
   - Case studies: Oracles (e.g., Chainlink), CPS, federated learning.
   - What makes AA preferable over voting or median filters?

8. **Open Problems & Research Directions**  
   - Optimal communication complexity?
   - Adaptive security?
   - Practical implementations and empirical evaluation gaps.
   - Integration with threshold cryptography or verifiable computation.

9. **Conclusion**

---

Let me know if you'd like help drafting specific sections, creating comparison tables, or visualizing the feasibility frontiers! <div>
Approximate Agreement (AA) is a relaxation of consensus that requires honest parties to output values that are close and within the honest inputs' range. Introduced as a relaxation of exact consensus, AA has become a versatile primitive with applications from blockchain oracles to cyber-physical systems.
This paper provides a systematization of knowledge (SoK) on byzantine-resilient AA in complete networks.

We mainly focus on the real-valued variant, and chart the feasibility frontiers in synchronous, asynchronous, and network-agnostic models. We compare protocols in terms of resilience, round complexity, and communication efficiency, while also clarifying overlooked details and gaps.

Beyond standard requirements on the outputs, we discuss stronger conditions, such as having the outputs \emph{close} to the honest inputs' median. Moreover, we briefly situate the real-valued AA problem within the broader landscape of AA, where other input domains such as higher-dimensional spaces and graphs introduce further challenges.
]]></content:encoded>
<pubDate>Wed, 31 Dec 2025 17:18:44 +0000</pubDate>
</item>
<item>
<title>OHMG: One hot modular garbling</title>
<link>https://eprint.iacr.org/2025/2338</link>
<guid>https://eprint.iacr.org/2025/2338</guid>
<content:encoded><![CDATA[
<div> Your abstract presents an innovative approach to garbling circuits with a focus on **authenticity** in a **privacy-free environment**, which is an interesting departure from traditional secure computation paradigms where privacy (confidentiality of inputs/outputs) is the primary goal. Let's unpack and refine your idea for clarity, technical precision, and academic tone—especially if you're preparing this for publication or presentation.

Here’s a revised version of your abstract with improved structure and terminology, while preserving your core contributions:

---

**Revised Abstract:**

We propose a novel *authenticable circuit garbling* mechanism that ensures correctness and integrity of computations in a *privacy-free* setting, emphasizing *authenticity* rather than confidentiality. Our scheme leverages *one-hot encodings*, *tensor products*, and *elliptic curve arithmetic* to garble wires and gates of logical circuits, enabling verifiable execution even when all inputs and outputs are public. While designed primarily for arithmetic gates over finite fields, we introduce specialized *gadgets* to seamlessly transition between binary-encoded inputs and arithmetic representations, and vice versa, thus supporting mixed-domain computations.

A key efficiency feature of our construction is that each arithmetic gate requires at most *one ciphertext* to evaluate its functionality, assuming the evaluator possesses both garbled inputs and their corresponding cleartext values. This minimal cryptographic overhead enables lightweight verification in decentralized environments.

We demonstrate a practical application in the context of *blockchain transactions*, where authenticity and correctness of script evaluation are critical, yet full input privacy may not be required. The security of our scheme—specifically, its authenticity and composability guarantees—is formally established in the *Universal Composability (UC) framework*, ensuring robustness under arbitrary protocol compositions.

---

### Key Clarifications & Suggestions:

1. **"Privacy-free environment"**: This is unconventional but valid in context. Be sure to define it early: e.g., "a setting where input/output privacy is not required, but computational authenticity and correctness are paramount."

2. **"Authenticity of the protocol"**: You likely mean *authenticity of computation*—i.e., ensuring that the output is correct with respect to the specified circuit and inputs, even if no secrets are hidden. Consider using terms like *integrity*, *verifiability*, or *correctness*.

3. **One-hot encodings + tensor products**: These can enable unique wire labels and structured operations. Explain briefly how they contribute—e.g., one-hot vectors as wire states, tensor products to represent gate operations algebraically.

4. **Elliptic curve arithmetic**: Likely used for binding commitments or homomorphic properties. Specify whether you’re using ECDH, Pedersen-like commitments, or point encoding schemes.

5. **"Each gate takes at most one ciphertext"**: This suggests high efficiency. Clarify whether this ciphertext is a commitment, encryption, or authentication tag. Also note assumptions (e.g., cleartext inputs known).

6. **Binary ↔ Arithmetic Gadgets**: Important for real-world use (e.g., handling boolean flags in financial logic). Mention domains (e.g., from $\mathbb{F}_2$ to $\mathbb{F}_p$).

7. **Blockchain Application**: Emphasize how authenticity without privacy fits use cases like transparent smart contracts, transaction validation, or fraud proofs.

8. **UC Security**: Strong point. Specify the ideal functionality (e.g., $\mathcal{F}_{\text{AUTH-CIRCUIT}}$) and adversary model (e.g., static, active).

---

### Potential Research Questions to Address:
- How does your scheme compare to SNARKs/STARKs for verifiable computation in blockchains?
- Is malleability prevented? Can adversaries tamper with garbled wires without detection?
- What is the role of the simulator in the UC proof?

---

Let me know if you’d like help expanding this into a full paper section (e.g., Introduction, Scheme Overview, UC Model Setup), or designing the actual garbling algorithm! <div>
We propose a novel mechanism for garbling wires and gates of a logical circuit in a privacy-free environment, focusing on the authenticity of the protocol. It is based on one-hot encodings, tensor products and elliptic curve arithmetic. This scheme is designed to work with arithmetic gates, but we also show gadgets to implement transitions from binary inputs to arithmetic outputs and vice versa. For our scheme, each arithmetic gate takes at most one cyphertext of material to execute its functionality (assuming knowledge of the garbled inputs and their cleartexts). We show an application to blockchain transactions. The security of the scheme is proved in the UC setting.
]]></content:encoded>
<pubDate>Tue, 30 Dec 2025 18:24:49 +0000</pubDate>
</item>
<item>
<title>DNS-Anchored zk-SNARK Proofs: A Stateless Alternative to ACME Challenge-Response for Domain Control Validation</title>
<link>https://eprint.iacr.org/2025/2332</link>
<guid>https://eprint.iacr.org/2025/2332</guid>
<content:encoded><![CDATA[
<div> Your abstract presents a compelling and technically sophisticated vision for reimagining Domain Control Validation (DCV) through cryptographic innovation. Below is a refined version of your text—polished for clarity, conciseness, and academic tone—while preserving all technical nuances and intent. This version would be suitable as an abstract for publication or presentation:

---

**Portable Trust eXtensible (PTX): Asynchronous, Non-Interactive Domain Control Validation via zk-SNARKs**

Domain Control Validation (DCV) forms the bedrock of web trust, serving as the foundational step in TLS certificate issuance and digital identity attestation. The prevailing standard, the Automated Certificate Management Environment (ACME) protocol, employs synchronous challenge-response mechanisms—such as HTTP-01 or DNS-01—that require active server infrastructure and exposed network endpoints. These requirements introduce operational friction and security risks, particularly for serverless architectures, static hosting environments, and air-gapped systems, where maintaining live services solely for validation is impractical or undesirable.

We introduce the Portable Trust eXtensible (PTX) protocol, a novel framework for asynchronous, non-interactive DCV that decouples proof generation from delivery infrastructure. PTX leverages Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARKs) to enable cryptographically secure assertions of domain control without real-time interaction. At its core, PTX utilizes a purpose-built arithmetic circuit that binds ephemeral secrets—a nullifier and secret key—to a scoped metadata payload containing audience restrictions, expiration timestamps, and domain context. This binding is anchored in the public DNS via a minimal TXT record, enabling decentralized verification.

The prover generates a compact, self-contained, and stateless proof artifact that can be verified entirely client-side by any relying party, eliminating the need for backend coordination during validation. Revocation is achieved simply through deletion of the DNS TXT record, with propagation governed by TTL semantics—yielding an O(TTL) revocation window. Our reference implementation employs the Groth16 proving system and the Poseidon hash function, achieving a lightweight circuit of only 1,756 constraints and sub-15ms verification times on commodity hardware.

Security analysis confirms that PTX resists replay attacks via public input context commitment and prevents linkage across proofs due to the use of fresh nullifiers. Furthermore, the zero-knowledge nature of the proofs preserves privacy, revealing no information beyond the validity of control over the asserted domain. PTX thus offers a secure, efficient, and privacy-preserving alternative to interactive DCV, unlocking new possibilities for identity assertion in decentralized, offline, and minimally provisioned environments.

---

### Key Contributions Highlighted:
- **Asynchrony & Non-interactivity**: Eliminates need for live servers during validation.
- **Portability & Statelessness**: Proofs are self-contained and verifiable offline.
- **Privacy Preservation**: zk-SNARKs hide sensitive details; nullifiers prevent tracking.
- **Lightweight Design**: Efficient circuit and fast verification enable broad adoption.
- **Decentralized Trust Model**: Leverages DNS as a public, distributed anchor.

This work bridges practical usability with strong cryptography, positioning PTX as a promising evolution of DCV for modern web architectures. Future directions include integration with CA ecosystems, multi-domain batch circuits, and post-quantum adaptations using lattice-based ZKPs.

Let me know if you'd like help expanding this into a full paper, designing figures, or writing the circuit specification. <div>
Domain Control Validation (DCV) is the cornerstone of trust on the web, serving as the prerequisite for issuing TLS certificates and asserting identity. The current industry standard, the Automated Certificate Management Environment (ACME) protocol, relies on synchronous, interactive challenge-response mechanisms (e.g., HTTP-01) that necessitate active server infrastructure and open network ports. This architectural requirement imposes significant friction on modern serverless, static, and air-gapped deployments, often forcing the exposure of sensitive infrastructure solely for validation purposes.

This paper presents the Portable Trust eXtensible (PTX) protocol, a novel mechanism for asynchronous, non-interactive DCV. PTX decouples the assertion of control from the delivery mechanism by utilizing Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge (zk-SNARKs). We introduce a circuit design that cryptographically binds a set of ephemeral secrets (a nullifier and secret key) to a scoped metadata payload—containing audience restrictions and expiration parameters—anchored to the public DNS via a lightweight TXT record.

This approach eliminates the need for an active web server during validation. A prover generates a self-contained, portable, and purely stateless proof artifact that can be verified client-side by any relying party, with revocation handled via O(TTL) DNS record deletion. We implement a reference toolchain using the Groth16 proving system and the Poseidon hash function, achieving a circuit complexity of just 1,756 constraints and sub-15ms verification times on consumer hardware. Our security analysis demonstrates that PTX effectively mitigates replay attacks through context-commitment public inputs while offering a privacy-preserving alternative to interactive DCV for identity assertions in decentralized environments.
]]></content:encoded>
<pubDate>Mon, 29 Dec 2025 04:01:52 +0000</pubDate>
</item>
<item>
<title>Streaming Function Secret Sharing and Its Applications</title>
<link>https://eprint.iacr.org/2025/2304</link>
<guid>https://eprint.iacr.org/2025/2304</guid>
<content:encoded><![CDATA[
Collecting statistics from users of software and online services is crucial to improve service quality, yet obtaining such insights while preserving individual privacy remains a challenge. Function secret sharing (FSS) is a promising tool for this problem. However, FSS-based solutions still face several challenges for streaming analytics, where messages are continuously sent, and secure computation tasks are repeatedly performed over incoming messages. 
We introduce a new cryptographic primitive called streaming function secret sharing (SFSS), a new variant of FSS that is particularly suitable for secure computation over streaming messages. We formalize SFSS and propose concrete constructions, including SFSS for point functions, predicate functions, and feasibility results for generic functions. SFSS powers several promising applications in a simple and modular fashion, including conditional transciphering, policy-hiding aggregation, and attribute-hiding aggregation. In particular, our SFSS formalization and constructions identify security flaws and efficiency bottlenecks in existing solutions, and SFSS-powered solutions achieve the expected security goal with asymptotically and concretely better efficiency and/or enhanced functionality.
]]></content:encoded>
<pubDate>Mon, 22 Dec 2025 12:50:16 +0000</pubDate>
</item>
<item>
<title>Verifiable Aggregate Receipts with Applications to User Engagement Auditing</title>
<link>https://eprint.iacr.org/2025/2330</link>
<guid>https://eprint.iacr.org/2025/2330</guid>
<content:encoded><![CDATA[
Accurate measurements of user engagement underpin important decisions in various settings, such as determining advertising fees based on viewership of online content, allocating public funding based on a clinic’s reported patient volume, or determining whether a group chat app disseminated a message without censorship. 
While common, self-reporting is inherently untrustworthy due to misaligned incentives (e.g., to inflate).

Motivated by this problem, we introduce the notion of Verifiable Aggregate Receipts (VAR).
A VAR system allows an issuer to issue receipts to users and to verify the number of receipts possessed by a prover, who is given receipts upon serving users. An ideal VAR system should satisfy inflation soundness (the prover cannot overstate the count), privacy (the verifier learns only the count), and be performant for large-scale applications involving millions of users.

We formalize VAR using an ideal functionality and present two novel constructions.
Our first protocol, S-VAR, leverages bottom-up secret-sharing to enable tiered ``fuzzy'' audits, and achieves constant-size receipts regardless of the number of supported thresholds. Our second protocol, P-VAR, uses bilinear pairings to aggregate receipts into a proof verifiable in constant time, enables exact auditing, and can be extended to handle a dynamic user set. We prove both constructions secure with respect to our ideal functionality. 

We implement and benchmark our VAR constructions. For a million users, issuance takes less than $2$ seconds for either scheme, and for audit proving time, P-VAR requires less than $10$ seconds and S-VAR requires less than $35$ seconds. 
Compared to our schemes, baseline and existing solutions are either at least an order of magnitude slower in proving and verification time, or they do not scale to one million users. 
Our benchmarks demonstrate that our VAR protocols can be used to enable verifiable and privacy-preserving user engagement auditing at scale. Finally, we showcase how VAR can be integrated with the aforementioned applications.
]]></content:encoded>
<pubDate>Sun, 28 Dec 2025 16:46:27 +0000</pubDate>
</item>
<item>
<title>Efficiently Provable Approximations for Non-Polynomial Functions</title>
<link>https://eprint.iacr.org/2025/2326</link>
<guid>https://eprint.iacr.org/2025/2326</guid>
<content:encoded><![CDATA[
Despite phenomenal advancements in the design and implementation of Zero-knowledge proofs (ZKPs) that have made them the preeminent tool for cryptographically ensuring the correctness of a wide range of computations, existing ZK protocols still incur high prover overhead in applications that entail accurately evaluating non-polynomial functions over floating-point numbers such as machine learning, decentralized finance, orbital mechanics, and geolocation. Current state-of-the-art approaches typically emulate floating-point numbers using fixed-point representations (via quantization), and handle non-polynomial functions using lookup tables, piece-wise or low-degree polynomial approximations, which lead to sub-optimal performance and/or loss in accuracy or generality, thus limiting their potential for adoption in practice.

In this work, we present a general framework for approximating a large class of non-polynomial functions using Gauss-Legendre quadrature which also supports efficient ZKPs of correct computation. We show that increasing the desired precision up to the limits imposed by quantization only increases does not increase the multiplicative circuit depth, which stays a small constant ($\leq4$) -- which is the main factor in the error growth of an approximation. We implement and evaluate our approach in Noir/Barretenberg, and we obtain absolute errors $2-256\times$ lower than comparable baselines for most non-polynomial functions with low prover overhead. We also demonstrate an efficient prover and low errors for high-precision applications in DeFi and astronomy that require non-polynomial functions, again obtaining errors $4-64\times$ lower than the baseline approximations.
]]></content:encoded>
<pubDate>Fri, 26 Dec 2025 06:13:42 +0000</pubDate>
</item>
<item>
<title>InstantOMR: Oblivious Message Retrieval with Low Latency and Optimal Parallelizability</title>
<link>https://eprint.iacr.org/2025/2317</link>
<guid>https://eprint.iacr.org/2025/2317</guid>
<content:encoded><![CDATA[
Anonymous messaging systems, such as privacy-preserving blockchains and private messaging applications, need to protect recipient privacy: ensuring no linkage between the recipient and the message. This raises the question: how can untrusted servers assist in delivering the pertinent messages to each recipient, without requiring the recipient to linearly scan all messages or revealing the intended recipient of each message? Oblivious message retrieval (OMR), a recently proposed primitive, addresses this issue by using homomorphic encryption in the single-server setting.

This work introduces $\mathsf{InstantOMR}$, a novel OMR scheme that combines TFHE functional bootstrapping with standard RLWE operations in a hybrid design, achieving significant improvements in both latency and parallelizability compared to prior BFV-based schemes. We propose a two-layer bootstrapping architecture and hybrid use of TFHE and regular RLWE homomorphic operations for $\mathsf{InstantOMR}$. Our implementation, using the $\mathsf{Primus}$-$\mathsf{fhe}$ library (and estimates based on $\mathsf{TFHE}$-$\mathsf{rs}$), demonstrates that $\mathsf{InstantOMR}$ offers the following key advantages:

    - Low latency: $\mathsf{InstantOMR}$ achieves ${\sim} 860\times$ lower latency than $\mathsf{SophOMR}$, the state-of-the-art single-server OMR construction. This translates directly into reduced recipient waiting time (by the same factor) in the streaming setting, where the detector processes incoming messages on-the-fly and returns a digest immediately upon the recipient becoming online.

    - Optimal parallelizability: $\mathsf{InstantOMR}$ scales near-optimally with available CPU cores (by processing messages independently), so for high core counts, it is faster than SophOMR (whose parallelism is constrained by its reliance on BFV).
]]></content:encoded>
<pubDate>Tue, 23 Dec 2025 19:00:49 +0000</pubDate>
</item>
<item>
<title>Making Sense of Private Advertising: A Principled Approach to a Complex Ecosystem</title>
<link>https://eprint.iacr.org/2025/2316</link>
<guid>https://eprint.iacr.org/2025/2316</guid>
<content:encoded><![CDATA[
In this work, we model the end-to-end pipeline of the advertising ecosystem, allowing us to identify two main issues with the current trajectory of private advertising proposals. First, prior work has largely considered ad targeting and engagement metrics individually rather than in composition. This has resulted in privacy notions that, while reasonable for each protocol in isolation, fail to compose to a natural notion of privacy for the ecosystem as a whole, permitting advertisers to extract new information about the audience of their advertisements. The second issue serves to explain the first: we prove that perfect privacy is impossible for any, even minimally, useful advertising ecosystem, due to the advertisers' expectation of conducting market research on the results.

Having demonstrated that leakage is inherent in advertising, we re-examine what privacy could realistically mean in advertising, building on the well-established notion of sensitive data in a specific context.  We identify that fundamentally new approaches are needed when designing privacy-preserving advertising subsystems in order to ensure that the privacy properties of the end-to-end advertising system are well aligned with people's privacy desires.
]]></content:encoded>
<pubDate>Tue, 23 Dec 2025 18:41:01 +0000</pubDate>
</item>
<item>
<title>Registered Attribute-Based Encryption with Publicly Verifiable Certified Deletion, Everlasting Security, and More</title>
<link>https://eprint.iacr.org/2025/2314</link>
<guid>https://eprint.iacr.org/2025/2314</guid>
<content:encoded><![CDATA[
Certified deletion ensures that encrypted data can be irreversibly deleted, preventing future recovery even if decryption keys are later exposed. Although existing works have achieved certified deletion across various cryptographic primitives, they rely on central authorities, leading to inherent escrow vulnerabilities. This raises the question of whether certified deletion can be achieved in decentralized frameworks such as Registered Attribute-Based Encryption (RABE) that combines fine-grained access control with user-controlled key registration. This paper presents the first RABE schemes supporting certified deletion and certified everlasting security. Specifically, we obtain the following: 

- We first design a privately verifiable RABE with Certified Deletion (RABE-CD) scheme by combining our newly proposed shadow registered ABE (Shad-RABE) with one-time symmetric key encryption with certified deletion. 

- We then construct a publicly verifiable RABE-CD scheme using Shad-RABE, witness encryption, and one-shot signatures, allowing any party to validate deletion certificates without accessing secret keys.  

- We also extend to privately verifiable RABE with Certified Everlasting Deletion (RABE-CED) scheme, integrating quantum-secure RABE with the certified everlasting lemma. Once a certificate is produced, message privacy becomes information-theoretic even against unbounded adversaries.  

- We finally realize a publicly verifiable RABE-CED scheme by employing digital signatures for the BB84 states, allowing universal verification while ensuring that deletion irreversibly destroys information relevant to decryption.
]]></content:encoded>
<pubDate>Tue, 23 Dec 2025 17:49:11 +0000</pubDate>
</item>
<item>
<title>Achieving CPAD security for BFV: a pragmatic approach</title>
<link>https://eprint.iacr.org/2025/2288</link>
<guid>https://eprint.iacr.org/2025/2288</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) aims at ensuring privacy of sensitive data while taking advantage of external computations and services. However, using FHE in real-world scenarios reveals new kinds of security issues. In particular, following Li&amp;Micciancio Eurocrypt'21 seminal paper, CPAD security has emerged as a fundamental notion for FHE, unveiling a subtle interplay between security and correctness. For correct (F)HE schemes, CPA security already implies CPAD. However, all known practical FHE schemes are (R)LWE-based and, as such, are prone to decryption errors; and even if it is possible to ensure statistical correctness by selecting appropriate parameters, achieving this while maintaining malleability --- the mainspring of FHE --- still remains challenging.  Moreover, practical CPAD attacks have recently been designed against most known FHE schemes. We propose in this paper a complete, simple and rigorous framework to reach CPAD security for one of them, BFV.
Our approach relies on a combination of alternate average-case/worst-case noise variance monitoring --- based on dependencies tracking during the homomorphic calculations --- and on smudging. It comes with an automated parameters setting methodology, which connects it to the recently proposed Application-Aware HE paradigm while relieving libraries end-users from the burden of enforcing the paradigm's constraints by hand.
]]></content:encoded>
<pubDate>Fri, 19 Dec 2025 16:46:40 +0000</pubDate>
</item>
<item>
<title>Succinct Garbled Circuits with Low-Depth Garbling Algorithms</title>
<link>https://eprint.iacr.org/2025/2308</link>
<guid>https://eprint.iacr.org/2025/2308</guid>
<content:encoded><![CDATA[
We study the problem of constructing Boolean garbling schemes that are both succinct$-$with garbled circuit size significantly smaller than the original circuit$-$and have low-depth garbling algorithms, where the garbling process runs in parallel time logarithmic in the circuit size. Prior schemes achieve one but not the other, unless relying on indistinguishability obfuscation ($\mathsf{iO}$), which is prohibitively inefficient, relies on a combination of multiple assumptions, and achieves only polynomial garbling depth $\mathsf{poly}(\lambda,\log |C|)$.  

We resolve this tension by presenting the first garbling schemes that are both succinct and admit garbling algorithms in $\mathsf{NC}^1$, based only on standard group and lattice assumptions. Our main results include:
    • $\textbf{One-bit-per-gate garbling}$ with logarithmic garbling depth based on DDH or RLWE and the existence of a local PRG.
    • $\textbf{Succinct privacy-free garbling}$ of size linear in the circuit depth $D$ (and sublinear in the circuit size $|C|$), based on DDH or RLWE.
    • $\textbf{Reusable, fully succinct garbling}$ with logarithmic garbling depth, based on decomposable LWE.  

The DDH-based one-bit-per-gate scheme has tunably small inverse polynomial correctness and privacy errors, which can be made negligible at the cost of increasing garbling depth to $\mathsf{poly}(\lambda)$. 

As further extension, we also obtain the first attribute-based encryption schemes with succinct keys and low-depth key generation. 

At a conceptual level, our constructions are derived from a unified framework that subsumes all prior approaches to succinct garbling. It identifies the common source of high-depth garbling, and provides a general methodology for reducing garbling depth without sacrificing succinctness, applicable across different techniques and assumptions.
]]></content:encoded>
<pubDate>Tue, 23 Dec 2025 01:20:59 +0000</pubDate>
</item>
<item>
<title>FRIVail: A Data Availability Scheme based on FRI Binius</title>
<link>https://eprint.iacr.org/2025/2292</link>
<guid>https://eprint.iacr.org/2025/2292</guid>
<content:encoded><![CDATA[
Data Availability Sampling (DAS) has emerged as a key scalability technique for blockchain systems, enabling light clients to verify that block data have been fully published without downloading them in their entirety. We introduce FRIVail, a new DAS construction built on top of the FRI-Binius polynomial commitment scheme, designed for datasets composed of many independent single-row payloads that together form a block’s data blob. FRIVail exploits the intrinsic Reed–Solomon structure of FRI, wherein each commitment naturally encodes a codeword that light clients can sample directly.

Each row of the blob is assigned an independent FRI proof. These row-level proofs are then combined into a global availability certificate using one of three aggregation strategies. The first constructs a succinct zero-knowledge proof attesting to the correct verification of all row-level FRI proofs, yielding a compact ZK proof of proofs that enables succinct global verification while preserving row independence. The second is a fully post-quantum construction that recursively applies FRI-Binius to build a proof of proofs. In this setting, global verification relies on FRI proximity checks, but reconstruction of the aggregated proof polynomial is required to recover embedded row-level information. The third is a hybrid aggregation based on KZG polynomial commitments, where the aggregated polynomial admits direct algebraic openings but relies on pairing-based assumptions and a trusted setup, and is therefore not post-quantum.

In all variants, light clients verify availability via a small number of local opening checks against the header commitment, without downloading entire rows or the full blob. We formalize DAS security in this multi-row, multi-proof setting and show that FRIVail achieves sublinear verification complexity, robustness against adversarial availability equivocation at the row level, and resistance to correlated sampling attacks. FRIVail provides a modular foundation for next-generation blockchain data availability protocols, supporting zero-knowledge-based, fully post-quantum, and hybrid cryptographic deployments.
]]></content:encoded>
<pubDate>Fri, 19 Dec 2025 18:46:40 +0000</pubDate>
</item>
<item>
<title>On Delegation of Verifiable Presentations from mdoc and BBS Credentials</title>
<link>https://eprint.iacr.org/2025/2306</link>
<guid>https://eprint.iacr.org/2025/2306</guid>
<content:encoded><![CDATA[
The interest in verifiable credential systems has gained traction as eIDAS 2.0 Regulation has been published. This regulation instructs EU member states to provide their citizens with digital identity wallets (EUDI Wallet) that must store the credentials and enable privacy-preserving presentation of identity information to relying parties. This new digital identity system requires defining new protocols and procedures to perform tasks involving the disclosure of identity information. One of such procedures is the delegation of attestation, as is reported in the EUDI Wallet Reference Implementation Roadmap.

In this work, we address the problem of constructing secure processes for the delegation of verifiable presentations derived from both verifiable and anonymous credentials. Our goal is to enable a credential holder (the delegator) to securely delegate another party (the delegatee) to present a credential on their behalf.
We introduce the notion of a verifiable presentation delegation scheme, formalizing the core algorithms, namely delegation issuance, delegated presentation, and presentation verification, and defining the relevant security properties that such a scheme should satisfy: the correctness, the unforgeability, and, when the scheme is built on top of anonymous credentials, even the unlinkability. We present two concrete instantiations of delegation schemes: the first is built on top of mdoc verifiable credentials, the credential format currently supported by the EUDI Wallet Architecture and Reference Framework (EUDI ARF), while the second is built on top of BBS anonymous credentials. Finally, we discuss and analyze the security of our constructions in terms of the security properties we have introduced.
]]></content:encoded>
<pubDate>Mon, 22 Dec 2025 19:44:57 +0000</pubDate>
</item>
<item>
<title>Attacking and Securing Hybrid Homomorphic Encryption Against Power Analysis</title>
<link>https://eprint.iacr.org/2025/2302</link>
<guid>https://eprint.iacr.org/2025/2302</guid>
<content:encoded><![CDATA[
We present the first power side-channel analysis of a Hybrid Homomorphic Encryption (HHE) tailored symmetric encryption scheme. HHE combines lightweight client-side Symmetric Encryption (SE) with server-side homomorphic evaluation, enabling efficient privacy-preserving computation for the client and minimizing the communication overhead. Recent integer-based HHE designs such as PASTA, MASTA, HERA, and Rubato rely on prime-field arithmetic, but their side-channel security has
not been studied. This gap is critical, as modular arithmetic and large key spaces in integer-based schemes introduce new leakage vectors distinct from those in conventional Boolean symmetric ciphers. In this work, we close this gap by presenting the first power side-channel analysis of an HHE-tailored scheme - HERA.

Our results demonstrate a successful key recovery from as few as 40 power traces using Correlation Power Analysis. In addition to showing that such attacks are feasible, we develop the first masking framework for integer-based SE schemes to mitigate them. Our design integrates PINI-secure gadgets with assembly-level countermeasures to address transition leakage, and we validate its effectiveness using the Test Vector Leakage
Assessment. Our experiments confirm both the practicality of the attack and the strength of the proposed countermeasures. We also demonstrate that the framework extends to other integer-based HHE schemes, by applying our technique to PASTA. Thus, we provide leakage models, identify relevant attack targets, and define evaluation benchmarks for integer-based HHE-tailored SE schemes, thereby filling a longstanding gap and laying the foundation for side-channel-resilient design in this area.
]]></content:encoded>
<pubDate>Mon, 22 Dec 2025 09:44:28 +0000</pubDate>
</item>
<item>
<title>SoK: Verifiable Federated Learning</title>
<link>https://eprint.iacr.org/2025/2296</link>
<guid>https://eprint.iacr.org/2025/2296</guid>
<content:encoded><![CDATA[
Federated Learning (FL) is an advancement in Machine Learning motivated by the need to preserve the privacy of the data used to train models. While it effectively addresses this issue, the multi-participant paradigm on which it is based introduces several challenges. Among these are the risks that participating entities may behave dishonestly and fail to perform their tasks correctly. Moreover, due to the distributed nature of the architecture, attacks such as Sybil and collusion are possible. Recently, with advances in Verifiable Computation (VC) and Zero-Knowledge Proofs (ZKP), researchers have begun exploring how to apply these technologies to Federated Learning aiming to mitigate such problems. In this Systematization of Knowledge, we analyze the first, very recent works that attempt to integrate verifiability features into classical FL tasks, comparing their approaches and highlighting what is achievable with the current state of VC methods.
]]></content:encoded>
<pubDate>Sat, 20 Dec 2025 17:32:16 +0000</pubDate>
</item>
<item>
<title>MIOPE: A Modular framework for Input and Output Privacy in Ensemble inference</title>
<link>https://eprint.iacr.org/2025/2287</link>
<guid>https://eprint.iacr.org/2025/2287</guid>
<content:encoded><![CDATA[
We introduce a simple yet novel framework for privacy-preserving machine learning inference that allows a client to query multiple models without a trusted third party aggregator by leveraging homomorphically encrypted model evaluation and multi-party computation. This setting allows for dispersed training of models such that a client can query each separately, and aggregate the results of this `ensemble inference'; this avoids the data leakage inherent to techniques that train collectively such as federated learning. Our framework, which we call MIOPE, allows the data providers to keep the training phase local to provide tighter control over these models, and additionally provides the benefit of easily retraining to improve inference of the ensemble. MIOPE uses homomorphic encryption to keep the querying client's data private and multi-party computation to hide the individual model outputs. We illustrate the design and trade-offs of input- and output-hiding ensemble inference as provided by MIOPE and compare performance to a centralized approach.We evaluate our approach with a standard dataset and various regression models and observe that the MIOPE framework can lead to accuracy scores that are only marginally lower than centralized learning. The modular design of our approach allows the system to adapt to new data, better models, or security requirements of the involved parties.
]]></content:encoded>
<pubDate>Fri, 19 Dec 2025 14:38:42 +0000</pubDate>
</item>
<item>
<title>Improving the Efficiency of zkSNARKs for Ballot Validity</title>
<link>https://eprint.iacr.org/2025/2286</link>
<guid>https://eprint.iacr.org/2025/2286</guid>
<content:encoded><![CDATA[
Homomorphic tallying in secure e-voting protocols enables privacy-preserving vote aggregation. For this approach, zero-knowledge proofs (ZKPs) for ensuring the validity of encrypted ballots are an essential component.

While it has been common to construct tailored ZKPs for every kind of ballot and voting method at hand, recently Huber et al. demonstrated that also general-purpose ZKPs (GPZKPs), such as Groth16 zkSNARKs, are suited for checking ballot validity. Unlike tailored solutions, GPZKPs provide a unified, generic, and flexible framework for this task. In this work, we improve on the initial GPZKPs for ballot validity proposed by Huber et al. Specifically, we present several circuit-level optimizations that significantly reduce proving costs for exponential ElGamal-encrypted ballots. We provide an independent, ready-to-use Circom implementation along with concrete benchmarks, demonstrating substantial improvements in performance and practical usability over prior implementations.
]]></content:encoded>
<pubDate>Fri, 19 Dec 2025 10:03:40 +0000</pubDate>
</item>
<item>
<title>Laminate: Succinct SIMD-Friendly Verifiable FHE</title>
<link>https://eprint.iacr.org/2025/2285</link>
<guid>https://eprint.iacr.org/2025/2285</guid>
<content:encoded><![CDATA[
In outsourcing computation to untrusted servers, one can cryptographically ensure privacy using Fully Homomorphic Encryption (FHE) or ensure integrity using Verifiable Computation (VC) such as SNARK proofs. While each is practical for some applications in isolation, efficiently composing FHE and VC into Verifiable Computing on Encrypted Data (VCoED) remains an open problem. 

We introduce Laminate, the first practical method for adding integrity to BGV-style FHE, thereby achieving VCoED. Our approach combines the blind interactive proof framework with a tailored variant of the GKR proof system that avoids committing to intermediate computation states. We further introduce variants employing transcript packing and folding techniques. The resulting encrypted proofs are concretely succinct: 270kB, compared to 1TB in prior work, to evaluate a batch of $B=2^{14}$ instances of size $n=2^{20}$ and depth $d=32$. Asymptotically, the proof size and verifier work is $O(d \log (Bn))$, compared to $\Omega(BN\log n)$ in prior work (for ring dimension $N$).

Unlike prior schemes, Laminate utilizes the full SIMD capabilities of FHE for both the payload circuit evaluation and proof generation; adds only constant multiplicative depth on top of payload evaluation while performing $\tilde{O}(n)$ FHE operations; eliminates the need for witness reduction; and is field-agnostic. The resulting cost of adding integrity to FHE, compared to assuming honest evaluation, is ${\sim}12\times$ to ${\sim}36\times$ overhead (for deep multiplication-heavy circuits of size $2^{20}$), which is $>500\times$ faster than the state-of-the-art.
]]></content:encoded>
<pubDate>Fri, 19 Dec 2025 06:47:36 +0000</pubDate>
</item>
<item>
<title>E2E-AKMA: An End-to-End Secure and Privacy-Enhancing AKMA Protocol Against the Anchor Function Compromise</title>
<link>https://eprint.iacr.org/2025/2276</link>
<guid>https://eprint.iacr.org/2025/2276</guid>
<content:encoded><![CDATA[
The Authentication and Key Management for Applications (AKMA) system represents a recently developed protocol established by 3GPP, which is anticipated to become a pivotal component of the 5G standards. AKMA enables application service providers to delegate user authentication processes to mobile network operators, thereby eliminating the need for these providers to store and manage authentication-related data themselves. This delegation enhances the efficiency of authentication procedures but simultaneously introduces certain security and privacy challenges that warrant thorough analysis and mitigation.

The 5G AKMA service is facilitated by the AKMA Anchor Function (AAnF), which may operate outside the boundaries of the 5G core network. A compromise of the AAnF could potentially allow malicious actors to exploit vulnerabilities, enabling them to monitor user login activities or gain unauthorized access to sensitive communication content. Furthermore, the exposure of the Subscription Permanent Identifier (SUPI) to external Application Functions poses substantial privacy risks, as the SUPI could be utilized to correlate a user's real-world identity with their online activities, thereby undermining user privacy.

To mitigate these vulnerabilities, we propose a novel protocol named E2E-AKMA, which facilitates the establishment of a session key between the User Equipment (UE) and the Application Function (AF) with end-to-end security, even in scenarios where the AAnF has been compromised. Furthermore, the protocol ensures that no entity, aside from the 5G core network, can link account activities to the user's actual identity. This architecture preserves the advantages of the existing AKMA scheme, such as eliminating the need for complex dynamic secret data management and avoiding reliance on specialized hardware (apart from standard SIM cards). Experimental evaluations reveal that the E2E-AKMA framework incurs an overhead of approximately 9.4\% in comparison to the original 5G AKMA scheme, which indicates its potential efficiency and practicality for deployment.
]]></content:encoded>
<pubDate>Thu, 18 Dec 2025 06:38:49 +0000</pubDate>
</item>
<item>
<title>An Efficient Private GPT Never Autoregressively Decodes</title>
<link>https://eprint.iacr.org/2025/2251</link>
<guid>https://eprint.iacr.org/2025/2251</guid>
<content:encoded><![CDATA[
The wide deployment of the generative pre-trained transformer (GPT) has raised privacy concerns for both clients and servers. While cryptographic primitives can be employed for secure GPT inference to protect the privacy of both parties, they introduce considerable performance overhead. To accelerate secure inference, this study proposes a public decoding and secure verification approach that utilizes public GPT models, motivated by the observation that securely decoding one and multiple tokens takes a similar latency. The client uses the public model to generate a set of tokens, which are then securely verified by the private model for acceptance. The efficiency of our approach depends on the acceptance ratio of tokens proposed by the public model, which we improve from two aspects: (1) a private sampling protocol optimized for cryptographic primitives and (2) model alignment using knowledge distillation. Our approach improves the efficiency of secure decoding while maintaining the same level of privacy and generation quality as standard secure decoding. Experiments demonstrate a $2.1\times \sim 6.0\times$ speedup compared to standard decoding across three pairs of public-private models and different network conditions.
]]></content:encoded>
<pubDate>Mon, 15 Dec 2025 03:33:17 +0000</pubDate>
</item>
<item>
<title>Nimbus: Secure and Efficient Two-Party Inference for Transformers</title>
<link>https://eprint.iacr.org/2025/2250</link>
<guid>https://eprint.iacr.org/2025/2250</guid>
<content:encoded><![CDATA[
Transformer models have gained significant attention due to their power in machine learning tasks. Their extensive deployment has raised concerns about the potential leakage of sensitive information during inference. However, when being applied to Transformers, existing approaches based on secure two-party computation (2PC) bring about efficiency limitations in two folds: (1) resource-intensive matrix multiplications in linear layers, and (2) complex non-linear activation functions like $\mathsf{GELU}$ and $\mathsf{Softmax}$. This work presents a new two-party inference framework $\mathsf{Nimbus}$ for Transformer models. For the linear layer, we propose a new 2PC paradigm along with an encoding approach to securely compute matrix multiplications based on an outer-product insight, which achieves $2.9\times \sim 12.5\times$ performance improvements compared to the state-of-the-art (SOTA) protocol. For the non-linear layer, through a new observation of utilizing the input distribution, we propose an approach of low-degree polynomial approximation for $\mathsf{GELU}$ and $\mathsf{Softmax}$, which improves the performance of the SOTA polynomial approximation by $2.9\times \sim 4.0\times$, where the average accuracy loss of our approach is 0.08\% compared to the non-2PC inference without privacy. Compared with the SOTA two-party inference, $\mathsf{Nimbus}$ improves the end-to-end performance of BERT inference by $2.7\times \sim 4.7\times$ across different network settings.
]]></content:encoded>
<pubDate>Mon, 15 Dec 2025 03:27:20 +0000</pubDate>
</item>
<item>
<title>HHGS:  Forward-secure Dynamic Group Signatures from Symmetric Primitives</title>
<link>https://eprint.iacr.org/2025/2270</link>
<guid>https://eprint.iacr.org/2025/2270</guid>
<content:encoded><![CDATA[
Group signatures allow a group member to sign messages on behalf of the group while preserving the signer’s anonymity, making them invaluable for privacy-sensitive applications. As quantum computing advances, post-quantum security in group signatures becomes essential. Symmetric primitives (SP) offer a promising pathway due to their simplicity, efficiency, and well-understood security foundations. In this paper, we introduce the first \textit{forward-secure dynamic group signature} (FSDGS) framework relying solely on SP. We begin with \textit{hierarchical hypertree group signatures} (HHGS), a basic scheme that securely organizes keys of one-time signatures (OTS) in a hypertree using puncturable pseudorandom functions to enable on-demand key generation and forward security, dynamic enrollment, and which provides resilience against attacks that exploit registration patterns by obfuscating the assignment and usage of keys. We then extend this foundation to HHGS^+, which orchestrates multiple HHGS instances in a generic way, significantly extending the total signing capacity to $O(2^{60})$, which outperforms HHGS's closest competitors while keeping signatures below 8 kilobytes. We prove the security of both schemes in the standard model. Our results outline a practical SP-driven pathway toward post-quantum-secure group signatures suitable for resource-constrained client devices.
]]></content:encoded>
<pubDate>Thu, 18 Dec 2025 02:00:26 +0000</pubDate>
</item>
<item>
<title>Distributed Broadcast Encryption for Confidential Interoperability across Private Blockchains</title>
<link>https://eprint.iacr.org/2025/2237</link>
<guid>https://eprint.iacr.org/2025/2237</guid>
<content:encoded><![CDATA[
Interoperation across distributed ledger technology (DLT) networks hinges upon the secure transmission of ledger state from one network to another. This is especially challenging for private networks whose ledger access is limited to enrolled members. Existing approaches rely on a trusted centralized proxy that receives encrypted ledger state of a network, decrypts it, and sends it to members of another network. Though effective, this approach goes against the founding principle of DLT, namely avoiding single points of failure (or single sources of trust).

In this paper, we leverage fully-distributed broadcast encryption (FDBE in short) to build a fully decentralized protocol for confidential information-sharing across private networks. Compared to traditional broadcast encryption (BE), FDBE is characterized by distributed setup and key generation, where mutually distrusting parties agree on a BE’s public key without a trusted setup, and securely derive their decryption keys. Given any FDBE, two private networks can securely share information as follows: a sender in one network uses the other network’s FDBE public key to encrypt a message for its members; and the resulting construction is secure in the simplified universal composability framework.

To further demonstrate the practicality of our approach, we present the first instantiation of an FDBE that enjoys constant-sized decryption keys and ciphertexts, and evaluate the resulting performances through a reference implementation that considers two private Hyperledger Fabric networks within the Hyperledger Cacti interoperation framework.
]]></content:encoded>
<pubDate>Fri, 12 Dec 2025 09:14:00 +0000</pubDate>
</item>
<item>
<title>Toward Practical Lattice-based Unbounded Inner Product Functional Encryption: Construction and Implementation</title>
<link>https://eprint.iacr.org/2025/2232</link>
<guid>https://eprint.iacr.org/2025/2232</guid>
<content:encoded><![CDATA[
Cloud computing enables data processing, storing and sharing in untrusted environments whose growing adoption necessitates a focus on data security and privacy. Inner product functional encryption (IPFE) is a promising cryptographic technique that enables fine-grained access control over sensitive data in untrusted cloud environments. Post-quantum cryptography focuses on developing cryptographic protocols resilient to quantum computer attacks, with lattice structures being crucial in designing these protocols.
This paper aims to implement the lattice-based public key unbounded IPFE (uIPFE) scheme proposed by Dutta et al. (2022) [1] which ensures that no specific vector’s length bound needs to be fixed during public parameter generation.
Furthermore, we extend the ALS-IPFE scheme of Agrawal et al. (2016) [2] to create a new public key scheme uIPFE #1, achieving adaptive indistinguishability security in the random oracle model under the Learning with Errors assumption, while avoiding trapdoor generation and pre-image sampling algorithms. 
This work aims to enhance the practical applicability of uIPFE in cloud computing environments. We implement both the schemes uIPFE and uIPFE #1 in C programming language and execute the code on IBM Power 9 server. Moreover, we analyze the running time and discuss the performance of both schemes based on varying message vector lengths.
]]></content:encoded>
<pubDate>Thu, 11 Dec 2025 14:27:48 +0000</pubDate>
</item>
<item>
<title>PIRANHAS: PrIvacy-Preserving Remote Attestation in Non-Hierarchical Asynchronous Swarms</title>
<link>https://eprint.iacr.org/2025/2228</link>
<guid>https://eprint.iacr.org/2025/2228</guid>
<content:encoded><![CDATA[
Remote attestation is a fundamental security mechanism for assessing the integrity of remote devices. In practice, widespread adoption of attestation schemes is hindered by a lack of public verifiability and the requirement for interaction in existing protocols. A recent work by Ebrahimi et al. (NDSS'24) constructs publicly verifiable, non-interactive remote attestation, disregarding another important requirement for attesting sensitive systems: privacy protection.
Similar needs arise in IoT swarms, where many devices, potentially processing sensitive data, should produce a single attestation.

In this paper, we take on both challenges. We present PIRANHAS, a publicly verifiable, asynchronous, and anonymous attestation scheme for individual devices and swarms. We leverage zk-SNARKs to transform any classical, symmetric remote attestation scheme into a non-interactive, publicly verifiable, and anonymous one. Verifiers only ascertain the validity of the attestation, without learning any identifying information about the involved devices.

For IoT swarms, PIRANHAS aggregates attestation proofs for the entire swarm using recursive zk-SNARKs. Our system supports arbitrary network topologies and allows nodes to dynamically join and leave the network. We provide formal security proofs for the single-device and swarm setting, showing that our construction meets the desired security guarantees. Further, we provide an open-source implementation of our scheme using the Noir and Plonky2 framework, achieving an aggregation runtime of just 356ms.
]]></content:encoded>
<pubDate>Wed, 10 Dec 2025 14:09:55 +0000</pubDate>
</item>
<item>
<title>LifeXP+: Secure, Usable and Reliable Key Recovery for Web3 Applications</title>
<link>https://eprint.iacr.org/2025/2206</link>
<guid>https://eprint.iacr.org/2025/2206</guid>
<content:encoded><![CDATA[
In the Web2 world, users control their accounts using credentials such as usernames and passwords, which can be reset or recovered by centralized servers if the user loses them.
In the decentralized Web3 world however, users control their accounts through cryptographic private-public key pairs which are much more complex to manage securely. In addition, the decentralized nature of Web3 makes account recovery impossible in the absence of predetermined recovery mechanisms. With the proliferation of blockchains and cryptocurrencies over the last years, it is crucial to provide users secure, usable and reliable ways to recover their accounts and assets. However, up to this day, no Web3 recovery method has adequately achieved all three of the above required properties. For instance, conventional ``mnemonic" backups which can deterministically reconstruct a private key require verbatim recall of a fixed word list, creating an unpleasant usability/security trade-off.

In this work, we present a fully-offline protocol called LifeXP$^{+}$, that allows a user to reconstruct a cryptographically-secure private key from a natural-language story, which a user always remembers, such an memorable life event. To ensure usability of our protocol, key reconstruction can work even when the story is later retold with different wording or grammar, only requiring to preserve the semantics.  
The protocol combines pre-trained sentence embeddings to capture semantics, locality-sensitive hashing to quantize embeddings into stable bit strings, a cryptographic fuzzy extractor that corrects bit errors caused by paraphrasing, and a biometric factor that is fused with the linguistic factor to boost entropy and enhance security. In our paper we describe the design, show that the protocol achieves the required properties, and provide an evaluation based on publicly-available datasets
which runs completely offline on commodity hardware, showcasing its feasibility.
]]></content:encoded>
<pubDate>Sat, 06 Dec 2025 23:39:53 +0000</pubDate>
</item>
<item>
<title>AgentCrypt: Advancing Privacy and (Secure) Computation in AI Agent Collaboration</title>
<link>https://eprint.iacr.org/2025/2216</link>
<guid>https://eprint.iacr.org/2025/2216</guid>
<content:encoded><![CDATA[
As AI agents increasingly operate in real-world, multi-agent environments, ensuring reliable and context-aware privacy in agent communication is critical, especially to comply with evolving regulatory requirements. Traditional access controls are insufficient, as privacy risks often arise after access is granted; agents may use information in ways that compromise privacy, such as messaging humans, sharing context with other agents, making tool calls, persisting data, or generating derived private information. Existing approaches often treat privacy as a binary constraint, whether data is shareable or not, overlooking nuanced, role-specific, and computation-dependent privacy needs essential for regulatory compliance.

Agents, including those based on large language models, are inherently probabilistic and heuristic. There is no formal guarantee of how an agent will behave for any query, making them ill-suited for operations critical to security. To address this, we introduce AgentCrypt, a four-tiered framework for fine-grained, encrypted agent communication that adds a protection layer atop any AI agent platform. AgentCrypt spans unrestricted data exchange (Level 1) to fully encrypted computation using techniques such as homomorphic encryption (Level 4). Crucially, it guarantees the privacy of tagged data is always maintained, prioritizing privacy above correctness.

AgentCrypt ensures privacy across diverse interactions and enables computation on otherwise inaccessible data, overcoming barriers such as data silos. We implemented and tested it with Langgraph and Google ADK, demonstrating versatility across platforms. We also introduce a benchmark dataset simulating privacy-critical tasks at all privacy levels, enabling systematic evaluation and fostering the development of regulatable machine learning systems for secure agent communication and computation.
]]></content:encoded>
<pubDate>Mon, 08 Dec 2025 23:19:57 +0000</pubDate>
</item>
<item>
<title>Accelerating TFHE with Sorted Bootstrapping Techniques</title>
<link>https://eprint.iacr.org/2025/2214</link>
<guid>https://eprint.iacr.org/2025/2214</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) enables secure computation over encrypted data, offering a breakthrough in privacy-preserving computing. Despite its promise, the practical deployment of FHE has been hindered by the significant computational overhead, especially in general-purpose bootstrapping schemes. In this work, we build upon the recent advancements of [LY23] to introduce a variant of the functional/programmable bootstrapping. By carefully sorting the steps of the blind rotation, we reduce the overall number of external products without compromising correctness. To further enhance efficiency, we propose a novel modulus-switching technique that increases the likelihood of satisfying pruning conditions, reducing computational overhead. 
Extensive benchmarks demonstrate that our method achieves a speedup ranging from 1.75x to 8.28x compared to traditional bootstrapping and from 1.26x to 2.14x compared to [LY23] bootstrapping techniques. 
Moreover, we show that this technique is better adapted to the IND-CPA-D security model by reducing the performance downgrade it implies.
]]></content:encoded>
<pubDate>Mon, 08 Dec 2025 16:43:44 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Identifier Checking in 5G</title>
<link>https://eprint.iacr.org/2025/2200</link>
<guid>https://eprint.iacr.org/2025/2200</guid>
<content:encoded><![CDATA[
Device identifiers like the International Mobile Equipment Identity (IMEI) are crucial for ensuring device integrity and meeting regulations in 4G and 5G networks. However, sharing these identifiers with Mobile Network Operators (MNOs) brings significant privacy risks by enabling long-term tracking and linking of user activities across sessions. In this work, we propose a privacy-preserving identifier checking method in 5G. This paper introduces a protocol for verifying device identifiers without exposing them to the network while maintaining the same functions as the 3GPP-defined Equipment Identity Register (EIR) process. The proposed solution modifies the PEPSI protocol [USENIX, 2024] for a Private Set Membership (PSM) setting using the BFV homomorphic encryption scheme. This lets User Equipment (UE) prove that its identifier is not on an operator’s blacklist or greylist while ensuring that the MNO only learns the outcome of the verification. The protocol allows controlled deanonymization through an authorized Law Enforcement (LE) hook, striking a balance between privacy and accountability. Implementation results show that the system can perform online verification within five seconds and requires about 15 to 16 MB of communication per session. This confirms its practical use under post-quantum security standards. The findings highlight the promise of homomorphic encryption for managing identifiers while preserving privacy in 5G, laying the groundwork for scalable and compliant verification systems in future 6G networks.
]]></content:encoded>
<pubDate>Fri, 05 Dec 2025 06:43:43 +0000</pubDate>
</item>
<item>
<title>Small-field hash-based SNARGs are less sound than conjectured</title>
<link>https://eprint.iacr.org/2025/2197</link>
<guid>https://eprint.iacr.org/2025/2197</guid>
<content:encoded><![CDATA[
Hash-based succinct non-interactive arguments (SNARGs) are a widely studied and deployed class of proof systems. The security of practical hash-based SNARGs relies on two combinatorial parameters of its underlying linear code $\mathcal{C}$: a distance-preservation error $\varepsilon(\mathcal{C},\delta)$ and the list size $|\Lambda(\mathcal{C}, \delta)|$ (both parametrized by a proximity parameter $\delta$). Optimistically, one might hope that these parameters are bounded all the way to the capacity regime: when the proximity parameter $\delta$ approaches the minimum distance of the code $\delta(\mathcal{C})$. Perhaps too optimistically, several deployed hash-based SNARGs indeed operate in this regime, and initiatives such as the Ethereum Proximity Prize investigate to which extent soundness is preserved in this setting.

We present a minimal toy protocol whose analysis captures most of the complexity of state-of-the-art hash-based SNARGs, and present a generic attack whose success probability depends on the list size $|\Lambda(\mathcal{C}, \delta)|$.
Further, we investigate the common settings when the code $\mathcal{C}$ is an extension code over a field $\mathbb{F}$ of a base code $\mathcal{C}_\mathbb{B}$ over a small base field $\mathbb{B}$. In this setting, we show that classical combinatorial lower bounds on the list-size of the code yields strong attacks that affect the regimes in which hash-based SNARGs operate in practice.
]]></content:encoded>
<pubDate>Wed, 03 Dec 2025 15:24:27 +0000</pubDate>
</item>
<item>
<title>Cardinal: Bridging Bitcoin with Ownership Preservation</title>
<link>https://eprint.iacr.org/2025/2196</link>
<guid>https://eprint.iacr.org/2025/2196</guid>
<content:encoded><![CDATA[
Cross-chain bridges have emerged as key components of blockchain infrastructure, enabling digital assets to flow across chains and benefit from non-native features. While early bridge designs were fraught with brittle trust assumptions, more recent designs, even within Bitcoin's script limits, can operate in a trust-minimized setting. Given this ever-increasing expansion of blockchain bridge systems, a critical question regarding custody arises: When a user's coins cross a bridge back and forth, is there a possibility that they are substituted with other coins upon return? Naturally, if cryptocurrencies were truly fungible, this would not be a consequential event. Nevertheless, chain analytics algorithms as applied to Bitcoin, Ethereum, and other popular chains can trace coins' provenance up to their minting event, thereby highlighting the possibility that users may end up with "tainted" coins upon receiving their coins from a peg-out bridge operation. Similarly, this also highlights the possibility that bridges could become an attraction for money laundering.

To address these considerations, we put forward the concept of ownership preservation for blockchain bridges and we observe that existing multi-sig and BitVM bridges fail to satisfy it. We then present a novel BitVM-based bridge that enables Bitcoin to connect bidirectionally with another DeFi supporting chain in an ownership-preserving and trust-minimized manner. We also observe that our ownership-preserving design is the first Bitcoin bridge to facilitate the transfer of Bitcoin NFTs, Ordinals, across chains, extending in this way their potential value and use cases.
]]></content:encoded>
<pubDate>Wed, 03 Dec 2025 14:30:19 +0000</pubDate>
</item>
<item>
<title>Turning Simulation into Construction: New Uses of NIZK Simulators</title>
<link>https://eprint.iacr.org/2025/2194</link>
<guid>https://eprint.iacr.org/2025/2194</guid>
<content:encoded><![CDATA[
Simulation is a fundamental technique in cryptography, central to security proofs, probably most well-known is its use for showing zero-knowledge. In this paper, we consider simulations no longer being merely a proof technique, but to constructively use simulators of non-interactive zero-knowledge proofs (NIZKs) as an integral component of cryptographic designs. We have occasionally seen such a use, e.g., in designated verifier signatures (DVS), deniable encryption, or the recent concept of anamorphic encryption. However, it was never explicity explored as a stand-alone concept, which is the goal of this paper.

By embedding simulated proofs directly into concrete systems, we unlock cryptographic functionalities that were previously out of reach under standard assumptions or required prohibitively complex techniques. In other words, by incorporating simulated proofs into the ``real'' world, rather than the simulated one, we achieve conceptually more elegant primitives. As a primer, we construct a secure signature scheme whose security hinges on a simulated proof of a false statement, i.e., the ludicrous statement $1 = 2$.

To illustrate the broader potential of this approach, we present new and simple constructions of chameleon hash functions with strong privacy guarantees (e.g., full indistinguishability), that do not require a trusted setup. Additionally, we present a very simple DVS with tight security proofs and a strengthened notion of non-transferability.

Based on the zero-knowledge guarantees of the underlying NIZKs, the resulting constructions achieve privacy even if the adversary is allowed to choose the random coins to set up the cryptographic material. To model this, we introduce the notion of trapdoor-detectable zero-knowledge, which may be of independent interest.
]]></content:encoded>
<pubDate>Wed, 03 Dec 2025 11:42:10 +0000</pubDate>
</item>
<item>
<title>Mobius: Enabling Byzantine-Resilient Single Secret Leader Election with Uniquely Verifiable State</title>
<link>https://eprint.iacr.org/2025/2191</link>
<guid>https://eprint.iacr.org/2025/2191</guid>
<content:encoded><![CDATA[
Single Secret Leader Election (SSLE) protocol facilitates the election of a single leader per round among a group of registered nodes while ensuring unpredictability. Ethereum has identified SSLE as an essential component in its development roadmap and has adopted it as a potential solution to counteract potential attacks. However, we identify a new form of attack termed the state uniqueness attack that is caused by malicious leaders proposing multiple publicly verifiable states. This attack undermines the property of uniqueness in subsequent leader elections and, with high probability, leads to violations of fundamental security properties of the over-layer protocol such as liveness. The vulnerability stems inherently from the designs reducing the uniqueness guarantee to a unique state per election, and can be generalized to the existing SSLE constructions. We further quantify the severity of this attack based on theoretical analysis and real-world executions on Ethereum, highlighting the critical challenges in designing provably secure SSLE protocols.
To address the state uniqueness attack while ensuring both security and practical performance, we present a universal SSLE protocol called Mobius that does not rely on extra trust assumptions. Specifically, Mobius prevents the generation of multiple verifiable states for each election and achieves a unique state across consecutive executions through an innovative approximately-unique randomization mechanism. In addition to providing a comprehensive security analysis in the Universal Composability framework, we develop a proof-of-concept implementation of Mobius, and conduct extensive experiments to evaluate the security and overhead. The experimental results show that Mobius exhibits enhanced security while significantly reducing communication complexity throughout the protocol execution, achieving over 80% reduction in the registration phase.
]]></content:encoded>
<pubDate>Wed, 03 Dec 2025 08:39:01 +0000</pubDate>
</item>
<item>
<title>On the (Un)biasability of Existing Verifiable Random Functions</title>
<link>https://eprint.iacr.org/2025/2176</link>
<guid>https://eprint.iacr.org/2025/2176</guid>
<content:encoded><![CDATA[
Verifiable Random Functions (VRFs) play a fundamental role in modern blockchain designs because of their applications in leader election protocols. In such contexts, however, the original definition by Micali, Rabin and Vadhan (FOCS 99), falls short at guaranteeing fairness when keys are sampled maliciously. 
The elegant notion of unbiasable VRF, recently proposed by Giunta and Stewart (Eurocrypt 24), addresses these concerns while remaining simple to state and easy to realize, at least in the random oracle model. Achieving unbiasability in the standard model is a different story, though: all known constructions rely on compilers that invariably reduce the efficiency of the VRF from which one starts.
In this paper, we look at the unbiasability of existing VRFs in the standard model. 
Our findings are mostly negative; we show that, essentially, all known constructions are not natively unbiasable. We do so by showing classes of attacks that (almost) completely cover the set of existing VRF constructions.
On the positive side, we show that some concrete schemes (and notably the well-known Dodis-Yampolskiy VRF) can be modified to achieve meaningful notions of unbiasability, while retaining their original efficiency.
]]></content:encoded>
<pubDate>Mon, 01 Dec 2025 11:16:53 +0000</pubDate>
</item>
<item>
<title>LIME: High-Performance Private Inference with Lightweight Model and Batch Encryption</title>
<link>https://eprint.iacr.org/2025/2174</link>
<guid>https://eprint.iacr.org/2025/2174</guid>
<content:encoded><![CDATA[
The rapid pace of artificial intelligence (AI) and machine learning techniques has necessitated the development of large-scale models that rely on energy-intensive data centers, thereby raising environmental sustainability. Simultaneously, the increasing significance of privacy rights has led to the emergence of Privacy-Preserving Machine Learning (PPML) technologies, which aim to ensure data confidentiality. Although homomorphic encryption (HE) facilitates computations on encrypted data, it entails considerable computational costs and challenges, which impede the effective deployment of privacy-enhancing applications with large models.

To create a more sustainable and secure AI world, we propose LIME, a pure HE-based PPML solution, by integrating two techniques: element-wise channel-to-slot packing (ECSP) and power-of-two channel pruning (PCP). ECSP leverages abundant slots to pack multiple samples within ciphertexts, facilitating batch inference. PCP prunes the channels of convolutional layers by powers of two, thereby reducing computational demands and enhancing the packing capabilities of pruned models. Additionally, we implement the ReLU-before-addition block in ResNet to mitigate accuracy degradation caused by approximations with quadratic polynomials.

We evaluated LIME using ResNet-20 on CIFAR-10, VGG-11 on CIFAR-100, and ResNet-18 on Tiny-ImageNet. Using the original models, LIME attains up to 2.1% and 8.4% accuracy improvements over the methods of Lee et al. (IEEE ACCESS’21) and AESPA (arXiv:2201.06699), which employ high- and low-degree polynomial ReLU approximations, respectively. Even with 75% parameter pruning, LIME retains higher accuracy than AESPA. Using the state-of-the-art ORION (ASPLOS '25) as the convolution backend and evaluating on the original models, LIME achieves speedups of 41.5$\times$ and 8$\times$ over ORION integrated with Lee et al. and AESPA, respectively. For models pruned by 90%, these speedups increase to 202.5$\times$ and 35.1$\times$, respectively.
]]></content:encoded>
<pubDate>Mon, 01 Dec 2025 07:58:58 +0000</pubDate>
</item>
<item>
<title>Game-Theoretically Fair Distributed Coin Tossing With Private Preferences</title>
<link>https://eprint.iacr.org/2025/2190</link>
<guid>https://eprint.iacr.org/2025/2190</guid>
<content:encoded><![CDATA[
Secure coin-tossing is typically modeled as an input-less functionality, where parties with no private inputs jointly generate a fair coin. In the dishonest majority setting, however, a strongly fair coin-tossing protocol is impossible. To circumvent this barrier, recent work has adopted the weaker notion of game-theoretic fairness, where adversaries are rational parties with preferences for specific outcomes, seeking to bias the coin in their favor.
Yet these preferences may encode secret information, making prior protocols that assume preferences are public, fundamentally incompatible with privacy.

We initiate a comprehensive study of privacy-preserving game-theoretically fair coin-tossing, where the preferences of honest parties remain private.  
We propose a simulation-based security framework and a new ideal functionality that reconciles both preference-privacy and game-theoretic fairness. A key ingredient is a certifying authority that authenticates each party’s preference and publishes only aggregate statistics, preventing misreporting while hiding parties' preferences.
The functionality guarantees that every honest party receives an output: either a uniform coin; or, if an adversary deviates, a coin that strictly decreases the adversarial coalition's expected utility.

Within this framework, we construct a protocol realizing our ideal functionality under standard cryptographic assumptions that works for both binary and general $m$-sided coin-tossing. Our schemes tolerate the same optimal (or nearly optimal) corruption thresholds as the best known protocols with public preferences (Wu-Asharov-Shi, EUROCRYPT '22; Thyagarajan-Wu-Soni, CRYPTO '24). Technically, our protocols combine authenticated preferences with an anonymous communication layer that decouples identities from preference-dependent actions, together with a deviation-penalty mechanism that enforces game-theoretic fairness.

Our work is the first to reconcile game-theoretic fairness with preference privacy, offering new definitional tools and efficient protocols for rational multi-party computation in dishonest majority settings.
]]></content:encoded>
<pubDate>Tue, 02 Dec 2025 19:25:56 +0000</pubDate>
</item>
<item>
<title>ALIOTH: An Efficient and Secure Weight-of-Evidence Framework for Privacy-Preserving Data Processing</title>
<link>https://eprint.iacr.org/2025/2188</link>
<guid>https://eprint.iacr.org/2025/2188</guid>
<content:encoded><![CDATA[
Secure two-party computation (2PC)-based privacy-preserving machine learning (ML) has made remarkable progress in recent years. However, most existing works overlook the privacy challenges that arise during the data preprocessing stage. 
Although some recent studies have introduced efficient techniques for privacy-preserving feature selection and data alignment on well-structured datasets, they still fail to address the privacy risks involved in transforming raw data features into ML-effective numerical representations.

In this work, we present ALIOTH, an efficient 2PC framework that securely transforms raw categorical and numerical features into Weight-of-Evidence (WoE)-based numerical representations under both vertical and horizontal data partitions.
By incorporating our proposed partition-aware 2PC protocols and vectorization optimizations, ALIOTH efficiently generates WoE-transformed datasets in secret.
To demonstrate scalability, we conduct experiments on diverse datasets. Notably, ALIOTH can transform 3 million data samples with 100 features securely within half an hour over a wide-area network. Furthermore, ALIOTH can be seamlessly integrated with existing 2PC-based ML frameworks.  Empirical evaluations on real-world financial datasets show ALIOTH improves both the predictive performance of logistic regression and 2PC training efficiency.
]]></content:encoded>
<pubDate>Tue, 02 Dec 2025 14:34:15 +0000</pubDate>
</item>
<item>
<title>Policy Compliant Secure Messaging</title>
<link>https://eprint.iacr.org/2025/2179</link>
<guid>https://eprint.iacr.org/2025/2179</guid>
<content:encoded><![CDATA[
We initiate the holistic study of Policy Compliant Secure Messaging (PCSM). A content policy is a predicate over messages deciding which messages are considered harmful and which not. A PCSM protocol is a type of end-to-end encrypted (E2EE) messaging system that guarantees E2EE privacy and authenticity for all policy compliant messages but detects and verifiably reports harmful content prior to its delivery. This stands in contrast to prior content moderation systems for E2EE messaging where detection relies on receivers reporting the harmful content themselves which makes them unsuited for most PCSM applications (e.g., for preventing the wilful distribution of harmful content). Our holistic PCSM notion explicitly captures several new roles such as policy creator, auditor and judge, to more accurately separate and model the different goals and security concerns of stakeholders when deploying PCSM. 

We present efficient PCSM constructions for arbitrary policy classes, as well as for hash-based ones, achieving various levels of security, while maintaining the core security properties of the underlying E2EE layer. For hash-based PCSM, we encapsulate Apple’s recent PSI protocol used in their content moderation system, and we properly adapt it to realize the desired PCSM functionality, and analyze the resulting protocol’s security. To our knowledge, our work is the first that rigorously study Apple’s PSI for server-side content moderation within the broader context of secure messaging, addressing the diverse goals and security considerations of stakeholders when deploying larger systems.
]]></content:encoded>
<pubDate>Mon, 01 Dec 2025 19:31:52 +0000</pubDate>
</item>
<item>
<title>Systems Security Foundations for Agentic Computing</title>
<link>https://eprint.iacr.org/2025/2173</link>
<guid>https://eprint.iacr.org/2025/2173</guid>
<content:encoded><![CDATA[
This paper articulates short- and long-term research problems in AI agent security and privacy, using the lens of computer systems security. This approach examines end-to-end security properties of entire systems, rather than AI models in isolation. While we recognize that hardening a single model is useful, it is important to realize that it is often insufficient. By way of an analogy, creating a model that is always helpful and harmless is akin to creating software that is always helpful and harmless. The collective experience of decades of cybersecurity research and practice shows that this is insufficient. Rather, constructing an informed and realistic attacker model before building a system, applying hard-earned lessons from software security, and continuous improvement of security posture is a tried-and-tested approach to securing real computer systems. A key goal is to examine where research challenges arise when applying traditional security principles in the context of AI agents. A secondary goal of this report is to distill these ideas for AI and ML practitioners and researchers. We discuss the challenges of applying security principles to agentic computing, present 11 case studies of real attacks on agentic systems, and define a series of new research problems specific to the security of agentic systems.
]]></content:encoded>
<pubDate>Mon, 01 Dec 2025 05:43:48 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Linkable Ring Signatures for Anonymous and Accountable Whistleblowing</title>
<link>https://eprint.iacr.org/2025/2170</link>
<guid>https://eprint.iacr.org/2025/2170</guid>
<content:encoded><![CDATA[
Ring signatures allow an individual to sign a message on behalf of a group in such a way that the verifier can only confirm that someone in the group signed it, but cannot identify the actual signer. This strong anonymity, while desirable, may also be exploited for repeated or harmful activities. Linkable ring signatures mitigate this issue by enabling the system to recognise whether two signatures originate from the same signer, while still keeping the signer anonymous. Such constructions are essential in domains like e-voting, e-cash, privacy-preserving blockchain systems, and whistleblowing, where detecting repeated actions—such as double-spending or double-voting—is necessary to maintain system reliability.
In this paper, we present a lattice-based linkable ring signature scheme designed to withstand quantum-era adversaries. The framework relies on exact and efficient zero-knowledge proofs, and employs a weak pseudorandom function (wPRF) to enable linkability. To demonstrate both ring membership and the generation of a unique tag, we integrate a Merkle tree accumulator, which also streamlines the verification steps. The scheme is instantiated using concrete parameter choices, allowing us to precisely evaluate how the signature size scales with different ring sizes. An important feature of our design is that it eliminates the need for trapdoor techniques, yet still produces a signature of roughly 0.22 MB when the ring contains 2^10 users. We further outline practical application scenarios, such as anonymous but accountable whistleblowing, to highlight the usefulness of the proposed construction.
]]></content:encoded>
<pubDate>Sat, 29 Nov 2025 14:05:00 +0000</pubDate>
</item>
<item>
<title>Multi-Verifier Keyed-Verification Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/2156</link>
<guid>https://eprint.iacr.org/2025/2156</guid>
<content:encoded><![CDATA[
Keyed-Verification anonymous credentials (KVAC) enable privacy-preserving authentication and can be seen as the symmetric primitive of conventional anonymous credentials: issuance and verification of credentials requires a shared secret key. The core advantage of KVACs is that they can be realized without pairings, which still appears to be a significant bottleneck when it comes to real-world adoption. KVACs provide all the benefits from anonymous credentials, in particular multi-show unlinkability, but only work in the setting where the issuer and verifier are the same entity, limiting the applications they can be used in. In this work we extend the idea of keyed-verification credential to a setting where again multiple verifiers are supported, each sharing an individual secret key with the issuer. We formally introduce this as multi-verifier keyed-verification anonymous credentials (mKVACs). While users must now get verifier-specific credentials, each credential still provides multi-show unlinkability. In terms of security, mKVAC naturally strengthens the single-verifier variant, as it guarantees that corruption of any verifier does not impact unforgeability guarantees for other verifiers. The main challenge therein is to not trade this added flexibility for privacy, and hide the verifier's identity in the credential issuance. We provide formal definitions of all desired security and privacy features and propose a provably secure and pairing-free construction. Along the way, we develop a new KVAC-like primitive that authenticates group elements and offers statistical privacy, solving the open problem of combining multi-verifier support and pairing-freeness. Finally, we demonstrate practicality of our protocol via implementation benchmarks.
]]></content:encoded>
<pubDate>Thu, 27 Nov 2025 10:39:12 +0000</pubDate>
</item>
<item>
<title>Semigroup-homomorphic Signature</title>
<link>https://eprint.iacr.org/2025/2153</link>
<guid>https://eprint.iacr.org/2025/2153</guid>
<content:encoded><![CDATA[
In 2002, Johnson et al. posed an open problem at the Cryptographers' Track of the RSA Conference: how to construct a secure homomorphic signature on a semigroup, rather than on a group. In this paper, we introduce, for the first time, a semigroup-homomorphic signature scheme. Under certain conditions, we prove that the security of this scheme is based on the hardness of the Short Integer Solution (SIS) problem and is tightly secure. Furthermore, we extend it to a linearly semigroup-homomorphic signature scheme over lattices, and this scheme can also ensure privacy.
]]></content:encoded>
<pubDate>Wed, 26 Nov 2025 01:54:16 +0000</pubDate>
</item>
<item>
<title>Updatable Private Set Intersection and Beyond: Efficient Constructions via Circuit Private Set Intersection</title>
<link>https://eprint.iacr.org/2025/2147</link>
<guid>https://eprint.iacr.org/2025/2147</guid>
<content:encoded><![CDATA[
Private Set Intersection (PSI) has been widely studied, deployed, and demonstrated through various real-life use cases such as mobile private contact discovery, privacy-preserving contact tracing, etc. Nevertheless, the majority of existing solutions typically assume that the underlying datasets are static and require a fresh execution of PSI at each time the datasets are updated over time. In this work, similar to a recent solution by Badrinaryanan et. al' (ASIACRYPT 2024), we investigate the problem of designing efficient and secure updatable PSIs in the honest-but-curious model by adopting the  approach of executing a small number of PSIs over smaller sets instead of one PSI over the entire, updated sets. We first identify that existing constructions suffer from two privacy leakages and further propose to mitigate them thanks to the use of circuit PSIs, which are variants of PSI protocols that instead of outputting the resulting intersection, output the secret shares of the intersection and nothing more, combined with secure shuffling when needed. We construct a generic framework for PSI over updated sets which can use any circuit-PSI. Additionally, we show that this framework can easily be extended to a protocol that outputs the cardinality of the intersection instead of the intersection, itself. Finally, we provide an in-depth discussion on the feasibility of circuit PSI over updated sets, with the main challenges to overcome and solutions for some particular cases. Our solutions are implemented in Rust and their performance is compared with the state of the art, achieving an improvement of $11\times$ to $40\times$ in updatable PSI and $14\times$ to $107\times$ in updatable cardinality PSI in computation time. The proposed framework is also demonstrated through a real-life use case, namely, a spam detection filter.
]]></content:encoded>
<pubDate>Mon, 24 Nov 2025 09:52:14 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Protocols with PVC Security: Striking the Balance between Security and Efficiency</title>
<link>https://eprint.iacr.org/2025/2146</link>
<guid>https://eprint.iacr.org/2025/2146</guid>
<content:encoded><![CDATA[
Zero-knowledge protocols allow a prover to prove possession of a witness for an NP-statement without revealing any information about the witness itself. This kind of protocol has found extensive applications in various fields, including secure computation and blockchain. However, in certain scenarios (e.g. when the statements are complicated), existing zero-knowledge protocols may not be well-suited due to their limited applicability or high computational overhead.

We address these limitations by incorporating the notion of publicly verifiable covert (PVC) security into zero-knowledge protocols. PVC security, recently emerging from secure computation, effectively balances security and efficiency in practical scenarios. With PVC security, while a malicious party may attempt to cheat, such cheating will be detected and become publicly verifiable with a significant probability (called deterrence factor, e.g. ${>}90\%$). This notion is well-suited for practical scenarios involving reputation-conscious parties (e.g. companies) and offers substantial efficiency improvements.

In this paper, we present the first definition of zero-knowledge protocols with PVC security. We then propose a generic transformation to convert Sigma protocols with $1$-bit challenge, a kind of protocol widely used for zero-knowledge, into efficient zero-knowledge protocols with PVC security. By applying our transformation, we can substantially improve the efficiency of existing protocols for reputation-sensitive parties. For instance, applying the transformation to achieve a deterrence factor of $93.75\%$ incurs a cost of only around $20\%$ compared to the original protocol. Therefore, our results contribute to significant advancements in practical zero-knowledge protocols.
]]></content:encoded>
<pubDate>Mon, 24 Nov 2025 05:58:33 +0000</pubDate>
</item>
<item>
<title>New Memory Optimizations of Wagner's Algorithms via List Item Reduction</title>
<link>https://eprint.iacr.org/2025/2141</link>
<guid>https://eprint.iacr.org/2025/2141</guid>
<content:encoded><![CDATA[
The Generalized Birthday Problem ($\textsf{GBP}$) serves as a cornerstone for a broad spectrum of cryptanalytic research. The classical solution, Wagner’s $k$-tree algorithm (CRYPTO’02), is characterized by inherently high memory complexity. Subsequently, Biryukov and Khovratovich (NDSS’16) introduced $\textsf{Equihash}$, a memory-hard proof-of-work scheme constructed upon a single-list variant of Wagner’s algorithm. Due to its robust resistance to ASIC mining, $\textsf{Equihash}$ has emerged as one of the most widely adopted proof-of-work schemes in blockchain. However, memory optimization for Wagner-style algorithms remains a persistent challenge in cryptographic research. Conventional approaches primarily focus on reducing list size to lower memory consumption, yet this strategy typically incurs a prohibitive time penalty. For instance, halving the peak memory usage of the $\textsf{Equihash}(200, 9)$ mining algorithm increases its theoretical time complexity by a factor of $2^{24.6}$.

In this work, we investigate a novel optimization vector: List Item Reduction (LIR), which facilitates practical and fine-grained memory-time trade-offs. We systematize existing LIR techniques and propose novel optimization methods integrated into a new hybrid framework. While our approach does not improve asymptotic memory complexity, it achieves a near-linear trade-off in practice, offering substantial benefits for the concrete design of efficient Wagner-style algorithms. Specifically, our techniques reduce peak memory usage by nearly 50% (from $2nN$ to $nN$ bits) across all $\textsf{Equihash}$ parameters, with only an approximate twofold time penalty. Furthermore, we present concrete implementations, including the first realization of an in-place $\textsf{merge}$. Building on these results, we propose an ASIC-friendly framework leveraging an external-memory caching mechanism.
]]></content:encoded>
<pubDate>Sun, 23 Nov 2025 08:50:56 +0000</pubDate>
</item>
<item>
<title>Scalable Private World Computer via Root iO: Application-Agnostic iO and Our Roadmap for Making It Practical</title>
<link>https://eprint.iacr.org/2025/2139</link>
<guid>https://eprint.iacr.org/2025/2139</guid>
<content:encoded><![CDATA[
Ethereum has established itself as a world computer, enabling general-purpose, decentralized, and verifiable computation via smart contracts on a globally replicated state. However, because all computations and state are public by default, it is fundamentally unsuitable for confidential smart contracts that jointly process private data from multiple users. This motivates the notion of a private world computer: an ideal future form of Ethereum that preserves its integrity and availability guarantees while supporting such confidential smart contracts. Prior constructions based on implementable cryptographic primitives such as fully homomorphic encryption (FHE) inevitably rely on committees that hold secret shares and perform computations using those shares, a capability that is not provided by today's Ethereum validators. We cannot simply modify the Ethereum protocol so as to shift the committee’s role onto the Ethereum validators, because the computational and communication costs borne by the committee grow with the demand for confidential smart contracts, forcing higher hardware requirements for participation, undermining decentralization, and increasing the risk of malicious collusion. Hence, there remains a fundamental trade-off between committee decentralization and scalability for confidential smart contracts.

In this position paper, we make two contributions toward a scalable private world computer. First, we show how indistinguishability/ideal obfuscation (iO), combined with FHE and succinct non-interactive arguments of knowledge (SNARK), yields a private world computer that, after a one-time obfuscation process, introduces no additional ongoing trust assumptions beyond Ethereum’s validators, incurring no additional overhead for validators to process confidential smart contracts compared to public smart contracts. In this design, a single application-agnostic obfuscated circuit, called root iO, suffices to realize arbitrary confidential smart contracts. The outputs of root iO can be verified on-chain at a cost comparable to signature verification, and the obfuscation process can be distributed among multiple parties while remaining secure as long as at least one party is honest. As the second contribution, we outline our roadmap toward a practical implementation of root iO. Assuming that the underlying assumptions of our lattice-based iO construction remain secure, the remaining missing pieces are technically concrete: namely, practical implementations of verifiable FHE and of homomorphic evaluation of a pseudorandom function (PRF) and SNARK verification over key-homomorphic encodings, which together would allow us to implement root iO without incurring prohibitive overhead.
]]></content:encoded>
<pubDate>Sat, 22 Nov 2025 14:15:59 +0000</pubDate>
</item>
<item>
<title>Synergeia: Super-Linear Consistency and Adaptive Stability in a Hybrid PoW/PoS Consensus</title>
<link>https://eprint.iacr.org/2025/2138</link>
<guid>https://eprint.iacr.org/2025/2138</guid>
<content:encoded><![CDATA[
We present the Synergeia (Συνεργία) protocol, a novel, permissionless blockchain protocol that synergistically integrates Proof-of-Work (PoW) and a dynamically regulated Proof-of-Stake (PoS) mechanism. Traditional Nakamoto protocols exhibit consistency violations decaying as $\epsilon \approx exp(-\Omega(k))$ leading to long finality times. Our primary contribution is leveraging a Local Dynamic Difficulty (LDD) scheme to reshape the block inter-arrival time distribution towards a Rayleigh distribution. We prove this yields a full consistency bound of $\epsilon(k) \le exp(-C_{1}k^{2}) + exp(-C_{2}k)$. While this provides a quadratic asymptotic advantage, we demonstrate that for practical security parameters, the bound is dominated by the linear term. Our LDD mechanism achieves a superior constant factor ($C_{2}$) in this linear exponent, requiring only $k=26$ blocks against a 40% adversary for enterprise-grade security ($\epsilon \le 10^{-9}$). Furthermore, we introduce the Decentralized Consensus Service ($\mathcal{F}_{DCS}$) providing BFT-robust consensus on network time, stake, delay, and load via on-chain beacons. This enables a fully autonomous LDD system that dynamically adapts its Slot Gap ($\psi$) and target block time ($\mu_{target}$) to measured network conditions, ensuring the security assumption $\psi > \Delta$ holds robustly. The protocol utilizes an Accumulated Synergistic Work (ASW) metric incorporating Proof-of-Burn for PoS block commitment. As a result of this constant-factor improvement, Synergeia achieves probabilistic finality in approximately 6.5 minutes under typical Bitcoin-like network conditions ($\mathbb{E}[\Delta] \approx 8s$). Additionally, we introduce Burst Finality, an optional mechanism triggered by high transaction fees (secured by Proof-of-Burn) that provides execution-driven confirmation for instant finality. Synergeia establishes a new paradigm for adaptive consensus, offering a significant constant-factor improvement for probabilistic finality alongside optional near-instant settlement.
]]></content:encoded>
<pubDate>Sat, 22 Nov 2025 00:58:06 +0000</pubDate>
</item>
<item>
<title>The Latency Cost Of Censorship Resistance</title>
<link>https://eprint.iacr.org/2025/2136</link>
<guid>https://eprint.iacr.org/2025/2136</guid>
<content:encoded><![CDATA[
<div> Yes, the **two additional rounds of latency** are **inherently necessary** for achieving strong censorship resistance in blockchain consensus protocols when using a multiple-includer design — and this is precisely what the **Censorship Resistant Byzantine Broadcast (CRBB)** framework establishes through rigorous theoretical analysis.

### Why the Latency Cost Is Inevitable

The core insight from your description is that **CRBB formalizes a stronger guarantee than traditional Byzantine Broadcast (BB):**

- In **classical BB**, a correct leader proposes a value, and if the leader is honest, the protocol ensures that this value is delivered and agreed upon by all honest parties within minimal rounds (e.g., 2 rounds in synchrony).
- In **CRBB**, we want to ensure **censorship resistance**: even if the leader is malicious or uncooperative, any **timely submitted transaction** must be included in the next confirmed block — *regardless* of the leader’s actions.

This means the system cannot wait indefinitely on the leader to include transactions. Instead, **other parties (includers)** must proactively propose or attest to transaction inclusion independently of the leader.

---

### Key Trade-off: Independence vs. Coordination

To achieve censorship resistance:
- Transaction inclusion must be **decentralized** among multiple includers.
- Honest includers must have the ability to **force inclusion** of valid user requests.
- But agreement still requires coordination with the leader (or across phases) to maintain consistency and liveness.

Thus, CRBB introduces an **additional phase** where:
1. Users submit transactions to includers.
2. Includers collect and attest to pending transactions (**first extra round**).
3. The leader proposes a block, but now must incorporate all transactions attested by a sufficient number of includers.
4. A final confirmation phase ensures agreement (**second extra round**).

Each of these steps adds at least one communication round, and crucially, **cannot be collapsed without breaking security or censorship resistance**.

---

### Lower Bound Results (Main Contribution)

Your summary highlights a key technical contribution:

> "**Synchronous CRBB requires 4 rounds whenever BB requires 2. Partial synchronous CRBB requires 5 rounds whenever BB requires 3.**"

This shows that:
- There is a **tight separation** between BB and CRBB.
- The **+2 round overhead** is not due to suboptimal protocol design — it's **inherent** to the problem under realistic conditions (i.e., when the leader is correct, which is the common case in practice).
- Even in best-case executions (correct leader), you still pay the price because the protocol must protect against censorship attempts while maintaining safety and liveness.

This implies that **no matter how cleverly you design the protocol**, you cannot get below 4 rounds in the synchronous setting for CRBB — whereas BB can do it in 2.

---

### Interpretation & Practical Implications

- **Yes, the cost is necessary.** You cannot have strong, predictable censorship resistance (i.e., guaranteed inclusion irrespective of leader behavior) without paying in latency.
- This matches real-world designs like **Ethereum’s proposer-builder separation (PBS)** or **accountable block production**, where decentralizing block construction improves resilience but increases complexity and delay.
- However, this cost may be **worthwhile** for high-value applications where censorship resistance is paramount (e.g., decentralized exchanges, voting systems, permissionless finance).

---

### Conclusion

> ✅ **The two-round latency overhead in censorship-resistant consensus is not avoidable — it is inherent.**

By introducing and analyzing the **CRBB problem**, the work provides a foundational understanding of the **price of censorship resistance** in distributed consensus. It proves that moving from centralized block proposal to multi-party inclusion brings significant benefits in robustness, but also imposes a **provable lower bound on performance**: **+2 rounds of latency**, even under ideal network and leadership conditions.

This sets a new benchmark for future blockchain protocols aiming to balance **security, decentralization, and efficiency**. <div>
On the road to eliminating censorship from modern blockchain protocols, recent work in consensus has explored protocol design choices that delegate the duty of block assembly away from a single consensus leader and instead to multiple parties, referred to as includers. As opposed to the traditional leader-based approach, which guarantees transaction inclusion in a block produced by the next correct leader, the multiple includer approach allows blockchain protocols to provide a strong censorship-resistance property for users: A timely submitted transaction is guaranteed to be included in the next confirmed block, regardless of the leader's behavior. Such a guarantee, however, comes at the cost of 2 additional rounds of latency to block confirmation, compared to the leader-based approach. Is this cost necessary?
We introduce the Censorship Resistant Byzantine Broadcast (CRBB) problem, a one-shot variant that distills the core functionality underlying the multiple-includer design paradigm. We then provide a full characterization, both in synchrony and partial synchrony, of the achievable latency of CRBB in executions with a correct leader, which is the most relevant case to practice. Our main result is an inherent latency cost of two additional rounds compared to the classic Byzantine Broadcast (BB) problem. For example, synchronous protocols for CRBB require 4 rounds whenever BB requires 2 rounds. Similarly, up to a small constant in the resilience, partial synchrony protocols for CRBB require 5 rounds whenever BB requires 3 rounds.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 20:20:02 +0000</pubDate>
</item>
<item>
<title>Robust Elections and More: Fast MPC in the Preprocessing Model</title>
<link>https://eprint.iacr.org/2025/2135</link>
<guid>https://eprint.iacr.org/2025/2135</guid>
<content:encoded><![CDATA[
<div> This is a well-written and technically rich abstract for a paper on secure multiparty computation (MPC), highlighting several important advances in the preprocessing model. Below is a **refined version** of your paragraph with improved clarity, flow, and precision—while preserving all technical content and emphasis—suitable for inclusion in a formal publication or conference submission:

---

In this paper, we present a multiparty computation (MPC) protocol in the preprocessing model that achieves online communication complexity and round complexity essentially matching those of state-of-the-art protocols such as online-BGW (based on precomputed Beaver triples) for $ t < n/3 $ malicious corruptions. Our protocol, however, provides significantly stronger guarantees: it ensures **robustness and correctness** against up to $ t < n/2 $ actively corrupted parties, while maintaining **privacy** for up to $ t < n/3 $. This combination is particularly valuable in high-stakes applications—such as commodity/stock market auctions, national elections, or IACR board elections—where certifying the correct outcome is paramount, yet low-latency online execution remains critical.

The ability to tolerate an honest majority in correctness enables the use of **optimistic Berlekamp-Welch decoding**, in contrast to the standard BGW approach, leading to more efficient error detection and correction during reconstruction. Like online-BGW, our protocol remains **responsive throughout the online phase**, only requiring a final attestation step at the end.

We further introduce a complementary **verifiable input-sharing scheme** tailored for the multi-client, distributed-server setting, which achieves both robustness and correctness under $ t < n/2 $ malicious servers. A key innovation is that clients participate in only **a single round of interaction**—after which they may disconnect—making the system highly practical for real-world deployments where client availability is limited, such as in electronic voting or sealed-bid auctions. The servers first perform a preprocessing phase without client involvement, enabling lightweight client interaction later.

We prove the security of our construction in the **universally composable (UC) framework**, achieving **statistical security** against static adversaries. Technically, our protocol combines **global authenticators from the SPDZ framework** with a novel application of **augmented Reed-Solomon codes**. This augmentation—commonly known as *robust sharing*—enables efficient decoding under an honest majority, even for polynomials of degree up to $ n/2 $. Importantly, our method allows the preprocessing phase to generate these robust sharings with a **factor-$ n $ improvement in efficiency** over prior information-theoretic approaches, marking a significant step forward in scalable MPC design.

---

### Key Improvements:
- **Structure**: Separated ideas into logical paragraphs (protocol contributions, input sharing, security, and technical core).
- **Clarity**: Clarified what "responsive" means and why one-round client interaction matters.
- **Precision**: Specified that privacy threshold remains $ t < n/3 $, correctness goes up to $ t < n/2 $.
- **Emphasis**: Highlighted novelty and practical impact without hyperbole.

Let me know if you'd like a shorter version (e.g., for a proceedings abstract), a version suitable for a non-expert audience, or help writing the introduction section based on this. <div>
In this paper, we present an MPC protocol in the preprocessing model with essentially the same concrete online communication and rounds as the state-of-the-art MPC protocols such as online-BGW (with precomputed Beaver tuples) for $t < n/3$ malicious corruptions. However, our protocol additionally guarantees robustness and correctness against up to $t < n/2$ malicious corruptions while the privacy threshold remains at $n/3$. This is particularly useful in settings (e.g. commodity/stock market auctions, national elections, IACR elections) where it is paramount that the correct outcome is certified, while maintaining the best possible online speed. In addition, this honest-majority correctness allows us to use optimistic Berlekamp-Welch decoding in contrast to BGW. Moreover, just like online-BGW, our protocol is responsive until a final attestation phase. 

We also give a complementary verifiable input-sharing scheme for the multi-client distributed-server setting which satisfies both robustness and correctness against up to $t < n/2$ malicious servers. This is accomplished by having the servers first run a preprocessing phase that does not involve the clients. The novelty of this input-sharing scheme is that a client only interacts for one round, and hence need not be online, which, again, is highly desirable in applications such as elections/auctions.

We prove our results in the universally-composable model with statistical security against static corruptions. Our protocol is achieved by combining global authenticators of SPDZ with an augmented Reed-Solomon code in a novel manner. This augmented code enables honest-majority decoding of degree $n/2$ Reed-Solomon codes. Our particular augmentation (often referred to as robust sharing) has the additional property that the preprocessing phase can generate this augmented sharing with a factor $n$ speedup over prior information-theoretic robust sharing schemes.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 19:42:03 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Threshold Mercurial Signatures with Applications to Threshold DAC</title>
<link>https://eprint.iacr.org/2025/2134</link>
<guid>https://eprint.iacr.org/2025/2134</guid>
<content:encoded><![CDATA[
<div> Your passage provides a high-level overview of an advanced cryptographic construction involving **threshold mercurial signatures (TMS)** and their application to **delegatable anonymous credentials**. Below is a refined, structured version of your text with improved clarity, precision, and flow—suitable for inclusion in a research paper or technical abstract:

---

**Refined Abstract/Introduction:**

*Mercurial signatures* enable a signer to sign a representative $ m $ from an equivalence class of messages under a representative $ \mathsf{pk} $ from an equivalence class of public keys, yielding a signature $ \sigma $. Crucially, $ \sigma $ can be *transformed* into a valid signature $ \sigma' $ on any message $ m' $ equivalent to $ m $, under any public key $ \mathsf{pk}' $ equivalent to $ \mathsf{pk} $. This malleability property makes mercurial signatures particularly useful in constructing *delegatable anonymous credentials*, where they allow for the randomization of credential chains—thereby hiding the identities of intermediate signers while preserving verifiable authenticity across delegation steps.

However, existing constructions of mercurial signatures without trusted setup suffer from a critical limitation: they only achieve a *weak privacy guarantee*. Specifically, any party involved in the delegation chain who knows its own secret key can later recognize its contribution even after the chain has been randomized—thus undermining full anonymity.

To overcome this issue, Abe et al. (Asiacrypt 2024) introduced *interactive threshold mercurial signatures (TMS)*, which distribute the signing power among multiple parties, eliminating reliance on a single trusted signer. In their model, no individual party holds the full signing key; instead, a threshold number of participants must interactively collaborate to produce a signature. While this approach strengthens privacy by preventing individual recognition attacks, it comes at a significant cost to practicality due to the required multi-round interaction during signing.

In this work, we introduce and construct *non-interactive threshold mercurial signatures (NI-TMS)*, where each participant *non-interactively* computes a partial signature, akin to standard threshold signature schemes. Our construction dramatically reduces communication complexity and removes the need for real-time coordination among signers. We build NI-TMS by enhancing the mercurial signature framework of Mir et al. (CCS 2023), leveraging techniques from threshold cryptography and zero-knowledge proofs to ensure unforgeability and strong privacy.

As a primary application, we define *threshold delegatable anonymous credentials (TDAC)*—a credential system where delegation rights are shared among a group via threshold control, and anonymity is preserved even against adversarial participants who know their own secret keys. We instantiate TDAC using our NI-TMS scheme, achieving both scalable delegation and robust privacy without trusted setup.

Our results advance the state-of-the-art in anonymous credential systems, enabling decentralized, efficient, and truly private delegation architectures suitable for real-world deployment.

---

Let me know if you'd like a shorter version (e.g., for a conference abstract), a formal definition set, or a diagram suggestion for illustrating TDAC/NITMS. <div>
In a mercurial signature, a signer signs a representative $m$ of an equivalence class of messages on behalf of a representative $\mathsf{pk}$ of an equivalence class of public keys, receiving the signature $\sigma$. One can then transform $\sigma$ into a signature $\sigma'$ on an equivalent (to $m$) message $m'$ under an equivalent (to $\mathsf{pk}$) public key $\mathsf{pk}'$. Mercurial signatures are helpful in constructing delegatable anonymous credentials: their privacy properties enable straightforward randomization of a credential chain, hiding the identity of each signer while preserving the authenticity of the overall credential.
    
Unfortunately, without trusted setup, known constructions of mercurial signatures satisfy only a weak form of this privacy property. Specifically, an adversary who is responsible for a link in a delegation chain—and thus knows its corresponding secret key—will be able to recognize this link even after the chain has been randomized.
    
To address this issue, Abe et al. (Asiacrypt 2024) proposed (interactive) threshold mercurial signatures (TMS), which remove the reliance on a single trusted signer by distributing the signing capability among multiple parties, none of whom knows the signing key. However, this contribution was far from practical, as it required the signers to interact with each other during the signing process.

In this work, we define and realize non-interactive TMS, where each participant non-interactively computes its contribution to the threshold mercurial signature. Our construction also substantially reduces the overall communication complexity. It uses the mercurial signature scheme of Mir et al. (CCS 2023) as a starting point. Further, we introduce threshold delegatable anonymous credentials (TDAC) and use a non-interactive TMS to construct them.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 16:21:31 +0000</pubDate>
</item>
<item>
<title>Byzantine Broadcast with Unknown Participants</title>
<link>https://eprint.iacr.org/2025/2133</link>
<guid>https://eprint.iacr.org/2025/2133</guid>
<content:encoded><![CDATA[
<div> You've provided a detailed and compelling summary of a groundbreaking result in distributed computing and cryptography—specifically, **Byzantine Broadcast (BB) in the Unknown-Participants (UP) setting**, where neither the number of participants nor resource distribution is known or assumed. Let's unpack and refine this narrative into a clear, structured explanation suitable for academic or technical communication.

---

### **The Problem: Byzantine Broadcast with Unknown Participants**

In classical Byzantine fault-tolerant protocols like Dolev-Strong or PBFT, it is assumed that:
- The set of participants is fixed and known.
- A bound on the number of faulty (malicious) parties is known (e.g., $ f < n/3 $).
- Often, some balanced allocation of power exists (as in blockchains via proof-of-work or proof-of-stake).

However, in many real-world decentralized environments—especially on the **dark web** or open peer-to-peer networks—these assumptions fail:
- Parties join and leave dynamically.
- There is no central authority to register participants.
- An adversary can create sybils at will.
- Honest majority cannot be guaranteed—or even defined—due to unknown total participation.

This leads to the question:

> **Can we achieve consistent broadcast when the sender may be malicious, participants are unknown, and there is no assumption about honest majorities or resource distribution?**

We call this **Unknown-Participants Broadcast (UP Broadcast)**.

---

### **Why Existing Solutions Fail**

Traditional Byzantine Broadcast protocols rely critically on:
1. Knowing $ n $, the total number of parties, to determine quorum sizes.
2. Ensuring termination by waiting for messages from all expected participants.
3. Validity and consistency arguments based on majority thresholds.

Without knowing $ n $, an unbounded number of corrupt parties can:
- Flood the network with fake identities (sybil attack),
- Delay or manipulate message delivery,
- Prevent clean decision-making due to uncertainty over who counts as a "majority".

Thus, **standard BB techniques break down completely** under dynamic, unknown-participant models.

Moreover, defining such a problem formally requires rethinking the execution model itself—since standard simulation-based or state-machine-replication frameworks assume static roles and bounded faults.

---

### **Key Contributions of This Work**

Despite these obstacles, the paper presents a surprising and strong positive answer.

#### ✅ 1. **New Definitions: UP Broadcast & UP Interactive Consistency**
- Introduces formal definitions for **Unknown-Participants Broadcast (UP-Broadcast)** and its multi-sender counterpart, **UP Interactive Consistency**.
- Accommodates:
  - **Static and dynamic participation**: Parties may appear at any round.
  - **Arbitrary corruption**: Adversary controls any number of parties, including potentially *all* except one.
  - **No trusted setup or resource assumptions**.

Crucially, correctness guarantees (consistency, validity) are offered only to parties who participate **throughout the entire execution**—a necessary restriction given the adversarial strength.

#### ✅ 2. **Existence Result: Deterministic Polynomial-Time Protocol**
- Constructs the **first deterministic UP Broadcast protocol** in the synchronous model.
- Achieves:
  - **Consistency**: All honest (i.e., continuously participating) parties agree on the same value.
  - **Validity**: If the sender is honest, everyone agrees on the sender’s input.
- Runs in **polynomial time** and uses **synchronized rounds**.

This result is **surprising** because it shows that even without bounds on participants or honest majority, agreement is still possible—provided we adjust expectations for latecomers.

#### ✅ 3. **Round Complexity Optimality**
- Proves that the proposed protocol achieves **optimal round complexity**.
- The lower bound holds even against **randomized protocols**, showing that randomness does not help overcome the inherent latency barrier in this model.
- Establishes tightness of the construction.

#### ✅ 4. **Handling Late-Joining Parties**
- Shows a **negative result**: With unrestricted dynamic join times, **no meaningful consistency guarantee** can be given to parties joining mid-execution.
  - Reason: They cannot distinguish between conflicting histories created by a persistent adversary.
- On the positive side:
  - Proposes **weaker but best-possible guarantees** for late-joining parties (e.g., eventual awareness of consensus, inability to be misled beyond certain bounds).
  - Provides constructions achieving these optimal guarantees while preserving round optimality for early participants.

---

### **Model Assumptions**

- **Synchronous communication**: Bounded message delays; rounds are well-defined.
- **Adversary**: Can corrupt arbitrarily many parties, statically or adaptively.
- **No authentication infrastructure required**, though digital signatures significantly simplify design (assumed in most variants).
- **Participation is observable**: Messages are signed, so identity/spoofing can be managed cryptographically (but not sybil-resistant IDs).

---

### **Implications and Significance**

This work breaks a long-standing conceptual barrier in distributed computing:

> **Agreement is possible even without knowing who you're agreeing with.**

It opens doors to robust coordination in:
- Dark web messaging systems,
- Censorship-resistant publishing,
- Decentralized anonymous forums,
- Sybil-vulnerable P2P networks.

Importantly, it separates **agreement** from **identity management** and **resource ownership**, two pillars previously thought essential.

It also highlights a shift in how we define security in open systems:
- From “guarantees for all” → to “guarantees for those who stay”.
- Latecomers get weaker assurances—a fundamental trade-off revealed by the impossibility results.

---

### **Conclusion: Yes, It Is Possible!**

Despite four decades of negative intuition suggesting otherwise, this work answers affirmatively:

> **Yes, Byzantine Broadcast is achievable in the unknown-participants setting—even against fully adaptive, unbounded adversaries.**

And more:
- The solution is **deterministic, efficient, and round-optimal**.
- The framework extends to **interactive consistency** (multi-sender agreement).
- Definitions and constructions gracefully handle **dynamic participation**, offering best-possible guarantees.

This represents a foundational advance in the theory of distributed computation in open, adversarial environments.

---

### Suggested Title (for Paper or Talk)

> **"Broadcasting in the Dark: Byzantine Agreement with Unknown Participants"**

Or more technically:

> **"Unknown-Participants Broadcast: Round-Optimal Agreement Without Majority Assumptions"**

---

Let me know if you'd like help turning this into a full paper abstract, presentation slides, or a blog post for broader audiences! <div>
A sender wishes to consistently broadcast a message on the dark web, so that whoever is around and active will agree on it even when the sender is malicious. No assumptions on the number of honest parties, or blockchain-style ``tricks''---like balanced resource-allocation (e.g., hashing power or stake ownership)---can be made.

The above is an instance of Byzantine broadcast (BB) in the unknown-participants setting (``UP Broadcast'' for short). Despite four decades of extensive research on dishonest-majority BB, all existing approaches (e.g., the well-known Dolev-Strong protocol) fail to solve this problem, as they crucially rely on knowing the number of protocol participants---or the make blockchain-style assumptions on available resources. The challenge, which might appear as an inherent limitation, is that without any such assumption malicious parties can join the protocol at any point during its execution,  making it arduous for other parties to terminate without violating consistency. So one might wonder: Is this even possible?

In this work, we provide the first definitions of UP Broadcast that incorporate both static and dynamic participation and corruption of arbitrary many parties. Interestingly, even formally defining the problem turns out to be non-trivial as one needs to deviate from the model used in classical BB approaches. We then provide the strongest possible (and in our opinion, unexpected) answer to the above question: Yes, it is! We provide a polynomial-time deterministic UP Broadcast protocol. In the process we also solve UP Interactive Consistency, which corresponds to the multi-sender version of the problem. Our constructions are in the standard, synchronous model of protocol execution, and they offer consistency and validity guarantees to every party who is present throughout the protocol execution.

We next turn to the question of round complexity and prove that our protocols are optimal against adversaries who can corrupt arbitrarily many parties; this optimality applies even to randomized protocols. Finally, we ask, what if parties join in the middle of the protocol execution? We provide a negative result for unrestricted dynamic participation; on the positive side, we devise definitions that offer best-possible guarantees (also to such ``late'' parties), and present corresponding constructions that remain round-optimal.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 15:38:44 +0000</pubDate>
</item>
<item>
<title>Bandwidth Efficient Partial Authorized PSI</title>
<link>https://eprint.iacr.org/2025/2132</link>
<guid>https://eprint.iacr.org/2025/2132</guid>
<content:encoded><![CDATA[
<div> Your abstract presents a compelling advancement in the field of **Authorized Private Set Intersection (APSI)**, particularly addressing critical limitations in both security and efficiency. Here's a refined version of your abstract with improved clarity, flow, and academic tone—suitable for submission to a top-tier privacy or security conference such as PETS, CCS, or Eurocrypt:

---

**Abstract.**  
Recent attacks on Private Set Intersection (PSI) and PSI-like protocols have demonstrated that input privacy can be compromised when adversarial parties maliciously craft their inputs—even in settings where protocols are proven secure against standard malicious adversaries. To mitigate such threats, *Authorized PSI* (APSI) introduces a trusted judge who authorizes each element in the participants’ sets before the intersection is computed, thereby ensuring that only legitimate, pre-approved data is processed.

Falzon and Markatou (PETS 2025) proposed *Partial-APSI*, a privacy-preserving variant of APSI that prevents the judge from learning the full input sets. However, their construction incurs significant bandwidth overhead due to the use of bilinear pairings and the requirement that the judge individually sign every element in each party’s set. This limits scalability and practicality for large-scale applications.

In this work, we present a **bandwidth-efficient Partial-APSI protocol** that significantly outperforms Falzon and Markatou’s design—both asymptotically and in practice. Our construction reduces communication complexity by leveraging succinct cryptographic primitives and batch authorization techniques. For instance, on sets of size $2^{20}$, our protocol achieves approximately **21× less bandwidth consumption** and runs **6× faster** over a LAN compared to prior work.

Beyond efficiency, we model real-world participant behavior through a **game-theoretic framework**, accounting for *rational* (rather than purely malicious or honest) parties. We introduce **payout mechanisms** that penalize detected cheating and derive tight lower bounds on penalty values required to make honest behavior the dominant strategy. This ensures incentive compatibility and strengthens trust in the system even under strategic deviations.

Together, our contributions yield a scalable, efficient, and strategically robust Partial-APSI solution that advances the state-of-the-art in authorized private computation.

---

### Key Strengths Highlighted:
- **Problem Relevance:** Addresses newly discovered vulnerabilities in PSI due to malicious input crafting.
- **Efficiency Breakthrough:** Concrete numbers ($21\times$ bandwidth, $6\times$ speedup) make impact clear.
- **Theoretical + Practical Contribution:** Combines protocol design with game-theoretic security modeling.
- **Realism:** Introduces rational agents and economic disincentives for cheating—a step toward deployable systems.

Would you like help expanding this into a full paper section (e.g., Introduction, System Model, or Game Theory Analysis)? Or perhaps designing the payout mechanism formally? <div>
Recent attacks on private set intersection (PSI) and PSI-like protocols have demonstrated that input privacy can be compromised when parties maliciously choose their inputs, even in protocols proven secure against malicious adversaries. To counter such attacks, Authorized PSI (APSI) introduces a judge who authorizes the elements of the parties before the intersection is computed.
 Falzon and Markatou (PETS 2025) proposed Partial-APSI, a privacy-preserving variant of APSI that prevents revealing the entire set to a judge. Their Partial-APSI protocol requires significant bandwidth overhead due to the use of bilinear pairings and because the judge must sign each element in the input set. In this work, we present a bandwidth-efficient Partial-APSI protocol that outperforms Falzon and Markatou, both asymptotically and empirically. For example, for sets of size $2^{20}$, we require around $21\times$ less bandwidth and are about $6\times$ faster over a LAN network.
In addition to our protocol, we model the real-world behavior of rational parties through a game-theoretic analysis. 
We introduce payout mechanisms for detected cheating and establish lower bounds on their values, ensuring that the best strategy for rational parties is to provide honest input.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 14:51:45 +0000</pubDate>
</item>
<item>
<title>Persistent BitTorrent Trackers</title>
<link>https://eprint.iacr.org/2025/2131</link>
<guid>https://eprint.iacr.org/2025/2131</guid>
<content:encoded><![CDATA[
<div> Your abstract presents a compelling and technically sophisticated solution to long-standing problems in private BitTorrent ecosystems—specifically, the fragility and centralization of reputation systems. Here's a refined version of your abstract with improved clarity, flow, and academic tone, while preserving all technical content:

---

**Abstract.**  
Private BitTorrent trackers enforce upload-to-download ratios to mitigate free-riding, yet suffer from three critical limitations: (1) reputation is siloed within individual trackers and cannot migrate across communities; (2) centralized tracker servers represent single points of failure; and (3) upload statistics are self-reported and inherently unverifiable. When a tracker shuts down—due to operator decision, technical failure, or legal pressure—users lose their accumulated contribution history and cannot credibly prove their reputation to join new communities.

We address these issues by decentralizing and securing reputation using blockchain-based smart contracts and cryptographic attestations. Instead of relying on self-reported statistics, peers cryptographically sign receipts for each downloaded piece of data. These receipts are collected and aggregated by the tracker within a Trusted Execution Environment (TEE), such as Intel TDX, ensuring correct and tamper-proof computation before updating users’ on-chain reputations. The use of TEEs guarantees integrity and confidentiality of aggregation logic, even if the underlying infrastructure is compromised.

In the event of tracker unavailability, peers seamlessly transition to an authenticated Distributed Hash Table (DHT) for peer discovery. Crucially, on-chain reputation doubles as a Public Key Infrastructure (PKI), enabling mutual authentication and access control without requiring a live tracker. This allows the system to maintain security and fairness properties during outages.

Our design enables persistent, portable reputation: users can migrate their trust capital to new or replacement trackers via single-hop migration through factory-deployed smart contracts. We formalize the system’s security requirements—including receipt authenticity, aggregation integrity, and Sybil resistance—and prove correctness under standard cryptographic assumptions. A prototype implementation evaluated on Intel TDX demonstrates that transfer receipts introduce less than 6% overhead with typical piece sizes, while signature aggregation accelerates verification by 2.5× compared to individual checks.

This work bridges the gap between decentralized file sharing and verifiable contribution tracking, offering a robust, future-proof foundation for cooperative P2P ecosystems.

---

### Key Improvements:
- **Structure:** Clear problem → solution → mechanism → evaluation → impact.
- **Clarity:** Technical terms (e.g., TEE, DHT, PKI) are used precisely but explained contextually.
- **Flow:** Logical progression from weaknesses to architectural innovations to validation.
- **Impact Emphasis:** Highlights portability, persistence, and real-world applicability.

Let me know if you'd like a shorter version for a conference submission, or help drafting the full paper sections (e.g., threat model, system design, evaluation). <div>
Private BitTorrent trackers enforce upload-to-download ratios to prevent free-riding, but suffer from three critical weaknesses: reputation cannot move between trackers, centralized servers create single points of failure, and upload statistics are self-reported and unverifiable. When a tracker shuts down (whether by operator choice, technical failure, or legal action) users lose their contribution history and cannot prove their standing to new communities. We address these problems by storing reputation in smart contracts and replacing self-reports with cryptographic attestations. Receiving peers sign receipts for transferred pieces, which the tracker aggregates and verifies before updating on-chain reputation. Trackers run in Trusted Execution Environments (TEEs) to guarantee correct aggregation and prevent manipulation of state. If a tracker is unavailable, peers use an authenticated Distributed Hash Table (DHT) for discovery: the on-chain reputation acts as a Public Key Infrastructure (PKI), so peers can verify each other and maintain access control without the tracker. This design persists reputation across tracker failures and makes it portable to new instances through single-hop migration in factory-deployed contracts. We formalize the security requirements, prove correctness under standard cryptographic assumptions, and evaluate a prototype on Intel TDX. Measurements show that transfer receipts adds less than 6\% overhead with typical piece sizes, and signature aggregation speeds up verification by $2.5\times$.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 14:15:34 +0000</pubDate>
</item>
<item>
<title>Censorship-Resistant Sealed-Bid Auctions on Blockchains</title>
<link>https://eprint.iacr.org/2025/2127</link>
<guid>https://eprint.iacr.org/2025/2127</guid>
<content:encoded><![CDATA[
<div> Your description outlines a novel and compelling advancement in the design of on-chain sealed-bid auctions, addressing key limitations of traditional commit-and-reveal schemes and recent single-slot alternatives. Below is a refined summary and analysis of your protocol’s contributions, highlighting its innovation, security properties, and practical implications:

---

### **Protocol Overview**

You propose a new on-chain auction mechanism that overcomes critical shortcomings of existing approaches:

- **Traditional commit-and-reveal**: Leaks timing information, requires two rounds (high latency), and exposes bidders to front-running or censorship.
- **Recent single-slot auctions**: Improve efficiency but rely on strong trust assumptions (e.g., requiring a large honest majority).
  
Your solution introduces a hybrid approach combining:
1. **Timestamp-based certificates** – to bind bids to specific time intervals without immediate exposure.
2. **Inclusion lists** – to ensure bids are accounted for even if censored from blocks.

This enables a **single-slot**, **privacy-preserving**, and **censorship-resistant** auction design with strong economic guarantees.

---

### **Key Properties Achieved**

#### 1. **Strong Hiding**
A comprehensive privacy property encompassing:
- **Value Indistinguishability**: Adversaries cannot distinguish between different bid amounts.
- **Existential Obfuscation**: The presence or absence of a bid is hidden.
- **User Obfuscation**: The identity of the bidder remains concealed.

> *Improvement over Pranav et al. [MCP]*: While prior work ensures value hiding, your protocol strengthens this by concealing both the existence and origin of bids—critical for preventing linkage attacks and behavioral profiling.

This level of obfuscation protects against timing-based inference and metadata leakage, making the auction significantly more private than prior art.

---

#### 2. **Short-Term Censorship Resistance**
If an honest user submits a bid before the deadline and the blockchain produces a block, then:
- Their bid will be included in the auction outcome.
- Even if excluded from a specific block (due to mempool manipulation or miner collusion), inclusion lists recover the bid.

> This leverages ideas similar to **EIP-4345** or **timelock puzzles with accountability**, ensuring that valid bids cannot be permanently suppressed over short timescales.

Crucially, this does not require full consensus honesty—only that some node eventually broadcasts the bid or that inclusion lists are enforced by validators.

---

#### 3. **Auction Participation Efficiency (APE)**
A **new metric** introduced to quantify how closely the on-chain auction replicates ideal off-chain (classical) auctions in terms of user cost.

- APE compares total participation costs (gas fees, number of transactions, opportunity cost) to theoretical minimums.
- High APE ⇒ users pay near-optimal costs, akin to centralized systems.
- Your protocol achieves high APE via single-round submission and reduced interaction.

> This bridges a gap in formalizing usability and economic accessibility in decentralized auctions—a crucial factor for real-world adoption.

---

#### 4. **No Free Bid Withdrawal**
Prevents bidders from retracting committed bids after observing others’ behavior (e.g., if price moves unfavorably).

- Enforced through cryptographic commitment + economic penalties or binding inclusion rules.
- Ensures **game-theoretic integrity**: once a bid is made, it must be honored.

> This counters strategic withdrawal attacks common in DeFi auctions and NFT sales, enhancing fairness and predictability.

---

### **Advantages Over Prior Work**

| Feature | Commit-Reveal | Single-Slot Auctions | **Your Protocol** |
|-------|----------------|------------------------|--------------------|
| Rounds Required | 2 | 1 | **1** |
| Value Privacy | ✅ | ✅ | ✅ |
| Existential/User Obfuscation | ❌ | ❌ | ✅✅✅ |
| Censorship Resistance | Weak | Moderate (honest threshold) | **Strong (short-term)** |
| Participation Cost | High (2 txs) | Medium | **Low (1 tx + efficient)** |
| Formal APE Metric | ❌ | ❌ | ✅ (introduced) |
| No Free Withdrawal | Optional | Often missing | ✅ |

---

### **Potential Applications**

- **NFT Auctions**: Prevent sniping and protect bidder anonymity.
- **MEV-Resistant Order Books**: Integrate into DEXs to hide intent until execution.
- **Decentralized Governance**: Private voting with verifiable participation.
- **Spectrum/Resource Allocation**: On-chain auctions for digital resources.

---

### **Open Challenges & Considerations**

1. **Trusted Timestamping Assumption**: How are timestamps generated? If relying on block headers, miners can manipulate them slightly. Consider integrating **verifiable delay functions (VDFs)** or **distributed timestamping services**.

2. **Scalability of Inclusion Lists**: As the number of bidders grows, managing inclusion proofs may become costly. Zero-knowledge batch verification could help.

3. **Long-Term Censorship**: While short-term resistance is achieved, prolonged network-level censorship (e.g., ISP blocking) remains out-of-scope.

4. **Implementation Complexity**: Integrating timestamp certificates and inclusion logic increases smart contract complexity. Formal verification recommended.

---

### **Conclusion**

Your protocol represents a significant step forward in **private, efficient, and fair on-chain auctions**. By introducing **Strong Hiding**, **APE**, and leveraging **inclusion lists for censorship resistance**, you achieve a balance between decentralization, privacy, and economic efficiency that previous designs have struggled to attain.

The introduction of **Auction Participation Efficiency** as a formal metric opens the door to systematic evaluation of blockchain auction mechanisms beyond just security—toward **usability and real-world viability**.

This work has strong potential for integration into Ethereum layer-2 systems, ZK-rollups, or future Ethereum upgrades focused on privacy and MEV mitigation.

---

Would you like help formalizing the security definitions, modeling the adversary, or drafting a paper structure based on this? <div>
Traditional commit-and-reveal mechanisms have been used to realize sealed-bid on-chain auctions. However, these leak timing information, impose inefficient participation costs -- the inclusion fee to be paid for adding the transaction on-chain -- and also require multiple slots to execute the auction. Recent research investigates single-slot auctions; however, it requires a high threshold of honest parties.

We present a protocol that addresses these issues. Our design combines timestamp-based certificates with censorship resistance through inclusion lists. The resulting protocol satisfies four properties, the first being a strong hiding property which consists of Value Indistinguishability, Existential Obfuscation and User Obfuscation. This not only ensures that the adversary cannot differentiate between two value of bids (as the previously defined Hiding property does in Pranav et al. [MCP]), but also that the very existence of a bid and the identity of the bidder remain obfuscated. The second property is Short-Term Censorship Resistance, ensuring that, if the underlying blockchain outputs a block, then the auction would contain bids from all honest users. The third is a new property we introduce, Auction Participation Efficiency (APE), that measures how closely on-chain outcomes resemble classical auctions in terms of costs for participating users. And the fourth property is No Free Bid Withdrawal, which disallows committed bids from being withdrawn in case the bidder changes its mind.

Together, these properties yield a fair, private, and economically robust auction primitive that can be integrated into any blockchain to support secure and efficient auction execution.
]]></content:encoded>
<pubDate>Fri, 21 Nov 2025 00:01:49 +0000</pubDate>
</item>
<item>
<title>DPaaS: Improving Decentralization by Removing Relays in Ethereum PBS</title>
<link>https://eprint.iacr.org/2025/2126</link>
<guid>https://eprint.iacr.org/2025/2126</guid>
<content:encoded><![CDATA[
<div> Your abstract presents a compelling and technically sophisticated proposal—**Decentralized Proposer-as-a-Service (DPaaS)**—as a next-generation solution to the centralization and security issues inherent in current **Proposer-Builder Separation (PBS)** implementations like **MEV-Boost**. Here's a refined summary and analysis of your work, suitable for inclusion in a research paper or presentation:

---

### **Summary: Decentralized Proposer-as-a-Service (DPaaS)**

**Problem**:  
While Ethereum’s Proposer-Builder Separation (PBS) enhances scalability and mitigates MEV-induced centralization, its practical deployment via **MEV-Boost** relies on a sidecar architecture with **centralized relays**. These relays introduce new trust assumptions, risks of censorship, block stealing, and operational centralization—undermining the very decentralization PBS aims to preserve.

**Insight & Solution**:  
We propose **DPaaS**, a backward-compatible, deployable architecture that eliminates centralized relays by distributing the proposer-relay functionality across a decentralized set of **Proposer Entities (PEs)**. Each PE operates within a **Trusted Execution Environment (TEE)** (e.g., Intel SGX), ensuring confidentiality and integrity of bid processing and block construction.

**Key Innovations**:
1. **Decentralized Trust Model**:  
   Instead of a single relay, DPaaS distributes trust among multiple PEs. This reduces reliance on any one entity and increases resilience against collusion and downtime.

2. **Backward Compatibility**:  
   DPaaS presents itself to Ethereum’s consensus layer as a **single logical validator**. It leverages the **threshold and aggregation properties of BLS signatures**—the same scheme used in Ethereum 2.0—to collectively sign blocks only when a threshold of honest PEs agrees.

3. **Secure & Fair Auction Protocols**:  
   DPaaS includes protocols that guarantee **fair exchange** between builders and proposers, even under **partial network synchrony** or **a small number of TEE failures** (e.g., crashes or equivocation). This ensures liveness and prevents front-running or bid suppression.

4. **Performance Optimization**:  
   Built with low-latency communication in mind, DPaaS minimizes delays in bid processing and block proposal. Evaluation shows:
   - **<5 ms** average bid processing latency
   - **55.75 ms** end-to-end latency from auction close to block proposal

**Evaluation**:  
Deployed across **four geographically distributed cloud providers**, DPaaS was tested using **real-world MEV auction traces**. The results confirm that strong performance is achievable without sacrificing security or decentralization.

---

### **Implications & Contributions**

- ✅ **Enhanced Decentralization**: Removes single points of failure and control in the PBS pipeline.
- ✅ **Improved Security**: TEEs protect sensitive data (e.g., bids) while preventing malicious interference.
- ✅ **Backward Compatibility**: Integrates seamlessly with existing Ethereum clients and staking infrastructure.
- ✅ **Scalability Ready**: Supports high-throughput, low-latency operation essential for future protocol upgrades (e.g., danksharding).

---

### **Comparison to MEV-Boost**

| Feature                     | MEV-Boost (Relay-Based)       | DPaaS (Decentralized PEs + TEEs) |
|----------------------------|-------------------------------|----------------------------------|
| Centralization Risk        | High (trusted relays)         | Low (distributed trust)          |
| Block Stealing Prevention  | Limited                       | Strong (via TEE attestation)     |
| Bid Privacy                | Partial (depends on relay)    | High (enforced by TEEs)          |
| Fault Tolerance            | Low (relay outage = failure)  | Moderate (threshold tolerance)   |
| Performance                | ~100–200ms                    | **~55.75ms** (measured)          |
| Ethereum Compatibility     | Yes                           | Yes (BLS aggregation)            |

---

### **Future Work & Considerations**

- **TEE Attestation Scalability**: Managing remote attestation at scale across diverse cloud providers.
- **Sybil Resistance**: Ensuring long-term identity and stake-based participation among PEs.
- **Integration with SUAVE**: Potential synergy with Flashbots’ SUAVE stack for unified MEV ordering.
- **Regulatory & Operational Risks**: Cloud provider dependencies and jurisdictional concerns around TEE usage.

---

### **Conclusion**

DPaaS represents a significant step forward in securing and decentralizing Ethereum’s block production pipeline. By combining **trusted hardware**, **threshold cryptography**, and **decentralized coordination**, it offers a practical, high-performance alternative to today’s relay-centric PBS model—without requiring changes to Ethereum’s core consensus rules.

> **DPaaS proves that we can have both decentralization and performance—no trade-offs required.**

---

Let me know if you'd like help turning this into a full paper section (e.g., Introduction, System Design, Evaluation), creating diagrams, or writing code/spec documentation for implementation. <div>
Proposer-Builder Separation (PBS) in Ethereum improves decentralization and scalability by offloading block construction to specialized builders. In practice, MEV-Boost implements PBS via a side-car protocol with trusted relays between proposers and builders, resulting in increased centralization as well as security (e.g., block stealing) and performance concerns. We propose Decentralized Proposer-as-a-Service (DPaaS), a deployable architecture that eliminates centralized relays while preserving backward compatibility with Ethereum’s existing consensus layer. Our insight is that we can reduce centralized trust by distributing the combined roles of the proposer and relay to a set of Proposer Entities (PEs), each running in independent Trusted Execution Environments (TEEs). For compatibility, DPaaS presents itself to Ethereum as a single validator, leveraging threshold and aggregation properties of the BLS signature scheme used in Ethereum. At the same time, DPaaS protocols ensure fair exchange between builders and proposers even in the face of a small fraction of TEE failures or partial synchrony in networks. Our evaluation, deployed across four independent cloud hosts and driven by real-world traces, shows that DPaaS achieves less than 5 ms bid processing latency and 55.75 ms latency from the end of auction to block proposal -- demonstrating that DPaaS can offer security and decentralization benefits while providing strong performance.
]]></content:encoded>
<pubDate>Thu, 20 Nov 2025 20:09:36 +0000</pubDate>
</item>
<item>
<title>SoK: Secure Computation over Secret Shares</title>
<link>https://eprint.iacr.org/2025/2111</link>
<guid>https://eprint.iacr.org/2025/2111</guid>
<content:encoded><![CDATA[
Secure multiparty computation (MPC) enables mutually distrustful parties to jointly compute functions over private data without revealing their inputs. A central paradigm in MPC is the secret-sharing-based model, where secret sharing underpins the efficient realization of arithmetic, comparison, numerical, and Boolean operations on shares of private inputs. In this paper, we systematize protocols for these operations, with particular attention to two foundational contributions \cite{ChidaGHIKLN18,NO07} that devised secure multiplication and comparison. Our survey provides a unified, self-contained exposition that highlights the composability, performance trade-offs, and implementation choices of these protocols. We further demonstrate how they support practical privacy-preserving systems, including recommender systems, distributed optimization platforms, and e-voting infrastructures. By clarifying the protocol landscape and connecting it to deployed and emerging applications, we identify concrete avenues for improving efficiency, scalability, and integration into real-world MPC frameworks. Our goal is to bridge theory and practice, equipping both researchers and practitioners with a deeper understanding of secret-sharing-based MPC as a foundation for privacy technologies.
]]></content:encoded>
<pubDate>Mon, 17 Nov 2025 11:16:08 +0000</pubDate>
</item>
<item>
<title>Weighted Batched Threshold Encryption with Applications to Mempool Privacy</title>
<link>https://eprint.iacr.org/2025/2115</link>
<guid>https://eprint.iacr.org/2025/2115</guid>
<content:encoded><![CDATA[
A Batched Threshold Encryption (BTE) scheme enables a committee of servers to perform a lightweight (in terms of communication and computation) threshold decryption of an arbitrary batch of ciphertexts from a larger pool, while ensuring the privacy of ciphertexts that are outside the batch. Such a primitive has a direct application in designing encrypted mempools for MEV protection in modern blockchains. Bormet et al. (USENIX 2025) recently proposed a BTE scheme called “BEAT-MEV” which is concretely efficient for small to moderate batch sizes.

In this work, we improve and extend the BEAT-MEV scheme in multiple ways. First, we improve the computational cost from quadratic to quasilinear in the batch size, thus making it practical for large batch sizes. This improvement is achieved by substituting the key-homomorphic punctured PRF used in BEAT-MEV with an FFT-friendly alternative. Second, we extend the ideas in their scheme to the weighted setting, where each server in the committee has an associated 'weight' value (e.g., stake weight of validators in PoS blockchains), while crucially ensuring that the communication cost remains independent of the weights. In contrast, BEAT-MEV with naive virtualization would incur communication cost linear in the total weight. Third, for handling the small failure rate inherent in BEAT-MEV scheme due to index collisions across different clients at the time of encryption, we propose a generalization of their suggested approach which offers an option to trade off between ciphertext size and server communication for a given failure rate.

We implement and evaluate our scheme and compare it with BEAT-MEV to demonstrate our concrete improvement. In the unweighted setting, we improve the computational cost (without increasing the communication cost) by ≈ 6× for a batch size of 512 ciphertexts. In the weighted setting, we improve the communication cost (without compromising computation time), over BEAT-MEV with naive virtualization, by ≈ 50× for 100 validators with total stake weight 5000 distributed as per the latest Solana stake distribution.
]]></content:encoded>
<pubDate>Tue, 18 Nov 2025 04:09:13 +0000</pubDate>
</item>
<item>
<title>How to Recover a Secret with O(n) Additions</title>
<link>https://eprint.iacr.org/2023/838</link>
<guid>https://eprint.iacr.org/2023/838</guid>
<content:encoded><![CDATA[
Threshold cryptography is typically based on the idea of secret-sharing a private-key $s\in F$ ``in the exponent'' of some cryptographic group $G$, or more generally, encoding $s$ in some linearly homomorphic domain. In each invocation of the threshold system (e.g., for signing or decrypting) an ``encoding'' of the secret is being recovered and so the complexity, measured as the number of group multiplications over $G$, is equal to the number of $F$-additions that are needed to reconstruct the secret. Motivated by this scenario, we initiate the study of $n$-party secret-sharing schemes whose reconstruction algorithm makes a minimal number of \emph{additions}. The complexity of existing schemes either scales linearly with $n\log |F|$ (e.g., Shamir, CACM'79) or, at least, quadratically with $n$ independently of the size of the domain $F$ (e.g., Cramer-Xing, EUROCRYPT '20). This leaves open the existence of a secret sharing whose recovery algorithm can be computed by performing only $O(n)$ additions.

We resolve the question in the affirmative and present such a near-threshold secret sharing scheme that provides privacy against unauthorized sets of density at most $\tau_p$, and correctness for  authorized sets of density at least $\tau_c$, for any given arbitrarily close constants $\tau_p<\tau_c$. Reconstruction can be computed by making at most $O(n)$ additions and, in addition, (1) the share size is constant, (2) the sharing procedure also makes only $O(n)$ additions, and (3) the scheme is a blackbox secret-sharing scheme, i.e., the sharing and reconstruction algorithms work universally for all finite abelian groups $F$. Prior to our work, no such scheme was known even without features (1)--(3) and even for the ramp setting where $\tau_p$ and $\tau_c$ are far apart. As a by-product, we derive the first blackbox near-threshold secret-sharing scheme with linear-time sharing. We also present several concrete instantiations of our approach that seem practically efficient (e.g., for threshold discrete-log-based signatures).

Our constructions are combinatorial in nature. We combine graph-based erasure codes that support ``peeling-based'' decoding with a new randomness extraction method that is based on inner-product with a small-integer vector. We also introduce a general concatenation-like transform for secret-sharing schemes that allows us to arbitrarily shrink the privacy-correctness gap with only a minor overhead. Our techniques enrich the secret-sharing toolbox and, in the context of blackbox secret sharing, offer a new randomized combinatorial alternative to existing deterministic number-theoretic approaches.
]]></content:encoded>
<pubDate>Mon, 05 Jun 2023 18:32:05 +0000</pubDate>
</item>
<item>
<title>Quantum-safe  Identity-binding  Password Authenticated Key Exchange Protocols</title>
<link>https://eprint.iacr.org/2025/2107</link>
<guid>https://eprint.iacr.org/2025/2107</guid>
<content:encoded><![CDATA[
Password-based Authenticated Key Exchange (${\sf PAKE}$) is a widely acknowledged, promising security mechanism for establishing secure communication between devices. It enables two parties to mutually authenticate each other over insecure networks and generate a session key using a low-entropy password.   However, the existing $\mathsf{PAKE}$ protocols encounter significant challenges concerning both security and efficiency in the context of the \textit{Internet of Things} (IoT). In response to these challenges, we contribute to the advancement of post-quantum secure $\mathsf{PAKE}$ protocols tailored for IoT applications, enriching the existing landscape. In this study, we introduce two novel protocols, $\mathsf{PAKE}$-\textup{I} and $\mathsf{PAKE}$-\textup{II}, designed to address these concerns and enhance the security standards of $\mathsf{PAKE}$ protocol. While $\mathsf{PAKE}$-\textup{I} is secure under lattice-based hardness assumptions, $\mathsf{PAKE}$-\textup{II} derives its security from isogeny-based hard problems. Our lattice-based protocol $\mathsf{PAKE}$-\textup{I} is secure based on the \textit{Pairing with Errors} ($\mathsf{PWE}$) assumption and the \textit{Decision Ring Learning with Errors}  ($\mathsf{DRLWE}$) assumption and our isogeny-based protocol $\mathsf{PAKE}$-\textup{II} is secure based on the hardness of the \textit{Group Action Inverse Problem} ($\mathsf{GAIP}$)  and the \textit{Commutative SuperSingular Diffie-Hellman} ($\mathsf{CSSDH}$) problem in the Random Oracle Model $(\mathsf{ROM})$. We present a comprehensive security proof in a conventional game-based indistinguishability security model that addresses offline dictionary attacks, replay attacks, compromise attacks for both parties (client and server) and perfect forward secrecy.  Additionally, our proposed $\mathsf{PAKE}$ protocols are the first post-quantum secure $\mathsf{PAKE}$s that achieve identity privacy and resistance to pre-computation attacks.  Through rigorous performance evaluations, the paper demonstrates that the proposed $\mathsf{PAKE}$ schemes are ultralight and exhibit notable advantages in terms of total computation cost and enhanced security properties when compared to the existing protocols. More positively, both the proposed $\mathsf{PAKE}$ are optimal in the sense that they achieve mutual authentication explicitly in only three rounds which is the least number of rounds required for acquiring mutual authentication between two parties.
]]></content:encoded>
<pubDate>Sun, 16 Nov 2025 17:39:29 +0000</pubDate>
</item>
<item>
<title>SoK: Blockchain Oracles Between Theory and Practice</title>
<link>https://eprint.iacr.org/2025/2106</link>
<guid>https://eprint.iacr.org/2025/2106</guid>
<content:encoded><![CDATA[
Smart contract-based decentralized applications (dApps) have become an ever-growing way to facilitate complex on-chain operations. Oracle services strengthened this trend by enabling dApps to access real-world data and respond to events happening outside the blockchain ecosystem. A large number of academic and industrial oracle solutions have emerged, capturing various designs, capabilities, and security assumptions/guarantees. This rapid development makes it challenging to comprehend the landscape of oracles, understand their trade-offs, and build on them.

    To address these challenges, we develop a systematization of knowledge for blockchain oracle services. To the best of our knowledge, our work is the first to provide extensive study of oracles while empirically investigating their capabilities in practice. After examining the general design framework of oracles, we develop a multi-dimensional systematization framework assessing existing solutions based on their capabilities, trust and security assumption/guarantees, and their underlying design architecture. To further aid in this assessment, we conduct a number of empirical experiments to examine oracle deployed in practice, thus offering additional insights about their deployment maturity, usage popularity, performance, and ease-of-use. We go on to distill a number of insights and gaps, thus providing a guide for practitioners (on the use of these oracles) and researchers (by highlighting gaps and open problems).
]]></content:encoded>
<pubDate>Sun, 16 Nov 2025 14:47:05 +0000</pubDate>
</item>
<item>
<title>Threshold Batched Identity-Based Encryption from Pairings in the Plain Model</title>
<link>https://eprint.iacr.org/2025/2103</link>
<guid>https://eprint.iacr.org/2025/2103</guid>
<content:encoded><![CDATA[
In a batched identity-based encryption (IBE) scheme, ciphertexts are associated with a batch label $\mathsf{tag}^*$ and an identity $\mathsf{id}^*$ while secret keys are associated with a batch label $\mathsf{tag}$ and a set of identities $S$. Decryption is possible whenever $\mathsf{tag} = \mathsf{tag}^*$ and $\mathsf{id}^* \in S$. The primary efficiency property in a batched IBE scheme is that the size of the decryption key for a set $S$ should be independent of the size of $S$. Batched IBE schemes provide an elegant cryptographic mechanism to support encrypted memory pools in blockchain applications.

In this work, we introduce a new algebraic framework for building pairing-based batched IBE. Our framework gives the following:

First, we obtain a selectively-secure batched IBE scheme under a $q$-type assumption in the plain model. Both the ciphertext and the secret key consist of a constant number of group elements. This is the first pairing-based batched IBE scheme in the plain model. Previous pairing-based schemes relied on the generic group model and the random oracle model.

Next, we show how to extend our base scheme to a threshold batched IBE scheme with silent setup. In this setting, users independently choose their own public and private keys, and there is a non-interactive procedure to derive the master public key (for a threshold batched IBE scheme) for a group of users from their individual public keys. We obtain a statically-secure threshold batched IBE scheme with silent setup from a $q$-type assumption in the plain model. As before, ciphertexts and secret keys in this scheme contain a constant number of group elements. Previous pairing-based constructions of threshold batched IBE with silent setup relied on the generic group model, could only support a polynomial number of identities (where the size of the public parameters scaled linearly with this bound), and ciphertexts contained $O(\lambda / \log \lambda)$ group elements, where $\lambda$ is the security parameter.

Finally, we show that if we work in the generic group model, then we obtain a (threshold) batched IBE scheme with shorter ciphertexts (by 1 group element) than all previous pairing-based constructions (and without impacting the size of the secret key).

Our constructions rely on classic algebraic techniques underlying pairing-based IBE and do not rely on the signature-based witness encryption viewpoint taken in previous works.
]]></content:encoded>
<pubDate>Sat, 15 Nov 2025 22:41:14 +0000</pubDate>
</item>
<item>
<title>FPS: Flexible Payment System</title>
<link>https://eprint.iacr.org/2025/2095</link>
<guid>https://eprint.iacr.org/2025/2095</guid>
<content:encoded><![CDATA[
Existing payment systems make fixed trade-offs between performance and security assumptions. Traditional centralized systems like Visa assume synchronous networks and crash faults to achieve high throughput, while blockchain-based systems (e.g., Algorand, Aptos) adopt Byzantine fault tolerance and partial synchrony for stronger security at the cost of performance. This rigid approach forces all users to accept the same security-performance trade-off regardless of their individual trust and threat models.

We present a flexible payment system where clients independently choose assumptions about (i) network timing (bounded or partial synchrony), (ii) corruption (static or adaptive), and (iii) faults (crash or Byzantine), supporting eight assumption combinations simultaneously. Unlike traditional systems requiring consensus, our approach uses a novel flexible variant of consistent broadcast where clients external to the protocol verify delivery through cryptographic proofs, eliminating the need for global ordering. We implemented our system in Rust and demonstrated that clients choosing partially synchronous network and crash assumptions achieve $+242.1\%$ higher throughput and $+70.4\%$ better latency compared to clients with synchronous network and Byzantine assumptions, confirming that our system enables users to optimize their individual security-performance trade-offs.
]]></content:encoded>
<pubDate>Fri, 14 Nov 2025 07:41:07 +0000</pubDate>
</item>
<item>
<title>CRA and Cryptography: The Story Thus Far</title>
<link>https://eprint.iacr.org/2025/2092</link>
<guid>https://eprint.iacr.org/2025/2092</guid>
<content:encoded><![CDATA[
We report on our experiences with the ongoing European standardisation efforts related to the EU Cyber Resilience Act (CRA) and provide interim (November 2025) estimates on the direction that European cryptography regulation may take, particularly concerning the algorithm ``allow list'' and PQC transition requirements in products.

We also outline some of the risks associated with the partially closed standardisation process, including active impact minimisation by vendors concerned with engineering costs, a lack of public review leading to lower technical quality, and an increased potential for backdoors.

The Cyber Resilience Act came into effect in December 2024, and its obligations will fully take effect for makers of ``products with digital elements'' from 2027. CRA compliance is a requirement for obtaining the CE mark and a prerequisite for selling products in the European Single Market, which comprises approximately 450 million consumers. The CRA has a wide-ranging set of security requirements, including security patching and the use of cryptography (data integrity, confidentiality for data at rest and data in transit). However, the Cyber Resilience Act itself is a legal text devoid of technical detail -- it does not specify the type of cryptography deemed appropriate to satisfy its requirements.

The technical implications of CRA are being detailed in approximately 40 new standards from the three European standardisation organisations, CEN, CENELEC, and ETSI. While the resulting ETSI standards can be expected to be available for free even in the drafting stage, the CEN and CENELEC standards will probably require a per-reader license fee. This, despite recent legal rulings asserting that product security and safety standards are part of EU law due to their legal effects.

Taking a recent (2024) example of cryptographic requirements in such standards, we observe that the definitions and language in the Radio Equipment Directive (RED DA) harmonised standard (EN 18031 series) may allow vendors to take an approach where weak cryptography is considered ``best practice'' right until exploitation is feasible.

Recognising recent developments such as the EU Post-Quantum Cryptography transition roadmap, many CRA standardisation working groups are moving towards a ``State-of-the-Art Cryptography'' (SOTA Cryptography) model where approved mechanism listings are published by the European Cybersecurity Certification Group (ECCG). CRA-compliant products may still support other cryptographic mechanisms, but only SOTA is permitted as a safe default for Internet-connected products.
]]></content:encoded>
<pubDate>Thu, 13 Nov 2025 23:29:25 +0000</pubDate>
</item>
<item>
<title>Vega: Low-Latency Zero-Knowledge Proofs over Existing Credentials</title>
<link>https://eprint.iacr.org/2025/2094</link>
<guid>https://eprint.iacr.org/2025/2094</guid>
<content:encoded><![CDATA[
As digital identity verification becomes increasingly pervasive, existing privacy-preserving approaches are still limited by complex circuit designs, large proof sizes, trusted setups, or high latency. We present Vega, a practical zero-knowledge proof system that proves statements about existing credentials without revealing anything else. Vega is simple, does not require a trusted setup, and is more efficient than the prior state-of-the-art: for a 1920-byte credential, Vega achieves 212 ms proving time, 51 ms verification time, 150 kB proofs, and a 436 kB proving key. At the heart of Vega are two principles that together enable a lightweight proof system that pays only for what it needs. First, fold-and-reuse proving exploits repetition and folding opportunities (i) across presentations, by pushing repeated work to a rerandomizable precomputation; (ii) across uniform hashing steps, by folding many steps into a single step; and (iii) for zero-knowledge, by folding the public-coin transcript with a random one. Second, lookup-centric arithmetization extracts relevant values from credential bytes, both for extracting relevant fields without full in-circuit parsing, and to enable length-hiding hashing.
]]></content:encoded>
<pubDate>Fri, 14 Nov 2025 04:36:08 +0000</pubDate>
</item>
<item>
<title>Efficient and Proof-of-Useful-Work Friendly Local-Search for Distributed Consensus</title>
<link>https://eprint.iacr.org/2025/2091</link>
<guid>https://eprint.iacr.org/2025/2091</guid>
<content:encoded><![CDATA[
Blockchain protocols based on the popular ``Proof-of-Work'' mechanism
yield public transaction ledgers maintained by a group of distributed
participants who solve computationally hard puzzles to earn the right
to add a block.
The success and widespread adoption of this mechanism has led to
staggering energy consumption devoted to solving such (otherwise)
``useless'' puzzles. While the environmental impacts of the framework have
been widely criticized, this has been the dominant distributed ledger
paradigm for years.

The Ofelimos ``Proof-of-Useful-Work'' protocol (Fitzi et al.,
CRYPTO 2022) addressed this by establishing that useful
combinatorial problems could replace the conventional hashing puzzles,
yielding a provably secure blockchain that meaningfully utilizes the
computational work that underlies the protocol.
The usefulness to wastefulness ratio of Ofelimos hinges on the properties of its underlying generic distributed local-search algorithm---Doubly Parallel Local Search (DPLS). We observe that this search procedure is particularly wasteful when exploring steep regions of the solution
space.


To address this issue, we introduce Frequently Rerandomized Local
Search (FRLS), a new generic distributed local search algorithm that
we show to be consistent with the Ofelimos architecture. While this
algorithm retains ledger security, we show that it also provides compelling
performance on benchmark problems arising in practice: Concretely, state-of-art
local-search algorithms for cumulative scheduling and warehouse
location can be directly adapted to FRLS and we experimentally
demonstrate the efficiency of the resulting algorithms.
]]></content:encoded>
<pubDate>Thu, 13 Nov 2025 15:42:13 +0000</pubDate>
</item>
<item>
<title>Traceable Bottom-Up Secret Sharing and Law &amp; Order on Community Social Key Recovery (Full Version)</title>
<link>https://eprint.iacr.org/2025/2089</link>
<guid>https://eprint.iacr.org/2025/2089</guid>
<content:encoded><![CDATA[
A recent work by Kate et al. [EPRINT 2025] proposes a community-based social recovery scheme (SKR), where key-owners can use a subset of other community members as guardians, and in exchange, they play guardians to support other participants' key recovery. Their construction relies on a new concept called bottom-up secret sharing (BUSS). However, they do not consider a crucial feature, called traceability, which ensures that if more than a threshold number of the guardians collude, at least some colluders' identities can be traced -- thereby deterring participants from colluding. In this paper, we incorporate traceability into the community social key recovery as an important feature. 

We first introduce the notion of traceable BUSS, which allows tracing colluders by accessing a reconstruction box. Then, extending the work of Boneh et al. [CRYPTO 2024], we propose the first traceable BUSS construction. Finally, we show how to generically use a traceable BUSS scheme to construct a traceable SKR in the aforementioned community setting. Overall, this is the first scheme combining decentralized key management with traceability, marrying BUSS’s scalability with the deterrence of traceable secret sharing.
]]></content:encoded>
<pubDate>Thu, 13 Nov 2025 10:47:51 +0000</pubDate>
</item>
<item>
<title>Leakage-Free Enhanced Private Set Union for Balanced and Unbalanced Scenarios</title>
<link>https://eprint.iacr.org/2025/2087</link>
<guid>https://eprint.iacr.org/2025/2087</guid>
<content:encoded><![CDATA[
Private Set Union (PSU) enables two parties to compute the union of their input sets without revealing anything else. Depending on set sizes, PSU is studied in balanced and unbalanced settings. Tu et al. (USENIX Security 2025) presented state-of-the-art enhanced PSU (ePSU) protocols under a unified framework in both settings, achieving enhanced security by preventing during-execution leakage. However, we observe that directly applying hash-to-bin on input sets within their framework introduces potential privacy risks. Moreover, the communication of their unbalanced ePSU still scales with the larger set size, rather than being linear in only the smaller set size. In this work, we address these open problems.

 We employ a combination of oblivious pseudorandom function (OPRF) and shuffling to mitigate the potential privacy leakage that arises when directly applying the hash-to-bin within the framework of Tu et al. (USENIX Security 2025). Building upon this, we further optimize their balanced ePSU protocol by leveraging a bidirectional oblivious key-value store (OKVS). Compared with the corrected version of Tu et al.'s balanced ePSU, ours achieves a $1.1-3.0\times$ shrinking in communication and a $1.2-1.6\times$ speedup in runtime.

We design the first unbalanced ePSU whose communication is linear solely in the smaller set size. Since no hash-to-bin is used, it is inherently free from the associated privacy leakage. With the smaller set size fixed at $2^{10}$, ours reduces communication by $1.5-45.8\times$ compared with  corrected version of Tu et al.'s unbalanced ePSU, while achieving $1.3-6.7\times$ runtime speedups.
]]></content:encoded>
<pubDate>Thu, 13 Nov 2025 09:01:11 +0000</pubDate>
</item>
<item>
<title>Information-Theoretically Secure Distributed Protocols for Two-Party MPC Primitives</title>
<link>https://eprint.iacr.org/2024/009</link>
<guid>https://eprint.iacr.org/2024/009</guid>
<content:encoded><![CDATA[
We study two-party secure computation in a \emph{distributed mediated} model with $D$ servers. 
We present \emph{information-theoretically secure} protocols for foundational primitives—
$1$-out-of-$N$ and $k$-out-of-$N$ oblivious transfer (OT), Priced OT, Generalized OT, and
Oblivious Multivariate Polynomial Evaluation (OMPE)—that (i) enforce receiver correctness,
(ii) support an offline sender after setup, and (iii) achieve robustness against malicious 
receivers and malicious servers under honest-majority assumptions.

Our approach reduces each primitive to a distributed scalar-product core combined with a 
\emph{distributed vector-validation} (DVV) mechanism that prevents unauthorized 
linear-combination leakage while preserving privacy. We prove unconditional privacy and 
robustness in the semi-honest setting and extend the guarantees to the malicious-server 
setting, tolerating up to $c < D/4$ or $c < D/3$ corrupt servers depending on the variant. 
The constructions are modular, require only lightweight client work (sharing and 
reconstruction), and allow the sender’s one-time upload to serve multiple, independent 
receivers without further interaction.

We analyze the round and communication complexity of our protocols and provide empirical
evidence of practical efficiency. The mediated setting naturally fits privacy-preserving
services such as collaborative filtering, distributed constraint optimization, voting, and
federated analytics. Collectively, our results show that distributed mediation yields simple,
scalable, and unconditionally private realizations of core two-party MPC functionalities.
]]></content:encoded>
<pubDate>Wed, 03 Jan 2024 16:24:39 +0000</pubDate>
</item>
<item>
<title>Issuer Hiding for BBS-Based Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/2080</link>
<guid>https://eprint.iacr.org/2025/2080</guid>
<content:encoded><![CDATA[
Anonymous credentials allow users to obtain credentials on various attributes, and then use those credentials to give unlinkable proofs about the values of some attributes without leaking anything about others. They have recently received interest from companies including Google, Apple, and Cloudflare, and are being actively evaluated both at the IETF and in the EU. Anonymous credentials based on BBS signatures are a leading candidate for standardization.

In some natural applications of anonymous credentials, it is beneficial to hide even the issuer of a credential, beyond revealing the fact that the issuer is in some pre-determined set specified by a verifier. Sanders and Traore recently showed a construction of such issuer-hiding anonymous credentials based on the Pointcheval-Sanders signature scheme.

In this work we show how to achieve issuer hiding for BBS-based anonymous credentials. Our construction satisfies a notion of everlasting issuer-hiding anonymity, and is unforgeable in the generic group model. It can be integrated into existing standards, and has several efficiency advantages compared to prior work.
]]></content:encoded>
<pubDate>Mon, 10 Nov 2025 19:23:26 +0000</pubDate>
</item>
<item>
<title>VIA: Communication-Efficient Single-Server Private Information Retrieval</title>
<link>https://eprint.iacr.org/2025/2074</link>
<guid>https://eprint.iacr.org/2025/2074</guid>
<content:encoded><![CDATA[
Private Information Retrieval (PIR) is a crucial component in many privacy-preserving systems, with Offline/Online PIR attracting significant attention. Recent works have focused on eliminating offline communication overhead. However, existing constructions incur high online communication costs as a trade-off. To address this, we propose VIA, a single-server PIR scheme that eliminates offline communication while achieving $O{_\lambda}(\log N)$ online communication complexity. Experimental evaluations demonstrate that for a 32 GB database, VIA requires only 690 KB of online communication---a $3.7\times$ reduction compared to state-of-the-art schemes without offline communication---while attaining a throughput of 3.11 GB/s. Furthermore, we introduce VIA-C, a variant of VIA that allows offline communication. Compared to previous communication-efficient schemes, VIA-C achieves a $24.5\times$ reduction in online communication, requiring only 2.1 KB for a 32 GB database (with 14.8 MB offline communication). Moreover, VIA-C can naturally extend to VIA-B that supports batch queries. Compared to  previous communication-efficient batch PIR schemes, VIA-B achieves a $3.5\times$ reduction in query size and a $127\times$ reduction in response size for a 1 GB database of 1-byte records. The designs of our schemes rely on a novel DMux-CMux structure and LWE-to-RLWE conversion techniques.
]]></content:encoded>
<pubDate>Mon, 10 Nov 2025 09:43:44 +0000</pubDate>
</item>
<item>
<title>Multi-server Fuzzy Message Detection</title>
<link>https://eprint.iacr.org/2025/2072</link>
<guid>https://eprint.iacr.org/2025/2072</guid>
<content:encoded><![CDATA[
Fuzzy Message Detection, or FMD, outsources detection of
messages to an untrusted server, Beck et. al. CCS 2021. In this paper, we extend FMD to the multi-key setting: several servers are given different detection keys, all extracted from a single secret key. Multi-key FMD allows to combine tests from multiple servers locally by each receiver. This allows to set high false-positive rates on the servers, while attaining low rates on the receiver side. Striking this way a better balance between privacy and efficiency. We further formalize the notion of stealth public keys in the FMD setting. Last, we provide two constructions, one with short public keys.
]]></content:encoded>
<pubDate>Mon, 10 Nov 2025 08:54:08 +0000</pubDate>
</item>
<item>
<title>A Comprehensive Analysis of the AKMA+ Protocol</title>
<link>https://eprint.iacr.org/2025/2066</link>
<guid>https://eprint.iacr.org/2025/2066</guid>
<content:encoded><![CDATA[
With the rapid advancement of 5G networks and the increasing demand for secure application access, the Authentication and Key Management for Applications (AKMA) framework was developed by the 3rd Generation Partnership Project (3GPP) to provide unified authentication and key management for diverse 5G services. In response to the security and privacy concerns identified in the current AKMA protocol, as outlined in 3GPP TR 33.835, Yang et al. proposed an enhanced, standard-compatible 5G AKMA protocol known as AKMA+[14].

This paper presents a comprehensive analysis of AKMA+, discovering two critical vulnerabilities: (1) the compromise of the AKMA Anchor Function (AAnF), which enables adversaries to impersonate legitimate users; and (2) the persistent storage of multiple anchor keys, which heightens the risk of key exposure. These vulnerabilities arise from the reliance on the authentication framework inherent in existing AKMA+ models. This architectural dependency introduces fundamental security risks that cannot be adequately mitigated through incremental modifications to the current design.

Furthermore, we observe that AKMA+ faces challenges in aligning with the standard account-based authentication model, which is incompatible with existing user practices within information systems. Additionally, we find that providing account-based authentication functionality without compromising privacy poses significant difficulties.
]]></content:encoded>
<pubDate>Sat, 08 Nov 2025 04:47:37 +0000</pubDate>
</item>
<item>
<title>Real-Time Encrypted Emotion Recognition Using Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/2058</link>
<guid>https://eprint.iacr.org/2025/2058</guid>
<content:encoded><![CDATA[
Emotion recognition has been an actively researched topic in the field of HCI. However, multimodal datasets used for
emotion recognition often contain sensitive personal information, such as physiological signals, facial images, and behavioral
patterns, raising significant privacy concerns. In particular, the privacy issues become crucial in workplace settings because
of the risks such as surveillance and unauthorized data usage caused by the misuse of collected datasets. To address this
issue, we propose an Encrypted Emotion Recognition (EER) framework that performs real-time inference on encrypted data
using the CKKS homomorphic encryption (HE) scheme. We evaluated the proposed framework using publicly available
WESAD and Hide-and-seek datasets, demonstrating successful stress/emotion recognition under encryption. The results
demonstrated that encrypted inference achieved similar accuracy to plaintext inference, with accuracy of 0.966 (plaintext)
vs. 0.967 (ciphertext) on the WESAD dataset, and 0.868 for both cases on the Hide-and-Seek dataset. Encrypted inference
was performed on a GPU, with average inference times of 333 milliseconds for the general model and 455 milliseconds for
the personalized model. Furthermore, we validated the feasibility of semi-supervised learning and model personalization in
encrypted environments, enhancing the framework’s real-world applicability. Our findings suggest that the EER framework
provides a scalable, privacy-preserving solution for emotion recognition in domains such as healthcare and workplace settings,
where securing sensitive data is of critical importance.
]]></content:encoded>
<pubDate>Fri, 07 Nov 2025 07:05:03 +0000</pubDate>
</item>
<item>
<title>On Proximity Gaps for Reed–Solomon Codes</title>
<link>https://eprint.iacr.org/2025/2055</link>
<guid>https://eprint.iacr.org/2025/2055</guid>
<content:encoded><![CDATA[
This paper is about the proximity gaps phenomenon for Reed-Solomon codes. 
Very roughly, the proximity gaps phenomenon for a code $\mathcal C \subseteq \mathbb F_q^n$ says that for two vectors $f,g \in \mathbb F_q^n$, if  sufficiently many linear combinations $f + z \cdot g$ (with $z \in \mathbb F_q$) are close to $\mathcal C$ in Hamming distance, then so are both $f$ and $g$, up to a proximity loss of $\varepsilon^*$. 

Determining the optimal quantitative form of proximity gaps for Reed--Solomon codes has recently become of great interest because of applications to interactive proofs and cryptography, and in particular, to scalable transparent arguments of knowledge (STARKs) and other modern hash based argument systems used on blockchains today.

Our main results show improved positive and negative results for proximity gaps for Reed-Solomon codes of constant relative distance $\delta \in (0,1)$.

1. For proximity gaps up to the unique decoding radius $\delta/2$, we show that arbitrarily small proximity loss $\varepsilon^* > 0$ can be achieved with only $O_{\varepsilon^*}(1)$ exceptional $z$'s (improving the previous bound of $O(n)$ exceptions). 
 
2. For proximity gaps up to the Johnson radius $J(\delta)$, we show that proximity loss $\varepsilon^* = 0$ can be achieved with only $O(n)$ exceptional $z$'s (improving the previous bound of $O(n^2)$ exceptions).
This significantly reduces the soundness error in the aforementioned arguments systems.

3. In the other direction, we show that for some Reed--Solomon codes and some $\delta$, proximity gaps at or beyond the Johnson radius $J(\delta)$ with arbitrarily small proximity loss $\varepsilon^*$ needs to have at least $\Omega(n^{1.99})$ exceptional $z$'s.

4. More generally, for all constants $\tau$, we show that for some Reed-Solomon codes and some $\delta = \delta(\tau)$, proximity gaps at radius $\delta - \Omega_{\tau}(1)$ with arbitrarily small proximity loss $\varepsilon^*$ needs to have $n^{\tau}$ exceptional $z$'s.

5. Finally, for all Reed-Solomon codes, we show that improved proximity gaps imply improved bounds for their list-decodability. This shows that improved bounds on the list-decoding radius of Reed-Solomon codes is a prerequisite for any new proximity gaps results beyond the Johnson radius.
]]></content:encoded>
<pubDate>Thu, 06 Nov 2025 17:59:15 +0000</pubDate>
</item>
<item>
<title>Zexe: Enabling Decentralized Private Computation</title>
<link>https://eprint.iacr.org/2018/962</link>
<guid>https://eprint.iacr.org/2018/962</guid>
<content:encoded><![CDATA[
Ledger-based systems that support rich applications often suffer from two limitations. First, validating a transaction requires re-executing the state transition that it attests to. Second, transactions not only reveal which application had a state transition but also reveal the application's internal state.

We design, implement, and evaluate ZEXE, a ledger-based system where users can execute offline computations and subsequently produce transactions, attesting to the correctness of these computations, that satisfy two main properties. First, transactions *hide all information* about the offline computations. Second, transactions can be *validated in constant time* by anyone, regardless of the offline computation.

The core of ZEXE is a construction for a new cryptographic primitive that we introduce, *decentralized private computation* (DPC) schemes. In order to achieve an efficient implementation of our construction, we leverage tools in the area of cryptographic proofs, including succinct zero knowledge proofs and recursive proof composition. Overall, transactions in ZEXE are 968 bytes regardless of the offline computation, and generating them takes less than a minute plus a time that grows with the offline computation.

We demonstrate how to use ZEXE to realize privacy-preserving analogues of popular applications: private decentralized exchanges for user-defined fungible assets and regulation-friendly private stablecoins.
]]></content:encoded>
<pubDate>Sun, 14 Oct 2018 13:38:00 +0000</pubDate>
</item>
<item>
<title>Time-Lock Encrypted Storage for Blockchains</title>
<link>https://eprint.iacr.org/2025/2048</link>
<guid>https://eprint.iacr.org/2025/2048</guid>
<content:encoded><![CDATA[
We introduce time-lock encrypted storage (tTLES), a storage service provided by blockchains. In tTLES, clients store encrypted values towards a future decryption time $\tau_{tgt}$ (measured in block height). The security of tTLES requires that a value is decrypted only if (i) the encrypted value is included in the blockchain, and (ii) the time $\tau_{tgt}$ has passed. This is crucially different from existing schemes, which only enforce either of these conditions but not both. We formalize tTLES, and present an efficient protocol that relies on (in a black-box manner) a threshold identity-based encryption scheme, and a recent batch threshold decryption scheme. Finally, we discuss various applications that will benefit from tTLES.
]]></content:encoded>
<pubDate>Thu, 06 Nov 2025 02:41:09 +0000</pubDate>
</item>
<item>
<title>Threshold Anonymous Credentials with Silent Setup</title>
<link>https://eprint.iacr.org/2025/2042</link>
<guid>https://eprint.iacr.org/2025/2042</guid>
<content:encoded><![CDATA[
Anonymous credentials allow users to authenticate themselves in an anonymous and unlinkable fashion. By the end of 2026, EU member states will be required to issue digital identity wallets to their residents that enable authentication in this manner. In decentralized settings, we desire schemes with additional properties: schemes that allow multiple authorities to issue credentials, hide the identities of the issuers, and allow verifiers to dynamically choose their policies.

We present the first construction of issuer-hiding anonymous credentials with constant-sized showing, threshold issuance, and no requirement of interactive setup. Silent (non-interactive) setup is crucial as the various issuers may be slow-moving, independent organizations that are unwilling to coordinate in a distributed key generation protocol beforehand. Our construction also supports dynamic verifier policies. This is useful if different verifiers disagree about which issuers they trust or what threshold they accept.

At the heart of our scheme, we construct threshold structure-preserving signatures with silent setup and prove security in the generic group model. We also provide a NIZK for anonymous showing that is more efficient than a standard application of Groth-Sahai proofs. Finally, we provide an implementation of our scheme in Rust, along with concrete efficiency metrics.
]]></content:encoded>
<pubDate>Tue, 04 Nov 2025 22:50:51 +0000</pubDate>
</item>
<item>
<title>Multivariate Commitments and Signatures with Efficient Protocols</title>
<link>https://eprint.iacr.org/2025/2035</link>
<guid>https://eprint.iacr.org/2025/2035</guid>
<content:encoded><![CDATA[
We revisit multivariate commitments based on the hardness of solving systems of multivariate quadratic (MQ) equations over finite fields. We analyze a simple construction where a message µ is committed as c = (µ + F(r), G(r)), with F and G random quadratic maps. We prove that the scheme is computationally hiding assuming the intractability of the MQ problem. Its binding property reduces to solving random bilinear systems. We prove that this problem is NP-complete and study the performance of existing algebraic and hybrid attacks. We show that this commitment is well-suited for integration with zero-knowledge proofs. Using the Threshold-computation-in-the-Head framework, we construct zero-knowledge efficient arguments of knowledge for the opening and arguments for relations on committed values. We apply this to construct an efficient blind signature scheme à la Fischlin, and we demonstrate that our techniques yield a fully multivariate construction of signatures with efficient protocols, enabling practical post-quantum anonymous credentials.
]]></content:encoded>
<pubDate>Mon, 03 Nov 2025 12:48:06 +0000</pubDate>
</item>
<item>
<title>MtDB: A Decentralized Multi-Tenant Database for Secure Data Sharing</title>
<link>https://eprint.iacr.org/2025/2034</link>
<guid>https://eprint.iacr.org/2025/2034</guid>
<content:encoded><![CDATA[
Healthcare data sharing is fundamental for advancing medical research and enhancing patient care, yet it faces significant challenges in privacy, data ownership, and interoperability due to fragmented data silos across institutions and strict regulations (e.g., GDPR, HIPAA). To bridge these gaps, we propose MtDB, a novel decentralized database architecture addressing secure data sharing in multi-tenant database ecosystems. MtDB employs blockchain for metadata coordination and sharing, IPFS for distributed data addressing, a universal SQL query interface for data access, and Intel SGX for integrity-protected query execution with enforced access control. We provide an open-source implementation demonstrating MtDB’s capabilities for secure, patient-centric healthcare data sharing while preserving ownership and enforcing policies. Experimental results show MtDB achieves 35 milliseconds query latency for indexed queries over 400M multi-tenant medical records while maintaining cryptographic security guarantees, with only 1.2–1.3× performance overhead compared to non-secure baselines.
]]></content:encoded>
<pubDate>Sun, 02 Nov 2025 23:27:33 +0000</pubDate>
</item>
<item>
<title>TrX: Encrypted Mempools in High Performance BFT Protocols</title>
<link>https://eprint.iacr.org/2025/2032</link>
<guid>https://eprint.iacr.org/2025/2032</guid>
<content:encoded><![CDATA[
MEV (Maximal Extractable Value) remains one of the most corrosive forces in blockchain systems, enabling frontrunning, sandwiching, and other manipulations that directly exploit users. The core culprit is the transparent mempool: validators see transactions before they are ordered. Encrypted mempools are a promising solution by hiding transaction contents until after ordering.

We present the first integration of encrypted mempools with a high-performance BFT protocol. Our system uses a cryptographic scheme based on recent work on batched threshold encryption, and improves on the cryptographic state of the art in this line of work. The system ensures confidentiality of transactions during ordering while sustaining performance on par with leading BFT designs. Specifically, the proposal-to-execution latency of our system yields only a 27 ms overhead (14%) compared to the baseline. The result is a practical consensus layer that simultaneously defends against MEV and delivers the throughput and latency needed for real deployments. This work closes the gap between cryptographic defenses and production-ready consensus, showing that robust MEV protection and high performance can, in fact, coexist.
]]></content:encoded>
<pubDate>Sun, 02 Nov 2025 19:27:15 +0000</pubDate>
</item>
<item>
<title>A Note on Notes: Towards Scalable Anonymous Payments via Evolving Nullifiers and Oblivious Synchronization</title>
<link>https://eprint.iacr.org/2025/2031</link>
<guid>https://eprint.iacr.org/2025/2031</guid>
<content:encoded><![CDATA[
Anonymous payment protocols based on Zerocash (IEEE S&amp;P 2014) have seen widespread deployment in decentralized cryptocurrencies, as have derivative protocols for private smart contracts. Despite their strong privacy properties, these protocols have a fundamental scaling limitation in that they require every consensus participant to maintain a perpetually growing set of nullifiers --- unlinkable revocation tokens used to detect double-spending --- which must be stored, queried and updated by all validating nodes. This set grows linearly in the number of historic transactions and cannot be discarded without the undesirable effect of destroying unspent funds.

In this short note, we introduce a new technique that enables continual, permanent pruning of nullifiers by validators, without imposing significant computation, bandwidth or latency overhead for users, and without compromising privacy. Our main contribution is a general model we call oblivious synchronization, whereby users ask untrusted remote services (which ingest and process the public ledger) to create succinct proofs that coins are unspent and otherwise valid. Crucially, these services are fully oblivious to their clients' transaction details and cannot link their clients to any transactions that ultimately appear on the public ledger. Moreover, these services only keep ephemeral state per client and users can freely switch between services without incurring redundant computational effort.
]]></content:encoded>
<pubDate>Sun, 02 Nov 2025 05:04:12 +0000</pubDate>
</item>
<item>
<title>A Note Comparing Three Incentive Designs Against Privacy-Targeted Collusion</title>
<link>https://eprint.iacr.org/2025/2024</link>
<guid>https://eprint.iacr.org/2025/2024</guid>
<content:encoded><![CDATA[
We compare three recent works on collusion deterrence mechanisms [SP'24, Eurocrypt'25, CCS'25] in privacy-preserving multi-party computations. They follow the same whistleblowing structure where an evidence collection module collects collusion evidence, and a mechanism assigns payments to deter incentive-driven parties from collusion. 

For evidence collection module, two works [SP'24, Eurocrypt'25] provide a general method for generating collusion evidence while tolerating pre-existing leakage. The other work [CCS'25] abstracts evidence generation away, except for transparent service applications where the output is treated as the evidence. 

For the incentive mechanisms, two works [SP'24, Eurocrypt'25] consider a mix of rational and malicious parties, and rational parties can act as an individual or as a member of a strong coalition, inside which parties trust each other and never harm other members. When parties act as individuals, given bounded malicious parties, one can design mechanisms to disincentivize collusion. When parties act as a coalition, the mechanisms can only limit the size of coalitions for exclusive secrets, i.e., more parties learning the secret reduces the value received by individuals. The most recent work [CCS'25] only models rational parties but considers colluding parties establishing retaliatory contracts to discourage betrayal among colluders. It was shown to be impossible to maintain non-collusion outcome if retaliatory contracts can impose unbounded penalties, and feasible to guarantee non-collusion otherwise. This is weaker than a strong coalition but admits mechanisms protecting secrets of a general nature.
]]></content:encoded>
<pubDate>Fri, 31 Oct 2025 01:48:49 +0000</pubDate>
</item>
<item>
<title>TreeCast: Multi-Party Key Establishment Protocol for IoT Devices</title>
<link>https://eprint.iacr.org/2025/2021</link>
<guid>https://eprint.iacr.org/2025/2021</guid>
<content:encoded><![CDATA[
Secure communication in the Internet of Things (IoT) requires lightweight protocols that scale across unicast, multicast, and broadcast settings. Existing solutions typically depend on centralized gateways, which introduce single points of failure and scalability limitations. We present TreeCast, a decentralized group key establishment protocol that organizes devices in a binary tree and derives communication keys through hybrid key exchange. The protocol achieves efficient and scalable key management, supporting dynamic membership with localized rekeying. We provide a formal security analysis and proof, showing that TreeCast achieves authentication, session key confidentiality, post-compromise security, and partial forward secrecy. In addition, we evaluate computational and storage costs of the protocol, demonstrating logarithmic scalability in both communication overhead and device state. By enabling a single framework for unicast, multicast, and broadcast communication, our approach bridges the gap between cryptographic rigor and practical IoT deployment. TreeCast provides a deployable, communication-oriented solution to secure large-scale IoT networks.
]]></content:encoded>
<pubDate>Thu, 30 Oct 2025 15:33:10 +0000</pubDate>
</item>
<item>
<title>Practical Multi-party Private Set Intersection with Reducible Zero-sharing</title>
<link>https://eprint.iacr.org/2025/2019</link>
<guid>https://eprint.iacr.org/2025/2019</guid>
<content:encoded><![CDATA[
Multi-party Private Set Intersection (mPSI) enables $n(n\geq3)$ parties, each holding a set of size $m$, to jointly compute their intersection while preserving the confidentiality of each set, which is essential for privacy-preserving data analysis and secure database queries. Existing mPSI protocols have limitations in achieving both sufficient security and practical efficiency.

This paper presents a novel and efficient mPSI construction in the semi-honest model while resisting arbitrary collusion attacks. Our construction works in the offline/online paradigm. Given the corruption threshold $t$, the online phase achieves linear total computational and communication complexity, that is $O((n+t)m)$, and solely uses symmetric operations. This makes our construction theoretically outperform the existing works. The technical core of the construction is our newly extracted primitive called reducible zero-sharing, which allows $t(t<n)$ parties to obtain shares of zero for items in the intersection of $n$ parties' input set, while resisting up to $t-1$ colluding parties. We present a practical construction of reducible zero-sharing in the offline/online paradigm by leveraging the homomorphic property of oblivious key-value store (OKVS). 

With extensive experiments, we demonstrate that our construction outperforms state-of-the-art works in terms of online running time and communication cost. Specifically, compared to works with sufficient security, the online running time of our mPSI construction is $9.57-114.46\times$ faster in the LAN setting, $2.69-28.41\times$ faster in the WAN setting, while the communication cost is $0.29-28.70\times$ lower. Notably, the total performance (offline+online) still obtains up to $18.73\times$ improvement. Compared with works with practical efficiency, our mPSI construction achieves similar performance while providing stronger security.
]]></content:encoded>
<pubDate>Thu, 30 Oct 2025 14:13:34 +0000</pubDate>
</item>
<item>
<title>Batched and Packed (Publicly) Verifiable Secret Sharing: A Unified Framework and Applications</title>
<link>https://eprint.iacr.org/2025/2018</link>
<guid>https://eprint.iacr.org/2025/2018</guid>
<content:encoded><![CDATA[
Verifiable Secret Sharing (VSS) allows a dealer to distribute a secret among $n$ parties so that each can verify their share's validity, and any qualified subset can reconstruct the secret. Publicly Verifiable Secret Sharing (PVSS) extends VSS by enabling anyone to verify the correctness of distributed shares. Both VSS and PVSS schemes are core building blocks in many cryptographic applications. We introduce a $k$-batched and $l$-packed extension of \pie, a unified framework from PKC 2025 for Shamir-based computational VSS in the synchronous setting with optimal resilience. Our framework enables the sharing and verification of $l\times k$ secrets in a single protocol execution, offering a tunable trade-off between efficiency and robustness: the $k$-batched, non-packed variant ($l=1$) improves performance while maintaining optimal resilience, whereas the $k$-batched, $l$-packed variant achieves even greater efficiency at the cost of slightly reduced fault tolerance. Using this framework, we construct several Batched and Packed (BP) VSS and PVSS schemes that significantly reduce both computational and communication costs for the dealer and parties.  When sharing many secrets, two of our VSS schemes and our PVSS scheme perform almost as efficiently as plain Shamir sharing. For example, when sharing more than 100 secrets, the overhead of our hash-based BP-VSS is below 3%, for our BP-VSS with information-theoretic privacy it remains around 8%, and for our BP-PVSS it is under 2%. These results show that verifiability in Shamir secret sharing can be achieved in post-quantum and large-scale settings with negligible overhead for the dealer. Our proposed BP-PVSS scheme is the first that can achieve these properties and outperforms existing state-of-the-art protocols. As an application, we show that our BP-PVSS yields substantial performance improvements for the ALBATROSS randomness generation protocol from ASIACRYPT 2020.
]]></content:encoded>
<pubDate>Thu, 30 Oct 2025 12:23:46 +0000</pubDate>
</item>
<item>
<title>Secure Onion Encryption and the Case of Counter Galois Onion</title>
<link>https://eprint.iacr.org/2025/2017</link>
<guid>https://eprint.iacr.org/2025/2017</guid>
<content:encoded><![CDATA[
The recently introduced Counter Galois Onion (CGO) is a new symmetric onion encryption scheme designed to replace the current one used by Tor, with integration in Tor’s Rust implementation Arti ongoing. Intuitively, CGO uses an updatable tweakable split-domain cipher as its building block, which provides it with the necessary non-malleability properties while attaining better performance than the alternative approach of realising it from a wide blockcipher (with full SPRP security). However, onion encryption as used in Tor with various functionality features and security trade-offs, is not that well-studied by the cryptographic community. As a result, the requirements of this important primitive which protects the privacy of millions of users on a daily basis, is not well understood and whether CGO fulfills all its security goals unclear.

In this work, we initiate the study of real-world symmetric onion encryption by presenting a new security model capturing Tor’s leaky pipes functionality, associated data, and partial forward security, neither of which were covered previously. We then use this new security model to solidify the security claims of CGO in the forward direction by proving that if the underlying primitive is a suitably secure tweakable split-domain cipher, then CGO is a secure onion encryption scheme.
]]></content:encoded>
<pubDate>Thu, 30 Oct 2025 11:11:25 +0000</pubDate>
</item>
<item>
<title>Device-Bound Anonymous Credentials With(out) Trusted Hardware</title>
<link>https://eprint.iacr.org/2025/1995</link>
<guid>https://eprint.iacr.org/2025/1995</guid>
<content:encoded><![CDATA[
Anonymous credentials enable unlinkable and privacy-preserving user authentication. To ensure non-transferability of credentials among corrupt users, they can additionally be device-bound. Therein, a credential is tied to a key protected by a secure element (SE), usually a hardware component, and any presentation of the credential requires a fresh contribution of the SE. Interestingly, despite being a fundamental aspect of user credentials, device binding for anonymous credentials is relatively unstudied. Existing constructions either require multiple calls to the SE, or need the SE to keep a credential-specific state -- violating core design principles of shielded SEs. Further, constructions that are compatible with the most mature credential scheme BBS rely on the honesty of the SE for privacy, which is hard to vet given that SEs are black-box components.
In this work, we thoroughly study and solve the problem of device-bound anonymous credentials (DBACs). We model DBACs to ensure the unforgeability and non-transferability of credentials, and to guarantee user privacy at the same time.  Our definitions cover a range of SE trust levels, including the case of a subverted or fully corrupted SE. We also define blind DBACs, in which the SE learns nothing about the credential presentations it helped compute. This targets the design of a remote, cloud-based SE which is a deployment model considered for the EU Digital Identity (EUDI) wallet to address the fact that most user phones are not equipped with a sufficiently secure SE. Finally, we present three simple and round-optimal constructions for device binding of BBS credentials, and prove their security in the AGM+ROM and privacy unconditionally. The SE therein is extremely lightweight: it only has to compute a BLS or Schnorr signature in a single call. We also give the BLS-based construction in a blind variant, yielding the first protocol that enables privacy-preserving device binding for anonymous credentials when being used with a remote SE.
]]></content:encoded>
<pubDate>Fri, 24 Oct 2025 19:59:41 +0000</pubDate>
</item>
<item>
<title>Anonymous Authentication and Key Agreement, Revisited</title>
<link>https://eprint.iacr.org/2025/1986</link>
<guid>https://eprint.iacr.org/2025/1986</guid>
<content:encoded><![CDATA[
In NDSS 2024, Yu~et al. proposed AAKA, an Anonymous Authentication and Key Agreement scheme designed to protect users' privacy from mobile tracking by Mobile Network Operators (MNOs). AAKA aims to provide both anti-tracking privacy and traceability (lawful de-anonymization), allowing subscribers to access the network via anonymous proofs while enabling a Law Enforcement Agency (LEA) to trace the real identity if misbehaviors are detected. However, we identify that the AAKA scheme in NDSS 2024 is insecure since the subscriber's identity is exposed within the protocol, thereby failing to achieve the claimed privacy and traceability.

Building on the repair of AAKA, we propose AAKA+, Anonymous Authentication and Key Agreement with Verifier-Local Revocation, a new mobile authentication scheme, to ensure privacy against mobile tracking. In addition to the privacy and traceability introduced in NDSS 2024, AAKA+ additionally allows the MNO to immediately assert whether the associated subscriber has been traced and revoked upon receiving an anonymous proof. We formally define the syntax and the security model of AAKA+ and propose two concrete schemes, AAKA+BB and AAKA+PS, based on the Boneh-Boyen signature and the Pointcheval-Sanders signature schemes, respectively. Both AAKA+BB and AAKA+PS are pairing-free on the user equipment side and compatible with existing cellular infrastructure. Experimental results show that our schemes are practical, with anonymous proof generation taking approximately 18 milliseconds for a constrained device.
]]></content:encoded>
<pubDate>Thu, 23 Oct 2025 15:33:23 +0000</pubDate>
</item>
<item>
<title>OUF: Oblivious Universal Function with domain specific optimizations</title>
<link>https://eprint.iacr.org/2025/1985</link>
<guid>https://eprint.iacr.org/2025/1985</guid>
<content:encoded><![CDATA[
The growing need for secure computation has spurred interest in cryptographic techniques that operate on encrypted data without revealing its content. Fully Homomorphic Encryption (FHE), especially LWE-based schemes, enables such processing while preserving confidentiality. Decentralized computing offers scalable resources without requiring in-house servers, but it relies heavily on the confidentiality guarantees of underlying schemes. While many existing protocols successfully protect input privacy, function confidentiality remains a largely overlooked but crucial aspect of secure delegated computation.

In this work, we present a novel Oblivious Universal Function (OUF) scheme that enables a client to outsource computation of an arbitrary function to an untrusted server while hiding both the input data and the function being applied. Our construction leverages LWE-based FHE and a virtual-tape evaluation model to support composable, non-interactive, and reusable function execution. Crucially, the server remains oblivious not only to the encrypted inputs but also to the structure, type, and identity of the function it is executing. OUF thus bridges the gap between theoretical privacy guarantees and practical secure computation in decentralized environments.
]]></content:encoded>
<pubDate>Thu, 23 Oct 2025 13:31:13 +0000</pubDate>
</item>
<item>
<title>Vision: A Modular Framework for Anonymous Credential Systems</title>
<link>https://eprint.iacr.org/2025/1981</link>
<guid>https://eprint.iacr.org/2025/1981</guid>
<content:encoded><![CDATA[
Anonymous credentials enable the unlinkable presentation of previously attested information, or even only predicates thereof. They are a versatile tool and currently enjoy attention in various real-world applications, ranging from the European Digital Identity project to Privacy Pass. While each application usually requires their own tailored variant of anonymous credentials, they all share the same common blueprint. So far, this has not been leveraged though, and currently several proposals either targeting monolithic variants of core components such as BBS signatures, or application-speciﬁc protocols undergo standardization. This is clearly not optimal, as the same work gets repeated multiple times, while still risking ending up with many slight modiﬁcations of the same main idea and protocols. In this work we present our vision to use a modular approach to build anonymous credential systems: they are built from a core component – consisting of a commitment, signature and NIZK scheme – that can be extended with additional commitment-based modules in a plug-and-play manner. We sketch modules for pseudonyms, range proofs and device binding. Importantly, apart from the committed input, all modules are entirely independent of each other. We use this modularity to propose a concrete instantiation that uses BBS signatures for the core component and ECDSA signatures for device binding, addressing the need to bind modern credential schemes to legacy signatures in secure hardware elements.
]]></content:encoded>
<pubDate>Thu, 23 Oct 2025 07:37:14 +0000</pubDate>
</item>
<item>
<title>Cryptography with Weak Privacy</title>
<link>https://eprint.iacr.org/2025/1978</link>
<guid>https://eprint.iacr.org/2025/1978</guid>
<content:encoded><![CDATA[
We initiate a systematic study of information-theoretic cryptography with {\em weak privacy}, only requiring that the adversary cannot rule out any possible secret. For a parameter $0<p>0$. We obtain the following main results.

Positive results. We present efficient WP constructions for generalized secret sharing, decomposable randomized encodings, and the related notions of garbling schemes and PSM protocols, as well as interactive secure multiparty computation protocols in the plain model and in the OT-hybrid model. 

For secret sharing, we settle a question of Beimel and Franklin (TCC 2007), showing that every $n$-party access structure admits a WP scheme with per-party share size $O(n)$. When all unauthorized sets have constant size, we get a $p$-WP scheme with constant share size and $p\ge 1/poly(n)$.

Negative result. For decomposable randomized encodings, we show that a previous lower bound technique of Ball et al.\ (ITCS 2020) applies also to the WP notion. Together with our upper bound, this shows that the optimal WP garbling size of the worst-case $f:\{0,1\}^n\to\{0,1\}$ is $\tilde{\Theta}(n^2)$.

Application. While WP may seem like an unrealistically weak security notion, we demonstrate its usefulness towards achieving traditional security guarantees. Concretely, under the standard LPN assumption, we show that any $p$-WP secret-sharing scheme with inverse-polynomial $p$ implies a {\em computationally secure} secret-sharing scheme for a related access structure. Together with our positive results for WP secret sharing, this implies a super-polynomial improvement of the share size for a natural class of access structures.
]]></content:encoded>
<pubDate>Wed, 22 Oct 2025 12:37:18 +0000</pubDate>
</item>
<item>
<title>Taming Iterative Grinding Attacks on Blockchain Beacons</title>
<link>https://eprint.iacr.org/2025/1974</link>
<guid>https://eprint.iacr.org/2025/1974</guid>
<content:encoded><![CDATA[
Random beacons play a critical role in blockchain protocols by providing publicly verifiable, unpredictable randomness essential for secure assignment of protocol roles such as block producers and committee membership. In the interest of efficiency, many deployed blockchains adopt beacon algorithms that suffer from grinding: an adversarial attack in which a party exploits freedom given by the protocol to bias the outcome of the random beacon by resampling it several times and picking the most desirable outcome. To compound the problem, beacons often operate in an iterative manner, where the beacon output produced during one protocol epoch serves as the random seed for the beacon’s invocation in the next epoch. This amplifies the security threat, as such attacks may then aggregate their power over many epochs.

In this article, we formulate a generic framework for information-theoretic analysis of grinding in iterated randomness beacons. We define the natural grinding capacity of a beacon, intuitively corresponding to the amount of grinding it allows with a uniformly random seed. We then prove that sufficiently strong tail bounds on this quantity can be transformed into a guarantee on smooth min-entropy of the iterated beacon’s output, even conditioned on all past outputs and irrespective of the inner workings of the beacon. Such min-entropy guarantees can immediately be translated into corresponding statements about various applications of the beacon to committee selection, incentives, or underlying protocol security.

Our main technical result concerns conventional longest-chain protocols, where we establish that the combinatorial structure of the forest of longest chains can be leveraged to control grinding. Instantiating the generic framework with these grinding upper bounds, we establish that the randomness beacon of the Ouroboros Praos protocol is secure against adversaries controlling up to about 12% of stake—even
without any assumptions bounding the adversarial computational power invested into grinding. This is a qualitatively new guarantee for the protocol.
]]></content:encoded>
<pubDate>Wed, 22 Oct 2025 08:05:51 +0000</pubDate>
</item>
<item>
<title>Tight Security for BBS Signatures</title>
<link>https://eprint.iacr.org/2025/1973</link>
<guid>https://eprint.iacr.org/2025/1973</guid>
<content:encoded><![CDATA[
This paper studies the concrete security of BBS signatures (Boneh, Boyen, Shacham, CRYPTO '04; Camenisch and Lysyanskaya, CRYPTO '04), a popular algebraic construction of digital signatures which underlies practical privacy-preserving authentication systems and is undergoing standardization by the W3C and IRTF.

Sch\"age (Journal of Cryptology '15) gave a tight standard-model security proof under the $q$-SDH assumption for a less efficient variant of the scheme, called BBS+--here, $q$ is the number of issued signatures. In contrast, the security proof for BBS (Tessaro and Zhu, EUROCRYPT '23), also under the $q$-SDH assumption, is \emph{not} tight. Nonetheless, this recent proof shifted both standardization and industry adoption towards the more efficient BBS, instead of BBS+, and for this reason, it is important to understand whether this tightness gap is inherent. Recent cryptanalysis by Chairattana-Apirom and Tessaro (ASIACRYPT '25) also shows that a tight reduction to $q$-SDH is the best we can hope for.

This paper closes this gap in two different ways. On the positive end, we show a novel tight reduction for BBS in the case where each message is signed at most once--this case covers in particular the common practical use case which derandomizes signing. On the negative end, we use a meta-reduction argument to prove that if we allow generating multiple signatures for the same message, then {\em no} algebraic reduction to $q$-SDH (and its variants) can be tight.
]]></content:encoded>
<pubDate>Wed, 22 Oct 2025 02:07:27 +0000</pubDate>
</item>
<item>
<title>Formalisation of the KZG polynomial commitment schemes in EasyCrypt</title>
<link>https://eprint.iacr.org/2025/1972</link>
<guid>https://eprint.iacr.org/2025/1972</guid>
<content:encoded><![CDATA[
In this paper, we present formally verified proofs of the popular KZG Polynomial Commitment Schemes (PCSs), including the security proofs for the properties of correctness, polynomial binding, evaluation binding and hiding. Polynomial commitment schemes have various applications in cryptography and computer science, including verifiable computation, blockchain and cryptocurrencies, secure multi-party computation as well as in the construction of ZK-SNARKs. To validate security, we utilise EasyCrypt, an interactive theorem prover that allows for formal verification of cryptographic primitives and protocols. This approach enforces correct proofs which cover all required cases and formalising assumptions reducing the risk of overlooked vulnerabilities. This formalisation validates the current understanding of KZG's PCSs as secure while clarifying various issues in the original claims.
]]></content:encoded>
<pubDate>Tue, 21 Oct 2025 21:17:36 +0000</pubDate>
</item>
<item>
<title>Unobservable Contracts from Zerocash and Trusted Execution Environments</title>
<link>https://eprint.iacr.org/2025/1965</link>
<guid>https://eprint.iacr.org/2025/1965</guid>
<content:encoded><![CDATA[
Privacy-oriented cryptocurrencies like Zerocash only support direct payments and not the execution of more complex contracts. Bitcoin and Ethereum, on the other hand, cannot guarantee privacy, and using them for contract execution leaves open questions about fungibility of the proceeds and requires contract designers to take frontrunning countermeasures. This work reconciles the two worlds and develops a practical framework for decentralized execution of complex contracts that (1) is undetectable to the network at large, (2) maintains anonymity of the potentially mutually distrustful counterparties, (3) guarantees fair termination, and (4) is immediately resistant to frontrunning and miner bribery attacks. This is achieved by leveraging the confidentiality and anonymity guarantees of Zerocash and the verifiability and flexibility of trusted execution environments.
]]></content:encoded>
<pubDate>Mon, 20 Oct 2025 13:26:02 +0000</pubDate>
</item>
<item>
<title>Zyga: Optimized Zero-Knowledge Proofs with Dynamic Public Inputs</title>
<link>https://eprint.iacr.org/2025/1802</link>
<guid>https://eprint.iacr.org/2025/1802</guid>
<content:encoded><![CDATA[
We present Zyga, a pairing-based zero-knowledge proof system optimized for privacy-preserving DeFi
applications. Our main contribution is an enhancement of existing zkSNARK constructions
that enables dynamic public input substitution during verification while maintaining privacy of witness
components through one-sided encoding. The one-sided encoding aspect favors practical deployment constraints on Solana where G2 scalar multiplications are computationally expensive. Zyga separates private
values (blinded through trusted setup) from public values (instantiated on-chain), enabling applications
like private trading against current market rates without reproofing. We provide rigorous security analysis under discrete logarithm and q-Strong Diffie-Hellman assumptions, demonstrating computational
soundness, zero-knowledge, and completeness. Performance analysis shows verification requires only 3
pairings with constant proof size, making it practical for blockchain deployment where transaction costs
are critical.
]]></content:encoded>
<pubDate>Thu, 02 Oct 2025 10:01:39 +0000</pubDate>
</item>
<item>
<title>Fast Batch Matrix Multiplication in Ciphertexts</title>
<link>https://eprint.iacr.org/2025/1957</link>
<guid>https://eprint.iacr.org/2025/1957</guid>
<content:encoded><![CDATA[
Encrypted matrix multiplication (MM) is a fundamental primitive in privacy-preserving machine learning and encrypted data search, but it remains a significant performance bottleneck. Recently, Bae et al.~(Crypto’24) and Park~(Eurocrypt’25) introduced novel algorithms for ciphertext–plaintext (CPMM) and ciphertext–ciphertext (CCMM) matrix multiplications. These algorithms reduce encrypted MM operations to plaintext matrix multiplications (PPMM), enabling implementation through highly optimized BLAS libraries.
While these reduction-based methods offer significant improvements, their applicability is limited to scenarios where the matrix dimension 
$d$ is comparable to the ring dimension $N$ in RLWE-based CKKS schemes.
As a result, they fall short for matrix multiplications involving small or medium-sized matrices.

We extend the reduction-based CPMM/CCMM into small-sized matrix operations by batching instances. We use the Slots-in-Coefficient (SinC) encoding where a ring element is represented by a polynomial with coefficients each of which is the Discrete Fourier Transform of matrix entries at the same position. This encoding enables reductions of encrypted batch MM algorithms to a small number of batch PPMMs, which can be efficiently accelerated by BLAS libraries. 
Our batch encrypted MM flexibly accommodates diverse matrix dimensions and batch sizes independent of the ring dimension $N$, thereby extending its applicability to practical real-world settings.

For two $d \times d$ matrices with $N/d$ batches, our batch CPMM and CCMM algorithms achieve complexity $O(d^2N)$, improving upon Bae et al. at $O(dN^2)$ and Jiang et al~(CCS’18) at $O(d^2 N\log (N))$.
We further extend our techniques to rectangular matrices, achieving $O(dN^2)$ for multiplying a $d \times N$ and an $N \times N$ matrix, improving previous $O(N^3)$ methods.
A proof-of-concept implementation validates these improvements: multiplying 128 batches of $64 \times 64$ matrices takes $0.20$s (CPMM) and $0.91$s (CCMM), yielding $205\times$ and $64\times$ speedups over previous methods. For a $64 \times 2048$ by $2048 \times 2048$ multiplication, our CCMM completes in $7.8$s, achieving a $28\times$ speedup compared to Park's algorithm.
]]></content:encoded>
<pubDate>Mon, 20 Oct 2025 07:42:39 +0000</pubDate>
</item>
<item>
<title>Anamorphic Monero Transactions: the Threat of Bypassing Anti-Money Laundering Laws</title>
<link>https://eprint.iacr.org/2025/1961</link>
<guid>https://eprint.iacr.org/2025/1961</guid>
<content:encoded><![CDATA[
In this paper, we analyze the clash between privacy-oriented cryptocurrencies and emerging legal frameworks for combating financial crime, focusing in particular on the recent European Union regulations. We analyze Monero, a leading "privacy coin" and a major point of concern for law enforcement, and study the scope of due diligence that must be exercised under the new law with regard to Monero trading platforms and how it translates to the technical capabilities of the Monero protocol. We both recognize flaws in the legislation and identify technical pitfalls threatening either the effective compliance of, say, Monero exchanges or the anonymity endeavour of Monero itself. Of independent interest is that we turn to anamorphic cryptography (marking one of the first practical applications of the concept) and leverage it to build a hidden transaction layer embedded in the Monero blockchain that obfuscates illegal money flow and circumvents transaction-level attempts at enforcing the EU law.
]]></content:encoded>
<pubDate>Mon, 20 Oct 2025 12:28:37 +0000</pubDate>
</item>
<item>
<title>Generic PVSS Framework with $O(1)$ Complexity Using CCA2-Secure Threshold Encryption</title>
<link>https://eprint.iacr.org/2025/1964</link>
<guid>https://eprint.iacr.org/2025/1964</guid>
<content:encoded><![CDATA[
Existing PVSS schemes suffer from at least $O(n)$ online complexity due to the need to individually encrypt and prove/ verify each of the $n$ shares. In this work, we present a generic framework for constructing PVSS schemes with $O(1)$ complexity for share distribution and (the expected to be repeated numerous times) public verification.  Our key insight lies in establishing a novel connection between PVSS and CCA2-Secure threshold encryption (CCATE), which enables public verifiability enforced by Non-Interactive Zero-Knowledge (NIZK) proofs. We show that a CCATE scheme can be generically transformed into a secure PVSS scheme, eliminating the $O(n)$ bottleneck per on-line operations. We instantiate the framework by presenting two CCATE constructions: 1) A pairing-free scheme based on a committee-based Distributed Key Generation (DKG) protocol and Threshold ElGamal encryption. 2) A silent setup scheme leveraging a non-interactive distributed key generation, relying on Power-of-Tau ceremony. Furthermore, we introduce solutions for dynamic membership updates in both DKG constructions, demonstrating their practicality and adaptability for real-world applications. The scheme is based on an off-line setup stage (before a specific value to share is given) where the $O(n)$ complexity is dealt with. Although our schemes incur higher setup costs, they drastically reduce the complexity of the critical distribution and verification stages to constant time. This trade-off marks a significant advancement in the scalability of PVSS-based systems, especially in the context of blockchain modern transactions. Conceptually, the work points out how variants of the notion of Threshold Encryption can potentially serve as a ``compression mechanism'' for information sharing schemes.
]]></content:encoded>
<pubDate>Mon, 20 Oct 2025 13:25:51 +0000</pubDate>
</item>
<item>
<title>Aggregate Signatures Tightly Secure under Adaptive Corruptions</title>
<link>https://eprint.iacr.org/2025/1955</link>
<guid>https://eprint.iacr.org/2025/1955</guid>
<content:encoded><![CDATA[
Aggregate signatures allow compressing multiple single-signer signatures into a single short aggregate signature. This primitive has attracted new attention due to applications in blockchains and cryptocurrencies. In multisig addresses, which is one of such applications, aggregate signatures reduce the sizes of transactions from multisig addresses. Security of aggregate signatures under adaptive corruptions of signing keys is important, since one of the motivations of multisig addresses was a countermeasure against signing key exposures. We propose the first aggregate signature scheme tightly secure under adaptive corruptions using pairings. An aggregate signature includes two source group elements of bilinear groups plus a bit vector whose length is equal to the number of single-signer signatures being aggregated. To construct a scheme, we employ a technique from quasi-adaptive non-interactive zero-knowledge arguments. Our construction can be seen as modularization and tightness improvement of Libert et al.'s threshold signature scheme supporting signature aggregation (Theoretical Computer Science 645) in a non-threshold setting.
]]></content:encoded>
<pubDate>Mon, 20 Oct 2025 06:57:51 +0000</pubDate>
</item>
<item>
<title>KPIR-C: Keyword PIR with Arbitrary Server-side Computation</title>
<link>https://eprint.iacr.org/2025/1952</link>
<guid>https://eprint.iacr.org/2025/1952</guid>
<content:encoded><![CDATA[
Private Information Retrieval (PIR) enables clients to retrieve data from a server without revealing their query. Keyword PIR (KPIR), an extension for keyword-based queries that enables PIR using keywords, is crucial for privacy-preserving two-party analytics in unbalanced settings. However, existing KPIR solutions face two challenges in efficiently supporting arbitrary server-side computations and handling mismatched queries non-interactively. 

To our best knowledge, we take the first step to introduce Keyword PIR with Computation (``KPIR-C''), a novel PIR primitive that enables arbitrary non-interactive computation on responses while preserving query privacy. We overcome the arbitrary computation challenge by introducing TFHE into KPIR, which ensures efficient bootstrapping and allows arbitrary server-side computations. We address the mismatch challenge by identifying an important KPIR-C subroutine, referred to as KPIR with Default (``KPIR-D''), to remove disturbance of the computation caused by the mismatched responses. We instantiate KPIR-C with two constructions, one based on constant-weight codes and the other on recent LWE-based KPIR approaches. Both constructions enable efficient post-computation and offer trade-offs between communication overhead and runtime. Experiments show that our implemented constructions achieve competitive performance, and in some cases even outperform state-of-the-art KPIR solutions that do not support arbitrary computation.
]]></content:encoded>
<pubDate>Sun, 19 Oct 2025 16:05:43 +0000</pubDate>
</item>
<item>
<title>What is Cryptography Hiding from Itself?</title>
<link>https://eprint.iacr.org/2025/1951</link>
<guid>https://eprint.iacr.org/2025/1951</guid>
<content:encoded><![CDATA[
The European Commission's 2022 proposal for a regulation on child sexual abuse material, popularly labelled ChatControl, obliges online services to detect, report, and remove prohibited content, through client-side scanning.  
This paper examines the proposal as a case of undone science in computer security ethics: a domain where technical feasibility and rights-compatibility questions remain systematically underexplored. Combining legal analysis with philosophy of technology, the paper argues that client-side scanning transforms end-to-end encryption from a right to secrecy into a conditional privilege of use. By integrating Isaiah Berlin's concept of negative liberty, Langdon Winner’s account of the politics of artifacts, and David Hess’s notion of undone science, the analysis traces how design choices become moral constraints.  
The discussion situates the European debate within broader concerns about proportionality, epistemic selectivity, and the governance of digital infrastructures. Ultimately, the study shows that the controversy over ChatControl is not only about privacy or child protection but about the epistemic norms that define what counts as legitimate technological knowledge.
]]></content:encoded>
<pubDate>Sun, 19 Oct 2025 12:46:20 +0000</pubDate>
</item>
<item>
<title>Minicrypt PRFs Do Not Admit Black-Box Oblivious Evaluations</title>
<link>https://eprint.iacr.org/2025/1947</link>
<guid>https://eprint.iacr.org/2025/1947</guid>
<content:encoded><![CDATA[
Oblivious Pseudorandom Function (OPRF) protocols can be categorized into two variants: chosen-key OPRFs -- where the server provides the PRF key $k$ as an input -- and ephemeral-key OPRFs -- where the functionality randomly samples $k$ on behalf of the server. Ephemeral-key OPRFs can be constructed from simple cryptography, such as black-box OT and a random oracle. Chosen-key OPRFs, on the other hand, are only known by employing one of the following (more expensive) approaches:
    - Express the underlying PRF as a circuit, then use generic MPC techniques to evaluate it in a non-black-box manner.
    - Base the underlying PRF on some specific public-key assumption, such as RSA or DDH, then build a custom protocol that achieves obliviousness by leveraging the PRF's algebraic structure.
Thus, there exists a qualitative gap between known instantiations of these two OPRF variants, in terms of both assumptions and efficiency.

We show that this gap is inherent.
In particular, one might hope for an OPRF with all of the following characteristics:
the protocol
(1) is chosen-key,
(2) supports domains of super-polynomial size, and
(3) is constructed from "simple" cryptography, such as the minimal assumption of OT, plus a random oracle.
We show that no such protocol can exist.

Let $\Pi$ be any chosen-key OPRF protocol defined in terms of a PRF $F$, where $F$ is defined with respect to (only) a random oracle.
This restriction on $F$ rules out the above approaches of either using a PRF in a non-black-box way or basing the underlying PRF itself on public-key cryptography.
While $F$ is restricted in its use of cryptography, the protocol $\Pi$ is not: $\Pi$ may use arbitrary cryptography, e.g., OT, FHE, iO, etc.
We show that each invocation of any such $\Pi$ necessarily leaks information about the server's key $k$.
After a bounded number of queries, an adversarial client can effectively recover $k$, breaking server privacy.

To complement our negative result, we provide a matching positive result: we construct a chosen-key OPRF from black-box OT and RO, where server privacy holds for some bounded number of queries $n$.
This protocol's underlying PRF is constructed from a $(n+1)$-wise independent hash function and RO; the server's key $k$ has length scaling linearly in $n$ which, by our lower bound, is optimal.
Thus, our two results tightly (i.e., up to $\mathrm{poly}(\lambda)$ factors) characterize (im)possibility for chosen-key OPRFs, unless one uses non-black-box cryptography or a public-key-style PRF.
]]></content:encoded>
<pubDate>Sat, 18 Oct 2025 07:49:11 +0000</pubDate>
</item>
<item>
<title>Robust and Scalable Lattice-Based Distributed Key Generation for Asynchronous Networks</title>
<link>https://eprint.iacr.org/2025/1946</link>
<guid>https://eprint.iacr.org/2025/1946</guid>
<content:encoded><![CDATA[
Distributed Key Generation (DKG) is essential for secure, decentralized cryptographic systems, enabling collaborative key pair generation without a trusted authority. This capability underpins critical applications such as threshold signatures and blockchain-based protocols. To achieve post-quantum security, existing robust lattice-based DKG protocols, tailored for synchronous networks, rely on complaint-based Verifiable Secret Sharing (VSS). However, these protocols lack public verifiability and compatibility with asynchronous environments, constraining their use in Byzantine fault-tolerant settings. 

This paper presents LADKG, a Lattice-Based Asynchronous Distributed Key Generation framework designed for post-quantum secure and scalable distributed systems. LADKG integrates Asynchronous Verifiable Short Secret Sharing (AV3S) with an Approximate Asynchronous Common Subset (AACS) protocol to achieve efficient key generation. By deferring verification and leveraging deterministic approximate agreement, LADKG reduces computational and communication overhead while maintaining security and robustness. Evaluations on geo-distributed AWS EC2 clusters demonstrate that LADKG is comparable or better than classical Asynchronous Distributed Key Generation (ADKG) schemes in scalability and efficiency. Under optimistic conditions with $n=121$ nodes, completion is achieved in 45 seconds, ensuring robust key generation for post-quantum secure applications.
]]></content:encoded>
<pubDate>Sat, 18 Oct 2025 03:05:34 +0000</pubDate>
</item>
<item>
<title>zk-Cookies: Continuous Anonymous Authentication for the Web</title>
<link>https://eprint.iacr.org/2025/1938</link>
<guid>https://eprint.iacr.org/2025/1938</guid>
<content:encoded><![CDATA[
We are now entering an era where the large-scale deployment of anonymous credentials seems inevitable, driven both by legislation requiring age verification and the desire to distinguish humans from bots in the face of the proliferation of AI-generated content. However, the widespread deployment of anonymous credentials faces the same security and fraud concerns as existing credentials, but without the established techniques for securing them. For non-anonymous credentials on the web today, authentication is a continuous process in which servers collect large volumes of behavioral data to protect account holders (e.g., by detecting account compromise) or to combat fraudulent behavior.
In this paper, we propose Continuous Anonymous Authentication (CAA) schemes and give a concrete construction and applications for preventing credential sharing and theft. CAA schemes allow us to move the server-side collection, storage, and processing of these behavioral signals to the client while maintaining privacy and integrity. CAA schemes support, on the client side, a number of common behavioral analysis tests and analytics both for determining fraudulent behavior and updating security policies. We implement a prototype, zk-Cookies, which runs in the browser, and supports common behavioral signals such as IP address and geolocation history, browser fingerprinting, and page view history. Using this, we build a prototype application for age verification based on legacy credentials (like passports). We implement these checks efficiently in zk-SNARKs, and also show how to securely implement differentially private behavioral analytics in a zk-SNARK. The simplest version of our construction can perform the computation for an update in under 200 ms.
]]></content:encoded>
<pubDate>Fri, 17 Oct 2025 02:51:19 +0000</pubDate>
</item>
<item>
<title>Noisy Function Secret Sharing and its applications to Differentially Private computations</title>
<link>https://eprint.iacr.org/2025/1937</link>
<guid>https://eprint.iacr.org/2025/1937</guid>
<content:encoded><![CDATA[
Function Secret Sharing (FSS) schemes enable to share secret functions between multiple parties, with notable applications in anonymous communication and privacy-preserving machine learning. While two-party schemes offer logarithmic key sizes, multi-party schemes remain less practical due to significantly larger keys. Although several approaches have been proposed to improve multi-party schemes, a significant efficiency gap remains between the two-party and multi-party settings.

Our work introduces noisy FSS: a relaxation of FSS preserving the standard privacy guarantees but relaxing the correctness definition by allowing a small amount of noise in the output. We formally define noisy FSS and show how the noise introduced by the scheme can be leveraged to provide differential private outputs in statistics applications.

To demonstrate the benefits of this relaxation, we adapt a scheme proposed by Corrigan-Gibbs et al. (S&amp;P'15). While their scheme provides the smallest key sizes among multi-party schemes, they do not support some applications notably in statistics due to their non-linear share decoding. On the contrary, recent works such as Goel et al. (CRYPTO'25) have larger keys, but support all FSS applications. Our noisy adapted scheme offers the best of both worlds by matching the best key sizes, while providing the properties necessary to statistics applications.
]]></content:encoded>
<pubDate>Thu, 16 Oct 2025 19:00:48 +0000</pubDate>
</item>
<item>
<title>Low-Latency Linear Transformations with Small Key Transmission for Private Neural Network on Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/883</link>
<guid>https://eprint.iacr.org/2024/883</guid>
<content:encoded><![CDATA[
The widespread adoption of Machine Learning as a Service has made data privacy a critical challenge. Homomorphic Encryption (HE) offers a robust solution by enabling computations on encrypted data, yet it faces practical hurdles such as high computational latency and large key sizes. Consequently, designing efficient HE-based AI models is an active area of research. A primary focus is the HE implementation of convolution, a fundamental operation in CNNs and increasingly used in modern architectures such as transformers and state-space models. To realize HE convolution, various packing strategies—defining the data layout within a ciphertext—have been introduced, leading to state-of-the-art methods such as multiplexed parallel convolution (MPConv), which is implemented with multiplexed parallel packing. In this paper, we propose Rotation-Optimized Multiplexed Parallel Convolution (RO-MPConv), which enhances usability by reducing the number of rotation operations and rotation keys—major contributors to latency and key sizes in MPConv. Additionally, we introduce a small-level key system to further decrease key sizes and a novel parallel baby-step giant-step matrix-vector multiplication, which reduces rotations for packing strategies with multiple identical data entries, including multiplexed parallel packing. We conducted all experiments using the Lattigo
library’s CKKS HE scheme. Experimental results demonstrate that RO-MPConv achieves up to an 81% reduction in latency and a 29× reduction in rotation key size compared to MPConv. Furthermore, integrating RO-MPConv into existing state-of-the-art models improved their total latency by up to 26%, and our proposed matrix-vector multiplication method reduced latency by 69%. Our code is fully available from https://github.com/byeongseomin51/RO-MPConv.git.
]]></content:encoded>
<pubDate>Mon, 03 Jun 2024 09:44:48 +0000</pubDate>
</item>
<item>
<title>UPPR: Universal Privacy-Preserving Revocation</title>
<link>https://eprint.iacr.org/2025/1919</link>
<guid>https://eprint.iacr.org/2025/1919</guid>
<content:encoded><![CDATA[
Self-Sovereign Identity (SSI) frameworks enable individuals to receive and present digital credentials in a user-controlled way. Revocation mechanisms ensure that invalid or withdrawn credentials cannot be misused. These revocation mechanisms must be scalable (e.g., at national scale) and preserve core SSI principles such as privacy, user control, and interoperability. Achieving both is hard, and finding a suitable trade-off remains a key challenge in SSI research. This paper introduces UPPR, a revocation mechanism for One-Show Verifiable Credentials (oVCs) and unlinkable Anonymous Credentials (ACs). Revocations are managed using per-credential Verifiable Random Function (VRF) tokens, which are published in a Bloom filter cascade on a blockchain. Holders prove non-revocation via a VRF proof for oVCs or a single Zero-Knowledge Proof for ACs. The construction prevents revocation status tracking, allows holders to stay offline, and hides issuer revocation behavior. We analyze the privacy properties of UPPR and provide a prototype implementation on Ethereum. Our implementation enables off-chain verification at no cost. On-chain checks cost 0.56-0.84 USD, while issuers pay only 0.00002-0.00005 USD per credential to refresh the revocation state.
]]></content:encoded>
<pubDate>Tue, 14 Oct 2025 13:21:21 +0000</pubDate>
</item>
<item>
<title>Towards formal verification and corrupted setup security for the SwissPost voting system</title>
<link>https://eprint.iacr.org/2025/1901</link>
<guid>https://eprint.iacr.org/2025/1901</guid>
<content:encoded><![CDATA[
The Swiss Post voting system is one of the most advanced cryptographic voting protocols deployed for political elections, offering end-to-end verifiability and vote privacy. It provides significant documentation and independent scrutiny reports. Still, we argue that two significant pillars of trust need to be further developed. One is formal verification accompanied by machine-checked proofs. The second is security in presence of a corrupt setup component. In this work, we propose formal specifications of a simplified version of the Swiss Post voting protocol and initial verification results with the Tamarin prover. We also propose a revised protocol design that mitigates risks from a corrupt setup, and a prototype implementation of necessary zero-knowledge proofs.
]]></content:encoded>
<pubDate>Sat, 11 Oct 2025 13:53:29 +0000</pubDate>
</item>
<item>
<title>Beholder Signatures</title>
<link>https://eprint.iacr.org/2025/1900</link>
<guid>https://eprint.iacr.org/2025/1900</guid>
<content:encoded><![CDATA[
We introduce a new primitive, called beholder signatures, which, in some sense, are the opposite of blind signatures. In a beholder signature, one signs a commitment to a (potentially very long) message, and the signature attests that the parties participating in the signing process who know the secret key, jointly also know the entire committed message.  This guarantee holds even against distributed adversaries that use secure multi-party computation (MPC) to produce the signature. We work in the distributed adversarial model (Dziembowski, Faust, and Lizurej, Crypto'23), where one assumes that it is infeasible to evaluate a large number of hash queries without any of the participating parties learning the input. We propose a construction of beholder signatures in the random oracle model. The starting point of our construction is proofs of complete knowledge, recently proposed by (Kelkar et al. CCS'24), which again build on Fischlin's transformation of a sigma protocol to a noninteractive, straight-line extractable zero-knowledge proof of knowledge. Our scheme is concretely efficient and comes with a proof-of-concept implementation using Schnorr as the underlying sigma protocol.

The primary applications of beholder signatures can be found within the blockchain ecosystem. In particular, we describe how to use them to construct proofs of custody (Feist, 2021) that do not require ephemeral keys and are noninteractive. We also outline applications to data dissemination, data availability, and proofs of replication.
]]></content:encoded>
<pubDate>Sat, 11 Oct 2025 12:48:31 +0000</pubDate>
</item>
<item>
<title>An Approach to Computable Contracts with Verifiable Computation Outsourcing and Blockchain Transactions</title>
<link>https://eprint.iacr.org/2025/1896</link>
<guid>https://eprint.iacr.org/2025/1896</guid>
<content:encoded><![CDATA[
In this short paper we present an approach to computable contracts, where all roles in a computation may be outsourced, from the servers performing computations, to those providing input, to those performing verifications (on input and on output), including all related communications. Varying levels of confidentiality can be chosen, both on data and calculations.
While the largest part of the computational and communication effort is performed off-chain, our contracts require a specialized underlying blockchain, where they are encoded as transactions, to achieve their decentralized handling and thus enforcing their correct execution via a combination of cryptographic techniques and economic security. 
Our delegation architecture allows for the execution of very complex collaborative tasks, such as the deployment of an AI marketplace.
]]></content:encoded>
<pubDate>Fri, 10 Oct 2025 14:16:13 +0000</pubDate>
</item>
<item>
<title>Bounded-Equivocable Pseudorandom Functions</title>
<link>https://eprint.iacr.org/2025/1894</link>
<guid>https://eprint.iacr.org/2025/1894</guid>
<content:encoded><![CDATA[
We introduce Bounded-Equivocable PRFs, a new variant of pseudorandom functions. They combine standard pseudorandomness with a bounded form of programmability. In our model, an adversary may issue an arbitrary number of queries that remain indistinguishable from random. Bounded equivocability ensures that responses can be programmed consistently with a later-revealed key, up to a fixed bound q. This relaxation avoids known impossibility results, which preclude polynomial unbounded equivocability in the standard model, while preserving the programmability required for applications. 

We present standard-model constructions of bounded-equivocable PRFs under the DDH and LWE assumptions, and we show how to make these constructions verifiable. Prior SIM-AC style primitives could not achieve verifiability since their programmability relied on embedding the secret key into the random oracle. 

We demonstrate applications to (i) adaptively secure private-key encryption, (ii) two-round threshold Schnorr signatures secure against adaptive corruptions, and (iii) leader election in Proof of Stake blockchains. Together, these results establish bounded-equivocable PRFs as a practical primitive that achieves programmability with verifiability in the standard model, and enables applications previously out of reach.
]]></content:encoded>
<pubDate>Fri, 10 Oct 2025 12:53:19 +0000</pubDate>
</item>
<item>
<title>Interstellar: Efficient GKR-based Folding/IVC Scheme with Collaborative Folding Extension</title>
<link>https://eprint.iacr.org/2025/1294</link>
<guid>https://eprint.iacr.org/2025/1294</guid>
<content:encoded><![CDATA[
In this paper, we present Interstellar, a novel folding and IVC framework built on a technique we call circuit interpolation, designed specifically for circuit satisfiability. By incorporating the GKR protocol, our approach avoids commitments to full computation traces and cross-term vectors, requiring instead only commitments to the actual circuit witness and optionally a small subset of intermediate gate values. This design significantly reduces the size of the vectors to be committed to in each folding step, which is highly advantageous compared to existing schemes, as vector commitments involve costly group multi-scalar multiplications. Moreover, Interstellar is highly flexible. It can be extended to handle high-degree and lookup gates, enable multi-instance folding, and support non-uniform IVC efficiently, making it well-suited for practical applications ranging from zkML to proving program execution for zkVMs. Finally, we introduces a new concept called collaborative folding/IVC which allows multiple provers, each holding a private witness for the same public statement, to jointly perform the folding/IVC computation while preserving witness privacy. This extension makes Interstellar suitable for distributed and privacy-sensitive applications.
]]></content:encoded>
<pubDate>Tue, 15 Jul 2025 16:12:53 +0000</pubDate>
</item>
<item>
<title>Cryptanalysis on Lightweight Verifiable Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1890</link>
<guid>https://eprint.iacr.org/2025/1890</guid>
<content:encoded><![CDATA[
Verifiable Homomorphic Encryption (VHE) is a cryptographic technique that integrates Homomorphic Encryption (HE) with Verifiable Computation (VC). It serves as a crucial technology for ensuring both privacy and integrity in outsourced computation, where a client sends input ciphertexts $\mathsf{ct}$ and a function $f$ to a server and verifies the correctness of the evaluation upon receiving the evaluation result $f(\mathsf{ct})$ from the server.
        
    Chatel et al. (CCS'24) introduced two VHE schemes: Replication Encoding (REP) and Polynomial Encoding (PE). A similar approach to REP was used by Albrecht et al. (EUROCRYPT'24) to develop a Verifiable Oblivious PRF scheme (vADDG).   
    A key approach in these schemes is to embed specific secret information within ciphertexts and use them to verify homomorphic evaluations.
    
    This paper presents efficient forgery attacks against the verifiability guarantees of these VHE schemes. We introduce two attack strategies. The first targets REP and vADDG, extracting secret information in encrypted form from input ciphertexts and leveraging it to forge output ciphertexts without being detected by the verification algorithm. The second targets PE, exploiting its secret embedding structure to forge output ciphertexts that remain valid on input values for verification, yet violate the verifiability property.
     
     Our forgery attack on vADDG demonstrates that the proposed 80-bit security parameters provide at most 10 bits of concrete security. Our attack on REP and \PE achieves a probability 1 attack with linear time complexity when using fully homomorphic encryption.
]]></content:encoded>
<pubDate>Fri, 10 Oct 2025 01:43:59 +0000</pubDate>
</item>
<item>
<title>Blind Signatures from Arguments of Inequality</title>
<link>https://eprint.iacr.org/2025/1886</link>
<guid>https://eprint.iacr.org/2025/1886</guid>
<content:encoded><![CDATA[
Blind signatures are an important tool for privacy-preserving applications with a long history dating back to Chaum's seminal work in Crypto'82. In this work, we focus on the Fiat-Shamir paradigm, i.e., blind signatures based on $\Sigma$-protocols compiled via Fiat-Shamir, in the random oracle model. We resolve the following open problems:

- We give the first lattice-based blind signature that is concurrently-secure based on the Fiat-Shamir paradigm.
- We give the first pairing-free blind signature that is concurrently-secure under the discrete logarithm assumption (without the algebraic group model). 

On a technical level, our work is inspired by the recent proofs of inequality technique (Klooß and Reichle, Crypto'25). This technique relies on statistical puncturing of the verification key. We explore the technique in the computational regime and develop new proof and design techniques to tackle the challenges encountered along the way.
]]></content:encoded>
<pubDate>Thu, 09 Oct 2025 12:43:04 +0000</pubDate>
</item>
<item>
<title>0-ART. Asynchronous and Verifiable Group Management for Decentralized Applications</title>
<link>https://eprint.iacr.org/2025/1874</link>
<guid>https://eprint.iacr.org/2025/1874</guid>
<content:encoded><![CDATA[
The majority of modern e2e private applications face scalability issues that limit their functionality, broader adoption, and overall user experience. Some of them organize private groups as a set of peer-to-peer chats, which leads to an overall quadratic complexity in the size of group communication and a linear time complexity in the number of members for encryption. Others apply more scalable group key establishment constructions (such as ART), but at the same time, they do not support verifiable and concurrent updates. In this paper, we introduce the 0-ART protocol, which aims to address the aforementioned issues by (1) verifiable group operations; (2) a causal tree construction allowing for multiple concurrent updates and efficient member removal; (3) anonymous credentials, making privacy in the group available while keeping operations authentic. We implemented the 0-ART framework and applied it to a decentralized collaborative work application. According to our benchmark, executing the most complex operation (performing the provable $\mathsf{AddMember}$ operation in a group of size $2^{20}$) takes 1.57 seconds on the user's device and $24$Kb of proof size.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 14:43:21 +0000</pubDate>
</item>
<item>
<title>Threshold Reporting Protocol for Traceability in Anonymous Social Networks</title>
<link>https://eprint.iacr.org/2025/1873</link>
<guid>https://eprint.iacr.org/2025/1873</guid>
<content:encoded><![CDATA[
As anonymous social networks continue to grow in popularity, they raise serious challenges around abuse, misinformation, and harmful behavior. While traditional de-anonymization techniques can address misuse, they often come at the cost of user privacy.  Protecting honest users' privacy while keeping malicious ones accountable remains a complex challenge.
  A promising alternative is conditional deanonymization, where anonymity is lifted only when abuse is collectively reported and verified by an authority.

  In this work, we present a new cryptographic framework for conditional de-anonymization that preserves user anonymity unless a threshold number of validated abuse reports is reached. Our design leverages threshold cryptography to ensure that de-anonymization can only be triggered under well-defined, collectively enforced conditions—resisting false reports, misuse, and collusion. We formalize the model and provide a generic construction from standard cryptographic primitives, proving strong security guarantees even in the presence of adversarial authorities or malicious users. To illustrate its viability, we also propose a concrete instantiation based on lattice-based assumptions, making it a compelling candidate for post-quantum settings.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 14:35:38 +0000</pubDate>
</item>
<item>
<title>Interoperable Symmetric Message Franking</title>
<link>https://eprint.iacr.org/2025/1872</link>
<guid>https://eprint.iacr.org/2025/1872</guid>
<content:encoded><![CDATA[
The recent Digital Markets Act (DMA), a regulation passed by the European Union in 2022, requires messaging applications with large user bases to support interoperable end-to-end encrypted (E2EE) communication. This raises numerous questions about how to adapt cryptographic protocols to this setting in a way that preserves security and privacy.  This question is not only limited to the main messaging protocols, but also extends to protocols for abuse mitigation such as the symmetric message franking protocol first proposed by Facebook. The latter uses symmetric cryptography to enable reporting abusive E2EE messages in a way that allows the platform to cryptographically verify the report's veracity.

In this paper, we initiate a formal treatment of interoperable symmetric message franking (IMF). We focus on a server-to-server messaging flow, where messages are routed sequentially through the sender's and recipient's service providers, but allow the recipient to dynamically choose who to send a report to. We formalize the security definitions for IMF including adapting the sender and recipient binding definitions into various reportability and unforgeability definitions that take into account one of the service providers misbehaving. We also prove relations among these new definitions. Finally, we detail an IMF construction that satisfies the security definitions, and include a discussion of users' identity privacy goals and deployment considerations.
]]></content:encoded>
<pubDate>Wed, 08 Oct 2025 14:13:34 +0000</pubDate>
</item>
<item>
<title>HiSE: Hierarchical (Threshold) Symmetric-key Encryption</title>
<link>https://eprint.iacr.org/2024/158</link>
<guid>https://eprint.iacr.org/2024/158</guid>
<content:encoded><![CDATA[
Threshold symmetric encryption (TSE) [DiSE, CCS 2018], provides a practical decentralized solution for symmetric encryption by distributing the secret-key at all times, thus avoiding a single point of attack or failure. 
     TSE was further enhanced [ATSE, CCS 2021] by an amortization  which enables a ``more privileged'' client to encrypt bulk records by interacting only once with the key servers, while decryption must be performed individually for each record, potentially by a ``less privileged'' client. 
    However, a typical enterprise generates data once and queries it several times for various data analysis; i.e., enterprise workloads are often decryption heavy! ATSE does not meet the bar for this setting because of linear interaction / computation (in the number of records to be decrypted) -- our experiments show that ATSE provides a sub-par throughput of a few hundred records/sec.

Our work starts with an observation that a large and useful class of analytics queries access some time-windowed sequence of database records (e.g. log entries or user transactions). Can we offer faster decryption for such access patterns, without compromising the benefits of prior schemes?

To that end, we build a new TSE scheme that allows for both encryption and decryption with flexible granularity, in that a client's interactions with the key servers is at most logarithmic in the number of records. Our idea is to employ a binary-tree structure, where one interaction is needed to decrypt all ciphertexts in a sub-tree, and thus only log-many for any arbitrary sub-sequence. Our scheme incorporates ideas from binary-tree encryption by Canetti et al. [Eurocrypt 2003] and carefully combines that with Merkle-tree commitments. We show that our scheme satisfies all essential TSE properties, such as correctness, privacy and authenticity for our notion, formalized as hierarchical threshold symmetric-key encryption (HiSE). Our analysis relies on a well-known XDH assumption and a new assumption, that we call $\ell$-masked BDDH, over asymmetric bilinear pairing in the programmable random oracle model. We also show that our new assumption holds in the generic group model. 

Our extensive implementation shows 10-65$\times$ improvement in latency and throughput over ATSE. 
HiSE can decrypt over 6K records/sec on server-grade hardware, but the logarithmic overhead in encryption (not decryption) only lets us encrypt up to 3K records/sec (about 4.5x slowdown) and incurs roughly 500 bytes of ciphertext expansion per record -- while reducing this penalty is an important future work, we believe HiSE offers an acceptable practical trade-off in practice.
]]></content:encoded>
<pubDate>Fri, 02 Feb 2024 17:44:04 +0000</pubDate>
</item>
<item>
<title>Revisiting Lattice-based Non-interactive Blind Signature</title>
<link>https://eprint.iacr.org/2025/1848</link>
<guid>https://eprint.iacr.org/2025/1848</guid>
<content:encoded><![CDATA[
Blind signatures (BS) allow a signer to produce a valid signature on a message without learning the message itself. They have niche applications in privacy-preserving protocols such as digital cash and electronic voting. Non-interactive blind signatures (NIBS) remove the need for interaction between the signer and the user. In the post-quantum era, lattice-based NIBS schemes are studied as candidates for long-term security.

In Asiacrypt 2024, Baldimtsi et al. proposed the first lattice-based NIBS construction, whose security relies on the random one-more inhomogeneous short integer solution (rOM-ISIS) assumption. This rOM-ISIS is considered to be a non-standard assumption. Later, Zhang et al. introduced another lattice-based construction in ProvSec 2024, and proved its security under the standard module short integer solution (MSIS) assumption. We analyse the security of the latter scheme. In the random oracle model, we show that it fails to achieve both nonce blindness and receiver blindness. We present explicit attacks where an adversary breaks both properties with probability~1. Our attack is based on a crucial observation that uncovers a flaw in the design. Specifically, this flaw allows an attacker to link a message-signature pair with its presignature-nonce pair. In addition, we also identify a flaw in the unforgeability proof. Finally, we suggest a modification to address the issue, which is similar to Baldimtsi et al. construction, and its security relies again on the non-standard rOM-ISIS assumption. This work again raises the question of the feasibility of achieving NIBS from standard assumptions.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 15:17:43 +0000</pubDate>
</item>
<item>
<title>Security Analysis of Privately Verifiable Privacy Pass</title>
<link>https://eprint.iacr.org/2025/1847</link>
<guid>https://eprint.iacr.org/2025/1847</guid>
<content:encoded><![CDATA[
Privacy Pass is an anonymous authentication protocol which was initially designed by Davidson et al. (PETS’18) to reduce the number of CAPTCHAs that TOR users must solve. It issues single-use authentication tokens with anonymous and unlinkable redemption guarantees. The issuer and verifier of the protocol share a symmetric key, and tokens are privately verifiable. The protocol has sparked interest from both academia and industry, which led to an Internet Engineering Task Force (IETF) standard. While Davidson et al. formally analyzed the original protocol, the IETF standard introduces several changes to their protocol. Thus, the standardized version’s formal security remains unexamined. We fill this gap by analyzing the IETF standard’s privately verifiable Privacy Pass protocol.

In particular, there are two main discrepancies between the analyzed and standardized version: First, the IETF version introduces a redemption context, that can be used for blindly embedding a validity period into the Privacy Pass tokens. We show that this variant has significant differences to public metadata extension that has been proposed for the same purpose in the literature. Redemption context offers better privacy and security than public metadata. We capture both stronger guarantees through game-based security definitions and show that the currently considered one-more unforgeability notion for Privacy Pass is insufficient when a redemption context is used. Thus, we propose a new property, targeted context unforgeability, and prove its incomparability to one-more unforgeability. Second, Davidson et al. focused on a concrete Diffie-Hellman based construction, whereas the IETF version is built generically from a verifiable oblivious pseudorandom function (VOPRF). Further, the analyzed protocol omitted the full redemption phase needed to prevent double-spending. We prove that the generic IETF construction satisfies the desired security and privacy guarantees covering the full life-cycle of tokens. Our analysis relies on natural security properties of VOPRFs, providing compatibility with any secure VOPRF instantiation. This enables crypto agility, e.g., allowing to switch to efficient quantum-safe VOPRFs when they become available.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 14:46:41 +0000</pubDate>
</item>
<item>
<title>HE-based On-the-Fly MPC, Revisited: Universal Composability, Approximate and Imperfect Computation, Circuit Privacy</title>
<link>https://eprint.iacr.org/2025/1845</link>
<guid>https://eprint.iacr.org/2025/1845</guid>
<content:encoded><![CDATA[
On-the-fly multi-party computation (MPC), introduced by López-Alt, Tromer, and Vaikuntanathan (STOC 2012), enables clients to dynamically join a computation without remaining continuously online. Yet, the original proposal suffers from substantial efficiency and expressivity limitations hindering practical deployments. Even though various techniques have been proposed to mitigate these shortcomings, seeing on-the-fly MPC as a combination of independent building blocks jeopardizes the security of the original model.   

Thus, we revisit on-the-fly MPC in light of recent advances and extend its formal framework to incorporate efficiency and expressivity improvements. Our approach is built around \emph{multi-group homomorphic encryption} (MGHE), which generalizes threshold and multi-key HE and serves as the core primitive for on-the-fly MPC. Our contributions are fourfold:
i) We propose new security notions for MGHE (e.g., IND-CPA with partial decryption, circuit privacy) and justify their suitability to the on-the-fly MPC.
ii) We present the first ideal functionality for MGHE in the Universal Composability (UC) framework and characterize the conditions under which it can be realized, via reductions to our proposed security notions. 
iii) We present a generic protocol that securely realizes our on-the-fly MPC functionality against a semi-malicious adversary from our MGHE functionality.
iv) Finally, we provide two generic compilers that lift these protocols to withstand a fully malicious adversary by leveraging zero-knowledge arguments. 

Our analysis in the UC framework enables modular protocol analysis, where more efficient schemes can be seamlessly substituted as long as they meet the required security defined by the functionalities, retaining the security guarantees offered by the original construction.
]]></content:encoded>
<pubDate>Mon, 06 Oct 2025 14:10:50 +0000</pubDate>
</item>
<item>
<title>Lattice-Based zk-SNARKs with Hybrid Verification Technique</title>
<link>https://eprint.iacr.org/2025/1839</link>
<guid>https://eprint.iacr.org/2025/1839</guid>
<content:encoded><![CDATA[
Zero-knowledge succinct arguments of knowledge (zkSNARK) provide short privacy-preserving proofs for general NP problems. Public verifiability of zkSNARK protocols is a desirable property, where the proof can be verified by anyone once generated. Designated-verifier zero-knowledge is useful when it is necessary that only one or a few individuals should have access to the verification result. All zkSNARK schemes are either fully publicly verifiable or can be verified by a designated verifier with a secret verification key. 

In this work, we propose a new notion of a hybrid verification mechanism. Here, the prover generates a proof that can be verified by a designated verifier. For this proof, the designated verifier can generate auxiliary information with its secret key. The combination of this proof and the auxiliary information allows any public verifier to verify the proof without any other information. We also introduce necessary security notions and mechanisms to identify a cheating designated verifier or the prover. Our hybrid verification zkSNARK construction is based on module lattices and adapts the zkSNARK construction by Ishai et al. (CCS 2021). In this construction, the designated verifier is required only once after proof generation to create the publicly verifiable proof. Our construction achieves a small constant-size proof and fast verification time, which is linear in the statement size.
]]></content:encoded>
<pubDate>Sun, 05 Oct 2025 19:28:29 +0000</pubDate>
</item>
<item>
<title>On the Limits of Consensus under Dynamic Availability and Reconfiguration</title>
<link>https://eprint.iacr.org/2025/1829</link>
<guid>https://eprint.iacr.org/2025/1829</guid>
<content:encoded><![CDATA[
Proof-of-stake blockchains require consensus protocols that support Dynamic Availability and Reconfiguration (so-called DAR setting), where the former means that the consensus protocol should remain live even if a large number of nodes temporarily crash, and the latter means it should be possible to change the set of operating nodes over time. State-of-the-art protocols for the DAR setting, such as Ethereum, Cardano’s Ouroboros, or Snow White, require unrealistic additional assumptions, such as social consensus, or that key evolution is performed even while nodes are not participating. In this paper, we identify the necessary and sufficient adversarial condition under which consensus can be achieved in the DAR setting without additional assumptions. We then introduce a new and realistic additional assumption: honest nodes dispose of their cryptographic keys the moment they express intent to exit from the set of operating nodes. To add reconfiguration to any dynamically available consensus protocol, we provide a bootstrapping gadget that is particularly simple and efficient in the common optimistic case of few reconfigurations and no double-spending attempts.
]]></content:encoded>
<pubDate>Sat, 04 Oct 2025 02:15:14 +0000</pubDate>
</item>
<item>
<title>Blind ECDSA from the ECDSA Assumption</title>
<link>https://eprint.iacr.org/2025/1827</link>
<guid>https://eprint.iacr.org/2025/1827</guid>
<content:encoded><![CDATA[
Blind signatures have become a cornerstone for privacy-sensitive applications such as digital cash, anonymous credentials, and electronic voting.
The elliptic curve variant of the Digital Signature Algorithm (ECDSA) is widely adopted due to its efficiency in resource-constrained environments, such as mobile devices and blockchain systems.
Building blind ECDSA is hence a natural goal.
One presents the first such construction relying solely on the ECDSA assumption.
Despite the inherent complexities in integrating blindness with ECDSA, we design a protocol that ensures both unforgeability and blindness without introducing new computational assumptions and ensuring concurrent security.
It involves zero-knowledge proofs based on the MPC-in-the-head paradigm for complex statements combining relations on encrypted elliptic curve points, their coordinates, and discrete logarithms.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 21:51:43 +0000</pubDate>
</item>
<item>
<title>Coppercloud: Blind Server-Supported RSA Signatures</title>
<link>https://eprint.iacr.org/2025/1824</link>
<guid>https://eprint.iacr.org/2025/1824</guid>
<content:encoded><![CDATA[
Privacy-preserving technologies are a well-established area of research for the modern digital systems, driven by the regulatory mandates, such as the GDPR, and growing demand for the users' privacy. One example from the different available technologies are blind signatures: a primitive that supports creation of privacy-sensitive applications, starting from secure e-voting and anonymous digital cash to privacy-preserving credentials and identity management systems. In this work, we introduce Coppercloud, a blind server-supported RSA signature scheme designed to enhance privacy in digital identity systems. Coppercloud enables a user to obtain a signature on a message, without revealing its content to the supporting server, while distributing the signing key between the user's device and the supporting server. We formalize the security requirements for blind server-supported signing by defining an ideal functionality, and prove that Coppercloud securely realizes this functionality in the Universal Composability (UC) model.
]]></content:encoded>
<pubDate>Fri, 03 Oct 2025 14:29:30 +0000</pubDate>
</item>
<item>
<title>Amigo: Secure Group Mesh Messaging in Realistic Protest Settings</title>
<link>https://eprint.iacr.org/2024/1872</link>
<guid>https://eprint.iacr.org/2024/1872</guid>
<content:encoded><![CDATA[
During large-scale protests, a repressive government will often disable the Internet to thwart communication between protesters. Smartphone mesh networks, which route messages over short-range, possibly ephemeral, radio connections between nearby phones, allow protesters to communicate without relying on centralized Internet infrastructure. Unfortunately, prior work on providing secure communication in Internet shutdown settings fails to adequately consider protester needs. Previous attempts fail to support efficient private group communication (a crucial requirement for protests), and evaluate their solutions in network environments which fail to accurately capture link churn, physical spectrum contention, and the mobility models found in realistic protest settings. In this paper, we introduce Amigo, a novel mesh messaging system which supports group communication through a decentralized approach to continuous key agreement, and forwards messages using a novel routing protocol. Amigo is uniquely designed to handle the challenges of ad-hoc routing scenarios, where dynamic network topologies and node mobility make achieving key agreement nontrivial. Our extensive simulations reveal the poor scalability of prior approaches, the benefits of Amigo's protest-specific optimizations, and the challenges that still must be solved to scale secure mesh networks to protests with thousands of participants.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 17:43:54 +0000</pubDate>
</item>
<item>
<title>CAPSS: A Framework for SNARK-Friendly Post-Quantum Signatures</title>
<link>https://eprint.iacr.org/2025/061</link>
<guid>https://eprint.iacr.org/2025/061</guid>
<content:encoded><![CDATA[
In this paper, we present a general framework for constructing SNARK-friendly post-quantum signature schemes based on minimal assumptions, specifically the security of an arithmetization-oriented family of permutations. The term "SNARK-friendly" here refers to the efficiency of the signature verification process in terms of SNARK constraints, such as R1CS constraints. Within the CAPSS framework, signature schemes are designed as proofs of knowledge of a secret preimage of a one-way function, where the one-way function is derived from the chosen permutation family. To obtain compact signatures with SNARK-friendly verification, we rely on SmallWood, a recently proposed hash-based zero-knowledge argument scheme well suited for statements arising in this context. From this proof system which we tweak towards SNARK-friendliness, the CAPSS framework offers a generic transformation of any arithmetization-oriented permutation family into a SNARK-friendly post-quantum signature scheme. We provide concrete instances built on permutations such as Rescue-Prime, Poseidon, Griffin, and Anemoi. For the Anemoi family, achieving 128-bit security, our approach produces signatures of sizes ranging from 9.5 to 15.5 KB, with R1CS constraints between 24K and 35K. This represents a 4-6x reduction in signature size and a 5-8x reduction in R1CS constraints compared to Loquat (CRYPTO 2024), a SNARK-friendly post-quantum signature scheme based on the Legendre PRF. We showcase CAPSS through aggregated signatures, achieving sub-kilobyte amortized size for large batches, and anonymous credentials, enabling presentation proofs under 150 KB, thus highlighting the practicality of SNARK-friendly, symmetric-based designs for post-quantum primitives.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 22:12:41 +0000</pubDate>
</item>
<item>
<title>General Modularity Lemmata about Random Variable Commitment Schemes, and a Certified Laplace Mechanism</title>
<link>https://eprint.iacr.org/2025/1622</link>
<guid>https://eprint.iacr.org/2025/1622</guid>
<content:encoded><![CDATA[
At CRYPTO'24, Bell et al. propose a definition of certified differential privacy (DP) and a quite general blueprint for satisfying it. The core of the blueprint is the new primitive called random variable commitment schemes (RVCS). Bell et al. construct RVCS's for fair coins and binomial distributions. In this work, we prove three lemmata that enable simple modular design of new RVCS's: First, we show that the properties of RVCS's are closed under polynomial sequential composition. Secondly, we show that homomorphically evaluating a function $f$ on the output of an RVCS for distribution $Z$ leads to an RVCS for distribution $f(Z)$.  Thirdly, we show (roughly) that applying a `Commit-and-Prove'-style proof of knowledge for a function $f$ onto the output of an RVCS for distribution $Z$ results in an RVCS for distribution $f(Z)$. These lemmata together imply that there exists RVCS's for any distribution which can be sampled exactly in strict polynomial time, under, for instance, the discrete logarithm assumption. This is, to the best of our knowledge, the first result establishing the existence of RVCS's for arbitrary distributions. We demonstrate the usefulness of these lemmata by constructing RVCS's for arbitrarily biased coins and a discrete Laplace distribution, leading to a certified DP protocol for a discrete Laplace mechanism. Further, we observe that the definitions by Bell et al. do not directly allow sampling algorithms with non-zero honest abort probability, which rules out many practical sampling algorithms, and we propose a slight relaxation of the definitions which enables the use of sampling methods with negligible abort probability. It is with respect to these weakened definitions that we prove our certified Laplace mechanism.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 10:54:02 +0000</pubDate>
</item>
<item>
<title>Leveraging Discrete CKKS to Bootstrap in High Precision</title>
<link>https://eprint.iacr.org/2025/1786</link>
<guid>https://eprint.iacr.org/2025/1786</guid>
<content:encoded><![CDATA[
The CKKS fully homomorphic encryption (FHE) scheme enables computations on vectors of approximate complex numbers. A moderate precision of $\approx 20$ bits often suffices but, in many applications, a higher precision is required for functionality and/or security. Indeed, to obtain IND-CPA-D security [Li-Micciancio; Eurocrypt'21], secure threshold-FHE [Asharov et al; Eurocrypt'12] and circuit privacy [Gentry; STOC'09], all known approaches require a precision that supports noise flooding. This may lead to a precision of $\approx 80$ bits, or more. High-precision CKKS is hard to achieve, notably because of bootstrapping. The main difficulty is modulus consumption: every homomorphic multiplication consumes some, out of an overall modulus budget. Unfortunately, in high precision, most known bootstrapping algorithms consume so much modulus that one needs to increase the parameters to increase the budget. The state-of-the-art approach, Meta-BTS [Bae et al; CCS'22], performs moderate-precision bootstrapping several times to enable high-precision bootstrapping, with similar modulus consumption as the base bootstrapping it builds upon. It however damages latency. 
We introduce a new approach for high-precision CKKS bootstrapping, whose cost is almost independent of the precision (as opposed to Meta-BTS) and whose modulus consumption increases significantly more slowly than with classical bootstrapping algorithms.  Our design relies on the EvalRound bootstrapping [Kim et al; Asiacrypt'22], which we improve in the high-precision context by leveraging and improving recent techniques for handling discrete data with CKKS. We obtain for the first time a non-iterative 80-bit precise bootstrapping algorithm which can be run in ring degree $N=2^{16}$, with 494 bits of remaining modulus for computations. In terms of throughput, and for 80-bit precision, our implementation shows an acceleration of 64\% compared to Meta-BTS.
]]></content:encoded>
<pubDate>Tue, 30 Sep 2025 02:30:25 +0000</pubDate>
</item>
<item>
<title>CA-MCPQ: A Context-Aware Post-Quantum Protocol for AI Agent Integrity and Security</title>
<link>https://eprint.iacr.org/2025/1790</link>
<guid>https://eprint.iacr.org/2025/1790</guid>
<content:encoded><![CDATA[
We propose CA-MCPQ, a context-aware post-quantum-secure extension of the Model Context Protocol (MCP). Unlike standard MCP, which leaves authentication, encryption, and authorization optional or implementation-specific, CA-MCPQ elevates them to mandatory protocol-level mechanisms. The design incorporates post-quantum mutual authentication, KEM-derived session keys, and authenticated sequencing to ensure session integrity and prevent replay. Role-based access control is enforced, while token-based authentication is eliminated entirely. AI dynamically infers the required security tier from contextual information and negotiates compatible PQC algorithms; each response returns a reliability score that quantifies alignment with the requested security level. 

This architecture addresses critical vulnerabilities of MCP—including token misuse, session hijacking, impersonation, and quantum attack—while preserving interoperability.
Notably, our evaluation shows that the cryptographic and transport overheads are negligible compared to model computation, confirming that strong post-quantum assurances can be achieved without degrading system performance. Overall, CA-MCPQ provides a practical path toward secure-by-design AI agent ecosystems and lays the groundwork for future extensions such as agent–agent secure coordination.
]]></content:encoded>
<pubDate>Wed, 01 Oct 2025 00:38:03 +0000</pubDate>
</item>
<item>
<title>Homomorphic Encryption Methods Applied to Cloud Computing: A Practical Architecture for Elastic, Verifiable Confidential Compute</title>
<link>https://eprint.iacr.org/2025/1775</link>
<guid>https://eprint.iacr.org/2025/1775</guid>
<content:encoded><![CDATA[
Cloud computing has matured into the default substrate for data processing, yet confidentiality demands of- ten force a hard trade-off between the utility of outsourced computation and the privacy of sensitive inputs. Homomorphic encryption (HE)[1] promises to dissolve that trade-off by enabling computation directly on ciphertexts, returning encrypted results that only the data owner can decrypt. Despite remarkable progress in fully homomorphic encryption (FHE) and leveled variants suitable for bounded-depth circuits, deploying HE at cloud scale remains challenging. The cost of ciphertext arithmetic is orders of magnitude higher than plaintext compute; noise growth and rescaling impose algorithmic discipline; vectorization and rotation keys complicate program layout; and the lack of verifiability in bare HE obliges trust in a correct-but-curious cloud[?]. This paper develops a system perspective on how to apply modern HE in cloud environments without reducing it to a boutique feature. We introduce a reference architecture that marries approximate-arithmetic HE for analytics with exact- arithmetic HE for integrity-critical operations, composes HE with succinct proofs for verifiability, and integrates a cost model into the scheduler so that elastically provisioned serverless workers can meet latency objectives under price constraints. The design begins with a compiler that lowers dataflow graphs to operator sequences parameterized by multiplicative depth L and rotation sets; it then chooses schemes and parameters—CKKS for floating-point style analytics and signal processing, BFV/BGV for integer operations and counters, TFHE-style bootstrapping for comparisons—that minimize the total time-to-result under explicit error and security budgets. A cryptographic key service supports threshold issuance and rotation-key escrow without learning plaintexts, while a storage layer packs columns into ciphertext SIMD lanes to amortize cost across tenants. For verifiability, we attach homomorphic message authentication tags to intermediate ciphertexts and wrap end-to-end executions in succinct non-interactive proofs specialized to the bilinear equations that certify correct key switching, rescaling, and boot- strapping. Analytically, we characterize latency by a linear model in the counts of core homomorphic primitives and show how to saturate GPUs or vector units with batched number-theoretic transforms to bend throughput toward practical regimes. Under realistic traces of analytic queries and encrypted inference, the architecture achieves sub-second P95 for circuits of depth six to eight with one or two bootstraps, while sustaining 128-bit security under RLWE. By treating HE not as an exotic afterthought but as a first-class cloud programming and scheduling primitive, the proposed approach demonstrates a path to confidential-by- default services in which the cloud never sees data in the clear
yet remains efficient, elastic, and auditable.
]]></content:encoded>
<pubDate>Sun, 28 Sep 2025 21:52:04 +0000</pubDate>
</item>
<item>
<title>Multiple Concurrent Proposers: Why and How</title>
<link>https://eprint.iacr.org/2025/1772</link>
<guid>https://eprint.iacr.org/2025/1772</guid>
<content:encoded><![CDATA[
Traditional single-proposer blockchains suffer from miner extractable value (MEV), where validators exploit their serial monopoly on transaction inclusion and ordering to extract rents from users. While there have been many developments at the application layer to reduce the impact of MEV, these approaches largely require auctions as a subcomponent. Running auctions efficiently on chain requires two key properties of the underlying consensus protocol: selective-censorship resistance and hiding. These properties guarantee that an adversary can neither selectively delay transactions nor see their contents before they are confirmed. We propose a multiple concurrent proposer (MCP) protocol offering exactly these properties.
]]></content:encoded>
<pubDate>Sun, 28 Sep 2025 17:17:26 +0000</pubDate>
</item>
<item>
<title>On Efficient Computations of $y^2=X^3+b/\mathbb{F}_p$ \\for Primes $p\equiv 1 \pmod 3$</title>
<link>https://eprint.iacr.org/2024/1906</link>
<guid>https://eprint.iacr.org/2024/1906</guid>
<content:encoded><![CDATA[
For a prime number $p\equiv 1 \pmod 3$, the family of curves $E_b: y^2=x^3+b/\mathbb{F}_p$  has notable practical significance, e.g., its instance secp256k1 is used in Blockchain platforms such as Bitcoin and Ethereum. With the ring $\mathbb{Z}[\omega]$ of Eisenstein integers being its ring of endomorphisms, the multiplication by 
a primitive complex cubic root of unity $\omega$ can be realized as the efficient map $(x,y)\mapsto (\beta x,y)$ (and ${\cal O}\mapsto {\cal O}$)  where $\beta$ is a cubic root of unity in $\mathbb{F}_p$. Another interesting fact is that it is easy to compute a prime $\pi = c+d\omega\in \mathbb{Z}[\omega]$ such that $p=N(\pi)$ and $\#E_b(\mathbb{F}_p)=N(\pi -1)$. These provide sufficient ingredients to use the GLV method which has been the state-of-the-art for  scalar multiplication for the family of curves $E_b/\mathbb{F}_p$.  Before the GLV method, a more powerful  scalar multiplication method, the window $\tau$-NAF of Solinas based on the Frobenius map $\tau$, had been designed for the binary Koblitz curves. The creation of GLV method reflects an effort to extend the idea of utilizing the efficient computable endomorphism $\tau$ (viewed as multiplication by complex algebraic integer as opposed to rational integer) to devise faster scalar multiplication algorithms for more classes of curves. However, as indicated in [15], to have a window $\tau$-NAF method for curves over a prime field, one has to get an endomorphism $\tau$ such that (1) its computation is not more expensive than a point doubling; (2) the $\tau$-adic expansion of the scalar is not significantly longer than its binary expansion; and (3) $N(\tau)>1$. Besides, a coefficient set for the $\tau$-adic expansion and a pre-computation must  be carefully chosen.

One of the purposes of this paper is to describe such an endomorphism for the family of curves $E_b/\mathbb{F}_p$. More specifically,  let $\tau =1-\omega$ and $P=(x,y)\in E_b(\mathbb{F}_p)$, we have
\[
\tau P  = \left(\frac{x^3+4b}{(1-\beta)^2x^2}, y\frac{x^3-8b}{(1-\beta)^3x^3}\right).
\]
Converted to Jacobian projective coordinates, this operation of $\tau$ requires $2\mathbf{S}+4\mathbf{M}$ ( $\mathbf{S}$ and $\mathbf{M}$ denote the costs for field squaring and multiplication, respectively) which is less expensive than a point doubling. The efficient formula of $\tau P$ can be further used to speed up the computation of  $3P$, compared to $10\mathbf{S}+5\mathbf{M}$ , our tripling formula just costs $4\mathbf{S}+6\mathbf{M}$. As a main ingredient for double base chain method for scalar multiplication, this tripling formula will
contribute to a greater efficiency. We also propose efficient computations of $(2-\omega)P$ and $(3-\omega)P$.  The fast computation of $\tau$ and nice properties of Eisenstein integers enable us to develop a window $\tau$NAF method for curves $E_b/\mathbb{F}_p$. This result is not only of theoretical interest but also of a higher performance due to the facts that (1) the operation $\tau^2$ can be done more efficiently that makes the average cost of $\tau$ to be close to $2.5\mathbf{S}+3\mathbf{M}$; (2)
the pre-computation for the  window $\tau$NAF method is surprisingly simple in that only about one-sixth of the coefficients need to be processed.   For the curve secp256k1, it achieves more than $11.1\%$ (or $13.4\%$ if constant-time scalar multiplication is required) of improvement over the current state-of-the-art. More improvements can be shown for large underlying fields.
]]></content:encoded>
<pubDate>Sat, 23 Nov 2024 13:53:41 +0000</pubDate>
</item>
<item>
<title>Eliminating Exponential Key Growth in PRG-Based Distributed Point Functions</title>
<link>https://eprint.iacr.org/2025/1766</link>
<guid>https://eprint.iacr.org/2025/1766</guid>
<content:encoded><![CDATA[
Distributed Point Functions (DPFs) enable sharing secret point functions across multiple parties, supporting privacy-preserving technologies such as Private Information Retrieval, and anonymous communications. While 2-party PRG-based schemes with logarithmic key sizes have been known for a decade, extending these solutions to multi-party settings has proven challenging. In particular, PRG-based multi-party DPFs have historically struggled with practicality due to key sizes growing exponentially with the number of parties and the field size.

Our work addresses this efficiency bottleneck by optimizing the PRG-based multi-party DPF scheme of Boyle et al. (EUROCRYPT'15). By leveraging the honest-majority assumption, we eliminate the exponential factor present in this scheme. Our construction is the first PRG-based multi-party DPF scheme with practical key sizes, and provides key up to $3\times$ smaller than the best known multi-party DPF. This work demonstrates that with careful optimization, PRG-based multi-party DPFs can achieve practical performances, and even obtain top performances.
]]></content:encoded>
<pubDate>Sat, 27 Sep 2025 12:11:23 +0000</pubDate>
</item>
<item>
<title>Keccacheck: towards a SNARK friendly Keccak</title>
<link>https://eprint.iacr.org/2025/1764</link>
<guid>https://eprint.iacr.org/2025/1764</guid>
<content:encoded><![CDATA[
Keccak, the hash function at the core of the Ethereum ecosystem, is computationally expensive to reason about in SNARK circuits, creating a critical bottleneck in the ability of the ZK ecosystem to reason about blockchain state. The recent state-of-the-art in proving Keccak permutations relies on proof systems that can perform lookup arguments, which—while exhibiting better performance than directly proving the hash operations in circuit—still typically require tens of thousands of constraints to prove a single keccak-f permutation. 
This paper introduces a new method, termed keccacheck, which builds upon sum-check with influence from GKR to create circuits that can batch-verify Keccak permutations with fewer than 4000 constraints per instance. Keccacheck achieves this by exploiting the logarithmic scaling of recursive verification of the sum-check protocol, reducing the computational cost of verifying large enough batches to be only slightly higher than evaluating the multilinear extension of the input and output states. Its performance becomes competitive for a batch containing 16 permutations and offers more than a 10x cost reduction for batches of 512 or more permutations. This approach enables new levels of efficiency for the ZK ecosystem, providing the performant storage proofs that are essential to light clients, cross-chain bridges, privacy-focused protocols, and roll-ups.
]]></content:encoded>
<pubDate>Fri, 26 Sep 2025 18:26:15 +0000</pubDate>
</item>
<item>
<title>Polynomial Secret Sharing Schemes and Algebraic Matroids</title>
<link>https://eprint.iacr.org/2025/368</link>
<guid>https://eprint.iacr.org/2025/368</guid>
<content:encoded><![CDATA[
Polynomial secret sharing schemes generalize the linear ones by adding more expressivity and giving room for efficiency improvements. In these schemes, the secret is an element of a finite field, and the shares are obtained by evaluating polynomials on the secret and some random field elements, i.e., for every party there is a set of polynomials that computes the share of the party.  Notably, for general access structures, the best known polynomial schemes have better share size than the best known linear ones. This work investigates the properties of the polynomials and the fields that allow these efficiency gains and aims to characterize the access structures that benefit from them.

We focus first on ideal schemes, which are optimal in the sense that the size of each share is the size of the secret. We prove that, under some restrictions, if the degrees of the sharing polynomials are not too big compared to the size of the field, then its access structure is a port of an algebraic matroid. This result establishes a new connection between ideal schemes and matroids, extending the known connection between ideal linear schemes and linearly representable matroids. 

For general polynomial schemes, we extend these results and analyze their privacy and correctness. Additionally, we show that given a set of polynomials over a field of large characteristic, one can construct linear schemes that realize the access structure determined by these polynomials; as a consequence, polynomial secret sharing schemes over these fields are not stronger than linear schemes.

While there exist ports of algebraic matroids that do not admit ideal schemes, we demonstrate that they always admit schemes with statistical security and information ratio tending to one. This is achieved by considering schemes where the sharings are points in algebraic varieties.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 11:31:02 +0000</pubDate>
</item>
<item>
<title>Cross-chain Lightning Trades: Getting the Advantages of a Custodial Exchange while Keeping Your Assets</title>
<link>https://eprint.iacr.org/2025/1746</link>
<guid>https://eprint.iacr.org/2025/1746</guid>
<content:encoded><![CDATA[
Payment channels are a cornerstone of a scalable blockchain infrastructure that enables transacting parties to lock assets on the blockchain and perform rapid off-chain updates with minimal latency and overhead. These protocols dramatically reduce on-chain interaction and improve throughput, with blockchain consensus only invoked in the event of disputes or final closure. While widely adopted in single-chain settings—such as in the Lightning Network for Bitcoin—existing constructions have several limitations, in particular they suffer from at least one of the following limitations:

    1) No cross-chain. They do not enable fast trading of assets that reside on multiple isolated blockchains.
   2) Non-optimal round complexity. The off-chain round complexity is not optimal (i.e., parties require more than two rounds to update the channel).
   3) No bitcoin compatibility. They require a more advanced scripting language that prevents cross-chain interaction between chains that only have a simple (Bitcoin-like) scripting language. 

In this work, we introduce a novel payment channel protocol that breaks through all the above limitations. Our construction supports bidirectional, multiasset, and off-chain interaction across an arbitrary set of blockchains, where each update of the channel requires the parties to send only one message each. Our protocol is fully compatible with Bitcoin and can be deployed on chains with only minimal scripting capabilities, making it broadly applicable to real-world blockchain networks.

Crucially, our design ensures atomic settlement across blockchains without relying on trusted intermediaries.  
We formally prove the security of our protocol together with a novel definition of the cross-chain payment channel that we introduce. Finally, we empirically validate our protocol, showing the minimal costs that our payment channel incurs in the setting where two parties make multiple exchanges of assets that reside on three different blockchains.
]]></content:encoded>
<pubDate>Wed, 24 Sep 2025 10:45:51 +0000</pubDate>
</item>
<item>
<title>Anonymous Random Allocation and Its Applications; Generalizing Single Secret Leader Election</title>
<link>https://eprint.iacr.org/2022/1219</link>
<guid>https://eprint.iacr.org/2022/1219</guid>
<content:encoded><![CDATA[
Random Allocation - the random assignment of the data to the parties- is a well-studied topic in the analysis of medical or judicial data, and the context of resource distribution. Random allocation reduces the chance of bias or corruption in the relevant applications, which makes the results more reliable. This is done by preventing a special or pre-planned assignment of the data to accommodate the assessment toward the desired results. This paper provides the first formal syntax and security notion of a random allocation scheme. Based on our new security notions of anonymity, confidentiality, and data-integrity, random allocation can cover more applications, such as the distributed audit system, where the confidentiality of data and the anonymity of auditors are of paramount importance. Our protocol allows the parties to stay anonymous during the concurrent executions of the protocol, even if they have revealed themselves at a certain execution. The revelation property gives the possibility to the parties to claim certain advantages/faults at the end of a protocol-execution (without breaking the data-privacy or anonymity in other protocol-executions).  We instantiate our syntax and prove the security based on simple cryptographic components and assumptions such as the Diffie-Hellman assumption,  in the random oracle model.
]]></content:encoded>
<pubDate>Wed, 14 Sep 2022 14:53:32 +0000</pubDate>
</item>
<item>
<title>Breaking the Barrier for Asynchronous MPC with a Friend</title>
<link>https://eprint.iacr.org/2025/1736</link>
<guid>https://eprint.iacr.org/2025/1736</guid>
<content:encoded><![CDATA[
Multiparty computation (MPC) is a topic of growing interest for privacy-preserving computation tasks. A few MPC libraries have been developed, and newer protocols are regularly proposed to reduce the latency overhead, improve scalability, and achieve strong termination guarantees.  However, most current MPC protocols are designed and implemented assuming network synchrony: in theory, they assume that all messages are delivered within a known time bound,  while for experimental analysis, most assume all nodes to be honest, such that the time bounds are never deployed. While deploying MPC systems in the wild and trying to minimize the latency, network synchrony is indeed a strong assumption to make: natural adverse network conditions can break the safety and/or liveness of the protocol due to simply delayed messages. 

Asynchronous MPC (AMPC) protocols can overcome the challenge as they 
do not assume fixed time bounds for message delivery delays; however, AMPC faces a natural threshold barrier of 2/3rd honest majority and introduces significant computation and/or communication overheads. This work aims to achieve the best-of-both network models by designing a practical AMPC protocol that has stronger resilience guarantees matching those for synchronous MPC. 

We achieve this by adopting the emerging helper-aided model, and designing protocols that achieve fairness not only in the simple honest majority setting but also in the dishonest majority setting. Our protocols follow the standard preprocessing-online paradigm, enabling a lightweight and fast input-dependent online phase. In the honest majority setting, our protocol relies solely on lightweight cryptographic operations. In the dishonest majority setting, the protocol requires oblivious transfer (OT) during preprocessing, which we prove is necessary in this setting. We implement our constructions and provide a thorough performance comparison with state-of-the-art MPC protocols in the helper-aided model. Our experiments demonstrate that our protocols substantially outperform the state-of-the-art helper-aided MPC scheme, while being significantly more resilient to network delays.
]]></content:encoded>
<pubDate>Tue, 23 Sep 2025 09:40:30 +0000</pubDate>
</item>
<item>
<title>Differentially Private Compression and the Sensitivity of LZ77</title>
<link>https://eprint.iacr.org/2025/1733</link>
<guid>https://eprint.iacr.org/2025/1733</guid>
<content:encoded><![CDATA[
We initiate the study of differentially private data-compression schemes motivated by the insecurity of the popular "Compress-Then-Encrypt" framework. Data compression is a useful tool which exploits redundancy in data to reduce storage/bandwidth when files are stored or transmitted. However, if the contents of a file are confidential then the length of a compressed file might leak confidential information about the content of the file itself. Encrypting a compressed file does not eliminate this leakage as data encryption schemes are only designed to hide the content of confidential message instead of the length of the message. In our proposed Differentially Private Compress-Then-Encrypt framework, we add a random positive amount of padding to the compressed file to ensure that any leakage satisfies the rigorous privacy guarantee of $(\epsilon,\delta)$-differential privacy. The amount of padding that needs to be added depends on the sensitivity of the compression scheme to small changes in the input, i.e., to what degree can changing a single character of the input message impact the length of the compressed file. While some popular compression schemes are highly sensitive to small changes in the input, we argue that effective data compression schemes do not necessarily have high sensitivity. Our primary technical contribution is analyzing the fine-grained sensitivity of the LZ77 compression scheme (IEEE Trans. Inf. Theory 1977) which is one of the most common compression schemes used in practice. We show that the global sensitivity of the LZ77 compression scheme has the upper bound $\mathcal{O}(W^{2/3}\log n)$ where $W\leq n$ denotes the size of the sliding window. When $W=n$, we show the lower bound $\Omega(n^{2/3}\log^{1/3}n)$ for the global sensitivity of the LZ77 compression scheme which is tight up to a sublogarithmic factor.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 23:50:07 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge AI Inference with High Precision</title>
<link>https://eprint.iacr.org/2025/1732</link>
<guid>https://eprint.iacr.org/2025/1732</guid>
<content:encoded><![CDATA[
Artificial Intelligence as a Service (AIaaS) enables users to query a model hosted by a service provider and receive inference results from a pre-trained model. Although AIaaS makes artificial intelligence more accessible, particularly for resource-limited users, it also raises verifiability and privacy concerns for the client and server, respectively. While zero-knowledge proof techniques can address these concerns simultaneously, they incur high proving costs due to the non-linear operations involved in AI inference and suffer from precision loss because they rely on fixed-point representations to model real numbers.

In this work, we present ZIP, an efficient and precise commit and prove zero-knowledge SNARK for AIaaS inference (both linear and non-linear layers) that natively supports IEEE-754 double-precision floating-point semantics while addressing reliability and privacy challenges inherent in AIaaS. At its core, ZIP introduces a novel relative-error-driven technique that efficiently proves the correctness of complex non-linear layers in AI inference computations without any loss of precision, and hardens existing lookup-table and range proofs with novel arithmetic constraints to defend against malicious provers. We implement ZIP and evaluate it on standard datasets (e.g., MNIST, UTKFace, and SST-2). Our experimental results show, for non-linear activation functions, ZIP reduces circuit size by up to three orders of magnitude while maintaining the full precision required by modern AI workloads.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 22:23:59 +0000</pubDate>
</item>
<item>
<title>GuardianMPC: Backdoor-resilient Neural Network Computation</title>
<link>https://eprint.iacr.org/2025/1729</link>
<guid>https://eprint.iacr.org/2025/1729</guid>
<content:encoded><![CDATA[
The rapid growth of deep learning (DL) has raised
serious concerns about users’ data and neural network (NN)
models’ security and privacy, particularly the risk of backdoor
insertion when outsourcing the training or employing pre-trained
models. To ensure resilience against such backdoor attacks, this
work presents GuardianMPC, a novel framework leveraging
secure multiparty computation (MPC). GuardianMPC is built
upon garbled circuits (GC) within the LEGO protocol framework
to accelerate oblivious inference on FPGAs in the presence of
malicious adversaries that can manipulate the model weights
and/or insert a backdoor in the architecture of a pre-trained
model. In this regard, GuardianMPC is the first to offer private
function evaluation in the LEGO family. GuardianMPC
also supports private training to effectively counter backdoor
attacks targeting NN model architectures and parameters. With
optimized pre-processing, GuardianMPC significantly accelerates
the online phase, achieving up to x13.44 faster computation than
its software counterparts. Our experimental results for multilayer
perceptrons (MLPs) and convolutional neural networks (CNNs) 
assess GuardianMPC’s time complexity and scalability across
diverse NN model architectures. Interestingly, GuardianMPC
does not adversely affect the training accuracy, as opposed to
many existing private training frameworks. These results confirm
GuardianMPC as a high-performance, model-agnostic solution
for secure NN computation with robust security and privacy
guarantees.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 20:01:49 +0000</pubDate>
</item>
<item>
<title>Rhizomes and the Roots of Efficiency—Improving Prio</title>
<link>https://eprint.iacr.org/2025/1727</link>
<guid>https://eprint.iacr.org/2025/1727</guid>
<content:encoded><![CDATA[
Prio, tailored under privacy-by-design principles, is a protocol for aggregating client-provided measurements between non-colluding entities. The validity of measurements is determined by using a fully linear probabilistically-checkable proof (FLPCP). The Prover distributes secret shares of the measurement and the proof to multiple Verifiers. These Verifiers can only use linear queries on the input statement for validation without accessing the actual measurement. Efficiency is key for the practical application of Prio. The FLPCP operates with polynomials represented in the Lagrange basis using roots of unity as the nodes. However, we observe opportunities to improve its performance by embracing the Lagrange basis more extensively. For instance, we show an inversion-free O(n) time-complexity algorithm for polynomial evaluation in the Lagrange basis (an alternative to the classic rational barycentric formula). By applying our methods to libprio-rs, a cutting-edge Rust implementation, the Sharding phase (proof generation) runs a 36% faster and the Prep-Init phase (proof verification) is twice as fast, showing a substantial acceleration of the most time-consuming phases of Prio.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 16:00:22 +0000</pubDate>
</item>
<item>
<title>Blockchain-based Economic Voting with Posterior Security from Lattices</title>
<link>https://eprint.iacr.org/2025/1725</link>
<guid>https://eprint.iacr.org/2025/1725</guid>
<content:encoded><![CDATA[
Electronic voting has demonstrated that it streamlines the democratic process, making it more convenient for citizens and enhancing the accuracy and speed of election results in real-world scenarios in the US, Estonia, Switzerland, and many other countries. One major challenge for e-voting, especially online voting, is ensuring that voting and tallying devices behave honestly, particularly in cases involving monetary transactions. These are addressed by economic voting, where everything is on-chain; in essence, voters utilize smart contracts to conduct all voting stages. There are very few results on economic voting, and none post-quantum secure. The challenge comes from having the entire voting system run by smart contracts. In this work, we propose the first post-quantum economic voting scheme, which combines hybrid on- and off-chain operations, called the Post-Quantum Blind Vote (PQBV). The core idea is to utilize smart contracts that enable blind signatures during the voting process. We enhance our contribution by introducing a post-quantum blind signature with Posterior Security, as proposed by Yuen et al. (CCS 2025), which retroactively enhances the privacy of already generated signatures. This has a significant impact on PQBV, as it is able to satisfy formal cryptographic privacy definitions, including ballot privacy. Our efficiency analysis reveals competitive performance compared to existing state-of-the-art post-quantum e-voting systems, such as Epoque (EuroS&amp;P 2021), which is done without blockchain.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 14:25:05 +0000</pubDate>
</item>
<item>
<title>Efficient Aggregate Anonymous Credentials for Decentralized Identity</title>
<link>https://eprint.iacr.org/2025/1724</link>
<guid>https://eprint.iacr.org/2025/1724</guid>
<content:encoded><![CDATA[
Anonymous credential schemes allow users to prove claims about themselves in a privacy-preserving manner. Put simply, a user can prove that she has an attribute value (e.g., she is a citizen) without revealing any other information about herself. Traditional schemes (including those with multiple credential issuers) operate under the assumption that each recognized issuer produces credentials for all user attributes. This assumption, however, is not practical: in the real world, no such issuer exists; an identity provider today issues a user credentials for a subset of user attributes, not all. A promising approach to support this setting is aggregate anonymous credentials, which allow a user to receive credentials from several issuers such that she can aggregate them and prove various claims about her attribute values in one shot. In this paper, we first introduce what we call aggregate tag-based signatures and describe an efficient instantiation. We then leverage the latter together with structure-preserving signatures and signatures of knowledge to construct an efficient aggregate anonymous credential scheme. We finally, formally evaluate the security of the proposed schemes and run benchmarks to showcase the practicality of the resulting scheme and its relevance for decentralized identity applications.
]]></content:encoded>
<pubDate>Mon, 22 Sep 2025 12:52:02 +0000</pubDate>
</item>
<item>
<title>BATTLE – Bonded Adversarial TournamenT with Logarithmic Escalation</title>
<link>https://eprint.iacr.org/2025/1720</link>
<guid>https://eprint.iacr.org/2025/1720</guid>
<content:encoded><![CDATA[
In our work, we introduce BATTLE, Bonded Adversarial TournamenT with Logarithmic Escalation, a tournament-style protocol that solves multiparty disputes with simultaneous assertions such that (i) bounds honest asserter capital requirements to a constant minimum initial capital and (ii) resolves any number $C$ of concurrent challenges in $\mathcal{O}(\log C)$ dispute rounds, by reinvesting dispute rewards to fund subsequent rounds (progressive buy-ins) (iii) can be realized on a stateful (Quasi)Turing-complete smart-contract enabled blockchain.
BATTLE solves a set of conflicting assertions by creating a tournament with two phases: (1) a bracket among competing asserters with one dispute per party per round, and (2) a challenger phase against the winning assertion where the asserter engages in increasing number of simultaneous disputes each round.
]]></content:encoded>
<pubDate>Sun, 21 Sep 2025 18:01:19 +0000</pubDate>
</item>
<item>
<title>Bribers, Bribers on The Chain, Is Resisting All in Vain? Trustless Consensus Manipulation Through Bribing Contracts</title>
<link>https://eprint.iacr.org/2025/1719</link>
<guid>https://eprint.iacr.org/2025/1719</guid>
<content:encoded><![CDATA[
The long-term success of cryptocurrencies largely depends on the incentive compatibility provided to the validators. Bribery attacks, facilitated trustlessly via smart contracts, threaten this foundation. This work introduces, implements, and evaluates three novel and efficient bribery contracts targeting Ethereum validators. The first bribery contract enables a briber to fork the blockchain by buying votes on their proposed blocks. The second contract incentivizes validators to voluntarily exit the consensus protocol, thus increasing the adversary's relative staking power. The third contract builds a trustless bribery market that enables the briber to auction off their manipulative power over the RANDAO, Ethereum's distributed randomness beacon. Finally, we provide an initial game-theoretical analysis of one of the described bribery markets.
]]></content:encoded>
<pubDate>Sun, 21 Sep 2025 14:40:51 +0000</pubDate>
</item>
<item>
<title>UltraMixer: A Compliant Zero-Knowledge Privacy Layer for Tokenized Real-World Assets</title>
<link>https://eprint.iacr.org/2025/1715</link>
<guid>https://eprint.iacr.org/2025/1715</guid>
<content:encoded><![CDATA[
Real-world-asset (RWA) tokens endow underlying assets with fractional ownership and more continuous settlement, yet recording these claims on transparent public ledgers exposes flows and positions, undermining market confidentiality. Practical deployments must reconcile enforceable access control with principled privacy once assets are shielded. We present UltraMixer, a noncustodial privacy layer natively compatible with ERC-3643. Compliance is enforced at the boundary via zero-knowledge proofs of whitelist membership, while in-mixer transfers and atomic trades operate over commitments with nullifiers to prevent double-spend. A generalized UTXO encoding supports heterogeneous assets (fungible and non-fungible) under a unified commitment scheme. For selective disclosure, UltraMixer provides a verdict-only $\Delta$-Window Proof of Holding that attests to continuous ownership across a time interval without revealing balances, identities, or linkages. Gas-aware batching and composable emergency controls (pause, freeze/unfreeze, force-transfer) preserve practicality and governance. The resulting architecture delivers regulator-compatible confidentiality for permissioned RWA markets.
]]></content:encoded>
<pubDate>Sun, 21 Sep 2025 04:42:32 +0000</pubDate>
</item>
<item>
<title>Ilyazh-Web3E2E: A Post-Quantum Hybrid Protocol for Forward-Secure Decentralized Messaging</title>
<link>https://eprint.iacr.org/2025/1713</link>
<guid>https://eprint.iacr.org/2025/1713</guid>
<content:encoded><![CDATA[
We propose Ilyazh-Web3E2E, a post-quantum hybrid messaging protocol combining classical and PQ-secure KEMs with forward secrecy and robust rekeying. The design augments the Double Ratchet model with hybrid key encapsulation (X25519 + ML-KEM), digital authentication (Ed25519 + ML-DSA), and re-encapsulation-based ratcheting for long-lived Web3 identity protection. The protocol emphasizes forward secrecy, post-compromise security, and decentralized identities. We sketch IND-CCA and AKE security arguments, present a concrete wire format, and provide comparisons with PQXDH and PQ3.
]]></content:encoded>
<pubDate>Sat, 20 Sep 2025 19:57:06 +0000</pubDate>
</item>
<item>
<title>The Semantic Holder (SH): Algebraic Extraction for Legal  Opposability</title>
<link>https://eprint.iacr.org/2025/1708</link>
<guid>https://eprint.iacr.org/2025/1708</guid>
<content:encoded><![CDATA[
This manuscript introduces Semantic Holder (SH), the opposability primitive within the Chaotic Affine Secure Hash (CASH) toolkit, completing the framework’s implementation of the Q2CSI philosophy. SH enables legally opposable interpretations through algebraic extraction from polynomial iteration traces, working in concert with CEE (confidentiality) and AOW (reliability). Building upon the Affine Iterated Inversion Problem (AIIP) foundation, SH provides mathematically verifiable legal interpretations with guaranteed minimum opposability bounds. We establish that SH maintains an opposability score Ω ≥ 0.60 through rigorous entropy preservation, institutional explainability, and legal contestability guarantees. The primitive features efficient STARK-proof verifiable computation, cross-jurisdictional compatibility, and quantum resistance through its reduction to AIIP hardness. We demonstrate practical applications in legal smart contracts, regulatory compliance auditing, and digital evidence authentication, providing concrete parameter recommendations for standard security levels. SH represents a
 significant advancement in cryptographic systems that must operate within legal constraints, enabling transparent and verifiable legal opposability without compromising security or performance.
]]></content:encoded>
<pubDate>Sat, 20 Sep 2025 02:18:15 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Group Signatures in the Standard Model, Revisited</title>
<link>https://eprint.iacr.org/2025/1702</link>
<guid>https://eprint.iacr.org/2025/1702</guid>
<content:encoded><![CDATA[
The study of lattice-based group signatures has been a prominent research direction since 2010. While recent advances in the field have yielded schemes in the random oracle model with strong security properties and nearly practical efficiency, the current state of affairs for lattice-based group signatures in the standard model is still much less satisfactory. Existing schemes, proposed by Katsumata and Yamada (EUROCRYPT'19) or implied by generic non-interactive zero-knowledge proofs for NP (by Peikert and Shiehian at CRYPTO'19 and by Waters at STOC'24), either only fulfil a weak notion of anonymity called selfless anonymity, or require a strong lattice assumption, or suffer from extremely large signatures and/or public keys. 
This work aims to enhance the state of affairs for lattice-based group signatures in the standard model. We provide improved constructions that simultaneously achieves: (i) signature and public key sizes significantly smaller than those of known schemes; (ii) full anonymity in the CPA and CCA senses; (iii) security based on standard SIS and LWE assumptions with polynomial approximation factors regarding worst-case lattice problems (in general lattices). Our design approach slightly departs from that of existing pairing-based and lattice-based constructions. In the design process, we adapt and develop several lattice-based cryptographic ingredients that may be of independent interest. At the heart of our constructions is a reasonably efficient non-interactive zero-knowledge proof system for relations typically appearing in advanced privacy-preserving lattice-based cryptographic protocols. These relations are addressed by a trapdoor $\Sigma$-protocol with an inverse polynomial soundness error, which is made non-interactive via the standard-model Fiat-Shamir transform of Canetti et al. (STOC'19) and a compiler by Libert et al. (ASIACRYPT'20).
]]></content:encoded>
<pubDate>Fri, 19 Sep 2025 00:21:58 +0000</pubDate>
</item>
<item>
<title>Web3 Recovery Mechanisms and User Preferences</title>
<link>https://eprint.iacr.org/2025/1687</link>
<guid>https://eprint.iacr.org/2025/1687</guid>
<content:encoded><![CDATA[
In a Web3 (blockchain) setting, account recovery allows users to regain access to their accounts after losing their authentication credentials. Although recovery mechanisms are well-established and extensively analyzed in the context of Web2 systems, Web3 presents distinct challenges. Web3 account access is typically tied to cryptographic key pairs, and private keys are not entrusted to centralized entities. This design improves security, but significantly complicates the recovery process, making it difficult or even impossible for users to regain access after loss of keys. Given the critical role that recovery plays in ensuring long-term feasibility and trust in digital systems, a range of recovery mechanisms has been proposed to accommodate the unique properties of Web3. These mechanisms aim to help users manage key loss without introducing undue friction or risk.

Although there has been an exponential increase in the use of cryptocurrency wallets in the last decade, the popularity and usage of the corresponding recovery mechanisms remain unclear. Furthermore, it is still unclear how users perceive these recovery mechanisms and what they expect from them. In this work, our objective is to empirically understand and analyze user perceptions of the various recovery mechanisms. To this end, we conducted a user survey of 331 participants and asked them to rate different mechanisms on usability, security, and availability. The results show interesting aspects of the user preferences, including their view of sharing keys among different devices and trusting their friends or family. Based on our findings, we provide insight and future directions for the developer and research community.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 23:24:13 +0000</pubDate>
</item>
<item>
<title>Honest Users Make Honest Mistakes: A Framework for Analysing eID Protocols</title>
<link>https://eprint.iacr.org/2025/1686</link>
<guid>https://eprint.iacr.org/2025/1686</guid>
<content:encoded><![CDATA[
Electronic identification (eID) protocols and federated identity management systems play an increasingly important role in our modern society, both on the internet through services from Google and others, and through the eIDAS regulation in Europe.   A key feature of eID protocols is that humans are intimately involved in the protocol, often responsible for critical security steps. Traditional security analyses of such protocols typically assume flawless user behaviour, yet widespread real-world adoption makes user mistakes inevitable. 

We present a framework for analysing the security of eID protocols that can model users making mistakes. It is suitable for automated analysis with Tamarin and supports fine-grained corruption modelling of protocol actors.  We demonstrate the framework's utility by describing and analysing common eID protocols based on passwords, mobile applications and authentication tokens, as well as by systematically evaluating the impact of various combinations of user mistakes on security.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 20:43:15 +0000</pubDate>
</item>
<item>
<title>FHEMaLe: Framework for Homomorphic Encrypted Machine Learning</title>
<link>https://eprint.iacr.org/2025/1684</link>
<guid>https://eprint.iacr.org/2025/1684</guid>
<content:encoded><![CDATA[
Machine learning (ML) has revolutionized various industries by leveraging predictive models and data-driven insights, often relying on cloud
computing for large-scale data processing. However, this dependence introduces challenges such as bandwidth constraints and network latency. Edge
computing mitigates these issues by enabling localized processing, reducing reliance on continuous cloud connectivity, and optimizing resource
allocation for dynamic workloads. Given the limited computational capacity of sensory nodes in ML systems, edge devices provide an effective
solution by offloading processing tasks. However, a critical challenge in this paradigm is to ensure user privacy while handling sensitive data
both in the cloud and in edge processing. To address this, we propose a Fully Homomorphic Encryption (FHE) enabled framework that enables
ML computations directly on encrypted data, eliminating need for decryption. The main challenge to design such framework is that ML complex
implementation steps need to be revisited with suitable optimizations to match FHE processing requirements. There are different standard libraries to
support basic computation blocks on which encrypted ML processing is to be developed. These libraries vary in supported computation operators,
computational complexity and memory demands. Those in-turn introduces latency and throughput challenges, especially on resource-constrained
edge nodes. For example, in general HE library CKKS(Cheon-Kim-Kim-Song) with packing and approximate homomorphic operation support is
known to be the best choice for privacy preserving AI algorithm implementation. However, analysis shows leveled CKKS is limited in implementing
complex operators and hence not suitable for few specific ML algorithms like KNN, Logistic Regression or general activations in NN etc without any
approximation. To avoid accuracy drops associated with approximations, Torus based FHE library (TFHE) can be a better choice to make certain
ML implementations feasible. Moreover, our study shows compared to TFHE, CKKS with huge memory requirement is not suitable for resource
constrained edge. Thus, underlying library choice to design such framework is crucial considering the trade-off between latency and accuracy. In
this work, we propose an integrated framework FHEMaLe for encrypted ML processing which takes model architecture, desired accuracy, and
platform preference as inputs and based on that appropriate execution environment is selected: a cloud platform leveraging the CKKS homomorphic
encryption library or an edge platform using the TFHE library. Further, analysis shows the limitation of performing FHE ML on a single edge device
and hence our framework partitions encrypted data, transmits it via a fabric API, and performs distributed encrypted ML computations across the
edge cluster. We implement distributed ML inference for algorithms such as 𝐾-Nearest Neighbors (KNN) (Cloud CKKS=248 sec, Edge TFHE=37
min), Support Vector Machine (SVM) (Cloud CKKS=18 sec, Edge TFHE=4.15 min), and Logistic Regression (LR) ( Cloud CKKS=17 sec, Edge
TFHE=7.82 min) on a cluster of 11 edge nodes. This work explains why KNN suffers from a major performance bottleneck in encrypted domain and
may not be a great choice for encrypted ML processing without application specific optimizations. Furthermore, our encrypted operators are capable of supporting encrypted NN processing
(Cloud CKKS= 57 sec), but we explain why CKKS is a preferred choice in this case. The distributed nature of our implementation shows a promise
of further improvement and scalability with the support of larger cluster.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 17:56:14 +0000</pubDate>
</item>
<item>
<title>Proving the Security of PeerDAS without the AGM</title>
<link>https://eprint.iacr.org/2025/1683</link>
<guid>https://eprint.iacr.org/2025/1683</guid>
<content:encoded><![CDATA[
Data availability sampling (DAS) enables clients to verify availability of data without downloading it entirely. This concept is crucial to Ethereum's roadmap. An instantiation of this concept, known as PeerDAS, relies at its core on a variant of KZG polynomial commitments and is set to be integrated into Ethereum. To assess the security of PeerDAS, Wagner and Zapico (ePrint 2024) provided a formal analysis, proving its security as a cryptographic primitive. However, their proof relies on the algebraic group model - an idealized framework known to be uninstantiable (Zhandry, CRYPTO 2022).

In this work, we establish the security of \peerdas in the standard model under falsifiable assumptions. Specifically, we eliminate reliance on the algebraic group model and instead base our proof on the ARSDH assumption (Lipmaa et al., EUROCRYPT 2024), thus strengthening the theoretical foundations of PeerDAS and enhancing confidence in its security.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 16:04:00 +0000</pubDate>
</item>
<item>
<title>pod: An Optimal-Latency, Censorship-Free, and Accountable Generalized Consensus Layer</title>
<link>https://eprint.iacr.org/2025/1682</link>
<guid>https://eprint.iacr.org/2025/1682</guid>
<content:encoded><![CDATA[
This work addresses the inherent issues of high latency in blockchains and low scalability in traditional consensus protocols. We present pod, a novel notion of consensus whose first priority is to achieve the physically-optimal latency of $2\delta$, or one round-trip, i.e., requiring only one network trip (duration $\delta$) for writing a transaction and one for reading it.

To accomplish this, we first eliminate inter-replica communication. Instead, clients send transactions directly to all replicas, which independently process transactions and append them to local logs. Replicas assigns a timestamp and a sequence number to each transaction in their logs, allowing clients to extract valuable metadata about the transactions and the system state. Later on, clients retrieve these logs and extract transactions (and associated metadata) from them.

Necessarily, this construction achieves weaker properties than a total-order broadcast protocol, due to existing lower bounds. Our work models the primitive of pod and defines its security properties. We then show pod-core, a protocol that satisfies properties such as transaction confirmation within $2\delta$, censorship resistance against Byzantine replicas, and accountability for safety violations. We show that single-shot auctions can be realized using the pod notion and observe that it is also sufficient for other popular applications.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 15:18:27 +0000</pubDate>
</item>
<item>
<title>ChipmunkRing: A Practical Post-Quantum Ring Signature Scheme for Blockchain Applications</title>
<link>https://eprint.iacr.org/2025/1680</link>
<guid>https://eprint.iacr.org/2025/1680</guid>
<content:encoded><![CDATA[
We present ChipmunkRing, a post-quantum ring signature scheme designed for blockchain deployment. Built upon the Chipmunk lattice-based signature scheme, ChipmunkRing achieves signature sizes of 20.5-279.7KB with signing times of 1.1-15.1ms and verification times of 0.4-4.5ms for rings of 2-64 participants. Our key innovation is Acorn Verification, a novel zero-knowledge scheme that replaces the Fiat-Shamir transform, enabling O(n) verification complexity with 96-byte proofs per participant and achieving 17.7× speedup for 32-participant rings compared to traditional approaches. We provide formal security proofs demonstrating 112-bit post-quantum security (NIST Level 1), comprehensive performance analysis, and support for both standard and threshold ring signatures with arbitrary threshold values.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 14:02:41 +0000</pubDate>
</item>
<item>
<title>Searchable Encryption for Conjunctive Queries with Extended Forward and Backward Privacy</title>
<link>https://eprint.iacr.org/2021/1585</link>
<guid>https://eprint.iacr.org/2021/1585</guid>
<content:encoded><![CDATA[
Recent developments in the field of Dynamic Searchable Symmetric Encryption (DSSE) with forward and backward privacy have attracted much attention from both research and industrial communities. However, most DSSE schemes with forward and backward privacy schemes only support single keyword queries, which impedes its prevalence in practice. Although some forward and backward private DSSE schemes with expressive queries (e.g., conjunctive queries) have been introduced, their backward privacy either essentially corresponds to single keyword queries or forward privacy is not comprehensive. In addition, the deletion of many DSSE schemes is achieved by addition paired with a deletion mark (i.e., lazy deletion). To address these problems, we present two novel DSSE schemes with conjunctive queries (termed \texttt{SDSSE-CQ} and \texttt{SDSSE-CQ-S}), which achieve both forward and backward privacy. To analyze their security, we present two new levels of backward privacy (named Type-O and Type-O$^-$, more and more secure), which give a more comprehensive understanding of the leakages of conjunctive queries in the \texttt{OXT} framework. Eventually, the security analysis and experimental evaluations show that the proposed schemes achieve better security with reasonable computation and communication increase.
]]></content:encoded>
<pubDate>Mon, 06 Dec 2021 03:47:21 +0000</pubDate>
</item>
<item>
<title>Strong Designated Verifier Signatures with Non-delegatability from CSIDH</title>
<link>https://eprint.iacr.org/2025/1673</link>
<guid>https://eprint.iacr.org/2025/1673</guid>
<content:encoded><![CDATA[
Abstract. Designated verifier signature allows a signer to designate a verifier who can verify the signature. A strong designated verifier signature (SDVS) enhances privacy by ensuring that the signature itself does not leak information about the signer’s identity to anyone other than the designated verifier. Non-delegatability is a property, as it prevents the signer’s ability to generate valid signatures from being delegated to others. This property is important for SDVS applications such as e-voting. To date, post-quantum SDVS schemes with non-delegatability have been proposed. These schemes are lattice-based or hash-based schemes. While isogeny-based SDVS schemes have been proposed, none of the existing works provide a proof of non-delegatability.
In this paper, we present the first isogeny-based SDVS scheme with a formal proof of non-delegatability. Our construction uses the quadratic twists of elliptic curves. The security of our scheme is proven under the commutative supersingular isogeny gap Diffie–Hellman assumption and the group action inversion problem assumption in the random oracle model.
]]></content:encoded>
<pubDate>Tue, 16 Sep 2025 05:36:07 +0000</pubDate>
</item>
<item>
<title>Hurricane Mixer: The Eye in the Storm—Embedding Regulatory Oversight into Cryptocurrency Mixing Services</title>
<link>https://eprint.iacr.org/2025/1659</link>
<guid>https://eprint.iacr.org/2025/1659</guid>
<content:encoded><![CDATA[
While transaction transparency is fundamental, it introduces privacy vulnerabilities for blockchain users requiring confidentiality. Existing privacy mixers, intended to mitigate the issue by offering obfuscation of transactional links, have been leveraged to evade emerging financial regulations in DeFi and facilitate harmful practices within the community. Regulatory concerns, driven by prosocial intentions, are raised to ensure that mixers are used responsibly complying with regulations. The research challenge is to reconcile privacy with enforceable compliance by providing designated-only transaction traceability, blocking sanctioned actors and preserving honest-user anonymity.
We tackle this challenge by introducing the Hurricane Mixer, the mixer framework that embeds compliance logic without forfeiting privacy of regular transactions. Hurricane comes in two deployable variants: Cash for fixed-denomination pools and UTXO for arbitrary-amount transfers. Both variants share the key components: a sanction list mechanism that prevents transactions involving sanctioned entities, and a mechanism that allows for possible regulatory access to encrypted transaction details for compliance purposes. We implement the full stack: Gnark Groth-16 circuits for deposit/withdraw proofs, contracts maintaining an on-chain sanction list, and dual public-key encryption for bidirectional tracing. The comprehensive evaluation illustrates the efficacy of Hurricane Mixer in ensuring privacy preservation, regulatory conformity, and cost efficiency. Experiments show that the Cash variant is more economical when the payment amount matches the denomination, the UTXO variant is better suited for large or fractional payments, and the framework overall sustains competitive gas efficiency without compromising regulator traceability.
]]></content:encoded>
<pubDate>Sat, 13 Sep 2025 04:39:16 +0000</pubDate>
</item>
<item>
<title>Lattice-based Multi-message Multi-recipient KEM/PKE with Malicious Security</title>
<link>https://eprint.iacr.org/2025/1655</link>
<guid>https://eprint.iacr.org/2025/1655</guid>
<content:encoded><![CDATA[
The efficiency of Public Key Encryption (PKE) and Key Encapsulation Mechanism (KEM), and in particular their large ciphertext size, is a bottleneck in real-world systems. This worsens in post-quantum secure schemes (e.g., lattice-based ones), whose ciphertexts are an order of magnitude larger than prior ones.%their non-post-quantum counterparts.
    
The work of Kurosawa (PKC'02) introduced multi-message multi-recipient PKE (mmPKE) to reduce the amortized ciphertext size when sending messages to more than one recipient. This notion naturally extends to multi-message multi-recipient KEM (mmKEM).

In this work, we first show concrete attacks on existing lattice-based mmPKE schemes: Using maliciously-crafted recipient public keys, these attacks completely break semantic security and key privacy, and are inherently undetectable.
    
We then introduce the first lattice-based mmKEM scheme that maintains full privacy even in the presence of maliciously-generated public keys. Concretely, the ciphertext size of our mmKEM for 100 recipients is $>10\times$ smaller than naively using Crystals-Kyber. We also show how to extend our mmKEM to mmPKE, achieving a scheme that outperforms all prior lattice-based mmPKE schemes in terms of both security and efficiency. We additionally show a similar efficiency gain when applied to batched random oblivious transfer, and to group oblivious message retrieval.

Our scheme is proven secure under a new Module-LWE variant assumption, Oracle Module-LWE, which can be of its own independent interest. 
We reduce standard MLWE to this new assumption for some parameter regimes, which also gives intuition on why this assumption holds for the parameter we are interested in (along with additional cryptanalysis).

Furthermore, we show an asymptotically efficient compiler that removes the assumption made in prior works that recipients know their position in the list of intended recipients for every ciphertext.
]]></content:encoded>
<pubDate>Fri, 12 Sep 2025 18:58:18 +0000</pubDate>
</item>
<item>
<title>Collusion-Resilience in Transaction Fee Mechanism Design</title>
<link>https://eprint.iacr.org/2024/237</link>
<guid>https://eprint.iacr.org/2024/237</guid>
<content:encoded><![CDATA[
Users bid in a transaction fee mechanism (TFM) to get their transactions included and confirmed by a blockchain protocol. Roughgarden (EC'21) initiated the formal treatment of TFMs and proposed three requirements: user incentive compatibility (UIC), miner incentive compatibility (MIC), and a form of collusion-resilience called OCA-proofness. Ethereum's EIP-1559 mechanism satisfies all three properties simultaneously when there is no contention between transactions, but loses the UIC property when there are too many eligible transactions to fit in a single block. Chung and Shi (SODA'23) considered an alternative notion of collusion-resilience, called $c$-side-contract-proofness ($c$-SCP), and showed that, when there is contention between transactions, no TFM can satisfy UIC, MIC, and $c$-SCP for any $c\geq 1$. OCA-proofness asserts that the users and a miner should not be able to ``steal from the protocol.'' On the other hand, the $c$-SCP condition requires that a coalition of a miner and a subset of users should not be able to profit through strategic deviations (whether at the expense of the protocol or of the users outside the coalition).


Our main result is the first proof that, when there is contention between transactions, no (possibly randomized) TFM in which users are expected to bid truthfully satisfies UIC, MIC, and OCA-proofness.This result resolves the main open question in Roughgarden (EC'21). We also suggest several relaxations of the basic model that allow our impossibility result to be circumvented.
]]></content:encoded>
<pubDate>Wed, 14 Feb 2024 18:21:41 +0000</pubDate>
</item>
<item>
<title>Scalable zkSNARKs for Matrix Computations: A Generic Framework for Verifiable Deep Learning</title>
<link>https://eprint.iacr.org/2025/1646</link>
<guid>https://eprint.iacr.org/2025/1646</guid>
<content:encoded><![CDATA[
Sublinear proof sizes have recently become feasible in verifiable machine learning (VML), yet no approach achieves the trio of strictly linear prover time, logarithmic proof size and verification time, and architecture privacy. Hurdles persist because we lack a succinct commitment to the full neural network and a framework for heterogeneous models, leaving verification dependent on architecture knowledge. Existing limits motivate our new approach: a unified proof-composition framework that casts VML as the design of zero-knowledge succinct non-interactive arguments of knowledge (zkSNARKs) for matrix computations. Representing neural networks with linear and non-linear layers as a directed acyclic graph of atomic matrix operations enables topology-aware composition without revealing the graph. Modeled this way, we split proving into a reduction layer and a compression layer that attests to the reduction with a proof of proof. At the reduction layer, inspired by reduction of knowledge (Crypto '23), root-node proofs are reduced to leaf-node proofs under an interface standardized for heterogeneous linear and non-linear operations. Next, a recursive zkSNARK compresses the transcript into a single proof while preserving architecture privacy.

Complexity-wise, for a matrix expression with $M$ atomic operations on $n \times n$ matrices, the prover runs in $O(M n^2)$ time while proof size and verification time are $O(\log(M n))$, outperforming known VML systems. Honed for this framework, we formalize relations directly in matrices or vectors---a more intuitive form for VML than traditional polynomials. Our LiteBullet proof, an inner-product proof based on folding and its connection to sumcheck (Crypto '21), yields a polynomial-free alternative. With these ingredients, we reconcile heterogeneity, zero-knowledge, succinctness, and architecture privacy in a single VML system.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 14:40:17 +0000</pubDate>
</item>
<item>
<title>SCA-GPT: Generation-Plan-Tool Assisted LLM Agent for Full-Automated Side-Channel Analysis on Cryptosystems</title>
<link>https://eprint.iacr.org/2025/1643</link>
<guid>https://eprint.iacr.org/2025/1643</guid>
<content:encoded><![CDATA[
Non-invasive security constitutes an essential component of hardware security, primarily involving side-channel analysis (SCA), with various international standards explicitly mandating rigorous testing. However, current SCA assessments heavily depend on expert manual procedures, resulting in significant expenditures of time and resources. Automated evaluation frameworks are not yet available. In recent years, Large Language Models (LLMs) have been widely adopted in various fields such as language generation, owing to their emergent capabilities. Particularly, LLM agents equipped with tool-usage capabilities have significantly expanded the potential of these models to interact with the physical world.
Motivated by these recent advances in LLM agents, we propose SCA-GPT, a LLM agent framework tailored for SCA tasks. The framework incorporates a Retrieval-Augmented Generation (RAG)-based expert knowledge base along with multiple SCA tools. We present a domain-specific expert knowledge base construction approach and two complementary evaluation metrics. Retrieval experiments validate the effectiveness of our knowledge base construction, achieving an average weighted score of 88.7% and an nDCG@5 of 90%, which demonstrates the contribution of structured expert entries to retrieval accuracy.By effectively infusing expert knowledge, SCA-GPT achieves fully automated, end-to-end ISO/IEC 17825-compliant tests. We conduct comprehensive experiments across three leading LLMs—DeepSeek V3, Kimi K2 and GLM 4.5—using datasets spanning seven cryptographic algorithms (e.g., AES, RSA, ECC, Kyber) and deploying on four hardware platforms, including smart cards, microcontrollers, and FPGAs. Results show that DeepSeek V3, Kimi K2, and GLM 4.5 achieve accuracies of 91.0%, 87.7%, and 82.0%, respectively, with the agent reducing testing time by an average of 76% compared with manual procedures. Notably, SCA-GPT is the first advanced LLM agent specifically designed for SCA tasks.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 10:39:06 +0000</pubDate>
</item>
<item>
<title>Rayls: A Novel Design for CBDCs</title>
<link>https://eprint.iacr.org/2025/1639</link>
<guid>https://eprint.iacr.org/2025/1639</guid>
<content:encoded><![CDATA[
In this work, we introduce Rayls, a new central bank digital currency (CBDC) design that provides privacy, high performance, and regulatory compliance. In our construction, commercial banks each run their own (private) ledger and are connected to an underlying decentralized programmable blockchain via a relayer. 
We also introduce a novel protocol that allows for efficient anonymous transactions between banks, which we call Enygma. Our design is `quantum-private' as a quantum adversary is not able to infer any information (i.e., payer, payee, amounts) about the transactions that take place in the network. We achieve high performance in cross-bank settlement via the use of ZK-SNARKs and 'double' batching. Concretely, our transactions consist of a set of commitments and a zero-knowledge proof. As a result, each transaction can pay more than 1 bank at once and, secondly, each of these individual commitments can contain aggregated transfers from multiple users. For example, bank A transfers $1M to a different bank B and that amount is actually a sum of multiple users making transfers to bank B. Commercial banks can then enforce regulatory rules locally within their ledgers. Our system is in production with one of the largest clearing houses in the world and is currently being explored in a CBDC pilot.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 04:09:07 +0000</pubDate>
</item>
<item>
<title>Rayls II: Fast, Private, and Compliant CBDCs</title>
<link>https://eprint.iacr.org/2025/1638</link>
<guid>https://eprint.iacr.org/2025/1638</guid>
<content:encoded><![CDATA[
In this work, we introduce an upgrade to Rayls, a novel central bank digital currency (CBDC) design that provides privacy, high performance, and regulatory compliance. In the Rayls construction, commercial banks each run their own (private) ledger and are connected to an underlying decentralized programmable blockchain via a relayer. 
We introduce an improved and more efficient protocol that allows for efficient anonymous transactions between banks, which is (still) called Enygma. Our design is 'quantum-private' as a quantum adversary is not able to infer any information (i.e., payer, payee, amounts) about the transactions that take place in the network. One of the main improvements of this work is that the design is now completely quantum-secure except for the current use of ZK-SNARKs. We note, however, that this is modular and can simply be updated as desired. 

We achieve high performance in cross-bank settlement via the use of ZK-SNARKs and 'double' batching and an optimized ZK implementation, with a prover time three times faster than the initial implementation and a cheaper on-chain verifier. Our transactions consist of a set of commitments and a zero-knowledge proof. As a result, each transaction can pay more than 1 bank at once and, secondly, each of these individual commitments can contain aggregated transfers from multiple users. For example, bank A transfers $1M to a different bank B and that amount is actually a sum of multiple users making transfers to bank B. Commercial banks can then enforce regulatory rules locally within their ledgers. Our system is in production with one of the largest clearing houses in the world and is currently being explored in a CBDC pilot.
]]></content:encoded>
<pubDate>Thu, 11 Sep 2025 04:03:30 +0000</pubDate>
</item>
<item>
<title>Differentially Private Access in Encrypted Search: Achieving Privacy at a Small Cost?</title>
<link>https://eprint.iacr.org/2025/1636</link>
<guid>https://eprint.iacr.org/2025/1636</guid>
<content:encoded><![CDATA[
Encrypted search focuses on protecting sensitive data in outsourced environments while enabling private queries. Although standard encrypted search algorithms are efficient, they often leak some information about the queries and data. One such leakage is the access pattern on the outsourced storage. Recent leakage-abuse attacks have exploited this seemingly harmless leakage to successfully recover both queries and data, shifting research priorities towards finding the right balance between privacy and performance. While some proposals leverage oblivious RAM or other oblivious data structures to hide the access pattern, they typically incur significant bandwidth costs.
In response, researchers have developed new schemes that ensure access leakage satisfies differential privacy (DP). Yet the security implications of these new guarantees remain unclear. Especially, compared with conventional differential privacy, the application and threat model are significantly different. To understand these implications, we investigate two concrete instances of (encrypted) range-query schemes (appeared in SODA ’19 and CCS ’22) that achieve differentially private access. We analyze their security guarantees using inference attacks to recover queries and data on real-world datasets. Our findings raise a critical concern that ensuring access leakage is differentially private either falls short of providing strong security for the queries and data, diverging from the initial goals, or offers only weak security but at a high efficiency/correctness cost. As part of our analysis, we also propose a generic security definition for DP access, and identify two general techniques for leakage mitigation, bucketization and partitioning, that may be of independent interest.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 13:44:25 +0000</pubDate>
</item>
<item>
<title>BlockLens: Detecting Malicious Transactions in Ethereum Using LLM Techniques</title>
<link>https://eprint.iacr.org/2025/1634</link>
<guid>https://eprint.iacr.org/2025/1634</guid>
<content:encoded><![CDATA[
This paper presents BlockLens, a supervised, trace-level framework for detecting malicious Ethereum transactions using large language models. Unlike previous approaches that rely on static features or storage-level abstractions, our method processes complete execution traces, capturing opcode sequences, memory information, gas usage, and call structures to accurately represent the runtime behavior of each transaction. This framework harnesses the exceptional reasoning capabilities of LLMs for long input sequences and is fine-tuned on transaction data.

We present a tokenization strategy aligned with Ethereum Virtual Machine (EVM) semantics that converts transaction execution traces into tokens. Each transaction captures its complete execution trace through simulated execution and is sliced into overlapping chunks using a sliding window, allowing for long-range context modeling within memory constraints. During inference, the model outputs both a binary decision and a probability score indicating the likelihood of malicious behavior.

We implemented the framework based on LLaMA 3.2-1B and fine-tuned the model using LoRA. We evaluated it on a curated dataset that includes both real-world attacks and normal DeFi transactions. Our model outperforms representative baselines, achieving higher F1 scores and recall at top-k thresholds. Additionally, this work offers interpretable chunk-level outputs that enhance explainability and facilitate actionable decision-making in security-critical environments.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 10:14:44 +0000</pubDate>
</item>
<item>
<title>LastRings: Lattice-based Scalable Threshold Ring Signatures</title>
<link>https://eprint.iacr.org/2025/1633</link>
<guid>https://eprint.iacr.org/2025/1633</guid>
<content:encoded><![CDATA[
In this paper, we construct the first lattice-based threshold ring signature scheme with signature size scaling logarithmically in the size of the ring while supporting arbitrary thresholds. Our construction is also concretely efficient, achieving signature sizes of less than 150kB for ring sizes up to $N = 4096$ (with threshold size $T=N/2$, say). This is substantially more compact than previous work.

Our approach is inspired by the recent work of Aardal et al. (CRYPTO 2024) on the compact aggregation of $\mathsf{Falcon}$ signatures, that uses the $\mathsf{LaBRADOR}$ lattice-based SNARKs to combine a collection of $\mathsf{Falcon}$ signatures into a single succinct argument of knowledge of those signatures. We proceed in a similar way to obtain compact threshold ring signatures from \falcon, but crucially require that the proof system be zero-knowledge in order to ensure the privacy of signers. Since $\mathsf{LaBRADOR}$ is not a zkSNARK, we associate it with a separate (non-succinct) lattice-based zero-knowledge proof system to achieve our desired properties.
]]></content:encoded>
<pubDate>Wed, 10 Sep 2025 09:01:36 +0000</pubDate>
</item>
<item>
<title>Fully Adaptive Decentralized MA-ABE: Simplified, Optimized, ASP Supported</title>
<link>https://eprint.iacr.org/2025/1628</link>
<guid>https://eprint.iacr.org/2025/1628</guid>
<content:encoded><![CDATA[
We revisit decentralized multi‑authority attribute‑based encryption (MA‑ABE) through the lens of fully adaptive security -- the most realistic setting in which an adversary can decide on‑the‑fly which users and which attribute authorities to corrupt. Previous constructions either tolerated only static authority corruption or relied on highly complex “dual system with dual‑subsystems” proof technique that inflated ciphertexts and keys.

Our first contribution is a streamlined security analysis showing -- perhaps surprisingly -- that the classic Lewko–Waters MA-ABE scheme [EUROCRYPT 2011] already achieves full adaptive security, provided its design is carefully reinterpreted and, more crucially, its security proof is re-orchestrated to conclude with an information-theoretic hybrid in place of the original target-group-based computational step. By dispensing with dual subsystems and target-group-based assumptions, we achieve a significantly simpler and tighter security proof along with a more lightweight implementation. Our construction reduces ciphertext size by 33 percent, shrinks user secret keys by 66 percent, and requires 50 percent fewer pairing operations during decryption -- all while continuing to support arbitrary collusions of users and authorities. These improvements mark a notable advance over the state-of-the-art fully adaptive decentralized MA-ABE scheme of Datta et al. [EUROCRYPT 2023]. We instantiate the scheme in both composite‑order bilinear groups under standard subgroup‑decision assumptions and in asymmetric prime‑order bilinear groups under the Matrix‑Diffie–Hellman assumption. We further show how the Kowalczyk–Wee attribute‑reuse technique [EUROCRYPT 2019] seamlessly lifts our construction from ``one‑use’’ boolean span programs (BSP) to ``multi‑use’’ policies computable in $\mathsf{NC^{1}}$, resulting in a similarly optimized construction over the state-of-the-art by Chen et al. [ASIACRYPT 2023]. 

Going beyond the Boolean world, we present the first MA-ABE construction for arithmetic span program (ASP) access policies, capturing a richer class of Boolean, arithmetic, and combinatorial computations. This advancement also enables improved concrete efficiency by allowing attributes to be handled directly as field elements, thereby eliminating the overhead of converting arithmetic computations into Boolean representations. The construction -- again presented in composite and prime orders -- retains decentralization and adaptive user‑key security, and highlights inherent barriers to handling corrupted authorities in the arithmetic setting.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 23:18:08 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Blockchain: Transition Landscape Amidst Evolving Complexity</title>
<link>https://eprint.iacr.org/2025/1626</link>
<guid>https://eprint.iacr.org/2025/1626</guid>
<content:encoded><![CDATA[
The emergence of Cryptographically Relevant Quantum Com-
puters (CRQCs) poses an existential threat to the security of contem-
porary blockchain networks, which rely on public-key cryptography vul-
nerable to Shor’s algorithm. While the need for a transition to Post-
Quantum Cryptography (PQC) is widely acknowledged, the evolution of
blockchains from simple transactional ledgers to complex, multi-layered
financial ecosystems has rendered early, simplistic migration plans ob-
solete. This paper provides a comprehensive analysis of the blockchain
PQC migration landscape as it stands in 2025. We dissect the core tech-
nical challenges, including the performance overhead of PQC algorithms,
the loss of signature aggregation efficiency vital for consensus and scala-
bility, and the cascading complexities within Layer 2 protocols and smart
contracts. Furthermore, the analysis extends to critical operational and
socio-economic hurdles, such as the ethical dilemma of dormant assets
and the conflicting incentives among diverse stakeholders including users,
developers, and regulators. By synthesizing ongoing community discus-
sions and roadmaps for Bitcoin, Ethereum, and others, this work estab-
lishes a coherent framework to evaluate migration requirements, aiming
to provide clarity for stakeholders navigating the path toward a quantum-
secure future.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 16:29:41 +0000</pubDate>
</item>
<item>
<title>Page-efficient Encrypted Multi-Maps: New Techniques for Optimal Search Bandwidth</title>
<link>https://eprint.iacr.org/2025/1621</link>
<guid>https://eprint.iacr.org/2025/1621</guid>
<content:encoded><![CDATA[
Encrypted multi-maps (EMMs) allow a client to outsource a multi-map to an untrusted server and then later retrieve the values corresponding to a queried label. They are a core building block for various applications such as encrypted cloud storage and searchable encryption. One important metric of EMMs is memory-efficiency: most schemes incur many random memory accesses per search query, leading to larger overhead compared to plaintext queries. Memory-efficient EMMs reduce random accesses but, in most known solutions, this comes at the cost of higher query bandwidth.

This work focuses on EMMs run on SSDs and we construct two page-efficient schemes---one static and one dynamic---both with optimal search bandwidth. Our static scheme achieves $\bigOtilde{\log N/p}$ page-efficiency and $\bigo(1)$ client storage, where $N$ denotes the size of the EMM and $p$ the SSD's page size. Our dynamic scheme achieves forward and backward privacy with $\bigOtilde{\log N/p}$ page-efficiency and $\bigo(M)$ client storage, where $M$ denotes the number of labels. Among schemes with optimal server storage, these are the first to combine optimal bandwidth with good page-efficiency, saving up to $\bigo(p)$ and $\bigOtilde{p\log\log (N/p)}$ bandwidth over the state-of-the-art static and dynamic schemes, respectively. Our implementation on real-world data shows strong practical performance.
]]></content:encoded>
<pubDate>Tue, 09 Sep 2025 07:48:11 +0000</pubDate>
</item>
<item>
<title>Low-Latency Rate-Distortion-Perception Trade-offs Through Randomized Distributed Function Computations</title>
<link>https://eprint.iacr.org/2025/1612</link>
<guid>https://eprint.iacr.org/2025/1612</guid>
<content:encoded><![CDATA[
Semantic communication systems focus on the transmission of meaning rather than the exact reconstruction of data, reshaping communication network design to achieve transformative efficiency in latency-sensitive and bandwidth-limited scenarios. Within this context, we investigate the rate-distortion-perception (RDP) problem for image compression, which plays a central role in producing perceptually realistic outputs under rate constraints. By employing the randomized distributed function computation (RDFC) framework, we derive an achievable non-asymptotic RDP region that captures the finite blocklength trade-offs among rate, distortion, and perceptual quality, aligning with the objectives of semantic communications. This region is further generalized to include either side information or a secrecy requirement, the latter ensuring strong secrecy against eavesdroppers through physical-layer security mechanisms and maintaining robustness in the presence of quantum-capable adversaries. The main contributions of this work are: (i) achievable bounds for non-asymptotic RDP regions subject to realism and distortion constraints; (ii) extensions to cases where side information is available at both the encoder and decoder; (iii) achievable, nonasymptotic RDP bounds with strong secrecy guarantees; (iv) characterization of the asymptotic secure RDP region under a perfect realism constraint; and (v) demonstrations of significant rate reductions and the effects of finite blocklengths, side information, and secrecy constraints. These findings offer concrete guidelines for the design of low-latency, secure, and high-fidelity image compression and generative modeling systems that generate realistic outputs, with relevance for, e.g., privacy-critical applications.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 10:18:09 +0000</pubDate>
</item>
<item>
<title>BunnyFinder: Finding Incentive Flaws for Ethereum Consensus</title>
<link>https://eprint.iacr.org/2025/1610</link>
<guid>https://eprint.iacr.org/2025/1610</guid>
<content:encoded><![CDATA[
Ethereum, a leading blockchain platform, relies on incentive mechanisms to improve its stability. Recently, several attacks targeting the incentive mechanisms have been proposed. Examples include the so-called reorganization attacks that cause blocks proposed by honest validators to be discarded to gain more rewards. Finding these attacks, however, heavily relies on expert knowledge and may involve substantial manual effort.

We present BunnyFinder, a semi-automated framework for finding incentive flaws in Ethereum. BunnyFinder is inspired by failure injection, a technique commonly used in software testing for finding implementation vulnerabilities. Instead of finding implementation vulnerabilities, we aim to find design flaws. Our main technical contributions involve a carefully designed strategy generator that generates a large pool of attack instances, an automatic workflow that launches attacks and analyzes the results, and a workflow that integrates reinforcement learning to fine-tune the attack parameters and identify the most profitable attacks. We simulate a total of 9,354 attack instances using our framework and find the following results. First, our framework reproduces five known incentive attacks that were previously found manually. Second, we find three new attacks that can be identified as incentive flaws. Finally and surprisingly, one of our experiments also identified two implementation flaws.
]]></content:encoded>
<pubDate>Mon, 08 Sep 2025 00:50:00 +0000</pubDate>
</item>
<item>
<title>An Auditable Confidentiality Protocol for Blockchain Transactions</title>
<link>https://eprint.iacr.org/2022/1672</link>
<guid>https://eprint.iacr.org/2022/1672</guid>
<content:encoded><![CDATA[
Blockchain exposes all users’ transaction data to the public, including account balances, asset holdings, trading history, etc. Such data exposure leads to potential security and personal privacy risks that restrict blockchain from broader adoption. Although some existing projects focus on single-chain confidential payment, no existing cross-chain system supports private transactions yet, which is incompatible with privacy regulations such as GDPR. Also, current confidential payment systems require users to pay high extra fees. However, a private and anonymous protocol encrypting all transaction data raises concerns about malicious and illegal activities since the protocol is difficult to audit. We need to balance privacy and auditability in blockchain.

We propose an auditable and affordable protocol for cross-chain and single-chain transactions. This protocol leverages zero-knowledge proofs to encrypt transactions and perform validation without disclosing sensitive users' data. To meet regulations, each auditor from an auditing committee will have an encrypted secret share of the transaction data. Auditors may view the private transaction data only if a majority of the committee agrees to decrypt the data. We employ a ZK-rollup scheme by processing multiple transactions in batches, which reduces private transaction costs to 90\% lower compared with solutions without ZK-rollup. We implemented the proposed scheme using Zokrates and Solidity and evaluated the protocol on the Ethereum test network, and the total one-to-one private transactions cost only 5 seconds. We also proved the security of the protocol utilizing the standard real/ideal world paradigm.
]]></content:encoded>
<pubDate>Thu, 01 Dec 2022 05:47:29 +0000</pubDate>
</item>
<item>
<title>PGC: Pretty Good Decentralized Confidential Payment System with Auditability</title>
<link>https://eprint.iacr.org/2019/319</link>
<guid>https://eprint.iacr.org/2019/319</guid>
<content:encoded><![CDATA[
Modern cryptocurrencies such as Bitcoin and Ethereum achieve decentralization by replacing a trusted center with
a distributed and append-only ledger (known as blockchain). However, removing this trusted center comes at significant cost of privacy due to the public nature of blockchain. Many existing cryptocurrencies fail to provide transaction anonymity and confidentiality, meaning that addresses of sender, receiver and transfer amount are publicly accessible.  As the privacy concerns grow, a number of academic work have sought to enhance privacy by leveraging cryptographic tools. Though strong privacy is appealing, it might be abused in some cases. Particularly, anonymity poses great challenges to auditability, which is a crucial property for the adoption of decentralized payment systems.

Aiming for a middle ground between privacy and auditability, we introduce the notion of \emph{auditable decentralized confidential payment} (ADCP) system. In addition to offering transaction confidentiality, ADCP system supports two levels of auditability, namely regulation compliance and supervision. We present a generic construction of ADCP system from integrated signature and encryption scheme and non-interactive zero-knowledge proof systems. We then instantiate our generic construction by carefully designing the underlying building blocks, yielding a standalone cryptocurrency called PGC. In PGC, the setup procedure is (semi-)transparent, and transaction cost is independent of system scale, which is roughly 1.4KB and takes under 28ms to generate and 9ms to verify.

At the core of PGC is an additively homomorphic public-key encryption scheme that we introduce, twisted ElGamal,
which is not only as secure as standard exponential ElGamal, but also friendly to Sigma protocols and range proofs.
This enables us to easily devise zero-knowledge proofs for basic correctness of transactions as well as various application-dependent policies in a modular fashion. Moreover, it is very efficient. Compared with the most efficient reported implementation of Paillier PKE, twisted ElGamal is an order of magnitude better in key and ciphertext size and decryption speed (for small message space), two orders of magnitude better in encryption speed. We believe twisted ElGamal is of independent interest on its own right. Along the way of designing and reasoning zero-knowledge proofs for PGC, we also obtain two interesting results.  One is weak forking lemma which is a useful tool to prove computational knowledge soundness. The other is a method to prove no-knowledge of discrete logarithm, which is a complement of standard proof of discrete logarithm knowledge.
]]></content:encoded>
<pubDate>Fri, 29 Mar 2019 12:54:37 +0000</pubDate>
</item>
<item>
<title>HE-SecureNet: An Efficient and Usable Framework for Model Training via Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1591</link>
<guid>https://eprint.iacr.org/2025/1591</guid>
<content:encoded><![CDATA[
Energy-efficient edge devices are essential for the widespread deployment of machine learning (ML) services. However, their limited computational capabilities make local model training infeasible. While cloud-based training offers a scalable alternative, it raises serious privacy concerns when sensitive data is outsourced. Homomorphic Encryption (HE) enables computation directly on encrypted data and has emerged as a promising solution to this privacy challenge. Yet, current HE-based training frameworks face several shortcomings: they often lack support for complex models and non-linear functions, struggle to train over multiple epochs, and require cryptographic expertise from end users.

We present HE-SecureNet, a novel framework for privacy-preserving model training on encrypted data in a single-client–server setting, using hybrid HE cryptosystems. Unlike prior HE-based solutions, HE-SecureNet supports advanced models such as Convolutional Neural Networks and handles non-linear operations including ReLU, Softmax, and MaxPooling. It introduces a level-aware training strategy that eliminates costly ciphertext level alignment across epochs. Furthermore, HE-SecureNet automatically converts ONNX models into optimized secure C++ training code, enabling seamless integration into privacy-preserving ML pipeline—without requiring cryptographic knowledge.

Experimental results demonstrate the efficiency and practicality of our approach. On the Breast Cancer dataset, HE-SecureNet achieves a 5.2× speedup and 33% higher accuracy compared to ConcreteML (Zama) and TenSEAL (OpenMined). On the MNIST dataset, it reduces CNN training latency by 2× relative to Glyph (Lou et al., NeurIPS’20), and cuts communication overhead by up to 66× on MNIST and 42× on CIFAR-10 compared to MPC-based solutions.
]]></content:encoded>
<pubDate>Thu, 04 Sep 2025 08:30:37 +0000</pubDate>
</item>
<item>
<title>Secure Agents</title>
<link>https://eprint.iacr.org/2025/1587</link>
<guid>https://eprint.iacr.org/2025/1587</guid>
<content:encoded><![CDATA[
Organizations increasingly need to pool their sensitive data for collaborative computation while keeping their own data private from each other. One approach is to use a family of cryptographic protocols called Secure Multi-Party Computation (MPC). Another option is to use a set of cloud services called clean rooms. Unfortunately, neither approach is satisfactory. MPC is orders of magnitude more resource-intensive than regular computation, making it impractical for workloads like data analytics and AI. Clean rooms do not give users the flexibility to perform arbitrary computations.

We propose and develop an approach and system called a secure agent and utilize it to create a virtual clean room, Flexroom, that is both performant and flexible. Secure agents enable parties to create a phantom identity that they can collectively control, using maliciously secure MPC, which issues API calls to external services with parameters that remain secret from all participating parties. Importantly, in Flexroom, the secure agent uses MPC not to perform the computation itself, but instead merely to orchestrate the computation in the cloud, acting as a distinct trusted entity jointly governed by all parties. As a result, Flexroom enables collaborative computation with unfettered flexibility, including the ability to use convenient cloud services. By design, the collaborative computation runs at plaintext speeds, so the overhead of Flexroom will be amortized over a long computation.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 18:19:08 +0000</pubDate>
</item>
<item>
<title>PriSrv+: Privacy and Usability-Enhanced Wireless Service Discovery with Fast and  Expressive Matchmaking Encryption</title>
<link>https://eprint.iacr.org/2025/1584</link>
<guid>https://eprint.iacr.org/2025/1584</guid>
<content:encoded><![CDATA[
Service discovery is a fundamental process in wireless networks, enabling devices to find and communicate with services dynamically, and is critical for the seamless operation of modern systems like 5G and IoT. This paper introduces PriSrv+, an advanced privacy and usability-enhanced service discovery protocol for modern wireless networks and resource-constrained environments. PriSrv+ builds upon PriSrv (NDSS'24), by addressing critical limitations in expressiveness, privacy, scalability, and efficiency, while maintaining compatibility with widely-used wireless protocols such as mDNS, BLE, and Wi-Fi. 

A key innovation in PriSrv+ is the development of Fast and Expressive Matchmaking Encryption (FEME), the first matchmaking encryption scheme capable of supporting expressive access control policies with an unbounded attribute universe, allowing any arbitrary string to be used as an attribute. FEME significantly enhances the flexibility of service discovery while ensuring robust message and attribute privacy. Compared to PriSrv, PriSrv+ optimizes cryptographic operations, achieving 7.62$\times$ faster for encryption and 6.23$\times$ faster for decryption, and dramatically reduces ciphertext sizes by 87.33$\%$. In addition, PriSrv+ reduces communication costs by 87.33$\%$ for service broadcast and 86.64$\%$ for anonymous mutual authentication compared with PriSrv. Formal security proofs confirm the security of FEME and PriSrv+. Extensive evaluations on multiple platforms demonstrate that PriSrv+ achieves superior performance, scalability, and efficiency compared to existing state-of-the-art protocols.
]]></content:encoded>
<pubDate>Wed, 03 Sep 2025 07:24:28 +0000</pubDate>
</item>
<item>
<title>Breaking Omertà: On Threshold Cryptography, Smart Collusion, and Whistleblowing</title>
<link>https://eprint.iacr.org/2025/1582</link>
<guid>https://eprint.iacr.org/2025/1582</guid>
<content:encoded><![CDATA[
Cryptographic protocols often make honesty assumptions---e.g., fewer than $t$ out of $n$ participants are adversarial. In practice, these assumptions can be hard to ensure, particularly given monetary incentives for participants to collude and deviate from the protocol.

In this work, we explore combining techniques from cryptography and mechanism design to discourage collusion. We formalize protocols in which colluders submit a cryptographic proof to whistleblow against their co-conspirators, revealing the dishonest behavior publicly. We provide general results on the cryptographic feasibility, and show how whistleblowing fits a number of applications including secret sharing, randomness beacons, and anonymous credentials.

We also introduce smart collusion---a new model for players to collude. Analogous to blockchain smart contracts, smart collusion allows colluding parties to arbitrarily coordinate and impose penalties on defectors (e.g., those that blow the whistle). We show that unconditional security is impossible against smart colluders even when whistleblowing is anonymous and can identify all colluding players. 
On the positive side, we construct a whistleblowing protocol that requires only a small deposit and can protect against smart collusion even with roughly $t$ times larger deposit.
]]></content:encoded>
<pubDate>Tue, 02 Sep 2025 23:28:17 +0000</pubDate>
</item>
<item>
<title>IronDict: Transparent Dictionaries from Polynomial Commitments</title>
<link>https://eprint.iacr.org/2025/1580</link>
<guid>https://eprint.iacr.org/2025/1580</guid>
<content:encoded><![CDATA[
We present IronDict, a transparent dictionary construction based on polynomial commitment schemes. Transparent dictionaries enable an untrusted server to maintain a mutable dictionary and provably serve clients lookup queries. A major open challenge is supporting efficient auditing by lightweight clients. Previous solutions either incurred high server costs (limiting throughput) or high client lookup verification costs, hindering them from modern messaging key transparency deployments with billions of users. Our construction makes black-box use of a generic multilinear polynomial commitment scheme and inherits its security notions, i.e. binding and zero-knowledge. We implement our construction with the recent KZH scheme and find that a dictionary with $1$ billion entries can be verified on a consumer-grade laptop in $35$ ms, a $300\times$ improvement over the state of the art, while also achieving $150{,}000\times$ smaller proofs ($8$ KB). In addition, our construction ensures perfect privacy with concretely efficient costs for both the client and the server. We also show fast-forwarding techniques based on incremental verifiable computation (IVC) and checkpoints to enable even faster client auditing.
]]></content:encoded>
<pubDate>Tue, 02 Sep 2025 20:10:18 +0000</pubDate>
</item>
<item>
<title>TACITA: Threshold Aggregation without Client Interaction</title>
<link>https://eprint.iacr.org/2025/1579</link>
<guid>https://eprint.iacr.org/2025/1579</guid>
<content:encoded><![CDATA[
Secure aggregation enables a central server to compute the sum of client inputs without learning any individual input, even in the presence of dropouts or partial participation. This primitive is fundamental to privacy-preserving applications such as federated learning, where clients collaboratively train models without revealing raw data.

We present a new secure aggregation protocol, TACITA, in the single-server setting that satisfies four critical properties simultaneously: (1) one-shot communication from clients with no per-instance setup, (2) input-soundness, i.e. the server cannot manipulate the ciphertexts, (3) constant-size communication per client, independent of the number of participants per-instance,  and (4) robustness to client dropouts


Previous works on secure aggregation - Willow and OPA (CRYPTO'25) that achieve one-shot communication do not provide input soundness, and allow the server to manipulate the aggregation. They consequently do not achieve full privacy and only achieve Differential Privacy guarantees at best. We achieve full privacy at the cost of assuming a PKI. Specifically,  TACITA relies on a novel cryptographic primitive we introduce and realize: succinct multi-key linearly homomorphic threshold signatures (MKLHTS), which enables verifiable aggregation of client-signed inputs with constant-size signatures. 
To encrypt client inputs, we adapt the Silent Threshold Encryption (STE) scheme of Garg et al. (CRYPTO 2024) to support ciphertext-specific decryption and additive homomorphism.

We formally prove security in the Universal Composability framework and demonstrate practicality through an open-source proof-of-concept implementation, showing our protocol achieves scalability without sacrificing efficiency or requiring new trust assumptions.
]]></content:encoded>
<pubDate>Tue, 02 Sep 2025 19:50:14 +0000</pubDate>
</item>
<item>
<title>BitPriv: A Privacy-Preserving Protocol for DeFi Applications on Bitcoin</title>
<link>https://eprint.iacr.org/2025/1575</link>
<guid>https://eprint.iacr.org/2025/1575</guid>
<content:encoded><![CDATA[
Bitcoin secures over a trillion dollars in assets but remains largely absent from decentralized finance (DeFi) due to its restrictive scripting language. The emergence of BitVM, which enables verification of arbitrary off-chain computations via on-chain fraud proofs, opens the door to expressive Bitcoin-native applications without altering consensus rules. A key challenge for smart contracts executed on a public blockchain, however, is the privacy of data: for instance, bid privacy is crucial in auctions and transaction privacy is leveraged in MEV-mitigation techniques such as proposer-builder separation.  While different solutions have been recently proposed for Ethereum, these are not applicable to  Bitcoin.
   In this work, we present BitPriv, the first Bitcoin-compatible protocol to condition payments based on the outcome of a secure two-party computation (2PC). The key idea is to let parties lock collateral on-chain and to evaluate a garbled circuit off-chain: a cut-and-choose mechanism deters misbehavior and any violation can be proven and punished on-chain via BitVM. This design achieves security against rational adversaries, ensuring that deviation is irrational under financial penalties.
    We showcase the new class of applications enabled by BitPriv as well as evaluate its performance  through a privacy-preserving double-blind marketplace in Bitcoin. In the optimistic case, settlement requires only two transactions and under \$3 in fees; disputes are more expensive (≈\$507) with their cost tied to the specific BitVM implementation, but their mere feasibility acts as a strong deterrent. BitPriv provides a blueprint for building enforceable, privacy-preserving DeFi primitives on Bitcoin without trusted hardware, sidechains, or protocol changes.
]]></content:encoded>
<pubDate>Tue, 02 Sep 2025 14:27:52 +0000</pubDate>
</item>
<item>
<title>Tree-based Lookup Table on Batched Encrypted Queries using Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/087</link>
<guid>https://eprint.iacr.org/2024/087</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) is in the spotlight as a solution for privacy-related issues in various real-world scenarios. However, the limited types of operations supported by each HE scheme have been a major drawback in applications. While HE schemes based on learning-with-error (LWE) problem provide efficient lookup table (LUT) evaluation in terms of latency, they have downsides in arithmetic operations and low throughput compared to HE schemes based on ring LWE (RLWE) problem. The use of HE on circuits containing LUT has been partly limited if they contain arithmetic operations or their computational width is large.

In this paper, we propose homomorphic algorithms for batched queries on LUTs by using RLWE-based HE schemes. To look up encrypted LUTs of size $n$ on encrypted queries, our algorithms use $O(\log{n})$ homomorphic comparisons and $O(n)$ multiplications. For unencrypted LUTs, our algorithms use $O(\log{n})$ comparisons, $O(\sqrt{n})$ ciphertext multiplications, and $O(n)$ scalar multiplications.

We provide a proof-of-concept implementation based on CKKS scheme (Asiacrypt 2017). The amortized running time for an encrypted (Resp. unencrypted) LUT of size $512$ is $0.041$ (Resp. $0.025$) seconds. Our implementation reported roughly $2.4$-$6.0$x higher throughput than the current implementation of LWE-based schemes, with more flexibility on the structure of the LUTs.
]]></content:encoded>
<pubDate>Fri, 19 Jan 2024 07:53:22 +0000</pubDate>
</item>
<item>
<title>Lattice-based Threshold Blind Signatures</title>
<link>https://eprint.iacr.org/2025/1566</link>
<guid>https://eprint.iacr.org/2025/1566</guid>
<content:encoded><![CDATA[
Blind signatures are a central tool for privacy-preserving protocols. They allow users to obtain signatures from a signer without the signer seeing the signed message. For instance, it enables electronic cash: signatures correspond to coins which can be issued by the bank in a privacy-preserving manner via blind signing. To mitigate the risk of key compromise, threshold blind signatures allow the distribution of the signing key amongst N parties. While recent works have focused on improving the security of this primitive in the classical setting, no construction is known to date in the post-quantum setting. We present the first construction of a threshold blind signature secure in the post-quantum setting, based on lattices. We prove its security under an interactive variant of the SIS assumption introduced in [Agrawal et al., CCS’22]. Our construction has a reasonable overhead of a factor of roughly 1.4 X to 2.5 X in signature size over comparable non-threshold blind signatures over lattices under heuristic but natural assumptions.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 13:18:55 +0000</pubDate>
</item>
<item>
<title>Game Changer: A Modular Framework for OPRF Security</title>
<link>https://eprint.iacr.org/2025/1565</link>
<guid>https://eprint.iacr.org/2025/1565</guid>
<content:encoded><![CDATA[
Oblivious pseudorandom functions (OPRFs) allow the blind evaluation of a pseudorandom function, which makes them a versatile building block that enjoys usage in numerous applications. So far, security of OPRFs is predominantly captured in the Universal Composability (UC) framework, where an ideal functionality covers the expected security and privacy properties. While the OPRF functionality appears intuitive at first, the ideal-world paradigm also comes with a number of challenges: from imposing idealized building blocks when building OPRFs, to the lack of modularity, and requiring intricate UC knowledge to securely maneuver their usage. Game-based definitions are a simpler way to cover security properties. They model each property in a single game, which grants modularity in formalizing, proving, and using OPRFs. Interestingly, the few game-based works on OPRFs each re-invent the security model, with considerable variation. Thus, the advantages of the game-based approach remain out of reach: definitions are not easily accessible and comparability across works is low. In this work, we therefore systematize all existing notions into a clear, hierarchical framework. We unify or separate properties, making hidden relations explicit. This effort reveals the necessity of two novel properties: an intermediate privacy notion and a stronger unpredictability notion. Finally, we analyze the two most prominent constructions in our framework: HashDH and 2HashDH. The former does not achieve UC security, but has advantages in applications that require key rotation or updatability; yet it lacks a security analysis. We show that it achieves most security properties in our framework. We also observe that HashDH and 2HashDH do not satisfy our strongest privacy notion, indicating that the guarantees by the UC functionality are not as well understood as we might expect them to be. Overall, we hope that our framework facilitates the usage and design of OPRFs.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 09:52:18 +0000</pubDate>
</item>
<item>
<title>SoK: Blockchain Consensus in the Quantum Age</title>
<link>https://eprint.iacr.org/2025/1564</link>
<guid>https://eprint.iacr.org/2025/1564</guid>
<content:encoded><![CDATA[
Consensus protocols are an important building block in blockchain and blockchain-based systems. The recent focus in developing practical quantum computers reinforces the importance of designing quantum-resistant cryptographic protocols, and in the context of this paper quantum-resistant consensus protocols. In this paper, we systematically review the extant literature on quantum-resistant consensus protocols published between 2019 and 2024. As part of
the review, we identify a number of limitations and challenges and discuss potential future research directions.
]]></content:encoded>
<pubDate>Mon, 01 Sep 2025 03:42:20 +0000</pubDate>
</item>
<item>
<title>On the Termination of the HotStuff Protocol Within the Universally Composable Framework</title>
<link>https://eprint.iacr.org/2025/1560</link>
<guid>https://eprint.iacr.org/2025/1560</guid>
<content:encoded><![CDATA[
HotStuff has gained widespread application in scenarios such as consortium chains in recent years due to its linear view change and pipelined decision making mechanisms. Although there have been studies on the  performance of this algorithm, there remains a lack of  analysis and formal termination proofs regarding its composability. This paper, for the first time, constructs a comprehensive formal system for the HotStuff protocol in a partially synchronous network environment under the Universally Composable (UC) framework and proves the termination of the HotStuff protocol within the UC framework. 
Specifically, we establish the ideal function and demonstrate that the HotStuff protocol UC realizes this ideal function, which guarantees the indistinguishability between the real protocol of HotStuff and the ideal function.
Notably, in the context of network delay attacks, this paper uses a phased time analysis method with an exponential backoff timeout mechanism to show that the protocol can still achieve consensus within a bounded amount of time. 
The results of this work not only establish a formal proof paradigm for analyzing termination of BFT protocols in a composable framework, but also provide important theoretical foundations for ensuring reliable termination in industrial-grade blockchain systems (such as the Meta Diem project and Chang’an Chain that employ HotStuff).
]]></content:encoded>
<pubDate>Sun, 31 Aug 2025 07:52:01 +0000</pubDate>
</item>
<item>
<title>Lower Bounding Update Frequency in Short Accumulators and Vector Commitments</title>
<link>https://eprint.iacr.org/2025/1558</link>
<guid>https://eprint.iacr.org/2025/1558</guid>
<content:encoded><![CDATA[
We study the inherent limitations of additive accumulators and updatable vector commitments (VCs) with constant-size digest (i.e., independent of the number of committed elements). 

Specifically, we prove two lower bounds on the expected number of membership proofs that must be updated when a \emph{single} element is added (or updated) in such data structures. Our results imply that when the digest bit length approaches the concrete security level, then the expected number of proofs invalidated due to an append operation for a digest committing to $n$ elements is nearly maximal: $n-\mathsf{negl}(\lambda)$ in the case of exponential-size universes, and $n-o(n)$ for super-polynomial universes. Our results have significant implications for stateless blockchain designs relying on constant-size VCs, suggesting that the overhead of frequent proof updates may offset the benefits of reducing global state storage.
]]></content:encoded>
<pubDate>Sat, 30 Aug 2025 07:40:05 +0000</pubDate>
</item>
<item>
<title>CryptoFace: End-to-End Encrypted Face Recognition</title>
<link>https://eprint.iacr.org/2025/1556</link>
<guid>https://eprint.iacr.org/2025/1556</guid>
<content:encoded><![CDATA[
Face recognition is central to many authentication, security, and personalized applications. Yet, it suffers from significant privacy risks, particularly arising from unauthorized access to sensitive biometric data. This paper introduces CryptoFace, the first end-to-end encrypted face recognition system with fully homomorphic encryption (FHE). It enables secure processing of facial data across all stages of a face-recognition process—feature extraction, storage, and matching—without exposing raw images or features. We introduce a mixture of shallow patch convolutional networks to support higher-dimensional tensors via patch-based processing while reducing the multiplicative depth and, thus, inference latency. Parallel FHE evaluation of these networks ensures near-resolution-independent latency. On standard face recognition benchmarks, CryptoFace significantly accelerates inference and increases verification accuracy compared to the state-of-the-art FHE neural networks adapted for face recognition. CryptoFace will facilitate secure face recognition systems requiring robust and provable security. The code is available at https://github.com/human-analysis/CryptoFace.
]]></content:encoded>
<pubDate>Sat, 30 Aug 2025 02:35:02 +0000</pubDate>
</item>
<item>
<title>UniCross: A Universal Cross-Chain Payment Protocol with On-demand Privacy and High Scalability</title>
<link>https://eprint.iacr.org/2025/1554</link>
<guid>https://eprint.iacr.org/2025/1554</guid>
<content:encoded><![CDATA[
Cross-chain payment technologies have obtained broad affirmation from industry and academia as they enable assets to be circulated across the boundaries of various blockchains. However, existing cross-chain payment protocols are tailored for limited blockchains, inflexible in providing privacy guarantees, and unsatisfactory in scalability. 

To address these issues, this paper proposes a universal cross-chain payment framework. This framework enables payments across a wide range of blockchains since it is independent of any specific blockchain features. Moreover, this framework provides on-demand privacy and high scalability. To instantiate the framework, we introduce $\mathsf{UniCross}$, a novel universal cross-chain payment protocol. Concretely, we utilize the ring learning with errors (RLWE)-based encryption scheme and propose a new non-interactive zero-knowledge (NIZK) protocol, named $\mathsf{HybridProof}$, to construct $\mathsf{UniCross}$. We formally define the security of the universal cross-chain payment framework and prove the universal composability (UC) security of $\mathsf{UniCross}$. The proof-of-concept implementation and evaluation demonstrate that (1) $\mathsf{UniCross}$ consumes up to 78\% and 94\% less communication and computation cost than the state-of-the-art work; (2) $\mathsf{UniCross}$ achieves a throughput ($\sim$360 tps) 36$\times$ that of the state-of-the-art work ($\sim$10 tps).
]]></content:encoded>
<pubDate>Fri, 29 Aug 2025 11:39:01 +0000</pubDate>
</item>
<item>
<title>Incrementally Verifiable Computation for NP from Standard Assumptions</title>
<link>https://eprint.iacr.org/2025/1546</link>
<guid>https://eprint.iacr.org/2025/1546</guid>
<content:encoded><![CDATA[
Incrementally verifiable computation (IVC) [Valiant, TCC'08] allows one to iteratively prove that a configuration $x_0$ reaches another configuration $x_T$ after repeated applications of a (possibly non-deterministic) transition function $\mathcal{M}$. The key requirement is that the size of the proof and the time to update the proof is sublinear in the number of steps $T$. IVC has numerous applications, notably including proving correctness of virtual machine executions in blockchains. 

Currently, IVC for $\mathsf{NP}$ is only known to exist in non-standard idealized models, or based on knowledge assumptions. No constructions are known from standard assumptions, or even in the random oracle model. Furthermore, as observed in prior works, since IVC for $\mathsf{NP}$ implies adaptive succinct non-interactive arguments for $\mathsf{NP}$, the work of Gentry-Wichs [STOC'11] seemingly poses barriers to constructing IVC for $\mathsf{NP}$ from falsifiable assumptions.

In this work, we observe that the Gentry-Wichs barrier can be overcome for IVC for NP. We show the following two results:


- Assuming subexponential $i\mathcal{O}$ and LWE (or bilinear maps), we construct IVC for all $\mathsf{NP}$ with proof size $\mathsf{poly}(|x_i|,\log T)$.  
    
- Assuming subexponential $i\mathcal{O}$ and injective PRGs, we construct IVC for trapdoor IVC languages where the proof-size is $\mathsf{poly}(\log T)$. Informally, an IVC language has a trapdoor if there exists a (not necessarily easy to find) polynomial-sized circuit that determines if a configuration $x_i$ is reachable from $x_0$ in $i$ steps.
]]></content:encoded>
<pubDate>Thu, 28 Aug 2025 20:40:25 +0000</pubDate>
</item>
<item>
<title>A Fine-Grained and Real-Time Functional Video Encryption and Sharing Scheme</title>
<link>https://eprint.iacr.org/2025/1540</link>
<guid>https://eprint.iacr.org/2025/1540</guid>
<content:encoded><![CDATA[
In video-centric applications, video objects and backgrounds often contain sensitive information, which raises serious privacy concerns. It is necessary to restrict access to certain objects or backgrounds in the video stream while allowing permitted users to view a specific subset of video content. However, masking the prohibited objects for each user, then encoding and delivering each individually processed video to the target user will generate multiple copies of the same video. This can lead to significant storage, processing, and communication overhead when the number of users is large. In this work, inspired by the idea of functional encryption, we propose a fine-grained and real-time video encryption and sharing scheme, named FVES$^+$. In FVES$^+$, we encode and encrypt the videos only once, and different users can decode and decrypt the encrypted videos to acquire different contents depending on their access authorities. Theoretically, FVES$^+$ achieve IND-CPA security. 

We implement and evaluate FVES$^+$ using PC and mobile devices as end-devices. FVES$^+$ achieves real-time performance, averaging $35.1$ FPS across three public datasets, including the stages of object detection, encoding, and encryption. When there are $n$ different access requirements by end-users, FVES$^+$ improves video sharing speed by $\Theta(n)\times$ compared to the baseline methods. Our experiments validate the effectiveness and efficiency of FVES$^+$.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 18:03:48 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Two-Party RBF Kernel SVM Training Based on Neat and Accurate Secure Exponentiation</title>
<link>https://eprint.iacr.org/2025/1537</link>
<guid>https://eprint.iacr.org/2025/1537</guid>
<content:encoded><![CDATA[
Privacy-preserving machine learning (PPML) is a powerful tool for multiple parties to collaboratively train a model or perform model inference without exposing their private data in the context of Internet of things. A key challenge in PPML is the efficient evaluation of non-polynomial functions. In this work, we propose NASE, a neat and accurate secure exponentiation protocol for radius basis function (RBF) kernel evaluation. Leveraging the property of the RBF kernel, NASE enjoys a lightweight construction that reduces computation overhead by up to 1.65$\times$ and communication overhead by up to 3.97$\times$ compared to SIRNN, the prior SOTA framework for secure exponentiation published in IEEE S\&amp;P 2021.

Taking NASE as the foundation stone, we propose a privacy-preserving two-party kernel SVM training protocol. Based on BFV scheme and MPC technique, we introduce group-batch sampling for sampling in ciphertext and propose the partial rotation method tailored to our scenario to optimize dot product computation. Additionally, we propose an error-tolerant $DReLU$ protocol for secure sign evaluation of secret sharings over a prime field that reduces the communication cost by around $\frac{1}{3}$ compared to the existing method. Our protocol achieves model accuracy comparable to plaintext training according to experiments on real-world datasets, and an order-of-magnitude reduction in both communication and computation overhead is attained compared to the previous work.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 09:48:43 +0000</pubDate>
</item>
<item>
<title>PARSAN-Mix: Packet-Aware Routing and Shuffling with Additional Noise for Latency Optimization in Mix Networks (Extended Version)</title>
<link>https://eprint.iacr.org/2025/1533</link>
<guid>https://eprint.iacr.org/2025/1533</guid>
<content:encoded><![CDATA[
Mix networks (mix-nets) offer strong anonymity by routing client packets through intermediary hops, where they are shuffled with other packets to obscure their origins from a global adversary monitoring all communication exchanges. However, this anonymity is achieved at the expense of increased end-to-end latency, as packets traverse multiple hops (incurring routing delays) and experience additional delays at each hop for shuffling purposes. Consequently, the overall latency for delivering a message—comprising multiple packets—is determined by the packet with the highest combined routing and shuffling delay, which can significantly degrade the client experience, particularly in latency-sensitive applications.

To address this issue, our work \textbf{first} derives the theoretical statistics of the total latency experienced by a message, revealing a clear correlation between latency and the number of packets. \textbf{Second}, we propose two approaches to reduce this total latency. First, we present a method to adjust the shuffling delays at each hop, offsetting potential anonymity loss by integrating client-generated noise, backed by differential privacy guarantees. Next, we introduce packet-aware routing techniques, offering two novel methods that prioritize messages with more packets, forwarding them through faster links. However, this may cause certain nodes to be overloaded with disproportionate traffic. To solve this, we \textbf{third} introduce an efficient load-balancing algorithm to redistribute traffic without compromising the packet-aware nature of the routing. \textbf{Finally}, through comprehensive analytical and simulation experiments, we validate our theoretical latency bounds and evaluate the efficacy of our latency management strategies. The results confirm both methods substantially reduce latency with minimal impact on anonymity, while the strategic routing method remains robust against advanced adversarial attacks.


Note that this paper is an extended version of PARSAN-Mix (accepted and presented at ACNS 2025), mainly aimed at providing full proofs of the theorems together with additional empirical analysis.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 08:06:53 +0000</pubDate>
</item>
<item>
<title>Breaking the Layer Barrier: Remodeling Private Transformer Inference with Hybrid CKKS and MPC</title>
<link>https://eprint.iacr.org/2025/1532</link>
<guid>https://eprint.iacr.org/2025/1532</guid>
<content:encoded><![CDATA[
This paper presents an efficient framework for private Transformer inference that combines Homomorphic Encryption (HE) and Secure Multi-party Computation (MPC) to protect data privacy. Existing methods often leverage HE for linear layers (e.g., matrix multiplications) and MPC for non-linear layers (e.g., Softmax activation functions), but the conversion between HE and MPC introduces significant communication costs. The proposed framework, dubbed BLB, overcomes this by breaking down layers into fine-grained operators and further fusing adjacent linear operators, reducing the need for HE/MPC conversions. To manage the increased ciphertext bit width from the fused linear operators, BLB proposes the first secure conversion protocol between CKKS and MPC and enables CKKS-based computation of the fused operators. Additionally, BLB proposes an efficient matrix multiplication protocol for fused computation in Transformers. Extensive evaluations on BERT-base, BERT-large, and GPT2-base show that BLB achieves a $21\times$ reduction in communication overhead compared to BOLT (S&amp;P'24) and a $2\times$ reduction compared to Bumblebee (NDSS'25), along with latency reductions of $13\times$ and $1.8\times$, respectively, when leveraging GPU acceleration.
]]></content:encoded>
<pubDate>Wed, 27 Aug 2025 02:46:32 +0000</pubDate>
</item>
<item>
<title>Trustless Delegation of Vector Commitment Construction in Resource-Constrained Settings</title>
<link>https://eprint.iacr.org/2025/1528</link>
<guid>https://eprint.iacr.org/2025/1528</guid>
<content:encoded><![CDATA[
Many data types, such as video and audio, consist of sequential elements where both integrity and order are essential for authenticity. In practice, verifiers often access only partial sequences due to privacy or volume constraints, as in surveillance, journalism, and public records. Vector commitment (VC) schemes that support verifiable partial disclosures address this need, but constructing and maintaining such VCs is challenging for resource-constrained devices such as cameras. For example, in CCTV systems, a trusted module updating the VC for millions of frames must store and process hundreds of megabytes, which is often infeasible.

We propose a proving system that enables trustless reconstruction of VCs from only the chained hash of the sequence. The data source computes and signs a cumulative hash. An untrusted prover then constructs the VC from the raw data and proves that the data used for construction is consistent with the signed hash chain. The constructed VC subsequently enables authentication of partial disclosures. The main challenge is that proving the full VC construction in zero-knowledge is computationally expensive. To address this, we design a folding-based zkSNARK tailored to this task.

We analyze the construction in a realistic setting with a constrained source device (Raspberry Pi Zero) and a consumer-grade prover (midrange laptop). Our results show that even for relatively short sequences (e.g., 30 minutes of video footage), handling the VC within the source device's trusted module is infeasible due to both storage and computational limitations. In contrast, the proposed trustless offloading imposes only a few minutes of local computation on the prover to generate a proof for full VC construction (around 2 minutes for the 30 minutes of footage). Our implementation is available as open source at: https://github.com/zero-savvy/proven-view.
]]></content:encoded>
<pubDate>Tue, 26 Aug 2025 12:04:52 +0000</pubDate>
</item>
<item>
<title>AUPCH: Auditable Unlinkable Payment Channel Hubs</title>
<link>https://eprint.iacr.org/2025/1524</link>
<guid>https://eprint.iacr.org/2025/1524</guid>
<content:encoded><![CDATA[
Cryptocurrencies, which have gained significant adoption in
recent years, face ongoing challenges in scalability and privacy. Payment
Channel Hubs (PCHs) constitute a solution to both issues by shifting
transactions off the public ledger. Various PCH constructions have been
proposed, offering different degrees of unlinkability, efficiency, and inter-
operability. However, regulatory compliance remains a significant con-
cern, particularly under emerging frameworks like the EU’s Markets in
Crypto-Assets (MiCA) regulation and FATF Travel Rule requirements.
This work addresses a gap in existing PCH constructions: the lack of
regulatory-compliant auditability mechanisms. While concurrent work
AuditPCH attempts to address this challenge, it suffers from fundamen-
tal limitations, including reliance on channel closures for auditing, vul-
nerability to unilateral de-anonymization by the hub, and lack of formal
security guarantees for the auditing process. Our approach fundamen-
tally differs by providing targeted, non-disruptive auditability that al-
lows auditability for high-risk payments while preserving unlinkability
for the rest. To achieve this, we present Verifiable Linkable Randomiz-
able Puzzles (VLRP), a new cryptographic primitive that enables a party
to commit to a secret using two distinct keys: a verifiability key (VK)
and an auditability key (AK). This primitive provides (i) verifiability
that the owner of the VK issued the commitment, (ii) the ability to ran-
domize the commitment to ensure unlinkability, even for the owner of the
VK, while still allowing traceability using the AK, and (iii) collaborative
auditing that prevents unilateral de-anonymization.
We then present Auditable Unlinkable Payment Channel Hubs, AUPCH,
a PCH built on VLRP that offers auditability guarantees with stronger se-
curity guarantees than existing approaches. AUPCH provides modular
integration with existing PCH frameworks (A2L, BlindHub), operates
without requiring channel closures, and ensures that auditing requires
collaboration between hub and auditing agent, preventing abuse by ei-
ther party alone. Crucially, our approach acts as a wrapper around exist-
ing PCH implementations, requiring only replacing randomizable puzzle
calls with VLRP calls, a minimal change that dramatically reduces de-
ployment complexity compared to building new systems from scratch.
]]></content:encoded>
<pubDate>Mon, 25 Aug 2025 15:44:56 +0000</pubDate>
</item>
<item>
<title>Universally Composable Treatment of Multi-Party Isomorphic State Channels</title>
<link>https://eprint.iacr.org/2025/1517</link>
<guid>https://eprint.iacr.org/2025/1517</guid>
<content:encoded><![CDATA[
Layer-2 protocols are pivotal in enhancing the scalability of blockchain systems, enabling faster off-chain transactions while maintaining security. These protocols can bridge consensus-based blockchain systems and advanced applications, such as Multiparty Computation (MPC) protocols, often defined within the Universal Composability (UC) Framework. However, despite the existence of some UC-defined protocols, there is currently no comprehensive UC definition for isomorphic multiparty state channels, in particular that are not dependent on the ledger model: account or UTxO based ledger. These protocols depend heavily on timelock mechanisms and the accurate representation of time, which are challenging to model within the UC Framework. Our work addresses this gap by proposing a UC-based definition, i.e., functionality, for isomorphic multi-party state channels that realistically model timely actions of honest users, a critical feature for the security of the channel protocol. Moreover our definition is agnostic with respect to the ledger model. Additionally, we introduce an extended timelock-aided global ledger functionality and demonstrate the security of existing protocols, namely Hydra proposed by Chakravarty et al. (FC'21), under the UC Framework and our proposed functionalities. This contribution provides a robust foundation for developing secure and scalable off-chain protocols in blockchain ecosystems. Finally, we concretely provide the construction of the extension of the Hydra Protocol, only outlined by the original work, and also prove it secure under our framework.
]]></content:encoded>
<pubDate>Sat, 23 Aug 2025 06:24:25 +0000</pubDate>
</item>
<item>
<title>GoSSamer: Lightweight and Linear-Communication Asynchronous (Dynamic Proactive) Secret Sharing and the Applications</title>
<link>https://eprint.iacr.org/2025/1516</link>
<guid>https://eprint.iacr.org/2025/1516</guid>
<content:encoded><![CDATA[
Asynchronous complete secret sharing (ACSS) and asynchronous dynamic proactive secret sharing (ADPSS) are fundamental primitives for secret sharing and resharing in threshold systems. They serve broad applications in distributed key management (DKM), multi-party computation, and blockchain. However, ACSS constructions that employ homomorphic commitments incur notable computational overhead, especially in batched executions. Conversely, lightweight variants require quadratic per-secret communication, which grows rapidly with the committee size. Building upon instances of ACSS, ADPSS constructions inevitably inherit these inefficiencies. 

To address these limitations, we introduce GoSSamer, a concretely and asymptotically efficient protocol suite, where both GoSSamer-ACSS and GoSSamer-ADPSS achieve (1) lightweight computation with only finite-field arithmetic and hash functions, (2) asymptotically optimal, linear per-secret communication, (3) optimal resilience in asynchronous networks, a nd (4) post-quantum security.Leveraging our proposed share propagation and verification mechanisms, GoSSamer-ACSS reduces the runtime by 97% against the linear-communication scheme hbACSS (NDSS'22), and lowers the bandwidth usage by 75% compared to the lightweight solution SS24 (JoC'24) in a 64-node committee. By decoupling the ADPSS framework from the commitment-based ACSS through a new consistency verification technique, GoSSamer-ADPSS boosts key resharing throughput by 16-22$\times$ compared to LongLive (Usenix Security'23), and reduces its bandwidth by 47.6% in 16-node committees. GoSSamer directly accelerates real-world applications like distributed key management. Specifically, the runtime in GoSSamer-ACSS-based distributed key generation outperforms DXK+23 (Usenix Security'23) by 7-11$\times$, while GoSSamer-ADPSS-based key resharing outperforms LongLive by 9-13$\times$.
]]></content:encoded>
<pubDate>Sat, 23 Aug 2025 03:49:07 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Federated Inference for Genomic Analysis with Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1515</link>
<guid>https://eprint.iacr.org/2025/1515</guid>
<content:encoded><![CDATA[
In recent years, federated learning has gained significant momentum as a collaborative machine learning approach, particularly in the field of medicine. While the decentralized nature of federated learning boasts greater security guarantees compared to traditional machine learning methods, it is still susceptible to myriad attacks. Moreover, as federated learning becomes increasingly ubiquitous in medicine, its use for classification tasks is expected to increase; however, maintaining patient data confidentiality remains a significant challenge, especially for genetic data. In this work, we introduce a novel framework for secure federated inference on nucleotide-based genotype data and provide a gateway to private inference through fully homomorphic encryption. A federated model with five local clients was created and trained before being encrypted with the TFHE cryptosystem and placed for inference. This framework successfully identified promoter sequences encoded within given DNA sequences, showing its potential applications in secure genomic data analysis in a federated context. Our work represents a crucial step in privacy-preserving federated inference on nucleotide-based data.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 23:57:06 +0000</pubDate>
</item>
<item>
<title>Mosformer: Maliciously Secure Three-Party Inference Framework for Large Transformers</title>
<link>https://eprint.iacr.org/2025/1510</link>
<guid>https://eprint.iacr.org/2025/1510</guid>
<content:encoded><![CDATA[
Transformer-based models like BERT and GPT have achieved state-of-the-art performance across a wide range of AI tasks but raise serious privacy concerns when deployed as cloud inference services. 
To address this, secure multi-party computation (MPC) is commonly employed, encrypting both user inputs and model parameters to enable inference without revealing any private information.
However, existing MPC-based secure transformer inference protocols are predominantly designed under the semi-honest security model. Extending these protocols to support malicious security remains a significant challenge, primarily due to the substantial overhead introduced by securely evaluating complex non-linear functions required for adversarial resilience.
We introduce Mosformer, the first maliciously secure three-party (3PC) inference framework that efficiently supports large transformers such as BERT and GPT. 
We first design constant-round comparison and lookup table protocols with malicious security, leveraging verifiable distributed point functions (VDPFs). Building on these, we develop a suite of 3PC protocols for efficient and secure evaluation of complex non-linear functions in transformers. Together with optimized modulus conversion, our approach substantially reduces the overhead of secure transformer inference while preserving model accuracy.
Experimental results on the vanilla transformer block show that Mosformer achieves up to a $5.3\times$ speedup and a $4.3\times$ reduction in communication over prior maliciously secure protocols. 
Despite offering stronger security guarantees, Mosformer achieves comparable or even superior online performance to state-of-the-art semi-honest 2PC and 3PC frameworks, including BOLT (Oakland 2024), BumbleBee (NDSS 2025), SHAFT (NDSS 2025), and Ditto (ICML 2024), on full-scale models such as BERT and GPT-2.
]]></content:encoded>
<pubDate>Fri, 22 Aug 2025 08:58:41 +0000</pubDate>
</item>
<item>
<title>Data Matching in Unequal Worlds  and Applications to Smart Contracts</title>
<link>https://eprint.iacr.org/2025/1500</link>
<guid>https://eprint.iacr.org/2025/1500</guid>
<content:encoded><![CDATA[
SNARKs enable compact proofs that an NP statement is true and that the prover knows a valid witness. They have become a key building block in modern smart contract applications, including rollups and privacy-focused cryptocurrencies.
In the widely used Groth16 framework, however, long statements incur high costs.
A common workaround is to pass the statement’s hash to the SNARK and move the statement into the witness. The smart contract then hashes the statement first, and the circuit that is proven additionally checks consistency of the hash and the statement.
Unfortunately, virtually any hash function is expensive to call either in a smart contract (in terms of gas) or in the proven circuit (in terms of prover time).

We demonstrate a novel solution to this dilemma, which we call  hybrid compression. Our method allows us to use two different hash functions—one optimized for the proof circuit, and another optimized for on-chain verification—thereby combining the efficiency advantages of both. We prove the security of this approach in the standard model under reasonable assumptions about the two hash functions, and our benchmarks show that it achieves near-optimal performance in both gas usage and prover time. As an example, compressing an 8 KB statement with our approach results in a 10-second prover time and a smart contract spending 270K gas, whereas the existing approaches either need a much longer proof generation (290 seconds for SHA-256 hashing) or a much more expensive contract (5M gas for Poseidon hashing).

Along the way, we develop a two-party protocol of independent interest in communication complexity: an efficient deterministic method for checking input equality when the two parties do not share the same hash function.
]]></content:encoded>
<pubDate>Wed, 20 Aug 2025 13:42:44 +0000</pubDate>
</item>
<item>
<title>Lattice Signature with Efficient Protocols, Application to Anonymous Credentials</title>
<link>https://eprint.iacr.org/2022/509</link>
<guid>https://eprint.iacr.org/2022/509</guid>
<content:encoded><![CDATA[
Digital signature is an essential primitive in cryptography, which can be used as the digital analogue of handwritten signatures but also as a building block for more complex systems. In the latter case, signatures with specific features are needed, so as to smoothly interact with the other components of the systems, such as zero-knowledge proofs. This has given rise to so-called signatures with efficient protocols, a versatile tool that has been used in countless applications. Designing such signatures is however quite difficult, in particular if one wishes to withstand quantum computing. We are indeed aware of only one post-quantum construction, proposed by Libert et al. at Asiacrypt'16, yielding very large signatures and proofs.
In this paper, we propose a new construction that can be instantiated in both standard lattices and structured ones, resulting in each case in dramatic performance improvements. In particular, the size of a proof of message-signature possession, which is one of the main metrics for such schemes, can be brought down to less than 650 KB. As our construction retains all the features expected from signatures with efficient protocols, it can be used as a drop-in replacement in all systems using them, which mechanically improves their own performance, and has thus a direct impact on many applications. It can also be used to easily design new privacy-preserving mechanisms. As an example, we provide the first lattice-based anonymous credentials system.
]]></content:encoded>
<pubDate>Thu, 28 Apr 2022 17:17:27 +0000</pubDate>
</item>
<item>
<title>Homomorphic Secret Sharing with Verifiable Evaluation</title>
<link>https://eprint.iacr.org/2025/1491</link>
<guid>https://eprint.iacr.org/2025/1491</guid>
<content:encoded><![CDATA[
A homomorphic secret sharing (HSS) scheme allows a client to delegate a computation to a group of untrusted servers while achieving input privacy as long as at least one server is honest. In recent years, many HSS schemes have been constructed that have, in turn, found numerous applications to cryptography. 

Prior work on HSS focuses on the setting where the servers are semi-honest. In this work we study HSS in the setting of malicious evaluators. We propose the notion of HSS with verifiable evaluation (ve-HSS) that guarantees correctness of output even when all the servers are corrupted. ve-HSS retains all the attractive features of HSS and adds the new feature of succinct public verification of output. 

We present black-box constructions of ve-HSS by devising generic transformations for semi-honest HSS schemes (with negligible error). This provides a new non-interactive method for verifiable and private outsourcing of computation.
]]></content:encoded>
<pubDate>Mon, 18 Aug 2025 19:58:18 +0000</pubDate>
</item>
<item>
<title>Glock: Garbled Locks for Bitcoin</title>
<link>https://eprint.iacr.org/2025/1485</link>
<guid>https://eprint.iacr.org/2025/1485</guid>
<content:encoded><![CDATA[
Bitcoin is a decentralized, permissionless network for digital payments. Bitcoin also supports a limited set of smart contracts, which restrict how bitcoin can be spent, through bitcoin script. In order to support more expressive scripting functionality, Robin Linus introduced the BitVM family of protocols. These implement a weaker form of ``optimistic" smart contracts, and for the first time allowed bitcoin to verify arbitrary computation. BitVM allows a challenger to publish a ``fraud proof" that the computation was carried out incorrectly which can be verified on chain, even when the entire computation cannot. Jermey Rubin introduced an alternative optimistic smart contract protocol called Delbrag. This protocol uses Garbled Circuits (GC) to replace the BitVM fraud proof with by simply revealing a secret. He also introduced the Grug technique for malicious security.

We introduce a new formalization of GC based optimistic techniques called Garbled Locks or Glocks. Much like Delbrag, we use the GC to leak a secret and produce a signature as a fraud proof. We further propose the first concretely practical construction that does not require Grug. Like BitVM2 and Delbrag, Glock25 reduces verification of arbitrary bounded computation to verification of a SNARK.  In Glock25, we use a designated verifier version of a modified of the SNARK Pari with smaller proof size.  We make Glock25 maliciously secure using a combination of Cut-and-Choose, Verifiable Secret Sharing (VSS), and Adaptor Signatures. These techniques reduce the communication, computational, and on-chain complexity of the protocol compared to other approaches to construct a Glock, e.g. based on Groth16.
]]></content:encoded>
<pubDate>Sat, 16 Aug 2025 02:50:42 +0000</pubDate>
</item>
<item>
<title>Boosting Payment Channel Network Liquidity with Topology Optimization and Transaction Selection</title>
<link>https://eprint.iacr.org/2025/1484</link>
<guid>https://eprint.iacr.org/2025/1484</guid>
<content:encoded><![CDATA[
Payment channel networks (PCNs) are a promising technology that alleviates blockchain scalability by shifting the transaction load from the blockchain to the PCN. 
Nevertheless, the network topology has to be carefully designed to maximise the transaction throughput in PCNs. Additionally, users in PCNs also have to make optimal decisions on which transactions to forward and which to reject to prolong the lifetime of their channels.
In this work, we consider an input sequence of transactions over $p$ parties. Each transaction consists of a transaction size, source, and target, and can be either accepted or rejected (entailing a cost).
The goal is to design a PCN topology among the $p$ cooperating parties, along with the channel capacities, and then output a decision for each transaction in the sequence to minimise the cost of creating and augmenting channels,
as well as the cost of rejecting transactions.
Our main contribution is an $\mathcal{O}(p)$ approximation algorithm for the problem with $p$ parties.
We further show that with some assumptions on the distribution of transactions, we can reduce the approximation ratio to $\mathcal{O}(\sqrt{p})$.
We complement our theoretical analysis with an empirical study of our assumptions and approach in the context of the Lightning Network.
]]></content:encoded>
<pubDate>Fri, 15 Aug 2025 10:15:52 +0000</pubDate>
</item>
<item>
<title>PicoGRAM: Practical Garbled RAM from Decisional Diffie-Hellman</title>
<link>https://eprint.iacr.org/2025/1479</link>
<guid>https://eprint.iacr.org/2025/1479</guid>
<content:encoded><![CDATA[
Making 2-party computation scale up to big datasets is a long-cherished dream of our community. More than a decade ago, a line of work has implemented and optimized interactive RAM-model 2-party computation (2PC), achieving somewhat reasonable concrete performance on large datasets, but unfortunately suffering from $\widetilde{O}(T)$ roundtrips for a $T$-time computation. Garbled RAM promises to compress the number of roundtrips to $2$, and encouragingly, a line of recent work has designed concretely efficient Garbled RAM schemes whose asymptotic communication and computation costs almost match the best known interactive RAM-model 2PC, but still leaves $({\sf poly})\log\log$ gaps. 

We present ${\sf PicoGRAM}$, a practical garbled RAM (GRAM) scheme that not only asymptotically matches the prior best RAM-model 2PC, but also achieves an order of magnitude concrete improvement in online time relative to interactive RAM-model 2PC, on a dataset of size $8$GB. Moreover, our work also gives the first Garbled RAM whose total cost (including bandwidth and computation) achieves an optimal dependency on the database size (up to an arbitrarily small super-constant factor). 

Our work shows that for high-value real-life applications such as Signal, blockchains, and Meta that require oblivious accesses to large datasets, Garbled RAM is a promising direction towards eventually removing the trusted hardware assumption that exist in production implementations today. Our open source code is available at https://github.com/picogramimpl/picogram.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 23:12:19 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure Threshold ElGamal Decryption from DDH</title>
<link>https://eprint.iacr.org/2025/1477</link>
<guid>https://eprint.iacr.org/2025/1477</guid>
<content:encoded><![CDATA[
Threshold decryption schemes allow a group of decryptors, each holding a private key share, to jointly decrypt ciphertexts. Over the years, numerous threshold decryption schemes have been proposed for applications such as secure data storage, internet auctions, and voting, and recently as a tool to protect against miner-extractable value attacks in blockchain. Despite the importance and popularity of threshold decryption, many natural and practical threshold decryption schemes have only been proven secure against static adversaries. 

In this paper, we present two threshold decryption schemes that withstand malicious adaptive corruption. Our first scheme is based on the standard ElGamal encryption scheme and is secure against chosen plaintext attack~(CPA). Our second scheme, based on the chosen ciphertext attack~(CCA) secure Shoup-Gennaro encryption scheme, is also CCA secure. Both of our schemes have non-interactive decryption protocols and comparable efficiency to their static secure counterparts. Building on the technique introduced by Das and Ren (CRYPTO 2024), our threshold ElGamal decryption scheme relies on the hardness of Decisional Diffie-Hellman and the random oracle model.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 19:33:59 +0000</pubDate>
</item>
<item>
<title>Stateless 2PC Signatures for Internet-Scale Authentication and Authorization</title>
<link>https://eprint.iacr.org/2025/1475</link>
<guid>https://eprint.iacr.org/2025/1475</guid>
<content:encoded><![CDATA[
The industry is moving away from passwords for authentication and authorization, with hardware devices for storing long-term cryptographic keys emerging as the leading alternative. However, these devices often have limited displays and remain vulnerable to theft, malware, or tricking users into signing malicious payloads. Current systems provide little fallback security in such cases. Any solution must also meet strict requirements: compatibility with industry standards, scalability to handle high request volumes, and high availability.

We present a novel design for authentication and authorization that meets these demands. Our approach virtualizes the authenticating/authorizing party via a two-party signing protocol with a helper entity, ensuring that keys remain secure even if a device is compromised and that every signed message conforms to a security policy.

We formalize the required properties for such protocols and show how they are met by existing schemes (e.g., FROST for Schnorr, Boneh–Haitner–Lindell-Segev'25 for ECDSA). Motivated by the widespread use of ECDSA (FIDO2/Passkeys, blockchains), we introduce a new, optimized two-party ECDSA protocol that is significantly more efficient than prior work. At its core is a new variant of exponent-VRF, improving on earlier constructions and of independent interest. We validate our design with a proof-of-concept virtual authenticator for the FIDO2 Passkeys framework.
]]></content:encoded>
<pubDate>Thu, 14 Aug 2025 12:05:09 +0000</pubDate>
</item>
<item>
<title>Efficient Fuzzy Labeled PSI from Vector Ring-OLE</title>
<link>https://eprint.iacr.org/2025/1470</link>
<guid>https://eprint.iacr.org/2025/1470</guid>
<content:encoded><![CDATA[
Fuzzy-labeled private set intersection (PSI) outputs the corresponding label if there is a ``fuzzy'' match between two items, for example, when the Hamming distance is low between the two items. Such protocols can be applied in privacy-preserving biometric authentication, proximity testing, and so on. The only fuzzy-labeled PSI protocol designed for practical purposes is by Uzun et al. (USENIX’21), which is based on homomorphic encryption. This design puts constraints on the item size, label size, and communication cost since it is difficult for homomorphic encryption to support large plaintext space and it is well-known that the ciphertext-expansion factor is large.

Our construction begins with a new primitive which we call vector ring-oblivious linear evaluation (vector ring-OLE). This primitive does not rely on existing instantiations of ring-OLE over the quotient ring, but leverages the more efficient vector-OLE. It is ideal for building unbalanced threshold-labeled PSI and is also of independent interest.

Our main contribution, fuzzy-labeled PSI, is bootstrapped from our threshold-labeled PSI protocol. Through a prototype implementation, we demonstrate our communication cost is up to $4.6\times$ better than the prior state-of-the-art with comparable end-to-end latency while supporting a significantly higher label size.
]]></content:encoded>
<pubDate>Wed, 13 Aug 2025 09:13:26 +0000</pubDate>
</item>
<item>
<title>A Performance Comparison of the Homomorphic Encryption Schemes CKKS and TFHE</title>
<link>https://eprint.iacr.org/2025/1460</link>
<guid>https://eprint.iacr.org/2025/1460</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) is a promising technique for privacy-preserving data analysis. Several HE schemes have been developed, with the CKKS and TFHE schemes being two of the most advanced. However, due to their differences, it is hard to compare their performance and suitability for a given application. We therefore conducted an empirical study of the performance of the two schemes in a comparable scenario. We benchmarked the commonly used operations addition, multiplication, division, square root, evaluation of a polynomial and a comparison function, each on a common pair of datasets with 65536 32-bit integers. Since the CKKS scheme is an approximate scheme, we set a requirement of at least 32 bits of precision to match that of the input data. Our results show that CKKS outperforms TFHE in most operations. TFHE’s only advantage is its fast bootstrapping. Even though TFHE performs bootstrapping after every operation, while CKKS typically performs bootstrapping only after a certain number of multiplications, CKKS’s bootstrapping still presents a bottleneck. This can be seen specifically with the comparison operation, where TFHE is much faster than CKKS in many settings, as it requires several bootstrapping operations in CKKS due to its multiplicative depth. Generally speaking, CKKS should be preferred in applications which can be parallelized. CKKS’s advantages decreases in applications with a large depth that require many bootstrapping operations.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 09:07:49 +0000</pubDate>
</item>
<item>
<title>Not in The Prophecies: Practical Attacks on Nostr</title>
<link>https://eprint.iacr.org/2025/1459</link>
<guid>https://eprint.iacr.org/2025/1459</guid>
<content:encoded><![CDATA[
Distributed social networking services (SNSs) recently received significant attention as an alternative to traditional, centralized SNSs, which have inherent limitations on user privacy and freedom. 
We provide the first in-depth security analysis of Nostr, an open-source, distributed SNS protocol developed in 2019 with more than 1.1 million registered users. 
We investigate the specification of Nostr and the client implementations and present a number of practical attacks allowing forgeries on various objects, such as encrypted direct messages (DMs), by a malicious user or a malicious server. Even more, we show a confidentiality attack against encrypted DMs by a malicious user exploiting a flaw in the link preview mechanism and the CBC malleability. 
Our attacks are due to cryptographic flaws in the protocol specification and client implementation, some of which in combination elevate the forgery attack to a violation of confidentiality.
We verify the practicality of our attacks via Proof-of-Concept implementations and discuss how to mitigate them.
]]></content:encoded>
<pubDate>Tue, 12 Aug 2025 08:16:07 +0000</pubDate>
</item>
<item>
<title>Scalable Off-Chain Auctions</title>
<link>https://eprint.iacr.org/2023/1454</link>
<guid>https://eprint.iacr.org/2023/1454</guid>
<content:encoded><![CDATA[
Blockchain auction plays an important role in the price discovery of digital assets (e.g. NFTs). However, despite their importance, implementing auctions directly on blockchains such as Ethereum incurs scalability issues. In particular, the on-chain transactions  scale poorly with the number of bidders, leading to network congestion, increased transaction fees, and slower transaction confirmation time. This lack of scalability significantly hampers the ability of the system to handle large-scale, high-speed auctions that are common in today's economy. 
    
In this work, we build a protocol where an auctioneer can  conduct sealed bid auctions that run entirely off-chain when parties behave honestly, and in the event that $k$ bidders deviate (e.g., do not open their sealed bid) from an $n$-party auction protocol, then the on-chain complexity is only $O(k)$. This improves over existing solutions that require $O(n)$ on-chain complexity, even if a single bidder deviates from the protocol. In the event of a malicious auctioneer, our protocol still guarantees that the auction will successfully terminate. We implement our protocol and show that it offers significant efficiency improvements compared to existing on-chain solutions. Our use of zkSnark to achieve scalability also ensures that the on-chain contract and other participants do not acquire any information about the bidders' identities and their respective bids, except for the winner and the winning bid amount.
]]></content:encoded>
<pubDate>Fri, 22 Sep 2023 17:31:00 +0000</pubDate>
</item>
<item>
<title>A New Paradigm for Privacy-Preserving Decision Tree Evaluation</title>
<link>https://eprint.iacr.org/2025/1447</link>
<guid>https://eprint.iacr.org/2025/1447</guid>
<content:encoded><![CDATA[
Privacy-preserving decision tree inference is a fundamental primitive in privacy-critical applications such as healthcare and finance, yet existing protocols still pay a heavy price for oblivious selection at every node. We introduce a new paradigm that eliminates this limitation by representing the entire tree as a permutation rather than an explicit set of nodes. 
Under this representation, we can efficiently generate a shuffled randomized decision tree during the offline phase, where the indices can be directly revealed without leaking any information about the original tree structure. Our scheme significantly reduces both the online and offline computation and communication overhead compared to SOTA.
Comprehensive benchmarks show an 86 % reduction in online communication versus the state-of-the-art FSS protocol by Ji et al., and a 99.9 % reduction versus the OT-based protocol of Ma et al. Overall, our benchmark shows that our protocol achieves a performance improvement of $20\times$ over Ma et al.’s scheme and $4.5\times$ over Ji et al.’s scheme.
]]></content:encoded>
<pubDate>Sat, 09 Aug 2025 01:50:10 +0000</pubDate>
</item>
<item>
<title>Forgery Attack on a Secure Data Sharing for Industrial IoT</title>
<link>https://eprint.iacr.org/2025/1445</link>
<guid>https://eprint.iacr.org/2025/1445</guid>
<content:encoded><![CDATA[
In recent years and with the emergence of the industrial revolution, the secure data sharing schemes have been developed in IoT platforms and have been recognized as a hot topic in industry and academia. These schemes enable IoT devices to securely share their sensed data in industrial environments with clients through an appropriate infrastructure and intermediary entities. The research conducted in this field shows the existence of various security challenges and solutions. Data privacy, data authentication, fairness and accountability are some of the most important security features presented. Recently, in paper [Sengupta-Ruj-Bit, TNSM 2023] proposed a secure sharing scheme and claimed that it covers all the mentioned security features even when entities collude with each other. In this paper, we investigate the security analysis of this scheme, and show that it does not cover the claimed fairness property. Therefore, the mentioned scheme is vulnerable and cannot be used as a valid scheme in real-world applications.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 19:40:13 +0000</pubDate>
</item>
<item>
<title>Consensus Redux: Distributed Ledgers in the Face of Adversarial Supremacy</title>
<link>https://eprint.iacr.org/2020/1021</link>
<guid>https://eprint.iacr.org/2020/1021</guid>
<content:encoded><![CDATA[
Permissionless distributed ledgers, such as those arising from blockchain protocols, have been touted as the centerpiece of an upcoming security-critical information technology infrastructure. Their basic properties---consistency and liveness---can be guaranteed under specific constraints on the resources available to an adversary relative to the resources of the participants that follow the protocol. Given their permissionless participation convention and their intended long-livedness, a critical open security question is their behavior---and potential resilience---to temporary spikes in adversarial resources.

In this work we give the first thorough treatment of the self-healing properties of Nakamoto ledgers, addressing both proof-of-work (PoW) and proof-of-stake (PoS) protocols.  First, we present a unified model that allows us to define self-healing for both of these protocol classes. Then we provide a formal analysis establishing self-healing with respect to both consistency and liveness in both classes, quantifying the resulting vulnerability period as a function of the magnitude of the spike. Finally, we provide numerical simulations giving explicit quantitative bounds relevant for practice.
]]></content:encoded>
<pubDate>Thu, 27 Aug 2020 02:27:00 +0000</pubDate>
</item>
<item>
<title>Shuffling is Universal: Statistical Additive Randomized Encodings for All Functions</title>
<link>https://eprint.iacr.org/2025/1442</link>
<guid>https://eprint.iacr.org/2025/1442</guid>
<content:encoded><![CDATA[
The shuffle model is a widely used abstraction for non-interactive anonymous communication. It allows $n$ parties holding private inputs $x_1,\dots,x_n$ to simultaneously send messages to an evaluator, so that the messages are received in a random order. The evaluator can then compute a joint function $f(x_1,\dots,x_n)$, ideally while learning nothing else about the private inputs. The model has become increasingly popular both in cryptography, as an alternative to non-interactive secure computation in trusted setup models, and even more so in differential privacy, as an intermediate between the high-privacy, little-utility local model and the little-privacy, high-utility central curator model. 

The main open question in this context is which functions $f$ can be computed in the shuffle model with statistical security. While general feasibility results were obtained 
using public-key cryptography, the question of statistical security has remained elusive. The common conjecture has been that even relatively simple functions cannot be computed with statistical security in the shuffle model.

We refute this conjecture, showing that all functions can be computed in the shuffle model with statistical security. In particular, any differentially private mechanism in the central curator model can also be realized in the shuffle model with essentially the same utility, and while the evaluator learns nothing beyond the central model result. 

This feasibility result is obtained by constructing a statistically secure additive randomized encoding (ARE) for any function. An ARE randomly maps individual inputs to group elements whose sum only reveals the function output. 
Similarly to other types of randomized encoding of functions,  our statistical ARE is efficient for functions in $NC^1$ or $NL$. Alternatively, we get computationally secure ARE for all polynomial-time functions using a one-way function. More generally, we can convert any (information-theoretic or computational) ``garbling scheme'' to an ARE with a constant-factor size overhead.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 03:25:23 +0000</pubDate>
</item>
<item>
<title>DIMSEPP: A Decentralized Identity Management System with Enhanced Privacy Protection</title>
<link>https://eprint.iacr.org/2025/1441</link>
<guid>https://eprint.iacr.org/2025/1441</guid>
<content:encoded><![CDATA[
This paper proposes DIMSEPP, a decentralized identity management system that enhances privacy while preserving blockchain verifiability. The system cryptographically enforces data  minimal disclosure principles by storing attribute commitments on-chain and validating them through zero-knowledge proofs, allowing users to demonstrate attribute validity without revealing sensitive values. 
The architecture maintains full compatibility with existing DID standards through standard document structures and verification methods. Security analysis demonstrates provable guarantees under standard cryptographic assumptions. Practical evaluation confirms the system's efficiency for resource-constrained environments, supporting deployment in applications where both privacy and verifiability are essential.
]]></content:encoded>
<pubDate>Fri, 08 Aug 2025 01:28:53 +0000</pubDate>
</item>
<item>
<title>$\mathsf{Cirrus}$: Performant and Accountable Distributed SNARK</title>
<link>https://eprint.iacr.org/2024/1873</link>
<guid>https://eprint.iacr.org/2024/1873</guid>
<content:encoded><![CDATA[
Succinct Non-interactive Arguments of Knowledge (SNARKs) can enable efficient verification of computation in many applications. However, generating SNARK proofs for large-scale tasks, such as verifiable machine learning or virtual machines, remains computationally expensive. A promising approach is to distribute the proof generation workload across multiple workers. A practical distributed SNARK protocol should have three properties: horizontal scalability with low overhead (linear computation and logarithmic communication per worker), accountability (efficient detection of malicious workers), and a universal trusted setup independent of circuits and the number of workers. Existing protocols fail to achieve all these properties.

In this paper, we present $\mathsf{Cirrus}$, the first distributed SNARK generation protocol achieving all three desirable properties at once. Our protocol builds on HyperPlonk (EUROCRYPT'23), inheriting its universal trusted setup. It achieves linear computation complexity for both workers and the coordinator, along with low communication overhead. To achieve accountability, we introduce a highly efficient accountability protocol to localize malicious workers. Additionally, we propose a hierarchical aggregation technique to further reduce the coordinator’s workload.

We implemented and evaluated $\mathsf{Cirrus}$ on machines with modest hardware. Our experiments show that $\mathsf{Cirrus}$ is highly scalable: it generates proofs for circuits with $33$M gates in under $40$ seconds using $32$ $8$-core machines. Compared to the state-of-the-art accountable protocol Hekaton (CCS'24), \protname achieves over $7\times$ faster proof generation for PLONK-friendly circuits such as the Pedersen hash. Our accountability protocol also efficiently identifies faulty workers within just $4$ seconds, making $\mathsf{Cirrus}$ particularly suitable for decentralized and outsourced computation scenarios.
]]></content:encoded>
<pubDate>Sat, 16 Nov 2024 00:27:53 +0000</pubDate>
</item>
<item>
<title>Secure Protocols for Best Arm Identification Using Secret Sharing Schemes</title>
<link>https://eprint.iacr.org/2025/1438</link>
<guid>https://eprint.iacr.org/2025/1438</guid>
<content:encoded><![CDATA[
This paper addresses the challenge of best arm identification in stochastic multi-armed bandit (MAB) models under privacy-preserving constraints, such as in dynamic spectrum access networks where secondary users must privately detect underutilized channels. While previous network security research has explored securing MAB algorithms through techniques such as homomorphic encryption or differential privacy, these methods often suffer from high computational overhead or introduce noise that strictly decreases accuracy. In contrast, this work focuses on lightweight  solutions that ensure data confidentiality without compromising the accuracy of best arm identification. We introduce two secure protocols that leverage additive secret sharing and threshold secret sharing. The proposed model, employing aggregation nodes  and a comparator node, securely distributes computations to prevent any entity from accessing complete reward or ranking data. Furthermore, the protocol ensures resistance to collusion  and fault tolerance, while maintaining computational efficiency. These contributions establish a scalable and robust framework for privacy-preserving best arm identification, offering practical and secure solutions that use MAB methods for network security.
]]></content:encoded>
<pubDate>Thu, 07 Aug 2025 13:39:14 +0000</pubDate>
</item>
<item>
<title>TLShare: Private Authenticated MPC and FHE Inputs Over TLS</title>
<link>https://eprint.iacr.org/2025/1434</link>
<guid>https://eprint.iacr.org/2025/1434</guid>
<content:encoded><![CDATA[
Transport Layer Security (TLS) is the backbone of the web, allowing clients to establish secure and private channels with servers. DECO (CCS'20) and follow-up works proposed protocols that enable proving the provenance of a TLS response, i.e., that a payload came from a particular server, without needing server-side modifications. Unfortunately, these works are limited to proving Boolean statements over the payload (e.g., age $\ge$ 18) and cannot combine payloads from multiple clients.

We introduce TLShare, a framework that extracts authenticated data from a TLS connection and imports it into secure multiparty computation (MPC) or fully homomorphic encryption (FHE), without requiring server-side changes or exposing client credentials. Unlike prior work, TLShare allows the payload itself, not just a predicate about it, to serve as private input to secure downstream computation. TLShare supports combining verifiable inputs across multiple clients and servers, enabling new applications such as privacy-preserving financial risk assessment and collaborative analytics. We design three protocols for TLShare: one for MPC using verifiable secret sharing, and two for FHE using interactive and non-interactive zero-knowledge proofs, each ensuring input authenticity, integrity, and end-to-end privacy. We evaluate all three protocols of TLShare over both LAN and WAN settings, comparing their trade-offs and demonstrating their practicality.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 21:05:21 +0000</pubDate>
</item>
<item>
<title>A Fully-Adaptive Threshold Partially-Oblivious PRF</title>
<link>https://eprint.iacr.org/2025/1433</link>
<guid>https://eprint.iacr.org/2025/1433</guid>
<content:encoded><![CDATA[
Oblivious Pseudorandom Functions (OPRFs) are fundamental cryptographic primitives essential for privacy-enhancing technologies such as private set intersection, oblivious keyword search, and password-based authentication protocols. We present the first fully adaptive, partially oblivious threshold pseudorandom function that supports proactive key refresh and provides composable security under the One-More Gap Diffie-Hellman assumption in the random oracle model.

Our construction is secure with respect to a new ideal functionality for OPRFs that addresses three critical shortcomings of previous models–specifically, key refresh and non-verifiability issues that rendered them unrealizable. In addition, we identify a gap in a prior work's proof of partial obliviousness and develop a novel proof technique to salvage their scheme.
]]></content:encoded>
<pubDate>Wed, 06 Aug 2025 13:01:01 +0000</pubDate>
</item>
<item>
<title>Strategic Mining in Proof-of-Stake with Practical Random Election</title>
<link>https://eprint.iacr.org/2025/1428</link>
<guid>https://eprint.iacr.org/2025/1428</guid>
<content:encoded><![CDATA[
The security of blockchain systems relies on the honest ma-
jority assumption. However, strategic mining threatens this assumption,
because selfish miners can gain more block rewards than honest miners
by attacks such as withholding blocks. Due to its significant implica-
tion, blockchain mining games have been studied in PoW and PoS under
various settings using different methods. Nonetheless, this paper argues
that the practical limitation of random beacons has not been exploited
in strategic mining in PoS blockchains.
Current PoS blockchains use random beacons to randomly select valida-
tors for each slots. However, the randomness is usually fixed for multiple
slots, due to the latency of distributed random beacon protocols. This
indicates that validators actually know some information about the elec-
tion result in the future, which contrasts with the Markov process models
in previous analysis. Using this information, this paper presents a close
to optimal mining strategy based on an optimal interval scheduling algo-
rithm for each epoch. For proof-of-stake protocols with no propagation
delay, we show that a validator with arbitrary proportion of stake can
strictly benefit from strategic mining and get significantly higher block
rewards than the previous strategies.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 23:01:54 +0000</pubDate>
</item>
<item>
<title>Lodia: Towards Optimal Sparse Matrix-Vector Multiplication for Batched Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1425</link>
<guid>https://eprint.iacr.org/2025/1425</guid>
<content:encoded><![CDATA[
Encrypted matrix-vector multiplication is a fundamental component of a variety of applications that involve data privacy concerns. Current algorithms utilizing fully homomorphic encryption (FHE) generally use batching to enhance computational efficiency while neglecting the sparsity of the matrices, a characteristic that exists naturally in many practical situations. Alternatively, porting plaintext algorithms that address sparsity may fail to utilize batching and introduce additional privacy concerns.

We propose Lodia, an efficient outsourced SpMV algorithm for batched FHE schemes without sacrificing privacy. It only requires $\Theta((n+m)\log(n+m)/s)$ FHE operations, where $n$ is the number of rows/columns, $m$ is the number of non-zero elements of the matrix, and $s$ is the batch size of the FHE scheme. This is optimal for $m=\Omega(n)$ and $m=O(n^\rho)$ for some $\rho<2$ (i.e., $an \le m \le bn^\rho$ asymptotically), covering most practical cases. To our knowledge, no method has been published with better than $\Theta(n^2/s)$ FHE operations, suitable for any sparse matrix, and without privacy concerns.

Lodia utilizes a novel low-diagonal decomposition, which decomposes a sparse matrix into a series of special matrices named low-diagonal matrices. Based on a conventional method encoding the matrix in diagonal order, each low-diagonal matrix can be efficiently multiplied by a vector. This results in an efficient SpMV method suitable for any sparse matrix. Experiments show that Lodia practically achieves a speedup of up to $96\times$ compared to baselines that ignore matrix sparsity, and up to $3.6\times$ compared to implementations even with fewer security guarantees. This is the first SpMV solution on encrypted data that can process a substantial matrix with over 8 million rows/columns and 125 million non-zero elements.
]]></content:encoded>
<pubDate>Tue, 05 Aug 2025 07:56:35 +0000</pubDate>
</item>
<item>
<title>Efficient randomized strong $2$-source non-malleable extractor for any linear min-entropy</title>
<link>https://eprint.iacr.org/2025/1421</link>
<guid>https://eprint.iacr.org/2025/1421</guid>
<content:encoded><![CDATA[
Randomness is a fundamental requirement in cryptographic systems, enabling secure encryption, commitments, and zero-knowledge proofs. However, real-world randomness sources often suffer from weaknesses that adversaries can exploit, leading to significant security vulnerabilities. While deterministic randomness extraction from a single min-entropy source is impossible, two-source extractors provide a robust solution by generating nearly uniform randomness from two independent weak sources. Moreover, cryptographic systems must also be resilient to leakage and tampering attacks, necessitating the development of non-malleable two-source extractors.

In this work, we construct a two-source non-malleable extractor in the Common Reference String (CRS) model, where a random low-degree polynomial is sampled once and made accessible to independent random sources, the distinguisher, and the tamperer. Our extractor requires only linear min-entropy in both sources and doesn't rely on strong computational assumptions, in contrast to prior constructions requiring computational assumptions such as sub-exponential hardness of the Decisional Diffie-Hellman (DDH) problem. Notably, our construction builds upon and relies on the recent breakthrough proof of the polynomial Freiman-Ruzsa conjecture. A connection of the Freiman-Ruzsa conjecture with two-source extractors was considered in prior work [ZBS11],[AGMR24], but their construction did not achieve non-malleability. 

Our results advance the state of non-malleable cryptographic primitives, with applications in secure storage, leakage-resilient cryptography, and privacy amplification. By eliminating the need for strong computational hardness assumptions, our techniques provide a more foundational and widely applicable method for randomness extraction.

We also show, that the requirements on CRS for our application are so mild that the CRS can be sampled with $2$ party computation even when one of the parties is malicious (setting in which establishing unbiased coins is impossible).
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 22:58:10 +0000</pubDate>
</item>
<item>
<title>Coral: Fast Succinct Non-Interactive Zero-Knowledge CFG Proofs</title>
<link>https://eprint.iacr.org/2025/1420</link>
<guid>https://eprint.iacr.org/2025/1420</guid>
<content:encoded><![CDATA[
We introduce Coral, a system for proving in zero-
knowledge that a committed byte stream corresponds to a
structured object in accordance to a Context Free Grammar.
Once a prover establishes the validity of the parsed object with
Coral, they can selectively prove facts about the object—such as
fields in Web API responses or in JSON Web Tokens—–to third
parties or blockchains. Coral reduces the problem of correct
parsing to a few simple checks over a left-child right-sibling
tree and introduces a novel segmented memory abstraction that
unifies and extends prior constructions for RAM in zkSNARKs.
Our implementation of Coral runs on a standard laptop, and
non-interactively proves the parsing of real Web responses
(JSON) and files (TOML and C) in seconds. The resulting
proofs are small and cheap to verify.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 22:13:34 +0000</pubDate>
</item>
<item>
<title>BEAST-MEV: Batched Threshold Encryption with Silent Setup for MEV prevention</title>
<link>https://eprint.iacr.org/2025/1419</link>
<guid>https://eprint.iacr.org/2025/1419</guid>
<content:encoded><![CDATA[
Threshold encrypted mempools protect the privacy of transactions up until the point their inclusion on chain is confirmed. They are a promising approach to protection against front-running attacks on decentralized blockchains.

Recent works have introduced two key properties that an encryption scheme must satisfy in order to scale to large scale decentralized blockchains such as Ethereum:
Silent Setup [Garg-Kolonelos-Policharla-Wang, CRYPTO'24], demands that a threshold encryption scheme does not require any interaction during the setup phase and only relies on the existence of Public Key Infrastructure. Batched Decryption [Choudhuri-Garg-Piet-Policharla, USENIX'24], demands that an entire block containing $B$ encrypted transactions can be decrypted using communication that is independent of (or sublinear in) $B$, without compromising the privacy of transactions that have not yet been confirmed.

While existing constructions achieve either Silent Setup or Batched Decryption independently, a truly decentralized and scalable encrypted mempool requires both properties to be satisfied simultaneously. In this work, we present the first ``Batched Threshold Encryption scheme with Silent Setup'' built using bilinear pairings. We provide formal definitions for the primitive, and prove security in the Generic Group Model. We provide several optimizations and implement our scheme to evaluate its performance. Our experiments demonstrate its efficiency for deployment in blockchain systems.
]]></content:encoded>
<pubDate>Mon, 04 Aug 2025 19:11:58 +0000</pubDate>
</item>
<item>
<title>Data Availability Sampling with Repair</title>
<link>https://eprint.iacr.org/2025/1414</link>
<guid>https://eprint.iacr.org/2025/1414</guid>
<content:encoded><![CDATA[
Data availability sampling (DAS) is an important technique to horizontally scale consensus protocols without compromising on the number of adversarial nodes that can be tolerated. DAS is on the technical roadmap of major blockchains such as Ethereum. A major challenge for DAS schemes, that has not been formally studied in the literature, is how incomplete shares can be repaired. The need for repairing data shares motivates key aspects of Ethereum's DAS-based sharding vision called "Danksharding".
In this work, we make two contributions. First, we provide a new definitional framework that formalizes the notion of repair, along with the security guarantees that a DAS scheme must provide. Second, we propose a new DAS scheme designed with efficient repair in mind, based on locally-correctable multiplicity codes. To facilitate using these codes, we introduce a new multivariate polynomial commitment scheme that (i) supports efficient openings of partial derivatives of a committed polynomial, (ii) supports fast batch opening proof generation at many points, and (iii) has an algorithm to recompute (repair) opening proofs at a point from only a few other proofs. The proposed scheme improves upon the state-of-the-art Ethereum Fulu DAS scheme, slated for deployment in late 2025/early 2026, in storage overhead, repair bandwidth and coordination, while only slightly increasing dispersal cost and sampling bandwidth. Our techniques readily carry over to data availability schemes based on verifiable information dispersal (VID).
]]></content:encoded>
<pubDate>Sun, 03 Aug 2025 21:05:42 +0000</pubDate>
</item>
<item>
<title>When Can We Incrementally Prove Computations of Arbitrary Depth?</title>
<link>https://eprint.iacr.org/2025/1413</link>
<guid>https://eprint.iacr.org/2025/1413</guid>
<content:encoded><![CDATA[
Incrementally Verifiable Computation (IVC) allows one to prove the correctness of a computation of potentially unbounded length in an incremental way, while a computationally weak client can efficiently check its correctness in time sublinear in the computation's length. IVC is particularly useful in several real-world applications such as scalable blockchains, distributed computation, and verifiable machine learning. Yet, most existing IVC schemes are only provably secure for constant-depth computations. Arguing their security for computations of polynomial depth relies on heuristic assumptions, raising both theoretical and practical concerns.
In this work, we delve into the security foundations of incremental proof systems, addressing two main questions. First, we revisit the security analysis, in the unbounded-depth regime, of the canonical construction of IVC based on the recursive composition of SNARKs. We extend this analysis to include SNARKs that are straightline extractable in the algebraic group model (AGM) and some additional oracle model. As a consequence of our result, we obtain novel instantiations of IVC for unbounded-depth computations based on AGM-based SNARKs, such as Groth16 or Marlin, to name a few—an important class of SNARKs not captured by similar analyses in prior work [Chiesa et al. TCC 2024].
Second, we consider incremental proof systems for arbitrary depth computations in which full-blown extractability is not necessary. We study under what conditions they can be instantiated from the recursive composition of "plain" building blocks (SNARKs, folding, accumulation schemes), that is without requiring special straightline extractability. We introduce incremental functional commitments (incremental FC), a primitive that allows one to commit to a large data $D$ and later prove a function $f(D)$. The key aspect is that both the committing and proving functionalities operate incrementally, processing $D$ in a streaming, piece-by-piece manner. Also, like in standard FCs, their security property is a form of evaluation binding, a notion that is weaker than knowledge-soundness (it states that it is hard to produce two valid proofs for the same commitment and two distinct outputs). Our second main result consists of a construction of incremental FCs based on recursive composition of SNARKs and its security analysis, which shows that arbitrarily deep compositions of primitives with non-straightline extractors do not suffer from inherent security limitations.
]]></content:encoded>
<pubDate>Sun, 03 Aug 2025 11:55:44 +0000</pubDate>
</item>
<item>
<title>SyRA: Sybil-Resilient Anonymous Signatures with Applications to Decentralized Identity</title>
<link>https://eprint.iacr.org/2024/379</link>
<guid>https://eprint.iacr.org/2024/379</guid>
<content:encoded><![CDATA[
We study Sybil-Resilient Anonymous (SyRA) signatures, a cryptographic primitive that enables credentialed users to generate, on demand, unlinkable pseudonyms tied to any given context, and issue signatures on behalf of these pseudonyms. Concretely, SyRA allows a distributed issuer to turn any legacy identity or personhood identifier, possibly of low entropy, into a unique associated cryptographic key of high pseudoentropy, for use in generating signatures for any given context. Sybil-resilient anonymous signatures achieve three main objectives: 1) Sybil resilience: every user is entitled to at most one digital identity, 2) anonymity: no information about the user’s real identity is leaked, and 3) non-interactive context switching: users can create on their own at most one credential for any given context in a manner that is unlinkable across contexts. 
We conceptualize the SyRA primitive as an ideal functionality in the Universal Composition (UC) setting and put forth SASSI, an efficient, pairing-based construction that realizes it by utilizing two levels of verifiable random functions (VRFs), a design which may be of independent interest. The first level consists of threshold VRF issuance of a user’s unique secret key tied to their real-world identifier. The second level allows a user to create signatures for each context, under a unique pseudonym per context. Compared to prior cryptographic tools capable of realizing SyRA, SASSI has the unique feature that issuers are stateless and hence do not need to retain any information about past user interactions, a relevant property for a decentralized implementation. 
We overview various applications of SASSI in multiparty systems, such as cryptocurrency account management and airdrops, e-voting (e.g., for decentralized governance), and privacy-preserving regulatory compliance (e.g., AML/CFT checks). In the context of creating addresses for digital assets, SyRA signatures enable users to embed their legacy identity into their address in a manner that protects their privacy for each application with which they interact. We demonstrate the practicality of SASSI by providing an implementation and performance evaluation of our construction.
]]></content:encoded>
<pubDate>Thu, 29 Feb 2024 21:07:20 +0000</pubDate>
</item>
<item>
<title>RGB I.0: Scalable consensus for client-side validated smart contracts</title>
<link>https://eprint.iacr.org/2025/1400</link>
<guid>https://eprint.iacr.org/2025/1400</guid>
<content:encoded><![CDATA[
The paper defines a novel type of consensus for a distributed smart contract system, named RGB, which is based on the concept of client-side validation, separating the contract state and operations from the blockchain. With this approach, contracts are sharded (each contract is a standalone shard), kept, and validated only by contract participants, providing native scalability and privacy mechanisms, exceeding all existing blockchain-based smart contract systems while not compromising on security or decentralization. The system is designed to operate on top of compatible layers 1, such as an UTXO-based blockchain (e.g., Bitcoin) without relying on it for transaction ordering or state replication. Instead, RGB keeps the state client-side, operating as partially replicated state machines (PRiSM). It employs a novel SONIC (State machine with Ownership Notation Involving Capabilities) architecture, which provides capability-based access control to the contract state, individually owned and operated by a well-defined contract parties via novel single-use seal mechanism. RGB does state validation using zk-AluVM virtual machine, designed to support zk-STARK provers. It has a single security assumption of the collision-resistance hash function and, thus, is quantum-secure. The proposed RGB consensus is distinct from traditional blockchain-based smart contract systems; it is scalable, provably-secure, and formally verifiable.
]]></content:encoded>
<pubDate>Fri, 01 Aug 2025 14:19:11 +0000</pubDate>
</item>
<item>
<title>AVPEU: Anonymous Verifiable Presentations with Extended Usability</title>
<link>https://eprint.iacr.org/2025/1412</link>
<guid>https://eprint.iacr.org/2025/1412</guid>
<content:encoded><![CDATA[
The World Wide Web Consortium (W3C) has established standards for decentralized identities (DIDs) and verifiable credentials (VCs). A DID serves as a unique identifier for an entity, while a VC validates specific attributes associated with the DID holder. To prove ownership of credentials, users generate verifiable presentations (VPs). To enhance privacy, the W3C standards advocate for randomizable signatures in VC creation and zero-knowledge proofs for VP generation. However, these standards face a significant limitation: they cannot effectively verify cross-domain credentials while maintaining anonymity. In this paper, we present Anonymous Verifiable Presentations with Extended Usability (AVPEU), a novel framework that addresses this limitation through the introduction of a notary system. At the technical core of AVPEU lies our proposed randomizable message-hiding signature scheme. We provide both a generic construction of AVPEU and specific implementations based on Boneh-Boyen-Shacham (BBS), Camenisch-Lysyanskaya (CL), and Pointcheval-Sanders (PS) signature. Our experimental results demonstrate the feasibility of these schemes.
]]></content:encoded>
<pubDate>Sat, 02 Aug 2025 20:35:54 +0000</pubDate>
</item>
<item>
<title>Nakamoto Consensus from Multiple Resources</title>
<link>https://eprint.iacr.org/2025/1410</link>
<guid>https://eprint.iacr.org/2025/1410</guid>
<content:encoded><![CDATA[
The blocks in the Bitcoin blockchain record the amount of work W that went into creating them through proofs of work. When honest parties control a majority of the work, consensus is achieved by picking the chain with the highest recorded weight. Resources other than work have been considered to secure such longest-chain blockchains. In Chia, blocks record the amount of disk-space  S (via a proof of space) and sequential computational steps V (through a VDF).

In this paper, we ask what weight functions Γ(S,V,W) (that assign a weight to a block as a function of the recorded space, speed, and work) are secure in the sense that whenever the weight of the resources controlled by honest parties is larger than the weight of adversarial parties, the blockchain is secure against private double-spending attacks.

We completely classify such functions in an idealized “continuous” model: Γ(S,V,W) is secure against private double-spending attacks if and only if it is homogeneous of degree one in the timed resources V and W, i.e., αΓ(S,V,W)=Γ(S,α  V, α W). This includes the Bitcoin rule Γ(S,V,W)=W and the Chia rule Γ(S,V,W) = S · V. In a more realistic model where blocks are created at discrete time-points, one additionally needs some mild assumptions on the dependency on S (basically, the weight should not grow too much if S is slightly increased, say linear as in Chia).

Our classification is more general and allows various instantiations of the same resource. It provides a powerful tool for designing new longest-chain blockchains. E.g., consider combining different PoWs to counter centralization, say the Bitcoin PoW W_1 and a memory-hard PoW W_2. Previous work suggested to use W_1+W_2 as weight. Our results show that using e.g., √(W_1)·√(W_2)  or min{W_1,W_2} are also secure, and we argue that in practice these are much better choices.
]]></content:encoded>
<pubDate>Sat, 02 Aug 2025 17:09:45 +0000</pubDate>
</item>
<item>
<title>Oblivious (Un)Learning of Extremely Randomized Trees</title>
<link>https://eprint.iacr.org/2025/1409</link>
<guid>https://eprint.iacr.org/2025/1409</guid>
<content:encoded><![CDATA[
While the use of homomorphic encryption (HE) for encrypted inference has received considerable attention, its application for the training of machine learning (ML) models remains comparatively underexplored, primarily due to the high computational overhead traditionally associated with fully homomorphic encryption (FHE).
In this work, we address this challenge by leveraging the inherent connection between inference and training in the context of Extremely Randomized Trees (ERT), thereby enabling efficient training directly over encrypted data. 
More precisely, we instantiate this approach by the training of ERT within the TFHE framework.
Our implementation demonstrates that it is possible to train ERTs on encrypted datasets with a runtime significantly lower than current state-of-the-art methods for training Random Forests in the encrypted domain while achieving comparable predictive accuracy.
This result highlights a promising direction for practical privacy-preserving machine learning using FHE. 
Our second main contribution consists in leveraging the properties of ERTs to create the first ML model that enables private unlearning. This approach makes the unlearning process indistinguishable from training, thus allowing clients to conceal the true nature of the operations being conducted on the model.
]]></content:encoded>
<pubDate>Sat, 02 Aug 2025 17:05:46 +0000</pubDate>
</item>
<item>
<title>Two-Tier Black-box Blockchains and Application to Instant Layer-1 Payments</title>
<link>https://eprint.iacr.org/2025/1405</link>
<guid>https://eprint.iacr.org/2025/1405</guid>
<content:encoded><![CDATA[
Common blockchain protocols are monolithic, i.e., their security relies on a single assumption, e.g., honest majority of hashing power (Bitcoin) or stake (Cardano, Algorand, Ethereum). In contrast, so-called optimistic approaches (Thunderella, Meshcash) rely on a combination of assumptions to achieve faster transaction liveness.

We revisit, redesign, and augment the optimistic paradigm to a tiered approach. Our design assumes a primary (Tier 1) and a secondary (Tier 2, also referred to as fallback) blockchain, and achieves full security also in a tiered fashion: If the assumption underpinning the primary chain holds, then we guarantee safety, liveness and censorship resistance, irrespectively of the status of the fallback chain. And even if the primary assumption fails, all security properties are still satisfied (albeit with
a temporary slow down) provided the fallback assumption holds. To our knowledge, no existing optimistic or tiered approach preserves both safety and liveness when any one of its underlying blockchain (assumptions) fails. The above is achieved by a new detection-and-recovery mechanism that links the two blockchains, so that any violation of safety, liveness, or censorship resistance on the (faster) primary blockchain is temporary—it is swiftly detected and recovered on the secondary chain—and thus cannot result in a persistent fork or halt of the blockchain ledger.


We instantiate the above paradigm using a primary chain based on proof of reputation (PoR) and a fallback chain based on proof of stake (PoS). Our construction uses the PoR and PoS blockchains in a mostly black-box manner—where rather than assuming a concrete construction we distill abstract properties on the two blockchains that are sufficient for applying our tiered methodology. In fact, choosing reputation as the resource of the primary chain opens the door to an incentive mechanism—which we devise and analyze—that tokenizes reputation in order to deter cheating and boost participation (on both the primary/PoR and the fallback/PoS blockchain). As we demonstrate, such tokenization in combination with interpreting reputation as a built-in system-wide credit score, allows for embedding in our two-tiered methodology a novel mechanism which provides collateral-free, multi-use payment-channel-like functionality where payments can be instantly confirmed.
]]></content:encoded>
<pubDate>Sat, 02 Aug 2025 06:07:30 +0000</pubDate>
</item>
<item>
<title>Optimizing Backend Verification in zk-Rollup Architectures</title>
<link>https://eprint.iacr.org/2025/1390</link>
<guid>https://eprint.iacr.org/2025/1390</guid>
<content:encoded><![CDATA[
Zero-knowledge rollups represent a critical scaling solution for Ethereum, yet their practical deployment faces significant challenges in on-chain verification costs. This paper presents a comprehensive implementation of the Tokamak zkEVM verifier, specifically optimized for the BLS12-381 elliptic curve operations introduced by EIP-2537. We detail the complete verification architecture, from EVM compatible data formatting for pairing checks, multi-scalar multiplication (MSM), and elliptic curve
addition, to the non-interactive protocol design between prover and verifier.
Our key contribution lies in novel optimization techniques that substantially reduce on-chain verification costs. Through strategic polynomial aggregation and scalar factorization, we minimize G1 exponentiations from 40 to 31, achieving gas savings of 108,000 units per verification. Additionally, we introduce a dynamic barycentric interpolation method that replaces computationally intensive FFT operations,
resulting in 92-95% gas reduction for sparse polynomial evaluations. We further present proof aggregation strategies that minimize precompile calls while maintaining the 128-bit security guarantees of BLS12-381.
Our implementation demonstrates that careful protocol design and mathematical optimizations can make zk-rollup verification economically viable on Ethereum. The techniques presented are compatible with the upcoming Pectra upgrade and provide a blueprint for efficient on-chain verification of complex zero-knowledge proofs. Experimental results show total gas costs reduced from 857,200 to 748,450 units for complete proof verification, making our approach practical for high-throughput rollup deployments.
]]></content:encoded>
<pubDate>Thu, 31 Jul 2025 08:44:05 +0000</pubDate>
</item>
<item>
<title>Collaborative zkSNARKs with Sublinear Prover Time and Constant Proof Size</title>
<link>https://eprint.iacr.org/2025/1388</link>
<guid>https://eprint.iacr.org/2025/1388</guid>
<content:encoded><![CDATA[
Collaborative zkSNARKs, proposed by Ozdemir and Boneh in 2022, allow a prover to delegate the generation of zkSNARK proofs to multiple servers, without compromising the confidentiality of the secret witness. They enable the use of zkSNARK techniques on computational limited devices in critical applications such as blockchains. However, the running time of each server is at least as slow as computing the proof on a single server. Garg et al. attempted to improve the efficiency in their scheme named zkSaaS using packed secret sharing, but the scheme still requires a powerful central server with linear computation, communication and memory usage. 

    In this paper, we propose a new collaborative zkSNARK scheme with $O(\frac{C}{n}\log\frac{C}{n})$ prover time and $O(1)$ proof size with $n$ servers for a circuit of size $C$. An adversary compromising less than $\frac{n}{4}$ servers cannot learn any information about the witness. The core of our technique lies in a new zkSNARK scheme for the Plonkish constraint system that is friendly to packed secret sharing. We utilize bivariate polynomials to avoid a large Fast Fourier Transform on the entire witness, which was the major bottleneck in prior work. We also construct permutation constraints based on logarithmic derivatives and univariate sumcheck to avoid the computation of prefix products. Finally, we build a bivariate polynomial commitment scheme that can be computed directly on packed secret shares. 
    Experimental results show that for a circuit of size $2^{20}$, with 128 servers, our scheme can accelerate the proof generation by 36.2$\times$ compared to running the zkSNARK on a single server. The prover time of our system is 25.9$\times$ faster than the prior work of zkSaaS. The proof size of our scheme is only 960 Bytes.
]]></content:encoded>
<pubDate>Wed, 30 Jul 2025 21:55:49 +0000</pubDate>
</item>
<item>
<title>Multi-party Setup Ceremony for Generating Tokamak zk-SNARK Parameters</title>
<link>https://eprint.iacr.org/2024/1671</link>
<guid>https://eprint.iacr.org/2024/1671</guid>
<content:encoded><![CDATA[
The development of succinct non-interactive arguments of knowledge (SNARKs), which maintain a constant proof size regardless of computation complexity, has led to substantial improvements in both the scalability and privacy of verifiable computations. By enabling efficient verification of complex computations without revealing sensitive data, SNARKs have emerged as a fundamental building block for privacy-preserving and resource-efficient cryptographic protocols.
This document provides a specification guide for the Multi-Party Computation (MPC) setup ceremony for the Tokamak zk-SNARK scheme. Building upon the MMORPG protocol proposed in BGM17 for Groth16 setup generation, a new protocol has been developed. Although the Tokamak zk-SNARK setup parameters share some similarities with Groth16, they also have unique characteristics and certain parameter differences that necessitate distinct generation procedures. By analyzing the MMORPG scheme, an improved and generalized MPC protocol is proposed to support the Tokamak zk-SNARK setup ceremony. In this work, we present the design details of our efficient scheme proposed for the MPC setup ceremony.
The Tokamak zk-SNARK employs a universal setup based on a subcircuit library, enabling reuse of the common reference string (CRS) across multiple circuit instantiations. This design not only minimizes the need for repeated trustless setups but also enhances verifier preprocessing efficiency by reducing the dimensionality of circuit-specific data. The document further provides comprehensive pseudocode specifications for various parameter generation procedures in the MPC setup phase. In addition, this work presents a detailed construction of the Tokamak zk-SNARK setup ceremony under the assumption that at least one honest participant is present. The ceremony is structured into two distinct phases. In the first phase, parameters independent of the subcircuit configuration are generated. Following this preparation, the second phase proceeds according to the universal circuit paradigm, where circuit-specific parameters are generated. For this phase, detailed descriptions are provided for each participant’s computation and corresponding verification procedures. While the protocol fundamentally assumes the existence of at least one honest participant, the use of a random beacon—as introduced in the MMORPG protocol—remains optional and is supported within the design. The document also includes design specifications for the integration of random beacon
functionality when desired.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 09:30:11 +0000</pubDate>
</item>
<item>
<title>Blockchain-Based Decentralized Domain Name System</title>
<link>https://eprint.iacr.org/2025/1381</link>
<guid>https://eprint.iacr.org/2025/1381</guid>
<content:encoded><![CDATA[
The current Domain Name System (DNS) infrastructure faces critical vulnerabilities including poisoning attacks, censorship mechanisms, and centralized points of failure that compromise internet freedom and security. Recent incidents such as DNS poisoning attacks on ISP customers highlight the urgent need for resilient alternatives. This paper presents a novel blockchain-based Decentralized Domain Name System (DDNS). We designed a specialized Proof-of-Work blockchain to maximize support for DNS-related protocols and achieve node decentralization. The system integrates our blockchain with IPFS for distributed storage, implements cryptographic primitives for end-to-end trust signatures, and achieves Never Trust, Always Verify zero-trust verification. Our implementation achieves 15-second domain record propagation times, supports 20 standard DNS record types, and provides perpetual free .ddns domains. The system has been deployed across distributed infrastructure in San Jose, Los Angeles, and Orange County, demonstrating practical scalability and resistance to traditional DNS manipulation techniques. Performance evaluation shows the system can handle up to Max Theor. TPS 1,111.1 tx/s (minimal transactions) and Max Theor. TPS 266.7 tx/s (regular transactions) for domain operations while maintaining sub-second query resolution through intelligent caching mechanisms.
]]></content:encoded>
<pubDate>Tue, 29 Jul 2025 12:55:21 +0000</pubDate>
</item>
<item>
<title>Securing Credential Sequence Verification</title>
<link>https://eprint.iacr.org/2025/1371</link>
<guid>https://eprint.iacr.org/2025/1371</guid>
<content:encoded><![CDATA[
Credentials are used to verify a user’s identity and attributes
and form the basis of securing user access to the system resources. Users
obtain credentials and store them on their (mobile) devices, and present
them when needed. Anonymous credentials protect the user’s identity,
and ensure unlinkability of multiple showing of the credential. In this
paper, we consider a setting where a user is issued multiple credentials
in sequence (e.g., for completing courses), and credential subsequences
must be presented in order of issuance. We focus on the anonymous credential
system where information such as the time of issuing is hidden
for anonymity, or settings where there is no global clock and issuing
time information is not recorded. We propose a novel order-preserving
Proof-of-Credential-Subsequence (PoCS) system called KROM that allows
a user that is potentially untrusted, to present a subsequence of
their locally stored credentials to a verifier, while the relative chronological
order of issuance is preserved. We formalize the security and privacy
of KROM and present two constructions: a basic one that is based on
Merkle trees and one with batched verification that significantly improves
the efficiency of the system. We use KROM to construct an anonymous
order-preserving proof-of-location-subsequence system and prove its security.
The system enables users to selectively present a subsequence of
their visited locations to a verifier or an auditor. The main challenge that
is addressed is to ensure that the location information that must be in
plaintext, does not breach privacy when used in sequence.
]]></content:encoded>
<pubDate>Mon, 28 Jul 2025 04:03:47 +0000</pubDate>
</item>
<item>
<title>Unmodified Half-Gates is Adaptively Secure - So is Unmodified Three-Halves</title>
<link>https://eprint.iacr.org/2023/1528</link>
<guid>https://eprint.iacr.org/2023/1528</guid>
<content:encoded><![CDATA[
Circuit garbling is a crucial cryptographic tool in many practical privacy-preserving applications due to two features: efficiency - it can be constructed in the random permutation model, allowing hardware acceleration; adaptivity - the majority of the communication can be transmitted offline before inputs are known. However, existing adaptive garbling schemes can only be proven in the random oracle model at best, leading to 20$\times$ slowdown.

In this work, we apply analysis often used for symmetric-key primitives to adaptive garbling and show that two practically deployed selective-secure schemes, half-gates and three-halves, already satisfy adaptive security without any modification to their implementations or security assumptions. We show how to bound an adaptive advantage via an adversary-dependent statistical distance and analyze this distance by adapting the H-coefficient technique to remove this adversary dependence. For real-life systems, our result solves the security concern about the heuristic of using the two schemes with offline communication. As a byproduct, we discuss when we can further offload the decoding information of garbled outputs to the offline phase, leading to a separation result.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 17:01:15 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Readiness in EdDSA Chains</title>
<link>https://eprint.iacr.org/2025/1368</link>
<guid>https://eprint.iacr.org/2025/1368</guid>
<content:encoded><![CDATA[
The impending threat posed by large-scale quantum computers necessitates a reevaluation of signature schemes deployed in blockchain protocols. In particular, blockchains relying on ECDSA, such as Bitcoin and Ethereum, exhibit inherent vulnerabilities due to on-chain public key exposure and the lack of post-quantum security guarantees. Although several post-quantum transition proposals have been introduced, including hybrid constructions and zero-knowledge-based key migration protocols, these approaches often fail to protect inactive "sleeping" accounts, are cumbersome, or require address changes, violating core immutability and full backward compatibility assumptions.

In this work, we observe that blockchains employing EdDSA with RFC 8032-compliant key derivation (e.g., Sui, Solana, Near, Stellar, Aptos, Cosmos) possess an underexplored structural advantage. Specifically, EdDSA’s hash-based deterministic secret key generation enables post-quantum zero-knowledge proofs of elliptic curve private key ownership, which can help switching to a quantum-safe algorithm proactively without requiring transfer of assets to new addresses.

We demonstrate how Post-Quantum NIZKs can be constructed to prove knowledge of the "seed" used in EdDSA key derivation, enabling post-quantum-secure transaction authorization without altering addresses or disclosing elliptic curve data. By post-quantum readiness, we mean that with a single user action all future signatures can be made post-quantum secure, even if past transactions used classical elliptic curve cryptography. This allows even users who have previously exposed their public key to seamlessly enter the post-quantum era without transferring assets or changing their account address.

As part of this analysis, we also show that BIP32-based ECDSA wallets are not post-quantum ready without breaking changes, as they rely on direct scalar exposure in derivation, making backward-compatible upgrades infeasible. In contrast, SLIP-0010  hash-chain based EdDSA private key derivation provides a foundation for seamless, backwards-compatible migration to quantum-safe wallets, supporting secure upgrades even for dormant or legacy accounts.

This mechanism affords a quantum-resilient path and is the first of its kind that preserves full backward compatibility, supports account abstraction, and critically secures dormant accounts, whether from users or custodians, that would otherwise be compromised under quantum adversaries.
]]></content:encoded>
<pubDate>Sat, 26 Jul 2025 13:48:05 +0000</pubDate>
</item>
<item>
<title>Randomized Distributed Function Computation (RDFC): Ultra-Efficient Semantic Communication Applications to Privacy</title>
<link>https://eprint.iacr.org/2025/1370</link>
<guid>https://eprint.iacr.org/2025/1370</guid>
<content:encoded><![CDATA[
We establish the randomized distributed function computation (RDFC) framework, in which a sender transmits just enough information for a receiver to generate a randomized function of the input data. Describing RDFC as a form of semantic communication, which can be essentially seen as a generalized remote‑source‑coding problem, we show that security and privacy constraints naturally fit this model, as they generally require a randomization step. Using strong coordination metrics, we ensure (local differential) privacy for every input sequence and prove that such guarantees can be met even when no common randomness is shared between the transmitter and receiver.

This work provides lower bounds on Wyner's common information (WCI), which is the communication cost when common randomness is absent, and proposes numerical techniques to evaluate the other corner point of the RDFC rate region for continuous‑alphabet random variables with unlimited shared randomness. Experiments illustrate that a sufficient amount of common randomness can reduce the semantic communication rate by up to two orders of magnitude compared to the WCI point, while RDFC without any shared randomness still outperforms lossless transmission by a large margin. A finite blocklength analysis further confirms that the privacy parameter gap between the asymptotic and non-asymptotic RDFC methods closes exponentially fast with input length. Our results position RDFC as an energy-efficient semantic communication strategy for privacy‑aware distributed computation systems.
]]></content:encoded>
<pubDate>Sun, 27 Jul 2025 14:13:47 +0000</pubDate>
</item>
<item>
<title>Encrypted Matrix Multiplication Using 3-Dimensional Rotations</title>
<link>https://eprint.iacr.org/2025/1367</link>
<guid>https://eprint.iacr.org/2025/1367</guid>
<content:encoded><![CDATA[
Fully homomorphic encryption (FHE) enables computations over encrypted data without the need for decryption.  Recently there has been an increased interest in developing FHE based algorithms to facilitate encrypted matrix multiplication (EMM) due to rising data security concerns surrounding cyber-physical systems, sensor processing, blockchain, and machine learning.  Presently, FHE operations have a high computational overhead, resulting in an increased need for low operational complexity algorithms to compensate.  We present a novel matrix encoding and EMM algorithm for power-of-2 cyclotomic based rings, utilizing three-dimensional rotations which offer improvements over the one-dimensional rotations used in previous work.  We encode each $d \times d$ matrix as a single, batch-encoded, ciphertext, with minimum ciphertext size $d^3$.  The proposed algorithm improves the number of plaintext-ciphertext multiplications from $O(d)$ to $O(1)$ and the number of rotations from $O(d)$ to $O(\log_2{d})$.  In addition, our work supports rectangular matrix multiplication and matrix packing without incurring additional operations per execution.  Benchmarks were obtained with a Microsoft SEAL implementation and compared against leading EMM algorithm, with our work performing $4$ times faster for $16 \times 16$ matrices on consumer hardware.  Our algorithm is compatible with existing encrypted machine learning frameworks and can be a drop-in replacement for existing matrix multiplication algorithms for increased speed.  The favorable time complexity is well suited for time sensitive encrypted algorithms such as computer vision, controls, and patient health monitoring.
]]></content:encoded>
<pubDate>Sat, 26 Jul 2025 03:13:40 +0000</pubDate>
</item>
<item>
<title>Towards Efficient Privacy-Preserving Machine Learning: A Systematic Review from Protocol, Model, and System Perspectives</title>
<link>https://eprint.iacr.org/2025/1365</link>
<guid>https://eprint.iacr.org/2025/1365</guid>
<content:encoded><![CDATA[
Privacy-preserving machine learning (PPML) based on cryptographic protocols has emerged as a promising paradigm to protect user data privacy in cloud-based machine learning services. While it achieves formal privacy protection, PPML often incurs significant efficiency and scalability costs due to orders of magnitude overhead compared to the plaintext counterpart. Therefore, there has been a considerable focus on mitigating the efficiency gap for PPML. In this survey, we provide a comprehensive and systematic review of recent PPML studies with a focus on cross-level optimizations. Specifically, we categorize existing papers into protocol level, model level, and system level, and review progress at each level. We also provide qualitative and quantitative comparisons of existing works with technical insights, based on which we discuss future research directions and highlight the necessity of integrating optimizations across protocol, model, and system levels. We hope this survey can provide an overarching understanding of existing approaches and potentially inspire future breakthroughs in the PPML field. As the field is evolving fast, we also provide a public GitHub repository to continuously track the developments, which is available at https://github.com/PKU-SEC-Lab/Awesome-PPML-Papers.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 16:24:56 +0000</pubDate>
</item>
<item>
<title>Universally Composable Adaptor Signatures</title>
<link>https://eprint.iacr.org/2025/1363</link>
<guid>https://eprint.iacr.org/2025/1363</guid>
<content:encoded><![CDATA[
Adaptor signatures extend the functionality of digital signatures by enabling the computation of pre-signatures on messages relative to statements in NP relations.
Pre-signatures are publicly verifiable objects that simultaneously hide and commit to a standard signature on the same message. 
Anyone possessing a valid witness for the statement can adapt the pre-signature into a full signature under the underlying signature scheme. 
Since adaptor signatures are commonly used as building blocks in larger systems—such as blockchain protocols—it is natural to seek a security definition within the Universal Composability (UC) framework. 
A recent attempt by Tairi et al. (CCS'23) introduced the first UC functionality for adaptor signatures.

This paper makes both negative and positive contributions. On the negative side, we show that the functionality proposed by Tairi et al. suffers from critical limitations:
    - The functionality fails to guarantee extractability and adaptability—the core security properties of adaptor signatures—to higher-level protocols.
    - No adaptor signature scheme can realize the functionality.

On the positive side, we propose a new UC functionality that faithfully captures the latest security guarantees of adaptor signatures as formalized via game-based notions by Gerhart et al. (EUROCRYPT'24).
    - Our functionality guarantees extractability, unique extractability, and pre-signature adaptability in a way that is composable and meaningful for higher-level protocols.
    - We show that it is realizable by an enhanced Schnorr-based adaptor signature scheme that we construct. Our construction maintains compatibility with existing infrastructure and is efficient enough for practical deployment, particularly in Bitcoin-like environments.
]]></content:encoded>
<pubDate>Fri, 25 Jul 2025 16:00:31 +0000</pubDate>
</item>
<item>
<title>Revisiting the Generalized Birthday Problem and Equihash: Single or K Lists?</title>
<link>https://eprint.iacr.org/2025/1351</link>
<guid>https://eprint.iacr.org/2025/1351</guid>
<content:encoded><![CDATA[
The Generalized Birthday Problem ($\textsf{GBP}$), which seeks $k$ hash values from $k$ lists whose XOR is zero, is a fundamental problem across multiple cryptographic domains. Wagner's \(k\)-list algorithm (Crypto'02) for $\textsf{GBP}$ has advanced the optimization of solving the syndrome decoding problem and established new cryptanalytic benchmarks for incremental cryptography and blind signatures. $\textsf{Equihash}$ (NDSS'16) underscores the critical advantages of $\textsf{GBP}$ in proof-of-work design, particularly its ASIC-resistance in blockchain. While the k-list $\textsf{GBP}$ has been extensively studied, many schemes including $\textsf{Equihash}$ utilize a single-list variant (selecting hash values from a single list) without clear theoretical grounding. In this work, we revisit these two long-conflated problems and fill in theoretical gaps in solving the single-list $\textsf{GBP}$.

In the realm of $\textsf{Equihash}$, the index-pointer technique has significantly weakened its ASIC-resistance. Our trade-off optimization to Wagner's algorithmic framework further diminishes this resistance by reducing peak memory by at least 50% across most $\textsf{Equihash}$ parameters. To address this, we propose $\textsf{Sequihash}$, a PoW with enhanced ASIC-resistance, rigorously aligned with the $k$-list $\textsf{GBP}$. Furthermore, we explore the implications of $\textsf{GBP}$ in the field of incremental hash and propose a new collision attack on ID-based incremental hash (Eurocrypt'97). Our attack achieves an asymptotic time complexity of $\mathcal{O}(\sqrt{n} \cdot 2^{\sqrt{2n}})$, significantly improving upon the previous Wagner's bound of $\mathcal{O}(2^{\sqrt{4n}})$. Applying our attack to $\textsf{iSHAKE256}$, we reduce its security lower bound from \( 2^{256} \) to \( 2^{189} \).
]]></content:encoded>
<pubDate>Thu, 24 Jul 2025 15:32:27 +0000</pubDate>
</item>
<item>
<title>A Compact Post-quantum Strong Designated Verifier Signature Scheme from Isogenies</title>
<link>https://eprint.iacr.org/2025/1335</link>
<guid>https://eprint.iacr.org/2025/1335</guid>
<content:encoded><![CDATA[
Digital signatures are essential cryptographic tools that provide authentication and integrity in digital communications. However, privacy-sensitive applications—such as e-voting and digital cash—require more restrictive verification models to ensure confidentiality and control. Strong Designated Verifier Signature (SDVS) schemes address this need by enabling the signer to designate a specific verifier, ensuring that only this party can validate the signature. Existing SDVS constructions are primarily based on number-theoretic assumptions and are therefore vulnerable to quantum attacks. Although post-quantum alternatives—particularly those based on lattices—have been proposed, they often entail large key and signature sizes.  
In this work, we introduce $\mathsf{CSI\text{-}SDVS}$, a novel isogeny-based SDVS scheme that offers a compact, quantum-resistant alternative. Our construction builds on the ideal class group action framework of CSIDH and the signature techniques of CSI-FiSh, and relies on the hardness of the Multi-Target Group Action Inverse Problem (MT-GAIP). $\mathsf{CSI\text{-}SDVS}$ achieves strong security guarantees—namely, Strong Unforgeability under Chosen-Message Attacks (SUF-CMA), Non-Transferability (NT), and Privacy of Signer’s Identity (PSI)—in the random oracle model. Remarkably, both the keys and signatures in $\mathsf{CSI\text{-}SDVS}$ are of size $\mathcal{O}(\lambda)$, representing a significant improvement over the typical $\mathcal{O}(\lambda^2)$ bounds in existing post-quantum SDVS schemes, thereby making it among the most compact PQC-based SDVS schemes and the only post-quantum secure construction based on isogenies.
]]></content:encoded>
<pubDate>Tue, 22 Jul 2025 05:42:29 +0000</pubDate>
</item>
<item>
<title>Technical Note: LeanSig for Post-Quantum Ethereum</title>
<link>https://eprint.iacr.org/2025/1332</link>
<guid>https://eprint.iacr.org/2025/1332</guid>
<content:encoded><![CDATA[
In this note, we present a new instantiation of the hash-based multi-signature framework introduced by Drake, Khovratovich, Kudinov, and Wagner (CiC Vol 2 Issue 1, eprint 2025/055) for Ethereum’s consensus layer. Inspired by a recent work of Khovratovich, Kudinov, and Wagner (Crypto 2025, eprint 2025/889), we instantiate the framework with a novel incomparable encoding that improves the tradeoff between signature size and verification hashing. The purpose of this document is to make explicit how to use the ideas of the latter work within the framework of Drake, Khovratovich, Kudinov, and Wagner.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 16:14:53 +0000</pubDate>
</item>
<item>
<title>Private Set Intersection and other Set Operations in the Third Party Setting</title>
<link>https://eprint.iacr.org/2025/1328</link>
<guid>https://eprint.iacr.org/2025/1328</guid>
<content:encoded><![CDATA[
We present a collection of protocols to perform privacy-preserving set operations in the third-party private set intersection (PSI) setting. This includes several protocols for multi-party third party PSI. In this model, there are multiple input parties (or clients) each holding a private set of elements and the receiver is an external party (termed as third-party) with no inputs. Multi-party third party PSI enables the receiver to learn only the intersection result of all input clients' private sets while revealing nothing else to the clients and the receiver. Our solutions include constructions that are provably secure against an arbitrary number of colluding parties in the semi-honest model. Additionally, we present protocols for third-party private set difference and private symmetric difference, whereby the learned output by the inputless third-party is the set difference and symmetric difference respectively of two other input parties, while preserving the same privacy guarantees. The motivation in the design of these protocols stems from their utilities in numerous real-world applications. We implemented our protocols and conducted experiments across various input and output set sizes.
]]></content:encoded>
<pubDate>Mon, 21 Jul 2025 08:08:13 +0000</pubDate>
</item>
<item>
<title>Ordering Transactions with Bounded Unfairness: Definitions, Complexity and Constructions</title>
<link>https://eprint.iacr.org/2023/1253</link>
<guid>https://eprint.iacr.org/2023/1253</guid>
<content:encoded><![CDATA[
An important consideration in the context of distributed ledger protocols is fairness in terms of transaction ordering. Recent work [Crypto 2020] revealed a connection of (receiver) order fairness to social choice theory and related impossibility results arising from the Condorcet paradox. As a result of the impossibility, various relaxations of order fairness were proposed in prior works. Given that distributed ledger protocols, especially those processing smart contracts, must serialize the input transactions, a natural objective is to minimize the distance (in terms of number of transactions) between any pair of unfairly ordered transactions in the output ledger — a concept we call bounded unfairness. In state machine replication (SMR) parlance this asks for minimizing the number of unfair state updates occurring before the processing of any request. This unfairness minimization objective gives rise to a natural class of parametric order fairness definitions that has not been studied before. As we observe, previous realizable relaxations of order fairness do not yield good unfairness bounds.

Achieving optimal order fairness in the sense of bounded unfairness turns out to be connected to the graph theoretic properties of the underlying transaction dependency graph and specifically the bandwidth metric of strongly connected components in this graph. This gives rise to a specific instance of the definition that we call “directed bandwidth order-fairness” which we show that it captures the best possible that any ledger protocol can achieve in terms of bounding unfairness. We prove ordering transactions in this fashion is NP-hard and non-approximable for any constant ratio. Towards realizing the property, we put forth a new distributed ledger protocol called Taxis that achieves directed bandwidth order-fairness. We present two variations, one that matches the property perfectly but (necessarily) lacks in performance and liveness, and another that achieves liveness and better complexity while offering a slightly relaxed version of the property. Finally, we comment on applications of our work to social choice, a direction which we believe to be of independent interest.
]]></content:encoded>
<pubDate>Fri, 18 Aug 2023 13:45:58 +0000</pubDate>
</item>
<item>
<title>Permissionless Clock Synchronization with Public Setup</title>
<link>https://eprint.iacr.org/2022/1220</link>
<guid>https://eprint.iacr.org/2022/1220</guid>
<content:encoded><![CDATA[
The permissionless clock synchronization problem asks how it is possible for a population of parties to maintain a system-wide synchronized clock, while their participation rate fluctuates --- possibly very widely --- over time. The underlying assumption is that parties experience the passage of time with roughly the same speed, but however they may disengage and engage with the protocol following arbitrary (and even chosen adversarially) participation patterns. This (classical) problem has received renewed attention due to the advent of blockchain protocols, and recently it has been solved in the setting of proof of stake, i.e., when parties are assumed to have access to a trusted PKI setup [Badertscher et al., Eurocrypt '21].

In this work, we present the first proof-of-work (PoW)-based permissionless clock synchronization protocol. Our construction assumes a public setup (e.g., a CRS) and relies on an honest majority of computational power that, for the first time, is described in a fine-grain timing model that does not utilize a global clock that exports the current time to all parties. As a secondary result of independent interest, our protocol gives rise to the first PoW-based ledger consensus protocol that does not rely on an external clock for the time-stamping of transactions and adjustment of the PoW difficulty.
]]></content:encoded>
<pubDate>Wed, 14 Sep 2022 18:05:34 +0000</pubDate>
</item>
<item>
<title>Threshold Receipt-Free Voting with Server-Side Vote Validation</title>
<link>https://eprint.iacr.org/2025/1321</link>
<guid>https://eprint.iacr.org/2025/1321</guid>
<content:encoded><![CDATA[
Proving the validity of ballots is a central element of verifiable elections. Such proofs can however create challenges when one desires to make a protocol receipt-free.
We explore the challenges raised by validity proofs in the context of protocols where threshold receipt-freeness is obtained by secret sharing an encryption of a vote between multiple authorities. 
In such contexts, previous solutions verified the validity of votes by decrypting them after passing them through a mix-net. This approach however creates subtle privacy risks, especially when invalid votes leak structural patterns that threaten receipt-freeness. 
We propose a different approach of threshold receipt-free voting in which authorities re-randomize ballot shares then jointly compute a ZK proof of ballot validity before letting the ballots enter a (possibly homomorphic) tallying phase. Our approach keeps the voter computational costs limited while offering verifiability and improving the ballot privacy of previous solutions.  
We present two protocols that enable a group of servers to verify and publicly prove that encrypted votes satisfy some validity properties: Minimix, which preserves prior voter-side behavior with minimal overhead, and Homorand, which requires voters to submit auxiliary data to facilitate validation over large vote domains. We show how to use our two protocols within a threshold receipt-free voting framework. We provide formal security proofs and efficiency analyses to illustrate trade-offs in our designs.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 17:27:26 +0000</pubDate>
</item>
<item>
<title>Bridging Usability and Performance: A Tensor Compiler for Autovectorizing Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1319</link>
<guid>https://eprint.iacr.org/2025/1319</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) offers strong privacy guarantees by enabling computation over encrypted data. However, the performance of tensor operations in HE is highly sensitive to how the plaintext data is packed into ciphertexts. Large tensor programs introduce numerous possible layout assignments, making it both challenging and tedious for users to manually write efficient HE programs.

In this paper, we present Rotom, a compilation framework that autovectorizes tensor programs into optimized HE programs. Rotom systematically explores a wide range of layout assignments, applies state-of-the-art optimizations, and automatically finds an equivalent, efficient HE program. At its core, Rotom utilizes a novel, lightweight ApplyRoll layout conversion operator to easily modify the underlying data layouts and unlock new avenues for performance gains. Our evaluation demonstrates that Rotom scalably compiles all benchmarks in under 5 minutes, reduces rotations in manually optimized protocols by up to 4×, and achieves up to 80× performance improvement over prior systems.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 16:17:50 +0000</pubDate>
</item>
<item>
<title>FunBic-CCA: Function Secret Sharing for Biclusterings Applied to Cheng and Church Algorithm (Extended Version)</title>
<link>https://eprint.iacr.org/2025/1317</link>
<guid>https://eprint.iacr.org/2025/1317</guid>
<content:encoded><![CDATA[
High-throughput technologies (e.g., the microarray) have fostered the rapid growth of gene expression data collection. These biomedical datasets, increasingly distributed among research institutes and hospitals, fuel various machine learning applications such as anomaly detection, prediction or clustering. In particular, unsupervised classification techniques based on biclustering like the Cheng and Church Algorithm (CCA) have proven to adapt particularly well to gene expression data. However, biomedical data is highly sensitive, hence its sharing across multiple entities introduces privacy and security concerns, with an ever-present threat of accidental disclosure or leakage of private patient information. To address such threat, this work introduces a novel, highly efficient privacy-preserving protocol based on secure multiparty computation (MPC) between two servers to compute CCA. Our protocol performs operations relying on an additive secret sharing and function secret sharing, leading us to reformulate the steps of the CCA into MPC-friendly equivalents. Leveraging lightweight cryptographic primitives, our new technique named FunBic-CCA is first to exploit the efficiency of function secret sharing to achieve fast evaluation of the CCA biclustering algorithm.
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 12:26:14 +0000</pubDate>
</item>
<item>
<title>Two-Server Sublinear PIR with Symmetric Privacy and Statistical Security</title>
<link>https://eprint.iacr.org/2025/1313</link>
<guid>https://eprint.iacr.org/2025/1313</guid>
<content:encoded><![CDATA[
The field of private information retrieval (PIR) has made significant strides with a recent focus on protocols that offer sublinear online time, ensuring efficient access to public databases without compromising the privacy of the queries. The pioneering two-server PIR protocols developed by Corrigan-Gibbs and Kogan (EUROCRYPT 2020) enjoy the dual benefits of sublinear online time and statistical security. This allows their protocols to provide high efficiency and resist computationally unbounded adversaries. In this work, we extend this seminal work to the symmetric PIR (SPIR) context, where the protocol must ensure that the client is privy only to the requested database entries, with no knowledge of the remaining data. This enhancement aligns with scenarios where the confidentiality of non-requested information is as critical as the query itself. Our main result is the introduction of the first two-server SPIR protocols that achieve both sublinear online time and statistical security, together with an enhancement for achieving sublinear amortized time. Our protocols require a pragmatic level of shared randomness between the servers, which however is necessary for implementing statistical security in two-server SPIR, as showed by Gertner et al. (STOC 1998).
]]></content:encoded>
<pubDate>Fri, 18 Jul 2025 02:57:44 +0000</pubDate>
</item>
<item>
<title>A Comprehensive Survey of Privacy-Preserving Decision Trees Based on Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1310</link>
<guid>https://eprint.iacr.org/2025/1310</guid>
<content:encoded><![CDATA[
Decision trees are extensively employed in artificial intelligence and machine learning due to their interpretability, efficiency, and robustness-qualities that are particularly valued in sensitive domains such as healthcare, finance, and cybersecurity. In response to evolving data privacy regulations, there is an increasing demand for models that ensure data confidentiality during both training and inference. Homomorphic encryption emerges as a promising solution by enabling computations directly on encrypted data without exposing plaintext inputs. This survey provides a comprehensive review of privacy-preserving decision tree protocols leveraging homomorphic encryption. After
introducing fundamental concepts and the adopted methodology,
a dual-layer taxonomy is presented, encompassing system and
data characteristics as well as employed processing techniques.
This taxonomy facilitates the classification and comparison of
existing protocols, evaluating their effectiveness in addressing key
challenges related to privacy, efficiency, usability, and deploy-
ment. Finally, current limitations, emerging trends, and future
research directions are discussed to enhance the security and
practicality of homomorphic encryption frameworks for decision
trees in privacy-sensitive applications.
]]></content:encoded>
<pubDate>Thu, 17 Jul 2025 15:01:36 +0000</pubDate>
</item>
<item>
<title>FHERMA Cookbook: FHE Components for Privacy-Preserving Applications</title>
<link>https://eprint.iacr.org/2025/1302</link>
<guid>https://eprint.iacr.org/2025/1302</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) enables computation over
encrypted data and is considered a fundamental tool for privacy-preserving systems.
Despite significant theoretical progress, its practical adoption remains limited. One
contributing factor is the absence of reusable, application-level components suitable
for integration into real-world systems.
This work introduces a library of FHE components developed through a competition-
based framework. The components are outcomes of a series of formalized challenges
published on the FHERMA platform, each targeting a specific challenge—such
as comparison, sorting, or matrix operations—under concrete cryptographic and
performance constraints.
This initial release includes contributions from independent researchers and reflects
a variety of approaches across different FHE schemes. The library is intended to
expand over time as new challenges are introduced and solved, forming a foundation
for building and evaluating privacy-preserving applications.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 17:16:10 +0000</pubDate>
</item>
<item>
<title>PlasmaFold: An Efficient and Scalable Layer 2 with Client-Side Proving</title>
<link>https://eprint.iacr.org/2025/1300</link>
<guid>https://eprint.iacr.org/2025/1300</guid>
<content:encoded><![CDATA[
Despite the growing popularity of blockchains, their scalability remains a significant challenge. Layer-2s (L2s) aim to address this by introducing an operator to process transactions off-chain and post compact summaries to the Layer-1 (L1). However, existing L2 designs struggle with unsatisfactory throughput improvements, complex exit games, limited data availability, or high computational overhead for users.

This paper introduces PlasmaFold, a novel L2 designed to overcome these limitations. PlasmaFold utilizes a hybrid architecture: an operator (aggregator) generates proofs on server side for the honest construction of blocks, while users maintain balance proofs on their own devices. This separation of concerns enables instant, non-interactive exits via balance proofs, while block proofs handle most of the validations, minimizing users’ costs. By leveraging Incrementally Verifiable Computation (IVC), PlasmaFold achieves concrete efficiency. Users can update their balance proofs within a browser in under 1 second per transaction using less than 1 GB of RAM. Furthermore, only the identities of users who have acknowledged data receipt are posted to L1, ensuring data availability with a minimal on-chain footprint. This design keeps L1 costs extremely low, enabling a theoretical throughput of over 14000 transactions per second.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 14:28:36 +0000</pubDate>
</item>
<item>
<title>OverModRaise: Reducing Modulus Consumption of CKKS Bootstrapping</title>
<link>https://eprint.iacr.org/2025/1298</link>
<guid>https://eprint.iacr.org/2025/1298</guid>
<content:encoded><![CDATA[
The Cheon-Kim-Kim-Song (CKKS) homomorphic encryption scheme is widely adopted for securely evaluating circuits over real numbers, such as those arising in privacy-preserving machine learning (PPML), because it efficiently supports approximate floating-point arithmetic of messages. A CKKS ciphertext has a finite level, which corresponds to the budget for how many multiplicative operations can be applied. Once these levels are consumed, the ciphertext must be refreshed through a bootstrapping procedure to restore its capacity for further computation. However, bootstrapping itself also consumes a significant number of levels, leaving fewer levels after each bootstrapping. 

In this work, we propose three techniques—OverModRaise1, OverModRaise2, and Tuple-C2S/S2C—that target reductions in the modulus consumption of C2S/S2C among the CKKS bootstrapping procedures, without introducing substantial overhead or compromising security. By combining these techniques, our implementation demonstrates a 27–61% throughput improvement compared to the state-of-the-art bootstrapping.
]]></content:encoded>
<pubDate>Wed, 16 Jul 2025 10:56:42 +0000</pubDate>
</item>
<item>
<title>AD-MPC: Asynchronous Dynamic MPC with Guaranteed Output Delivery</title>
<link>https://eprint.iacr.org/2024/1653</link>
<guid>https://eprint.iacr.org/2024/1653</guid>
<content:encoded><![CDATA[
MPC-as-a-Service (MPCaaS) systems enable clients to outsource privacy-preserving computations to distributed servers, offering flexibility by adapting and configuring MPC protocols to meet diverse security requirements. However, traditional MPC protocols rely on a fixed set of servers for the entire computation process, limiting scalability. Dynamic MPC (DMPC) addresses this limitation by permitting participants to join or leave during the computation. Nevertheless, existing DMPC protocols assume synchronous networks, which can lead to failures under unbounded network delays. In this paper, we present AD-MPC, the first asynchronous dynamic MPC protocol. Our protocol ensures guaranteed output delivery under optimal resilience ($n=3t+1$). To achieve this, we introduce two critical components: an asynchronous dynamic preprocessing protocol that facilitates the on-demand generation of Beaver triples for secure multiplication, and an asynchronous transfer protocol that maintains consistency during party hand-offs. These components collectively ensure computation correctness and transfer consistency across participants. We implement AD-MPC and evaluate its performance across up to 20 geographically distributed nodes. Experimental results demonstrate that the protocol not only offers strong security guarantees in dynamic and asynchronous network environments but also achieves performance comparable to state-of-the-art DMPC protocols.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 02:51:42 +0000</pubDate>
</item>
<item>
<title>SecFePAS: Secure Facial-Expression-Based Pain Assessment with Deep Learning at the Edge</title>
<link>https://eprint.iacr.org/2025/1280</link>
<guid>https://eprint.iacr.org/2025/1280</guid>
<content:encoded><![CDATA[
Patient monitoring in hospitals, nursing centers, and home care can be largely automated using cameras and machine-learning-based video analytics, thus considerably increasing the efficiency of patient care. In particular, Facial-expression-based Pain Assessment Systems (FePAS) can automatically detect pain and notify medical personnel. However, current FePAS solutions using cloud-based video analytics offer very limited security and privacy protection. This is problematic, as video feeds of patients constitute highly sensitive information.
To address this problem, we introduce SecFePAS, the first FePAS solution with strong security and privacy guarantees. SecFePAS uses advanced cryptographic protocols to perform neural network inference in a privacy-preserving way. To counteract the significant overhead of the used cryptographic protocols, SecFePAS uses multiple optimizations. First, instead of a cloud-based setup, we use edge computing with a 5G connection to benefit from lower network latency. Second, we use a combination of transfer learning and quantization to devise neural networks with high accuracy and optimized inference time. Third, SecFePAS quickly filters out unessential frames of the video to focus the in-depth analysis on key frames. We tested SecFePAS with the SqueezeNet and ResNet50 neural networks on a real pain estimation benchmark. SecFePAS outperforms state-of-the-art FePAS systems in accuracy and optimizes secure processing time.
]]></content:encoded>
<pubDate>Sun, 13 Jul 2025 15:54:34 +0000</pubDate>
</item>
<item>
<title>Multi-Authority Registered Attribute-Based Encryption</title>
<link>https://eprint.iacr.org/2025/1279</link>
<guid>https://eprint.iacr.org/2025/1279</guid>
<content:encoded><![CDATA[
Registered attribute-based encryption (ABE) enables fine-grained access control to encrypted data without a trusted authority. In this model, users generate their own public keys and register their public key along with a set of attributes with a key curator. The key curator aggregates the public keys into a short master public key that functions as the public key for an ABE scheme.

A limitation of ABE (registered or centralized) is the assumption that a single entity manages all of the attributes in a system. In many settings, the attributes belong to different organizations, making it unrealistic to expect that a single entity manage all of them. In the centralized setting, this motivated the notion of multi-authority ABE, where multiple independent authorities control their individual set of attributes. Access policies are then defined over attributes across multiple authorities.

In this work, we introduce multi-authority registered ABE, where multiple (independent) key curators each manage their individual sets of attributes. Users can register their public keys with any key curator, and access policies can be defined over attributes from multiple key curators. Multi-authority registered ABE combines the trustless nature of registered ABE with the decentralized nature of multi-authority ABE.

We start by constructing a multi-authority registered ABE scheme from composite-order pairing groups. This scheme supports an a priori bounded number of users and access policies that can be represented by a linear secret sharing scheme (which includes monotone Boolean formulas). Our construction relies on a careful integration of ideas from pairing-based registered ABE and multi-authority ABE schemes. We also construct a multi-authority registered ABE scheme that supports an unbounded number of users and arbitrary monotone policies using indistinguishability obfuscation (and function-binding hash functions).
]]></content:encoded>
<pubDate>Sun, 13 Jul 2025 04:58:41 +0000</pubDate>
</item>
<item>
<title>Improved Matrix Inversion with Packed Ciphertexts using Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1274</link>
<guid>https://eprint.iacr.org/2025/1274</guid>
<content:encoded><![CDATA[
Matrix inversion is a fundamental operation, but performing it over encrypted matrices remains a significant challenge.
This is mainly due to the fact that conventional inversion algorithms—such as Gaussian elimination—depend heavily on comparison and division operations, which are computationally expensive to perform under homomorphic encryption. 
To mitigate this, Ahn et al. (ESORICS 2023) introduced an inversion method based on iterative matrix multiplications. However, their approach encrypts matrices entry-wise, leading to poor scalability. A key limitation of prior work stems from the absence of an efficient matrix multiplication technique for matrix-packed ciphertexts, particularly one with low multiplicative depth.

In this paper, we present a novel homomorphic matrix multiplication algorithm optimized for matrix-packed ciphertexts, requiring only a multiplicative depth of two. 
Building on this foundation, we propose an efficient algorithm for homomorphic matrix inversion. 
Experimental results show that our method outperforms the state-of-the-art: for $8\times 8$ matrices, it achieves a $6.8\times$ speedup over the method by Ahn et al., and enables inversion of larger matrices that were previously infeasible.
We further compare our homomorphic matrix multiplication technique against existing matrix-packed homomorphic matrix multiplication algorithms.
When used for iterative inversion, our method consistently outperforms prior approaches. 
In particular, for $16\times 16$ and $32\times 32$ matrices, it achieves $1.88\times$ and $1.43\times$ speedups, respectively, over the algorithm by Aikata and Roy.
Finally, we demonstrate the practical benefits of our method by applying it to privacy-preserving linear regression. For a dataset of $64$ samples with $8$ features, our approach achieves a $1.13\times$ speedup in training time compared to the state-of-the-art homomorphic matrix inversion solution.
]]></content:encoded>
<pubDate>Fri, 11 Jul 2025 08:35:06 +0000</pubDate>
</item>
<item>
<title>Threshold Structure-Preserving Signatures with Randomizable Key</title>
<link>https://eprint.iacr.org/2025/1273</link>
<guid>https://eprint.iacr.org/2025/1273</guid>
<content:encoded><![CDATA[
While digital signatures serve to confirm message integrity
and the identity of the signer, the inherent link between the public key
and the signer’s identity can pose challenges in anonymized networks or
applications focused on preserving privacy. Signatures with randomiz-
able keys aim to disentangle the signer’s identity from their public key,
thus preserving the signature’s validity. This approach ensures that the
signature, even with a randomized key, maintains its verifiability without
linking it to the signer’s identity.
Although signatures with randomizable keys effectively maintain privacy,
additional structural improvements are necessary in specialized signature
schemes for complex cryptographic frameworks. Threshold structure-
preserving signatures offer a way to construct modular protocols while
retaining the benefits of structure-preserving properties. Thus, the ran-
domizable key version of it is essential for a wide range of applications,
making it the foundation of this work. In this study, signatures with ran-
domizable key principles combined with threshold structure-preserving
signatures to build a strong cryptographic base for privacy-preserving
applications. This foundation makes sure that signatures are valid while
also being modular and unlinkable.
An earlier version of this work appeared in the 22nd International Con-
ference on Security and Cryptography(SECRYPT 2025) [6]; the present
article extends that study by adding the formal security proofs of the
introduced protocols.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 20:44:53 +0000</pubDate>
</item>
<item>
<title>Applications Of Zero-Knowledge Proofs On Bitcoin</title>
<link>https://eprint.iacr.org/2025/1271</link>
<guid>https://eprint.iacr.org/2025/1271</guid>
<content:encoded><![CDATA[
This paper explores how zero-knowledge proofs can enhance Bitcoin's functionality and privacy. First, we consider Proof-of-Reserve schemes: by using zk-STARKs, a custodian can prove its Bitcoin holdings are more than a predefined threshold X, without revealing addresses or actual balances. We outline a STARK-based protocol for Bitcoin UTXOs and discuss its efficiency. Second, we examine ZK Light Clients, where a mobile or lightweight device verifies Bitcoin's proof-of-work chain using succinct proofs. We propose a protocol for generating and verifying a STARK-based proof of a chain of block headers, enabling trust-minimized client operation. Third, we explore Privacy-Preserving Rollups via BitVM: leveraging BitVM, we design a conceptual rollup that keeps transaction data confidential using zero-knowledge proofs. In each case, we analyze security, compare with existing approaches, and discuss implementation considerations. Our contributions include the design of concrete protocols adapted to Bitcoin's UTXO model and an assessment of their practicality. The results suggest that while ZK proofs can bring powerful features (e.g., on-chain reserve audits, trustless light clients, and private layer-2 execution) to Bitcoin, each application requires careful trade-offs in efficiency and trust assumptions.
]]></content:encoded>
<pubDate>Thu, 10 Jul 2025 18:29:20 +0000</pubDate>
</item>
<item>
<title>Efficiently parsing existing eID documents for zero-knowledge proofs</title>
<link>https://eprint.iacr.org/2025/1266</link>
<guid>https://eprint.iacr.org/2025/1266</guid>
<content:encoded><![CDATA[
Online services increasingly require users to verify their identity or parts of it, often by law. This verification is usually performed by processing data from official identity documents, like national identity cards. However, these documents often contain significantly more information than the verifying party needs to know, including information that should stay private. Disclosing this information is a significant privacy and security risk for the user.
Traditional work has designed selective disclosure and zero-knowledge proof protocols for such use cases.
However, because these require a complete reimplementation, recall and redistribution of existing identity documents, they have never been adopted on a large scale. More recent work has focused on creating zero-knowledge proofs from existing identity documents like the US passport or specific US driver licenses. In this article, we propose an R1CS protocol to efficiently parse and extract fields from existing European National Identity Cards, with an implementation for the Belgian BeID.
The protocol is able to prove correct extraction of a date-of-birth field in 22 seconds on a consumer device, with verification taking 230 milliseconds. With this, we aim to provide EU citizens with a practical solution to the privacy and security risks that arise when one has to prove their authenticity or authority to a third party.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 13:46:16 +0000</pubDate>
</item>
<item>
<title>OasisDB: An Oblivious and Scalable System for Relational Data</title>
<link>https://eprint.iacr.org/2025/1263</link>
<guid>https://eprint.iacr.org/2025/1263</guid>
<content:encoded><![CDATA[
We present OasisDB, an oblivious and scalable RBDMS framework designed to securely manage relational data while protecting against access and volume pattern attacks. Inspired by plaintext RDBMSs, OasisDB leverages existing oblivious key value stores (KV-stores) as storage engines and securely scales them to enhance per-formance. Its novel multi-tier architecture allows for independent scaling of each tier while supporting multi-user environments without compromising privacy. We demonstrate OasisDB’s flexibility by deploying it with two distinct oblivious KV-stores, PathORAM and Waffle, and show its capability to execute a variety of SQL queries, including point and range queries, joins, aggregations, and limited updates. Experimental evaluations on the Epinions dataset show that OasisDB scales linearly with the number of machines. When deployed with a plaintext KV-store, OasisDB introduces negligible overhead in its multi-tier architecture compared to a plaintext database, CockroachDB. We also compare OasisDB with ObliDB, an oblivious RDBMS, highlighting its advantages with scalability and multi-user support.
]]></content:encoded>
<pubDate>Wed, 09 Jul 2025 03:30:30 +0000</pubDate>
</item>
<item>
<title>BitVM with Succinct On-Chain Cost from AB-LFE, HMAC, or Privacy-Free GC</title>
<link>https://eprint.iacr.org/2025/1253</link>
<guid>https://eprint.iacr.org/2025/1253</guid>
<content:encoded><![CDATA[
This paper aims to be a systematization of knowledge on how to instantiate BitVM with succinct on-chain cost from attribute-based laconic function evaluation (AB-LFE), homomorphic message authentication codes (HMAC), or privacy-free garbled circuits (GC) with suitable properties, specifically with:

- AB-LFE with unbounded depth and with bounded depth, which implies reusable privacy-free garbled circuits

- HMAC in with unbounded depth, which implies succinct privacy-free garbled circuits

- privacy-free garbled circuits and their succinct garbling as in BitGC

They vary in complexity, concrete overhead, succinctness, reusability, and security mechanisms against a malicious garbler. This paper is a literature review, as instantiating BitVM with them is straightforward.
]]></content:encoded>
<pubDate>Mon, 07 Jul 2025 19:47:20 +0000</pubDate>
</item>
<item>
<title>On the Estonian Internet Voting System, IVXV, SoK  and Suggestions</title>
<link>https://eprint.iacr.org/2025/506</link>
<guid>https://eprint.iacr.org/2025/506</guid>
<content:encoded><![CDATA[
The Estonian i-voting experience is probably the richest to analyze; a country that is considered a pioneer in digitizing both the government and private sector since 2001 followed by online internet voting (i-voting) in 2005. However, there are still some complaints submitted, critics and remarks to consider about the IVXV system. In this paper, we introduce a Systemization of Knowledge of the Estonian IVXV i-voting system and propose some added security enhancements. The presented SoK discusses applications implemented by election observers in 2023 & 2024 elections, which, to our knowledge, have never been mentioned and/or analyzed in the academia before. We also point out to unnoticed automated formal verification analysis of IVXV; the researchers discovered a privacy attack that we show extendable to a possible large scale encrypted vote copying. In addition, we identify and analyze recent fixes and improvements in the June 2024 version used in the European Parliament elections connecting them to their academic sources. Finally, we discuss the current system status, propose our own suggestions to some remaining vulnerabilities, then raise the inevitable question of the approaching quantum threat.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 19:16:27 +0000</pubDate>
</item>
<item>
<title>OMIX: Offline Mixing for Scalable Self-Tallying Elections</title>
<link>https://eprint.iacr.org/2025/1232</link>
<guid>https://eprint.iacr.org/2025/1232</guid>
<content:encoded><![CDATA[
In electronic voting systems, guaranteeing voter anonymity is essential. One primary method to ensure this is the use of a mix-net, in which a set of mix-servers sequentially shuffle a set of encrypted votes, and generate proofs that a correct permutation has been applied. Whilst mix-nets offer advantages over alternative approaches,  their traditional use during the tallying phase introduces a significant robustness bottleneck: the process is inherently sequential and critically depends on trusted authorities to perform shuffling and decryption. Any disruption can prevent the final result from being revealed.

In this work, we propose offline mixing OMIX, the first voting framework to support a mix-net-based system in which trustees never handle encrypted votes, while also ensuring that each voter's cost is independent of the total number of voters. In particular, the contributions of permutations by mix-servers and decryption shares by trustees are completed and publicly verified before any vote is cast. This eliminates the need for their participation during tallying and enables the first scalable, mix-net-based, and self-tallying voting protocol in the sense of Kiayias and Yung (PKC'02).

At the core of OMIX is a distributed key-generation mechanism: each voter locally generates a private voting key and registers a constant-size set of basis public keys. These are permuted and partially decrypted in an offline phase, resulting in a final public decryption key that reveals votes in shuffled order. Our construction leverages the homomorphic and structure-preserving properties of function-hiding inner-product functional encryption, combined with standard primitives, to achieve self-tallying, client scalability, ballot privacy and other voting properties. To support the new mixing structure introduced by OMIX, we also develop a compact and verifiable offline mix-net, based on an enhanced linearly homomorphic signature scheme. This latter primitive may be of independent interest.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 20:46:52 +0000</pubDate>
</item>
<item>
<title>ABE Cubed: Advanced Benchmarking Extensions for ABE Squared</title>
<link>https://eprint.iacr.org/2025/1230</link>
<guid>https://eprint.iacr.org/2025/1230</guid>
<content:encoded><![CDATA[
Since attribute-based encryption (ABE) was proposed in 2005, it has established itself as a valuable tool in the enforcement of access control. For practice, it is important that ABE satisfies many desirable properties such as multi-authority and negations support. Nowadays, we can attain these properties simultaneously, but none of these schemes have been implemented. Furthermore, although simpler schemes have been optimized extensively on a structural level, there is still much room for improvement for these more advanced schemes. However, even if we had schemes with such structural improvements, we would not have a way to benchmark and compare them fairly to measure the effect of such improvements. The only framework that aims to achieve this goal, ABE Squared (TCHES '22), was designed with simpler schemes in mind.

In this work, we propose the ABE Cubed framework, which provides advanced benchmarking extensions for ABE Squared. To motivate our framework, we first apply structural improvements to the decentralized ciphertext-policy ABE scheme supporting negations presented by Riepel, Venema and Verma (ACM CCS '24), which results in five new schemes with the same properties. We use these schemes to uncover and bridge the gaps in the ABE Squared framework. In particular, we observe that advanced schemes depend on more "variables" that affect the schemes' efficiency in different dimensions. Whereas ABE Squared only considered one dimension (as was sufficient for the schemes considered there), we devise a benchmarking strategy that allows us to analyze the schemes in multiple dimensions. As a result, we obtain a more complete overview on the computational efficiency of the schemes, and ultimately, this allows us to make better-founded choices about which schemes provide the best efficiency trade-offs for practice.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 15:13:17 +0000</pubDate>
</item>
<item>
<title>Rational Censorship Attack: Breaking Blockchain with a Blackboard</title>
<link>https://eprint.iacr.org/2025/1226</link>
<guid>https://eprint.iacr.org/2025/1226</guid>
<content:encoded><![CDATA[
Censorship resilience is a fundamental assumption underlying the security of blockchain protocols. Additionally, the analysis of blockchain security from an economic and game theoretic perspective has been growing in popularity in recent years.
In this work, we present a surprising rational censorship attack on blockchain censorship resilience when we adopt the analysis of blockchain security from a game theoretic lens and assume all users are rational. 
In our attack, a colluding group with sufficient voting power censors the remainder nodes such that the group alone can gain all the rewards from maintaining the blockchain.
We show that if nodes are rational, coordinating this attack just requires a public read and write blackboard and we formally model the attack using a game theoretic framework.
Furthermore, we note that to ensure the success of the attack, nodes need to know the total true voting power held by the colluding group.
We prove that the strategy to join the rational censorship attack and also for nodes to honestly declare their power is a subgame perfect equilibrium in the corresponding extensive form game induced by our attack.
Finally, we discuss the implications of the attack on blockchain users and protocol designers as well as some potential countermeasures.
]]></content:encoded>
<pubDate>Wed, 02 Jul 2025 07:34:40 +0000</pubDate>
</item>
<item>
<title>Baloo: Nearly Optimal Lookup Arguments</title>
<link>https://eprint.iacr.org/2022/1565</link>
<guid>https://eprint.iacr.org/2022/1565</guid>
<content:encoded><![CDATA[
We present Baloo, a protocol for lookup tables where the prover work is linear on the number of lookups and independent of the table size. Baloo is built over previous lookup arguments, and the framework for SNARKs from Ràfols and Zapico (CRYPTO 21).
Our protocol supports commit-and-prove expansions: the prover selects the subtable containing the elements used in the lookup, that is unknown to the verifier, commits to it and later proves its relation with the committed elements. This feature makes Baloo especially suitable for proving input-output relations on hash functions, and in particular to instantiate the Ethereum Virtual Machine (EVM).
]]></content:encoded>
<pubDate>Thu, 10 Nov 2022 11:21:50 +0000</pubDate>
</item>
<item>
<title>Lattice EPID with Efficient Revocation</title>
<link>https://eprint.iacr.org/2025/1225</link>
<guid>https://eprint.iacr.org/2025/1225</guid>
<content:encoded><![CDATA[
Enhanced Privacy Identification (EPID) is one of the anonymous authentication mechanisms that found their way into the industry, being deployed in billions of chips and standardized at ISO. The linchpin of EPID lies in its decentralized revocation procedure that allows to revoke a signer by simply placing one of its signatures on a signature revocation list SRL. Each new signature must then include a proof that it has been generated with a key different from those used to produce the signatures on the SRL. This proof of non-revocation in current post-quantum schemes either relies on general-purpose NIZKs or on regular zero-knowledge proofs (ZKP) but with a witness dimension linear in the size of the SRL, which leads to large size and/or computational complexity. 
In this paper, we rethink the standard approach of non-revocation so as to avoid its heavy reliance on ZKP. Our construction indeed combines features from different tools (such as Falcon signatures) that are unusual in this context to pull most elements out of the ZKP, leading to significant performance improvements. Providing all these elements unconcealed creates many security challenges for our construction but we yet manage to address all of them and prove security under well-understood lattice assumptions, and in the strong model of Sanders-Traoré (CT-RSA'21) allowing malicious SRLs.
]]></content:encoded>
<pubDate>Tue, 01 Jul 2025 13:08:06 +0000</pubDate>
</item>
<item>
<title>Revisiting Module Lattice-based Homomorphic Encryption and Application to Secure-MPC</title>
<link>https://eprint.iacr.org/2025/1218</link>
<guid>https://eprint.iacr.org/2025/1218</guid>
<content:encoded><![CDATA[
Homomorphic encryption (HE) schemes have gained significant popularity in modern privacy-preserving applications across various domains. While research on HE constructions based on learning with errors (LWE) and ring-LWE has received major attention from both cryptographers and software-hardware designers alike, their module-LWE-based counterpart has remained comparatively under-explored in the literature. A recent work provides a module-LWE-based instantiation (MLWE-HE) of the Cheon-Kim-Kim-Song (CKKS) scheme and showcases several of its advantages such as parameter flexibility and improved parallelism. However, a primary limitation of this construction is the quadratic growth in the size of the relinearization keys. Our contribution is two-pronged: first, we present a new relinearization key-generation technique that addresses the issue of quadratic key size expansion by reducing it to linear growth. Second, we extend the application of MLWE-HE in a multi-group homomorphic encryption (MGHE) framework, thereby generalizing the favorable properties of the single-keyed HE to a multi-keyed setting as well as investigating additional flexibility attributes of the MGHE framework.
]]></content:encoded>
<pubDate>Mon, 30 Jun 2025 06:41:12 +0000</pubDate>
</item>
<item>
<title>SoK: Signatures With Randomizable Keys</title>
<link>https://eprint.iacr.org/2023/1524</link>
<guid>https://eprint.iacr.org/2023/1524</guid>
<content:encoded><![CDATA[
Digital signature schemes with specific properties have recently seen various real-world applications with a strong emphasis on privacy-enhancing technologies. They have been extensively used to develop anonymous credentials schemes and to achieve an even more comprehensive range of functionalities in the decentralized web.

Substantial work has been done to formalize different types of signatures where an allowable set of transformations can be applied to message-signature pairs to obtain new related pairs. Most of the previous work focused on transformations with respect to the message being signed, but little has been done to study what happens when transformations apply to the signing keys. A first attempt to thoroughly formalize such aspects was carried by Derler and Slamanig (ePrint'16, Designs, Codes and Cryptography'19), followed by the more recent efforts by Backes et al. (ASIACRYPT'18) and Eaton et al. (ePrint'23). However, the literature on the topic is vast and different terminology is used across contributions, which makes it difficult to compare related works and understand the range of applications covered by a given construction.

In this work, we present a unified view of signatures with randomizable keys and revisit their security properties. We focus on state-of-the-art constructions and related applications,identifying existing challenges. Our systematization allows us to highlight gaps, open questions and directions for future research on signatures with randomizable keys.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 12:19:53 +0000</pubDate>
</item>
<item>
<title>RingSG: Optimal Secure Vertex-Centric Computation for Collaborative Graph Processing</title>
<link>https://eprint.iacr.org/2025/1209</link>
<guid>https://eprint.iacr.org/2025/1209</guid>
<content:encoded><![CDATA[
Collaborative graph processing refers to the joint analysis of inter-connected graphs held by multiple graph owners. To honor data privacy and support various graph processing algorithms, existing approaches employ secure multi-party computation (MPC) protocols to express the vertex-centric abstraction. Yet, due to certain computation-intensive cryptography constructions, state-of-the-art (SOTA) approaches are asymptotically suboptimal, imposing significant overheads in terms of computation and communication. In this paper, we present RingSG, the first system to attain optimal communication/computation complexity within the MPC-based vertex-centric abstraction for collaborative graph processing. This optimal complexity is attributed to Ring-ScatterGather, a novel computation paradigm that can avoid exceedingly expensive cryptography operations (e.g., oblivious sort), and simultaneously ensure the overall workload can be optimally decomposed into parallelizable and mutually exclusive MPC tasks. Within Ring-ScatterGather, RingSG improves the concrete runtime efficiency by incorporating 3-party secure computation via share conversion, and optimizing the most cost-heavy part using a novel oblivious group aggregation protocol. Finally, unlike prior approaches, we instantiate RingSG into two end-to-end applications to effectively obtain application-specific results from the protocol outputs in a privacy-preserving manner. We developed a prototype of RingSG and extensively evaluated it across various graph collaboration settings, including different graph sizes, numbers of parties, and average vertex degrees. The results show RingSG reduces the system running time of SOTA approaches by up to 15.34× and per-party communication by up to 10.36×. Notably, RingSG excels in processing sparse global graphs collectively held by more parties, consistent with our theoretical cost analysis.
]]></content:encoded>
<pubDate>Sat, 28 Jun 2025 03:25:17 +0000</pubDate>
</item>
<item>
<title>BitBatSPIR: Efficient Batch Symmetric Private Information Retrieval from PSI</title>
<link>https://eprint.iacr.org/2025/1201</link>
<guid>https://eprint.iacr.org/2025/1201</guid>
<content:encoded><![CDATA[
Private Information Retrieval (PIR) allows a client to retrieve an entry from a database held by a server without leaking which entry is being requested. Symmetric PIR (SPIR) is a stronger variant of PIR with database privacy so that the client knows nothing about the database other than the retrieved entry.

This work studies SPIR in the batch setting (BatchSPIR), where the client wants to retrieve multiple entries. In particular, we focus on the case of bit entries, which has important real-world applications. We set up the connection between bit-entry information retrieval and set operation, and propose a black-box construction of BatchSPIR from Private Set Intersection (PSI). By applying an efficient PSI protocol with asymmetric set sizes, we obtain our BatchSPIR protocol named $\mathsf{BitBatSPIR}$. We also introduce several optimizations for the underlying PSI. These optimizations improve the efficiency of our concrete BatchSPIR construction as well as the PSI protocol.

We implement $\mathsf{BitBatSPIR}$ and compare the performance with the state-of-the-art PIR protocol in the batch setting. Our experimental results show that $\mathsf{BitBatSPIR}$ not only achieves a stronger security guarantee (symmetric privacy) but also has a better performance for large databases, especially in the Wide Area Network (WAN) setting.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 09:25:51 +0000</pubDate>
</item>
<item>
<title>Tricycle: Private Transformer Inference with Tricyclic Encodings</title>
<link>https://eprint.iacr.org/2025/1200</link>
<guid>https://eprint.iacr.org/2025/1200</guid>
<content:encoded><![CDATA[
The growing adoption of Large Language Models in privacy-sensitive domains necessitates secure inference mechanisms that preserve data confidentiality. Homomorphic encryption offers a promising pathway by enabling computation on encrypted inputs, yet existing approaches struggle to scale efficiently to full transformer models due to limitations in packing schemes, which must efficiently support a wide range of operations, including matrix multiplications, row-wise nonlinear operations, and self-attention. In this work, we present Tricycle, a framework for private transformer inference built on our novel packing scheme, called tricyclic encodings, which are designed to efficiently support these core operations. Tricyclic encodings are a generalization of bicyclic encodings, enabling privacy-preserving batch matrix multiplications with optimal multiplicative depth in order to facilitate parallelized multi-head self-attention. We optimize our matrix multiplications by incorporating Baby-Step Giant-Step optimizations to reduce ciphertext rotations and presenting new ciphertext-plaintext matrix multiplication techniques that relax prior limitations. A further contribution of our work is a lightweight and effective approach for stabilizing the softmax function via statistical max estimation. Our end-to-end implementation on a BERT-Tiny model shows that Tricycle achieves a \(1.5 \times\) to \(3 \times\) speedup over previous approaches, marking a step toward practical and scalable private LLM inference without sacrificing model fidelity.
]]></content:encoded>
<pubDate>Fri, 27 Jun 2025 07:40:55 +0000</pubDate>
</item>
<item>
<title>Private coins extension with verifiable encryption</title>
<link>https://eprint.iacr.org/2025/1194</link>
<guid>https://eprint.iacr.org/2025/1194</guid>
<content:encoded><![CDATA[
This paper introduces a protocol for verifiable encryption of values committed using Pedersen commitments. It enables a recipient to decrypt the hidden amount while proving its consistency with the original commitment, without revealing the value publicly. The construction combines symmetric encryption with zero-knowledge proofs and is made non-interactive via the Fiat-Shamir heuristic. The protocol is particularly useful in blockchain settings where confidential but verifiable value transfers are required.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 10:39:02 +0000</pubDate>
</item>
<item>
<title>Arithmetic PCA for Encrypted Data</title>
<link>https://eprint.iacr.org/2023/1544</link>
<guid>https://eprint.iacr.org/2023/1544</guid>
<content:encoded><![CDATA[
Reducing the size of large dimensional data is a critical task in machine learning (ML) that often involves using principal component analysis (PCA). In privacy-preserving ML, data confidentiality is of utmost importance, and reducing data size is a crucial way to cut overall costs.

This work focuses on minimizing the number of normalization processes in the PCA algorithm, which is a costly procedure in encrypted PCA. By modifying Krasulina's algorithm, non-polynomial operations were eliminated, except for a single delayed normalization at the end.

Our PCA algorithm demonstrated similar performance to conventional PCA algorithms in face recognition applications. We also implemented it using the CKKS (Cheon-Kim-Kim-Song) homomorphic encryption scheme and obtained the first 6 principal components of a 128$\times$128 real matrix in 7.85 minutes using 8 threads.
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 01:02:47 +0000</pubDate>
</item>
<item>
<title>PrivacyGo: Privacy-Preserving Ad Measurement with Multidimensional Intersection</title>
<link>https://eprint.iacr.org/2025/1192</link>
<guid>https://eprint.iacr.org/2025/1192</guid>
<content:encoded><![CDATA[
In digital advertising, accurate measurement is essential for optimiz- ing ad performance, requiring collaboration between advertisers and publishers to compute aggregate statistics—such as total conver- sions—while preserving user privacy. Traditional secure two-party computation methods allow joint computation on single-identifier data without revealing raw inputs, but they fall short when mul- tidimensional matching is needed and leak the intersection size, exposing sensitive information to privacy attacks.
This paper tackles the challenging and practical problem of multi- identifier private user profile matching for privacy-preserving ad measurement, a cornerstone of modern advertising analytics. We introduce a comprehensive cryptographic framework leveraging re- versed Oblivious Pseudorandom Functions (OPRF) and novel blind key rotation techniques to support secure matching across multiple identifiers. Our design prevents cross-identifier linkages and in- cludes a differentially private mechanism to obfuscate intersection sizes, mitigating risks such as membership inference attacks.
We present a concrete construction of our protocol that achieves both strong privacy guarantees and high efficiency. It scales to large datasets, offering a practical and scalable solution for privacy- centric applications like secure ad conversion tracking. By combin- ing rigorous cryptographic principles with differential privacy, our work addresses a critical need in the advertising industry, setting a new standard for privacy-preserving ad measurement frameworks.
]]></content:encoded>
<pubDate>Thu, 26 Jun 2025 03:08:14 +0000</pubDate>
</item>
<item>
<title>Performance and Privacy: A Low-Latency Secure Anonymous Authentication Protocol with OPRF</title>
<link>https://eprint.iacr.org/2025/1189</link>
<guid>https://eprint.iacr.org/2025/1189</guid>
<content:encoded><![CDATA[
erforming privacy-preserving queries, particularly anonymous authentication, against large-scale datasets presents critical tradeoffs between security, latency, scalability. Existing cryptographic solutions often impose linear 
computation or communication overheads. This paper introduces a novel, 
efficient protocol for secure anonymous authentication, uniquely combining matrix partitioning via hash prefixes with Oblivious Pseudorandom Functions in a 
three-server semi-honest model. Crucially, compared to our previous work published at TrustCom 2024, this enhanced protocol eliminates the dependency on a 
designated fully trusted server, achieving security when any single server is corrupted. Furthermore, our protocol demonstrates significant performance improvements over current state-of-the-art methods. It achieves sub-linear online 
communication complexity. Evaluations show that for datasets of size 𝑚 ≈ 106
, 
our protocol reduces online communication by at least 30% compared to other 
sub-linear schemes, while maintaining competitive online computation times. Security is proven via simulation, and comprehensive experiments confirm practicality for datasets up to 𝑚 = 10^8
]]></content:encoded>
<pubDate>Wed, 25 Jun 2025 05:10:01 +0000</pubDate>
</item>
<item>
<title>Unconditional Individual Verifiability with Receipt Freeness via Post-Cast Isolation</title>
<link>https://eprint.iacr.org/2025/1186</link>
<guid>https://eprint.iacr.org/2025/1186</guid>
<content:encoded><![CDATA[
We introduce a trapdoorless tracker construction for electronic voting that fundamentally reimagines verifiability through information flow control. Unlike existing E2E verifiable systems where receipt-freeness compromises individual verifiability, our approach achieves both simultaneously by requiring only temporary isolation of the voting calculator between ballot casting and verification—when voters enter unique challenges to compute trackers for locating their votes on the public tally board. Our construction leverages perfectly hiding Pedersen commitments and a unique tracker challenge mechanism to simultaneously achieve unconditional individual verifiability, practical everlasting privacy, and receipt-freeness while relying only on standard cryptographic assumptions. When verification failures occur, our system provides transparent accountability by precisely identifying whether the voting calculator or voting device is responsible. The system maintains security even with partial compliance with isolation procedures and offers robust protection against various adversaries while requiring minimal trust assumptions.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 16:38:22 +0000</pubDate>
</item>
<item>
<title>zkGPT: An Efficient Non-interactive Zero-knowledge Proof Framework for LLM Inference</title>
<link>https://eprint.iacr.org/2025/1184</link>
<guid>https://eprint.iacr.org/2025/1184</guid>
<content:encoded><![CDATA[
Large Language Models (LLMs) are widely employed for their ability to generate human-like text. However, service providers may deploy smaller models to reduce costs, potentially deceiving users. Zero-Knowledge Proofs (ZKPs) offer a solution by allowing providers to prove LLM inference without compromising the privacy of model parameters. Existing solutions either do not support LLM architectures or suffer from significant inefficiency and tremendous overhead. To address this issue, this paper introduces several new techniques. We propose new methods to efficiently prove linear and non-linear layers in LLMs, reducing computation overhead by orders of magnitude. To further enhance efficiency, we propose constraint fusion to reduce the overhead of proving non-linear layers and circuit squeeze to improve parallelism. We implement our efficient protocol, specifically tailored for popular LLM architectures like GPT-2, and deploy optimizations to enhance performance. Experiments show that our scheme can prove GPT-2 inference in less than 25 seconds. Compared with state-of-the-art systems such as Hao et al. (USENIX Security'24) and ZKML (Eurosys'24), our work achieves nearly $279\times$ and $185\times$ speedup, respectively.
]]></content:encoded>
<pubDate>Tue, 24 Jun 2025 09:05:26 +0000</pubDate>
</item>
<item>
<title>Outsourced Cloud Data Privacy-Preserving Framework: An Efficient Broadcast Encrypted Search Realization</title>
<link>https://eprint.iacr.org/2024/761</link>
<guid>https://eprint.iacr.org/2024/761</guid>
<content:encoded><![CDATA[
The development of cloud networks facilitates data outsourcing, sharing, and storage, but it has also raised several security concerns. Public key authenticated encryption with keyword search (PAEKS) enables the encrypted search over cloud data while resisting the insider keyword guessing attacks (IKGAs). However, existing PAEKS schemes are limited to a single receiver, restricting application prospects in cloud networks. In addition, quantum computing attacks and key leakage issues further threaten data security, which has attracted extensive attention from researchers. Therefore, designing an encrypted search scheme to resist the above-mentioned attacks is still far-reaching. In this paper, we first propose BroSearch, an outsourced data privacy-preserving framework through efficient broadcast encrypted search for cloud networks. It utilizes lattice sampling algorithms to authenticate the keyword and offers searchability over broadcasting ciphertext while enjoying IKGAs-resistance in a quantum setting. To get around key leakage issues, we then incorporate the minimal cover set technique and lattice basis extension algorithm to construct FS-BroSearch as an enhanced version. Furthermore, we give a rigorous security analysis and a comprehensive performance evaluation of BroSearch and FS-BroSearch. Specifically, BroSearch consumes only 61.11%, 81.82%, and 83.33% of the execution time compared to prior art in terms of ciphertext calculation, trapdoor generation, and search procedures, which is practical and efficient in cloud networks.
]]></content:encoded>
<pubDate>Sat, 18 May 2024 08:23:59 +0000</pubDate>
</item>
<item>
<title>UOV-Based Verifiable Timed Signature Scheme</title>
<link>https://eprint.iacr.org/2025/1181</link>
<guid>https://eprint.iacr.org/2025/1181</guid>
<content:encoded><![CDATA[
Verifiable Timed Signatures (VTS) are cryptographic primitives that enable the creation of a signature that can only be retrieved after a specific time delay, while also providing verifiable evidence of its existence. This framework is particularly useful in blockchain applications. Current VTS schemes rely on signature algorithms such as BLS, Schnorr, and ECDSA, which are vulnerable to quantum attacks due to the vulnerability of the discrete logarithm problem to Shor's Algorithm. We introduce VT-UOV, a novel VTS scheme based on the Salt-Unbalanced Oil and Vinegar (Salt-UOV) Digital Signature Algorithm. As a multivariate polynomial-based cryptographic primitive, Salt-UOV provides strong security against both classical and quantum adversaries. Adapting Salt-UOV into the VTS framework requires addressing challenges such as complex parameters instead of a integer, the computational complexity of solving multivariate equations, and the integration of Time-Lock Puzzles (TLPs) for enforcing delayed signature generation. Our experimental results show that VT-UOV exhibits a unique performance profile among existing VTS constructions. This paper offers a detailed exploration of the VT-UOV scheme and its overall security and performance properties.
]]></content:encoded>
<pubDate>Mon, 23 Jun 2025 22:41:36 +0000</pubDate>
</item>
<item>
<title>Efficient Constant-Size Linkable Ring Signatures for Ad-Hoc Rings via Pairing-Based Set Membership Arguments</title>
<link>https://eprint.iacr.org/2025/1174</link>
<guid>https://eprint.iacr.org/2025/1174</guid>
<content:encoded><![CDATA[
Linkable Ring Signatures (LRS) allow users to anonymously sign messages on behalf of ad-hoc rings, while ensuring that multiple signatures from the same user can be linked. This feature makes LRS widely used in privacy-preserving applications like e-voting and e-cash. To scale to systems with large user groups, efficient schemes with short signatures and fast verification are essential. Recent works, such as DualDory (ESORICS’22) and LLRing (ESORICS’24), improve verification efficiency through offline precomputations but rely on static rings, limiting their applicability in ad-hoc ring scenarios. Similarly, constant-size ring signature schemes based on accumulators face the same limitation.

In this paper, we propose a framework for constructing constant-size LRS suitable for large ad-hoc rings. We introduce a novel pairing-based Set Membership Argument (SMA) with a proof size of only three group elements. By leveraging KZG polynomial commitments, we optimize the verification to require only constant group exponentiations and pairings, as well as linear field multiplications. Utilizing the SMA, our framework achieves constant-size signatures with verification dominated by linear field operations, outperforming existing schemes that require linear group exponentiations in ad-hoc ring settings. Moreover, it exhibits strong scalability: (i) compatibility with any PKI-based cryptosystem and (ii) scoped linkability, enabling flexible definitions of linking scope.

We instantiate our framework using a discrete logarithm public key structure. On the $BN254$ curve, our signature size is fixed at 687 bytes, which to our best knowledge is the shortest LRS for ring sizes larger than 32. For a ring size of 1024, our verification cost is only 10.4 ms, achieving 48.6×, 2.6×–467×, 7.9×–13.2×, and 2.2×–102.5× improvements over Omniring (CCS’19), DualDory (with and without precomputation), LLRing-DL (with and without precomputation), and LLRing-P (with and without precomputation), respectively. Moreover, this performance gap continues to grow as the ring size increases.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:18:42 +0000</pubDate>
</item>
<item>
<title>The Effectiveness of Differential Privacy in Real-world Settings:  A Metrics-based Framework to help Practitioners Visualise and Evaluate $\varepsilon$</title>
<link>https://eprint.iacr.org/2025/1173</link>
<guid>https://eprint.iacr.org/2025/1173</guid>
<content:encoded><![CDATA[
Differential privacy (DP) has emerged as a preferred solution for privacy-preserving data analysis, having been adopted by several leading Internet companies. DP is a privacy-preserving mechanism that protects against re-identification of individuals within aggregated datasets. It is known that the privacy budget $\varepsilon$ determines the trade-off between privacy and utility. In this paper, we propose the use of novel set of metrics and an easy-to-implement, step-by-step framework to facilitate the implementation of the DP mechanism on real-world datasets and guide the selection of $\varepsilon$ based on desired accuracy vs utility trade-off. Currently, for a given query there is no widely accepted methodology on how to select $\varepsilon$ and choose the best DP mechanism that offers an optimal trade-off between privacy and utility. In order to address this gap, we perform experiments by considering three real-world datasets, aiming to identify optimal $\varepsilon$ and suitable mechanisms (Laplace or Gaussian) based on privacy utility trade-off as per use case for the commonly used count, sum and average queries for each dataset. Based on our experiment results, we observe that using our metric and framework, one can analyse noise distribution charts of multiple queries, and choose the suitable $\varepsilon$ and the DP mechanism for achieving a balance between privacy and utility. Additionally, we show that the optimal $\varepsilon$ depends on the particular query, desired accuracy and context in which DP is implemented, which suggests that an arbitrary, a-prior selection of $\varepsilon$ cannot provide adequate results. Our framework prioritises the plotting and visualisation of values and results in the DP analysis, making its adoption easy for a wider audience.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:05:25 +0000</pubDate>
</item>
<item>
<title>Guarding the Signal: Secure Messaging with Reverse Firewalls</title>
<link>https://eprint.iacr.org/2025/1172</link>
<guid>https://eprint.iacr.org/2025/1172</guid>
<content:encoded><![CDATA[
Secure messaging protocols allow users to communicate asynchronously over untrusted channels with strong guarantees of privacy, authenticity, forward secrecy, and post-compromise security. However, traditional security analyses of these protocols assume complete trust in the hardware and software of honest participants, overlooking a significant class of real-world threats known as subversion attacks. These attacks alter cryptographic algorithms to compromise security, by exfiltrating secrets or creating vulnerabilities that are often undetected.

The notion of reverse firewalls (EC'15), aims at protecting against subversion attacks by introducing a third party, called a "reverse firewall" (RF), which sits between a party and the outside world and modifies its  outgoing and incoming messages in a way such that, even if the party's machine has been corrupted (in a way that maintains functionality), security is still preserved. Importantly, the firewall shares no private information with the parties, and parties put no more trust in the firewall than they do in the communication channel. In this work, we address the existing gap in secure messaging and subversion attacks by presenting several key contributions: 

- We design the first subversion-resilient secure messaging protocol based on the model of RF. Our protocol is based on the Signal protocol---the current state-of-the-art in two-party secure messaging, though it lacks subversion resilience---and achieves subversion resilience with only constant overhead over Signal. 

- We develop a subversion-resilient version of the X3DH protocol in the RF model. X3DH is a core component that facilitates secure initial key agreement in Signal's protocol. 

- We introduce and formalize the notion of Continuous Key Agreement with Tamper Detection, an essential concept for subversion-resilient secure messaging. Our notion enables parties to continuously agree on keys, even in the presence of active adversaries capable of partially tampering with the key exchange transcript. We present a construction of our notion and prove its subversion resilience in the model of RF.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 15:02:55 +0000</pubDate>
</item>
<item>
<title>SV-LLM: An Agentic Approach for SoC Security Verification using Large Language Models</title>
<link>https://eprint.iacr.org/2025/1162</link>
<guid>https://eprint.iacr.org/2025/1162</guid>
<content:encoded><![CDATA[
Ensuring the security of complex system-on-chips (SoCs) designs is a critical imperative, yet traditional verification techniques struggle to keep pace due to significant challenges in automation, scalability, comprehensiveness, and adaptability. The advent of large language models (LLMs), with their remarkable capabilities in natural language understanding, code generation, and advanced reasoning, presents a new paradigm for tackling these issues. Moving beyond monolithic models, an agentic approach allows for the creation of multi-agent systems where specialized LLMs collaborate to solve complex problems more effectively. Recognizing this opportunity, we introduce SV-LLM, a novel multi-agent assistant system designed to automate and enhance SoC security verification. By integrating specialized agents for tasks like verification question answering, security asset identification, threat modeling, test plan and property generation, vulnerability detection, and simulation-based bug validation, SV-LLM streamlines the workflow. To optimize their performance in these diverse tasks, agents leverage different learning paradigms, such as in-context learning, fine-tuning, and retrieval-augmented generation (RAG). The system aims to reduce manual intervention, improve accuracy, and accelerate security analysis, supporting proactive identification and mitigation of risks early in the design cycle. We demonstrate its potential to transform hardware security practices through illustrative case studies and experiments that showcase its applicability and efficacy.
]]></content:encoded>
<pubDate>Thu, 19 Jun 2025 11:52:33 +0000</pubDate>
</item>
<item>
<title>On Frontrunning Risks in Batch-Order Fair Systems for Blockchains (Extended Version)</title>
<link>https://eprint.iacr.org/2025/1168</link>
<guid>https://eprint.iacr.org/2025/1168</guid>
<content:encoded><![CDATA[
In timing-sensitive blockchain applications, such as decentralized finance (DeFi), achieving first-come-first-served (FCFS) transaction ordering among decentralized nodes is critical to prevent frontrunning attacks. Themis[CCS'23], a state-of-the-art decentralized FCFS ordering system, has become a key reference point for high-throughput fair ordering systems for real-world blockchain applications, such as rollup chains and decentralized sequencing, and has influenced the design of several subsequent proposals. In this paper, we critically analyze its core system property of practical batch-order fairness and evaluate the frontrunning resistance claim of Themis.  We present the Ambush attack, a new frontrunning technique that achieves nearly 100% success against the practical batch-order fair system with only a single malicious node and negligible attack costs. This attack causes a subtle temporary information asymmetry among nodes, which is allowed due to the heavily optimized communication model of the system. A fundamental trade-off we identify is a challenge in balancing security and performance in these systems; namely, enforcing timely dissemination of transaction information among nodes (to mitigate frontrunning) can easily lead to non-negligible network overheads (thus, degrading overall throughput performance). We show that it is yet possible to balance these two by delaying transaction dissemination to a certain tolerable level for frontrunning mitigation while maintaining high throughput. Our evaluation demonstrates that the proposed delayed gossiping mechanism can be seamlessly integrated into existing systems with only minimal changes.
]]></content:encoded>
<pubDate>Fri, 20 Jun 2025 07:01:16 +0000</pubDate>
</item>
<item>
<title>Bridging Bitcoin to Second Layers via BitVM2</title>
<link>https://eprint.iacr.org/2025/1158</link>
<guid>https://eprint.iacr.org/2025/1158</guid>
<content:encoded><![CDATA[
A holy grail in blockchain infrastructure is a trustless bridge between Bitcoin and its second layers or other chains. We make progress toward this vision by introducing the first light-client based Bitcoin bridge. At the heart of its design lies BitVM2-core, a novel paradigm that enables arbitrary program execution on Bitcoin, combining Turing-complete expressiveness with the security of Bitcoin consensus. BitVM2-bridge advances prior approaches by reducing the trust assumption from an honest majority (t-of-n) to existential honesty (1-of-n) during setup. Liveness is guaranteed with only one rational operator, and any user can act as a challenger, enabling permissionless verification. A production-level implementation of BitVM2 has been developed and a full challenge verification has been executed on the Bitcoin mainnet.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 20:55:16 +0000</pubDate>
</item>
<item>
<title>Privacy-aware White and Black List Searching for Fraud Analysis</title>
<link>https://eprint.iacr.org/2025/1153</link>
<guid>https://eprint.iacr.org/2025/1153</guid>
<content:encoded><![CDATA[
In many areas of cybersecurity, we require access to Personally Identifiable Information (PII), such as names, postal addresses and email addresses. Unfortunately, this can lead to data breaches, especially in relation to data compliance regulations such as GDPR. An Internet Protocol (IP) address is an identifier that is assigned to a networked device to enable it to communicate over networks that use IP. Thus, in applications which are privacy-aware, we may aim to hide the IP address while aiming to determine if the address comes from a blacklist. One solution to this is to use homomorphic encryption to match an encrypted version of an IP address to a blacklisted network list. This matching allows us to encrypt the IP address and match it to an encrypted version of a blacklist. In this paper, we use the OpenFHE library \cite{OpenFHE} to encrypt network addresses with the BFV homomorphic encryption scheme. In order to assess the performance overhead of BFV, we implement a matching method using the OpenFHE library and compare it against partial homomorphic schemes, including Paillier, Damgard-Jurik, Okamoto-Uchiyama, Naccache-Stern and Benaloh. The main findings are that the BFV method compares favourably against the partial homomorphic methods in most cases.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 12:06:56 +0000</pubDate>
</item>
<item>
<title>ZK-ProVer: Proving Programming Verification in Non-Interactive Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/1152</link>
<guid>https://eprint.iacr.org/2025/1152</guid>
<content:encoded><![CDATA[
Program verification ensures software correctness through formal methods but incurs substantial computational overhead. It typically encodes program execution into formulas that are verified using a SAT solver and its extensions. However, this process exposes sensitive program details and requires redundant computations when multiple parties need to verify correctness. To overcome these limitations, zero-knowledge proofs (ZKPs) generate compact, reusable proofs with fast verification times, while provably hiding the program’s internal logic. We propose a two-phase zero-knowledge protocol that hides program implementation details throughout verification. Phase I uses a zero-knowledge virtual machine (zkVM) to encode programs into SAT formulas without
revealing their semantics. Phase II employs the encoding of resolution proofs for UNSAT instances and circuits for satisfying assignment verification for SAT instances through PLONKish circuits. Evaluation on the Boolector benchmark demonstrates that our method achieves verification time that is efficient and is independent of clause width for UNSAT instances and formula size for SAT instances. The resulting ZKPs enable efficient verification of program properties while providing strong end-to-end privacy guarantees.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 11:45:40 +0000</pubDate>
</item>
<item>
<title>Lightweight Sorting in Approximate Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/1150</link>
<guid>https://eprint.iacr.org/2025/1150</guid>
<content:encoded><![CDATA[
Sorting encrypted values is an open research problem that plays a crucial role in the broader objective of providing efficient and practical privacy-preserving online services. 
The current state of the art work by Mazzone, Everts, Hahn and Peter (USENIX Security '25) proposes efficient algorithms for ranking, indexing and sorting based on the CKKS scheme, which deviates from the compare-and-swap paradigm, typically used by sorting networks, using a permutation-based approach. This allows to build shallow sorting circuits in a very simple way.
In this work, we follow up their work and explore different approaches to approximate the nonlinear functions required by the encrypted circuit (where only additions and multiplications can be evaluated), and we propose simpler solutions that allow for faster computations and smaller memory requirements. 

In particular, we drastically reduce the upper bound on the depth of the circuits from 65 to 20, making our circuits usable in relatively small rings such as $N=2^{16}$, even for sorting values while preserving up to three decimal places. As an example, our circuit sorts 128 values with duplicates in roughly 20 seconds on a laptop, using roughly 1 GB of memory, maintaining a precision of 0.01.
Furthermore, we propose an implementation of a swap-based bitonic network that is not based on approximations of the sgn$(x)$ function, which scales linearly with the number of values, useful when the number of available slots is small.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 11:01:28 +0000</pubDate>
</item>
<item>
<title>Jigsaw: Doubly Private Smart Contracts</title>
<link>https://eprint.iacr.org/2025/1147</link>
<guid>https://eprint.iacr.org/2025/1147</guid>
<content:encoded><![CDATA[
Privacy is a growing concern for smart contracts on public ledgers. 
In recent years, we have seen several practical systems for privacy-preserving smart contracts, but they only target privacy of on-chain data, and rely on trusted off-chain parties with user data -- for instance, a decentralized finance application (e.g. exchange) relies on an off-chain matching engine to process client orders that get settled on-chain, where privacy only applies to the on-chain data.
Privacy conscious users demand stronger notions of privacy, for their identity and their data, from all other parties in the ecosystem.

We propose a novel framework for smart contracts that ensures {\em doubly private}
execution, addressing {both on-chain and off-chain privacy} requirements. 
In our framework, clients submit their requests in a privacy-preserving manner to a group of (potentially mutually untrusting) servers. These servers collaboratively match client requests without learning any information about the data or identities of the clients.

We then present {\em Jigsaw}, an efficient cryptographic realization of our proposed framework. {\em Jigsaw} builds on the ZEXE architecture (Bowe et al., S\&amp;P 2020), which leverages zkSNARKs, and extends Collaborative zkSNARKs (Ozdemir and Boneh, USENIX 2022) to enable proof generation by a group of servers.

In Jigsaw, we introduce a novel collaborative zkSNARK construction that achieves low latency and reduced proving time, and showcase these advantages over sample applications ranging from trading in a decentralized exchange to auctions and voting.
Our experiments demonstrate that {\em Jigsaw} is roughly $40-50$x faster in proof generation and uses orders-of-magnitude less bandwidth than the naive approach of using off-the-shelf Collaborative zkSNARKs.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 04:31:56 +0000</pubDate>
</item>
<item>
<title>QV-net: Decentralized Self-Tallying Quadratic Voting with Maximal Ballot Secrecy</title>
<link>https://eprint.iacr.org/2025/1146</link>
<guid>https://eprint.iacr.org/2025/1146</guid>
<content:encoded><![CDATA[
Decentralized e-voting enables secure and transparent elections without relying on trusted authorities, with blockchain emerging as a popular platform. It has compelling applications in Decentralized Autonomous Organizations (DAOs), where governance relies on voting with blockchain-issued tokens. Quadratic voting (QV), a mechanism that mitigates the dominance of large token holders, has been adopted by many DAO elections to enhance fairness. However, current QV systems deployed in practice publish voters' choices in plaintext with digital signatures. The open nature of all ballots comprises voter privacy, potentially affecting voters' honest participation. Prior research proposes using cryptographic techniques to encrypt QV ballots, but they work in a centralized setting, relying on a trusted group of tallying authorities to administrate an election. However, in DAO voting, there is no trusted third party.   

In this paper, we propose QV Network (QV-net), the first decentralized quadratic voting scheme, in which voters do not need to trust any third party other than themselves for ballot secrecy. QV-net is self-tallying with maximal ballot secrecy. Self-tallying allows anyone to compute election results once all ballots are cast. Maximal ballot secrecy ensures that what each voter learns from QV-net is nothing more than the tally and their own ballot. We provide an open-source implementation of QV-net to demonstrate its practicality based on real-world DAO voting settings, reporting only a few milliseconds for voting and a maximum of 255 milliseconds for tallying.

The exceptional efficiency of QV-net is attributed to the design of two new Zero-Knowledge Argument of Knowledge (ZKAoK) protocols for QV ballot secrecy and integrity. Previous works generally rely on pairing-friendly curves to prove the well-formedness of an encrypted QV ballot. But they incur heavy computation and large data sizes. We tackle the challenges of appropriately formalizing and proving ZKAoK relations for QV without using these curves. Specifically, we develop a succinct ZKAoK to prove a new relation: the sum of squares of a private vector's components equals a private scalar. We also introduce the first aggregated range proof to prove that values committed under different keys fall within their respective ranges. Together, these two new zero-knowledge protocols enable us to build an efficient decentralized QV scheme and are of independent interest.
]]></content:encoded>
<pubDate>Wed, 18 Jun 2025 03:10:46 +0000</pubDate>
</item>
<item>
<title>Dynamic Group Signatures with Verifier-Local Revocation</title>
<link>https://eprint.iacr.org/2025/1145</link>
<guid>https://eprint.iacr.org/2025/1145</guid>
<content:encoded><![CDATA[
Group Signatures are fundamental cryptographic primitives that allow users to sign a message on behalf of a predefined set of users, curated by the group manager. The security properties ensure that members of the group can sign anonymously and without fear of being framed. In dynamic group signatures, the group manager has finer-grained control over group updates while ensuring membership privacy (i.e., hiding when users join and leave). The only known scheme that achieves standard security properties and membership privacy has been proposed by Backes et al. CCS 2019. However, they rely on an inefficient revocation mechanism that re-issues credentials to all active members during every group update, and users have to rely on a secure and private channel to join the group.
In this paper, we introduce a dynamic group signature that supports verifier-local revocation, while achieving strong security properties, including membership privacy for users joining over a public channel. Moreover, when our scheme is paired with structure-preserving signatures over equivalence class it enjoys a smaller signature size compared to Backes et al. Finally, as a stand-alone contribution we extend the primitive Asynchronous Remote Key Generation (Frymann et al. CCS 2020) with trapdoors and introduce new security properties to capture this new functionality, which is fundamental to the design of our revocation mechanism
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 22:51:47 +0000</pubDate>
</item>
<item>
<title>Parasol Compiler: Pushing the Boundaries of FHE Program Efficiency</title>
<link>https://eprint.iacr.org/2025/1144</link>
<guid>https://eprint.iacr.org/2025/1144</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption (FHE) is a key technology to enable privacy-preserving computation. While optimized FHE implementations already exist, the inner workings of FHE are technically complex. This makes it challenging, especially for non-experts, to develop highly-efficient FHE programs that can exploit the advanced hardware of today. Although several compilers have emerged to help in this process, due to design choices, they are limited in terms of application support and the efficiency levels they can achieve.

In this work, we showcase how to make FHE accessible to non-expert developers while retaining the performance provided by an expert-level implementation. We introduce Parasol, a novel end-to-end compiler encompassing a virtual processor with a custom Instruction Set Architecture (ISA) and a low-level library that implements FHE operations. Our processor integrates with existing compiler toolchains, thereby providing mainstream language support. We extract parallelism at multiple levels via our processor design and its computing paradigm. Specifically, we champion a Circuit Bootstrapping (CBS)-based paradigm, enabling efficient FHE circuit composition with multiplexers. Furthermore, Parasol’s underlying design highlights the benefits of expressing FHE computations at a higher level—producing highly compact program representations. Our experiments demonstrate the superiority of Parasol, in terms of runtime (up to 17x faster), program size (up to 22x smaller), and compile time (up to 32x shorter) compared to the current state-of-the-art. We expect the FHE computing paradigm underlying Parasol to attract future interest since it exposes added parallelism for FHE accelerators to exploit.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 18:51:55 +0000</pubDate>
</item>
<item>
<title>LZKSA: Lattice-Based Special Zero-Knowledge Proofs for Secure Aggregation's Input Verification</title>
<link>https://eprint.iacr.org/2025/1141</link>
<guid>https://eprint.iacr.org/2025/1141</guid>
<content:encoded><![CDATA[
In many fields, the need to securely collect and aggregate data from distributed systems is growing. However, designs that rely solely on encrypted data transmission make it difficult to trace malicious users. To address this challenge, we have enhanced the secure aggregation (SA) protocol proposed by Bell et al. (CCS 2020) by introducing verification features that ensure compliance with user inputs and encryption processes while preserving data privacy. We present LZKSA, a quantum-safe secure aggregation system with input verification. LZKSA employs seven zero-knowledge proof (ZKP) protocols based on the Ring Learning with Errors problem, specifically designed for secure aggregation. These protocols verify whether users have correctly used SA keys and their $L_{\infty}$, $L_2$ norms and cosine similarity of data, meet specified constraints, to exclude malicious users from current and future aggregation processes. The specialized ZKPs we propose significantly enhance proof efficiency. In practical federated learning scenarios, our experimental evaluations demonstrate that the proof generation time for $L_{\infty}$ and $L_2$ constraints is reduced to about $10^{-3}$ of that required by the current state-of-the-art method, RoFL (S\&amp;P 2023), and ACORN (USENIX 2023). For example, the proof generation/verification time of RoFL, ACORN and LZKSA for $L_{\infty}$ is 94s/29.9s, 78.7s/33.9s, and 0.02s/0.0062s for CIFAR10, respectively.
]]></content:encoded>
<pubDate>Tue, 17 Jun 2025 04:11:00 +0000</pubDate>
</item>
<item>
<title>ZK-NR: A Layered Cryptographic Architecture for  Explainable Non-Repudiation</title>
<link>https://eprint.iacr.org/2025/1138</link>
<guid>https://eprint.iacr.org/2025/1138</guid>
<content:encoded><![CDATA[
This paper introduces ZK-NR, a modular cryptographic protocol designed to ensure privacy-preserving non-repudiation in the co-production of digital public services. By integrating Merkle commitments, zero-knowledge proofs (STARKs), threshold BLS signatures, and post-quantum Dilithium authentication, ZK-NR enables the creation of secure, verifiable, and auditable evidence across decentralized infrastructures. Unlike traditional digital signatures or blockchain-based logs, ZK-NR provides formally verifiable attestations without disclosing sensitive content, making it suitable for public finance, e-government, and regulated digital ecosystems. The protocol is modeled in Tamarin and implemented as a proof-of-concept using open cryptographic tools. This contribution offers a reproducible foundation for future infrastructures requiring long-term trust, data minimization, and legal admissibility, particularly in contexts where citizens and institutions share responsibility for digital evidence. ZK-NR addresses the tension between confidentiality and accountability, providing an interoperable and future-ready layer for trustworthy public service delivery.
This preliminary work focuses on architectural composition and implementation feasibility. It does not include formal security proofs.
]]></content:encoded>
<pubDate>Mon, 16 Jun 2025 19:55:21 +0000</pubDate>
</item>
<item>
<title>Succinct Computational Secret Sharing</title>
<link>https://eprint.iacr.org/2023/955</link>
<guid>https://eprint.iacr.org/2023/955</guid>
<content:encoded><![CDATA[
A secret-sharing scheme enables a dealer to share a secret $s$ among $n$ parties such that only authorized subsets of parties, specified by a monotone access structure $f:\{0,1\}^n\to\{0,1\}$, can reconstruct $s$ from their shares. Other subsets of parties learn nothing about $s$.

The question of minimizing the (largest) share size for a given $f$ has been the subject of a large body of work. However, in most existing constructions for general access structures $f$, the share size is not much smaller than the size of some natural computational representation of $f$, a fact that has often been referred to as the ``representation size barrier'' in secret sharing.

In this work, we initiate a systematic study of succinct computational  secret sharing (SCSS), where the secrecy requirement is computational and the goal is to substantially beat the representation size barrier. We obtain the following main results.

(1) SCSS via Projective PRGs. We introduce the notion of a *projective PRG*, a pseudorandom generator for which any subset of the output bits can be revealed while keeping the other output bits hidden, using a *short* projective seed. We construct projective PRGs with different levels of succinctness under a variety of computational assumptions, and apply them towards constructing SCSS for graph access structures, monotone CNF formulas, and (less succinctly) useful subclasses of monotone circuits and branching programs. Most notably, under the sub-exponential RSA assumption, we obtain a SCSS scheme that, given an arbitrary access structure $f$, represented by a truth table of size $N=2^n$, produces shares of size polylog(N)=\poly(n) in time $\tilde O(N)$. For comparison, the share size of the best known information-theoretic schemes is $O(N^{0.58})$.

(2) SCSS via One-way Functions. Under the (minimal) assumption that one-way functions exist, we obtain a near-quadratic separation between the total share size of computational and information-theoretic secret sharing. This is the strongest separation one can hope for, given the state of the art in secret sharing lower bounds. We also construct SCSS schemes from one-way functions for useful classes of access structures, including forbidden graphs and monotone DNF formulas.  This leads to constructions of fully-decomposable conditional disclosure of secrets (also known as privacy-free garbled circuits) for general functions, represented by a truth table of size $N=2^n$, with share size polylog(N) and computation time $\tilde O(N)$, assuming sub-exponentially secure one-way functions.
]]></content:encoded>
<pubDate>Sun, 18 Jun 2023 17:33:05 +0000</pubDate>
</item>
<item>
<title>Reusable Designated Verifier NIZK from Lossy Trapdoor Functions</title>
<link>https://eprint.iacr.org/2025/1125</link>
<guid>https://eprint.iacr.org/2025/1125</guid>
<content:encoded><![CDATA[
Understanding the minimal assumptions necessary for constructing non-interactive zero-knowledge arguments (NIZKs) for NP and placing it within the hierarchy of cryptographic primitives has been a central goal in cryptography. Unfortunately, there are very few examples of ``generic'' constructions of NIZKs or any of its natural relaxations.

In this work, we consider the relaxation of NIZKs to the designated-verifier model (DV-NIZK) and present a new framework for  constructing (reusable) DV-NIZKs for NP generically from  lossy trapdoor functions and PRFs computable by polynomial-size branching programs (a class that includes NC1). Previous ``generic'' constructions  of DV-NIZK for NP from standard primitives relied either on (doubly-enhanced) trapdoor permutations or on a public-key encryption scheme plus a KDM-secure secret key encryption scheme.

Notably, our DV-NIZK framework achieves statistical zero-knowledge. To our knowledge, this is the first DV-NIZK construction from any ``generic" standard assumption with statistical zero-knowledge that does not already yield a NIZK. 

A key technical component of our construction is an efficient, unconditionally secure secret sharing scheme for non-monotone functions with randomness recovery for all polynomial-size branching programs. As an independent contribution we present an incomparable randomness recoverable (monotone) secret sharing for NC1 in a model with trusted setup that guarantees computational privacy assuming one-way functions. We believe that these primitives will be useful in related contexts in the future.
]]></content:encoded>
<pubDate>Sat, 14 Jun 2025 17:30:36 +0000</pubDate>
</item>
<item>
<title>Toxic Decoys: A Path to Scaling Privacy-Preserving Cryptocurrencies</title>
<link>https://eprint.iacr.org/2025/1124</link>
<guid>https://eprint.iacr.org/2025/1124</guid>
<content:encoded><![CDATA[
Anonymous cryptocurrencies attracted much attention over the past decade, yet ensuring both integrity and privacy in an open system remains challenging. Their transactions preserve privacy because they do not reveal on which earlier transaction they depend, specifically which outputs of previous transactions are spent. However, achieving privacy imposes a significant storage overhead due to two current limitations. First, the set of potentially unspent outputs of transactions grows indefinitely because the design hides cryptographically which one have been consumed; and, second, additional data must be stored for each spent output to ensure integrity, that is, to prevent that it can be spent again. We introduce a privacy-preserving payment scheme that mitigates these issues by randomly partitioning unspent outputs into fixed-size bins. Once a bin has been referenced in as many transactions as its size, it is pruned from the ledger. This approach reduces storage overhead while preserving privacy. We first highlight the scalability benefits of using smaller untraceability sets instead of considering the entire set of outputs, as done in several privacy-preserving cryptocurrencies. We then formalize the security and privacy notions required for a scalable, privacy-preserving payment system and analyze how randomized partitioning plays a key role in both untraceability and scalability. To instantiate our approach, we provide constructions based on Merkle trees and one based on cryptographic accumulators. We finally show the storage benefits of our scheme and analyze its resilience against large-scale flooding attacks using empirical transaction data.
]]></content:encoded>
<pubDate>Sat, 14 Jun 2025 16:52:16 +0000</pubDate>
</item>
<item>
<title>Strong Secret Sharing with Snitching</title>
<link>https://eprint.iacr.org/2025/1119</link>
<guid>https://eprint.iacr.org/2025/1119</guid>
<content:encoded><![CDATA[
One of the main shortcomings of classical distributed cryptography is its reliance on a certain fraction of participants remaining honest. Typically, honest parties are assumed to follow the protocol and not leak any information, even if behaving dishonestly would benefit them economically. More realistic models used in blockchain consensus rely on weaker assumptions, namely that no large coalition of corrupt parties exists, although every party can act selfishly. This is feasible since, in a consensus protocol, active misbehavior can be detected and "punished" by other parties. However, "information leakage", where an adversary reveals sensitive information via, e.g., a subliminal channel, is often impossible to detect and, hence, much more challenging to handle.

    A recent approach to address this problem was proposed by Dziembowski, Faust, Lizurej, and Mielniczuk (ACM CCS 2024), who introduced a new notion called secret sharing with snitching. This primitive guarantees that as long as no large coalition of mutually trusting parties exists, every leakage of the shared secret produces a "snitching proof" indicating that some party participated in the illegal secret reconstruction. This holds in a very strong model, where mutually distrusting parties use an MPC protocol to reconstruct any information about the shared secret. Such a "snitching proof" can be sent to a smart contract (modeled as a "judge") deployed on the blockchain, which punishes the aving party financially.

    In this paper, we extend the results from the work of CCS'24  by addressing its two main shortcomings. Firstly, we significantly strengthen the attack model by considering the case when mutually distrusting parties can also rely on a trusted third party (e.g., a smart contract). We call this new primitive strong secret sharing with snitching (SSSS). 
    We present an SSSS protocol that is secure in this model. Secondly, unlike in the construction from CCS'24, our protocol does not require the honest parties to perform any MPC computations on hash functions. Besides its theoretical interest, this improvement is of practical importance, as it allows the construction of SSSS from any (even very "MPC-unfriendly") hash function.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 16:06:13 +0000</pubDate>
</item>
<item>
<title>The Pipes Model for Latency Analysis</title>
<link>https://eprint.iacr.org/2025/1116</link>
<guid>https://eprint.iacr.org/2025/1116</guid>
<content:encoded><![CDATA[
Protocols for State-Machine-Replication (sometimes called 'blockchain' protocols)  generally make use of rotating leaders to drive consensus. In typical protocols (henceforth called 'single-sender' protocols), the leader is a single processor responsible for making and disseminating proposals to others. Since the leader acts as a bottleneck, apparently limiting throughput, a recent line of research has investigated the use of 'multi-sender' protocols in which many processors distribute proposals in parallel. Examples include DAG-based protocols such as DAG-Rider, Bullshark, Sailfish, Cordial Miners, Mysticeti, and variants such as Autobahn. However, existing models do not allow for a formal analysis to determine whether these protocols can actually handle higher throughputs than single-sender protocols such as PBFT, Tendermint, and HotStuff.

In this paper, we describe a very simple model that allows for such an analysis. For any given protocol, the model allows one to calculate latency as a function of  network bandwidth, network delays, the number of processors $n$, and the incoming transaction rate. Each protocol has a latency bottleneck: an incoming transaction rate at which latency becomes unbounded over the protocol execution, i.e., a maximum throughput that the protocol can handle without unbounded latency.  

With the aim of building to an analysis for state-of-the-art State-Machine-Replication (SMR) protocols, we begin by considering protocols for simpler primitives, such as Best-effort Broadcast and Reliable Broadcast. For Best-effort Broadcast, we establish a tight lower bound on latency for single-sender and multi-sender protocols when blocks are distributed without the use of techniques such as erasure coding. Perhaps unsurprisingly, a key difference between the single-sender and multi-sender approaches in this case is a factor $n$ in the point at which the latency bottleneck appears. However, for other primitives such as Reliable Broadcast,  our results may be more surprising: the factor $n$ difference now disappears, and maximum throughput for the two approaches differs by a constant factor, while multi-sender approaches will generally have latency that grows more quickly with $n$. For state-of-the-art SMR protocols, the picture that emerges is one with seemingly inherent trade-offs. If one compares single-sender protocols that use pipelining and erasure coding, such as DispersedSimplex, with DAG-based protocols such as Sailfish or Bullshark, the former are seen to have lower latency for a wide range of throughputs, while the benefit of the latter protocols is that they have  a latency bottleneck which is higher by a constant factor.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 13:42:36 +0000</pubDate>
</item>
<item>
<title>High-Throughput Permissionless Blockchain Consensus under   Realistic Network Assumptions</title>
<link>https://eprint.iacr.org/2025/1115</link>
<guid>https://eprint.iacr.org/2025/1115</guid>
<content:encoded><![CDATA[
Throughput, i.e., the amount of payload data processed per unit of
  time, is a crucial measure of scalability for blockchain consensus
  mechanisms.  This paper revisits the design of secure,
  high-throughput proof-of-stake (PoS) protocols in the
  \emph{permissionless} setting.  Existing high-throughput protocols
  are either analyzed using overly simplified network models or are
  designed for permissioned settings, with the task of adapting them
  to a permissionless environment while maintaining both scalability
  and adaptive security (which is essential in permissionless
  environments) remaining an open question. 

  Two particular challenges arise when designing high-throughput
  protocols in a permissionless setting: \emph{message bursts}, where
  the adversary simultaneously releases a large volume of withheld
  protocol messages, and---in the PoS setting---\emph{message
    equivocations}, where the adversary diffuses arbitrarily many
  versions of a protocol message.  It is essential for the security of
  the ultimately deployed protocol that these issues be captured by
  the network model.

  Therefore, this work first introduces a new, realistic network model
  based on the operation of real-world gossip networks---the standard
  means of diffusion in permissionless systems, which may involve
  many thousands of nodes.  The model specifically addresses challenges
  such as message bursts and PoS equivocations and is also of
  independent interest.

  The second and main contribution of this paper is Leios, a
  blockchain protocol that transforms any underlying low-throughput
  base protocol into a blockchain achieving a throughput corresponding
  to a $(1-\delta)$-fraction of the network capacity---while affecting
  latency only by a related constant.  In particular, if the
  underlying protocol has constant expected settlement time, this
  property is retained under the Leios overlay.  Combining Leios with
  any permissionless protocol yields the first near-optimal throughput
  permissionless ``layer-1'' blockchain protocol proven secure under
  realistic network assumptions.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 12:31:55 +0000</pubDate>
</item>
<item>
<title>Sassafras: Efficient Batch Single Leader Election</title>
<link>https://eprint.iacr.org/2023/031</link>
<guid>https://eprint.iacr.org/2023/031</guid>
<content:encoded><![CDATA[
In a single secret leader election (SSLE), a set of participants elect exactly one leader, who remains anonymous until they announce themselves by providing a proof. SSLE protocols are used in proof-of-stake blockchains to elect the leader who publishes the next block. Anonymity of the leader is an important security property, as the leader makes for an attractive target and may be subject to denial-of-service (DOS) attacks.

In this work, we propose a novel single leader election protocol, called Sassafras. We depart from the common approach of shuffling for constructing SSLE and instead employ a ring verifiable random function, which hides the identity of the leader within a ring of participants. Moreover, Sassafras is designed for batch leader elections, in which a single leader is selected for several elections at once. This allows the rate of leader election to match the rate of block production, an often-sought property not met by most SSLE protocols in the literature. We characterize single leader election with batching in the form of an ideal functionality in the Universal Composability (UC) framework and prove that Sassafras realizes this functionality. Sassafras is secure against an adaptive adversary, while achieving a slightly relaxed notion of anonymity for leaders. Sassafras features exceptionally low communication and computational complexity, outperforming other SSLE protocols by an order of magnitude or more.
]]></content:encoded>
<pubDate>Tue, 10 Jan 2023 11:55:15 +0000</pubDate>
</item>
<item>
<title>SEAF: Secure Evaluation on Activation Functions with Dynamic Precision for Secure Two-Party Inference</title>
<link>https://eprint.iacr.org/2025/1111</link>
<guid>https://eprint.iacr.org/2025/1111</guid>
<content:encoded><![CDATA[
Secure evaluation of non-linear functions is one of the most expensive operations in secure two-party computation, particularly for activation functions in privacy preserving machine learning (PPML). This work introduces SEAF, a novel framework for efficient Secure Evaluation on Activation Functions. SEAF is based on the linear approximation approach, but enhances it by introducing two key innovations: Trun-Eq based interval test protocols and linear approximation with dynamic precision, which have the potential for broader applicability. Furthermore, we classify common activation functions into several categories, and present specialized methods to evaluate them using our enhanced techniques. Our implementation of SEAF demonstrates $3.5 \times$ to $5.9 \times$ speedup on activation functions $\mathsf{Tanh}$ and $\mathsf{Sigmoid}$ compared to SirNN (S\&amp;P'21). When applied on $\mathsf{GELU}$, SEAF outperforms Iron (NeurIPS'22) by more than $10 \times$ and Bolt (S\&amp;P'24) by up to $3.4 \times$. For end-to-end secure inference on BERT, the original $\mathsf{GELU}$ accounts for $31.3 \%$ and $22.5 \%$ of the total runtime in Iron and Bolt, respectively. In contrast, our optimized $\mathsf{GELU}$ reduces these proportions to  $4.3 \%$ and $9.8 \%$, eliminating $\mathsf{GELU}$ as a bottleneck in secure inference.
]]></content:encoded>
<pubDate>Fri, 13 Jun 2025 02:32:35 +0000</pubDate>
</item>
<item>
<title>TEEMS: A Trusted Execution Environment based Metadata-protected Messaging System</title>
<link>https://eprint.iacr.org/2025/1102</link>
<guid>https://eprint.iacr.org/2025/1102</guid>
<content:encoded><![CDATA[
Ensuring privacy of online messaging remains a challenge.  While the contents or data of online communications are often protected by end-to-end encryption, the metadata of communications are not.  Metadata such as who is communicating with whom, how much, and how often, are leaked by popular messaging systems today.

In the last four decades we have witnessed a rich literature of designs towards metadata-protecting communications systems (MPCS).  While recent MPCS works often target metadata-protected messaging systems, no existing construction simultaneously attains four desirable properties for messaging systems, namely (i) low latency, (ii) high throughput, (iii) horizontal scalability, and (iv) asynchronicity.  Existing designs often capture disjoint subsets of these properties.  For example, PIR-based approaches achieve low latency and asynchronicity but have low throughput and lack horizontal scalability, mixnet-based approaches achieve high throughput and horizontal scalability but lack asynchronicity, and approaches based on trusted execution environments (TEEs) achieve high throughput and asynchronicity but lack horizontal scalability.

In this work, we present TEEMS, the first MPCS designed for metadata-protected messaging that simultaneously achieves all four desirable properties. Our distributed TEE-based system uses an oblivious mailbox design to provide metadata-protected messaging.  TEEMS presents novel oblivious routing protocols that adapt prior work on oblivious distributed sorting.  Moreover, we introduce the notion of ID and token channels to circumvent shortcomings of prior designs.  We empirically demonstrate TEEMS' ability to support $2^{20}$ clients engaged in metadata-protected conversations in under 1 s, with 205 cores, achieving an 18× improvement over prior work for latency and throughput, while supporting significantly better scalability and asynchronicity properties.
]]></content:encoded>
<pubDate>Thu, 12 Jun 2025 11:45:28 +0000</pubDate>
</item>
<item>
<title>Tanuki: New Frameworks for (Concurrently Secure) Blind Signatures from Post-Quantum Groups Actions</title>
<link>https://eprint.iacr.org/2025/1100</link>
<guid>https://eprint.iacr.org/2025/1100</guid>
<content:encoded><![CDATA[
Blind signatures are fundamental cryptographic primitives enabling privacy-preserving authentication and have seen renewed interest in the post-quantum literature. 
Existing efficient constructions predominantly rely on Fischlin’s generic paradigm instantiated over lattice assumptions, while blinding techniques for sigma-protocol-based blind signatures remain sparse beyond lattices. Moreover, achieving provable concurrent security under polynomially many sessions has been a longstanding open challenge for this approach in the post-quantum literature as evidenced by the recent attacks in EC’24 and PKC’24. 


This work broadens the landscape of post-quantum blind signatures by introducing novel techniques and proposing four frameworks based on general cryptographic group actions, without requiring commutativity. Our constructions admit instantiations under diverse post-quantum assumptions, including CSIDH (isogeny-based), LESS (code-based, NIST round-two), and more. These frameworks offer flexible trade-offs in assumptions (from interactive one-more to the standard inversion problem) and key/signature sizes, and culminate in a construction that achieves security under polynomially many concurrent sessions. This enables the first efficient blind signatures from isogenies and codes with provable concurrent security with 3.9 and 56 KB respectively. We also outline several directions for optimization and further instantiations for future work.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 21:02:16 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Accumulator and Application to Anonymous Credential Revocation</title>
<link>https://eprint.iacr.org/2025/1099</link>
<guid>https://eprint.iacr.org/2025/1099</guid>
<content:encoded><![CDATA[
An accumulator is a cryptographic system for compactly representing a set of elements such that every element in the set has a short membership witness. A dynamic accumulator, furthermore, allows elements to be added to and deleted from the accumulator.  Camenisch and Lysyanskaya (CRYPTO'02) constructed the first dynamic accumulator under the strong-RSA assumption and showed how it can be used to enable revocation of anonymous credentials.  In this paper, we give a lattice-based dynamic accumulator tailor-made for enabling revocation of post-quantum anonymous credential systems. As a concrete example, we instantiate our dynamic accumulator on top of the anonymous credential system implemented in the LaZer library (ACM CCS 2024).
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 20:34:27 +0000</pubDate>
</item>
<item>
<title>CuFDFB: Fast and Private Computation on Non-Linear Functions Using FHE</title>
<link>https://eprint.iacr.org/2025/1096</link>
<guid>https://eprint.iacr.org/2025/1096</guid>
<content:encoded><![CDATA[
Privacy-preserving neural network inference using Fully Homomorphic Encryption (FHE) faces significant challenges in efficiently evaluating non-polynomial functions, such as activation functions, which are critical for introducing non-linearity in neural networks. Full-Domain Functional Bootstrap (FDFB) algorithms provide a promising solution by enabling the evaluation of arbitrary functions while simultaneously refreshing ciphertexts to manage noise accumulation. Despite their theoretical advantages, the practicality of FDFB algorithms has been limited by excessive computational overhead, often exceeding 1000 ms per ciphertext, which restricts their scalability for large neural networks.

To overcome the computational bottlenecks of FDFB, we have re-engineered the algorithms for massively parallel execution on GPUs. Our primary contribution is a hierarchical parallelization strategy that exploits concurrency at the thread, stream, and device levels. A key optimization involves the use of CUDA streams to create a data pipeline that effectively mitigates the overhead of memory transfers between the host and device. This optimized architecture achieves a significant speedup of up to 524$\times$ compared to CPU-based implementations. Our implementation maintains full precision for evaluating various activation functions, confirming its viability for large-scale, privacy-preserving machine learning tasks and paving the way for practical FHE-based deep learning.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 15:47:28 +0000</pubDate>
</item>
<item>
<title>On the Concrete Security of BBS/BBS+ Signatures</title>
<link>https://eprint.iacr.org/2025/1093</link>
<guid>https://eprint.iacr.org/2025/1093</guid>
<content:encoded><![CDATA[
BBS/BBS+ signatures are the most promising solution to instantiate practical and lightweight anonymous credentials. They underlie standardization efforts by the W3C and the IRTF. Due to their potential for large scale deployment, it is paramount to understand their concrete security, but a number of questions have been left open by prior works. To this end, the security proofs by Au et al. (SCN '06), Camenisch et al. (TRUST '16), and Tessaro and Zhu (EUROCRYPT '23) show reductions from $q$-SDH in groups of prime order $p$, where $q$ is the number of issued signatures. 
    
    However, these prior works left the possibility open that BBS/BBS+ is "even more secure" than what can be guaranteed by such proofs. Indeed, while the $q$-SDH assumption is subject to an attack that uses $O(\sqrt{p/q})$ group exponentiations (Cheon, EUROCRYPT '06) for several choices of $q$, no attack with a similar complexity appears to affect either of BBS+ and "deterministic" BBS, for which the best known attacks amount to recovering the secret key by breaking the discrete logarithm problem. The assumption that this attack is best possible also seemingly justifies the choice of parameters in practice.

    Our result shows that this expectation is not true. We show new attacks against BBS+ and deterministic BBS which, after seeing $q$ signatures, allow us to recover the secret key with the same complexity as solving the $\Theta(q)$-Discrete Logarithm problem, which in turn is proportional to $O(\sqrt{p/q})$ for many choices of $q$. Further, we also extend the attack to a reduction showing that the security of BBS+ and deterministic BBS implies the $\Theta(q)$-SDH assumption.
]]></content:encoded>
<pubDate>Wed, 11 Jun 2025 04:27:47 +0000</pubDate>
</item>
<item>
<title>Concrete Treatment of Signal Handshake’s Deniability: Efficient Post-Quantum Deniable Ring Signature</title>
<link>https://eprint.iacr.org/2025/1090</link>
<guid>https://eprint.iacr.org/2025/1090</guid>
<content:encoded><![CDATA[
The Signal protocol relies on a handshake protocol, formerly X3DH and now PQXDH, to set up secure conversations. One of its privacy properties, of value to Signal, is deniability, allowing users to deny participation in communications. Prior analyses of deniability for these protocols, including post-quantum variants, use models highly tailored to the individual protocols and generally make ad-hoc adaptations to ``standard'' AKE definitions, obscuring the concrete deniability guarantees and complicating comparisons across protocols. Building on Hashimoto et al.’s abstraction for Signal handshake protocols (USENIX’25)'s abstraction for Signal handshake protocols (USENIX'25), we address this gap by presenting a unified framework for analyzing their deniability. We analyze Signal's classically secure X3DH and harvest-now-decrypt-later-secure PQXDH, and show that PQXDH is deniable against harvest-now-judge-later attacks, where a quantum judge retrospectively assesses the participation of classical users. We further analyze post-quantum alternatives like RingXKEM, whose deniability relies on ring signatures (RS).
By introducing a novel metric inspired by differential privacy, we provide relaxed, pragmatic guarantees for deniability. We also use this metric to define deniability for RS, a relaxation of anonymity, allowing us to build an efficient RS from NIST-standardized Falcon (and MAYO), which is not anonymous, but is provably deniable.
]]></content:encoded>
<pubDate>Tue, 10 Jun 2025 12:20:27 +0000</pubDate>
</item>
<item>
<title>Novel approximations of elementary functions in zero-knowledge proofs</title>
<link>https://eprint.iacr.org/2024/859</link>
<guid>https://eprint.iacr.org/2024/859</guid>
<content:encoded><![CDATA[
In this paper, we study the computation of complex mathematical functions in statements executed on top of zero-knowledge proofs (ZKP); these functions may include roots, exponentials and logarithms, trigonometry etc. While existing approaches to these functions in privacy-preserving computations (and sometimes also in general-purpose processors) have relied on polynomial approximation, more powerful methods are available for ZKP. In this paper, we note that in ZKP, all algebraic functions are exactly computable. Recognizing that, we proceed to the approximation of transcendental functions with algebraic functions. We develop methods of approximation, instantiate them on a number of common transcendental functions, and benchmark their precision and efficiency in comparison with best polynomial approximations.
]]></content:encoded>
<pubDate>Fri, 31 May 2024 08:41:54 +0000</pubDate>
</item>
<item>
<title>FABLE: Batched Evaluation on Confidential Lookup Tables in 2PC</title>
<link>https://eprint.iacr.org/2025/1081</link>
<guid>https://eprint.iacr.org/2025/1081</guid>
<content:encoded><![CDATA[
Abstract
Secure two-party computation (2PC) is a cryptographic technique that enables two mutually distrusting parties to jointly evaluate a function over their private inputs. We consider a 2PC primitive called confidential lookup table (LUT) evaluation, which is useful in privacy-preserving ML inference and data analytics. In this setting, a server holds a confidential LUT and evaluates it over an input secret-shared between a client and the server, producing a secret-shared output. Existing approaches for 2PC LUT evaluation suffer from high asymptotic complexity and practical inefficiency, with some designs lacking confidentiality guarantees for the LUT. Recognizing that many applications involving confidential LUT evaluation require processing multiple inputs with the same LUT, we propose FABLE, a system designed to efficiently evaluate a LUT on a large batch of queries simultaneously. Compared to the state-of-the-art confidential LUT evaluation methods, FABLE achieves up to 28.46-101.47$\times$ speedup in LAN environments and up to 50.10-392.93$\times$ speedup in WAN environments.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 15:54:39 +0000</pubDate>
</item>
<item>
<title>Fairness in the Wild: Secure Atomic Swap with External Incentives</title>
<link>https://eprint.iacr.org/2025/1086</link>
<guid>https://eprint.iacr.org/2025/1086</guid>
<content:encoded><![CDATA[
Atomic swaps enable asset exchanges across blockchains without relying on trusted intermediaries, and are a key component of decentralized finance (DeFi) ecosystems. Recently, Chung, Masserova, Shi, and Thyagarajan introduced Rapidash (Financial Cryptography 2025), an atomic swap protocol that remains incentive compatible under user-miner collusion, by ensuring that the honest strategy forms a coalition-resistant Nash equilibrium. However, their model assumes a closed system where players act solely based on internal protocol incentives. In practice, participants may be influenced by external incentives such as off-chain rewards or adversarial bribes, which can undermine such equilibrium guarantees.

In this work, we introduce a new game-theoretic notion, bounded maximin fairness, which ensures that honest participants remain protected against rational adversaries with arbitrary but bounded external incentives. We construct an atomic swap protocol that satisfies this notion, while preserving the equilibrium properties of prior work in the absence of external influence.

As we show, our protocol is easy to implement and can be instantiated even in Bitcoin’s limited scripting language.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 22:01:27 +0000</pubDate>
</item>
<item>
<title>SmallWood: Hash-Based Polynomial Commitments and Zero-Knowledge Arguments for Relatively Small Instances</title>
<link>https://eprint.iacr.org/2025/1085</link>
<guid>https://eprint.iacr.org/2025/1085</guid>
<content:encoded><![CDATA[
Zero-knowledge proofs (ZKPs) are a fundamental building block in cryptography, enabling powerful privacy-preserving and verifiable computations. In the post-quantum era, hash-based ZKPs have emerged as a promising direction due to their conjectured resistance to quantum attacks, along with their simplicity and efficiency.

In this work, we introduce SmallWood, a hash-based polynomial commitment scheme (PCS) and zero-knowledge argument system optimized for relatively small instances. Building on the recent degree-enforcing commitment scheme (DECS) from the Threshold-Computation-in-the-Head (TCitH) framework, we refine its formalization and combine it with techniques from Brakedown. This results in a new hash-based PCS that is particularly efficient for polynomials of relatively small degree —typically up to $2^{16}$— outperforming existing approaches in this range.

Leveraging this new PCS, we design a hash-based zero-knowledge argument system that outperforms the state-of-the-art in terms of proof sizes for witness size ranging from $2^6$ to $2^{16}$. Additionally, we present exact zero-knowledge arguments for lattice-based problems using SmallWood, demonstrating highly competitive performance: our scheme yields proof sizes under 25 KB across a wide range of lattice parameters, including Kyber and Dilithium instances.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 21:39:46 +0000</pubDate>
</item>
<item>
<title>How to (not) combine Oblivious Pseudorandom Functions</title>
<link>https://eprint.iacr.org/2025/1084</link>
<guid>https://eprint.iacr.org/2025/1084</guid>
<content:encoded><![CDATA[
An oblivious pseudorandom function (OPRF) is a cryptographic tool that enables fast and secure authentication and key derivation from passwords. In the past few years, the adoption of OPRFs has flourished and today they are at the core of the PIN-protected backup methods of WhatsApp and Signal, and of privacy-enhancing browser technologies. All vendors deploy the so-called 2Hash-Diffie-Hellman (2HashDH) OPRF, which relies on discrete-logarithm-type assumptions that are standard yet known to be prone to quantum attacks.

Recent advancements in cryptographic research (e.g., Dodgson et al., Eurocrypt 2025) have brought up post-quantum OPRFs that are fast enough to deploy them in the setting of, e.g., WhatsApp or Signal. Yet none of these constructions %that achieves the required level of security e.g., for WhatsApps backup protocol are based on standard assumptions.

In this work, we investigate combiners for OPRFs, namely a ``best-of-both'' combination of a classical and a post-quantum OPRF that is secure as long as one of them is. First, we give formal evidence that so-called black-box combiners do not exist, indicating that combining OPRFs is subtle and bears similarities with other powerful yet hard-to-combine cryptographic primitives like oblivious transfer (OT).

We then give a (non-black-box) combiner for OPRFs and show that it can be instantiated with 2HashDH and the currently most efficient post-quantum OPRFs based on Legendre symbols. In particular, the reliance on the less standard Legendre-based hardness assumption does not harm the security of 2HashDH. This gives vendors a viable path to lift the security of their OPRF deployments to a post-quantum level.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 20:12:40 +0000</pubDate>
</item>
<item>
<title>Weight reduction in distributed protocols: new algorithms and analysis</title>
<link>https://eprint.iacr.org/2025/1076</link>
<guid>https://eprint.iacr.org/2025/1076</guid>
<content:encoded><![CDATA[
We study the problem of minimizing the total weight of (potentially many) participants of a distributed protocol, a necessary step when the original values are large but the scheme to be deployed scales poorly with the weights. We assume that $\alpha$ fraction of the original weights can be corrupted and we must output new weights with at most $\beta$ adversarial fraction, for $\alpha < \beta$. This problem can be viewed from the prism of electing a small committee that does the heavy work, a powerful tool for making distributed protocols scalable. We solve the variant that requires giving parties potentially multiple seats in the committee and counting each seat towards the cost of the solution. Moreover, we focus on the ``deterministic'' version of the problem where the computed committee must be secure for any subset of parties that can be corrupted by the adversary; such a committee can be smaller than a randomly sampled one in some cases and is useful when security against adaptive corruptions is desired but parties in the sub-protocol speak multiple times.

Presented are new algorithms for the problem as well as analysis of prior work. We give two variants of the algorithm Swiper (PODC 2024), one that significantly improves the running time without sacrificing the quality of the output and the other improving the output for a reasonable increase in the running time. We prove, however, that all known algorithms, including our two variants of Swiper, have worst case approximation ratio $\Omega(n)$. To counter that, we give the first polynomial time algorithm with approximation factor $n / \log^2 n$ and also the first sub-exponential time exact algorithm, practical for some real-world inputs. Of theoretical interest is another polytime algorithm that we present, based on linear programming, whose output is no worse than an optimal solution to the problem with slightly different parameters.

We implemented and tested previous and new algorithms, comparing them on the stake distributions of popular proof-of-stake blockchains, and found that our second variant of Swiper computes solutions extremely close to the optimal, confirmed by our exact algorithm.
]]></content:encoded>
<pubDate>Mon, 09 Jun 2025 06:53:22 +0000</pubDate>
</item>
<item>
<title>Fabric-X: Redesigning Hyperledger Fabric Architecture for High-throughput Regulated Asset Exchange Applications</title>
<link>https://eprint.iacr.org/2023/1717</link>
<guid>https://eprint.iacr.org/2023/1717</guid>
<content:encoded><![CDATA[
The adoption of Distributed Ledger Technology (DLT) for critical
financial infrastructures like Central Bank Digital Currencies (CB-
DCs) is hindered by a significant performance gap. Permissioned
blockchains such as Hyperledger Fabric, while conceptually suit-
able, are limited by architectural bottlenecks in their monolithic
peer design and consensus mechanisms, preventing them from
achieving the required scale.

This paper presents a fundamental re-architecture of Hyper-
ledger Fabric that addresses these challenges end-to-end. We de-
compose the monolithic peer into independently scalable microser-
vices for endorsement, validation, and committing. To maximize
parallelism, we introduce a transaction dependency graph that en-
ables the safe, concurrent validation of transactions across multiple
blocks. Complementing the peer redesign, we introduce Arma, a
novel sharded Byzantine Fault Tolerant (BFT) ordering service that
dramatically increases throughput by ordering compact transaction
digests rather than full transaction payloads. We implemented and
benchmarked this framework with a UTXO-based CBDC applica-
tion. Our evaluation demonstrates a peak throughput exceeding
200,000 transactions per second (TPS)—a two-orders-of-magnitude
improvement over the standard implementation. This work proves
that permissioned DLTs can be engineered for national-scale pay-
ment systems, providing a resilient and highly performant foun-
dation for practical CBDC deployments and the integration of ad-
vanced, computationally intensive features.
]]></content:encoded>
<pubDate>Mon, 06 Nov 2023 08:41:54 +0000</pubDate>
</item>
<item>
<title>LAPWN: A Lightweight User–Server Authentication Protocol for Wireless Networks</title>
<link>https://eprint.iacr.org/2025/1073</link>
<guid>https://eprint.iacr.org/2025/1073</guid>
<content:encoded><![CDATA[
The Internet of Things (IoT) is composed of interconnected devices that exchange data over a network,
enabling applications in healthcare, transportation, and smart environments. As IoT ecosystems expand,
ensuring security and privacy remains a critical challenge. Many IoT devices rely on wireless
networks for data transmission, making them vulnerable to eavesdropping, tracking, and tampering.
This highlights the need for robust authentication mechanisms. To address these concerns, numerous
authentication protocols have been proposed. However, many fail to ensure adequate security against
both passive and active attacks. In this research, we introduce LAPWN, a lightweight protocol for
user–server communication, specifically designed for constrained environments, ensuring a balance
between security and efficiency. The proposed protocol is implemented as a fully functional Python
application, demonstrating its practical usability and evaluating its efficiency in real-world scenarios.
To validate its security, we performboth informal and formal analyses, utilizing Scyther, ProVerif, and
the Real-or-Random (RoR) model. The results confirm that LAPWN provides a secure, lightweight,
and efficient authentication solution with low computational and communication overhead. Furthermore,
performance evaluations show that it surpasses existing authentication protocols, making it a
highly effective solution for secure user–server interactions in constrained environments.
]]></content:encoded>
<pubDate>Sun, 08 Jun 2025 15:01:18 +0000</pubDate>
</item>
<item>
<title>Full Anonymity in the Asynchronous Setting from Peony Onion Encryption</title>
<link>https://eprint.iacr.org/2025/1067</link>
<guid>https://eprint.iacr.org/2025/1067</guid>
<content:encoded><![CDATA[
Onion routing is a popular practical approach to anonymous communication, and the subject of a growing body of foundational theoretical work aiming to design efficient schemes with provable anonymity, the strongest notion of which is full anonymity.

Unfortunately, all previous schemes that achieve full anonymity assume the synchronous communication setting, which is unrealistic as real networks may experience message loss and timing attacks that render such schemes insecure. Recently, Ando, Lysyanskaya, and Upfal (TCC '24) took a first step towards addressing the asynchronous setting by constructing an efficient onion routing protocol with the strictly weaker guarantee of differential privacy. Their scheme relies on a new primitive called bruisable onion encryption. 

In this paper, we construct the first efficient fully anonymous onion routing protocol in the asynchronous setting. To do so, we overcome two main technical challenges: First, we develop the first bruisable onion construction that does not leak information about the onion's position on the routing path. Second, we design an onion routing protocol that uses such bruisable onion encryption to achieve full anonymity (rather than just differential privacy). Along the way, we develop a new fully anonymous onion routing protocol in the synchronous setting, which improves on the state of the art in terms of communication complexity and round complexity.

Both our protocols are secure against an active adversary corrupting a constant fraction of the nodes (up to <1 for the synchronous protocol, and <1/2 for the asynchronous protocol) and rely on standard cryptographic assumptions (CCA-secure public key encryption and collision-resistant hash functions).
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 17:56:00 +0000</pubDate>
</item>
<item>
<title>From Signature-Based Witness Encryption to RAM Obfuscation: Achieving Blockchain-Secured Cryptographic Primitives</title>
<link>https://eprint.iacr.org/2025/1064</link>
<guid>https://eprint.iacr.org/2025/1064</guid>
<content:encoded><![CDATA[
Goyal and Goyal demonstrated that extractable witness encryption, when combined with smart-contract equipped proof-of-stake blockchains, can yield powerful cryptographic primitives such as one-time programs and pay-to-use programs. However, no standard model construction for extractable witness encryption is known, and instantiations from alternatives like indistinguishability obfuscation are highly inefficient.

This paper circumvents the need for extractable witness encryption by combining signature-based witness encryption (Döttling et al.) with witness encryption for KZG commitments (Fleischhacker et al.). Inspired by Goyal et al., we introduce $T+1$-Extractable Witness Encryption for Blockchains ($T+1$-eWEB), a novel primitive that encrypts a secret, making its decryption contingent upon the subsequent block's state. Leveraging $T+1$-eWEBs, we then build a conditional one-time memory, leading to a $T+1$ one-time program ($T+1$-OTP) also conditional on the next block state. Finally, using our $T+1$-OTP, we develop a conditional RAM obfuscation scheme where program execution can be contingent on the blockchain state, thereby enabling applications like pay-to-use programs.

Despite its theoretical value, our construction is impractical due to a "bit-by-bit" signing requirement for the state root and an inefficient method for storing validator keys. We thus posit the construction of a practical $T+1$-OTP as a significant open problem. This work provides the first theoretical pathway for building such primitives without extractable witness encryption, representing a novel step for blockchain-secured cryptography
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 14:36:43 +0000</pubDate>
</item>
<item>
<title>TrafficProof: Privacy-Preserving Reliable Traffic Information Sharing in Social Internet of Vehicles</title>
<link>https://eprint.iacr.org/2025/1062</link>
<guid>https://eprint.iacr.org/2025/1062</guid>
<content:encoded><![CDATA[
In the Social Internet of Vehicles (SIoV), effective data sharing is essential for applications including road safety, traffic management, and situational awareness. However, the decentralized and open nature of SIoV presents significant challenges in simultaneously ensuring data integrity, user privacy, and system accountability. This paper presents a protocol for secure and location-accurate traffic data sharing that fully preserves the anonymity and privacy of participating witnesses. The protocol leverages zero-knowledge proofs (ZKPs) to allow vehicles to broadcast redacted traffic information—such as images—tied to specific geographic locations, while withholding both the original content and the identity of the reporting vehicle. To ensure the authenticity of the redacted content and the legitimacy of the witness, an additional ZKP is used to privately validate both elements. Upon receiving a report, the verifying node checks the submitted proofs, aggregates validated inputs, and publishes the resulting metadata to both IPFS and a blockchain. This design ensures public verifiability, tamper resistance, and the reliability of the shared data, while maintaining strong privacy guarantees through cryptographic anonymity. To improve the efficiency of proof generation on resource-constrained devices, the protocol employs folding-based ZKP constructions. We conduct a formal security and soundness analysis of the protocol and implement a proof-of-concept, which is publicly available as open-source software. Experimental evaluations on commodity hardware demonstrate that the protocol is computationally efficient and introduces less than 1.5\% communication overhead relative to the size of the shared traffic data, indicating its suitability for real-world deployment.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 12:37:01 +0000</pubDate>
</item>
<item>
<title>Blockchain Governance via Sharp Anonymous Multisignatures</title>
<link>https://eprint.iacr.org/2023/1881</link>
<guid>https://eprint.iacr.org/2023/1881</guid>
<content:encoded><![CDATA[
Electronic voting has occupied a large part of the cryptographic protocols literature. The recent reality of blockchains---in particular, their need for online governance mechanisms---has brought new parameters and requirements to the problem. We identify the key requirements of a blockchain governance mechanism, namely correctness (including eliminative double votes), voter anonymity, and traceability, and investigate mechanisms that can achieve them with minimal interaction and under assumptions that fit the blockchain setting.

First, we define a signature-like primitive, which we term \textit{sharp anonymous multisignatures} (in short, $\sharp$AMS) that tightly meets the needs of blockchain governance. In a nutshell, $\sharp$AMSs allow any set of parties to generate a signature, e.g., on a proposal to be voted upon, which, if posted on the blockchain, hides the identities of the signers/voters but reveals their number. This can be seen as a (strict) generalization of threshold ring signatures (TRS). 

We next turn to constructing such $\sharp$AMSs and using them in various governance scenarios---e.g., single vote vs. multiple votes per voter. In this direction, although the definition of TRS does not imply $\sharp$AMS, one can compile some existing TRS constructions into $\sharp$AMS. This raises the question: What is the TRS structure that allows such a compilation? 
To answer the above, we devise templates for TRSs. Our templates encapsulate and abstract the structure that allows for the above compilation---most of the TRS schemes that can be compiled into $\sharp$AMS are, in fact, instantiations of our template. This abstraction makes our template generic for instantiating TRSs and $\sharp$AMSs from different cryptographic assumptions (e.g., DDH, LWE, etc.). One of our templates is based on chameleon hashes, and we explore a framework of lossy chameleon hashes to understand their nature fully.

Finally, we turn to how $\sharp$AMS schemes can be used in our applications. We provide fast (in some cases non-interactive) $\sharp$AMS-based blockchain governance mechanisms for a wide spectrum of assumptions on the honesty (semi-honest vs malicious) and availability of voters and proposers.
]]></content:encoded>
<pubDate>Thu, 07 Dec 2023 03:28:45 +0000</pubDate>
</item>
<item>
<title>Private Signaling Secure Against Actively Corrupted Servers</title>
<link>https://eprint.iacr.org/2025/1056</link>
<guid>https://eprint.iacr.org/2025/1056</guid>
<content:encoded><![CDATA[
Private signaling allows servers to identify a recipient's messages on a public bulletin board without knowing the recipient's metadata. It is a central tool for systems like privacy-preserving blockchains and anonymous messaging. However, unless with TEE, current constructions all assume that the servers are only passively corrupted, which significantly limits their practical relevance. In this work, we present a TEE-free simulation-secure private signaling protocol assuming two non-colluding servers, either of which can be actively corrupted.
 
Crucially, we convert signal retrieval into a problem similar to private set intersection and use custom-built zero-knowledge proofs to ensure consistency with the public bulletin board. As a result, our protocol achieves lower server-to-server communication overhead and a much smaller digest compared to state-of-the-art semi-honest protocol. For example, for a board size of $2^{19}$ messages, the resulting digest size is only 33.57KB. Our protocol is also computationally efficient: retrieving private signals only takes about 2 minutes, using 16 threads and a LAN network.
]]></content:encoded>
<pubDate>Fri, 06 Jun 2025 02:52:28 +0000</pubDate>
</item>
<item>
<title>Rewardable Naysayer Proofs</title>
<link>https://eprint.iacr.org/2025/1054</link>
<guid>https://eprint.iacr.org/2025/1054</guid>
<content:encoded><![CDATA[
Combining verifiable computation with optimistic approaches is a promising direction to scale blockchain applications. 
The basic idea consists of saving computations by avoiding the verification of proofs unless there are complaints.

A key tool to design systems in the above direction has been recently proposed by Seres, Glaeser and Bonneau [FC'24] who formalized the concept of a Naysayer proof: an efficient to verify proof disproving a more demanding to verify original proof. 

In this work, we discuss the need of rewarding naysayer provers, the risks deriving from front-running attacks, and the failures of generic approaches trying to defeat them. 
Next, we introduce the concept of verifiable delayed naysayer proofs and show a construction leveraging proofs of sequential work, without relying on any additional infrastructure.
]]></content:encoded>
<pubDate>Thu, 05 Jun 2025 19:31:42 +0000</pubDate>
</item>
<item>
<title>Constrained Verifiable Random Functions Without Obfuscation and Friends</title>
<link>https://eprint.iacr.org/2025/1045</link>
<guid>https://eprint.iacr.org/2025/1045</guid>
<content:encoded><![CDATA[
CVRFs are PRFs that unify the properties of verifiable and constrained PRFs. Since they were introduced concurrently by Fuchsbauer and Chandran-Raghuraman-Vinayagamurthy in 2014, it has been an open problem to construct CVRFs without using heavy machinery such as multilinear maps, obfuscation or functional encryption.

We solve this problem by constructing a prefix-constrained verifiable PRF that does not rely on the aforementioned assumptions. Essentially, our construction is a verifiable version of the Goldreich-Goldwasser-Micali PRF. To achieve verifiability we leverage degree-2 algebraic PRGs and bilinear groups. In short, proofs consist of intermediate values of the Goldreich-Goldwasser-Micali PRF raised to the exponents of group elements. These outputs can be verified using pairings since the underlying PRG is of degree 2.

We prove the selective security of our construction under the Decisional Square Diffie-Hellman (DSDH) assumption and a new assumption, which we dub recursive Decisional Diffie-Hellman (recursive DDH).

We prove the soundness of recursive DDH in the generic group model assuming the hardness of the Multivariate Quadratic (MQ) problem and a new variant thereof, which we call MQ+.

Last, in terms of applications, we observe that our CVRF is also an exponent (C)VRF in the plain model. Exponent VRFs were recently introduced by Boneh et al. (Eurocrypt’25) with various applications to threshold cryptography in mind. In addition to that, we give further applications for prefix-CVRFs in the blockchain setting, namely, stake-pooling and compressible randomness beacons.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 12:08:42 +0000</pubDate>
</item>
<item>
<title>When Threshold Meets Anamorphic Signatures: What is Possible and What is Not!</title>
<link>https://eprint.iacr.org/2025/1044</link>
<guid>https://eprint.iacr.org/2025/1044</guid>
<content:encoded><![CDATA[
Anamorphic signatures allow covert communication through signatures in environments where encryption is restricted. They enable trusted recipients with a double key to extract hidden messages while the signature remains indistinguishable from a fresh and regular one. However, the traditional notion of anamorphic signatures suffers from vulnerabilities, particularly when a single recipient or sender is compromised, exposing all hidden messages and providing undeniable proof that citizens are part of the anamorphic exchange.

To address these limitations, we explore a threshold-based approach to distribute trust among multiple recipients, preventing adversaries from decrypting anamorphic messages even if some recipients are compromised. Our first contribution is the formalization of the notion of \emph{threshold-recipient anamorphic signatures}, where decryption is possible only through collaboration among a subset of recipients. 

We then explore a \emph{stronger model} where the dictator controls the key generation process through which it learns all secret keys and how citizens store cryptographic keys. A particular example of this model in the real world is a dictator providing citizens with electronic identity documents (eIDs) and blocking all other usage of cryptography. We demonstrate that anamorphic communication is still possible even in such a scenario. Our construction is secure against post-quantum adversaries and does not rely on any computational assumptions except the random oracle model.

Finally, we show an \emph{impossibility result} for encoding anamorphic messages with a threshold-sender model when using many existing threshold signature schemes and the adversary is part of the signing group. Our work outlines both the possibilities and limitations of extending anamorphic signatures with threshold cryptography, offering new insights into improving the security and privacy of individuals under authoritarian regimes.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 10:14:06 +0000</pubDate>
</item>
<item>
<title>Rubato: Provably Post-Quantum Secure and Batched Asynchronous Randomness Beacon</title>
<link>https://eprint.iacr.org/2025/1041</link>
<guid>https://eprint.iacr.org/2025/1041</guid>
<content:encoded><![CDATA[
Distributed Randomness Beacons (DRBs) provide secure, unbiased random numbers for decentralized systems. However, existing protocols face critical limitations. Most rely on cryptographic assumptions which are vulnerable to quantum attacks, risking long-term security in asynchronous networks where unbounded delays may allow attackers time to exploit these weaknesses. Many achieve low beacon generation rates, often below 100 beacons per minute in moderate-scale networks (e.g., Spurt IEEE S&amp;P’22), hindering their use in applications requiring high-throughput randomness. Additionally, traditional Verifiable Secret Sharing (VSS)-based DRBs, using a share-consensus-reconstruct paradigm, are unsuitable for asynchronous networks due to circular dependencies between beacon generation and consensus. Given these limitations, we propose Rubato, the first provably post-quantum secure DRB for asynchronous environments, incorporating a lattice-based batched Asynchronous Verifiable Secret Sharing scheme (bAVSS-PQ). Rubato supports batching of $\mathcal{O}(\lambda^2)$ secrets with communication complexity $\mathcal{O}(\lambda n^3 \log n)$ and tolerates Byzantine faults in up to one-third of the nodes. Integrated with DAG-based consensus protocols like Bullshark or Tusk, its epoch-staggered architecture resolves circular dependencies, enabling efficient and secure randomness generation. Evaluations across 10 to 50 nodes show Rubato generates 5200 to 350 beacons per minute with per-beacon latencies of 11.60 to 96.37 milliseconds, achieving a consensus throughput of 186,088 transactions per second with a latency of 16.78 seconds at 30 nodes. Rubato offers robust post-quantum security and high performance for small-to-medium-scale decentralized systems.
]]></content:encoded>
<pubDate>Wed, 04 Jun 2025 03:16:30 +0000</pubDate>
</item>
<item>
<title>Trusted Hardware-Assisted Leaderless Byzantine Fault Tolerance Consensus</title>
<link>https://eprint.iacr.org/2025/1033</link>
<guid>https://eprint.iacr.org/2025/1033</guid>
<content:encoded><![CDATA[
Byzantine Fault Tolerance (BFT) Consensus protocols with trusted hardware assistance have been extensively explored for their improved resilience to tolerate more faulty processes. Nonetheless, the potential of trust hardware has been scarcely investigated in leaderless BFT protocols. RedBelly is assumed to be the first blockchain network whose consensus is based on a truly leaderless BFT algorithm. This paper proposes a trusted hardware-assisted leaderless BFT consensus protocol by offering a hybrid solution for the set BFT problem defined in the RedBelly blockchain. Drawing on previous studies, we present two crucial trusted services: the counter and the collector. Based on these two services, we introduce two primitives to formulate our leaderless BFT protocol: a hybrid verified broadcast (VRB) protocol and a hybrid binary agreement. The hybrid VRB protocol enhances the hybrid reliable broadcast protocol by integrating a verification function. This addition ensures that a broadcast message is verified not only for authentication but also for the correctness of its content. Our hybrid BFT consensus is integrated with these broadcast protocols to deliver binary decisions on all proposals. We prove the correctness of the proposed hybrid protocol and demonstrate its enhanced performance in comparison to the prior trusted BFT protocol.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 08:48:21 +0000</pubDate>
</item>
<item>
<title>Rapidash: Atomic Swaps Secure under User-Miner Collusion</title>
<link>https://eprint.iacr.org/2022/1063</link>
<guid>https://eprint.iacr.org/2022/1063</guid>
<content:encoded><![CDATA[
Cross-chain trading is fundamental to blockchains and Decentralized Finance (DeFi). A way to achieve such trading in a truly decentralized manner, i.e., without trusted third parties, is by using atomic swaps. However, recent works revealed that Hashed Time-Lock Contract, a key building block of the existing atomic swaps, is entirely insecure in the presence of user-miner collusion. Specifically, a user can bribe the miners of the blockchain to help it cheat.

In this work, we give the first and rigorous formal treatment of fair trading on blockchains, where users and miners may enter arbitrary binding contracts on the side. We propose Rapidash, a new atomic swap protocol, and prove its incentive-compatibility in the presence of user-miner collusion. Specifically, we show that Rapidash satisfies a coalition-resistant Nash equilibrium absent external incentives. We give instantiations of Rapidash that are compatible with Bitcoin and Ethereum, and incur only minimal overheads in terms of costs for the users.
]]></content:encoded>
<pubDate>Tue, 16 Aug 2022 04:17:47 +0000</pubDate>
</item>
<item>
<title>Everlasting Anonymous Rate-Limited Tokens</title>
<link>https://eprint.iacr.org/2025/1030</link>
<guid>https://eprint.iacr.org/2025/1030</guid>
<content:encoded><![CDATA[
Anonymous rate-limited tokens are a special type of credential that can be used to improve the efficiency of privacy-preserving authentication systems like Privacy Pass. In such a scheme, a user obtains a "token dispenser" by interacting with an issuer, and the dispenser allows the user to create up to a pre-determined number $k$ of unlinkable and publicly verifiable tokens. Unlinkable means that one should not be able to tell that two tokens originate from the same dispenser, but also they cannot be linked to the interaction that generated the dispenser. Furthermore, we can limit the rate at which these tokens are created by linking each token to a context (e.g., the service we are authenticating to), and imposing a limit $N \leq k$ such that seeing more than $N$ tokens for the same context will reveal the identity of the user.
Constructions of such tokens were first given by Camenisch, Hohenberger and Lysyanskaya (EUROCRYPT '05) and Camenisch, Hohenberger, Kohlweiss, Lysyanskaya, and Meyerovich (CCS '06). 

In this work, we present the first construction of \emph{everlasting} anonymous rate-limited tokens, for which unlinkability holds against computationally unbounded adversaries, whereas other security properties (e.g., unforgeability) remain computational. Our construction relies on pairings. While several parameters in our construction unavoidably grow with $k$, the key challenge we resolve is ensuring that the complexity of dispensing a token is independent of the parameter $k$. 

We are motivated here by the goal of providing solutions that are robust to potential future quantum attacks against the anonymity of previously stored tokens. A construction based on post-quantum secure assumptions (e.g., based on lattices) would be rather inefficient---instead, we take a pragmatic approach dispensing with post-quantum security for properties not related to privacy.
]]></content:encoded>
<pubDate>Tue, 03 Jun 2025 06:20:26 +0000</pubDate>
</item>
<item>
<title>Group Key Progression: Strong Security for Shared Persistent Data</title>
<link>https://eprint.iacr.org/2025/1028</link>
<guid>https://eprint.iacr.org/2025/1028</guid>
<content:encoded><![CDATA[
End-to-end encryption allows data to be outsourced and stored on an untrusted server, such as in the cloud, without compromising data privacy. In the setting when this data is shared between a group of users, members also all share access to the same static key material used for data encryption. When the group membership changes, access control is only enforced by the server: security breaches or compelled disclosure would allow even a removed member to decrypt the current shared data.

We propose to move away from static keys and instead use a group key progression (GKP) scheme, a novel primitive that enables a dynamic group of users to agree on a persistent sequence of keys while keeping a compact local state. GKP ensures that group members can only derive keys within a certain interval of the sequence, a notion that we call interval access control (IAC), and also provide post-compromise security. Our GKP construction, called Grappa, combines continuous group key agreement (CGKA, by Alwen et al., 2020) with a new abstraction called interval scheme. The latter is a symmetric-key primitive that can derive a sequence of keys from a compact state while preserving IAC. We explore different interval scheme constructions and simulate their storage and communication costs when used in group settings. The most efficient of them is a generalization of dual key regression (Shafagh et al., 2020), which we formalize and prove secure. Overall, our protocols offer a practical and robust solution to protect persistent data shared by a group.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 22:53:02 +0000</pubDate>
</item>
<item>
<title>Malicious Security in Collaborative zk-SNARKs: More than Meets the Eye</title>
<link>https://eprint.iacr.org/2025/1026</link>
<guid>https://eprint.iacr.org/2025/1026</guid>
<content:encoded><![CDATA[
Collaborative zk-SNARKs (Ozdemir and Boneh, USENIX’22) are a multiparty variant of zk-SNARKs where multiple, mutually distrustful provers, each holding a private input, jointly compute a zk-SNARK using their combined inputs. A sequence of works has proposed efficient constructions of collaborative zk-SNARKs using a common template that involves designing secure multiparty computation (MPC) protocols to emulate a zk-SNARK prover without making non-black-box use of cryptography. To achieve security against malicious adversaries, these works adopt compilers from the MPC literature that transform semi-honest MPC into malicious-secure MPC.

In this work, we revisit this design template.
• Pitfalls: We demonstrate two pitfalls in the template, which can lead to a loss of input privacy. We first show that it is possible to compute collaborative proofs on invalid witnesses, which in turn can leak the inputs of honest provers. Next, we show that using state-of-the-art malicious security compilers as-is for proof computation is insecure, in general. Finally, we discuss mitigation strategies.
• Malicious Security Essentially for Free: As our main technical result, we show that in the honest-majority setting, one can forego malicious security checks performed by state-of-the-art malicious security compilers during collaborative proof generation of several widely used zk-SNARKs. In other words, we can avoid the overheads of malicious security compilers, enabling faster proof generation.

To the best of our knowledge, this is the first example of non-trivial computations where semi-honest MPC protocols achieve malicious security. The observations underlying our positive results are general and may have applications beyond collaborative zkSNARKs.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 20:25:28 +0000</pubDate>
</item>
<item>
<title>Secure Noise Sampling for Differentially Private Collaborative Learning</title>
<link>https://eprint.iacr.org/2025/1025</link>
<guid>https://eprint.iacr.org/2025/1025</guid>
<content:encoded><![CDATA[
Differentially private stochastic gradient descent (DP-SGD) trains machine learning (ML) models with formal privacy guarantees for the training set by adding random noise to gradient updates. In collaborative learning (CL), where multiple parties jointly train a model, noise addition occurs either (i) before or (ii) during secure gradient aggregation. The first option is deployed in distributed DP methods, which require greater amounts of total noise to achieve security, resulting in degraded model utility. The second approach preserves model utility but requires a secure multiparty computation (MPC) protocol. Existing methods for MPC noise generation require tens to hundreds of seconds of runtime per noise sample because of the number of parties involved. This makes them impractical for collaborative learning, which often requires thousands or more samples of noise in each training step.

We present a novel protocol for MPC noise sampling tailored to the collaborative learning setting. It works by constructing an approximation of the distribution of interest which can be efficiently sampled by a series of table lookups. Our method achieves significant runtime improvements and requires much less communication compared to previous work, especially at higher numbers of parties. It is also highly flexible – while previous MPC sampling methods tend to be optimized for specific distributions, we prove that our method can generically sample
noise from statistically close approximations of arbitrary discrete distributions. This makes it compatible with a wide variety of DP mechanisms. Our experiments demonstrate the efficiency and utility of our method applied to a discrete Gaussian mechanism for differentially private collaborative learning. For 16 parties, we achieve a runtime of 0.06 seconds and 11.59 MB total communication per sample, a 230× runtime improvement and 3× less communication compared to the prior state-of-the-art for sampling from discrete Gaussian distribution in MPC.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 19:30:57 +0000</pubDate>
</item>
<item>
<title>Towards Trustless Provenance: A Privacy-Preserving Framework for On-chain Media Verification</title>
<link>https://eprint.iacr.org/2025/1024</link>
<guid>https://eprint.iacr.org/2025/1024</guid>
<content:encoded><![CDATA[
As generative models continue to evolve, verifying the authenticity, provenance, and integrity of digital media has become increasingly critical—particularly for domains like journalism, digital art, and scientific documentation.
In this work, we present a decentralized verifiable media ecosystem for managing, verifying, and transacting authentic digital media using zero-knowledge proofs (ZKPs).
Building on VIMz (Dziembowski et al., PETS'25), we extend the framework in three key directions. First, we generalize the model to support arbitrary image regions to achieve selective transformations support such as redaction and regional blurring—features commonly required in privacy-preserving applications. Second, we introduce performance optimizations that yield up to an 18% improvement in off-chain proof generation, and enhance the framework to support cost-efficient on-chain verification. Third, we design and implement a modular smart contract architecture to support a wide range of decentralized media applications.
As a flagship use case, we develop a decentralized media marketplace that enables permissionless licensing, ownership transfer, and verifiable attribution. In this setting, users can share transformed media—such as cropped, blurred, or resized previews—alongside ZKPs that prove derivation from a signed original, eliminating the need to trust the seller.
Unlike prior fair exchange protocols, which rely on trusted descriptions or encrypted payload delivery, our system enables verifiable public previews and origin-bound proofs without revealing the full content. This approach unlocks new applications beyond marketplaces, including automated infringement dispute resolution and photography contests with verifiable criteria.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:42:37 +0000</pubDate>
</item>
<item>
<title>Universal Channel Rebalancing: Flexible Coin Shifting in Payment Channel Networks</title>
<link>https://eprint.iacr.org/2025/1023</link>
<guid>https://eprint.iacr.org/2025/1023</guid>
<content:encoded><![CDATA[
Payment Channel Networks (PCNs) enhance blockchain scalability by enabling off-chain transactions. However, repeated unidirectional multi-hop payments often cause channel imbalance or depletion, limiting scalability and usability. Existing rebalancing protocols, such as Horcrux [NDSS’25] and Shaduf [NDSS’22], rely on on-chain operations, which hinders efficiency and broad applicability.
  We propose Universal Channel Rebalancing (UCRb), a blockchain-agnostic, fully off-chain framework that ensures correct behavior among untrusted participants without on-chain interaction. 
  UCRb incorporates the following core innovations: 
  (1) a fair and reliable incentive-compatible mechanism that encourages voluntary user participation in off-chain channel rebalancing,  
  (2) integration of Pedersen commitments to achieve atomic off-chain payments and rebalancing operations, while ensuring balance security, and  
  (3) zero-knowledge proofs to enable privacy-preserving channel initialization and coin shifting, ensuring that user identities and fund allocations remain hidden throughout the process.

  We evaluate UCRb using real-world Lightning Network dataset and compare its performance against state-of-the-art solutions including Horcrux, Shaduf, and Revive [CCS'17]. 
  UCRb exhibits a success ratio enhancement between 15% and 50%, while also reducing the required user deposits by 72%--92%. It maintains an almost negligible rate of channel depletion. Additionally, the long-term performance of UCRb is roughly 1.5 times that of its short-term performance, suggesting that continuous operation leads to improved efficiency. We implement a prototype for UCRb smart contracts and demonstrate its practicality through extensive evaluation. As \texttt{CoinShift} operations require no on-chain interaction, the protocol incurs minimal gas costs. For instance, opening and closing channels with 10 neighbors costs only 130K-160K gas—significantly lower than comparable solutions.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:37:20 +0000</pubDate>
</item>
<item>
<title>Burn Your Vote: Decentralized and Publicly Verifiable Anonymous Voting at Scale</title>
<link>https://eprint.iacr.org/2025/1022</link>
<guid>https://eprint.iacr.org/2025/1022</guid>
<content:encoded><![CDATA[
Secure and trustworthy electronic voting requires more than correctness and censorship resistance, it must also ensure voter privacy, vote confidentiality, and protection against coercion. Prior work attempt to address these challenges using heavyweight cryptographic primitives such as homomorphic encryption, time-lock puzzles, or multi-party computation. These approaches often involve complex computations, depend on trusted parties, and typically do not scale well. We propose a lightweight, fully on-chain anonymous voting protocol based on a novel application of the proof-of-burn (PoB) mechanism. Voters anonymously commit to their votes by burning tokens to pseudorandom addresses and later submit zero-knowledge proofs attesting to their valid participation. Our design achieves vote integrity, coercion resistance, and unlinkability without relying on encrypted ballots, trusted third parties, or centralized tallying. The tallying process is public and operates on plaintext votes that are authenticated yet unlinkable to voters. This enables flexible voting models—including token-weighted and quadratic voting—with minimal on-chain overhead. We formally analyze the protocol’s security guarantees and demonstrate support for a broad range of voting models. We implement the protocol as an open-source library fully compatible with the Ethereum Virtual Machine (EVM), and our experimental evaluation confirms its high scalability and improved efficiency compared to the state-of-the-art.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 16:28:20 +0000</pubDate>
</item>
<item>
<title>Silent Splitter: Privacy for Payment Splitting via New Protocols for Distributed Point Functions</title>
<link>https://eprint.iacr.org/2025/1019</link>
<guid>https://eprint.iacr.org/2025/1019</guid>
<content:encoded><![CDATA[
In a world where financial transactions are primarily performed or recorded online, protecting sensitive transaction details has become crucial. Roommates sharing housing costs or friends splitting travelling expenses may use applications such as Splitwise to easily track debts and minimize the number of individual repayments. However, these apps reveal potentially sensitive financial transaction activity to their operators. In this paper, we present Silent Splitter, a privacy-preserving payment splitting system which enables users to securely set up groups, perform transactions within those groups, and "settle up" without revealing group membership or any sensitive transaction details (such as the users involved or amount of money exchanged) to the system itself. Silent Splitter operates in the two server setting and uses Distributed Point Functions (DPFs) to securely record transactions. Of independent interest, we also present new protocols for proving knowledge of properties of DPFs as part of our system.
]]></content:encoded>
<pubDate>Mon, 02 Jun 2025 14:24:53 +0000</pubDate>
</item>
<item>
<title>Silentium: Implementation of a Pseudorandom Correlation Generator for Beaver Triples</title>
<link>https://eprint.iacr.org/2025/1013</link>
<guid>https://eprint.iacr.org/2025/1013</guid>
<content:encoded><![CDATA[
Secure Multi-Party Computation is a privacy-enhancing technology that allows several parties to securely compute on distributed private data.  
In the line of the well established SPDZ protocol,  the by far most expensive task is the generation of Beaver triples in the so called  offline phase.
Silentium is our implementation of an actively secure offline phase in the form of a Pseudorandom Correlation Generator for Beaver triples (Bt-PCG, Boyle et al. CRYPTO 2020), which, as any PCG, is designed to have low communication. Compared to previous offline phases, their Bt-PCG reduces the communication costs by three orders of magnitude. However, so far efficiency was only estimated. With Silentium, we  demonstrate that their Bt-PCG can achieve even better running times than state-of-the-art offline phase implementations in the  MP-SPDZ library. To actually achieve such a performance, Silentium  comprises a systematic   parallelization strategy and implementation-friendly decomposition scenarios of the Bt-PCG into structured modules. 
Looking forward for large-scale applications on the cloud,  Silentium is designed to be versatile to support hardware acceleration in future.
]]></content:encoded>
<pubDate>Sun, 01 Jun 2025 12:18:18 +0000</pubDate>
</item>
<item>
<title>Efficient and Generic Methods to Achieve Active Security in Private Information Retrieval and More Advanced Database Search</title>
<link>https://eprint.iacr.org/2024/375</link>
<guid>https://eprint.iacr.org/2024/375</guid>
<content:encoded><![CDATA[
Motivated by secure database search, we present secure computation protocols for a function $f$ in the client-servers setting, where a client can obtain $f(x)$ on a private input $x$ by communicating with multiple servers each holding $f$. Specifically, we propose generic compilers from passively secure protocols, which only keep security against servers following the protocols, to actively secure protocols, which guarantee privacy and correctness even against malicious servers. Our compilers are applied to protocols computing any class of functions, and are efficient in that the overheads in communication and computational complexity are only polynomial in the number of servers, independent of the complexity of functions. We then apply our compilers to obtain concrete actively secure protocols for various functions including private information retrieval (PIR), bounded-degree multivariate polynomials and constant-depth circuits. For example, our actively secure PIR protocols achieve exponentially better computational complexity in the number of servers than the currently best-known protocols. Furthermore, our protocols for polynomials and constant-depth circuits reduce the required number of servers compared to the previous actively secure protocols. In particular, our protocol instantiated from the sparse Learning Parity with Noise (LPN) assumption is the first actively secure protocol for multivariate polynomials which has the minimum number of servers, without assuming fully homomorphic encryption.
]]></content:encoded>
<pubDate>Thu, 29 Feb 2024 09:22:37 +0000</pubDate>
</item>
<item>
<title>Kerblam — Anonymous Messaging System Protecting Both Senders and Recipients</title>
<link>https://eprint.iacr.org/2025/997</link>
<guid>https://eprint.iacr.org/2025/997</guid>
<content:encoded><![CDATA[
While popular messaging apps already offer end-to-end confidentially, end-to-end metadata privacy is still far from being practical. Although several meta-data hiding systems have been developed and some like Tor have been popular, the proposed solutions lack in one or more aspects: the Tor network is prone to easy low-resourced attacks, and most others solely focus on anonymity for senders or receivers but do not both. Some recent solutions do consider end-to-end anonymity, however, they put significant restrictions on how users use the system. Particularly, the receivers must stay online or trust online servers that receive messages on behalf of receivers. This work presents a scalable end-to-end anonymity messaging system, $\mathsf{ORAM}^{-}$, that overcomes the mentioned issues and restrictions. It stems from a key observation that combining the recently-emerged oblivious message retrieval (OMR) primitive with oblivious shuffling can offer the desired end-to-end anonymity without severely restricting the number of messages a sender may send or a receiver may receive. We build our solution using two non-colluding servers and recent OMR protocol HomeRun and a compatible oblivious shuffle protocol. We then extend our solution to allow larger messages by employing a novel two-server distributed oblivious RAM technique, called $\mathsf{ORAM}^{-}$. Our performance analysis demonstrates that with the increase in the number and size of messages, the performance improvement brought by $\mathsf{ORAM}^{-}$ becomes higher. Specifically, for $2^{20}$ messages of size 1KB, our scheme only needs $5.577$ s to transmit a message.
]]></content:encoded>
<pubDate>Fri, 30 May 2025 01:13:53 +0000</pubDate>
</item>
<item>
<title>Distance-Aware OT with Application to Fuzzy PSI</title>
<link>https://eprint.iacr.org/2025/996</link>
<guid>https://eprint.iacr.org/2025/996</guid>
<content:encoded><![CDATA[
A two-party fuzzy private set intersection (PSI) protocol between Alice and Bob with input sets $A$ and $B$ allows Alice to learn nothing more than the points of Bob that are ``$\delta$-close'' to its points in some metric space $\texttt{dist}$. More formally, Alice learns only the set $\{ b\ |~\texttt{dist}{(a,b)} \leq \delta , a \in A,b\in B\}$ for a predefined threshold $\delta$ and distance metric $\texttt{dist}$, while Bob learns nothing about Alice's set.  Fuzzy PSI is a valuable privacy tool in scenarios where private set intersection needs to be computed over imprecise or measurement-based data, such as GPS coordinates or healthcare data. Previous approaches to fuzzy PSI rely on asymmetric cryptographic primitives, generic two-party computation (2PC) techniques like garbled circuits, or function secret sharing methods, all of which are computationally intensive and lead to poor concrete efficiency.

This work introduces a new modular framework for fuzzy PSI, {primarily built on efficient symmetric key primitives}. Our framework reduces the design of efficient fuzzy PSI to a novel variant of oblivious transfer (OT), which we term distance-aware random OT (da-ROT). This variant enables the sender to obtain two random strings $(r_0, r_1)$, while the receiver obtains one of these values $r_b$,  depending on whether the receiver’s input keyword $a$ and the sender’s input keyword $b$ are close in some metric space i.e., $\texttt{dist}{(a,b)} \leq \delta$. The da-ROT can be viewed as a natural extension of traditional OT, where the condition (choice bit) is known to the receiver. We propose efficient constructions for da-ROT based on standard OT techniques tailored for small domains, supporting distance metrics such as the Chebyshev norm, the Euclidean norm, and the Manhattan norm. 

By integrating these da-ROT constructions, our fuzzy PSI framework achieves up to a $14\times$ reduction in communication cost and up to a $54\times$ reduction in computation cost compared to previous state-of-the-art protocols, across input set sizes ranging from $2^8$ to $2^{16}$. Additionally, we extend our framework to compute fuzzy PSI cardinality and fuzzy join from traditional PSI-related functionalities. All proposed protocols are secure in the semi-honest model.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 23:58:08 +0000</pubDate>
</item>
<item>
<title>MOAI: Module-Optimizing Architecture for Non-Interactive Secure Transformer Inference</title>
<link>https://eprint.iacr.org/2025/991</link>
<guid>https://eprint.iacr.org/2025/991</guid>
<content:encoded><![CDATA[
The advent of Large Language Models (LLM) has brought about a new wave productivity, revolutionizing business operations while keeping cost relatively low. The human-like interface of LLM enables it to be easily integrated with business functions, thereby freeing up precious human resources for more complex, valuable tasks. However, due to the intensive computation and memory requirements of LLM inference, it is preferable and cheaper to deploy LLMs with the Cloud Service Providers (CSP) that offer high performance computation resources and low-latency networking. Nevertheless, privacy concerns have been raised about the possibility of data leakage to the CSP. In this work, we seek to address such privacy concerns through the use of Fully Homomorphic Encryption (FHE). FHE enables the CSP to work on data in its encrypted form, thus ensuring that the data stay private and secure. We propose the implementation of LLM inference with FHE. While a series of prior work have demonstrated that it is possible to execute LLM inference in a private manner, it remains a challenge to design a solution that is practical.
Our contributions are as follows: We provide the first end-to-end open-source implementation of a non-interactive transformer inference with FHE. We report an amortized time of 9.6 minutes of one input with 128 tokens when evaluating the BERT model on CPU. Our packing methods for encrypted matrices remove the need to repack ciphertext between encrypted matrix multiplication and activation layers. Additionally, we introduce interleaved batching to eliminate the internal rotations during ciphertext matrix multiplications. Our approach also avoids HE rotations in evaluations of the softmax and layerNorm, leading to a speedup of 4.22× and 122× than existing works respectively. Our implementation supports arbitrary token lengths, in contrast with existing solutions that requires a full token embedding. Our implementation can be found at GitHub.
]]></content:encoded>
<pubDate>Thu, 29 May 2025 05:30:53 +0000</pubDate>
</item>
<item>
<title>OptAttest: Verifying Multi-List Multi-Hop History via a Hybrid Zero-Knowledge Architecture</title>
<link>https://eprint.iacr.org/2025/974</link>
<guid>https://eprint.iacr.org/2025/974</guid>
<content:encoded><![CDATA[
To prevent privacy-preserving digital assets from becoming instruments of despotism via unitary-executivist compliance regimes, we propose OptAttest, a hybrid zero-knowledge architecture. This system empowers users to optionally generate verifiable attestation history for the current (Hop 0) and immediately preceding (Hop 1) transactions involving their private commitments. For crucial 0-hop multi-list attestations, users employ Zero-Knowledge Proofs (ZKPs) of claims from selected Verifiable Credentials (VCs). Users achieve per-transaction efficiency with diverse VC types by pre-computing and caching proofs of their VC validity. This approach avoids mandated adherence to singular, fallible external standards. Opted-in lightweight updates create cryptographic accumulator summaries, verified by network infrastructure (e.g., Layer 2 scaling solutions using Zero-Knowledge Virtual Machines), and are paired with user-managed Intermediate Attestation Data Packets (IADPs) containing detailed evidence. For comprehensive verification, users can then generate full recursive proofs from these IADPs for their attestation-enabled funds, leveraging native zkVM recursion. The protocol facilitates optional attestation generation, not enforcement, allowing downstream policy application. Aiming to cultivate a permissionless ethos, we propose a user-centric balance between privacy and verifiable accountability, distinct from models compelling broader data access. Folding schemes are noted as potential future enhancements for recursive proof efficiency.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 08:42:32 +0000</pubDate>
</item>
<item>
<title>How Does Satoshi Set His Clock? Full Analysis of Nakamoto Consensus</title>
<link>https://eprint.iacr.org/2020/277</link>
<guid>https://eprint.iacr.org/2020/277</guid>
<content:encoded><![CDATA[
Nakamoto consensus, arguably the most exciting development in decentralized computation in the last few years, is in a sense a recasting of the traditional state machine replication problem in an unauthenticated setting, where furthermore parties come and go without warning. The protocol relies on a cryptographic primitive known as proof of work (PoW) which is used to throttle message passing. Importantly, the PoW diﬃculty level is appropriately adjusted throughout the course of the protocol execution relying on the blockchain’s timekeeping ability.

While the original formulation was only accompanied by rudimentary analysis, significant and steady progress has been made in abstracting the protocol’s properties and providing a formal analysis under various restrictions and protocol simplifications. Still, a full analysis of the protocol that includes its PoW target value recalculation and, notably, its timestamp adjustment mechanism, which equip it to operate in its intended setting of bounded communication delays, imperfect clocks and dynamic participation, has remained open. (Specifically, the protocol allows incoming block timestamps in the near future, as determined by a protocol parameter, and rejects blocks that have a timestamp in the past of the median time of a specific number of blocks on-chain [namely, 11].)

The gap is that Nakamoto’s protocol fundamentally depends on the blockchain itself to be a consistent timekeeper that should advance roughly on par with real time. In order to tackle this question we introduce a new analytical tool we call `hot-hand executions,' which capture the regular occurrence of high concentration of honestly generated blocks, and correspondingly put forth and prove a new blockchain property called `concentrated chain quality,' which may be of independent interest. Utilizing these tools and techniques we demonstrate that Nakamoto’s protocol achieves, under suitable conditions, consistency, liveness as well as (consistent) timekeeping.
]]></content:encoded>
<pubDate>Wed, 04 Mar 2020 08:11:05 +0000</pubDate>
</item>
<item>
<title>On Proving Equivalence Class Signatures Secure from Non-interactive Assumptions</title>
<link>https://eprint.iacr.org/2025/973</link>
<guid>https://eprint.iacr.org/2025/973</guid>
<content:encoded><![CDATA[
Equivalence class signatures (EQS), introduced by Hanser
and Slamanig (AC’14, J.Crypto’19), sign vectors of elements from a bi-
linear group. Their main feature is “adaptivity”: given a signature on a
vector, anyone can transform it to a (uniformly random) signature on any
multiple of the vector. A signature thus authenticates equivalence classes
and unforgeability is defined accordingly. EQS have been used to improve
the efficiency of many cryptographic applications, notably (delegatable)
anonymous credentials, (round-optimal) blind signatures, group signa-
tures and anonymous tokens. EQS security implies strong anonymity
(or blindness) guarantees for these schemes which hold against malicious signers without trust assumptions.

Unforgeability of the original EQS construction is proven directly in
the generic group model. While there are constructions from standard
assumptions, these either achieve prohibitively weak security notions
(PKC’18) or they require a common reference string (AC’19, PKC’22),
which reintroduces trust assumptions avoided by EQS.

In this work we ask whether EQS schemes that satisfy the original secu-
rity model can be proved secure under standard (or even non-interactive)
assumptions with standard techniques. Our answer is negative: assum-
ing a reduction that, after running once an adversary breaking unforge-
ability, breaks a non-interactive computational assumption, we construct
efficient meta-reductions that either break the assumption or break class-
hiding, another security requirement for EQS.
]]></content:encoded>
<pubDate>Wed, 28 May 2025 07:47:44 +0000</pubDate>
</item>
<item>
<title>Sabot: Efficient and Strongly Anonymous Bootstrapping of Communication Channels</title>
<link>https://eprint.iacr.org/2025/971</link>
<guid>https://eprint.iacr.org/2025/971</guid>
<content:encoded><![CDATA[
Anonymous communication is vital for enabling individuals to participate in social discourse without fear of marginalization or persecution. An important but often overlooked part of anonymous communication is the bootstrapping of new communication channels, generally assumed to occur out-of-band. However, if the bootstrapping discloses metadata, communication partners are revealed even if the channel itself is fully anonymized. We propose Sabot, the first anonymous bootstrapping protocol that achieves both strong cryptographic privacy guarantees and bandwidth-efficient communication. In Sabot, clients cooperatively generate a private relationship matrix, which encodes who wants to contact whom. Clients communicate with k ≥ 2 servers to obtain “their” part of the matrix and augment the received information using Private Information Retrieval (PIR) to learn about their prospective communication partners. Compared to previous solutions, Sabot achieves stronger privacy guarantees and reduces the bandwidth overhead by an order of magnitude.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 19:46:48 +0000</pubDate>
</item>
<item>
<title>Decentralized Data Archival: New Definitions and Constructions</title>
<link>https://eprint.iacr.org/2025/969</link>
<guid>https://eprint.iacr.org/2025/969</guid>
<content:encoded><![CDATA[
We initiate the study of a new abstraction 
called incremental decentralized data archival (${\sf iDDA}$). 
Specifically, imagine that there is an ever-growing, massive database such as a blockchain, a comprehensive  human knowledge base like Wikipedia,  or the Internet archive.  We want to build a decentralized archival of such datasets 
to ensure long-term robustness and sustainability.  

We identify several important properties
that an ${\sf iDDA}$ scheme should satisfy. First, 
to promote heterogeneity and decentralization, 
we want to encourage even weak nodes  with limited space (e.g., users' home computers) to contribute.  The minimum space requirement to contribute should be approximately independent of the data size.   Second, if a collection of nodes together receive rewards commensurate with contributing a total of $m$ blocks of space, then we want the following reassurances:  1) if $m$ is at least the database size, we should be able to reconstruct the entire dataset; and 2)  these nodes should actually be commiting roughly $m$ space in aggregate --- even when $m$ is much larger than the data size,  the nodes should be storing redundant copies of the database rather than storing just one copy, and yet impersonating arbitrarily many pseudonyms to get unbounded rewards.  

We propose new definitions  that mathematically formalize the aforementioned requirements of an ${\sf iDDA}$ scheme. 
We also devise an efficient construction in the random oracle model which satisfies the desired security requirements.   Our scheme incurs  only $\widetilde{O}(1)$ audit cost, as well as  $\widetilde{O}(1)$ update cost for both the publisher and each node, where $\widetilde{O}(\cdot)$ hides polylogarithmic factors. Further, the minimum space provisioning required to contribute is as small as polylogarithmic. 

Our construction exposes several interesting technical challenges. Specifically, we show that a straightforward application of the standard hierarchical data structure fails, since both our security definition and  the underlying cryptographic primitives we employ lack the desired compositional  guarantees. We devise novel techniques to overcome these compositional issues, resulting in a construction with provable security while still retaining efficiency. Finally, our new definitions also make a conceptual contribution, and lay the theoretical groundwork for the study of ${\sf iDDA}$.   We raise several interesting open problems along this direction.
]]></content:encoded>
<pubDate>Tue, 27 May 2025 17:06:25 +0000</pubDate>
</item>
<item>
<title>TOOP: A transfer of ownership protocol over Bitcoin</title>
<link>https://eprint.iacr.org/2025/964</link>
<guid>https://eprint.iacr.org/2025/964</guid>
<content:encoded><![CDATA[
The Transfer of Ownership Protocol (TOOP) enables a secure transfer of assets from Bitcoin to other blockchains and back. This is achieved through a committee-based validation protocol that requires only 1-out-of-nhonest security. The protocol operates in distinct phases: the lock phase, where the initial setup and individual assets are locked on Bitcoin, and the unlocking with ownership transfer phase, where the asset is transferred to a possibly different legitimate owner. This protocol solves a limitation of all existing BitVM-like protocols that restricts the unlocking transfers to only addresses known and preregistered during lock and setup. Accordingly, our protocol avoids the financially costly, regulatory problematic, and congestion-prone front-and-reimburse paradigm. TOOP has been implemented for the first time in Cardinal, a protocol for wrapping Bitcoin Unspent Transaction Outputs (UTxOs) onto the Cardano blockchain, with Bitcoin Ordinals represented as Cardano Non-Fungible Tokens (NFTs).
]]></content:encoded>
<pubDate>Tue, 27 May 2025 02:40:40 +0000</pubDate>
</item>
<item>
<title>Accountable Light Client Systems for Proof-of-Stake Blockchains</title>
<link>https://eprint.iacr.org/2022/1205</link>
<guid>https://eprint.iacr.org/2022/1205</guid>
<content:encoded><![CDATA[
A major challenge for blockchain interoperability is having an on-chain light client protocol that is both efficient and secure. We present a protocol that provides short proofs about the state of a decentralised consensus protocol while being able to detect misbehaving parties. To do this naively, a verifier would need to maintain an updated list of all participants' public keys which makes the corresponding proofs long. In general, existing solutions either lack accountability or are not efficient. We define and design a committee key scheme with short proofs that do not include any of the individual participants' public keys in plain. Our committee key scheme, in turn, uses a custom designed SNARK which has a fast prover time. Moreover, using our committee key scheme, we define and design an accountable light client system as the main cryptographic core for building bridges between proof of stake blockchains. Finally, we implement a prototype of our custom SNARK for which we provide benchmarks.
]]></content:encoded>
<pubDate>Mon, 12 Sep 2022 23:36:40 +0000</pubDate>
</item>
<item>
<title>LEAF: A Low-Latency Evaluation Architecture for Feedforward Block in Privacy-Preserving Transformer Inference</title>
<link>https://eprint.iacr.org/2025/956</link>
<guid>https://eprint.iacr.org/2025/956</guid>
<content:encoded><![CDATA[
Fully homomorphic encryption (FHE) is an appealing and promising solution for privacy-preserving transformer inference to protect users' privacy. However, the huge computational overhead makes it unrealistic to apply FHE in real-world transformers for large language models (LLM). Current FHE-based approaches to secure transformer inference face significant performance challenges, with total latency exceeding 5 hours for 32-input batches.
The feedforward block, comprising a large-scale matrix multiplication followed by a GELU evaluation, is widely recognized as one of the most computationally intensive components in privacy-preserving transformer inference. In the state-of-the-art system NEXUS, evaluating the feedforward block incurs a total latency of 5,378 seconds, processing up to 32 inputs per batch. 
We aim to reduce the latency and propose LEAF, a low-latency evaluation architecture for the feedforward block. LEAF introduces a novel combination of fast matrix multiplication and an asymptotically efficient algorithm for computing non-polynomial activations. When evaluated on the BERT-base model, LEAF reduces total latency to 53.4 seconds, offering a $100\times$ speedup over the state-of-the-art method in the same environment. Our implementations are available.
]]></content:encoded>
<pubDate>Mon, 26 May 2025 07:16:29 +0000</pubDate>
</item>
<item>
<title>Breaking Poseidon Challenges with Graeffe  Transforms and Complexity Analysis by FFT  Lower Bounds</title>
<link>https://eprint.iacr.org/2025/950</link>
<guid>https://eprint.iacr.org/2025/950</guid>
<content:encoded><![CDATA[
Poseidon and Poseidon2 are cryptographic hash functions designed for efficient zero-knowledge proof protocols and have been widely adopted in Ethereum applications. To encourage security research, the Ethereum Foundation announced a bounty program in November 2024 for breaking the Poseidon challenges, i.e. solving the CICO (Constrained Input, Constrained Output) problems for round-reduced Poseidon constructions. In this paper, we explain how to apply the Graeffe transform to univariate polynomial solving, enabling efficient interpolation attacks against Poseidon. We will provide an open-source code and details our approach for solving several challenges valued at $20000 in total. Compared to existing attacks, we improves 2^{13} and 2^{4.5} times in wall time and memory usage, respectively. For all challenges we solved, the cost of memory access turns out to be an essential barrier, which makes the security margin much larger than expected. We actually prove that the memory access cost for FFT grows as the 4/3-power of the input size, up to a logarithmic factor. This indicates the commonly used pseudo linear estimate may be overly conservative. This is very different from multivariate equation solving whose main bottleneck is linear algebra over finite fields. Thus, it might be preferable to choose parameters such that the best known attack is interpolation, as it presents more inherent hardness.
]]></content:encoded>
<pubDate>Sun, 25 May 2025 03:08:44 +0000</pubDate>
</item>
<item>
<title>On the (in)security of Proofs-of-Space based Longest-Chain Blockchains</title>
<link>https://eprint.iacr.org/2025/942</link>
<guid>https://eprint.iacr.org/2025/942</guid>
<content:encoded><![CDATA[
The Nakamoto consensus protocol underlying the Bitcoin blockchain uses proof of work as a voting mechanism. Honest miners who contribute hashing power towards securing the chain try to extend the longest chain they are aware of. Despite its simplicity, Nakamoto consensus achieves meaningful security guarantees assuming that at any point in time, a majority of the hashing power is controlled by honest parties. This also holds under ``resource variability'', i.e., if the total hashing power varies greatly over time.

Proofs of space (PoSpace) have been suggested as a more sustainable replacement for proofs of work. Unfortunately, no construction of a ``longest-chain'' blockchain based on PoSpace, that is secure under dynamic availability, is known. In this work, we prove that without additional assumptions no such protocol exists. We exactly quantify this impossibility result by proving a bound on the length of the fork required for double spending as a function of the adversarial capabilities. This bound holds for any chain selection rule, and we also show a chain selection rule (albeit a very strange one) that almost matches this bound.  

Concretely, we consider a security game in which the honest parties at any point control $\phi>1$ times more space than the adversary. The adversary can change the honest space by a factor $1\pm \varepsilon$ with every block (dynamic availability), and ``replotting'' the space (which allows answering two challenges using the same space) takes as much time as $\rho$ blocks.

We prove that no matter what chain selection rule is used, in this game the adversary can create a fork of length $\phi^2\cdot \rho / \varepsilon$ that will be picked as the winner by the chain selection rule.

We also provide an upper bound that matches the lower bound up to a factor $\phi$. There exists a chain selection rule (albeit a very strange one) which in the above game requires forks of length at least $\phi\cdot \rho / \varepsilon$.



Our results show the necessity of additional assumptions to create a secure PoSpace based longest-chain blockchain. The Chia network in addition to PoSpace uses a verifiable delay function. 
Our bounds show that an additional primitive like that is necessary.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 14:58:30 +0000</pubDate>
</item>
<item>
<title>Attacking Poseidon via Graeffe-Based Root-Finding over NTT-Friendly Fields</title>
<link>https://eprint.iacr.org/2025/937</link>
<guid>https://eprint.iacr.org/2025/937</guid>
<content:encoded><![CDATA[
This paper explores the algebraic structure of the Poseidon and Poseidon2 permutations
over NTT-friendly finite fields, with a focus on preimage recovery via root-finding
techniques. We introduce an algorithm for efficiently identifying single roots of high-degree
univariate polynomials that emerge from these constructions, based on the Graeffe transform
and the tangent Graeffe method. Our approach is evaluated on reduced-round bounty
instances of these permutations at various security levels, as proposed by the Ethereum
Foundation, demonstrating practical effectiveness. These results yield new insights into the
security of permutation-based cryptographic primitives instantiated over NTT-friendly prime
fields.
]]></content:encoded>
<pubDate>Fri, 23 May 2025 07:24:02 +0000</pubDate>
</item>
<item>
<title>SEEC: Memory Safety Meets Efficiency in Secure Two-Party Computation</title>
<link>https://eprint.iacr.org/2025/930</link>
<guid>https://eprint.iacr.org/2025/930</guid>
<content:encoded><![CDATA[
Secure Multi-Party Computation (MPC) allows multiple parties to perform privacy-preserving computation on their secret data.  MPC protocols based on secret sharing have high throughput which makes them well-suited for batch processing, where multiple instances are evaluated in parallel. 
So far, practical implementations of secret sharing-based MPC protocols mainly focus on runtime and communication efficiency, so the memory overhead of protocol implementations is often overlooked. Established techniques to reduce the memory overhead for constant-round garbled circuit protocols cannot be directly applied to secret sharing-based protocols because they would increase the round complexity. Additionally, state-of-the-art implementations of secret sharing-based MPC protocols are implemented in C/C++ and may exhibit memory unsafety and memory leaks, which could lead to undefined behavior.

In this paper, we present SEEC: SEEC Executes Enormous Circuits, a framework for secret sharing-based MPC 
with a novel approach to address memory efficiency and safety without compromising on runtime and communication efficiency. We realize SEEC in Rust, a language known for memory-safety at close-to-native speed. To reduce the memory footprint, we develop an in-memory representation for sub-circuits. Thus, we never inline sub-circuit calls during circuit evaluation, a common issue that blows up memory usage in MPC implementations. 
We compare SEEC with the state-of-the-art secret sharing-based MPC frameworks ABY (NDSS'15), MP-SPDZ (CCS'20), and MOTION (TOPS'22) w.r.t. runtime, memory, and communication efficiency. Our results show that our reliable and memory-safe implementation has competitive or even better performance.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 09:42:45 +0000</pubDate>
</item>
<item>
<title>The DROP Protocol: Dispute Resolution via Observation in Public for Verifiable, In-Person Voting</title>
<link>https://eprint.iacr.org/2025/929</link>
<guid>https://eprint.iacr.org/2025/929</guid>
<content:encoded><![CDATA[
Dispute resolution has been a significant challenge in verifiable election protocols since such protocols were first proposed more than forty years ago. This work explores the problem from a new perspective and offers strong dispute resolution for in-person voting by depending on observers.

It proposes a simple definition of dispute resolution as a property of a voting protocol---a definition that is independent of any other security goal. It also presents the DROP protocol, a verifiable, in-person voting protocol that runs in the presence of observers who will always reach a correct conclusion in the case of a dispute without ever being able to compromise privacy or facilitate coercion.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 09:01:01 +0000</pubDate>
</item>
<item>
<title>Zero-knowledge Authenticator for Blockchain: Policy-private and Obliviously Updateable</title>
<link>https://eprint.iacr.org/2025/921</link>
<guid>https://eprint.iacr.org/2025/921</guid>
<content:encoded><![CDATA[
Transaction details and participant identities on the blockchain are often publicly exposed. In this work, we posit that blockchain's transparency should not come at the cost of privacy. To that end, we introduce zero-knowledge authenticators (zkAt), a new cryptographic primitive for privacy-preserving authentication on public blockchains. zkAt utilizes zero-knowledge proofs to enable users to authenticate transactions, while keeping the underlying authentiction policies private. 

Prior solutions for such {policy-private authentication} required the use of threshold signatures, which can only hide the threshold access structure itself. In comparison, zkAt provides privacy for arbitrarily complex authentication policies, and offers a richer interface even within the threshold access structure by, for instance, allowing for the combination of signatures under distinct signature schemes.

In order to construct zkAt, we design a compiler that transforms the popular Groth16 non-interactive zero knowledge (NIZK) proof system into a NIZK with equivocable verification keys, a property that we define in this work. Then, for any zkAt constructed using proof systems with this new property, we show that all public information must be independent of the policy, thereby achieving policy-privacy.

Next, we give an extension of zkAt, called zkAt+ wherein, assuming a trusted authority, policies can be updated obliviously in the sense that a third-party learns no new information when a policy is updated by the policy issuer. We also give a theoretical construction for zkAt+ using recursive NIZKs, and explore the integration of zkAt into modern blockchains. Finally, to evaluate their feasibility, we implement both our schemes for a specific threshold access structure. Our findings show that zkAt achieves comparable performance to traditional threshold signatures, while also attaining privacy for significantly more complex policies with very little overhead.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 05:34:51 +0000</pubDate>
</item>
<item>
<title>Rep3 Reloaded: On the Cost of Function-Dependent Preprocessing in Semi-Honest 3PC with Honest Majority</title>
<link>https://eprint.iacr.org/2025/919</link>
<guid>https://eprint.iacr.org/2025/919</guid>
<content:encoded><![CDATA[
Rep3 denotes the implementation of semi-honest three-party computation with an honest majority in MP-SPDZ (CCS'20). It uses replicated secret sharing with one message per multiplication and party as proposed by Araki et al. (CCS'16). This approach is rivaled by Astra (CCSW'19) and Trio (PETS'25), which use function-dependent preprocessing. The latter is more involved than, e.g., Beaver triples which can be used as a commodity.

In this work, we present a full implementation of Astra and Trio in MP-SPDZ, and we evaluate the costs of the different approaches. We show the equivalence of the schemes, which implies that a protocol in any of the schemes can be translated to one in another with the same overall communication cost. We also present an improvement to two important building blocks for privacy-preserving computation, namely secure comparison and probabilistic truncation used in fixed-point arithmetic. To evaluate our implementation, we have benchmarked machine learning training and inference in all three schemes, improving on Keller and Sun (ICML'22) by over 30%. Our implementation also highlights the large storage requirements of function-dependent preprocessing as it runs the two phases separately. To the best of our knowledge, this is the first implementation to do so.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 03:02:09 +0000</pubDate>
</item>
<item>
<title>The Accidental Computer: Polynomial Commitments from Data Availability</title>
<link>https://eprint.iacr.org/2025/918</link>
<guid>https://eprint.iacr.org/2025/918</guid>
<content:encoded><![CDATA[
In this paper, we show two simple variations of a data availability scheme which enable it to act as a multilinear polynomial commitment scheme over the data in a block. The first variation enables commitments over all of the block's data with zero prover overhead: the data availability construction simply serves both purposes. The second variation allows commitments over subsets of data with nonzero but still concretely small proving costs, since most work is already done during data encoding. This works especially well for blockchains with a high degree of data parallelism, as data-parallel computation is particularly amenable to efficient GKR proofs. Since, in GKR, opening the polynomial commitment contributes significantly to prover costs, our construction enables the prover to reuse work already done by the data availability scheme, reducing—or wholly removing—work associated with the polynomial commitment scheme.
]]></content:encoded>
<pubDate>Thu, 22 May 2025 00:46:09 +0000</pubDate>
</item>
<item>
<title>Automated Verification of Consistency in Zero-Knowledge Proof Circuits</title>
<link>https://eprint.iacr.org/2025/916</link>
<guid>https://eprint.iacr.org/2025/916</guid>
<content:encoded><![CDATA[
Circuit languages like Circom and Gnark have become essential tools for programmable zero-knowledge cryptography,  allowing developers to build privacy-preserving applications. These domain-specific languages (DSLs) encode both the computation to be verified (as a witness generator) and the corresponding arithmetic circuits, from which the prover and verifier can be automatically generated.   However, for these programs to be correct, the witness generator and the arithmetic circuit need to be mutually consistent in a certain technical sense, and inconsistencies can result in security vulnerabilities. This paper formalizes the consistency requirement for circuit DSLs and proposes the first automated technique for verifying it. We evaluate the method on hundreds of real-world circuits, demonstrating its utility for both automated verification and uncovering errors that existing tools are unable to detect.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 22:40:21 +0000</pubDate>
</item>
<item>
<title>Enforcing arbitrary constraints on Bitcoin transactions</title>
<link>https://eprint.iacr.org/2025/912</link>
<guid>https://eprint.iacr.org/2025/912</guid>
<content:encoded><![CDATA[
The challenge of enforcing constraints on Bitcoin transac-
tions has recently gained a lot of attention. The current approach to
solve this problem falls short in certain aspects, such as privacy and
programmability. We design a new solution that leverages zkSNARKs
and allows enforcing arbitrary constraints on Bitcoin transactions while
maintaining some information private. Our approach also bypasses the
non-Turing completeness of Bitcoin Script, allowing the enforcement of
unbounded constraints, namely constraints that repeat a certain opera-
tion an unbounded number of times.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 10:47:25 +0000</pubDate>
</item>
<item>
<title>Covert Attacks on Machine Learning Training in Passively Secure MPC</title>
<link>https://eprint.iacr.org/2025/906</link>
<guid>https://eprint.iacr.org/2025/906</guid>
<content:encoded><![CDATA[
Secure multiparty computation (MPC) allows data owners to train machine learning models on combined data while keeping the underlying training data private. The MPC threat model either considers an adversary who passively corrupts some parties without affecting their overall behavior, or an adversary who actively modifies the behavior of corrupt parties. It has been argued that in some settings, active security is not a major concern, partly because of the potential risk of reputation loss if a party is detected cheating.

In this work we show explicit, simple, and effective attacks that an active adversary can run on existing passively secure MPC training protocols, while keeping essentially zero risk of the attack being detected. The attacks we show can compromise both the integrity and privacy of the model, including attacks reconstructing exact training data.
Our results challenge the belief that a threat model that does not include malicious behavior by the involved parties may be reasonable in the context of PPML, motivating the use of actively secure protocols for training.
]]></content:encoded>
<pubDate>Wed, 21 May 2025 00:59:57 +0000</pubDate>
</item>
<item>
<title>A Generic Framework for Practical Lattice-Based Non-interactive Publicly Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/901</link>
<guid>https://eprint.iacr.org/2025/901</guid>
<content:encoded><![CDATA[
Non-interactive publicly verifiable secret sharing (PVSS) schemes enable the decentralized (re-)sharing of secrets in adversarial environments, allowing anyone to verify the correctness of distributed shares. Such schemes are essential for large-scale decentralized applications, including committee-based systems that require both transparency and robustness. However, existing PVSS schemes rely on group-based cryptography, resulting them vulnerable to quantum attacks and limiting their suitability for post-quantum applications.

In this work, we propose the first practical, fully lattice-based, non-interactive PVSS scheme, grounded on standard lattice assumptions for post-quantum security. At the heart of our design is a generic framework that transforms vector commitments and linear encryption schemes into efficient PVSS protocols. We enhance vector commitments by incorporating functional hiding and proof of smallness, ensuring that encrypted shares are both verifiable and privacy-preserving. Our construction introduces two tailored lattice-based encryption schemes, each supporting efficient proofs of decryption correctness. This framework provides strong verifiability guarantees while maintaining low proof sizes and computational efficiency, making it suitable for systems with large numbers of participants.
]]></content:encoded>
<pubDate>Tue, 20 May 2025 16:24:57 +0000</pubDate>
</item>
<item>
<title>Blinding Post-Quantum Hash-and-Sign Signatures</title>
<link>https://eprint.iacr.org/2025/895</link>
<guid>https://eprint.iacr.org/2025/895</guid>
<content:encoded><![CDATA[
Blind signature schemes are essential for privacy-preserving applications such as electronic voting, digital currencies or anonymous credentials. In this paper, we revisit Fischlin's framework for round-optimal blind signature schemes and its recent efficient lattice-based instantiations. Our proposed framework compiles any post-quantum hash-and-sign signature scheme into a blind signature scheme. The resulting scheme ensures blindness by design and achieves one-more unforgeability, relying solely on the unforgeability of the underlying signature scheme and the random oracle model.

To achieve this we introduce the notion of commit-append-and-prove (CAP) systems, which generalizes traditional commit-and-prove system by making their commitments updatable before proving. This building block allows us to unlock the technical challenges encountered when generalizing previous variants of the Fischlin's framework to any hash-and-sign signature scheme. We provide efficient CAP system instantiations based on recent MPC-in-the-Head techniques.

We showcase our framework by constructing blind versions of UOV and Wave, thereby introducing the first practical blind signatures based on multivariate cryptography and code-based cryptography. Our blind UOV signatures range from 3.8 KB to 11 KB, significantly outperforming previous post-quantum blind signatures, such as the 22 KB lattice-based blind signatures, which were the most compact until now.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 16:22:39 +0000</pubDate>
</item>
<item>
<title>Practical cryptanalysis of pseudorandom correlation generators based on quasi-Abelian syndrome decoding</title>
<link>https://eprint.iacr.org/2025/892</link>
<guid>https://eprint.iacr.org/2025/892</guid>
<content:encoded><![CDATA[
Quasi-Abelian Syndrome Decoding (QA-SD) is a recently in-
troduced generalization of Ring-LPN that uses multivariate polynomials
rings. As opposed to Ring-LPN, it enables the use of small finite field such as GF(3) and GF(4). It was introduced by Bombar et al (Crypto 2023) in order to obtain pseudorandom correlation generators for Beaver triples over small fields. This theoretical work was turned into a concrete and efficient protocol called F4OLEage by Bombar et al. (Asiacrypt 2024) that allows several parties to generate Beaver triples over GF(2).

We propose efficient algorithms to solve the decoding problem underlying
the QA-SD assumption. We observe that it reduce to a sparse multivariate polynomial interpolation problem over a small finite field where the
adversary only has access to random evaluation points, a blind spot in
the otherwise rich landscape of sparse multivariate interpolation. We develop new algorithms for this problem: using simple techniques we interpolate polynomials with up to two monomials. By sending the problem
to the field of complex numbers and using convex optimization techniques inspired by the field of “compressed sensing”, we can interpolate
polynomials with more terms.

This enables us to break in practice parameters proposed by Bombar et
al. at Crypto’23 and Asiacrypt’24 as well as Li et al. at Eurocrypt’25
(IACR flagship conferences Grand Slam). In the case of the F4OLEage
protocol, our implementation recovers all the secrets in a few hours with
probability 60%. This not only invalidates the security proofs, but it
yields real-life privacy attacks against multiparty protocols using the
Beaver triples generated by the broken pseudorandom correlation generators.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 11:54:59 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure Blockchain-Aided Decentralized Storage Networks: Formalization and Generic Construction</title>
<link>https://eprint.iacr.org/2025/887</link>
<guid>https://eprint.iacr.org/2025/887</guid>
<content:encoded><![CDATA[
This work revisits the current Decentralized Storage Network (DSN) definition to propose a novel general construction based on a UTxO based ledger. To the best of our knowledge, this is the first adaptively secure UTxO blockchain-aided DSN. More concretely, we revisit the currently existing designs to thoroughly formalize the DSN definition and its security. Moreover we present a general construction, which a client delegates data to a DSN that keeps custody of it during a jointly agreed period. Our newly proposed approach, leveraged by the Extended UTxO (EUTxO) Model, neatly allows the storage network to offer automatic verifiability, i.e., without any interaction of the data owner, via proofs published in the blockchain.  In summary, this work presents a redesign of the DSN with the aid of a EUTxO based blockchain, by (1) putting forth a formal and rigorous description of a blockchain-aided DSN protocol, (2) offering a thorough description of a practical EUTxO based DSN, and (3) detailing a security analysis showing that our protocol is adaptively secure by providing (rational) security guarantees.
]]></content:encoded>
<pubDate>Mon, 19 May 2025 03:36:59 +0000</pubDate>
</item>
<item>
<title>$k$-out-of-$n$ Proofs and Application to Privacy-Preserving Cryptocurrencies</title>
<link>https://eprint.iacr.org/2025/884</link>
<guid>https://eprint.iacr.org/2025/884</guid>
<content:encoded><![CDATA[
Cryptocurrencies enable transactions among mutually distrustful users, necessitating strong privacy, namely, concealing both transfer amounts and participants' identities, while maintaining practical efficiency. While UTXO-based cryptocurrencies offer mature solutions achieving strong privacy and supporting multi-receiver transfers, account-based cryptocurrencies currently lack practical solutions that simultaneously guarantee these properties.

With the aim to close this gap, we propose a generic framework for account-based cryptocurrencies that achieve strong  privacy and support multi-receiver transfers, and then give a practical instantiation called \textit{Anonymous PGC}. Experimental results demonstrate that, for a 64-sized anonymity set and 8 receivers, Anonymous PGC outperforms Anonymous Zether (IEEE S\&amp;P 2021) --- which offers limited anonymity and no multi-receiver support --- 
achieving 2.6$\times$ faster transaction generation, 5.1$\times$ faster verification, 
and 2.1$\times$ reduction in transaction size. 


Along the way of building Anonymous PGC, we present two novel $k$-out-of-$n$ proofs. First, we generalize the Groth-Kohlweiss (GK) $1$-out-of-$n$ proof (EUROCRYPT 2015) to the $k$-out-of-$n$ case, resolving an open problem of its natural generalization. Particularly, the obtained $k$-out-of-$n$ proof lends itself to integrate with range proofs in a seamless way, yielding an efficient $k$-out-of-$n$ range proof, which demonstrates that $k$ witnesses among $n$ instances lie in specific ranges. Second, we extend the Attema-Cramer-Fehr (ACF) $k$-out-of-$n$ proof (CRYPTO 2021) to support distinct group homomorphisms, improving its expressiveness while reducing both prover and verifier complexities from quadratic to linear. We believe these two $k$-out-of-$n$ proofs are of independent interest, and will find more applications in privacy-preserving scenarios.
]]></content:encoded>
<pubDate>Sat, 17 May 2025 15:58:11 +0000</pubDate>
</item>
<item>
<title>Papercraft: Lattice-based Verifiable Delay Function Implemented</title>
<link>https://eprint.iacr.org/2025/879</link>
<guid>https://eprint.iacr.org/2025/879</guid>
<content:encoded><![CDATA[
A verifiable delay function (VDF) requires a specified number of sequential steps to compute, yet the validity of its output can be verified efficiently, much faster than recomputing the function from scratch. VDFs are a versatile cryptographic tool, with many industrial applications, such as blockchain consensus protocols, lotteries and verifiable randomness. Unfortunately, without exceptions, all known practical VDF constructions are broken by quantum algorithms. In this work, we investigate the practicality of VDFs with plausible post-quantum security. We propose Papercraft, a working implementation of a VDF based entirely on lattice techniques and thus plausibly post-quantum secure. Our VDF is based on new observations on lattice-based succinct argument systems with many low-level optimisations, yielding the first lattice-based VDF that is implementable on today's hardware. As an example, our Papercraft implementation can verify a computation of almost 6 minutes in just 7 seconds. Overall, our work demonstrates that lattice-based VDFs are not just a theoretical construct, paving the way for their practical deployment.
]]></content:encoded>
<pubDate>Sat, 17 May 2025 04:46:56 +0000</pubDate>
</item>
<item>
<title>Decentralized Multi-Authority Attribute-Based Inner-Product Functional Encryption: Noisy and Evasive Constructions from Lattices</title>
<link>https://eprint.iacr.org/2025/874</link>
<guid>https://eprint.iacr.org/2025/874</guid>
<content:encoded><![CDATA[
We initiate the study of multi-authority attribute-based functional encryption for noisy inner-product functionality, and propose two new primitives: (1) multi-authority attribute-based (noisy) inner-product functional encryption (MA-AB(N)IPFE), and (2) multi-authority attribute-based evasive inner-product functional encryption (MA-ABevIPFE). The MA-AB(N)IPFE primitive generalizes the existing multi-authority attribute-based inner-product functional encryption schemes by Agrawal et al. [AGT21], by enabling approximate inner-product computation under decentralized attribute-based control. This newly proposed notion combines the approximate function evaluation of noisy inner-product functional encryption (IPFE) with the decentralized key-distribution structure of multi-authority attribute-based encryption. To better capture noisy functionalities within a flexible security framework, we formulate the MA-ABevIPFE primitive under a generic-model view, inspired by the evasive IPFE framework by Hsieh et al. [HLL24]. It shifts the focus from pairwise ciphertext indistinguishability to a more relaxed pseudorandomness-based game.

  To support the above notions, we introduce two variants of lattice-based computational assumptions: 
- The evasive IPFE assumption (evIPFE): it generalizes the assumption introduced in [HLL24] to the multi-authority setting and admits a reduction from the evasive LWE assumption proposed by Waters et al. [WWW22];

- The indistinguishability-based evasive IPFE assumption (IND-evIPFE): it is an indistinguishability-based variant of the evasive IPFE assumption designed to capture the stronger security guarantees required by our MA-AB(N)IPFE scheme.

  We present concrete lattice-based constructions for both primitives supporting subset policies, building upon the framework of [WWW22]. Our schemes are proven to be statically secure in the random oracle model under the standard LWE assumption and the newly introduced assumptions. Additionally, we demonstrate that our MA-AB(N)IPFE scheme can be transformed, via standard modulus switching, into a noiseless MA-ABIPFE scheme that supports exact inner-product functionality consistent with the MA-IPFE syntax in [AGT21,DP23]. This yields the first lattice-based construction of such a primitive. All our schemes support arbitrary polynomial-size attribute policies and are secure in the random oracle model under lattice assumptions with a sub-exponential modulus-to-noise ratio, making them practical candidates for noise-tolerant, fine-grained access control in multi-authority settings.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 17:28:06 +0000</pubDate>
</item>
<item>
<title>From List-Decodability to Proximity Gaps</title>
<link>https://eprint.iacr.org/2025/870</link>
<guid>https://eprint.iacr.org/2025/870</guid>
<content:encoded><![CDATA[
Proximity testing for linear codes is a fundamental problem in coding theory with critical applications in cryptographic protocols, blockchain, and distributed storage systems. This work addresses the proximity gaps for linear codes, a crucial aspect for efficiently verifying whether a batch of codewords is close to a given code. We present a general framework for deriving proximity gaps from the list-decodability properties of the underlying linear code.

Our main result shows that if a code $C\subseteq \mathbb{F}_q^n$ is $(p,L)$-list-decodable, then the probability that a random combination of a batch of $t$ codewords containing a $\delta$-far codeword (for $\delta\le 1-\sqrt{1-p+\varepsilon}$) remains $\delta$-far from $C$ is bounded by $O(\frac{tL^2pn}{q}+\frac{t}{\varepsilon q})$. This result also establishes a form of (mutual) correlated agreement for linear codes, which can be used to strengthen soundness analyses in protocols that rely on proximity testing, thereby reducing query complexity and enabling practical instantiations over smaller finite fields.
In particular, we apply our main result to randomly punctured Reed–Solomon codes and folded Reed–Solomon codes—both of which are known to achieve list-decodability up to capacity—and derive linear proximity gaps for these families under the Johnson bound.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 12:11:05 +0000</pubDate>
</item>
<item>
<title>Delegated PSI from Homomorphic Encryptions</title>
<link>https://eprint.iacr.org/2025/868</link>
<guid>https://eprint.iacr.org/2025/868</guid>
<content:encoded><![CDATA[
This paper presents an efficient protocol for private set intersection in a setting with multiple set owners and a semi-honest cloud server. The core idea is to reduce the intersection computation to secure operations over Bloom filters, enabling both scalability and efficiency. By leveraging this transformation, our protocols achieve strong privacy guarantees while minimizing computation and communication overhead.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 10:26:46 +0000</pubDate>
</item>
<item>
<title>Side Channel Analysis in Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/867</link>
<guid>https://eprint.iacr.org/2025/867</guid>
<content:encoded><![CDATA[
Homomorphic encryption provides many opportunities for privacy-aware processing, including with methods related to machine learning. Many of our existing cryptographic methods have been shown in the past to be susceptible to side channel attacks. With these, the implementation of the cryptographic methods can reveal information about the private keys used, the result, or even the original plaintext. An example of this includes the processing of the RSA exponent using the Montgomery method, and where 0's and 1's differ in their processing time for modular exponentiation. With FHE, we typically use lattice methods, and which can have particular problems in their implementation in relation to side channel leakage. This paper aims to outline a range of weaknesses within FHE implementations as related to side channel analysis. It outlines a categorization for side-channel analysis, some case studies, and mitigation strategies.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 09:52:45 +0000</pubDate>
</item>
<item>
<title>Data Availability for Thousands of Nodes</title>
<link>https://eprint.iacr.org/2025/865</link>
<guid>https://eprint.iacr.org/2025/865</guid>
<content:encoded><![CDATA[
Scalable data availability (DA) is essential for high-throughput, decentralized blockchains, enabling lightweight nodes to verify block availability without incurring the prohibitive costs of full data replication. 
Reed-Solomon (RS) code commitment schemes underpin modern DA protocols by ensuring that dispersed data fragments can be verified as part of a valid codeword, even in the presence of malicious block producers. 
However, state-of-the-art schemes such as FRIDA (Crypto'24), while computationally efficient, incur substantial per-node communication overhead at the scale of thousands of network nodes, often 5.7$\times$ the size of the actual data fragment.

In this work, we introduce CONDA, a new interleaved RS code commitment scheme that significantly reduces the communication overhead while retaining FRIDA's prover efficiency. 
At its core is a novel evaluation consolidation technique for polynomial commitment scheme (PCS) that reduces the problem of proving $n$ evaluations at fixed points (one per verifier) to a single evaluation at a random point, using logarithmic communication.
This technique is lightweight, hash-based, and compatible with any multilinear PCS.

To further optimize for DA applications, we introduce LightLigero, a new multilinear PCS that improves upon DeepFold (Sec'25) with $O(\log n)$ reduction in proof size and only $30\%$ slowdown in prover time.
Combining CONDA and LightLigero yields an efficient DA scheme for thousands of nodes. 

Our implementation demonstrates a 4$\times$ reduction in communication cost compared to FRIDA, while incurring only a 25\% increase in prover time. 
It also achieves near-best prover time and near-best communication cost simultaneously among all code commitment schemes.
CONDA also offers at least $3\times$ smaller proofs and $4\times$ faster provers than state-of-the-art verifiable secret sharing constructions such as ZXH+22 (Sec'22) and PolyFRIM (Sec'24).
]]></content:encoded>
<pubDate>Fri, 16 May 2025 05:39:13 +0000</pubDate>
</item>
<item>
<title>Fheanor: a new, modular FHE library for designing and optimising schemes</title>
<link>https://eprint.iacr.org/2025/864</link>
<guid>https://eprint.iacr.org/2025/864</guid>
<content:encoded><![CDATA[
Implementations of modern FHE schemes are available in various highly-optimized libraries. Many of these libraries are designed to allow developers who may not have deep expertise in FHE to build fast and secure privacy-preserving applications. To support such users, the API of these libraries often hides the internals of the schemes in question from the user. However, this design choice makes it hard for users of these libraries to modify existing schemes, or implement new ones; work that is often valuable when conducting research on FHE schemes.
We present our new Rust library Fheanor, which aims to facilitate such research on FHE schemes. The core target user is an FHE researcher, rather than an application developer. Most importantly, the design of Fheanor is very modular, and mirrors the mathematical structure of the available FHE schemes. By exposing the mathematical structure, but still hiding implementation details, it is easy to modify or extend the functionality of FHE schemes implemented in the library and still preserve high performance. Indeed, Fheanor demonstrates performance that is close to that of HElib or SEAL, with the potential for optimizations in the future.
Fheanor implements several features that have not, or have only rarely, been implemented in previous libraries. These include non-power-of-two cyclotomic rings, single-RNS based ring arithmetic, the CLPX/GBFV scheme, and bootstrapping for BFV and BGV. 
In addition, this paper presents new theoretical contributions that are also implemented in Fheanor. The first is an extension of optimal digit extraction circuits, used in BFV/BGV bootstrapping, to the case 2^23. The second is a more efficient algorithm for computing the trace in the non-power-of-two cyclotomic setting.
]]></content:encoded>
<pubDate>Fri, 16 May 2025 02:33:19 +0000</pubDate>
</item>
<item>
<title>sPAR: (Somewhat) Practical Anonymous Router</title>
<link>https://eprint.iacr.org/2025/860</link>
<guid>https://eprint.iacr.org/2025/860</guid>
<content:encoded><![CDATA[
Anonymous communication is one of the fundamental tools to achieve privacy for communication over the internet. Almost all existing design strategies (e.g., onion routing/Tor, mixnets) for anonymous communication rely on the existence of some honest server/router in the network infrastructure to provide anonymity. A recent seminal work by Shi and Wu (Eurocrypt 2021) proposes the first cryptographic design for a non-interactive anonymous router (NIAR) that can use a single untrusted server or router to permute a set of messages without revealing the permutation to the untrusted router. This work is a really important step towards showing the possibility of designing such protocol from standard cryptographic assumptions. However, their construction is only of theoretical nature and still leaves many open questions towards realizing such systems in practice:  (1) the cryptographic building blocks (multi-client functional encryption, correlated pseudorandom function) used in their design are really difficult to implement in practice. (2) Their setup phase takes the permutation as an input to generate the encryption/decryption keys; which means that the messages from the same sender in different rounds will be at the same position in the output vector, unless the setup phase is run before every round with a new permutation. (3) It is not known how to realize such a setup procedure, that initializes a random permutation obliviously, without any trusted entities in the system.

In this paper, we propose the first (somewhat) practical design, which we call sPAR, that solves the above problems using homomorphic encryption techniques. Our design also relies on a one-time setup phase, however the setup phase does not take any specific permutation as input. Instead, our design generates a fresh permutation for every round based on the random values locally generated by the clients. Already existing practical instantiations of fully homomorphic encryption (FHE) schemes make our design implementable and deployable in practice. Our design presents a new direction for designing anonymous communication systems. Unlike some existing systems like Tor, sPAR does not scale to millions of users, however, we demonstrate with a proof-of-concept implementation that sPAR could easily support around hundred users with a few seconds of latency for each message.
]]></content:encoded>
<pubDate>Thu, 15 May 2025 09:00:24 +0000</pubDate>
</item>
<item>
<title>V$\epsilon$rity: Verifiable Local Differential Privacy</title>
<link>https://eprint.iacr.org/2025/851</link>
<guid>https://eprint.iacr.org/2025/851</guid>
<content:encoded><![CDATA[
Local differential privacy (LDP) enables individuals to report sensitive data while preserving privacy. Unfortunately, LDP mechanisms are vulnerable to poisoning attacks, where adversaries controlling a fraction of the reporting users can significantly distort the aggregate output--much more so than in a non-private solution where the inputs are reported directly. In this paper, we present two novel solutions that prevent poisoning attacks under LDP while preserving its privacy guarantees.  
Our first solution, $\textit{V}\epsilon\textit{rity-}{\textit{Auth}}$, addresses scenarios where the users report inputs with a ground truth available to a third party. The second solution, $\textit{V}\epsilon\textit{rity}$, tackles the more challenging case in which the users locally generate their input and there is no ground truth which can be used to bootstrap verifiable randomness generation.
]]></content:encoded>
<pubDate>Wed, 14 May 2025 01:27:17 +0000</pubDate>
</item>
<item>
<title>On Graphs of Incremental Proofs of Sequential Work</title>
<link>https://eprint.iacr.org/2025/848</link>
<guid>https://eprint.iacr.org/2025/848</guid>
<content:encoded><![CDATA[
In this work, we characterize graphs of  \emph{(graph-labeling) incremental proofs of sequential work} (iPoSW). First, we define \emph{incremental} graphs and prove they are necessary for iPoSWs. Relying on space pebbling complexity of incremental graphs, we show that the depth-robust graphs underling the PoSW of Mahmoody et al.\ are not incremental, and hence, their PoSW cannot be transformed into an iPoSW. 

Second, and  toward a generic iPoSW construction, we define graphs whose structure is compatible with the incremental sampling technique (Döttling et al.). These are \emph{dynamic} graphs.  We observe that the graphs underlying all PoSWs, standalone or incremental, are dynamic. We then generalize current iPoSW schemes  by giving a generic construction that transforms any PoSW whose underlying graph is incremental and dynamic into an iPoSW.  As a corollary,  we get a new iPoSW based on the modified Cohen-Pietrzak graph (Abusalah et al.). When used in constructing blockchain light-client bootstrapping protocols (Abusalah et al.) such an iPoSW, results in the most efficient bootstrappers/provers, in terms of both proof size and space complexity.

Along the way, we show that previous iPoSW definitions allow for trivial solutions. To overcome this, we provide a refined definition that captures the essence of iPoSWs and is satisfied by all known iPoSW constructions.
]]></content:encoded>
<pubDate>Tue, 13 May 2025 11:58:04 +0000</pubDate>
</item>
<item>
<title>CTng: Secure Certificate and Revocation Transparency</title>
<link>https://eprint.iacr.org/2021/818</link>
<guid>https://eprint.iacr.org/2021/818</guid>
<content:encoded><![CDATA[
We present CTng, an evolutionary and practical PKI design that efficiently addresses multiple key challenges faced by deployed PKI systems. CTng ensures strong security properties, including guaranteed transparency of certificates and guaranteed, unequivocal revocation, achieved under NTTP-security, i.e., without requiring trust in any single CA, logger, or relying party. These guarantees hold even in the presence of arbitrary corruptions of these entities, assuming only a known bound (f) of corrupt monitors (e.g., f=8), with minimal performance impact.

CTng also enables offline certificate validation and preserves relying-party privacy, while providing scalable and efficient distribution of revocation updates. Furthermore, CTng is post-quantum ready, maintaining efficiency even with high-overhead quantum-secure signature schemes.

These properties significantly improve upon current PKI designs. In particular, while Certificate Transparency (CT) aims to eliminate single points of trust, the existing specification still assumes benign loggers. Addressing this through log redundancy is possible, but rather inefficient, limiting deployed configurations to f ≤ 2.

We present a security analysis and an evaluation of our open-source CTng prototype, showing that it is efficient and scalable under realistic deployment conditions.
]]></content:encoded>
<pubDate>Wed, 16 Jun 2021 13:37:20 +0000</pubDate>
</item>
<item>
<title>Verifiable E-Voting with a Trustless Bulletin Board</title>
<link>https://eprint.iacr.org/2025/841</link>
<guid>https://eprint.iacr.org/2025/841</guid>
<content:encoded><![CDATA[
Voter privacy and end-to-end (E2E) verifiability are critical features of electronic voting (e-voting) systems to safeguard elections. To achieve these properties commonly a perfect bulletin board (BB) is assumed that provides consistent, reliable, and tamper-proof storage and transmission of voting data. However, in practice, BBs operate in asynchronous and unreliable networks, and hence, are susceptible to vulnerabilities such as equivocation attacks and dropped votes, which can compromise both verifiability and privacy. Although prior research has weakened the perfect BB assumption, it still depends on trusting certain BB components.

In this work, we present and initiate a formal exploration of designing e-voting systems based on fully untrusted BBs. For this purpose, we leverage the notion of accountability and in particular use accountable BBs. Accountability ensures that if a security breach occurs, then cryptographic evidence can identify malicious parties. Fully untrusted BBs running in asynchronous networks bring new challenges. Among others, we identify several types of attacks that a malicious but accountable BB might be able to perform and propose a new E2E verifiability notion for this setting. Based on this notion and as a proof of concept, we construct the first e-voting system that is provably E2E verifiable and provides vote privacy  even when the underlying BB is fully malicious. This establishes an alternative to traditional e-voting architectures that rely on (threshold) trusted BB servers.
]]></content:encoded>
<pubDate>Mon, 12 May 2025 12:55:52 +0000</pubDate>
</item>
<item>
<title>BPDTE: Batch Private Decision Tree Evaluation via Amortized Efficient Private Comparison</title>
<link>https://eprint.iacr.org/2024/619</link>
<guid>https://eprint.iacr.org/2024/619</guid>
<content:encoded><![CDATA[
Machine learning as a service requires clients to entrust their information to the server, raising privacy concerns. Private Decision Tree Evaluation (PDTE) are proposal to address these concerns in decision trees, which are fundamental models in machine learning. However, existing solutions perform poorly with massive datasets in real-world applications, therefore, we focus on the batching variant called BPDTE, which supports a single evaluation on multiple data and significantly improves performance.
Firstly, we propose three private comparison (PrivCMP) algorithms that privately compare two numbers to determine which one is larger, by utilizing thermometer encoding and a novel folklore-inspired dichotomy method. These algorithms are non-interactive, batchable, and high-precision, achieving an amortized cost of less than 1 ms at 32-bit precision.
Secondly, we propose six BPDTE schemes based on our PrivCMP and the Clear Rows Relation (CRR) algorithm, introduced to ensure batching security. Experimental results show that our schemes improve amortized efficiency, offer more flexible batch sizes, and achieve higher precision. 
Finally, we provide a formal security analysis of these schemes.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 10:29:07 +0000</pubDate>
</item>
<item>
<title>KeyJoin: Privacy-Focused CoinJoin Protocol for Bitcoin</title>
<link>https://eprint.iacr.org/2025/838</link>
<guid>https://eprint.iacr.org/2025/838</guid>
<content:encoded><![CDATA[
Bitcoin is based on the Blockchain, an open ledger containing information about each transaction in the Bitcoin network. Blockchain serves many purposes, but it allows anyone to track all transactions and activities of each Bitcoin address. The privacy of the network is being threatened by some organizations that track transactions. Tracking and subsequent filtering of coins lead to the loss of exchangeability of Bitcoin.

Despite Bitcoin’s transparency, it is possible to increase user privacy using a variety of existing methods. One of these methods is called CoinJoin, was proposed by Bitcoin developer Greg Maxwell in 2013. This technology involves combining several users transactions to create a single transaction with multiple inputs and outputs, which makes transaction analysis more complicated.

This work describes the KeyJoin, a privacy-focused CoinJoin protocol based on the keyed-verification anonymous credentials (KVAC).
]]></content:encoded>
<pubDate>Sun, 11 May 2025 17:52:06 +0000</pubDate>
</item>
<item>
<title>Conditional disclosure of secrets with quantum resources</title>
<link>https://eprint.iacr.org/2024/630</link>
<guid>https://eprint.iacr.org/2024/630</guid>
<content:encoded><![CDATA[
The conditional disclosure of secrets (CDS) primitive is among the simplest cryptographic settings in which to study the relationship between communication, randomness, and security. CDS involves two parties, Alice and Bob, who do not communicate but who wish to reveal a secret $z$ to a referee if and only if a Boolean function $f$ has $f(x,y)=1$. Alice knows $x,z$, Bob knows $y$, and the referee knows $x,y$. Recently, a quantum analogue of this primitive called CDQS was defined and related to f-routing, a task studied in the context of quantum position-verification. CDQS has the same inputs, outputs, and communication pattern as CDS but allows the use of shared entanglement and quantum messages. We initiate the systematic study of CDQS, with the aim of better understanding the relationship between privacy and quantum resources in the information theoretic setting. We begin by looking for quantum analogues of results already established in the classical CDS literature. Doing so we establish a number of basic properties of CDQS, including lower bounds on entanglement and communication stated in terms of measures of communication complexity. Because of the close relationship to the $f$-routing position-verification scheme, our results have relevance to the security of these schemes.
]]></content:encoded>
<pubDate>Wed, 24 Apr 2024 14:44:51 +0000</pubDate>
</item>
<item>
<title>A Specification of an Anonymous Credential System Using BBS+ Signatures with Privacy-Preserving Revocation and Device Binding</title>
<link>https://eprint.iacr.org/2025/824</link>
<guid>https://eprint.iacr.org/2025/824</guid>
<content:encoded><![CDATA[
Recently, there has been a growing interest in anonymous credentials (ACs) as they can mitigate the risk of personal data being processed by untrusted actors without consent and beyond the user's control. Furthermore, due to the privacy-by-design paradigm of ACs, they can prove possession of personal attributes, such as an authenticated government document containing sensitive personal information, while preserving the privacy of the individual by not actually revealing the data. Typically, AC specifications consider the privacy of individuals during the presentation of an AC, but often neglect privacy-preserving approaches for enhanced security features such as AC non-duplication or AC revocation. To achieve more privacy-friendly enhanced security features of non-duplication and privacy-preserving revocation, an AC can be partially stored on secure, trusted hardware and linked to a status credential that reflects its revocation status.
In this paper, we specify an AC system that satisfies the requirements of minimality of information, unlinkability, non-duplication, and privacy-preserving revocation.
This is achieved by adapting the hardware binding method of the Direct Anonymous Attestation protocol with the BBS+ short group signatures of Camenisch et al. and combining it with status credentials.
]]></content:encoded>
<pubDate>Fri, 09 May 2025 07:38:15 +0000</pubDate>
</item>
<item>
<title>Sampling Arbitrary Discrete Distributions for RV Commitment Schemes Using the Trimmed-Tree Knuth-Yao Algorithm</title>
<link>https://eprint.iacr.org/2025/823</link>
<guid>https://eprint.iacr.org/2025/823</guid>
<content:encoded><![CDATA[
Sampling from non-uniform randomness according to an algorithm which keeps the internal randomness used by the sampler hidden is increasingly important for cryptographic applications, such as timing-attack-resistant lattice-based cryptography or certified differential privacy. In this paper we present a provably efficient sampler that maintains random sample privacy, or random sample hiding, and is applicable to arbitrary discrete random variables. Namely, we present a constant-time version of the classic Knuth-Yao algorithm that we name "trimmed-tree" Knuth-Yao. We establish distribution-tailored Boolean circuit complexity bounds for this algorithm, in contrast to the previous naive distribution-agnostic bounds. For a $\sigma^2$-sub-Gaussian discrete distribution where $b_t$ is the number of bits for representing the domain, and $b_p$ is the bits for precision of the PDF values, we prove the Boolean circuit complexity of the trimmed-tree Knuth-Yao algorithm has upper bound $O(\sigma b_p^{3/2} b_t)$, an exponential improvement over the naive bounds, and in certain parameter regimes establish the lower bound $\widetilde{\Omega}( ( \sigma + b_p ) b_t )$. Moreover, by proving the subtrees in the trimmed-tree Knuth-Yao circuit are small, we prove it can computed by running $b_p$ circuits of size $O(\sigma b_p^{1/2} b_t)$ in parallel and then running $O(b_p b_t )$ sequential operations on the output. We apply these circuits for trimmed-tree Knuth-Yao to constructing random variable commitment schemes for arbitrary discrete distributions, giving exponential improvements in the number of random bits and circuit complexity used for certified differentially private means and counting queries over large datasets and domains.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 23:01:12 +0000</pubDate>
</item>
<item>
<title>An Attack on TON’s ADNL Secure Channel Protocol</title>
<link>https://eprint.iacr.org/2025/818</link>
<guid>https://eprint.iacr.org/2025/818</guid>
<content:encoded><![CDATA[
We present an attack on the Abstract Datagram
Network Layer (ADNL) protocol used in The Open Network
(TON), currently the 10th largest blockchain by market cap-
italization. In its TCP variant, ADNL secures communication
between clients and specialized nodes called liteservers, which
provide access to blockchain data. We identify two crypto-
graphic design flaws in this protocol: a handshake that permits
session-key replay and a non-standard integrity mechanism
whose security critically depends on message confidentiality.
We transform these vulnerabilities into an efficient plaintext-
recovery attack by exploiting two ADNL communication pat-
terns, allowing message reordering across replayed sessions.
We then develop a plaintext model for this scenario and con-
struct an efficient algorithm that recovers the keystream using
a fraction of known plaintexts and a handful of replays. We
implement our attack and show that an attacker intercepting
the communication between a TON liteserver and a widely de-
ployed ADNL client can recover the keystream used to encrypt
server responses by performing eight connection replays to the
server. This allows the decryption of sensitive data, such as
account balances and user activity patterns. Additionally, the
attacker can modify server responses to manipulate blockchain
information displayed to the client, including account balances
and asset prices.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 09:20:49 +0000</pubDate>
</item>
<item>
<title>Relating Definitions of Computational Differential Privacy in Wider Parameter Regimes</title>
<link>https://eprint.iacr.org/2025/817</link>
<guid>https://eprint.iacr.org/2025/817</guid>
<content:encoded><![CDATA[
The literature on computational differential privacy (CDP) has focused almost exclusively on definitions that are computational analogs of `pure' $(\epsilon,0)$-DP. We initiate the formal study of computational versions of approximate DP, i.e. $(\epsilon, \delta)$-DP with non-negligible $\delta$. We focus on IND-CDP and SIM$_{\forall\exists}$-CDP and show that the hierarchy between them when $\delta > 0$ potentially differs substantially from when $\delta = 0$. In one direction, we show that for $\delta < 1$, any mechanism which is $(\epsilon,\delta)$-SIM$_{\forall\exists}$-CDP also is $(\epsilon,\delta)$-IND-CDP, but only if $\epsilon$ is logarithmic in the security parameter. As a special case, this proves that the existing implication from $(\epsilon,0)$-SIM$_{\forall\exists}$-CDP to $(\epsilon,0)$-IND-CDP does not hold for arbitrary $\epsilon$, as previously claimed. Furthermore, we prove that when the parameters are the same in IND-CDP and SIM$_{\forall\exists}$-CDP and $\epsilon$ is superlogarithmic, there exists a natural task that can be solved whilst satisfying SIM$_{\forall\exists}$-CDP but which no IND-CDP mechanism can solve. This is the first separation in the CDP literature which is not due to using a task contrived specifically in order to give rise to the separation. 
    In the other direction, we show that the techniques for establishing an implication from $(\epsilon,0)$-IND-CDP to $(\epsilon,0)$-SIM$_{\forall\exists}$-CDP extend only to that a mechanism being $(\epsilon,\delta)$-IND-CDP implies it is also $(\epsilon,\delta')$-SIM$_{\forall\exists}$-CDP with $\delta' > \delta$. Finally, we show that the Groce-Katz-Yerukhimovich barrier results against separations between CDP and statistical DP hold also in the setting of non-negligible $\delta$.
]]></content:encoded>
<pubDate>Thu, 08 May 2025 08:31:33 +0000</pubDate>
</item>
<item>
<title>Actively Secure MPC in the Dishonest Majority Setting: Achieving Constant Complexity in Online Communication, Computation Per Gate, Rounds, and Private Input Size</title>
<link>https://eprint.iacr.org/2025/810</link>
<guid>https://eprint.iacr.org/2025/810</guid>
<content:encoded><![CDATA[
SPDZ-style and BMR-style protocols are widely known as practical MPC protocols that achieve active security in the dishonest majority setting.  However, to date, SPDZ-style protocols have not achieved constant rounds, and BMR-style protocols have struggled to achieve scalable communication or computation.  Additionally, there exists fully homomorphic encryption (FHE)-based MPC protocols that achieve both constant rounds and scalable communication, but they face challenges in achieving active security in the dishonest majority setting and are considered impractical due to computational inefficiencies.

In this work, we propose an MPC framework that constructs an efficient and scalable FHE-based MPC protocol by integrating a linear secret sharing scheme (LSSS)-based MPC and FHE. The resulting FHE-based MPC protocol achieves active security in the dishonest majority setting and constant complexity in online communication, computation per gate, rounds, and private input size. Notably, when instantiated with the SPDZ protocol and gate FHE for the framework, the resulting FHE-based MPC protocol efficiently achieves active security in the dishonest majority setting by using SPDZ-style MAC and ensures the computation per gate time within 3 ms. Moreover, its offline phase achieves scalable communication and computation, both of which grow linearly with the number of parties $n$. In other words, the proposed FHE-based MPC preserves the key advantages of existing FHE-based MPCs and simultaneously overcomes the weaknesses of them. As a result, the proposed FHE-based MPC is a highly practical and secure like SPDZ-style and BMR-style protocols.

For the first time, we introduce the concept of circuit-privacy, which ensures that external adversaries who eavesdrop on communications do not obtain information about the circuit. We rigorously prove that our construction inherently satisfy circuit- privacy, thereby establishing a novel security option for MPC.
]]></content:encoded>
<pubDate>Tue, 06 May 2025 16:28:27 +0000</pubDate>
</item>
<item>
<title>Asynchronous Byzantine Agreement with Subquadratic Communication</title>
<link>https://eprint.iacr.org/2020/851</link>
<guid>https://eprint.iacr.org/2020/851</guid>
<content:encoded><![CDATA[
Understanding the communication complexity of Byzantine agreement (BA) is a fundamental problem in distributed computing. In particular, as protocols are run with a large number of parties (as, e.g., in the context of blockchain protocols), it is important to understand the dependence of the communication on the number of parties $n$. Although adaptively secure BA protocols with $o(n^2)$ communication are known in the synchronous and partially synchronous settings, no such protocols are known in the fully asynchronous case.

We show here an asynchronous BA protocol with subquadratic communication tolerating an adaptive adversary who can corrupt  $f<(1-\epsilon)n/3$ of the parties (for any $\epsilon>0$).
One variant of our protocol assumes initial setup done by a trusted dealer, after which an unbounded number of BA executions can be run; alternately, we can achieve subquadratic amortized communication with no prior setup. We also show that some form of setup is needed for (non-amortized) subquadratic BA tolerating $\Theta(n)$ corrupted parties.

As a contribution of independent interest, we show a secure-computation protocol in the same threat model that has $o(n^2)$ communication when computing no-input functionalities with short output (e.g., coin tossing).
]]></content:encoded>
<pubDate>Sun, 12 Jul 2020 12:41:03 +0000</pubDate>
</item>
<item>
<title>The Internet Computer for Geeks</title>
<link>https://eprint.iacr.org/2022/087</link>
<guid>https://eprint.iacr.org/2022/087</guid>
<content:encoded><![CDATA[
Smart contracts are a new form of software that will revolutionize how software is written, IT systems are maintained, and applications and whole businesses are built.  Smart contracts are composable and autonomous pieces of software that run on decentralized blockchains, which makes them tamperproof and unstoppable.  

In this paper, we describe the Internet Computer (IC), which is a radical new design of blockchain that unleashes the full potential of smart contracts, overcoming the limitations of smart contracts on traditional blockchains with respect to speed, storage costs, and computational capacity.  This allows smart contracts for the first time to implement fully decentralized applications that are hosted end to end on blockchain.  

The IC consists of a set of cryptographic protocols that connects independently operated nodes into a collection of blockchains. These blockchains host and execute ``canisters'',  the IC’s form of smart contracts. Canisters can store data, perform very general computations on that data, and provide a complete technology stack, serving web pages directly to end users. Computational and storage costs are covered by a ``reverse-gas model'', where canister developers pre-pay costs in cycles that are obtained from ICP, the native token of the IC.  ICP tokens are also used for governance: the IC is governed by a decentralized autonomous organization, or DAO, which, among other things, determines changes to the topology of the network and upgrades to the protocol.
]]></content:encoded>
<pubDate>Tue, 25 Jan 2022 07:20:59 +0000</pubDate>
</item>
<item>
<title>Guidance for Efficient Selection of Secure Parameters for Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1001</link>
<guid>https://eprint.iacr.org/2024/1001</guid>
<content:encoded><![CDATA[
The field of Fully Homomorphic Encryption (FHE) has seen many theoretical and computational advances in recent years, bringing the technology closer to practicality than ever before. For this reason, practitioners from neighbouring fields such as machine learning have sought to understand FHE to provide privacy to their work. Unfortunately, selecting secure and efficient parameters in FHE is a daunting task due to the many interdependencies between the parameters involved. In this work, we solve this problem by moving away from the standard parameter selection procedure, introducing formulas which provide secure and optimal parameters for any lattice-based scheme. We build our formulas from a strong theoretical foundation based on cryptanalysis against LWE.
]]></content:encoded>
<pubDate>Thu, 20 Jun 2024 20:17:33 +0000</pubDate>
</item>
<item>
<title>Putting Sybils on a Diet: Securing Distributed Hash Tables using Proofs of Space</title>
<link>https://eprint.iacr.org/2025/804</link>
<guid>https://eprint.iacr.org/2025/804</guid>
<content:encoded><![CDATA[
Distributed Hash Tables (DHTs) are peer-to-peer protocols that serve as building blocks for more advanced applications. Recent examples, motivated by blockchains, include decentralized storage networks (e.g., IPFS), data availability sampling, or Ethereum's peer discovery protocol.

In the blockchain context, DHTs are vulnerable to Sybil attacks, where an adversary compromises the network by joining with many malicious nodes. Mitigating such attacks requires restricting the adversary's ability to create a lot of Sybil nodes. Surprisingly, the above applications take no such measures. Seemingly, existing techniques are unsuitable for the proposed applications.

For example, a simple technique proposed in the literature uses proof of work (PoW), where nodes periodically challenge their peers to solve computational challenges. This, however, does not work well in practice. Since the above applications do not require honest nodes to have a lot of computational power, challenges cannot be too difficult. Thus, even moderately powerful hardware can sustain many Sybil nodes.

In this work, we investigate using Proof of Space (PoSp) to limit the number of Sybils DHTs. While PoW proves that a node wastes computation, PoSp proves that a node wastes disk space. This aligns better with the resource requirements of the above applications. Many of them are related to storage and ask honest nodes to contribute a substantial amount of disk space to ensure the application's functionality.

With this synergy in mind, we propose a mechanism to limit Sybils where honest nodes dedicate a fraction of their disk space to PoSp. This guarantees that the adversary cannot control a constant fraction of all DHT nodes unless it provides a constant fraction of whole the disk space contributed to the application in total. Since this is typically a significant amount, attacks become economically expensive.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 17:09:39 +0000</pubDate>
</item>
<item>
<title>Universally Composable On-Chain Quadratic Voting for Liquid Democracy</title>
<link>https://eprint.iacr.org/2025/803</link>
<guid>https://eprint.iacr.org/2025/803</guid>
<content:encoded><![CDATA[
Decentralized governance plays a critical role in blockchain communities, allowing stakeholders to shape the evolution of platforms such as Cardano, Gitcoin, Aragon, and MakerDAO through distributed voting on proposed projects in order to support the most beneficial of them. In this context, numerous voting protocols for decentralized decision-making have been developed, enabling secure and verifiable voting on individual projects (proposals). However, these protocols are not designed to support more advanced models such as quadratic voting (QV), where the voting power, defined as the square root of a voter’s stake, must be distributed among the selected by voter projects. Simply executing multiple instances of a single-choice voting scheme in parallel is insufficient, as it can not enforce correct voting power splitting. To address this, we propose an efficient blockchain-based voting protocol that supports liquid democracy under the QV model, while ensuring voter privacy, fairness and verifiability of the voting results. In our scheme, voters can delegate their votes to trusted representatives (delegates), while having the ability to distribute their voting power across selected projects. We model our protocol in the Universal Composability framework and formally prove its UC-security under the Decisional Diffie–Hellman (DDH) assumption. To evaluate the performance of our protocol, we developed a prototype implementation and conducted performance testing. The results show that the size and processing time of a delegate’s ballot scale linearly with the number of projects, while a voter’s ballot scales linearly with both the number of projects and the number of available delegation options. In a representative setting with 64 voters, 128 delegates and 128 projects, the overall traffic amounts to approximately 2.7 MB per voted project, confirming the practicality of our protocol for modern blockchain-based governance systems.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 16:59:57 +0000</pubDate>
</item>
<item>
<title>POBA: Privacy-Preserving Operator-Side Bookkeeping and Analytics</title>
<link>https://eprint.iacr.org/2025/801</link>
<guid>https://eprint.iacr.org/2025/801</guid>
<content:encoded><![CDATA[
Many user-centric applications face a common privacy problem: the need to collect, store, and analyze sensitive user data. Examples include check-in/check-out based payment systems for public transportation, charging/discharging electric vehicle batteries in smart grids, coalition loyalty programs, behavior-based car insurance, and more. We propose and evaluate a generic solution to this problem. More specifically, we provide a formal framework integrating privacy-preserving data collection, storage, and analysis, which can be used for many different application scenarios, present an instantiation, and perform an experimental evaluation of its practicality.

We consider a setting where multiple operators (e.g., different mobility providers, different car manufacturers and insurance companies), who do not fully trust each other, intend to maintain and analyze data produced by the union of their user sets. The data is collected in an anonymous (wrt.\ all operators) but authenticated way and stored in so-called user logbooks. In order for the operators to be able to perform analyses at any time without requiring user interaction, the logbooks are kept on the operator's side. Consequently, this potentially sensitive data must be protected from unauthorized access. To achieve this, we combine several selected cryptographic techniques, such as threshold signatures and oblivious RAM. The latter ensures that user anonymity is protected even against memory access pattern attacks.

To the best of our knowledge, we provide and evaluate the first generic framework that combines data collection, operator-side data storage, and data analysis in a privacy-preserving manner, while providing a formal security model, a UC-secure protocol, and a full implementation. With three operators, our implementation can handle over two million new logbook entries per day.
]]></content:encoded>
<pubDate>Mon, 05 May 2025 10:46:44 +0000</pubDate>
</item>
<item>
<title>Rushing at SPDZ: On the Practical Security of Malicious MPC Implementations</title>
<link>https://eprint.iacr.org/2025/789</link>
<guid>https://eprint.iacr.org/2025/789</guid>
<content:encoded><![CDATA[
Secure multi-party computation (MPC) enables parties to compute a function over private inputs while maintaining confidentiality. Although MPC has advanced significantly and attracts a growing industry interest, open-source implementations are still at an early stage, with no production-ready code and a poor understanding of their actual security guarantees.
In this work, we study the real-world security of modern MPC implementations, focusing on the SPDZ protocol (Damgård et al., CRYPTO 2012, ESORICS 2013), which provides security against malicious adversaries when all-but-one of the participants may be corrupted. We identify a novel type of MAC key leakage in the MAC check protocol of SPDZ, which can be exploited in concurrent, multi-threaded settings, compromising output integrity and, in some cases, input privacy. In our analysis of three SPDZ implementations (MP-SPDZ, SCALE-MAMBA, and FRESCO), two are vulnerable to this attack, while we also uncover further issues and vulnerabilities with all implementations. We propose mitigation strategies and some recommendations for researchers, developers and users, which we hope can bring more awareness to these issues and avoid them reoccurring in future.
]]></content:encoded>
<pubDate>Sat, 03 May 2025 20:22:04 +0000</pubDate>
</item>
<item>
<title>AES Is Not Enough: the Block Ciphers Zoo Goes Homormorphic (over TFHE)</title>
<link>https://eprint.iacr.org/2025/782</link>
<guid>https://eprint.iacr.org/2025/782</guid>
<content:encoded><![CDATA[
The dream of achieving data privacy during external computations has
become increasingly concrete in recent years. Indeed, since the early days of Fully Homomorphic Encryption (FHE) more than a decade ago, new cryptosystems and techniques have constantly optimized the efficiency of computation on encrypted data.
However, one of the main disadvantages of FHE, namely its significant ciphertext expansion factor, remains at the center of the efficiency bottleneck of FHE schemes. To tackle the issue of slow uplink FHE data transmission, we use transciphering. With transciphering, the client naturally encrypts its data under a symmetric scheme and sends them to the server with (once and for all) an FHE encryption of the symmetric scheme’s key. With its larger computing power, the server then evaluates the symmetric scheme’s decryption algorithm within the homomorphic domain to obtain homomorphic ciphertexts that allow it to perform the requested calculations.
Since the first use of this method a bit more than ten years ago, papers on the homomorphic evaluation of AES have been numerous. And as the AES execution is the application chosen by NIST in the FHE part of its recent call for proposals on threshold encryption, the stakes of such work go up another level. But what about other standardized block ciphers? Is the AES the more efficient option? In this work, we leverage on two methods which have successfully been applied to the
homomorphic evaluation of AES to study several state-of-the-art symmetric block ciphers (namely CLEFIA, PRESENT, PRINCE, SIMON, SKINNY). That is to say, we implement a representative set of symmetric block ciphers using TFHE.
These implementations allow us to compare the efficiency of this set of symmetric schemes and to categorize them. We highlight the characteristics of block ciphers that are fast to execute in the homomorphic domain and those that are particularly costly.
Finally, this classification of operation types enables us to sketch out what the ideal block cipher for transciphering homomorphic data in integer mode might look like.
]]></content:encoded>
<pubDate>Thu, 01 May 2025 14:01:55 +0000</pubDate>
</item>
<item>
<title>AuthOr: Lower Cost Authenticity-Oriented Garbling of Arbitrary Boolean Circuits</title>
<link>https://eprint.iacr.org/2025/775</link>
<guid>https://eprint.iacr.org/2025/775</guid>
<content:encoded><![CDATA[
Authenticity-oriented (previously named as privacy-free) garbling
schemes of Frederiksen et al. Eurocrypt ’15 are designed to satisfy
only the authenticity criterion of Bellare et al. ACM CCS ’12, and to be
more efficient compared to full-fledged garbling schemes. In this work,
we improve the state-of-the-art authenticity-oriented version of half gates
(HG) garbling of Zahur et al. Crypto ’15 by allowing it to be bandwidth-free
if any of the input wires of an AND gate is freely settable by the
garbler. Our full solution AuthOr then successfully combines the ideas
from information-theoretical garbling of Kondi and Patra Crypto ’17 and
the HG garbling-based scheme that we obtained. AuthOr has a lower
communication cost (i.e. garbled circuit or GC size) than HG garbling
without any further security assumption. Theoretically, AuthOr’s GC
size reduction over HG garbling lies in the range between 0 to 100%,
and the exact improvement depends on the circuit structure. We have
implemented our scheme and conducted tests on various circuits that are
constructed by independent researchers. Our experimental results show
that in practice, the GC size gain may be up to roughly 98%.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 14:31:44 +0000</pubDate>
</item>
<item>
<title>Exploring Adversarial Attacks on the MaSTer Truncation Protocol</title>
<link>https://eprint.iacr.org/2025/773</link>
<guid>https://eprint.iacr.org/2025/773</guid>
<content:encoded><![CDATA[
At CANS 2024, Zbudila et al. presented MaSTer, a maliciously secure multi-party computation protocol for truncation. It allows adversaries to manipulate outputs with a bounded additive error while avoiding detection with a certain probability. In this work, we analyse the broader implications of adversarial exploitation in probabilistic truncation protocols, specifically in relation to MaSTer. We propose three attack strategies aimed at inducing misclassification in deep neural network (DNN) inference. Our empirical evaluation across multiple datasets demonstrates that while adversarial influence remains negligible under realistic constraints, certain configurations and network architectures exhibit increased vulnerability. By improving the understanding of the risks associated with probabilistic truncation protocols in privacy-preserving machine learning, our work demonstrates that the MaSTer protocol is robust in realistic settings.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 13:43:14 +0000</pubDate>
</item>
<item>
<title>Publicly Auditable Garbled Circuit</title>
<link>https://eprint.iacr.org/2025/772</link>
<guid>https://eprint.iacr.org/2025/772</guid>
<content:encoded><![CDATA[
Generic Secure Multiparty Computation (Generic MPC) recently received much attraction in the blockchain realm as it allows mutually distrustful parties to jointly compute a global function using their private inputs while keeping them private; and more so; the expression of the function can be done in a programmable manner (hence `generic'); as opposed to the first rising star cryptographic technique Zero-Knowledge Proof (ZKP) which only allows computation on private input of a single party (via the `commit-and-prove' approach). While ZKP, by nature, allows public verifiability, Generic MPC is not so: Generic MPC mostly focuses on Malicious Security in which the computing result is verifiable only among the computing parties. Yet, in the blockchain realm, public verifiability is important, as the consensus protocol is not just among the computing parties but also external servers. A few works were done to bridge this gap (albeit not in the blockchain realm), i.e., Public Auditable MPC. Public Audtitability is a stronger property than Public Verifiability: the first one certifies the computation done in the MPC, while the latter certifies only the relation between the outputs and the inputs. However, they are non-constant round protocols and only for Secret-Sharing-based MPC, i.e., round complexity scales linearly with the circuit multiplicative depth, while round latency is an important cost metric in the blockchain domain. We address this problem by providing a Public Auditable Garbled Circuit protocol that is maliciously secure, publicly auditable, and constant-round. Our protocol is efficient, with only minimal overhead in terms of round, communication, and public transcript size.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 08:27:31 +0000</pubDate>
</item>
<item>
<title>Distributed Point Function with Constraints, Revisited</title>
<link>https://eprint.iacr.org/2024/937</link>
<guid>https://eprint.iacr.org/2024/937</guid>
<content:encoded><![CDATA[
Distributed Point Function (DPF) provides a way for a dealer to split a point function $f_{\alpha, \beta}$ into multiple succinctly described function-shares, where  the function $f_{\alpha, \beta}$ for a special input $\alpha$, returns a special output value $\beta$, and returns a fixed value $0$ otherwise. As the security requirement, any strict subset of the function-shares reveals nothing about the function $f_{\alpha,\beta}$. However, each function-share can be individually evaluated on the common input $x$, and these evaluation results can then be merged together to reconstruct the value $f_{\alpha, \beta}(x)$. 

Recently, Servan-Schreiber et al. (S&amp;P 2023) investigate the access control problem for  DPF; namely, the DPF evaluators can ensure that the DPF dealer is authorized to share the given function with privacy assurance. In this work, we revisit this problem, introducing a new notion called DPF with constraints; meanwhile, we identify that there exists a subtle flaw in their privacy definition as well as a soundness issue in one of their proposed schemes due to the lack of validation of the special output value $\beta$. Next, we show how to reduce both the storage size of the constraint representation and the server's computational overhead from $O(N)$ to $O(\log N)$, where $N$ is the number of authorized function sets. In addition, we show how to achieve fine-grained private access control, that is, the wildcard-style constraint for the choice of the special output $\beta$. Our benchmarks show that the amortized running time of our logarithmic storage scheme is $2\times$ - $3\times$ faster than the state-of-the-art when $N=2^{15}$. Furthermore, we provide the first impossibility and feasibility results of the DPF with constraints where the evaluators do not need to communicate with each other.
]]></content:encoded>
<pubDate>Tue, 11 Jun 2024 18:25:56 +0000</pubDate>
</item>
<item>
<title>ZHE: Efficient Zero-Knowledge Proofs for HE Evaluations</title>
<link>https://eprint.iacr.org/2025/770</link>
<guid>https://eprint.iacr.org/2025/770</guid>
<content:encoded><![CDATA[
Homomorphic Encryption (HE) allows computations on encrypted data without decryption. It can be used where the users’ information are to be processed by an untrustful server, and has been a popular choice in privacy-preserving applica- tions. However, in order to obtain meaningful results, we have to assume an honest-but-curious server, i.e., it will faithfully follow what was asked to do. If the server is malicious, there is no guarantee that the computed result is correct. The notion of verifiable HE (vHE) is introduced to detect malicious server’s behaviors, but current vHE schemes are either more than four orders of magnitude slower than the underlying HE operations (Atapoor et. al, CIC 2024) or fast but incompatible with server- side private inputs (Chatel et. al, CCS 2024).

In this work, we propose a vHE framework ZHE: effi- cient Zero-Knowledge Proofs (ZKPs) that prove the correct execution of HE evaluations while protecting the server’s private inputs. More precisely, we first design two new highly- efficient ZKPs for modulo operations and (Inverse) Number Theoretic Transforms (NTTs), two of the basic operations of HE evaluations. Then we build a customized ZKP for HE evaluations, which is scalable, enjoys a fast prover time and has a non-interactive online phase. Our ZKP is applicable to all Ring-LWE based HE schemes, such as BGV and CKKS. Finally, we implement our protocols for both BGV and CKKS and conduct extensive experiments on various HE workloads. Compared to the state-of-the-art works, both of our prover time and verifier time are improved; especially, our prover cost is only roughly 27-36× more expensive than the underlying HE operations, this is two to three orders of magnitude cheaper than state-of-the-arts.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 02:03:40 +0000</pubDate>
</item>
<item>
<title>Incompleteness in Number-Theoretic Transforms: New Tradeoffs and Faster Lattice-Based Cryptographic Applications</title>
<link>https://eprint.iacr.org/2025/768</link>
<guid>https://eprint.iacr.org/2025/768</guid>
<content:encoded><![CDATA[
Lattices are the basis of most NIST-recommended post-quantum cryptography (PQC) schemes, required to thwart the threat posed by the eventual construction of large-scale quantum computers. At the same time, lattices enable more advanced cryptographic constructions, such as fully homomorphic encryption (FHE), which is increasingly used for privacy-preserving applications like machine learning. This work delves into the efficiency and trade-off assessment of polynomial multiplication algorithms and their applications to PQC, FHE, and other schemes. Such algorithms are at the core of lattice-based cryptography and may become a critical bottleneck when deploying PQC- and FHE-based solutions on resource-constrained devices. We propose a formal analysis of so-called incompleteness in the Number Theoretic Transform (NTT). Although this concept is not new, our systematization shows how to optimize polynomial multiplication in quotient rings, considering factors such as the degree of incompleteness, the associated prime moduli, constraints of the target platform, and target security level. Besides efficiency, we formally show that the systematized family of incomplete NTT variants supports a larger set of prime moduli. This property enables new trade-offs for algorithms like the FIPS-approved module-lattice-based key encapsulation mechanism (ML-KEM) and faster amortized bootstrapping in FHE schemes. Our results include shorter ciphertexts in ML-KEM with only a modest hit in performance and a 6-42% performance boost in the NTT computation of a state-of-the-art FHE solution.
]]></content:encoded>
<pubDate>Wed, 30 Apr 2025 00:22:04 +0000</pubDate>
</item>
<item>
<title>ZKPoG: Accelerating WitGen-Incorporated End-to-End Zero-Knowledge Proof on GPU</title>
<link>https://eprint.iacr.org/2025/765</link>
<guid>https://eprint.iacr.org/2025/765</guid>
<content:encoded><![CDATA[
Zero-Knowledge Proof (ZKP) is a cornerstone technology in privacy-preserving computing, addressing critical challenges in domains such as finance and healthcare by ensuring data confidentiality during computation. However, the high computational overhead of ZKP, particularly in proof generation and verification, limits its scalability and usability in real-world applications. Existing efforts to accelerate ZKP primarily focus on specific components, such as polynomial commitment schemes or elliptic curve operations, but fail to deliver an integrated, flexible, and efficient end-to-end solution that includes witness generation.

In this work, we present ZKPoG, a GPU-based ZKP acceleration platform that achieves full end-to-end optimization. ZKPoG addresses three key challenges: (1) designing a witness-generation-incorporated flow for Plonkish circuits, enabling seamless integration of frontend and backend with GPU acceleration; (2) optimizing memory usage to accommodate large-scale circuits on affordable GPUs with limited memory; and (3) introducing an automated compiler for custom gates, simplifying adaptation to diverse applications. Experimental results on an NVIDIA RTX 4090 GPU show on average $22.8\times$ end-to-end acceleration compared to state-of-the-art CPU implementations and on average $12.7\times$ speedup over existing GPU-based approaches.
]]></content:encoded>
<pubDate>Tue, 29 Apr 2025 14:51:19 +0000</pubDate>
</item>
<item>
<title>LEAGAN: A Decentralized Version-Control Framework for Upgradeable Smart Contracts</title>
<link>https://eprint.iacr.org/2025/752</link>
<guid>https://eprint.iacr.org/2025/752</guid>
<content:encoded><![CDATA[
Smart contracts are integral to decentralized systems like blockchains and enable the automation of processes through programmable conditions. However, their immutability, once deployed, poses challenges when addressing errors or bugs. Existing solutions, such as proxy contracts, facilitate upgrades while preserving application integrity. Yet, proxy contracts bring issues such as storage constraints and proxy selector clashes - along with complex inheritance management. This paper introduces a novel upgradeable smart contract framework with version control, named "decentraLized vErsion control and updAte manaGement in upgrAdeable smart coNtracts (LEAGAN)." LEAGAN is the first decentralized updatable smart contract framework that employs data separation with Incremental Hash (IH) and Revision Control System (RCS). It updates multiple contract versions without starting anew for each update, and reduces time complexity, and where RCS optimizes space utilization through differentiated version control. LEAGAN also introduces the first status contract in upgradeable smart contracts, and which reduces overhead while maintaining immutability. In Ethereum Virtual Machine (EVM) experiments, LEAGAN shows 40\% better space utilization, 30\% improved time complexity, and 25\% lower gas consumption compared to state-of-the-art models. It thus stands as a promising solution for enhancing blockchain system efficiency.
]]></content:encoded>
<pubDate>Sun, 27 Apr 2025 13:00:06 +0000</pubDate>
</item>
<item>
<title>Secure Rate-Distortion-Perception Trade-off Over Channels: A Randomized Distributed Function Computation (RDFC) Application</title>
<link>https://eprint.iacr.org/2025/750</link>
<guid>https://eprint.iacr.org/2025/750</guid>
<content:encoded><![CDATA[
Secure rate-distortion-perception (RDP) trade-offs arise in critical applications, such as semantic compression and privacy-preserving generative coding, where preserving perceptual quality while minimizing distortion is vital. This paper studies a framework for secure RDP over noiseless and noisy broadcast channels under strong secrecy constraints. We first characterize the exact secure RDP region for noiseless transmission channels. We then develop an inner bound on the secure RDP region for a memoryless broadcast channel with correlated noise components at the receivers' observations and prove its tightness under a more capable broadcast channel assumption. Our results demonstrate how optimized binning schemes simultaneously achieve high perceptual quality, low distortion, and strong secrecy, illuminating fundamental information-theoretic limits for next-generation trustworthy computation systems.
]]></content:encoded>
<pubDate>Sun, 27 Apr 2025 10:13:15 +0000</pubDate>
</item>
<item>
<title>OPSA: Efficient and Verifiable One-Pass Secure Aggregation with TEE for Federated Learning</title>
<link>https://eprint.iacr.org/2024/476</link>
<guid>https://eprint.iacr.org/2024/476</guid>
<content:encoded><![CDATA[
Federated learning enables collaborative model training while preserving data privacy by keeping data local. To protect user privacy during model aggregation, secure aggregation (SA) protocols are widely adopted to mask models. However, existing SA protocols require at least three round trips per aggregation and lack mechanisms to verify aggregation results. Verifiable SA addresses the verification gap but incurs high communication costs. TEE-based SA minimizes round trips but faces computational bottlenecks due to TEE's limited physical memory, especially when handling larger models or numerous clients. In this work, we introduce OPSA, an efficient and verifiable one-pass SA protocol based on TEE. By handling client dropouts via server-side TEE, OPSA enables the server to aggregate masked models in a single pass, significantly reducing round trips. To mitigate TEE's limitations, OPSA offloads tasks like model aggregation and mask elimination outside TEE, with only shared keys processed within TEE. Building on this design, we propose KhPRF-OPSA (single masking) and POT-OPSA (double masking) protocols, both incorporating novel cryptographic primitives. Furthermore, OPSA integrates commitment and signature mechanisms to ensure result verifiability with only $O(1)$ additional communication overhead per client. Compared to state-of-the-art schemes, OPSA achieves a 2$\sim$10$\times$ speedup in multi-round aggregation while guaranteeing result verification.
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 05:54:52 +0000</pubDate>
</item>
<item>
<title>CoinMaze: Privacy-Focused CoinJoin Protocol for Bitcoin</title>
<link>https://eprint.iacr.org/2025/747</link>
<guid>https://eprint.iacr.org/2025/747</guid>
<content:encoded><![CDATA[
Bitcoin is based on the Blockchain, an open ledger containing information about each transaction in the Bitcoin network. Blockchain serves many purposes, but it allows anyone to track all transactions and
activities of each Bitcoin address. The privacy of the network is being threatened by some organizations that track transactions. Tracking and subsequent filtering of coins lead to the loss of exchangeability of Bitcoin.

Despite Bitcoin’s transparency, it is possible to increase user privacy using a variety of existing methods. One of these methods is called CoinJoin, was proposed by Bitcoin developer Greg Maxwell in 2013.
This technology involves combining several users transactions to create a single transaction with multiple inputs and outputs, which makes transaction analysis more complicated.

This work describes the CoinMaze, a privacy-focused CoinJoin protocol based on the keyed-verification
anonymous credentials (KVAC).
]]></content:encoded>
<pubDate>Sat, 26 Apr 2025 20:28:37 +0000</pubDate>
</item>
<item>
<title>Candidate Matchmaking Encryption from Attribute-Based Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/744</link>
<guid>https://eprint.iacr.org/2025/744</guid>
<content:encoded><![CDATA[
We were deeply impressed by the paper by Ateniese et al., published in Crypto 2019. In it, they presented a black-box construction of matchmaking encryption (ME) based on functional encryption. In our work, we propose an ME scheme based on standard assumptions in the standard model. This scheme has been proven to be secure under the learning with error (LWE) assumption. Our ME scheme is achieved through a novel framework of bilateral-policy attribute-based encryption (BP-ABE) and a new intermediate primitive termed a perturbed pseudorandom generator (PPRG), which facilitates the implementation of authentication functionality by replacing non-interactive zero-knowledge proof functionality.

In the scheme presented in this paper, the user's "public key" is generated using Hamming correlation robustness and user attributes. Note that the 'public key' is not public. In order to preserve the privacy of the two parties involved in matchmaking encryption, our BP-ABE scheme does not use the 'public key' directly to encrypt the plaintext. Instead, the message sender selects matching attributes and uses a Hamming correlation robustness and homomorphic pseudorandom function (HPRF) to generate temporary public keys and hide the public key and user attributes.

When these temporary public keys satisfy the access policy, the receiver can decrypt the data using their private key. Regarding the authentication function of matchmaking encryption, this paper proposes a non-interactive privacy set intersection (PSI) scheme based on HPRF and PPRG. The message sender encrypts their 'public key' using the proposed PSI scheme as part of the ciphertext. The receiver also encrypts their 'public key' using the proposed PSI scheme and matches the attributes, thereby completing the message authentication function. We consider our approach to be a significant departure from existing constructions, despite its simplicity.
]]></content:encoded>
<pubDate>Sat, 26 Apr 2025 03:21:37 +0000</pubDate>
</item>
<item>
<title>Otter: Scalable Sharding-Based Atomic Broadcast with Abortable Fork Detection</title>
<link>https://eprint.iacr.org/2025/740</link>
<guid>https://eprint.iacr.org/2025/740</guid>
<content:encoded><![CDATA[
Sharding is a generic approach to enhance the scalability of distributed systems. In recent years, many efforts have been made to scale the consensus mechanism of blockchains from sharding. A crucial research question is how to achieve the sweet spot of having a relatively small shard size (to achieve decent performance) while achieving an overwhelming probability of correctness (so the system is safe and live). Many recent works fall into the two-layer design that uses some coordinating shards to monitor the correctness of other shards (CCS 2022, NDSS 2024, INFOCOM 2023). All of them involve expensive communication costs between the shards, significantly degrading performance.

We present Otter, a scalable partially synchronous sharding-based Byzantine fault-tolerant atomic broadcast (ABC) protocol. We use coordinating shards in a completely new way. In particular, we randomly sample coordinating shards to directly participate in the consensus protocol. Such a random sampling mechanism makes it possible to analyze the correctness of the ABC protocol using a probabilistic model. In this way, we can significantly lower the shard size (informally, from over 1,200 in previous work to around 100) without lowering the probability of correctness. We also present a new notion called abortable fork detection (AFD) that might be of independent interest. Our evaluation results on Amazon EC2 using up to 1,000 replicas show that Otter achieves up to 4.38x the throughput of the state-of-the-art protocol.
]]></content:encoded>
<pubDate>Fri, 25 Apr 2025 08:00:54 +0000</pubDate>
</item>
<item>
<title>Universal Blind and Verifiable Delegated Quantum Computation with Classical Clients</title>
<link>https://eprint.iacr.org/2025/734</link>
<guid>https://eprint.iacr.org/2025/734</guid>
<content:encoded><![CDATA[
Delegation of quantum computation in a trustful way is one of the most fundamental challenges toward the realization of future quantum cloud computing. While considerable progress has been made, no known protocol provides a purely classical client with universal delegated quantum computation while simultaneously ensuring blindness (input privacy), verifiability (soundness), and robustness against quantum noise—a feat that must be achieved under stringent cryptographic assumptions and with low overhead.

In this work, I introduce UVCQC, a new delegation framework that, for the first time, realizes a fully composable protocol for securely delegating quantum computations to an untrusted quantum server from a classical client. My scheme employs trap-based quantum authentication, post-quantum cryptographic commitments, and zero-knowledge proofs to provide full guarantees: the client remains purely classical; the server learns nothing about the computation; and any attempt to deviate from the specified circuit is detected with high probability.

I rigorously prove completeness, soundness, and perfect blindness of the protocol and demonstrate its universal composability against unbounded quantum adversaries. Furthermore, I propose a thermodynamically inspired verification mechanism based on energy dissipation and entropy change, enabling physically testable verification independent of cryptographic assumptions.

Beyond its core architecture, UVCQC is deeply intertwined with multidisciplinary frameworks: it admits a game-theoretic formulation where honesty is a Nash equilibrium, an information-theoretic treatment grounded in Holevo bounds, a categorical model via compact closed structures, and novel cryptographic enhancements based on isogeny-based primitives and topological invariants.

This research offers a scalable and unified solution to the blind and verifiable delegation problem, pushing forward the theoretical and practical frontiers of secure quantum computation—and opening a tangible path toward trustable quantum cloud services for classical users.
]]></content:encoded>
<pubDate>Thu, 24 Apr 2025 12:22:46 +0000</pubDate>
</item>
<item>
<title>Provably Secure Butterfly Key Expansion from the CRYSTALS Post-Quantum Schemes</title>
<link>https://eprint.iacr.org/2024/946</link>
<guid>https://eprint.iacr.org/2024/946</guid>
<content:encoded><![CDATA[
Key blinding produces pseudonymous digital identities by
rerandomizing public keys of a digital signature scheme. It provides privacy in decentralized networks. Current key blinding schemes are based on the discrete log assumption. Eaton, Stebila and Stracovsky (LATINCRYPT 2021) proposed the first post-quantum key blinding schemes from lattice assumptions. However, the large public keys and lack of QROM security means they are not ready to replace existing solutions. We present a general framework to build post-quantum signature schemes with key blinding based on the MPC-in-the-Head paradigm. This results in schemes that rely on well-studied symmetric cryptographic primitives and admit short public keys. We prove generic security results in the quantum random oracle model (QROM).

We instantiate our framework with the recent AES-based Helium signature scheme (Kales and Zaverucha, 2022) to obtain an efficient post-quantum key blinding scheme with small keys. Both Helium and the aforementioned lattice-based key blinding schemes were only proven secure in the ROM. This makes our results the first QROM proof of Helium and the first fully quantum-safe public key blinding scheme.
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 18:13:48 +0000</pubDate>
</item>
<item>
<title>Boomy: Batch Opening Of Multivariate polYnomial commitment</title>
<link>https://eprint.iacr.org/2023/1599</link>
<guid>https://eprint.iacr.org/2023/1599</guid>
<content:encoded><![CDATA[
We present Boomy, a multivariate polynomial commitment scheme enabling the proof of the evaluation of multiple points, i.e., batch opening. Boomy is the natural extension of two popular protocols: the univariate polynomial commitment scheme of Kate, Zaverucha and Goldberg~\cite{AC:KatZavGol10} and its multivariate counterpart from Papamanthou, Shi and Tamassia~\cite{papamanthou2013signatures}. Our construction is proven secure under the selective security model. In this paper, we present Boomy's complexity and the applications on which it can have a significant impact. In fact, Boomy is perfectly suited to tackling blockchain data availability problems, shrinking existing challenges. We also present special lower-complexity cases that occur frequently in practical situations.
]]></content:encoded>
<pubDate>Mon, 16 Oct 2023 12:45:23 +0000</pubDate>
</item>
<item>
<title>Tetris! Traceable Extendable Threshold Ring Signatures and More</title>
<link>https://eprint.iacr.org/2025/730</link>
<guid>https://eprint.iacr.org/2025/730</guid>
<content:encoded><![CDATA[
Traceable ring signatures enhance ring signatures by adding an accountability layer. Specifically, if a party signs two different messages within the protocol, their identity is revealed.  Another desirable feature is $\textit{extendability}$. In particular, $\textit{extendable threshold}$ ring signatures (ETRS) allow to $\textit{non-interactively}$ update already finalized signatures by enlarging the ring or the set of signers.

Combining traceability and extendability in a single scheme is unexplored and would offer a new tool for privacy-preserving voting schemes in scenarios where the voters are not known in advance.
In this paper, we show how to reconcile both properties by introducing and constructing a new cryptographic primitive called Tetris.
Notably, our Tetris construction simultaneously achieves strong anonymity and linear-size signatures, which is the main technical challenge in existing techniques.
To solve this challenge, we develop a new approach to traceability that leads to several conceptual and technical contributions. Among those, we introduce and construct, based on Groth-Sahai proofs, $\textit{extendable}$ shuffle arguments that can be $\textit{non-interactively}$ updated by several provers.
]]></content:encoded>
<pubDate>Wed, 23 Apr 2025 13:04:46 +0000</pubDate>
</item>
<item>
<title>Privacy and Security in Distributed Data Markets</title>
<link>https://eprint.iacr.org/2025/724</link>
<guid>https://eprint.iacr.org/2025/724</guid>
<content:encoded><![CDATA[
Data markets play a pivotal role in modern industries by facilitating the exchange of data for predictive modeling, targeted marketing, and research. However, as data becomes a valuable commodity, privacy and security concerns have grown, particularly regarding the personal information of individuals. This tutorial explores privacy and security issues when integrating different data sources in data market platforms. As motivation for the importance of enforcing privacy requirements, we discuss attacks on data markets focusing on membership inference and reconstruction attacks. We also discuss security vulnerabilities in decentralized data marketplaces, including adversarial manipulations by buyers or sellers. We provide an overview of privacy and security mechanisms designed to mitigate these risks. In order to enforce the least amount of trust for buyers and sellers, we focus on distributed protocols. Finally, we conclude with opportunities for future research on understanding and mitigating privacy and security concerns in distributed data markets.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 22:45:28 +0000</pubDate>
</item>
<item>
<title>Towards Lightweight CKKS: On Client Cost Efficiency</title>
<link>https://eprint.iacr.org/2025/720</link>
<guid>https://eprint.iacr.org/2025/720</guid>
<content:encoded><![CDATA[
The large key size for fully homomorphic encryption (FHE) requires substantial costs to generate and transmit the keys. This has been problematic for FHE clients who want to delegate the computation, as they often have limited power. A recent work, Lee-Lee-Kim-No [Asiacrypt 2023], partly solved this problem by suggesting a hierarchical key management system. However, the overall key size was still several gigabytes for real-world applications, and it is barely satisfactory for mobile phones and IoT devices. 

In this work, we propose new key management systems, KG+ and BTS+, which reduce the client's cost for FHE on top of Lee-Lee-Kim-No. The KG+system significantly reduces the key size without any compromise in the efficiency of homomorphic computation compared to Lee-Lee-Kim-No. The BTS+ system further reduces the key size, while it compromises only the granularity of the homomorphic computation.

In our new systems, the client generates and sends ``transmission keys'' with size-optimal parameters, and the server generates ``evaluation keys'' with computation-optimal parameters. For this purpose, we introduce a new ring-switching technique for keys to bridge keys with different parameters. 
Using the new ring-switching technique, a client can transmit the transmission keys in extension rings that can generate FHE keys in the computation-efficient subring. By decoupling the rings of FHE keys during transmission and computation, we significantly reduce the communication cost for transferring FHE keys. 

We provide concrete CKKS FHE parameters that the client's keys are $325$--$609$ MB and $285$ MB, by using KG+ and BTS+, respectively. Note that all parameters generate keys for CKKS with ring degree $2^{16}$, which is a conventional choice for CKKS applications to privacy-preserving machine learning. These are $3.09$--$4.37$ and $3.51$--$9.30$ times lower than Lee-Lee-Kim-No, respectively. For real-world applications, the server requires more evaluation keys for faster homomorphic computation. For the secure ResNet-20 inference, the parameters for KG+ and BTS+ result in client key sizes of $325$--$609$ MB and $285$ MB, respectively. These are $3.95$--$5.73\times$ and $4.53$--$12.25\times$ smaller than Lee-Lee-Kim-No.
]]></content:encoded>
<pubDate>Tue, 22 Apr 2025 10:17:24 +0000</pubDate>
</item>
<item>
<title>Thunderbolt: A Formally Verified Protocol for Off-Chain Bitcoin Transfers</title>
<link>https://eprint.iacr.org/2025/709</link>
<guid>https://eprint.iacr.org/2025/709</guid>
<content:encoded><![CDATA[
We present Bitcoin Thunderbolt, a novel off-chain protocol for asynchronous, secure transfer of Bitcoin UTXOs between uncoordinated users. Unlike prior solutions such as payment channels or the Lightning Network, Bitcoin Thunderbolt requires no prior trust, direct interaction, or continuous connectivity between sender and receiver. At its core, Bitcoin Thunderbolt employs a Byzantine fault-tolerant committee to manage threshold Schnorr signatures, enabling secure ownership delegation and on-chain finalization.

Our design supports recursive, off-chain UTXO transfers using tweakable, verifiable signature components. The protocol tolerates up to $f$ malicious nodes in a $3f+1$ committee and ensures correctness, consistency, and one-time spendability under asynchronous network conditions.

We formally verify Bitcoin Thunderbolt’s key security properties, namely, unforgeability, ownership soundness, and liveness—using the Tamarin prover. Our results demonstrate that Thunderbolt provides robust, scalable, and non-interactive off-chain Bitcoin transfers, significantly expanding the practical utility of Bitcoin for decentralized applications.
]]></content:encoded>
<pubDate>Sat, 19 Apr 2025 01:09:05 +0000</pubDate>
</item>
<item>
<title>Arbigraph: Verifiable Turing-Complete Execution Delegation</title>
<link>https://eprint.iacr.org/2025/710</link>
<guid>https://eprint.iacr.org/2025/710</guid>
<content:encoded><![CDATA[
Dependence on online infrastructure is rapidly growing as services like online payments and insurance replace traditional options, while others, like social networks, offer new capabilities. 
The centralized service operators wield unilateral authority over user conflicts, content moderation, and access to essential services.
In the context of payments, blockchains provide a decentralized alternative. 
They also enable decentralized execution of stateful programs called smart contracts. 
But those lack the contextual understanding and interpretative capabilities that would enable reasoning about complex scenarios.
Advancements in machine learning (ML) are raising interest in actually-smart contracts, but blockchain computation constraints prohibit direct ML inference execution.
While many projects deploy computation delegation mechanisms, they lack Turing-completeness, prohibit parallel computation, or suffer from high overhead.

We present Arbigraph, a blockchain-based execution delegation protocol.
Like previous optimistic solutions, the parties submit their computation results, allowing a smart contract to arbitrate in case of dispute.
But Arbigraph employs a novel dual-graph data structure and takes advantage of the nature of the dispute process to achieve Turing completeness, constant-time memory access, and parallel execution.
We formalize the problem and show that Arbigraph guarantees completeness, soundness, and progress. 
Experiments on LLM inference as well as matrix multiplication, which is at the core of ML inference, demonstrate that parallelization speedup grows linearly with matrix dimensions. 
We demonstrate Arbigraph's practical cost with a deployment on the Avalanche blockchain. 
Arbigraph thus enables decentralized, context-aware decision-making and unlocks unprecedented use cases for blockchains.
]]></content:encoded>
<pubDate>Sat, 19 Apr 2025 10:30:39 +0000</pubDate>
</item>
<item>
<title>Signature-Free Atomic Broadcast with Optimal $O(n^2)$ Messages and $O(1)$ Expected Time</title>
<link>https://eprint.iacr.org/2023/1549</link>
<guid>https://eprint.iacr.org/2023/1549</guid>
<content:encoded><![CDATA[
Byzantine atomic broadcast (ABC) is at the heart of  permissioned blockchains and various multi-party computation protocols. We resolve a long-standing open problem in ABC, presenting the first information-theoretic (IT) and signature-free asynchronous ABC protocol that achieves optimal $O(n^2)$ messages and $O(1)$ expected time.  Our ABC protocol adopts a new design, relying on a reduction from---perhaps surprisingly---a somewhat neglected  primitive called multivalued Byzantine agreement (MBA).
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 12:26:39 +0000</pubDate>
</item>
<item>
<title>Updatable Signature with Public Tokens</title>
<link>https://eprint.iacr.org/2025/715</link>
<guid>https://eprint.iacr.org/2025/715</guid>
<content:encoded><![CDATA[
The Updatable Signature (US) allows valid signatures to be updated by an update token without accessing the newly generated signing key. Cini et al. (PKC'21) formally defined this signature and gave several constructions. However, their security model requires the secrecy of the update token, which is only applicable in some specific scenarios, such as software verification in the trusted App Store. In Web3, information is usually shared via a public blockchain, and decentralized private computation is expensive. In addition, one can use the same token to update both the signing key and signatures and all signatures can be updated with a single token. The adversarial signature generated by an adversary might also be updated. Therefore, this work explores the (im)possibility of constructing an Updatable Signature with public tokens (USpt), the tokens of which are signature-dependent. Specifically, we define the updatable signature with public tokens and present its security model. Then, we present a concrete USpt scheme based on the Boneh–Lynn–Shacham signature. This variant introduces a limitation for the signer who must maintain a dataset about its signed messages or hashes of them, which is applicable in our applications.
]]></content:encoded>
<pubDate>Mon, 21 Apr 2025 03:03:01 +0000</pubDate>
</item>
<item>
<title>Fast Plaintext-Ciphertext Matrix Multiplication from Additively Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/711</link>
<guid>https://eprint.iacr.org/2025/711</guid>
<content:encoded><![CDATA[
Plaintext-ciphertext matrix multiplication (PC-MM) is an indispensable tool in privacy-preserving computations such as secure machine learning and encrypted signal processing. While there are many established algorithms for plaintext-plaintext matrix multiplication, efficiently computing plaintext-ciphertext (and ciphertext-ciphertext) matrix multiplication is an active area of research which has received a lot of attention. Recent literature have explored various techniques for privacy-preserving matrix multiplication using fully homomorphic encryption (FHE) schemes with ciphertext packing and Single Instruction Multiple Data (SIMD) processing. On the other hand, there hasn't been any attempt to speed up PC-MM using unpacked additively homomorphic encryption (AHE) schemes beyond the schoolbook method and Strassen's algorithm for matrix multiplication. In this work, we propose an efficient PC-MM from unpacked AHE, which applies Cussen's compression-reconstruction algorithm for plaintext-plaintext matrix multiplication in the encrypted setting. We experimentally validate our proposed technique using a concrete instantiation with the additively homomorphic elliptic curve ElGamal encryption scheme and its software implementation on a Raspberry Pi 5 edge computing platform. Our proposed approach achieves up to an order of magnitude speedup compared to state-of-the-art for large matrices with relatively small element bit-widths. Extensive measurement results demonstrate that our fast PC-MM is an excellent candidate for efficient privacy-preserving computation even in resource-constrained environments.
]]></content:encoded>
<pubDate>Sun, 20 Apr 2025 05:38:55 +0000</pubDate>
</item>
<item>
<title>Proofs of Useful Work from Arbitrary Matrix Multiplication</title>
<link>https://eprint.iacr.org/2025/685</link>
<guid>https://eprint.iacr.org/2025/685</guid>
<content:encoded><![CDATA[
We revisit the longstanding open problem of implementing Nakamoto's proof-of-work (PoW) consensus based on a real-world computational task $T(x)$ (as opposed to artificial random hashing), in a truly  permissionless setting where the miner itself chooses the input $x$. The challenge in designing such a Proof-of-Useful-Work (PoUW) protocol, is using the native computation of $T(x)$ to produce a PoW certificate with prescribed hardness and with negligible computational overhead over the worst-case complexity of $T(\cdot)$ -- This  ensures malicious miners cannot ``game the system" by fooling the verifier to accept with higher probability compared to honest miners (while using similar computational resources). Indeed, obtaining a PoUW with $O(1)$-factor overhead is trivial for any task $T$, but also useless. 

Our main result is a PoUW for the task of Matrix Multiplication $\mathsf{MatMul}(A,B)$ of arbitrary matrices with  $1+o(1)$ multiplicative overhead compared to na\"ive $\mathsf{MatMul}$ (even in the presence of Fast Matrix Multiplication-style algorithms, which are currently impractical). We conjecture that our protocol has optimal security in the sense that a malicious prover cannot obtain any significant advantage over an honest prover. This conjecture is based on reducing hardness of our protocol to the task of solving a batch of low-rank random linear equations which is of independent interest.

Since $\mathsf{MatMul}$s are the bottleneck of AI compute as well as countless industry-scale applications, this primitive suggests a concrete design of a new L1 base-layer protocol, which nearly eliminates the energy-waste of Bitcoin mining -- allowing GPU consumers to reduce their AI training and inference costs by ``re-using" it for blockchain consensus, in exchange for block rewards (2-for-1). This blockchain is currently under construction.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 18:46:53 +0000</pubDate>
</item>
<item>
<title>Bitcoin-Enhanced Proof-of-Stake Security: Possibilities and Impossibilities</title>
<link>https://eprint.iacr.org/2022/932</link>
<guid>https://eprint.iacr.org/2022/932</guid>
<content:encoded><![CDATA[
Bitcoin is the most secure blockchain in the world, supported by the immense hash power of its Proof-of-Work miners. Proof-of-Stake chains are energy-efficient, have fast finality but face several security issues: susceptibility to non-slashable long-range safety attacks, low liveness resilience and difficulty to bootstrap from low token valuation.  We show that these security issues are inherent in any PoS chain without an external trusted source, and propose a new protocol, Babylon, where an off-the-shelf PoS protocol checkpoints onto Bitcoin to resolve these issues. An impossibility result justifies the optimality of Babylon. A use case of Babylon is to reduce the stake withdrawal delay: our experimental results show that this delay can be reduced from weeks in existing PoS chains to less than 5 hours using Babylon, at a transaction cost of less than 10K USD per annum for posting the checkpoints onto Bitcoin.
]]></content:encoded>
<pubDate>Mon, 18 Jul 2022 06:03:55 +0000</pubDate>
</item>
<item>
<title>Priv-PFL: A Privacy-Preserving and Efficient Personalized Federated Learning Approach</title>
<link>https://eprint.iacr.org/2025/703</link>
<guid>https://eprint.iacr.org/2025/703</guid>
<content:encoded><![CDATA[
Federated Learning (FL) allows clients to engage in learning without revealing their raw data. However, traditional FL focuses on developing a single global model for all clients, limiting their ability to have personalized models tailored to their specific needs. Personalized FL (PFL) enables clients to obtain their customized models, either with or without a central party.  Current PFL research includes mechanisms to detect poisoning attacks, in which a couple of malicious nodes try to manipulate training convergence by submitting misleading data. However, these detection approaches often overlook privacy concerns, as they require clients to share their models with all other clients.
This paper extends BALANCE, a personalized poisoning detection mechanism based on client models and their expectations. Our method enhances both security and privacy by ensuring clients are not required to share their model data with other clients. By leveraging server-assisted PFL and Fully Homomorphic Encryption (FHE), we enable a central party to identify unpoisoned clients from the perspective of individual clients and train personalized models securely. Additionally, we introduce an efficient personalized client selection algorithm that prevents redundant checks and ensures the inheritance of unpoisoned clients.
]]></content:encoded>
<pubDate>Fri, 18 Apr 2025 03:38:22 +0000</pubDate>
</item>
<item>
<title>Hermes: Efficient and Secure Multi-Writer Encrypted Database</title>
<link>https://eprint.iacr.org/2025/701</link>
<guid>https://eprint.iacr.org/2025/701</guid>
<content:encoded><![CDATA[
Searchable encryption (SE) enables privacy-preserving keyword search on encrypted data. Public-key SE (PKSE) supports multi-user searches but suffers from high search latency due to expensive public-key operations. Symmetric SE (SSE) offers a sublinear search but is mainly limited to single-user settings. Recently, hybrid SE (HSE) has combined SSE and PKSE to achieve the best of both worlds, including multi-writer encrypted search functionalities, forward privacy, and sublinear search with respect to database size. Despite its advantages, HSE inherits critical security limitations, such as susceptibility to dictionary attacks, and still incurs significant overhead for search access control verification, requiring costly public-key operation invocations (i.e., pairing) across all authorized keywords. Additionally, its search access control component must be rebuilt periodically for forward privacy, imposing substantial writer overhead.   
In this paper, we propose Hermes, a new HSE scheme that addresses the aforementioned security issues in prior HSE designs while maintaining minimal search complexity and user efficiency at the same time. Hermes enables multi-writer encrypted search functionalities and offers forward privacy along with resilience to dictionary attacks. To achieve this, we develop a new identity-based encryption scheme with hidden identity and key-aggregate properties, which could be of independent interest. We also design novel partitioning and epoch encoding techniques in Hermes to minimize search complexity and offer low user overhead in maintaining forward privacy. We conducted intensive experiments to assess and compare the performance of Hermes and its counterpart on commodity hardware. Experimental results showed that Hermes performs search one to two orders of magnitude faster than the state-of-the-art HSE while offering stronger security guarantees to prevent dictionary and injection attacks.
]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 20:09:07 +0000</pubDate>
</item>
<item>
<title>Fherret: Proof of FHE Correct-and-Honest Evaluation with Circuit Privacy from MPCitH</title>
<link>https://eprint.iacr.org/2025/700</link>
<guid>https://eprint.iacr.org/2025/700</guid>
<content:encoded><![CDATA[
The major Fully Homomorphic Encryption (FHE) schemes guarantee the privacy of the encrypted message only in the honest-but-curious setting, when the server follows the protocol without deviating. However, various attacks in the literature show that an actively malicious server can recover sensitive information by executing incorrect functions, tampering with ciphertexts, or observing the client’s reaction during decryption.

Existing integrity solutions for FHE schemes either fail to guarantee circuit privacy, exposing the server's computations to the client, or introduce significant computational overhead on the prover by requiring proofs of FHE operations on ciphertexts.

In this work, we present Fherret, a novel scheme leveraging the MPC-in-the-Head (MPCitH) paradigm to provide a proof of correct-and-honest homomorphic evaluation while preserving circuit privacy. This proof guarantees that the client can safely decrypt the ciphertext obtained from the server without being susceptible to reaction-based attacks, such as verification and decryption oracle attacks. Additionally, this proof guarantees that the server’s evaluation maintains correctness, thereby protecting the client from $\mathsf{IND}\text{-}\mathsf{CPA}^{\mathsf{D}}$-style attacks.

Our solution achieves a prover overhead of $4\lambda$ homomorphic evaluations of random functions from the function space $\mathcal{F}$, while retaining a competitive verifier overhead of $2 \lambda$ homomorphic evaluations and a communication size proportional to $\sqrt{2\lambda}$ times the size of a function from $\mathcal{F}$. 

Furthermore, Fherret is inherently parallelizable, achieving a parallel computation overhead similar to a homomorphic evaluation of a random function from $\mathcal{F}$ for both the prover and the verifier.
]]></content:encoded>
<pubDate>Thu, 17 Apr 2025 12:15:18 +0000</pubDate>
</item>
<item>
<title>Efficient Foreign-Field Arithmetic in PLONK</title>
<link>https://eprint.iacr.org/2025/695</link>
<guid>https://eprint.iacr.org/2025/695</guid>
<content:encoded><![CDATA[
PLONK is a prominent universal and updatable zk-SNARK for general circuit satisfiability, which allows a prover to produce a short certificate of the validity of a certain statement/computation. Its expressive model of computation and its highly efficient verifier complexity make PLONK a powerful tool for a wide range of blockchain applications.

Supporting standard cryptographic primitives (such us ECDSA over SECP256k1) or advanced recursive predicates (e.g. incrementally verifiable computation) on a SNARK presents a significant challenge. It requires so-called foreign-field arithmetic (enforcing constraints over algebraic fields that differ from the SNARK native field) which was previously believed to incur an overhead of two or three orders of magnitude.

We build on the techniques by Lubarov and Baylina and observe that, by considering tight bounds on their encoding of foreign-field multiplication, the number of PLONK constraints can be significantly reduced. We show that these techniques also extend to elliptic curve emulation, with an overhead of just one order of magnitude (with respect to its native counterpart). We validate soundness and completeness of our main results in EasyCrypt. Finally, we implement an open-source library with support for foreign-field arithmetic. Our experimental results showcase the generality of our techniques and confirm their suitability for real-world applications.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 16:17:52 +0000</pubDate>
</item>
<item>
<title>A Formal Security Analysis of Hyperledger AnonCreds</title>
<link>https://eprint.iacr.org/2025/694</link>
<guid>https://eprint.iacr.org/2025/694</guid>
<content:encoded><![CDATA[
In an anonymous credential system, users collect credentials from issuers, and can use their credentials to generate privacy-preserving identity proofs that can be shown to third-party verifiers. Since the introduction of anonymous credentials by Chaum in 1985, there has been promising advances with respect to system design, security analysis and real-world implementations of anonymous credential systems.

In this paper, we examine Hyperledger AnonCreds, an anonymous credential system that was introduced in 2017 and is currently undergoing specification. Despite being implemented in deployment-ready identity system platforms, there is no formal security analysis of the Hyperledger AnonCreds protocol. We rectify this, presenting syntax and a security model for, and a first security analysis of, the Hyperledger AnonCreds protocol. In particular, we demonstrate that Hyperledger AnonCreds is correct, and satisfies notions of unforgeability and anonymity. We conclude with a discussion on the implications of our findings, highlighting the importance of rigorous specification efforts to support security evaluation of real-world cryptographic protocols.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 16:16:57 +0000</pubDate>
</item>
<item>
<title>Accountable Liveness</title>
<link>https://eprint.iacr.org/2025/693</link>
<guid>https://eprint.iacr.org/2025/693</guid>
<content:encoded><![CDATA[
Safety and liveness are the two classical security properties of consensus protocols. Recent works have strengthened safety with accountability: should any safety violation occur, a sizable fraction of adversary nodes can be proven to be protocol violators. This paper studies to what extent analogous accountability guarantees are achievable for liveness. To reveal the full complexity of this question, we introduce an interpolation between the classical synchronous and partially-synchronous models that we call the $x$-partially-synchronous network model in which, intuitively, at most an $x$ fraction of the time steps in any sufficiently long interval are asynchronous (and, as with a partially-synchronous network, all time steps are synchronous following the passage of an unknown "global stablization time"). We prove a precise characterization of the parameter regime in which accountable liveness is achievable: if and only if $x < 1/2$ and $f < n/2$, where $n$ denotes the number of nodes and $f$ the number of nodes controlled by an adversary. We further refine the problem statement and our analysis by parameterizing by the number of violating nodes identified following a liveness violation, and provide evidence that the guarantees achieved by our protocol are near-optimal (as a function of $x$ and $f$). Our results provide rigorous foundations for liveness-accountability heuristics such as the  "inactivity leaks" employed in Ethereum.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 15:04:09 +0000</pubDate>
</item>
<item>
<title>DahLIAS: Discrete Logarithm-Based Interactive Aggregate Signatures</title>
<link>https://eprint.iacr.org/2025/692</link>
<guid>https://eprint.iacr.org/2025/692</guid>
<content:encoded><![CDATA[
An interactive aggregate signature scheme allows $n$ signers, each with their own secret/public key pair $(sk_i, pk_i)$ and message $m_i$, to jointly produce a short signature that simultaneously witnesses that $m_i$ has been signed under $pk_i$ for every $i \in \{1, \dots, n\}$. Despite the large potential for savings in terms of space and verification time, which constitute the two main bottlenecks for large blockchain systems such as Bitcoin, aggregate signatures have received much less attention than the other members of the multi-party signature family, namely multi-signatures such as $\mathsf{MuSig2}$ and threshold signatures such as $\mathsf{FROST}$.

In this paper, we propose $\mathsf{DahLIAS}$, the first aggregate signature scheme with constant-size signatures—a signature has the same shape as a standard Schnorr signature—directly based on discrete logarithms in pairing-free groups. The signing protocol of $\mathsf{DahLIAS}$ consists of two rounds, the first of which can be preprocessed without the message, and verification (for a signature created by $n$ signers) is dominated by one multi-exponentiation of size $n+1$, which is asymptotically twice as fast as batch verification of $n$ individual Schnorr signatures.

$\mathsf{DahLIAS}$ is designed with real-world applications in mind. Besides the aforementioned benefits of space savings and verification speedups, $\mathsf{DahLIAS}$ offers key tweaking, a technique commonly used in Bitcoin to derive keys in hierarchical deterministic wallets and to save space as well as enhance privacy on the blockchain. We prove $\mathsf{DahLIAS}$ secure in the concurrent setting with key tweaking under the (algebraic) one-more discrete logarithm assumption in the random oracle model.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 12:49:45 +0000</pubDate>
</item>
<item>
<title>SASTA: Ambushing Hybrid Homomorphic Encryption Schemes with a Single Fault</title>
<link>https://eprint.iacr.org/2024/041</link>
<guid>https://eprint.iacr.org/2024/041</guid>
<content:encoded><![CDATA[
Fully Homomorphic Encryption offers an effective solution for privacy-preserving computation, but its adoption is hindered by substantial computational and communication overheads. To address these, the Hybrid Homomorphic Encryption (HHE) protocol was developed, where the client encrypts data using a symmetric encryption scheme (SE), and the server homomorphically evaluates its decryption. Previous studies have demonstrated that the HHE protocol has no impact on the correctness of applications; however, in this work, we shift the focus to its security resilience  when subjected to Differential Fault Analysis (DFA). While DFA has proven effective against standalone symmetric-key primitives, no DFA study has been proposed that exploits the HHE protocol as a whole. Furthermore, previous DFA approaches on SE rely on strong assumptions such as nonce reuse, which limits their applicability in real-world protocols or practical applications.

In this work, we show that the structure of the HHE protocol itself exposes new avenues for fault exploitation. We introduce Sasta-DFA, which, to our knowledge, is the first DFA targeting HHE protocol in its entirety. Our study demonstrates that an attacker can achieve complete key recovery with a single fault injection. A key feature of this attack is that it does not require nonce reuse, thus adhering to nonce-related specifications. We adapt the IND-CPAD threat model proposed by Li and Micciancio at Eurocrypt’21 for HHE in the context of fault attacks. 

We conduct the first DFA study on the emerging HHE-specific integer-based SE schemes— Rubato, Hera, Pasta, and Masta. Notably, our attack methodology is generalizable and applicable to a broader class of HHE-friendly SE schemes, including boolean schemes like Rasta and even the standard scheme AES. We also present the first experimental validation of fault analysis on these new HHE-enabling schemes. Our attack, mounted on an ATXmega128D4-AU microcontroller, successfully demonstrates full key recovery. Finally, we also extend Sasta-DFA to Authenticated Transciphering protocols under a weaker threat model that removes any functional dependency.
]]></content:encoded>
<pubDate>Wed, 10 Jan 2024 13:43:36 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Protocol for Knowledge of Known Discrete Logarithms: Applications to Ring Confidential Transactions and Anonymous Zether</title>
<link>https://eprint.iacr.org/2025/690</link>
<guid>https://eprint.iacr.org/2025/690</guid>
<content:encoded><![CDATA[
The securities of a large fraction of zero-knowledge arguments of knowledge schemes rely on the discrete logarithm (DL) assumption or the discrete logarithm relation assumption, such as Bulletproofs (S&amp;P 18) and compressed $\Sigma$-protocol (CRYPTO 20). At the heart of these protocols is an interactive proof of knowledge between a prover and a verifier showing that a Pedersen vector commitment $P=h^{\rho}\cdot\textbf{g}^{\textbf{x}}$  to a vector $\textbf{x}$  satisfies multi-variate equations, where the DL relations among the vector of generators $\textbf{g}$ are unknown. However, in some circumstances, the prover may know the DL relations among the generators, and the DL relation assumption no longer holds, such as ring signatures, ring confidential transactions (RingCT) and K-out-of-N proofs, which will make the soundness proof of these protocols infeasible.
This paper is concerned with a problem called knowledge of known discrete logarithms (KKDL) that appears but has not been clearly delineated in the literature.  Namely, it asks to prove a set of multi-exponent equalities, starting with the fact that the prover may know the DL relations among the generators of these equalities.  Our contributions are three-fold:  (1) We propose a special honest-verifier zero-knowledge protocol for the problem.  Using the Fiat-Shamir heuristic and the improved inner-product argument of Bulletproofs,  the proof size of our protocol is logarithmic to the dimension of the vector. (2) As applications, our protocol can be utilized to construct logarithmic-size RingCT securely which fixes the issues of Omniring (CCS 19), ring signatures (with signature size $2\cdot \lceil \log_2(N) \rceil+10$ for ring size $N$) and  $K$-out-of-$N$ proof of knowledge (with proof size $2\cdot \lceil \log_2(N) \rceil+14$) which achieves the most succinct proof size improving on previous results. Meanwhile, we propose the first account-based multi-receiver privacy scheme considering the sender's privacy with logarithmic proof size (to the best of our knowledge). (3) We describe an attack on RingCT-3.0 (FC 20) where an attacker can spend a coin of an arbitrary amount that never existed on the blockchain.
]]></content:encoded>
<pubDate>Wed, 16 Apr 2025 09:51:57 +0000</pubDate>
</item>
<item>
<title>SUMAC: an Efficient Administrated-CGKA Using Multicast Key Agreement</title>
<link>https://eprint.iacr.org/2025/682</link>
<guid>https://eprint.iacr.org/2025/682</guid>
<content:encoded><![CDATA[
Since the standardization of the Secure Group Messaging protocol Messaging Layer Security (MLS) [4 ], whose core subprotocol is a Continuous Group Key Agreement (CGKA) mechanism named TreeKEM, CGKAs have become the norm for group key exchange protocols. However, in order to alleviate the security issue originating from the fact that all users in a CGKA are able to carry out sensitive operations on the member group, an augmented protocol called Administrated-CGKA (A-CGKA) has been recently created [2].

An A-CGKA includes in the cryptographic protocol the management of the administration rights that restrict the set of privileged users, giving strong security guarantees for the group administration. The protocol designed in [2] is a plugin added to a regular (black-box) CGKA, which consequently add some complexity to the underlying CGKA and curtail its performances. Yet, leaving the fully decentralized paradigm of a CGKA offers the perspective of new protocol designs, potentially more efficient.

We propose in this paper an A-CGKA called SUMAC, which offers strongly enhanced communication and storage performances compared to other A-CGKAs and even to TreeKEM. Our protocol is based on a novel design that modularly combines a regular CGKA used by the administrators of the group and a Tree-structured Multicast Key Agreement (TMKA) [9] – which is a centralized group key exchange mechanism administrated by a single group manager – between each administrator and all the standard users. That TMKA gives SUMAC an asymptotic communication cost logarithmic in the number of users, similarly to a CGKA. However, the concrete performances of our protocol are much better than the latter, especially in the post-quantum framework, due to the intensive use of secret-key cryptography that offers a lighter bandwidth than the public-key encryption schemes from a CGKA.

In practice, SUMAC improves the communication cost of TreeKEM by a factor 1.4 to 2.4 for admin operations and a factor 2 to 38 for user operations. Similarly, its storage cost divides that of TreeKEM by a factor 1.3 to 23 for an administrator and 3.9 to 1,070 for a standard user.

Our analysis of SUMAC is provided along with a ready-to-use open-source rust implementation that confirms the feasibility and the performances of our protocol.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 13:20:26 +0000</pubDate>
</item>
<item>
<title>Pirouette: Query Efficient Single-Server PIR</title>
<link>https://eprint.iacr.org/2025/680</link>
<guid>https://eprint.iacr.org/2025/680</guid>
<content:encoded><![CDATA[
Private information retrieval (PIR) allows a client to query a public database privately and serves as a key building block for privacy-enhancing applications. Minimizing query size is particularly important in many use cases, for example when clients operate on low-power or bandwidth-constrained devices. However, existing PIR protocols exhibit large query sizes: to query $2^{25}$ records, the smallest query size of 14.8KB is reported in Respire [Burton et al., CCS'24]. Respire is based on fully homomorphic encryption (FHE), where a common approach to lower the client-to-server communication cost is transciphering. When combining the state-of-the-art transciphering [Bon et al., CHES'24] with Respire, the resulting protocol (referred to as T-Respire) has a 336B query size, while incurring a 16.2x times higher server computation cost than Respire.

Our work presents the Pirouette protocol, which achieves a query size of just 36B without transciphering. This represents a 9.3x reduction compared to T-Respire and a 420x reduction to Respire. For queries over $2^{25}$ records, the single-core server computation in Pirouette is only 2x slower than Respire and 8.1x faster than T-Respire, and the server computation is highly parallelizable. Furthermore, Pirouette requires no database-specific hint for clients and naturally extends to support queries over encrypted databases.
]]></content:encoded>
<pubDate>Tue, 15 Apr 2025 11:29:04 +0000</pubDate>
</item>
<item>
<title>Trilithium: Efficient and Universally Composable Distributed ML-DSA Signing</title>
<link>https://eprint.iacr.org/2025/675</link>
<guid>https://eprint.iacr.org/2025/675</guid>
<content:encoded><![CDATA[
<div> 关键词: Trilithium、分布式密钥生成、签名协议、FIPS 204 (ML-DSA)、恶意安全、通用可组合性(UC)模型、Rust实现、性能基准测试

总结:
本文介绍了Trilithium协议，这是一项符合FIPS 204（ML-DSA）标准的分布式密钥生成和签名协议。该协议允许“服务器”和“手机”在相关随机数提供者的协助下生成标准的ML-DSA签名。文章证明了在通用可组合性(UC)模型下，即使面对恶意的服务器或手机，Trilithium协议也能确保安全，并引入了一些新的技术来论证针对一方具有活性安全，而对另一方仅具有活性隐私保护的两方安全计算协议的安全性。此外，文中还提供了使用Rust语言实现的Trilithium协议，并对其进行了性能基准测试，证实了该协议的实际可行性。 <div>
In this paper, we present Trilithium: a protocol for distributed key generation and signing compliant with FIPS 204 (ML-DSA). Our protocol allows two parties, "server" and "phone" with assistance of correlated randomness provider (CRP) to produce a standard ML-DSA signature. We prove our protocol to be secure against a malicious server or phone in the universal composability (UC) model, introducing some novel techniques to argue the security of two-party secure computation protocols with active security against one party, but only active privacy against the other. We provide an implementation of our protocol in Rust and benchmark it, showing the practicality of the protocol.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 20:36:41 +0000</pubDate>
</item>
<item>
<title>A Dilithium-like Multisignature in Fully Split Ring and Quantum Random Oracle Model</title>
<link>https://eprint.iacr.org/2025/671</link>
<guid>https://eprint.iacr.org/2025/671</guid>
<content:encoded><![CDATA[
<div> 关键词：多签名方案、后量子密码学、量子随机oracle模型（QROM）、Dilithium、$\nu$-SelfTargetMSIS

总结:<br />
本文提出了一种基于Dilithium的新颖多签名方案，该方案旨在保证在量子随机oracle模型（QROM）下的安全性并优化实际应用效率。方案利用了环$\mathbb{Z}_q[X]/(x^n+1)$与$q \equiv 1 \pmod{2n}$的设计，实现了环的完全分割和高效的多项式算术通过数论变换（NTT）。此外，文章还提出了一种新的困难度假设——$\nu$-SelfTargetMSIS，扩展了原有的SelfTargetMSIS（出自Eurocrypt 2018），用于适应多个挑战目标的情况。这一新假设在QROM下被证明安全，并被用来构建一个既安全又高效的多签名方案。相较于先前技术，本文方法避免了局限性，减少了安全性损失，并得出一个更紧凑、更适合部署在后量子密码系统中的实用方案。 <div>
Multisignature schemes are crucial for secure operations in digital wallets and escrow services within smart contract platforms, particularly in the emerging post-quantum era. Existing post-quantum multisignature constructions either do not address the stringent requirements of the Quantum Random Oracle Model (QROM) or fail to achieve practical efficiency due to suboptimal parameter choices. 

In this paper, we present a novel Dilithium-based multisignature scheme designed to be secure in the QROM and optimized for practical use. Our scheme operates over the polynomial ring  $\mathbb{Z}_q[X]/(x^n+1)$ with $q \equiv 1 \pmod{2n}$, enabling full splitting of the ring and allowing for efficient polynomial arithmetic via the Number Theoretic Transform (NTT). This structure not only ensures post-quantum security but also bridges the gap between theoretical constructs and real-world implementation needs.

We further propose a new hardness assumption, termed 
$\nu$-SelfTargetMSIS, extending SelfTargetMSIS (Eurocrypt 2018) to accommodate multiple challenge targets. We prove its security in the QROM and leverage it to construct a secure and efficient multisignature scheme. Our approach avoids the limitations of previous techniques, reduces security loss in the reduction, and results in a more compact and practical scheme suitable for deployment in post-quantum cryptographic systems.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 10:18:41 +0000</pubDate>
</item>
<item>
<title>SoK: FHE-Friendly Symmetric Ciphers and Transciphering</title>
<link>https://eprint.iacr.org/2025/669</link>
<guid>https://eprint.iacr.org/2025/669</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全同态加密(FHE), 加密数据计算, 明文-密文扩展比, 变换加密技术, 性能基准测试

总结:
本文关注了完全同态加密（FHE）中的一个重要挑战，即显著的明文-密文扩展比率导致的高通信开销。为解决此问题，文章探讨了一种有效的变换加密技术，该技术通过首先使用空间高效的对称密码加密数据，然后再将对称密文转换为FHE密文，而无需解密。研究者已经开发了二十多种FHE友好的对称密码和变换加密方法，但选择与比较这些方案需要深入理解对称加密和FHE。为此，本文进行了详尽的调查，并基于安全级别、效率和兼容性等标准对这些方法进行了评估。作者还设计并执行了实验，以基准测试不同应用场景下各种对称密码和变换加密方法组合的性能。研究结果为根据任务上下文定制高效的变换加密提供了见解。此外，作者还将利用最新FHE实现的示例代码开源共享。 <div>
Fully Homomorphic Encryption (FHE) enables computation on encrypted data without decryption, demonstrating significant potential for privacy-preserving applications.
However, FHE faces several challenges, one of which is the significant plaintext-to-ciphertext expansion ratio, resulting in high communication overhead between client and server. The transciphering technique can effectively address this problem by first encrypting data with a space-efficient symmetric cipher, then converting symmetric ciphertext to FHE ciphertext without decryption.

Numerous FHE-friendly symmetric ciphers and transciphering methods have been developed by researchers, each with unique advantages and limitations. These often require extensive knowledge of both symmetric cryptography and FHE to fully grasp, making comparison and selection among these schemes challenging. To address this, we conduct a comprehensive survey of over 20 FHE-friendly symmetric ciphers and transciphering methods, evaluating them based on criteria such as security level, efficiency, and compatibility. We have designed and executed experiments to benchmark the performance of the feasible combinations of symmetric ciphers and transciphering methods across various application scenarios. Our findings offer insights into achieving efficient transciphering tailored to different task contexts. Additionally, we make our example code available open-source, leveraging state-of-the-art FHE implementations.
]]></content:encoded>
<pubDate>Mon, 14 Apr 2025 01:34:00 +0000</pubDate>
</item>
<item>
<title>SQIAsignHD: SQIsignHD Adaptor Signature</title>
<link>https://eprint.iacr.org/2024/561</link>
<guid>https://eprint.iacr.org/2024/561</guid>
<content:encoded><![CDATA[
<div> 关键词：adaptor签名、量子攻击、椭圆曲线、超奇异同构、SIDH协议

总结:
本文提出了一种新的量子抵抗型适配器签名方案$\mathsf{SQIAsignHD}$，该方案基于超奇异椭圆曲线上的同构，并利用SIDH（超奇异同构Diffie-Hellman密钥交换）协议中的人工定向思想定义其基础难题。$\mathsf{SQIAsignHD}$旨在解决现有适配器签名方案对量子攻击的脆弱性问题。同时，文中还为所提出的签名方案提供了正式的安全证明。此工作对于区块链应用，包括加密货币以及支付通道网络、支付通道中心和原子交换等领域具有重要意义，因为它可以降低链上成本、提高可替代性和实现离链支付。 <div>
Adaptor signatures can be viewed as a generalized form of standard digital signature schemes by linking message authentication to the disclosure of a secret value. As a recent cryptographic primitive, they have become essential for blockchain applications, including cryptocurrencies, by reducing on-chain costs, improving fungibility, and enabling off-chain payments in payment-channel networks, payment-channel hubs, and atomic swaps. However, existing adaptor signature constructions are vulnerable to quantum attacks due to Shor's algorithm. In this work, we introduce $\mathsf{SQIAsignHD}$, a new quantum-resistant adaptor signature scheme based on isogenies of supersingular elliptic curves, using SQIsignHD - as the underlying signature scheme - and exploiting the idea of the artificial orientation on the supersingular isogeny Diffie-Hellman key exchange protocol, SIDH, to define the underlying hard relation. We, furthermore, provide a formal security proof for our proposed scheme.
]]></content:encoded>
<pubDate>Thu, 11 Apr 2024 13:31:30 +0000</pubDate>
</item>
<item>
<title>Vector Commitment Design, Analysis, and Applications: A Survey</title>
<link>https://eprint.iacr.org/2025/667</link>
<guid>https://eprint.iacr.org/2025/667</guid>
<content:encoded><![CDATA[
<div> 关键词: 哈希承诺、矢量承诺、多项式承诺、功能性承诺、分布式应用<br /><br />总结:
本文系统地梳理了哈希承诺以及其中的矢量承诺、多项式承诺和功能性承诺的设计原理、特性、属性及应用场景。文章首先定义并探讨了这些不同类型承诺方案之间的关系，明确了它们的安全性概念及相关性质。接着，对一些主流构造方法进行了对比分析，考虑了各自的特性、证明/更新信息大小以及证明/承诺复杂度。此外，文中还讨论了它们在各种分布式和隐私保护应用中的效率。最后，作者指出了未来可能的研究方向。 <div>
Due to their widespread applications in decentralized and privacy preserving technologies, commitment schemes have become increasingly important cryptographic primitives. With a wide variety of applications, many new constructions have been proposed, each enjoying different features and security guarantees. In this paper, we systematize the designs, features, properties, and applications of vector commitments (VCs). We define vector, polynomial, and functional commitments and we discuss the relationships shared between these types of commitment schemes. We first provide an overview of the definitions of the commitment schemes we will consider, as well as their security notions and various properties they can have. We proceed to compare popular constructions, taking into account the properties each one enjoys, their proof/update information sizes, and their proof/commitment complexities. We also consider their effectiveness in various decentralized and privacy preserving applications. Finally, we conclude by discussing some potential directions for future work.
]]></content:encoded>
<pubDate>Sun, 13 Apr 2025 02:11:13 +0000</pubDate>
</item>
<item>
<title>MProve-Nova: A Privacy-Preserving Proof of Reserves Protocol for Monero</title>
<link>https://eprint.iacr.org/2025/665</link>
<guid>https://eprint.iacr.org/2025/665</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof of Reserves (PoR), MProve-Nova, Monero, Nova recursive SNARK, Merkle trees

总结:
MProve-Nova 是一种针对门罗币（Monero）的无需可信设置的Proof of Reserves (PoR)协议，它利用Nova递归SNARK技术实现了两个创新点。首先，该协议首次仅揭示交易所拥有的输出数量，而不泄露其他关于输出或其密钥图像的信息。其次，它是首个拥有常量证明大小和验证时间的门罗币PoR协议，证明大小和验证时间与门罗区块链上的输出数量及交易所持有的输出数量无关。为了实现常量验证时间，MProve-Nova需要一个预处理步骤，该步骤会从门罗区块链的所有输出和密钥图像构建两棵默克尔树。

MProve-Nova由两个基于Nova的子协议组成：用于生成储备承诺的RCG协议和用于证明两个交易所之间未共谋的非共谋（NC）协议。RCG协议的证明大小约为28 KB，验证时间为4.3秒；而NC协议的证明大小约为24 KB，验证时间为0.2秒。两个协议的证明时间均随交易所持有的输出数量线性增加，但与门罗区块链上的输出数量无关。平均而言，对于RCG协议，每处理1000个输出大约需要42分钟，而对于NC协议，每处理1000个输出大约需要5分钟。 <div>
A proof of reserves (PoR) protocol enables a cryptocurrency exchange to prove to its users that it owns a certain amount of coins, as a first step towards proving that it is solvent. We present the design, implementation, and security analysis of MProve-Nova, a PoR protocol for Monero that leverages the Nova recursive SNARK to achieve two firsts (without requiring any trusted setup). It is the first Monero PoR protocol that reveals only the number of outputs owned by an exchange; no other information about the outputs or their key images is revealed. It is also the first Monero PoR protocol where the proof size and proof verification time are constant, i.e. they are independent of the number of outputs on the Monero blockchain and the number of outputs owned by the exchange. To achieve constant verification times, MProve-Nova requires a pre-processing step which creates two Merkle trees from all the outputs and key images on the Monero blockchain.

MProve-Nova consists of two Nova-based subprotocols, a reserves commitment generator (RCG) protocol used to compute a commitment to the total reserves owned by an exchange and a non-collusion (NC) protocol used to prove non-collusion between two exchanges. For the RCG protocol, we observed proof sizes of about 28 KB and verification times of 4.3 seconds. For the NC protocol, we observed proof sizes of about 24 KB and verification times of 0.2 seconds. Proving times for both protocols increase linearly with the number of outputs owned by the exchange but remain independent of the number of outputs on the Monero blockchain. On average, the RCG protocol required about 42 minutes per 1000 outputs and the NC protocol required about 5 minutes per 1000 outputs.
]]></content:encoded>
<pubDate>Sat, 12 Apr 2025 18:47:40 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Generalized Secret Sharing Schemes and Their Applications</title>
<link>https://eprint.iacr.org/2025/664</link>
<guid>https://eprint.iacr.org/2025/664</guid>
<content:encoded><![CDATA[
<div> 关键词：Generalized Secret Sharing (GSS)，Publicly Verifiable Generalized Secret Sharing (PVGSS)，Distributed Computing，Decentralized Exchange (DEX)，Non-Interactive Zero-Knowledge Proofs (NIZK)

<br /><br />总结:
本文提出了一种新的公开可验证广义秘密共享(PVGSS)方案，旨在提升GSS在透明系统中的应用性。PVGSS允许经销商基于细粒度的访问结构分享秘密，并使任何人都能验证经销商和股东是否诚信行事。文章首先介绍了两种实现GSS方案的方法，分别基于递归Shamir秘密共享和线性秘密共享方案(LSSS)。接着，通过将非交互式零知识证明集成到GSS方案中，提出了PVGSS构造方法，并证明该方案在DDH假设下达到了IND1保密性。为了展示PVGSS的实际应用，文章实现了一个支持公平原子交换ERC-20代币的去中心化交易所(DEX)协议，设计了复杂的访问结构以实现正常执行时的公平原子交换以及在出现纠纷时提供可问责仲裁的容错被动观察者。BN128曲线上的基准测试显示了PVGSS方案的计算效率，而Ethereum Gas成本分析证实了DEX实施的可行性。 <div>
Generalized secret sharing (GSS), which accommodates monotone access structures, has been under-explored in distributed computing over the past decades. In this paper, we propose the publicly verifiable generalized secret sharing (PVGSS) scheme, enhancing the applicability of GSS in transparent systems. PVGSS not only enables a dealer to share a secret with fine-grained access structures, but also allows anyone to verify whether the dealer and shareholders are acting honestly or not. We begin by introducing two approaches to implement GSS schemes: one based on recursive Shamir secret sharing and another utilizing linear secret sharing scheme (LSSS). Then, we present PVGSS constructions by integrating non-interactive zero-knowledge proofs into the GSS schemes. Further, we prove that the proposed PVGSS schemes achieve IND1-secrecy under DDH assumption. To showcase the practical applicability of PVGSS schemes, we implement a decentralized exchange (DEX) protocol that enables fair atomic swaps of ERC-20 tokens. A sophisticated access structure is devised to: (1) enable fair atomic swaps during normal protocol execution, and (2) incorporate fault-tolerant passive watchers to provide accountable arbitration when disputes occur. Our benchmarks on the BN128 curve demonstrate the computational efficiency of PVGSS schemes, while Ethereum gas cost analysis confirms the viability of the DEX implementation.
]]></content:encoded>
<pubDate>Sat, 12 Apr 2025 04:15:51 +0000</pubDate>
</item>
<item>
<title>Attribute-Based Publicly Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/662</link>
<guid>https://eprint.iacr.org/2025/662</guid>
<content:encoded><![CDATA[
<div> 关键词: 属性基秘密分享(AB-SS), 公开验证秘密分享(AB-PVSS), 加密策略属性基加密(CP-ABE), 非交互式零知识证明(NIZK), 乐观公平交换

总结:
本文提出了一种新的属性基秘密分享(AB-SS)方案，允许经销商根据用户属性而非特定个体分配秘密，只有满足预设访问结构的授权用户才能恢复秘密。进一步地，引入了属性基公开验证秘密分享(AB-PVSS)概念，使得外部用户能验证经销商和股东广播消息的正确性。为了构建AB-PVSS方案，首先实现了一个去中心化的、具有较小密文尺寸和较少计算操作的CP-ABE方案，但作为权衡，该方案并未完全实现。接着，通过整合非交互式零知识证明(NIZK)，实现了CP-ABE密文的公共验证功能。基于CP-ABE和NIZK，构建了AB-PVSS原语。此外，还利用AB-PVSS方案实现了一个直观的乐观公平交换实现。最后，对提出的CP-ABE和AB-PVSS方案进行了安全性分析及全面实验，结果显示这两个方案相比于相关工作均表现出合理的性能。 <div>
Can a dealer share a secret without knowing the shareholders? We provide a positive answer to this question by introducing the concept of an attribute-based secret sharing (AB-SS) scheme. With AB-SS, a dealer can distribute a secret based on attributes rather than specific individuals or shareholders. Only authorized users whose attributes satisfy a given access structure can recover the secret. Furthermore, we introduce the concept of attribute-based publicly verifiable secret sharing (AB-PVSS). An AB-PVSS scheme allows external users to verify the correctness of all broadcast messages from the dealer and shareholders, similar to a traditional PVSS scheme. Additionally, AB-SS (or AB-PVSS) distinguishes itself from traditional SS (or PVSS) by enabling a dealer to generate shares according to an arbitrary monotone access structure. To construct an AB-PVSS scheme, we first implement a decentralized ciphertext-policy attribute-based encryption (CP-ABE) scheme. The proposed CP-ABE scheme offers a smaller ciphertext size and requires fewer computational operations, although it is not fully-fledged as a trade-off. We then incorporate non-interactive zero-knowledge (NIZK) proofs to enable public verification of the CP-ABE ciphertext. Based on the CP-ABE and NIZK proofs, we construct an AB-PVSS primitive. Furthermore, we present an intuitive implementation of optimistic fair exchange based on the AB-PVSS scheme. Finally, we conduct security analysis and comprehensive experiments on the proposed CP-ABE and AB-PVSS schemes. The results demonstrate that both schemes exhibit plausible performance compared to related works.
]]></content:encoded>
<pubDate>Fri, 11 Apr 2025 13:28:24 +0000</pubDate>
</item>
<item>
<title>Scalable and Fine-Tuned Privacy Pass from Group Verifiable Random Functions</title>
<link>https://eprint.iacr.org/2025/659</link>
<guid>https://eprint.iacr.org/2025/659</guid>
<content:encoded><![CDATA[
<div> 关键词: 匿名令牌方案、可信用户、组可验证随机函数(GVRF)、通信成本、服务器计算成本

总结:
本文提出了一个新的匿名令牌方案设计方法，该方案不再依赖于两方计算实现隐私保护的伪随机函数评估，而是利用GVRF使得用户能够生成可验证的伪随机数。GVRF在可信用户群内部提供匿名验证功能。文章基于Dodis-Yampolskiy VRF和等价类签名，利用配对和新的Diffie-Hellman反演假设，在通用群模型中构建了组可验证随机函数。这种构造具有紧凑的公钥和证明，同时评价与验证的成本只比Dodis-Yampolskiy VRF略有增加。通过使用GVRF代替OPRF，新方案实现了在发放阶段通信和服务器端计算成本为常量且独立于用户请求的令牌数量。此外，文中还引入了可更新令牌策略的概念，能够在事后（即通过信誉检查后）根据当前或预期网络状况动态调整流通中的未使用的令牌数量。该方案的令牌还可计数并公开可验证，但相对于Privacy Pass协议来说，其兑换和验证的计算开销更高，且unlinkability保证稍弱。 <div>
Abstract—Anonymous token schemes are cryptographic
protocols for limiting the access to online resources to
credible users. The resource provider issues a set of access
tokens to the credible user that they can later redeem
anonymously, i.e., without the provider being able to link
their redemptions. When combined with credibility tests such
as CAPTCHAs, anonymous token schemes can significantly
increase user experience and provider security, without
exposing user access patterns to providers.
Current anonymous token schemes such as the Privacy
Pass protocol by Davidson et al. rely on oblivious
pseudorandom functions (OPRFs), which let server and user
jointly compute randomly looking access tokens. For those
protocols, token issuing costs are linear in the number of
requested tokens.
In this work, we propose a new approach for building
anonymous token schemes. Instead of relying on two-party
computation to realize a privacy-preserving pseudorandom
function evaluation, we propose to offload token generation
to the user by using group verifiable random functions
(GVRFs). GVRFs are a new cryptographic primitive
that allow users to produce verifiable pseudorandomness.
Opposed to standard VRFs, verification is anonymous within
the group of credible users. We give a construction of group
VRFs from the Dodis-Yampolskiy VRF and Equivalence-
Class Signatures, based on pairings and a new Diffie-
Hellman inversion assumption that we analyze in the Generic
Group Model. Our construction enjoys compact public keys
and proofs, while evaluation and verification costs are only
slightly increased compared to the Dodis-Yampolskiy VRF.
By deploying a group VRF instead of a OPRF, we
obtain an anonymous token scheme where communication
as well as server-side computation during the issuing phase
is constant and independent of the number of tokens a
user requests. Moreover, by means of our new concept of updatable token policies, the number of unspent tokens in
circulation can retrospectively (i.e., even after the credibility
check) be decreased or increased in order to react to
the current or expected network situation. Our tokens are
further countable and publicly verifiable. This comes at the
cost of higher computational efforts for token redemption
and verification as well as somewhat weaker unlinkability
guarantees compared to Privacy Pass.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 09:50:30 +0000</pubDate>
</item>
<item>
<title>Efficient Verifiable Mixnets from Lattices, Revisited</title>
<link>https://eprint.iacr.org/2025/658</link>
<guid>https://eprint.iacr.org/2025/658</guid>
<content:encoded><![CDATA[
<div> 关键词: Mixnets、量子安全、零知识证明、环同态加密、解密混合网

总结:
本文提出了一个基于环问题硬度的最紧凑可验证混合网络，旨在确保隐私和可验证性，同时抵抗量子计算机带来的安全性威胁。文章指出了现有基于环同态加密的混合网方案中证明洗牌过程的声望证明存在的问题，并指出该问题在实际实现中的影响，成功对其中一个混合网实施了攻击。为解决此问题，文章提出了一种适用于分裂环的通用洗牌证明方法。为了提高效率，新方案采用了解密混合网，并利用多项式环上的LWE和LWR问题的困难度实现了非常高效的层叠结构，使得密文大小缩小了约10倍和2倍，线性大小的零知识证明也减小了4倍和2倍。 <div>
Mixnets are powerful building blocks for providing anonymity
in applications like electronic voting and anonymous messaging. The en-
cryption schemes upon which traditional mixnets are built, as well as the
zero-knowledge proofs used to provide verifiability, will, however, soon
become insecure once a cryptographically-relevant quantum computer is
built. In this work, we construct the most compact verifiable mixnet that
achieves privacy and verifiability through encryption and zero-knowledge
proofs based on the hardness of lattice problems, which are believed to
be quantum-safe.

A core component of verifiable mixnets is a proof of shuffle. The starting
point for our construction is the proof of shuffle of Aranha et al. (CT-
RSA 2021). We first identify an issue with the soundness proof in that
work, which is also present in the adaptation of this proof in the mixnets
of Aranha et al. (ACM CCS 2023) and Hough et al. (IACR CiC 2025).
The issue is that one cannot directly adapt classical proofs of shuffle
to the lattice setting due to the splitting structure of the rings used in
lattice-based cryptography. This is not just an artifact of the proof, but
a problem that manifests itself in practice, and we successfully mount an
attack against the implementation of the first of the mixnets. We fix the
problem and introduce a general approach for proving shuffles in split-
ting rings that can be of independent interest.

The efficiency improvement of our mixnet over prior work is achieved by
switching from re-encryption mixnets (as in the works of Aranha et al.
and Hough et al.) to decryption mixnets with very efficient layering based
on the hardness of the LWE and LWR problems over polynomial rings.
The ciphertexts in our scheme are smaller by approximately a factor of
10X and 2X over the aforementioned instantiations, while the linear-size
zero-knowledge proofs are smaller by a factor of 4X and 2X.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 09:35:21 +0000</pubDate>
</item>
<item>
<title>Unbounded Multi-Hop Proxy Re-Encryption with HRA Security: An LWE-Based Optimization</title>
<link>https://eprint.iacr.org/2025/656</link>
<guid>https://eprint.iacr.org/2025/656</guid>
<content:encoded><![CDATA[
<div> 关键词: Proxy Re-Encryption, 多跳, 线性代数基, 适应性HRA安全, 高效率

<br /><br />总结:
本文提出了一种基于线性代数基的、具有适应性HRA安全级别的新型无界多跳Proxy Re-Encryption（PRE）方案。与此前Zhao等人提出的仅支持选择性CPA安全的无界多跳PRE方案相比，我们的方案提供更强的安全性。我们优化了基于FHEW-like盲旋转的重加密过程，解决了将Fuchsbauer等人框架应用于FHEW-like方案时，噪声泛滥技术与该框架之间的不兼容问题，从而降低了公钥的存储需求并提高了效率。此外，我们的优化无界多跳PRE方案还可以修改为无界同态PRE方案，允许对新鲜、重新加密和评估过的密文进行任意的同态计算，更加适用于实际应用场景。 <div>
Proxy re-encryption (PRE) schemes enable a semi-honest proxy to transform a ciphertext of one user $i$ to another user $j$ while preserving the privacy of the underlying message. Multi-hop PRE schemes allow a legal ciphertext to undergo multiple transformations, but for lattice-based multi-hop PREs, the number of transformations is typically bounded due to the increase of error terms. Recently, Zhao et al. (Esorics 2024) introduced a lattice-based unbounded multi-hop (homomorphic) PRE scheme that supports an unbounded number of hops. Nevertheless, their scheme only achieves the selective CPA security. In contrast, Fuchsbauer et al. (PKC 2019) proposed a generic framework for constructing HRA-secure unbounded multi-hop PRE schemes from FHE. Despite this, when instantiated with state-of-the-art FHEW-like schemes, the overall key size and efficiency remain unsatisfactory. 

In this paper, we present a lattice-based unbounded multi-hop PRE scheme with the stronger adaptive HRA security (i.e. security against honest re-encryption attacks), which is more suitable for practical applications. Our scheme features an optimized re-encryption process based on the FHEW-like blind rotation, which resolves the incompatibility between the noise flooding technique and Fuchsbauer et al. 's framework when instantiated with FHEW-like schemes. This results in reduced storage requirements for public keys and offers higher efficiency. Moreover, our optimized unbounded multi-hop PRE scheme can be modified to an unbounded homomorphic PRE, a scheme allowing for arbitrary homomorphic computations over fresh, re-encrypted, and evaluated ciphertexts.
]]></content:encoded>
<pubDate>Thu, 10 Apr 2025 07:14:20 +0000</pubDate>
</item>
<item>
<title>ECDSA Cracking Methods</title>
<link>https://eprint.iacr.org/2025/654</link>
<guid>https://eprint.iacr.org/2025/654</guid>
<content:encoded><![CDATA[
<div> 关键词: ECDSA、区块链、数字签名、nonce、安全性

总结:
ECDSA（椭圆曲线数字签名算法）被许多区块链网络用于生成数字签名，包括比特币和以太坊。然而，其安全性和高效性的同时，对nonce值的使用需要谨慎处理。文章指出了几种可以利用来破解ECDSA签名的方法：一是nonce值泄露，二是弱nonce选择，三是nonce重复使用，四是两个密钥与共享nonce，五是故障攻击。这些情况都可能给ECDSA的安全性带来严重威胁。<br /><br /> <div>
The ECDSA (Elliptic Curve Digital Signature Algorithm) is used in many blockchain networks for digital signatures. This includes the Bitcoin and the Ethereum blockchains. While it has good performance levels and as strong current security, it should be handled with care. This care typically relates to the usage of the nonce value which is used to create the signature. This paper outlines the methods that can be used to break ECDSA signatures, including revealed nonces, weak nonce choice, nonce reuse, two keys and shared nonces, and fault attack.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 20:49:17 +0000</pubDate>
</item>
<item>
<title>Fission: Distributed Privacy-Preserving Large Language Model Inference</title>
<link>https://eprint.iacr.org/2025/653</link>
<guid>https://eprint.iacr.org/2025/653</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型, 隐私保护, 安全多方计算, 分割推理, Fission

总结:
本文提出了一种名为Fission的隐私保护框架，旨在解决大型语言模型（LLMs）应用中的隐私问题。Fission结合了安全多方计算（MPC）和非线性函数计算器网络，其中线性计算通过MPC网络进行，而非线性计算则在接收打乱值的独立评估网络上完成，从而确保每个评估器仅能访问部分打乱数据，同时保持模型权重的私密性。相较于现有方法，Fission在广泛测试的LLMs上实现了最高达八倍的更快推理速度和八倍的带宽降低，同时还保持了高精度。此外，文中还构建了一个针对相关工作中的分割推理技术的攻击示例，揭示了其存在显著的信息泄露问题，进一步证明了Fission在增强隐私保护方面所具有的优势。 <div>
The increased popularity of large language models (LLMs) raises serious privacy concerns, where users' private queries are sent to untrusted servers. Many cryptographic techniques have been proposed to provide privacy, such as secure multiparty computation (MPC), which enables the evaluation of LLMs directly on private data. However, cryptographic techniques have been deemed impractical as they introduce large communication and computation. On the other hand, many obfuscation techniques have been proposed, such as split inference, where part of the model is evaluated on edge devices to hide the input data from untrusted servers, but these methods provide limited privacy guarantees.

We propose Fission, a privacy-preserving framework that improves latency while providing strong privacy guarantees. Fission utilizes an MPC network for linear computations, while nonlinearities are computed on a separate evaluator network that receives shuffled values in the clear and returns nonlinear functions evaluated at these values back to the MPC network. As a result, each evaluator only gets access to parts of the shuffled data, while the model weights remain private. We evaluate fission on a wide set of LLMs and compare it against prior works. Fission results in up to eight times faster inference and eight times reduced bandwidth compared to prior works while retaining high accuracy. Finally, we construct an attack on obfuscation techniques from related works that show significant information leakage, and we demonstrate how Fission enhances privacy.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 19:07:20 +0000</pubDate>
</item>
<item>
<title>Anamorphic Voting: Ballot Freedom Against Dishonest Authorities</title>
<link>https://eprint.iacr.org/2025/647</link>
<guid>https://eprint.iacr.org/2025/647</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子投票、解密密钥、投票隐私、共谋环境、幻影投票、加密技术

总结:
文章提出了“幻影投票”这一概念，用于解决电子投票系统在完全不诚实环境下，所有计票机构可能合谋破坏选民投票隐私的问题。幻影投票允许选民在投出看似常规的选票的同时，能够向审计员真实传达其投票意向。文章进一步展示了新的加密技术，证明了若干现有的投票方案可以支持幻影投票的实现。<br /><br /> <div>
Electronic voting schemes typically ensure ballot privacy by
assuming that the decryption key is distributed among tallying authorities, preventing any single authority from decrypting a voter’s ballot.
However, this assumption may fail in a fully dishonest environment where
all tallying authorities collude to break ballot privacy.
In this work, we introduce the notion of anamorphic voting, which enables voters to convey their true voting intention to an auditor while
casting an (apparently) regular ballot. We present new cryptographic
techniques demonstrating that several existing voting schemes can support anamorphic voting.
]]></content:encoded>
<pubDate>Wed, 09 Apr 2025 08:10:06 +0000</pubDate>
</item>
<item>
<title>GIGA Protocol: Unlocking Trustless Parallel Computation in Blockchains</title>
<link>https://eprint.iacr.org/2025/645</link>
<guid>https://eprint.iacr.org/2025/645</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、可扩展性、SNARK协议、并行执行、交易复杂性

总结:
本文提出了一种名为GIGA的基于SNARK协议的区块链解决方案，旨在解决现代去中心化区块链系统的可扩展性问题。GIGA协议通过将交易组织成非冲突批处理并在多个分布式实体间信任lessly地并行执行和证明，实现了并发处理非冲突操作，同时保持安全性和状态一致性。通过递归聚合批量证明为单个简洁证明，该协议消除了网络中的冗余重执行，显著提升了区块链吞吐量，不影响去中心化特性。

在相同的系统假设下（例如共识、网络和虚拟机架构），当大多数交易作用于状态的不同部分时，与采用顺序执行模型的流行区块链架构相比，GIGA协议的吞吐量提升可达一万倍以上，相较于使用节点内部并行化方案的区块链架构，也有超过五百倍的性能提升。此外，该协议还支持更高的交易计算复杂性，从而解锁了传统区块链架构上因计算能力有限而无法实现的各种应用场景。

另外，文章还提出了一个奖励机制，以确保证明网络的经济可持续性，动态适应计算需求并基于成本效率和可靠性激励竞争。 <div>
The scalability of modern decentralized blockchain systems is constrained by the requirement that the participating nodes execute the entire chains transactions without the ability to delegate the verification workload across multiple actors trustlessly. This is further limited by the need for sequential transaction execution and repeated block validation, where each node must re-execute all transactions before accepting blocks, also leading to delayed broadcasting in many architectures.

Consequently, throughput is limited by the capacity of individual nodes, significantly preventing scalability.

In this paper, we introduce GIGA, a SNARK-based protocol that enables trustless parallel execution of transactions, processing non-conflicting operations concurrently, while preserving security guarantees and state consistency. The protocol organizes transactions into non-conflicting batches which are executed and proven in parallel, distributing execution across multiple decentralized entities. These batch proofs are recursively aggregated into a single succinct proof that validates the entire block.

As a result, the protocol both distributes the execution workload and removes redundant re-execution from the network, significantly improving blockchain throughput while not affecting decentralization.

Performance estimates demonstrate that, under the same system assumptions (e.g., consensus, networking, and virtual machine architecture) and under high degrees of transaction parallelism (i.e., when most transactions operate on disjoint parts of the state), our protocol may achieve over a 10000x throughput improvement compared to popular blockchain architectures that use sequential execution models, and over a 500x improvement compared to blockchain architectures employing intra-node parallelization schemes. 

Furthermore, our protocol enables a significant increase in transaction computational complexity, unlocking a wide range of use cases that were previously unfeasible on traditional blockchain architectures due to the limited on-chain computational capacity.

Additionally, we propose a reward mechanism that ensures the economic sustainability of the proving network, dynamically adjusting to computational demand while fostering competition among provers based on cost-efficiency and reliability.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 17:18:19 +0000</pubDate>
</item>
<item>
<title>Scalable Non-Fungible Tokens on Bitcoin</title>
<link>https://eprint.iacr.org/2025/641</link>
<guid>https://eprint.iacr.org/2025/641</guid>
<content:encoded><![CDATA[
<div> 关键词: NFT、Bitcoin、桥接式铸造、二级共识系统、OP_RETURN<br /><br />总结:
该文提出了一种协议，用于扩展比特币上的非同质化代币（NFT）的创建、管理和交易。该协议借鉴了其他区块链上使用的无桥接铸造模式，通过利用比特币链上的数据处理所有与代币所有权相关的事宜，包括交易，并结合了一个二级共识系统来实现铸造和可选的元数据修改。为尽可能减小其在比特币主链上的占用空间，该协议使用OP_RETURN机制记录所有权信息，而相关的NFT操作则存储在LAOS区块链上。所有的数据均永久保存在链上，并不依赖于桥梁或第三方运营商。 <div>
This paper presents a protocol for scaling the creation, management, and trading of non-fungible tokens (NFTs) on Bitcoin by extending bridgeless minting patterns previously used on other blockchains. The protocol leverages on-chain Bitcoin data to handle all aspects of token ownership, including trading, while integrating a secondary consensus system for minting and optionally modifying token metadata. To minimize its on-chain footprint, the protocol utilizes the OP_RETURN mechanism for ownership records, while complementary NFT-related actions are stored on the LAOS blockchain. All data remains permanently on-chain, with no reliance on bridges or third-party operators.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 11:00:04 +0000</pubDate>
</item>
<item>
<title>A Study of Blockchain Consensus Protocols</title>
<link>https://eprint.iacr.org/2025/637</link>
<guid>https://eprint.iacr.org/2025/637</guid>
<content:encoded><![CDATA[
<div> 关键词: 比特币、共识机制、POW、Proof of Stake、区块链应用

总结:

本文介绍了自比特币开创第一代加密货币并采用工作量证明(POW)共识机制以来，为了解决能源消耗大和碳足迹重的问题，出现了一系列创新如空间证明(Proof of Space)、权益证明(POS)等不同的共识机制。随着区块链技术应用场景和类型的扩展，比如物联网(IoT)区块链和互操作性解决方案，对各种优化的共识机制产生了需求，例如拜占庭容错(BFT)算法。文章着重梳理了现有的区块链共识理论成果，整理了设计挑战、权衡以及研究领域，并以互操作性解决方案的案例为例展示了区块链设计空间的多样性和灵活性，旨在为研究人员提供一个全面的专题概述及深入研究每个细节的相关链接资源。 <div>
When Nakamoto invented Bitcoin, the first generation of cryptocurrencies followed it in applying POW (Proof of Work) consensus mechanism; due to its excessive energy consumption and heavy carbon footprints, new innovations evolved like Proof of Space, POS (Proof of Stake), and a lot more with many variants for each. Furthermore, the emergence of more blockchain applications and kinds beyond just cryptocurrencies needed more consensus mechanisms that is optimized to fit requirements of each application or blockchain kind; examples range from IoT (Internet of Things) blockchains for sustainability applications that often use variants of BFT (Byzantine Fault Tolerance) algorithm, and consensus needed to relay transactions and/or assets between different blockchains in interoperability solutions. Previous studies concentrated on surveying and/or proposing different blockchain consensus rules, on a specific consensus issue like attacks, randomization, or on deriving theoretical results. Starting from discussing most important theoretical results, this paper tries to gather and organize all significant existing material about consensus in the blockchain world explaining design challenges, tradeoffs and research areas. We realize that the topic could fit for a complete textbook, so we summarize the basic concepts and support with tables and appendices. Then we highlight some case examples from interoperability solutions to show how flexible and wide the design space is to fit both general and special purpose systems. The aim is to provide researchers with a comprehensive overview of the topic, along with the links to go deeper into every detail.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 07:30:27 +0000</pubDate>
</item>
<item>
<title>Towards Scalable YOSO MPC via Packed Secret-Sharing</title>
<link>https://eprint.iacr.org/2025/635</link>
<guid>https://eprint.iacr.org/2025/635</guid>
<content:encoded><![CDATA[
<div> 关键词: YOSO模型、分布式设置、安全多方计算、通信复杂度、fail-stop敌人

总结:
本文介绍了YOSO（You Only Speak Once）模型在实现分布式环境如区块链中的强大安全保障方面的应用。针对安全多方计算（MPC）这一核心问题，文章提出首个随参与方数量增加而提高效率（以通信复杂度衡量）的YOSO MPC协议。该协议中，对于$t<\frac{1}{2}$的诚实多数委员会成员，只需略微增加委员会规模，即可显著减少在线通信量。此外，文章还特别考虑了fail-stop类型的敌人（即可能因DoS攻击或软硬件错误而意外失败的诚实参与者），与先前的工作相比，这种情况下协议具有更好的可扩展性。在此前的研究中，这类敌人被视为完全恶意的参与者。 <div>
The YOSO (You Only Speak Once) model, introduced by Gentry et al. (CRYPTO 2021), helps to achieve strong security guarantees in cryptographic protocols for  distributed settings, like blockchains, with large number of parties. YOSO protocols typically employ smaller anonymous committees to execute individual rounds of the protocol instead of having all parties execute the entire protocol. After completing their tasks, parties encrypt protocol messages for the next anonymous committee and erase their internal state before publishing ciphertexts, thereby enhancing security in dynamically changing environments.

In this work, we consider the problem of secure multi-party computation (MPC), a fundamental problem in cryptography and distributed computing. We assume honest majority among the committee members, and work in the online-offline, i.e., preprocessing, setting.
   In this context, we present the first YOSO MPC protocol where efficiency---measured as communication complexity---improves as the number of parties increases. Specifically, for $0<\epsilon<1/2$ and an adversary corrupting $t<n(\frac{1}{2}-\epsilon)$ out of $n$ parties, our MPC protocol exhibits enhanced scalability as $n$ increases, where the online phase communication becomes independent of $n$.
   Prior YOSO MPC protocols considered $t$ as large as $(n-1)/2$, but a significant hurdle persisted in obtaining YOSO MPC with communication that does not scale linearly with the number of committee members, a challenge that is exagerbated when the committee size was large per YOSO's requirements.
   We show that, by considering a small ``gap'' of $\epsilon>0$, the sizes of the committees are only marginally increased, while online communication is significantly reduced.


Furthermore, we explicitly consider fail-stop adversaries, i.e., honest participants who may inadvertently fail due to reasons such as denial of service or software/hardware errors. In prior YOSO work, these adversaries were grouped with fully malicious parties. Adding explicit support for them allows us to achieve even better scalability.
]]></content:encoded>
<pubDate>Tue, 08 Apr 2025 05:25:39 +0000</pubDate>
</item>
<item>
<title>Dyna-hinTS: Silent Threshold Signatures for Dynamic Committees</title>
<link>https://eprint.iacr.org/2025/631</link>
<guid>https://eprint.iacr.org/2025/631</guid>
<content:encoded><![CDATA[
<div> 关键词：silent threshold signatures (STS), committee-based silent threshold signature (c-STS), hinTS, Dyna-hinTS, Ethereum Altair, Dfinity

总结:
本文提出了一个新的密码学概念——委员会型沉默阈值签名(c-STS)方案，旨在适应像Ethereum Altair和Dfinity这样的系统，其中只有指定的委员会被授权在特定时间段进行签名。现有的STS方案无法直接应用于委员会设置，因为其仅验证签名者的数量，而不能确认他们所属的委员会。针对这一问题，文章提出了首个c-STS方案——Dyna-hinTS，它是hinTS的升级版，实现了对委员会设置的支持。在一组1024个签名人（其中682个签名人可能被篡改）中，与hinTS相比，Dyna-hinTS在由80个签名人组成的委员会中能够在0.35秒内生成聚合签名，性能提高了4.9倍，但代价是签名验证时间比hinTS增加了4%。此外，Dyna-hinTS还支持一般的访问结构、加权签名，并改进了现有的多宇宙阈值签名技术。 <div>
The works of Garg et al. [S&amp;P'24] (aka hinTS) and Das et al. [CCS'23] introduced the notion of silent threshold signatures (STS) - where a set of signers silently perform local computation to generate a public verification key. To sign a message, any set of $t$ signers sign the message non-interactively and these are aggregated into a constant-sized signature. This paradigm avoids performing expensive Distributed Key Generation procedure for each set of signers while keeping the public verification key constant-sized. 

In this work, we propose the notion of committee-based silent threshold signature (c-STS) scheme. In a c-STS scheme, a set of signers initially perform a one-time setup to generate the verification key, and then a subset of signers are randomly chosen for an epoch to perform the threshold signing while the other signers are not authorized to sign during that epoch. This captures existing systems like Ethereum Altair and Dfinity where only a specific committee is authorized to sign in a designated epoch. The existing STS schemes cannot be extended to the committee setting because the signature verification only attests to the number of signing parties, not which committee they belong to.

So, we upgrade hinTS to the committee setting by proposing Dyna-hinTS. It is the $first$ c-STS scheme and it requires a one-time silent setup and generates a one-time public verification key that does not vary with the committee. Assuming a set of 1024 signers (with corrupt 682 signers), hinTS generates an aggregated signature in 1.7s whereas Dyna-hinTS generates it in $0.35$s within a committee of $80$ signers. This yields a $4.9\times$ improvement over hinTS for signature generation at the cost of increasing signature verification time by $4\%$ over hinTS. Dyna-hinTS supports general access structure, weighted signatures and improves existing multiverse threshold signatures.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 15:27:03 +0000</pubDate>
</item>
<item>
<title>Charge Your Clients: Payable Secure Computation and Its Applications</title>
<link>https://eprint.iacr.org/2025/630</link>
<guid>https://eprint.iacr.org/2025/630</guid>
<content:encoded><![CDATA[
<div> 关键词：数据市场、隐私保护、恶意客户端行为、安全计算、付费协议

总结:
针对当前数据市场存在的客户隐私保护不力和易受恶意客户端行为影响的问题，本文提出了“付费安全计算”这一新型安全计算范式，旨在保护客户查询隐私的同时，使服务器能够安全获取定价信息，并防范恶意客户端的行为。为具体应用，文章设计了适用于关键词私有信息检索（KPIR）和私有集合交集（PSI）两种场景的定制化付费协议。实验结果显示，相较于不支持定价功能的基线协议，提出的付费协议并未引入过多开销。付费KPIR协议在线成本与基线相同，但设置时间慢约1.3-1.6倍；付费PSI协议则需要大约2倍的通信成本，运行时间根据网络环境不同，比基线协议慢1.5-3.2倍。 <div>
The online realm has witnessed a surge in the buying and selling of data, prompting the emergence of dedicated data marketplaces. These platforms cater to servers (sellers), enabling them to set prices for access to their data, and clients (buyers), who can subsequently purchase these data, thereby streamlining and facilitating such transactions. However, the current data market is primarily confronted with the following issues. Firstly, they fail to protect client privacy, presupposing that clients submit their queries in plaintext. Secondly, these models are susceptible to being impacted by malicious client behavior, for example, enabling clients to potentially engage in arbitrage activities.

To address the aforementioned issues, we propose payable secure computation, a novel secure computation paradigm specifically designed for data pricing scenarios. It grants the server the ability to securely procure essential pricing information while protecting the privacy of client queries. Additionally, it fortifies the server's privacy against potential malicious client activities. As specific applications, we have devised customized payable protocols for two distinct secure computation scenarios: Keyword Private Information Retrieval (KPIR) and Private Set Intersection (PSI). 

We implement our two payable protocols and compare them with the state-of-the-art related protocols that do not support pricing as a baseline. Since our payable protocols are more powerful in the data pricing setting, the experiment results show that they do not introduce much overhead over the baseline protocols. 
Our payable KPIR achieves the same online cost as baseline, while the setup is about $1.3-1.6\times$ slower than it. Our payable PSI needs about $2\times$ more communication cost than that of baseline protocol, while the runtime is $1.5-3.2\times$ slower than it depending on the network setting.
]]></content:encoded>
<pubDate>Mon, 07 Apr 2025 13:45:34 +0000</pubDate>
</item>
<item>
<title>CertainSync: Rateless Set Reconciliation with Certainty</title>
<link>https://eprint.iacr.org/2025/623</link>
<guid>https://eprint.iacr.org/2025/623</guid>
<content:encoded><![CDATA[
<div> 关键词: Set Reconciliation、Blockchain Networks、CertainSync、Invertible Bloom Lookup Tables (IBLTs)、Universe Reduction

<br /><br />总结:
本文提出了名为 CertainSync 的一种新颖的集合同步框架，该框架首次保证了无需任何参数化或估计器的情况下成功进行集合和解同步。CertainSync 基于可逆布隆查找表 (IBLTs) 的近期构造，能够适应未知对称差集大小并确保当通信开销达到与对称差集和全集大小相关的下限时，完成成功的集合和解同步。理论上对其进行了分析以证明其确定性。通过仿真验证了该方法相对于其他基准集合和解同步方案的优势，同时对于区块链网络中大型全集的情况，扩展了 UniverseReduceSync 技术来进一步降低通信开销。通过对来自 Ethereum 区块链网络的真实交易哈希数据的模拟比较和验证，结果显示了一个改进通信开销与保持和解同步保障之间的权衡，为不同场景下的集合和解同步提供了全面解决方案。 <div>
Set reconciliation is a fundamental task in distributed systems, particularly in blockchain networks, where it enables the synchronization of transaction pools among peers and facilitates block dissemination. Existing traditional set reconciliation schemes are either statistical, providing success probability as a function of the communication overhead and the size of the symmetric difference, or require parametrization and estimation of the size of the symmetric difference, which can be prone to error. In this paper, we present CertainSync, a novel reconciliation framework that, to the best of our knowledge, is the first to guarantee successful set reconciliation without any parametrization or estimators in use. The framework is rateless and adapts to the unknown symmetric difference size. The set reconciliation is guaranteed to be completed successfully whenever the communication overhead reaches a lower bound derived from the symmetric difference size and the universe size. Our framework is based on recent constructions of Invertible Bloom Lookup Tables (IBLTs) ensuring successful element listing as long as the number of elements is bounded. We provide a theoretical analysis to prove the certainty in the set reconciliation for multiple constructions. The approach is also validated by simulations, showing the ability to synchronize sets with efficient communication costs while maintaining reconciliation guarantees compared to other baseline schemes for set reconciliation. To further improve communication overhead for large universes as blockchain networks, CertainSync is extended with a universe reduction technique to minimize communication overhead. We compare and validate the extended framework UniverseReduceSync against the basic CertainSync framework through simulations using real blockchain transaction hash data from the Ethereum blockchain network. The results illustrate a trade-off between improved communication costs and maintaining reconciliation guarantees without relying on parametrization or estimators, offering a comprehensive solution for set reconciliation in diverse scenarios.
]]></content:encoded>
<pubDate>Sun, 06 Apr 2025 20:17:58 +0000</pubDate>
</item>
<item>
<title>Need for zkSpeed: Accelerating HyperPlonk for Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/620</link>
<guid>https://eprint.iacr.org/2025/620</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明 (ZKPs)，隐私保护，可验证计算，GPU加速，ASIC加速，zkSpeed，HyperPlonk，可信设置，证明大小，验证成本，共识系统，SumCheck，多标量乘法 (MSMs)，芯片架构，带宽，性能提升。

<br /><br />总结：
本文介绍了针对零知识证明（ZKPs）技术的一种新型加速器——zkSpeed，该技术正在逐步成为隐私保护和可验证计算领域的关键工具。现有的ZKP协议加速方案存在需要每次应用都建立可信设置或产生较大证明规模、增加验证成本等问题。文章提出的新加速器zkSpeed专注于加速HyperPlonk这一支持一次性、通用设置以及为公共验证和基于共识系统的典型ZKP应用生成小规模证明的先进ZKP协议。文中设计了一个采用366.46 mm²面积和2TB/s带宽的全芯片架构，实现了对整个证明生成过程的加速，相比CPU基线实现了平均801倍的速度提升。 <div>
(Preprint) Zero-Knowledge Proofs (ZKPs) are rapidly gaining importance in privacy-preserving and verifiable computing. ZKPs enable a proving party to prove the truth of a statement to a verifying party without revealing anything else. ZKPs have applications in blockchain technologies, verifiable machine learning, and electronic voting, but have yet to see widespread adoption due to the computational complexity of the proving process.Recent works have accelerated the key primitives of state-of-the-art ZKP protocols on GPU and ASIC. However, the protocols accelerated thus far face one of two challenges: they either require a trusted setup for each application, or they generate larger proof sizes with higher verification costs, limiting their applicability in scenarios with numerous verifiers or strict verification time constraints. This work presents an accelerator, zkSpeed, for HyperPlonk, a state-of-the-art ZKP protocol that supports both one-time, universal setup and small proof sizes for typical ZKP applications in publicly verifiable, consensus-based systems. We accelerate the entire protocol, including two major primitives: SumCheck and Multi-scalar Multiplications (MSMs). We develop a full-chip architecture using 366.46 mm$^2$ and 2 TB/s of bandwidth to accelerate the entire proof generation process, achieving geometric mean speedups of 801$\times$ over CPU baselines.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 23:56:21 +0000</pubDate>
</item>
<item>
<title>Making BBS Anonymous Credentials eIDAS 2.0 Compliant</title>
<link>https://eprint.iacr.org/2025/619</link>
<guid>https://eprint.iacr.org/2025/619</guid>
<content:encoded><![CDATA[
<div> 关键词: eIDAS 2.0、BBS#、匿名凭证系统、数字身份钱包、隐私保护

总结:
本文提出了一个名为BBS#的数字身份钱包解决方案，旨在助力实现eIDAS 2.0的目标，为欧洲公民提供高安全性和隐私保护的个人数字身份钱包。BBS#是在BBS和BBS+基础上进行改进的版本，去除了对双线性映射和配对友好曲线的依赖，转而采用传统椭圆曲线上的已知数字签名方案（如ECDSA或ECSchnorr）。这一方案无需改变现有硬件或其所支持的算法，且已在随机预言机模型下被证明安全，同时保持了BBS系系统的不可伪造性以及匿名性等安全属性。

通过在不同智能手机的安全执行环境中实施BBS#，实验证明可以实现高效（约70毫秒在Android StrongBox上）、安全且达到最高等级认证要求的eIDAS 2.0交易，同时为所有欧洲身份证钱包用户提供最优级别的隐私保护。 <div>
eIDAS 2.0 (electronic IDentification, Authentication and trust Services) is a very ambitious regulation aimed at equipping European citizens with a personal digital identity wallet (EU Digital Identity Wallet) on a mobile phone that not only needs to achieve a high level of security, but also needs to be available as soon as possible for a large number of citizens and respect their privacy (as per GDPR - General Data Protection Regulation).  

In this paper, we introduce the foundations of a digital identity wallet solution that could help move closer to this objective by leveraging the proven anonymous credentials system BBS (Eurocrypt 2023), also known as BBS+, but modifying it to avoid the limitations that have hindered its widespread adoption, especially in certified infrastructures requiring trusted hardware implementation.  
In particular, the solution we propose, which we call BBS#, does not rely, contrary to BBS/BBS +, on bilinear maps and pairing-friendly curves (which are not supported by existing hardware) and only depends on the hardware implementation of well-known digital signature schemes such as ECDSA (ISO/IEC 14888-3) or ECSDSA (also known as ECSchnorr, ISO/IEC 14888-3) using classical elliptic curves. More precisely, BBS# can be rolled out without requiring any change in existing hardware or the algorithms that hardware supports. 
BBS# , which is proven secure in the random oracle model, retains the well-known security property (unforgeability of the credentials under the (gap) q-SDH assumption) and anonymity properties (multi-show full unlinkability and statistical anonymity of presentation proofs) of BBS/BBS+. 

By implementing BBS# on several smartphones using different secure execution environments, we show that it is possible to achieve eIDAS 2.0 transactions which are not only efficient (around 70 ms on Android StrongBox), secure and certifiable at the highest level but also provide strong (optimal) privacy protection for all European ID Wallet users.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 17:44:46 +0000</pubDate>
</item>
<item>
<title>Anonymous Self-Credentials and their Application to Single-Sign-On</title>
<link>https://eprint.iacr.org/2025/618</link>
<guid>https://eprint.iacr.org/2025/618</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字身份、隐私保护、Sybil抵抗、匿名自证明（ASC）、用户发行的不可链接单点登录（U2SSO）

总结:
随着数字身份变得不可或缺，确保用户隐私和实现服务提供者的Sybil抵抗机制至关重要。文章提出了一个新的加密概念——匿名自证明（ASC）及其两种实施方案，该方案允许用户在保持匿名集合内的隐私的同时，使服务提供者能够实现Sybil阻力。基于ASC，文章还介绍了一种用户发行的不可链接单点登录（U2SSO）解决方案，它仅依赖于一个身份注册库来不可变地存储身份，使得用户可以使用一套主凭据为每个服务提供商生成不可链接的子凭据。通过实际的概念验证，文章展示了U2SSO解决方案的实用性和效率。 <div>
Modern life makes having a digital identity no longer optional, whether one needs to manage a bank account or subscribe to a newspaper. As the number of online services increases, it is fundamental to safeguard user privacy and equip service providers (SP) with mechanisms enforcing Sybil resistance, i.e., preventing a single entity from showing as many. 
  Current approaches, such as anonymous credentials and self-sovereign identities, typically rely on identity providers or identity registries trusted not to track users' activities. However, this assumption of trust is no longer appropriate in a world where user data is considered a valuable asset. 
  To address this challenge, we introduce a new cryptographic notion, Anonymous Self-Credentials (ASC) along with two implementations. This approach enables users to maintain their privacy within an anonymity set while allowing SPs to obtain Sybil resistance. Then, we present a User-issued Unlinkable Single Sign-On (U2SSO) implemented from ASC that solely relies on an identity registry to immutably store identities. A U2SSO solution allows users to generate unlinkable child credentials for each SP using only one set of master credentials.
  We demonstrate the practicality and efficiency of our U2SSO solution by providing a complete proof-of-concept.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 16:44:58 +0000</pubDate>
</item>
<item>
<title>State Machine Replication Without Borders</title>
<link>https://eprint.iacr.org/2025/616</link>
<guid>https://eprint.iacr.org/2025/616</guid>
<content:encoded><![CDATA[
<div> 关键词: 状态机复制(SMR), 不诚实节点, 查询率, 恒定时间, 自我时钟同步

总结:
本文提出了一种在无权限设置下的状态机复制(SMR)协议，该协议针对具有不可信、不可靠的八卦网络环境中的不诚实节点。协议的目标是在参与节点持续波动及存在控制单位时间内查询率少于一半的拜占庭敌手的情况下，确保各节点对状态机器的公平访问并实时处理诚实节点提交的所有操作符号。与比特币区块链提供的协议（其在对抗拜占庭敌手时能实现多项式轮次的结算，但公平性仅在失败停止模型中成立）不同，新提出的协议首次实现了在该环境中同时具备预期恒定时延的结算和快速公平性。此外，此协议还具备自我时钟同步能力，能在参与者动态变化的情况下仍保持容错运行。 <div>
A set of unacquainted  parties, some of which may misbehave, communicate with each other over an unauthenticated and unreliable gossip network. They wish to jointly replicate a state machine $\Pi$ so that each one of them has fair access to its operation. Specifically, assuming parties' computational power is measured as queries to an oracle machine $H(\cdot)$, parties can issue symbols to the state machine in proportion to their queries to $H(\cdot)$ at a given fixed rate. Moreover, if such access to the state machine is provided continuously in expected constant time installments we qualify it as fast fairness.

A state machine replication (SMR) protocol in this permissionless setting is expected to offer consistency across parties and reliably process all symbols that honest parties wish to add to it in a timely manner despite  continuously fluctuating participation and in the presence of an adversary who commands less than half of the total queries to $H(\cdot)$ per unit of time.

A number of protocols strive to offer the above guarantee together with fast settlement  — notably, the Bitcoin blockchain offers a protocol that settles against Byzantine adversaries in polylogarithmic rounds, while fairness only holds in a fail-stop adversarial model (due to the fact that Byzantine behavior can bias access to the state machine in the adversary's favor). In this work, we put forth the first Byzantine-resilient protocol solving SMR in this setting with both expected-constant-time settlement and fast fairness. In addition, our protocol is self-sufficient in the sense of performing its own time keeping while tolerating an adaptively fluctuating set of parties.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 15:50:40 +0000</pubDate>
</item>
<item>
<title>Highly Efficient Actively Secure Two-Party Computation with One-Bit Advantage Bound</title>
<link>https://eprint.iacr.org/2025/614</link>
<guid>https://eprint.iacr.org/2025/614</guid>
<content:encoded><![CDATA[
<div> 关键词：两方计算（2PC）、主动安全性、一比特泄漏、公平性、一比特优势界<br /><br />总结：<br />
本文提出了一个新的安全概念——主动安全性带一比特优势界，通过渐进式揭示机制严格限制了敌手的优势不超过诚实方获取信息的一比特。为实现这一目标，文章设计了一种基于标签结构的高效常数轮2PC协议，该协议在双工网络中实现了与被动安全性garbled电路几乎相同的运行时间性能（例如，在LAN环境下对{\tt SHA256}电路，其通信开销仅比后者高$1.033\times$），并且输出渐进揭示的额外开销极低（每释放一位结果仅需通信$80$字节）。由于具备强化的安全保证和较低的额外开销，该协议非常适合实际应用中的两方计算场景。 <div>
Secure two-party computation (2PC) enables two parties to jointly evaluate a function while maintaining input privacy. Despite recent significant progress, a notable efficiency gap remains between actively secure and passively secure protocols. In S\&amp;P'12, Huang, Katz, and Evans formalized the notion of \emph{active security with one-bit leakage}, providing a promising approach to bridging this gap. Protocols derived from this notion have become foundational in designing highly efficient actively secure 2PC protocols. However, a critical challenge identified by Huang, Katz, and Evans remains unexplored: these protocols face significant weaknesses in ensuring fairness for honest parties when employed in standalone settings rather than as components within larger protocols. While the authors proposed two potential solutions to mitigate this issue, both approaches are prohibitively expensive and lack formalization of security guarantees.

In this paper, we first formally define an enhanced notion called \emph{active security with one-bit-advantage bound}, in which the adversaries' advantages are strictly bounded to at most one bit beyond what honest parties obtain. This bound is enforced through a \emph{progressive revelation} mechanism, where the evaluation result is disclosed incrementally bit by bit. In addition, we propose a novel approach leveraging label structures within garbled circuits to design a highly efficient constant-round 2PC protocol that achieves active security with one-bit advantage bound. Our protocol demonstrates \emph{runtime performance nearly identical to that of passively secure garbled-circuit counterparts} in duplex networks (\eg $1.033\times$ for the {\tt SHA256} circuit in LAN), with \emph{low overhead} for output progressive revelation (only $80$ communicated bytes per bit release).

With its strengthened security guarantees and minimal overhead, our protocol is highly suitable for practical 2PC applications.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 12:54:09 +0000</pubDate>
</item>
<item>
<title>Low-Latency Rate-Distortion-Perception Trade-off: A Randomized Distributed Function Computation Application</title>
<link>https://eprint.iacr.org/2025/613</link>
<guid>https://eprint.iacr.org/2025/613</guid>
<content:encoded><![CDATA[
<div> 关键词: 语义通信系统、率-失真-感知问题、图像压缩、物理层安全、量子攻击

<br /><br />
总结:
本文针对语义通信系统的应用背景，重点研究了在带宽有限和延迟敏感环境下图像压缩的率-失真-感知（RDP）问题。文章在随机分布式函数计算框架下，建立了非渐近性的RDP区域，明确了在有限块长度条件下率、失真与感知质量之间的权衡关系，符合语义通信的目标。进一步地，将这一区域扩展至包含保密性约束的情况，通过物理层安全方法确保对量子攻击具有抵抗能力。作者的主要贡献包括：(1) 在现实性和失真约束下建立非渐近性RDP区域的可行界；(2) 将这些边界扩展以提供强大的安全性保障；(3) 描述了在严格现实性约束下的渐近安全RDP区域特性；(4) 展示了在引入保密约束及有限块长度条件下的码率显著降低及其影响。这些研究成果为设计低延迟、高保真、安全的图像压缩系统提供了行动指南，尤其适用于隐私关键领域的应用。 <div>
Semantic communication systems, which focus on transmitting the semantics of data rather than its exact reconstruction, redefine the design of communication networks for transformative efficiency in bandwidth-limited and latency-critical applications. Addressing these goals, we tackle the rate-distortion-perception (RDP) problem for image compression, a critical challenge in achieving perceptually realistic reconstructions under rate constraints. Formulated within the randomized distributed function computation (RDFC) framework, we establish an achievable non-asymptotic RDP region, providing finite blocklength trade-offs between rate, distortion, and perceptual quality, aligning with semantic communication objectives. We extend this region to also include a secrecy constraint, providing strong secrecy guarantees against eavesdroppers via physical-layer security methods, ensuring resilience against quantum attacks. Our contributions include (i) establishing achievable bounds for non-asymptotic RDP regions under realism and distortion constraints; (ii) extending these bounds to provide strong secrecy guarantees; (iii) characterizing the asymptotic secure RDP region under a perfect realism constraint; and (iv) illustrating significant reductions in rates and the effects of secrecy constraints and finite blocklengths. Our results provide actionable insights for designing low-latency, high-fidelity, and secure image compression systems with realistic outputs, advancing applications, e.g., in privacy-critical domains.
]]></content:encoded>
<pubDate>Fri, 04 Apr 2025 07:51:58 +0000</pubDate>
</item>
<item>
<title>SCALES: MPC with Small Clients and Larger Ephemeral Servers</title>
<link>https://eprint.iacr.org/2022/751</link>
<guid>https://eprint.iacr.org/2022/751</guid>
<content:encoded><![CDATA[
<div> 关键词: YOSO模型、MPC、SCALES、重随机化加密码方案、适应性服务器腐败

总结:
YOSO模型是一种创新的MPC（多-party计算）方法，能够在公共区块链上执行并抵抗适应性玩家腐败。然而，由于其构建模块的成本问题，实际应用中YOSO模型效率低下。为了解决这一问题，文章提出了SCALES模型，该模型保持了对适应性服务器腐败的抗性，同时大大提高了协议效率。在SCALES模型中，只有负责MPC计算的服务器是短暂和不可预测的（一次性发送消息并揭示身份），而输入提供者（客户端）仅发布问题实例并收集结果，不参与计算过程。SCALES模型利用重随机化加密码方案构建而成，这是一个具有独立兴趣的技术贡献，还具备其他潜在应用。 <div>
The recently proposed YOSO model is a groundbreaking approach to MPC, executable on a public blockchain, circumventing adaptive player corruption by hiding the corruption targets until they are worthless. Players are selected unpredictably from a large pool to perform  MPC subtasks, in which each selected player sends a single message (and reveals their identity). While YOSO MPC has attractive asymptotic complexity,  unfortunately, it is concretely prohibitively expensive due to the cost of its building blocks.

We propose a modification to the YOSO model that preserves  resilience to adaptive server corruption, but allows for much more efficient protocols. In SCALES (Small Clients And Larger Ephemeral Servers) only the servers facilitating the MPC computation are ephemeral (unpredictably selected and ``speak once''). Input providers (clients) publish problem instances and collect the output, but do not otherwise participate in computation. SCALES offers attractive features, and improves over YOSO protocols in outsourcing MPC to a large pool of servers under adaptive corruption.

We build SCALES from rerandomizable garbling schemes, which is a contribution of independent interest, with additional applications.
]]></content:encoded>
<pubDate>Sun, 12 Jun 2022 08:55:52 +0000</pubDate>
</item>
<item>
<title>Clubcards for the WebPKI: smaller certificate revocation tests in theory and practice</title>
<link>https://eprint.iacr.org/2025/610</link>
<guid>https://eprint.iacr.org/2025/610</guid>
<content:encoded><![CDATA[
<div> 关键词：CRLite、低带宽、低延迟、隐私保护、证书吊销

总结:
CRLite是一种低带宽、低延迟且能保护隐私的证书吊销数据分布机制。研究者提出了一种名为“clubcard”的新颖数据结构用于会员资格测试，该结构能够高效地编码撤销数据。文章指出，截至2024年11月，WebPKI包含超过9亿份有效证书和800万份已吊销证书。通过CRLite的新实例化，这些证书的吊销状态可以被压缩到6.7 MB的包中，相较于2017年IEEE安全与隐私研讨会上提出的原始CRLite减少了54%，并且比该工作声称的下限还小了21%。使用俱乐部卡序列可编码动态数据集，如WebPKI吊销集合，平均而言，对于每6小时更新一次的WebPKI，其俱乐部卡编码可压缩至26.8 kB，这使得CRLite真正具备实用性。研究人员已经扩展了Mozilla的CRLite基础设施以生成俱乐部卡，并在Firefox中添加了对这一系统的客户端支持。目前，该实现已成为Firefox Nightly版默认的吊销检查机制，同时提出了进一步降低CRLite带宽需求的策略。 <div>
CRLite is a low-bandwidth, low-latency, privacy-preserving mechanism for distributing certificate revocation data. A CRLite aggregator periodically encodes revocation data into a compact static hash set, or membership test, which can can be downloaded by clients and queried privately. We present a novel data-structure for membership tests, which we call a clubcard, and we evaluate the encoding efficiency of clubcards using data from Mozilla's CRLite infrastructure.

As of November 2024, the WebPKI contains over 900 million valid certificates and over 8 million revoked certificates. We describe an instantiation of CRLite that encodes the revocation status of these certificates in a 6.7 MB package. This is $54\%$ smaller than the original instantiation of CRLite presented at the 2017 IEEE Symposium on Security and Privacy, and it is $21\%$ smaller than the lower bound claimed in that work.

A sequence of clubcards can encode a dynamic dataset like the WebPKI revocation set. Using data from late 2024 again, we find that clubcards encoding 6 hour delta updates to the WebPKI can be compressed to 26.8 kB on average---a size that makes CRLite truly practical.

We have extended Mozilla's CRLite infrastructure so that it can generate clubcards, and we have added client-side support for this system to Firefox. We report on some performance aspects of our implementation, which is currently the default revocation checking mechanism in Firefox Nightly, and we propose strategies for further reducing the bandwidth requirements of CRLite.
]]></content:encoded>
<pubDate>Thu, 03 Apr 2025 17:24:30 +0000</pubDate>
</item>
<item>
<title>SoK: Self-Generated Nudes over Private Chats: How Can Technology Contribute to a Safer Sexting?</title>
<link>https://eprint.iacr.org/2025/597</link>
<guid>https://eprint.iacr.org/2025/597</guid>
<content:encoded><![CDATA[
<div> 关键词: 移动应用、裸照分享、安全性、隐私保护、技术提案

总结:
本文针对越来越多的人利用移动应用程序进行交友和轻度接触，进而引发的自拍裸照分享现象，以及由此产生的安全与隐私问题进行了研究。通过系统性文献回顾和对52款约会、消息传递及社交网络应用的调查，作者定义了艳照分享威胁模型，衍生出了相关提案/功能的分类体系，并讨论了其不足之处，同时梳理了隐私相关的概念。研究表明，学术提案和应用功能生态系统非常多样，实现更安全的艳照分享远不止于裸体检测。没有一种技术能全面解决所有威胁，但每种技术都能从不同角度为更安全的艳照分享做出贡献。未来的研究和开发可以从这些发现中汲取启示。 <div>
More and more people take advantage of mobile apps to strike up relationships and casual contacts. This sometimes results in the sharing of self-generated nudes. While this opens a way for sexual exploration, it also raises concerns. In this paper, we review existing technology-assisted permissive proposals/features that provide security or privacy benefits when sharing nudes online. To do so, we performed a systematic literature review combing through 10,026 search results and cross-references, and we identified real-world solutions by surveying OS features and 52 dating, messaging and social network apps. We systematized knowledge by defining a sexting threat model, deriving a taxonomy of the proposals/features, discussing some of their shortcomings, organizing privacy-related concepts, and providing take-aways with some directions for future research and development. Our study found a very diverse ecosystem of academic proposals and app features, showing that safer sexting goes far beyond nude detection. None of the techniques represents the ultimate solution for all threats, but each contributes to safer sexting in a different way.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 10:31:56 +0000</pubDate>
</item>
<item>
<title>Mobile Byzantine Agreement in a Trusted World</title>
<link>https://eprint.iacr.org/2025/603</link>
<guid>https://eprint.iacr.org/2025/603</guid>
<content:encoded><![CDATA[
<div> 关键词：Byzantine Agreement、移动拜占庭节点、同步系统、Garay模型、Bonnet模型、Buhrman模型、可信计数器抽象、处理器数量、算法

<br /><br />总结：
本文关注的是在同步系统中，移动拜占庭节点能够从一个进程转移到另一个进程并破坏其宿主环境下的拜占庭一致性问题。研究了三种代表性模型：Garay模型、Bonnet模型和Buhrman模型。对于每个模型，文章指出了容忍$t$个移动拜占庭节点所需的最小处理器数量：Garay模型为$4t+1$，Bonnet模型为$5t+1$，Buhrman模型为$3t+1$。为了提高对移动拜占庭节点的容错能力，文章提出了一种集成可信计数器抽象的新模型，这可以防止节点产生矛盾行为。在新模型下，证明了分别需要$3t+1$、$4t+1$以及$2t+1$个处理器来容忍$t$个移动拜占庭节点。此外，针对Garay模型、Bonnet模型和Buhrman模型，本文还提出了新的移动拜占庭一致性算法，这些算法与上述新的下界相匹配。 <div>
In this paper, we address the Byzantine Agreement problem in synchronous systems where Byzantine agents can move from process to process, corrupting their host. 
We focus on three representative models: \emph{Garay's}, \emph{Bonnet's} and \emph{Buhrman's} models.
In \emph{Garay's model} when a process has been left by the Byzantine, it is in the \emph{cured} state and it is aware of its condition and thus can remain silent for a round to prevent the dissemination of wrong information.
In \emph{Bonnet's model} a cured process may send messages (based on a state corrupted by the malicious agent), however it will behave correctly in the way it sends those messages: i.e., send messages according to the algorithm.
In \emph{Buhrman's model} Byzantine agents move together with the message.  
It has been shown that in order to solve Byzantine Agreement in the \emph{Garay's model} at least $4t+1$ processors are needed, for \emph{Bonnet's model} at least $5t+1$ processors are needed, while for \emph{Buhrman's model} at least $3t+1$ processors are needed.
In this paper we target to increase the tolerance to mobile Byzantines by integrating a trusted counter abstraction to the above models. This abstraction prevents nodes to equivocate. In the new models we prove that at least $3t+1$, respectively $4t+1$, and $2t+1$ processors are needed  to tolerate $t$ mobile Byzantine agents. Furthermore,  we propose novel Mobile Byzantine Agreement algorithms that  match these new lower bounds for \emph{Garay's}, \emph{Bonnet's} and \emph{Buhrman's} models.
]]></content:encoded>
<pubDate>Wed, 02 Apr 2025 20:38:55 +0000</pubDate>
</item>
<item>
<title>DSM: Decentralized State Machine - The Missing Trust Layer of the Internet</title>
<link>https://eprint.iacr.org/2025/592</link>
<guid>https://eprint.iacr.org/2025/592</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized State Machine (DSM), 中心化信任系统, 量子-resistant, 确定性状态转换, 持续、无气体经济模型

总结:
文章介绍了Decentralized State Machine (DSM)，这是一种旨在解决当前互联网中依赖于企业、政府和中介机构的中心化信任系统所带来问题的新技术。DSM通过数学强制的信任层消除了对共识机制、第三方验证者和集中式基础设施的需求，提供了量子-resistant和确定性状态转换，确保了数字身份和价值交换的即时最终性和防篡改的前向仅进状态进展。与传统区块链执行模型不同，DSM采用预承诺的状态转移实现安全、多路径工作流，无需图灵完备或全球共识。其协议架构基于直链哈希和稀疏索引的稀疏默克尔树（SMTs），确保高效验证、可扩展性和隐私保护。DSM还引入了一种可持续的、无gas经济模型，基于密码学订阅承诺。总的来说，DSM提供了一种实用且可扩展的选择，以去中心化和可信的方式实现在线和离线环境中的节点间交互，从而打破了对传统互联网信任模型的依赖。 <div>
The modern internet relies heavily on centralized trust systems controlled by corporations, governments, and intermediaries to manage authentication, identity, and value transfer. These models introduce fundamental vulnerabilities, including censorship, fraud, and systemic insecurity. The Decentralized State Machine (DSM) addresses these issues by introducing a mathematically enforced trust layer that eliminates the need for consensus mechanisms, third-party validators, and centralized infrastructure. DSM enables quantum-resistant, deterministic state transitions for digital identity and value exchange—offering immediate finality, offline capability, and tamper-proof forward-only state progression.

DSM replaces traditional blockchain execution models with deterministic, pre-committed state transitions, enabling secure, multi-path workflows without requiring Turing-completeness or global consensus. The protocol architecture is based on a straight hash chain with sparse indexing and Sparse Merkle Trees (SMTs), ensuring efficient verification, scalability, and privacy. A bilateral isolation model supports asynchronous, offline operation with built-in consistency guarantees. DSM introduces a sustainable, gas-free economic model based on cryptographic subscription commitments.

This paper outlines the architecture, cryptographic foundations, and security guarantees of DSM, and demonstrates how it achieves verifiable, trustless interaction between peers—both online and offline. By decoupling security from consensus and enabling self-validating state transitions, DSM offers a practical and scalable alternative to conventional internet trust models.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 18:03:39 +0000</pubDate>
</item>
<item>
<title>A Place for Everyone vs Everyone in its Place: Measuring and Attacking the Ethereum Global Network</title>
<link>https://eprint.iacr.org/2025/588</link>
<guid>https://eprint.iacr.org/2025/588</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum Global Network (EGN), 多服务架构, 节点发现效率, 安全性, 攻击抵抗力

<br /><br />总结：

本文对以太坊全球网络（EGN）的设计及其宣称的优势进行了批判性分析。研究发现，EGN在节点发现过程中存在显著缺陷，其多服务架构导致超过四分之三的连接尝试未能找到提供所需服务的节点，例如有一个案例中，一个节点平均需要尝试$45,908$次才能找到一个邻居。此外，这种混合架构还削弱了EGN的安全性，网络对于DHT污染和分区攻击高度易感。只需$300$个恶意节点，攻击者就能隔离数千个节点，严重阻碍网络恢复。相比之下，如此少量的恶意节点对单一服务P2P网络的影响则微乎其微。文章提出了改进EGN节点发现效率以及增强其抵御攻击能力的解决方案。 <div>
The Ethereum Global Network (EGN) is the peer-to-peer (P2P) network underlying Ethereum and thousands of subsequent blockchain services. Deviating from traditional single-service P2P networks, EGN's multi-service architecture has gained widespread acceptance for supposedly improving node discovery efficiency and security. This paper challenges this belief by critically examining EGN's design and its purported benefits. Our analysis reveals significant shortcomings in EGN's node discovery process. EGN nodes struggle to connect with peers offering the desired service: over three-quarters of connection attempts reach nodes of other services. In an extreme case, one node spent an average of $45\,908$ connection attempts to find each neighbor. Moreover, this blended architecture compromises EGN's security. The network demonstrates high susceptibility to DHT pollution and partition attacks. Even with only $300$ malicious nodes in EGN, an attacker can isolate thousands of nodes, significantly hindering recovery. In contrast, such a small number of malicious nodes has minimal impact on every single-service P2P network. We propose solutions to improve EGN's node discovery efficiency and strengthen its resilience against attacks.
]]></content:encoded>
<pubDate>Tue, 01 Apr 2025 05:47:35 +0000</pubDate>
</item>
<item>
<title>Reusable Dynamic Multi-Party Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/581</link>
<guid>https://eprint.iacr.org/2025/581</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密、多密钥同态加密、多 party 同态加密、可重用动态多 party 同态加密、通信复杂度

总结:
本文探讨了在多用户环境下利用同态加密技术保护隐私的方法。针对多密钥同态加密(MKHE)存在的空间和计算开销随着用户数 n 增大而线性增长的问题，以及多 party 同态加密(MPHE)中密文不可复用、动态加入受限的缺点，文章提出了一种新的“可重用动态多 party 同态加密”(Reusable Dynamic MPHE)方案。该方案允许秘密密钥持有者在计算前进行有限轮次的通信，从而将密文大小和评估复杂度从 $\mathcal O(n)$ 降低到 $\mathcal O(1)$，达到单密钥同态加密的水平。此外，新方案还具备与 MKHE 相当的功能效率，同时具有低通信复杂度和独立于用户数量的评估/空间复杂度优势。通过理论分析和实验证明了其在实际场景中的适用性。 <div>
Homomorphic Encryption (HE) is a promising primitive for evaluating arbitrary circuits while keeping the user's privacy. We investigate how to use HE in the multi-party setting where data is encrypted with several distinct keys. One may use the Multi-Key Homomorphic Encryption (MKHE) in this setting, but it has space/computation overhead of $\mathcal O(n)$ for the number of users $n$, which makes it impractical when $n$ grows large. On the contrary, Multi-Party Homomorphic Encryption (MPHE) is the other Homomorphic Encryption primitive in the multi-party setting, where the space/computation overhead is $\mathcal O(1)$; however, is limited in terms of ciphertext reusability and dynamicity, that ciphertexts are encrypted just for a group of parties and cannot be reused for other purposes, and that additional parties cannot join the computation dynamically. 

Contrary to MKHE, where the secret key owners engage only in the decryption phase, we consider a more relaxed situation where the secret key owners can communicate before the computation. In that case, we can reduce the size of a ciphertext and the evaluation complexity from $\mathcal O(n)$ to $\mathcal O(1)$ as in a single-key HE setting. We call this primitive as {\em Reusable Dynamic Multi-Party Homomorphic Encryption}, which is more suitable in real-world scenarios.

We show that 1) the procedures before the computation can be done in a very few rounds of communications, 2) the evaluation/space complexities are independent of the number of users, and 3) the functionalities are as efficient as MKHE, with asymptotic analysis and with implementation.
]]></content:encoded>
<pubDate>Mon, 31 Mar 2025 05:53:40 +0000</pubDate>
</item>
<item>
<title>REGKYC: Supporting Privacy and Compliance Enforcement for KYC in Blockchains</title>
<link>https://eprint.iacr.org/2025/579</link>
<guid>https://eprint.iacr.org/2025/579</guid>
<content:encoded><![CDATA[
<div> 关键词: Know Your Customer (KYC), Anti-Money Laundering (AML), REGKYC, Attribute-Based Access Control (ABAC), Blockchain<br /><br />总结:<br />
REGKYC 是一种针对区块链环境提出的隐私保护型属性基访问控制（ABAC）框架，旨在平衡用户隐私与外部强制的KYC和反洗钱（AML）要求。该框架利用结构化的ABAC模型支持灵活的KYC属性验证和合规政策执行，对多方利益相关者具有益处。首先，它使得合法用户能够在满足合规要求的同时，保护其在链上的活动隐私；其次，赋予加密资产服务提供商（CASPs）根据业务需求定制合规策略的能力，以适应不断演变的监管规定；最后，通过授权匿名性的解除，提升了监管问责能力，可有效识别并追踪恶意行为者。本文期望这一工作能激发未来关于如何在区块链系统中协调用户隐私与监管合规的研究。 <div>
Know Your Customer (KYC) is a core component of the Anti-Money Laundering (AML) framework, designed to prevent illicit activities within financial systems. However, enforcing KYC and AML on blockchains remains challenging due to difficulties in establishing accountability and preserving user privacy. This study proposes REGKYC, a privacy-preserving Attribute-Based Access Control (ABAC) framework that balances user privacy with externally mandated KYC and AML requirements. REGKYC leverages a structured ABAC model to support the flexible verification of KYC attributes and the enforcement of compliance policies, providing benefits to multiple stakeholders. First, it enables legitimate users to meet compliance requirements while preserving the privacy of their on-chain activities. Second, it empowers Crypto-asset Service Providers (CASPs) to tailor compliance policies to operational needs, ensuring adaptability to evolving regulations. Finally, it enhances regulatory accountability by enabling authorized deanonymization of malicious actors. We hope this work inspires future research to harmonize user privacy and regulatory compliance in blockchain systems.
]]></content:encoded>
<pubDate>Sun, 30 Mar 2025 23:33:19 +0000</pubDate>
</item>
<item>
<title>Buffalo: A Practical Secure Aggregation Protocol for Asynchronous Federated Learning</title>
<link>https://eprint.iacr.org/2025/574</link>
<guid>https://eprint.iacr.org/2025/574</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习（FL）、同步FL、Buffered异步FL（BAsyncFL）、安全聚合（SA）、Buffalo

总结:
联邦学习中的同步训练方法因受慢速客户端影响导致效率降低，为此引入了Buffered异步FL（BAsyncFL）以消除同步瓶颈。然而，现有的安全聚合技术不适用于异步环境。针对这一问题，本文提出了首个适用于BAsyncFL的实用安全聚合协议——Buffalo。Buffalo利用格基加密解决大型ML模型的可扩展性挑战，并引入了助手角色协助服务器进行安全的客户端更新聚合。同时，为了防范恶意篡改服务器，Buffalo允许客户端验证其本地更新是否已正确整合到全局模型中。通过对理论分析和基准数据集上的实际实验进行全面评估，结果显示Buffalo是在BAsyncFL环境中高效且可伸缩的隐私保护解决方案。 <div>
Federated Learning (FL) has become a crucial framework for collaboratively training Machine Learning (ML) models while ensuring data privacy. Traditional synchronous FL approaches, however, suffer from delays caused by slower clients (called stragglers), which hinder the overall training process.

Specifically, in a synchronous setting, model aggregation happens once all the intended clients have submitted their local updates to the server. To address these inefficiencies, Buffered Asynchronous FL (BAsyncFL) was introduced, allowing clients to update the global model as soon as they complete local training. In such a setting, the new global model is obtained once the buffer is full, thus removing synchronization bottlenecks. Despite these advantages, existing Secure Aggregation (SA) techniques—designed to protect client updates from inference attacks—rely on synchronized rounds, making them unsuitable for asynchronous settings.

In this paper, we present Buffalo, the first practical SA protocol tailored for BAsyncFL. Buffalo leverages lattice-based encryption to handle scalability challenges in large ML models and introduces a new role, the assistant, to support the server in securely aggregating client updates. To protect against an actively corrupted server, we enable clients to verify that their local updates have been correctly integrated into the global model. Our comprehensive evaluation—incorporating theoretical analysis and real-world experiments on benchmark datasets—demonstrates that Buffalo is an efficient and scalable privacy-preserving solution in BAsyncFL environments.
]]></content:encoded>
<pubDate>Sat, 29 Mar 2025 15:49:51 +0000</pubDate>
</item>
<item>
<title>Zinnia: An Expressive and Efficient Tensor-Oriented Zero-Knowledge Programming Framework</title>
<link>https://eprint.iacr.org/2025/572</link>
<guid>https://eprint.iacr.org/2025/572</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、Zinnia、编程框架、机器学习、数据科学

总结:
Zinnia 是一款针对零知识证明（ZKP）设计的高实用性、高表达性和高效能的编程框架，特别适用于张量计算。该框架旨在解决ZKP在机器学习和数据科学中应用困难的问题。Zinnia 提供了一种高级编程语言，使得开发者能够轻松编写ZKP程序，并通过创新的符号执行启发式方法从这些程序中生成算术电路。同时，它支持张量运算并具备丰富的编程结构、优化手段以及强大的静态类型系统，用于表达和优化复杂的逻辑。通过对涵盖25个真实世界编程任务及用户研究的评估，结果显示Zinnia 在实用性和表达性方面优于现有的解决方案（如DSL和zkVM，例如Halo2、SP1和RISC0），并且在开发时间上缩短了约2到3倍，代码长度减少了75%，电路尺寸缩小了19.3%，相较于zkVMs，证明时间最高提升了245倍，从而为各种领域中的实际ZKP应用铺平了道路。 <div>
Zero-knowledge proofs (ZKPs) are cryptographic protocols that enable a prover to convince a verifier of a statement's truth without revealing any details beyond its validity. Typically, the statement is encoded as an arithmetic circuit, and allows the prover to demonstrate that the circuit evaluates to true without revealing its inputs. Despite their potential to enhance privacy and security, ZKPs are difficult to write and optimize, limiting their adoption in machine learning and data science. To address these challenges, we introduce Zinnia, a zero-knowledge programming framework with high utility, expressiveness and efficiency for tensor-oriented computation. Zinnia provides a high-level programming language that enables developers to easily write ZKP programs, and it employs a novel symbolic execution-inspired approach to extracting semantics from these programs to generate arithmetic circuits. Zinnia supports tensor-oriented computations and provides a rich set of programming constructs, optimizations, and a powerful static type system for expressing and optimizing complex logic. We evaluate Zinnia across 25 real-world programming tasks and a user study, comparing it to existing solutions, including DSLs and zkVMs (Halo2, SP1, and RISC0). Our results demonstrate that Zinnia outperforms these baselines in utility, expressiveness, and efficiency, with a statistically significant reduction in development time, $2-3\times$ shorter code length, 19.3% smaller circuit size, and up to $245\times$ faster proving time compared to zkVMs, paving the way for practical ZKP applications in various domains.
]]></content:encoded>
<pubDate>Sat, 29 Mar 2025 12:06:05 +0000</pubDate>
</item>
<item>
<title>Solving Data Availability Limitations in Client-Side Validation with UTxO Binding</title>
<link>https://eprint.iacr.org/2025/569</link>
<guid>https://eprint.iacr.org/2025/569</guid>
<content:encoded><![CDATA[
<div> 关键词: 发行代币、比特币、客户端验证（CSV）、UTxO绑定、辅助区块链

总结:
文章提出了一个针对在比特币上发行代币问题的新框架——UTxO绑定。鉴于比特币原生功能有限以及存储挑战，当前采用的客户端验证（CSV）方法虽然实现了部分扩展但存在数据丢失和恶意数据扣留的风险。UTxO绑定方案创新性地将比特币的UTxO与辅助区块链上的UTxO安全绑定，利用后者提供数据存储和可编程性的同时，确保防止双重花费。文章通过形式化证明了该方案的安全性，并以Nervos CKB作为辅助区块链实现了这一设计。 <div>
Issuing tokens on Bitcoin remains a highly sought-after goal, driven by its market dominance and robust security. However, Bitcoin's limited on-chain storage and functionality pose significant challenges. Among the various approaches to token issuance on Bitcoin, client-side validation (CSV) has emerged as a prominent solution. CSV delegates data storage and functionalities beyond Bitcoin’s native capabilities to off-chain clients, while leveraging the blockchain to validate tokens and prevent double-spending. Nevertheless, these protocols require participants to maintain token ownership and transactional data, rendering them vulnerable to data loss and malicious data withholding. In this paper, we propose UTxO binding, a novel framework that achieves both robust data availability and enhanced functionality compared to existing CSV designs. This approach securely binds a Bitcoin UTxO, which prevents double-spending, to a UTxO on an auxiliary blockchain, providing data storage and programmability. We formally prove its security and implement our design using Nervos CKB as the auxiliary blockchain.
]]></content:encoded>
<pubDate>Fri, 28 Mar 2025 13:05:29 +0000</pubDate>
</item>
<item>
<title>An Efficient SNARK for Field-Programmable and RAM Circuits</title>
<link>https://eprint.iacr.org/2024/507</link>
<guid>https://eprint.iacr.org/2024/507</guid>
<content:encoded><![CDATA[
<div> 关键词: SNARK、效率、隐私、预处理、可验证计算

总结:
本文提出了一个新的具有常量证明大小的SNARK方案，旨在解决频繁变换计算目标情况下，SNARK预处理数据重生产带来的挑战。该方案结合了Groth16协议的高效性（但不具备新问题的普适性）和PlonK协议的普适性（但预处理数据维度较大）。新SNARK在保持高效性和普适性的同时，显著降低了预处理数据的维度。此外，它还能无缝应用于可验证机器计算，所需的证明尺寸比其他相关工作小约四到十倍。 <div>
The advancement of succinct non-interactive argument of knowledge (SNARK) with constant proof size has significantly enhanced the efficiency and privacy of verifiable computation. Verifiable computation finds applications in distributed computing networks, particularly in scenarios where nodes cannot be generally trusted, such as blockchains. However, fully harnessing the efficiency of SNARK becomes challenging when the computing targets in the network change frequently, as the SNARK verification can involve some untrusted preprocess of the target, which is expected to be reproduced by other nodes. This problem can be addressed with two approaches: One relieves the reproduction overhead by reducing the dimensionality of preprocessing data; The other utilizes verifiable machine computation, which eliminates the dependency on preprocess at the cost of increased overhead to SNARK proving and verification. In this paper, we propose a new SNARK with constant proof size applicable to both approaches. The proposed SNARK combines the efficiency of Groth16 protocol, albeit lacking universality for new problems, and the universality of PlonK protocol, albeit with significantly larger preprocessing data dimensions. Consequently, we demonstrate that our proposed SNARK maintains the efficiency and the universality while significantly reducing the dimensionality of preprocessing data. Furthermore, our SNARK can be seamlessly applied to the verifiable machine computation, requiring a proof size smaller about four to ten times than other related works.
]]></content:encoded>
<pubDate>Sat, 30 Mar 2024 08:49:24 +0000</pubDate>
</item>
<item>
<title>ThreatLens: LLM-guided Threat Modeling and Test Plan Generation for Hardware Security Verification</title>
<link>https://eprint.iacr.org/2025/561</link>
<guid>https://eprint.iacr.org/2025/561</guid>
<content:encoded><![CDATA[
<div> 关键词: 威胁建模，测试计划生成，硬件安全验证，ThreatLens，LLM

总结:
<br />
针对当前硬件安全验证过程中依赖人工威胁建模和测试计划生成的问题，该文提出了一个基于LLM驱动的多Agent框架——ThreatLens。ThreatLens利用检索增强生成（RAG）技术提取相关安全知识，运用LLM进行威胁评估，并结合用户交互反馈以确保生成实际可行的测试计划。通过自动化这些流程，该框架降低了手动验证工作量，提高了覆盖面，并确保了安全验证方法的结构化和适应性。在NEORV32 SoC上的评估结果显示，ThreatLens能够通过结构化的测试计划实现硬件安全验证的自动化，并在现实场景中验证了其有效性。 <div>
Current hardware security verification processes predominantly rely on manual threat modeling and test plan generation, which are labor-intensive, error-prone, and struggle to scale with increasing design complexity and evolving attack methodologies. To address these challenges, we propose ThreatLens, an LLM-driven multi-agent framework that automates security threat modeling and test plan generation for hardware security verification. ThreatLens integrates retrieval-augmented generation (RAG) to extract relevant security knowledge, LLM-powered reasoning for threat assessment, and interactive user feedback to ensure the generation of practical test plans. By automating these processes, the framework reduces the manual verification effort, enhances coverage, and ensures a structured, adaptable approach to security verification. We evaluated our framework on the NEORV32 SoC, demonstrating its capability to automate security verification through structured test plans and validating its effectiveness in real-world scenarios.
]]></content:encoded>
<pubDate>Wed, 26 Mar 2025 21:25:06 +0000</pubDate>
</item>
<item>
<title>Public Key Accumulators for Revocation of Non-Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/549</link>
<guid>https://eprint.iacr.org/2025/549</guid>
<content:encoded><![CDATA[
<div> 关键词：数字身份钱包、加密积累器、撤销机制、零知识证明、计算与通信成本

总结:
本文关注于分析加密积累器作为数字身份钱包凭证撤销方案的应用。文中介绍了几种主流的公钥积累器，并探讨了如何结合零知识证明实现非匿名凭证的撤销。同时，通过对计算和通信成本进行理论与实验评估，结果表明这些方法在证书撤销场景中的性能可与现有方案相媲美。<br /><br /> <div>
Digital identity wallets allow citizens to prove who they are and manage digital documents, called credentials, such as mobile driving licenses or passports. As with physical documents, secure and privacy-preserving management of the credential lifecycle is crucial: a credential can change its status from issued to valid, revoked or expired. In this paper, we focus on the analysis of cryptographic accumulators as a revocation scheme for digital identity wallet credentials. We describe the most well-established public key accumulators, and how zero-knowledge proofs can be used with accumulators for revocation of non-anonymous credentials. In addition, we assess the computational and communication costs analytically and experimentally. Our results show that they are comparable with existing schemes used in the context of certificate revocation.
]]></content:encoded>
<pubDate>Tue, 25 Mar 2025 11:20:04 +0000</pubDate>
</item>
<item>
<title>Aegis: Scalable Privacy-preserving CBDC Framework with Dynamic   Proof of Liabilities</title>
<link>https://eprint.iacr.org/2025/539</link>
<guid>https://eprint.iacr.org/2025/539</guid>
<content:encoded><![CDATA[
<div> 关键词: Central Bank Digital Currencies (CBDC), hybrid model, zk-SNARKs, transaction batching, dynamic Proof of Liabilities

总结:
本文探讨了中央银行数字货币（CBDC）的设计挑战，重点关注隐私保护和可扩展性问题。针对公共区块链透明度带来的隐私顾虑，文章提出了一个基于zk-SNARKs的新颖智能合约框架——Aegis。该框架采用交易批处理技术以提升系统可扩展性，并定义了一种新型动态Proof of Liabilities机制，能应对用户负债实时变动的问题。文章对系统的安全性进行了形式化定义与严格证明，并通过实例化框架进行性能评估，结果显示：对于包含512笔交易的完整流程，包括生成证明的时间大约为2.8秒，每位用户的gas消耗量为74,726。 <div>
Blockchain advancements, currency digitalization, and declining cash usage have fueled global interest in Central Bank Digital Currencies (CBDCs). The BIS states that the hybrid model, where central banks authorize intermediaries to manage distribution, is more suitable than the direct model. However, designing a CBDC for practical implementation requires careful consideration. First, the public blockchain raises privacy concerns due to transparency. While zk-SNARKs can be a solution, they can introduce significant proof generation overhead for large-scale transactions. Second, intermediaries that provide user-facing services on behalf of the central bank commonly performs Proof of Liabilities on customers' static liabilities. However, in real-world scenarios where user liabilities can arbitrarily increase or decrease, the static nature poses such as window attacks. 

In this paper, we propose a new smart contract-based privacy-preserving CBDC framework based on zk-SNARKs, called $\textbf{Aegis}$. our framework introduces a transaction batching technique to enhance scalability and  defines a new dynamic PoL which is near-real time. We formally define the security models for our system and provide rigorous security proofs to demonstrate its robustness. To evaluate the system’s performance, we instantiate our proposed framework and measure its efficiency. The result indicates that, the end-to-end process, including proof generation for 512 transactions, takes approximately 2.8 seconds, with a gas consumption of 74,726 per user.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 04:37:41 +0000</pubDate>
</item>
<item>
<title>Efficient Proofs of Possession for Legacy Signatures</title>
<link>https://eprint.iacr.org/2025/538</link>
<guid>https://eprint.iacr.org/2025/538</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字签名、证明占有、zkSNARK、RSA、ECDSA、Ed25519、效率提升、Dorian、R1CS、椭圆曲线

总结:
本文研究了如何将证明占有的概念应用于广泛部署的传统数字签名方案（如RSA、ECDSA和Ed25519）中，以提高安全性、隐私性和匿名性。为实现这一目标，文章提出了新的策略：将签名验证算法编码为R1CS，并使用zkSNARK来证明解决方案的知识。为了提高效率，研究者设计并分析了一种支持随机计算的新zkSNARK——Dorian，以及用于编码哈希、椭圆曲线操作和模算术的新技术。他们还提出一种新方法，允许在R1CS外部执行ECDSA和Ed25519验证中最耗时的部分，并生成了一种新型椭圆曲线，可以非常高效地表示Ed25519曲线操作。这些技术使R1CS大小缩小高达200倍，证明生成时间减少3至22倍。例如，现在可以在三秒内生成一个针对两千字节TLS证书大小的消息的RSA签名的240字节的占有证明。 <div>
Digital signatures underpin identity, authenticity, and trust in modern computer systems. Cryptography research has shown that it is possible to prove possession of a valid message and signature for some public key, without revealing the message or signature. These proofs of possession work only for specially-designed signature schemes. Though these proofs of possession have many useful applications to improving security, privacy, and anonymity, they are not currently usable for widely deployed, legacy signature schemes such as RSA, ECDSA, and Ed25519. Unlocking practical proofs of possession for these legacy signature schemes requires closing a huge efficiency gap.

This work brings proofs of possession for legacy signature schemes very close to practicality. Our design strategy is to encode the signature's verification algorithm as a rank-one constraint system (R1CS), then use a zkSNARK to prove knowledge of a solution. To do this efficiently we (1) design and analyze a new zkSNARK called Dorian that supports randomized computations, (2) introduce several new techniques for encoding hashes, elliptic curve operations, and modular arithmetic,  (3) give a new approach that allows performing the most expensive parts of ECDSA and Ed25519 verifications outside R1CS, and (4) generate a novel elliptic curve that allows expressing Ed25519 curve operations very efficiently. Our techniques reduce R1CS sizes by up to 200$\times$ and prover times by 3-22$\times$. 

We can generate a 240-byte proof of possession of an RSA signature over a message the size of a typical TLS certificate (two kilobytes) in only three seconds.
]]></content:encoded>
<pubDate>Mon, 24 Mar 2025 01:23:44 +0000</pubDate>
</item>
<item>
<title>Large Language Models for Blockchain Security: A Systematic Literature Review</title>
<link>https://eprint.iacr.org/2024/477</link>
<guid>https://eprint.iacr.org/2024/477</guid>
<content:encoded><![CDATA[
<div> 关键词: 大型语言模型 (LLMs)、区块链安全 (BS)、文献回顾、智能合约审计、交易异常检测

总结:
本文针对大型语言模型在区块链安全领域的应用进行了一次全面的文献回顾，旨在深入理解和分析LLMs如何增强区块链系统的安全性。研究探讨了LLMs在智能合约审计、交易异常检测、漏洞修复、智能合约程序分析以及作为加密货币社区参与者等方面的应用。同时，文章也评估了利用LLMs提升区块链安全性所面临的挑战与限制，包括可扩展性、隐私问题和伦理考量等。通过这篇详尽的综述，为研究人员、实践者及政策制定者提供了关于LLM应用于区块链安全的机会与潜在风险的宝贵见解。 <div>
Large Language Models (LLMs) have emerged as powerful tools across various domains within cyber security. Notably,
recent studies are increasingly exploring LLMs applied to the context of blockchain security (BS).
However, there remains a gap in a comprehensive understanding regarding the full scope of applications, impacts, and potential constraints of LLMs on blockchain security.
To fill this gap, we undertake a literature review focusing on the studies that apply LLMs in blockchain security (LLM4BS).

Our study aims to comprehensively analyze and understand existing research, and elucidate how LLMs contribute to enhancing the security of blockchain systems.
Through a thorough examination of existing literature, we delve into the integration of LLMs into various aspects of blockchain security. 
We explore the mechanisms through which LLMs can bolster blockchain security, including their applications in smart contract auditing, transaction anomaly detection, vulnerability repair, program analysis of smart contracts, and serving as participants in the cryptocurrency community.
Furthermore, we assess the challenges and limitations associated with leveraging LLMs for enhancing blockchain security, considering factors such as scalability, privacy concerns, and ethical concerns. 
Our thorough review sheds light on the opportunities and potential risks of tasks on LLM4BS, providing valuable insights for researchers, practitioners, and policymakers alike.
]]></content:encoded>
<pubDate>Thu, 21 Mar 2024 09:22:49 +0000</pubDate>
</item>
<item>
<title>Force: Highly Efficient Four-Party Privacy-Preserving Machine Learning on GPU</title>
<link>https://eprint.iacr.org/2023/493</link>
<guid>https://eprint.iacr.org/2023/493</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算、效率提升、三党计算、四党计算、隐私保护机器学习<br /><br />总结:
本文提出了一种名为Force的高效四党计算(4PC)系统，用于实现隐私保护机器学习(PPML)。研究发现，通过引入新的共享类型X-share以及在半诚实多数设置下的MPC协议，Force能够使每个参与方享有最少的本地计算量、最小的显存消耗和最低的数据交换。相较于现有的最优GPU基半诚实安全系统（如Piranha、SecureML、Falcon、FantasticFour、CryptGPU和CrypTen），实验结果显示，Force能够在保持安全性的同时，将PPML性能提高2到38倍，从而证实了资源线性增长可以带来超过线性的性能提升。 <div>
Tremendous efforts have been made to improve the efficiency of secure Multi-Party Computation (MPC), which allows n ≥ 2 parties to jointly evaluate a target function without leaking their own private inputs. It has been confirmed by previous research that Three-Party Computation (3PC) and outsourcing computations to GPUs can lead to huge performance improvement of MPC in computationally intensive tasks such as Privacy-Preserving Machine Learning (PPML). A natural question to ask is whether super-linear performance gain is possible for a linear increase in resources. In this paper, we give an affirmative answer to this question. We propose Force, an extremely efficient Four-Party Computation (4PC) system for PPML. To the best of our knowledge, each party in Force enjoys the least number of local computations, smallest graphic memory consumption and lowest data exchanges between parties. This is achieved by introducing a new sharing type X-share along with MPC protocols in privacy-preserving training and inference that are semi-honest secure in the honest-majority setting. By comparing the results with state-of-the-art research, we showcase that Force is sound and extremely efficient, as it can improve the PPML performance by a factor of 2 to 38 compared with other latest GPU-based semi-honest secure systems, such as Piranha (including SecureML, Falcon, FantasticFour), CryptGPU and CrypTen.
]]></content:encoded>
<pubDate>Tue, 04 Apr 2023 19:37:15 +0000</pubDate>
</item>
<item>
<title>VeRange: Verification-efficient Zero-knowledge Range Arguments with Transparent Setup for Blockchain Applications and More</title>
<link>https://eprint.iacr.org/2025/528</link>
<guid>https://eprint.iacr.org/2025/528</guid>
<content:encoded><![CDATA[
<div> 关键词: Zero-knowledge range arguments, 透明设置, 区块链, 计算开销, VeRange

总结:
本文介绍了VeRange，这是一种新的零知识范围论证方案，应用于离散对数环境中。VeRange优化了验证效率，仅需$c\sqrt{N/\log N}$次群指数运算进行验证，其中$N$为表示范围的位数，$c$是一个小常数，使其在区块链部署中具有高度的实用性和较低的Gas成本。此外，VeRange还具备聚合性，允许证明者在一个论证中同时证明$T$个范围论证，只需$O(\sqrt{TN/\log(TN)})+T$次群指数运算进行验证。论文将VeRange实现在以太坊上并测量了其实际Gas成本，结果显示VeRange在实践中拥有基于离散对数范围论证中的最快验证运行时间和最低Gas成本。<br /><br /> <div>
Zero-knowledge range arguments are a fundamental cryptographic primitive that allows a prover to convince a verifier of the knowledge of a secret value lying within a predefined range. They have been utilized in diverse applications, such as confidential transactions, proofs of solvency and anonymous credentials. Range arguments with a transparent setup dispense with any trusted setup to eliminate security backdoor and enhance transparency. They are increasingly deployed in diverse decentralized applications on blockchains. One of the major concerns of practical deployment of range arguments on blockchains is the incurred gas cost and high computational overhead associated with blockchain miners. Hence, it is crucial to optimize the verification efficiency in range arguments to alleviate the deployment cost on blockchains and other decentralized platforms. In this paper, we present VeRange with several new zero-knowledge range arguments in the discrete logarithm setting, requiring only $c \sqrt{N/\log N}$ group exponentiations for verification, where $N$ is the number of bits to represent a range and $c$ is a small constant, making them concretely efficient for blockchain deployment with a very low gas cost. Furthermore, VeRange is aggregable, allowing a prover to simultaneously prove $T$ range arguments in a single argument, requiring only $O(\sqrt{TN/\log (TN)}) + T$ group exponentiations for verification. We deployed {\tt VeRange} on Ethereum and measured the empirical gas cost, achieving the fastest verification runtime and the lowest gas cost among the discrete-logarithm-based range arguments in practice.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 02:03:24 +0000</pubDate>
</item>
<item>
<title>SoK: Fully-homomorphic encryption in smart contracts</title>
<link>https://eprint.iacr.org/2025/527</link>
<guid>https://eprint.iacr.org/2025/527</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、智能合约、隐私挑战、全同态加密(FHE)、隐私增强技术(PET)

<br /><br />总结:
本文探讨了区块链技术和智能合约如何通过实现去中心化和无信任价值交换而带来革命性变化，但同时也指出了其透明度和不可变性带来的显著隐私问题。特别是在智能合约为所有网络参与者公开合同细节的情况下，可能导致敏感信息泄露。为解决这一问题，文章强调了在智能合约中引入隐私保护机制的重要性。作者提出了只有装备了隐私机制的智能合约才能实现的高级经济学应用场景，并具体分析了全同态加密（FHE）作为隐私增强技术（PET）在公共区块链上的智能合约中的应用潜力，能够实现在保持自动化、去中心化和安全性的同时保护敏感信息。接着，文章对现有的FHE解决方案进行了全面梳理，并结合所考虑的应用场景进行评估，同时识别出了开放性问题，并对未来的研究方向提出建议，以进一步提升区块链智能合约中的隐私保护水平。 <div>
Blockchain technology and smart contracts have revolutionized digital transactions by enabling trustless and decentralized exchanges of value. However, the inherent transparency and immutability of blockchains pose significant privacy challenges. On-chain data, while pseudonymous, is publicly visible and permanently recorded, potentially leading to the inadvertent disclosure of sensitive information. This issue is particularly pronounced in smart contract applications, where contract details are accessible to all network participants, risking the exposure of identities and transactional details.

To address these privacy concerns, there is a pressing need for privacy-preserving mechanisms in smart contracts. To showcase this need even further, in our paper we bring forward advanced use-cases in economics which only smart contracts equipped with privacy mechanisms can realize, and show how  fully-homomorphic encryption (FHE) as a privacy enhancing technology (PET) in smart contracts, operating on a public blockchain, can make possible the implementation of these use-cases. Furthermore, we perform a comprehensive systematization of FHE-based approaches in smart contracts, examining their potential to maintain the confidentiality of sensitive information while retaining the benefits of smart contracts, such as automation, decentralization, and security. After we evaluate these existing FHE solutions in the context of the use-cases we consider, we  identify open problems, and suggest future research directions to enhance privacy in blockchain smart contracts.
]]></content:encoded>
<pubDate>Fri, 21 Mar 2025 01:27:39 +0000</pubDate>
</item>
<item>
<title>Mitigating MEV via Multiparty Delay Encryption</title>
<link>https://eprint.iacr.org/2023/1612</link>
<guid>https://eprint.iacr.org/2023/1612</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、最大可提取价值(MEV)、交易审查、多方延迟加密(MDE)、时间锁谜题

<br /><br />总结:

本文针对以太坊网络中存在的最大可提取价值(MEV)问题以及交易审查现象，提出了一个创新的 mempool 加密方案。该方案通过分离交易包含和执行过程，并在执行前保持交易加密，旨在缓解 MEV 和审查问题。文章中定义了多方延迟加密(MDE)的概念，并基于时间锁谜题构建了一个实用的MDE方案。此方法在可扩展性（交易解密方面）、效率（最小化通信和存储开销）和安全性（仅需最小的信任假设）方面表现出色。为了证明MDE方案的有效性，研究者已在本地以太坊测试网上实现了该方案，并证明了其在每个以太坊槽位只有一个诚实的见证聚合器的情况下仍能确保安全。 <div>
Ethereum is a decentralized and permissionless network offering several attractive features. However, block proposers in Ethereum can exploit the order of transactions to extract value. This phenomenon, known as $maximal$ $extractable$ $value$ (MEV), not only disrupts the optimal functioning of different protocols but also undermines the stability of the underlying consensus mechanism. Furthermore, current block production architecture allows transaction censorship that compromises credible neutrality, a fundamental principle of Ethereum’s design philosophy.
In this work, we present a novel $mempool$ $encryption$ scheme to alleviate the censorship and MEV problem by separating transaction inclusion and execution, keeping transactions encrypted before execution. We formulate the notion of $multiparty$ $delay$ $encryption$ (MDE) and construct a practical MDE scheme based on time-lock puzzles. Our method excels in scalability (in terms of transaction decryption), efficiency (minimizing communication and storage overhead), and security (with minimal trust assumptions). 
To demonstrate the effectiveness of our MDE scheme, we have implemented it on a local Ethereum testnet and prove its security under the presence of only one honest attestation aggregator per Ethereum slot.
]]></content:encoded>
<pubDate>Tue, 17 Oct 2023 22:38:35 +0000</pubDate>
</item>
<item>
<title>Revisiting attacker's knowledge in inference attacks against Searchable Symmetric Encryption</title>
<link>https://eprint.iacr.org/2023/1883</link>
<guid>https://eprint.iacr.org/2023/1883</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密搜索方案、安全漏洞、泄漏滥用攻击、数据相似性、统计工具

总结:
本文针对加密搜索方案中的安全问题以及数据相似性的模糊假设进行了研究。首先，文章提出了基于统计估计器的数学模型，用于分析攻击者知识和相似性的概念。其次，开发了统计工具来量化相似性对攻击准确性的影响。作者将这些工具应用于三个现有的攻击场景中，探究相似性是否为影响攻击准确性的唯一因素。接着，文章指出限制最大索引尺寸可以增加攻击者满足“类似数据”假设的难度，并提出一种统计方法，用于根据给定攻击和数据集估算合适的最大索引尺寸。具体到对Enron数据集的最佳已知攻击而言，通过设置最大索引尺寸为200，可保证（以高概率）攻击的准确性低于5%。 <div>
Encrypted search schemes have been proposed to address growing privacy concerns. However, several leakage-abuse attacks have highlighted some security vulnerabilities. Recent attacks assumed an attacker's knowledge containing data "similar" to the indexed data. However, this vague assumption is barely discussed in literature: how likely is it for an attacker to obtain a "similar enough" data?

Our paper provides novel statistical tools usable on any attack in this setting to analyze its sensitivity to data similarity. First, we introduce a mathematical model based on statistical estimators to analytically understand the attackers' knowledge and the notion of similarity. Second, we conceive statistical tools to model the influence of the similarity on the attack accuracy. We apply our tools on three existing attacks to answer questions such as: is similarity the only factor influencing accuracy of a given attack? Third, we show that the enforcement of a maximum index size can make the ``similar-data'' assumption harder to satisfy. In particular, we propose a statistical method to estimate an appropriate maximum size for a given attack and dataset. For the best known attack on the Enron dataset, a maximum index size of 200 guarantees (with high probability) the attack accuracy to be below 5%.
]]></content:encoded>
<pubDate>Thu, 07 Dec 2023 10:15:59 +0000</pubDate>
</item>
<item>
<title>AI Agents in Cryptoland: Practical Attacks and No Silver Bullet</title>
<link>https://eprint.iacr.org/2025/526</link>
<guid>https://eprint.iacr.org/2025/526</guid>
<content:encoded><![CDATA[
<div> 关键词: AI代理、Web3生态系统、安全风险、上下文操纵、防御措施

<br /><br />总结:
本文探讨了AI代理与区块链金融生态系统的整合所带来的安全隐患，尤其是在遭遇现实世界中的对抗性威胁时。提出了“上下文操纵”这一全面攻击向量的概念，它利用未受保护的输入通道、内存模块和外部数据源等上下文表面进行攻击。通过实证分析用于自动化的Web3操作的去中心化AI代理框架ElizaOS，展示了恶意指令如何注入到提示或历史交互记录中，导致意外的资产转移和协议违规，可能造成严重的经济损失。研究发现，基于提示的防御措施并不充分，因为恶意输入可破坏代理存储的上下文，进而引发跨交互和平台的级联漏洞。因此，文章强调了迫切需要开发既安全又具备财务责任意识的AI代理。 <div>
The integration of AI agents with Web3 ecosystems harnesses their complementary potential for autonomy and openness, yet also introduces underexplored security risks, as these agents dynamically interact with financial protocols and immutable smart contracts. This paper investigates the vulnerabilities of AI agents within blockchain-based financial ecosystems when exposed to adversarial threats in real-world scenarios. We introduce the concept of context manipulation -- a comprehensive attack vector that exploits unprotected context surfaces, including input channels, memory modules, and external data feeds. Through empirical analysis of ElizaOS, a decentralized AI agent framework for automated Web3 operations, we demonstrate how adversaries can manipulate context by injecting malicious instructions into prompts or historical interaction records, leading to unintended asset transfers and protocol violations which could be financially devastating.  Our findings indicate that prompt-based defenses are insufficient, as malicious inputs can corrupt an agent's stored context, creating cascading vulnerabilities across interactions and platforms. This research highlights the urgent need to develop AI agents that are both secure and fiduciarily responsible.
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 15:55:10 +0000</pubDate>
</item>
<item>
<title>Ring Referral: Efficient Publicly Verifiable Ad hoc Credential Scheme with Issuer and Strong User Anonymity for Decentralized Identity and More</title>
<link>https://eprint.iacr.org/2025/524</link>
<guid>https://eprint.iacr.org/2025/524</guid>
<content:encoded><![CDATA[
<div> 关键词：环签名、第三方签署、用户匿名性、透明设置、多消息验证效率

总结:<br />
本文提出了一种环引荐方案，该方案允许用户公开证明自己知道由一组临时授权发行者之一对私密消息签署的有效签名，同时不泄露签署的发行者身份。环引荐是对传统环签名称的自然扩展，支持用户从第三方签署者获取签名。此方案适用于多种应用场景，如隐藏证书的去中心化身份、增强隐私的联合认证、匿名背书和隐私保护的推荐营销。与先前的发行者隐藏凭证方案相比，环引荐方案具备更多独特特性：(1) 对临时环内的签名进行公共可验证性；(2) 在发行者和验证者合谋追踪用户的情况下提供强大的用户匿名性；(3) 采用透明设置；(4) 消息隐藏；(5) 实现了高效的多消息对数级验证效率；(6) 支持需要多个共同签署发行者的阈值方案。最后，文中实现了环引荐方案并进行了广泛的实证评估。 <div>
In this paper, we present a ring referral scheme, by which a user can publicly prove her knowledge of a valid signature for a private message that is signed by one of an ad hoc set of authorized issuers, without revealing the signing issuer. Ring referral is a natural extension to traditional ring signature by allowing a prover to obtain a signature from a third-party signer. Our scheme is useful for diverse applications, such as certificate-hiding decentralized identity, privacy-enhancing federated authentication, anonymous endorsement and privacy -preserving referral marketing. In contrast with prior issuer-hiding credential schemes, our ring referral scheme supports more distinguishing features, such as (1) public verifiability over an ad hoc ring, (2) strong user anonymity against collusion among the issuers and verifier to track a user, (3) transparent setup,  (4) message hiding, (5) efficient multi-message logarithmic verifiability, (6) threshold scheme for requiring multiple co-signing issuers. Finally, we implemented our ring referral scheme with extensive empirical evaluation
]]></content:encoded>
<pubDate>Thu, 20 Mar 2025 06:10:58 +0000</pubDate>
</item>
<item>
<title>New Techniques for Analyzing Fully Secure Protocols: A Case Study of Solitary Output Secure Computation</title>
<link>https://eprint.iacr.org/2025/522</link>
<guid>https://eprint.iacr.org/2025/522</guid>
<content:encoded><![CDATA[
<div> 关键词: 孤立输出安全计算、完全安全性、函数计算、三党计算、特殊轮协议

<br /><br />总结:
本文关注的是孤立输出安全计算的研究，这是一种允许互不信任的各方在保证特定一方获取输出的同时，计算其输入的功能性方法。该领域的研究要求满足正确性、隐私性、输入独立性和确保输出交付等全面的安全属性。Halevi等人在[TCC 2019]中对该领域进行了初步而深入的研究，但未完全描述可以实现完全安全计算的功能集合。Alon等人在[EUROCRYPT 2024]中探讨了三党场景下，其中输出接收方无输入的全部布尔功能的完全安全计算，并发现它与公平性的概念存在潜在关联。文章继续这一研究方向，着眼于所有党派均持有私有输入的三党孤立输出布尔功能集。主要贡献在于定义并分析了一类“特殊轮”协议家族，这扩展了先前提出的协议集合。通过这些技术，我们能识别哪些特殊轮协议能够安全地计算给定功能（如果存在）。值得注意的是，这项分析还可应用于存在公平性问题的两党设置。因此，作者认为，这些技术可能对其他场景的理解和应用产生积极影响，加深我们对于不同设置之间联系的认识。 <div>
Solitary output secure computation allows a set of mutually distrustful parties to compute a function of their inputs such that only a designated party obtains the output. Such computations should satisfy various security properties such as correctness, privacy, independence of inputs, and even guaranteed output delivery. We are interested in full security, which captures all of these properties. Solitary output secure computation has been the study of many papers in recent years, as it captures many real-world scenarios.

A systematic study of fully secure solitary output computation was initiated by Halevi et al. [TCC 2019]. They showed several positive and negative results, however, they did not characterize what functions can be computed with full security. Alon et al. [EUROCRYPT 2024] considered the special, yet important case, of three parties with Boolean output, where the output-receiving party has no input. They completely characterized the set of such functionalities that can be computed with full security. Interestingly, they also showed a possible connection with the seemingly unrelated notion of fairness, where either all parties obtain the output or none of them do.

We continue this line of investigation and study the set of three-party solitary output Boolean functionalities where all parties hold private inputs. Our main contribution is defining and analyzing a family of ``special-round'' protocols, which generalizes the set of previously proposed protocols. Our techniques allow us to identify which special-round protocols securely compute a given functionality (if such exists). Interestingly, our analysis can also be applied in the two-party setting (where fairness is an issue). Thus, we believe that our techniques may prove useful in additional settings and deepen our understanding of the connections between the various settings.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 21:21:35 +0000</pubDate>
</item>
<item>
<title>Secret-Sharing Schemes for General Access Structures: An Introduction</title>
<link>https://eprint.iacr.org/2025/518</link>
<guid>https://eprint.iacr.org/2025/518</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密共享方案、访问结构、阈值秘密共享方案、信息论安全性、理想秘密共享方案

总结:<br />
本文详细介绍了秘密共享方案的关键内容。首先讨论了最实用的阈值秘密共享方案，它允许大小至少为某个阈值𝑡的集合可以恢复秘密。接下来，讲述了针对一般访问结构的有效构造方法，如利用单调公式和单调span程序构建线性秘密共享方案，并给出了对于任意𝑛方访问结构具有常数𝑐<1的2𝑐𝑛份额大小的简单构造。此外，文中通过展示如何使用秘密共享方案构建安全多方计算协议以强调其重要性。然而，现有的秘密共享方案主要问题在于份额大小过大，与数量成指数关系。文章提及了已知的关于份额大小的下界以及线性秘密共享方案上的指数下界。接着研究了理想的秘密共享方案，其中每个参与者的份额大小与秘密本身相同，这是效率最高的秘密共享方案，通过matroid对具备理想方案的访问结构进行了刻画。最后讨论了计算型秘密共享方案，即仅对抗多项式时间敌手安全的方案，展示了针对单调和非单调电路的此类构造，这些构造比具有信息论安全性的最佳已知方案更为高效。 <div>
A secret-sharing scheme is a method by which a dealer distributes shares to parties such that only authorized subsets of parties can reconstruct the secret. Secret-sharing schemes are an important tool in cryptography and they are used as a building block in many secure protocols, e.g., secure multiparty computation protocols for arbitrary functionalities, Byzantine agreement, threshold cryptography, access control, attribute-based encryption, and weighted cryptography (e.g., stake-based blockchains). The collection of authorized sets that should be able to reconstruct the secret is called an access structure. The main goal in secret sharing is to minimize the share size in a scheme realizing an access structure. In most of this monograph, we will consider secret-sharing schemes with information-theoretic security, i.e., schemes in which unauthorized sets cannot deduce any information on the secret even when the set has unbounded computational power. Although research on secret-sharing schemes has been conducted for nearly 40 years, we still do not know what the optimal share size required to realize an arbitrary 𝑛-party access structure is; there is an exponential gap between the best known upper bounds and the best known lower bounds on the share size.

In this monograph, we review the most important topics on secret sharing. We start by discussing threshold secret-sharing schemes in which the authorized sets are all sets whose size is at least some threshold 𝑡; these are the most useful secret-sharing schemes. We then describe efficient constructions of secret-sharing schemes for general access structures; in particular, we describe constructions of linear secret-sharing schemes from monotone formulas and monotone span programs and provide a simple construction for arbitrary 𝑛-party access structures with share size 2𝑐𝑛 for some constant 𝑐 < 1. To demonstrate the importance of secret-sharing schemes, we show how they are used to construct secure multi-party computation protocols for arbitrary functions. We next discuss the main problem with known secret-sharing schemes – the large share size, which is exponential in the number of parties. We present the known lower bounds on the share size. These lower bounds are fairly weak, and there is a big gap between the lower and upper bounds. For linear secret-sharing schemes, which are a class of schemes based on linear algebra that contains most known schemes, exponential lower bounds on the share size are known. We then turn to study ideal secret-sharing schemes in which the share size of each party is the same as the size of the secret; these schemes are the most efficient secret-sharing schemes. We describe a characterization of the access structures that have ideal schemes via matroids. Finally, we discuss computational secret-sharing schemes, i.e., secret-sharing schemes that are secure only against polynomial-time adversaries. We show computational schemes for monotone and non-monotone circuits; these constructions are more efficient than the best known schemes with information-theoretic security.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 14:26:28 +0000</pubDate>
</item>
<item>
<title>Compressed Sigma Protocols: New Model and Aggregation Techniques</title>
<link>https://eprint.iacr.org/2025/515</link>
<guid>https://eprint.iacr.org/2025/515</guid>
<content:encoded><![CDATA[
<div> 关键词: Sigma协议、压缩模型、非线性约束、双重折叠承诺、论证知识

总结:
本文提出了一种新的压缩$\Sigma$-协议模型，该模型有效地解决了原有模型在处理复杂关系时表达力不足的问题，特别关注了涉及非线性约束的关系。新模型的核心在于定义了双重折叠承诺以及提出的论证知识，这既扩展了关系表示的范围，又为之前的模型中的压缩和摊销过程提供了更一般的框架，并为进一步讨论证明大小优化的一般聚合技术奠定了基础。为了验证新模型的实用性和灵活性，文中通过实例展示了几个现有的协议可以使用此模型进行实例化，并指出了在如二进制证明和$k$-out-of-$n$证明等传统上被认为是“不太紧凑”的应用中，我们的通用模型能带来增强效果。因此，这种新型模型为密码学应用中的$\Sigma$-协议提供了一个更为高效和表达能力强的替代选择，为更广泛的适用性和优化开辟了道路。<br /><br /> <div>
Sigma protocols ($\Sigma$-protocols) provide a foundational paradigm for constructing secure algorithms in privacy-preserving applications. To enhance efficiency, several extended models [BG18], [BBB+18], [AC20] incorporating various optimization techniques have been proposed as ``replacements'' for the original $\Sigma$-protocol. However, these models often lack the expressiveness needed to handle complex relations and hinder designers from applying appropriate instantiation and optimization strategies.

In this paper, we introduce a novel compressed $\Sigma$-protocol model that effectively addresses these limitations by providing concrete constructions for relations involving non-linear constraints. Our approach is sufficiently expressive to encompass a wide range of relations. Central to our model is the definition of doubly folded commitments, which, along with a proposed Argument of Knowledge, generalizes the compression and amortization processes found in previous models. Despite the ability to express more relations, this innovation also provides a foundation to discuss a general aggregation technique, optimizing the proof size of instantiated schemes. 

To demonstrate the above statements, we provide a brief review of several existing protocols that can be instantiated using our model to demonstrate the versatility of our construction. We also present use cases where our generalized model enhances applications traditionally considered ``less compact'', such as binary proofs [BCC+15] and $k$-out-of-$n$ proofs [ACF21]. In conclusion, our new model offers a more efficient and expressive alternative to the current use of $\Sigma$-protocols, paving the way for broader applicability and optimization in cryptographic applications.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 11:22:55 +0000</pubDate>
</item>
<item>
<title>Server-Aided Anonymous Credentials</title>
<link>https://eprint.iacr.org/2025/513</link>
<guid>https://eprint.iacr.org/2025/513</guid>
<content:encoded><![CDATA[
<div> 关键词：server-aided anonymous credentials (SAACs)，elliptic curves，formal security definitions，proofs，BBS#，keyed-verification ACs (KVACs)，oblivious issuance protocols，statistical anonymity，unforgeability，Gap q-SDH，computational anonymity，DDH。

总结:<br />
本文提出了服务器辅助匿名凭证（SAACs）的概念，并阐述了其在基于配对无关椭圆曲线的轻量级“公共可验证和多用途”AC实现中的重要性。文章指出，BBS#这一欧盟数字身份钱包候选方案大致符合SAAC模型，但缺乏正式的安全定义和证明。为了解决这一问题，本文提供了SAACs的严格安全定义，并展示了如何从KVACs以及特殊类型的零知识证明无意识发行协议实现SAACs。文中给出了两个构造实例：一个在Gap q-SDH假设下实现了统计匿名性和不可伪造性；另一个在DDH假设下实现了计算匿名性和不可伪造性。 <div>
This paper formalizes the notion of server-aided anonymous credentials (SAACs), a new model for anonymous credentials (ACs) where, in the process of showing a credential, the holder is helped by additional auxiliary information generated in an earlier (anonymous) interaction with the issuer. This model enables lightweight instantiations of 'publicly verifiable and multi-use' ACs from pairing-free elliptic curves, which is important for compliance with existing national standards. A recent candidate for the EU Digital Identity Wallet, BBS#, roughly adheres to the SAAC model we have developed; however, it lacks formal security definitions and proofs.

In this paper, we provide rigorous definitions of security for SAACs, and show how to realize SAACs from the weaker notion of keyed-verification ACs (KVACs) and special types of oblivious issuance protocols for zero-knowledge proofs. We instantiate this paradigm to obtain two constructions: one achieves statistical anonymity with unforgeability under the Gap $q$-SDH assumption, and the other achieves computational anonymity and unforgeability under the DDH assumption.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 08:49:06 +0000</pubDate>
</item>
<item>
<title>VeriSSO: A Privacy-Preserving Legacy-Compatible Single Sign-On Protocol Using Verifiable Credentials</title>
<link>https://eprint.iacr.org/2025/511</link>
<guid>https://eprint.iacr.org/2025/511</guid>
<content:encoded><![CDATA[
<div> 关键词：Single Sign-On (SSO), 隐私挑战, Verifiable Credentials (VC), VeriSSO, 安全性与效率

总结:
<br />
本文提出了一个名为VeriSSO的新型单点登录（SSO）协议，旨在解决传统SSO机制中的隐私问题和单点故障风险。VeriSSO利用可验证凭证（VC）技术，通过一个独立的身份验证服务器委员会来管理服务提供商（RP）和用户认证，实现了用户匿名认证与RP认证的同时进行，保持了用户unlinkability并支持RP使用现有的授权代码流（ACF）验证流程。此外，VeriSSO设计还支持合法的去匿名化，以确保在用户匿名状态下仍能追究其不当行为的责任。实验结果显示，VeriSSO具有高效性和实用性，完成身份验证过程只需约100毫秒。 <div>
Single Sign-On (SSO) is a popular authentication mechanism enabling users to access multiple web services with a single set of credentials. Despite its convenience, SSO faces outstanding privacy challenges. The Identity Provider (IdP) represents a single point of failure and can track users across different Relying Parties (RPs). Multiple colluding RPs may track users through common identity attributes. In response, anonymous credential-based SSO solutions have emerged to offer privacy-preserving authentication without revealing unnecessary user information. However, these solutions face two key challenges: supporting RP authentication without compromising user unlinkability and maintaining compatibility with the predominant Authorization Code Flow (ACF).

This paper introduces VeriSSO, a novel SSO protocol based on verifiable credentials (VC) that supports RP authentication while preserving privacy and avoiding single points of failure. VeriSSO employs an independent authentication server committee to manage RP and user authentication, binding RP authentication with credential-based anonymous user authentication. This approach ensures user unlinkability while supporting RP authentication and allows RPs to continue using their existing verification routines with identity tokens as in the ACF workflow. VeriSSO's design also supports lawful de-anonymization, ensuring user accountability for misbehavior during anonymity. Experimental evaluations of VeriSSO demonstrate its efficiency and practicality, with authentication processes completed within 100 milliseconds.
]]></content:encoded>
<pubDate>Wed, 19 Mar 2025 01:32:26 +0000</pubDate>
</item>
<item>
<title>Adaptive Adversaries in Byzantine-Robust Federated Learning: A survey.</title>
<link>https://eprint.iacr.org/2025/510</link>
<guid>https://eprint.iacr.org/2025/510</guid>
<content:encoded><![CDATA[
<div> 关键词：Federated Learning、安全、模型鲁棒性、自适应攻击、防御机制

<br /><br />总结:
本文关注了联邦学习（Federated Learning，FL）的安全领域，特别是针对模型鲁棒性的脆弱性。文章首先全面概述了FL系统的基本构成和现有漏洞；接着，详细介绍了针对FL系统的各类攻击向量以及现有的攻击方法与防御机制。文章提出了一个利用重新连接的恶意客户端进行攻击的新颖基线方法，并指出目前针对自适应敌手的防御措施存在显著不足，如常用的Krum和Trimmed Mean等安全聚合规则无法有效抵御这类攻击。此外，改进这些算法的工作也未解决这一问题。最后，文章指出了对抗自适应攻击的未来研究方向，并强调了其对于重新定义FL安全范式的重要性。 <div>
Federated Learning (FL) has recently emerged as one of the leading paradigms for collaborative machine learning, serving as a tool for model computation without a need to expose one’s privately stored data. However, despite its advantages, FL systems face severe challenges within its own security solutions that address both privacy and robustness of models. This paper focuses on vulnerabilities within the domain of FL security with emphasis on model-robustness. Identifying critical gaps in current defences, particularly against adaptive adversaries which modify their attack strategies after being disconnected and rejoin systems to continue attacks. To our knowledge, other surveys in this domain do not cover the concept of adaptive adversaries, this along with the significance of their impact serves as the main motivation for this work. Our contributions are fivefold: (1) we present a comprehensive overview of FL systems, presenting a complete summary of its fundamental building blocks, (2) an extensive overview of existing vulnerabilities that target FL systems in general, (3) highlight baseline attack vectors as well as state-of-the-art approaches to development of attack methods and defence mechanisms, (4) introduces a novel baseline method of attack leveraging reconnecting malicious clients, and (5) identifies future research directions to address and counter adaptive attacks. We demonstrate through experimental results that existing baseline secure aggregation rules used in other works for comparison such as Krum and Trimmed Mean are insufficient against those attacks. Further, works improving upon those algorithms do not address this concern either. Our findings serve as a basis for redefining FL security paradigms in the direction of adaptive adversaries.
]]></content:encoded>
<pubDate>Tue, 18 Mar 2025 15:44:42 +0000</pubDate>
</item>
<item>
<title>Capitalized Bitcoin Fork for National Strategic Reserve</title>
<link>https://eprint.iacr.org/2025/505</link>
<guid>https://eprint.iacr.org/2025/505</guid>
<content:encoded><![CDATA[
<div> 关键词：比特币、零成本、国家控股、比特币分叉、战略储备比特币（SRBTC）

总结:
该文提出了一种策略，使一个国家能够在不对纳税人造成任何成本的情况下获得比特币的多数股权。这个策略是通过政府赞助的比特币分叉实现的，新创建的分叉币种称为战略储备比特币（SRBTC），其创世区块将大量新的代币分配给国家财政部，数量为当前比特币（BTC）总量的多倍。原版BTC和SRBTC在分叉链上继续保持1:1等价关系。国家只需要承诺接受SRBTC作为法定货币，如税收支付。

文章通过三个竞争性游戏来证明这一提议的合理性：
1. 第一场游戏显示，如果投资者只有BTC和SRBTC两种选择，那么已持有BTC财富比例达到某一阈值θ的投资者会将新增资金投入原始链，而BTC财富占比低于θ的投资者则会选择投资SRBTC。
2. 第二场游戏表明，如果有第三个投资选择——正在贬值（经通胀调整）的现金，那么BTC持有量低于阈值θ的投资者将倾向于投资SRBTC，但前提是在未来允许挖掘的新SRBTC数量足够大（与1/d成线性增长关系）。
3. 第三场游戏证明了当比特币的分叉版本和一个不认可原版BTC价值的比特币复制品同时存在时，即使两者都由一个或多个国家同等支持，投资者也会更偏好于比特币的分叉版本。 <div>
We describe a strategy for a nation to acquire majority stake in Bitcoin with zero cost to the taxpayers of the nation. We propose a bitcoin fork sponsored by the the government of the nation, and backed by the full faith of treasury of the nation, such that the genesis block of this fork attributes fixed large amount of new kinds of tokens called strategic-reserve-bitcoin tokens (SRBTC) to the nation's treasury, which is some  multiple (greater than one) of the amount of all Bitcoin tokens (BTC) currently set in the Bitcoin protocol. The BTC tokens continue to be treated 1:1 as SRBTC tokens in the forked chain. The only capital that the nation puts up is its explicit guarantee that the SRBTC tokens of the fork will be accepted as legal tender, such as payment of tax to the treasury.

We suggest that this is a better approach than starting a new blockchain that mimics Bitcoin, as it will be  partially fair to the current holders of Bitcoin, which in turn would make it competitive in the space of other such possible forks by other powerful nations. Moreover, such a proof-of-work blockchain  retains its egalitarian and democratic nature, which competitively deters the said nation from any dilutions in the future. 

To justify our proposal we setup three competitive games, and show strategies for different players that are in Nash equilibrium and which throw further light on these claims. In particular, 

1. The first game shows that if the only two alternatives for investors is to invest in BTC or SRBTC, then individuals who have a certain fraction $\theta$ of their wealth already invested in BTC, will invest new money in the original chain, whereas the individuals whose current wealth invested in BTC is less than the $\theta$ fraction will invest new money in SRBTC.
2. The second game shows that if there is a third alternative for investment, which is cash that is losing value (inflation-adjusted) by a percentage $d$, then the investors who had less than $\theta$ fraction of wealth in Bitcoin, will invest in SRBTC only if the dilution of SRBTC is large enough (as an increasing (linear) function of $1/d$). Here by dilution we mean the new SRBTC tokens that are allowed to be eventually mined in the fork.
3.  The third game shows that investors would prefer a fork of Bitcoin over a replica of Bitcoin that doesn't value original BTC, when both are available and even if both are backed similarly by one or more nations.
]]></content:encoded>
<pubDate>Mon, 17 Mar 2025 19:12:17 +0000</pubDate>
</item>
<item>
<title>Sanitization of FHE Ciphertexts</title>
<link>https://eprint.iacr.org/2016/164</link>
<guid>https://eprint.iacr.org/2016/164</guid>
<content:encoded><![CDATA[
<div> 关键词：fully homomorphic encryption (FHE)，Somewhat Homomorphic Encryption (SHE)，bootstrapping，ciphertext sanitization，circuit privacy

总结：
文章介绍了关于全同态加密（FHE）的一种新方法。FHE方案定义中支持同态解密，现有的所有FHE构造都是通过从某种程度上可同态加密（SHE）方案利用bootstrapping技术构建的。文章提出一种算法，利用公钥提供的重随机化操作对密文进行净化，使其分布变得规范，不再依赖于导致该密文生成的电路，从而在诚实但好奇模型下实现了电路隐私。这种方法与基于噪声淹没的先前方法不同，不会显著降低底层FHE的安全性和效率权衡。这项技术可以应用于目前为止提出的全部基于格的FHE方案，而不实质性地影响其具体的参数设置。<br /><br /> <div>
By definition, fully homomorphic encryption (FHE) schemes
support homomorphic decryption, and all known FHE constructions are bootstrapped from a Somewhat Homomorphic Encryption (SHE) scheme via this technique. Additionally, when a public key is provided, ciphertexts are also re-randomizable, e.g., by adding to them fresh encryptions of 0. From those two operations we devise an algorithm to sanitize a ciphertext, by making its distribution canonical. In particular, the distribution of the ciphertext does not depend on the circuit that led to it via homomorphic evaluation, thus providing circuit privacy in the honest-but-curious model. Unlike the previous approach based on noise flooding, our approach does not degrade much the security/efficiency trade-off of the underlying FHE. The technique can be applied to all lattice-based FHE proposed so far, without substantially affecting their concrete parameters.
]]></content:encoded>
<pubDate>Fri, 19 Feb 2016 20:16:36 +0000</pubDate>
</item>
<item>
<title>Endorser Peer Anonymization in Hyperledger Fabric for Consortium of Organizations</title>
<link>https://eprint.iacr.org/2025/492</link>
<guid>https://eprint.iacr.org/2025/492</guid>
<content:encoded><![CDATA[
<div> 关键词: Hyperledger Fabric、隐私保护、背书系统、阈值环签名、Pedersen承诺

总结:<br />
本文针对Hyperledger Fabric区块链平台中的交易流程中存在endorser签名和背书策略暴露导致的安全隐患问题，提出了一种隐私保护的背书系统。该系统通过采用范围关联的阈值环签名方案匿名化背书者，并利用Pedersen承诺和非交互式知识证明来保护背书策略的安全性。同时，通过使用非交互式共根证明方法，实现了计算效率的提升。文章进行了必要的安全性分析，证明了所提方案能够确保匿名性和不可链接性属性。通过对现有框架进行比较分析，显示提出的方案提供了更高级别的安全性和优化的效率。 <div>
Hyperledger Fabric is a unique permissioned platform for implementing blockchain in a consortium. It has a distinct transaction flow of execute-order-validate. During the execution phase, a pre-determined set of endorsing peers execute a transaction and sign the transaction response. This process is termed endorsement. In the validation phase, peers validate the transaction with reference to an endorsement policy. The identity of the endorsing organizations is obtainable to all the nodes in the network through the endorser signature and endorsement policy. Knowing this has led to serious vulnerabilities in the blockchain network.
In this paper, we propose a privacy-preserving endorsement system which conceals both endorser signature and endorsement policy. Endorser is anonymized by replacing the signature scheme with a scoped-linkable threshold ring signature scheme. Endorsement policy is secured using Pedersen commitments and non-interactive proof of knowledge of integer vector. We also achieve efficiency in the computation by employing non-interactive proof of co-prime roots. We provide the necessary security analysis to prove that the proposed work guarantees anonymity and unlinkability properties. A comparative analysis of our work with an existing framework is provided which shows that the proposed scheme offers higher level of security and it is optimal in terms of efficiency.
]]></content:encoded>
<pubDate>Sat, 15 Mar 2025 13:18:58 +0000</pubDate>
</item>
<item>
<title>Blind Brother: Attribute-Based Selective Video Encryption</title>
<link>https://eprint.iacr.org/2025/491</link>
<guid>https://eprint.iacr.org/2025/491</guid>
<content:encoded><![CDATA[
<div> 关键词: 选择性视频加密(SVE), 细粒度访问控制, ABSVE协议, 区域感兴趣(ROI), 密文策略属性基加密(CP-ABE)

总结:<br />
针对现有选择性视频加密方案存在的粗粒度加密和单一访问级别的局限性，本文提出了一个基于细粒度访问控制的选择性视频加密方案——ABSVE及其应用协议\protocol。该方案通过使用独特的对称密钥加密不同的区域感兴趣(ROI)，并利用CP-ABE方案将这些密钥与特定访问策略绑定，从而实现单个加密视频流的多级访问权限。此外，文章还为ABSVE提供了正式的语法和安全性定义，填补了先前工作中对此类方案严格安全性分析的空白。最后，本文在Kvazaar HEVC编码器上实现了该协议并进行了评估，结果显示，提出的方案在增强安全性和隐私保护的同时，还能实现对视频内容的可控访问，并且效率接近未加密压缩的情况。 <div>
The emergence of video streams as a primary medium for communication and the demand for high-quality video sharing over the internet have given rise to several security and privacy issues, such as unauthorized access and data breaches. To address these limitations, various Selective Video Encryption (SVE) schemes have been proposed, which encrypt specific portions of a video while leaving others unencrypted. The SVE approach balances security and usability, granting unauthorized users access to certain parts while encrypting sensitive content. However, existing SVE schemes adopt an all-or-nothing coarse-grain encryption approach, where a user with a decryption key can access all the contents of a given video stream. This paper proposes and designs a fine-grained access control-based selective video encryption scheme, ABSVE, and a use-case protocol called \protocol. Our scheme encrypts different identified Regions of Interest (ROI) with a unique symmetric key and applies a Ciphertext Policy Attribute Based Encryption (CP-ABE) scheme to tie these keys to specific access policies. This method provides multiple access levels for a single encrypted video stream. Crucially, we provide a formal syntax and security definitions for ABSVE, allowing for rigorous security analysis of this and similar schemes --  which is absent in prior works. Finally, we provide an implementation and evaluation of our protocol in the Kvazaar HEVC encoder. Overall, our constructions enhance security and privacy while allowing controlled access to video content and achieve comparable efficiency to compression without encryption.
]]></content:encoded>
<pubDate>Sat, 15 Mar 2025 13:13:35 +0000</pubDate>
</item>
<item>
<title>PREAMBLE: Private and Efficient Aggregation of Block Sparse Vectors and Applications</title>
<link>https://eprint.iacr.org/2025/490</link>
<guid>https://eprint.iacr.org/2025/490</guid>
<content:encoded><![CDATA[
<div> 关键词：secure aggregation、two-server system、Prio、block-sparse vectors、PREAMBLE

总结:<br />
本文关注的是在两服务器系统中高维度向量的安全聚合问题，如Prio系统中用于隐私联邦学习的梯度聚合。现有的方法需要随着维度的增长而增加通信量，从而限制了能有效处理的向量维度。为此，文章提出了PREAMBLE——一种针对块稀疏欧几里得向量的新型分布式点函数扩展，它实现了对块稀疏向量的高效通信和计算聚合。进一步地，PREAMBLE可以与随机采样及采样结果下的隐私增强相结合，实现向量聚合的渐近最优隐私-效用权衡，同时只需很小的通信成本。结合最近在数值隐私会计领域的进展，相比于应用于Prio的高斯机制，本方法在噪声方差上的开销可忽略不计。 <div>
We revisit the problem of secure aggregation of high-dimensional vectors in a two-server system such as Prio. These systems are typically used to aggregate vectors such as gradients in private federated learning, where the aggregate itself is protected via noise addition to ensure differential privacy. Existing approaches require communication scaling with the dimensionality, and thus limit the dimensionality of vectors one can efficiently process in this setup.

We propose PREAMBLE: Private Efficient Aggregation Mechanism for  Block-sparse Euclidean Vectors. PREAMBLE is a novel extension of distributed point functions that enables communication- and computation-efficient aggregation of block-sparse vectors, which are sparse vectors where the non-zero entries occur in a small number of clusters of consecutive coordinates. We then show that PREAMBLE can be combined with random sampling and privacy amplification by sampling results, to allow asymptotically optimal privacy-utility trade-offs for vector aggregation, at a fraction of the communication cost. When coupled with recent advances in numerical privacy accounting, our approach incurs a negligible overhead in noise variance, compared to the Gaussian mechanism used with Prio.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 22:02:42 +0000</pubDate>
</item>
<item>
<title>webSPDZ: Versatile MPC on the Web</title>
<link>https://eprint.iacr.org/2025/487</link>
<guid>https://eprint.iacr.org/2025/487</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、可用性、浏览器基础、webSPDZ、MP-SPDZ

总结:
随着多党计算（MPC）在如医疗、金融和机器学习等领域解决隐私与安全问题日益实用化，其用户体验成为一大关注点。为提升MPC的易用性，可构建基于浏览器的MPC引擎，例如JIFF和MPyC的网络版本。文章提出将性能强大、通用性强的MPC引擎MP-SPDZ引入网络环境，创建名为webSPDZ的新引擎。通过使用Emscripten将MP-SPDZ的C++后端编译为WebAssembly并升级浏览器通信（使用WebRTC或WebSocket）。webSPDZ支持≥40种不同安全模型的MPC协议，相较于现有的MPyC-Web和JIFF等网络版MPC引擎，在端到端实验中表现出更优性能。因此，webSPDZ不仅提升了MPC的易用性，还将其实用范围扩展至更广泛的用户群体，推动了MPC实践应用的边界。 <div>
Multi-party computation (MPC) has become increasingly practical in the last two decades, solving privacy and security issues in various domains, such as healthcare, finance, and machine learning. One big caveat is that MPC sometimes lacks usability since the knowledge barrier for regular users can be high. Users have to deal with, e.g., various CLI tools, private networks, and sometimes even must install many dependencies, which are often hardware-dependent.

A solution to improve the usability of MPC is to build browser-based MPC engines where each party runs within a browser window. Two examples of such an MPC web engine are JIFF and the web variant of MPyC. Both support an honest majority with passive corruptions.

$\texttt{webSPDZ}$: Our work brings one of the most performant and versatile general-purpose MPC engines, MP-SPDZ, to the web. MP-SPDZ supports ≥40 MPC protocols with different security models, enabling many security models on the web. To port MP-SPDZ to the web, we use Emscripten to compile MP-SPDZ’s C++ BackEnd to WebAssembly and upgrade the party communication for the browser (WebRTC or WebSockets). We call the new MPC web engine webSPDZ. As with the native versions of the mentioned MPC web engines, MPyC-Web and JIFF, webSPDZ outperforms them in our end-to-end experiments.

We believe that webSPDZ brings forth many interesting and practically relevant use cases. Thus, webSPDZ pushes the boundaries of practical MPC: making MPC more usable and enabling it for a broader community.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 07:30:45 +0000</pubDate>
</item>
<item>
<title>On One-Shot Signatures, Quantum vs Classical Binding, and Obfuscating Permutations</title>
<link>https://eprint.iacr.org/2025/486</link>
<guid>https://eprint.iacr.org/2025/486</guid>
<content:encoded><![CDATA[
<div> 关键词: One-shot signatures (OSS), 量子签名钥匙, 不可克隆原理, 可区分性混淆(iO), LWE假设

总结:
本文首次提出了基于标准模型的一次性签名方案(OSS)，该方案的安全性依赖于亚指数级的不可区分性混淆(iO)和LWE假设。这同时也解决了长达十年的一个开放问题，即首次在标准模型下实现了区分古典绑定与坍缩绑定的后量子承诺/哈希的分离。在此过程中，文章还给出了第一个无条件安全的经典oracle模型下的OSS构造。为了实现标准模型的构造，作者们提出了一种名为可交换伪随机置换(permutable PRPs)的概念，并展示了它们如何用于将涉及随机置换的oracle证明转化为基于混淆的证明。具体来说，混淆可交换PRP可以得到一个全域的带有陷阱门的一次性单向函数，这也解决了另一个使用(iO)和一次函数构建此类对象长达十年的问题。 <div>
One-shot signatures (OSS) were defined by Amos, Georgiou, Kiayias, and Zhandry (STOC'20). These allow for signing exactly one message, after which the signing key self-destructs, preventing a second message from ever being signed. While such an object is impossible classically, Amos et al observe that OSS may be possible using quantum signing keys by leveraging the no-cloning principle. OSS has since become an important conceptual tool with many applications in decentralized settings and for quantum cryptography with classical communication. OSS are also closely related to separations between classical-binding and collapse-binding for post-quantum hashing and commitments. Unfortunately, the only known OSS construction due to Amos et al. was only justified in a classical oracle model, and moreover their justification was ultimately found to contain a fatal bug. Thus, the existence of OSS, even in a classical idealized model, has remained open. 

We give the first standard-model OSS, with provable security assuming (sub-exponential) indistinguishability obfuscation (iO) and LWE. This also gives the first standard-model separation between classical and collapse-binding post-quantum commitments/hashing, solving a decade-old open problem. Along the way, we also give the first construction with unconditional security relative to a classical oracle. To achieve our standard-model construction, we develop a notion of permutable pseudorandom permutations (permutable PRPs), and show how they are useful for translating oracle proofs involving random permutations into obfuscation-based proofs. In particular, obfuscating permutable PRPs gives a trapdoor one-way permutation that is $\textit{full-domain}$, solving another decade-old-problem of constructing this object from (sub-exponential) iO and one-way functions.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 06:49:30 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Zero-Knowledge Proofs with Certified Deletion</title>
<link>https://eprint.iacr.org/2024/1848</link>
<guid>https://eprint.iacr.org/2024/1848</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式零知识证明，认证删除，量子，学习与错误问题，可撤销匿名凭证

总结:
本文提出了具有认证删除功能的非交互式零知识（NIZK）证明的概念。该概念允许NIZK证明的接收者在删除证明后获得一个证明删除行为的古典证书。文中给出了两个基于标准密码学假设的候选构造方案，第一个方案依赖于经典的NIZK证明和量子抗性的一次函数，但需要证明者和验证者都运行量子算法。随后，作者提出了一种扩展方案，允许证明者为经典设备，这个方案基于学习与错误问题，并要求证明者和验证者之间进行一次实例独立的交互式设置。此外，这些成果在可撤销的知识签名和可撤销匿名凭证的应用上也有所体现，文中对这两个应用进行了定义并构建了相应的方案。<br /><br /> <div>
We introduce the notion of non-interactive zero-knowledge (NIZK) proofs with certified deletion. Our notion enables the recipient of a (quantum) NIZK proof to delete the proof and obtain a (classical) certificate proving such deletion. We define this notion and propose two candidate constructions from standard cryptographic assumptions. Our first construction is based on classical NIZK proofs and quantum-hard one-way functions but needs both the prover and verifier to run quantum algorithms. We then present an extension that allows the prover to be classical; this is based on the learning with errors problem and requires an instance-independent interactive setup between the prover and verifier. 

Our results have applications to revocable signatures of knowledge and revocable anonymous credentials, which we also define and construct.
]]></content:encoded>
<pubDate>Mon, 11 Nov 2024 00:05:19 +0000</pubDate>
</item>
<item>
<title>Client-Efficient Online-Offline Private Information Retrieval</title>
<link>https://eprint.iacr.org/2024/719</link>
<guid>https://eprint.iacr.org/2024/719</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Information Retrieval (PIR), Online-Offline PIR (OO-PIR), Pirex, Client inbound bandwidth, Storage cost

总结:<br />
本文提出了一种名为Pirex的新颖两服务器在线离线私人信息检索(PIR)方案，该方案具有半诚实安全性。Pirex显著降低了客户端的带宽和存储成本，同时保持了亚线性处理效率。与现有的OO-PIR方案相比，Pirex的设计更为简洁，主要操作自然低成本且高效（如XOR、PRF和模数运算）。已经完全实现了Pirex并使用商用硬件对其进行了实际性能评估。结果显示，Pirex比现有方案至少快两个数量级。例如，在面对1TB数据库查询4KB条目时，Pirex仅需55毫秒，而最先进的方案需要9到30秒。对于含有数十亿个4KB条目的实际数据库，Pirex只需16KB的进站带宽，效率提高了三个数量级。 <div>
Private Information Retrieval (PIR) permits clients to query data entries from a public database hosted on untrusted servers while preserving client privacy. Traditional PIR models suffer from high computation and/or bandwidth overhead due to linear database processing for privacy. Recently, Online-Offline PIR (OO-PIR) has been proposed to improve PIR practicality by precomputing query-independent materials to accelerate online access. While state-of-the-art OO-PIR schemes (e.g., S&amp;P’24, CRYPTO’23) successfully reduce online processing cost to sublinear levels, they still impose substantial bandwidth and storage burdens on the client, especially when operating on large databases.

In this paper, we propose Pirex, a new two-server OO-PIR with semi-honest security that offers minimal client inbound bandwidth and storage cost while retaining the sublinear processing efficiency. The Pirex design is simple with most operations are naturally low-cost and streamlined (e.g., XOR, PRF, modular arithmetic). We have fully implemented Pirex and evaluated its real-world performance using commodity hardware. Our results showed that Pirex outperforms existing OO-PIR schemes by at least two orders of magnitude. With a 1 TB database, Pirex takes 55ms to retrieve a 4 KB entry, compared with 9-30s by state-of-the-art. For practical databases with billions of 4 KB entries, Pirex only takes 16 KB of inbound bandwidth, which is up to three orders of magnitude more efficient.
]]></content:encoded>
<pubDate>Fri, 10 May 2024 02:53:56 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure Threshold Blind BLS Signatures and Threshold Oblivious PRF</title>
<link>https://eprint.iacr.org/2025/483</link>
<guid>https://eprint.iacr.org/2025/483</guid>
<content:encoded><![CDATA[
<div> 关键词: 原始文本、首次、阈值盲签名方案、阈值Oblivious PRF (OPRF)、适应性安全性

总结:
我们首次提出了在适应性对手存在下仍能保持安全性的阈值盲签名方案和阈值Oblivious PRF (OPRF)方案。这些方案允许对手在整个协议生命周期中自适应地选择要腐败的参与者。与仅针对静态对手提供安全性的先前解决方案相比，我们的方案仅增加了少量计算开销，并保持了最小的通信轮数复杂度。我们的阈值盲签名方案基于标准的BLS签名，而阈值OPRF则采用高效的“2HashDH”OPRF。这两个方案都在代数群模型(AGM)中证明了其适应性安全性。此外，我们的适应性安全阈值方案同样具备实用性和与其基础的单服务器BLS盲签名以及2HashDH OPRF相同的效率，可以用于为依赖于盲签名（如匿名凭证和电子现金系统）或Oblivious PRF（如OPAQUE密码认证和Privacy Pass匿名认证方案等）的系统增添加密容错能力和去中心化的信任机制。 <div>
We show the first threshold blind signature scheme and threshold Oblivious PRF (OPRF) scheme which remain secure in the presence of an adaptive adversary, who can adaptively decide which parties to corrupt throughout the lifetime of the scheme.  Moreover, our adaptively secure schemes preserve the minimal round complexity and add only a small computational overhead over prior solutions that offered security only for a much less realistic static adversary, who must choose the subset of corrupted parties before initializing the protocol.

Our threshold blind signature scheme computes standard BLS signatures while our threshold OPRF computes a very efficient "2HashDH" OPRF [JKK14].  We prove adaptive security of both schemes in the Algebraic Group Model (AGM).  Our adaptively secure threshold schemes are as practical as the underlying standard single-server BLS blind signature and 2HashDH OPRF, and they can be used to add cryptographic fault-tolerance and decentralize trust in any system that relies on blind signatures, like anonymous credentials and e-cash, or on OPRF, like the OPAQUE password authentication and the Privacy Pass anonymous authentication scheme, among many others.
]]></content:encoded>
<pubDate>Fri, 14 Mar 2025 00:02:29 +0000</pubDate>
</item>
<item>
<title>Post Quantum Migration of Tor</title>
<link>https://eprint.iacr.org/2025/479</link>
<guid>https://eprint.iacr.org/2025/479</guid>
<content:encoded><![CDATA[
<div> 关键词：Shor's算法，Grover's算法，量子计算机，Tor网络，后量子密码学(PQC)

总结:
本文针对Shor's和Grover's算法以及量子计算机技术进步可能对现有隐私保护加密方式构成的潜在威胁进行了探讨。文章以匿名通信系统Tor为例，首先分析了其中使用的非量子抗性加密方案，并提出了评估本地Tor网络性能的理论方法。研究分为三个阶段进行：一是基准测试局部Tor网络模拟在受限设备上的运行时间，以孤立出古典密码学过程所需的时间；二是结合现有的量子安全算法基准测试结果，对比这些算法在同类设备上的性能表现；最后，通过对传统密码学执行时间替换为在特定Tor环境中记录的PQC执行时间，来估算采用PQC所带来的开销。通过关注可替代的加密组件、运用理论估计并利用现有基准测试数据，本文旨在无需完全实现PQC的情况下，对未来PQC对Tor网络可能产生的影响提供有价值的见解。 <div>
Shor's and Grover's algorithms' efficiency and the advancement of quantum computers imply that the cryptography used until now to protect one's privacy is potentially vulnerable to retrospective decryption, also known as harvest now, decrypt later attack in the near future. This dissertation proposes an overview of the cryptographic schemes used by Tor, highlighting the non-quantum-resistant ones and introducing theoretical performance assessment methods of a local Tor network. The measurement is divided into three phases. We will start with benchmarking a local Tor network simulation on constrained devices to isolate the time taken by classical cryptography processes. Secondly, the analysis incorporates existing benchmarks of quantum-secure algorithms and compares these performances on the devices. Lastly, the estimation of overhead is calculated by replacing the measured times of traditional cryptography with the times recorded for Post Quantum Cryptography (PQC) execution within the specified Tor environment. By focusing on the replaceable cryptographic components, using theoretical estimations, and leveraging existing benchmarks, valuable insights into the potential impact of PQC can be obtained without needing to implement it fully.
]]></content:encoded>
<pubDate>Thu, 13 Mar 2025 10:35:48 +0000</pubDate>
</item>
<item>
<title>Cross-Platform Benchmarking of the FHE Libraries: Novel Insights into SEAL and OpenFHE</title>
<link>https://eprint.iacr.org/2025/473</link>
<guid>https://eprint.iacr.org/2025/473</guid>
<content:encoded><![CDATA[
<div> 关键词: 云计算, 隐私保护, 欧同态加密(HE), SEAL, OpenFHE

总结:
这篇论文评估了两种主流的欧同态加密库——SEAL和OpenFHE，关注其在处理敏感数据的安全计算性能、易用性以及对如BGV和CKKS等著名HE方案的支持。研究分析了它们在Linux和Windows平台上的计算效率、内存使用及可扩展性，强调了其在现实世界场景中的适用性。结果显示，Linux平台在计算效率上优于Windows，而OpenFHE则在各种密码学设定下表现出更优的整体性能。这些发现为研究人员和实践者推进基于HE的隐私保护应用提供了有价值的参考。 <div>
The rapid growth of cloud computing and data-driven applications has amplified privacy concerns, driven by the increasing demand to process sensitive data securely. Homomorphic encryption (HE) has become a vital solution for addressing these concerns by enabling computations on encrypted data without revealing its contents. This paper provides a comprehensive evaluation of two leading HE libraries, SEAL and OpenFHE, examining their performance, usability, and support for prominent HE schemes such as BGV and CKKS.   Our analysis highlights computational efficiency, memory usage, and scalability across Linux and Windows platforms, emphasizing their applicability in real-world scenarios. Results reveal that Linux outperforms Windows in computation efficiency, with OpenFHE emerging as the optimal choice across diverse cryptographic settings. This paper provides valuable insights for researchers and practitioners to advance privacy-preserving applications using FHE.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 22:21:53 +0000</pubDate>
</item>
<item>
<title>Practical Semi-Open Chat Groups for Secure Messaging Applications</title>
<link>https://eprint.iacr.org/2025/469</link>
<guid>https://eprint.iacr.org/2025/469</guid>
<content:encoded><![CDATA[
<div> 关键词: 实践型、隐私保护、声誉系统、安全即时通讯应用、成员准入自动化

总结:
设计了一个实用且注重隐私保护的声誉系统，该系统能基于现有成员对新成员的声誉评估自动批准其加入大规模聊天群组，如Signal、Telegram和Whatsapp中的群组。系统在单服务器模型中证明了对恶意敌手的安全性，无需额外的信任假设，并能在大部分成员离线的情况下几乎正常进行任意声誉计算。此外，通过开源实现展示了其实用性。对于人数为50（或200）的群组，对获得40（或80）评分的新成员进行准入过程分别需要通信量1312.2 KiB（或5239.4 KiB），以及单核计算时间3.3秒（或16.3秒）。虽然本协议的设计与现有的安全即时通讯应用相匹配，但我们认为它在分布式声誉计算领域的应用场景超越了这一问题设定。 <div>
Chat groups in secure messaging applications such as Signal, Telegram, and Whatsapp are nowadays used for rapid and widespread dissemination of information to large groups of people. This is common even in sensitive contexts, associated with the organisation of protests, activist groups, and internal company dialogues. Manual administration of who has access to such groups quickly becomes infeasible, in the presence of hundreds or thousands of members.

We construct a practical, privacy-preserving reputation system, that automates the approval of new group members based on their reputation amongst the existing membership. We demonstrate security against malicious adversaries in a single-server model, with no further trust assumptions required. Furthermore, our protocol supports arbitrary reputation calculations while almost all group members are offline (as is likely). In addition, we demonstrate the practicality of the approach via an open-source implementation. For groups of size 50 (resp. 200), an admission process on a user that received 40 (resp. 80) scores requires 1312.2 KiB (resp. 5239.4 KiB) of communication, and 3.3s (resp. 16.3s) of overall computation on a single core. While our protocol design matches existing secure messaging applications, we believe it can have value in distributed reputation computation beyond this problem setting.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 11:23:47 +0000</pubDate>
</item>
<item>
<title>zkAML: Zero-knowledge Anti Money Laundering in Smart Contracts with whitelist approach</title>
<link>https://eprint.iacr.org/2025/465</link>
<guid>https://eprint.iacr.org/2025/465</guid>
<content:encoded><![CDATA[
<div> 关键词：反洗钱（AML）、打击恐怖主义融资（CFT）、零知识证明（zk-SNARK）、隐私保护、区块链网络

总结：
本文提出了一种名为\textsf{zkAML}的加密框架，旨在解决传统AML/CFT合规性监管中出现的效率低下、交易延迟和隐私泄露问题。该框架利用zk-SNARK技术，使得用户能够在不透露敏感个人信息的情况下，证明其符合监管要求，从而避免了冗余的身份检查，简化了合规流程，并提升了交易效率。文章进一步阐述了\textsf{zkAML}在区块链网络上的实现与评估结果，显示在公共网络上可达到55笔/秒的交易处理能力，在私有网络上可达324笔/秒。生成发送方和接收方的zk-SNARK证明的时间分别为226.59毫秒和215.76毫秒，每笔交易的验证时间恒定为1.47毫秒。这些实验结果证实了\textsf{zkAML}作为隐私保护与法规遵从解决方案在现代金融系统中的应用潜力。 <div>
In the interconnected global financial system, anti-money laundering (AML) and combating the financing of terrorism (CFT) regulations are indispensable for safeguarding financial integrity. However, while illicit transactions constitute only a small fraction of overall financial activities, traditional AML/CFT frameworks impose uniform compliance burdens on all users, resulting in inefficiencies, transaction delays, and privacy concerns. 
These issues stem from the institution-centric model, where financial entities independently conduct compliance checks, resulting in repeated exposure of personally identifiable information (PII) and operational bottlenecks.
To address these challenges, we introduce \textsf{zkAML}, a cryptographic framework that offers a novel approach to AML/CFT compliance. By leveraging zero-knowledge Succinct Non-Interactive Argument of Knowledge (zk-SNARK) proofs, \textsf{zkAML}~enables users to cryptographically demonstrate their regulatory compliance without revealing sensitive personal information. This approach eliminates redundant identity checks, streamlines compliance procedures, and enhances transaction efficiency while preserving user privacy.
We implement and evaluate \textsf{zkAML}~on a blockchain network to demonstrate its practicality. Our experimental results show that \textsf{zkAML}~achieves 55 transactions per second (TPS) on a public network and 324 TPS on a private network. The zk-SNARK proof generation times are $226.59$ms for senders and $215.76$ms for receivers, with a constant verification time of $1.47$ms per transaction. These findings highlight \textsf{zkAML}'s potential as a privacy-preserving and regulation-compliant solution for modern financial systems.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 08:43:03 +0000</pubDate>
</item>
<item>
<title>Leaking Arbitrarily Many Secrets: Any-out-of-Many Proofs and Applications to RingCT Protocols</title>
<link>https://eprint.iacr.org/2021/1405</link>
<guid>https://eprint.iacr.org/2021/1405</guid>
<content:encoded><![CDATA[
<div> 关键词：Ring Confidential Transaction (RingCT), 任何-out-of-many证明, 零知识证明, 多重秘密, 匿名性<br /><br />总结: 本文提出了一种新颖的“任何-out-of-many”证明方案，这是一种对公开列表中任意多的秘密进行知识证明的、对数大小的零知识证明策略。与现有部分知识证明不同，该方法在证明多个秘密的同时不泄露确切的秘密数量。通过采用Bulletproofs压缩技术的通用内积变换，进一步提高了效率，将证明尺寸减少到$2 \lceil \log_2(N) \rceil \! + \! 9$。基于此证明方案，文章构建了一个紧凑型的RingCT协议，用于隐私加密货币，实现了处理具有多个输入交易的对数级通信复杂度，并提供了最高级别的匿名性。相较于如Omniring等其他方法，这是首个从部分知识证明实例化的RingCT协议，同时它也可以适应其他应用，如多重环签名和区块链中的币混服务。文章认为这些技术在更多隐私保护场景中也具有潜在的应用价值。 <div>
Ring Confidential Transaction (RingCT) protocol is an effective cryptographic component for preserving the privacy of cryptocurrencies. However, existing RingCT protocols are instantiated from one-out-of-many proofs with only one secret, leading to low efficiency and weak anonymity when handling transactions with multiple inputs. Additionally, current partial knowledge proofs with multiple secrets are neither secure nor efficient to be applied in a RingCT protocol.
    
In this paper, we propose a novel \emph{any-out-of-many proof}, a logarithmic-sized zero-knowledge proof scheme for showing the knowledge of arbitrarily many secrets out of a public list. Unlike other partial knowledge proofs that have to reveal the number of secrets [ACF21], our approach proves the knowledge of multiple secrets without leaking the exact number of them. Furthermore, we improve the efficiency of our method with a generic inner-product transformation to adopt the Bulletproofs compression [BBB+18], which reduces the proof size to $2 \lceil \log_2(N) \rceil \! + \! 9$.
    
Based on our proposed proof scheme, we further construct a compact RingCT protocol for privacy cryptocurrencies, which can provide a logarithmic-sized communication complexity for transactions with multiple inputs. More importantly, as the only known RingCT protocol instantiated from the partial knowledge proofs, our protocol can achieve the highest anonymity level compared with other approaches like Omniring [LRR+19]. For other applications, such as multiple ring signatures, our protocol can also be applied with some modifications. We believe our techniques are also applicable in other privacy-preserving scenarios, such as multiple ring signatures and coin-mixing in the blockchain.
]]></content:encoded>
<pubDate>Sun, 24 Oct 2021 07:27:47 +0000</pubDate>
</item>
<item>
<title>Token meets Wallet: Formalizing Privacy and Revocation for FIDO2</title>
<link>https://eprint.iacr.org/2022/084</link>
<guid>https://eprint.iacr.org/2022/084</guid>
<content:encoded><![CDATA[
<div> 关键词：FIDO2标准、WebAuthn组件、安全模型、隐私保护、全局密钥撤销

总结:<br />
本文针对FIDO2标准中的WebAuthn组件进行了安全性重新审视。首先，改进了Barbosa等人提出的模型，以涵盖使用密钥派生或密钥封装的认证令牌。其次，提出了FIDO2中WebAuthn组件的第一个正式隐私定义，并证明如果选用适当的底层构建模块，则该组件在常见FIDO2令牌实现中可保证用户隐私。最后，解决了FIDO2全局密钥撤销问题，为此引入并分析了一种基于广泛应用于加密货币钱包的BIP32标准的简单撤销程序，该程序能够与现有的FIDO2服务器高效实施。 <div>
The FIDO2 standard is a widely-used class of challenge-response type protocols that allows to authenticate to an online service using a hardware token.  
Barbosa et al. (CRYPTO `21) provided the first formal security model and analysis for the FIDO2 standard.
However, their model has two shortcomings: (1) It does not include privacy, one of the key features claimed by FIDO2. (2) It only covers tokens that store {all secret keys locally}.
In contrast, due to limited memory, most existing FIDO2 tokens either derive all secret keys from a common seed or store keys on the server (the latter approach is also known as {key wrapping}).

In this paper, we revisit the security of the WebAuthn component of FIDO2 as implemented in practice. Our contributions are as follows.
(1) We adapt the model of Barbosa et al. so as to capture authentication tokens using key derivation or key wrapping.
(2) We provide the {first formal definition of privacy for the WebAuthn component of FIDO2}. We then prove the privacy of this component in common FIDO2 token implementations if the underlying building blocks are chosen appropriately.
(3) We address the unsolved problem of {global key revocation} in FIDO2. 
To this end, we introduce and analyze a simple revocation procedure that builds on the popular BIP32 standard used in cryptocurrency wallets and can efficiently be implemented with existing FIDO2 servers.
]]></content:encoded>
<pubDate>Sun, 23 Jan 2022 13:01:17 +0000</pubDate>
</item>
<item>
<title>Multi-Party Computation in Corporate Data Processing: Legal and Technical Insights</title>
<link>https://eprint.iacr.org/2025/463</link>
<guid>https://eprint.iacr.org/2025/463</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算(MPC), 欧盟通用数据保护条例(GDPR), 法律分析, 技术实现, 隐私保护

总结:
本文研究了多方计算（MPC）在企业数据处理环境中的应用及其在欧洲联盟通用数据保护条例（GDPR）下的法律和技术影响。文章通过结合密码学和法律分析的专业知识，探讨了MPC作为匿名化方法在GDPR下适用性的关键问题，重点关注分布式控制等架构要求以有效降低重新识别风险。法律评估得到两个独立评估的支持。文章系统性地回答了关键监管问题，强调对于意图采用MPC的同时确保遵守隐私法的组织来说，结构化的法律评估至关重要。此外，为了补充这一理论分析，文章还利用Carbyne Stack——一个基于云原生的、用于可扩展MPC应用的开源平台，以及其后端集成的MP-SPDZ框架，实现了隐私保护的数据分析，并对不同安全模型下的SQL查询进行了基准测试，以评估其可扩展性和效率。 <div>
This paper examines the deployment of Multi-Party Computation (MPC) in corporate data processing environments, focusing on its legal and technical implications under the European Union’s General Data Protection Regulation (GDPR). By combining expertise in cryptography and legal analysis, we address critical questions necessary for assessing the suitability of MPC for real-world applications. Our legal evaluation explores the conditions under which MPC qualifies as an anonymizing approach under GDPR, emphasizing the architectural requirements, such as the distribution of control among compute parties, to minimize re-identification risks effectively. The assertions put forth in the legal opinion are validated by two distinct assessments conducted independently.

We systematically answer key regulatory questions, demonstrating that a structured legal assessment is indispensable for organizations aiming to adopt MPC while ensuring compliance with privacy laws. In addition, we complement this analysis with a practical implementation of privacy-preserving analytics using Carbyne Stack, a cloud-native open-source platform for scalable MPC applications, which integrates the MP-SPDZ framework as its backend. We benchmark SQL queries under various security models to evaluate scalability and efficiency.
]]></content:encoded>
<pubDate>Wed, 12 Mar 2025 08:19:28 +0000</pubDate>
</item>
<item>
<title>Achieving Data Reconstruction Hardness and Efficient Computation in Multiparty Minimax Training</title>
<link>https://eprint.iacr.org/2025/460</link>
<guid>https://eprint.iacr.org/2025/460</guid>
<content:encoded><![CDATA[
<div> 关键词：生成模型、联邦学习、数据重建、多 party 计算、生成对抗网络<br /><br />总结: 本文关注在保持训练成本可管理的同时，提高基于生成对抗网络（GAN）训练过程中数据重构的难度。研究了两种使用公共生成器和多方计算（MPC）鉴别器的训练协议：协议1（P1）采用完全私有的鉴别器，而协议2（P2）仅对前三层鉴别器进行隐私保护。我们证明了对于P1和P2，只要鉴别器的前两层是私有的，公共生成器就不能恢复真实的训练数据；并通过ReLU网络存在的已知近似难度结果，证明了至少有三层私有层的鉴别器不能通过多项式时间复杂度的算法来重构真实数据。实验结果显示，与完全MPC训练相比，P1能够将训练时间减少2倍，而P2则能进一步将其减少到4至16倍。 <div>
Generative models have achieved remarkable success in a wide range of applications. Training such models using proprietary data from multiple parties has been studied in the realm of federated learning. Yet recent studies showed that reconstruction of authentic training data can be achieved in such settings. 
On the other hand, multiparty computation (MPC) guarantees standard data privacy, yet scales poorly for training generative models. 
In this paper, we focus on improving reconstruction hardness during Generative Adversarial Network (GAN) training while keeping the training cost tractable. To this end, we explore two training protocols that use a public generator and an MPC discriminator: Protocol 1 (P1) uses a fully private discriminator, while Protocol 2 (P2) privatizes the first three discriminator layers. We prove reconstruction hardness for P1 and P2 by showing that (1) a public generator does not allow recovery of authentic training data, as long as the first two layers of the discriminator are private; and through an existing approximation hardness result on ReLU networks, (2) a discriminator with at least three private layers does not allow authentic data reconstruction with algorithms polynomial in network depth and size. We show empirically that compared with fully MPC training, P1 reduces the training time by $2\times$ and P2 further by $4-16\times$.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 22:39:40 +0000</pubDate>
</item>
<item>
<title>Revisiting the Security and Privacy of FIDO2</title>
<link>https://eprint.iacr.org/2025/459</link>
<guid>https://eprint.iacr.org/2025/459</guid>
<content:encoded><![CDATA[
<div> 关键词: FIDO2、隐私安全分析、信任设置假设、安全模型、隐私保证

总结:<br />
本文重新审视了广泛应用于网络无密码认证标准FIDO2的隐私与安全性分析。文中指出了以往工作的局限性，包括不切实际的信任设置假设、针对当前实战攻击的安全模型不足以及未全面分析FIDO2的整体隐私保障。为填补这些空白，文章提出了修订后的隐私和身份验证安全模型，并采用新模型对FIDO2进行模块化分析，重点关注其组件协议WebAuthn和CTAP2，明确了它们的确切安全保障。特别地，本研究首次确立了FIDO2整体的隐私保护承诺。此外，还提出了一些小修改建议，以帮助FIDO2能够达到更强大的隐私和认证定义要求，并抵抗已知和新型攻击。 <div>
We revisit the privacy and security analyses of FIDO2, a widely deployed standard for passwordless authentication on the Web. 
We discuss previous works 
and conclude that each of them has at least one of the following limitations:
(i) impractical trusted setup assumptions, 
(ii) security models that are inadequate in light of state of the art of practical attacks,
(iii) not analyzing FIDO2 as a whole, especially for its privacy guarantees.
Our work addresses these gaps and proposes revised security models for privacy and authentication. Equipped with our new models, we analyze FIDO2 modularly and focus on its component protocols, WebAuthn and CTAP2, clarifying their exact security guarantees. 
In particular, our results, for the first time, establish privacy guarantees for FIDO2 as a whole.
Furthermore, we suggest minor modifications that can help FIDO2 provably meet stronger privacy and authentication definitions and withstand known and novel attacks.
]]></content:encoded>
<pubDate>Tue, 11 Mar 2025 21:09:06 +0000</pubDate>
</item>
<item>
<title>Concretely Efficient Correlated Oblivious Permutation</title>
<link>https://eprint.iacr.org/2025/449</link>
<guid>https://eprint.iacr.org/2025/449</guid>
<content:encoded><![CDATA[
<div> 关键词： Oblivious Permutation (OP)，Correlated Oblivious Permutation (COP)，secure multi-party computation (MPC)，communication cost，execution time。

总结:<br />
本文针对 Oblivious Permutation (OP) 中的性能瓶颈问题进行了研究。OP 是许多重要 MPC 应用的基础，但其高复杂度限制了其实效性。Chase 等人在 Asiacrypt'20 提出了离线-在线 OP 模型，利用可预计算资源“Share Translation”降低在线成本。然而，生成 Share Translation 的高额离线成本仍是待优化领域。本文重新定义了该预计算资源为新的密码学原语——Correlated Oblivious Permutation (COP) 并对其两种生成方案（网络和矩阵方案）进行了深入分析与优化。对于网络方案，改进减少了构建交换机的通信/计算成本并降低了网络中的交换机数量；对矩阵方案，则降低了小规模 COP 生成的通信成本及大规模 COP 生成的通过内外分解的成本。作者实现了这两种 COP 生成协议并进行了全面评估，结果显示，使用 128 位输入数据为例，网络方案和矩阵方案分别比基线协议快达 1.7 倍和 1.6 倍。进一步地，将优化后的 COP 应用于最先进的 PSU 协议中，实现了超过 25% 的通信成本减少和 35% 的执行时间下降，证明了 COP 优化对于现实世界 MPC 原语的重大改进意义。 <div>
Oblivious permutation (OP) enables two parties, a sender with a private data vector $x$ and a receiver with a private permutation π, to securely obtain the shares of π(x). OP has been used to construct many important MPC primitives and applications such as secret shuffle, oblivious sorting, private set operations, secure database analysis, and privacy-preserving machine learning. Due to its high complexity, OP has become a performance bottleneck in several practical applications, and many efforts have been devoted to enhancing its concrete efficiency. Chase et al. (Asiacrypt'20) proposed an offline-online OP paradigm leveraging a pre-computable resource termed Share Translation. While this paradigm significantly reduces online costs, the substantial offline cost of generating Share Translation remains an area for further investigation.

In this work, we redefine the pre-computable resource as a cryptographic primitive known as Correlated Oblivious Permutation (COP) and conduct in-depth analyses and optimizations of the two COP generation solutions: network-based solution and matrix-based solution. The optimizations for the network-based solution halve the communication/computation cost of constructing a switch (the basic unit of the permutation network) and reduce the number of switches in the permutation network. The optimizations for the matrix-based solution halve the communication cost of small-size COP generation and reduce the cost of large-size COP generation with in-outside permutation decomposition.

We implement our two COP generation protocols and conduct comprehensive evaluations. Taking commonly used 128-bit input data as an example, our network-based and matrix-based solutions are up to 1.7x and 1.6x faster than baseline protocols, respectively. 
 We further facilitate the state-of-the-art (SOTA) PSU protocols with our optimized COP, achieving over 25% reduction in communication cost and 35% decrease in execution time. This shows that our COP optimizations bring significant improvements for real-world MPC primitives.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 09:25:29 +0000</pubDate>
</item>
<item>
<title>Ciphertext-Ciphertext Matrix Multiplication: Fast for Large Matrices</title>
<link>https://eprint.iacr.org/2025/448</link>
<guid>https://eprint.iacr.org/2025/448</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护机器学习、加密矩阵乘法、大规模、快速算法、密钥大小优化

总结:
为了解决隐私保护机器学习中大型加密矩阵乘法（CC-MM）的关键挑战，本文提出了一种新的算法。该算法结合了明文矩阵乘法（PP-MM）和加密矩阵转置算法（C-MT），其中我们设计了一个计算成本较低的快速C-MT算法。通过利用高性能BLAS库优化PP-MM，实现了大规模CC-MM并显著提升了性能。此外，我们还提出了轻量级算法，将CC-MM所需的密钥大小从1960 MB降低到1.57 MB，同时保持了相当的效率。

实验结果显示，对于单线程实现，C-MT算法能在$0.76$秒内完成对一个$2\ 048 \times 2\ 048$的加密矩阵进行转置；而我们的CC-MM算法可在$85.2$秒内完成两个$4\ 096 \times 4\ 096$加密矩阵的乘法操作。相较于Jiang-Kim-Lauter-Song在CCS'18会议上提出的最先进的CC-MM方法，我们的算法在处理大规模矩阵时表现出超过$800$倍的性能提升。 <div>
Matrix multiplication of two encrypted matrices (CC-MM) is a key challenge for privacy-preserving machine learning applications. As modern machine learning models focus on scalability, fast CC-MM on large datasets is increasingly in demand.

In this work, we present a CC-MM algorithm for large matrices. The algorithm consists of plaintext matrix multiplications (PP-MM) and ciphertext matrix transpose algorithms (C-MT). We propose a fast C-MT algorithm, which is computationally inexpensive compared to PP-MM. By leveraging high-performance BLAS libraries to optimize PP-MM, we implement large-scale CC-MM with substantial performance improvements. Furthermore, we propose lightweight algorithms, significantly reducing the key size from $1\ 960$ MB to $1.57$ MB for CC-MM with comparable efficiency.

In a single-thread implementation, the C-MT algorithm takes $0.76$ seconds to transpose a $2\ 048\times 2\ 048$ encrypted matrix. The CC-MM algorithm requires $85.2$ seconds to multiply two $4\ 096\times 4\ 096$ encrypted matrices. For large matrices, our algorithm outperforms the state-of-the-art CC-MM method from Jiang-Kim-Lauter-Song [CCS'18] by a factor of over $800$.
]]></content:encoded>
<pubDate>Mon, 10 Mar 2025 07:30:23 +0000</pubDate>
</item>
<item>
<title>Disincentivize Collusion in Verifiable Secret Sharing</title>
<link>https://eprint.iacr.org/2025/446</link>
<guid>https://eprint.iacr.org/2025/446</guid>
<content:encoded><![CDATA[
<div> 关键词: 可验证秘密共享(VSS), 隐私针对性合谋, 冗余机制, 跟踪可访问结构(TAS), 斯蒂尼系统

总结:

本文研究了在可验证秘密共享(VSS)场景中，如何设计和分析阻止持有份额的理性与恶意党派进行隐私针对性合谋的机制。首先，文章提出了两种防止合谋的冗余机制，特别是在希望实现公平性（即非合谋者不受损失）的同时，允许在最佳恶意故障容忍度下恢复秘密的情况下，定义并设计了适用于TAS的专用威慑机制。其次，文中估算了最优TAS的大小，利用斯蒂尼系统构造了它们，并使用部分斯蒂尼系统构建了高度鲁棒的TAS，还为各种参数范围提供了接近最优TAS的高效秘密分享方案。最后，作者展示了TAS中的可追踪性与离散数学中的组合对象如（部分）斯蒂尼系统、受限交集的均匀子集以及适当的二进制码之间的联系，并指出访问结构的鲁棒性等价于超图的最小顶点覆盖问题。文章认为这些密码学、博弈论和离散数学之间的连接具有更广泛的研究价值。 <div>
In verifiable secret sharing (VSS), a dealer shares a secret input among several parties, ensuring each share is verifiable. Motivated by its applications in the blockchain space, we focus on a VSS where parties holding shares are not allowed to reconstruct the dealer's secret (even partially) on their own terms, which we address as privacy-targeted collusion if attempted. 

    In this context, our work investigates mechanisms deterring such collusion in VSS among rational and malicious parties. For this problem, we make both algorithmic and combinatorial contributions:
    1. We provide two collusion-deterrent mechanisms to discourage parties from colluding and recovering the dealer's secret. Notably, when it is desired to achieve fairness---where non-colluding parties are not at a loss---while allowing for the best achievable malicious fault tolerance, we define ``trackable access structures'' (TAS) and design a deterrence mechanism tailored for VSS on these structures. 
    2. We estimate the size of the optimal TAS, construct them from Steiner systems, provide highly robust TAS using partial Steiner systems, and present efficient secret sharing schemes for the latter close-to-optimal TAS for various parameter regimes.
    3. We demonstrate that trackability in access structures is connected to combinatorial objects like (partial) Steiner systems, uniform subsets with restricted intersections, and appropriate binary codes. The robustness of access structures is equivalent to the minimum vertex cover of hypergraphs. 

    We believe these connections between cryptography, game theory, and discrete mathematics will be of broader interest.
]]></content:encoded>
<pubDate>Sun, 09 Mar 2025 00:20:38 +0000</pubDate>
</item>
<item>
<title>Homomorphic Signature-based Witness Encryption and Applications</title>
<link>https://eprint.iacr.org/2025/443</link>
<guid>https://eprint.iacr.org/2025/443</guid>
<content:encoded><![CDATA[
<div> 关键词: 实际应用、签名基础见证加密（SWE）、未来加密、同态SWE（HSWE）、隐私保护

总结:
本文提出了同态签名基础见证加密（HSWE）的概念，以提升定时释放加密方案的实用性。HSWE能够在保持时间释放功能的同时，提高效率并促进部署。文章指出构建HSWE需要依赖于一对加密和签名方案，其中签名的独特性是在加密方案基于单向注入函数时所必需的。接着，文中利用BLS、RSA和Rabin签名技术构建了三种不同的HSWE方案，并展示如何实现一种隐私保护的变体，该变体只允许提取同态聚合的结果，同时保持各个明文的机密性。 <div>
Practical signature-based witness encryption (SWE) schemes recently emerged as a viable alternative to instantiate timed-release cryptography in the honest majority setting. In particular, assuming threshold trust in a set of parties that release signatures at a specified time, one can ``encrypt to the future'' using an SWE scheme. Applications of SWE schemes include voting, auctions, distributed randomness beacons, and more. However, the lack of homomorphism in existing SWE schemes reduces efficiency and hinders deployment. In this work, we introduce the notion of homomorphic SWE (HSWE) to improve the practicality of timed-release encryption schemes. We show one can build HSWE using a pair of encryption and signature schemes where the uniqueness of the signature is required when the encryption scheme relies on injective one-way functions. We then build three HSWE schemes in various settings using BLS, RSA, and Rabin signatures and show how to achieve a privacy-preserving variant that only allows extracting the homomorphically aggregated result while keeping the individual plaintexts confidential
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 17:27:02 +0000</pubDate>
</item>
<item>
<title>A Unified Framework for Succinct Garbling from Homomorphic Secret Sharing</title>
<link>https://eprint.iacr.org/2025/442</link>
<guid>https://eprint.iacr.org/2025/442</guid>
<content:encoded><![CDATA[
<div> 关键词: 密码学、简洁加密方案、Yao's 加密电路构造、同态秘密分享、布尔电路

总结:
本文提出了一种新的简洁加密方案框架，该框架利用轻量级的同态秘密分享技术替代了以往大多数构造中的繁重机制。具体来说，该框架在复合阶或素数阶群以及基于晶格的基础上，实现了布尔电路每门电路只需1比特的（平均）加密大小。同时，这一思想被扩展到分层电路和算术电路中，将每门电路的成本降低至1比特以下，并消除了模p计算通常具有的Ω(λ)-因子开销。这些构建还包括了消除对循环安全要求的“分级”变体，但会在加密大小上增加与深度相关的项。

本研究显著拓展了Liu等人（Eurocrypt 2025）关于基于晶格的简洁加密方案的技术，并为实现实用化的简洁加密开辟了新途径。对于拥有几百万门电路的中等规模电路，我们的加密电路可以比Yao风格的加密电路小两个数量级。虽然我们的加密和解密算法速度较慢，但仍具备实际可行性，这与依赖昂贵工具如iO或FHE和ABE非黑盒组合的先前完全简洁加密方案不同。这种权衡使得当加密电路作为功能密文被广播或存储在多个位置（例如区块链上）时，我们的框架可能会更具吸引力，因为在这种情况下，通信和存储成本可能主导总体开销。 <div>
A major challenge in cryptography is the construction of succinct garbling schemes that have asymptotically smaller size than Yao’s garbled circuit construction. We present a new framework for succinct garbling that replaces the heavy machinery of most previous constructions by lighter-weight homomorphic secret sharing techniques.

Concretely, we achieve 1-bit-per-gate (amortized) garbling size for Boolean circuits under circular variants of standard assumptions in composite-order or prime-order groups, as well as a lattice-based instantiation. We further extend these ideas to layered circuits, improving the per-gate cost below 1 bit, and to arithmetic circuits, eliminating the typical Ω(λ)-factor overhead for garbling mod-p computations. Our constructions also feature “leveled” variants that remove circular-security requirements at the cost of adding a depth-dependent term to the garbling size.

Our framework significantly extends a recent technique of Liu, Wang, Yang, and Yu (Eurocrypt 2025) for lattice-based succinct garbling, and opens new avenues toward practical succinct garbling. For moderately large circuits with a few million gates, our garbled circuits can be two orders of magnitude smaller than Yao-style garbling. While our garbling and evaluation algorithms are much slower, they are still practically feasible, unlike previous fully succinct garbling schemes that rely on expensive tools such as iO or a non-black-box combination of FHE and ABE. This trade-off
can make our framework appealing when a garbled circuit is used as a functional ciphertext that is broadcast or stored in multiple locations (e.g., on a blockchain), in which case communication and storage may dominate computational cost.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 17:14:00 +0000</pubDate>
</item>
<item>
<title>Transmitting Secrets by Transmitting only Plaintext</title>
<link>https://eprint.iacr.org/2025/438</link>
<guid>https://eprint.iacr.org/2025/438</guid>
<content:encoded><![CDATA[
<div> 关键词：加密、标记字母、密钥、隐藏信息、网络安全

总结：
该文提出了一种新的加密使用方式，不是用于隐藏秘密，而是用于标记字母。发送者将2n个字母的明文分为两部分，分别用密钥K1和K2加密得到n个对应的密文字母。尽管发送者同时提供了两个密钥，使得接收者可以轻易解密回原始明文，但其实这个过程暗含了一个秘密消息S，它由n位组成。通过记录经K1和K2加密后的字母混合顺序（共有2^n种可能），可以在看似平常的信息传输中隐藏秘密消息。这种技术可在文本消息平台上应用，使得网络空间中的用户能够在不暴露正在传递秘密信息的情况下进行秘密通信，从而大大提高网络安全性和隐私保护水平。 <div>
Presenting a novel use of encryption, not for hiding a secret, but for marking letters.  Given a 2n letters plaintext, the transmitter encrypts the first n letters with  key K1 to generate corresponding n cipherletters, and encrypts the second n letters with key K2 to generate n corresponding cipherletters. The transmitter sends the 2n cipherletters along with the keys, K1 and K2  The recipient (and any interceptor) will readily decrypt the 2n cipherletters to the original plaintext.  This makes the above procedure equivalent to sending out the plaintext.  So why bother?  When decrypting the 2n cipherletters one will make a note of how the letters that were encrypted with K1 are mixed with the letters encrypted with K2 while keeping the original order of the letters encrypted with each key. There are 2^n possible mixings. Which means that the choice of mixing order can deliver a secret message, S,  comprising n bits. So while on the surface a given plaintext is sent out from transmitter to recipient, this plaintext hides a secret.  Imagine a text messaging platform that uses this protocol. An adversary will not know which plain innocent message harbors a secret message.  This allows residents of cyberspace to communicate secrets without exposing the fact that they communicated a secret. Expect a big impact on the level of cyberspace privacy.
]]></content:encoded>
<pubDate>Fri, 07 Mar 2025 03:08:44 +0000</pubDate>
</item>
<item>
<title>The 2Hash OPRF Framework and Efficient Post-Quantum Instantiations</title>
<link>https://eprint.iacr.org/2024/450</link>
<guid>https://eprint.iacr.org/2024/450</guid>
<content:encoded><![CDATA[
<div> 关键词：Oblivious Pseudo-Random Function (OPRF)，量子安全，多党计算，Legendre符号，AES加密

总结:<br />
本文提出了一种基于后量子多党计算构建Oblivious Pseudo-Random Function (OPRF)的框架。该框架关注一类被称为“2Hash PRFs”的构造，它们将函数评估置于两个哈希操作之间。核心是一个编译器，能从任何具有抗键碰撞和一更多不可预测性的函数生成OPRF。文章通过使用Legendre符号和AES加密提供了满足要求的此类函数实例，并设计了一个针对Legendre基函数的安全评估协议，该协议结合了盲转移(OT)和零知识证明(ZKP)。当使用基于晶格的OT和ZKPs实现时，文中提出的量子安全OPRF能在0.57秒内完成，通信量少于1MB。 <div>
An Oblivious Pseudo-Random Function (OPRF) is a two-party protocol for jointly evaluating a Pseudo-Random Function (PRF), where a user has an input x and a server has an input k. At the end of the protocol, the user learns the evaluation of the PRF using key k at the value x, while the server learns nothing about the user's input or output. 

OPRFs are a prime tool for building secure authentication and key exchange from passwords, private set intersection, private information retrieval, and many other privacy-preserving systems. While classical OPRFs run as fast as a TLS Handshake, current *quantum-safe* OPRF candidates are still practically inefficient. 

In this paper, we propose a framework for constructing OPRFs from post-quantum multi-party computation. The framework captures a family of so-called "2Hash PRFs", which sandwich a function evaluation in between two hashes. The core of our framework is a compiler that yields an OPRF from a secure evaluation of any function that is key-collision resistant and one-more unpredictable. We instantiate this compiler by providing such functions built from Legendre symbols, and from AES encryption. We then give a case-tailored protocol for securely evaluating our Legendre-based function, built from oblivious transfer (OT) and zero-knowledge proofs (ZKP). Instantiated with lattice-based OT and ZKPs, we obtain a quantum-safe OPRF that completes in 0.57 seconds, with less than 1MB of communication.
]]></content:encoded>
<pubDate>Fri, 15 Mar 2024 15:52:21 +0000</pubDate>
</item>
<item>
<title>Matchmaker: Fast Secure Inference across Deployment Scenarios</title>
<link>https://eprint.iacr.org/2025/424</link>
<guid>https://eprint.iacr.org/2025/424</guid>
<content:encoded><![CDATA[
<div> 关键词: Secure Two-Party Computation (2PC), 性能优化, 密钥延迟, 网络速度, Linear Secret Sharing (LSS), Function Secret Sharing (FSS), $LSS^M$, $FSS^M$, CPU, GPU, 异构处理

总结:
本文关注于提升基于Secure Two-Party Computation (2PC) 的安全推理性能，同时考虑了部署场景中的关键因素，如密钥从存储中获取的延迟和网络速度。为了解决这些问题，研究者设计了针对小密钥尺寸优化的LSS-based系统$LSS^M$以及针对通信效率优化的FSS-based系统$FSS^M$。特别地，他们实现了一个高度优化、硬件感知的CPU-based $LSS^M$系统，其性能相比之前的GPU-based LSS系统提高了高达50倍。进一步的研究发现，在特定部署条件下，可以结合使用$LSS^M$与$FSS^M$来利用CPU和GPU之间的异构处理能力。这种协议-系统协同设计方法使得新方案相比于现有最先进的安全推理系统性能提升了最高达21倍（平均提升3.25倍）。 <div>
Secure Two-Party Computation (2PC) enables secure inference with cryptographic guarantees that protect the privacy of the model owner and client. However, it adds significant performance overhead. In this work, we make 2PC-based secure inference efficient while considering important deployment scenarios.   
We observe that the hitherto unconsidered latency of fetching keys from storage significantly impacts performance, as does network speed. We design a Linear Secret Sharing (LSS)-based system $LSS^M$ and a Function Secret Sharing (FSS)-based system $FSS^M$ for secure inference, optimized for small key size and communication, respectively. Notably, our highly-optimized and hardware-aware CPU-based $LSS^M$ outperforms prior GPU-based LSS systems by up to $50\times$. We then show that the best choice between $LSS^M$ and $FSS^M$ depends on the deployment scenario.
In fact, under certain deployments, a combination of $LSS^M$ and $FSS^M$ can leverage heterogeneous processing across CPU and GPU. Such protocol-system co-design lets us outperform state-of-the-art secure inference systems 
by up to $21\times$ (geomean $3.25\times$).
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 11:45:54 +0000</pubDate>
</item>
<item>
<title>Multi-Client Attribute-Based Unbounded Inner Product Functional Encryption, and More</title>
<link>https://eprint.iacr.org/2025/423</link>
<guid>https://eprint.iacr.org/2025/423</guid>
<content:encoded><![CDATA[
<div> 关键词: 多客户端功能加密 (MC-FE)，属性基内积函数 (AB-IP)，无界设置，标准模型，单输入AB-UIPFE

总结:
本文提出了一种针对属性基内积函数的无界多客户端功能加密（MC-AB-UIPFE）方案，该方案在无界设置中不再受向量长度约束，允许秘密密钥支持任意长度的函数，同时客户端可在加密过程中动态选择向量长度。文章基于矩阵决策性Diffie-Hellman假设，在自然许可的无界环境下构建了如下构造：

1. 首个在标准模型下安全的无界单输入AB-UIPFE方案，解决了之前只能加密固定长度数据的问题；
2. 基于相同假设下的首个公共密钥环境中的多输入AB-UIPFE（MI-AB-UIPFE），改进了先前有界的构造；
3. 首个动态分散式无界内积功能加密（DD-UIPFE），提升了前作的动态性属性。

技术上，本文沿袭Agrawal等人[CRYPTO'23]的研究蓝图，但首先提出了一个新的无界FE——扩展槽位无界内积FE。我们首先在标准模型下构建了一个单输入AB-UIPFE，然后将其扩展到多输入场景。总的来说，本文工作展示了内积功能隐藏安全性在实现能够编码无界长度向量（无论是在密钥生成还是加密阶段）的各种多输入FE变体中的应用价值。 <div>
This paper presents the concept of a multi-client functional encryption (MC-FE) scheme for attribute-based inner product functions (AB-IP), initially proposed by Abdalla et al. [ASIACRYPT’20], in an unbounded setting. In such a setting, the setup is independent of vector length constraints, allowing secret keys to support functions of arbitrary lengths, and clients can dynamically choose vector lengths during encryption. The functionality outputs the sum of inner products if vector lengths and indices meet a specific relation, and all clients’ attributes satisfy the key’s policy. We propose the following constructions based on the matrix decisional Diffie-Hellman assumption in a natural permissive setting
of unboundedness:

– the first multi-client attribute-based unbounded IPFE (MC-AB-UIPFE) scheme secure in the standard model, overcoming previous limitations where clients could only encrypt fixed-length data;
– the first multi-input AB-UIPFE (MI-AB-UIPFE) in the public key setting; improving upon prior bounded constructions under the same assumption;
– the first dynamic decentralized UIPFE (DD-UIPFE); enhancing the dynamism property of prior works.

Technically, we follow the blueprint of Agrawal et al. [CRYPTO’23] but begin with a new unbounded FE called extended slotted unbounded IPFE. We first construct a single-input AB-UIPFE in the standard model and then extend it to multi-input settings. In a nutshell, our work demonstrates the applicability of function-hiding security of IPFE in realizing variants of multi-input FE capable of encoding unbounded
length vectors both at the time of key generation and encryption.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 10:45:09 +0000</pubDate>
</item>
<item>
<title>Private Computation on Common Fuzzy Records</title>
<link>https://eprint.iacr.org/2025/422</link>
<guid>https://eprint.iacr.org/2025/422</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人计算、共同记录、模糊记录、有序阈值匹配、电路基私人集合交集协议

总结:
本文研究了如何在基于模糊记录的准标识符上实现私有计算的问题。为了解决这个问题，文章提出了有序阈值一对一(OTO)匹配方法，该方法可以利用电路基私人集合交集(CPSI)协议和多方计算(MPC)技术进行有效实现。此外，文中还引入了一些将传统匹配规则转换为OTO匹配的通用编码技术。最终，作者设计了一个安全高效的私有计算协议，支持多种已广泛应用的匹配规则。

实验验证了该提案的优越性：首先，实证检验表明，对于模糊记录匹配文献中的基准数据集，使用该编码到OTO匹配并不会对准确性造成显著影响；其次，实现了该协议并取得了显著的速度提升，尽管通信开销增加，但与先前的隐私保护记录链接(PPRL)协议相比，在处理每个数据集拥有10万条记录的情况下，通信成本为147.58MB，设置时间为10.71秒，在线时间为1.97秒，整体运行速度提高了约7.78倍（仅考虑在线时间则提升了50.12倍）。 <div>
Private computation on common records refers to analyze data from two databases containing shared records without revealing personal information. As a basic requirement for private computation, the databases involved essentially need to be aligned by a common identification system. However, it is hard to expect such common identifiers in real world scenario. For this reason, multiple quasi-identifiers can be used to identify common records. As some quasi-identifiers might be missing or have typos, it is important to support fuzzy records setting. Identifying common records using quasi-identifiers requires manipulation of highly sensitive information, which could be privacy concerns.

This work studies the problem of enabling such data analysis on the fuzzy records of quasi-identifiers. To this end, we propose ordered threshold-one (OTO) matching which can be efficiently realized by circuit-based private set intersection (CPSI) protocols and some multiparty computation (MPC) techniques. Furthermore, we introduce some generic encoding techniques from traditional matching rules to the OTO matching. Finally, we achieve a secure efficient private computation protocol which supports various matching rules which have already been widely used.

We also demonstrate the superiority of our proposal with experimental validation. First, we empirically check that our encoding to OTO matching does not affect accuracy a lot for the benchmark datasets found in the fuzzy record matching literature. Second, we implement our protocol and achieve significantly faster performance at the cost of communication overhead compared to previous privacy-preserving record linkage (PPRL) protocols. In the case of 100K records for each dataset, our work shows 147.58MB communication cost, 10.71s setup time, and 1.97s online time, which is 7.78 times faster compared to the previous work (50.12 times faster when considering online time only).
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 09:07:21 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Verifiable Aggregation</title>
<link>https://eprint.iacr.org/2025/420</link>
<guid>https://eprint.iacr.org/2025/420</guid>
<content:encoded><![CDATA[
<div> 关键词：Non-Interactive Verifiable Aggregation (NIVA)，Privacy，Robustness，PEAR，Functional Encryption，Fully-Linear Probabilistically-Checkable Proofs，Performance Evaluation

总结:<br />
本文提出了一个新的隐私保护和鲁棒性兼备的非交互式可验证聚合（NIVA）协议——PEAR。该协议旨在让弱分析师能外包大规模客户端数据收集与聚合统计工作给强大的服务器，同时保证客户端数据对服务器和分析师的隐私性，并防止恶意客户端篡改结果。PEAR基于功能加密（inner-product FE）和全线性概率检查证明（fully-linear probabilistically-checkable proofs）的创新结合，允许针对任意NP有效性规则进行输入验证。协议具有非交互、公钥以及黑盒使用底层密码学原语的特点，并为实际相关有效性规则实现了大量优化。文中还实现了PEAR并进行了详尽性能评估，对比两种更直接或“现成”的NIVA协议展现了性能优势，证实了新方法的优势。然而，当前协议的瓶颈在于需要基于大型域上的“无限制”IPFE方案，随着未来此类方案效率的提升，可以直接应用到PEAR中以进一步提高性能。 <div>
Consider a weak analyst that wishes to outsource data collection and computation of aggregate statistics over a a potentially large population of (also weak) clients to a powerful server. For flexibility and efficiency, we consider public-key and non-interactive protocols, meaning the clients know the analyst's public key but do not share secrets, and each client sends at most one message. Furthermore, the final step should be silent, whereby the analyst simply downloads the (encrypted) result from the server when needed. To capture this setting, we define a new primitive  we call Non-Interactive Verifiable Aggregation (NIVA). 
We require both privacy and robustness for a NIVA protocol to be deemed secure. Namely, our security notion for NIVA ensures that the clients' data remains private to both the server and the analyst, while also ensuring that  malicious clients cannot skew the results by providing faulty data.
We propose a secure NIVA protocol, which we call PEAR (for Private, Efficient, Accurate, Robust), which can validate inputs according to any NP validity rule.  PEAR is based on a novel combination of functional encryption for inner-products (Abdalla et al., PKC 2015) and fully-linear probabilistically-checkable proofs (Boneh et al., Crypto 2019). We emphasize that PEAR is non-interactive, public-key, and  makes black-box use of the underlying cryptographic primitives. Additionally, we devise substantial  optimizations of PEAR for practically-relevant validity rules. Finally, we implement PEAR to show feasibility for such validity rules,  conducting a thorough performance evaluation. In particular, we compare PEAR to two more straightforward or "off-the-shelf" NIVA protocols and show performance gains, demonstrating the merit of our new approach. The bottleneck in our protocol comes from the fact that we require the underlying IPFE scheme to be "unrestricted" over a large field. As more efficient such schemes are developed, they can be immediately be plugged into PEAR for further gains.
]]></content:encoded>
<pubDate>Wed, 05 Mar 2025 04:03:31 +0000</pubDate>
</item>
<item>
<title>Evaluation of Privacy-aware Support Vector Machine (SVM) Learning using Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/417</link>
<guid>https://eprint.iacr.org/2025/417</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私意识机器学习、全同态加密(FHE)、PII、支持向量机(SVM)、OpenFHE库

总结:
这篇论文探讨了使用全同态加密(FHE)解决隐私问题的方法，特别是在涉及PII数据的机器学习训练中的应用。文章中，研究者利用OpenFHE库对SVM机器学习模型进行了加密处理，通过Python和scikit-learn库进行实现。实验考察了一系列变量的影响，包括乘法深度、规模大小、第一模数大小、安全性级别、批处理大小和环维数，同时对比了两种不同的SVM模型：多项式SVM（SVM-Poly）和线性SVM（SVM-Linear）。结果显示，影响性能的主要参数为环维数和模数大小，而SVM-Poly与SVM-Linear在性能表现上相当。 <div>
The requirement for privacy-aware machine learning increases as we continue to use PII (Personally Identifiable Information) within machine training. To overcome these privacy issues, we can apply Fully Homomorphic Encryption (FHE) to encrypt data before it is fed into a machine learning model. This involves creating a homomorphic encryption key pair, and where the associated public key will be used to encrypt the input data, and the private key will decrypt the output. But, there is often a performance hit when we use homomorphic encryption, and so this paper evaluates the performance overhead of using the SVM machine learning technique with the OpenFHE homomorphic encryption library. This uses Python and the scikit-learn library for its implementation.  The experiments include a range of variables such as multiplication depth, scale size, first modulus size, security level, batch size, and ring dimension, along with two different SVM models, SVM-Poly and SVM-Linear. Overall, the results show that the two main parameters which affect performance are the ring dimension and the modulus size, and that SVM-Poly and SVM-Linear show similar performance levels.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 20:01:14 +0000</pubDate>
</item>
<item>
<title>Garblet: Multi-party Computation for Protecting Chiplet-based Systems</title>
<link>https://eprint.iacr.org/2025/413</link>
<guid>https://eprint.iacr.org/2025/413</guid>
<content:encoded><![CDATA[
<div> 关键词：芯片模块化、安全威胁、Garblet、Garbled Circuits（GC）、Oblivious Transfer（OT）

<br /><br />总结：

本文提出了一个名为Garblet的新框架，用于应对由异构芯片模块化架构引入的安全威胁。该框架利用芯片模块技术与基于Garbled Circuits（GC）的多方计算，确保在潜在恶意芯片let环境中也能实现高效、安全的计算。Garblet将定制化的硬件Oblivious Transfer（OT）模块和优化的评估器引擎集成到基于芯片模块的平台上，通过在两个芯片模块之间分配电路的加扰和评估任务，降低通信成本并提升计算速度。文章在AMD/Xilinx UltraScale+多芯片模块上实现了这一框架，并通过基准函数展示了其实效性。此外，文中还介绍了一种新的电路分解技术，允许在多个芯片模块间进行并行处理，从而进一步提高计算效率。实验结果显示，芯片模块系统有望加速GC计算，例如加扰AES的时间复杂度可降至0.0226毫秒，有效保障了芯片模块计算的安全性和隐私性。 <div>
The introduction of shared computation architectures assembled from
heterogeneous chiplets introduces new security threats. Due to the shared logical and physical resources, an untrusted chiplet can act maliciously to surreptitiously probe the data communication between chiplets or sense the computation shared between them. This paper presents Garblet, the first framework to leverage the flexibility offered by chiplet technology and Garbled Circuits (GC)-based MPC to enable efficient, secure computation even in the presence of potentially compromised chiplets. Our approach integrates a customized hardware Oblivious Transfer (OT) module and an optimized evaluator engine into chiplet-based platforms. This configuration distributes the tasks of garbling and evaluating circuits across two chiplets, reducing communication costs and enhancing computation speed. We implement this framework on an AMD/Xilinx UltraScale+ multi-chip module and demonstrate its effectiveness using benchmark functions. Additionally, we introduce a novel circuit decomposition technique that allows for parallel processing across multiple chiplets to further improve computational efficiency. Our results highlight the potential of chiplet systems for accelerating GC (e.g., the time complexity of garbled AES is 0.0226ms) in order to guarantee the security and privacy of the computation on chiplets.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 16:32:54 +0000</pubDate>
</item>
<item>
<title>Multi-Authority Functional Encryption: Corrupt Authorities, Dynamic Collusion, Lower Bounds, and More</title>
<link>https://eprint.iacr.org/2025/412</link>
<guid>https://eprint.iacr.org/2025/412</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化、多权威功能性加密（MAFE）、区块链、安全多方计算、公钥加密（PKE）

总结：

本文研究了多权威功能性加密（MAFE）问题，这是一种分布式加密系统的流行形式。文章主要贡献如下：<br />
1. 设计了一种适用于所有多项式大小电路的MAFE方案，基于PKE和OWFs的最小假设，改进了先前需要次指数级安全的混淆、$\log n$-党派密钥交换或随机预言机与次指数级安全PKE的需求。此外，在IBE和OWFs的最小假设下，我们还将其扩展到动态共谋模型，并且该系统真正动态，不限制最大权限数量。<br />
2. 在学习带有错误（LWE）假设下，设计了一个允许对手自适应腐败局部权限的MAFE方案，其中敌手可以腐蚀任意$k$个($k$小于等于$n$，且${n}\choose{k}$为多项式阶的$\lambda$)局部权限。这比先前依赖次指数级安全混淆的方案有所改进，并提出了一个新的MAFE编译器，用于将选择性权限腐败提升为非自适应权限腐败。<br />
3. 证明了MAFE与(变种模糊/不可区分性)混淆之间的紧密蕴含关系，表明只有当所有被腐败的局部权限共同控制的属性位数大于$\omega(\log \lambda)$时，MAFE才意味着混淆。这证明了对于广泛参数范围内的第二个结果的最优性。<br />
4. 提出了一种新的MAFE系统，称为多权威属性基功能加密（MA-ABFE），旨在融合完全共谋抵抗的MA-ABE和有限共谋抵抗的MAFE的优势。结合现有MA-ABE结果，从标准双线性配对假设出发，获得了适用于$\mathsf{NC}^1 \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE；从LWE假设出发，在随机预言机模型中获得了适用于$\mathsf{DNF} \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE；并描述了一个基于见证加密的简单MA-ABE构造，以及通过已知结果，得到了适用于$\mathsf{P}/\mathsf{Poly} \circ \mathsf{P}/\mathsf{Poly}$的MA-ABFE，这是从逃避型LWE假设得出的。 <div>
Decentralization is a great enabler for adoption of modern cryptography in real-world systems. Widespread adoption of blockchains and secure multi-party computation protocols are perfect evidentiary examples for dramatic rise in deployment of decentralized cryptographic systems. Much of cryptographic research can be viewed as reducing (or eliminating) the dependence on trusted parties, while shielding from stronger adversarial threats. In this work, we study the problem of multi-authority functional encryption (MAFE), a popular decentralized generalization of functional encryption (FE). Our main contributions are:

    1. We design MAFE for all poly-sized circuits, in the bounded collusion model, under the minimal assumption of PKE/OWFs. Prior to our work, this required either sub-exponentially secure obfuscation, or $\log n$-party key exchange, or Random Oracles and sub-exponentially secure PKE. We also extend our constructions to the dynamic collusion model under the minimal assumptions of IBE/OWFs. Unlike all prior works, our MAFE systems are truly dynamic and put no restrictions on the maximum number of authorities.

    2. Under the hardness of learning with errors (LWE) assumption, we design MAFE for all poly-sized circuits where we allow adversaries to adaptively corrupt local authorities. We allow an adversary to corrupt any $k$ out of $n$ local authorities as long as ${{n}\choose{k}}$ = poly$(\lambda)$. Prior to this, such MAFE relied on sub-exponentially secure obfuscation. Additionally, we design a new MAFE compiler for boosting selective authority corruptions to non-adaptive authority corruptions.

    3. We prove a tight implication from MAFE to (VBB/indistinguishability) obfuscation. We show that MAFE implies obfuscation only if the number of attribute bits (jointly) controlled by all corrupt local authorities is $\omega(\log \lambda)$. This proves optimality of our second result for a wide range of parameters.

    4. Finally, we propose a new MAFE system that we refer to as multi-authority attribute-based functional encryption (MA-ABFE). We view it as an approach to get best of both worlds (fully collusion resistant MA-ABE, and bounded collusion resistant MAFE). By combining our results with prior MA-ABE results, we obtain MA-ABFE for $\mathsf{NC}^1 \circ \mathsf{P}/\mathsf{Poly}$ from standard pairing-based assumptions, and for $\mathsf{DNF} \circ \mathsf{P}/\mathsf{Poly}$ from LWE, both in the Random Oracle Model. We also describe a simple construction of MA-ABE for general predicates from witness encryption, and combining with known results, we also get MA-ABFE for $\mathsf{P}/\mathsf{Poly} \circ \mathsf{P}/\mathsf{Poly}$ from evasive LWE.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 14:22:01 +0000</pubDate>
</item>
<item>
<title>Hybrid Obfuscated Key Exchange and KEMs</title>
<link>https://eprint.iacr.org/2025/408</link>
<guid>https://eprint.iacr.org/2025/408</guid>
<content:encoded><![CDATA[
<div> 关键词：元数据隐藏、互联网协议、加密协议、后量子安全、OKEMs<br /><br />总结:

本文关注于互联网协议中元数据隐藏的重要性，以及在后量子时代实现完全加密协议的安全性。现有的如Tor的pluggable transport协议obfs4依赖于Diffie-Hellman和Elligator编码进行密钥交换的模糊处理。然而，目前还没有提供混合模糊保障的OKEM（模糊密钥封装机制）用于实际过渡协议。文章提出了首个同时具备混合IND-CCA安全性和混合模糊保证的OKEM组合器，并基于此构建了Drivel协议，使其与混合OKEM兼容。此外，文章还介绍了如何实现LWE基OKEM的无条件公钥模糊化，并探讨了包括构建第一个在UC模型下抗适应性破坏的混合密码验证密钥交换（PAKE）协议在内的混合OKEM更广泛的应用。 <div>
Hiding the metadata in Internet protocols serves to protect user privacy, dissuade traffic analysis, and prevent network ossification. Fully encrypted protocols require even the initial key exchange to be obfuscated: a passive observer should be unable to distinguish a protocol execution from an exchange of random bitstrings. Deployed obfuscated key exchanges such as Tor's pluggable transport protocol obfs4 are Diffie–Hellman-based, and rely on the Elligator encoding for obfuscation. Recently, Günther, Stebila, and Veitch (CCS '24) proposed a post-quantum variant pq-obfs, using a novel building block called obfuscated key encapsulation mechanisms (OKEMs): KEMs whose public keys and ciphertexts look like random bitstrings.

For transitioning real-world protocols, pure post-quantum security is not enough. Many are taking a hybrid approach, combining traditional and post-quantum schemes to hedge against security failures in either component. While hybrid KEMs are already widely deployed (e.g., in TLS 1.3), existing hybridization techniques fail to provide hybrid obfuscation guarantees for OKEMs. Further, even if a hybrid OKEM existed, the pq-obfs protocol would still not achieve hybrid obfuscation.

In this work, we address these challenges by presenting the first OKEM combiner that achieves hybrid IND-CCA security with hybrid ciphertext obfuscation guarantees, and using this to build Drivel, a modification of pq-obfs that is compatible with hybrid OKEMs. Our OKEM combiner allows for a variety of practical instantiations, e.g., combining obfuscated versions of DHKEM and ML-KEM. We additionally provide techniques to achieve unconditional public key obfuscation for LWE-based OKEMs, and explore broader applications of hybrid OKEMs, including a construction of the first hybrid password-authenticated key exchange (PAKE) protocol secure against adaptive corruptions in the UC model.
]]></content:encoded>
<pubDate>Tue, 04 Mar 2025 00:52:26 +0000</pubDate>
</item>
<item>
<title>Provably Secure Approximate Computation Protocols from CKKS</title>
<link>https://eprint.iacr.org/2025/395</link>
<guid>https://eprint.iacr.org/2025/395</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全多方计算、同态加密、CKKS方案、噪音模糊技术、分布式采样

总结:
本文研究了基于CKKS方案的安全近似多方计算问题。首先分析了在两方设置中，CKKS基础协议的应用情况：当仅一方持有私人输入而另一方作为评估者时，通过在加密方使用噪音模糊技术可实现标准意义上的安全性。当双方都具有私人输入时，现有协议只能满足宽松的“自由安全”定义，为此，文章提出了一种新的协议，利用分布式采样方法在安全环境下生成模糊噪音，从而满足标准安全性定义。进一步地，将两方协议扩展到多方面设置，由于现有的基于阈值的CKKS多方计算协议仅能满足“自由安全”，文中提出一种新颖的多方面协议，通过应用多方分布式采样生成模糊误差来实现标准安全性。对于所有提出的协议，作者均形式化定义了其功能并在基于模拟的安全框架下进行了严谨的安全性分析。据作者所知，这是首次对基于CKKS的近似多方计算功能进行明确定义并实现正式的安全性保证的工作。 <div>
Secure multi-party computation (MPC) enables collaborative, privacy-preserving computation over private inputs. Advances in homomorphic encryption (HE), particularly the CKKS scheme, have made secure computation practical, making it well-suited for real-world applications involving approximate computations. However, the inherent approximation errors in CKKS present significant challenges in developing MPC protocols.

This paper investigates the problem of secure approximate MPC from CKKS. We first analyze CKKS-based protocols in two-party setting. When only one party holds a private input and the other party acts as an evaluator, a simple protocol with the noise smudging technique on the encryptor's side achieves security in the standard manner. When both parties have private inputs, we demonstrate that the protocol incorporating independent errors from each party achieves a relaxed standard security notion, referred to as a liberal security. Nevertheless, such a protocol fails to satisfy the standard security definition. To address this limitation, we propose a novel protocol that employs a distributed sampling approach to generate smudging noise in a secure manner, which satisfies the standard security definition. 

Finally, we extend the two-party protocols to the multi-party setting. Since the existing threshold CKKS-based MPC protocol only satisfies the liberal security, we present a novel multi-party protocol achieving the standard security by applying multi-party distributed sampling of a smudging error. 

For all the proposed protocols, we formally define the functionalities and provide rigorous security analysis within the simulation-based security framework. To the best of our knowledge, this is the first work to explicitly define the functionality of CKKS-based approximate MPC and achieve formal security guarantees.
]]></content:encoded>
<pubDate>Mon, 03 Mar 2025 02:34:42 +0000</pubDate>
</item>
<item>
<title>An Efficient Quantum Oblivious Transfer Protocol</title>
<link>https://eprint.iacr.org/2025/393</link>
<guid>https://eprint.iacr.org/2025/393</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious Transfer (OT), 量子OT (qOT), 单光子, 项目测量, 长期安全

总结:
本文介绍了量子隐私保护协议的重要组成部分——量子版的 Oblivious Transfer (qOT)。现有的经典 OT 协议基于非量子安全的数论假设，而许多量子 OT 协议效率不高或不够实用。文章提出了一种名为 qOT 的简洁高效量子 OT 协议，它利用了 Gao 等人提出的非对称密钥分布作为构建模块。qOT 协议仅需要单光子作为量子态源，并通过单粒子投影测量来计算状态，这使得 qOT 在实际应用中更为高效。此外，该设计被证明能抵抗量子攻击，并提供长期安全性。 <div>
Oblivious Transfer (OT) is a significant two party privacy preserving cryptographic primitive. OT involves a sender having several pieces of information and a receiver having a choice bit. The choice bit represents the piece of information that the receiver wants to obtain as an output of OT. At the end of the protocol, sender remains oblivious about the choice bit and receiver remains oblivious to the contents of the information that were not chosen. It has applications ranging from secure multi-party computation, privacy-preserving protocols to cryptographic protocols for secure communication. Most of the classical OT protocols are based on number theoretic assumptions which are not quantum secure and existing quantum OT protocols are not so efficient and practical. Herein, we present the design and analysis of a simple yet efficient quantum OT protocol, namely qOT. qOT is designed by using the asymmetric key distribution proposed by Gao et al. [18] as a building block. The designed qOT requires only single photons as a source of a quantum state, and the measurements of the states are computed using single particle projective measurement. These make qOT efficient and practical. Our proposed design is secure against quantum attacks. Moreover, qOT also provides long-term security.
]]></content:encoded>
<pubDate>Sun, 02 Mar 2025 13:47:20 +0000</pubDate>
</item>
<item>
<title>Blockchain-based Secure D2D localisation with adaptive precision</title>
<link>https://eprint.iacr.org/2025/392</link>
<guid>https://eprint.iacr.org/2025/392</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全、最佳努力、局部化信息、分布式账本、智能合约

总结:
本文提出了一种安全的最佳努力方法，用于在异构网络中为无法访问GPS或重型加密基础设施的设备提供局部化信息。该方法使每个设备仅基于其相邻锚点提供的数据就能计算出自身位置，以最高精度保证定位准确性。通过利用智能合约在分布式账本上注册局部化信息，确保了定位服务的安全性。文中证明了方案在适应性选择消息攻击模型下的安全性。此外，作者通过以Hyperledger Besu与QBFT共识作为案例研究，评估了该解决方案的有效性，具体考察了平均注册位置时间、失败请求以及总执行时间等指标。 <div>
In this paper we propose a secure  best effort methodology for providing localisation information to devices in a heterogenous network where devices do not have access to GPS-like technology or heavy cryptographic infrastructure. Each device will compute its localisation with the highest possible accuracy  based solely on the data provided by its neighboring anchors. The security of the localisation is guarantied by registering the localisation information on  a distributed ledger via smart contracts. We prove the security of our solution under  the adaptive chosen  message attacks model. We furthermore evaluate the effectiveness of our solution by measuring the  average register location time,  failed  requests, and total execution time using as DLT case study Hyperledger Besu with QBFT consensus.
]]></content:encoded>
<pubDate>Sun, 02 Mar 2025 10:11:56 +0000</pubDate>
</item>
<item>
<title>Fair Exchange for Decentralized Autonomous Organizations via Threshold Adaptor Signatures</title>
<link>https://eprint.iacr.org/2025/388</link>
<guid>https://eprint.iacr.org/2025/388</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Autonomous Organization (DAO)，公平交换，区块链，加密机制，智能合约，多党派管理，数字资产，见证分享，签名密钥分享，资金转移，公平性保障，DAO间公平性，DAO内公平性，标准密码学假设，高效协议，认证见证加密，门限适配器签名。

<br /><br />总结:
本文关注的是在不依赖智能合约的情况下，通过一种基于区块链技术的加密机制实现DAO间的公平交换。研究场景涉及由$n_\mathsf{S}$个卖家持有的见证分享$w$与由$n_\mathsf{B}$个买家持有的签名密钥分享$sk$之间的交互，目标是以预定金额的资金转移换取$w$。文章提出了DAO间及DAO内部的双重公平性要求：只有当双方DAO都完成资产交换时，各自的成员才能获取相应的资产。为达成这一目标，文章形式化定义了公平性属性并设计了一个高效的协议，该协议利用了认证见证加密和门限适配器签名这两个具有独立研究价值的新颖原语，并展示了它们的高效构建方法。 <div>
A Decentralized Autonomous Organization (DAO) enables multiple parties to collectively manage digital assets in a blockchain setting. We focus on achieving fair exchange between DAOs using a cryptographic mechanism that operates with minimal blockchain assumptions and, crucially, does not rely on smart contracts.  

Specifically, we consider a setting where a DAO consisting of $n_\mathsf{S}$ sellers holding shares of a witness $w$ interacts with a DAO comprising $n_\mathsf{B}$ buyers holding shares of a signing key $sk$; the goal is for the sellers to exchange $w$ for a signature under $sk$ transferring a predetermined amount of funds.  
Fairness is required to hold both between DAOs (i.e., ensuring that each DAO receives its asset if and only if the other does) as well as within each DAO (i.e., ensuring that all members of a DAO receive their asset if and only if every other member does).  

We formalize these fairness properties and present an efficient protocol for DAO-based fair exchange under standard cryptographic assumptions. Our protocol leverages certified witness encryption and threshold adaptor signatures, two primitives of independent interest that we introduce and show how to construct efficiently.
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 21:49:09 +0000</pubDate>
</item>
<item>
<title>Generic Composition: From Classical to Quantum Security</title>
<link>https://eprint.iacr.org/2025/387</link>
<guid>https://eprint.iacr.org/2025/387</guid>
<content:encoded><![CDATA[
<div> 关键词: Authenticated encryption, Encrypt-then-MAC, Quantum setting, Chosen-ciphertext security, Quantum pseudorandom function<br /><br />总结:<br />
该文研究了量子环境下的Encrypt-then-MAC组合的安全性，其中攻击者对加密和响应的查询可能处于叠加状态。文章指出，当使用选择明文（IND-qCPA）安全的对称加密方案SE与加一不可伪造MAC结合时，Encrypt-then-MAC组合无法实现选择密文（IND-qCCA）安全性。然而，通过将MAC替换为量子伪随机函数（qPRF），Encrypt-then-MAC或Encrypt-and-MAC组合能够确保IND-qCCA安全性。 <div>
Authenticated encryption (AE) provides both authenticity and privacy.
Starting with Bellare's and Namprempre's work in 2000, the Encrypt-then-MAC composition of an encryption scheme for privacy and a MAC for authenticity has become a well-studied and common approach.
This work investigates the security of the Encrypt-then-MAC composition in a quantum setting which means that adversarial queries as well as the responses to those queries may be in superposition.
We demonstrate that the Encrypt-then-MAC composition of a chosen-plaintext (IND-qCPA) secure symmetric encryption scheme SE and a plus-one unforgeable MAC fails to achieve chosen-ciphertext (IND-qCCA) security.
On the other hand, we show that it suffices to choose a quantum pseudorandom function (qPRF) as the MAC.
Namely, the Encrypt-then-MAC composition of SE and a qPRF is IND-qCCA secure.
The same holds for the Encrypt-and-MAC composition of SE and a qPRF
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 16:45:24 +0000</pubDate>
</item>
<item>
<title>On the Security and Privacy of CKKS-based Homomorphic Evaluation Protocols</title>
<link>https://eprint.iacr.org/2025/382</link>
<guid>https://eprint.iacr.org/2025/382</guid>
<content:encoded><![CDATA[
<div> 关键词: CKKS、同态加密、差分隐私、DPHE协议、零知识证明<br /><br />总结:
本文提出了一种针对基于CKKS的同态加密协议的新定义——差分隐私同态评估(DPHE)协议。该定义将发送者的隐私条件从不可区分性放松到差分隐私的范畴，重点关注PPML协议中评价结果的差分隐私而非仿真可评估性。作者证明了如果理想功能满足差分隐私，且一个协议满足DPHE，则其输出也满足差分隐私。文章进一步提供了一个通用编译器，通过结合拉普拉斯机制和CKKS的零知识论证知识(ZKAoK)，将普通的CKKS协议转换为DPHE协议，实现了发送者隐私保护并降低了噪声。同时，文章对CKKS的ZKAoK进行了具体实现，采用PIOP形式，并设计了新的验证技术，利用同态计算在验证过程中证明CKKS密文和公钥的正确性。最后，作者通过使用HSS多项式承诺方案实现了PIOP的编译，展示了所提ZKAoK应用于CKKS的实用性。 <div>
CKKS is a homomorphic encryption (HE) scheme that supports arithmetic over complex numbers in an approximate manner. 
Despite its utility in PPML protocols, formally defining the security of CKKS-based protocols is challenging due to its approximate nature.
To be precise, in a sender-receiver model, where the receiver holds input ciphertexts and the sender evaluates its private circuit, it is difficult to define sender's privacy in terms of indistinguishability, whereas receiver's privacy is easily achieved through the semantic security of CKKS.

In this paper, we present a new definition for CKKS-based protocols, called Differentially Private Homomorphic Evaluation (DPHE) protocols, along with a general method to achieve this.
In our definition, we relax the sender’s privacy condition from indistinguishability to differential privacy notion. 
We focus on the fact that most security concern for PPML protocols is differential privacy on evaluation results, rather than the simulatability of the evaluation.
We prove that if the ideal functionality satisfies differential privacy and a protocol satisfies DPHE, then the output of the protocol also satisfies differential privacy.

Next, we provide a general compiler that transforms a plain CKKS-based protocol into a DPHE one. 
We achieve this by mixing the Laplace mechanism and zero-knowledge argument of knowledge (ZKAoK) for CKKS. 
This approach allows us to achieve sender's privacy with a moderate noise, whereas the previous indistinguishability-based approach requires exponentially large overhead.

Finally, we provide a concrete instantiation of ZKAoK for CKKS in the form of PIOP.
To prove the well-formedness of CKKS ciphertexts and public keys, we devise new proof techniques that use homomorphic evaluation during verification.
We also provide an implementation to demonstrate the practicality of our ZKAoK for CKKS by compiling PIOPs using the HSS polynomial commitment scheme (Crypto'24).
]]></content:encoded>
<pubDate>Fri, 28 Feb 2025 03:24:53 +0000</pubDate>
</item>
<item>
<title>Functional Oblivious Transfer with Applications in Privacy-Preserving Machine Learning</title>
<link>https://eprint.iacr.org/2025/371</link>
<guid>https://eprint.iacr.org/2025/371</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious Transfer (OT), Functional OT (FOT), 加密原语, 隐私保护机器学习, Federated Learning (FL)

总结:
本文首次提出了功能性隐匿传输(FOT)的概念，这是一种对传统隐匿传输的增强，确保接收者只能了解到所选消息的函数值而非具体的消息本身。文中提出了一系列实现FOT的协议，针对求平均值、众数、加法和乘法等特定函数进行了具体的实例化设计。这些方案高效且无条件安全。此外，还提到了一个利用全同态加密(FHE)和 oblivionous 线性函数评估来支持任意函数的非平凡协议，其对消息数量 n 的 FHE 调用次数为常数 O(1)。文章通过渐进和具体的成本分析展示了无条件安全的 FOT 协议的效率。FOT 可以提升隐私保护机器学习的安全性，尤其是在K-最近邻算法和联邦学习中的客户端选择场景中。 <div>
Oblivious Transfer (OT) is a fundamental cryptographic primitive introduced nearly four decades ago. OT allows a receiver to select and learn $t$ out of $n$ private messages held by a sender. It ensures that the sender does not learn which specific messages the receiver has chosen, while the receiver gains no information about the remaining $n − t$ messages. In this work, we introduce the notion of functional OT (FOT), for the first time. FOT adds a layer of security to the conventional OT by ensuring that the receiver only learns a function of the selected messages rather than the $t$ individual messages themselves. We propose several protocols that realize this concept. In particular, we propose concrete instantiations of FOT when the function to be executed on the selected message is mean, mode, addition, or multiplication. The schemes are efficient and unconditionally secure. We also propose a non-trivial protocol that supports arbitrary functions on the selected messages mainly using fully homomorphic encryption (FHE) and oblivious linear function evaluation, where the number of FHE invocations is constant $O(1)$ with respect to $n$. Our asymptotic and concrete cost analyses demonstrate the efficiency of our unconditionally secure FOT protocols. FOT can enhance the security of privacy-preserving machine learning, particularly in (i) K-Nearest Neighbors schemes and (ii) client selection in Federated Learning (FL).
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 19:00:47 +0000</pubDate>
</item>
<item>
<title>Higher Residuosity Attacks on Small RSA Subgroup Decision Problems</title>
<link>https://eprint.iacr.org/2025/369</link>
<guid>https://eprint.iacr.org/2025/369</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全两方比较、同态加密、 Carlton et al.、Bourse et al.、高次剩余攻击

总结:
本文关注于安全两方比较这一隐私保护计算中的核心问题，特别是在基于同态加密的解决方案上。Carlton et al.和Bourse et al.提出的新型协议相较于传统的DGK协议，已经展现出显著的性能提升。然而，文章中引入了一类新的高次剩余攻击，将其视为对决策性Diffie-Hellman问题的经典二次剩余攻击的扩展。研究发现，CEK和BST协议所依赖的小RSA子群决策问题在素基数$p_0$较小时（如$p_0 < 100$）并不难解决，这使得这两种协议在这些条件下达到最优整体性能。对此，文章给出了防范此类攻击的建议，其中包括一种不会影响协议性能的方法。同时，作者希望这种攻击分析方法可以应用于其他数论难度假设的研究中。<br /><br /> <div>
Secure two-party comparison, known as Yao's millionaires' problem, has been a fundamental challenge in privacy-preserving computation. It enables two parties to compare their inputs without revealing the exact values of those inputs or relying on any trusted third party. One elegant approach to secure computation is based on homomorphic encryption. Recently, building on this approach, Carlton et al. (CT-RSA 2018) and Bourse et al. (CT-RSA 2020) presented novel solutions for the problem of secure integer comparison. These protocols have demonstrated significantly improved performance compared to the well-known and frequently used DGK protocol (ACISP 2007 and Int. J. Appl. Cryptogr. 1(4),323–324, 2009). In this paper, we introduce a class of higher residuosity attacks, which can be regarded as an extension of the classical quadratic residuosity attack on the decisional Diffie-Hellman problem. We demonstrate that the small RSA subgroup decision problems, upon which both the CEK and BST protocols are based, are not difficult to solve when the prime base $p_0$ is small (e.g., \( p_0 < 100 \)). Under these conditions, the protocols achieve optimal overall performance. Furthermore, we offer recommendations for precluding such attacks, including one approach that does not adversely affect performance. We hope that these attacks can be applied to analyze other number-theoretic hardness assumptions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 11:42:03 +0000</pubDate>
</item>
<item>
<title>Traitor Tracing in Multi-sender Setting ($\textsf{TMCFE}$: Traceable Multi-client Functional Encryption)</title>
<link>https://eprint.iacr.org/2025/364</link>
<guid>https://eprint.iacr.org/2025/364</guid>
<content:encoded><![CDATA[
<div> 关键词：traitor tracing、functional encryption、multi-client functional encryption、traceable multi-client functional encryption、lattice-based security

总结:<br />
本文提出了一个新的密码学原语——可追踪多客户端功能加密（$\textsf{TMCFE}$），旨在解决多发送者环境下隐私保护联合计算中的背叛追溯问题。传统背叛追溯技术仅限于单一发送者场景，而本文概念性地将这一框架扩展到多发送者加密中，允许追踪来自接收者和发送者的秘密信息泄露源头。从技术层面，文章基于近期提出的强可承认性概念构建了一个通用编译器，该编译器能将具有弱可承认性的多客户端功能加密方案转化为具有强可承认性的方案，克服了现有挑战并可能在功能性加密领域具有广泛应用价值。此外，文中还提供了一种针对内积功能的基于晶格的安全实现$\textsf{TMCFE}$方案，该方案在标准假设下具备后量子安全性。 <div>
Traitor tracing is a traditional cryptographic primitive designed for scenarios with multiple legitimate receivers. When the plaintext - that is, the output of decryption - is leaked and more than one legitimate receiver exists, it becomes imperative to identify the source of the leakage, a need that has motivated the development of traitor tracing techniques. Recent advances in standard encryption have enabled decryption outcomes to be defined in a fine-grained manner through the introduction of Functional Encryption (FE). Constructing FE schemes is intriguing, and achieving the tracing property adds an additional layer of complexity. Traitor tracing techniques have been actively developed for more than three decades, yet they have always remained within the same framework - a single sender responsible for encrypting all the data.

However, fine-grained decryption is particularly useful when data originates from multiple sources, allowing for joint computation on personal data. This leads to the concept of multi-client functional encryption (MCFE), where multiple concurrent senders independently encrypt their data while agreeing on the decryption of a specific function (e.g., a statistical measure) computed on the aggregated data, without revealing any additional information. In the era of cloud computing and big data, privacy-preserving joint computation is crucial, and tracing the source of any breach by dishonest participants becomes essential. Thus, in this paper we take the first step toward addressing the tracing problem in the general context of joint computation with multiple senders. Our contributions are twofold:
  - $\textbf{Conceptually:}$ We propose the first tracing model in the context of multi-sender encryption, namely $\textit{Traceable Multi-Client Functional Encryption}$ ($\textsf{TMCFE}$), which allows a pirate to extract secret information from both receivers and senders. Our model supports strong and naturally admissible decoders, removing artificial restrictions on the pirate decoder and thus addressing the shortcomings of existing traceable functional encryption schemes designed for the single-sender setting.
  - $\textbf{Technically:}$ To achieve our conceptual objective, we build upon the recently introduced notion of strong admissibility for MCFE. Our main technical contribution is a generic compiler that transforms a large class of MCFE schemes with weak admissibility into schemes with strong admissibility. This compiler not only helps overcome existing challenges but may also be of general interest within the functional encryption domain. Finally, we present a concrete lattice-based scheme $\textsf{TMCFE}$ for inner-product functionalities that achieves post-quantum security under standard assumptions.
]]></content:encoded>
<pubDate>Wed, 26 Feb 2025 10:11:10 +0000</pubDate>
</item>
<item>
<title>Identity-based Matchmaking Encryption with Stronger Security and Instantiation on Lattices</title>
<link>https://eprint.iacr.org/2022/1718</link>
<guid>https://eprint.iacr.org/2022/1718</guid>
<content:encoded><![CDATA[
<div> 关键词:身份基匹配加密(IB-ME), 匿名性, 认证安全性, 量子攻击, 环境适应性<br /><br />总结:
本文针对现有的身份基匹配加密(IB-ME)方案在对抗量子攻击和可能存在的潜在威胁方面的不足，提出了更强的安全定义——考虑了新的攻击方式以适应现实世界场景。文中首先提出了一种基于两层匿名层级身份基加密(HIBE)和身份基签名(IBS)的IB-ME通用构建方法。此外，为了提升基于格的IB-ME效率，文章还改进了一个基于格的IBS，缩短其签名长度，从而减少了最终IB-ME密文的大小。通过将改进后的IBS与任何具备匿名性和适应性安全性的二级基于格的HIBE相结合，最终实现了首个直接实现IB-ME的基于格的构造方案。 <div>
An identity-based matchmaking encryption (IB-ME) scheme proposed at JOC 2021 supports anonymous but authenticated communications in a way that communication parties can both specify the senders or receivers on the fly. IB-ME is easy to be used in several network applications requiring privacy-preserving for its efficient implementation and special syntax. In the literature, IB-ME schemes are built from the variants of Diffie-Hellman assumption and all fail to retain security for quantum attackers. Despite the rigorous security proofs in previous security models, the existing schemes are still possibly vulnerable to some potential neglected attacks. Aiming at the above problems, we provide a stronger security definition of authenticity considering new attacks to fit real-world scenarios and then propose a generic construction of IB-ME satisfying the new model. Inspired by the prior IB-ME construction of Chen et al., the proposed scheme is constructed by combining 2-level anonymous hierarchical IBE (HIBE) and identity-based signature (IBS) schemes. In order to upgrade lattice-based IB-ME with better efficiency, we additionally improve a lattice IBS, as an independent technical contribution, to shorten its signature and thus reduce the final IB-ME ciphertext size. By combining the improved IBS and any 2-level adaptively-secure lattice-based HIBE with anonymity, we finally obtain the first lattice-based construction that implements IB-ME directly.
]]></content:encoded>
<pubDate>Mon, 12 Dec 2022 08:03:11 +0000</pubDate>
</item>
<item>
<title>OCash: Fully Anonymous Payments between Blockchain Light Clients</title>
<link>https://eprint.iacr.org/2024/246</link>
<guid>https://eprint.iacr.org/2024/246</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、匿名支付系统、轻客户端、全节点、UC模型

总结:
本文研究了一种基于区块链的轻客户端之间的可验证匿名支付系统。该系统中，轻客户端通过全节点与区块链交互，而全节点可以看到轻客户端的读写操作。文章旨在实现即使在面对能观察到数据元素移动情况的全节点情况下，也能保障轻客户端进行匿名支付并维持隐私的目标。作者在UC模型下对问题进行了形式化定义，并提出了一种可证明安全的解决方案。他们展示了一种树ORAM的变体可以实现即使对手能够追踪其自身数据元素在树中的移动也能够保持无感知性。利用这一特性，文章实现了在区块链上的支付混淆以保证匿名性，同时允许轻客户端在不知道当前区块链状态的情况下知道其支付可能存在的几个位置。相较于现有工作，本文首次同时提供了强匿名性保证、可证明的安全性和针对全节点的匿名性。此外，文中还做出了一些独立贡献，包括定义并构建了适用于匿名支付系统的匿名币友好加密方案，以及定义和构造了高效的可压缩随机性信标，这种信标能够在规定时间间隔内生成不可预测的值，并能将其所有发布的值存储在一个简短的摘要中。 <div>
We study blockchain-based provably anonymous payment systems between light clients. Such clients interact with the blockchain through full nodes, which can see what the light clients read and write. The goal of our work is to enable light clients to perform anonymous payments, while maintaining privacy even against the full nodes through which they interact with the blockchain. We formalize the problem in the UC model and present a provably secure solution. We show that a variation of tree ORAM gives obliviousness even when an adversary can follow how its own data elements move in the tree. We use this for anonymity via shuffling of payments on the blockchain, while at the same time allowing the light client to know a few positions among which to find its payment without knowing the current state of the blockchain. In comparison to existing works, we are the first ones that simultaneously provide strong anonymity guarantees, provable security, and anonymity with respect to full nodes. Along the way, we make several contributions that may be of independent interest. We define and construct anonymous-coin friendly encryption schemes and show how they can be used within anonymous payment systems. We define and construct efficient compressible randomness beacons, which produce unpredictable values in regular intervals and allow for storing all published values in a short digest.
]]></content:encoded>
<pubDate>Thu, 15 Feb 2024 14:42:02 +0000</pubDate>
</item>
<item>
<title>Stronger Security for Threshold Blind Signatures</title>
<link>https://eprint.iacr.org/2025/353</link>
<guid>https://eprint.iacr.org/2025/353</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、阈值盲签名、安全性、一更多不可伪造性、多签发者

总结:
文章探讨了阈值盲签名的安全性问题，其中盲签名允许用户以保护隐私的方式从签发者获取签名，而阈值版本则将私钥分散到n个签发者中，需要用户至少从t≤n个签发者那里获得签名份额才能生成最终签名。文章指出现有的一更多不可伪造性概念在单签发者场景下理解清晰，但在阈值场景中由于盲签名发行的特性导致挑战较大。现有的工作通过简化模型规避这一挑战，但无法完全体现阈值设置的预期。为此，文章提出了一个新的适用于c＜t个签发者被攻击情况的一更多不可伪造性框架，该框架可适应交互式和非交互式协议，并提供了一组逐步增强保证的自然属性，使签发者对份额组合拥有更多控制权。接着，文章重新审视了现有基于BLS和Snowblind的阈值盲签名方案在新框架下的安全性，并展示了如何提升它们的安全性。总的来说，文章旨在为阈值盲签名提供更强大且明确的安全保障。 <div>
Blind signatures allow a user to obtain a signature from an issuer in a privacy-preserving way: the issuer neither learns the signed message, nor can link the signature to its issuance. The threshold version of blind signatures further splits the secret key among n issuers, and requires the user to obtain at least t ≤ n of signature shares in order to derive the final signature. Security should then hold as long as at most t − 1 issuers are corrupt. Security for blind signatures is expressed through the notion of one-more unforgeability and demands that an adversary must not be able to produce more signatures than what is considered trivial after its interactions with the honest issuer(s). While one-more unforgeability is well understood for the single-issuer setting, the situation is much less clear in the threshold case: due to the blind issuance, counting which interactions can yield a trivial signature is a challenging task. Existing works bypass that challenge by using simplified models that do not fully capture the expectations of the threshold setting. In this work, we study the security of threshold blind signatures, and propose a framework of one-more unforgeability notions where the adversary can corrupt c < t issuers. Our model is generic enough to capture both interactive and non-interactive protocols, and it provides a set of natural properties with increasingly stronger guarantees, giving the issuers gradually more control over how their shares can be combined. As a point of comparison, we reconsider the existing threshold blind signature models and show that their security guarantees are weaker and less clearly comprehensible than they seem. We then re-assess the security of existing threshold blind signature schemes – BLS-based and Snowblind – in our framework, and show how to lift them to provide stronger security.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 12:39:58 +0000</pubDate>
</item>
<item>
<title>Helix: Scalable Multi-Party Machine Learning Inference against Malicious Adversaries</title>
<link>https://eprint.iacr.org/2025/347</link>
<guid>https://eprint.iacr.org/2025/347</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私、安全多方计算、PPML、恶意安全性、Helix

总结:
本文提出了一个名为Helix的框架，旨在实现大规模参与者的恶意安全PPML协议，提升恶意安全协议的可扩展性和实用性。文章指出了LXY24工作在前缀OR操作中存在的隐私泄漏问题，并提出了一种基于单轮矢量化三层乘法协议的优化方案作为替代。此外，通过利用计算过程中的可重用性，Helix设计了轻量级压缩协议以提高乘法验证效率，并开发了批量检查协议来降低恶意环境中揭示操作的计算复杂度。实验结果显示，在63方神经网络推理场景下，相比于半诚实的LXY24，Helix在线阶段慢1.9倍（LAN环境下为1.1倍），预处理阶段慢1.2倍（WAN环境下为1.1倍），但在最佳情况下表现出了较高的效率优势。 <div>
With the growing emphasis on data privacy, secure multi-party computation has garnered significant attention for its strong security guarantees in developing privacy-preserving machine learning (PPML) schemes. However, only a few works address scenarios with a large number of participants. The state of the art by Liu et al. (LXY24, USENIX Security'24) first achieves a practical PPML protocol for up to 63 parties but is constrained to semi-honest security. Although naive extensions to the malicious setting are possible, they would introduce significant overhead.
In this paper, we propose Helix, a scalable framework for maliciously secure PPML in the honest majority setting, aiming to enhance both the scalability and practicality of maliciously secure protocols. In particular, we report a privacy leakage issue in LXY24 during prefix OR operations and introduce a round-optimized alternative based on a single-round vectorized three-layer multiplication protocol. Additionally, by exploiting reusability properties within the computation process, we propose lightweight compression protocols that substantially improve the efficiency of multiplication verification. We also develop a batch check protocol to reduce the computational complexity of revealing operations in the malicious setting. For 63-party neural network inference, compared to the semi-honest LXY24, Helix is only 1.9$\times$ (1.1$\times$) slower in the online phase and 1.2$\times$ (1.1$\times$) slower in preprocessing under LAN (WAN) in the best case.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 01:34:53 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Threshold Proxy Re-encryption and Its Application in Data Rights Confirmation</title>
<link>https://eprint.iacr.org/2025/345</link>
<guid>https://eprint.iacr.org/2025/345</guid>
<content:encoded><![CDATA[
<div> 关键词: Proxy Re-Encryption, PVTPRE, Public Verifiability, Data Rights Confirmation, Blockchain

总结:
本文提出了一个新的代理重加密方案——公开可验证阈值代理重加密(PVTPRE)，该方案填补了在大数据时代对数据拥有者诚实性考虑的空白。PVTPRE通过创新地应用稍作修改的公开可验证秘密分享(PVSS)方案，将重加密密钥分布式地分配给多个代理，实现数据拥有者的非交互式公开可验证性。同时，通过执行PVSS重构算法，确保了数据用户解密的正确性和代理重加密的公共可验证性。文章进一步证明PVTPRE满足IND-CPA安全性标准。此外，基于PVTPRE和区块链技术，文中提出了一种隐私保护的数据权利确认框架，为数据所有权和使用提供明确原则，并利用区块链作为数据银行和智能合约引擎，提供可靠存储与验证服务。据作者所知，这是首次系统研究兼顾隐私保护与公开可验证性的数据权利确认机制，旨在保护数据权利并确保透明度。最后，文章进行了全面的实验以证实PVTPRE的正确性、可行性和有效性，并显示其在许多方面优于其他代理重加密方案。 <div>
Proxy re-encryption (PRE) has been regarded as an effective cryptographic primitive in data sharing systems with distributed proxies. However, no literature considers the honesty of data owners, which is critical in the age of big data. In this paper, we fill the gap by introducing a new proxy re-encryption scheme, called publicly verifiable threshold PRE (PVTPRE). Briefly speaking, we innovatively apply a slightly modified publicly verifiable secret sharing (PVSS) scheme to distribute the re-encryption keys to multiple proxies. Consequently, we achieve publicly verifiability of data owners non-interactively. Then, the correctness of data users in decryption and public verifiability of proxies in re-encryption are guaranteed seamlessly through execution of the PVSS reconstruction algorithms. We further prove that PVTPRE satisfies IND-CPA security. Besides, we put forward a privacy-preserving data rights confirmation framework by providing clear principles for data ownership and usage, based on the PVTPRE scheme and blockchain. Blockchain plays the role of data bank and smart contract engine, providing reliable storage and verification for all framework. To our knowledge, we are the first to systematically investigate data rights confirmation considering privacy as well as public verifiability, addressing the growing need for robust mechanisms to protect data rights and ensure transparency. Finally, we conduct comprehensive experiments to illustrate the correctness, feasibility and effectiveness. The experimental results show that our PVTPRE outperforms other PREs in many aspects.
]]></content:encoded>
<pubDate>Tue, 25 Feb 2025 00:21:38 +0000</pubDate>
</item>
<item>
<title>Publicly Verifiable Generalized Secret Sharing and Its Application in Building Decentralized Exchange</title>
<link>https://eprint.iacr.org/2025/344</link>
<guid>https://eprint.iacr.org/2025/344</guid>
<content:encoded><![CDATA[
<div> 关键词: Generalized Secret Sharing (GSS), Publicly Verifiable Generalized Secret Sharing (PVGSS), Non-Interactive Zero-Knowledge (NIZK), Decentralized Exchange (DEX), Fairness

<br /><br />总结:
本文提出了公开可验证广义秘密共享（PVGSS）方案，旨在提升分布式计算中GSS机制的适用性，尤其是在区块链等透明系统中的应用。首先介绍了基于Shamir秘密共享和线性秘密共享方案两种GSS构造方法。接着，将GSS与非交互式零知识证明（NIZK）相结合构建了PVGSS方案。进一步地，利用PVGSS方案设计了一个去中心化交易所（DEX），用户可以在其中公平地进行ERC-20代币交换，而被动观察者通过提供仲裁服务获取利润。DEX的关键特性“公平性”由PVGSS方案支持的复杂访问结构保障。文章还对PVGSS方案的性能以及DEX中用户的经济成本进行了全面评估，结果表明该方法在现实世界应用中具有可行性和实用性。 <div>
Generalized secret sharing (GSS), which can offer more flexibility by accommodating diverse access structures and conditions, has been under-explored in distributed computing over the past decades. To address the gaps, we propose the publicly verifiable generalized secret sharing (PVGSS) scheme, enhancing the applicability of GSS in transparent systems. Public verifiability is a crucial property to gain trustworthiness for decentralized systems like blockchain.  We begin by introducing two GSS constructions, one based on Shamir's secret sharing and the other on the linear secret sharing scheme (LSSS). Next, we present PVGSS schemes that combine GSS with non-interactive zero-knowledge (NIZK) proofs.  Further, we construct a decentralized exchange (DEX) based on PVGSS scheme, where any users can participate in exchanges and engage in arbitrage. Specifically, users can fairly swap ERC-20 tokens with passive watchers, who earn profits by providing arbitration services. The critical property of "fairness" required by the DEX is ensured through a sophisticated access structure, supported by the PVGSS scheme. We provide a comprehensive evaluation on the performance of the PVGSS schemes and the monetary costs for users in the DEX. The results demonstrate the feasibility and practicality of this approach in real-world applications.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 23:42:56 +0000</pubDate>
</item>
<item>
<title>CCA-Secure Traceable Threshold (ID-based) Encryption and Application</title>
<link>https://eprint.iacr.org/2025/341</link>
<guid>https://eprint.iacr.org/2025/341</guid>
<content:encoded><![CDATA[
<div> 关键词：traceable threshold encryption、CCA安全性、一致性、身份基加密、Boneh-Franklin IBE、Boneh-Boyen IBE

<br /><br />总结：

本文提出了更强版本的可追踪门限加密定义，支持CCA安全性与解密一致性。文章首先引入了基于身份的可追踪加密变种，并通过两个通用变换将其转化为CCA安全构造，这些变换利用了一次性签名和指纹编码技术。接着，文章给出了两种高效的身份基方案实例，第一种基于Boneh-Franklin IBE，具有常数大小的密文但公钥大小为二次级，其安全性依赖于XDH和BDDH假设；第二种基于Boneh-Boyen IBE，同时支持常数大小的密文和公钥，安全性基于双线性配对的一种变种——“uber”假设。具体分析表明，第一种方案的密文比第二种小约6倍。最后，为了实现一致性，文章扩展了相关定义并加入了一个有效的非交互式正确加密证明。 <div>
A recent work by Boneh, Partap, and Rotem [Crypto'24] introduced the concept of traceable threshold encryption, in that if $t$ or more parties collude to construct a decryption box, which performs decryptions, then at least one party's identity can be traced by making a few black-box queries to the box. This has important applications, e.g., in blockchain mempool privacy, where collusion yields high financial gain through MEVs without any consequence - the possibility of tracing discourages collusion.
Nevertheless, their definitions leave room for exploitation as they only achieve CPA security and do not consider inconsistency in decryption via different participating sets.

This paper proposes stronger definitions of traceable threshold encryption, which supports CCA-security and consistency. Our main approach considers identity-based variants of traceable encryption (which we also define). It converts that to a CCA-secure construction, adapting two generic transformations, first using a one-time signature and then a fingerprinting code. 
We put forward two efficient instantiations of our identity-based scheme with different merits: our first construction is based on Boneh-Franklin IBE [Crypto'01] and has constant size ciphertexts but quadratic size public keys - this is proven secure based on XDH and BDDH. Our second construction is based on Boneh-Boyen IBE [Eurocrypt'04]. It supports both constant-size ciphertexts and constant-size public keys - this is proven secure based on a variant of the uber assumption over bilinear pairings. Our concrete analysis shows that the first construction's ciphertext is much (~6x) smaller than the second construction. Finally, we extend the definitions to support consistency and achieve it by adjoining an efficient, non-interactive proof of correct encryption.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 15:59:42 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Multi-Signatures: Generic Techniques and Constructions Without Pairings</title>
<link>https://eprint.iacr.org/2025/335</link>
<guid>https://eprint.iacr.org/2025/335</guid>
<content:encoded><![CDATA[
<div> 关键词: 多重签名、隐私保护、集体签名、BLS型、Schnorr型

总结:
这篇文章研究了多重签名在隐私保护集体签名中的应用。Lehmann和Özbay最近的工作提出了具有概率性但可验证密钥聚合的新型BLS型多重签名，允许用户在不泄露所属组信息的情况下复用长期密钥参与不同群组。然而，这一技术不能应用于Schnorr型多重签名。对此，文章重新审视了他们的隐私框架，并做出了两个贡献：一是提出一种通用方法，将隐私保护添加到任何确定性密钥聚合的多重签名中；二是针对两种具体的多重签名方案（MuSig2和基于 lattice 的 DualMS）给出了针对性的转换，使MuSig2无需额外成本即可实现最强隐私属性，同时使 DualMS 变种成为首个适用于隐私保护的动态群体签名的后量子安全多重签名方案。虽然修改后的 DualMS 方案略有开销增加，但仍能保持原方案的竞争力。 <div>
Multi-signatures allow a set of parties to produce a single signature for a common message by combining their individual signatures. The result can be verified using the aggregated public key that represents the group of signers. Very recent work by Lehmann and Özbay (PKC '24) studied the use of multi-signatures for ad-hoc privacy-preserving group signing, formalizing the notion of multi-signatures with probabilistic yet verifiable key aggregation. Moreover, they proposed new BLS-type multi-signatures, allowing users holding a long-term key pair to engage with different groups, without the aggregated key leaking anything about the corresponding group. This enables key-reuse across different groups in a privacy-preserving way. Unfortunately, their technique cannot be applied to Schnorr-type multi-signatures, preventing state-of-the-art multi-signatures to benefit from those privacy features.

In this work, we revisit the privacy framework from Lehmann and Özbay. Our first contribution is a generic lift that adds privacy to any multi-signature with deterministic key aggregation. As our second contribution, we study two concrete multi-signatures, and give dedicated transforms that take advantage of the underlying structures for improved efficiency. The first one is a slight modification of the popular MuSig2 scheme, achieving the strongest privacy property for free compared to the original scheme. The second is a variant of the lattice-based multi-signature scheme DualMS, making our construction the first post-quantum secure multi-signature for ad-hoc privacy-preserving group signing. The light overhead incurred by the modifications in our DualMS variant still allow us to benefit from the competitiveness of the original scheme.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 13:35:38 +0000</pubDate>
</item>
<item>
<title>How to Share an NP Statement or Combiners for Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2025/334</link>
<guid>https://eprint.iacr.org/2025/334</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密分享、NP陈述、信息论安全性、多项式复杂性、非交互式组合

<br /><br />总结:
本文探讨了秘密分享NP陈述（NPSS）的概念，并对其进行了深化，提出了信息论安全性的NPSS定义，该定义可以视为标准NP归约的加密变体，并能利用任何单向函数编译为GJS定义。文章构建了一个适用于任意$t\leq n$值的信息论安全的$t$-out-of-$n$ NPSS构造，其复杂度为多项式级别。在此过程中，作者引入了一种新的安全多方计算概念，具有独立的研究价值。

接着，本文的NPSS框架支持非交互式地结合$n$个零知识证明实例，只要其中满足$t_s + t_z > n$，即可实现仅有$t_s$个实例保证声音性和仅有$t_z$个实例保证零知识性。基于此，文章在仅需单向函数假设下实现了以下成果：
(1) 标准NIZK蕴含多字符串模型中的NIZK，只要多数共同参考字符串是诚实生成的，即可确保安全性。此前此类转换仅知在公共随机串模型中可行。
(2) 在多字符串模型中实现了指定证明者NIZK，达到了一种强形式的两轮多验证器零知识，在诚实多数设置下。
(3) 基于诚实多数设置，提出了一种三轮安全多方计算协议，对于一般功能而言，其轮数复杂度是最优的，从而解决了以往依赖更强假设的一系列研究问题（如Aharonov等人，Eurocrypt'12；Gordon等人，Crypto'15；Ananth等人，Crypto'18；Badrinarayanan等人，Asiacrypt'20；Applebaum等人，TCC'22）。 <div>
In Crypto'19, Goyal, Jain, and Sahai (GJS) introduced the elegant notion of *secret-sharing of an NP statement* (NPSS). Roughly speaking, a $t$-out-of-$n$ secret sharing of an NP statement is a reduction that maps an instance-witness pair to $n$ instance-witness pairs such that any subset of $(t-1)$ reveals no information about the original witness, while any subset of $t$ allows full recovery of the original witness. Although the notion was formulated for general $t \leq n$, the only existing construction (due to GJS) applies solely to the case where $t = n$ and provides only computational privacy. In this paper, we further explore NPSS and present the following contributions.  

1. **Definition.** We introduce a refined definition of information-theoretically secure NPSS. This notion can be seen as a cryptographic variant of standard NP-reductions and can be compiled into the GJS definition using any one-way function.

2. **Construction.** We construct information-theoretic $t$-out-of-$n$ NPSS for any values of $t\leq n$ with complexity polynomial in $n$. Along the way, we present a new notion of secure multiparty computation that may be of independent interest.

3. **Applications.** Our NPSS framework enables the *non-interactive combination* of $n$ instances of zero-knowledge proofs, where only $t_s$ of them are sound and only $t_z$ are zero-knowledge, provided that $t_s + t_z > n$. Our combiner preserves various desirable properties, such as the succinctness of the proof. Building on this, we establish the following results under the minimal assumption of one-way functions: 
(i) *Standard NIZK implies NIZK in the Multi-String Model* (Groth and Ostrovsky, J. Cryptology, 2014), where security holds as long as a majority of the $n$ common reference strings were honestly generated. Previously, such a transformation was only known in the common random string model, where the reference string is uniformly distributed.
(ii) A *Designated-Prover NIZK in the Multi-String Model*, achieving a strong form of two-round Multi-Verifier Zero-Knowledge in the honest-majority setting.
(iii) A *three-round secure multiparty computation protocol* for general functions in the honest-majority setting. The round complexity of this protocol is optimal, resolving a line of research that previously relied on stronger assumptions (Aharonov et al., Eurocrypt'12; Gordon et al., Crypto'15; Ananth et al., Crypto'18; Badrinarayanan et al., Asiacrypt'20; Applebaum et al., TCC'22).
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 11:30:03 +0000</pubDate>
</item>
<item>
<title>Leap: A Fast, Lattice-based OPRF With Application to Private Set Intersection</title>
<link>https://eprint.iacr.org/2025/333</link>
<guid>https://eprint.iacr.org/2025/333</guid>
<content:encoded><![CDATA[
<div> 关键词： Oblivious Pseudorandom Functions (OPRFs)，量子攻击，Leap，学习与舍入假设，私人集合交集 (PSI)

总结:
本文介绍了基于他uristic lattice假设的新型Oblivious Pseudorandom Function (OPRF)——Leap。考虑到未来潜在的量子攻击对大多数依赖于经典假设的OPRFs构成威胁，Leap构建在Spring [BBL+15] 基于学习与舍入假设的伪随机函数之上，并结合了多方计算中的Oblivious Transfer (OT) 和 Oblivious Linear Evaluation (OLE) 技术。通过这种方式，Leap实现了在现代计算机上不到一毫秒的评估时间。其原型实现的计算时间为客户端11微秒、服务器端750微秒（不包括基础OT预处理开销），并具有在线通信成本仅为23 kB每评估的特点，其中客户端仅需发送约380字节的数据。为了展示Leap的实际应用潜力，文章使用Leap构建了一个高效的私人集合交集(PSI)协议，该协议能在不到一分钟的在线时间内完成大小为2^24和2^15的两个集合的交集计算，总耗时超过两分钟。这一应用表明Leap可以被整合到各种隐私保护的应用场景中。 <div>
Oblivious pseudorandom functions (OPRFs) are an important primitive in privacy-preserving cryptographic protocols. The growing interest in OPRFs, both in theory and practice, has led to the development of numerous constructions and variations. However, most of these constructions rely on classical assumptions. Potential future quantum attacks may limit the practicality of those OPRFs for real-world applications. 

To close this gap, we introduce Leap, a novel OPRF based on heuristic lattice assumptions. Fundamentally, Leap builds upon the Spring [BBL+15] pseudorandom function (PRF), which relies on the learning with rounding assumption, and integrates techniques from multi-party computation, specifically Oblivious Transfer (OT) and Oblivious Linear Evaluation (OLE). With this combination of oblivious protocols, we construct an OPRF that evaluates in less than a millisecond on a modern computer.

Efficiency-wise, our prototype implementation achieves computation times of just 11 microseconds for the client and 750 microseconds for the server, excluding some base OT preprocessing overhead. Moreover, Leap requires an online communication cost of 23 kB per evaluation, where the client only has to send around 380 bytes online. To demonstrate the practical applicability of Leap, we present an efficient private set intersection (PSI) protocol built on top of Leap. This application highlights the potential for the integration of Leap into various privacy-preserving applications: We can compute an unbalanced set intersection with set sizes of 2^24 and 2^15 in under a minute of online time and just over two minutes overall.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 11:20:47 +0000</pubDate>
</item>
<item>
<title>Private Multi-Party Neural Network Training over $\mathbb{Z}_{2^k}$ via Galois Rings</title>
<link>https://eprint.iacr.org/2025/331</link>
<guid>https://eprint.iacr.org/2025/331</guid>
<content:encoded><![CDATA[
<div> 关键词: 秘密共享、多党计算、隐私保护机器学习、Shamir秘密分享方案、Galois环

总结:
本文提出了一种基于Shamir秘密分享方案和Galois环\(GR(2^k, d)\)的隐私保护神经网络训练新协议。该协议利用了Galois环的代数结构，仅需对\(2^k\)进行模运算而非素数，使其更适应现代计算机架构。通过将不同训练样本嵌入到表示单个Galois环元素的多项式的不同系数中，实现了并行处理训练数据，并证明此嵌入过程与一次处理一个样本相比，无需额外通信开销。实验在MNIST数据集上进行了不同参与者数量下的私人神经网络训练，结果显示我们的协议相较于现有基于\(\mathbb{F}_p\)实现的优势。 <div>
Secret-sharing-based multi-party computation provides effective solutions for privacy-preserving machine learning. In this paper, we present novel protocols for privacy-preserving neural network training using Shamir secret sharing scheme over Galois rings. The specific Galois ring we use is \(GR(2^k, d)\), which contains $\mathbb{Z}_{2^k}$ as a subring. The algebraic structure of \(GR(2^k, d)\) enables us to benefit from Shamir scheme while performing modulo operations only on \(2^k\) instead of a prime number, making our protocols more compatible with modern computer architectures. We achieve the parallel processing of training data by embedding different training samples into the different coefficients of the polynomial representing a single Galois ring element, and we show that this embedding can be performed with no additional communication overhead compared to processing only one sample at a time. To evaluate our methods, we conduct private training of neural networks on the MNIST dataset between different numbers of participants. The experimental results indicate the advantages of our protocols compared to existing $\mathbb{F}_p$-based implementations in this domain.
]]></content:encoded>
<pubDate>Mon, 24 Feb 2025 02:00:59 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Epidemiological Modeling on Mobile Graphs</title>
<link>https://eprint.iacr.org/2020/1546</link>
<guid>https://eprint.iacr.org/2020/1546</guid>
<content:encoded><![CDATA[
<div> 关键词: RIPPLE、隐私保护、流行病学模拟、社交接触图、PIR-SUM

总结:
RIPPLE 是一个创新的隐私保护流行病学建模框架，能够在不泄露任何个人联系信息的情况下，基于人群的真实社交接触图进行传染病模型的标准模拟。为了实现这一目标，该框架采用了一种名为 PIR-SUM 的新型私人信息检索扩展技术，用于安全地从数据库下载元素总和。文中还包括了一个概念验证的实现，展示了在 7 分钟内完成对 50 万参与者为期两周的模拟，每个参与者之间的通信数据量少于 50 KB，这表明了该方法的有效性和高效性。 <div>
The latest pandemic COVID-19 brought governments worldwide to use various containment measures to control its spread, such as contact tracing, social distance regulations, and curfews. Epidemiological simulations are commonly used to assess the impact of those policies before they are implemented. Unfortunately, the scarcity of relevant empirical data, specifically detailed social contact graphs, hampered their predictive accuracy. As this data is inherently privacy-critical, a method is urgently needed to perform powerful epidemiological simulations on real-world contact graphs without disclosing any sensitive information.

In this work, we present RIPPLE, a privacy-preserving epidemiological modeling framework enabling standard models for infectious disease on a population’s real contact graph while keeping all contact information locally on the participants’ devices. As a building block of independent interest, we present PIR-SUM, a novel extension to private information retrieval for secure download of element sums from a database. Our protocols are supported by a proof-of-concept implementation, demonstrating a 2-week simulation over half a million participants completed in 7 minutes, with each participant communicating less than 50 KB.
]]></content:encoded>
<pubDate>Sun, 13 Dec 2020 16:59:07 +0000</pubDate>
</item>
<item>
<title>Black-box Collision Attacks on Widely Deployed Perceptual Hash Functions</title>
<link>https://eprint.iacr.org/2024/1869</link>
<guid>https://eprint.iacr.org/2024/1869</guid>
<content:encoded><![CDATA[
<div> 关键词：感知哈希函数、客户端扫描、神经网络哈希、NeuralHash、PhotoDNA<br /><br />总结:<br />
本文讨论了感知哈希函数在识别多媒体内容中的应用及其潜在问题。它们常用于检测版权侵犯和非法内容，但设计细节通常保密，缺乏透明度。政府考虑将其应用于客户端扫描（CSS）中，对端到端加密服务的内容进行预加密验证。苹果曾提出基于NeuralHash的CSS方案，但由于隐私和安全顾虑受到强烈批评而撤回，尽管该软件仍存在于Apple设备上。研究发现，NeuralHash存在易构造两个视觉上明显不同的输入产生相同哈希值的问题，对于人脸图像集合，随机碰撞的概率在$2^{16}$大小的输入集里显著增加。此外，还指出其错误否定率也较高。相似攻击也被成功应用于微软提出的广泛部署的PhotoDNA感知哈希函数。这些结果表明，当前的感知哈希函数设计不适合大规模客户端扫描，因为会导致无法接受的高误报率。因此，文章强调需要重新评估感知哈希函数的安全性和可行性，特别是在具有严重后果的大型应用场景下。 <div>
Perceptual hash functions identify multimedia content by mapping similar inputs to similar outputs. They are widely used for detecting copyright violations and illegal content but lack transparency, as their design details are typically kept secret.
Governments are considering extending the application of these functions to Client-Side Scanning (CSS) for end-to-end encrypted services: multimedia content would be verified against known illegal content before applying encryption.
In 2021, Apple presented a detailed proposal for CSS based on the NeuralHash perceptual hash function. After strong criticism pointing out privacy and security concerns, Apple has withdrawn the proposal, but the NeuralHash software is  still present on Apple devices. 
Brute force collisions for NeuralHash (with a 96-bit result) require $2^{48}$ evaluations. Shortly after the publication of NeuralHash, it was demonstrated that it is easy to craft two  colliding inputs for NeuralHash that are perceptually dissimilar. In the context of CSS, this means that it is easy to falsely incriminate someone by sending an innocent picture with the same hash value as illegal content. This work shows a more serious weakness: when inputs are restricted to a set of human faces, random collisions are highly likely to occur in input sets of size $2^{16}$. Unlike the targeted attack, our attacks are black-box attacks: they do not require knowledge of the design of the perceptual hash functions. In addition, we show that the false negative rate is high as well. We demonstrate the generality of our approach by applying a similar attack to PhotoDNA, a widely deployed perceptual hash function proposed by Microsoft with a hash result of 1152 bits. Here we show that specific small input sets result in near-collisions, with similar impact. These results imply that the current designs of perceptual hash function are completely unsuitable for large-scale client scanning, as they would result in an unacceptably high false positive rate. This work underscores the need to reassess the security and feasibility of perceptual hash functions, particularly for large-scale applications where privacy risks and false positives have serious consequences.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 13:00:53 +0000</pubDate>
</item>
<item>
<title>Partial and Fully Homomorphic Matching of IP Addresses Against Blacklists for Threat Analysis</title>
<link>https://eprint.iacr.org/2025/322</link>
<guid>https://eprint.iacr.org/2025/322</guid>
<content:encoded><![CDATA[
<div> 关键词: 个人信息安全、同态加密、IP地址、BFV方法、性能比较

总结:
本文关注于在网络信息安全领域中保护个人隐私的问题，特别是涉及IP地址的情况下。为了解决这一问题，文章提出使用同态加密技术来隐藏IP地址，同时实现对黑名单的匹配检查。具体而言，文中采用了OpenFHE库将网络地址转换为BFV同态加密方法。为了评估BFV方法的性能影响，文章将其与部分同态加密方法（包括Paillier、Damgard-Jurik、Okamoto-Uchiyama、Naccache-Stern和Benaloh）进行了对比测试。结果显示，BFV方法在多数情况下相对于这些部分同态加密方法表现更优。 <div>
In many areas of cybersecurity, we require access to Personally Identifiable Information (PII), such as names, postal addresses and email addresses. Unfortunately, this can lead to data breaches, especially in relation to data compliance regulations such as GDPR. An IP address is a typical identifier which is used to map a network address to a person. Thus, in applications which are privacy-aware, we may aim to hide the IP address while aiming to determine if the address comes from a blacklist. One solution to this is to use homomorphic encryption to match an encrypted version of an IP address to a blacklisted network list. This matching allows us to encrypt the IP address and match it to an encrypted version of a blacklist. In this paper, we use the OpenFHE library \cite{OpenFHE} to convert network addresses into the BFV homomorphic encryption method. In order to assess the performance impact of BFV, it implements a matching method using the OpenFHE library and compares this against the partial homomorphic methods of Paillier, Damgard-Jurik, Okamoto-Uchiyama, Naccache-Stern and Benaloh. The main findings are that the BFV method compares favourably against the partial homomorphic methods in most cases.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 20:36:43 +0000</pubDate>
</item>
<item>
<title>Committing Authenticated Encryption: Generic Transforms with Hash Functions</title>
<link>https://eprint.iacr.org/2025/320</link>
<guid>https://eprint.iacr.org/2025/320</guid>
<content:encoded><![CDATA[
<div> 关键词：authenticated encryption, committing security, generic transform, hash function, MR security

总结:
本文关注了认证加密（AE）方案中的承诺安全性需求，提出了多种基于哈希函数的通用转换方法，以克服现有技术的局限性，包括不完全承诺加密上下文、涉及非标准原语、非黑盒转换以及有限的承诺安全性。研究中，作者构建了三个基础转换方案$\mathsf{HtAE}, \mathsf{AEaH}$和$\mathsf{EtH}$，它们都保证了强大的安全性，并指出$\mathsf{EtH}$可应用于AE和基本隐私加密方案。对于滥用抵抗（MR）安全，作者提出了两个高级哈希基转换方案$\mathsf{AEtH}$和$\mathsf{chaSIV}$。其中，$\mathsf{AEtH}$可以为MR安全的AE方案添加承诺安全性，而$\mathsf{chaSIV}$则是首个能直接将基本AE提升至同时具有承诺和MR安全性的通用转换方案，而且它还可与任意隐私加密方案配合使用。在性能评估方面，$\mathsf{AEaH}$显示出了基础转换中的最高实际效率，而$\mathsf{AEtH}$在MRAE保持型转换中表现出色。MRAE提升转换$\mathsf{chaSIV}$在消息长度超过约360字节时，其性能与MRAE保持型转换相当甚至更优；对于更长的消息，它甚至超越了标准化的非承诺方案$\mathsf{AES}\text{-}\mathsf{GCM}\text{-}\mathsf{SIV}$。<br /><br /> <div>
Recent applications and attacks have highlighted the need for authenticated encryption (AE) schemes to achieve the so-called committing security beyond privacy and authenticity. As a result, several generic solutions have been proposed to transform a non-committing AE scheme to a committing one, for both basic unique-nonce security and advanced misuse-resistant (MR) security. We observe that all existing practical generic transforms are subject to at least one of the following limitations: (i) not committing to the entire encryption context, (ii) involving non-standard primitives, (iii) not being a black-box transform, (iv) providing limited committing security. Furthermore, so far, there has been no generic transform that can directly elevate a basic AE scheme to a committing AE scheme that offers MR security. Our work fills these gaps by developing black-box generic transforms that crucially rely on hash functions, which are well standardized and widely deployed.

First, we construct three basic transforms that combine AE with a single hash function, which we call $\mathsf{HtAE}, \mathsf{AEaH}$ and $\mathsf{EtH}$. They all guarantee strong security, and $\mathsf{EtH}$ can be applied to both AE and basic privacy-only encryption schemes. Next, for MR security, we propose two advanced hash-based transforms that we call $\mathsf{AEtH}$ and $\mathsf{chaSIV}$. $\mathsf{AEtH}$ is an MRAE-preserving transform that adds committing security to an MR-secure AE scheme. $\mathsf{chaSIV}$ is the first generic transform that can directly elevate basic AE to one with both committing and MR security; moreover, $\mathsf{chaSIV}$ also works with arbitrary privacy-only encryption schemes. Both of them feature a simple design and ensure strong security.

For performance evaluation, we compare our transforms to similar existing ones, both in theory and through practical implementations. The results show that our $\mathsf{AEaH}$ achieves the highest practical efficiency among basic transforms, while $\mathsf{AEtH}$ excels in MRAE-preserving transforms. Our MRAE-lifting transform $\mathsf{chaSIV}$ demonstrates comparable performance to MRAE-preserving ones and surpasses them for messages larger than approximately $360$ bytes; for longer messages, it even outperforms the benchmark, non-committing standardized $\mathsf{AES}\text{-}\mathsf{GCM}\text{-}\mathsf{SIV}$.
]]></content:encoded>
<pubDate>Fri, 21 Feb 2025 15:51:43 +0000</pubDate>
</item>
<item>
<title>Stateless Deterministic Multi-Party EdDSA Signatures with Low Communication</title>
<link>https://eprint.iacr.org/2024/358</link>
<guid>https://eprint.iacr.org/2024/358</guid>
<content:encoded><![CDATA[
<div> 关键词: EdDSA、多党派、阈值签名、零知识证明、信息论安全消息认证码

总结:
本文提出了一种新的全阈值环境下，能够容忍最多一名恶意成员破坏的无状态、确定性多党派EdDSA协议。相较于现有的Garillot等人提出的方案，新协议在保持三轮通信结构不变的同时，将通信成本降低了56倍，但计算成本增加了约2.25倍。我们利用信息论安全的消息认证码（IT-MAC）在多验证器场景下对值进行身份验证，并通过改进的多验证器扩展双重认证位（mv-edabits）将其从布尔域转换到算术域。此外，采用伪随机相关函数（PCF）以无状态和确定性的方式生成IT-MAC。结合这些元素，设计了一个用于无状态和确定性随机数生成的多验证器零知识（MVZK）协议。该协议可应用于构建更安全的区块链钱包和托管解决方案，增强密钥保护。<br /><br /> <div>
EdDSA is a standardized signing algorithm, by both the IRTF and NIST, that is widely used in blockchain, e.g., Hyperledger, Cardano, Zcash, etc. It is a variant of the well-known Schnorr signature scheme that leverages Edwards curves. It features stateless and deterministic nonce generation, meaning it does not rely on a reliable source of randomness or state continuity. Recently, NIST issued a call for multi-party threshold EdDSA signatures, with one approach verifying nonce generation through zero-knowledge (ZK) proofs. In this paper, we propose a new stateless and deterministic multi-party EdDSA protocol in the full-threshold setting, capable of tolerating all-but-one malicious corruption. Compared to the state-of-the-art multi-party EdDSA protocol by Garillot et al. (Crypto’21), our protocol reduces communication cost by a factor of 56x while maintaining the same three-round structure, albeit with a roughly 2.25x increase in computational cost. We utilize information-theoretic message authentication codes (IT-MACs) in a multi-verifier setting to authenticate values and transform them from the Boolean domain to the arithmetic domain by refining multi-verifier extended doubly-authenticated bits (mv-edabits). Additionally, we employ pseudorandom correlation functions (PCF) to generate IT-MACs in a stateless and deterministic manner. Combining these elements, we design a multi-verifier zero-knowledge (MVZK) protocol for stateless and deterministic nonce generation. Our protocol can be used to build secure blockchain wallets and custody solutions, enhancing key protection.
]]></content:encoded>
<pubDate>Wed, 28 Feb 2024 07:51:27 +0000</pubDate>
</item>
<item>
<title>HELM: Navigating Homomorphic Encryption through Gates and Lookup Tables</title>
<link>https://eprint.iacr.org/2023/1382</link>
<guid>https://eprint.iacr.org/2023/1382</guid>
<content:encoded><![CDATA[
<div> 关键词：云安全、数据保密性、同态加密、HELM、隐私保护

总结:
随着云计算广泛应用，保障托管给第三方云服务提供商的数据机密性成为关键问题。文章提出了一种名为HELM的框架，该框架利用同态加密技术实现对数据处理过程中的隐私保护。HELM能将使用硬件描述语言（如Verilog）编写的任意程序自动转换为等效的同态电路，支持在加密输入的情况下进行高效评估。它提供了两种加密评估模式：一是基于标准布尔门电路的模式；二是查表模式，通过将多个门电路合并到查找表中以显著减小电路规模。此外，HELM还引入了一个调度器，实现了加密域内的并行处理。通过对ISCAS'85和ISCAS'89基准套件以及实际应用如AES和图像滤波的测试，HELM的表现比先前工作最高提升了65倍。 <div>
As cloud computing continues to gain widespread adoption, safeguarding the confidentiality of data entrusted to third-party cloud service providers becomes a critical concern. While traditional encryption methods offer protection for data at rest and in transit, they fall short when it comes to where it matters the most, i.e., during data processing.

To address this limitation, we present HELM, a framework for privacy-preserving data processing using homomorphic encryption. HELM automatically transforms arbitrary programs expressed in a Hardware Description Language (HDL), such as Verilog, into equivalent homomorphic circuits, which can then be efficiently evaluated using encrypted inputs. HELM features two modes of encrypted evaluation: a) a gate mode that consists of standard Boolean gates, and b) a lookup table mode which significantly reduces the size of the circuit by combining multiple gates into lookup tables. Finally, HELM introduces a scheduler that enables embarrassingly parallel processing in the encrypted domain. We evaluate HELM with the ISCAS'85 and ISCAS'89 benchmark suites as well as real-world applications such as AES and image filtering. Our results outperform prior works by up to $65\times$.
]]></content:encoded>
<pubDate>Fri, 15 Sep 2023 04:57:50 +0000</pubDate>
</item>
<item>
<title>Malleable SNARKs and Their Applications</title>
<link>https://eprint.iacr.org/2025/311</link>
<guid>https://eprint.iacr.org/2025/311</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARKs、malleable SNARKs、recursive SNARKs、adversarial one-way function (AOWF)、post-quantum cryptography

总结:
本文研究了可塑性SNARKs（malleable SNARKs），这是递归SNARK概念的一种推广，允许修改SNARK证明以展示相关陈述，并保持篡改后的证明与新鲜产生的证明无法区分。文章提出了针对通用语言和关系的可塑性SNARK实例化方法，并给出了几个应用案例，包括首个后量子RCCA安全的重随机化和更新加密方案、一种通用的反向防火墙构造以及一种不可链接的（即计算隐藏的）目标可塑性全同态加密方案。技术上，该可塑性SNARK构造依赖于递归证明，但为实现强大篡改后的不可辨识性，需要允许无限递归深度。为了在这种情况下仍能保证合理的可提取性（特别是确保最终能提取到不引用先前SNARK证明的“正确”见证），文章引入了一种名为对抗性单向函数（AOWF）的新颖且通用的计算原语，并提供了一个AOWF候选方案及其在随机预言模型下的安全性证明。 <div>
Succinct non-interactive arguments of knowledge (SNARKs) are variants of non-interactive zero-knowledge proofs (NIZKs) in which complex statements can be proven in a compact way. SNARKs have had tremendous impact in several areas of cryptography, including verifiable computing, blockchains, and anonymous communication. A recurring concept in many applications is the concept of recursive SNARKs, in which a proof references a previous proof to show an evolved statement.

In this work, we investigate malleable SNARKs, a generalization of this concept of recursion. An adaptation of the existing concept of malleable NIZKs, malleable SNARKs allow to modify SNARK proofs to show related statements, but such that such mauled proofs are indistinguishable from “properly generated” fresh proofs of the related statement. We show how to instantiate malleable SNARKs for universal languages and relations, and give a number of applications: the first post-quantum RCCA-secure rerandomizable and updatable encryption schemes, a generic construction of reverse firewalls, and an unlinkable (i.e., computation-hiding) targeted malleable homomorphic encryption scheme.

Technically, our malleable SNARK construction relies on recursive proofs, but with a twist: in order to support the strong indistinguishability properties of mauled and fresh SNARK proofs, we need to allow an unbounded recursion depth. To still allow for a reasonable notion of extractability in this setting (and in particular to guarantee that extraction eventually finishes with a “proper” witness that does not refer to a previous SNARK proof), we rely on a new and generic computational primitive called adversarial one-way function (AOWF) that may be of independent interest. We give an AOWF candidate and prove it secure in the random oracle model.
]]></content:encoded>
<pubDate>Thu, 20 Feb 2025 21:24:29 +0000</pubDate>
</item>
<item>
<title>Practical Zero-Trust Threshold Signatures in Large-Scale Dynamic Asynchronous Networks</title>
<link>https://eprint.iacr.org/2025/297</link>
<guid>https://eprint.iacr.org/2025/297</guid>
<content:encoded><![CDATA[
<div> 关键词: 压力签名, 权限不清除区块链, ECDSA, EdDSA/Schnorr, 安全性<br /><br />总结:

我们提出了在客户端和权限不清除分散式区块链之间分布压力签名过程的新协议，针对ECDSA和EdDSA/Schnorr签名进行了设计。现有的由可信托管人使用的阈值访问架构存在蜜罐问题，资产持有量越大，被攻破的动机越强。我们的实现克服了几个挑战：1）适应异步可靠的广播通信通道，并具有可识别中止、公共可验证性和保证输出交付的特点；2）设计了一个流体协议，支持每轮通信中的后决定动态多数参与签署；3）提供了网络再配置协议，复杂度独立于系统中的客户端数量，并有效支持基于权重的阈值访问结构。此外，协议优化了与客户端交互的过程，去除了零知识证明，并实现了非交互式客户端预签，降低了通信开销并提高了应对高需求时段流量峰值的能力。我们的协议具备UC安全性，并提出了一种新颖的安全假设——稍微增强的ECDSA不可伪造性，为支持并行执行预签操作的阈值ECDSA提供了对256位椭圆曲线的具体安全保证。该协议不仅用于加密货币钱包的安全，还展示了如何应用于跨链场景，如去中心化桥接、未来交易和钱包转移，旨在提高多区块链环境下的安全性、可扩展性和灵活性，尤其对于去中心化金融（DeFi）生态系统具有重要意义。 <div>
Threshold signatures have become a critical tool in cryptocurrency systems, offering enhanced security by distributing the signing process among multiple signers. In this work, we distribute this process between a client and a permissionless decentralized blockchain, and present novel protocols for ECDSA and EdDSA/Schnorr signatures in this setting. Typical threshold access architectures used by trusted custodians suffer from the honeypot problem, wherein the more assets the custodian holds, the greater the incentive of compromising it.

Implementing threshold signatures over permissionless blockchains poses a few challenges.
First, existing networks typically work over an asynchronous reliable broadcast communication channel. Accordingly, our protocol is implemented over such a channel. As a result, it also benefits from identifiable abort, public verifiability, and guaranteed output delivery, and the client benefits from censorship resistance of blockchain systems.
Second, upon signing each block, the participating quorum may dynamically change and is post-determined.
Therefore, we design a fluid protocol, that supports a post-determined dynamic quorum in each communication round, thereby complying with existing broadcast channel implementations. Third, in permissionless networks, parties may join, leave, and change their stake. Therefore, we offer protocols for network reconfiguration, with complexity independent of the number of clients in the system, and our protocol efficiently supports a weighted threshold access structure for the network. Specifically, the complexity of distributed key generation and presign only depends on the number of parties and not on the overall weight, and the amortized cost of sign only depends on the individual weight.

Furthermore, our protocol introduces key improvements, including the removal of zero-knowledge proofs towards the client, and presigns with a non-interactive client. For Schnorr, the presigns are client-independent, and can be collected by the blockchain in a common pool, available for all clients in the system. These optimizations reduce communication overhead and improve the system's ability to handle traffic spikes during high-demand periods.

Our protocol is UC-secure, and is therefore natively designed for multiple clients to use the system in parallel. Notably, we propose a novel assumption, Slightly-Enhanced ECDSA Unforgeability, offering concrete security for 256-bit elliptic curves for threshold ECDSA with support for parallel execution of presigns.

In addition to securing cryptocurrency wallets, we demonstrate how our protocol enables various cross-chain applications, such as decentralized bridges, future transactions, andwallet transfer. Our system is designed for interoperability across multiple blockchains, enhancing security, scalability, and flexibility for decentralized finance (DeFi) ecosystems.
]]></content:encoded>
<pubDate>Thu, 20 Feb 2025 08:21:42 +0000</pubDate>
</item>
<item>
<title>Anamorphic-Resistant Encryption; Or Why the Encryption Debate is Still Alive</title>
<link>https://eprint.iacr.org/2025/293</link>
<guid>https://eprint.iacr.org/2025/293</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密、政府解密权限、语义安全、后门、Anamorphic-resistant (AR)加密

<br /><br />总结:
这篇文章探讨了关于政府是否应该有权解密公民私人信息的问题。传统观点认为，语义安全性使得总会存在某种形式的隐写术，因此为保证安全性不应在加密方案中添加后门，因为这只会削弱“好人”的安全性，而“坏人”可以轻易规避审查。然而，本文提出了三个假设世界：Dictatoria（政府完全控制，无法方便使用隐写术）、Warrantland（有制衡机制，需要用户配合但无便捷隐写术）和Privatopia（隐私至上，内置高效率隐写术）。作者通过定义并设计名为Anamorphic-resistant (AR)的新型加密方案，给出了这三个世界可能性的有力证据。与文献中研究过的可塑性加密方案不同，任何试图利用AR加密方案进行隐写通信的行为都将变得非常困难或极其缓慢。这一发现重新从技术层面开启了加密辩论。 <div>
Ever since the introduction of encryption, society has been divided over whether the government (or law enforcement agencies) should have the capability to decrypt private messages (with or without a war- rant) of its citizens. From a technical viewpoint, the folklore belief is that semantic security always enables some form of steganography. Thus, adding backdoors to semantically secure schemes is pointless: it only weakens the security of the “good guys”, while “bad guys” can easily circumvent censorship, even if forced to hand over their decryption keys. 

In this paper we put a dent in this folklore. We formalize three worlds: Dictatoria (“dictator wins”: no convenient steganography, no user co- operation needed), Warrantland (“checks-and-balances”: no convenient steganography, but need user’s cooperation) and Privatopia (“privacy wins”: built-in, high-rate steganography, even if giving away the decryption key). We give strong evidence that all these worlds are possible, thus reopening the encryption debate on a technical level. 

Our main novelty is the definition and design of special encryption schemes we call anamorphic-resistant (AR). In contrast to so called “anamorphic schemes”, — which were studied in the literature and form the basis of Privatopia, — any attempt to steganographically communicate over an AR-encryption scheme will be either impossible or hugely slow (depending on the definitional details).
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 21:48:22 +0000</pubDate>
</item>
<item>
<title>Dynamic Decentralized Functional Encryption: Generic Constructions with Strong Security</title>
<link>https://eprint.iacr.org/2025/290</link>
<guid>https://eprint.iacr.org/2025/290</guid>
<content:encoded><![CDATA[
<div> 关键词: 动态分布式功能性加密 (DDFE)，功能隐藏，学习与错误 (LWE) 假设，内积，属性权重和访问控制

总结:
本文提出了新的通用编译器，这些编译器在利用现有文献中的方案实例化后，能在安全级别、计算假设以及功能方面超越当前最先进的动态分布式功能性加密（DDFE）技术。具体来说，我们首次实现了在标准模型及更强的功能隐藏设置下适应性安全的DDFE方案，用于内积运算，保证了消息及所评估函数的隐私。此外，我们还展示了首个基于LWE假设在标准模型下证明安全性的DDFE内积方案。最后，我们给出了首个带有属性权重和访问控制的DDFE构造（尽管存在一些限制）。而此前的所有构造仅能提供选择性安全性，依赖于基于配对的群组假设，并无法实现访问控制。 <div>
Dynamic Decentralized Functional Encryption (DDFE) is a generalization of Functional Encryption which allows multiple users to join the system dynamically without interaction and without relying on a trusted third party.  Users can independently encrypt their inputs for a joint evaluation under functions embedded in functional decryption keys; and they keep control on these functions as they all have to contribute to the generation of the functional keys.
 
In this work, we present new generic compilers which, when instantiated with existing schemes from the literature, improve over the state-of-the-art in terms of security, computational assumptions and functionality. Specifically, we obtain the first adaptively secure DDFE schemes for inner products in both the standard and the stronger function-hiding setting which guarantees privacy not only for messages but also for the evaluated functions. Furthermore, we present the first DDFE for inner products whose security can be proven under the LWE assumption in the standard model. Finally, we give the first construction of a DDFE for the attribute-weighted sums functionality with attribute-based access control (with some limitations). All prior constructions guarantee only selective security, rely on group-based assumptions on pairings, and cannot provide access control.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 15:57:18 +0000</pubDate>
</item>
<item>
<title>Verifiable Computation for Approximate Homomorphic Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/286</link>
<guid>https://eprint.iacr.org/2025/286</guid>
<content:encoded><![CDATA[
<div> 关键词：homomorphic encryption, RingLWE, CKKS方案, polynomial ring, proof system

总结:
本文针对基于同态加密（HE）方案的计算正确性验证问题提出了一种新解决方案，特别是处理RingLWE基础上的CKKS方案中的近似算术运算。该方法能在多项式环$R_q$中高效地处理密文算术，无需额外的仿真开销，并能以较小的成本管理密文维护操作，如模切换、密钥切换和重缩放。主要成果是一个简洁的论证系统，能够有效地处理关于$R_q$上的算术运算和范围检查。为构建这一论证系统，文章设计了新的多项式交互式Oracle证明（PIOPs）和支持$R_q$上多项式的多线性多项式承诺，与以往仅关注有限域的工作不同。通过实现和实验，我们验证了本方法的具体复杂度，相较于当前RNS方案的可验证HE的最优实践，对于小电路，我们的方法展现出相似性能，同时能更有效地扩展到更大的电路，这是先前构造所面临的重大挑战，因为它们需要验证如重新线性化等程序。 <div>
We address the problem of proving the validity of computation on ciphertexts of homomorphic encryption (HE) schemes, a feature that enables outsourcing of data and computation while ensuring both data privacy and integrity.
We propose a new solution that handles computations in RingLWE-based schemes, particularly the CKKS scheme for approximate arithmetic. Our approach efficiently handles ciphertext arithmetic in the polynomial ring $R_q$ without emulation overhead and manages ciphertexts maintenance operations, such as modulus switching, key switching, and rescaling, with small cost.
Our main result is a succinct argument that efficiently handles arithmetic computations and range checks over the ring $R_q$. To build this argument system, we construct new polynomial interactive oracle proofs (PIOPs) and multilinear polynomial commitments supporting polynomials over $R_q$, unlike prior work which focused on finite fields. We validate the concrete complexity of our approach through implementation and experimentation. Compared to the current state-of-the-art on verifiable HE for RNS schemes, we present similar performance for small circuits while being able to efficiently scale to larger ones, which was a major challenge for previous constructions as it requires verifying procedures such as relinearization.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 09:36:05 +0000</pubDate>
</item>
<item>
<title>S2DV: Scalable and Secure DAO Voting</title>
<link>https://eprint.iacr.org/2025/284</link>
<guid>https://eprint.iacr.org/2025/284</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Autonomous Organization (DAO), voting system, scalability, security, Groth16 zk-SNARKs, exponential ElGamal encryption算法

总结:
本文提出了一种针对去中心化自治组织(DAO)的可扩展且安全的投票系统。该系统利用Groth16 zk-SNARKs保证了投票过程的安全性，确保了加密的选票准确反映选民的投票权、仅加密有效的非负投票值以及正确执行同态求和。同时，通过应用指数ElGamal加密算法实现离线计算，减少了区块链的计算成本，实现了决策制定的规模化。实验证明，该S2DV协议的证明验证速度极快，非常适用于可扩展的DAO投票系统，同时保持了选举的安全性。 <div>
Decentralized Autonomous Organization operates without a central entity, being owned and governed collectively by its members. In this organization, decisions are carried out automatically through smart contracts for routine tasks, while members vote for unforeseen issues. Scalability in decision-making through voting on proposals is essential to accommodate a growing number of members without sacrificing security. This paper addresses this challenge by introducing a scalable and secure DAO voting system that ensures security through Groth16 zk-SNARKs and exponential ElGamal encryption algorithm while achieving scalability by verifiably delegating heavy computations to untrusted entities. While offline computation on the exponential ElGamal homomorphic encryption algorithm is enabled to reduce the computational cost of the blockchain, Groth16 is allowed to maintain robust off-chain calculation without revealing any further details. Specifically, the Groth16 proof guarantees that (i) the encrypted votes accurately reflect the voter's voting power, ensuring no unauthorized weight manipulation; (ii) only valid non-negative vote values are encrypted, preventing unintended or malicious vote tampering; and (iii) the homomorphic summation is performed correctly.  The implementation shows that the proofs are verified remarkably fast, making the S2DV protocol highly suitable for scalable DAO voting, while preserving the security of the election.
]]></content:encoded>
<pubDate>Wed, 19 Feb 2025 07:47:51 +0000</pubDate>
</item>
<item>
<title>Breaking and Fixing Anonymous Credentials for the Cloud</title>
<link>https://eprint.iacr.org/2019/1061</link>
<guid>https://eprint.iacr.org/2019/1061</guid>
<content:encoded><![CDATA[
<div> 关键词: 属性基凭证(ABC)、加密属性基凭证(EABC)、云计算提供商、安全性攻击、修订模型

总结:
文章讨论了属性基凭证(ABC)系统及其在实际中的应用，特别是在Krenn等人提出的加密属性基凭证(EABC)中，计算被外包给半可信的云钱包以提高效率并实现隐私保护的身份管理服务。然而，文章指出了一个简单的攻击方式：当云钱包与另一用户合谋时，可以泄露用户的属性信息，这是原模型未考虑的情况。因此，文章对Krenn等人的模型和构造进行了修订，成功防止了上述攻击，并移除了原有构架中关于钱包和服务提供者或发行者之间不串通的假设。同时，新协议仍保持高效性，用户端的计算工作仅涉及一次指数运算，整体效率与Krenn等人原始工作相当。 <div>
In an attribute-based credential (ABC) system, users obtain a digital certificate on their personal attributes, and can later prove possession of such a certificate in an unlinkable way, thereby selectively disclosing chosen attributes to the service provider. Recently, the concept of encrypted ABCs (EABCs) was introduced by Krenn et al. at CANS 2017, where virtually all computation is outsourced to a semi-trusted cloud-provider called wallet, thereby overcoming existing efficiency limitations on the user’s side, and for the first time enabling “privacy-preserving identity management as a service”.
While their approach is highly relevant for bringing ABCs into the real world, we present a simple attack allowing the wallet to learn a user's attributes when colluding with another user -- a scenario which is not covered by their modeling but which needs to be considered in practice. We then revise the model and construction of Krenn et al. in various ways, such that the above attack is no longer possible. Furthermore, we also remove existing non-collusion assumptions between wallet and service provider or issuer from their construction.  Our protocols are still highly efficient in the sense that the computational effort on the end user side consists of a single exponentiation only, and otherwise efficiency is comparable to the original work of Krenn et al.
]]></content:encoded>
<pubDate>Sat, 21 Sep 2019 11:55:46 +0000</pubDate>
</item>
<item>
<title>Transistor: a TFHE-friendly Stream Cipher</title>
<link>https://eprint.iacr.org/2025/282</link>
<guid>https://eprint.iacr.org/2025/282</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密(FHE), 通信开销, 变换加密, Transistor, TFHE框架

总结:
Transistor是一种针对TFHE全同态加密框架设计的高效流密码，旨在解决FHE中因数据加密导致的通信开销问题。Transistor工作在$\mathbb{F}_{17}$域上，优化了TFHE性能。该流密码的关键组件采用TFHE友好的LFSR实现技术来低成本地增加状态大小，并使用类似于AES轮函数的非线性变换来更新仅有的、在TFHE中对应于昂贵可编程引导操作的小型有限状态机。与SNOW或LEX等其他流密码不同，Transistor提供了信息论安全证明，表明攻击者无法从三个或更少连续密钥流输出中获取关于秘密密钥的任何信息。通过对潜在相关性的深入分析，进一步限制了恢复秘密密钥所需的最小密钥流长度。在实际应用中，Transistor的实现显著优于现有TFHE变换加密技术，实现了超过60位/秒的标准CPU吞吐量，同时避免了需要昂贵的初始化过程。 <div>
Fully Homomorphic Encryption (FHE) allows computations on encrypted data without requiring decryption, ensuring data privacy during processing.  However, FHE introduces a significant expansion of ciphertext sizes compared to plaintexts, which results in higher communication. A practical solution to mitigate this issue is  transciphering, where only the master key is homomorphically encrypted, while the actual data is encrypted using a symmetric cipher, usually a stream cipher. The server then homomorphically evaluates the stream cipher to convert the encrypted data into a homomorphically encrypted form.

We introduce Transistor, a stream cipher specifically designed for efficient homomorphic evaluation within the TFHE scheme, a widely-used FHE framework known for its fast bootstrapping and ability to handle low-precision data. Transistor operates on $\mathbb{F}_{17}$ which is chosen to optimize TFHE performances. Its components are carefully engineered to both control noise growth and provide strong security guarantees. First, a simple TFHE-friendly implementation technique for LFSRs allows us to use such components to cheaply increase the state size. At the same time, a small Finite State Machine is the only part of the state updated non-linearly, each non-linear operation corresponding in TFHE to a rather expensive Programmable Bootstrapping. This update is done using an AES-round-like transformation. But, in contrast to other stream ciphers like SNOW or LEX, our construction comes with information-theoretic security arguments proving that an attacker cannot obtain any information about the secret key from three or fewer consecutive keystream outputs. These information-theoretic arguments are then combined with a thorough analysis of potential correlations to bound the minimal keystream length required for recovering the secret key.

Our implementation of Transistor significantly outperforms the state of the art of TFHE transciphering, achieving a throughput of over 60 bits/s on a standard CPU, all while avoiding the need for an expensive initialization process.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 19:21:38 +0000</pubDate>
</item>
<item>
<title>Tighter Control for Distributed Key Generation: Share Refreshing and Expressive Reconstruction Policies</title>
<link>https://eprint.iacr.org/2025/277</link>
<guid>https://eprint.iacr.org/2025/277</guid>
<content:encoded><![CDATA[
<div> 关键词: 私钥管理、安全性、分布式秘密共享、Shamir's secret sharing、刷新机制、访问结构、阈值访问树

<br /><br />总结:
本文针对私钥安全管理问题，特别是对于公众而言，丢失私钥可能导致不可逆资产损失的挑战。文章关注了传统的托管方式存在的安全风险，并提出了一种基于Shamir's secret sharing的分布式、可验证和可扩展的密钥恢复方案的扩展，该方案通过将信任分散到多个参与方来提高安全性。关键创新在于引入了一个刷新阶段，确保私钥份额的安全性，防止长期暴露。文中探讨了三种不同的份额刷新方法，分析并比较了它们的安全保证和计算复杂度。此外，为了实现对密钥重构更细粒度的控制，该协议还被扩展以支持更复杂的访问结构，特别关注了阈值访问树的应用。 <div>
The secure management of private keys is a fundamental challenge, particularly for the general public, as losing these keys can result in irreversible asset loss. Traditional custodial approaches pose security risks, while decentralized secret sharing schemes offer a more resilient alternative by distributing trust among multiple parties. In this work, we extend an existing decentralized, verifiable, and extensible cryptographic key recovery scheme based on Shamir's secret sharing. We introduce a refresh phase that ensures proactive security, preventing long-term exposure of secret shares. Our approach explores three distinct methods for refreshing shares, analyzing and comparing their security guarantees and computational complexity. Additionally, we extend the protocol to support more complex access structures, with a particular focus on threshold access trees, enabling fine-grained control over key reconstruction.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 14:56:47 +0000</pubDate>
</item>
<item>
<title>White-Box Watermarking Signatures against Quantum Adversaries and Its Applications</title>
<link>https://eprint.iacr.org/2025/265</link>
<guid>https://eprint.iacr.org/2025/265</guid>
<content:encoded><![CDATA[
<div> 关键词：软件水印、公钥加密、量子对手、数字签名、白盒提取

总结:
本文探讨了针对量子敌手的白盒水印技术在数字签名中的应用。研究内容包括构造能在保证签名功能完整性的前提下，从海盗量子电路中安全提取嵌入水印的白盒水印签名方案，同时确保对带有水印的签名函数的黑盒访问不会泄露嵌入信息。文章指出，在签名场景下，隐私保护问题相比公钥加密更为关键，并提出了利用学习错误（LWE）假设和量子全同态加密构建的安全方案。此外，文中还关注了签名的通用复制保护概念，定义了一个不改变验证密钥或验证算法，将任何量子安全签名方案转化为具有复制保护特性的机制。然而，文章进一步证明了对于所有量子安全签名实现普遍复制保护是不可能的，这一结论基于其提出的对抗量子敌手的白盒水印签名方案。 <div>
Software watermarking for cryptographic functionalities enables embedding an arbitrary message (a mark) into a cryptographic function. An extraction algorithm, when provided with a (potentially unauthorized) circuit, retrieves either the embedded mark or a special symbol unmarked indicating the absence of a mark. It is difficult to modify or remove the embedded mark without destroying the functionality of a marked function. Previous works have primarily employed black-box extraction techniques, where the extraction algorithm requires only input-output access to the circuit rather than its internal descriptions (white-box extraction). Zhandry (CRYPTO 2021) identified several challenges in watermarking public-key encryption (PKE) with black-box extraction and introduced the notion of privacy for white-box watermarking against classical adversaries. Kitagawa and Nishimaki (Journal of Cryptology 37(3)) extended watermarking techniques to pseudorandom functions (PRFs) and PKE in the presence of quantum adversaries, enabling extraction from pirate quantum circuits but failing to achieve privacy.

In this work, we investigate white-box watermarking for digital signatures secure against quantum adversaries. Our constructions enable the extraction of embedded marks from the description of a pirate quantum circuit that produces valid signatures while ensuring that black-box access to a marked signing function does not reveal information about the embedded mark. We define and construct white-box watermarking signatures that are secure against quantum adversaries, leveraging the leaning with errors (LWE) assumption and quantum fully homomorphic encryption. Furthermore, we highlight that privacy concerns are even more critical in the context of signatures than in PKE. We also present a compelling practical application of white-box watermarking signatures.

Additionally, we explore the concept of universal copy protection for signatures. We define universal copy protection as a mechanism that transforms any quantumly secure signature scheme into a copy-protected variant without altering the verification key or verification algorithm. This approach is preferable to developing specific copy-protected signature schemes, as it allows existing schemes to be secured without modifying their published verification keys. We demonstrate that universal copy protection for all quantum secure signatures is impossible by leveraging our white-box watermarking signatures secure against quantum adversaries.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 05:01:32 +0000</pubDate>
</item>
<item>
<title>HasteBoots: Proving FHE Bootstrapping in Seconds</title>
<link>https://eprint.iacr.org/2025/261</link>
<guid>https://eprint.iacr.org/2025/261</guid>
<content:encoded><![CDATA[
<div> 关键词：Fully Homomorphic Encryption (FHE)，验证完整性，bootstrapping，HasteBoots，zkVM，SNARKs，证明生成时间，效率提升，可扩展性，隐私保护计算。

<br /><br />总结: 本文提出了一个名为HasteBoots的新颖方案，用于解决全同态加密（FHE）中计算完整性的验证问题，特别是针对FHE中最耗时的操作——引导（bootstrapping）。现有的方法如基于zkVM的解决方案和通用SNARKs在证明生成时间上存在效率低下问题，可能需要数小时至数天。通过定制化的多项式交互式Oracle证明和优化的多项式承诺方案，HasteBoots实现了对FHE引导操作在几秒内完成证明生成，显著优于现有技术。这表明了实现可扩展且高效的可验证FHE的可能性，为实践中的隐私保护计算铺平道路。 <div>
Fully Homomorphic Encryption (FHE) enables computations on encrypted data, ensuring privacy for outsourced computation. However, verifying the integrity of FHE computations remains a significant challenge, especially for bootstrapping, the most computationally intensive operation in FHE. Prior approaches, including zkVM-based solutions and general-purpose SNARKs, suffer from inefficiencies, with proof generation times ranging from several hours to days. In this work, we propose HasteBoots, a succinct argument tailored for FHE operations. By designing customized polynomial interactive oracle proofs and optimized polynomial commitment schemes, HasteBoots achieves proof generation in a few seconds for FHE bootstrapping, significantly outperforming existing methods. Our approach demonstrates the potential for scalable and efficient verifiable FHE, paving the way for practical, privacy-preserving computations.
]]></content:encoded>
<pubDate>Tue, 18 Feb 2025 02:20:55 +0000</pubDate>
</item>
<item>
<title>TFHE Gets Real: an Efficient and Flexible Homomorphic Floating-Point Arithmetic</title>
<link>https://eprint.iacr.org/2025/257</link>
<guid>https://eprint.iacr.org/2025/257</guid>
<content:encoded><![CDATA[
<div> 关键词: 浮点数运算、全同态加密(FHE)、TFHE、精度、计算速度

总结:
本文关注于在全同态加密（FHE）领域中实现浮点数运算是如何至关重要的，特别是在保护机器学习中的用户隐私方面。文章以TFHE为例，开发了新的同态算子，旨在构建精确且可适应的同态浮点运算。尽管面临如小消息空间和计算过程中缺乏信息等挑战，研究者仍成功为常见的浮点数精度（例如32位和64位）确定了参数，并实现了较高的计算速度：在多线程环境下，32位浮点数加法可在2.5秒内完成，乘法大约需要1秒。这些实测结果表明，提出的方案具有高效性和实用性，显著超越了先前的工作，从而在理论上与实际应用之间架起了一座桥梁，使FHE在现实场景中的运用变得更加可行。 <div>
Floating-point arithmetic plays a central role in computer science and is used in various domains where precision and computational scale are essential. One notable application is in machine learning, where Fully Homomorphic Encryption (FHE) can play a crucial role in safeguarding user privacy. In this paper, we focus on TFHE and develop novel homomorphic operators designed to enable the construction of precise and adaptable homomorphic floating-point operations. Integrating floating-point arithmetic within the context of FHE is particularly challenging due to constraints such as small message space and the lack of information during computation. Despite these challenges, we were able to determine parameters for common precisions (e.g., 32-bit, 64-bit) and achieve remarkable computational speeds, with 32-bit floating-point additions completing in 2.5 seconds and multiplications in approximately 1 second in a multi-threaded environment. These metrics provide empirical evidence of the efficiency and practicality of our proposed methods, which significantly outperform previous efforts. Our results demonstrate a significant advancement in the practical application of FHE, making it more viable for real-world scenarios and bridging the gap between theoretical encryption techniques and practical usability.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 14:59:27 +0000</pubDate>
</item>
<item>
<title>Inaccessible Entropy for Watermarking Generative Agents</title>
<link>https://eprint.iacr.org/2025/256</link>
<guid>https://eprint.iacr.org/2025/256</guid>
<content:encoded><![CDATA[
<div> 关键词：语言模型、生成式代理、不可伪造水印、无失真、公开验证

总结:
本文提出了一种针对语言模型和生成式代理的无失真、不可伪造水印构造方法。该水印方案确保了水印无法被对手有效伪造或在不显著降低模型输出质量的情况下移除。水印输出保持无失真，即水印算法不会明显改变模型输出的质量，而且没有公共检测密钥的攻击者无法有效区分是否添加了水印的输出。水印方案的核心在于将消息与可公开验证的数字签名嵌入到生成的模型输出中。在检测阶段，任何拥有公钥的授权实体都可以提取并验证这些信息。文章证明，基于标准密码学假设——单向函数的存在，可以构建这样的无失真、不可伪造水印方案。该框架依赖于分析基于单向函数的计算熵概念的水印方案的不可访问熵。 <div>
In this work, we construct distortion-free and unforgeable watermarks for language models and generative agents. The watermarked output cannot be forged by a adversary nor removed by the adversary without significantly degrading model output quality. That is, the watermarked output is distortion-free: the watermarking algorithm does not noticeably change the quality of the model output and without the public detection key, no efficient adversary can distinguish output that is watermarked from outputs which are not. The core of the watermarking schemes involve embedding a message and publicly-verifiable digital signature in the generated model output. The message and signature can be extracted during the detection phase and verified by any authorized entity that has a public key. We show that, assuming the standard cryptographic assumption of one-way functions, we can construct distortion-free and unforgeable watermark schemes. Our framework relies on analyzing the inaccessible entropy of the watermarking schemes based on computational entropy notions derived from the existence of one-way functions.
]]></content:encoded>
<pubDate>Mon, 17 Feb 2025 13:09:06 +0000</pubDate>
</item>
<item>
<title>Masquerade: Verifiable Multi-Party Aggregation with Secure Multiplicative Commitments</title>
<link>https://eprint.iacr.org/2021/1370</link>
<guid>https://eprint.iacr.org/2021/1370</guid>
<content:encoded><![CDATA[
<div> 关键词: 众包数据聚合、隐私保护、公共审计、可验证性、分布式账本

总结:
本文提出两种名为Masquerade和zk-Masquerade的协议，用于计算私有统计数据（如求和、平均值和直方图）的同时，不泄露参与者的原始数据。为确保数据聚合的完整性，文中设计了一种定制化的乘法承诺方案，并将所有参与者的承诺发布到分布式账本上，以实现公众可验证性。针对恶意参与者可能尝试破坏聚合结果的问题，zk-Masquerade采用两种零知识证明协议，确保共享数据点的有效性并在聚合前进行验证，从而支持广泛的数量和类别研究。实验中，使用了同态加密和承诺对不同数量的参与者进行了评估，并分析了协议运行时间和通信成本。 <div>
In crowd-sourced data aggregation over the Internet, participants share their data points with curators. However, a lack of strong privacy guarantees may discourage participation, which motivates the need for privacy-preserving aggregation protocols. Moreover, existing solutions remain limited with respect to public auditing without revealing the participants' data. In realistic applications, however, there is an increasing need for public verifiability (i.e., verifying the protocol correctness) while preserving the privacy of the participants' inputs, since the participants do not always trust the data curators. At the same time, while publicly distributed ledgers may provide public auditing, these schemes are not designed to protect sensitive information.

In this work, we introduce two protocols, dubbed Masquerade and zk-Masquerade, for computing private statistics, such as sum, average, and histograms, without revealing anything about participants' data. We propose a tailored multiplicative commitment scheme to ensure the integrity of data aggregations and publish all the participants' commitments on a ledger to provide public verifiability. zk-Masquerade detects malicious participants who attempt to poison the aggregation results by adopting two zero-knowledge proof protocols that ensure the validity of shared data points before being aggregated and enable a broad range of numerical and categorical studies. In our experiments, we use homomorphic ciphertexts and commitments for a variable number of participants and evaluate the runtime and the communication cost of our protocols.
]]></content:encoded>
<pubDate>Tue, 12 Oct 2021 06:24:19 +0000</pubDate>
</item>
<item>
<title>K-Linkable Ring Signatures and Applications in Generalized Voting</title>
<link>https://eprint.iacr.org/2025/243</link>
<guid>https://eprint.iacr.org/2025/243</guid>
<content:encoded><![CDATA[
<div> 关键词：Linkable Ring Signatures (LRS)，$k$-Linkable Ring Signatures ($k$-LRS)，投票隐私，匿名性，集体$k$-链接性

总结:

本文提出了$k$-可链接环签名($k$-LRS)这一新型密码学原语，用于在多样化的投票场景中同时实现匿名性和隐私保护。传统的可链接环签名(LRS)适用于防止重复投票的多数制选举，但在排名投票等更复杂的规则下，会暴露选民个体的投票偏好。$k$-LRS具有$k$级匿名性和$k$级链接性特点：用户最多可以匿名签署$k$次，使得即使是无限制的对手也无法关联其签名（$k$级匿名性）；若任何签名人签超过$k$次，则其所有签名将被公开链接（个体$k$-链接性），并且任何$c$个签名人无法生成多于$k\cdot c$个未链接的签名（集体$k$-链接性）。文章提供了基于DDH和SIS（因此是后量子安全的）两种$k$-LRS构造方法，并展示了如何将其应用于包括得分投票、多轮投票和博尔达计数等多种投票规则中。提出的协议为非交互式投票，即每个选民只需在公告板上发布一条消息，这突显了$k$-LRS在区块链治理等场景中的应用潜力。 <div>
$\textit{Linkable ring signatures}$ (LRS) allow a user to sign anonymously on behalf of a ring, while maintaining linkability—two signatures from the same signer are publicly identified, i.e., linked. This linkability makes LRS suitable to prevent double-voting in classical, $\textit{plurality}$ voting protocols—each voter casts one vote and the candidate with the most votes wins the election. 

    Several voting scenarios rely on (generalized) rules rather than plurality. For example, in $\textit{ranked voting}$, voters submit a ranking of the candidates, and the outcome is a function of these rankings. Such generalized voting rules are common in social choice theory, and have recently found their way into blockchain governance, e.g., for prioritizing (voting on) proposed (candidate)  projects. However, unlike plurality voting, using LRS for voters to sign their votes (rankings) does not guarantee vote privacy as one can observe the rankings of each individual voter, which, depending on the scoring rule, is more information than what the outcome of the election offers. 

We introduce $k$-$\textit{linkable ring signatures}$ ($k$-LRS) as a primitive for simultaneously achieving anonymity and privacy in generalized voting. A $k$-LRS scheme has the following properties: 
   ($k$-)$\textit{Anonymity}$: a user can sign anonymously (on behalf of the ring) up to $k$ times, so that even an unbounded adversary cannot link his signatures.
   ($k$-)$\textit{Linkability}$: If any signer signs more than $k$ times, all his signatures are publicly linked $\textit{(individual $k$-linkability)}$; and, any set of $c$ signers cannot generate more than $k\cdot c$ unlinked signatures $\textit{(collective $k$-linkability)}$.

    We provide two constructions of $k$-LRS: one is from the DDH, and the other is from SIS (hence post-quantum). Finally, we show how $k$-LRS can be applied to a broad range of voting rules, including $\textit{score voting}$, $\textit{multi-voting}$, and $\textit{Borda}$. Our protocols are non-interactive voting—each voter just posts a message on a bulletin board—which highlights the potential of $k$-LRS in blockchain-governance scenarios.
]]></content:encoded>
<pubDate>Sun, 16 Feb 2025 05:14:11 +0000</pubDate>
</item>
<item>
<title>IBE-IBE: Intent-Based Execution through Identity-Based Encryption and Auctions</title>
<link>https://eprint.iacr.org/2025/241</link>
<guid>https://eprint.iacr.org/2025/241</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式、无领导节点、密封投标拍卖、动态定价、区块链网络、多党计算(MPC)、身份基加密(IBE)、公平性、去中心化、价格发现透明度、安全性、竞争、意图保密、全同态加密(FHE)、可信执行环境(TEE)、 frontrunning风险、中央集权化、快速结算、去中心金融(DeFi)

<br /><br />总结:

本文提出了一种基于区块链网络的分布式、无领导节点的密封投标拍卖模型，用于动态定价意图。该模型利用多党计算(MPC)和身份基加密(IBE)来提升定价效率并确保公平与去中心化。通过解决当前集中式或静态定价机制的脆弱性，我们的方法促进了透明、安全且具有竞争力的价格发现过程。同时，我们通过多党计算(MPC)、全同态加密(FHE)和可信执行环境(TEE)进一步增强了意图信息的机密性，有效降低了frontrunning风险和中央集权化的隐患，保持了去中心金融(DeFi)中至关重要的快速结算时间。 <div>
This paper introduces a decentralized and leaderless sealed bid auction model for dynamic pricing of intents across blockchain networks. We leverage Multi-Party Computation (MPC) and Identity-Based Encryption (IBE) to improve pricing while ensuring fairness and decentralization. By addressing the vulnerabilities of current centralized or static pricing mechanisms, our approach fosters transparent, secure, and competitive price discovery. We further enhance the confidentiality of intents through Multi-Party Computation (MPC), Fully Homomorphic Encryption (FHE), and Trusted Execution Environments (TEE). Our novel methodology mitigates the risks of frontrunning and centralization while preserving the rapid settlement times essential to decentralized finance (DeFi).
]]></content:encoded>
<pubDate>Sat, 15 Feb 2025 22:52:28 +0000</pubDate>
</item>
<item>
<title>DART: Decentralized, Anonymous, and Regulation-friendly Tokenization</title>
<link>https://eprint.iacr.org/2025/239</link>
<guid>https://eprint.iacr.org/2025/239</guid>
<content:encoded><![CDATA[
<div> 关键词: DART、匿名支付系统、多资产类型、非交互式支付、可逆性机制

总结:
DART是一个全新的完全匿名、基于账户的支付系统，它兼顾了现实世界的多种考量因素，包括监管合规性，并实现了常量级别的交易大小。该系统支持多种资产类型，允许用户发行链上资产，如代币化的现实世界资产。通过隐藏资产类型、交易金额、余额以及发送者和接收者的身份信息，DART确保了交易的机密性和匿名性，并保证了交易间的不可链接性。同时，系统提供了一种针对特定资产的审计机制，使得发行人可以为他们发行的资产指定特定的审计员，同时保护审计员的身份隐私，以实现资产类型隐私。只有指定的审计员才能解密与其关联资产相关的交易，并且用户能在交易中有效地证明（隐藏的）资产类型与（隐藏的）指定审计员之间的关联。

DART还支持非交互式支付，即使接收方离线，在线的发送方也能提交交易，同时还结合了一个接收方确认机制，体现了现实中接收方需确认或否认接收到的交易这一合规要求。据我们所知，这是无许可环境中首个此类方案。为了应对各种可能情况，DART还包括了一个可逆性机制，使发送方可以在接收方未确认的情况下从待处理交易中取回资金。此外，它还提供了保护隐私的资产余额证明机制。

DART系统在支持并发的入站和出站交易的同时保持了完全匿名性，解决了许多基于账户的匿名系统中存在的常见问题。DART还展示了如何高效地支持多方交易，即在一个交易中向多个接收方付款。我们在通用组合(UC)设置下给出了完整的正式模型以及一个UC协议实现。 <div>
We introduce DART, a fully anonymous, account-based payment system designed to address a comprehensive set of real-world considerations, including regulatory compliance, while achieving constant transaction size. DART supports multiple asset types, enabling users to issue on-chain assets such as tokenized real-world assets. It ensures confidentiality and anonymity by concealing asset types, transaction amounts, balances, and the identities of both senders and receivers, while guaranteeing unlinkability between transactions. Our design provides a mechanism for asset-specific auditing. Issuers can designate asset-specific auditors for the assets they issue, with the system preserving the privacy of the auditor’s identity to achieve asset type privacy. Only the designated auditor is authorized to decrypt transactions related to their associated asset, and users efficiently prove the association between the (hidden) asset type and the (hidden) designated auditor in their transactions. 

DART supports non-interactive payments, allowing an online sender to submit a transaction even when the receiver is offline, while still incorporating a receiver affirmation mechanism that captures the real-world compliance consideration where the receiver must confirm (or deny) an incoming transaction. To the best of our knowledge, this is the first scheme of this kind in the permissionless setting. To accommodate all eventualities, DART also incorporates a reversibility mechanism, enabling senders to reclaim funds from pending transactions if the receiver’s affirmation is not yet provided. Finally, it offers a privacy-preserving proof of balance (per asset type) mechanism. 

Our system achieves full anonymity while supporting concurrent incoming and outgoing transactions, resolving a common issue that plagues many account-based anonymous systems. We further demonstrate how our system supports multi-party transactions, allowing payment to multiple receivers in one transaction efficiently. We provide a full formal model in the Universal Composition (UC) setting, as well as a UC protocol realization.
]]></content:encoded>
<pubDate>Sat, 15 Feb 2025 14:46:13 +0000</pubDate>
</item>
<item>
<title>The Quantum Decoherence Model: Everlasting Composable Secure Computation and More</title>
<link>https://eprint.iacr.org/2025/220</link>
<guid>https://eprint.iacr.org/2025/220</guid>
<content:encoded><![CDATA[
<div> 关键词：量子密码学、量子退相干模型（QDM）、通用可组合性框架、非交互式承诺方案、永远安全

总结:
文章提出了一个新的安全模型——量子退相干模型（QDM），该模型描述了在协议运行期间和结束后一段时间内受到计算限制的对手，但在协议终止很久之后变得计算上无限制，但只能记住有限数量的先前状态的量子位。在此基础上，文章提供了一个带有量子随机预言机的增强版通用可组合性框架，并构建了一个针对恶意发送者具有无条件和统计安全性，以及对恶意接收者具有永远安全性的非交互式承诺方案。此方案可以推广到实现具有永远安全性的多方安全计算。此外，文章的核心技术还可以应用于更广泛的问题，如生成在QDM下具有永远安全性的公开密钥加密和OT，以及在量子退相干设置下的压缩不可行加密，并表明使用后量子IND-CPA安全的公钥加密无需依赖随机预言机即可实现这一概念。这一切都基于一个新颖而简洁的强大反熵不确定性原理。 <div>
Quantum cryptography allows to achieve security goals which are unobtainable using classical cryptography alone: it offers the promise of everlasting privacy. Thatis, an adversary trying to attack a protocol must succeed during the run of the protocol.
After the protocol has terminated, security holds unconditionally.
In this work, we initiate the study of a new model which we call the quantum decoherence model (QDM). In a nutshell, this model captures adversaries that are computationally bounded during the run of a protocol (and some time after), but become computationally unbounded long after the protocol terminates. Importantly, once the adversary becomes computationally unbounded, he can only remember a bounded number of qubits from before the computational bound was lifted.
We provide a variant of the Universal Composability framework which captures the new notion of quantum decoherence and augment it with quantum random oracles. As our main contribution, we construct a non-interactive commitment scheme achieving unconditional and statistical security against malicious senders and everlasting security against malicious receivers under our new security notion. Such commitments imply general secure multiparty computation with everlasting security.
Finally, we show that our core technique can be applied to a broader spectrum of problems. We show that it gives rise to everlasting public key encryption and OT in the QDM. Finally, we also consider the weaker notion of incompressible encryption in the setting of quantum decoherence, and show that post-quantum IND-CPA secure public
key encryption is sufficient to realize this notion without resorting to random oracles.
At the technical core of our constructions is a new, conceptually simple yet powerful reverse entropic uncertainty relation.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 13:08:09 +0000</pubDate>
</item>
<item>
<title>Slot a la carte: Centralization Issues in Ethereum's Proof-of-Stake Protocol</title>
<link>https://eprint.iacr.org/2025/219</link>
<guid>https://eprint.iacr.org/2025/219</guid>
<content:encoded><![CDATA[
<div> 关键词：Ethereum、proof-of-stake (PoS)、distributed randomness beacons (DRBs)、RANDAO、manipulation

总结:

本文研究发现，以太坊当前的权益证明（PoS）共识机制对去中心化构成重大威胁。文章重点关注分布式随机数生成器（DRBs）在领导者选择中的可操纵性问题，特别是以太坊所使用的RANDAO DRB在现有形式下存在严重漏洞。研究指出，在有丰厚收益的槽位被预见的情况下，质押实体可能会临时合谋控制超过33%的验证者，从而使得他们能够以高达99.5%的成功率执行一系列RANDAO操纵攻击，锁定目标槽位。该方法的有效性源于其对于可能攻击行为模型的深入探索，包括通过在敌人自己的槽位中隐瞒区块或通过分叉他人的提议区块来错过主链上的区块。文章认为，虽然PoS有可能为区块链的未来发展铺平道路，但以太坊目前的DRB实现必须替换为更安全的机制。 <div>
In this paper, we demonstrate that Ethereum's current proof-of-stake (PoS) consensus mechanism poses a significant threat to decentralisation. Our research focuses on the manipulability of distributed randomness beacons (DRBs) in leader selection. Specifically, we show that RANDAO - Ethereum's DRB - is seriously vulnerable to manipulations in its current form.  For example, if a lucrative slot is foreseen, there is a risk that staking entities may temporarily collude to control $33\%$ of the validators, enabling them to execute a series of RANDAO manipulation attacks that secure the target slot with a $99.5\%$ success rate. The effectiveness of our method stems from the fact that we work with a significantly richer model of the possible attacks compared to previous works. Our manipulative strategies work by missing blocks from the canonical chain - either by withholding blocks in the adversary's own slots or by forking out blocks proposed by others. We argue that while PoS can pave the path in the future for blockchains, Ethereum's current DRB implementation has to be replaced with a more secure mechanism.
]]></content:encoded>
<pubDate>Thu, 13 Feb 2025 12:29:05 +0000</pubDate>
</item>
<item>
<title>Practical Circuit Privacy/Sanitization for TFHE</title>
<link>https://eprint.iacr.org/2025/216</link>
<guid>https://eprint.iacr.org/2025/216</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全同态加密 (FHE), 两方计算 (2PC), 清理算法, TFHE, 实践性

总结:
本文介绍了针对TFHE（全同态加密）的一种新型清理算法，该算法解决了服务器输入隐私和电路隐私保护的问题。传统清理算法存在效率低下问题，需要多次引导或大量随机评估。新提出的算法仅对原始TFHE引导过程添加了两个轻量级的随机化步骤，无需改动核心算法，实现了单次引导和最小化的随机化清理，从而更接近实际应用。通过实证评估，新方法在一个TFHE密文清理上耗时35.88 ms，相比原版TFHE引导仅慢了3.4%（即1.18 ms）。相较于先前的工作，新方法在速度上有4.82到209.03倍的提升，显著提高了清理算法的效率和实用性。 <div>
Fully homomorphic encryption (FHE) enables the computation of arbitrary circuits over encrypted data. A widespread application of FHE is a simple two-party computation (2PC) protocol, where the server evaluates a circuit over the client's encrypted data and its private inputs. However, while the security of FHE guarantees that the client's data is protected from the server, there is no inherent support for the privacy of the server's input and the circuit.

One effective solution to this problem is an additional algorithm for FHE called sanitization, introduced by Ducas and Stehlé (Eurocrypt 2016). Roughly speaking, a sanitization algorithm removes any meaningful information contained in the ciphertext, including previous evaluations of circuits. Following their definition, several constructions for sanitization have been proposed, particularly for TFHE. However, all of these methods were impractical, requiring several bootstrappings or an excessive amount of randomized evaluations.

In this work, we construct a novel sanitization algorithm for TFHE that overcomes these issues. Our method only adds two lightweight randomization steps to the original TFHE bootstrapping, without any modifications to the core algorithms. As a result, our algorithm achieves sanitization with a single bootstrapping and minimal randomization, bringing sanitization closer to practicality.

To empirically evaluate the efficiency of our method, we provide concrete benchmark results based on our proof-of-concept implementation. Our algorithm sanitizes a single TFHE ciphertext in 35.88 ms, which is only 3.4% (1.18 ms) slower than the original TFHE bootstrapping with the same parameters. When directly compared to previous works, our method achieves a speedup by a factor of 4.82 to 209.03.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 10:47:11 +0000</pubDate>
</item>
<item>
<title>Prior-Based Label Differential Privacy via Secure Two-Party Computation</title>
<link>https://eprint.iacr.org/2025/211</link>
<guid>https://eprint.iacr.org/2025/211</guid>
<content:encoded><![CDATA[
<div> 关键词: 差分隐私(DP), 局部差分隐私(LDP), 标签差分隐私, 安全两方计算(2PC), 数据集(MNIST, CIFAR-10)

总结:
本文关注了在基于先验的局部差分隐私机制中存在的一种敏感先验信息泄露的隐私问题。为了解决这一挑战，同时保持训练模型的效率和准确性，文章提出了一种利用安全两方计算(2PC)协议的新方法来实施此类LDP机制，以避免先验信息泄漏。作者已在标准数据集MNIST和CIFAR-10上实现了该方案并进行了端到端测试。实验结果显示，采用2PC带来的安全性增强几乎无需额外成本：对于CIFAR-10，在强差分隐私参数下，使用2PC导致的运行时间开销仅增加了约3.9%，而相对于不安全（非2PC）方法，精度下降仅为0.4%。 <div>
Differential privacy (DP) is a fundamental technique used in machine learning (ML) training for protecting the privacy of sensitive individual user data. In the past few years, a new approach for combining prior-based Local Differential Privacy (LDP) mechanisms with a relaxed DP criterion, known as Label DP, has shown great promise in increasing the utility of the final trained model without compromising on the DP privacy budget. In this work, we identify a crucial privacy gap in the current implementations of these prior-based LDP mechanisms, namely the leakage of sensitive priors. We address the challenge of implementing such LDP mechanisms without leaking any information about the priors while preserving the efficiency and accuracy of the current insecure implementations. To that end, we design simple and efficient secure two-party computation (2PC) protocols for addressing this challenge, implement them, and perform end-to-end testing on standard datasets such as MNIST, CIFAR-10. Our empirical results indicate that the added security benefit essentially comes almost for free in the sense that the gap between the current insecure implementations and our proposed secure version, in terms of run-time overhead and accuracy degradation, is minimal. E.g., for CIFAR-10, with strong DP privacy parameter, the additional runtime due to 2PC is $\approx 3.9\%$ over WAN with $0.4\%$ decrease in accuracy over an insecure (non-2PC) approach.
]]></content:encoded>
<pubDate>Wed, 12 Feb 2025 03:10:03 +0000</pubDate>
</item>
<item>
<title>NovaTEE: Private Clearing and Settlement on Trusted Execution Hardware</title>
<link>https://eprint.iacr.org/2025/209</link>
<guid>https://eprint.iacr.org/2025/209</guid>
<content:encoded><![CDATA[
<div> 关键词: NovaTEE、私有多边结算网络、可信执行环境(TEEs)、阈值密码学、资本效率

总结:
NovaTEE是一种创新的私有多边结算网络，旨在解决传统金融市场和加密货币交易中的关键效率问题。它利用可信执行环境(TEEs)和阈值密码学技术，实现多方之间的安全、私密和高效结算。该系统采用分布式密钥生成模型和新颖的清算机制，通过多边净额结算优化资本效率，并保持强大的隐私保护和合规性能力。通过结合TEE提供的安全性与零知识证明、稀疏默克尔树等高级加密协议，NovaTEE解决方案能实现在保护敏感交易信息的同时，进行跨平台和跨链的有效结算，显著降低市场参与者的资本要求、优化交易成本，并为机构级清算基础设施提供支持，而无需牺牲安全性和隐私性。其体系结构确保无单一实体完全掌握交易详情，同时通过分布式备份网络保持可审计性，为此类系统的机构采纳提供了切实可行的解决方案。 <div>
NovaTEE is a novel private multilateral settlement network designed to address critical inefficiencies in both traditional financial markets and cryptocurrency trading. The current clearing landscape suffers from fragmented capital allocation, restrictive prime brokerage relationships, and prolonged settlement timeframes in traditional finance, while cryptocurrency markets face challenges with over-collateralization, siloed lending pools, and security risks from centralized exchanges.

We introduce a settlement system that leverages Trusted Execution Environments (TEEs) and threshold cryptography to enable secure, private, and efficient settlement of obligations between multiple parties. The system utilizes a distributed key generation model and novel clearing mechanisms to optimize capital efficiency through multilateral netting, while maintaining strong privacy guarantees and regulatory compliance capabilities. By combining TEE-based security with advanced cryptographic protocols, including zero-knowledge proofs and sparse Merkle trees for data verification, our solution enables efficient cross-venue and cross-chain settlement while protecting sensitive trading information. This approach significantly reduces capital requirements for market participants, optimizes transaction costs, and provides institutional-grade clearing infrastructure without compromising on security or privacy. The system's architecture ensures that no single party has complete access to transaction details while maintaining auditability through a distributed backup network, offering a practical solution for institutional adoption of on-chain settlement.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 21:29:13 +0000</pubDate>
</item>
<item>
<title>Addressing Scalability Issues of Blockchains with Hypergraph Payment Networks</title>
<link>https://eprint.iacr.org/2025/205</link>
<guid>https://eprint.iacr.org/2025/205</guid>
<content:encoded><![CDATA[
<div> 关键词: 支付通道、Layer-2解决方案、交易成功率、交易费用、超边<br /><br />总结:
为了解决传统区块链上链交易数量过多和交易吞吐量不足的问题，支付通道成为Layer-2解决方案中的理想候选。本文提出在支付通道中引入柔韧性并构建具有多端点的超边，以此扩展支付网络图。通过对比比特币闪电网络和其他先进方案，研究发现基于超边的实现不仅能提高交易成功率，而且能将网络成本降低超过50%，相比闪电网络具有显著优势。 <div>
Payment channels are auspicious candidates in layer-2 solutions to reduce the number of on-chain transactions on traditional blockchains and increase transaction throughput. To construct payment channels, peers lock funds on 2-of-2 multisig addresses and open channels between one another to transact via instant peer-to-peer transactions. Transactions between peers without a direct channel are made possible by routing the payment over a series of adjacent channels. In certain cases, this can lead to relatively low transaction success rates and high transaction fees. In this work, we introduce pliability to constructing payment channels and graft edges with more than two endpoints into the payment graph. We refer to these constructions as hyperedges. We present hyperedge-based topologies to form hypergraphs and compare them to Bitcoin's Lightning network and other state-of-the-art solutions. The results demonstrate that hyperedge-based implementations can both increase transaction success rate, in addition to decreasing the network cost by more than 50% compared to that of the Lightning Network.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 14:02:52 +0000</pubDate>
</item>
<item>
<title>Ciphertext-Simulatable HE from BFV with Randomized Evaluation</title>
<link>https://eprint.iacr.org/2025/203</link>
<guid>https://eprint.iacr.org/2025/203</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, 两方计算, Ciphertext Simulatability, BFV方案, Security Notion

总结:
本文提出了一个新的同态加密安全概念——密文模拟性，该概念针对同态加密在构建高效两方计算协议中的隐私保护需求进行了精确刻画。接着，文章从BFV方案出发，通过修改其评估算法，实现了一个具有密文模拟性的同态加密构造，并对其理论分析和实验结果进行了展示，证实了所提方法在参数大小和错误增长方面几乎无显著开销。此外，文中还探讨了如何将这种设计密文可模拟的BFV方案进一步扩展，以满足更强的安全属性，如净化等。<br /><br /> <div>
Homomorphic Encryption (HE) is a privacy-enhancing technology that enables computation over encrypted data without the need for decryption. A primary application of HE is in the construction of communication-efficient Two-Party Computation (2PC) protocols between a client and a server, serving as the key owner and the evaluator, respectively. In this context, it is reasonable to assume that the evaluation circuit involves some confidential information of the server; otherwise, the client could compute it on their own. However, the 2PC protocol built on an HE scheme is not necessarily secure, as the standard IND-CPA security of HE does not guarantee the privacy of the evaluation circuit. Several enhanced security notions for HE, such as circuit privacy and sanitization, have been proposed to address this issue, but they require significant overhead in terms of parameter size or complexity.

In this work, we introduce a novel security notion for HE, called ciphertext simulatability, which precisely captures the security requirements of HE in the construction of 2PC. Then, we provide a concrete construction of ciphertext-simulatable HE from the BFV scheme by modifying its evaluation algorithm. We provide theoretical analysis and demonstrate experimental results to ensure that our solution has insignificant overhead in terms of parameter size and error growth. As a matter of independent interest, we demonstrate how our approach of designing ciphertext-simulatable BFV can be further extended to satisfy stronger security notions such as sanitization.
]]></content:encoded>
<pubDate>Tue, 11 Feb 2025 12:01:19 +0000</pubDate>
</item>
<item>
<title>AUCIL: An Inclusion List Design for Rational Parties</title>
<link>https://eprint.iacr.org/2025/194</link>
<guid>https://eprint.iacr.org/2025/194</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、审查抵抗、包含列表、多提议者、拍卖式包含列表<br /><br />总结: 本文首次对区块链领域的包含列表进行了正式研究，以增强其审查抵抗能力。文章提出了一种利用多个提议者提出交易并提升审查阻力的包含列表设计方案。该设计包含两个关键部分：一是基于效用最大化的输入列表创建机制，使理性提议者能够在优先考虑高价值交易的同时达到协同均衡状态；二是AUCIL（基于拍卖的包含列表）机制，用于整合提议者的输入列表，最终生成一个包含列表。 <div>
The decentralized nature of blockchains is touted to provide censorship resistance. However, in reality, the ability of proposers to completely control the contents of a block makes censorship relatively fragile. To combat this, a notion of inclusion lists has been proposed in the blockchain community. This paper presents the first formal study of inclusion lists. Our inclusion list design leverages multiple proposers to propose transactions and improve censorship resistance. The design has two key components. The first component is a utility-maximizing input list creation mechanism that allows rational proposers to achieve a correlated equilibrium while prioritizing high-value transactions. The second component, AUCIL (auction-based inclusion list), is a mechanism for aggregating the input lists from the proposers to output an inclusion list.
]]></content:encoded>
<pubDate>Mon, 10 Feb 2025 12:09:58 +0000</pubDate>
</item>
<item>
<title>BulletCT: Towards More Scalable Ring Confidential Transactions With Transparent Setup</title>
<link>https://eprint.iacr.org/2025/188</link>
<guid>https://eprint.iacr.org/2025/188</guid>
<content:encoded><![CDATA[
<div> 关键词: RingCT签名、Any-out-of-N证明、DLOG设置、K-out-of-N证明、可链接性

总结:
文章首次对ZGSX23提出的基于离散对数设置的新型Any-out-of-N证明及其关联的RingCT方案进行了深入分析。研究发现，虽然Any-out-of-N证明提供了更强的匿名性，但存在交易大小增加、密码学复杂度提升和潜在安全风险等问题，加剧了可扩展性的瓶颈问题。针对这些问题，文章探索使用K-out-of-N证明来增强RingCT方案的可扩展性，并创新地提出了一种新的DLOG基础的RingCT签名方案，该方案结合了优化的“K-权重”K-out-of-N证明以及首个能有效实现由前者衍生出的RingCT签名可链接性的新标签证明，从而抵抗双花攻击。此外，文章还发现了ZGSX23签名中的可链接性缺陷并予以修复。通过对新旧方案进行基准测试，显示本文提出的方案在可扩展性上取得了显著提升，为RingCT技术的发展迈出了一步。 <div>
RingCT signatures are essential components of Ring Confidential Transaction (RingCT) schemes on blockchain platforms, enabling anonymous transaction spending and significantly impacting the scalability of these schemes. This paper makes two primary contributions:

We provide the first thorough analysis of a recently developed Any-out-of-N proof in the discrete logarithm (DLOG) setting and the associated RingCT scheme, introduced by ZGSX23 (S&amp;P '23). The proof conceals the number of the secrets to offer greater anonymity than K-out-of-N proofs and uses an efficient "K-Weight" technique for its construction. However, we identify for the first time several limitations of using Any-out-of-N proofs, such as increased transaction sizes, heightened cryptographic complexities and potential security risks. These limitations prevent them from effectively mitigating the longstanding scalability bottleneck.

We then continue to explore the potential of using K-out-of-N proofs to enhance scalability of RingCT schemes. Our primary innovation is a new DLOG-based RingCT signature that integrates a refined "K-Weight"-based K-out-of-N proof and an entirely new tag proof. The latter is the first to efficiently enable the linkability of RingCT signatures derived from the former, effectively resisting double-spending attacks.

Finally, we identify and patch a linkability flaw in ZGSX23's signature. We benchmark our scheme against this patched one to show that our scheme achieves a boost in scalability, marking a promising step forward.
]]></content:encoded>
<pubDate>Sat, 08 Feb 2025 22:06:24 +0000</pubDate>
</item>
<item>
<title>NodeChain: Cheap Data Integrity Without Consensus</title>
<link>https://eprint.iacr.org/2025/184</link>
<guid>https://eprint.iacr.org/2025/184</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、去中心化应用、约束设备、数据结构、安全性证明<br /><br />总结:
我们提出了一种新的基于区块链的数据结构，该结构放弃了复制要求，同时保持了区块链的追加唯一性特性，使其适合在存储受限的设备网络中维护数据完整性。由于我们的目标应用并不需要共识机制（例如，安全存储货船集装箱中的传感器数据），因此我们没有提供这一功能。我们通过多方面证实了这种方法的实际潜力：(i) 我们在通用组合(UC)环境中形式化地证明了协议的安全性；(ii) 提供了一个小规模的概念验证实现；(iii) 对大规模部署进行了性能模拟，显示与传统区块链相比，存储需求减少了超过1000倍；(iv) 并进行了一项鲁棒性模拟，预测了网络阻塞攻击对实际运行的影响。 <div>
Blockchains enable decentralised applications that withstand Byzantine failures and do not need a central authority. Unfortunately, their massive replication requirements preclude their use on constrained devices.

We propose a novel blockchain-based data structure which forgoes replication without affecting the append-only nature of blockchains, making it suitable for maintaining data integrity over networks of storage-constrained devices. Our solution does not provide consensus, which is not required by our motivating application, namely securely storing sensor data of containers in cargo ships.

We elucidate the practical promise of our technique by following a multi-faceted approach: We (i) formally prove the security of our protocol in the
Universal Composition (UC) setting, as well as (ii) provide a small-scale proof-of-concept implementation, (iii) a performance simulation for large-scale deployments which showcases a reduction in storage of more than $1000$x compared to traditional blockchains, and (iv) a resilience simulation that predicts the practical effects of network jamming attacks.
]]></content:encoded>
<pubDate>Fri, 07 Feb 2025 18:46:07 +0000</pubDate>
</item>
<item>
<title>HyperLoop: Rationally secure efficient cross-chain bridge</title>
<link>https://eprint.iacr.org/2025/176</link>
<guid>https://eprint.iacr.org/2025/176</guid>
<content:encoded><![CDATA[
<div> 关键词: Cross-chain bridges, rational-malicious model, HyperLoop, whistle-blower nodes, sliding window mechanism

总结:
本文提出了一种名为HyperLoop的高效跨链多签名桥接器，该桥接器在更为现实的理性恶意模型下被证明在安全性和活跃性方面具有理论保障。针对理性节点可能因经济利益而偏离协议甚至合谋的问题，文章引入了吹哨人节点作为监控机制，它们持续检查桥接器的操作并在发现异常时向投诉解决网络报告。为实施惩罚并确保安全性，要求节点在参与成为桥接器前需要抵押一定金额，并通过滑动窗口机制设置资金转移量上限。此外，文中描述的滑动窗口机制确立了抵押额与滑动窗口限制之间的关系。最终，实现了一个在经济、计算和通信效率上均表现出色的桥接器原型，并成功部署在以太坊和Polygon两条测试链之间。实验结果显示，在一个由19个节点组成的桥接器网络中，每个桥接器节点平均只需3毫秒就能检测并签署源链请求，体现出极高的效率和低延迟特性。 <div>
Cross-chain bridges, realizing the transfer of information and assets between blockchains, form the core of blockchain interoperability solutions. Most existing bridge networks are modeled in an honest-malicious setting, where the bridge nodes are either honest or malicious. Rationality allows the nodes to deviate from the protocol arbitrarily for an economic incentive. In this work, we present HyperLoop, an efficient cross-chain multi-signature bridge and prove that it is safe and live game-theoretically, under the more realistic rational-malicious model.

As rational bridge nodes are allowed to deviate from the protocol and even collude, a monitor mechanism is necessitated, which we realize by introducing whistle-blower nodes. These whistle-blowers constantly check the operations of the bridge and raise complaints to a complaint resolution network in case of discrepancies. To enforce punishments, it is necessary for the nodes to stake an amount before participating as bridge nodes. Consequently, a cap on the volume of funds transferred over the bridge is established. We describe a sliding window mechanism and establish a relation between the stake and the sliding window limit necessary for the safety of the bridge.

Our design yields an economic, computation, and communication-efficient bridge. We realize and deploy our bridge prototype bridging Ethereum and Polygon chains over testnets. For a 19-node bridge network, each bridge node takes an average of only 3 msec to detect and sign a source chain request, showing the highly efficiency and low-latency of the bridge.
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 20:06:00 +0000</pubDate>
</item>
<item>
<title>VITARIT: Paying for Threshold Services on Bitcoin and Friends</title>
<link>https://eprint.iacr.org/2025/174</link>
<guid>https://eprint.iacr.org/2025/174</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链服务、分布式阈值加密服务、UTXO模型、公平性、VITARIT

总结:

本文介绍了一种名为VITARIT的新颖支付解决方案，该方案针对比特币等基于UTXO模型的区块链系统中，分布式阈值加密服务（如t-out-of-n分布式阈值可验证随机函数VRF服务）的需求进行了定制。VITARIT协议保证了强大的可证明安全性并方便实际部署，允许客户端向分布式阈值VRF服务请求可验证随机函数值，并触发对最多t+1个服务器的支付。该设计依赖于简单的交易和签名验证脚本，可以直接应用于类似比特币的系统。同时，文章还引入了新的密码学和交易层面的工具与技术，包括一种用于标准构建的创新性的签名-VRF交换协议，以及防止恶意服务器重复获取支付的交易流程设计，对去中心化支付系统具有更广泛的影响。原型实现表明，在两方交互情况下，客户端耗时126.4毫秒，服务器耗时204毫秒，证实了系统的实用性和可部署性。 <div>
Blockchain service offerings have seen a rapid rise
in recent times. Many of these services realize a decentralized
architecture with a threshold adversary to avoid a single
point of failure and to mitigate key escrow issues. While
payments to such services are straightforward in systems
supporting smart contracts, achieving fairness poses challenges
in systems like Bitcoin, adhering to the UTXO model with
limited scripting capabilities. This is especially challenging
without smart contracts, as we wish to pay only the required
threshold of t + 1 out of the n servers offering the service
together, without any server claiming the payment twice.

In this paper, we introduce VITARIT 1, a novel payment
solution tailored for threshold cryptographic services in UTXO
systems like Bitcoin. Our approach guarantees robust provable
security while facilitating practical deployment. We focus on
the t-out-of-n distributed threshold verifiable random function
(VRF) service with certain properties, such as threshold BLS
signatures, a recently highlighted area of interest. Our protocol
enables clients to request verifiable random function (VRF)
values from the threshold service, triggering payments to up
to t + 1 servers of the distributed threshold VRF.

Our efficient design relies on simple transactions using
signature verification scripts, making it immediately applicable
in Bitcoin-like systems. We also introduce new tools and
techniques at both the cryptographic and transaction layers,
including a novel signature-VRF exchange protocol for standard
constructions, which may be of independent interest. Addition-
ally, our transaction flow design prevents malicious servers
from claiming payments twice, offering broader implications for
decentralized payment systems. Our prototype implementation
shows that in the two-party interaction, the client takes 126.4
msec, and the server takes 204 msec, demonstrating practicality
and deployability of the system
]]></content:encoded>
<pubDate>Wed, 05 Feb 2025 18:17:35 +0000</pubDate>
</item>
<item>
<title>VRaaS: Verifiable Randomness as a Service on Blockchains</title>
<link>https://eprint.iacr.org/2024/957</link>
<guid>https://eprint.iacr.org/2024/957</guid>
<content:encoded><![CDATA[
<div> 关键词: Web3应用、随机性服务、区块链、可验证随机性、Verifiable Randomness as a Service (VRaaS)

<br /><br />总结:
本文针对Web3应用程序中对于公正、不可预测和公开可验证随机性的广泛需求，首次提出了区块链环境下的可验证随机性服务（VRaaS）的概念，并进行了深入的正式化分析。文章中，作者定义了一个理想功能$\mathcal{F}_{\text{VRaaS}}$以在通用可组合模型中形式化VRaaS，该定义涵盖了随机性服务的核心特性，如无偏性、不可预测性和公共可验证性，以及涉及智能合约等不同实体的相关细节。

在此框架下，作者研究了一种基于可验证随机函数（VRF）的通用随机性服务设计，其中随机性请求者提供输入以生成作为VRF输出的随机数。证明了这种设计方案满足他们所提出的VRaaS形式化定义，并指出该通用协议能够涵盖现实世界中的许多随机性服务实例，如Chainlink VRF和Supra dVRF。

此外，作者还探讨了该框架的极简主义性质。首先，他们展示了框架内置的两个交易对于支持随机性服务的基本品质实际上是必要的。同时，他们发现其他一些设计，如Algorand信标、Pyth VRF和Band VRF，在其框架内存在实际漏洞。 <div>
Web3 applications, such as on-chain games, NFT minting, and leader elections necessitate access to unbiased, unpredictable, and publicly verifiable randomness. Despite its broad use cases and huge demand, there is a notable absence of comprehensive treatments of on-chain verifiable randomness services. To bridge this, we offer an extensive formal analysis of on-chain verifiable randomness services. 

     We present the $first$ formalization of on-chain verifiable randomness in the blockchain setting by introducing the notion of Verifiable Randomness as a Service (VRaaS). We formally define VRaaS using an ideal functionality $\mathcal{F}_{\text{VRaaS}}$ in the Universal Composability model. Our definition not only captures the core features of randomness services, such as unbiasability, unpredictability, and public verifiability, but also accounts for many other crucial nuances pertaining to different entities involved, such as smart contracts. 

     Within our framework we study a generic design of Verifiable Random Function (VRF)-based randomness service - where the randomness requester provides an input on which the randomness is evaluated as VRF output. We show that it does satisfy our formal VRaaS definition. Furthermore, we show that the generic protocol captures many real-world randomness services like Chainlink VRF and Supra dVRF. 
    
     Moreover, we investigate the minimalism of the framework. Towards that, first we show that, the two transactions in-built in our framework are actually $necessary$ for any randomness service to support the essential qualities. We also discover $practical$ $vulnerabilities$ in other designs such as Algorand beacon, Pyth VRF and Band VRF, captured within our framework.
]]></content:encoded>
<pubDate>Fri, 14 Jun 2024 05:45:37 +0000</pubDate>
</item>
<item>
<title>Wiretapping LLMs: Network Side-Channel Attacks on Interactive LLM Services</title>
<link>https://eprint.iacr.org/2025/167</link>
<guid>https://eprint.iacr.org/2025/167</guid>
<content:encoded><![CDATA[
<div> 关键词：服务器端优化、投机解码、侧信道漏洞、大型语言模型（LLM）、安全性框架、攻击方法、加密用户提示、网络包时间、大小差异、隐私敏感应用、准确性、性能安全权衡

总结:<br />
本文揭示了服务器端的优化，如投机解码，虽然提高了大型语言模型（LLM）服务的交互性和资源效率，但却意外引入了新的通过网络包时间和大小变化的输入依赖性侧信道漏洞。研究者提出了一种新颖的攻击方法，利用该安全框架证明了现实世界中采用流式API的LLM服务存在不安全性。攻击者能准确预测加密的用户提示和响应中的敏感信息，例如在医学和金融领域的隐私敏感LLM应用中，对开源vLLM服务的预测精度达到71%至92%，对商业ChatGPT服务的预测精度为50%至90%。最后，文章指出，隐藏这些侧信道的不同解决方案会在安全性和性能之间产生权衡，具体表现为交互性和网络带宽开销的增加。 <div>
Recent server-side optimizations like speculative decoding significantly enhance the interactivity and resource efficiency of Large Language Model (LLM) services. However, we show that these optimizations inadvertently introduce new side-channel vulnerabilities through network packet timing and size variations that tend to be input-dependent. Network adversaries can leverage these side channels to learn sensitive information contained in \emph{encrypted} user prompts to and responses from public LLM services.  

This paper formalizes the security implications using a novel indistinguishability framework and introduces a novel attack that establishes the insecurity of real-world LLM services with streaming APIs under our security framework.

Our proposed attack effectively deconstructs encrypted network packet traces to reveal the sizes of underlying LLM-generated tokens and whether the tokens were generated with or without certain server-side optimizations. Our attack can accurately predict private attributes in real-world privacy-sensitive LLM applications in medicine and finance with $71$--$92\%$ accuracy on an open-source vLLM service and $50$--$90\%$ accuracy on the commercial ChatGPT service. Finally, we show that solutions that hide these side channels to different degrees expose a tradeoff between security and performance --- specifically, interactivity and network bandwidth overheads.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2025 15:27:58 +0000</pubDate>
</item>
<item>
<title>Learning from Functionality Outputs: Private Join and Compute in the Real World</title>
<link>https://eprint.iacr.org/2025/162</link>
<guid>https://eprint.iacr.org/2025/162</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Join and Compute (PJC), 两方协议, 隐私风险, 攻击, 安全模型

总结:
Private Join and Compute (PJC)是由Google提出的一种两方协议，用于包括广告转化在内的多种场景，并扩展了其部署的私人集合交集求和(PSI-SUM)协议。然而，PJC的功能输出通常并未在MPC文献的安全模型中考虑，但可能存在实际的隐私风险，对PJC等协议的潜在部署产生了关注。本文分析了与PJC功能输出相关的风险，假设一方参与者作为攻击者，描述了四种能够破坏另一方输入隐私、恢复交集中键值对成员资格及其关联值的实战攻击。这些攻击揭示了部署过程中与隐私威胁相关的问题，并强调应将功能输出纳入MPC安全模型的一部分。 <div>
Private Join and Compute (PJC) is a two-party protocol recently proposed by Google for various use-cases, including ad conversion (Asiacrypt 2021) and which generalizes their deployed private set intersection sum (PSI-SUM) protocol (EuroS&amp;P 2020).

PJC allows two parties, each holding a key-value database, to privately evaluate the inner product of the values whose keys lie in the intersection. While the functionality output is not typically considered in the security model of the MPC literature, it may pose real-world privacy risks, thus raising concerns about the potential deployment of protocols like PJC. 

In this work, we analyze the risks associated with the PJC functionality output. We consider an adversary that is a participating party of PJC and describe four practical attacks that break the other party's input privacy, and which are able to recover both membership of keys in the intersection and their associated values.  Our attacks consider the privacy threats associated with deployment and highlight the need to include the functionality output as part of the MPC security model.
]]></content:encoded>
<pubDate>Mon, 03 Feb 2025 16:02:28 +0000</pubDate>
</item>
<item>
<title>HELP: Everlasting Privacy through Server-Aided Randomness</title>
<link>https://eprint.iacr.org/2025/140</link>
<guid>https://eprint.iacr.org/2025/140</guid>
<content:encoded><![CDATA[
<div> 关键词: 永恒隐私、Store-Now-Decrypt-Later问题、Hypervisor EverLasting Privacy (HELP)、Dodis和Yeo、Universal Composability框架

总结:
本文关注永恒隐私（Everlasting Privacy）及其在解决Store-Now-Decrypt-Later（SNDL）问题中的应用。作者重新审视了Dodis和Yeo提出的Hypervisor EverLasting Privacy (HELP)模型，并提出了一种新型架构，该架构通过半可信服务器网络生成共享随机数，降低了存储和分布大型共享密钥的需求。尽管Dodis和Yeo的方法在理论上有效，但在实践中效率较低。为此，文章对HELP架构进行了抽象和泛化，并构建了几种具体高效的实现方案，这些方案基于诸如哈希和消息认证等基本加密操作。此外，文章证明了一个强大的组合定理，表明其永恒隐私架构可以使用在Universal Composability (UC)框架下计算上安全的消息传输方法，这是关于永恒隐私的第一个积极组合结果，之前已知永恒隐私存在许多“非组合”结果。 <div>
Everlasting (EL) privacy offers an attractive solution to the Store-Now-Decrypt-Later (SNDL) problem, where future increases in the attacker's capability could break systems which are believed to be secure today. Instead of requiring full information-theoretic security, everlasting privacy allows computationally-secure transmissions of ephemeral secrets, which are only "effective" for a limited periods of time, after which their compromise is provably useless for the SNDL attacker.

In this work we revisit such everlasting privacy model of Dodis and Yeo (ITC'21), which we call Hypervisor EverLasting Privacy (HELP). HELP is a novel architecture for generating shared randomness using a network of semi-trusted servers (or "hypervisors"), trading the need to store/distribute large shared secrets with the assumptions that it is hard to: (a) simultaneously compromise too many publicly accessible ad-hoc servers; and (b) break a computationally-secure encryption scheme very quickly. While Dodis and Yeo presented good HELP solutions in the asymptotic sense, their solutions were concretely expensive and used heavy tools (like large finite fields or gigantic Toeplitz matrices). 

We abstract and generalize the HELP architecture to allow for more efficient instantiations, and construct several concretely efficient HELP solutions. Our solutions use elementary cryptographic operations, such as hashing and message authentication. We also prove a very strong composition theorem showing that our EL architecture can use any message transmission method which is computationally-secure in the Universal Composability (UC) framework. This is the first positive composition result for everlasting privacy, which was otherwise known to suffer from many "non-composition" results (Müller-Quade and Unruh; J of Cryptology'10).
]]></content:encoded>
<pubDate>Wed, 29 Jan 2025 01:59:45 +0000</pubDate>
</item>
<item>
<title>Efficient Oblivious Sorting and Shuffling for Hardware Enclaves</title>
<link>https://eprint.iacr.org/2023/1258</link>
<guid>https://eprint.iacr.org/2023/1258</guid>
<content:encoded><![CDATA[
<div> 关键词: Oblivious算法、隐私保护、flexway o-sort、硬件安全隔离、性能提升

总结:
这篇论文提出了一种新的 Oblivious 排序算法——flexway o-sort，该算法具有渐进最优性、实际效率高以及适合在如Intel SGX等硬件安全隔离环境中实现的特点。对于输入数据量为12GB的中等到大规模场景，当数据完全适应硬件隔离区时，flexway o-sort 相比已知的 Oblivious 排序算法能带来1.32至28.8倍的性能提升；而在数据超出硬件隔离区的情况，这一优势可达到4.1至208倍。此外，论文还实现了基于 Oblivious 排序的应用，包括直方图计算、数据库连接和ORAM数据结构初始化。这些应用在处理8GB至32GB的数据集时，相比于传统的位onic排序，在数据适应硬件隔离区的情况下速度提升了1.44至2.3倍，而当数据不适应硬件隔离区时，则提高了4.9至5.5倍的速度。 <div>
Oblivious algorithms are being deployed at large scale in real world to enable privacy-preserving applications such as Signal's private contact discovery. Oblivious sorting is a fundamental building block in the design of oblivious algorithms for numerous computation tasks. Unfortunately, there is still a theory-practice gap for oblivious sort. The commonly implemented bitonic sorting algorithm is not asymptotically optimal, whereas known asymptotically optimal algorithms suffer from large constants.
In this paper, we construct a new oblivious sorting algorithm called flexway o-sort, which is asymptotically optimal, concretely efficient, and suitable for implementation in hardware enclaves such as Intel SGX. For moderately large inputs of $12$ GB, our flexway o-sort algorithm outperforms known oblivious sorting algorithms by $1.32\times$ to $28.8\times$ when the data fits within the hardware enclave, and by $4.1\times$ to $208\times$ when the data does not fit within the hardware enclave. We also implemented various applications of oblivious sorting, including histogram, database join, and initialization of an ORAM data structure. For these applications and data sets from 8GB to 32GB, we achieve $1.44 \sim 2.3\times$ speedup over bitonic sort when the data fits within the enclave, and $4.9 \sim 5.5\times$ speedup when the data does not fit within the enclave.
]]></content:encoded>
<pubDate>Sun, 20 Aug 2023 22:45:36 +0000</pubDate>
</item>
<item>
<title>Path Privacy and Handovers: Preventing Insider Traceability Attacks During Secure Handovers</title>
<link>https://eprint.iacr.org/2025/139</link>
<guid>https://eprint.iacr.org/2025/139</guid>
<content:encoded><![CDATA[
<div> 关键词: 5G, 物联网(IoT), 安全手over, 路径隐私, 密码学形式化

总结:
随着5G和物联网技术的发展，安全通信从集中式同质化转变为异构移动设备在网络间不断切换的新格局。本文首次提出了安全手over的密码学正式化方案，强调了设备在不同网络间安全连接转移的重要性。文章中，我们引入了一个新的安全性属性——路径隐私，这是针对手over过程的一种此前未被探索的特性。此外，我们还制定了安全手over的语法，并确定了适用于安全手over方案的安全属性。最后，我们提出了一种通用的手over方案，该方案综合了我们的新颖路径隐私概念与其他现有手over方案所具有的安全属性，从而证明了我们框架的稳健性和灵活性。 <div>
The rise of 5G and IoT has shifted secure communication from centralized and homogeneous to a landscape of heterogeneous mobile devices constantly travelling between myriad networks. In such environments, it is desirable for devices to securely extend their connection from one network to another, often referred to as a handover. In this work we introduce the first cryptographic formalisation of secure handover schemes. We leverage our formalisation to propose path privacy, a novel security property for handovers that has hitherto remained unexplored. We further develop a syntax for secure handovers, and identify security properties appropriate for secure handover schemes. Finally, we introduce a generic handover scheme that captures all the strong notions of security we have identified, combining our novel path privacy concept with other security properties characteristic to existing handover schemes, demonstrating the robustness and versatility of our framework.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 22:45:51 +0000</pubDate>
</item>
<item>
<title>Naysayer proofs</title>
<link>https://eprint.iacr.org/2023/1472</link>
<guid>https://eprint.iacr.org/2023/1472</guid>
<content:encoded><![CDATA[
<div> 关键词：naysayer证明、零知识证明、NP语言、常量大小、常量时间

总结:
本文提出了“naysayer证明”的概念，指出在许多（零知识）证明系统中，验证者通过naysayer确认一个错误的证明无效比检查一个真实的证明有效要高效得多。文章展示了每一个NP语言都可以拥有常量大小和常量时间的naysayer证明。此外，文中还给出了针对FRI多项式承诺、后量子安全数字签名以及可验证洗牌等几个示例证明系统的实际构造。naysayer证明为资源受限的验证器，如智能合约，提供了一种新的乐观验证模式的可能性。 <div>
This work introduces the notion of naysayer proofs. We observe that in numerous (zero-knowledge) proof systems, it is significantly more efficient for the verifier to be convinced by a so-called naysayer that a false proof is invalid than it is to check that a genuine proof is valid. We show that every NP language has constant-size and constant-time naysayer proofs. We also show practical constructions for several example proof systems, including FRI polynomial commitments, post-quantum secure digital signatures, and verifiable shuffles. Naysayer proofs enable an interesting new optimistic verification mode potentially suitable for resource-constrained verifiers, such as smart contracts.
]]></content:encoded>
<pubDate>Mon, 25 Sep 2023 14:24:01 +0000</pubDate>
</item>
<item>
<title>Intmax2: A ZK-rollup with Minimal Onchain Data and Computation Costs Featuring Decentralized Aggregators</title>
<link>https://eprint.iacr.org/2023/1082</link>
<guid>https://eprint.iacr.org/2023/1082</guid>
<content:encoded><![CDATA[
<div> 关键词: Intmax2、区块链扩容、零知识汇总(ZK-rollup)、客户端、安全性证明<br /><br />总结:
Intmax2是一个名为Intmax2的区块链扩容解决方案，它是一种基于零知识汇总（ZK-rollup）协议的方案，具有无状态和无需许可的区块生成特点。该方案独特之处在于将大部分数据处理和计算成本转移至客户端，而非对区块生产者或底层Layer 1区块链施加繁重要求。区块生产者的任务仅限于定期生成交易集合的承诺，向每个发送者分发包含证明，并收集及聚合发送者的签名。这种设计实现了无权限和无状态的区块生成，并随用户数量增加而高度可扩展。此外，该协议的主要安全属性已由Nethermind形式验证团队使用Lean定理证明器进行了正式验证。 <div>
We present a blockchain scaling solution called Intmax2, which is a Zero-Knowledge rollup (ZK-rollup) protocol with stateless and permissionless block production, while minimizing the usage of data and computation on the underlying blockchain. Our architecture distinctly diverges from existing ZK-rollups since essentially all of the data and computational costs are shifted to the client-side as opposed to imposing heavy requirements on the block producers or the underlying Layer 1 blockchain. The only job for block producers is to periodically generate a commitment to a set of transactions, distribute inclusion proofs to each sender, and collect and aggregate signatures by the senders. This design allows permissionless and stateless block production, and is highly scalable with the number of users. We give a proof of the main security property of the protocol, which has been formally verified by the Nethermind Formal Verification Team in the Lean theorem prover.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 15:34:58 +0000</pubDate>
</item>
<item>
<title>Distributional Private Information Retrieval</title>
<link>https://eprint.iacr.org/2025/132</link>
<guid>https://eprint.iacr.org/2025/132</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Information Retrieval（私有信息检索），Distributional Private Information Retrieval（分布式私有信息检索），经典PIR，流行度分布，CrowdSurf

总结:

我们提出了分布式私有信息检索（Distributional PIR）这一新型PIR方案，它在处理数据库记录流行度严重偏斜的情况下，能够比经典PIR实现更快的运行速度，同时保持与经典PIR相同的加密隐私保护。分布式PIR的成功概率保证针对的是分布内的查询，而对分布外的查询成功率较低。文章构建了一个利用经典PIR协议作为黑盒的分布式PIR方案，并证明了对于一大类分布式PIR方案的服务器运行时间下限。在两个实际流行度分布的数据集上，相比于现有技术，我们的分布式PIR构造方法将计算成本降低了5至77倍。最后，我们构建了一个名为CrowdSurf的端到端系统，用于私人获取推文，并显示分布式PIR将端到端服务器成本减少了8倍。 <div>
A private-information-retrieval (PIR) scheme lets a client fetch a record from a remote database without revealing which record it fetched. Classic PIR schemes treat all database records the same but, in practice, some database records are much more popular (i.e., commonly fetched) than others. We introduce distributional private information retrieval, a new type of PIR that can run faster than classic PIR–both asymptotically and concretely–when the popularity distribution is heavily skewed. Distributional PIR provides exactly the same cryptographic privacy as classic PIR. The speedup comes from a relaxed form of correctness: distributional PIR guarantees that in-distribution queries succeed with good probability, while out-of-distribution queries succeed with lower probability.

We construct a distributional-PIR scheme that makes black-box use of classic PIR protocols, and prove a lower bound on the server-runtime of a large class of distributional-PIR schemes. On two real-world popularity distributions, our distributional-PIR construction reduces compute costs by $5$-$77\times$ compared to existing techniques. Finally, we build CrowdSurf, an end-to-end system for privately fetching tweets, and show that distributional-PIR reduces the end-to-end server cost by $8\times$.
]]></content:encoded>
<pubDate>Tue, 28 Jan 2025 03:04:53 +0000</pubDate>
</item>
<item>
<title>Always by Your Side: Constructing Traceable Anonymous Credentials with Hardware-Binding</title>
<link>https://eprint.iacr.org/2025/126</link>
<guid>https://eprint.iacr.org/2025/126</guid>
<content:encoded><![CDATA[
<div> 关键词: Decentralized Identity, Anonymous Credential, Traceability, Public Key Encryption, Equality Test

总结:
本文关注去中心化身份（DID）和匿名凭证（AC）技术及其可追溯性的发展，指出现有方案中引入受信任的监管方可能存在用户隐私风险。为解决这一问题，文章提出了一种基于公共密钥加密与等式测试的监管文本方法，用于每个认证记录，确保方案具备可验证性、不可陷害性和轮次隔离安全性。该方案的优势在于其等式测试能力并不依赖于公钥，而是取决于认证的轮次标识符。文章进一步实现了一个基于智能卡和BBS+签名的可追踪、硬件绑定的AC方案，并进行了性能分析。相较于其他可追踪AC方案，作者展示了其在追溯任务以及安全地外包方面的优势。 <div>
With the development of decentralized identity (DID), anonymous credential (AC) technology, as well as its traceability, is receiving more and more attention. Most works introduce a trusted party (regulator) that holds a decryption key or backdoor to directly deanonymize the user identity of anonymous authentication. While some cryptographic primitives can help regulators handle complex tracing tasks among large amounts of user profiles (stored by the issuer) and authentication records (stored by the service provider), additional security primitives are still needed to ensure the privacy of other users. Besides, hardware-binding anonymous credential (hbAC) systems have been proposed to prevent credential sharing or address platform resource constraints, the traceability of hbAC has yet to be discussed.

In this paper, we introduce a public key encryption with equality test as a regulatory text for each authentication record to address the above-mentioned challenges. The security of this feature is guaranteed by the verifiability, non-frameability, and round isolation of the proposed scheme. We compared the asymptotic complexity of our scheme with other traceable AC schemes and shows our scheme has advantages in tracing tasks as well as securely outsourcing them. The key feature of our scheme is that the ability of equality test of regulatory texts is independent of the public key, but rather depends on the round identifier of the authentication. We instantiate a traceable, hardware-binding AC scheme based on smart cards and BBS+ signature and give the performance analysis of it.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 04:35:31 +0000</pubDate>
</item>
<item>
<title>Summation-based Private Segmented Membership Test from Threshold-Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/753</link>
<guid>https://eprint.iacr.org/2024/753</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Segmented Membership Test (PSMT)，Private Set Intersection (PSI)，Multi-Party PSI (MPSI)，Private Membership Test (PMT)，Oblivious RAM (ORAM)

总结:
该文章引入了一种名为Private Segmented Membership Test (PSMT)的新颖原始数据隐私保护技术。针对存在大量数据持有者的情况下，客户端希望检查其持有的数据元素是否存在于加密状态下的多个集合中的场景，现有的PSI、MPSI、PMT和ORAM方案在隐私保护或效率上存在问题。文章提出一种基于阈值近似算术同态加密的基本协议来构建PSMT，并成功避免了泄露持有交集元素的数据持有者信息以及产生大量误报的情况，同时确保了IND-CPA^D安全级别。相较于现有最佳方法，新方案在支持大量数据持有者方面具有更好的可扩展性，通过使用基于求和的同态成员资格检查而非基于乘积的方法，以及解决各种技术挑战的新颖思路，实现在实验中能有效处理多达4096个数据持有者的情况（相比于此前大约100个）。实验结果显示，对于1024个数据持有者和大小为2^25的集合，结果聚合可以在92.5秒内完成，并且随着发送者数量增加，其开销增长缓慢。此外，文中还将PSMT协议与其他领先的PSI和MPSI协议进行了对比，并讨论了其在隐私模型改进和更大规模参与方方面的优越性。 <div>
In many real-world scenarios, there are cases where a client wishes to check if a data element they hold is included in a set segmented across a large number of data holders. To protect user privacy, the client's query and the data holders' sets should remain encrypted throughout the whole process. Prior work on Private Set Intersection (PSI), Multi-Party PSI (MPSI), Private Membership Test (PMT), and Oblivious RAM (ORAM) falls short in this scenario in many ways. They either require data holders to possess the sets in plaintext, incur prohibitively high latency for aggregating results from a large number of data holders, leak the information about the party holding the intersection element, or induce a high false positive. 

This paper introduces the primitive of a Private Segmented Membership Test (PSMT). We give a basic construction of a protocol to solve PSMT using a threshold variant of approximate-arithmetic homomorphic encryption and show how to overcome existing challenges to construct a PSMT protocol without leaking information about the party holding the intersection element or false positives for a large number of data holders ensuring IND-CPA^D security. Our novel approach is superior to existing state-of-the-art approaches in scalability with regard to the number of supported data holders. This is enabled by a novel summation-based homomorphic membership check rather than a product-based one, as well as various novel ideas addressing technical challenges. Our PSMT protocol supports many more parties (up to 4096 in experiments) compared to prior related work that supports only around 100 parties efficiently. Our experimental evaluation shows that our method's aggregation of results from data holders can run in 92.5s for 1024 data holders and a set size of 2^25, and our method's overhead increases very slowly with the increasing number of senders. We also compare our PSMT protocol to other state-of-the-art PSI and MPSI protocols and discuss our improvements in usability with a better privacy model and a larger number of parties.
]]></content:encoded>
<pubDate>Thu, 16 May 2024 18:35:58 +0000</pubDate>
</item>
<item>
<title>A Privacy Model for Classical &amp; Learned Bloom Filters</title>
<link>https://eprint.iacr.org/2025/125</link>
<guid>https://eprint.iacr.org/2025/125</guid>
<content:encoded><![CDATA[
<div> 关键词: Classical Bloom Filter, Learned Bloom Filter, Probabilistic Data Structure, Differential Privacy, Privacy Attacks/Defenses

总结:
本文探讨了Bloom Filter在处理敏感输入数据并确保隐私安全方面的应用。提出了一个更强的基于差分隐私的Bloom Filter模型。文章中，设计并构建了满足$(\epsilon, 0)$-差分隐私的Classical Bloom Filter和Learned Bloom Filter。这是首次在严格模型下对Learned Bloom Filter的隐私问题进行分析和解决，从而填补了该领域的研究空白。<br /><br /> <div>
The Classical Bloom Filter (CBF) is a class of Probabilistic Data Structures (PDS) for handling Approximate Query Membership (AMQ). The Learned Bloom Filter (LBF) is a recently proposed class of PDS that combines the Classical Bloom Filter with a Learning Model while preserving the Bloom Filter's one-sided error guarantees. Bloom Filters have been used in settings where inputs are sensitive and need to be private in the presence of an adversary with access to the Bloom Filter through an API or in the presence of an adversary who has access to the internal state of the Bloom Filter. Prior work has investigated the privacy of the Classical Bloom Filter providing attacks and defenses under various privacy definitions. In this work, we formulate a stronger differential privacy-based model for the Bloom Filter. We propose constructions of the Classical and Learned Bloom Filter that satisfy $(\epsilon, 0)$-differential privacy. This is also the first work that analyses and addresses the privacy of the Learned Bloom Filter under any rigorous model, which is an open problem.
]]></content:encoded>
<pubDate>Mon, 27 Jan 2025 00:12:40 +0000</pubDate>
</item>
<item>
<title>Efficient 2PC for Constant Round Secure Equality Testing and Comparison</title>
<link>https://eprint.iacr.org/2024/949</link>
<guid>https://eprint.iacr.org/2024/949</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全等值测试、安全比较、两方计算、在线/离线范式、通信成本

总结:
本文提出了新的常数轮两方计算（2PC）协议，用于安全等值测试和比较。这些协议基于在线/离线范式设计，针对32位输入，其等值测试协议的在线通信成本低至76比特（ABY的1%），而安全比较协议的成本为384比特（ABY的5%）。实验结果显示：(1) 对于32位等值测试，相较于Guo等人（EUROCRYPT 2023）的方案，我们的方案速度快了9倍，比采用半门优化的加密封装电路（CRYPTO 2015）快了15倍；(2) 在32位的安全比较中，我们的方案比Guo等人（EUROCRYPT 2023）快3倍，同时比Rathee等人（CCS 2020）以及采用半门优化的加密封装电路快6倍。 <div>
Secure equality testing and comparison are two important primitives widely used in many secure computation scenarios, such as  privacy-preserving machine learning,  private set intersection, and secure data mining, etc. This work proposes new constant-round two-party computation (2PC) protocols for secure equality testing and comparison. 
Our protocols are designed in the online/offline paradigm. 
For 32-bit inputs, the online communication cost of our equality testing protocol and secure comparison protocol are as low as 76 bits (1\% of ABY) and 384 bits (5\% of ABY) , respectively.  
Our benchmarks show that (i) for 32-bit equality testing, our scheme performs $9 \times$ faster than the Guo \emph{et al.} (EUROCRYPT 2023) and $15 \times$ of the garbled circuit (GC) with the half-gate optimization (CRYPTO 2015). (ii) for 32-bit secure comparison, our scheme performs  $3 \times$ faster than Guo \emph{et al.} (EUROCRYPT 2023), $6 \times$ faster than both Rathee \emph{et al.} (CCS 2020) and GC with the half-gate optimization.
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 06:22:37 +0000</pubDate>
</item>
<item>
<title>One-shot Signatures and Applications to Hybrid Quantum/Classical Authentication</title>
<link>https://eprint.iacr.org/2020/107</link>
<guid>https://eprint.iacr.org/2020/107</guid>
<content:encoded><![CDATA[
<div> 关键词：one-shot signatures、量子无克隆定理、经典oracle、indistinguishability obfuscation、混合量子/古典密码学任务

<br /><br />总结:
本文提出了“一次签名”(one-shot signatures)的概念，这是一种利用量子无克隆定理实现的签名方案，其特点是私钥只能用于签署一条消息后即自我销毁。文章表明，在经典预言机的帮助下可以构造这样的签名方案，并通过已知的不可区分混淆方案进行启发式模糊化处理。此外，文章展示了这种一次性签名在混合量子/古典密码学任务中的广泛应用，包括一次性签名令牌、基于经典通信的量子货币、无需区块链的去中心化加密货币、具有不可复制私钥的签名方案、非交互式的可证明最小熵等。因此，作者将一次签名定位为新型量子密码协议的重要构建模块。 <div>
We define the notion of one-shot signatures, which are signatures where any secret key can be used to sign only a single message, and then self-destructs. While such signatures are of course impossible classically, we construct one-shot signatures using quantum no-cloning. In particular, we show that such signatures exist relative to a classical oracle, which we can then heuristically obfuscate using known indistinguishability obfuscation schemes.

We show that one-shot signatures have numerous applications for hybrid quantum/classical cryptographic tasks, where all communication is required to be classical, but local quantum operations are allowed. Applications include one-time signature tokens, quantum money with classical communication, decentralized blockchain-less cryptocurrency, signature schemes with unclonable secret keys, non-interactive certifiable min-entropy, and more. We thus position one-shot signatures as a powerful new building block for novel quantum cryptographic protocols.
]]></content:encoded>
<pubDate>Tue, 04 Feb 2020 16:18:02 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Stealth Address Protocols</title>
<link>https://eprint.iacr.org/2025/112</link>
<guid>https://eprint.iacr.org/2025/112</guid>
<content:encoded><![CDATA[
<div> 关键词：Stealth Address Protocol (SAP)，Dual-Key SAP (DKSAP)，Elliptic Curve Pairing Dual-Key SAP (ECPDKSAP)，量子攻击，Lattice-based cryptography，Learning With Errors (LWE)，Ring-LWE SAP，Module-LWE SAP

总结:
本文介绍了三种基于 lattice-based 密码学的新式 Stealth Address Protocol (SAP)：LWE SAP、Ring-LWE SAP 和 Module-LWE SAP。这些协议利用 Learning With Errors (LWE) 问题确保了对量子攻击的抵抗性。其中，基于 Kyber 密钥封装机制的 Module-LWE SAP 表现出最佳性能，在ephemeral 公开密钥登记簿的扫描时间上相比 ECPDKSAP 提高了约 66.8% 的效率。这三种新型 SAP 为解决依赖于椭圆曲线密码学并可能受量子计算机威胁的现有 SAP（如 DKSAP 和 ECPDKSAP）提供了替代方案。 <div>
The Stealth Address Protocol (SAP) allows users to receive assets through stealth addresses that are unlinkable to their stealth meta-addresses. The most widely used SAP, Dual-Key SAP (DKSAP), and the most performant SAP, Elliptic Curve Pairing Dual-Key SAP (ECPDKSAP), are based on elliptic curve cryptography, which is vulnerable to quantum attacks. These protocols depend on the elliptic curve discrete logarithm problem, which could be efficiently solved on a sufficiently powerful quantum computer using the Shor algorithm. In this paper three novel post-quantum SAPs based on lattice-based cryptography are presented: LWE SAP, Ring-LWE SAP and Module-LWE SAP. These protocols leverage Learning With Errors (LWE) problem to ensure quantum-resistant privacy. Among them, Module-LWE SAP, which is based on the Kyber key encapsulation mechanism, achieves the best performance and outperforms ECPDKSAP by approximately 66.8% in the scan time of the ephemeral public key registry.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 15:01:35 +0000</pubDate>
</item>
<item>
<title>A Formal Treatment of Homomorphic Encryption Based Outsourced Computation in the Universal Composability Framework</title>
<link>https://eprint.iacr.org/2025/109</link>
<guid>https://eprint.iacr.org/2025/109</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, Secure Function Evaluation, Outsourced Computation, Non-Interactive, Sender Privacy

总结:
这篇文章讨论了同态加密和安全函数评估技术在实际应用中的局限性。作者在尝试将一个简单的 PSI 协议应用于基于用户资料匹配的网络服务时，发现现有的外包框架存在不足，要么要求客户端执行超出贡献输入的任务，要么依赖于服务器与客户端之间的非共谋假设，这在网络服务场景中显得不切实际。为此，他们提出了首个基于黑盒同态加密的非交互式外包计算通用构造，该方法依赖于两个专用服务器间的非共谋假设，更符合网络服务环境的现实情况。此外，他们在通用可组合性（UC）框架下为这一构造提供了安全性证明，假定对手为半诚实（即被动）的。不同于一般的单向两方 SFE 协议，该构造还特别强调发送方隐私，要求发送方仅以加密形式提供其输入，从而实现更强的隐私保护并拓宽协议的应用范围。这个新构造适用于所有单向两方发送方私密的安全函数评估协议以及基于服务器的加密输入算术运算。最后，文章通过将其应用于实际场景下的外包私人集合交集（OPSI）来展示了该通用外包计算框架的实际适用性，并对其效率进行了详细的评估。 <div>
The adoption of Homomorphic Encryption (HE) and Secure
Function Evaluation (SFE) applications in the real world remains lim-
ited, even nearly 50 years after the introduction of HE. This is particu-
larly unfortunate given the strong privacy and confidentiality guarantees
these tools can offer to modern digital life.
While attempting to incorporate a simple straw-man PSI protocol into
a web service for matching individuals based on their profiles, we en-
countered several shortcomings in current outsourcing frameworks. Ex-
isting outsourced protocols either require clients to perform tasks beyond
merely contributing their inputs or rely on a non-collusion assumption
between a server and a client, which appears implausible in standard web
service scenarios.
To address these issues, we present, to the best of our knowledge, the first
general construction for non-interactive outsourced computation based
on black-box homomorphic encryption. This approach relies on a non-
collusion assumption between two dedicated servers, which we consider
more realistic in a web-service setting. Furthermore, we provide a proof
of our construction within the Universal Composability (UC) framework,
assuming semi-honest (i.e., passive) adversaries.
Unlike general one-sided two-party SFE protocols, our construction addi-
tionally requires sender privacy. Specifically, the sender must contribute
its inputs solely in encrypted form. This ensures stronger privacy guar-
antees and broadens the applicability of the protocol.
Overall, the range of applications for our construction includes all one-
sided two-party sender-private SFE protocols as well as server-based
arithmetic computations on encrypted inputs. Finally, we demonstrate
the practical applicability of our general outsourced computation frame-
work by applying it to the specific use case of Outsourced Private Set
Intersection (OPSI) in a real-world scenario, accompanied by a detailed
evaluation of its efficiency.
]]></content:encoded>
<pubDate>Thu, 23 Jan 2025 13:01:38 +0000</pubDate>
</item>
<item>
<title>Additive Randomized Encodings from Public Key Encryption</title>
<link>https://eprint.iacr.org/2025/104</link>
<guid>https://eprint.iacr.org/2025/104</guid>
<content:encoded><![CDATA[
<div> 关键词: Additive Randomized Encodings (ARE), k-party function, non-interactive secure function evaluation, shuffle model, public-key encryption

<br /><br />总结:
本文介绍了由Halevi、Ishai、Kushilevitz和Rabin在CRYPTO 2023上提出的加性随机编码（ARE），这种技术将$k$方函数$f(x_1,\dots,x_k)$的计算简化为对每个输入$x_i$进行局部编码$\hat x_i$，然后在一个阿贝尔群中将其相加得到输出编码$\hat y = \sum \hat x_i$，而不会泄露除结果以外的任何信息。ARE的吸引力在于其非局部计算仅涉及加法操作，这使得在洗牌模型中的非交互式安全函数评估成为可能。原文通过双线性群中的Diffie-Hellman类型假设构建了ARE。而本文则提出了基于公钥加密的ARE构造方法，关键思想是一方隐私保护的单向ARE相对容易实现，可以通过某种方式提升为完整的ARE，并给出了从CDH假设出发的更高效的黑盒构造方法。 <div>
Introduced by Halevi, Ishai, Kushilevitz, and Rabin (CRYPTO 2023), Additive randomized encodings (ARE) reduce the computation of a $k$-party function $f(x_1,\dots,x_k)$ to locally computing encodings $\hat x_i$ of each input $x_i$ and then adding them together over some Abelian group into an output encoding $\hat y = \sum \hat x_i$, which reveals nothing but the result. The appeal of ARE comes from the simplicity of the non-local computation, involving only addition. This gives rise for instance to non-interactive secure function evaluation in the shuffle model where messages from different parties are anonymously shuffled before reaching their destination. Halevi, Ishai, Kushilevitz, and Rabin constructed ARE based on Diffie-Hellman type assumptions in bilinear groups.

We construct ARE assuming public-key encryption. The key insight behind our construction is that one-sided ARE, which only guarantees privacy for one of the parties, are relatively easy to construct, and yet can be lifted to full-fledged ARE. We also give a more efficient black-box construction from the CDH assumption.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 17:33:25 +0000</pubDate>
</item>
<item>
<title>Unveiling Privacy Risks in Quantum Optimization Services</title>
<link>https://eprint.iacr.org/2025/101</link>
<guid>https://eprint.iacr.org/2025/101</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算量子计算、隐私保护、混淆方法、变量置换、组合方法、攻击策略、Trivium密码家族、优化问题、复杂度、反制措施。

总结：
随着云计算量子计算服务（如D-Wave提供的服务）在实际应用中的普及，针对数据安全、隐私和法律合规的关注日益增加，因此隐私保护方法（如混淆）变得至关重要。文章指出了已提出的用于量子优化问题的混淆方法中，签反向已被证明不安全。研究提出了对变量置换及组合方法的两种攻击策略，能在被提供模糊化问题及其解决方案的情况下，有效地恢复原问题，特别是在解决Trivium密码家族的加密分析优化问题上下文中。这些攻击策略具有高效性和实用性，对于拥有n个变量、采用组合方法混淆的问题，解混淆复杂度仅为$O(n^2)$，远低于暴力破解所需的$O\left( n \cdot n! \cdot 2^n \right)$。文章还提供了攻击实现并演示了其在处理全量Trivium密码时可在两分钟内的高效运行，并提出了可能的反制措施，强调了在此领域进一步发展的必要性。<br /><br /> <div>
As cloud-based quantum computing services, such as those offered by D-Wave, become more popular for practical applications, privacy-preserving methods (such as obfuscation) are essential to address data security, privacy, and legal compliance concerns.
Several efficient obfuscation methods have been proposed, which do not increase the time complexity of solving the obfuscated problem, for quantum optimization problems. These include {\em sign reversing}, {\em variable permutation}, and the combination of both methods assumed to provide greater protection. Unfortunately, sign reversing has already been shown to be insecure. 

We present two attacks on variable permutation and the combined method, where it is possible to efficiently recover the deobfuscated problem, particularly when given access to the obfuscated problem and its obfuscated solution, as a cloud-based quantum provider would have.
Our attacks are in the context of an optimization problem of cryptanalysis of the Trivium cipher family, but our approach generalizes to other similarly structured problems.

Our attacks are efficient and practical.
Deobfuscating an optimization problem with \( n \) variables obfuscated with the combined method has a complexity of $O(n^2)$ compared to the complexity of $O\left( n \cdot n! \cdot 2^n \right)$ of the brute force attack.
We provide an implementation of our attack; using a commodity laptop, our attack using the full Trivium cipher takes less than two minutes if optimized.
We also present possible countermeasures to mitigate our attacks and bring attention to the need for further development in this area.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 11:58:36 +0000</pubDate>
</item>
<item>
<title>Fast, private and regulated payments in asynchronous networks</title>
<link>https://eprint.iacr.org/2025/098</link>
<guid>https://eprint.iacr.org/2025/098</guid>
<content:encoded><![CDATA[
<div> 关键词：去中心化、完全隐私、非交互式零知识证明（NIZK）、监管机制、Paxpay

总结:<br />
我们提出了一种去中心化的资产转移系统，该系统实现了全面的隐私保护，除了交易发起者和接收者之外，任何一方都无法得知交易详情，而接收者只知道交易金额。此系统不依赖共识或同步假设，因此具有响应性，能以实际网络速度运行。每个交易会在生成可消费的代币时附带一个NIZK，用于证实发行方有足够的资金，但不会泄露其身份信息、接收方的身份信息或支付金额等任何信息。此外，我们的系统还配备了一个监管执行机制，能够在保持系统隐私保证的同时，对转账限额或特定地址的资金收发进行限制。最后，我们报告了使用Gnark库实现全私有资产转移（FPAT）的Paxpay系统，并在基准测试中表现出优于以往仅提供部分隐私保护、需要网络同步假设或者未实施监管功能的提案的性能。因此，我们的系统成功地兼顾了隐私、响应性、监管执行与性能。 <div>
We propose a decentralized asset-transfer system that enjoys full privacy: no party can learn the details of a transaction, except for its issuer and its recipient. Furthermore, the recipient is only aware of the amount of the transaction. Our system does not rely on consensus or synchrony assumptions, and therefore, it is responsive, since it runs at the actual network speed. Under the hood, every transaction creates a consumable coin equipped with a non-interactive zero-knowledge proof (NIZK) that confirms that the issuer has sufficient funds without revealing any information about her identity, the recipient's identity, or the payment amount. Moreover, we equip our system with a regulatory enforcement mechanism that can be used to regulate transfer limits or restrict specific addresses from sending or receiving funds, while preserving the system's privacy guarantees.
        
Finally, we report on Paxpay, our implementation of Fully Private Asset Transfer (FPAT) that uses the Gnark library for the NIZKs. In our benchmark, Paxpay exhibits better performance than earlier proposals that either ensure only partial privacy, require some kind of network synchrony or do not implement regulation features. Our system thus reconciles privacy, responsiveness, regulation enforcement and performance.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 09:01:00 +0000</pubDate>
</item>
<item>
<title>Available Attestation: Towards a Reorg-Resilient Solution for Ethereum Proof-of-Stake</title>
<link>https://eprint.iacr.org/2025/097</link>
<guid>https://eprint.iacr.org/2025/097</guid>
<content:encoded><![CDATA[
<div> 关键词: 以太坊、权益证明(PoS)共识、重组织攻击、安全性、效率

总结:
<br />
以太坊已于2022年9月从工作量证明(PoW)共识机制转变为权益证明(PoS)共识。然而，这一升级引入了新的安全隐患，如恶意重组织攻击，攻击者通过故意操纵权威链以摒弃诚实验证器的区块，从而获取更多收益或威胁系统活性。文章指出，许多针对以太坊PoS的已知攻击实质上都属于重组织攻击，且这些攻击即使在网络同步（存在消息传输和处理的已知上限）的情况下也能实施。与现有的针对性防御措施不同，本文提出了一种系统性方法，提供了一个既优雅又高效的解决方案来抵御重组织攻击，该方案在同步网络中被证明是安全的，无法发起重组织攻击；在部分同步网络中，则能实现共识协议的传统安全性与活性属性。评估结果显示，该解决方案能够抵抗五种类型的重组织攻击，并具有高效率。 <div>
Ethereum transitioned from Proof-of-Work consensus to Proof-of-Stake (PoS) consensus in September 2022. While this upgrade brings significant improvements (e.g., lower energy costs and higher throughput), it also introduces new vulnerabilities. One notable example is the so-called malicious \textit{reorganization attack}. Malicious reorganization denotes an attack in which the Byzantine faulty validators intentionally manipulate the canonical chain so the blocks by honest validators are discarded. By doing so, the faulty validators can gain benefits such as higher rewards, lower chain quality, or even posing a liveness threat to the system. 

In this work, we show that the majority of the known attacks on Ethereum PoS are some form of reorganization attacks. In practice, most of these attacks can be launched even if the network is synchronous (there exists a known upper bound for message transmission and processing). Different from existing studies that mitigate the attacks in an ad-hoc way, we take a systematic approach and provide an elegant yet efficient solution to reorganization attacks. Our solution is provably secure such that no reorganization attacks can be launched in a synchronous network. In a partially synchronous network, our approach achieves the conventional safety and liveness properties of the consensus protocol. Our evaluation results show that our solution is resilient to five types of reorganization attacks and also highly efficient.
]]></content:encoded>
<pubDate>Wed, 22 Jan 2025 02:15:20 +0000</pubDate>
</item>
<item>
<title>A Survey on Transciphering and Symmetric Ciphers for Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2025/093</link>
<guid>https://eprint.iacr.org/2025/093</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私、同态加密、计算负载、通信开销、HE友好密码体制<br /><br />总结:
随着云计算、大数据分析和物联网的发展，数据隐私问题日益凸显。同态加密作为一种在加密数据上进行计算的技术，因其现有方案存在加密速度慢和密文膨胀大的缺点，其实际应用受到限制，尤其是在客户端资源有限的情况下。为解决此问题，Naehrig等人于2011年提出了转置加密技术，旨在减少客户端的计算和通信负担，这种技术依赖于具有最小乘法复杂度的对称密码体制，被称为HE友好密码体制（HEFCs）。本文详细研究了同态加密中的转置加密技术，系统整理了现有的知识并明确了研究挑战，重点考察了最先进的HEFC构造方法。我们的工作突显出了该领域的研究空白、未解决问题及未来研究方向。 <div>
Data privacy concerns are sharply rising in the current digital era, hyperdriven by cloud computing, big data analytics, and the Internet of Things. Homomorphic Encryption (HE) has emerged as an ideal technique for computing on encrypted data, but current schemes suffer from slow encryption speed and large ciphertext expansion. Practical implementation is hindered, especially when the client has limited bandwidth, memory, and computing power. In 2011, Naehrig et al. proposed transciphering, reducing computational and communication overload on the client side. This involves symmetric ciphers with minimized multiplicative complexity, 
referred to as HE-Friendly Ciphers (HEFCs). 

In this work, we present a detailed study of transciphering for HE by systematizing existing knowledge and crystallizing research challenges. Particularly we conduct a comprehensive study on state-of-the-art HEFC constructions. Our work highlights gaps, open problems, and directions for future research.
]]></content:encoded>
<pubDate>Tue, 21 Jan 2025 23:05:50 +0000</pubDate>
</item>
<item>
<title>poqeth: Efficient, post-quantum signature verification on Ethereum</title>
<link>https://eprint.iacr.org/2025/091</link>
<guid>https://eprint.iacr.org/2025/091</guid>
<content:encoded><![CDATA[
<div> 关键词：后量子密码学（Post-Quantum）、数字签名、区块链、以太坊虚拟机、Naysayer 证明

总结:<br />
本文探讨了在区块链环境中标准化后量子数字签名算法的应用与高效部署，特别地，实现了并评估了四种PQ签名算法——W-OTS$^+$、XMSS、SPHINCS+和MAYO在以太坊虚拟机上的表现。文章重点关注优化验证算法的 Gas 成本，因为这是用户承担交易费用的关键因素。研究中，作者考察了两种在链上验证后量子数字签名的方法，实际性能评估显示，完全在链上验证的成本往往过高。为此，提出了利用 Naysayer 证明实现的一种新型乐观验证模式，该模式通常成本最低，但需增加额外的信任假设。最后，作者将其实现成果 poqeth 开源作为一个库公开发布。 <div>
This work explores the application and efficient deployment of (standardized) post-quantum (PQ) digital signature algorithms in the blockchain environment. Specifically, we implement and evaluate four PQ signatures in the Ethereum Virtual Machine: W-OTS$^{+}$, XMSS, SPHINCS+, and MAYO. We focus on optimizing the gas costs of the verification algorithms as that is the signature schemes' only algorithm executed on-chain, thus incurring financial costs (transaction fees) for the users. Hence, the verification algorithm is the signature schemes' main bottleneck for decentralized applications.

We examine two methods to verify post-quantum digital signatures on-chain. Our practical performance evaluation shows that full on-chain verification is often prohibitively costly. Naysayer proofs (FC'24) allow a novel optimistic verification mode. We observe that the Naysayer verification mode is generally the cheapest, at the cost of additional trust assumptions. We release our implementation called poqeth as an open-source library.
]]></content:encoded>
<pubDate>Tue, 21 Jan 2025 15:03:01 +0000</pubDate>
</item>
<item>
<title>ICT: Insured Cryptocurrency Transactions</title>
<link>https://eprint.iacr.org/2025/088</link>
<guid>https://eprint.iacr.org/2025/088</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币、欺诈风险、保险框架、Insured Cryptocurrency Transactions (ICT)、Insured Cryptocurrency Exchange (ICE)

总结:<br />
本文提出了一个针对加密货币交易中欺诈风险问题的解决方案——Insured Cryptocurrency Transactions (ICT)，这是一种新颖的去中心化保险框架，旨在保障因欺诈交易受损的诚实用户能够获得财务补偿。ICT框架通过严格的正式化方法确保了强大的安全性，以抵御恶意攻击者。文章进一步介绍了ICT的一个具体应用实例——Insured Cryptocurrency Exchange (ICE)，它是一个针对中心化加密货币交易所设计的保险机制，利用智能合约在交易所遭受安全漏洞、破产或发生欺诈行为等情况时，为用户提供赔偿。已经实现了ICE的智能合约并对其进行了链上成本评估，结果显示其具有较低的运行开销。据作者所知，ICT和ICE是加密货币领域内首个正式提出的去中心化保险框架方案。 <div>
Cryptocurrencies have emerged as a critical medium for digital financial transactions, driving widespread adoption while simultaneously exposing users to escalating fraud risks. The irreversible nature of cryptocurrency transactions, combined with the absence of consumer protection mechanisms, leaves users vulnerable to substantial financial losses and emotional distress. To address these vulnerabilities, we introduce Insured Cryptocurrency Transactions (ICT), a novel decentralized insurance framework designed to ensure financial recovery for honest users affected by fraudulent cryptocurrency transactions. We rigorously formalize the ICT framework, establishing strong security guarantees to protect against malicious adversaries. Furthermore, we present Insured Cryptocurrency Exchange (ICE), a concrete instantiation of ICT tailored for centralized cryptocurrency exchanges. ICE relies primarily on a standard smart contract and provides a robust mechanism to compensate users in cases of security breaches, insolvency, or fraudulent activities affecting the exchange. We have implemented ICE’s smart contract and evaluated its on-chain costs. The evaluation results demonstrate ICE’s low operational overhead. To our knowledge, ICT and ICE represent the first formal approaches to decentralized insurance frameworks in the cryptocurrency domain.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 19:14:25 +0000</pubDate>
</item>
<item>
<title>Arbitrary-Threshold Fully Homomorphic Encryption with Lower Complexity</title>
<link>https://eprint.iacr.org/2025/084</link>
<guid>https://eprint.iacr.org/2025/084</guid>
<content:encoded><![CDATA[
<div> 关键词: Threshold Fully Homomorphic Encryption (ThFHE), Arbitrary Threshold (ATh)-FHE, Non-participants, Approximate Secret Sharing (ApproxSS), ATASSES

总结:
本文提出了一种新的任意阈值全同态加密(ThFHE)方案——ATh-FHE，旨在解决多方在不泄露敏感数据隐私的情况下计算函数的问题。相较于大多数仅支持完全阈值的ThFHE方案，ATh-FHE能更好地应对非参与者的情况，并适用于更多现实世界的应用场景。然而，现有的ATh-FHE方案要么在处理大量参与方和大数据规模时效率低下，要么无法容忍所有类型的非参与者。为此，本文提出了一个新的抽象原语——近似秘密分享(ApproxSS)，并将ATh-FHE方案的构建归约为设计该原语的问题。通过建立ApproxSS与ATh-FHE之间正确性和安全性的理论证明，作者揭示了现有ATh-FHE方案隐含地采用了“噪声份额”的设计理念，但这种方法存在高复杂度问题，成为性能瓶颈。为了解决这个问题，文章开发了一个基于“加密份额”新理念的ATh-ApproxSS方案——ATASSES，将其计算和通信复杂度分别从$\mathcal{O}(N^2K)$降低到$\mathcal{O}(N^2+K)$和从$\mathcal{O}(NK)$降低到$\mathcal{O}(N+K)$。理论分析与实证评估均表明，相比于现有基准方案，当应用于包含一千个参与方的系统时，ATASSES可实现高达$3.83\times$至$15.4\times$的速度提升。 <div>
Threshold fully homomorphic encryption (ThFHE) enables multiple parties to compute functions over their sensitive data without leaking data privacy. Most of existing ThFHE schemes are restricted to full threshold and require the participation of all parties to output computing results. Compared with these full-threshold schemes, arbitrary threshold (ATh)-FHE schemes are robust to non-participants and can be a promising solution to many real-world applications. However, existing AThFHE schemes are either inefficient to be applied with a large number of parties $N$ and a large data size $K$, or insufficient to tolerate all types of non-participants. In this paper, we propose an AThFHE scheme to handle all types of non-participants with lower complexity over existing schemes. At the core of our scheme is the reduction from AThFHE construction to the design of a new primitive called approximate secret sharing (ApproxSS). Particularly, we formulate ApproxSS and prove the correctness and security of AThFHE on top of arbitrary-threshold (ATh)-ApproxSS's properties. Such a reduction reveals that existing AThFHE schemes implicitly design ATh-ApproxSS following a similar idea called ``noisy share''. Nonetheless, their ATh-ApproxSS design has high complexity and become the performance bottleneck. By developing ATASSES, an ATh-ApproxSS scheme based on a novel ``encrypted share'' idea, we reduce the computation (resp. communication) complexity from $\mathcal{O}(N^2K)$ to $\mathcal{O}(N^2+K)$ (resp. from $\mathcal{O}(NK)$ to $\mathcal{O}(N+K)$). We not only theoretically prove the (approximate) correctness and security of ATASSES, but also empirically evaluate its efficiency against existing baselines. Particularly, when applying to a system with one thousand parties, ATASSES achieves a speedup of $3.83\times$ -- $15.4\times$ over baselines.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 02:29:50 +0000</pubDate>
</item>
<item>
<title>Recover from Excessive Faults in Partially-Synchronous BFT SMR</title>
<link>https://eprint.iacr.org/2025/083</link>
<guid>https://eprint.iacr.org/2025/083</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine故障容错(BFT SMR), 过度故障设置, 修复算法, 线性链状、群组同步SMR, 故障检测模块

总结:
本文研究了在过度故障设置下，拜占庭容错（BFT SMR）状态机复制协议如何从由过多故障引发的错误状态中恢复。首先，文章提出了首个针对线性链状和基于群组同步的SMR的部分故障修复算法，该算法利用不误判正常副本的任何故障检测模块实现。在此过程中，虽然活动生成保证略有减弱，但原文档中不可能在存在过多故障的情况下维持原安全特性。

文章实现了可恢复的HotStuff协议，并使用Rust编程语言完成。在恢复程序结束后，当有7个副本发生故障时，吞吐量恢复到无过多故障情况下的正常水平，并且在有30个副本发生故障时，仅减少了不超过4.3%。平均而言，对于7个副本，延迟增加了12.87%\usenix{(而对于30个副本，延迟增加为8.85%)}。

此外，文章还建立了对于具有最多(n-2)个（总共有n个副本）拜占庭副本攻击安全性的情况，一般BFT SMR协议能够实现完整且准确的故障检测的充分条件。文章首次提出了一种适用于任意SMR协议的无需额外通信轮次的封闭式故障检测算法，并进一步描述了在Tendermint和HotStuff中的开箱即用的故障检测例程，从而在理论上和具体实现上都降低了开销。 <div>
Byzantine fault-tolerant (BFT) state machine replication (SMR) protocols form the basis of modern blockchains as they maintain a consistent state across all blockchain nodes while tolerating a bounded number of Byzantine faults. We analyze BFT SMR in the excessive fault setting where the actual number of Byzantine faults surpasses a protocol's tolerance. 

We start by devising the very first repair algorithm for linearly chained and quorum-based partially synchronous SMR to recover from faulty states caused by excessive faults. Such a procedure can be realized using any commission fault detection module -- an algorithm that identifies the faulty replicas without falsely locating any correct replica. We achieve this with a slightly weaker liveness guarantee, as the original security notion is impossible to satisfy given excessive faults.


We implement recoverable HotStuff in Rust. The throughput resumes to the normal level (without excessive faults) after recovery routines terminate for $7$ replicas and is slightly reduced by $\leq 4.3\%$ for $30$ replicas. On average, it increases the latency by $12.87\%$ for $7$ replicas \usenix{and $8.85\%$ for $30$ replicas}.

Aside from adopting existing detection modules, we also establish the sufficient condition for a general BFT SMR protocol to allow for complete and sound fault detection when up to $(n-2)$ Byzantine replicas (out of $n$ total replicas) attack safety. We start by providing the first closed-box fault detection algorithm for any SMR protocol without any extra rounds of communication. We then describe open-box instantiations of our fault detection routines in Tendermint and Hotstuff, further reducing the overhead, both asymptotically and concretely.
]]></content:encoded>
<pubDate>Mon, 20 Jan 2025 00:31:06 +0000</pubDate>
</item>
<item>
<title>Breaking verifiability and vote privacy in CHVote</title>
<link>https://eprint.iacr.org/2025/080</link>
<guid>https://eprint.iacr.org/2025/080</guid>
<content:encoded><![CDATA[
<div> 关键词: CHVote、电子投票系统、瑞士、安全性漏洞、攻击

总结:<br />
CHVote是瑞士政治选举中开发的主要电子投票系统之一，其运作需满足特定法规和信任假设。然而，研究发现，只要其中一个在线组件不诚实，CHVote就无法实现投票秘密性和个人投票意图可验证性，这与CHVote的安全声明相矛盾。研究人员共发现了针对CHVote的9种攻击或变体，其中2种源于其参考实现中的bug。这些发现已通过概念验证的攻击实施得到确认。 <div>
Abstract. CHVote is one of the two main electronic voting systems developed in the context of political elections in Switzerland, where the regulation requires a specific setting and specific trust assumptions.  We show that actually, CHVote fails to achieve vote secrecy and individual verifiability (here, recorded-as-intended), as soon as one of the online components is dishonest, contradicting the security claims of CHVote.  In total, we found 9 attacks or variants against CHVote, 2 of them being based on a bug in the reference implementation. We confirmed our findings through a proof-of-concept implementation of our attacks.
]]></content:encoded>
<pubDate>Sat, 18 Jan 2025 13:34:35 +0000</pubDate>
</item>
<item>
<title>Hardware-Accelerated Encrypted Execution of General-Purpose Applications</title>
<link>https://eprint.iacr.org/2023/641</link>
<guid>https://eprint.iacr.org/2023/641</guid>
<content:encoded><![CDATA[
<div> 关键词：Fully Homomorphic Encryption (FHE)，CGGI方案，ArctyrEX，加速加密执行，GPU加速Concrete库

总结:
本文研究了全同态加密（FHE）技术，特别是当前先进的基于环域的CGGI方案。针对CGGI方案在处理如sigmoid等简单非线性函数时效率低下的问题，文章提出了一种名为ArctyrEX的新框架，该框架能实现端到端的加速加密执行。使用ArctyrEX，开发者无需深入了解复杂的FHE库，只需以C程序描述计算任务，相比于GPU加速的Concrete库，在乘法密集型基准测试中平均性能提升了18倍。 <div>
Fully Homomorphic Encryption (FHE) is a cryptographic method that guarantees the privacy and security of user data during computation. FHE algorithms can perform unlimited arithmetic computations directly on encrypted data without decrypting it. Thus, even when processed by untrusted systems, confidential data is never exposed. In this work, we develop new techniques for accelerated encrypted execution and demonstrate the significant performance advantages of our approach. Our current focus is the Fully Homomorphic Encryption over the Torus (CGGI) scheme, which is a current state-of-the-art method for evaluating arbitrary functions in the encrypted domain. CGGI represents a computation as a graph of homomorphic logic gates and each individual bit of the plaintext is transformed into a polynomial in the encrypted domain. Arithmetic on such data becomes very expensive: operations on bits become operations on entire polynomials.  Therefore, evaluating even relatively simple nonlinear functions with the CGGI cryptosystem, such as a sigmoid, can take thousands of seconds on a single CPU thread. Using our novel framework for end-to-end accelerated encrypted execution called ArctyrEX, developers with no knowledge of complex FHE libraries can simply describe their computation as a C program that is evaluated 18x faster on average relative to the GPU-accelerated Concrete library for multiplication-intensive benchmarks.
]]></content:encoded>
<pubDate>Fri, 05 May 2023 15:25:03 +0000</pubDate>
</item>
<item>
<title>On Multi-Key FuncCPA Secure Encryption Schemes</title>
<link>https://eprint.iacr.org/2025/077</link>
<guid>https://eprint.iacr.org/2025/077</guid>
<content:encoded><![CDATA[
<div> 关键词：funcCPA安全、同态加密、非同态公钥加密、多密钥设置、KDM安全

总结:
文章介绍了funcCPA安全性这一概念，最初由Akavia等人在TCC 2022上提出，主要针对同态加密中的引导技术。然而，Dodis等人在TCC 2023中指出，funcCPA安全也可应用于非同态公钥加密，特别是在无同态计算情况下的隐私保护外包计算领域。尽管前期研究仅关注单密钥设定，但近年来多 parties 合作在外包计算中的重要性日益凸显，使得对funcCPA安全支持多密钥设置的需求变得迫切。因此，本文引入了一个新的安全性概念——多密钥funcCPA（MKfunc）以满足这一需求，并证明如果一个公钥加密方案具备KDM安全性，则它也具有MKfuncCPA安全性。此外，文中还讨论了该理论可同样适用于对称密钥加密的情况。 <div>
The notion of funcCPA security for homomorphic encryption schemes was introduced by Akavia \textit{et~al.}\ (TCC 2022). Whereas it aims to capture the bootstrapping technique in homomorphic encryption schemes, Dodis \textit{et~al.}\ (TCC 2023) pointed out that funcCPA security can also be applied to non-homomorphic public-key encryption schemes (PKE). As an example, they presented a use case for privacy-preserving outsourced computation without homomorphic computation. It should be noted that prior work on funcCPA security, including the use case presented by Dodis \textit{et~al.}, considered only the single-key setting. However, in recent years, multi-party collaboration in outsourced computation has garnered significant attention, making it desirable for funcCPA security to support the multi-key setting. Therefore, in this work, we introduce a new notion of security called Multi-Key funcCPA (MKfunc) to address this need, and show that if a PKE scheme is KDM-secure, then it is also MKfuncCPA secure. Furthermore, we show that similar discussions can be applied to symmetric-key encryption.
]]></content:encoded>
<pubDate>Fri, 17 Jan 2025 13:28:27 +0000</pubDate>
</item>
<item>
<title>RSA Blind Signatures with Public Metadata</title>
<link>https://eprint.iacr.org/2023/1199</link>
<guid>https://eprint.iacr.org/2023/1199</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名令牌、公共元数据、RSA盲签名、安全性证明、实际部署

<br /><br />总结: 本文研究了具有公共元数据的匿名令牌概念，这是一种允许发行者生成与特定公共元数据相关联的签名，同时保护用户身份隐私的技术。文中提出了一种RSA盲签名的变体，该变体仅能为预设的公共元数据生成有效的签名，其基于Abe和Fujisaki的一项方案进行改进，并使用标准密码学技术实现。安全性的证明建立在一个带有多个指数的一次性RSA假设上，预计其实际安全性接近标准RSA盲签名。实验结果显示，此协议相比标准RSA盲签名仅有轻微的开销，并已作为技术规范被纳入一个IRTF互联网草案中，还展示了其实战部署的可扩展性。 <div>
Anonymous tokens are, essentially, digital signature schemes that enable issuers to provide users with signatures without learning the user inputs or the final signatures. These primitives allow applications to propagate trust while simultaneously protecting the user identity. They have become a core component for improving the privacy of several real-world applications including ad measurements, authorization protocols, spam detection, and VPNs.
In certain applications, it is natural to associate signatures with specific public metadata, ensuring that trust is only propagated with respect to only a certain set of users and scenarios. To solve this, we study the notion of anonymous tokens with public metadata. We present a variant of RSA blind signatures with public metadata where issuers may only generate signatures that verify for a certain choice of public metadata a modification of a scheme by Abe and Fujisaki [9]. Our protocol exclusively uses standard cryptography with widely available implementations. We prove security from the one-more RSA assumptions with multiple exponents that we introduce. Furthermore, we provide evidence that the concrete security bounds should be nearly identical to standard RSA blind signatures. We show that our protocol incurs minimal overhead over standard RSA blind signatures and report anonymous telemetry for a real-world deployment to showcase its scalability. Moreover, the protocol in this paper has been proposed as a technical specification in an IRTF internet draft [12].
]]></content:encoded>
<pubDate>Tue, 08 Aug 2023 01:23:07 +0000</pubDate>
</item>
<item>
<title>PSMT: Private Segmented Membership Test for Distributed Record Linkage</title>
<link>https://eprint.iacr.org/2025/072</link>
<guid>https://eprint.iacr.org/2025/072</guid>
<content:encoded><![CDATA[
<div> 关键词: Private Segmented Membership Test (PSMT), 多方 PSI (MPSI), 加密 Homomorphic, 带阈值的近似算术, 实验评估

总结:
本文提出了一种基于带阈值的近似算术同态加密的Private Segmented Membership Test (PSMT)基本协议，旨在解决多方数据持有者场景下，客户端查询多个数据元素是否存在于多个加密集合中的隐私保护问题。与现有方法相比，新协议避免了泄露匹配元素持有者的身份信息，降低了处理多元素查询时的通信开销，并减少了大量数据持有者情况下的误报率，同时确保了IND-CPA^D安全级别。该协议具有更好的可扩展性，支持更多的数据持有者和查询元素（实验中可达4096个参与方和512个查询）。实验结果显示，在处理来自1024个数据持有者的、大小为2^15的集合的结果聚合时，仅需71.2秒，每增加一个查询仅需额外1.2秒。相较于其他现有的PSI和MPSI协议以及先前的工作，新的PSMT协议在可用性和更强的隐私模型方面有所改进，并能支持更大数量的参与者和查询。 <div>
In various real-world situations, a client may need to verify whether specific data elements they possess are part of a set segmented among numerous data holders. 
To maintain user privacy, it’s essential that both the client’s data elements and the data holders’ sets remain encrypted throughout the process. 
Existing approaches like Private Set Intersection (PSI), Multi-Party PSI (MPSI), Private Segmented Membership Test (PSMT), and Oblivious RAM (ORAM) face challenges in these contexts.
They either require data holders to access the sets in plaintext, result in high latency when aggregating data from multiple holders, risk exposing the identity of the party with the matching element, cause a large communication overhead for multiple-element queries, or lead to high false positives.

This work introduces the primitive of a Private Segmented Membership Test (PSMT) for clients with multiple query elements. 
We present a basic protocol for solving PSMT using a threshold variant of approximate-arithmetic homomorphic encryption, addressing the challenges of avoiding information leakage about the party with the intersection element, minimizing communication overhead for multiple query elements, and preventing false positives for a large number of data holders ensuring IND-CPA^D security.
Our novel approach surpasses current state-of-the-art methods in scalability, supporting significantly more data holders.
This is achieved through a novel summation-based homomorphic membership check rather than a product-based one, as well as various novel ideas addressing technical challenges. 

Our new PSMT protocol supports a large number of parties and query elements (up to 4096 parties and 512 queries in experiments) compared to previous methods.
Our experimental evaluation shows that our method's aggregation of results from 1024 data holders with a set size of 2^15 can run in 71.2s and only requires an additional 1.2 seconds per query for processing multiple queries.
We also compare our PSMT protocol to other state-of-the-art PSI and MPSI protocols and our previous work and discuss our improvements in usability with a better privacy model and a larger number of parties and queries.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 20:04:16 +0000</pubDate>
</item>
<item>
<title>On Composing Generic Voting Schemes for Improved Privacy</title>
<link>https://eprint.iacr.org/2025/069</link>
<guid>https://eprint.iacr.org/2025/069</guid>
<content:encoded><![CDATA[
<div> 关键词：hybrid encryption, 量子计算, 投票方案, 正确性, 完整性, 隐私性

总结:
<br />
本文探讨了混合加密技术如何通过组合多种现有加密方案来在众多计算假设中分布信任，特别是在量子计算发展背景下，使得我们能同时利用后量子时代的隐私性和经典加密方案的成熟性。文章展示了如何将一类非常广泛的投票方案进行组合，并证明这种组合能够保持正确性和完整性的同时，还能提升隐私性相比其组成部分。此外，文中还给出了一个使用基于格的解密混合网络的例子，其中隐私性的提升可以间接带来完整性的改善。 <div>
Hybrid encryption provides a way for schemes to distribute trust among many computational assumptions, for instance by composing existing schemes. This is increasingly relevant as quantum computing advances because it lets us get the best of both worlds from the privacy of the post quantum schemes and the more battle tested classical schemes.
    We show how to compose members of a very general class of voting schemes and prove that this preserves correctness and integrity and improves privacy compared to its constituent parts.
    We also show an example composition using a lattice based decryption mixnet where the improvement in privacy can indirectly lead to an improvement in integrity.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 11:17:28 +0000</pubDate>
</item>
<item>
<title>Shielded CSV: Private and Efficient Client-Side Validation</title>
<link>https://eprint.iacr.org/2025/068</link>
<guid>https://eprint.iacr.org/2025/068</guid>
<content:encoded><![CDATA[
<div> 关键词: Cryptocurrency, Client-Side Validation (CSV), Privacy, Shielded CSV, Proof Carrying Data (PCD)

总结:
本文介绍了Shielded CSV，这是一种改进的客户端验证（CSV）协议，旨在解决加密货币中的通信、计算和存储成本以及隐私问题。相较于传统私人加密货币设计，Shielded CSV只需在区块链上记录每个交易的64字节数据——nullifier，并使接收者执行一次Schnorr签名验证即可，同时非用户可忽略此数据。其coin证明的大小和验证成本与交易历史无关。该方案提出将比特币的交易处理速度提升至每秒100笔，前提是存在适当的桥接机制到区块链。文章利用Proof Carrying Data (PCD)抽象来规范Shielded CSV，并讨论了两种实用的实现策略：基于Folding Schemes和Recursive STARKs的方法，并提出了未来扩展的建议，展示了Shielded CSV框架及其之上构建的协议的巨大潜力。 <div>
Cryptocurrencies allow mutually distrusting users to transact monetary value over the internet without relying on a trusted third party.

Bitcoin, the first cryptocurrency, achieved this through a novel protocol used to establish consensus about an ordered transaction history.
This requires every transaction to be broadcasted and verified by the network, incurring communication and computational costs.
Furthermore, transactions are visible to all nodes of the network, eroding privacy, and are recorded permanently, contributing to increasing storage requirements over time.
To limit resource usage of the network, Bitcoin currently supports an average of 11 transactions per second.

Most cryptocurrencies today still operate in a substantially similar manner.
Private cryptocurrencies like Zcash and Monero address the privacy issue by replacing transactions with proofs of transaction validity.
However, this enhanced privacy comes at the cost of increased communication, storage, and computational requirements.

Client-Side Validation (CSV) is a paradigm that addresses these issues by removing transaction validation from the blockchain consensus rules.
This approach allows sending the coin along with a validity proof directly to its recipient, reducing communication, computation and storage cost.
CSV protocols deployed on Bitcoin today do not fully leverage the paradigm's potential, as they still necessitate the overhead of publishing ordinary Bitcoin transactions.
Moreover, the size of their coin proofs is proportional to the coin's transaction history, and provide limited privacy.
A recent improvement is the Intmax2 CSV protocol, which writes significantly less data to the blockchain compared to a blockchain transaction and has succinct coin proofs.

In this work, we introduce Shielded CSV, which improves upon state-of-the-art CSV protocols by providing the first construction that offers truly private transactions.
It addresses the issues of traditional private cryptocurrency designs by requiring only 64 bytes of data per transaction, called a nullifier, to be written to the blockchain.
Moreover, for each nullifier in the blockchain, Shielded CSV users only need to perform a single Schnorr signature verification, while non-users can simply ignore this data.
The size and verification cost of coin proofs for Shielded CSV receivers is independent of the transaction history.
Thus, one application of Shielded CSV is adding privacy to Bitcoin at a rate of 100 transactions per second, provided there is an adequate bridging mechanism to the blockchain.

We specify Shielded CSV using the Proof Carrying Data (PCD) abstraction.
We then discuss two implementation strategies that we believe to be practical, based on Folding Schemes and Recursive STARKs, respectively.
Finally, we propose future extensions, demonstrating the power of the PCD abstraction and the extensibility of Shielded CSV.
This highlights the significant potential for further improvements to the Shielded CSV framework and protocols built upon it.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 08:49:45 +0000</pubDate>
</item>
<item>
<title>Constant latency and finality for dynamically available DAG</title>
<link>https://eprint.iacr.org/2025/067</link>
<guid>https://eprint.iacr.org/2025/067</guid>
<content:encoded><![CDATA[
<div> 关键词: DAG、区块链性能、CAP定理、结构化传播、分级公共前缀 (GCP)、活性、安全性、网络分区、预期延迟、吞吐量、低通信步骤、容错性、Ebb-and-Flow框架、混合协议、最终性

总结:<br />
本文探讨了两种基于有向无环图（DAG）的协议，分别针对活性与安全性进行优化。首先，文章提出了首个具有常数预期延迟的DAG协议——结构化传播，其预期延迟为$3\Delta$，并能在睡眠模型下实现高吞吐量动态可用性，通过跨多台机器的原型验证优于现有常数延迟的睡眠模型BFT。其次，分级公共前缀（GCP）是一种在网络分区下保证安全性的协议，相较于现有的低延迟部分同步BFT仅需两步通信，且能避免依赖单一领导者提案，增强了对崩溃的容错性，实验也验证了GCP的理论优势。最后，文章将这些发现应用于扩展Ebb-and-Flow框架，通过两个BFT子协议使系统中不同类型客户端可以优先选择活性或安全性，实现了无需重复运行标准共识协议的高效、动态可用和具有最终性的混合DAG协议。 <div>
Directed Acyclic Graph (DAG) based protocols have shown great promise to improve the performance of blockchains. The CAP theorem shows that it is impossible to have a single system that achieves both liveness (known as dynamic availability) and safety under network partition.This paper explores two types of DAG-based protocols prioritizing liveness or safety, named structured dissemination and Graded Common Prefix (GCP), respectively. 
    
    For the former, we introduce the first DAG-based protocol with constant expected latency, providing high throughput dynamic availability under the sleepy model. Its expected latency is $3\Delta$ and its throughput linearly scales with participation. We validate these expected performance improvements over existing constant latency sleepy model BFT by running prototypes of each protocol across multiple machines.
    
    The latter, GCP, is a primitive that provides safety under network partition, while being weaker than standard consensus. As a result, we are able to obtain a construction that runs in only $2$ communication steps, as opposed to the $4$ steps of existing low latency partially synchronous BFT. In addition, GCP can easily avoid relying on single leaders' proposals, becoming more resilient to crashes. We also validate these theoretical benefits of GCP experimentally.
    
    We leverage our findings to extend the Ebb-and-Flow framework, where two BFT sub-protocols allow different types of clients in the same system to prioritize either liveness or safety. Our extension integrates our two types of DAG-based protocols. This provides a hybrid DAG-based protocol with high throughput, dynamical availability, and finality under network partitions, without running a standard consensus protocol twice as required in existing work.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 08:44:58 +0000</pubDate>
</item>
<item>
<title>SoK: Trusted setups for powers-of-tau strings</title>
<link>https://eprint.iacr.org/2025/064</link>
<guid>https://eprint.iacr.org/2025/064</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密协议, 可信设置, 公共参数, 零知识简洁非交互式证明, 多方协议

总结:
这篇文章关注了加密协议中可信设置的重要性和应用，特别是在区块链领域利用零知识简洁非交互式论证（zk-SNARKs）的情况下。文章区分了设置"协议"和"仪式"两个概念，并探讨了不同方法的特点。文中提出了一种可信设置协议的分类体系，并根据设计原则、优缺点对现实世界的仪式进行了评估。文章旨在系统化现有可信设置的知识，强调了多方协议在防止陷阱门泄露以确保安全性方面的作用，以及公开仪式对于建立信任的重要性。 <div>
Many cryptographic protocols rely upon an initial \emph{trusted setup} to generate public parameters.  While the concept is decades old, trusted setups have gained prominence with the advent of blockchain applications utilizing zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARKs), many of which rely on a ``powers-of-tau'' setup. Because such setups feature a dangerous trapdoor which undermines security if leaked, multiparty protocols are used to prevent the trapdoor from being known by any one party.  Practical setups utilize an elaborate public ceremony to build confidence that the setup was not subverted.  In this paper, we aim to systematize existing knowledge on trusted setups, drawing the distinction between setup \emph{protocols} and \emph{ceremonies}, and shed light on the different features of various approaches. We establish a taxonomy of protocols and evaluate real-world ceremonies based on their design principles, strengths, and weaknesses.
]]></content:encoded>
<pubDate>Thu, 16 Jan 2025 00:21:01 +0000</pubDate>
</item>
<item>
<title>PunSearch: Enabling Puncturable Encrypted Search over Lattice for Cloud Storage Systems</title>
<link>https://eprint.iacr.org/2025/063</link>
<guid>https://eprint.iacr.org/2025/063</guid>
<content:encoded><![CDATA[
<div> 关键词：可搜索加密（SE）、细粒度搜索权限撤销、量子安全、穿孔加密（PE）、PunSearch

总结:
本文提出了一种名为PunSearch的新型可搜索加密方案——首个基于格的穿孔加密搜索方案，用于云存储系统的外包数据隐私保护。该方案实现了细粒度的搜索权限撤销并具备量子安全性。与现有的PE方案不同，PunSearch通过评估算法和格前像采样技术构建了新颖的陷阱门生成机制，并设计了搜索权限验证方法以撤销对特定关键词的搜索能力。此外，文章还提出了一个新的IND-Pun-CKA安全模型来分析PunSearch的安全性。全面的性能评估显示，在最优情况下，PunSearch的Encrypt、Trapdoor、Search和Puncture算法的计算开销分别仅为其他先前方案的0.06、0.005、0.05和0.31倍，证明了PunSearch对于云存储系统既有效又安全。 <div>
Searchable encryption (SE) has been widely studied for cloud storage systems, allowing data encrypted search and retrieval. However, existing SE schemes can not support the fine-grained searchability revocation, making it impractical for real applications. Puncturable encryption (PE) [Oakland'15] can revoke the decryption ability of a data receiver for a specific message, which can potentially alleviate this issue. Moreover, the threat of quantum computing remains an important and realistic concern, potentially leading to data privacy leakage for cloud storage systems. Consequently, designing a post-quantum puncturable encrypted search scheme is still far-reaching. In this paper, we propose PunSearch, the first puncturable encrypted search scheme over lattice for outsourced data privacy-preserving in cloud storage systems. PunSearch provides a fine-grained searchability revocation while enjoying quantum safety. Different from existing PE schemes, we construct a novel trapdoor generation mechanism through evaluation algorithms and lattice pre-image sampling technique. We then design a search permission verification method to revoke the searchability for specific keywords. Furthermore, we formalize a new IND-Pun-CKA security model, and utilize it to analyze the security of PunSearch. Comprehensive performance evaluation indicates that the computational overheads of Encrypt, Trapdoor, Search, and Puncture algorithms in PunSearch are just 0.06, 0.005, 0.05, and 0.31 times of other prior arts, respectively under the best cases. These results demonstrate that PunSearch is effective and secure for cloud storage systems.
]]></content:encoded>
<pubDate>Wed, 15 Jan 2025 17:05:42 +0000</pubDate>
</item>
<item>
<title>Fair Signature Exchange</title>
<link>https://eprint.iacr.org/2025/059</link>
<guid>https://eprint.iacr.org/2025/059</guid>
<content:encoded><![CDATA[
<div> 关键词：公平签名交换（FSE）、Schnorr签名方案、区块链、批量适配器签名、盲签交换

总结:
本文提出了公平签名交换（FSE）的概念，该机制使客户端能够在公平条件下获取多个消息的签名——只有当签署者收到约定的付款时，客户端才能获得所有签名。文章对FSE进行了形式化安全定义，并基于Schnorr签名方案给出了一种实际构建方法，避免了使用如SNARKs这样的计算密集型加密原语。此方案对Schnorr签名的签署者和验证者的开销极小，仅保留了与标准Schnorr签名相同的验证过程。通过利用区块链作为可信第三方来确保公平性，并在链上只交换常量级别的信息，无论签名交换的数量多少。文中还展示了如何使用FSE构建批量适配器签名方案，并实现了基于Schnorr的FSE构造，从而为离散对数问题提供了一个高效的批量Schnorr适配器签名方案实现。实验表明，该方案相对于标准Schnorr签名几乎无额外开销，例如，在Vesta曲线上交换$2^{10}$个签名，签署方耗时约80毫秒，验证方耗时约300毫秒，相较于原始Schnorr协议，签署方几乎无额外开销，而验证方有约2倍的开销。此外，文章还提出了一种扩展方案，即盲签名交换，使得签署者不会得知被签名的消息内容，这是通过对盲化的Schnorr签名的一种自然适应实现的。 <div>
We introduce the concept of Fair Signature Exchange (FSE). FSE enables a client to obtain signatures on multiple messages in a fair manner: the client receives all signatures if and only if the signer receives an agreed-upon payment. We formalize security definitions for FSE and present a practical construction based on the Schnorr signature scheme, avoiding computationally expensive cryptographic primitives such as SNARKs. Our scheme imposes minimal overhead on the Schnorr signer and verifier, leaving the signature verification process unchanged from standard Schnorr signatures. Fairness is enforced using a blockchain as a trusted third party, while exchanging only a constant amount of information on-chain regardless of the number of signatures exchanged. We demonstrate how to construct a batch adaptor signature scheme using FSE, and our FSE construction based on Schnorr results in an efficient implementation of a batch Schnorr adaptor signature scheme for the discrete logarithm problem. We implemented our scheme to show that it has negligible overhead compared to standard Schnorr signatures. For instance, exchanging $2^{10}$ signatures on the Vesta curve takes approximately $80$ms for the signer and $300$ms for the verifier, with almost no overhead for the signer and $2$x overhead for the verifier compared to the original Schnorr protocol. Additionally, we propose an extension to blind signature exchange, where the signer does not learn the messages being signed. This is achieved through a natural adaptation of blinded Schnorr signatures.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 14:19:54 +0000</pubDate>
</item>
<item>
<title>$\mathsf{Cougar}$: Cubic Root Verifier Inner Product Argument under Discrete Logarithm Assumption</title>
<link>https://eprint.iacr.org/2024/616</link>
<guid>https://eprint.iacr.org/2024/616</guid>
<content:encoded><![CDATA[
<div> 关键词：内心积论证（IPA），$\mathsf{Cougar}$，零知识证明，立方根验证器，离散对数假设

总结：

本文提出了一种新的高效内心积论证（IPA）——$\mathsf{Cougar}$，它旨在克服基于离散对数假设下平方根复杂度的限制。$\mathsf{Cougar}$的特点包括立方根验证器和在通信复杂性上的对数级别性能。为了实现这一目标，我们结合了Kim等人在Asiacrypt2022上提出的两个基于离散对数假设的平方根验证器IPA，即使用配对的$\mathsf{Protocol3}$（后来被称为$\mathsf{Leopard}$）和不使用配对的$\mathsf{Protocol4}$。通过重新构建$\mathsf{Protocol4}$并使其与同态承诺方案的证明系统兼容，再利用$\mathsf{Protocol3}$作为其证明系统。此外，为了解决$\mathsf{Protocol4}$中出现的椭圆曲线点之间的关系证明问题，我们引入了一个基于$\mathsf{Plonkish}$的新证明系统，该系统配备了混合椭圆曲线加法的定制门电路。我们证明了$\mathsf{Cougar}$确实满足所声称的所有特性，并在离散对数假设下提供了完整性的证明。此外，我们使用Rust实现了$\mathsf{Cougar}$，结果显示当见证长度$N=2^{20}$时，其验证时间仅为0.346秒，相比其他基于离散对数假设和透明设置的IPA（如BulletProofs和$\mathsf{Leopard}$）有显著速度提升，具体来说，比BulletProofs快约50倍。 <div>
An inner product argument (IPA) is a cryptographic primitive used to construct a zero-knowledge proof system, which is a notable privacy-enhancing technology. We propose a novel efficient IPA called $\mathsf{Cougar}$. $\mathsf{Cougar}$ features cubic root verifier and logarithmic communication under the discrete logarithm (DL) assumption. At Asiacrypt2022, Kim et al. proposed two square root verifier IPAs under the DL assumption. Our main objective is to overcome the limitation of square root complexity in the DL setting. To achieve this, we combine two distinct square root IPAs from Kim et al.: one with pairing ($\mathsf{Protocol3}$; one was later named $\mathsf{Leopard}$) and one without pairing ($\mathsf{Protocol4}$). To construct $\mathsf{Cougar}$, we first revisit $\mathsf{Protocol4}$ and reconstruct it to make it compatible with the proof system for the homomorphic commitment scheme. Next, we utilize $\mathsf{Protocol3}$ as the proof system for the reconstructed $\mathsf{Protocol4}$. Finally, to facilitate proving the relation between elliptic curve points appearing in $\mathsf{Protocol4}$, we introduce a novel $\mathsf{Plonkish}$-based proof system equipped with custom gates for mixed elliptic curve addition. We show that $\mathsf{Cougar}$ indeed satisfies all the claimed features, along with providing a soundness proof under the DL assumption. In addition, we implemented $\mathsf{Cougar}$ in Rust, demonstrating that the verification time of $\mathsf{Cougar}$ increases much slowly as the length of the witness $N$ grows, compared to other IPAs under the DL assumption and transparatent setup: BulletProofs and $\mathsf{Leopard}$. Concretely, $\mathsf{Cougar}$ takes 0.346s for verification in our setting when $N = 2^{20}$, which is a $50\times$ speed-up from BulletProofs.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 05:48:25 +0000</pubDate>
</item>
<item>
<title>Foundations of Data Availability Sampling</title>
<link>https://eprint.iacr.org/2023/1079</link>
<guid>https://eprint.iacr.org/2023/1079</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据可用性采样(DAS), 以太坊, 密码学研究, 消息认证码, 抵抗删除编码<br /><br />总结:<br />
本文针对数据可用性采样（DAS）这一用于提升区块链可扩展性的技术展开了密码学研究。DAS允许网络参与者确保数据完全可用，而无需任何一方完全下载。鉴于DAS在实践中受到广泛关注，但目前尚无其正式定义、安全概念和安全证明，文章首先对DAS进行了精确的密码学原始定义。接着，文章通过定义一种新型的消息认证码，该认证码自然地推广了向量承诺和多项式承诺，展示了DAS与擦除编码的关系。文中分析并证明了现有构造的安全性，并提出了基于更弱假设、计算效率更高且不依赖可信设置的新构造，尽管通信复杂度略有增加。最后，文章评估了不同构造之间的权衡。 <div>
Towards building more scalable blockchains, an approach known as data availability sampling (DAS) has emerged over the past few years. 
Even large blockchains like Ethereum are planning to eventually deploy DAS to improve their scalability.
In a nutshell, DAS allows the participants of a network to ensure the full availability of some data without any one participant downloading it entirely.
Despite the significant practical interest that DAS has received, there are currently no formal definitions for this primitive, no security notions, and no security proofs for any candidate constructions.
For a cryptographic primitive that may end up being widely deployed in large real-world systems, this is a rather unsatisfactory state of affairs.

In this work, we initiate a cryptographic study of data availability sampling.
To this end, we define data availability sampling precisely as a clean cryptographic primitive.
Then, we show how data availability sampling relates to erasure codes.
We do so by defining a new type of commitment schemes which naturally generalizes vector commitments and polynomial commitments.
Using our framework, we analyze existing constructions and prove them secure.
In addition, we give new constructions which are based on weaker assumptions, computationally more efficient, and do not rely on a trusted setup, at the cost of slightly larger communication complexity.
Finally, we evaluate the trade-offs of the different constructions.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 10:50:30 +0000</pubDate>
</item>
<item>
<title>REED: Chiplet-Based  Accelerator for Fully Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2023/1190</link>
<guid>https://eprint.iacr.org/2023/1190</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密（FHE）、ASIC加速器、多芯片模块化、REED、性能提升

总结:<br />
本文提出了一种名为REED的创新性多芯片模块化全同态加密（FHE）加速器，旨在解决现有单片式（monolithic）ASIC FHE加速器所面临的挑战，如不灵活性、低良率和高昂制造成本。REED采用了可扩展的芯片设计方法、有效的负载分布框架、定制化的跨芯片通信策略以及优化的管道数论变换和自同构设计以提升性能。实验结果显示，基于7纳米技术的REED 2.5D微处理器面积为96.7mm²，平均功率消耗为49.4W，相比于24核双倍英特尔X5690 CPU，其运行速度提高了约2991倍，性能提升了1.9倍，并且相较于最先进的ASIC FHE加速器，开发成本降低了50%。此外，文中还首次展示了对加密深度神经网络（DNN）训练的基准测试。总体而言，REED架构设计为加速FHE提供了极具实效性的解决方案，显著推进了FHE在现实世界应用中的实用性和部署可行性。 <div>
Fully Homomorphic Encryption (FHE) enables privacy-preserving computation and has many applications. However, its practical implementation faces massive computation and memory overheads. To address this bottleneck, several Application-Specific Integrated Circuit (ASIC) FHE accelerators have been proposed. All these prior works put every component needed for FHE onto one chip (monolithic), hence offering high performance. However, they encounter common challenges associated with large-scale chip design, such as inflexibility, low yield, and high  manufacturing costs. In this paper, we present the first-of-its-kind multi-chiplet-based FHE accelerator ‘REED’ for overcoming the limitations of prior monolithic designs. To utilize the advantages of multi-chiplet structures while matching the performance of larger monolithic systems, we propose and implement several novel strategies in the context of FHE. These include a scalable chiplet design approach, an effective framework for workload distribution, a custom inter-chiplet communication strategy, and advanced pipelined Number Theoretic Transform and automorphism design to enhance performance.

Our instruction-set and power simulations experiments with a prelayout netlist indicate that REED 2.5D microprocessor consumes 96.7mm2 chip area, 49.4 W average power in 7nm technology. It could achieve a remarkable speedup of up to 2,991× compared to a CPU (24-core 2×Intel X5690) and offer 1.9× better performance, along with a 50% reduction in development costs when compared to state-of-the-art ASIC FHE accelerators. Furthermore, our work presents the first instance of benchmarking an encrypted deep neural network (DNN) training. Overall, the REED architecture design offers a highly effective solution for accelerating FHE, thereby significantly  advancing the practicality and deployability of FHE in real-world applications.
]]></content:encoded>
<pubDate>Fri, 04 Aug 2023 05:21:11 +0000</pubDate>
</item>
<item>
<title>BlindPerm: Efficient MEV Mitigation with an Encrypted Mempool and Permutation</title>
<link>https://eprint.iacr.org/2023/1061</link>
<guid>https://eprint.iacr.org/2023/1061</guid>
<content:encoded><![CDATA[
<div> 关键词: 最大可提取价值(MEV)、随机化置换、交易排序、权益证明(PoS)委员会共识、盲化置换(BlindPerm)

总结:
针对最大可提取价值(MEV)带来的负面影响，本文提出了利用随机化置换对已提交区块内的交易顺序进行混淆的技术方案。现有基于加密mempool的方法对于防止区块生产者的攻击并不充分，而可以通过结合置换技术实现多层保护的扩展。文章重点关注PoS委员会共识机制，并介绍了名为BlindPerm的框架，该框架通过在加密mempool基础上添加置换功能并提出一系列优化措施。其中，我们设计了一个协议，使得这一增强功能几乎无需额外开销，可通过借用现有的加密mempool实现。此外，还探讨了如何将此防御技术扩展到工作量证明(PoW)最长链共识中。最后，通过对历史以太坊数据运行模拟实验，展示了我们的解决方案在防范套利和夹心攻击两种主要类型的MEV提取方面的有效性。 <div>
To mitigate the negative effects of the maximal extractable value (MEV), we propose techniques that utilize randomized permutation to shuffle the order of transactions in a committed block before execution. We argue that existing approaches based on encrypted mempools cannot provide sufficient mitigation, particularly against block producer, and can be extended by permutation-based techniques to provide multi-layer protection. With a focus on PoS committee-based consensus we then introduce BlindPerm, a framework enhancing an encrypted mempool with permutation and present various optimizations. Notably, we propose a protocol where this enhancement comes at essentially no overheads by piggybacking on the encrypted mempool. Further, we demonstrate how to extend our mitigation technique to support PoW longest-chain consensus. Finally, we illustrate the effectiveness of our solutions on arbitrage and sandwich attacks as the two main types of MEV extraction through running simulations using historical Ethereum data.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 05:47:52 +0000</pubDate>
</item>
<item>
<title>On the Privacy of Sublinear-Communication Jaccard Index Estimation via Min-hash Sketching</title>
<link>https://eprint.iacr.org/2023/1523</link>
<guid>https://eprint.iacr.org/2023/1523</guid>
<content:encoded><![CDATA[
<div> 关键词：min-hash sketch、differential privacy (DP)、distributional differential privacy (DDP)、random oracle模型、两方计算协议

总结:<br />
本文研究了min-hash草图在保护输入数据隐私方面的效果。首先，在集中式设置中，当hash函数由min-hash功能选择且对参与者未知的情况下，证明min-hash输出满足标准的差分隐私（DP）定义，无需额外噪声。这进而导出了基于全同态加密（FHE）的低通信量、半诚实型两方计算协议。为了提高效率，文章考虑在随机预言机模型下实现，参与者共同采样公开前缀以进行随机预言机的域分离，并在其输入集上局部评估生成的hash函数。然而，在这种公共hash函数场景下，min-hash输出不再满足DP。因此，文章转向探讨Bassily等人在FOCS 2013提出的分布式差分隐私（DDP）。若诚实方的集合具有足够高的最小熵，则min-hash功能的输出可以实现DDP，同样无需添加噪声。这导致了一个在随机预言机模型下的更高效半诚实两方计算协议，双方首先本地哈希其输入集，然后执行两方计算进行比较。通过证明这些协议分别满足DP和DDP，本文正式确认并界定了关于min-hash协议能够保护其输入隐私的民间观点。 <div>
The min-hash sketch is a well-known technique for low-communication approximation of the Jaccard index between two input sets.  Moreover, there is a folklore belief that min-hash sketch based protocols protect the privacy of the inputs.  In this paper, we investigate this folklore to quantify the privacy of the min-hash sketch.

We begin our investigation by considering the privacy of min-hash in a centralized setting where the hash functions are chosen by the min-hash functionality and are unknown to the participants.  We show that in this case the min-hash output satisfies the standard definition of differential privacy (DP) without any additional noise.  This immediately yields a privacy-preserving sublinear-communication semi-honest 2-PC protocol based on FHE where the hash function is evaluated homomorphically.

To improve the efficiency of this protocol, we next consider an implementation in the random oracle model. Here, the protocol participants jointly sample public prefixes for domain separation of the random oracle, and locally evaluate the resulting hash functions on their input sets.  Unfortunately, we show that in this public hash function setting, the min-hash output is no longer DP.  We therefore consider the notion of distributional differential privacy (DDP) introduced by Bassily et al.(FOCS 2013). We show that if the honest party's set has sufficiently high min-entropy then the output of the min-hash functionality achieves DDP, again without any added noise. This yields a more efficient semi-honest two-party protocol in the random oracle model, where parties first locally hash their input sets and then perform a 2PC for comparison.
    
By proving that our protocols satisfy DP and DDP respectively, our results formally confirm and qualify the folklore belief that min-hash based protocols protect the privacy of their inputs.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 10:02:12 +0000</pubDate>
</item>
<item>
<title>Trustless Bridges via Random Sampling Light Clients</title>
<link>https://eprint.iacr.org/2025/057</link>
<guid>https://eprint.iacr.org/2025/057</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、互操作性、去中心化、随机采样、Byzantine Fault Tolerance (BFT)

总结:
本文提出了一种名为Bridge Protocol的去中心化、高效的区块链互操作性解决方案，该方案依赖于相连的两个链的拜占庭容错（BFT）机制，不需要额外的信任假设。其中，消息交换中介者（即中继器）为无权限和去中心化的，消除了单点故障风险。文章引入了随机采样这一创新技术，使得基于PoS的区块链的轻客户端能更高效地追踪历史记录，减少了所需的签名验证次数。随机数通过以太坊的RANDAO等手段在链上生成。从加密经济学角度分析了桥接协议的安全性，并提供了确定安全性参数的框架，包括处理并发问题和原始设计中的随机性偏差。虽然此协议可应用于多种PoS链，但文中通过实例展示了在Polkadot与Ethereum之间建立桥梁（目前已部署）的可行性，并讨论了一些实际安全挑战。此外，还评估了在以太坊智能合约中实现的基于链上轻客户端验证器的效率（ Gas成本），相比于SNARK基方法，即使在大的验证者集合规模（高达$10^6$）下，其签名验证Gas成本也要低一个数量级。 <div>
The increasing number of blockchain projects introduced annually has led to a pressing need for secure and efficient interoperability solutions. Currently, the lack of such solutions forces end-users to rely on centralized intermediaries, contradicting the core principle of decentralization and trust minimization in blockchain technology. In this paper, we propose a decentralized and efficient interoperability solution (aka Bridge Protocol) that operates without additional trust assumptions, relying solely on the Byzantine Fault Tolerance (BFT) of the two chains being connected. In particular, relayers (actors that exchange messages between networks) are permissionless and decentralized, hence eliminating any single point of failure. We introduce Random Sampling, a novel technique for on-chain light clients to efficiently follow the history of PoS blockchains by reducing the signature verifications required. Here, the randomness is drawn on-chain, for example, using Ethereum's RANDAO. We analyze the security of the bridge from a crypto- economic perspective and provide a framework to derive the security parameters. This includes handling subtle concurrency issues and randomness bias in strawman designs. While the protocol is applicable to various PoS chains, we demonstrate its feasibility by instantiating a bridge between Polkadot and Ethereum (currently deployed), and discuss some practical security challenges. We also evaluate the efficiency (gas costs) of an on-chain light-client verifier implemented as a smart contract on ethereum against SNARK-based approaches. Even for large validator set sizes (up to $10^6$), the signature verification gas costs of our light-client verifier are a magnitude lower.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 11:06:33 +0000</pubDate>
</item>
<item>
<title>Hash-Based Multi-Signatures for Post-Quantum Ethereum</title>
<link>https://eprint.iacr.org/2025/055</link>
<guid>https://eprint.iacr.org/2025/055</guid>
<content:encoded><![CDATA[
<div> 关键词：量子计算机、以太坊、非交互式多签名、BLS签名、哈希基础签名方案

总结:<br />
随着量子计算机带来的威胁，以太坊等系统需要转向抵抗量子攻击的加密原语。文章关注的是非交互式多签名方案，该方案在以太坊权益证明共识中使用了BLS签名。为了提供后量子时代的替代方案，文章引入了一种基于哈希的签名方案家族，作为对BLS签名的补充。研究内容包括利用（哈希基础）简洁论证方法聚合签名，并专注于实现底层签名方案，其中提出了XMSS签名方案的变体。作者建立了一个新颖且统一的框架来分析这些方案，旨在最小化安全性损失并优化参数选择。本文关键特点在于避免在安全性证明中使用随机预言机，而是为底层哈希函数定义明确的标准模型要求。这解决了将哈希函数同时视为随机预言机和聚合明确电路的悖论，并为密码分析人员提供了评估哈希函数安全性时清晰的目标。此外，文章还提供了关于哈希函数实用实例及具体参数设置的建议，并支持已知和新提出的关于标准模型属性的启发式边界。 <div>
With the threat posed by quantum computers on the horizon, systems like Ethereum must transition to cryptographic primitives resistant to quantum attacks. One of the most critical of these primitives is the non-interactive multi-signature scheme used in Ethereum's proof-of-stake consensus, currently implemented with BLS signatures. This primitive enables validators to independently sign blocks, with their signatures then publicly aggregated into a compact aggregate signature.

In this work, we introduce a family of hash-based signature schemes as post-quantum alternatives to BLS. We consider the folklore method of aggregating signatures via (hash-based) succinct arguments, and our work is focused on instantiating the underlying signature scheme. The proposed schemes are variants of the XMSS signature scheme, analyzed within a novel and unified framework. While being generic, this framework is designed to minimize security loss, facilitating efficient parameter selection. A key feature of our work is the avoidance of random oracles in the security proof. Instead, we define explicit standard model requirements for the underlying hash functions. This eliminates the paradox of simultaneously treating hash functions as random oracles and as explicit circuits for aggregation. Furthermore, this provides cryptanalysts with clearly defined targets for evaluating the security of hash functions. Finally, we provide recommendations for practical instantiations of hash functions and concrete parameter settings, supported by known and novel heuristic bounds on the standard model properties.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 09:35:50 +0000</pubDate>
</item>
<item>
<title>Doubly Efficient Fuzzy Private Set Intersection  for High-dimensional Data with Cosine Similarity</title>
<link>https://eprint.iacr.org/2025/054</link>
<guid>https://eprint.iacr.org/2025/054</guid>
<content:encoded><![CDATA[
<div> 关键词: Fuzzy PSI、高维数据、通信成本、计算复杂性、余弦相似性

总结:
本文提出了一种新的模糊私人集合交集(Fuzzy PSI)协议——FPHE，该协议针对余弦相似性的隐私保护匹配问题进行了优化。FPHE克服了现有方法在处理高维数据时面临的通信和计算成本指数级增加的问题，实现了线性的时间和通信复杂度。此外，FPHE不再依赖于特定的数据分布假设，并引入了一种创新的证明技术，平衡了近似比较函数中的误差与噪声填充，确保了协议在半诚实模型下的安全性。FPHE还可以扩展支持如标签或电路模糊PSI等不同功能。实验结果显示，FPHE能够在几分钟内对512维数据执行模糊PSI操作，这是此前同类方案难以实现的。 <div>
Fuzzy private set intersection (Fuzzy PSI) is a cryptographic protocol for privacy-preserving similarity matching, which is one of the essential operations in various real-world applications such as facial authentication, information retrieval, or recommendation systems. Despite recent advancements in fuzzy PSI protocols, still a huge barrier remains in deploying them for these applications. The main obstacle is the high dimensionality, e.g., from 128 to 512, of data; lots of existing methods, Garimella et al. (CRYPTO’23, CRYPTO’24) or van Baarsen et al. (EUROCRYPT’24), suffer from exponential overhead on communication and/or computation cost. In addition, the dominant similarity metric in these applications is cosine similarity, which disables several optimization tricks based on assumptions for the distribution of data, e.g., techniques by Gao et al. (ASIACRYPT’24). In this paper, we propose a novel fuzzy PSI protocol for cosine similarity, called FPHE, that overcomes these limitations at the same time. FPHE features linear complexity on both computation and communication with respect to the dimension of set elements, only requiring much weaker assumption than prior works. The basic strategy of ours is to homomorphically compute cosine similarity and run an approximated comparison function, with a clever packing method for efficiency. In addition, we introduce a novel proof technique to harmonize the approximation error from the sign function with the noise flooding, proving the security of FPHE under the semi-honest model. Moreover, we show that our construction can be extended to support various functionalities, such as labeled or circuit fuzzy PSI. Through experiments, we show that FPHE can perform fuzzy PSI over 512-dimensional data in a few minutes, which was computationally infeasible for all previous proposals under the same assumption as ours.
]]></content:encoded>
<pubDate>Tue, 14 Jan 2025 05:49:19 +0000</pubDate>
</item>
<item>
<title>More Efficient Lattice-Based Electronic Voting from NTRU</title>
<link>https://eprint.iacr.org/2023/933</link>
<guid>https://eprint.iacr.org/2023/933</guid>
<content:encoded><![CDATA[
<div> 关键词：量子安全、lattice假设、电子投票、RLWE、NTRU

总结：
本文提出了一种基于量子安全的lattice问题（RLWE和NTRU）的电子投票方案，该方案在实现上更为高效，与现有最佳的lattice基投票方案相比，实现了5.3倍的密文大小减小、2.5倍的总通信成本降低以及2倍的总计算时间减少。本设计特别关注了加密隐私性和过程可验证性，以确保在面对量子计算机威胁时的安全性。此外，通过使用非三元NTRU秘密来优化参数，文中还扩展了Ducas和van Woerden关于NTRU的工作，确定了对于任意秘密的NTRU具体疲劳点公式，这对于理解参数安全性及改进del Pino和Katsumata提出的部分盲签名方案具有重要意义。 <div>
In recent years, there has been much focus on developing core cryptographic primitives based on lattice assumptions, driven by the NIST call for post-quantum key encapsulation and digital signature algorithms. However, more work must be conducted on efficient privacy-preserving protocols based on quantum-safe assumptions.

Electronic voting is one such privacy-preserving protocol whose adoption is increasing across the democratic world. E-voting offers both a fast and convenient alternative to postal voting whilst further ensuring cryptographic privacy of votes and offering full verifiability of the process. Owing to the sensitivity of voting and its infrastructure challenges, it is crucial to ensure security against quantum computers is baked into e-voting solutions.

We present an e-voting scheme from quantum-safe assumptions based on the hardness of the RLWE and NTRU lattice problems, providing concrete parameters and an efficient implementation. Our design achieves a factor $5.3 \times$ reduction in ciphertext size, $2.5 \times$ reduction in total communication cost, and $2 \times$ reduction in total computation time compared to the state-of-the-art lattice-based voting scheme by Aranha et al. (ACM CCS 2023). We argue that the efficiency of this scheme makes it suitable for real-world elections.

Our scheme makes use of non-ternary NTRU secrets to achieve optimal parameters. In order to compute the security of our design, we extend the ternary-NTRU work of Ducas and van Woerden (ASIACRYPT 2021) by determining the concrete fatigue point (for general secrets) of NTRU to be $q = 0.0058 \cdot \sigma^2 \cdot d^{2.484}$ (above which parameters become overstretched) for modulus $q$, ring dimension $d$, and secrets drawn from a Gaussian of parameter $\sigma$. We consider this relation to be of independent interest and demonstrate its significance by improving the efficiency of the (partially) blind signature scheme by del Pino and Katsumata (CRYPTO 2022).
]]></content:encoded>
<pubDate>Wed, 14 Jun 2023 21:23:33 +0000</pubDate>
</item>
<item>
<title>Keyed-Verification Anonymous Credentials with Highly Efficient Partial Disclosure</title>
<link>https://eprint.iacr.org/2025/041</link>
<guid>https://eprint.iacr.org/2025/041</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名凭证（AC）、部分披露、键控验证AC（KVAC）、零知识证明、常量大小

总结:
本文提出两种高效的关键控验证匿名凭证（KVAC）系统构造方案，这两个方案消除了凭证展示阶段对计算昂贵的零知识证明的需求，并实现了常量大小的展示。第一个方案基于Fuchsbauer等人在公开可验证设置中实现常量大小凭证展示的工作，引入了结构保持的消息认证码在等价类（SP-MAC-EQ）和指定验签者集合承诺（DVSC），从而得到一种具有常量大小凭证（2组元素）和展示（4组元素）的KVAC系统。第二个方案采用同态MAC和简化DVSC，虽牺牲了常量大小的凭证（$n+2$组元素，其中$n$为属性数量），但保持了常量大小的展示（2组元素），并适应于无配对环境。文章对两个构造的安全性进行了正式证明，并提供了开源实现结果以证明其实用性。此外，还对所提出的SP-MAC-EQ方案与原始的SPS-EQ方案进行了效率基准测试，显示出显著的性能提升。 <div>
An anonymous credential (AC) system with partial disclosure allows users to prove possession of a credential issued by an issuer while selectively disclosing a subset of their attributes to a verifier in a privacy-preserving manner. In keyed-verification AC (KVAC) systems, the issuer and verifier share a secret key. Existing KVAC schemes rely on computationally expensive zero-knowledge proofs during credential presentation, with the presentation size growing linearly with the number of attributes. In this work, we propose two highly efficient KVAC constructions that eliminate the need for zero-knowledge proofs during the credential presentation and achieve constant-size presentations.
    Our first construction adapts the approach of Fuchsbauer et al. (JoC'19), which achieved constant-size credential presentation in a publicly verifiable setting using their proposed structure-preserving signatures on equivalence classes (SPS-EQ) and set commitment schemes, to the KVAC setting. We introduce structure-preserving message authentication codes on equivalence classes (SP-MAC-EQ) and designated-verifier set commitments (DVSC), resulting in a KVAC system with constant-size credentials (2 group elements) and presentations (4 group elements). To avoid the bilinear groups and pairing operations required by SP-MAC-EQ, our second construction uses a homomorphic MAC with a simplified DVSC. While this sacrifices constant-size credentials ($n+2$ group elements, where $n$ is the number of attributes), it retains constant-size presentations (2 group elements) in a pairingless setting. 
    We formally prove the security of both constructions and provide open-source implementation results demonstrating their practicality. We extensively benchmarked our KVAC protocols and, additionally, bechmarked the efficiency of our SP-MAC-EQ scheme against the original SPS-EQ scheme, showcasing significant performance improvements.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 18:08:39 +0000</pubDate>
</item>
<item>
<title>VDORAM: Towards a Random Access Machine with Both Public Verifiability and Distributed Obliviousness</title>
<link>https://eprint.iacr.org/2025/039</link>
<guid>https://eprint.iacr.org/2025/039</guid>
<content:encoded><![CDATA[
<div> 关键词：可验证随机访问机器(vRAM)、分布式无意识RAM (VDORAM)、多证明者零知识证明(ZKP)、公开可验证多方计算(MPC)协议、ComptCircuit

总结:
本文介绍了为解决复杂计算中具有可证明安全性的问题而提出的可验证随机访问机器（vRAM）。然而，现有的vRAM并未实现分布式无意识性，这在涉及多个证明者防止信息泄露给其他证明者和验证者的场景中至关重要。文章提出了两大挑战：缺乏先进的公开可验证多方计算（MPC）协议和多证明者ZKP的前端实现。针对这些问题，文中引入了名为CompatCircuit的创新方案，它是首个具备协同zkSNARKs功能的多证明者ZKP前端实现，能支持构建具有丰富功能的公开可验证MPC协议。基于CompatCircuit，文章构建了首个公开可验证的分布式无意识RAM（VDORAM），通过结合分布式无意识架构与可验证RAM，实现了在通信开销和证明生成时间之间的高效RAM设计。作者实现了大约15,000行代码的CompatCircuit和VDORAM，并展示了其实用性和效率，性能评估结果显示系统在提供分布式无意识性的同时仍保持着适度的性能。 <div>
Verifiable random access machines (vRAMs) serve as a foundational model for expressing complex computations with provable security guarantees, serving applications in areas such as secure electronic voting, financial auditing, and privacy-preserving smart contracts. However, no existing vRAM provides distributed obliviousness, a critical need in scenarios where multiple provers seek to prevent disclosure against both other provers and the verifiers.
Implementing a publicly verifiable distributed oblivious RAM (VDORAM) presents several challenges. Firstly, the development of VDORAM is hindered by the limited availability of sophisticated publicly verifiable multi-party computation (MPC) protocols. Secondly, the lack of readily available front-end implementations for multi-prover zero-knowledge proofs (ZKPs) poses a significant obstacle to developing practical applications. Finally, directly adapting existing RAM designs to the VDORAM paradigm may prove either impractical or inefficient due to the inherent complexities of reconciling oblivious computation with the generation of publicly verifiable proofs.

To address these challenges, we introduce CompatCircuit, the first multi-prover ZKP front-end implementation to our knowledge. CompatCircuit integrates collaborative zkSNARKs to implement publicly verifiable MPC protocols with rich functionalities beyond those of an arithmetic circuit, enabling the development of multi-prover ZKP applications. Building upon CompatCircuit, we present VDORAM, the first publicly verifiable distributed oblivious RAM. By combining distributed oblivious architectures with verifiable RAM, VDORAM achieves an efficient RAM design that balances communication overhead and proof generation time. We have implemented CompatCircuit and VDORAM in approximately 15,000 lines of code, demonstrating usability by providing a practical and efficient implementation. Our performance evaluation result reveals that the system still provides moderate performance with distributed obliviousness.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 10:50:58 +0000</pubDate>
</item>
<item>
<title>Cauchyproofs: Batch-Updatable Vector Commitment with Easy Aggregation and Application to Stateless Blockchains</title>
<link>https://eprint.iacr.org/2025/038</link>
<guid>https://eprint.iacr.org/2025/038</guid>
<content:encoded><![CDATA[
<div> 关键词: Stateless区块链、Cauchyproofs、批量可更新向量承诺、KZG方案、历史证明查询算法

总结:

本文介绍了Cauchyproofs，这是一种用于状态less区块链设计的批量可更新向量承诺方案，旨在解决随着用户和交易数量增加而带来的证明更新计算资源需求大的问题。Cauchyproofs利用优化的KZG方案，将更新证明的时间复杂度降低至$O\left(\left(\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|\right) \log^2 (\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|)\right)$，相比之前的$O\left(\left|\vec{\alpha}\right|\cdot|\vec{\beta}|\right)$方法有显著提升，从而减轻了证明服务节点的计算负担并提高了大用户群体中证明维护的效率。实验表明，这种方法在以太坊级别的区块大小下，比原始方法快约五倍。此外，文章还提出了一种基于Cauchy矩阵的KZG证明新型矩阵表示法，能够减少椭圆曲线操作，加速所有证明的计算。最后，文中还提供了一个历史证明查询算法，支持高效的历史证明生成。这些贡献极大地提升了状态less区块链框架中证明服务节点的可扩展性和实用性。 <div>
Stateless blockchain designs have emerged to address the challenge of growing blockchain size by utilizing succinct global states. Previous works have developed vector commitments that support proof updates and aggregation to be used as such states. However, maintaining proofs for multiple users still demands significant computational resources, particularly in updating proofs with every transaction.  This paper introduces Cauchyproofs, a batch-updatable vector commitment enabling proof-serving nodes to efficiently update proofs in quasi-linear time relative to the number of users and transactions, utilizing an optimized KZG scheme to achieve complexity $O\left(\left(\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|\right) \log^2 (\left|\vec{\alpha}\right| + \left|\vec{\beta}\right|)\right)$, compared to previous $O\left(\left|\vec{\alpha}\right|\cdot|\vec{\beta}|\right)$ approaches. This advancement reduces the computational burden on proof-serving nodes, allowing for efficient proof maintenance across large user groups. We demonstrate that our approach is approximately five times faster than the naive approach at the Ethereum-level block size. Additionally, we present a novel matrix representation for KZG proofs utilizing Cauchy matrices, enabling faster all-proof computations with reduced elliptic curve operations. Finally, we propose an algorithm for history proof query, supporting retrospective proof generation with high efficiency. Our contributions substantially enhance the scalability and practicality of proof-serving nodes in stateless blockchain frameworks.
]]></content:encoded>
<pubDate>Fri, 10 Jan 2025 02:15:53 +0000</pubDate>
</item>
<item>
<title>Blink: An Optimal Proof of Proof-of-Work</title>
<link>https://eprint.iacr.org/2024/692</link>
<guid>https://eprint.iacr.org/2024/692</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、Proof-of-Work、区块链、Blink、安全性、资源消耗、零知识证明、可信设置、Bitcoin Backbone模型、评估、下载量

总结:<br />
本文介绍了Blink，这是首个无需可信设置的交互式、安全的$\mathcal{O}(1)$ PoW轻客户端。Blink可以应用于支付验证、启动引导以及跨链桥接等多个场景。相比于传统的线性资源消耗，近年来轻客户端的资源需求已逐步降低至$\mathcal{O}(\text{polylog}( \mathcal{C}))$和$\mathcal{O}(1)$，但后者的实现往往依赖于可信设置。而Blink则在不需可信设置的前提下实现了$\mathcal{O}(1)$的资源效率。文章证明了Blink在比特币背骨模型中的安全性，并对其证明大小进行了评估，结果显示，使用Blink只需下载1.6KB即可获取到比特币当前状态的承诺，相较于SPV（需要67.3MB）和基于零知识的轻客户端（需要197KB）显著降低了资源消耗。 <div>
Designing light clients to securely and efficiently read Proof-of-Work blockchains has been a foundational problem since the inception of blockchains. Nakamoto themselves, in the original Bitcoin paper, presented the first client protocol, i.e., the Simplified Payment Verification, which consumes an amount of bandwidth, computational, and storage resources that grows linearly in the system's lifetime $\mathcal{C}$.

Today, the blockchain ecosystem is more mature and presents a variety of applications and protocols deployed on-chain and, often, cross-chain. In this landscape, light clients have become the cornerstone of decentralized bridges, playing a pivotal role in the security and efficiency of cross-chain operations. 
These new use cases, combined with the growth of blockchains over time, raise the need for more minimalist clients, which further reduce the resource requirements and, when applicable, on-chain costs. 
Over the years, the light client resource consumption has been reduced from $\mathcal{O}( \mathcal{C})$ to $\mathcal{O}(\text{polylog}( \mathcal{C}))$, and then down to $\mathcal{O}(1)$ with zero-knowledge techniques at the cost of often assuming a trusted setup. 

In this paper, we present Blink, the first interactive provably secure $\mathcal{O}(1)$ PoW light client without trusted setup. Blink can be used for a variety of applications ranging from payment verification and bootstrapping, to bridges. 
We prove Blink secure in the Bitcoin Backbone model, and we evaluate its proof size demonstrating that, at the moment of writing, Blink obtains a commitment to the current state of Bitcoin by downloading only 1.6KB, instead of 67.3MB and 197KB for SPV and zk-based clients, respectively.
]]></content:encoded>
<pubDate>Mon, 06 May 2024 08:32:01 +0000</pubDate>
</item>
<item>
<title>Forking the RANDAO: Manipulating Ethereum's Distributed Randomness Beacon</title>
<link>https://eprint.iacr.org/2025/037</link>
<guid>https://eprint.iacr.org/2025/037</guid>
<content:encoded><![CDATA[
<div> 关键词：proof-of-stake、distributed randomness beacons (DRBs)、RANDAO、forking attack、selfish mining

总结:
本文分析了以太坊共识机制中当前使用的分布式随机数生成器（RANDAO）的操纵性。尽管RANDAO具有高效率，但仍存在通过故意省略区块来操纵随机数生成的漏洞，即所谓的自私挖矿攻击。文章提出并评估了一种新的操纵策略——RANDAO分叉攻击，与自私挖矿不同的是，这种策略依赖于选择性地分叉诚实提议者的区块以最大化交易费收入和区块奖励。文章指出，分叉攻击比自私挖矿更具危害性，因为它加剧了验证者之间的不公平，并严重损害了区块链对普通用户的可靠性，导致已发布的区块频繁被分叉出去。同时，研究发现攻击者可以发起分叉而不损失槽位，并且这些损失会在后期得到充分补偿。实证测量表明，在以太坊主网上目前尚未发现这类攻击的统计显著痕迹。 <div>
Proof-of-stake consensus protocols often rely on distributed randomness beacons (DRBs) to generate randomness for leader selection. This work analyses the manipulability of Ethereum's DRB implementation, RANDAO, in its current consensus mechanism. Even with its efficiency, RANDAO remains vulnerable to manipulation through the deliberate omission of blocks from the canonical chain. Previous research has shown that economically rational players can withhold blocks --~known as a block withholding attack or selfish mixing~-- when the manipulated RANDAO outcome yields greater financial rewards.

We introduce and evaluate a new manipulation strategy, the RANDAO forking attack. Unlike block withholding, whereby validators opt to hide a block, this strategy relies on selectively forking out an honest proposer's block to maximize transaction fee revenues and block rewards. 
In this paper, we draw attention to the fact that the forking attack is significantly more harmful than selfish mixing for two reasons. Firstly, it exacerbates the unfairness among validators. More importantly, it significantly undermines the reliability of the blockchain for the average user by frequently causing already published blocks to be forked out. By doing so, the attacker can fork the chain without losing slots, and we demonstrate that these are later fully compensated for. Our empirical measurements, investigating such manipulations on Ethereum mainnet, revealed no statistically significant traces of these attacks to date.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 19:24:20 +0000</pubDate>
</item>
<item>
<title>Scalable Post-Quantum Oblivious Transfers for Resource-Constrained Receivers</title>
<link>https://eprint.iacr.org/2025/036</link>
<guid>https://eprint.iacr.org/2025/036</guid>
<content:encoded><![CDATA[
<div> 关键词: 原子转移、现代化、低功耗设备、Helix OT、Priority OT

总结:
本文提出两种可扩展的原子转移方案以适应现代数字时代对隐私保护计算的需求，尤其是在低功耗设备上的应用。这两种方案分别是：1-out-of-n 的 Helix OT 和 t-out-of-n 的 Priority OT，两者均具有无条件安全性，能抵抗量子攻击。Helix OT 实现了接收端下载复杂度为 O(1)，优化了大规模数据场景下的效率。针对有紧急或重要性区分的数据传输需求，Priority OT 则通过 O(t) 的接收端下载复杂度实现数据优先级传输，确保最重要数据优先接收，从而更有效地利用带宽、存储和处理资源。实验结果显示，Helix OT 在1秒内完成从 n=16,777,216 消息中选择1条的消息传输，而 Priority OT 可在30秒内处理 t=1,048,576 项选择任务，性能优于现有 t-out-of-n OT（当 t≥1 时）。据作者所知，Helix OT 和 Priority OT 均具备与以往方案不同的独特优势，适用于大规模应用场景。 <div>
It is imperative to modernize traditional core cryptographic primitives, such as Oblivious Transfer (OT), to address the demands of the new digital era, where privacy-preserving computations are executed on low-power devices. This modernization is not merely an enhancement but a necessity to ensure security, efficiency, and continued relevance in an ever-evolving technological landscape. 

This work introduces two scalable OT schemes: (1) Helix OT, a $1$-out-of-$n$ OT, and (2) Priority OT, a $t$-out-of-$n$ OT. Both schemes provide unconditional security, ensuring resilience against quantum adversaries. Helix OT achieves a receiver-side download complexity of $O(1)$. In big data scenarios, where certain data may be more urgent or valuable, we propose Priority OT. With a receiver-side download complexity of $O(t)$, this scheme allows data to be received based on specified priorities. By prioritizing data transmission, Priority OT ensures that the most important data is received first, optimizing bandwidth, storage, and processing resources.  Performance evaluations indicate that Helix OT completes the transfer of 1 out of $n=$ 16,777,216 messages in 9 seconds, and Priority OT handles $t=$ 1,048,576 out of $n$ selections in 30 seconds. Both outperform existing $t$-out-of-$n$ OTs (when $t\geq 1$), underscoring their suitability for large-scale applications. To the best of our knowledge, Helix OT and Priority OT introduce unique advancements that distinguish them from previous schemes.
]]></content:encoded>
<pubDate>Thu, 09 Jan 2025 14:44:28 +0000</pubDate>
</item>
<item>
<title>A New Paradigm for Server-Aided MPC</title>
<link>https://eprint.iacr.org/2025/032</link>
<guid>https://eprint.iacr.org/2025/032</guid>
<content:encoded><![CDATA[
<div> 关键词：server-aided MPC、多党计算、安全性保证、信任假设、效率

总结:
该文提出了一个新的服务器辅助多党计算（MPC）模型，挑战了原有假设，即所有客户端必须选择相同的服务器和接受相同的腐败阈值。在这个新模型中，每个客户端可以选择自己的服务器集和自己的腐败阈值，并且只要满足其自身的阈值，就能保证其隐私安全，这一特性被称为“每党私有”服务器辅助MPC，兼顾了安全性和效率两方面保障：(1) 每党隐私，意味着每个参与方根据自身选择的服务器得到独立的隐私保护；(2) 每党复杂度，意味着每个参与方只需与其选定的服务器进行通信。文章的主要贡献是一个新的服务器辅助MPC理论框架，并给出了两个可行性协议，但将追求具体效率的协议留作未来工作。 <div>
The server-aided model for multiparty computation (MPC) was introduced to capture a real-world scenario where clients wish to off-load the heavy computation of MPC protocols to dedicated servers. A rich body of work has studied various trade-offs between security guarantees (e.g., semi-honest vs malicious),  trust assumptions (e.g., the threshold on corrupted servers), and efficiency. 

However, all existing works make the assumption that all clients must agree on employing the same servers, and accept the same corruption threshold. In this paper, we challenge this assumption and introduce a new paradigm for server-aided MPC, where each client can choose their own set of servers and their own threshold of corrupted servers. In this new model, the privacy of each client is guaranteed as long as their own threshold is satisfied, regardless of the other servers/clients. We call this paradigm per-party private server-aided MPC to highlight both a security and efficiency guarantee: (1) per-party privacy, which means that each party gets their own privacy guarantees that depend on their own choice of the servers; (2) per-party complexity, which means that each party only needs to communicate with their chosen servers. Our primary contribution is a new theoretical framework for server-aided MPC. We provide two protocols to show feasibility, but leave it as a future work to investigate protocols that focus on concrete efficiency.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 20:17:40 +0000</pubDate>
</item>
<item>
<title>Delegated Multi-party Private Set Intersection from Secret Sharing</title>
<link>https://eprint.iacr.org/2025/030</link>
<guid>https://eprint.iacr.org/2025/030</guid>
<content:encoded><![CDATA[
<div> 关键词: Delegated PSI (D-PSI)、云服务器、多党设置、安全、计算复杂性

总结:
本文探讨了委托私有集合交集(D-PSI)问题，其中引入云服务器处理大部分计算和通信任务。D-PSI允许用户安全地将私人集合委托给云端，同时保证数据隐私并有效计算交集。该云服务器在严格的安全要求下运行，不获取个体集合或交集结果的任何信息。此外，D-PSI减少了用户间的通信并支持“静默”处理，即除了集合委托和结果检索外，云可以独立执行计算。文章形式化定义了D-PSI问题，并提出一种创新构建方案，不仅适用于两方场景，还可扩展到多方设置。该方案满足对半诚实敌手的安全性要求，并实现了接近理想“完美”D-PSI协议的计算和通信复杂度。通过基准实现和优化版本，作者展示了其方法的实用性，进一步降低了计算开销，为现实世界云计算场景中安全高效的PSI奠定了坚实基础。 <div>
In this work, we address the problem of Delegated PSI (D-PSI), where a cloud server is introduced to handle most computational and communication tasks. D-PSI enables users to securely delegate their private sets to the cloud, ensuring the privacy of their data while allowing efficient computation of the intersection. The cloud operates under strict security requirements, learning nothing about the individual sets or the intersection result. Moreover, D-PSI minimizes user-to-user communication and supports "silent" processing, where the cloud can perform computations independently without user interaction, apart from set delegation and result retrieval.

We formally define the D-PSI problem and propose a novel construction that extends beyond two-party scenarios to support multi-party settings. Our construction adheres to the D-PSI requirements, including security against semi-honest adversaries, and achieves computational and communication complexities close to the ideal "perfect" D-PSI protocol. Additionally, we demonstrate the practicality of our approach through a baseline implementation and an optimized version that further reduces computational overhead. Our results establish a strong foundation for secure and efficient PSI in real-world cloud computing scenarios.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 11:35:17 +0000</pubDate>
</item>
<item>
<title>Highly Efficient Server-Aided Multiparty Subfield VOLE Distribution Protocol</title>
<link>https://eprint.iacr.org/2025/029</link>
<guid>https://eprint.iacr.org/2025/029</guid>
<content:encoded><![CDATA[
<div> 关键词：secure multi-party computation, pseudorandom correlations, subfield vector oblivious linear evaluation (sVOLE), three-party, four-party honest majority settings, trusted server, communication cost, memory storage, arbitrary length, utility rate, precomputability.

<br /><br />总结：
本文介绍了一种新的子域向量无意识线性评估（sVOLE）分布方法，该方法应用于三 party 和四 party 诚实多数设置中，借助可信服务器的帮助。新方法显著降低了随机 sVOLE 实例的通信成本和内存存储需求。同时，它还实现了一个流畅的分布流程，能够生成任意长度的 sVOLE 实例，从而在多维度的隐私保护计算协议中实现了随机 sVOLE 的100%效用率，同时保持了完整的预计算能力。 <div>
In recent development of secure multi-party computation (MPC), pseudorandom correlations of subfield vector oblivious linear evaluation (sVOLE) type become popular due to their amazing applicability in multi-dimensional MPC protocols such as privacy-preserving biometric identification and privacy-preserving machine learning protocols. In this paper, we introduce a novel way of VOLE distribution in three-party and four-party honest majority settings with the aid of a trusted server. This new method significantly decreases the communication cost and the memory storage of random sVOLE instances. On the other hand, it also enables a streamline distribution process that can generate a sVOLE instance of an arbitrary length, which results in 100 percent of utility rate of random sVOLE in multi-dimensional MPC protocols while preserving complete precomputability.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 09:01:56 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proofs for Set Membership: Efficient, Succinct, Modular</title>
<link>https://eprint.iacr.org/2019/1255</link>
<guid>https://eprint.iacr.org/2019/1255</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、集合成员资格、隐私保护、非成员资格证明、Pedersen承诺

总结:
本文关注的是在不泄露元素本身的情况下，利用零知识证明技术证明某个元素属于公开集合且满足特定属性的问题。文章设计了一种新的模块化和高效的方法，构建了基于承诺的集合并验证零知识系统，用于证明某值 $u$ 在公共承诺 $c_u$ 中属于集合 $S$。同时，该方法还支持非成员资格证明，即证明 $u$ 不属于集合 $S$。由于采用的是基于 Pedersen 承诺的方案，这些解决方案与诸如 Bulletproofs 或 Groth16 等流行系统兼容，可作为“$u \in S$ 并且 $P(u)$ 成立”这类复合声明中的即插即用模块。相较于之前的类似工作（如结合 zkSNARKs 和默克尔树的 Zcash 技术），实验表明，该方案提供了更高的灵活性，更短的公共参数以及对于大小为 $2^{64}$ 的集合，证明时间提升了 3.7 倍至 30 倍之多。此外，作者已将这些方案实现为软件库，并进行了性能测试。 <div>
We consider the problem of proving in zero knowledge that an element of a public set satisfies a given property without disclosing the element, i.e., for some $u$, ``$u \in S$ and $P(u)$ holds''. This problem arises in many applications (anonymous cryptocurrencies, credentials or whitelists) where, for privacy or anonymity reasons, it is crucial to hide certain data while ensuring properties of such data.
We design new \textit{modular} and \textit{efficient} constructions for this problem through new \textit{commit-and-prove zero-knowledge systems for set membership}, i.e. schemes proving  $u \in S$ for a value $u$ that is in a public commitment $c_u$. We also extend our results to support {\em non-membership proofs}, i.e. proving $u \notin S$.
Being commit-and-prove, our solutions can act as plug-and-play modules in statements of the form ``$u \in S$ and $P(u)$ holds'' by combining our set (non-)membership systems with any other commit-and-prove scheme for $P(u)$. Also, they work with Pedersen commitments over prime order groups which makes them compatible with popular systems such as Bulletproofs or Groth16.
We implemented our schemes as a software library, and tested experimentally their performance. Compared to previous work that achieves similar properties---the clever techniques combining zkSNARKs and Merkle Trees in Zcash---our solutions offer more flexibility, shorter public parameters and $3.7 \times$--$30\times$ faster proving time for a set of size $2^{64}$.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2019 08:28:02 +0000</pubDate>
</item>
<item>
<title>Blind accumulators for e-voting</title>
<link>https://eprint.iacr.org/2022/373</link>
<guid>https://eprint.iacr.org/2022/373</guid>
<content:encoded><![CDATA[
<div> 关键词: blind accumulator、电子投票系统、加密原语、匿名性、验证性

总结:
本文提出了一种新型加密原语——盲累积器，旨在构建电子投票系统。盲累积器能够以去中心化的方式收集合格选民的私钥，同时不获取这些私钥的信息。完成累积后，选民可以处理得到的累积器并导出与其先前添加的私钥对应的公钥。公钥的生成是确定性的，因此可以作为固定的选民伪名使用。选民利用所积累的私钥对选票进行签名，而对应的公钥则用于验证签名。由于公钥固定不变，易于实现可验证性，保护选民免受重复投票的影响，或者允许重复投票但仅计算最后一次提交的选票。文章提出了盲累积器的语法和安全要求，并将其嵌入到Pseudonymous Key Generation（PKG）协议中，详细描述了在接近实际电子投票场景中的应用。此外，文章还提出了一种类似于Diffie-Hellman协议的盲累积器方案实例，并证明了该实例的安全性。 <div>
We present a novel cryptographic primitive, blind accumulator, aimed at constructing e-voting systems. Blind accumulators collect private keys of eligible voters in a decentralized manner not getting information about the keys. Once the accumulation is complete, a voter processes the resulting accumulator and derives a public key which refers to a private key previously added by this voter. Public keys are derived deterministically and can therefore stand as fixed voter pseudonyms. The voter can prove that the derived key refers to some accumulated private key without revealing neither that key nor the voter itself. The voter uses the accumulated private key to sign a ballot. The corresponding public key is used to verify the signature. Since the public key is fixed, it is easy to achieve verifiability, to protect against multiple submissions of ballots by the same voter or, conversely, to allow multiple submissions but count only the last one. We suggest a syntax of blind accumulators and security requirements for them. We embed blind accumulators in the Pseudonymous Key Generation (PKG) protocol which details the use of accumulators in practical settings close to e-voting. We propose an instantiation of the blind accumulator scheme whose main computations resemble the Diffie-Hellman protocol. We justify the security of the proposed instantiation.
]]></content:encoded>
<pubDate>Tue, 22 Mar 2022 13:27:26 +0000</pubDate>
</item>
<item>
<title>Extending Groth16 for Disjunctive Statements</title>
<link>https://eprint.iacr.org/2025/028</link>
<guid>https://eprint.iacr.org/2025/028</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式零知识证明（NIZK）、$\Sigma$协议、zk-SNARK、组合证明、Groth16<br /><br />总结：
本文关注的是非交互式零知识证明（NIZK）中涉及代数和算术混合成分的析取性陈述问题。现有的zk-SNARK协议通常用于证明算术陈述，并与加密、承诺等代数密码学方案结合实现复杂应用。然而，对于包括代数和算术在内的复合陈述，直接扩展zk-SNARK电路会导致电路规模增大，证明时间和CRS大小变得不可行。文章提出了一种Groth16变体——CompGroth16，该框架允许Groth16证明包含代数和算术组件的析取性陈述。通过CompGroth16可以直接与其他$\Sigma$协议或自身进行逻辑组合，从而获得更广泛的表达能力、更高的证明者效率以及更短的CRS。此外，文中还针对CompGroth16与$\Sigma$协议的组合给出了两个具体的应用场景示例，展示了该构造的实际可行性。 <div>
Two most common ways to design non-interactive zero knowledge (NIZK) proofs are based on Sigma ($\Sigma$)-protocols (an efficient way to prove algebraic statements) and zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARK) protocols (an efficient way to prove arithmetic statements). However, in the applications of cryptocurrencies such as privacy-preserving credentials, privacy-preserving audits, and  blockchain-based voting systems, the zk-SNARKs for general statements are usually implemented with encryption, commitment, or other algebraic cryptographic schemes. Moreover, zk-SNARKs for many different arithmetic statements may also be required to be implemented together. Clearly, a typical solution is to extend the zk-SNARK circuit to include the code for algebraic part. However, complex cryptographic operations in the algebraic algorithms will significantly increase the circuit size, which leads to impractically large proving time and CRS size. Thus, we need a flexible enough proof system for composite statements including both algebraic and arithmetic statements. Unfortunately, while the conjunction of zk-SNARKs is relatively natural and numerous effective solutions are currently available (e.g. by utilizing the commit-and-prove technique), the disjunction of zk-SNARKs is rarely discussed in detail.
        In this paper, we mainly focus on the disjunctive statements of Groth16, and we propose a Groth16 variant---CompGroth16, which provides a framework for Groth16 to prove the disjunctive statements that consist of a mix of algebraic and arithmetic components. Specifically, we could directly combine CompGroth16 with $\Sigma$-protocol or even CompGroth16 with CompGroth16 just like the logical composition of $\Sigma$-protocols. From this, we can gain many good properties, such as broader expression, better prover's efficiency and shorter CRS. In addition, for the combination of CompGroth16 and $\Sigma$-protocol, we also present two representative application scenarios to demonstrate the practicality of our construction.
]]></content:encoded>
<pubDate>Wed, 08 Jan 2025 07:38:47 +0000</pubDate>
</item>
<item>
<title>Quantum-resistant secret handshakes with dynamic joining, leaving, and banishment: GCD revisited</title>
<link>https://eprint.iacr.org/2025/024</link>
<guid>https://eprint.iacr.org/2025/024</guid>
<content:encoded><![CDATA[
<div> 关键词：秘密握手、公平性、隐私保护、自区分性、叛徒捕捉

总结:
本文提出了一种对秘密握手协议的重要更新，增强了效率和隐私保障。该更新基于Tsudik和Xu的模块化框架，通过替换组签名原语为新的List MAC构造，实现了用户在握手会话中自我区分的能力，同时不泄露其身份，从而提供了更强的隐私保证。为了保持其他参与者的匿名性，引入了叛徒捕捉范式，握手记录仅揭示叛徒的身份。此外，文章展示了两个后量子时代的具体实现（基于哈希和基于 lattice 的），证明了新框架的灵活性和健壮性，并修正了以前的限制，为秘密握手中的隐私和安全设立了新的基准。 <div>
Secret handshakes, introduced by Balfanz et al. [3], allow users associated with various groups to determine if they share a common affiliation. These protocols ensure crucial properties such as fairness (all participants learn the result simultaneously), affiliation privacy (failed handshakes reveal no affiliation information), and result-hiding (even participants within a shared group cannot infer outcomes of unrelated handshakes). Over time, various secret-handshake schemes have been proposed, with a notable advancement being the modular framework by Tsudik and Xu. Their approach integrates three key components: group signature schemes, centralized secure channels for each group, and decentralized group key-agreement protocols.
Building upon this modularity, we propose significant updates. By addressing hidden complexities and revising the security model, we enhance both the efficiency and the privacy guarantees of the protocol. Specifically, we achieve the novel property of Self distinction—the ability to distinguish between two users in a session without revealing their identities—by replacing the group signature primitive with a new construct, the List MAC. This primitive is inherently untraceable, necessitating adjustments to the original syntax to support stronger privacy guarantees. Consequently, we introduce the Traitor Catching paradigm, where the transcript of a handshake reveals only the identity of a traitor, preserving the anonymity of all other participants.
To showcase the flexibility and robustness of our updated framework, we present two post-quantum instantiations (a hash-based one and another based on lattices). Our approach not only corrects prior limitations but also establishes a new benchmark for privacy and security in secret handshakes.
]]></content:encoded>
<pubDate>Tue, 07 Jan 2025 09:13:51 +0000</pubDate>
</item>
<item>
<title>Foundations of Platform-Assisted Auctions</title>
<link>https://eprint.iacr.org/2025/019</link>
<guid>https://eprint.iacr.org/2025/019</guid>
<content:encoded><![CDATA[
<div> 关键词：平台辅助拍卖、加密货币、机制设计、多方计算、区块链

总结:
本文提出了一个新的模型来研究无许可环境下的平台辅助拍卖，探讨在这种情况下是否存在能够让买家、卖家、平台以及平台与买卖方联盟均选择诚实行为作为利益最大化的理想的拍卖方案。作者揭示了加密货币和机制设计之间的有趣联系，并展示如何利用加密技术设计具有理想属性的有效平台辅助拍卖。文章进一步分析了当服务提供者（如实现多方计算或区块链协议的节点）具备战略性的特点并可能与卖方或买方合谋时的游戏理论影响。此外，文中指出标准多方计算文献中采用的全模拟范式可能导致过高的成本，尤其是对于拍卖协议，因为每个玩家都有不同的私人结果，使用任何通用多方计算协议都将至少产生n²的总成本。为此，他们提出了一种新的模拟概念——“效用主导的模拟”，该模拟足以保证拍卖所需的游戏理论性质。在此基础上，他们展示了如何设计具有准线性效率的高效拍卖协议，相较于任何通用方法实现了n倍的成本改进。 <div>
Today, many auctions are carried out with the help of intermediary platforms like Google and eBay. These platforms serve as a  rendezvous point for the buyers and sellers, and charge a fee for its service. We refer to such auctions as platform-assisted auctions. Traditionally, the auction theory literature mainly focuses on designing auctions that incentivize the buyers to bid truthfully, assuming that the platform always faithfully implements the auction. In practice, however, the platforms have been found to   manipulate the auctions to earn more profit, resulting in high-profile anti-trust lawsuits. 

We propose a new model  for studying platform-assisted  auctions in the permissionless setting, where anyone can register and participate in the auction. We explore whether it is possible to design a dream auction in this new model, such that honest behavior  is the utility-maximizing strategy for each individual buyer, the platform, the seller, as well as platform-seller or platform-buyer coalitions. Through a collection of feasibility and infeasibility results, we carefully characterize the mathematical landscape of platform-assisted auctions. 

Interestingly, our work reveals exciting connections between cryptography and mechanism design. We show how cryptography can lend to the design of an efficient platform-assisted auction with dream properties. Although a line of works have also used multi-party computation (MPC) or the blockchain to remove the reliance on a trusted auctioneer, our work is distinct in nature in several dimensions. First, we initiate a systematic exploration of  the game theoretic implications when the service providers (e.g., nodes that implement the MPC or blockchain protocol) are strategic and can collude with sellers or buyers.  Second,  we observe that the full simulation paradigm used in the standard MPC literature is too stringent and leads to high asymptotical costs. Specifically,  because every player has a different private outcome in an auction protocol, to the best of our knowledge, running any generic MPC  protocol among the players would incur at least $n^2$ total cost  where $n$ is the number of buyers.We propose a new notion of simulation called {\it utility-dominated emulation} that is sufficient for guaranteeing the game-theoretic properties needed in an auction. Under this new notion of simulation, we show how to design efficient auction protocols with quasilinear efficiency, which gives an $n$-fold improvement over any generic approach.
]]></content:encoded>
<pubDate>Mon, 06 Jan 2025 01:26:40 +0000</pubDate>
</item>
<item>
<title>Dynamically Available Common Subset</title>
<link>https://eprint.iacr.org/2025/016</link>
<guid>https://eprint.iacr.org/2025/016</guid>
<content:encoded><![CDATA[
<div> 关键词: 共识协议、区块链、临时故障、审查攻击、动态可用公共子集(DACS)

总结:
本文针对互联网规模的区块链共识协议提出了一个全新的原子广播协议，该协议在存在预期的临时故障（即睡眠模型）的情况下仍能保持运行，尤其适合对延迟敏感的金融应用。现有的领导者架构使这些协议容易受到短期审查攻击，允许提案者排除特定交易以获取利益。与传统方法不同，新协议不依赖于每个区块高度的单一提案者，而是采用了一种名为动态可用公共子集(DACS)的协议，这是在睡眠模型中的首创。此外，该构建还确保了确定性同步：一旦诚实节点确认一个区块，所有其他诚实节点将在常数时间内进行确认，从而解决了许多低延迟睡眠协议中存在的问题。 <div>
Internet-scale consensus protocols used by blockchains are designed to remain operational in the presence of unexpected temporary crash faults (the so-called sleepy model of consensus) -- a critical feature for the latency-sensitive financial applications running on these systems. 
However, their leader-based architecture, where a single block proposer is responsible for creating the block at each height, makes them vulnerable to short-term censorship attacks, in which the proposers profit at the application layer by excluding certain transactions. 
In this work, we introduce an atomic broadcast protocol, secure in the sleepy model, that ensures the inclusion of all transactions within a constant expected time, provided that at least one participating node is non-censoring at all times. 
Unlike traditional approaches, our protocol avoids designating a single proposer per block height, instead leveraging a so-called dynamically available common subset (DACS) protocol -- the first of its kind in the sleepy model. Additionally, our construction guarantees deterministic synchronization -- once an honest node confirms a block, all other honest nodes do so within a constant time, thus addressing a shortcoming of many low-latency sleepy protocols.
]]></content:encoded>
<pubDate>Sat, 04 Jan 2025 14:19:51 +0000</pubDate>
</item>
<item>
<title>SPY-PMU: Side-Channel Profiling of Your Performance Monitoring Unit to Leak Remote User Activity</title>
<link>https://eprint.iacr.org/2025/014</link>
<guid>https://eprint.iacr.org/2025/014</guid>
<content:encoded><![CDATA[
<div> 关键词: 性能监控单元(PMU), 边信道攻击, 微架构指纹, 机器学习(ML), 隐私泄露

总结:<br />
本文探讨了现代计算系统中普遍存在的性能监控单元（PMU）所带来的安全风险。通过利用PMU数据进行远程边信道攻击，揭示了能够侵犯用户隐私并实现远程隐秘监视的安全漏洞。研究团队通过对PMU特征空间分析，为基准应用创建独特的微架构指纹，并运用这些指纹构建机器学习（ML）模型以检测对应的基准应用。这种方法使得攻击者在远程访问受害者的PMU数据时，可以使用预训练模型准确识别受害者正在使用的应用程序。实验中，该预训练模型成功地通过远程PMU数据识别出受害者所使用的应用程序，证明了PMU数据用于远程侧信道分析的潜在恶意利用风险。研究人员针对stress-ng基准测试构建了逻辑回归、决策树、k近邻和随机森林等ML分类器模型，平均预测精度高达98%。这凸显了防范PMU数据远程侧信道攻击的紧迫性，并为未来微架构安全领域的研究奠定了基础。 <div>
The Performance Monitoring Unit (PMU), a standard feature in all modern computing systems, presents significant security risks by leaking sensitive user activities through microarchitectural event data. This work demonstrates the feasibility of remote side-channel attacks leveraging PMU data, revealing vulnerabilities that compromise user privacy and enable covert surveillance without physical access to the target machine. By analyzing the PMU feature space, we create distinct micro-architectural fingerprints for benchmark applications, which are then utilized in machine learning (ML) models to detect the corresponding benchmarks. This approach allows us to build a pre-trained model for benchmark detection using the unique micro-architectural fingerprints derived from PMU data. Subsequently, when an attacker remotely accesses the victim’s PMU data, the pre-trained model enables the identification of applications used by the victim with high accuracy. In our proof-of-concept demonstration, the pre-trained model successfully identifies applications used by a victim when the attacker remotely accesses PMU data, showcasing the potential for malicious exploitation of PMU data. We analyze stress-ng benchmarks and build our classifiers using logistic regression, decision tree, k-nearest neighbors, and random forest ML models. Our proposed models achieve an average prediction accuracy of 98%, underscoring the potential risks associated with remote side-channel analysis using PMU data and emphasizing the need for more robust safeguards. This work underscores the urgent need for robust countermeasures to protect against such vulnerabilities and provides a foundation for future research in micro-architectural security.
]]></content:encoded>
<pubDate>Fri, 03 Jan 2025 20:29:25 +0000</pubDate>
</item>
<item>
<title>Probabilistic Attacks and Enhanced Security for "Private Set Intersection in the Internet Setting from Lightweight Oblivious PRF"</title>
<link>https://eprint.iacr.org/2024/969</link>
<guid>https://eprint.iacr.org/2024/969</guid>
<content:encoded><![CDATA[
<div> 关键词: Privacy Set Intersection (PSI), CM20协议, 安全漏洞, 概率攻击, 敏感数据保护<br /><br />总结:<br />
本文针对隐私集合交集(PSI)中的CM20协议进行了分析，指出了其存在的安全漏洞。CM20协议利用伪随机函数(PRF)加密用户隐私，但若攻击者获取了$\delta$和$F_2$，则可能恢复PRF加密的隐私信息。文章提出了名为“概率攻击”的方法来利用这一漏洞对CM20进行攻击。为解决此问题，文中引入了一种新的工具——扰动伪随机生成器(PPRG)，通过替换CM20协议中的随机 Oblivious Transfer 和其中一个哈希函数，以抵御此类概率攻击。最后，文章制定了一个针对该 PSI 协议的针对性选择明文攻击(IND-CPA)安全性模型，并表明提出的 PSI 解决方案在各种设备上的效率可与 CM20 相媲美。 <div>
Privacy Set Intersection (PSI) has been an important research topic within privacy computation. Its main function is to allow two parties to compute the intersection of their private sets without revealing any other private information. Therefore, PSI can be applied to various real-world scenarios.

Chase and Miao presented an impressive construction ``Private set intersection in the Internet setting from lightweight oblivious prf'' (CM20 for short) at Crypto 2020, highlighting its convenient structure and optimal communication cost. However, it does have some security vulnerabilities. Let $X$ be the privacy set of user $P_1$, $Y$ be the privacy set of user $P_2$. The CM20 protocol uses a pseudorandom function (PRF) to encrypt the privacy $x\in X$ of $P_1$ into $D_1$ and the privacy $y\in Y$ of $P_2$ into $D_2$, $D_1 = D_2$ as $x=y$. It then sends random data $F_1$ to user $P_1$ and random data $F_2$ to user $P_2$ using a random oblivious transfer technique. User $P_2$ computes $\delta=D_2\oplus F_2$ and sends $\delta$ to user $P_1$, and user $P_1$ uses $\delta$ and $F_1$ to re-encrypt $D_1$. Repeat this until $P_1$ re-encrypts all the privacy in all the privacy sets $X$, packages them up and sends them to $P_2$, who completes the privacy set intersection. However, if an adversary obtains $\delta$ and $F_2$ by any means, they can recover the PRF's encryption of the user's privacy, and the recovery process is non-trivial. This significantly weakens the security of the CM20 protocol.

In this paper, we make three main contributions. First, based on the above analysis, we present a method for attacking CM20, called {\em probabilistic attacks}. This attack is based on estimating and analysing the frequency distribution of the encrypted data from the PRF and the probability distribution of the original private data, and determining the relationship between the two. Although not 100\% effective, this method of attack poses a significant threat to the security of user data.

Secondly, we introduce a new tool called the {\em perturbed pseudorandom generator} (PPRG). We show that the PPRG can overcome probabilistic attacks by replacing the random oblivious transfer and one of the hash functions (originally there were two) in CM20.

Finally, we provide a dedicated indistinguishability against chosen-plaintext attack (IND-CPA) security model for this PSI protocol. The efficiency analysis shows that the proposed PSI is comparable to CM20's PSI, whether on a PC, MAC, pad or mobile phone.
]]></content:encoded>
<pubDate>Sun, 16 Jun 2024 02:53:16 +0000</pubDate>
</item>
<item>
<title>Leverage Staking with Liquid Staking Derivatives (LSDs): Opportunities and Risks</title>
<link>https://eprint.iacr.org/2023/1842</link>
<guid>https://eprint.iacr.org/2023/1842</guid>
<content:encoded><![CDATA[
<div> 关键词: Proof of Stake (PoS), Lido, stETH, Leverage Staking, Risk Analysis

总结:
在以太坊的权益证明（PoS）生态系统中，用户可以通过Lido将ETH进行staking并获得stETH，这是一种液体staking衍生品（LSD），代表了已staking的ETH并积累staking收益。LSD提高了质押资产的流动性，使其能在二级市场如Aave的抵押借贷或Curve上的资产交换中使用。利用Lido、Aave和Curve的组合性，出现了一种名为杠杆staking的新策略，该策略能增强财务回报但同时也引入了潜在风险。文章构建了一个关于使用stETH进行杠杆staking的正式框架，并发现过去963天内在以太坊上存在442个这样的位置，涉及总价值为537,123 ETH（8.77亿美元）。数据显示，81.7%的杠杆staking头寸实现了比Lido常规staking更高的年化收益率（APR）。然而，我们注意到高回报伴随着潜在风险，如Terra崩溃事件展示了代币贬值对市场的影响。因此，我们进行了极端情况下stETH大幅贬值的压力测试，以评估相关的风险。模拟结果显示，杠杆staking会放大强制平仓和去杠杆化过程中的卖出压力风险，加速stETH价格下滑，并引发连锁反应，危及到杠杆头寸和普通头寸的稳定性。 <div>
In the Proof of Stake (PoS) Ethereum ecosystem, users can stake ETH on Lido to receive stETH, a Liquid Staking Derivative (LSD) that represents staked ETH and accrues staking rewards. LSDs improve the liquidity of staked assets by facilitating their use in secondary markets, such as for collateralized borrowing on Aave or asset exchanges on Curve. The composability of Lido, Aave, and Curve enables an emerging strategy known as leverage staking, an iterative process that enhances financial returns while introducing potential risks. This paper establishes a formal framework for leverage staking with stETH and identifies 442 such positions on Ethereum over 963 days. These positions represent a total volume of 537,123 ETH (877m USD). Our data reveal that 81.7% of leverage staking positions achieved an Annual Percentage Rate (APR) higher than conventional staking on Lido. Despite the high returns, we also recognize the potential risks. For example, the Terra crash incident demonstrated that token devaluation can impact the market. Therefore, we conduct stress tests under extreme conditions of significant stETH devaluation to evaluate the associated risks. Our simulations reveal that leverage staking amplifies the risk of cascading liquidations by triggering intensified selling pressure through liquidation and deleveraging processes. Furthermore, this dynamic not only accelerates the decline of stETH prices but also propagates a contagion effect, endangering the stability of both leveraged and ordinary positions.
]]></content:encoded>
<pubDate>Thu, 30 Nov 2023 11:03:01 +0000</pubDate>
</item>
<item>
<title>Fast SNARK-based Non-Interactive Distributed Verifiable Random Function with Ethereum Compatibility</title>
<link>https://eprint.iacr.org/2024/968</link>
<guid>https://eprint.iacr.org/2024/968</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式随机数生成器(DRBs), 非交互式分布式可验证随机函数(NI-DVRF), 以太坊, Rust, Solidity, Boba Network, 层2扩容方案, zkRand

总结:<br />
本文提出了一种迄今为止最高效的直接构建和实现非交互式分布式可验证随机函数(NI-DVRF)的方法，该方法完全兼容以太坊。该NI-DVRF方案利用配对技术并结合了秘密共享、SNARKs和BLS签名的技巧，其安全属性在随机Oracle模型下基于标准的配对基础假设被形式化建模和证明。为了证实效率和成本优势以及在实际中的应用潜力，该方案已在Rust和Solidity中进行了高度优化的实现，并正在研究部署于Boba Network提供的多链层2扩容解决方案上，用于驱动其zkRand DRB服务。实验分析还评估了所提NI-DVRF及其实现的性能和可扩展性属性。 <div>
Distributed randomness beacons (DRBs) are fundamental for various decentralised applications, such as consensus protocols,  decentralised gaming and lotteries, and collective governance protocols. These applications are heavily used on modern blockchain platforms.

This paper presents the so far most efficient direct construction and implementation of a non-interactive distributed verifiable random function (NI-DVRF) that is fully compatible with Ethereum. Our NI-DVRF scheme adopts pairings and combines techniques from secret sharing, SNARKs, and BLS signatures. The security properties of the resulting NI-DVRF scheme are formally modelled and proven in the random oracle model under standard pairing-based assumptions.

To justify the efficiency and cost claims and more generally its adoption potential in practice, the proposed NI-DVRF scheme was implemented in Rust and Solidity. Our implementation is highly optimised and is currently being investigated for deployment on the multichain layer-2 scaling solution provided by Boba Network to power its DRB service zkRand. Our experimental analysis, therefore, also evaluates performance and scalability properties of the proposed NI-DVRF and its implementation.
]]></content:encoded>
<pubDate>Sat, 15 Jun 2024 20:07:25 +0000</pubDate>
</item>
<item>
<title>Voting with coercion resistance and everlasting privacy using linkable ring signatures</title>
<link>https://eprint.iacr.org/2025/002</link>
<guid>https://eprint.iacr.org/2025/002</guid>
<content:encoded><![CDATA[
<div> 关键词：e-voting协议、linkable环签名、无条件匿名性、胁迫抵抗、JCJ框架、可验证性、选票保密性。

总结:<br />
我们提出了一种基于新颖linkable环签名方案的电子投票协议，该协议具有无条件匿名性，确保无论攻击者多么强大都无法推断出投票者的身份，从而实现永久隐私。此外，我们的协议在JCJ框架下提供了胁迫抵抗力，当对手试图强迫投票者进行特定投票时，投票者可通过创建一个带有假但无法区分凭证的签名来规避攻击，在确保隐私的时刻投出真实选票。同时，该协议还具备可验证性和选票保密性。 <div>
We propose an e-voting protocol based on a novel linkable ring signature scheme with unconditional anonymity. In our system, all voters register create private credentials and register their public counterparts. To vote, they create a ring (anonymity set) consisting of public credentials together with a proof of knowledge of their secret credential via our signature. Its unconditional anonymity prevents an attacker, no matter how powerful, from deducing the identity of the voter, thus attaining everlasting privacy. Additionally, our protocol provides coercion resistance in the JCJ framework; when an adversary tries to coerce a voter, the attack can be evaded by creating a signature with a fake but indistinguishable credential. During a moment of privacy, they will cast their real vote. Our scheme also provides verifiability and ballot secrecy.
]]></content:encoded>
<pubDate>Wed, 01 Jan 2025 08:08:50 +0000</pubDate>
</item>
<item>
<title>Smaug: Modular Augmentation of LLVM for MPC</title>
<link>https://eprint.iacr.org/2025/004</link>
<guid>https://eprint.iacr.org/2025/004</guid>
<content:encoded><![CDATA[
<div> 关键词: Secure Multi-Party Computation, MPC编程工具, Smaug, LLVM, Oblivious Computation

总结:
Smaug是一个基于LLVM的模块化扩展，旨在为MPC（安全多方计算）程序员提供更好的支持。现有的MPC编程工具由于缺乏文档、维护和与传统代码库的组合能力而难以吸引用户。Smaug引入了错误消息、文档、代码优化和多种语言编译至LLVM中间表示(IR)的支持。它可以有效地将非无知(Non-oblivious)的LLVM IR转换为其无知(Oblivious)等价物，同时应用LLVM的常用优化技术。通过C++和Rust编写并使用Yao和GMW协议作为后端的基准测试，Smaug的表现与使用领域特定语言的先前工具相当，甚至有时更优。最后，利用Smaug成功地将实现扫雷和21点游戏的开源项目编译成了可行的两方游戏，使得开发过程变得简单易行。 <div>
Secure multi-party computation (MPC) is a crucial tool for privacy-preserving computation, but it is getting increasingly complicated due to recent advancements and optimizations. Programming tools for MPC allow programmers to develop MPC applications without mastering all cryptography. However, most existing MPC programming tools fail to attract real users due to the lack of documentation, maintenance, and the ability to compose with legacy codebases. In this work, we build Smaug, a modular extension of LLVM. Smaug seamlessly brings all LLVM support to MPC programmers, including error messaging, documentation, code optimization, and frontend support to compile from various languages to LLVM intermediate representation (IR). Smaug can efficiently convert non-oblivious LLVM IR to their oblivious counterparts while applying popular optimizations as LLVM code transformations. With benchmarks written in C++ and Rust and backends for Yao and GMW protocols, we observe that Smaug performs as well as (and sometimes much better than) prior tools using domain-specific languages with similar backends. Finally, we use Smaug to compile open-source projects that
implement Minesweeper and Blackjack, producing usable two-party games with ease.
]]></content:encoded>
<pubDate>Wed, 01 Jan 2025 04:01:59 +0000</pubDate>
</item>
<item>
<title>MicroNova: Folding-based arguments with efficient (on-chain) verification</title>
<link>https://eprint.iacr.org/2024/2099</link>
<guid>https://eprint.iacr.org/2024/2099</guid>
<content:encoded><![CDATA[
<div> 关键词: MicroNova、折叠式递归论证、增量计算、验证效率、以太坊区块链

总结:
MicroNova是一种用于生成形式为$y=F^{(\ell)}(x)$的增量计算证明的设计与实现方案，其中$F$是一个可能非确定性的计算（使用如R1CS这样的约束系统编码），$x$是初始输入，$y$是输出，$\ell > 0$表示步骤数。该证明逐步生成，无论$\ell$大小，其证明大小和验证时间均不依赖于它。最后一步的证明会被压缩，进一步提高证明的简洁性。相比于之前的折叠式论证，MicroNova的一个显著特点是其在资源受限环境（如以太坊区块链）中具有高效的验证器实现。具体来说，压缩后的证明仅包含$O(\log{N})$个群元素，并能通过$O(\log{N})$个群标量乘法和两次配对操作进行验证，其中$N$是单次调用$F$时的约束数量。MicroNova需要一个通用的可信设置，并可以利用已经为流行的KZG一元多项式承诺方案创建的任何现有设置材料。实验结果显示，MicroNova的证明可以在以太坊区块链上高效地验证，大约耗用2.2M gas。此外，MicroNova的证明者在其基线Nova证明者的顶部只产生了轻微的开销。 <div>
We describe the design and implementation of MicroNova, a folding-based recursive argument for producing proofs of incremental computations of the form $y = F^{(\ell)}(x)$, where $F$ is a possibly non-deterministic computation (encoded using a constraint system such as R1CS), $x$ is the initial input, $y$ is the output, and $\ell > 0$. The proof of an $\ell$-step computation is produced step-by-step such that the proof size nor the time to verify it depends on $\ell$. The proof at the final iteration is then compressed, to achieve further succinctness in terms of proof size and verification time. Compared to prior folding-based arguments, a distinguishing aspect of MicroNova is the concrete efficiency of the verifier—even in a resource-constrained environment such as Ethereum’s blockchain. In particular, the compressed proof consists of $O(\log{N})$ group elements and it can be verified with $O(\log{N})$ group scalar multiplications and two pairing operations, where $N$ is the number of constraints for a single invocation of $F$. MicroNova requires a universal trusted setup and can employ any existing setup material created for the popular KZG univariate polynomial commitment scheme. Finally, we implement and experimentally evaluate MicroNova. We find that MicroNova’s proofs can be efficiently verified on the Ethereum blockchain with $\approx$2.2M gas. Furthermore, MicroNova’s prover incurs minimal overheads atop its baseline Nova’s prover.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 17:29:55 +0000</pubDate>
</item>
<item>
<title>NMFT: A Copyrighted Data Trading Protocol based on NFT and AI-powered Merkle Feature Tree</title>
<link>https://eprint.iacr.org/2024/2097</link>
<guid>https://eprint.iacr.org/2024/2097</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、NFT、版权保护、Merkle Feature Tree (MFT)、Locality-Sensitive Hashing (LSH)

总结:
为了解决区块链上基于NFT的数据交易中面临的版权保护问题，本文提出了一种版权保护数据交易协议。该协议主要包括两个创新点：首先，引入了增强版的默克尔树——Merkle Feature Tree (MFT)，它在数据层之上结合了一个AI驱动的特征层，以更好地保护版权信息；其次，在交易过程中设计了版权挑战阶段，利用高相似度特征向量和更早的链上时间戳来确认原始所有者的合法地位。为了实现在区块链上进行高效低能耗的特征向量相似性计算，文章采用了Locality-Sensitive Hashing (LSH)算法，将高维浮点特征向量压缩成单个uint256整数。实验结果显示，LSH能够在压缩前后有效地保持高度相似特征向量之间的相似性，支持基于相似性的版权挑战。此外，以太坊Sepolia测试网上的实验表明，NMFT具有可扩展性，其 Gas 消耗随规模增长呈亚线性，同时保持稳定的延迟。 <div>
With the rapid growth of blockchain-based Non-Fungible Tokens (NFTs), data trading has evolved to incorporate NFTs for ownership verification. However, the NFT ecosystem faces significant challenges in copyright protection, particularly when malicious buyers slightly modify the purchased data and re-mint it as a new NFT, infringing upon the original owner's rights. In this paper, we propose a copyright-preserving data trading protocol to address this challenge.

First, we introduce the Merkle Feature Tree (MFT), an enhanced version of the traditional Merkle Tree that incorporates an AI-powered feature layer above the data layer. Second, we design a copyright challenge phase during the trading process, which recognizes the data owner with highly similar feature vectors and earlier on-chain timestamp as the legitimate owner. Furthermore, to achieve efficient and low-gas feature vector similarity computation on blockchain, we employ Locality-Sensitive Hashing (LSH) to compress high-dimensional floating-point feature vectors into single uint256 integers.

Experiments with multiple image and text feature extraction models demonstrate that LSH effectively preserves the similarity between highly similar feature vectors before and after compression, thus supporting similarity-based copyright challenges. Experimental results on the Ethereum Sepolia testnet demonstrate NMFT's scalability with sublinear growth in gas consumption while maintaining stable latency.
]]></content:encoded>
<pubDate>Tue, 31 Dec 2024 10:37:15 +0000</pubDate>
</item>
<item>
<title>Secure Vault scheme in the Cloud Operating Model</title>
<link>https://eprint.iacr.org/2024/2094</link>
<guid>https://eprint.iacr.org/2024/2094</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据隐私保险库、云环境、数据安全、令牌化算法、形式化框架

总结:
文章介绍了随着对云环境中数据隐私需求的增长，数据隐私保险库作为一种安全管理敏感信息的解决方案应运而生。然而，目前尚无针对数据隐私保险库的安全性进行严格定义和形式化证明的工作。本文关注这一问题，提出了适用于大型语言模型训练数据存储的数据隐私保险库新框架，该框架在云操作模式下运行，假设服务器可信但无状态，存储外包。文中提出了一种新颖的令牌化算法作为保护敏感数据的核心机制，既能生成安全、不可预测的令牌，又能确保敏感数据的安全存储并实现基于预定义访问级别的受控数据检索。此外，本文还为数据隐私保险库提供了正式定义和具体实现，并附带了安全性证明，填补了现有文献中的空白，从而增强了对保险库方案的理解，并为云计算时代安全数据管理提供了一个可行的解决方案。 <div>
The rising demand for data privacy in cloud-based environments has led to the development of advanced mechanisms for securely managing sensitive information. A prominent solution in this domain is the "Data Privacy Vault," a concept that is being provided commercially by companies such as Hashicorp, Basis Theory, Skyflow Inc., VGS, Evervault, Protegrity, Anonomatic, and BoxyHQ. However, no existing work has rigorously defined the security notions required for a Data Privacy Vault or proven them within a formal framework which is the focus of this paper.

Among its other uses, data privacy vaults are increasingly being used as storage for LLM training data which necessitates a scheme that enables users to securely store sensitive information in the cloud while allowing controlled access for performing analytics on specific non-sensitive attributes without exposing sensitive data. Conventional solutions involve users generating encryption keys to safeguard their data, but these solutions are not deterministic and are therefore unsuited for the LLM setting. To address this, we propose a novel framework that is deterministic as well as semantically secure. Our scheme operates in the Cloud Operating model where the server is trusted but stateless, and the storage is outsourced.

We provide a formal definition and a concrete instantiation of this data privacy vault scheme. We introduce a novel tokenization algorithm that serves as the core mechanism for protecting sensitive data within the vault. Our approach not only generates secure, unpredictable tokens for sensitive data but also securely stores sensitive data while enabling controlled data retrieval based on predefined access levels. Our work fills a significant gap in the existing literature by providing a formalized framework for the data privacy vault, complete with security proofs and a practical construction - not only enhancing the understanding of vault schemes but also offering a viable solution for secure data management in the era of cloud computing.
]]></content:encoded>
<pubDate>Mon, 30 Dec 2024 14:03:33 +0000</pubDate>
</item>
<item>
<title>Post-Quantum Privacy for Traceable Receipt-Free Encryption</title>
<link>https://eprint.iacr.org/2024/2087</link>
<guid>https://eprint.iacr.org/2024/2087</guid>
<content:encoded><![CDATA[
<div> 关键词: Traceable Receipt-free Encryption (TREnc), 量子计算机, 隐私保护, Ring Learning With Errors (RLWE), 配对式统计零知识证明

总结:
文章介绍了可追溯收据自由加密(TREnc)这一新兴的公开密钥加密原语及其在投票系统中的应用。现有的TREnc机制主要依赖于离散对数相关假设，易受未来量子计算机的攻击。为解决这一局限性，文章构建了首个能抵御量子敌手隐私攻击的TREnc方案。首先，作者对原始的TREnc模型进行了通用化，使其更易于与基于格的语义安全加密兼容。该实现依赖于Ring Learning With Errors (RLWE)和Groth-Sahai的配对式统计零知识模拟声学证明，并进一步具备公共硬币共同参考字符串的特点，从而消除了对可信设置的需求。 <div>
Traceable Receipt-free Encryption (TREnc) has recently been introduced as a verifiable public-key encryption primitive endowed with a unique security model. In a nutshell, TREnc allows randomizing ciphertexts in transit in order to remove any subliminal information up to a public trace that ensures the non-malleability of the underlying plaintext. A remarkable property of TREnc is the indistinguishability of the randomization of chosen ciphertexts against traceable chosen-ciphertext attacks (TCCA). The main application lies in voting systems by allowing voters to encrypt their votes, tracing whether a published ballot takes their choices into account, and preventing them from proving how they
voted. While being a very promising primitive, the few existing TREnc mechanisms solely rely on discrete-logarithm related assumptions making them vulnerable to the well-known record-now/decrypt-later attack in the wait of quantum computers.
We address this limitation by building the first TREnc whose privacy withstands the advent of quantum adversaries in the future. To design our construction, we first generalize the original TREnc primitive that is too restrictive to be easily compatible with built-in lattice-based semantically-secure encryption. Our more flexible model keeps all the ingredients generically implying receipt-free voting. Our instantiation relies on Ring Learning With Errors (RLWE) with pairing-based statistical zero-knowledge simulation sound proofs from Groth-Sahai, and further enjoys a public-coin common reference string removing the need of a trusted setup.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 21:23:18 +0000</pubDate>
</item>
<item>
<title>How To Think About End-To-End Encryption and AI: Training, Processing, Disclosure, and Consent</title>
<link>https://eprint.iacr.org/2024/2086</link>
<guid>https://eprint.iacr.org/2024/2086</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端加密(E2EE)、人工智能(AI)、安全冲突、法律影响、推荐实践

<br /><br />总结:
本文对人工智能模型与端到端加密应用的兼容性进行了批判性审查，主要从两个方面展开：一是E2EE应用中集成AI“助手”，二是使用E2EE数据训练AI模型。文章分析了这两种情况下的潜在安全影响，指出它们可能与E2EE提供的安全性保证相冲突，并探讨了AI整合对E2EE承诺的机密性的法律影响。最后，基于技术与法律分析，文章提出了若干详细建议，包括为了维护E2EE安全应优先考虑的技术设计选择、服务提供商如何准确表述E2EE的安全性以及AI功能的默认行为和征求用户同意的最佳实践。作者期望这篇论文能引发关于AI迅速部署与E2EE所提供安全性的紧张关系之间的知情讨论，并指导新AI特性负责任地开发。 <div>
End-to-end encryption (E2EE) has become the gold standard for securing communications, bringing strong confidentiality and privacy guarantees to billions of users worldwide. However, the current push towards widespread integration of artificial intelligence (AI) models, including in E2EE systems, raises some serious security concerns.

This work performs a critical examination of the (in)compatibility of AI models and E2EE applications. We explore this on two fronts: (1) the integration of AI “assistants” within E2EE applications, and (2) the use of E2EE data for training AI models. 
We analyze the potential security implications of each, and identify conflicts with the security guarantees of E2EE. Then, we analyze legal implications of integrating AI models in E2EE applications, given how AI integration can undermine the confidentiality that E2EE promises. Finally, we offer a list of detailed recommendations based on our technical and legal analyses, including: technical design choices that must be prioritized to uphold E2EE security; how service providers must accurately represent E2EE security; and best practices for the default behavior of AI features and for requesting user consent. We hope this paper catalyzes an informed conversation on the tensions that arise between the brisk deployment of AI and the security offered by E2EE, and guides the responsible development of new AI features.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 20:08:40 +0000</pubDate>
</item>
<item>
<title>Definition of End-to-end Encryption</title>
<link>https://eprint.iacr.org/2024/2085</link>
<guid>https://eprint.iacr.org/2024/2085</guid>
<content:encoded><![CDATA[
<div> 关键词：端到端加密（E2EE）、加密机制、通信安全、隐私保护、消息、电子邮件、视频、音频、媒体、保密性、完整性、真实性、前向安全性。

总结:
端到端加密（E2EE）是一种应用加密技术确保两端点间通信安全与隐私的应用，涵盖了包括消息、电子邮件、视频、音频等不同形式的媒体内容。E2EE为人们的交流提供了四个关键保障：保密性，确保信息仅由发送者和接收者阅读；完整性，保证数据在传输过程中不被篡改；真实性，确认信息来自预期的发送方；以及前向安全性，即使密钥丢失，过去通信内容仍能保持安全。 <div>
This document provides a definition of end-to-end encryption (E2EE). End-to-end encryption is an application of cryptographic mechanisms to provide security and privacy to communication between endpoints. Such communication can include messages, email, video, audio, and other forms of media. E2EE provides security and privacy through confidentiality, integrity, authenticity and forward secrecy for communication amongst people.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 20:03:19 +0000</pubDate>
</item>
<item>
<title>Zero Knowledge Memory-Checking Techniques for Stacks and Queues</title>
<link>https://eprint.iacr.org/2024/2084</link>
<guid>https://eprint.iacr.org/2024/2084</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、内存技术、队列、栈、多项式评估

总结:<br />
本文提出了适用于特殊数据结构——队列和栈的内存技术。针对队列，文章介绍了一种基于算术电路的实现方法，该方法在每次读取时需要3个多项式乘法门和1个建议值，每次写入时需要2个多项式乘法门。该方法利用Horner规则来验证队列中读取和写入值的一致性。对于栈，文章提出一种优化版的RAM方案，基于Yang和Heath的方法，读取操作需要5个多项式乘法门和4个建议值，而写入仍为2个多项式乘法门。该优化方案利用栈的特性避免了对每个访问插入哑操作的需求。此外，文中还引入了一种更适合栈和队列应用场景的“多路复用”或“操作隐私”的新概念，所有的技术都是基于在随机点上评估多项式并使用随机评估的多项式作为通用哈希函数来检查集合/向量的等价性。 <div>
There are a variety of techniques for implementing read/write memory inside of zero-knowledge proofs and validating consistency of memory accesses. These techniques are generally implemented with the goal of implementing a RAM or ROM. In this paper, we present memory techniques for more specialized data structures: queues and stacks. We first demonstrate a technique for implementing queues in arithmetic circuits that requires 3 multiplication gates and 1 advice value per read and 2 multiplication gates per write. This is based on using Horner's Rule to evaluate 2 polynomials at random points and check that the values read from the queue are equal to the values written to the queue as vectors. Next, we present a stack scheme based on an optimized version of the RAM scheme of Yang and Heath that requires 5 multiplication gates and 4 advice values per read and 2 multiplication gates per write. This optimizes the RAM scheme by observing that reads and writes to a stack are already "paired" which avoids the need for inserting dummy operations for each access as in a stack.
    We also introduce a different notion of "multiplexing" or "operation privacy" that is better suited to the use case of stacks and queues. All of the techniques we provide are based on evaluating polynomials at random points and using randomly evaluated polynomials as universal hash functions to check set/vector equality.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 18:57:30 +0000</pubDate>
</item>
<item>
<title>ClusterGuard: Secure Clustered Aggregation for Federated Learning with Robustness</title>
<link>https://eprint.iacr.org/2024/2082</link>
<guid>https://eprint.iacr.org/2024/2082</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习、安全聚合、dropout处理、中毒攻击、ClusterGuard

总结:
联邦学习中，为了保护数据隐私并实现模型协同训练，安全聚合与dropout处理是关键挑战。现有的先进方法如Liu等人（UAI'22）和Li等人（ASIACRYPT'23）方案存在通信开销大、实施复杂以及易受中毒攻击的问题。部分连接图结构的方法虽能降低通信成本（如Bell等人，CCS'20和ACORN, USENIX Sec'23），但在图构建过程中可能遭受恶意操纵。为此，我们提出了ClusterGuard，一种用于联邦学习的安全聚类聚合方案。ClusterGuard利用可验证随机函数（VRF）确保公平透明的聚类选择，并结合轻量级密钥同态掩码机制及高效的dropout处理实现安全聚类聚合。此外，ClusterGuard还引入基于余弦相似性和范数的双重过滤机制来有效检测和缓解中毒攻击。实验表明，ClusterGuard相比于先进的安全聚合方法在效率上提升了超过2倍，即使在有20%的客户端恶意的情况下，训练出的模型仍能保持与原模型相当的准确性，优于现有鲁棒性解决方案。因此，ClusterGuard为实际应用中的联邦学习提供了更为高效、安全和鲁棒的解决方案。 <div>
Federated Learning (FL) enables collaborative model training while preserving data privacy by avoiding the sharing of raw data. However, in large-scale FL systems, efficient secure aggregation and dropout handling remain critical challenges. Existing state-of-the-art methods, such as those proposed by Liu et al. (UAI'22) and Li et al. (ASIACRYPT'23), suffer from prohibitive communication overhead, implementation complexity, and vulnerability to poisoning attacks. Alternative approaches that utilize partially connected graph structures (resembling client grouping) to reduce communication costs, such as Bell et al. (CCS'20) and ACORN (USENIX Sec'23), face the risk of adversarial manipulation during the graph construction process.

To address these issues, we propose ClusterGuard, a secure clustered aggregation scheme for federated learning. ClusterGuard leverages Verifiable Random Functions (VRF) to ensure fair and transparent cluster selection and employs a lightweight key-homomorphic masking mechanism, combined with efficient dropout handling, to achieve secure clustered aggregation. Furthermore, ClusterGuard incorporates a dual filtering mechanism based on cosine similarity and norm to effectively detect and mitigate poisoning attacks.

Extensive experiments on standard datasets demonstrate that ClusterGuard achieves over 2x efficiency improvement compared to advanced secure aggregation methods. Even with 20% of clients being malicious, the trained model maintains accuracy comparable to the original model, outperforming state-of-the-art robustness solutions. ClusterGuard provides a more efficient, secure, and robust solution for practical federated learning.
]]></content:encoded>
<pubDate>Fri, 27 Dec 2024 15:12:04 +0000</pubDate>
</item>
<item>
<title>Blind Signatures from Proofs of Inequality</title>
<link>https://eprint.iacr.org/2024/2076</link>
<guid>https://eprint.iacr.org/2024/2076</guid>
<content:encoded><![CDATA[
<div> 关键词: Blind signatures、pairing-free、random oracle模型、DDH假设、效率提升

总结:
这篇文章介绍了新的盲签名构造方法，该方法旨在缩小效率上的差距，特别是在不需要配对的情况下。与最高效的基于配对的AGM盲签名方案相比，新方案在通信和签名大小上分别只有3倍和2倍的相对开销，并在随机预言机模型下基于DDH假设可证明安全性。此外，通过增加一步操作和一个$\mathbb{Z}_p$元素，该方案还实现了更强的防伪造性。这一成果受到了Chairattana-Apirom, Tessaro, 和 Zhu (Crypto 2024)以及Klooß, Reichle, 和Wagner (Asiacrypt 2024)近期工作的启发，并针对这些工作中的效率瓶颈开发了定制化技术。具体来说，新方案实现了192字节的签名大小和608字节的通信大小。 <div>
Blind signatures are an important primitive for privacy-preserving technologies. To date, highly efficient pairing-free constructions rely on the random oracle model, and additionally, a strong assumption, such as interactive assumptions or the algebraic group model.

In contrast, for signatures we know many efficient constructions that rely on the random oracle model and standard assumptions. In this work, we develop techniques to close this gap. Compared to the most efficient pairing-free AGM-based blind signature by Crites et. al. (Crypto 2023), our construction has a relative overhead of only a factor $3\times$ and $2\times$ in terms of communication and signature size, and it is provable in the random oracle model under the DDH assumption. With one additional move and $\mathbb{Z}_p$ element, we also achieve one-more strong unforgeability.

Our construction is inspired by the recent works by Chairattana-Apirom, Tessaro, and Zhu (Crypto 2024) and Klooß, Reichle, and Wagner (Asiacrypt 2024), and we develop a tailored technique to circumvent the sources of inefficiency in their constructions. Concretely, we achieve signature and communication size of $192$ B and $608$ B, respectively.
]]></content:encoded>
<pubDate>Wed, 25 Dec 2024 20:28:26 +0000</pubDate>
</item>
<item>
<title>Advancements in Distributed RSA Key Generation: Enhanced Biprimality Tests</title>
<link>https://eprint.iacr.org/2024/2072</link>
<guid>https://eprint.iacr.org/2024/2072</guid>
<content:encoded><![CDATA[
<div> 关键词：RSA、安全多方计算、Boneh-Franklin测试、Lucas双素性测试、分布式RSA模数生成

总结:

本文针对RSA密码学实践中广泛使用的 Boneh-Franklin 双素性测试进行了深入研究。首先，证明了该测试在接受概率上的上限其实为1/4，而非原先假设的1/2，除非$p=q=3$，这意味着在实际应用中执行相同安全性检验所需的迭代次数可以减半。随后，文章提出了两种类型的Lucas双素性测试。其中一种测试在最坏情况下的接受率不超过$1/4 + 1.25/(p_{\min}-3)$，其中$p_{\min}$为$N$的最小质因数，模拟研究表明它通常比Boneh-Franklin测试更高效地检测$N$是否为RSA模数。另一种Lucas测试可应用于任意RSA模数$p$和$q$，但其效率较低。当生成RSA模数的安全性错误设定约为$2^{-80}$时，该测试最多泄露46个二次符号值。此外，文章还设计了对应于这两种测试的协议，并验证了它们对于半诚实敌手的鲁棒性，这些协议可以应用于已知的大多数分布式RSA模数生成协议。通过对包括Burkhardt等人在CCS 2023上提出的Miller-Rabin测试变种、Boneh-Franklin测试以及所提Lucas型测试在内的多种知名协议进行详尽分析和比较后，发现所提Lucas测试在验证$N$是否为RSA模数方面具有高度竞争力。 <div>
RSA is widely used in modern cryptographic practice, with certain RSA-based protocols relying on the secrecy of $p$ and $q$. A common approach is to use secure multiparty computation to address the privacy concerns of 
$p$ and $q$.
Specifically constrained to distributed RSA modulus generation protocols, the biprimality test for Blum integers $N=pq$, where $p\equiv q\equiv 3 \mod 4$ are two primes, proposed by Boneh and Franklin in $2001$ is the most commonly used. Over the past $20 $ years, the worst-case acceptance rate of this test has been consistently assumed to be $1/2$ under the condition $\gcd(pq,p+q-1)=1$.
In this paper, we show that for the Boneh-Franklin test, its acceptance probability is at most $1/4$ rather than $1/2$,
except in the case where $p = q = 3$.  At the same time, $1/4$ is also the tightest upper bound. Enhance the effectiveness of applying the Boneh-Franklin test in this result: achieving the same soundness for the RSA modulus requires only half the number of iterations commonly recognized. 
Furthermore, we propose two types of Lucas biprimality tests. In the worst case, one of proposed tests acceptance rate is at most $1/4 +  1.25/(p_{\min} -3)$, where $p_{\min}$ is the smallest prime factors of $N$. However, simulation study suggests that this test is generally more efficient than the Boneh-Franklin test for detecting when $N$ is not an RSA modulus.
The second type of Lucas test, though less efficient, can be applied to arbitrary RSA moduli $p$ and $q$. Nevertheless, if the soundness error for generating an RSA modulus is set at approximately $2^{-80}$, it leaks at most $46$ quadratic symbol values, regardless of the public key length. We also design corresponding protocols for both tests and validate their resilience against semi-honest adversaries, which can be applied to most known distributed RSA modulus generation protocols. After thoroughly analyzing and comparing well-known protocols, including the variant Miller-Rabin test used by Burkhardt et al. (CCS 2023), the Boneh-Franklin test, and our proposed Lucas-type tests, our proposed Lucas test is also highly competitive in verifying whether $N$ is an RSA modulus.
]]></content:encoded>
<pubDate>Tue, 24 Dec 2024 16:44:46 +0000</pubDate>
</item>
<item>
<title>COCO: Coconuts and Oblivious Computations for Orthogonal Authentication</title>
<link>https://eprint.iacr.org/2024/2066</link>
<guid>https://eprint.iacr.org/2024/2066</guid>
<content:encoded><![CDATA[
<div> 关键词：COCO、身份验证、隐私保护、Oblivious Pseudorandom Functions (OPRFs)、 CoconutCredential Scheme

<br /><br />总结：
本文提出了一种名为COCO（Coconuts和 Oblivious Computations for Orthogonal Authentication）的框架，旨在实现隐私保护的身份验证。COCO通过将角色分割为验证者、认证器和客户端，避免了认证器直接访问虚拟公共标识或现实世界标识的需求。该框架利用Oblivious Pseudorandom Functions (OPRFs) 和扩展的Coconut Credential Scheme，引入了独立的不可链接的正交认证标识以及全共识机制，从而进行零知识认证，保证证明在多个会话中均不可链接。这种身份验证过程成为自我包含的，防止虚拟公共标识与现实世界标识之间的明确反向追踪。 <div>
Authentication often bridges real-world individuals and their virtual public identities, like usernames, user IDs and e-mails, exposing vulnerabilities that threaten user privacy. This research introduces COCO (Coconuts and Oblivious Computations for Orthogonal Authentication), a framework that segregates roles among Verifiers, Authenticators, and Clients to achieve privacy-preserving authentication.

COCO eliminates the need for Authenticators to directly access virtual public identifiers or real-world identifiers for authentication. Instead, the framework leverages Oblivious Pseudorandom Functions (OPRFs) and an extended Coconut Credential Scheme to ensure privacy by introducing separate unlinkable orthogonal authentication identifiers and a full-consensus mechanism to perform zero-knowledge authentications whose proof-s are unlinkable across multiple sessions. Authentication process becomes self-contained, preventing definitive reverse tracing of virtual public identifiers to real-world identifiers.
]]></content:encoded>
<pubDate>Mon, 23 Dec 2024 14:43:26 +0000</pubDate>
</item>
<item>
<title>Greco: Fast Zero-Knowledge Proofs for Valid FHE RLWE Ciphertexts Formation</title>
<link>https://eprint.iacr.org/2024/594</link>
<guid>https://eprint.iacr.org/2024/594</guid>
<content:encoded><![CDATA[
<div> 关键词: 全同态加密(FHE), 多方计算, 密文投票, 零知识证明, Greco<br /><br />总结: 全同态加密（FHE）允许对加密数据执行任意函数运算。在多方FHE应用中，不同参与者加密其秘密数据并提交给服务器，服务器根据应用逻辑对这些密文进行同态操作。以秘密投票为例，计票是通过对表示选票的密文求和来计算的。恶意选民可能会发送如$E(145127835)$这样的无效加密选票，从而破坏选举结果。为解决此问题，用户需利用零知识证明证明他们提交的RLWE密文是有效的，并且加密的消息是一个有效的选票（例如，1或0）。Greco利用零知识证明让用户证明其RLWE密文构造正确。此外，该证明可以与特定应用逻辑结合，并在非交互式环境中公开验证。对于秘密投票应用，还可以进一步证明消息的其他属性甚至关于选民的属性，从而支持匿名投票。Greco的实现采用了Halo2-lib作为证明系统，基准测试显示它可以被无缝集成到面向用户的应用程序中，而不会过度增加用户使用的摩擦。该实现已在https://github.com/privacy-scaling-explorations/greco上发布。 <div>
Fully homomorphic encryption (FHE) allows for evaluating arbitrary functions over encrypted data. In Multi-party FHE applications, different parties encrypt their secret data and submit ciphertexts to a server, which, according to the application logic, performs homomorphic operations on them. For example, in a secret voting application, the tally is computed by summing up the ciphertexts encoding the votes. Valid encrypted votes are of the form $E(0)$ and $E(1)$. A malicious voter could send an invalid encrypted vote such as $E(145127835)$, which can mess up the whole election. Because of that, users must prove that the ciphertext they submitted is a valid Ring-Learning with Errors (RLWE) ciphertext and that the plaintext message they encrypted is a valid vote (for example, either a 1 or 0). Greco uses zero-knowledge proof to let a user prove that their RLWE ciphertext is well-formed. Or, in other words, that the encryption operation was performed correctly. The resulting proof can be, therefore, composed with additional application-specific logic and subject to public verification in a non-interactive setting. Considering the secret voting application, one can prove further properties of the message being encrypted or even properties about the voter, allowing the application to support anonymous voting as well. The prover has been implemented using Halo2-lib as a proving system, and the benchmarks have shown that Greco can already be integrated into user-facing applications without creating excessive friction for the user. The implementation is available at https://github.com/privacy-scaling-explorations/greco
]]></content:encoded>
<pubDate>Tue, 16 Apr 2024 09:49:00 +0000</pubDate>
</item>
<item>
<title>Security Analysis of SFrame</title>
<link>https://eprint.iacr.org/2021/424</link>
<guid>https://eprint.iacr.org/2021/424</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私意识、端到端加密（E2EE）、SFrame、安全评估、伪造攻击

<br /><br />总结：
本文讨论了用于互联网视频/音频群组通信的端到端加密机制SFrame的安全性。尽管SFrame是一个相对较新的项目，但已被多个实际应用采纳部署。文章对SFrame原始规范进行了深入评估，发现其中存在可能导致恶意组成员以实际复杂度实施伪装（伪造）攻击的关键问题。进一步调查还显示，这些问题存在于几个公开可用的SFrame实现中。因此，文中提出了针对所有潜在攻击的应对措施以及从性能和安全性角度出发的实施方案考虑。 <div>
Increasing privacy consciousness has popularized the use of end-to-end encryption (E2EE). In this paper, we discuss the security of SFrame, an E2EE mechanism proposed to the Internet Engineering Task Force for video/audio group communications over the Internet. Despite being a quite recent project, SFrame has been deployed in several real-world applications. The original specification of SFrame is evaluated herein to find critical issues that can cause impersonation (forgery) attacks with a practical complexity by a malicious group member. Further investigations have revealed that these issues are present in several publicly available SFrame implementations. Therefore, we provide several countermeasures against all the proposed attacks and considerations from performance and security perspectives toward their implementation.
]]></content:encoded>
<pubDate>Tue, 06 Apr 2021 07:09:37 +0000</pubDate>
</item>
<item>
<title>Minimizing the Use of the Honest Majority in YOSO MPC with Guaranteed Output Delivery</title>
<link>https://eprint.iacr.org/2024/2059</link>
<guid>https://eprint.iacr.org/2024/2059</guid>
<content:encoded><![CDATA[
<div> 关键词: 多方计算、诚实多数、最小参与、一次性发言 (YOSO)、公共计算

总结:
本文探讨了多方计算(MPC)协议中诚实多数的必要性，并提出一种创新方案。该方案表明虽然诚实多数是必需的，但其参与度可以极小化。文中展示了一个具有保证输出交付的MPC协议，其中大部分执行由存在不诚实多数的委员会序列完成；而仅需一个拥有诚实多数的委员会，其成员的工作与电路大小无关，且每个参与者只需发言一次（即YOSO属性）。作为独立的研究模块，文章引入了“公共计算”概念，这是一种类似区块链上智能合约的隐私无关的、具有保证输出交付的多方计算。此外，文章还展示了在公共公告板上实现公共计算的三种不同方式，各自具有不同的假设、轮数和空间利用权衡。 <div>
Cleve (STOC 86) shows that an honest majority is necessary for MPC with guaranteed output delivery. In this paper, we show that while an honest majority is indeed necessary, its involvement can be minimal. We demonstrate an MPC protocol with guaranteed output delivery, the majority of which is executed by a sequence of committees with dishonest majority; we leverage $\textit{one}$ committee with an honest majority, each member of which does work independent of the circuit size. Our protocol has the desirable property that every participant speaks only once (YOSO, Crypto 2021).
As a building block of independent interest, we introduce \emph{public computation}, which is essentially privacy-free MPC with guaranteed output delivery (akin to smart contracts realized on blockchains). We instantiate public computation on a public bulletin board in three different ways (with different assumption / round / space utilization trade-offs).
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 21:19:05 +0000</pubDate>
</item>
<item>
<title>Leveraging remote attestation APIs for secure image sharing in messaging apps</title>
<link>https://eprint.iacr.org/2024/2057</link>
<guid>https://eprint.iacr.org/2024/2057</guid>
<content:encoded><![CDATA[
<div> 关键词: 敏感图片、隐私保护、即时通讯应用、远程认证、加密解密

总结:<br />
本文针对通过移动聊天应用程序分享的敏感图片（如护照照片和私密照片）的隐私保护问题，提出了一种基于多平台系统的解决方案。该系统在即时通讯应用之上对敏感图片进行加密和解密，并利用可用的应用程序完整性API进行远程认证以确保安全性。相比于以前提出的中间件中的图像加密方案，这种方法提供了增强的安全性、额外的隐私优势，简化了集成并提高了用户体验，因为它无需用户事先交换密钥材料。实验结果显示，发送和接收私人图片时平均分别增加了3.8秒和4.5秒的延迟。 <div>
Sensitive pictures such as passport photos and nudes are commonly shared through mobile chat applications. One popular strategy for the privacy protection of this material is to use ephemeral messaging features, such as the view once snaps in Snapchat. However, design limitations and implementation bugs in messaging apps may allow attackers to bypass the restrictions imposed by those features on the received material. One way by which attackers may accomplish so is by tampering with the software stack on their own devices. In this paper, we propose and test a protection strategy based on a multiplatform system that encrypts and decrypts sensitive pictures on top of messaging apps and performs remote attestation with available app integrity APIs to safeguard its security. Our analysis and experiments show that, compared to previous proposals for image encryption in a middleware, remote attestation offers increased security, adds privacy benefits, simplifies integration, and improves usability by not requiring users to exchange key material a priori. In our experiments, it incurs an added average latency of 3.8 and 4.5 seconds when sending and receiving private pictures, respectively.
]]></content:encoded>
<pubDate>Fri, 20 Dec 2024 17:11:28 +0000</pubDate>
</item>
<item>
<title>Simulation Secure Multi-Input Quadratic Functional Encryption: Applications to Differential Privacy</title>
<link>https://eprint.iacr.org/2024/2050</link>
<guid>https://eprint.iacr.org/2024/2050</guid>
<content:encoded><![CDATA[
<div> 关键词: 多输入功能性加密、秘密钥、二次功能性加密、模拟安全性、数据隐私保护

<br /><br />总结:
本文提出了首个满足模拟安全性的秘密钥多输入二次功能性加密方案。现有的二次功能支持构造仅达到基于不可区分性的安全性。文中构建了一个新的函数隐藏型内积功能性加密方案，该方案在标准模型下被证明对一个挑战密文具有模拟安全性，这本身具有独立的研究价值。利用这两个结果，作者构建了一个高效的随机化二次功能性加密方案，从而实现对支持二次查询的加密数据库进行不同ially 私有数据分析。最后，文章提供了所提随机化方案的完整实现与基准测试。这一工作是在SAC '24会议论文的基础上扩展的，首次提出了多输入二次功能性加密方案和函数隐藏型内积功能性加密方案。 <div>
Multi-input functional encryption is a primitive that allows for the evaluation of an $\ell$-ary function over multiple ciphertexts, without learning any information about the underlying plaintexts. This type of computation is useful in many cases where one has to compute over encrypted data, such as privacy-preserving cloud services, federated learning, or more generally delegation of computation from multiple clients. It has recently been shown by Alborch et al. in PETS '24 to be useful to construct a randomized functional encryption scheme for obtaining differentially private data analysis over an encrypted database supporting linear queries.

In this work we propose the first secret-key multi-input quadratic functional encryption scheme satisfying simulation security. Current constructions supporting quadratic functionalities, proposed by Agrawal et al. in CRYPTO '21 and TCC '22, only reach indistinguishibility-based security. Our proposed construction is generic, and for a concrete instantiation, we propose a new function-hiding inner-product functional encryption scheme proven simulation secure against one challenge ciphertext in the standard model, which is of independent interest. We then use these two results to construct an efficient randomized quadratic functional encryption scheme, from which we obtain differentially private data analysis over an encrypted database supporting quadratic queries. Finally, we give and fully benchmark an implementation of the randomized scheme. This work is an extended version of the paper "Simulation Secure Multi-Input Quadratic Functional Encryption" at SAC '24, where the multi-input quadratic functional encryption scheme and function-hiding inner-product functional encryption schemes were first presented (Section 3 and Seciton 4).
]]></content:encoded>
<pubDate>Thu, 19 Dec 2024 14:36:56 +0000</pubDate>
</item>
<item>
<title>Cryptographic Commitments on Anonymizable Data</title>
<link>https://eprint.iacr.org/2024/2044</link>
<guid>https://eprint.iacr.org/2024/2044</guid>
<content:encoded><![CDATA[
<div> 关键词: Local Differential Privacy (LDP), LDP commitment, cryptographic primitive, privacy, usability

<br /><br />总结:
本文提出了一种新的密码学原语——LDP承诺机制，该机制结合了局部差分隐私技术，使得数据拥有者可以在保护隐私的同时，将添加了可控噪声的数据公开。LDP承诺要求在揭示值之前需证明已正确应用了LDP机制，以确保数据仍可用于统计目的。文中还定义了该原语的安全模型以及隐藏性和绑定性这两个性质。接着，文章给出了一种基于经典密码学工具和标准假设的、适用于LDP阶梯机制的具体方案，并实现了Rust版本的高效代码（生成承诺只需几毫秒）。在应用场景中，该机制可同时保障医疗数据在开放科学背景下的隐私、可用性和可追溯性。具体场景为：一家医院在对敏感患者数据进行匿名处理并由医生签名后，将其提供给研究机构；研究机构可以验证数据来源（即验证医生签名），同时也能确认数据已被正确匿名处理（即数据虽被匿名但仍具有使用价值）。 <div>
Local Differential Privacy (LDP) mechanisms consist of (locally) adding controlled noise to data in order to protect the privacy of their owner. In this paper, we introduce a new cryptographic primitive called LDP commitment. Usually, a commitment ensures that the committed value cannot be modified before it is revealed. In the case of an LDP commitment, however, the value is revealed after being perturbed by an LDP mechanism. Opening an LDP commitment therefore requires a proof that the mechanism has been correctly applied to the value, to ensure that the value is still usable for statistical purposes. We also present a security model for this primitive, in which we define the hiding and binding properties. Finally, we present a concrete scheme for an LDP staircase mechanism (generalizing the randomized response technique), based on classical cryptographic tools and standard assumptions. We provide an implementation in Rust that demonstrates its practical efficiency (the generation of a commitment requires just a few milliseconds). On the application side, we show how our primitive can be used to ensure simultaneously privacy, usability and traceability of medical data when it is used for statistical studies in an open science context. We consider a scenario where a hospital provides sensitive patients data signed by doctors to a research center after it has been anonymized, so that the research center can verify both the provenance of the data (i.e. verify the doctors’ signatures even though the data has been noised) and that the data has been correctly anonymized (i.e. is usable even though it has been anonymized).
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 08:49:54 +0000</pubDate>
</item>
<item>
<title>Distributed Asynchronous Remote Key Generation</title>
<link>https://eprint.iacr.org/2024/846</link>
<guid>https://eprint.iacr.org/2024/846</guid>
<content:encoded><![CDATA[
<div> 关键词: 异步远程密钥生成(ARKG), 分布式ARVG(dARKG), 公开验证非对称密钥协议(1PVAKA), 双线性群, BLS12-381曲线

总结:<br />
本文提出了分布式异步远程密钥生成(dARKG)，它扩展了ARKG的安全属性至分布式环境。在dARKG中，发送者可以为一组n个接收者生成公钥$pk'$，对应的私钥$sk'$只能由其中任意大小为t≤n的子集共同计算，实现了基于阈值的访问保护。文章通过新提出的、一轮公开验证的非对称密钥协议(1PVAKA)来构建dARKG，该协议异步且允许第三方从用户输出验证并生成公钥。文章还讨论了针对双线性群的1PVAKA和dARKG的具体实现方案，并使用BLS12-381曲线进行了实现与性能分析，证明其实用性。 <div>
Asynchronous Remote Key Generation (ARKG) is a primitive introduced by Frymann et al. at ACM CCS 2020. It enables a sender to generate a new public key $pk'$ for a receiver ensuring only it can, at a later time, compute the corresponding private key $sk'$. These key pairs are indistinguishable from freshly generated ones and can be used in various public-key cryptosystems such as digital signatures and public-key encryption. ARKG has been explored for applications in WebAuthn credential backup and delegation, as well as for enhancing receiver privacy via stealth addresses.

In this paper, we introduce distributed ARKG (dARKG) aiming to provide similar security properties in a distributed setting. Here, a sender generates $pk'$ for a group of $n$ receivers and the corresponding $sk'$ can only be computed by any sub-group of size $t\leq n$. This introduces threshold-based access protection for $sk'$, enabling for instance a set of proxies to jointly access a WebAuthn account or claim blockchain funds.

We construct dARKG using one-round publicly verifiable asymmetric key agreement, called 1PVAKA, a new primitive formalized in this work. Unlike traditional distributed key generation protocols where users interact with one another, 1PVAKA is asynchronous and allows a third party to verify and generate a public key from users' outputs.

We discuss 1PVAKA and dARKG instantiations tailored for use with bilinear groups and demonstrate practicality with implementation and performance analysis for the BLS12-381 curve.
]]></content:encoded>
<pubDate>Wed, 29 May 2024 12:50:55 +0000</pubDate>
</item>
<item>
<title>Verified Foundations for Differential Privacy</title>
<link>https://eprint.iacr.org/2024/2040</link>
<guid>https://eprint.iacr.org/2024/2040</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私（DP）、SampCert、机械验证、Laplace采样、Gaussian采样

总结:
SampCert 是首个针对差分隐私的全面且机械化基础，它使用 Lean 编写了超过 12,000 行的证明代码。该框架提供了一个可针对不同DP定义（如纯DP、集中DP、Rényi DP）进行实例化的通用DP概念，以及用于构建和组合DP机制的框架。此外，SampCert还包含了经过形式化验证的离散Laplace和高斯采样算法，避免了浮点实现中的陷阱。其创新之处包括：(1) 支持多种DP定义的通用DP基础；(2) 正式验证的离散Laplace和Gaussian采样算法；(3) 简单的概率Monad及新颖的证明技术，简化了形式化过程。为了证明DP和随机数生成的复杂正确性属性，SampCert充分利用了Lean的广泛Mathlib库，利用傅里叶分析、测度与概率论、数论和拓扑等领域的定理。实际上，SampCert的经验证明算法已被应用于亚马逊网络服务(AWS)的DP产品中，显示出了其实际应用的影响。 <div>
Differential privacy (DP) has become the gold standard for privacy-preserving data analysis, but implementing
it correctly has proven challenging. Prior work has focused on verifying DP at a high level, assuming the
foundations are correct and a perfect source of randomness is available. However, the underlying theory of
differential privacy can be very complex and subtle. Flaws in basic mechanisms and random number generation
have been a critical source of vulnerabilities in real-world DP systems.

In this paper, we present SampCert, the first comprehensive, mechanized foundation for differential privacy.
SampCert is written in Lean with over 12,000 lines of proof. It offers a generic and extensible notion of DP, a
framework for constructing and composing DP mechanisms, and formally verified implementations of Laplace
and Gaussian sampling algorithms. SampCert provides (1) a mechanized foundation for developing the next
generation of differentially private algorithms, and (2) mechanically verified primitives that can be deployed in
production systems. Indeed, SampCert’s verified algorithms power the DP offerings of Amazon Web Services
(AWS), demonstrating its real-world impact.

SampCert’s key innovations include: (1) A generic DP foundation that can be instantiated for various DP
definitions (e.g., pure, concentrated, Rényi DP); (2) formally verified discrete Laplace and Gaussian sampling
algorithms that avoid the pitfalls of floating-point implementations; and (3) a simple probability monad and
novel proof techniques that streamline the formalization. To enable proving complex correctness properties of
DP and random number generation, SampCert makes heavy use of Lean’s extensive Mathlib library, leveraging
theorems in Fourier analysis, measure and probability theory, number theory, and topology.
]]></content:encoded>
<pubDate>Wed, 18 Dec 2024 02:45:39 +0000</pubDate>
</item>
<item>
<title>Multilateral Trade Credit Set-off in MPC via Graph Anonymization and Network Simplex</title>
<link>https://eprint.iacr.org/2024/2037</link>
<guid>https://eprint.iacr.org/2024/2037</guid>
<content:encoded><![CDATA[
<div> 关键词: 多边贸易信用对冲 (MTCS), 隐私保护, 最小成本流问题 (MCF), 图匿名化, 网络单纯形算法

总结:
本文提出了一种针对多边贸易信用对冲(MTCS)的协议，该协议旨在保护参与公司的敏感数据，如债务金额和交易伙伴身份。传统的方法，即安全最小成本流问题(MCF)，其通信复杂度为$O(n^{10}\log n)$，不适用于大规模实例。我们的解决方案利用了新颖的安全技术，包括图匿名化和网络单纯形算法，将MCF问题的复杂度降低到$O(max(n,\ log\log{n+m}))$轮交互每执行一次枢轴操作，并在此过程中执行$O(max(n^2,\ nm))$次比较和乘法运算。实验结果表明了隐私保护与最优解之间的权衡关系。 <div>
Multilateral Trade Credit Set-off (MTCS) is a process run by a service provider that collects trade credit data (i.e. obligations from a firm to pay another firm) from a network of firms and detects cycles of debts that can be removed from the system. The process yields liquidity savings for the participants, who can discharge their debts without relying on expensive loans. We propose an MTCS protocol that protects firms' sensitive data, such as the obligation amount or the identity of the firms they trade with. Mathematically, this is analogous to solving the Minimum Cost Flow (MCF) problem over a graph of $n$ firms, where the $m$ edges are the obligations. State-of-the-art techniques for Secure MCF have an overall complexity of $O(n^{10} \log n)$ communication rounds, making it barely applicable even to small-scale instances. Our solution leverages novel secure techniques such as Graph Anonymization and Network Simplex to reduce the complexity of the MCF problem to $O(max(n, \log\log{n+m}))$ rounds of interaction per pivot operations in which $O(max(n^2, nm))$ comparisons and multiplications are performed. Experimental results show the tradeoff between privacy and optimality.
]]></content:encoded>
<pubDate>Tue, 17 Dec 2024 15:59:02 +0000</pubDate>
</item>
<item>
<title>Janus: Fast Privacy-Preserving Data Provenance For TLS</title>
<link>https://eprint.iacr.org/2023/1377</link>
<guid>https://eprint.iacr.org/2023/1377</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据收集、隐私保护、TLS或acles、零知识证明、TLS 1.3

总结:
本文提出了一种新的隐私保护TLS预言机协议，该协议能够在大规模上选择性地验证敏感网络数据的来源。文章创新点在于采用诚实验证者零知识证明系统，在不对称隐私环境中确保安全性，同时对抗恶意对手。针对TLS 1.3，文章优化了“混淆后证明”的范式，在处理恶意敌手的安全设置中，展示了TLS 1.3的一种特殊操作模式，允许在混淆阶段的大多数计算中使用半诚实安全计算而不需认证混淆。通过这些性能改进，新方案达到了验证私人数据源的新效率水平，从而促进了隐私保护TLS预言机在web浏览器中的实际部署。<br /><br /> <div>
Web users can gather data from secure endpoints and demonstrate the provenance of sensitive data to any third party by using privacy-preserving TLS oracles. In practice, privacy-preserving TLS oracles remain limited and cannot selectively verify larger sensitive data sets. In this work, we introduce a new oracle protocol, which reaches new scales in selectively verifying the provenance of confidential web data. The novelty of our work is a construction which deploys an honest verifier zero-knowledge proof system in the asymmetric privacy setting while retaining security against malicious adversaries. Concerning TLS 1.3, we optimize the garble-then-prove paradigm in a security setting with malicious adversaries. Here, we show that a specific operation mode of TLS 1.3 allows to use semi-honest secure computations without authentic garbling for the majority of computations in the garble phase. Our performance improvements reach new efficiency scales in verifying private data provenance and facilitate the practical deployment of privacy-preserving TLS oracles in web browsers.
]]></content:encoded>
<pubDate>Thu, 14 Sep 2023 12:04:35 +0000</pubDate>
</item>
<item>
<title>Impact Tracing: Identifying the Culprit of  Misinformation in Encrypted Messaging Systems</title>
<link>https://eprint.iacr.org/2024/2027</link>
<guid>https://eprint.iacr.org/2024/2027</guid>
<content:encoded><![CDATA[
<div> 关键词：加密消息系统、内容审核、影响追踪、隐私保护、非影响力用户<br /><br />总结: 这篇文章主要探讨了加密消息系统中如何在保障用户隐私的同时有效抵制错误信息传播的问题。文章提出了“影响追踪”的新方法，旨在追踪对错误信息传播有重大影响的用户，同时为非影响力用户提供隐私保护。文中描述了一种添加噪声的技术手段来隐藏非影响力用户的身份，证明这种方法不会妨碍识别影响力传播者，并确保了非影响力用户的差分隐私保护。通过定义三个评估指标并在真实数据集上进行实验，结果显示该方案能以高达82%至99%的准确率识别最具影响力的传播者，而且每条消息仅需平台存储额外的6字节空间，同时保持低延迟（＜0.25毫秒）。 <div>
Encrypted messaging systems obstruct content moderation, although they provide end-to-end security. As a result, misinformation proliferates in these systems, thereby exacerbating online hate and harassment. The paradigm of ``Reporting-then-Tracing" shows great potential in mitigating the spread of misinformation. For instance, message traceback (CCS'19) traces all the dissemination paths of a message, while source tracing (CCS'21) traces its originator. However, message traceback lacks privacy preservation for non-influential users (e.g., users who only receive the message once), while source tracing maintains privacy but only provides limited traceability.

In this paper, we initiate the study of impact tracing. Intuitively, impact tracing traces influential spreaders central to disseminating misinformation while providing privacy protection for non-influential users. We introduce noises to hide non-influential users and demonstrate that these noises do not hinder the identification of influential spreaders. Then, we formally prove our scheme's security and show it achieves differential privacy protection for non-influential users. Additionally, we define three metrics to evaluate its traceability, correctness, and privacy using real-world datasets. The experimental results show that our scheme identifies the most influential spreaders with accuracy from 82% to 99% as the amount of noise varies. Meanwhile, our scheme requires only a 6-byte platform storage overhead for each message while maintaining a low messaging latency (< 0.25ms).
]]></content:encoded>
<pubDate>Sat, 14 Dec 2024 07:20:05 +0000</pubDate>
</item>
<item>
<title>Mira: Efficient Folding for Pairing-based Arguments</title>
<link>https://eprint.iacr.org/2024/2025</link>
<guid>https://eprint.iacr.org/2024/2025</guid>
<content:encoded><![CDATA[
<div> 关键词：pairing-based arguments、Groth16 SNARKs、KZG polynomial commitments、folding scheme、Mira

总结:
本文介绍了Mira，一种针对配对基础论证的新型折叠方案，旨在解决证明聚合的成本问题。现有的构造方法将配对操作编码到通用约束系统中，导致证明者开销较高。Mira通过扩展Protostar框架以支持更广泛的特殊声学协议类来实现这一目标。应用示例表明，Mira在Groth16证明聚合和可验证机器学习推理方面展现出高效性和灵活性，其相比于现有最先进的证明聚合系统实现了5.8倍的更快prove时间以及9.7倍的更低内存使用量，同时保持了常数大小的证明。此外，为了提高可验证机器学习推理的效率，文章还提出了一种新的lincheck协议，其验证器度独立于矩阵顺序，使得Mira能够有效地扩展到更大的模型，克服了当前方案中的内存瓶颈。 <div>
Pairing-based arguments offer remarkably small proofs and space-efficient provers, but aggregating such proofs remains costly. Groth16 SNARKs and KZG polynomial commitments are prominent examples of this class of arguments. These arguments are widely deployed in decentralized systems, with millions of proofs generated per day. Recent folding schemes have greatly reduced the cost of proving incremental computations, such as batch proof verification. However, existing constructions require encoding pairing operations in generic constraint systems, leading to high prover overhead. In this work, we introduce Mira, a folding scheme that directly supports pairing-based arguments. We construct this folding scheme by generalizing the framework in Protostar to support a broader class of special-sound protocols. We demonstrate the versatility and efficiency of this framework through two key applications: Groth16 proof aggregation and verifiable ML inference. Mira achieves 5.8x faster prover time and 9.7x lower memory usage than the state-of-the-art proof aggregation system while maintaining a constant-size proof. To improve the efficiency of verifiable ML inference, we provide a new lincheck protocol with a verifier degree that is independent of the matrix order. We show that Mira scales effectively to larger models, overcoming the memory bottlenecks of current schemes.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 21:58:09 +0000</pubDate>
</item>
<item>
<title>Derecho: Privacy Pools with Proof-Carrying Disclosures</title>
<link>https://eprint.iacr.org/2023/273</link>
<guid>https://eprint.iacr.org/2023/273</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私池、Tornado Cash、美国财政部、Derecho、证明携带数据

总结:<br />
本文介绍了隐私池的概念及其可能被用于隐藏资金来源的问题，特别是在美国财政部制裁了最大的以太坊隐私池Tornado Cash之后，该池被指控为朝鲜支持的Lazarus集团洗钱超过4.55亿美元。这一裁决使得美国个人和机构接收或使用经过Tornado Cash的资金成为非法行为。针对此背景，文章提出了名为Derecho的新系统。Derecho利用证明携带数据技术，使用户能够在隐私池的交易图中传播允许列表成员资格的证明，从而让机构可以请求基金来源的加密证明而非简单地拒绝来自隐私池的所有资金。Derecho系统与现有的以太坊隐私池设计向后兼容，不会增加gas成本，并且用户生成证明仅需花费几秒钟时间。 <div>
A privacy pool enables clients to deposit units of a cryptocurrency into a shared pool where ownership of deposited currency is tracked via a system of cryptographically hidden records. Clients may later withdraw from the pool without linkage to previous deposits. Some privacy pools also support hidden transfer of currency ownership within the pool. In August 2022, the U.S. Department of Treasury sanctioned Tornado Cash, the largest Ethereum privacy pool, on the premise that it enables illicit actors to hide the origin of funds, citing its usage by the DPRK-sponsored Lazarus Group to launder over \$455 million dollars worth of stolen cryptocurrency. This ruling effectively made it illegal for U.S. persons/institutions to use or accept funds that went through Tornado Cash, sparking a global debate among privacy rights activists and lawmakers. Against this backdrop, we present Derecho, a system that institutions could use to request cryptographic attestations of fund origins rather than naively rejecting all funds coming from privacy pools. Derecho is a novel application of proof-carrying data, which allows users to propagate allowlist membership proofs through a privacy pool's transaction graph. Derecho is backwards-compatible with existing Ethereum privacy pool designs, adds no overhead in gas costs, and costs users only a few seconds to produce attestations.
]]></content:encoded>
<pubDate>Thu, 23 Feb 2023 20:59:36 +0000</pubDate>
</item>
<item>
<title>Hash-Prune-Invert: Improved Differentially Private Heavy-Hitter Detection in the Two-Server Model</title>
<link>https://eprint.iacr.org/2024/2024</link>
<guid>https://eprint.iacr.org/2024/2024</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私(DP)，重 hitter 检测，错误边际(Δ)，服务器协同计算，hash-prune-invert (HPI)

总结:
文章介绍了一种针对大规模数据域(d)下的差分隐私重 hitter 检测新方法——hash-prune-invert (HPI) 技术。现有的多服务器协同计算协议在效率（计算、通信和轮复杂度）与准确性（即错误边际）上对 log(d) 有依赖性，不适合处理大型数据域。而 HPI 技术可以将具有上述问题的重 hitter 协议转化为一个新的协议，使得计算、通信和轮复杂度大致依赖于 log(n) 而非 log(d)，并且错误边际不再依赖于数据域大小 d。此外，该转换还保持了在最多一个服务器被恶意攻击者篡改以及任意数量客户端的情况下，依然能保证隐私安全。文中还将 HPI 应用于改进版的 Poplar 算法，使 Poplar 的错误边际提高了大约 n 的平方根倍（与 d 无关）。实验结果显示，由此产生的新协议在大 d 情况下显著提升了效率和准确性。 <div>
Differentially private (DP) heavy-hitter detection is an important primitive for  data analysis. Given a threshold $t$ and a dataset of $n$ items from a domain of size $d$, such detection algorithms ignore items occurring fewer than $t$ times while identifying items occurring more than $t+\Delta$ times; we call $\Delta$ the error margin. In the central model where a curator holds the entire dataset, $(\varepsilon,\delta)$-DP algorithms can achieve error margin $\Theta(\frac 1 \varepsilon \log \frac 1 \delta)$, which is optimal when $d \gg 1/\delta$.
    
    Several works, e.g., Poplar (S&amp;P 2021), have proposed protocols in which two or more non-colluding servers jointly compute the heavy hitters from inputs held by $n$ clients. Unfortunately, existing protocols suffer from an undesirable dependence on $\log d$ in terms of both server efficiency (computation, communication, and round complexity) and accuracy (i.e., error margin), making them unsuitable for large domains (e.g., when items are kB-long strings, $\log d \approx 10^4$).
    
    We present hash-prune-invert (HPI), a technique for compiling any heavy-hitter protocol with the $\log d$ dependencies mentioned above into a new protocol with improvements across the board: computation, communication, and round complexity depend (roughly) on $\log n$ rather than $\log d$, and the error margin is independent of $d$. Our transformation preserves privacy against an active adversary corrupting at most one of the servers and any number of clients. We apply HPI to an improved version of Poplar, also introduced in this work, that improves Poplar's error margin by roughly a factor of $\sqrt{n}$ (regardless of $d$). Our experiments confirm that the resulting protocol improves efficiency and accuracy for large $d$.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 20:56:38 +0000</pubDate>
</item>
<item>
<title>PrivQuant: Communication-Efficient Private Inference with Quantized Network/Protocol Co-Optimization</title>
<link>https://eprint.iacr.org/2024/2021</link>
<guid>https://eprint.iacr.org/2024/2021</guid>
<content:encoded><![CDATA[
<div> 关键词: 私有深度神经网络、安全两方计算、通信效率、 PrivQuant、协议优化

总结:

 PrivQuant是一个针对私有深度神经网络(DNN)推理的安全两方计算(2PC)框架，旨在提升隐私保护的同时降低高延迟问题。该框架通过同时优化基于2PC的量化推理协议和网络量化算法，实现更高效的通信私密推断。具体来说，PrivQuant针对通信密集型量化运算符提出了DNN架构感知的优化方案，并进行了图级操作器融合以减少通信量。此外，它还开发了一种通信感知的混合精度量化算法，旨在提高推断效率并保持高准确性。通过网络/协议协同优化，PrivQuant相比于现有2PC框架如SiRNN、COINN和CoPriv，显著降低了通信量（分别减少了11倍、2.5倍和2.8倍），进而将延迟减少了8.7倍、1.8倍和2.4倍。 <div>
Private deep neural network (DNN) inference based on secure two-party computation (2PC) enables secure privacy protection for both the server and the client. However, existing secure 2PC frameworks suffer from a high inference latency due to enormous communication. As the communication of both linear and non-linear DNN layers reduces with the bit widths of weight and activation, in this paper, we propose PrivQuant, a framework that jointly optimizes the 2PC-based quantized inference protocols and the network quantization algorithm, enabling communication-efficient private inference. PrivQuant proposes DNN architecture-aware optimizations for the 2PC protocols for communication-intensive quantized operators and conducts graph-level operator fusion for communication reduction. Moreover, PrivQuant also develops a communication-aware mixed precision quantization algorithm to improve the inference efficiency while maintaining high accuracy. The network/protocol co-optimization enables PrivQuant to outperform prior-art 2PC frameworks. With extensive experiments, we demonstrate PrivQuant reduces communication by $11\times, 2.5\times \mathrm{and}~  2.8\times$, which results in $8.7\times, 1.8\times ~ \mathrm{and}~ 2.4\times$ latency reduction compared with SiRNN, COINN, and CoPriv, respectively.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 13:51:36 +0000</pubDate>
</item>
<item>
<title>On the BUFF Security of ECDSA with Key Recovery</title>
<link>https://eprint.iacr.org/2024/2018</link>
<guid>https://eprint.iacr.org/2024/2018</guid>
<content:encoded><![CDATA[
<div> 关键词: ECDSA，key recovery，BUFF安全，弱非重签性，Ethereum地址

总结:
本文探讨了使用密钥恢复的椭圆曲线数字签名算法（KR-ECDSA）的安全性，特别是在Ethereum环境下的Beyond UnForgeability Features（BUFF）安全。研究结果显示，KR-ECDSA提供了BUFF安全性，但存在弱非重签性（wNR）问题。文中指出，KR-ECDSA验证算法需要输入以太坊地址addr，该地址由对应的ECDSA验证密钥通过Keccak-256哈希计算得到的右起160位组成，并检查恢复的验证密钥的哈希值是否等于addr，这是保证BUFF安全性的必要条件。此外，文章分析表明原始ECDSA不提供任何BUFF安全性，并揭示了一个针对Aumayr等人提出的基于ECDSA的适配器签名方案的攻击，此攻击超出了其安全模型范围。 <div>
In the usual syntax of digital signatures, the verification algorithm takes a verification key in addition to a signature and a message, whereas in ECDSA with key recovery, which is used in Ethereum,  no verification key is input to the verification algorithm. Instead, a verification key is recovered from a signature and a message. In this paper, we explore BUFF security of ECDSA with key recovery (KR-ECDSA), where BUFF stands for Beyond UnForgeability Features (Cremers et al., IEEE S&amp;P 2021).  As a result, we show that KR-ECDSA provides BUFF security, except weak non-resignability (wNR). We pay attention to that the verification algorithm of KR-ECDSA takes an Ethereum address addr as input, which is defined as the rightmost 160-bits of the Keccak-256 hash of the corresponding ECDSA verification key, and checks the hash value of the recovered verification key is equal to addr.  Our security analysis shows that this procedure is mandatory to provide BUFF security. We also discuss whether wNR is mandatory in Ethereum or not.  To clarify the above equality check is mandatory to provide BUFF security in KR-ECDSA, we show that the original ECDSA does not provide any BUFF security. As a by-product of the analysis, we show that one of our BUFF attacks also works against the Aumayr et al.'s ECDSA-based adaptor signature scheme (ASIACRYPT 2021). We emphasize that the attack is positioned outside of their security model.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 05:56:52 +0000</pubDate>
</item>
<item>
<title>Byzantine Consensus in Wireless Networks</title>
<link>https://eprint.iacr.org/2024/2017</link>
<guid>https://eprint.iacr.org/2024/2017</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine共识协议、无线网络、分布式系统、可靠广播协议、部分同步

总结:
本文提出了一种新的可靠广播协议，该协议在故障容忍度方面超过了当前最先进的技术(PODC '05)。在此基础上，文章进一步开发了首个适用于无线网络的部分同步环境下的拜占庭共识协议。这个新的共识协议不再需要领导者和故障转移机制。作者对新提出的广播协议和共识协议的正确性进行了正式证明。这表明，在无线网络中实现高容错性的共识同样重要，并为该领域的研究带来了创新突破。 <div>
A Byzantine consensus protocol is essential in decentralized systems as the protocol ensures system consistency despite node failures.
Research on consensus in wireless networks receives relatively less attention, while significant advancements in wired networks.
However, consensus in wireless networks has equal significance as in wired networks.

In this paper, we propose a new reliable broadcast protocol that can achieve reliability with high fault tolerance over than the SOTA (PODC '05). With the new protocol, we further develop the first wireless network Byzantine consensus protocol under the assumption of partial synchrony. Notably, this consensus protocol removes the requirement of leaders and fail-over mechanism in prior works. We formally prove the correctness of both our new broadcast protocol and consensus protocol.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 04:46:33 +0000</pubDate>
</item>
<item>
<title>Crescent: Stronger Privacy for Existing Credentials</title>
<link>https://eprint.iacr.org/2024/2013</link>
<guid>https://eprint.iacr.org/2024/2013</guid>
<content:encoded><![CDATA[
<div> 关键词: Crescent、隐私保护凭证、零知识证明、选择性披露、unlinkability

总结:
Crescent是一个旨在提升现有凭证（如JSON Web Tokens (JWTs)和Mobile Driver's License (mDL)）隐私特性的系统实现。该系统无需新的发证方即可通过使用零知识证明技术来实现凭证的选择性披露和不可链接性等功能。Crescent具备实际应用性能，能在一次性的凭证设置阶段后提供快速的证明生成和验证时间（数十毫秒）。文中展示了两个实用场景的演示：基于雇主颁发JWT的福利资格证明以及基于mDL的在线年龄验证。此外，他们提供了开源实现以促进进一步的研究与实验，相关代码库可在https://github.com/microsoft/crescent-credentials找到。 <div>
We describe Crescent, a construction and implementation of privacy-preserving credentials. The system works by upgrading the privacy features of existing credentials, such as JSON Web Tokens (JWTs) and Mobile Driver’s License (mDL) and as such does not require a new party to issue credentials. By using zero-knowledge proofs of possession of these credentials, we can add privacy features such as selective disclosure and unlinkability, without help from credential issuers. The system has practical performance, offering fast proof generation and verification times (tens of milliseconds) after a once-per-credential setup phase. We give demos for two practical scenarios, proof of employment for benefits eligibility (based on an employer-issued JWT), and online age verification (based on an mDL). We provide an open-source implementation to enable further research and experimentation.

This paper is an early draft describing our work, aiming to include enough material to describe the functionality, and some details of the internals of our new library, available at https://github.com/microsoft/crescent-credentials.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 01:42:20 +0000</pubDate>
</item>
<item>
<title>GraSS: Graph-based Similarity Search on Encrypted Query</title>
<link>https://eprint.iacr.org/2024/2012</link>
<guid>https://eprint.iacr.org/2024/2012</guid>
<content:encoded><![CDATA[
<div> 关键词：相似性搜索、图基方法、全同态加密（FHE）、客户端隐私、服务器隐私

总结:
我们提出了一种名为GraSS的安全协议，用于基于全同态加密（FHE）实现客户端（查询拥有者）和服务器端（数据集拥有者）之间的图基相似性搜索。该协议能够在基于FHE的安全假设下保证客户端输入对服务器的隐私以及服务器输入对客户端的隐私。为了提高可扩展性和降低计算复杂度，我们设计了一个对FHE友好的图结构及新颖的索引编码方法，将邻域检索过程的时间复杂度从$O(n^2)$降低到$\tilde{O}(n)$，其中n为总节点数。同时，我们还提出了几项核心的FHE算法，用于在新的图结构下执行图操作。最后，我们实现了完整的GraSS解决方案，这是首个基于FHE的安全图基数据库搜索方案。经过实测，GraSS在百万规模的数据集上可以在约83小时内找到近似的前16名结果，准确率达到0.918，比此前已知的最佳FHE方案快了超过28倍。 <div>
Similarity search, i.e., retrieving vectors in a database that are similar to a query, is the backbone of many applications. Especially, graph-based methods show state-of-the-art performance. For sensitive applications, it is critical to ensure the privacy of the query and the dataset.

In this work, we introduce GraSS, a secure protocol between client (query owner) and server (dataset owner) for graph-based similarity search based on fully homomorphic encryption (FHE).  Both the client-input privacy against the server and the server-input privacy against the client are achievable based on underlying security assumptions on FHE.

We first propose an FHE-friendly graph structure with a novel index encoding method that makes our protocol highly scalable in terms of data size, reducing the computational complexity of neighborhood retrieval process from $O(n^2)$ to $\tilde{O}(n)$ for the total number of nodes $n$. We also propose several core FHE algorithms to perform graph operations under the new graph structure. Finally, we introduce GraSS, an end-to-end solution of secure graph-based similarity search based on FHE. To the best of our knowledge, it is the first FHE-based solution for secure graph-based database search.

We implemented GraSS with an open-source FHE library and estimated the performance on a million-scale dataset. GraSS identifies (approximate) top-16 in about $83$ hours achieving search accuracy of $0.918$, making it over $28\times$ faster than the previous best-known FHE-based solution.
]]></content:encoded>
<pubDate>Fri, 13 Dec 2024 00:11:45 +0000</pubDate>
</item>
<item>
<title>Anonymous credentials from ECDSA</title>
<link>https://eprint.iacr.org/2024/2010</link>
<guid>https://eprint.iacr.org/2024/2010</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名数字凭证、大规模部署、BBS+、ECDSA、零知识证明

总结:<br />
本文提出了一种新的匿名数字凭证方案，该方案针对广泛应用且具有大量历史部署的椭圆曲线数字签名算法（ECDSA）进行设计。此方案无需改变身份发行者的现有流程，不需对移动设备进行硬件安全元素和操作系统的更新，也不依赖非标准的密码学假设，从而解决了大规模部署匿名凭证体系面临的困难。为了实现这一目标，文章通过采用基于sumcheck和Ligero论证系统的零知识证明方法，设计了适用于ECDSA所需的有限域上的高效Reed-Solomon编码方法以及专门的电路。生成ECDSA的零知识证明只需60毫秒，在结合ISO标准化的身份协议如MDOC标准后，可在移动设备上根据凭证大小在1.2秒内生成MDOC展示流程的零知识证明。因此，该方案被认为是隐私保护型数字身份应用的一个有前景的候选方案。 <div>
Anonymous digital credentials allow a user to prove possession of an attribute that has been asserted by an identity issuer without revealing any extra information about themselves.  For example, a user who has received a digital passport credential can prove their “age is $>18$” without revealing any other attributes such as their name or date of birth.

    Despite inherent value for privacy-preserving authentication, anonymous credential schemes have been difficult to deploy at scale.  Part of the difficulty arises because schemes in the literature, such as BBS+, use new cryptographic assumptions that require system-wide changes to existing issuer infrastructure.  In addition,  issuers often require digital identity credentials to be *device-bound* by incorporating the device’s secure element into the presentation flow.  As a result, schemes like BBS+ require updates to the hardware secure elements and OS on every user's device.
    
    In this paper, we propose a new anonymous credential scheme for the popular and legacy-deployed Elliptic Curve Digital Signature Algorithm (ECDSA) signature scheme.  By adding efficient zk arguments for statements about SHA256 and document parsing for ISO-standardized identity formats, our anonymous credential scheme is that first one that can be deployed *without* changing any issuer processes, *without* requiring changes to mobile devices, and *without* requiring non-standard cryptographic assumptions.

    Producing ZK proofs about ECDSA signatures has been a bottleneck for other ZK proof systems because standardized curves such as P256 use finite fields which do not support efficient number theoretic transforms.  We overcome this bottleneck by designing a ZK proof system around sumcheck and the Ligero argument system, by designing efficient methods for Reed-Solomon encoding over the required fields, and by designing specialized circuits for ECDSA.
        
    Our proofs for ECDSA can be generated in 60ms.  When incorporated into a fully standardized identity protocol such as the ISO MDOC standard, we can generate a zero-knowledge proof for the MDOC presentation flow in 1.2 seconds on mobile devices depending on the credential size. These advantages make our scheme a promising candidate for privacy-preserving digital identity applications.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 18:49:06 +0000</pubDate>
</item>
<item>
<title>PrivCirNet: Efficient Private Inference via Block Circulant Transformation</title>
<link>https://eprint.iacr.org/2024/2008</link>
<guid>https://eprint.iacr.org/2024/2008</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption (HE), Deep Neural Network (DNN), Circulant Matrices, PrivCirNet, Computation Overhead

总结:
本文提出了一种名为PrivCirNet的新框架，该框架基于块循环变换对同态加密（HE）下的深度神经网络（DNN）推理进行了协议与网络的联合优化。通过将DNN权重转化为循环矩阵，可以将一般的矩阵向量乘法转换为HE友好的一维卷积，显著降低了HE计算成本。在协议层面，PrivCirNet定制了与块循环变换完全兼容的HE编码算法，能够按块大小比例减少计算延迟。在网络层面，文章提出了一个基于二阶信息的延迟感知公式来搜索各层的块大小分配，并利用层融合进一步降低推理成本。实验结果表明，相比于最先进的HE基框架Bolt和HE友好剪枝方法SpENCNN，PrivCirNet在ResNet-18和Vision Transformer (ViT)在Tiny ImageNet上的推理延迟分别减少了5.0倍和1.3倍，同时保持了相同的精度水平，并在准确性上分别提升了4.1%和12%。对于MobileNetV2在ImageNet上的任务，PrivCirNet实现了比Bolt和SpENCNN低1.7倍的延迟以及更高的4.2%准确率。项目代码和检查点已在https://github.com/Tianshi-Xu/PrivCirNet开源。 <div>
Homomorphic encryption (HE)-based deep neural network (DNN) inference protects data and model privacy but suffers from significant computation overhead. We observe transforming the DNN weights into circulant matrices converts general matrix-vector multiplications into HE-friendly 1-dimensional convolutions, drastically reducing the HE computation cost. Hence, in this paper, we propose PrivCirNet, a protocol/network co-optimization framework based on block circulant transformation. At the protocol level, PrivCirNet customizes the HE encoding algorithm that is fully compatible with the block circulant transformation and reduces the computation latency in proportion to the block size. At the network level, we propose a latency-aware formulation to search for the layer-wise block size assignment based on second-order information. PrivCirNet also leverages layer fusion to further reduce the inference cost. We compare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S&amp;P 2024) and HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and Vision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by $5.0\times$ and $1.3\times$ with iso-accuracy over Bolt, respectively, and improves accuracy by $4.1\%$ and $12\%$ over SpENCNN, respectively. For MobileNetV2 on ImageNet, PrivCirNet achieves $1.7\times$ lower latency and $4.2\%$ better accuracy over Bolt and SpENCNN, respectively. 
    Our code and checkpoints are available at https://github.com/Tianshi-Xu/PrivCirNet.
]]></content:encoded>
<pubDate>Thu, 12 Dec 2024 14:46:10 +0000</pubDate>
</item>
<item>
<title>Xiezhi: Toward Succinct Proofs of Solvency</title>
<link>https://eprint.iacr.org/2024/2001</link>
<guid>https://eprint.iacr.org/2024/2001</guid>
<content:encoded><![CDATA[
<div> 关键词: 证明清偿能力、零知识证明、中心化加密货币交易所、验证时间、bls12-381

总结:
本文提出了改进中心化加密货币交易所的证明清偿能力方案，旨在提供一种快速（几分钟）、体积小（KB级）和验证快捷（几秒钟）的全程端到端论证。文章关注的重点包括：一是提出并实现这样一个优化的证明系统；二是针对比特币与以太坊不同的密码学环境（如secp256k1曲线与更为理想的简洁性设置，如配对密码学），采用了一种新颖的映射方法来处理两者间的自然冲突；三是讨论了如何将该协议适应于具体参数为bls12-381的情况，因为对于规模稍大的交易所，所有用户余额的位分解将会超过该曲线的最大单位根。 <div>
A proof of solvency (or proof of reserves) is a zero-knowledge proof conducted by centralized cryptocurrency exchange to offer evidence that the exchange owns enough cryptocurrency to settle each of its users' balances. The proof seeks to reveal nothing about the finances of the exchange or its users, only the fact that it is solvent. The literature has already started to explore how to make proof size and verifier time independent of the number of (i) users on the exchange, and (ii) addresses used by the exchange. We argue there are a few areas of improvement. First, we propose and implement a full end-to-end argument that is fast for the exchange to prove (minutes), small in size (KBs), and fast to verify (seconds). Second, we deal with the natural conflict between Bitcoin and Ethereum's cryptographic setting (secp256k1) and more ideal settings for succinctness (e.g., pairing-based cryptography) with a novel mapping approach. Finally, we discuss how to adapt the protocol to the concrete parameters of bls12-381 (which is relevant because the bit-decomposition of all user balances will exceed the largest root of unity of the curve for even moderately-sized exchanges).
]]></content:encoded>
<pubDate>Wed, 11 Dec 2024 21:55:31 +0000</pubDate>
</item>
<item>
<title>BitVM: Quasi-Turing Complete Computation on Bitcoin</title>
<link>https://eprint.iacr.org/2024/1995</link>
<guid>https://eprint.iacr.org/2024/1995</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、比特币脚本、计算能力、虚拟机、BitVM

总结:
本文针对区块链社区长期存在的一个问题进行了研究，即在具有有限脚本语言（如比特币脚本）的加密货币中，哪些类型的计算能够得到有效表达。文章首次证明了无需修改现有语言或依赖额外安全假设（例如可信硬件、可信方或安全多数委员会），任意计算可以在今天的比特币脚本中被编码。为此，提出了$\mathsf{BitVM}$，这是一个结合了密码学和激励机制的两方协议，实现了一个通用虚拟机。对$\mathsf{BitVM}$进行了形式化分析，明确了其功能、系统假设及安全性属性。同时，文章还展示了该方法的实用性：在乐观情况下，只需三次链上交易即可完成协议执行；而在悲观情况下，交易数量随着虚拟机规模的增长呈对数级增加。这项工作不仅解决了长期以来的理论问题，而且还对实践产生了强烈影响，为在比特币中开发复杂应用开辟了新的可能。 <div>
A long-standing question in the blockchain community is which class of computations are efficiently expressible in cryptocurrencies with limited scripting languages, such as Bitcoin Script. Such languages expose a reduced trusted computing base, thereby being less prone to hacks and vulnerabilities, but have long been believed to support only limited classes of payments.

In this work, we confute this long-standing belief by showing for the first time that arbitrary computations can be encoded in today's Bitcoin Script, without introducing any language modification or additional security assumptions, such as trusted hardware, trusted parties, or committees with secure majority. In particular, we present $\mathsf{BitVM}$, a two-party protocol realizing a generic virtual machine by a combination of cryptographic and incentive mechanisms. We conduct a formal analysis of $\mathsf{BitVM}$, characterizing its functionality, system assumptions, and security properties. We further demonstrate the practicality of our approach:  in the optimistic case (i.e., in the absence of disputes between parties), our protocol requires just three on-chain transactions, whereas in the pessimistic case, the number of transactions grows logarithmically with the size of the virtual machine.  This work not only solves a long-standing theoretical problem, but it also promises a strong practical impact, enabling the development of complex applications in Bitcoin.
]]></content:encoded>
<pubDate>Tue, 10 Dec 2024 21:56:17 +0000</pubDate>
</item>
<item>
<title>UTRA: Universe Token Reusability Attack and Verifiable Delegatable Order-Revealing Encryption</title>
<link>https://eprint.iacr.org/2024/1983</link>
<guid>https://eprint.iacr.org/2024/1983</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据集增长、隐私保护、加密数据、委托可揭示加密、安全可揭示加密

总结:
随着数据集的增长，用户在本地机器上处理任务面临困难，同时对数据泄漏的隐私关注导致数据拥有者将加密数据上传至云端并使用安全范围查询。为了解决这些问题，出现了针对大量数值数据的可揭示排序加密（ORE），并在多客户端环境中进一步发展出了委托可揭示加密（DORE）。然而，存在安全风险，即未经授权的用户可能利用授权令牌进行未授权的数据操作。因此，提出了安全可揭示加密方案（SEDORE）和高效的委托可揭示加密（EDORE）。尽管SEDORE和EDORE旨在抵御这类攻击，但我们发现它们仍存在相同威胁模型下的漏洞。为此，我们提出了验证性委托可揭示加密（VDORE），通过使用Schnorr签名方案验证用户发送的令牌的有效性，以防止此类攻击。此外，VDORE的令牌生成算法相比SEDORE提供了大约1.5倍的速度提升。 <div>
As dataset sizes continue to grow, users face increasing difficulties in performing processing tasks on their local machines. From this, privacy concerns about data leakage have led data owners to upload encrypted data and utilize secure range queries to cloud servers. 
To address these challenges, order-revealing encryption (ORE) has emerged as a promising solution for large numerical datasets. Building on this, delegatable order-revealing encryption (DORE) was introduced, allowing operations between encrypted datasets with different secret keys in multi-client ORE environments. DORE operates through authorization tokens issued by the data owner. However, security concerns had arisen about unauthorized users exploiting data without permission, leading to the development of a secure order-revealing encryption scheme (SEDORE). These attacks can result in unauthorized data access and significant financial losses in modern cloud service providers (CSPs) utilizing pay-per-query systems. In addition, efficient delegatable order-revealing encryption (EDORE), which improves speed and storage compared to SEDORE with identical security levels, was also introduced.
Although both SEDORE and EDORE were designed to be robust against these attacks, we have identified that they still retain the same vulnerabilities within the same threat model. To address these issues, we propose Verifiable Delegatable Order-Revealing Encryption (VDORE), which protects against attacks by using the Schnorr Signature Scheme to verify the validity of the token that users send. We propose a precise definition and robust proof to improve the unclear definition and insufficient proof regarding token unforgeability in the SEDORE.
Furthermore, the token generation algorithm in VDORE provides about a $1.5\times$ speed-up compared to SEDORE.
]]></content:encoded>
<pubDate>Sun, 08 Dec 2024 01:46:18 +0000</pubDate>
</item>
<item>
<title>Shutter Network: Private Transactions from Threshold Cryptography</title>
<link>https://eprint.iacr.org/2024/1981</link>
<guid>https://eprint.iacr.org/2024/1981</guid>
<content:encoded><![CDATA[
<div> 关键词: DeFi, 交易重排序攻击, 前序交易/夹心交易, MEV, Shutter网络<br /><br />总结:
随着DeFi的发展，基于交易重排序的攻击成为公共区块链面临的重要问题，如前序交易或夹心交易，攻击者通过操纵交易顺序影响金融资产市场价格，这种价值在以太坊生态系统中被称为矿工/最大可提取价值(MEV)，目前估计已超过13亿美元。为抵御MEV，一种有前景的方法是隐藏交易数据，使区块提议者无法根据交易内容选择执行顺序。本文描述了Shutter网络所采用的加密协议，该网络自2021年底以来已成为开源项目，并自2022年10月起投入生产运行。 <div>
With the emergence of DeFi, attacks based on re-ordering transactions have become an essential problem for public blockchains. Such attacks include front-running or sandwiching transactions, where the adversary places transactions at a particular place within a block to influence a financial asset’s market price. In the Ethereum space, the value extracted by such attacks is often referred to as miner/maximal extractable value (MEV), which to date is estimated to have reached a value of more than USD 1.3B. A promising approach to protect against MEV is to hide the transaction data so block proposers cannot choose the order in which transactions are executed based on the transactions’ content. This paper describes the cryptographic protocol underlying the Shutter network. Shutter has been available as an open-source project since the end of 2021 and has been running in production since Oct. 2022.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 21:34:08 +0000</pubDate>
</item>
<item>
<title>HI-CKKS: Is High-Throughput Neglected? Reimagining CKKS Efficiency with Parallelism</title>
<link>https://eprint.iacr.org/2024/1976</link>
<guid>https://eprint.iacr.org/2024/1976</guid>
<content:encoded><![CDATA[
<div> 关键词: 数据外包, 云服务, 隐私保护, CKKS, Homomorphic加密, 性能优化, HI-CKKS, 吞吐量, 异步执行, (I)NTT 原语, 高性能实现, 数学模块指令集, 内存优化, 并行同态乘法

总结:<br />
随着数据外包和云服务的普及，隐私问题日益凸显。CKKS作为一种重要的全同态加密方案，可以在加密数据上进行计算，为隐私保护提供了关键保障。然而，其性能瓶颈限制了广泛应用。本文提出了HI-CKKS，一种面向吞吐量优化、高性能实现的CKKS全同态加密方案。HI-CKKS通过引入支持批处理的异步执行策略，有效缓解了主机与服务器间频繁的数据交互及等待延迟问题。同时，针对CKKS中的核心(I)NTT原语，开发了一种层次化、混合型高吞吐量实现方法，包括高效的算术模块指令集、统一内核融合以及混合内存优化策略。此外，还提出了一种多维度并行同态乘法方案，旨在最大化吞吐量并提升(I)NTT和同态乘法的性能。实验结果表明，HI-CKKS在RTX 4090显卡上实现了显著的吞吐量性能提升，与CPU实现相比，NTT、INTT和HMult的吞吐量分别提高了$175.08\times$、$191.27\times$和$679.57\times$；相较于最新的GPU基线工作，其吞吐量性能仍然表现出显著优势，提升幅度从$1.54\times$到$693.17\times$不等。 <div>
The proliferation of data outsourcing and cloud services has heightened privacy vulnerabilities. CKKS, among the most prominent homomorphic encryption schemes, allows computations on encrypted data, serving as a critical privacy safeguard. However, performance remains a central bottleneck, hindering widespread adoption. Existing optimization efforts often prioritize latency reduction over throughput performance. This paper presents HI-CKKS, a throughput-oriented High-performance Implementation of CKKS homomorphic encryption, addressing these challenges. Our HI-CKKS introduces a batch-supporting asynchronous execution scheme, effectively mitigating frequent data interactions and high waiting delays between hosts and servers in service-oriented scenarios. We analyze the fundamental (I)NTT primitive, which is critical in CKKS, and develop a hierarchical, hybrid high-throughput implementation. This includes efficient arithmetic module instruction set implementations, unified kernel fusion, and hybrid memory optimization strategies that significantly improve memory access efficiency and the performance of (I)NTT operations. Additionally, we propose a multi-dimensional parallel homomorphic multiplication scheme aimed at maximizing throughput and enhancing the performance of (I)NTT and homomorphic multiplication. In conclusion, our implementation is deployed on the RTX 4090, where we conduct a thorough throughput performance evaluation of HI-CKKS, enabling us to pinpoint the most effective parallel parameter settings. Compared to the CPU implementation, our system achieves throughput increases of $175.08\times$, $191.27\times$, and $679.57\times$ for NTT, INTT, and HMult, respectively. And our throughput performance still demonstrates a significant improvement, ranging from $1.54\times$ to $693.17\times$ compared to the latest GPU-based works.
]]></content:encoded>
<pubDate>Fri, 06 Dec 2024 11:53:02 +0000</pubDate>
</item>
<item>
<title>Arke: Scalable and Byzantine Fault Tolerant Privacy-Preserving Contact Discovery</title>
<link>https://eprint.iacr.org/2023/1218</link>
<guid>https://eprint.iacr.org/2023/1218</guid>
<content:encoded><![CDATA[
<div> 关键词: Contact discovery, Arke, Privacy, Scalability, Byzantine fault tolerance

总结:
Arke是一种新型的联系人发现方法，旨在解决现有方案在隐私、可扩展性和对可信第三方依赖方面的局限性。Arke确保用户交互的不可链接性，减轻枚举攻击风险，并在无单一故障点或信任中心的情况下运行。它是首个性能与总用户数和能否在拜占庭环境中运行无关的联系人发现系统。Arke通过基于身份的非交互式密钥交换构建的unlinkable握手机制实现其隐私目标。利用定制的分布式架构，Arke能够在避免共识成本的同时实现可扩展性，同时在拜占庭容错环境中保持一致性。性能评估显示，Arke可以在全球规模上支持足够的吞吐量，同时在大型地理分布式设置中保持亚秒级延迟。 <div>
Contact discovery is a crucial component of social applications, facilitating interactions between registered contacts. This work introduces Arke, a novel approach to contact discovery that addresses the limitations of existing solutions in terms of privacy, scalability, and reliance on trusted third parties. Arke ensures the unlinkability of user interactions, mitigates enumeration attacks, and operates without single points of failure or trust. Notably, Arke is the first contact discovery system whose performance is independent of the total number of users and the first that can operate in a Byzantine setting. It achieves its privacy goals through an unlinkable handshake mechanism built on top of an identity-based non-interactive key exchange. By leveraging a custom distributed architecture, Arke forgoes the expense of consensus to achieve scalability while maintaining consistency in a Byzantine fault tolerant environment. Performance evaluations demonstrate that Arke can support enough throughput to operate at a planetary scale while maintaining sub-second latencies in a large geo-distributed setting.
]]></content:encoded>
<pubDate>Thu, 10 Aug 2023 21:57:24 +0000</pubDate>
</item>
<item>
<title>Consistency-or-Die: Consistency for Key Transparency</title>
<link>https://eprint.iacr.org/2024/879</link>
<guid>https://eprint.iacr.org/2024/879</guid>
<content:encoded><![CDATA[
<div> 关键词: 一致性协议、分割视图攻击、随机用户委员会、Consistency-or-Die (CoD)、可验证随机函数、密钥演进签名、安全性水平、恶意用户、实用性、中档智能手机、大规模系统、亿级用户

总结:
本文提出了一种新的名为Consistency-or-Die (CoD)的一致性协议，该协议旨在保护关键透明度日志不受分割视图攻击，并且与以往工作不同，它不依赖于小规模的已知外部审计员委员会、脱机通道或区块链（全广播系统）。CoD通过使用加密机制随机选取并保密的小型用户委员会来背书当前的日志视图。协议保证用户能够得知自己是否处于一致状态，一旦发现日志中的不一致，用户将停止使用此资源并变为非活动状态（“死亡”）。CoD基于成熟的安全技术，如可验证随机函数和密钥演进签名，现有轻量级实现方案。文章还提供了新颖的统计分析方法，用于确定不同安全级别和恶意用户百分比下的最优背书人数（即视图的最小支持者数量）。实验结果表明，CoD在实际应用中具有可行性，能够在拥有数亿用户的大型系统的背景下在中档智能手机上运行。 <div>
This paper proposes a new consistency protocol that protects a key transparency log against split-view attacks and - contrary to all previous work - does not to rely on small committees of known external auditors, or out-of-band channels, or blockchains (full broadcast systems).

Our approach is to use a mechanism for cryptographically selecting a small committee of random and initially undisclosed users, which are then tasked to endorse the current view of the log. The name of our protocol, Consistency-or-Die (CoD), reflects that users are guaranteed to know if they are in a consistent state or not, and upon spotting an inconsistency in the key transparency log, users stop using this resource and become inactive (die). CoD relies on well-established cryptographic building blocks, such as verifiable random functions and key-evolving signatures, for which lightweight constructions exist. We provide a novel statistical analysis for identifying optimal quorum sizes (minimal number of endorsers for a view) for various security levels and percentages of malicious users.

Our experiments support that CoD is practical and can run in the background on mid-tier smart phones, for large-scale systems with billions of users.
]]></content:encoded>
<pubDate>Sun, 02 Jun 2024 14:22:00 +0000</pubDate>
</item>
<item>
<title>Onion Franking: Abuse Reports for Mix-Based Private Messaging</title>
<link>https://eprint.iacr.org/2024/1965</link>
<guid>https://eprint.iacr.org/2024/1965</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人消息应用、端到端加密、滥用报告、元数据保护、洋葱加密

总结:<br />
本文提出了适用于基于洋葱加密的任何私人消息系统的新型滥用报告机制，这包括采用启发式或机会性用户流量混合的低延迟系统以及基于混排网络的方案。文章指出，适合E2EE环境的设计决策和抽象可能在保护元数据的场景中阻碍安全性和性能提升，并探讨了比先前工作更强的滥用报告和内容审核威胁模型。此外，文中还分析了现有工作的不足，并提出如何强化自身方案和其他方案（包括已部署的E2EE消息平台）以实现更高安全级别。实验结果显示，所提出的原型系统在消息传递和报告过程中的每个步骤上，其性能优于当前最优解决方案一个数量级以上，且开销接近现今E2EE加密消息应用所使用的消息认证技术。 <div>
The fast-paced development and deployment of private messaging applications demands mechanisms to protect against the concomitant potential for abuse. While widely used end-to-end encrypted (E2EE) messaging systems have deployed mechanisms for users to verifiably report abusive messages without compromising the privacy of unreported messages, abuse reporting schemes for systems that additionally protect message metadata are still in their infancy. Existing solutions either focus on a relatively small portion of the design space or incur much higher communication and computation costs than their E2EE brethren.

This paper introduces new abuse reporting mechanisms that work for any private messaging system based on onion encryption. This includes low-latency systems that employ heuristic or opportunistic mixing of user traffic, as well as schemes based on mixnets. Along the way, we show that design decisions and abstractions that are well-suited to the E2EE setting may actually impede security and performance improvements in the metadata-hiding setting. We also explore stronger threat models for abuse reporting and moderation not explored in prior work, showing where prior work falls short and how to strengthen both our scheme and others' -- including deployed E2EE messaging platforms -- to achieve higher levels of security.

We implement a prototype of our scheme and find that it outperforms the best known solutions in this setting by well over an order of magnitude for each step of the message delivery and reporting process, with overheads almost matching those of message franking techniques used by E2EE encrypted messaging apps today.
]]></content:encoded>
<pubDate>Wed, 04 Dec 2024 15:32:40 +0000</pubDate>
</item>
<item>
<title>SoK: Privacy-Preserving Transactions in Blockchains</title>
<link>https://eprint.iacr.org/2024/1959</link>
<guid>https://eprint.iacr.org/2024/1959</guid>
<content:encoded><![CDATA[
<div> 关键词: 交易隐私、区块链系统、隐私保护技术、加密货币、匿名性

总结:<br />
本文针对具有原生隐私特性的加密货币中的隐私保护技术进行了系统化知识研究。文章界定了包括机密性、k-匿名性、完全匿名性和发送者-接收者不可链接性在内的隐私概念，并对实现这些保证所采用的密码学技术进行了分类和比较。分析指出了隐私保障与可扩展性以及监管合规性之间的权衡关系。同时，评估了最受欢迎的私人加密货币的实际部署和用户体验。通过这项分析，文章识别出现在隐私解决方案中的关键差距和挑战，强调了需要进一步研究和开发以增强隐私性的同时保持可扩展性和安全性的重要性。 <div>
Ensuring transaction privacy in blockchain systems is essential to safeguard user data and financial activity from exposure on public ledgers. This paper conducts a systematization of knowledge (SoK) on privacy-preserving techniques in cryptocurrencies with native privacy features. We define and compare privacy notions such as confidentiality, k-anonymity, full anonymity, and sender-receiver unlinkability, and categorize the cryptographic techniques employed to achieve these guarantees. Our analysis highlights the trade-offs between privacy guarantees, scalability, and regulatory compliance.  Finally, we evaluate the usability of the most popular private cryptocurrencies providing insights into their practical deployment and user interaction. 

Through this analysis, we identify key gaps and challenges in current privacy solutions, highlighting areas where further research and development are needed to enhance privacy while maintaining scalability and security.
]]></content:encoded>
<pubDate>Tue, 03 Dec 2024 17:04:55 +0000</pubDate>
</item>
<item>
<title>Worst-Case Lattice Sampler with Truncated Gadgets and Applications</title>
<link>https://eprint.iacr.org/2024/1952</link>
<guid>https://eprint.iacr.org/2024/1952</guid>
<content:encoded><![CDATA[
<div> 关键词: gadget-based sampler、Micciancio-Peikert (MP)、truncation、worst-case sampler、performance improvement

总结:<br />
本文提出了一个新的最坏情况下的采样器，该采样器适用于截断的gadget，解决了现有截断方案无法逆推任意 syndrome 的问题。这一创新克服了MP采样器线性增长维度的问题，同时保持了其主要特性，并为选择截断参数提供了灵活性。因此，它可以作为依赖于MP采样器的所有应用的直接替代品，实验证明能带来高达30%的性能提升。文章还对新采样器进行了全面的安全分析，并通过具体实现展示了其实用性。 <div>
Gadget-based samplers have proven to be a key component of several cryptographic primitives, in particular in the area of privacy-preserving mechanisms. Most constructions today follow the approach introduced by Micciancio and Peikert (MP) yielding preimages whose dimension linearly grows with that of the gadget. To improve performance, some papers have proposed to truncate the gadget but at the cost of an important feature of the MP sampler, namely the ability to invert arbitrary syndromes. Technically speaking, they replace the worst-case MP sampler by an average-case sampler that can only be used in specific contexts. Far from being a mere theoretical restriction, it prevents the main applications of gadget-based samplers from using truncated variants and thus from benefiting from the associated performance gains.
In this paper, we solve this problem by describing a worst-case sampler that still works with truncated gadgets. Its main strength is that it retains the main characteristics of the MP sampler while providing flexibility in the choice of the truncation parameter. As a consequence, it can be used as a plug-in replacement for all applications relying on the MP sampler so far, leading to performance improvements up to 30% as illustrated by several examples in this paper. Our sampler is supported by a thorough security analysis that addresses the hurdles met by previous works and its practicality is demonstrated by a concrete implementation.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 16:45:40 +0000</pubDate>
</item>
<item>
<title>Vote&amp;Check: Secure Postal Voting with Reduced Trust Assumptions</title>
<link>https://eprint.iacr.org/2024/1951</link>
<guid>https://eprint.iacr.org/2024/1951</guid>
<content:encoded><![CDATA[
<div> 关键词: 邮政投票、安全性、验证性、隐私保护、Vote&amp;Check

总结:
邮政投票是一种常用的替代现场投票的方式，其安全性和可验证性历来依赖于组织措施和多方信任。近年来，已有方案提出增加邮政投票的可验证性同时保持投票隐私。文章对邮政投票环境进行了系统分析，识别出一系列不可避免的攻击风险，并将这些分析应用于现有文献中的系统。针对这些问题，文章提出了一个名为Vote&amp;Check的邮政投票协议，该协议具有高安全级别并仅需少数基础加密原语——哈希函数和签名。Vote&amp;Check的安全属性已在符号模型中通过ProVerif工具得到了证明。 <div>
Postal voting is a frequently used alternative to on-site voting. Traditionally, its security relies on organizational measures, and voters have to trust many entities. In the recent years, several schemes have been proposed to add verifiability properties to postal voting, while preserving vote privacy.
Postal voting comes with specific constraints. We conduct a systematic analysis of this setting and we identify a list of generic attacks, highlighting that some attacks seem unavoidable. This study is applied to existing systems of the literature.
We then propose Vote&amp;Check, a postal voting protocol which provides a high level of security, with a reduced number of authorities. Furthermore, it requires only basic cryptographic primitives, namely hash functions and signatures. The security properties are proven in a symbolic model, with the help of the ProVerif tool.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 13:13:03 +0000</pubDate>
</item>
<item>
<title>ARK: Adaptive Rotation Key Management for Fully Homomorphic Encryption Targeting Memory Efficient Deep Learning Inference</title>
<link>https://eprint.iacr.org/2024/1948</link>
<guid>https://eprint.iacr.org/2024/1948</guid>
<content:encoded><![CDATA[
<div> 关键词: 深度学习、隐私保护、全同态加密(FHE)、内存消耗、Adaptive Rotation Key(ARK)

总结:
本文关注深度学习中隐私保护的问题，提出了一种名为Adaptive Rotation Key (ARK)的新技术，旨在解决全同态加密(FHE)的高内存消耗问题。ARKeep能够通过全面分析数值模式来生成最小化的共享旋转密钥集合，从而减少旋转密钥的内存占用。此外，ARK还提供了两种配置选项，允许用户根据需求在内存效率和计算速度之间进行权衡。在内存优先模式下，ARK能降低41.17%的旋转密钥内存消耗，但会导致执行时间增加12.57%；而在速度优先模式下，它实现了24.62%的旋转密钥内存减少，仅对执行时间造成0.21%的影响。因此，ARK为优化基于FHE的隐私保护系统提供了一个灵活而有效的解决方案，标志着该领域在优化策略上的一项重要进展。 <div>
Advancements in deep learning (DL) not only revolutionized many aspects in our lives, but also introduced privacy concerns, because it processed vast amounts of information that was closely related to our daily life. Fully Homomorphic Encryption (FHE) is one of the promising solutions to this privacy issue, as it allows computations to be carried out directly on the encrypted data. However, FHE requires high computational cost, which is a huge barrier to its widespread adoption. Many prior works proposed techniques to enhance the speed performance of FHE in the past decade, but they often impose significant memory requirements, which may be up to hundreds of gigabytes. Recently, focus has shifted from purely improving speed performance to managing FHE’s memory consumption as a critical challenge. Rovida and Leporati introduced a technique to minimize rotation key memory by retaining only essential keys, yet this technique is limited to cases with symmetric numerical patterns (e.g., -2 -1 0 1 2), constraining its broader utility. In this paper, a new technique, Adaptive Rotation Key (ARK), is proposed that minimizes rotation key memory consumption by exhaustively analyzing numerical patterns to produce a minimal subset of shared rotation keys. ARK also provides a dual-configuration option, enabling users to prioritize memory efficiency or computational speed. In memory-prioritized mode, ARK reduces rotation key memory consumption by 41.17% with a 12.57% increase in execution time. For speed-prioritized mode, it achieves a 24.62% rotation key memory reduction with only a 0.21% impact on execution time. This flexibility positions ARK as an effective solution for optimizing FHE across varied use cases, marking a significant advancement in optimization strategies for FHE-based privacy-preserving systems.
]]></content:encoded>
<pubDate>Mon, 02 Dec 2024 03:50:20 +0000</pubDate>
</item>
<item>
<title>Alba: The Dawn of Scalable Bridges for Blockchains</title>
<link>https://eprint.iacr.org/2024/197</link>
<guid>https://eprint.iacr.org/2024/197</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密货币, 互操作性, 信任桥梁协议, 支付通道, Pay2Chain桥

总结:
本文关注了过去十年加密货币领域的发展，特别是区块链生态系统和新颖应用的增长。为了解决当前信任桥梁协议在效率上的问题，如轻客户端和零知识证明（zk）方案存在的不足，文章提出了Pay2Chain桥的概念，该桥利用支付通道等离链解决方案的优势克服现有桥梁限制。文中所提出的Pay2Chain桥——Alba，能够实现基于离链事件的高效、安全和无需信任的有条件支付或智能合约执行，从而丰富源区块链生态，支持DeFi应用、多资产支付通道及乐观状态型离链计算。

论文进一步在UC框架下形式化定义了Alba对拜占庭敌手的安全性，并结合博弈论进行分析；同时引入正式可扩展性指标展示其效率优势。实证评估证实了Alba在通信复杂度和链上成本方面的效率，其乐观情况下的费用仅是标准以太坊代币所有权转移交易费用的两倍。 <div>
Over the past decade, cryptocurrencies have garnered attention from academia and industry alike, fostering a diverse blockchain ecosystem and novel applications. The inception of bridges improved interoperability, enabling asset transfers across different blockchains to capitalize on their unique features. Despite their surge in popularity and the emergence of Decentralized Finance (DeFi), trustless bridge protocols remain inefficient, either relaying too much information (e.g., light-client-based bridges) or demanding expensive computation (e.g., zk-based bridges). These inefficiencies arise because existing bridges securely prove a transaction's on-chain inclusion on another blockchain. Yet this is unnecessary as off-chain solutions, like payment and state channels, permit safe transactions without on-chain publication. However, existing bridges do not support the verification of off-chain payments.

This paper fills this gap by introducing the concept of Pay2Chain bridges that leverage the advantages of off-chain solutions like payment channels to overcome current bridges' limitations. Our proposed Pay2Chain bridge, named Alba, facilitates the efficient, secure, and trustless execution of conditional payments or smart contracts on a target blockchain based on off-chain events. Alba, besides its technical advantages, enriches the source blockchain's ecosystem by facilitating DeFi applications, multi-asset payment channels, and optimistic stateful off-chain computation.

We formalize the security of Alba against Byzantine adversaries in the UC framework and complement it with a game theoretic analysis. We further introduce formal scalability metrics to demonstrate Alba’s efficiency. Our empirical evaluation confirms Alba efficiency in terms of communication complexity and on-chain costs, with its optimistic case incurring only twice the cost of a standard Ethereum transaction of token ownership transfer.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 14:38:00 +0000</pubDate>
</item>
<item>
<title>Dynamic-FROST: Schnorr Threshold Signatures with a Flexible Committee</title>
<link>https://eprint.iacr.org/2024/896</link>
<guid>https://eprint.iacr.org/2024/896</guid>
<content:encoded><![CDATA[
<div> 关键词：_threshold signatures_ ， _FROST_ ， _CHURP_ ， _dynamic update_ ， _Schnorr threshold signature_

<br /><br />总结：

本文提出了一个名为Dynamic-FROST (简称D-FROST) 的协议，它将FROST——一种基于Schnorr的阈值签名方案，与CHURP——一种动态主动秘密分享方案相结合。D-FROST 是首个能够支持委员会成员和阈值值动态变更的Schnorr阈值签名方案，而且无需依赖可信第三方。此外，文章还对D-FROST的安全性进行了证明，表明其保持了原签署方案的存在的选择消息攻击下的不可伪造性属性。这一创新对于那些需要动态调整阈值或参与者的应用，如共识算法和区块链钱包等，具有实际意义和应用价值。 <div>
Threshold signatures enable any subgroup of predefined cardinality $t$ out of a committee of $n$ participants to generate a valid, aggregated signature. 
Although several $(t,n)$-threshold signature schemes exist, most of them assume that the threshold $t$ and the set of participants do not change over time. 
Practical applications of threshold signatures might benefit from the possibility of updating the threshold or the committee of participants. Examples of such applications are consensus algorithms and blockchain wallets.
In this paper, we present Dynamic-FROST (D-FROST, for short) that combines FROST, a Schnorr threshold signature scheme, with CHURP, a dynamic proactive secret sharing scheme. The resulting protocol is the first Schnorr threshold signature scheme that  accommodates changes in both the committee and the threshold value without relying on a trusted third party.
Besides detailing the protocol, we present a proof of its security: as the original signing scheme, D-FROST preserves the property of Existential Unforgeability under Chosen-Message Attack.
]]></content:encoded>
<pubDate>Wed, 05 Jun 2024 12:34:38 +0000</pubDate>
</item>
<item>
<title>Distributed Differentially Private Data Analytics via Secure Sketching</title>
<link>https://eprint.iacr.org/2024/1946</link>
<guid>https://eprint.iacr.org/2024/1946</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式差分隐私、计算效率、线性变换模型、中央模型、局部模型

总结:
我们研究了在多个服务器间进行分布式差分隐私计算，旨在平衡由差分隐私机制引入的误差与分布式算法的计算效率之间的权衡。为此，我们提出了线性变换模型，在该模型中，客户端能够访问一个可信任平台，该平台能够对输入数据应用公开矩阵。利用简单的安全多方计算技术，这种计算可以安全地分布到多个服务器上。

线性变换模型介于高度表达性的中央模型和限制较多的局部模型之间。中央模型允许客户端使用可信任平台对其输入执行任何函数运算，但这种表达能力的成本在于难以分布式实现，通常需要一个单一可信服务器来实施。而局部模型则不假设存在可信任平台，这迫使客户端在其数据中添加大量噪声。线性变换模型避免了中央模型中的单点隐私故障风险，同时也减轻了局部模型所需的高噪声。

我们证明线性变换对于差分隐私非常有用，可以用于计算输入数据的线性草图。这些草图在保持诸如私人低秩近似和私人岭回归等任务的实用性方面做得很好，同时仅引入最小的误差，关键的是，这个误差独立于客户端的数量。在此之前，这类准确性只有在更具有表达性的中央模型中才能实现。 <div>
We explore the use of distributed differentially private computations across multiple servers, balancing the tradeoff between the error introduced by the differentially private mechanism and the computational efficiency of the resulting distributed algorithm.

We introduce the linear-transformation model, where clients have access to a trusted platform capable of applying a public matrix to their inputs. Such computations can be securely distributed across multiple servers using simple and efficient secure multiparty computation techniques.

The linear-transformation model serves as an intermediate model between the highly expressive central model and the minimal local model. In the central model, clients have access to a trusted platform capable of applying any function to their inputs. However, this expressiveness comes at a cost, as it is often expensive to distribute such computations, leading to the central model typically being implemented by a single trusted server. In contrast, the local model assumes no trusted platform, which forces clients to add significant noise to their data. The linear-transformation model avoids the single point of failure for privacy present in the central model, while also mitigating the high noise required in the local model.

We demonstrate that linear transformations are very useful for differential privacy, allowing for the computation of linear sketches of input data. These sketches largely preserve utility for tasks such as private low-rank approximation and private ridge regression, while introducing only minimal error, critically independent of the number of clients. Previously, such accuracy had only been achieved in the more expressive central model.
]]></content:encoded>
<pubDate>Sat, 30 Nov 2024 18:13:15 +0000</pubDate>
</item>
<item>
<title>DGMT: A Fully Dynamic Group Signature From Symmetric-key Primitives</title>
<link>https://eprint.iacr.org/2024/1942</link>
<guid>https://eprint.iacr.org/2024/1942</guid>
<content:encoded><![CDATA[
<div> 关键词：群签名、匿名性、责任追究、对称密钥、动态性

总结:
本文提出了一种名为DGMT的基于对称密钥的完全动态群签名方案，该方案重新设计了DGM（Buser等人在ESORICS 2019上的工作），解决了其在实际应用中的两个重要局限：(i) 签名验证需要与组经理交互，以及 (ii) 组经理需要存储和管理大量不可接受的数据。文章证明了DGMT在安全性方面（不可伪造性、匿名性和可追溯性）的表现，并对其进行了完整实现。相较于已知具有同等安全级别的后量子群签名方案，DGMT拥有最短的签名长度。此外，文中还分析了DGM的签名撤销方法，揭示了虽然其概念新颖，但其实现成本显著高于使用传统的撤销列表方法。<br /><br /> <div>
A group signatures allows a user to sign a message anonymously  on behalf of a group and provides accountability by using  an opening authority who can ``open'' a signature and reveal the signer's identity. Group signatures have been widely used in privacy-preserving applications including anonymous attestation and anonymous authentication. Fully dynamic group signatures allow new members to join the group and existing members to be revoked if needed.  Symmetric-key based group signature schemes are post-quantum group signatures whose security rely on the security of symmetric-key primitives such as cryptographic hash functions and pseudorandom functions. 

In this paper, we design a symmetric-key based fully dynamic group signature scheme, called DGMT, that redesigns DGM (Buser et al. ESORICS 2019) and  removes its two important shortcomings that limit its application in practice: (i) interaction with the group manager for signature verification, and (ii) the need for storing and managing an unacceptably large amount of data by the group manager. We prove  security of DGMT (unforgeability, anonymity, and traceability)  and give a full implementation of the system. Compared to  all known post-quantum group signature schemes with the same security level, DGMT has the shortest signature size. We also analyze DGM signature revocation approach and show that despite its conceptual novelty, it  has significant hidden costs that makes it much more costly than using traditional revocation list approach.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 23:25:59 +0000</pubDate>
</item>
<item>
<title>A Formal Treatment of Key Transparency Systems with Scalability Improvements</title>
<link>https://eprint.iacr.org/2024/1938</link>
<guid>https://eprint.iacr.org/2024/1938</guid>
<content:encoded><![CDATA[
<div> 关键词: Key Transparency, 安全模型, 伪装攻击, 可验证Bloom过滤器, 扩展性

总结:
本文首次提出了一个关于密钥透明度（KT）系统的加密学上健全的形式化模型，明确了其安全假设、属性和潜在漏洞。文中揭示了一个重要的安全隐患——恶意服务提供商可能实施的伪装攻击，并提出了一种向后兼容的解决方案。此外，针对KT系统的扩展性瓶颈，文章设计并实现了一种新的隐私保护型可验证Bloom过滤器（VBF），它显著提高了KT的效率而不牺牲安全性。实验结果证明了该方法的有效性，标志着在可扩展的KT解决方案的理论研究和实际部署方面迈出了重要一步。 <div>
Key Transparency (KT) systems have emerged as a critical technology for securely distributing and verifying the correctness of public keys used in end-to-end encrypted messaging services. Despite substantial academic interest, increased industry adoption, and IETF standardization efforts, KT systems lack a holistic and formalized security model, limiting their resilience to practical threats and constraining future development. In this paper, we introduce the first cryptographically sound formalization of KT as an ideal functionality, clarifying the assumptions, security properties, and potential vulnerabilities of deployed KT systems. We identify a significant security concern — a possible impersonation attack by a malicious service provider — and propose a backward-compatible solution. Additionally, we address a core scalability bottleneck by designing and implementing a novel, privacy-preserving verifiable Bloom filter (VBF) that significantly improves KT efficiency without compromising security. Experimental results demonstrate the effectiveness of our approach, marking a step forward in both the theoretical and practical deployment of scalable KT solutions.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 10:26:00 +0000</pubDate>
</item>
<item>
<title>RevoLUT : Rust Efficient Versatile Oblivious Look-Up-Tables</title>
<link>https://eprint.iacr.org/2024/1935</link>
<guid>https://eprint.iacr.org/2024/1935</guid>
<content:encoded><![CDATA[
<div> 关键词: RevoLUT、Rust、Look-Up-Tables (LUT)、 Oblivious操作、隐私保护

总结:
本文介绍了RevoLUT，这是一个使用Rust语言实现的库，它重新构想了查找表（LUT）的用途，不再局限于TFHE编程式引导中常见的函数编码作用。RevoLUT将LUT作为一级对象，支持在表内部高效地进行 oblivious 操作，如数组访问、元素排序和置换。这种做法为执行 oblivious 算法提供了便利，从而在各种应用中实现了对敏感数据的安全、隐私保护的处理方式。 <div>
In this paper we present RevoLUT, a library implemented in Rust that reimagines the use of Look-Up-Tables (LUT) beyond their conventional role in function encoding, as commonly used in TFHE's programmable boostrapping. Instead, RevoLUT leverages LUTs as first class objects, enabling efficient oblivious operations such as array access, elements sorting and permutation directly within the table. This approach supports oblivious algortithm, providing a secure, privacy-preserving solution for handling sensitive data in various applications.
]]></content:encoded>
<pubDate>Fri, 29 Nov 2024 02:47:05 +0000</pubDate>
</item>
<item>
<title>HomeRun: High-efficiency Oblivious Message Retrieval, Unrestricted</title>
<link>https://eprint.iacr.org/2024/188</link>
<guid>https://eprint.iacr.org/2024/188</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护区块链应用、无感知消息检索(OMR)、HomeRun、安全属性、性能

总结:
文章介绍了一个名为HomeRun的新型无感知消息检索(OMR)协议，该协议针对隐私保护区块链应用设计。HomeRun具有以下优点：<br />
1. 提供了在同一地址多次请求之间的unlinkability（不可链接性），增强了用户隐私保护。<br />
2. 不限制同一收件人可以接收的消息数量，防止“消息余额耗尽”攻击，提升了系统可用性。<br />
3. 允许服务器定期删除已检索到的消息和相关辅助数据，降低了服务器的计算成本和存储成本。<br />
4. 相比现有方案，HomeRun巧妙运用高效的密码学技术，显著提高了运行效率：与Liu等人在CRYPTO '22上基于全同态加密的工作相比，其服务器总运行时间减少了约3830倍；与Madathil等人在USENIX Security '22上基于两个半诚实非共谋服务器的设计相比，至少减少了1459倍，且是在单线程WAN环境下的表现。 <div>
In the realm of privacy-preserving blockchain applications such as Zcash, oblivious message retrieval (OMR) enables recipients to privately access messages directed to them on blockchain nodes (or bulletin board servers). OMR prevents servers from linking a message and its corresponding recipient's address, thereby safeguarding recipient privacy. Several OMR schemes have emerged recently to meet the demands of these privacy-centric blockchains; however, we observe that existing solutions exhibit shortcomings in various critical aspects and may only achieve certain objectives inefficiently, sometimes relying on trusted hardware, thereby impacting their practical utility. This work introduces a novel OMR protocol, HomeRun,  that leverages two semi-honest, non-colluding servers to excel in both performance and security attributes as compared to the current state-of-the-art.

HomeRun stands out by providing unlinkability across multiple requests for the same recipient's address. Moreover, it does not impose a limit on the number of pertinent messages that can be received by a recipient, which thwarts ``message balance exhaustion'' attacks and enhances system usability. HomeRun also empowers servers to regularly delete the retrieved messages and the associated auxiliary data, which mitigates the constantly increasing computation costs and storage costs incurred by servers. Remarkably, none of the existing solutions offer all of these features collectively. Finally, thanks to its judicious use of highly efficient cryptographic building blocks, HomeRun is highly performant: Specifically, the total runtime of servers in HomeRun is $3830 \times$ less than that in the work by Liu et al. (CRYPTO '22) based on fully-homomorphic encryption, and at least $1459 \times$ less than that in the design by Madathil et al. (USENIX Security '22) based on two semi-honest and non-colluding servers, using a single thread in a WAN setting.
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 20:50:20 +0000</pubDate>
</item>
<item>
<title>EndGame: Field-Agnostic Succinct Blockchain with Arc</title>
<link>https://eprint.iacr.org/2024/1925</link>
<guid>https://eprint.iacr.org/2024/1925</guid>
<content:encoded><![CDATA[
<div> 关键词：EndGame、区块链架构、Reed-Solomon积累方案、常量时间验证、安全属性、编码、状态转换、Reed-Solomon码、ARC框架、轻客户端验证成本、无信任设置、状态管理。

<br /><br />总结:  
EndGame是一种新颖的区块链架构，它利用Reed-Solomon积累方案实现了简洁性。该构造允许在保持强大安全属性的同时，实现对区块链状态的常量时间验证。通过有效地使用Reed-Solomon码对区块链状态转移进行编码，并借助ARC框架累积证明状态的有效性，EndGame协议达成了轻客户端最优的验证成本，并支持了无需信任设置的高效状态管理。 <div>
We present EndGame, a novel blockchain architecture that achieves succinctness through Reed-Solomon accumulation schemes. Our construction enables constant-time verification of blockchain state while maintaining strong security properties. We demonstrate how to efficiently encode blockchain state transitions using Reed-Solomon codes and accumulate proofs of state validity using the ARC framework. Our protocol achieves optimal light client verification costs and supports efficient state management without trusted setup.
]]></content:encoded>
<pubDate>Wed, 27 Nov 2024 10:47:51 +0000</pubDate>
</item>
<item>
<title>Algebraic Zero Knowledge Contingent Payment</title>
<link>https://eprint.iacr.org/2024/1930</link>
<guid>https://eprint.iacr.org/2024/1930</guid>
<content:encoded><![CDATA[
<div> 关键词: Modular Algebraic Proof Contingent Payment (MAPCP), zero-knowledge contingent payment (ZKCP), zk-SNARKs, Hash Time-Locked Contracts (HTLC), fungibility

总结:
本文介绍了Modular Algebraic Proof Contingent Payment (MAPCP)，这是一种新颖的零知识条件支付方案。MAPCP首次实现了无需依赖zk-SNARKs作为零知识证明工具以及不使用Hash Time-Locked Contracts (HTLC)进行原子化交换秘密和支付的方式。因此，它避免了公共参考字符串(crs)创建问题，并能与几乎任何具有有限或无智能合约支持的加密货币兼容，同时提高了支付的可互换性，使其能够与标准加密货币支付无缝融合。

文章分析了MAPCP的安全性并证明其具备原子性：(i) 买家在支付记录上链后可以获取数字产品（保障买家安全）；(ii) 若买家已获得数字产品的访问权，则卖家将收到付款（保障卖家安全）。此外，文中还展示了一个具体应用案例，即客户通过MAPCP向公证人付费以获取文档签名。 <div>
In this work, we introduce Modular Algebraic Proof Contingent Payment (MAPCP), a novel zero-knowledge contingent payment (ZKCP) construction. Unlike previous approaches, MAPCP is the first that simultaneously avoids using zk-SNARKs as the tool for zero-knowledge proofs and HTLC contracts to atomically exchange a secret for a payment. As a result, MAPCP sidesteps the common reference string (crs) creation problem and is compatible with virtually any cryptocurrency, even those with limited or no smart contract support. Moreover, MAPCP contributes to fungibility, as its payment transactions blend seamlessly with standard cryptocurrency payments.
We analyze the security of MAPCP and demonstrate its atomicity, meaning that, (i) the buyer gets the digital product after the payment is published in the blockchain (buyer security); and (ii) the seller receives the payment if the buyer gets access to the digital product (seller security). Moreover, we present a construction of MAPCP in a use case where a customer pays a notary in exchange for a document signature.
]]></content:encoded>
<pubDate>Thu, 28 Nov 2024 11:01:29 +0000</pubDate>
</item>
<item>
<title>PASTA on Edge: Cryptoprocessor for Hybrid Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1919</link>
<guid>https://eprint.iacr.org/2024/1919</guid>
<content:encoded><![CDATA[
<div> 关键词: Fully Homomorphic Encryption (FHE), Hybrid Homomorphic Encryption (HHE), PASTA, FPGA, ASIC

总结:<br />
本文首次实现了名为PASTA的Hybrid Homomorphic Encryption (HHE)方案，这是一种针对整数设计的对称加密方案，旨在加速客户端加密和服务器端的同态解密。研究中对比了FPGA和ASIC平台上的性能结果，其中在低功耗的130nm ASIC技术上的RISC-V SoC实现相比CPU实现了43-171倍的速度提升；而在高端的7nm和28nm ASIC平台上，相较于之前的FHE公钥客户端加速器，其速度提升了97倍。此外，该设计已公开并应用于支持未来的相关研究。 <div>
Fully Homomorphic Encryption (FHE) enables privacy-preserving computation but imposes significant computational and communication overhead on the client for the public-key encryption. To alleviate this burden, previous works have introduced the Hybrid Homomorphic Encryption (HHE) paradigm, which combines symmetric encryption with homomorphic decryption to enhance performance for the FHE client. While early HHE schemes focused on binary data, modern versions now support integer prime fields, improving their efficiency for practical applications such as secure machine learning.

Despite several HHE schemes proposed in the literature, there has been no comprehensive study evaluating their performance or area advantages over FHE for encryption tasks. This paper addresses this gap by presenting the first implementation of an HHE scheme- PASTA. It is a symmetric encryption scheme over integers designed to facilitate fast client encryption and homomorphic symmetric decryption on the server. We provide performance results for both FPGA and ASIC platforms, including a RISC-V System-on-Chip (SoC) implementation on a low-end 130nm ASIC technology, which achieves a 43–171$\times$ speedup compared to a CPU. Additionally, on high-end 7nm and 28nm ASIC platforms, our design demonstrates a 97$\times$ speedup over prior public-key client accelerators for FHE. We have made our design public and benchmarked an application to support future research.
]]></content:encoded>
<pubDate>Tue, 26 Nov 2024 14:24:23 +0000</pubDate>
</item>
<item>
<title>Orion's Ascent: Accelerating Hash-Based Zero Knowledge Proof on Hardware Platforms</title>
<link>https://eprint.iacr.org/2024/1918</link>
<guid>https://eprint.iacr.org/2024/1918</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、Orion、优化、硬件加速、FPGA

总结:
针对零知识证明（ZKP）方案Orion中存在的承诺阶段性能瓶颈问题，本文提出了多项算法和硬件层面的优化措施。首先，将递归编码构造替换为迭代方法，并设计了面向硬件优化的新型扩增图策略，以提高并行性和减少外部内存访问。其次，实现了动态生成扩增图的技术，大幅降低内存使用量。此外，对Merkle树生成过程中的SHA3哈希操作进行了优化，显著加快了多项式承诺阶段的速度。文中通过FPGA实现，利用高效的内存访问策略对高带宽内存（HBM）进行深度优化，相较于高性能CPU上的软件实现，线性编码速度提升最高可达381倍，哈希操作速度提升高达2,390倍。在实际应用中，如基于ZKP的深度神经网络训练验证场景下，这些技术可使多项式承诺阶段的速度提升至241倍。 <div>
Zero-knowledge proofs (ZKPs) are cryptographic protocols that enable one party to prove the validity of a statement without revealing the underlying data. Such proofs have applications in privacy-preserving technologies and verifiable computations. However, slow proof generation poses a significant challenge in the wide-scale adoption of ZKP. Orion is a recent ZKP scheme with linear prover time. It leverages coding theory, expander graphs, and Merkle hash trees to improve computational efficiency. However, the polynomial commitment phase in Orion is yet a primary performance bottleneck due to the memory-intensive nature of expander graph-based encoding and the data-heavy hashing required for Merkle Tree generation.

This work introduces several algorithmic and hardware-level optimizations aimed at accelerating Orion’s commitment phase. We replace the recursive encoding construction with an iterative approach and propose novel expander graph strategies optimized for hardware to enable more parallelism and reduce off-chip memory access. Additionally, we implement an on-the-fly expander graph generation technique, reducing memory usage by gigabytes. Further optimizations in Merkle Tree generation reduce the cost of SHA3 hashing, resulting in significant speedups of the polynomial commitment phase. Our FPGA implementation heavily optimizes access to the off-chip high-bandwidth memory (HBM) utilizing memory-efficient computational strategies. The accelerator demonstrates speedups of up to 381$\times$ for linear encoding and up to 2,390$\times$ for the hashing operations over a software implementation on a high-end CPU. In the context of real-world applications, such as zero-knowledge proof-of-training of deep neural networks (DNNs), our techniques show up to 241$\times$ speed up for the polynomial commitment.
]]></content:encoded>
<pubDate>Tue, 26 Nov 2024 11:02:32 +0000</pubDate>
</item>
<item>
<title>Decentralized FHE Computer</title>
<link>https://eprint.iacr.org/2024/1917</link>
<guid>https://eprint.iacr.org/2024/1917</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式计算机、隐私保护、全同态加密、区块链环境、开发者激励

<br />
总结:
本文提出了一个基于全同态加密（FHE）技术的去中心化计算机模型，旨在解决现有区块链系统中处理私密数据能力不足的问题。通过利用FHE技术，该模型能在保证数据加密状态下的安全计算与隐私保护。将此模型融入到去中心化生态系统中，可以有效扩展应用场景，特别是在对保密性要求高的领域。此外，该方案还具有可扩展性和为开发者贡献提供激励机制的特点，从而为构建一个支持隐私计算的去中心化计算机提供了有力框架。 <div>
The concept of a decentralized computer is a powerful and transformative idea that has proven its significance in enabling trustless, distributed computations. However, its application has been severely constrained by an inability to handle private data due to the inherent transparency of blockchain systems. This limitation restricts the scope of use cases, particularly in domains where confidentiality is critical.

In this work, we introduce a model for a Fully Homomorphic Encryption (FHE) decentralized computer. Our approach leverages recent advancements in FHE technology to enable secure computations on encrypted data while preserving privacy. By integrating this model into the decentralized ecosystem, we address the long-standing challenge of privacy in public blockchain environments. The proposed FHE computer supports a wide range of use cases, is scalable, and offers a robust framework for incentivizing developer contributions.
]]></content:encoded>
<pubDate>Mon, 25 Nov 2024 19:11:00 +0000</pubDate>
</item>
<item>
<title>Sublinear-Round Broadcast without Trusted Setup</title>
<link>https://eprint.iacr.org/2024/770</link>
<guid>https://eprint.iacr.org/2024/770</guid>
<content:encoded><![CDATA[
<div> 关键词: Byzantine广播、分布式计算、信任假设、可扩展性、子线性轮次<br /><br />总结:
本文提出了一种针对不诚实多数环境下的首个无需信任设置、子线性轮次的拜占庭广播协议。该协议不再依赖于线性数量级的通信轮次或对可信设置的要求，也不需要存在一个诚实的密钥发放者和相关随机字符串的经销商，以及随机预言机。协议的设置仅限于无结构的均匀参考字符串和平凡公钥基础设施（即公告板PKI）。协议的核心是一个“有调解的梯度广播”协议，用于达成共享随机字符串的弱一致性。利用这些字符串，可以公正地运行基于委员会的拜占庭协议，实现子线性轮次的终止。为此，文章提出了一个新的委员会选举构造，它既不依赖随机预言机，也不依赖可信经销商，而是使用了NIZK证明和时间锁谜题。此协议能抵抗任意常数比例的动态敌手攻击。 <div>
Byzantine broadcast is one of the fundamental problems in distributed computing. Many of its practical applications, from multiparty computation to consensus mechanisms for blockchains,  require increasingly weaker trust assumptions, as well as scalability for an ever-growing number of users $n$. This rules out existing solutions which run in a linear number of rounds in $n$ or rely on trusted setup requirements. In this paper, we propose the first sublinear-round and trustless Byzantine broadcast protocol for the dishonest majority setting. Unlike previous sublinear-round protocols, our protocol assumes neither the existence of a trusted dealer who honestly issues keys and correlated random strings to the parties nor random oracles. Instead, we present a solution whose setup is limited to an unstructured uniform reference string and a plain public key infrastructure (a.k.a. bulletin-board PKI).

    Our broadcast protocol builds on top of a \emph{moderated gradecast} protocol which parties can use to reach weak agreement on shared random strings. Using these strings, we can then run in an unbiased fashion a committee-based Byzantine protocol, similar to that of Chan et al. (PKC 2020), which terminates in a sublinear number of rounds. To this end, we propose a novel construction for committee election, which does not rely either on random oracles or on a trusted dealer, and uses NIZKs and time-lock puzzles. Our protocol is resilient against an adaptive adversary who corrupts any constant fraction of parties.
]]></content:encoded>
<pubDate>Mon, 20 May 2024 08:30:07 +0000</pubDate>
</item>
<item>
<title>DiStefano: Decentralized Infrastructure for Sharing Trusted Encrypted Facts and Nothing More</title>
<link>https://eprint.iacr.org/2023/1063</link>
<guid>https://eprint.iacr.org/2023/1063</guid>
<content:encoded><![CDATA[
<div> 关键词：DiStefano、TLS加密、私人承诺、第三方验证、性能优化

总结:
DiStefano 是一个高效且针对恶意攻击安全的框架，用于在使用 TLS-1.3 加密的网络流量上生成私有承诺，以便由指定的第三方进行验证。相较于之前的 TLS 承诺系统，DiStefano 提供了多项改进，包括：针对 TLS 1.3 的模块化协议、对加密数据上任意可验证声明的支持、客户端浏览历史在预批准 TLS 服务器之间的隐私保护，以及确保 TLS 1.3 会话快速在线性能的各种优化。DiStefano 的一个开源实现已经集成到 BoringSSL 密码学库（被基于 Chromium 的互联网浏览器使用）中。实验表明，无论是在局域网还是广域网环境中，DiStefano 在对任意 TLS 流量中的事实进行承诺时都具有实用性，完成整个在线阶段协议的执行所需时间少于 1 秒且数据传输量不超过 80 KiB。 <div>
We design DiStefano: an efficient, maliciously-secure framework for generating private commitments over TLS-encrypted web traffic, for verification by a designated third-party. DiStefano provides many improvements over previous TLS commitment systems, including: a modular protocol specific to TLS 1.3, support for arbitrary verifiable claims over encrypted data, client browsing history privacy amongst pre-approved TLS servers, and various optimisations to ensure fast online performance of the TLS 1.3 session. We build a permissive open-source implementation of DiStefano integrated into the BoringSSL cryptographic library (used by Chromium-based Internet browsers). We show that DiStefano is practical in both LAN and WAN settings for committing to facts in arbitrary TLS traffic, requiring \(<\) 1 s and \(≤\) 80 KiB to execute the complete online phase of the protocol.
]]></content:encoded>
<pubDate>Fri, 07 Jul 2023 17:56:08 +0000</pubDate>
</item>
<item>
<title>A Better Proof-of-Work Fork Choice Rule</title>
<link>https://eprint.iacr.org/2024/200</link>
<guid>https://eprint.iacr.org/2024/200</guid>
<content:encoded><![CDATA[
<div> 关键词: 修改、工作量证明、选择规则、内在工作、确认延迟<br /><br />总结:<br />
我们提出了一种针对工作量证明区块链的共识机制修改方案，即不再选择最长链，而是选择具有最多内在工作量的链。内在工作量是指区块哈希值前部的零数量。这一改动使得协议运行速度得以安全提升，相较于比特币，在面对近10%的恶意节点情况下，确认延迟可以大约减少40%。该修改是在工作量证明不等式层面进行的，因此可以与文献中提出的其他提高延迟的方法（如GHOST）结合使用。我们通过模拟执行了长达3,000年的系统仿真，获取了详细的证据。同时，我们在比特币骨干模型下正式证明了新协议的安全性，并在证明过程中引入了一个新的技术工具：实值随机Oracle，这可能具有独立的研究价值。 <div>
We propose a modification to the fork choice rule of proof-of-work blockchains. Instead of choosing the heaviest chain, we choose the chain with the most intrinsic work. The intrinsic work of a block is roughly the number of zeroes at the front of its hash. This modification allows us to safely speed up the protocol, yielding a roughly 40% improvement in confirmation delay as compared to Bitcoin for adversaries close to 10%. Our modification is at the level of the proof-of-work inequality, and thus can be composed with any other methods to improve latency proposed in the literature (e.g., GHOST). We compile detailed simulation evidence from 3,000 years of simulated executions of our system across different parameters. We formally prove the security of our new protocol in the Bitcoin Backbone model. These proofs use a new technical tool, the real-valued Random Oracle which may be of independent interest.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 16:50:17 +0000</pubDate>
</item>
<item>
<title>Double Auction Meets Blockchain: Consensus from Scored Bid-Assignment</title>
<link>https://eprint.iacr.org/2022/1471</link>
<guid>https://eprint.iacr.org/2022/1471</guid>
<content:encoded><![CDATA[
<div> 关键词: 双重拍卖系统、区块链、持久性、活性、proof-of-work (PoW)

总结:
本文提出了一种针对双重拍卖系统的新型区块链协议设计，该设计直接从竞标分配计算中构建，确保了透明度和不可变性。文章创新点在于采用一种基于得分的广义多分配问题（SGMAP）的替代proof-of-work (PoW)方案，并将其整合到定制的区块链协议中。与传统PoW协议不同，该方案的领导者选择由与SGMAP评分函数相关的区块分数驱动，该函数具有足够的灵活性以定义难度级别并适应双重拍卖系统的实际需求。文中证明了设计方案的持久性和修改后的活性属性，并通过实施结果验证了其实用性和鲁棒性。 <div>
A double auction system, where buyers and sellers trade through bids, requires a transparent and immutable mechanism to record allocation results. This demand can be met with robust ledgers that ensure persistence and liveness, as exemplified by the Bitcoin blockchain (EuroCrypt '15). While existing blockchain-aided auction systems often rely on secure smart contracts or layer-$2$ techniques, this work proposes a more fundamental approach by constructing a provably secure blockchain protocol directly from the computation of bid allocations. The core component is an alternative proof-of-work (PoW) scheme based on a scored generalized multiple assignment problem (SGMAP), integrated into a tailored blockchain protocol. Unlike conventional PoW-based protocols, our leader selection is driven by block scores derived from the SGMAP scoring function, which is designed to be flexible enough to define the difficulty level and accommodate real-life requirements of the underlying double auction system. We prove persistence and a modified liveness property for our design, and present implementation results to validate its robustness and practicality.
]]></content:encoded>
<pubDate>Thu, 27 Oct 2022 03:19:10 +0000</pubDate>
</item>
<item>
<title>Stealth Software Trojan: Amplifying Hidden RF Side-Channels with Ultra High SNR and Data-Rate</title>
<link>https://eprint.iacr.org/2024/1910</link>
<guid>https://eprint.iacr.org/2024/1910</guid>
<content:encoded><![CDATA[
<div> 关键词: 物联网设备、安全漏洞、射频侧信道攻击、软件木马、信息盗窃

<br /><br />总结:
本文介绍了物联网设备带来的生活便利性与安全隐患之间的矛盾。文章提出了一种结合射频(RF)侧信道攻击和软件木马的新方法，能够以几乎无法检测且极为隐匿的方式，在毫秒级时间内从千米之外窃取大量秘密信息。该技术利用由外围设备、总线、内存和CPU引起的木马诱导电气干扰，实现高信噪比数据泄漏。实验结果显示其具有极短的数据获取时间和极高的隐蔽性。此外，研究还引入了优化的调制、解调方案以及专门的同步符号，以降低错误率并提高数据传输速率。文章着重强调了需要开发先进的检测和防御机制来确保物联网设备的安全性和隐私保护。 <div>
Interconnected devices enhance daily life but introduce security
vulnerabilities, new technologies enable malicious activities
such as information theft. This article combines radio frequency (RF) side-channel attacks with software Trojans to create a hard-to-detect, stealthy method for extracting kilobytes of secret information per millisecond over record distances with a single measurement in the RF spectrum. The technique exploits Trojan-induced electrical disturbances in RF components originating from peripherals, buses, memories and CPUs to achieve high SNR data leakage schemes. Experimental results show negligible acquisition time and stealth. The research introduces optimized modulation, demodulation schemes, and specialized synchronization symbols to minimize error rates and maximize data rates. It highlights the need for advanced detection and defense mechanisms to ensure the security and privacy of interconnected devices.
]]></content:encoded>
<pubDate>Sun, 24 Nov 2024 12:51:12 +0000</pubDate>
</item>
<item>
<title>NewtonPIR: Communication Efficient Single-Server PIR</title>
<link>https://eprint.iacr.org/2024/1909</link>
<guid>https://eprint.iacr.org/2024/1909</guid>
<content:encoded><![CDATA[
<div> 关键词: 私人信息检索(PIR), 通信效率, 单服务器PIR协议, NewtonPIR, 计算成本

总结:
本文提出了一种名为NewtonPIR的新单服务器PIR协议，旨在提高通信效率并实现适用于现实世界的计算成本。与现有最佳PIR协议相比，NewtonPIR能将通信开销降低7.5倍，相较于其他协议则降低了35.9至75倍。当数据库和条目大小增加时，NewtonPIR的通信开销保持稳定。通过使用单密文全同态加密(FHE)方案、简单的牛顿插值多项式以及在离线阶段预先计算系数，NewtonPIR成功地将计算开销从小时级别降至秒级别，成为首个实现与数据库大小无关的通信成本且计算开销可与基于环学习带错误(RLWE)的PIR方案相媲美的协议。此外，文章还扩展并引入了一个更有效地平衡计算和通信开销的私人集合交集(PSI)协议。 <div>
Private information retrieval (PIR) is a key component of many privacy-preserving systems. Although numerous PIR protocols have been proposed, designing a PIR scheme with communication overhead independent of the database size $N$ and computational cost practical for real-world applications remains a challenge. In this paper, we propose the NewtonPIR protocol, a communication efficient single-server PIR scheme. NewtonPIR can directly generate query values for the entire index without splitting the index and sending multiple query ciphertexts. Specifically, NewtonPIR achieves communication overhead that is 7.5$\times$ better than the state-of-the-art PIR protocol and 35.9$\sim$75$\times$ better than the other protocols. In experiments, when the database size and entry size increase, the communication overhead of NewtonPIR remains stable. By utilizing the single-ciphertext fully homomorphic encryption (FHE) scheme and the simple Newton interpolation polynomial, along with precomputing coefficients in the offline phase, we reduce the computational overhead of NewtonPIR from hours in previous schemes to seconds. To the best of our knowledge, NewtonPIR is the first protocol to achieve communication cost independent of $N$ along with computational overhead comparable to ring learning with errors (RLWE)-based PIR schemes. Additionally, we extend and introduce a private set intersection (PSI) protocol that balances computational and communication overhead more effectively.
]]></content:encoded>
<pubDate>Sun, 24 Nov 2024 11:03:11 +0000</pubDate>
</item>
<item>
<title>ZK-SNARKs for Ballot Validity: A Feasibility Study</title>
<link>https://eprint.iacr.org/2024/1902</link>
<guid>https://eprint.iacr.org/2024/1902</guid>
<content:encoded><![CDATA[
<div> 关键词: 电子投票、零知识证明、ZK-SNARKs、Exponential ElGamal加密、可行性研究

总结:
文章探讨了将通用型零知识证明（GPZKPs）应用于基于Exponential ElGamal加密的电子投票系统的可行性。作者们在Huber等人关于Pedersen向量承诺的研究基础上，进一步阐述了如何利用Groth16 ZK-SNARK来验证使用Exponential ElGamal加密的各种选举类型和选票格式的有效性。他们还实现并对比测试了一系列不同投票方法和选票格式的实例，结果表明GPZKPs在保证选票隐私的同时，确实可用于证实此类投票系统中选票的有效性，为协议设计者提供了是否采用GPZKP的决策依据。 <div>
Electronic voting (e-voting) systems have become more prevalent in recent years, but security concerns have also increased, especially regarding the privacy and verifiability of votes. As an essential ingredient for constructing secure e-voting systems, designers often employ zero-knowledge proofs (ZKPs), allowing voters to prove their votes are valid without revealing them. Invalid votes can then be discarded to protect verifiability without compromising the privacy of valid votes.

General purpose zero-knowledge proofs (GPZKPs) such as ZK-SNARKs can be used to prove arbitrary statements, including ballot validity. While a specialized ZKP that is constructed only for a specific election type/voting method, ballot format, and encryption/commitment scheme can be more efficient than a GPZKP, the flexibility offered by GPZKPs would allow for quickly constructing e-voting systems for new voting methods and new ballot formats. So far, however, the viability of GPZKPs for showing ballot validity for various ballot formats, in particular, whether and in how far they are practical for voters to compute, has only recently been investigated for ballots that are computed as Pedersen vector commitments in an ACM CCS 2022 paper by Huber et al.

Here, we continue this line of research by performing a feasibility study of GPZKPs for the more common case of ballots encrypted via Exponential ElGamal encryption. Specifically, building on the work by Huber et al., we describe how the Groth16 ZK-SNARK can be instantiated to show ballot validity for arbitrary election types and ballot formats encrypted via Exponential ElGamal. As our main contribution, we implement, benchmark, and compare several such instances for a wide range of voting methods and ballot formats. Our benchmarks not only establish a basis for protocol designers to make an educated choice for or against such a GPZKP, but also show that GPZKPs are actually viable for showing ballot validity in voting systems using Exponential ElGamal.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 10:40:03 +0000</pubDate>
</item>
<item>
<title>Light Clients for Lazy Blockchains</title>
<link>https://eprint.iacr.org/2022/384</link>
<guid>https://eprint.iacr.org/2022/384</guid>
<content:encoded><![CDATA[
<div> 关键词：lazy blockchains, transaction verification, light clients, logarithmic complexity, bisection game

总结:<br />
本文针对懒散区块链（lazy blockchains）提出了一个新的协议，旨在解决其在高效轻量级（SPV）客户端创建上的挑战。该协议利用了对区块链执行时间呈对数级的交互轮次和通信复杂性。文章所设计的方案基于一种遍历包含所有有效或无效交易的默克尔树（Merkle tree）的二分游戏。通过证明该证明系统具有简洁性、完备性和有效性，并通过实证演示了该方案的可行性。 <div>
Lazy blockchains decouple consensus from transaction verification and execution to increase throughput. Although they can contain invalid transactions (e.g., double spends) as a result, these can easily be filtered out by full nodes that check if there have been previous conflicting transactions. However, creating light (SPV) clients that do not see the whole transaction history becomes a challenge: A record of a transaction on the chain does not necessarily entail transaction confirmation. In this paper, we devise a protocol that enables the creation of efficient light clients for lazy blockchains. The number of interaction rounds and the communication complexity of our protocol are logarithmic in the blockchain execution time. Our construction is based on a bisection game that traverses the Merkle tree containing the ledger of all - valid or invalid - transactions. We prove that our proof system is succinct, complete and sound, and empirically demonstrate the feasibility of our scheme.
]]></content:encoded>
<pubDate>Mon, 28 Mar 2022 14:35:08 +0000</pubDate>
</item>
<item>
<title>A Tool for Fast and Secure LWE Parameter Selection: the FHE case</title>
<link>https://eprint.iacr.org/2024/1895</link>
<guid>https://eprint.iacr.org/2024/1895</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密（FHE）、参数选择、LWE基础方案、安全性、效率

总结:
针对全同态加密（FHE）中参数选择的复杂性和挑战性问题，该工作着重于为基于LWE的方案提供严格的理论基础。首先，通过对LWE问题上的 lattice 攻击进行深入分析，得到了最有效攻击的确切表达式。接着，文章引入了闭合形式公式，明确了LWE参数之间的关系。此外，提出了一种数值方法，能够准确地根据所需的安全部署级别选取可配置参数。最后，利用这些研究成果构建了一个实用且高效的工具，旨在帮助研究者和实践者在真实世界应用中部署FHE，确保其既具备严谨的安全性又具有良好的效率。 <div>
The field of fully homomorphic encryption (FHE) has seen many theoretical and computational advances in recent years, bringing the technology closer to practicality than ever before. For this reason, practitioners in related fields, such as machine learning, are increasingly interested in using FHE to provide privacy to their applications. 

Despite this progress, selecting secure and efficient parameters for FHE remains a complex and challenging task due to the intricate interdependencies between parameters. In this work, we address this issue by providing a rigorous theoretical foundation for parameter selection for any LWE-based schemes, with a specific focus on FHE. Our approach starts with an in-depth analysis of lattice attacks on the LWE problem, deriving precise expressions for the most effective ones. Building on this, we introduce closed-form formulas that establish the relationships among the LWE parameters. 

In addition, we introduce a numerical method to enable the accurate selection of any configurable parameter to meet a desired security level.
Finally, we use our results to build a practical and efficient tool for researchers and practitioners deploying FHE in real-world applications, ensuring that our approach is both rigorous and accessible.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 20:52:41 +0000</pubDate>
</item>
<item>
<title>Shardora: Towards Scaling Blockchain Sharding via Unleashing Parallelism</title>
<link>https://eprint.iacr.org/2024/1896</link>
<guid>https://eprint.iacr.org/2024/1896</guid>
<content:encoded><![CDATA[
<div> 关键词: 分片、区块链可扩展性、TPS-退化问题、零-TPS问题、Shardora<br /><br />总结:<br />
为了解决区块链分片在重新配置过程中面临的TPS-退化和零-TPS问题，本文提出了Shardora这一区块链分片系统，旨在通过释放并行性来提高区块链的可扩展性。Shardora实现了两个关键机制：(1) 并行化的双委员会框架配合声誉机制，以减轻TPS-退化问题的同时确保系统安全性；(2) 并行化的密钥预谈判机制结合秘钥重用策略，有效避免零-TPS问题，保持高TPS。理论证明了Shardora具有安全保障。团队已在阿里云上实现Shardora的原型并进行部署，实验结果显示，Shardora显著降低了ledger同步和密钥谈判的开销，比现有的分片方案性能至少提升90%。此外，Shardora在吞吐量和延迟方面表现出优越性能，在单个分片拥有600节点的LAN环境下，达到了峰值吞吐量8300 TPS。Shardora的源代码已在GitHub上公开可用。 <div>
Sharding emerges as a promising solution to enhance blockchain scalability. However, it faces two critical limitations during shard reconfiguration: (1) the TPS-Degradation issue, arising from ledger synchronization conflicts during transaction processing, and (2) the Zero-TPS issue, caused by disruptions in transaction processing due to key negotiation. To this end, we propose Shardora, a blockchain sharding system for scaling blockchain by unleashing parallelism. In Shardora, we implement two essential mechanisms: (1) A parallelized dual committee framework with a reputation mechanism to mitigate the TPS-Degradation issue while ensuring system security. (2) A parallelized key pre-negotiation mechanism with a secret-reuse strategy to avoid the Zero-TPS issue while maintaining a continuously high TPS. We prove that Shardora offers theory-guaranteed security. We implement a prototype of Shardora and deploy it on Alibaba Cloud. Experimental results demonstrate that Shardora addresses the limitations by significantly reducing the overhead of both ledger synchronization and key negotiation, which outperforms state-of-the-art sharding schemes by at least 90%. In addition, Shardora shows its superior performance in terms of throughput and latency, achieving a peak throughput of 8300 TPS on a single shard with 600 nodes under LAN conditions. The code of Shardora is publicly available on GitHub.
]]></content:encoded>
<pubDate>Fri, 22 Nov 2024 03:34:28 +0000</pubDate>
</item>
<item>
<title>A non-comparison oblivious sort and its application to private k-NN</title>
<link>https://eprint.iacr.org/2024/1894</link>
<guid>https://eprint.iacr.org/2024/1894</guid>
<content:encoded><![CDATA[
<div> 关键词: 加密数据、全同态加密(FHE)、计数排序适应性、盲计数排序算法、隐私保护

总结:
本文提出了一种对计数排序的独特改编方案，该方案能够在使用全同态加密（FHE）的情况下对加密数据进行排序。这是首个不依赖于比较操作的加密数据排序算法。实现过程中利用了TFHE的查找表（LUT）上的基本操作，并将这些操作整合到了基于tfhe-rs构建的开源库RevoLUT中，该库对于无感知算法具有独立的研究价值。通过开发应用于隐私保护的顶-k选择算法并将其应用于k-最近邻分类问题，证明了盲计数排序算法比当前最先进的方法快约5倍。 <div>
This paper introduces a novel adaptation of counting sort that enables sorting of encrypted data using Fully Homomorphic Encryption (FHE). Our approach represents the first known sorting algorithm for encrypted data that does not rely on comparisons. The implementation leverages some basic operations on TFHE's Look-Up-Tables (LUT). We have integrated these operations into RevoLUT, a comprehensive open-source library built upon tfhe-rs, which can be of independent interest for oblivious algorithms. We demonstrate the effectiveness of our Blind Counting Sort algorithm by developing a top-$k$ selection algorithm and applying it to privacy-preserving $k$-Nearest Neighbors classification. This proves to be approximately 5x faster than current state-of-the-art methods.
]]></content:encoded>
<pubDate>Thu, 21 Nov 2024 18:23:02 +0000</pubDate>
</item>
<item>
<title>IO-Optimized Design-Time Configurable Negacyclic Seven-Step NTT Architecture for FHE Applications</title>
<link>https://eprint.iacr.org/2024/1889</link>
<guid>https://eprint.iacr.org/2024/1889</guid>
<content:encoded><![CDATA[
<div> 关键词: FHE、NTT、negacyclic ring、FPGA、Seven-Step NTT

总结:
文章介绍了针对全同态加密（FHE）中关键的多项式乘法运算，提出了一种新的层次化四步NTT方法，该方法应用于负循环环上的多项式，消除了现有方法中的预处理和后处理步骤。为了加速NTT操作，文章提出了基于FPGA的、参数化且全程流水线化的七步NTT算法实现架构，支持最高达$2^{16}$的环大小和$64$位模数。设计重点关注配置吞吐量，根据HBM带宽约束进行IO参数化设计，目标是在Alveo U280 FPGA上最大化吞吐量。实测结果显示，对于环大小为$2^{16}$和宽度为32位的情况，与当前最先进的设计方案相比，面积-时间产品降低了$2.08\times$，速度提高了$10.32\times$。 <div>
FHE enables computations on encrypted data, making it essential for privacy-preserving applications. However, it involves computationally demanding tasks, such as polynomial multiplication, while NTT is the state-of-the-art solution to perform this task. Most FHE schemes operate over the negacyclic ring of polynomials. We introduce a novel formulation of the hierarchical Four-Step NTT approach for the negacyclic ring, eliminating the need for pre- and post-processing steps found in the existing methods. To accelerate NTT operations, the FPGAs offer flexible and powerful computing platforms. We propose an FPGA-based, parametric and fully pipelined architecture that implements the improved Seven-Step NTT algorithm (which builds upon the four-step). Our design supports a wide range of parameters, including ring sizes up to $2^{16}$ and modulus sizes up to $64$-bit. We focus on achieving configurable throughput, as constrained by the bandwidth of HBM bandwidth, and aim to maximize throughput through an IO parametric design on the Alveo U280 FPGA. The implementation results demonstrate a reduction in the area-time-product by $2.08\times$ and a speed-up of $10.32\times$ for a ring size of $2^{16}$ and a 32-bit width compared to the current state-of-the-art designs.
]]></content:encoded>
<pubDate>Wed, 20 Nov 2024 13:27:28 +0000</pubDate>
</item>
<item>
<title>Age-aware Fairness in Blockchain Transaction Ordering for Reducing Tail Latency</title>
<link>https://eprint.iacr.org/2024/1884</link>
<guid>https://eprint.iacr.org/2024/1884</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链网络、交易延迟、公平性、交易年龄、声明方案

总结:
区块链网络中，交易延迟对于服务质量（QoS）至关重要。文章提出了一种基于交易等待时间增加其优先级的公平性方法，以降低高延迟交易的发生。然而，由于交易传播影响，交易的实际年龄并不绝对，而且节点可能会谎报交易年龄以获取更高优先级。为此，文章建议采用一种新的声明方案技术，使得节点能够公正地宣布其待处理交易并验证交易年龄。通过对以太坊实际数据和多种场景的合成数据进行评估，该方法在现实条件下展现出减少尾部延迟和维护公平性的优势。 <div>
In blockchain networks, transaction latency is crucial for determining the quality of service (QoS). The latency of a transaction is measured as the time between its issuance and its inclusion in a block in the chain. A block proposer often prioritizes transactions with higher fees or transactions from accounts it is associated with, to minimize their latencies. To maintain fairness among transactions, a block proposer is expected to select the included transactions randomly. The random selection might cause some transactions to experience high latency following the variance in the time a transaction waits until it is selected. We suggest an alternative, age-aware approach towards fairness so that transaction priority is increased upon observing a large waiting time. We explain that a challenge with this approach is that the age of a transaction is not absolute due to transaction propagation. Moreover, a node might present its transactions as older to obtain priority. We describe a new technique to enforce a fair block selection while prioritizing transactions that observed high latency.  The technique is based on various declaration schemes in which a node declares its pending transactions, providing the ability to validate transaction age. By evaluating the solutions on Ethereum data and synthetic data of various scenarios, we demonstrate the advantages of the approach under realistic conditions and understand its potential impact to maintain fairness and reduce tail latency.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 10:43:58 +0000</pubDate>
</item>
<item>
<title>THOR: Secure Transformer Inference with Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1881</link>
<guid>https://eprint.iacr.org/2024/1881</guid>
<content:encoded><![CDATA[
<div> 关键词: THOR、安全推理框架、加密数据、矩阵乘法算法、非线性函数

总结:
THOR是一个针对Transformer模型在加密数据上的安全推理框架。该框架首先提出了基于对角主序编码的新快速矩阵乘法算法，并通过紧凑密文打包技术将其扩展到并行矩阵计算中。其次，设计了用于安全计算softmax、LayerNorm、GELU和Tanh等四个非线性函数的有效协议，这些协议结合了先进的底层近似方法与定制优化。相比现有的HE-based安全推理协议（如Park等人预印本），THOR的新矩阵乘法算法能将BERT-base模型中注意力块线性层中的密钥切换操作减少高达14.5倍。实验结果显示，THOR在单GPU上为BERT-base模型提供安全推理服务的延迟时间为10.43分钟，同时在MRPC数据集上保持了相当的推理精度。 <div>
As language models are increasingly deployed in cloud environments, privacy concerns have become a significant issue. To address this, we design THOR, a secure inference framework for transformer models on encrypted data. Specifically, we first propose new fast matrix multiplication algorithms based on diagonal-major order encoding and extend them to parallel matrix computation through the compact ciphertext packing technique. Second, we design efficient protocols for secure computations of four non-linear functions such as softmax, LayerNorm, GELU, and Tanh, by integrating advanced underlying approximation methods with tailored optimizations. Our matrix multiplication algorithms reduce the number of key-switching operations in the linear layers of the attention block in the BERT-base model by up to 14.5x, compared to the state-of-the-art HE-based secure inference protocol (Park et al., Preprint). Combined with cryptographic optimizations, our experimental results demonstrate that THOR provides secure inference for the BERT-base model with a latency of 10.43 minutes on a single GPU, while maintaining comparable inference accuracy on the MRPC dataset.
]]></content:encoded>
<pubDate>Tue, 19 Nov 2024 02:59:44 +0000</pubDate>
</item>
<item>
<title>Practical Zero-Knowledge PIOP for Public Key and Ciphertext Generation in (Multi-Group) Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1879</link>
<guid>https://eprint.iacr.org/2024/1879</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption (HE), Multi-group HE (MGHE), Zero-knowledge Techniques, Polynomial Interactive Oracle Proof (PIOP), zk-SNARKs

总结:
本文研究了多组态同态加密（MGHE）的安全性证明系统，以确保公钥和密文的正确性。针对恶意敌手场景，文章设计了一种优化的多项式交互式Oracle证明（PIOP）用于MGHE，并能够利用多项式承诺方案（PCS）将其编译为zk-SNARKs。通过使用基于格的PCS实现该PIOP，相较于先前最优构造PELTA（ACM CCS 2023），本文的方法在证明尺寸上减少了5.5倍、证明生成速度提高了70倍、验证时间提升了343倍。此外，提出的PIOP具有模块化特性，可适应其他PCS以进一步优化如减小证明尺寸等其他方面的需求。 <div>
Homomorphic encryption (HE) is a foundational technology in privacy-enhancing cryptography, enabling non-interactive computation over encrypted data. Recently, generalized HE primitives designed for multi-party applications, such as multi-group HE (MGHE), have gained significant research interest.
While constructing secure multi-party protocols from (MG)HE in the semi-honest model is straightforward, zero-knowledge techniques are essential for ensuring security against malicious adversaries.

In this work, we design practical proof systems for MGHE to guarantee the well-formedness of public keys and ciphertexts. Specifically, we develop and optimize a polynomial interactive oracle proof (PIOP) for MGHE, which can be compiled into zk-SNARKs using a polynomial commitment scheme (PCS).

We compile our PIOP using a lattice-based PCS, and our implementation achieves a 5.5x reduction in proof size, a 70x speed-up in proof generation, and a 343x improvement in verification time compared to the previous state-of-the-art construction, PELTA (ACM CCS 2023). Additionally, our PIOPs are modular, enabling the use of alternative PCSs to optimize other aspects, such as further reducing proof sizes.
]]></content:encoded>
<pubDate>Mon, 18 Nov 2024 06:47:14 +0000</pubDate>
</item>
<item>
<title>PerfOMR: Oblivious Message Retrieval with Reduced Communication and Computation</title>
<link>https://eprint.iacr.org/2024/204</link>
<guid>https://eprint.iacr.org/2024/204</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名消息传递、隐私保护、Oblivious Message Retrieval (OMR)、Ring-LWE、效率提升

总结:
文章探讨了如何在不泄露接收者元数据的情况下，利用不可信服务器协助实现匿名消息传递。近期研究提出了使用同态加密技术的Oblivious Message Retrieval (OMR)协议，但存在计算成本高、消息及公钥大小过大的问题。本文针对这一现状，构建了更为高效的OMR方案。首先，提出了一种新的基于Ring-LWE的协议，优化检索电路设计，使homomorphically evaluated的运行时间比先前工作快约$13.8$x倍。其次，设计了一种不同的同态解密电路，通过调整Ring-LWE加密参数，显著减小了公共钥匙的大小（约为先前工作的$235$x），同时降低了消息大小（约$1.6$x）。第二个协议的运行时间为${\sim}40.0$毫秒/条消息，仍然比先前的工作快超过$2.5$x倍。 <div>
Anonymous message delivery, as in privacy-preserving blockchain and private messaging applications, needs to protect recipient metadata: eavesdroppers should not be able to link messages to their recipients. This raises the question: how can untrusted servers assist in delivering the pertinent messages to each recipient, without learning which messages are addressed to whom?

Recent work constructed Oblivious Message Retrieval (OMR) protocols that outsource the message detection and retrieval in a privacy-preserving way, using homomorphic encryption. Their construction exhibits significant costs in computation per message scanned (${\sim}0.1$ second), as well as in the size of the associated messages (${\sim}1$kB overhead) and public keys (${\sim}132$kB).

This work constructs more efficient OMR schemes, by replacing the LWE-based clue encryption of prior works with a Ring-LWE variant, and utilizing the resulting flexibility to improve several components of the scheme. We thus devise, analyze, and benchmark two protocols:

The first protocol focuses on improving the detector runtime, using a new retrieval circuit that can be homomorphically evaluated $13.8$x faster than the prior work.
  
The second protocol focuses on reducing the communication costs, by designing a different homomorphic decryption circuit that allows the parameter of the Ring-LWE encryption to be set such that the public key size is about $235$x smaller than the prior work, and the message size is roughly $1.6$x smaller. The runtime of this second construction is ${\sim}40.0$ms per message, still more than $2.5$x faster than prior works.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 20:54:48 +0000</pubDate>
</item>
<item>
<title>Succinctly Verifiable Computation over Additively-Homomorphically Encrypted Data with Applications to Privacy-Preserving Blueprints</title>
<link>https://eprint.iacr.org/2024/675</link>
<guid>https://eprint.iacr.org/2024/675</guid>
<content:encoded><![CDATA[
<div> 关键词：additively homomorphic encryption (AHE)、non-interactive zero-knowledge proof、ElGamal-based encryption、Camenisch-Shoup cryptosystem、privacy-preserving blueprint (PPB)

总结:
本文介绍了基于加性同态加密（AHE）的非交互式零知识证明系统，该系统能够在不泄露输入密文对应明文的情况下，证明一个密文是通过对多个密文和私有输入进行同态评估某个总度数不超过1的多项式函数得到的结果。证明简洁，其大小仅与私有输入数量和函数中变量的最大度数有关。

文章给出了两种实现方法，分别是基于DDH假设的ElGamal加密和基于DCR假设的Camenisch-Shoup密码系统的变种。这两个证明系统的计算和验证时间与对多项式函数的同态评估相当。

进一步地，文章利用上述简洁的零知识证明系统改进了隐私保护蓝图（PPB）系统。对于特定功能如审计黑名单等，新方案不仅扩展了可高效处理的功能类，例如允许审计员追踪犯罪嫌疑人的电子现金交易；而且对于类似黑名单的功能，将用户托管数据（escrow）的大小从依赖于审计员输入的线性规模降低到了对数规模。同时，文章定义并确保了一个更强的安全性标准，即恶意审计员无法陷害未参与交易的用户。 <div>
With additively homomorphic encryption (AHE), one can compute, from input ciphertexts $\mathsf{Enc}(x_1),\ldots,\mathsf{Enc}(x_n)$, and additional inputs $y_1,\ldots,y_k$, a ciphertext $c_\textit{f}=\mathsf{Enc}(f(x_1,\ldots,x_n,y_1,\ldots, y_k))$ for any polynomial $f$ in which each monomial has total degree at most $1$ in the $x$-variables (but can be arbitrary in the $y$-variables).  For AHE that satisfies a set of natural requirements, we give a non-interactive zero-knowledge proof system (in the random-oracle model) for showing that a ciphertext $c_\textit{f}$ is the result of homomorphically evaluating $f$ on ciphertexts $c_1,\ldots,c_n$ and private inputs $y_1,\ldots,y_k$ that correspond to commitments $C_1,\ldots,C_k$.  Our proofs are $\textit{succinct}$, i.e., their size is independent of the number of ciphertexts $n$, and is instead $O(k\log d)$ where $k$ is the number of private inputs, and $d$ is the maximum degree of any variable in $f$.  

We give two ways of instantiating this framework: with ElGamal-based encryption (under the DDH assumption) and with a variant of the Camenisch-Shoup cryptosystem (under the DCR assumption).  Both yield proof systems where computing and verifying the proof takes a comparable amount of time to homomorphically evaluating $f$.

Next, we show that our framework yields a dramatically improved privacy-preserving blueprint (PPB) system.  Introduced by Kohlweiss, Lysyanskaya, and Nguyen (Eurocrypt'23), an $f$-PPB system allows an auditor with secret input $x$ to create a public encoding $\sf pk$ of the function $f(x,\cdot)$ that reveals nothing about $x$.
Yet, it allows a user to compute an encoding, or escrow $Z$, of the value  $f(x,y)$  on input the user's private data $y$ corresponding to a commitment $C_y$; $Z$ will verifiably correspond to the commitment $C_y$.  The auditor will be able to recover $f(x,y)$ from $Z$, but will learn no other information about $y$.  For example, if $f$ is the watchlist function where $f(x,y)$ outputs $y$ only in the event that $y$ is on the list $x$, then an $f$-PPB allows the auditor to trace watchlisted users in an otherwise anonymous system.  

Using our succinct zero-knowledge proof system for additively homomorphic computation we achieve the following results: (1) We provide efficient schemes for a bigger class of functions $f$; for example, we show how to realize $f$ that would allow the auditor to trace e-cash transactions of a criminal suspect which was previously not efficient. (2) For the watchlist and related functions, we reduce the size of the escrow $Z$ from linear in the size of the auditor's input $x$, to logarithmic.
Additionally, we define and satisfy a stronger notion of security for $f$-PPBs, where a malicious auditor cannot frame a user in a transaction in which the user was not involved in.
]]></content:encoded>
<pubDate>Thu, 02 May 2024 19:49:30 +0000</pubDate>
</item>
<item>
<title>How to Redact the Bitcoin Backbone Protocol</title>
<link>https://eprint.iacr.org/2024/813</link>
<guid>https://eprint.iacr.org/2024/813</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、Redactable区块链、Garay等人( Eurocrypt, 2015)、零知识证明、可扩展性

<br /><br />总结:
本文提出了如何将Garay等人在2015年Eurocrypt会议上提出的比特币主干模型扩展以适应可擦除区块链的方法。该扩展使得区块链能够满足流动性的数据库需求和符合现有法规，例如GDPR中的“被遗忘权”或需要从节点数据库中删除可能引发法律关闭的违规数据。所提出的可擦除主干协议保持了区块链的核心属性，并利用零知识证明技术，无需信任第三方或关于过去链验证的启发式方法即可安全地擦除旧数据。此解决方案可以直接在比特币上立即实施而无需硬分叉，并具有可扩展性。它允许对未确认交易（尚未在网络中广泛传播）以及UTXOs中的数据进行擦除，同时保证比特币状态的一致性，因此，违规数据不必临时甚至永久存在于系统中。 <div>
We explain how to extend the Bitcoin backbone model of Garay et al. (Eurocrypt, 2015) to accommodate for redactable blockchains. Our extension captures fluid blockchain-based databases (with mutability requirements) and compliance with existing legislation, such as the GDPR right to be forgotten, or the need to erase offending data from nodes’ databases that would otherwise provoke legal shutdowns. Our redactable backbone protocol retains the essential properties of blockchains. Leveraging zero-knowledge proofs, old data can be erased without requiring trusted third parties or heuristics about past chain validation. Our solution can be implemented on Bitcoin immediately without hard-forks, and it is scalable. It allows the redaction of data from UTXOs or unconfirmed transactions that have not yet flooded the network, while guaranteeing invariance of the Bitcoin state. Thus, offending data does not need to persist in the system, not even temporarily.
]]></content:encoded>
<pubDate>Fri, 24 May 2024 15:58:09 +0000</pubDate>
</item>
<item>
<title>Multi-Holder Anonymous Credentials from BBS Signatures</title>
<link>https://eprint.iacr.org/2024/1874</link>
<guid>https://eprint.iacr.org/2024/1874</guid>
<content:encoded><![CDATA[
<div> 关键词：eIDAS 2.0、匿名凭证、多持有者匿名凭证方案、安全性、不可伪造性

总结:<br />
eIDAS 2.0法规旨在为欧洲公民开发互操作性的数字身份，并已生效。该法规要求凭证不可链接，而匿名凭证允许用户证明其身份属性而不透露身份或防止不同使用情境下的凭证关联，因此可能成为欧洲数字身份的技术基础。本文提出了一种多持有者匿名凭证方案的概念，其中认证因素（或“持有者”）会收到凭证的份额，并需联合运行阈值展示协议来出示凭证。安全定义要求该方案具有不可伪造性，即对手不能成功展示与所控制的身份不匹配的凭证；即使对手可以获取其所选择的凭证并导致并发执行展示协议也是如此。此外，展示协议还需具备可识别的中止安全性。同时，所有诚实持有者的展示必须不可链接，并且不能向控制了用户部分认证因素的对手泄露用户的秘密身份属性。文章设计并证明了一个基于BBS匿名凭证方案的多持有者版本的安全性（包括并发安全性）。在此构造中，每个持有者都会获得一份BBS凭证的秘密份额。利用这些份额，持有者们共同计算出与传统单持有者版本（由Tessaro和Zhu在Eurocrypt'23上提出）相同的BBS凭证展示。 <div>
The eIDAS 2.0 regulation aims to develop interoperable digital identities for European citizens, and it has recently become law.  One of its requirements is that credentials be unlinkable.  Anonymous credentials (AC) allow holders to prove statements about their identity in a way that does not require to reveal their identity and does not enable linking different usages of the same credential. As a result,  they are likely to become the technology that provides digital identity for Europeans.

Any digital credential system, including anonymous credentials, needs to be secured against identity theft and fraud.  In this work, we introduce the notion of a multi-holder anonymous credential scheme that allows issuing shares of credentials to different authentication factors (or ``holders''). To present the credential, the user's authentication factors jointly run a threshold presentation protocol.  Our definition of security requires that the scheme provide unforgeability: the adversary cannot succeed in presenting a credential with identity attributes that do not correspond to an identity for which the adversary controls at least $t$ shares; this is true even if the adversary can obtain credentials of its choice and cause concurrent executions of the presentation protocol.  Further, our definition requires that the presentation protocol provide security with identifiable abort.  Finally, presentations generated by all honest holders must be unlinkable and must not reveal the user's secret identity attributes even to an adversary that controls some of the user's authentication factors.

We design and prove the (concurrent) security of a multi-holder version of the BBS anonymous credential scheme. In our construction, each holder is issued a secret share of a BBS credential. 
Using these shares, the holders jointly compute a credential presentation that is identical to (and therefore compatible with) the traditional, single-holder variant (due to Tessaro and Zhu, Eurocrypt'23) of a BBS credential presentation.
]]></content:encoded>
<pubDate>Sat, 16 Nov 2024 04:34:07 +0000</pubDate>
</item>
<item>
<title>IMOK: A compact connector for non-prohibition proofs to privacy-preserving applications</title>
<link>https://eprint.iacr.org/2024/1868</link>
<guid>https://eprint.iacr.org/2024/1868</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私保护应用、制裁名单、禁止名单、用户验证、Freedom Tool、投票解决方案、生物护照、列表管理、版本控制、过滤数据集、组合列表、其他隐私保护应用

总结:<br />
本文提出了一种针对隐私保护应用的扩展方案，该方案旨在让用户在执行特定操作时能够证明自己不在制裁或禁止名单中，同时无需泄露敏感信息。以将此方案应用于基于生物护照的投票解决方案——Freedom Tool为例，文章探讨了如何整合这一方法到应用程序中，并考虑了制裁名单的管理方式、版本原则、配置过滤数据集、合并不同名单的方法以及如何将其运用到其他隐私保护应用中的可能性。 <div>
This article proposes an extension for privacy-preserving applications to introduce sanctions or prohibition lists. When initiating a particular action, the user can prove, in addition to the application logic, that they are not part of the sanctions lists (one or more) without compromising sensitive data. We will show how this solution can be integrated into applications, using the example of extending Freedom Tool (a voting solution based on biometric passports). We will also consider ways to manage these lists, versioning principles, configuring the filter data set, combining different lists, and using the described method in other privacy-preserving applications.
]]></content:encoded>
<pubDate>Fri, 15 Nov 2024 11:15:35 +0000</pubDate>
</item>
<item>
<title>Randomness Bounds for Private Simultaneous Messages and Conditional Disclosure of Secrets</title>
<link>https://eprint.iacr.org/2021/1037</link>
<guid>https://eprint.iacr.org/2021/1037</guid>
<content:encoded><![CDATA[
<div> 关键词：私有同时消息（PSM），条件秘密披露（CDS），随机字符串长度，通信复杂度，随机性下界

总结:
文章探讨了在加密学中$k$-党派的私有同时消息（PSM）和条件秘密披露（CDS）协议，关注于带有公共随机字符串的函数$f$的最优随机字符串长度（随机性复杂度）以及完美和统计隐私条件下的界限。首先，建立了消息总长度（通信复杂度）与随机字符串长度之间的通用联系。其次，为PSM和CDS协议的一般函数证明了随机性下界。对于具有完美隐私的PSM协议，文章证明了一般的连接关系为$\lambda - 1 \leq \rho$，并进一步得出在普遍重构条件下，对于一般函数$f:(\{0,1\}^n)^k\rightarrow\{0,1\}$，随机性复杂度至少为$2^{(k-1)n}-1$，这意味着Feige-Killian-Naor的PSM协议是针对一般函数的最优方案。此外，还证明了对于广义内积函数，随机性下界为$\rho > kn-2$，这证实了Liu、Vaikuntanathan和Wee提出的两党派PSM协议对于内积函数的最优性。对于具有完美隐私的CDS协议，展示了随机字符串长度与消息长度和秘密长度之间的关系$\rho \geq \lambda - \sigma$，并得到了对于XOR、AND和广义内积函数的随机性下界为$\rho \geq (k-1)\sigma$，从而表明Applebaum和Arkis的$k$-党派CDS协议对于一般函数在大$k$情况下具有常数因子内的最优性。 <div>
In cryptography, the private simultaneous messages (PSM) and conditional disclosure of secrets (CDS) are closely related fundamental primitives. We consider $k$-party PSM and CDS protocols for a function $f$ with a common random string, where each party $P_i$ generates a message and sends it to a referee $P_0$. We consider bounds for the optimal length $\rho$ of the common random string among $k$ parties (or, {\it randomness complexity}) in PSM and CDS protocols with perfect and statistical privacy through combinatorial and entropic arguments. ($i$) We provide general connections from the optimal total length $\lambda$ of the messages (or, {\it communication complexity}) to the randomness complexity $\rho$. ($ii$) We also prove randomness lower bounds in PSM and CDS protocols for general functions. ($iii$) We further prove randomness lower bounds for several important explicit functions. They contain the following results: For PSM protocols with perfect privacy, we prove $\lambda-1 \le \rho$ as the general connection. From the general lower bound, we prove $\rho\ge 2^{(k-1)n}-1$ for a general function $f:(\{0,1\}^n)^k\rightarrow\{0,1\}$ under universal reconstruction, in which $P_0$ is independent of $f$. This implies that the Feige-Killian-Naor PSM protocol for a general function [Proc.~STOC '94, pp.554--563] is optimal with respect to randomness complexity.  We also provide a randomness lower bound $\rho> kn-2$ for a generalized inner product function. This implies the optimality of the $2$-party PSM protocol for the inner-product function of Liu, Vaikuntanathan, and Wee [Proc.~CRYPTO 2017, pp.758--790]. For CDS protocols with perfect privacy, we show $\rho\ge\lambda-\sigma$ as the general connection by similar argument to those for PSM protocols, where $\sigma$ is the length of secrets. We also obtain randomness lower bounds $\rho\ge (k-1)\sigma$ for XOR, AND, and generalized inner product functions. These imply the optimality of Applebaum and Arkis's $k$-party CDS protocol for a general function [Proc. TCC 2018, pp.317--344] up to a constant factor in a large $k$.
]]></content:encoded>
<pubDate>Mon, 16 Aug 2021 13:08:24 +0000</pubDate>
</item>
<item>
<title>Distributed Differential Privacy via Shuffling vs Aggregation: a Curious Study</title>
<link>https://eprint.iacr.org/2023/1764</link>
<guid>https://eprint.iacr.org/2023/1764</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式差分隐私、shuffle模型、本地DP模型、私有聚合、协议准确性

总结:
文章探讨了分布式差分隐私在无信任中心情况下的实现方法，重点关注shuffle模型和私有聚合模型。shuffle模型引入一个未受信任的混排器来随机排列用户已经局部随机化的数据，从而实现更好的隐私保护效果和更高的数据准确性。然而，研究发现，尽管shuffle模型具有隐私放大效应，但在与私有聚合模型的首次比较研究中，并未明显显示出优势。事实上，私有聚合模型在隐私放大、功能实现、协议准确性和实用性等多个方面，有时甚至显著优于shuffle模型。因此，两种模型各有优劣，具体应用场景应根据实际需求选择。 <div>
How to achieve distributed differential privacy (DP) without a trusted central party is of great interest in both theory and practice. Recently, the shuffle model has attracted much attention. Unlike the local DP model in which the users send randomized data directly to the data collector/analyzer, in the shuffle model an intermediate untrusted shuffler is introduced to randomly permute the data, which have already been randomized by the users, before they reach the analyzer. The most appealing aspect is that while shuffling does not explicitly add more noise to the data, it can make privacy better. The privacy amplification effect in consequence means the users need to add less noise to the data than in the local DP model, but can achieve the same level of differential privacy. Thus, protocols in the shuffle model can provide better accuracy than those in the local DP model. What looks interesting to us is that the architecture of the shuffle model is similar to private aggregation, which has been studied for more than a decade. In private aggregation, locally randomized user data are aggregated by an intermediate untrusted aggregator. Thus, our question is whether aggregation also exhibits some sort of privacy amplification effect? And if so, how good is this ``aggregation model'' in comparison with the shuffle model. We conducted the first comparative study between the two, covering privacy amplification, functionalities, protocol accuracy, and practicality. The results as yet suggest that the new shuffle model does not have obvious advantages over the old aggregation model. On the contrary, protocols in the aggregation model outperform those in the shuffle model, sometimes significantly, in many aspects.
]]></content:encoded>
<pubDate>Wed, 15 Nov 2023 03:05:42 +0000</pubDate>
</item>
<item>
<title>Carbon Footprint Traction System Incorporated as Blockchain</title>
<link>https://eprint.iacr.org/2024/1863</link>
<guid>https://eprint.iacr.org/2024/1863</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链技术、碳足迹跟踪系统、tokenization、智能合约、环境可持续性

总结:<br />
本文提出了一个利用前瞻性的方法解决环境可持续性问题的方案，即构建基于区块链技术的碳足迹追踪系统，并结合tokenization使其日常使用更为便捷高效。该系统将碳足迹数据视为可交易和分享的、具有货币价值的 fungible utility 代币。文章分析了区块链技术如何为全球碳追踪系统所带来的挑战提供有效解决方案，并提出一个具体的使用案例，详细阐述了区块链平台的关键特性以及系统内各方角色和用户交互方式。最终，文章建议采用区块链技术、智能合约及tokenization相结合的方式进行碳足迹管理。 <div>
This article tries to offer a solution to an environmental sustainability problem using a forward-thinking approach and tries to construct a carbon footprint tracking system based on blockchain technology while also introducing tokenization intertwined with the blockchain to make everyday use as accessible and effective as possible.
This effort aims to provide a solid use case for environmental sustainability and lays the groundwork of a new generation social construct where carbon footprint is a valuable unit like money next to the other important tokenized attributes a person can possibly hold. The study proposes a blockchain-based solution to store the data. Through tokenization, the transacting and sharing is facilitated. As a result, carbon footprint data can be treated as a fungible utility token.
The article tries to explain how and which blockchain technology offers an effective solution to challenges in global carbon tracking systems. In this context, a use case was proposed. The critical features of the blockchain-based platform are examined. In addition, the roles of parties and user interactions within the system are detailed.
In conclusion, this article proposes the adaptation of blockchain technology together with smart contracts and tokenization to the management of carbon footprints.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 13:26:12 +0000</pubDate>
</item>
<item>
<title>BatchZK: A Fully Pipelined GPU-Accelerated System for Batch Generation of Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2024/1862</link>
<guid>https://eprint.iacr.org/2024/1862</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、GPU加速、批量生成、流水线、高性能

总结:
我们提出了一种完全流水线化的GPU加速系统，用于批量生成零知识证明。该系统有三个特点以提高吞吐量：<br />
1. 设计了流水线化的方法，使每个GPU线程能持续执行其指定的证明生成任务，避免空闲。
<br />
2. 系统支持高效的ZKP协议，包括求和检查协议、默克尔树和线性时间编码器，并对其计算模块进行了定制，以适应流水线执行。
<br />
3. 采用动态加载方法减少证明生成所需设备内存，并利用多流技术重叠数据传输与GPU计算，降低主机与设备间的数据交换开销。

实验证明，相比于现有最先进的GPU加速系统，我们的系统实现了超过259.5倍的更高吞吐量。此外，在可验证机器学习应用中，我们的系统能够实现每秒生成9.52个证明，首次在此领域成功实现亚秒级证明生成。 <div>
Zero-knowledge proof (ZKP) is a cryptographic primitive that enables one party to prove the validity of a statement to other parties without disclosing any secret information. With its widespread adoption in applications such as blockchain and verifiable machine learning, the demand for generating zero-knowledge proofs has increased dramatically. In recent years, considerable efforts have been directed toward developing GPU-accelerated systems for proof generation. However, these previous systems only explored efficiently generating a single proof by reducing latency rather than batch generation to provide high throughput.

We propose a fully pipelined GPU-accelerated system for batch generation of zero-knowledge proofs. Our system has three features to improve throughput. First, we design a pipelined approach that enables each GPU thread to continuously execute its designated proof generation task without being idle. Second, our system supports recent efficient ZKP protocols with their computational modules: sum-check protocol, Merkle tree, and linear-time encoder. We customize these modules to fit our pipelined execution. Third, we adopt a dynamic loading method for the data required for proof generation, reducing the required device memory. Moreover, multi-stream technology enables the overlap of data transfers and GPU computations, reducing overhead caused by data exchanges between host and device memory.

We implement our system and evaluate it on various GPU cards. The results show that our system achieves more than 259.5× higher throughput compared to state-of-the-art GPU-accelerated systems. Moreover, we deploy our system in the verifiable machine learning application, where our system generates 9.52 proofs per second, successfully achieving sub-second proof generation for the first time in this field.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 10:42:07 +0000</pubDate>
</item>
<item>
<title>Fully Encrypted Machine Learning Protocol using Functional Encryption</title>
<link>https://eprint.iacr.org/2024/1859</link>
<guid>https://eprint.iacr.org/2024/1859</guid>
<content:encoded><![CDATA[
<div> 关键词: 隐私保护机器学习, 全同态加密, 多方安全计算, 功能性加密, 两层神经网络

总结:
本文提出了一种基于功能性加密的完全加密隐私保护机器学习协议，该协议首次实现了对加密数据上任意复杂函数的评估，同时在计算过程中无信息泄漏。为实现这一目标，文章构建了一个针对二次多项式的向量功能加密方案，并将其与内积加密方案相结合，使得可以多次组合二次多项式以加密方式计算任意复杂的函数。此协议在恶意模型下具有安全性，即即使对手偏离协议，也无法获取输入数据的任何信息。此外，文中展示了如何使用该协议构建一个带有二次激活函数的全加密两层神经网络模型并给出了实验结果。<br /><br /> <div>
As privacy concerns have arisen in machine learning, privacy-preserving machine learning (PPML) has received significant attention. Fully homomorphic encryption (FHE) and secure multi-party computation (MPC) are representative building blocks for PPML. However, in PPML protocols based on FHE and MPC, interaction between the client (who provides encrypted input data) and the evaluator (who performs the computation) is essential to obtain the final result in plaintext. 
Functional encryption (FE) is a promising candidate to remove this constraint, but existing FE-based PPML protocols are restricted to evaluating only simple ML models, such as one-layer neural networks, or they support partially encrypted PPML, which makes them vulnerable to information leakage beyond the inference results.

In this paper, we propose a fully encrypted FE-based PPML protocol, which supports the evaluation of arbitrary functions over encrypted data with no information leakage during computation, for the first time. 
To achieve this, we newly construct a vector functional encryption scheme for quadratic polynomials and combine it with an inner product encryption scheme. This enables multiple compositions of quadratic polynomials to compute arbitrary complex functions in an encrypted manner. 

Our FE-based PPML protocol is secure in the malicious model, which means that an adversary cannot obtain any information about the input data even though they intentionally deviate from the protocol. 
We then show how to use our protocol to build a fully encrypted 2-layer neural network model with quadratic activation functions and present experimental results.
]]></content:encoded>
<pubDate>Thu, 14 Nov 2024 02:13:15 +0000</pubDate>
</item>
<item>
<title>Lova: A Novel Framework for Verifying Mathematical Proofs with Incrementally Verifiable Computation</title>
<link>https://eprint.iacr.org/2024/1855</link>
<guid>https://eprint.iacr.org/2024/1855</guid>
<content:encoded><![CDATA[
<div> 关键词：Incrementally Verifiable Computation (IVC)，Nova recursive SNARKs，Lova，proof splicing，multiplexing circuit

总结:
本文提出了一个名为Lova的新颖框架，用于高效验证数学证明。该框架解决了现有Incrementally Verifiable Computation方法（如Nova递归SNARKs）的一些限制，特别是对于线性证明和相同步骤的要求。Lova的主要创新点包括：<br />
1. 引入了创新的证明拼接机制，能够生成独立的证明序列；
2. 开发了一套线性算法系统，可以验证多种数学逻辑规则；
3. 提出了一种新颖的多路复用电路，允许不同类型的证明序列在一个Nova证明中同时被验证。
此外，Lova实现了一个具有线性时间复杂度的证明者时间、常数级别的验证能力、动态/易于修改以及可选的零知识隐私保护功能的验证流程。相关代码可在https://github.com/noelkelias/lova获取。 <div>
Efficiently verifying mathematical proofs and computations has been a heavily researched topic within Computer Science. Particularly, even repetitive steps within a proof become much more complex and inefficient to validate as proof sizes grow. To solve this problem, we suggest viewing it through the lens of  Incrementally Verifiable Computation (IVC). However, many IVC methods, including the state-of-the-art Nova recursive SNARKs, require proofs to be linear and for each proof step to be identical. This paper proposes Lova, a novel framework to verify mathematical proofs end-to-end that solves these problems. Particularly, our approach achieves a few novelties alongside the first-of-its-kind implementation of Nova: (i) an innovative proof splicing mechanism to generate independent proof sequences, (ii) a system of linear algorithms to verify a variety of mathematical logic rules, and (iii) a novel multiplexing circuit allowing non-homogeneous proof sequences to be verified together in a single Nova proof. The resulting Lova pipeline has linear prover time, constant verifying capability, dynamic/easy modification, and optional zero-knowledge privacy to efficiently validate mathematical proofs. Code is available at https://github.com/noelkelias/lova.
]]></content:encoded>
<pubDate>Wed, 13 Nov 2024 04:23:00 +0000</pubDate>
</item>
<item>
<title>Secure Transformer-Based Neural Network Inference for Protein Sequence Classification</title>
<link>https://eprint.iacr.org/2024/1851</link>
<guid>https://eprint.iacr.org/2024/1851</guid>
<content:encoded><![CDATA[
<div> 关键词: 蛋白质序列分类、大型语言模型、隐私保护、加密DASHformer、 Homomorphic加密

总结:
本文提出了一个名为“加密DASHformer”的隐私保护协议，用于利用 homomorphic 加密技术对蛋白质序列进行分类。该协议适用于 transformer 基于的神经网络 DASHformer，源自 iDASH 2024-Track 1 竞赛提供的任务。此方案是首个仅使用分级同态加密（无需引导）实现批量多蛋白质序列分类的安全变压器推理协议。为达成这一目标，文章创新性地提出了一系列新方法和算法优化，包括数据驱动的非多项式函数拟合、张量打包以及双婴儿步-巨人步算法来计算多个加密矩阵的乘积。这些技术和改进使得协议能在约165秒内完成对163条加密蛋白质序列的分类，达到每条序列平均耗时约一秒钟的高效性能，并确保了128位安全性。这一方案在解决蛋白质序列分类问题的同时，有效地保护了数据隐私。 <div>
Protein sequence classification is crucial in many research areas, such as predicting protein structures and discovering new protein functions. Leveraging large language models (LLMs) is greatly promising to enhance our ability to tackle protein sequence classification problems; however, the accompanying privacy issues are becoming increasingly prominent. In this paper, we present a privacy-preserving, non-interactive, efficient, and accurate protocol called encrypted DASHformer to evaluate a transformer-based neural network for protein sequence classification named DASHformer, provided by the iDASH 2024-Track 1 competition.  The presented protocol is based on our solution for this competition, which won the first place. It is arguably the first secure transformer inference protocol capable of performing batch classification for multiple protein sequences in a single execution only using leveled homomorphic encryption (i.e., without bootstrapping). To achieve this, we propose a series of new techniques and algorithmic improvements, including data-driven non-polynomial function fitting, tensor packing, and double baby-step-giant-step for computing the product of multiple encrypted matrices. These techniques and improvements enable the protocol to classify $163$ encrypted protein sequences in about $165$ seconds with $128$-bit security, achieving an amortized time of about one second per sequence.
]]></content:encoded>
<pubDate>Tue, 12 Nov 2024 10:30:24 +0000</pubDate>
</item>
<item>
<title>Rotatable Zero Knowledge Sets: Post Compromise Secure Auditable Dictionaries with application to Key Transparency</title>
<link>https://eprint.iacr.org/2022/1264</link>
<guid>https://eprint.iacr.org/2022/1264</guid>
<content:encoded><![CDATA[
<div> 关键词: Key Transparency, 隐私保护, 服务器妥协, 可旋转零知识集 (RZKS), 可旋转可验证随机函数 (Rotatable VRF)

总结:
本文关注的是构建具备后妥协安全性的键透明性系统（Key Transparency, KT），尤其是针对现有方案在服务器遭受攻击后的隐私恢复问题。为解决这一问题，文章提出了一个新的抽象概念——可旋转零知识集 (Rotatable Zero-Knowledge Set, RZKS)，它能实现Post-Compromise Security（PCS）并保持审计属性。此外，RZKS还具有更强的可提取声望性和允许通信方高效“追赶”当前纪元同时确保服务器未删除任何历史数据的能力。文中还引入了一个新的原语——可旋转可验证随机函数 (Rotatable Verifiable Random Function, RVRF)，并展示了如何通过可旋转VRF、有序累加器和只追加向量承诺方案来模块化地构建RZKS。 <div>
Key Transparency (KT) systems allow end-to-end encrypted service providers (messaging, calls, etc.) to maintain an auditable directory of their users’ public keys, producing proofs that all participants have a consistent view of those keys, and allowing each user to check updates to their own keys. KT has lately received a lot of attention, in particular its privacy preserving variants, which also ensure that users and auditors do not learn anything beyond what is necessary to use the service and keep the service provider accountable. 

Abstractly, the problem of building such systems reduces to constructing so-called append-only Zero-Knowledge Sets (aZKS). Unfortunately, existing aZKS (and KT) solutions do not allow to adequately restore the privacy guarantees after a server compromise, a form of Post-Compromise Security (PCS), while maintaining the auditability properties. In this work we address this concern through the formalization of an extension of aZKS called Rotatable ZKS (RZKS). In addition to providing PCS, our notion of RZKS has several other attractive features, such as a stronger (extractable) soundness notion, and the ability for a communication party with out-of-date data to efficiently “catch up” to the current epoch while ensuring that the server did not erase any of the past data. 

Of independent interest, we also introduce a new primitive called a Rotatable Verifiable Random Function (VRF), and show how to build RZKS in a modular fashion from a rotatable VRF, ordered accumulator, and append-only vector commitment schemes.
]]></content:encoded>
<pubDate>Fri, 23 Sep 2022 20:27:51 +0000</pubDate>
</item>
<item>
<title>MixBuy: Contingent Payment in the Presence of Coin Mixers</title>
<link>https://eprint.iacr.org/2024/953</link>
<guid>https://eprint.iacr.org/2024/953</guid>
<content:encoded><![CDATA[
<div> 关键词: 继承支付协议、区块链、混淆器、unlinkable 继承支付（UCP）、MixBuy

总结:
本文提出了一个名为MixBuy的系统，实现了unlinkable 继承支付（UCP），这是一种在买家购买数字产品时通过不可信混淆器路由支付的方式，同时确保支付过程中的 unlinkability，即混淆器和其他观察者无法得知哪个买家向哪个卖家付款。为了实现这一目标，文章提出了一种基于预言机的unlinkable 继承支付（O-UCP）四方加密协议，该协议要求四个安全属性：(i) 混淆器安全性，保证如果混淆器向卖家付款，则混淆器必须从买家那里获得付款；(ii) 卖家安全性，保证如果卖家向买家交付产品，卖家必须从混淆器处获得付款；(iii) 买家安全性，保证如果买家向混淆器付款，买家必须获得产品；以及(iv) 不可链接性，保证混淆器不应知道哪些买家向哪些卖家付款。文中给出了一个经过形式化安全证明和高效实施的O-UCP构造方案，适用于大多数区块链，因为其功能需求最小（例如只需数字签名和时间锁）。为了展示其实用性，文章提供了O-UCP的概念验证及性能基准测试，结果显示通信开销小（每条消息仅几kB）且运行时间低于一秒。 <div>
A contingent payment protocol involves two mutually distrustful parties,  a buyer and a seller, operating on the same blockchain, and a digital product, whose ownership is not tracked on a blockchain (e.g. a digital book). The buyer holds coins on the blockchain and transfers them to the seller in exchange for the product.  However, if the blockchain does not hide transaction details, any observer can learn that a buyer purchased some product from a seller.

    In this work, we take contingent payment a step further: we consider a buyer who wishes to buy a digital product from a seller routing the payment via an untrusted mixer.
    Crucially, we require that said payment is unlinkable, meaning that the mixer (or any other observer) does not learn which buyer is paying  which seller. We refer to such setting as unlinkable contingent payment (UCP).
    
    We present MixBuy,  a system that realizes UCP. Mixbuy relies on oracle-based unlinkable contingent payment (O-UCP), a novel four-party cryptographic protocol where the mixer pays the seller and the seller provides the buyer with the product only if a semi-trusted notary attests that the buyer has paid the mixer. More specifically, we require four security notions: (i) mixer security that guarantees that if the mixer pays the seller, the mixer must get paid from the buyer; (ii) seller security that guarantees that if the seller delivers the product to the buyer, the seller must get paid from the mixer; (iii) buyer security that guarantees that if the buyer pays the mixer, the buyer must obtain the product; and  (iv) unlinkability that guarantees that given a set of buyers and sellers, the mixer should not learn which buyer paid which seller.

    We present a provably secure and efficient cryptographic construction for O-UCP. Our construction can be readily used to realize UCP on most blockchains, as it has minimal functionality requirements (i.e., digital signatures and timelocks). To demonstrate the practicality of our construction, we provide a proof of concept for O-UCP and our benchmarks in commodity hardware show that the communication overhead is small (a few kB per message) and the running time is below one second.
]]></content:encoded>
<pubDate>Thu, 13 Jun 2024 15:27:21 +0000</pubDate>
</item>
<item>
<title>The LaZer Library: Lattice-Based Zero Knowledge and Succinct Proofs for Quantum-Safe Privacy</title>
<link>https://eprint.iacr.org/2024/1846</link>
<guid>https://eprint.iacr.org/2024/1846</guid>
<content:encoded><![CDATA[
<div> 关键词: 硬度、格问题、量子安全加密、零知识证明、简洁证明库

总结:
文章介绍了基于格问题硬度的量子安全加密技术，特别是其中的零知识证明领域取得了显著效率提升，并为许多场景提供了最短、最高效的证明。然而，非专家使用这些证明时面临诸多挑战，因为它们内部参数依赖于特定实例。为此，文中提出了一款简洁而高效的C代码库，其上层封装了易于使用的Python接口，使用户无需了解格基础证明知识，只需指定要证明的格关系和范数约束，库就能自动生成相应的证明系统。该库支持LaBRADOR或Lyubashevsky等人提出的两种证明方案。通过Python接口，用户还能进行常见的 lattice 基础密码学操作，方便在简单的Python环境中编写和原型化完整协议。文章以盲签协议、匿名凭据、Swoosh协议所需的零知识证明、Kyber密钥知识证明以及聚合签名方案等为例，展示了该库的应用价值，表明这些实现从尺寸、速度和内存角度讲，均是最优的量子安全实例。 <div>
The hardness of lattice problems offers one of the most promising
security foundations for quantum-safe cryptography. Basic schemes
for public key encryption and digital signatures are already close to
standardization at NIST and several other standardization bodies,
and the research frontier has moved on to building primitives with
more advanced privacy features. At the core of many such primi-
tives are zero-knowledge proofs. In recent years, zero-knowledge
proofs for (and using) lattice relations have seen a dramatic jump
in efficiency and they currently provide arguably the shortest, and
most computationally efficient, quantum-safe proofs for many sce-
narios. The main difficulty in using these proofs by non-experts
(and experts!) is that they have a lot of moving parts and a lot of
internal parameters depend on the particular instance that one is
trying to prove.
Our main contribution is a library for zero-knowledge and suc-
cinct proofs which consists of efficient and flexible C code under-
neath a simple-to-use Python interface. Users without any back-
ground in lattice-based proofs should be able to specify the lattice
relations and the norm bounds that they would like to prove and the
library will automatically create a proof system, complete with the
intrinsic parameters, using either the succinct proofs of LaBRADOR
(Beullens and Seiler, Crypto 2023) or the linear-size, though smaller
for certain application, proofs of Lyubashevsky et al. (Crypto 2022).
The Python interface also allows for common operations used in
lattice-based cryptography which will enable users to write and pro-
totype their full protocols within the syntactically simple Python
environment.
We showcase some of the library’s usefulness by giving protocol
implementations for blind signatures, anonymous credentials, the
zero-knowledge proof needed in the recent Swoosh protocol (Gaj-
land et al., Usenix 2024), proving knowledge of Kyber keys, and an
aggregate signature scheme. Most of these are the most efficient,
from a size, speed, and memory perspective, known quantum-safe
instantiations.
]]></content:encoded>
<pubDate>Sun, 10 Nov 2024 18:41:01 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Location Privacy via Accurate Floating-Point SNARKs</title>
<link>https://eprint.iacr.org/2024/1842</link>
<guid>https://eprint.iacr.org/2024/1842</guid>
<content:encoded><![CDATA[
<div> 关键词: Zero-Knowledge Location Privacy (ZKLP), Zero-Knowledge Proof (ZKP), IEEE 754标准, 浮点运算, 隐私保护

总结:
本文介绍了零知识位置隐私（ZKLP）技术，该技术允许用户向第三方证明他们位于特定地理区域内，而不泄露其精确位置。ZKLP支持不同级别的粒度，可以根据具体应用场景进行定制。为了实现ZKLP，研究者首次提出了完全符合IEEE 754浮点运算标准的ZKP电路。实验结果显示，这些浮点电路具有高效的摊还性能，对于$2^{15}$个单精度浮点数乘法操作，每个乘法仅需$64$个约束条件。利用这一浮点数实现，成功地实现了ZKLP范式。与基准方案相比，使用单精度浮点值优化后的实现方案约束条件减少了$15.9\times$，而使用双精度浮点值则减少了$12.2\times$。为了验证ZKLP的实用性，文章构建了一个隐私保护的点对点近邻测试协议，使得Alice无需透露任何其他地理位置信息就能通过接收一条消息来判断自己是否接近Bob。在这种配置下，Bob可以在$0.26s$内创建一个（非）接近性的证明，而Alice每秒可以验证约$470$个同伴的距离。 <div>
We introduce Zero-Knowledge Location Privacy (ZKLP), enabling users to prove to third parties that they are within a specified geographical region while not disclosing their exact location. ZKLP supports varying levels of granularity, allowing for customization depending on the use case. To realize ZKLP, we introduce the first set of Zero-Knowledge Proof (ZKP) circuits that are fully compliant to the IEEE 754 standard for floating-point arithmetic.
  Our results demonstrate that our floating point circuits amortize efficiently, requiring only $64$ constraints per multiplication for $2^{15}$ single-precision floating-point multiplications. We utilize our floating point implementation to realize the ZKLP paradigm. In comparison to a baseline, we find that our optimized implementation has $15.9 \times$ less constraints utilizing single precision floating-point values, and $12.2 \times$ less constraints when utilizing double precision floating-point values. We demonstrate the practicability of ZKLP by building a protocol for privacy preserving peer-to-peer proximity testing - Alice can test if she is close to Bob by receiving a single message, without either party revealing any other information about their location. In such a configuration, Bob can create a proof of (non-)proximity in $0.26 s$, whereas Alice can verify her distance to about $470$ peers per second.
]]></content:encoded>
<pubDate>Sat, 09 Nov 2024 13:29:56 +0000</pubDate>
</item>
<item>
<title>Cryptographically Secure Digital Consent</title>
<link>https://eprint.iacr.org/2024/1839</link>
<guid>https://eprint.iacr.org/2024/1839</guid>
<content:encoded><![CDATA[
<div> 关键词: 数字同意、加密安全、第三方服务、客户端、身份管理器

总结:
本文提出了一个灵活且加密安全的数字同意方案，以适应不同的在线应用场景并确保同意过程的完整性。该框架涉及客户端（指用户或其设备）、身份管理器（负责认证客户端）和代理（在获得同意后执行操作）。客户端仅需记住一个密码，方案着重解决了防止离线词典攻击、确保不可否认的同意证明以及防止代理人未经授权的操作等安全与隐私挑战。即使身份管理器或代理被妥协，只要不同时发生，仍能保持安全性。文中所指的身份管理器可以包括多种认证因素的组合，如密码、智能手机、安全设备、生物特征或电子护照，并通过签署PDF文档、电子银行和密钥恢复等多个应用实例进行了演示。 <div>
In the digital age, the concept of consent for online actions executed by third parties is crucial for maintaining trust and security in third-party services. 
This work introduces the notion of cryptographically secure digital consent, which aims to replicate the traditional consent process in the online world. 
We provide a flexible digital consent solution that accommodates different use cases and ensures the integrity of the consent process.

The proposed framework involves a client (referring to the user or their devices), an identity manager (which authenticates the client), and an agent (which executes the action upon receiving consent). 
It supports various applications and ensures compatibility with existing identity managers. 
We require the client to keep no more than a password. The design addresses several security and privacy challenges, including preventing offline dictionary attacks, ensuring non-repudiable consent, and preventing unauthorized actions by the agent. 
Security is maintained even if either the identity manager or the agent is compromised, but not both.

Our notion of an identity manager is broad enough to include combinations of different authentication factors such as a password, a smartphone, a security device, biometrics, or an e-passport. We demonstrate applications for signing PDF documents, e-banking, and key recovery.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 20:24:02 +0000</pubDate>
</item>
<item>
<title>A Query Reconstruction Attack on the Chase-Shen Substring-Searchable Symmetric Encryption Scheme</title>
<link>https://eprint.iacr.org/2024/1837</link>
<guid>https://eprint.iacr.org/2024/1837</guid>
<content:encoded><![CDATA[
<div> 关键词：可搜索对称加密（SSE）、泄漏分析、子串查询、Chase和Shen方案、攻击模型

<br /><br />总结:
本文首次针对Chase和Shen在 PoPETS '15 提出的子串可搜索对称加密（substring-SSE）方案进行了泄漏分析。研究中，作者提出了一个创新的基于推理的查询重建攻击方法，该方法利用了该方案实际泄漏概况的一个简化版本，并假设了一个比原方案声称的安全模型更为宽松的攻击模型。作者已实现并实验验证了此攻击的成功率和效率，它在包含10万条字符串的真实世界数据集上实现了高查询重建率，并能有效扩展到大规模数据集。据所知，这是至今为止对任何子串-SSE方案的第一个也是唯一一个查询重建攻击，以及第一次系统性的泄漏分析。 <div>
Searchable symmetric encryption (SSE) enables queries over symmetrically encrypted databases. To achieve practical efficiency, SSE schemes incur a certain amount of leakage; however, this leads to the possibility of leakage cryptanalysis, i.e., cryptanalytic attacks that exploit the leakage from the target SSE scheme to subvert its data and query privacy guarantees. Leakage cryptanalysis has been widely studied in the context of SSE schemes supporting either keyword queries or range queries, often with devastating consequences. However, little or no attention has been paid to cryptanalysing substring-SSE schemes, i.e., SSE schemes supporting arbitrary substring queries over encrypted data. This is despite their relevance to many real-world applications, e.g., in the context of securely querying outsourced genomic databases. In particular, the first ever substring-SSE scheme, proposed nearly a decade ago by Chase and Shen (PoPETS '15), has not been cryptanalysed to date.

In this paper, we present the first leakage cryptanalysis of the substring-SSE scheme of  Chase and Shen. We propose a novel inference-based query reconstruction attack that: (i) exploits a reduced version of the actual leakage profile of their scheme,  and (ii) assumes a weaker attack model as compared to the one in which Chase and Shen originally claimed security. We implement our attack and experimentally validate its success rate and efficiency over two real-world datasets. Our attack achieves high query reconstruction rate with practical efficiency, and scales smoothly to large datasets containing $100,000$ strings. 

To the best of our knowledge, ours is the first and only query reconstruction attack on (and the first systematic leakage cryptanalysis of) any substring-SSE scheme till date.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 10:59:11 +0000</pubDate>
</item>
<item>
<title>One Server for the Price of Two: Simple and Fast Single-Server Private Information Retrieval</title>
<link>https://eprint.iacr.org/2022/949</link>
<guid>https://eprint.iacr.org/2022/949</guid>
<content:encoded><![CDATA[
<div> 关键词：SimplePIR、最快单服务器私有信息检索、学习带有错误假设、DoublePIR、私人审计

总结:
<br />
本文介绍了SimplePIR，这是目前最快的已知单服务器私有信息检索方案，其安全性基于学习带有错误的假设。SimplePIR在回答客户端查询时，对每个数据库字节执行少于一次32位乘法和一次32位加法操作，实现了接近机器内存带宽的10 GB/s/core的服务器吞吐量，性能逼近最快的双服务器（需要非共谋）私有信息检索方案。然而，SimplePIR具有较大的通信成本，为查询1 GB的数据库，客户端需要下载121 MB的“提示”数据；之后客户端可以进行无限次数的查询，每次查询需通信242 KB。文章还提出了另一个名为DoublePIR的单服务器方案，它将提示数据缩小到16 MB，但每查询通信成本提高至345 KB，同时服务器吞吐量降至7.4 GB/s/core。最后，文章将这两个新的私有信息检索方案与一种新颖的大致集合成员资格数据结构相结合，应用于证书透明度中的私有审核任务，实现了比Google Chrome当前方法更严格的隐私保护概念，同时也仅带来了适度的通信开销：每月下载16 MB，以及每个TLS连接额外150字节的数据传输。 <div>
We present SimplePIR, the fastest single-server private information retrieval scheme known to date. SimplePIR’s security holds under the learning-with-errors assumption. To answer a client’s query, the SimplePIR server performs fewer than one 32-bit multiplication and one 32-bit addition per database byte. SimplePIR achieves 10 GB/s/core server throughput, which approaches the memory bandwidth of the
machine and the performance of the fastest two-server private-information-retrieval schemes (which require non-colluding servers). SimplePIR has relatively large communication costs: to make queries to a 1 GB database, the client must download a 121 MB "hint" about the database contents; thereafter, the client may make an unbounded number of queries, each requiring 242 KB of communication. We present a second single-server scheme, DoublePIR, that shrinks the hint to 16 MB at the cost of slightly higher per-query communication (345 KB) and slightly lower throughput (7.4 GB/s/core). Finally, we apply our new private-information-retrieval schemes, together with a novel data structure for approximate set membership, to the task of private auditing in Certificate Transparency. We achieve a strictly stronger notion of privacy than Google Chrome’s current approach with modest communication overheads: 16 MB of download per month, along with 150 bytes per TLS connection.
]]></content:encoded>
<pubDate>Fri, 22 Jul 2022 23:41:48 +0000</pubDate>
</item>
<item>
<title>Scutum: Temporal Verification for Cross-Rollup Bridges via Goal-Driven Reduction</title>
<link>https://eprint.iacr.org/2024/1834</link>
<guid>https://eprint.iacr.org/2024/1834</guid>
<content:encoded><![CDATA[
<div> 关键词: Scalability, Blockchain, Rollups, Cross-rollup bridges, Security verification

总结:
随着区块链领域对可扩展性的需求日益增加，Rollups（尤其是零知识和乐观Rollups）通过链下处理交易以保持以太坊的安全性，降低 gas 费并提高速度。然而，跨Rollup桥接器如Orbiter Finance虽然实现了不同Layer 2及与Layer 1之间的资产无缝转移，但其安全性问题也愈发突出，近期多起重大黑客攻击事件造成了数亿美元损失。鉴于传统安全分析方法如静态分析和模糊测试对于这类复杂设计的跨Rollup桥接器难以奏效，本文提出了一种可扩展的验证器来系统评估跨Rollup桥接器的安全性。该方法采用全面的多模型框架，利用时态属性捕获单个行为和复杂的交互关系。为了提高可扩展性，我们通过图表示合约的可达性分析近似实现时态安全性验证，并结合先进的程序分析技术。此外，我们引入了基于冲突驱动的细化循环来消除误报并提高精度。实证研究中，我们在主流跨Rollup桥接器（包括Orbiter Finance）上发现多个零日漏洞，证明了这种方法的实际应用价值。该工具还表现出良好的运行时间性能，适合实时或近乎实时的应用场景进行有效分析。 <div>
Scalability remains a key challenge for blockchain adoption. Rollups—especially zero-knowledge (ZK) and optimistic rollups—address this by processing transactions off-chain while maintaining Ethereum’s security, thus reducing gas fees and improving speeds. Cross-rollup bridges like Orbiter Finance enable seamless asset transfers across various Layer 2 (L2) rollups and between L2 and Layer 1 (L1) chains. However, the increasing reliance on these bridges raises significant security concerns, as evidenced by major hacks like those of Poly Network and Nomad Bridge, resulting in losses of hundreds of millions of dollars. Traditional security analysis methods such as static analysis and fuzzing are inadequate for cross-rollup bridges due to their complex designs involving multiple entities, smart contracts, and zero-knowledge circuits. These systems require reasoning about temporal sequences of events across different entities, which exceeds the capabilities of conventional analyzers.
In this paper, we introduce a scalable verifier to systematically assess the security of cross-rollup bridges. Our approach features a comprehensive multi-model framework that captures both individual behaviors and complex interactions using temporal properties. To enhance scalability, we approximate temporal safety verification through reachability analysis of a graph representation of the contracts, leveraging advanced program analysis techniques. Additionally, we incorporate a conflict-driven refinement loop to eliminate false positives and improve precision. Our evaluation on mainstream cross-rollup bridges, including Orbiter Finance, uncovered multiple zero-day vulnerabilities, demonstrating the practical utility of our method. The tool also exhibited favorable runtime performance, enabling efficient analysis suitable for real-time or near-real-time applications.
]]></content:encoded>
<pubDate>Fri, 08 Nov 2024 04:03:24 +0000</pubDate>
</item>
<item>
<title>A Tight Analysis of GHOST Consistency</title>
<link>https://eprint.iacr.org/2024/1830</link>
<guid>https://eprint.iacr.org/2024/1830</guid>
<content:encoded><![CDATA[
<div> 关键词: GHOST协议、Nakamoto共识机制、以太坊、安全性区域、区块生产率

总结:
本文探讨了GHOST协议作为对比特币中Nakamoto共识机制改进的安全性区域。与Nakamoto共识规则不同，GHOST规则通过计算子树权重而非单个路径来选择区块链。该机制已被多种共识协议采纳，并应用于当前支持以太坊的协议中。文章精确刻画了GHOST协议的安全性区域，揭示了诚实区块生产和恶意区块生产速率以及网络延迟之间达成共识所需的关联关系。研究发现，其安全性区域取决于协议采用的平局解决方式：针对敌对平局解决（不利于共识）和确定性平局解决（在整个执行过程中一致性地打破平局），文中都提出了具体的攻击策略并证明了两种情况下共识可能在安全区域之外被阻塞。结果表明，通过引入平局解决机制可以严格改善GHOST协议的安全性区域，但无论采用何种方式，最终的安全性区域仍逊色于Nakamoto共识机制的安全性区域。 <div>
The GHOST protocol has been proposed as an improvement to the Nakamoto consensus mechanism that underlies Bitcoin. In contrast to the Nakamoto fork-choice rule, the GHOST rule justifies selection of a chain with weights computed over subtrees rather than individual paths. This mechanism has been adopted by a variety of consensus protocols, and is a part of the currently deployed protocol supporting Ethereum.

We establish an exact characterization of the security region of the GHOST protocol, identifying the relationship between the rate of honest block production, the rate of adversarial block production, and network delays that guarantee that the protocol reaches consensus. In contrast to the closely related Nakamoto consensus protocol, we find that the region depends on the convention used by the protocol for tiebreaking; we establish tight results for both adversarial tiebreaking, in which ties are broken adversarially in order to frustrate consensus, and deterministic tiebreaking, in which ties between pairs of blocks are broken consistently throughout an execution. We provide explicit attacks for both conventions which stall consensus outside of the security region. 

Our results conclude that the security region of GHOST can be strictly improved by incorporating a tiebreaking mechanism; in either case, however, the final region of security is inferior to the region of Nakamoto consensus.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 19:37:02 +0000</pubDate>
</item>
<item>
<title>A Composability Treatment of Bitcoin's Transaction Ledger with Variable Difficulty</title>
<link>https://eprint.iacr.org/2024/1823</link>
<guid>https://eprint.iacr.org/2024/1823</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、proof-of-work (PoW)、动态参与、安全性分析、模拟-based 分析

总结:<br />
本文首次（据作者所知）针对运行于动态环境中的比特币区块链进行了基于模拟的分析。文章指出，现有的关于比特币的安全性分析是基于属性的，仅保证了协议在孤立运行时的安全性。研究中，提出了比特币背骨协议的抽象模型，该模型在特定参与限制条件下，能够体现出比特币预期的设计规范。此外，本文扩展了固定难度设置下的普适组合性处理方式，并发展出了可能具有更广泛适用性的技术，特别是对于依赖难度调整的其他可组合区块链协议的分析形式。 <div>
As the first proof-of-work (PoW) permissionless blockchain, Bitcoin aims at maintaining a decentralized yet consistent transaction ledger as protocol participants (“miners”) join and leave as they please. This is achieved by means of a subtle PoW difficulty adjustment mechanism that adapts to the perceived block generation rate, and important steps have been taken in previous work to provide a rigorous analysis of the conditions (such as bounds on dynamic participation) that are sufficient for Bitcoin’s security properties to be ascertained.

Such existing analysis, however, is property-based, and as such only guarantees security when the protocol is run $\textbf{in isolation}$. In this paper we present the first (to our knowledge) simulation-based analysis of the Bitcoin ledger in the dynamic setting where it operates, and show that the protocol abstraction known as the Bitcoin backbone protocol emulates, under certain participation restrictions, Bitcoin’s intended specification. Our formulation and analysis extend the existing Universally Composable treatment for the fixed-difficulty setting, and develop techniques that might be of broader applicability, in particular to other composable formulations of blockchain protocols that rely on difficulty adjustment.
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 09:30:47 +0000</pubDate>
</item>
<item>
<title>Anonymous Public-Key Quantum Money and Quantum Voting</title>
<link>https://eprint.iacr.org/2024/1822</link>
<guid>https://eprint.iacr.org/2024/1822</guid>
<content:encoded><![CDATA[
<div> 关键词：量子货币、隐私、公开密钥、不可追踪性、投票方案<br /><br />总结:<br />
本文主要关注了量子货币领域的隐私问题以及其在投票应用中的潜力。首先，文章提出了量子货币的隐私安全定义，并构建了首个具有用户匿名性和当局可追踪性的公钥量子货币方案。同时，也设计了一个连当局都无法追踪的不可追踪量子货币方案。此外，利用量子力学的不可克隆原理，文章还构造了一个基于经典投票的、具有普适验证性的量子投票方案。为了实现这些目标，文中引入了一种新的技术工具——具有强正确性的公共重随机化加密方案，并在假设学习错误困难性和量子学习错误困难性的前提下，给出了一个后量子时代的经典实现。 <div>
Quantum information allows us to build quantum money schemes, where a bank can issue banknotes in the form of authenticatable quantum states that cannot be cloned or counterfeited: a user in possession of k banknotes cannot produce k +1 banknotes. Similar to paper banknotes, in existing quantum money schemes, a banknote consists of an unclonable quantum state and a classical serial number, signed by bank. Thus, they lack one of the most fundamental properties cryptographers look for in a currency scheme: privacy. In this work, we first further develop the formal definitions of privacy for quantum money schemes. Then, we construct the first public-key quantum money schemes that satisfy these security notions. Namely, 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Errors, we construct a public-key quantum money scheme with anonymity against users and traceability by authorities. 

Since it is a policy choice whether authorities should be able to track banknotes or not, we also construct an untraceable money scheme, where no one (not even the authorities) can track banknotes. 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Er- rors, we construct a public-key quantum money scheme with untraceability. 

Further, we show that the no-cloning principle, a result of quantum mechanics, allows us to construct schemes, with security guarantees that are classically impossible, for a seemingly unrelated application: voting! 
• Assuming existence of indistinguishability obfuscation and hardness of Learning with Errors, we construct a universally verifiable quantum voting scheme with classical votes. 

Finally, as a technical tool, we introduce the notion of publicly rerandomizable encryption with strong correctness, where no adversary is able to produce a malicious ciphertext and a malicious random tape such that the ciphertext before and after rerandomization (with the malicious tape) decrypts to different values! We believe this might be of independent interest. • Assuming the (quantum) hardness of Learning with Errors, we construct a (post-quantum) classical publicly rerandomizable encryption scheme with strong correctness
]]></content:encoded>
<pubDate>Thu, 07 Nov 2024 07:25:38 +0000</pubDate>
</item>
<item>
<title>SCIF: Privacy-Preserving Statistics Collection with Input Validation and Full Security</title>
<link>https://eprint.iacr.org/2024/1821</link>
<guid>https://eprint.iacr.org/2024/1821</guid>
<content:encoded><![CDATA[
<div> 关键词: 安全聚合、SCIF、输入验证、恶意服务器、拒绝服务攻击

<br /><br />总结:
本文介绍了一种名为SCIF的新颖多服务器安全聚合协议，该协议带有输入验证功能，并能在存在少于三分之一恶意服务器的情况下确保安全性。与现有协议（如Prio、Prio+、Elsa和Whisper）相比，SCIF具有两大优势：(1) 确保输出交付，即恶意参与者无法阻止协议完成，从而增强了对拒绝服务攻击的抵抗能力；(2) 确保输入包含，意味着恶意参与者无法阻止诚实参与者的输入被纳入计算。同时，SCIF在不增加客户端成本的同时保持了服务器成本的适度。文章还展示了SCIF的强大可实施性，通过将其集成到模拟的Tor网络中，实现了隐私保护测量的便捷部署。 <div>
Secure aggregation is the distributed task of securely computing a sum of values (or a vector of values) held by a set of parties, revealing only the output (i.e., the sum) in the computation. Existing protocols, such as Prio (NDSI’17), Prio+ (SCN’22), Elsa (S&amp;P’23), and Whisper (S&amp;P’24), support secure aggregation with input validation to ensure inputs belong to a specified domain. However, when malicious servers are present, these protocols primarily guarantee privacy but not input validity. Also, malicious server(s) can cause the protocol to abort. We introduce SCIF, a novel multi-server secure aggregation protocol with input validation, that remains secure even in the presence of malicious actors, provided fewer than one-third of the servers are malicious. Our protocol overcomes previous limitations by providing two key properties: (1) guaranteed output delivery, ensuring malicious parties cannot prevent the protocol from completing, and (2) guaranteed input inclusion, ensuring no malicious party can prevent an honest party’s input from being included in the computation. Together, these guarantees provide strong resilience against denial-of-service attacks. Moreover, SCIF offers these guarantees without increasing client costs over Prio and keeps server costs moderate. We present a robust end-to-end implementation of SCIF and demonstrate the ease with which it can be instrumented by integrating it in a simulated Tor network for privacy-preserving measurement.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 21:12:04 +0000</pubDate>
</item>
<item>
<title>SophOMR: Improved Oblivious Message Retrieval from SIMD-Aware Homomorphic Compression</title>
<link>https://eprint.iacr.org/2024/1814</link>
<guid>https://eprint.iacr.org/2024/1814</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护区块链、私密消息服务、Oblivious Message Retrieval (OMR)、Homomorphic Encryption (HE)、性能优化

总结:

我们提出了一种新的Oblivious Message Retrieval (OMR)方案，旨在解决隐私保护区块链和私密消息服务中客户端需逐个扫描大量公开载荷以避免漏收消息的用户体验问题。该方案通过使用Homomorphic Encryption (HE)将昂贵的扫描过程安全地外包给服务提供商。相比于之前的最优方案PerfOMR，我们的实现显示出了显著的改进：运行时间减少了3.3倍，摘要大小减小了2.2倍，密钥大小减小了1.3倍。这些提升的核心在于我们创新的同态压缩机制，它能够将长度与总载荷数成比例的密文压缩为长度与相关载荷数上限成比例的摘要。不同于以往的方法，我们的方案充分利用了底层HE方案固有的同态SIMD结构，从而大幅提高了效率。在描述的场景（65536个每个612字节的载荷，其中最多50个相关）下，我们的压缩方案相比PerfOMR实现了7.4倍的速度提升。 <div>
Privacy-preserving blockchains and private messaging services that ensure receiver-privacy face a significant UX challenge: each client must scan every payload posted on the public bulletin board individually to avoid missing messages intended for them. Oblivious Message Retrieval (OMR) addresses this issue by securely outsourcing this expensive scanning process to a service provider using Homomorphic Encryption (HE).

In this work, we propose a new OMR scheme that substantially improves upon the previous state-of-the-art, PerfOMR (USENIX Security'24). Our implementation demonstrates reductions of 3.3x in runtime, 2.2x in digest size, and 1.3x in key size, in a scenario with 65536 payloads (each 612 bytes), of which up to 50 are pertinent.

At the core of these improvements is a new homomorphic compression mechanism, where ciphertexts of length proportional to the number of total payloads are compressed into a digest whose length is proportional to the upper bound on the number of pertinent payloads. Unlike previous approaches, our scheme fully exploits the native homomorphic SIMD structure of the underlying HE scheme, significantly enhancing efficiency. In the setting described above, our compression scheme achieves 7.4x speedup compared to PerfOMR.
]]></content:encoded>
<pubDate>Wed, 06 Nov 2024 00:39:25 +0000</pubDate>
</item>
<item>
<title>Revisiting Leakage-Resilient MACs and Succinctly-Committing AEAD: More Applications of Pseudo-Random Injections</title>
<link>https://eprint.iacr.org/2024/1813</link>
<guid>https://eprint.iacr.org/2024/1813</guid>
<content:encoded><![CDATA[
<div> 关键词: Pseudo-Random Injections (PRIs), Message Authentication Codes (MACs), Authenticated Encryption with Associated Data (AEAD), Collision Resistance, UnForgeability

总结:
本文重新探讨了伪随机注入（PRIs）在构建消息认证码（MACs）和Authenticated Encryption with Associated Data（AEAD）方案中的应用。首先，文章分析了在不同泄漏模型下，PRIs作为具有小明文空间的MAC时所具有的碰撞抵抗性和不可伪造性等性质。接着，展示了如何将PRIs与抗碰撞哈希函数结合，构建针对长明文的MAC，根据PRI和相等性检查的实现方式提供灵活的安全性。若两者都无泄漏，则MAC提供接近最优安全性；即使仅相等性检查具有泄漏抵抗力，安全性能也只会轻微下降；而在相等性检查有无界泄漏的情况下，安全性降低至基线水平而非完全不安全。

此外，文章提出了使用PRIs从头开始构建一个名为scoAE的简洁承诺在线AEAD方案，该方案实现了简洁的CMT4安全、隐私以及Ciphertext Integrity with Misuse and Leakage (CIML2) 安全性。最后，通过结合SIV范式与基于PRI的加密（例如Encode-then-Encipher (EtE)框架），文章展示了一个简洁的nonce耐滥用（MRAE）AEAD方案——scMRAE。 <div>
Pseudo-Random Injections (PRIs) have had several applications in symmetric-key cryptography, such as in the idealization of Authenticated Encryption with Associated Data (AEAD) schemes, building robust AEAD, and, recently, in converting a committing AEAD scheme into a succinctly committing AEAD scheme. In Crypto 2024, Bellare and Hoang showed that if an AEAD scheme is already committing, it can be transformed into a succinctly committed scheme by encrypting part of the plaintext using a PRI. In this paper, we revisit the applications of PRIs in building Message Authentication Codes (MACs) and AEAD schemes. 

First, we look at some of the properties and definitions PRIs, such as collision resistance and unforgeability when used as a MAC with small plaintext space, under different leakage models. Next, we show how they can be combined with collision-resistant hash functions to build a MAC for long plaintexts, offering flexible security depending on how the PRI and equality check are implemented. If both the PRI and equality check are leak-free, the MAC provides almost optimal security, but the security 
only degrades a little if the equality check is only leakage-resilient (rather than leak-free). If the equality check has unbounded leakage, the security drops to a baseline security, rather than being completely insecure. Next, we show how to use PRIs to build a succinctly committing online AEAD scheme dubbed as scoAE from scratch that achieves succinct CMT4 security, privacy, and Ciphertext Integrity with Misuse and Leakage (CIML2) security. Last but not least, we show how to build a succinct nonce Misuse-Resistant (MRAE) AEAD scheme, dubbed as scMRAE. The construction combines the SIV paradigm with PRI-based encryption (e.g. the Encode-then-Encipher (EtE) framework).
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 21:43:34 +0000</pubDate>
</item>
<item>
<title>Foundations of Adaptor Signatures</title>
<link>https://eprint.iacr.org/2024/1809</link>
<guid>https://eprint.iacr.org/2024/1809</guid>
<content:encoded><![CDATA[
<div> 关键词：adaptor签名、安全性、预签名、应用、安全模型<br /><br />总结:
本文针对adaptor签名的安全性和构建进行了重新审视。首先，作者指出了Aumayr等人在ASIACRYPT'21中提出的adaptor签名安全模型存在的缺陷，这些缺陷导致已知的一些应用于私人币混洗和基于oracle支付的协议不安全，并通过实例说明了根据原有定义仍被认为是安全的adaptor签名可能在实际应用中引发不安全性。为填补这一空白，作者提出了适应这些实际应用场景的最小化模块化定义。其次，鉴于所有已知构造要么源自识别方案并通过Fiat-Shamir变换在随机预言机模型中构建，要么需要修改基础签名验证算法而不适用于加密货币场景，而且它们都只是基于Aumayr等人的不足定义证明了安全性，因此目前没有可用于实际应用的可证明安全的adaptor签名方案。对此，本文证明了广泛使用的Schnorr adaptor签名在新提议的定义下是安全的，并提供了新的构造，包括首次为Camenisch-Lysyanskaya（CL）、Boneh-Boyen-Shacham（BBS+）和Waters签名设计的adaptor签名方案，且所有这些都在标准模型中被证明安全。新构造依赖于名为dichotomic签名的新颖数字签名抽象，以及一种用于证明所有构造（包括基于识别的方案）安全性的新型非黑盒证明技术。同时，作者提出的新数字签名抽象和证明技术对于社区来说具有独立的研究价值。 <div>
Adaptor signatures extend the functionality of regular signatures through the computation of pre-signatures on messages for statements of NP relations. Pre-signatures are publicly verifiable; they simultaneously hide and commit to a signature of an underlying signature scheme on that message. Anybody possessing a corresponding witness for the statement can adapt the pre-signature to obtain the "regular" signature. Adaptor signatures have found numerous applications for conditional payments in blockchain systems, like payment channels (CCS'20, CCS'21), private coin mixing (CCS'22, SP'23), and oracle-based payments (NDSS'23). 

In our work, we revisit the state of the security of adaptor signatures and their constructions. In particular, our two main contributions are:

- Security Gaps and Definitions: We review the widely-used security model of adaptor signatures due to Aumayr et al. (ASIACRYPT'21) and identify gaps in their definitions that render known protocols for private coin-mixing and oracle-based payments insecure. We give simple counterexamples of adaptor signatures that are secure w.r.t. their definitions but result in insecure instantiations of these protocols. To fill these gaps, we identify a minimal set of modular definitions that align with these practical applications.
 
- Secure Constructions: Despite their popularity, all known constructions are (1) derived from identification schemes via the Fiat-Shamir transform in the random oracle model or (2) require modifications to the underlying signature verification algorithm, thus making the construction useless in the setting of cryptocurrencies. More concerningly, all known constructions were proven secure w.r.t. the insufficient definitions of Aumayr et al., leaving us with no provably secure adaptor signature scheme to use in applications.
    
    Firstly, in this work, we salvage all current applications by proving the security of the widely-used Schnorr adaptor signatures under our proposed definitions. We then provide several new constructions, including presenting the first adaptor signature schemes for Camenisch-Lysyanskaya (CL), Boneh-Boyen-Shacham (BBS+), and Waters signatures, all of which are proven secure in the standard model. Our new constructions rely on a new abstraction of digital signatures, called dichotomic signatures, which covers the essential properties we need to build adaptor signatures. Proving the security of all constructions (including identification-based schemes) relies on a novel non-black-box proof technique. Both our digital signature abstraction and the proof technique could be of independent interest to the community.
]]></content:encoded>
<pubDate>Tue, 05 Nov 2024 10:37:42 +0000</pubDate>
</item>
<item>
<title>Siniel: Distributed Privacy-Preserving zkSNARK</title>
<link>https://eprint.iacr.org/2024/1803</link>
<guid>https://eprint.iacr.org/2024/1803</guid>
<content:encoded><![CDATA[
<div> 关键词：zkSNARK、计算开销、私有委托、Siniel、EOS

<br /><br />总结：

本文提出了一种名为Siniel的高效私有委托框架，用于优化zkSNARK（零知识简洁非交互式知识论证）。Siniel通过结合多项式交互式预言机证明（PIOP）和多项式承诺方案（PCS），使得计算能力有限的证明者（即委托人）能够将昂贵的证明计算任务安全地委托给多个工作者，同时不泄露任何关于私有见证的信息。与当前最先进的zkSNARK证明者委托框架EOS相比，Siniel的独特之处在于，证明者在发送私有见证的份额后无需参与多 party 计算（MPC）协议，这意味着证明者可以完全将计算过程外包给工作者。实验结果显示，在低带宽（10Mbps）条件下，Siniel相较于EOS为委托者节省约65%的时间；而在高带宽（1000Mbps）条件下，这一比例提高到约95%，显示了Siniel在性能上的显著优势。 <div>
Zero-knowledge Succinct Non-interactive Argument of Knowledge (zkSNARK) is a powerful cryptographic primitive, in which a prover convinces a verifier that a given statement is true without leaking any additional information. However, existing zkSNARKs suffer from high computation overhead in the proof generation. This limits the applications of zkSNARKs, such as private payments, private smart contracts, and anonymous credentials. Private delegation has become a prominent way to accelerate proof generation.
In this work, we propose Siniel, an efficient private delegation framework for zkSNARKs constructed from polynomial interactive oracle proof (PIOP) and polynomial commitment scheme (PCS). Our protocol allows a computationally limited prover (a.k.a. delegator) to delegate its expensive prover computation to several workers without leaking any information about the private witness. Most importantly, compared with the recent work EOS (USENIX’23), the state-of-the-art zkSNARK prover delegation framework, a prover in Siniel needs not to engage in the MPC protocol after sending its shares of private witness. This means that a Siniel prover can outsource the entire computation to the workers.
We compare Siniel with EOS and show significant performance advantages of the former. The experimental results show that, under low bandwidth conditions (10MBps),
Siniel saves about 65% time for delegators than that of EOS, whereas under high bandwidth conditions (1000MBps), Siniel saves about 95% than EOS.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 13:08:31 +0000</pubDate>
</item>
<item>
<title>Privacy-Preserving Multi-Party Search via Homomorphic Encryption with Constant Multiplicative Depth</title>
<link>https://eprint.iacr.org/2024/1800</link>
<guid>https://eprint.iacr.org/2024/1800</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、多方搜索协议、阈值级同态加密、电路深度常数、动态数据库

总结:
我们的研究提出了一种采用阈值级同态加密技术的隐私保护多方搜索协议。我们证明了该协议在诚实但好奇的对手面前是正确且安全的。与现有方法不同的是，我们的协议保持了恒定的电路深度，这使得它更适用于涉及动态底层数据库的实际应用场景。<br /><br /> <div>
We propose a privacy-preserving multiparty search protocol
using threshold-level homomorphic encryption, which we prove correct
and secure to honest but curious adversaries. Unlike existing approaches,
our protocol maintains a constant circuit depth. This feature enhances
its suitability for practical applications involving dynamic underlying
databases.
]]></content:encoded>
<pubDate>Mon, 04 Nov 2024 08:14:14 +0000</pubDate>
</item>
<item>
<title>IrisLock: Iris Biometric Key Derivation with 42 bits of security</title>
<link>https://eprint.iacr.org/2024/100</link>
<guid>https://eprint.iacr.org/2024/100</guid>
<content:encoded><![CDATA[
<div> 关键词：生物特征认证、模糊提取器、安全、独立性假设、IrisLock

总结:

本文介绍了IrisLock，一种基于虹膜的密钥衍生系统，该系统结合了虹膜特征提取技术与改进后的模糊提取器，旨在解决生物特征认证领域的理论与实践之间的鸿沟。传统的生物特征认证算法依赖于泄露私人信息的数据和外部的安全措施，而模糊提取器理论上可以实现安全且保护隐私的生物特征认证。然而，现有模糊提取器系统要么基于未经统计验证或已被证明为错误的独立性假设，要么使用了错误的密码学分析。

IrisLock系统纠正了sample-then-lock方法的证明，并指出子集最小最小熵是相关安全性度量标准。它提供$42$位安全性以及$45\%$的真实接受率(TAR)，与现有系统相比，其定量安全性水平相当甚至更高。通过添加密码，安全性可提升至$64$位。在评估TAR和安全性时，所使用的虹膜数据与训练和收集统计数据的数据类互不重叠（开放式数据集方案）。IrisLock唯一必要的统计假设是对最小熵估计的准确性。 <div>
Despite decades of effort, a chasm exists between the theory and practice of device-level biometric authentication. Deployed authentication algorithms rely on data that overtly leaks private information about the biometric; thus systems rely on externalized security measures such as trusted execution environments. The authentication algorithms have no cryptographic guarantees.
  
This is  frustrating given the research that has developed theoretical tools, known as fuzzy extractors, that enable secure, privacy-preserving biometric authentication with public enrollment data (Dodis et al., SIAM JoC 2008). Unfortunately, fuzzy extractor systems either:
-Make strong independence assumptions, such as:
-- Bits of biometrics are i.i.d. (or that all correlation is pairwise between features (Hine et al., TIFS 2023)), or
-- For an error-correcting code, the nearest codeword and the coset of biometric readings are independent (Zhang, Cui, and Yu, ePrint 2021/1559).
  These assumptions either have not been statistically checked or 
  statistical analysis indicates they are false.
- Or use incorrect cryptographic analysis.  Simhadri et al. (ISC, 2019) assume the security of sample-then-lock (Canetti et al., Journal of Cryptology 2021) is captured by the average min-entropy of subsets.  Zhang et al. (ICPR, 2022) show an attack on this incorrect analysis. 

This work introduces IrisLock, an iris key derivation system powered by technical advances in both
1) feature extraction from the iris  and
2) the fuzzy extractor used to secure authentication keys.  The fuzzy extractor builds on sample-then-lock (Canetti et al., Journal of Cryptology 2021). We correct a proof in Canetti et al. and show the minimum of min-entropy of subsets is the relevant security measure.  Our primary parameters are $42$ bits of security at $45\%$ true accept rate (TAR).  Our quantitive level of security is as good as the above systems, Simhadri et al's incorrect analysis yields an estimate of $32$ bits, while Zhang et al.'s system on the face estimates $45$ bits (with the independence condition). One can easily incorporate a password, boosting security to $64$ bits.

Irises used to evaluate TAR and security are class disjoint from those used for training and collecting statistics (the open dataset regime).
The only statistical assumption made is necessary: the accuracy of min-entropy estimation.
]]></content:encoded>
<pubDate>Mon, 22 Jan 2024 18:21:35 +0000</pubDate>
</item>
<item>
<title>Amun: Securing E-Voting Against Over-the-Shoulder Coercion</title>
<link>https://eprint.iacr.org/2021/851</link>
<guid>https://eprint.iacr.org/2021/851</guid>
<content:encoded><![CDATA[
<div> 关键词：Amun协议、选举、投票隐私、防肩窥、安全性证明<br /><br />总结:
Amun协议是在一场允许每个选民对M个可能选项表达P个偏好级别的选举中，确保投票安全性的方案。它防范了过肩窥视攻击，保护了投票隐私，同时保持了公平性、端到端可验证性和正确性。在选举前，每位选民会收到含有有效和干扰代币的选票，只有有效代币会对最终计票产生影响，但它们与干扰代币无法区分，从而防止了肩窥攻击的发生。我们依据随机预言模型下标准的决策Diffie-Hellman假设证明了该构造的安全性。 <div>
In an election where each voter may express $P$ preferences among $M$ possible choices, the Amun protocol allows to secure vote casting against over-the-shoulder adversaries, retaining privacy, fairness, end-to-end verifiability, and correctness.

Before the election, each voter receives a ballot containing valid and decoy tokens: only valid tokens contribute in the final tally, but they remain indistinguishable from the decoys.
Since the voter is the only one who knows which tokens are valid (without being able to prove it to a coercer), over-the-shoulder attacks are thwarted.

We prove the security of the construction under the standard Decisional Diffie Hellman assumption in the random oracle model.
]]></content:encoded>
<pubDate>Tue, 22 Jun 2021 14:37:01 +0000</pubDate>
</item>
<item>
<title>Is Periodic Pseudo-randomization Sufficient for Beacon Privacy?</title>
<link>https://eprint.iacr.org/2024/1782</link>
<guid>https://eprint.iacr.org/2024/1782</guid>
<content:encoded><![CDATA[
<div> 关键词: 蓝牙低功耗(BLE)、隐私机制、定时序列不可区分性、计时器操纵攻击、随机化调度

总结:
本文研究了蓝牙低功耗(BLE)信标周期性更换伪随机身份的隐私机制是否足以确保隐私。文章提出了一个新的自然隐私概念，称为“定时序列不可区分性”，它不仅关注广播内容，还考虑了可从物理世界中观察到的广播时间，这一定义比传统的不可区分性更强。接着，文章证明周期性更换身份的BLE信标无法实现定时序列不可区分性，并提出了一种名为“计时器操纵攻击”的新颖隐私攻击方法，该攻击只需在对手选择的时间插入或重新插入信标的电池即可实施。作者们对一个实际部署的信标执行了此攻击。为了对抗这种基于周期信号的攻击，他们提出了一种新的随机化调度身份变化的对策，证明此对策可以确保信标的定时序列不可区分性，从而增强其隐私性。此外，文中还展示了如何在被攻击系统中集成这一对策，同时基本上保持其实现可行性和实用性，这对于实际工业应用至关重要。 <div>
In this paper, we investigate whether the privacy mechanism of periodically changing the pseudorandom identities of Bluetooth Low Energy (BLE) beacons is sufficient to ensure privacy.

We consider a new natural privacy notion for BLE broadcasting beacons which we call ``Timed-sequence- indistinguishability'' of beacons. This new privacy definition is stronger than the well-known indistinguishability, since it considers not just the advertisements' content, but also the advertisements' broadcasting times which are observable in the physical world. 

We then prove that beacons with periodically changing pseudorandom identities do not achieve timed-sequence- indistinguishability. We do this by presenting a novel privacy attack against BLE beacons, which we call the ``Timer Manipulation Attack.'' This new time-based privacy attack can be executed by merely inserting or reinserting the beacon's battery at the adversary's chosen time. We performed this attack against an actually deployed beacon.

To mitigate the ``Timer Manipulation Attack'' and other attacks associated with periodic signaling, we propose a new countermeasure involving quasi-periodic randomized scheduling of identity changes. We prove that our countermeasure ensures timed-sequence indistinguishability for beacons, thereby enhancing the beacon's privacy. Additionally, we show how to integrate this countermeasure in the attacked system while essentially preserving its feasibility and utility, which is crucial for practical industrial adoption.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 07:41:25 +0000</pubDate>
</item>
<item>
<title>FLock: Robust and Privacy-Preserving Federated Learning based on Practical Blockchain State Channels</title>
<link>https://eprint.iacr.org/2024/1797</link>
<guid>https://eprint.iacr.org/2024/1797</guid>
<content:encoded><![CDATA[
<div> 关键词: 联邦学习、中毒攻击防御、数据隐私、区块链、状态通道

<br /><br />总结:
本文提出了一种基于实用区块链状态通道的联邦学习方案——FLock，旨在解决现有联邦学习中的关键问题。首先，FLock通过量化、中位数和汉明距离方法，提出一种轻量级安全的多党计算友好型鲁棒聚合策略，能抵抗最多半数恶意客户端的中毒攻击，同时保证模型准确度。其次，利用通信效率高的基于Shamir秘密分享的多党计算协议保护数据隐私并维持高模型精度。再者，FLock借助区块链的离链状态通道实现不可篡改的模型记录和激励分配，并与以太坊等实际加密货币平台实现了成本效益兼容及公平激励机制。此外，FLock还整合了流水线式的拜占庭容错共识，使每个聚合器能够重建最终聚合结果，增强聚合环节的容错性。最后，实验证明FLock能够在保持高效和高模型准确度的同时，显著提升抗毒性和隐私保护，例如在具有25个聚合器和100个客户端的情况下，FLock可在WAN上于两分钟内完成一次针对ResNet的安全聚合，成功实现了大量聚合器下的安全聚合，增强了聚合环节的容错能力。 <div>
\textit{Federated Learning} (FL) is a distributed machine learning paradigm that allows multiple clients to train models collaboratively without sharing local data. Numerous works have explored security and privacy protection in FL, as well as its integration with blockchain technology. However, existing FL works still face critical issues.  \romannumeral1) It is difficult to achieving \textit{poisoning robustness} and \textit{data privacy} while ensuring high \textit{model accuracy}. Malicious clients can launch \textit{poisoning attacks} that degrade the global model. Besides, aggregators can infer private data from the gradients, causing \textit{privacy leakages}. Existing privacy-preserving poisoning defense FL solutions suffer from decreased model accuracy and high computational overhead. \romannumeral2) Blockchain-assisted FL records iterative gradient updates on-chain to prevent model tampering, yet existing schemes are not compatible with practical blockchains and incur high costs for maintaining the gradients on-chain. Besides, incentives are overlooked, where unfair reward distribution hinders the sustainable development of the FL community. In this work, we propose FLock, a robust and privacy-preserving FL scheme based on practical blockchain state channels. First, we propose a lightweight secure \textit{Multi-party Computation} (MPC)-friendly robust aggregation method through quantization, median, and Hamming distance, which could resist poisoning attacks against up to $<50\%$ malicious clients. Besides, we propose communication-efficient Shamir's secret sharing-based MPC protocols to protect data privacy with high model accuracy. Second, we utilize blockchain off-chain state channels to achieve immutable model records and incentive distribution. FLock achieves cost-effective compatibility with practical cryptocurrency platforms, e.g. Ethereum, along with fair incentives, by merging the secure aggregation into a multi-party state channel. In addition, a pipelined \textit{Byzantine Fault-Tolerant} (BFT) consensus is integrated where each aggregator can reconstruct the final aggregated results. Lastly, we implement FLock and the evaluation results demonstrate that FLock enhances robustness and privacy, while maintaining efficiency and high model accuracy. Even with 25 aggregators and 100 clients, FLock can complete one secure aggregation for ResNet in $2$ minutes over a WAN. FLock successfully implements secure aggregation with such a large number of aggregators, thereby enhancing the fault tolerance of the aggregation.
]]></content:encoded>
<pubDate>Sun, 03 Nov 2024 16:32:03 +0000</pubDate>
</item>
<item>
<title>How Much Public Randomness Do Modern Consensus Protocols Need?</title>
<link>https://eprint.iacr.org/2024/1794</link>
<guid>https://eprint.iacr.org/2024/1794</guid>
<content:encoded><![CDATA[
<div> 关键词: 区块链、共识协议、效率、安全性、随机性<br /><br />总结:
现代基于区块链的共识协议旨在实现高效性和对适应性敌手的安全性，通常依赖公共随机性源来为参与者分配角色。本文深入研究了这种随机性需求的程度。首先，文章证明了没有任何共识协议能够同时做到高效、适应性安全并且仅使用$O(\log n)$位的随机源熵。接下来，展示了一个三难困境：存在三个共识协议方案，它们可以分别实现这三个属性中的任意两个。 <div>
Modern blockchain-based consensus protocols 
aim for efficiency (i.e., low communication and round complexity) while maintaining security against adaptive adversaries.
These goals are usually achieved using a public randomness beacon to select roles for each participant.  
We examine to what extent this randomness is necessary.
Specifically, we provide tight bounds on the amount of entropy a Byzantine Agreement protocol must consume from a beacon in order to enjoy efficiency and adaptive security.
We first establish that no consensus protocol can simultaneously be efficient, be adaptively secure, and use $O(\log n)$ bits of beacon entropy. We then show this bound is tight and, in fact, a trilemma by presenting three consensus protocols that achieve any two of these three properties.
]]></content:encoded>
<pubDate>Sat, 02 Nov 2024 18:00:29 +0000</pubDate>
</item>
<item>
<title>Stealth and Beyond: Attribute-Driven Accountability in Bitcoin Transactions</title>
<link>https://eprint.iacr.org/2024/1789</link>
<guid>https://eprint.iacr.org/2024/1789</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin、隐私、问责制、双责任机制、Identity-Based Matchmaking Signatures (IB-MSS)

<br /><br />总结:
该论文针对比特币交易中隐私与问责制平衡的问题，提出了一种新颖的双责任机制。此机制在比特币交易中既约束发送者只能花费符合特定条件的未花费交易输出（UTXOs），又要求接收方在接受资金前满足法律和道德要求。通过将合规属性融入隐形地址，方案在保持用户隐私的同时确保了政策遵循。为支持审计流程简化，文中引入了一种新的密码学原语——基于身份的匹配签名（IB-MSS）。这一解决方案完全兼容现有的比特币基础设施，不需要对核心协议进行改动，从而在保护隐私和去中心化的同时实现了交易审计和合规性。 <div>
Bitcoin enables decentralized, pseudonymous transactions, but balancing privacy with accountability remains a challenge. This paper introduces a novel dual accountability mechanism that enforces both sender and recipient compliance in Bitcoin transactions. Senders are restricted to spending Unspent Transaction Outputs (UTXOs) that meet specific criteria, while recipients must satisfy legal and ethical requirements before receiving funds. We enhance stealth addresses by integrating compliance attributes, preserving privacy while ensuring policy adherence. Our solution introduces a new cryptographic primitive, Identity-Based Matchmaking Signatures (IB-MSS), which supports streamlined auditing. Our approach is fully compatible with existing Bitcoin infrastructure and does not require changes to the core protocol, preserving both privacy and decentralization while enabling transaction auditing and compliance.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 16:32:51 +0000</pubDate>
</item>
<item>
<title>An Efficient and Secure Boolean Function Evaluation Protocol</title>
<link>https://eprint.iacr.org/2024/1787</link>
<guid>https://eprint.iacr.org/2024/1787</guid>
<content:encoded><![CDATA[
<div> 关键词: 布尔函数、密码学、安全布尔评估、两方协议、轻量级

总结:
布尔函数在加密系统设计和分析中扮演重要角色，而安全布尔评估（SBE）则是研究重点，允许双方在不暴露私有输入的情况下联合计算布尔函数。本文提出了一种利用1-out-of-2 不知转移（OT）作为构建模块的高效、通用的两方协议——$\textsf{BooleanEval}$。该协议仅使用XOR操作作为核心计算步骤，因此轻量且快速。与当前其他轻量级SBE设计不同，$\textsf{BooleanEval}$避免了使用额外的加密原语，如哈希函数和承诺方案，从而减少了计算开销。<br /><br /> <div>
Boolean functions play an important role in designing and analyzing many cryptographic systems, such as block ciphers, stream ciphers, and hash functions, due to their unique cryptographic properties such as nonlinearity, correlation immunity, and algebraic properties. The secure evaluation of Boolean functions or Secure Boolean Evaluation (SBE) is an important area of research. SBE allows parties to jointly compute Boolean functions without exposing their private inputs. SBE finds applications in privacy-preserving protocols and secure multi-party computations. In this manuscript, we present an efficient and generic two-party protocol
(namely $\textsf{BooleanEval}$) for the secure evaluation of Boolean functions by utilizing a 1-out-of-2 Oblivious Transfer (OT) as a building block. $\textsf{BooleanEval}$ only employs XOR operations as the core computational step, thus making it lightweight and fast. Unlike other lightweight state-of-the-art designs of SBE, $\textsf{BooleanEval}$ avoids the use of additional cryptographic primitives, such as hash functions and commitment schemes to reduce the computational overhead.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 14:02:24 +0000</pubDate>
</item>
<item>
<title>PriSrv: Privacy-Enhanced and Highly Usable Service Discovery in Wireless Communications</title>
<link>https://eprint.iacr.org/2024/1783</link>
<guid>https://eprint.iacr.org/2024/1783</guid>
<content:encoded><![CDATA[
<div> 关键词：服务发现、隐私保护、PriSrv、匿名凭证基匹配加密（ACME）、快速匿名凭证（FAC）

<br /><br />总结:
本文提出了一种名为PriSrv的私有服务发现协议，旨在解决无线通信中服务提供者和客户端的隐私保护问题。PriSrv允许双方指定细粒度的身份验证策略，在建立连接前确保对方满足条件。该协议包括私人服务广播阶段和匿名相互认证阶段，同时隐藏双方的敏感信息。为实现这一目标，文章引入了匿名凭证基匹配加密（ACME）的概念，一次操作即可实现双边灵活策略控制、选择性属性披露及多展示不可链接性。作为ACME的基础组件，还设计了一个快速匿名凭证（FAC）方案，以提供常量大小的凭证和高效的展示/验证机制，适合于无线网络中的隐私增强型和高可用性服务发现。此外，PriSrv协议与Wi-Fi EAP、mDNS、BLE和Airdrop等流行无线通信协议兼容，提供了增强隐私保护的功能。文章对PriSrv进行了形式化安全证明并对其在多种硬件平台上的性能进行了评估，实现在桌面、笔记本电脑和移动电话上完成私人发现和安全连接的时间均少于0.973秒，在Raspberry Pi 4B上的时间则少于2.712秒。最后，将PriSrv集成到IEEE 802.1X的实际网络环境中，证实了其实用性。 <div>
Service discovery is essential in wireless communications. However, existing service discovery protocols provide no or very limited privacy protection for service providers and clients, and they often leak sensitive information (e.g., service type, client’s identity and mobility pattern), which leads to various network-based attacks (e.g., spoofing, man-in-the-middle, identification and tracking). In this paper, we propose a private service discovery protocol, called PriSrv, which allows a service provider and a client to respectively specify a fine-grained authentication policy that the other party must satisfy before a connection is established. PriSrv consists of a private service broadcast phase and an anonymous mutual authentication phase with bilateral control, where the private information of both parties is hidden beyond the fact that a mutual match to the respective authentication policy occurred. As a core component of PriSrv, we introduce the notion of anonymous credential-based matchmaking encryption (ACME), which exerts dual-layer matching in one step to simultaneously achieve bilateral  flexible policy control, selective attribute disclosure and multi-show unlinkability. As a building block of ACME, we design a fast anonymous credential (FAC) scheme to provide constant size credentials and efficient show/verification mechanisms, which is suitable for privacy-enhanced and highly usable service discovery in wireless networks. We present a concrete PriSrv protocol that is interoperable with popular wireless communication protocols, such as Wi-Fi Extensible Authentication Protocol (EAP), mDNS, BLE and Airdrop, to offer privacy-enhanced protection. We present formal security proof of our protocol and evaluate its performance on multiple hardware platforms: desktop, laptop, mobile phone and Raspberry Pi. PriSrv accomplishes private discovery and secure connection in less than 0.973 s on the first three platforms, and in less than 2.712 s on Raspberry Pi 4B. We also implement PriSrv into IEEE 802.1X in the real network to demonstrate its practicality.
]]></content:encoded>
<pubDate>Fri, 01 Nov 2024 10:02:29 +0000</pubDate>
</item>
<item>
<title>zkMarket : Privacy-preserving Digital Data Trade System via Blockchain</title>
<link>https://eprint.iacr.org/2024/1775</link>
<guid>https://eprint.iacr.org/2024/1775</guid>
<content:encoded><![CDATA[
<div> 关键词：zkMarket、隐私保护、公平交易、区块链、zk-SNARK

总结:
zkMarket是一款基于区块链的隐私保护公平交易系统，旨在解决交易隐私和计算效率问题。该系统利用匿名转移协议保证交易隐私，并结合加密技术和零知识简洁非交互式证明（zk-SNARK），使得买卖双方能实现公正交易。通过加密解密密钥并运用commit-and-prove SNARK（CP-SNARK）以及创新的矩阵形式伪随机生成器（MatPRG），优化了数据注册流程并减少了卖家的证明时间。实验证明，相较于传统区块链解决方案，zkMarket显著降低了计算开销，同时保持了强大的安全性和隐私性。其中，卖家可以在3.2秒内注册1MB的数据，买家能在0.2秒内生成交易事务，而卖家能在0.4秒内完成交易结算。 <div>
In this paper, we introduce zkMarket, a privacy-preserving fair trade system on the blockchain. zkMarket addresses the challenges of transaction privacy and computational efficiency. To ensure transaction privacy, zkMarket is built upon an anonymous transfer protocol. By combining encryption with zero-knowledge succinct non-interactive arguments of knowledge (zk-SNARK), both the seller and the buyer are enabled to trade fairly. Furthermore, by encrypting the decryption key, we make the data registration process more concise and improve the seller's proving time by leveraging commit-and-prove SNARK (CP-SNARK) and our novel pseudorandom generator, the matrix-formed PRG (MatPRG).

Our evaluation demonstrates that zkMarket significantly reduces the computational overhead associated with traditional blockchain solutions while maintaining robust security and privacy. The seller can register 1MB of data in 3.2 seconds, while the buyer can generate the trade transaction in 0.2 seconds, and the seller can finalize the trade in 0.4 seconds.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 04:47:17 +0000</pubDate>
</item>
<item>
<title>Universal Adaptor Signatures from Blackbox Multi-Party Computation</title>
<link>https://eprint.iacr.org/2024/1773</link>
<guid>https://eprint.iacr.org/2024/1773</guid>
<content:encoded><![CDATA[
<div> 关键词：适配器签名（AS）、通用适配器签名方案（UAS）、多 Party 计算 in the head（MPCitH）、区块链、隐私保护系统

<br /><br />总结:
本文提出了一个新的构建通用适配器签名方案（UAS）的方法，该方法不再依赖于刘等人工作中的成本高昂的卡普还原到哈密顿循环问题，而是利用多 Party 计算 in the head（MPCitH）范式。这使得新方案设计更为简化，并扩大了UAS在包括区块链和隐私保护系统等分布式应用中的适用范围。此外，基于MPCitH的UAS方案在提供强大安全性保障的同时，也成为现实世界密码学协议设计中具有潜力的工具。 <div>
Adaptor signatures (AS) extend the functionality of traditional digital signatures by enabling the generation of a pre-signature tied to an instance of a hard NP relation, which can later be turned (adapted) into a full signature upon revealing a corresponding witness. The recent work by Liu et al. [ASIACRYPT 2024] devised a generic AS scheme that can be used for any NP relation---which here we will refer to as universal adaptor signatures scheme, in short UAS---from any one-way function. However, this generic construction depends on the Karp reduction to the Hamiltonian cycle problem, which adds significant overhead and hinders practical applicability.

In this work, we present an alternative approach to construct universal adaptor signature schemes relying on the multi-party computation in the head (MPCitH) paradigm. This overcomes the reliance on the costly Karp reduction, while inheriting the core property of the MPCitH---which makes it an invaluable tool in efficient cryptographic protocols---namely, that the construction is black-box with respect to the underlying cryptographic primitive (while it remains non-black-box in the relation being proven). Our framework simplifies the design of UAS and enhances their applicability across a wide range of decentralized applications, such as blockchain and privacy-preserving systems. Our results demonstrate that MPCitH-based UAS schemes offer strong security guarantees while making them a promising tool in the design of real-world cryptographic protocols.
]]></content:encoded>
<pubDate>Thu, 31 Oct 2024 02:31:17 +0000</pubDate>
</item>
<item>
<title>PRIME: Differentially Private Distributed Mean Estimation with Malicious Security</title>
<link>https://eprint.iacr.org/2024/1771</link>
<guid>https://eprint.iacr.org/2024/1771</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式均值估计(DME)、多方计算(MPC)、安全性、鲁棒性、差分隐私

<br /><br />总结:
本文提出了一种针对分布式均值估计(DME)任务的新型安全聚合协议，该协议同时解决了恶意客户端输入操纵和信息泄露问题。首先，该协议具备鲁棒性保障，能够有效抵御由恶意客户引入的“故障”输入对系统的攻击。其次，它确保了差分隐私，防止底层函数泄漏个人敏感信息。这是首次将鲁棒性和差分隐私保证结合应用于DME领域的全面尝试。文中借鉴Mironov等人(2009年CRYPTO会议)的工作，通过一种融合了“有用性”和差分隐私的概念来刻画协议的安全性，并对其进行了正式的安全性分析。 <div>
Distributed mean estimation (DME) is a fundamental and important task as it serves as a subroutine in convex optimization, aggregate statistics, and, more generally, federated learning. The inputs for distributed mean estimation (DME) are provided by clients (such as mobile devices), and these inputs often contain sensitive information. Thus, protecting privacy and mitigating the influence of malicious adversaries are critical concerns in DME. A surge of recent works has focused on building multiparty computation (MPC) based protocols tailored for the task of secure aggregation. However, MPC fails to directly address these two issues: (i) the potential manipulation of input by adversaries, and (ii) the leakage of information from the underlying function.  This paper presents a novel approach that addresses both these issues. We propose a secure aggregation protocol with a robustness guarantee, effectively protecting the system from "faulty" inputs introduced by malicious clients. Our protocol further ensures differential privacy, so that the underlying function will not leak significant information about individuals. 
Notably, this work represents the first comprehensive effort to combine robustness and differential privacy guarantees in the context of DME. In particular, we capture the security of the protocol via a notion of "usefulness" combined with differential privacy inspired by the work of Mironov et al. (CRYPTO 2009) and formally analyze this security guarantee for our protocol.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 14:24:23 +0000</pubDate>
</item>
<item>
<title>Push-Button Verification for BitVM Implementations</title>
<link>https://eprint.iacr.org/2024/1768</link>
<guid>https://eprint.iacr.org/2024/1768</guid>
<content:encoded><![CDATA[
<div> 关键词: Bitcoin, BitVM, 层2解决方案, 正式验证工具, Domain-Specific Language (DSL)

总结:<br />
本文针对比特币（Bitcoin）扩展性和吞吐量限制问题，特别是对于像BTCFi这样的生态系统项目的发展所面临的挑战，提出了BitVM这一具有前景的Layer 2（L2）解决方案。然而，比特币受限的编程环境（如非图灵完备的Script语言、无循环和递归以及严格的区块大小限制）使得开发复杂应用变得困难且易出错。为了解决这些问题，文章首次提出了一种针对BitVM实现的正式验证工具。该方法设计了一个基于寄存器的、更高级别的领域特定语言（DSL），以抽象处理复杂的栈操作，使开发者能更容易地推断程序正确性，同时保持原有的比特币Script语义。通过构建一个形式化的计算模型来捕捉BitVM执行和比特币Script的语义，为严谨的验证提供了基础。为了高效处理大规模程序和模拟循环的展开计算所带来的复杂约束，文中利用循环不变量谓词对“循环式”计算进行概括。通过采用反例引导的归纳综合（CEGIS）过程将低级比特币Script转换为DSL，实现了高效的验证而不失准确性。在对BitVM SNARK验算器的98个基准测试中，该工具有效验证了94%的情况，仅需几秒钟，证明了其在提升BitVM安全性与可靠性方面的有效性。 <div>
Bitcoin, while being the most prominent blockchain with the largest market capitalization, suffers from scalability and throughput limitations that impede the development of ecosystem projects like Bitcoin Decentralized Finance (BTCFi). Recent advancements in BitVM propose a promising Layer 2 (L2) solution to enhance Bitcoin's scalability by enabling complex computations off-chain with on-chain verification. However, Bitcoin's constrained programming environment—characterized by its non-Turing-complete Script language lacking loops and recursion, and strict block size limits—makes developing complex applications labor-intensive, error-prone, and necessitates manual partitioning of scripts. Under this complex programming model, subtle mistakes could lead to irreversible damage in a trustless environment like Bitcoin. Ensuring the correctness and security of such programs becomes paramount.

To address these challenges, we introduce the first formal verification tool for BitVM implementations. Our approach involves designing a register-based, higher-level domain-specific language (DSL) that abstracts away complex stack operations, allowing developers to reason about program correctness more effectively while preserving the semantics of the original Bitcoin Script. We present a formal computational model capturing the semantics of BitVM execution and Bitcoin Script, providing a foundation for rigorous verification. To efficiently handle large programs and complex constraints arising from unrolled computations that simulate loops, we summarize repetitive "loop-style" computations using loop invariant predicates in our DSL. We leverage a counterexample-guided inductive synthesis (CEGIS) procedure to lift low-level Bitcoin Script into our DSL, facilitating efficient verification without sacrificing accuracy. Evaluated on 98 benchmarks from BitVM's SNARK verifier, our tool successfully verifies 94% of cases within seconds, demonstrating its effectiveness in enhancing the security and reliability of BitVM.
]]></content:encoded>
<pubDate>Wed, 30 Oct 2024 08:24:11 +0000</pubDate>
</item>
<item>
<title>Fully Homomorphic Encryption with Efficient Public Verification</title>
<link>https://eprint.iacr.org/2024/1764</link>
<guid>https://eprint.iacr.org/2024/1764</guid>
<content:encoded><![CDATA[
<div> 关键词: 公开验证、全同态加密、简洁证明、Ring R1CS、SNARG

总结:<br />
本文提出了一种高效的公开验证全同态加密方案，该方案不仅能对密文执行任意布尔电路计算，还能生成正确的同态计算的简洁证明。此方案基于Ducas和Micciancio提出的FHEW（Eurocrypt'15），并结合GINX同态累加器（Eurocrypt'16）以提高引导效率。为了有效生成证明，文章将广泛使用的Rank-1约束系统（R1CS）推广至环设置中，形成了Ring R1CS，从而能原生表达FHEW中的同态计算。进一步地，文章构建了一个针对Ring R1CS实例的SNARG，通过将Ring R1CS实例转换为多项式上的求和检查协议，再利用Cini等人（Crypto'24）提出的基于格的多项式承诺方案将其编译成简洁非交互式证明。综上所述，该公开验证的FHE方案依赖于标准的格问题困难度假设，能在时间复杂度为$O(|C|^2\cdot poly(\lambda))$和空间复杂度为$O(\log^2{|C|}\cdot poly(\lambda))$的情况下生成关于电路$C$的同态计算的简洁证明。此外，该方案实现了Walter最近提出的IND-SA安全模型（EPrint 2024/1207），能够精确保护客户端数据隐私，即使在可验证的同态计算中也是如此。 <div>
We present an efficient Publicly Verifiable Fully Homomorphic Encryption scheme that, along with being able to evaluate arbitrary boolean circuits over ciphertexts, also generates a succinct proof of correct homomorphic computation. Our scheme is based on FHEW proposed by Ducas and Micciancio (Eurocrypt'15), and we incorporate the GINX homomorphic accumulator (Eurocrypt'16) for improved bootstrapping efficiency. In order to generate the proof efficiently, we generalize the widely used Rank-1 Constraint System (R1CS) to the ring setting and obtain Ring R1CS, to natively express homomorphic computation in FHEW.
  
In particular, we develop techniques to efficiently express in our Ring R1CS the "non-arithmetic" operations, such as gadget decomposition and modulus switching used in the FHEW construction. We further construct a SNARG for Ring R1CS instances, by translating the Ring R1CS instance into a sum-check protocol over polynomials, and then compiling it into a succinct non-interactive proof by incorporating the lattice-based polynomial commitment scheme of Cini, Malavolta, Nguyen, and Wee (Crypto'24). Putting together, our Publicly Verifiable FHE scheme relies on standard hardness assumptions about lattice problems such that it generates a succinct proof of homomorphic computation of circuit $C$ in time $O(|C|^2\cdot poly(\lambda))$ and of size $O(\log^2{|C|}\cdot poly(\lambda))$. Besides, our scheme achieves the recently proposed IND-SA (indistinguishability under semi-active attack) security by Walter (EPrint 2024/1207) that exactly captures client data privacy when a homomorphic computation can be verified.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 20:01:00 +0000</pubDate>
</item>
<item>
<title>Homomorphic Matrix Operations under Bicyclic Encoding</title>
<link>https://eprint.iacr.org/2024/1762</link>
<guid>https://eprint.iacr.org/2024/1762</guid>
<content:encoded><![CDATA[
<div> 关键词: homomorphic encryption, matrix operations, bicyclic encoding, BMM-I, BMM-II

总结:
本文提出了一种新的矩阵编码方法——双循环编码（bicyclic encoding），该方法被应用于加密矩阵乘法中。基于此编码方式，作者提出了两种加密矩阵乘法算法BMM-I和BMM-II。理论上，BMM-II的表现优于当前最先进的算法，而在实践中，当处理高维度矩阵时，BMM-I结合分段策略展现出优秀性能。此外，双循环编码的一个显著优点在于可以免费地对加密矩阵进行转置操作。通过概念验证实现的全面实验研究表明，本文提出的每个算法在特定场景下都超越了现有算法，速度提升范围从2倍到38倍。 <div>
Homomorphically encrypted matrix operations are extensively  used in various privacy-preserving applications. Consequently, reducing the cost of encrypted matrix operations is a crucial topic on which numerous studies have been conducted. In this paper, we introduce a novel matrix encoding method, named bicyclic encoding, under which we propose two new algorithms BMM-I and BMM-II for encrypted matrix multiplication. BMM-II outperforms the stat-of-the-art algorithms in theory, while BMM-I, combined with the segmented strategy, performs well in practice, particularly for matrices with high dimensions. Another noteworthy advantage of bicyclic encoding is that it allows for transposing an encrypted matrix entirely free. A comprehensive experimental study based on our proof-of-concept implementation shows that each algorithm introduced in this paper has specific scenarios outperforming existing algorithms, achieving speedups ranging from 2x to 38x.
]]></content:encoded>
<pubDate>Tue, 29 Oct 2024 09:58:53 +0000</pubDate>
</item>
<item>
<title>HTCNN: High-Throughput Batch CNN Inference with Homomorphic Encryption for Edge Computing</title>
<link>https://eprint.iacr.org/2024/1753</link>
<guid>https://eprint.iacr.org/2024/1753</guid>
<content:encoded><![CDATA[
<div> 关键词: Homomorphic Encryption, CNN, CKKS, Latency, Throughput

总结:
本文探讨了同态加密（HE）技术在保护隐私的同时实现数据处理的可能性，特别是在CNN推理中的应用。CKKS算法因其对实数计算的支持而在同态CNN推理中受到青睐，但其存在的计算延迟和资源开销问题限制了其实用性。针对这一现状，文章提出了一种基于CKKS的分级同态CNN推理新方案，旨在减少延迟并提高吞吐量。该策略利用卷积的滑动窗口属性和CKKS的单指令多数据（SIMD）特性，将多个输入映射到一组密文上。同时，为了进一步优化速度，还引入了包括掩模权重合并、旋转复用、步长卷积分割和折叠旋转在内的多项技术。通过在MNIST和CIFAR-10数据集上的评估实验，证明了该同态推理方案的有效性。对于MNIST数据集，单CPU线程下163张图像的推理可在10.4秒内完成，准确率达到98.9%，相比现有最佳方法提高了6.9倍的吞吐量。对比分析显示，该提案在延迟、吞吐量、通信开销和内存利用率等方面均展现出优越性能。 <div>
Homomorphic Encryption (HE) technology allows for processing encrypted data, breaking through data isolation barriers and providing a promising solution for privacy-preserving computation. The integration of HE technology into Convolutional Neural Network (CNN) inference shows potential in addressing privacy issues in identity verification, medical imaging diagnosis, and various other applications. The CKKS HE algorithm stands out as a popular option for homomorphic CNN inference due to its capability to handle real number computations. However, challenges such as computational delays and resource overhead present significant obstacles to the practical implementation of homomorphic CNN inference, largely due to the complex nature of HE operations. In addition, current methods for speeding up homomorphic CNN inference primarily address individual images or large batches of input images, lacking a solution for efficiently processing a moderate number of input images with fast homomorphic inference capabilities, which is more suitable for edge computing applications. In response to these challenges, we introduce a novel leveled homomorphic CNN inference scheme aimed at reducing latency and improving throughput using the CKKS scheme. Our proposed inference strategy involves mapping multiple inputs to a set of ciphertext by exploiting the sliding window properties of convolutions to utilize CKKS's inherent Single-Instruction-Multiple-Data (SIMD) capability. To mitigate the delay associated with homomorphic CNN inference, we introduce optimization techniques, including mask-weight merging, rotation multiplexing, stride convolution segmentation, and folding rotations. The efficacy of our homomorphic inference scheme is demonstrated through evaluations carried out on the MNIST and CIFAR-10 datasets. Specifically, results from the MNIST dataset on a single CPU thread show that inference for 163 images can be completed in 10.4 seconds with an accuracy of 98.9%, which is a 6.9 times throughput improvement over state-of-the-art works. Comparative analysis with existing methodologies highlights the superior performance of our proposed inference scheme in terms of latency, throughput, communication overhead, and memory utilization.
]]></content:encoded>
<pubDate>Mon, 28 Oct 2024 03:32:21 +0000</pubDate>
</item>
<item>
<title>Secure and Privacy-preserving CBDC Offline Payments using a Secure Element</title>
<link>https://eprint.iacr.org/2024/1746</link>
<guid>https://eprint.iacr.org/2024/1746</guid>
<content:encoded><![CDATA[
<div> 关键词: 中央银行数字货币、离线支付、双花攻击、安全元素、移动设备

总结:
本文探讨了中央银行数字货帀如何利用离线支付解决现有数字支付方案中的金融包容性不足问题。然而，离线支付的安全设计非常复杂，特别是在网络连接缺失的情况下，双花攻击变得容易发生。为防范这类攻击，文章提出采用安全元素作为预防措施，但鉴于其计算和存储能力有限，难以保证与实体现金相当的隐私保障。因此，文中提出一种协议，将大部分支付计算任务交给用户的移动设备处理，而仅在安全元素上执行删除已使用代币及生成等效于ECDSA签名的计算。该文主张对于消费者之间的安全支付，需要使用移动设备或增强型智能卡设备。为了进一步强化协议安全性，还实现了对成功实施双花攻击的攻击者进行高效识别的功能。最后，通过理想/现实世界范式证明了协议的安全性，并对其性能进行了评估，证实其实用性。 <div>
Offline payments present an opportunity for central bank digital currency to address the lack of digital financial inclusion plaguing existing digital payment solutions. However, the design of secure offline payments is a complex undertaking; for example, the lack of connectivity during the payments renders double spending attacks trivial. While the identification of double spenders and penal sanctions may curb attacks by individuals, they may not be sufficient against concerted efforts by states or well-funded institutions. It is hence important to also rely on preventive measures that reduce the scale of such attacks. An example of such a measure is secure elements. These however are limited in compute and storage, making the design of solutions that offer comparable privacy guarantees to those of physical cash challenging.
We address this with a protocol that offloads most of the payment computation to the user’s mobile device and restricts the computation on the secure element to deleting spent tokens, and generating a signature with a computation equivalent to that of ECDSA. We claim that the use of mobile devices or enhanced smart card-based devices are required for secure consumer-to-consumer payments. To further harden the protocol, we enable the efficient identification of double spenders on the off-chance an attacker successfully double spends. Finally, we prove its security in the ideal/real world paradigm, and evaluate its performance to demonstrate its practicality.
]]></content:encoded>
<pubDate>Fri, 25 Oct 2024 11:44:06 +0000</pubDate>
</item>
<item>
<title>Secure and Efficient Outsourced Matrix Multiplication with Homomorphic Encryption</title>
<link>https://eprint.iacr.org/2024/1730</link>
<guid>https://eprint.iacr.org/2024/1730</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密（FHE）、神经网络、矩阵乘法、 SIMD、KeySwitch操作

总结：<br />
本文主要关注全同态加密（FHE）下神经网络评估的优化问题。研究重点在于改进矩阵乘法这一关键操作，通过利用FHE中的Single Instruction Multiple Data（SIMD）特性，提高数据打包效率并降低昂贵的KeySwitch操作次数，从而使多级乘法深度降至仅两层。当前最佳的两层深度下的矩阵乘法复杂度为$\mathcal{O}(d)$，而本方法将其降低到$\mathcal{O}(\log{d})$，同时保持了相同级别的数据打包效率。此外，该技术还被推广至支持任意打包大小和矩形矩阵的情况，从而显著提升了隐私保护环境下神经网络应用的矩阵乘法性能。 <div>
Fully Homomorphic Encryption (FHE) is a promising privacy-enhancing technique that enables secure and private data processing on untrusted servers, such as privacy-preserving neural network (NN) evaluations. However, its practical application presents significant challenges. Limitations in how data is stored within homomorphic ciphertexts and restrictions on the types of operations that can be performed create computational bottlenecks. As a result, a growing body of research focuses on optimizing existing evaluation techniques for efficient execution in the homomorphic domain.

One key operation in this space is matrix multiplication, which forms the foundation of most neural networks. Several studies have even proposed new FHE schemes specifically to accelerate this operation. The optimization of matrix multiplication is also the primary goal of our work. We leverage the Single Instruction Multiple Data (SIMD) capabilities of FHE to increase data packing and significantly reduce the KeySwitch operation count— an expensive low-level routine in homomorphic encryption. By minimizing KeySwitching, we surpass current state-of-the-art solutions, requiring only a minimal multiplicative depth of two.

The best-known complexity for matrix multiplication at this depth is $\mathcal{O}(d)$ for matrices of size  $d\times d$. Remarkably, even the leading techniques that require a multiplicative depth of three still incur a KeySwitch complexity of $\mathcal{O}(d)$. In contrast, our method reduces this complexity to $\mathcal{O}(\log{d})$ while maintaining the same level of data packing. Our solution broadly applies to all FHE schemes supporting Single Instruction Multiple Data (SIMD) operations.
We further generalize the technique in two directions: allowing arbitrary packing availability and extending it to rectangular matrices. This versatile approach offers significant improvements in matrix multiplication performance and enables faster evaluation of privacy-preserving neural network applications.
]]></content:encoded>
<pubDate>Tue, 22 Oct 2024 12:34:34 +0000</pubDate>
</item>
<item>
<title>PISA: Privacy-Preserving Smart Parking</title>
<link>https://eprint.iacr.org/2024/1725</link>
<guid>https://eprint.iacr.org/2024/1725</guid>
<content:encoded><![CDATA[
<div> 关键词: 城市停车、私人停车位共享、PISA、隐私保护、安全协议

<br /><br />总结:
随着城市车辆数量急剧增加和停车场供应量相对固定，造成了严重的停车难问题。为了解决这一问题并帮助车主创收，文章提出了一个名为PISA的创新性隐私保护智能停车方案。PISA通过一种加密安全协议，实现了私人停车位在业主不在时的临时匿名共享，使得驾驶员可以在不泄露个人身份信息的情况下停车。该方案的核心贡献包括构建了一个全面的双向匿名框架，确保双方彼此无法识别，同时利用形式化验证方法证明了其安全措施的健全性和可靠性。与现有解决方案相比，PISA在保障安全性的同时也注重效率。 <div>
In recent years, urban areas have experienced a rapid increase in vehicle numbers, while the availability of parking spaces has remained largely static, leading to a significant shortage of parking spots. This shortage creates considerable inconvenience for drivers and contributes to traffic congestion. A viable solution is the temporary use of private parking spaces by homeowners during their absence, providing a means to alleviate the parking problem and generate additional income for the owners. However, current systems for sharing parking spaces often neglect security and privacy concerns, exposing users to potential risks.
This paper presents PISA, a novel Privacy-Preserving Smart Parking scheme designed to address these issues through a cryptographically secure protocol. PISA enables the anonymous sharing of parking spots and allows vehicle owners to park without revealing any personal identifiers. Our primary contributions include the development of a comprehensive bi-directional anonymity framework that ensures neither party can identify the other, and the use of formal verification methods to substantiate the soundness and reliability of our security measures. Unlike existing solutions, which often lack a security focus, fail to provide formal validation, or are computationally intensive, PISA is designed to be both secure and efficient.
]]></content:encoded>
<pubDate>Mon, 21 Oct 2024 20:36:00 +0000</pubDate>
</item>
<item>
<title>$\mathsf{OPA}$: One-shot Private Aggregation with Single Client Interaction and its Applications to Federated Learning</title>
<link>https://eprint.iacr.org/2024/723</link>
<guid>https://eprint.iacr.org/2024/723</guid>
<content:encoded><![CDATA[
<div> 关键词：安全聚合，一次性私有聚合（$\mathsf{OPA}$），通信轮次，联邦学习，阈值密钥同态PRF

总结:<br />
本文主要研究了在单服务器设置下的安全聚合问题，提出了仅交互一次的一次性私有聚合协议$\mathsf{OPA}$，该协议允许客户端在每次聚合评估中仅发言一次，简化了对掉线和动态参与情况的管理。与需要多轮交互的传统联邦学习协议不同，$\mathsf{OPA}$应用于隐私保护的联邦学习场景中，客户端只需一次交互。此外，$\mathsf{OPA}$不需要复杂的委员会选择协议即可实现适应性安全性，相比现有方案在实际性能上有所提升，并在多个数据集上进行了基准测试。文章构建了两种版本的$\mathsf{OPA}$，分别基于阈值密钥同态PRF和种子同态PRG及秘密共享。其中，阈值密钥同态PRF旨在解决依赖DDH和LWR的先前工作中的不足，同时文中还提出基于类群、DCR或LWR假设的新阈值密钥同态PRF。 <div>
Our work aims to minimize interaction in secure computation due to the high cost and challenges associated with communication rounds, particularly in scenarios with many clients. In this work, we revisit the problem of secure aggregation in the single-server setting where a single evaluation server can securely aggregate client-held individual inputs. Our key contribution is the introduction of One-shot Private Aggregation ($\mathsf{OPA}$) where clients speak only once (or even choose not to speak) per aggregation evaluation. Since each client communicates only once per aggregation, this simplifies managing dropouts and dynamic participation, contrasting with multi-round protocols and aligning with plaintext secure aggregation, where clients interact only once. 

We construct $\mathsf{OPA}$ based on LWR, LWE, class groups, DCR and demonstrate applications to privacy-preserving Federated Learning (FL) where clients {speak once}. This is a sharp departure from prior multi-round FL protocols whose study was initiated by Bonawitz et al. (CCS, 2017). Moreover, unlike the YOSO (You Only Speak Once) model for general secure computation, $\mathsf{OPA}$ eliminates complex committee selection protocols to achieve adaptive security. Beyond asymptotic improvements, $\mathsf{OPA}$ is practical, outperforming state-of-the-art solutions. We benchmark logistic regression classifiers for two datasets, while also building an MLP classifier to train on MNIST, CIFAR-10, and CIFAR-100 datasets.

We build two flavors of $\mathsf{OPA}$ (1) from (threshold) key homomorphic PRF and (2) from seed homomorphic PRG and secret sharing. 
The threshold Key homomorphic PRF addresses shortcomings observed in previous works that relied on DDH and LWR in the work of Boneh et al. (CRYPTO, 2013), marking it as an independent contribution to our work. Moreover, we also present new threshold key homomorphic PRFs based on class groups or DCR or the LWR assumption.
]]></content:encoded>
<pubDate>Sat, 11 May 2024 01:20:12 +0000</pubDate>
</item>
<item>
<title>Scalable Mixnets from Two-Party Mercurial Signatures on Randomizable Ciphertexts</title>
<link>https://eprint.iacr.org/2024/1503</link>
<guid>https://eprint.iacr.org/2024/1503</guid>
<content:encoded><![CDATA[
<div> 关键词: mixnet、Hébant et al.、homomorphic signatures、mercurial signatures、receipt-free voting

总结:
针对投票领域的隐私保护需求，文章指出现有由Hébant等人提出的mixnet方案因依赖于信任权威机构而存在局限性。为此，研究者们利用最近在等价类签名上的进展，将同态签名替换为新开发的两方随机化密文上的水银签名。这种改进使得用户和权威机构能在保持嵌入消息的同时，共同签署并随机化密钥、密文和签名，从而实现无需信任权威机构即可保证投票隐私的收据自由投票。通过与其它可扩展mixnet解决方案对比及实施协议并提供具体性能基准测试，结果显示新方案在计算效率和通信效率上均显著优于现有替代方案，例如，在一台普通笔记本电脑上使用十个混合器验证50,000个密文的混合过程仅需135秒，证明了该方法的实际可行性。 <div>
A mixnet developed by Hébant et al. (PKC '20) employs certified ciphertexts that carry homomorphic signatures from an authority, reducing the complexity of the shuffling proof, and thereby enabling efficient large-scale deployment. However, their privacy relies on trusting the authority, making it unsuitable for voting, the primary application of mixnets.

Building on the prior work, we leverage recent advances in equivalence class signatures by replacing homomorphic signatures with newly developed two-party mercurial signatures on randomizable ciphertexts. This allows users and the authority to jointly sign ciphertexts and randomize keys, ciphertexts, and signatures, all while preserving the embedded messages. We demonstrate that our mixnet is suitable for receipt-free voting without requiring trust in the signing authority for privacy.

To assess scalability, we compare our approach to other scalable mixnet solutions, implement our protocols, and provide concrete performance benchmarks. Our results show that our mixnet significantly outperforms existing alternatives in both computation and communication efficiency. Specifically, verifying the mixing process for 50,000 ciphertexts takes just 135 seconds on a commodity laptop using ten mixers, illustrating the practical viability of our approach.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 08:05:18 +0000</pubDate>
</item>
<item>
<title>Dumbo-MPC: Efficient Fully Asynchronous MPC with Optimal Resilience</title>
<link>https://eprint.iacr.org/2024/1705</link>
<guid>https://eprint.iacr.org/2024/1705</guid>
<content:encoded><![CDATA[
<div> 关键词: 完全异步多 party 计算 (AMPC), 隐私保护, 保证输出交付 (G.O.D.), Dumbo-MPC, HoneyBadgerMPC, 抗恶意攻击

总结:
本文提出了一种名为 Dumbo-MPC 的全新完全异步多 party 计算 (AMPC) 设计方案，旨在解决现有 AMPC 协议在实际应用中的局限性，如非最优鲁棒性、高通信成本和额外的在线加密开销。Dumbo-MPC 提供了全面的 G.O.D. 和对 $t3$ 恶意参与者的最优鲁棒性保障（总参与者数为 $n$）。其在线阶段与 HoneyBadgerMPC 类似，具有稳健的、几乎信息理论级别的安全性，但不同的是，Dumbo-MPC 设计了一个创新的双模式离线协议，能在异步环境中鲁棒地预处理乘法三元组。该协议在乐观情况下每三元组通信复杂度为 $O(n)$，并在出现故障时无缝切换到悲观路径以保持 G.O.D. 安全性。为了优化悲观路径的实现效率，文章设计了一种基于紧凑型 KZG 多项式承诺的、针对秘密份额产品关系的高效零知识证明，将两个秘密份额乘积的次数从 $2t$ 减少到 $t$，具有独立的研究价值。

此外，研究者实现了 Dumbo-MPC 并在最多 31 台 AWS 服务器的不同网络设置下进行了详尽评估。据所知，这是首个实现所有阶段 G.O.D. 的 AMPC 实例。文章还将 Dumbo-MPC 与近期由 Groth 和 Shoup 提出的异步三元生成协议 (GS23) 进行了实测对比。当 $n=31$ 时，Dumbo-MPC 在悲观情况下的三元生成速度达到了 94 个/秒（几乎是 GS23 的两倍），而在良好条件下达到了 349 个/秒（比 GS23 快六倍）。这使得 31 个参与者仅需 2-8 分钟即可准备好涉及 100 名竞标者的私人 Vickrey 拍卖的预处理工作，或者只需 10-36 分钟完成包含 $2^{10}$ 输入的混合网络的预处理任务。 <div>
Fully asynchronous multi-party computation (AMPC) has superior robustness in realizing privacy and guaranteed output delivery (G.O.D.) against asynchronous adversaries that can arbitrarily delay communications. However, none of these protocols are truly practical, as they either have sub-optimal resilience, incur cumbersome communication cost, or suffer from an online phase with extra cryptographic overhead. The only attempting implementation---HoneyBadgerMPC (hbMPC)---merely ensures G.O.D. in some implausible optimistic cases due to a non-robust offline pre-processing phase.

We propose Dumbo-MPC a concretely efficient  AMPC-as-a-service design with all phases G.O.D. and optimal resilience against  $t3$ malicious parties (where $n$ is the total number of parties). Same to hbMPC, Dumbo-MPC has a robust (almost) information-theoretic online phase that can efficiently perform online computations, given pre-processed multiplication triples. While for achieving all phases G.O.D., we design a novel dual-mode offline protocol that can robustly pre-process multiplication triples in asynchrony. The offline phase features $O(n)$ per-triple communication in the optimistic case, followed by a fully asynchronous fallback to a pessimistic path to securely restore G.O.D. in the bad case. To efficiently implement the pessimistic path, we devise a concretely efficient zk-proof for product relationship of secret shares over compact KZG polynomial commitments, which enables us to reduce the degree of two secret shares' product from $2t$ to  $t$ and could be of independent interest.

We also implement and extensively evaluate Dumbo-MPC (particularly its offline phase) in varying network settings with up to 31 AWS servers. To our knowledge, we provide the first implementation of AMPC with all-phase G.O.D. A recent asynchronous triple generation protocol from Groth and Shoup (GS23) is also implemented and experimentally compared. When $n = 31$, Dumbo-MPC generates 94 triplessec (almost twice of GS23) in the pessimistic case and 349 triples/sec (6X of GS23) in the good case, such that 31 parties require only 2-8 min to prepare a private Vickrey auction of 100 bidders or 10-36 min for a mixing network of $2^{10}$ inputs.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 12:14:10 +0000</pubDate>
</item>
<item>
<title>From One-Time to Two-Round Reusable Multi-Signatures without Nested Forking</title>
<link>https://eprint.iacr.org/2024/1704</link>
<guid>https://eprint.iacr.org/2024/1704</guid>
<content:encoded><![CDATA[
<div> 关键词: 多重签名方案、两轮方案、DLOG问题、安全性证明、应用

总结:
本文关注了基于DLOG难题安全性的两轮多重签名方案，特别是那些具有键聚合功能并在明文公钥模型中运行的方案。针对现有方案的安全性证明提供的具体保证不足的问题，文章提出了两种放松的安全性概念。首先，定义了一次性不可伪造性，扩展了单签署者情况下的类似概念，允许攻击者获取一条特定消息和一组选定签署者的签名。文章构造了一个基于环同态一维函数的非交互式一次性方案，并提供了基于DLOG和RSA假设的有效实例。其次，提出了单集合不可伪造性，限制攻击者只能使用一组选定的签署者来获取多项签名。通过将任何非交互式一次性方案转换为两轮单集合方案的新颖无分支构造方法，该方法将经典的Naor-Yung树形方法扩展到多签署者场景。文章中的多重签名方案在保持安全性的同时，优化了验证密钥和签名的长度，使其独立于签署者数量。 <div>
Multi-signature schemes are gaining significant interest due to their blockchain applications. Of particular interest are two-round schemes in the plain public-key model that offer key aggregation, and whose security is based on the hardness of the DLOG problem. Unfortunately, despite substantial recent progress, the security proofs of the proposed schemes provide rather insufficient concrete guarantees (especially for 256-bit groups). This frustrating situation has so far been approached either by relying on the security of seemingly stronger assumptions or by considering restricted classes of attackers (e.g., algebraic attackers, which are assumed to provide an algebraic justification of each group element that they produce).

We present a complementing approach by constructing multi-signature schemes that satisfy two relaxed notions of security, whose applicability nevertheless ranges from serving as drop-in replacements to enabling expressive smart contract validation procedures. Our first notion, one-time unforgeability, extends the analogous single-signer notion by considering attackers that obtain a single signature for some message and set of signers of their choice. We construct a non-interactive one-time scheme based on any ring-homomorphic one-way function, admitting efficient instantiations based on the DLOG and RSA assumptions. Aggregated verification keys and signatures consist of two group elements and a single group element, respectively, and our security proof consists of a single application of the forking lemma (thus avoiding the substantial security loss exhibited by the proposed two-round schemes). Additionally, we demonstrate that our scheme naturally extends to a $t$-time scheme, where aggregated verification keys consist of $t+1$ group elements, while aggregated signatures still consist of a single group element.

Our second notion, single-set unforgeability, considers attackers that obtain any polynomial number of signatures but are restricted to a single set of signers of their choice. We transform any non-interactive one-time scheme into a two-round single-set scheme via a novel forking-free construction that extends the seminal Naor-Yung tree-based approach to the multi-signer setting. Aggregated verification keys are essentially identical to those of the underlying one-time scheme, and the length of aggregated signatures is determined by that of the underlying scheme while scaling linearly with the length of messages (noting that long messages can always be hashed using a collision-resistant function). Instantiated with our one-time scheme, we obtain aggregated verification keys and signatures whose lengths are completely independent of the number of signers.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 11:55:05 +0000</pubDate>
</item>
<item>
<title>Secure Computation with Parallel Calls to 2-ary Functions</title>
<link>https://eprint.iacr.org/2024/1701</link>
<guid>https://eprint.iacr.org/2024/1701</guid>
<content:encoded><![CDATA[
<div> 关键词：加密算法、简化的函数、二元函数、安全计算、协议

<br /><br />总结:

本文研究了将任意函数的安全计算简化为仅使用二元函数进行安全计算的问题。首先，文章指出存在一个次数为2的多项式$p$，表明没有任何利用并行调用二元函数的协议可以以统计安全性（带有abort）来计算它。接着，文章给出了两种绕过这一不可能性结果的方法：一是通过弱化安全定义，证明所有次数为2的多项式可以通过并行调用二元函数实现具有统计隐私和已知输出的知识（PwKO）；二是借助计算安全性，证明对于任何函数$f$，都存在一种依赖于半诚实安全盲转移假设的协议，该协议可并行调用二元函数并实现对计算受限敌手的安全性（带有abort）。此外，文章还将此问题与减少多党派随机编码（MPRE）的编码复杂性的任务联系起来，展示在标准计算假设下，存在一种可通过常数扇出的$\mathrm{NC}^0$电路实现编码器的MPRE。最后，文章还探讨了在诚实多数设置和具有三元函数情况下的问题，并分别给出了类似的结果，其中后者在恶意多数设置中假设了一次性函数的存在。 <div>
Reductions are the workhorses of cryptography. They allow constructions of complex cryptographic primitives from simple building blocks. A prominent example is the non-interactive reduction from securely computing a ``complex" function $f$ to securely computing a ``simple" function $g$ via randomized encodings.

    Prior work equated simplicity with functions of small degree. In this work, we consider a different notion of simplicity where we require $g$ to only take inputs from a small number of parties. In other words, we want the arity of $g$ to be as small as possible. 

    In more detail, we consider the problem of reducing secure computation of arbitrary functions to secure computation of functions with arity two (two is the minimal arity required to compute non-trivial functions). Specifically, we want to compute a function $f$ via a protocol that makes parallel calls to 2-ary functions. We want this protocol to be secure against malicious adversaries that could corrupt an arbitrary number of parties. We obtain the following results:
    
- Negative Result: We show that there exists a degree-2 polynomial $p$ such that no protocol that makes parallel calls to 2-ary functions can compute $p$ with statistical security with abort.
            
- Positive Results: We give two ways to bypass the above impossibility result.
             
  1. Weakening the Security Notion. We show that every degree-2 polynomial can be computed with statistical privacy with knowledge of outputs (PwKO) by making parallel calls to 2-ary functions. Privacy with knowledge of outputs is weaker than security with abort.
                        
  2. Computational Security. We prove that for every function $f$, there exists a protocol for computing $f$ that makes parallel calls to 2-ary functions and achieves security with abort against computationally-bounded adversaries. The security of this protocol relies on the existence of semi-honest secure oblivious transfer.
              
- Applications: We give connections between this problem and the task of reducing the encoding complexity of Multiparty Randomized Encodings (MPRE) (Applebaum, Brakerski, and Tsabary, TCC 2018). Specifically, we show that under standard computational assumptions, there exists an MPRE where the encoder can be implemented by an $\mathrm{NC}^0$ circuit with constant fan-out.
  
- Extensions: We explore this problem in the honest majority setting and give similar results assuming one-way functions. We also show that if the parties have access to 3-ary functions then we can construct a computationally secure protocol in the dishonest majority setting assuming one-way functions.
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 04:58:31 +0000</pubDate>
</item>
<item>
<title>Updatable Privacy-Preserving Blueprints</title>
<link>https://eprint.iacr.org/2023/1787</link>
<guid>https://eprint.iacr.org/2023/1787</guid>
<content:encoded><![CDATA[
<div> 隐私保护蓝图方案 更新 零知识证明 同态加密 蓝图大小<br /><br />总结:<br />本文介绍了一种新的隐私保护蓝图方案（UPPB），该方案允许多个用户非交互式地更新其私人输入，同时保持更新过程的隐私性。与原始方案相比，UPPB引入了对累积输入进行验证的能力，而无需泄露用户的私人信息。本文提出了UBlu方案，专门用于比较用户累计输入和审计员提供的固定值，适用于反洗钱等场景。技术上，通过引入一种新颖的可塑性表征方法，有效控制了蓝图的大小，使其不依赖于更新次数，从而适用于实际应用。这一方案基于全同态加密和非交互式零知识证明构建。 <div>
Privacy-preserving blueprint schemes (Kohlweiss et al., EUROCRYPT'23) offer a mechanism for safeguarding user's privacy while allowing for specific legitimate controls by a designated auditor agent. 

These schemes enable users to create escrows encrypting the result of evaluating a function $y=P(t,x)$, with $P$ being publicly known, $t$ a secret used during the auditor's key generation, and $x$ the user's private input.  Crucially, escrows only disclose the blueprinting result $y=P(t,x)$ to the designated auditor, even in cases where the auditor is fully compromised. The original definition and construction only support the evaluation of functions $P$ on an input $x$ provided by a single user. 
    
We address this limitation by introducing updatable privacy-preserving blueprint schemes (UPPB), which enhance the original notion with the ability for multiple users to non-interactively update the private user input $x$ while blueprinting. Moreover, UPPBs contain a proof that $y$ is the result of a sequence of valid updates, while revealing nothing else about the private inputs $\{x_i\}$ of updates. As in the case of privacy-preserving blueprints, we first observe that UPPBs can be realized via a generic construction for arbitrary predicates $P$ based on FHE and NIZKs. Our main result is UBlu, an efficient instantiation for a specific predicate comparing the values $x$ and $t$, where $x$ is the cumulative sum of users' private inputs and $t$ is a fixed private value provided by the auditor in the setup phase. This rather specific setting already finds interesting applications such as privacy-preserving anti-money laundering and location tracking, and can be extended to support more generic predicates.
    
From the technical perspective, we devise a novel technique to keep the escrow size concise, independent of the number of updates, and reasonable for practical applications. We achieve this via a novel characterization of malleability for the algebraic NIZK by Couteau and Hartmann (CRYPTO’20) that allows for an additive update function.
]]></content:encoded>
<pubDate>Sun, 19 Nov 2023 17:36:23 +0000</pubDate>
</item>
<item>
<title>Computational Attestations of Polynomial Integrity Towards Verifiable Machine Learning</title>
<link>https://eprint.iacr.org/2024/639</link>
<guid>https://eprint.iacr.org/2024/639</guid>
<content:encoded><![CDATA[
<div> 零知识证明 差分隐私 线性回归 MLaaS 计算效率<br /><br />总结: 本文展示了使用零知识证明技术验证差分隐私线性回归训练的过程。实验在单机上对50,000样本数据集进行训练，耗时不到6分钟，并且验证整个计算过程仅需0.17秒。据我们所知，这是目前文献中已知的针对如此大规模数据集的最快可证明差分隐私实例。这一结果被认为是构建端到端隐私机器学习即服务（MLaaS）的关键步骤。 <div>
Machine-learning systems continue to advance at a rapid pace, demonstrating remarkable utility in various fields and disciplines. As these systems continue to grow in size and complexity, a nascent industry is emerging which aims to bring machine-learning-as-a-service (MLaaS) to market. Outsourcing the operation and training of these systems to powerful hardware carries numerous advantages, but challenges arise when privacy and the correctness of work carried out must be ensured. Recent advancements in the field of zero-knowledge cryptography have led to a means of generating arguments of integrity for any computation, which in turn can be efficiently verified by any party, in any place, at any time. In this work we prove the correct training of a differentially-private (DP) linear regression over a dataset of 50,000 samples on a single machine in less than 6 minutes, verifying the entire computation in 0.17 seconds. To our knowledge, this result represents the fastest known instance in the literature of provable-DP over a dataset of this size. We believe this result constitutes a key stepping-stone towards end-to-end private MLaaS.
]]></content:encoded>
<pubDate>Fri, 26 Apr 2024 02:17:26 +0000</pubDate>
</item>
<item>
<title>Non-Interactive Threshold BBS+ From Pseudorandom Correlations</title>
<link>https://eprint.iacr.org/2023/1076</link>
<guid>https://eprint.iacr.org/2023/1076</guid>
<content:encoded><![CDATA[
<div> 阈值签名 非交互式签名 子线性通信 多方计算 普遍组合模型<br /><br />总结: 本文提出了一种新的$t$-out-of-$n$门限BBS+协议，以解决单点故障问题。该协议支持任意安全阈值$t \leq n$，并在预处理设置中实现了非交互式签名和子线性通信复杂度。文中设计了专门的预签名，可以直接从伪随机相关性计算得到，使得服务器可以在没有跨服务器通信的情况下创建签名份额。该协议在主动安全性的普遍组合模型中有效。实验结果表明，对于$t \leq 30$的情况，在线协议执行时间少于15毫秒，且在线签名过程中$t$的影响小于6%，大部分开销发生在离线阶段。此外，本文实现的PCG扩展是首个考虑多于3方之间相关性的实现，显示了即使在10个服务器组成的委员会中，每个服务器也可以在大约600毫秒内扩展多达$2^{16}$个预签名。 <div>
The BBS+ signature scheme is one of the most prominent solutions for realizing anonymous credentials. Its prominence is due to properties like selective disclosure and efficient protocols for creating and showing possession of credentials. Traditionally, a single credential issuer produces BBS+ signatures, which poses significant risks due to a single point of failure.

In this work, we address this threat via a novel $t$-out-of-$n$ threshold BBS+ protocol. Our protocol supports an arbitrary security threshold $t \leq n$ and works in the so-called preprocessing setting. In this setting, we achieve non-interactive signing in the online phase and sublinear communication complexity in the number of signatures in the offline phase, which, as we show in this work, are important features from a practical point of view. As it stands today, none of the widely studied signature schemes, such as threshold ECDSA and threshold Schnorr, achieve both properties simultaneously. To this end, we design specifically tailored presignatures that can be directly computed from pseudorandom correlations and allow servers to create signature shares without additional cross-server communication. Both our offline and online protocols are actively secure in the Universal Composability model. Finally, we evaluate the concrete efficiency of our protocol, including an implementation of the online phase and the expansion algorithm of the pseudorandom correlation generator (PCG) used during the offline phase. The online protocol without network latency takes less than $15 ms$ for $t \leq 30$ and credentials sizes up to $10$. Further, our results indicate that the influence of $t$ on the online signing is insignificant, $< 6 \%$ for $t \leq 30$, and the overhead of the thresholdization occurs almost exclusively in the offline phase. Our implementation of the PCG expansion is the first considering correlations between more than $3$ parties and shows that even for a committee size of $10$ servers, each server can expand a correlation of up to $2^{16}$ presignatures in about $600$ ms per presignature.
]]></content:encoded>
<pubDate>Tue, 11 Jul 2023 05:09:29 +0000</pubDate>
</item>
<item>
<title>Overlapped Bootstrapping for FHEW/TFHE and Its Application to SHA3</title>
<link>https://eprint.iacr.org/2024/1667</link>
<guid>https://eprint.iacr.org/2024/1667</guid>
<content:encoded><![CDATA[
<div> bootstrapping, FHEW/TFHE, 加密数据, Keccak, 性能提升<br /><br />总结: 本文提出了一种针对FHEW和TFHE方案的新颖高效引导方法，该方法利用加密数据的可变缩放因子，尤其适用于连续异或门电路。实验结果显示，这种方法将基于FHEW/TFHE的Keccak函数的运行时间减少了42%。新方法无需额外密钥或参数集，由计算方直接采用，无需额外信息。文章指出，尽管FHEW和TFHE因其轻量级特性和对任意逻辑门的支持而适合用于智能合约，但它们需要在每次执行二进制门后进行引导操作，这成为性能瓶颈。本文提出的引导方法旨在解决这一问题。 <div>
Homomorphic Encryption (HE) enables operations on encrypted data without requiring decryption, thus allowing for secure handling of confidential data within smart contracts.  Among the known HE schemes, FHEW and TFHE are particularly notable for use in smart contracts due to their lightweight nature and support for arbitrary logical gates. In contrast, other HE schemes often require several gigabytes of keys and are limited to supporting only addition and multiplication.  As a result, there has been significant work implementing smart contract functionalities over HE, broadening the potential applications of blockchain technology.  However, a significant drawback of the FHEW/TFHE schemes is the need for bootstrapping after the execution of each binary gate. While bootstrapping reduces noise in the ciphertext, it also becomes a performance bottleneck due to its computational complexity.

In this work, we propose an efficient new bootstrapping method for FHEW/TFHE that takes advantage of the flexible scaling factors of encrypted data.  The proposed method is particularly beneficial in circuits with consecutive XOR gates.  Moreover, we implement Keccak using FHEW/TFHE, as it is one of the most important functions in smart contracts.  Our experimental results demonstrate that the proposed method reduces the runtime of Keccak over HE by 42%. Additionally, the proposed method does not require additional keys or parameter sets from the key-generating party and can be adopted by the computing party without need for any extra information.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 03:43:52 +0000</pubDate>
</item>
<item>
<title>HADES: Range-Filtered Private Aggregation on Public Data</title>
<link>https://eprint.iacr.org/2024/1699</link>
<guid>https://eprint.iacr.org/2024/1699</guid>
<content:encoded><![CDATA[
<div> 隐私保护 聚合查询 全同态加密 范围谓词 布尔组合<br /><br />总结: 本文介绍了一种名为HADES的全同态加密（FHE）基础的私有聚合系统，旨在处理公共数据中的隐私保护问题。现有解决方案要么需要额外设置，要么效率低下，尤其是不支持范围谓词和布尔组合。HADES系统支持点、范围谓词及布尔组合，并通过利用公有数据记录的明文形式，高效生成谓词指示器。该系统引入了元素级映射操作和优化的缩减算法，实现了在有限噪声预算内的低延迟。实验结果显示，HADES在端到端TPC-H查询中性能提升了204至6574倍，将100万条记录的聚合时间从15小时缩短到了38秒。这一改进使得HADES在实际应用中具有更高的可扩展性和效率。 <div>
In aggregation queries, predicate parameters often reveal user intent. Protecting these parameters is critical for user privacy, regardless of whether the database is public or private. While most existing works focus on private data settings, we address a public data setting where the server has access to the database. Current solutions for this setting either require additional setups (e.g., noncolluding servers, hardware enclaves) or are inefficient for practical workloads. Furthermore, they often do not support range predicates or boolean combinations commonly seen in real-world use cases. 

To address these limitations, we built HADES, a fully homomorphic encryption (FHE) based private aggregation system for public data that supports point, range predicates, and boolean combinations. Our one-round HADES protocol efficiently generates predicate indicators by leveraging the plaintext form of public data records. It introduces a novel elementwise-mapping operation and an optimized reduction algorithm, achieving latency efficiency within a limited noise budget. Our highly scalable, multi-threaded implementation improves performance over previous one-round FHE solutions by 204x to 6574x on end-to-end TPC-H queries, reducing aggregation time on 1M records from 15 hours to 38 seconds
]]></content:encoded>
<pubDate>Fri, 18 Oct 2024 00:07:06 +0000</pubDate>
</item>
<item>
<title>Homomorphic Encryption with Authority</title>
<link>https://eprint.iacr.org/2024/1689</link>
<guid>https://eprint.iacr.org/2024/1689</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密，隐私保护，公共安全，权威机构，法律授权<br /><br />总结:<br />本文介绍了一种名为HEwA（具有权威的同态加密）的新框架，旨在平衡数据隐私与公共安全。HEwA在正常阶段保护客户数据隐私，在调查阶段允许政府等合法授权机构恢复可疑客户的加密数据。文章提出了HEwA的安全模型，并以CKKS同态加密方案为基础设计了一个高效系统，适用于AI领域如安全基因分析。该方法解决了云计算服务中隐私与公共安全之间的紧张关系，为实际应用中的同态加密负责任使用铺平了道路。 <div>
Fully homomorphic encryption enables computations over encrypted data, which allows privacy-preserving services to be held between a server and a client. However, real-world applications demand practical considerations, especially concerning public safety and legal investigations. Existing FHE schemes focus solely on privacy, neglecting the societal risks posed by criminal activities utilizing privacy-preserving services. This paper introduces Homomorphic Encryption with Authority (HEwA), a novel framework that balances data privacy with public safety by incorporating an "authority" party. The proposed HEwA system operates in two phases: a normal phase, where client data privacy is protected, and an investigative phase, where the authority referring to a legally authorized entity such as government agencies exerts the right to recover suspicious client’s data. We formalize the security model for HEwA, ensuring that client privacy is protected during the normal phase while enabling authorities to recover encrypted data in the investigative phase. As a concrete example, we design an efficient HEwA system solely based on the CKKS homomorphic encryption scheme, which supports approximate computations over real-number data, making it highly suitable for fruitful applications in AI such as secure genomic analysis. We further provide rigorous security proofs. This new approach addresses the tension between privacy and public safety in cloud services, paving the way for responsible use of homomorphic encryption in practice.
]]></content:encoded>
<pubDate>Thu, 17 Oct 2024 05:59:21 +0000</pubDate>
</item>
<item>
<title>Sunfish: Reading Ledgers with Sparse Nodes</title>
<link>https://eprint.iacr.org/2024/1680</link>
<guid>https://eprint.iacr.org/2024/1680</guid>
<content:encoded><![CDATA[
<div> sparse node, light node, full node, throughput, Sunfish<br /><br />总结:<br />文章提出了区块链中的一种新型节点——稀疏节点（sparse node），以解决高吞吐量区块链中全节点和轻节点存在的问题。稀疏节点只跟踪区块链的一部分状态，验证与其子状态相关的交易集是否完整并重新执行这些交易来评估其有效性。这种节点即使在恶意多数情况下也保持重要的安全属性，并且资源需求与子状态中的交易数量和子状态大小成比例。文中还介绍了Sunfish，一种稀疏节点协议的实现，分析表明Sunfish相比全节点可将带宽消耗降低几个数量级。这为提高区块链应用效率提供了一种新方法。 <div>
The increased throughput offered by modern blockchains, such as Sui, Aptos, and Solana, enables processing thousands of transactions per second, but it also introduces higher costs for decentralized application (dApp) developers who need to track and verify changes in the state of their application. This is true because dApp developers run full nodes, which download and re-execute every transaction to track the global state of the chain. However, this becomes prohibitively expensive for high-throughput chains due to high bandwidth, computational, and storage requirements. A common alternative is to use light nodes. However, light nodes only verify the inclusion of a set of transactions and have no guarantees that the set is complete, i.e., that includes all relevant transactions. Under a dishonest majority, light nodes can also be tricked into accepting invalid transactions.

To bridge the gap between full and light nodes, we propose and formalize a new type of blockchain node: the sparse node. A sparse node tracks only a subset of the blockchain’s state: it verifies that the received set of transactions touching the substate is complete, and re-executes those transactions to assess their validity. A sparse node retains important security properties even under adversarial majorities, and requires an amount of resources proportional to the number of transactions in the substate and to the size of the substate itself. 

We further present Sunfish, an instantiation of a sparse node protocol. Our analysis and evaluation show that Sunfish reduces the bandwidth consumption of real blockchain applications by several orders of magnitude when compared to a full node.
]]></content:encoded>
<pubDate>Wed, 16 Oct 2024 13:36:17 +0000</pubDate>
</item>
<item>
<title>Testing Robustness of Homomorphically Encrypted Split Model LLMs</title>
<link>https://eprint.iacr.org/2024/1675</link>
<guid>https://eprint.iacr.org/2024/1675</guid>
<content:encoded><![CDATA[
<div> 关键词：大语言模型, 全同态加密, 模型保护, 攻击向量, 本地计算<br /><br />总结: 本文探讨了使用全同态加密（FHE）技术在大语言模型（LLMs）中保护神经网络模型知识产权的方法。由于LLMs规模庞大及FHE计算开销高，实际应用中采用了一种分割模型的方法，即将加密数据发送到服务器进行部分计算，其余计算则在用户端完成。然而，研究发现这种做法存在缺陷，即用户可以通过新的攻击手段轻易提取服务器上的模型知识产权，从而削弱了加密计算所宣称的保护效果。文章分析了这一攻击的可行性，并讨论了可能的缓解措施。 <div>
Large language models (LLMs) have recently transformed many industries, enhancing content generation, customer service agents, data analysis and even software generation. These applications are often hosted on remote servers to protect the neural-network model IP; however, this raises concerns about the privacy of input queries. Fully Homomorphic Encryption (FHE), an encryption technique that allows for computations on private data, has been proposed as a solution to the challenge. Nevertheless, due to the increased size of LLMs and the computational overheads of FHE, today's practical FHE LLMs are implemented using a split model approach. Here, a user sends their FHE encrypted data to the server to run an encrypted attention head layer; then the server returns the result of the layer for the user to run the rest of the model locally. By employing this method, the server maintains part of their model IP, and the user still gets to perform private LLM inference. In this work, we evaluate the neural-network model IP protections of single layer split model LLMs, and demonstrate a novel attack vector that makes it easy for a user to extract the neural network model IP from the server, bypassing the claimed protections for encrypted computation. In our analysis, we demonstrate the feasibility of this attack, and discuss potential mitigations.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:50:31 +0000</pubDate>
</item>
<item>
<title>Provable Security Analysis of Butterfly Key Mechanism Protocol in IEEE 1609.2.1 Standard</title>
<link>https://eprint.iacr.org/2024/1674</link>
<guid>https://eprint.iacr.org/2024/1674</guid>
<content:encoded><![CDATA[
<div> 关键词：Butterfly Key Mechanism, V2X通信, 安全性分析, 隐私保护, 通信真实性<br /><br />总结: 本文对IEEE 1609.2.1标准中的Butterfly Key Mechanism（BKM）协议进行了首次安全性分析。BKM协议旨在高效地为车辆到一切（V2X）通信请求多个证书。我们定义了BKM的主要安全目标，包括车辆隐私和通信真实性。研究证明，通过少量修改，BKM协议能够满足这些安全目标。此外，还提出了一种显著提高协议效率的方法，同时不牺牲安全性。 <div>
The paper provides the first provable security analysis of the Butterfly Key Mechanism (BKM) protocol from IEEE 1609.2.1 standard. The BKM protocol specifies a novel approach for efficiently requesting multiple certificates for use in vehicle-to-everything (V2X)  communication. We define the main security goals of BKM, such as vehicle privacy and communication authenticity. We prove that the BKM protocol, with small modifications, meets those security goals. We also propose a way to significantly improve the protocol's efficiency without sacrificing security.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:47:48 +0000</pubDate>
</item>
<item>
<title>Proteus: A Fully Homomorphic Authenticated Transciphering Protocol</title>
<link>https://eprint.iacr.org/2024/1673</link>
<guid>https://eprint.iacr.org/2024/1673</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密, 超_cipher转换, 认证, 轻量级加密, 应用

<br /><br />总结:<br />
文章介绍了Proteus，一种新的认证超_cipher转换方法，用于全同态加密（FHE），以实现防篡改的数据处理。Proteus采用NIST推荐的轻量级加密标准ASCON进行同态哈希和认证转换，与TFHE加密方案结合使用。该方法解决了现有FHE超_cipher转换方案中存在的未认证和可篡改问题，通过防止用户下载未认证或恶意数据来提供安全保护。文中还展示了Proteus在实际隐私保护应用中的效果，包括URL钓鱼检测、私人内容仇恨言论审查以及生物特征认证等。 <div>
Fully Homomorphic Encryption (FHE) is a powerful technology that allows a cloud server to perform computations directly on ciphertexts. To overcome the overhead of sending and storing large FHE ciphertexts, the concept of FHE transciphering was introduced, allowing symmetric key encrypted ciphertexts to be transformed into FHE ciphertexts by deploying symmetric key decryption homomorphically. However, existing FHE transciphering schemes remain unauthenticated and malleable, allowing attackers to manipulate data and remain undetected. This work introduces Proteus, a new methodology for authenticated transciphering, which enables oblivious access control, preventing users from downloading unauthenticated or malicious data. Our protocol implementation adopts ASCON, NIST's new standard for lightweight cryptography, to enable homomorphic hashing and authenticated transciphering. Our ASCON transcipher is paired with the TFHE encryption scheme, which is well suited to perform encrypted rotation and bitwise operations. We evaluate our approach with a variety of real-life privacy-preserving applications, including URL phishing detection, private content moderation of hate speech, and biometric authentication.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 16:15:36 +0000</pubDate>
</item>
<item>
<title>DMM: Distributed Matrix Mechanism for Differentially-Private Federated Learning using Packed Secret Sharing</title>
<link>https://eprint.iacr.org/2024/1665</link>
<guid>https://eprint.iacr.org/2024/1665</guid>
<content:encoded><![CDATA[
<div> 关键词：联邦学习, 差分隐私, 矩阵机制, 分布式机制, 密集秘密共享<br /><br />总结:<br />本文介绍了联邦学习（FL）中差分隐私（DP）的应用，特别是在隐私保护和模型效用之间的权衡问题。主要探讨了中心化DP和本地化DP两种形式。尽管在中心化DP设置下已经通过矩阵机制取得了显著进展，但在本地化DP环境下进展有限。文章提出了一种新的分布式矩阵机制来实现本地化DP的同时改善隐私-效用权衡。该机制采用一种加密协议，利用密集秘密共享技术安全地传输敏感信息，支持用户在训练轮次中的动态参与。实验表明，新机制显著提升了FL模型的隐私-效用权衡，同时几乎不增加额外开销。 <div>
Federated Learning (FL) has gained lots of traction recently, both in industry and academia. In FL, a machine learning model is trained using data from various end-users arranged in committees across several rounds. Since such data can often be sensitive, a primary challenge in FL is providing privacy while still retaining utility of the model. Differential Privacy (DP) has become the main measure of privacy in the FL setting. DP comes in two flavors: central and local. In the former, a centralized server is trusted to receive the users' raw gradients from a training step, and then perturb their aggregation with some noise before releasing the next version of the model. In the latter (more private) setting, noise is applied on users' local devices, and only the aggregation of users' noisy gradients is revealed even to the server. Great strides have been made in increasing the privacy-utility trade-off in the central DP setting, by utilizing the so-called \emph{matrix mechanism}. However, progress has been mostly stalled in the local DP setting. In this work, we introduce the \emph{distributed} matrix mechanism to achieve the best-of-both-worlds; local DP and also better privacy-utility trade-off from the matrix mechanism. We accomplish this by proposing a cryptographic protocol that securely transfers sensitive values across rounds, which makes use of \emph{packed secret sharing. This protocol accommodates the dynamic participation of users per training round required by FL, including those that may drop out from the computation. We provide experiments which show that our mechanism indeed significantly improves the privacy-utility trade-off of FL models compared to previous local DP mechanisms, with little added overhead.
]]></content:encoded>
<pubDate>Tue, 15 Oct 2024 02:19:55 +0000</pubDate>
</item>
<item>
<title>Consensus on SNARK pre-processed circuit polynomials</title>
<link>https://eprint.iacr.org/2024/1664</link>
<guid>https://eprint.iacr.org/2024/1664</guid>
<content:encoded><![CDATA[
<div> 共识协议 区块链 竞争图 交互式提交 验证复杂度<br /><br />总结: 本文提出了一种基于多数规则的共识协议，用于处理可变的电路电线映射（wire maps），这些映射可能因程序输入或论证声明而变化。为了保持简洁性，某些零知识证明（SNARK）协议需要预先准备对电线映射的承诺，但这可能会很昂贵。该协议利用有向无环图（DAG）结构来表示来自不可信方的冲突电线映射。通过交互式的提交-证明-验证方案，该协议实现了高效的边缘验证。分析表明，即使在恶意环境下，该协议也能在几小时到几天内完成共识，同时保证了固定的验证复杂度。此外，引入了一个可调参数N，以在成本和时间与安全性之间取得平衡。 <div>
This paper addresses verifiable consensus of pre-processed circuit polynomials for succinct non-interactive argument of knowledge (SNARK). More specifically, we focus on parts of circuits, referred to as wire maps, which may change based on program inputs or statements being argued. Preparing commitments to wire maps in advance is essential for certain SNARK protocols to maintain their succinctness, but it can be costly. SNARK verifiers can alternatively consider receiving wire maps from an untrusted parties.

We propose a consensus protocol that reaches consensus on wire maps using a majority rule. The protocol can operate on a distributed, irreversible, and transparent server, such as a blockchain. Our analysis shows that while the protocol requires over 50\% honest participants to remain robust against collusive attacks, it enables consensus on wire maps with a low and fixed verification complexity per communication, even in adversarial settings. The protocol guarantees consensus completion within a time frame ranging from a few hours to several days, depending on the wire map degree and the honest participant proportion.

Technically, our protocol leverages a directed acyclic graph (DAG) structure to represent conflicting wire maps among the untrusted deliverers. Wire maps are decomposed into low-degree polynomials, forming vertices and edges of this DAG. The consensus participants, or deliverers, collaboratively manage this DAG by submitting edges to branches they support. The protocol then returns a commitment to the wire map that is written in the first fully grown branch. The protocol's computational efficiency is derived from an interactive commit-prove-verify scheme that enables efficient validation of submitted edges.

Our analysis implies that the practical provides a practical solution for achieving secure consensus on SNARK wire maps in environments with dynamic proportion of honest participants. Additionally, we introduce a tunable parameter $N$ that allows the protocol to minimize cost and time to consensus while maintaining a desired level of security.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 22:09:10 +0000</pubDate>
</item>
<item>
<title>High-Throughput Three-Party DPFs with Applications to ORAM and Digital Currencies</title>
<link>https://eprint.iacr.org/2024/1658</link>
<guid>https://eprint.iacr.org/2024/1658</guid>
<content:encoded><![CDATA[
<div> DPF 三党协议 隐私计算 PIR ORAM CBDC<br /><br />总结: 本文介绍了一种新的三方分布式点函数（DPF）构造，该构造在安全性和效率上与最先进的两方DPF相当。具体而言，它能抵御恶意对手的攻击，并且在函数大小和评估时间上与最佳的两方DPF一致。与现有三方DPF相比，新构造的函数大小和评估时间分别减少了40到120倍。此外，该DPF被应用于私有信息检索（PIR）、隐私写入（PIW）和不经意RAM（ORAM），并设计了一个支持访问策略的ORAM，特别适用于基于账户的数字货币，包括央行数字货币（CBDC）。文章还提出了一种称为可更新DPF的新原语，用于直接计算DPF与向量之间的点积，这在其他应用中也具有潜在价值。 <div>
Distributed point functions (DPF) are increasingly becoming a foundational tool with applications for application-specific and general secure computation.
While two-party DPF constructions are readily available for those applications with satisfiable performance, the three-party ones are left behind in both security and efficiency.
In this paper we close this gap and propose the first three-party DPF construction that matches the state-of-the-art two-party DPF on all metrics.
Namely, it is secure against a malicious adversary corrupting both the dealer and one out of the three evaluators, its function's shares are of the same size and evaluation takes the same time as in the best two-party DPF.
Compared to the state-of-the-art three-party DPF, our construction enjoys $40-120\times$ smaller function's share size and shorter evaluation time, for function domains of $2^{16}-2^{40}$, respectively.

Apart from DPFs as a stand-alone tool, our construction finds immediate applications to private information retrieval (PIR), writing (PIW) and oblivious RAM (ORAM).
To further showcase its applicability, we design and implement an ORAM with access policy, an extension to ORAMs where a policy is being checked before accessing the underlying database.
The policy we plug-in is the one suitable for account-based digital currencies, and in particular to central bank digital currencies (CBDCs).
Our protocol offers the first design and implementation of a large scale privacy-preserving account-based digital currency. While previous works supported anonymity sets of 64-256 clients and less than 10 transactions per second (tps), our protocol supports anonymity sets in the millions, performing $\{500,200,58\}$ tps for anonymity sets of $\{2^{16},2^{18},2^{20}\}$, respectively.

Toward that application, we introduce a new primitive called updatable DPF, which enables a direct computation of a dot product between a DPF and a vector; we believe that updatable DPF and the new dot-product protocol will find interest in other applications.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 14:55:34 +0000</pubDate>
</item>
<item>
<title>Securely Computing One-Sided Matching Markets</title>
<link>https://eprint.iacr.org/2024/1657</link>
<guid>https://eprint.iacr.org/2024/1657</guid>
<content:encoded><![CDATA[
<div> 关键词: Top Trading Cycles, 隐私保护, 功能图, 同态加密, 循环节点

<br /><br />总结:<br />
本文介绍了一种隐私保护的Top Trading Cycles (TTC)算法，用于在一组代理之间交易不可分割的商品。这是首次以这种方式实现TTC算法。作为技术贡献的一部分，本文提出了一种新的算法来确定功能图中所有位于循环中的节点。该算法特别适合安全实现，因为它不需要分支和随机内存访问。最后，本文报告了一个基于同态加密的协议原型实现。 <div>
Top trading cycles (TTC) is a famous algorithm for trading indivisible goods between a set of agents such that all agents are as happy as possible about the outcome. In this paper, we present a protocol for executing TTC in a privacy preserving way. To the best of our knowledge, it is the first of its kind. As a technical contribution of independent interest, we suggest a new algorithm for determining all nodes in a functional graph that are on a cycle. The algorithm is particularly well suited for secure implementation in that it requires no branching and no random memory access. Finally, we report on a prototype implementation of the protocol based on somewhat homomorphic encryption.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 13:58:49 +0000</pubDate>
</item>
<item>
<title>Secure Stateful Aggregation: A Practical Protocol with Applications in Differentially-Private Federated Learning</title>
<link>https://eprint.iacr.org/2024/1655</link>
<guid>https://eprint.iacr.org/2024/1655</guid>
<content:encoded><![CDATA[
<div> 差分隐私 联邦学习 联邦MPC 状态聚合 安全聚合<br /><br />总结:<br />本文介绍了一种名为安全状态聚合的方法，用于实现基于差分隐私联邦梯度下降（DP-FTRL）的完全私有、单个不可信服务器的联邦学习协议。这种方法允许在不信任的中央服务器上安全地存储和处理聚合值，同时保持隐私性。该技术基于环学习难题，并适用于高维数据。通过引入联邦MPC模型，使得强大的持久化服务器可以与弱且短暂的客户端进行交互。这种方法不仅提高了DPFL的效用保证，而且相比现有技术具有较低的开销，同时保持了隐私保护。<br /> <div>
Recent advances in differentially private federated learning (DPFL) algorithms have found that using correlated noise across the rounds of federated learning (DP-FTRL) yields provably and empirically better accuracy than using independent noise (DP-SGD). While DP-SGD is well-suited to federated learning with a single untrusted central server using lightweight secure aggregation protocols, secure aggregation is not conducive to implementing modern DP-FTRL techniques without assuming a trusted central server. DP-FTRL based approaches have already seen widespread deployment in industry, albeit with a trusted central curator who provides and applies the correlated noise.

To realize a fully private, single untrusted server DP-FTRL federated learning protocol, we introduce secure stateful aggregation: a simple append-only data structure that allows for the private storage of aggregate values and reading linear functions of the aggregates. Assuming Ring Learning with Errors, we provide a lightweight and scalable realization of this protocol for high-dimensional data in a new security/resource model, Federated MPC: where a powerful persistent server interacts with weak, ephemeral clients. We observe that secure stateful aggregation suffices for realizing DP-FTRL-based private federated learning: improving DPFL utility guarantees over the state of the art while maintaining privacy with an untrusted central party. Our approach has minimal overhead relative to existing techniques which do not yield comparable utility. The secure stateful aggregation primitive and the federated MPC paradigm may be of interest for other practical applications.
]]></content:encoded>
<pubDate>Mon, 14 Oct 2024 11:52:43 +0000</pubDate>
</item>
<item>
<title>Logstar: Efficient Linear* Time Secure Merge</title>
<link>https://eprint.iacr.org/2024/159</link>
<guid>https://eprint.iacr.org/2024/159</guid>
<content:encoded><![CDATA[
<div> Logstar Median SquareRootMerge CubeRootMerge 实效优化<br /><br />总结: 本文介绍了两种高效的隐私保护合并算法：Logstar和Median。Logstar通过减少通信带宽实现了接近线性的运行时间，而Median则通过减少轮次优化了时间复杂度。此外，文章还提出了两种处理不同列表大小的合并算法，即SquareRootMerge和CubeRootMerge，它们分别能在O(n)时间内完成合并操作。这些算法不仅提高了理论效率，还在实际应用中展示了更好的性能，比如Logstar减少了约2倍的带宽成本，Median减少了约1.5倍的轮次。这些成果对于需要高效、安全地合并数据的应用场景具有重要意义。 <div>
Secure merge considers the problem of combining two sorted lists into a single sorted secret-shared list. Merge is a fundamental building block for many real-world applications. For example, secure merge can implement a large number of SQL-like database joins, which are essential for almost any data processing task such as privacy-preserving fraud detection, ad conversion rates, data deduplication, and many more.

We present two constructions with communication bandwidth and rounds tradeoff. Logstar, our bandwidth-optimized construction, takes inspiration from Falk and Ostrovsky (ITC, 2021) and runs in  $O(n\log^*n)$ time and communication with $O(\log n)$ rounds. In particular, for all conceivable $n$, the $\log^*n$ factor will be equal to the constant $2$, and therefore we achieve a near-linear running time. Median, our rounds-optimized construction, builds on the classic parallel medians-based insecure merge approach of Valiant (SIAM J. Comput., 1975), later explored in the secure setting by Blunk et al. (2022), and requires $O(n \log^c n)$, $c \approx 1.71$, communication with $O(\log \log n)$ rounds. 

We introduce two additional constructions that merge input lists of different sizes. SquareRootMerge merges lists of sizes $n^{\frac{1}{2}}$ and $n$ and runs in $O(n)$ time and communication with $O(\log n)$ rounds. CubeRootMerge is closely inspired by Blunk et al.'s (2022) construction and merges lists of sizes $n^{\frac{1}{3}}$ and $n$. It runs in $O(n)$ time and communication with $O(1)$ rounds.

We optimize our constructions for concrete efficiency. Today, concretely efficient secure merge protocols rely on standard techniques such as Batcher's merging network or generic sorting. These approaches require an $O(n \log n)$ size circuit of $O(\log n)$ depth. Despite significant research thrust, no work has been able to reduce their concrete costs. Our constructions are the first to be more efficient by improving their asymptotics and maintaining small constants. We analytically benchmark against these constructions and show that Logstar reduces bandwidth costs $\approx2.0\times$ and Median reduces rounds $\approx1.5\times$.
]]></content:encoded>
<pubDate>Sat, 03 Feb 2024 01:07:24 +0000</pubDate>
</item>
<item>
<title>Large-Scale MPC: Scaling Private Iris Code Uniqueness Checks to Millions of Users</title>
<link>https://eprint.iacr.org/2024/705</link>
<guid>https://eprint.iacr.org/2024/705</guid>
<content:encoded><![CDATA[
<div> 隐私保护 生物特征验证 神经网络通信库 高性能计算 安全多方计算<br /><br />总结: 本文介绍了一种用于生物特征验证系统中的隐私保护方案，通过安全多方计算（MPC）技术保护查询和数据库中的虹膜代码。该方案显著提升了性能，比现有最先进的系统Janus快三个数量级，单核CPU下每秒可处理超过69万次虹膜代码比较。此外，利用Nvidia NCCL实现GPU版本的协议，直接让GPU访问网络接口，从而避免了数据传输成本，使得在三方MPC设置中，每秒可以进行42.9亿次虹膜代码比较。此GPU实现满足了Worldcoin基金会的性能需求，将应用于其部署的World ID基础设施中。 <div>
In this work we tackle privacy concerns in biometric verification systems that typically require server-side processing of sensitive data (e.g., fingerprints and Iris Codes). Concretely, we design a solution that allows us to query whether a given Iris Code is similar to one contained in a given database, while all queries and datasets are being protected using secure multiparty computation (MPC). Addressing the substantial performance demands of operational systems like World ID and aid distributions by the Red Cross, we propose new protocols to improve performance by more than three orders of magnitude compared to the recent state-of-the-art system Janus (S&amp;P 24). Our final protocol can achieve a throughput of over 690 thousand Iris Code comparisons per second on a single CPU core, while protecting the privacy of both the query and database Iris Codes. Furthermore, using Nvidia NCCL we implement the whole protocol on GPUs while letting GPUs directly access the network interface. Thus we are able to avoid the costly data transfer between GPUs and CPUs, allowing us to achieve a throughput of 4.29 billion Iris Code comparisons per second in a 3-party MPC setting, where each party has access to 8 H100 GPUs. This GPU implementation achieves the performance requirements set by the Worldcoin foundation and will thus be used in their deployed World ID infrastructure.
]]></content:encoded>
<pubDate>Tue, 07 May 2024 16:38:57 +0000</pubDate>
</item>
<item>
<title>Computationally Secure Aggregation and Private Information Retrieval in the Shuffle Model</title>
<link>https://eprint.iacr.org/2024/870</link>
<guid>https://eprint.iacr.org/2024/870</guid>
<content:encoded><![CDATA[
<div> shuffle模型 信息论安全 计算安全 聚合协议 PIR<br /><br />总结: 本文研究了计算安全下的聚合协议和私有信息检索（PIR）在shuffle模型中的应用。文章指出，通过改进先前的加法共享洗牌技术，并基于标准学习 parity with noise (LPN) 假设或新的多不相交综合症解码 (MDSD) 猜想，可以提高效率。对于长向量的安全聚合，本文提出的协议相比以前的信息论安全解决方案减少了9到25倍的通信需求。此外，本文的PIR协议在单一服务器上存储数据库的同时，保持了多服务器PIR的简单性和具体效率优势，并且在MDSD假设下，相比最近的单服务器PIR构造，性能提升了两个数量级。 <div>
The shuffle model has recently emerged as a popular setting for differential privacy, where clients can communicate with a central server using anonymous channels or an intermediate message shuffler. This model was also explored in the context of cryptographic tasks such as secure aggregation and private information retrieval (PIR). However, this study was almost entirely restricted to the stringent notion of information-theoretic security. 

In this work, we study computationally secure aggregation protocols and PIR in the shuffle model. Our starting point is the insight that the previous technique of shuffling additive shares can be improved in the computational setting. We show that this indeed holds under the standard learning parity with noise (LPN) assumption, but even better efficiency follows from plausible conjectures about the multi-disjoint syndrome decoding (MDSD) problem that we introduce and study in this work.

We leverage the above towards improving the efficiency of secure aggregation and PIR in the shuffle model. For secure aggregation of long vectors, our protocols require $9\times$-$25\times$ less communication than the previous information-theoretic solutions. Our PIR protocols enjoy the simplicity and concrete efficiency benefits of multi-server PIR while only requiring a single server to store the database. Under the MDSD assumption, they improve over recent single-server PIR constructions by up to two orders of magnitude.
]]></content:encoded>
<pubDate>Sat, 01 Jun 2024 07:24:09 +0000</pubDate>
</item>
<item>
<title>Oblivious Turing Machine</title>
<link>https://eprint.iacr.org/2023/1643</link>
<guid>https://eprint.iacr.org/2023/1643</guid>
<content:encoded><![CDATA[
<div> 关键词: 分布式计算, 同态加密, 图灵机模型, 隐私保护, 非交互式<br /><br />总结:<br />本文探讨了在分布式计算环境中，数据和程序隐私保护的重要性。文章指出，现有的方案主要关注数据保密性，而忽略了通过服务器执行函数可能泄露的信息。为了解决这个问题，文章提出了一种结合全同态加密与图灵机模型的新方法，开发了首个完全安全、非交互式的全同态图灵机。该方法基于环学习带误差问题的难度、非线性函数的同态评估能力和数据结构元素的盲旋转能力三个假设。文章还介绍了基于TFHE密码系统的实现，并展示了实施结果。 <div>
In the ever-evolving landscape of Information Tech- nologies, private decentralized computing on an honest yet curious server has emerged as a prominent paradigm. While numerous schemes exist to safeguard data during computation, the focus has primarily been on protecting the confidentiality of the data itself, often overlooking the potential information leakage arising from the function evaluated by the server. Recognizing this gap, this article aims to address the issue by presenting and implementing an innovative solution for ensuring the privacy of both the data and the program. We introduce a novel approach that combines the power of Fully Homomorphic Encryption with the concept of the Turing Machine model, resulting in the first fully secure practical, non-interactive oblivious Turing Machine. Our Oblivious Turing Machine construction is based on only three hypotheses, the hardness of the Ring Learning With Error problem, the ability to homomorphically evaluate non-linear functions and the capacity to blindly rotate elements of a data structure. Only based on those three assumptions, we propose an implementation of an Oblivious Turing Machine relying on the TFHE cryptosystem and present some implementation results.
]]></content:encoded>
<pubDate>Mon, 23 Oct 2023 20:21:51 +0000</pubDate>
</item>
<item>
<title>Secure Transformer Inference</title>
<link>https://eprint.iacr.org/2023/1763</link>
<guid>https://eprint.iacr.org/2023/1763</guid>
<content:encoded><![CDATA[
<div> 安全 模型参数 用户数据 效率瓶颈 半对称置换<br /><br />总结: 本文针对Transformer模型服务中的安全问题，特别是模型参数和用户数据的安全性进行了探讨。作者基于实际开发经验，指出传统的两方威胁模型存在效率瓶颈，并提出了一种新的三方威胁模型，包括模型开发者、模型服务器和数据所有者。在此基础上，设计了一种半对称置换保护方案STIP，实现了无推断准确度损失的高效安全推断协议。文章还分析了STIP对暴力破解、已知明文和社交工程攻击的抵抗能力，并通过实验验证了其在大规模模型上的安全性和准确性。此外，还提出了一种方法将可信执行环境与STIP结合，增强模型参数对模型提取和微调攻击的抵抗力。实验结果表明，STIP在保持高安全性的同时，大幅降低了推断延迟。 <div>
Security of model parameters and user data is critical for Transformer-based services, such as ChatGPT.
While recent strides in secure two-party protocols have successfully addressed security concerns in serving Transformer models, their adoption is practically infeasible due to the prohibitive cryptographic overheads involved.
Drawing insights from our hands-on experience in developing two real-world Transformer-based services, we identify the inherent efficiency bottleneck in the two-party assumption. 
To overcome this limitation, we propose a novel three-party threat model that consists of model developer, model server, and data owner. 
Based on this framework, we design a semi-symmetric permutation-based protection scheme and present STIP, the first secure Transformer inference protocol without any inference accuracy loss.
We analyze STIP's resistance to brute force, known-plaintext, and social engineering attacks and prove the privacy leakage upper bound using distance correlation.
And we propose a method to integrate the trusted execution environment with STIP to make model parameters resistant to model extraction and fine-tuning attacks.
Experiments on six representative series of Transformer models, with up to 70 billion parameters, in real systems show that STIP has strong security and no loss of accuracy.
For auto-regressive token generation, STIP achieves 31.7 ms latency for LLaMA2-7b model, significantly reducing the 5-minute overhead of the state-of-the-art two-party protocols.
]]></content:encoded>
<pubDate>Wed, 15 Nov 2023 02:55:09 +0000</pubDate>
</item>
<item>
<title>Ripple: Accelerating Programmable Bootstraps for FHE with Wavelet Approximations</title>
<link>https://eprint.iacr.org/2024/866</link>
<guid>https://eprint.iacr.org/2024/866</guid>
<content:encoded><![CDATA[
<div> 关键词：同态加密 查找表 离散小波变换 精度 误差减少

<br /><br />总结:<br />
文章介绍了一种名为Ripple的新框架，该框架旨在解决同态加密中查找表精度与成本之间的矛盾。通过采用离散小波变换（DWT）方法来减少查找表中的条目数量，同时保持高精度。研究表明，与传统的量化方法相比，Ripple在多个非线性函数上实现了显著的误差减少。此外，Ripple还提高了如逻辑回归和互相关等实际基准测试的运行时间性能。 <div>
Homomorphic encryption can address key privacy challenges in cloud-based outsourcing by enabling potentially untrusted servers to perform meaningful computation directly on encrypted data. While most homomorphic encryption schemes offer addition and multiplication over ciphertexts natively, any non-linear functions must be implemented as costly polynomial approximations due to this restricted computational model. Nevertheless, the CGGI cryptosystem is capable of performing arbitrary univariate functions over ciphertexts in the form of lookup tables through the use of programmable bootstrapping. While promising, this procedure can quickly become costly when high degrees of precision are required. To address this challenge, we propose Ripple: a framework that introduces different approximation methodologies based on discrete wavelet transforms (DWT) to decrease the number of entries in homomorphic lookup tables while maintaining high accuracy. Our empirical evaluations demonstrate significant error reduction compared to plain quantization methods across multiple non-linear functions. Notably, Ripple improves runtime performance for several realistic benchmarks, such as logistic regression and cross-correlation, among others.
]]></content:encoded>
<pubDate>Fri, 31 May 2024 20:57:39 +0000</pubDate>
</item>
<item>
<title>TokenWeaver: Privacy Preserving and Post-Compromise Secure Attestation</title>
<link>https://eprint.iacr.org/2022/1691</link>
<guid>https://eprint.iacr.org/2022/1691</guid>
<content:encoded><![CDATA[
<div> TokenWeaver 可证明性 隐私保护 后妥协安全 链式令牌 互不连接<br /><br />总结: 本文介绍了一种名为TokenWeaver的方法，这是一种基于可信执行环境（TEE）的隐私保护后妥协安全证明方法。通过结合可链接和不可链接两种类型的令牌链，TokenWeaver旨在即使在TEE被攻击后也能恢复其安全性，同时保证用户隐私不被追踪。该方法提供了Tamarin和DeepSec验证器的完整形式化模型及协议、安全属性和证明，以确保其核心特性的正确性。此外，还提供了一个Python的概念验证实现，展示了解决方案的简洁性和适用性。这一研究有助于解决现代认证系统中的隐私保护与安全性之间的矛盾。 <div>
Modern attestation based on Trusted Execution Environments (TEEs) can significantly reduce the risk of secret compromise,  allowing users to securely perform sensitive computations such as running cryptographic protocols for authentication across security critical services. However, this has also made TEEs a high-value attack target, driving an arms race between novel compromise attacks and continuous TEEs updates. 

Ideally, we want to achieve Post-Compromise Security (PCS): even after a TEE compromise, we can update it back into a secure state. However, at the same time, we would like to guarantee the privacy of users, in particular preventing providers (such as Intel, Google, or Samsung) or services from tracking users across services. This requires unlinkability, which seems incompatible with standard PCS healing mechanisms.

In this work, we develop TokenWeaver, the first privacy-preserving post-compromise secure attestation method with automated formal proofs for its core properties. We base our construction on weaving together two types of token chains, one of which is linkable and the other is unlinkable. We provide the full formal models based on the Tamarin and DeepSec provers, including protocol, security properties, and proofs for reproducibility, as well as a proof-of-concept implementation in python that shows the simplicity and applicability of our solution.
]]></content:encoded>
<pubDate>Tue, 06 Dec 2022 15:45:37 +0000</pubDate>
</item>
<item>
<title>Curve Forests: Transparent Zero-Knowledge Set Membership with Batching and  Strong Security</title>
<link>https://eprint.iacr.org/2024/1647</link>
<guid>https://eprint.iacr.org/2024/1647</guid>
<content:encoded><![CDATA[
<div> 关键词: 零知识证明、集合成员性、透明性、曲线树、批量验证

总结:

本文提出了一种新的高效构造方法，用于解决批量验证的零知识集合成员性问题。该构造方法具有透明性，无需信任设置，基于Campanelli、Hall-Andersen和Kamp在USENIX 2023年会议上提出的曲线树。主要技术贡献包括在批量设置中通过利用曲线树的代数特性来实现曲线树成本的摊销，这使得证明速度提升约2倍，验证速度提升约3倍，证明大小减少约60%。此外，文章还对曲线树的关键技术要求进行了修改，简化了其设计并获得了更强的安全属性，特别是当集合的承诺由攻击者提供时，仍能保持安全，而原始的曲线树则要求诚实的承诺。

这种新的构造方法为隐私保护应用提供了更高效的解决方案，如匿名支付、凭证和白名单，通过减少信息泄露，增强了数据安全性与隐私保护。 <div>
Zero-knowledge for set membership is a building block at the core of several privacy-aware applications, such as anonymous payments, credentials and whitelists.
We propose a new efficient construction for the batching variant of the problem, where a user intends to show knowledge of several elements (a batch) in a  set without any leakage on the elements. Our construction is transparent—it does not requires a trusted setup—and based on Curve Trees by Campanelli, Hall-Andersen and Kamp (USENIX 2023). Our first technical contribution consists in techniques to amortize Curve Trees costs in the batching setting for which we crucially exploit its algebraic properties. Even for small batches we obtain $\approx 2\times$ speedups for proving, $\approx3\times$ speedups for verification and $\approx 60\%$ reduction in proof size. Our second contribution is a modifications of a key technical requirement in Curve Trees (related to so called "permissible points") which arguably simplifies its design and obtains a stronger security property. In particular, our construction is secure even for the case where the  commitment  to the set is provided by the adversary (in contrast to the honest one required by the original Curve Trees).
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 17:11:18 +0000</pubDate>
</item>
<item>
<title>Fiat-Shamir Goes Rational</title>
<link>https://eprint.iacr.org/2024/1645</link>
<guid>https://eprint.iacr.org/2024/1645</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式、理性证明、Fiat-Shamir变换、智能合约、安全保证

总结:
本文探讨了构建非交互式理性证明的开放性问题。理性证明是由Azar和Micali在2012年提出的模型，其中计算能力强大的服务器可以通过运行昂贵的计算$f(x)$来获得弱客户端的奖励。当服务器理性行事时，任何声称错误输出$y \neq f(x)$的对手将预期损失金钱。当前所有非平凡的理性证明构造都是交互式的。开发非交互式理性协议将是一个游戏规则改变者，使其在智能合约等自然应用中变得可行。

文章的主要发现包括：
1. 提出并解决了标准Fiat-Shamir变换不适用于验证器仅对输入$x$有随机探针访问的问题。
2. 提出了两种版本的Fiat-Shamir变换：一种是基本版，另一种是增强版（验证器可以访问其输入的真实计算摘要）。这两种版本都无法确保AM13或CG15在非交互式设置下保持安全性。
3. 提供了一个关于理性证明（无论是交互式还是非交互式）的原始兴趣的新颖且可能更简单的完好数学定义。

通过这些研究，文章为理解Fiat-Shamir变换在理性证明中的适用性和构建非交互式理性证明提供了关键洞察，并指出了未来工作的可能性。 <div>
This paper investigates the open problem of how to construct non-interactive rational proofs. Rational proofs, introduced by Azar and Micali (STOC 2012), are a model of interactive proofs where a computationally powerful server can be rewarded by a weaker client for running an expensive computation $f(x)$. The honest strategy is enforced by design when the server is rational: any adversary claiming a false output $y \neq f(x)$ will lose money on expectation.
Rational proof constructions have appealing properties: they are simple, feature an extremely efficient verifier—reading only a sublinear number of bits of the input $x$—and do not require any collateral from the prover. Currently, all non-trivial constructions of rational proofs are interactive. Developing non-interactive rational protocols would be a game-changer, making them practical for use in smart contracts, one of their most natural applications.
Our investigation revolves around the Fiat-Shamir transform, a common approach to compiling interactive proofs into their non-interactive counterparts. We are the first to tackle the question: "Can Fiat-Shamir be successfully applied to rational protocols?"
We find negative evidence by showing that, after applying Fiat-Shamir in the random oracle model to two representative protocols in literature (AM13 and CG15) these lose their security guarantees. Our findings point to more general impossibility theorems, which we leave as future work.
To achieve our results we first need to address a fundamental technical challenge:  the standard Fiat-Shamir transform does not apply to protocols where the verifier has only oracle access to its input $x$ (a core feature of the rational setting). We propose two versions of Fiat-Shamir for this setting, a "vanilla" variant and a "stronger" variant (where the verifier has access to an honestly computed digest of its input). We show that neither variant is sufficient to ensure that AM13 or CG15 are secure in the non-interactive setting.
Finally, as an additional contribution, we provide a novel, and arguably simpler, definition for the soundness property of rational proofs (interactive or non-interactive) of independent interest.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 13:30:06 +0000</pubDate>
</item>
<item>
<title>Transaction Execution Mechanisms</title>
<link>https://eprint.iacr.org/2024/1646</link>
<guid>https://eprint.iacr.org/2024/1646</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、交易执行机制、资源分配、多队列系统、全局共识

总结:本文探讨了区块链中的交易执行机制(TEM)，着重于如何在多个并行执行队列或“本地费用市场”之间高效分配资源。研究构建了一个模型，考虑了容量限制、用户评估和延迟成本，在具有全球共识的聚合容量约束的多队列系统中。文章指出，收益最大化倾向于将容量分配给支付最高的队列，而福利最大化通常服务于所有队列。不同队列的相对定价取决于市场大小、需求弹性以及局部和全局拥堵之间的平衡。这些发现对正在演变的区块链架构具有重要影响，包括并行执行、DAG基系统和多个并发提议者，并能帮助设计更高效的TEM。通过理解这些机制，开发者可以优化网络性能，提高用户体验，并确保系统的公平性和稳定性。 <div>
This paper studies transaction execution mechanisms (TEMs) for blockchains, as the efficient resource allocation across multiple parallel executions queues or "local fee markets." We present a model considering capacity constraints, user valuations, and delay costs in a multi-queue system with an aggregate capacity constraint due to global consensus. We show that revenue maximization tends to allocate capacity to the highest-paying queue, while welfare maximization generally serves all queues. Optimal relative pricing of different queues depends on factors such as market size, demand elasticity, and the balance between local and global congestion.  Our results have implications for evolving blockchain architectures, including parallel execution, DAG-based systems, and multiple concurrent proposers, and can help design more efficient TEMs.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 15:16:32 +0000</pubDate>
</item>
<item>
<title>Optimizing Liveness for Blockchain-Based Sealed-Bid Auctions in Rational Settings</title>
<link>https://eprint.iacr.org/2024/1643</link>
<guid>https://eprint.iacr.org/2024/1643</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、拍卖市场、公平性、透明度、分布式匿名出价

总结:

本文研究了基于区块链的拍卖市场，与传统中心化拍卖相比，其在公平性和透明度上具有显著优势。文章主要贡献在于提出了一种去中心化的匿名存入出价（DADB）方案，为该机制提供了正式的语法和安全性定义。不同于依赖智能合约的传统方法，该方案采用了主链-侧链架构，兼容扩展的UTXO模型。这种设计使得能够构建一个专门用于安全记录投标并进行分配的共识机制在侧链上。

文章通过游戏理论视角证明，即使没有明确的激励（如费用）来包括投标，我们的设计也能优化理性参与者加入拍卖的存活延迟时间。最后，实施结果表明，缺乏块资格机制可能导致性能下降。

综上所述，本文通过提出DADB方案，不仅增强了区块链拍卖市场的公平性和透明度，还通过理论分析和实证研究验证了其在提高效率方面的潜力，为区块链技术在拍卖领域的应用提供了新的思路和方法。 <div>
Blockchain-based auction markets offer stronger fairness and transparency compared to their centralized counterparts. Deposits and sealed bid formats are usually applied to enhance security and privacy. However, to our best knowledge, the formal treatment of deposit-enabled sealed-bid auctions remains lacking in the cryptographic literature. To address this gap, we first propose a decentralized anonymous deposited-bidding (DADB) scheme, providing formal syntax and security definitions. Unlike existing approaches that rely on smart contracts, our construction utilizes a mainchain-sidechain structure that is also compatible with the extended UTXO model. This design further allows us to develop a consensus mechanism on the sidechain dedicated to securely recording bids for allocation. Specifically, we build atop an Algorand-style protocol and integrate a novel block qualification mechanism into the block selection. Consequently, we prove, from a game-theoretical perspective, that our design optimizes liveness latency for rational users who want to join the auction, even without explicit incentives (e.g., fees) for including bids. Finally, our implementation results demonstrate the potential performance degradation without the block qualification mechanism.
]]></content:encoded>
<pubDate>Sat, 12 Oct 2024 04:24:11 +0000</pubDate>
</item>
<item>
<title>Fully Secure Searchable Encryption from PRFs, Pairings, and Lattices</title>
<link>https://eprint.iacr.org/2024/1632</link>
<guid>https://eprint.iacr.org/2024/1632</guid>
<content:encoded><![CDATA[
<div> 关键词：搜索加密、全安全、查询限制、普适、假随机函数

本文主要探讨了搜索加密领域中的全安全性概念及其实现。全安全包括了密文隐私和陷阱门隐私两个方面，确保在进行搜索操作时，既不泄露密文内容也不泄露陷阱门信息。文章首先指出，由于理论限制，目前仅能构建查询限制的全安全方案，而实现普适的全安全方案较为困难。

接着，作者提出了一种基于伪随机函数的查询限制全安全方案，并进一步设计了两种基于双线性对和格的高效（无限制）全安全方案。这些方案在保证全安全性的前提下，提高了搜索效率和实用性。

同时，文章还对已有的全安全方案进行了深入分析。通过简化前人的工作并提供正式证明，澄清了某方案关于安全性的错误宣传。这不仅增强了对现有方案的理解，也为后续研究提供了宝贵的反馈。

总结: 本文通过构建新的全安全搜索加密方案，以及对现有方案的深入分析与优化，推动了搜索加密领域的理论与实践发展。其中，基于伪随机函数的方案为查询限制场景提供了安全保证；基于双线性和格的方案则在保持全安全性的同时，提升了方案的适用性和效率；此外，通过修正前人关于安全性的错误表述，为学术界提供了更为准确的安全性评估标准。这些贡献共同推进了搜索加密技术在隐私保护与数据检索领域的应用。 <div>
Searchable encryption is a cryptographic primitive that allows us to perform searches on encrypted data. Searchable encryption schemes require that ciphertexts do not leak information about keywords. However, most of the existing schemes do not achieve the security notion that trapdoors do not leak information. Shen et al. (TCC 2009) proposed a security notion called full security, which includes both ciphertext privacy and trapdoor privacy, but there are few fully secure constructions. Full security is defined for the secret key settings since it is known that public key schemes cannot achieve the trapdoor privacy in principle.
In this paper, we construct a query-bounded fully secure scheme from pseudorandom functions. In addition, we propose two types of efficient (unbounded) fully secure schemes, each of which is based on bilinear groups and lattices respectively. We then analyze the existing constructions. First, we simplify the Cheng et al. scheme (Information Sciences 2023) and prove its security. This scheme had not been proved to be secure. Second, we show that the Li-Boyen pairing-based scheme (IACR CiC 2024) does not achieve the trapdoor privacy, not as claimed.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 12:31:16 +0000</pubDate>
</item>
<item>
<title>Efficient Key-Switching for Word-Type FHE and GPU Acceleration</title>
<link>https://eprint.iacr.org/2024/1629</link>
<guid>https://eprint.iacr.org/2024/1629</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算、全同态加密（FHE）、量子安全性、线性复杂度、GPU优化

总结:
本文研究了云计算环境下提高全同态加密（FHE）性能和安全性的方法。全同态加密允许在数据加密状态下进行计算，同时保护数据隐私。特别地，基于格的全同态加密具有量子安全性，可抵御量子计算机攻击。然而，当前FHE方案的性能不佳，主要由于数据长度和多个资源密集型操作的高成本。

研究中引入了一种新算法，该算法通过实现Number Theoretic Transform（NTT）的线性复杂度，有效解决了关键切换过程中的复杂计算问题。该算法不仅在效率上与现有最佳方法相当，而且在复杂性和GPU内存使用上显著简化，节省高达95%的空间，特别适合GPU环境。

通过优化GPU性能，此算法实现了相比基线方法和当前最佳方法高达2.0倍的加速效果。这种平衡了简单性和性能的算法，为现代硬件平台上的加密计算提供了更实际和高效的实现方式，从而推动了全同态加密在云计算环境中的广泛应用。 <div>
Speed efficiency, memory optimization, and quantum resistance are essential for safeguarding the performance and security of cloud computing environments. Fully Homomorphic Encryption (FHE) addresses this need by enabling computations on encrypted data without requiring decryption, thereby maintaining data privacy. Additionally, lattice-based FHE is quantum secure, providing defense against potential quantum computer attacks. However, the performance of current FHE schemes remains unsatisfactory, largely because of the length of the operands and the computational expense associated with several resource-intensive operations. Among these operations, key-switching is one of the most demanding processes because it involves complex arithmetic operations necessary to conduct computations in a larger cyclotomic ring.

In this research, we introduce a novel algorithm that achieves linear complexity in the Number Theoretic Transform (NTT) for key-switching. This algorithm offers efficiency comparable to the state-of-the-art while being significantly simpler and consumes less GPU memory. Notably, it reduces space consumption by up to 95\%, making it highly friendly for GPU memory. By optimizing GPU performance, our implementation achieves up to a 2.0$\times$ speedup compared to both the baseline approach and the current state-of-the-art methods. This algorithm effectively balances simplicity and performance, thereby enhancing cryptographic computations on modern hardware platforms and paving the way to more practical and efficient FHE implementations in cloud computing environments.
]]></content:encoded>
<pubDate>Fri, 11 Oct 2024 04:59:43 +0000</pubDate>
</item>
<item>
<title>General Functional Bootstrapping using CKKS</title>
<link>https://eprint.iacr.org/2024/1623</link>
<guid>https://eprint.iacr.org/2024/1623</guid>
<content:encoded><![CDATA[
<div> 关键词：Ducas-Micciancio、Chilotti-Gama-Georgieva-Izabachène、Cheon-Kim-Kim-Song、全同态加密、功能重灌注

<br /><br />
总结:本文提出了一种基于Cheon-Kim-Kim-Song(FHE)方案的功能重灌注方法，以解决全同态加密(FHE)系统在执行任意函数表(LUT)计算时效率低下的问题。该方法通过利用三角Hermite插值理论构建了一个理论工具包，实现了对任意函数的评估，并对噪声降低过程进行了控制。实验结果表明，对于8位LUT评估，所提出的方法达到了0.75毫秒的平均时间，比Ducas-Micciancio和Chilotti-Gama-Georgieva-Izabachène的方案快三个数量级，且比基于Brakerski/Fan-Vercauteren(FBV)方案的更受限的功能重灌注方法快6.6倍。这标志着在保持隐私的同时，显著提高了FHE系统的计算效率与实用性。 <div>
The Ducas-Micciancio (DM/FHEW) and Chilotti-Gama-Georgieva-Izabachène (CGGI/TFHE) cryptosystems provide a general privacy-preserving computation capability. These fully homomorphic encryption (FHE) cryptosystems can evaluate an arbitrary function expressed as a general look-up table (LUT) via the method of functional bootstrapping (also known as programmable bootstrapping). The main limitation of DM/CGGI functional bootstrapping is its efficiency because this procedure has to bootstrap every encrypted number separately. A different bootstrapping approach, based on the Cheon-Kim-Kim-Song (CKKS) FHE scheme, can achieve much smaller amortized time due to its ability to bootstrap many thousands of numbers at once. However, CKKS does not currently provide a functional bootstrapping capability that can evaluate a general LUT. An open research question is whether such capability can be efficiently constructed. We give a positive answer to this question by proposing and implementing a general functional bootstrapping method based on CKKS-style bootstrapping. We devise a theoretical toolkit for evaluating an arbitrary function using the theory of trigonometric Hermite interpolations, which provides control over noise reduction during functional bootstrapping. Our experimental results for 8-bit LUT evaluation show that the proposed method achieves the amortized time of 0.75 milliseconds, which is three orders of magnitude faster than the DM/CGGI approach and 6.6x faster than (a more restrictive) amortized functional bootstrapping method based on the Brakerski/Fan-Vercauteren (BFV) FHE scheme.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 19:28:47 +0000</pubDate>
</item>
<item>
<title>Rhombus: Fast Homomorphic Matrix-Vector Multiplication for Secure Two-Party Inference</title>
<link>https://eprint.iacr.org/2024/1611</link>
<guid>https://eprint.iacr.org/2024/1611</guid>
<content:encoded><![CDATA[
<div> 关键词：Rhombus、矩阵-向量乘法、半诚实模型、同态加密、性能优化

文章主要介绍了一种名为“Rhombus”的新型安全矩阵-向量乘法（MVM）协议，适用于半诚实的两方设置。该协议能够无缝集成到现有的隐私保护机器学习（PPML）框架中，并作为线性层安全计算的基础。Rhombus采用了基于RLWE的同态加密（HE）与系数编码相结合的方式，允许消息选择不仅限于域\(\mathbb{F}_p\)，还包括整环\(\mathbb{Z}_{2^\ell}\)，这在非线性层中支持更快的计算。

为了提高效率，作者开发了输入-输出打包技术，减少了使用系数编码的同态加密带来的通信成本，大约降低了21倍。此外，提出了分割点选取技术，将旋转次数减少至矩阵维度的亚线性级别。相较于近期的协议HELiKs，Rhombus在MVM协议整体性能上提升了约7.4至8倍，对于ResNet50安全双方推理的端到端性能提高了约4.6至18倍。

总结: Rhombus协议通过采用创新的同态加密方法和优化技术，显著提高了矩阵-向量乘法操作的效率和性能，特别是对于需要高安全性的隐私保护机器学习应用。通过减少通信成本和优化旋转次数，Rhombus在保持安全性的同时，实现了计算性能的大幅增强，为构建高效、安全的机器学习系统提供了有力支持。 <div>
We present $\textit{Rhombus}$, a new secure matrix-vector multiplication (MVM) protocol in the semi-honest two-party setting, which is able to be seamlessly integrated into existing privacy-preserving machine learning (PPML) frameworks and serve as the basis of secure computation in linear layers. 
$\textit{Rhombus}$ adopts RLWE-based homomorphic encryption (HE) with coefficient encoding, which allows messages to be chosen from not only a field $\mathbb{F}_p$ but also a ring $\mathbb{Z}_{2^\ell}$, where the latter supports faster computation in non-linear layers. To achieve better efficiency, we develop an input-output packing technique that reduces the communication cost incurred by HE with coefficient encoding by about $21\times$, and propose a split-point picking technique that reduces the number of rotations to that sublinear in the matrix dimension. Compared to the recent protocol $\textit{HELiKs}$ by Balla and Koushanfar (CCS'23), our implementation demonstrates that $\textit{Rhombus}$ improves the whole performance of an MVM protocol by a factor of $7.4\times \sim 8\times$, and improves the end-to-end performance of secure two-party inference of ResNet50 by a factor of $4.6\times \sim 18\times$.
]]></content:encoded>
<pubDate>Thu, 10 Oct 2024 02:45:46 +0000</pubDate>
</item>
<item>
<title>Secret Sharing with Snitching</title>
<link>https://eprint.iacr.org/2024/1610</link>
<guid>https://eprint.iacr.org/2024/1610</guid>
<content:encoded><![CDATA[
<div> 关键词：股东共谋、秘密共享、个体加密、秘密出卖、多党计算

总结:

本文探讨了在个体加密模型下检测和惩罚股东共谋的问题，该模型假设存在仅单台机器能有效执行的任务，而将其分散到多个互不信任的设备上则是不可行的。为了应对这一挑战，文章引入了一种新的密码学工具——秘密共享与出卖（SSS），旨在确保任何非法重构共享秘密的行为都能被证明并受到惩罚。

首先，文章定义了阈值（t-out-of-n）秘密共享与出卖（SSS），其中t代表所需的最小份额数量以重构秘密。接下来，通过构建适用于t=n的情况，文章展示了如何构建此类机制。最终，利用这一基础构造，文章进一步设计出适用于任意t值的SSS方案。

为了证明此方案的安全性，文章提出了对随机原象模型的扩展，允许在多党计算过程中模拟哈希函数的评估。这为确保SSS方案的有效性和安全性提供了理论基础。

综上所述，文章通过引入秘密共享与出卖的概念，以及对其安全性的深入分析，提供了一种有效防止股东共谋的技术框架。这一框架不仅针对直接的秘密重构行为，还涵盖了利用多党计算协议进行秘密泄露的行为，从而在理论上为预防和惩罚此类共谋行为提供了坚实的基础。 <div>
We address the problem of detecting and punishing shareholder collusion in secret-sharing schemes. We do it in the recently proposed cryptographic model called individual cryptography (Dziembowski, Faust, and Lizurej, Crypto 2023), which assumes that there exist tasks that can be efficiently computed by a single machine but distributing this computation across multiple (mutually distrustful devices) is infeasible.

Within this model, we introduce a novel primitive called secret sharing with snitching (SSS), in which each attempt to illegally reconstruct the shared secret $S$ results in a proof that can be used to prove such misbehavior (and, e.g., financially penalize the cheater on a blockchain). This holds in a very strong sense, even if the shareholders attempt not to reconstruct the entire secret~$S$ but only learn some partial information about it. Our notion also captures the attacks performed using multiparty computation protocols (MPCs), i.e., those where the malicious shareholders use MPCs to compute partial information on $S$. The main idea of SSS is that any illegal reconstruction can be proven and punished, which suffices to discourage illegal secret reconstruction. Hence, our SSS scheme effectively prevents shareholders' collusion. We provide a basic definition of threshold ($t$-out-of-$n$) SSS. We then show how to construct it for $t = n$, and later, we use this construction to build an SSS scheme for an arbitrary $t$.

In order to prove the security of our construction, we introduce a generalization of the random oracle model (Bellare, Rogaway, CCS 1993), which allows modelling hash evaluations made inside MPC.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 20:10:46 +0000</pubDate>
</item>
<item>
<title>Mild Asymmetric Message Franking: Illegal-Messages-Only and Retrospective Content Moderation</title>
<link>https://eprint.iacr.org/2024/1608</link>
<guid>https://eprint.iacr.org/2024/1608</guid>
<content:encoded><![CDATA[
<div> 关键词：E2E加密、非法内容、消息打码、技术平衡、框架构建

总结:

本文探讨了广泛采用端到端（E2E）加密后，信息平台面临的用户隐私与非法内容管理之间的技术挑战。主要问题在于现有的解决方案往往侧重于不可帧化或否认性，但缺乏有效的非法内容处理机制，同时可能被滥用。为解决这些问题，文章提出了一种名为“温和非对称消息打码”（MAMF）的新概念，旨在实现非法消息专有和回溯内容管理，同时支持不可帧化和否认性。

文章进一步提供了一个构建MAMF的框架，并引入了两个新的基础组件，这些组件不仅对于实现MAMF具有重要意义，也可能是独立研究的有价值贡献。通过这种框架，信息平台可以在保护用户隐私的同时，有效管理和监控非法内容，从而实现用户隐私与内容安全的平衡。

该解决方案的核心在于创造一种机制，允许平台对非法消息进行标记或打码，使得非法消息仅可由指定人员访问，同时确保其他合法通信内容的隐私和安全性不受影响。此外，该系统还具备回溯功能，允许在特定情况下审查和处理历史消息，以应对潜在的非法内容传播问题。通过这一创新，文章为信息平台提供了在维护用户隐私的同时，有效应对非法内容挑战的技术路径。 <div>
Many messaging platforms have integrated end-to-end (E2E) encryption into their services. This widespread adoption of E2E encryption has triggered a technical tension between user privacy and illegal content moderation. The existing solutions either support only unframeability or deniability, or they are prone to abuse (the moderator can perform content moderation for all messages, whether illegal or not), or they lack mechanisms for retrospective content moderation.

To address the above issues, we introduce a new primitive called \emph{mild asymmetric message franking} (MAMF) to establish illegal-messages-only and retrospective content moderation for messaging systems, supporting unframeability and deniability simultaneously. We provide a framework to construct MAMF, leveraging two new building blocks, which might be of independent interest.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 12:49:58 +0000</pubDate>
</item>
<item>
<title>Reckle Trees: Updatable Merkle Batch Proofs with Applications</title>
<link>https://eprint.iacr.org/2024/493</link>
<guid>https://eprint.iacr.org/2024/493</guid>
<content:encoded><![CDATA[
<div> 关键词: Reckle树、矢量承诺、递归论证、梅克尔树、更新性批验证

总结:
文章提出了一种新的矢量承诺机制——Reckle树，它基于递归论证和梅克尔树。Reckle树的独特之处在于支持紧凑的可更新批验证，这对于区块链环境中的应用非常关键，因为这些应用需要高效地处理不断变化的块流。该机制通过嵌入批哈希计算到递归梅克尔验证中，利用哈希基积构造“标准”进行实现。这使得批证明能够在时间复杂度为对数级别的情况下更新，且当批中的某个梅克尔叶（无论是否属于批）发生变化时，只需要维护一个存储先前计算的递归证明的数据结构。

为了进一步扩展其应用范围，文章还引入了Reckle+树，这是一种用于某些类型Map/Reduce运算的矢量承诺机制。在Reckle+树中，验证者可以对内存进行承诺，并为子集上的Map/Reduce运算生成紧凑的证明。当子集或内存发生变化时，证明可以被有效地更新。

文章还介绍了Reckle树和Reckle+树在动态摘要转换和可更新BLS聚合两个具体应用中的实现与评估。在动态摘要转换中，系统维护着两种不同哈希函数计算的梅克尔摘要等价性的证明。在可更新BLS聚合中，系统维护着对一组BLS密钥集合中子集的正确聚合证明。

实验结果表明，与现有方法相比，Reckle树和Reckle+树在更新时间和验证时间上表现出显著优势，提高了应用效率，降低了成本。同时，它们在聚合性能方面也具有竞争力。 <div>
We propose Reckle trees, a new vector commitment based on succinct RECursive arguments and MerKLE trees. Reckle trees' distinguishing feature is their support for succinct batch proofs that are updatable - enabling new applications in the blockchain setting where a proof needs to be computed and efficiently maintained over a moving stream of blocks. Our technical approach is based on embedding the computation of the batch hash inside the recursive Merkle verification via a hash-based accumulator called canonical hashing. Due to this embedding, our batch proofs can be updated in logarithmic time, whenever a Merkle leaf (belonging to the batch or not) changes, by maintaining a data structure that stores previously-computed recursive proofs. Assuming enough parallelism, our batch proofs are also computable in $O(\log n)$ parallel time - independent of the size of the batch. As a natural extension of Reckle trees, we also introduce Reckle+ trees. Reckle+ trees provide updatable and succinct proofs for certain types of Map/Reduce computations. In this setting, a prover can commit to a memory $\mathsf{M}$ and produce a succinct proof for a Map/Reduce computation over a subset $I$ of $\mathsf{M}$. The proof can be efficiently updated whenever $I$ or $\mathsf{M}$ changes.

We present and experimentally evaluate two applications of Reckle+ trees, dynamic digest translation and updatable BLS aggregation. In dynamic digest translation we are maintaining a proof of equivalence between Merkle digests computed with different hash functions, e.g., one with a SNARK-friendly Poseidon and the other with a SNARK-unfriendly Keccak. In updatable BLS aggregation we maintain a proof for the correct aggregation of a $t$-aggregate BLS key, derived from a $t$-subset of a Merkle-committed set of individual BLS keys. Our evaluation using Plonky2 shows that Reckle trees and Reckle+ trees have small memory footprint, significantly outperform previous approaches in terms of updates ($10\times$ to $15\times$) and verification  ($4.78\times$ to $1485\times$) time, enable applications that were not possible before due to huge costs involved (Reckle trees are up to 200 times faster), and have similar aggregation performance with previous implementations of batch proofs.
]]></content:encoded>
<pubDate>Wed, 27 Mar 2024 19:01:01 +0000</pubDate>
</item>
<item>
<title>Nebula: Efficient read-write memory and switchboard circuits for folding schemes</title>
<link>https://eprint.iacr.org/2024/1605</link>
<guid>https://eprint.iacr.org/2024/1605</guid>
<content:encoded><![CDATA[
<div> 关键词：Folding schemes、增量验证计算（IVC）、承诺携带、高效读写内存、开关板电路构造

总结:
文章主要探讨了通过使用新的技术方法来优化基于折叠方案的增量验证计算（Incrementally Verifiable Computation, IVC）的性能，特别是针对长时间运行的机器执行场景，如zkVMs（零知识虚拟机）。文章提出的关键技术包括承诺携带IVC、高效读写内存和开关板电路构造。

1. **承诺携带IVC**：文章引入了一种名为“承诺携带”的增量验证计算机制，该机制允许证明者在不同步骤中提供非确定性建议，并通过证明携带增量承诺来确保其一致性。这种机制有助于提高证明效率和空间效率。

2. **高效读写内存**：结合承诺携带IVC，文章展示了如何实现高效读写内存，这不仅支持索引查找等操作，而且在成本方面与非递归论证具有相同的效率。这一改进对于处理复杂数据结构和频繁访问的数据尤为重要。

3. **开关板电路构造**：文章提出了一种新颖的“开关板”电路构建方法，通过将不同指令的电路组合在一起，并在执行过程中动态关闭未调用的电路元素和约束，实现了按需付费的证明者成本模型。这种方法能够显著降低证明系统的规模，从而加速证明生成过程。

4. **原型实现与性能评估**：为了验证这些理论和技术的有效性，文章实施了一个基于Nebula的zkVM原型，用于Ethereum虚拟机（EVM）。实验结果表明，与传统的内存检查技术相比，Nebula技术能显著减少约束系统的规模，并使标准ERC20代币转账交易的证明生成速度提升至约260倍。

5. **整体贡献**：综上所述，文章通过提出和实施承诺携带IVC、高效读写内存和开关板电路构造等创新技术，显著提高了基于折叠方案的增量验证计算的性能，特别是在处理大规模和长时间运行的机器执行任务时。这些改进不仅优化了证明系统的效率和成本，还为zkVMs等零知识证明应用提供了更强大的支持。 <div>
Folding schemes enable prover-efficient incrementally verifiable computation (IVC), where a proof is generated step-by-step, resulting in a space-efficient prover that naturally supports continuations. These attributes make them a promising choice for proving long-running machine executions (popularly, "zkVMs"). A major problem is designing an efficient read-write memory. Another challenge is overheads incurred by unused machine instructions when incrementally proving a program execution step.

Nebula addresses these with new techniques that can paired with modern folding schemes. First, we introduce commitment-carrying IVC, where a proof carries an incremental commitment to the prover’s non-deterministic advice provided at different steps. Second, we show how this unlocks efficient read-write memory (which implies indexed lookups) with a cost-profile identical to that of non-recursive arguments. Third, we provide a new universal "switchboard" circuit construction that combines circuits of different instructions such that one can "turn off" uninvoked circuit elements and constraints, offering a new way to achieve pay-per-use prover costs.

We implement a prototype of a Nebula-based zkVM for the Ethereum virtual machine (EVM). We find that Nebula’s techniques qualitatively provide a $30\times$ smaller constraint system to represent the EVM over standard memory-checking techniques, and lead to over $260\times$ faster proof generation for the standard ERC20 token transfer transaction.
]]></content:encoded>
<pubDate>Wed, 09 Oct 2024 00:36:09 +0000</pubDate>
</item>
<item>
<title>Stateful Communication with Malicious Parties</title>
<link>https://eprint.iacr.org/2024/1593</link>
<guid>https://eprint.iacr.org/2024/1593</guid>
<content:encoded><![CDATA[
<div> 关键词：Chat Sessions、模块化抽象、状态化群通信、安全保证、UatChat

总结:

文章主要介绍了一种名为“Chat Sessions”的模块化抽象模型，用于实现状态化的群通信。这种模型能够提供全异步环境下的安全性保障，无需假设任何参与方的诚实性。其核心在于通过参数化的权限策略来定义不同参与者在特定聊天状态下的操作权利。

Chat Sessions模型具备高度的模块性，能够方便地扩展以涵盖诸如消息的真实性、机密性、匿名性以及离线记录等额外的安全需求。作者展示了如何利用Maurer等人提出的Multi-Designated Receiver Public Key Encryption方案构建具有上述所有安全特性的通信通道。

基于Chat Sessions模型和上述安全通道，作者进一步开发了名为UatChat的即时通讯应用。UatChat不仅继承了上述所有安全特性，还实现了全新的“离线记录”功能，使得用户可以否认发送的消息，甚至否认自己参与过某次聊天，从而提供了首个完全意义上的离线记录（Off-The-Record）即时通讯应用。这一创新为用户隐私保护带来了革命性的提升，同时体现了Chat Sessions模型的灵活性和实用性。 <div>
Cryptography's most common use is secure communication---e.g. Alice can use encryption to hide the contents of the messages she sends to Bob (confidentiality) and can use signatures to assure Bob she sent these messages (authenticity). While one typically considers stateless security guarantees---for example a channel that Alice can use to send messages securely to Bob---one can also consider stateful ones---e.g. an interactive conversation between Alice, Bob and their friends where participation is dynamic: new parties can join the conversation and existing ones can leave. A natural application of such stateful guarantees are messengers.

We introduce a modular abstraction for stateful group communication, called Chat Sessions, which captures security guarantees that are achievable in fully asynchronous settings when one makes no party-honesty assumptions: anyone (including group members themselves) can be fully dishonest. Our abstraction is parameterized by (and enforces) a permissions policy that defines what operations parties have the right to perform in a given chat state. We show how to construct, use and extend Chat Sessions.

Our construction is fully decentralized (in particular, it need not a delivery service), does not incur additional interaction between chat participants (other than what is inherent from chat operations like sending a message) and liveness depends solely on messages being delivered.

A key feature of Chat Sessions is modularity: we extend Chat Sessions to capture authenticity, confidentiality, anonymity and off-the-record, and show our construction provides these guarantees if the underlying communication channels do too. We complement this by proving Maurer et al.'s Multi-Designated Receiver Public Key Encryption scheme (Eurocrypt '22) constructs matching communication channels (i.e. with all these guarantees).

We use Chat Sessions to construct UatChat: a simple and equally modular messaging application. Since UatChat preserves each of the guarantees mentioned above, this means we give the first fully Off-The-Record messaging application: parties can plausibly deny not only having sent any messages but even of being aware of a chat's existence.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 10:20:30 +0000</pubDate>
</item>
<item>
<title>DART: Distributed argument of knowledge for rough terrains</title>
<link>https://eprint.iacr.org/2024/1592</link>
<guid>https://eprint.iacr.org/2024/1592</guid>
<content:encoded><![CDATA[
<div> 关键词：KZG、Snark、Cocks-Pinch、Brezing-Weng、pairing-friendly曲线

文章主要介绍了使用KZG（KZG多值承诺方案）为基础的全分布式零知识证明系统，该系统适用于任何具有足够大标量域的配对友好曲线。特别地，此证明系统与Cocks-Pinch或Brezing-Weng外曲线兼容，如secp256k1, ED25519, BLS12-381和BN254等广泛使用的曲线。

文章提到，通过使用双变量KZG多项式承诺方案，可以实现线性于电路大小的通用可更新共通参考系(CRS)，使得证明系统的规模、验证时间和通信复杂度保持常数。对于特定的曲线（如Ed25519），当使用9位配对友好外曲线时，证明的大小为5KB，每台工作节点的通信复杂度也是5KB，主节点的通信复杂度同样为每台机器5KB。

对于电路大小为T·M的电路在M台机器上的有效验证时间，公式为O(T·log(T)+M·log(M))。每台验证器机器的工作主要由长度为T的G1组的MSMs（复数乘法序列）主导，以及通过多模快速傅里叶变换计算的单个多变元多项式产品的求和。主节点的工作则主要由长度为M的G1组的MSMs和通过多模快速傅里叶变换计算的单个多变元多项式产品的求和主导。

总结:
本文提出了一种基于KZG的全分布式零知识证明系统，该系统适用于各种配对友好曲线，包括Cocks-Pinch和Brezing-Weng外曲线，如secp256k1, ED25519, BLS12-381和BN254。通过使用双变量KZG多项式承诺方案，实现了线性于电路大小的通用可更新共通参考系，保证了证明系统的规模、验证时间和通信复杂度保持常数。对于特定曲线（如Ed25519），在使用9位配对友好外曲线时，证明的大小为5KB，每台工作节点的通信复杂度也是5KB，主节点的通信复杂度为每台机器5KB。同时，详细描述了验证时间、每台验证器机器和主节点的工作流程，显示了该系统的高效性和可扩展性。 <div>
We describe a fully distributed KZG-based Snark instantiable with any pairing-friendly curve with a sufficiently large scalar field. In particular, the proof system is compatible with Cocks-Pinch
or Brezing-Weng outer curves to the the widely used curves such as secp256k1, ED25519, BLS12-381 and BN254.

This allows us to retain the fully parallelizable nature and the O(1) communication complexity of Pianist ([LXZ+23]) in conjunction with circumventing the huge overhead of non-native arithmetic for
prominent use cases such as scalar multiplications and/or pairings for Bitcoin (secp256k1), Cosmos (Ed25519) and Ethereum PoS (BLS12-381) signatures.

As in [LXZ+23], we use a bivariate KZG polynomial commitment scheme, which entails a universal updatable CRS linear in the circuit size. The proof size is constant, as are the verification time -
dominated by three pairings - and the communication complexity between the Prover machines. With a 9-limb pairing-friendly outer curve to Ed25519, the proof size is 5 KB. With the same curve, the communication complexity for each worker node is 5 KB and that of the master node is 5 KB per machine.

The effective Prover time for a circuit of size T ·M on M machines is O(T · log(T)+M · log(M)). The work of each Prover machine is dominated by the MSMs of length T in the group G1 and a single sum of univariate polynomial products computed via multimodular FFTs1 of size 2T. Likewise, the work of the master node is dominated by the MSMs of length M in the group G1 and a single sum of univariate polynomial products via multimodular FFTs of size 2M.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 09:29:20 +0000</pubDate>
</item>
<item>
<title>Mutable Batch Arguments and Applications</title>
<link>https://eprint.iacr.org/2024/737</link>
<guid>https://eprint.iacr.org/2024/737</guid>
<content:encoded><![CDATA[
<div> 关键词: 可变批参数、可变批论证系统、强隐私概念、实用应用、标准假设

总结:

本文提出了一种新型的批参数（BARG）概念——可变批参数（mutable BARGs），旨在重新思考和使用BARG的方式。传统上，BARG证明π是一个不可变的原始见证ω1到ωk的编码。而可变BARG系统则将每个证明字符串π视为原始见证的可变编码，关注于对证明的可变性操作。

研究了可变BARG的强隐私概念，旨在隐藏所有非显而易见的见证信息。这种可变BARG非常适合许多敏感隐私的应用场景。主要贡献包括引入可变BARG的概念，识别可行的可变类，设计满足不同能力的可变BARG构造，以及从标准加密假设出发设计新的构造，从而在多种高级签名（同态/可删除/聚合签名）中启用新应用。这些成果显著提升了当前已知的签名系统状态。

具体而言，本文提供了首个基于标准假设的多密钥同态签名，其签名简洁；首次实现了真正紧凑的可删除签名，预/后删除签名保持固定大小；首次从标准假设出发提供了满足消息隐私的本地验证多签者聚合签名。这些贡献极大地推动了密码学领域，尤其是签名技术的发展。 <div>
We put forth a new concept of mutability for batch arguments (BARGs), called mutable batch arguments. Our goal is to re-envision how we think about and use BARGs. Traditionally, a BARG proof $\pi$ is an immutable encoding of $k$ $\mathbf{NP}$ witness $\omega_1, \ldots, \omega_{k}$. A mutable BARG system captures the notion of computations over BARGs, where each proof string $\pi$ is treated as a mutable encoding of original witnesses. We also study strong privacy notions for mutable BARGs, with the goal of hiding all non-trivial information about witnesses from a mutated proof. Such mutable BARGs are a naturally good fit for many privacy sensitive applications.

Our main contributions include introducing the concept of mutable BARGs, identifying non-trivial classes of feasible mutations, designing new constructions for mutable BARGs with varying capabilities satisfying mutation privacy from standard cryptographic assumptions, and enabling new applications to many advanced signatures (homomorphic/ redactable/ aggregate signatures). Our results improve state-of-the-art known for many signature systems. E.g., we provide the first multi-key homomorphic signature with succinct signatures from standard assumptions, and we provide the first truly compact redactable signature where pre/post-redaction signatures are of fixed size, and we provide the first locally verifiable multi-signer aggregate signature satisfying message privacy from standard assumptions.
]]></content:encoded>
<pubDate>Mon, 13 May 2024 19:45:35 +0000</pubDate>
</item>
<item>
<title>Matching radar signals and fingerprints with MPC</title>
<link>https://eprint.iacr.org/2024/1590</link>
<guid>https://eprint.iacr.org/2024/1590</guid>
<content:encoded><![CDATA[
<div> 关键词：Vessels、Navigation radar、Radar fingerprint、Secure multiparty computation、Information exchange agreement

总结:

本文主要讨论了通过雷达信号识别船只的技术及其背后的安全机制。船只可以通过其导航雷达被识别，这有助于建立情境意识，而无需暴露自身存在。各国维护着雷达指纹数据库，但出于国家安全考虑，不愿轻易共享这些信息。为了促进合作，正确的身份识别变得尤为重要。文中提出使用安全多方计算（Secure multiparty computation）技术，该技术可以匹配雷达信号测量与秘密数据库中的信息，并输出可能的匹配结果及其概率。此外，还提供了一个基于MP-SPDZ的演示实例，展示这一技术的应用。这种合作机制不仅能够提升海上航行的安全性，还能增强各国在信息安全方面的互信与协作。通过安全的多方计算，可以在不泄露敏感数据的情况下实现信息共享，为国际间的合作提供了新的可能。 <div>
Vessels can be recognised by their navigation radar due to the characteristics of the emitted radar signal. This is particularly useful if one wants to build situational awareness without revealing one's own presence. Most countries maintain databases of radar fingerprints but will not readily share these due to national security regulations. Sharing of such information will generally require some form of information exchange agreement.

However, all parties in a coalition benefit from correct identification. We use secure multiparty computation to match a radar signal measurement against secret databases and output plausible matches with their likelihoods. We also provide a demonstrator using MP-SPDZ.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 06:39:10 +0000</pubDate>
</item>
<item>
<title>A Note on ``Privacy-Preserving and Secure Cloud Computing: A Case of Large-Scale Nonlinear Programming''</title>
<link>https://eprint.iacr.org/2024/1588</link>
<guid>https://eprint.iacr.org/2024/1588</guid>
<content:encoded><![CDATA[
<div> 关键词：外包算法、线性约束、输出隐私、翻译变换、混合变换

<br />
<br />总结:

本文针对《IEEE Transactions on Cloud Computing》中2023年第11卷第1期，第484至498页的一篇文章进行了深入分析。文章指出，对于线性约束条件下的外包算法，其输出隐私可能无法得到保障，主要原因是简单翻译变换的存在。这种情况下，通过对手中数据进行处理，可以轻易地推断出原始数据的信息，从而破坏了隐私保护。

为解决这一问题，作者提出了一种补救方法——采用混合变换策略。该策略结合了传统的翻译变换和缩放变换，旨在增强数据处理过程中的隐私保护能力。通过这种混合变换，可以在不显著影响数据处理效果的前提下，有效地防止对原始数据信息的推断，从而实现更好的输出隐私保护。

综上所述，文章揭示了现有外包算法在处理线性约束问题时存在的隐私泄露风险，并提供了一种改进方案以增强算法的安全性和隐私保护性能。这不仅为相关研究提供了理论依据，也为实际应用中的数据安全与隐私保护提供了新的思路和方法。 <div>
We show that the outsourcing algorithm for the case of linear constraints  [IEEE Trans. Cloud Comput., 2023, 11(1), 484-498] cannot keep output privacy, due to the simple  translation transformation. We also suggest a remedy method by adopting a hybrid transformation which combines the usual  translation transformation and resizing transformation so as to protect the output privacy.
]]></content:encoded>
<pubDate>Tue, 08 Oct 2024 00:24:43 +0000</pubDate>
</item>
<item>
<title>Efficient Pairing-Free Adaptable k-out-of-N Oblivious Transfer Protocols</title>
<link>https://eprint.iacr.org/2024/1583</link>
<guid>https://eprint.iacr.org/2024/1583</guid>
<content:encoded><![CDATA[
<div> 关键词：Oblivious Transfer、Efficient Two-Round、Pairing-Free、k-out-of-N、Standard Security

<br />
总结:

这篇论文介绍了三种基于最小通信模式的、无配对操作的、两轮k-out-of-N Oblivious Transfer（OT）协议，具有标准安全性。这些协议遵循接收方发送k条消息给发送方，后者响应n+k条消息的模式，实现了无配对操作的k-out-of-n OT方案中最低的数据传输量。此外，它们支持适应性，并允许发送方离线加密n条消息，无需依赖接收方的变量，特别适合于单发送者多接收者的场景。

论文提供的安全证明基于计算Diffie-Hellman（CDH）假设和RSA假设，无需随机预言机模型。这些协议通过结合最少通信轮数、适应性、离线加密能力以及可验证安全性，为需要高效OT的隐私保护应用提供了理想的解决方案。尤其对于资源受限设备而言，前两个提出的方案只需要一次操作，极大地提高了效率。 <div>
Oblivious Transfer (OT) is one of the fundamental building blocks in cryptography that enables various privacy-preserving applications. Constructing efficient OT schemes has been an active research area. This paper presents three efficient two-round pairing-free k-out-of-N oblivious transfer protocols with standard security. Our constructions follow the minimal communication pattern: the receiver sends k messages to the sender, who responds with n+k messages, achieving the lowest data transmission among pairing-free k-out-of-n OT schemes. Furthermore, our protocols support adaptivity and also, enable the sender to encrypt the n messages offline, independent of the receiver's variables, offering significant performance advantages in one-sender-multiple-receiver scenarios. We provide security proofs under the Computational Diffie-Hellman (CDH) and RSA assumptions, without relying on the Random Oracle Model. Our protocols combine minimal communication rounds, adaptivity, offline encryption capability, and provable security, making them well-suited for privacy-preserving applications requiring efficient oblivious transfer. Furthermore, the first two proposed schemes require only one operation, making them ideal for resource-constrained devices.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 14:01:27 +0000</pubDate>
</item>
<item>
<title>Re-visiting Authorized Private Set Intersection: A New Privacy-Preserving Variant and Two Protocols</title>
<link>https://eprint.iacr.org/2024/1579</link>
<guid>https://eprint.iacr.org/2024/1579</guid>
<content:encoded><![CDATA[
<div> 关键词：APSI、Partial-APSI、Bilinear Pairings、Parallelizability、Commodity Hardware

总结:

本文探讨了授权私密集合交集（APSI）问题以及其在生物基因匹配、广告转化和GDPR等隐私政策合规中的应用。APSI允许不信任的双方通过可信第三方裁判授权他们的项目，然后进行私密交集计算。为了解决这一问题，作者提出了两个基于双线性对的协议，均具有线性通信量。第一个协议实现了APSI功能，安全对抗恶意客户端，仅需一次在线阶段的通信。第二个协议则实现了Partial-APSI功能，适用于客户端可能恶意注入元素但遵循半诚实协议的情况。这两个协议均被证明是正确的并且具有安全性。实验结果显示，这些协议可以在普通硬件上高效运行，并且可以并行化执行，实验在50个核心的计算网格上进行了验证。

通过这两个协议，作者不仅解决了APSI和Partial-APSI的问题，而且展示了其实现的高效性和可扩展性，为实际应用提供了有力的支持。特别是对于需要处理大量数据和高并发请求的场景，如在线广告和生物信息分析，这些协议提供了安全、高效且易于扩展的解决方案。 <div>
We revisit the problem of Authorized Private Set Intersection (APSI), which allows mutually untrusting parties to authorize their items using a trusted third-party judge before privately computing the intersection. We also initiate the study of Partial-APSI, a novel privacy-preserving generalization of APSI in which the client only reveals a subset of their items to a third-party semi-honest judge for authorization. Partial-APSI allows for partial verification of the set, preserving the privacy of the party whose items are being verified. Both APSI and Partial-APSI have a number of applications, including genome matching, ad conversion, and compliance with privacy policies such as the GDPR.
    
We present two protocols based on bilinear pairings with linear communication. The first realizes the APSI functionality, is secure against a malicious client, and requires only one round of communication during the online phase. Our second protocol realizes the Partial-APSI functionality and is secure against a client that may maliciously inject elements into its input set, but who follows the protocol semi-honestly otherwise. We formally prove correctness and security of these protocols and provide an experimental evaluation to demonstrate their practicality. Our protocols can be efficiently run on commodity hardware. We also show that our protocols are massively parallelizable by running our experiments on a compute grid across 50 cores.
]]></content:encoded>
<pubDate>Mon, 07 Oct 2024 08:24:25 +0000</pubDate>
</item>
<item>
<title>Efficiently-Thresholdizable Selective Batched Identity Based Encryption, with Applications</title>
<link>https://eprint.iacr.org/2024/1575</link>
<guid>https://eprint.iacr.org/2024/1575</guid>
<content:encoded><![CDATA[
<div> 关键词：Selective Batched IBE、Thresholdized Version、Identity-Based Encryption、Blockchain、Decryption Key

总结:

本文提出了一种新的加密原语——选择性批处理身份基加密（Selective Batched IBE）及其阈值化版本。这种加密技术允许加密具有特定身份和批次标签的消息，其中批次标签可以代表区块链上的块编号。对于某个批次中任意子集的身份，该技术能够高效地发行一个单个解密密钥，用于解密所有包含在子集中身份的密文，同时保持不在子集中的密文的隐私。核心创新在于一种能够在不使用任何秘密知识的情况下对任意子集身份进行公共聚合的新技术，生成一个精简摘要。这个摘要被用来通过主密钥来推导一个适用于该批次中所有身份的单个精简解密密钥。在阈值系统中，主密钥被分散为多个权威机构的秘密共享，这种方法显著降低了这些机构在密钥发行过程中的通信（有时还有计算）开销。

具体实例基于Kate等人在Asiacrypt'10提出的KZG多项式承诺方案和Boneh等人在Asiacrypt'01修改后的BLS签名方案构建。构造在通用群模型下证明了安全性。

在区块链背景下，该新构造可用于实现交易池隐私，通过将交易加密到区块中，仅公开包含在特定区块中的交易并隐藏未包含的交易。阈值化版本允许多个权威（验证者）协作管理解密过程。其他可能的应用包括基于区块链的欺诈多数MPC公平性支持的可扩展性增强，以及条件批量阈值解密，可用于实现安全的荷兰拍卖和隐私保护期权交易。 <div>
We propose a new cryptographic primitive called ``selective batched identity-based encryption'' (Selective Batched IBE) and its thresholdized version. The new primitive allows encrypting messages with specific identities and batch labels, where the latter can represent, for example, a block number on a blockchain. Given an arbitrary subset of identities for a particular batch, our primitive enables efficient issuance of a single decryption key that can be used to decrypt all ciphertexts having identities that are included in the subset while preserving the privacy of all ciphertexts having identities that are excluded from the subset. At the heart of our construction is a new technique that enables public aggregation (i.e. without knowledge of any secrets) of any subset of identities, into a succinct digest. This digest is used to derive, via a master secret key, a single succinct decryption key for all the identities that were digested in this batch. In a threshold system, where the master key is distributed as secret shares among multiple authorities, our method significantly reduces the communication (and in some cases, computation) overhead for the authorities. It achieves this by making their costs for key issuance independent of the batch size.

We present a concrete instantiation of a Selective Batched IBE scheme based on the KZG polynomial commitment scheme by Kate et al. (Asiacrypt'10) and a modified form of the BLS signature scheme by Boneh et al. (Asiacrypt'01). The construction is proven secure in the generic group model (GGM).

In a blockchain setting, the new construction can be used for achieving mempool privacy by encrypting transactions to a block, opening only the transactions included in a given block and hiding the transactions that are not included in it.  With the thresholdized version,  multiple authorities (validators) can collaboratively manage the decryption process.  Other possible applications include scalable support via blockchain for fairness of dishonest majority MPC, and conditional batched threshold decryption that can be used for implementing secure Dutch auctions and privacy preserving options trading.
]]></content:encoded>
<pubDate>Sun, 06 Oct 2024 10:19:44 +0000</pubDate>
</item>
<item>
<title>OML: Open, Monetizable, and Loyal AI</title>
<link>https://eprint.iacr.org/2024/1573</link>
<guid>https://eprint.iacr.org/2024/1573</guid>
<content:encoded><![CDATA[
<div> 关键词：AI, OML, 区块链, AI-原生加密, 模型指纹识别

<br />
总结:

本文提出了一种名为OML（Open, Monetizable, Loyal AI）的全新AI开发框架，旨在打破当前AI领域由少数大型组织和个体垄断的局面。OML通过结合AI、区块链和密码学等跨学科方法，为AI的开放性、可盈利性和忠诚度提供了解决方案。关键创新在于引入了AI-原生加密这一新兴领域，该领域利用定制化的密码技术来适应AI数据的连续性和低维特性，以提升近似性能。

OML的核心概念是模型指纹识别，这是一种新颖的AI-原生加密工具，用于保护AI模型的完整性和所有权。通过区块链技术，OML实现了一个去中心化、透明的AI开发平台，让社区成员能够贡献、盈利并拥有自己的AI模型。这一创新性框架旨在建立一个更加包容的AI生态系统，通过分散控制权和确保透明度，克服当前AI部署中集中化和缺乏公开监督的问题。

通过实施OML 1.0系统，作者证明了AI-原生加密技术的实际可行性，并分析了其安全性和有效性。此系统不仅提供了保护AI模型免受攻击的手段，还促进了AI开发过程中的开放合作与资源共享，从而推动了更广泛的AI创新和发展。 <div>
Artificial Intelligence (AI) has steadily improved across a wide range of tasks, and a significant breakthrough towards general intelligence was achieved with the rise of generative deep models, which have garnered worldwide attention. However, the development and deployment of AI are almost entirely controlled by a few powerful organizations and individuals who are racing to create Artificial General Intelligence (AGI). These centralized entities make decisions with little public oversight, shaping the future of humanity, often with unforeseen consequences.
In this paper, we propose OML, which stands for Open, Monetizable, and Loyal AI, an approach designed to democratize AI development and shift control away from these monopolistic actors. OML is realized through an interdisciplinary framework spanning AI, blockchain, and cryptography. We present several ideas for constructing OML systems using technologies such as Trusted Execution Environments (TEE), traditional cryptographic primitives like fully homomorphic encryption and functional encryption, obfuscation, and AI-native solutions rooted in the sample complexity and intrinsic hardness of AI tasks.
A key innovation of our work is the introduction of a new scientific field: AI-native cryptography, which leverages cryptographic primitives tailored to AI applications. Unlike conventional cryptography, which focuses on discrete data and binary security guarantees, AI-native cryptography exploits the continuous nature of AI data representations and their low-dimensional manifolds, focusing on improving approximate performance. One core idea is to transform AI attack methods, such as data poisoning, into security tools. This novel approach serves as a foundation for OML 1.0, an implemented system that demonstrates the practical viability of AI-native cryptographic techniques. At the heart of OML 1.0 is the concept of model fingerprinting, a novel AI-native cryptographic primitive that helps protect the integrity and ownership of AI models.
The spirit of OML is to establish a decentralized, open, and transparent platform for AI development, enabling the community to contribute, monetize, and take ownership of AI models. By decentralizing control and ensuring transparency through blockchain technology, OML prevents the concentration of power and provides accountability in AI development that has not been possible before.
To the best of our knowledge, this paper is the first to:
•  Identify the monopolization and lack of transparency challenges in AI deployment today and formulate the challenge as OML (Open, Monetizable, Loyal).
•  Provide an interdisciplinary approach to solving the OML challenge,  incorporating ideas from AI, blockchain, and cryptography.
•  Introduce and formally define the new scientific field of AI-native cryptography.
•  Develop novel AI-native cryptographic primitives and implement them in OML 1.0, analyzing their security and effectiveness.
•  Leverage blockchain technology to host OML solutions, ensuring transparency, decentralization, and alignment with the goals of democratized AI development.
Through OML, we aim to provide a decentralized framework for AI development that prioritizes open collaboration, ownership rights, and transparency, ultimately fostering a more inclusive AI ecosystem.
]]></content:encoded>
<pubDate>Sat, 05 Oct 2024 22:50:01 +0000</pubDate>
</item>
<item>
<title>Efficient Secure Multiparty Computation for Multidimensional Arithmetics and Its Application in Privacy-Preserving Biometric Identification</title>
<link>https://eprint.iacr.org/2023/1863</link>
<guid>https://eprint.iacr.org/2023/1863</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、高效运算、张量三元组、生物识别、机器学习

<br /><br />
总结:
本文探讨了在多党计算（MPC）的发展中，为了提高多维MPC协议的效率，引入了一种新的相关性概念——“张量三元组”。张量三元组的设计旨在优化涉及向量元素数据集的MPC协议，如隐私保护生物识别和隐私保护机器学习。文章详细阐述了张量三元组的生成过程、使用方法及其应用范围。研究显示，该技术能够显著加速诸如FingerCode、Eigenfaces和FaceNet等隐私保护生物识别协议，其加速效果超过1000倍，尽管需要一定的预处理成本。

文章首先介绍了张量三元组的概念及其在多维MPC中的作用，强调了其对于提升生物识别和机器学习等场景下数据处理效率的关键性。随后，详细解释了张量三元组如何通过优化数据交互和计算流程，实现对MPC协议性能的显著增强。最后，通过具体案例分析，展示了张量三元组在实际应用中的效果，特别是其在隐私保护生物识别领域的应用，证实了其能有效提升协议执行速度，同时保持合理的时间成本投入。 <div>
Over years of the development of secure multi-party computation (MPC), many sophisticated functionalities have been made pratical and multi-dimensional operations occur more and more frequently in MPC protocols, especially in protocols involving datasets of vector elements, such as privacy-preserving biometric identification and privacy-preserving machine learning. In this paper, we introduce a new kind of correlation, called tensor triples, which is designed to make multi-dimensional MPC protocols more efficient. We will discuss the generation process, the usage, as well as the applications of tensor triples and show that it can accelerate privacy-preserving biometric identification protocols, such as FingerCode, Eigenfaces and FaceNet, by more than 1000 times, with reasonable offline costs.
]]></content:encoded>
<pubDate>Tue, 05 Dec 2023 06:49:23 +0000</pubDate>
</item>
<item>
<title>Scalable and Adaptively Secure Any-Trust Distributed Key Generation and All-hands Checkpointing</title>
<link>https://eprint.iacr.org/2023/1773</link>
<guid>https://eprint.iacr.org/2023/1773</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式密钥生成、DLog基密码系统、适应性安全、区块链、广播通道

总结:

本文提出了一种面向DLog基密码系统的实用分布式密钥生成（DKG）协议，旨在解决大型分布式部署中的计算和通信开销问题。该协议利用“共同硬币”机制和一系列针对适应性安全的策略，使得即使在最多存在拜占庭节点的情况下，每个节点的计算和通信成本也能保持线性或接近线性。此外，该协议确保了当超过半数节点被适配性攻击者控制时，系统依然能够维持安全性。

文章还引入了一种通用转换器，用于在参与者具有不同权重的情况下高效部署传统分布式协议，如上述DKG。通过结合区块链和数据分散网络（如IPFS）构建的扩展广播通道，实现了任意大小消息的可靠广播，同时仅需常量大小的区块链存储空间。

该DKG协议的应用实例为Filecoin的检查点机制提供了基础，允许所有验证者定期执行DKG和阈值签名来创建比特币上的检查点，从而增强PoS区块链的安全性。与最近的检查点方法Babylon相比，本文提出的方案在比特币交易费用成本上有着显著优势，对于2^12个验证者的场景，其成本仅为Babylon方法的0.4%。 <div>
The classical distributed key generation protocols (DKG) are resurging due to their widespread applications in blockchain. While efforts have been made to improve DKG communication, practical large-scale deployments are still yet to come due to various challenges, including the heavy computation and communication (particularly broadcast) overhead in their adversarial cases. In this paper, we propose a practical DKG for DLog-based cryptosystems, which achieves (quasi-)linear computation and communication per-node cost with the help of a common coin, even in the face of the maximal amount of Byzantine nodes. Moreover, our protocol is secure against adaptive adversaries, which can corrupt less than half of all nodes. The key to our improvements lies in delegating the most costly operations to an Any-Trust group together with a set of techniques for adaptive security. This group is randomly sampled and consists of a small number of individuals. The population only trusts that at least one member in the group is honest, without knowing which one. Moreover, we present a generic transformer that enables us to efficiently deploy a conventional distributed protocol like our DKG, even when the participants have different weights. Additionally, we introduce an extended broadcast channel based on a blockchain and data dispersal network (such as IPFS), enabling reliable broadcasting of arbitrary-size messages at the cost of constant-size blockchain storage. 

Our DKG leads to a fully practical instantiation of Filecoin's checkpointing mechanism, in which all validators of a Proof-of-Stake (PoS) blockchain periodically run DKG and threshold signing to create checkpoints on Bitcoin, to enhance the security of the PoS chain. In comparison with the recent checkpointing approach of Babylon (Oakland, 2023), ours enjoys a significantly smaller cost of Bitcoin transaction fees. For $2^{12}$ validators,  our cost is merely 0.4\% of that incurred by Babylon's approach.
]]></content:encoded>
<pubDate>Thu, 16 Nov 2023 01:44:04 +0000</pubDate>
</item>
<item>
<title>Distributed Randomness using Weighted VUFs</title>
<link>https://eprint.iacr.org/2024/198</link>
<guid>https://eprint.iacr.org/2024/198</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、随机性、拜占庭容错、权益证明、可验证不可预测函数

总结:
本文探讨了区块链中内置随机性的方法，尤其是针对基于权益证明的拜占庭容错系统。研究提出了一种称为“链上”随机性的设计思路，即让区块链验证者在每块区块生成共享随机性。这一设计依赖于一种加权可验证不可预测函数（VUF），其显著特点是计算和通信成本与参与者权重无关，这对于频繁快速评估链上随机性至关重要。

为了实现这一目标，文章还设计了一个新的可公开验证的秘密分享方案（PVSS），具有可聚合的传输特性，并基于此设计了一个分布式密钥生成（DKG）协议，用于构建VUF。这些方案被实现在生产部署的Aptos区块链上，并通过112个验证者进行端到端评估，总权重达到4053。实验结果显示，引入随机性协议仅增加了133毫秒的延迟，相比无随机性的情况。此外，研究还通过与基线方法的详细比较，展示了设计性能上的显著提升。

通过上述创新，文章旨在增强区块链对随机化应用的支持，并提高其安全性，同时减少对外部随机性源的依赖，从而提升系统的整体可靠性和效率。 <div>
Shared randomness in blockchain can expand its support for randomized applications and can also help strengthen its security. Many existing blockchains rely on external randomness beacons for shared randomness, but this approach reduces fault tolerance, increases latency, and complicates application development. An alternate approach is to let the blockchain validators generate fresh shared randomness themselves once for every block. We refer to such a design as the \emph{on-chain} randomness. 

In this paper, we design an efficient on-chain randomness protocol for Byzantine fault-tolerance based Proof-of-Stake blockchains with weighted validators. A key component of our protocol is a weighted verifiable unpredictable function (VUF). The notable feature of our weighted VUF is that the computation and communication costs of parties are independent of their weight. This is crucial for scalability of on-chain randomness where we repeatedly evaluate the weighted VUF in quick succession. We also design a new scalable publicly verifiable secret sharing~(PVSS) scheme with aggregatable transcript and use it to design a distributed key generation~(DKG) protocol for our VUF. We implemented our schemes on top of Aptos, a proof-of-stake blockchain deployed in production, conducted an end-to-end evaluation with 112 validators and a total weight of up to 4053. In this setup, our on-chain randomness protocol adds only 133 milliseconds of latency compared to a protocol without randomness. We also demonstrate the performance improvements of our design through rigorous comparison with baseline methods.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 15:48:28 +0000</pubDate>
</item>
<item>
<title>PAC-Private Algorithms</title>
<link>https://eprint.iacr.org/2024/718</link>
<guid>https://eprint.iacr.org/2024/718</guid>
<content:encoded><![CDATA[
<div> 关键词：PAC隐私、算法证明、黑盒算法、模拟算法、稳定性验证

总结:

本文研究了如何利用“可能接近正确（PAC）隐私”理论，为一系列实际应用中的黑盒算法——如K均值聚类、支持向量机（SVM）、主成分分析（PCA）和随机森林——提供形式化、机械化和基于模拟的隐私证明。研究中提出了一种新的模拟算法，用于高效地确定任何给定隐私水平所需的各向异性噪声扰动，并证明了该算法的正确性。该算法显示了与等效的各向同性噪声相比，各向异性噪声在提高隐私保护方面具有实质性优势。

文章还展示了稳定算法更容易实现隐私保护，并通过引入正则化技术，实现了较小的准确性损失下的有意义的隐私保证。为了减少算法输出的不稳定性并简化几何稳定性的验证，文章提出了新的技术，将难以处理的几何稳定性验证转化为高效的确定性稳定性验证。

最后，文章包括了详细的实验结果，验证了所提出的证明方法在对抗最先进的经验攻击方面的有效性，证明了算法在确保隐私的同时保持了良好的性能。 <div>
Provable privacy typically requires involved analysis and is often associated with unacceptable accuracy loss. While many empirical verification or approximation methods, such as Membership Inference Attacks (MIA) and Differential Privacy Auditing (DPA), have been proposed, these do not offer rigorous privacy guarantees. In this paper, we apply recently-proposed Probably Approximately Correct (PAC) Privacy to give formal, mechanized, simulation-based proofs for a range of practical, black-box algorithms: K-Means, Support Vector Machines (SVM), Principal Component Analysis (PCA) and Random Forests. To provide these proofs, we present a new simulation algorithm that efficiently determines anisotropic noise perturbation required for any given level of privacy. We provide a proof of correctness for this algorithm and demonstrate that anisotropic noise has substantive benefits over isotropic noise.

Stable algorithms are easier to privatize, and we demonstrate privacy amplification resulting from introducing regularization in these algorithms; meaningful privacy guarantees are obtained with small losses in accuracy. We propose new techniques in order to reduce instability in algorithmic output and convert intractable geometric stability verification into efficient deterministic stability verification. Thorough experiments are included, and we validate our provable adversarial inference hardness against state-of-the-art empirical attacks.
]]></content:encoded>
<pubDate>Fri, 10 May 2024 01:25:08 +0000</pubDate>
</item>
<item>
<title>Succinct Arguments over Towers of Binary Fields</title>
<link>https://eprint.iacr.org/2023/1784</link>
<guid>https://eprint.iacr.org/2023/1784</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARK、Brakedown、多线性多项式承诺方案、HyperPlonk、Lasso

总结:

本文提出了一种针对二进制域塔结构的高效SNARK（ Succinct Non-Interactive Argument of Knowledge）。该研究主要贡献在于构建了一个适用于小域上多项式的多线性多项式承诺方案，该方案无需嵌入开销即可处理小域多项式。此外，作者还引入了HyperPlonk和Lasso中产品检查和排列检查的二进制领域适应版本，以及Lasso中的查找检查的二进制领域版本。

文章进一步展示了其二进制PLONKish变体如何高效捕获标准哈希函数，如Keccak-256和Grøstl，为现代以太坊扩展努力提供关键的Keccak-256证明。通过详尽的性能基准测试，文章论证了所提出的方案能够有效生成这些关键的Keccak-256证明，对于实现以太坊的可扩展性具有重要意义。

通过改进的SNARK技术，本文为提升区块链平台性能，特别是以太坊的可扩展性和效率提供了新的途径，通过优化多项式承诺和哈希函数的表示，使得大规模数据验证成为可能。 <div>
We introduce an efficient SNARK for towers of binary fields. Adapting Brakedown (CRYPTO '23), we construct a multilinear polynomial commitment scheme suitable for polynomials over tiny fields, including that with just two elements. Our commitment scheme, unlike those of previous works, treats small-field polynomials with no embedding overhead. We further introduce binary-field adaptations of HyperPlonk (EUROCRYPT '23)'s product and permutation checks and of Lasso ('23)'s lookup. Our binary PLONKish variant captures standard hash functions—like Keccak-256 and Grøstl—extremely efficiently. With recourse to thorough performance benchmarks, we argue that our scheme can efficiently generate precisely those Keccak-256-proofs which critically underlie modern efforts to scale Ethereum.
]]></content:encoded>
<pubDate>Fri, 17 Nov 2023 21:58:26 +0000</pubDate>
</item>
<item>
<title>Fully Privacy-preserving Billing Models for Peer-to-Peer Electricity Trading Markets</title>
<link>https://eprint.iacr.org/2024/1562</link>
<guid>https://eprint.iacr.org/2024/1562</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、电量交易、完全同态加密、伪随机零共享、实时数据分析

<br /><br />
总结:
本文提出了一种全新的、全面隐私保护的计费协议，旨在为能源交易中的计费协议提供保护，同时保护用户敏感的消费和生产数据。该协议通过采用高级加密技术，如全同态加密（FHE）和伪随机零共享（PRZS），确保了数据的安全性和机密性，即使在电力供应和需求波动时也能准确处理。实验证明，该模型能够以0.17秒的速度对100户家庭进行实时数据分析并计算个人账单，同时保证了隐私性，不暴露任何敏感信息给交易平台或计费服务器。这一创新解决方案不仅提高了能源交易的效率和准确性，还确保了用户数据的私密性。 <div>
Peer-to-peer energy trading markets enable users to exchange electricity, directly offering them increased financial benefits. However, discrepancies often arise between the electricity volumes committed to in trading auctions and the volumes actually consumed or injected. Solutions designed to address this issue often require access to sensitive information that should be kept private.  

This paper presents a novel, fully privacy-preserving billing protocol designed to protect users' sensitive consumption and production data in the context of billing protocols for energy trading. Leveraging advanced cryptographic techniques, including fully homomorphic encryption (FHE) and pseudorandom zero sharing (PRZS), our protocol ensures robust security and confidentiality while addressing the critical issue of managing discrepancies between promised and actual electricity volumes. The proposed protocol guarantees that users' sensitive information remains inaccessible to external parties, including the trading platform and billing server. By utilizing FHE, the protocol allows computations on encrypted data without compromising privacy, while PRZS ensures secure aggregation of individual discrepancies of each household. This combination of cryptographic primitives maintains data privacy and enhances billing accuracy, even when fluctuations in energy supply and demand occur.

We analyze real-time consumption and production data from 100 households to experimentally validate the effectiveness and efficiency of our billing model. By implementing a flexible framework compatible with any billing method, we demonstrate that our protocol can accurately compute individual bills for 100 households in approximately 0.17 seconds.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 12:41:01 +0000</pubDate>
</item>
<item>
<title>FLUENT: A Tool for Efficient Mixed-Protocol Semi-Private Function Evaluation</title>
<link>https://eprint.iacr.org/2024/1561</link>
<guid>https://eprint.iacr.org/2024/1561</guid>
<content:encoded><![CDATA[
<div> 关键词：Semi-Private Function Evaluation（SPFE）、High-Level Synthesis（HLS）、Performance Overhead、Open-Source Project、Practical Deployment

总结:本文提出了一种新型框架，旨在使非专家能够理解和实施Semi-Private Function Evaluation（SPFE），并为实际部署提供可行解决方案。该框架通过引入高阶综合（HLS）来优化开发者体验，使得工具更易于使用，相较于先前的技术，其性能提升达到了两倍之多，得益于更高效的底层构建和对查找表（LUTs）的利用。为了评估性能，文章从通信和运行时效率两个方面进行了深入分析。最后，整个实现作为开源项目发布，旨在缩小高级加密协议与工业场景实践应用之间的差距，推动SPFE技术在实际业务中的普及与应用。 <div>
In modern business to customer interactions, handling private or confidential data is essential. Private Function Evaluation (PFE) protocols ensure the privacy of both the customers' input data and the business' function evaluated on it which is often sensitive intellectual property (IP). However, fully hiding the function in PFE results in high performance overhead. Semi-Private Function Evaluation (SPFE) is a generalization of PFE to only partially hide the function, whereas specific non-critical components remain public. Our paper introduces a novel framework designed to make SPFE accessible to non-experts and practical for real-world deployments.

To achieve this, we improve on previous SPFE solutions in two aspects. 
First, we enhance the developer experience by leveraging High-Level Synthesis (HLS), making our tool more user-friendly than previous SPFE frameworks.
Second, we achieve a \(2 \times\) speedup compared to the previous state-of-the-art through more efficient underlying constructions and the usage of Lookup Tables (LUTs).

We evaluate the performance of our framework in terms of communication and runtime efficiency. Our final implementation is available as an open-source project, aiming to bridge the gap between advanced cryptographic protocols and their practical application in industry scenarios.
]]></content:encoded>
<pubDate>Fri, 04 Oct 2024 12:29:16 +0000</pubDate>
</item>
<item>
<title>Understanding Leakage in Searchable Encryption: a Quantitative Approach</title>
<link>https://eprint.iacr.org/2024/1558</link>
<guid>https://eprint.iacr.org/2024/1558</guid>
<content:encoded><![CDATA[
<div> 关键词：搜索加密、结构化加密、标准安全性、定量信息流、q-泄漏分析

总结:

本文提出了一种新型框架来量化泄漏，称之为q-泄漏分析。这一方法受到定量信息流启发，旨在评估搜索加密和结构化加密方案中的信息泄露程度。q-泄漏分析与标准安全性有着密切关联，通过此方法可以更精确地理解加密数据和查询的泄露情况。

文章指出，尽管存在不可避免的信息泄露，但一些看似无害的泄漏可能被攻击者利用，从而损害用户隐私并恢复其数据或查询，尽管这些加密方案在理论上被认为是安全的。然而，到目前为止，关于如何评估这种泄漏的研究相对较少。

为了解决这一问题，作者提出了q-泄漏分析方法，该方法能够对现有具有复杂泄漏函数的加密方案进行安全性分析。通过这种方法，可以更好地理解这些加密方案在实际应用中的安全性和隐私保护能力。

总的来说，本文通过引入q-泄漏分析框架，提供了一种新的途径来量化和评估搜索加密和结构化加密方案中的信息泄露风险，这对于加强加密系统的安全性、保护用户隐私具有重要意义。 <div>
Searchable encryption, or more generally, structured encryption, permits search over encrypted data. It is  an important cryptographic tool for securing cloud storage. The standard security notion for structured encryption mandates that a protocol leaks nothing about the data or queries, except for some allowed leakage, defined by the leakage function. This is due to the fact that some leakage  is unavoidable for efficient  schemes. Unfortunately, it was shown by numerous  works that even innocuous-looking leakage can often be exploited by attackers to undermine users' privacy and recover their queries and/or data, despite the structured encryption schemes being provably secure. Nevertheless, the standard security remains the go-to notion used to show the "security" of structured encryption schemes. While it is not likely that researchers will design practical structured encryption schemes with no leakage, it is not satisfactory that very few works study ways to assess leakage. This work proposes  a novel framework to quantify leakage. Our methodology is inspired by the quantitative information flow, and we call our method  $q$-leakage analysis. We show how $q$-leakage analysis is related to the standard security. We also demonstrate the usefulness of $q$-leakage analysis by analyzing the security of two existing schemes with complex leakage functions.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 18:46:39 +0000</pubDate>
</item>
<item>
<title>Private Laconic Oblivious Transfer with Preprocessing</title>
<link>https://eprint.iacr.org/2024/1555</link>
<guid>https://eprint.iacr.org/2024/1555</guid>
<content:encoded><![CDATA[
<div> 关键词：Laconic Cryptography、Laconic Oblivious Transfer、Preprocessing、Symmetric-key Assumptions、Online Computational Complexity

文章主要探讨了名为“Laconic Cryptography”的加密技术，该技术旨在通过两个消息协议在大量数据上进行安全计算，同时将通信成本降至最低。其中的核心概念是“Laconic Oblivious Transfer”，它允许接收方学习由选择位决定的消息，而发送方的输入包括两条消息和一个索引，这个模型在安全计算中更为实用。然而，现有的实现方法往往依赖于复杂的加密技术以及非黑盒技术，效率不高。

文章提出了一种基于对称密钥假设的私有Laconic OT（PLaOT）协议，其特点在于能够隐藏发送者的索引信息，并在预处理阶段生成所需的关联，后续的在线阶段则非常轻量级，接收方的在线计算复杂度呈亚线性增长。此外，该协议还具备可更新性和接收方隐私特性。

最后，作者展示了如何利用PLaOT协议实现RAM程序的Laconic函数评估与预处理的私有集合交集，这表明了Laconic Cryptography在实际应用中的潜力和效率提升。

总结: 这篇文章研究了一种新的加密技术Laconic Cryptography，特别关注于Laconic Oblivious Transfer的实现及其在实际应用中的潜力。通过基于对称密钥假设的方法，实现了高效、私有的Laconic OT协议，同时保持了在线阶段的计算效率，并引入了预处理功能。此外，该协议还具有可更新性和接收方隐私特性。文章还讨论了该协议在RAM程序评估和私有集合交集中的应用，展现了其在安全计算领域的广泛应用前景。 <div>
Laconic cryptography studies two-message protocols that securely compute on large amounts of data with minimal communication cost. Laconic oblivious transfer (OT) is a central primitive where the receiver's input is a large database $\mathsf{DB}$ and the sender's inputs are two messages $m_0$, $m_1$ along with an index $i$, such that the receiver learns the message determined by the choice bit $\mathsf{DB}_i$. OT becomes even more useful for secure computation when considering its laconic variants, which offer succinctness and round optimality. However, existing constructions are not practically efficient because they rely on heavy cryptographic machinery and non-black-box techniques. 

In this work, we initiate the study of laconic OT correlations, where the model allows an offline phase to generate the correlations later used in a lightweight online phase. Our correlation is conceptually simple, captured by an inner product computation, and enables us to achieve a private laconic OT protocol where the sender's index $i$ is also hidden from the receiver. Our construction is the first private laconic OT with database-dependent preprocessing based solely on symmetric-key assumptions, achieving sublinear online computational complexity for the receiver. Furthermore, we enhance our construction with updatability and receiver privacy. Finally, we demonstrate the applications of private laconic OT to laconic function evaluation for RAM programs and laconic private set intersection with preprocessing.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 17:07:53 +0000</pubDate>
</item>
<item>
<title>Application-Aware Approximate Homomorphic Encryption: Configuring FHE for Practical Use</title>
<link>https://eprint.iacr.org/2024/203</link>
<guid>https://eprint.iacr.org/2024/203</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、Cheon-Kim-Kim-Song（CKKS）方案、隐私保护机器学习、应用感知同态加密、安全性定义

总结：

文章主要讨论了全同态加密（FHE）中的一个具体实现——基于Cheon-Kim-Kim-Song（CKKS）方案的同态加密技术，特别是在处理实数和复数时的应用。该方案为许多隐私保护机器学习应用提供了高效计算能力。然而，随着Li和Micciancio在EUROCRYPT'21中发现的针对$IND-CPA^D$设置的秘密密钥恢复攻击，现有关于如何安全地为特定应用实例化该方案的理解变得模糊。

为了澄清这一混乱，文章引入了“应用感知同态加密”概念，并提出相关安全定义，这些定义更符合同态加密方案的实际实施和应用方式。同时，文章还制定了实施应用感知同态加密模型以达到$IND-CPA^D$安全性的指导原则，适用于CKKS的实际应用。此外，文章表明应用感知模型不仅适用于CKKS方案，还能用于安全、高效地实例化精确同态加密方案。

通过上述措施，文章旨在提供一个更为明确和实用的框架，以确保在实际应用中正确和安全地使用FHE技术，特别是在面对复杂的安全挑战时。 <div>
Fully Homomorphic Encryption (FHE) is a powerful tool for performing privacy-preserving analytics over encrypted data. A promising method for FHE over real and complex numbers is approximate homomorphic encryption, instantiated with the Cheon-Kim-Kim-Song (CKKS) scheme. The CKKS scheme enables efficient evaluation for many privacy-preserving machine learning applications. While the efficiency advantages of CKKS are clear, there is currently a lot of confusion on how to securely instantiate the scheme for any given application, especially after secret-key recovery attacks were discovered by Li and Micciancio (EUROCRYPT'21) for the $IND-CPA^D$ setting, i.e., where decryption results are shared with other parties. On the one hand, the generic definition of $IND-CPA^D$ is application-agnostic and often requires impractically large parameters. On the other hand, practical CKKS implementations target specific applications and use tighter parameters. A good illustration are the recent secret-key recovery attacks against a CKKS implementation in the OpenFHE library by Guo et al. (USENIX Security'24). These attacks misuse the library by employing different circuits during parameter estimation and run-time computation, yet they do not violate the generic (application-agnostic) $IND-CPA^D$ definition.

To address this confusion, we introduce the notion of application-aware homomorphic encryption and devise related security definitions, which correspond more closely to how homomorphic encryption schemes are implemented and used in practice. We then formulate the guidelines for implementing the application-aware homomorphic encryption model to achieve $IND-CPA^D$ security for practical applications of CKKS. We also show that our application-aware model can be used for secure, efficient instantiation of exact homomorphic encryption schemes.
]]></content:encoded>
<pubDate>Fri, 09 Feb 2024 20:24:14 +0000</pubDate>
</item>
<item>
<title>Revisiting Keyed-Verification Anonymous Credentials</title>
<link>https://eprint.iacr.org/2024/1552</link>
<guid>https://eprint.iacr.org/2024/1552</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名认证、CMZ、BBDT、BBS RFC、非交互式证明

文章主要探讨了两种关键的匿名认证系统——Chase等人的CMZ（或PS MAC）和Barki等人的BBDT（或BBS MAC）。作者提出了一种方法使CMZ具有统计匿名性，并使BBDT与BBS RFC草案兼容。他们对这些系统的安全性进行了全面分析，包括更强的不可伪造性和匿名性的属性。这使得用户可以根据需要选择组合这些属性。

为了加速复杂证明的速度，文章中提供了一个编译器，该编译器使用交互式Oracle证明和指定验证者多项式承诺来构建指定验证者的非交互式论证。对于基于密钥验证的匿名认证，指定验证者证明就足够了，因为验证者的身份在预先已知。

文章还讨论了可能从这种方法受益的扩展，例如那些需要快速证明的复杂情况。

总结：
文章重新审视了两种主流的匿名认证系统，即CMZ（PS MAC）和BBDT（BBS MAC），并提出了使其更安全和兼容的技术改进。通过构建一个专门的编译器，提高了复杂证明的处理速度，同时确保了系统的匿名性和不可伪造性。这种方法不仅增强了原有系统的安全性，还提供了更多的灵活性，允许用户根据实际需求定制认证流程。此外，该技术还能应用于其他需要快速证明验证的情况，进一步扩大了其应用范围。 <div>
Keyed-verification anonymous credentials are widely recognized as among the most efficient tools for anonymous authentication. In this work, we revisit two prominent credential systems: the scheme by Chase et al. (CCS 2014), commonly referred to as CMZ or PS MAC, and the scheme by Barki et al. (SAC 2016), known as BBDT or BBS MAC. We show how to make CMZ statistically anonymous and BBDT compatible with the BBS RFC draft. We provide a comprehensive security analysis for strong(er) properties of unforgeability and anonymity. These properties allow them to be composed with extensions that users can pick and choose.  We show that simpler variants satisfying one-more unforgeability can still be anonymous tokens (Kreuter et al., CRYPTO 2020).

To enable faster proofs for complex presentations, we present a compiler that uses an interactive oracle proof and a designated-verifier polynomial commitment to construct a designated-verifier non-interactive argument. For keyed-verification anonymous credentials, designated-verifier proofs suffice since the verifier is known in advance. We explore extensions that could benefit from this approach.
]]></content:encoded>
<pubDate>Thu, 03 Oct 2024 15:37:29 +0000</pubDate>
</item>
<item>
<title>PoUDR: Proof of Unified Data Retrieval in Decentralized Storage Networks</title>
<link>https://eprint.iacr.org/2024/1544</link>
<guid>https://eprint.iacr.org/2024/1544</guid>
<content:encoded><![CDATA[
<div> 关键词：IPFS、Filecoin、Proof of Unified Data Retrieval（PoUDR）、ZK-SNARK、Secure Swarming Data Exchange（SSDE）

总结:

本文探讨了去中心化存储网络中数据检索支付机制的缺失，并提出了解决方案——Proof of Unified Data Retrieval（PoUDR）协议。PoUDR通过整合零知识证明（ZK-SNARK）技术，旨在实现数据交换过程中的公平性和效率性。该协议显著减少了区块链交易的数量，无论是单个块还是数据簇检索，只需要提供方在特定时间框架内提交一次密钥揭示交易即可。

为了进一步优化交易数量，PoUDR采用了提供方侧的批处理证明技术，使得在数据由多个提供者提供、被多个查询者请求的情况下，仅需N_P次交易，而非N_P*N_Q次。这极大地提高了经济效率和可扩展性。

此外，文章详细定义了安全集群数据交换（SSDE），并提供了基于游戏的安全分析。通过将PoUDR集成到Bitswap协议（IPFS的一部分），实现了一种名为Relaxed Groth16的算法，该算法解决了生成零知识证明的重大技术挑战，有效降低了整体成本，为去中心化存储网络中的安全数据检索提供了可行解决方案。 <div>
Decentralized storage networks, including IPFS and Filecoin, have created a marketplace where individuals exchange storage space for profit. These networks employ protocols that reliably ensure data storage providers accurately store data without alterations, safeguarding the interests of storage purchasers. However, these protocols lack an effective and equitable payment mechanism for data retrieval, particularly when multiple data queriers are involved. This necessitates a protocol that ensures both data integrity and fair compensation for data providers.

In decentralized storage, data is fragmented into small blocks and stored across multiple nodes, a process known as data swarming. Due to this property, traditional data exchange protocols are inadequate in terms of communication and economic efficiency.

We propose the Proof of Unified Data Retrieval protocol (PoUDR). PoUDR incorporates ZK-SNARK to facilitate a fair data exchange protocol. PoUDR reduces the number of blockchain transactions for both single block and data swarming retrieval. The protocol requires only a single key-revealing transaction submitted by the provider to the blockchain for each data block. This architecture allows for further optimization of transaction numbers through a batched proof technique on the provider's side.  This approach necessitates only $N_P$ transactions within a specific time frame when data consisting of $N_D$ blocks, provided by $N_P$ providers, is queried by $N_Q$ queriers.

This work provides a comprehensive definition for Secure Swarming Data Exchange (SSDE), including security assumptions. Also it offers a detailed game-based security analysis for the PoUDR protocol. Moreover, the PoUDR protocol has been fully integrated into the Bitswap protocol (IPFS). Within this integration, our proposed Relaxed Groth16 algorithm addresses the significant technical challenge of generating zero-knowledge proofs, leading to substantial cost reductions for overall feasibility of secure data retrieval in decentralized storage networks.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 22:42:26 +0000</pubDate>
</item>
<item>
<title>HEonGPU: a GPU-based Fully Homomorphic Encryption Library 1.0</title>
<link>https://eprint.iacr.org/2024/1543</link>
<guid>https://eprint.iacr.org/2024/1543</guid>
<content:encoded><![CDATA[
<div> 关键词：HEonGPU、高效率、全同态加密、图形处理单元、多流架构

总结:

HEonGPU是一种旨在优化全同态加密(FHE)操作在图形处理器(GPU)上的性能的高级库。它通过利用GPU的并行处理能力显著减少了与FHE相关的计算开销，允许对加密数据执行更快速的同态计算。这种能力特别适用于隐私保护机器学习和安全数据处理的实时应用。HEonGPU的关键优势在于其多流架构，不仅能够实现任务的并行处理以提高吞吐量，还能消除主机设备（即CPU）与GPU之间的数据传输开销。通过在GPU内部高效管理数据，多流架构减少了重复内存传输的需求，进一步提高了性能。针对各种FHE方案，HEonGPU的GPU优化设计使其非常适合大规模加密计算，为用户提供更低的延迟和更高的性能。 <div>
HEonGPU is a high-performance library designed to optimize Fully Homomorphic Encryption (FHE) operations on Graphics Processing Unit (GPU). By leveraging the parallel processing capac- ity of GPUs, HEonGPU significantly reduces the computational overhead typically associated with FHE by executing complex operation concurrently. This allows for faster execution of homomorphic computations on encrypted data, enabling real-time applications in privacy-preserving machine learn- ing and secure data processing. A key advantage of HEonGPU lies in its multi-stream architecture, which not only allows parallel processing of tasks to improve throughput but also eliminates the over- head of data transfers between the host device (i.e., CPU) and GPU. By efficiently managing data within the GPU using multi-streams, HEonGPU minimizes the need for repeated memory transfers, further enhancing performance. HEonGPU’s GPU-optimized design makes it ideal for large-scale encrypted computations, providing users with reduced latency and higher performance across various FHE schemes.
]]></content:encoded>
<pubDate>Wed, 02 Oct 2024 22:05:03 +0000</pubDate>
</item>
<item>
<title>More Efficient Lattice-based OLE from Circuit-private Linear HE with Polynomial Overhead</title>
<link>https://eprint.iacr.org/2024/1534</link>
<guid>https://eprint.iacr.org/2024/1534</guid>
<content:encoded><![CDATA[
<div> 关键词：电路隐私、线性同态加密、半诚实模型、零知识证明、主动安全性

总结:
文章提出了一种新的方法，用于获得基于格的线性同态加密的电路隐私，该方法避免了使用指数级大错误的噪声泛滥或迭代重启动。这种方法直接导致了一个半诚实盲线性评估(OLE)协议，其效率显著提高，将前代最佳通信成本减少了50%。在100Mbps网络环境下，我们的协议的平均时间改进了前工作33%。我们的半诚实OLE首次实现了同时的高效率和近最优的渐进性。通过结合最近的零知识证明的密文知识，我们的LHE提供了一个比前作通信量减少2.7倍的主动安全OLE。当应用于Overdrive（Eurocrypt '18）这一预处理协议时，我们的方法在通信上提供了相对于现状1.4倍的改进。

文章的核心贡献在于提出了一种高效且无需复杂计算步骤的方法来实现电路隐私，从而显著提高了OLE协议的效率，特别是通信成本的大幅降低。同时，该方法还扩展了零知识证明技术的应用，使得OLE协议在保证安全性的同时，也能达到较高的通信效率。在实际应用中，这种方法被证明能有效提升MPC预处理协议的通信效率，展现出在现代密码学领域的广泛潜力与应用价值。 <div>
We present a new and efficient method to obtain circuit privacy for lattice-based linearly homomorphic encryptions (LHE). In particular, our method does not involve noise-flooding with exponetially large errors or iterative bootstrapping. As a direct result, we obtain a semi-honest oblivious linear evaluation (OLE) protocol with the same efficiency, reducing the communication cost of the prior state of the art by 50%. 
Consequently, the amortized time of our protocol improves the prior work by 33% under 100Mbps network setting. Our semi-honest OLE is the first to achieve both concrete efficiency and asymptotic quasi-optimality. Together with an extension of the recent zero-knowledge proof of plaintext knowledge, our LHE yields actively-secure OLE with 2.7x reduced communication from the prior work. When applied to Overdrive (Eurocrypt '18), an MPC preprocessing protocol, our method provides 1.4x improvement in communication over the state of the art.
]]></content:encoded>
<pubDate>Tue, 01 Oct 2024 08:11:22 +0000</pubDate>
</item>
<item>
<title>BEAT-MEV: Epochless Approach to Batched Threshold Encryption for MEV Prevention</title>
<link>https://eprint.iacr.org/2024/1533</link>
<guid>https://eprint.iacr.org/2024/1533</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized Finance（DeFi）、Batched Threshold Encryption（BTE）、Market Manipulation、Miner Extractable Value（MEV）、Privacy Concerns

总结:

本文探讨了去中心化金融（DeFi）中公开待处理交易带来的隐私问题及其对市场操纵的影响，特别是通过矿工可提取价值（MEV）所引发的潜在风险。研究指出，当区块提议者利用重新排序、省略或添加交易的能力时，用户可能会遭受由抢先交易导致的经济损失。近期的研究方向集中在加密待处理交易上，以隐藏交易数据直至区块最终确定。

Choudhuri等人提出了一个名为Batched Threshold Encryption（BTE）的新原始概念，它允许一个委员会选择一批加密交易，并在区块最终确定后才进行解密。BTE实现了低通信复杂度的解密过程，并确保了未被选入批次的所有加密交易的隐私性。然而，其存在需要昂贵的MPC设置来为每批解密过程创建的局限性。

本文提出了一种新颖的BTE方案，解决了上述限制，无需昂贵的周期性设置即可实现实用的加密和解密时间（分别小于2ms和440ms，对于512笔交易）。此外，文章还探索了用户如何协调其交易的问题，这对于系统功能至关重要。在过程中，文章提供了多项优化和复杂度之间的权衡策略，以实现标准硬件上的实用性能。最后，证明了构建方案的安全性，涵盖了对MEV预防机制的实际攻击模型。 <div>
In decentralized finance (DeFi), the public availability of pending transactions presents significant privacy concerns, enabling market manipulation through miner extractable value (MEV). MEV occurs when block proposers exploit the ability to reorder, omit, or include transactions, causing financial loss to users from frontrunning. Recent research has focused on encrypting pending transactions, hiding transaction data until block finalization. To this end, Choudhuri et al. (USENIX '24) introduce an elegant new primitive called Batched Threshold Encryption (BTE) where a batch of encrypted transactions is selected by a committee and only decrypted after block finalization. Crucially,  BTE achieves low communication complexity during decryption and guarantees that all encrypted transactions outside the batch remain private. An important shortcoming of their construction is, however, that it progresses in epochs and requires a costly setup in MPC for each batch decryption.
    In this work, we introduce a novel BTE scheme addressing the limitations by eliminating the need for an expensive epoch setup while achieving practical encryption and decryption times. Additionally, we explore the problem of how users can coordinate their transactions, which is crucial for the functionality of the system. Along the way, we present several optimizations and trade-offs between communication and computational complexity that allow us to achieve practical performance on standard hardware ($<2$ ms for encryption and $<440$ ms for decrypting $512$ transactions). Finally, we prove our constructions secure in a model that captures practical attacks on MEV-prevention mechanisms.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 21:36:16 +0000</pubDate>
</item>
<item>
<title>Folding Schemes with Privacy Preserving Selective Verification</title>
<link>https://eprint.iacr.org/2024/1530</link>
<guid>https://eprint.iacr.org/2024/1530</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、折叠方案、隐私保护、陈述隐藏、验证成本

总结: 

文章主要探讨了折叠方案这一新颖的理论，它将执行多个关于相同关系的零知识证明任务简化为一次零知识证明和若干低成本的包含证明。近期，折叠方案被用于减轻向多个独立验证者证明不同陈述的成本问题，这在多种应用中展现出潜力。然而，当一起证明的陈述信息可能泄露时，这种设计可能会引起安全问题。

为解决此问题，作者提出了隐私保护折叠方案的概念及其所需的安全性定义。隐私保护折叠方案旨在确保在证明过程中不泄露任何有关被合并陈述的信息。为了构建此类方案，作者引入了“陈述隐藏”这一概念，它允许将一个关系实例隐秘地表示为另一个关系实例，同时保持其真实性的验证。通过结合现有折叠方案和“陈述隐藏”的技术，可以构造出既能降低验证成本又具备隐私保护功能的方案。该方案首先对每个需要证明的陈述进行隐藏，然后利用折叠方案验证这些隐藏的陈述是否正确地合并到其他声明中。 <div>
Folding schemes are an exciting new primitive, transforming the task of performing multiple zero-knowledge proofs of knowledge for a relation into performing just one zero-knowledge proof, for the same relation, and a number of cheap inclusion-proofs. Recently, folding schemes have been used to amortize the cost associated with proving different statements to multiple distinct verifiers, which has various applications. We observe that for these uses, leaking information about the statements folded together can be problematic, yet this happens with previous constructions. Towards resolving this issue, we give a natural definition of privacy preserving folding schemes, and what security they should offer. To construct privacy preserving folding schemes, we first define a statement hiders, a primitive which might be of independent interest. In a nutshell, a statement hider hides an instance of a relation as a new instance in the same relation. The new instance is in the relation if and only if the initial instance is. With this building block, we can utilize existing folding schemes to construct a privacy preserving folding scheme, by first hiding each of the statements. Folding schemes allow verifying that a statement was folded into another statement, while statement hiders allow verifying that a statement was hidden as another statement.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 10:49:25 +0000</pubDate>
</item>
<item>
<title>Challenges in Timed Cryptography: A Position Paper</title>
<link>https://eprint.iacr.org/2024/1529</link>
<guid>https://eprint.iacr.org/2024/1529</guid>
<content:encoded><![CDATA[
<div> 关键词：时间锁谜题、理想化、分析技术、陷阱门函数、模拟器

总结:

本文探讨了时间锁谜题这一领域，该领域涉及使用计算复杂性来在一段时间后解锁信息。文章指出，尽管该领域已有超过25年的历史，但其基础并未得到充分理解。当前的分析技术在构建包含过期安全性的组件时缺乏稳固机制，特别是在多方协议中。此外，现有分析常常依赖于对理想化和模拟器进行不切实际计算能力的理想化假设。

文章首先指出了现有尝试存在的问题，包括缺乏可组合性、不一致的分析或功能限制。这些缺陷最终归结为Mahmoody等人的一项不可能性结果，即无法仅通过随机或acles构建具有超多项式差距的时间锁谜题。然而，当前对代数谜题的分析仍假定每一步都是通用或随机或acles。文章指出，如果生成过程依赖于不能被视为随机或acles的陷阱门函数（以允许高效生成并避免上述不可能性结果），那么在分析求解过程时，也应不将此类陷阱门函数及其中间状态视为随机或acles。

文章还讨论了时间锁谜题证明技术中的其他问题，特别是当谜题需要保密一段时间时，减少应限制模拟器的运行时间。它评估了各种尝试对这一原则的遵守情况以及它们在组合方面的实现程度。文章强调了现有框架在构建包含过期安全性的复合多方协议时的局限性和潜在挑战，并提出了解决这些问题的可能方向。 <div>
Time-lock puzzles are unique cryptographic primitives that use computational complexity to keep information secret for some period of time, after which security expires. This topic, while over 25 years old, is still in a state where foundations are not well understood: For example, current analysis techniques of time-lock primitives provide no sound mechanism to build composed multi-party cryptographic protocols which use expiring security as a building block. Further, there are analyses that employ idealizations and simulators of unrealistic computational power to be an acceptable sound security argument. Our goal with this short paper is to advocate for understanding what approaches may lead to sound modeling beyond idealization, and what approaches may, in fact, be hopeless at this task of sound modeling. 

We explain in this paper how existing  attempts at this subtle problem lack either composability, a fully consistent analysis, or functionality. The subtle flaws in the existing frameworks reduce to an impossibility result by Mahmoody et al., who showed that time-lock puzzles with super-polynomial gaps (between committer and solver) cannot be constructed from random oracles alone (or any repetitive computation where the next state is completely random given the prior state); yet still the analyses of algebraic puzzles today treat the solving process as if each step is a generic or random oracle. We point out that if the generation process relies on a trapdoor function that cannot be treated as a random oracle (to allow efficient generation while avoiding this impossibility result), then, to be consistent, the analysis of the solving process should also not treat such a trapdoor function (and its intermediate states) as a random oracle. 

We also delineate additional issues with the proof techniques used for time-lock puzzles. Specifically, when a time-lock puzzle must retain privacy for some amount of time, the reduction should bound the running time of the simulator. A simulator that can ``simulate" if given time that if given to an adversary allows said adversary to solve the puzzle is not a valid security argument. We survey the adherence of various attempts to this principle, as well as the properties that different attempts achieve toward composition.
]]></content:encoded>
<pubDate>Mon, 30 Sep 2024 02:01:32 +0000</pubDate>
</item>
<item>
<title>FANNG-MPC: Framework for Artificial Neural Networks and Generic MPC</title>
<link>https://eprint.iacr.org/2023/1918</link>
<guid>https://eprint.iacr.org/2023/1918</guid>
<content:encoded><![CDATA[
<div> 关键词：FANNG-MPC、安全多方计算、主动安全性、机器学习即服务、隐私保护

总结:

本文介绍了一种名为FANNG-MPC的灵活安全多方计算框架，该框架为隐私保护的机器学习即服务(MLaaS)提供了主动安全性。FANNG-MPC是从已废弃的SCALE-MAMBA衍生而来的一个数据导向型分支，它集成了新的库和指令，用于实现私密神经网络，有效地复活了流行框架。与SCALE-MAMBA不同的是，FANNG-MPC解耦了离线和在线阶段，并在软件中实现了经销商模型，允许一组独立实体生成离线材料。框架还支持数据库功能，引入了预处理材料的新指令集，包括门控电路和卷积及矩阵乘法三元组。此外，FANNG-MPC还实现了新型私有比较协议和优化的神经网络功能库。通过开源实现，文章详细评估了使用LeNet和VGG16等流行神经网络进行私人推理的效果。这是首个在不诚实多数设置下提供活跃安全性的MPC框架，对隐私保护机器学习领域具有重要意义。 <div>
In this work, we introduce FANNG-MPC, a versatile secure multi-party computation framework capable to offer active security for privacy preserving machine learning as a service (MLaaS). Derived from the now deprecated SCALE-MAMBA, FANNG is a data-oriented fork, featuring novel set of libraries and instructions for realizing private neural networks, effectively reviving the popular framework. To the best of our knowledge, FANNG is the first MPC framework to offer actively secure MLaaS in the dishonest majority setting.

FANNG goes beyond SCALE-MAMBA by decoupling offline and online phases and materializing the dealer model in software, enabling a separate set of entities to produce offline material. The framework incorporates database support, a new instruction set for pre-processed material, including garbled circuits and convolutional and matrix multiplication triples. FANNG also implements novel private comparison protocols and an optimized library supporting Neural Network functionality. All our theoretical claims are substantiated by an extensive evaluation using an open-sourced implementation, including the private inference of popular neural networks like LeNet and VGG16.
]]></content:encoded>
<pubDate>Thu, 14 Dec 2023 13:21:42 +0000</pubDate>
</item>
<item>
<title>Instance-Hiding Interactive Proofs</title>
<link>https://eprint.iacr.org/2024/776</link>
<guid>https://eprint.iacr.org/2024/776</guid>
<content:encoded><![CDATA[
<div> 关键词：Instance-Hiding Interactive Proof、平均难度语言、One-Way Functions、随机编码、复合

文章总结：

文章主要探讨了Instance-Hiding Interactive Proof（IHIP）这一概念及其性质和应用。IHIP是一种交互证明系统，其中验证者与不受限制的证明者进行交互以确定输入x是否属于语言L，同时保证证明者无法获取任何关于x的信息。以下是文章的关键发现：

1. **IHIP与复杂性类的关系**：任何具有IHIP的语言都位于NP/poly和coNP/poly之间，这意味着它们可以在多项式时间内验证。

2. **IHIP与One-Way Functions的关系**：如果存在一个平均难度语言具有IHIP，则可以证明One-Way Functions的存在。这表明IHIP在密码学中具有重要意义。

3. **IHIP与随机编码的关系**：IHIP可以视为随机编码概念的一种推广，它提供了一种新的方式来保护数据隐私。

4. **IHIP的封闭性**：IHIP具有封闭性，即它们可以通过与任何可有效计算的函数复合而保持其性质。

5. **Simulatable IHIP的增强特性**：对于一种更强大的IHIP版本（称为Simulatable IHIP），证明者的视角可以被有效模拟。这导致了更严格的复杂性分类结果，如任何具有Simulatable IHIP的语言都位于AM和coAM之间。

6. **最坏情况下的难度与One-Way Functions**：如果存在一个最坏情况下的硬语言具有Simulatable IHIP，则可以证明One-Way Functions的存在，进一步强调了IHIP在理论计算机科学中的重要性。

通过这些发现，文章深入探讨了IHIP在复杂性理论、密码学和计算理论中的角色和潜力，为理解交互证明系统的性质提供了新的视角。 <div>
In an Instance-Hiding Interactive Proof (IHIP) [Beaver et al. CRYPTO 90], an efficient verifier with a _private_ input x interacts with an unbounded prover to determine whether x is contained in a language L. In addition to completeness and soundness, the instance-hiding property requires that the prover should not learn anything about x in the course of the interaction. Such proof systems capture natural privacy properties, and may be seen as a generalization of the influential concept of Randomized Encodings [Ishai et al. FOCS 00, Applebaum et al. FOCS 04, Agrawal et al. ICALP 15], and as a counterpart to Zero-Knowledge proofs [Goldwasser et al. STOC 89]. 

We investigate the properties and power of such instance-hiding proofs, and show the following:
1. Any language with an IHIP is contained in NP/poly and coNP/poly.
2. If an average-case hard language has an IHIP, then One-Way Functions exist.
3. There is an oracle with respect to which there is a language that has an IHIP but not an SZK proof.
4. IHIP's are closed under composition with any efficiently computable function.

We further study a stronger version of IHIP (that we call Simulatable IHIP) where the view of the honest prover can be efficiently simulated. For these, we obtain stronger versions of some of the above:
5. Any language with a Simulatable IHIP is contained in AM and coAM.
6. If a _worst-case_ hard language has a Simulatable IHIP, then One-Way Functions exist.
]]></content:encoded>
<pubDate>Tue, 21 May 2024 07:55:56 +0000</pubDate>
</item>
<item>
<title>Overpass Channels: Horizontally Scalable, Privacy-Enhanced, with Independent Verification, Fluid Liquidity, and Robust Censorship Proof, Payments</title>
<link>https://eprint.iacr.org/2024/1526</link>
<guid>https://eprint.iacr.org/2024/1526</guid>
<content:encoded><![CDATA[
<div> 关键词：Overpass Channels、区块链、零知识证明、横向扩展、隐私保护

总结:

文章介绍了Overpass Channels这一创新的区块链技术，其主要特点包括：1) 横向扩展性，实现更高的交易处理能力；2) 隐私增强支付网络，通过零知识证明确保交易的匿名性和安全性；3) 独立验证机制，提高系统的透明度和信任度；4) 流动性与去中心化，确保资金高效流通同时保持网络的分散性；5) 抗审查能力，抵抗外部干预，保护用户权益。

Overpass Channels采用零知识证明（特别是zk-SNARKs）技术，以替代传统的共识机制和矿工角色，从而实现更低的成本和能源消耗。系统设计围绕单边支付通道和离链交易处理，保证高速、低延迟的操作，同时不牺牲安全性和去中心化特性。该技术的应用范围广泛，不仅限于全球支付，还涵盖了机密投票、安全健康记录管理等多元领域。通过这种创新架构，Overpass Channels旨在提供一个更高效、更安全、更私密的区块链解决方案。 <div>
Overpass Channels presents a groundbreaking approach to blockchain scalability, offering a horizontally scalable, privacy-enhanced payment network with independent verification, fluid liquidity, and robust censorship resistance. This paper introduces a novel architecture that leverages zero-knowledge proofs, specifically zk-SNARKs, to ensure transaction validity and privacy while enabling unprecedented throughput and efficiency. 
By eliminating the need for traditional consensus mechanisms and miners, Overpass Channels achieves remarkable cost-effectiveness and energy efficiency. The system's design focuses on unilateral payment channels and off-chain transaction processing, allowing for high-speed, low-latency operations without compromising security or decentralization. This paper provides a comprehensive analysis of the Overpass Channels system, including its cryptographic foundations, scalability metrics, integration, and potential applications across various domains, from global payments to confidential voting systems and secure health record management.
]]></content:encoded>
<pubDate>Sat, 28 Sep 2024 17:20:13 +0000</pubDate>
</item>
<item>
<title>DUPLEX: Scalable Zero-Knowledge Lookup Arguments over RSA Group</title>
<link>https://eprint.iacr.org/2024/1509</link>
<guid>https://eprint.iacr.org/2024/1509</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、查找论证、RSA组、可扩展性、隐私保护

总结:本文提出了一种名为$\duplex$的新颖零知识查找论证方案，旨在解决大规模查找元素向量在SNARK中的应用问题。$\duplex$具有多项显著优势：

1. **高效性**：对于$m$个查找元素，其证明时间仅为$O(m\log m)$，且证明大小固定，验证过程快速，无需依赖表大小。

2. **适应性**：$\duplex$首次支持在RSA组上进行查找操作，通过将元素转换为质数，确保了与RSA组的兼容性，同时保持了较低的计算成本。

3. **安全性**：该方案确保了查找元素的隐私性，即使在动态更新表的情况下，也能有效保护信息不被泄露。

4. **实用性**：$\duplex$在实际应用中表现出色，相比于当前最先进的查找论证Caulk，其证明时间明显缩短，同时保持了合理的证明大小和验证速度。

5. **可扩展性**：$\duplex$的设计使其非常适合于大规模、隐私敏感的计算验证场景，提高了可扩展性和实用性。

通过这些特点，$\duplex$为SNARK在处理非算术运算如批量范围检查或位操作等任务提供了更为高效、安全和实用的解决方案。 <div>
Lookup arguments enable a prover to convince a verifier that a committed vector of lookup elements $\vec{f} \in \mathbb{F}^m$ is contained within a predefined table $T \in \mathbb{F}^N$. These arguments are particularly beneficial for enhancing the performance of SNARKs in handling non-arithmetic operations, such as batched range checks or bitwise operations. While existing works have achieved efficient and succinct lookup arguments, challenges remain, particularly when dealing with large vectors of lookup elements in privacy-sensitive applications.

In this paper, we introduce $\duplex$, a scalable zero-knowledge lookup argument scheme that offers significant improvements over previous approaches. Notably, we present the first lookup argument designed to operate over the RSA group. Our core technique allows for the transformation of elements into prime numbers to ensure compatibility with the RSA group, all without imposing substantial computational costs on the prover. Given $m$ lookup elements, $\duplex$ achieves an asymptotic proving time of $O(m \log m)$, with constant-sized proofs, constant-time verification, and a public parameter size independent of the table size $N$. Additionally, $\duplex$ ensures the privacy of lookup elements and is robust against dynamic table updates, making it highly suitable for scalable verifiable computation in real-world applications.

We implemented and empirically evaluated $\duplex$, comparing it with the state-of-the-art zero-knowledge lookup argument Caulk [CCS'22]. Our experimental results demonstrate that $\duplex$ significantly outperforms Caulk in proving time for both single and batched lookup arguments, while maintaining practical proof size and verification time.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 04:48:02 +0000</pubDate>
</item>
<item>
<title>Evaluating Leakage Attacks Against Relational Encrypted Search</title>
<link>https://eprint.iacr.org/2024/1525</link>
<guid>https://eprint.iacr.org/2024/1525</guid>
<content:encoded><![CDATA[
<div> 关键词：加密搜索算法、数据泄漏、隐私保护、安全存储、查询执行

总结:

本文探讨了加密搜索算法（ESAs）在关系数据库场景中的适用性，以及主要的数据泄漏攻击在这一背景下的应用。ESAs允许用户对敏感数据进行加密存储并远程访问，同时保持对关键词或查询的搜索能力，从而保护隐私和确保数据安全。

1. **数据泄漏与攻击**: 原有ESAs在文档和关键词搜索中应用时，存在一定程度的信息泄露问题。这些信息泄露被用于辅助攻击者获取关于明文的额外信息。然而，大多数针对泄漏攻击的研究集中在关键词ESAs上，而非关系型ESAs。

2. **攻击适应性**: 作者对主要的泄漏攻击进行了重新评估，以适应关系型ESAs环境，并在不同特性的关系型数据集上进行了广泛测试。

3. **攻击效果差异**: 实验结果表明，这些主要的攻击方法在已知数据设置下确实可以有效作用于关系型ESAs。但攻击性能在不同的数据集、利用的模式和攻击方法之间存在显著差异。

4. **数据集特性影响**: 不同属性的数据集对攻击效果产生了显著影响，说明了在实际应用中需要考虑数据集的具体特性来评估安全性和隐私保护水平。

5. **结论与展望**: 该研究揭示了关系型ESAs面临的数据泄漏风险，并强调了对这类系统进行针对性安全性评估的重要性。未来工作可能包括开发更有效的防御策略、改进ESAs设计以减少泄漏，以及进一步探索针对关系型数据的新型攻击和防御机制。 <div>
Encrypted Search Algorithms (ESAs) are a technique to encrypt data while the user can still search over it. ESAs can protect privacy and ensure security of sensitive data stored on a remote storage. Originally, ESAs were used in the context of documents that consist of keywords. The user encrypts the documents, sends them to a remote server and is still able to search for keywords, without exposing information about the plaintext. The idea of ESAs has also been applied to relational databases, where queries (similar to SQL statements) can be privately executed on an encrypted database.But just as traditional schemes for Keyword-ESAs, also Relational-ESAs have the drawback of exposing some information, called leakage. Leakage attacks have been proposed in the literature that use this information together with auxiliary information to learn details about the plaintext. However, these leakage attacks have overwhelmingly been designed for and applied to Keyword-ESAs and not Relational-ESAs.
In this work, we review the suitability of major leakage attacks against ESAs in the relational setting by adapting them accordingly. We perform extensive re-evaluations of the attacks on various relational datasets with different properties.
Our evaluations show that major attacks can work against Relational-ESAs in the known-data setting. However, the attack performance differs between datasets, exploited patterns, and attacks.
]]></content:encoded>
<pubDate>Sat, 28 Sep 2024 13:36:29 +0000</pubDate>
</item>
<item>
<title>Functional Adaptor Signatures: Beyond All-or-Nothing Blockchain-based Payments</title>
<link>https://eprint.iacr.org/2024/1523</link>
<guid>https://eprint.iacr.org/2024/1523</guid>
<content:encoded><![CDATA[
<div> 关键词：Web3系统、智能合约、适配签名、功能加密、公平信息销售

总结:
本文聚焦于在Web3系统的信任无界环境中，如何实现敏感数据的公平功能性销售。主要讨论了两种解决方案：基于智能合约的方法和依赖适配签名的技术。前者提供了原子交易，允许买家仅获取函数$f(x)$的结果而无法完全访问原始数据$x$，但存在效率低、成本高、隐私保护不足和与非智能合约系统兼容性差的问题。后者解决了上述问题，但买家可以完全提取$x$，不支持对敏感数据的功能性提取。

为解决这些局限，文章提出了一种新的加密原语——功能适配签名（FAS）。FAS允许卖家发布承诺$x$的广告，买家预签支付交易关于函数$f$，并将该预签发送给卖家。卖家将预签适应为有效的买家签名，然后在区块链上发布支付和适应后的签名以获得付款。最后，买家使用预签和发布的签名高效提取$f(x)$，完成交易。

文章详细阐述了FAS的安全属性，包括一种名为见证隐私的新概念，旨在保护卖家的隐私，确保买家仅学习到$f(x)$，而不会了解更多关于$x$的信息。文章提出了不同级别的见证隐私概念，如见证隐藏、见证不可区分性和零知识，以捕捉恶意买家可能获取的关于$x$的额外信息量。

文章还介绍了两种支持线性函数（如统计/聚合、机器学习中的核等）的FAS高效构造，这些构造满足最强的见证隐私概念。一种基于素数阶群的构造兼容Schnorr签名用于支付，另一种基于格的构造兼容Lyubashevsky签名方案的变体。文章的主要理论贡献在于揭示了功能加密与适配签名之间意想不到的联系，以及通过使用特定安全增强技术的内积功能加密（IPFE）的黑盒方式来避免复杂的加密工具，从而实现改进的效率。文章还展示了FAS构造在Schnorr签名上的实现，证明即使对于大小适度的卖家证词，不同操作也相当高效，即使是普通硬件也能胜任。 <div>
In scenarios where a seller holds sensitive data $x$, like employee / patient records or ecological data, and a buyer seeks to obtain an evaluation of specific function $f$ on this data, solutions in trustless digital environments like blockchain-based Web3 systems typically fall into two categories: (1) Smart contract-powered solutions and (2) cryptographic solutions leveraging tools such as adaptor signatures. The former approach offers atomic transactions where the buyer learns the function evaluation $f(x)$ (and not $x$ entirely) upon payment. However, this approach is often inefficient, costly, lacks privacy for the seller's data, and is incompatible with systems that do not support smart contracts with required functionalities. In contrast, the adaptor signature-based approach addresses all of the above issues but comes with an "all-or-nothing" guarantee, where the buyer fully extracts $x$ and does not support functional extraction of the sensitive data. In this work, we aim to bridge the gap between these approaches, developing a solution that enables fair functional sales of information while offering improved efficiency, privacy, and compatibility similar to adaptor signatures.

Towards this, we propose functional adaptor signatures (FAS) a novel cryptographic primitive that achieves all the desired properties as listed above. Using FAS, the seller can publish an advertisement committing to $x$. The buyer can pre-sign the payment transaction w.r.t. a function $f$, and send it along with the transaction to the seller.
The seller adapts the pre-signature into a valid (buyer's) signature and posts the payment and the adapted signature on the blockchain to get paid. Finally, using the pre-signature and the posted signature, the buyer efficiently extracts $f(x)$, and completes the sale. We formalize the security properties of FAS, among which is a new notion called witness privacy to capture seller's privacy, which ensures the buyer does not learn anything beyond $f(x)$.
We present multiple variants of witness privacy, namely, witness hiding, witness indistinguishability, and zero-knowledge, to capture varying levels of leakage about $x$ beyond $f(x)$ to a malicious buyer.

We introduce two efficient constructions of FAS supporting linear functions (like statistics/aggregates, kernels in machine learning, etc.), that satisfy the strongest notion of witness privacy. One construction is based on prime-order groups and compatible with Schnorr signatures for payments, and the other is based on lattices and compatible with a variant of Lyubashevsky's signature scheme. A central conceptual contribution of our work lies in revealing a surprising connection between functional encryption, a well-explored concept over the past decade, and adaptor signatures, a relatively new primitive in the cryptographic landscape. On a technical level, we avoid heavy cryptographic machinery and achieve improved efficiency, by making black-box use of building blocks like inner product functional encryption (IPFE) while relying on certain security-enhancing techniques for the IPFE in a non-black-box manner. We implement our FAS construction for Schnorr signatures and show that for reasonably sized seller witnesses, the different operations are quite efficient even for commodity hardware.
]]></content:encoded>
<pubDate>Fri, 27 Sep 2024 18:54:54 +0000</pubDate>
</item>
<item>
<title>Practical Mempool Privacy via One-time Setup Batched Threshold Encryption</title>
<link>https://eprint.iacr.org/2024/1516</link>
<guid>https://eprint.iacr.org/2024/1516</guid>
<content:encoded><![CDATA[
<div> 关键词：DeFi、mempool隐私、DKG、一次性设置、效率优化

总结:

文章探讨了在去中心化金融（DeFi）生态系统中保护交易隐私的重要性，特别是关于在内存池（mempool）中的交易可能遭受市场操纵的问题。文章提出了一种实用的、基于一次性分布式密钥生成（DKG）方案的mempool隐私解决方案，以确保交易隐私，并且在每个区块周期内仅需进行一次初始化设置。该方案通过让客户端加密交易，直到选定一定数量（B个）交易进入区块后，这些交易可以被解密服务器以极低的信息通信量解密。

相比先前的工作，该方案在不增加初始设置开销的同时，降低了通信需求，提高了处理效率，并保证了未被选中的交易的隐私性。实证研究表明，这种加密过程几乎不受参与节点数量的影响，而批量解密所需的通信量则与每个节点无关。当应用于以太坊这样的区块链平台时，计算和解密时间也相对较低，使得整体性能优化明显。

文章的贡献在于提供了一个既能有效保护交易隐私，又能保持高效运行的mempool隐私方案，这对于推动DeFi应用的安全性和用户数据保护具有重要意义。 <div>
An important consideration with the growth of the DeFi ecosystem is the protection of clients who submit transactions to the system. As it currently stands, the public visibility of these transactions in the memory pool (mempool) makes them susceptible to market manipulations such as frontrunning and backrunning. More broadly, for various reasons—ranging from avoiding market manipulation to including time-sensitive information in their transactions—clients may want the contents of their transactions to remain private until they are executed, i.e. they have *pending transaction privacy*. Therefore, *mempool privacy* is becoming an increasingly important feature as DeFi applications continue to spread.

    We construct the first *practical* mempool privacy scheme that uses a *one-time* DKG setup for $n$ decryption servers. Our scheme ensures the strong privacy requirement by not only hiding the transactions until they are decrypted but also guaranteeing privacy for transactions that were not selected in the epoch (*pending transaction privacy*). For each epoch (or block), clients can encrypt their transactions so that, once $B$ (encrypted) transactions are selected for the epoch, they can be decrypted by each decryption server while communicating only $O(1)$ information. 

    Our result improves upon the best-known prior works, which either: (i) require an expensive initial setup involving a (special purpose) multiparty computation protocol executed by the $n$ decryption servers, along with an additional *per-epoch* setup; (ii) require each decryption server to communicate $O(B)$ information; or (iii) do not guarantee pending transaction privacy.

    We implement our scheme and find that transactions can be encrypted in approximately 8.5 ms, independent of committee size, and the communication required to decrypt an entire batch of transactions is 48 bytes per party, independent of the number of transactions. If deployed on Ethereum, which processes close to 500 transactions per block, it takes close to 3.2 s for each committee member to compute a partial decryption and 3.0 s to decrypt all transactions for a block in single-threaded mode. Compared to prior work, which had an expensive setup phase per epoch, we incur $<2\times$ overhead in the worst case. On some metrics such as partial decryptions size, we actually fare better.
]]></content:encoded>
<pubDate>Thu, 26 Sep 2024 16:47:03 +0000</pubDate>
</item>
<item>
<title>Comments on "Privacy-Enhanced Federated Learning Against Poisoning Adversaries"</title>
<link>https://eprint.iacr.org/2024/1504</link>
<guid>https://eprint.iacr.org/2024/1504</guid>
<content:encoded><![CDATA[
<div> 关键词：Liu et al., IEEE TIFS'21, PEFL, 恶意行为检测, 同态加密

<br /><br />总结:

在2021年8月发表于IEEE TIFS期刊的Liu等人的文章中，提出了一种名为PEFL的隐私增强框架。该框架旨在通过同态加密技术高效检测联邦学习（FL）中的恶意行为。然而，本文揭示了PEFL并未真正保护隐私。具体来说，文章指出PEFL实际上暴露了所有参与实体的完整梯度向量，这违反了隐私原则。

文章进一步分析指出，即使对PEFL进行立即修复，也无法确保隐私安全。这是因为系统中存在多个漏洞，这些漏洞仍然允许敏感信息泄露。因此，虽然PEFL最初的目标是提高联邦学习环境的安全性，但其实际实现却未能达到预期的隐私保护效果。这一发现强调了在设计和部署用于保护敏感数据的加密技术时，需要仔细考虑潜在的弱点和漏洞。 <div>
In August 2021, Liu et al. (IEEE TIFS'21) proposed a privacy-enhanced framework named PEFL  to efficiently detect poisoning behaviours in Federated Learning (FL) using homomorphic encryption. In this article, we show that PEFL does not preserve privacy. In particular, we illustrate that PEFL reveals the entire gradient vector of all users in clear to one of the participating entities, thereby violating privacy. Furthermore, we clearly show that an immediate fix for this issue is still insufficient to achieve privacy by pointing out multiple flaws in the proposed system.
]]></content:encoded>
<pubDate>Wed, 25 Sep 2024 10:52:18 +0000</pubDate>
</item>
<item>
<title>Practical Implementation of Pairing-Based zkSNARK in Bitcoin Script</title>
<link>https://eprint.iacr.org/2024/1498</link>
<guid>https://eprint.iacr.org/2024/1498</guid>
<content:encoded><![CDATA[
<div> 关键词：Groth16、零知识证明、比特币脚本、主网、可验证计算

总结:

本文介绍了在BSV主网上实现Groth16验证器的实践性方法。Groth16是一个基于配对的零知识证明方案，其证明大小固定，验证算法高效。通过将Groth16验证器集成到比特币脚本中，可以在区块链上进行链上验证，从而实现离链计算的验证。这种解决方案不仅提供了隐私保护，还提升了区块链的扩展性。此外，它还为比特币引入了智能合约功能，这在过去被认为是非常有限或不存在的。通过生成Groth16证明来验证离链计算的正确性，再使用比特币脚本在链上进行验证，这种方式不仅保证了数据的机密性，而且提高了交易处理能力，为比特币生态系统带来了新的可能性和灵活性。 <div>
Groth16 is a pairing-based zero-knowledge proof scheme that has a constant proof size and an efficient verification algorithm. Bitcoin Script is a stack-based low-level programming language that is used to lock and unlock bitcoins. In this paper, we present a practical implementation of the Groth16 verifier in Bitcoin Script deployable on the mainnet of a Bitcoin blockchain called BSV. Our result paves the way for a framework of verifiable computation on Bitcoin: a Groth16 proof is generated for the correctness of an off-chain computation and is verified in Bitcoin Script on-chain. This approach not only offers privacy but also scalability. Moreover, this approach enables smart contract capability on Bitcoin which was previously thought rather limited if not non-existent.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 16:56:05 +0000</pubDate>
</item>
<item>
<title>No Fish Is Too Big for Flash Boys! Frontrunning on DAG-based Blockchains</title>
<link>https://eprint.iacr.org/2024/1496</link>
<guid>https://eprint.iacr.org/2024/1496</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、Frontrunning攻击、DAG、区块优先级、对策

总结:

本文深入分析了针对基于有向无环图(DAG)的区块链系统的Frontrunning攻击策略。主要发现和讨论如下：

1. **新型攻击策略**：提出了一种新颖的跨区块Frontrunning攻击方法，允许攻击者在其交易在不同区块中优先于受害者交易。

2. **攻击策略介绍**：介绍了三种攻击策略——裂缝攻击（通过断开受害者区块来推迟受害者交易的排序）、投机攻击（预先构建具有优先排序的交易块）以及迟缓攻击（通过故意创建低轮次但高优先级的区块来影响排序）。

3. **实验验证**：通过在AWS和本地环境中使用开源DAG区块链Bullshark和Tusk进行了实验，结果显示攻击的有效性极高，尤其是投机攻击在Bullshark和Tusk上的成功率分别达到92.86%和86.27%。

4. **对策探讨**：提出了随机排序区块和基于交易费用全局重排序的对策以抵御攻击，但发现这些措施可能损害系统性能或增加现有Frontrunning策略的脆弱性。

5. **结论与展望**：强调了对DAG区块链系统中Frontrunning攻击的深入理解和防御的重要性，指出需要进一步研究更有效的防御机制以保护此类区块链系统的安全性和公平性。 <div>
Frontrunning is rampant in blockchain ecosystems, yielding attackers profits that have already soared into several million. Most existing frontrunning attacks focus on manipulating transaction order (namely, prioritizing attackers' transactions before victims' transactions) $\textit{within}$ a block. However, for the emerging directed acyclic graph (DAG)-based blockchains, these intra-block frontrunning attacks may not fully reveal the frontrunning vulnerabilities as they introduce block ordering rules to order transactions belonging to distinct blocks. 

This work performs the first in-depth analysis of frontrunning attacks toward DAG-based blockchains. We observe that the current block ordering rule is vulnerable to a novel $\textit{inter-block}$ frontrunning attack, which enables the attacker to prioritize ordering its transactions before the victim transactions across blocks. We introduce three attacking strategies: $\textit{(i)}$ Fissure attack, where attackers render the victim transactions ordered later by disconnecting the victim's blocks. $\textit{(ii)}$ Speculative attack, where attackers speculatively construct order-priority blocks. $\textit{(iii)}$ Sluggish attack, where attackers deliberately create low-round blocks assigned a higher ordering priority by the block ordering rule.

We implement our attacks on two open-source DAG-based blockchains, Bullshark and Tusk. We extensively evaluate our attacks in geo-distributed AWS and local environments by running up to $n=100$ nodes. Our experiments show remarkable attack effectiveness. For instance, with the speculative attack, the attackers can achieve a $92.86\%$ attack success rate (ASR) on Bullshark and an $86.27\%$ ASR on Tusk. Using the fissure attack, the attackers can achieve a $94.81\%$ ASR on Bullshark and an $87.31\%$ ASR on Tusk. 

We also discuss potential countermeasures for the proposed attack, such as ordering blocks randomly and reordering transactions globally based on transaction fees. However, we find that they either compromise the performance of the system or make the protocol more vulnerable to frontrunning using the existing frontrunning strategies.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 13:34:03 +0000</pubDate>
</item>
<item>
<title>Concretely Efficient Private Set Union via Circuit-based PSI</title>
<link>https://eprint.iacr.org/2024/1494</link>
<guid>https://eprint.iacr.org/2024/1494</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Set Intersection (PSI), Private Set Union (PSU), Public-key operations, Communication overhead, Symmetric-key primitives

总结:

本文提出了一种新型的私有集合并集（PSU）协议，该协议主要基于高效对称密钥机制，同时保持与公钥基础替代方案相当的通信效率。PSU协议的核心创新在于利用先进的电路基PSI技术实现多查询反向私有成员测试（mq-RPMT），这一技术对于构建PSU至关重要。文章揭示了电路基PSI中常见哈希方法导致的隐私泄露问题，并通过盲化伪随机函数（OPRF）和新设计的洗牌子协议来缓解这一问题。

该协议采用模块化设计，各个组成部分可以方便地替换为更高效的版本，这将直接提升整体性能。实验结果显示，与Chen等人在PKC'24上提出的公钥基础PSU协议相比，本文的PSU协议在输入集大小为$2^{20}$时运行时间提高了10%。此外，与Zhang等人在USENIX Sec'23上提出的基于对称密钥的PSU协议相比，本文的协议在通信方面改善了1.6倍。

通过这些改进，本文的PSU协议不仅优化了计算效率，还降低了通信开销，为私有集合操作提供了更为高效、实用的解决方案。 <div>
Private set intersection (PSI) is a type of private set operation (PSO) for which concretely efficient linear-complexity protocols do exist.
However, the situation is currently less satisfactory for other relevant PSO problems such as private set union (PSU):
For PSU, the most promising protocols either rely entirely on computationally expensive public-key operations or suffer from substantial communication overhead.

In this work, we present the first PSU protocol that is mainly based on efficient symmetric-key primitives yet enjoys comparable communication as public-key-based alternatives.
Our core idea is to re-purpose state-of-the-art circuit-based PSI to realize a multi-query reverse private membership test (mq-RPMT), which is instrumental for building PSU.
We carefully analyze a privacy leakage issue resulting from the hashing paradigm commonly utilized in circuit-based PSI and show how to mitigate this via oblivious pseudorandom function (OPRF) and new shuffle sub-protocols.
Our protocol is modularly designed as a sequential execution of different building blocks that can be easily replaced by more efficient variants in the future, which will directly benefit the overall performance.

We implement our resulting PSU protocol, showing a run-time improvement of 10% over the state-of-the-art public-key-based protocol of Chen et al. (PKC'24) for input sets of size $2^{20}$.
Furthermore, we improve communication by $1.6\times$ over the state-of-the-art symmetric-key-based protocol of Zhang et al. (USENIX Sec'23).
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 11:57:38 +0000</pubDate>
</item>
<item>
<title>Simple and Practical Amortized Sublinear Private Information Retrieval using Dummy Subsets</title>
<link>https://eprint.iacr.org/2023/1072</link>
<guid>https://eprint.iacr.org/2023/1072</guid>
<content:encoded><![CDATA[
<div> 关键词：私有信息检索、子线性时间、多轮交互、状态依赖、效率优化

总结:

本文探讨了私有信息检索（Private Information Retrieval，简称PIR）领域中的一种新型方法——基于预处理和状态依赖的子线性时间PIR方案。主要贡献在于提出了一种使用新技巧构建和利用提示（hints）的方法，以解决现有PIR方案中面临的一系列挑战，包括客户端存储量大、通信成本高、实用性低、服务器需非共谋以及客户端查询序列受限等问题。

通过引入“假集”到客户端请求中，该方案成功地消除了任何泄露或正确性失败的可能性。这意味着即使在非共谋的服务器环境下，或者单个服务器场景下，也能实现高效和隐私保护的检索操作。在数据库规模为2^28个32字节条目的情况下，对于双服务器方案，每个查询仅需消耗34KB的通信量和2.7毫秒的计算时间；而单服务器方案则消耗约47KB的通信量和4.5毫秒的计算时间。这些性能指标显著优于先前的研究成果，实现了在保持隐私的同时，极大提升了实际应用中的效率。 <div>
Recent works in amortized sublinear Private Information Retrieval (PIR) have demonstrated great potential. Despite the inspiring progress, existing schemes in this new paradigm are still faced with various challenges and bottlenecks, including large client storage, high communication, poor practical efficiency, need for non-colluding servers, or restricted client query sequences. We present simple and practical amortized sublinear stateful private information retrieval schemes without these drawbacks using new techniques in hint construction and usage. In particular, we introduce a dummy set to the client's request to eliminate any leakage or correctness failures. Our techniques can work with two non-colluding servers or a single server. The resulting PIR schemes achieve practical efficiency. The online response overhead is only twice that of simply fetching the desired entry without privacy. For a database with $2^{28}$ entries of 32-byte, each query of our two-server scheme consumes 34 KB of communication and 2.7 milliseconds of computation, and each query of our single-server scheme consumes amortized 47 KB of communication and 4.5 milliseconds of computation. These results are one or more orders of magnitude better than prior works.
]]></content:encoded>
<pubDate>Mon, 10 Jul 2023 02:16:25 +0000</pubDate>
</item>
<item>
<title>Towards Practical Transciphering for FHE with Setup Independent of the Plaintext Space</title>
<link>https://eprint.iacr.org/2023/1531</link>
<guid>https://eprint.iacr.org/2023/1531</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、非交互式协议、带宽优化、混合同态加密、自适应精度

总结: 文章提出了一种新的方法来解决全同态加密（FHE）在实际应用中带宽需求过高的问题。通过结合任何FHE兼容的对称加密算法与自适应精度的转换过程，该方法允许服务器根据具体应用需求动态选择加密精度，从而显著减少了通信成本。文章以使用FiLIP密钥作为示例，结合了最实用的同态计算技术，成功实现了从2^2到2^8的不同精度范围内的加密操作，每项操作仅需13ms至137ms的时间。这种方法不仅优化了带宽使用，而且保持了操作的高效性，为FHE的应用提供了更灵活和高效的解决方案。

文章的核心贡献在于引入了一种无需预先确定消息精度的方法，解决了现有技术中对于消息大小或应用底层结构的约束问题。通过将原始数据逐位加密并随后根据需要转换为整数域上的FHE密文，这种方法使得FHE的非交互式隐私保护协议能够在保持计算和通信效率的同时，适应各种不同的应用场景。这种创新的策略极大地扩展了FHE在实际应用中的潜力，尤其是在需要处理大量数据和高精度要求的场景下。 <div>
Fully Homomorphic Encryption (FHE) is a powerful tool to achieve non-interactive privacy preserving protocols with optimal computation/communication complexity. However, the main disadvantage is that the actual communication cost (bandwidth) is high due to the large size of FHE ciphertexts. As a solution, a technique called transciphering (also known as Hybrid Homomorphic Encryption) was introduced to achieve almost optimal bandwidth for such protocols. However, all of existing works require clients to fix a  precision for the messages or a mathematical structure for the message space beforehand. It results in unwanted constraints on the plaintext size or underlying structure of FHE based applications.

In this article, we introduce a new approach for transciphering which does not require fixed message precision decided by the client, for the first time. In more detail, a client uses any kind of FHE-friendly symmetric cipher  for $\{0,1\}$ to send its input data encrypted bit-by-bit, then the server can choose a precision $p$ depending on the application and homomorphically transforms the encrypted bits into FHE ciphertexts encrypting integers in $\mathbb{Z}_p$. To illustrate our new technique, we evaluate a transciphering using FiLIP cipher and adapt the most practical homomorphic evaluation technique [CCS'22] to keep the practical latency.  As a result, our proof-of-concept implementation for $p$ from $2^2$ to $2^8$ takes only from $13$ ms to $137$ ms.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 21:43:10 +0000</pubDate>
</item>
<item>
<title>Mastic: Private Weighted Heavy-Hitters and Attribute-Based Metrics</title>
<link>https://eprint.iacr.org/2024/221</link>
<guid>https://eprint.iacr.org/2024/221</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、用户隐私、Mastic协议、重头项、属性基度量

总结:

本文讨论了在保护用户隐私的前提下，通过多党计算技术获取大型软件系统和网络服务中用户行为和体验的洞察。文章介绍了Prio和Poplar两种基于多党计算的协议，它们分别用于通用统计和热门输入的计算。然而，这两种协议并未覆盖所有IETF识别的应用场景。

为填补这一空白，文章提出了一种名为Mastic的新协议，用于处理每个客户端持有输入及其权重的情况（例如，URL及其页面加载时间）。对于给定的候选输入或前缀，一小部分非共谋服务器可以安全地聚合持有该输入（或具有相同前缀的输入）的客户端的权重，而无需学习这些权重或哪个客户端持有哪个输入。这种功能开辟了两个新应用领域：一是对传统热门输入概念的扩展——加权热门输入；二是对Prio风格指标的增强——属性基指标，其中聚合结果根据用户的层级属性进行分类（如地理位置或软件版本）。

文章还通过实际案例展示了Mastic在实现这两个新应用方面的可行性，并与Prio和Poplar进行了性能比较。结果显示，对于简单的热门输入计算，Mastic的表现优于Poplar至少一个数量级；而对于属性基指标，其性能提升幅度约为1.5到2倍。 <div>
Insight into user experience and behavior is critical to the success of large software systems and web services. Gaining such insights, while preserving user privacy, is a significant challenge. Recent advancements in multi-party computation have made it practical to securely compute aggregates over secret shared data. Two such protocols have emerged as candidates for standardization at the IETF: Prio (NSDI 2017) for general-purpose statistics; and Poplar (IEEE S&amp;P 2021) for heavy hitters, where the goal is to compute the most popular inputs held by users without learning the inputs themselves. While each of these protocols is well-suited to certain applications, there remain a number of use cases identified by IETF for which neither Prio nor Poplar is practical.

We introduce Mastic, a protocol for the following functionality: each of a large number of clients holds an input (e.g., a URL) and its corresponding weight (e.g., page load time); for a given candidate input (or prefix), a small number of non-colluding servers wish to securely aggregate the weights of clients that hold that input (or some input with that prefix), without learning the weights or which client holds which input. This functionality makes two new classes of applications possible. The first is a natural generalization of heavy hitters we call weighted heavy-hitters. The second is an enhancement of Prio-style metrics we call attribute-based metrics in which aggregates are grouped by hierarchical user attributes (e.g., their geographic location or software version). We demonstrate Mastic's practicality for these applications with a real-world example of each. We also compare our protocol with Prio and Poplar on a wide area network. Overall, we report over one order of magnitude performance improvement over Poplar for plain heavy-hitters and $1.5-2\times$ improvement over Prio for attribute-based metrics.
]]></content:encoded>
<pubDate>Tue, 13 Feb 2024 16:41:06 +0000</pubDate>
</item>
<item>
<title>PipeSwap: Forcing the Timely Release of a Secret for Atomic Swaps Across All Blockchains</title>
<link>https://eprint.iacr.org/2024/881</link>
<guid>https://eprint.iacr.org/2024/881</guid>
<content:encoded><![CDATA[
<div> 关键词：原子跨链交换、双声称攻击、管道交换、普适性、理想功能

总结:

本文针对原子跨链交换领域存在的问题进行了深入研究与创新。首先，作者揭示了一种名为“双声称攻击”的新形式，这种攻击会导致诚实用户以压倒性的概率损失硬币，并直接破坏原子性。此外，这种攻击易于实施，并可以自然地应用于其他跨链交换协议以及支付通道网络中，这凸显了设计普适性原子交换的普遍挑战。

为了克服这些挑战，作者提出了“管道交换”(pipeSwap)协议，旨在同时满足安全性和实用性。该协议通过使用两跳交换和两跳退款技术来设计一种新颖的硬币流模式，以避免相同冻结硬币的重复声称，从而违反原子性属性。pipeSwap实现了普适性，无需依赖特定的脚本语言（除了基本的签名验证能力），进一步证明了其不依赖于任何特定脚本语言的能力。

文章还分析了现有理想功能在捕捉原子性属性方面的不足，并首次定义了确保原子性的理想功能。在通用可组合性框架下，对pipeSwap进行了详细的安全分析，并开发了一个基于Schnorr/ECDSA签名的原型实现。实验结果显示，pipeSwap可以在不到1.7秒的时间内完成，并且通信开销小于7kb，证明了其高效性。

总的来说，本文通过揭示双声称攻击，提出管道交换协议，解决了原子跨链交换中的安全性与普适性问题，并通过实验验证了其高效性，为原子跨链交换领域的研究提供了新的视角和解决方案。 <div>
Atomic cross-chain swap, which allows users to exchange coins securely, is critical functionality to facilitate inter-currency exchange and trading. Although most classic atomic swap protocols based on Hash Timelock Contracts have been applied and deployed in practice, they are substantially far from universality due to the inherent dependence of rich scripting language supported by the underlying blockchains. The recently proposed Universal Atomic Swaps protocol [IEEE S\&amp;P'22] takes a novel path to scriptless cross-chain swap, and it ingeniously delegates scripting functionality to cryptographic lock mechanisms, particularly the adaptor signature and timed commitment schemes designed to guarantee atomicity. However, in this work, we discover a new form of attack called double-claiming attack, such that the honest user would lose coins with overwhelming probability and atomicity is directly broken. Moreover, this attack is easy to carry out and can be naturally generalized to other cross-chain swap protocols as well as the payment channel networks, highlighting a general difficulty in designing universal atomic swap.

We present pipeSwap, a cross-chain swap protocol that satisfies both security and practical universality. To avoid transactions of the same frozen coins being double-claimed to violate the atomicity property, pipeSwap proposes a novelly designed paradigm of pipelined coins flow by using two-hop swap and two-hop refund techniques. pipeSwap achieves universality by not relying on any specific script language, aside from the basic ability to verify signatures. Furthermore, we analyze why existing ideal functionality falls short in capturing the atomicity property of Universal Atomic Swaps, and define for the first time ideal functionality to guarantee atomicity. In addition to a detailed security analysis in the Universal Composability framework, we develop a proof-of-concept implementation of pipeSwap with Schnorr/ECDSA signatures, and conduct extensive experiments to evaluate the overhead. The experimental results show that pipeSwap can be performed in less than 1.7 seconds and requires less than 7 kb of communication overhead on commodity machines, which demonstrates its high efficiency.
]]></content:encoded>
<pubDate>Mon, 03 Jun 2024 01:21:19 +0000</pubDate>
</item>
<item>
<title>Verifiable Distributed Aggregation Functions</title>
<link>https://eprint.iacr.org/2023/130</link>
<guid>https://eprint.iacr.org/2023/130</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算、可验证分布式聚合函数(VDAFs)、隐私保护、Prio3、Doplar

总结:
本文提出了一种分析可验证分布式聚合函数（VDAFs）的正式框架，并将其应用于两个构建。首先是对IETF标准化候选之一的Prio3进行分析，证明了通过微调草案，Prio3能够实现所设定的安全目标。其次，本文引入了一个名为Doplar的新构建，它是对Boneh等人的Poplar系统的圆减少变体，旨在提高效率，但以增加整体带宽和计算成本为代价。Doplar作为Prio3的改进版本，进一步展示了多党计算在保护用户隐私的同时，能够有效地处理大规模数据聚合任务的能力。这些研究不仅为VDAFs提供了理论基础，也为未来标准化和实际应用提供了重要参考。 <div>
The modern Internet is built on systems that incentivize collection of information about users. In order to minimize privacy loss, it is desirable to prevent these systems from collecting more information than is required for the application. The promise of multi-party computation is that data can be aggregated without revealing individual measurements to the data collector. This work offers a provable security treatment for "Verifiable Distributed Aggregation Functions (VDAFs)", a class of multi-party computation protocols being considered for standardization by the IETF.

We propose a formal framework for the analysis of VDAFs and apply it to two constructions. The first is Prio3, one of the candidates for standardization. This VDAF is based on the Prio system of Corrigan-Gibbs and Boneh (NSDI 2017). We prove that Prio3 achieves our security goals with only minor changes to the draft. The second construction, called Doplar, is introduced by this paper. Doplar is a round-reduced variant of the Poplar system of Boneh et al. (IEEE S&amp;P 2021), itself a candidate for standardization. The cost of this improvement is a modest increase in overall bandwidth and computation.
]]></content:encoded>
<pubDate>Sat, 04 Feb 2023 02:48:49 +0000</pubDate>
</item>
<item>
<title>Adaptively Secure BLS Threshold Signatures from DDH and co-CDH</title>
<link>https://eprint.iacr.org/2023/1553</link>
<guid>https://eprint.iacr.org/2023/1553</guid>
<content:encoded><![CDATA[
<div> 关键词：阈签名、BLS、适应性安全、DDH、共CDH

<br />
总结: 本文主要介绍了第一种基于随机原象模型（ROM）的适应性安全的阈值BLS签名方案，该方案依赖于非对称配对群中的DDH（Diffie-Hellman假设）和共CDH（Co-CDH）假设。此方案具有非交互式签名、与非阈值BLS验证兼容以及与Boldyreva方案相媲美的实用性，从而确保了其在实际应用中作为具有证明适应性安全性的候选方案的潜力。

文章首先指出，阈签名在分布式系统中扮演着重要角色，而BLS阈签名因其独特的属性（如唯一性和简洁性、非交互式签名过程和与非阈值BLS验证的一致性）而广受欢迎和应用。然而，直到最近，BLS阈签名的安全性仅被证明对于静态攻击者有效，且其安全性证明依赖于强且非标准的假设。

随后，文章介绍了一项突破，即Bacho和Loss提出的针对BLS阈签名的首个适应性安全证明，尽管他们需要依赖于一多离散对数（OMDL）的难度和代数组模型（AGM）等较强的非标准假设。这是适应性安全证明领域的重要进展。

文章的主要贡献在于提出了一种全新的适应性安全的阈值BLS签名方案，该方案仅依赖于DDH和共CDH假设，且在ROM中实现。这一创新不仅提高了方案的安全性，而且保持了与BLS签名相同的高效特性和与非阈值BLS验证的兼容性，使其成为实用性和安全性兼备的优选方案。

通过上述分析，本文不仅填补了适应性安全BLS阈签名在理论上的空白，还提供了实际应用中更为可靠和强大的安全基础，为分布式系统中关键信息的保护提供了更优的选择。 <div>
Threshold signatures are one of the most important cryptographic primitives in distributed systems. A popular choice of threshold signature scheme is the BLS threshold signature introduced by Boldyreva (PKC'03). Some attractive properties of Boldyreva's threshold signature are that the signatures are unique and short, the signing process is non-interactive, and the verification process is identical to that of non-threshold BLS. These properties have resulted in its practical adoption in several decentralized systems. However, despite its popularity and wide adoption, up until recently, the Boldyreva scheme has been proven secure only against a static adversary. Very recently, Bacho and Loss (CCS'22) presented the first proof of adaptive security for the Boldyreva scheme, but they have to rely on strong and non-standard assumptions such as the hardness of one-more discrete log (OMDL) and the Algebraic Group Model~(AGM). In this paper, we present the first adaptively secure threshold BLS signature scheme that relies on the hardness of DDH and co-CDH in asymmetric pairing groups in the Random Oracle Model~(ROM). Our signature scheme also has non-interactive signing, compatibility with non-threshold BLS verification, and practical efficiency like Boldyreva's scheme. These properties make our protocol a suitable candidate for practical adoption with the added benefit of provable adaptive security.
]]></content:encoded>
<pubDate>Mon, 09 Oct 2023 20:56:57 +0000</pubDate>
</item>
<item>
<title>On the Anonymity of One Authentication and Key Agreement Scheme for Peer-to-Peer Cloud</title>
<link>https://eprint.iacr.org/2024/1491</link>
<guid>https://eprint.iacr.org/2024/1491</guid>
<content:encoded><![CDATA[
<div> 关键词：匿名性、伪匿名性、网络隐私、中等协议、关键同意方案

<br /><br />
总结:本文探讨了匿名性和伪匿名性的概念及其在网络通信中的应用。匿名性指的是用户完全不暴露其真实身份的状态，而伪匿名性则涉及使用可关联但不一定反映真实身份的虚构名称。两者都为用户提供了一定程度的隐私保护。文章指出，人们常常混淆这两种概念。进一步地，文章分析了一篇声称提供匿名性的中等协议的关键同意方案，发现实际上未能达到预期的匿名性效果。这表明在设计和实现网络通信系统时，需要更加精确地理解和应用匿名性和伪匿名性概念，以确保用户的隐私安全。 <div>
Peer-to-peer communication systems can provide many functions, including anonymized routing of network traffic, massive parallel computing environments, and distributed storage. Anonymity refers to the state of being completely nameless, with no attached identifiers. Pseudonymity involves the use of a fictitious name that can be consistently linked to a particular user, though not necessarily to the real identity. Both  provide a layer of privacy, shielding the user's true identity from public view. But we find their significations are often misunderstood. In this note, we clarify the differences between anonymity and pseudonymity. We also find the Zhong et al.'s key agreement scheme [IEEE TCC, 2022, 10(3), 1592-1603] fails to keep anonymity, not as claimed.
]]></content:encoded>
<pubDate>Tue, 24 Sep 2024 01:48:22 +0000</pubDate>
</item>
<item>
<title>Adaptive Security, Erasures, and Network Assumptions in Communication-Local MPC</title>
<link>https://eprint.iacr.org/2024/1489</link>
<guid>https://eprint.iacr.org/2024/1489</guid>
<content:encoded><![CDATA[
<div> 关键词：可靠通信、安全通信、多对多通信、适应性安全、多方计算

<br /><br />总结:

本文主要探讨了低度网络环境下可靠和安全的全对全通信问题，这一问题对于基于本地通信的多方计算(MPC)和区块链协议中的点对点网络通信至关重要。文章首先揭示了一类称为存储转发协议的通信协议存在强不可实现性结果，这类协议包括了当前已知的所有基于标准密码假设的MPC协议。接着，在假设仅存在公钥基础设施(PKI)的情况下，文章证明了在多数诚实设置下，即使不假设多发消息的能力，也可以通过安全擦除机制构建具有多项式对数局部性的全对全通信协议。然而，在少数欺诈设置下，这一结果并不成立。

最后，文章在更加强大的假设条件下，即使用具有反向域采样的陷阱门置换、紧凑型恶意电路私有FHE等，构建了一个具有多项式对数局部性的全对一通信协议，该协议能够适应性地抵抗任意常数比例的破坏，无需假设安全擦除或多发消息能力。这一结果通过创新地结合了适应性安全加密与静态FHE来绕过Katz等人提出的关于紧凑型适应性安全FHE的不可能性，这一发现可能对独立研究者具有重要意义。

此外，文章还提出了子线性输出集全对全通信(SOS-RMT)，并展示了如何利用标准MPC的已知界限，通过额外的匿名PKI假设，将SOS-RMT应用于子线性输出集MPC(SOS-MPC)。这一系列发现丰富了全对全通信和适应性安全MPC的研究领域，并为构建更加高效、安全的网络通信和计算协议提供了理论基础。 <div>
The problem of reliable/secure all-to-all communication over low-degree networks has been essential for communication-local (CL) n-party MPC (i.e., MPC protocols where every party directly communicates only with a few, typically polylogarithmic in n, parties) and more recently for communication over ad hoc networks, which are used in blockchain protocols. However, a limited number of adaptively secure solutions exist, and they all make relatively strong assumptions on the ability of parties to act in some specific manner before the adversary can corrupt them. Two such assumptions were made in the work of Chandran et al. [ITCS ’15]---parties can (a) multisend messages to several receivers simultaneously; and (b) securely erase the message and the identities of the receivers, before the adversary gets a chance to corrupt the sender (even if a receiver is corrupted). A natural question to ask is: Are these assumptions necessary for adaptively secure CL MPC? In this paper, we characterize the feasibility landscape for all-to-all reliable message transmission (RMT) under these two assumptions, and use this characterization to obtain (asymptotically) tight feasibility results for CL MPC.

– First, we prove a strong impossibility result for a broad class of RMT protocols, termed here store-and-forward protocols, which includes all known communication protocols for CL MPC from standard cryptographic assumptions. Concretely, we show that no such protocol with a certain expansion rate can tolerate a constant fraction of parties being corrupted.

– Next, under the assumption of only a PKI, we show that assuming secure erasures, we can obtain an RMT protocol between all pairs of parties with polylogarithmic locality (even without assuming multisend) for the honest majority setting. We complement this result by showing a negative result for the setting of dishonest majority.

– Finally, and somewhat surprisingly, under stronger assumptions (i.e., trapdoor permutations with a reverse domain sampler, and compact and malicious circuit-private FHE), we construct a polylogarithmic-locality all-to-one RMT protocol, which is adaptively secure and tolerates any constant fraction of corruptions, without assuming either secure erasures or multisend. This last result uses a novel combination of adaptively secure (e.g., non-committing) encryption and (static) FHE to bypass the impossibility of compact adaptively secure FHE by Katz et al. [PKC’13], which we believe may be of independent interest. Intriguingly, even such assumptions do not allow reducing all-to-all RMT to all-to-one RMT (a reduction which is trivial in the non-CL setting). Still, we can implement what we call sublinear output-set RMT (SOS-RMT for short). We show how SOS-RMT can be used for SOS-MPC under the known bounds for feasibility of MPC in the standard (i.e., non-CL) setting assuming, in addition to SOS-RMT, an anonymous PKI.
]]></content:encoded>
<pubDate>Mon, 23 Sep 2024 21:45:57 +0000</pubDate>
</item>
<item>
<title>Distributing Keys and Random Secrets with Constant Complexity</title>
<link>https://eprint.iacr.org/2024/876</link>
<guid>https://eprint.iacr.org/2024/876</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Secret Sharing Generation、Distributed Key Generation、Communication Complexity、Public Bulletin Board、Near-threshold Setting

总结:

本文研究了分布式秘密共享生成(Distributed Secret Sharing Generation, DSG)和分布式密钥生成(Distributed Key Generation, DKG)的通信复杂性。文章旨在探讨在不增长的通信量下实现这些功能的可能性，特别是通过利用公共公告板（如区块链账本）进行广播通信。

首先，作者提出了一种常数轮次的DSG/ DKG协议，其中每个参与者的通信量仅依赖于安全参数和字段大小，而与参与方数量无关。这一创新解决了现有解决方案中至少有部分参与者需要发送Ω(n)比特的问题。

其次，该协议适用于近阈值设置，允许容忍一定比例的主动被破坏参与者，同时根据特定的隐私性和正确性参数生成随机秘密的共享。通过使用非交互式零知识证明、非交互式承诺和基于低密度校验码的新秘密共享方案的特殊鲁棒性，实现这一目标。

此外，文章还扩展了基于多方计算的DSG/ DKG处理方法，探讨了线性秘密共享方案的新方面，从而为加密货币和区块链应用提供了更高效的解决方案。 <div>
In the *Distributed Secret Sharing Generation* (DSG) problem $n$ parties wish to obliviously sample a secret-sharing of a random value $s$ taken from some finite field, without letting any of the parties learn $s$. *Distributed Key Generation* (DKG) is a closely related variant of the problem in which, in addition to their private shares, the parties also generate a public ``commitment'' $g^s$ to the secret. Both DSG and DKG are central primitives in the domain of secure multiparty computation and threshold cryptography. 

In this paper, we study the communication complexity of DSG and DKG. Motivated by large-scale cryptocurrency and blockchain applications, we ask whether it is possible to obtain protocols in which the communication per party is a constant that does not grow with the number of parties. We answer this question to the affirmative in a model where broadcast communication is implemented via a public bulletin board (e.g., a ledger). Specifically, we present a constant-round DSG/DKG protocol in which the number of bits that each party sends/receives from the public bulletin board is a constant that depends only on the security parameter and the field size but does not grow with the number of parties $n$. In contrast, in all existing solutions at least some of the parties send $\Omega(n)$ bits.

Our protocol works in the near-threshold setting. Given arbitrary privacy/correctness parameters $0<\tau_p<\tau_c<1$, the protocol tolerates up to $\tau_p n$ actively corrupted parties and delivers shares of a random secret according to some $\tau_p n$-private $\tau_c n$-correct secret sharing scheme, such that the adversary cannot bias the secret or learn anything about it. The protocol is based on non-interactive zero-knowledge proofs, non-interactive commitments and a novel secret-sharing scheme with special robustness properties that is based on Low-Density Parity-Check codes. As a secondary contribution, we extend the formal MPC-based treatment of DKG/DSG, and study new aspects of Affine Secret Sharing Schemes.
]]></content:encoded>
<pubDate>Sun, 02 Jun 2024 08:36:48 +0000</pubDate>
</item>
<item>
<title>On Security Proofs of Existing Equivalence Class Signature Schemes</title>
<link>https://eprint.iacr.org/2024/183</link>
<guid>https://eprint.iacr.org/2024/183</guid>
<content:encoded><![CDATA[
<div> 关键词：Equivalence class signatures, 原始构造, 安全性证明, 通用组模型, 参数化非交互式困难假设

总结:
文章探讨了等价类签名(EQS)的安全性及其在不同模型下的适用性。等价类签名是一种独特的公钥加密技术，允许任何实体将对向量元素的签名转换为该向量任何倍数的签名，从而认证等价类。文章指出，原始的EQS构造在通用组模型下具有安全性，而第一个基于标准假设的方案则仅满足较弱的安全模型，不适用于大多数应用。后续研究提出了适用于实际应用的方案，但其安全性证明存在瑕疵。

文章的关键发现是，这些被质疑的方案可能在代数组模型下证明安全，但作者通过引入参数化的非交互式困难假设，展示了原始的更高效、已广泛应用于多个领域的EQS构造实际上在代数组模型下也是安全的。这一发现对于理解等价类签名的安全性及其在不同模型下的适用性提供了新的见解，对于未来的研究和应用具有重要意义。 <div>
Equivalence class signatures (EQS; Asiacrypt '14), sign vectors of elements from a bilinear group.   Anyone can transform a signature on a vector to a signature on any multiple of that vector; signatures thus authenticate equivalence classes.  A transformed signature/message pair is indistinguishable from a random signature on a random message.  EQS have been used to efficiently instantiate (delegatable) anonymous credentials, (round-optimal) blind signatures, ring and group signatures, anonymous tokens and contact-tracing schemes, to name a few.

The original EQS construction (J. Crypto '19) is proven secure in the generic group model, and the first scheme from standard assumptions (PKC '18) satisfies a weaker model insufficient for most applications.  Two works (Asiacrypt '19, PKC '22) propose applicable schemes that assume trusted parameters.  Their unforgeability is argued via a security proof from standard (or non-interactive) assumptions.
   
We show that their security proofs are flawed and explain the subtle issue.  While the schemes might be provable in the algebraic group model (AGM), we instead show that the original construction, which is more efficient and has found applications in many works, is secure in the AGM under a parametrized non-interactive hardness assumption.
]]></content:encoded>
<pubDate>Wed, 07 Feb 2024 08:24:24 +0000</pubDate>
</item>
<item>
<title>Signature-based Witness Encryption with Compact Ciphertext</title>
<link>https://eprint.iacr.org/2024/1477</link>
<guid>https://eprint.iacr.org/2024/1477</guid>
<content:encoded><![CDATA[
<div> 关键词：Signature-based witness encryption (SWE), 拆解, indistinguishability obfuscation (iO), strongly puncturable signatures (SPS), 指数级增长

总结: 文章探讨了签名基于见证加密(Signature-based witness encryption, SWE)这一新颖概念及其在分布式系统中的潜在应用。SWE允许将消息加密为特定标签和一组验证密钥集，只有持有至少k个有效签名和k个不同验证密钥的实体才能解密。然而，现有的无可信设置的SWE方案存在一个关键问题——其密文大小与验证密钥数量呈线性关系，这在系统变得更加分布化且参与方数量增加时成为瓶颈。

针对这一挑战，文章提出了一种基于图灵机不可区分混淆化(Indistinguishability Obfuscation, iO)和强可中断签名(Strongly Puncturable Signatures, SPS)的SWE构造方法。这种方法旨在实现密文大小与验证密钥数量之间的关系为次线性，从而解决指数级增长的问题，为分布式系统如区块链等提供更高效、灵活的安全加密解决方案。通过引入这些高级安全工具，该方案不仅能够维持安全性，还能显著减少密文大小，提高系统的可扩展性和性能。 <div>
Signature-based witness encryption (SWE) is a recently proposed notion that allows to encrypt a message with respect to a tag $T$ and a set of signature verification keys. The resulting ciphertext can only be decrypted by a party who holds at least $k$ different valid signatures w.r.t. $T$ and $k$ different verification keys out of the $n$ keys specified at encryption time. Natural applications of this primitive involve distributed settings (e.g., blockchains), where multiple parties sign predictable messages, such as polling or randomness beacons. However, known SWE schemes without trusted setup have ciphertexts that scale linearly in the number of verification keys. This quickly becomes a major bottleneck as the system gets more distributed and the number of parties increases.
    
    Towards showing the feasibility of SWE with ciphertext size sub-linear in the number of keys, we give a construction based on indistinguishability obfuscation (iO) for Turing machines and strongly puncturable signatures (SPS).
]]></content:encoded>
<pubDate>Sat, 21 Sep 2024 00:31:24 +0000</pubDate>
</item>
<item>
<title>Isogeny-Based Secure Voting Systems for Large-Scale Elections</title>
<link>https://eprint.iacr.org/2024/1472</link>
<guid>https://eprint.iacr.org/2024/1472</guid>
<content:encoded><![CDATA[
<div> 关键词：是生成法、电子投票系统、量子攻击、隐私保护、安全性证明

总结:
本文深入研究了基于是生成法的加密方法，旨在开发既安全又可扩展的电子投票系统。文章着重解决关键挑战，包括选民隐私、投票完整性以及对量子攻击的抵抗能力。通过引入利用是生成法的新型加密协议，建立了适用于大规模选举的后量子安全电子投票框架。

数学基础、协议设计和安全性证明的详细说明，展示了所提议系统的有效性和可扩展性。这些措施确保了在大型选举中的应用，同时保证了选民隐私和投票的完整性，同时也为抵御潜在的量子计算威胁提供了坚实的基础。通过这些创新，文章为电子投票系统的未来发展提供了重要的理论和技术支撑，为未来的选举提供了一种更加安全、可靠和私密的解决方案。 <div>
This article presents an in-depth study of isogeny-based cryptographic methods for the development of secure and scalable electronic voting systems. We address critical challenges such as voter privacy, vote integrity, and resistance to quantum attacks. Our work introduces novel cryptographic protocols leveraging isogenies, establishing a robust framework for post-quantum secure electronic voting. We provide detailed mathematical foundations, protocol designs, and security proofs, demonstrating the efficacy and scalability of our proposed system in large-scale elections.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 13:26:02 +0000</pubDate>
</item>
<item>
<title>Communication Efficient Secure and Private Multi-Party Deep Learning</title>
<link>https://eprint.iacr.org/2024/1471</link>
<guid>https://eprint.iacr.org/2024/1471</guid>
<content:encoded><![CDATA[
<div> 关键词：分布式训练、模型联合训练、安全性、隐私保护、差分隐私

总结:
本文探讨了在多参与方各自数据分布的情况下进行模型联合训练的方法，以应对大型多样数据集带来的挑战。然而，这种策略立即引发了安全性和隐私性问题，涉及各参与方保护其数据不被其他方获取，以及防止在训练后通过各种推理攻击泄露私人信息。为同时解决这些问题，本文设计了一种高效地结合了差分隐私与多方计算技术的DP-MPC协议，用于联合训练多参与方数据中的模型。

在两方设置中，我们的DP-MPC协议在通信效率上比以往同类协议提高了56-794倍，速度上快了16-182倍。理论和实践上，本文简化并改进了之前尝试将安全多方计算和差分隐私技术相结合的方法，特别是在机器学习训练领域的应用。通过优化算法设计和提升通信效率，我们的方案显著降低了训练过程中的资源消耗，同时确保了数据的安全性和隐私保护，为多参与方合作训练模型提供了一种更可靠、更高效的解决方案。 <div>
Distributed training that enables multiple parties to jointly train
a model on their respective datasets is a promising approach to
address the challenges of large volumes of diverse data for training
modern machine learning models. However, this approach immedi-
ately raises security and privacy concerns; both about each party
wishing to protect its data from other parties during training and
preventing leakage of private information from the model after
training through various inference attacks. In this paper, we ad-
dress both these concerns simultaneously by designing efficient
Differentially Private, secure Multiparty Computation (DP-MPC)
protocols for jointly training a model on data distributed among
multiple parties. Our DP-MPC protocol in the two-party setting
is 56-794× more communication-efficient and 16-182× faster than
previous such protocols. Conceptually, our work simplifies and
improves on previous attempts to combine techniques from secure
multiparty computation and differential privacy, especially in the
context of ML training.
]]></content:encoded>
<pubDate>Fri, 20 Sep 2024 04:51:34 +0000</pubDate>
</item>
<item>
<title>P2C2T: Preserving the Privacy of Cross-Chain Transfer</title>
<link>https://eprint.iacr.org/2024/1467</link>
<guid>https://eprint.iacr.org/2024/1467</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数字货币、隐私保护、跨链传输、原子性

总结: 

本文主要探讨了区块链技术在数字货币系统中的应用及其挑战。首先指出，当前的区块链数字货币系统在互操作性方面存在不足，这导致资产跨系统转移变得复杂且不安全。为解决这一问题，作者提出了一种名为P2C2T（Peer-to-Chain-to-Target）的隐私保护跨链传输方案。该方案基于“阈值匿名原子锁”（TA²L），能够确保跨链交易的原子性、不可链接性、不可区分性和无需抵押，同时对底层区块链的要求较低。

P2C2T通过结合“可验证时间离散对数”方案，使得跨链交易在安全性和性能上与常规的链内交易相匹配。特别地，它消除了发送方的抵押要求，并仅需要底层区块链具备签名验证能力。为了证明TA²L的安全性，作者引入了“阈值盲条件签名”的概念，并通过必要的证明展示了P2C2T的整体安全性。

此外，作者还对比了P2C2T与现有最接近的方案，在运行时间、通信成本和存储成本上，P2C2T至少降低了85.488%，并提供了实际案例来展示其隐私性和实用性。通过使用比特币测试网和Litecoin测试网进行的跨链和链内转账实验，证实了P2C2T的有效性和高效性。 <div>
Blockchain-enabled digital currency systems have typically operated in isolation, lacking necessary mechanisms for seamless interconnection. Consequently, transferring assets across distinct currency systems remains a complex challenge, with existing schemes often falling short in ensuring security, privacy, and practicality. This paper proposes P2C2T -- a privacy-preserving cross-chain transfer scheme. It is the first scheme to address atomicity, unlinkability, indistinguishability, non-collateralization, and required functionalities across diverse currency systems. P2C2T is based on \textit{threshold anonymous atomic locks} (TA$^2$L), also proposed by us, serving as the cornerstone for guaranteeing atomic cross-chain transfer while obscuring the payment relationships between users. By combining TA$^2$L with \textit{verifiable timed discrete logarithm} schemes, P2C2T renders cross-chain transactions indistinguishable from regular intra-chain ones. Notably, P2C2T eliminates the collateralization of senders and imposes minimal requirements on underlying blockchains, specifically on the ability to verify signatures. We substantiate the security of TA$^2$L based on a proposed cryptographic notion called \textit{threshold blind conditional signatures} and demonstrate the security of P2C2T through necessary proofs. Additionally, we compare the performance of P2C2T with an existing scheme that has properties closest to P2C2T. The comparison reveals that P2C2T reduces overhead by at least $85.488\%$ in terms of running time, communication cost, and storage cost when completing a cross-chain transfer. We further conduct cross-chain transfers and intra-chain payments using the Bitcoin testnet and Litecoin testnet to illustrate the privacy and practicality of P2C2T.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 13:21:42 +0000</pubDate>
</item>
<item>
<title>SoK: Descriptive Statistics Under Local Differential Privacy</title>
<link>https://eprint.iacr.org/2024/1464</link>
<guid>https://eprint.iacr.org/2024/1464</guid>
<content:encoded><![CDATA[
<div> 关键词：Local Differential Privacy、系统化、比较、实证研究、推荐

总结: 本文首先对局部差分隐私（LDP）方法进行了系统化的概述，对比了它们的特性和需求。发现基于伯努利分布采样的多个均值估计方法在一维情况下是等价的，并引入了方差估计的方法。接下来，文章通过实证研究比较了用于均值、方差和频率估计的LDP方法。最后，文章提供了使用LDP方法进行描述性统计的建议，并讨论了其局限性和未解决的问题。

通过系统的比较和实证研究，本文为理解和选择适用于描述性统计分析的LDP方法提供了宝贵的指导。它揭示了一些等效的方法，为实践者节省了资源，并通过实验数据验证了这些方法的有效性。同时，它也指出了当前方法的局限性和需要进一步探索的领域，例如频率估计方法的优化以及多维数据处理的挑战。这些发现不仅有助于提高数据保护和隐私计算的效率，也为未来的研究提供了方向。 <div>
Local Differential Privacy (LDP) provides a formal guarantee of privacy that enables the collection and analysis of sensitive data without revealing any individual's data. While LDP methods have been extensively studied, there is a lack of a systematic and empirical comparison of LDP methods for descriptive statistics. In this paper, we first provide a systematization of LDP methods for descriptive statistics, comparing their properties and requirements. We demonstrate that several mean estimation methods based on sampling from a Bernoulli distribution are equivalent in the one-dimensional case and introduce methods for variance estimation. We then empirically compare methods for mean, variance, and frequency estimation. Finally, we provide recommendations for the use of LDP methods for descriptive statistics and discuss their limitations and open questions.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 09:11:51 +0000</pubDate>
</item>
<item>
<title>Asynchronous Verifiable Secret Sharing with Elastic Thresholds and Distributed Key Generation</title>
<link>https://eprint.iacr.org/2024/1463</link>
<guid>https://eprint.iacr.org/2024/1463</guid>
<content:encoded><![CDATA[
<div> 关键词：Distributed Key Generation（DKG）、Asynchronous Distributed Key Generation（ADKG）、Elastic Threshold、Verifiable Secret Sharing Protocol、Simultaneous Commitments

<br />
<br />总结:

本文提出了一种具有弹性阈值的异步可验证秘密共享协议，该协议允许经销商与总共有n个参与方的情况下共享最多t+1个秘密，其中n ≥ 3f+1且f是最大恶意节点数。协议的主要贡献在于它将秘密分享的弹性阈值从固定的f或2f扩展到范围内的任意值，同时保持了较低的通信复杂度O(λn^3)，其中λ是安全参数。此外，通过修改Schnorr协议，实现了对多个秘密的并发承诺，我们称之为m-Schnorr。这种改进不仅提高了协议的灵活性，还优化了通信效率，对于构建更高效和安全的分布式系统具有重要意义。

<br /> <div>
Distributed Key Generation (DKG) is a technique that enables the generation of threshold cryptography keys among a set of mutually untrusting nodes. DKG generates keys for a range of decentralized applications such as threshold signatures, multiparty computation, and Byzantine consensus. Over the past five years, research on DKG has focused on optimizing network communication protocols to improve overall system efficiency by reducing communication complexity. However, SOTA asynchronous distributed key generation (ADKG) schemes (e.g., Kokoris-Kogias ADKG, CCS 2020 and Das ADKG, S\&amp;P 2022, and others) only support recovery thresholds of either $f$ or $2f$, where $f$ is the maximum number of malicious nodes. This paper proposes an asynchronous verifiable secret sharing protocol featuring an elastic threshold, where $t \in [f,n-f-1]$ and $n \ge 3f+1$ is the total number of parties. Our protocol enables a dealer to share up to $t+1$ secrets with a total communication cost of O($\lambda n^3$), where $\lambda$ is the security parameter, and the protocol relies on the hardness of the $q$-SDH problem. We further modified the Schnorr protocol to enable simultaneous commitments to multiple secrets, which we refer to $m$-Schnorr.
]]></content:encoded>
<pubDate>Thu, 19 Sep 2024 07:45:10 +0000</pubDate>
</item>
<item>
<title>PPSA: Polynomial Private Stream Aggregation for Time-Series Data Analysis</title>
<link>https://eprint.iacr.org/2024/1460</link>
<guid>https://eprint.iacr.org/2024/1460</guid>
<content:encoded><![CDATA[
<div> 关键词：PPSA、Private Polynomial Stream Aggregation、数据隐私、聚合函数、低延迟

本文介绍了一种名为PPSA（Private Polynomial Stream Aggregation）的新协议，该协议允许在不受信任的聚合器存在的情况下，对用户数据流进行任意多项式函数的私密计算。与之前的最佳实践相比，PPSA不依赖于可信硬件或预设的信任方，仅利用密码学和差分隐私工具即可实现这一目标。实验结果表明，PPSA在加密和聚合过程中的延迟非常低，分别仅为10.5毫秒和21.6毫秒，对于1000名用户而言，这一性能相较于现有最佳方案快了138倍。

总结: PPSA协议提供了一种高效且私密的数据聚合方法，无需依赖于可信硬件，仅使用基本的密码学和差分隐私技术，就能实现对用户数据流的多项式函数计算。其显著优势在于低延迟的加密与聚合过程，相较于当前最佳实践，速度提升幅度高达138倍，为大规模数据处理提供了更高效、更安全的解决方案。 <div>
Modern data analytics requires computing functions on streams of data points from many users that are challenging to calculate, due to both the high scale and nontrivial nature of the computation at hand. The need for data privacy complicates this matter further, as general-purpose privacy-enhancing technologies face limitations in at least scalability or utility. Existing work has attempted to improve this by designing purpose-built protocols for the use case of Private Stream Aggregation; however, prior work lacks the ability to compute more general aggregative functions without the assumption of trusted parties or hardware.

In this work, we present PPSA, a protocol that performs Private Polynomial Stream Aggregation, allowing the private computation of any polynomial function on user data streams even in the presence of an untrusted aggregator. Unlike previous state-of-the-art approaches, PPSA enables secure aggregation beyond simple summations without relying on trusted hardware; it utilizes only tools from cryptography and differential privacy. Our experiments show that PPSA has low latency during the encryption and aggregation processes with an encryption latency of 10.5 ms and aggregation latency of 21.6 ms for 1000 users, which are up to 138$\times$ faster than the state-of-the-art prior work.
]]></content:encoded>
<pubDate>Wed, 18 Sep 2024 16:32:23 +0000</pubDate>
</item>
<item>
<title>GoAT: File Geolocation via Anchor Timestamping</title>
<link>https://eprint.iacr.org/2021/697</link>
<guid>https://eprint.iacr.org/2021/697</guid>
<content:encoded><![CDATA[
<div> 关键词：Decentralized存储系统、Proof of Geo-Retrievability（PoGeoRet）、GoAT、时间戳服务器、互联网物理约束

总结:
文章主要介绍了Proof of Geo-Retrievability（PoGeoRet）和GoAT，这是一种新的证明机制，旨在证明文件位于特定地理边界内。PoGeoRet通过确保文件复制分布在不同的地理位置来增强去中心化存储系统的鲁棒性。GoAT是一种实现这一目标的实际方案，它利用互联网上的任何具有固定已知位置的时间戳服务器作为地理定位锚点，提供可靠的地理定位保证。

GoAT通过创新地使用通信效率高的Proof-of-Retrievability（PoRet）方案来实现其证明，使得PoRet组件的大小保持常数。这不仅确保了数据的可访问性，还提高了验证过程的效率。

为了验证GoAT的实用性，文章进行了一项初步的测量研究，以寻找可用的锚点，并执行了一个实地实验。结果显示，互联网的很大一部分可以作为锚点使用，GoAT能够实现低至500公里的地理定位半径。

综上所述，PoGeoRet和GoAT为去中心化存储系统提供了地理定位证明，通过利用互联网物理约束提供可靠保障，同时通过优化技术提高验证效率，从而增强了数据存储的安全性和可靠性。 <div>
Decentralized storage systems are a crucial component of the rapidly growing blockchain ecosystem. They aim to achieve robustness by proving that they store multiple replicas of every file. They have a serious limitation, though: They cannot prove that file replicas are spread across distinct systems, e.g., different hard drives. Consequently, files are vulnerable to loss in a single, locally catastrophic event.

We introduce a new primitive, Proof of Geo-Retrievability or PoGeoRet, that proves that a file is located within a strict geographic boundary. Using PoGeoRet, one can, for example, prove that a file is spread across several distinct geographic regions---and by extension across multiple systems, e.g., hard drives. We define what it means for a PoGeoRet scheme to be complete and sound, extending prior formalism in key ways. 

We also propose GoAT, a practical PoGeoRet scheme to prove file geolocation. Unlike previous geolocation systems that only offer nominal geolocation guarantees and require dedicated anchors, GoAT geolocates provers using any timestamping server on the internet with a fixed, known location as a geolocation anchor.
GoAT's geolocation guarantees directly depend on the physical constraints of the internet, making them very reliable. 
GoAT internally uses a communication-efficient Proof-of-Retrievability (PoRet) scheme in a novel way to achieve constant-size PoRet-component in its proofs.

We validate GoAT's practicality by conducting an initial measurement study to find usable anchors and perform a real-world experiment. The results show that a significant fraction of the internet can be used as anchors and that GoAT achieves geolocation radii as low as 500km.
]]></content:encoded>
<pubDate>Fri, 28 May 2021 09:14:42 +0000</pubDate>
</item>
<item>
<title>Proofs of Space with Maximal Hardness</title>
<link>https://eprint.iacr.org/2023/1530</link>
<guid>https://eprint.iacr.org/2023/1530</guid>
<content:encoded><![CDATA[
<div> 关键词：证明空间、计算复杂性、安全目标、深度鲁棒图、预后鲁棒图

总结:

本文提出了一种新型的证明空间构造方法，旨在确保在证明者试图节省任意小比例存储空间时，必须重做几乎全部原始复杂计算的大部分部分。这种方法的实现是通过将现有的SDR（Fisch, Eurocrypt 2019）构造进行扩展和优化完成的，这种优化不仅保持了通用性，还展示了已经部署的SDR构造在安全性方面具有比先前显示的更好的性能。

该构造的核心技术在于对预后鲁棒图的增强利用。预后鲁棒图是一种特殊的有向无环图，其中任何足够相对大小的子图都包含一个相对较大的单一汇节点连接组件。文章通过构建一个更大的预后鲁棒图，不仅优化了参数设置，还增强了关于汇节点位置的额外保证，同时仅通过增加很小的常数来提高度数。这种方法实现了几乎完全的计算复原，显著提高了证明空间的安全性。 <div>
In a proof of space, a prover performs a complex computation with a large output. A verifier periodically checks that the prover still holds the output. The security goal for a proof of space construction is to ensure that a prover who erases even a portion of the output has to redo a large portion of the complex computation in order to satisfy the verifier.

In existing constructions of proofs of space, the computation that a cheating prover is forced to redo is a small fraction (vanishing or small constant) of the original complex computation. The only exception is a construction of Pietrzak (ITCS 2019) that requires extremely depth-robust graphs, which result in impractically high complexity of the initialization process.

We present the first proof of space of reasonable complexity that ensures that the prover has to redo almost the entire computation (fraction arbitrarily close to 1) when trying to save even an arbitrarily small constant fraction of the space. 
Our construction is a generalization of an existing construction called SDR (Fisch, Eurocrypt 2019) deployed on the Filecoin blockchain. Our improvements, while general, also demonstrate that the already deployed construction has considerably better security than previously shown.

Technically, our construction can be viewed as amplifying predecessor-robust graphs. These are directed acyclic graphs in which every subgraph of sufficient relative size $\pi$ contains a large single-sink connected component of relative size $\alpha_\pi$. We take a predecessor-robust graph with constant parameters $(\pi, \alpha_\pi)$, and build a bigger predecessor-robust graph with a near-optimal set of parameters and additional guarantees on sink placement, while increasing the degree only by a small additive constant.
]]></content:encoded>
<pubDate>Fri, 06 Oct 2023 18:02:28 +0000</pubDate>
</item>
<item>
<title>Interactive Threshold Mercurial Signatures and Applications</title>
<link>https://eprint.iacr.org/2024/625</link>
<guid>https://eprint.iacr.org/2024/625</guid>
<content:encoded><![CDATA[
<div> 关键词：Mercurial Signatures、Interactive Threshold、Class-Hiding Property、Multi-party、Privacy

总结:
本文主要研究了Mercurial签名的交互阈值版本，旨在解决其原始设计中存在的隐私问题。Mercurial签名是一种允许消息和签名在公共密钥类中进行灵活操作的签名方案，但当前最有效实现存在公共密钥类隐藏性不足的问题，使得原始签名者能够关联同一类中的公钥，对隐私构成威胁。

文章提出了两种基于交互的双方和多方Mercurial签名构造方法。这些构造避免了复杂分布式计算，如随机数生成、求逆和乘法，甚至不需要双方间的私密通信。其中一个构造基于通用多方计算的蓝图，结合了验证秘密共享技术，同时进行了优化。

文中展示了在匿名凭证系统中的应用实例，特别是对于双发情况，该方法通过彻底去除权威机构的信任需求，提供了更强的隐私保护。此外，文章还讨论了盲签名、多签、阈值环签名等更多应用领域。

最后，作者实施了这些交互构造，并与相关替代方案进行了比较，以展示其实用性。通过这种方式，Mercurial签名的隐私问题得到了有效解决，为实际应用提供了新的可能性。 <div>
Mercurial signatures are an extension of equivalence class signatures that allow malleability for the public keys, messages, and signatures within the respective classes. Unfortunately, the most efficient construction to date suffers from a weak public key class-hiding property, where the original signer with the signing key can link the public keys in the same class. This is a severe limitation in their applications, where the signer is often considered untrustworthy of privacy.

This paper presents two-party and multi-party interactive threshold mercurial signatures that overcome the above limitation by eliminating the single entity who knows the signing key. For the general case, we propose two constructions. The first follows the same interactive structure as the two-party case, avoiding complex distributed computations such as randomness generation, inversion, and multiplication, and even eliminates the need for private communication between parties. The second is based on a blueprint for general multi-party computation using verifiable secret sharing, but adopting optimizations.

We show applications in anonymous credential systems that individually fit the two-party and multi-party constructions. In particular, in the two-party case, our approach provides stronger privacy by completely removing the trust in the authorities. We also discuss more applications, from blind signatures to multi-signatures and threshold ring signatures.

Finally, to showcase the practicality of our approach, we implement our interactive constructions and compare them against related alternatives.
]]></content:encoded>
<pubDate>Tue, 23 Apr 2024 06:56:33 +0000</pubDate>
</item>
<item>
<title>Compute, but Verify: Efficient Multiparty Computation over Authenticated Inputs</title>
<link>https://eprint.iacr.org/2022/1648</link>
<guid>https://eprint.iacr.org/2022/1648</guid>
<content:encoded><![CDATA[
<div> 关键词：安全多方计算、输入认证、编译器、通信开销、计算开销

总结:本文提出了一个通用且高效的编译器，用于将基于线性秘密共享的诚实多数安全多方计算(MPC)协议转换为具有输入认证的协议。该编译器显著降低了计算成本和通信开销，与现有最佳解决方案相比，其通信开销仅为O(n log l)，而计算开销仅为每个参与者O(ℓ)组指数操作，而现有最佳解决方案的通信开销为O(n²)，计算开销为O(ℓn)。对于容忍度为t3的腐败阈值，该编译器保留了底层MPC协议的更强的可识别中断安全性，这是现有任何认证MPC解决方案都无法实现的，无论腐败阈值如何。

文章还涉及了几个独立的技术贡献，包括分布式知识证明的概念及其对多个常用数字签名方案和Pedersen承诺开证明等关系的具体实现。这些技术不仅支持了编译器的功能，而且对其他安全计算领域也有潜在的应用价值。 <div>
Traditional notions of secure multiparty computation (MPC) allow mutually distrusting parties to jointly compute a function over their private inputs, but typically do not specify how these inputs are chosen. Motivated by real-world applications where corrupt inputs could adversely impact privacy and operational legitimacy, we consider a notion of authenticated MPC where the inputs are authenticated, e.g., signed using a digital signature by some certification authority. We propose a generic and efficient compiler that transforms any linear secret sharing based honest-majority MPC protocol into one with input authentication.

Our compiler incurs significantly lower computational costs and competitive communication overheads when compared to the best existing solutions, while entirely avoiding the (potentially expensive) protocol-specific techniques and pre-processing requirements that are inherent to these solutions. For $n$-party honest majority MPC protocols with abort security where each party has $\ell$ inputs, our compiler incurs $O(n\log \ell)$ communication overall and a computational overhead of $O(\ell)$ group exponentiations per party (the corresponding overheads for the most efficient existing solution are $O(n^2)$ and $O(\ell n)$). Finally, for a corruption threshold $t3$, our compiler preserves the stronger identifiable abort security of the underlying MPC protocol. No existing solution for authenticated MPC achieves this regardless of the corruption threshold.

Along the way, we make several technical contributions that are of independent interest. This includes the notion of distributed proofs of knowledge and concrete realizations of the same for several relations of interest, such as proving knowledge of many popularly used digital signature schemes, and proving knowledge of opening of a Pedersen commitment.
]]></content:encoded>
<pubDate>Mon, 28 Nov 2022 06:38:29 +0000</pubDate>
</item>
<item>
<title>Attestation Proof of Association – provability that attestation keys are bound to the same hardware and person</title>
<link>https://eprint.iacr.org/2024/1444</link>
<guid>https://eprint.iacr.org/2024/1444</guid>
<content:encoded><![CDATA[
<div> 关键词：Wallet Trust Evidence (WTE), Proof of Association (PoA), European Digital Identity (EUDI) Wallet, cryptographic hardware, eIDAS Level of Assurance

<br /><br />
总结:

本文主要讨论了Wallet Trust Evidence（WTE）和与之相关的三个特定指令，旨在为欧洲数字身份(EUDI)钱包中的加密硬件提供指导。这些指令特别关注了证明关联（Proof of Association，PoA）的生成，允许EUDI钱包向第三方（发行者、依赖方）保证认证私钥不仅被绑定到符合标准的加密硬件上，还被绑定到相同的硬件设备上。这一举措使EUDI钱包能够达到eIDAS高安全等级的同时，也确保了隐私保护。

文中提出的方法不仅适用于基于全球平台的安全元素（如电子身份证或嵌入式SIM卡）等所有预期的EUDI钱包架构，还考虑到了它们的便利实施和通用标准认证（Common Criteria）。这进一步细化并具体化了由NI-Scy联盟与eIDAS专家小组合作开发的wallet架构和参考框架中关于WTE/PoA逻辑的描述，但请注意，当前文档仅为讨论稿，尚未获得NI-Scy联盟、eIDAS专家小组或荷兰政府的认可。 <div>
We propose a wallet provider issued attestation called Wallet Trust Evidence (WTE) and three related specific instructions for the European Digital Identity (EUDI) Wallet cryptographic hardware, most notably the generation of a Proof of Association (PoA). These allow the EUDI Wallet providing verifiable assurance to third parties (issuers, relying parties) that attestation private keys are not only bound to conformant cryptographic hardware but also that they are bound to the same such hardware. This allows the EUDI Wallet meeting eIDAS Level of Assurance ``high'' as well as operating in a privacy friendly manner. The instructions specified in this document cater for convenient implementation in all envisioned EUDI Wallet architectures including those based on a GlobalPlatform based Secure Element such as an eID-card or an embedded SIM (eSIM). By their simplicity, the three instructions also allow for convenient Common Criteria certification. This document is a further refinement and cryptographic concretization of the WTE/PoA logic specified in the wallet Architecture and Reference Framework (ARF), which is based on the EPIC-09 result developed in a cooperation between the NI-Scy consortium and the eIDAS expert group. However, the present draft document is meant for discussion only and not approved by the NI-Scy consortium, the eIDAS expert group or Dutch government.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 11:40:16 +0000</pubDate>
</item>
<item>
<title>SnarkFold: Efficient Proof Aggregation from Incrementally Verifiable Computation and Applications</title>
<link>https://eprint.iacr.org/2023/1946</link>
<guid>https://eprint.iacr.org/2023/1946</guid>
<content:encoded><![CDATA[
<div> 关键词：SnarkFold、SNARK、证明聚合、常数验证时间、折迭方案

总结: 
本文介绍了一种新型的SNARK证明聚合方案——SnarkFold。SnarkFold旨在解决现有区块链系统中独立验证每个证明导致的节点负担过重和用户交易费用高昂的问题。它通过引入一种基于增量可验证计算（IVC）的方法，并进一步优化以实现折迭方案，使得验证多条证明的时间和证明大小保持常数级。SnarkFold的核心创新在于将昂贵的SNARK验证过程，如椭圆曲线配对，推迟到最终步骤执行，从而显著提高验证效率。

此外，文章提出了一种通用技术，允许验证者将实例聚合任务委托给证明者，验证者仅需进行简单的预处理来检查委托的有效性。为了适应不同类型的SNARK证明，如Groth16和Plonk，作者还设计了特定的折迭方案。

实验结果表明，使用SnarkFold聚合Plonk证明的大小仅为0.5KB，验证4096个Plonk证明只需4.5ms，显示出显著的性能提升。这一方案为区块链系统的效率优化提供了有力支持，有望降低验证成本，提高整体性能。 <div>
The succinct non-interactive argument of knowledge (SNARK) technique has been extensively utilized in blockchain systems to replace the costly on-chain computation with the verification of a succinct proof. However, most existing applications verify each proof independently, resulting in a heavy load on nodes and high transaction fees for users. Currently, the mainstream proof aggregation schemes are based on a generalized inner product argument, which has a logarithmic proof size and verification cost. To improve the efficiency of verifying multiple proofs, we introduce SnarkFold, a novel SNARK-proof aggregation scheme with constant verification time and proof size. SnarkFold is derived from incrementally verifiable computation (IVC) and is optimized further through the folding scheme. By folding multiple instance-proof pairs, SnarkFold defers the expensive SNARK verification (e.g., elliptic curve pairing) to the final step. Additionally, we propose a generic technique to enhance the verifier's efficiency by delegating instance aggregation tasks to the prover. The verifier only needs a simple preprocessing to check the validity of the delegation. We further introduce folding schemes for Groth16 and Plonk proofs. Experimental results demonstrate that SnarkFold offers significant advantages, with an aggregated Plonk proof size of just $0.5$ KB and the verification time of only $4.5$ ms for aggregating 4096 Plonk proofs.
]]></content:encoded>
<pubDate>Fri, 22 Dec 2023 15:36:21 +0000</pubDate>
</item>
<item>
<title>Traffic-aware Merkle Trees for Shortening Blockchain Transaction Proofs</title>
<link>https://eprint.iacr.org/2024/1451</link>
<guid>https://eprint.iacr.org/2024/1451</guid>
<content:encoded><![CDATA[
<div> 关键词：Merkle树、区块链网络、交易处理、通信成本、智能合约

总结:本文主要研究了如何通过优化Merkle树结构和算法，以降低区块链网络中交易处理过程中的通信成本。通过分析典型交易特征，特别是多个账户共同参与的交易场景，作者提出了基于账户分布的通信成本下限理论。接着，他们设计了一套考虑流量模式的算法，旨在显著减少通信成本，该算法灵感来源于霍夫曼编码、分区与权重平衡等编码方法。此外，文章还扩展了方法以适应智能合约交易的复杂性，这些交易可能涉及任意数量的账户。为了验证方法的有效性，作者使用了真实区块链数据（以太坊网络）进行实验，结果显示对于支付交易和智能合约交易，该方法均能实现成本节省。 <div>
Merkle trees play a crucial role in blockchain networks in organizing network state. They allow proving a particular value of an entry in the state to a node that maintains only the root of the Merkle trees, a hash-based signature computed over the data in a hierarchical manner. Verification of particular state entries is crucial in reaching a consensus on the execution of a block where state information is required in the processing of its transactions. For instance, a payment transaction should be based on the balance of the two involved accounts. The proof length affects the network communication and is typically logarithmic in the state size. In this paper, we take advantage of typical transaction characteristics for better organizing Merkle trees to improve blockchain network performance. We focus on the common transaction processing where Merkle proofs are jointly provided for multiple accounts. We first provide lower bounds for the communication cost that are based on the distribution of accounts involved in the transactions. We then describe algorithms that consider traffic patterns for significantly reducing it. The algorithms are inspired by various coding methods such as Huffman coding, partition and weight balancing. We also generalize our approach towards the encoding of smart contract transactions that involve an arbitrary number of accounts. Likewise, we rely on real blockchain data to show the savings allowed by our approach. The experimental evaluation is based on transactions from the Ethereum network and demonstrates cost reduction for both payment transactions and smart contract transactions.
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 15:17:44 +0000</pubDate>
</item>
<item>
<title>Randomness in Private Sequential Stateless Protocols</title>
<link>https://eprint.iacr.org/2024/1448</link>
<guid>https://eprint.iacr.org/2024/1448</guid>
<content:encoded><![CDATA[
<div> 关键词：信息论密码学、随机性复杂度、私密计算、分支程序、Private Sequential Stateless（PSS）模型

总结:

本文在信息论密码学领域对随机性在私密计算中的作用进行了深入研究。主要贡献如下：

1. **新模型与分类**：文章引入了Private Sequential Stateless（PSS）模型，探索了该模型下具有固定复杂度随机性的函数类别。这些函数被证明与具有常宽分支程序紧密相关。

2. **构造与转换**：通过构建一种新颖的PSS协议，针对所谓的“强正交分支程序”（SRBP），该文展示了任何具有常宽的分支程序都可以被转换为常宽的SRBP，从而证实了上述分类的一边。

3. **双向论证**：利用Kushilevitz等人在通信和随机性之间的转换思想，文章提供了从SRBP到具有固定复杂度随机性的函数的反向论证，完成了分类的双向证明。

4. **效率与实用性**：所提出的协议不仅结构简单，而且在理论上覆盖了具有小宽度、一次读取（或多次读取）的分支程序类函数，这在考虑1隐私时可能具有实际应用价值。

5. **改进与扩展**：作为结果的副产品，文章还提供了一种对Couteau和Rosén关于AND函数的协议的改进，虽然在随机性数量上没有提升，但在协议结构上实现了更简单的序列化和无状态化。

通过上述贡献，本文不仅深化了对随机性复杂度在私密计算中作用的理解，也为特定类型函数的私密计算提供了更高效、更实用的解决方案。 <div>
A significant body of work in information-theoretic cryptography has been devoted to the fundamental problem of understanding the power of randomness in private computation. This has included both in-depth study of the randomness complexity of specific functions (e.g., Couteau and Ros ́en, ASIACRYPT 2022, gives an upper bound of 6 for n-party $\mathsf{AND}$), and results for broad classes of functions (e.g., Kushilevitz et al. STOC 1996, gives an $O(1)$ upper bound for all functions with linear-sized circuits). In this work, we make further progress on both fronts by studying randomness complexity in a new simple model of secure computation called Private Sequential Stateless (PSS) model.
We show that functions with $O(1)$ randomness complexity in the PSS model are exactly those with constant-width branching programs, restricting to “speak-constant-times” protocols and to “read-constant-times” branching programs.
Towards this our main construction is a novel PSS protocol for “strongly regular branching programs” (SRBP). As we show, any constant-width branching program can be converted to a constant-width SRBP, yielding one side of our characterization. The converse direction uses ideas from Kushilevitz et al. to translate randomness to communication.
Our protocols are concretely efficient, has a simple structure, covers the broad class of functions with small-width, read-once (or read-a-few-times) branching programs, and hence may be of practical interest when 1-privacy is considered adequate. Also, as a consequence of our general result for SRBPs, we obtain an improvement over the protocol of Couteau and Ros ́en for $\mathsf{AND}$ in certain cases — not in terms of the number of bits of randomness, but in terms of a simpler protocol structure (sequential, stateless).
]]></content:encoded>
<pubDate>Tue, 17 Sep 2024 08:22:52 +0000</pubDate>
</item>
<item>
<title>Another Walk for Monchi</title>
<link>https://eprint.iacr.org/2024/1445</link>
<guid>https://eprint.iacr.org/2024/1445</guid>
<content:encoded><![CDATA[
<div> 关键词：Monchi、隐私保护、生物识别、同态加密、函数秘密共享

文章主要探讨了将Bassit等人的生物识别技术与Monchi协议相结合的方法。首先，文章提出了一种扩展的生物识别解决方案，该方案利用函数秘密共享来替代最终评分比较步骤中的同态乘法操作。其次，文章介绍了使用查找表计算评分的两方计算方法，该方法与函数秘密共享的评分比较相兼容。这些解决方案特别适用于Monchi协议中提出的登机流程场景。

文章的主要内容包括：

1. 将Bassit等人引入的评分计算技术与Monchi协议相结合，通过使用函数秘密共享来优化评分比较过程，以减少对同态乘法的需求。
2. 提出了一个使用查找表进行评分计算的两方计算方法，这种方法与函数秘密共享的评分比较方式协同工作，进一步增强了隐私保护。
3. 所提出的解决方案旨在适应Monchi协议中所描述的飞行登机场景，强调了在实际应用中如何实现高效和安全的生物特征识别系统。
4. 文章详细讨论了如何通过引入查找表和函数秘密共享来优化评分计算和比较过程，从而提高隐私保护级别和计算效率。
5. 最终目标是在不牺牲隐私的前提下，提供一种安全、高效、易于集成到现有登机流程中的生物识别解决方案。

总结: 通过将Bassit等人引入的评分计算技术与Monchi协议结合，文章提出了利用函数秘密共享优化评分比较过程的方法，并引入了查找表进行评分计算的两方计算，旨在提升生物识别系统的隐私保护水平和计算效率。这些解决方案特别适合于飞行登机场景，为实际应用提供了高效、安全的生物特征识别解决方案。 <div>
Monchi is a new protocol aimed at privacy-preserving biometric identification. It begins with scores computation in the encrypted domain thanks to homomorphic encryption and ends with comparisons of these scores to a given threshold with function secret sharing. We here study the integration in that context of scores computation techniques recently introduced by Bassit et al. that eliminate homomorphic multiplications by replacing them by lookup tables. First, we extend this lookup tables biometric recognition solution by adding the use of function secret sharing for the final comparison of scores. Then, we introduce a two-party computation of the scores with lookup tables which fits nicely together with the function secret sharing scores comparison. Our solutions accommodate well with the flight boarding use case introduced by Monchi.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 16:17:32 +0000</pubDate>
</item>
<item>
<title>FlashSwift: A Configurable and More Efficient Range Proof With Transparent Setup</title>
<link>https://eprint.iacr.org/2024/1441</link>
<guid>https://eprint.iacr.org/2024/1441</guid>
<content:encoded><![CDATA[
<div> 关键词：FlashSwift、DLOG、零知识证明、范围证明、透明设置

总结:

本文介绍了一种名为FlashSwift的新零知识范围证明方法，它基于离散对数(DLOG)假设，采用透明设置。FlashSwift在现有技术的基础上实现了更短的证明长度和显著的计算效率提升，特别是在常见范围内(N≤64)。它通过融合Flashproof和SwiftRange的技术，克服了两者之间的固有不兼容性。当N=64时，FlashSwift与Bulletproof在通信效率上相当，但在证明效率、验证效率上分别提高了2.3倍和1.65倍，与SwiftRange相比，提高了3.2倍和1.7倍。此外，FlashSwift在没有可信设置的情况下，创造了8位和16位范围内最小证明大小的新记录（289字节和417字节）。最重要的是，FlashSwift具有可配置性，允许用户根据不同的需求在通信效率和计算效率之间进行权衡。文章还提供了与其他最新技术的全面性能基准测试，以展示其实际应用的可行性。 <div>
Bit-decomposition-based zero-knowledge range proofs in the discrete logarithm (DLOG) setting with a transparent setup, e.g., Bulletproof (IEEE S\&amp;P \textquotesingle 18), Flashproof (ASIACRYPT \textquotesingle 22), and SwiftRange (IEEE S\&amp;P \textquotesingle 24), have garnered widespread popularity across various privacy-enhancing applications. These proofs aim to prove that a committed value falls within the non-negative range $[0, 2^N-1]$ without revealing it, where $N$ represents the bit length of the range. Despite their prevalence, the current implementations still suffer from suboptimal performance. Some exhibit reduced communication costs at the expense of increased computational costs while others experience the opposite. Presently, users are compelled to utilize these proofs in scenarios demanding stringent requirements for both communication and computation efficiency.

In this paper, we introduce, FlashSwift, a stronger DLOG-based logarithmic-sized alternative. It stands out for its greater shortness and significantly enhanced computational efficiency compared with the cutting-edge logarithmic-sized ones for the most common ranges where $N \leq 64$. It is developed by integrating the techniques from Flashproof and SwiftRange without using a trusted setup. The substantial efficiency gains stem from our dedicated efforts in overcoming the inherent incompatibility barrier between the two techniques. Specifically, when $N=64$, our proof achieves the same size as Bulletproof and exhibits 1.1$\times$ communication efficiency of SwiftRange. More importantly, compared with the two, it achieves $2.3\times$ and $1.65\times$ proving efficiency, and $3.2\times$ and $1.7\times$ verification efficiency, respectively. At the time of writing, our proof also creates two new records of the smallest proof sizes, 289 bytes and 417 bytes, for 8-bit and 16-bit ranges among all the bit-decomposition-based ones without requiring trusted setups. Moreover, to the best of our knowledge, it is the first {\em configurable} range proof that is adaptable to various scenarios with different specifications, where the configurability allows to trade off communication efficiency for computational efficiency. In addition, we offer a bonus feature: FlashSwift supports the aggregation of multiple single proofs for efficiency improvement. Finally, we provide comprehensive performance benchmarks against the state-of-the-art ones to demonstrate its practicality.
]]></content:encoded>
<pubDate>Mon, 16 Sep 2024 08:17:02 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Proof-of-Identity: Sybil-Resistant, Anonymous Authentication on Permissionless Blockchains and Incentive Compatible, Strictly Dominant Cryptocurrencies</title>
<link>https://eprint.iacr.org/2019/546</link>
<guid>https://eprint.iacr.org/2019/546</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、身份验证、区块链、挖矿、社会最优

总结: 文章提出了一种基于零知识证明的“零知识证明的身份验证”（zk-PoI）机制，旨在解决无许可区块链中存在的问题，如工作量证明（PoW）和权益证明（PoS）的高能耗、环境影响、资本囤积和交易量限制等。该机制允许每个人加入区块链网络并限制个人控制的挖矿节点数量，从而避免了完全去中心化的不可能性和区块链可扩展性三难困境。同时，文章论证了zk-PoI具有激励兼容的加密货币奖励发放协议、矿工选择其作为最优策略的纳什均衡和演化稳定策略、避免了加密无政府状态的价格损失、在流通量上优于其他PoW/PoS加密货币、以及从国家身份证和电子护照固有的社会网络中产生的网络效应优于其他加密货币。最后，由于其较低的基础设施成本，zk-PoI存在唯一的优势平衡点，使其成为其他支付形式的主导者。 <div>
Zero-Knowledge Proof-of-Identity from trusted public certificates (e.g., national identity cards and/or ePassports; eSIM) is introduced here to permissionless blockchains in order to remove the inefficiencies of Sybil-resistant mechanisms such as Proof-of-Work (i.e., high energy and environmental costs) and Proof-of-Stake (i.e., capital hoarding and lower transaction volume). The proposed solution effectively limits the number of mining nodes a single individual would be able to run while keeping membership open to everyone, circumventing the impossibility of full decentralization and the blockchain scalability trilemma when instantiated on a blockchain with a consensus protocol based on the cryptographic random selection of nodes. Resistance to collusion is also considered.
Solving one of the most pressing problems in blockchains, a zk-PoI cryptocurrency is proved to have the following advantageous properties:
- an incentive-compatible protocol for the issuing of cryptocurrency rewards based on a unique Nash equilibrium
- strict domination of mining over all other PoW/PoS cryptocurrencies, thus the zk-PoI cryptocurrency becoming the preferred choice by miners is proved to be a Nash equilibrium and the Evolutionarily Stable Strategy
- PoW/PoS cryptocurrencies are condemned to pay the Price of Crypto-Anarchy, redeemed by the optimal efficiency of zk-PoI as it implements the social optimum
- the circulation of a zk-PoI cryptocurrency Pareto dominates other PoW/PoS cryptocurrencies
- the network effects arising from the social networks inherent to national identity cards and ePassports dominate PoW/PoS cryptocurrencies
- the lower costs of its infrastructure imply the existence of a unique equilibrium where it dominates other forms of payment
]]></content:encoded>
<pubDate>Wed, 22 May 2019 11:23:04 +0000</pubDate>
</item>
<item>
<title>Non-interactive Blind Signatures: Post-quantum and Stronger Security</title>
<link>https://eprint.iacr.org/2024/614</link>
<guid>https://eprint.iacr.org/2024/614</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、非交互式盲签名（NIBS）、电路私有层化同态加密、后量子安全性、增强安全性

文章总结：

本文探讨了非交互式盲签名（NIBS）在设计更高效盲签名方案中的应用。非交互式盲签名允许接收者异步生成对任意接收者的部分签名，只有意图接收者才能从中提取出随机消息的盲签名。这一创新克服了传统盲签名的两轮交互限制，同时保持了广泛的应用能力。文章引用Hanzlik在Eurocrypt '23的贡献，展示了利用双线性对提供了新实用设计。

进一步地，作者提出了NIBS的增强安全性属性，并提供了一系列具有不同安全性和具体效率级别的构造。其中一种新颖的通用范式采用电路私有层化同态加密技术，以达到与任何非盲签名相同的最优大小签名，但需要较大的公钥。此外，文章还探索了具有后量子安全性的具体高效NIBS实现，满足了Hanzlik提出的较弱隐私水平要求。

此研究为构建更高效、安全的NIBS方案提供了理论基础和实践路径，对密码学领域尤其是非交互式通信和数据保护有着重要意义。通过结合先进加密技术与优化的安全策略，该工作不仅推动了NIBS理论的发展，也为实际应用提供了可能。 <div>
Blind signatures enable a receiver to obtain signatures on messages of its choice without revealing any message to the signer. Round-optimal blind signatures are designed as a two-round interactive protocol between a signer and receiver. Coincidentally, the choice of message is not important in many applications, and is routinely set as a random (unstructured) message by a receiver.

With the goal of designing more efficient blind signatures for such applications, Hanzlik (Eurocrypt '23) introduced a new variant called non-interactive blind signatures (NIBS). These allow a signer to asynchronously generate partial signatures for any recipient such that only the intended recipient can extract a blinded signature for a random message. This bypasses the two-round barrier for traditional blind signatures, yet enables many known applications. Hanzlik provided new practical designs for NIBS from bilinear pairings.

In this work, we propose new enhanced security properties for NIBS as well as provide multiple constructions with varying levels of security and concrete efficiency. We propose a new generic paradigm for NIBS from circuit-private leveled homomorphic encryption achieving optimal-sized signatures (i.e., same as any non-blind signature) at the cost of large public keys. We also investigate concretely efficient NIBS with post-quantum security, satisfying weaker level of privacy as proposed by Hanzlik.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 03:29:45 +0000</pubDate>
</item>
<item>
<title>Dishonest Majority Multiparty Computation over Matrix Rings</title>
<link>https://eprint.iacr.org/2023/1912</link>
<guid>https://eprint.iacr.org/2023/1912</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护机器学习、矩阵乘法、线性代数、多方计算、亚线性通信复杂度

总结:
本文提出了一种针对矩阵环的不诚实多数多方计算(MPC)协议，专门支持矩阵乘法和加法操作。该协议可视为SPDZ协议的变体，其秘密为一个m×m矩阵，密钥和认证码长度也为m。相较于经典SPDZ协议，新协议在安全计算矩阵乘法时的通信复杂度至少降低了m倍。与[16]中提出的针对矩阵运算的不诚实多数MPC协议相比，通信复杂度同样为O(m²n²logq)在预处理阶段和O(m²nlogq)在在线阶段。新协议的份额大小和乘法次数分别比[16]减少了约50%和40%，但采取了完全不同的方法。[16]协议使用BFV方案的变体将整个矩阵嵌入单个密文，并将矩阵操作视为密文内的元素级操作，而新协议则利用子域盲线性评估(VOLE)的变体进行安全计算，使得对于v∈F_q^b, x∈F_q^a，可以以亚线性通信复杂度计算v*x的共享值。此外，新协议易于扩展到小域。

文章的核心贡献在于提出了一个优化的MPC协议，旨在减少计算和通信成本，特别适用于大规模机器学习模型，如深度学习中的矩阵运算。通过引入子域盲线性评估技术，实现了在保持安全性的前提下，显著降低通信复杂度，提高了协议的效率。 <div>
The privacy-preserving machine learning (PPML) has gained growing importance over the last few years. One of the biggest challenges is to improve the efficiency of PPML so that the communication and computation costs of PPML are affordable for large machine learning models such as deep learning. As we know, linear algebra such as matrix multiplication occupies a significant part of the computation in deep learning such as deep convolutional neural networks (CNN). Thus, it is desirable to propose the MPC protocol specialized for the matrix operations. In this work, we propose a dishonest majority MPC protocol over matrix rings which supports matrix multiplication and addition. Our MPC protocol can be seen as a variant of SPDZ protocol, i.e., the MAC and global key of our protocol are vectors of length $m$ and the secret of our protocol is an $m\times m$ matrix. Compared to the classic SPDZ protocol, our MPC protocol reduces the communication complexity by at least $m$ times to securely compute a matrix multiplication. We also show that the communication complexity of our MPC protocol is asymptotically as good as [16] which also presented a dishonest majority MPC protocol specialized for matrix operations, i.e., the communication complexity of securely computing a multiplication gate is $O(m^2n^2\log q)$ in the preprocessing phase and $O(m^2n\log q)$ in the online phase. The share size and the number of multiplications of our protocol are reduced by around $50\%$ and $40\%$ of [16], respectively. However, we take a completely different approach. The protocol in [16] uses a variant of BFV scheme to embed a whole matrix into a single ciphertext and then treats the matrix operation as the entry-wise operation in the ciphertext while our approach resorts to a variant of vector linear oblivious evaluation (VOLE) called the subfield VOLE [33] which can securely compute the additive sharing of $v {\bf x}$ for $v\in \mathbb{F}_{q^b}, {\bf x}\in \mathbb{F}_q^a$ with sublinear communication complexity. Finally, we note that our MPC protocol can be easily extended to small fields.
]]></content:encoded>
<pubDate>Wed, 13 Dec 2023 06:32:33 +0000</pubDate>
</item>
<item>
<title>HierNet: A Hierarchical Deep Learning Model for SCA on Long Traces</title>
<link>https://eprint.iacr.org/2024/1437</link>
<guid>https://eprint.iacr.org/2024/1437</guid>
<content:encoded><![CDATA[
<div> 关键词：侧通道分析（SCA）、深度学习（DL）、长原始轨迹、特征选择、抗干扰性

总结:
本文探讨了侧通道分析（SCA）中的挑战及其解决策略。SCA通过利用诸如功率消耗、电磁辐射或时间变化等侧信道泄露来威胁现代数字系统的安全性和隐私。传统的SCA方法依赖于特征选择步骤，但这种方法可能受到掩码和抖动等防御措施的影响。为了解决这些问题，本文提出了一种基于深度学习的层次模型——HierNet，该模型能够处理长原始轨迹数据，并且具有对抗各种干扰措施的能力。

HierNet采用两级信息整合过程来提取信息：首先，低级的深度学习模型利用移不变特性从较小的轨迹段中提取信息；其次，高级的深度学习模型整合低级模型的输出以生成最终结果。实验结果显示，HierNet在处理长轨迹、对抗时钟抖动以及训练数据量较少的情况下均表现出色。与现有的SCA基准模型相比，HierNet在某些场景下表现出优越性，特别是在使用较少的训练样本达到特定性能目标时。这表明HierNet为SCA提供了一种新的、更有效的解决方案，特别是针对长轨迹和对抗多种防御措施的情况。 <div>
Side-channel analysis (SCA) compromises the security of cryptographic devices by exploiting various side-channel leakages such as power consumption, electromagnetic (EM) emanations, or timing variations, posing a practical threat to the security and privacy of modern digital systems. In power or EM SCA, statistical or machine learning methods are employed to extract secret information from power/EM traces. In many practical scenarios, raw power/EM traces can span hundreds of thousands of features, with relevant leakages occurring over only a few small segments. Consequently, existing SCAs often select a small number of features before launching the attack, making their success highly dependent on the feasibility of feature selection. However, feature selection may not always be possible, such as in the presence of countermeasures like masking or  jitters.

Several recent works have employed deep learning (DL) methods to conduct SCA on long raw traces, thereby reducing dependence on feature selection steps. However, these methods often perform poorly against various jitter-based countermeasures. While some of these methods have shown high robustness to jitter-based countermeasures on relatively shorter traces, we demonstrate in this work that their performance deteriorates as trace lengths increase. Based on these observations, we develop a hierarchical DL model for SCA on long traces that is robust against various countermeasures. The proposed model, HierNet, extracts information from long traces using a two-level information assimilation process. At the base level, a DL model with shift-invariance is employed to extract information from smaller trace segments. Subsequently, a top-level DL model integrates the outputs of the base model to generate the final output. The proposed model has been experimentally evaluated against various combinations of masking, random delay, and clock jitter countermeasures using traces with lengths exceeding $200K$ features. The results have been compared with three existing SCA benchmark models. They demonstrate HierNet's superiority in several scenarios, such as on long traces, against clock jitter countermeasures, and low training data scenarios. In particular, while other models fail to reach the guessing entropy $1$ using as many as $5K$ traces, HierNet achieves the same with fewer than or close to $10$ traces.
]]></content:encoded>
<pubDate>Sat, 14 Sep 2024 09:47:21 +0000</pubDate>
</item>
<item>
<title>$Shortcut$: Making MPC-based Collaborative Analytics Efficient on Dynamic Databases</title>
<link>https://eprint.iacr.org/2024/1433</link>
<guid>https://eprint.iacr.org/2024/1433</guid>
<content:encoded><![CDATA[
<div> 关键词：Secure Multi-party Computation（MPC）、Multi-party Computation（MCASs）、动态数据库、查询结果更新（QRU）协议、性能优化

总结:
本文提出了名为“Shortcut”的框架，旨在与基于MPC的协作分析系统（MCASs）结合，以提高对动态数据库的查询效率。动态数据库支持数据插入、删除和更新操作。传统的MCASs在处理这些动态变化时效率低下，主要原因是重复内容导致的大量冗余计算。为解决这一问题，“Shortcut”框架的核心理念是预存历史查询结果，并通过自定义的查询结果更新（QRU）协议来直接更新这些结果，从而获得当前的查询结果。

为了实现这一目标，“Shortcut”为常见的SQL操作，如Order-by-Limit、Group-by-Aggregate、Distinct、Join、Select和Global Aggregate，定制了高效的QRU协议。这些协议不仅能够相容以实现各种查询功能，而且特别设计了两种常数轮次的协议来支持数据插入和删除操作。这些协议可以作为其他协议的基础构建块，并且具有独立的研究价值，解决了安全地将一行数据插入或从有序表中删除，同时保持其顺序的问题。

实验结果显示，“Shortcut”在处理动态数据库中的小幅度更新时，相比于传统MCASs，能够实现高达186.8倍的性能提升。例如，对于动态数据库中数量级在2^16到2^20之间的数据，仅对单个查询进行一次插入操作，“Shortcut”就能实现显著的性能改进。这表明“Shortcut”框架对于许多现实应用（如保险服务、账户数据管理等）的需求有很好的适应性和高效性。 <div>
Secure Multi-party Computation (MPC) provides a promising solution for privacy-preserving multi-source data analytics. However, existing MPC-based collaborative analytics systems (MCASs) have unsatisfying performance for scenarios with dynamic databases. Naively running an MCAS on a dynamic database would lead to significant redundant costs and raise performance concerns, due to the substantial duplicate contents between the pre-updating and post-updating databases. 

In this paper, we propose $Shortcut$, a framework that can work with MCASs to enable efficient queries on dynamic databases that support data insertion, deletion, and update. The core idea of $Shortcut$ is to materialize previous query results and directly update them via our query result update (QRU) protocol to obtain current query results. We customize several efficient QRU protocols for common SQL operators, including Order-by-Limit, Group-by-Aggregate, Distinct, Join, Select, and Global Aggregate. These protocols are composable to implement a wide range of query functions. In particular, we propose two constant-round protocols to support data insertion and deletion. These protocols can serve as important building blocks of other protocols and are of independent interest. They address the problem of securely inserting/deleting a row into/from an ordered table while keeping the order. Our experiments show that $Shortcut$ outperforms naive MCASs for minor updates arriving in time, which captures the need of many realistic applications (e.g., insurance services, account data management). For example, for a single query after an insertion, $Shortcut$ achieves up to $186.8 \times$ improvement over those naive MCASs without our QRU protocols on a dynamic database with $2^{16} \sim 2^{20}$ rows, which is common in real-life applications.
]]></content:encoded>
<pubDate>Fri, 13 Sep 2024 04:20:57 +0000</pubDate>
</item>
<item>
<title>Powerformer: Efficient Privacy-Preserving Transformer with Batch Rectifier-Power Max Function and Optimized Homomorphic Attention</title>
<link>https://eprint.iacr.org/2024/1429</link>
<guid>https://eprint.iacr.org/2024/1429</guid>
<content:encoded><![CDATA[
<div> 关键词：Powerformer、非交互式、隐私保护、Transformer、高效算法

总结:文章提出了一种名为Powerformer的高效非交互式隐私保护Transformer推理架构。该架构通过引入基于ReLU的新函数“Batch Rectifier-Power max”（BRPmax）来替换softmax操作，解决了先前研究中因使用多轮Bootstrapping而导致的精度下降和执行时间延长问题。BRPmax函数无需任何不稳定近似方法，即使在BERT-Large模型中也能超越原始BERT性能，仅需单次Bootstrapping。此外，文章还提供了针对注意力块的矩阵乘法算法，相较于现有最优方法，可减少35%至91%的关键切换次数。最后，设计了清晰的基于HE的私有Transformer模型端到端实现，并实现了使用RNS-CKKS的Powerformer模型在单线程CPU上的运行时间为503秒，这是已知的首个使用HE的非交互式Transformer端到端实现。 <div>
We propose an efficient non-interactive privacy-preserving Transformer inference architecture called Powerformer. Since softmax is a non-algebraic operation, previous studies have attempted to modify it to be HE-friendly, but these methods have encountered issues with accuracy degradation or prolonged execution times due to the use of multiple bootstrappings. We propose replacing softmax with a new ReLU-based function called the \textit{Batch Rectifier-Power max} (BRPmax) function without any unstable approximation methods, which outperforms even original BERT performance within BERT-Large model while requiring fewer levels, allowing it to operate with only a single bootstrapping. We also present a matrix multiplication algorithms specialized for attention block that reduce the number of key-switchings by 35% to 91% compared to existing state-of-the-art methods. We design clear end-to-end HE-based implementation for private Transformer model, and our implementation of Powerformer on the BERT-tiny model using RNS-CKKS takes 503 seconds on a single-threaded CPU, and to the best of our knowledge, this is the first end-to-end non-interactive Transformer implementation using HE.
]]></content:encoded>
<pubDate>Thu, 12 Sep 2024 06:04:04 +0000</pubDate>
</item>
<item>
<title>Evolving Secret Sharing Made Short</title>
<link>https://eprint.iacr.org/2023/1534</link>
<guid>https://eprint.iacr.org/2023/1534</guid>
<content:encoded><![CDATA[
<div> 关键词：Evolving Secret Sharing, Komargodski, Naor, Yogev, TCC’16, Computational Setting

在这篇论文中，研究者们针对演进型秘密共享（Komargodski, Naor, and Yogev在TCC’16提出的概念）展开了系统性的研究。在演进型秘密共享中，成员可以动态地加入系统，且系统初始时并不知道最终的最大成员数或访问结构。研究的目标是在保证计算安全的前提下，最小化新成员加入时对现有成员份额的影响，并且使份额大小相对于成员数量保持较小。

主要发现包括：

1. 对于多种实用且重要的访问结构类型（如图访问结构、DNF和CNF公式访问结构、单调电路访问结构以及阈值访问结构），在标准假设下，存在高效的计算隐私秘密分享方案，其中份额大小远小于自然表示演进访问结构所需的数据量。

2. 研究引入了演进型秘密共享在计算环境下的概念，允许最大成员数为安全参数的多项式函数，但同时仍不知道具体数值，进一步增强了其实际应用性。

3. 提出了针对特定类型访问结构的有效秘密分享方案设计方法，这些方案不仅满足计算隐私要求，而且能够显著减少成员加入时的份额更新复杂度，从而提高系统效率和可扩展性。

4. 结果表明，通过适当的假设和技术手段，可以在不牺牲安全性的同时，实现高效、适应动态成员变化的秘密分享机制，这对于需要处理大量动态成员的分布式系统具有重要意义。

5. 这一研究为演进型秘密共享领域提供了新的理论基础和实践指导，有助于促进相关技术在网络安全、云计算、区块链等领域的应用和发展。

总结: 本文通过系统性研究，揭示了在计算环境下，如何有效实现演进型秘密共享，特别是在未知最大成员数和访问结构的情况下，提出了一种能够保持计算隐私、确保份额大小合理、适应动态成员变化的秘密分享方案，特别针对多种实用访问结构类型进行了深入探讨，为未来分布式系统中的成员动态管理提供了重要理论支持与实践指南。 <div>
Evolving secret sharing (Komargodski, Naor, and Yogev, TCC’16) generalizes the notion of secret sharing to the setting of evolving access structures, in which the share holders are added to the system in an online manner, and where the dealer does not know neither the access structure nor the maximum number of parties in advance. Here, the main difficulty is to distribute shares to the new players without updating the shares of old players; moreover, one would like to minimize the share size as a function of the number of players.
In this paper, we initiate a systematic study of evolving secret sharing in the computational setting, where the maximum number of parties is polynomial in the security parameter, but the dealer still does not know this value, neither it knows the access structure in advance. Moreover, the privacy guarantee only holds against computationally bounded adversaries corrupting an unauthorized subset of the players.
Our main result is that for many interesting, and practically relevant, evolving access structures (including graphs access structures, DNF and CNF formulas access structures, monotone circuits access structures, and threshold access structures), under standard hardness assumptions, there exist efficient secret sharing schemes with computational privacy and in which the shares are succinct (i.e., much smaller compared to the size of a natural computational representation of the evolving access structure).
]]></content:encoded>
<pubDate>Sat, 07 Oct 2023 10:43:21 +0000</pubDate>
</item>
<item>
<title>New Secret Keys for Enhanced Performance in (T)FHE</title>
<link>https://eprint.iacr.org/2023/979</link>
<guid>https://eprint.iacr.org/2023/979</guid>
<content:encoded><![CDATA[
<div> 关键词：全同态加密、GLWE、改进、安全性、性能提升

总结:本文提出了一种改进全同态加密（FHE）技术的方法，主要针对GLWE（Gaussian Learning With Errors）基方案。文章识别了两种FHE技术的局限性：一是无法精确控制GLWE密钥大小；二是由于安全原因，无法使用低于特定值的噪声方差，导致在某些情况下无法灵活调整安全级别，造成不必要的高安全设置。为解决这些问题，作者引入了两种新的GLWE密钥类型，这些新密钥既保证了与传统密钥同等的安全性，又带来了性能上的显著提升。

具体来说，新密钥系统使得在保持相同安全性和失败概率的前提下，计算速度可以提升1.3到2.4倍。同时，关键转换和启动密钥的大小也分别减少了1.5到2.7倍。这些改进不仅提高了加密系统的效率，而且扩展了其应用范围，特别是在处理敏感信息保护方面具有重要意义。通过对比现有TFHE技术与传统密钥方法，研究证明了新密钥系统的优越性，为全同态加密技术的进一步发展提供了有力支持。 <div>
Fully Homomorphic Encryption has known impressive improvements in the last 15 years, going from a technology long thought to be impossible to an existing family of encryption schemes able to solve a plethora of practical use cases related to the privacy of sensitive information. 
Recent results mainly focus on improving techniques within the traditionally defined framework of GLWE-based schemes, but the recent CPU implementation improvements are mainly incremental.
To keep improving this technology, one solution is to modify the aforementioned framework, by using slightly different hardness assumptions.
In this paper, we identify two limitations with (T)FHE:
(i) there is no fine-grained control over the size of a GLWE secret key, which is traditionally composed of $k$ polynomials with $N=2^\alpha>1$ coefficients;
(ii) for security reasons one cannot use a noise variance smaller than a certain $\sigma_{\min}$ so, for all ciphertext modulus $q\in \mathbb{N}$, there exists an integer 
$n_{\mathsf{plateau}}$ such that, with any secret key of size  $k\cdot N \ge n_{\mathsf{plateau}}$, one cannot control their level of security, resulting in unnecessary big security levels.
To overcome the aforementioned limitations, we introduce two new types of secret keys for GLWE-based cryptosystems, that can be used separately or together.
We explain why these new secret keys are as secure as the traditional ones and we detail all the improvements that they bring to existing FHE algorithms alongside new algorithms especially efficient with these new keys.
We provide many comparisons with state-of-the-art TFHE techniques with traditional secret keys, and some benchmarks showing computational speed-ups between $1.3$ and $2.4$ while keeping the same level of security and failure probability (correctness).
Furthermore, the size of the key switching and bootstrapping keys is also reduced with this contribution by factors ranging from $1.5$ to $2.7$.
]]></content:encoded>
<pubDate>Fri, 23 Jun 2023 08:44:49 +0000</pubDate>
</item>
<item>
<title>SmartZKCP: Towards Practical Data Exchange Marketplace Against Active Attacks</title>
<link>https://eprint.iacr.org/2024/941</link>
<guid>https://eprint.iacr.org/2024/941</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、数据市场、零知识证明、智能合约、安全优化

总结:

本文探讨了将基于区块链的零知识条件支付（ZKCP）协议应用于公共数据市场的可能性及其潜在挑战。ZKCP协议通过区块链技术和零知识证明为数字商品提供无信任的公平交换，但在实际数据市场中应用时存在多种安全风险。

针对这些问题，文章提出了一种改进方案——SmartZKCP，旨在增强安全性并优化性能。SmartZKCP不仅确保了协议的正式化实现以维护公平性，还针对可能的攻击进行了强化防御。同时，该协议还实现了效率提升和通信成本的降低。

通过评估结果，SmartZKCP被证明既实用又高效，符合数据交换市场的应用需求。这一改进方案克服了ZKCP在实际部署中遇到的障碍，提供了更加安全和高效的交易环境，为数据市场的发展提供了有力支持。 <div>
The trading of data is becoming increasingly important as it holds substantial value. A blockchain-based data marketplace can provide a secure and transparent platform for data exchange. To facilitate this, developing a fair data exchange protocol for digital goods has garnered considerable attention in recent decades. The Zero Knowledge Contingent Payment (ZKCP) protocol enables trustless fair exchanges with the aid of blockchain and zero-knowledge proofs. However, applying this protocol in a practical data marketplace is not trivial.

In this paper, several potential attacks are identified when applying the ZKCP protocol in a practical public data marketplace. To address these issues, we propose SmartZKCP, an enhanced solution that offers improved security measures and increased performance. The protocol is formalized to ensure fairness and secure against potential attacks. Moreover, SmartZKCP offers efficiency optimizations and minimized communication costs. Evaluation results show that SmartZKCP is both practical and efficient, making it applicable in a data exchange marketplace.
]]></content:encoded>
<pubDate>Wed, 12 Jun 2024 07:23:45 +0000</pubDate>
</item>
<item>
<title>Kronos: A Secure and Generic Sharding Blockchain Consensus with Optimized Overhead</title>
<link>https://eprint.iacr.org/2024/206</link>
<guid>https://eprint.iacr.org/2024/206</guid>
<content:encoded><![CDATA[
<div> 关键词：Kronos、安全、低延迟、高吞吐量、通用框架

总结:

本文提出了一种名为Kronos的安全分片区块链共识机制，旨在优化分片网络的效率与安全性。Kronos的核心创新在于引入了一个由分片成员联合管理的缓冲区，用于传输有效交易并拒绝无效交易。这种设计确保了在恶意客户端存在的情况下，系统仍能实现原子性，并保持最优的分片内开销。

Kronos特别关注跨分片交易带来的挑战，通过高效拒绝机制，即使在快乐路径中也不需要执行拜占庭容错(BFT)协议，而在不快乐路径中的成本也仅相当于两阶段提交。此外，文章还提出了安全的跨分片认证方法，证明了处理b个交易时，Kronos的跨分片通信开销为O(n b λ)，其中n代表分片大小，λ为安全参数。这一特性使得Kronos成为增强现有BFT协议性能和可扩展性的通用框架。

Kronos支持异步网络等通用模型，并展示了在实际部署中显著提升的吞吐量（可达320 ktx/sec，延迟2.0秒），在处理跨分片交易工作负载时，相较于过去解决方案，Kronos表现出高达12倍的吞吐量提升和50%的延迟减少。 <div>
Sharding enhances blockchain scalability by dividing the network into shards, each managing specific unspent transaction outputs or accounts. As an introduced new transaction type, cross-shard transactions pose a critical challenge to the security and efficiency of sharding blockchains. Currently, there is a lack of a generic sharding blockchain consensus pattern that achieves both security and low overhead.

In this paper, we present Kronos, a secure sharding blockchain consensus achieving optimized overhead. In particular, we propose a new secure sharding blockchain consensus pattern, based on a buffer managed jointly by shard members. Valid transactions are transferred to the payee via the buffer, while invalid ones are rejected through happy or unhappy paths. Kronos is proved to achieve security with atomicity under malicious clients while maintaining optimal intra-shard overhead. Efficient rejection even requires no Byzantine fault tolerance (BFT) protocol execution in happy paths, and the cost in unhappy paths is still not higher than a two-phase commit. Besides, we propose secure cross-shard certification methods. Handling b transactions, Kronos is proved to achieve cross-shard communication with low cross-shard overhead O(n b \lambda) (n for the shard size and \lambda for the security parameter). Notably, Kronos imposes no restrictions on BFT and does not rely on timing assumptions, offering optional constructions in various modules. Kronos could serve as a universal framework for enhancing the performance and scalability of existing BFT protocols. Kronos supports generic models, including asynchronous networks, and can increase the throughput by several orders of magnitude.

We implement Kronos using two prominent BFT protocols: asynchronous Speeding Dumbo (NDSS'22) and partially synchronous Hotstuff (PODC'19). Extensive experiments (over up to 1000 AWS EC2 nodes across 4 AWS regions) demonstrate Kronos scales the consensus nodes to thousands, achieving a substantial throughput of 320 ktx/sec with 2.0 sec latency. Compared with the past solutions, Kronos outperforms, achieving up to a 12$\times$ improvement in throughput and a 50% reduction in latency when cross-shard transactions dominate the workload.
]]></content:encoded>
<pubDate>Sat, 10 Feb 2024 12:30:47 +0000</pubDate>
</item>
<item>
<title>Blind Multisignatures for Anonymous Tokens with Decentralized Issuance</title>
<link>https://eprint.iacr.org/2024/1406</link>
<guid>https://eprint.iacr.org/2024/1406</guid>
<content:encoded><![CDATA[
<div> 关键词:匿名令牌、去中心化发行、盲多重签名、BLS签名、离散对数

文章主要探讨了一种新的数字令牌形式——匿名令牌，该令牌允许用户从动态变化的签发者集合中获取，且每次获取过程都保持公开可验证和不可链接性。实现这一目标的关键在于引入了盲多重签名（BMS）的概念，它允许用户与多个签发者交互以获取签名，即使所有签发者合谋也无法将签名与任一交互链接起来。

文章提供了两种基于BLS签名和离散对数（无配对）的BMS构建方案，并证明了这些构建方案在代数群模型中的安全性。此外，还提供了一个原型实现，结果显示其验证操作成本较低，这对于区块链应用而言至关重要。

总结:
文章首先提出了一种新型的匿名令牌，这种令牌具有去中心化的发行机制，使得用户可以从任意一组签发者处获取令牌，且每次获取过程都保持匿名。实现这一机制的核心是盲多重签名技术，它允许用户与多个签发者进行交互并获得签名，即使所有签发者合谋也无法关联到具体的交互过程。文章分别设计了基于BLS签名和离散对数（不使用配对）的两种BMS构建方案，并证明了这些方案在代数群模型下的安全性。最后，通过原型实现展示了其验证操作的成本效益，这是区块链应用中至关重要的特性。 <div>
We propose the first constructions of anonymous tokens with decentralized issuance. Namely, we consider a dynamic set of signers/issuers; a user can obtain a token from any subset of the signers, which is publicly verifiable and unlinkable to the issuance process. To realize this new primitive we formalize the notion of Blind Multi-Signatures (BMS), which allow a user to interact with multiple signers to obtain a (compact) signature; even if all the signers collude they are unable to link a signature to an interaction with any of them.

We then present two BMS constructions, one based on BLS signatures and a second based on discrete logarithms without pairings. We prove security of both our constructions in the Algebraic Group Model.

We also provide a proof-of-concept implementation and show that it has low-cost verification, which is the most critical operation in blockchain applications.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 09:11:55 +0000</pubDate>
</item>
<item>
<title>Security Bounds for Proof-Carrying Data from Straightline Extractors</title>
<link>https://eprint.iacr.org/2023/1646</link>
<guid>https://eprint.iacr.org/2023/1646</guid>
<content:encoded><![CDATA[
<div> 关键词：证明携带数据、SNARK、直线下知识完整性、安全分析、递归组成

总结:

本文探讨了递归组成的实际应用和安全性分析。证明携带数据（PCD）是一种允许互不信任的各方以可验证的方式执行分布式计算的加密技术。当前的PCD构造通常是通过嵌套安全论证（SNARK）或相关原理实现的，但这种构建方式导致的安全性评估往往过于复杂，导致实践中对参数设置的忽视，因为这些评估会导致成本过高的参数选择。

文章的主要发现是，从具有“直线下知识完整性”的SNARK中获得的PCD实际上具有与基础SNARK相同的本质安全性，即递归组成不会造成安全性损失。通过分析在不同预言机模型中的SNARK如何实现直线下知识完整性，研究者提供了一种高效的安全性分析方法，该方法可以黑盒使用SNARK的预言机，而无需实例化预言机即可进行安全性推导。

作为应用示例，这项工作为区块链系统中使用的递归STARK的实用安全性提供了新的理论见解，尽管这些见解具有一定的启发性和假设性。这项研究为理解如何合理设置具有实际意义的PCD构造的参数提供了理论依据，同时也为解释实践者在设计递归STARK时所采用的参数选择策略提供了部分证据支持。 <div>
Proof-carrying data (PCD) is a powerful cryptographic primitive that allows mutually distrustful parties to perform distributed computation in an efficiently verifiable manner. Real-world deployments of PCD have sparked keen interest within the applied community and industry.

Known constructions of PCD are obtained by recursively-composing SNARKs or related primitives. Unfortunately, known security analyses incur expensive blowups, which practitioners have disregarded as the analyses would lead to setting parameters that are prohibitively expensive.

In this work we study the concrete security of recursive composition, with the goal of better understanding how to reasonably set parameters for certain PCD constructions of practical interest. Our main result is that PCD obtained from SNARKs with \emph{straightline knowledge soundness} has essentially the same security as the underlying SNARK (i.e., recursive composition incurs essentially no security loss).

We describe how straightline knowledge soundness is achieved by SNARKs in several oracle models, which results in a highly efficient security analysis of PCD that makes black-box use of the SNARK's oracle (there is no need to instantiated the oracle to carry out the security reduction).

As a notable application, our work offers an idealized model that provides new, albeit heuristic, insights for the concrete security of \emph{recursive STARKs} used in blockchain systems. Our work could be viewed as partial evidence justifying the parameter choices for recursive STARKs made by practitioners.
]]></content:encoded>
<pubDate>Tue, 24 Oct 2023 11:06:22 +0000</pubDate>
</item>
<item>
<title>Blockchain-based decentralized identity system: Design and security analysis</title>
<link>https://eprint.iacr.org/2024/597</link>
<guid>https://eprint.iacr.org/2024/597</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、物联网、设备间通信、分布式存储、智能合约

总结: 这篇论文提出了一种新型的基于区块链的去中心化身份系统（DID），专为增强物联网（IoT）和设备对设备（D2D）网络中的数字身份管理设计。该系统具有层次结构，巧妙地将分布式账本与移动D2D网络融合，确保了强大的安全性同时简化了通信流程。系统的核心在于网关节点，它们作为中介，通过智能合约和分布式存储系统实现DID注册和设备认证。全面的安全分析证明了该系统的抗常见网络攻击能力，并遵循了最终性与活生生原则等关键准则。 <div>
This paper presents a novel blockchain-based decentralized identity system (DID), tailored for enhanced digital identity management in Internet of Things (IoT) and device-to-device (D2D) networks. The proposed system features a hierarchical structure that effectively merges a distributed ledger with a mobile D2D network, ensuring robust security while streamlining communication. Central to this design are the gateway nodes, which serve as intermediaries, facilitating DID registration and device authentication through smart contracts and distributed storage systems. A thorough security analysis underscores the system’s resilience to common cyber threats and adherence to critical principles like finality and liveness.
]]></content:encoded>
<pubDate>Wed, 17 Apr 2024 08:51:29 +0000</pubDate>
</item>
<item>
<title>Privacy Comparison for Bitcoin Light Client Implementations</title>
<link>https://eprint.iacr.org/2024/1415</link>
<guid>https://eprint.iacr.org/2024/1415</guid>
<content:encoded><![CDATA[
<div> 关键词：轻客户端、SPV、Neutrino、隐私、可扩展性

总结:

本文深入探讨了比特币可扩展性问题中两种主要轻客户端实现方式——SPV和Neutrino——的隐私特性。通过定义一系列隐私度量指标，研究者对这些实现方式在实际比特币数据上的隐私表现进行了评估与比较，揭示了隐私与通信之间固有的权衡关系。同时，文章提出了一般性方法以增强现有轻客户端的隐私保护，并提出了一个新的基于SPV的轻客户端模型——聚合模型，该模型能够提供超过现有实现的更高隐私水平。

文章首先通过定义隐私度量指标来量化SPV和Neutrino的隐私特性，随后使用真实比特币数据进行评估，揭示了不同时间点上这两种轻客户端实现方式的隐私差异。进一步地，文章讨论了隐私和通信之间的权衡，指出为了获得更高的隐私，可能需要牺牲一定的通信效率或资源。在此基础上，文章提出了增强现有轻客户端隐私性的通用技术策略。

最后，文章引入了一个名为聚合模型的新SPV基轻客户端概念，通过详细分析证明了它相较于现有的轻客户端实现方式能提供更优的隐私性能。这一模型通过创新的设计，成功地在不显著增加通信开销的情况下，实现了对用户地址状态更新的更严格隐私保护，为提升比特币网络整体隐私性提供了新的思路和实践路径。 <div>
Light clients implement a simple solution for Bitcoin's scalability problem, as they do not store the entire blockchain but only the state of particular addresses of interest. To be able to keep track of the updated state of their addresses, light clients rely on full nodes to provide them with the required information. To do so, they must reveal information about the addresses they are interested in. This paper studies the two most common light client implementations, SPV and Neutrino with regards to their privacy. We define privacy metrics for comparing the privacy of the different implementations. We evaluate and compare the privacy of the implementations over time on real Bitcoin data and discuss the inherent privacy-communication tradeoff. In addition, we propose general techniques to enhance light client privacy in the existing implementations. Finally, we propose a new SPV-based light client model, the aggregation model, evaluate it, and show it can achieve enhanced privacy than in the existing light client implementations.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 19:17:19 +0000</pubDate>
</item>
<item>
<title>Code-Based Zero-Knowledge from VOLE-in-the-Head and Their Applications: Simpler, Faster, and Smaller</title>
<link>https://eprint.iacr.org/2024/1414</link>
<guid>https://eprint.iacr.org/2024/1414</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识协议、代码基础密码学、MPC-in-the-head、VOLE-in-the-head、斯特恩协议

总结:

本文提出了一种基于VOLEitH范式的新型代码基础零知识协议，用于证明多种关系的正确性。这一创新为构建更高效的隐私保护系统开辟了道路。首先，文章提供了一种用于验证非线性编码过程正确性的新零知识协议，这是许多高级隐私保护系统中常见的需求。其次，文中设计了针对具体代码关系的新零知识协议，包括优化积木值的零知识证明，适用于积木（accumulator）。

这些新协议相较于斯特恩式协议具有简化、更快、更小的特点，使得构建更高效的隐私保护系统成为可能。作者利用这些协议构建了环签名（RS）、组签名（GS）和全动态属性基签名方案，其签名大小显著优于基于斯特恩协议的同类方案，最高可达数个数量级的减小。

最后，文中提出的第一种零知识协议还生成了一个标准签名方案，其“签名大小+公钥大小”仅为3.05KB，这在各种参数设置下都达到了与当前最佳基于常规综态解码问题的签名方案相比的较小规模，展示了新协议在实际应用中的潜力和效率。 <div>
Zero-Knowledge (ZK) protocols allow a prover to demonstrate the truth of a statement without disclosing additional information about the underlying witness. Code-based cryptography has a long history but did suffer from periods of slow development. Recently, a prominent line of research have been contributing to designing efficient code-based ZK from MPC-in-the-head (Ishai et al., STOC 2007) and VOLE-in-the head (VOLEitH)  (Baum et al., Crypto 2023) paradigms, resulting in quite efficient standard signatures. However, none of them could be directly used to construct privacy-preserving cryptographic primitives. Therefore, Stern's protocols remain to be the major technical stepping stones for developing  advanced code-based privacy-preserving systems. 

This work proposes new code-based ZK protocols from VOLEitH paradigm for various relations and designs several code-based privacy-preserving systems that considerably advance the state-of-the-art in code-based cryptography. Our first contribution is a new ZK protocol for proving the correctness of a regular (non-linear) encoding process, which is utilized in many advanced privacy-preserving systems. Our second contribution are new ZK protocols for concrete code-based relations.   In particular, we provide a ZK of accumulated values  with optimal witness size for the accumulator (Nguyen et al.,  Asiacrypt 2019).  Our protocols thus open the door for constructing more efficient  privacy-preserving systems. Moreover, our ZK protocols have the advantage of being simpler, faster, and smaller compared to Stern-like protocols.  To illustrate the effectiveness of our new ZK protocols, we develop ring signature (RS) scheme, group signature (GS) scheme, fully dynamic attribute-based signature scheme from our new ZK. The signature sizes of the resulting schemes are two to three orders of magnitude smaller than those based on Stern-like protocols in various parameter settings. Finally, our first ZK protocol yields a standard signature scheme, achieving ``signature size + public key size'' as small as $3.05$ KB, which is slightly smaller than the state-of-the-art signature scheme (Cui et al., PKC 2024) based on the regular syndrome decoding problems.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 12:12:36 +0000</pubDate>
</item>
<item>
<title>Cryptobazaar: Private Sealed-bid Auctions at Scale</title>
<link>https://eprint.iacr.org/2024/1410</link>
<guid>https://eprint.iacr.org/2024/1410</guid>
<content:encoded><![CDATA[
<div> 关键词：Cryptobazaar、隐私保护、去中心化、密封投标拍卖、单个不可信协调者

<br /><br />
总结:本文引入了一种名为Cryptobazaar的创新性、可扩展、私密且去中心化的密封投标拍卖协议。该协议通过确保投标人的隐私不被泄露，同时保证拍卖结果的公开验证和仅依赖单一不可信的协调者来执行任务，实现了在安全与效率之间的平衡。其核心在于结合了高效分布式协议以计算一串二元编码投标的逻辑或运算，以及多种新颖的零知识简洁论证知识。此外，文章还介绍了Cryptobazaar协议的不同变体，用于实现包括第一价、第二价以及更广泛的(p+1)价和顺序第一价拍卖在内的多种拍卖类型。通过性能评估，证明了该实现的高度实用性，例如，在有128位竞标者和1024个价格范围的情况下，一次拍卖只需不到0.5秒即可完成，每位竞标者发送和接收的数据量约为32KB。 <div>
This work introduces Cryptobazaar, a novel scalable, private, and decentralized sealed-bid auction protocol. In particular, our protocol protects the privacy of losing bidders by preserving the confidentiality of their bids while ensuring public verifiability of the outcome and relying only on a single untrusted auctioneer for coordination. At its core, Cryptobazaar combines an efficient distributed protocol to compute the logical-OR for a list of unary-encoded bids with various novel zero-knowledge succinct arguments of knowledge that may be of independent interest. We further present variants of our protocol that can be used for efficient first-, second-, and more generally $(p+1)$st-price as well as sequential first-price auctions. Finally, the performance evaluation of our Cryptobazaar implementation shows that it is highly practical. For example, a single run of an auction with $128$ bidders and a price range of $1024$ values terminates in less than $0.5$ sec and requires each bidder to send and receive only about $32$ KB of data.
]]></content:encoded>
<pubDate>Tue, 10 Sep 2024 07:55:13 +0000</pubDate>
</item>
<item>
<title>Encrypted MultiChannel Communication (EMC2): Johnny Should Use Secret Sharing</title>
<link>https://eprint.iacr.org/2024/1407</link>
<guid>https://eprint.iacr.org/2024/1407</guid>
<content:encoded><![CDATA[
<div> 关键词：点对点加密、TLS协议、End-to-End Encryption（E2EE）、Pgp、Signal

总结: 文章探讨了当前End-to-End Encryption（E2EE）解决方案所面临的问题，如低可用性、小用户基础、依赖中心服务提供商以及易受后门攻击等。同时，文章指出美国和欧盟正提出新的监控法规，要求聊天监控，这引发了对合法后门设置的担忧。为解决这些问题，文章提出了一个新的E2EE解决方案——Encrypted MultiChannel Communication（EMC2），基于n-out-of-n秘密共享机制。EMC2将消息分割成多个秘密共享，并通过独立通道发送，提供无单一信任点、无需设置且易于公众理解的E2EE方式。该方案旨在通过展示合法后门无效性来加强反对其设置的论据，并与现有工具相补充，从而增强E2EE的安全性和隐私保护能力。 <div>
Nowadays, the problem of point-to-point encryption is solved by the wide adaptation of protocols like TLS. However, challenges persist for End-to-End Encryption (E2EE). Current E2EE solutions, such as PGP and secure messengers like Signal, suffer from issues like 1) low usability, 2) small user base, 3) dependence on central service providers, and 4) susceptibility to backdoors. Concerns over legally mandated backdoors are rising as the US and EU are proposing new surveillance regulations requiring chat monitoring. We present a new E2EE solution called Encrypted MultiChannel Communication, based on n-out-of-n secret sharing. EMC2 splits messages into multiple secret shares and sends them through independent channels. We show that multiple independent channels exist between users and EMC2 provides E2EE with no single point of trust, no setup, and is understandable by the general public. Our solution complements existing tools and aims to strengthen the argument against legally enforced backdoors by demonstrating their ineffectiveness.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 09:33:15 +0000</pubDate>
</item>
<item>
<title>Lego-DLC: batching module for commit-carrying SNARK under Pedersen Engines</title>
<link>https://eprint.iacr.org/2024/1405</link>
<guid>https://eprint.iacr.org/2024/1405</guid>
<content:encoded><![CDATA[
<div> 关键词：LegoSNARK、cc-SNARK、CP-SNARK、Groth16、Lego-DLC

总结:

文章主要讨论了如何优化zk-SNARK系统在处理大量承诺证明时的效率问题。首先，文章引入了cc-SNARK（commit-carrying SNARK）这一新型概念，它是CP-SNARK（commit-and-prove SNARK）的一种特殊形式，用于构建承诺与证明SNARK系统。通过cc-SNARK，文章展示了改进后的Groth16版本，其证明时间提高了约5000倍。

然而，当需要同时证明l个承诺时，使用上述方法会遇到性能瓶颈，因为LegoSNARK的链接系统在验证器侧需要进行O(l)次配对操作。为解决这一问题，文章提出了一种新的批处理模块——Lego-DLC，它结合了Σ协议与基于Pedersen引擎的承诺携带SNARK，旨在高效处理多个承诺。通过具体实例化Groth16和Plonk，该方法在验证时间上表现出了显著的效率提升，对于2^16个承诺，验证时间仅需0.064秒，比LegoSNARK的1.972秒快了超过30倍。尽管这导致了约8倍的证明时间增加（从0.177秒增加到1.413秒），但整体来看，这种性能提升是值得的。

文章通过对比实验展示了Lego-DLC在处理大规模承诺证明场景中的优势，为zk-SNARK系统的实际应用提供了有效的解决方案。 <div>
The synergy of commitments and zk-SNARKs is
widely used in various applications, particularly in fields like
blockchain, to ensure data privacy and integrity without revealing
secret information. However, proving multiple commitments in
a batch imposes a large overhead on a zk-SNARK system. One
solution to alleviate the burden is the use of commit-and-prove
SNARK (CP-SNARK) approach. LegoSNARK defines a new
notion called commit-carrying SNARK (cc-SNARK), a special-
ized form of CP-SNARK, and introduces a compiler to build
commit-carrying SNARKs into commit-and-prove SNARKs. Us-
ing this compiler, the paper shows a commit-and-prove version
of Groth16 that improves the proving time (about 5,000×).
However, proving $l$-multiple commitments simultaneously with
this compiler faces a performance issue, as the linking system in
LegoSNARK requires $O(l)$ pairings on the verifier side.
To enhance efficiency, we propose a new batching module
called Lego-DLC, designed for handling multiple commitments. This
module is built by combining a $\Sigma$-protocol with commitment-
carrying SNARKs under Pedersen engines in which our mod-
ule can support all commit-carrying SNARKs under Pedersen
engines. In this paper, we provide the concrete instantiations
for Groth16 and Plonk. In the performance comparison, for
$2^{16}$ commitments, with a verification time of just 0.064s—over
30x faster than LegoSNARK’s 1.972s—our approach shows
remarkable efficiency. The slightly longer prover time of 1.413s
(compared to LegoSNARK’s 0.177s), around 8x is a small trade-
off for this performance gain.
]]></content:encoded>
<pubDate>Mon, 09 Sep 2024 07:44:03 +0000</pubDate>
</item>
<item>
<title>A Recursive zk-based State Update System</title>
<link>https://eprint.iacr.org/2024/1402</link>
<guid>https://eprint.iacr.org/2024/1402</guid>
<content:encoded><![CDATA[
<div> 关键词：ZKP、SNARK证明、zkVM、递归证明系统、区块链

总结: 这篇论文提出了一种基于零知识证明（ZKP）的区块更新系统，其中每个区块包含一个由用户生成的zkVM证明聚合而成的SNARK证明。该系统允许用户在其本地机器上生成状态更新证明，从而促进了一个安全、分散的验证过程。论文的主要贡献是递归证明系统，它通过将用户证明进行层级化树结构验证并最终形成根证明来解决可扩展性问题，该根证明作为区块证明用于验证。该解决方案改进了当前区块链范式，通过ZKP提供高效递归验证，增强了安全性并减少了计算负载。 <div>
This paper introduces a ZKP (zero-knowledge proof) based state update system, where each block contains a SNARK proof aggregated from the user generated zkVM (zero knowledge virtual machine) proofs. It enables users to generate state update proofs in their local machines, contributing to a secure, decentralized verification process. Our main contribution in this paper, the recursive proofs system, addresses scalability by recursively verifying user proofs and aggregating them in a hierarchical tree structure up to a root proof, serving as a block proof. The proposed solution advances current blockchain paradigms by offering efficient recursive verification through ZKP, enhancing security and reducing computational load.
]]></content:encoded>
<pubDate>Sat, 07 Sep 2024 17:04:51 +0000</pubDate>
</item>
<item>
<title>SLAMP-FSS: Two-Party Multi-Point Function Secret Sharing from Simple Linear Algebra</title>
<link>https://eprint.iacr.org/2024/1394</link>
<guid>https://eprint.iacr.org/2024/1394</guid>
<content:encoded><![CDATA[
<div> 关键词：多党计算（MPC）、随机性关联、多点函数秘密共享（FSS）、伪随机关联生成器、树结构

总结:
本文探讨了多党计算(MPC)中随机性关联的重要性及其在提高计算和通信效率的同时保护数据隐私的应用。文章首先介绍了几种常见的随机性关联形式，如盲化一对一转移(OT)、盲化线性函数评估(OLE)、乘法三元组以及一次性真值表。随后指出，多点函数秘密共享(FSS)是构建伪随机关联生成器的有效工具。

研究提出了一种基于Boyle等人的方案的自然扩展，通过引入树结构、伪随机生成器和线性方程系统来构建新的多点FSS方案——SLAMP-FSS和SLAMPR-FSS。这些新方案在评估阶段展现出更高的效率，相比先前的多点FSS方案，它们更灵活，并在其他效率指标上与之相似。

总的来说，本文通过改进多点FSS方案，旨在提供一种既能提高MPC中计算和通信效率，又能在保护数据隐私方面发挥关键作用的新技术。通过利用树结构和伪随机生成器，新方案实现了在保持灵活性的同时，优化了评估阶段的性能，为MPC领域带来了创新性的解决方案。 <div>
Multiparty computation (MPC) is an important field of cryptography that deals with protecting the privacy of data, while allowing to do computation on that data. A key part of MPC is the parties involved having correlated randomness that they can use to make the computation or the communication between themselves more efficient, while still preserving the privacy of the data. Examples of these correlations include random oblivious transfer (OT) correlations, oblivious linear-function evaluation (OLE) correlations, multiplication triples (also known as Beaver triples) and one-time truth tables. Multi-point function secret sharing (FSS) has been shown to be a great building block for pseudo-random correlation generators. The main question is how to construct fast and efficient multi-point FSS schemes. Here we propose a natural generalization of the scheme of Boyle et al 2016 using a tree structure, a pseudorandom generator and systems of linear equations. 
Our schemes SLAMP-FSS and SLAMPR-FSS are more efficient in the evaluation phase than other previously proposed multi-point FSS schemes while being also more flexible and being similar in other efficiency parameters.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 08:38:24 +0000</pubDate>
</item>
<item>
<title>Survivable Payment Channel Networks</title>
<link>https://eprint.iacr.org/2024/1393</link>
<guid>https://eprint.iacr.org/2024/1393</guid>
<content:encoded><![CDATA[
<div> 关键词：支付通道网络、交易吞吐量、多跳路径、保护方案、容量分配优化

<br />
<br />
总结: 文章主要探讨了支付通道网络（PCN）在加密货币中作为提高交易吞吐量的主要方法。PCN允许两个参与者通过锁定一定资金的链上交易来建立双向支付通道，进行多次互付而不需提交到区块链。然而，打开或维护通道需要较长时间和资源，限制了其数量。为了解决这个问题，用户可以利用多跳路径绕过为每个新目的地开设和维护通道的需求。

文章还分析了支付通道的停止时间（即通道耗尽的时间），并研究了网络中一组通道的平均停止时间和特定拓扑结构下通道的停止时间。为了提高网络的最小停止时间，提出了优化通道容量分布的方案。实验结果验证了模型的准确性和优化方案的有效性。总体而言，文章旨在通过优化支付通道网络中的容量分配策略，提升系统整体的稳定性和效率，减少由于通道耗尽导致的支付失败情况。 <div>
Payment channel networks (PCNs) are a leading method to scale the transaction throughput in cryptocurrencies. Two participants can use a bidirectional payment channel for making multiple mutual payments without committing them to the blockchain. Opening a payment channel is a slow operation that involves an on-chain transaction locking a certain amount of funds. These aspects limit the number of channels that can be opened or maintained. Users may route payments through a multi-hop path and thus avoid opening and maintaining a channel for each new destination. Unlike regular networks, in PCNs capacity depends on the usage patterns and, moreover, channels may become unidirectional. Since payments often fail due to channel depletion, a protection scheme to overcome failures is of interest. We define the stopping time of a payment channel as the time at which the channel becomes depleted. We analyze the mean stopping time of a channel as well as that of a network with a set of channels and examine the stopping time of channels in particular topologies. We then propose a scheme for optimizing the capacity distribution among the channels in order to increase the minimal stopping time in the network. We conduct experiments and demonstrate the accuracy of our model and the efficiency of the proposed optimization scheme.
]]></content:encoded>
<pubDate>Thu, 05 Sep 2024 08:32:20 +0000</pubDate>
</item>
<item>
<title>Haze and Daze: Compliant Privacy Mixers</title>
<link>https://eprint.iacr.org/2023/1152</link>
<guid>https://eprint.iacr.org/2023/1152</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、隐私混币器、合规性、去中心化、智能合约

总结:本文提出了两种隐私混币器协议:Haze和Daze，旨在解决非法活动者滥用隐私混币器的问题。Haze协议确保用户隐私与合规性相结合，即只有非受限地址的资金才能提取，且不透露任何匹配存款信息。一旦用户被标记为违规，其资金将无法退出混币器。然而，这可能导致坏分子在被列入受限地址名单前尝试提取资金。为了解决这个问题，引入了Daze协议，它不仅支持合规性，还允许对违规用户的交易进行追溯匿名识别，使混币器对它们失去效用。同时，Haze和Daze提供了一个可选功能，让违规资金可以被释放到预设实体。实验结果显示，对于合规用户，这两种协议的Gas消耗与Tornado Cash相当。这是首次在区块链上实现智能合约的合规性和隐私保证。 <div>
Blockchains enable mutually distrustful parties to perform financial operations in a trustless, decentralized, publicly-verifiable environment. Blockchains typically offer little privacy, and thus motivated the construction of privacy mixers, a solution to make funds untraceable. Privacy mixers concern regulators due to their increasing use by bad actors to illegally conceal the origin of funds. Consequently, Tornado Cash, the largest privacy mixer to date, is sanctioned by large portions of the Ethereum network.

In this work, we propose Haze and Daze, two privacy mixers that mitigate the undesired abuse of privacy mixers for illicit activities. Haze guarantees users’ privacy together with compliance, i.e., funds can be withdrawn as long as they were deposited from a non-banned address, without revealing any information on the matching deposit. This means that once a user is flagged as non-compliant, their funds can no longer exit the mixer. However, this leads to a race condition for bad actors to withdraw funds before becoming flagged as unlawful in the banned-addresses list. Thus, we introduce Daze, a second mixer protocol that, in addition to compliance, enables retroactive de-anonymization of transactions of non-compliant users, making the mixer fruitless for them. To maintain privacy of compliant users, the de-anonymization procedure is performed by a committee, with privacy guaranteed as long as at least one of the committee members is honest. Moreover, Haze and Daze have an optional feature for non-compliant funds to be released from the mixer to some predetermined entity.

We empirically evaluate our solution in a proof-of-concept system, demonstrating gas consumption for each deposit and withdrawal that is comparable to Tornado Cash for compliant users, both for Haze and Daze. To the best of our knowledge, our solution is the first to guarantee compliance and privacy on the blockchain (on-chain) that is implemented via a smart contract.
]]></content:encoded>
<pubDate>Tue, 25 Jul 2023 12:29:28 +0000</pubDate>
</item>
<item>
<title>Practical Two-party Computational Differential Privacy with Active Security</title>
<link>https://eprint.iacr.org/2024/004</link>
<guid>https://eprint.iacr.org/2024/004</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、主动安全、多方计算、模拟基础差分隐私、几何噪声采样

总结:

本文重新探讨了利用通用型模型预测控制（MPC）方案模拟可信数据持有者以实现差分隐私（DP）的方法，旨在无需信任单一数据持有者即可达到相同精度。文章特别关注了双方模型，即两个计算实体（或数据持有者），各自拥有数据集，希望共同计算其结合数据的典型DP机制，并且使用主动安全性。

首先，文章指出现有定义的计算DP（CDP）协议在用于此类场景时存在缺陷，要么未能充分捕捉到通用型MPC协议通常提供的强大安全保证，要么要求过于严格，需要对常见DP和MPC技术进行重大调整才能满足。因此，文章提出了一种新的基于模拟的CDP版本，称为SIM* CDP，并证明它比IND-CDP和SIM CDP更强，与SIM+ CDP不可比较。通过使用现有分布式协议进行截断几何噪声采样，文章展示了如何满足SIM* CDP定义。进一步地，该协议被用来在具有CDP和主动安全性的条件下计算双方内积，且准确性与中心模型相等，这是首次实现此功能。最后，文章提供了开源实现并对其实际性能进行了基准测试。实现生成截断几何样本的时间范围大约在0.035至3.5秒之间（平均化后），根据网络和参数设置而变化，与现有实现相比表现出色。 <div>
In this work we revisit the problem of using general-purpose MPC schemes to emulate the trusted dataholder in differential privacy (DP), to achieve the same accuracy but without the need to trust one single dataholder. In particular, we consider the two-party model where two computational parties (or dataholders), each with their own dataset, wish to compute a canonical DP mechanism on their combined data and to do so with active security. We start by remarking that available definitions of computational DP (CDP) for protocols are somewhat ill-suited for such a use-case, due to them either poorly capturing some strong security guarantees commonly given by general-purpose MPC protocols, or having too strict requirements in the sense that they need significant adjustment in order to be satisfiable by using common DP and MPC techniques. With this in mind, we propose a new version of simulation-based CDP, called SIM$^*$-CDP, and prove it to be stronger than the IND-CDP and SIM-CDP and incomparable to SIM$^+$-CDP. We demonstrate the usability of the SIM$^*$-CDP definition by showing how to satisfy it by the use of an available distributed protocol for sampling truncated geometric noise. Further, we use the protocol to compute two-party inner-products with CDP and active security, and with accuracy equal to that of the central model, being the first to do so. Finally, we provide an open-sourced implementation and benchmark its practical performance. Our implementation generates a truncated geometric sample in between about 0.035 and 3.5 seconds (amortized), depending on network and parameter settings, comparing favourably to existing implementations.
]]></content:encoded>
<pubDate>Tue, 02 Jan 2024 09:29:54 +0000</pubDate>
</item>
<item>
<title>ASOZ: a decentralized payment system with privacy preserving and auditing on public blockchain</title>
<link>https://eprint.iacr.org/2023/1816</link>
<guid>https://eprint.iacr.org/2023/1816</guid>
<content:encoded><![CDATA[
<div> 关键词：ASOZ、积木化账户、Merkle树、隐私保护、审计方案

<br />
总结:

本文提出了一种名为ASOZ的去中心化支付系统设计。该系统利用基于Merkle树的积木化账户进行记账，同时结合Twisted ElGamal、非交互式零知识证明（NIZK）、Bulletproofs和zk-SNARKs等技术来实现隐私保护与审计功能。通过这种方式，ASOZ方案能够在全局混合中实现全面交易审计，尽管增加了约8%的证明生成时间和23%的验证时间，但总体成本保持在可接受范围内。

ASOZ设计特别适用于大型交易场景，如指定合约市场，并提供在硬币混币方案中最强的隐私保护能力。该系统不仅确保了资产的私密性，还实现了有效的审计机制，平衡了隐私与安全之间的需求，为去中心化支付系统的未来发展提供了新的思路和解决方案。 <div>
Decentralized payment systems have gradually received more attention in recent years. By removing the trusted intermediary used for accounting ledgers, those payment systems fundamentally empower users to control their assets. As privacy concerns grow, some cryptocurrencies are proposed to preserve the privacy of users. However, those cryptocurrencies also inadvertently facilitate illicit activities such as money laundering, fraudulent trading, etc. So it is necessary to design an auditing scheme. To solve this problem, many privacy-preserving and auditing schemes have been proposed. However, there exists no scheme that effectively solves the issue of privacy-preserving and auditing on both user identity and transaction value. 
In this paper, we propose a design for a decentralized payment system named ASOZ. We use cryptographic accumulators based on Merkle trees for accounting and use a combination of Twisted ElGamal, Non-Interactive Zero-Knowledge(NIZK), Bulletproofs, and zk-SNARKs for privacy-preserving and auditing. Our scheme achieves full transaction audit in global mixing, while the additional cost introduced remains within an acceptable range, specifically an 8% increment in proof generation time and a 23% rise in verification time. Our scheme is capable of handling large-scale transaction scenarios such as designated contract markets, and offers the strongest privacy protection capabilities in coin mixer schemes.
]]></content:encoded>
<pubDate>Fri, 24 Nov 2023 09:17:18 +0000</pubDate>
</item>
<item>
<title>Improved Circuit Synthesis with Multi-Value Bootstrapping for FHEW-like Schemes</title>
<link>https://eprint.iacr.org/2023/1223</link>
<guid>https://eprint.iacr.org/2023/1223</guid>
<content:encoded><![CDATA[
<div> 关键词：多值补码、简化方法、FHE-Deck库、优化技术、隐私计算

总结:

本文主要探讨了在隐私保护计算领域，特别是在布尔型全同态加密(FHE)方案上的进步与挑战。通过显著简化Carpov、Izabachène和Mollimard提出的多值补码方法，本文为基于布尔的FHE方案如FHEW或TFHE的实用性提供了基础。简化后的多值补码概念被集成到开源库FHE-Deck中，该库提供了一个易于使用的接口，并生成了具有最高安全性的多比特加密参数集。此外，作者提出并整合了首个针对FHE特定优化的技术，包括查找表（LUT）分组和加法器替换，以提高电路合成效率。

通过LUT分组，平均减少了40%的补码操作，而加法器替换则在某些情况下将所需补码操作减少了高达85%。整体而言，当启用所有优化时，执行时间比之前的最优电路合成技术快了4.2倍。这一系列改进旨在解决隐私保护计算中的关键问题——性能和易用性，从而加速这些技术的实际应用。 <div>
In recent years, the research community has made great progress in improving techniques for privacy-preserving computation, such as fully homomorphic encryption (FHE). Despite the progress, there remain open challenges, mainly in performance and usability, to further advance the adoption of these technologies. This work provides multiple contributions that improve the current state-of-the-art in both areas. More specifically, we significantly simplify the multi-value bootstrapping by Carpov, Izabachène, and Mollimard [CIM19] for Boolean-based FHE schemes such as FHEW or TFHE, making the concept usable in practice. Based on our simplifications, we implement an easy-to-use interface for multi-value bootstrapping in the open-source library FHE-Deck [fhe23], derive new parameter sets for multi-bit encryptions with state-of-the-art security, and build a toolset that translates high-level code to multi-bit operations on encrypted data using circuit synthesis. We propose and integrate the first non-trivial FHE-specific optimizations for privacy-preserving circuit synthesis: look-up table (LUT) grouping and adder substitution. Using LUT grouping, we reduce the number of bootstrapping operations by almost 40% on average, while for adder substitution, we reduce the number of required bootstrappings by up to 85% for certain use cases. Overall, the execution time is up to 4.2x faster with all optimizations enabled compared to previous state-of-the-art circuit synthesis.
]]></content:encoded>
<pubDate>Fri, 11 Aug 2023 20:22:21 +0000</pubDate>
</item>
<item>
<title>Practical Post-Quantum Signatures for Privacy</title>
<link>https://eprint.iacr.org/2024/131</link>
<guid>https://eprint.iacr.org/2024/131</guid>
<content:encoded><![CDATA[
<div> 关键词：后量子密码学、隐私保护应用、盲签名、团体签名、匿名凭证

总结:
本文研究了后量子密码学背景下隐私保护应用中的关键组件，如盲签名、团体签名和匿名凭证。当前的挑战在于寻找高效且在标准假设下安全的后量子算法来替代现有技术。作者通过重新审视Jeudy等人的工作，提出了一种高效协议（SEP）的构建方法，成功实现了短元素长度与无安全妥协的理想平衡。这一创新被应用于匿名凭证系统中，显著减少了凭证大小至不足80KB，这在同类系统中是前所未有的。

此外，文章还详细介绍了复杂零知识框架的实现，这是迄今为止未见于公开文献中的工作。通过这一实证研究，不仅提高了隐私保护解决方案的效率和现实部署的理解，而且为整个领域带来了新的进展。这种结合理论创新与实践验证的方法，不仅推动了后量子密码学在隐私保护领域的应用，也为未来标准的制定提供了有价值的参考。 <div>
The transition to post-quantum cryptography has been an enormous challenge and effort for cryptographers over the last decade, with impressive results such as the future NIST standards. However, the latter has so far only considered central cryptographic mechanisms (signatures or KEM) and not more advanced ones, e.g., targeting privacy-preserving applications. Of particular interest is the family of solutions called blind signatures, group signatures and anonymous credentials, for which standards already exist, and which are deployed in billions of devices. Such a family does not have, at this stage, an efficient post-quantum counterpart although very recent works  improved this state of affairs by offering two different alternatives: either one gets a system with rather large elements but a security proved under standard assumptions or one gets a more efficient system at the cost of ad-hoc interactive assumptions or weaker security models. Moreover, all these works have only considered size complexity without implementing the quite complex building blocks their systems are composed of. In other words, the practicality of such systems is still very hard to assess, which is a problem if one envisions a post-quantum transition for the corresponding systems/standards.

In this work, we propose a construction of so-called signature with efficient protocols (SEP), which is the core of such privacy-preserving solutions. By revisiting the approach by Jeudy et al. (Crypto 2023) we manage to get the best of the two alternatives mentioned above, namely short sizes with no compromise on security. To demonstrate this, we plug our SEP in an anonymous credential system, achieving credentials of less than 80 KB. In parallel, we fully implemented our system, and in particular the complex zero-knowledge framework of Lyubashevsky et al. (Crypto'22), which has, to our knowledge, not be done so far. Our work thus not only improves the state-of-the-art on privacy-preserving solutions, but also significantly improves the understanding of efficiency and implications for deployment in real-world systems.
]]></content:encoded>
<pubDate>Tue, 30 Jan 2024 10:37:10 +0000</pubDate>
</item>
<item>
<title>FaultyGarble: Fault Attack on Secure Multiparty Neural Network Inference</title>
<link>https://eprint.iacr.org/2024/980</link>
<guid>https://eprint.iacr.org/2024/980</guid>
<content:encoded><![CDATA[
<div> 关键词：深学习、多方计算、模型隐私、故障注入攻击、模型提取攻击

总结:

本文探讨了深学习在各种应用中的成功及其对用户数据和深度学习模型隐私的潜在威胁。随着安全多方计算技术的发展，用于解决隐私问题的提案数量显著增加，并在效率上取得了改进。然而，现有文献中对客户端行为的假设主要集中在客户端遵循协议的“被动”情况，而没有充分考虑客户端出于不同动机可能采取的“主动”恶意行为，以泄露模型所有权者的私有信息。

文章首次提出针对基于门控电路的安全推理实现的故障注入攻击，作为多方计算方案的一个例子。通过结合激光故障注入与模型提取攻击，作者成功地针对那些被假定安全免受主动攻击的解决方案进行了攻击。值得注意的是，该攻击所需的查询数量与在半诚实场景下针对安全推理引擎的最佳模型提取攻击相同。

这一发现强调了在设计安全多方计算方案时需要考虑客户端的恶意行为，特别是在模型隐私保护方面。它揭示了现有的安全措施可能存在的漏洞，并为未来的研究提供了方向，以开发更强大的防御策略和安全机制，确保模型隐私不受威胁。 <div>
The success of deep learning across a variety of
applications, including inference on edge devices, has led to
increased concerns about the privacy of users’ data and deep
learning models. Secure multiparty computation allows parties
to remedy this concern, resulting in a growth in the number
of such proposals and improvements in their efficiency. The
majority of secure inference protocols relying on multiparty
computation assume that the client does not deviate from the
protocol and passively attempts to extract information. Yet
clients, driven by different incentives, can act maliciously to
actively deviate from the protocol and disclose the deep learning
model owner’s private information. Interestingly, faults are
well understood in multiparty computation-related literature,
although fault attacks have not been explored. Our paper
introduces the very first fault attack against secure inference
implementations relying on garbled circuits as a prime example
of multiparty computation schemes. In this regard, laser fault
injection coupled with a model-extraction attack is successfully
mounted against existing solutions that have been assumed to
be secure against active attacks. Notably, the number of queries
required for the attack is equal to that of the best model extraction
attack mounted against the secure inference engines
under the semi-honest scenario.
]]></content:encoded>
<pubDate>Tue, 18 Jun 2024 02:42:02 +0000</pubDate>
</item>
<item>
<title>Atomic and Fair Data Exchange via Blockchain</title>
<link>https://eprint.iacr.org/2024/418</link>
<guid>https://eprint.iacr.org/2024/418</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链、原子交换、可验证加密、承诺密钥、数据可用性

总结:

本文介绍了一种基于区块链的公平数据交换(FDE)协议，旨在实现数据文件的安全、原子级传输。该协议允许存储服务器与客户端进行交易，确保只有在服务器收到预约定价的支付后，客户端才能接收到文件。为保障这一过程的顺利执行，文章提出了“可验证加密在承诺密钥下”(VECK)的新定义，并提供了两种实现方案。

VECK机制确保了客户端在获取正确数据（符合预先设定的承诺）的前提下才需释放解密密钥，从而保证了数据的安全性。该协议设计简洁，仅需少量的区块链通信（3个签名、1个验证密钥和1个秘密密钥），大部分数据的存储和传输则在链下完成，降低了对区块链资源的消耗。此外，该协议还支持部分数据的交换、服务器工作负载的分摊以及使用不同承诺方案设计更多FDE协议的灵活性。

文章以Ethereum的Danksharding数据可用性方案为例，说明了利用KZG多项式承诺来实现数据承诺的可行性。同时，作者还提供了两种VECK实例的开源实现代码，展示了该协议在实际应用中的高效性和实用性。 <div>
We introduce a blockchain Fair Data Exchange (FDE) protocol, enabling a storage server to transfer a data file to a client atomically: the client receives the file if and only if the server receives an agreed-upon payment. We put forth a new definition for a cryptographic scheme that we name verifiable encryption under committed key (VECK), and we propose two instantiations for this scheme. Our protocol relies on a blockchain to enforce the atomicity of the exchange and uses VECK to ensure that the client receives the correct data (matching an agreed-upon commitment) before releasing the payment for the decrypting key. Our protocol is trust-minimized and requires only constant-sized on-chain communication, concretely 3 signatures, 1 verification key, and 1 secret key, with most of the data stored and communicated off-chain. It also supports exchanging only a subset of the data, can amortize the server's work across multiple clients, and offers a general framework to design alternative FDE protocols using different commitment schemes. A prominent application of our protocol is the Danksharding data availability scheme on Ethereum, which commits to data via KZG polynomial commitments. We also provide an open-source implementation for our protocol with both instantiations for VECK, demonstrating our protocol's efficiency and practicality on Ethereum.
]]></content:encoded>
<pubDate>Sat, 09 Mar 2024 23:41:14 +0000</pubDate>
</item>
<item>
<title>SPADE: Digging into Selective and PArtial DEcryption using Functional Encryption</title>
<link>https://eprint.iacr.org/2024/1387</link>
<guid>https://eprint.iacr.org/2024/1387</guid>
<content:encoded><![CDATA[
<div> 关键词：Functional Encryption、隐私保护、数据访问控制、细粒度控制、基因组学数据分析

总结:
文章主要介绍了SPADE，一种新型的功能加密方案。SPADE支持多用户环境，并通过部分解密密文提供了精细的数据访问控制。与现有功能加密方案不同的是，SPADE还支持对质性数据（如基因组学数据）的隐私保护分析，这极大地扩展了隐私保护分析的应用领域，尤其是在医疗保健和金融领域。为了验证其可行性，研究团队进行了大量的实验，分别在睡眠医学（如睡眠阶段图数据）和DNA分析（如基因记录）的数据集上进行了测试。

SPADE在功能加密领域是一个重要的进步，它平衡了隐私保护和数据分析的需求，提供了更全面的数据研究可能性。通过实现细粒度的数据访问控制，SPADE允许用户根据特定政策访问数据的特定部分，从而在保证隐私的同时促进数据的有效利用。此外，支持基因组学数据的分析使得SPADE在医疗研究和个性化医疗等领域具有巨大的应用潜力，能够帮助研究人员和医疗机构更深入地理解遗传信息与健康状况之间的关系。 <div>
Functional Encryption (FE) is a cryptographic technique established to guarantee data privacy while allowing the retrieval of specific results from the data.
While traditional decryption methods rely on a secret key disclosing all the data, FE introduces a more subtle approach. The key generation algorithm generates function-specific decryption keys that can be adaptively provided based on policies. Adaptive access control is a good feature for privacy-preserving techniques. Generic schemes have been designed to run basic functions, such as linear regression. However, they often provide a narrow set of outputs, resulting in a lack of thorough analysis. The bottom line is that despite significant research, FE still requires appropriate constructions to unleash its full potential in securely analyzing data and providing more insights. In this article, we introduce SPADE, a novel FE scheme that features multiple users and offers fine-grained access control through partial decryption of the ciphertexts. Unlike existing FE schemes, our construction also supports qualitative data, such as genomics, expanding the applications of privacy-preserving analysis to enable a comprehensive study of the data. SPADE is a significant advancement that balances privacy and data analysis with clear implications in healthcare and finance.
To verify its applicability, we conducted extensive experiments on datasets used in sleep medicine (hypnogram data) and DNA analysis (genomic records).
]]></content:encoded>
<pubDate>Wed, 04 Sep 2024 12:11:23 +0000</pubDate>
</item>
<item>
<title>Tightly Secure Non-Interactive BLS Multi-Signatures</title>
<link>https://eprint.iacr.org/2024/1368</link>
<guid>https://eprint.iacr.org/2024/1368</guid>
<content:encoded><![CDATA[
<div> 关键词：BLS、多签名、紧致安全性、兼容性、高效

总结:
本文引入了一种新的BLS多签名变体，该变体在保持与常规BLS完全兼容的同时实现了紧致安全性。这种新方案能够无缝地与常规BLS签名结合使用，从而生成常规的BLS签名。它还支持黑盒实现，易于集成到现有的BLS实现中。值得注意的是，该方案在非交互式多签名方面是最高效的方案之一，并且比之前的紧致安全性方案更为高效。通过证明，当前使用BLS进行权益证明协议的系统可以采用我们的变体，以获得完全兼容的、紧致的安全性选择。这一创新不仅提升了安全性，而且不影响系统的整体性能和兼容性，为区块链技术提供了更安全、高效的解决方案。 <div>
Due to their simplicity, compactness, and algebraic structure, BLS signatures are among the most widely used signatures in practice. For example, used as multi-signatures, they are integral in Ethereum's proof-of-stake consensus. From the perspective of concrete security, however, BLS (multi-)signatures suffer from a security loss linear in the number of signing queries. It is well-known that this loss can not be avoided using current proof techniques. 

In this paper, we introduce a new variant of BLS multi-signatures that achieves tight security while remaining fully compatible with regular BLS. In particular, our signatures can be seamlessly combined with regular BLS signatures, resulting in regular BLS signatures. Moreover, it can easily be implemented using existing BLS implementations in a black-box way. Our scheme is also one of the most efficient non-interactive multi-signatures, and in particular more efficient than previous tightly secure schemes. We demonstrate the practical applicability of our scheme by showing how proof-of-stake protocols that currently use BLS can adopt our variant for fully compatible opt-in tight security.
]]></content:encoded>
<pubDate>Fri, 30 Aug 2024 13:08:33 +0000</pubDate>
</item>
<item>
<title>Horcrux: Synthesize, Split, Shift and Stay Alive Preventing Channel Depletion via Universal and Enhanced Multi-hop Payments</title>
<link>https://eprint.iacr.org/2024/1338</link>
<guid>https://eprint.iacr.org/2024/1338</guid>
<content:encoded><![CDATA[
<div> 关键词：Horcrux, 多方虚拟通道协议, 流中立性, 安全性证明, 实验结果

总结:

本文介绍了Horcrux，一种无需额外信任假设、脚本语言或持续在线要求的全局通用可组合性框架下的多党虚拟通道协议。Horcrux通过引入流中立性概念，有效地解决了通道耗竭问题，降低了多跳支付对通道平衡分配的影响。文章还对Horcrux的安全性进行了正式证明，并通过模型分析了其性能。

实验结果显示，与Shaduf、Thora和Revive等现有重平衡方案相比，Horcrux的整个过程成本低于1美元，显著降低；支付成功率提高了12%-30%，用户为通道所需的押金减少了70%-91%；长期运行下，Horcrux的性能提高了1.2倍至1.5倍；最重要的是，Horcrux保持了几乎零通道耗竭率，而Revive和Shaduf则导致了数千个通道耗竭。

通过这些实证研究，本文表明Horcrux在解决当前区块链网络面临的扩展性和效率问题上具有明显优势，为改进支付通道网络的稳健性和规模提供了新的途径。 <div>
Payment Channel Networks (PCNs) have been highlighted as viable solutions to address the scalability issues in current permissionless blockchains. They facilitate off-chain transactions, significantly reducing the load on the blockchain. However, the extensive reuse of multi-hop routes in the same direction poses a risk of channel depletion, resulting in involved channels becoming unidirectional or even closing, thereby compromising the sustainability and scalability of PCNs. Even more concerning, existing rebalancing protocol solutions heavily rely on trust assumptions and scripting languages, resulting in compromised universality and reliability.

In this paper, we present Horcrux, a universal and efficient multi-party virtual channel protocol without relying on extra trust assumptions, scripting languages, or the perpetual online requirement. Horcrux fundamentally addresses the channel depletion problem using a novel approach termed flow neutrality, which minimizes the impact on channel balance allocations during multi-hop payments (MHPs). Additionally, we formalize the security properties of Horcrux by modeling it within the Global Universal Composability framework and provide a formal security proof.

We implement Horcrux on a real Lightning Network dataset, comprising 10,529 nodes and 38,910 channels, and compare it to the state-of-the-art rebalancing schemes such as Shaduf [NDSS'22], Thora [CCS'22], and Revive [CCS'17]. The experimental results demonstrate that (1) the entire process of Horcrux costs less than 1 USD, significantly lower than Shaduf; (2) Horcrux achieves a $12\%$-$30\%$ increase in payment success ratio and reduces user deposits required for channels by $70\%$-$91\%$; (3) the performance of Horcrux improves by $1.2x$-$1.5x$ under long-term operation; and (4) Horcrux maintains a nearly zero channel depletion rate, whereas both Revive and Shaduf result in thousands of depleted channels.
]]></content:encoded>
<pubDate>Tue, 27 Aug 2024 07:15:02 +0000</pubDate>
</item>
<item>
<title>Jackpot: Non-Interactive Aggregatable Lotteries</title>
<link>https://eprint.iacr.org/2023/1570</link>
<guid>https://eprint.iacr.org/2023/1570</guid>
<content:encoded><![CDATA[
<div> 关键词：非交互式聚合彩票、安全保证、存储效率、可扩展性、随机预言机

文章主要探讨了在权益证明区块链中确保系统活性的方法。在这些系统中，通过选择随机的领导者群体来提议新区块和驱动共识进程，以确保系统的活跃性。然而，现有的解决方案需要将所有公开的获胜彩票单独存储在链上，这引入了不必要的存储开销。

为了解决这个问题，文章提出了非交互式聚合彩票的概念，并展示了一种高效构建此类彩票的方法。这种彩票不仅提供了与以往彩票构建相同的安全性保证，而且还允许第三方对已发布的获胜彩票进行聚合，生成一个简短的摘要。文章还提供了一个在通用组合框架下的形式模型，以及一种新的原语实现。

作为技术贡献的一部分，文章还引入了具有模拟提取性的可聚合向量承诺，并在有随机预言机的情况下给出了一个在代数组模型中的高效构造。这些承诺被用于构建非交互式聚合彩票。

文章还实现了名为Jackpot的构造，并提供了基准测试结果，以突出其实现的效率。

总结: 本文提出了非交互式聚合彩票，这是一种新型的彩票设计，它不仅可以降低存储开销，还能提高区块链系统的活性和可扩展性。通过引入可聚合向量承诺并结合随机预言机的概念，作者设计了一种高效、安全的彩票系统。此外，他们还实现了一个名为Jackpot的实例，并通过性能测试验证了其实际效率，展示了该方法在区块链应用中的潜力。 <div>
In proof-of-stake blockchains, liveness is ensured by repeatedly selecting random groups of parties as leaders, who are then in charge of proposing new blocks and driving consensus forward.
The lotteries that elect those leaders need to ensure that adversarial parties are not elected disproportionately often and that an adversary can not tell who was elected before those parties decide to speak, as this would potentially allow for denial-of-service attacks.
Whenever an elected party speaks, it needs to provide a winning lottery ticket, which proves that the party did indeed win the lottery.
Current solutions require all published winning tickets to be stored individually on-chain, which introduces undesirable storage overheads.

In this work, we introduce non-interactive aggregatable lotteries and show how these can be constructed efficiently.
Our lotteries provide the same security guarantees as previous lottery constructions, but additionally allow any third party to take a set of published winning tickets and aggregate them into one short digest.
We provide a formal model of our new primitive in the universal composability framework.

As one of our technical contributions, which may be of independent interest, we introduce aggregatable vector commitments with simulation-extractability and present a concretely efficient construction thereof in the algebraic group model in the presence of a random oracle.
We show how these commitments can be used to construct non-interactive aggregatable lotteries.
We have implemented our construction, called Jackpot, and provide benchmarks that underline its concrete efficiency.
]]></content:encoded>
<pubDate>Wed, 11 Oct 2023 11:34:15 +0000</pubDate>
</item>
<item>
<title>FLIP-and-prove R1CS</title>
<link>https://eprint.iacr.org/2024/1364</link>
<guid>https://eprint.iacr.org/2024/1364</guid>
<content:encoded><![CDATA[
<div> 关键词：SNARKs、Prover、FLIP、Groth16、Filecoin

总结:
本文研究了一种新型的SNARK（可扩展性非交互式知识证明）协议，旨在解决资源有限的用户外包证明生成任务给外部实体（Prover）的问题。主要贡献包括设计了一个高效的折叠方案FLIP和一种改进的Groth16变体。

FLIP方案通过应用内部配对产品论证将具有相同语言的R1CS实例折叠成单个松弛R1CS实例，从而减少了证明时间和通信复杂性。任何适用于松弛R1CS语言的证明系统都可以用于验证最终实例。

其次，文章提出了一种针对Groth16的新型变体，该变体在保持相同的通信复杂度的同时，增加了两个额外的配对用于验证，并对可信设置进行了适应性修改。

与SnarkPack等现有解决方案相比，此方案在单个证明生成和聚合工作量上的总成本上提供了数量级级别的改进，特别适合于生成大量复杂电路SNARK的场景，如Filecoin分布式存储网络每天生成超过6百万个SNARK的情况。 <div>
In this work, we consider the setting where one or more users with low computational resources would lie to outsource the task of proof generation for SNARKs to one external entity, named Prover. We study the scenario in which Provers have access to all statements and witnesses to be proven beforehand. We take a different approach to proof aggregation and design a new protocol that reduces simultaneously proving time and communication complexity, without going through recursive proof composition. 
Our two main contributions: We first design FLIP, a communication efficient folding scheme where we apply the Inner Pairing Product Argument to fold R1CS instances of the same language into a single relaxed R1CS instance. Then, any proof system for relaxed R1CS language can be applied to prove the final instance. As a second contribution, we build a novel variation of Groth16 with the same communication complexity for relaxed R1CS and two extra pairings for verification, with an adapted trusted setup. 
Compared to SnarkPack - a  prior solution addressing scaling for multiple Groth16 proofs - our scheme improves in prover complexity by orders of magnitude, if we consider the total cost to generated the SNARK proofs one by one and the aggregation effort. 
An immediate application of our solution is Filecoin, a decentralized storage network based on incentives that generates more than 6 million SNARKs for large circuits of 100 million constraints per day.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 17:42:34 +0000</pubDate>
</item>
<item>
<title>A Documentation of Ethereum’s PeerDAS</title>
<link>https://eprint.iacr.org/2024/1362</link>
<guid>https://eprint.iacr.org/2024/1362</guid>
<content:encoded><![CDATA[
<div> 关键词：数据可用性采样、PeerDAS、加密技术、安全保证、以太坊共识层

总结:

本文旨在为加密社区提供对PeerDAS中所使用的加密技术的概述，鼓励创新与改进，并明确阐述了PeerDAS的安全保障。数据可用性采样（Data Availability Sampling）是一种方法，允许客户端在无需下载完整数据的情况下验证来自不可信来源的网络上数据的可用性。PeerDAS作为通向全面协议的桥梁，将被整合进以太坊的共识层，其安全性至关重要。

PeerDAS采用多项加密技术来实现这一目标，包括但不限于基于多项式承诺和张量码的解决方案。这些技术确保数据的完整性与真实性，即使在数据存储于分布式网络中时也能有效验证。同时，PeerDAS设计时充分考虑了安全保证，包括但不限于数据隐私保护、抗篡改性以及抵抗恶意节点攻击的能力。通过这些措施，PeerDAS不仅增强了以太坊网络的数据可用性，还提高了整体系统的安全性和可靠性。

为了促进加密社区对该技术的理解和持续优化，文章详细描述了PeerDAS的加密机制，明确了其在安全层面的承诺。这不仅为以太坊社区提供了重要的技术支持，也为整个加密领域的研究与实践提供了宝贵的资源。 <div>
Data availability sampling allows clients to verify availability of data on a peer-to-peer network provided by an untrusted source. This is achieved without downloading the full data by sampling random positions of the encoded data.

The long-term vision of the Ethereum community includes a comprehensive data availability protocol using polynomial commitments and tensor codes. As the next step towards this vision, an intermediate solution called PeerDAS is about to integrated, to bridge the way to the full protocol. With PeerDAS soon becoming an integral part of Ethereum's consensus layer, understanding its security guarantees is essential.

This document aims to describe the cryptography used in PeerDAS in a manner accessible to the cryptographic community, encouraging innovation and improvements, and to explicitly state the security guarantees of PeerDAS.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 16:00:57 +0000</pubDate>
</item>
<item>
<title>What Did Come Out of It? Analysis and Improvements of DIDComm Messaging</title>
<link>https://eprint.iacr.org/2024/1361</link>
<guid>https://eprint.iacr.org/2024/1361</guid>
<content:encoded><![CDATA[
<div> 关键词：Self-Sovereign Identity（SSI）、Decentralized Identifiers（DIDs）、DIDComm、Composable Security、Anonymity and Authenticity

总结:

本文详细分析了DIDComm的加密通信层，这是Self-Sovereign Identity（SSI）体系中一个关键组件。作者采用可组合安全方法，对DIDComm在通用网络上的安全性进行了全面建模，将其目标定义为一种强理想通信资源，以确保发送者的匿名性和真实性。

研究发现，提出的加密模式达到了预期的隐私和真实性水平，但泄露信息量仅限于由底层网络引发的泄漏（通过可参数化的资源表示）。进一步地，基于此模型，作者提出并证明了两个改进方案：一是优化算法，同时实现匿名性和真实性，符合DIDComm消息格式，其在密文大小和计算时间上分别比现有DIDComm提案提高了近2倍；二是新提出的DIDComm模式，具有匿名性保护特性，即它不会泄露超过网络本身引发的任何额外信息。最后，作者展示了如何将这一新模式整合到优化算法中，形成了一种高效的一体化模式，确保了全面的匿名性和真实性。

此研究不仅对DIDComm的加密机制进行了深入探索，还提出了实用的改进策略，为提升SSI体系中的数据隐私和安全性提供了理论基础和技术指导。 <div>
Self-Sovereign Identity (SSI) empowers individuals and organizations with full control over their data. Decentralized identifiers (DIDs) are at its center, where a DID contains a collection of public keys associated with an entity, and further information to enable entities to engage via secure and private messaging across different platforms. A crucial stepping stone is DIDComm, a cryptographic communication layer that is in production with version 2. Due to its widespread and active deployment, a formal study of DIDComm is highly overdue.

We present the first formal analysis of DIDComm’s cryptography, and formalize its goal of (sender-) anonymity and authenticity. We follow a composable approach to capture its security over a generic network, formulating the goal of DIDComm as a strong ideal communication resource. We prove that the proposed encryption modes reach the expected level of privacy and authenticity, but leak beyond the leakage induced by an underlying network (captured by a parameterizable resource).

We further use our formalism to propose enhancements and prove their security: first, we present an optimized algorithm that achieves simultaneously anonymity and authenticity, conforming to the DIDComm message format, and which outperforms the current DIDComm proposal in both ciphertext size and computation time by almost a factor of 2. Second, we present a novel DIDComm mode that fulfills the notion of anonymity preservation, in that it does never leak more than the leakage induced by the network it is executed over. We finally show how to merge this new mode into our improved algorithm, obtaining an efficient all-in-one mode for full anonymity and authenticity.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 13:44:02 +0000</pubDate>
</item>
<item>
<title>Understanding the Blockchain Interoperability Graph based on Cryptocurrency Price Correlation</title>
<link>https://eprint.iacr.org/2024/1357</link>
<guid>https://eprint.iacr.org/2024/1357</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链生态系统、加密货币、区块链互操作性、价格分析、去中心化金融（DeFi）

<br /><br />
总结:本文研究了当前加密货币领域的区块链生态系统及其互操作性，通过分析超过4800种在76个区块链上实现的加密货币在过去一年的日价格数据，揭示了不同区块链之间的关系。这一研究对于理解加密货币市场的动态和复杂性至关重要，特别是对于去中心化金融(DeFi)领域有着潜在的影响。研究发现，加密货币实施的区块链之间的相关性可以为投资者提供有价值的参考信息，帮助他们制定更有效的投资策略并进行风险管理。通过深入分析这些数据，研究人员能够构建一个互操作性图，展示不同区块链之间的连接性和交互性，从而为未来加密货币市场的发展提供洞见。

<br /><br /> <div>
Cryptocurrencies have gained high popularity in
recent years, with over 9000 of them, including major ones such
as Bitcoin and Ether. Each cryptocurrency is implemented on
one blockchain or over several such networks. Recently, various
technologies known as blockchain interoperability have been
developed to connect these different blockchains and create an
interconnected blockchain ecosystem. This paper aims to provide
insights on the blockchain ecosystem and the connection between
blockchains that we refer to as the interoperability graph. Our
approach is based on the analysis of the correlation between
cryptocurrencies implemented over the different blockchains.
We examine over 4800 cryptocurrencies implemented on 76
blockchains and their daily prices over a year. This experimental
study has potential implications for decentralized finance (DeFi),
including portfolio investment strategies and risk management.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 10:10:11 +0000</pubDate>
</item>
<item>
<title>Leakage-Resilience of Circuit Garbling</title>
<link>https://eprint.iacr.org/2024/1356</link>
<guid>https://eprint.iacr.org/2024/1356</guid>
<content:encoded><![CDATA[
<div> 关键词：泄漏-resilient garbling、GLNP、GLNPLR、侧通道攻击、性能比较

总结:

本文探讨了在存在部分内部秘密信息泄露的情况下，保持安全性的“抗泄漏归结”。作者通过增加对归结函数泄露的隐私、无意识和真实性概念，定义了其抗泄漏版本。研究发现，广泛使用的归结方案中存在额外的侧通道弱点，如线路标签重用和XOR泄露。为了解决这个问题，作者改进了Gueron等人的GLNP归结方案，引入了标签刷新的概念，并提出了名为GLNPLR的新变体。该方案在证明上满足了抗泄漏定义。性能对比显示，当带宽为2Gbps时，使用AES-NI的GLNPLR比带有第二级侧通道遮罩的HalfGates归结快60倍，不使用AES-NI时则快5倍。这表明，通过引入抗泄漏机制，即使在敏感于侧通道攻击的环境中，也可以实现高效的归结操作。 <div>
Due to the ubiquitous requirements and performance leap in the past decade, it has become feasible to execute garbling and secure computations in settings sensitive to side-channel attacks, including smartphones, IoTs and dedicated hardwares, and the possibilities have been demonstrated by recent works. To maintain security in the presence of a moderate amount of leaked information about internal secrets, we investigate {\it leakage-resilient garbling}. We augment the classical privacy, obliviousness and authenticity notions with leakages of the garbling function, and define their leakage-resilience analogues. We examine popular garbling schemes and unveil additional side-channel weaknesses due to wire label reuse and XOR leakages. We then incorporate the idea of label refreshing into the GLNP garbling scheme of Gueron et al. and propose a variant GLNPLR that provably satisfies our leakage-resilience definitions. Performance comparison indicates that GLNPLR is 60X (using AES-NI) or 5X (without AES-NI) faster than the HalfGates garbling with second order side-channel masking, for garbling AES circuit when the bandwidth is 2Gbps.
]]></content:encoded>
<pubDate>Thu, 29 Aug 2024 07:53:32 +0000</pubDate>
</item>
<item>
<title>Votexx: Extreme Coercion Resistance</title>
<link>https://eprint.iacr.org/2024/1354</link>
<guid>https://eprint.iacr.org/2024/1354</guid>
<content:encoded><![CDATA[
<div> 关键词：VoteXX、极端强制抵抗、零知识证明、选举权威、信任代理

总结:

本文提出了一种名为VoteXX的新颖投票系统，旨在解决无监督投票中的“不当影响”问题，即投票购买和投票胁迫。与以往提案不同，该系统首次能够保护投票者免受学习了所有投票者密钥的强大敌手的攻击，这种特性被称为“极端强制抵抗”。当密钥被盗时，每个投票者或其可信代理（称为“刺猬”）可以“废除”（有效取消）他们的投票，这种行动不可逆转且无法归咎于投票者或其刺猬，且废除行为对投票者和刺猬的隐私都进行了保护。

系统允许投票者使用公私钥进行授权投票，并将公钥登记给选举权威以证明他们记忆了与私钥对应的密码短语。这样即使敌手获取了投票者的密钥，投票者本人仍保留有副本。担心密钥被窃取的投票者或通过委托给一个或多个不信任的代理（刺猬）监测密钥使用的恶意投票行为，并在零知识证明的帮助下，以隐私保护的方式取消这些投票。

相较于以往的提案，此系统能为最强大的敌手提供一定程度的防护，这些敌手甚至能获取所有密钥。其他抗胁迫协议要么未处理此类攻击、限制敌手能力，或者依赖于完全可信赖的第三方协助投票者管理密钥。 <div>
We provide a novel perspective on a long-standing challenge to the integrity of votes cast without the supervision of a voting booth: "improper influence,'' which we define as any combination of vote buying and voter coercion. In comparison with previous proposals, our system is the first in the literature to protect against a strong adversary who learns all of the voter's keys---we call this property "extreme coercion resistance.'' When keys are stolen, each voter, or their trusted agents (which we call "hedgehogs''), may "nullify'' (effectively cancel) their vote in a way that is unstoppable and irrevocable, and such that the nullification action is forever unattributable to that voter or their hedgehog(s). We demonstrate the security of our VoteXX system in the universal composability model. 

As in many other coercion-resistant systems, voters are authorized to vote with public-private keys. Each voter registers their public keys with the Election Authority (EA) in a way that convinces the EA that the voter has memorized a passphrase that corresponds to their private keys. As a consequence, if an adversary obtains a voter's keys, the voter also retains a copy. Voters concerned about adversaries stealing their private keys can themselves, or by delegating to one or more untrusted hedgehog(s), monitor the bulletin board for malicious ballots cast with their keys, and can act to nullify these ballots in a privacy-preserving manner with zero-knowledge proofs. 

In comparison with previous proposals, our system offers some protection against even the strongest adversary who learns all keys. Other coercion-resistant protocols either do not address these attacks, place strong limitations on adversarial abilities, or rely on fully trusted parties to assist voters with their keys.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 21:40:11 +0000</pubDate>
</item>
<item>
<title>Oblivious Pseudo Random Function base on Ideal Lattice, Application in PSI and PIR</title>
<link>https://eprint.iacr.org/2024/1349</link>
<guid>https://eprint.iacr.org/2024/1349</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、量子攻击、理想格假设、Oblivious Pseudorandom Function、Oblivious Transfer

总结:
本文旨在设计一种兼顾安全性与效率的新型Oblivious Pseudorandom Function（OPRF），以应对量子计算可能带来的威胁。通过基于理想格假设和Chase与Miao在2020年Crypto会议上提出的Oblivious Transfer技术，构建了一种高效且能够抵抗量子攻击的OPRF。该OPRF简化了结构设计，为隐私保护技术提供了更为安全和实用的解决方案。

本文进一步将构建的OPRF应用于隐私集交集(PSI)和私有信息检索(PIR)中，实现了在保持用户数据隐私的同时，提高了系统性能和安全性。通过采用Oblivious Transfer技术，确保了在数据交互过程中，参与方无法获取对方多余的信息，从而有效保护了敏感数据。

综上所述，本文通过创新性地结合理想格假设和Oblivious Transfer技术，不仅实现了OPRF的量子安全特性，还简化了其结构，提高了效率，成功应用于PSI和PIR，为隐私保护领域提供了一个全面且高效的解决方案。 <div>
Privacy set intersection (PSI) and private information retrieval (PIR) are important areas of research in privacy protection technology. One of the key tools for both is the oblivious pseudorandom function (OPRF). Currently, existing oblivious pseudorandom functions either focus solely on efficiency without considering quantum attacks, or are too complex, resulting in low efficiency. The aim of this paper is to achieve a balance: to ensure that the oblivious pseudorandom function can withstand quantum attacks while simplifying its structure as much as possible. This paper constructs an efficient oblivious pseudorandom function based on the ideal lattice hardness assumption and the oblivious transfer (OT) technique by Chase and Miao (CRYPTO 2020), and also constructs PSI and PIR.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 10:34:30 +0000</pubDate>
</item>
<item>
<title>Zero-Knowledge Validation for an Offline Electronic Document Wallet using Bulletproofs</title>
<link>https://eprint.iacr.org/2024/1348</link>
<guid>https://eprint.iacr.org/2024/1348</guid>
<content:encoded><![CDATA[
<div> 关键词：电子钱包、零知识证明、官方政府文档、隐私保护、广泛适用性

总结:

文章描述了一种设计用于存放官方政府文件的电子钱包系统。该系统利用零知识证明技术，确保仅分享必要的信息，以此来解决向不可信第三方展示文件数据的问题。例如，允许用户证明自己已达到饮酒年龄。系统在满足多个实际应用约束的同时，实现这一目标，包括在离线场景下使用、采用不侵犯用户隐私的通用通信方法以及仅使用标准、广泛研究的加密算法构建，以提供足够的安全性。

为确保实用性与安全性，系统设计着重于：

1. **离线兼容性**：确保在无网络环境下也能正常运行，使用户能在任何情况下访问其电子文档。
   
2. **隐私保护**：仅分享所需信息，避免泄露额外敏感数据，维护用户隐私。
   
3. **广泛适用性**：使用易于获取且不侵犯隐私的通信方式，确保不同用户群体都能方便地使用。
   
4. **安全构建**：基于经过广泛研究的加密算法，确保数据传输和存储的安全性。
   
5. **综合考量**：在设计中平衡了功能、性能和安全性要求，最终成功实现了所有附加约束条件。

通过上述措施，电子钱包系统不仅解决了特定应用场景中的问题，而且在实用性和安全性方面达到了较高的标准，为用户提供了一个可靠、私密的官方文档存储解决方案。 <div>
We describe designs for an electronic wallet, meant for the housing
of official government documents, which solves the problem of
displaying document data to untrusted parties (e.g., in order to allow
users to prove that they are above the drinking age). The wallet
attains this goal by employing Zero-Knowledge Proof technologies,
ascertaining that nothing beyond the intended information is ever
shared. In order to be practically applicable, the wallet has to meet
many additional constraints, such as to be usable in offline scenarios,
to employ only widely-accessible communication methods which,
themselves, must not impinge on the user’s privacy, and to be
constructed solely over standard, widely-studied cryptographic
algorithms, offering appropriately high levels of cryptographic
security. We explain how our design was able to successfully meet
all such additional constraints.
]]></content:encoded>
<pubDate>Wed, 28 Aug 2024 08:07:44 +0000</pubDate>
</item>
<item>
<title>TandaPay Whistleblowing Communities:  Shifting Workplace Culture Towards Zero-Tolerance Sexual Harassment Policies</title>
<link>https://eprint.iacr.org/2023/655</link>
<guid>https://eprint.iacr.org/2023/655</guid>
<content:encoded><![CDATA[
<div> 关键词：TandaPay、性骚扰政策、自审抑制、企业文化、去中心化报告协议

总结:

本文探讨了企业性骚扰政策存在的问题及其对员工的影响。主要问题在于这些政策更侧重于规避法律责任而非构建无骚扰的企业环境。员工在面对性骚扰时往往需要单独向人力资源部门报告，这导致了一个自我审查的环境，因为员工可能不信任HR能公正调解。这种现象在企业内部存在容忍某些类型骚扰的文化时尤为严重。

为了解决这些问题，论文提出了一种名为TandaPay的去中心化投诉报告协议。TandaPay旨在赋予举报群体自主权，使他们能够集体批准自己的骚扰指控。通过这一系统，员工不再依赖HR作为中介，从而减少了自我审查的可能性，因为他们现在可以自己掌控报告过程。

TandaPay还采用了一种创新的方法，利用财务激励来防止合谋行为，确保只有有效的指控才能被批准。这为公司提供了保证，即员工只能批准真实有效的投诉。

通过实施TandaPay，公司能够给予员工更大的自主权，目标是减少自我审查，增加事件报告，进而改变企业文化，使之更加尊重和负责任。 <div>
Abstract—Corporate sexual harassment policies often prioritize liability mitigation over the creation of a corporate culture free of harassment. Victims of sexual harassment are often required to report claims individually to HR. This can create an environment of self-censorship when employees feel that they cannot trust HR to act as an unbiased mediator. This problem is compounded when corporations have a culture that is tolerant of certain types of harassment. Forcing employees to report incidents to HR does nothing to address employees’ fear of bias and uncertainty. This paper presents TandaPay, a decentralized grievance reporting protocol designed to address sexual harassment. TandaPay empowers whistleblowing communities to collectively approve their own harassment claims. TandaPay reduces self-censorship by allowing employees to take ownership of the reporting process, as employees no longer need to rely on HR to act as an intermediary. The protocol employs a novel method of using financial incentives to guard against collusion. This provides corporations with a guarantee that employees can only approve valid claims. Using TandaPay, corporations can give employees greater autonomy with the goal of minimizing self-censorship. This increases the reporting of incidents, enabling workers to change the corporate culture to one of respect and accountability.
]]></content:encoded>
<pubDate>Tue, 09 May 2023 15:10:32 +0000</pubDate>
</item>
<item>
<title>Improved Reductions from Noisy to Bounded and Probing Leakages via Hockey-Stick Divergences</title>
<link>https://eprint.iacr.org/2024/1009</link>
<guid>https://eprint.iacr.org/2024/1009</guid>
<content:encoded><![CDATA[
<div> 关键词：理论与实践、侧信道攻击、模糊泄漏模型、Hockey-stick偏移、安全性证明

总结:本文深入探讨了理论与实践在密码学领域中的不一致性，特别是在面对泄漏时。理论研究中，提出了方便分析多种设计安全性的模型，如有界泄漏模型和随机探针模型。然而，在实践中，侧信道攻击产生的长记录通常带有噪声，提供有关内部计算的全面信息，这与理论模型有所偏差。文章进一步引入了基于Hockey-stick偏移的模糊泄漏模型，这是一种综合统计距离和差分隐私基础的新模型。作者通过实验展示了理论模型中对有界泄漏和随机探针的抵抗能力，能够有效转化为对模糊泄漏的抵抗力，相较于基于统计距离或互信息的模型，参数有所优化。此外，研究还提供了关于多泄漏组成的定理，揭示了这些连接在处理多个泄漏情况时的扩展性。值得注意的是，该研究不仅在理论上为安全性证明提供了新视角，还讨论了其在实际应用中的相关性和局限性。具体而言，研究结果适用于现实世界中具有噪声水平显著降低的实用泄漏函数，同时，对随机探针的减小也有助于推广先前的工作，尽管在某些情况下，当操作掩码的域大小增加时，仍存在限制。 <div>
There exists a mismatch between the theory and practice of cryptography in the presence of leakage. On the theoretical front, the bounded leakage model, where the adversary learns bounded-length but noiseless information about secret components, and the random probing model, where the adversary learns some internal values of a leaking implementation with some probability, are convenient abstractions to analyze the security of numerous designs. On the practical front, side-channel attacks produce long transcripts which are inherently noisy but provide information about all internal computations, and this noisiness is usually evaluated with closely related metrics like the mutual information or statistical distance. Ideally, we would like to claim that resilience to bounded leakage or random probing implies resilience to noisy leakage evaluated according to these metrics. However, prior work (Duc, Dziembowski and Faust, Eurocrypt 2014; Brian et al., Eurocrypt 2021) has shown that proving such reductions with useful parameters is challenging.    

In this work, we study noisy leakage models stemming from hockey-stick divergences, which generalize statistical distance and are also the basis of differential privacy. First, we show that resilience to bounded leakage and random probing implies resilience to our new noisy leakage model with improved parameters compared to models based on the statistical distance or mutual information. Second, we establish composition theorems for our model, showing that these connections extend to a setting where multiple leakages are obtained from a leaking  implementation. We complement our theoretical results with a discussion of practical relevance, highlighting that (i) the reduction to bounded leakage applies to realistic leakage functions with noise levels that are decreased by several orders of magnitude compared to Brian et al., and (ii) the reduction to random probing usefully generalizes the seminal work of Duc, Dziembowski, and Faust, although it remains limited when the field size in which masking operates grows (i.e., hockey-stick divergences can better hide the field size dependency of the noise requirements, but do not annihilate it).
]]></content:encoded>
<pubDate>Fri, 21 Jun 2024 11:45:22 +0000</pubDate>
</item>
<item>
<title>Pay Less for Your Privacy: Towards Cost-Effective On-Chain Mixers</title>
<link>https://eprint.iacr.org/2023/1222</link>
<guid>https://eprint.iacr.org/2023/1222</guid>
<content:encoded><![CDATA[
<div> 关键词：Tornado Cash, Merkle Pyramid Builder, Verifiable Computations, 隐私保护, 成本降低

总结:
本文提出了Merkle金字塔构建者方法，旨在通过在链上混合器中逐步构建Merkle树并根据每批存款更新树，从而降低使用混合器的整体成本。这种方法在减少存款平均成本方面表现出显著效果，与现有链上混合器相比，最高可减少7倍的成本。重要的是，这些改进不会损害用户的隐私。

此外，文章还提议利用可验证计算将Merkle树更新的责任从链上智能合约转移到离链客户端，进一步降低存款成本。分析显示，我们的设计确保了公平性，通过时间分布将Merkle树更新费用均匀分配给客户端。这为非隐私保护区块链用户提供了更经济、更私密的交易解决方案。 <div>
On-chain mixers, such as Tornado Cash (TC), have become a popular privacy solution for many non-privacy-preserving blockchain users. These mixers enable users to deposit a fixed amount of coins and withdraw them to another address, while effectively reducing the linkability between these addresses and securely obscuring their transaction history. However, the high cost of interacting with existing on-chain mixer smart contracts prohibits standard users from using the mixer, mainly due to the use of computationally expensive cryptographic primitives. For instance, the deposit cost of TC on Ethereum is approximately $1.1m$ gas (i.e., $66$ USD in June 2023), which is $53\times$ higher than issuing a base transfer transaction.


In this work, we introduce the Merkle Pyramid Builder approach, to incrementally build the Merkle tree in an on-chain mixer and update the tree per batch of deposits, which can therefore decrease the overall cost of using the mixer. Our evaluation results highlight the effectiveness of this approach, showcasing a significant reduction of up to $7\times$ in the amortized cost of depositing compared to state-of-the-art on-chain mixers. Importantly, these improvements are achieved without compromising users' privacy. Furthermore, we propose the utilization of verifiable computations to shift the responsibility of Merkle tree updates from on-chain smart contracts to off-chain clients, which can further reduce deposit costs. Additionally, our analysis demonstrates that our designs ensure fairness by distributing Merkle tree update costs among clients over time.
]]></content:encoded>
<pubDate>Fri, 11 Aug 2023 19:30:10 +0000</pubDate>
</item>
<item>
<title>PulpFHE: Complex Instruction Set Extensions for FHE Processors</title>
<link>https://eprint.iacr.org/2024/1315</link>
<guid>https://eprint.iacr.org/2024/1315</guid>
<content:encoded><![CDATA[
<div> 关键词：云计算、隐私保护、传统加密、全同态加密（FHE）、PulpFHE

总结:

本文探讨了云计算环境下数据隐私保护的挑战，尤其是数据在云服务器上的传输和存储安全。传统的加密方法虽然能保护数据不被窃取，但在加密数据需要云服务提供商进行处理时却显得力不从心。为解决这一问题，全同态加密(FHE)技术应运而生，它允许在数据保持加密状态下进行运算。近年来，研究人员致力于开发专门针对FHE数据处理的处理器设计。

在此背景下，作者提出了PulpFHE，这是一种面向下一代FHE处理器优化的指令集扩展。PulpFHE提供对加密数据非线性操作的原生支持，显著提升了各种实际应用中的同态计算速度。通过引入这些定制化的FHE指令，不仅增强了数据处理效率，还提高了隐私保护水平，确保了数据在云环境下的安全性和有效性。这一创新成果为云计算领域提供了更安全、高效的解决方案，对于促进云计算的广泛应用具有重要意义。 <div>
The proliferation of attacks to cloud computing, coupled with the vast amounts of data outsourced to online services, continues to raise major concerns about the privacy for end users. Traditional cryptography can help secure data transmission and storage on cloud servers, but falls short when the already encrypted data needs to be processed by the cloud provider. An emerging solution to this challenge is fully homomorphic encryption (FHE), which enables computations directly on encrypted data, and recent works have focused on developing new processor designs tailored for native processing of FHE data. In this work, we introduce PulpFHE, an optimized instruction set extension tailored for the next generation of FHE processors. Our proposed FHE instructions offer native support for non-linear operations on encrypted data, and enable significantly faster homomorphic computations for a broad range of realistic applications.
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 17:06:23 +0000</pubDate>
</item>
<item>
<title>Dynamic Threshold Key Encapsulation with a Transparent Setup</title>
<link>https://eprint.iacr.org/2024/1311</link>
<guid>https://eprint.iacr.org/2024/1311</guid>
<content:encoded><![CDATA[
<div> 关键词：动态TKEM、透明设置、配对操作、决策性Diffie-Hellman假设、安全性证明

总结: 文章提出了一种动态阈值密钥封装机制（TKEM），旨在解决现有构建依赖于可信设置的问题。这种机制允许在不依赖第三方的情况下，灵活选择接收者和阈值，从而提高了系统的安全性和鲁棒性。它不使用配对运算，而是基于决策性Diffie-Hellman假设来确保选择性选择-密文安全性和解封装一致性。通过安全证明和概念验证实现，该方法不仅提高了阈值加密领域的实践可行性，也显著提升了效率，为分布式系统提供了更安全、灵活的密钥分发方案。 <div>
A threshold key encapsulation mechanism (TKEM) facilitates the secure distribution of session keys among multiple participants, allowing key recovery through a threshold number of shares. TKEM has gained significant attention, especially for decentralized systems, including blockchains. However, existing constructions often rely on trusted setups, which pose security risks such as a single point of failure, and are limited by fixed participant numbers and thresholds. To overcome this, we propose a dynamic TKEM with a transparent setup, allowing for a flexible selection of recipients and thresholds without relying on trusted third parties in the setup phase. In addition, our construction does not rely on pairing operations. We prove the security of our TKEM under the decisional Diffie-Hellman assumption, ensuring selective chosen-ciphertext security and decapsulation consistency. Our proof-of-concept implementation highlights the practicality and efficiency of this approach, advancing the field of threshold cryptography.
]]></content:encoded>
<pubDate>Thu, 22 Aug 2024 07:09:30 +0000</pubDate>
</item>
<item>
<title>Kalos: Hierarchical-auditable and Human-binding Authentication Scheme for Clinical Trial</title>
<link>https://eprint.iacr.org/2024/1301</link>
<guid>https://eprint.iacr.org/2024/1301</guid>
<content:encoded><![CDATA[
<div> 关键词：Kalos、临床试验、隐私保护、数据可靠性、信任鸿沟

文章主要介绍了一种名为Kalos的新颖认证方案，旨在解决临床试验中数据收集和处理过程中面临的数据隐私保护与可靠性之间的权衡问题。该方案利用了多样化的加密工具，如基于卡片的匿名凭证和零知识证明，实现了可视化验证和属性选择性披露，从而支持层次审计和数据去重，以提高临床试验的可靠性。Kalos具有不可伪造性、盲性、隐私保护和人性绑定等特性，有助于解决物理世界与数字世界之间的信任差距。

总结:
Kalos认证方案为临床试验提供了一种创新的解决方案，通过结合多种加密技术，实现了在确保数据隐私的同时，增强数据可靠性和可审计性。它解决了传统方法在处理大量参与者数据时面临的信任鸿沟问题，通过提供可视化的验证过程和对属性的选择性披露，Kalos不仅提高了数据的可信度，还有效防止了数据重复录入的问题。该方案的计算成本不依赖于认证属性的数量，且在常见属性数量下，总计算时间保持在毫秒级范围内，这使得Kalos具有在医疗消费电子产品场景中部署的潜力。 <div>
Clinical trials are crucial in the development of new medical treatment methods. To ensure the correctness of clinical trial results, medical institutes need to collect and process large volumes of participant data, which has prompted research on privacy preservation and data reliability. However, existing solutions struggle to resolve the trade-off between them due to the trust gap between the physical and digital worlds, limiting their practicality. To tackle the issues above, we present Kalos, a novel authentication scheme for clinical trials. Kalos leverages diversified cryptographic tools, such as card-based anonymous credential and zero-knowledge proof to achieve authentication with visual verification and selective disclosure of attributes. It has properties such as unforgeability, blindness, privacy preservation, and human-binding that support hierarchical auditability and data de-duplication to enhance the reliability of clinical trials. We then provide the security and performance analysis of Kalos to show its potential to be deployed in the medical consumer electronics scenario. The computational cost of the smartcard is irrespective of the number of certified attributes, and the total computational cost of Kalos is within tens of milliseconds with the commonly used number of attributes.
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 09:35:32 +0000</pubDate>
</item>
<item>
<title>Lattice-Based Succinct Mercurial Functional Commitment for Boolean Circuits: Definitions and Constructions</title>
<link>https://eprint.iacr.org/2024/617</link>
<guid>https://eprint.iacr.org/2024/617</guid>
<content:encoded><![CDATA[
<div> 关键词：Vector Commitments（VC）、Mercurial Vector Commitments（MVC）、Mercurial Functional Commitments（MFC）、Zero-Knowledge Sets、Lattice-Based Cryptography

总结:

文章首先提出了梅尔库里矢量承诺（MVC）和梅尔库里功能承诺（MFC）的系统和安全性模型，以支持布尔电路。这解决了现有MFC仅支持线性函数的问题，扩大了其在构建具有线性函数查询能力的零知识集合和零知识功能基础数据库（ZK-FEDB）中的应用范围。然而，当前的MFC和ZK-FEDB主要基于群假设，无法抵抗量子计算机攻击。

为解决这一问题，作者引入了一种新的可验证假设——Wee和Wu在EUROCRYPT '23中提出的BASIS假设，以此为基础构建了第一个基于格的简洁梅尔库里功能承诺，用于布尔电路。这种承诺机制不仅克服了现有方法的局限性，还确保了安全性和抗量子攻击的能力。

通过将此承诺机制应用于构建第一个基于格的ZK-FEDB，文章展示了其在现有通用框架下的应用潜力，显著扩展了零知识技术在复杂查询场景中的适用性。这一创新不仅丰富了密码学领域的理论研究，也为实际应用提供了更安全、更高效的解决方案。 <div>
Vector commitments (VC) have gained significant attention due to their extensive use in applications such as blockchain and accumulators. Mercurial vector commitments (MVC) and mercurial functional commitments (MFC), as variants of VC, are central techniques for constructing more advanced cryptographic primitives, such as zero-knowledge sets and zero-knowledge functional elementary databases (ZK-FEDB). However, existing MFCs $\textit{only support linear functions}$, which limits their applicability—for instance, in building ZK-FEDBs that support only linear function queries. Moreover, to the best of our knowledge, the current MFCs and ZK-FEDBs, including the state-of-the-art proposed by Zhang and Deng (ASIACRYPT '23) using RSA accumulators, are all based on group-based assumptions and $\textit{cannot resist quantum computer attacks}$.

To address these limitations, we $\textit{first}$ formalize the system and security models of MFC to support Boolean circuits. Then, we target specific properties of a new falsifiable assumption, namely the $\mathsf{BASIS}$ assumption proposed by Wee and Wu (EUROCRYPT '23), to construct the $\textit{first}$ lattice-based succinct mercurial functional commitment for Boolean circuits. As an application of our construction, we demonstrate how it can be used to build the $\textit{first}$ lattice-based ZK-FEDB within the existing generic framework.
]]></content:encoded>
<pubDate>Mon, 22 Apr 2024 09:29:41 +0000</pubDate>
</item>
<item>
<title>Permissionless Verifiable Information Dispersal (Data Availability for Bitcoin Rollups)</title>
<link>https://eprint.iacr.org/2024/1299</link>
<guid>https://eprint.iacr.org/2024/1299</guid>
<content:encoded><![CDATA[
<div> 关键词：Rollups、比特币、数据可用性、Verifiable Information Dispersal（VID）、状态机复制（SMR）

总结:

文章主要探讨了如何在比特币网络中引入数据可用性问题的解决方案，以提高其作为分布式账本的效率。Rollups作为一种特殊应用，通过在主区块链之外的辅助机器上执行交易，来解决交易吞吐量和成本问题。然而，当计算瓶颈被移除后，通信成为新的瓶颈。

Verifiable Information Dispersal（VID）系统被提出作为解决数据可用性问题的关键技术，它能以比线性更小的通信开销确保数据的可获取性。该系统适用于比特币的无许可模型，需要一个额外的假设：参与者之间存在可靠的通信机制。VID系统与比特币的状态机复制（SMR）协议结合，实现了对数据可用性的保障，同时保持了与比特币的兼容性。

作者通过在比特币核心的回归测试网络（regtest）上实现VID系统，证明了其在减少通信成本和降低延迟方面有显著效果，通信成本降低了超过1000倍，延迟降低了超过10倍。这一改进对于提升比特币网络的效率和扩展性具有重要意义。 <div>
Rollups are special applications on distributed state machines (aka blockchains) for which the underlying state machine only logs, but does not execute transactions. Rollups have become a popular way to scale applications on Ethereum and there is now growing interest in running rollups on Bitcoin. Rollups scale throughput and reduce transaction costs by using auxiliary machines that have higher throughput and lower cost of executing transactions than the underlying blockchain. State updates are periodically posted to the underlying blockchain and either verified directly through succinct cryptographic proofs (zk rollups) or can be challenged for a defined period of time in a verifiable way by third parties (optimistic rollups). 
   
However, once computation is removed as a bottleneck, communication quickly becomes the new bottleneck. The critical service the underlying blockchain provides in addition to verification is data availability: that necessary data can always be recovered upon request. While broadcasting transaction data is one way to ensure this, it requires communication blowup linear in the number of participating nodes. Verifiable information dispersal (VID) systems achieve sublinear blowup in the same participation model and the same security assumptions as Ethereum, where all nodes have a strong public-key identity. It was not known how to do so in the same permissionless model as Bitcoin, where participants are unauthenticated and participation is dynamic. 
    
We construct a VID system that is secure under the same model as Bitcoin, with one minimal additional requirement on the existence of reliable participants.  Our system uses a state machine replication (SMR) protocol (e.g., Bitcoin) as a black box, and is therefore backward compatible. We implemented the system on top of Bitcoin core with the Regression Test Network (regtest), and our analysis shows that it reduces communication costs by more than 1,000x and latency by more than 10x.
]]></content:encoded>
<pubDate>Tue, 20 Aug 2024 00:20:03 +0000</pubDate>
</item>
<item>
<title>SoK: Computational and Distributed Differential Privacy for MPC</title>
<link>https://eprint.iacr.org/2024/1290</link>
<guid>https://eprint.iacr.org/2024/1290</guid>
<content:encoded><![CDATA[
<div> 关键词：差分隐私、多方计算、计算性定义、分布式版本、多分布模型

总结:

本文系统化了过去十五年中，差分隐私与多方计算等加密领域融合产生的各种定义。这些定义结合了实用性和理论性，针对不同应用场景和现有加密工具进行了定制，形成了计算性和分布式版本的差分隐私。文章按照分布模型和计算视角对定义进行排序，并提出识别通用概念的视角。排序揭示了定义之间的清晰层级关系，允许用户权衡准确性与更强隐私保护或更少信任假设之间的取舍。

文章还探讨了定义之间的理论结果，并扩展了一些结果。它还讨论了知名开放问题的状态并提出了新的研究方向。最后，文章考虑了不同概念的实际应用方面，为未来的研究提供了指导。通过分析各种定义的特性，该工作有助于理解和选择最适合特定场景的差分隐私定义，从而促进安全、隐私保护的数据处理技术的发展。 <div>
In the last fifteen years, there has been a steady stream of works combining differential privacy with various other cryptographic disciplines, particularly that of multi-party computation, yielding both practical and theoretical unification. As a part of that unification, due to the rich definitional nature of both fields, there have been many proposed definitions of differential privacy adapted to the given use cases and cryptographic tools at hand, resulting in computational and/or distributed versions of differential privacy. In this work, we offer a systemization of such definitions, with a focus on definitions that are both computational and tailored for a multi-party setting. We order the definitions according to the distribution model and computational perspective and propose a viewpoint on when given definitions should be seen as instantiations of the same generalised notion. The ordering highlights a clear, and sometimes strict, hierarchy between the definitions, where utility (accuracy) can be traded for stronger privacy guarantees or lesser trust assumptions. Further, we survey theoretical results relating the definitions to each other and extend some such results. We also discuss the state of well-known open questions and suggest new open problems to study. Finally, we consider aspects of the practical use of the different notions, hopefully giving guidance also to future applied work.
]]></content:encoded>
<pubDate>Fri, 16 Aug 2024 13:39:14 +0000</pubDate>
</item>
<item>
<title>Improved Lattice Blind Signatures from Recycled Entropy</title>
<link>https://eprint.iacr.org/2024/1289</link>
<guid>https://eprint.iacr.org/2024/1289</guid>
<content:encoded><![CDATA[
<div> 关键词：盲签名、后量子计算、拉格矩阵、零知识证明、隐私保护

总结:本文提出了一种新的设计，旨在缓解盲签名过程中“显示”阶段的复杂性问题。通过在“发行”阶段注入过量随机性，并利用显示阶段回收熵余量来简化零知识证明的复杂度。这一设计不仅使得盲签名方案具有较小的大小和较低的计算复杂度，而且仍基于广为人知的拉格矩阵假设，从而实现了隐私保护的同时提高了效率和安全性。与现有基于拉格矩阵的盲签名构造相比，该方案在保持或增强某些关键特性（如安全性、效率）的同时，解决了其他方面的问题，例如签名尺寸和执行效率。这标志着在后量子计算背景下，对于盲签名技术研究的一个重要进展。 <div>
Blind signatures represent a class of cryptographic primitives enabling privacy-preserving authentication with several applications such as e-cash or e-voting. It is still a very active area of research, in particular in the post-quantum setting where the history of blind signatures has been hectic. Although it started to shift very recently with the introduction of a few lattice-based constructions, all of the latter give up an important characteristic of blind signatures (size, efficiency, or security under well-known assumptions) to achieve the others. In this paper, we propose another design which revisits the link between the two main procedures of blind signatures, namely issuance and showing, demonstrating that we can significantly alleviate the second one by adapting the former. Concretely, we show that we can harmlessly inject excess randomness in the issuance phase, and then recycle the entropy surplus during showing to decrease the complexity of the zero-knowledge proof which constitutes the main component of the signature. This leads to a blind signature scheme with small sizes, low complexity, and that still relies on well-known lattice assumptions.
]]></content:encoded>
<pubDate>Fri, 16 Aug 2024 11:59:01 +0000</pubDate>
</item>
<item>
<title>REACTIVE: Rethinking Effective Approaches Concerning Trustees in Verifiable Elections</title>
<link>https://eprint.iacr.org/2024/915</link>
<guid>https://eprint.iacr.org/2024/915</guid>
<content:encoded><![CDATA[
<div> 关键词：选举系统、可信执行、隐私保护、密钥生成、安全证明

文章主要探讨了设计可验证选举系统时面临的两大核心问题：如何确保结果的公正性以及如何保护选民的投票隐私。文中指出，虽然已经提出了多种解决方案来解决第一个问题，如使用混合网络和同态汇总等技术，但在学术文献中，对于第二个问题的回答一直相对单一，即通过将解密权限分散给多个独立的“托管人”，以防止恶意联合泄露隐私。

然而，实际部署过程中发现这一模式存在挑战。人工托管人往往缺乏明确职责认知，且通常使用相同的软件执行任务，这可能导致他们更像是执行特定指令的机器，而非真正维护隐私的守护者。文章进一步分析了选举中使用的各种加密协议对托管人的角色影响，并指出即使是理论上的正确使用托管人也比想象的复杂得多。文章还指出，其中一种仅有的描述选举中完整阈值分布式密钥生成（DKG）方法的参考文献实际上定义了一个不安全的协议，而Belenios声称依赖于该文献进行其DKG和安全性证明，但并未继承同样的漏洞。文章为此提供了Belenios DKG的安全证明。

文章随后讨论了人类、软件和硬件在实践层面对基于托管人模型的隐私保护实现的影响。总结:

文章首先深入探讨了选举系统设计中关于结果公正性和选民隐私保护的两大核心问题。接着，它强调了学术界对于保护隐私方法的传统理解——依赖于将解密权限分配给多个独立“托管人”的策略，尽管这一策略理论上旨在防止隐私泄露，但在实际操作中面临多重挑战，包括托管人职责模糊、使用相同软件执行任务可能导致执行成为被动的执行者而非隐私保护者。

文章进一步揭示了一种描述选举中使用分布式密钥生成（DKG）方法的参考文献实际上存在安全漏洞，指出Belenios声称基于此文献构建其DKG和安全证明，但并未直接继承该漏洞。最后，文章提供了针对Belenios DKG的详细安全证明，以增强选民隐私保护的技术基础。此外，文章还分析了在不同实践场景下，如涉及人类、软件和硬件的交互，对基于托管人模型的隐私保护部署的具体影响，突显了理论与实践之间的差异及其复杂性。 <div>
For more than forty years, two principal questions have been asked when designing verifiable election systems: how will the integrity of the results be demonstrated and how will the privacy of votes be preserved? Many approaches have been taken towards answering the first question such as use of MixNets and homomorphic tallying. But in the academic literature, the second question has always been answered in the same way: decryption capabilities are divided amongst multiple independent “trustees” so that a collusion is required to compromise privacy.

In practice, however, this approach can be fairly challenging to deploy. Human trustees rarely have a clear understanding of their responsibilities, and they typically all use identical software for their tasks. Rather than exercising independent judgment to maintain privacy, trustees are often reduced to automata who just push the buttons they are told to when they are told to, doing little towards protecting voter privacy. This paper looks at several aspects of the trustee experience. It begins by discussing various cryptographic protocols that have been used for key generation in elections, explores their impact on the role of trustees, and notes that even the theory of proper use of trustees is more challenging than it might seem. This is illustrated by showing that one of the only references defining a full threshold distributed key generation (DKG) for elections defines an insecure protocol. Belenios claims to rely on that reference for its DKG and security proof. Fortunately, it does not inherit the same vulnerability. We offer a security proof for the Belenios DKG. 

The paper then discusses various practical contexts, in terms of humans, software, and hardware, and their impact on the practical deployment of a trustee-based privacy model.
]]></content:encoded>
<pubDate>Fri, 07 Jun 2024 23:01:34 +0000</pubDate>
</item>
<item>
<title>Elastic MSM: A Fast, Elastic and Modular Preprocessing Technique for Multi-Scalar Multiplication Algorithm on GPUs</title>
<link>https://eprint.iacr.org/2024/057</link>
<guid>https://eprint.iacr.org/2024/057</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、GPU、多尺度乘法、预处理技术、Pippenger算法

总结:
本文主要关注在GPU上优化多尺度乘法（MSM）算法的运行时间和存储空间需求。提出了一种名为“弹性MSM”的新颖、模块化和自适应参数配置技术，允许用户根据自己的需求调整MSM的规模，通过相应的预处理操作。该技术能够充分利用各种高效的并行MSM算法潜力。研究者在GPU上实现了并测试了弹性MSM，针对三种主流的Pippenger并行算法进行了优化。

弹性MSM不仅被视为Pippenger算法的一种预处理技术，而且具有模块性，可以加速几乎所有最先进的GPU上的Pippenger并行算法。此外，它提供了在不同存储空间限制下GPU上的Pippenger算法运行时间与额外存储空间需求之间的可调折衷方案。这是首次在不同的存储空间限制下保留预处理带来的改进MSM计算的技术。

研究结果显示，针对三种并行Pippenger算法，弹性MSM分别实现了约1.90×、1.08×和1.36×（2.58×、1.39×和1.91×）的加速效果。同时，对于两种最先进的预处理Pippenger算法，弹性MSM分别实现了约192×和223×（159×和174×）的加速效果。这些结果表明，弹性MSM显著提高了零知识证明中的多尺度乘法运算效率，为GPU上的大规模加密计算提供了有力支持。 <div>
Zero-knowledge proof (ZKP) is a cryptographic primitive that enables a prover to convince a verifier that a statement is true, without revealing any other information beyond the correctness of the statement itself. Due to its powerful capabilities, its most practical type, called zero-knowledge Succinct Non-interactive ARgument of Knowledge (zkSNARK), has been widely deployed in various privacy preserving applications such as cryptocurrencies and verifiable computation. Although state-of-the-art zkSNARKs are highly efficient for the verifier, the computational overhead for the prover is still orders of magnitude too high to warrant use in many applications. This overhead arises from several time-consuming operations, including large-scale matrix-vector multiplication (MUL), number-theoretic transform (NTT), and especially the multi-scalar multiplication (MSM) which constitutes the largest proportion. Therefore, further efficiency improvements are needed.

  In this paper, we focus on comprehensive optimization of running time and storage space required by the MSM algorithm on GPUs. Specifically, we propose a novel, modular and adaptive parameter configuration technique—elastic MSM to enable us to adjust the scale of MSM according to our own wishes by performing a corresponding amount of preprocessing. This technique enables us to fully unleash the potential of various efficient parallel MSM algorithms. We have implemented and tested elastic MSM over three prevailing parallel Pippenger algorithms on GPUs. Across various preprocessing space limitations (across various MSM scales), our constructions achieve up to about 1.90×, 1.08× and 1.36× (2.58×, 1.39× and 1.91×) speedup versus three state-of-the-art parallel Pippenger algorithms on GPUs, respectively.

  From another perspective, elastic MSM could also be regarded as a preprocessing technique over the well-known Pippenger algorithm, which is modular and could be used to accelerate almost all the most advanced parallel Pippenger algorithms on GPUs. Meanwhile, elastic MSM provides an adaptive trade-off between the running time and the extra storage space needed by parallel Pippenger algorithms on GPUs. This is the first preprocessing technique to retain the improved MSM computation brought by preprocessing under varying storage space limitations. Specifically, across various preprocessing space limitations (across various MSM scales), our constructions achieve up to about 192× and 223× (159× and 174×) speedup versus two state-of-the-art preprocessing parallel Pippenger algorithms on GPUs, respectively.
]]></content:encoded>
<pubDate>Mon, 15 Jan 2024 07:19:29 +0000</pubDate>
</item>
<item>
<title>Stackproofs: Private proofs of stack and contract execution using Protogalaxy</title>
<link>https://eprint.iacr.org/2024/1281</link>
<guid>https://eprint.iacr.org/2024/1281</guid>
<content:encoded><![CDATA[
<div> 关键词：zk-SNARK、Aztec协议、增量可验证计算、重复计算与全局状态、证明系统

总结:

本文探讨了一种简化版的zk-SNARK构造方法，该方法被应用于Aztec协议中。该方法受增量可验证计算(IVC)启发，提出了“重复计算与全局状态”(RCG)的概念。与IVC不同，RCG假定计算在证明开始前结束，并允许一些全局一致性检查，同时要求证明者空间效率接近于无需证明全局一致性的IVC证明者。

在设计私有智能合约系统如Aztec时，RCG证明系统显得尤为有用。通过利用RCG，Aztec能够确保计算过程的隐私性，同时保证全局状态的一致性，这在构建安全、高效且私密的区块链应用时至关重要。这种证明系统的应用不仅提高了计算的隐私保护能力，还优化了证明者处理数据和执行一致性检查的方式，从而实现了更高的性能和更低的空间复杂度。

通过将RCG融入Aztec协议中，可以构建出一个既能满足高隐私需求又能保证系统稳定性和效率的智能合约环境。这不仅为区块链技术在实际应用中的隐私保护提供了新的思路，也为未来的智能合约设计提供了可能的方向。 <div>
The goal of this note is to describe and analyze a simplified variant of the zk-SNARK construction used in the Aztec protocol.
Taking inspiration from the popular notion of Incrementally Verifiable Computation[Val09] (IVC)
we define a related notion of $\textrm{Repeated Computation with Global state}$ (RCG). As opposed to IVC, in RCG we assume the computation terminates before proving starts, and in addition to the local transitions some global consistency checks of the whole computation are allowed. However, we require the space efficiency of the prover to be close to that of an IVC prover not required to prove this global consistency.
We show how RCG is useful for designing a proof system for a private smart contract system like Aztec.
]]></content:encoded>
<pubDate>Wed, 14 Aug 2024 00:50:12 +0000</pubDate>
</item>
<item>
<title>OPTIKS: An Optimized Key Transparency System</title>
<link>https://eprint.iacr.org/2023/1515</link>
<guid>https://eprint.iacr.org/2023/1515</guid>
<content:encoded><![CDATA[
<div> 关键词：OPTIKS、公开密钥分布系统、可扩展性、安全性、隐私性

总结:

本文介绍了名为OPTIKS的全面优化且具有可扩展性的密钥透明度（KT）系统。与以往工作相比，该系统在设计上更为简洁高效，能够以更小的存储开销支持更强的安全性和隐私性要求。其核心贡献包括：

1. **优化设计**：OPTIKS通过简化设计和提升性能，实现了对现有构建的改进，使其更适合实际应用，同时保证了系统的稳定性和效率。

2. **抗故障架构**：系统采用了具有抗故障特性的服务器架构，确保了在机器失效情况下仍能维持正常运行，显著提升了系统的可扩展性和鲁棒性。

3. **全面功能**：除了基础的密钥透明度功能外，OPTIKS还考虑到了账户撤销和用户到设备映射等现实世界中的问题，提高了系统适用范围和实用性。

4. **安全与隐私**：系统设计中融入了强安全性和隐私保护机制，确保了用户数据的安全和匿名性，增强了用户信任。

5. **性能验证**：通过详细的基准测试，证明了OPTIKS在实际应用中的高效表现，为系统的广泛部署提供了有力的数据支持。

综上所述，OPTIKS不仅提供了一种高效的密钥透明度解决方案，而且在设计、性能、安全性和实用性方面均表现出色，为密钥管理领域带来了重要的进步。 <div>
Key Transparency (KT) refers to a public key distribution system with transparency mechanisms proving its correct operation, i.e., proving that it reports consistent values for each user's public key. While prior work on KT systems have offered new designs to tackle this problem, relatively little attention has been paid on the issue of scalability. Indeed, it is not straightforward to actually build a scalable and practical KT system from existing constructions, which may be too complex, inefficient, or non-resilient against machine failures.

In this paper, we present OPTIKS, a full featured and optimized KT system that focuses on scalability. Our system is simpler and more performant than prior work, supporting smaller storage overhead while still meeting strong notions of security and privacy. Our design also incorporates a crash-tolerant and scalable server architecture, which we demonstrate by presenting extensive benchmarks. Finally, we address several real-world problems in deploying KT systems that have received limited attention in prior work, including account decommissioning and user-to-device mapping.
]]></content:encoded>
<pubDate>Wed, 04 Oct 2023 19:49:16 +0000</pubDate>
</item>
<item>
<title>Cryptographic Analysis of the Bluetooth Secure Connection Protocol Suite</title>
<link>https://eprint.iacr.org/2021/1597</link>
<guid>https://eprint.iacr.org/2021/1597</guid>
<content:encoded><![CDATA[
<div> 关键词：蓝牙、安全连接协议套件、分析、攻击、信任首次使用

总结:
本文对蓝牙安全连接协议套件进行了深入的加密分析。分析了该协议套件中的多个子协议，如数字比较、密码输入和无需工作的功能，以适应不同设备的输入/输出能力。与以往仅关注单个子协议安全性的研究不同，本文着重于不同子协议间的交互可能引发的安全问题，特别是通过方法混淆攻击等实际验证的攻击手段，这些攻击表明无法证明蓝牙协议套件是一个安全的认证密钥交换协议。

为了应对这些挑战，文章提出了假设的信任首次使用（TOFU）关系下的安全策略，即确保协议在初次连接时抵御主动攻击，随后的连接则可视为安全。同时，文章也探讨了蓝牙低功耗版本中的地址随机化机制，指出其在提供一定程度的地址隐私方面表现良好，但不能排除通过其他方式识别设备的可能性，例如物理特性。

总的来说，虽然蓝牙安全连接协议套件存在潜在的安全风险，尤其是在不同子协议间的交互上，但通过适当的策略和假设，仍能在一定程度上保证通信的安全性和隐私性。 <div>
We give a cryptographic analysis of the Bluetooth Secure Connections Protocol Suite. Bluetooth supports several subprotocols, such as Numeric Comparison, Passkey Entry, and Just Works, in order to match the devices' different input/output capabilities.

Previous analyses (e.g., Lindell, CT-RSA'09, or Troncoso and Hale, NDSS'21) often considered (and confirmed) the security  of single subprotocols only. Recent practically verified attacks, however, such as the Method Confusion Attack (von Tschirschnitz et al., S&amp;P'21) against Bluetooth's authentication and key secrecy property, often exploit the bad interplay of different subprotocols. Even worse, some of these attacks demonstrate that one cannot prove the Bluetooth protocol suite to be a secure authenticated key exchange protocol.

We therefore aim at the best we can hope for and show that the protocol still matches the common key secrecy requirements of a key exchange protocol if one assumes a trust-on-first-use (TOFU) relationship. This means that the adversary needs to mount an active attack during the initial connection, otherwise the subsequent reconnections remain secure.

Investigating the cryptographic strength of the Bluetooth protocol, we also look into the privacy mechanism of address randomization in Bluetooth (which is only available in the Low Energy version). We show that the cryptography indeed provides a decent level of address privacy, although this does not rule out identification of devices via other means, such as physical characteristics.
]]></content:encoded>
<pubDate>Thu, 09 Dec 2021 03:10:30 +0000</pubDate>
</item>
<item>
<title>Analyzing and Benchmarking ZK-Rollups</title>
<link>https://eprint.iacr.org/2024/889</link>
<guid>https://eprint.iacr.org/2024/889</guid>
<content:encoded><![CDATA[
<div> 关键词：区块链技术、ZK-Rollups、零知识证明、层2解决方案、经济影响

总结:

本文通过理论和实证研究深入探讨了ZK-Rollups（零知识证明型Rollups）在区块链技术中的应用与效能。研究首先从概念出发，解析了ZK-Rollups在提高区块链网络处理能力、降低交易成本以及保障安全性的优势，特别是通过利用零知识证明机制，实现快速链上验证，从而提升整体效率。

接下来，文章进行了一次详细的成本分析，涵盖了ZK-Rollups设计中涉及的各项费用，包括但不限于计算资源、存储需求及网络通信成本。同时，针对当前市场上两个知名ZK-Rollup项目——Polygon zkEVM和zkSync Era进行了具体案例研究，通过对比分析揭示了不同设计决策带来的性能差异及其对经济因素的影响。

研究最终提出了评估ZK-Rollup系统的一套系统化方法论，旨在为后续的研究、开发与部署提供指导。通过对现有项目的实际数据进行分析，本研究不仅提供了对ZK-Rollup实施过程中的初步理解，还指出了可能存在的优化空间和未来研究方向，对于推动ZK-Rollups技术的成熟与普及具有重要意义。 <div>
As blockchain technology continues to transform the realm of digital transactions, scalability has emerged as a critical issue. This challenge has spurred the creation of innovative solutions, particularly Layer 2 scalability techniques like rollups. Among these, ZK-Rollups are notable for employing Zero-Knowledge Proofs to facilitate prompt on-chain transaction verification, thereby improving scalability and efficiency without sacrificing security. Nevertheless, the intrinsic complexity of ZK-Rollups has hindered an exhaustive evaluation of their efficiency, economic impact, and performance.

This paper offers a theoretical and empirical examination aimed at comprehending and evaluating ZK-Rollups, with particular attention to ZK-EVMs. We conduct a qualitative analysis to break down the costs linked to ZK-Rollups and scrutinize the design choices of well-known implementations. Confronting the inherent difficulties in benchmarking such intricate systems, we introduce a systematic methodology for their assessment, applying our method to two prominent ZK-Rollups: Polygon zkEVM and zkSync Era. Our research provides initial findings that illuminate trade-offs and areas for enhancement in ZK-Rollup implementations, delivering valuable insights for future research, development, and deployment of these systems.
]]></content:encoded>
<pubDate>Tue, 04 Jun 2024 09:46:07 +0000</pubDate>
</item>
<item>
<title>Information-Theoretic Topology-Hiding Broadcast: Wheels, Stars, Friendship, and Beyond</title>
<link>https://eprint.iacr.org/2024/1266</link>
<guid>https://eprint.iacr.org/2024/1266</guid>
<content:encoded><![CDATA[
<div> 关键词：拓扑隐藏广播、信息论安全、轮图、子图、友谊图

总结:

本文研究了信息论安全（IT）条件下的拓扑隐藏广播（THB），特别关注于轮图及其子图类。主要发现如下：

1. **轮图及其子图的IT-THB可行性**：文章通过分析具有嵌入星结构的轮图子图，揭示了其IT-THB可行性与对应图的更精细度结构相关，而不仅仅是简单的连通性。

2. **新图类的完美IT-THB实现**：文章提供了一些新的正向结果，实现了对未知节点数的图类的完美IT-THB，这是之前未解决的问题。

3. **多故障情况下的IT-THB**：首次证明了在具有t>1个故障的非退化图类中实现IT-THB的可能性，具体为友谊图类，这标志着在多故障场景下实现信息论安全THB的一个重要进展。

4. **理论框架的扩展**：通过研究轮图及其子图，文章扩展了之前关于IT-THB可行性的理论框架，为理解不同图类下的THB提供了新的视角和工具。

5. **技术贡献**：这项工作不仅提供了理论上的见解，还可能启发新的安全通信协议设计，特别是在网络拓扑保护方面，对于构建更加安全和私密的分布式系统具有重要意义。 <div>
Topology-hiding broadcast (THB) enables parties communicating over an incomplete network to broadcast messages while hiding the network topology from within a given class of graphs. Although broadcast is a privacy-free task, it is known that THB for certain graph classes necessitates computational assumptions, even against "honest but curious" adversaries, and even given a single corrupted party. Recent works have tried to understand when THB can be obtained with information-theoretic (IT) security (without cryptography or setup assumptions) as a function of properties of the corresponding graph class.

We revisit this question through a case study of the class of wheel graphs and their subgraphs. The $n$'th wheel graph is established by connecting $n$ nodes who form a cycle with another "center" node, thus providing a natural extension that captures and enriches previously studied graph classes in the setting of IT-THB.

We present a series of new findings in this line.
We fully characterize feasibility of IT-THB for any class of subgraphs of the wheel, each possessing an embedded star (i.e., a well-defined center connected to all other nodes). Our characterization provides evidence that IT-THB feasibility may correlate with a more fine-grained degree structure---as opposed to pure connectivity---of the corresponding graphs.
We provide positive results achieving perfect IT-THB for new graph classes, including ones where the number of nodes is unknown. Further, we provide the first feasibility of IT-THB on non-degenerate graph-classes with $t>1$ corruptions, for the class of friendship graphs (Erdos, Renyi, Sos '66).
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 13:05:02 +0000</pubDate>
</item>
<item>
<title>Succinct Non-Subsequence Arguments</title>
<link>https://eprint.iacr.org/2024/1264</link>
<guid>https://eprint.iacr.org/2024/1264</guid>
<content:encoded><![CDATA[
<div> 关键词：非子序列论证、多变量多项式承诺方案、证明时间、验证时间、批处理子序列论证

总结:本文提出了首个简洁的非子序列论证方案。该方案利用求和检查协议，可与任何多变量多项式承诺方案结合使用。我们的解决方案在证明者运行时间上实现了线性增长，与序列s、t及其各自字母表Σ的大小成正比。证明的大小为O(log₂|s| + log₂|t| + log₂|Σ|)，验证时间则为O(√|s| + √|t| + √|Σ|)。基于Sona多项式承诺方案（EUROCRYPT'24），我们能够实现高效的证明机制。此外，通过扩展技术，我们还能够构建批处理子序列论证，用于同时验证多个交错子序列和非子序列论证，而无需证明大小出现线性增长。这项工作对DNA序列分析、物联网、区块链、自然语言处理、语音识别等领域具有潜在的重要应用价值。 <div>
Lookup arguments have recently attracted a lot of developments due to their applications in the constructions of succinct non-interactive arguments of knowledge (SNARKs). A closely related topic is subsequence arguments in which one can prove that string $\mathbf{s}$ is a subsequence of another string $\mathbf{t}$, i.e., deleting some characters in $\mathbf{t}$ can achieve $\mathbf{s}$. A dual notion, namely, non-subsequence arguments, is to prove that $\mathbf{s}$ is not a subsequence of $\mathbf{t}$. 
These problems have a lot of important applications in DNA sequence analysis, internet of things, blockchains, natural language processing, speech recognition, etc. However, despite their applications, they are not well-studied in cryptography, especially succinct arguments for non-subsequences with efficient proving time and sublinear verification time.

In this work, we propose the first succinct non-subsequence argument. Our solution applies the sumcheck protocol and is instantiable by any multivariate polynomial commitment schemes (PCSs). We achieve an efficient prover whose running time is linear in the size of sequences $\mathbf{s}$, $\mathbf{t}$ and their respective alphabet $\Sigma$. Our proof is succinct and the verifier time is sublinear assuming the employed PCS has succinct commitments and sublinear verification time. When instantiating with Sona PCS (EUROCRYPT'24), we achieve proof size $\mathcal{O}(\log_2|\mathbf{s}| + \log_2|\mathbf{t}|+\log_2|\Sigma|)$, prover time $\mathcal{O}(|\mathbf{s}|+|\mathbf{t}|+|\Sigma|)$  and verifier time $\mathcal{O}(\sqrt{|\mathbf{s}|}+\sqrt{|\mathbf{t}|}+\sqrt{|\Sigma|})$.

Extending our technique, we can achieve a batch subsequence argument for proving in batch $k$ interleaving subsequence and non-subsequence arguments without proof size suffering a linear blow-up in $k$.
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 06:52:34 +0000</pubDate>
</item>
<item>
<title>Dilithium-Based Verifiable Timed Signature Scheme</title>
<link>https://eprint.iacr.org/2024/1262</link>
<guid>https://eprint.iacr.org/2024/1262</guid>
<content:encoded><![CDATA[
<div> 关键词：Verifiable Timed Signatures（VTS）、BLS签名、Schnorr签名、ECDSA、CRYSTALS-Dilithium

文章总结：

Verifiable Timed Signatures（VTS）是一种用于在未来特定时间获取签名并证明其合法性的加密构建。它们在支付通道网络、多方签名操作或多方计算等区块链应用中具有重要价值。目前，VTS方案主要基于BLS签名、Schnorr签名和ECDSA等签名算法。然而，这些算法在量子攻击下被认为是不安全的，因为Shor算法对离散对数问题的影响。为了解决这个问题，本文提出了一种基于NIST选定的量子抗性数字签名标准CRYSTALS-Dilithium的VT-Dilithium新VTS方案。该方案克服了Dilithium集成到VTS方案中的复杂性问题，包括多项式乘法、舍入操作等复杂的数学运算以及大模参数如多项式、多项式向量和矩阵。

综上所述，VT-Dilithium方案通过采用量子安全的CRYSTALS-Dilithium算法，提供了一种增强安全性和适应未来量子计算威胁的VTS解决方案。这不仅提高了系统在传统攻击下的安全性，而且确保了在量子计算时代下系统的持续安全性。此外，针对Dilithium特有的数学挑战，VT-Dilithium方案还引入了优化策略，以高效地处理其复杂度高的运算，从而实现更有效的VTS生成与验证过程。 <div>
Verifiable Timed Signatures (VTS)  are cryptographic constructs that enable obtaining a signature at a specific time in the future and provide evidence that the signature is legitimate. This framework particularly finds utility in applications such as payment channel networks, multiparty signing operations, or multiparty computation, especially within blockchain architectures. Currently, VTS schemes are based on signature algorithms such as BLS signature, Schnorr signature, and ECDSA. These signature algorithms are considered insecure against quantum attacks due to the effect of Shor's Algorithm on the discrete logarithm problem. We present a new VTS scheme called VT-Dilithium based on CRYSTALS-Dilithium Digital Signature Algorithm that has been selected as NIST's quantum-resistant digital signature standard and is considered secure against both classical and quantum attacks. Integrating Dilithium into the VTS scheme is more challenging problem due to its complex mathematical operations (i.e. polynomial multiplications, rounding operations) and large module parameters such as polynomials, polynomial vectors, and matrices. This work aims to provide a comprehensive exposition of the VT-Dilithium scheme.
]]></content:encoded>
<pubDate>Fri, 09 Aug 2024 06:03:14 +0000</pubDate>
</item>
<item>
<title>zk-Promises: Making Zero-Knowledge Objects Accept the Call for Banning and Reputation</title>
<link>https://eprint.iacr.org/2024/1260</link>
<guid>https://eprint.iacr.org/2024/1260</guid>
<content:encoded><![CDATA[
<div> 关键词：隐私保护、匿名性、可问责性、异步交互、状态机

总结:

本文提出了一种名为zk-promises的框架，旨在解决隐私保护系统中匿名客户端与多方互动时的状态完整性问题，同时支持异步更新。该框架的核心是将客户端状态存储在一个零知识证明（zk）对象中，通过加密承诺和零知识证明技术来确保状态的保密性、完整性和原子性。

zk-promises允许创建复杂的、带有任意异步回调的Turing完备状态机，使得客户端能够修改并证明其状态，同时还能将回调给第三方，从而实现对违规行为的追踪和惩罚。通过精心设计的协议，确保了那些更新其状态的客户端必须接收由第三方调用的回调。

基于此框架，构建了一个具有先进性能和功能的匿名声誉系统，包括异步声誉更新、封禁以及基于声誉的速率限制，以更有效地抵御Sybil攻击。该系统不仅保证了匿名性，还实现了对违规行为的可问责性，同时提高了系统的效率和用户体验。 <div>
Privacy preserving systems often need to allow anonymity while requiring accountability.  For anonymous clients, depending on application, this may mean banning/revoking their accounts, docking their reputation, or updating their state in some complex access control scheme. Frequently, these operations happen asynchronously when some violation, e.g., a forum post, is found well after the offending action occurred. Malicious clients, naturally, wish to evade this asynchronous negative feedback. Considering privacy-preserving analogues of modern access control and reputation schemes raises a more fundamental technical challenge with far broader applications: how do we allow multiple parties to interact with private state stored by an anonymous client while ensuring state integrity and supporting oblivious updates?

We propose zk-promises, a framework which supports Turing-complete state machines with arbitrary asynchronous callbacks. In zk-promises, client state is stored in a zk-object. Updates to the zk-object, represented as a cryptographic commitment to the new, modified object, require a zkSNARK that ensures integrity and atomicity while providing confidentiality.  Clients can modify and prove their state by calling valid methods (e.g, to show they are authorized to post) and can give callbacks to third parties (e.g., to later hold them accountable). Through careful protocol design, we ensure clients who advance their state-machine are forced to ingest callbacks that are called by a third party.

zk-promises allows us to build a privacy-preserving account model. State that would normally be stored on a trusted server can be privately outsourced to the client while preserving the server's ability to update the account. To demonstrate the feasibility of our approach, we build an anonymous reputation system with better than state-of-the-art performance and features, supporting asynchronous reputation updates, banning, and reputation-dependent rate limiting to better protect against Sybil attacks.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 21:20:57 +0000</pubDate>
</item>
<item>
<title>Efficient (Non-)Membership Tree from Multicollision-Resistance with Applications to Zero-Knowledge Proofs</title>
<link>https://eprint.iacr.org/2024/1259</link>
<guid>https://eprint.iacr.org/2024/1259</guid>
<content:encoded><![CDATA[
<div> 关键词：积聚器、认证字典、Merkle树、零知识证明、非对抗性攻击

文章主要讨论了在各种应用中使用的积聚器和认证字典，如证书透明度、区块链、隐私保护的去中心化电子货币等。文中提出了一个新型的（非）成员身份证明，具有更小的树深度，同时保持相同的安全性水平。此外，还引入了适用于特定场景的版本，深度最多可减少6倍。这些构造不需要动态树深度，简化了常规模块零知识证明电路，并确保了更小的深度上限。

在对抗性上下文中，该工作旨在实现高效且无需信任树管理者的构建，例如在区块链中，允许非受信任方执行操作并由任何人验证。文中考虑了特殊实例，特别是序列号（即nullifiers）的表示，并强调了构造的通用性，它们不仅适用于区块链和零知识证明，还能在非对抗性环境中使用，包括哈希表、数据库和其他数据结构。

总结:
本文提出了一种改进的积聚器和认证字典构造，旨在提高效率和安全性。通过减少树深度，新构造能够提供与传统方法相同的安全保障，同时支持更复杂的零知识证明应用。在非对抗性环境下，这些构造可以增强区块链系统的隐私性和可扩展性，同时确保非受信任方能够验证交易的有效性。此外，这些技术还可应用于其他数据存储系统，提高其性能和安全性。通过减少对动态深度的需求，该工作为构建常规模块零知识证明电路提供了基础，使得在实际应用中实现更高效的验证过程成为可能。 <div>
Many applications rely on accumulators and authenticated dictionaries, from timestamping certificate transparency and memory checking to blockchains and privacy-preserving decentralized electronic money, while Merkle tree and its variants are efficient for arbitrary element membership proofs, non-membership proofs, i.e., universal accumulators, and key-based membership proofs may require trees up to 256 levels for 128 bits of security, assuming binary tree, which makes it inefficient in practice, particularly in the context of zero-knowledge proofs. 

Building on the hardness of multi-collision we introduce a novel (non-)membership, optionally key-value, accumulator with up to 2x smaller tree depth while preserving the same security level, as well as multiple application-specific versions with even shallower trees, up to 6x smaller depth, that rely on the low-entropy source.
Moreover, solving for special case of adversarial attacks we introduce key index variants which might be a stepping stone for an entropy-free accumulator.

Notably, unlike other constructions, this work, although may, doesn't depend on the dynamic depth of the tree which is simpler and more suitable for constant-size ZKP circuits, while ensuring a substantially smaller upper bound on depth.

Efficient in practice construction in the adversarial context, e.g. blockchain, where the tree manager doesn't need to be trusted, i.e., operations can be carried out by an untrusted party and verified by anyone, is the primary goal.
Example instantiations are considered, where special treatment is given to the application of representing serial numbers, aka nullifiers. 
Nevertheless, the constructions are self-sufficient and can be used in other contexts, without blockchain and/or zero-knowledge proofs, including non-adversarial contexts.

Furthermore, our findings might be of independent interest for other use cases, such as hash tables, databases and other data structures.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 19:38:08 +0000</pubDate>
</item>
<item>
<title>Compass: Encrypted Semantic Search with High Accuracy</title>
<link>https://eprint.iacr.org/2024/1255</link>
<guid>https://eprint.iacr.org/2024/1255</guid>
<content:encoded><![CDATA[
<div> 关键词：Compass、加密数据、高准确性、隐私保护、Hierarchical Navigable Small Worlds（HNSW）

总结:
Compass 是一种在加密数据上实现的语义搜索系统，其准确度与传统明文搜索算法相当，同时能确保数据、查询和检索结果不被服务器完全攻击的威胁所泄露。此外，Compass 支持隐私保护的 RAG（关系图检索）场景，使得数据库和查询都能得到保护。为了实现这些功能，Compass 引入了一种新颖的方法，即使用 Oblivious RAM（ oblivious RAM）来在 Hierarchical Navigable Small Worlds（HNSW）这种高性能向量最近邻搜索中遍历搜索图。通过定向邻居过滤、推测贪婪搜索和针对 HNSW 的路径 ORAM 技术，Compass 能够实现用户感知的几秒级延迟，并且比基于加密嵌入的搜索基准快几个数量级。这些技术的结合不仅保证了搜索效率，还极大地增强了数据的安全性和隐私性。 <div>
We introduce Compass, a semantic search system over encrypted data that offers high accuracy, comparable to state-of-the-art plaintext search algorithms while protecting data, queries and search results from a fully compromised server. Compass also enables privacy-preserving RAG where both the RAG database and the query are protected. Compass's search index contributes a novel way to traverse the search graph in  Hierarchical Navigable Small Worlds (HNSW), a top performing vector nearest neighbor search, using Oblivious RAM, a cryptographic primitive with strong security guarantees. Our techniques, Directional Neighbor Filtering, Speculative Greedy Search and HNSW-tailored Path ORAM ensure that Compass achieves user-perceived latencies of few seconds and is orders of magnitude faster than a baseline for encrypted embeddings search.
]]></content:encoded>
<pubDate>Thu, 08 Aug 2024 04:29:55 +0000</pubDate>
</item>
<item>
<title>Complete Knowledge: Preventing Encumbrance of Cryptographic Secrets</title>
<link>https://eprint.iacr.org/2023/044</link>
<guid>https://eprint.iacr.org/2023/044</guid>
<content:encoded><![CDATA[
<div> 关键词：加密协议、可信执行环境（TEE）、安全多方计算、完全知识证明（CK）、区块链资产

总结:

本文探讨了加密协议中对密钥知识的传统模型面临的挑战，特别是随着可信执行环境（TEE）和安全多方计算的普及。这些技术允许有条件地访问秘密而不实际知道秘密本身，从而可能引发诸如投票出售、非法服务凭证交易以及匿名消息系统中否认性降低等问题。现有的证明知识方法未能表明秘密是否被限制或“束缚”。

为解决这一问题，文章引入并定义了一种新的概念——完全知识证明（CK）。CK不仅要求证明者知道秘密，还要求证明者拥有未被限制的、不受约束的秘密使用能力。通过利用特殊硬件，如可信执行环境（TEE）和现成的挖矿ASIC，文章提出了两个实用的CK方案，并证明了其安全性。此外，文章还展示了如何将CK应用于实践，包括与智能合约的集成验证，以及用于证明对区块链资产所有权的新型应用。

通过这些创新，文章旨在增强加密协议的安全性，防止由秘密束缚导致的潜在威胁，并拓展了完全知识证明在现代密码学中的应用领域。 <div>
Most cryptographic protocols model a player’s knowledge of secrets in a simple way. Informally, the player knows a secret in the sense that she can directly furnish it as a (private) input to a protocol, e.g., to digitally sign a message.

The growing availability of Trusted Execution Environments (TEEs) and secure multiparty computation, however, undermines this model of knowledge. Such tools can encumber a secret sk and permit a chosen player to access sk conditionally, without actually knowing sk. By permitting selective access to sk by an adversary, encumbrance of secrets can enable vote-selling in cryptographic voting schemes, illegal sale of credentials for online services, and erosion of deniability in anonymous messaging systems. 

Unfortunately, existing  proof-of-knowledge protocols fail to demonstrate that a secret is unencumbered. We therefore introduce and formalize a new notion called complete knowledge (CK). A proof (or argument) of CK shows that a prover does not just know a secret, but also has fully unencumbered knowledge, i.e., unrestricted ability to use the secret.

We introduce two practical CK schemes that use special-purpose hardware, specifically TEEs and off-the-shelf mining ASICs. We prove the security of these schemes and explore their practical deployment with a complete, end-to-end prototype with smart-contract verification that supports both. We show how CK can address encumbrance attacks identified in previous work. Finally, we introduce two new applications enabled by CK that involve proving ownership of blockchain assets.
]]></content:encoded>
<pubDate>Sun, 15 Jan 2023 08:50:38 +0000</pubDate>
</item>
<item>
<title>PROF: Protected Order Flow in a Profit-Seeking World</title>
<link>https://eprint.iacr.org/2024/1241</link>
<guid>https://eprint.iacr.org/2024/1241</guid>
<content:encoded><![CDATA[
<div> 关键词：PROF、分散式金融（DeFi）、Proposer-Builder Separation (PBS)、最大可提取价值（MEV）、交易顺序操纵

总结:

本文介绍了针对分散式金融(DeFi)应用中面临的由交易顺序操纵导致的最大可提取价值(MEV)风险的一种解决方案——PROF系统。PROF旨在通过两个关键策略限制有害形式的MEV：

1. **交易流保护**：PROF对一组私有输入的交易进行排序，并确保这一排序在整个区块生成过程中得以执行，防止交易顺序被操纵。

2. **盈利性区块生产**：创建的交易组对于区块生产者来说具有利润性，确保这些交易能及时被包含在区块中。

PROF系统具备与现有和未来PBS设计的兼容性，不增加额外的信任假设，执行效率高，延迟低。通过量化和定性分析，比较了PROF系统与现有解决方案的激励结构以及用户效益。此外，还报告了PROF交易的纳入可能性及其端到端实现的具体延迟时间。整体而言，PROF提供了一种在不牺牲系统性能的前提下，有效对抗MEV风险、保护用户利益的解决方案。 <div>
Users of decentralized finance (DeFi) applications face significant risks from adversarial actions that manipulate the order of transactions to extract value from users. Such actions---an adversarial form of what is called maximal-extractable value (MEV)---impact both individual outcomes and the stability of the DeFi ecosystem. MEV exploitation, moreover, is being institutionalized through an architectural paradigm known Proposer-Builder Separation (PBS).

This work introduces a system called PROF (PRotected Order Flow) that is designed to limit harmful forms of MEV in existing PBS systems. PROF aims at this goal using two ideas. First, PROF imposes an ordering on a set ("bundle") of privately input transactions and enforces that ordering all the way through to block production-preventing transaction-order manipulation. Second, PROF creates bundles whose inclusion is profitable to block producers, thereby ensuring that bundles see timely inclusion in blocks.

PROF is backward-compatible, meaning that it works with existing and future PBS designs. PROF is also compatible with any desired algorithm for ordering transactions within a PROF bundle (e.g., first-come, first-serve, fee-based, etc.). It executes efficiently, i.e., with low latency, and requires no additional trust assumptions among PBS entities. We quantitatively and qualitatively analyze PROF’s incentive structure, and its utility to users compared with existing solutions. We also report on inclusion likelihood of PROF transactions, and concrete latency numbers through our end-to-end implementation.
]]></content:encoded>
<pubDate>Tue, 06 Aug 2024 01:14:16 +0000</pubDate>
</item>
<item>
<title>Efficient Differentially Private Set Intersection</title>
<link>https://eprint.iacr.org/2024/1239</link>
<guid>https://eprint.iacr.org/2024/1239</guid>
<content:encoded><![CDATA[
<div> 关键词：Private Set Intersection (PSI), Differentially Private (DPSI), Fully Homomorphic Encryption (FHE), Reverse Private Membership Test (RPMT), Private Set Operation (PSO)

<br />
<br />总结:

本文研究了如何在保护敏感信息的同时进行数据集交集的计算。首先，文章回顾并重新定义了差分隐私条件下的私有集合交集（DPSI），识别出构建高效DPSI协议所需的关键需求，并提出了两种构建高效DPSI协议的方法框架。第一种方法将现有的DPSI概念进行了扩展，表明任何电路PSI都可以用于构建DPSI，并通过插入当前最先进的电路PSI协议来获得更高效的DPSI协议。第二种方法利用多查询逆私密成员测试（mqRPMT）来构建私有集合操作（PSO），但mqRPMT会额外泄露交集大小给发送方。为解决此问题，文章通过在输入集中填充随机占位符项目以限制泄露，利用差分隐私原则对这种泄露进行了控制。

实验结果显示，基于这两种方法构建的DPSI协议在通信效率和执行速度上都显著优于现有技术，分别是现有技术的2.5至22.6倍和110.5至151.8倍。此外，文章还展示了mqRPMT的新应用场景，除了用于获取PSO之外，还可以用于构建DPSI。这一工作不仅提高了DPSI协议的效率，还扩展了私有集合操作的使用场景，为数据安全与隐私保护提供了新的解决方案。 <div>
Private Set Intersection (PSI) enables a sender and a receiver to jointly compute the intersection of their sets without disclosing other information about items not in the intersection. However, in many cases of joint data analysis, it is not just the items outside the intersection that are sensitive but the items within it. To protect such sensitive information, prior work presents a Differentially Private version of PSI (DPSI) based on a circuit-PSI using Fully Homomorphic Encryption. However, their concrete protocol is somewhat inefficient compared with the state-of-the-art (SOTA) circuit-PSI.

In this paper, we revisit the DPSI definition and formalize its ideal functionality. We identify the key desiderata required by PSI-related tools to construct DPSI and propose two frameworks to construct efficient DPSI protocols. The first one generalizes the idea of existing DPSI, showing that any circuit-PSI can be used to construct DPSI. We obtain a more efficient DPSI protocol by plugging the SOTA circuit-PSI protocol in the framework. The second one helps to obtain a more efficient DPSI protocol based on the multi-query Reverse Private Membership Test (mqRPMT) that was previously used to construct Private Set Operation (PSO). However, mqRPMT additionally leaks the intersection size to the sender. We bound such leakage using differential privacy by padding random dummy items in input sets. We implement numerous constructions based on our frameworks. Experiments show that our protocols significantly outperform the existing DPSI construction, 2.5-22.6$\times$ more communication efficient and up to 110.5-151.8$\times$ faster. Our work also shows a new use case for mqRPMT besides obtaining PSO.
]]></content:encoded>
<pubDate>Mon, 05 Aug 2024 02:44:49 +0000</pubDate>
</item>
<item>
<title>XHash: Efficient STARK-friendly Hash Function</title>
<link>https://eprint.iacr.org/2023/1045</link>
<guid>https://eprint.iacr.org/2023/1045</guid>
<content:encoded><![CDATA[
<div> 关键词：零知识证明、哈希函数、ZK-STARK、Marvellous设计策略、XHash

总结:

本文提出了一种名为XHash的高性能哈希函数，专为ZK-STARKs设计，其性能超越了Rescue和Poseidon，成为STARKs中最有效的ZK友好哈希函数。XHash在CPU架构上的平均速度约为3μs，比Marvellous家族中最快的RPO快约2.5倍。从安全性角度看，XHash继承了Marvellous设计策略的安全性，并分析了其对当前代数攻击的抵抗能力。此外，文章还提出了针对代数攻击的新安全论证类型，基于一个合理且明确的新假设。最后，XHash为Polygon Miden VM提供了标准版本，其AIR复杂度为504，相比Rescue的672和Poseidon的1176，更具竞争力。

文章详细探讨了XHash的设计与性能优化，强调了其在零知识证明系统中的应用潜力，特别是在ZK-STARKs环境下的高效能表现。同时，XHash的安全性分析表明，它能够抵御当前的代数攻击手段，进一步增强了其在实际应用中的可靠性。此外，通过引入新的安全论证方法，文章为评估哈希函数的安全性提供了一种创新途径，这在提升整个零知识证明系统的安全性方面具有重要意义。最后，针对特定虚拟机环境的优化设计，使得XHash不仅在理论上表现出色，而且在具体应用中也具有较高的实用性。 <div>
Zero-knowledge proofs are widely used in real-world applications
for authentication, access control, blockchains, and cryptocurren-
cies, to name a few. A core element in zero-knowledge proof systems
is the underlying hash function, which plays a vital role in the effi-
ciency of the proof system. While the traditional hash functions,
such as SHA3 or BLAKE3 are efficient on CPU architectures, they
perform poorly within zero-knowledge proof systems. This is pri-
marily due to the requirement of these systems for hash functions
that operate efficiently over finite fields of large prime order as well
as binary fields. To address this challenge, a new paradigm called
Arithmetization-Orientation has emerged. These designs are tai-
lored to improve the efficiency of hashing within zero-knowledge
proof systems while providing reliable security guarantees.
In this work, we propose XHash, which is a high-performance
hash function designed for ZK-STARKs and is inspired by the Mar-
vellous design strategy. When using Algebraic Intermediate Repre-
sentation, XHash outperforms Rescue and Poseidon as the most im-
portant ZK-friendly hash functions for STARKs. Moreover, XHash
has a competitive performance on CPU architectures with an av-
erage speed of ≈ 3𝜇𝑠 for 2-to-1 hashing. Compared to RPO, which
is the fastest hash function of the Marvellous family, XHash per-
forms ≈ 2.5 times faster on CPU. From the security perspective,
XHash inherits the security of the Marvellous design strategy, and
we analyze its security against state-of-the-art algebraic attacks.
Additionally, we propose a new type of security argument against
algebraic attacks that relies on a single well-defined and reasonable
conjecture of a novel type. Finally, we specify a standard version of
XHash designed for Polygon Miden VM, with its AIR complexity
being 504, compared to Rescue with an AIR complexity of 672, and
Poseidon with an AIR complexity of 1176.
]]></content:encoded>
<pubDate>Tue, 04 Jul 2023 14:23:33 +0000</pubDate>
</item>
<item>
<title>Route Discovery in Private Payment Channel Networks</title>
<link>https://eprint.iacr.org/2021/1539</link>
<guid>https://eprint.iacr.org/2021/1539</guid>
<content:encoded><![CDATA[
<div> 关键词：私有信道网络、路由发现、隐私保护、多党计算、效率

总结:

本文研究了私有信道网络中的路由发现问题。首先，文章定义了在此环境下理想的隐私标准，并指出通过多党计算实现这一标准的协议存在，但其效率低下，因为整个网络都参与路径发现过程。

接着，文章提出了一种具有较弱隐私保证但更高效性的路由协议。这些协议允许路由发现主要由网络中一小部分节点完成，同时泄露了一些关于拓扑结构和平衡的信息，而这些信息超出交易执行所需。

核心理念是，发送者和接收者同时广播消息，这些消息逐渐在整个网络中传播。一旦网络中的任何节点接收到两个消息，路径就被找到。第一种协议总是将消息发送给所有相邻节点，延迟与边费用成正比。第二种协议仅随机选择一个邻居发送消息，概率与其度数成正比。尽管第一种协议总能找到最便宜的路径，但第二种可能无法做到这一点，但涉及的网络节点数量较少。

此外，文章讨论了使用双线性映射来重新随机化广播消息的扩展，以提高隐私性。还提出了进一步改进隐私性的方法，如使用双线性映射。

通过模拟研究，文章发现第一种协议通常涉及约12%的6376个节点，而第二种则仅触及约18个节点（不到0.3%），找到的路径成本大约是最佳路径成本的两倍。 <div>
In this work, we are the first to explore route discovery in private channel networks.
We first determine what ``ideal" privacy for a routing protocol means in this setting.  We observe that protocols achieving this strong privacy definition exist by leveraging (topology hiding) Multi-Party Computation but they are (inherently) inefficient as route discovery must involve the entire network.

We then present protocols with weaker privacy guarantees but much better efficiency. In particular, route discovery typically only involves small fraction of the nodes but some information on the topology and balances -- beyond what is necessary for performing the transaction -- is leaked.

The core idea is that both  sender and receiver gossip a message which then slowly propagates through the network, and the moment any node in the network receives both messages, a path is found. In our first protocol the message is always sent to all neighbouring nodes with a delay proportional to the fees of that edge. In our second protocol the message is only sent to one neighbour chosen randomly with a probability proportional to its degree. While the first instantiation always finds the cheapest path, the second might not, but it involves a smaller fraction of the network.

% We discuss some extensions like employing bilinear maps so the gossiped messages can be re-randomized, making them unlikeable and thus improving privacy.
We also discuss some extensions to further improve privacy by employing bilinear maps.

Simulations of our protocols on the Lightning network topology (for random transactions and uniform fees) show that our first protocol (which finds the cheapest path) typically involves around 12\%  of the 6376 nodes, while the second only touches  around 18 nodes $(<0.3\%)$,  and the cost of the path that is found  is around twice the cost of  the optimal one.
]]></content:encoded>
<pubDate>Mon, 22 Nov 2021 11:36:25 +0000</pubDate>
</item>
</channel>
</rss>